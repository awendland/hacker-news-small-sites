<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 5]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 5. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Tue, 08 Dec 2020 20:27:40 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-5.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Tue, 08 Dec 2020 20:27:40 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[The CIA's Deadly Deceits and the Vietnam War, with Ralph McGehee (1986)]]>
            </title>
            <description>
<![CDATA[
Score 50 | Comments 30 (<a href="https://news.ycombinator.com/item?id=25329913">thread link</a>) | @AndrewBissell
<br/>
December 6, 2020 | https://ourhiddenhistory.org/entry/the-cia-s-deadly-deceits-and-the-vietnam-war-w-ex-cia-officer-ralph-mcgehee | <a href="https://web.archive.org/web/*/https://ourhiddenhistory.org/entry/the-cia-s-deadly-deceits-and-the-vietnam-war-w-ex-cia-officer-ralph-mcgehee">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-bolt-field="body"><p><iframe allowfullscreen="" frameborder="0" src="https://www.youtube.com/embed/BDZv57p1Ixk"></iframe></p>



<p><b>Ralph W. McGehee:</b> It's a real honor for me to be here today. I don't often say that, but I really mean it. I like to start off my talk by mentioning two things. One, please don't believe anything I'm going to tell you. The American people are so inundated by misinformation, there's absolutely no reason you should believe anything anybody tells you, particularly the evening news. Of course, with everything there is an exception, and I think in my case, I have a fairly valid exception. Because of the process that I had to go through to clear my book, I had to prove that everything I am saying is in the public domain. I still go down to the Agency about twice a month and turn in new material to let them clear it. And in doing that process, I have to produce or pull out from government documents that particular information, because they inevitably will say, "You can't say it, it's classified." And I will inevitably locate that information in the public domain.</p> 
 
<p>So if you doubt me, and I hope you will, there is a way to check up on me. Go to the library and look in the back of my book, and almost every major conclusion that I will be talking about here today will be documented to an official government document. I've drawn upon the Pentagon Papers. Are you all familiar with the Pentagon Papers? And the Senate and House investigations of the Agency and a variety of other material. So don't believe what I say, but if you want to check up on me, the information is available.</p> 
 
<p>Secondly, I'd like to say my message is basically a real downer. It is real negative, but I don't want to leave you with that impression, because I just returned from a two week speaking trip in Iowa, where I was going to testify at the court case there in Iowa City for the protesters, and in Nebraska. And I've been in Arizona and various other places speaking, and wherever you go, you find concerned groups. So I am encouraged. I know during the Vietnam War for the first ten years, we didn't even know what was going on. And then eleven or twelve years later, people began to protest. But this time in Latin America, the protest was almost instantaneous. The substructure is there. The only reason we got out of Vietnam, of course, is because of the student protests. So I am very encouraged. My message is negative, but I don't want to leave you with that impression. I am very, very encouraged.</p> 
 
<p>I think I should talk in three basic phases. One, walk you very quickly through my career with the Agency up to right now where I am today, and back up and walk you through Vietnam a little bit or walk you through my career in a little more detail, including Vietnam. Now I do that not to talk about Vietnam but because the processes that are followed today in Central America, in the Middle East and in Africa have all been used in Vietnam. I'll take out three or four incidences, and they are documented by the way, and show you that these are sort of typical of what the Agency does around the world since the very beginning in '47, what it's doing today in '86.</p> 
 
<p>Then I'll go back and review the Agency's domestic operations, and I'll do that for one purpose, because everything they were doing up to the mid-seventies they are now doing again. The only difference now is under President Reagan's Executive Order 12333 of December '81, they can do the things legally that they were doing illegally before. It's the only difference. Then I would like to talk, sort of bring it all together in Central America and talk about El Salvador, Grenada, and particularly Nicaragua, and then come to my conclusion. So that's basically the approach I'll take.</p> 
 
<p>I went to the University of Notre Dame. I played on four undefeated football teams, three national championships, and then I tried out with the Green Bay Packers. And to this day, I can't understand what's the matter with the coaches up there. When I was cut, I received a cable, "Would you be interested in an important government position similar to the State Department in function?" My football background was not irrelevant. When I went down to Washington, I found that the class before me, my class, and the class after me were basically rejects from the National Football League, not the standard concept of an intelligent (He does say "intelligent" here, I think as a joke about football players) officer.</p> 
 
<p>Well, I served in the Agency for 25 years. The first 15 or 16 years, I believed that the CIA was sort of like a missionary organization, out saving the world for democracy and religion and gathering good intelligence to help our policymakers make good decisions. When I'd go into work in the morning, I'd feel a real pride that I'm part of the great crusade to stop the international communist conspiracy. All that began to change for me in Vietnam. That's when I began protesting.</p> 
 
<p>I should mention that I served my entire 25 years in the Directorate of Operations. Now, the Agency is broken down to basically four directorates, Administration, Science and Technology, Intelligence, and Operations. Administrators administrate. Science and Technology, they devise the sophisticated collection devices and monitor the results. The Directorate of Intelligence, that's the scholars who sit and read the reports that come in from around the world and then put out the final reports. And the Operators operate. The Directorate of Operations has two basic functions, covert operations and gathering intelligence covertly.</p> 
 
<p>Since it's my contention that the Agency is little more than a covert action agency, I will dwell a little bit on it. Now, covert action operations in broadest context can be described as those operations designed to overthrow or support foreign governments. Overthrow operations have four basic components, economic warfare, political warfare, psychological warfare, and economic warfare. In my 25 years in the Agency, I served overseas in Japan, in the Philippines, in Taiwan, six years or three tours in Thailand, and two years as the chief police adviser to the head of the Vietnamese Special Police. That's the equivalent of our FBI.</p> 
 
<p>As I said, my period of protests began around the Vietnam War. I for the next period within the Agency began protesting, and having no luck with those protests, I finally left the Agency in 1977. Now, in a stroke of real irony at this particular point, because they had assigned me to the CIA’s Siberia. When you escalate your protest, you become persona non grata. In '77 in a stroke of irony, they awarded me the Career Intelligence Medal and the Honorable Service Medal. Of course, I think I know why. They knew they had a loose cannon and they wanted to kind of damp me down, appease me a little bit. And I think that was the purpose of giving them to me.</p> 
 
<p>But I also earlier had won awards, two Vietnam service awards, a commendation from the director for devising a program of counterinsurgency and intelligence, and a variety of other CIA and foreign awards. Well, when I left the Agency, I testified before the Senate and House intelligence committees and before a variety of other Senate and House committees, all related to CIA activities.</p> 
 
<p>I immediately set about writing a book about my experiences. It took me three years to research and write the book, and then like all CIA officers, when you join the Agency, you have to sign a secrecy agreement. And as I said, I must now submit everything to the CIA for pre-publication review. I did, and they came back and they said they have identified approximately 400 security violations in my manuscript. And they returned it in little bits and pieces of paper, because some of these deletions ran up to several pages in length.</p> 
 
<p>Well, to defeat this process, I went through going through the public record and pulling out the identical information. And ultimately with this effort, I got virtually everything reinstated. There are a few little specifics that I didn't get reinstated, but for the most part they were all reinstated. I did in a few cases, they had deleted some very boring information, so I said rather than fight them over this one, let's just leave this comment, "Seven words deleted." It looks a lot sexier than mine. So I didn't fight them on all of them.</p> 
 
<p>Then I went looking for a publisher, a long hard process, and finally one publisher said, "You know, you've written a nice legal brief here. You make your points and then you have your citations to your information. But boy, it's dull as mud. Who would want to read a legal brief? So we will publish it if you'll rewrite it as a autobiography," which I did. I then resubmitted it to the CIA for pre-publication review. I didn't put any more secret details in there. I just added my personal life.</p> 
 
<p>At this time, William Casey had become Director of the CIA, and they in essence told me, "We're not going to let you publish a book." And I said, "Well, you can't stop me. Everything that's in the book, you have not only cleared for other people, it's not only in the public record, but you also cleared for me before. And the laws that you operate under say you may not reclassify information once it's been declassified and released." And their response in essence, "Well, that's tough. We're doing it anyhow. There's nothing you can do about it." Well, this was a very critical period. I just didn't know what to do. I really worried about this, because if they would've stopped me with that, then I would not be able to speak to you here this evening, because everything would have been classified.</p> 
 
<p>So I called <i>The Washington Post</i>, and <i>The Washington Post</i> ran a long exposé of how the CIA was violating the law by reclassifying information that was in the public domain, a violation of the law of the land. This public exposure forced the Agency to relent, and the book was finally released. Subsequent to the release of the book, I then traveled to Cuba, where we stayed about a week, and to Grenada, …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://ourhiddenhistory.org/entry/the-cia-s-deadly-deceits-and-the-vietnam-war-w-ex-cia-officer-ralph-mcgehee">https://ourhiddenhistory.org/entry/the-cia-s-deadly-deceits-and-the-vietnam-war-w-ex-cia-officer-ralph-mcgehee</a></em></p>]]>
            </description>
            <link>https://ourhiddenhistory.org/entry/the-cia-s-deadly-deceits-and-the-vietnam-war-w-ex-cia-officer-ralph-mcgehee</link>
            <guid isPermaLink="false">hacker-news-small-sites-25329913</guid>
            <pubDate>Mon, 07 Dec 2020 06:45:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[TeX: A Tale of Two Worlds]]>
            </title>
            <description>
<![CDATA[
Score 23 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25329049">thread link</a>) | @Bella-Xiang
<br/>
December 6, 2020 | https://bitbashing.io/tex.html | <a href="https://web.archive.org/web/*/https://bitbashing.io/tex.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
    <!-- for XeTeX -->


<p>Best viewed in <del>Internet Explorer 6</del>
<a href="https://assets.bitbashing.io/papers/tex-tale-of-two-worlds.pdf">PDF</a>
because… well… read the damn thing.</p>

<!--
It all started when a college friend told me about a cool program for typesetting
papers. Now typography books litter my apartment and I can't read a menu
without noticing bad kerning. Thanks, Max. This is all your fault.
-->

<hr>

<p>Most serious programmers have heard of Donald Knuth,
the man who coined the term <em>analysis of algorithms</em> in 1968
and pioneered many of the computer science fundamentals we use today.
Knuth is perhaps most famous for his ongoing magnum opus,
<em>The Art of Computer Programming</em>.</p>

<p>When the first volume of TAOCP was released that same year,
it was printed the way most books had been since the turn of the century:
with <em>hot metal</em> type.
Each individual letter was cast from molten lead,
then arranged into its line.</p>

<figure>
<img src="https://upload.wikimedia.org/wikipedia/commons/7/72/Matrixcase-bembo-16pts.jpg" alt="Monotype matrix case" height="400">
<figcaption>
A case of letter molds—or <em>matrices</em>—used by the Monotype caster,
the most commonly-used machine for printing books in the days of hot metal type.
Its main contemporary, the Linotype, molded entire lines at a time,
and was often used for printing newspapers.
</figcaption>
</figure>

<p>These lines were clamped together to form pages of the book,
which were finally inked and pressed against paper.
By March of 1977, Knuth was ready for a second run of TAOCP, Volume&nbsp;2,
but he was horrified when he received the proofs.
Hot metal typesetting was an expensive, complicated, and time-consuming process,
so publishers had replaced it with phototypesetting,
which works by projecting characters onto film.
The new technology, while much cheaper and faster,
didn’t provide the same level of quality he had come to expect.</p>

<p>The average author would have resigned themselves to the change and moved on,
but Knuth took great pride in print quality,
especially for the mathematics in his books.
Around this time, he discovered an exciting new technology:
digital typesetting.
Instead of working with metal or film,
letters and shapes were built from tiny dots,
often packed together at over 1,000 per inch.
Inspired by this burgeoning tech and frustrated with the current state of affairs,
Knuth set off on one of the greatest yak shaves of all time.
For years, he paused all work on his books to create his own
digital typesetting system.
When the dust settled in 1978, Knuth had the first version of
<span>T<sub>e</sub>X</span>
.<sup id="fnref:1"><a href="#fn:1">1</a></sup></p>

<p>It’s hard to understand how much of a revolution <span>T<sub>e</sub>X</span>
 was,
especially looking back from a time where anybody with a copy
of Word can be their own desktop publisher.
Adobe’s PDF wouldn’t exist for another decade, so Knuth
invented a device-independent format, DVI.
Scalable fonts were uncommon at the time, so Knuth created a system,
<span>METAFONT</span>
, to rasterize his characters into dots on the
page.<sup id="fnref:2"><a href="#fn:2">2</a></sup>
Perhaps most importantly, Knuth and his graduate students designed algorithms
to automatically hyphenate and justify lines of text into
beautifully-typeset paragraphs.</p>

<p>Here is where the timelines diverge.
In one, <span>T<sub>e</sub>X</span>
 was just the beginning.
Computer typography evolves rapidly as the decades go by,
building on Knuth’s prior work and
taking advantage of the million-fold increases we’ve seen in computing power.
Browsers, e-readers, and word processors deliver beautiful type
to every person who looks at a screen, with almost no effort from authors.</p>

<p>In the darker timeline… none of this happens.
<span>T<sub>e</sub>X</span>
 is still some of the best we’ve got for computer typesetting.
It’s seen some impressive improvements,<sup id="fnref:3"><a href="#fn:3">3</a></sup>
but its core hasn’t changed much in decades.
To this day,
it doesn’t lay out more than one page at a time because 1980s computers didn’t
have enough RAM to do any better.<sup id="fnref:4"><a href="#fn:4">4</a></sup>
Almost no other software—except for a handful of professional layout
programs like Adobe InDesign—leverages any of the advances
<span>T<sub>e</sub>X</span>
 made in line breaking and hyphenation.
Layout in Word, browsers, and even e-readers is a sad joke.</p>

<figure>
<img src="https://assets.bitbashing.io/images/exa.png" alt="Mobile browser layout example" height="400">
<figcaption>
State of the art text layout in today's browsers. Mind the gaps.
</figcaption>
</figure>

<p>I’m not sure what to make of this.
Maybe most people, outside a small cadre of designers and
enthusiasts, just don’t care about typography very much.
After all, the human brain is incredibly good glossing over minor details and
im<span>p</span>erfections when reading.
But even the design world seems largely unaware or indifferent to Knuth’s work.
Despite collaborations with famous type designers like Hermann Zapf,
you’ll find no mention of him in renowned books and documentaries on
the subject.<sup id="fnref:5"><a href="#fn:5">5</a></sup>
And parametric font families—just like the ones <span>METAFONT</span>
 offered in 1983—are
heralded in 2017 as “a new era of type design”.<sup id="fnref:6"><a href="#fn:6">6</a></sup>
It’s bizarre.</p>

<p>Good typography can make almost anything more enjoyable to read,
and it feels like such a shame that better layout isn’t
available to the masses
when so much of the groundwork was laid almost forty years ago.
In an age when the average American reads from a screen they keep in their pocket
dozens of times a day,
and where each one of those devices holds more processing power than you could
fit in several rooms back when Donald Knuth
wrote <span>T<sub>e</sub>X</span>
, surely we can—and <em>should</em>—do better.</p>

<hr>



  </article></div>]]>
            </description>
            <link>https://bitbashing.io/tex.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25329049</guid>
            <pubDate>Mon, 07 Dec 2020 03:23:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Three Cheers for Solutionism?]]>
            </title>
            <description>
<![CDATA[
Score 41 | Comments 27 (<a href="https://news.ycombinator.com/item?id=25328149">thread link</a>) | @panic
<br/>
December 6, 2020 | https://aelkus.github.io/theory/2020/12/03/solu.html | <a href="https://web.archive.org/web/*/https://aelkus.github.io/theory/2020/12/03/solu.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody"><p>Economist Noah Smith <a href="https://noahpinion.substack.com/p/climate-change-isnt-that-hard">is fed up with</a> generic critiques of technological “solutionism,” specifically what he calls the “2010s consensus that technology is a sideshow compared to social movements.”</p>

<blockquote>
  <p>In the last decade, we’ve basically been taught to deride “solutionism” — while Silicon Valley techbros were bending their genius toward figuring out ways to sell more ads or lower taxi drivers’ wages, inequality was running rampant and parents were struggling to feed their kids. Instead of trusting wizardry to solve the world’s problems, we were supposed to place our faith in politics, in mass action, and in cultural change.</p>

  <p>Except then consider what happened with COVID. Our leaders failed to fight the virus effectively, and the President actively sabotaged containment efforts. Culturally, we screeched our heads off about masks and herd immunity and “just the flu” and beach parties and school closings and bar closings and restaurant closings and dorm closings and so on and so forth. We didn’t implement strict lockdowns and we protested against lockdowns and we didn’t even obey the half-assed lockdowns we did implement. We became one of the planet’s worst-hit countries, despite having the planet’s most expensive health care system. We died in the red states, we died in the blue states. We died in droves, in hundreds of thousands. Collectively, as a society, we wrung our hands and ran in circles and screeched and died and screeched and died and screeched and died until scientists made vaccines against the virus.</p>
</blockquote>

<p>Is this correct? In some ways, Smith stacks the deck in his favor. Scientific breakthroughs on vaccines can be produced by small groups of experts insulated from public pressure and the clown show of 21st century American politics. This was never the case with non-pharmaceutical interventions, even if I share Smith’s sense out of outrage and horror over America’s failed response to COVID.</p>

<p>Comparing them is a little akin to comparing World War II’s military-technical research achievements to the great campaigns of Europe and the Pacific War. The latter required extensive political and organizational coordination on a hitherto unprecedented scale, and buy-in from millions of ordinary people. The former were not exactly a bunch of eggheads in a seminar room, but they represent at least crudely processes that are largely autonomous from the need to attain large-scale consensus and cooperation.</p>

<p>Come next year, when we enter into the challenge of rolling out vaccines while preserving basic social distancing measures, we will get a reminder of how different these two kinds of activities are. I’m more optimistic that next year will be significantly better than 2020 was, but only guardedly. However, Smith is also on to something larger when he notes the dubious framing of how the answer to engineering our way to nirvana is supposed to be large-scale political and cultural change driven by mass popular mobilization.</p>

<p>‘Political solution’ in this framing seems to be a euphemism for either a deliberative process that harmonizes competing views or (more often) the imposition of one’s will on the body politic via political struggle. Neither look particularly promising in a polarized society in which merely putting on a piece of cloth held together with string has become a <a href="https://www.pewresearch.org/politics/2020/06/25/republicans-democrats-move-even-further-apart-in-coronavirus-concerns/">partisan issue</a>. Moreover, Smith <a href="https://www.bloomberg.com/opinion/articles/2019-10-17/california-is-back-on-the-brink-of-being-a-failed-state">observes elsewhere</a> that even in my home state of California – where GOP opposition has been virtually eradicated – single-party dominance has failed to resolve basic governance issues.</p>

<p>Certainly most thoughtful critics of techno-determinism likely will say that they aren’t categorically against the use of technology, but rather criticize a particular mindset that uncritically postulates that objective solutions can be discovered to objectively framed problems and then objectively implemented and accepted by a mostly cooperative public. However, it is hard to tell if they are talking about the technologists or themselves when they make this criticism. Statements like “if only we had the political will” to do something of interest are just as naive as “if only we had the right app.”</p>

<p>Technologists are often criticized for wanting to ‘route around’ the US political system, but <a href="https://www.pewresearch.org/fact-tank/2019/07/22/key-findings-about-americans-declining-trust-in-government-and-each-other/">given</a> low institutional trust and increasingly low interpersonal trust, it is difficult to be entirely critical of that desire. The biggest problem with it is that it often devolves into fantasies of taking one’s toys and exiting into an autonomous space free of the need to gain mass consensus (seasteading!) or instituting impersonal mechanisms that suppress political resistance (make the AI president!) There are idiots. Look around. But we’re all idiots in some shape or form and we’re stuck with each other. What do we do next?</p>

<p>First, somewhat of a meta-point: indirection often is a very underrated way of creating change. Part of what this post is looking to encourage is something I sometimes refer to as the “Andrew Marshall style” of change. For decades, Marshall headed up the Office of Net Assessment (ONA) within the United States Department of Defense. Most people interested in defense and strategy, including yours truly, have in some way directly or indirectly benefited from ONA and its projects. But Marshall did so largely below the radar.</p>

<p>Demanding only autonomy, a tiny (by Pentagon standards) budget, a small office, and the freedom to report directly to the Secretary of Defense, Marshall at first glance took a rather counter-intuitive approach. But this was actually critical to his success. He was not a threat to other people’s bureaucratic rice bowls. But he preserved his own autonomy. And by slowly building up a network of relationships and becoming a hub for innovative work, ONA ended up exercising a profound influence on American national security and defense.</p>

<p>What is remarkable about Marshall’s success is that he propagated his particular institutional relationships forward through decades of changing political, economic, and bureaucratic turmoil while slowly altering the surrounding environment around him. It would be ridiculous to assert that Marshall is singularly responsible for any particular major shift in American national security and defense, but it is also very evident that ONA’s presence and persistence changed the boundary conditions of the US defense and security system.</p>

<p>While many technologists often valorize another Cold War American defense icon – John Boyd – Marshall is also a model worth emulating. Technology is complicated, frustrating, and more often than not disappointing relative to our ambitions. But it can change the boundary conditions of problems. Tweaking the boundary conditions of problems is a big part of how meaningful change can happen overall.</p>

<p>Getting 2-3 promising vaccines in under a year is a great example. Vaccines do not change the massive amount of political and institutional failures America has experienced since the COVID-19 outbreak began. However, consider the alternative world without vaccines that we were in only a short time ago. We had all of those problems but without any kind of roadmap as to how we might escape them. Now we have a <a href="https://www.forbes.com/sites/carlieporterfield/2020/11/15/heres-when-experts-say-things-could-get-back-to-back-to-normal-after-coronavirus/?sh=3f66c9d936ed">hazy but nonetheless meaningful</a> idea of how long it could take to get back to normal, even if there is no really coherent shared idea of ‘normality.’ This is worth celebrating!</p>

<p>Even without a vaccine, we would be much worse off than we are now if everything from the physical network backbone to distributed work solutions did not perform well under significant stress. The Internet, also created originally in part for the purpose of scientific collaboration, enabled scientific researchers around the world to work together at breakneck speed to learn as much as possible about a novel virus and figure out how to attack it. Outside of the US and most <a href="https://www.atlanticcouncil.org/blogs/new-atlanticist/lessons-from-taiwans-experience-with-covid-19/">successfully in Taiwan</a>, governments have also found success in working together with the private sector to manage information flows during the pandemic.</p>

<p>Beyond COVID, what might this mean? Even in the best of times, the <a href="https://texaspolitics.utexas.edu/archive/html/bur/features/0303_02/muddling.html">most</a> we can often accomplish on the most intractable social problems is to <a href="https://texaspolitics.utexas.edu/archive/html/bur/features/0303_02/muddling.html">muddle through</a>. They have <a href="https://link.springer.com/article/10.1007/BF01405730">no inherent point</a> at which they officially stop being problems, and often no inherently correct shared framing. It doesn’t mean that action is pointless, but true students of politics often understand that politics is a secular activity instead of a means of bringing about religious salvation.</p>

<p>It seems unwise to stake our hopes on some kind of decisive reckoning at which political solutions will somehow materialize and then be imposed on our friends, neighbors, and co-workers. Much for the same reason that many of us find that we cannot get even members of our own family to take sensible COVID precautions no matter how much we plead, cajole, and threaten them. Still, we have also seen what happens when we simply stand still and do nothing.</p>

<p>“Techno-scientific” changes in the surrounding environment can do a number of salient things. They can provide tools we did not have before to mitigate problems. They can subtly influence or even shift the dynamics of particular interpersonal and institutional relationships and interactions. New frontiers to explore can distract people that otherwise would make trouble, and a bigger pie can make people feel more generous than they otherwise would be. While much has been made of the costs of technological disruption, breaking up established social hierarchies can be necessary for the system as a whole to survive and grow.</p>

<p>Preventing stasis and injecting more slack into the system are both means to the same end: propagating the system forward into the future. So technological “solutionism” (a term I have always disliked due to its imprecision), is both more and less important than ever. It certainly falls short of the hopes of its biggest boosters and the fears of its opponents. But if you are a technologist looking to make a difference now is as good of a …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://aelkus.github.io/theory/2020/12/03/solu.html">https://aelkus.github.io/theory/2020/12/03/solu.html</a></em></p>]]>
            </description>
            <link>https://aelkus.github.io/theory/2020/12/03/solu.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25328149</guid>
            <pubDate>Mon, 07 Dec 2020 00:40:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[My Procedurally Generated Music Is Awful]]>
            </title>
            <description>
<![CDATA[
Score 82 | Comments 88 (<a href="https://news.ycombinator.com/item?id=25327533">thread link</a>) | @mproud
<br/>
December 6, 2020 | https://devlog.groovelet.com/p/procedurally-generated-music-is-awful | <a href="https://web.archive.org/web/*/https://devlog.groovelet.com/p/procedurally-generated-music-is-awful">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><blockquote><p>"I don't think that this could ever create something that I wouldn't mute" </p><p><em>- Voxel, laying down the hard truths about music generation in general and my music generator in specific</em></p></blockquote><p>In groovelet32.exe, I’d like for the art assets to be capable of wiggling and booping in time with the music. </p><p>That’s seemingly simple sounding, but that simple idea contains, uh, <em>multitudes</em>.</p><p>This can be accomplished in one of a few different ways: </p><ol><li><p>Buy, commission, or write music, transcribe the music whole into the execution environment and play the music with locally available music generation tools (Tone.js in JavaScript, Helm or wwise in Unity) </p></li><li><p>Buy, commission, or write music, transcribe important moments in written music into software language, have instrument hits trigger effects.</p></li><li><p>Buy, commission, or write music, use automated analysis (Koreographer in Unity) to guess when dynamics are occcuring in the music and use those to trigger effects.</p></li><li><p>Buy, commission, or write music, output music as midi, play music while using midi engine to drive effects. </p></li><li><p>Generate music entirely in place, have instrument hits directly trigger effects.</p></li></ol><p>Each strategy has its ups and downs. Notably, the first four strategies start with the simple-sounding but imposing “buy, commission, or write music”. Buying music - well, it’s hard to build a whole game around stock music - especially if music is as fundamental to the experience as it should be in a game about musical robots. </p><p>Commissioning music is simply too expensive, if I’m planning on paying my composer fairly (which I would be, if I had any money).</p><p>Writing music on my own would imply a strong upgrade in my own personal music production skills, because currently I’m operating at somewhere near the “Three Blind Mice” level. A number of my family members are talented musically - my younger brother married into a “music teacher” family - but I don’t think any of them have ever cracked open a <a href="https://en.wikipedia.org/wiki/Digital_audio_workstation">DAW</a>, and they’re pretty busy with their own lives, so that’s a hard tree to shake and expect that video-game ready tunes will fall out.</p><p>So that leaves me with <strong>procedurally generated music</strong>. It’s perhaps naive to think that I, a person who can’t even write a regular song, could build a computer that could write music for me, but hey - if I’m good at anything¹ , it’s programming.</p><h2>A Basic Architecture for Procgen Music</h2><p>Some time back, I watched this inspiring JSConf talk: </p><p id="youtube2-_0ij8vY2gzE" data-attrs="{&quot;videoId&quot;:&quot;_0ij8vY2gzE&quot;,&quot;startTime&quot;:null,&quot;endTime&quot;:null}"><iframe src="https://www.youtube-nocookie.com/embed/_0ij8vY2gzE?rel=0&amp;autoplay=0&amp;showinfo=0" frameborder="0" gesture="media" allow="autoplay; fullscreen" allowautoplay="true" allowfullscreen="true"></iframe></p><p><em>so cool</em></p><p><strong>tl;dr</strong> “we built a tool called <a href="https://magenta.tensorflow.org/js-announce">Magenta.js</a> that allows you to tensorflow up some tunes”</p><p>I like tensorflow! I like tunes!</p><p>Setting upon the task with some zeal I managed to get Magenta.js generating tunes, slowly. I had a simple plan for how I would take slowly-generated 8-second tunes and convert them into longer songs:</p><ol><li><p>Have a background server process generate 8-second three-part-tune clips</p></li><li><p>Use some basic heuristics to guess at the key signature (“C# major”) of the clips, evaluate their intensity (lots of drum hits? loads of notes?) and save them in a huge clip database.</p></li><li><p>Create a search interface for the clip database.</p></li><li><p>Have the client request clips from the server in a specific key and intensity.</p></li><li><p>Weave two or three clips together, repeating them a couple of times, to make a full “song”.</p></li><li><p>Add tools to control the requested key signature, intensity, and change instrument, tempo, and what-have-you at the last second.</p></li><li><p>Take the output and make it sound like real human music that people would listen to on purpose.</p></li></ol><p>Now, there are some definite problems with this scheme. One of them is <a href="https://tonejs.github.io/">Tone.js</a> - an unbelievably powerful synth workbench written for people who have read<a href="http://msp.ucsd.edu/techniques/latest/book-html/"> the entire book on Digital Signal Processing</a>, and <em>no other people</em>.</p><p>I actually took and passed a senior-level course in DSP for music generation, some 12 years ago. I have less of an excuse than the average person to be absolutely garbage at attaching oscillators to things. I’m still garbage, mind you, I just have less of an excuse.</p><p>Anyways, after some serious effort, I got steps 1-6 working.</p><div><figure><a target="_blank" href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fca1c57c1-7653-4b87-af3b-44ec32498063_624x749.png"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fca1c57c1-7653-4b87-af3b-44ec32498063_624x749.png" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/ca1c57c1-7653-4b87-af3b-44ec32498063_624x749.png&quot;,&quot;height&quot;:749,&quot;width&quot;:624,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:41766,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null}" alt=""></a></figure></div><p>Look at that! Sliders! Tempo! Intensity! Configurable per-channel instruments and levels! </p><div><p>Here’s the first song that ever sounded remotely passable, produced by the system.</p><p>It’s… <em>okay</em>, right? Not <em>bad</em>. That’s where the system was a year ago.</p></div><p>Here’s another song from just a few days ago: </p><div><p>Admittedly, I haven’t been working on the procgen engine for that entire year, but it hasn’t evolved much in the interim, huh?</p><p>I figured I might be able to shape the musicality of the output with simple heuristic rules and adjustments and embellishments, but - I can’t. An extremely talented musician/producer might be able to, but as we’ve established, I’m worse at finding C than <a href="https://www.youtube.com/watch?v=VCr91EwGGxk">the salty pirates of landlocked Saskatchewan</a>. </p></div><p>Most of my clever changes would make the output sound better… some of the time. And worse, some of the time. Sometimes, rarely, the system produces something that, if you weren’t paying a terrible lot of attention, you might confuse for real music. A lot of the time it produces something bland and amusical. About as often it produces something <em>actively unpleasant</em>.</p><p>One idea I’ve had is building an underlying voting system to try to clear “bad” tunes out of the system - if my music generation system is actually powered by a thousand clips that sound pretty good under most any circumstances because all of the ones that sound bad have been downvoted out of existence, well, that’s one way of doing things.</p><p>But even at it’s best, the output isn’t… terribly good. </p><div><figure><a target="_blank" href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Faa2c453a-e28c-4d54-8a6f-02ea23b50ff9_534x577.webp"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Faa2c453a-e28c-4d54-8a6f-02ea23b50ff9_534x577.webp" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/aa2c453a-e28c-4d54-8a6f-02ea23b50ff9_534x577.webp&quot;,&quot;height&quot;:577,&quot;width&quot;:534,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:138006,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/webp&quot;,&quot;href&quot;:null}" alt=""></a></figure></div><div><p>And a big part of the problem is just that composing music is <em>hard</em>. If you take the simplest musical style that you can think of, there’s someone online explaining in painful detail that the soundtrack to Fart Chalice IV <em>actually</em> takes advantage of phrygian pentameter and post-modern phrasing to create artificial dissonance between the fourth and sixteenth notes in an alternating jazz-inspired progression.</p><p>I can just <em>barely</em> read music. I can’t deal with that! </p></div><p>There isn’t a simple set of rules for what will sound good when music is involved - people are too different from one another. There are dozens of conflicting sets of rules, and because there are so many ways to break those rules and still have music come out sounding good (or follow the rules and still have music come out sounding bad) a lot of music theory isn’t so much “helpful guidelines” as it is “endless taxonomy”, and most of that taxonomy has been compiled over the last 500 years by mostly Germans and Italians.</p><div><figure><a target="_blank" href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F3797b22b-8653-4a82-8325-0fd59ade6bf0_960x960.jpeg"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F3797b22b-8653-4a82-8325-0fd59ade6bf0_960x960.jpeg" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/3797b22b-8653-4a82-8325-0fd59ade6bf0_960x960.jpeg&quot;,&quot;height&quot;:960,&quot;width&quot;:960,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:125325,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/jpeg&quot;,&quot;href&quot;:null}" alt=""></a></figure></div><p><em>I am literally more afraid of music theory than digital signal processing.</em></p><h2>The Many Flaws of Procedural Generation</h2><div><figure><a target="_blank" href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F1401d2c0-9c56-43ff-acbd-d29f26cc11c0_331x500.jpeg"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F1401d2c0-9c56-43ff-acbd-d29f26cc11c0_331x500.jpeg" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/1401d2c0-9c56-43ff-acbd-d29f26cc11c0_331x500.jpeg&quot;,&quot;height&quot;:500,&quot;width&quot;:331,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:41426,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/jpeg&quot;,&quot;href&quot;:null}" alt=""></a></figure></div><p>I love this book. I’ve read it cover-to-cover, more than once. Even the chapter on music generation - the author cleverly chose a scheme where they fudged it by picking a pentatonic scale where everything sounds pretty nice together and then bonking around pretty-much randomly. (A lot of procedurally generated/input driven music uses a technique like this).</p><p>It’s packed with cool ideas involving graphs and rules engines and a bunch of stuff that gets me actively excited. One of the contributing authors uses the term “gestalt” a few too many times.</p><p>A big part of the book was just talking about <strong>when</strong> to use procedural generation.</p><p>I’d summarize the book’s answer as “if you’re reading this, less than you imagine”.    </p><div><figure><a target="_blank" href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fbc8ac403-70e9-4356-bbc5-b01b4dd1d353_910x529.webp"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fbc8ac403-70e9-4356-bbc5-b01b4dd1d353_910x529.webp" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/bc8ac403-70e9-4356-bbc5-b01b4dd1d353_910x529.webp&quot;,&quot;height&quot;:529,&quot;width&quot;:910,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:9114,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/webp&quot;,&quot;href&quot;:null}" alt=""></a></figure></div><p><em>this, for example, is probably too big a promise, unless they mean just the clouds</em></p><p>The benefits of generated content are obvious. Infinite content - even infinite bland content, is still <em>infinite</em>. This is why people still go to buffet restaurants - unlimited bad food is still pretty compelling. </p><p>So, some of the problems of procgen:</p><ul><li><p>If you restrict the output-space too aggressively, your procgen output will feel bland and samey. <em>When I restricted the output of my music generator using too many Music Theory rules, it could only produce like, 6 different songs, which all felt very bland and similar.</em></p></li><li><p>If you don’t restrict the output-space enough, your output will feel formless and unfair. <em>When I turned off the Music Theory rules, the amount of garbage output got out of control.</em></p></li><li><p>In order to produce procedurally generated output that’s meaningful, you must understand the problem space very well, and work hard at crafting intelligent rules.</p></li><li><p>It is orders of magnitude more work than just making good output.</p></li></ul><p>Or, to put it bluntly, “<strong>don’t try to procedurally generate something that you can’t already create, dummy</strong>”.</p><p>If I play with the generator long enough, I hit little patches of vaguely almost-listenable music, but most of the time the output is more of a formless mush:</p><p>Even worse, after listening to it for long stretches of time, I’d manage to convince myself that <strong>maybe I actually had something good on my hands</strong> - usually it would take either playing it for Voxel, who <em>knows what music is supposed to sound like</em> - or listening to some actual human-generated music on my own, to remind me that I had been listening to a droning mess of nothing for several consecutive hours and it was starting to melt my brain into a puddle.</p><h2>So, You’re Giving Up, Then?</h2><p>Yeah - maybe not permanently, but sometimes it’s important to know when to throw in the towel. This part of the project has, I think, failed, and it’s reaching the point where more effort is being met with <em>diminishing returns</em>.</p><div><p>I think I’m going to try a new plan from my list - “buy, commission, or write music, output music as midi, play music while using the midi data to silently drive effects”.</p><p>I’ll probably write some basic drum-loop first-fifteen-minutes-of-the-FruityLoops-tutorial jams to get the project off the ground, and then find someone competent to compose music if I ever feel like the project is within biting distance of actually shipping. </p></div><p>Anyways, Groovelet Music Engine, you’ve got one last chance to shine. Play yourself off! Preferably with something a little sad.</p><h2>A Goodbye From the Groovelet Music Engine</h2><p>… god dammit.</p></div></div>]]>
            </description>
            <link>https://devlog.groovelet.com/p/procedurally-generated-music-is-awful</link>
            <guid isPermaLink="false">hacker-news-small-sites-25327533</guid>
            <pubDate>Sun, 06 Dec 2020 23:06:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[New Sauerbraten 2020 Edition Released]]>
            </title>
            <description>
<![CDATA[
Score 127 | Comments 40 (<a href="https://news.ycombinator.com/item?id=25327267">thread link</a>) | @silentmars
<br/>
December 6, 2020 | http://www.sauerworld.org/new-sauerbraten-2020-edition-released/ | <a href="https://web.archive.org/web/*/http://www.sauerworld.org/new-sauerbraten-2020-edition-released/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<div>
<div role="main">
<div>
<article id="post-6949" data-id="6949">
<div>
<p>Dear all, we are happy to announce that the long-awaited <strong>Sauerbraten 2020 Edition</strong> is finally available! You can find it on the Sauerbraten homepage (<a href="http://sauerbraten.org/" target="_blank" rel="noopener noreferrer">http://sauerbraten.org/</a>)</p>
<p>The full changelog is here: <a href="http://sauerbraten.org/docs/history.html#_2020_11_29">http://sauerbraten.org/docs/history.html</a></p>
<h3>New Features!</h3>
<ul><li>Almost 200 (yes, 200) new maps!</li><li>A fully configurable HUD gameclock</li><li>Color coded health display</li><li>Teammate health bars for easy communication</li><li>Pickup icons display over players in item modes</li><li>Configurable HUD ammobar</li><li>Explosion brightness can now be changed in-game</li><li>Water quality has been improved</li></ul>
<h3>Game Improvements!</h3>
<ul><li>Update from SDL 1 to SDL 2</li><li>Hold has received an update. The flag counter now does not reset upon dropping the flag, but the time starts to increase back to 20 for every second it is not picked up. The enemy team picking up the flag still resets the counter for your team.</li><li>An improved design for sound radius</li><li>A new, more intelligent spawn system</li><li>The Health Boost mechanic has been redesigned – it lasts only until death and provides +100 health up to 150 for the first pickup, and up to 200 for any subsequent pickups before dying</li></ul>
<h3>Editing Stuff!</h3>
<ul><li>Atmospheric effects</li><li>Multiplayer undo in coop-edit</li><li>vcommands now work without sendmap</li><li>More user friendly editing menus</li><li>Mapmodel menu now previews the mapmodels and their animations</li><li>Texture menu now previews the texture path</li><li>Hundreds of new assets!</li></ul>
<h3>Server and Demos</h3>
<ul><li>Demos can now be named when saving</li><li><code>/seekdemo</code> allows you to fast forward, like <code>/demotime</code> in Community Edition</li><li>Default server has settings for overtime and persistent teams</li><li>Blue armour in Regen Capture can (and should) now be disabled as a server setting</li></ul>
<p>And much, much more!</p>
<p>Happy fragging!</p>

 
</div>
</article>


</div>
</div>
</div>

</div></div>]]>
            </description>
            <link>http://www.sauerworld.org/new-sauerbraten-2020-edition-released/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25327267</guid>
            <pubDate>Sun, 06 Dec 2020 22:31:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Golang First Impressions]]>
            </title>
            <description>
<![CDATA[
Score 9 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25327099">thread link</a>) | @leemason
<br/>
December 6, 2020 | https://leemason.co.uk/golang-first-impressions/ | <a href="https://web.archive.org/web/*/https://leemason.co.uk/golang-first-impressions/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><img width="1062" height="938" src="https://leemason.co.uk/wp-content/uploads/2020/12/Go-Logo_Aqua.jpg" alt="Golang Logo" loading="lazy" srcset="https://leemason.co.uk/wp-content/uploads/2020/12/Go-Logo_Aqua.jpg 1062w, https://leemason.co.uk/wp-content/uploads/2020/12/Go-Logo_Aqua-300x265.jpg 300w, https://leemason.co.uk/wp-content/uploads/2020/12/Go-Logo_Aqua-1024x904.jpg 1024w, https://leemason.co.uk/wp-content/uploads/2020/12/Go-Logo_Aqua-768x678.jpg 768w" sizes="(max-width: 1062px) 100vw, 1062px"></p><p>Ive recently had the perfect use case to try my hand at Golang (more on the particular project later).</p><p>It’s been a long time coming. Its no secret you will find many articles on the web proclaiming how good Golang is, and its always been something I wanted to try out.</p><p>Until now I haven’t really had a use case and I feel its always much better to have a “need” to use something to really evaluate it, or your stuck just running through hello world’s and tutorials where your doing little more than copy/pasting working code.</p><p>The project in question is almost ready for a big reveal, but for the purposes of this article lets just say I needed a binary I could distribute without the surrounding architecture needing a runtime to run the application.</p><p>So that ruled out my two go to languages, PHP and NodeJs/Javascript. And lead me down the Golang or Rust path.</p><p>I will concede I actually attempted to use Rust first. There seems to be even more hype around Rust at present and watching all the conferences around Rust and WebAssembly that are popping up on YouTube I took a stab. As this is a Golang article I won’t delve too deep into Rust, lets just say after half a day I quickly realised if I wanted to get a proof of concept out quickly for this new project Rust was not the language I should be learning on the job for. This is by far not a knock at Rust. It looks really promising, it is probably just a little too far out of my comfort level right now.</p><p>So having wasted a half a day I picked up the Golang handbook and started a project.</p><p>I had run all the samples you can find in the <a href="https://golang.org/doc/tutorial/getting-started">documentation</a> and the <a href="https://tour.golang.org/welcome/1">tour guide</a> multiple times in the past so the core concepts like operators, values, structs etc I had an understanding of already. Packages on the other hand caused me some confusion early on which I’ll delve into further down this article.</p><h2>The Proof Of Concept</h2><p>Building the POC I dumped all my code in the <code>main</code> package. At this point the code was pretty ropey. But it did confirm for me the approach was going to work. I felt pretty at home with writing at least basic code, the syntax is very similar to PHP and javascript. Well to be more specific strongly typed PHP8.0 and Typescript.</p><p>I was getting on quite well with the language and now wanted to refactor the work into something I would be happy to commit to version control.</p><h2>Folder Structure</h2><p>This still irks me a little, it’s almost hard coded into my brain. Code goes into a <code>src</code> folder and is organised by logical groupings. At least this is how I work and is the accepted structure for the languages I use day to day.</p><p>Golang on the other hand has a different recommended structure. Its not a requirement but is recommended so I went with it. Full details can be found here: <a href="https://github.com/golang-standards/project-layout">https://github.com/golang-standards/project-layout</a></p><p>Im sure there must be a reason that’s inherent in the language or devised by some people smarter than me that makes this a better structure, but at this point I just don’t like it. It may become clearer the more I use Golang but I just feel the separation detaches the domain relationships and functionality. I don’t see why private code should be in a wholly different location when Golang has public exports inherent in the language.</p><h2>Modules</h2><p>This is where I hit my first real hurdle, maybe I didn’t read the docs well enough, or maybe it was just me. But I had a good few hours of frustration with my IDE (Intellij IDEA) shouting at me because it couldn’t find my code. At least part of the problem was my choice to just dump everything in <code>main.go</code>, then migrating to a directory type project, and finally landing on a module structure. I also think I may of been led down a few garden paths reading up on outdated articles.</p><p>I managed to figure it out eventually and it is pretty obvious with hindsight. I haven’t yet been in a position to write a module that’s meant to be consumed externally so i’m cautious of being too critical here. But from my relatively short experience I don’t understand why you can’t use relative imports in internal code?</p><p>The fact only its name is known by a package, but it needs to explicitly define the whole module path to pickup other packages feels a little off to me:</p><div><pre data-setting="{&quot;mode&quot;:&quot;go&quot;,&quot;mime&quot;:&quot;text/x-go&quot;,&quot;theme&quot;:&quot;material&quot;,&quot;lineNumbers&quot;:false,&quot;styleActiveLine&quot;:false,&quot;lineWrapping&quot;:false,&quot;readOnly&quot;:true,&quot;showPanel&quot;:false,&quot;language&quot;:&quot;Go&quot;,&quot;modeName&quot;:&quot;go&quot;}">package foobar
  
import (
	"github.com/xxx/xxx/internal/bazzer" // why not just "../bazzer"?
)</pre></div><h2>Dependency Loops</h2><p>Im not sure how common this is, but I had a real hard time when refactoring due to cyclic dependencies on structs. Again mainly my fault and bad design in my proof of concept. If I had started with modules up front I don’t think I would of had this issue. But the good thing that came of this is my understanding of Golang interfaces.</p><p>What I really like about them is their implicit rather than explicit nature (duck typing). When I found out about this it all became clear what I needed to do to resolve my problems.</p><h2>err != nil</h2><p>I don’t think a Golang article is complete without the mention of <code>err != nil</code>. Even before I started I knew about this. I have seen various articles propose how to write better code to prevent the repetition. Something I did pickup along the way was the use of <code>defer</code> which is a pretty neat feature allowing you to something similar to <code>try{}finally</code>. But I would be lying if I didn’t say I would be immensely grateful to see <code>try{}catch</code> make an appearance in Golang.</p><h2>Releasing</h2><p>Building the project was always super simple. I then needed to figure out how I could distribute this for different architecture. By the time I got here I was feeling pretty confident with what I had achieved, my confidence lead me to starting to reinventing a process already handled exceptionally by the <a href="https://goreleaser.com/">Goreleaser</a> and <a href="https://github.com/goreleaser/godownloader">Godownloader</a> projects. These two projects make it super simple to provide access to built copies of your app.</p><p>Which made it very surprising Godownloader seems to be struggling: <a href="https://github.com/goreleaser/godownloader/issues/161">https://github.com/goreleaser/godownloader/issues/161</a></p><p>To me these two packages feel like the composer and npm of the PHP and Javascript world i’m used to.</p><p>They appear to be a critical part of the ecosystem and certainly helped me get to a usable system very quickly.</p><p>In short a simple generated yml file and some CI scripts and I had automated releases available to the project without much customisation required.</p><h2>Conclusion</h2><p>There are definitely some things i’m not used to or fully understand. But i’m still very interested and very happy with what i’ve able to achieve pretty quickly. It has a familiar syntax which no doubt helps and I can’t believe i’ve got to the conclusion without mentioning its SUPER fast. I’ll be talking more about the specific project this was about when its ready for launch. The source code will be open source, so please don’t judge it too harshly. It will be my first Golang project, hopefully one of many.</p><h4>Want to know when I have new content? Enter your email address to be notified when it’s available.</h4></div></div>]]>
            </description>
            <link>https://leemason.co.uk/golang-first-impressions/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25327099</guid>
            <pubDate>Sun, 06 Dec 2020 22:10:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Ad-tech as a bubble overdue for a bursting]]>
            </title>
            <description>
<![CDATA[
Score 20 | Comments 7 (<a href="https://news.ycombinator.com/item?id=25325974">thread link</a>) | @samizdis
<br/>
December 6, 2020 | https://pluralistic.net/2020/12/06/surveillance-tulip-bulbs/#adtech-bubble | <a href="https://web.archive.org/web/*/https://pluralistic.net/2020/12/06/surveillance-tulip-bulbs/#adtech-bubble">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-1669">
	<!-- .entry-header -->

	
	
	<div>
		<p><!--
Tags:
shock doctrine, labor, ad-tech, freakonomics, podcasts, spoken word, bubbles, surveillance capitalism, india, labor, modi, neoliberalism, sovkitsch, paleocomputing, urbex,

Summary:
Ad-tech as a bubble overdue for a bursting; The largest strike in human history; Soviet computing graveyard

URL:
https://pluralistic.net/2020/12/06/surveillance-tulip-bulbs/

Title:
Pluralistic: 06 Dec 2020 surveillance-tulip-bulbs

Bullet:
🧦

Separator:
_,.-'~'-.,__,.-'~'-.,__,.-'~'-.,__,.-'~'-.,__,.-'~'-.,_

Top Sources:
Today's top sources: Naked Capitalism (https://www.nakedcapitalism.com/), Slashdot (https://slashdot.org/).

--><br>
<a href="https://pluralistic.net/2020/12/06/surveillance-tulip-bulbs/"><img src="https://i2.wp.com/craphound.com/images/06Dec2020.jpg?w=840&amp;ssl=1" data-recalc-dims="1" data-lazy-src="https://i2.wp.com/craphound.com/images/06Dec2020.jpg?w=840&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></a></p>

<ul>
<li attrs="{'class': ['xToC']}"><a attrs="{'href': '#xslug'}" href="https://pluralistic.net/2020/12/06/surveillance-tulip-bulbs/#adtech-bubble">Ad-tech as a bubble overdue for a bursting</a>: Upton Sinclair was an optimist.
</li>
<li attrs="{'class': ['xToC']}"><a attrs="{'href': '#xslug'}" href="https://pluralistic.net/2020/12/06/surveillance-tulip-bulbs/#modi-miscalulation">The largest strike in human history</a>: The Shock Doctrine's breaking-point.
</li>
<li attrs="{'class': ['xToC']}"><a attrs="{'href': '#xslug'}" href="https://pluralistic.net/2020/12/06/surveillance-tulip-bulbs/#paleocomputing-sovkitsch">Soviet computing graveyard</a>: Recovering a Saratov-2 from presumed extinction.
</li>
<li attrs="{'class': ['xToC']}"><a attrs="{'href': '#xslug'}" href="https://pluralistic.net/2020/12/06/surveillance-tulip-bulbs/#retro">This day in history</a>: 2015, 2019
</li>
<li attrs="{'class': ['xToC']}"><a attrs="{'href': '#xslug'}" href="https://pluralistic.net/2020/12/06/surveillance-tulip-bulbs/#bragsheet">Colophon</a>: Recent publications, upcoming appearances, current writing projects, current reading
</li>
</ul>

<hr>
<p><a name="adtech-bubble"></a><br>
<img src="https://i0.wp.com/craphound.com/images/9780374538651_FC.jpg?w=840&amp;ssl=1" data-recalc-dims="1" data-lazy-src="https://i0.wp.com/craphound.com/images/9780374538651_FC.jpg?w=840&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></p>

<p>In my book "How to Destroy Surveillance Capitalism" I point out that the claims for Big Tech powers of behavior modification powers emanate from the companies' own self-serving boasts pitched to bring in new ad-tech customers.</p>
<p><a href="https://onezero.medium.com/how-to-destroy-surveillance-capitalism-8135e6744d59">https://onezero.medium.com/how-to-destroy-surveillance-capitalism-8135e6744d59</a></p>
<p>I point to the thinness of the external research on ad-tech's efficacy, and the replication failures of its research foundations on things like "sentiment analysis," "microexpressions" and "Big 5 Personalities" – the whole panoply of digital phrenology.</p>
<p>Meanwhile, there are undeniable, easily measured means by which Big Tech modifies our behavior that don't require us to treat marketing puffery as ground truth.</p>
<ul>
<li>If you want to talk to your friends you have to use Facebook because Mark Zuckerberg is holding them hostage with monopoly tactics
</li>
<li>
<p>Google uses monopoly rents to buy its way to search default on every platform, so the answer to every question you ask comes from Google</p>
</li>
<li>
<p>Apple gets to decide which apps you're allowed to use, who can fix your devices, and when you have to throw them away and buy new ones, thanks to DRM and lavish spending to kill dozens of Right to Repair initiatives</p>
</li>
</ul>
<p>These are mass-scale, persistent behavior modifications that have nothing to do with psychological manipulation and everything to do with economic chicanery.</p>
<p>This week on the Freakonomics podcast, Stephen Dubner turns an economic lens on Big Tech's ad-tech boasts.</p>
<p>He talks to Steve Tadelis, an academic economist who once headed a program at Ebay to evaluate the efficacy of ad spending. First they tried eliminating "brand" advertising (that is, advertising buys for the word "ebay") and found that there was no drop in their revenues.</p>
<p>The logic behind Ebay buying ads for "ebay" is that if they don't, their competitors will, so a search for "ebay" will bring up links to Amazon. That happened…and people scrolled right past the Amazon ads to the "organic" Ebay link below the ads.</p>
<p>But Ebay also buys a bunch of keyword ads for products, like "guitar" or "washing machine" or "picture frame." They estimated 5% of their revenue came from these ads, and that every $1 they spent on them brought in $1.50.</p>
<p>Tadelis designed another experiment and found that these ads were actually responsible for 0.5% of their revenue – an order of magnitude less than their estimate – and that every $1 they spent generated $0.60 in <em>losses</em>. They cut $100m from their ad-spending.</p>
<p>But despite publication of these findings, the world increased its ad-tech spending. Tadelis attributes this to the fact that the major players in ad-tech are all incentivized to repeat the unsubstantiated tale of ad-tech's efficacy.</p>
<p>Ad-tech companies, publishers, and ad-tech buying consultancies are all compromised and unable to objectively assess whether ads work (cue Upton Sinclair: "It's difficult to get a man to understand something when his salary depends on his not understanding it").</p>
<p>And, of course, now Big Tech's critics have joined the ranks of those who insist that ad-tech works with spooky, devastating efficacy.</p>
<p>For evidence, all of them point to how much money the industry generates.</p>
<p>Why would people buy these products if they didn't work? Well, the obvious answer is, "That happens all the time." See:</p>
<ul>
<li>Multivitamins
</li>
<li>
<p>Hedge funds</p>
</li>
</ul>
<p>But there's another answer: "it's a bubble."</p>
<p>A recent, excellent book on the ad-tech bubble is Tim Hwang's SUBPRIME ATTENTION CRISIS:</p>
<p><a href="https://pluralistic.net/2020/10/05/florida-man/#wannamakers-ghost">https://pluralistic.net/2020/10/05/florida-man/#wannamakers-ghost</a></p>
<p>Hwang tells Dubner that in a bubble, "the red lights are flashing but everybody in the industry just refuses to take a look at the real data."</p>
<p>Bubbles thrive on opacity and complexity. Think of the 2008 financial crisis, where the lack of transparency in "toxic assets" was compounded by their complexity, which led people – including "sophisticated" regulators and investors – to trust them.</p>
<p>They assumed that the manifest absurdity of the claims made by CDO salespeople must reflect their own ignorance. After all, all those OTHER people wouldn't spend trillions on derivatives if they weren't safe enough to buy yourself and exercise regulatory forbearance over.</p>
<p>But as Hwang points out, the ad-tech market is built on garbage. By Google's own reckoning, 60% of the ads that are charged for are never seen by any human being – literally the majority of the industry's product is a figment of feverish machine imaginations.</p>
<p>While Google's own research (and that of other Big Tech players) show that ad-tech works, independent researchers find the opposite: switching from "behavioral" (surveillance) ads to "contextual" ads only reduces clickthrough by 5%.</p>
<p>Behavioral ad clickthroughs are 0.01-0.03%, and much of that is bot activity.</p>
<p>The industry is opaque and incestuous. Ad agencies – nominally working for advertisers – get massive kickbacks from ad-tech platforms for bringing them business.</p>
<p>Proctor and Gamble – the company that invented the concept of brand ads – tried taking $200m out of its online ad spend and saw <em>zero</em> change in sales.</p>
<p>And yet, ad-tech spending continues to rise.</p>
<p>Hwang says we need a "punk rock" National Bureau of Economic Research, an org that will neutrally measure ad-tech performance and slowly deflate the bubble rather than bursting it, because an ad-tech collapse would kill ad-supported media.</p>
<p>All this is kind of a microcosm for the problems of economics in general. For decades, economics was dominated by the neoclassical idea of "homo economicus," a rational utility maximizer whose bad choices were good, actually.</p>
<p>(That's still the cartoon that undergrads get)</p>
<p>Advertising – especially brand ads – is grounded in the idea that irrationality is universal and exploitable, that you can trick people into paying a 50,000% markup by slapping a logo on a t-shirt.</p>
<p>But advertisers – and the industry – assume <em>they</em> are immune to irrationality, that they don't need to worry that they themselves will be suckered by slick sales-patter from ad tech, or their agencies.</p>
<hr>
<p><a name="modi-miscalulation"></a><br>
<img src="https://i2.wp.com/craphound.com/images/indiastrikedemocracynow2020.jpg?w=840&amp;ssl=1" data-recalc-dims="1" data-lazy-src="https://i2.wp.com/craphound.com/images/indiastrikedemocracynow2020.jpg?w=840&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></p>

<p>Last week, the largest organized strike in human history shut down India. 250,000,000 people struck against Indian PM Narendra Modi's neoliberal reforms to the agricultural sector.</p>
<p><a href="https://www.democracynow.org/2020/12/3/india_protests_modi_neoliberal_reforms">https://www.democracynow.org/2020/12/3/india_protests_modi_neoliberal_reforms</a></p>
<p>These reforms don't just remove the collective bargaining and price controls that protect the ag sector (which employs more than half the Indian working population), but also stripped multinational corporations and government of liability for harms to their workers.</p>
<p>All this while unemployment is at 27%, and 76% of rural Indians lack the funds to cover their basic nutritional needs. Meanwhile Indian billionaires have increased their wealth by 35% during the pandemic. India's richest man, Mukesh Ambani, has made $12m per <em>hour</em> since March.</p>
<p>The strike didn't just turn out unemployed people and farmers: the turnout was driven by acts of solidarity from ever sector of society.</p>
<p>In his discussion with Amy Goodman on Democracy Now, P Sainath offers some really important political context.</p>
<p>Modi has had a comfortable Congressional majority for two years and has three years left to go in his mandate, so why did he wait for the pandemic to make this far-reaching power-grab?</p>
<p>Sainath: "The reasoning was, these blokes are on their knees now. They can’t organize. They can’t hit back. And in fact, many leading neoliberal intellectuals, economists and journalists, editors, incited the government, saying, 'Never waste a good crisis.'"</p>
<p>It's shock doctrine shit, in other words. But Modi badly misjudged the moment: rather than being beating beyond resistance, Indians have been beaten to the sticking point, and will no longer be fooled by religious bigotry and neoliberal fairy tales.</p>
<p>Right wing movements around the world are grounded in the idea that some people are born to rule and the rest of us are born to be ruled over. Antimajoritarian philosophy isn't compatible with democracy, because it requires sustained turkeys-voting-for-Christmas to survive.</p>
<p>As India shows, the traditional tools of antimajoritarianism – xenophobia, sectarianism, armed violence – are unstable in the long run. Eventually there comes a point when you can't just shout "Muslims are scary!" at starving people and expect them to take that for an answer.</p>
<p>Indians have been slaughtered by both covid and mismanagement. They are at the breaking point. They are rising up.</p>
<hr>
<p><a name="paleocomputing-sovkitsch"></a><br>
<img src="https://i0.wp.com/craphound.com/images/6.jpg?w=840&amp;ssl=1" data-recalc-dims="1" data-lazy-src="https://i0.wp.com/craphound.com/images/6.jpg?w=840&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></p>

<p>In the 1970s, the Soviet Union started to clone DEC's PDP workhorse minicomputers, especially the PDP-8, which was replicated in the USSR as the Saratov-2. Today, the Saratov-2 is a distant memory, with not even a single high-quality photo of the system online.</p>
<p>Until now. Russian urban explorer Ralph Mirebs's photos of a "Soviet Computing Cemetery" (location undisclosed) that features the rotting remains of a Saratov-2 amid the ashes and fire-suppresant residue of a long-ago data-center blaze.</p>
<p><a href="https://rusue.com/cemetery-of-soviet-computers/">https://rusue.com/cemetery-of-soviet-computers/</a></p>
<p>The Saratov-2 was wild: it didn't have a microprocessor; rather, it was broken down into components, each in its own drawer: a 12-bit computing unit, I/O, RAM (ferromagnetic cubes).</p>
<p>Also present in the cemetery: an Electronics 100/25 – the Soviet version of the PDP-11 – and some DVK-2Ms (early personal computers).</p>
<p>The author recalls their own computer science education in 1993, when "one teaching DVK could distribute programs for a couple of dozen Spectrums through the network."</p>
<p>One of my last trips before the crisis hit was my visit to the Computer History Museum's boneyard – a massive warehouse filled …</p></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://pluralistic.net/2020/12/06/surveillance-tulip-bulbs/#adtech-bubble">https://pluralistic.net/2020/12/06/surveillance-tulip-bulbs/#adtech-bubble</a></em></p>]]>
            </description>
            <link>https://pluralistic.net/2020/12/06/surveillance-tulip-bulbs/#adtech-bubble</link>
            <guid isPermaLink="false">hacker-news-small-sites-25325974</guid>
            <pubDate>Sun, 06 Dec 2020 19:31:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Thought Leaders and Chicken Sexers]]>
            </title>
            <description>
<![CDATA[
Score 172 | Comments 58 (<a href="https://news.ycombinator.com/item?id=25325716">thread link</a>) | @michael_fine
<br/>
December 6, 2020 | https://ideolalia.com/essays/thought-leaders-and-chicken-sexers.html | <a href="https://web.archive.org/web/*/https://ideolalia.com/essays/thought-leaders-and-chicken-sexers.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

	

	<div>
		<article>
			<p>From the moment I started paying attention to the tech industry, Paul Graham was there.  My first job out of college was in SoMa, around the corner from the Justin.tv offices, and his essays were just floating around in the ether, impossible to ignore.  His popularization of Lisp was a small part of why I tried Clojure, and a big part of why Clojure was successful.</p>

<p>I recognized that he had a tendency towards <a href="http://www.paulgraham.com/avg.html">self-aggrandizement</a> and <a href="http://www.paulgraham.com/nerds.html">awkward flattery of his readers</a>, but at worst he seemed harmless.  As his writing became increasingly focused on startups, and I became increasingly sure I didn’t want to be a founder, he simply drifted out of view.</p>

<p>Recently, however, his writing has taken a reactionary turn which is hard to ignore.  He’s <a href="http://www.paulgraham.com/mod.html">written</a> about the need to defend “moderates” from bullies on the “extreme left”, <a href="https://twitter.com/paulg/status/1334441961147822081">asserted</a> that “the truth is to the right of the median” because “the left is culturally dominant,” and <a href="https://pbs.twimg.com/media/EjGX2-bU4AAWkUX?format=jpg&amp;name=medium">justified</a> Coinbase’s policy to ban discussion of anything deemed “political” by saying that it “will push away some talent, yes, but not very talented talent.”</p>

<p>I went back to the essays I had read a decade before, to see if I had missed something.  It turned out that I had.  There was a consistent intellectual framework underpinning all his writing, from his very first essays on Lisp and language design.  In many ways, those early essays contained the clearest articulation of his framework; it just took me ten years to see it.</p>

<hr>

<p>In April 2001, six years after the release of the Java language, Paul Graham weighed in:</p>

<blockquote>
  <p><a href="http://paulgraham.com/javacover.html">I’ve never written a Java program, never more than glanced over reference books about it, but I have a hunch that it won’t be a very successful language.</a></p>
</blockquote>

<p>He followed up with a number of observations about Java, such as the fact that it was designed by committee, infantilizes its users, and owed its initial success to an ailing corporate sponsor.  But, he wrote, this wasn’t an analysis of Java so much as introspection on his own “hacker’s radar”.  This radar was the aesthetic response of an expert programmer, drawn from epiphenomena surrounding the language and the opinions of other experts in his social circle.</p>

<p>A month later, in an essay on why languages are popular, he doubled down on the importance of his personal intuition:</p>

<blockquote>
  <p><a href="http://www.paulgraham.com/popular.html">Programming languages are <em>for</em> hackers, and a programming language is good as a programming language (rather than, say, an exercise in denotational semantics or compiler design) if and only if hackers like it.</a></p>
</blockquote>

<p>The quality of a language can only be judged by experts (“a tiny minority, admittedly, but that tiny minority write all the good software”), and adoption by those experts will drive adoption by everyone else.  Ultimately, “a programming language probably becomes about as popular as it deserves to be.”</p>

<p>The context for both essays was that Graham was creating his own language, <a href="http://www.paulgraham.com/arc.html">Arc</a>.  He wanted it to be popular, and was working out how to make that happen.</p>

<p>The first intrinsic driver of popularity he named was “brevity”:</p>

<blockquote>
  <p><a href="http://www.paulgraham.com/popular.html">It would not be far from the truth to say that a hacker about to write a program decides what language to use, at least subconsciously, based on the total number of characters he’ll have to type.</a></p>
</blockquote>

<p>He called back to this when discussing the importance of libraries, which can reduce any program to a single invocation:</p>

<blockquote>
  <p><a href="http://www.paulgraham.com/popular.html">Of course the ultimate in brevity is to have the program already written for you, and merely to call it. And this brings us to what I think will be an increasingly important feature of programming languages: library functions. Perl wins because it has large libraries for manipulating strings.</a></p>
</blockquote>

<p>It appears that Graham was referring to Perl’s core library functions, not the much larger set of library functions that were even then available via <a href="https://www.cpan.org/">CPAN</a>, because he placed this responsibility wholly upon the shoulders of the language designer, saying language design would become increasingly focused on “how to design great libraries.”</p>

<p>Graham named other drivers of popularity in this essay, but he returned to brevity <a href="http://www.paulgraham.com/langdes.html">again</a> and <a href="http://www.paulgraham.com/power.html">again</a> over the next year, culminating in an essay on the singular importance of brevity, now dubbed “succinctness”:</p>

<blockquote>
  <p><a href="http://www.paulgraham.com/power.html">My hypothesis is that succinctness is power, or is close enough that except in pathological examples you can treat them as identical.</a></p>
</blockquote>

<p>Drawing from studies that found “programmers seemed to generate about the same amount of code per day regardless of the language”, he declared that “the only way to get software written faster was to use a more succinct language”.</p>

<p>Nowhere, however, did he mention libraries.  The next month, he explained that given a sufficiently succinct language, users could simply write their own libraries:</p>

<blockquote>
  <p><a href="http://www.paulgraham.com/icad.html">As for libraries, their importance also depends on the application. For less demanding problems, the availability of libraries can outweigh the intrinsic power of the language. Where is the breakeven point? Hard to say exactly, but wherever it is, it is short of anything you’d be likely to call an application. If a company considers itself to be in the software business, and they’re writing an application that will be one of their products, then it will probably involve several hackers and take at least six months to write. In a project of that size, powerful languages probably start to outweigh the convenience of pre-existing libraries.</a></p>
</blockquote>

<p>This was a significant departure from his earlier writings.  Only a year before, he had stated that “[i]t’s hard to design good libraries. It’s not simply a matter of writing a lot of code.”  He had emphasized that library design was a key part of language design, and even a year later he would tell us “[d]esign usually has to be under the control of a single person to be any good.”</p>

<p>Now he argued that the language designer only need provide a barebones language of sufficient brevity, and all else would follow.  Library design can’t be both critically important and an incidental part of someone else’s six-month software project.  Despite this, Graham never mentioned libraries ever again.</p>

<p>A year later, he explained that Arc was trying to be a “hundred-year language”.  “It may seem presumptuous,” he wrote, but “[l]anguages evolve slowly because they’re not really technologies. Languages are notation. A program is a formal description of the problem you want a computer to solve for you.”  He asserted the most important part of the language were the “fundamental operators”, because the rest of the language “could in principle be written in terms of these fundamental operators”.</p>

<p>What, then, makes a language ready for the 22nd century?  Certainly not any concerns about performance, since “[e]ven if [computers] only end up being a paltry million times faster, that should change the ground rules for programming languages substantially.”  Not data structures, since they’re just a premature optimization of the humble list.  Not a mechanism (or even notation) for parallel computation, since a simple description of the problem will “ignore any advantages to be got from parallel computation, just as they will ignore advantages to be got from specific representations of data.”</p>

<p>A hundred-year language <em>should</em>, however, be succinct.  First “write down the program you’d like to be able to write, regardless of whether there is a compiler that can translate it or hardware that can run it.”  And of course the program you’d really like to write is the shortest one possible:</p>

<blockquote>
  <p><a href="http://www.paulgraham.com/hundred.html">[T]he algorithm for language design becomes: look at a program and ask, is there any way to write this that’s shorter?</a></p>
</blockquote>

<p>“If we had the hundred-year language now,” Graham wrote, “it would at least make a great pseudocode.”  Confusingly, he asserted that since it will need to perform well on its million-times-faster future processor, “presumably it could generate code efficient enough to run acceptably well on our hardware.”</p>

<p>“When you see these ideas laid out like that,” he wrote, “it’s hard not to think, why not try writing the hundred-year language now?”</p>

<hr>

<p>Four years later, in 2008, Arc was released.  It was a <a href="https://en.wikipedia.org/wiki/Common_Lisp#The_function_namespace">Lisp-1</a> with shorter names and fewer parentheses than most other Lisps, and some reader macros to make anonymous functions easier to define.  All primitives were defined in terms of MzScheme, a different Lisp, which provided the compiler and other tooling.  It also came with a barebones web framework which used continuations, reminiscent of the Smalltalk-based <a href="https://en.wikipedia.org/wiki/Seaside_(software)">Seaside framework</a> which had been around since 2002.</p>

<p>It was, in all, underwhelming.  There were many paths that could have led Graham to his professed goals, and he took none of them.</p>

<p>He had written that strings were premature optimization, and should be replaced by lists of characters.  If he had done so, and made the characters full <a href="https://en.wikipedia.org/wiki/Code_point">Unicode code points</a>, Arc could have been one of the few languages not suffering from a half-century hangover stretching all the way back to <a href="https://en.wikipedia.org/wiki/EBCDIC">EBCDIC</a>.  Instead, the initial release used byte strings which only supported the ASCII character set.</p>

<p>Graham had asked “[h]ow many times have you heard hackers speak fondly of how in, say, APL, they could do amazing things with just a couple lines of code? I think anything that really smart people really love is worth paying attention to.”  But the undeniably succinct primitives and composition rules of array programming languages were nowhere to be found.</p>

<p>Server-based deployment of software was a <a href="http://www.paulgraham.com/road.html">central theme</a> in Graham’s essays, and his continuation-based web framework was an interesting and fairly novel way to create continuity across multiple requests in a single session.  But since each link on the page was a continuation, and each continuation was stored in-memory in a single process, this created a single, memory-hungry point of failure.  For years, <a href="https://news.ycombinator.com/news">Hacker News</a> would simply display “unknown or expired link” if you waited too long to click a link.  If Arc had its own runtime, it could have supported …</p></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://ideolalia.com/essays/thought-leaders-and-chicken-sexers.html">https://ideolalia.com/essays/thought-leaders-and-chicken-sexers.html</a></em></p>]]>
            </description>
            <link>https://ideolalia.com/essays/thought-leaders-and-chicken-sexers.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25325716</guid>
            <pubDate>Sun, 06 Dec 2020 19:04:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Docker's Second Death]]>
            </title>
            <description>
<![CDATA[
Score 287 | Comments 246 (<a href="https://news.ycombinator.com/item?id=25325056">thread link</a>) | @alexellisuk
<br/>
December 6, 2020 | https://www.tariqislam.com/posts/kubernetes-docker-dep/ | <a href="https://web.archive.org/web/*/https://www.tariqislam.com/posts/kubernetes-docker-dep/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><h3>Docker's Second Death</h3></p><h3 id="feels-like-forever">Feels Like Forever</h3><p>Perhaps not quite forever, but the history with Docker <em>feels</em> really long in good and bad ways. I had joined Red Hat in the summer of 2015, the same summer that OpenShift 3.0 went GA. This was a remarkable event because it marked a redesign of the platform onto Kubernetes which itself had just gone to v1.0 (this is the same timeframe that GKE went GA, if you can believe it’s that old). Like many, I had no clue what Kubernetes or OpenShift were, and I definitely didn’t know much about Docker. I knew <em>of</em> containers. By fall I was neck deep in all three, and in love with the ecosystem a few months after.</p><p>The next spring was my first “real” encounter with Docker Inc. I didn’t attend Red Hat Summit 2016, but I distinctly remember that being the year that Docker really made its first outward antagonistic move against Red Hat OpenShift, at Red Hat’s own event. They were giving out the following shirt:</p><p><img src="https://www.tariqislam.com/images/dockerpatch.jpg" alt="docker-shirt"></p><p>To briefly summarize, this was an attack on Red Hat’s model of backporting patches to older versions of software (also known as “enterprise support”). Red Hat at that time shipped a version of Docker that was just slightly behind the latest cut, whereas Docker shipped their latest. I won’t go into the details of why that matters because there is still a debate today about whether backporting patches is better for an organization versus staying on the latest version of a thing (the latter has gotten considerably better in recent times). This was significant because up until that time, Docker was an integral part of the OpenShift narrative. We sold one with the other and the underlying assumption by most if not all of us was that Docker was just a great tech. In retrospect, this should have been expected as Docker Inc. started making its moves into the enterprise space and suddenly stopped being just great tech.</p><h3 id="it-was-inevitable">It Was Inevitable</h3><p>The early platform wars, as I call them, were primarily focused around OpenShift, Docker, and Pivotal. Pivotal had made significant inroads into enterprise organizations early on, and for good reason: the platform experience was pretty great. Couple that with Pivotal Labs and you had some pretty good mojo. Docker was the up and comer. It was the industry darling making a splash and it had the tech that everyone wanted or that everyone was already using. Kubernetes was still a bit of a question mark. I spent a lot of my time talking to organizations about the nuts and bolts of Kubernetes and why it mattered, or more accurately: why it should matter to them. The move by Docker to knock on OpenShift forced Red Hat messaging to over-index on Kubernetes and Linux over and above anything else. It worked and the industry caught up.</p><p>Docker, still in its industry darling state, responded quickly with Docker Swarm but never really caught on. Swarm was eventually overwhelmed (pun intended) by the uptake of Kubernetes across the industry, and this was when it died the first time: it lost the platform wars and became the very first commodity in the cloud native ecosystem. The second half of 2016 is really when Kubernetes edged out Swarm. This was made evident by the keynote demo at DockerCon 2017 in the following Spring when the presenters showcased Docker’s integration with Kubernetes on the big stage. Notably, that was the last “big” DockerCon that made a splash. From there on out, it was the Kubernetes/CNCF show.</p><h3 id="docker-debt">Docker Debt</h3><p>In all this time, Docker was always an integral part of Kubernetes. This was the relationship:</p><p><img src="https://www.tariqislam.com/images/dockershim.png" alt="dockershim"></p><p>And for the last 19 releases, that chain is what has been supported in Kubernetes. All that just to spin up a pod with a container in it. Docker went from necessity to technical debt. And out of all that, the community laboured until now where Docker will be deprecated in the next release of 1.20. The community has (rightfully) carried the technical debt of Docker for years to ensure the industry had what it needed for the most seamless experience given the ubiquity of the docker daemon. Here is what’s been around for a little while, but will be officially prime time in 1.20 and beyond:</p><p><img src="https://www.tariqislam.com/images/withoutdocker.png" alt="withoutdocker"></p><p>It’s a great simplification, and a return to consistency. To help visualize why this was necessary, I encourage you to view Docker as a platform abstraction on top of containers which are just an aggregate of some Linux constructs. Part of this abstraction involved an integration between the docker platform and containerd, the latter of which lives on today as arguably the most popular container runtime. Docker was never the runtime. Docker simply made containerd and other Linux constructs easy to work with so that container management would be a breeze. Instead of a dozen lines of code to create and deploy a running container, all you needed was:</p><pre><code>docker run
</code></pre><p>But like any platform, that convenience comes with a lot of bloat and technical debt. Especially over time. The removal of docker and the optimization of containerd marks a cultural shift of sorts for the cloud native landscape. None of this is meant to dismiss Docker Inc. Kubernetes today would not be where it is without Docker Inc. That’s a fact. The technologies and the competition that Docker Inc drove were some of the best things to ever happen to the industry. Now as far as turning a profitable business model out of open source technology goes, Docker Inc will likely be studied as a cautionary flash in the pan. Still, it’s important that we separate out the company’s contributions versus its business model. What’s left of the Docker platform, at this point, are its shadows within Kubernetes platforms. Though it does live on strongly within CI/CD ecosystems and, ostensibly, the inner loop of development thanks to the de facto standard Dockerfile. It is a testament to the power that Docker Inc once had, that its technology lived on far beyond the obsolescence of the company until community innovation caught up to it. With all the years of bloat baked into the platform, it’s really just a matter of time before other areas to the left of the platform shed the debt of the Docker daemon.</p><p>While it had an amazing journey and an indelible impact to the industry, practically speaking Docker is dead and dying.</p></div></div>]]>
            </description>
            <link>https://www.tariqislam.com/posts/kubernetes-docker-dep/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25325056</guid>
            <pubDate>Sun, 06 Dec 2020 17:38:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Speaker Snitch tells you when your smart speaker is listening in on you]]>
            </title>
            <description>
<![CDATA[
Score 12 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25324440">thread link</a>) | @nickbild
<br/>
December 6, 2020 | https://www.hackster.io/nickbild/speaker-snitch-26a642 | <a href="https://web.archive.org/web/*/https://www.hackster.io/nickbild/speaker-snitch-26a642">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="text"><h3 id="toc-speaker-snitch-0"><span>Speaker Snitch</span></h3><p><span>How can you </span><em>really</em><span> know when your smart speaker is listening and sending data to the cloud? There have been </span><a href="https://content.sciendo.com/view/journals/popets/2020/4/article-p255.xml?language=en" data-ha="{&quot;eventName&quot;:&quot;Clicked link&quot;,&quot;customProps&quot;:{&quot;value&quot;:&quot;documented cases &quot;,&quot;href&quot;:&quot;https://content.sciendo.com/view/journals/popets/2020/4/article-p255.xml?language=en&quot;,&quot;type&quot;:&quot;story&quot;,&quot;location&quot;:&quot;story&quot;},&quot;clickOpts&quot;:{&quot;delayRedirect&quot;:true}}" rel="nofollow">documented cases </a><span>in which up to a minute of speech has been transferred to the cloud without a wake-word having been spoken.</span></p><p>Speaker Snitch can give an absolute answer to this question by sniffing local network traffic and flashing a light sitting next to the speaker any time there is traffic between the speaker and the vendor's cloud service.</p>
<h3 id="toc-how-it-works-1"><span>How It Works</span></h3><p>A Raspberry Pi computer promiscuously sniffs packets on the local network. A Python script parses these packets, looking for any communication between the smart speaker and the vendor's cloud service. When detected, an API endpoint on an Arduino Nano 33 IoT microcontroller development board is accessed. This causes an LED attached to the Arduino to flash, thus alerting you to a speaker sending data to the vendor.</p><p>A single Raspberry Pi can trigger alerts on a number of Speaker Snitch devices all throughout your home.</p>
<h3 id="toc-use-2"><span>Use</span></h3><p><span>Packet parsing and control of the Speaker Snitch devices is handled by a simple </span><a href="https://github.com/nickbild/speaker_snitch/blob/main/snitch.py" data-ha="{&quot;eventName&quot;:&quot;Clicked link&quot;,&quot;customProps&quot;:{&quot;value&quot;:&quot;Python script.&quot;,&quot;href&quot;:&quot;https://github.com/nickbild/speaker_snitch/blob/main/snitch.py&quot;,&quot;type&quot;:&quot;story&quot;,&quot;location&quot;:&quot;story&quot;},&quot;clickOpts&quot;:{&quot;delayRedirect&quot;:true}}" rel="nofollow">Python script.</a><span> From the Raspberry Pi, the script is launched with:</span></p><p><code>sudo tcpdump -U -i wlan0 host [SPEAKER IP ADDRESS] | stdbuf -o0 python3 -u snitch.py</code></p><p>For example:</p><p><code>sudo tcpdump -U -i wlan0 host 192.168.1.196 | stdbuf -o0 python3 -u snitch.py</code></p><p><span>The Arduino devices are controlled by </span><a href="https://github.com/nickbild/speaker_snitch/tree/main/speaker_snitch_alert" data-ha="{&quot;eventName&quot;:&quot;Clicked link&quot;,&quot;customProps&quot;:{&quot;value&quot;:&quot;this sketch.&quot;,&quot;href&quot;:&quot;https://github.com/nickbild/speaker_snitch/tree/main/speaker_snitch_alert&quot;,&quot;type&quot;:&quot;story&quot;,&quot;location&quot;:&quot;story&quot;},&quot;clickOpts&quot;:{&quot;delayRedirect&quot;:true}}" rel="nofollow">this sketch.</a></p><h3 id="toc-media-3"><span>Media</span></h3><p>YouTube: </p><p>Speaker Snitch, top: </p>
<p>Speaker Snitch, angle: </p>
<p>Raspberry Pi 3 B+: </p>
<h3 id="toc-bill-of-materials-4"><span>Bill of Materials</span></h3><ul><li>1 x Raspberry Pi 3 B+ (or similar)</li><li>1 x Arduino Nano 33 IoT</li><li>1 x NeoPixel RGB LED</li><li>1 x Battery pack (for Arduino)</li><li>Miscellaneous wires</li></ul><h3 id="toc-about-the-author-5"><span>About the Author</span></h3><p><a href="https://nickbild79.firebaseapp.com/#!/" data-ha="{&quot;eventName&quot;:&quot;Clicked link&quot;,&quot;customProps&quot;:{&quot;value&quot;:&quot;Nick A. Bild, MS&quot;,&quot;href&quot;:&quot;https://nickbild79.firebaseapp.com/#!/&quot;,&quot;type&quot;:&quot;story&quot;,&quot;location&quot;:&quot;story&quot;},&quot;clickOpts&quot;:{&quot;delayRedirect&quot;:true}}" rel="nofollow">Nick A. Bild, MS</a></p></div></div>]]>
            </description>
            <link>https://www.hackster.io/nickbild/speaker-snitch-26a642</link>
            <guid isPermaLink="false">hacker-news-small-sites-25324440</guid>
            <pubDate>Sun, 06 Dec 2020 16:20:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[EmacsConf 2020 Talks]]>
            </title>
            <description>
<![CDATA[
Score 339 | Comments 64 (<a href="https://news.ycombinator.com/item?id=25324311">thread link</a>) | @AlexeyBrin
<br/>
December 6, 2020 | https://emacsconf.org/2020/talks/ | <a href="https://web.archive.org/web/*/https://emacsconf.org/2020/talks/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div class="page">



<div id="pagebody">







<div id="content" role="main">
<p><a href="https://emacsconf.org/2020/emacsconf-2020.m3u">Download an .m3u playlist</a></p>

<p>EmacsConf 2020 was on November 28 (Sat) and November 29 (Sun), 2020 from 9am-5pm Toronto/EST time; equivalently, 6am-2pm PST, 2pm-10pm UTC, 3pm-11pm Zurich/CET.</p>

<p>Many of the talks include accompanying material such as slides, questions, and notes. When present, these material are included or linked to on the talk page.</p>

<table><thead><tr><th>Duration</th><th>Title</th><th>Speakers</th></tr></thead><tbody><tr><td colspan="3">Talks</td></tr>
<tr><td colspan="3">NOVEMBER 28 (Saturday)</td></tr>
<tr><td>7:04</td><td><a href="https://emacsconf.org/2020/talks/00">Day 1 opening remarks</a></td><td>Amin Bandali, Sacha Chua, Leo Vivier</td></tr><tr>
</tr><tr><td>3:58</td><td><a href="https://emacsconf.org/2020/talks/01">Emacs News Highlights</a></td><td>Sacha Chua</td></tr><tr>
</tr><tr><td>24:15</td><td><a href="https://emacsconf.org/2020/talks/02">An Emacs Developer Story: From User to Package Maintainer</a></td><td>Leo Vivier</td></tr><tr>
</tr><tr><td>14:50</td><td><a href="https://emacsconf.org/2020/talks/03">Idea to Novel Superstructure: Emacs for Writing</a></td><td>Bala Ramadurai</td></tr><tr>
</tr><tr><td>8:26</td><td><a href="https://emacsconf.org/2020/talks/04">Music in Plain Text</a></td><td>Jonathan Gregory</td></tr><tr>
</tr><tr><td>29:50</td><td><a href="https://emacsconf.org/2020/talks/05">Bard Bivou(m)acs - Building a bandcamp-like page for an album of music</a></td><td>Grant Shangreaux</td></tr><tr>
</tr><tr><td>13:41</td><td><a href="https://emacsconf.org/2020/talks/06">Trivial Emacs Kits</a></td><td>Corwin Brust (mplsCorwin)</td></tr><tr>
</tr><tr><td>22:05</td><td><a href="https://emacsconf.org/2020/talks/07">Beyond Vim and Emacs: A Scalable UI Paradigm</a></td><td>Sid Kasivajhula (countvajhula)</td></tr><tr>
</tr><tr><td>17:19</td><td><a href="https://emacsconf.org/2020/talks/08">Building reproducible Emacs</a></td><td>Andrew Tropin (abcdw)</td></tr><tr>
</tr><tr><td>47:08</td><td><a href="https://emacsconf.org/2020/talks/21">On why most of the best features in eev look like 5-minute hacks</a></td><td>Eduardo Ochs (edrx)</td></tr><tr>
</tr><tr><td>14:09</td><td><a href="https://emacsconf.org/2020/talks/09">Orgmode - your life in plain text</a></td><td>Rainer König</td></tr><tr>
</tr><tr><td>8:18</td><td><a href="https://emacsconf.org/2020/talks/10">Lead your future with Org</a></td><td>Andrea</td></tr><tr>
</tr><tr><td>15:18</td><td><a href="https://emacsconf.org/2020/talks/11">the org-gtd package: opinions about Getting Things Done</a></td><td>Aldric</td></tr><tr>
</tr><tr><td>16:38</td><td><a href="https://emacsconf.org/2020/talks/12">One Big-ass Org File or multiple tiny ones?  Finally, the End of the debate!</a></td><td>Leo Vivier</td></tr><tr>
</tr><tr><td>12:05</td><td><a href="https://emacsconf.org/2020/talks/13">Experience Report: Steps to "Emacs Hyper Notebooks"</a></td><td>Joseph Corneli, Raymond Puzio, and Cameron Ray Smith</td></tr><tr>
</tr><tr><td>19:41</td><td><a href="https://emacsconf.org/2020/talks/14">README-Driven Design</a></td><td>Adam Ard</td></tr><tr>
</tr><tr><td>25:00</td><td><a href="https://emacsconf.org/2020/talks/15">Moving from Jekyll to OrgMode, an experience report</a></td><td>Adolfo Villafiorita</td></tr><tr>
</tr><tr><td>21:56</td><td><a href="https://emacsconf.org/2020/talks/16">Org-roam: Presentation, Demonstration, and What's on the Horizon</a></td><td>Leo Vivier</td></tr><tr>
</tr><tr><td>21:15</td><td><a href="https://emacsconf.org/2020/talks/17">Org-mode and Org-Roam for Scholars and Researchers</a></td><td>Noorah Alhasan</td></tr><tr>
</tr><tr><td>21:26</td><td><a href="https://emacsconf.org/2020/talks/18">Org-roam: Technical Presentation</a></td><td>Leo Vivier</td></tr><tr>
</tr><tr><td>8:13</td><td><a href="https://emacsconf.org/2020/talks/19">Sharing blogs (and more) with org-webring</a></td><td>Brett Gilio</td></tr><tr>
</tr><tr><td>22:50</td><td><a href="https://emacsconf.org/2020/talks/20">OMG Macros</a></td><td>Corwin Brust (mplsCorwin)</td></tr><tr>
</tr><tr><td>15:47</td><td><a href="https://emacsconf.org/2020/talks/40">Day 1 closing remarks</a></td><td>Amin Bandali, Sacha Chua, Leo Vivier, Corwin Brust</td></tr><tr>
</tr><tr><td colspan="3">NOVEMBER 29 (Sunday)</td></tr>
<tr><td>11:47</td><td><a href="https://emacsconf.org/2020/talks/41">Day 2 opening remarks</a></td><td>Amin Bandali, Sacha Chua, Leo Vivier</td></tr><tr>
</tr><tr><td>5:07</td><td><a href="https://emacsconf.org/2020/talks/38">Emacs development update</a></td><td>John Wiegley</td></tr><tr>
</tr><tr><td>29:06</td><td><a href="https://emacsconf.org/2020/talks/22">Powering-up Special Blocks</a></td><td>Musa Al-hassy</td></tr><tr>
</tr><tr><td>43:54</td><td><a href="https://emacsconf.org/2020/talks/23">Incremental Parsing with emacs-tree-sitter</a></td><td>Tuấn-Anh Nguyễn</td></tr><tr>
</tr><tr><td>20:46</td><td><a href="https://emacsconf.org/2020/talks/24">Analyze code quality through Emacs: a smart forensics approach and the story of a hack</a></td><td>Andrea</td></tr><tr>
</tr><tr><td>9:52</td><td><a href="https://emacsconf.org/2020/talks/25">Traverse complex JSON structures with live feedback</a></td><td>Zen Monk Alain M. Lafon</td></tr><tr>
</tr><tr><td>53:38</td><td><a href="https://emacsconf.org/2020/talks/39">NonGNU ELPA</a></td><td>Richard Stallman</td></tr><tr>
</tr><tr><td>14:57</td><td><a href="https://emacsconf.org/2020/talks/26">Emacs as a Highschooler: How It Changed My Life</a></td><td>Pierce Wang</td></tr><tr>
</tr><tr><td>21:26</td><td><a href="https://emacsconf.org/2020/talks/27">State of Retro Gaming in Emacs</a></td><td>Vasilij "wasamasa" Schneidermann</td></tr><tr>
</tr><tr><td>1:09:00</td><td><a href="https://emacsconf.org/2020/talks/28">Welcome To The Dungeon</a></td><td>Erik Elmshauser and Corwin Brust</td></tr><tr>
</tr><tr><td>(combined with previous)</td><td><a href="https://emacsconf.org/2020/talks/29">Pathing of Least Resistance</a></td><td>Erik Elmshauser and Corwin Brust (mplsCorwin)</td></tr><tr>
</tr><tr><td>11:30</td><td><a href="https://emacsconf.org/2020/talks/30">A tour of vterm</a></td><td>Gabriele Bozzola (@sbozzolo)</td></tr><tr>
</tr><tr><td>16:50</td><td><a href="https://emacsconf.org/2020/talks/31">Lakota Language and Emacs</a></td><td>Grant Shangreaux</td></tr><tr>
</tr><tr><td>23:57</td><td><a href="https://emacsconf.org/2020/talks/32">Object Oriented Code in the Gnus Newsreader</a></td><td>Eric Abrahamsen</td></tr><tr>
</tr><tr><td>39:16</td><td><a href="https://emacsconf.org/2020/talks/33">Maxima a computer algebra system in Emacs</a></td><td>Fermin MF</td></tr><tr>
</tr><tr><td>22:22</td><td><a href="https://emacsconf.org/2020/talks/34">Extend Emacs to Modern GUI Applications with EAF</a></td><td>Matthew Zeng</td></tr><tr>
</tr><tr><td>16:02</td><td><a href="https://emacsconf.org/2020/talks/35">WAVEing at Repetitive Repetitive Repetitive Music</a></td><td>Zachary Kanfer</td></tr><tr>
</tr><tr><td>36:29</td><td><a href="https://emacsconf.org/2020/talks/42">Day 2 closing remarks</a></td><td>Amin Bandali, Sacha Chua, Leo Vivier, Corwin Brust</td></tr><tr></tr></tbody></table>




</div>







</div>



</div></div>]]>
            </description>
            <link>https://emacsconf.org/2020/talks/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25324311</guid>
            <pubDate>Sun, 06 Dec 2020 16:00:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Building a Distributed Android Remote Testing Platform]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25324142">thread link</a>) | @elvischidera
<br/>
December 6, 2020 | https://elvischidera.com/2020-11-23-building-distributed-android-remote-testing-platform/ | <a href="https://web.archive.org/web/*/https://elvischidera.com/2020-11-23-building-distributed-android-remote-testing-platform/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><img src="https://elvischidera.com/1ffaeb44c8a342b87f8aea771c98c871/dart_work_flow.svg"><p>There are currently ~2.5 billion Android devices — consisting of ~1,300 discrete brands and ~24,000 unique device models. I'm exploring tapping into this latent resource pool to make automated testing affordable &amp; unlock a more comprehensive configuration coverage.</p><p>The goal of DART (Distributed Android Remote Testing) is to enable any Android device to run automated tests — without ADB or complex setups/maintenance. A commercial product could pay people per hour of device use, allowing anyone to utilize idle device time. Each device is subsumed to provide a distributed testbed.</p><p>DART is orthogonal to <a href="https://en.wikipedia.org/wiki/Crowdsourced_testing">crowdsourced testing</a> — the latter requires active human participation.</p><p>DART seems to be the best solution to utilize device idle time — the best way to verify that an app works on "Samsung S9" is by executing it on "Samsung S9".  Contrast this to other procedures where phones are usually a suboptimal option: server hosting, remote computation, etc.</p><p>In the demo below, I ran a few test cases on <a href="https://play.google.com/store/apps/details?id=org.mozilla.focus&amp;hl=en_US&amp;gl=US">Mozilla Focus Privacy Browser</a> without cables/ADB.</p><p><iframe width="100%" height="100%" src="https://www.youtube.com/embed/CcHEsx7ODyw" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></p><h3>1.1. 💪 Motivation</h3><p>The following problems motivated the development of DART.</p><h5>i. 🧩 Android Device Fragmentation</h5><img src="https://elvischidera.com/4c37a9cd069bcaa8ee86c04764a37790/android_fragmentation.gif" alt="Android device fragmentation"><p>The top device farms barely cover 1% of the total number of Android device models. Nondistributed device farms favor depth instead of breadth — maintenance cost increases as more diverse devices are added.</p><p>Testing on flagship devices alone doesn't always suffice.</p><blockquote><p>Anecdote: I once spent an entire day debugging an ANR that occurs to a small fraction of our users. I discovered it only affects phones purchased in specific regions. I never was able to reproduce the issue on the same phone bought in the USA.</p></blockquote><p>The Android version distribution exacerbates this problem.</p><p><span>
      <a href="https://elvischidera.com/static/b242c178d4653a1a85fcaaeddfff889a/53fe7/android_os_distribution.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="Android OS Distribution" title="Android OS Distribution" src="https://elvischidera.com/static/b242c178d4653a1a85fcaaeddfff889a/7d769/android_os_distribution.png" srcset="https://elvischidera.com/static/b242c178d4653a1a85fcaaeddfff889a/5243c/android_os_distribution.png 240w,https://elvischidera.com/static/b242c178d4653a1a85fcaaeddfff889a/ab158/android_os_distribution.png 480w,https://elvischidera.com/static/b242c178d4653a1a85fcaaeddfff889a/7d769/android_os_distribution.png 960w,https://elvischidera.com/static/b242c178d4653a1a85fcaaeddfff889a/87339/android_os_distribution.png 1440w,https://elvischidera.com/static/b242c178d4653a1a85fcaaeddfff889a/88b03/android_os_distribution.png 1920w,https://elvischidera.com/static/b242c178d4653a1a85fcaaeddfff889a/53fe7/android_os_distribution.png 2097w" sizes="(max-width: 960px) 100vw, 960px" loading="lazy">
  </a>
    </span></p><p><a href="https://www.headspin.io/">Headspin</a> aims to alleviate some of these issues. They claim to have a global infrastructure of more than 22,000 SIM-enabled (similar) devices in 150 locations. A big plus as traditional services (like Firebase Testlabs) can't handle geographical concerns. At Headspin's core is the <a href="https://github.com/DeviceFarmer/stf">DeviceFarmer STF</a> open-source library. But like its predecessors, Headspin only supports a limited set of device models.</p><h5>ii. 💸 Expensive Physical Devices</h5><img src="https://elvischidera.com/457ab6ec0d4f4335573264b78937f40d/real_device_pricing_chart.svg"><p>Real device test farms have an initial cost and require periodic maintenance, hence why they are more expensive than virtual device farms.</p><blockquote><p>Running 10 hours of test daily on real devices costs <strong>$1000/month</strong> (assuming 20 working days of equal levels of productivity).</p></blockquote><h3>1.2. 📱 Product</h3><p><strong>The key 🔑:</strong> Uber averts enormous maintenance costs by not owning all the cars on its global network. Similarly, with a distributed network of test devices, extensive device coverage is attainable with minimal maintenance costs. For one or two co-located devices, maintenance isn't fastidious.</p><blockquote><p>From <a href="https://github.com/DeviceFarmer/stf#faq">DeviceFramer STF</a> FAQ: "Aside from a single early failure we had within only a few months, all of our devices were doing fine for about two years. However, having reached the 2-3 year mark, several devices have started to experience visibly expanded batteries <!-- -->[...]<!-- -->
In our experience, the system runs just fine most of the time, and any issues are mostly USB-related. You'll usually have to do something about once a week."</p></blockquote><p>Organizations can decide what type of tests are ideal for DART and if the network is made-up of single nodes or clusters of nodes. The simple taxonomy of android testing below should be helpful. <!-- -->[1]</p><img src="https://elvischidera.com/3c544343e6de6b0d393c6101c4359694/taxonomy_android_testing.svg" alt="Taxonomy of Android testing"><p>The network can be internal to an organization. An example: <code>X</code> devices stored in HQ, each employee can remotely contribute their test device into the system.</p><p>It can also be external to an organization. Imagine paying people <code>$1.5/hour</code> of device time. Assuming a device runs test overnight (thanks to timezone differences), the estimated monthly earning is <code>$240</code> (<code>$1.5 * 8 hours * 20 working days</code>).</p><blockquote><p>The median income in some countries is ~$400/month. </p></blockquote><p>Below is a demo of the <a href="https://github.com/Elvis10ten/dart">proof-of-concept</a>.</p><p><iframe width="100%" height="100%" src="https://www.youtube.com/embed/7SotlhlwMDA" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></p><p>Currently, a simple dashboard renders the test summary.</p><div>
  <p><span>
      <a href="https://elvischidera.com/static/df61ab399fe3e586915d07813ac34298/e60a2/dashboard_timeline.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="Dashboard timeline" title="Dashboard timeline" src="https://elvischidera.com/static/df61ab399fe3e586915d07813ac34298/7d769/dashboard_timeline.png" srcset="https://elvischidera.com/static/df61ab399fe3e586915d07813ac34298/5243c/dashboard_timeline.png 240w,https://elvischidera.com/static/df61ab399fe3e586915d07813ac34298/ab158/dashboard_timeline.png 480w,https://elvischidera.com/static/df61ab399fe3e586915d07813ac34298/7d769/dashboard_timeline.png 960w,https://elvischidera.com/static/df61ab399fe3e586915d07813ac34298/87339/dashboard_timeline.png 1440w,https://elvischidera.com/static/df61ab399fe3e586915d07813ac34298/88b03/dashboard_timeline.png 1920w,https://elvischidera.com/static/df61ab399fe3e586915d07813ac34298/e60a2/dashboard_timeline.png 3086w" sizes="(max-width: 960px) 100vw, 960px" loading="lazy">
  </a>
    </span>
  </p>
  <p><span>
      <a href="https://elvischidera.com/static/adbbe95cc9f013049dcec4967d3c551b/e60a2/dashboard_screenshots.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="Dashboard screenshots" title="Dashboard screenshots" src="https://elvischidera.com/static/adbbe95cc9f013049dcec4967d3c551b/7d769/dashboard_screenshots.png" srcset="https://elvischidera.com/static/adbbe95cc9f013049dcec4967d3c551b/5243c/dashboard_screenshots.png 240w,https://elvischidera.com/static/adbbe95cc9f013049dcec4967d3c551b/ab158/dashboard_screenshots.png 480w,https://elvischidera.com/static/adbbe95cc9f013049dcec4967d3c551b/7d769/dashboard_screenshots.png 960w,https://elvischidera.com/static/adbbe95cc9f013049dcec4967d3c551b/87339/dashboard_screenshots.png 1440w,https://elvischidera.com/static/adbbe95cc9f013049dcec4967d3c551b/88b03/dashboard_screenshots.png 1920w,https://elvischidera.com/static/adbbe95cc9f013049dcec4967d3c551b/e60a2/dashboard_screenshots.png 3086w" sizes="(max-width: 960px) 100vw, 960px" loading="lazy">
  </a>
    </span>
  </p></div><h3>1.3. 🛡️ Security</h3><p><span>
      <a href="https://elvischidera.com/static/2964435cc8375c02bac5d7ac8e9d9646/9211e/network_of_devices.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="Network of devices" title="Network of devices" src="https://elvischidera.com/static/2964435cc8375c02bac5d7ac8e9d9646/7d769/network_of_devices.png" srcset="https://elvischidera.com/static/2964435cc8375c02bac5d7ac8e9d9646/5243c/network_of_devices.png 240w,https://elvischidera.com/static/2964435cc8375c02bac5d7ac8e9d9646/ab158/network_of_devices.png 480w,https://elvischidera.com/static/2964435cc8375c02bac5d7ac8e9d9646/7d769/network_of_devices.png 960w,https://elvischidera.com/static/2964435cc8375c02bac5d7ac8e9d9646/87339/network_of_devices.png 1440w,https://elvischidera.com/static/2964435cc8375c02bac5d7ac8e9d9646/88b03/network_of_devices.png 1920w,https://elvischidera.com/static/2964435cc8375c02bac5d7ac8e9d9646/9211e/network_of_devices.png 1955w" sizes="(max-width: 960px) 100vw, 960px" loading="lazy">
  </a>
    </span></p><p>There are two perspectives here:</p><h5>i. 🧐 End-user Perspective</h5><p>The end-user is concerned about malignant binaries &amp; privacy.</p><p>Security checks will guard devices from malicious binaries. The system will be closed — only verified publishers allowed. GooglePlay is leveraged to enforce package name and signature correspondence.</p><p>A sandboxed test environment guarantees that private data is inaccessible to apps under test.</p><p><a href="https://blog.google/products/android-enterprise/android-enterprise-security-assessed-gartner/"><span>
      <span></span>
  <img alt="Android Enterprise security" title="Android Enterprise security" src="https://elvischidera.com/static/a60424159862b8385fef4219304a1b71/18e3b/android_enterpise_security.jpg" srcset="https://elvischidera.com/static/a60424159862b8385fef4219304a1b71/46946/android_enterpise_security.jpg 240w,https://elvischidera.com/static/a60424159862b8385fef4219304a1b71/55489/android_enterpise_security.jpg 480w,https://elvischidera.com/static/a60424159862b8385fef4219304a1b71/18e3b/android_enterpise_security.jpg 960w,https://elvischidera.com/static/a60424159862b8385fef4219304a1b71/dbdff/android_enterpise_security.jpg 1000w" sizes="(max-width: 960px) 100vw, 960px" loading="lazy">
    </span></a></p><h5>ii. 👩🏽‍💻 Publisher Perspective</h5><p>The publisher cares about test fraud and product leaks.</p><p>Proof of work disincentivizes test fraud. The server can use device logs, screenshots, videos with UUID, and past executions to validate submitted work results. As this isn't watertight, it is best combined with other strategies: user verifications, <a href="https://developer.android.com/training/safetynet">device attestation</a>, randomization, and device throughput throttling.</p><p>Preventing product leaks is hard  — if it runs on a phone, any sufficiently motivated (&amp; knowledgeable) person can figure out a way to access objects. Three good-enough solutions are:</p><p>a. Running headless tests.</p><p>b. Using a private network of vetted devices.</p><p>c. Adopting only for binaries at the later end of the release pipeline.</p><h3>1.4. 🎃 Going Headless</h3><p>It is possible to obscure the application under test using a simple overlay. The video below shows the execution of the test cases of the Google IO 2019 app. On the right, the app interactions are invisible. Depending on the strategy, concealing actions do not affect screenshots or videos.</p><p><iframe width="100%" height="100%" src="https://www.youtube.com/embed/jxwsoe3T8yE" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></p><p>With framework UI component wrappers, it is possible to borrow some ideas from <a href="https://android.googlesource.com/platform/frameworks/base/+/4db1f432b853152075923499768639e14403b73a/tools/layoutlib/README">Layoutlib</a> to offer a full headless solution. <code>Layoutlib</code> is a custom version of the android View framework designed to run inside Eclipse. The goal of the library is to provide layout rendering in Eclipse that are very close to their rendering on devices.</p><h3>1.5. 📦 Containerization</h3><p>Tests need to run in an isolated environment. A plugin framework like <a href="https://github.com/didi/VirtualAPK">VirtualAPK</a> can be built to offer a layer of isolation between apps and the OS. This works using the <code>DexClassLoader</code> and some reflection hacks to modify framework components. With this approach, apps can be seamlessly loaded &amp; unloaded without any user interaction.</p><p><span>
      <a href="https://elvischidera.com/static/d9bbe7fecdd50b018b77ea33d7766d4a/56ba3/virtual_apk_diagram.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="VirtualAPK" title="VirtualAPK" src="https://elvischidera.com/static/d9bbe7fecdd50b018b77ea33d7766d4a/7d769/virtual_apk_diagram.png" srcset="https://elvischidera.com/static/d9bbe7fecdd50b018b77ea33d7766d4a/5243c/virtual_apk_diagram.png 240w,https://elvischidera.com/static/d9bbe7fecdd50b018b77ea33d7766d4a/ab158/virtual_apk_diagram.png 480w,https://elvischidera.com/static/d9bbe7fecdd50b018b77ea33d7766d4a/7d769/virtual_apk_diagram.png 960w,https://elvischidera.com/static/d9bbe7fecdd50b018b77ea33d7766d4a/87339/virtual_apk_diagram.png 1440w,https://elvischidera.com/static/d9bbe7fecdd50b018b77ea33d7766d4a/56ba3/virtual_apk_diagram.png 1542w" sizes="(max-width: 960px) 100vw, 960px" loading="lazy">
  </a>
    </span></p><blockquote><p>The <a href="https://developer.android.com/guide/app-bundle/play-feature-delivery">GooglePlay dynamic feature delivery</a> system uses some of these reflection techniques to support legacy devices (pre Android 7.0) 🙈. For instance, <code>addAssetPath</code> is called via reflection to make resources not bundled in an APK available for use.
<span>
      <span></span>
  <img alt="Splitcompat source" title="Splitcompat source" src="https://elvischidera.com/static/66a528e3618765871f563545a91cb424/7d769/split_compat_source.png" srcset="https://elvischidera.com/static/66a528e3618765871f563545a91cb424/5243c/split_compat_source.png 240w,https://elvischidera.com/static/66a528e3618765871f563545a91cb424/ab158/split_compat_source.png 480w,https://elvischidera.com/static/66a528e3618765871f563545a91cb424/7d769/split_compat_source.png 960w,https://elvischidera.com/static/66a528e3618765871f563545a91cb424/5d7c1/split_compat_source.png 1290w" sizes="(max-width: 960px) 100vw, 960px" loading="lazy">
    </span></p></blockquote><p>This plugin approach adds cruft that is nonexistent on a regular device. An alternative is using the <a href="https://developer.android.com/work/managed-profiles">Android work profile</a>. Work profile creates a separate, self-contained profile on Android devices that isolates corporate data from personal apps and data. <!-- -->[3]</p><a href="https://blog.google/products/android-enterprise/work-profile-new-standard-employee-privacy/"><img src="https://elvischidera.com/a15aea53c7e448bdc96e55650ee95419/android_work_profiles.gif" alt="Android work profile"></a><p>Work profiles also provide always-on VPN configuration, control of runtime permissions, extra security, etc. Work profiles are a great fit, only deviating slightly from the operating mode used by the average user.</p><blockquote><p>Android allows apps signed with the same key to run in the same process, if the apps so request, so that the system treats them as a single application. <!-- -->[3]</p></blockquote><h3>1.6. 💔 Flakiness</h3><p>The system should eliminate most causes of flakiness that results from running tests on real peoples' devices — I have run over <strong>5,000 tests</strong> so far without any issues 🚀. In an external network, it would be naive to assume perfection as there are so many variables introduced. As the project evolves, these issues would be identified and mitigated.</p><p>A few researchers manually examined <strong>423</strong> projects featuring the Espresso automated GUI testing tool. They derived a set of <strong>27</strong> different causes of modifications and grouped them into <strong>nine</strong> macro-categories. Category percentages were then computed based on the frequency of modification causes. <!-- -->[2]</p><img src="https://elvischidera.com/8779fc45863974d0b90fac96e035dd14/graphic_taxonomy_of_modification_causes.svg"><h3>1.7. 🚧 Code Repository</h3><p>There are four primary directories in the <a href="https://github.com/Elvis10ten/dart">Github repo</a>:</p><p>i. <code>Apollo</code>: Android project for the client (worker).</p><p>ii. <code>WorkServer</code>: Kotlin project for the gRPC work server.</p><p>iii. <code>WorkSpecs</code>: Protobuf definitions shared by both the server &amp; Android client.</p><p>iv. <code>Dashboard</code>: React project for the web dashboard.</p><p>All projects are still a work in progress and lack adequate documentation.</p><h2>2. 🏗️ System Overview</h2><img src="https://elvischidera.com/1ffaeb44c8a342b87f8aea771c98c871/dart_work_flow.svg"><p>As shown above, multiple components must work in tandem to run tests on a device. The sequence diagram below shows the component interactions at a high-level.</p><p>sequenceDiagram
    participant Worker as Worker (Device)
    participant WorkRunner
    participant TestServer
    participant TestClient
    participant Telemetry
    participant InstrumentationTests
    participant AppUnderTest
    participant UiAutomator
    
    activate Worker
    Worker-&gt;&gt;WorkRunner: Run Work-X
    activate WorkRunner

    WorkRunner-&gt;&gt;WorkRunner: Download &amp; unpack payload
    WorkRunner-&gt;&gt;WorkRunner: Perform redundant cleanup
    
    WorkRunner-&gt;&gt;UiAutomator: Connect UiAutomator
    activate UiAutomator
    UiAutomator--&gt;&gt;WorkRunner: Connected!

    WorkRunner-&gt;&gt;UiAutomator: Install AppUnderTest.apk
    UiAutomator--&gt;&gt;WorkRunner: Installed!
    WorkRunner-&gt;&gt;UiAutomator: Install Test.apk
    UiAutomator--&gt;&gt;WorkRunner: Installed!

    WorkRunner-&gt;&gt;Worker: Kill other apps
    activate Worker
    Worker--&gt;&gt;WorkRunner: Killed!
    deactivate Worker

    WorkRunner-&gt;&gt;Worker: Dismiss system dialogs
    activate Worker
    Worker--&gt;&gt;WorkRunner: Dismissed!
    deactivate Worker

    WorkRunner-&gt;&gt;Worker: Activate DND
    activate Worker
    Worker--&gt;&gt;WorkRunner: Activated!
    deactivate Worker

    WorkRunner-&gt;&gt;TestServer: Start test server
    activate TestServer
    TestServer-&gt;&gt;TestServer: Start timeout timer
    TestServer-&gt;&gt;TestServer: Prepare test config

    TestServer-&gt;&gt;TestClient: Start Instrumentation(config)
    activate TestClient
    TestClient--&gt;&gt;TestServer: Started!

    TestClient-&gt;&gt;TestServer: Establish server connection
    TestServer--&gt;&gt;TestClient: Established!
    TestServer-xTestClient: Connect Activity boostrapper

    TestClient-&gt;&gt;UiAutomator: Acquire runtime permissions
    UiAutomator--&gt;&gt;TestClient: Acquired!

 …</p></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://elvischidera.com/2020-11-23-building-distributed-android-remote-testing-platform/">https://elvischidera.com/2020-11-23-building-distributed-android-remote-testing-platform/</a></em></p>]]>
            </description>
            <link>https://elvischidera.com/2020-11-23-building-distributed-android-remote-testing-platform/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25324142</guid>
            <pubDate>Sun, 06 Dec 2020 15:36:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Elementary OS on Raspberry Pi]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25323787">thread link</a>) | @rcarmo
<br/>
December 6, 2020 | https://blog.elementary.io/elementary-os-on-raspberry-pi/ | <a href="https://web.archive.org/web/*/https://blog.elementary.io/elementary-os-on-raspberry-pi/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
  
  <header>
    
    
      <h2>



   Continuing our experimental Early Access&nbsp;builds

</h2>
    

    



<div>
  <p><img srcset="https://www.gravatar.com/avatar/41275ecc8271aca852ce2c0ff72d2610?s=96&amp;d=blank 2x" src="https://www.gravatar.com/avatar/41275ecc8271aca852ce2c0ff72d2610?s=48&amp;d=blank" alt="Avatar for Cassidy James Blaede">
  </p>
  
  <p><time datetime="2020-12-04">Fri, Dec  4, 2020</time>
  
    <span title="Estimated read time">
  
  5 min read
</span>


  
</p></div>


    


  </header>

  <section>
    <p>Following our <a href="https://blog.elementary.io/elementary-os-on-pinebook-pro">efforts to bring elementary OS to the ARM-based Pinebook Pro</a>, we’ve added experimental builds for the ARM-based Raspberry Pi 4 series—including the recently-launched Raspberry Pi 400—to our <a rel="nofollow noopener noreferrer" target="_blank" href="https://builds.elementary.io/">Early Access</a> program. Like Pinebook Pro builds, Raspberry Pi support is considered an experiment and is not something we have committed to officially support indefinitely. However, if you’re one of the many folks with a Raspberry Pi 4 sitting around and wanted to see how a full, modern desktop operating system runs, elementary OS is now an option!</p>

<figure>
  <p><img src="https://blog.elementary.io/images/elementary-os-on-raspberry-pi/desktop.jpg" alt="Raspberry Pi 4 running elementary OS"></p>
  <figcaption>My current desktop, powered by a Raspberry Pi 4 running elementary OS</figcaption>
</figure>

<p>Personally, I typically use Raspberry Pi 4 as a network device, e.g. a DNS server and for network-attached storage. However, I’ve been using elementary OS builds on it for the past week, and I’m impressed. While it won’t compete experience-wise with a high end desktop, it is a real option for casual computing, development, and writing. In fact, this blog post was written entirely on my Raspberry Pi 4 running elementary OS. It would even be possible to run the same network services on the hardware from within elementary OS just so you get a nice modern GUI when doing any local management.</p>

<p>Like with <a href="https://blog.elementary.io/elementary-os-on-pinebook-pro">Pinebook Pro</a>, there are some things you should know if you plan to use elementary OS Early Access builds on Raspberry Pi:</p>

<h2 id="kernel">Kernel</h2>

<p>Since Ubuntu has released Raspberry Pi images, we are able to rely on that work to ship a supported and updated kernel. Thanks to all of the folks at Canonical and in the Ubuntu community who have worked to make that happen!</p>

<h2 id="performance">Performance</h2>

<p>elementary OS on Raspberry Pi 4 is not going to match the polished experience of a full modern desktop computer, largely due to our current software stack. GTK3 does not offer GPU-accelerated animations, so animations within apps are less smooth than we would like. Still, for a computer coming in at under $100, it’s impressive and perfectly usable for several tasks.</p>

<p>There are also some things you can do to improve performance. We would definitely recommend using some sort of cooling with your Raspberry Pi, whether that’s a a heatsink and fan (like the recently-announced <a rel="nofollow noopener noreferrer" target="_blank" href="https://www.raspberrypi.org/blog/new-raspberry-pi-4-case-fan/">Raspberry Pi 4 Case Fan</a>), or a passive case like one from <a rel="nofollow noopener noreferrer" target="_blank" href="https://flirc.tv/">Flirc</a>—my favorite for its looks and silence. Since Raspberry Pi 4 tends to throttle due to heat under desktop loads, cooling will help it stay more responsive. We also recommend trying USB3 storage as your boot drive, as it should be faster than a microSD card. Using a 1080p (or lower) resolution also works a fair bit better than trying to push a 1440p or 4K display, but your mileage may vary based on your use case.</p>

<h2 id="supported-raspberry-pi-models">Supported Raspberry Pi Models</h2>

<p>We recommend Raspberry Pi 4 or Raspberry Pi 400 with 4 GB RAM at a minimum—but the more, the better. (We don’t even recommend less than 8 GB for computers with much faster CPUs, graphics, and storage.)</p>

<p>Older models of Raspberry Pi (like the original, Raspberry Pi Zero, Raspberry Pi 2 series, and Raspberry Pi 3 series) are not supported; elementary OS requires the faster processor, additional RAM, and 64-bit architecture of the Raspberry Pi 4 series. For older models, we recommend sticking to Raspberry Pi OS or a “headless” OS like Ubuntu Server.</p>

<h2 id="run-elementary-os-on-raspberry-pi">Run elementary OS on Raspberry Pi</h2>

<p>In its current state, we would not consider elementary OS on Raspberry Pi as polished of an experience as running on well-supported AMD- or Intel-based hardware.</p>

<p>That said, the audience for Raspberry Pi leans toward tinkerers and experimenters; as such, we’ve decided to publish our builds under our <a rel="nofollow noopener noreferrer" target="_blank" href="https://builds.elementary.io/">Early Access builds</a> program. This means dedicated <a rel="nofollow noopener noreferrer" target="_blank" href="https://github.com/sponsors/elementary">sponsors</a> of elementary OS who wish to run elementary OS on Raspberry Pi can download it from the same place as Early Access builds of elementary OS. As a note, all of this work has been focused on bringing the <strong>pre-release of elementary OS 6</strong> to Raspberry Pi, so all the usual disclaimers about pre-release builds apply here as well.</p>



<p>Once you have access to Early Access builds, head over to the <a rel="nofollow noopener noreferrer" target="_blank" href="https://github.com/elementary/os/wiki/Raspberry-Pi">elementary OS wiki</a> to get it installed on your own hardware. If you find and file any issues, please remember to specify the build of the OS you downloaded as well as that you are running on Raspberry Pi—it will help us validate and triage issues much more quickly.</p>

<h2 id="thanks-to-andrew-david-hewitt-and-marius-meisenzahl">Thanks to Andrew, David Hewitt, and Marius Meisenzahl</h2>

<p>Bringing elementary OS to Raspberry Pi was a collaborative effort. <a rel="nofollow noopener noreferrer" target="_blank" href="https://github.com/andrewc910">Andrew</a>, <a rel="nofollow noopener noreferrer" target="_blank" href="https://github.com/davidmhewitt">David Hewitt</a>, and <a rel="nofollow noopener noreferrer" target="_blank" href="https://github.com/meisenzahl">Marius Meisenzahl</a> specifically worked to prototype, improve, and ultimately ship these builds. And of course countless folks across the Raspberry Pi Foundation, Debian, Canonical, Ubuntu, and more have worked for years on making the underlying system work well for us to build on.</p>


  </section>

  
<div>
  <hr>

  <h2>Thank You</h2>
  <p>Thanks to all of our supporters, backers, and customers! Your contributions make elementary possible. If you’d like to help build and improve elementary OS, don’t hesitate to <a rel="nofollow noopener noreferrer" target="_blank" href="https://elementary.io/get-involved" onclick="plausible('Link: Get Involved')">Get Involved</a>.</p>

  
</div>




</article></div>]]>
            </description>
            <link>https://blog.elementary.io/elementary-os-on-raspberry-pi/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25323787</guid>
            <pubDate>Sun, 06 Dec 2020 14:49:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Talos – Modern OS for Kubernetes at the Edge]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25323700">thread link</a>) | @andrewrynhard
<br/>
December 6, 2020 | https://www.talos-systems.com/blog/talos-on-sbcs/ | <a href="https://web.archive.org/web/*/https://www.talos-systems.com/blog/talos-on-sbcs/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-1549">
	
	
	<!-- .entry-header -->

	
	<div>
		<p>It has been almost two years since Talos was first announced to the world. ARM support was almost immediately a feature request. At the time the project had major features missing that needed to be implemented before we could even <em>think</em> about Talos on ARM. Only after forming a company, hiring a kick ass team, and pouring a tremendous amount of time and love into Talos have we finally been able to achieve this.</p>
<p>The Talos team is proud to announce support for four ARM single board computers (SBCs) in our latest alpha release:</p>
<ul>
<li>Raspberry Pi 4 Model B</li>
<li>Pine64 Rock64</li>
<li>Banana Pi M64</li>
<li>Libre Computer ALL-H3-CC H5 (Tritium)</li>
</ul>
<p>For those not familiar with Talos, it is an ultra minimal OS with an API instead of ssh+shell built for the purpose of running Kubernetes with security as a priority. The image is immutable, the runtime is ephemeral, and the configuration is declarative. For more on what all of this means, see our documentation at <a href="https://www.talos.dev/">https://www.talos.dev/</a>. We think you will love it.</p>
<p>Landing support for SBCs signifies a huge milestone for Talos. You can now run Talos nearly anywhere you can imagine. The same Talos is able to run in the cloud, on-premise, and now at the edge. This means you get a resource efficient, secure, and reliable OS running the same vanilla Kubernetes that you run in production datacenters - wherever you might need it.</p>
<p>We are looking to add support for more boards. Please, let us know what boards you might be interested in by creating an issue in the GitHub <a href="https://github.com/talos-systems/talos">repo</a>.</p>
			</div><!-- .entry-content -->

	<!-- .entry-footer -->

	
</article></div>]]>
            </description>
            <link>https://www.talos-systems.com/blog/talos-on-sbcs/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25323700</guid>
            <pubDate>Sun, 06 Dec 2020 14:36:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Rust makes cross compilation child's play]]>
            </title>
            <description>
<![CDATA[
Score 20 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25323560">thread link</a>) | @susam
<br/>
December 6, 2020 | https://www.marcoieni.com/2020/12/rust-makes-cross-compilation-childs-play/ | <a href="https://web.archive.org/web/*/https://www.marcoieni.com/2020/12/rust-makes-cross-compilation-childs-play/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    

<h2 id="why-do-i-care-about-this">Why do I care about this</h2>

<p>Recently I solved <a href="https://github.com/dandavison/delta/issues/396">this</a> delta issue,
where the maintainer asked to switch from Travis CI to GitHub actions.</p>

<p>These are all the pull requests I’ve done if you want to have a look at this journey:
<a href="https://github.com/dandavison/delta/pull/399">#399</a>, <a href="https://github.com/dandavison/delta/pull/400">#400</a>,
<a href="https://github.com/dandavison/delta/pull/409">#409</a>, <a href="https://github.com/dandavison/delta/pull/411">#411</a>,
<a href="https://github.com/dandavison/delta/pull/413">#413</a>, <a href="https://github.com/dandavison/delta/pull/417">#417</a>
and finally <a href="https://github.com/dandavison/delta/pull/418">#418</a>.</p>

<p>And yes..As you can see I like small incremental work and early feedback instead of giant pull requests. 😁</p>

<p>Anyway, the delta project has a lot of compilation targets and the binaries are automatically released in the
GitHub releases <a href="https://github.com/dandavison/delta/releases">page</a> every time the project is tagged. Sweet. 😌</p>

<p><img src="https://www.marcoieni.com/2020/12/rust-makes-cross-compilation-childs-play/delta.png" alt="delta releases" title="Releases"></p>

<p>From an x86_64 architecture (TLDR: common 64 bit Intel or AMD processors) it is really straightforward to
compile for a different operating system with <code>cargo</code> if you are targeting the same architecture.
For example if you want to compile for macOS you just need to run:</p>

<pre><code>rustup target add x86_64-apple-darwin
cargo build --target x86_64-apple-darwin
</code></pre>

<p>The problems start to arise when you want to compile for a different architecture, such as i686 (32 bit) or ARM processors.
In this case, you have to install some dependencies and set some environment variables, which may be painful.
For example, in the old continuous integrations scripts of delta,
<a href="https://github.com/dandavison/delta/blob/15d06cbf7584570ec3b5beaba99cb8898f9ec3dc/etc/ci/before_install.sh">this</a>
was the way dependencies were installed. Ugly, I know. As rust developers we are used to great tools,
so there must be a better way right?</p>

<h2 id="meet-cross">Meet Cross</h2>

<blockquote>
<p>“Zero setup” cross compilation and “cross testing” of Rust crates.</p>
</blockquote>

<p>This is the description of the <a href="https://github.com/rust-embedded/cross">Cross</a> tool.</p>

<p>The TLDR is that it let you compile and test rust projects for architectures other than i686 and x86_64.</p>

<p>Instead of doing <code>cargo build --target &lt;YOUR_TARGET&gt;</code> you simply do <code>cross build --target &lt;YOUR_TARGET&gt;</code>.
Based on the target, in fact, cross will run a docker image that has all the right dependencies already
installed and configured by the rust-embedded team itself. 😉
And that’s it..just run <code>cargo install cross</code> and you are ready to cross-compile for all
<a href="https://github.com/rust-embedded/cross#supported-targets">these</a> targets in rust, no other dependency
is required, except docker of course!</p>

<p>Obviously this was not an exhaustive overview about cross and I encourage you to have a look at the GitHub page
if you are interested.</p>

<h2 id="cross-in-github-actions">Cross in GitHub actions</h2>

<p>Of course, after a whole morning getting mad trying to setup weird ubuntu dependencies for the delta issue,
when I found out about cross I felt very stupid for not knowing it in advance and I tried to integrate it in the
Continuous Deployment delta pipeline.</p>

<p>It turns out that this is like the easiest thing in the world! The <a href="https://github.com/actions-rs/cargo">action-rs/cargo</a> action
I was already using had built-in <a href="https://github.com/actions-rs/cargo#cross-compilation">support</a> for cross.
Now I even felt more stupid, but anyway..you just need to set the <code>use-cross</code> variable to <code>true</code> and you are done!</p>

<p><a href="https://github.com/dandavison/delta/blob/e198c0d841d9fb660e59e0329235a8601b407c69/.github/workflows/cd.yml#L32-L37">This</a>
is the step that builds the whole delta project for all its different targets..easy, right? 😀</p>

<h2 id="cross-in-rust-github-template">Cross in Rust GitHub template</h2>

<p>You may or (probably) may not be aware of <a href="https://rust-github.github.io/">Rust GitHub Template</a>.</p>

<blockquote>
<p>Rust GitHub Template is a template for cargo generate that aims to be a starting point suitable for the vast majority of rust projects that will be hosted on GitHub.</p>
</blockquote>

<p>Beyond all its nice goodies, this template will setup Continuous Deployment for you, therefore whenever
you tag your project, it will be published on <code>crates.io</code> and the binaries will be released in the GitHub Releases page,
just like in delta. 😁</p>

<p>Until today, Rust GitHub template only supported x86_64 windows, linux and mac, but after I found out Cross I couldn’t resist
and I added support for i686 and aarch64 linux architectures, which are both two <a href="https://doc.rust-lang.org/nightly/rustc/platform-support.html">tier 1</a> rust targets.
In practice, this means your “old thinkpad” and “raspberry pi” users will thank you a lot. 😛</p>

<p><img src="https://www.marcoieni.com/2020/12/rust-makes-cross-compilation-childs-play/rust-gh.png" alt="gh template releases" title="Releases"></p>

<p><a href="https://github.com/rust-github/rust-gh-example/blob/01e0aae91f83e1e932f4498a0eddb2905c8fffc3/.github/workflows/cd.yml#L57-L63">This</a>
is an example of the resulting Continuous Deployment step.</p>

<p>And that was it, after I spent a lot of <em>very useful</em> time trying to setup compilation dependencies basically I just wanted to share my love for the <code>cross</code>
tool with the rest of the world in order to avoid this pain to as many people as possible. 😅</p>

<p>Thanks for reading this far! You can find me on <a href="https://twitter.com/MarcoIeni">twitter</a> or <a href="https://www.youtube.com/MarcoIeni">YouTube</a>, bye! 👋</p>

  </div></div>]]>
            </description>
            <link>https://www.marcoieni.com/2020/12/rust-makes-cross-compilation-childs-play/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25323560</guid>
            <pubDate>Sun, 06 Dec 2020 14:11:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Self-Driving Cars with Duckietown: Learning Autonomy on the Jetson Nano]]>
            </title>
            <description>
<![CDATA[
Score 20 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25323435">thread link</a>) | @ArtWomb
<br/>
December 6, 2020 | https://www.duckietown.org/mooc | <a href="https://web.archive.org/web/*/https://www.duckietown.org/mooc">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<section data-id="1b90ddb2" data-settings="{&quot;stretch_section&quot;:&quot;section-stretched&quot;}" data-element_type="section">

</section>
<section data-id="5f45efba" data-settings="{&quot;stretch_section&quot;:&quot;section-stretched&quot;,&quot;background_background&quot;:&quot;classic&quot;}" data-element_type="section">
<div>
<div>
<div data-id="44184fe1" data-element_type="column">
<div>
<div>
<div data-id="56f50bc1" data-element_type="heading.default">
<div>
<h2>The Duckietown Massive Online Open Course</h2>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</section>
<section data-id="7257d191" data-settings="{&quot;stretch_section&quot;:&quot;section-stretched&quot;}" data-element_type="section">
<div>
<div>
<div data-id="3f17e26e" data-element_type="column">
<div>
<div>
<section data-id="5f5f08f5" data-element_type="section">
<div>
<div>
<div data-id="2a891138" data-element_type="column">
<div>
<div>
<div data-id="6e068eec" data-element_type="text-editor.default">
<div>
<div>
<p>The Duckietown Foundation presents the first <b>hardware based massive online open course (MOOC) in AI and robotics: “Self-driving cars with Duckietown”</b>, free on edX.</p>
<p>Learn autonomy hands-on by making real robots take their own decisions and accomplish broadly defined tasks. Step by step from the theory, to the implementation, to the deployment in simulation as well as on Duckiebots.</p>
<p>Leverage the power of the new NVIDIA’s Jetson Nano powered Duckiebot to see your algorithms come to life!</p>
</div></div>
</div>
</div>
</div>
</div>

</div>
</div>
</section></div>
</div>
</div>
</div>
</div>
</section>
<section data-id="6430b354" data-settings="{&quot;stretch_section&quot;:&quot;section-stretched&quot;}" data-element_type="section">
<div>
<div>
<div data-id="30390fb8" data-element_type="column">
<div>
<div>
<section data-id="26e3c22d" data-element_type="section">
<div>
<div>
<div data-id="47641e95" data-element_type="column">
<div>
<div>

<div data-id="3a9d956c" data-element_type="icon-list.default">
<div>
<ul>
<li>
											<span><br>
							<br>
						</span><br>
										<span>Name: Self-driving cars with Duckietown</span>
									</li>
<li>
											<span><br>
							<br>
						</span><br>
										<span>Start: February 2021</span>
									</li>
<li>
					<a href="https://www.edx.org/course/self-driving-cars-with-duckietown">						<span><br>
							<br>
						</span><br>
										<span>Platform: edX</span><br>
											</a>
									</li>
<li>
											<span><br>
							<br>
						</span><br>
										<span>Cost: free to attend</span>
									</li>
<li>
											<span><br>
							<br>
						</span><br>
										<span>Instructors:<br>
Swiss Federal Institute of Technology in Zurich (ETHZ),<br>
Université de Montréal (UdM),<br>
Toyota Technological Institute at Chicago (TTIC)</span>
									</li>
</ul></div>
</div>
</div>
</div>
</div>
</div>
</div>
</section></div>
</div>
</div>
<div data-id="4b76852" data-element_type="column">
<div>
<div>
<section data-id="585e3d9" data-element_type="section">
<div>
<div>
<div data-id="a83ae57" data-element_type="column">
<div>
<div>

<div data-id="7a50f136" data-element_type="icon-list.default">
<div>
<ul>
<li>
											<span><br>
							<br>
						</span><br>
										<span>Basic Linux, Python, Git</span>
									</li>
<li>
											<span><br>
							<br>
						</span><br>
										<span>Elements of linear algebra, probability, calculus</span>
									</li>
<li>
											<span><br>
							<br>
						</span><br>
										<span>Elements of kinematics, dynamics</span>
									</li>
<li>
											<span><br>
							<br>
						</span><br>
										<span>Computer with native Ubuntu installation</span>
									</li>
</ul></div>
</div>
</div>
</div>
</div>
</div>
</div>
</section></div>
</div>
</div>
<div data-id="70e2b69" data-element_type="column">
<div>
<div>
<section data-id="75a50f3" data-element_type="section">

</section>
<div data-id="e239b41" data-element_type="icon-list.default">
<div>
<ul>
<li>
											<span><br>
							<br>
						</span><br>
										<span>Computer Vision</span>
									</li>
<li>
											<span><br>
							<br>
						</span><br>
										<span>Robot operations</span>
									</li>
<li>
											<span><br>
							<br>
						</span><br>
										<span>Object Detection</span>
									</li>
<li>
											<span><br>
							<br>
						</span><br>
										<span>Onboard localization</span>
									</li>
<li>
											<span><br>
							<br>
						</span><br>
										<span>Robot Control</span>
									</li>
<li>
											<span><br>
							<br>
						</span><br>
										<span>Planning</span>
									</li>
<li>
											<span><br>
							<br>
						</span><br>
										<span>Reinforcement Learning</span>
									</li>
</ul></div>
</div>
</div>
</div>
</div>
</div>
</div>
</section>
<section data-id="6b005adf" data-settings="{&quot;stretch_section&quot;:&quot;section-stretched&quot;,&quot;background_background&quot;:&quot;classic&quot;}" data-element_type="section">

</section>
<section data-id="1b3409a" data-element_type="section">
<div>
<div>
<div data-id="660d899" data-element_type="column">
<div>
<div>
<div data-id="3f7c8d3" data-settings="{&quot;speed&quot;:750,&quot;slides_per_view&quot;:&quot;1&quot;,&quot;show_arrows&quot;:&quot;yes&quot;,&quot;pagination&quot;:&quot;bullets&quot;,&quot;autoplay&quot;:&quot;yes&quot;,&quot;autoplay_speed&quot;:5000,&quot;loop&quot;:&quot;yes&quot;,&quot;pause_on_interaction&quot;:&quot;yes&quot;,&quot;space_between&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;size&quot;:10},&quot;space_between_tablet&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;size&quot;:10},&quot;space_between_mobile&quot;:{&quot;unit&quot;:&quot;px&quot;,&quot;size&quot;:10}}" data-element_type="testimonial-carousel.default">
<div>
<div>
<div>
<div>
<div>
<div>
<div>
<p>
						“I’m thrilled that ETH, with UMontreal, the Duckietown Foundation, and the Toyota Technological Institute in Chicago, are collaborating to bring this course in self-driving cars and robotics to the 35 million learners on edX. This emerging technology has the potential to completely change the way we live and travel, and the course provides a unique opportunity to get in on the ground floor of understanding and using the technology powering autonomous vehicles.”					</p>
</div>
<div>
<p><img src="https://www.duckietown.org/wp-content/uploads/2020/10/anant-1.jpeg" alt="Anant Agarwal">
					</p>
<p>								<cite><span>Anant Agarwal</span><span>Founder and CEO of edX,  Professor at the Massachussetts Institute of Technology (MIT)​</span></cite>			</p></div>
</div>
</div>
<div>
<div>
<div>
<p>
						“The new NVIDIA Jetson Nano 2GB is the ultimate starter AI computer for educators and students to teach and learn AI at an incredibly affordable price. Duckietown and its EdX MOOC are leveraging Jetson to take hands-on experimentation and understanding of AI and autonomous machines to the next level.”					</p>
</div>
<div>
<p><img src="https://www.duckietown.org/wp-content/uploads/2020/10/talla.jpeg" alt="Deepu Talla">
					</p>
<p>								<cite><span>Deepu Talla</span><span>Vice President and General Manager of Edge Computing at NVIDIA</span></cite>			</p></div>
</div>
</div>
<div>
<div>
<div>
<p>
						“The Duckietown educational platform provides a hands-on, scaled down, accessible version of real world autonomous systems. Integrating NVIDIA’s Jetson Nano power in Duckietown enables unprecedented access to state-of-the-art compute solutions for learning autonomy.”					</p>
</div>
<div>
<p><img src="https://www.duckietown.org/wp-content/uploads/2020/10/emilio-2-1.jpeg" alt="Emilio Frazzoli">
					</p>
<p>								<cite><span>Emilio Frazzoli</span><span>Professor at the Swiss Federal Institute of Technology in Zurich (ETHZ)​</span></cite>			</p></div>
</div>
</div>
</div>



</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</section>
<section data-id="5da441a" data-settings="{&quot;stretch_section&quot;:&quot;section-stretched&quot;}" data-element_type="section">

</section>
<section data-id="d824e20" data-settings="{&quot;stretch_section&quot;:&quot;section-stretched&quot;}" data-element_type="section">

</section>
<section data-id="3632c2b8" data-settings="{&quot;stretch_section&quot;:&quot;section-stretched&quot;}" data-element_type="section">
<div>
<div>
<div data-id="79390ce6" data-element_type="column">
<div>
<div>
<div data-id="6be6d720" data-element_type="image.default">
<div>
<p><img width="480" height="259" src="https://www.duckietown.org/wp-content/uploads/2020/10/ezgif.com-gif-maker-1-1-1-2.gif" alt="">											</p>
</div>
</div>
<div data-id="30b88b59" data-element_type="text-editor.default">
<div>
<p><b>Robot Perception</b>: Duckiebots detect lane marking on the fly and use mathematical models of their camera and environment to estimate their position and orientation in the lane.&nbsp;</p></div>
</div>
</div>
</div>
</div>
<div data-id="41466e10" data-element_type="column">
<div>
<div>
<div data-id="3b538f06" data-element_type="image.default">
<div>
<p><img width="480" height="259" src="https://www.duckietown.org/wp-content/uploads/2020/10/duckietown_duckiebot_detection-4712_cropped-1-2.gif" alt="">											</p>
</div>
</div>
<div data-id="6d1ade5e" data-element_type="text-editor.default">
<div>
<p><strong>Duckiebot Detection</strong>: driving in Duckietown is fun but safety should always be paramount. DuckieBots can detect other vehicles and estimate their relative poses to avoid collisions.</p></div>
</div>
</div>
</div>
</div>
</div>
</div>
</section>
<section data-id="5a0d068c" data-settings="{&quot;stretch_section&quot;:&quot;section-stretched&quot;}" data-element_type="section">

</section>
<section data-id="6d62786b" data-settings="{&quot;stretch_section&quot;:&quot;section-stretched&quot;}" data-element_type="section">
<div>
<div>
<div data-id="4bed0569" data-element_type="column">
<div>
<div>
<div data-id="897e1e0" data-element_type="image.default">
<div>
<p><img width="600" height="338" src="https://www.duckietown.org/wp-content/uploads/2020/10/planning-smaller-1-2.gif" alt="">											</p>
</div>
</div>
<div data-id="77a7938e" data-element_type="text-editor.default">
<div>
<p><strong>Robot Planning</strong>: as Duckietowns grow bigger, smart Duckiebots plan their path in town. Traffic signs at intersections provide landmarks to localize on the global map and determine next turns.</p></div>
</div>
</div>
</div>
</div>
<div data-id="6a7565d5" data-element_type="column">
<div>
<div>
<div data-id="4587f56f" data-element_type="image.default">
<div>
<p><img width="600" height="338" src="https://www.duckietown.org/wp-content/uploads/2020/10/ezgif.com-gif-maker-1-2-2.gif" alt="">											</p>
</div>
</div>
<div data-id="6869aae7" data-element_type="text-editor.default">
<div>
<p><b>Pedestrian detection</b>: there are many obstacles in Duckietown – some move and some don’t. Being able to detect pedestrians (duckies) is important to guarantee safe driving.</p></div>
</div>
</div>
</div>
</div>
</div>
</div>
</section>
<section data-id="03ac2c5" data-settings="{&quot;stretch_section&quot;:&quot;section-stretched&quot;}" data-element_type="section">
<div>
<div>
<div data-id="cfaabf3" data-element_type="column">
<div>
<div>
<div data-id="1ab4146" data-element_type="image.default">
<div>
<p><img width="300" height="250" src="https://www.duckietown.org/wp-content/uploads/2020/10/NVIDIA_Logo_V_ForScreen_ForLightBG-300x250.png" alt="" srcset="https://www.duckietown.org/wp-content/uploads/2020/10/NVIDIA_Logo_V_ForScreen_ForLightBG-300x250.png 300w, https://www.duckietown.org/wp-content/uploads/2020/10/NVIDIA_Logo_V_ForScreen_ForLightBG-160x133.png 160w, https://www.duckietown.org/wp-content/uploads/2020/10/NVIDIA_Logo_V_ForScreen_ForLightBG-768x641.png 768w, https://www.duckietown.org/wp-content/uploads/2020/10/NVIDIA_Logo_V_ForScreen_ForLightBG-1024x854.png 1024w" sizes="(max-width: 300px) 100vw, 300px">											</p>
</div>
</div>
</div>
</div>
</div>
<div data-id="e250367" data-element_type="column">
<div>
<div>
<div data-id="1fb98e7" data-element_type="image.default">
<div>
<p><img width="200" height="83" src="https://www.duckietown.org/wp-content/uploads/2020/10/edx-logo-registered-1.png" alt="" srcset="https://www.duckietown.org/wp-content/uploads/2020/10/edx-logo-registered-1.png 200w, https://www.duckietown.org/wp-content/uploads/2020/10/edx-logo-registered-1-160x66.png 160w" sizes="(max-width: 200px) 100vw, 200px">											</p>
</div>
</div>
</div>
</div>
</div>
</div>
</div>
</section></div></div>]]>
            </description>
            <link>https://www.duckietown.org/mooc</link>
            <guid isPermaLink="false">hacker-news-small-sites-25323435</guid>
            <pubDate>Sun, 06 Dec 2020 13:49:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Time Management Strategies: A Compendium of 58 Effective Techniques and Methods]]>
            </title>
            <description>
<![CDATA[
Score 19 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25323248">thread link</a>) | @Geeflow
<br/>
December 6, 2020 | https://www.focalityapp.com/en/resources/time-management-strategies/ | <a href="https://web.archive.org/web/*/https://www.focalityapp.com/en/resources/time-management-strategies/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
				<div>
					<div>
						<div>
							<div>

								<!-- ![Goal Setting Questions](/assets/img/goal-setting-questions.jpg) -->
<!-- # Goal Setting Questions:<br> Discover, Prioritize and Refine Goal Ideas -->

<h2>A Compendium of 58 Effective Strategies, Techniques and Methods</h2>
<p><img src="https://www.focalityapp.com/assets/img/mood/glenn-carstens-peters-RLw-UC03Gwc-unsplash.1920.jpg" alt="Time Management Strategies"></p>
<p>Managing your own time is an essential skill in today’s fast-paced world. It's also more challenging than ever. Fortunately, there are many <strong>time management strategies that can help you become organized and efficient</strong>. Use this overview of 58 strategies and techniques to find the ones that work best for you.</p>
<!-- It’s hard to keep track of all the time management strategies out there. Productivity gurus tend to create their own, building on the massive fundus of existing strategies. So to get you ready for the next time someone mentions their favorite but obscure time management technique, here is an exhaustive overview of more than 50 strategies. -->
<h2>Deep Planning</h2>
<!-- <img src="/assets/img/funktionsgrafik-play-store-2019-10-18.jpg" alt="Plan, Reflect, Improve"/> -->
<!-- <img src="/assets/img/values-finder-banner.jpg" alt="Plan, Reflect, Improve" style="max-width: 100%"/> -->
<p><a href="https://www.focalityapp.com/en/time-management-app/"><img src="https://www.focalityapp.com/assets/img/plan-reflect-improve-banner.jpg" alt="Time Management App"></a></p>
<!-- Did we just complain about everybody creating their own time management strategy? Well, obviously it’s all right if we do it, isn’t it? :) -->
<p>Most plans are strictly sequential. When you invariably have to adjust your plan to reality, you have to update the whole lengthy sequence. Time-consuming at best, motivation consuming at worst. With deep planning, you create a simple hierarchy instead.</p>
<p>Think about what you want to achieve this year. Based on that, what do you want to achieve this month? This week? Today? This way you create a long-term strategy and still adjust your plans with little effort.</p>
<!-- At the end of each period, take a step back and reflect. What went well? What not? What can I do differently next time? -->
<p>Curious? Then take a look at <a href="https://www.focalityapp.com/en/time-management-app/">Focality, our time management app</a>. Focality combines deep planning, self-reflection and data-driven insights to let you constantly improve your time management skills.</p>
<h2>The complete list of time management strategies</h2>
<p>Without further ado, here comes the complete list of time management techniques in alphabetic order:</p>
<h3>1-3-5 rule</h3>
<p>For every day, create a list of one big thing, three medium things and five small things that you want to accomplish this day. This brings clarity into your workday and helps not to get buried by an endless flood of to-do items.</p>
<h3>2-Hour Solution</h3>
<p>See Two-Hour Solution.</p>
<h3>2-Minute Rule</h3>
<p>There are two 2-Minute Rules:</p>
<ol>
<li>
<p>If you want to establish a new habit, make sure that it requires no more than 2 minutes in the beginning. Work yourself up from there.</p>
</li>
<li>
<p>In the Getting Things Done methodology (see below), if a task takes only 2 minutes or less, then do it right away instead of organizing it.</p>
</li>
</ol>
<h3>10-Minute Rule</h3>
<p>If you are putting something off, force yourself to do it for just 10 minutes. Chances are that you will continue past the 10 minutes.</p>
<h3>18 Minutes</h3>
<p>Start your day by planning what you will do that day for 5 minutes. Every hour, take one minute, review your progress and refocus. At the end of the day, take 5 minutes to reflect and evaluate your day.</p>
<h3>4Ds of Time Management</h3>
<p>This method helps you to quickly decide what to do with a task. Either Do it, Defer it, Delegate it or Drop it.</p>
<h3>7 Minute Life</h3>
<p>Spend 7 minutes in the morning to plan your day. Then another 7 minutes in the evening to reflect. Accompanied by many <a href="https://the7minutelife.com/member-tools/">templates</a>.</p>
<h3>80/20 Rule</h3>
<p>The 80/20 rule, also known as the Pareto Principle, is a rule of thumb that states that 80% of the effect step from 20% of the causes. Applied to time management it means that you can get 80% of the results with just 20% of the work. Getting to 100% will require disproportionately more work. Perfect is the enemy of done.</p>
<h3>90-Minute Rule / 90-Minute Focus Sessions / 90-Minute Solution</h3>
<p>Align your work with your <a href="https://en.wikipedia.org/wiki/Basic_rest%E2%80%93activity_cycle">basic rest–activity cycle</a> by doing focused work for approximately 90 minutes, followed by a 20-minute break. The following article sums it up nicely: <a href="https://medium.com/better-humans/avoid-burnout-and-increase-awareness-using-ultradian-rhythms-5e64158e7e19">Avoid Burnout and Increase Awareness Using Ultradian Rhythms</a></p>
<h3>ABCDE Method</h3>
<p>Created by Brian Tracy, ABCDE is a method for setting priorities. Basically assign each task a priority from A to E. A: Very important, must do. B: Important, should do. C: Nice to do, without consequence if skipped. D: Delegate. E: Eliminate.</p>
<h3>Action Method</h3>
<p>Leave every meeting, workshop or other event with a set of concrete tasks that need to be performed, called “action steps”. These should be kept separately from accompanying information (“reference items”). Everything that can’t / shouldn’t be approached right now becomes a “backburner item” to be possibly revived later. The method was developed by Behance. There used to be an online tool that implemented the action method, but it  was discontinued in 2015.</p>
<h3>Agile Results</h3>
<p>The <a href="http://jdmeier.com/agile-results-on-a-page/">Agile Results</a> technique is heavily inspired by software development frameworks like Scrum. At the beginning of the week, identify three wins that you want to achieve. Each day, identify three wins for that day. Use Fridays to recognize three things that are going well and three things to improve. Accompanied by a set of further practices to improve your time management like 30 day improvement sprints, reference collections and more.</p>
<h3>Autofocus</h3>
<p><a href="http://markforster.squarespace.com/autofocus-system/">Autofocus</a> is a to-do list methodology by Mark Forster which tries to use as little structure as possible. Dump everything in a ruled notebook. Scan your list and work on what stands out for as long as you feel like it. Then cross the item off the list. If you haven’t finished it, add it to the bottom again. Repeat. If you pass through a whole page (except the latest page) without anything standing out, dismiss all items on that page.</p>
<h3>Batching / Time Batching / Task Batching</h3>
<p>Work on batches of similar tasks instead of mixing unrelated ones. It reduces friction by minimizing context switching.</p>
<h3>Biological Prime Time</h3>
<p>Track your energy levels and identify your most energetic times of the day. Schedule your most important work for those times. First described by Sam Carpenter in his book <a href="https://www.goodreads.com/book/show/6019060-work-the-system">Work the System</a>.</p>
<h3>Bullet Journal</h3>
<p>A bullet journal combines to-do list, planning and journaling. The name bullet journal comes from the extensive use of bullet(ish) points to structure and mark information.</p>
<h3>COPE</h3>
<p>The Clear-Organized-Productive-Efficient technique helps you to eliminate low-value activities and prioritize everything so that you can focus on the things with the most impact.</p>
<h3>Don’t break the chain</h3>
<p>See Seinfeld Strategy.</p>
<h3>Eat That Frog</h3>
<p>Tackle the biggest and/or most difficult and/or most disliked task first thing in the morning. Then you won’t waste energy or distract yourself the rest of the day because you are secretly dreading that task. <a href="https://www.briantracy.com/blog/time-management/the-truth-about-frogs/">Eat That Frog</a> was created by Brian Tracy who named it after a quote by Mark Twain: “Eat a live frog first thing in the morning and nothing worse will happen to you the rest of the day.”</p>
<h3>Eisenhower Matrix / Box / Method / Principle</h3>
<p>Former U.S. president Dwight D. Eisenhower used to rate his problems by the two criteria urgency and importance. These criteria are commonly used as axis on a 2x2 matrix with 4 quadrants:</p>
<ol>
<li>Urgent and important</li>
<li>Not urgent and important</li>
<li>Urgent but not important</li>
<li>Not urgent and not important</li>
</ol>
<p>The Eisenhower Matrix helps you to better prioritize your tasks and avoid the urgency trap where you fill your day with everything that’s urgent and neglecting the important.</p>
<h3>Final Version</h3>
<p>Start with a list of tasks. Select the first one on the list. Think about which other task from the list you would rather do. Select that one but remember/mark the first. Repeat until you no longer want to do anything before the currently selected task. Then work on the tasks in this chain - but in reverse order! Once you are done with the chain start the process again with the next open task on the list. Reference: <a href="http://archive.constantcontact.com/fs004/1100358239599/archive/1109511856508.html">The Final Version newsletter</a></p>
<h3>Flowtime Technique</h3>
<p>Work on only one task at a time. When you start, write down the time. Continue working on the task until you feel that you need a break. If you are exhausted or can’t focus anymore, take a break. Write down the stop time. Decide how long this break should be and set a timer for it. Repeat.</p>
<h3>Fresh or Fried</h3>
<p>At the end of the day, when your brain is fried, prioritize your tasks for the next day. Schedule important tasks to the beginning of the day, when your brain is still fresh. Schedule less important or easier tasks towards the later parts of the day when your brain fries again.</p>
<p>Reference: <a href="https://thefyslife.com/article/fresh-or-fried-productivity/">Dominate Your Day With the “Fresh or Fried” Prioritization System</a></p>
<h3>Getting Things Done (GTD)</h3>
<p>Getting Things Done is a famous method created by David Allen. It makes extensive use of to-do lists and techniques to manage them. At its core it employs five basic activities to bring structure to your task management:</p>
<ol>
<li>Capture everything: Don’t keep tasks in your head, write everything down.</li>
<li>Clarify: Make sure all your items are clear and actionable.</li>
<li>Organize: Use categories, priorities and due dates to bring structure to your lists.</li>
<li>Review: Frequently go over your lists. Update priorities, remove outdated items, etc.</li>
<li>Engage: Do it.</li>
</ol>
<h3><a href="https://www.focalityapp.com/en/resources/goal-setting/">Goal Setting</a></h3>
<p>Goal setting is the process of defining what you want to achieve in the long-term (or mid-term). Instead of focusing just on tasks, it helps you getting direction in life. If you don’t have clear goals, you are basically adrift. And you hardly get to where you want to be by accident.</p>
<p>We have compiled an <a href="https://www.focalityapp.com/en/resources/goal-setting/">extensive guide to personal goal setting</a> which will help you to understand the topic in depth. Learn why it is important, what types of goals to set, attributes of well-defined goals and much, much more.</p>
<h3>Inbox Zero</h3>
<p>This strategy focuses on managing your email inbox with maximum efficiency. According to its creator, Merlin Mann, the name Inbox Zero does not refer to the number of emails in your inbox, but “how long it takes to use the inbox”. Basically, you run every incoming email through a short process in which you do one of the following things: Delete, delegate, respond, defer (to do later), do (immediately).</p>
<h3>Ivy Lee Method</h3>
<p>This time management strategy has been created in 1918 by productivity consultant Ivy Lee. He recommends writing down six tasks at the end of each day that you want to accomplish the next day. Order them by importance. Then, on the next day, work your way down the list. At the end of the day, move any uncompleted task to the list for the next day. Repeat.</p>
<h3>Medium Method</h3>
<p>Combine the strengths of digital and paper tools. Chad Hall’s <a href="https://todoist.com/productivity-methods/medium-method">Medium Method</a> employs paper notebooks, post-it notes, a task-management app, an online calendar and a note app.</p>
<h3>MIT: Most Important Tasks</h3>
<p>Write down the most important tasks for the next day. Up to three. At the beginning of the day, focus on those and do nothing else until your MITs are completed.</p>
<h3>MoSCow Prioritization</h3>
<p>Borrowed from requirements management this technique helps you prioritize your tasks. Give each task a priority of …</p></div></div></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.focalityapp.com/en/resources/time-management-strategies/">https://www.focalityapp.com/en/resources/time-management-strategies/</a></em></p>]]>
            </description>
            <link>https://www.focalityapp.com/en/resources/time-management-strategies/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25323248</guid>
            <pubDate>Sun, 06 Dec 2020 13:03:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Whirlwind Tour of Stack (Haskell Build Tool) for Beginners]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25323081">thread link</a>) | @schooloffp
<br/>
December 6, 2020 | https://schooloffp.co/2020/12/05/whirlwind-tour-of-stack-for-beginners.html | <a href="https://web.archive.org/web/*/https://schooloffp.co/2020/12/05/whirlwind-tour-of-stack-for-beginners.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
    <p>In this post, we will take a look at <a href="https://www.haskellstack.org/"><code>stack</code></a>. It is the 3rd in a series of posts about getting started with Haskell. The first post looked into the basics of <a href="https://schooloffp.co/2020/07/25/setting-up-haskell-development-environment-the-basics.html">Setting Up Haskell Development Environment</a>, while the second post was an introduction to <a href="https://schooloffp.co/2020/08/17/whirlwind-tour-of-cabal-for-beginners.html">Cabal for beginners</a>. This post presents <code>stack</code> which is an alternate build tool to <code>cabal-install</code>.</p>

<p>This post contains the following sections:</p>

<ul>
  <li><a href="#clarifying-terms">Clarifying Terms</a></li>
  <li><a href="#what-stack-is">What Stack is</a></li>
  <li><a href="#moving-parts">Moving Parts</a></li>
  <li><a href="#installing-stack">Installing Stack</a></li>
  <li><a href="#creating-a-new-project">Creating a new project</a></li>
  <li><a href="#configuring-stack">Configuring Stack</a></li>
  <li><a href="#building-and-running-executables">Building and running executables</a></li>
  <li><a href="#adding-dependencies">Adding dependencies</a></li>
  <li><a href="#having-a-project-with-both-library-and-executable">Having a project with both library and executable</a></li>
  <li><a href="#configuring-visibility-of-modules-in-a-library">Configuring visibility of modules in a library</a></li>
  <li><a href="#using-different-ghc-compiler-across-different-projects">Using different GHC compiler across different projects</a></li>
  <li><a href="#using-the-repl">Using the REPL</a></li>
  <li><a href="#how-to-execute-a-haskell-file-as-a-script">How to execute a Haskell file as a script</a></li>
  <li><a href="#how-to-install-packages">How to install packages</a></li>
  <li><a href="#some-interesting-stack-paths">Some interesting Stack paths</a></li>
</ul>

<!--end_excerpt-->

<blockquote>
  <p>This post is going to be a quick tour of the essential aspects of <code>stack</code> targeted at beginners. It will not only list commands that should be executed but would try to provide contextual explanations as much as possible. The aim is to give an introduction to <code>stack</code> that is not filled with commands to be memorized but one that can help the beginner to start forming a better understanding of <code>stack</code> so they can explore the tool further on their own.</p>
</blockquote>

<h2 id="clarifying-terms">Clarifying terms</h2>

<p>It is important to have an understanding of some basic terms and concepts when it comes to working and building Haskell programs. This includes understanding what is meant when we say things like <em>Cabal</em>, the difference between <em>Modules, Libraries, Packages</em>, etc. These terms were already explained in the previous post, so instead of reproducing it again here, please take a moment to read the <a href="https://schooloffp.co/2020/08/17/whirlwind-tour-of-cabal-for-beginners.html#clarifying-terms">Clarifying Terms section</a> in the Whirlwind Tour Of Cabal For Beginners post.</p>

<p>One thing to point out regarding the concepts of packages and projects is that <code>stack</code> provides configuration for projects via a file called <code>stack.yaml</code>, while packages are configured via either <code>package.yaml</code> file or <code>.cabal</code> file. These files are covered in more depth in <a href="#creating-a-new-project">Creating a new project</a> section.</p>

<h2 id="what-stack-is">What Stack is</h2>

<p><code>stack</code> is a build tool for Haskell. It is an alternative to <code>cabal-install</code>, but still makes use of cabal the package format and Cabal the library. It has a strong focus on reproducible build plans. It was conceived to solve dependency problems (commonly referred to as cabal hell) that used to plague <code>cabal-install</code>. It does this by providing a curated package set that is guaranteed to always compile.</p>

<blockquote>
  <p>It should be stressed that the cabal hell issue that used to plague cabal-install has mostly been resolved. The solution took a different approach than what <code>stack</code> employed. It made use of an approach similar to what is obtained in Nix. The details of this are not important, just that using either <code>cabal-install</code> or <code>stack</code>is now a matter of preference and UX choices.</p>
</blockquote>

<h2 id="moving-parts">Moving parts</h2>

<p><code>stack</code> also comes with some moving parts and terms that could be confusing to a beginner. In this section, these terms are explained before moving to how to install <code>stack</code>.</p>

<h3 id="curated-package-set">Curated Package Set</h3>

<p>Hackage is Haskell’s central package archive of open-source software. Anyone can upload (and also download) packages from Hackage hence it contains different versions of packages that are not guaranteed to be compatible. A curated package set is then a subset of packages from Hackage which are regularly tested for compatibility. <code>stack</code> makes use of the idea of a curated package set to resolve the problem of incompatible dependencies.</p>

<h3 id="stackage">Stackage</h3>

<p><a href="https://www.stackage.org/">Stackage</a> is the central package archive of open-source software of Haskell packages <strong>that have been curated and tested for compatibility</strong>. Hence the curated package set used by <code>stack</code> is hosted on Stackage. Stackage is spearheaded by folks at <a href="http://www.fpcomplete.com/">fpcomplete</a>, but is still a community effort, hence anyone can also <a href="https://github.com/commercialhaskell/stackage/blob/master/MAINTAINERS.md#adding-a-package">submit packages</a> for inclusion in the curated package set that is hosted on Stackage.</p>

<h3 id="resolver">Resolver</h3>

<p>It is easy to imagine the need for versioning when working with these curated package sets hosted on Stackage. Where a particular version uniquely identifies a particular curated package set and the packages it contains. In <code>stack</code>, the version of a curated package set is referred to or specified as a <em>resolver</em>.</p>

<p>A resolver uniquely identifies the GHC version and the other Haskell packages contained within a package set. Package sets that have been thoroughly tested and would be maintained for a long period are identified by LTS (long term support) resolver version numbers, while package sets that are still in flux are identified by nightly resolvers. The available LTS resolvers can be found <a href="https://www.stackage.org/lts">here</a> while nightly resolvers can be seen <a href="https://www.stackage.org/nightly">here</a>. For example <a href="https://www.stackage.org/lts-16.22">lts-16.22</a>, is a LTS Resolver, while <a href="https://www.stackage.org/nightly-2020-11-19">nightly-2020-11-19</a> is a nightly Resolver.</p>

<blockquote>
  <p>Based on its name, it might be tempting to think of resolver as a piece of software that performs the act of resolution. A better way is to see the resolver as an identifier or a tag. It is a way to refer to a particular curated package set.</p>
</blockquote>

<h3 id="hpack">hpack</h3>

<p>As explained in <a href="https://schooloffp.co/2020/08/17/whirlwind-tour-of-cabal-for-beginners.html#clarifying-terms">Clarifying Terms section</a> Haskell makes use of cabal package format, a text-based, key-value format used to describe a Haskell package. <code>hpack</code> is an alternate format to cabal package format. Instead of a custom key-value text-based format, it makes use of <a href="https://yaml.org/"><code>yaml</code></a>.</p>

<p>So while the cabal package format uses a custom key-value text-based format specified in a file ending with <code>.cabal</code> extension, <code>hpack</code> uses <code>yaml</code> with package descriptions specified in <code>package.yaml</code> file. <code>stack</code>has inbuilt support for <code>hpack</code>. This means <code>stack</code>can parse <code>hpack</code>s’ <code>package.yaml</code> and use it to generate <code>.cabal</code> file.</p>

<p>In summary, you can view <code>stack</code>as a Haskell build tool, that makes use of curated package sets, identified by resolvers and hosted on Stackage, with inbuilt support for <code>hpack</code> as an alternative package specification format.</p>

<h2 id="installing-stack">Installing Stack</h2>

<p>Installing <code>stack</code>is straight forward. On Un*x operating systems, run:</p>

<div><div><pre><code>curl <span>-sSL</span> https://get.haskellstack.org/ | sh
</code></pre></div></div>

<p>On windows, the provided <a href="https://get.haskellstack.org/stable/windows-x86_64-installer.exe">Windows Installer</a> can be used</p>

<p>To confirm <code>stack</code>is properly installed run <code>stack --version</code> which will give an output similar to this:</p>

<div><div><pre><code><span>$ </span>stack <span>--version</span>
Version 2.3.3, Git revision cb44d51bed48b723a5deb08c3348c0b3ccfc437e x86_64 hpack-0.33.0
</code></pre></div></div>

<blockquote>
  <p>Note that you do not need to install GHC separately when using <code>stack</code>. <code>stack</code>handles getting the version of GHC needed for each project created. This is also one of the ways in which <code>stack</code>differs from <code>cabal-install</code> which requires GHC to be separately downloaded and installed. So <code>stack</code>not only takes care of resolving dependencies, compiling Haskell code, it also handles the management of the toolchain required to do this, and GHC is included in the toolchain.</p>
</blockquote>

<h2 id="creating-a-new-project">Creating a new project</h2>

<p>Now we have <code>stack</code>installed, the next thing to do is to create a new Haskell project. Doing this is straightforward. To create a new project, run <code>stack new</code>.</p>

<p>Doing so will produce an output similar to this:</p>

<div><div><pre><code><span>$ </span>stack new firstproject
Downloading template <span>"new-template"</span> to create project <span>"firstproject"</span> <span>in </span>firstproject/ ...

The following parameters were needed by the template but not provided: author-name
You can provide them <span>in</span> /Users/schooloffp/.stack/config.yaml, like this:
templates:
  params:
    author-name: value
Or you can pass each one as parameters like this:
stack new firstproject new-template <span>-p</span> <span>"author-name:value"</span>

The following parameters were needed by the template but not provided: author-email, author-name, category, copyright, github-username
You can provide them <span>in</span> /Users/schooloffp/.stack/config.yaml, like this:
templates:
  params:
    author-email: value
    author-name: value
    category: value
    copyright: value
    github-username: value
Or you can pass each one as parameters like this:
stack new firstproject new-template <span>-p</span> <span>"author-email:value"</span> <span>-p</span> <span>"author-name:value"</span> <span>-p</span> <span>"category:value"</span> <span>-p</span> <span>"copyright:value"</span> <span>-p</span> <span>"github-username:value"</span>

Looking <span>for</span> .cabal or package.yaml files to use to init the project.
Using cabal packages:
- firstproject/

Selecting the best among 18 snapshots...

<span>*</span> Matches lts-16.22

Selected resolver: lts-16.22
Initialising configuration using resolver: lts-16.22
Total number of user packages considered: 1
Writing configuration to file: firstproject/stack.yaml
All <span>done</span><span>.</span>
/Users/schooloffp/.stack/templates/new-template.hsfiles:    3.72 KiB downloaded...
</code></pre></div></div>

<p>The above command will create a directory named <code>firstproject</code> with will contain the source files for the project.</p>

<blockquote>
  <p>The above command creates a project based on a default template which dictates the default files and configuration that will be created. It should be noted that it is possible to pass an extra option together with <code>new</code> that specifies the template that <code>stack</code>should use to create a new project. When the template option is left out, <code>stack</code>uses the <code>new-template</code> template by default. Hence <code>stack new firstproject</code> is same as running <code>stack new firstproject new-template</code>. Run <code>stack templates</code> to see the available templates.</p>
</blockquote>

<p>The state of the directory after running <code>stack new firstproject</code> can be seen:</p>

<div><div><pre><code><span>$ </span>tree firstproject/
firstproject/
├── ChangeLog.md
├── LICENSE
├── README.md
├── Setup.hs
├── app
│   └── Main.hs
├── firstproject.cabal
├── package.yaml
├── src
│   └── Lib.hs
├── stack.yaml
└── <span>test</span>
    └── Spec.hs
</code></pre></div></div>
<p>Let’s take a pause to talk about the files generated after running the <code>stack new</code> command.</p>

<h3 id="changelogmd">ChangeLog.md</h3>

<p>As is evident in the name, this is a markdown file that should be used to capture the revision history for the project.</p>

<h3 id="license">LICENSE</h3>

<p>This is where the license governing the project is specified, as also evident in the name.</p>

<h3 id="readmemd">README.md</h3>

<p>The well-known README file.</p>

<h3 id="setuphs">Setup.hs</h3>
<p>The <code>Setup.hs</code> file comes in handy in the scenario where one needs to circumvent tools like <code>cabal-install</code> or <code>stack</code>for direct usage of the Cabal library when compiling Cabal packages. The <code>Setup.hs</code> is, in essence, a runnable Haskell program that can be further configured and used to compile Cabal packages.</p>

<p>This is an exceptional use case. Everyday Haskell development would …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://schooloffp.co/2020/12/05/whirlwind-tour-of-stack-for-beginners.html">https://schooloffp.co/2020/12/05/whirlwind-tour-of-stack-for-beginners.html</a></em></p>]]>
            </description>
            <link>https://schooloffp.co/2020/12/05/whirlwind-tour-of-stack-for-beginners.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25323081</guid>
            <pubDate>Sun, 06 Dec 2020 12:28:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Blue Light: Beware the Ways It'll Damage Your Sleep]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25322893">thread link</a>) | @scottbucks
<br/>
December 6, 2020 | https://www.thedetechtor.com/post/blue-light-beware-the-ways-it-ll-damage-your-sleep | <a href="https://web.archive.org/web/*/https://www.thedetechtor.com/post/blue-light-beware-the-ways-it-ll-damage-your-sleep">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-hook="post-description"><article><div><div data-rce-version="8.6.5"><div dir="ltr"><div><div id="viewer-4mcbu"><div><div data-hook="imageViewer" role="button" tabindex="0"><div role="img"><p><img data-pin-url="https://www.thedetechtor.com/post/blue-light-beware-the-ways-it-ll-damage-your-sleep" data-pin-media="https://static.wixstatic.com/media/f361a8_76dde261ab224670b4073408cdcaa804~mv2.png/v1/fit/w_1000%2Ch_1000%2Cal_c%2Cq_80/file.png" src="https://static.wixstatic.com/media/f361a8_76dde261ab224670b4073408cdcaa804~mv2.png/v1/fit/w_300,h_300,al_c,q_5/file.png"></p></div></div></div></div><p id="viewer-6tpvk"><span>For a while now, there's been a debate on whether or not Blue Light has a negative impact on your sleep. In this article, I'll be discussing some of the studies that have covered this subject along with some of the solutions to reduce the amount of blue light you're being subjected to.</span></p><h2 id="viewer-cpun"><span>What is Blue Light?</span></h2><p id="viewer-bj5bp"><span>Sunlight is composed of red, yellow, orange, green, and blue light rays and many shades of each of these colours, depending on the energy and wavelength of the individual rays (otherwise known as <!-- -->electromagnetic radiation<!-- -->). Combined, this spectrum of coloured light rays creates sunlight called “white light”.</span></p><p id="viewer-bc2fl"><span>Without getting into the details, there is an inverse relationship between the wavelength of light rays and the amount of energy they contain.</span></p><p id="viewer-825iu"><span>This means that the rays on the red end of the visible light spectrum have longer wavelengths and, therefore, less energy. On the other hand, rays on the blue end of the spectrum have shorter wavelengths and more energy.</span></p><p id="viewer-15gnj"><span>Not all colours of light have the same effect. Blue wavelengths are beneficial during daylight hours because they boost your mood, attention and reaction times, however, studies suggest they're more disruptive at night.</span></p><h2 id="viewer-65vu6"><span>What exposes you to Blue Light?</span></h2><p id="viewer-bi01v"><span>Although sunlight is the biggest source of Blue Light that you'll be subjected too, here are some of the others:</span></p><ul><li id="viewer-cugnd"><p>LED light</p></li><li id="viewer-di5pk"><p>Fluorescent light</p></li><li id="viewer-ads93"><p>Flat-screen LED televisions</p></li><li id="viewer-7b2ak"><p>Computer monitors</p></li><li id="viewer-ep37g"><p>Smartphones and tablet screens</p></li></ul><p id="viewer-5valn"><span>Although you receive a lot less Blue Light from these sources than from the sun, it's the fact that we tend to use them more and more before going to bed that is of concern.</span></p><h3 id="viewer-qt2o"><span><strong><span>Suggested Articles:</span></strong></span></h3><ul><li id="viewer-apq6a"><p><strong>🚄 </strong><a href="https://www.thedetechtor.com/post/hyperloop-the-future-of-travel" target="_blank" rel="noopener"><strong><u>Hyperloop, the future of travel?</u></strong></a><strong>
</strong>
</p></li><li id="viewer-f07kd"><p><strong>⌚️ </strong><a href="https://www.thedetechtor.com/post/fitness-trackers-helping-us-get-fit-or-just-another-gadget" target="_blank" rel="noopener"><strong><u>Fitness Trackers: Helping us Get Fit or Just Another Gadget?</u></strong></a><strong>
</strong>
</p></li><li id="viewer-acds1"><p><a href="https://www.thedetechtor.com/post/how-can-we-reduce-our-screen-time" target="_blank" rel="noopener"><strong>📱 <u>How can we reduce our screen time?</u></strong><u>
</u></a>
</p></li></ul><h2 id="viewer-2t17p"><span>Blue Light and your sleep</span></h2><p id="viewer-2nnnh"><span>For a while now people have debated whether or not Blue Light can directly impact your sleep. <!-- -->We all have an approximately 24-hour internal clock that is known as a circadian rhythm, which is what helps our bodies determine when we feel tired and when we feel awake. </span></p><div id="viewer-2d39m"><div><div data-hook="imageViewer" role="button" tabindex="0"><div role="img"><p><img data-pin-url="https://www.thedetechtor.com/post/blue-light-beware-the-ways-it-ll-damage-your-sleep" data-pin-media="https://static.wixstatic.com/media/f361a8_abee6cf1fc244c8f92a371474018e5e1~mv2.jpg/v1/fit/w_1000%2Ch_1000%2Cal_c%2Cq_80/file.png" src="https://static.wixstatic.com/media/f361a8_abee6cf1fc244c8f92a371474018e5e1~mv2.jpg/v1/fit/w_300,h_300,al_c,q_5/file.jpg"></p></div></div></div></div><p id="viewer-23l8i"><span>This rhythm is automatically regulated thanks to natural light and darkness, however, studies show that Blue Light can affect our circadian rhythm by delaying the release of melatonin, the sleep-inducing hormone.</span></p><p id="viewer-5umnl"><span>This study published in the <a href="https://journals.physiology.org/doi/full/10.1152/japplphysiol.00165.2011" target="_blank" rel="noopener"><u>Journal of Applied Physiology</u></a> suggests that the Blue L<!-- -->ight emitted by computer screens has an impact on circadian physiology, alertness, and cognitive performance levels. </span></p><blockquote id="viewer-6q11o"><span><span>"A 5-h evening exposure to a white LED-backlit screen with more than twice as much 464 nm light (Blue Light) emission than a white non-LED-backlit screen elicited a significant suppression of the evening rise in endogenous melatonin"</span></span></blockquote><p id="viewer-dv3mt"><span>This means that using any type of computer screen, smartphone, tablet or television that emits Blue Light before going to bed will affect your sleep. </span></p><p id="viewer-3p9bt"><span><a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3786545/" target="_blank" rel="noopener"><u>Another study</u></a> from the University of Toronto also concluded that Blue Light could slow down the production of melatonin. During the study, some participants were instructed to wear special glasses that blocked blue light wavelengths whilst the rest didn't. The results showed that the people in the study that wore these glasses produced more melatonin than those who didn’t and hence, had a better night's sleep.</span></p><p id="viewer-8nqqi"><span>These studies do seem pretty conclusive, however since then others have said otherwise.</span></p><p id="viewer-8kim"><span>In 2019, a group of researchers at the University of Manchester in the U.K. <a href="https://www.cell.com/current-biology/fulltext/S0960-9822(19)31368-5" target="_blank" rel="noopener"><u>challenged that notion</u></a>. After exposing mice to lights that were different in hue but equal brightness and assessing their subsequent activity, the researchers concluded that yellow light actually seems to disturb sleep more than blue. Warm-toned light, they hypothesized, could trick the body into thinking it’s daytime, while cooler blue light more closely mimics twilight.</span></p><p id="viewer-7o6g0"><span>It is important to note however, that animals studies don't always reflect the entire reality, as they often can't translate directly to human behavior. Furthermore, since rodents are nocturnal, they may respond differently to light than humans do. Finally the lights were also kept very dim, regardless of color, which may not property represent the bright lights of electronics.</span></p><p id="viewer-b6bbs"><span>Because of these conditions, the results of the study can't be taken too seriously, given how many previous ones have concluded that Blue Light has a negative impact on sleep.</span></p><h3 id="viewer-2fn3f"><span>How to minimise the effects </span></h3><p id="viewer-ctu4b"><span>If you're worried that Blue Light might be affecting your sleep, here are a few solutions:</span></p><ol><li id="viewer-fljja"><p>First of all, try and <a href="https://www.thedetechtor.com/post/how-can-we-reduce-our-screen-time" target="_blank" rel="noopener"><u>cut down on your screen time</u></a>. By doing this you'll be subjecting your eyes to less Blue Light from being on your computer or smartphone. <a href="https://www.thedetechtor.com/post/how-can-we-reduce-our-screen-time" target="_blank" rel="noopener"><u>Here's an article</u></a> I wrote to help reduce screen time and stay active.</p></li><li id="viewer-9htd6"><p>Try not to look at your devices just before bed. Consider turning off your phone a few hours before bed to avoid letting Blue Light affect your sleep.</p></li><li id="viewer-fo8o1"><p>Consider buying Blue Light filtering glasses, they're widely available and can help to reduce Blue Light if you need to use your devices a lot during the day.</p></li><li id="viewer-aps00"><p>Blue Light screen protectors are also available to buy. If you think you'll forget to wear your glasses then blue light screen protectors can be a useful alternative seeing as you only need to apply it once.</p></li><li id="viewer-fnvc5"><p>Use different lights: LED light bulbs in your house can also emit blue light, so instead of using bright white lights, you could try switching to dimmer red lights closer to bedtime so you are exposed to less blue light.</p></li></ol><h3 id="viewer-82ggv"><span>The bottom line</span></h3><p id="viewer-1fhfe"><span>The bottom line is that most studies conclude that too much Blue Light, especially in the evening, can have a negative impact on your sleep. How much it affects us is up for debate, everybody may not notice the same effects but it definitely can't hurt to try and minimise the amount of blue light we're be subjected too, whether it's from generally <a href="https://www.thedetechtor.com/post/how-can-we-reduce-our-screen-time" target="_blank" rel="noopener"><u>reducing our screen time</u></a> or thanks go a pair of dedicated Blue Light glasses.</span></p><h3 id="viewer-1kir8"><span><strong><span>More from The Detechtor:</span></strong></span></h3><ul><li id="viewer-fdnuu"><p><strong>🚄 </strong><a href="https://www.thedetechtor.com/post/hyperloop-the-future-of-travel" target="_blank" rel="noopener"><strong><u>Hyperloop, the future of travel?</u></strong></a><strong>
</strong>
</p></li><li id="viewer-drmot"><p><strong>⌚️ </strong><a href="https://www.thedetechtor.com/post/fitness-trackers-helping-us-get-fit-or-just-another-gadget" target="_blank" rel="noopener"><strong><u>Fitness Trackers: Helping us Get Fit or Just Another Gadget?</u></strong></a><strong>
</strong>
</p></li><li id="viewer-bqciv"><p><a href="https://www.thedetechtor.com/post/how-can-we-reduce-our-screen-time" target="_blank" rel="noopener"><strong>📱 <u>How can we reduce our screen time?</u></strong><u>
</u></a>
</p></li></ul><h3 id="viewer-aksjo"><span><span>Stay updated:</span></span></h3><ul><li id="viewer-c0ngu"><p>📩 Want the latest on the impact of tech? <strong>Subscribe</strong> to our <strong>newsletter</strong>!</p></li><li id="viewer-2q79s"><p>🎙 <strong>NEW</strong>! <a href="http://thedetechtor.com/" target="_blank" rel="noopener"><strong><u>The Detechtor Podcast</u></strong></a> is now available on all podcast players!                                 <strong>Subscribe</strong> on <a href="https://podcasts.apple.com/fr/podcast/the-detechtor-podcast/id1537457578?l=en" target="_blank" rel="noopener"><strong><u>Apple Podcasts</u></strong></a><strong> | </strong><a href="https://open.spotify.com/show/5kc8WA6nZC69bQ1sbOrlNi?si=CwAuAtpfRpe7WmLu1PlO8w" target="_blank" rel="noopener"><strong><u>Spotify</u></strong></a><strong> | </strong><a href="https://podcasts.google.com/search/The%20detechtor%20Podcast" target="_blank" rel="noopener"><strong><u>Google Podcasts</u></strong></a><strong> | </strong><a href="https://www.stitcher.com/show/the-detechtor-podcast" target="_blank" rel="noopener"><strong><u>Stitcher</u></strong></a><strong> | </strong><a href="https://tunein.com/podcasts/Technology-Podcasts/The-Detechtor-Podcast-p1377296/?topicid=158813573" target="_blank" rel="noopener"><strong><u>Tunein</u></strong></a></p></li><li id="viewer-bb30g"><p>📲 Let's connect! <strong>Follow</strong> <strong>us</strong> on <a href="https://twitter.com/the_detechtor" target="_blank" rel="noopener"><strong><u>Twitter</u></strong></a><strong> | </strong><a href="https://www.instagram.com/thedetechtor/" target="_blank" rel="noopener"><strong><u>Instagram</u></strong></a><strong> | </strong><a href="https://www.facebook.com/thedetechtor" target="_blank" rel="noopener"><strong><u>Facebook</u></strong></a><strong> | </strong><a href="https://www.youtube.com/channel/UCAW--4_mML4A86W3670ix3w" target="_blank" rel="noopener"><strong><u>Youtube</u></strong></a></p></li></ul></div></div></div></div></article></div></div>]]>
            </description>
            <link>https://www.thedetechtor.com/post/blue-light-beware-the-ways-it-ll-damage-your-sleep</link>
            <guid isPermaLink="false">hacker-news-small-sites-25322893</guid>
            <pubDate>Sun, 06 Dec 2020 11:44:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Is the preprocessor still needed in C++? (2017)]]>
            </title>
            <description>
<![CDATA[
Score 42 | Comments 59 (<a href="https://news.ycombinator.com/item?id=25322891">thread link</a>) | @appehuli
<br/>
December 6, 2020 | https://foonathan.net/2017/05/preprocessor/ | <a href="https://web.archive.org/web/*/https://foonathan.net/2017/05/preprocessor/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">

<article>
<header>

<section>


</section>
</header>
<a id="content"></a>
<p>The C++, eh C, preprocessor is wonderful.</p>
<p>Well, no - it isn’t wonderful.</p>
<p>It is a primitive text replacement tool that must be used to work with C++.
But is “must” really true?
Most of the usage has become obsolete thanks to new and better C++ language features.
And many more features like modules will come soon™.
So can we get rid of the preprocessor?
And if so, how can we do it?</p>
<a id="more"></a>
<p>Much of the preprocessor use is already bad practice:
Don’t use it for symbolic constants, don’t use it for inline functions etc.</p>
<blockquote>
<p>As this gained a lot of traction, let me clarify something:
I’m not advocating for removing the preprocessor with this post.
Some people in the C++ community and many on the standardization committee want to do that, however,
so I wanted to explore the feasibility.</p>
</blockquote>
<p>But there still a few ways it is used in idiomatic C++.
Let’s go through them and see what alternative we have.</p>

<p>Let’s start with the most common usage:
<code>#include</code> a header file.</p>
<h3 id="why-is-the-preprocessor-needed">Why is the preprocessor needed?</h3>
<p>In order to compile a source file, the compiler needs to see the declarations of all functions that are being called.
So if you define a function in one file,
and want to call it in another, you have to declare it in that file as well.
Only then can the compiler generate the appropriate code to call the function.</p>
<p>Of course, manually copying the declaration can lead to errors:
If you change the signature you have to change all declarations as well.
So, instead of manually copying the declarations,
you write them in a special file - the header file,
and let the preprocessor copy it for you with <code>#include</code>.
Now you still need to update all declarations, but just in one place.</p>
<p>But plain text inclusion is dumb.
It can sometimes happens that the same file gets included twice,
which leads to two copies of that file.
This is no problem for function declarations,
but if you have class definitions in an header file,
that’s an error.</p>
<p>To prevent that, you have to use include guards or the non-standard <code>#pragma once</code>.</p>
<h2 id="how-can-we-replace-it">How can we replace it?</h2>
<p>With current C++ features, we can’t (without resorting to copy pasta).</p>
<p>But with the <a href="http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2017/n4647.pdf">Modules TS</a> we can.
Instead of providing header files and source files,
we can write a module and <code>import</code> that.</p>
<p>If you want to learn more about modules, I highly recommend the <a href="https://www.youtube.com/watch?v=Wjvh127abfw">most recent CppChat</a>.</p>
<h2 id="conditional-compilation">Conditional Compilation</h2>
<p>The second most common job of the preprocessor is conditional compilation:
Change the definitions/declarations by defining or not defining a macro.</p>
<h3 id="why-is-the-preprocessor-needed-1">Why is the preprocessor needed?</h3>
<p>Consider the situation where you’re writing a library that provides a function <code>draw_triangle()</code>
which draws a single triangle on the screen.</p>
<p>Now the declaration is straightforward:</p>
<div><pre><code data-lang="cpp"><span>// draws a single triangle
</span><span></span><span>void</span> <span>draw_triangle</span><span>();</span>
</code></pre></div><p>But the implementation of the function changes depending on your operating system, window manager, display manager
and/or moon phase (for exotic window manager).</p>
<p>So you need something like this:</p>
<div><pre><code data-lang="cpp"><span>// use this one for Windows
</span><span></span><span>void</span> <span>draw_triangle</span><span>()</span>
<span>{</span>
    <span>// create window using the WinAPI 
</span><span></span>    <span>// draw triangle using DirectX
</span><span></span><span>}</span>

<span>// use this one for Linux
</span><span></span><span>void</span> <span>draw_triangle</span><span>()</span>
<span>{</span>
    <span>// create window using X11
</span><span></span>    <span>// draw triangle using OpenGL
</span><span></span><span>}</span>
</code></pre></div><p>The preprocessor helps there:</p>
<div><pre><code data-lang="cpp"><span>#if _WIN32
</span><span></span>    <span>// Windows triangle drawing code here 
</span><span></span><span>#else
</span><span></span>    <span>// Linux triangle drawing code here
</span><span></span><span>#endif
</span></code></pre></div><p>The code in the branch that is not taken will be deleted before compilation,
so we won’t get any errors about missing APIs etc.</p>
<h3 id="how-can-we-replace-it-1">How can we replace it?</h3>
<p>C++17 adds <code>if constexpr</code>, this can be used to replace simple <code>#if … #else</code>:</p>
<p>Instead of this:</p>
<div><pre><code data-lang="cpp"><span>void</span> <span>do_sth</span><span>()</span>
<span>{</span>
    <span>#if DEBUG_MODE
</span><span></span>        <span>log</span><span>();</span>
    <span>#endif
</span><span></span>    <span>…</span>
<span>}</span>
</code></pre></div><p>We can write this:</p>
<div><pre><code data-lang="cpp"><span>void</span> <span>do_sth</span><span>()</span>
<span>{</span>
    <span>if</span> <span>constexpr</span> <span>(</span><span>DEBUG_MODE</span><span>)</span>
    <span>{</span>
        <span>log</span><span>();</span>
    <span>}</span>

    <span>…</span>
<span>}</span>
</code></pre></div><p>If <code>DEBUG_MODE</code> is <code>false</code>, then the branch will not be compiled properly,
it will only check for syntax errors, similar to the checking done for a not yet instantiated template.</p>
<blockquote>
<p>This is not correct, as was pointed out.
It will still be fully checked if outside a template.
It doesn’t matter here though, as it still doesn’t have any runtime overhead.</p>
</blockquote>
<p>This is even better than <code>#if</code> as it will spot obvious errors in the code without checking all macro combinations.
Another benefit with <code>if constexpr</code> is that <code>DEBUG_MODE</code> can now be a normal <code>constexpr</code> variable,
instead of a constant coming from a macro expansion.</p>
<blockquote>
<p>And if you don’t have <code>if constexpr</code>, you can use class template specializations,
or <a href="https://foonathan.net/blog/2015/11/16/overload-resolution-3.html">tag dispatching</a>.</p>
</blockquote>
<p>Of course, there are downsides to <code>if constexpr</code>:
You can’t use it to constrain preprocessor directives, i.e. <code>#include</code>.
For the <code>draw_triangle()</code> example, the code needs to include the proper system header.
<code>if constexpr</code> can help, so you’d need true conditional compilation there or manually copy the declarations.</p>
<blockquote>
<p>This is better than normally as system header declarations are usually pretty stable.
But it’s still not recommended.</p>
</blockquote>
<p>And modules can’t help either as the system headers do not define any module you can import.
Furthermore, you can’t conditionally import a module (as far as I know).</p>
<h2 id="passing-configuration-options">Passing configuration options</h2>
<p>On a related note, you sometimes want to pass some configuration options to a library.
You might want to enable or disable assertions, precondition checks, change some default behavior…</p>
<p>For example, it might have a header like this:</p>
<div><pre><code data-lang="cpp"><span>#ifndef USE_ASSERTIONS
</span><span></span>    <span>// default to enable
</span><span></span>    <span>#define USE_ASSERTIONS 1
</span><span>#endif
</span><span></span>
<span>#ifndef DEFAULT_FOO_IMPLEMENTATION
</span><span></span>    <span>// use the general implementation
</span><span></span>    <span>#define DEFAULT_FOO_IMPLEMENTATION general_foo
</span><span>#endif
</span><span></span>
<span>…</span>
</code></pre></div><p>When building the library you can then override the macros either when invoking the compiler,
or through CMake, for example.</p>
<h3 id="how-can-we-replace-it-2">How can we replace it?</h3>
<p>Macros are the obvious choice here, but there are is an alternative:</p>
<p>We could use a different strategy to pass options,
like <a href="https://en.wikipedia.org/wiki/Policy-based_design">policy-based design</a>,
where you pass a policy to a class template that defines the chosen behavior.
This has the benefit that it doesn’t force a single implementation to all users,
but of course has <a href="https://foonathan.net/blog/2017/02/08/policy-based-design-problem.html">its own downsides</a>.</p>
<p>But what I’d really like to see is the ability to pass these configuration options when you <code>import</code> the module:</p>
<div><pre><code data-lang="cpp"><span>import</span> <span>my</span><span>.</span><span>module</span><span>(</span><span>use_assertions</span> <span>=</span> <span>false</span><span>);</span>
<span>…</span>
</code></pre></div><p>This would be the ideal replacement for:</p>
<div><pre><code data-lang="cpp"><span>#define USE_ASSERTIONS 0
</span><span>#include</span> <span>"my_library.hpp"</span><span>
</span></code></pre></div><p>But I don’t think that’s technically feasible without sacrificing the benefits modules provide,
i.e. pre-compiling modules.</p>
<h2 id="assertion-macros">Assertion macros</h2>
<p>The macro you’ll most commonly use probably does some kind of assertion.
And macros are the obvious choice here:</p>
<ul>
<li>You’ll need to conditionally disable assertions and remove them so they have zero overhead in release.</li>
<li>If you have a macro, you can use the pre-defined <code>__LINE__</code>, <code>__FILE__</code> and <code>__func__</code> to get the location where the assertion is
and use that in the diagnostic.</li>
<li>If you have a macro, you can also stringify the expression that is being checked and use it in the diagnostic as well.</li>
</ul>
<p>That’s why almost all assertions are macros.</p>
<h3 id="how-can-we-replace-it-3">How can we replace it?</h3>
<p>I’ve already explored how conditional compilation can be replaced and how you can specify whether or not they should be enabled,
so that’s no problem.</p>
<blockquote>
<p>Using policy-based design here also allows customization of how the diagnostic is reported to the user.</p>
</blockquote>
<p>Getting the file information is also possible in the Library Fundamentals TS v2 as it adds <code>std::experimental::source_location</code>:</p>
<div><pre><code data-lang="cpp"><span>void</span> <span>my_assertion</span><span>(</span><span>bool</span> <span>expr</span><span>,</span> <span>std</span><span>::</span><span>experimental</span><span>::</span><span>source_location</span> <span>loc</span> <span>=</span> <span>std</span><span>::</span><span>experimental</span><span>::</span><span>source_location</span><span>::</span><span>current</span><span>())</span>
<span>{</span>
    <span>if</span> <span>(</span><span>!</span><span>expr</span><span>)</span>
        <span>report_error</span><span>(</span><span>loc</span><span>.</span><span>file_name</span><span>,</span> <span>loc</span><span>.</span><span>line</span><span>,</span> <span>loc</span><span>.</span><span>function_name</span><span>);</span>
<span>}</span>
</code></pre></div><p>The function <code>std::experimental::source_location::current()</code> expands to the information about the source file at the point of writing it.
Furthermore, if you use it as a default argument, it will expand to the caller location.
So the second point is no problem either.</p>
<p>The third point is the critical one:
You can’t stringify the expression and print it in the diagnostic without using a macro.
If you’re okay with that, you can implement your assertion function today.</p>
<p>But otherwise you still need a macro for that.
Check out <a href="https://foonathan.net/blog/2016/09/16/assertions.html">this blog post</a> how you could implement an (almost) macro-less assertion function,
where you can control the level with <code>constexpr</code> variables instead of macros.
You can find the full implementation <a href="https://github.com/foonathan/debug_assert">here</a>.</p>
<h2 id="compatibility-macros">Compatibility macros</h2>
<p>Not all compilers support all C++ features, which makes porting a real pain,
especially if you don’t have access to a compiler for a testing and need to do the “change a line, push to CI, wait for CI build, change another line” cycle just because some compiler really doesn’t like an important C++ feature!</p>
<p>Anyways, the usual compatibility problems can be solved with macros.
The implementations even define certain macros once they’ve implemented a feature,
making checking trivial:</p>
<div><pre><code data-lang="cpp"><span>#if __cpp_noexcept
</span><span></span>    <span>#define NOEXCEPT noexcept
</span><span></span>    <span>#define NOEXCEPT_COND(Cond) noexcept(Cond)
</span><span></span>    <span>#define NOEXCEPT_OP(Expr) noexcept(Expr)
</span><span>#else
</span><span></span>    <span>#define NOEXCEPT
</span><span></span>    <span>#define NOEXCEPT_COND(Cond)
</span><span></span>    <span>#define NOEXCEPT_OP(Expr) false
</span><span>#endif
</span><span></span>
<span>…</span>

<span>void</span> <span>func</span><span>()</span> <span>NOEXCEPT</span>
<span>{</span>
    <span>…</span>
<span>}</span>
</code></pre></div><p>This allows a portable usage of features even though not all compilers have them already.</p>
<h2 id="how-can-we-replace-it-4">How can we replace it?</h2>
<p>We can’t do that in any other way.
Workaround missing features requires some kind of preprocessing tool to get rid of not-supported features.
We have to use macros here.</p>
<h2 id="boilerplate-macros">Boilerplate macros</h2>
<p>C++’s templates and TMP go a long way to eliminate a lot of boilerplate code you otherwise need to write.
But sometimes, you just need to write a lot of code that is the same but not <em>quite</em> the same:</p>
<div><pre><code data-lang="cpp"><span>struct</span> <span>less</span>
<span>{</span>
    <span>bool</span> <span>operator</span><span>()(</span><span>const</span> <span>foo</span><span>&amp;</span> <span>a</span><span>,</span> <span>const</span> <span>foo</span><span>&amp;</span> <span>b</span><span>)</span>
    <span>{</span>
        <span>return</span> <span>a</span><span>.</span><span>bar</span> <span>&lt;</span> <span>b</span><span>.</span><span>bar</span><span>;</span>
    <span>}</span>
<span>};</span>

<span>struct</span> <span>greater</span>
<span>{</span>
    <span>bool</span> <span>operator</span><span>()(</span><span>const</span> <span>foo</span><span>&amp;</span> <span>a</span><span>,</span> <span>const</span> <span>foo</span><span>&amp;</span> <span>b</span><span>)</span>
    <span>{</span>
        <span>return</span> <span>a</span><span>.</span><span>bar</span> <span>&gt;</span> <span>b</span><span>.</span><span>bar</span><span>;</span>
    <span>}</span>
<span>};</span>

<span>…</span>
</code></pre></div><p>Macros can generate that boilerplate for you:</p>
<div><pre><code data-lang="cpp"><span>#define MAKE_COMP(Name, Op) \
</span><span>struct Name \
</span><span>{ \
</span><span>    bool operator()(const foo&amp; a, const foo&amp; b) \
</span><span>    { \
</span><span>        return a.bar Op b.bar; \
</span><span>    } \
</span><span>};
</span><span></span>
<span>MAKE_COMP</span><span>(</span><span>less</span><span>,</span> <span>&lt;</span><span>)</span>
<span>M…</span></code></pre></div></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://foonathan.net/2017/05/preprocessor/">https://foonathan.net/2017/05/preprocessor/</a></em></p>]]>
            </description>
            <link>https://foonathan.net/2017/05/preprocessor/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25322891</guid>
            <pubDate>Sun, 06 Dec 2020 11:44:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Doom on Pico-8]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25322744">thread link</a>) | @homarp
<br/>
December 6, 2020 | https://freds72.itch.io/poom | <a href="https://web.archive.org/web/*/https://freds72.itch.io/poom">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Mars base, Union Aerospace Corporation experiments opened a portal to Hell. You appear to be the last human, fight your way out!</p>
<blockquote>Beaming up the virtual feed from Mars takes about 20s, be patient while loading the battle simulator soldier.<br><em>If experiencing slowdowns, prefer desktop browser or beefy mobile.</em></blockquote>
<h2>How to Play</h2>
<blockquote><strong>click on game to enable mouse support</strong></blockquote>
<p>Recommended controls: P2 keys + mouse<br></p>
<p>Second best controls: control scheme 2</p>
<p><img src="https://img.itch.zone/aW1nLzQ2NTIzNjEucG5n/original/frSHG1.png"></p>

<blockquote>mobile menu controls: use left paddle to navigate, use up/down from right paddle to cancel/selec</blockquote>
<p><img src="https://img.itch.zone/aW1nLzQ2NTIzNjMucG5n/original/ZR8g8y.png"></p>
<p>From title screen, use pause menu [P] to switch between control schemes.&nbsp;</p>
<p><img src="https://img.itch.zone/aW1nLzQ3MzYxMzkucG5n/original/6SO90E.png">
</p>
<h2>Release Notes</h2>
<p>Version 1.0:</p>
<ul><li>HTML player with mouse lock support</li><li>Windows binaries with mouse lock support (new upcoming PICO8 feature)</li></ul>
<blockquote>Mac OS&nbsp;X + linux binaries + standalone versions will be provided later</blockquote>
<h2>Credits</h2>
<p>Original levels + art + sfx by&nbsp;<a href="https://paranoidcactus.itch.io/">@gamecactus</a></p><p>Zep for PICO-8 and support (and sneaky versions!)<br></p>
<p>ID Software for producing such a timeless game</p>
<p><a href="https://zdoom.org/wiki/Main_Page" rel="nofollow noopener">ZDoom Wiki</a>&nbsp;for their fantastic compendium of everything DOOM</p>
<p>LZS compression by&nbsp;James Bowman (<a href="https://www.excamera.com/sphinx/article-compression.html" rel="nofollow noopener">https://www.excamera.com/sphinx/article-compression.html</a>)<br></p>
<p>Beta testing &amp; gameplay feedback by&nbsp;Tom Hall &amp; Jusiv&nbsp; (&amp; my kids!)</p></div></div>]]>
            </description>
            <link>https://freds72.itch.io/poom</link>
            <guid isPermaLink="false">hacker-news-small-sites-25322744</guid>
            <pubDate>Sun, 06 Dec 2020 11:14:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Protect Your .env]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25322721">thread link</a>) | @bbotond
<br/>
December 6, 2020 | https://tatooine-sunset.botond.online/2020-12-06-protect-your-dotenv/ | <a href="https://web.archive.org/web/*/https://tatooine-sunset.botond.online/2020-12-06-protect-your-dotenv/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            



<p>This blog has been online for about 10 hours. To put it more harshly: I’m a
nobody on the internet. Yet, when I generated my first visitor report with
<a href="https://goaccess.io/">goaccess</a>, I saw that the bot army has already started
attacking my server. A lot of suspicious-looking URLs have been requested:</p>

<ul>
  <li><code>/config/getuser?index=0</code></li>
  <li><code>/vendor/phpunit/phpunit/src/Util/PHP/eval-stdin.php</code></li>
  <li><code>/api/jsonws/invoke</code></li>
  <li><code>/solr/admin/info/system?wt=json</code></li>
  <li><code>/index.php?s=/Index/\x5Cthink\x5Capp/invokefunction</code>
<code>&amp;function=call_user_func_array&amp;vars[0]=md5&amp;vars[1][]=HelloThinkPHP21</code></li>
  <li><code>/console/</code></li>
  <li><code>/wp-content/plugins/wp-file-manager/readme.txt</code></li>
  <li><code>/Autodiscover/Autodiscover.xml</code></li>
  <li><code>/vendor/phpunit/phpunit/src/Util/PHP/eval-stdin.php</code></li>
</ul>

<p>This is just a small sample but it is obvious that they are trying to exploit
known vulnerabilities. These are absolutely harmless because this is a static
website but there was one request that caught my attention:</p>



<p>My static site doesn’t have a <code>.env</code> file but I work on a lot of projects that
have one. I of course know that exposing the <code>.env</code> file is a mistake – it
usually contains passwords, keys and other sensitive information and in a
production environment, these should be in environment variables – but it is
very scary to see that this is <em>among the first things</em> hackers try – because
it’s so easy to accidentally copy it into a public directory.</p>

<p>So please, everyone: <strong>protect your <code>.env</code>!</strong></p>





        </div></div>]]>
            </description>
            <link>https://tatooine-sunset.botond.online/2020-12-06-protect-your-dotenv/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25322721</guid>
            <pubDate>Sun, 06 Dec 2020 11:06:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why Programming Is Hard to Fundamentally Improve (2017)]]>
            </title>
            <description>
<![CDATA[
Score 58 | Comments 33 (<a href="https://news.ycombinator.com/item?id=25322656">thread link</a>) | @mpweiher
<br/>
December 6, 2020 | https://aidancunniffe.com/why-programming-is-hard-to-fundamentally-improve-4101612d4ad9 | <a href="https://web.archive.org/web/*/https://aidancunniffe.com/why-programming-is-hard-to-fundamentally-improve-4101612d4ad9">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><section><div><div><div><div><div><div><p><a href="https://medium.com/@aidandcunniffe?source=post_page-----4101612d4ad9--------------------------------" rel="noopener"><img alt="Aidan Cunniffe" src="https://miro.medium.com/fit/c/96/96/1*26JtOGzXJBiOCbDzaKjrWg.jpeg" width="48" height="48"></a></p></div></div></div></div><p id="cb76"><em>and why I’m still trying…</em></p><p id="5880">One of the curious things about being human is the ability to hold two contradictory views simultaneously. When I’m in analysis mode I try to understand what market, technical and social forces have lead to the status quo. To do this effectively, or at least to induce useful principles for later use, you have to believe that things are the way they are for good reasons. As soon as I put my innovator hat on however, I get all jazzed up and think “screw that! X would be so much better if Y”. I’ve learned over the last year that balancing these two perspectives is essential to an inventor.</p><p id="9c7d">This week I watched Bret Victor’s <a href="http://worrydream.com/dbx/" rel="noopener">Future of Programming</a> lecture from July 2013 and it compelled me to put these thoughts down on paper. During the lecture, Bret uses an overhead projector and pretends its 1973. He proudly presents the latest in programming research for the time and explains why it’d be really silly if we aren’t using them in 40 years. To Victor’s credit he remains in character the whole time as he satirically paints the ideal world we’ll soon enter — one the audience knows doesn’t really exist.</p><p id="cbac">The future Bret showed off included direct manipulations of the output (result) instead of the code, programming via constraints/goals, spatial (visual) programming paradigms, and massively parallel programming approaches. Declarative programming, functional programming, microservice architectures and WYSIWYG editors check some of those boxes, but not nearly at the level of their potential. All that being said, there’s no argument against real progress having been made the last 40 years, just not the progress many expected.</p><p id="f16a">So now I’ll put on my analysis hat and work through why the art of programming is so hard to advance beyond its current levels.</p><p id="a3f1">Many blame the lack of advancements on developers. We built shinny thing X, but developers are too arrogant, stubborn, busy, dismissive or all of the above to adopt it. I’ve even heard people accuse developers of selfishly protecting their future job prospects by trying to stifle the adoption of new programming mediums. Heck, I’ve said this before…</p><p id="f628">^ This is just wrong. In my experience developers are very rational beings. Their job is to find the most efficient way of solving problems every single day and if you create a tool that provides that they’ll be all over it. They’ll even volunteer their time to help you build it for free. If you move forward accepting that developers are mostly rational actors and have good reasons for adopting something / not adopting something you can learn a lot to inform future design.</p><p id="33a0">So I did that. I actually sat down with people over the last 3 months and asked them why they failed to adopt a variety of tools. I overwhelmingly got rational explanations to why switching to something new was irrational.</p><h2 id="99cb">Better Hammer Tradeoff</h2><p id="8f1e">Imagine you’re building a log cabin by hand with a bad, but usable hammer. When you’re 90% of the way finished a magical genie comes and offers you a better hammer. Great! But there’s a tradeoff: If you take the new shinny hammer, you have to start the house from scratch…oh and he turns back humanity to the stone age. You can get your new hammer, but you’ll have to do without bandsaws, your pickup truck, and yes, nails.</p><p id="3e8b">What’s the rational choice? Hint, it involves the old hammer.</p><p id="7f24">That parable emerged from summarizing all the interviews I conducted and highlights the frustrations developers have had with many of the new ‘solve all your problems’ tools they’ve tried. For context these tools fit into two categories: new programming languages including some flow &amp; graph based paradigms and no-code visual builders.</p><p id="6a39">There are two areas of value to consider when choosing a programming paradigm: the developer experience of the [language, tooling, GUI] and the strength of the ecosystem (what common problems have been solved already). Many of the new paradigms, while often built on sound principles, miss out on the massive body of work that already exists is language X. How do you weight these two areas when picking your paradigm? 30–70? 90–10? 1–99? Most people I spoke with rated the ecosystem as 2–3x more important than DX.</p><p id="9ab3">Tool-builders usually only focus on DX and [assume, hope, pray] that a community comes along and builds an ecosystem. This still can happens, but it was much much more common in the 90s than it is today. There are network effects in programming and a beautiful virtuous cycle quickly emerges among the most used tools. When a user shares functionality openly it makes paradigm more capable, which attracts new users, who continue to improve that paradigm. Boom! Node module for everything.</p><p id="0b6c">When you look at the languages that have really caught on recently, they tend to share one thing in common: they tap into an existing body of work. Look at TypeScript, the most popular language released after 2000, which interoperates with Javascript. Then there’s Swift, the second most popular language released after 2000. Just imagine where Swift would be today if it hadn’t been interoperable with Objective-C and the Cocoa legacy or if TypeScript’s ecosystem was a blue ocean from day one.</p><p id="272c">There are consequences for tool makers building an entirely new base abstraction, be it visual, text based or otherwise. If you choose not to interoperate with an existing ecosystem, you or your community will need to spend years coming up from the stone age to modernity. Programming is just learning to use a bunch of stacked abstractions. Even if you have an objectively better base abstraction, one that would have clearly won out over everything else had it been introduced in 1992, people will have few incentives to adopt it if there’s no ecosystem.</p><h2 id="749d">Sunk Cost…Sensibility</h2><p id="5881">Most people complete the phrase “Sunk cost _____” with “fallacy”. The classic economics thought experiment usually involves a couple staying at a concert they hate just because they paid face value for the tickets. An enlightened economist would, as the story goes, leave as soon as they became unhappy with the concert and reclaim a few precious hours. But if you had to pay $50k, $50M or $5B to leave the concert early, you’d probably stay. When the switching costs are that high, there’s good reason to stay and the largest employers of programmers in the world have enormous switching costs. This keeps mainstream programmers anchored to the status quo.</p><p id="2c6d">This is another completely rational choice developers make when sticking to the paradigms they know. The combined costs of hiring new people, training, rewriting the code, and the opportunity cost of choosing these actions over improving your product almost always outweigh the benefits of making the change. <a href="https://www.joelonsoftware.com/2000/04/06/things-you-should-never-do-part-i/" rel="noopener">Joel has a classic article about code rewrites that expands on this more.</a></p><p id="ccc1">Young companies without much in the way of legacy or those with no other choice have the luxury of picking new paradigms, but few of these companies end up becoming incumbents. Those who do make it are the kingmakers. Both Facebook and Twitter were first built on technologies that were inadequate for their eventual scale (PHP and Ruby). Facebook became so attached to PHP that they enhanced the language to suit their needs with Hack and other tools. Similarly, Twitter switched over to Scala which one could argue is a key reason for Scala’s mainstream success.</p><h2 id="a2d4">Solving the Least Important Problems</h2><p id="513f">Tool makers must strike a balance between learnability and productivity. A visual programming environment like MIT’s <a href="https://scratch.mit.edu/" rel="noopener">Scratch</a> is incredibly learnable. I’ve seen 4-5 year old kids build games with it after just a few hours. The drag/drop interface and shape based constraints are really easy to learn and prevent Scratch from ever being in a broken state. This is great for kids and individuals trying to learn programming.</p><p id="bb8d">The same things that make Scratch easy to learn also make it an unproductive environment for more serious programmers. For a professional, programming with drag and drop is way slower than keying in code — that’s just a fact.</p><p id="cad2">These tradeoffs must be considered whenever building a new tool. If you build something super learnable that is not productive you’ll get a lot of praise, but little follow through. If you build something that’s too difficult to learn, but very productive you’ll turn a lot of people off. To reach mainstream programmers you need to make something that is both learnable and productive.</p><p id="5100">I think most of the stalled innovations in programming focused disproportionally on learnability. The problem is, within a few weeks of using any paradigm developers usually have built a repository of habits that keep them from making mistakes. For instance, if a new visual logic builder prides itself on preventing all syntax errors, that’s really cool, but most developers have learned to do that automatically.</p><p id="742f">Truth is, every tool you have ever used is flawed and every new tool will also be flawed. Humans subconsciously come up with ways to cope with their tools so they can keep themselves focussed on the bigger conceptual issues. That isn’t going to change anytime soon. If professionals already have habits in place to cope with things that have been made easier/more learnable by new tooling, those new tools do not have much value to them. It’s like offering a 40 year old who’s been driving manual her whole life an automatic car — yeah that’s great, but it’s not needed and she certainly won’t pay a premium for it to be included.</p><h2 id="6e7a">Things Have Been Getting Better</h2><p id="10b2">No good analysis fails to include a few words from the Advocatus Diaboli.</p><p id="e04a">Things have been getting better. The growth has just been in the ecosystems and not the paradigms themselves. We’ve been building this amazing tower of abstraction since the early days of programming that provide really useful abstractions for things like:</p><ul><li id="fb86">Charging a credit card, which has gone from a 20 person team to processor.charge()</li><li id="b32b">Configuring a massive cluster of servers is done with a short text file instead of …</li></ul></div></div></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://aidancunniffe.com/why-programming-is-hard-to-fundamentally-improve-4101612d4ad9">https://aidancunniffe.com/why-programming-is-hard-to-fundamentally-improve-4101612d4ad9</a></em></p>]]>
            </description>
            <link>https://aidancunniffe.com/why-programming-is-hard-to-fundamentally-improve-4101612d4ad9</link>
            <guid isPermaLink="false">hacker-news-small-sites-25322656</guid>
            <pubDate>Sun, 06 Dec 2020 10:48:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Choose Boring Technology]]>
            </title>
            <description>
<![CDATA[
Score 195 | Comments 188 (<a href="https://news.ycombinator.com/item?id=25322651">thread link</a>) | @amzans
<br/>
December 6, 2020 | https://panelbear.com/blog/boring-tech/ | <a href="https://web.archive.org/web/*/https://panelbear.com/blog/boring-tech/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p>Note: the ideas in this post have already been covered numerous times in the past. One article that has greatly influenced my perspective over the years is <a href="https://mcfunley.com/choose-boring-technology" target="_blank" rel="noopener">McKinley's Choose Boring Technology</a>. Below I'll explore the topic from my own experience, and how I ended up using Kubernetes for a recent project.</p><p>Over the years I have observed that many engineers tend to attribute much of the success or failure of a company to the technical choices made. I know I’m often guilty of this too. And while it is often justified, I would argue that for the vast majority of startups out there, the choice of programming language, framework, or even database doesn’t matter that much. This seems especially true during the early stages.</p><h2>Through the engineering lens</h2><p>This perception is understandable, we as engineers tend to look at the world from a specific lens, and are often biased by what we know best. Our daily activities may include things such as debugging CI pipelines, implementing new features, pairing with colleagues, or migrating the always present legacy codebase. The environment that surrounds us makes it easy to believe that it all boils down to those things that we see and understand. It’s an illusion that makes us feel like we’re fully in control of what makes or breaks the product.</p><p>Don’t get me wrong, it can be a huge advantage for many companies to make their product 3x more efficient than competitors, or to have elegant, composable code. But you might be focusing on the wrong problems if nobody cares about the product you’re actually building, and sooner or later your business will hit this wall.</p><p>I’m not saying that software doesn’t matter. A solid foundation for your startup goes a long way. If investing in this allows you to build better features faster than your competitors, more power to you. But finding the right balance is highly dependent on what you’re trying to solve and the resources you have at hand. There’s no right or wrong way to do it, and as usual, it mainly comes down to tradeoffs.</p><p><img src="https://panelbear.com/static/img/blog/lenses.png" alt="Different lenses"></p><h2>Boring is less surprising</h2><p>I believe aiming for a healthy balance of risk vs reward when it comes to your technical choices is something to strive for. In particular, if it decreases the chances you get stuck on the wrong problems down the road.</p><p>Boring is often interpreted as “picking old technologies over newer ones”, but it doesn’t necessarily mean that. For me, this comes down to using proven technologies in which the ways it can fail are mostly known, but occasionally experimenting with different, possibly newer tools that might suit the problem at hand better.</p><p>Maybe you want to gain more experience by using the latest framework or programming language, or you just want to have some fun. You do what makes you happy. But if you’re trying to make a decision to increase the odds that your product or business will succeed, it’s worth stepping back and considering your options.</p><p>For me, mainly choosing software that has been around for longer is not about it being boring or older, it’s about the fact that the ways in which it fails are better known. There are fewer unknowns for you to deal with and this maximizes your chances of actually shipping the project.</p><p>For example the other day I had an issue with my Django app, and a quick search led me to tens of answers to this problem in various forums and websites. It took me at most 10 minutes to get back on track and that was the end of this issue.</p><p>I experienced the exact opposite a few years ago with a popular, but not so battle-tested Scala library my team had been using for a while. We were probably among the first to encounter the issues we were facing, and it seemed nobody had walked down this path before. Maybe it sounds like a fun challenge or a great chance to contribute back to OSS (which I’m happy to), but once you solve it, do your customers really care about it? How many days, weeks, or even months are you willing to invest in such issues? In my case, I’d rather use that time to ship new features or improve the existing ones.</p><h2>Exploit vs explore</h2><p>I try to follow an 80/20 distribution when it comes to my choice of tools. This means my stack consists of about 80% software I already know well, but I do allow myself 20% of the stack to explore tech I have less experience with. The exact ratio is not what’s important here, it’s more the fact that you should lean towards using proven technologies.</p><p>This also resonates with how <a href="https://en.wikipedia.org/wiki/Multi-armed_bandit" target="_blank" rel="noopener">Multi-armed bandits</a> work. You try to maximize your expected gain by taking advantage of what worked well in the past, while sometimes exploring new things to avoid missing out on a possible goldmine.</p><p><img src="https://panelbear.com/static/img/blog/bandits.png" alt="Balance new vs proven"></p><p>A more recent example of mine started as an embarrassingly simple Django app with no charts, all metrics were rendered on a plain HTML table, and all data was stored on a SQLite database. Took literally a weekend to get it up and running including manually deploying to a $5/mo VM. Low risk and high reward for my needs at the time.</p><p>Fast forward and as I added more features and began handling more page views for various websites, I started to notice that the codebase could use some refactoring. It also became increasingly repetitive to do things like deploying to new instances, issuing SSL certs, and keeping the DNS records up to date in case the IP address of my instances changed.</p><p>As a second iteration, I upgraded to a docker-compose setup plus lots of glue code. But soon enough I found myself reinventing what other tools already do well. There are multiple ways to solve each of these pain points, but in my case, it came down to using a tool I am very familiar with from my full-time job: Kubernetes.</p><p>Yes, I am well aware it can be overkill for a lot of projects out there, and I could have gotten away with a more traditional solution. But it works well for me, and I have been running production workloads with it for several years already. Please do not just blindly follow my path. Use what you already know best.</p><p>Kubernetes allowed me to simplify the operational aspects tremendously, and I feel comfortable debugging issues with it after having the pleasure of putting down multiple production fires for my employer over the years. It has also been around several years, there's lots of documentation, and a huge helpful community who can help. It'd argue that there's more documentation available than for any home-grown deployment system, or even EC2/Lambda/DigitalOcean for that matter.</p><p>As an added benefit, it also made it trivial when I migrated from DigitalOcean to Linode, and most recently to AWS (each migration took mostly an evening of changing my Terraform files and deploying them - I’m being serious). But that’s for another post.</p><h2>Let complexity come over time</h2><p>My point is, I moved into these technologies as the pain with the previous solution was higher than dealing with the new tech. But more importantly, it helped me ship features even faster to my customers while reducing the operational overhead for me.</p><p>If I had started with the more advanced setup from day one, I might have lost all motivation before I would have had the first version of Panelbear. The key is to solve the problems that are getting between you and your goals, not potential issues you believe one day will be yours.</p></div></div></div>]]>
            </description>
            <link>https://panelbear.com/blog/boring-tech/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25322651</guid>
            <pubDate>Sun, 06 Dec 2020 10:46:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Sugar – a typed lispy language targeting webasm/wat]]>
            </title>
            <description>
<![CDATA[
Score 47 | Comments 13 (<a href="https://news.ycombinator.com/item?id=25322596">thread link</a>) | @marksmillibend
<br/>
December 6, 2020 | https://ph1lter.bitbucket.io/blog/2020-12-06-sugar-compiler.html | <a href="https://web.archive.org/web/*/https://ph1lter.bitbucket.io/blog/2020-12-06-sugar-compiler.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">

<a href="https://ph1lter.bitbucket.io/index.html">(home)</a> <span>2020-12-06</span>
<p>Despite what I may have said in an earlier post, it's not <em>all</em> that nice to code directly in wat.
So I've started work on a compiler. A very thin compiler. The language should feel very similar to our, beloved, <code>wat</code>, but save us from
typing all those <code>i32.const, local.get</code>.
</p>
<p>Some points up front:
</p>
<ul><li>
the compiler targets <code>WAT</code> (not <code>WASM</code>). This means using <code>WABT::wat2wasm</code>.
</li><li>
not self hosting <span>come on people, I don't even have malloc to play with yet, let alone a buggy, poorly implemented, partial copy of common lisp.</span>
</li><li>
the compiler is written in common lisp (specifically, sbcl). <span>hereinafter CL</span>.
</li><li>
syntax checking is state-of-the-art and errors are output in a readable format (i.e. you will get a cryptic <code>sbcl</code> debug trace if you make the
slightest mistake).
</li><li>
why <strong>sugar</strong>? It was either that or <code>watson, watsup, watsamatta, watulookin</code>. <span>Also cos it's just syntactical sugar, get it?</span>
</li><li>
internet searches are to be done using <code>sugarlang</code> <span>or sugarland if you prefer</span>.
</li><li>
there is no manual; not even mul/div or all the relation operators (e.g. &lt;=) are written yet!
</li><li>
the compiler output is not a standalone executable but a <code>wasm</code> file. The <em>best</em> standalone wasm runtime I've found so far is <code>wasm-interp</code>.
Please don't say node.js. You can say <code>v8</code>, maybe.
</li></ul>
<blockquote><strong>node.js/npm</strong><br>That feeling when ...<br>People say <em>Minimalist System</em><br>Then say "just use npm install ..."<br></blockquote><h2> sugar example</h2>
<p>Here is the <code>malloc.wat</code> example from the previous blog post on webasm re-written in <code>sugar</code>.
It's quite a bit more concise and convenient than the original raw <code>wat</code> (see below).
</p>
<p>(previous post on <code>wat</code>
<a href="https://ph1lter.bitbucket.io/blog/2020-12-03-webasm-forth-with-lisp-syntax.html">/blog/2020-12-03-webasm-forth-with-lisp-syntax.html</a>
)
</p>
<pre>; malloc.sugar - sugar example code
(memory (import "js" "mem") 10)
(import "console" "log" (func js_log (i i32)))
(global memend i32 #x1000)
(global sbrk (mut i32) 0)
; ----- allocate some memory in wasm-space
(defun (export "malloc") (len i32) :result i32
  (locals (i32 (newbrk (+ sbrk len)) (mem sbrk)))
  (if (&gt;= newbrk memend) (return 0))
  (set sbrk newbrk)
  mem)
; ----- write bytes in wasm-space memory using js callback
(defun (export dump_range) (start i32 len i32)
  (locals (i32 i (end (+ start len))))
  (for (i start end)
    (js_log (get.u8* i))))
</pre>
<p>And this is what you would have written if you were coding directly in <code>wat</code>.
</p>
<pre>(module
  (memory (import "js" "mem") 10)
  (import "console" "log" (func $js_log (param $i i32)))
  (global $memend i32  (i32.const 4096))
  (global $sbrk (mut i32)  (i32.const 0))
  ;; ----- allocate some memory in wasm-space
  (func (export "malloc") (param $len i32) (result i32)
    (local $newbrk i32)
    (local $mem i32)
    (local.set $newbrk (i32.add (global.get $sbrk) (local.get $len)))
    (if (i32.ge_u (local.get $newbrk) (global.get $memend))
      (return (i32.const 0)))
    (local.set $mem (global.get $sbrk))
    (global.set $sbrk (local.get $newbrk))
    (local.get $mem))
  ;; ----- write bytes in wasm-space memory using js callback
  (func (export "dump_range") (param $start i32) (param $len i32)
    (local $i i32)
    (local $end i32)
    (local.set $end (i32.add (local.get $start) (local.get $len)))
    (local.set $i (local.get $start))
    (block $break2 (loop $head1
      (br_if $break2 (i32.eq (local.get $i)  (local.get $end)))
      (call $js_log (i32.load8_u (local.get $i)))
      (local.set $i (i32.add  (i32.const 1) (local.get $i)))
      (br $head1)))))
</pre>
<h2> using sugar</h2>
<p>Write a <code>your-source.sugar</code> source file in your favorite text editor. Then run <code>sugar</code> on it to produce <code>your-source.wat</code>
</p>
<p>This is how I use sugar (with a makefile for calling sugar, then wat2wasm):
<a href="https://ph1lter.bitbucket.io/src/sugar.mk">/src/sugar.mk</a>
</p>
<pre>$ mk malloc.wasm
./sugar malloc.sugar &gt;malloc.wat
summary: globals:2 functions:3 macros:2
wat2wasm malloc.wat
</pre>
<p>(see below for installing common lisp)
</p>
<h2> compiler</h2>
<p>The compiler is very small and may be interesting to read, for that reason.
<a href="https://ph1lter.bitbucket.io/src/sugar">/src/sugar</a>
</p>
<p>It includes a macro system, which I have used to implement <code>inc</code> and <code>for</code> but it's not yet available for use from sugar
itself. <span>Also the full CL defmacro/destructuring-bind lambda list syntax is non trivial to replicate; not to mention backquote.</span>
</p>
<h3> compiler structure</h3>
<p>Here is the overall compiler structure
</p>
<pre>loop:
  read a form [from source file]
  (compile form) =&gt; stdout
compile form:
  integer =&gt; (i32.const int)
  symbol =&gt; (local/global.get varname) [check in environment/scope]
  list/s-expr/cons =&gt;
    if (is-macro? form)
      (compile (expand-macro form))
    else:
      is-special? form =&gt; (compile-special form) [defun/import/export/global/set...]
      is-function? =&gt;
        for all args (compile arg)
        call func with args
      otherwise =&gt; error undefined function
</pre>
<h3> common lisp?</h3>
<p>Too many brackets?
</p><blockquote>Rule 1: There are no brackets, only indentation.<br>Rule 0: We suffer the brackets cos it gives us defmacro and that's worth a lot of suffering.<br></blockquote><p>Did you ever generate code? Did you think that was cool? You'll love common lisp. Try it for 2 weeks.
Money back guarantee if not satisfied.
</p>
<h3> value-if</h3>
<p>Lisp has value-IF i.e. you can use IF anywhere you use a value. That's like C's ternary but more powerful.
At first I thought WAT doesn't have it, but (if) has an optional
<code>(result type)</code> clause, like (func) so that it's branches
can return (type matched) values. So you can do clever things like this:
<span>note the (result i32) clause between if and condition.</span></p>
<pre>(set x
  (if (result i32) (&gt;= z limit)
    (comp-true-value y)
    (comp-false-value s 14 q)))
</pre>
<p><code>wat (select)</code> is like the C ternary operator although it can have blocks/statement sequences inside.</p><p>select v if: select has all 3 clauses always evaluated while (if) has only the conditional and the chosen branch evaluated. The other
(if) branch is not evaluated.
</p>
<h2> future directions</h2>
<h3> user accessible macros (defmacro)</h3>
<p>Implement (defmacro ...) for sugar.
</p>
<h3> shortcut and/or</h3>
<p>At the moment I only have the bitwise and/or operators '&amp;' and 'bor' and next on the list is having shortcutting logical <code>and/or</code> operators
like CL.
</p>
<p>Ideally I'd like to have lisp-style <code>and/or</code> where the expression value is
returned rather than just 0 or 1. Also standalone <code>and/or</code> so we can have things like
</p>
<pre>(and (file-existsp fname) (process-file fname))
(or (setup-completep) (error setup-failed))
</pre>
<span>Shortcut <code>and/or</code> actually compile to nested (if) expressions.</span><h3> missing operators/functions</h3>
<p>A whole slew of function counterparts for other types (i64,f32,f64) are missing. The compiler cannot type-infer which one (see below)
so these would have explicit names like <code>+f64, set.f64</code> etc.
</p>
<p>There are many other relops missing etc. They are fairly trivial to add.
</p>
<h3> arrays</h3>
<p>Currently I'm using pointer <code>get*/set*</code> but I'd like to have <code>aref</code> and implicit index to pointer arithmetic.
</p>
<h3> loops</h3>
<p>Some more loops. <code>while repeat</code> etc. The underlying <code>block, loop, br_if, br</code> are exposed so writing loops is possible.
It would only be the case of adding some more macros to enable:
</p>
<pre>(while condition body...)
(forever body...)
</pre>
<p>Also <code>continue, break</code> would be nice.
</p>
<h3> structures / defstruct</h3>
<p>Some kind of struct might be nice to have. Even if all the fields had to be i32 initially i.e. just a vector with named,
instead of numbered, fields.
</p>
<h3> better syntax/semantic checking</h3>
<p>Even the current error messages drop you into the SBCL debugger, which can be a scary place - [<code>ctrl-d</code>] to exit.
</p>
<h3> type tracing</h3>
<p>Knowing the types of values would allow the compiler to check signatures of calls of user functions and builtins.
It would also allow me to infer the correct type for <code>set</code> rather than requiring <code>set.f32</code> etc.
</p>
<h3> LET</h3>
<p>Locals <em>must</em> be defined at the start of a function. This means implementing LET (scoped blocks with local variables) is not trivial.
The current, single-pass, compiler would need to become far more complex to first decide how many locals are required in a function,
then allocate them up-front and possibly rename them if there are clashes.
</p>
<h3> self hosting</h3>
<p>The <em>holy grail</em> of compiler writers is that they rewrite their compiler in their new language. Common Lisp is <em>so far</em> above
the level of <code>wat</code> that this would be a large undertaking. First I'd need to write malloc...
</p>
<h2> installing common lisp</h2>
<p>Setting up sugar/common lisp may be trivial or hard depending on how familiar with common lisp you are :)
</p>
<p>Installing common lisp (I use SBCL) is outside the scope of this post. (Tell me it's harder than npm ...)
</p>
<p>I refer you to [Zach Beane's]
<a href="https://www.quicklisp.org/beta/">https://www.quicklisp.org/beta/</a>
</p>
<p>SBCL might even be in your package manager:
</p>
<pre>$ pacman -Ss sbcl
</pre>
<p><code>sugar</code> is run as a unix script. I've made a custom sbcl core since I prefer <code>iterate</code> over <code>loop</code>.
Here is a very brief explanation of how to make such a core, starting with <em>plain, vanilla</em> sbcl.
</p>
<pre>$ sbcl
* (ql:quickload '#:iterate)
* (sb-ext:save-lisp-and-die "sbcl-iterate")
$ sudo mv sbcl-iterate /usr/share/sbcl/sbcl-iterate
</pre>
<h2> source</h2>
<ul><li>
<a href="https://ph1lter.bitbucket.io/src/malloc.sugar">/src/malloc.sugar</a>
</li><li>
<a href="https://ph1lter.bitbucket.io/src/sugar">/src/sugar</a>
</li></ul>
<h2> mistakes</h2>
<p>[2020-12-07] My original compiler structure had a macro expansion bug. I was misled since I was in a block where I had just checked that
(form) was a consp/list and I assumed this remained true inside that block.
However, I missed the fact that I am modifying the form inside the block, with (expand-macro).
It's possible (expand-macro) returns a non-list e.g. a symbol. Then my list assumptions break.
</p>
<pre>compile form:
  ...
  list/s-expr/cons =&gt;
    while: (is-macro? form)
      form := (expand-macro form) &lt;---- bug: this can change form into a non-list
    is-special? form =&gt; ...
    is-function? =&gt; ...
</pre>
<p>First I fixed this with an extra list check in is-macro and also in the is-special/is-function parts, and a recursive call to compile
for non-list forms.
</p>
<p>I later thought if I had used a functional approach and avoided the mutation, I would not have made this mistake. My visual hint
that I was dealing with a list would have remained true. It turns out the functional solution is even more elegant than the original
and doesn't have the bug (+1 to functional purists).
</p>
<p>The functional solution, doesn't loop, it recurses on compile. Then compile gets the chance to decide again
what type of form expand-macro returned (nested macros …</p></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://ph1lter.bitbucket.io/blog/2020-12-06-sugar-compiler.html">https://ph1lter.bitbucket.io/blog/2020-12-06-sugar-compiler.html</a></em></p>]]>
            </description>
            <link>https://ph1lter.bitbucket.io/blog/2020-12-06-sugar-compiler.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25322596</guid>
            <pubDate>Sun, 06 Dec 2020 10:36:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Understanding Peer-to-Peer Git Forges with Radicle]]>
            </title>
            <description>
<![CDATA[
Score 37 | Comments 11 (<a href="https://news.ycombinator.com/item?id=25322584">thread link</a>) | @todsacerdoti
<br/>
December 6, 2020 | http://blog.vmsplice.net/2020/12/understanding-peer-to-peer-git-forges.html | <a href="https://web.archive.org/web/*/http://blog.vmsplice.net/2020/12/understanding-peer-to-peer-git-forges.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>Git is a distributed version control system and does not require a central server. Although repositories are usually published at a well-known location for convenient cloning and fetching of the latest changes, this is actually not necessary. Each clone can have the full commit history and evolve independently. Furthermore, code changes can be exchanged via email or other means. Finally, even the clone itself does not need to be made from a well-known domain that hosts a git repository (see <tt>git-bundle(1)</tt>).</p>

<p>Given that git itself is already fully decentralized one would think there is no further work to do. I came across the <a href="https://radicle.xyz/">Radicle</a> project and its somewhat psychedelic website. Besides having a website with a wild color scheme, the project aims to offer a social coding experiment or git forge functionality using a peer-to-peer network architecture. According to the <a href="https://docs.radicle.xyz/docs/what-is-radicle">documentation</a> the motivation seems to be that git's built-in functionality works but is not user-friendly enough to make it accessible. In particular, it lacks social coding features.</p>

<p>The goal is to add git forge features like project and developer discovery, issue trackers, wikis, etc. Additional, distinctly decentralized functionality, is also touched on involving Ethereum as a way to anchor project metadata, pay contributors, etc. Radicle is still in early development so these features are not yet implemented. Here is my take on the <a href="https://radicle.xyz/">How it Works</a> documentation, which is a little confusing due to its early stage and some incomplete sentences or typos. I don't know whether my understanding actually corresponds to the Radicle implementation that exists today or its eventual vision, because I haven't studied the code or tried running the software. However, the ideas that the documentation has brought up are interesting and fruitful in their own right, so I wanted to share them and explain them in my own words in case you also find them worth exploring.</p>

<h2>The git data model</h2>
<p>Let's quickly review the git data model because it is important for understanding peer-to-peer git forges. A git repository contains a <tt>refs/</tt> subdirectory that provides a namespace for local branch heads (<tt>refs/heads/</tt>), local and remotely fetched tags (<tt>refs/tags/</tt>), and remotely fetched branches (<tt>refs/remotes/&lt;remote&gt;/</tt>). Actually this namespace layout is just a convention for everyday git usage and it's possible to use the <tt>refs/</tt> namespace differently as we will see. The git client fetches refs from a remote according to a <i>refspec</i> rule that maps remote refs to local refs. This gives the client the power to fetch only certain refs from the server. The client can also put them in a different location in its local <tt>refs/</tt> directory than the server. For details, see the <tt>git-fetch(1)</tt> man page.</p>

<p>Refs files contain the commit hash of an <i>object</i> stored in the repository's object database. An object can be a commit, tree (directory), tag, or a blob (file). Branch refs point to the latest commit object. A commit object refers to a tree object that may refer to further tree objects for sub-directories and finally the blob objects that make up the files being stored. Note that a git repository supports <i>disjoint</i> branches that share no history. Perhaps the most well-known example of disjoint branches are the GitHub Pages and GitLab Pages features where these git forges publish static websites from the HTML/CSS/JavaScript/image files on a specific branch in the repository. That branch shares no version history with other branches and the directories/files typically have no similarity to the repository's main branch.</p>

<p>Now we have covered enough git specifics to talk about peer-to-peer git forges. If you want to learn more about how git objects are actually stored, check out my article on the <a href="http://blog.vmsplice.net/2016/05/git-internals-of-how-objects-are-stored.html">repository layout and pack files</a>.</p>

<h2>Identity and authority</h2>
<p>Normally a git repository has one or more owners who are allowed to push refs. No one else has permission to modify the refs namespace. What if we tried to share a single refs namespace with the whole world and everyone could push? There would be chaos due to naming conflicts and malicious users would delete or change other users' refs. So it seems like an unworkable idea unless there is some way to enforce structure on the global refs namespace.</p>

<p>Peer-to-peer systems have solutions to these problems. First, a unique identity can be created by picking a random number with a sufficient number of bits so that the chance of collision is improbable. That unique identity can be used as a prefix in the global ref namespace to avoid accidental collisions. Second, there needs to be a way to prevent unauthorized users from modifying the part of the global namespace that is owned by other users.</p>

<p><a href="https://en.wikipedia.org/wiki/Public-key_cryptography">Public-key cryptography</a> provides the primitive for achieving both these things. A public key or its hash can serve as the unique identifier that provides identity and prevents accidental collisions. Ownership can be enforced by verifying that changes to the global namespace are signed with the private key corresponding to the unique identity.</p>

<p>For example, we fetch the following refs from a peer:</p>
<pre>&lt;identity&gt;/
  heads/
    main
  metadata/
    signed_refs
</pre>

<p>This is a simplified example based on the Radicle documentation. Here <tt>identity</tt> is the unique identity based on a public key. Remember no one else in the world has the same identity because the chance of generating the same public key is improbable. The <tt>heads/</tt> refs are normal git refs to commit objects - these are published branches. The <tt>signed_refs</tt> ref points to an git object that contains a list of commit hashes and a signature generated using the public key. The signature can be verified using the public key.</p>

<p>Next we need to <i>verify</i> these changes to check that they were created with the private key that is only known to the identity's owner. First, we check the signature on the object pointed to by the <tt>signed_refs</tt> ref. If the signature is not valid we reject these changes and do not store them in our local repository. Next, we look up each ref in <tt>heads/</tt> against the list in <tt>signed_refs</tt>. If a ref is missing from the list then we reject these refs and do not allow them into our local repository.</p>

<p>This scheme lends itself to peer-to-peer systems because the refs can be propagated (copied) between peers and verified at each step. The identity owner does not need to be present at each copy step since their cryptographic signature is all we need to be certain that they authorized these refs. So I can receive refs originally created by identity A from peer B and still be sure that peer B did not modify them since identity A's signature is intact.</p>

<p>Now we have a global refs namespace that is partitioned so that each identity is able to publish refs and peers can verify that these changes are authorized.</p>

<h2>Gossip</h2>
<p>It may not be clear yet that it's not necessary to clone the entire global namespace. In fact, it's possible that no single peer will ever have a full copy of the entire global namespace! That's because this is a distributed system. Peers only fetch refs that they care about from their peers. Peers fetch from each other and this forms a network. The network does not need to be fully connected and it's possible to have multiple clusters of peers running without full global connectivity.</p>

<p>To bootstrap the global namespace there are <i>seed</i> repositories. Seeds are a common concept in peer-to-peer systems. They provide an entry point for new peers to learn about and start participating with other peers. In BitTorrent this is called a "tracker" rather than a "seed".</p>

<p>According to the Radicle documentation it is possible to directly fetch from peers. This probably means a <tt>git-daemon(1)</tt> or <tt>git-http-backend(1)</tt> needs to be accessible on the public internet. Many peers will not have sufficient network connectivity due to <a href="https://en.wikipedia.org/wiki/Network_address_translation">NAT</a> limitations. I guess Radicle does not expect every user to participate as a repository.</p>

<p>Interestingly, there is a <i>gossip</i> system for propagating refs through the network. Let's revisit the refs for an identity in the global namespace:</p>
<pre>&lt;identity&gt;/
  heads/
    main
  metadata/
    signed_refs
  remotes/
    &lt;another-identity&gt;/
      heads/
        main
        foo
      metadata/
        signed_refs
      remotes/
        ...
</pre>

<p>We can publish identities that we track in <tt>remotes/</tt>. It's a recursive refs layout. This is how someone tracking our refs can find out about related identities and their refs.</p>

<p>Thanks to git's data model the commit, tree, and blob objects can be shared even though we duplicate refs published by another identity. Since git is a <a href="https://en.wikipedia.org/wiki/Content-addressable_storage">content-addressable</a> object database the data is stored once even though multiple refs point to it.</p>

<p>Now we not only have a global namespace where anyone can publish git refs, but also ways to build a peer-to-peer network and propagate data throughout the network. It's important to note that data is only propagated if peers are interested in fetching it. Peers are not forced to store data that they are not interested in.</p>

<h2>How data is stored locally</h2>
<p>Let's bring the pieces together and show how the system stores data. The peer creates a local git repository called the <i>monorepo</i> for the purpose of storing portions of the global namespace. It fetches refs from seeds or direct peers to get started. Thanks to the <tt>remotes/</tt> refs it also learns about other refs on the network that it did not request directly.</p>

<p>This git repository is just a data store, it is not usable for normal git workflows. The conventional <tt>git branch</tt> and <tt>git tag</tt> commands would not work well with the global namespace layout and verification requirements. Instead we can clone a local file:/// repository from the monorepo that fetches a subset of the refs into the conventional git refs layout. The files can be shared because <tt>git-clone(1)</tt> supports hard links to local repositories. Thanks to <tt>githooks(5)</tt> and/or extensible <tt>git-push(1)</tt> remote helper support it's possible to generate the necessary global namespace …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://blog.vmsplice.net/2020/12/understanding-peer-to-peer-git-forges.html">http://blog.vmsplice.net/2020/12/understanding-peer-to-peer-git-forges.html</a></em></p>]]>
            </description>
            <link>http://blog.vmsplice.net/2020/12/understanding-peer-to-peer-git-forges.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25322584</guid>
            <pubDate>Sun, 06 Dec 2020 10:34:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Thinking About Decentralized Communities]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25322532">thread link</a>) | @SubGenius
<br/>
December 6, 2020 | https://gurlic.com/root/thinking-about-decentralized-communities | <a href="https://web.archive.org/web/*/https://gurlic.com/root/thinking-about-decentralized-communities">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
          
            <p>Earlier today, I had the misfortune of reading a blog post about the dangers of the decentralized web and how we should not partake in or encourage it's development. Hacker News had a pretty <a href="https://news.ycombinator.com/item?id=25312854" rel="noopener noreferrer nofollow">active discussion</a> about the post.</p><p>Ideological takes on this always turn ugly, and I'm at a point in my life where I avoid that at all costs. I can only talk about my preferences about the world, not about how things ought to be, implying some sort of inherent value or divine moral good.</p><p>Here's what I prefer: a world where ideas, no matter how silly or dangerous, are allowed to be expressed, shared, ignored, attacked and laughed at. I don't imagine a world like this can ever exist easily, but a more decentralized web can help us get halfway there.</p><h3 id="ok-so-what-about-gurlic-then">Ok so what about Gurlic then?</h3><p><a href="https://gurlic.com/" rel="noopener noreferrer nofollow">Gurlic</a> is roughly just over two months old now, and at a point where I am relatively comfortable with the basic features it has. In the coming weeks and months, I want to focus on modifying the backend to either adopt an existing decentralized protocol, or think about how to approach writing a new one. Perhaps it would have been smarter to do this before building it first, but that would have limited how I envisioned Gurlic to be and it would've turned out differently.</p><p>Right now I'm looking into the <a href="https://www.w3.org/TR/activitypub/" rel="noopener noreferrer nofollow">activitypub</a> spec, and the <a href="https://matrix.org/docs/spec/" rel="noopener noreferrer nofollow">matrix</a> spec - here are some initial thoughts I have about how Gurlic should approach decentralization/federation.</p><ul><li><p>Decentralization can be a priority, but must never be promoted as a feature, or made to be a selling point. When decentralization becomes the main selling point of a product or service, the usability and polish tend to suffer. Not always, but nearly always. None of the marketing copy should include the words 'decentralization', 'privacy' etc. <strong>Normal users don't care about any of this</strong>.</p></li><li><p>User experience should be seamless. The user shouldn't have to generate a key, remember an extra password, remember weird URL schemes, or download utilities and clients just to be part of an online community or to write an article. Above all, the user must not be confused, as one usually is when looking at Mastodon instances, which one to sign up to, and so on. My mom should be able to use it without having to call me, just like she does with Facebook. <strong>Normal users do care about this</strong>.</p></li><li><p>The protocol must be flexible enough to allow for all of Gurlic's current features. This means communities, user profiles, publications, articles, galleries, rich media posts, sharing/responding and so on. All seamlessly without any rough edges.</p></li><li><p>Any and all cryptocurrency/blockchain must be avoided.</p></li></ul><p>I'll have more to write about this in the near future.</p>
            </section></div>]]>
            </description>
            <link>https://gurlic.com/root/thinking-about-decentralized-communities</link>
            <guid isPermaLink="false">hacker-news-small-sites-25322532</guid>
            <pubDate>Sun, 06 Dec 2020 10:23:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Handy tips for staying secure on the go]]>
            </title>
            <description>
<![CDATA[
Score 11 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25322461">thread link</a>) | @henrikwm
<br/>
December 6, 2020 | https://security.christmas/2020/6 | <a href="https://web.archive.org/web/*/https://security.christmas/2020/6">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><main id="main-content"><article><img src="https://images.unsplash.com/photo-1517400508447-f8dd518b86db?w=1226&amp;h=400&amp;fit=crop&amp;crop=edges" alt=""><div><section><p>We wrote about <a href="https://security.christmas/2019/21">"Safe travels for the road warrior"</a> last year. This year we offer one more trick, and expand our list for staying safe and secure on the road.</p>
<p>Watch out for shoulder surfers, and protect your equipment if you have to leave it in for example your hotel room.</p>
</section><article><section><p><em>PANDEMIC WARNING: Stay at home if you can. A virus has for the better part of 2020 attacked physical infrastructure (people). We have no patch or hotfix, so while that is being worked out, we advice you to travel as little as possible.</em> </p>
<h2>Shoulder surfers:</h2>
<p>Be aware of your surroundings and reduce the risk of shoulder surfers. A shoulder surfer is someone who is peaking over your shoulder to get information. We can spot people prone to this type of social engineering attack all the time. When people are visiting a cafee, are on public transport, or on air planes they will use their laptop for work stuff. And they don’t notice, or care if someone is looking.</p>
<p>To protect your information, you can, and should invest in a privacy shield for you screen. They cost next to nothing, but reduce/limit the viewing angle of your display.</p>
<p><img src="https://cdn57.androidauthority.net/wp-content/uploads/2019/04/privacy-screen-protector-angle-2.jpg" alt="privacy screen protector"></p>
<p>Reduce the number of apps visible on your computer. On a Mac I recommend that you use <a href="https://www.macbartender.com/">Bartender</a>, but there are Windows and *Nix options as well. The point of this application is that it hides all the running apps from the menu bar, so that it looks like this: </p>
<p><img src="https://i.imgur.com/QsbNjHu.png" alt="a neat menu bar"></p>
<p>rather than this abomination of a menu bar: </p>
<p><img src="https://eshop.macsales.com/blog/wp-content/uploads/2019/05/1password1280.jpg" alt="an untidy and talkative menue bar"></p>
<p>The reason for hiding this information from shoulder surfers is that it reveals many of your attack vector. If someone knows what applications you are running, they know a lot about you. Developer tools, Automator scripts, and a password manager? You presumably work in IT. Bluetooth enabled, an old version of Outlook and a TorrentClient? The bad guys already have tools for these applications.  </p>
<h2>Mikado security</h2>
<p>The other tip is to not leave your computer laying around. This may seem obvious, but there are times when this is impossible. There will be events where you have super secret stuff on your computer, and must step away for a period of time. For instance in a hotel room while you are away for an hour, or go to a resturant.</p>
<p>If an adversary has physical access to your device, they can do all sort of damage. <a href="https://www.theregister.com/2013/12/11/poker_pros_call_shenanigans_over_hotel_malware_infections/">A poker player had this happen to him</a>, where someone broke into his hotel room to install malware on his laptop. This is only one of the cases, but we suspect there are many more based on  the fact that hotel room locks are <a href="https://youtu.be/-Bazy3Ew6D4">ridiculously insecure</a>, and <a href="https://youtu.be/RX-O4XuCW1Y">easy to bypass</a>.<br>
So to combat this problem, we have devised a nice little trick to help you stay safe if you have to leave your device behind.</p>
<p><img src="https://live.staticflickr.com/5475/9350249910_6aeb4b5d85_h.jpg">
<a href="https://flic.kr/p/ffftxm">Mikado</a> by <a href="https://www.flickr.com/photos/kobakpontorg/">Balazs Koren</a>, on Flickr</p>
<p>Mikado (also known as “pick-up sticks game”) is a game where players drop a bundle of sticks as a loose bunch onto a table top. Each player in turn tries to remove a stick from the pile without disturbing any of the others.</p>
<p>MikadoSecurity is where you spread the sticks over the object that you want to protect. You then take a picture of it, and when you return, you can verify that no one has tampered with your device.
In the event that the sticks are not as you left them, you can escalate the problem. Either to do forensics, or discard the computer if you need to.</p>
<p>This trick relies on the same principles as we rely on for computer security. Prime number factoring, traveling salesman problem and SAT are hard to solve if P != NP, but easy to verify.
An example of this is a sudoku board. It is hard for both humans and computers to solve, but if I hand you a board, it is easy for you to verify if I did it correct. </p>
<p><img src="https://i.imgur.com/fibOzob.png" title="Hard to solve / Easy to verify"></p></section></article></div></article><section><ul><li></li><li></li><li></li></ul></section></main></div></div>]]>
            </description>
            <link>https://security.christmas/2020/6</link>
            <guid isPermaLink="false">hacker-news-small-sites-25322461</guid>
            <pubDate>Sun, 06 Dec 2020 10:05:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[When Good Patterns Go Bad: The False Positive Regex]]>
            </title>
            <description>
<![CDATA[
Score 34 | Comments 3 (<a href="https://news.ycombinator.com/item?id=25322343">thread link</a>) | @jsnell
<br/>
December 6, 2020 | https://blog.donbowman.ca/2020/12/04/when-good-patterns-go-bad-the-false-positive-regex/ | <a href="https://web.archive.org/web/*/https://blog.donbowman.ca/2020/12/04/when-good-patterns-go-bad-the-false-positive-regex/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-3099" itemscope="" itemtype="https://schema.org/CreativeWork"><div><p><img width="795" height="485" src="https://blog.donbowman.ca/wp-content/uploads/2020/12/image.png" alt="When Good Patterns Go Bad: The False Positive Regex" loading="lazy" itemprop="thumbnailUrl" srcset="https://blog.donbowman.ca/wp-content/uploads/2020/12/image.png 795w, https://blog.donbowman.ca/wp-content/uploads/2020/12/image-300x183.png 300w, https://blog.donbowman.ca/wp-content/uploads/2020/12/image-768x469.png 768w, https://blog.donbowman.ca/wp-content/uploads/2020/12/image-100x61.png 100w, https://blog.donbowman.ca/wp-content/uploads/2020/12/image-150x92.png 150w, https://blog.donbowman.ca/wp-content/uploads/2020/12/image-200x122.png 200w, https://blog.donbowman.ca/wp-content/uploads/2020/12/image-450x275.png 450w, https://blog.donbowman.ca/wp-content/uploads/2020/12/image-600x366.png 600w" sizes="(max-width: 795px) 100vw, 795px" data-old-src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://blog.donbowman.ca/wp-content/uploads/2020/12/image.png" data-lazy-srcset="https://blog.donbowman.ca/wp-content/uploads/2020/12/image.png 795w, https://blog.donbowman.ca/wp-content/uploads/2020/12/image-300x183.png 300w, https://blog.donbowman.ca/wp-content/uploads/2020/12/image-768x469.png 768w, https://blog.donbowman.ca/wp-content/uploads/2020/12/image-100x61.png 100w, https://blog.donbowman.ca/wp-content/uploads/2020/12/image-150x92.png 150w, https://blog.donbowman.ca/wp-content/uploads/2020/12/image-200x122.png 200w, https://blog.donbowman.ca/wp-content/uploads/2020/12/image-450x275.png 450w, https://blog.donbowman.ca/wp-content/uploads/2020/12/image-600x366.png 600w"></p><div itemprop="text"><p>I once worked for a company that used regular expression matching (pattern matching) on network traffic. A big source of angst was the amount of “unknown traffic”, things which matched no patterns. Our sales team wanted this less. Our customers wanted it less. Our competitors had less. Why couldn’t we?</p><p>I used to answer this question as follows. “You know, I can put in one bad pattern, that mis-matches, a false positive. The amount of unknown will go down. Will that make it better? I can make 0% unknown right now.”. Interestingly, some would agree with the statement “sure, lets do that”. Some would say “don’t be ridiculous, I want 100% known, and 0% incorrect.”. I would answer the last question as “what if you made your own proprietary protocol, the license-plate protocol. You, and only you use it. The data in the stream is ciphered from your license plate. Would you expect a pattern for that?”. They would usually say no, I would then point out that 0% unknown as a false goal, the real goal was 0% incorrectly known and as much known as feasible. Still didn’t stop the competitor from using weak false positives to get to higher <code>known</code> amount.</p><p>Yesterday I received an email from the good people at Google. They are launching a new document leakage tool. It scans your shared documents for sensitive things (emails, medical, that sort of thing). Mine is below. Its alarming. 7% of my shared files contain sensitive information! O no!</p><div><figure><img loading="lazy" width="1024" height="624" src="https://blog.donbowman.ca/wp-content/uploads/2020/12/image-2-1024x624.png" alt="" srcset="https://blog.donbowman.ca/wp-content/uploads/2020/12/image-2-1024x624.png 1024w, https://blog.donbowman.ca/wp-content/uploads/2020/12/image-2-300x183.png 300w, https://blog.donbowman.ca/wp-content/uploads/2020/12/image-2-768x468.png 768w, https://blog.donbowman.ca/wp-content/uploads/2020/12/image-2-100x61.png 100w, https://blog.donbowman.ca/wp-content/uploads/2020/12/image-2-150x91.png 150w, https://blog.donbowman.ca/wp-content/uploads/2020/12/image-2-200x122.png 200w, https://blog.donbowman.ca/wp-content/uploads/2020/12/image-2-450x274.png 450w, https://blog.donbowman.ca/wp-content/uploads/2020/12/image-2-600x366.png 600w, https://blog.donbowman.ca/wp-content/uploads/2020/12/image-2-900x549.png 900w, https://blog.donbowman.ca/wp-content/uploads/2020/12/image-2.png 1158w" sizes="(max-width: 1024px) 100vw, 1024px" data-old-src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-lazy-src="https://blog.donbowman.ca/wp-content/uploads/2020/12/image-2-1024x624.png" data-lazy-srcset="https://blog.donbowman.ca/wp-content/uploads/2020/12/image-2-1024x624.png 1024w, https://blog.donbowman.ca/wp-content/uploads/2020/12/image-2-300x183.png 300w, https://blog.donbowman.ca/wp-content/uploads/2020/12/image-2-768x468.png 768w, https://blog.donbowman.ca/wp-content/uploads/2020/12/image-2-100x61.png 100w, https://blog.donbowman.ca/wp-content/uploads/2020/12/image-2-150x91.png 150w, https://blog.donbowman.ca/wp-content/uploads/2020/12/image-2-200x122.png 200w, https://blog.donbowman.ca/wp-content/uploads/2020/12/image-2-450x274.png 450w, https://blog.donbowman.ca/wp-content/uploads/2020/12/image-2-600x366.png 600w, https://blog.donbowman.ca/wp-content/uploads/2020/12/image-2-900x549.png 900w, https://blog.donbowman.ca/wp-content/uploads/2020/12/image-2.png 1158w"></figure></div><p>But then I started reading… Its the same pattern match technology. I can guarantee my company deals with 0% “FDA Approved Prescription” information. We also have 0% IBAN and SWIFT and Credit Card Number.</p><p>Now, from the report there must be a way to find the offending documents, right? Wrong. You get a number: “9% of your documents shared have Global Gender Identity”. What does that even mean?</p><p>This is how you make data untrustworthy and less than useless. I spent time trying to figure out what the call to action was. Eventually I realised the call to action was to ignore: someone at Google has written a few bad regex. They’ve run them on my documents. They’ve shared the categories and counts, but not the links. Their false positive engine cost me time and adds nothing to the universe.</p><p>Sadly, I think there are people out there buying pattern engines for all sorts of things, and, pushing towards the false goal of 0% unknown. It must match, right? Wrong.</p></div></div></article></div>]]>
            </description>
            <link>https://blog.donbowman.ca/2020/12/04/when-good-patterns-go-bad-the-false-positive-regex/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25322343</guid>
            <pubDate>Sun, 06 Dec 2020 09:42:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Perils of File Typing]]>
            </title>
            <description>
<![CDATA[
Score 56 | Comments 36 (<a href="https://news.ycombinator.com/item?id=25322288">thread link</a>) | @panic
<br/>
December 6, 2020 | https://invisibleup.com/articles/34/ | <a href="https://web.archive.org/web/*/https://invisibleup.com/articles/34/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
	
	
	<img src="https://invisibleup.com/articles/34/thumb.gif" alt="The Perils of File Typing thumbnail">
	
	

	
<p>Corrections added to the Creator/Type code section thanks to user "Somebody" on Hacker News</p>

<p>Suppose you double-click on a file on your computer. You're doing this so you can open the file and work with it. But does your operating system know what that means? How does it know <em>what</em> to open the file <em>in</em>? Let's look at some solutions that have been proposed over the years to solving this issue.</p>
<p>(fun fact: this originally started as a touchup of <a href="https://invisibleup.com/articles/2/">one of my oldest articles</a> before just kinda becoming this whole <em>thing</em>, so expect a bit of retreading.)</p>
<h2>Nothing</h2>
<p><img alt="IBM 709 in use" src="https://invisibleup.com/articles/34/IBM709.jpg"></p>
<p><strong>Used in</strong>: Early mainframes such as the <a href="https://en.wikipedia.org/wiki/IBM_704">IBM 704</a>, etc.</p>
<p>(Image credit: <a href="https://www.computer-history.info/Page4.dir/pages/IBM.704.dir/">Lawrence Livermore National Laboratory</a>)</p>
<p>What's a "file", anyways? It's a sequence of bytes on a disk, possibly floppy. Or a tape. (Cassette or paper, your choice.) Or on stacks of cards with holes in them. Or toggled in by hand on a front panel.</p>
<p>File types weren't relevant because <em>files</em> weren't really a thing. In the mainframe era, you typically 
1. loaded a program on to your computer from punch cards or a tape
2. fed input into that program either from a teletype terminal or from a different tape/card deck
3. received output from the teletype, a line printer, or yet another tape/card deck</p>
<p>Computers weren't complicated enough where there was any confusion as to what a file on a certain medium <em>was</em>, simply because there was so little to work with. If you had a stack of punchcards, that was your "file". Hope you labeled the box you put it in!</p>
<p>Tapes are more interesting, because they hold substantially more data. (A whopping 5.76 megabytes, stored on 3/4 of a kilometer of magentic tape. How exciting!) That said, storing more than one file on a tape was a strange task. Operating systems weren't really a <em>thing</em> yet. The best that existed were programming languages such as FORTRAN or COBOL that had statements for hardware tasks such as reading from or writing to a tape or punch card. For example, <a href="http://archive.computerhistory.org/resources/text/Fortran/102649787.05.01.acc.pdf">here's the manual for FORTRAN for the IBM 704.</a> We have several commands such as <code>READ</code> (from the punch card reader), <code>READ TAPE</code>, <code>PUNCH</code> (new cards), <code>PRINT</code> (to the printer), etc.</p>
<p>On the IBM tape units of the time (ex: the <a href="https://en.wikipedia.org/wiki/IBM_727">IBM 727</a>), tapes were separated into <em>files</em> and <em>records</em>. In FORTRAN, records were created on every <code>WRITE TAPE</code> command, and could be read with <code>READ TAPE</code> later. Records could be overwritten by using the <code>BACKSPACE</code> statement and then writing again. Files were collections of records, and could be created with an <code>END FILE</code> command.</p>
<p>As an aside, later programming languages such as C still share their heritage from this era. This is why we draw text to the screen with <a href="http://www.cplusplus.com/reference/cstdio/printf/"><code>printf</code></a> which long ago would have literally printed to a <a href="https://en.wikipedia.org/wiki/Teletype_Model_33">teletype terminal</a>, why we read files using <a href="http://www.cplusplus.com/reference/cstdio/rewind/"><code>rewind</code></a>, <a href="http://www.cplusplus.com/reference/cstdio/fseek/"><code>fseek</code></a>, <a href="http://www.cplusplus.com/reference/cstdio/fread/"><code>fread</code></a>, and <a href="http://www.cplusplus.com/reference/cstdio/fwrite/"><code>fwrite</code></a> as if we were on a tape drive still. Even <a href="http://www.asciitable.com/">ASCII</a>, the encoding most commonly used for the basic Latin alphabet, has code points for file, group, record, and unit separators. (This may also be related to block terminals, something that will be discussed in a future article.)</p>
<p>As mainframes moved onto more advanced batch processing and later interactive time-share operating systems like UNIX, <a href="https://en.wikipedia.org/wiki/OS/360_and_successors">OS/360</a>, <a href="https://en.wikipedia.org/wiki/Michigan_Terminal_System">Michigan Terminal System</a>, <a href="https://en.wikipedia.org/wiki/Incompatible_Timesharing_System">ITS</a>, etc., they gained more sophisticated methods of dealing with files than raw tape drive access. But then came the microcomputers.</p>
<h2>Type Codes</h2>
<p><img alt="Apple DOS file listing" src="https://invisibleup.com/articles/34/appledos.gif"></p>
<p><strong>Used in</strong>: <a href="https://en.wikipedia.org/wiki/Apple_DOS">Apple DOS for Apple II</a> (1978-1980), <a href="https://www.hpmuseum.org/hp28c.htm">HP-28</a> and <a href="https://www.hpmuseum.org/hp48s.htm">HP-48</a> series, etc.</p>
<p>We have floppy disks now. They can store a lot of files, rename them, delete them, etc. without too much issue. There's this neat computer called the Apple II that just came out. It uses these new-fangled disks, so it needs to figure out how to store files on it.</p>
<p>The way that Apple DOS (the Apple II's disk operating system for most of it's life) stored files is somewhat interesting. Each file has a name (up to 30 characters) and also a <em>type code</em>. 8 of them were defined but only 4 of them mattered:</p>
<ul>
<li>I (Integer BASIC program)</li>
<li>A (Applesoft BASIC program)</li>
<li>B (Binary files; either assembled programs or data)</li>
<li>T (ASCII text files)</li>
</ul>
<p>Apple DOS had some specific commands that interacted with these types. For instance, the <code>RUN</code> command worked on both Interger BASIC and Applesoft BASIC programs, and chose which one to use. <code>BRUN</code>, <em>binary run</em>, only worked on binary files. <code>OPEN</code>, <code>READ</code>, <code>WRITE</code>, and <code>CLOSE</code> all worked only on ASCII text files.</p>
<p><strong>The types more served as a way to help the operating system more so than you.</strong> This is especially evident in the late 80's and early 90's HP calculators such as the HP-28c and the HP-48GX. These calculators didn't have disks, but they did have persistent memory that could store objects into folders much like a computer.</p>
<p>These calculators used Reverse Polish Notation. Essentially, you do math by placing objects on the stack and then executing commands, which take things from the stack and put a new thing on. An <em>object</em> in RPN is something you placed on the stack. The HP-48's Advanced User's Reference Manual lists 32 distinct types, including real numbers, complex numbers, character strings, arrays, lists, variable names, executable programs, graphics objects, directories, etc. A <em>command</em> could be, say, <code>ADD</code> or some fancy plotting calculus stuff. Whatever they were, they needed to know what types they were dealing with so that they could either reject the input or properly work with it.</p>
<p>Like the Apple II, just having an integer for a type is perfectly okay because the types don't serve the user. They're just there so the operating system knows what a given chunk of bytes on the stack <em>is</em>. There are a few reserved spots for custom types, but for the most parts new types aren't expected to ever be added, nor should they be.</p>
<h3>File Extensions</h3>
<p><img alt="CP/M disk listing as seen on an Amstrad CPC" src="https://invisibleup.com/articles/34/cpm.gif"></p>
<p><strong>Used in</strong>: AMSDOS (Amstrad CPC), CP/M, MS-DOS, etc.</p>
<p>Microcomputers really started to gain in popularity with the likes of the ZX Spectrum, the Amstrad CPC and the Commodore 64 among others. These were fairly cheap and simple computers. When first launched, these came with nothing but cassette tape inputs, as disks were too expensive.</p>
<p>On these computers, you'd attach a cassette player using a standard AUX cord (although some, like the CPC, had a cassette player built in), and the computer would instruct you when to start and stop the tape. These cassette players usually came with a little counter that rolled up as the tape progressed, to help you tell where the tape was. When you insert a tape, you reset the counter to zero. When you want to <em>make</em> a file, you'd write down what the counter read, then save the file. To <em>load a specific file</em>, you'd seek the tape until you're at the location you've written down, then start reading.</p>
<p>More advanced computers such as the Amstrad CPC instead saved <a href="http://www.cpcwiki.eu/index.php/AMSDOS_Header">a header</a> with each file containing, among other things, a file name and extension. If asked for a specific file it could just read the tape until it found it. Later these computers gained disk drives, and any ad-hoc tape fiddling was replaced with a proper file system such as <a href="https://en.wikipedia.org/wiki/File_Allocation_Table">FAT</a> or <a href="https://en.wikipedia.org/wiki/Macintosh_File_System">MFS</a> that stored <em>where</em> a file was on a given disk and <em>what is was called</em>.</p>
<p>File codes are limited. It is nigh-on impossible to add more ones. What you have is what you got. So... what if we just made the codes out of letters? A couple of them? And they could be anything. Then programmers could come up with whatever file extensions they want and that's okay.</p>
<p>Suppose, in MS-DOS, you have a file named <code>REPORT.TXT</code>. <code>REPORT</code> is the file name, <code>TXT</code> is the extension. <strong>File extensions give an easy, consistent indicator of what a file contains.</strong> A <code>TXT</code> file contains text, a <code>BMP</code> file is a bitmap, etc. </p>
<p>Some file extensions, like <code>EXE</code>, <code>BAT</code>, <code>SYS</code> and <code>COM</code> had special meaning much in the same way that the Apple DOS codes had special meanings, but other than that they're just there to help the user. <strong>The user had to manually choose which program to use.</strong> This allowed for the user to choose what view or editor to use depending on what would be the most helpful. Unfortunately, there were no default programs. If the user didn't know which program, say, a <code>VIZ</code> file is for, they're out of luck. Is it a visualization? Some manga thing? The digital manifestation of a cute internet ghost who's staying up way too late geeking out about old computers? <em>The world may never know...</em></p>
<h3>Creator Codes</h3>
<p><strong>Used in:</strong> Classic Mac OS</p>
<p><img alt="File properties dialog on Classic Mac OS" src="https://invisibleup.com/articles/34/macinfo.gif"></p>
<p>Let's hop on over to the Macintosh for a quick second. It was a newfangled thing in 1984, and it had the opportunity to reinvent the wheel and break compatibility with CP/M and mainframe traditions. And so it did.</p>
<p>The original 128K Macintosh used 400K floppy disks, a not-completely-terrible amount of space for the time. It used the <a href="https://en.wikipedia.org/wiki/Macintosh_File_System">MFS</a>, which didn't support directories but <em>did</em> support files. It was also completely graphically driven. The Finder was supposed to be the primary way of interacting with files, and the <code>File &gt; Open</code> command could launch the program that made the file. How'd it do that?</p>
<p><strong>Instead of file extensions, the Macintosh used type and creator codes</strong>. These were 4-byte identifiers, much like file extensions, but there were two of them each with a different meaning. The type code was mean to represent the format the data was stored in, used to filter files in the Finder's "Open" dialog. The creator code was meant to indicate the application that created the file, and used by the Finder to choose which specific application to launch. Now, these weren't normally visible to the user. They just saw the file name and a icon for that type.</p>
<p>To do that, the system kept a database of codes and their associated icons and programs. When ran for the first time or moved from disk to disk, <strong>the Finder would read the program data and register in a database what creator codes and file types it supported.</strong> The Finder would then save this information on the disk containing the application. Later, <strong>when the user opened a file, the OS would check its type and creator code against its stored list to determine which application to use.</strong> This worked pretty well.</p>
<p><img alt="ResEdit view" src="https://invisibleup.com/articles/34/macresedit.gif"></p>
<p>A similar system was used for …</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://invisibleup.com/articles/34/">https://invisibleup.com/articles/34/</a></em></p>]]>
            </description>
            <link>https://invisibleup.com/articles/34/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25322288</guid>
            <pubDate>Sun, 06 Dec 2020 09:27:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Greta Thunberg Meets Sir David Attenborough]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25322245">thread link</a>) | @maxekman
<br/>
December 6, 2020 | https://www.dn.se/kultur/greta-thunberg-meets-sir-david-attenborough/ | <a href="https://web.archive.org/web/*/https://www.dn.se/kultur/greta-thunberg-meets-sir-david-attenborough/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://www.dn.se/kultur/greta-thunberg-meets-sir-david-attenborough/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25322245</guid>
            <pubDate>Sun, 06 Dec 2020 09:17:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Monopoly Technology Platforms Are Colonizing Education]]>
            </title>
            <description>
<![CDATA[
Score 193 | Comments 106 (<a href="https://news.ycombinator.com/item?id=25322202">thread link</a>) | @partingshots
<br/>
December 6, 2020 | https://instituteforpubliceducation.org/monopoly-technology-platforms-are-colonizing-education/ | <a href="https://web.archive.org/web/*/https://instituteforpubliceducation.org/monopoly-technology-platforms-are-colonizing-education/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://instituteforpubliceducation.org/monopoly-technology-platforms-are-colonizing-education/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25322202</guid>
            <pubDate>Sun, 06 Dec 2020 09:07:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[VisiData in 60 Seconds]]>
            </title>
            <description>
<![CDATA[
Score 104 | Comments 14 (<a href="https://news.ycombinator.com/item?id=25322091">thread link</a>) | @luu
<br/>
December 6, 2020 | https://jsvine.github.io/intro-to-visidata/the-big-picture/visidata-in-60-seconds/ | <a href="https://web.archive.org/web/*/https://jsvine.github.io/intro-to-visidata/the-big-picture/visidata-in-60-seconds/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>TL;DR? Here’s a three-step introduction to VisiData.</p><div id="step-1-use-vd-to-open-a-data-file">
<h2>Step 1: Use <code><span>vd</span></code> to open a data file<a href="#step-1-use-vd-to-open-a-data-file" title="Permalink to this headline">¶</a></h2>
<p>Download <a download="" href="https://jsvine.github.io/intro-to-visidata/_downloads/83e70cf67e909f3ac177575439e5f3c5/faa-wildlife-strikes.csv"><code><span>faa-wildlife-strikes.csv</span></code></a>, a dataset of all aircraft-wildlife collisions <a href="https://wildlife.faa.gov/database.aspx">reported to the Federal Aviation Adminsitration</a> between 2010 and mid-2016.</p>
<p>From your terminal, move into the directory where you downloaded the dataset. Then run the following command:</p>
<div><div><pre><span></span>vd faa-wildlife-strikes.csv
</pre></div>
</div>
<p>If it worked, you should see something like this:</p>
<div>
<pre><span></span><span></span><span> OPERATOR           </span><span></span><span>|</span><span></span><span> ATYPE        </span><span></span><span>|</span><span></span><span> INCIDENT_DATE     </span><span></span><span>|</span><span></span><span> STATE </span><span></span><span>|</span><span></span><span> AIRPORT            </span><span></span><span>|</span><span></span><span> PHASE_OF_FLT</span><span></span><span>&gt;</span><span> 
</span><span></span><span> BUSINESS           </span><span></span><span></span><span>| PA-28        | 05/22/15 00:00:00 | FL    | VERO BEACH MUNICIP…| APPROACH     ║
</span><span></span><span></span><span> BUSINESS           </span><span></span><span>|</span><span> BE-1900</span><span>      </span><span>|</span><span> 06/18/15 00:00:00 </span><span>|</span><span> AK    </span><span>|</span><span> KENAI MUNICIPAL AR…</span><span>|</span><span> APPROACH     </span><span>║
</span><span></span><span> BUSINESS           </span><span></span><span>|</span><span> PA-46 MALIBU </span><span>|</span><span> 09/20/15 00:00:00 </span><span>|</span><span> TX    </span><span>|</span><span> DAVID WAYNE HOOKS …</span><span>|</span><span>              </span><span>║
</span><span></span><span> DELTA AIR LINES    </span><span></span><span>|</span><span> B-717-200    </span><span>|</span><span> 11/07/15 00:00:00 </span><span>|</span><span> MO    </span><span>|</span><span> LAMBERT-ST LOUIS I…</span><span>|</span><span> APPROACH     </span><span>║
</span><span></span><span> BUSINESS           </span><span></span><span>|</span><span> BE-90 KING   </span><span>|</span><span> 12/17/15 00:00:00 </span><span>|</span><span> FL    </span><span>|</span><span> POMPANO BEACH AIRP…</span><span>|</span><span> LANDING ROLL </span><span>║
</span><span></span><span> DELTA AIR LINES    </span><span></span><span>|</span><span> B-757</span><span>        </span><span>|</span><span> 07/17/15 00:00:00 </span><span>|</span><span> VI    </span><span>|</span><span> HENRY E ROHLSEN AR…</span><span>|</span><span>              </span><span>║
</span><span></span><span> DELTA AIR LINES    </span><span></span><span>|</span><span> B-717-200    </span><span>|</span><span> 08/02/15 00:00:00 </span><span>|</span><span> TX    </span><span>|</span><span> SAN ANTONIO INTL   </span><span>|</span><span> APPROACH     </span><span>║
</span><span></span><span> BUSINESS           </span><span></span><span>|</span><span> C-414</span><span>        </span><span>|</span><span> 08/03/15 00:00:00 </span><span>|</span><span> TX    </span><span>|</span><span> LONE STAR EXECUTIV…</span><span>|</span><span> DEPARTURE    </span><span>║
</span><span></span><span> ALLEGIANT AIR      </span><span></span><span>|</span><span> MD-80</span><span>        </span><span>|</span><span> 09/02/15 00:00:00 </span><span>|</span><span> FL    </span><span>|</span><span> TAMPA INTL</span><span>         </span><span>|</span><span> APPROACH     </span><span>║
</span><span></span><span> TRANS STATES AIRLI…</span><span></span><span>|</span><span> EMB-145</span><span>      </span><span>|</span><span> 09/07/15 00:00:00 </span><span>|</span><span> MO    </span><span>|</span><span> LAMBERT-ST LOUIS I…</span><span>|</span><span> APPROACH     </span><span>║
</span><span></span><span> BUSINESS           </span><span></span><span>|</span><span> C-172</span><span>        </span><span>|</span><span> 11/28/15 00:00:00 </span><span>|</span><span> FL    </span><span>|</span><span> OPA-LOCKA EXECUTIV…</span><span>|</span><span> APPROACH     </span><span>║
</span><span></span><span> GOVERNMENT         </span><span></span><span>|</span><span> EC120</span><span>        </span><span>|</span><span> 12/08/15 00:00:00 </span><span>|</span><span> CA    </span><span>|</span><span> NORMAN Y. MINETA S…</span><span>|</span><span>              </span><span>║
</span><span></span><span> AMERICAN AIRLINES  </span><span></span><span>|</span><span> A-321</span><span>        </span><span>|</span><span> 05/06/15 00:00:00 </span><span>|</span><span> FL    </span><span>|</span><span> FORT LAUDERDALE/HO…</span><span>|</span><span> APPROACH     </span><span>║
</span><span></span><span> EXPRESSJET AIRLINES</span><span></span><span>|</span><span> CRJ100/200   </span><span>|</span><span> 05/06/15 00:00:00 </span><span>|</span><span> AR    </span><span>|</span><span> FORT SMITH REGIONA…</span><span>|</span><span> CLIMB</span><span>        </span><span>║
</span><span></span><span> MESA AIRLINES      </span><span></span><span>|</span><span> CRJ900</span><span>       </span><span>|</span><span> 05/08/15 00:00:00 </span><span>|</span><span> AR    </span><span>|</span><span> BILL AND  HILLARY …</span><span>|</span><span> LANDING ROLL </span><span>║
</span><span></span><span> BUSINESS           </span><span></span><span>|</span><span> HELICOPTER   </span><span>|</span><span> 05/06/15 00:00:00 </span><span>|</span><span>       </span><span>|</span><span> UNKNOWN</span><span>            </span><span>|</span><span> En Route     </span><span>║
</span><span></span><span> DELTA AIR LINES    </span><span></span><span>|</span><span> A-320</span><span>        </span><span>|</span><span> 05/07/15 00:00:00 </span><span>|</span><span> CA    </span><span>|</span><span> METRO OAKLAND INTL </span><span>|</span><span>              </span><span>║
</span><span></span><span> DELTA AIR LINES    </span><span></span><span>|</span><span> A-320</span><span>        </span><span>|</span><span> 05/08/15 00:00:00 </span><span>|</span><span> UT    </span><span>|</span><span> SALT LAKE CITY INTL</span><span>|</span><span>              </span><span>║
</span><span></span><span> LUFTHANSA          </span><span></span><span>|</span><span> A-380</span><span>        </span><span>|</span><span> 05/10/15 00:00:00 </span><span>|</span><span> TX    </span><span>|</span><span> GEORGE BUSH INTERC…</span><span>|</span><span> CLIMB</span><span>        </span><span>║
</span><span></span><span> BUSINESS           </span><span></span><span>|</span><span> C-172</span><span>        </span><span>|</span><span> 05/08/15 00:00:00 </span><span>|</span><span> FL    </span><span>|</span><span> ORLANDO SANFORD IN…</span><span>|</span><span> APPROACH     </span><span>║
</span><span></span><span> SPIRIT AIRLINES    </span><span></span><span>|</span><span> A-319</span><span>        </span><span>|</span><span> 05/10/15 00:00:00 </span><span>|</span><span> IL    </span><span>|</span><span> CHICAGO O'HARE INT…</span><span>|</span><span> CLIMB</span><span>        </span><span>║
</span><span></span><span> EXPRESSJET AIRLINES</span><span></span><span>|</span><span> EMB-145</span><span>      </span><span>|</span><span> 05/11/15 00:00:00 </span><span>|</span><span> AL    </span><span>|</span><span> BIRMINGHAM-SHUTTLE…</span><span>|</span><span> LANDING ROLL </span><span>║
</span><span></span><span>1› faa-wildlife-strikes| user_macros | saul.pw/VisiData v2.1 | opening datasets/        73448 rows </span><span> </span>
</pre>
</div>
</div><div id="step-2-test-drive-a-frequency-table">
<h2>Step 2: Test-drive a frequency table<a href="#step-2-test-drive-a-frequency-table" title="Permalink to this headline">¶</a></h2>
<p>One of VisiData’s strengths is how quickly it lets you summarize your data. Frequency tables are a great example. To create one, press <kbd>Shift+F</kbd>.</p>
<p>If it worked, you should see something like this:</p>
<div>
<pre><span></span><span></span><span> OPERATOR           </span><span></span><span>║</span><span></span><span>↓count♯</span><span></span><span>|</span><span></span><span> percent%</span><span></span><span>|</span><span></span><span> histogram                                         ~</span><span></span><span>║</span><span>        
</span><span></span><span> UNKNOWN            </span><span></span><span></span><span>║ 23076 |   31.42 | ************************************************** ║</span><span>        
</span><span></span><span> SOUTHWEST AIRLINES </span><span></span><span>║</span><span>  7752 </span><span>|</span><span>   10.55 </span><span>|</span><span> ****************</span><span>                                   </span><span>║</span><span>        
</span><span></span><span> BUSINESS           </span><span></span><span>║</span><span>  5868 </span><span>|</span><span>    7.99 </span><span>|</span><span> ************</span><span>                                       </span><span>║</span><span>        
</span><span></span><span> AMERICAN AIRLINES  </span><span></span><span>║</span><span>  4337 </span><span>|</span><span>    5.90 </span><span>|</span><span> *********</span><span>                                          </span><span>║</span><span>        
</span><span></span><span> DELTA AIR LINES    </span><span></span><span>║</span><span>  2817 </span><span>|</span><span>    3.84 </span><span>|</span><span> ******</span><span>                                             </span><span>║</span><span>        
</span><span></span><span> FEDEX EXPRESS      </span><span></span><span>║</span><span>  2709 </span><span>|</span><span>    3.69 </span><span>|</span><span> *****   </span><span>                                           </span><span>║</span><span>        
</span><span></span><span> UNITED AIRLINES    </span><span></span><span>║</span><span>  2194 </span><span>|</span><span>    2.99 </span><span>|</span><span> ****</span><span>                                               </span><span>║</span><span>        
</span><span></span><span> US AIRWAYS         </span><span></span><span>║</span><span>  1885 </span><span>|</span><span>    2.57 </span><span>|</span><span> ****</span><span>                                               </span><span>║</span><span>        
</span><span></span><span> UPS AIRLINES       </span><span></span><span>║</span><span>  1773 </span><span>|</span><span>    2.41 </span><span>|</span><span> ***</span><span>                                                </span><span>║</span><span>        
</span><span></span><span> SKYWEST AIRLINES   </span><span></span><span>║</span><span>  1769 </span><span>|</span><span>    2.41 </span><span>|</span><span> ***</span><span>                                                </span><span>║</span><span>        
</span><span></span><span> JETBLUE AIRWAYS    </span><span></span><span>║</span><span>  1740 </span><span>|</span><span>    2.37 </span><span>|</span><span> ***</span><span>                                                </span><span>║</span><span>        
</span><span></span><span> EXPRESSJET AIRLINES</span><span></span><span>║</span><span>  1347 </span><span>|</span><span>    1.83 </span><span>|</span><span> **   </span><span>                                              </span><span>║</span><span>        
</span><span></span><span> AMERICAN EAGLE AIR…</span><span></span><span>║</span><span>  1041 </span><span>|</span><span>    1.42 </span><span>|</span><span> **</span><span>                                                 </span><span>║</span><span>        
</span><span></span><span> ENVOY AIR          </span><span></span><span>║</span><span>   883 </span><span>|</span><span>    1.20 </span><span>|</span><span> *   </span><span>                                               </span><span>║</span><span>        
</span><span></span><span> ALASKA AIRLINES    </span><span></span><span>║</span><span>   835 </span><span>|</span><span>    1.14 </span><span>|</span><span> * </span><span>                                                 </span><span>║</span><span>        
</span><span></span><span> REPUBLIC AIRLINES  </span><span></span><span>║</span><span>   804 </span><span>|</span><span>    1.09 </span><span>|</span><span> *</span><span>                                                  </span><span>║</span><span>        
</span><span></span><span> MESA AIRLINES      </span><span></span><span>║</span><span>   693 </span><span>|</span><span>    0.94 </span><span>|</span><span> *</span><span>                                                  </span><span>║</span><span>        
</span><span></span><span> AIR WISCONSIN AIRL…</span><span></span><span>║</span><span>   623 </span><span>|</span><span>    0.85 </span><span>|</span><span> *</span><span>                                                  </span><span>║</span><span>        
</span><span></span><span> PSA AIRLINES       </span><span></span><span>║</span><span>   577 </span><span>|</span><span>    0.79 </span><span>|</span><span> *</span><span>                                                  </span><span>║</span><span>        
</span><span></span><span> PRIVATELY OWNED    </span><span></span><span>║</span><span>   516 </span><span>|</span><span>    0.70 </span><span>|</span><span> *</span><span>                                                  </span><span>║</span><span>        
</span><span></span><span> PHI INC            </span><span></span><span>║</span><span>   491 </span><span>|</span><span>    0.67 </span><span>|</span><span> *     </span><span>                                             </span><span>║</span><span>        
</span><span></span><span> SHUTTLE AMERICA    </span><span></span><span>║</span><span>   467 </span><span>|</span><span>    0.64 </span><span>|</span><span> *</span><span>                                                  </span><span>║</span><span>        
</span><span></span><span>2› faa-wildlife-strikes_OPERATOR_freq|</span><span>                         </span><span></span><span> </span><span>        </span><span></span><span>        F         282 bins </span><span> </span>
</pre>
</div>
</div><div id="step-3-read-visidata-s-manual-page">
<h2>Step 3: Read VisiData’s manual page<a href="#step-3-read-visidata-s-manual-page" title="Permalink to this headline">¶</a></h2>
<p>VisiData’s “<a href="http://visidata.org/man/">quick reference guide</a>” enumerates all of VisiData’s commands and features. You can <a href="http://visidata.org/man/">read it online</a> or access it from anywhere within VisiData by pressing the <kbd>F1</kbd> key or typing <kbd>Control-h</kbd>:</p>
<div>
<pre>vd(1)                        Quick Reference Guide                       vd(1)                      
<span>NAME</span>                     
     <span>VisiData</span> -- a terminal utility for exploring and arranging tabular data                        
<span>SYNOPSIS</span>                 
     <span>vd</span> [<span>options</span>] [<span>input</span> ...]                     
     <span>vd</span> [<span>options</span>] <span>--play</span> <span>cmdlog</span> [<span>-w</span> <span>waitsecs</span>] [<span>--batch</span>] [<span>-o</span> <span>output</span>] [<span>field</span><span></span><span></span><span>=</span><span></span><span></span><span>value</span>]                   
     <span>vd</span> [<span>options</span>] [<span>input</span> ...] <span>+</span><span></span><span></span><span>toplevel</span>:<span>subsheet</span>:<span>col</span>:<span>row</span>                                            
<span>DESCRIPTION</span>              
     <span>VisiData</span> is an easy-to-use multipurpose tool to explore, clean, edit, and restructure          
     data. Rows can be selected, filtered, and grouped; columns can be rearranged, trans-           
     formed, and derived via regex or Python expressions; and workflows can be saved, doc-          
     umented, and replayed.                       
   <span>REPLAY</span> <span>MODE</span>           
     <span>-p</span>, <span>--play</span>=<span>cmdlog</span>       replay a saved <span>cmdlog</span> within the interface                             
     <span>-w</span>, <span>--replay-wait</span>=<span>seconds</span>                    
                             wait <span>seconds</span> between commands                                          
     <span>-b</span>, <span>--batch</span>             replay in batch mode (with no interface)                               
     <span>-o</span>, <span>--output</span>=<span>file</span>       save final visible sheet to <span>file</span> as .tsv                               
:                        
</pre>
</div>
<div>
<p>Note</p>
<p>If you open the manual from within VisiData it will launch in your terminal’s “pager” program —&nbsp;typically the <a href="https://en.wikipedia.org/wiki/Less_(Unix)">less program</a>. To move around:</p>
<table>
<colgroup>
<col width="55%">
<col width="45%">
</colgroup>
<thead>
<tr><th>Keystroke(s)</th>
<th>Action</th>
</tr>
</thead>
<tbody>
<tr><td><kbd>Space</kbd> / <kbd>b</kbd></td>
<td>Scroll forward/backward</td>
</tr>
<tr><td><kbd>/</kbd> + <em>search term</em> + <kbd>Enter</kbd></td>
<td>Search for <em>search term</em></td>
</tr>
<tr><td><kbd>n</kbd> / <kbd>N</kbd></td>
<td>Go to next/previous search match</td>
</tr>
<tr><td><kbd>q</kbd></td>
<td>Exit and return to VisiData</td>
</tr>
</tbody>
</table>
<p>You can find additional commands <a href="https://en.wikipedia.org/wiki/Less_(Unix)#Frequently_used_commands">here</a>.</p>
</div>
</div></div>]]>
            </description>
            <link>https://jsvine.github.io/intro-to-visidata/the-big-picture/visidata-in-60-seconds/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25322091</guid>
            <pubDate>Sun, 06 Dec 2020 08:41:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[An Airbnb Thanksgiving Burglary]]>
            </title>
            <description>
<![CDATA[
Score 39 | Comments 60 (<a href="https://news.ycombinator.com/item?id=25321770">thread link</a>) | @dsr12
<br/>
December 5, 2020 | https://ternaus.blog/incident/2020/12/01/Airbnb-Thanksgiving-Burglary.html | <a href="https://web.archive.org/web/*/https://ternaus.blog/incident/2020/12/01/Airbnb-Thanksgiving-Burglary.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section itemprop="text">
        
        <p><img src="https://habrastorage.org/webt/mm/dk/wp/mmdkwpapgwobqrzcauk213qoglk.png" alt=""></p>



<p>I used <a href="https://www.airbnb.com/">Airbnb</a> for years in Russia, Germany, and the United States. All the time, the experience was great. At some point, I read a <a href="https://amzn.to/3o9JywH">book about Airbnb</a> to understand the company better.</p>

<p>For Thanksgiving week (November 21-29), five of my friends and I rented a house in Las Vegas.</p>

<p>The total price for nine days: <strong>$2543</strong>.</p>

<p>Previously people went to Vegas to spend time in casinos or walk on The Strip. This year, <a href="https://www.worldometers.info/coronavirus/">the pandemic</a> made it impossible.</p>

<p>It was not a problem for us. We did not plan to socialize; we were going rock climbing.</p>

<p><a href="https://www.mountainproject.com/area/105731932/red-rock">Red Rocks</a>, located next to Vegas, is an excellent place for traditional, sport, bouldering, multi-pitch climbing.</p>

<p>The plan was for some people to take days off and climb every day, and for others to work three days remotely and join the gang during the rest.</p>

<h2 id="incident">Incident</h2>

<p>We moved in on Saturday night. The next morning, excited, we woke up at 6am, had breakfast, verified that we closed back and front doors and at 7am drove to the Red Rocks Park.</p>

<p>We had a fantastic day of climbing, but after the sunset, we went home to realize that the window in one of the rooms was open and some of our belongings had disappeared.</p>

<ul>
  <li>Three work Macbook Pro (I do not include the price, they are replaced by our employees for free)</li>
  <li>One personal <a href="https://amzn.to/33uWB3F">Macbook Pro</a> ($1550)</li>
  <li><a href="https://amzn.to/2JCZWqE">Oculus Quest 2</a>. I just bought it. Really cool. Wanted to share the experience. ($399)</li>
  <li><a href="https://amzn.to/2VnyrUt">GoPro Hero 6</a> ($194)</li>
  <li><a href="https://amzn.to/36oMMGz">Lenovo Tab 4, 10.1in Android Tablet</a> ($190)</li>
  <li><a href="https://amzn.to/3lms9is">Sony WH1000XM3 Noise Cancelling Headphones</a> ($348)</li>
  <li><a href="https://amzn.to/3qbPNSm">Bose Quietcontrol 30 Wireless Headphones</a> ($169)</li>
  <li><a href="https://amzn.to/3fVzzIh">Bose Noise Cancelling Wireless Bluetooth Headphones 700</a> ($339)</li>
  <li><a href="https://amzn.to/37qgsSN">BlueTooth ledger</a> ($118)</li>
  <li>Two backpacks. (2 x $100)</li>
</ul>

<p><img src="https://habrastorage.org/webt/kz/an/pd/kzanpdzeno_6rkrjjgbrhbscbbs.jpeg" alt=""></p>

<p>I called the host, told her about the situation. She shared a set of images from the cameras and the next day sent the whole video.</p>

<!-- Courtesy of embedresponsively.com //-->

<p>
    <iframe src="https://www.youtube-nocookie.com/embed/cg3Z9ZxtKGw" frameborder="0" webkitallowfullscreen="" mozallowfullscreen="" allowfullscreen=""></iframe>
  </p>

<p>We believe this is what happened:</p>

<p>At 8:55am, two hours after we left, someone</p>
<ol>
  <li>Openly came to the front door.</li>
  <li>Knocked in the door.</li>
  <li>Waved Lexus car keys at the camera. (We do not have Lexus.)</li>
  <li>Ringed the bell.</li>
  <li>Waited to verify that no one was at home.</li>
  <li>Got to the back of the house.</li>
  <li>Put gloves and balaclava on.</li>
  <li>Checked if the back door was open. It was not.</li>
  <li>Checked if he can open the window. And it was possible.
10 Moved the pool chair below the window.</li>
  <li>Got into the house.</li>
</ol>

<p>We called the police, and in two hours an officer came. He was polite and professional. He got the list of the stolen items, our version of the incident in the written form, and left.</p>

<p>I was curious, how did the burglar open the window? I checked, and the answer was simple: <strong>the lock on the window was not operational.</strong> No need to break anything, anyone can open the window from the outside!</p>

<p>If the weather was warmer, we would probably try to open windows the night we came. In that case we would discover the problem, but the night was cold and we did not touch the windows.</p>

<p>Till this moment, I was chill. Bad things happen. Burglars get into houses, and no one could be protected from it. We were safe in this incident, and from the money perspective, our loss was not huge.</p>

<p>But the fact that the lock on that window was not functioning is an issue (few more windows had the same problem). If the front door lock was broken it would be worse but even windows that could not be locked are sketchy.</p>

<p>In general, I prefer to blame myself for bad things that happen to me. This time I cannot figure out what was my fault. For sure, we could check all the locks in the house, but it is an overkill.</p>

<p>I am ok with making mistakes and paying for them. But this time, we paid for the host’s errors and Airbnb’s as a company.</p>

<ul>
  <li><strong>Host</strong>: the house was not ready for hosting the guests.</li>
  <li><strong>Airbnb</strong>: limitations of the onboarding policy. I believe there is a list of things that the house owner needs to mark to become a host, and either functioning window locks are not on the list, or it is not enforced.</li>
</ul>

<p>After we told the host about our discovery, she sent a person to lock all the windows completely. From now on, no one would be able to open them from inside or outside.</p>



<p>I wanted to reach out to Airbnb, tell them about the situation, and ask about the next steps.</p>

<p>Safety comes first. Hence I assumed that even if you are under stress and your brain is not functioning well, it is obvious how to contact the support team.</p>

<p>To my surprise, it is not the case.</p>

<p>I spent some time on the Airbnb website but could not figure out which phone number I should call.</p>

<p><strong>Message to AirBnb</strong>: It would be great if you simplify the design of the support page. When we talk about safety, it should be about efficiency and not about the visual appeal or cuteness level.</p>

<p>I would like it to be:</p>

<ul>
  <li>I open the Airbnb website =&gt; I see an obvious button/link to the support page.</li>
  <li>I open the support page =&gt; I see an obvious button/link to the hotline phone number.</li>
</ul>

<p>I posted the tweet about the incident and tagged Airbnb and Las Vegas police in it.</p>

<blockquote>— Vladimir Iglovikov (@viglovikov) <a href="https://twitter.com/viglovikov/status/1330741490759266304?ref_src=twsrc%5Etfw">November 23, 2020</a></blockquote>


<p>A miracle happened. Airbnb contacted me and asked for my email to identify the account and to get more details.</p>

<p>My guess is that the Marketing team at Airbnb has alarms that trigger when someone mentions the company on social media.</p>

<p>Finally, after two hours, we got into the conversation about the incident, but the path to get there was not obvious at all.</p>

<p>Imagine how many people got into trouble in similar situations and did not leverage this communication channel?</p>

<p>I got an email:</p>

<blockquote>
  <p>My name is XXX, from the Airbnb claims team.</p>

  <p>I am contacting you regarding the incident that occurred during your reservation with YYY.</p>

  <p>As my colleague informed you in the previous email, we are only able to offer up to $500 for any stolen property. In order to proceed with this refund, I will need the following:</p>

  <p>*Original purchase invoice for the stolen items.</p>

  <p>This is requested as “proof of ownership”, if you don’t have the original purchase invoice, a picture of you where the item can be seen will also be accepted as proof of ownership.</p>
</blockquote>

<p>All this story is not about money. But getting compensated for the host’s and Airbnb’s mistake with cash or AirBnB credits would be nice. It does not address the issue with window locks but sweetens the situation.</p>

<p>We interpreted the email as: “We will compensate up to $500 per stolen item”. Using the numbers from the invoices, it summed to $2600.</p>

<p>We collected invoices, sent them to Airbnb, and got the reply with words: “After additional review, I’m happy to report that we have just released a payout in the amount of $500 to your Airbnb account. You can confirm in your Airbnb Transaction History.”</p>

<p>The guess about up to $500 per item was overly optimistic.</p>

<p>After the end of the stay, I got a message from the host:</p>

<blockquote>
  <p>Hi Vladimir,</p>

  <p>Thank you again for choosing our home for your vacation stay.</p>

  <p>I hope the home met (and even surpassed) your expectations. It was a sincere pleasure hosting you, and I really hope to host you again in the near future. I would be truly grateful for a 5 star review of your stay when you have a spare moment and I would definitely do the same for you.</p>

  <p>Also, please in the private comments if there is something, the home or myself can approve of please let me know.</p>
</blockquote>

<p>I understand that this is a standard template, but under the circumstances, it sounds strange and
does not fit the story and overall experience.</p>

<p>I did not plan to share the actual address of the property. The harm to the renting business could be material. But after this text, I changed my mind. It does not look like the host plans to revise the house and look for things that can and should be fixed. For example, the front door lock is barely working. The door could be open with a good push.</p>



<p>We had a great vacation. The weather was good, and the red rocks are remarkable. We had a lot of fun and plan to come back sometime soon.</p>

<p>Work laptops were replaced. We accepted the loss of personal items.</p>

<p>The Airbnb experience was not as smooth as we expected. Our things got stolen, and even on the other days, we did not feel comfortable leaving belongings in the house.</p>

<p>The host was responsive, but it is not enough. Communicating with guests and collecting money should not be the only responsibility. It is worth inspecting the house and fixing things that do not work as expected proactively, without waiting till the universe gives you feedback.</p>

<p>Overall, I believe that staying at AirBnB is safe, and such incidents are the exception rather than the rule, but, for sure, Airbnb has some work to do to improve communication and increase the guests’ safety. The compensation of $500 for all the stolen items does not look fair either.</p>

<p>I would like to end the story with some action items like: “<strong>Next time, when I rent a place, I will do XXX</strong>.” Nothing reasonable comes to my mind.</p>

<p>When I sit in front of the computer in San Francisco, the only thing that comes to my mind is to build a Face Recognition system and check the burglar’s face in it. Something similar to Clearview. Machine Learning is my expertise; creating such a system is straightforward but will take some time. Tempting. Thinking about it.</p>

<p>What would be your action item after such an experience?</p>

        
      </section></div>]]>
            </description>
            <link>https://ternaus.blog/incident/2020/12/01/Airbnb-Thanksgiving-Burglary.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25321770</guid>
            <pubDate>Sun, 06 Dec 2020 07:14:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Lessons for Early Stage Founders]]>
            </title>
            <description>
<![CDATA[
Score 123 | Comments 22 (<a href="https://news.ycombinator.com/item?id=25321667">thread link</a>) | @sarathyweb
<br/>
December 5, 2020 | https://calv.info/early-stage-lessons | <a href="https://web.archive.org/web/*/https://calv.info/early-stage-lessons">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>In Segmentâ€™s early days, we hit countless problems as a founding team. And at the time, I thought those problems were unique to our own special snowflake of a founding journey. I chalked it up to us being new grads and first-time founders.</p><p>But as I've worked with more and more startups, I've realized just how wrong I was.</p><p>Over the past five years, I've made about 25 different seed-stage investments. In doing so, it's taught me a <em>LOT</em> about the common errors that startup founders make. Even across different industries and levels of experience, I see founders hitting the exact same set of problems we encountered in the early days of Segment!</p><p>This post shares a handful of the top lessons that benefit todayâ€™s early stage founders. Itâ€™s a list of the things I wish weâ€™d figured out earlier at Segment. [1]</p><p>This sounds incredibly boring... but the #1 mistake I see startups making is that they donâ€™t set goals. If you take one thing from this post, it's that you should set goals for where you want to be.</p><p>For the longest time at Segment, we didn't have goals. We moved ahead in various (often random) directions, and we would launch features consistently... but we never really set goals at all.</p><p>As we grew the company, we started to lose momentum. Teams were spending time on a bunch of stuff that frankly just didn't really matter to the overall business.</p><p>It wasn't until we hired our VP Eng, Tido, that we finally started setting focused and audacious product goals. Just by verbalizing where we wanted to go and then grading our results, our velocity improved by an order of magnitude.</p><p>I don't care if you call them OKRs, sprints, or something else entirely. Just set a deadline when you want to have something done and a metric you want to move or some other concrete result.</p><p>When early stage founders do attempt to set goals, I often see them agonize over what specific goals to choose. In practice, a "pretty good goal" is way better than "no goals at all". Perfect is the enemy of good.</p><p>If you don't yet have product-market fit, your goal should probably be getting your first 3-5 customers using the product. If you've hit the level where you now have dozens of users, your goal should be growing by an order of magnitude. It's better to get in the habit of setting and driving towards goals rather than being too worried about their exact semantics. Worst case, you just pick a better goal later.</p><p>A great set of goals answers the question: <em><strong>"what would have to be true in order for us to feel good about our progress at the end of the month?"</strong></em><em> [2]</em></p><p>If each teammate can independently answer "what are our goals for the month?" in the same way, you'll know you've succeeded. If youâ€™re looking for prior art, read <a href="https://www.amazon.com/Measure-What-Matters-Google-Foundation/dp/0525536221">Measure What Matters</a>. </p><p>If you strictly focus on making things true by a certain date, you are bound to make at least some progress towards your end result. </p><p>At the end of the day, every billion-dollar startup is really just the sum of many small deltas.</p><p>Let's get one thing straight: your investors won't know everything. But investors won't know <em>anything</em> if you don't keep them updated on how things are going.</p><p>For the longest time, we were fearful of our Segment investors, to the point that we wouldn't bother sending them emails unless they asked about us. I can say now with confidence that this was 100% the wrong approach.</p><p>We worried that investors would think that we were screwing up (true) and failing (true as well!). And while that might be the case, a founder-friendly investor won't think that way. Investors, especially angels, invested because they believe in <em>you</em>. If I didn't think a team would go somewhere, I wouldn't put money in.</p><p>With each investor, <strong>include the goals you're working towards, as well as the asks for them</strong>. I think monthly is about the right cadence for this in the early days, moving to quarterly around Series A/B time when you start partnering more with a few board members.</p><p>Simply writing the updates should clarify your own thinking tremendously. If it takes you more than 1-2h to put together an update on the most important things happening at the company, it's probably a sign that you should be doing more thinking about the big picture.</p><p>When asking for help, the things that our investors have been able to help us with evolved quite a bit over time. But here's a good rule of thumb for what to ask for:</p><ul><li><p><u>Seed/Pre-seed</u>: user-testing, intros to beta users, hiring</p></li><li><p><u>Series A</u>: hiring, early customers, go-to-market</p></li><li><p><u>Series B/C+</u>: comparables at other companies, senior/exec hires, specific expertise around things like management, infrastructure, systems, etc.</p></li></ul><p>Not all investors will be able to help with everything. But at the very least, sending them information will help you be top of mind. I've lost track of how many times a moment of serendipity where I'm catching up with an old friend has led to a meaningful conversation for a company I've invested in.</p><p>As an extra bonus, the strongest startups send these updates to everyone on their team. It's amazing how much putting the goals in writing helps everyone stay on the same page about what's most important.</p><p>One other note here: take pictures. I now wish we had far more pictures of Segment at every stage of the company. They help turn investor updates into cherished memories.</p><p>Okay, this lesson is taken directly from the YC playbook. And YET, I see so many founders (including YC founders) fail to launch their product. </p><p>If no one notices your launch... just ignore it and then launch again. If you're doing things right, you'll never run out of stuff to launch! [3]</p><p>Why is launching so important? Let me share a personal story...</p><p>We spent about 1.5 years building different iterations of analytics tools. For every iteration, we had a waitlist that users could sign up to use. We personally reached out to the users who we thought were the best fits, and then tried to set up time to use the product. </p><p>The result? Nobody cared. We had no users. We never launched. </p><p>When we finally launched Segment in it's current incarnation, we threw out that approach entirely. We put up a self-service flow, and let anyone who wanted to sign up for it.</p><p>That's when something strange happened... we attracted an entirely new set of developers who just were crawling out of the woodwork and excited to use the new product we'd built. They were coming from companies far outside of SV that we'd never heard of.</p><p>It floored me.</p><p><strong>Lesson learned: the people you happen to be talking to now are probably not the people who have the biggest problem in your space. Do everything you can to reach the folks with the biggest problem, and then, reduce any barriers they might encounter.</strong></p><p>I expect a bunch of you reading this post to ignore this advice, just like we did in the early days. It takes a certain confidence to launch something you've built and put it out there for the world to see. Ultimately though, the rewards are worth it. You'll see users coming from communities you've never even heard of.</p><p>Let me tell you a tale of two startups.</p><p><strong>Startup A</strong> is constantly putting up interesting content on their blog. Their founders are sharing product launches, engineering posts, and creatively brainstorming about what it takes to solve problems in their market.</p><p><strong>Startup B</strong> is operating in stealth. You can't find much about them online, but one of the founders reached out with a nice personalized email mentioning their funding by a top-tier VC. </p><p>Suppose you're looking for a job... do you pick Startup A or Startup B? In my experience, A almost always wins. Momentum is a compounding force.</p><p><strong>Unless you are working in a space that heavily depends on IP, you should probably be publishing more content about what you are doing.</strong> This could be open source, it could be a weekly newsletter, it could be a changelog. [4]</p><p>Whatever it is, it's going to help you both hire <em>and</em> attract customers. So much of the internet is merely about consuming, that just by putting ideas out there, youâ€™ll have a leg up on the competition.</p><p>In the early days of Segment, our <a href="https://segment.com/blog/show-hn-to-series-d/">user acquisition was powered by open source projects and blog posts</a>. But I've seen founders have success with Twitter, Substacks, Podcasts and a variety of different channels.</p><p>If you're looking for inspiration, the <a href="https://railway.app/changelog">Railway</a> and <a href="https://linear.app/changelog">Linear</a> changelogs are epic examples. Companies like <a href="https://baremetrics.com/blog/i-sold-baremetrics">Baremetrics</a> and <a href="https://buffer.com/resources/shareholder-update-q2-2020-and-july/">Buffer</a> differentiated themselves by just being open and honest. <a href="https://stripe.com/blog/globe">Stripe</a> and <a href="https://www.figma.com/blog/behind-the-feature-the-making-of-the-new-auto-layout/">Figma's blogs</a> not only share what they build, but how they built it.</p><p>There are three big inputs that all startups need to continue growing</p><ol><li><p>product capabilities</p></li><li><p>customers and users</p></li><li><p>hiring</p></li></ol><p>I've put them in roughly the order that most teams encounter them. </p><p>Startups begin with a small product that has a modicum of utility. It starts attracting a handful of customers organically. And as more and more customers start using the product, the founders realize that they need extra help to stay on top of all of those requests.</p><p>Remember though, the real goal here is #2. Itâ€™s not the size of your team, itâ€™s the value youâ€™re able to provide to the world. [5]</p><p>I see hiring a big team before you have product-market fit as a red flag. If the company doesn't yet have a set direction, it's going to be harder to pivot with 10 people than it is with 3.</p><p>But, I've worked with startups who have traction and runway... and just seem to be spinning their wheels under load from existing customers.</p><p>I get it. Hiring isn't the most fun, especially for an introvert. It's a lot of interviewing and feeling like there's a lot of rejection. Rejecting people sucks. Losing candidates sucks. For many of our roles at Segment, we've had to talk with 50-100 different people to make an eventual hire.</p><p><strong>If you have 24 months of runway, and a clear list of things youâ€™d do if you had more copies of yourself: you probably aren't spending time to hire the people you need.</strong></p><p>At Segment, my co-founder <a href="https://twitter.com/ivolo">Ilya</a> fulfilled this role. It was back in 2014, we were 12 people at the time, had raised a $10m Series A, and had $1m in revenue.</p><p>Thing…</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://calv.info/early-stage-lessons">https://calv.info/early-stage-lessons</a></em></p>]]>
            </description>
            <link>https://calv.info/early-stage-lessons</link>
            <guid isPermaLink="false">hacker-news-small-sites-25321667</guid>
            <pubDate>Sun, 06 Dec 2020 06:46:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Semantic segmentation algorithms do not generalize to off-road datasets]]>
            </title>
            <description>
<![CDATA[
Score 28 | Comments 4 (<a href="https://news.ycombinator.com/item?id=25321540">thread link</a>) | @srik901
<br/>
December 5, 2020 | https://unmannedlab.github.io/research/RELLIS-3D | <a href="https://web.archive.org/web/*/https://unmannedlab.github.io/research/RELLIS-3D">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
    <p>
<a href="https://www.tamu.edu/"><img src="https://unmannedlab.github.io/assets/images/rellis_3d/tamu_logo.png" alt="Texas A&amp;M University" height="90px" width="450px"></a>    <a href="https://www.arl.army.mil/"><img src="https://unmannedlab.github.io/assets/images/rellis_3d/arl_logo.png" alt="CCDC Army Research Laboratory" height="90px" width="270px"></a></p>
<p>
Peng Jiang<sup>1</sup>, Philip Osteen<sup>2</sup>, Maggie Wigness<sup>2</sup> and Srikanth Saripalli<sup>1</sup><br>
1. <a href="https://www.tamu.edu/">Texas A&amp;M University; </a> 2. <a href="https://www.arl.army.mil/">CCDC Army Research Laboratory</a><br>
<a href="https://unmannedlab.github.io/research/RELLIS-3D">[Website]</a> <a href="https://arxiv.org/abs/2011.12954">[Paper]</a> <a href="https://github.com/unmannedlab/RELLIS-3D">[Github]</a> 
</p>
<h2 id="overview">Overview</h2>
<p>Semantic scene understanding is crucial for robust and safe autonomous navigation, particularly so in off-road environments. Recent deep learning advances for 3D semantic segmentation rely heavily on large sets of training data; however, existing autonomy datasets represent urban environments or lack multimodal off-road data. We fill this gap with RELLIS-3D, a multimodal dataset collected in an off-road environment containing annotations for <strong>13,556 LiDAR scans</strong> and <strong>6,235 images</strong>. The data was collected on the Rellis Campus of Texas A\&amp;M University and presents challenges to existing algorithms related to class imbalance and environmental topography. Additionally, we evaluate the current state of the art deep learning semantic segmentation models on this dataset. Experimental results show that RELLIS-3D presents challenges for algorithms designed for segmentation in urban environments. Except for the annotated data, the dataset also provides full-stack sensor data in ROS bag format, including <strong>RGB camera images</strong>, <strong>LiDAR point clouds</strong>, <strong>a pair of stereo images</strong>, <strong>high-precision GPS measurement</strong>, and <strong>IMU data</strong>. This novel dataset provides the resources needed by researchers to develop more advanced algorithms and investigate new research directions to enhance autonomous navigation in off-road environments.</p>

<p>
<img src="https://unmannedlab.github.io/assets/images/rellis_3d/data_example.png">
</p>
<h3 id="recording-platform">Recording Platform</h3>
<ul>
  <li><a href="https://clearpathrobotics.com/warthog-unmanned-ground-vehicle-robot/">Clearpath Robobtics Warthog</a></li>
</ul>

<h3 id="sensor-setup">Sensor Setup</h3>
<ul>
  <li>64 channels Lidar: <a href="https://ouster.com/products/os1-lidar-sensor">Ouster OS1</a></li>
  <li>32 Channels Lidar: <a href="https://velodynelidar.com/vlp-32c.html">Velodyne Ultra Puck</a></li>
  <li>3D Stereo Camera: <a href="https://nerian.com/products/karmin2-3d-stereo-camera/">Nerian Karmin2</a> + <a href="https://nerian.com/products/scenescan-stereo-vision/">Nerian SceneScan</a></li>
  <li>RGB Camera: <a href="https://www.baslerweb.com/en/products/cameras/area-scan-cameras/ace/aca1920-50gc/">Basler acA1920-50gc</a> + <a href="https://www.edmundoptics.com/p/16mm-focal-length-hp-series-fixed-focal-length-lens/28990/">Edmund Optics 16mm/F1.8 86-571</a></li>
  <li>Inertial Navigation System (GPS/IMU): <a href="https://www.vectornav.com/products/vn-300">Vectornav VN-300 Dual Antenna GNSS/INS</a></li>
</ul>

<p>
<img src="https://unmannedlab.github.io/assets/images/rellis_3d/sensor_setup.png">
</p>
<h2 id="annotated-data">Annotated Data:</h2>
<h3 id="ontology">Ontology:</h3>
<p>With the goal of providing multi-modal data to enhance autonomous off-road navigation, we defined an ontology of object and terrain classes, which largely derives from <a href="http://rugd.vision/">the RUGD dataset</a> but also includes unique terrain and object classes not present in RUGD. Specifically, sequences from this dataset includes classes such as mud, man-made barriers, and rubble piles. Additionally, this dataset provides a finer-grained class structure for water sources, i.e., puddle and deep water, as these two classes present different traversability scenarios for most robotic platforms. Overall, 20 classes (including void class) are present in the data.</p>

<p><strong>Ontology Definition</strong> (<a href="https://drive.google.com/file/d/1K8Zf0ju_xI5lnx3NTDLJpVTs59wmGPI6/view?usp=sharing">Download 18KB</a>)</p>

<h3 id="images-statics">Images Statics:</h3>

<p>
<img src="https://unmannedlab.github.io/assets/images/rellis_3d/img_dist.png">
</p>
<h3 id="image-download">Image Download:</h3>

<p><strong>Image with Annotation Examples</strong> (<a href="https://drive.google.com/file/d/1wIig-LCie571DnK72p2zNAYYWeclEz1D/view?usp=sharing">Download 3MB</a>)</p>

<p><strong>Full Images</strong> (<a href="https://drive.google.com/file/d/1F3Leu0H_m6aPVpZITragfreO_SGtL2yV/view?usp=sharing">Download 11GB</a>)</p>

<p><strong>Full Image Annotations</strong> (<a href="https://drive.google.com/file/d/16URBUQn_VOGvUqfms-0I8HHKMtjPHsu5/view?usp=sharing">Download 94MB</a>)</p>

<p><strong>Image Split File</strong> (<a href="https://drive.google.com/file/d/1zHmnVaItcYJAWat3Yti1W_5Nfux194WQ/view?usp=sharing">44KB</a>)</p>

<h3 id="lidar-scans-statics">LiDAR Scans Statics:</h3>

<p>
<img src="https://unmannedlab.github.io/assets/images/rellis_3d/pt_dist.png">
</p>

<h3 id="lidar-download">LiDAR Download:</h3>

<ul>
  <li>
    <p>LiDAR with Annotation Examples (<a href="https://drive.google.com/file/d/1QikPnpmxneyCuwefr6m50fBOSB2ny4LC/view?usp=sharing">Download 24MB</a>)</p>
  </li>
  <li>
    <p>LiDAR with Color Annotation PLY Format (<a href="https://drive.google.com/file/d/1BZWrPOeLhbVItdN0xhzolfsABr6ymsRr/view?usp=sharing">Download 26GB</a>)</p>
  </li>
  <li>
    <p>LiDAR SemanticKITTI Format (<a href="https://drive.google.com/file/d/1lDSVRf_kZrD0zHHMsKJ0V1GN9QATR4wH/view?usp=sharing">Download 14GB</a>)</p>
  </li>
  <li>
    <p>LiDAR Annotation SemanticKITTI Format (<a href="https://drive.google.com/file/d/1LUmmO2imJ4m5uCtGv1FYusCo-bEPDbBx/view?usp=sharing">Download 174MB</a>)</p>
  </li>
  <li>
    <p>LiDAR Scan Poses files (<a href="https://drive.google.com/file/d/1cyVqJEnlzO9ANOP7hU8GJk28ckPDUSGv/view?usp=sharing">Download 174MB</a>)</p>
  </li>
  <li>
    <p>LiDAR Split File (<a href="https://drive.google.com/file/d/1raQJPySyqDaHpc53KPnJVl3Bln6HlcVS/view?usp=sharing">75KB</a>)</p>
  </li>
</ul>

<h3 id="calibration-download">Calibration Download:</h3>
<ul>
  <li>
    <p>Camera Instrinsic (<a href="https://drive.google.com/file/d/1NAigZTJYocRSOTfgFBddZYnDsI_CSpwK/view?usp=sharing">Download 2KB</a>)</p>
  </li>
  <li>
    <p>Camera to LiDAR (<a href="https://drive.google.com/file/d/1Xra1E8Bc4l5VwjjNm7o41nDFO29nmx-u/view?usp=sharing">Download 3KB</a>)</p>
  </li>
</ul>

<h2 id="benchmarks">Benchmarks</h2>

<h3 id="image-semantic-segmenation">Image Semantic Segmenation</h3>
<p>
<iframe width="560" height="315" src="https://www.youtube.com/embed/vr3g6lCTKRM" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
</p>
<h3 id="lidar-semantic-segmenation">LiDAR Semantic Segmenation</h3>

<p>
<iframe width="560" height="315" src="https://www.youtube.com/embed/wkm8UiVNGao" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
</p>
<h2 id="ros-bag-raw-data">ROS Bag Raw Data</h2>

<p>Data included in raw ROS bagfiles:</p>

<table>
  <thead>
    <tr>
      <th>Topic Name</th>
      <th>Message Tpye</th>
      <th>Message Descriptison</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>/img_node/intensity_image</td>
      <td>sensor_msgs/Image</td>
      <td>Intensity image generated by ouster Lidar</td>
    </tr>
    <tr>
      <td>/img_node/noise_image</td>
      <td>sensor_msgs/Image</td>
      <td>Noise image generated by ouster Lidar</td>
    </tr>
    <tr>
      <td>/img_node/range_image</td>
      <td>sensor_msgs/Image</td>
      <td>Range image generated by ouster Lidar</td>
    </tr>
    <tr>
      <td>/imu/data</td>
      <td>sensor_msgs/Imu</td>
      <td>Filtered imu data from embeded imu of Warthog</td>
    </tr>
    <tr>
      <td>/imu/data_raw</td>
      <td>sensor_msgs/Imu</td>
      <td>Raw imu data from embeded imu of Warthog</td>
    </tr>
    <tr>
      <td>/imu/mag</td>
      <td>sensor_msgs/MagneticField</td>
      <td>Raw magnetic field data from embeded imu of Warthog</td>
    </tr>
    <tr>
      <td>/nerian_stereo/left_image</td>
      <td>sensor_msgs/Image</td>
      <td>Left image from Nerian Karmin2</td>
    </tr>
    <tr>
      <td>/nerian_stereo/right_image</td>
      <td>sensor_msgs/Image</td>
      <td>Right image from Nerian Karmin2</td>
    </tr>
    <tr>
      <td>/odometry/filtered</td>
      <td>nav_msgs/Odometry</td>
      <td>A filtered local-ization estimate based on wheel odometry (en-coders) and integrated IMU from Warthog</td>
    </tr>
    <tr>
      <td>/os1_cloud_node/imu</td>
      <td>sensor_msgs/Imu</td>
      <td>Raw imu data from embeded imu of Ouster Lidar</td>
    </tr>
    <tr>
      <td>/os1_cloud_node/points</td>
      <td>sensor_msgs/PointCloud2</td>
      <td>Point cloud data from Ouster Lidar</td>
    </tr>
    <tr>
      <td>/os1_node/imu_packets</td>
      <td>ouster_ros/PacketMsg</td>
      <td>Raw imu data from Ouster Lidar</td>
    </tr>
    <tr>
      <td>/os1_node/lidar_packets</td>
      <td>ouster_ros/PacketMsg</td>
      <td>Raw lidar data from Ouster Lidar</td>
    </tr>
    <tr>
      <td>/vectornav/GPS</td>
      <td>sensor_msgs/NavSatFix</td>
      <td>INS data from VectorNav-VN300</td>
    </tr>
    <tr>
      <td>/vectornav/IMU</td>
      <td>sensor_msgs/Imu</td>
      <td>Imu data from VectorNav-VN300</td>
    </tr>
    <tr>
      <td>/vectornav/Mag</td>
      <td>sensor_msgs/MagneticField</td>
      <td>Raw magnetic field data from VectorNav-VN300</td>
    </tr>
    <tr>
      <td>/vectornav/Odom</td>
      <td>nav_msgs/Odometry</td>
      <td>Odometry from VectorNav-VN300</td>
    </tr>
    <tr>
      <td>/vectornav/Pres</td>
      <td>sensor_msgs/FluidPressure</td>
      <td>&nbsp;</td>
    </tr>
    <tr>
      <td>/vectornav/Temp</td>
      <td>sensor_msgs/Temperature</td>
      <td>&nbsp;</td>
    </tr>
    <tr>
      <td>/velodyne_points</td>
      <td>sensor_msgs/PointCloud2</td>
      <td>PointCloud produced by the Velodyne Lidar</td>
    </tr>
  </tbody>
</table>

<h3 id="ros-bag-download">ROS Bag Download</h3>

<p><strong>ROS Bag Examples</strong> (<a href="https://drive.google.com/file/d/163pEtjMhcM1OJo36ZOi6_zDHpuPSL8us/view?usp=sharing">2GB</a>)</p>

<p><strong>Sequence 00000</strong>: Synced data: (<a href="https://drive.google.com/file/d/10dHPMCschg1dMeb_Y6pcPvC-HZQZ8_ek/view?usp=sharing">12GB</a>) Filtered data: (<a href="https://drive.google.com/file/d/1d-t4P1idWkfxDEkodBrsbd4B2nAc8rZ3/view?usp=sharing">23GB</a>) Full-stack Raw data: (<a href="https://drive.google.com/drive/folders/1IZ-Tn_kzkp82mNbOL_4sNAniunD7tsYU?usp=sharing">29GB</a>)</p>

<p>
<iframe width="560" height="315" src="https://www.youtube.com/embed/Qc7IepWGKr8" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
</p>

<p><strong>Sequence 00001</strong>: Synced data: (<a href="https://drive.google.com/file/d/1I98lEog0xFFAVVZ_AEBvXzIEcFQ2bGRl/view?usp=sharing">8GB</a>) Filtered data: (<a href="https://drive.google.com/file/d/1LogHRN1ElE2xryILMPU3OtnV6VCnjs52/view?usp=sharing">16GB</a>) Full-stack Raw data: (<a href="https://drive.google.com/drive/folders/1hf-vF5zyTKcCLqIiddIGdemzKT742T1t?usp=sharing">22GB</a>)</p>

<p>
<iframe width="560" height="315" src="https://www.youtube.com/embed/nO5JADjDWQ0" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
</p>

<p><strong>Sequence 00002</strong>: Synced data: (<a href="https://drive.google.com/file/d/1yhohyWOIIf00YLUZ1RT7ouq3B-iaOU91/view?usp=sharing">14GB</a>) Filtered data: (<a href="https://drive.google.com/file/d/1F_8yviLHcAVmBpWEyCITFd1nRgPRmkVX/view?usp=sharing">28GB</a>) Full-stack Raw data: (<a href="https://drive.google.com/drive/folders/1R8jP5Qo7Z6uKPoG9XUvFCStwJu6rtliu?usp=sharing">37GB</a>)</p>

<p>
<iframe width="560" height="315" src="https://www.youtube.com/embed/aXaOmzjHmNE" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
</p>

<p><strong>Sequence 00003</strong>:Synced data: (<a href="https://drive.google.com/file/d/1poY5eaKKhmjUQpF1rsoL4mm4wO7T8CJM/view?usp=sharing">8GB</a>) Filtered data: (<a href="https://drive.google.com/file/d/1HDbtqaYhfeyLoq9UsxOhgCJl2urGVKUc/view?usp=sharing">15GB</a>) Full-stack Raw data: (<a href="https://drive.google.com/drive/folders/1iP0k6dbmPdAH9kkxs6ugi6-JbrkGhm5o?usp=sharing">19GB</a>)</p>

<p>
<iframe width="560" height="315" src="https://www.youtube.com/embed/Kjo3tGDSbtU" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
</p>

<p><strong>Sequence 00004</strong>:Synced data: (<a href="https://drive.google.com/file/d/1xLvai6rorpjxRZXraZK7qPsA1vYMkTHJ/view?usp=sharing">7GB</a>) Filtered data: (<a href="https://drive.google.com/file/d/1usxAjxHrw89R6rMA0GtmYQRtzIP-QGJF/view?usp=sharing">14GB</a>) Full-stack Raw data: (<a href="https://drive.google.com/drive/folders/1WV9pecF2beESyM7N29W-nhi-JaoKvEqc?usp=sharing">17GB</a>)</p>

<p>
<iframe width="560" height="315" src="https://www.youtube.com/embed/lLLYTI4TCD4" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
</p>

<h2 id="full-data-download">Full Data Download:</h2>
<p><a href="https://drive.google.com/drive/folders/1aZ1tJ3YYcWuL3oWKnrTIC5gq46zx1bMc?usp=sharing">Access Link</a></p>

<h2 id="citation">Citation</h2>
<div><div><pre><code>@misc{jiang2020rellis3d,
      title={RELLIS-3D Dataset: Data, Benchmarks and Analysis}, 
      author={Peng Jiang and Philip Osteen and Maggie Wigness and Srikanth Saripalli},
      year={2020},
      eprint={2011.12954},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}
</code></pre></div></div>

<h2 id="collaborator">Collaborator</h2>
<p><a href="https://www.arl.army.mil/"><img src="https://unmannedlab.github.io/assets/images/rellis_3d/arl_logo.png" alt="The DEVCOM Army Research Laboratory"></a></p>

<h2 id="license">License</h2>
<p>All datasets and code on this page are copyright by us and published under the Creative Commons Attribution-NonCommercial-ShareAlike 3.0 License.</p>



<p><a href="https://unmannedlab.github.io/research/SemanticUSL">SemanticUSL: A Dataset for Semantic Segmentation Domain Adatpation</a></p>

<p><a href="https://unmannedlab.github.io/research/LiDARNet">LiDARNet: A Boundary-Aware Domain Adaptation Model for Lidar Point Cloud Semantic Segmentation</a></p>

  </article></div>]]>
            </description>
            <link>https://unmannedlab.github.io/research/RELLIS-3D</link>
            <guid isPermaLink="false">hacker-news-small-sites-25321540</guid>
            <pubDate>Sun, 06 Dec 2020 06:15:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[All good writing is swimming underwater and holding your breath]]>
            </title>
            <description>
<![CDATA[
Score 9 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25321207">thread link</a>) | @thecodrr
<br/>
December 5, 2020 | https://blog.streetwriters.co/how-to-write-good-metaphors/ | <a href="https://web.archive.org/web/*/https://blog.streetwriters.co/how-to-write-good-metaphors/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Metaphors are everywhere;&nbsp;in literature, visual arts, poetry, and films. Language, in a way, itself&nbsp;is a metaphor. But try to make one on the fly, and you will find out it is not easy. Creating a metaphor requires ingenuity and care. A small mistake can make a metaphor clumsy. So how does one write a good metaphor?&nbsp;Let’s find out.</p><h2>Why Metaphors are Important</h2><p>Metaphors make us understand things better. When feelings are involved or when something happens which has no proper words in our vocabulary, we need something to communicate our experience. Metaphors come in handy in such situations. For example, author F. Scott Fitzgerald wanted to describe good writing. He could simply say that good writing was hard or good writing is very difficult. But he chose to say it like this:</p><p><em>All good writing is swimming underwater and holding your breath.</em></p><p>The metaphor&nbsp;“swimming underwater while holding breath” opens a door for us into the experience of Fitzgerald as a writer. That was a very difficult thing to convey in plain words. A whole paragraph might have not sufficed. But here a metaphor has conveyed the meaning completely in a single sentence. Metaphors help us convey meaning by using similarities in different objects and experiences. They relate things with one another and the result is a new understanding of a certain thing. All good poetry and literature do this to create new meanings. Another example is this beautiful metaphor by Shakespeare:</p><blockquote><p>All the world's a stage,<br>And all the men and women merely players;<br>They have their exits and their entrances;<br>And one man in his time plays many parts.</p><p><em>As You Like It</em>, William Shakespeare</p></blockquote><p>Metaphors help us use all of our senses in reading a sentence. They make the experience of language more immersive. Take this sentence as an example:</p><blockquote><p>Time has not stood still. It has washed over me, washed me away as if I'm nothing more than a woman of sand, left by a careless child too near the water.</p><p><em>The Handmaid's Tale</em>, Margaret Atwood</p></blockquote><p>The writer could simply have said that time has changed me. But the use of sand and water as metaphors has given the whole experience a life of its own. We can hear in our minds the sound of waves when reading the sentence. We can imagine a woman of sand. Therefore, metaphors give a deeper meaning to our words. They can convey meanings for which sometimes whole pages are necessary and sometimes even a book is not enough.</p><blockquote><p>I'm a little pencil in the hand of a writing God.</p><p>Mother Teresa</p></blockquote><p>In this small sentence, Mother Teresa has conveyed the whole of her faith. We can get a glimpse of her intimate relationship with God. We can sense her metaphysical experience. This was not possible without the use of a metaphor.</p><p>Along with that, plain words can be boring for our minds. Our minds hate repetitiveness and mundaneness and loves newness and ingenuity. Metaphors give us this freshness and livens ordinary language. Language becomes more interesting.</p><blockquote><p>She herself is a haunted house. She does not possess herself; her ancestors sometimes come and peer out of the windows of her eyes and that is very frightening.</p><p><em>The Bloody Chamber, </em>Angela Carter</p></blockquote><p>Simply saying that there is an eerie feeling attached to her the writer could have told us about the character but using a metaphor makes it more interesting and memorable. In addition to that, Metaphors add vagueness and abstractedness to our language. This gives readers free rein to make their own interpretations.</p><blockquote><p><em>There's a bluebird in my heart that<br></em><em>wants</em><em> to get out<br></em><em>but</em><em> I'm too tough for him,<br></em><em>I say, stay in there, I'm not going<br></em><em>to</em><em> let anybody see<br></em><em>you</em><em>.</em></p><p><em>Bluebird</em>, Charles Bukowski</p></blockquote><p>Nobody has a clear idea of what the bluebird is in this poem and so people make their interpretations. Metaphors give us the freedom to read works in the context of our own Worldview.</p><h2>How to Write Good Metaphors?</h2><p>First of all, start thinking about the thing or experience you want to express. Concentrate on the idea and think about it deeply. Understand it thoroughly. How do you feel about the whole idea?</p><p>For example, you want to describe the scene of someone waking up for the first time to the sound of the coming train. Lean into the experience of someone peacefully sleeping in a cozy room under blankets in a comfy bed. Now imagine a train passing over with an ear-shattering sound. What will the character feel like? Imagine it. Now can you compare it to something else that is similar in its sudden experience?</p><p>For me, the scene of a car suddenly breaking through the bedroom wall is similar so I would construct my metaphor around that imagery.</p><p><em>He woke up and thought a car had crashed in his bedroom. Everything was moving. His heart was pumping. "Oh! It's the train!" he let out a sigh and shook his head.</em></p><p>Secondly, try using original metaphors in your writing or ones that are rare. Commonly used metaphors are dead in a sense. Some dead metaphors are given here as an example:</p><ul><li>It's raining cats and dogs.</li><li>I'm visiting an old flame.</li><li>He's loose cannon.</li><li>She found herself behind the eight balls.</li><li>He drives me up a wall.</li><li>She saw the light at the end of the tunnel.</li><li>Ticking time bomb</li><li>Tip of the iceberg</li><li>Slippery slope</li><li>Going the extra mile</li><li>Early bird</li><li>Icy personality</li><li>Turning in one's grave</li><li>About to explode (from anger)</li></ul><p>Here are some more complex examples of metaphors. Read them carefully so you can get an idea of how a metaphor works.</p><p><em>1. Books are the mirrors of the soul.</em></p><p>Virginia Woolf describes here the connection between an author and his/her books. Books describe the inner thoughts of the author's mind. That is an experience similar to seeing one's soul. A mirror reflects everything that is in front of it. It does not lie. This small sentence combines these two concepts perfectly to convey a beautiful meaning.</p><p>2. <em>"</em><em>But soft, what light through yonder window breaks? It is the east, and Juliet is the sun!"</em></p><p>Shakespeare is trying to describe the feeling of love that Romeo had for Juliet. The sun is a classic metaphor used in ancient literature to describe a lover.</p><p>3. <em>The parents looked upon Matilda in particular as nothing more than a scab. A scab is </em><em>something you have to put up with until the time comes when you can pick it off and flick </em><em>it away.</em></p><p>The author here depicts the anger Matilda's parents felt for their child using “a scab on skin”. A person puts up with it because it's painful and messy to remove it before time.</p><p>4. <em>"O Lord, You are our Father, We are the clay, and You, our potter; And all of us are the work of Your hand."</em></p><p>In this verse of the Bible, the feeling of helplessness and the might of the All-Mighty God is described. Helplessness is compared with the inertness of the clay. And the potter's hands are the workings of God.</p><p>5. <em>Alas,</em><em> and yet what are you, my written and painted thoughts! It is not long ago that you were still so many-</em><em>coloured</em><em>, young, and malicious, so full of thorns and hidden spices you made me sneeze and laugh and now? You </em><em>have already taken off your novelty and some of you, I fear, are on the point of becoming truths: they already look so immortal, so pathetically righteous, so boring! And has it ever been otherwise? For what things do we write and paint, we mandarins with </em><em>Chinese brushes, we immortalizers of things which let themselves </em><em>be</em><em> written, what alone are we capable of painting? Alas, only that which is about to wither and is beginning to lose its fragrance! Alas, only storms departing exhausted and feelings grown old and yellow! Alas, only birds strayed and grown weary in flight </em><em>who</em><em> now let themselves be caught in the hand in our hand! We immortalize that which cannot live and fly much longer, weary and mellow things alone! And it is only your afternoon, my written and painted thoughts, for which alone I have the </em><em>colours</em><em>, many </em><em>colours</em><em> perhaps, many many-</em><em>coloured</em><em>&nbsp;</em><em>tendernesses</em><em> and fifty yellows and browns and greens and reds: but no one will divine from these how you looked in your morning, you sudden sparks and wonders of my solitude, you my old beloved wicked thoughts!</em></p><p>Here Nietzsche is describing the thoughts in the human mind which are immortal, ever-changing with infinite possibilities, and how impossible it is to define them truly words.</p><h2>Conclusion</h2><p>Good metaphors spice up any piece of art, be it a painting or a poem or a novel. Some writers use whole characters as forms of metaphors, others use symbolism. Learning to write a good metaphor can be a difference between a good piece and a great piece. Here are some other resources you can consult:</p><ol><li><a href="https://prowritingaid.com/Metaphors">Metaphor - The Grammar Guide</a></li><li><a href="https://www.liminalpages.com/write-powerful-metaphors">How to Write Powerful Metaphors</a></li></ol></div></div>]]>
            </description>
            <link>https://blog.streetwriters.co/how-to-write-good-metaphors/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25321207</guid>
            <pubDate>Sun, 06 Dec 2020 05:08:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Traits of the Financially Independent]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 5 (<a href="https://news.ycombinator.com/item?id=25320594">thread link</a>) | @adrian_monk
<br/>
December 5, 2020 | https://www.thriftythoughts.io/fire-movement/ | <a href="https://web.archive.org/web/*/https://www.thriftythoughts.io/fire-movement/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            
<div>
    <main>
            <article>
    
    <div>
                <h3 id="who-makes-up-the-fi-re-movement">Who makes up the FI/RE Movement?</h3><p>Despite its relatively recent popularity, the FI/RE movement is still in many ways ambiguous. Who are these millionaires next door and what common traits are shared among them? Fortunately based off of data obtained from a survey conducted of nearly 1,400 individuals in the r/financialindependence subreddit, we can get a bit more insight into not only those who are pursuing FI/RE, but also those who have already achieved it. Special thanks to u/melonbalon for conducting the survey in the first place!</p><!--kg-card-begin: html--><!--kg-card-end: html--><figure><img src="https://www.thriftythoughts.io/content/images/2020/12/UNCLAIMED-PROPERTY--7-.png" alt="" srcset="https://www.thriftythoughts.io/content/images/size/w600/2020/12/UNCLAIMED-PROPERTY--7-.png 600w, https://www.thriftythoughts.io/content/images/2020/12/UNCLAIMED-PROPERTY--7-.png 800w" sizes="(min-width: 720px) 720px"></figure><h3 id="insights-obtained">Insights Obtained</h3><p>So much data was obtained as part of this survey and the figures reported in the above visual only scratch the surface of valuable insights that could be drawn. Of note however are a couple items:</p><ol><li><strong>Commute times are very low.</strong> Over 20% of respondents noted that it takes last than 10 minutes to get to work. Additionally, nearly 70% had a commute of less than 30 minutes. It's likely that these smaller commute times result in less transportation costs which could be a motivating factor.</li><li><strong>Individuals who have already FI/RE'd are highly educated.</strong> Not only did nearly 85% of respondents have a college degree, but an additional 7% had multiple graduate degrees. Perhaps these individuals have more time for additional schooling post-retirement. It also could be the case that this additional education helped them FI/RE in the first place. Regardless, more schooling was expected in comparison to the respondent group that had not yet FI/RE'd simply given the older average age. </li><li><strong>Respondents favored urban and suburban environments equally. </strong>Additionally this ratio remained constant in both the pursuing FI/RE and FI/RE'd populations. I would have expected far more suburban living, but perhaps the increased cost of living in an urban environment is offset enough by the reduced transportation costs to be appealing.</li></ol>
                            <section>
                                <h2>Enjoying these posts? Subscribe for more</h2>
                                
                                <br>
                                
                            </section>
    </div>
        
</article>                            </main>
</div>
        </div></div>]]>
            </description>
            <link>https://www.thriftythoughts.io/fire-movement/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25320594</guid>
            <pubDate>Sun, 06 Dec 2020 02:50:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[iPhone Is Inferior to Android]]>
            </title>
            <description>
<![CDATA[
Score 9 | Comments 27 (<a href="https://news.ycombinator.com/item?id=25320572">thread link</a>) | @technojunkie
<br/>
December 5, 2020 | https://www.arencambre.com/iphone-is-inferior-to-android/ | <a href="https://web.archive.org/web/*/https://www.arencambre.com/iphone-is-inferior-to-android/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<p><strong>UPDATE: While these are valid reasons, <a href="https://www.arencambre.com/iphones-are-inferior-to-android-phones-the-value/">scoring them suggests I should still switch to the iPhone</a>.</strong></p>



<p>I am on day 10 of using an iPhone. I came from the Android world.</p>



<p>The iPhone is deficient. I am leaning towards returning it.</p>




<h2><span id="Context"></span>Context<span></span></h2>



<p>Ten days ago, I switched from a Pixel 4 XL to the iPhone 12 Pro Max. I went with this iPhone model because it’s similarly sized to the Pixel 4 XL, plus I value photography.</p>



<h3><span id="Why_I_switched"></span>Why I switched<span></span></h3>



<p>I made the switch due to intellectual curiosity, to overcome limitations of the Pixel 4 XL, and to get on board with the rest of my family.</p>



<p>I am questioning this decision. While the iPhone helps me escape two Pixel 4 XL limitations, iOS’s regressions from Android feel like a heavy burden.</p>



<p>I am inside Apple’s return window, so I can return the iPhone for a full refund. It is tempting.</p>



<h3><span id="Android_only_has_two_worthwhile_brands"></span>Android only has two worthwhile brands<span></span></h3>



<p>My analysis relies heavily on my experience with the Pixel 4 XL. Much of what I say about Android applies to to top-tier Android manufacturers. Among the requirements of top-tier manufacturers is they deliver highly vanilla Android. This includes <a href="https://store.google.com/us/magazine/compare_pixel">Pixel </a>(Google’s in-house brand), <a href="https://www.oneplus.com/">OnePlus</a>, and more.</p>



<p><strong>Samsung is not a top-tier phone manufacturer.</strong> Its hardware is decent, but it has bad software. Samsung replaces Android’s best features with <a href="https://www.samsung.com/us/support/answer/ANS00078945/">poor, fussy substitutes</a>. It also adds annoying, pointless bloat. In other words, just to differentiate its brand, it <em>devalues its brand </em>by trashing up its core software.</p>



<p>The Bixby assistant is the best example of Samsung’s stupidity. It’s awful. Samsung killing Bixby might signal that it’s ready to take Android seriously. Until then, Samsung is simply not a top-tier manufacturer.</p>



<p>The Samsung example is important because Apple is the same: <strong>great hardware, bad software</strong>.</p>



<h2><span id="A_note_about_definitions"></span>A note about definitions<span></span></h2>



<p>The article’s language is sometimes imprecise. Truly, if you’re comparing Android to something in the Apple ecosystem, it would be iOS. But that is not how people talk about their phones, so I am using loose terminology in places.</p>



<p>If you’re a True Nerd™ and find my word use upsetting, just associate my word with its parent ecosystem.</p>



<p>This is how several terms are correctly used:</p>



<figure><table><tbody><tr><td><strong>Word category</strong></td><td><strong>Android phone ecosystem</strong></td><td><strong>Apple phone ecosystem</strong></td></tr><tr><td>Operating system</td><td>Android</td><td>iOS</td></tr><tr><td>Manufacturers</td><td>Google, OnePlus, and more</td><td>Apple</td></tr><tr><td>Phone brand</td><td>Pixel (Google), OnePlus, and more</td><td>iPhone</td></tr><tr><td>Phone model (current generation)</td><td>For Pixel: Pixel 4A, Pixel 4A 5G, Pixel 5. For OnePlus: OnePlus 8T, OnePlus 8 Pro, OnePlus 8, OnePlus 7T. There are more current model from other manufacturers.</td><td>iPhone 12, iPhone 12 Mini, iPhone 12 Pro, iPhone 12 Pro Max, iPhone SE, and more</td></tr></tbody></table></figure>



<p>Also, some Android features I enjoy are Pixel-specific. While Google freely distributes Android to other manufactures, it reserves some newer features for its own Pixel phones. Sometimes I may mistakenly generalize a Pixel-specific feature as an Android feature. Since Pixel-specific features often eventually end up on other phones, associating Pixel with Android is probably correct in the long run.</p>



<h2><span id="Where_Android_is_better"></span>Where Android is better<span></span></h2>



<p>Android is well thought out. It has a great UX. I really miss its great design.</p>



<h3><span id="Call_screening_Android_wins"></span>Call screening: Android wins<span></span></h3>



<p>Android’s <a href="https://support.google.com/phoneapp/answer/9118387?hl=en">built-in call screener</a> is excellent. It blocks calls it is confident are garbage. If the caller is in a gray area, it will ask the caller first to state the reason for calling, then show that to me on the screen where I can accept the call. And even if does nothing to the call, I can still use a <strong>Screen Call </strong>button to kick the call to a digital assistant, where the caller is invited to state the reason for the call.</p>



<figure><img src="https://www.xda-developers.com/files/2019/11/call_screen_assistant.jpg" alt=""><figcaption>Example call-screen opportunity. (This image shamelessly <a href="https://www.xda-developers.com/automatic-call-screen-google-pixel-phones/">stolen</a> from XDA Developers.)</figcaption></figure>



<p><strong>NOTE:</strong> This may be mostly a Pixel feature right now. Google plans to <a href="https://www.androidpolice.com/2020/09/08/google-phone-will-soon-be-downloadable-from-play-store-verified-calls-feature-rolling-out/">extend</a> this to more Android brands. Because Samsung uses its own, poor quality dialer, it’s unclear how Samsung will get this feature.</p>



<p><strong>Why iPhone sucks:</strong> Apple only has a <a href="https://support.apple.com/en-us/HT207099">crude tool</a>: block callers not in your contacts. You can’t report calls or texts as spam.</p>



<p>If you want to be more selective than Apple’s crude tool, and instead block specific spammers, you must add the spammers to your contacts. That’s dumb; it just clutters your contacts!</p>



<p>You can also subscribe to a third party service. That’s grating, because the phone should manage that itself, given that this is a years-old problem.</p>



<h3><span id="Browser_ad_blocking_Android_wins"></span>Browser ad blocking: Android wins<span></span></h3>



<p>On Android, browser ad-blocking is easy: Switch to the free <a href="https://play.google.com/store/apps/details?id=org.mozilla.firefox&amp;hl=en_US&amp;gl=US">Mozilla Firefox browser</a>. Inside Firefox, add the free <a href="https://addons.mozilla.org/en-US/firefox/addon/ublock-origin/">uBlock Origin extension</a>. Then set Firefox as your default browser for happy browsing. Simple! (Android’s Chrome browser does not support extensions.)</p>



<p><strong>Why iPhone sucks:</strong> Install the <a href="https://apps.apple.com/us/app/adguard-adblock-privacy/id1047223162">AdGuard app</a>, jump through several fussy hoops in the <strong>Settings </strong>console’s <strong>Safari </strong>area, and get nagged about going to paid AdGuard. </p>



<p>Maybe I am fussing too much. The hassle is a one-time step, and AdGuard seems to work decently.</p>



<p>Part of the point of ad-blocking is to make YouTube worthwhile. That leads to my next point…</p>



<h3><span id="YouTube_ad_blocking_Android_wins"></span>YouTube ad blocking: Android wins<span></span></h3>



<p>To block YouTube’s ads on Android, just view all YouTube content in Firefox with the uBlock Origin extension. Easy!</p>



<p><strong>Why iPhone sucks:</strong> While Safari + AdGuard = ads blocked on YouTube, it’s still a major regression from Android:</p>



<ul><li>Video quality <a href="https://www.reddit.com/r/apple/comments/aom6ge/why_does_youtube_only_go_up_to_720p_on_mobile/">maxes out at 720p</a>.</li><li>Every YouTube video in Safari starts as low quality (360p). To change it, on <em>every video you watch</em>, you must wade through the settings menu, and it has to be done before you switch to full screen, because of the next bullet’s deficiency.</li><li>When you’re viewing a video in a browser and switch to full screen, Apple cancels the website’s native video player and forces you to use iOS’s default, bad, native video player. Want to double-tap and skip 10 seconds? Want to access the site’s in-video settings? Want any feature not supported by iOS’s dumbed down video control? Forget it! iOS nukes it in full-screen mode.</li></ul>



<p>Firefox Focus is not a solution. It doesn’t fix iOS’s deficiencies.</p>



<h3><span id="Universal_back_button_Android_wins"></span>Universal back button: Android wins<span></span></h3>



<p>For at least a decade, Android has had a back button at the bottom of all windows. This means the valuable concept of “take me back” is baked into the Android paradigm. Need to return where you were, in <em>any</em> app? Just tap the back button, on bottom left of the screen. Or use the back gesture (next section).</p>



<p><strong>Why iPhone sucks:</strong> The back button is a mess.</p>



<p>In Safari, it’s on bottom left.</p>



<p>In most other apps, top left.</p>



<p>To get to the prior app that sent you to the current app, find a tiny button between the app’s top-left back button and the clock. And good luck on that; too much of the time, iOS lists a wrong or irrelevant prior app, especially if you got to your current app from a system notification.</p>



<figure><img loading="lazy" width="1024" height="449" src="https://www.arencambre.com/wp-content/uploads/2020/12/image-1024x449.png" alt="" srcset="https://www.arencambre.com/wp-content/uploads/2020/12/image-1024x449.png 1024w, https://www.arencambre.com/wp-content/uploads/2020/12/image-300x132.png 300w, https://www.arencambre.com/wp-content/uploads/2020/12/image-768x337.png 768w, https://www.arencambre.com/wp-content/uploads/2020/12/image.png 1225w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>Even though the mini back button says otherwise, I was not sent to GroupMe by NPR One! I was sent there by a notification I tapped while NPR One was active.</figcaption></figure>



<p>Even worse, because the non-Safari back buttons are on the opposite end of the phone from where you hold it, you’re less precise with finger positioning. Therefore, when you intend to use a “back” feature, you’ll instead make the phone think you’re trying to pull down the notification area.</p>



<h3><span id="Gestures_Android_wins"></span>Gestures: Android wins<span></span></h3>



<p>Building on its native strengths, Android’s <a href="https://support.google.com/pixelphone/answer/6073614?hl=en">gestures</a> are excellent. They edge out iOS with the back gesture, which I use a lot. No matter what app you’re in, swipe in from the phone’s right to go back. Simple!</p>



<p><strong>Why iPhone sucks:</strong> Without a “back” gesture, you’re stuck fumbling with iOS’s haphazard back buttons.</p>



<h3><span id="Exiting_apps_Android_wins"></span>Exiting apps: Android wins<span></span></h3>



<p>In Android, you can exit apps with the back gesture or swiping up from the bottom. The back gesture is superior, because it can’t be confused with other gestures.</p>



<p><strong>Why iPhone sucks:</strong> Your only choice is the swipe-up gesture, which sometimes conflicts with normal swipes one does in apps.</p>



<p><strong>NOTE: </strong>I don’t literally mean app-exiting in the computer-science sense. I mean more in a common-parlance sense: you’re out of the app and back to the home screen, or in another app that may have called the current app. One an app is no longer visible, and running in the background, Android and iOS both do fine managing it.</p>



<h3><span id="Ambient_display_Android_wins"></span>Ambient display: Android wins<span></span></h3>



<p>The Pixel has a great feature: even when you’re not using the phone, it shows the current time on the screen, along with some other useful information. This takes minimal power: thanks to the OLED screen, the main power use is when it lights up the specific pixels that show the time.</p>



<figure><img loading="lazy" width="768" height="1024" src="https://www.arencambre.com/wp-content/uploads/2020/12/image-1-768x1024.png" alt="" srcset="https://www.arencambre.com/wp-content/uploads/2020/12/image-1-768x1024.png 768w, https://www.arencambre.com/wp-content/uploads/2020/12/image-1-225x300.png 225w, https://www.arencambre.com/wp-content/uploads/2020/12/image-1-1152x1536.png 1152w, https://www.arencambre.com/wp-content/uploads/2020/12/image-1-1536x2048.png 1536w" sizes="(max-width: 768px) 100vw, 768px"><figcaption>Ambient display. This Pixel 4 XL is not active. It’s basically in sleep mode. It uses minimal power to give me useful information on its OLED screen.</figcaption></figure>



<p><strong>Why iPhone sucks:</strong> While the iPhone also has an OLED screen, Apple has no similar feature. You have to tap the phone to see the time, which lights up the whole screen.</p>



<h3><span id="Treating_me_like_an_adult_Android_wins"></span>Treating me like an adult: Android wins<span></span></h3>



<p>Android’s UX language is simply clean. It’s intuitive, simple, and it just works.</p>



<p><strong>Why iPhone sucks:</strong> iOS’s UX feels like a cartoon spoof of a phone OS. Naturally garish colors, toddler-like corner-rounding, goofy font sizes, etc. It’s like iOS’s design semantics were intended to tussle with our innate senses. Barf!</p>



<figure><img loading="lazy" width="473" height="1024" src="https://www.arencambre.com/wp-content/uploads/2020/12/image-2-473x1024.png" alt="" srcset="https://www.arencambre.com/wp-content/uploads/2020/12/image-2-473x1024.png 473w, https://www.arencambre.com/wp-content/uploads/2020/12/image-2-139x300.png 139w, https://www.arencambre.com/wp-content/uploads/2020/12/image-2-768x1662.png 768w, https://www.arencambre.com/wp-content/uploads/2020/12/image-2-710x1536.png 710w, https://www.arencambre.com/wp-content/uploads/2020/12/image-2-947x2048.png 947w, https://www.arencambre.com/wp-content/uploads/2020/12/image-2.png 1284w" sizes="(max-width: 473px) 100vw, 473px"><figcaption>When a toddler breaks out crayons and designs a phone, this is what you get.</figcaption></figure>



<h3><span id="Application_organization_Android_wins"></span>Application organization: Android wins<span></span></h3>



<p>All newly installed Android apps go into the app drawer. This is an alphabetized list of apps, accessed by swiping up from a home screen (when you’re not inside an app).</p>



<figure><img loading="lazy" src="https://www.arencambre.com/wp-content/uploads/2020/12/image-4-485x1024.png" alt="" width="485" height="1024" srcset="https://www.arencambre.com/wp-content/uploads/2020/12/image-4-485x1024.png 485w, https://www.arencambre.com/wp-content/uploads/2020/12/image-4-142x300.png 142w, https://www.arencambre.com/wp-content/uploads/2020/12/image-4-768x1621.png 768w, https://www.arencambre.com/wp-content/uploads/2020/12/image-4-728x1536.png 728w, https://www.arencambre.com/wp-content/uploads/2020/12/image-4-970x2048.png 970w, https://www.arencambre.com/wp-content/uploads/2020/12/image-4.png 1440w" sizes="(max-width: 485px) 100vw, 485px"><figcaption>Android app drawer. Simple. Organized. Appropriate icon density.</figcaption></figure>



<p>Suppose you have 150 apps. That is 30 rows of five icons each, all in alpha sort. It’s fast to find any application.</p>



<p><strong>Why iPhone sucks:</strong> It wasn’t until <em>this year</em> that Apple delivered its poor ripoff of the app drawer. Before then, people were stuck with jumbled messes of icons on multiple home-screen pages.</p>



<p>Apple’s app-drawer ripoff …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.arencambre.com/iphone-is-inferior-to-android/">https://www.arencambre.com/iphone-is-inferior-to-android/</a></em></p>]]>
            </description>
            <link>https://www.arencambre.com/iphone-is-inferior-to-android/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25320572</guid>
            <pubDate>Sun, 06 Dec 2020 02:45:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Urgent appeal to Paul Graham, etc.: Please help kickstart Common Lisp revolution]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 32 (<a href="https://news.ycombinator.com/item?id=25320063">thread link</a>) | @Hexstream
<br/>
December 5, 2020 | https://sponsors.hexstreamsoft.com/urgent-appeal/#paul-graham | <a href="https://web.archive.org/web/*/https://sponsors.hexstreamsoft.com/urgent-appeal/#paul-graham">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

      

      <nav>
        <ul>
          <li><a href="#context">Context</a></li>
        </ul>
        <ul>
          <li><a href="#lispworks-and-franz">LispWorks and Franz</a></li>
          <li><a href="#common-lisp-foundation">Common Lisp Foundation</a></li>
          <li><a href="#paul-graham">Paul Graham</a></li>
          <li><a href="#planck-ez">Planck EZ (Ergodox, ZSA)</a></li>
          <li><a href="#everyone-else">Everyone else</a></li>
        </ul>
      </nav>

      

      <section id="context">

        

        <p><a href="https://github.com/sponsors/Hexstream" target="_blank">I am trying to kickstart the Common Lisp revolution from 28 november to <strong>10 december 2020</strong></a>, and as of 5 december 2020, it did look like we were going to run out of time, so this is my last-ditch attempt at rectifying the situation before it's too late. <strong><em><a href="https://github.com/sponsors/Hexstream" target="_blank">Please support the Common Lisp Revival 2020 Fundraiser!!!</a></em></strong></p>

        <p>
          Since we are on such a tight deadline, I am soliciting donations of <strong>1000$ or more</strong> from the following organizations and people. This is the only way we can realistically make it in time.
          <br>
          I can confirm that they are all eligible for <a href="https://sponsors.hexstreamsoft.com/about/#perks" target="_blank">Advanced Perks</a>, including <a href="https://sponsors.hexstreamsoft.com/about/#lifetime-perks" target="_blank">Lifetime Perks</a>.
        </p>

        <p>
          Please make sure to <a href="https://github.com/sponsors/Hexstream" target="_blank">sponsor me</a> from an account able to give out doublers, you should see a banner confirming this at the top (when logged in).
          <br>
          Also <strong>beware of prorating</strong>, which might significantly cut down your contribution if you are not careful. Any prorating will be announced on the checkout page, and you may need to sponsor at a higher tier to arrive at the amount that you intended to contribute.
        </p>

        <p>I wrote this page's core content in one day, so please excuse any sloppy writing.</p>

      </section>

      <section id="lispworks-and-franz">

        

        <p>Dear LispWorks, Dear Usha, Dear Franz, Dear Jans,</p>

        <p>
          One of the biggest divisions within the Common Lisp community remains largely unacknowledged. That is <strong>the division between <em>Open Source and Proprietary</em></strong>.
          <br>
          There is tremendous untapped, latent energy to unlock to help make Common Lisp successful, and we just need a slight paradigm shift to do so.
        </p>

        <p>
          <a href="https://twitter.com/HexstreamSoft/status/1213964177657794577" target="_blank" rel="noreferrer">We can make Common Lisp a top 5 programming language by 2040</a>, and this will be much easier to achieve if we unify our forces.
          <br>
          <strong><a href="https://cv.hexstream.expert/" target="_blank">Through my work</a>, I am working to dramatically expand the Common Lisp community, which is guaranteed to greatly benefit your business</strong>.</p>

        <p>
          <strong>You could boost my productivity almost beyond imagination just by providing me a tiny fraction of a normal salary!</strong>
          <br>
          For instance, 1000$/month would be basically infinite money in my current situation. How about you each contribute 500$/month for 6 months as a trial?
          <br>
          Of course, please consider starting with a large donation to the <a href="https://github.com/sponsors/Hexstream" target="_blank">Common Lisp Revival 2020 Fundraiser</a> before <strong>10 december 2020</strong>, as GitHub will double your contribution!
        </p>

        <p>
          I also urge you to open source more of your technology, not even necessarily out of pure generosity, but simply because it makes so much business sense!
          <br>
          For instance, you could send SHOCKWAVES throughout the world simply by open sourcing <a href="http://www.lispworks.com/products/capi.html" target="_blank">CAPI</a> and <a href="https://allegrograph.com/products/allegrograph/" target="_blank">AllegroGraph</a>!
          <br>
          Inherently, the more you open source, the more you stand to benefit from the great Open Source Marketing Machine!
        </p>

        <p>In fact, I almost wonder if you should also open source LispWorks and Allegro Common Lisp and transform yourself into a services company like Red Hat? It's really hard to compete with world-class open source implementations like <a href="http://sbcl.org/" target="_blank">SBCL</a> these days. But obviously, this would be a more long-term project, and I don't presume to understand your business better than you do or tell you what to do. I'm just suggesting ideas. We stand to greatly benefit from a healthy exchange of ideas.</p>

        <p>
          Please check out the details about <a href="https://sponsors.hexstreamsoft.com/about/" target="_blank">HexstreamSoft Sponsors</a>. I think you may find them very compelling.
          <br>
          You are obviously eligible for <a href="https://sponsors.hexstreamsoft.com/about/#perks" target="_blank">Advanced Perks</a>, including <a href="https://sponsors.hexstreamsoft.com/about/#lifetime-perks" target="_blank">Lifetime Perks</a>. These grant you great visibility on <a href="" target="_blank">HexstreamSoft</a>, <a href="https://cv.hexstream.expert/#hexstreamsoft-alexa-stats" target="_blank">the #1 Common Lisp site</a>!
        </p>

      </section>

      <section id="common-lisp-foundation">

        

        <p>Dear Common Lisp Foundation, Dear Dave,</p>

        <p>Thank you for giving birth to <a href="https://twitter.com/HexstreamSoft/status/1041671580957466624" target="_blank" rel="noreferrer">one of the most important conversations in the Common Lisp community</a>!</p>

        <p>I have reason to believe that your understanding and appreciation for <a href="https://cv.hexstream.expert/" target="_blank">my crucial work within the Common Lisp community</a> has only been growing since this historic event.</p>

        <p>I believe you have the necessary knowledge and resources to be a key ally in <a href="https://github.com/sponsors/Hexstream" target="_blank">leading Common Lisp to unprecedented success</a>.</p>

        <p>You are already managing <a href="https://www.common-lisp.net/" target="_blank">common-lisp.net</a> and <a href="https://www.cliki.net/" target="_blank">cliki.net</a>, both crucial resources. It is time to unify our efforts. I <a href="https://twitter.com/HexstreamSoft/status/1250142510267224065" target="_blank" rel="noreferrer">again</a> urge you to move to GitHub, the best open source platform, and the <a href="https://github.com/sponsors/Hexstream" target="_blank">Common Lisp Revival 2020 Fundraiser</a> is a great occasion to demonstrate to the world what already ought to be quite obvious: <a href="https://github.com/" target="_blank">GitHub</a> is the best code hosting platform, and <a href="https://github.com/sponsors" target="_blank">GitHub Sponsors</a> is the best open source funding platform! Let's leave <q>avoid success at all costs</q> to Haskell!</p>

        <p>
          I am not sure if your corporate processes in any way allow for such a quick turnaround time, or if you can sanely make an exception, but if in any way possible,
          <br>
          <strong>please make a large donation to <a href="https://github.com/sponsors/Hexstream" target="_blank">the Common Lisp Revival 2020 Fundraiser</a> <em>before 10 december 2020</em> if you wish to help kickstart the Common Lisp revolution right now! Thank you.</strong>
        </p>

      </section>

      <section id="paul-graham">

        

        <p>Dear Paul Graham, Dear Y Combinator,</p>

        <p><a href="https://cv.hexstream.expert/" target="_blank">I have been almost entirely dedicating my life to Common Lisp since mid-2006</a> when I discovered Common Lisp, largely thanks to <a href="http://www.paulgraham.com/" target="_blank">your essays</a>, especially <a href="http://www.paulgraham.com/avg.html" target="_blank">Beating the Averages</a>. After spending 2 weeks reading your essays and researching Common Lisp, I went all-in on Common Lisp and completely abandoned Java. <strong>To this day, this has been the best and most determinant event in my life and I am deeply thanking you for it!</strong></p>

        <p>Basically, I've been running <a href="https://www.hexstreamsoft.com/" target="_blank">an unregistered Common Lisp startup</a> for 14 years. I am planning to register in 2022 at the latest. I have finally started experiencing <a href="https://cv.hexstream.expert/#hexstreamsoft-alexa-stats" target="_blank">some visible success</a> this year, as I am finally reaching the interesting point in the exponential curve. <strong>I am requesting your help to further accelerate and embolden this process.</strong></p>

        <p>
          Unfortunately, I believe the traditional Y Combinator process would not be a good fit for me, due to various reasons.
          <br>
          I am requesting a fairly insignificant amount of funding compared to your usual investments, but this would completely change my life.
        </p>

        <p><a href="https://github.com/sponsors/Hexstream" target="_blank">I am the chief architect of the looming Common Lisp revolution.</a> The revolution would still happen even if you just decided to watch it unfold from afar, but I thought I would highlight your opportunity to lend it a bit of your vast resources and influence, thereby greatly empowering it. Everyone has much to gain from this happening. This is a traditional win-win-win scenario.</p>

        <p>I trust that your world-class expertise in startups will easily detect the amazing intrinsic value and potential of me and my startup.</p>

        <p><strong>Please make a large donation to <a href="https://github.com/sponsors/Hexstream" target="_blank">the Common Lisp Revival 2020 Fundraiser</a> <em>before 10 december 2020</em> if you wish to help kickstart the Common Lisp revolution right now! Thank you.</strong></p>

      </section>

      <section id="planck-ez">

        

        <p>Dear Ergodox/ZSA, Dear Erez, Dear Tisha, Dear Florian,</p>

        <p>The <a href="https://ergodox-ez.com/pages/planck" target="_blank">Planck EZ</a> is truly revolutionary and life-changing! I predict that it (or its close descendants) will remain the best keyboard on the planet for decades to come!</p>

        <p>Thank you for implementing custom labels in <a href="https://configure.ergodox-ez.com/planck-ez/layouts/ABWNG/latest/0" target="_blank">Oryx</a>, <a href="https://twitter.com/HexstreamSoft/status/1237462417577295873" target="_blank" rel="noreferrer">as I requested</a>. Your email support is truly amazing, and I was surprised to find that indeed, we have already exchanged <strong>more than 100 emails in 9 months!</strong> I greatly value our great relationship, and here is a perfect occasion to go to the next level!</p>

        <p>
          The <a href="https://ergodox-ez.com/pages/planck" target="_blank">Planck EZ</a> is so damn great that I couldn't resist making <a href="https://status-quo.hexstream.expert/hardware/planck-ez/#my-config" target="_blank">an advanced presentation for my custom keyboard layout</a>.
          <br>
          You were so impressed with it that you quickly offered to <a href="https://status-quo.hexstream.expert/articles/planck-ez-interview/" target="_blank">interview me</a>, and I then proceeded to really pour my soul into that article, with quite impressive results I might say!</p>

        <p>
          The kicker? <strong>I did this while I was already late to launch <a href="https://github.com/sponsors/Hexstream" target="_blank">the Common Lisp Revival 2020 Fundraiser</a>! <em>Oh noes!!</em></strong> 🤣
          <br>
          But seriously, I just <em>couldn't wait</em> to share my passion for the <a href="https://ergodox-ez.com/pages/planck" target="_blank">Planck EZ</a> with the world! That's how goddamn amazing it is!!
        </p>

        <p>I had already been using the TypeMatrix 2030 (a somewhat similar keyboard) for more than a decade, and the <a href="https://ergodox-ez.com/pages/planck" target="_blank">Planck EZ</a> is at least 20x better! It's easy to infer that I'm probably going to stick to the <a href="https://ergodox-ez.com/pages/planck" target="_blank">Planck EZ</a> or a close descendant for the next decade at least... As <a href="https://status-quo.hexstream.expert/articles/planck-ez-interview/#alternative-to-qmk" target="_blank">previously stated</a>, I am planning to build much more powerful alternatives to <a href="https://qmk.fm/" target="_blank">QMK</a>, <a href="https://ergodox-ez.com/pages/wally" target="_blank">Wally</a> and <a href="https://configure.ergodox-ez.com/" target="_blank">Oryx</a>, all written in Common Lisp, of course. Admittedly, it would take at least a few years before I can start working on this, due to <a href="https://roadmap.hexstreamsoft.com/" target="_blank">more pressing priorities</a>. My <a href="https://status-quo.hexstream.expert/hardware/planck-ez/#my-config" target="_blank">awesome Planck EZ layout presentation</a> is already a good first step towards an Oryx alternative, although it is not yet written in Common Lisp. (I would probably only support the <a href="https://ergodox-ez.com/pages/planck" target="_blank">Planck EZ</a>, since that's the only keyboard I find interesting...) <strong><a href="https://status-quo.hexstream.expert/articles/planck-ez-interview/#stenography" target="_blank">I believe the Planck EZ will be the key to unlocking 100x productivity!</a></strong></p>

        <p>
          I think there is already an inherent and fundamental link between Common Lisp and the <a href="https://ergodox-ez.com/pages/planck" target="_blank">Planck EZ</a>:
          <br>
          <em>It's only fair to expect that the best programmers would gravitate not only towards the best programming language, but also the <a href="https://ergodox-ez.com/pages/planck" target="_blank">best keyboard</a>!</em>
          <br>
          Thankfully, we have a tremendous opportunity to make that connection even more concrete today!
        </p>

        <p><strong>As such, I would be extremely honored if you made a large donation to <a href="https://github.com/sponsors/Hexstream" target="_blank">the Common Lisp Revival 2020 Fundraiser</a> <em>before 10 december 2020</em> to help kickstart the Common Lisp revolution right now! Thank you.</strong></p>

        <p>I can confirm ZSA is eligible for <a href="https://sponsors.hexstreamsoft.com/about/#perks" target="_blank">Advanced Perks</a>, including <a href="https://sponsors.hexstreamsoft.com/about/#lifetime-perks" target="_blank">Lifetime Perks</a>. You can advertise your amazing products on the front page of the #1 Common Lisp site thanks to <a href="https://sponsors.hexstreamsoft.com/about/#monthly-perks" target="_blank">Monthly Perks</a>.</p>

      </section>

      <section id="everyone-else">

        

        <p>Dear everyone interested in Common Lisp and/or Open Source or …</p></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://sponsors.hexstreamsoft.com/urgent-appeal/#paul-graham">https://sponsors.hexstreamsoft.com/urgent-appeal/#paul-graham</a></em></p>]]>
            </description>
            <link>https://sponsors.hexstreamsoft.com/urgent-appeal/#paul-graham</link>
            <guid isPermaLink="false">hacker-news-small-sites-25320063</guid>
            <pubDate>Sun, 06 Dec 2020 01:21:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How does Brown University know where you are?]]>
            </title>
            <description>
<![CDATA[
Score 203 | Comments 137 (<a href="https://news.ycombinator.com/item?id=25319392">thread link</a>) | @jswrenn
<br/>
December 5, 2020 | https://jack.wrenn.fyi/blog/brown-location-surveillance | <a href="https://web.archive.org/web/*/https://jack.wrenn.fyi/blog/brown-location-surveillance">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
    <p>In September 2020, Brown University <a href="https://www.browndailyherald.com/2020/09/28/remote-students-receive-emails-brown-accusing-violating-code-student-conduct">accused students</a> of lying about their location; e.g.:</p>
<p><img src="https://jack.wrenn.fyi/blog/brown-location-surveillance/notice.png" height="auto" width="100%" alt="The University has learned that between September 14, 2020 and September 21, 2020 you were allegedly in the Providence area during which time your location of study was listed as remote. This alleged behavior is a violation of the Student Code of Conduct and the COVID-19 Campus Safety Policy. A copy of the Student Commitment to COVID-19 Community Health and Safety Requirements is attached for your review, along with this link to the COVID-19 Campus Safety Policy. failure to abide by these requirements is a violation of the Code of Student Conduct. 
Based on the details of the incident and your student conduct history, the Office of Student Conduct &amp; Community Standards has decided to allow you the opportunity to accept responsibility for the following prohibited conduct without having a COVID-19 Dean's Review Meeting:
• D.8 Failure to Comply
• D.13 Misrepresentation
"></p>
<p><strong>What was Brown's basis for these accusations?</strong></p>
<p>In an <a href="https://www.browndailyherald.com/2020/09/28/remote-students-receive-emails-brown-accusing-violating-code-student-conduct">interview with The Brown Daily Herald</a>, University Spokesperson Brian Clark said the University evaluated a variety of indicators, including:</p>
<ol>
<li>indications of building access,</li>
<li>indications of accessing private electronic services,</li>
<li>indications of accessing secure networks, and</li>
<li>reports from community members.</li>
</ol>
<p>The mechanics of that last indicator are pretty self-explanatory, but what about the others? <a href="https://it.brown.edu/services/type/canvas-learning-management-system">Canvas</a> <em>doesn't</em> <a href="https://knowyourmeme.com/memes/google-wants-to-know-your-location">Want To Know Your Location</a>. <strong>In this post, I'm going to break down the technical mechanisms behind each of these indicators.</strong></p>
<p>For the most part, I do not have insider knowledge on how Brown reached its decisions. Rather, I'm going to consider each of the indicators Brian Clark named, and describe the technical mechanisms to which Brown <em>could</em> have availed itself to generating location data.</p>
<h2 id="indications-of-building-access">Indications of Building Access</h2>
<p>This is an easy one. Brown's buildings are located on Brown's campus. Brown's campus is in Providence. If you are in Brown's buildings, you are on Brown's campus, in Providence. QED.</p>
<p>At Brown, building access is primarily regulated with electronic control systems (namely Software House's <a href="https://www.swhouse.com/products/software_CCURE9000.aspx"><strong>C•CURE 9000</strong></a> system), not mechanical keys.</p>
<p>Encoded on <a href="https://en.wikipedia.org/wiki/Magnetic_stripe_card#Track_2">track 2</a> of the magnetic stripe on every University ID card is a sixteen digit number that uniquely identifies the card:</p>
<p><img src="https://jack.wrenn.fyi/blog/brown-location-surveillance/brown-id-card-back.jpg" height="auto" width="100%" alt="Image of back of Brown ID card. A tall magnetic stripe runs across the entire width of the card."></p>
<p>Well, that's underwhelming — of <em>course</em> you can't <em>see</em> it! However, up until 2017 or 2018, this number was also <em>printed</em> on the front of ID cards, just above the card-holder's name:</p>
<p><img src="https://jack.wrenn.fyi/blog/brown-location-surveillance/brown-id-card-front.jpg" height="auto" width="100%" alt="Image fo the front of a Brown ID card, displaying the building access code: 6009553660926201"></p>
<p>This pseudo-random identifier (well, its last ten digits) are what uniquely identify you whenever you swipe your Brown ID card <em>anywhere</em>. And, if you lose your Brown ID card, this is the <em>only</em> thing that's changed when you're issued a replacement. Convenient! In contrast, when you lose your dorm room's mechanical key, Brown must replace (or rather, <a href="https://en.wikipedia.org/wiki/Rekeying">rekey</a>) the locks.</p>
<p>But, <em>also</em> unlike a mechanical key, <em>every</em> swipe of a Brown ID card is logged in a central database. <strong>The C•CURE 9000 lets administrators view the complete historical building access history of a person.</strong> Last Spring, Brown used this mechanism to identify and prod students who were slow to evacuate Providence.</p>
<h2 id="indicators-from-electronic-services">Indicators from Electronic Services</h2>
<p>University web services like Canvas <em>don't</em> directly ask you for your location. Nonetheless, accessing these services leaves a location finger print: your IP address.</p>
<p>Your <a href="https://en.wikipedia.org/wiki/IP_address">IP address</a> is a number that identifies your device (computer, phone, etc.) for the purposes of network routing. In principle, nobody but you and your internet provider know the <em>exact</em> mapping of your IP address to your physical address.</p>
<p>In practice, IP addresses can be used to <em>roughly</em> geolocate a device. Batches of IP addresses are associated <em>loosely</em> with geographic areas. Since every web service access leaves an IP address as a trace, there are tremendous incentives for advertisers to be able accurately identify what city or town an IP address is probably associated with.</p>
<p>Brown probably <em>isn't</em> analyzing the access logs of its <em>individual</em> web services (like Canvas). Rather, they need only to audit the access logs of its three identity access management (IAM) systems:</p>
<ul>
<li>The <a href="https://workspace.google.com/">Google Workplace</a> IAM system is used to control access to your @brown.edu email, and to the various Google Drive services. <a href="https://support.google.com/a/answer/4580120?hl=en"><strong>Google Workplace</strong> provides administrators with login audit logs that include users' IP addresses.</a></li>
<li>The <a href="https://www.shibboleth.net/">Shibboleth</a> IAM system controls access to all <em>other</em> Brown web services, such as Canvas. It's what you think of as your "Brown account". Shibboleth is <em>very</em> flexible, and can be <a href="https://wiki.shibboleth.net/confluence/display/IDP30/AuditLoggingConfiguration#AuditLoggingConfiguration-GenericFields">configured to log IP addresses</a>.</li>
<li><a href="https://duo.com/">DUO</a> is used to provide two-factor authentication for Shibboleth logins. <a href="https://help.duo.com/s/article/1023?language=en_US#docs-internal-guid-0aa3b4ce-c686-7559-8814-1377592fce4a:%7E:text=Access%20Device">It too provides administrators with detailed access logs</a>.</li>
</ul>
<p>You can partly view your Google Workplace login history for yourself by opening your Brown email and clicking "Details" in the bottom right-hand corner of the page; e.g.:</p>
<p><img src="https://jack.wrenn.fyi/blog/brown-location-surveillance/gmail-account-activity.png" height="auto" width="100%"></p>
<p>With <em>either</em> of these access logs in hand, Brown could then turn to any number of geolocation services (<a href="https://tools.keycdn.com/geo">like this one</a>) to guess your physical location.</p>
<h2 id="indicators-from-secure-networks">Indicators from Secure Networks</h2>
<p>This is another easy one. Brown's WiFI network <a href="https://jack.wrenn.fyi/blog/blog/brown-location-surveillance/Campus_Wireless_Coverage_Map_24x36_1.pdf">blankets Brown's campus</a>. Brown's campus is in Providence. If you are on Brown's WiFi network, you are on Brown's campus. QED.</p>
<p>What might surprise you is the sheer depth of surveillance that's capable with WiFi alone. This section will <em>barely</em> scratch the surface.</p>
<h3 id="identification">Identification</h3>
<p>Brown's WiFi routers each broadcast three <a href="https://en.wikipedia.org/wiki/Service_set_(802.11_network)">service sets</a>:</p>
<ol>
<li><a href="https://it.brown.edu/services/type/wireless-network-brown">Brown</a></li>
<li><a href="https://it.brown.edu/services/type/wireless-network-eduroam">eduroam</a></li>
<li><a href="https://it.brown.edu/services/type/wireless-access-brown-guest">Brown Guest</a></li>
</ol>
<p>The Brown and eduroam networks require that you authenticate with your Brown account credentials. Brown University is thus able to identify the owner of any device connected to these networks.</p>
<p>While Brown Guest does <em>not</em> require authentication, it still provides mechanisms of identification. Your network devices broadcast a unique identifier called a <a href="https://en.wikipedia.org/wiki/MAC_address"><strong>MAC address</strong></a>.</p>
<p><a href="https://drawings.jvns.ca/mac-address/"><img type="image/svg+xml" src="https://drawings.jvns.ca/drawings/mac-address.svg" height="auto" width="100%" alt="Comic by Julia Evans. Text: Every computer on the internet has a network card. When you make HTTP requests with Ethernet/WiFi, every packet gets sent to a MAC address. (&quot;Wait, how do I know someone else on the same network isn't reading all my packets?&quot; &quot;You don't! That's one reason we use HTTPS &amp; secure WiFi networks.&quot;) Your router has a table that maps IP addresses to MAC addresses.  (Read about ARP for more.)
"></a></p>
<p>Brown <a href="https://it.brown.edu/computing-policies/network-connection-policy#32:%7E:text=CIS%20maintains%20a%20database%20of%20unique,a%20computer%20when%20it%20is%20necessary.">maintains databases of the MAC addresses of all connected devices</a>.</p>
<p>If you have ever connected to an authenticated network, Brown will be able to de-anonymize your connections to Brown Guest — <em>unless</em> your device implements <a href="https://en.wikipedia.org/wiki/MAC_address#Randomization">MAC address randomization</a>, which (as the name suggests) randomizes your device's MAC address on a per-network basis.</p>
<h3 id="localization">Localization</h3>
<p>Brown's access points log the MAC addresses of the devices that have connected to them. As of 2015, Brown retained these logs for at least several years — possibly indefinitely. Since there are so many access points on campus, which access point you are connected to can narrow your location down to a particular room. <strong>Combined, these logs paint a <em>very</em> accurate picture of your location on campus at any time.</strong></p>
<p>You do not need to be <em>actively</em> browsing the internet for Brown to know where you are via this mechanism. As you walk through campus, your phone likely <em>automatically</em> reconnects to the nearest available access point. If you are within a literal stone's throw of campus, you should assume that Brown can (roughly) identify your location.</p>
<p>Furthermore, if you are in range of three or more of Brown's ARUBA access points, Brown can, in principle, precisely triangulate your location. This functionality is <a href="https://www.arubanetworks.com/pdf/technology/whitepapers/wp_Hybrid_WIDS.pdf">common</a> in enterprise-grade WiFi infrastructure. (If you've ever tried to run a "rogue" WiFi router in your dorm room and receive an angry knock on your door — this is the mechanism by which you were located.)</p>
<h2 id="how-do-i-find-out-more">How do I find out more?</h2>
<p>The <a href="https://en.wikipedia.org/wiki/Family_Educational_Rights_and_Privacy_Act"><em>Family Educational Rights and Privacy Act</em></a> empowers students to request their education records from their University.</p>
<p><iframe src="https://www.youtube.com/embed/jWzBrC8dVnw" frameborder="0" allowfullscreen=""></iframe></p>
<p>If you are a current Brown student and would like to go beyond my blog post and learn <em>exactly</em> how Brown University knows your location, <a href="https://www.brown.edu/about/administration/registrar/student-information-rightsferpa">file a FERPA request</a>. Brown University is obligated to respond within 45 days. You'll need to be specific with your request. I suggest requesting:</p>
<ul>
<li>the timestamps, MAC addresses and BSSIDs associated with your devices' connections to Brown University's wireless access points</li>
<li>the timestamps and locations associated with all building accesses conducted with your ID card</li>
<li>the login audit data associated with all Google Workplace, Shibboleth, and DUO authentications conducted by your accounts</li>
</ul>
<p>Additionally, the <a href="https://en.wikipedia.org/wiki/General_Data_Protection_Regulation"><em>General Data Protection Regulation</em></a> gives EU citizens and residents expansive control over how their personally identifiable information (PII) is used, and the right to request a copy of or the destruction of collected data. I believe these requests should be directed to <a href="https://compliance.brown.edu/">Brown's compliance office</a>. You might be able to do this even if you're a Brown alumni.</p>
<p><strong>If you attempt either of these steps, <a href="mailto:jack@wrenn.fyi">please get in touch</a>!</strong> I'm very curious as to what Brown is <em>actually</em> doing.</p>
<h2 id="bonus-surveillance-cameras">Bonus: Surveillance Cameras</h2>
<p>As of February 2020, <a href="https://www.browndailyherald.com/2020/02/21/cameras-installed-hegeman-hall/#post-2838338:%7E:text=The%20University%20uses%20approximately%20800%20cameras,with%20high%20crime%20activity%2C%20Porter%20said."><em>eight hundred</em> surveillance cameras monitor campus 24/7</a>. Brown has as about as many surveillance cameras as it has full-time faculty! This map documents a <em>mere seven percent</em> of Brown University's total camera surveillance capacity:</p>

<p><small>This map displays data from <a href="https://www.openstreetmap.org/about">OpenStreetMap</a>. <a href="https://pietervdvn.github.io/Staging/surveillance.html?z=17&amp;lat=41.82681&amp;lon=-71.4016">Help improve its accuracy!</a></small></p><p>Brown University has a longstanding policy governing the appropriate uses of its surveillance cameras. <strong>Unfortunately, <a href="https://www.browndailyherald.com/2008/01/10/surveillance-cameras-on-campus-triple/#post-1679525:%7E:text=DPS%20would%20not%20release%20the%20University%E2%80%99s%20full%20policy%20on%20the%20surveillance%20camera%20system">this policy is secret</a>.</strong></p>
<p>While Brown probably does not <em>currently</em> have the capacity to both broadly and deeply inspect the firehose of data produced by these cameras, expect this to change in the near future. Axis Communications, Brown's primary supplier of surveillance cameras, <a href="https://www.axis.com/customer-story/3767">now touts cameras that can perform <em>on-board</em> facial recognition</a>. And Software House, the provider of the C•CURE 9000 access control system, has begun marketing the integration of facial recognition with its access control systems:</p>
<p><iframe src="https://www.youtube.com/embed/bk395D0tPRA" frameborder="0" allowfullscreen=""></iframe></p>

  </div></div>]]>
            </description>
            <link>https://jack.wrenn.fyi/blog/brown-location-surveillance</link>
            <guid isPermaLink="false">hacker-news-small-sites-25319392</guid>
            <pubDate>Sat, 05 Dec 2020 23:18:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Top PostgreSQL Tools]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25319372">thread link</a>) | @blopeur
<br/>
December 5, 2020 | https://blog.cherre.com/2020/11/30/60-top-postgresql-tools/ | <a href="https://web.archive.org/web/*/https://blog.cherre.com/2020/11/30/60-top-postgresql-tools/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                
<figure><img loading="lazy" src="https://blog.cherre.com/wp-content/uploads/2020/11/60-Top-Postgres-Tools2-1024x749.png" alt="#PostgreSQLtools" width="512" height="375" srcset="https://blog.cherre.com/wp-content/uploads/2020/11/60-Top-Postgres-Tools2-1024x749.png 1024w, https://blog.cherre.com/wp-content/uploads/2020/11/60-Top-Postgres-Tools2-300x219.png 300w, https://blog.cherre.com/wp-content/uploads/2020/11/60-Top-Postgres-Tools2-768x562.png 768w, https://blog.cherre.com/wp-content/uploads/2020/11/60-Top-Postgres-Tools2-1536x1124.png 1536w, https://blog.cherre.com/wp-content/uploads/2020/11/60-Top-Postgres-Tools2-2048x1498.png 2048w" sizes="(max-width: 512px) 100vw, 512px"></figure>



<p>PostgreSQL, or Postgres for short, comes with many out-of-the-box features that make it very popular among developers and data engineers. Among the numerous benefits of implementing Postgres are that there are many approaches to take to scale your database horizontally or vertically—but that is a discussion for a whole different article. Postgres comes with plenty of add-ons and a strong community of developers behind it too for open-source support.&nbsp;</p>



<p>Aside from plugins that you can quickly add a variety of tools and resources to your Postgres suite to expand the many functionalities of your Postgres database system to help you take your use of Postgres to the next level. This article shares the top 62 tools, plugins, and add-ons in that suite for you to improve your Postgres operations and productivity quickly and efficiently.</p>



<h2><strong>Graphical User Interface</strong></h2>



<p>Postgres doesn’t come with a native GUI, but that doesn’t mean you cannot manage your Postgres databases using a simple user interface. Web-based GUIs and tools for this specific purpose are easy to find.</p>



<figure><img loading="lazy" src="https://lh6.googleusercontent.com/plt54JgoE56tK9XTfy0n77S5kbUU3yOsxHuFncLuPYsC32QWHl9NQUTVulFjqJupJRB5i-Uvwy3u9NF0liPb4C2BCrEjvxNcZfSaUe2kJtPap4fiC3INTgPJubPtRHRhwi3zFGTl" alt="#DataGrip" width="254" height="113"></figure>



<ol><li><a href="https://www.jetbrains.com/datagrip/" target="_blank" rel="noreferrer noopener">Datagrip</a></li></ol>



<p>DataGrip is a tool that helps simplify managing multiple databases. It is compatible with multiple database systems, including PostgreSQL. You get a graphical interface for managing databases, running queries, and completing routine maintenance tasks. This tool is very popular at Cherre.</p>



<figure><img loading="lazy" src="https://lh3.googleusercontent.com/D0s1cOPz_g7XyuUoASoiIubUy5ZC5w3F5dSNp9KGUWF1alKUJCH-DzzBdO0yK_fgvUmG9_L1K59jYcq3OWfgrICkU6ov5uV9ukGNZQycHZvllxvtMZLYI_QfQEj1rroavXbnLVeb" alt="#DBeaver" width="216" height="108"></figure>



<ol start="2"><li><a href="https://dbeaver.io/" target="_blank" rel="noreferrer noopener">DBeaver&nbsp;</a></li></ol>



<p>The latest version of DBeaver, 7.1.4, includes data editing features that are designed to be intuitive. DBeaver, however, offers more than data editing. It supports PostgreSQL and many other database systems.</p>



<figure><img loading="lazy" src="https://lh3.googleusercontent.com/EIl8uFSl3bnrnLWOE5xbNYy_PLs0Gb1g5xC3CuhqGN_6Snr8DmyO0NI7BDxhRuKqqreLGm4hPwMTfA970hSC--k1D3UKg_xsNYk6qgnX5bTM9HFDX5IlPQhLTXC98UN3eEzLWuJu" alt="#Navicat" width="267" height="108"></figure>



<ol start="3"><li><a href="https://www.navicat.com/en/" target="_blank" rel="noreferrer noopener">Navicat for PostgreSQL</a></li></ol>



<p>Navicat is not a new name in the database landscape. Its product for Postgres is designed to offer you all the tools you need to manage complex databases. There are also data visualization tools available within.</p>



<figure><img loading="lazy" src="https://lh5.googleusercontent.com/FQ2Tdygv9EVAvWLrJo8Ab9jA-L1cBtv3ek41rVaaVmCKLfYyHpJewvoy6dlmIiuNaLFODhsDHFdMfeotCx9cmcoBzxLFbpAN_efDh5s13Qzn2xFSXFfQkAmqlucDgfMf4wPhxzT6" alt="#Pgadmin" width="113" height="117"></figure>



<ol start="4"><li><a href="https://www.pgadmin.org/" target="_blank" rel="noreferrer noopener">Pgadmin</a></li></ol>



<p>When it comes to keeping Postgres maintenance and management simple, Postgres has pgADmin. The web-based option now supports external configuration files and runs completely in the cloud. You can use it as a way to manage database clusters. However, it feels a little limited compared to a full gui.</p>



<ol start="5"><li><a href="https://www.valentina-db.com/en/studio-for-postgresql" target="_blank" rel="noreferrer noopener">Valentina Studio for PostgreSQL</a></li></ol>



<p>Valentina Studio comes in different flavors, but even the free version is capable enough for managing multiple Postgres databases. It supports forms, can be integrated with CI/CD pipelines, and simplifies data transfer between databases.</p>



<ol start="6"><li><a href="http://phppgadmin.sourceforge.net/doku.php" target="_blank" rel="noreferrer noopener">phpPgAdmin</a></li></ol>



<p>MySQL has phpMyAdmin, and PostgreSQL has phpPgAdmin. If you are familiar with phpMyAdmin, then you will have no trouble using the Postgres version. The features and tools are relatively the same with a few adjustments.</p>



<figure><img loading="lazy" src="https://lh5.googleusercontent.com/FHiWWzHKdvKOGEwdNi_FFJ4cmSFLW208aREpKrHw-fdNhR0AnIx7N5Rpe5_wVhnVpbGYfrF3dZJFVSjdse4ye7fXvVna-WxaW8oP94ZPEwl6VH5mOYfTCfoo12EQOp5mq8FgAc8A" alt="#Metabase" width="195" height="146"></figure>



<ol start="7"><li><a href="https://www.metabase.com/" target="_blank" rel="noreferrer noopener">Metabase</a></li></ol>



<p>Metabase is more of a data processing tool with advanced UIs. Rather than complex queries, it allows you to answer questions by visualizing insights collected from the PostgreSQL databases that you maintain.</p>



<figure><img loading="lazy" src="https://lh5.googleusercontent.com/Z1m1CLoiqrVOz1S1LHm1SJDB5RkgizMFx8mqRC-GWyMs7gfrhAMoCHwOe9yGqKGJpWYPxJM62NgdJVAKJy6NwbYcszplUaCl0o1SOs68VgNsjFIc_sljbRRimFGeJPIodS_Zqn3_" alt="#Slemma" width="240" height="80"></figure>



<ol start="8"><li><a href="https://slemma.com/connectors/database-reporting/" target="_blank" rel="noreferrer noopener">Slemma</a></li></ol>



<p>Slemma is far from just another GUI for Postgres. It takes data visualization to another level by introducing automation. Reports from a series of entries can be generated automatically based on parameters and the kind of insights you want to get in return.</p>



<figure><img loading="lazy" src="https://lh5.googleusercontent.com/vDAmrWbVqi9izoCkHpRiHKd7KC8sbos8p_L7tgBOLz-2EuI12hFg1BuhY9vgDfdyUGd__ChCmc37rpimb4LMqXPYnzLP7RHDqnU6_5PWA_B4UK5SZu6lEHxfZAwqSKcNxrGZF7CP" alt="#windwardstudios" width="331" height="76"></figure>



<ol start="9"><li><a href="https://www.windwardstudios.com/datasource/postgresql" target="_blank" rel="noreferrer noopener">Windward Studios</a></li></ol>



<p>Windward is the last GUI tool on our list with a special trick up its sleeve: it can be integrated with Microsoft Office natively. You can use Office apps to design templates for reports or to visualize your report using data stored in Postgres.</p>



<h2><strong>Utilities</strong></h2>



<p>Utilities for Postgres are usually designed to do specific things. While PostgreSQL doesn’t require special maintenance, it is still a good idea to integrate good utilities into your database management workflow. The best utilities tools will certainly make your life as a database engineer easier.</p>



<ol><li><a href="https://github.com/EnterpriseDB/pg_catcheck" target="_blank" rel="noreferrer noopener">Pg_catcheck</a></li></ol>



<p>System catalog corruption can be a huge problem that can bring an entire Postgres database down when it happens. Depending on the severity of the corruption, you may also lose entries and valuable information. Use pg_catheck to monitor for system catalog corruption.</p>



<ol start="2"><li><a href="http://www.pgbouncer.org/" target="_blank" rel="noreferrer noopener">pgBouncer</a></li></ol>



<p>As the name suggests, pgBouncer acts as the bouncer that prevents unauthorized access. The common use case for this tool is to manage connections, similar to a load balancer. While Postgres is relatively secure as long as you follow the best practices, having encrypted SCRAM secrets used for storing passwords is a good idea.</p>



<ol start="3"><li><a href="https://hypopg.readthedocs.io/en/latest/" target="_blank" rel="noreferrer noopener">HypoPG</a></li></ol>



<p>Hypotheticals are not always possible—and are certainly difficult to keep track of—and HypoPG is here to solve those challenges. It is basically a virtual index that doesn’t really consume cloud resources. It can also handle hypothetical partitioning.</p>



<ol start="4"><li><a href="https://www.postgis.net/" target="_blank" rel="noreferrer noopener">PostGIS</a></li></ol>



<p>PostGIS fills one specific hole, lack of native support for spatial information. Postgres users can now use PostGIS to use location information in queries. If your app relies on location data, this utility certainly helps.</p>



<ol start="5"><li><a href="https://www.postgresql.org/docs/11/postgres-fdw.htm" target="_blank" rel="noreferrer noopener">Postgres_fdw</a></li></ol>



<p>Foreign-data wrapper makes accessing external Postgres databases possible. Postgres_fdw takes that idea one step further and makes the whole process easier.&nbsp; In short you can use objects from other databases, without having to sync the two together, Postgres_fdw inexpensively makes it look like it’s in both. After installing the utility, you can create a foreign server object and work with user mapping accordingly.</p>



<ol start="6"><li><a href="https://www.yohz.com/dbdoc_details.htm" target="_blank" rel="noreferrer noopener">DB Doc for PostgreSQL</a></li></ol>



<p>While launching a new app or distributing it to a client is a fairly straightforward process, making sure that the app is used properly—and is developed with care—is still difficult. DB Doc for PostgreSQL takes care of creating documentation for your projects.</p>



<h2><strong>Platform as a Service (PaaS)</strong></h2>



<p>Being able to utilize Postgres without having to manage the entire cloud infrastructure supporting it is something that many development teams want these days. Organizations turn to managed database services so that they can utilize the features of Postgres without the usual complications. Fortunately, there are several solutions being offered as Platform as a Service or PaaS.</p>



<figure><img loading="lazy" src="https://lh5.googleusercontent.com/gxEUzL5xD9FYbEf-O1dSweSDqCeuqH29GAw6U5GyrdwRC_SO5VV4V9XPG3JysT_7F9kcsa-iE0r265pi6RwU5uzXM-tpSnsRHqLHsKTX7VlyNJC4Vx1grypmnH3oFvmQwyzQo2nW" alt="#AmazonRDSforPostgreSQL" width="118" height="132"></figure>



<ol><li><a href="https://aws.amazon.com/rds/postgresql/" target="_blank" rel="noreferrer noopener">&nbsp;Amazon RDS for PostgreSQL</a></li></ol>



<p>Amazon’s RDS is perhaps the most popular option of them all, offering cloud relational databases as managed services. It has Amazon RDS for PostgreSQL, which allows you to forget about storage, deployment cycles, availability, and backup while taking full advantage of what Postgres has to offer.</p>



<figure><img loading="lazy" src="https://lh6.googleusercontent.com/nS9uoXzAn68iKWqAXzTgHzMuvjQHn1hmVqNshUIYCWstM0cHCt6EbVAdiormaASkc-li1fJ1JWz71885r6tTmODgpyRt6J_gYBjbT1W3jaQwoOjMMg7HPYBOBYhqb5UfvyS8QJro" alt="#aiven" width="173" height="91"></figure>



<ol start="2"><li><a href="https://aiven.io/postgresql" target="_blank" rel="noreferrer noopener">Aiven for PostgreSQL</a></li></ol>



<p>Aiven for PostgreSQL is another option when it comes to fully managed SQL databases. You can give the platform a try for free before switching to one of the paid plans that suit your needs best. Even better, Aiven runs on AWS, GCP, Azure, and other cloud ecosystems for better availability.</p>



<figure><img loading="lazy" src="https://lh4.googleusercontent.com/iIeJzX5JFZAPYm24YDmJo3HzHIUgSfrhyGhrm15jrIPLNWot_qIWi3UDmEf7_2l2fn4Pxa2TsGECybWOVjqhOPiuRlNSyXiURZjhJT_Z9TAMg8bPSNEwyCrey_1jpPUCby_w8bAE" alt="#CloudSQLforPostgreSQL" width="137" height="128"></figure>



<ol start="3"><li><a href="https://cloud.google.com/sql/docs/postgres" target="_blank" rel="noreferrer noopener">Cloud SQL for PostgreSQL</a></li></ol>



<p>Cloud SQL for PostgreSQL is Google’s version of managed relational databases in the cloud. As part of Google Cloud, Cloud SQL for PostgreSQL integrates well with other GCP services, plus it can be used to support apps running in a multi-cloud environment thanks to its comprehensive API.</p>



<figure><img loading="lazy" src="https://lh5.googleusercontent.com/7ZleaQxKb5wx4XkzKSr7GNtUS2UEch28DRlFutxf3iS4Ai5-0qsFIv-M8oImaGQwLIKoWDxychrTKrgQebP-30aEA_AMuHy_prL3botCzH5qX5F9IrCTu0F2dvxaqY6olaoRk3Ww" alt="#AzureDatabaseforPostgrSQL" width="143" height="143"></figure>



<ol start="4"><li><a href="https://azure.microsoft.com/en-us/services/postgresql/" target="_blank" rel="noreferrer noopener">Azure Database for PostgreSQL</a></li></ol>



<p>Amazon has one. Google has one. So it is not surprising to see Microsoft offering the Azure Database for PostgreSQL. Azure doesn’t just offer another PaaS for Postgres users, though. It leans heavily on scalability and offers intelligent performance recommendations—powered by machine learning—as one of its features.</p>



<figure><img loading="lazy" src="https://lh5.googleusercontent.com/oEUtjqnAJ03bOJYbQwkiRuvcTTNe2Rd0hXx90YTR4ksZy60WEsiOeoAqZh6soY89yz2ifXnSwyryIuNfQSc_Ytrbo-7JeXi4Qs1wjdM3m20Ir-MtgmsHbU8baiND5WBHxTDHQ95s" alt="#DigitalOcean" width="132" height="132"></figure>



<ol start="5"><li><a href="https://www.digitalocean.com/products/managed-databases/" target="_blank" rel="noreferrer noopener">DigitalOcean Managed Databases</a></li></ol>



<p>For a more affordable option, DigitalOcean Managed Databases is the service you want to look into. It starts at only $15/month, but It offers easy setup, seamless maintenance, daily backups, and multiple redundancies to support your apps and microservices.</p>



<figure><img loading="lazy" src="https://lh6.googleusercontent.com/E59LDZy3uUEiBAnPPFauhfT3q6tyvzWyWtrC0xKGyp_pbVurrhrCDo4ZQW2eTvVX03fdD8MsegQvb0VlaobAgX5R_pY60qItNr8b9ZweovwCHE-2wZNeKnvohMiXKmDLZ9yitemq" alt="#Heroku" width="198" height="110"></figure>



<ol start="6"><li><a href="https://elements.heroku.com/addons/heroku-postgresql" target="_blank" rel="noreferrer noopener">Heroku PostgreSQL</a></li></ol>



<p>Heroku PostgreSQL offers all the Postgres features you will ever need, but without making the entire platform cluttered or too complicated. Available in the United States and Europe, Heroku PostgreSQL is also affordable thanks to its nano and micro plans.</p>



<h2><strong>Applications</strong></h2>



<p>There are a lot of tools designed to make designing Postgres databases, creating relationships, managing tables, and organizing the entire PostgreSQL platform easier, but most of them are designed to offer specific features. In this part, we are going to take a look at the two Postgres applications that you can use for end-to-end database design and management.</p>



<figure><img loading="lazy" src="https://lh6.googleusercontent.com/BNG9GB5GDj0UgmVKyLRJ2PFYbJBXPHemZTxuUfYYy3_WrsOTDydLH4eORC3gQwSQ6Bu38EGkcxzKd6N6yJ4emc88wRIhz9rQIZ-U6FrdXtxxRF21JdT2Toj9_vOWosaLeyTDG-ZA" alt="#agileBase" width="129" height="115"></figure>



<ol><li><a href="http://www.agilebase.co.uk/" target="_blank" rel="noreferrer noopener">agileBase</a></li></ol>



<p>AgileBase is famous for its low-code or no-code approach. You don’t have to be a database specialist—or any specialist for that matter—to build your own platform and support the application you want to deliver. AgileBase’s PostgreSQL features are designed as blocks and can be customized to your liking.</p>



<figure><img loading="lazy" src="https://lh4.googleusercontent.com/4COODpGprHglQA440b4to0ipwxVG3SIqAZJNOyqHQ_aERyOUZENL9c6nFzn5ue05rXnVomRuQRV9pkeF_m9T6l8cX9vZ2ojPzYanMVYL2HJgjWgDa3ZfrRrFk2AXoCqmXb28SKF-" alt="#Dataedo" width="255" height="78"></figure>



<ol start="2"><li><a href="https://dataedo.com/" target="_blank" rel="noreferrer noopener">Dataedo</a></li></ol>



<p>Dataedo is all about simplicity. You can manage even the most complex Postgres database through the app’s simple user interface. Even relationships are displayed visually and can be edited as such. This is a great app to use if you don’t want complex database management to be a bottleneck in your pipeline.</p>



<h2><strong>High-Availability</strong></h2>



<p>A database always sits at the core of the application that uses it. Database failures and unreliable database systems are unacceptable because they tend to bring the entire application down with them. That is why PostgreSQL is best implemented in a highly available environment, and these tools are the ones to use if you want to monitor high availability.</p>



<ol><li><a href="https://daamien.github.io/PostgreSQL-Dashboard/">B</a><a href="https://daamien.github.io/PostgreSQL-Dashboard/" target="_blank" rel="noreferrer noopener">G</a><a href="https://daamien.github.io/PostgreSQL-Dashboard/">R</a></li></ol>



<p>The PostgreSQL Dashboard offers access to key metrics that make ensuring high availability easier. There is no need to go through logs manually. Insights are displayed visually and you can go straight to refining your cloud infrastructure to boost the reliability of your database system.</p>



<figure><img loading="lazy" src="https://lh4.googleusercontent.com/THt0_k5TJV7ZBN8Evk-T8SDq_RMjV9WLgxMAHzjkfxFDer19sBClE-GQDwPNUtSqg3lclTrPQC48D46J2e6f72b4xArlJOO-SSusLTmXdNZ6FznQcBq24UGq3RDxKsHuKoroWXPy" alt="#Stolon" width="210" height="105"></figure>



<ol start="2"><li><a href="https://github.com/sorintlab/stolon" target="_blank" rel="noreferrer noopener">Stolon</a></li></ol>



<p>Stolon is another native PostgreSQL management tool designed to make high availability more accessible. It adds features such as native support for Kubernetes and automatic service discovery, allowing multiple database instances to run …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.cherre.com/2020/11/30/60-top-postgresql-tools/">https://blog.cherre.com/2020/11/30/60-top-postgresql-tools/</a></em></p>]]>
            </description>
            <link>https://blog.cherre.com/2020/11/30/60-top-postgresql-tools/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25319372</guid>
            <pubDate>Sat, 05 Dec 2020 23:14:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Building a Feature Store]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25318723">thread link</a>) | @nlathia
<br/>
December 5, 2020 | https://nlathia.github.io/2020/12/Building-a-feature-store.html | <a href="https://web.archive.org/web/*/https://nlathia.github.io/2020/12/Building-a-feature-store.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p>The corner of the internet that I read is awash with posts about feature stores: systems that aim to be <a href="https://blog.feast.dev/post/what-is-a-feature-store">“the interface between models and data.”</a></p>

<p>This idea has been around for quite a while, but there are now an increasing number of companies that are building feature store platforms or products–the concept is becoming established in the machine learning system <em>operations</em> arena.</p>

<p>A few months ago, I built a feature store at <a href="https://monzo.com/">Monzo</a>; in light of that, I thought I’d share some of the thinking that motivated my team to need to build one and how I designed it.</p>

<p>As a broad summary: the feature store that I built does not solve for the many different use cases that you may hear about feature store products–our feature store focuses on regularly and safely transferring data between our analytics and production stacks.</p>

<p>Let’s begin!</p>

<h2 id="-isnt-a-feature-store-just-a-database">🤔 Isn’t a feature store just a database?</h2>

<p>Well, yes. But also no.</p>

<p>When I first started talking about the idea of a feature store internally, some feedback that I received was ‘we already do this–we just haven’t been calling them feature stores.’ Indeed, the emphasis of the name “feature store” has often been on the “<strong>store</strong>” aspect, which does make the whole thing sound like it is just a database. The word “<strong>feature</strong>” is often used to mean “some type of data” (e.g., a column in a table).</p>

<p>At Monzo, you can’t look at any corner of our <a href="https://qconlondon.com/london2020/presentation/modern-banking-1500-microservices">production infrastructure</a> without running into the key-value store we use, Cassandra. In our systems, it’s common for each microservice to have its own keyspace, and for individual services to collect, aggregate, and store the different types of data that they need.</p>

<p>We already had two patterns across several systems which looked like “feature stores:”</p>

<ol>
  <li>Services that receive a request, fan out a bunch of calls to other services, and then munge and store the resulting features. For example, we have a system that filters help articles, and caches features about users, who will be actively navigating the content.</li>
  <li>Services that consume events from streams to construct features about different entities. For example, we have a system that consumes events that occur when chat messages are sent and received, and can then serve requests for features about conversations (e.g., the number of turns).</li>
</ol>

<p>What this means is that data across our keyspaces is typically organised around the systems that they serve: we design a system first (e.g., a system for user accounts), and the features it holds follows from that design (data about user accounts).</p>

<h2 id="-whats-different-about-feature-stores">🧐 What’s different about “feature stores?”</h2>

<p>The idea of a feature store is different because it is a system that is meant to prospectively hold a <em>wide diversity</em> of data–nearly anything that could be valuable input to machine learning models. The “features” could even be the output of <em>other</em> machine learning models (predictions or embeddings).</p>

<p>I think this is an important point because this inverts how data is organised in a production system. With a feature store, you can build a separation of concerns between the systems that generate data and the aggregations of that data that are input into ML models. If you want stats about user accounts, you no longer need to know about user account system– you <em>just</em> query the feature store.</p>

<p>The main reason that is often stated for having a centralised place for features is that they are <em>meant to be reused</em> to solve different problems. For example, let’s say that I’m building a feature, like “average number of transactions in the last 7 days.” This feature could potentially be very useful to a whole host of <em>different</em> machine learning models. If we were going to store this data inside of the system that uses it, we may end up:</p>
<ol>
  <li>Having to rebuild the same feature in more than one place, and</li>
  <li>Making it very difficult to discover what features are available for reuse across problems.</li>
</ol>

<h3 id="-pause-do-these-two-problems-actually-matter">⏸ Pause: do these two problems actually matter?</h3>

<p>Before I carry on to describe our feature store, I’ll pause to reiterate a word of warning that I mentioned in <a href="http://nlathia.github.io/2020/11/Why-ML-code.html">my last blog post</a>. Building something <em>twice</em> may, at first glance, sound like a waste of time. Folks pitching feature stores often tend to drive home that point. However, in some critical use cases, building something twice can help to validate the system’s correctness.</p>

<p>As <a href="https://twitter.com/danielchatfield">one of our Staff Engineers</a> told me, “the types of mistakes that you can make when writing SQL <em>are very different</em> from the types of mistakes you can make when writing Go.” Reimplementing a feature from SQL to Go provides us with two outputs which we can use for reconciliation: if both spit back the same number, we can be more confident the implementations are correct.</p>

<p>In short: the “only code things once” pitch doesn’t actually work for all use cases.</p>

<p>The second point, regarding discovering features for reuse across problems, is also contentious. You could imagine putting all of your features into a set of wide relational tables. At some point, centralising all of the data would come hand-in-hand with a loss of context about what that data means, and how it should be used. Once you have 1000s of features, a central list of them becomes difficult to navigate.</p>

<p>For example, if you had a feature that describes a user as <code>is_inactive</code>, what does that <em>actually</em> mean, and does that definition fit with the new use case?  How do you ensure that the feature store’s documentation for this remain lined up with the upstream system that is generating the raw data? How do you avoid ending up with multiple implementations of the same <em>concept</em>, expressed as variants of the same code, ad nauseam?</p>

<p>So the “discover all your features” is also a slightly trickier problem that “just put them all in one place.”</p>

<h2 id="-narrowing-down-the-problem-space">🔍 Narrowing down the problem space</h2>

<p>If you open up the website of your favourite company that is offering a feature store, it’s more than likely that they’ll have a list of five to ten (sometimes more!) problems that their feature store solves: integrations, data sources, consistency, monitoring, versioning, meta-data and documentation, training dataset creation, production serving, and so on.</p>

<p><em>It’s mind boggling.</em></p>

<p>Up front, I decided that I had no desire to migrate any of our existing systems to sit behind any kind of centralised “feature store” API. I didn’t want the feature store to become a replacement for things that already existed, or a behemoth that is owned by my (small) team. Instead, I learned about what we needed by looking for patterns in the machine learning models that we were shipping.</p>

<p>Specifically, we didn’t need a feature store until this year, when we ramped up how often we were designing and shipping machine learning models that were trained on tabular data (systems we built prior were very NLP-heavy).</p>

<p>When shipping tabular-based models, we kept finding that many of the features we would input into a model while training it were <em>not</em> readily available in our production infrastructure. A large part of this is because our <a href="https://cloud.google.com/customers/monzo">analytics stack</a>, where all of our Data Scientists and Analysts contribute, sits separately from our <a href="https://aws.amazon.com/solutions/case-studies/monzo/">production stack</a>.</p>

<p>Here’s a toy example: a customer’s account balance, accurate to this specific moment, is already available in production–so doesn’t need to be in a feature store. <em>But</em> aggregations on a customer’s balance (e.g., a customer’s 7-day average balance) were not, even though these numbers were already available in our <em>analytics</em>, based on SQL queries that Data Scientists had previously written.</p>

<p>We found that we already had an abundance of features in our analytics tables that, if used in production, would specifically be characterised by:</p>

<ol>
  <li>Having values that change “slowly.” These are different types of aggregations, like averages and counts, that we wanted to use, but specifically did not need them to be accurate up to the latest microsecond.</li>
  <li>Being easy to implement in BigQuery SQL, on our historical data, but would be harder (or, more simply, a lot of work) to rebuild and backfill in our production environment.</li>
</ol>

<blockquote>
  <p>Our problem, therefore, narrowed down to “we need a subset of the numbers, that only exist in our analytics, in production.”</p>
</blockquote>

<p>The first couple of times that anyone in my team ran into this, we queried BigQuery directly from our services, and cached the results. Job done. Over time, the pattern started becoming clearer: we were bound to regularly need this <em>bridge</em> between BigQuery and Cassandra, and didn’t want to rebuild it every single time.</p>

<blockquote>
  <p>This narrowed down the purpose and value-add for a building a feature store in our system: <em>enabling</em> the safe reuse of slow-changing features from our analytics, in production.</p>
</blockquote>

<h2 id="-our-analytics-feature-store">🏪 Our analytics feature store</h2>

<p>What we have today is a system that automates the journey of shipping features between our analytics (BigQuery) and production (Cassandra) databases.</p>

<p>The process starts with a Data Scientist writing some SQL, as they usually do. They tag it as a query that builds a feature table. These tables are automaticaly scheduled and generated alongside all of our other analytics tables, at varying frequencies (daily, hourly, etc.), using Airflow. We use <a href="https://www.getdbt.com/">dbt</a>, and so each query will be written with <a href="https://docs.getdbt.com/docs/building-a-dbt-project/tests/">tests</a>.</p>

<p>By design, feature tables must specificy a <code>subject_type</code> column. This defines the entity that the feature described, such as a “user” feature or a “sort code” feature. The table must also have a corresponding <code>subject_id</code>, which is the actual ID of the user for that row. The schema of this table is replicated in the feature store Go service, because we do not want it to “blindly” ingest data.</p>

<p>The creation of feature tables is monitored: a cron jobs regularly checks whether those tables should be sync’ed into Cassandra. A table should be sync’ed if:</p>
<ul>
  <li>It has been recreated (compared to the last time it was sync’ed), and;</li>
  <li>It passes data validation tests (i.e., it doesn’t accidentally have garbage in it);</li>
</ul>

<p>When a table needs to be sync’ed, it gets partitioned into batches and then exported as line-delimited JSON into …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://nlathia.github.io/2020/12/Building-a-feature-store.html">https://nlathia.github.io/2020/12/Building-a-feature-store.html</a></em></p>]]>
            </description>
            <link>https://nlathia.github.io/2020/12/Building-a-feature-store.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25318723</guid>
            <pubDate>Sat, 05 Dec 2020 21:47:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[In Defense of Blub Studies]]>
            </title>
            <description>
<![CDATA[
Score 32 | Comments 6 (<a href="https://news.ycombinator.com/item?id=25318635">thread link</a>) | @edavis
<br/>
December 5, 2020 | https://www.benkuhn.net/blub/ | <a href="https://web.archive.org/web/*/https://www.benkuhn.net/blub/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><p>Sometimes people ask me what they should learn to become a better programmer. I feel like the default recommendation here is usually an obscure programming language or a textbook on some high-powered machinery like ML. So I always feel a little bit embarrassed and boring when I instead suggest going really deep on what you already know: your main programming language, web framework, object-relational mapper, UI library, version control system, database, Unix tools, etc. It’s not shiny or esoteric, but for me, building a detailed mental model of those (and how they compare to alternatives) might be the learning that’s contributed most to my effectiveness as an engineer.</p><p>A coworker coined the phrase “blub studies” to refer to this sort of mundane, ultra-specific-seeming knowledge. “Blub” comes from a Paul Graham essay, <a href="http://www.paulgraham.com/avg.html" target="_blank">Beating the Averages</a>, in which Blub is a hypothetical middlebrow language whose programmers get defensive when Graham asserts that Lisp is superior. Blub studies is the study of what goes on in the guts of these boring, everyday systems—not the kind you get tenure for inventing, but the kind people actually use.</p><p>Blub studies is a never-ending treadmill of engineering know-how. It’s the fiddly technical details of how Git stores data, or how Postgres locking semantics <a href="https://gocardless.com/blog/zero-downtime-postgres-migrations-the-hard-parts/" target="_blank">caused your migration to bring down prod</a>, or why <code>pip install</code> failed <em>this</em> time. It’s what goes on inside the boiler rooms of your computer. There’s a seemingly infinite amount of it, full of bespoke details for you to stumble over, and that makes it, often, unbelievably frustrating. Experts in shiny fields like machine learning write shiny-sounding articles like <em><a href="https://blog.acolyer.org/2018/01/31/a-theory-of-the-learnable/" target="_blank">A theory of the learnable</a></em>; experts in blub studies emit screeds like <a href="https://www.joelonsoftware.com/2002/11/11/the-law-of-leaky-abstractions/" target="_blank">The Law of Leaky Abstractions</a> and <a href="https://www.stilldrinking.org/programming-sucks" target="_blank">Programming Sucks</a>.</p><p>In short, if you’re in search of generalizable knowledge that <a href="https://fs.blog/2019/02/compounding-knowledge/" target="_blank">compounds exponentially over time</a>, then blub studies looks like the crap you have to wade through to get to the good stuff. So it’s easy to see why people give up on understanding all the blub they’re surrounded by, except what they need to get the job done.</p><p>But for me, the opposite attitude has been more productive. <a href="https://blog.nelhage.com/post/computers-can-be-understood/" target="_blank">Computers can be understood</a>—even if it’s hard and takes a while. Blub studies is more generalizable than it seems, and has its own way of compounding over time, too. That makes it a lot more useful than you’d expect.<sup><label for="sn0">✻</label><span><span><sup>✻</sup>
Of course, there are useless parts of blub studies: if this essay gets you excited to memorize a bunch of command-line flags, consider <a href="https://slatestarcodex.com/2014/03/24/should-you-reverse-any-advice-you-hear/" target="_blank">reversing this advice</a>. But in my experience, it’s more common to neglect the useful parts of blubs, than to over-index on trivia.</span></span></sup></p><hr><p>The most straightforward benefit of blub expertise is that it saves you time. <a href="https://twitter.com/geoffreylitt/status/1305214228991750144" target="_blank">“You can’t apply those brilliant insights you learned from SICP if you don’t have the knowledge base and emotional fortitude to fight through <code>pip install</code> first."</a> If you know how Git’s internal model works, you can get your repository out of its borked state without spending hours on Stack Overflow.</p><p>This effect is larger than it might seem. If you’re working with a system you don’t understand, you’re limited to debugging via guess-and-check, which can be arbitrarily slow. A more efficient method would be to <a href="https://twitter.com/b0rk/status/1265360282513281025?lang=en" target="_blank">get as much information as possible about your program’s execution</a> and then use that information to exclude most of the hypothesis space. But this requires a good understanding of both the system, and the tools available for inspecting it. If you’re tracking down, say, a networking problem, staring at some <code>tcpdump</code> output will often get you most of the way there, but only if you know how to interpret it and what to look for.</p><p>If you spend half your programming time debugging, and being a blub expert lets you debug twice as fast, then just the speed gain from blub expertise will let you increase your output by a third.<sup><label for="sn1">†</label><span><span><sup>†</sup>
If you think “half of programming time debugging” sounds high, imagine how much faster you’d be if all your code worked the first time.<p>Doubling debugging speed is probably a conservative estimate—you can save pretty much unlimited time via things like <a href="http://rachelbythebay.com/w/2020/10/14/lag/" target="_blank">“hmm, 40 milliseconds sounds like the timeout for Nagle’s algorithm, try setting <code>TCP_NODELAY</code>”</a>. I somewhat frequently debug tricky things 5x+ faster than coworkers, just because I’ve been working with our stack for a long time, so I know where to look for problems and how to quickly test hypotheses.</p></span></span></sup> That justifies a lot of time staring at <code>tcpdump</code> output! But there are also more subtle reasons I’ve gotten so much from blub studies. It’s both more general, lasts longer, and has more of a compounding effect, than I expected.</p><hr><p>Blub studies are surprisingly broadly applicable because, even if you’re learning about the details of some specific blubby system, that system’s design will contain a juicy non-blubby core of extractible general principles. Unlike many “general principles” people try to teach you, the ones you learn via blub studies are guaranteed to be important to at least one real-world system (the one you’re learning about). And you’ll see them realized in all their messy detail, which academic presentations often leave out.</p><p>Suppose your blub of choice is React. You might worry that learning the gory details will be useless if you ever move to a different part of the stack, or even a different web framework. And, yes, some of them will. But the core idea of React—writing pure render functions, using <a href="https://reactjs.org/docs/reconciliation.html" target="_blank">reconciliation</a> to make updates fast—is extremely powerful and general. In fact, it’s now been copied by the next generation of UI frameworks on both iOS (<a href="https://developer.apple.com/xcode/swiftui/https://developer.apple.com/xcode/swiftui/" target="_blank">SwiftUI</a>) and Android (<a href="https://developer.android.com/jetpack/compose" target="_blank">Jetpack Compose</a>). Learning the principles behind React makes it easier to learn those other frameworks. In fact, it can even be a useful source of ideas to “import” from one to the other. At Wave, for instance, we’ve gotten a lot of mileage out of importing ideas from <a href="https://relay.dev/" target="_blank">Relay</a> into our mobile apps.</p><p>This is a good example of an idea that, as far as I know, you can <em>only</em> learn about through blub studies. Academia didn’t give much attention to React-style UI programming. In fact, it doesn’t seem to view user-interface programming paradigms as a particularly interesting object of study at all. People do sometimes publish on it but, for instance, I couldn’t find any courses on it in MIT’s extensive course catalog.<sup><label for="sn2">‡</label><span><span><sup>‡</sup>
You could argue that this is because UI programming is “too applied” and one shouldn’t expect it to be covered in an academic curriculum. But computer science covers many other equally-“applied” areas, like networking, databases, operating systems, and graphics.</span></span></sup></p><hr><p>Blub studies also compound more than you’d naively expect, in two ways. First, knowing about one blub makes it easier to learn about alternative blubs that serve the same purpose—like the React/SwiftUI example above. Second, knowing more about one blub helps you learn blubs in <em>adjacent</em> parts of the stack more quickly.</p><p>Once, while pair programming with a more junior coworker, we were writing a complicated SQLAlchemy query. My coworker used <code>user.name</code> (the <code>name</code> field of an object stored in the <code>user</code> variable) instead of <code>User.name</code> (the <code>name</code> field of the <em>class</em> <code>User</code>) and was wondering why her query gave the wrong results. I tried to explain the “magic” by which <code>User.name</code> was an instance of <code>Column</code> while <code>user.name</code> was a simple <code>str</code>. I went around in circles for a little while until I eventually explained Python’s <a href="https://docs.python.org/3/howto/descriptor.html" target="_blank">descriptor protocol</a> to her (the language feature SQLAlchemy uses to enable the “declarative” ORM syntax). At that point, everything clicked—and I realized that Python’s <code>__dunder__</code> methods are the key to decoding quite a lot of “magical” seeming code. If you learn the Python language features well, lots of complicated libraries will become a lot easier to understand.</p><p>I had a similar experience myself with Kubernetes. The first time I tried to learn it, it was a bewildering morass of jargon—all those namespaces and containers and Pods and Deployments and Services and Ingresses just to get a simple HTTP server running! Then I read <a href="http://intronetworks.cs.luc.edu/" target="_blank">a networking textbook</a> and everything made much more sense. The (arguably) most complicated parts of Kubernetes exist to solve networking-related problems—allowing hundreds of containers to talk to each other independently while hosted on a much smaller set of computers—so the networking textbook gave me a schema onto which I could hang all my Kubernetes factoids. Once I knew how Linux’s IP routing, iptables, and network namespaces worked, it was much easier for me to understand what exactly something like “kube-proxy” was doing.</p><p>If you know enough different blubs, you can end up at the point where you don’t even need to look things up to figure out how they’re (probably) implemented. An experienced Python programmer can guess immediately how SQLAlchemy’s “declarative” ORM works under the hood. That’s the point when your blub expertise will really start compounding—almost as soon as you start working with something new, you’ll start figuring out how it works and extracting the kernel of generally-interesting ideas.</p><hr><p>Because of this compounding effect, the most important step toward becoming a blub master is to kickstart your “blub flywheel”—the virtuous cycle of blub accumulation—however you can. That means starting with whichever blubs are the easiest or most motivating to learn, and branching out from there. For me, the easiest place to start has been with blubs I’m already using at my day job. I have a couple strategies for getting the most out of those.</p><p>First, I’ll try to <em>go deeper than necessary</em>. If I really want to ship something, it’s easy to give into temptation to, say, Google an error message, copy-paste a fix from Stack Overflow, and move on with my day. But it often doesn’t take that much longer to actually read the error message, understand what it means, and try to figure out <em>why</em> that Stack Overflow answer fixed my problem. Similarly, if I’m stuck in a tricky yak shave, I’ll bias against “guess-and-check” style …</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.benkuhn.net/blub/">https://www.benkuhn.net/blub/</a></em></p>]]>
            </description>
            <link>https://www.benkuhn.net/blub/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25318635</guid>
            <pubDate>Sat, 05 Dec 2020 21:37:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[That Time I Built a Crack for Nearly All Shareware]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25318373">thread link</a>) | @codazoda
<br/>
December 5, 2020 | https://joeldare.com/that-time-i-built-a-crack-for-nearly-all-shareware | <a href="https://web.archive.org/web/*/https://joeldare.com/that-time-i-built-a-crack-for-nearly-all-shareware">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      
      
      

      

<p>It was in the ’90s and shareware was still cool. I had written a couple of small shareware programs and I was worried about bugs related to dates and times.</p>

<p>So I wrote a new program called DateDesist.</p>

<p>DateDesist allowed me to test how my program would behave on specific dates. It was a fairly simple command line program. What it did was change the date on the machine, execute the program to be tested, wait a few seconds, then restore the date and exit.</p>

<p>It worked incredibly well for testing date-based shareware and making sure that programs expired when they were intended to.</p>

<p>I found it useful for my own testing and wanted to release it for other developers. So I package it up and released it on a bunch of shareware sites such as Tucows, SoftSeek and Freeware Home.</p>

<p>Sometime later I went looking for a <em>crack</em> for a piece of software that I was having trouble getting. I pulled up HotBot (my preferred search engine at the time) and quickly found what I was looking for. I downloaded the archive and took a look at the files inside.</p>

<p>There, I found the typical readme file with a short description of the program it was intended to crack and some ASCII art with the name of the cracking crew. Also included was a copy of my original DateDesist executable and a batch file to launch the target program on a specific date.</p>

<p>Now curious, I searched the web again for other cracks made by the same crew. To my surprise DateDesist had been used in dozens, maybe hundreds, of different cracks that were released by this group. I checked other cracks from other groups on the same sites and found DateDesist used in a significant number of them.</p>

<p><em>Written by Joel Dare on December 5th, 2020</em></p>


      
    </div></div>]]>
            </description>
            <link>https://joeldare.com/that-time-i-built-a-crack-for-nearly-all-shareware</link>
            <guid isPermaLink="false">hacker-news-small-sites-25318373</guid>
            <pubDate>Sat, 05 Dec 2020 21:08:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Descartes' God has failed and Thompson's Satan rules our computers]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25317557">thread link</a>) | @jrepinc
<br/>
December 5, 2020 | https://pluralistic.net/2020/12/05/trusting-trust/#thompsons-devil | <a href="https://web.archive.org/web/*/https://pluralistic.net/2020/12/05/trusting-trust/#thompsons-devil">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-1658">
	<!-- .entry-header -->

	
	
	<div>
		<p><!--
Tags:
tpms, crypto wars, monopolism, computer science, trickbot, uefi, trickboot, trusted computing, palladium, ken thompson, rene descartes, infosec, malware, apts, seth david schoen, peter biddle, ngscb

Summary:
Descartes' God has failed and Thompson's Satan rules our computers

URL:
https://pluralistic.net/2020/12/05/trusting-trust/

Title:
Pluralistic: 05 Dec 2020 trusting-trust

Bullet:
👒

Separator:
_,.-'~'-.,__,.-'~'-.,__,.-'~'-.,__,.-'~'-.,__,.-'~'-.,_

Top Sources:
Today's top sources: Naked Capitalism (https://www.nakedcapitalism.com/).

--><br>
<a href="https://pluralistic.net/2020/12/05/trusting-trust/"><img src="https://i2.wp.com/craphound.com/images/05Dec2020.jpg?w=840&amp;ssl=1" data-recalc-dims="1" data-lazy-src="https://i2.wp.com/craphound.com/images/05Dec2020.jpg?w=840&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></a></p>

<ul>
<li attrs="{'class': ['xToC']}"><a attrs="{'href': '#xslug'}" href="https://pluralistic.net/2020/12/05/trusting-trust/#thompsons-devil">Descartes' God has failed and Thompson's Satan rules our computers</a>: Computers, trust, and the knowability of the universe.
</li>
<li attrs="{'class': ['xToC']}"><a attrs="{'href': '#xslug'}" href="https://pluralistic.net/2020/12/05/trusting-trust/#retro">This day in history</a>: 2005, 2010, 2019
</li>
<li attrs="{'class': ['xToC']}"><a attrs="{'href': '#xslug'}" href="https://pluralistic.net/2020/12/05/trusting-trust/#bragsheet">Colophon</a>: Recent publications, upcoming appearances, current writing projects, current reading
</li>
</ul>

<hr>
<p><a name="thompsons-devil"></a><br>
<img src="https://i1.wp.com/craphound.com/images/NGSCBWHEC03.png?w=840&amp;ssl=1" data-recalc-dims="1" data-lazy-src="https://i1.wp.com/craphound.com/images/NGSCBWHEC03.png?w=840&amp;is-pending-load=1#038;ssl=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></p>

<p>Security researchers are alarmed: the already-notorious Trickbot malware has been spotted probing infected computers to find out which version of UEFI they're running. This is read as evidence that Trickbot has figured out how to pull off a really scary feat.</p>
<p>To understand why, you have to understand UEFI: a fascinating, deep, philosophical change to our view of computers, trust, and the knowability of the universe. It's a tale of hard choices, paternalism, and the race to secure the digital realm as it merges with the physical.</p>
<p>Computers were once standalone: a central processing unit that might be augmented by some co-processors for specialized processes, like a graphics card or even a math co-processor.</p>
<p>These co-pros were subordinate to the CPU though. You'd turn on the computer and it would read a very small set of hardcoded instructions telling it how to access a floppy disk or other storage medium for the rest of the boot sequence, the stuff needed to boot the system.</p>
<p>The hardwired instructions were in a ROM that had one job: wake up and feed some instructions to the "computer" telling it what to do, then go back to sleep. But there's a philosophical conundrum here.</p>
<p>Because the world of computing is adversarial and networked computing is doubly so: there are people who want your computer to do things that are antithetical to your interests, like steal your data or spy on you or encrypt all your files and demand ransom.</p>
<p>To stop this, you need to be able to examine the programs running on your computer and terminate the malicious ones. And therein lies the rub: when you instruct your computer to examine its own workings, how do you know if you can trust it?</p>
<p>In 1983, Ken Thompson (co-creator of C, Unix, etc) was awarded a Turing Award ("computer science's Nobel Prize"). He gave a fucking bombshell of an acceptance speech, called "Reflections on Trusting Trust."</p>
<p><a href="https://www.cs.cmu.edu/~rdriley/487/papers/Thompson_1984_ReflectionsonTrustingTrust.pdf">https://www.cs.cmu.edu/~rdriley/487/papers/Thompson_1984_ReflectionsonTrustingTrust.pdf</a></p>
<p>Thompson revealed that he had created a backdoor for himself that didn't just live in Unix, but in the C compiler that people made to create new Unix systems.</p>
<p>Here's what that means: when you write a program, you produce "high-level code" with instructions like "printf("Hello, World!");". Once your program is done, you turn it into machine code, a series of much shorter instructions that your CPU understands ("mov  dx, msg" etc).</p>
<p>Most programmers can't read this machine code, and even for those who can, it's a hard slog. In general, we write our code, compile it and run it, but we don't examine it. With nontrivial programs, looking at the machine code is very, very hard.</p>
<p>Compilers are treated as intrinsically trustworthy. Give 'em some source, they spit out a binary, you run the binary. Sometimes there are compiler bugs, sure, and compiler improvements can be a big deal. But compilers are infrastructure: inscrutable and forgotten.</p>
<p>Here's what Thompson did: he hid a program in his compiler that would check to see whether you were compiling an operating system or a compiler. If you were compiling an OS, it hid a secret login for him inside of it.</p>
<p>If you were compiling a compiler, it hid the program that looked for compilers or operating systems inside of it.</p>
<p>Think about what this means: every OS you compiled had an intentional security defect that the OS itself couldn't detect.</p>
<p>If you suspected that your compiler was up to no good and wrote your own compiler, it would be compromised as soon as you compiled it. What Thompson did was ask us to contemplate what we meant when we "trusted" something.</p>
<p>It was a move straight out of Rene Descartes, the reasoning that leads up to "I think therefore I am." Descartes' "Discourse on the Method" asks how we can know things about the universe.</p>
<p>He points out that sometimes he thinks he senses something but is wrong – he dreams, he hallucinates, he misapprehends.</p>
<p>If all our reasoning depends on the impressions we get from our senses, and if our senses are sometimes faulty, how can we reason at all?</p>
<p>Descartes wants a point of certainty, one thing he <em>knows</em> to be absolutely true. He makes the case that if you can be certain of one thing, you can anchor everything else to this point and build up a massive edifice of trustable knowledge that all hangs off of this anchor.</p>
<p>Thompson is basically saying, "You thought you had descartesed your way into a trustable computing universe because of the axiom that I would never poison your lowest-level, most fundamental tools.</p>
<p>"<em>Wrong</em>.</p>
<p>"Bwahahahaha."</p>
<p>(But, you know, in a nice way: an object lesson to serve as a wake-up call before computers fully merged with the physical world to form a global, species-wide digital nervous system whose untrustworthy low-level parts were foolishly, implicitly trusted).</p>
<p>But processors were expensive and computers were exploding. PCs running consumer operating systems like Windows and Mac OS (and more exotic ones like GNU/Linux and various Unices) proliferated, and they all shared this flawed security model.</p>
<p>They all relied on the operating system to be a faithful reporter of the computer's internals, and operated on the assumption that they could use programs supervised by the OS to detect and terminate malicious programs.</p>
<p>But starting in 1999, Ken Thompson's revenge was visited upon the computing world. Greg Hoglund released Ntrootkit, a proof-of-concept malware that attacked Windows itself, so that the operating system would lie to antivirus programs about what it was doing and seeing.</p>
<p>In Decartesspeak, your computer could no longer trust its senses, so it could no longer reason. The nub of trust, the piton driven into the mountainface, was made insecure and the whole thing collapsed. Security researchers at big companies like Microsoft took this to heart.</p>
<p>In 2002, Peter Biddle and his team from Microsoft came to EFF to show us a new model for computing: "Trusted Computing" (codenamed "Palladium").</p>
<p><a href="https://web.archive.org/web/20020805211111/https://www.microsoft.com/presspass/features/2002/jul02/0724palladiumwp.asp">https://web.archive.org/web/20020805211111/https://www.microsoft.com/presspass/features/2002/jul02/0724palladiumwp.asp</a></p>
<p>Palladium proposed to give computers back their nub of Descartesian certainty. It would use a co-processor, but unlike a graphics card or a math co-pro, it would run before the CPU woke up and did its thing.</p>
<p>And unlike a ROM, it wouldn't just load up the boot sequence and go back to sleep.</p>
<p>This chip – today called a "Secure Enclave" or a "Trusted Platform Module" (etc) – would have real computing power, and it would remain available to the CPU at all times.</p>
<p>Inside the chip was a bunch of cool cryptographic stuff that provided the nub of certainty. At the start of the boot, the TPM would pull the first stages of the boot-code off of the drive, along with a cryptographic signature.</p>
<p>A quick crypto aside:</p>
<p>Crypto is code that mixes a key (a secret known to the user) with text to produce a scrambled text (a "ciphertext") that can only be descrambled by the key.</p>
<p>Dual-key crypto has two keys. What one scrambles, the other descrambles (and vice-versa).</p>
<p>With dual-key crypto, you keep one key secret (the "private key") and you publish the other one (the "public key"). If you scramble something with a private key, then anyone can descramble it with your public key and know it came from you.</p>
<p>If you scramble it <em>twice</em>, first with your private key and then with your friend's public key, then they can tell it came from you (because only your private key's ciphertexts can be descrambled with your public key).</p>
<p>And <em>you</em> can be certain that only they can read it (because only their private key can descramble messages that were scrambled with their public key).</p>
<p>Code-signing uses dual-key crypto to validate who published some code.</p>
<p>Microsoft can make a shorter version of its code (like a fingerprint) and then you scramble it with its private key. The OS that came with your computer has a copy of MSFT's public key. When you get an OS update, you can descramble the fingerprint with that built-in key.</p>
<p>If it matches the update, then you know that Microsoft signed it and it hasn't been tampered with on its way to you. If you trust Microsoft, you can run the update.</p>
<p>But…What if a virus replaces Microsoft's public keys with its own?</p>
<p>That's where Palladium's TPM comes in. It's got the keys hardcoded into it. Programs running on the CPU can only ask the TPM to do very limited things like ask it to sign some text, or to check the signature on some text.</p>
<p>It's a kind of god-chip, running below the most privileged level of user-accessible operations. By design, you – the owner of the computer – can demand things of it that it is technically capable of doing, and it can refuse you, and you can't override it.</p>
<p>That way, programs running even in the most privileged mode can't compromise it.</p>
<p>Back to our boot sequence: the TPM fetches some startup code from the disk along with a signature, and checks to see whether the OS has been signed by its manufacturer.</p>
<p>If not, it halts and shows you a scary error message. Game over, Ken Thompson!</p>
<p>It is a very cool idea, but it's also very scary, because the chip doesn't take orders from Descartes' omnibenevolent God.</p>
<p>It takes orders from Microsoft, a rapacious monopolist with a history of complicity with human rights abuses. Right from that very first meeting the brilliant EFF technologist Seth Schoen spotted this (and made the Descartes comparison):</p>
<p><a href="https://web.archive.org/web/20021004125515/http://vitanuova.loyalty.org/2002-07-05.html">https://web.archive.org/web/20021004125515/http://vitanuova.loyalty.org/2002-07-05.html</a></p>
<p>Seth identified a way of having your cake and eating it too: he proposed a hypothetical thing called an "owner override" – a physical switch that, when depressed, could be used to change which public keys lived in the chip.</p>
<p>This would allow owners …</p></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://pluralistic.net/2020/12/05/trusting-trust/#thompsons-devil">https://pluralistic.net/2020/12/05/trusting-trust/#thompsons-devil</a></em></p>]]>
            </description>
            <link>https://pluralistic.net/2020/12/05/trusting-trust/#thompsons-devil</link>
            <guid isPermaLink="false">hacker-news-small-sites-25317557</guid>
            <pubDate>Sat, 05 Dec 2020 19:32:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[TeX: A Tale of Two Worlds]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25317503">thread link</a>) | @figomore
<br/>
December 5, 2020 | https://bitbashing.io/tex.html | <a href="https://web.archive.org/web/*/https://bitbashing.io/tex.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
    <!-- for XeTeX -->


<p>Best viewed in <del>Internet Explorer 6</del>
<a href="https://assets.bitbashing.io/papers/tex-tale-of-two-worlds.pdf">PDF</a>
because… well… read the damn thing.</p>

<!--
It all started when a college friend told me about a cool program for typesetting
papers. Now typography books litter my apartment and I can't read a menu
without noticing bad kerning. Thanks, Max. This is all your fault.
-->

<hr>

<p>Most serious programmers have heard of Donald Knuth,
the man who coined the term <em>analysis of algorithms</em> in 1968
and pioneered many of the computer science fundamentals we use today.
Knuth is perhaps most famous for his ongoing magnum opus,
<em>The Art of Computer Programming</em>.</p>

<p>When the first volume of TAOCP was released that same year,
it was printed the way most books had been since the turn of the century:
with <em>hot metal</em> type.
Each individual letter was cast from molten lead,
then arranged into its line.</p>

<figure>
<img src="https://upload.wikimedia.org/wikipedia/commons/7/72/Matrixcase-bembo-16pts.jpg" alt="Monotype matrix case" height="400">
<figcaption>
A case of letter molds—or <em>matrices</em>—used by the Monotype caster,
the most commonly-used machine for printing books in the days of hot metal type.
Its main contemporary, the Linotype, molded entire lines at a time,
and was often used for printing newspapers.
</figcaption>
</figure>

<p>These lines were clamped together to form pages of the book,
which were finally inked and pressed against paper.
By March of 1977, Knuth was ready for a second run of TAOCP, Volume&nbsp;2,
but he was horrified when he received the proofs.
Hot metal typesetting was an expensive, complicated, and time-consuming process,
so publishers had replaced it with phototypesetting,
which works by projecting characters onto film.
The new technology, while much cheaper and faster,
didn’t provide the same level of quality he had come to expect.</p>

<p>The average author would have resigned themselves to the change and moved on,
but Knuth took great pride in print quality,
especially for the mathematics in his books.
Around this time, he discovered an exciting new technology:
digital typesetting.
Instead of working with metal or film,
letters and shapes were built from tiny dots,
often packed together at over 1,000 per inch.
Inspired by this burgeoning tech and frustrated with the current state of affairs,
Knuth set off on one of the greatest yak shaves of all time.
For years, he paused all work on his books to create his own
digital typesetting system.
When the dust settled in 1978, Knuth had the first version of
<span>T<sub>e</sub>X</span>
.<sup id="fnref:1"><a href="#fn:1">1</a></sup></p>

<p>It’s hard to understand how much of a revolution <span>T<sub>e</sub>X</span>
 was,
especially looking back from a time where anybody with a copy
of Word can be their own desktop publisher.
Adobe’s PDF wouldn’t exist for another decade, so Knuth
invented a device-independent format, DVI.
Scalable fonts were uncommon at the time, so Knuth created a system,
<span>METAFONT</span>
, to rasterize his characters into dots on the
page.<sup id="fnref:2"><a href="#fn:2">2</a></sup>
Perhaps most importantly, Knuth and his graduate students designed algorithms
to automatically hyphenate and justify lines of text into
beautifully-typeset paragraphs.</p>

<p>Here is where the timelines diverge.
In one, <span>T<sub>e</sub>X</span>
 was just the beginning.
Computer typography evolves rapidly as the decades go by,
building on Knuth’s prior work and
taking advantage of the million-fold increases we’ve seen in computing power.
Browsers, e-readers, and word processors deliver beautiful type
to every person who looks at a screen, with almost no effort from authors.</p>

<p>In the darker timeline… none of this happens.
<span>T<sub>e</sub>X</span>
 is still some of the best we’ve got for computer typesetting.
It’s seen some impressive improvements,<sup id="fnref:3"><a href="#fn:3">3</a></sup>
but its core hasn’t changed much in decades.
To this day,
it doesn’t lay out more than one page at a time because 1980s computers didn’t
have enough RAM to do any better.<sup id="fnref:4"><a href="#fn:4">4</a></sup>
Almost no other software—except for a handful of professional layout
programs like Adobe InDesign—leverages any of the advances
<span>T<sub>e</sub>X</span>
 made in line breaking and hyphenation.
Layout in Word, browsers, and even e-readers is a sad joke.</p>

<figure>
<img src="https://assets.bitbashing.io/images/exa.png" alt="Mobile browser layout example" height="400">
<figcaption>
State of the art text layout in today's browsers. Mind the gaps.
</figcaption>
</figure>

<p>I’m not sure what to make of this.
Maybe most people, outside a small cadre of designers and
enthusiasts, just don’t care about typography very much.
After all, the human brain is incredibly good glossing over minor details and
im<span>p</span>erfections when reading.
But even the design world seems largely unaware or indifferent to Knuth’s work.
Despite collaborations with famous type designers like Hermann Zapf,
you’ll find no mention of him in renowned books and documentaries on
the subject.<sup id="fnref:5"><a href="#fn:5">5</a></sup>
And parametric font families—just like the ones <span>METAFONT</span>
 offered in 1983—are
heralded in 2017 as “a new era of type design”.<sup id="fnref:6"><a href="#fn:6">6</a></sup>
It’s bizarre.</p>

<p>Good typography can make almost anything more enjoyable to read,
and it feels like such a shame that better layout isn’t
available to the masses
when so much of the groundwork was laid almost forty years ago.
In an age when the average American reads from a screen they keep in their pocket
dozens of times a day,
and where each one of those devices holds more processing power than you could
fit in several rooms back when Donald Knuth
wrote <span>T<sub>e</sub>X</span>
, surely we can—and <em>should</em>—do better.</p>

<hr>



  </article></div>]]>
            </description>
            <link>https://bitbashing.io/tex.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25317503</guid>
            <pubDate>Sat, 05 Dec 2020 19:26:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Special Kind of Hell: intmax_t in C and C++]]>
            </title>
            <description>
<![CDATA[
Score 67 | Comments 108 (<a href="https://news.ycombinator.com/item?id=25316933">thread link</a>) | @ingve
<br/>
December 5, 2020 | https://thephd.github.io/intmax_t-hell-c++-c | <a href="https://web.archive.org/web/*/https://thephd.github.io/intmax_t-hell-c++-c">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
  
      <p>C and C++ as languages have a few things separating them from each other, mostly in their minute details and, occasionally, larger feature sets like designated initializers. But there is a disturbingly high amount of C++ that can simply do C’s job far better than C<!--more-->, including when it comes to solving some of the biggest problems facing the evolution of C and C++.</p>

<p>Let’s take a contemporary problem plaguing both C and C++, affecting everyone from standard library maintainers to project developers, that has been going on for the last 20 or so years: <code>intmax_t</code>.</p>



<p>The concept behind <code>intmax_t</code> is simple enough: it is the largest integer type that your implementation and its standard library support in conjunction. Here is a few things <code>intmax_t</code> controls inside the implementation:</p>

<ul>
  <li>numeric literals are preprocessed according to what <code>intmax_t</code> can handle (C and C++);</li>
  <li>it is the maximum number of bits that can be printed portably, e.g. with <code>printf("%j", (intmax_t)value)</code> (C and C++);</li>
  <li><code>intmax_t</code> is the largest type for which <code>std::numeric_limits</code> applies, including most types up to and including that type (C++ only);</li>
  <li><code>intmax_t</code> underpins <code>std::chrono</code>’s casts and similar (e.g. no information is lost during conversions out of and into the system) (C++ only);</li>
  <li>and, there are a set of integer operations provided by the standard library (like absolute value and quotient / remainder operations) that can be done with the maximum bit precision available to the implementation (C and C++).</li>
</ul>

<p>These properties forge the basis of <code>intmax_t</code>’s purpose. Lossless storage, pass-through operations, and more can all be achieved by relying on this implicit contract of the type. Since it is a type definition, the “real” integer type underneath it can be swapped out and people relying on it can be upgraded seamlessly!</p>



<p>We cannot upgrade seamlessly.</p>

<p>C has a much higher commitment to not breaking old code and keeping “developers close to the machine”. What this actually translates to for most Application Binary Interfaces is very simplistic “name mangling” schemes (i.e., none), <a href="https://twitter.com/__phantomderp/status/1329960075096694790">weak linkers</a>, and other shenanigans. The end result is that we expose C developers to platform details that become invisible dependencies for their code that must be preserved at all costs. For example, let’s take a C Standard function that uses <code>intmax_t</code>, <code>imaxabs</code>:</p>

<div><div><pre><code><span>intmax_t</span> <span>imaxabs</span><span>(</span><span>intmax_t</span> <span>j</span><span>);</span>
</code></pre></div></div>

<p>and, let’s try to figure out how we can upgrade someone off of this usage without breaking their code too badly. We will try fixing this in both C and C++.</p>



<p>Taking <code>intmax_t</code>, let’s do a no-brainer usage case: calling a function with <code>intmax_t</code> input and return types. The syntax and usage ends up looking like this:</p>

<div><div><pre><code><span>#include &lt;inttypes.h&gt;
</span>
<span>int</span> <span>main</span> <span>()</span> <span>{</span>
	<span>intmax_t</span> <span>original</span> <span>=</span> <span>(</span><span>intmax_t</span><span>)</span><span>-</span><span>2</span><span>;</span>
	<span>intmax_t</span> <span>val</span> <span>=</span> <span>imaxabs</span><span>(</span><span>original</span><span>);</span>
	<span>return</span> <span>(</span><span>int</span><span>)</span><span>val</span><span>;</span>
<span>}</span>
</code></pre></div></div>

<p>Easy enough! But, there’s also a hidden dependency here, based on how the code is compiled. While many people compile their C standard library as a static library and only generate final binary code for what they use as to have a “self-contained” binary, the vast majority of the shared ecosystem depends on shared libraries/dynamically linked libraries for the standard. This means that when a program is milled through an operating system at program startup, the “loader” runs off to find the symbol <code>imaxabs</code> inside some system library (e.g., <code>/lib/x86_64-linux-gnu/libc-2.27.so</code> for an “amd64” system). Harmless enough, right? Well, it turns out to be a bit of a problem in practice, because the name <code>imaxabs</code> is all that’s used in C to figure out what subroutine to talk with in some shared library,</p>

<p>and that name is completely inadequate.</p>

<p>Consider the following scenario:</p>

<ol>
  <li>The glibc maintainers decide they’re going to change from <code>long long</code> as their <code>intmax_t</code> and move to <code>__int256_t</code> for most platforms, because most platforms support it and they have a lot of customers asking for it.</li>
  <li>They upgrade the <code>libc</code> to its next version for various Linux distribution, and everyone links against it when they look for the default <code>libc</code>.</li>
  <li>You have an application. Your code was not changed or updated, so it was not recompiled. It calls <code>imaxabs</code>. The argument it passes is a <code>long long</code>, because that was the type at the time you last compiled and shipped your software.</li>
  <li>The <code>imaxabs</code> used to lookup the function to call finds the version that takes a <code>__int256_t</code> in the new <code>libc</code>.</li>
  <li>Different registers are used to pass and return the function value than expected by the <code>imaxabs</code> function call in the <code>libc</code> binary, because your application is in <code>long long</code> mode but glibc expects a <code>__int256_t</code>.</li>
  <li>All hell breaks loose.</li>
</ol>

<p>This is one of the manifestations of what is called an “Application Binary Interface (ABI) Break”. ABI Breaks are generally undetectable, silent breaks that occur within the runtime of a program that completely destroy any dependency your program has on that functionality for correctness. It typically happens when a subtle detail – the registers used to negotiate a large integral value between a shared library and its application, the amount of padding a structure might have on a certain build, the ordering and layout of class members, the interpretation of bits even if the layout or passing convention of a type never changes, and even more – changes.</p>

<h2 id="but-c-is-abi-stable">“But C Is ABI-Stable?!”</h2>

<p>Not necessarily. C is a simple language, and it both sells itself on and prides itself as such. So much so, that it’s even part of the <a href="http://www.open-std.org/jtc1/sc22/wg14/www/docs/n2021.htm">language’s rolling charter</a>. There’s barely any name mangling because there’s no overloading. If you want “virtual functions” you need to hand-craft your virtual table structure and initialize it yourself. There’s barely any lookup or entity negotiation: what you write – <a href="https://twitter.com/thingskatedid/status/1328918322507706368">however scary or cursed</a> – is what you get, in a general sense. (No, it’s not “portable assembly”. Compilers tear C code apart and make it far more efficient than the code people stuff into it. It’s not even a direct model of the machine anymore: just an abstract one.)</p>

<p>Still, sometimes even C can’t get away from it. The function <code>imaxabs</code> relates to exactly one entity that, for historical reasons, was pinned to a function taking and returning a <code>long long</code>. Upgrading it means dealing with this schism between what the user expects (<code>intmax_t</code> that got upgraded and can print <code>__int128_t</code>/<code>__int256_t</code>) with old, non-recompiled code that maintains the old invariant (<code>long long</code>, a 64-bit number).</p>



<p>Okay, so symbols can be repurposed between library versions that lead to ABI breaks. What are the ways to defend against such a world, in C?</p>

<h2 id="macros">Macros?</h2>

<p>Macros! Object-like macros are fun. You could do something like this…</p>

<div><div><pre><code><span>#define imaxabs __glibc228_imaxabs
</span></code></pre></div></div>

<p>… as a way to provide the <code>imaxabs</code> function. It is a bit like artisanal, hand-crafted, free-range, and organic ABI versioning (or, as I have affectionately come to call it: personal masochism to make up for language failures). This mostly works, until… it doesn’t!</p>

<h3 id="714">§7.1.4</h3>

<p>This is the “ABI Breaks Guaranteed” section in the C Standard. It’s real name is “§7.1.4 Use of library functions”. Reproduced below is the relevant piece that condemns us, emphasis mine:</p>

<blockquote>
  <p>Any function declared in a header may be additionally implemented as a function-like macro defined in the header, so if a library function is declared explicitly when its header is included, one of the techniques shown below can be used to ensure the declaration is not affected by such a macro. <strong>Any macro definition of a function can be suppressed locally by enclosing the name of the function in parentheses</strong>, because the name is then not followed by the left parenthesis that indicates expansion of a macro function name. For the same syntactic reason, it is permitted to take the address of a library function even if it is also defined as a macro. <strong>The use of <code>#undef</code> to remove any macro definition will also ensure that an actual function is referred to</strong>.</p>
</blockquote>

<p>Not only can a user suppress a function-like macro invocation by using the same trick used on <code>&lt;windows.h&gt;</code> like <code>(max)(value0, value1)</code>, but the C Standard Library permits them to also undefine function names:</p>

<div><div><pre><code><span>// implementer code: inttypes.h</span>
<span>#define imaxabs __glibc228_imaxabs
</span></code></pre></div></div>

<div><div><pre><code><span>// user code: main.c</span>
<span>#include &lt;inttypes.h&gt;
</span>
<span>#undef imaxabs // awh geez
</span>
<span>int</span> <span>main</span> <span>()</span> <span>{</span>
	<span>intmax_t</span> <span>val</span> <span>=</span> <span>-</span><span>1</span><span>;</span>
	<span>intmax_t</span> <span>absval</span> <span>=</span> <span>imaxabs</span><span>(</span><span>val</span><span>);</span> <span>// awH GEEZ</span>
	<span>return</span> <span>(</span><span>int</span><span>)</span><span>absval</span><span>;</span>
<span>}</span>
</code></pre></div></div>

<p>Mmm……</p>

<h3 id="implementation-specific-strategies">Implementation-specific strategies</h3>

<p>Alright, the C Standard basically loads a double barrel and brings our only standardized mitigation strategy out back behind the barn. What’s left? Well, implementation-specific insanity, that’s what:</p>

<div><div><pre><code><span>extern</span>
<span>intmax_t</span>
<span>__glibc228_imaxabs</span><span>(</span><span>intmax_t</span><span>);</span>

<span>__attribute</span><span>((</span><span>symbol</span><span>(</span><span>__MANGLE</span><span>(</span><span>__glibc228_imaxabs</span><span>))))</span>
<span>extern</span>
<span>intmax_t</span>
<span>imaxabs</span><span>(</span><span>intmax_t</span><span>);</span>
</code></pre></div></div>

<p>This is pseudo-code. But, wouldn’t you believe it, some implementations actually do things very similar to this to get around these problems! The things they do are far more involved, like actually dropping down to the level of the linker and creating symbol maps and other exceedingly painful workarounds. The sed scripts and the awk scripts and the bash starts coming out, people are doing lots of text processing to get symbol names and match them to versioned symbol names…</p>

<p>It’s a mess.</p>

<p>Still, given the mess, it does save us from the problem. In C code you get to use “the real name” <code>imaxabs</code> as Our Lord and Savior intended, the binary gets linked to <code>___glibc228_imaxabs</code>, and everyone’s happy. There’s only one problem with this kind of fix…</p>

<p>It’s Quality of Implementation (QoI).</p>

<p>QoI is great for the pure, theoretical standard. We get to write sexy narratives in the C standard and call them “Recommended Practice”, with little footnotes furtively implying a more wonderful world while waggling our eyebrows seductively at hot, young developers in our area. Just come along, it’s going to be so great, we’re going have soooooo much fun, just go with that lovely little implementation right over there, you’re making such fine progress, enjoy yourself and come back soon my …</p></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://thephd.github.io/intmax_t-hell-c++-c">https://thephd.github.io/intmax_t-hell-c++-c</a></em></p>]]>
            </description>
            <link>https://thephd.github.io/intmax_t-hell-c++-c</link>
            <guid isPermaLink="false">hacker-news-small-sites-25316933</guid>
            <pubDate>Sat, 05 Dec 2020 18:30:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How Distributed Systems Fail]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25316475">thread link</a>) | @parsecs
<br/>
December 5, 2020 | https://robertovitillo.com/how-distributed-systems-fail/ | <a href="https://web.archive.org/web/*/https://robertovitillo.com/how-distributed-systems-fail/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><header><p>December 05, 2020</p></header><p>At scale, any failure that can happen will eventually happen. Hardware failures, software crashes, memory leaks - you name it. The more components you have, the more failures you will experience.</p><p>This nasty behavior is caused by <em>cruel math</em> - given an operation that has a certain probability of failing, as the total number of operations performed increases, so does the total number of failures. In other words, as you scale out your application to handle more load, the more failures it will experience.</p><p>To protect your application against failures, you first need to know what can go wrong. Assuming you are using a cloud provider and not maintaning your own datacenter, the most common failures you will encounter are caused by single points of failure, the network being unreliable, slow processes, and unexpected load.</p><h2 id="single-point-of-failure"><a href="#single-point-of-failure" aria-label="single point of failure permalink"></a>Single Point of Failure</h2><p>A single point of failure is the most glaring cause of failure in a distributed system - it’s that one component that when it fails brings down the entire system with it. In practice, distributed systems can have multiple single points of failure.</p><p>A service that to start up needs to read its configuration from a non-replicated database is an example of a single point of failure - if the database isn’t reachable, the service won’t be able to start. </p><p>A more subtle example is a service that exposes a HTTP API on top of TLS and uses a certificate that needs to be manually renewed. If the certificate isn’t renewed by the time it expires, then most clients trying to connect to it wouldn’t be able to open a connection with the service. </p><p>Single points of failure should be identified when the system is architected before they can cause any harm. The best way to detect them is to examine every component of the system and ask what would happen if that component were to fail. Some single points of failure can be architected away, e.g., by introducing redundancy, while others can’t. In that case, the only option left is to minimize the blast radius.</p><h2 id="unreliable-network"><a href="#unreliable-network" aria-label="unreliable network permalink"></a>Unreliable Network</h2><p>When a client make a remote network call, it sends a request to a server and expects to receive a response from it a while later. In the best case, the client receives a response shortly after sending the request. But what if the client waits and waits and still doesn’t get a response? </p><p>In that case, the client doesn’t know whether a response will eventually arrive or not. At that point it has only two options, it can either continue to wait, or fail the request with an exception or an error.</p><p>Slow network calls are the <a href="https://robertovitillo.com/default-timeouts/">silent killers</a> of distributed systems. Because the client doesn’t know whether the response is on its way or not, it can spend a long time waiting before giving up, if it gives up at all. The wait can in turn cause degradations that are extremely hard to debug. </p><h2 id="slow-processes"><a href="#slow-processes" aria-label="slow processes permalink"></a>Slow Processes</h2><p>From an observer’s point of view, a very slow process is not very different from one that isn’t running at all - neither can perform useful work. Resource leaks are one of the most common causes of slow processes.</p><p>Memory leaks are arguably the most well-known source of leaks. A memory leak manifests itself with a steady increase in memory consumption over time. Run-times with garbage collection don’t help much either - if a reference to an object that isn’t longer needed is kept somewhere, the object won’t be deleted by the garbage collector. </p><p>A memory leak keeps consuming memory until there is no more of it, at which point the operating system starts swapping memory pages to the disk constantly, all the while the garbage collector kicks in more frequently trying its best to release any shred of memory. The constant paging and the garbage collector eating up CPU cycles make the process slower. Eventually, when there is no more physical memory, and there is no more space in the swap file, the process won’t be able to allocate more memory, and most operations will fail.</p><p>Memory is just one of the many resources that can leak. For example, if you are using a thread pool, you can lose a thread when it blocks on a synchronous call that never returns. If a thread makes a synchronous, and blocking, HTTP call <a href="https://robertovitillo.com/default-timeouts/">without setting a timeout</a>, and the call never returns, the thread won’t be returned to the pool. Since the pool has a fixed size and keeps losing threads, the pool will eventually run out of threads. </p><p>You might think that making <em>asynchronous</em> calls, rather than a synchronous ones, would mitigate the problem in the previous case. But, modern HTTP clients use socket pools to avoid recreating TCP connections and pay a <a href="https://robertovitillo.com/what-every-developer-should-know-about-tcp/">hefty performance fee</a>. If a request is made without a timeout, the connection is never returned to the pool. As the pool has a limited size, eventually there won’t be any connections left to communicate with the host.</p><p>On top of all that, the code you write isn’t the only one accessing memory, threads and sockets. The libraries your application depends on access the same resources, and they can do all kinds of shady things. Without digging into their implementation, assuming it’s open in the first place, you can’t be sure whether they can wreak havoc or not.</p><h2 id="unexpected-load"><a href="#unexpected-load" aria-label="unexpected load permalink"></a>Unexpected Load</h2><p>Every system has a limit to how much load it can withstand without scaling. Depending on how the load increases, you are bound to hit that brick wall sooner or later. But one thing is an organic increase in load, which gives you the time to scale your service out accordingly, and another is a sudden and unexpected spike.</p><p>For example, consider the number of requests received by a service in a period of time. The rate and the type of incoming requests can change over time, and sometimes suddenly, for a variety of reasons:</p><ul><li>The requests might have a seasonality - depending on the hour of the day the service is going to get hit by users in different countries.</li><li>Some requests are much more expensive than others and abuse the system in ways you didn’t really anticipate for, like scrapers slurping in data from your site at super human speed.</li><li>Some requests are malicious - think of DDoS attacks which try to saturate your service’s bandwidth, denying access to the service to legitimate users.</li></ul><h2 id="cascading-failures"><a href="#cascading-failures" aria-label="cascading failures permalink"></a>Cascading Failures</h2><p>You would think that if your system has hundreds of processes, it shouldn’t make much of a difference if a small percentage are slow or unreachable. The thing about faults is that they tend to spread like cancer, propagating from one process to the other until the whole system crumbles to its knees. This effect is also referred to as a <em>cascading failure</em>, which occurs when a portion of an overall system fails, increasing the probability that other portions fail.</p><p>For example, suppose there are multiple clients querying two database replicas A and B, which are behind a load balancer. Each replica is handling about 50 transactions per second.</p><p>{width: 75%}
<span>
      <a href="https://robertovitillo.com/static/ecfe94692571e20020cb4f0d878fdc89/67fe0/cascading_failure_1.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="cascading failure 1" title="cascading failure 1" src="https://robertovitillo.com/static/ecfe94692571e20020cb4f0d878fdc89/fcda8/cascading_failure_1.png" srcset="https://robertovitillo.com/static/ecfe94692571e20020cb4f0d878fdc89/12f09/cascading_failure_1.png 148w,https://robertovitillo.com/static/ecfe94692571e20020cb4f0d878fdc89/e4a3f/cascading_failure_1.png 295w,https://robertovitillo.com/static/ecfe94692571e20020cb4f0d878fdc89/fcda8/cascading_failure_1.png 590w,https://robertovitillo.com/static/ecfe94692571e20020cb4f0d878fdc89/efc66/cascading_failure_1.png 885w,https://robertovitillo.com/static/ecfe94692571e20020cb4f0d878fdc89/67fe0/cascading_failure_1.png 1101w" sizes="(max-width: 590px) 100vw, 590px" loading="lazy">
  </a>
    </span></p><p>Suddenly, replica B becomes unavailable because of a network fault. The load balancer detects that B is unavailable and removes it from its pool. Because of that, replica A has to pick up the slack for replica B, doubling the load it was previously under. </p><p>{width: 75%}
<span>
      <a href="https://robertovitillo.com/static/ddb5573d64e37dc344b9f58b15a91b97/561da/cascading_failure_2.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="cascading failure 2" title="cascading failure 2" src="https://robertovitillo.com/static/ddb5573d64e37dc344b9f58b15a91b97/fcda8/cascading_failure_2.png" srcset="https://robertovitillo.com/static/ddb5573d64e37dc344b9f58b15a91b97/12f09/cascading_failure_2.png 148w,https://robertovitillo.com/static/ddb5573d64e37dc344b9f58b15a91b97/e4a3f/cascading_failure_2.png 295w,https://robertovitillo.com/static/ddb5573d64e37dc344b9f58b15a91b97/fcda8/cascading_failure_2.png 590w,https://robertovitillo.com/static/ddb5573d64e37dc344b9f58b15a91b97/efc66/cascading_failure_2.png 885w,https://robertovitillo.com/static/ddb5573d64e37dc344b9f58b15a91b97/561da/cascading_failure_2.png 969w" sizes="(max-width: 590px) 100vw, 590px" loading="lazy">
  </a>
    </span></p><p>As replica A starts to struggle to keep up with the incoming requests, the clients experience more failures and timeouts. In turn, they retry the same failing requests several times, adding insult to injury. </p><p>Eventually, replica A is under so much load that it can no longer serve requests promptly, and becomes for all intent and purposes unavailable, causing replica A to be removed from the load balancer’s pool. In the meantime, replica B becomes available again and the load balancer puts it back in the pool, at which point it’s flooded with requests that kill the replica instantaneously. This feedback loop of doom can repeat several time.</p><p>Cascading failures are very hard to get under control once they have started. The best way to mitigate one is to not have it in the first place by stopping the cracks in your services to propagate to others.</p><h2 id="defense-mechanisms"><a href="#defense-mechanisms" aria-label="defense mechanisms permalink"></a>Defense Mechanisms</h2><p>There is a variety of best practices you can use to mitigate failures, like circuit breakers, load shedding, rate-limiting and bulkheads. I plan to blog about those in the future, but in the meantime Google is your friend. Also, I have an entire chapter dedicated to resiliency patterns in my <a href="https://distributedsystemsmanual.com/">book about distributed systems</a>. </p><hr></article></div>]]>
            </description>
            <link>https://robertovitillo.com/how-distributed-systems-fail/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25316475</guid>
            <pubDate>Sat, 05 Dec 2020 17:42:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Benefits of Walking]]>
            </title>
            <description>
<![CDATA[
Score 214 | Comments 105 (<a href="https://news.ycombinator.com/item?id=25316328">thread link</a>) | @KlimYadrintsev
<br/>
December 5, 2020 | https://klimy.co/blog/benefits-of-walking | <a href="https://web.archive.org/web/*/https://klimy.co/blog/benefits-of-walking">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="blog">
                    <h2>How long does it take to walk 1 mile?</h2>
<p>As both research and actual scientific measurements, an average adult will walk 1 mile in 15 to 18 minutes at moderate to a brisk pace. Or in other words, 3 to 4 miles per hour.</p>
<p>This is a general measure for a healthy adult between 20 and 50 years old, at dry weather, on relatively flat terrain, with no destruction from cars and other environments.</p>
<p>If you are either less healthy or subjected to any of the environmental distractions, your speed, of course, will be lower.</p>
<h2>Average walking speed by age group and gender</h2>
<p>There is little difference between male and female, with males walking on average 2% faster.</p>
<p>The table below shows the speed of walking based on age and gender:</p>
<pre><code>| Age      | Sex    | Meters per second | Miles per hour |
|----------|--------|-------------------|----------------|
| 20 to 29 | Male   | 1.36              | 3.04           |
|          | Female | 1.34              | 3.0            |
| 30 to 39 | Male   | 1.43              | 3.2            |
|          | Female | 1.34              | 3.0            |
| 40 to 49 | Male   | 1.43              | 3.2            |
|          | Female | 1.39              | 3.11           |
| 50 to 59 | Male   | 1.43              | 3.2            |
|          | Female | 1.31              | 2.93           |
| 60 to 69 | Male   | 1.34              | 3.0            |
|          | Female | 1.24              | 2.77           |
| 70 to 79 | Male   | 1.26              | 2.82           |
|          | Female | 1.13              | 2.53           |
| 80 to 89 | Male   | 0.97              | 2.17           |
|          | Female | 0.94              | 2.10           |
</code></pre>
<h2>Benefits of walking</h2>
<p>There has been a great deal of research that showed that walking brings a huge advantage to humans. To both <a href="https://journals.sagepub.com/doi/abs/10.1177/0013916518800798">physical, and mental well being.</a> The benefits are as follows:</p>
<p>Physical:</p>
<ul>
<li>Burning calories. A direct way to reduce and to control your weight.</li>
<li>Lower glucose level and blood sugar levels. <a href="https://care.diabetesjournals.org/content/early/2013/06/03/dc13-0084">Research</a> has focused on short walks, where it helped reduce glucose intolerance.</li>
<li><a href="https://bjsm.bmj.com/content/45/12/987?sid=fe62a8c5-430b-4506-b854-20b62e8a5e9e">Help deal with infection and possibly Covid.</a></li>
<li>Help boost immune function.</li>
<li>Give additional energy to do other tasks due to increased efficiency of nutrients absorption and conversion.</li>
<li>Prolonging life. There is a <a href="https://bjsm.bmj.com/content/52/12/761">research that showed</a> evidence of having a relationship between physical activity and overall life expectancy. </li>
<li>Strengthen the heart. Even 20 minutes of daily walking has shown to reduce the risk of stroke by at least 20%.</li>
</ul>
<p>Mental:</p>
<ul>
<li><a href="https://pubs.acs.org/doi/abs/10.1021/es903183r">Improving self esteem</a> by 45%.</li>
<li><a href="https://pubs.acs.org/doi/abs/10.1021/es903183r">Improving mood</a> by 54%.</li>
<li>Additional time on focusing on self-education with educational podcasts and books. <a href="https://digitalcommons.georgiasouthern.edu/nyar_savannah/2020/2020/90/">Research</a> has shown that it leads to better learning of the material, longer retention, better engagement in post-walk discussions, better behaviour and mood, AND improved health literacy.</li>
<li>Improving <a href="https://www.tandfonline.com/doi/abs/10.1080/10413200.2020.1815100">goal setting</a> in other areas by targeting non-specific goals which in consequence lead to better results.</li>
<li>Walking helps you get your thoughts in order. Whenever you are alone with yourself, and you are unable to really look at the phone, you are finally able to understand what is happening with yourself with no distractions.</li>
<li>Improve the creative part of the brain. While walking, <a href="https://psycnet.apa.org/record/2014-14435-001">research showed</a>, that it is easier to come up with great ideas.</li>
<li>Save money on medications. With the amount of food, we consume and with costly medicine, walking and doing exercises can help you save money and nerves.</li>
</ul>
<h2>Covid and sitting time</h2>
<p>In the world of pandemics and covid, it has been evident that humans are sitting more and more and do less and less exercises. There is a <a href="https://www.sciencedirect.com/science/article/pii/S221133552030214X">great research</a> that shows that 2020 has caused a sharp increase in average sitting time. The data is staggering.</p>
<p><code>Overall, 42.6% of participants reported sitting for &gt; 8 h/day (95% CI: 41.2%–44.0%) and 72.5% (71.2%–73.7%) reported being either sufficiently (150–300 MVPA minutes) or highly active (&gt;300 min).</code></p>
<p>If you want to boost your health and still to be able to keep up with a busy schedule walking or running can be the best idea for spending your free time. In the world where only entertainment inside your house is minimal. If being glued to the screen is no longer an option, than being outside can boost your health and your mental capabilities immensely.</p>
<p><img alt="walking in the park grass and women leg" src="https://i.gyazo.com/ecae9926d17ad69ded99b1a445482e9a.jpg"></p>
<h2>Tips on how to start walking</h2>
<h3>How to make walking a habit?</h3>
<p>The walk starts with the first step. It would be best if you did not put huge goals onto yourself. Start somewhere small, then later you can always adjust based on how you feel.</p>
<p>Start by putting on clothes(plus a mask) and go outside. Going back to your apartment would feel bad at that point.</p>
<p>Next, you should walk around your building or up and down the street.</p>
<p>Next, you walk around the block and later you can finally go for huge walks that can be a couple of hours long.</p>
<p>Don’t try to start at the last step that would only make you quit before you get the full benefit of the habit.</p>
<p>Peg your walking habit to something else. If you go for a coffee every morning, go to a coffee house that is further away. If you are usually riding a tube to work, start the journey at the stop further away from you</p>
<h3>Identify as a walker</h3>
<p>If you would like to start walking you need to think of <strong>how do you become a walker.</strong></p>
<p>You need to make sure you identify as someone who goes on walks, then keeping up with the habit will be much easier.</p>
<p>Next time someone asks you, whatever you do any exercises or what you love doing with your free time, you need to want to say that you love walking. At that point, you will be able to keep on walking and improving your health immensely.</p>
<h2>How much walking per week is enough?</h2>
<p>I think that it is tough to give a simple number for everyone, but if you are in the age range of 18-50, then:</p>
<ul>
<li>150 to 300 minutes per week is an ideal level if you are walking with moderate speed</li>
<li>75 to 150 minutes per week if you are walking with a brisk pace.</li>
</ul>
<p>Don’t think that doing extra physical exercise will be useless. In contrast, anything above that time limit will give even higher benefits to your health, so take the timing above as a general guideline. Do as much as you want.</p>
<h2>Personal tips on walking more</h2>
<h3>Wake up earlier</h3>
<p>Right now it is very easy to blame everything on covid and health, but not many people <a href="https://klimy.co/blog/how-to-wake-up-early">wake up very early in the morning</a>, that gives people that live in the city an ability to walk as much as they want, even in usually crowded spaces.</p>
<p>Also, your excuse of not having enough time can not be reinforced if you have an extra hour in the morning.</p>
<h3>Get a pet (dog)</h3>
<p>Even though it can seem like a lousy idea, multiple research papers show a relationship between owning a dog and the number of steps you do daily. If you are struggling to make time, your favourite pet will make you find time for walks.</p>
<p><img alt="man and dog walking in forest autumn" src="https://i.gyazo.com/5e16de8c0474f84f4285df88fab28c14.jpg"></p>
<h3>Podcasts and Audiobooks</h3>
<p>I love learning and listening to books. I do it all the time even when I am at home at my desk, so a change of pace for me is always going for an extended walk where I can do the same thing.</p>
<p>What I discovered is that I understand and remember information much better when I have consumed it while walking. That makes me spend twice as little time and getting twice the result. </p>
<p>Podcasts have been my go-to method of getting new relevant news and information in my field of expertise. Since I have started a habit of walking, I have been on top of my field and able to implement solutions that I would have never thought of otherwise.</p>
<h3>Music</h3>
<p>I also love discovering new music. Sometimes when I really need to get my head around something I go for a brisk walk with my favourite songs. This helps me to unwind and later really understand the problem.</p>
<p>Most of the time while on the walk, I solve the problem that I had, and in my experience would off taken me much more time to solve.</p>
<h3>Walking groups</h3>
<p><img alt="walking groups picture" src="https://i.gyazo.com/26609ccb0d7ae90e9f746389479a32b0.jpg"></p>
<p>Sometimes socialising can be hard and especially when all of your friends are on the lockdown and all of the socialising places, such as restaurants, are closed. </p>
<p>That is where walking groups can come into play! You can find someone who is staying healthy and being diligent with their health and walk together! That will allow you to catch up and have social interaction, that we humans require.</p>
<h5>So what this means?</h5>
<p>Now you have a social responsibility in your habit, and the whole activity can let you be more motivated to do it.</p>
<p>Also, walking groups normally allow you to meet new people and to bond better with existing relationships.</p>
<p>Also, walking groups is a great way to speed up your walking pace and improve your health.</p>
<h2>How do I get better at walking?</h2>
<p>If you would like to improve the speed at which you walk, there are multiple ways to do so:</p>
<ul>
<li>As mentioned above, walking groups are amazing for giving you a speedup of pace, just make sure to not overdo it.</li>
<li>Walking poles (tracking poles) are an easy way to speed up the pace. They are especially useful for those with back or leg injury, that immensely help reduce the stress on joints and back as well as speed up the pace. There is a lot of research behind use cases and benefits of using them.</li>
<li>Treadmills. If you are unable to properly walk in the wild or in the park, get yourself a treadmill. Although they can be expensive, some are very cheap and immensely powerful alternatives provide the same result. You don’t need something overly expensive. Treadmills are great for controlling your pace as well as letting you support yourself with the rails that are at either side of the treadmill.</li>
<li>Have an open goal. Whenever you are walking, the <a href="https://www.tandfonline.com/doi/abs/10.1080/10413200.2020.1815100">research has shown</a> that having an open goal to where you want to walk or for how long will extend the amount of walking that you will eventually do.</li>
<li>Keep track of your metrics. Understanding what your heart rate and your pace are, is vital for your well being and motivation. Seeing that you have improved over a period of time is the greatest motivator there is.</li>
<li>Strive towards a 13 minutes per mile goal. The 13 minutes per mile has been shown to be the meeting point between fast walkers and the joggers. As …</li></ul></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://klimy.co/blog/benefits-of-walking">https://klimy.co/blog/benefits-of-walking</a></em></p>]]>
            </description>
            <link>https://klimy.co/blog/benefits-of-walking</link>
            <guid isPermaLink="false">hacker-news-small-sites-25316328</guid>
            <pubDate>Sat, 05 Dec 2020 17:28:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Improbable Inspiration: Bayesian Networks (1996)]]>
            </title>
            <description>
<![CDATA[
Score 94 | Comments 20 (<a href="https://news.ycombinator.com/item?id=25315982">thread link</a>) | @1e
<br/>
December 5, 2020 | https://www.cs.ubc.ca/~murphyk/Bayes/la.times.html | <a href="https://web.archive.org/web/*/https://www.cs.ubc.ca/~murphyk/Bayes/la.times.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <td>

      <span face="Arial,Helvetica" color="#003366">

      <b>Improbable Inspiration</b><p>
      The future of software may lie in the obscure theories of an
      18th century cleric named Thomas Bayes.

      </p><p>

      By LESLIE HELM, Times Staff Writer

      </p><hr>
      <p>

      When Microsoft Senior Vice President Steve
      Ballmer first heard his company was planning to make a huge
      investment in an Internet service offering movie reviews and
      local entertainment information in major cities across the
      nation, he went to Chairman Bill Gates with his concerns.

      </p><p>

      &nbsp;&nbsp;&nbsp; After all, Ballmer has billions of dollars of
      his own money in Microsoft stock, and entertainment isn't
      exactly the company's strong point.

      </p><p>

      &nbsp;&nbsp;&nbsp; But Gates dismissed such
      reservations. Microsoft's competitive advantage, he responded,
      was its expertise in "Bayesian networks."

      </p><p>

      &nbsp;&nbsp;&nbsp; Asked recently when computers would finally
      begin to understand human speech, Gates began discussing the
      critical role of "Bayesian" systems.

      </p><p>

      &nbsp;&nbsp;&nbsp; Ask any other software executive about
      anything "Bayesian" and you're liable to get a blank
      stare.

      </p><p> 

      &nbsp;&nbsp;&nbsp; Is Gates onto something? Is this
      alien-sounding technology Microsoft's new secret weapon?

      </p><p>

      &nbsp;&nbsp;&nbsp; Quite possibly.
      
      </p><p>

      &nbsp;&nbsp;&nbsp; Bayesian networks are complex diagrams that
      organize the body of knowledge in any given area by mapping out
      cause-and-effect relationships among key variables and encoding
      them with numbers that represent the extent to which one
      variable is likely to affect another.

      </p><p>

      &nbsp;&nbsp;&nbsp; Programmed into computers, these systems can
      automatically generate optimal predictions or decisions even
      when key pieces of information are missing.

      </p><p>

      &nbsp;&nbsp;&nbsp; When Microsoft in 1993 hired Eric Horvitz,
      David Heckerman and Jack Breese, pioneers in the development of
      Bayesian systems, colleagues in the field were surprised. The
      field was still an obscure, largely academic enterprise.

      </p><p>
 
      &nbsp;&nbsp;&nbsp; Today the field is still obscure. But scratch
      the surface of a range of new Microsoft products and you're
      likely to find Bayesian networks embedded in the software. And
      Bayesian nets are being built into models that are used to
      predict oil and stock prices, control the space shuttle and
      diagnose disease.

      </p><p>

      &nbsp;&nbsp;&nbsp; Artificial intelligence (AI) experts, who saw
      their field discredited in the early 1980s after promising a
      wave of "thinking" computers that they ultimately
      couldn't produce, believe widening acceptance of the Bayesian
      approach could herald a renaissance in the field.

      </p><p>
      
      &nbsp;&nbsp;&nbsp; Bayesian networks provide "an
      overarching graphical framework" that brings together
      diverse elements of AI and increases the range of its likely
      application to the real world, says Michael Jordon, professor of
      brain and cognitive science at the Massachusetts Institute of
      Technology.

      </p><p>

      &nbsp;&nbsp;&nbsp; Microsoft is unquestionably the most
      aggressive in exploiting the new approach. The company offers a
      free Web service that helps customers diagnose printing problems
      with their computers and recommends the quickest way to resolve
      them. Another Web service helps parents diagnose their
      children's health problems.

      </p><p>

      &nbsp;&nbsp;&nbsp; The latest version of Microsoft Office
      software uses the technology to offer a user help based on past
      experience, how the mouse is being moved and what task is being
      done.

      </p><p>

      &nbsp;&nbsp;&nbsp; "If his actions show he is distracted,
      he is likely to need help," Horvitz says. "If he's
      been working on a chart, chances are he needs help formatting
      the chart."

      </p><p>

      &nbsp;&nbsp;&nbsp; "Gates likes to talk about how computers
      are now deaf, dumb, blind and clueless. The Bayesian stuff helps
      deal with the clueless part," says Daniel T.  Ling,
      director of Microsoft's research division and a former IBM
      scientist.

      </p><p>

      &nbsp;&nbsp;&nbsp; Bayesian networks get their name from the
      Rev. Thomas Bayes, who wrote an essay, posthumously published in
      1763, that offered a mathematical formula for calculating
      probabilities among several variables that are causally related
      but for which--unlike calculating the probability of a coin
      landing on heads or tails--the relationships can't easily be
      derived by experimentation.

      </p><p>

      &nbsp;&nbsp;&nbsp; Early students of probability applied the
      ideas to discussions about the existence of God or efforts to
      improve their odds in gambling. Much later, social scientists
      used it to help clarify the key factors influencing a particular
      event.

      </p><p>

      &nbsp;&nbsp;&nbsp; But it was the rapid progress in computer
      power and the development of key mathematical equations that
      made it possible for the first time, in the late 1980s, to
      compute Bayesian networks with enough variables that they were
      useful in practical applications.

      </p><p>

      &nbsp;&nbsp;&nbsp; The Bayesian approach filled a void in the
      decades-long effort to add intelligence to computers.

      </p><p>

      &nbsp;&nbsp;&nbsp; In the late 1970s and '80s, reacting to the
      "brute force" approach to problem solving by early
      users of computers, proponents of the emerging field of
      artificial intelligence began developing software programs using
      rule-based, if-then propositions. But the systems took time to
      put together and didn't work well if, as was frequently the
      case, you couldn't answer all the computer's questions clearly.

      </p><p>

      &nbsp;&nbsp;&nbsp; Later companies began using a technique
      called "neural nets" in which a computer would be
      presented with huge amounts of data on a particular problem and
      programmed to pull out patterns. A computer fed with a big stack
      of X-rays and told whether or not cancer was present in each
      case would pick out patterns that would then be used to
      interpret X-rays.

      </p><p>

      &nbsp;&nbsp;&nbsp; But the neural nets won't help predict the
      unforeseen. You can't train a neural net to identify an incoming
      missile or plane because you could never get sufficient data to
      train the system.

      </p><p>

      &nbsp;&nbsp;&nbsp; In part because of these limitations, a slew
      of companies that popped up in the early 1980s to sell
      artificial intelligence systems virtually all went bankrupt.

      </p><p>

      &nbsp;&nbsp;&nbsp; Many AI techniques continued to be
      used. Credit card companies, for example, began routinely using
      neural networks to pick out transactions that don't look right
      based on a consumer's past behavior. But increasingly, AI was
      regarded as a tool with limited use.

      </p><p>

      &nbsp;&nbsp;&nbsp; Then, in the late 1980s--spurred by the early
      work of Judea Pearl, a professor of computer science at UCLA,
      and breakthrough mathematical equations by <a href="http://www.hugin.dk/">Danish researchers</a>--AI
      researchers discovered that Bayesian networks offered an
      efficient way to deal with the lack or ambiguity of information
      that has hampered previous systems.

      </p><p>

      &nbsp;&nbsp;&nbsp; Horvitz and his two Microsoft colleagues, who
      were then classmates at Stanford University, began building
      Bayesian networks to help diagnose the condition of patients
      without turning to surgery.

      </p><p>

      &nbsp;&nbsp;&nbsp; The approach was efficient, says Horvitz,
      because you could combine historical data, which had been
      meticulously gathered, with the less precise but more intuitive
      knowledge of experts on how things work to get the optimal
      answer given the information available at a given time.

      </p><p>

      &nbsp;&nbsp;&nbsp; Horvitz, who with two colleagues founded
      Knowledge Industries to develop tools for developing Bayesian
      networks, says he and the others left the company to join
      Microsoft in part because they wanted to see their theoretical
      work more broadly applied.

      </p><p>

      &nbsp;&nbsp;&nbsp; Although the company did important work for
      the National Aeronautics and Space Administration and on medical
      diagnostics, Horvitz says, "It's not like your grandmother
      will use it."

      </p><p>

      &nbsp;&nbsp;&nbsp; Microsoft's activities in the field are now
      helping to build a groundswell of support for Bayesian ideas.

      </p><p>

      &nbsp;&nbsp;&nbsp; "People look up to Microsoft," says
      Pearl, who wrote one of the key early texts on Bayesian networks
      in 1988 and has become an unofficial spokesman for the
      field. "They've given a boost to the whole area."
                     
      </p><p>

      &nbsp;&nbsp;&nbsp; A researcher at German conglomerate Siemens
      says Microsoft's work has drawn the attention of his superiors,
      who are now looking seriously at applying Bayesian concepts to a
      range of industrial applications.

      </p><p>

      &nbsp;&nbsp;&nbsp; Scott Musman, a computer consultant in
      Arlington, Va., recently designed a Bayesian network for the
      Navy that can identify enemy missiles, aircraft or vessels and
      recommend which weapons could be used most advantageously
      against incoming targets.

      </p><p>

      &nbsp;&nbsp;&nbsp; Musman says previous attempts using
      traditional mathematical approaches on state-of-the-art
      computers would get the right answer but would take two to three
      minutes.

      </p><p>

      &nbsp;&nbsp;&nbsp; "But you only have 30 seconds before the
      missile has hit you," says Musman.

      </p><p>

      &nbsp;&nbsp;&nbsp; General Electric is using Bayesian techniques
      to develop a system that will take information from sensors
      attached to an engine and, based on expert opinion built into
      the system as well as vast amounts of data on past engine
      performance, pinpoint emerging problems.

      </p><p>

      &nbsp;&nbsp;&nbsp; Microsoft is working on techniques that will
      enable the Bayesian networks to "learn" or update
      themselves …</p></span></td></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.cs.ubc.ca/~murphyk/Bayes/la.times.html">https://www.cs.ubc.ca/~murphyk/Bayes/la.times.html</a></em></p>]]>
            </description>
            <link>https://www.cs.ubc.ca/~murphyk/Bayes/la.times.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25315982</guid>
            <pubDate>Sat, 05 Dec 2020 16:53:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Major Flaws of Human Thinking]]>
            </title>
            <description>
<![CDATA[
Score 197 | Comments 99 (<a href="https://news.ycombinator.com/item?id=25315667">thread link</a>) | @dandanua
<br/>
December 5, 2020 | https://dandanua.github.io/posts/major-flaws-of-human-thinking/ | <a href="https://web.archive.org/web/*/https://dandanua.github.io/posts/major-flaws-of-human-thinking/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>As in the lovely child’s quote found on the internet —</p><blockquote><p>I know everything. Except anything I don’t.</p></blockquote><p>— we think that we see everything around us. But we don’t. There are so many things that greatly affect our lives, yet we don’t aware of them. One type of such things is deep inside us — the flaws of our own thinking. Here is my top list of those flaws.</p><h2 id="1-wishful-thinking-conservatism-and-conformism"><strong>1. Wishful thinking, conservatism and conformism</strong></h2><p>By <em>wishful thinking</em> I don’t mean optimism, which is rather speculation about the future. Wishful thinking is when we put more weight on the present knowledge that is pleasant to us, and at the same time ignore the knowledge that is not so nice. For example, people like to ignore the knowledge that puts them in a bad light. This is clearly seen in toxic relationships, where an abuser justifies his actions by “the care” of its victim. A dictator probably thinks that he is doing the best for its nation, while completely ignoring his incapabilities and bad doings. The same is true for groups of people or even nations. An invasion is commonly portrayed as liberation.</p><p>On the other hand, anyone who had experienced an addiction probably knows how it can alter decision-making. “Vodka is an antiseptic, didn’t you know? Let’s drink those bottles so we’ll be healthier!” Gambler thinks that he is going to make money, so his family will be happy. An ordinary gamer thinks that other real affairs are not that important, so it’s ok to spend more time on the game.</p><p>This is just few examples, but such thinking is so common that I don’t think a single book will be enough to collect all different “use cases”.</p><hr><p>Another flaw of our thinking is <em>conservatism</em> — an insufficient ability to change our common views and beliefs with the new data, new evidence. This is understandable — changing basis views leads to a reconsideration of all related knowledge. An enormous amount of rebuilding is required. Our biological brains just can’t do that in a short time, also it’s much harder with age. Because of this, we give much more weight to old knowledge rather than new evidence, thus making a conservatism bias.</p><p>In our rapidly changing world, this problem will have even more impact.</p><hr><p><em>Conformism</em> is when we weigh our knowledge in accordance with our community. The effect of this is highly underrated. An ordinary human thinks that “her thoughts are her own”, without realizing to what extent they are shaped by a community. I think that we’re all conformists to some degree. And it’s hard to imagine what’s that means not to be. This is proved by numerous experiments with a group of actors and one unsuspicious testee, where actors trick the testee to make some ridiculous statements or to do some crazy actions, like the one described <a href="https://www.youtube.com/watch?v=vjP22DpYYh8">here</a>. We are social creatures.</p><p>An extreme version of conformist thinking is the one imposed by religion. I’m not against religions in general, they can be useful, but a blind belief, an unquestioning subordination to “sacred” authorities — that’s just a disaster for a clear mind. A clear mind should have the ability to stress any dogmas.</p><h2 id="2-binary-black-and-white-thinking-overgeneralization"><strong>2. Binary (black-and-white) thinking, overgeneralization</strong></h2><p>Good-evil, smart-stupid, beautiful-ugly, tall-short, fast-slow, and so on and on. We think in binary terms. Our language reflects that. And some people are stuck very hard in such thinking. The worst case of it is <em>all-or-nothing</em> thinking, when any result other than the best is considered as a failure. It causes stress and depression in people. They don’t realize anymore why the world is so mean to them. They stop seeing how many gradients are there, and also how colorful our world is.</p><p>A similar flaw is <em>overgeneralization</em>. We put into the same category very broad types of information. Prejudice, labeling, stereotypes are all related to overgeneralization.</p><h2 id="3-self-projecting-thinking"><strong>3. Self-projecting thinking</strong></h2><p>Mind reading is an ability that everyone would like to have. It would be so easier to communicate. Also, it’s an advantage if we could read the thoughts of our rivals. While we can’t do it in reality, we’re still trying to predict other people’s thoughts, both in collaboration and confrontation.</p><p>To make such predictions we use two main assumptions:</p><ol><li>Other people see the same things as we do.</li><li>Other people are like us, thus their way of thinking is similar to ours.</li></ol><p>Based on these assumptions we use our way of thinking to deduce the thoughts of others. And this is very natural since we have to model another person’s thinking somehow. But the only model that we have is ours. It’s the only model that we can use. So, we essentially project our mind into another person’s head.</p><p>This has a fatal flaw. Because both main assumptions are only half true. While we see the same bits of the world, perception is a way more complex process. From bits we see high-order patterns, but they can be very personal. People could see different patterns and focus on different things. Also, the same bits (e.g. colors) can cause different emotions. Associations are also personal. The way we do conclusions is also very different in people because every person has its own experience, principles, beliefs, preferences, etc. We do not understand how unique the mind of every human.</p><p>And this causes a lot of trouble. People are fighting because of misunderstandings. In most situations they don’t realize, that they are fighting against their own reflection (from a distorting mirror).</p><h2 id="4-human-centric-thinking"><strong>4. Human-centric thinking</strong></h2><p>Humans are extremely focused on their own businesses. Yes, we are successful as a whole, in comparison to other creatures. But we are still part of nature. We follow its laws. Despite this, we neglect nature and the life of other species at scale.</p><p>Moreover, we value leaders, rulers and heroes amongst us much more than others. Even in fiction secondary characters usually die (who cares), while all hail goes to the main performers. We think that leaders are responsible for like 99% of the job done. Thus, we are trying to analyze them, rather than abstract patterns, situations and laws of nature. For example, from the popular culture it may look like Hitler was solely responsible for WWII and the Holocaust. Yeah, sure. How about WWI? Or any other war, genocide, mass conflict in human history? It’s silly to think that all these things were mainly because of leaders. This is just how humans work. In every moment in history there is a mix of wishes, intentions, beliefs, possibilities, thoughts of a total population. It could be that nature just picks a random guy as a leader that represents the mass.</p><p>On the other hand, we think that human is a singular, indivisible unit. That’s also not true. We are a composition of attributes, that are selected by evolution. Any child has some attributes from its mother and some attributes from its father. Human is a composable organism, the same is true for its mind. I’m sure that everyone experienced competing thoughts in his head. There is a natural selection of thoughts ongoing in the mind of every human.</p><h2 id="5-false-associations-confusion-of-causation-and-correlation"><strong>5. False associations, confusion of causation and correlation</strong></h2><p>Our thinking is associative, and we can make connections very fast based on very small data. A typical example is superstition, which is clearly seen in <a href="https://www.psychologistworld.com/superstition">pigeon experiments</a>.</p><p>Survival bias and filtering are accompanying flaws that lead to false associations. In probability theory, this is related to the fact that independent events are not necessary conditionally independent.</p><p>Even when our associations are quite objective we can make false conclusions about the causes. In fact, in probability theory and statistics the notion of a <em>cause</em> is not even defined. Events can be either correlated or independent in this theory. To deduce <em>what causes what</em> we use other tools, like common sense, physics, etc. Typically, to deduce a causation from two correlated events, we check two main things:</p><ol><li>One event is earlier in time than another one.</li><li>There is no common cause that could explain the correlation.</li></ol><p>This is hard stuff even for scientists. Because you have to exclude any possible common cause. Earlier we could use physical locality of events to exclude a lot of possible common causes. But with the advance of quantum mechanics, even locality is not a reliable factor anymore.</p><h2 id="final-words"><strong>Final words</strong></h2><p>There are a lot of other flaws, if you want to learn more you can start <a href="https://en.wikipedia.org/wiki/Cognitive_bias">here</a> and <a href="https://en.wikipedia.org/wiki/Cognitive_distortion">here</a>. But those described above I find the most impactful. I feel them myself and meet them all the time.</p></div></div>]]>
            </description>
            <link>https://dandanua.github.io/posts/major-flaws-of-human-thinking/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25315667</guid>
            <pubDate>Sat, 05 Dec 2020 16:22:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[An accessible introduction to type theory and implementing a type-checker]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 3 (<a href="https://news.ycombinator.com/item?id=25315243">thread link</a>) | @mrathi12
<br/>
December 5, 2020 | https://mukulrathi.co.uk/demystifying-deep-learning/backpropagation-computation-graph-lstm/ | <a href="https://web.archive.org/web/*/https://mukulrathi.co.uk/demystifying-deep-learning/backpropagation-computation-graph-lstm/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><h3>Demystifying Deep Learning: Part 11</h3><p><h3>September 17, 2018</h3><h3>5 min read</h3></p><nav><h2>Series: Demystifying Deep Learning</h2><ul><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li></li><li><strong>Part 11: Backpropagation through, well, anything!</strong></li></ul></nav><hr><h2 id="introduction"><a href="#introduction" aria-label="introduction permalink"></a>Introduction</h2><p>So far in this series, we have looked at the general principle of <a href="https://mukulrathi.co.uk/demystifying-deep-learning/learning-gradient-descent">gradient descent</a>, and how we computed <a href="https://mukulrathi.co.uk/demystifying-deep-learning/backpropagation-maths-intuition-derivation-neural-network/">backpropagation</a> for each layer in a feedforward neural network, then generalising to look at <a href="https://mukulrathi.co.uk/demystifying-deep-learning/conv-net-backpropagation-maths-intuition-derivation/">backprop in different types of layers in a CNN</a>.</p><p>Now we will take a step back and look at backpropagation in a more general sense - <em>through a computation graph</em>. Through this we’ll get a general intuition for how the frameworks compute their</p><p>We’ll use the LSTM cell as our motivating example - to continue the task of sentiment analysis on the IMDB review dataset - you can find the code in the accompanying <a href="https://github.com/mukul-rathi/deep-learning-tutorials/tree/master/RecurrentNeuralNet">Jupyter notebook</a></p><h2 id="general-backpropagation-principles"><a href="#general-backpropagation-principles" aria-label="general backpropagation principles permalink"></a>General Backpropagation Principles</h2><p>Let’s look back at the principles we’ve used in this series:</p><ul><li><p><em>Partial Derivative Intuition</em>: Think of <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mrow><mi mathvariant="normal">∂</mi><mi>y</mi></mrow><mrow><mi mathvariant="normal">∂</mi><mi>x</mi></mrow></mfrac></mrow><annotation encoding="application/x-tex">\frac{\partial{y}}{\partial{x}}</annotation></semantics></math></span></span> loosely as quantifying how much <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>y</mi></mrow><annotation encoding="application/x-tex">y</annotation></semantics></math></span></span> would change if you gave the value of <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>x</mi></mrow><annotation encoding="application/x-tex">x</annotation></semantics></math></span></span> a little “nudge” at that point.</p></li><li><p><em>Breaking down computations</em> - we can use the <strong>chain rule</strong> to aid us in our computation - rather than trying to compute the derivative in one fell swoop, we break up the computation into smaller <strong>intermediate</strong> steps.</p></li><li><p><em>Computing the chain rule</em> - when thinking about which intermediate values to include in our chain rule expression, think about the immediate outputs of equations involving <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>x</mi></mrow><annotation encoding="application/x-tex">x</annotation></semantics></math></span></span> - which other values get directly affected when we slightly nudge <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>x</mi></mrow><annotation encoding="application/x-tex">x</annotation></semantics></math></span></span>?</p></li><li><p><em>One element at a time</em> - rather than worrying about the entire matrix <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi></mrow><annotation encoding="application/x-tex">A</annotation></semantics></math></span></span>, we’ll instead look at an element <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>A</mi><mrow><mi>i</mi><mi>j</mi></mrow></msub></mrow><annotation encoding="application/x-tex">A_{ij}</annotation></semantics></math></span></span>. One equation we will refer to time and time again is:</p><p><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>C</mi><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo>=</mo><msub><mo>∑</mo><mi>k</mi></msub><msub><mi>A</mi><mrow><mi>i</mi><mi>k</mi></mrow></msub><msub><mi>B</mi><mrow><mi>k</mi><mi>j</mi></mrow></msub><mtext>  </mtext><mo>⟺</mo><mtext>  </mtext><mi>C</mi><mo>=</mo><mi>A</mi><mi mathvariant="normal">.</mi><mi>B</mi></mrow><annotation encoding="application/x-tex">C_{ij} = \sum_k A_{ik}B_{kj} \iff  C=A.B</annotation></semantics></math></span></span></p><p>A useful tip when trying to go from one element to a matrix is to look for summations over repeated indices (here it was k) - this suggests a matrix multiplication.</p><p>Another useful equation is the element-wise product of two matrices:</p><p><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>C</mi><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo>=</mo><msub><mi>A</mi><mrow><mi>i</mi><mi>j</mi></mrow></msub><msub><mi>B</mi><mrow><mi>i</mi><mi>j</mi></mrow></msub><mtext>  </mtext><mo>⟺</mo><mtext>  </mtext><mi>C</mi><mo>=</mo><mi>A</mi><mo>∗</mo><mi>B</mi></mrow><annotation encoding="application/x-tex">C_{ij} = A_{ij}B_{ij} \iff  C=A*B</annotation></semantics></math></span></span></p></li><li><p><em>Sanity check the dimensions</em> - check the dimensions of the matrices all match (the derivative matrix should have same dimensions as the original matrix, and all matrices being multiplied together should have dimensions that align.</p></li></ul><p>A <strong>computation graph</strong> allows us to clearly break down the computations, as well as see the immediate outputs when computing our chain rule.</p><p>We will use the computation graph representation <em>(shown above</em>) of the LSTM to compute the gradients using backpropagation through time.</p><h2 id="the-lstm-computation-graph"><a href="#the-lstm-computation-graph" aria-label="the lstm computation graph permalink"></a>The LSTM Computation Graph</h2><h3 id="forward-propagation-equations"><a href="#forward-propagation-equations" aria-label="forward propagation equations permalink"></a>Forward Propagation equations</h3><p>From the <a href="https://mukulrathi.co.uk/demystifying-deep-learning/lstm-recurrent-neural-network-from-scratch/">previous post</a>, the forward propagation equations for one timestep in the LSTM are:</p><p><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="normal">Γ</mi><mi>i</mi></msub><mo>=</mo><mi>σ</mi><mo stretchy="false">(</mo><msub><mi>W</mi><mi>i</mi></msub><mi mathvariant="normal">.</mi><mo stretchy="false">[</mo><msup><mi>a</mi><mrow><mo>&lt;</mo><mi>t</mi><mo>−</mo><mn>1</mn><mo>&gt;</mo></mrow></msup><mo separator="true">,</mo><msup><mi>x</mi><mrow><mo>&lt;</mo><mi>t</mi><mo>&gt;</mo></mrow></msup><mo stretchy="false">]</mo><mo>+</mo><msub><mi>b</mi><mi>i</mi></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\Gamma_i = \sigma(W_i.[a^{&lt; t-1&gt;}, x^{&lt; t&gt;}]+b_i)</annotation></semantics></math></span></span></p><p><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="normal">Γ</mi><mi>f</mi></msub><mo>=</mo><mi>σ</mi><mo stretchy="false">(</mo><msub><mi>W</mi><mi>f</mi></msub><mi mathvariant="normal">.</mi><mo stretchy="false">[</mo><msup><mi>a</mi><mrow><mo>&lt;</mo><mi>t</mi><mo>−</mo><mn>1</mn><mo>&gt;</mo></mrow></msup><mo separator="true">,</mo><msup><mi>x</mi><mrow><mo>&lt;</mo><mi>t</mi><mo>&gt;</mo></mrow></msup><mo stretchy="false">]</mo><mo>+</mo><msub><mi>b</mi><mi>f</mi></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\Gamma_f = \sigma(W_f.[a^{&lt; t-1&gt;}, x^{&lt; t&gt;}]+b_f)</annotation></semantics></math></span></span></p><p><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="normal">Γ</mi><mi>o</mi></msub><mo>=</mo><mi>σ</mi><mo stretchy="false">(</mo><msub><mi>W</mi><mi>o</mi></msub><mi mathvariant="normal">.</mi><mo stretchy="false">[</mo><msup><mi>a</mi><mrow><mo>&lt;</mo><mi>t</mi><mo>−</mo><mn>1</mn><mo>&gt;</mo></mrow></msup><mo separator="true">,</mo><msup><mi>x</mi><mrow><mo>&lt;</mo><mi>t</mi><mo>&gt;</mo></mrow></msup><mo stretchy="false">]</mo><mo>+</mo><msub><mi>b</mi><mi>o</mi></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\Gamma_o = \sigma(W_o.[a^{&lt; t-1&gt;}, x^{&lt; t&gt;}]+b_o)</annotation></semantics></math></span></span></p><p><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mover accent="true"><mi>c</mi><mo>~</mo></mover><mrow><mo>&lt;</mo><mi>t</mi><mo>&gt;</mo></mrow></msup><mo>=</mo><mi>tanh</mi><mo>⁡</mo><mo stretchy="false">(</mo><msub><mi>W</mi><mi>c</mi></msub><mi mathvariant="normal">.</mi><mo stretchy="false">[</mo><msup><mi>a</mi><mrow><mo>&lt;</mo><mi>t</mi><mo>−</mo><mn>1</mn><mo>&gt;</mo></mrow></msup><mo separator="true">,</mo><msup><mi>x</mi><mrow><mo>&lt;</mo><mi>t</mi><mo>&gt;</mo></mrow></msup><mo stretchy="false">]</mo><mo>+</mo><msub><mi>b</mi><mi>c</mi></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\tilde{c}^{&lt; t&gt;} =\tanh (W_c.[a^{&lt; t-1&gt;}, x^{&lt; t&gt;}]+b_c)</annotation></semantics></math></span></span></p><p><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>c</mi><mrow><mo>&lt;</mo><mi>t</mi><mo>&gt;</mo></mrow></msup><mo>=</mo><msub><mi mathvariant="normal">Γ</mi><mi>i</mi></msub><mo>∗</mo><msup><mover accent="true"><mi>c</mi><mo>~</mo></mover><mrow><mo>&lt;</mo><mi>t</mi><mo>&gt;</mo></mrow></msup><mo>+</mo><msub><mi mathvariant="normal">Γ</mi><mi>f</mi></msub><mo>∗</mo><msup><mi>c</mi><mrow><mo>&lt;</mo><mi>t</mi><mo>−</mo><mn>1</mn><mo>&gt;</mo></mrow></msup></mrow><annotation encoding="application/x-tex">{c}^{&lt; t&gt;} = \Gamma_i*\tilde{c}^{&lt; t&gt;} + \Gamma_f*{c}^{&lt; t-1&gt;}</annotation></semantics></math></span></span></p><p><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>a</mi><mrow><mo>&lt;</mo><mi>t</mi><mo>&gt;</mo></mrow></msup><mo>=</mo><msub><mi mathvariant="normal">Γ</mi><mi>o</mi></msub><mo>∗</mo><mi>tanh</mi><mo>⁡</mo><msup><mi>c</mi><mrow><mo>&lt;</mo><mi>t</mi><mo>&gt;</mo></mrow></msup></mrow><annotation encoding="application/x-tex">a^{&lt; t&gt;} = \Gamma_o*\tanh{c}^{&lt; t&gt;}</annotation></semantics></math></span></span></p><p><strong>Notation used</strong>:</p><p><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">[</mo><msup><mi>a</mi><mrow><mo>&lt;</mo><mi>t</mi><mo>−</mo><mn>1</mn><mo>&gt;</mo></mrow></msup><mo separator="true">,</mo><msup><mi>x</mi><mrow><mo>&lt;</mo><mi>t</mi><mo>&gt;</mo></mrow></msup><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">[a^{&lt; t-1&gt;}, x^{&lt; t&gt;}]</annotation></semantics></math></span></span> denotes a <strong>concatenation of the two matrices</strong> to form a <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><msub><mi>n</mi><mi>a</mi></msub><mo>+</mo><msub><mi>n</mi><mi>x</mi></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(n_a+n_x)</annotation></semantics></math></span></span> x <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>m</mi></mrow><annotation encoding="application/x-tex">m</annotation></semantics></math></span></span> matrix. <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi><mi mathvariant="normal">.</mi><mi>B</mi></mrow><annotation encoding="application/x-tex">A.B</annotation></semantics></math></span></span> denotes matrix multiplication of <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi></mrow><annotation encoding="application/x-tex">A</annotation></semantics></math></span></span> and <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>B</mi></mrow><annotation encoding="application/x-tex">B</annotation></semantics></math></span></span>, whereas <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi><mo>∗</mo><mi>B</mi></mrow><annotation encoding="application/x-tex">A*B</annotation></semantics></math></span></span> denotes elementwise multiplication. <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">Γ</mi></mrow><annotation encoding="application/x-tex">\Gamma</annotation></semantics></math></span></span> refers to the gate - see the <a href="https://mukulrathi.co.uk/demystifying-deep-learning/lstm-recurrent-neural-network-from-scratch/">previous post</a> defining the LSTM for a full breakdown of the notation used.</p><p>To backpropagate through the cell, given the gradient with respect to <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>a</mi><mrow><mo>&lt;</mo><mi>t</mi><mo>&gt;</mo></mrow></msup></mrow><annotation encoding="application/x-tex">a^{&lt; t&gt;}</annotation></semantics></math></span></span> and <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>c</mi><mrow><mo>&lt;</mo><mi>t</mi><mo>&gt;</mo></mrow></msup></mrow><annotation encoding="application/x-tex">c^{&lt; t&gt;}</annotation></semantics></math></span></span> from the backprop from the next step, we need to compute the gradients for each of the weights <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>W</mi><mi>i</mi></msub><mo separator="true">,</mo><msub><mi>W</mi><mi>f</mi></msub><mo separator="true">,</mo><msub><mi>W</mi><mi>o</mi></msub><mo separator="true">,</mo><msub><mi>W</mi><mi>c</mi></msub></mrow><annotation encoding="application/x-tex">W_i, W_f, W_o, W_c</annotation></semantics></math></span></span> and biases <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>b</mi><mi>i</mi></msub><mo separator="true">,</mo><msub><mi>b</mi><mi>f</mi></msub><mo separator="true">,</mo><msub><mi>b</mi><mi>o</mi></msub><mo separator="true">,</mo><msub><mi>b</mi><mi>c</mi></msub></mrow><annotation encoding="application/x-tex">b_i, b_f, b_o, b_c</annotation></semantics></math></span></span>, and finally we will need to backpropagate to the previous timestep and compute the gradient with respect to <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>a</mi><mrow><mo>&lt;</mo><mi>t</mi><mo>−</mo><mn>1</mn><mo>&gt;</mo></mrow></msup></mrow><annotation encoding="application/x-tex">a^{&lt; t-1&gt;}</annotation></semantics></math></span></span> and <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>c</mi><mrow><mo>&lt;</mo><mi>t</mi><mo>−</mo><mn>1</mn><mo>&gt;</mo></mrow></msup></mrow><annotation encoding="application/x-tex">c^{&lt; t-1&gt;}</annotation></semantics></math></span></span>.</p><p>These are a <em>lot</em> of partial derivatives to compute - indeed as our neural networks get more complicated there will be more partial derivatives to calculate.</p><h3 id="how-can-we-use-our-computation-graph-to-break-this-down"><a href="#how-can-we-use-our-computation-graph-to-break-this-down" aria-label="how can we use our computation graph to break this down permalink"></a>How can we use our computation graph to break this down?</h3><p>Firstly, since the gate equations are identical, we can combine them so instead we have a <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>3</mn><msub><mi>n</mi><mi>a</mi></msub></mrow><annotation encoding="application/x-tex">3n_a</annotation></semantics></math></span></span> x <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>m</mi></mrow><annotation encoding="application/x-tex">m</annotation></semantics></math></span></span> matrix <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">Γ</mi></mrow><annotation encoding="application/x-tex">\Gamma</annotation></semantics></math></span></span> containing the 3 gates’ outputs, and we can refer to the first third of the matrix <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="normal">Γ</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">\Gamma_i</annotation></semantics></math></span></span> and the other two thirds <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="normal">Γ</mi><mi>f</mi></msub></mrow><annotation encoding="application/x-tex">\Gamma_f</annotation></semantics></math></span></span> and <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="normal">Γ</mi><mi>o</mi></msub></mrow><annotation encoding="application/x-tex">\Gamma_o</annotation></semantics></math></span></span> respectively. Then we have one <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>3</mn><msub><mi>n</mi><mi>a</mi></msub></mrow><annotation encoding="application/x-tex">3n_a</annotation></semantics></math></span></span> x <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><msub><mi>n</mi><mi>a</mi></msub><mo>+</mo><msub><mi>n</mi><mi>x</mi></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(n_a + n_x)</annotation></semantics></math></span></span> matrix of weights for the gates <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>W</mi><mi>g</mi></msub></mrow><annotation encoding="application/x-tex">W_g</annotation></semantics></math></span></span> and one <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>3</mn><msub><mi>n</mi><mi>a</mi></msub></mrow><annotation encoding="application/x-tex">3n_a</annotation></semantics></math></span></span> x <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn></mrow><annotation encoding="application/x-tex">1</annotation></semantics></math></span></span> bias vector <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>b</mi><mi>g</mi></msub></mrow><annotation encoding="application/x-tex">b_g</annotation></semantics></math></span></span>.</p><p>Next, we want to document all intermediate stages in calculation (every node in the graph).</p><p>So, walking through the computation graph node-by-node in the forward step:</p><ul><li><p>We concatenate <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>a</mi><mrow><mo>&lt;</mo><mi>t</mi><mo>−</mo><mn>1</mn><mo>&gt;</mo></mrow></msup></mrow><annotation encoding="application/x-tex">a^{&lt; t-1&gt;}</annotation></semantics></math></span></span> and <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>x</mi><mrow><mo>&lt;</mo><mi>t</mi><mo>&gt;</mo></mrow></msup></mrow><annotation encoding="application/x-tex">x^{&lt; t&gt;}</annotation></semantics></math></span></span> to form the <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">(</mo><msub><mi>n</mi><mi>a</mi></msub><mo>+</mo><msub><mi>n</mi><mi>x</mi></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">(n_a + n_x)</annotation></semantics></math></span></span> x <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>m</mi></mrow><annotation encoding="application/x-tex">m</annotation></semantics></math></span></span> concatenated input matrix <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">[</mo><msup><mi>a</mi><mrow><mo>&lt;</mo><mi>t</mi><mo>−</mo><mn>1</mn><mo>&gt;</mo></mrow></msup><mo separator="true">,</mo><msup><mi>x</mi><mrow><mo>&lt;</mo><mi>t</mi><mo>&gt;</mo></mrow></msup><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">[a^{&lt; t-1&gt;}, x^{&lt; t&gt;}]</annotation></semantics></math></span></span>.</p></li><li><p>We calculate the weighted input matrix for the gates <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>Z</mi><mi>g</mi></msub></mrow><annotation encoding="application/x-tex">Z_g</annotation></semantics></math></span></span> using the weights <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>W</mi><mi>g</mi></msub></mrow><annotation encoding="application/x-tex">W_g</annotation></semantics></math></span></span> and bias <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>b</mi><mi>g</mi></msub></mrow><annotation encoding="application/x-tex">b_g</annotation></semantics></math></span></span>.</p></li><li><p>Likewise we calculate the weighted input <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>Z</mi><mi>c</mi></msub></mrow><annotation encoding="application/x-tex">Z_c</annotation></semantics></math></span></span> for the candidate memory <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mover accent="true"><mi>c</mi><mo>~</mo></mover><mrow><mo>&lt;</mo><mi>t</mi><mo>&gt;</mo></mrow></msup></mrow><annotation encoding="application/x-tex">\tilde{c}^{&lt; t&gt;}</annotation></semantics></math></span></span> using the weight matrix <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>W</mi><mi>c</mi></msub></mrow><annotation encoding="application/x-tex">W_c</annotation></semantics></math></span></span> and bias <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>b</mi><mi>c</mi></msub></mrow><annotation encoding="application/x-tex">b_c</annotation></semantics></math></span></span>.</p></li></ul><p>(<em>NB:</em> the diagram uses one weight matrix W, but it helps to think about these weights separately because of the different activation functions used)</p><ul><li><p>We apply the sigmoid activation function to <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>Z</mi><mi>g</mi></msub></mrow><annotation encoding="application/x-tex">Z_g</annotation></semantics></math></span></span> to get the Gate matrix <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">Γ</mi></mrow><annotation encoding="application/x-tex">\Gamma</annotation></semantics></math></span></span> (denoted by <strong>f</strong>, <strong>i</strong>, <strong>o</strong> in diagram), and the tanh activation function to <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>Z</mi><mi>c</mi></msub></mrow><annotation encoding="application/x-tex">Z_c</annotation></semantics></math></span></span> to get <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mover accent="true"><mi>c</mi><mo>~</mo></mover><mrow><mo>&lt;</mo><mi>t</mi><mo>&gt;</mo></mrow></msup></mrow><annotation encoding="application/x-tex">\tilde{c}^{&lt; t&gt;}</annotation></semantics></math></span></span> (denoted by <strong>g</strong> in the diagram).</p></li><li><p>Since elementwise multiplication and addition are straightforward operations, for brevity we won’t give the intermediate outputs <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="normal">Γ</mi><mi>i</mi></msub><mo>∗</mo><msup><mover accent="true"><mi>c</mi><mo>~</mo></mover><mrow><mo>&lt;</mo><mi>t</mi><mo>&gt;</mo></mrow></msup></mrow><annotation encoding="application/x-tex">\Gamma_i*\tilde{c}^{&lt; t&gt;}</annotation></semantics></math></span></span> and <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi mathvariant="normal">Γ</mi><mi>f</mi></msub><mo>∗</mo><msup><mi>c</mi><mrow><mo>&lt;</mo><mi>t</mi><mo>−</mo><mn>1</mn><mo>&gt;</mo></mrow></msup></mrow><annotation encoding="application/x-tex">\Gamma_f*{c}^{&lt; t-1&gt;}</annotation></semantics></math></span></span> their own symbols.</p></li><li><p>Let us denote the <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>tanh</mi><mo>⁡</mo><msup><mi>c</mi><mrow><mo>&lt;</mo><mi>t</mi><mo>&gt;</mo></mrow></msup></mrow><annotation encoding="application/x-tex">\tanh{c}^{&lt; t&gt;}</annotation></semantics></math></span></span> intermediate output as <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mover accent="true"><mi>a</mi><mo>~</mo></mover><mrow><mo>&lt;</mo><mi>t</mi><mo>&gt;</mo></mrow></msup></mrow><annotation encoding="application/x-tex">\tilde{a}^{&lt; t&gt;}</annotation></semantics></math></span></span>.</p></li></ul><p>Now we have broken down the computation graph into steps, and added our intermediate variables we have the equations:</p><ol><li><p><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>Z</mi><mi>g</mi></msub><mo>=</mo><msub><mi>W</mi><mi>g</mi></msub><mi mathvariant="normal">.</mi><mo stretchy="false">[</mo><msup><mi>a</mi><mrow><mo>&lt;</mo><mi>t</mi><mo>−</mo><mn>1</mn><mo>&gt;</mo></mrow></msup><mo separator="true">,</mo><msup><mi>x</mi><mrow><mo>&lt;</mo><mi>t</mi><mo>&gt;</mo></mrow></msup><mo stretchy="false">]</mo><mo>+</mo><msub><mi>b</mi><mi>g</mi></msub></mrow><annotation encoding="application/x-tex">Z_g = W_g.[a^{&lt; t-1&gt;}, x^{&lt; t&gt;}]+b_g</annotation></semantics></math></span></span></p></li><li><p><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>Z</mi><mi>c</mi></msub><mo>=</mo><msub><mi>W</mi><mi>c</mi></msub><mi mathvariant="normal">.</mi><mo stretchy="false">[</mo><msup><mi>a</mi><mrow><mo>&lt;</mo><mi>t</mi><mo>−</mo><mn>1</mn><mo>&gt;</mo></mrow></msup><mo separator="true">,</mo><msup><mi>x</mi><mrow><mo>&lt;</mo><mi>t</mi><mo>&gt;</mo></mrow></msup><mo stretchy="false">]</mo><mo>+</mo><msub><mi>b</mi><mi>c</mi></msub></mrow><annotation encoding="application/x-tex">Z_c = W_c.[a^{&lt; t-1&gt;}, x^{&lt; t&gt;}]+b_c</annotation></semantics></math></span></span></p></li><li><p><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="normal">Γ</mi><mo>=</mo><mi>σ</mi><mo stretchy="false">(</mo><msub><mi>Z</mi><mi>g</mi></msub><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\Gamma = \sigma(Z_g)</annotation></semantics></math></span></span></p></li><li><p><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mover accent="true"><mi>c</mi><mo>~</mo></mover><mrow><mo>&lt;</mo><mi>t</mi><mo>&gt;</mo></mrow></msup><mo>=</mo><mi>tanh</mi><mo>⁡</mo><msub><mi>Z</mi><mi>c</mi></msub></mrow><annotation encoding="application/x-tex">\tilde{c}^{&lt; t&gt;} =\tanh Z_c</annotation></semantics></math></span></span></p></li><li><p><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>c</mi><mrow><mo>&lt;</mo><mi>t</mi><mo>&gt;</mo></mrow></msup><mo>=</mo><msub><mi mathvariant="normal">Γ</mi><mi>i</mi></msub><mo>∗</mo><msup><mover accent="true"><mi>c</mi><mo>~</mo></mover><mrow><mo>&lt;</mo><mi>t</mi><mo>&gt;</mo></mrow></msup><mo>+</mo><msub><mi mathvariant="normal">Γ</mi><mi>f</mi></msub><mo>∗</mo><msup><mi>c</mi><mrow><mo>&lt;</mo><mi>t</mi><mo>−</mo><mn>1</mn><mo>&gt;</mo></mrow></msup></mrow><annotation encoding="application/x-tex">{c}^{&lt; t&gt;} = \Gamma_i*\tilde{c}^{&lt; t&gt;} + \Gamma_f*{c}^{&lt; t-1&gt;}</annotation></semantics></math></span></span></p></li><li><p><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mover accent="true"><mi>a</mi><mo>~</mo></mover><mrow><mo>&lt;</mo><mi>t</mi><mo>&gt;</mo></mrow></msup><mo>=</mo><mi>tanh</mi><mo>⁡</mo><msup><mi>c</mi><mrow><mo>&lt;</mo><mi>t</mi><mo>&gt;</mo></mrow></msup></mrow><annotation encoding="application/x-tex">\tilde{a}^{&lt; t&gt;} = \tanh{c}^{&lt; t&gt;}</annotation></semantics></math></span></span></p></li><li><p><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>a</mi><mrow><mo>&lt;</mo><mi>t</mi><mo>&gt;</mo></mrow></msup><mo>=</mo><msub><mi mathvariant="normal">Γ</mi><mi>o</mi></msub><mo>∗</mo><msup><mover accent="true"><mi>a</mi><mo>~</mo></mover><mrow><mo>&lt;</mo><mi>t</mi><mo>&gt;</mo></mrow></msup></mrow><annotation encoding="application/x-tex">a^{&lt; t&gt;} = \Gamma_o*\tilde{a}^{&lt; t&gt;}</annotation></semantics></math></span></span></p></li></ol><p>These equations correspond to the nodes in the graph - the left-hand-side variable is the ouput edge of the node, and the right-hand-side variables are the input edges to the node.</p><h2 id="backpropagation-in-a-computation-graph"><a href="#backpropagation-in-a-computation-graph" aria-label="backpropagation in a computation graph permalink"></a>Backpropagation in a Computation Graph:</h2><p>These equations allow us to clearly see the immediate outputs with respect to a variable when computing the chain rule - <em>e.g. for <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo stretchy="false">[</mo><msup><mi>a</mi><mrow><mo>&lt;</mo><mi>t</mi><mo>−</mo><mn>1</mn><mo>&gt;</mo></mrow></msup><mo separator="true">,</mo><msup><mi>x</mi><mrow><mo>&lt;</mo><mi>t</mi><mo>&gt;</mo></mrow></msup><mo stretchy="false">]</mo></mrow><annotation encoding="application/x-tex">[a^{&lt; t-1&gt;}, x^{&lt; t&gt;}]</annotation></semantics></math></span></span> the immediate outputs are <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>Z</mi><mi>g</mi></msub></mrow><annotation encoding="application/x-tex">Z_g</annotation></semantics></math></span></span> and <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>Z</mi><mi>c</mi></msub></mrow><annotation encoding="application/x-tex">Z_c</annotation></semantics></math></span></span></em>.</p><p>If we look at the equations / computation graph, we can more generally look at the type of operations, and then use the same identities:</p><ul><li><p><strong>Addition</strong>: If <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>C</mi><mo>=</mo><mi>A</mi><mo>+</mo><mi>B</mi></mrow><annotation encoding="application/x-tex">C = A + B</annotation></semantics></math></span></span> then <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mrow><mi mathvariant="normal">∂</mi><mi>C</mi></mrow><mrow><mi mathvariant="normal">∂</mi><mi>A</mi></mrow></mfrac><mo>=</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">\frac{\partial{C}}{\partial{A}} = 1</annotation></semantics></math></span></span> and <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mrow><mi mathvariant="normal">∂</mi><mi>C</mi></mrow><mrow><mi mathvariant="normal">∂</mi><mi>B</mi></mrow></mfrac><mo>=</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">\frac{\partial{C}}{\partial{B}} = 1</annotation></semantics></math></span></span></p></li><li><p><strong>Elementwise multiplication</strong>:
If <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>C</mi><mo>=</mo><mi>A</mi><mo>∗</mo><mi>B</mi></mrow><annotation encoding="application/x-tex">C = A * B</annotation></semantics></math></span></span> then <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mrow><mi mathvariant="normal">∂</mi><mi>C</mi></mrow><mrow><mi mathvariant="normal">∂</mi><mi>A</mi></mrow></mfrac><mo>=</mo><mi>B</mi></mrow><annotation encoding="application/x-tex">\frac{\partial{C}}{\partial{A}} = B</annotation></semantics></math></span></span> and <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mrow><mi mathvariant="normal">∂</mi><mi>C</mi></mrow><mrow><mi mathvariant="normal">∂</mi><mi>B</mi></mrow></mfrac><mo>=</mo><mi>A</mi></mrow><annotation encoding="application/x-tex">\frac{\partial{C}}{\partial{B}} = A</annotation></semantics></math></span></span></p></li><li><p><strong>tanh</strong>: If <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>C</mi><mo>=</mo><mi>tanh</mi><mo>⁡</mo><mi>A</mi></mrow><annotation encoding="application/x-tex">C = \tanh A</annotation></semantics></math></span></span> then <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mrow><mi mathvariant="normal">∂</mi><mi>C</mi></mrow><mrow><mi mathvariant="normal">∂</mi><mi>A</mi></mrow></mfrac><mo>=</mo><mn>1</mn><mo>−</mo><msup><mo><mi>tanh</mi><mo>⁡</mo></mo><mn>2</mn></msup><mi>A</mi><mo>=</mo><mn>1</mn><mo>−</mo><msup><mi>C</mi><mn>2</mn></msup></mrow><annotation encoding="application/x-tex">\frac{\partial{C}}{\partial{A}} = 1 - \tanh^2 A = 1 - C^2</annotation></semantics></math></span></span></p></li><li><p><strong>sigmoid</strong>: If <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>C</mi><mo>=</mo><mi>σ</mi><mo stretchy="false">(</mo><mi>A</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">C = \sigma(A)</annotation></semantics></math></span></span> then <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mrow><mi mathvariant="normal">∂</mi><mi>C</mi></mrow><mrow><mi mathvariant="normal">∂</mi><mi>A</mi></mrow></mfrac><mo>=</mo><mi>σ</mi><mo stretchy="false">(</mo><mi>A</mi><mo stretchy="false">)</mo><mo>−</mo><msup><mi>σ</mi><mn>2</mn></msup><mo stretchy="false">(</mo><mi>A</mi><mo stretchy="false">)</mo><mo>=</mo><mi>C</mi><mo>∗</mo><mo stretchy="false">(</mo><mn>1</mn><mo>−</mo><mi>C</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\frac{\partial{C}}{\partial{A}} = \sigma (A)- \sigma^2 (A) = C*(1-C)</annotation></semantics></math></span></span></p></li><li><p><strong>Weighted Input</strong>: this is the same equation as the <a href="https://mukulrathi.co.uk/demystifying-deep-learning/feed-forward-neural-network/">feedforward neural network</a>. If <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>Z</mi><mo>=</mo><mi>W</mi><mi mathvariant="normal">.</mi><mi>X</mi><mo>+</mo><mi>b</mi></mrow><annotation encoding="application/x-tex">Z =  W.X + b</annotation></semantics></math></span></span> then:</p></li></ul><p><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mrow><mi mathvariant="normal">∂</mi><mi>J</mi></mrow><mrow><mi mathvariant="normal">∂</mi><mi>W</mi></mrow></mfrac><mo>=</mo><mfrac><mn>1</mn><mi>m</mi></mfrac><mfrac><mrow><mi mathvariant="normal">∂</mi><mi>J</mi></mrow><mrow><mi mathvariant="normal">∂</mi><mi>Z</mi></mrow></mfrac><mi mathvariant="normal">.</mi><msup><mi>X</mi><mi>T</mi></msup></mrow><annotation encoding="application/x-tex">\frac{\partial{J}}{\partial{W}}=  \frac{1}{m} \frac{\partial{J}}{\partial{Z}}.X^{T}</annotation></semantics></math></span></span></p><p><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mrow><mi mathvariant="normal">∂</mi><mi>J</mi></mrow><mrow><mi mathvariant="normal">∂</mi><mi>b</mi></mrow></mfrac><mo>=</mo><mfrac><mn>1</mn><mi>m</mi></mfrac><msubsup><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>m</mi></msubsup><mfrac><mrow><mi mathvariant="normal">∂</mi><mi>J</mi></mrow><mrow><mi mathvariant="normal">∂</mi><mi>Z</mi></mrow></mfrac></mrow><annotation encoding="application/x-tex">\frac{\partial{J}}{\partial{b}} = \frac{1}{m} \sum_{i=1}^{m}\frac{\partial{J}}{\partial{Z}}</annotation></semantics></math></span></span></p><p><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mrow><mi mathvariant="normal">∂</mi><mi>J</mi></mrow><mrow><mi mathvariant="normal">∂</mi><mi>X</mi></mrow></mfrac><mo>=</mo><msup><mi>W</mi><mi>T</mi></msup><mi mathvariant="normal">.</mi><mfrac><mrow><mi mathvariant="normal">∂</mi><mi>J</mi></mrow><mrow><mi mathvariant="normal">∂</mi><mi>Z</mi></mrow></mfrac></mrow><annotation encoding="application/x-tex">\frac{\partial{J}}{\partial{X}} = W^{T}.\frac{\partial{J}}{\partial{Z}}</annotation></semantics></math></span></span></p><p>Armed with these general computation graph principles, we can apply <strong>chain rule</strong>. We elementwise multiply (<span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo>∗</mo></mrow><annotation encoding="application/x-tex">*</annotation></semantics></math></span></span>) the partial derivatives, i.e.</p><p><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mrow><mi mathvariant="normal">∂</mi><mi>J</mi></mrow><mrow><mi mathvariant="normal">∂</mi><mi>A</mi></mrow></mfrac><mo>=</mo><mfrac><mrow><mi mathvariant="normal">∂</mi><mi>J</mi></mrow><mrow><mi mathvariant="normal">∂</mi><mi>B</mi></mrow></mfrac><mo>∗</mo><mfrac><mrow><mi mathvariant="normal">∂</mi><mi>B</mi></mrow><mrow><mi mathvariant="normal">∂</mi><mi>A</mi></mrow></mfrac></mrow><annotation encoding="application/x-tex">\frac{\partial{J}}{\partial{A}} = \frac{\partial{J}}{\partial{B}}*\frac{\partial{B}}{\partial{A}}</annotation></semantics></math></span></span></p><p>Also note we sum partial derivatives coming from each of the immediate outputs:</p><p>So if <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>B</mi><mo>=</mo><mi>f</mi><mo stretchy="false">(</mo><mi>A</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">B = f(A)</annotation></semantics></math></span></span>
and <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>C</mi><mo>=</mo><mi>g</mi><mo stretchy="false">(</mo><mi>A</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">C = g(A)</annotation></semantics></math></span></span>, i.e. <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>B</mi></mrow><annotation encoding="application/x-tex">B</annotation></semantics></math></span></span> and <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>C</mi></mrow><annotation encoding="application/x-tex">C</annotation></semantics></math></span></span> are immediate outputs of <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>A</mi></mrow><annotation encoding="application/x-tex">A</annotation></semantics></math></span></span> in the computation graph, then we sum the partial derivatives:</p><p><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mrow><mi mathvariant="normal">∂</mi><mi>J</mi></mrow><mrow><mi mathvariant="normal">∂</mi><mi>A</mi></mrow></mfrac><mo>=</mo><mfrac><mrow><mi mathvariant="normal">∂</mi><mi>J</mi></mrow><mrow><mi mathvariant="normal">∂</mi><mi>B</mi></mrow></mfrac><mo>∗</mo><mfrac><mrow><mi mathvariant="normal">∂</mi><mi>B</mi></mrow><mrow><mi mathvariant="normal">∂</mi><mi>A</mi></mrow></mfrac><mo>+</mo><mfrac><mrow><mi mathvariant="normal">∂</mi><mi>J</mi></mrow><mrow><mi mathvariant="normal">∂</mi><mi>C</mi></mrow></mfrac><mo>∗</mo><mfrac><mrow><mi mathvariant="normal">∂</mi><mi>C</mi></mrow><mrow><mi mathvariant="normal">∂</mi><mi>A</mi></mrow></mfrac></mrow><annotation encoding="application/x-tex">\frac{\partial{J}}{\partial{A}} = \frac{\partial{J}}{\partial{B}}*\frac{\partial{B}}{\partial{A}} + \frac{\partial{J}}{\partial{C}}*\frac{\partial{C}}{\partial{A}}</annotation></semantics></math></span></span></p><p>In a <strong>deep learning framework</strong> like <em>TensorFlow</em> or <em>Keras</em>, there will be identities like this for each of the differentiable operations.</p><h2 id="backpropagation-through-time-in-an-lstm-cell"><a href="#backpropagation-through-time-in-an-lstm-cell" aria-label="backpropagation through time in an lstm cell permalink"></a>Backpropagation Through Time in an LSTM Cell</h2><p>When trying to compute <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mrow><mi mathvariant="normal">∂</mi><mi>J</mi></mrow><mrow><mi mathvariant="normal">∂</mi><mi>A</mi></mrow></mfrac></mrow><annotation encoding="application/x-tex">\frac{\partial{J}}{\partial{A}}</annotation></semantics></math></span></span>, we’ll use the general equation:</p><p><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mrow><mi mathvariant="normal">∂</mi><mi>J</mi></mrow><mrow><mi mathvariant="normal">∂</mi><mi>A</mi></mrow></mfrac><mo>=</mo><mfrac><mrow><mi mathvariant="normal">∂</mi><mi>J</mi></mrow><mrow><mi mathvariant="normal">∂</mi><mi>B</mi></mrow></mfrac><mo>∗</mo><mfrac><mrow><mi mathvariant="normal">∂</mi><mi>B</mi></mrow><mrow><mi mathvariant="normal">∂</mi><mi>A</mi></mrow></mfrac></mrow><annotation encoding="application/x-tex">\frac{\partial{J}}{\partial{A}} = \frac{\partial{J}}{\partial{B}}*\frac{\partial{B}}{\partial{A}}</annotation></semantics></math></span></span></p><p>For brevity, we’ll substitute the value of <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mrow><mi mathvariant="normal">∂</mi><mi>B</mi></mrow><mrow><mi mathvariant="normal">∂</mi><mi>A</mi></mrow></mfrac></mrow><annotation encoding="application/x-tex">\frac{\partial{B}}{\partial{A}}</annotation></semantics></math></span></span> using the operations’ identities above.</p><p>The equations are thus as follows:</p><p>From equation 7:</p><p><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mrow><mi mathvariant="normal">∂</mi><mi>J</mi></mrow><mrow><mi mathvariant="normal">∂</mi><msup><mover accent="true"><mi>a</mi><mo>~</mo></mover><mrow><mo>&lt;</mo><mi>t</mi><mo>&gt;</mo></mrow></msup></mrow></mfrac><mo>=</mo><mfrac><mrow><mi mathvariant="normal">∂</mi><mi>J</mi></mrow><mrow><mi mathvariant="normal">∂</mi><msup><mi>a</mi><mrow><mo>&lt;</mo><mi>t</mi><mo>&gt;</mo></mrow></msup></mrow></mfrac><mo>∗</mo><msub><mi mathvariant="normal">Γ</mi><mi>o</mi></msub></mrow><annotation encoding="application/x-tex">\frac{\partial{J}}{\partial{\tilde{a}^{&lt; t&gt;}}} = \frac{\partial{J}}{\partial{a^{&lt; t&gt;}}}* \Gamma_o</annotation></semantics></math></span></span></p><p><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mrow><mi mathvariant="normal">∂</mi><mi>J</mi></mrow><mrow><mi mathvariant="normal">∂</mi><msub><mi mathvariant="normal">Γ</mi><mi>o</mi></msub></mrow></mfrac><mo>=</mo><mfrac><mrow><mi mathvariant="normal">∂</mi><mi>J</mi></mrow><mrow><mi mathvariant="normal">∂</mi><msup><mi>a</mi><mrow><mo>&lt;</mo><mi>t</mi><mo>&gt;</mo></mrow></msup></mrow></mfrac><mo>∗</mo><msup><mover accent="true"><mi>a</mi><mo>~</mo></mover><mrow><mo>&lt;</mo><mi>t</mi><mo>&gt;</mo></mrow></msup></mrow><annotation encoding="application/x-tex">\frac{\partial{J}}{\partial{\Gamma_o}}= \frac{\partial{J}}{\partial{a^{&lt; t&gt;}}}*\tilde{a}^{&lt; t&gt;}</annotation></semantics></math></span></span></p><p>Using equation 6, and writing equation 5 as an equation for <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>c</mi><mrow><mo>&lt;</mo><mi>t</mi><mo>+</mo><mn>1</mn><mo>&gt;</mo></mrow></msup></mrow><annotation encoding="application/x-tex">c^{&lt; t+1&gt;}</annotation></semantics></math></span></span> instead of <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>c</mi><mrow><mo>&lt;</mo><mi>t</mi><mo>&gt;</mo></mrow></msup></mrow><annotation encoding="application/x-tex">c^{&lt; t&gt;}</annotation></semantics></math></span></span> (i.e. adding 1 to the timestep):</p><p><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mrow><mi mathvariant="normal">∂</mi><mi>J</mi></mrow><mrow><mi mathvariant="normal">∂</mi><msup><mi>c</mi><mrow><mo>&lt;</mo><mi>t</mi><mo>&gt;</mo></mrow></msup></mrow></mfrac><mo>=</mo><mfrac><mrow><mi mathvariant="normal">∂</mi><mi>J</mi></mrow><mrow><mi mathvariant="normal">∂</mi><msup><mi>c</mi><mrow><mo>&lt;</mo><mi>t</mi><mo>+</mo><mn>1</mn><mo>&gt;</mo></mrow></msup></mrow></mfrac><mo>∗</mo><msub><mi mathvariant="normal">Γ</mi><mi>f</mi></msub><mo>+</mo><mfrac><mrow><mi mathvariant="normal">∂</mi><mi>J</mi></mrow><mrow><mi mathvariant="normal">∂</mi><msup><mover accent="true"><mi>a</mi><mo>~</mo></mover><mrow><mo>&lt;</mo><mi>t</mi><mo>&gt;</mo></mrow></msup></mrow></mfrac><mo>∗</mo><mo stretchy="false">(</mo><mn>1</mn><mo>−</mo><msup><mover accent="true"><mi>a</mi><mo>~</mo></mover><mrow><mo>&lt;</mo><mi>t</mi><mo>&gt;</mo><mn>2</mn></mrow></msup><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\frac{\partial{J}}{\partial{c^{&lt; t&gt;}}} = \frac{\partial{J}}{\partial{c^{&lt; t+1&gt;}}}*\Gamma_f + \frac{\partial{J}}{\partial{\tilde{a}^{&lt; t&gt;}}} *(1-\tilde{a}^{&lt; t&gt;2})</annotation></semantics></math></span></span></p><p>Also using equation 5:</p><p><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mrow><mi mathvariant="normal">∂</mi><mi>J</mi></mrow><mrow><mi mathvariant="normal">∂</mi><msup><mover accent="true"><mi>c</mi><mo>~</mo></mover><mrow><mo>&lt;</mo><mi>t</mi><mo>&gt;</mo></mrow></msup></mrow></mfrac><mo>=</mo><mfrac><mrow><mi mathvariant="normal">∂</mi><mi>J</mi></mrow><mrow><mi mathvariant="normal">∂</mi><msup><mi>c</mi><mrow><mo>&lt;</mo><mi>t</mi><mo>&gt;</mo></mrow></msup></mrow></mfrac><mo>∗</mo><msub><mi mathvariant="normal">Γ</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">\frac{\partial{J}}{\partial{\tilde{c}^{&lt; t&gt;}}} = \frac{\partial{J}}{\partial{c^{&lt; t&gt;}}}*\Gamma_i</annotation></semantics></math></span></span></p><p><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mrow><mi mathvariant="normal">∂</mi><mi>J</mi></mrow><mrow><mi mathvariant="normal">∂</mi><msub><mi mathvariant="normal">Γ</mi><mi>i</mi></msub></mrow></mfrac><mo>=</mo><mfrac><mrow><mi mathvariant="normal">∂</mi><mi>J</mi></mrow><mrow><mi mathvariant="normal">∂</mi><msup><mi>c</mi><mrow><mo>&lt;</mo><mi>t</mi><mo>&gt;</mo></mrow></msup></mrow></mfrac><mo>∗</mo><msup><mover accent="true"><mi>c</mi><mo>~</mo></mover><mrow><mo>&lt;</mo><mi>t</mi><mo>&gt;</mo></mrow></msup></mrow><annotation encoding="application/x-tex">\frac{\partial{J}}{\partial{\Gamma_i}}= \frac{\partial{J}}{\partial{c^{&lt; t&gt;}}}*\tilde{c}^{&lt; t&gt;}</annotation></semantics></math></span></span></p><p><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mrow><mi mathvariant="normal">∂</mi><mi>J</mi></mrow><mrow><mi mathvariant="normal">∂</mi><msub><mi mathvariant="normal">Γ</mi><mi>f</mi></msub></mrow></mfrac><mo>=</mo><mfrac><mrow><mi mathvariant="normal">∂</mi><mi>J</mi></mrow><mrow><mi mathvariant="normal">∂</mi><msup><mi>c</mi><mrow><mo>&lt;</mo><mi>t</mi><mo>&gt;</mo></mrow></msup></mrow></mfrac><mo>∗</mo><msup><mi>c</mi><mrow><mo>&lt;</mo><mi>t</mi><mo>−</mo><mn>1</mn><mo>&gt;</mo></mrow></msup></mrow><annotation encoding="application/x-tex">\frac{\partial{J}}{\partial{\Gamma_f}}= \frac{\partial{J}}{\partial{c^{&lt; t&gt;}}}*c^{&lt; t-1&gt;}</annotation></semantics></math></span></span></p><p>From equations 3 and 4 respectively:</p><p><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mrow><mi mathvariant="normal">∂</mi><mi>J</mi></mrow><mrow><mi mathvariant="normal">∂</mi><msub><mi>Z</mi><mi>g</mi></msub></mrow></mfrac><mo>=</mo><mfrac><mrow><mi mathvariant="normal">∂</mi><mi>J</mi></mrow><mrow><mi mathvariant="normal">∂</mi><mi mathvariant="normal">Γ</mi></mrow></mfrac><mo>∗</mo><mi mathvariant="normal">Γ</mi><mo>∗</mo><mo stretchy="false">(</mo><mn>1</mn><mo>−</mo><mi mathvariant="normal">Γ</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\frac{\partial{J}}{\partial{Z_g}} = \frac{\partial{J}}{\partial{\Gamma}}*\Gamma*(1-\Gamma)</annotation></semantics></math></span></span></p><p><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mrow><mi mathvariant="normal">∂</mi><mi>J</mi></mrow><mrow><mi mathvariant="normal">∂</mi><msub><mi>Z</mi><mi>c</mi></msub></mrow></mfrac><mo>=</mo><mfrac><mrow><mi mathvariant="normal">∂</mi><mi>J</mi></mrow><mrow><mi mathvariant="normal">∂</mi><msup><mover accent="true"><mi>c</mi><mo>~</mo></mover><mrow><mo>&lt;</mo><mi>t</mi><mo>&gt;</mo></mrow></msup></mrow></mfrac><mo>∗</mo><mo stretchy="false">(</mo><mn>1</mn><mo>−</mo><msup><mover accent="true"><mi>c</mi><mo>~</mo></mover><mrow><mo>&lt;</mo><mi>t</mi><msup><mo>&gt;</mo><mn>2</mn></msup></mrow></msup><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">\frac{\partial{J}}{\partial{Z_c}} = \frac{\partial{J}}{\partial{\tilde{c}^{&lt; t&gt;}}}*(1-\tilde{c}^{&lt; t&gt;^2})</annotation></semantics></math></span></span></p><p>Equations 1 and 2 are identical, and so are the partial derivatives, differing only in subscript.</p><p><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mrow><mi mathvariant="normal">∂</mi><mi>J</mi></mrow><mrow><mi mathvariant="normal">∂</mi><msub><mi>W</mi><mi>g</mi></msub></mrow></mfrac><mo>=</mo><mfrac><mn>1</mn><mi>m</mi></mfrac><mfrac><mrow><mi mathvariant="normal">∂</mi><mi>J</mi></mrow><mrow><mi mathvariant="normal">∂</mi><msub><mi>Z</mi><mi>g</mi></msub></mrow></mfrac><mi mathvariant="normal">.</mi><mo stretchy="false">[</mo><msup><mi>a</mi><mrow><mo>&lt;</mo><mi>t</mi><mo>−</mo><mn>1</mn><mo>&gt;</mo></mrow></msup><mo separator="true">,</mo><msup><mi>x</mi><mrow><mo>&lt;</mo><mi>t</mi><mo>&gt;</mo></mrow></msup><msup><mo stretchy="false">]</mo><mi>T</mi></msup></mrow><annotation encoding="application/x-tex">\frac{\partial{J}}{\partial{W_g}} = \frac{1}{m} \frac{\partial{J}}{\partial{Z_g}}.[a^{&lt; t-1&gt;}, x^{&lt; t&gt;}]^T</annotation></semantics></math></span></span></p><p><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mrow><mi mathvariant="normal">∂</mi><mi>J</mi></mrow><mrow><mi mathvariant="normal">∂</mi><msub><mi>b</mi><mi>g</mi></msub></mrow></mfrac><mo>=</mo><mfrac><mn>1</mn><mi>m</mi></mfrac><msubsup><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>m</mi></msubsup><mfrac><mrow><mi mathvariant="normal">∂</mi><mi>J</mi></mrow><mrow><mi mathvariant="normal">∂</mi><msubsup><mi>Z</mi><mi>g</mi><mrow><mo stretchy="false">(</mo><mi>i</mi><mo stretchy="false">)</mo></mrow></msubsup></mrow></mfrac></mrow><annotation encoding="application/x-tex">\frac{\partial{J}}{\partial{b_g}} = \frac{1}{m}\sum_{i=1}^{m} \frac{\partial{J}}{\partial{Z_g^{(i)}}}</annotation></semantics></math></span></span></p><p><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mrow><mi mathvariant="normal">∂</mi><mi>J</mi></mrow><mrow><mi mathvariant="normal">∂</mi><msub><mi>W</mi><mi>c</mi></msub></mrow></mfrac><mo>=</mo><mfrac><mn>1</mn><mi>m</mi></mfrac><mfrac><mrow><mi mathvariant="normal">∂</mi><mi>J</mi></mrow><mrow><mi mathvariant="normal">∂</mi><msub><mi>Z</mi><mi>c</mi></msub></mrow></mfrac><mi mathvariant="normal">.</mi><mo stretchy="false">[</mo><msup><mi>a</mi><mrow><mo>&lt;</mo><mi>t</mi><mo>−</mo><mn>1</mn><mo>&gt;</mo></mrow></msup><mo separator="true">,</mo><msup><mi>x</mi><mrow><mo>&lt;</mo><mi>t</mi><mo>&gt;</mo></mrow></msup><msup><mo stretchy="false">]</mo><mi>T</mi></msup></mrow><annotation encoding="application/x-tex">\frac{\partial{J}}{\partial{W_c}} = \frac{1}{m} \frac{\partial{J}}{\partial{Z_c}}.[a^{&lt; t-1&gt;}, x^{&lt; t&gt;}]^T</annotation></semantics></math></span></span></p><p><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mrow><mi mathvariant="normal">∂</mi><mi>J</mi></mrow><mrow><mi mathvariant="normal">∂</mi><msub><mi>b</mi><mi>c</mi></msub></mrow></mfrac><mo>=</mo><mfrac><mn>1</mn><mi>m</mi></mfrac><msubsup><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mi>m</mi></msubsup><mfrac><mrow><mi mathvariant="normal">∂</mi><mi>J</mi></mrow><mrow><mi mathvariant="normal">∂</mi><msubsup><mi>Z</mi><mi>c</mi><mrow><mo stretchy="false">(</mo><mi>i</mi><mo stretchy="false">)</mo></mrow></msubsup></mrow></mfrac></mrow><annotation encoding="application/x-tex">\frac{\partial{J}}{\partial{b_c}} = \frac{1}{m}\sum_{i=1}^{m} \frac{\partial{J}}{\partial{Z_c^{(i)}}}</annotation></semantics></math></span></span></p><p><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mfrac><mrow><mi mathvariant="normal">∂</mi><mi>J</mi></mrow><mrow><mi mathvariant="normal">∂</mi><mrow><mo stretchy="false">[</mo><msup><mi>a</mi><mrow><mo>&lt;</mo><mi>t</mi><mo>−</mo><mn>1</mn><mo>&gt;</mo></mrow></msup><mo separator="true">,</mo><msup><mi>x</mi><mrow><mo>&lt;</mo><mi>t</mi><mo>&gt;</mo></mrow></msup><mo stretchy="false">]</mo></mrow></mrow></mfrac><mo>=</mo><msubsup><mi>W</mi><mi>g</mi><mi>T</mi></msubsup><mi mathvariant="normal">.</mi><mfrac><mrow><mi mathvariant="normal">∂</mi><mi>J</mi></mrow><mrow><mi mathvariant="normal">∂</mi><msub><mi>Z</mi><mi>g</mi></msub></mrow></mfrac><mo>+</mo><msubsup><mi>W</mi><mi>c</mi><mi>T</mi></msubsup><mi mathvariant="normal">.</mi><mfrac><mrow><mi mathvariant="normal">∂</mi><mi>J</mi></mrow><mrow><mi mathvariant="normal">∂</mi><msub><mi>Z</mi><mi>c</mi></msub></mrow></mfrac></mrow><annotation encoding="application/x-tex">\frac{\partial{J}}{\partial{[a^{&lt; t-1&gt;}, x^{&lt; t&gt;}]}} =  W_g^T.\frac{\partial{J}}{\partial{Z_g}}+     W_c^T.\frac{\partial{J}}{\partial{Z_c}}</annotation></semantics></math></span></span></p><p>So by breaking the computation graph into many steps, we can break down the calculation into smaller simpler steps that just use the operations’ derivative identities mentioned above.</p><h3 id="code"><a href="#code" aria-label="code permalink"></a>Code:</h3><p>The motivating example we’ve looked at uses an <a href="https://github.com/mukul-rathi/deep-learning-tutorials/tree/master/RecurrentNeuralNet">LSTM network</a> for sentiment analysis on a dataset of IMDB reviews</p><div><div><pre><p><span>def</span><span> </span><span>backward_step</span><span>(</span><span>dA_next</span><span>,</span><span> dC_next</span><span>,</span><span>cache</span><span>,</span><span>parameters</span><span>)</span><span>:</span><span></span></p><p><span>    </span><span>(</span><span>a_next</span><span>,</span><span> c_next</span><span>,</span><span> input_concat</span><span>,</span><span> c_prev</span><span>,</span><span> c_candidate</span><span>,</span><span>IFO_gates</span><span>)</span><span> </span><span>=</span><span> cache</span></p><p><span>    n_a</span><span>,</span><span> m </span><span>=</span><span> a_next</span><span>.</span><span>shape</span></p><p><span>    dC_next </span><span>+=</span><span> dA_next</span><span>*</span><span> </span><span>(</span><span>IFO_gates</span><span>[</span><span>2</span><span>*</span><span>n_a</span><span>:</span><span>]</span><span>*</span><span>(</span><span>1</span><span>-</span><span>np</span><span>.</span><span>tanh</span><span>(</span><span>c_next</span><span>)</span><span>**</span><span>2</span><span>)</span><span>)</span><span></span></p><p><span>    dC_prev </span><span>=</span><span> dC_next </span><span>*</span><span> IFO_gates</span><span>[</span><span>n_a</span><span>:</span><span>2</span><span>*</span><span>n_a</span><span>]</span><span></span></p><p><span>    dC_candidate </span><span>=</span><span>  dC_next </span><span>*</span><span> IFO_gates</span><span>[</span><span>:</span><span>n_a</span><span>]</span><span></span></p><p><span>    dIFO_gates </span><span>=</span><span> np</span><span>.</span><span>zeros_like</span><span>(</span><span>IFO_gates</span><span>)</span><span></span></p><p><span>    dIFO_gates</span><span>[</span><span>:</span><span>n_a</span><span>]</span><span> </span><span>=</span><span> dC_next </span><span>*</span><span> c_candidate</span></p><p><span>    dIFO_gates</span><span>[</span><span>n_a</span><span>:</span><span>2</span><span>*</span><span>n_a</span><span>]</span><span>=</span><span> dC_next </span><span>*</span><span> c_prev</span></p><p><span>    dIFO_gates</span><span>[</span><span>2</span><span>*</span><span>n_a</span><span>:</span><span>]</span><span> </span><span>=</span><span> dA_next </span><span>*</span><span> np</span><span>.</span><span>tanh</span><span>(</span><span>c_next</span><span>)</span><span></span></p><p><span>    dZ_gate </span><span>=</span><span>  dIFO_gates</span><span>*</span><span> </span><span>(</span><span>IFO_gates</span><span>*</span><span>(</span><span>1</span><span>-</span><span>IFO_gates</span><span>)</span><span>)</span><span></span></p><p><span>    dA_prev </span><span>=</span><span>  </span><span>(</span><span>parameters</span><span>[</span><span>"Wg"</span><span>]</span><span>.</span><span>T</span><span>)</span><span>.</span><span>dot</span><span>(</span><span>dZ_gate</span><span>)</span><span>[</span><span>:</span><span>n_a</span><span>]</span><span></span></p><p><span>    dWg </span><span>=</span><span> </span><span>(</span><span>1</span><span>/</span><span>m</span><span>)</span><span>*</span><span>dZ_gate</span><span>.</span><span>dot</span><span>(</span><span>input_concat</span><span>.</span><span>T</span><span>)</span><span></span></p><p><span>    dbg </span><span>=</span><span> </span><span>(</span><span>1</span><span>/</span><span>m</span><span>)</span><span>*</span><span>np</span><span>.</span><span>sum</span><span>(</span><span>dZ_gate</span><span>,</span><span>axis</span><span>=</span><span>1</span><span>,</span><span> keepdims</span><span>=</span><span>True</span><span>)</span><span></span></p><p><span>    dZ_c </span><span>=</span><span> dC_candidate </span><span>*</span><span> </span><span>(</span><span>1</span><span>-</span><span>c_candidate</span><span>**</span><span>2</span><span>)</span><span></span></p><p><span>    dA_prev </span><span>+=</span><span>  </span><span>(</span><span>parameters</span><span>[</span><span>"Wc"</span><span>]</span><span>.</span><span>T</span><span>)</span><span>.</span><span>dot</span><span>(</span><span>dZ_c</span><span>)</span><span>[</span><span>:</span><span>n_a</span><span>]</span><span></span></p><p><span>    dWc </span><span>=</span><span> </span><span>(</span><span>1</span><span>/</span><span>m</span><span>)</span><span>*</span><span>dZ_c</span><span>.</span><span>dot</span><span>(</span><span>input_concat</span><span>.</span><span>T</span><span>)</span><span></span></p><p><span>    dbc </span><span>=</span><span> </span><span>(</span><span>1</span><span>/</span><span>m</span><span>)</span><span>*</span><span>np</span><span>.</span><span>sum</span><span>(</span><span>dZ_c</span><span>,</span><span>axis</span><span>=</span><span>1</span><span>,</span><span> keepdims</span><span>=</span><span>True</span><span>)</span><span></span></p><p><span>    </span><span>return</span><span> dA_prev</span><span>,</span><span> dC_prev</span><span>,</span><span> dWg</span><span>,</span><span> dbg</span><span>,</span><span> dWc</span><span>,</span><span> dbc</span></p></pre></div></div><div><h3>Join me on this learning journey!</h3><p>This summer I’m using my blog to teach the topics I’ve learnt this year. It’s a win-win - you get computer science tutorials and I get to share it with you!</p></div><h3 id="practical-considerations"><a href="#practical-considerations" aria-label="practical considerations permalink"></a>Practical Considerations:</h3><p>When checking the equations for the backprop, it helps to have a numerical checker - I’ve written one in the accompanying <a href="https://github.com/mukul-rathi/deep-learning-tutorials/tree/master/RecurrentNeuralNet">Jupyter notebook</a>.</p><h2 id="conclusion"><a href="#conclusion" aria-label="conclusion permalink"></a>Conclusion</h2><p>This seems like a good juncture to recap the series so far.</p><p>We started the series looking at the most commonly used termninology, followed by looking at simple machine learning algorithms in <a href="https://mukulrathi.co.uk/demystifying-deep-learning/linear-logistic-regression/">linear and logistic regression</a>, building up the intuition behind the maths behind <a href="https://mukulrathi.co.uk/demystifying-deep-learning/learning-gradient-descent/">gradient descent</a> as we built up to a <a href="https://mukulrathi.co.uk/demystifying-deep-learning/feed-forward-neural-network/">feedforward neural network</a>.</p><p>Next we looked at the learning process itself, and how we could <a href="https://mukulrathi.co.uk/demystifying-deep-learning/optimising-gradient-descent/">improve gradient descent</a> itself, as well as <a href="https://mukulrathi.co.uk/demystifying-deep-learning/debug-neural-network-learning/">debug our model</a> to see whether it was learning or not.</p><p>Finally, we moved onto more specialised neural networks - <a href="https://mukulrathi.co.uk/demystifying-deep-learning/convolutional-neural-network-from-scratch/">CNNs</a> and <a href="https://mukulrathi.co.uk/demystifying-deep-learning/lstm-recurrent-neural-network-from-scratch/">recurrent neural nets</a>, not only looking at their theory but the motivation behind them. We also looked at the maths behind them, deriving the <a href="https://mukulrathi.co.uk/demystifying-deep-learning/conv-net-backpropagation-maths-intuition-derivation/"> CNN backprop</a> equations from scratch.</p><p>Now that we’re at the point that we’re able to understand backprop in a general computation graph, we can use the abstractions of the deep learning frameworks in subsequent posts.</p></article></div>]]>
            </description>
            <link>https://mukulrathi.co.uk/demystifying-deep-learning/backpropagation-computation-graph-lstm/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25315243</guid>
            <pubDate>Sat, 05 Dec 2020 15:31:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Covid-19 in Sweden]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25314732">thread link</a>) | @ComputingMonk
<br/>
December 5, 2020 | https://limitlesscuriosity.com/the-story-of-covid-19-in-sweden/ | <a href="https://web.archive.org/web/*/https://limitlesscuriosity.com/the-story-of-covid-19-in-sweden/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                    <h2 id="i">I</h2><p>When Sweden announced their laissez-faire approach to COVID-19, experts, and politicians around the world, were in disbelief. Without a lockdown and mandatory masks, this could only end in a disaster. The famous model used to justify the lockdown in the <a href="https://www.businessinsider.com/neil-ferguson-transformed-uk-covid-response-oxford-challenge-imperial-model-2020-4?r=DE&amp;IR=T">UK and many other countries</a>, predicted 100.000 deaths by June if Sweden did not follow all the other countries and institute strict measures. It is now November, and at the time of writing, 6,972 people have died in Sweden from COVID-19. So what happened?</p><h2 id="ii">II</h2><p>Let’s take a step back and look at the famous model, which was the basis for many of the government measures back in March as well as for the 100.000 death prediction: The Imperial Model. It was developed by Neil Fergusson and his team at the Imperial College London.</p><p>The involvement of Neils Fergusson should already have raised doubts about the validity of the model because his track record, and there is no other way to say this, is terrible. If you think it cannot be that bad, you are in for a surprise.</p><p>We will do what <a href="https://www.businessinsider.com/neil-ferguson-transformed-uk-covid-response-oxford-challenge-imperial-model-2020-4?r=DE&amp;IR=T">Business Insider</a> promised back in April:</p><blockquote>Here's what we know about “Professor Lockdown” and the gold standard in science that is Imperial College.</blockquote><p>Of course, they did not mention his past predictions, and the “gold standard” turned out to be fake gold, but let's not get ahead of ourselves. His past predictions:</p><ul><li><a href="https://www.nationalreview.com/wp-content/uploads/2020/05/Ferguson-Estimating-the-human-health-risk-from-possible-BSE-infection-of-the-British-sheep-flock.pdf">In 2002</a>, Ferguson predicted that up to 150,000 people could die from exposure to BSE (mad cow disease) in the U.K. There were only 177 deaths.</li><li><a href="https://www.nationalreview.com/corner/professor-lockdown-modeler-resigns-in-disgrace/">In 2009</a>, Ferguson predicted that the bird flu could kill 150 million people. 282 people died worldwide.</li><li><a href="https://www.spectator.co.uk/article/six-questions-that-neil-ferguson-should-be-asked">In 2009</a>, Ferguson predicted as a “reasonable worst-case scenario” that the swine flu would kill 65,000 people in Britain. It killed 457.</li></ul><p>I think that is enough about our “Professor Lockdown.” We want to focus more on the model and “the gold standard in science that is Imperial College.”</p><h2 id="iii">III</h2><p>One reason why nobody doubted the model was that it was secret—always a smart move. When on March 16, 2020, Neil and his team published their paper, they did not publish their code. Yes, you read that correctly. Their paper made several policy recommendations based on predictions of a model <em>they did not publish</em>. So there was no way of knowing if their claims were true or false. They were simply baseless claims without any evidence.</p><p>To me, this destroys any trustworthiness Neil Ferguson might have had left. One hallmark of science is independent verifiability. Without others being able to verify the claims and run the model themselves, it is not science; it is pseudo-science with a strong appeal to authority.</p><p>On April 27, over one month after the paper in question was published, they finally released their code on <a href="https://github.com/mrc-ide/covid-sim">GitHub</a>. However, it turns out that they did not release the original code used to generate the predictions in their paper. The released version was edited by software engineers of GitHub to make it acceptable:</p><figure><blockquote data-width="550"><p lang="en" dir="ltr">Before the GitHub team started working on the code it was a single 15k line C file that had been worked on for a decade, and some of the functions looked like they were machine translated from Fortran. There are some tropes about academic code that have grains of truth, but \</p>— John Carmack (@ID_AA_Carmack) <a href="https://twitter.com/ID_AA_Carmack/status/1254872369556074496?ref_src=twsrc%5Etfw">April 27, 2020</a></blockquote>

</figure><p>As you can read in this Tweet, the original code was “a single 15k line C file that had been worked on for a decade.” Everyone with a little bit of knowledge about software engineering should be shocked. A single 15000 line C file is beyond bad practice.</p><p>But even GitHubs’s engineers could not salvage the code. The released version is still riddled with bugs and random equations that literally nobody can explain. Moreover, even if the released code were exactly the code used in the paper, no one could have replicated the results because the input parameters used in the paper were not published. As the <a href="https://github.com/mrc-ide/covid-sim/tree/master/data">GitHub page</a> reads:</p><blockquote>IMPORTANT: The parameter files are provided as a sample only and do not necessarily reflect runs used in published papers.</blockquote><p>At this point, we are long past science, with a small s, and far into the world of Science, with a capital S. The latter is the world where the term “Believe the Science” makes sense. While science (small s) is the process of doubting everything, disregarding authority, and searching for the truth, Science (capital S) is where the truth is determined by fiat, and your job is to believe, not question it. But I digress.</p><h2 id="iv">IV</h2><p>After several issues around the non-deterministic behavior of the model were brought up on GitHub, the team responded with an <a href="https://github.com/mrc-ide/covid-sim/issues/116#issuecomment-617304550">interesting answer</a>:</p><blockquote>We are aware of some small non-determinisms when using multiple threads to set up the network of people and places. (Look for the omp critical pragmas in the code). This has historically been considered acceptable because of the general stochastic nature of the model.</blockquote><p>Non-deterministic means that given the same input, you do not always get the same output (non-deterministic behavior is not necessarily bad; only in cases like this where it is not explainable). Their answer to this problem was that it does not matter because the model is “stochastic,” which is just a fancy word for saying that they run the model multiple times and average over all the outcomes.</p><p>Every time a new issue around non-determinism came up or a different bug was discovered, the team’s answer was the <a href="https://github.com/mrc-ide/covid-sim/issues/30">same</a>:</p><blockquote>This isn’t a problem running the model in full as it is stochastic anyway.</blockquote><p>But is this really true? You do not have to worry about bugs because “it is stochastic anyway”? The answer is, obviously, no.</p><p>To understand this stochastic magic better, let’s take a look at an example: baking a cake. If we weigh flour, we might weigh it several times and then average over all these measurements—only if we are nerds and want to follow the recipe particularly closely, of course. But why does this give us a more accurate result? The answer is that if, for example, we make an error when reading from the scale (imagine an old analog scale), then an error in one direction (more) is as likely as an error in the other direction (less). In other words, if the flour weighs 100 grams, you are just as likely to mistake it for 102 g the first time, and 98 g the next. Only if we make mistakes sometimes in one direction and sometimes in another, averaging out works. Otherwise, <em>it does not</em>. If your scale is broken, and always shows five grams more, averaging does not help you.</p><p>The same is true for bugs. If, and only if, we could be sure that the bugs distort the output sometimes upwards and sometimes downwards (preferably with equal probability and magnitude), we could solve the problem by running the model “stochastically.” However, this is not the case because, by definition, we do not know how bugs affect the code; otherwise we would understand them and probably be able to fix them. The point is that nobody, including the “scientists” who produced this model, can know how those bugs affect the code.</p><p>Do not get me wrong, stochastic models are not necessarily like this. Most of the time, if the model is not too complicated (we will get to this point later), small changes in the input create small changes in the output, and the randomness in the output stems from intentionally included pseudo-randomness. However, this model is not non-deterministic in the predictable (explainable) mathematical sense. It is non-deterministic in the angry-toddler-in-a-toy-store sense: nobody knows what is going to happen, and there is no way to replicate it. <a href="https://medium.com/@allenfarrington/simple-truths-and-complex-nonsense-2e1c28ae6f29">Put differently</a>:</p><blockquote>It has nondeterministic outputs that do not follow from seeded pseudorandomness but are rather an inexplicable part of the process. I am not using “inexplicable” rhetorically here: nobody can explain this. This is one of the great issues in Complexity Science. Clearly there is a stark mathematical difference between deterministic and non-deterministic. But there is also a fuzzy, and arguably more important, difference between non-deterministic and really, really, really NON-DETERMINISTIC.</blockquote><p>Unfortunately, the Imperial Model falls into the latter category.</p><h2 id="v">V</h2><p>Alright, a summary of what we have learned so far: the code was not released with the paper; the released code is not the code used in the paper; the original code was a single 15 thousand line C file; the model is non-deterministic bordering on chaotic; the parameters released are not the parameters used in the paper; the code is riddled with bugs. An impressive list for a “scientific” model that informed government decisions on life and death.</p><h2 id="vi">VI</h2><p>But what about the model without the code? Sure, the code that implements the model is awful, but maybe they have figured out a great way to model pandemics and just need better software engineering to make it work. Sadly, this is not the case.</p><p>Do you remember the parameters that were <em>not</em> provided so nobody could replicate the results of the paper? It turns out that the model has 450 input parameters. Let me say it again: the model depends on <em>450 (!!!)</em> parameters. Nobody can understand a model with this many parameters. And it gets even worse because as it turns out, complex systems like pandemics have many interdependencies, which complicates everything. As described by Allen <a href="https://medium.com/@allenfarrington/simple-truths-and-complex-nonsense-2e1c28ae6f29">here</a>:</p><blockquote>Now I should be clear that, maybe, the virus is that complicated. But it doesn’t matter. Because we can’t possibly understand this. And actually I lowballed it by a factor of 450 (Oh, God …). Because if this system is linear, which it surely is not, what this really means is that a single set of parameters can be represented as a 450-dimensional column vector acting on a 450x450 matrix with 450² = 202k independent numbers. Because, remember, the parameters can be anything. Katya suspects they are totally made up. So it’s not just the dimensions we need to account for. The surface of the earth has 2 dimensions but more than 2 locations. Assuming every entry in this matrix has only two possible states, which it surely does not, this model maps a system with at least …</blockquote></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://limitlesscuriosity.com/the-story-of-covid-19-in-sweden/">https://limitlesscuriosity.com/the-story-of-covid-19-in-sweden/</a></em></p>]]>
            </description>
            <link>https://limitlesscuriosity.com/the-story-of-covid-19-in-sweden/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25314732</guid>
            <pubDate>Sat, 05 Dec 2020 14:21:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: I Wrote a Book on Data Analysis with Rust Notebooks]]>
            </title>
            <description>
<![CDATA[
Score 99 | Comments 27 (<a href="https://news.ycombinator.com/item?id=25314170">thread link</a>) | @DataCrayon
<br/>
December 5, 2020 | https://datacrayon.com/shop/product/data-analysis-with-rust-notebooks/ | <a href="https://web.archive.org/web/*/https://datacrayon.com/shop/product/data-analysis-with-rust-notebooks/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main-content">
    <div id="et-boc">
			
		<!-- #end wrapper --><div>
			<div>
		<div>
				
				
				
				
					<div>
				<div>
				
				
				<div>
				
				
				
				
				<p>A practical book on Data Analysis with Rust Notebooks that teaches you the concepts and how they’re implemented in practice.</p>
			</div>
			</div> <!-- .et_pb_column --><div>
				
				
				<div>
				
				
				
				
				<div>
					<div data-columns="4">
	<figure>
		<p><a href="https://datacrayon.com/shop/wp-content/uploads/2020/02/cover_darn.jpg"><img width="480" height="679" src="https://datacrayon.com/shop/wp-content/uploads/2020/02/cover_darn.jpg" alt="" loading="lazy" title="cover_darn" data-caption="" data-src="https://datacrayon.com/shop/wp-content/uploads/2020/02/cover_darn.jpg" data-large_image="https://datacrayon.com/shop/wp-content/uploads/2020/02/cover_darn.jpg" data-large_image_width="480" data-large_image_height="679" srcset="https://datacrayon.com/shop/wp-content/uploads/2020/02/cover_darn.jpg 480w, https://datacrayon.com/shop/wp-content/uploads/2020/02/cover_darn-212x300.jpg 212w, https://datacrayon.com/shop/wp-content/uploads/2020/02/cover_darn-300x424.jpg 300w" sizes="(max-width: 480px) 100vw, 480px"></a></p>	</figure>
</div>

				</div>
			</div>
			</div> <!-- .et_pb_column -->
				
				
			</div> <!-- .et_pb_row -->
				
				
			</div> <!-- .et_pb_section --><div>
				
				
				
				<div>
					 <!-- .et_pb_column --><div>
				
				
				 <!-- .et_pb_row_inner --><div>
				<div>
				
				
				<div>
				
				
				<ul>
					<li><a href="#">Description</a></li>
				</ul>
				<div>
					<div>
					<div>
						<p>A practical book on Data Analysis with Rust Notebooks that teaches you the concepts and how they're implemented in practice.</p>
<ul>
<li><strong>Discounted</strong>&nbsp;<strong>Price</strong> that will grow as the book does,</li>
<li>All code examples in <strong>Rust</strong>,</li>
<li><strong>Rust (Jupyter) Notebooks</strong> for each Section,</li>
<li>Supplementary <strong>Video Tutorials</strong>,</li>
<li>Format: <strong>PDF download</strong>,</li>
<li><strong>Unlimited</strong> downloads and access to updates.</li>
</ul>
<p>Get it now to enhance your work in Rust, NDArray, Data Science, Data Analysis, and Machine Learning.</p>

					</div><!-- .et_pb_tab_content" -->
				</div>
				</div> <!-- .et_pb_all_tabs -->
			</div> <!-- .et_pb_tabs -->
			</div> <!-- .et_pb_column -->
				
				
			</div> <!-- .et_pb_row_inner -->
			</div> <!-- .et_pb_column -->
				</div> <!-- .et_pb_row -->
				
			</div> <!-- .et_pb_section --> <!-- .et_pb_section --><div>
				
				
				
				
					<div>
				<div>
				
				
				 <!-- .et_pb_text --><p><span><img src="https://store.shahinrostami.com/wp-content/uploads/2020/07/shahin_square.jpg" alt="" title="shahin_square" srcset="https://datacrayon.com/shop/wp-content/uploads/2020/07/shahin_square.jpg 288w, https://datacrayon.com/shop/wp-content/uploads/2020/07/shahin_square-150x150.jpg 150w, https://datacrayon.com/shop/wp-content/uploads/2020/07/shahin_square-100x100.jpg 100w" sizes="(max-width: 288px) 100vw, 288px"></span>
			</p>
			</div> <!-- .et_pb_column --><div>
				
				
				<div>
				
				
				<div><p>Dr. Shahin Rostami is a <a href="http://staffprofiles.bournemouth.ac.uk/display/srostami" target="_blank" rel="noopener noreferrer">Senior Academic (Associate Professor)</a> and <a href="https://www.linkedin.com/in/shahinrostami/" target="_blank" rel="noopener noreferrer">Consultant</a> in Data Science and Artificial Intelligence, with applications in the areas of Healthcare and Defence.</p>
<p>As a <a href="https://www.heacademy.ac.uk/system/files/downloads/UK%20Professional%20Standards%20Framework%20%28PSF%29_1.pdf">Senior Fellow</a> of the Higher Education Academy and <a href="https://shahinrostami.com/">Programme Leader</a> for many postgraduate programmes, he aims to contribute openly available learning resources through this website and his <a href="https://www.youtube.com/shahinrostami" target="_blank" rel="noopener noreferrer">YouTube channel</a>.</p></div>
			</div> <!-- .et_pb_text --><div>
				
				
				<p>Dr. Rostami writes and maintains the works published and offered through this website. You can expect ongoing updates and support through the communication channels listed below.</p>
			</div> <!-- .et_pb_text --> <!-- .et_pb_text --><ul>
				
				
				<li><a href="https://twitter.com/shahinrostami" title="Follow on Twitter" target="_blank"></a></li><li><a href="https://www.youtube.com/ShahinRostami" title="Follow on Youtube" target="_blank"></a></li><li><a href="https://www.linkedin.com/in/shahinrostami/" title="Follow on LinkedIn" target="_blank"></a></li><li><a href="https://www.instagram.com/stamilabs/" title="Follow on Instagram" target="_blank"></a></li>
			</ul> <!-- .et_pb_counters -->
			</div> <!-- .et_pb_column -->
				
				
			</div> <!-- .et_pb_row -->
				
				
			</div> <!-- .et_pb_section --><div>
				
				
				
				
					<div>
				<div>
				
				
				<p><span><img src="https://store.shahinrostami.com/wp-content/uploads/2020/07/author-icon-03-2.png" alt="" title=""></span>
			</p><div>
				
				
				<div><p>The aim is to generate everything in this book through code! This means you’ll see the code for all the figures and tables, including things like flowcharts.</p>
<p>Every section is intended to be independent and <span jsslot=""><span data-dobid="hdw">reproducible</span></span>, so you’ll find some repetition as you progress from one section to another.</p></div>
			</div> <!-- .et_pb_text -->
			</div> <!-- .et_pb_column -->
				
				
			</div> <!-- .et_pb_row -->
				
				
			</div> <!-- .et_pb_section --><div>
				
				
				
				
					<div>
				<div>
				
				
				<div>
				
				
				<div><h2>10% discount on books.</h2>
<p>Join the newsletter to receive book and software updates, as well as discounts and occasional freebies! Your email will only used for this newsletter.</p></div>
			</div> <!-- .et_pb_text --> <!-- .et_pb_code --><ul>
				
				
				<li><a href="https://twitter.com/shahinrostami" title="Follow on Twitter" target="_blank"></a></li><li><a href="https://www.youtube.com/ShahinRostami" title="Follow on Youtube" target="_blank"></a></li><li><a href="https://www.linkedin.com/in/shahinrostami/" title="Follow on LinkedIn" target="_blank"></a></li><li><a href="https://www.instagram.com/stamilabs/" title="Follow on Instagram" target="_blank"></a></li>
			</ul> <!-- .et_pb_counters -->
			</div> <!-- .et_pb_column --> <!-- .et_pb_column -->
				
				
			</div> <!-- .et_pb_row -->
				
				
			</div> <!-- .et_pb_section -->		</div><!-- .et_builder_inner_content -->
	</div><!-- .et-l -->
	
			
		</div><!-- #et-boc -->
		    </div></div>]]>
            </description>
            <link>https://datacrayon.com/shop/product/data-analysis-with-rust-notebooks/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25314170</guid>
            <pubDate>Sat, 05 Dec 2020 12:52:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Std::visit is everything wrong with modern C++ (2017)]]>
            </title>
            <description>
<![CDATA[
Score 117 | Comments 223 (<a href="https://news.ycombinator.com/item?id=25314126">thread link</a>) | @xucheng
<br/>
December 5, 2020 | https://bitbashing.io/std-visit.html | <a href="https://web.archive.org/web/*/https://bitbashing.io/std-visit.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
    <!--
Sorry once again for the infrequent posts.
I've been busy.
Originally, because I was supposed to get married this summer.
Then because my fiancée cheated on me while I was watching my grandfather die
and moved in with the other guy the following week.
So that's been fun, but I'm trying to get back into some more productive habits.
Hopefully that includes blogging regularly.
-->

<h2 id="sum-types-and-you">Sum Types and You</h2>

<p>Let’s talk about a simple, yet powerful concept in programming: <em>sum types</em>.<sup id="fnref:1"><a href="#fn:1">1</a></sup></p>

<p>A sum type, also called a <em>discriminated union</em>,
can hold one (and only one) of several types of things.
For example, consider some settings in an
<a href="https://en.wikipedia.org/wiki/INI_file">INI</a>-like configuration file.
Let’s say that each setting must be a string, an integer, or a Boolean value.
If we wanted to roll our own solution in C++, we might write something resembling:</p>

<div><pre><code><span>struct</span> <span>Setting</span> <span>{</span>
    <span>union</span> <span>{</span>
        <span>string</span> <span>str</span><span>;</span>
        <span>int</span> <span>num</span><span>;</span>
        <span>bool</span> <span>b</span><span>;</span>
    <span>};</span>
    <span>enum</span> <span>Type</span> <span>{</span> <span>Str</span><span>,</span> <span>Int</span><span>,</span> <span>Bool</span> <span>};</span>
    <span>Type</span> <span>tag</span><span>;</span>
<span>};</span>

<span>// Map settings to their names.
</span><span>using</span> <span>Settings</span> <span>=</span> <span>unordered_map</span><span>&lt;</span><span>string</span><span>,</span> <span>Setting</span><span>&gt;</span><span>;</span>
</code></pre>
</div>

<p>Here be dragons, though, since we must always remember to:</p>

<ul>
  <li>
    <p>Update <code>tag</code> whenever assigning a new value.</p>
  </li>
  <li>
    <p>Only retrieve the correct type from the union (according to <code>tag</code>).</p>
  </li>
  <li>
    <p>Call constructors and destructors at appropriate times for all non-trivial types.
(<code>string</code> is the only one here, but you could imagine similar
scenarios with others.)</p>
  </li>
</ul>

<p>If a step is ever forgotten, the object falls into an
inconsistent state and there shall be wailing and gnashing of teeth.
You could encapsulate all this trickery and interact with the type
through a series of methods—e.g., <code>getType()</code>, <code>asBool()</code>,
<code>asString()</code>, and so on—but this is quite verbose.
It also just shifts the problem onto whoever implements these methods; they
still need to carefully maintain the invariants with no help from the language.</p>

<p>It would be much nicer if a general-purpose sum type was provided by the standard
library.
In C++17, we finally get one!
It’s called <a href="http://en.cppreference.com/w/cpp/utility/variant"><code>std::variant</code></a>.
Let’s take a look.</p>

<h2 id="using-stdvariant">Using <code>std::variant</code></h2>

<p><code>variant</code> is a class template that takes, as template parameters, the types
it could hold.
For the example above,
we could define a setting as a <code><span>variant</span><span>&lt;</span><span>string</span><span>,</span> <span>int</span><span>,</span> <span>bool</span><span>&gt;</span></code>.
Assigning a value to a <code>variant</code> works just like you might expect:</p>
<div><pre><code><span>variant</span><span>&lt;</span><span>string</span><span>,</span> <span>int</span><span>,</span> <span>bool</span><span>&gt;</span> <span>mySetting</span> <span>=</span> <span>string</span><span>(</span><span>"Hello!"</span><span>);</span> <span>// Or,
</span><span>mySetting</span> <span>=</span> <span>42</span><span>;</span> <span>// Or,
</span><span>mySetting</span> <span>=</span> <span>false</span><span>;</span>
</code></pre>
</div>

<p>Once we put a value into a <code>variant</code>, we’ll eventually want to look at what that
value is, and just as importantly, what the type of the value is.
This is where the fun begins.
Some languages offer dedicated <em>pattern matching</em> syntax for the task,
such as:</p>
<div><pre><code><span>match</span> <span>(</span><span>theSetting</span><span>)</span> <span>{</span>
    <span>Setting</span><span>::</span><span>Str</span><span>(</span><span>s</span><span>)</span> <span>=&gt;</span>
        <span>println!</span><span>(</span><span>"A string: {}"</span><span>,</span> <span>s</span><span>),</span>
    <span>Setting</span><span>::</span><span>Int</span><span>(</span><span>n</span><span>)</span> <span>=&gt;</span>
        <span>println!</span><span>(</span><span>"An integer: {}"</span><span>,</span> <span>n</span><span>),</span>
    <span>Setting</span><span>::</span><span>Bool</span><span>(</span><span>b</span><span>)</span> <span>=&gt;</span>
        <span>println!</span><span>(</span><span>"A boolean: {}"</span><span>,</span> <span>b</span><span>),</span>
<span>};</span>
</code></pre>
</div>
<p>but this didn’t make the cut for C++17.<sup id="fnref:2"><a href="#fn:2">2</a></sup>
Instead we’re given a companion function called <code>std::visit</code>.
It takes the <code>variant</code> you want to examine, along with
some <em>visitor</em> that is callable for each type in the variant.</p>

<p>How do we define such a visitor?
One way is to create an object that overloads the call operator
for relevant types:</p>
<div><pre><code><span>struct</span> <span>SettingVisitor</span> <span>{</span>
    <span>void</span> <span>operator</span><span>()(</span><span>const</span> <span>string</span><span>&amp;</span> <span>s</span><span>)</span> <span>const</span> <span>{</span>
        <span>printf</span><span>(</span><span>"A string: %s</span><span>\n</span><span>"</span><span>,</span> <span>s</span><span>.</span><span>c_str</span><span>());</span>
    <span>}</span>

    <span>void</span> <span>operator</span><span>()(</span><span>const</span> <span>int</span> <span>n</span><span>)</span> <span>const</span> <span>{</span>
        <span>printf</span><span>(</span><span>"An integer: %d</span><span>\n</span><span>"</span><span>,</span> <span>n</span><span>);</span>
    <span>}</span>

    <span>void</span> <span>operator</span><span>()(</span><span>const</span> <span>bool</span> <span>b</span><span>)</span> <span>const</span> <span>{</span>
        <span>printf</span><span>(</span><span>"A boolean: %d</span><span>\n</span><span>"</span><span>,</span> <span>b</span><span>);</span>
    <span>}</span>
<span>};</span>
</code></pre>
</div>

<p>This seems terribly verbose, and it gets even worse
if we want our visitor to capture or modify some other state.
Hmm—<a href="https://stackoverflow.com/a/7627218">lambdas</a> are perfect
for capturing state.
What if we could build a visitor from those?</p>
<div><pre><code><span>make_visitor</span><span>(</span>
    <span>[</span><span>&amp;</span><span>](</span><span>const</span> <span>string</span><span>&amp;</span> <span>s</span><span>)</span> <span>{</span>
        <span>printf</span><span>(</span><span>"string: %s</span><span>\n</span><span>"</span><span>,</span> <span>s</span><span>.</span><span>c_str</span><span>());</span>
        <span>// ...
</span>    <span>},</span>
    <span>[</span><span>&amp;</span><span>](</span><span>const</span> <span>int</span> <span>d</span><span>)</span> <span>{</span>
        <span>printf</span><span>(</span><span>"integer: %d</span><span>\n</span><span>"</span><span>,</span> <span>d</span><span>);</span>
        <span>// ...
</span>    <span>},</span>
    <span>[</span><span>&amp;</span><span>](</span><span>const</span> <span>bool</span> <span>b</span><span>)</span> <span>{</span>
        <span>printf</span><span>(</span><span>"bool: %d</span><span>\n</span><span>"</span><span>,</span> <span>b</span><span>);</span>
        <span>// ...
</span>    <span>}</span>
<span>)</span>
</code></pre>
</div>
<p>That’s a bit better, but the standard library doesn’t provide any sort of
<code>make_visitor</code> to combine the lambdas into a callable object for us.
We’ll need to define it ourselves.</p>

<div><pre><code><span>template</span> <span>&lt;</span><span>class</span><span>...</span> <span>Fs</span><span>&gt;</span>
<span>struct</span> <span>overload</span><span>;</span>

<span>template</span> <span>&lt;</span><span>class</span> <span>F0</span><span>,</span> <span>class</span><span>...</span> <span>Frest</span><span>&gt;</span>
<span>struct</span> <span>overload</span><span>&lt;</span><span>F0</span><span>,</span> <span>Frest</span><span>...</span><span>&gt;</span> <span>:</span> <span>F0</span><span>,</span> <span>overload</span><span>&lt;</span><span>Frest</span><span>...</span><span>&gt;</span>
<span>{</span>
    <span>overload</span><span>(</span><span>F0</span> <span>f0</span><span>,</span> <span>Frest</span><span>...</span> <span>rest</span><span>)</span> <span>:</span> <span>F0</span><span>(</span><span>f0</span><span>),</span> <span>overload</span><span>&lt;</span><span>Frest</span><span>...</span><span>&gt;</span><span>(</span><span>rest</span><span>...)</span> <span>{}</span>

    <span>using</span> <span>F0</span><span>::</span><span>operator</span><span>();</span>
    <span>using</span> <span>overload</span><span>&lt;</span><span>Frest</span><span>...</span><span>&gt;::</span><span>operator</span><span>();</span>
<span>};</span>

<span>template</span> <span>&lt;</span><span>class</span> <span>F0</span><span>&gt;</span>
<span>struct</span> <span>overload</span><span>&lt;</span><span>F0</span><span>&gt;</span> <span>:</span> <span>F0</span>
<span>{</span>
    <span>overload</span><span>(</span><span>F0</span> <span>f0</span><span>)</span> <span>:</span> <span>F0</span><span>(</span><span>f0</span><span>)</span> <span>{}</span>

    <span>using</span> <span>F0</span><span>::</span><span>operator</span><span>();</span>
<span>};</span>

<span>template</span> <span>&lt;</span><span>class</span><span>...</span> <span>Fs</span><span>&gt;</span>
<span>auto</span> <span>make_visitor</span><span>(</span><span>Fs</span><span>...</span> <span>fs</span><span>)</span>
<span>{</span>
    <span>return</span> <span>overload</span><span>&lt;</span><span>Fs</span><span>...</span><span>&gt;</span><span>(</span><span>fs</span><span>...);</span>
<span>}</span>
</code></pre>
</div>

<p>Here we use C++11’s <a href="http://en.cppreference.com/w/cpp/language/parameter_pack">variadic templates</a>.
They must be defined recursively, so we create some base case <code>F0</code>,
then use that to define a cascading set of constructors for <code>overload</code>,
each of which peels off a lambda argument and adds it to the type
as a call operator.</p>

<p>If this seems troublesome, fear not! C++17 will offer a new syntax
that reduces all of the above to:</p>
<div><pre><code><span>template</span><span>&lt;</span><span>class</span><span>...</span> <span>Ts</span><span>&gt;</span> <span>struct</span> <span>overloaded</span> <span>:</span> <span>Ts</span><span>...</span> <span>{</span> <span>using</span> <span>Ts</span><span>::</span><span>operator</span><span>()...;</span> <span>};</span>
<span>template</span><span>&lt;</span><span>class</span><span>...</span> <span>Ts</span><span>&gt;</span> <span>overloaded</span><span>(</span><span>Ts</span><span>...)</span> <span>-&gt;</span> <span>overloaded</span><span>&lt;</span><span>Ts</span><span>...</span><span>&gt;</span><span>;</span>
</code></pre>
</div>
<p>Easy, right? But if don’t like any of these options, you could
use C++17’s compile-time conditionals instead:</p>
<div><pre><code><span>[](</span><span>auto</span><span>&amp;</span> <span>arg</span><span>)</span> <span>{</span>
    <span>using</span> <span>T</span> <span>=</span> <span>std</span><span>::</span><span>decay_t</span><span>&lt;</span><span>decltype</span><span>(</span><span>arg</span><span>)</span><span>&gt;</span><span>;</span>

    <span>if</span> <span>constexpr</span> <span>(</span><span>std</span><span>::</span><span>is_same_v</span><span>&lt;</span><span>T</span><span>,</span> <span>string</span><span>&gt;</span><span>)</span> <span>{</span>
        <span>printf</span><span>(</span><span>"string: %s</span><span>\n</span><span>"</span><span>,</span> <span>arg</span><span>.</span><span>c_str</span><span>());</span>
        <span>// ...
</span>    <span>}</span>
    <span>else</span> <span>if</span> <span>constexpr</span> <span>(</span><span>std</span><span>::</span><span>is_same_v</span><span>&lt;</span><span>T</span><span>,</span> <span>int</span><span>&gt;</span><span>)</span> <span>{</span>
        <span>printf</span><span>(</span><span>"integer: %d</span><span>\n</span><span>"</span><span>,</span> <span>arg</span><span>);</span>
        <span>// ...
</span>    <span>}</span>
    <span>else</span> <span>if</span> <span>constexpr</span> <span>(</span><span>std</span><span>::</span><span>is_same_v</span><span>&lt;</span><span>T</span><span>,</span> <span>bool</span><span>&gt;</span><span>)</span> <span>{</span>
        <span>printf</span><span>(</span><span>"bool: %d</span><span>\n</span><span>"</span><span>,</span> <span>arg</span><span>);</span>
        <span>// ...
</span>    <span>}</span>
<span>}</span>
</code></pre>
</div>

<p>Much better, no?</p>

<h2 id="no">No.</h2>

<p>The rigmarole needed for <code>std::visit</code> is entirely insane.
We started with a simple goal: look at the contents of a sum type.
To accomplish this meager mission, we had to:</p>

<ol>
  <li>
    <p>Define a function object, which requires a lot of
boilerplate, <em>or</em></p>
  </li>
  <li>Define our behavior with lambdas, which required:
    <ul>
      <li>An understanding of variadic templates, in all their recursively-defined fun, <em>or</em></li>
      <li>A familiarity with variadic <code>using</code> declarations, fresh on the scene from C++17.</li>
    </ul>

    <p><em>or</em></p>
  </li>
  <li>Use compile-time conditionals, which require you to know
about—and grok—the new <code><span>constexpr</span> <span>if</span></code> syntax, along with
<code>type_traits</code> fun like
<code>std::decay</code>.</li>
</ol>

<p>None of these concepts are too enigmatic if you’re an experienced C++ developer,
but several are certainly “advanced” features of the language.
Things have really gone sideways if we need to know so much
to do something so simple.</p>

<h2 id="how-did-we-get-here">How did we get here?</h2>

<p>My goal isn’t to disparage the folks on the ISO C++ committee
who picked this approach.
I’ve had beers with some of them,
and they’re smart, kind, hardworking people.
I’m sure that I’m missing important context since I’ve never sat in on a
standards meeting or read all of the relevant
<a href="http://www.open-std.org/jtc1/sc22/wg21/docs/papers/">committee papers</a>.
But from an outsider’s perspective, the disparity in complexity between the
problem being solved (“What’s in here?”)
and the solutions is just nuts.
How do you teach this without overwhelming a beginner with all this other…
stuff?
Is it expected to be common knowledge for your everyday programmer?
(And if the goal of adding <code>variant</code> to the standard library <em>isn’t</em> to
make it a tool for the masses, shouldn’t it be?)
The very least C++17 could do—if the committee didn’t have the time or resources
to get pattern matching into the language—is provide something akin to <code>make_visitor</code>.
But that too is left as an exercise for the user.</p>

<p>If I had to guess how we ended up this way,
I’d assume it comes down to confirmation bias.
Maybe when a bunch of really smart people who know how
<a href="http://en.cppreference.com/w/cpp/language/sfinae">SFINAE</a> works offhand
and don’t flinch when they see the likes of</p>

<div><pre><code><span>template</span> <span>&lt;</span><span>typename</span> <span>F</span><span>&gt;</span>
<span>typename</span> <span>std</span><span>::</span><span>enable_if</span><span>&lt;!</span><span>std</span><span>::</span><span>is_reference</span><span>&lt;</span><span>F</span><span>&gt;::</span><span>value</span><span>,</span> <span>int</span><span>&gt;::</span><span>type</span>
<span>foo</span><span>(</span><span>F</span> <span>f</span><span>)</span>
<span>{</span>
    <span>// ...
</span><span>}</span>
</code></pre>
</div>

<p>get together, the result is something like <code>std::visit</code>.
Nobody proclaims that the emperor has no clothes, or that it’s completely
bonkers to expect the average user to build an overloaded callable
object with recursive templates just to see if the thing they’re looking at
holds an <code><span>int</span></code> or a <code><span>string</span></code>.</p>

<p>I’m also not here to claim that C++ is too complicated for its own good,
but it’s certainly more complicated than it has to be.
Scott Meyers, the guy who wrote <em>Effective&nbsp;C++</em> and <em>Effective Modern&nbsp;C++</em>,
has made similar noises in <a href="http://www.ustream.tv/recorded/47947981">recent</a>
<a href="https://youtu.be/RT46MpK39rQ?t=29m51s">talks</a>.
To paraphrase Meyers, I’m sure each member of the committee cares very much
about avoiding needless complexity and making the language easier to use.
But if you look at the results of their work, it’s hard to tell.
The accidental complexity just keeps stacking up.</p>

<h2 id="where-are-we-headed">Where are we headed?</h2>

<p>There’s a reason C++ is so widely used, especially in systems programming.<sup id="fnref:3"><a href="#fn:3">3</a></sup>
It can be incredibly expressive, yet gives you nearly full control of your hardware.
The tooling around it is some of the most mature of any programming language
out there, bar C.
It supports a ridiculous number of platforms.</p>

<p>But even if you set aside all the historical baggage, it has some serious shortcomings.
Spend any amount of time messing with D and you’ll quickly realize that
metaprogramming needn’t require self-flagellation and insane syntax.
Play with Rust and <!-- Hi, PCJ --> you’ll feel like <code>unique_ptr</code>
and <code>shared_ptr</code>—which themselves have been a breath of fresh air—are
a bad joke.
The fact that we still handle dependencies in 2017
by literally copy-pasting files into each other with <code><span>#include</span></code>
macros is <em>obscene</em>.</p>

<p>You get the impression, based on what ends up in the ISO standards and what
you hear in conference talks,
that those driving C++ are trying to eliminate some of these shortcomings by
glomming nice bits from other languages onto it.
That’s a great idea on its face,
but these features often seem to arrive half-baked.
While C++ isn’t going away any time soon,
it feels like the language is constantly playing a clumsy game of catchup.</p>

<hr>

<p>In spite of all of this,
I’ll be busy encouraging my coworkers to use <code>variant</code> if anybody needs me.
Sum types are such a useful concept that they’re worth the pain,
and <a href="https://www.youtube.com/watch?v=wvtFGa6XJDU">to quote Jon Kalb</a>,
“If you can’t program in a language with ugly warts, maybe C++ isn’t the language
you should be programming in.”</p>

<hr>



  </article></div>]]>
            </description>
            <link>https://bitbashing.io/std-visit.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25314126</guid>
            <pubDate>Sat, 05 Dec 2020 12:44:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Scaling Down Deep Learning]]>
            </title>
            <description>
<![CDATA[
Score 122 | Comments 35 (<a href="https://news.ycombinator.com/item?id=25314066">thread link</a>) | @lelf
<br/>
December 5, 2020 | https://greydanus.github.io/2020/12/01/scaling-down/ | <a href="https://web.archive.org/web/*/https://greydanus.github.io/2020/12/01/scaling-down/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <div>
      <div>

  

  <article>
  

<div>
    <div>
    <video id="demoDisplay">
    	<source src="https://greydanus.github.io/assets/scaling-down/construction.mp4" type="video/mp4">
    </video>
    <p>Constructing the MNIST-1D dataset. As with the original MNIST dataset, the task is to learn to classify the digits 0-9. Unlike the MNIST dataset, which consists of 28x28 images, each of these examples is a one-dimensional sequence of points. To generate an example, we begin with 10 digit templates and then randomly pad, translate, add noise, and transform them as shown above.</p>
  	</div>
</div>





<p>By any scientific standard, the Human Genome Project <a href="https://deepblue.lib.umich.edu/handle/2027.42/62798">was enormous</a>: it involved billions of dollars of funding, dozens of institutions, and over a decade of accelerated research. But that was only the tip of the iceberg. Long before the project began, scientists were hard at work assembling the intricate science of human genetics. And most of the time, they were not studying humans. The foundational discoveries in genetics centered on far simpler organisms such as peas, molds, fruit flies, and mice. To this day, biologists use these simpler organisms as genetic “minimal working examples” in order to save time, energy, and money. A well-designed experiment with Drosophilia, such as <a href="https://pubmed.ncbi.nlm.nih.gov/10746727/">Feany and Bender (2000)</a>, can teach us an astonishing amount about humans.</p>

<p>The deep learning analogue of Drosophilia is the MNIST dataset. A large number of deep learning innovations including <a href="https://jmlr.org/papers/v15/srivastava14a.html">dropout</a>, <a href="https://arxiv.org/abs/1412.6980">Adam</a>, <a href="http://yann.lecun.com/exdb/publis/pdf/lecun-89e.pdf">convolutional networks</a>, <a href="https://arxiv.org/abs/1406.2661">generative adversarial networks</a>, and <a href="https://arxiv.org/abs/1312.6114">variational autoencoders</a> began life as MNIST experiments. Once these innovations proved themselves on small-scale experiments, scientists found ways to scale them to larger and more impactful applications.</p>

<p>They key advantage of Drosophilia and MNIST is that they dramatically accelerate the iteration cycle of exploratory research. In the case of Drosophilia, the fly’s life cycle is just a few days long and its nutritional needs are negligible. This makes it much easier to work with than mammals, especially humans. In the case of MNIST, training a strong classifier takes a few dozen lines of code, less than a minute of walltime, and negligible amounts of electricity. This is a stark contrast to state-of-the-art vision, text, and game-playing models which can take months and <a href="https://arxiv.org/abs/2004.08900">hundreds of thousands of dollars</a> of electricity to train.</p>

<p>Yet in spite of its historical significance, MNIST has three notable shortcomings. First, it does a poor job of differentiating between linear, nonlinear, and translation-invariant models. For example, logistic, MLP, and CNN benchmarks obtain 94, 99+, and 99+% accuracy on it. This makes it hard to measure the contribution of a CNN’s spatial priors or to judge the relative effectiveness of different regularization schemes. Second, it is somewhat large for a toy dataset. Each input example is a 784-dimensional vector and thus it takes a non-trivial amount of computation to perform hyperparameter searches or debug a metalearning loop. Third, MNIST is hard to hack. The ideal toy dataset should be procedurally generated so that researchers can smoothly vary parameters such as background noise, translation, and resolution.</p>

<p>In order to address these shortcomings, we propose the MNIST-1D dataset. It is a minimalist, low-memory, and low-compute alternative to MNIST, designed for exploratory deep learning research where rapid iteration is a priority. Training examples are 20 times smaller but they are still better at measuring the difference between 1) linear and nonlinear classifiers and 2) models with and without spatial inductive biases (eg. translation invariance). The dataset is procedurally generated but still permits analogies to real-world digit classification.</p>

<div>
  <div>
    <p><img src="https://greydanus.github.io/assets/scaling-down/overview_a.png"></p><p>Constructing the MNIST-1D dataset. Like MNIST, the classifier's objective is to determine which digit is present in the input. Unlike MNIST, each example is a one-dimensional sequence of points. To generate an example, we begin with a digit template and then randomly pad, translate, and transform it.</p>
  </div>
  <div>
    <p><img src="https://greydanus.github.io/assets/scaling-down/overview_b.png"></p><p>Visualizing the performance of common models on the MNIST-1D dataset. This dataset separates them cleanly according to whether they use nonlinear features (logistic regression vs. MLP) or whether they have spatial inductive biases (MLP vs. CNN). Humans do best of all. Best viewed with zoom.</p>
  </div>
</div>

<div>
  <p><img src="https://greydanus.github.io/assets/scaling-down/tsne.png">
  </p>
  <p>Visualizing the MNIST and MNIST-1D datasets with tSNE. The well-defined clusters in the MNIST plot indicate that the majority of the examples are separable via a kNN classifier in pixel space. The MNIST-1D plot, meanwhile, reveals a lack of well-defined clusters which suggests that learning a nonlinear representation of the data is much more important to achieve successful classification. Thanks to <a href="https://twitter.com/hippopedoid">Dmitry Kobak</a> for making this plot.</p>
</div>

<h2 id="example-use-cases">Example use cases</h2>

<p>In this section we will explore several examples of how MNIST-1D can be used to study core “science of deep learning” phenomena.</p>

<p><strong>Finding lottery tickets.</strong> It is not unusual for deep learning models to have ten or even a hundred times more parameters than necessary. This overparameterization helps training but increases computational overhead. One solution is to progressively prune weights from a model during training so that the final network is just a fraction of its original size. Although this approach works, conventional wisdom holds that sparse networks do not train well from scratch. Recent work by <a href="https://arxiv.org/abs/1803.03635">Frankle &amp; Carbin (2019)</a> challenges this conventional wisdom. The authors report finding sparse subnetworks inside of larger networks that train to equivalent or even higher accuracies. These “lottery ticket” subnetworks can be found through a simple iterative procedure: train a network, prune the smallest weights, and then rewind the remaining weights to their original initializations and retrain.</p>

<p>Since the original paper was published, a multitude of works have sought to explain this phenomenon and then harness it on larger datasets and models. However, very few works have attempted to isolate a “minimal working example” of this effect so as to investigate it more carefully. The figure below shows that the MNIST-1D dataset not only makes this possible, but also enables us to elucidate, via carefully-controlled experiments, some of the reasons for a lottery ticket’s success. Unlike many follow-up experiments on the lottery ticket, this one took just two days of researcher time to produce. The curious reader can also <a href="https://bit.ly/3nCEIaL">reproduce these results</a> in their browser in a few minutes.</p>

<div>
  <p><img src="https://greydanus.github.io/assets/scaling-down/lottery_a1.png">
  </p>
  <p><img src="https://greydanus.github.io/assets/scaling-down/lottery_a2.png">
  </p>
  <p>Finding and analyzing lottery tickets. In <b>a-b)</b>, we isolate a "minimum viable example" of the effect. Recent work by <a href="https://arxiv.org/abs/1906.02773">Morcos et al (2019)</a> shows that lottery tickets can transfer between datasets. We wanted to determine whether spatial inductive biases played a role. So we performed a series of experiments: in <b>c)</b> we plot the asymptotic performance of a 92% sparse ticket. In <b>d)</b> we reverse all the 1D signals in the dataset, effectively preserving spatial structure but changing the location of individual datapoints. This is analogous to flipping an image upside down. Under this ablation, the lottery ticket continues to win.</p>
</div>

<div>
  <p><img src="https://greydanus.github.io/assets/scaling-down/lottery_b1.png">
  </p>
  <p><img src="https://greydanus.github.io/assets/scaling-down/lottery_b2.png">
  </p>
    <p>Next, in <b>e)</b> we permute the indices of the 1D signal, effectively removing spatial structure from the dataset. This ablation hurts lottery ticket performance significantly more, suggesting that part of the lottery ticket's performance can be attributed to a spatial inductive bias. Finally, in <b>f)</b> we keep the lottery ticket sparsity structure but initialize its weights with a different random seed. Contrary to results reported in <a href="https://arxiv.org/abs/1803.03635">Frankle &amp; Carbin (2019)</a>, we see that our lottery ticket continues to outperform a dense baseline, aligning well with our hypothesis that the lottery ticket mask has a spatial inductive bias. In <b>g)</b>, we verify our hypothesis by measuring how often unmasked weights are adjacent to one another in the first layer of our model. The lottery ticket has many more adjacent weights than chance would predict, implying a local connectivity structure which helps gives rise to spatial biases.</p>
</div>

<p>You can also visualize the actual masks selected via random and lottery pruning:
<br></p>





<p><strong>Observing deep double descent.</strong> Another intriguing property of neural networks is the “double descent” phenomenon. This phrase refers to a training regime where more data, model parameters, or gradient steps can actually <em>reduce</em> a model’s test accuracy<sup id="fnref:fn1" role="doc-noteref"><a href="#fn:fn1">1</a></sup> <sup id="fnref:fn2" role="doc-noteref"><a href="#fn:fn2">2</a></sup> <sup id="fnref:fn3" role="doc-noteref"><a href="#fn:fn3">3</a></sup> <sup id="fnref:fn4" role="doc-noteref"><a href="#fn:fn4">4</a></sup>. The intuition is that during supervised learning there is an interpolation threshold where the learning procedure, consisting of a model and an optimization algorithm, is just barely able to fit the entire training set. At this threshold there is effectively just one model that can fit the data and this model is very sensitive to label noise and model mis-specification.</p>

<p>Several properties of this effect, such as what factors affect its width and location, are not well understood in the context of deep models. We see the MNIST-1D dataset as a good tool for exploring these properties. In fact, we were able to reproduce the double descent pattern after a few hours of researcher effort. The figure below shows our results for a fully-connected network and a convolutional model. We also observed a nuance that we had not seen mentioned in previous works: when using a mean square error loss, the interpolation threshold lies at \(n * K\) model parameters where \(n\) is the number of training examples and \(K\) is the number of model outputs. But when using a negative log likelihood loss, the interpolation threshold lies at \(n\) model parameters – it does not depend on the number of model outputs. This is an interesting empirical observation that may explain some of the advantage in using a log likelihood loss over a MSE loss on this type of task. You can reproduce these results <a href="https://bit.ly/2UBWWNu">here</a>.</p>

<div>
  <p><img src="https://greydanus.github.io/assets/scaling-down/ddd_a.png">
  </p>
  <p><img src="https://greydanus.github.io/assets/scaling-down/ddd_b.png">
  </p>
  <p>Observing deep double descent. MNIST-1D is a good environment for determining how to locate the interpolation threshold of deep models. This threshold is fairly easy to predict in fully-connected models but less easy to …</p></div></article></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://greydanus.github.io/2020/12/01/scaling-down/">https://greydanus.github.io/2020/12/01/scaling-down/</a></em></p>]]>
            </description>
            <link>https://greydanus.github.io/2020/12/01/scaling-down/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25314066</guid>
            <pubDate>Sat, 05 Dec 2020 12:30:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[V4 UUID generation Postgres benchmarks]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25313857">thread link</a>) | @shusson
<br/>
December 5, 2020 | https://shusson.info/post/benchmark-v4-uuid-generation-in-postgres | <a href="https://web.archive.org/web/*/https://shusson.info/post/benchmark-v4-uuid-generation-in-postgres">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
  

<p><strong>05/12/2020</strong></p>

<p>TLDR: use <code>gen_random_uuid</code> to generate v4 uuids.</p>

<p>There are two main functions to generate v4 uuids in postgres, <code>uuid_generate_v4</code> and <code>gen_random_uuid</code>. In postgres 13, <code>gen_random_uuid</code> is a built in function. Otherwise you will need to install the <code>pgcrypto</code> extension. <code>uuid_generate_v4</code> requires the <code>uuid-ossp</code> extension. Depending how postgres is configured, postgres may actually use different libraries for the <code>uuid-ossp</code> extension (ossp-uuid, libc, libuuid) see <a href="https://www.postgresql.org/docs/13/uuid-ossp.html">postgres doc</a> for more info.</p>

<h2 id="tests">Tests</h2>

<pre><code>CREATE EXTENSION IF NOT EXISTS "uuid-ossp";
CREATE EXTENSION IF NOT EXISTS "pgcrypto";
</code></pre>

<pre><code>EXPLAIN ANALYZE SELECT uuid_generate_v4() FROM generate_series(1, 10000);
EXPLAIN ANALYZE SELECT gen_random_uuid() FROM generate_series(1, 10000);
</code></pre>

<h2 id="notes">Notes</h2>

<ul>
  <li>All benchmarks used postgres 12.x.</li>
  <li>On windows, postgres was installed using https://www.enterprisedb.com.</li>
  <li>On linux, postgres was installed using respective package managers.</li>
  <li>All tests were done on google cloud VMs.
    <ul>
      <li>e2-medium: (2 vCPUs, 4 GB, HDD)</li>
      <li>e2-standard-4: (4 vCPUs, 16 GB, HDD)</li>
    </ul>
  </li>
</ul>

<h2 id="results">Results</h2>

<table>
  <thead>
    <tr>
      <th>hardware</th>
      <th>platform</th>
      <th>uuid_generate_v4</th>
      <th>gen_random_uuid</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>e2-medium</td>
      <td>ubuntu-16.04</td>
      <td>95ms</td>
      <td>10ms</td>
    </tr>
    <tr>
      <td>e2-standard-4</td>
      <td>centos-8</td>
      <td>80ms</td>
      <td>30ms</td>
    </tr>
    <tr>
      <td>e2-medium</td>
      <td>windows-server-2012</td>
      <td>1800ms</td>
      <td>5ms</td>
    </tr>
    <tr>
      <td>e2-medium</td>
      <td>windows-server-2016</td>
      <td>3600ms</td>
      <td>5ms</td>
    </tr>
    <tr>
      <td>e2-standard-4</td>
      <td>windows-server-2019</td>
      <td>4400ms</td>
      <td>5ms</td>
    </tr>
  </tbody>
</table>

<p>More investigation is required to determine why <code>uuid_generate_v4()</code> is so slow on windows server. It’s unclear what underlying lib the enterprisedb postgres is using for <code>uuid-ossp</code>. Regardless of why it’s slow on windows server, the best option for now is to use <code>gen_random_uuid</code> which is significantly faster on all platforms tested and comes built in on postgres 13.</p>

<p><strong>update</strong></p>

<p>To be sure the windows issue was not limited to the edb postgres 12.4 version, I did one quick benchmark on the latest edb postgres 13 and found similar execution times for uuid_generate_v4.</p>

      

  <span><time datetime="2020-12-05T00:00:00+01:00"></time></span>


  
  <!--<span class="meta"><time datetime="2020-12-05T00:00:00+01:00">December 5, 2020</time> &middot; </span>
  -->
</section></div>]]>
            </description>
            <link>https://shusson.info/post/benchmark-v4-uuid-generation-in-postgres</link>
            <guid isPermaLink="false">hacker-news-small-sites-25313857</guid>
            <pubDate>Sat, 05 Dec 2020 11:50:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Your Smart TV is probably ignoring your PiHole]]>
            </title>
            <description>
<![CDATA[
Score 403 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25313776">thread link</a>) | @giuliomagnifico
<br/>
December 5, 2020 | https://labzilla.io/blog/force-dns-pihole | <a href="https://web.archive.org/web/*/https://labzilla.io/blog/force-dns-pihole">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody"><p><span><i></i></span> <strong>Welcome Hacker News readers!</strong><br>
<strong>•</strong> Thank you to <a href="https://homepage.cs.uiowa.edu/~mmazhar/">M. Hammad Mazhar</a> for his <a href="https://arxiv.org/pdf/2001.08288.pdf">research</a> that inspired this guide.<br>
<strong>•</strong> <a href="https://twitter.com/healeyio">@healyio</a> made some great additional suggestions in this Twitter <a href="https://twitter.com/healeyio/status/1335347122649006080">thread</a> which I’ll be incorporating into a future update.<br>
<strong>•</strong> The HN <a href="https://news.ycombinator.com/item?id=25313480">comment thread</a> is full of insightful comments from individuals who work on IoT hardware and other embedded devices, and is well worth a read.<br>
<strong>•</strong> Finally, you can subscribe to the <a href="https://labzilla.io/feed.xml">RSS feed</a> or follow on <a href="https://twitter.com/labzilla">Twitter</a> for updates.</p>
<p>If you’re using PiHole on your network to block ads and prevent your various smart devices from sending tracking information to their manufacturers, <strong>you might be surprised to find out that some of these devices are using a sneaky tactic to bypass your PiHole entirely.</strong></p>
<p>Smart devices manufacturers often “hard-code” in a public DNS server, like Google’s 8.8.8.8, and their devices ignore whatever DNS server is assigned by your router - such as your PiHole.</p>
<p><a href="https://arxiv.org/pdf/2001.08288.pdf">Nearly 70% of smart TVs and 46% of game consoles</a> were found to contain hardcoded DNS settings - allowing them to simply ignore your local network’s DNS server entirely. On average, Smart TVs generate an average of 60 megabytes of outgoing Internet traffic <em>per day</em>, all the while bypassing tools like PiHole.</p>
<h2 id="force-all-dns-queries-through-pihole">Force all DNS queries through PiHole</h2>
<p>Fortunately, with a few simple firewall rules, you can intercept these hardcoded DNS queries and redirect them to your PiHole. These instructions are for pfSense, however you should be able to adapt them for Sophos XG, Ubiquiti EdgeRouter, etc.</p>
<h3 id="create-nat-rules">Create NAT Rules</h3>
<p>Log in to your pfSense admin interface, and navigate to <em>Firewall</em> &gt; <em>NAT</em> &gt; <em>Port Forward</em>.</p>
<p>We’re going to create two Port Forward NAT rules - one to redirect any DNS queries originating from devices on the LAN to PiHole, and another to allow PiHole to commmunicate with external DNS servers. We will also create an additional outbound NAT rule that will make this process invisible to any clients on the network with hardcoded DNS.</p>
<p><strong>NAT Rule 1: Redirect DNS queries to PiHole</strong></p>
<p>Click the <em>Add</em> button to create your first new NAT Port Forward rule.</p>
<ul>
<li><strong>Interface:</strong> LAN</li>
<li><strong>Protcol:</strong> TCP/UDP</li>
<li><strong>Source:</strong> LAN net (you may need to click the blue show advanced button to see this option)</li>
<li><strong>Destination - Invert match:</strong> Checked</li>
<li><strong>Destination - Type:</strong> Single host or alias</li>
<li><strong>Destination - Address/mask:</strong> Your PiHole’s IP address</li>
<li><strong>Destination Port Range - From:</strong> DNS</li>
<li><strong>Destination Port Range - To:</strong> DNS</li>
<li><strong>Redirect Target IP:</strong> Your PiHole’s IP address</li>
<li><strong>Redirect Target Port:</strong> DNS</li>
<li><strong>Description:</strong> Intercept any outgoing DNS queries and redirect them to PiHole.</li>
</ul>
<p><strong>NAT Rule 2: Exempt PiHole from DNS query redirects</strong></p>
<p>Click the <em>Add</em> button to create your second new NAT Port Forward rule.</p>
<ul>
<li><strong>No RDR (NOT):</strong> Checked</li>
<li><strong>Interface:</strong> LAN</li>
<li><strong>Protcol:</strong> TCP/UDP</li>
<li><strong>Source - Type:</strong> Single host or alias</li>
<li><strong>Source - Address/Mask:</strong> Your PiHole’s IP address</li>
<li><strong>Destination:</strong> Any</li>
<li><strong>Destination Port Range - From:</strong> DNS</li>
<li><strong>Destination Port Range - From:</strong> DNS</li>
<li><strong>Description:</strong> Allow PiHole to reach external DNS servers</li>
</ul>
<p><strong>Note:</strong> pfSense (and most other firewalls) process rules from top to bottom. Make sure you drag the second rule exempting PiHole from DNS query redirects <em>above</em> the first rule we created - otherwise PiHole will not be able to contact external DNS servers.</p>
<p><strong>NAT Rule 3: Prevent clients from giving unexpected source errors</strong></p>
<p>Finally, we need to create an outbound NAT rule. Navigate to <em>Firewall</em> &gt; <em>NAT</em> &gt; <em>Outbound</em>.</p>
<ul>
<li><strong>Interface:</strong> LAN</li>
<li><strong>Address Family:</strong> IPv4+IPv6</li>
<li><strong>Protocol:</strong> any</li>
<li><strong>Source - Type:</strong> Network</li>
<li><strong>Source - Network for the outbound NAT mapping:</strong> Your internal LAN network</li>
<li><strong>Destination - Type:</strong> Network</li>
<li><strong>Destination - Network for the outbound NAT Mappings:</strong> Your PiHole’s IP Address</li>
<li><strong>Destination Port Range:</strong> 53</li>
<li><strong>Translation:</strong> Interface Address</li>
<li><strong>Description:</strong> Prevents hardcoded DNS clients from giving unexpected source error after DNS redirected to PiHole.</li>
</ul>
<h3 id="test-it-out">Test it out</h3>
<p>You can easily test to make sure your DNS redirection is working properly.</p>
<ol>
<li>Create a new, temporary internal DNS entry on your network (“piholetest.example.com”), and point it to 10.0.1.1. You can do this right from PiHole under <em>Local DNS Records</em>.</li>
<li>Manually set your computer’s DNS server to <em>1.1.1.1</em>.</li>
<li>Open a terminal window (or command promt on Windows), and run <code>nslookup piholetest.example.com</code></li>
<li>
<p>If you set this up correctly, <code>nslookup</code> should return 10.0.1.1. Your computer <em>thinks</em> it’s receiving DNS records from 1.1.1.1, while in reality they are coming from your PiHole.</p>
<div><div><pre><code> macbookpro:~ labzilla$ nslookup piholetest.example.com
 Server:		1.1.1.1
 Address:	1.1.1.1#53
	
 Name:	piholetest.example.com
 Address: 10.0.1.1
</code></pre></div> </div>
</li>
<li>
<p>You can further demonstate this by temporarily disabling the first NAT rule we created, and running the same <code>nslookup piholetest.example.com</code> command:</p>
<div><div><pre><code> macbookpro:~ labzilla$ nslookup piholetest.example.com
 Server:		1.1.1.1
 Address:	1.1.1.1#53
	
 ** server can't find piholetest.example.com: NXDOMAIN 
</code></pre></div> </div>
<p>As “piholetest.example.com” doesn’t exist on the public Internet, the real 1.1.1.1 server has no record to provide - resulting in your <code>nslookup</code> request returning a NXDOMAIN error.</p>
</li>
</ol>
<p><strong>Don’t forget to revert your computer’s DNS settings back to their original value, and reenable any firewall rules you temporary disabled while testing.</strong></p>
<h2 id="hacker-news">Hacker News</h2>
<p>This post hit the front page of Hacker News <span><i></i></span> on Saturday December 5th, 2020. Thank you <a href="https://boramalper.org/">@boramalper</a> for submitting it, and I hope you found the information useful!</p>
<ul>
<li>If you’re curious about what the Hacker News bump looks like - this blog normally sees about 100 hits per day. Between December 5th-6th, this post had over 70,000 views.</li>
<li>The <a href="https://news.ycombinator.com/item?id=25313480">original comment thread</a> is full of insightful comments from individuals who work on IoT hardware and other embedded devices, and is well worth a read.</li>
<li>A follow up article incorporating some of the suggestion that <a href="https://twitter.com/healeyio">@healyio</a> made in this Twitter <a href="https://twitter.com/healeyio/status/1335347122649006080">thread</a> is coming soon.</li>
</ul>
</div></div>]]>
            </description>
            <link>https://labzilla.io/blog/force-dns-pihole</link>
            <guid isPermaLink="false">hacker-news-small-sites-25313776</guid>
            <pubDate>Sat, 05 Dec 2020 11:38:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[72% of smart TVs and 46% of game consoles hardcode DNS settings]]>
            </title>
            <description>
<![CDATA[
Score 516 | Comments 632 (<a href="https://news.ycombinator.com/item?id=25313480">thread link</a>) | @boramalper
<br/>
December 5, 2020 | https://labzilla.io/blog/force-dns-pihole | <a href="https://web.archive.org/web/*/https://labzilla.io/blog/force-dns-pihole">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody"><p><span><i></i></span> <strong>Welcome Hacker News readers!</strong><br>
<strong>•</strong> Thank you to <a href="https://homepage.cs.uiowa.edu/~mmazhar/">M. Hammad Mazhar</a> for his <a href="https://arxiv.org/pdf/2001.08288.pdf">research</a> that inspired this guide.<br>
<strong>•</strong> <a href="https://twitter.com/healeyio">@healyio</a> made some great additional suggestions in this Twitter <a href="https://twitter.com/healeyio/status/1335347122649006080">thread</a> which I’ll be incorporating into a future update.<br>
<strong>•</strong> The HN <a href="https://news.ycombinator.com/item?id=25313480">comment thread</a> is full of insightful comments from individuals who work on IoT hardware and other embedded devices, and is well worth a read.<br>
<strong>•</strong> Finally, you can subscribe to the <a href="https://labzilla.io/feed.xml">RSS feed</a> or follow on <a href="https://twitter.com/labzilla">Twitter</a> for updates.</p>
<p>If you’re using PiHole on your network to block ads and prevent your various smart devices from sending tracking information to their manufacturers, <strong>you might be surprised to find out that some of these devices are using a sneaky tactic to bypass your PiHole entirely.</strong></p>
<p>Smart devices manufacturers often “hard-code” in a public DNS server, like Google’s 8.8.8.8, and their devices ignore whatever DNS server is assigned by your router - such as your PiHole.</p>
<p><a href="https://arxiv.org/pdf/2001.08288.pdf">Nearly 70% of smart TVs and 46% of game consoles</a> were found to contain hardcoded DNS settings - allowing them to simply ignore your local network’s DNS server entirely. On average, Smart TVs generate an average of 60 megabytes of outgoing Internet traffic <em>per day</em>, all the while bypassing tools like PiHole.</p>
<h2 id="force-all-dns-queries-through-pihole">Force all DNS queries through PiHole</h2>
<p>Fortunately, with a few simple firewall rules, you can intercept these hardcoded DNS queries and redirect them to your PiHole. These instructions are for pfSense, however you should be able to adapt them for Sophos XG, Ubiquiti EdgeRouter, etc.</p>
<h3 id="create-nat-rules">Create NAT Rules</h3>
<p>Log in to your pfSense admin interface, and navigate to <em>Firewall</em> &gt; <em>NAT</em> &gt; <em>Port Forward</em>.</p>
<p>We’re going to create two Port Forward NAT rules - one to redirect any DNS queries originating from devices on the LAN to PiHole, and another to allow PiHole to commmunicate with external DNS servers. We will also create an additional outbound NAT rule that will make this process invisible to any clients on the network with hardcoded DNS.</p>
<p><strong>NAT Rule 1: Redirect DNS queries to PiHole</strong></p>
<p>Click the <em>Add</em> button to create your first new NAT Port Forward rule.</p>
<ul>
<li><strong>Interface:</strong> LAN</li>
<li><strong>Protcol:</strong> TCP/UDP</li>
<li><strong>Source:</strong> LAN net (you may need to click the blue show advanced button to see this option)</li>
<li><strong>Destination - Invert match:</strong> Checked</li>
<li><strong>Destination - Type:</strong> Single host or alias</li>
<li><strong>Destination - Address/mask:</strong> Your PiHole’s IP address</li>
<li><strong>Destination Port Range - From:</strong> DNS</li>
<li><strong>Destination Port Range - To:</strong> DNS</li>
<li><strong>Redirect Target IP:</strong> Your PiHole’s IP address</li>
<li><strong>Redirect Target Port:</strong> DNS</li>
<li><strong>Description:</strong> Intercept any outgoing DNS queries and redirect them to PiHole.</li>
</ul>
<p><strong>NAT Rule 2: Exempt PiHole from DNS query redirects</strong></p>
<p>Click the <em>Add</em> button to create your second new NAT Port Forward rule.</p>
<ul>
<li><strong>No RDR (NOT):</strong> Checked</li>
<li><strong>Interface:</strong> LAN</li>
<li><strong>Protcol:</strong> TCP/UDP</li>
<li><strong>Source - Type:</strong> Single host or alias</li>
<li><strong>Source - Address/Mask:</strong> Your PiHole’s IP address</li>
<li><strong>Destination:</strong> Any</li>
<li><strong>Destination Port Range - From:</strong> DNS</li>
<li><strong>Destination Port Range - From:</strong> DNS</li>
<li><strong>Description:</strong> Allow PiHole to reach external DNS servers</li>
</ul>
<p><strong>Note:</strong> pfSense (and most other firewalls) process rules from top to bottom. Make sure you drag the second rule exempting PiHole from DNS query redirects <em>above</em> the first rule we created - otherwise PiHole will not be able to contact external DNS servers.</p>
<p><strong>NAT Rule 3: Prevent clients from giving unexpected source errors</strong></p>
<p>Finally, we need to create an outbound NAT rule. Navigate to <em>Firewall</em> &gt; <em>NAT</em> &gt; <em>Outbound</em>.</p>
<ul>
<li><strong>Interface:</strong> LAN</li>
<li><strong>Address Family:</strong> IPv4+IPv6</li>
<li><strong>Protocol:</strong> any</li>
<li><strong>Source - Type:</strong> Network</li>
<li><strong>Source - Network for the outbound NAT mapping:</strong> Your internal LAN network</li>
<li><strong>Destination - Type:</strong> Network</li>
<li><strong>Destination - Network for the outbound NAT Mappings:</strong> Your PiHole’s IP Address</li>
<li><strong>Destination Port Range:</strong> 53</li>
<li><strong>Translation:</strong> Interface Address</li>
<li><strong>Description:</strong> Prevents hardcoded DNS clients from giving unexpected source error after DNS redirected to PiHole.</li>
</ul>
<h3 id="test-it-out">Test it out</h3>
<p>You can easily test to make sure your DNS redirection is working properly.</p>
<ol>
<li>Create a new, temporary internal DNS entry on your network (“piholetest.example.com”), and point it to 10.0.1.1. You can do this right from PiHole under <em>Local DNS Records</em>.</li>
<li>Manually set your computer’s DNS server to <em>1.1.1.1</em>.</li>
<li>Open a terminal window (or command promt on Windows), and run <code>nslookup piholetest.example.com</code></li>
<li>
<p>If you set this up correctly, <code>nslookup</code> should return 10.0.1.1. Your computer <em>thinks</em> it’s receiving DNS records from 1.1.1.1, while in reality they are coming from your PiHole.</p>
<div><div><pre><code> macbookpro:~ labzilla$ nslookup piholetest.example.com
 Server:		1.1.1.1
 Address:	1.1.1.1#53
	
 Name:	piholetest.example.com
 Address: 10.0.1.1
</code></pre></div> </div>
</li>
<li>
<p>You can further demonstate this by temporarily disabling the first NAT rule we created, and running the same <code>nslookup piholetest.example.com</code> command:</p>
<div><div><pre><code> macbookpro:~ labzilla$ nslookup piholetest.example.com
 Server:		1.1.1.1
 Address:	1.1.1.1#53
	
 ** server can't find piholetest.example.com: NXDOMAIN 
</code></pre></div> </div>
<p>As “piholetest.example.com” doesn’t exist on the public Internet, the real 1.1.1.1 server has no record to provide - resulting in your <code>nslookup</code> request returning a NXDOMAIN error.</p>
</li>
</ol>
<p><strong>Don’t forget to revert your computer’s DNS settings back to their original value, and reenable any firewall rules you temporary disabled while testing.</strong></p>
<h2 id="hacker-news">Hacker News</h2>
<p>This post hit the front page of Hacker News <span><i></i></span> on Saturday December 5th, 2020. Thank you <a href="https://boramalper.org/">@boramalper</a> for submitting it, and I hope you found the information useful!</p>
<ul>
<li>If you’re curious about what the Hacker News bump looks like - this blog normally sees about 100 hits per day. Between December 5th-6th, this post had over 70,000 views.</li>
<li>The <a href="https://news.ycombinator.com/item?id=25313480">original comment thread</a> is full of insightful comments from individuals who work on IoT hardware and other embedded devices, and is well worth a read.</li>
<li>A follow up article incorporating some of the suggestion that <a href="https://twitter.com/healeyio">@healyio</a> made in this Twitter <a href="https://twitter.com/healeyio/status/1335347122649006080">thread</a> is coming soon.</li>
</ul>
</div></div>]]>
            </description>
            <link>https://labzilla.io/blog/force-dns-pihole</link>
            <guid isPermaLink="false">hacker-news-small-sites-25313480</guid>
            <pubDate>Sat, 05 Dec 2020 10:46:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Make slides with text, markdown, YAML, JSON or JavaScript, your call]]>
            </title>
            <description>
<![CDATA[
Score 131 | Comments 27 (<a href="https://news.ycombinator.com/item?id=25313347">thread link</a>) | @abusedmedia
<br/>
December 5, 2020 | https://play.presenta.cc/v2 | <a href="https://web.archive.org/web/*/https://play.presenta.cc/v2">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://play.presenta.cc/v2</link>
            <guid isPermaLink="false">hacker-news-small-sites-25313347</guid>
            <pubDate>Sat, 05 Dec 2020 10:21:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Between two Lisps]]>
            </title>
            <description>
<![CDATA[
Score 138 | Comments 94 (<a href="https://news.ycombinator.com/item?id=25313311">thread link</a>) | @galfarragem
<br/>
December 5, 2020 | https://ane.github.io/2020/10/05/between-two-lisps.html | <a href="https://web.archive.org/web/*/https://ane.github.io/2020/10/05/between-two-lisps.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p>Out of all Lisps the ones I’ve come to appreciate the most are <a href="https://en.wikipedia.org/wiki/Scheme_(programming_language)">Scheme</a> and <a href="https://common-lisp.net/">Common
Lisp</a>. <!--break-->These two languages are fundamentally very different: Scheme
is a minimalist language built on the foundations of <a href="https://en.wikipedia.org/wiki/Lambda_calculus">lambda calculus</a>, while
Common Lisp is a multi-paradigm synthesis of many Lisps before it. Common Lisp
is a large standard with many implementations, Scheme is a collection of an
evolving but minimalistic standard with many implementations. The core of Scheme
is quite small compared to Common Lisp. The latest standard <a href="http://www.r6rs.org/final/r6rs-lib.pdf">R6RS</a> is about 65
pages, while the ANSI Common Lisp standard from 1994 is about 1100 pages. The
<a href="https://srfi.schemers.org/">Scheme Requests for Implementation</a> process aims to standardize additional
features (like <a href="https://srfi.schemers.org/srfi-64/srfi-64.html">test suites</a>) that implementations may implement.</p>

<p>Common Lisp has some wonderful features, <a href="http://www.gigamonkeys.com/book/beyond-exception-handling-conditions-and-restarts.html">conditions and restarts</a>, the <a href="https://lispcookbook.github.io/cl-cookbook/clos.html">Common
Lisp Object System (CLOS)</a>, <a href="http://www.paulgraham.com/onlisp.html">the macro system</a>, among many other things. The <a href="http://joaotavora.github.io/sly/">SLY
IDE for Emacs</a> is <em>amazing</em>, and the <a href="http://www.sbcl.org/">Steel Bank Common Lisp</a> compiler is really
great. It has <a href="https://www.quicklisp.org/index.html">Quicklisp</a> and <a href="https://common-lisp.net/project/asdf/">ASDF</a> for package and build management,
respectively. I find the developer experience of Common Lisp to be superior to
almost anything imaginable, and this is not an empty statement: having used all
sorts of IDEs and editors for over 25 years, I have seen <em>many</em>.</p>

<h3 id="tastes-differ">Tastes differ</h3>

<p>That said, Common Lisp is <em>weird</em>. What I find particularly jarring is that
functions and variables live in different namespaces: if you put a function into
a variable, you can’t just use it like a function, you have to <code>funcall</code> it.
Having programmed in lots of languages of the ML family this is just, well, odd;
but this is due to historical reasons and there are <a href="http://www.nhplace.com/kent/Papers/Technical-Issues.html">sound technical reasons for
it</a>.  There are other
oddities, some strange things like <code>(cdr '())</code> is not an error (in Scheme it
is), <code>()</code> and <code>nil</code> are equal (in Scheme <code>#f</code> and <code>()</code> are separate things), and
so on.</p>

<p>This isn’t really a fault in Common Lisp: other languages have impacted my taste
and preferences to bias me in the direction of Scheme, but that is not to say I
cannot work with Common Lisp’s idiosyncracies. Actually, I don’t mind them, I
just <em>notice</em> them.</p>

<p>I like the naming styles of Scheme more, as well. It has <code>string?</code> vs <code>string-p</code>
for predicate functions, <code>set!</code>  for state modifying functions, <code>foo-&gt;bar</code> for
conversions, these make code quite easier to read. Scheme has hygienic macros,
Guile has the traditional <code>defmacro</code> as well.</p>

<p>Many nice Scheme features are available in Common Lisp libraries. Pattern match
is available in the <a href="https://github.com/guicho271828/trivia">trivia</a> library. Named lets are easy to implement with a macro.</p>

<p>Common Lisp aficionados are quick to point out things Scheme <em>doesn’t</em> have:
keyword arguments, docstrings, rest arguments, but my Scheme implementation of
choice Guile has these built into the language.</p>

<h3 id="productivity-matters">Productivity matters</h3>

<p>Guile is in a strange niche is that its primary <em>raison d’être</em> is to be an
extension language for the GNU project. Like Emacs Lisp is for extending Emacs,
Guile is the <em>de facto</em> language for GNU programs for extension and scripting.</p>

<p>Guile doesn’t have Quicklisp and its package manager and build system is
basically nonexistent for the first and <a href="https://www.gnu.org/software/autoconf/">Autoconf</a> for the second. There is
<a href="https://lists.gnu.org/archive/html/guile-user/2017-03/msg00168.html">sentiment</a> in the Guile community to have <a href="https://guix.gnu.org/">Guix</a> as the package manager for
Guile. This might sound a bit onerous, since Guix is also a complete package
management for many other things than Guile, but consider this: as Andy Wingo
points out in his message that Guile libraries often come with C extensions,
Guile packages need some sort of managed build system for building the C
extensions. Since it doesn’t have one, to solve the problem of building a
package manager you’d also have to build a build system that can manage C code
and packages needed by the C code bits. To do this elegantly is a gargantuan
task, for instance, <a href="https://wiki.call-cc.org/man/5/Extensions#installing-eggs-that-use-libraries">chicken-install just asks you to put compiler/linker flags
on the command line before calling it</a>, so it obviously is a hard problem.</p>

<p>Now, Guix solves all that, and more, in a manner that is quite elegant and
interesting. But it’s not as lightweight as something like Quicklisp or
<a href="https://wiki.call-cc.org/man/5/Extensions"><code>chicken-install</code></a> from <a href="http://call-cc.org/">CHICKEN Scheme</a>. What is more, Guix works only on GNU/Linux
systems really, so macOS and Windows users won’t be able to do use your library
if you plan on distributing it via Guix. Duh, it’s the GNU project, but
portability is always nice.</p>

<p>But in Common Lisp I can write <code>(ql:quickload :alexandria)</code> and voilà, it will
automatically install the <a href="http://quickdocs.org/alexandria/">Alexandria</a> library that I can use. Then again, in
Common Lisp it’s somewhat rarer to have C extensions, so I don’t know how ASDF
handles that.</p>

<p>It is unfair to compare <a href="http://joaotavora.github.io/sly/">SLY</a> to <a href="https://www.nongnu.org/geiser/">Geiser</a>, the best Emacs Scheme integration
package.  SLY is based on <a href="https://common-lisp.net/project/slime/">SLIME</a> which has <em>decades</em> of man-years of work behind
it. Geiser is able to support multiple Scheme implementations and it is quite
impressive in this regard. But SLY obviously has much more (e.g. an interactive
debugger). That said, Geiser has nice Guile support, and Guile is in general the
most Common Lisp-y of all Schemes, in fact, it has</p>

<ul>
  <li>an imitation of CLOS in the form of <a href="https://www.gnu.org/software/goops/">GOOPS</a></li>
  <li>docstrings and keyword, rest, and optional arguments for function
definitions</li>
  <li>an interactive REPL and a mutable top-level (unlike many Schemes)</li>
  <li>a nice module system</li>
  <li><a href="https://www.gnu.org/software/guile/manual/html_node/Defmacros.html"><code>defmacro</code></a> and exceptions somewhat <a href="https://www.gnu.org/software/guile/manual/html_node/Raising-and-Handling-Exceptions.html">similar to Common Lisp restarts </a></li>
</ul>

<p>and some nice things Common Lisp doesn’t have like first-class
continuations. But then again I would use those rarely.</p>

<h3 id="when-would-i-pick-one-over-the-other">When would I pick one over the other?</h3>

<p>If I were to write an extensible C/C++/Rust program that I <em>know</em> will need to use
a low-level language, I might do the low level bits using a low level language
and then write the rest in Guile. Guile makes it very easy to spin up a REPL
socket to do something like <code>myprogram --repl=12345</code> that you can connect to, and
the interop between C and Guile is fantastic, it has to be, as it’s primarily an
extension language.</p>

<p>On the other hand, if were to build a wholly standalone application, the choice is
not as obvious. I could do the whole thing in either language. Common Lisp can
build native executables, although their size will be large (who cares?) since
the binary will include the whole Lisp implementation. Guile cannot compile to
native code so you’ll have to write a script executable, but that doesn’t really
matter.</p>

<p>Scenarios where I would pick Guile:</p>

<ul>
  <li>when I’m making an extensible program that has to have some C/C++ bits but I
want to make it scriptable by users</li>
  <li>when I want to write a native binary but not write too much C/C++ code</li>
  <li>I just want to write Scheme, because Scheme is a bit more elegant</li>
  <li>the project has something to do with the <a href="https://www.gnu.org/software/autoconf/">GNU project</a></li>
</ul>

<p>On the other hand, Common Lisp makes the most sense if I just want to enjoy a
seriously rapid development experience, a large standard library and language,
and I don’t mind having 50MB binaries (again, who cares?) if I were to write
standalone programs. Guile can’t do that, but it’s easy to either write Guile
scripts or a C program that essentially bootstraps a binary to load a Scheme
runtime. This is how <a href="http://lilypond.org/">LilyPond</a> is written, for example.</p>

<p>So the answer to which one is decidedly <strong>both</strong>! Both languages are really fun to
write. At the moment I don’t do Lisp at my day job so it’s all for fun
anyway. If this were for professional purposes, I don’t know. Very often a
strict requirement for professional work is to be able to be productive. In that
regard I think Common Lisp has a significant edge, not only due to its superior
development experience, but its history as a real production language. There are
actual companies doing stuff in Common Lisp. I have not heard of any
professional (in the industrial sense) uses of Guile, notwithstanding that many
projects powered by Guile (Guix, etc.)  are <em>extremely</em> professional in the way
they are written and maintained. But Common Lisp has <em>more</em> libraries and
companies behind it.</p>

<h3 id="what-about-clojure">What about Clojure?</h3>

<p>I’ve actually had the pleasure to use Clojure for personal fun, and a little bit
of professional use. I wrote a couple of libraries (<a href="https://github.com/ane/vigil">vigil</a> and <a href="https://github.com/ane/task">task</a>) and my
experience with has always been positive and its development experience is
excellent. Clojure isn’t a true Lisp, or well, it is part of the <em>Lisp
family</em>. Its ability to interface with the JVM makes it easy to leverage the
thousands of JVM libraries out there.</p>

<p>I’d gladly do it again, though I feel that Common Lisp with CLOS and its module
system makes it somewhat easier to practice <a href="https://en.wikipedia.org/wiki/Programming_in_the_large_and_programming_in_the_small"><em>programming in the large</em></a>. Clojure
explores interesting territories with <a href="https://clojure.org/guides/spec">spec</a>, so it is interesting to see what
direction the language will take in the future.</p>

<h3 id="final-words-emacs-lisp">Final words: Emacs Lisp</h3>

<p>There’s also a parenthetical elephant in the room here: Emacs Lisp! An old
descendant of <a href="https://en.wikipedia.org/wiki/Maclisp">MacLisp</a>, it’s actually quite fun to write, and the fact that Emacs
itself is the interpreter, you have superb introspectability for any Elisp
code. Most of the Lisp I write these days is probably Emacs Lisp. It’s very
close to Common Lisp. <a href="https://www.gnu.org/software/emacs/manual/html_mono/cl.html#Overview">cl-lib</a> adds a sufficient amount of convenience from
Common Lisp to make Elisp writing quite enjoyable. <a href="https://www.gnu.org/software/emacs/manual/html_mono/eieio.html#Top">EIEIO</a> adds a subset of CLOS
that can be used seamlessly with cl-lib. The condition system is missing.</p>

<p>I’ve also done a fair bit of <a href="https://fennel-lang.org/">Fennel</a>, a Lisp that compiles to Lua. I used it to
write a <a href="https://github.com/ane/mudrally">small game</a> and it was fun to write since you could develop the game in a
REPL.</p>

<p>All in all, Lisp in all its variants is the most fun I’ve ever had while
programming a computer. Guile and Common Lisp are definitely the most fun I’ve
had programming in <em>Lisp</em>.</p>

  </div></div>]]>
            </description>
            <link>https://ane.github.io/2020/10/05/between-two-lisps.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25313311</guid>
            <pubDate>Sat, 05 Dec 2020 10:16:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A tale of Template Haskell and cross compilation]]>
            </title>
            <description>
<![CDATA[
Score 12 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25313146">thread link</a>) | @fanf2
<br/>
December 5, 2020 | https://www.tweag.io/blog/2020-11-25-asterius-th/ | <a href="https://web.archive.org/web/*/https://www.tweag.io/blog/2020-11-25-asterius-th/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><p>Template Haskell (TH) is a widely used yet controversial language extension. You have
probably used it in your own code; with a single line of splice code, you can
achieve tasks like deriving instances and embedding files easily. And you might
also have heard the reasons why people may dislike it: it slows down
compilation, breaks encapsulation, arbitrary IO at compile time is risky, etc.</p>
<p>But it is less well known that Template Haskell also makes cross compilation
with GHC harder. In this post, we’ll show why this is a challenge, some existing
solutions developed by the community, and in particular, how this problem is
addressed by <a href="https://github.com/tweag/Asterius">Asterius</a>.</p>
<h2>Just run some code at compile time, what can go wrong?</h2>
<p>Conceptually, Template Haskell is a principled way of generating Haskell AST at
compile time, like in the simplified example below:</p>
<div data-language="haskell"><pre><code>

<span><span>import</span> Data.Char</span>
<span><span>import</span> Language.Haskell.TH.Syntax</span>
<span><span>import</span> System.Process</span>

<span>gitRev</span> <span>::</span> <span>String</span>
<span>gitRev</span> <span>=</span>
  <span>$</span><span>(</span> <span>do</span>
       <span>rev</span> <span>&lt;-</span>
         <span>runIO</span> <span>$</span>
           <span>filter</span> <span>isHexDigit</span> <span>&lt;$&gt;</span> <span>readProcess</span> <span>"git"</span> <span>[</span><span>"rev-parse"</span><span>,</span> <span>"HEAD"</span><span>]</span> <span>""</span>
       <span>liftString</span> <span>rev</span>
   <span>)</span></code></pre></div>
<p>Suppose we’d like to define a <code>gitRev</code> string that represents the current <code>git</code>
revision in the project repository. This can be done using an expression splice:
it is written using the <code>$(...)</code> syntax, and the content within <code>$()</code> is an
expression of type <code>Q Exp</code>, representing a compile-time computation that returns
an <code>Exp</code> value, which is, in this case, the current <code>git</code> revision as a string
literal.</p>
<p>Splice code lives in the <code>Q</code> monad, which manages the context for Template
Haskell and provides a rich set of interfaces. Inside <code>Q</code> we can query info
about datatypes or functions, allocate fresh identifiers, etc. Arbitrary <code>IO</code>
actions may also be run inside <code>Q</code>. Here, we run <code>git rev-parse HEAD</code> to obtain
the <code>git</code> revision and then return it. When GHC compiles this module, the splice
is replaced with a string literal, and compilation moves on.</p>
<p>So at first glance, Template Haskell is just about running user code at compile
time, what can go wrong? All is right for most developers, who compile to the
same platform they run GHC on, but there’s trouble ahead when you try to do
cross compilation…</p>
<h2>The what and why of cross compilation</h2>
<p>Suppose we’d like to write a Haskell app for an Android phone or a Raspberry
Pi. It’s possible to bootstrap a native GHC release on them and use it to
compile stuff, but given the limited hardware resources of these machines, it’s
wiser to run GHC on a proper x64 build server and emit code for these ARM
devices. When we do so, we’re performing <em>cross compilation</em>. Some terminology:</p>
<ul>
<li>The <em>host</em> platform is where we run GHC to compile stuff.</li>
<li>The <em>build</em> platform is where we compile GHC. For simplicity, we assume
build=host and only use the host term from now on.</li>
<li>The <em>target</em> platform is where we run the compiled Haskell app. When
host=target, the GHC is a <em>native</em> GHC, otherwise it’s a <em>cross</em> GHC.</li>
</ul>
<p>For a native GHC, Template Haskell isn’t a problem, since GHC can link and run its
emitted code just like native dynamic libraries. But this doesn’t work
out-of-the-box for a cross GHC.</p>
<p>Over the years, people have come up with different approaches to address the
cross compilation issue of Template Haskell, each coming with its own rough
edges; more details follow in later sections.</p>
<h2>Only run TH on the host platform</h2>
<p>If we can’t run emitted code, then how about we don’t run it at all and stay
with a cross GHC without TH support? We’ll preprocess the cross GHC input code,
strip usages of the Template Haskell extension, and replace all TH splices with
the expanded code. And the way to expand the splices would be… using a native
GHC to compile it!</p>
<p>There’s a GHC flag <code>-ddump-splices</code> which dumps the expanded splices code.
Unfortunately, the dump output has extra text decorations and isn’t proper Haskell
source code, so it takes more work to use the dumps. Here’s a list of known
implementations of the splice dump approach:</p>
<ul>
<li><a href="http://source.git-annex.branchable.com/?p=source.git;a=blob;f=Build/EvilSplicer.hs;h=e07034c5b05f47c316a1e68e6a85d54335c8e253;hb=aaa841e60a55524c3efb5e9783b8e6074d2413cc"><code>EvilSplicer</code></a> uses a <code>parsec</code>-based parser to process the dumps
for later consumption of cross GHC. It was used in the
<a href="https://git-annex.branchable.com/"><code>git-annex</code></a> project until late 2018.</li>
<li><a href="https://hackage.haskell.org/package/zeroth"><code>ZeroTH</code></a> is a tool which does something similar, and includes a CLI
and <code>Cabal</code>-related helper functions.</li>
<li><a href="https://github.com/reflex-frp/reflex-platform"><code>reflex-platform</code></a> uses a patched native GHC which dumps the
expanded splices as proper Haskell source code, and feeds into <a href="https://github.com/ghcjs/ghcjs">GHCJS</a>.</li>
</ul>
<p>However, making native/cross GHC work together is not trivial:</p>
<ul>
<li>Unlike <code>gcc</code> or <code>clang</code> which can emit code for other platforms by simply
adding relevant CLI flags, a GHC installation can only emit code for a single
target platform configured at its build time. So two different GHC
installations must be managed in isolated places.</li>
<li>Native/cross GHC must have the same version and process the same build plan to
minimize the chance of emitting wrong code. Say package <code>foo</code> includes a TH
splice that uses package <code>bar</code>, if native/cross GHC sees different versions
(or even same version but different build plan) of <code>bar</code>, the splice behavior
could potentially differ, expanding into wrong code that may be silently
consumed by cross GHC.</li>
</ul>
<p>Given the complexity of the required hacks and GHC/Cabal’s lack of cross
compilation support, it’s common to use an external build system (e.g.
<a href="https://nixos.org/">Nix</a>) to encapsulate this mechanism.</p>
<p>Other than saving dumps of expanded splices, there is another solution to only
run TH splice code on the host platform: the same GHC always compile everything
to both host/target code in one invocation! When running TH, we can just load
host code just like native GHC. This requires quite some customization of GHC
behavior and is only possible for 3rd-party compilers based on GHC API. In
fact, GHCJS used this approach in its earliest days.</p>
<h3>Pros and cons of running TH on the host platform</h3>
<p>Running TH on the host platform works for pure splices, which can only do
things like reifying info and generating ASTs. It should also work pretty well
for side-effecting splices which reads files, spawns processes or fires
missiles, since the splice behavior should be just the same as when we use a
native GHC to compile stuff.</p>
<p>But is this the end of story? Not yet. Here’s one immediate problem: the
native/cross GHC may not consume the same Haskell sources despite our best
efforts.</p>
<ul>
<li>Haskell modules may use the <code>CPP</code> extension with target-specific macros, so
when you compile for different targets, you see different top-level
definitions.</li>
<li>Cabal files may also check implementation/platform/etc, and end up with
different flags or even different modules to be consumed by GHC.</li>
</ul>
<p>The problems above will likely trigger compile-time errors. And there’s an even
stealthier problem that may lead to generating incorrect code instead of a
crash: the architecture difference of host/target, e.g. word size or endianness.
For instance, a TH splice may make use of <code>sizeOf (undefined :: Int)</code>, which is
4 on 32-bit target platforms, and if the host platform is 64-bit, then the TH
splice will see 8, which sneaks into the emitted code without a single warning.</p>
<h2>Run TH code on the target platform</h2>
<p>As explained in earlier sections, vanilla GHC can only link and run host code.
Would it be possible to teach GHC to link and run target code? The answer is
yes. The key to supporting running non-native code is RPC (Remote Procedure
Calls). GHC needs to call into target code to obtain the splice expansion
result; the target code needs to call GHC to do reification. These calls are
achieved via exchanging serialized messages between GHC and the loaded splices.
Since there is a fixed set of operations allowed in the <code>Q</code> monad (as methods of
the <code>Quasi</code> class), the operations and the results can be encoded as a
serializable <code>Message</code> datatype.</p>
<p>This RPC approach to run TH code is standardized in the <a href="https://gitlab.haskell.org/ghc/ghc/-/wikis/commentary/compiler/external-interpreter">external
interpreter</a> feature. When running TH, GHC starts an
external process calls <code>iserv</code>, pipes messages to <code>iserv</code> and tells it to load
archives, objects, etc and link code. After a splice starts running in <code>iserv</code>,
<code>iserv</code> may send queries back to GHC and get results. Finally, the splice
expansion result is sent back to GHC.</p>
<p>The external interpreter opens up the possibility of using various emulators
(e.g. <code>wine</code> for windows, <code>node</code> for js/wasm or even <code>qemu</code> for exotic
platforms) to run target code for TH. GHC itself doesn’t need to care about how
the code is actually linked and run in <code>iserv</code>, and TH should work as long as
our target-specific <code>iserv</code> can properly process the messages.</p>
<p>This approach was pioneered by GHCJS, and later made it into upstream GHC by
7.10. Other than GHCJS, known users include:</p>
<ul>
<li>GHC itself, even in native GHC! But why bother? Well, suppose we’re compiling
a profiled library with TH usage. Since profiled code follows different
runtime conventions and links with profiled runtime, in the early days, a
profiled GHC executable was needed. Now, we can simply use a profiled <code>iserv</code>
executable, and avoid the extra profiling overhead in GHC.</li>
<li><a href="https://github.com/input-output-hk/haskell.nix">haskell.nix</a>, which includes support for cross-compiling to
Windows via <code>wine</code> emulation of TH code.</li>
<li><a href="https://medium.com/@zw3rk">Mobile Haskell</a>, which are ARM-targetting GHC distributions.
They use Android/iOS emulators to set up the splice runtime environment. GHC
talks to an <code>iserv-proxy</code> process via pipes, and <code>iserv-proxy</code> merely relays
the messages to the real <code>iserv</code> program in the emulator via a socket.</li>
<li>The <a href="https://github.com/typelead/eta">Eta</a> Haskell-to-JVM compiler.</li>
<li><a href="https://github.com/tweag/Asterius">Asterius</a>, which uses <code>node</code> for running the WebAssembly &amp;
JavaScript code.</li>
</ul>
<h3>Pros and cons of running TH on the target platform</h3>
<p>Compared to running TH on the host platform, there are a few benefits to
running it on the target platform:</p>
<ul>
<li>No host/target incoherence issues, as explained in earlier sections.</li>
<li>Less hacky and more standardized. Although upstream GHC won’t likely contain
<code>iserv</code> implementations for all interesting target platforms out there,
developers can just roll their own if needed.</li>
<li>Simpler, since there isn’t a bunch of hacks to be packaged via nix anymore,
and it works with vanilla <code>cabal</code>/<code>stack</code>.</li>
</ul>
<p>It would be tempting to announce TH for cross compilation is now a solved
problem! Turns out it’s not. Recall how TH enables running …</p></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.tweag.io/blog/2020-11-25-asterius-th/">https://www.tweag.io/blog/2020-11-25-asterius-th/</a></em></p>]]>
            </description>
            <link>https://www.tweag.io/blog/2020-11-25-asterius-th/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25313146</guid>
            <pubDate>Sat, 05 Dec 2020 09:43:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Maybe we shouldn't want a fully decentralized web]]>
            </title>
            <description>
<![CDATA[
Score 171 | Comments 438 (<a href="https://news.ycombinator.com/item?id=25312854">thread link</a>) | @talhah
<br/>
December 5, 2020 | https://withblue.ink/2020/11/12/maybe-we-shouldnt-want-a-fully-decentralized-web.html | <a href="https://web.archive.org/web/*/https://withblue.ink/2020/11/12/maybe-we-shouldnt-want-a-fully-decentralized-web.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><p>I spent a large part of 2019 working with the distributed and decentralized web, especially IPFS, also known as the “Inter-Planetary File System”. I’ve written a few articles on the topic, on how you can host a web app on IPFS, one of which even ended up on the front page of HackerNews.</p><p>For about a year, I hosted my blog and other apps through an IPFS cluster. I wrote a utility for making pinning files easier on Pinata, a third-party cloud service for IPFS. I made some small contributions to the IPFS core projects. I built some projects with it, including one that I never released–nor fully completed–that used both IPFS and Ethereum. And I even gave a talk about hosting static web apps on IPFS at Node+JS Interactive last December in Montreal.</p><p>That all changed in the Spring of 2020. I called myself out of the distributed web.</p><p>My blog and other apps I built aren’t hosted on IPFS anymore. I don’t participate in those online communities anymore. I’ve stopped writing about the distributed and researching about it. I’ve shelved all my projects that were using those technologies.</p><p>I also updated my blog posts about IPFS adding a note that my blog isn’t hosted that way anymore. More than a few people asked me why, and I always gave the same answer: a mix of technical issues and mostly personal reasons. So, I think it’s time I explain the personal reasons.</p><p>First, I need to explain why I got involved with IPFS in the first place.</p><p>When I first read about IPFS, my mind immediately saw it as an exciting new platform I could build my apps for. The premise of a fully-decentralized platform included unlimited scalability, ultra-high availability and resiliency, no single points of failure, and resistance against attacks like DDoS.</p><p>Coming from a background in which I am always thinking about SLAs, number of nines of uptime, disaster recovery, etc, IPFS sounded like a dream platform that would magically solve all my concerns. And, aside from some performance issues at times, it did. Plus, the small engineer inside me was really excited about being able to play with a new, shiny toy, that had lots of hype around it!</p><p>What happened next for me was a reckoning with the reality of what many people behind the IPFS core project and the community around it saw: the dream of a radically open, unfiltered, and by-design un-censorable platform.</p><p>I have recently opened up about my experience, over a decade ago, with building an app with good intentions but that was then misused (<a href="https://withblue.ink/2020/09/24/that-time-i-accidentally-built-a-spying-app.html"><em>That time I accidentally built a spying app</em></a>). I learned early on in my life and (pre-)professional career about the importance of ethics in software development, and I am now a proponent of the idea that just because something <em>can</em> be built, it doesn’t mean it <em>should</em> be built.</p><p>And that brings me back to why, after spending some time in the world of the decentralized web, I have called myself out, and why I think that should things like IPFS actually become mainstream, they might cause more harm than good in the world.</p><p><strong>I have seen, and I am seeing every day, the dangers of completely unrestricted speech, and I don’t want to be the one enabling that.</strong></p><p>I know that last sentence is a strong ideological statement; some might call it a <em>political</em> statement, but for me it’s more than just political, which is often used to describe extemporary beliefs.</p><p>Many of you reading this will not agree with me, and that’s fine. I’m not going to try and change your beliefs with this blog post. Rather, I’m looking to explain why, while I respect that others might have differing opinions, I stopped doing anything that would actively advance a technology whose ethics I question. To put it in other terms: your freedom of speech isn’t my obligation to enable you and give you a platform.</p><p>In short, I think that while the Internet has helped the world in countless of ways, it has also brought out the worst in people.</p><p>I do believe we need some filters on the Internet. It’s not just about stopping criminal activities, terrorism and child pornography: while I am obviously unsupportive of all them, I also think they’re not the biggest dangers coming from the Internet (yet they’re a very convenient pretext for politicians).</p><p>Instead, I think that regular people’s writings on the Internet is hurting the world on a bigger scale. And the collective sentiment is often manipulated by some “agitators” that are exploiting anonymous online speech for their own agendas: that includes online militias–for example sponsored by foreign governments–whose goal is to destabilize a society.</p><p>In the last few years, completely unregulated online speech has given rise to fake news and conspiracy theories that have actually killed people. It’s offered a megaphone to those promoting dangerous ideas like white supremacy, Islamophobia, anti-Semitism, homophobia and other anti-LGBTQ positions, and sometimes outright Nazism. It has tilted many democracies towards right-wing populism and fascism.</p><p>All these extreme ideas have divided societies and increased social tensions. And they’re responsible for a number of acts of terrorism which caused the death of too many people.</p><p>Given our experiences so far, there’s no sign that indicates that a fully decentralized and unrestrained web would be anything but a dangerous wild west.</p><p>In fact, despite being tightly centralized and controlled, social media companies are facing significant challenges regulating what people write on their platforms, and in fact they are usually at the center of every scandal of these years. Decentralization and less control won’t be the solution to this issue, but rather the opposite.</p><p>If you believe that I’m overthinking this, and that it’s not going to be bad <em>this time</em>, I urge you to think twice.</p><p>First, there’s no indication that a new Web would be better than the previous one just on virtue of being decentralized. The same actors that are using today’s Internet to wreak havoc around the world would not disappear in the new Internet, and actually, they could be even more unrestrained.</p><p>Second, while almost everyone in the communities supporting a distributed web are good people, with good intentions, seeing some names in there is concerning to me. Regarding IPFS, advocates (at least for a while) included people like Nick Lim of BitMitigate and VanwaNet, companies responsible for rescuing, among others, <a href="https://www.geekwire.com/2017/seattles-bitmitigate-now-protecting-pro-nazi-site-daily-stormer-web-attacks/">pro-nazi website</a> The Daily Stormer <a href="https://arstechnica.com/information-technology/2019/11/breaking-the-law-how-8chan-or-8kun-got-briefly-back-online/">and the platform</a> 8chan, a cesspool full of Nazi propaganda, child pornography, and other hate speech. Gatherings on 8chan have been <a href="https://en.wikipedia.org/wiki/8chan#2019_shootings">blamed</a> for at least three mass shootings in 2019 alone, including the one in the <a href="https://time.com/5648479/8chan-ban-new-zealand/">mosque in Christchurch</a>, all of them motivated by racial hatred.</p><p>The first real examples of the distributed web aren’t particularly encouraging either. Among some of the most popular apps (“popular” in relative terms, of course) for the distributed web is DTube, a sort of YouTube that is built on top of IPFS. As you can expect, the website is full of questionable content, including conspiracy theories, cryptocurrency scams, weapons, RT&nbsp;International’s <a href="https://www.theguardian.com/commentisfree/2019/jul/26/russia-disinformation-rt-nuanced-online-ofcom-fine">Russian propaganda</a>… and of course, porn.</p><p>In essence, if it’s true that <em>a good beginning makes a good ending</em>… with such a mixed beginning, the outlook isn’t too rosy.</p><p>I understand that my opinion is somehow a minority one, and people will continue to build IPFS and other technologies part of the distributed web. There’s also a chance they might become successful and potentially get mainstream adoption–although at this stage the barrier to entry is too high for the average user.</p><p>However, I feel that it’s my responsibility to not be helping to advance this technology and the beliefs of at least some advocates in the world of the distributed web hold. If the advancement occurs, it won’t be because of my help.</p><hr><p><em>PS: The idea that freedom of speech is an absolute right that should have (almost) no limitations is not a universal one. While that right is granted to people living in all democratic countries, outside of North America it’s accepted that such right comes <a href="https://www.nytimes.com/2019/08/06/world/europe/el-paso-shooting-freedom-of-speech.html">with limitations</a>, and usually that has roots in the history of those places.</em></p><p><em>For example, in Italy where I grew up, the same constitution that grants freedom of expression (speech, press, etc) also criminalizes “apology of fascism”, or propagating the ideas of fascism; it also sets other limits on speech that is hateful or discriminatory. Other European countries have similar laws, such as the outlawing of Nazi rhetoric and symbology in Germany.</em></p></article></div>]]>
            </description>
            <link>https://withblue.ink/2020/11/12/maybe-we-shouldnt-want-a-fully-decentralized-web.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25312854</guid>
            <pubDate>Sat, 05 Dec 2020 08:31:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[From Coils to Curves – A Primer on Elliptic Curve Cryptography]]>
            </title>
            <description>
<![CDATA[
Score 10 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25312733">thread link</a>) | @roberla
<br/>
December 4, 2020 | https://security.christmas/2020/5 | <a href="https://web.archive.org/web/*/https://security.christmas/2020/5">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><section><p>It is well known that prime numbers are important for cryptography, although it has not always been true. The advent of primes came with several groundbreaking papers almost 50 years ago. Pioneers in introducing asymmetric cryptography, Whit Diffie, Martin Hellman, Ron Rivest, Adi Shamir and Leonard Adleman, used results from number theory to build key agreement, encryption, and signatures. Prime numbers hold a very special position in number theory, and this carried over to cryptography.</p>
<h2>From Primes to Crypto</h2>
<p>Cryptographic protocols are typically working <em>modulo</em> some prime <em>p</em>. This can be likened to turning the number line into a coil, such that 0, <em>p</em>, 2<em>p</em>, etc. all join at the same place. From then on, whenever we add or multiply the number such that we go beyond <em>p</em>, we can simply remove as many multiples of <em>p</em> as necessary until we come between 0 and <em>p</em> again.</p>
<p>Now, imagine that we used a composite number instead, for example 12. Then 0 and 12 are "the same" in this situation, but that also means that 3 multiplied by 4 is ... 0! One of the intuitions when working with normal numbers is that if <em>ab</em> = 0, then either <em>a</em> or <em>b</em> would have to be 0. Hence, when using composite numbers, there is simply stuff that no longer works the way we’re used to. Fortunately, this is not the case when using the primes — for instance 7 — as our so-called modulus.</p>
<p><img src="https://security.christmas/assets/curves.png"></p>
<p>Let’s make a rule, and let’s call it <em>m</em>. We take the coil we just made from the number line, and since we can always reduce numbers to below <em>p</em>, we label our points on this circle from 0 to <em>p</em>-1. Given two points <em>a</em> and <em>b</em> on the circle, we decided that the output of the rule <em>m</em>(<em>a</em>, <em>b</em>) should be the point which is represented by the product <em>ab</em>, possibly after reducing modulo <em>p</em>. It may look like a very natural rule, but it is nonetheless a rule we just agreed on. If you play around with this rule a bit, you will notice some properties:</p>
<ul>
<li>If <em>a</em> = 1, then <em>m</em>(<em>a</em>, <em>b</em>) = <em>b</em> (and the other way around).</li>
<li>For any <em>a</em>, <em>b</em> not equal to 0, <em>m</em>(<em>a</em>, <em>b</em>) is never zero. So, if we removed 0 from the circle entirely, no harm would happen — the rule would still be well-defined.</li>
<li>For any nonzero <em>a</em>, there is always some <em>b</em> such that <em>m</em>(<em>a</em>, <em>b</em>) = 1.</li>
</ul>
<p>These nice properties — together with a property called associativity — are the properties we need to be able to do cryptographic computations.</p>
<p>Now focus on a particular number on the circle, and let’s call it <em>g</em>. If we take <em>m</em>(<em>g</em>, <em>g</em>), or — to return to the more usual notation — <em>g²</em>, we will reach a new point on the circle. We can continue this process and compute <em>g</em>³, <em>g</em>⁴, etc. At some point, we will reach 1. All the points we have visited in this process are members of the set of numbers <em>generated</em> by <em>g</em>, and if the number of points on the coil is a large prime, then we have a very good candidate for doing cryptography, for example Diffie-Hellman key exchange. Let <em>h</em> be some number in this set generated by <em>g</em>. That means that <em>h</em> = <em>g</em>ᵉ for some exponent <em>e</em>. If it is easy to find this <em>e</em> from <em>g</em> and <em>h</em>, we would have trouble. Fortunately, it turns out that if we use <em>large enough</em> primes, then this <em>e</em> appears to be very difficult to find.</p>
<h2>From Coils to Curves</h2>
<p>Coiling up the number line is not the only way of finding suitable primitives for cryptography. Let’s make a new rule. Instead of using a circle like we did in the previous section, we consider the following equation:</p>
<p><em>y</em>² = <em>x</em>³ + <em>ax</em> + <em>b</em>, where <em>a</em> and <em>b</em> are fixed constants.</p>
<p>If we graph this in our usual coordinate system, it may look like this curve:</p>
<p><img src="https://security.christmas/assets/curves2.png"></p>
<p>We will now make a rule on how to combine two distinct points <em>P</em> and <em>Q</em> on this curve. The agreed upon notation is to call this rule addition, but we will have to define what we mean by that. Programming languages often include this mental concept as operation overloading. Draw the straight line between <em>P</em> and <em>Q</em>. It will intersect at a third point, say, <em>R</em>. This could have been a nice candidate for <em>P</em> + <em>Q</em>, but since we are making the rules, let’s make this a bit more interesting. Draw a vertical line through <em>R</em>. It will intersect the curve on the opposite side of the <em>x</em>-axis, and we define this point as <em>P</em> + <em>Q</em>. Just as before, this is a rule we’re deciding here and now. However, this also turns out to be a very useful rule, with the same properties as before:</p>
<ul>
<li>Instead of having the point 1 on the circle, we imagine a point infinitely far up. (Remember what you see when looking at railway tracks: parallel lines actually meet beyond the horizon, at infinity.) So, now the line intersecting <em>R</em> and <em>P</em> + <em>Q</em> is indeed also intersecting a third point: the point at infinity. This can be made precise, but requires maths from algebraic geometry, which is far beyond the scope of this blog post. This point at infinity has all the same properties as 1 had above.</li>
<li>For any point <em>S</em> on the curve, there is always a point <em>T</em> such that we get a line intersecting <em>S</em>, <em>T</em> and the point at infinity. This means that for any point <em>S</em>, we can find a point we can call -<em>S</em>.</li>
</ul>
<p>You can test this rule interactively in a simple <a href="https://www.geogebra.org/m/ukhajwzs">GeoGebra demonstration</a>.</p>
<p><img src="https://security.christmas/assets/ec_group_law.gif"></p>
<p>We just assumed that <em>P</em> and <em>Q</em> were distinct. If <em>P</em> = <em>Q</em>, then we simply use the tangent to the curve at point <em>P</em> instead, and proceed as before.</p>
<p>In particular, take a point <em>G</em>, and compute 2<em>G</em> = <em>G</em> + <em>G</em>, 3<em>G</em>, 4<em>G</em>, etc. Eventually, we reach the point at infinity, and then back to <em>G</em>. We have now spent about 1000 words of this blog post getting here, just to do the same as we did above, and what was the point? Above, we said that computing exponents are secure if the primes were large enough. It turns out that "large enough" is currently about 3072 bits, or a number with approximately 925 digits. That is somewhat strenuous even for a computer, but the elliptic curve version only requires us to work on numbers of size 256 bits, or 77 digits, which is far more efficient.</p>
<h2>Elliptic Curve Diffie-Hellman Key-Exchange</h2>
<p>The Diffie-Hellman key-exchange protocol is widely used today, and its instantiation using elliptic curves is ranked as the best choice in modern cryptographic protocols like TLS and SSH. The protocol is fairly simple. The public information is an elliptic curve <em>E</em> and a generator <em>G</em> for the points on this curve. One party, Alice, samples a random integer <em>a</em> and computes a point <em>A</em> = <em>a</em> <em>G</em>. Another party, Bob, samples a random integer <em>b</em> and computes <em>B</em> = <em>b</em> <em>G</em>. Then they exchange the values <em>A</em> and <em>B</em>, and compute the shared key <em>K</em> = <em>b</em> <em>A</em> = <em>a</em> <em>B</em> = <em>a</em> <em>b</em> <em>G</em>. As long as both <em>a</em> and <em>b</em> stay secret, even when an attacker knows <em>G</em>, <em>A</em> and <em>B</em>, then the key is secure.</p>
<p><img src="https://security.christmas/assets/dh.png"></p>
<p><em>Reference: <a href="https://asecuritysite.com/encryption/go_x3dh">https://asecuritysite.com/encryption/go_x3dh</a>. Used with permission.</em></p>
<p>To achieve long-term security, to protect previous messages in the case where someone’s secret keys are leaked after the fact, Alice and Bob can do an ephemeral key-exchange every time they communicate. If <em>a</em> and <em>A</em> is Alice’s long term key pair where <em>A</em> is public to everyone, and similar for Bob, they can run the following protocol to agree upon a one-time session-key. Alice samples a random integer <em>c</em> and computes <em>C</em> = <em>c</em> <em>G</em>, and Bob samples a random integer <em>d</em> and computes <em>D</em> = <em>d</em> <em>G</em>. Then they exchange <em>C</em> and <em>D</em>, and compute the shared key as (<em>a</em> <em>b</em> + <em>c</em> <em>d</em> )<em>G</em>.</p>
<p>The interested reader can check out this <a href="https://play.golang.org/p/qJBI0_2lsGP">simple example written in Go</a>. Are you able to extend the basic protocol to the ephemeral key-exchange on behalf of Alice and Bob?</p>
<p>We finally point out that this protocol is vulnerable to a man-in-the-middle attack, and we need to also send signatures computed on the messages to ensure that the communication is authentic. Are you able to attack the protocol as described above, when signatures are not used? If you found these problems interesting, we encourage you to check out similar challenges at <a href="https://cryptohack.org/challenges/ecc/">cryptohack.org</a>.</p>
<h2>Common Curves</h2>
<p>Not all elliptic curves are suitable for cryptography. There could also be power in choosing a curve and the distinguished base point(s). Hence, implementations tend to choose among a small number of well-known curves. The US National Institute of Standards and Technology <a href="https://csrc.nist.gov/publications/detail/fips/186/4/final">maintains a list</a> of recommended curves; P-256 is perhaps the most popular among these.&nbsp;</p>
<p>Among others, there is also the <a href="https://safecurves.cr.yp.to/">SafeCurves</a> collection proposed by Dan Bernstein and Tanja Lange. In particular, their Curve25519 has proven to be a popular choice.</p>
<p>Elliptic curve libraries will typically have tailored support for certain curves.</p></section></article></div>]]>
            </description>
            <link>https://security.christmas/2020/5</link>
            <guid isPermaLink="false">hacker-news-small-sites-25312733</guid>
            <pubDate>Sat, 05 Dec 2020 07:58:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Modern Tire-pressure monitoring system Sensors: Let's try a DoS attack]]>
            </title>
            <description>
<![CDATA[
Score 60 | Comments 33 (<a href="https://news.ycombinator.com/item?id=25312714">thread link</a>) | @pabs3
<br/>
December 4, 2020 | http://www.mirider.com/weblog/2020/12/04#20201204_Modern_TPMS_Sensors_Lets_try_a_DoS_attack | <a href="https://web.archive.org/web/*/http://www.mirider.com/weblog/2020/12/04#20201204_Modern_TPMS_Sensors_Lets_try_a_DoS_attack">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  <td>&nbsp; &nbsp;</td>

  <!-- left column -->
  <td>

<!--
   <p>
   <br />
   <b>About</b> <br />
   Dieter Spaar's blog, Dieter Spaar's personal Blosxom blog.<br /><br />
   Dieter Spaar<br />
   <a href="mailto:spaar@mirider.com">spaar@mirider.com</a> <br />
   </p>
-->

   <p>
   <a href="http://www.mirider.com/weblog/index.rss">RSS</a>
   </p>

   <p>
     <b>Dieter's Web</b> <br>
     <a href="http://www.mirider.com/">mirider.com</a><br>
   </p>

   <p>
   <b>Projects I am participating</b> <br>
    <a href="http://bb.osmocom.org/" target="_blank">OsmocomBB</a><br>
    <a href="http://openbsc.osmocom.org/" target="_blank">OpenBSC</a><br>
    
   </p>

   <p>
   <b>Categories</b> <br>
   </p>
   <ul>
<li><a href="http://www.mirider.com/weblog/index.html">Root</a> (24)
<ul>
<li><a href="http://www.mirider.com/weblog/automotive/index.html">automotive</a> (3)
</li>
<li><a href="http://www.mirider.com/weblog/gsm/index.html">gsm</a> (17)
</li>
<li><a href="http://www.mirider.com/weblog/misc/index.html">misc</a> (1)
</li>
<li><a href="http://www.mirider.com/weblog/sdr/index.html">sdr</a> (2)
</li>
</ul>
</li>
</ul>


   <p>
   <b>Archives</b> <br>
   </p>
   <ul>
	<li><a href="http://www.mirider.com/weblog/2020/">2020</a> (1)
		<ul>
			<li><a href="http://www.mirider.com/weblog/2020/12/index.html">December</a> (1)</li>
		</ul>
	</li>
	<li><a href="http://www.mirider.com/weblog/2018/">2018</a> (5)
		<ul>
			<li><a href="http://www.mirider.com/weblog/2018/09/index.html">September</a> (1)</li>
			<li><a href="http://www.mirider.com/weblog/2018/05/index.html">May</a> (1)</li>
			<li><a href="http://www.mirider.com/weblog/2018/03/index.html">March</a> (1)</li>
			<li><a href="http://www.mirider.com/weblog/2018/01/index.html">January</a> (2)</li>
		</ul>
	</li>
	<li><a href="http://www.mirider.com/weblog/2013/">2013</a> (3)
	</li>
	<li><a href="http://www.mirider.com/weblog/2012/">2012</a> (4)
	</li>
	<li><a href="http://www.mirider.com/weblog/2011/">2011</a> (3)
	</li>
	<li><a href="http://www.mirider.com/weblog/2010/">2010</a> (8)
	</li>
</ul>


<!--
   <p>
   <b>Flavours</b> <br />
   There's more than one way to view this weblog; try these flavours on
   for size.
    <li><a href="http://www.mirider.com/weblog/index.index">index</a></li>
    <li><a href="http://www.mirider.com/weblog/index.1993">circa 1993</a></li>
    <li><a href="http://www.mirider.com/weblog/index.rss">RSS</a></li>
   </p>
-->
   <p>
   <b>Other Bloggers</b> <br>
    <a href="http://laforge.gnumonks.org/weblog/" target="_blank">Harald Welte</a><br>
    <a href="http://openbts.blogspot.com/" target="_blank">David Burgess</a><br>
   </p>

<!--
   <p>
   
   </p>
-->

   <p>
    <br>
    <a href="http://www.blosxom.com/"><img src="http://mirider.com/weblog/pb_blosxom.gif" alt="blosxom"></a>
   </p>

   <p>
    <br>
    <a href="http://www.mirider.com/#Site%20Contact">Contact/Impressum</a>
   </p>

  </td>

  <td>&nbsp; &nbsp;</td>

  <td>&nbsp; &nbsp;</td> 

  <!-- main blog entry column -->
  <td> 

   <br>

<span>Fri, 04 Dec 2020</span>
<div>
<p><a name="20201204_Modern_TPMS_Sensors_Lets_try_a_DoS_attack"><b>Modern TPMS Sensors: Let's try a DoS attack</b></a></p><p>
TPMS (Tire-pressure monitoring system) sensors have been researched extensively
many years ago, they periodically transmit the tire pressure, temperature
and a unique ID which can be misused for tracking a vehicle. But there is
another aspect: modern TMPS sensors also have a receiver which is typically
used to trigger the data transmission when a new TPMS sensor is presented to
the vehicle ("learning procedure").
</p>

<p>
Here in Europe TPMS sensors usually transmit on the 433 MHz ISM band. The
receiver operates on 125 kHz, very similar to LF RFID. A simple way to make
use of the receiver is just to look for the presence of the 125 kHz carrier
and then trigger data transmission. Current sensors are usually more evolved
and use a modulated carrier which contains command packets and only if the
correct command is received data transmission is triggered.
</p>

<p>
If you already have a receiver you can do of course more than just trigger
data transmission: For example there might be support for different
commands, some sensors even allow firmware updates this way.
</p>

<p>
One such command which is typically supported is switching the sensor into
"Shipping" mode. Why would you need that? When the sensor is operating
normally it waits for motion (there is an acceleration/shock sensor inside)
and only starts periodic data transmission when the wheel is rotating. This
is used to safe battery life. When the TPMS sensor is not yet mounted in the
tire it should not react on motion, that’s why there is this "Shipping" mode.
In this mode the sensor only wakes up every few seconds and looks if there
is a 125 kHz signal, if yes it checks for a valid command, for example the
command to trigger data transmission which usually also leaves "Shipping"
mode and switches the sensor into normal operation.
</p>

<p>
This "Shipping" mode can be misused: If you can switch a TPMS sensor of a
vehicle’s wheel into "Shipping" mode the sensor will no longer transmit data
and the vehicle's tire pressure control light will go on after a while.
Just to make it clear: This warning light is annoying to the driver, it
does not affect safety of the car because the deactivated TMPS sensor has
not affected the actual tire pressure.
</p>

<p>
I have looked at a few TPMS sensors for different cars if this really works,
I choose sensors for BMW and Ford cars. Please note that most certainly
other car manufactures are affected too, mainly because there are only a
few manufactures of TPMS sensors which deliver their sensors to various
car manufactures. My choice for BMW and Ford came from the fact that I
found lots of cheap, used sensor for those cars.
</p>

<p>
Also I only looked at "OEM" sensors for BMW and Ford, which means that those
sensors are mounted by the car manufacturer. There are also so called
"Universal" sensors which are typically mounted by tire dealers, there
are some notes about them at the end of this text.
</p>

<p>
It is quite easy to build a tool for transmitting data on 125 kHz: There
is this cheap EL-50448 TMPS sensor activation tool which only transmits a
carrier without modulation. However the hardware can easily be modified
to modulate the carrier: Most of the time OOK (On-Off Keying) is used
for communication, which means that the carrier is just turned on and off.
The EL-50448 uses a power driver with an unused "enable" pin to generate
the carrier, you can use this "enable" pin to modulate the carrier. The
data rate is slow, a frequently used rate is 3900 baud.  Most of the time
Manchester encoding of the data bits is used, which means that the carrier
changes twice as much (7800 changes per second). This is nothing special
and can be done with probably any microcontroller you prefer to use. The
hardware costs for such a setup are below EUR 20, the transmission range
is about 20 centimeters.
</p>

<p>
How can you find the command to switch to Shipping" mode? Brute force by
trying all possible commands is only an option if the command is short.
The reason is that the sensor only looks for the LF 125 kHz signal every
few seconds. If the command is not longer than two bytes brute force is
possible (it takes a few days), for longer commands it is impractical.
Please note that you also have to find a way to detect if the command you
send causes a reaction of the TPMS sensor, e.g. by monitoring the power
consumption of the sensor or receiving the 433 MHz data signal (which of
course only works if the command you send causes a data transmission).
</p>

<p>
Another option is looking at those TPMS tools which tire dealers and
car repair workshops use to check TPMS sensors. Some of those tools
might support switching a TPMS sensor into "Shipping" mode.
</p>

<p>
Those are the results I found (I won't go into the details to avoid misuse):
</p>

<ul>
<li><b>BMW:</b>

  A certain sensor used in several car models from TPMS Sensor manufacturer
  "A" can be switched into "Shipping" mode. The deactivated TPMS sensor can
  be activated again with a different command. Also if the sensor detects a
  fast pressure change (e.g. by inflating the tire) the sensor leaves
  "Shipping" mode. The command length is four bytes so brute force is no option. 

</li>

<li><b>Ford:</b>

  A certain sensor used in several car models from TPMS Sensor manufacturer
  "A" (the same manufacture as above for the BMW sensor) can be switched
  into "Shipping" mode, it is the same command as used by the BMW sensor
  from above. The deactivated TPMS sensor can be activated again with a
  different command.
  
  A certain sensor used in several car models from TPMS Sensor manufacturer
  "B" can be switched into "Shipping" mode. The deactivated TPMS sensor can
  be activated again with a different command. The command in this case is
  only two bytes and I tried all combinations which resulted in several more
  "interesting" commands, a few examples:


    <ul>
<li>
      It is possible to completely turn off the TPMS sensor. In this case it
      will no longer react on anything, you have to break open the sensor
      case and apply a hardware reset or disconnect the battery to reactivate
      it again.
</li>

<li>
      It is possible to switch the sensor into continuous "carrier transmit"
      mode on 433 MHz. In this mode the sensor will continuously transmit
      the 433 MHz carrier until the battery is empty or you apply a hardware
      reset (see above), it will not react on anything else. There are two
      other similar commands which transmit on the upper and lower shifted
      frequency (the sensor uses FSK modulation, Frequency Shift Keying, when
      transmitting data).
</li>
</ul>      

  Those examples show that it is basically possible to destroy this specific
  sensor by transmitting the appropriate command. Also if the sensor is in
  "carrier transmit" mode it probably disturbs the remote control car
  key fob which usually uses the same frequency as the TPMS sensor.
</li>
</ul>

<p>
You have to be close to the sensor to send those LF 125 kHz signals but it
only takes a few seconds to send the signal. Using a larger antenna (which is
basically a coil) for the transmitter, e.g. large enough to fit in a suitcase,
might extend the transmission range to more than a meter. 
</p>

<p>
How can those problems be avoided? This is actually quite easy, the command
to switch into "Shipping" mode should not be allowed if the measured tire
pressure is above a certain limit, which means that the sensor is mounted in
the tire of a vehicle. This also applies to those other commands of the sensor
from manufacturer "B" which are probably some kind of factory test or developer
commands. Please note that during my tests the commands I described were
possible even when the measured tire pressure was in the range of a typical
vehicle wheel.
</p>

<p>
I contacted the car manufactures (BMW and Ford) before I published this
article, this is the experience I made:
</p>

<ul>
<li>
  <b>BMW:</b>
  The contact information for reporting security issues can be found on
  the BMW website. I had a phone call with the responsible person within
  a few days after reporting the issue. BMW already knew the problem, they
  found it during an internal review. Their latest TPMS sensors have fixed
  the issue by blocking certain commands if the tire pressure is above a
  certain limit.
</li>

<li>
  <b>Ford:</b>
  I wasn't able to find a security contact on the website of Ford Germany
  so I contacted the person responsible for "Public Relation". He promised
  to look for someone who takes care of the issue I reported, after several
  days I got a reply that it is possible to disturb the TPMS system due to
  the nature of radio transmission and that this is a known problem. I wasn't
  able to communicate directly with the responsible person and I then replied
  that the reported issue is not about disturbance but a "Denial of Service"
  and that it is even possible to destroy a certain TPMS sensor used in Ford
  cars. I didn't receive any further information about the security issue, I
  notified them again after several weeks that I am now going to publish
  the issue which was acknowledged.
</li>
</ul>

<p>
Some notes about those "Universal" sensors tire dealers normally use: Those
sensors are "Universal" because they can be programmed for different car
models. The main benefit for the tire dealer is that only a few different
kind of "Universal" sensors have to be on stock, it’s not necessary to have
lots of different "OEM" TPMS sensors for every possible car model lying
around. The programming of those …</p></div></td></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://www.mirider.com/weblog/2020/12/04#20201204_Modern_TPMS_Sensors_Lets_try_a_DoS_attack">http://www.mirider.com/weblog/2020/12/04#20201204_Modern_TPMS_Sensors_Lets_try_a_DoS_attack</a></em></p>]]>
            </description>
            <link>http://www.mirider.com/weblog/2020/12/04#20201204_Modern_TPMS_Sensors_Lets_try_a_DoS_attack</link>
            <guid isPermaLink="false">hacker-news-small-sites-25312714</guid>
            <pubDate>Sat, 05 Dec 2020 07:53:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Reading Manpages Like a Pro (2018)]]>
            </title>
            <description>
<![CDATA[
Score 56 | Comments 32 (<a href="https://news.ycombinator.com/item?id=25311867">thread link</a>) | @woodruffw
<br/>
December 4, 2020 | https://blog.yossarian.net/2018/01/22/Reading-Manpages-Like-a-Pro | <a href="https://web.archive.org/web/*/https://blog.yossarian.net/2018/01/22/Reading-Manpages-Like-a-Pro">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">


<h2><em>Programming, philosophy, pedaling.</em></h2>

<ul>
    <li><a href="https://blog.yossarian.net/">Home</a></li>
    <li><a href="https://blog.yossarian.net/tags">Tags</a></li>
    <li><a href="https://blog.yossarian.net/favorites">Favorites</a></li>
    <li><a href="https://blog.yossarian.net/archive">Archive</a></li>
    
      <li><a href="https://yossarian.net/">Main Site</a></li>
    
</ul>

<hr>



<h2>
  <em>Jan 22, 2018</em>
</h2>

  <p>Tags:
  
    
    <a href="https://blog.yossarian.net/tags#programming">programming</a>,
    
  
    
    <a href="https://blog.yossarian.net/tags#workflow">workflow</a>
    
  
  </p>


<h3 id="preword">Preword</h3>

<p>I often reference the <a href="https://en.wikipedia.org/wiki/Man_page">manpages</a> when giving a development
presentation or talk, but I’ve only recently come to realize how few people are both <em>comfortable</em>
with the <code>man</code> interface and adept at discovering information through it.</p>

<p>This post is my attempt to share some of the tricks and techniques I’ve picked up over years of
reading manpages.</p>

<h2 id="a-quick-recap">A Quick Recap</h2>

<p>The manpages (short for “manual pages”) are the oldest and longest-running documentation collection
on *nix, stemming back to the
<a href="https://www.bell-labs.com/usr/dmr/www/1stEdman.html">first edition of the Unix Programmer’s Manual</a>
in 1971.</p>

<p>On a modern system, the <code>man</code> command is the most common way to access the manpages:</p>

<div><div><pre><code><span># access the first manpage named "time", which happens to be time(1)</span>
man <span>time</span>

<span># access a specific section's "time", in this case the C time function</span>
man 2 <span>time</span>

<span># attempt to access a nonexistent "time" in section 5</span>
man 5 <span>time</span>
</code></pre></div></div>

<p>Because the manpages were originally published on paper, they were (and continue to be) typeset with
<a href="https://en.wikipedia.org/wiki/Troff"><code>troff</code></a> on most systems. Today, the <code>man</code> command (and other
manpage readers) invoke <code>troff</code> internally and pipe the output to the user’s
<a href="https://en.wikipedia.org/wiki/Terminal_pager">pager</a> (like <code>more</code> or <code>less</code>).</p>

<p>In fact, a very simple manpage reader (which only works with section 1) can be implemented with
just three commands pipelined together:</p>

<div><div><pre><code><span>function </span>myman <span>{</span>
    <span># `-t` and `-e`: run `tbl` and `eqn` on the input, for tables and equations</span>
    <span># `-mandoc`: use a set of troff macros specifically for manpages</span>
    <span># `-Tutf8`: output UTF-8 text rather than PostScript</span>
    <span>gunzip</span> &lt; /usr/share/man/man1/<span>"</span><span>${</span><span>1</span><span>}</span><span>.1.gz"</span> | groff <span>-t</span> <span>-e</span> <span>-mandoc</span> <span>-Tutf8</span> | less
<span>}</span>

myman gcc
myman <span>ls</span>
</code></pre></div></div>

<p>Apart from their simplicity and adherence to the UNIX philosophy, <code>man</code> and the manpages serve a
number of important roles:</p>

<ul>
  <li>
    <p>They provide a categorization: section 1 is for system commands, 2 for system calls, 3 for library
functions, and so forth. This categorization is followed both by the system itself (which populates
several of the sections) and by programs installed by the user or package manager.</p>
  </li>
  <li>
    <p>They provide offline documentation: <code>man</code> doesn’t require an internet connection, and can provide
much of the documentation that an internet search would yield.</p>
  </li>
  <li>
    <p>They offer <em>canonical</em> information: searching for a command or function online might tell you
whether it exists, but won’t tell you the flags, arguments, or behavior specific to your system.
For example, <code>man ls</code> will tell you whether your system’s <code>ls</code> is BSD or GNU (and the differences
therebetween). The manpages (on Linux) will also tell you which feature macros you’ll need to define
in a C program in order to use a function (or a variant of a function).</p>
  </li>
</ul>

<p>So, let’s move on to some techniques.</p>

<h2 id="colorized-manpages">Colorized manpages</h2>

<p>One of the simplest things you can do to enhance the readability of manpages within <code>man</code> is to
colorize the pager’s output:</p>

<p><img src="https://blog.yossarian.net/assets/gcc_man.png" alt="A colorized version of `man gcc`"></p>

<p>In <code>less</code>, this is accomplished by setting the <code>LESS_TERMCAP_*</code> environment variables to your
preferred ANSI color codes. Here are the variables you can set:</p>

<div><div><pre><code>LESS_TERMCAP_mb <span># blinking mode (not common in manpages)</span>
LESS_TERMCAP_md <span># double-bright mode (used for boldface)</span>
LESS_TERMCAP_me <span># exit/reset all modes</span>
LESS_TERMCAP_so <span># enter standout mode (used by the less statusbar and search results)</span>
LESS_TERMCAP_se <span># exit standout mode</span>
LESS_TERMCAP_us <span># enter underline mode (used for underlined text)</span>
LESS_TERMCAP_ue <span># exit underline mode</span>
</code></pre></div></div>

<p>You may be able to set others corresponding to the
<a href="https://www.gnu.org/software/termutils/manual/termcap-1.3/html_chapter/termcap_5.html">termcap capability names</a>,
but the variables above should cover all of your manpage needs.</p>

<p>By way of example, here is the <code>bash</code> function I use to colorize my manpages:</p>

<div><div><pre><code>man<span>()</span> <span>{</span>
    <span>env</span> <span>\</span>
    <span>LESS_TERMCAP_mb</span><span>=</span><span>"</span><span>$(</span><span>printf</span> <span>"</span><span>\e</span><span>[1;31m"</span><span>)</span><span>"</span> <span>\</span>
    <span>LESS_TERMCAP_md</span><span>=</span><span>"</span><span>$(</span><span>printf</span> <span>"</span><span>\e</span><span>[1;31m"</span><span>)</span><span>"</span> <span>\</span>
    <span>LESS_TERMCAP_me</span><span>=</span><span>"</span><span>$(</span><span>printf</span> <span>"</span><span>\e</span><span>[0m"</span><span>)</span><span>"</span> <span>\</span>
    <span>LESS_TERMCAP_se</span><span>=</span><span>"</span><span>$(</span><span>printf</span> <span>"</span><span>\e</span><span>[0m"</span><span>)</span><span>"</span> <span>\</span>
    <span>LESS_TERMCAP_so</span><span>=</span><span>"</span><span>$(</span><span>printf</span> <span>"</span><span>\e</span><span>[1;44;33m"</span><span>)</span><span>"</span> <span>\</span>
    <span>LESS_TERMCAP_ue</span><span>=</span><span>"</span><span>$(</span><span>printf</span> <span>"</span><span>\e</span><span>[0m"</span><span>)</span><span>"</span> <span>\</span>
    <span>LESS_TERMCAP_us</span><span>=</span><span>"</span><span>$(</span><span>printf</span> <span>"</span><span>\e</span><span>[1;32m"</span><span>)</span><span>"</span> <span>\</span>
    man <span>"</span><span>${</span><span>@</span><span>}</span><span>"</span>
<span>}</span>
</code></pre></div></div>

<p>Note that you don’t need to use escape sequences as above — <code>tput</code> will work just fine.</p>

<h2 id="other-sections">Other sections</h2>

<p>I mentioned some of the big sections above: 1 for system commands, 2 for system calls, and so on.</p>

<p>90% of <code>man</code> lookups will be in those three, but there are a few lesser-known sections that can also
be useful:</p>

<ul>
  <li>
    <p><code>man 4</code> - Special files and devices</p>

    <p>On Linux, section 4 is used to document special files, usually representing some aspect of
  the machine or its peripherals. For example, <code>man 4 mem</code> will tell you how to use the
  <code>/dev/mem</code>, <code>/dev/kmem</code>, and <code>/dev/port</code> files to read from and write to the system’s main
  memory.</p>
  </li>
  <li>
    <p><code>man 5</code> - Configuration files and formats</p>

    <p>You probably know the <code>/etc/shadow</code> file, but do you know how its format is specified?
  <code>man 5 shadow</code> will tell you that. Similarly, <code>man 5 deb</code> describes the <code>.deb</code> package format,
  and <code>man 5 ppm</code> lists the spec for <a href="https://en.wikipedia.org/wiki/Netpbm_format">PPM images</a>.</p>
  </li>
  <li>
    <p><code>man Np</code> - POSIX pages</p>

    <p>These pages come in handy for contrasting POSIX behavior with the system’s behavior.</p>

    <p>Some examples:</p>

    <div><div><pre><code>  <span># compare the system ls (on Linux, GNU) to the POSIX ls behavior</span>
  man 1 <span>ls
  </span>man 1p <span>ls</span>

  <span># compare the read syscall to the POSIX read function</span>
  <span># note the categorization: POSIX read is a function, not a syscall!</span>
  man 2 <span>read
  </span>man 3p <span>read</span>
</code></pre></div>    </div>
  </li>
</ul>

<h2 id="searching-and-navigating">Searching and navigating</h2>

<p>Like colorization, searching is more of a general <code>less</code> feature than one specific to <code>man</code>. That
being said, <code>less</code>’s searching and navigating features can make browsing the manpages a much faster
and more pleasant experience.</p>

<p>Searches in <code>less</code> can be forwards or backwards, using the <code>/</code> and <code>?</code> commands respectively. The
search syntax is mostly POSIX ERE, but with some additions (<code>man less</code> has the details!).</p>

<p>For example, to find the first instance of “x86” in <code>man gcc</code> (watch the bottom of the screen for
the search prompt):</p>

<p><a href="https://asciinema.org/a/Wc0OiKVTrTDiP4tG9bPRWtDwM" target="_blank" rel="noopener noreferrer">
  <img src="https://blog.yossarian.net/assets/asc_Wc0OiKVTrTDiP4tG9bPRWtDwM.png">
</a></p>

<p>Observe that instances of the search term are highlighted with the standout colors from before.</p>

<p>Once a search term is entered, its results can be navigated via the <code>n</code> and <code>N</code> commands, which
move forwards and backwards in the results list respectively. For example, going through all
of the results for “Windows”:</p>

<p><a href="https://asciinema.org/a/n3S3wteHmbdPrtmyTSkCSVMiX" target="_blank" rel="noopener noreferrer">
  <img src="https://blog.yossarian.net/assets/asc_n3S3wteHmbdPrtmyTSkCSVMiX.png">
</a></p>

<p>When the last result has been jumped to, the statusbar changes to “Pattern not found”. Once that
happens, as in the video above, previous results can be returned to by hitting <code>N</code>.</p>

<p>Even this can be simplified: the <code>&amp;</code> command can be used to display only lines that match the given
pattern. For example, retrieving every line that contains either “ARM” or “ABI”:</p>

<p><a href="https://asciinema.org/a/Wh8QZ4eideLNmCMBmAkYExgEm" target="_blank" rel="noopener noreferrer">
  <img src="https://blog.yossarian.net/assets/asc_Wh8QZ4eideLNmCMBmAkYExgEm.png">
</a></p>

<p>The effect is more dramatic when searching for the definition of a flag (in this case <code>-D</code>):</p>

<p><a href="https://asciinema.org/a/17Kcnb8PBNIz8JdogOFKVeDQn" target="_blank" rel="noopener noreferrer">
  <img src="https://blog.yossarian.net/assets/asc_17Kcnb8PBNIz8JdogOFKVeDQn.png">
</a></p>

<p>These commands are just the tip of the iceberg — <code>less</code> supports searching multiple files at
once, jumping around scopes (opening and closing parentheses, braces, brackets), and marking the
current location for later return. Each of these is documented on the help screen, which you can
get to in any <code>less</code> session via the <code>h</code> command:</p>

<p><a href="https://asciinema.org/a/8i6kyFTbFttVTgDNbgnzyJvGB" target="_blank" rel="noopener noreferrer">
  <img src="https://blog.yossarian.net/assets/asc_8i6kyFTbFttVTgDNbgnzyJvGB.png">
</a></p>

<h2 id="wrapup">Wrapup</h2>

<p>Before picking up these tricks (especially searching), the manpages were an item of last resort
for me: I would search the internet or ask a friend, with mixed results. I had no real idea how to
use <code>less</code>, and would just clumsily page around until I found what I was looking for. More often
than not, I would give up entirely.</p>

<p>At the end of the day, the manpages (and the <code>man</code> interface) are not perfect — there’s no
hyperlinking or real cross-referencing, and the entire corpus is written in a 45+ year old
typesetting language designed for <em>physical</em> output, not display in a virtual terminal.</p>

<p>That being said, they’re a <em>fantastic</em> initial resource for pretty much anything concerning your
system — they remain up-to-date (unlike blogs and articles), they’re accurate and concise, and
they’re <em>very</em> UNIX-y (text files and pipelines!).</p>

<hr>

<h3 id="addendum">Addendum</h3>

<p>This post was discussed on <a href="https://news.ycombinator.com/item?id=25311867">HN</a>; a response
by <a href="https://news.ycombinator.com/item?id=25313405">‘djeiasbsbo</a> includes some additionally
useful tricks and advice.</p>


<hr>




  


  





</div>]]>
            </description>
            <link>https://blog.yossarian.net/2018/01/22/Reading-Manpages-Like-a-Pro</link>
            <guid isPermaLink="false">hacker-news-small-sites-25311867</guid>
            <pubDate>Sat, 05 Dec 2020 04:53:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Visualizing Poker Hands Geometrically]]>
            </title>
            <description>
<![CDATA[
Score 27 | Comments 7 (<a href="https://news.ycombinator.com/item?id=25311545">thread link</a>) | @chairmanwow1
<br/>
December 4, 2020 | https://evermontbills.com/blogs/prop-money-musings/a-new-way-to-look-at-poker-hands | <a href="https://web.archive.org/web/*/https://evermontbills.com/blogs/prop-money-musings/a-new-way-to-look-at-poker-hands">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article aria-labelledby="title-0">
  <div>
    <div>
      <div id="shopify-section-article-template">

<div>
  
<p>An interesting way for getting an intuitive sense for why <a href="https://en.wikipedia.org/wiki/Poker_probability" title="Poker hand probabilities">certain hands</a> are rare in poker, I've laid out all the cards in a standard deck in a grid:&nbsp;</p>
<p><img src="https://cdn.shopify.com/s/files/1/0502/8370/8606/files/blank_1024x1024.png?v=1607133617" alt="Array of Playing Cards" width="1024x1024" height="1024x1024">
</p>


<p>When I first learned to play poker, it took a while before I could get an intuitive understanding of the relationships between the various poker hands. Calculating their likelihood definitely helped get a handle on how many ways for a specific hand to actually occur there were.</p>

<p>Nonetheless, I think laying the hands out in a grid like this would have given me an intuitive understanding of the game much more quickly.&nbsp;</p>
<h2>Poker Hands shown geometrically</h2>
<p>So the lowest poker hand, high card, is the most common happening 50% of the time, but will rarely be the winning hand:</p>
<p><img src="https://cdn.shopify.com/s/files/1/0502/8370/8606/files/High_Card_1024x1024.png?v=1607134813" alt="High Card" width="1023" height="1023"></p>

<p>The next highest hand is a single pair which has a geometric interpretation of one column with two dots in it:&nbsp;</p>
<p><img src="https://cdn.shopify.com/s/files/1/0502/8370/8606/files/Pair_1024x1024.png?v=1607134853" alt="Pair" width="1024x1024" height="1024x1024"></p>

<p>Two pair has a similar flair to it, except this one has 2 vertical lines:</p>
<p><img src="https://cdn.shopify.com/s/files/1/0502/8370/8606/files/Two_Pair_1024x1024.png?v=1607134962" width="1024x1024" height="1024x1024"></p>

<p>Three of a kind is similar in spirit, but is much rarer than the two preceding hands happening once every 50 hands:&nbsp;</p>
<p><img src="https://cdn.shopify.com/s/files/1/0502/8370/8606/files/three_of_a_kind_1024x1024.png?v=1607135086" alt="3 of a kind" width="1024x1024" height="1024x1024"></p>

<p>For a straight, we need 5 cards that are in order without any gaps and can look kind of like a nice scatter plot:&nbsp;</p>
<p><img src="https://cdn.shopify.com/s/files/1/0502/8370/8606/files/straight_1024x1024.png?v=1607135179" alt="Straight" width="1024x1024" height="1024x1024"></p>

<p>A flush requires all 5 cards in the hand to be in a single horizontal row, but there can gaps between them:</p>
<p><img src="https://cdn.shopify.com/s/files/1/0502/8370/8606/files/flush_84512f1f-428d-4ed7-b703-9372fc3575d6_1024x1024.png?v=1607135233" alt="Flush" width="1024x1024" height="1024x1024"></p>

<p>A full house requires that all points be split into two lines of 3 and 2 points each:</p>

<p><img src="https://cdn.shopify.com/s/files/1/0502/8370/8606/files/full_house_1024x1024.png?v=1607135454" alt="Full House" width="1024x1024" height="1024x1024"></p>

<p>Four of a Kind requires a vertical line that spans the entire grid with an extra point tucked away somewhere:&nbsp;</p>
<p><img src="https://cdn.shopify.com/s/files/1/0502/8370/8606/files/4_of_a_kind_1024x1024.png?v=1607135655" alt="4 of a kind" width="1024x1024" height="1024x1024"></p>

<p>A straight flush is one of the tidiest hands as it requires all cards to be colinear on the same row and be immediately adjacent to each other:</p>
<p><img src="https://cdn.shopify.com/s/files/1/0502/8370/8606/files/straight_flush_1024x1024.png?v=1607135809" alt="Straight Flush" width="1024x1024" height="1024x1024"></p>

<p>The best hand that you can get is a subset of all the straight flushes that you can get. It's just a straight flush all the way against the right side of the grid with the 5 highest cards:&nbsp;</p>
<p><img src="https://cdn.shopify.com/s/files/1/0502/8370/8606/files/Royal_Flush_1024x1024.png?v=1607135877" alt="Royal Flush" width="1024x1024" height="1024x1024"></p>


<p>Looking at poker this way made me realize that there are some interesting hands that we could add to the game.&nbsp;</p>
<h2>Rectangle</h2>
<p>This hand is formed when you have 4 points that are <a href="https://mathworld.wolfram.com/Collinear.html" title="Mathematical Definition of colinearity">colinear</a> in both orthogonal axes (form a rectangle):&nbsp;</p>
<p><img src="https://cdn.shopify.com/s/files/1/0502/8370/8606/files/Rectangle_1024x1024.png?v=1607136065" alt="Rectangle Hand" width="1024x1024" height="1024x1024"></p>

<h2>Flower</h2>
<p>This one seems like it would be complicated to spot in the wild, but in reality it's a lot like a full house. You need a Three of a Kind and the other two cards need to be the same suit as one of your 3oK cards, and just before and after it. So, maybe it is a little complicated to spot, but it certainly is an interesting idea.&nbsp;</p>
<p><img src="https://cdn.shopify.com/s/files/1/0502/8370/8606/files/Screen_Shot_2020-12-04_at_18.42.56_1024x1024.png?v=1607136337" alt="Flower Hand" width="1024x1024" height="1024x1024"></p>

<h2>Want More?</h2>
<p>If you found this interesting, you'll probably love the 3D reconstruction we did of <a href="https://evermontbills.com/pages/walter-white-did-not-have-80m" title="Walter White's Cash Pile Counting">Walter White's cash pile</a> in order to count it.&nbsp;</p>
</div>


  <!-- /snippets/social-sharing.liquid -->







</div>
    </div>
  </div>
</article></div>]]>
            </description>
            <link>https://evermontbills.com/blogs/prop-money-musings/a-new-way-to-look-at-poker-hands</link>
            <guid isPermaLink="false">hacker-news-small-sites-25311545</guid>
            <pubDate>Sat, 05 Dec 2020 03:48:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Esperanto Technologies to Reveal Chip with 1000 Cores at RISC-V Summit]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25310931">thread link</a>) | @FullyFunctional
<br/>
December 4, 2020 | https://www.esperanto.ai/esperanto-technologies-to-reveal-chip-with-1000-cores-at-risc-v-summit/ | <a href="https://web.archive.org/web/*/https://www.esperanto.ai/esperanto-technologies-to-reveal-chip-with-1000-cores-at-risc-v-summit/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
		<a href="#content">Skip to content</a>

	<div id="boxed-wrapper">
		
		<div id="wrapper">
			
			
				
			<header>
				
				
			</header>
							
				
		
				
				
			
			

						<main id="main">
				<div>

<section id="content">
	
					<article id="post-2771">
										<span>Esperanto Technologies to Reveal Chip with 1000+ Cores at RISC-V Summit</span>
			
				
						<div>
				<div><div><div><div><div><span><img width="504" height="168" title="riscv summit" src="https://www.esperanto.ai/wp-content/uploads/2020/12/riscv-summit.jpg" srcset="https://www.esperanto.ai/wp-content/uploads/2020/12/riscv-summit-200x67.jpg 200w, https://www.esperanto.ai/wp-content/uploads/2020/12/riscv-summit-400x133.jpg 400w, https://www.esperanto.ai/wp-content/uploads/2020/12/riscv-summit.jpg 504w" sizes="(max-width: 1024px) 100vw, 504px"></span></div><div><h3><strong>Esperanto Technologies to Reveal Chip with 1000+ Cores </strong><strong>at RISC-V Summit</strong></h3>
<p><em>Art Swift, CEO of Esperanto Technologies, will present chip that accelerates Machine Learning based on RISC-V ISA</em></p>
<p><strong>MOUNTAIN VIEW, Calif., Dec. 1, 2020</strong> – <a href="https://www.esperanto.ai/">Esperanto Technologies</a>™, developer of high-performance, energy-efficient computing solutions based on RISC-V for Artificial Intelligence (AI), Machine Learning (ML) and Deep Learning (DL) applications, will participate in the <a href="https://tmt.knect365.com/risc-v-summit/">RISC-V Summit</a>, December 8-10, 2020. <a href="https://tmt.knect365.com/risc-v-summit/speakers/art-swift/">Art Swift, CEO of Esperanto</a>, will deliver the presentation: <a href="https://tmt.knect365.com/risc-v-summit/speakers/art-swift/#hardware-coressocs_esperanto-accelerates-machine-learning-with-risc-v">Esperanto Accelerates Machine Learning with 1000+ Low-Power RISC-V Cores on a Single Chip</a> on Tuesday, December 8.</p>
<ul>
<li><strong>What</strong>: <a href="https://tmt.knect365.com/risc-v-summit/">RISC-V Summit.</a></li>
<li><strong>Where</strong>: Virtual event, online.</li>
<li><strong>When</strong>: December 8, 2020.</li>
<li><strong>Agenda</strong>: <a href="https://tmt.knect365.com/risc-v-summit/agenda/1/">View the agenda here</a>.</li>
<li><strong>Register here</strong>: <a href="https://riscv.informatech.com/2020/registrations/Attendee">https://riscv.informatech.com/2020/registrations/Attendee</a></li>
</ul>
<p><strong>Presentation: </strong><strong>Esperanto Accelerates Machine Learning With 1000+ Low-Power RISC-V Cores on a Single Chip</strong></p>
<ul>
<li>Esperanto Technologies has developed a ground-breaking accelerator chip for large-scale machine learning applications employing over 1000 RISC-V cores.</li>
<li>In this talk, Esperanto provides an overview of the company’s new ET-SoC-1 chip, which features two kinds of general-purpose 64-bit RISC-V cores. The ET-Maxion, previewed at the RISC-V Summit in 2018, is a superscalar out-of-order core delivering high performance for modern operating systems and applications. The complementary ET-Minion core designed by Esperanto is a leaner, energy efficient, in-order multithreaded core with a vector/tensor accelerator unit at the heart of the massively parallel compute array.</li>
<li>The chip’s performance and efficiency is derived from a combination of factors, including the simplicity of the RISC-V instruction set, wide vector/tensor units on every ET-Minion core, a uniquely optimized memory hierarchy, state of the art process technology, and custom pipeline architecture and low-voltage circuits which enables more energy-efficient operation. The result is that Esperanto will deliver better performance per watt than legacy CPU and GPU solutions, as well as competing fixed-function designs without compromising generally purpose flexibility.</li>
</ul>
<p><strong>About Esperanto Technologies</strong></p>
<p>Esperanto Technologies develops high-performance, energy-efficient computing solutions for Artificial Intelligence / Machine Learning based on the open standard RISC-V instruction set architecture. Esperanto is headquartered in Mountain View, California with engineering sites in Portland, Oregon and Austin, Texas in the United States and multiple sites in Europe. Esperanto has brought together a seasoned team of experienced processor and software engineers with the goal of making RISC-V the architecture of choice for compute-intensive applications such as AI and Machine Learning. For more information, please visit <a href="https://www.esperanto.ai/">https://www.esperanto.ai/</a></p>
<p><strong>About the RISC-V Summit</strong></p>
<p>The third annual RISC-V Summit will highlight the continued rapid expansion of the RISC-V ecosystem, presenting both commercial offerings and exciting open-source developments. Newcomers to RISC-V, as well as the seasoned developers who are interested in broadening their toolsets, are invited to choose from the broad range of tutorials. The comprehensive 100% virtual event will feature keynotes from industry pioneers as well as thought-provoking panel discussions. Network with thought-leaders, technology companies, and researchers spearheading the adoption of this evolutionary change in the silicon market.</p>
<p><em>All trademarks or registered trademarks are the property of Esperanto Technologies or their respective holders.</em></p>
</div></div></div></div></div>
							</div>

												<span><span><a href="https://www.esperanto.ai/author/hstump/" title="Posts by Holly Stump" rel="author">Holly Stump</a></span></span><span>2020-12-01T08:33:52-08:00</span>													
													<section>
				
			
	
	
	
	
				<!-- fusion-carousel -->
</section><!-- related-posts -->


																	</article>
	</section>
						
					</div>  <!-- fusion-row -->
				</main>  <!-- #main -->
				
				
								
					
		 <!-- fusion-footer -->

		
					

												</div> <!-- wrapper -->
		</div> <!-- #boxed-wrapper -->
		
		
		
		<a></a>

		

			
		


</div>]]>
            </description>
            <link>https://www.esperanto.ai/esperanto-technologies-to-reveal-chip-with-1000-cores-at-risc-v-summit/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25310931</guid>
            <pubDate>Sat, 05 Dec 2020 02:03:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How Microsoft crushed Slack]]>
            </title>
            <description>
<![CDATA[
Score 11 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25310547">thread link</a>) | @theBashShell
<br/>
December 4, 2020 | https://www.platformer.news/p/how-microsoft-crushed-slack | <a href="https://web.archive.org/web/*/https://www.platformer.news/p/how-microsoft-crushed-slack">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><figure><a target="_blank" href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fc7608632-a221-494e-8d80-66d16ad2a539_4608x3456.jpeg"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fc7608632-a221-494e-8d80-66d16ad2a539_4608x3456.jpeg" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/c7608632-a221-494e-8d80-66d16ad2a539_4608x3456.jpeg&quot;,&quot;height&quot;:1092,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:1771463,&quot;alt&quot;:&quot;Image of Slack running on a laptop. Muhammed Abiodun / Unsplash&quot;,&quot;title&quot;:null,&quot;type&quot;:&quot;image/jpeg&quot;,&quot;href&quot;:null}" alt="Image of Slack running on a laptop. Muhammed Abiodun / Unsplash"></a><figcaption>(Muhammed Abiodun / Unsplash)</figcaption></figure></div><p>Slack’s life as an underdog darling of Silicon Valley ended on November 2, 2016. That’s when the upstart communication startup <a href="https://www.theverge.com/2016/11/2/13497766/slack-microsoft-teams-new-york-times-ad">published an open letter to Microsoft in the </a><em><a href="https://www.theverge.com/2016/11/2/13497766/slack-microsoft-teams-new-york-times-ad">New York Times</a></em>, offering the tech giant an insincere “welcome” to the world of workplace chat software. The occasion was <a href="https://www.theverge.com/2016/10/25/13405200/microsoft-teams-slack-competitor-launch">Microsoft’s launch of Teams</a>, a Slack clone that would come bundled with the company’s popular Office 365 suite of products.</p><p>In its letter, Slack warned Microsoft that “Slack is here to stay,” adding: “we’re just getting started.” But the 4 million users it had at the time would increase to just 12 million four years later, while Microsoft — which added Teams to its 365 bundle without increasing the price — <a href="https://www.theverge.com/2020/10/27/21537286/microsoft-teams-115-million-daily-active-users-stats">took Teams from zero to 115 million users</a>. </p><p>That disparity helps to explain why <a href="https://www.nytimes.com/2020/12/01/technology/salesforce-slack-deal.html">Slack sold itself this week to Salesforce</a>. The deal, which values Slack at $27.7 billion on revenues of $833 million over the past year, has largely been greeted with cheers. (Ben Thompson <a href="https://stratechery.com/2020/salesforce-acquires-slack-salesforces-reasoning-salesforces-opportunity/">offers a typically excellent rundown of the opportunity here for both Salesforce and Slack</a>.)</p><p>But it also feels like the end of an era — one where workers gained new power to bring their own tools to the office, and decide for themselves how they wanted to get work done. Slack first succeeded with small teams who wanted to accelerate their work, and was often dragged into organizations by early adopters. But today, waves of consolidation are leaving people with fewer real choices.</p><p>The rise of smart phones in the early 2010s brought with it a new surge of workplace productivity tools that made mincemeat of everything that had come before them. Box and Dropbox brought easy file storage and sharing. Evernote introduced the idea of ubiquitous, cloud-synchronized note-taking. Sunrise created a more social calendar, while Mailbox and Acompli reimagined email for the mobile phone.</p><p>Slack tiptoed into the conversation in the middle of the decade, and almost immediately became the fastest-growing enterprise software tool of all time. In 2015, just 18 months after it launched, <a href="https://www.theverge.com/2015/6/24/8836087/slack-1-million-daily-users">Slack reported having more than 1 million daily users</a> —&nbsp;a figure then unheard-of in enterprise software.</p><p>It had a great backstory —&nbsp;a last-ditch pivot from a failed video game called Glitch —&nbsp;and, in Stewart Butterfield, one of the tech world’s most charming founders. It also had a bold pitch: it was going to “kill email” —&nbsp;or, at the very least, reduce your reliance on it. And it would do so by integrating hundreds of other services into real-time work chat, creating a kind of all-knowing command console for your organization.</p><p>The company embodied the belief, so common in Silicon Valley, that the best product would win in the end. “Building a product that allows for significant improvements in how people communicate requires a degree of thoughtfulness and craftsmanship that is not common in the development of enterprise software,” the company wrote in its open letter to Microsoft. “How far you go in helping companies truly transform to take advantage of this shift in working is even more important than the individual software features you are duplicating.”</p><p>And yet if there’s a lesson of the past four years, it’s that thoughtfulness and craftsmanship only got the company about 10 percent as far as Microsoft did by copy-pasting Slack’s basic design. In its open letter, Slack famously told Microsoft: “You’ve got to do this with love.” In 2020, looking at Slack’s size, the idea seems laughable. What’s love got to do with it?</p><p>The thing is, I <em>hate</em> that this was the outcome for Slack. I love good productivity tools, and was rooting for Slack to someday become as good as the company hyped it up to be. (And perhaps it still will: like most giants Salesforce has a mixed track record when it comes to the success of its acquisitions, but some seem to be thriving. When I asked about this on Twitter, people had <a href="https://twitter.com/caseynewton/status/1333891286185644032?s=21">a lot of good things to say about post-acquisition Heroku</a>.)</p><p>But Slack’s struggle to succeed as an independent company sadly mirrors that of many one-time innovators in enterprise productivity. Mailbox died and Acompli sold to Microsoft, where it became the mobile Outlook app. Evernote is a pale shadow of its former self. Of that early cohort, only Box and Dropbox became — and still remain —&nbsp;public companies.</p><p>Why is this the case? To get some insight, I called up Aaron Levie, Box’s affable CEO. In Levie’s telling —&nbsp;and he also wrote <a href="https://blog.box.com/salesforce-slack-and-future-work">a blog post about the Slack sale</a> — it all comes down to sales. The idea that workers would someday choose all their own tools was always a fantasy, he told me, in part because most workers don’t event want to think about their tools. In such a world, the winning app will almost always be one with a giant, er, salesforce behind it. </p><p>Microsoft had one. Slack didn’t. Enter Salesforce.</p><p>“The reality with the enterprise is that you can have the best product, but that’s not good enough,” Levie told me. “You need distribution. And what Salesforce has — they have the procurement officers, they have the finance people. They have all of the apparatus you need to interact with to sell software, and they have it for the top 100,000 corporations around the world.”</p><p>Levie is bullish on the acquisition, because it puts Slack and Salesforce on more even ground. </p><p>“The only advantage Microsoft has is distribution, and so now they’ve neutralized the advantage that Microsoft has had,” he said. “All of a sudden, they can actually fulfill the ultimate promise of the opportunity, because they have 10 times the amount of salespeople that can go distribute this thing into corporations around the world.”</p><p>Assuming Levie is right — and I wouldn’t bet against him — that means the medium-term future of work is increasingly a choice between three giants: Microsoft, Salesforce, and (in a distant third) Google. And with that, the golden age of worker choice in productivity tools seems to be coming to an end.</p><p>That’s not to say that the incumbents won’t always face new challengers. But I wonder whether the low ceiling that Slack turned out to have has implications for some of the other fast-growing productivity companies of the current moment. Should Slack’s sale diminish our expectations for Airtable, or Notion, or Coda? Don’t get me wrong — I’m confident their investors will all get their money back, and then some. But do they have a real future outside the arms of a monolith?</p><p>If not, then the productivity market will become as consolidated as any number of other spaces on the internet, from app stores to search engines to social networks. And as our government antitrust regulators begin to awaken after a long period of hibernation, I wonder if they’ll have anything to say about it.</p><h3>The Ratio</h3><p><em>Today in news that could affect public perception of the big tech companies</em></p><p>⬆️ <strong>Trending up</strong>: <strong><a href="https://techcrunch.com/2020/12/02/google-news-showcase-paywalled-stories/">Google</a></strong><a href="https://techcrunch.com/2020/12/02/google-news-showcase-paywalled-stories/">’s new paid deals with publishers mean that access to some paywalled content will now be available to readers for free</a>. Good for publishers, good for Google, good for democracy. (Anthony Ha / <em>TechCrunch</em>)</p><p>🔃 <strong>Trending sideways: <a href="https://www.geekwire.com/2020/microsoft-will-remove-user-names-productivity-score-feature-privacy-backlash/">Microsoft </a></strong><a href="https://www.geekwire.com/2020/microsoft-will-remove-user-names-productivity-score-feature-privacy-backlash/">made changes to the “productivity score” feature in its 365 platform, which gave employers fine-grained data on individual employees’ use of email, chat, and other features</a>. Critics called it “full-fledged workplace surveillance tool;” Microsoft says it will now detach the data from individual employee names.  (Todd Bishop / <em>GeekWire</em>) </p><p>🔃 <strong>Trending sideways:</strong> <strong><a href="https://www.theinformation.com/articles/amazon-drops-pandemic-test-to-track-warehouse-workers-through-wi-fi?utm_source=twitter&amp;utm_medium=page">Amazon </a></strong><a href="https://www.theinformation.com/articles/amazon-drops-pandemic-test-to-track-warehouse-workers-through-wi-fi?utm_source=twitter&amp;utm_medium=page">abandoned a test of a worker safety measure that involved tracking the location of warehouse workers through their personal cell phones</a>. Big week for pushback on worker surveillance initiatives! (Mark Di Stefano / <em>The Information</em>)</p><p>⬇️ <strong>Trending down</strong>: <strong><a href="https://www.theverge.com/2020/12/2/22047383/google-spied-workers-before-firing-labor-complaint">Google</a></strong><a href="https://www.theverge.com/2020/12/2/22047383/google-spied-workers-before-firing-labor-complaint"> illegally spied on workers before firing them, according to a new lawsuit by the National Labor Relations Board</a>. Two employees were fired for looking at their colleagues’ calendars as part of an organizing effort. Google says it didn’t do anything wrong. (Zoe Schiffer / <em>The Verge</em>)</p><h3>Governing</h3><p>⭐ <strong><a href="https://www.washingtonpost.com/technology/2020/12/01/trump-repeal-section-230-ndaa/">In a pair of late-night tweets, President Trump</a></strong><a href="https://www.washingtonpost.com/technology/2020/12/01/trump-repeal-section-230-ndaa/"> threatened to veto the defense reauthorization act if Congress does not repeal Section 230 of the Communications Decency Act</a>. But it’s <a href="https://www.protocol.com/Politics/trumps-section-230-veto-threat">not clear he has the leverage to make it happen</a>. (Tony Romm /  <em>Washington Post</em>)</p><p><a href="https://www.washingtonpost.com/politics/2020/12/02/technology-202-aclu-sues-dhs-over-purchase-cellphone-location-data-used-track-immigrants/">The ACLU sued the Department of Homeland Security over its purchase of cellphone location data to track immigrants</a>. Separately, the department’s inspector general said he would investigate the matter after Senate Democrats began asking questions. (Cat Zakrzewski / <em>Washington Post</em>)</p><p><a href="https://techcrunch.com/2020/12/01/massachusetts-votes-to-pass-statewide-police-ban-on-facial-recognition/">Massachusetts passed a statewide ban on the use of facial recognition technology by police</a>. It may be the largest US ban of facial recognition tech yet, and is part of a growing patchwork of laws regulating it around the country. (Taylor Hatmaker and Zack Whittaker / <em>TechCrunch</em>)</p><p><strong><a href="https://www.bloomberg.com/news/articles/2020-11-30/everyaction-and-mobilize-give-democrats-the-app-they-need-to-keep-winning?sref=ExbtjcSG">EveryAction</a></strong><a href="https://www.bloomberg.com/news/articles/2020-11-30/everyaction-and-mobilize-give-democrats-the-app-they-need-to-keep-winning?sref=ExbtjcSG">, a </a><strong><a href="https://www.bloomberg.com/news/articles/2020-11-30/everyaction-and-mobilize-give-democrats-the-app-they-need-to-keep-winning?sref=ExbtjcSG">Salesforce</a></strong><a href="https://www.bloomberg.com/news/articles/2020-11-30/everyaction-and-mobilize-give-democrats-the-app-they-need-to-keep-winning?sref=ExbtjcSG">-like platform for liberal campaigns and causes, acquired the organizing company </a><strong><a href="https://www.bloomberg.com/news/articles/2020-11-30/everyaction-and-mobilize-give-democrats-the-app-they-need-to-keep-winning?sref=ExbtjcSG">Mobilize</a></strong>. The move bolsters what Bloomberg calls “the central nervous system for practically all of Democratic politics.” (Joshua Green / Bloomberg)</p><p><a href="https://www.smh.com.au/world/asia/very-serious-situation-frydenberg-s-economic-warning-over-china-dispute-20201202-p56jzp.html">Amid rising tensions between China and Australia, </a><strong><a href="https://www.smh.com.au/world/asia/very-serious-situation-frydenberg-s-economic-warning-over-china-dispute-20201202-p56jzp.html">WeChat</a></strong><a href="https://www.smh.com.au/world/asia/very-serious-situation-frydenberg-s-economic-warning-over-china-dispute-20201202-p56jzp.html"> deleted the Australian prime minister’s response to a fabricated image sent by a Chinese foreign affairs official</a>. <strong>Twitter</strong> left the post up. (Eryk Bagshaw, Anthony Galloway and Shane Wright / <em>Sydney Morning Herald</em>)*</p><p>* <em>The description of this item has been corrected from an earlier, incorrect characterization</em>.</p><h3>Industry</h3><p>⭐ <strong><a href="https://www.washingtonpost.com/video-games/2020/12/01/facebook-reality-tv-game-rival-peak/">Facebook</a></strong><a href="https://www.washingtonpost.com/video-games/2020/12/01/facebook-reality-tv-game-rival-peak/"> teamed up with former employees of popular game developer </a><strong><a href="https://www.washingtonpost.com/video-games/2020/12/01/facebook-reality-tv-game-rival-peak/">Telltale</a></strong><a href="https://www.washingtonpost.com/video-games/2020/12/01/facebook-reality-tv-game-rival-peak/"> for </a><em><a href="https://www.washingtonpost.com/video-games/2020/12/01/facebook-reality-tv-game-rival-peak/">Rival Peak</a></em><a href="https://www.washingtonpost.com/video-games/2020/12/01/facebook-reality-tv-game-rival-peak/">, a new reality show where viewers will influence the story</a>. It feels … maybe a little too high-concept? We’ll see. Gene Park had the details at the <em>Washington Post</em>:</p><blockquote><p><em>Rival Peak</em> is a Facebook Watch program in which artificial intelligence-driven “contestants” will live, work and exist for every minute of the day within the fictional region of Rival Peak, a mountainous forest region that emulates the Pacific Northwest. With a diverse cast of internationally-based characters, …</p></blockquote></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.platformer.news/p/how-microsoft-crushed-slack">https://www.platformer.news/p/how-microsoft-crushed-slack</a></em></p>]]>
            </description>
            <link>https://www.platformer.news/p/how-microsoft-crushed-slack</link>
            <guid isPermaLink="false">hacker-news-small-sites-25310547</guid>
            <pubDate>Sat, 05 Dec 2020 01:03:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[No One Ever Got Fired for Choosing React]]>
            </title>
            <description>
<![CDATA[
Score 62 | Comments 90 (<a href="https://news.ycombinator.com/item?id=25310462">thread link</a>) | @petercooper
<br/>
December 4, 2020 | https://jake.nyc/words/no-one-ever-got-fired-for-choosing-react/ | <a href="https://web.archive.org/web/*/https://jake.nyc/words/no-one-ever-got-fired-for-choosing-react/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>If you spend a lot of time on Hacker News, it’s easy to get taken by the allure of building a web app without a framework. There are a bunch of potential advantages (no bloat! bespoke to your project!) and being able to say you built something with minimal dependencies gets you Engineer Points.</p>
<p>That is, if you can pull it off.</p>
<p>I started a new side project recently. It’s a web-based graphics editor, so it needs to be a single page app. My time spent profiling <a href="https://songrender.com/">SongRender</a> for performance issues has made me a little wary of React for building interfaces that update at 60 frames per second, so I decided to avoid it. I’d go (mostly) vanilla and see how far that took me.</p>
<p>I installed <a href="https://lit-html.polymer-project.org/">lit-html</a> and got to work. “Components” were simply functions that returned lit-html template results. A big singleton at the top of the tree held onto all the application state, stored as a global variable within that module.</p>
<p>The first hurdle came when a component needed local state. I could have lifted it to the singleton, but that would have broken the component’s encapsulation. I noticed that lit-html directives can keep state, so I decided to use them to build a tiny component library — ignoring a warning from the lit-html developers that this wasn’t a supported use case.</p>
<p>My home-brewed library worked great… until I needed to run some code when a component appeared on the screen. I started digging through lit-html documentation and issues looking for a way to detect a directive’s lifecycle, but it became clear to me that going down that path would be painful.</p>
<p>At that point, I recalled <a href="https://tomdale.net/2015/11/javascript-frameworks-and-mobile-performance/">this quote by Tom Dale</a>:</p>
<blockquote>
<p>I have heard from many developers who have told me that they accepted the argument that vanilla JavaScript or microlibraries would let them write leaner, meaner, faster apps. After a year or two, however, what they found themselves with was a slower, bigger, less documented and unmaintained in-house framework with no community. As apps grow, you tend to need the abstractions that a framework offers. Either you or the community write the code.</p>
</blockquote>
<p>Fair enough. Let’s avoid that trap. What about a small framework? I’d heard a lot of good things about Svelte, and although I was slightly worried about the size of the Svelte community I figured it would be fine.</p>
<p>My migration attempt quickly ground to a halt when I wanted a parent component to apply some styles to a child component. In React, I’d pass a class name in from the parent as a <code>className</code> prop. In Svelte, that’s considered a workaround, and the actual feature is the subject of an <a href="https://github.com/sveltejs/rfcs/blob/master/text/0000-style-properties.md">RFC</a>.<sup id="fnref:1"><a href="#fn:1" role="doc-noteref">1</a></sup></p>
<p>Maybe this is an example of <a href="https://prog21.dadgum.com/160.html">dangling by a trivial feature</a>. But it’s so basic a capability that I’m surprised Svelte is on version three without an officially blessed way to do it. I ran into this limitation when I created my <strong>second component</strong>. Way before I got to try out any of the cool reactivity that earns Svelte all that buzz.</p>
<p>So I changed my mind and went with React. After an hour or so, I’d finished moving everything over — and my anxiety had vanished. I stopped worrying about having most efficient component system, and picked up work on the thing I wanted to build in the first place.</p>
<p>No, React isn’t perfect. It’s optimized for apps that make network requests and then display lists of things (i.e. most apps) which isn’t really what I’m doing here<sup id="fnref:2"><a href="#fn:2" role="doc-noteref">2</a></sup>. The performance is fine now, although I expect I’ll have to optimize as my project gets more complex.</p>
<p>But React lets me stop thinking about the framework. React gets out of my way. React is <a href="https://mcfunley.com/choose-boring-technology">boring</a>. React is actively developed. React has a giant ecosystem and a giant community. React is battle-tested on some of the most visited websites in the world.</p>
<p>I’m sure there are technically better ways to build a highly interactive interface on the web, but life is too short for me to spend hours trying to figure them out. There are things I want to create, and the only way I can actually create them is to stop spending so much time on tooling.</p>
<p>For now, I’m choosing React.</p>
<section role="doc-endnotes">
<hr>
<ol>
<li id="fn:1" role="doc-endnote">
<p>The solution they seem to have landed on — letting the child expose CSS custom properties as props — is actually pretty cool, though I don’t like that Svelte will silently wrap your component with an extra <code>div</code>. <a href="#fnref:1" role="doc-backlink">↩︎</a></p>
</li>
<li id="fn:2" role="doc-endnote">
<p>Although Dan, if you read this, the <a href="https://twitter.com/dan_abramov/status/1133341485133438982">“animation pass” mode</a> you’ve mentioned offhandedly sounds very relevant! <a href="#fnref:2" role="doc-backlink">↩︎</a></p>
</li>
</ol>
</section></div></div>]]>
            </description>
            <link>https://jake.nyc/words/no-one-ever-got-fired-for-choosing-react/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25310462</guid>
            <pubDate>Sat, 05 Dec 2020 00:52:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I accidentally built a spying app]]>
            </title>
            <description>
<![CDATA[
Score 174 | Comments 59 (<a href="https://news.ycombinator.com/item?id=25310316">thread link</a>) | @akeck
<br/>
December 4, 2020 | https://withblue.ink/2020/09/24/that-time-i-accidentally-built-a-spying-app.html | <a href="https://web.archive.org/web/*/https://withblue.ink/2020/09/24/that-time-i-accidentally-built-a-spying-app.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><p>In the fall of 2007, my parents gave me an unforgettable gift for my sixteenth birthday: a first-generation iPhone.</p><p>I still clearly remember watching the keynote in which Steve Jobs announced the first Apple-branded phone a few months earlier. As a teenager attending high school in my hometown of Vicenza, Italy, I tuned into the livestream just before dinner, carefully listening to every word he said. That evening, Jobs started announcing a “widescreen iPod with touch controls”, a “revolutionary mobile phone” and a “breakthrough Internet communications device”–theatrically pausing before confessing that he was actually talking about one single device: the iPhone. Thousands of miles away from me, you could hear attendees exploding cheerfully through the live feed. Jobs went on demoing this amazing invention that, a decade later, would end up changing much more than the mobile phones market: it directly or indirectly impacted our society through mobile web, app stores, changing work-life balance, and social media.</p><p>October came, and so did the day I finally got my iPhone. I was really excited as I was the first one in my social circle with one. Every other teenager (and adult!) that saw my phone reacted in awe and with lots of curiosity. More than a few were also secretly envious, something I secretly did not mind. To add to the novelty, at the time the iPhone was only available for sale in the US.</p><p>To get an iPhone for me, my father had to ask a friend traveling to New York on a business trip to bring one back on the plane with her. That was not the end of it, however, as all phones were locked to the AT&amp;T network. In order for me to be able to use my iPhone in Italy, I had to unlock it.</p><p>That process required learning a variety of tools and techniques developed by hackers in the community, then documented in various blogs and forums. The first step was to <em>jailbreak</em> the phone, which gave you full access to the system and allowed you to run third-party apps. Then you’d have add one of those “hacking” apps to your phone, which patched the bootloader to remove the lock the US carrier had put on it. Despite sounding like a mouthful, the iPhone hacking community had worked hard on the User Experience (UX), making this entire process relatively easy for most people with basic tech skills.</p><hr><p>I really loved my shiny, new iPhone, and I was so excited about it that I was willing to accept many of its original limitations. It only supported slow 2G networks, didn’t have copy/paste, couldn’t transfer files via Bluetooth to my friends, and <a href="https://www.apple.com/hotnews/thoughts-on-flash/">famously</a> didn’t support Adobe Flash, which was ubiquitous on the web at the time.</p><p>However, there was one thing I really couldn’t stand: the Messages application could only store 1,000 texts (SMS).</p><p>That was 2007 — before the days of WhatsApp, Facebook Messenger, Telegram, etc. Instant messaging was something people did on their PCs only, with things like Windows Live Messenger (née MSN Messenger) or AIM.</p><p>For a high schooler like me, text messaging was the main way I kept in touch with my friends daily (<em>what was I supposed to do, call them?</em>). With my carrier giving me a whopping 100 free texts per day (seriously, we had to pay for them), between sent and received texts it would take less than a week to reach the storage limit of 1,000.</p><p>That’s when it all started.</p><p>Because my iPhone was already “hacked” (jailbroken), as a requirement for unlocking it and use it in Italy, I had full system access already. That allowed me to c extract any document I wanted, including my phone’s text message database.</p><p>It wasn’t even a month since I got my iPhone that I had already built a small “app” running on my laptop to archive my text messages forever. I would manually extract the SMS database from my iPhone, copy it to my laptop, then use a set of scripts written in PHP (the only programming language I knew at the time) to store the messages in a local database, and finally display them using a web-based interface.</p><p>This thing I put together worked just fine for me, but I immediately realized the “business potential” of what I had just created. Just like myself, I assumed many others had the same annoyance. I could have used what I learned to help them too, and maybe make some pocket change in the process. As a matter of fact, I did consider myself an enterprising teenager.</p><p>The idea had potential, and the “app” I built for myself already provided solid foundations, so I just needed to do a bit more work to turn it into a commercially-viable project.</p><p>The biggest challenge was making the solution more accessible to others, including those who were not particularly tech-savvy. That’s when I started learning about app development for iPhone.</p><p>Famously, Apple did not want the iPhone to support third-party apps at the beginning, saying developers should build web apps instead. That policy didn’t last long, and with the iPhone OS 2 update, launched in mid-2008, the official App Store came to life: the rest, as they say, is history.</p><p>However, the hacking community had already found a way to sideload apps and had even developed an “app store” called Cydia where you could find games, apps, and even mods to enhance the capabilities of the operating system itself. Cydia came preinstalled on every <em>jailbroken</em> iPhone, which meant potentially hundreds of thousands of people had access to it.</p><p>Everyone could build apps that would be published on Cydia, as long as you knew how to–something that was not remotely as easy to do as it is with today’s tools. As an enterprising teenager with quite a bit of free time on my hand during those winter afternoons and evenings, I took on that challenge.</p><hr><p>The first version of YouArchive.It came out in January 2008.</p><p>Today, you would describe YouArchive.It as a cloud service to store iPhone text messages. You could store all your messages in there, then read and search them using a web-based application.</p><p>There’s still a video left on YouTube showing the application in action (this was the third, and last, version):</p><p><iframe src="https://www.youtube-nocookie.com/embed/ps5ohEhO3S4" allowfullscreen="" title="YouTube Video"></iframe></p><p>With YouArchive.It came an iPhone application too. Published on the Cydia app store, it allowed importing messages into the “cloud service” directly from the phone.</p><p>YouArchive.It was free to use with a limit of 80,000 text messages. Because personal communications can be sensitive, all messages were stored encrypted. With a one-time payment of just €5 (about $6), you could become a VIP, remove any limit and enjoy unlimited storage.</p><p><img src="https://cdn-images-1.medium.com/max/2000/1*vTxYRljXFl3IBXGRsXOVag.png" alt="A screenshot of iTextUploader running on a first-generation iPhone"></p><figcaption>A screenshot of iTextUploader running on a first-generation iPhone</figcaption><p>For the next year and a half, YouArchive.It continued to grow organically. A few blogs and websites dedicated to iPhone “hacking” and to the underground app stores wrote about the app. Even a small radio program in the US featured it</p><p>I continued developing the app as a side project while in high school. I was also providing tech support and maintaining the infrastructure.</p><p>Listening to users' feedback, I would periodically add new features. YouArchive.It started displaying emojis as soon as the iPhone supported that (outside of Japan, it required downloading an app to enable them). Users asked for and got the ability to restore texts in another iPhone, before iCloud was available. I also implemented other privacy features such as requiring a password to open the mobile app.</p><blockquote><h3 id="what-i-didnt-realize-at-the-time-however-is-that-i-had-unknowingly-and-unwillingly-built-a-spying-tool-and-a-really-convenient-and-efficient-one">What I didn’t realize at the time, however, is that I had, unknowingly and unwillingly, built a spying tool, and a really convenient and efficient one.</h3></blockquote><p>Enough users were paying the fee to become VIP that I could cover the costs of running the service–this was before everyone was using Amazon Web Services or Microsoft Azure, so I was renting a co-located physical server which wasn’t cheap–and keep some pocket cash. Not much, but enough to pay for some hobbies and outings with friends.</p><p>Most importantly, building YouArchive.It gave me a lot of satisfaction and the opportunity to learn a lot of things about software development, business, dealing with customers and listening to their feedback.</p><hr><p>When I finally shut the service down, in June 2010, YouArchive.It had about 32,000 registered users who stored over 76 million messages.</p><p>The first, and stated, reason for the deprecation was a technical one: YouArchive.It’s iPhone app required using private APIs, which meant it could not be published on the App Store (and it still couldn’t to this day), limiting it to <em>jailbroken</em> phones only.</p><p>The second reason however was the most important to me, even though I have not revealed it until now.</p><p>About a year before the app closed, in April 2009 I implemented a new feature that was requested by many users: the ability to upload texts automatically, in background, without user intervention. For paying “VIP” users only, the mobile app could automatically send all new text messages to YouArchive.It, as often as every 15 minutes.</p><p>Automatic upload was an incredible convenience for many users that wanted to hoard their texts like me, to keep them forever, search within them, print or export them, or just liked having a backup.</p><p>What I didn’t realize at the time, however, is that I had, unknowingly and unwillingly, built a spying tool, and a really convenient and efficient one.</p><p>Thanks to background uploads, people could install the YouArchive.It app on another person’s iPhone, set it up, maybe even hide it (something possible on a <em>jailbroken</em> iPhone), and then watch as the text messages come in, almost real-time. Jealous partners, stalkers and the likes could install this tool on an unknowing victim’s phone with relative ease.</p><p>I can’t remember how I discovered that — it might have been a support request from a user or a post in a bulletin board. I also can’t know how many people were using YouArchive.It for their own archiving rather than to spy on others. Realizing what my users were doing, however, made me feel really uncomfortable and I did not want any part of that anymore.</p><p>As a senior in high school, barely eighteen years-old, I realized for the first time how technology can have a …</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://withblue.ink/2020/09/24/that-time-i-accidentally-built-a-spying-app.html">https://withblue.ink/2020/09/24/that-time-i-accidentally-built-a-spying-app.html</a></em></p>]]>
            </description>
            <link>https://withblue.ink/2020/09/24/that-time-i-accidentally-built-a-spying-app.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25310316</guid>
            <pubDate>Sat, 05 Dec 2020 00:32:22 GMT</pubDate>
        </item>
    </channel>
</rss>
