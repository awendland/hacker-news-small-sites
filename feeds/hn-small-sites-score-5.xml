<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 5]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 5. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Fri, 11 Sep 2020 20:24:03 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-5.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Fri, 11 Sep 2020 20:24:03 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[Annoying website features I face as a blind person]]>
            </title>
            <description>
<![CDATA[
Score 220 | Comments 123 (<a href="https://news.ycombinator.com/item?id=24429012">thread link</a>) | @Garbage
<br/>
September 9, 2020 | https://bighack.org/5-most-annoying-website-features-i-face-as-a-blind-screen-reader-user-accessibility/ | <a href="https://web.archive.org/web/*/https://bighack.org/5-most-annoying-website-features-i-face-as-a-blind-screen-reader-user-accessibility/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p><span>These are the five most annoying inaccessible web elements I face as a blind screen reader user every day, and how to fix them.
</span>
					</p><div>
						<p><span>For blind and visually impaired people like me, accessibility is the difference between us being able to use a website and clicking off it.&nbsp;</span></p>
<h2>How screen readers work</h2>
<p><span>Screen readers allow blind and visually impaired people to use computers, phones and tablets independently. Most screen readers use software, and a Text To Speech (TTS) engine, which is what converts the text from the screen reader into speech. Screen readers convert the text displayed on screen into a format that blind users can process.</span></p>
<p><span>Screen readers read out loud everything that’s on the screen and allow people to navigate using touch gestures and shortcut keys. They also work with other output devices such as a braille display.</span></p>
<p><span>As a screen reader user, here are the most common issues I encounter on a daily basis.&nbsp;</span></p>
<h2>Unlabelled links and buttons</h2>
<p><span>Screen reader users rely on links and buttons to navigate around a website and to find the information we need. If links and buttons are not labelled correctly or if at all, then it makes it difficult for screen reader users to find the information they need. Ultimately, unlabelled links make it much harder to navigate the website easily, quickly and independently.</span></p>
<p><span>For example, when linking to an about page, ‘click here’ doesn’t give any clue as to where it leads to, but ‘find out more about who we are’ is clear.</span></p>
<p><span>If links and buttons are labelled correctly, screen readers can read the label out loud. It means that blind and visually impaired people don’t have to press the link or button without knowing where it will take them.</span></p>
<p><span>As well as unlabelled elements, links and buttons that do not have a clear description are also really frustrating. They must have a clear description of where they will lead to when pressed, rather than ‘click here’. Never make your users guess where a link will take them or force them into a trial-and-error situation. This makes for tedious user experience.</span></p>
<h2>No image descriptions</h2>
<p><span>This is probably the most common issue I encounter when browsing the web.&nbsp;</span><span>Using image descriptions is essential for accessibility. Image descriptions are also known as alt text (alternative text) which is a written description of an image.</span></p>
<p><span>Screen readers read image descriptions out loud. This means that blind and visually impaired people can understand the content of the image in an accessible way.&nbsp;</span><span>If images do not have alt text, then screen readers will simply say “image” or “graphic” which gives no context or meaning.</span></p>
<p><span>Images often convey valuable information. It’s therefore important that people with a visual impairment can access this information as well.&nbsp;</span><span>Alt text should be clearly written and give an accurate description of the image.</span></p>
<p><strong>Check out <a href="https://bighack.org/how-to-write-better-alt-text-descriptions-for-accessibility/">our tips for writing better alt text</a> to ensure your images are fully accessible.</strong></p>
<h2>Poor use of headings</h2>
<p><span>For quick and easy navigation, many screen reader users navigate using various elements on the page such as headings. They are a great way to find the information we need quickly and effectively. Especially when they follow a logical heading structure with H1s, H2s and H3s helping to prioritise the content.</span></p>
<p><img src="https://bighack.org/wp-content/uploads/2020/05/Headings@2x.jpg" alt="Logical heading structure begins with Heading 1, with Heading 2 sitting beneath heading 1. Heading 3 sits within heading 2 and so on." width="1958" height="1236" srcset="https://bighack.org/wp-content/uploads/2020/05/Headings@2x.jpg 1958w, https://bighack.org/wp-content/uploads/2020/05/Headings@2x-300x189.jpg 300w, https://bighack.org/wp-content/uploads/2020/05/Headings@2x-768x485.jpg 768w, https://bighack.org/wp-content/uploads/2020/05/Headings@2x-1536x970.jpg 1536w" sizes="(max-width: 1958px) 100vw, 1958px" data-srcset="https://bighack.org/wp-content/uploads/2020/05/Headings@2x.jpg 1958w, https://bighack.org/wp-content/uploads/2020/05/Headings@2x-300x189.jpg 300w, https://bighack.org/wp-content/uploads/2020/05/Headings@2x-768x485.jpg 768w, https://bighack.org/wp-content/uploads/2020/05/Headings@2x-1536x970.jpg 1536w" data-src="https://bighack.org/wp-content/uploads/2020/05/Headings@2x.jpg" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p>
<p><span>If websites don’t use headings, it means screen reader users are unable to use the keyboard shortcuts to navigate through the webpage this way. If that’s the case, we have to resort to tabbing or arrowing through a long web page to find the information we need.</span></p>
<p>Headings also help to break up the web content visually and improve readability. Other elements that screen reader users use to navigate webpages include links, lists or landmarks.</p>
<h2>Inaccessible web forms</h2>
<p><span>Most websites use forms in one way or another. Whether it’s to help you search for a product or to get in touch through a contact form. However, when these forms are not labelled, or not labelled correctly, it means we cannot use them.</span></p>
<p><span>For example, if a search box is not labelled, it means screen reader users have no idea of the purpose of that box. It means people who use screen readers cannot access the same functionality.</span></p>
<p><span>Contact forms are an effective way for customers to get in touch with your brand or business. And as a screen reader user, there’s nothing more frustrating than these forms being labelled incorrectly.</span></p>
<p><span>Especially CAPTCHA checkout requirements. Without an option to hear the audio, it’s not accessible. It means we are unable to fill in the form independently. I often have to enlist help from a sighted person, but this isn’t possible for everyone.</span><b>&nbsp;</b></p>
<h2>Auto-playing audio and video</h2>
<p><span>Most people will know how annoying it is to load a web page with noisy adverts that start playing suddenly. But for screen reader users, it can be even more alarming. When video or audio starts playing automatically, it can drown out the voice of the screen reader. This makes it harder to find the pause or stop buttons.</span></p>
<p><span>(And if these buttons are unlabelled, then it’s practically impossible for me to stop the video quickly which causes extra frustration.) If I’m unable to stop the sound or video, I normally click off.</span></p>
<p><span>The solution? Make sure there’s no auto-playing video or audio when your website loads. If you really want to use video, make sure the audio is muted and the user can pause, stop or hide the media player.</span></p>
<p><span>These issues may seem small to sighted users. But they’re the difference between me being able to use a website independently or not. And they make a huge difference when implemented correctly.</span></p>
					</div></div>]]>
            </description>
            <link>https://bighack.org/5-most-annoying-website-features-i-face-as-a-blind-screen-reader-user-accessibility/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24429012</guid>
            <pubDate>Thu, 10 Sep 2020 04:55:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The rate of obsolescence of knowledge in software engineering]]>
            </title>
            <description>
<![CDATA[
Score 10 | Comments 5 (<a href="https://news.ycombinator.com/item?id=24428810">thread link</a>) | @dgs_sgd
<br/>
September 9, 2020 | https://daltyboy11.github.io/obsolescence-of-knowledge-in-software-engineering/ | <a href="https://web.archive.org/web/*/https://daltyboy11.github.io/obsolescence-of-knowledge-in-software-engineering/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p>A physicist loses half the value of their physics knowledge in just four years whereas
an English professor would take over 25 years to lose half the value of the
knowledge they had at the beginning of their career [1]. These estimates are
taken form a paper written in 1982 so software engineers obviously weren’t
included. But it begs the question… What would the half-life of the value of a
software engineer’s knowledge be? I suspect it’s somewhere between the physicist’s
and the English professor’s because a software engineer’s knowledge is a combination
of eternal computer science/engineering principles and ephemeral technologies that
drift in and out of popularity over time.</p>

<h2 id="knowledge-that-doesnt-expire">Knowledge that doesn’t expire</h2>
<p>Software engineers with a traditional computer science background learn things
that never expire with age: data structures, algorithms, compilers,
distributed systems, etc. But most of us don’t work with these concepts
directly. Abstractions and frameworks are built on top of these well studied
ideas so we don’t have to get into the nitty-gritty details on the job
(at least most of the time). Examples are the C++ standard library which
implements optimized sorting for arrays, and Apache Spark which provides fault
tolerant cluster computing out of the box.</p>

<h2 id="knowledge-that-does-expire">Knowledge that does expire</h2>
<p>The unavoidable ephemeral knowledge one accumulates during their career comes in
many forms and this isn’t an exhaustive list:</p>

<ol>
  <li>A vogue framework or programming paradigm that falls out of favor in a couple of years.</li>
  <li>Domain knowledge in a rapidly evolving industry/field.</li>
  <li>Knowledge of proprietry technology: e.g. internal tools at your company.</li>
</ol>

<p>Knowledge of this kind can quickly transition from zealous adoption to every company who
uses said knowledge trying to sunset everything they’ve built with it.</p>

<h2 id="my-experience">My Experience</h2>
<p>I’m inclined to say I use ephemeral knowledge more than eternal knowledge to perform
my job. And then there’s the added pressure in our industry of always having to learn
new and useful things.</p>

<p>A theoretical physicist who spends a great deal of time mastering a theory and
the mathematical techniques behind it, only to see that theory rendered obsolete
by a new and improved theory several years later, is analogous to a software
engineer who spends a great deal of time mastering a web development framework,
learning its intricacies and gotcha’s, only to see that framework rendered
obsolete by a new framework several years later, leaving no more demand for
that knowledge in the labor market.</p>

<p>I relate to the physicist more than the English professor. What do you think?</p>



<p>[1] McDowell, John M. “Obsolescence of Knowledge and Career Publication Profiles: Some Evidence of Differences among Fields in Costs of Interrupted Careers.” The American Economic Review, vol. 72, no. 4, 1982, pp. 752–768. JSTOR, www.jstor.org/stable/1810015. Accessed 9 Sept. 2020.</p>

  </div></div>]]>
            </description>
            <link>https://daltyboy11.github.io/obsolescence-of-knowledge-in-software-engineering/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24428810</guid>
            <pubDate>Thu, 10 Sep 2020 04:10:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Interfacing Microcontrollers with SD Card]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24428745">thread link</a>) | @peter_d_sherman
<br/>
September 9, 2020 | https://openlabpro.com/guide/interfacing-microcontrollers-with-sd-card/ | <a href="https://web.archive.org/web/*/https://openlabpro.com/guide/interfacing-microcontrollers-with-sd-card/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><img height="1" width="1" src="https://www.facebook.com/tr?id=720372835040462&amp;ev=PageView&amp;noscript=1">    <meta name="generator" content="WordPress Download Manager 3.0.4">
<a href="#content">Skip to content</a><div id="boxed-wrapper"><div id="wrapper"><header></header><main id="main"><div><section id="content"><article id="post-2339"><div><p>The secure digital card (SD) is a low cost, non-volatile memory card format developed by the SD Card Association. Since its inception back at the start of the century, the demand for this medium-sized, energy and space-efficient, the memory storage device has been growing at a fast rate. Therefore, to meet the market requirements, the SDA was set up as a non-profit organization to promote and create SD Card standards. There are various topics related to the SD card such as the different device families, speed classes, smart cards, card security and so on and it is used in various markets like digital cameras, personal computers, and embedded systems. Some of the standard variations include SD, SDHC, SDXC, SD-ultra high speed etc. The microSD is the miniaturized SD memory card format with a small form factor and is widely used in various electronic devices.<br>
What we are going to learn is the use of SD cards in an embedded system. To be specific, we will be dealing with the use of SD cards in small embedded systems.</p><h2>Circuit&nbsp;and Interfacing</h2><p>SD card has a native host interface apart from the SPI mode for communicating with master devices. The native interface uses four lines for data transfer where the microcontroller has SD card controller module and it needs separate license to use it. Since the SPI is a widely used protocol and it is available in most low-cost microcontrollers, the SPI mode is the widely used interface in low cost embedded systems. The working voltage range of SD family is 2.7V to 3.6V and this is indicated in the operation condition register (OCR).</p><p><img src="https://cdn.openlabpro.com/wp-content/uploads/2016/12/2000px-SD_Pins.svg_-1.png" alt="2000px-sd_pins-svg" width="214" height="292"></p><div id="attachment_2345"><img aria-describedby="caption-attachment-2345" src="https://cdn.openlabpro.com/wp-content/uploads/2016/12/SD-card.png" alt="sd-card" width="371" height="229" srcset="https://cdn.openlabpro.com/wp-content/uploads/2016/12/SD-card-200x124.png 200w, https://cdn.openlabpro.com/wp-content/uploads/2016/12/SD-card-300x185.png 300w, https://cdn.openlabpro.com/wp-content/uploads/2016/12/SD-card-400x247.png 400w, https://cdn.openlabpro.com/wp-content/uploads/2016/12/SD-card-600x371.png 600w, https://cdn.openlabpro.com/wp-content/uploads/2016/12/SD-card-768x475.png 768w, https://cdn.openlabpro.com/wp-content/uploads/2016/12/SD-card-800x495.png 800w, https://cdn.openlabpro.com/wp-content/uploads/2016/12/SD-card.png 1024w" sizes="(max-width: 371px) 100vw, 371px"><p id="caption-attachment-2345">SD Card pinout</p></div><div id="attachment_2347"><img aria-describedby="caption-attachment-2347" src="https://cdn.openlabpro.com/wp-content/uploads/2016/12/SD-card-2.png" alt="sd-card-2" width="381" height="213" srcset="https://cdn.openlabpro.com/wp-content/uploads/2016/12/SD-card-2-200x112.png 200w, https://cdn.openlabpro.com/wp-content/uploads/2016/12/SD-card-2-300x168.png 300w, https://cdn.openlabpro.com/wp-content/uploads/2016/12/SD-card-2-400x223.png 400w, https://cdn.openlabpro.com/wp-content/uploads/2016/12/SD-card-2-600x335.png 600w, https://cdn.openlabpro.com/wp-content/uploads/2016/12/SD-card-2-768x429.png 768w, https://cdn.openlabpro.com/wp-content/uploads/2016/12/SD-card-2-800x447.png 800w, https://cdn.openlabpro.com/wp-content/uploads/2016/12/SD-card-2.png 1024w" sizes="(max-width: 381px) 100vw, 381px"><p id="caption-attachment-2347">MicroSD Card pinout</p></div><p>Most micro-controllers use the SPI communication protocol to interface with the SD cards. The SD cards have a microcontroller that shows their availability to the master controller(microcontroller). The micro-controller sees the SD card as an addressable sector on which read/write functions are possible. Once the microcontroller is in the SPI mode, communication between the master and the slave is done via 4 pins viz. clock, chip select, data in and data out. It should be kept in mind that throughout the communication between the two devices, the micro-controller will be sending out the clock.<br>
Most development boards have a dedicated SD card slot. But to understand the connections, let us analyze this fairly simple circuit.</p><div id="openl-1138068715"><div data-animationoffset="100%"><div><div data-link="https://openlabpro.com/online-courses/pic-microcontroller/" data-link-target="_self" data-animationoffset="100%"><div>From the very basic I/O control to the advaced SD Card interfacing, this course covers what you need to get started in Embedded Systems.<div><div><iframe src="https://player.vimeo.com/video/362065141?autoplay=0&amp;autopause=0" width="600" height="360" allowfullscreen="" title="vimeo362065141" allow="autoplay; fullscreen"></iframe></div></div></div><a href="https://openlabpro.com/online-courses/pic-microcontroller/" target="_self">Learn more about the course</a></div></div></div></div><h3>Circuit</h3><p><img src="https://cdn.openlabpro.com/wp-content/uploads/2016/12/SD-card-circuit.png" alt="sd-card-circuit" width="506" height="284" srcset="https://cdn.openlabpro.com/wp-content/uploads/2016/12/SD-card-circuit-200x113.png 200w, https://cdn.openlabpro.com/wp-content/uploads/2016/12/SD-card-circuit-300x169.png 300w, https://cdn.openlabpro.com/wp-content/uploads/2016/12/SD-card-circuit-400x225.png 400w, https://cdn.openlabpro.com/wp-content/uploads/2016/12/SD-card-circuit-600x338.png 600w, https://cdn.openlabpro.com/wp-content/uploads/2016/12/SD-card-circuit-768x432.png 768w, https://cdn.openlabpro.com/wp-content/uploads/2016/12/SD-card-circuit-800x450.png 800w, https://cdn.openlabpro.com/wp-content/uploads/2016/12/SD-card-circuit-1024x576.png 1024w, https://cdn.openlabpro.com/wp-content/uploads/2016/12/SD-card-circuit-1200x675.png 1200w, https://cdn.openlabpro.com/wp-content/uploads/2016/12/SD-card-circuit.png 1280w" sizes="(max-width: 506px) 100vw, 506px"></p><p>If the logic level of the microcontroller is different than the SD card, level shifter needs to be used for converting the line voltages.<br>
The MISO (master in serial out) pin should be connected to the SDI (serial data in) pin on the microcontroller.<br>
The MOSI (master out serial in) pin should be connected to the SDO (serial data out) pin on the microcontroller.<br>
The SCK (serial clock) pin should be connected to the SCK (serial clock) pin on the microcontroller.<br>
The CS (chip select) pin should be connected to the corresponding CS pin on the microcontroller or on any digital I/O pin on the microcontroller. A common ground is provided.</p><p><b>IMPORTANT NOTE</b>: While connecting the power supply, make sure that the supply is drawn from a 3.3V supply as a 5V supply would see your card go up in smoke.</p><h3>Interfacing</h3><p>Once the connections are set up, we are ready to interface our hardware with the software.<br>
Set the directions of each of the four pins correctly. While activating the SPI mode, an ideal configuration should be, mode(0,0) and the phase with input sampled at the middle of data out. Also, the clock frequency should be set in the range of 100 kHz and 400 kHz prior to initializing the card. Once the initialization is done, the clock can be set to a more desired frequency.</p><h2>SD Commands</h2><p>Next comes the tricky part, initializing the SD card and performing the raw data communication. A systematic approach to programming the software would make the task pretty easy.<br>
But first, it is important to learn how the micro-controller activates the SD card. There are a fixed set of commands and responses, which must be followed to create a command to response structure in our program. The data is transmitted in a byte-oriented format with a definite length.<br>
The following table shows the necessary<b> commands</b> to the card and the corresponding response from the card.</p><p><img src="https://cdn.openlabpro.com/wp-content/uploads/2016/12/SD-card-3.png" alt="sd-card-3" width="507" height="1118" srcset="https://cdn.openlabpro.com/wp-content/uploads/2016/12/SD-card-3-136x300.png 136w, https://cdn.openlabpro.com/wp-content/uploads/2016/12/SD-card-3-200x441.png 200w, https://cdn.openlabpro.com/wp-content/uploads/2016/12/SD-card-3-400x882.png 400w, https://cdn.openlabpro.com/wp-content/uploads/2016/12/SD-card-3-464x1024.png 464w, https://cdn.openlabpro.com/wp-content/uploads/2016/12/SD-card-3-600x1323.png 600w, https://cdn.openlabpro.com/wp-content/uploads/2016/12/SD-card-3-768x1694.png 768w, https://cdn.openlabpro.com/wp-content/uploads/2016/12/SD-card-3-800x1765.png 800w, https://cdn.openlabpro.com/wp-content/uploads/2016/12/SD-card-3-1200x2647.png 1200w, https://cdn.openlabpro.com/wp-content/uploads/2016/12/SD-card-3.png 1274w" sizes="(max-width: 507px) 100vw, 507px"></p><p>Every command has a constant length of 6 bytes.<br>
The first byte is the addition of the command number and the number 64.<br>
<b>Example</b>:<br>
For CMD0: command number 0 + 64 = 64 = 0x40 in hexadecimal.<br>
For CMD1: command number 1 + 64 = 65 = 0x41 in hexadecimal.<br>
And so on.<br>
This is followed by a set of four bytes which are known as the arguments. These arguments usually contain the address of a data or the length of a block.<br>
The last byte is the CRC (Cyclic Redundancy Check) Byte. Most commands in the SPI mode does not require a check byte if the CRC feature isn’t enabled. For some commands like CMD0, the CRC is 0x95 and in most cases, a 0xFF is sent. Enabling the CRC requires you to send the correct check byte from the micro-controller. So, ensure whether the CRC feature is enabled or disabled.<br>
A <b>command frame</b> looks like this-</p><p><img src="https://cdn.openlabpro.com/wp-content/uploads/2016/12/Clr_frame1-800x267.png" alt="Interfacing Microcontrollers with SD Card - Command frame" width="800" height="267" srcset="https://cdn.openlabpro.com/wp-content/uploads/2016/12/Clr_frame1-200x67.png 200w, https://cdn.openlabpro.com/wp-content/uploads/2016/12/Clr_frame1-300x100.png 300w, https://cdn.openlabpro.com/wp-content/uploads/2016/12/Clr_frame1-400x133.png 400w, https://cdn.openlabpro.com/wp-content/uploads/2016/12/Clr_frame1-600x200.png 600w, https://cdn.openlabpro.com/wp-content/uploads/2016/12/Clr_frame1-768x256.png 768w, https://cdn.openlabpro.com/wp-content/uploads/2016/12/Clr_frame1-800x267.png 800w, https://cdn.openlabpro.com/wp-content/uploads/2016/12/Clr_frame1-1024x342.png 1024w, https://cdn.openlabpro.com/wp-content/uploads/2016/12/Clr_frame1-1200x400.png 1200w, https://cdn.openlabpro.com/wp-content/uploads/2016/12/Clr_frame1.png 1280w" sizes="(max-width: 800px) 100vw, 800px"></p><p>The card will receive a command when the DO pin (Data Out) is driven high as shown above. The CS pin (Chip Select) must be driven high to low before sending the command and must be kept low during the process. The time between a command and its response is known as the command response time (NCR). As mentioned earlier, regarding the clock pulses from the micro-controller, the corresponding response byte sent back from the card to the microcontroller should be driven by the serial clock pulses of the micro-controller. There is a chance that the response byte from the card might get skipped by the microcontroller due to the absence of a driving clock pulse. Hence it is necessary to make sure that an 8-Bit clock pulse is sent to the Card soon after the Command Frame is sent (Refer the <b>TECHNICAL NOTE </b>below). Also while receiving a Byte from the card, the DI pin (Data In) must be driven high.</p><p>Furthermore, let us analyze the different<b> types of responses</b> that we get from the card and what they mean.</p><p><img src="https://cdn.openlabpro.com/wp-content/uploads/2016/12/Response_Color-1.jpg" alt="response_color" width="568" height="289"></p><p>An R1 response, 0x01 means that the command sent prior to the response has resulted in the card going into an idle state.<br>
A response byte 0x00 means that the command has been accepted and the card will be waiting for the proposed event to take place. If any other bits in an R1 response is set, it is the result of an error and it’ll be down to the factor mentioned in each R1 response bit in the figure.</p><h2>Initializing&nbsp;the SD Card</h2><p>Now, as far as sending the commands are concerned, there is an order in which they must be sent. Only the commands, CMD0, CMD1, ACMD41, CMD58 and CMD59 will be accepted when the card is in its idle state. Sending any other command will likely to yield an illegal response.</p><p><b>TECHNICAL NOTE</b>: After interfacing the card, the micro-controller must always send a set of bytes, which we will refer to as dummy bytes. One dummy byte is 0xFF. These dummy bytes have a simple yet significant purpose. Prior to the initialization, the card must know the frequency at which the data is being sent. By sending around 75 dummy bits approximately (dummy byte * 10 times = 80 bits), the card will be ready for communication. Also even after every command is sent, it is a good practice to send at least one dummy byte. A logical explanation for this is that communication is driven by the clock pulse of the micro-controller. The clock pulse is sent only when the data buffer is filled. After every response is sent and prior to the next command or between command and response, the SCK will stop generating pulses due to an empty data buffer. To ensure the continual transmission of clock pulses between every command, fill the data buffer with a junk value such as a dummy byte. To create a dummy byte function with the number of loops as the argument.</p><p>The<b> first command</b> to be sent to the card is the <b>CMD0</b> command. The structure of every other command-response should be based on this model.</p><ul><li>Drive the DO pin high.</li><li>Drive the CS pin from high to low.</li><li>Send a dummy byte.</li><li>Then send the following 6-byte command continuously<br>
First byte: 0x40<br>
Next four bytes: 0x00000000<br>
CRC byte: 0x95</li></ul><ul><li>Send another dummy byte or as many as required, to generate the SCK giving time for the SD card to respond to the command request.</li><li>Wait for the receive flag bit to set and then read the response from the SD card or create a loop to read the response a few number of times. The response should reach back within the command to response (Ncr) time. Or else, something must be wrong.</li></ul><ul><li>The desired response is 0x01, meaning the card is in the idle state and we are good to go.</li></ul><p>Send the <b>CMD8</b> command next to check the version of your SD card.<br>
The difference in the 6-byte commands are<br>
First byte: 0x48<br>
Next four bytes: 0x000001AA<br>
CRC byte: 0x87</p><p>We are looking for two possibilities in our response byte. Either 0x01 or 0x05.</p><p>A 0x01 response means that you have a version 2 SD card. The 0x01 response is followed by the 4 bytes 0x00, 0x00, 0x01, 0xAA in the order of their transmission from the SD card which is, in fact, the argument you send in your command.</p><p>If the response is 0x05, it means the card is a version 1 or an MMC card. If the card is actually a version 2 SD card, then this response is the result of an illegal command. Also, the card is now in the idle state.</p><p>Once the above two commands (CMD0 and CMD8) are done, it is safe to say that our SD Card is working in good condition and ready for data Read/Write.<br>
Additionally, just to ensure whether the SD Card is functioning in the correct working voltage, send the <b>CMD58</b> Command.</p><p>Next, we must initiate the i<b>nitialization</b> process. For this send a <b>CMD1</b> command and wait for response 0x00, meaning the idle state bit is cleared.<br>
If you are using an SDC or for the purpose of creating a general code, it is …</p></div></article></section></div></main></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://openlabpro.com/guide/interfacing-microcontrollers-with-sd-card/">https://openlabpro.com/guide/interfacing-microcontrollers-with-sd-card/</a></em></p>]]>
            </description>
            <link>https://openlabpro.com/guide/interfacing-microcontrollers-with-sd-card/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24428745</guid>
            <pubDate>Thu, 10 Sep 2020 03:55:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[On moving away from a six figure consultancy to becoming an indie hacker]]>
            </title>
            <description>
<![CDATA[
Score 14 | Comments 12 (<a href="https://news.ycombinator.com/item?id=24428473">thread link</a>) | @jv22222
<br/>
September 9, 2020 | https://matteomosca.io/how-covid-and-a-kick-scooter-turned-me-into-an-indie-hacker | <a href="https://web.archive.org/web/*/https://matteomosca.io/how-covid-and-a-kick-scooter-turned-me-into-an-indie-hacker">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://matteomosca.io/how-covid-and-a-kick-scooter-turned-me-into-an-indie-hacker</link>
            <guid isPermaLink="false">hacker-news-small-sites-24428473</guid>
            <pubDate>Thu, 10 Sep 2020 02:52:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The amazing $1 microcontroller (2017)]]>
            </title>
            <description>
<![CDATA[
Score 265 | Comments 123 (<a href="https://news.ycombinator.com/item?id=24426882">thread link</a>) | @appwiz
<br/>
September 9, 2020 | https://jaycarlson.net/microcontrollers/ | <a href="https://web.archive.org/web/*/https://jaycarlson.net/microcontrollers/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><h4>Silcon Labs EFM8: Fantastic value and ease-of-use from the only 8-bit part with a totally-free cross-platform vendor ecosystem</h4><p>The <a href="https://jaycarlson.net/pf/silicon-labs-efm8/">EFM8</a> was the fastest 8-bit part in my round-up, and admittedly, my favorite 8-bit architecture to develop with overall. What these parts lack in brains they make up for in brawns — 14-bit ADCs, 12-bit DACs, lots of timers, and a 72 MHz core clock speed that gives you timing options not found in any other part in the round-up.</p><p>Plus, this is the only 8-bit part with a totally-free, cross-platform, vendor-provided ecosystem. Let that sink in.</p><p>Keil C51 is a silly compiler, but Silicon Labs does an excellent job hiding it under the hood — even when running its Eclipse-based Simplicity Studio on Linux or macOS.</p><p>Simplicity Configurator is the lightest-weight code generator in our round-up, using only 534 bytes of flash to house the entire DMX-512 receiver project. It was one of the easiest to use, and seemed to strike a good balance between abstraction, performance, and ease of use.</p><p>Debugging speeds are snappy with a J-Link debugger, but at $35, the official Silicon Labs USB Debug Adapter is one of the cheapest first-party debugger in the round-up, and clones of the hardware are even cheaper.</p><p>And call me old-fashioned, but I think the 8051 definitely has a place in 2017 — especially among hobbyists and students, where its bit-addressable memory, easy-to-use peripherals, and fuse-free configuration help get students comfortable with microcontrollers quickly.</p><h4>Microchip megaAVR &amp; tinyAVR 1-Series: Different strokes for different folks — still with the best 8-bit toolchain available</h4><p>The <a href="https://jaycarlson.net/pf/atmel-microchip-megaavr/">megaAVR</a> came in surprisingly flat for me: especially when compared with its lower-cost, new sibling, the <a href="https://jaycarlson.net/pf/atmel-microchip-tinyavr-1-series/">tinyAVR 1-Series</a>.</p><p>There’s no comparison when it comes to price: tinyAVR has incredible value — packing in a nice assortment of timers, analog peripherals (including a DAC), and a new 20 MHz internal oscillator — while costing 20-40% less than the megaAVR.</p><p>While the megaAVR has a perplexing debugging experience that requires two completely different interfaces and protocols to work with the part, the new one-wire UPDI interface the tinyAVR sports worked flawlessly in my testing.</p><p>But that’s the crux of the problem for the tinyAVR — by shedding many of its megaAVR roots, Microchip ended up with a wonderful microcontroller that will be challenging to use for a large base of Atmel fans: indie developers and hobbyists who use low-cost, open-source programmers (which don’t support the UPDI interface).</p><p>While the tinyAVR wasn’t the fastest part in the round-up (even among 8-bitters), it was the most efficient – both in terms of active-mode power and clock efficiency. Amazingly, the AVR only uses about twice as many instructions as 16- and 32-bit parts when performing 16-bit math.</p><p>Unfortunately, the AVR system as a whole is not without its issues. The Windows-only Atmel Studio is still buggy (especially with older megaAVR devices and AVR Dragon stuff in my tests), and there isn’t an under-$50 low-cost debugger available (other than hacking apart Xplained Mini dev boards).</p><p>In many ways, there seems to be a tacit demarcation Atmel creates between its hobbyist/indie developers, and the professional shops that use Atmel parts.</p><p>As a professional embedded developer, I most definitely have access to Windows computers, and I have no problem blowing a few billable hours’ worth of pay on a $140 debugger.</p><p>But even as popular as Atmel is among hobbyists, Atmel has largely stayed out of this space directly. Instead, they’ve secured small-volume AVR sales by relying on the open-source community to build their own tools for themselves: turning out a slew of hardware and software used to program the megaAVR devices.</p><p>While I applaud the efforts of these developers, these tools are inferior to Atmel’s. Their programming speeds are terrible, they don’t support the new tinyAVR 1-Series devices, and they have absolutely no debug capability.</p><p>Having said that, both the megaAVR and tinyAVR have the best toolchain available for 8-bit MCU development. The part supports a full, end-to-end Makefile-based GCC toolchain.</p><p>If you love printf() debugging, would never touch a proprietary toolchain, and hate IDEs, megaAVR and old tinyAVR parts are definitely for you. The older ones are still available in DIP packages, and as you probably know, there are a ton of low-cost programmers available across the world. The online community is massive, and as clunky as I find Atmel START to be, I have to applaud its support for Makefile-based project generation.</p><p>Consequently, the megaAVR remains the most open-source 8-bit microcontroller on the market — by a long shot.</p><p>But I’d really like to see Microchip provide a PicKit-priced debugger with UPDI support — and allow off-board debugging the way their PIC Curiosity Boards do.</p><p>I also hope these open-source projects can add UPDI support to their tools, so that hobbyists and indie developers can start integrating the tinyAVR into their projects — it’s a much better part, and if you’re an AVR user with access to Atmel Studio, you really ought to buy an Xplained Mini board and take it for a spin.</p><h4>STM32F0: A low-cost, no-nonsense part with arguably the best Arm development ecosystem tested</h4><p><a href="https://jaycarlson.net/pf/st-stm32f0/">The STM32F0</a> was the lowest-power Arm microcontroller in the round-up, and also one of the easiest to use. STM32CubeMX doesn’t generate the most compact code on Arm (that honor belongs to Cypress PSoC Creator and Infineon DAVE), but it has a snappy interface, and the generated code is easy enough to manipulate for your own goals.</p><p>I love the nearly-stock Eclipse-based environment that System Workbench for STM32 provides, and the ST-Link and excellent Discovery/Nucleo boards seals the deal for me.</p><p>Most pros have used ST parts in their work, but for all these reasons, any hobbyist looking at moving to Arm should probably pick up a dev board from this ecosystem, too. ST has a huge market footprint, so there’s tons of resources online — aimed at both hobbyists and professionals.</p><h4>SAM D10: Killer performance &amp; peripherals, but with runtime library hiccups</h4><p>The Microchip/Atmel <a href="https://jaycarlson.net/pf/atmel-microchip-sam-d10/">SAM D10</a> (and the broader D11/D20/D21 ecosystem) has good value (considering their analog portfolio includes a DAC, and they have good timing options), and the SAM D10 was the most efficient part tested when running at full speed.</p><p>Professionals will like the easy-to-use, well-documented header files, and hobbyists will appreciate the 1.27mm-pitch SOIC package options and GCC compilers that come with the Arm ecosystem. But before I grab this part for a project, Microchip really needs to fix the extremely slow, bloated peripheral library, and update their code-gen tool to do proper error-checking of clock and peripheral configurations.</p><p>As it is, whenever I use Atmel START on the D10, I want to STOP almost immediately. And there are no current, stand-alone peripheral drivers that Microchip has released for this part, so unless you want to do register programming from scratch, you’ll be relying on third-party, open-source projects — like Alex Taradov’s <a href="https://github.com/ataradov/mcu-starter-projects">code examples</a>.</p><h4>Infineon XMC1100: Interesting peripheral perks make this Cortex-M0 stand out</h4><p>The most interesting Arm chip was, without a doubt, the <a href="https://jaycarlson.net/pf/infineon-xmc1100/">Infineon XMC1100</a> — and I think professionals who may be wary of getting out of the ST/NXP/Atmel Arm ecosystem need to take a second look at these XMC1000 (and XMC4000) parts.</p><p>The timer options are amazingly flexible, and you can squeeze fantastic performance out of the USIC module.</p><p>I’m going to go out on a limb and recommend that serious hobbyists who are building motor / lighting control projects look into these parts, too. DAVE makes setting up these complex peripherals painless, and the 38-pin TSSOP chips will be substantially easier to solder than the 0.5mm QFNs and QFPs you usually end up with in these pin counts.</p><p>Like many of the parts reviewed here, the biggest problem for hobbyists and indie developers is the tiny online communities and lack of GitHub repos with open-source projects that use these chips. My advice — be bold, and post in the forums. Infineon employees monitor and usually respond within a day or so.</p><h4>PIC16: Tons of peripherals with a slower, power-efficient core</h4><p>When you compare the <a href="https://jaycarlson.net/pf/microchip-pic16-five-digit-enhanced/">PIC16</a> with other 8-bit parts out there, it’s obviously a part built for low-power applications, and not processing power. And while the development ecosystem is workable, there are other parts more friendlier pathways — especially for smaller shops, hobbyists, and students who need extremely low-cost tools (and free software).</p><p>To add fuel to the PIC-vs-AVR debate, my testing found that a 32 MHz PIC16 is roughly equivalent to an AVR part running at 1.4 MHz (in terms of math performance), and 9 MHz (in terms of bit-shuffling performance).</p><p>Having said that, the DMX-512 receiver seems a perfect match for the PIC16, and that’s where it looks best in my testing: the PIC16 was the lowest-power 8-bit part in my testing.</p><p>It’s also full of timers and digital logic-oriented peripherals that make it suitable for funky special-purpose projects that require some crafty use of configurable logic and and the numerically-controlled oscillator — these peripherals help offload the (relatively slow) CPU, at the expense of requiring more developer familiarity with the device and these peripherals.</p><p>The usual Microchip gotchas apply: clunky IDE, expensive compilers, and expensive debuggers.</p><p>The usual Microchip advantages apply: huge online community, seemingly infinite product lifetime guarantees, and DIP, SOIC, QFP, and QFN package availability.</p><h4>PIC24: An expensive MSP430 wannabe that doesn’t hit the mark</h4><p>The <a href="https://jaycarlson.net/pf/microchip-pic24/">PIC24</a> is nearly forgettable. In the biquad test, it’s marginally faster than the <a href="https://jaycarlson.net/pf/renesas-rl-78/">Renesas RL-78</a> but uses almost three times as much power. In the DMX-512 test, both the RL-78 and MSP430 beat it, too. It was also one of the least-endowed parts in the round-up (which really just means it’s expensive — higher-end PIC24 parts have no shortage …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://jaycarlson.net/microcontrollers/">https://jaycarlson.net/microcontrollers/</a></em></p>]]>
            </description>
            <link>https://jaycarlson.net/microcontrollers/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24426882</guid>
            <pubDate>Wed, 09 Sep 2020 22:56:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How Much Time Is Spent at Traffic Signals?]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 5 (<a href="https://news.ycombinator.com/item?id=24426023">thread link</a>) | @sharkweek
<br/>
September 9, 2020 | https://transportist.org/2018/03/06/how-much-time-is-spent-at-traffic-signals/ | <a href="https://web.archive.org/web/*/https://transportist.org/2018/03/06/how-much-time-is-spent-at-traffic-signals/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-24122">
	<!-- .entry-header -->

	<div>
		<figure data-shortcode="caption" id="attachment_26070" aria-describedby="caption-attachment-26070"><img loading="lazy" data-attachment-id="26070" data-permalink="https://transportist.org/books-2/books/the-30-minute-city-designing-for-access/the30-minutecity-cover-print/" data-orig-file="https://transportationist.files.wordpress.com/2019/12/the30-minutecity-cover-print.jpg" data-orig-size="2694,3434" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;1.8&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;iPhone XS Max&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1577200438&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;4.25&quot;,&quot;iso&quot;:&quot;250&quot;,&quot;shutter_speed&quot;:&quot;0.016666666666667&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="The30-MinuteCity-Cover-Print" data-image-description="<p>The 30-Minute City by David M. Levinson</p>
" data-medium-file="https://transportationist.files.wordpress.com/2019/12/the30-minutecity-cover-print.jpg?w=471" data-large-file="https://transportationist.files.wordpress.com/2019/12/the30-minutecity-cover-print.jpg?w=764" src="https://transportationist.files.wordpress.com/2019/12/the30-minutecity-cover-print.jpg?w=300&amp;h=383" alt="The 30-Minute City by David M. Levinson" width="300" height="383" srcset="https://transportationist.files.wordpress.com/2019/12/the30-minutecity-cover-print.jpg?w=300&amp;h=383 300w, https://transportationist.files.wordpress.com/2019/12/the30-minutecity-cover-print.jpg?w=600&amp;h=766 600w, https://transportationist.files.wordpress.com/2019/12/the30-minutecity-cover-print.jpg?w=118&amp;h=150 118w, https://transportationist.files.wordpress.com/2019/12/the30-minutecity-cover-print.jpg?w=471&amp;h=600 471w" sizes="(max-width: 300px) 100vw, 300px"><figcaption id="caption-attachment-26070"><a href="https://transportist.org/books/the-30-minute-city-designing-for-access/">The 30-Minute City</a> by David M. Levinson&nbsp;</figcaption></figure>
<p>While working on another piece, I came upon the question of how much time is spent at traffic lights, for which there is not a well-sourced answer. I posted to Twitter and got some useful replies.</p>
<blockquote>
<p dir="ltr" lang="en">Transport Twitter: What percent of total travel time is spent stopped at traffic lights? Empirical results please.</p>
<p>— David M. Levinson (@trnsprtst) <a href="https://twitter.com/trnsprtst/status/967547973788827648?ref_src=twsrc%5Etfw">February 24, 2018</a></p></blockquote>
<p>With that and some additional digging, I attempt to answer the question.</p>
<p>As the saying goes: Your Mileage May Vary. This depends on your origin and destination and path and mode and time of day and local traffic signal policies and street design. <a href="https://twitter.com/tvanvuren">Tom VanVuren</a> notes: “Much of the impact is in slow moving queues, rather than waiting for the signal cycle to complete. I expect you can make this number smaller than 10% (time at the stop line) or larger than 50% (time affected by traffic lights).” For simplicity, I am considering vehicles that would be stopped if they could either move at the desired speed or must stop (i.e. they are subject to “vertical” or “stacking” queues), but clearly measurement will depend on assumption. Still, there must be a system average. I had heard the number 20% bandied about, which feels right, but let’s first begin with some thought experiment, then look for some empirical results. We take different modes in turn.</p>
<figure data-shortcode="caption" id="attachment_24089" aria-describedby="caption-attachment-24089"><a href="https://transportationist.files.wordpress.com/2018/02/img_0230.jpg"><img loading="lazy" data-attachment-id="24089" data-permalink="https://transportist.org/2018/02/14/the-ambiguous-hump/img_0230/" data-orig-file="https://transportationist.files.wordpress.com/2018/02/img_0230.jpg" data-orig-size="4032,3024" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;2.2&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;iPhone 6s&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1518165138&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;4.15&quot;,&quot;iso&quot;:&quot;25&quot;,&quot;shutter_speed&quot;:&quot;0.00090991810737034&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="Free left" data-image-description="<p>A signalized but porkchop-islanded crosswalk at a Free Left (Free Right for those in the right-side drive countries). Notice the pedestrian light is red (don’t walk) but the pedestrians cross anyway. If the free left is not eliminated in a more comprehensive redesign, it could easily be de-signaled and the crosswalk raised, so pedestrians dominate, and cars travel when they can.</p>
" data-medium-file="https://transportationist.files.wordpress.com/2018/02/img_0230.jpg?w=600" data-large-file="https://transportationist.files.wordpress.com/2018/02/img_0230.jpg?w=764" src="https://transportationist.files.wordpress.com/2018/02/img_0230.jpg?w=300&amp;h=225&amp;crop=1" alt="A signalized but porkchop-islanded crosswalk at a Free Left (Free Right for those in the right-side drive countries). Notice the pedestrian light is red (don't walk) but the pedestrians cross anyway. If the free left is not eliminated in a more comprehensive redesign, it could easily be de-signaled and the crosswalk raised, so pedestrians dominate, and cars travel when they can." width="300" height="225" srcset="https://transportationist.files.wordpress.com/2018/02/img_0230.jpg?w=300&amp;h=225&amp;crop=1 300w, https://transportationist.files.wordpress.com/2018/02/img_0230.jpg?w=600&amp;h=450&amp;crop=1 600w, https://transportationist.files.wordpress.com/2018/02/img_0230.jpg?w=150&amp;h=113&amp;crop=1 150w" sizes="(max-width: 300px) 100vw, 300px"></a><figcaption id="caption-attachment-24089">Pedestrian Crossing at Broadway and City Road, Sydney. Pedestrians crossing against the light.</figcaption></figure>

<h2><strong>Thought Experiments</strong></h2>
<h3><strong>Thought Experiment&nbsp;</strong><strong>1 A</strong></h3>
<p>Imagine an urban grid.</p>
<ul>
<li>Assume 10 signalized intersections per km.</li>
<li>Assume a travel speed of 60 km/h when in motion. (This is probably too high with so many intersections and no platooning, but we are imagining here that you would not be stopping.)</li>
<li>Time to traverse 1 km=1 minute + signal delay. &nbsp;(Some of the distance traversal time overlaps some of the signal delay time, but we will imagine a stacking queue, rather than one that has physical distance for simplicity, we can correct this later if it matters.)</li>
<li>Assume each intersection has only 2 phases.</li>
<li>Assume fixed time signals at each intersection evenly distributing green time between N/S and E/W directions. &nbsp;So&nbsp;red time = 1/2 cycle length.</li>
<li>Assume 1 minute cycle length</li>
<li>If a vehicle stops, it waits 1/2 red time.</li>
<li>Vehicles obey traffic signals.</li>
<li>Assume no platooning.</li>
</ul>
<p><em>This means that the average vehicle will&nbsp;stop at 5 intersections for 15 seconds each = 75 seconds (or 1.25 &nbsp;minutes) (vs. 1 &nbsp;minute in motion time). In this case, 1.25/2.25 minutes (55.5%) is spent waiting at signals.</em></p>
<h3><strong>Thought Experiment 1 B</strong></h3>
<p>In contrast.</p>
<ul>
<li>Assume near perfect platooning.</li>
</ul>
<p>In this case, the vehicle will stop at 1 intersection per km, for 15 seconds = 15 seconds. In this case 0.25/1.25 = 20% of the time is spent waiting at signals.</p>
<h3><strong>Discussion</strong></h3>
<p>Now, not all travel takes place on an urban grid.</p>
<ul>
<li>Assume 25% of travel is on limited access roads (this is approximately true in the US), &nbsp;75% on non-limited access roads.</li>
</ul>
<p>With perfect platooning on the grid, and 25% off-grid, then 15% of travel time is intersection delay with near perfect platooning.</p>
<p>Clearly in practice platooning is far from perfect. My guess is the green wave breaks down after one or two intersections during peak times, but can survive well in the off-peak. As a rule of thumb, about ~10% of travel is in the peak hour, ~30% peak period. ~60% AM + PM Peak.</p>
<h2>Data</h2>
<h3>GPS Studies</h3>
<p>Eric Fischer of MapBox was kind enough to offer to run this question on their open traffic data. The results are not yet in. I will update when they are.</p>
<h3>Arterial Travel Time Studies</h3>
<p>There are a variety of Arterial Travel Time studies for specific corridors, but nothing that is universally generalizable. &nbsp;(And logically where people do arterial travel time studies, there is a congestion problem, otherwise why study it.)</p>
<p>I recall that in my childhood,<a href="https://conservancy.umn.edu/handle/11299/179862"> I did a study in Montgomery County, Maryland</a>&nbsp;using such data (from 1987 traffic counts and a floating car study published by Douglas and Douglas), I did not actually compute the percentage, but fortunately I reported enough data that allows me to compute the percentage now. (The sample is of course biased to what is measured). For the average arterial link, the speed was</p>
<div class="page" title="Page 24">
<table>
<tbody>
<tr>
<td>&nbsp;<strong>Variable</strong></td>
<td><strong>Inside the Beltway</strong></td>
<td><strong>&nbsp;Outside the Beltway</strong></td>
</tr>
<tr>
<td>&nbsp;Speed (km/h)</td>
<td>34.88</td>
<td>&nbsp;41.60</td>
</tr>
<tr>
<td>&nbsp;Length (km)</td>
<td>&nbsp;0.46</td>
<td>&nbsp;0.72</td>
</tr>
<tr>
<td>&nbsp;Time (min)</td>
<td>&nbsp;0.792</td>
<td>&nbsp;1.04</td>
</tr>
<tr>
<td>&nbsp;Downstream Delay (min)</td>
<td>&nbsp;0.27</td>
<td>&nbsp;0.24</td>
</tr>
<tr>
<td>&nbsp;Percentage of Signal Delay</td>
<td>&nbsp;25%</td>
<td>&nbsp;18.75%</td>
</tr>
</tbody>
</table>
<p>Which is consistent with expectations that signals are more significant in more urbanized areas (inside the beltway is basically Bethesda and Silver Spring, MD), and with our general estimates. Now of course the speed here is impacted by downstream signals, and so is lower than the speed limit and certainly lower than the free-flow speed sans-signals. More details are in the paper.</p>
<ul>
<li>Levinson, David (1998)&nbsp;<a href="http://hdl.handle.net/11299/179862">Speed and Delay on Signalized Arterials</a>.&nbsp;<em>ASCE Journal of Transportation Engineering</em>&nbsp;124(3) 258-264. [<a href="http://dx.doi.org/doi:10.1061/(ASCE)0733-947X(1998)124:3(258)">doi</a>]</li>
</ul>
</div>
<h3>Engine Idling Studies</h3>
<p>Moaz Ahmed pointed me to a<a href="https://tc.gc.ca/eng/policy/annual-2014-3141.html"> Vehicle Idling Study</a> by <a href="http://www.nrcan.gc.ca/energy/efficiency/communities-infrastructure/transportation/cars-light-trucks/idling/4415">Natural Resources Canada</a>.</p>
<p>The percent of time of vehicle idling ranged from 20-25%. (Not all vehicle idling is at signalized intersections).</p>
<p>(Engine idling of course burns fuel without doing work, so if the engine is going to be idling for an extended period, it would save fuel (and reduce air pollution) to turn it off. Turning the engine on and off also has costs, so the estimate was if idling was going to be longer than 10 seconds, it uses more fuel, but considering other wear and tear costs, the recommended threshold is if idling is longer than 60 seconds, then turn off the engine. &nbsp;But at a signalized intersection, how will vehicles know how long they will wait? Smart traffic signals with connected vehicles could provide this, but now they don’t. Eventually this will be moot with a full electric vehicle fleet. Until that time, it matters. I suspect given the longevity and sluggishness of the traffic control sector, smart signals informing trucks will not be widely or systematically deployed before trucks are electrified.)</p>

<p>Now as noted above, Your Mileage May Vary. If you are a pedestrian, you are unlikely to hit a greenwave designed for cars, though of course your travel speed is slower is well. So redoing the Thought Experiment</p>
<h2><strong>Thought Experiment 2</strong></h2>
<p>Imagine an urban grid.</p>
<ul>
<li>Assume 10 signalized intersections per km.</li>
<li>Assume a travel speed of 6 km/h when in motion. (this is a bit on the high side, average pedestrian speed is closer to <a href="https://westernite.org/datacollectionfund/2005/psu_ped_summary.pdf">5 km/h</a>)</li>
<li>Time to traverse 1 km=10 minutes + signal delay. &nbsp;(Some of the distance traversal time overlaps some of the signal delay time, but we will imagine a vertical stacking queue, rather than one that has physical distance for simplicity, this is a much better assumption for pedestrians than vehicles.)</li>
<li>Assume each intersection has only 2 phases.</li>
<li>Assume fixed time signals at each intersection evenly distributing green time between N/S and E/W directions. &nbsp;So&nbsp;red time = 1/2 cycle length.</li>
<li>Assume 1 minute cycle length</li>
<li>If a pedestrian stops, she waits 1/2 red time. (That is the “walk” phase for pedestrians is as long as the green phase for cars. Strictly speaking this is not true, it is more true in cities with narrow streets than it is in suburban environments with wide streets, as narrow streets can be crossed more quickly, so the amount of “walk” time allocated can be most of the phase. This is certainly not true in Sydney, where the “walk” phase is cut short so turning cars have fewer conflicts with late pedestrians.)</li>
<li>Pedestrians obey traffic lights. &nbsp;(This is not as good an assumption as vehicles obey signals, pedestrian signal violation is probably higher. This is not a moral judgment one way or the other, people tend to obey authority, even when <a href="https://en.wikipedia.org/wiki/Milgram_experiment">authority abuses power</a>.)</li>
<li>Assume no platooning. (This is probably too severe, a quick pedestrian with some signal coordination can probably make a couple of lights in a row).</li>
</ul>
<p>Here the average pedestrian will&nbsp;stop at 5 intersections for 15 seconds each = 2.5 minutes (vs. 10 &nbsp;minute in-motion time). In this case, 2.5/(2.5+10) minutes (or 20%) is spent waiting at signals. Now, this number is probably true for more pedestrians than the vehicle delay estimate is for vehicles, since pedestrians are more likely to be found on an urban grid and less in a suburban or limited access environment. (Self-selection at work).</p>

<p>If you are a bicyclist, you are unlikely to hit a greenwave designed for cars unless you travel at exactly an integer fraction (1/1, 1/2, 1/3) of the green wave, as your travel speed is slower is well. So redoing the Thought Experiment</p>
<h2><strong>Thought Experiment 3</strong></h2>
<p>Imagine an urban grid.</p>
<ul>
<li>Assume 10 signalized intersections per km.</li>
<li>Assume a travel speed of &nbsp;20 km/h when in motion. (This is a typical for <a href="http://www.road-bike.co.uk/articles/average-speed.php">experienced riders</a>).&nbsp;Time to traverse 1 km=3 minutes + signal delay. (Assume a stacking queue)</li>
<li>Assume each intersection has only 2 phases.</li>
<li>Assume fixed time signals at each intersection evenly distributing green time between N/S and E/W directions. &nbsp;So&nbsp;red time = 1/2 cycle length.</li>
<li>Assume 1 minute cycle length</li>
<li>If a bicyclist stops, she waits 1/2 red time. (That is the ‘bike’ phase for bicyclists is as long as the green phase for cars.)</li>
<li>Bicyclists obey traffic lights. &nbsp;(This is not as good an assumption as ‘motor vehicles obey signals’, bicyclists signal violation is probably higher.)</li>
<li>Assume no platooning. (This is probably too severe, a quick bicyclists with some signal coordination can probably make a couple of lights in a row).</li>
</ul>
<p>In this case the average bicyclists will&nbsp;stop at 5 intersections for 15 seconds each = 2.5 minutes (vs. 3 &nbsp;minute in-motion time). In this case, 2.5/(3+2.5) minutes (or 45%) is spent waiting at signals in an urban environment.</p>
<h2>Strava Data</h2>
<p>Strava, an app for tracking bicyclists and runners can produce some useful data. <a href="https://twitter.com/dr_hsu">Andrew Hsu</a>, e.g., <a href="https://www.strava.com/athletes/16556#interval_type?chart_type=hours&amp;interval_type=week&amp;interval=201807&amp;year_offset=0">reports</a>&nbsp;“28 mile bike commute. 1:30-ish moving time. 10-15 minutes waiting at lights.” From this, for him, we estimate 15 / (15+90) = 14%. To be clear, 1:30 is an extreme commute. I don’t have access to …</p></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://transportist.org/2018/03/06/how-much-time-is-spent-at-traffic-signals/">https://transportist.org/2018/03/06/how-much-time-is-spent-at-traffic-signals/</a></em></p>]]>
            </description>
            <link>https://transportist.org/2018/03/06/how-much-time-is-spent-at-traffic-signals/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24426023</guid>
            <pubDate>Wed, 09 Sep 2020 21:19:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Git/serve: A Git server for Plan 9]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24425114">thread link</a>) | @ori_b
<br/>
September 9, 2020 | https://orib.dev/gitserve.html | <a href="https://web.archive.org/web/*/https://orib.dev/gitserve.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">


<p>A while ago, I released <a href="https://orib.dev/git9.html">git9</a>, a git client for
Plan 9. However, it always felt like it was missing something: A git server.
over a few weekends of work, I sat down and put one together. This Labor
Day weekend, I took the opportunity to labor on it, and got something working.</p>

<h3>usage</h3>

<p><code>Git/serve</code> is a git server designed to fit into the Plan
9 ecosystem, allowing hosting of, and interacting with, code on a Plan 9
server, while still allowing legacy clients running on Unix to get a copy
of the code.</p>

<p><code>Git/serve</code> only speaks the <code>git://</code> protocol.
But because it runs behind
<a href="http://man.9front.org/8/listen">aux/listen</a>
and 
<a href="http://man.9front.org/8/tlssrv"><code>tlssrv</code></a>, we
effectively get two additional protocols for free: <code>gits://</code>, or
TLS-encrypted <code>git://</code>, and <code>hjgit://</code>, which is
<code>git://</code> but with Plan 9 authentication to support user login
over TLS. Unfortunately, only the unencrypted <code>git://</code> protocol
is supported out of the box by upstream git. There may be ways to solve
this, using <a href="https://rovaughn.github.io/2015-2-9.html">custom
transports</a>, and a unix port of tlsclient</p>

<p>To start a <code>git://</code> server, just run it under aux/listen1.
To enable encryption and user authentication, run it under
<code>tlssrv -a</code>. This doesn't need a certificate, because
the Plan 9 authentication generates the secret used for TLS. And,
finally, if you just want encryption, you can use <code>tlsclient</code>
with a certificate.</p>

<pre># git:// server, serving every repository under the current directory
% aux/listen1 'tcp!*!9418' git/serve -r `{pwd}

# gits:// server, doing the same: But with encryption.
% aux/listen1 'tcp!*!9418' tlsclient -c /path/to/cert.pem git/serve -r `{pwd}

# hjgit:// server doing the same: Requires account on server to connect
% aux/listen1 'tcp!*!9418' tlsclient -a git/serve -r `{pwd}
</pre>

<p>If you want to allow people to write, you can just add the
<code>-w</code> flag to git/serve. While you can do this on
any of the protocols, keep in mind that only <code>hjgit://</code>
authenticates the users. Push to the world, but don't let the
world push to you!</p>



<p>All the protocols git uses are closely related. The <code>ssh://</code>
protocol is just the <code>git://</code> protocol, with the command selected
sightly differently. The smart <code>http://</code> protocols are the same
as the <code>git://</code> protocol, with a different handshake, and split
over multiple post requests.</p>

<p>Git9 implements the git protocol in under 500 lines of C. The
full code is available on github, in
<a href="https://github.com/oridb/git9/blob/24abe6c00b6f65e7241763399fc72c043b7d9bbf/serve.c">serve.c</a>.
</p>

<p>The protocol look something like this for pushing:</p>

<pre>&lt;=w= 0030:	"git-fetch-pack /oridb/git9\0host=github.com\n"
=r=&gt; 0086:	"747e9e80f710c0b8bbd928080745915ad2493322 HEAD\n"
=r=&gt; 009d:	"747e9e80f710c0b8bbd928080745915ad2493322 refs/heads/master\n"
&lt;=w= 0076:	"747e9e80f710c0b8bbd928080745915ad2493322 dc802c499dc7164aa208b919a07c5bd18701b0e1 refs/heads/master\0report-status\n"
&lt;=w= 0000
&lt;=w= <pack-data>
=r=&gt; 000e:	unpack ok
=r=&gt; 0019:	ok refs/heads/master
</pack-data></pre>

<p>And this for pulling:</p>

<pre>&lt;=w= 0030:	"git-upload-pack /oridb/git9\0host=github.com\n"
=r=&gt; 013b:	"dc802c499dc7164aa208b919a07c5bd18701b0e1 HEAD\n"
=r=&gt; 003f:	"dc802c499dc7164aa208b919a07c5bd18701b0e1 refs/heads/master\n"
=r=&gt; 0000
&lt;=w= 0032:	"want 5d761590cfdce23e4b17e94050b0776c8804d4a1\n"
&lt;=w= 0032:	"want 8f0eb1386a2c748cb7bf26917684479ff8c6d5b5\n"
&lt;=w= 0032:	"want dc4a9d467c6a28dab3927c8611a1bfbc571f1568\n"
&lt;=w= 0000
&lt;=w= 0033:	"have dc802c499dc7164aa208b919a07c5bd18701b0e1\n"
&lt;=w= 0009:	"done\n"
=r=&gt; 0031:	"ACK dc802c499dc7164aa208b919a07c5bd18701b0e1\n"
<pack-data>
</pack-data></pre>

<p>The git protocol consists of pkt-lines, which are strings with a
hex-formatted length prefix.  The length prefix includes itself.  So,
the string <code>"hi"</code> would be formatted as
<code>0006hi</code>. A zero lenth packet where the length prefix
is not included is special. This is called a 'flush packet', and
is used to terminate a phase of negotiation.</p>

<p> All negotiation is with these packet lines, at
which git flips over to pure binary mode to transfer a pack file
over.</p>

<p>In the <code>git://</code> protocol, the client always starts off
by saying which action it wants to do: Either it wants the server to
fetch a pack from the client, or it wants the server to upload a pack
to the client.  That's this line:</p><pre>&lt;=w= 0030:	"git-fetch-pack /oridb/git9\0host=github.com\n"
</pre>

<p>The upload side of this protocol is simpler on the server side so
we'll go through it first.</p>

<h3>pushing</h3>

<p>In the upload protocol, the server begins by sending a list of
references that the client may update. In <code>git/serve</code>
we grab all the refs in the repository, and filter down to just
the ones beginning with <code>heads/</code>.</p>

<pre>	if((nrefs = listrefs(&amp;refs, &amp;names)) == -1)
		sysfatal("listrefs: %r");
	for(i = 0; i &lt; nrefs; i++){
		if(strncmp(names[i], "heads/", strlen("heads/")) != 0)
			continue;
		if(fmtpkt(c, "%H refs/%s\n", refs[i], names[i]) == -1)
			goto error;
	}
	if(flushpkt(c) == -1)
		goto error;
</pre>

<p>With the first phase of the protocol, the client then
sends the list of references it wants to update. This
takes the form of:</p>

<pre>	OLDHASH NEWHASH heads/refs/updateme\n"
</pre>

<p>Because the client knows what the reference versions are on
the server, it can compute what commits are between the version
on the server and the version that it has. If the new hash
is the zero hash, this signals to the server that the reference
should be deleted. This list of updates is terminated with a
flush packet. The code in git9 that handles this is below:

</p><pre>	while(1){
		/* Did we get a packet? */
		if((n = readpkt(c, pkt, sizeof(pkt))) == -1)
			goto error;
		/* Was it a flush packet? */
		if(n == 0)
			break;
		/* Split it up into the 3 parts: old, new, reference */
		if(getfields(pkt, sp, nelem(sp), 1, " \t\n\r") != 3){
			fmtpkt(c, "ERR  protocol garble %s\n", pkt);
			goto error;
		}
		/* verify that these are valid hashes */
		if(hparse(&amp;old, sp[0]) == -1){
			fmtpkt(c, "ERR bad old hash %s\n", sp[0]);
			goto error;
		}
		if(hparse(&amp;new, sp[1]) == -1){
			fmtpkt(c, "ERR bad new hash %s\n", sp[1]);
			goto error;
		}
		/* and valid refs */
		if(!validref(sp[2])){
			fmtpkt(c, "ERR invalid ref %s\n", sp[2]);
			goto error;
		}
		/* and then remember them for when we do the update */
		*cur = erealloc(*cur, (*nupd + 1)*sizeof(Hash));
		*upd = erealloc(*upd, (*nupd + 1)*sizeof(Hash));
		*ref = erealloc(*ref, (*nupd + 1)*sizeof(Hash));
		(*cur)[*nupd] = old;
		(*upd)[*nupd] = new;
		(*ref)[*nupd] = estrdup(sp[2]);
		*nupd += 1;
	}
</pre>

<p>Next, the client uploads the pack. This is a blob containing
the commit data. It goes into <code>.git/objects/packs/recv-$pid.pack</code>,
at least until we can index it and rename it.</p>

<pre>	while(1){
		n = read(c-&gt;rfd, buf, sizeof(buf));
		if(n == 0)
			break;
		if(n == -1 || write(pfd, buf, n) != n)
			return -1;
		packsz += n;
	}
	if(checkhash(pfd, packsz, &amp;h) == -1){
		dprint(1, "hash mismatch\n");
		goto error1;
	}
	if(indexpack(packtmp, idxtmp, h) == -1){
		dprint(1, "indexing failed\n");
		goto error1;
	}
	if(rename(packtmp, idxtmp, h) == -1){
		dprint(1, "rename failed: %r\n");
		goto error2;
	}
</pre>

<p>Finally, we update the references. Note that we haven't
locked the repository yet. This is because none of the data
we have here can conflict: All objects are addressed by hash,
so a race would simply leave us with a duplicate hash in the
packfile. Eventually, a <code>git/repack</code> will clean
that up.</p>

<p>However, updating the references can conflict. So,
for updating the references, we acquire a lock file.
We then read all the references, make sure that they
match the old reference, and then write in the new
reference.</p>

<pre>	for(i = 0; i &lt; nupd; i++){
		if(resolveref(&amp;h, ref[i]) == 0 &amp;&amp; !hasheq(&amp;h, &amp;cur[i])){
			fmtpkt(c, "ERR old ref changed: %s", ref[i]);
			goto error;
		}
		if((o = readobject(upd[i])) == nil){
			fmtpkt(c, "ERR update to nonexistent hash %H", upd[i]);
			goto error;
		}
		if(o-&gt;type != GCommit){
			fmtpkt(c, "ERR not commit: %H", upd[i]);
			goto error;
		}
		unref(o);
		if(snprint(refpath, sizeof(refpath), ".git/%s", ref[i]) == sizeof(refpath)){
			fmtpkt(c, "ERR ref path too long: %s", ref[i]);
			goto error;
		}
		if((fd = create(refpath, OWRITE, 0644)) == -1){
			fmtpkt(c, "ERR open ref: %r");
			goto error;
		}
		if(fprint(fd, "%H", upd[i]) == -1){
			close(fd);
			fmtpkt(c, "ERR upate ref: %r");
			goto error;
		}
		close(fd);
	}
</pre>

<p>And that's pushing.

</p><h3>pulling</h3>

<p>Pulling takes more work on the server side, because the
server needs to compute a reasonable packfile to send to
the client. The protocol itself is still fairly simple.</p>

<p>It begins the same way as pushing, by sending all the
branches that a client may want to obtain from the git
repository.</p>

<pre>=r=&gt; 013b:	"dc802c499dc7164aa208b919a07c5bd18701b0e1 HEAD\n"
=r=&gt; 003f:	"dc802c499dc7164aa208b919a07c5bd18701b0e1 refs/heads/master\n"
=r=&gt; 0000
</pre>

<p>The client then starts telling us what commits they want,
and what commits they have. This lets us find a graph difference
between the server and client graph, and generate a pack file
that contains few, if any, extraneous commits. </p>

<pre>&lt;=w= 0032:	"want 5d761590cfdce23e4b17e94050b0776c8804d4a1\n"
&lt;=w= 0032:	"want 8f0eb1386a2c748cb7bf26917684479ff8c6d5b5\n"
&lt;=w= 0032:	"want dc4a9d467c6a28dab3927c8611a1bfbc571f1568\n"
&lt;=w= 0000
&lt;=w= 0033:	"have dc802c499dc7164aa208b919a07c5bd18701b0e1\n"
&lt;=w= 0009:	"done\n"
=r=&gt; 0031:	"ACK dc802c499dc7164aa208b919a07c5bd18701b0e1\n"
</pre>

<p>Computing the commits that go into a pack is not always trivial.
The comits that the client may be on may have "bubbles" in the graph,
so simply walking back from the start of the graph to the commits
that the client has may end up walking around the commit, leading
to nearly the whole history of the repository being sent, instead
of just one or two commits.</p>

<p>Consider a repo where the server is ahead of the client, and
now the client is trying to pull the changes. The client has commits
<code>c</code>, and we're trying to compute a pack with only the
commits <code>o</code>.</p>


<pre>                o---o
               /     \
    --c---c---c---c---o---o &lt;-- server
                  ^
                client
</pre>

<p>The client does a git/pull, and sends that it has the
commit marked <code>[c]</code>. Since the server has
every commit the client does, and more, it can look at
all ancestors of the client commit. If we're smart, we
would, but a naive …</p></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://orib.dev/gitserve.html">https://orib.dev/gitserve.html</a></em></p>]]>
            </description>
            <link>https://orib.dev/gitserve.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24425114</guid>
            <pubDate>Wed, 09 Sep 2020 19:47:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Dolt, a SQL database with Git-like functionality, implements push and pull]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24424593">thread link</a>) | @reltuk
<br/>
September 9, 2020 | https://www.dolthub.com/blog/2020-09-09-push-pull-on-a-merkle-dag/ | <a href="https://web.archive.org/web/*/https://www.dolthub.com/blog/2020-09-09-push-pull-on-a-merkle-dag/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-cy="blog-post-text"><p><a href="https://www.github.com/liquidata-inc/dolt">Dolt</a> is a SQL database
with Git-like functionality, including branch, merge and diff and push
and pull to remotes. This is a post in a series of posts about the
internal workings of some of the core algorithms that underly Dolt's
implementation. The previous posts in this series were about:</p>
<ol>
<li><a href="https://www.dolthub.com/blog/2020-04-01-how-dolt-stores-table-data/">The Prolly-tree</a>,
a unique content-address indexed data structure that underlies Dolt's table storage.</li>
<li><a href="https://www.dolthub.com/blog/2020-05-13-dolt-commit-graph-and-structural-sharing/">The Commit Graph</a>
and structural sharing in Dolt's table storage.</li>
<li><a href="https://www.dolthub.com/blog/2020-06-16-efficient-diff-on-prolly-trees/">Dolt's Diff Implementation</a></li>
<li><a href="https://www.dolthub.com/blog/2020-07-15-three-way-merge/">Dolt's Merge Implementation</a></li>
</ol>
<p>In this post, we explore the Merkle DAG structure underlying Dolt's
commit graph and table storage a little more, and investigate how push
and pull to remote repositories is implemented in Dolt.</p>
<h2>Overview</h2>
<p>A Dolt repository contains any number of branches and tags, where each
branch or tag is a top-level reference to a particular commit. A
commit, in turn, points to a value of the database at that commit, and
0 or more parent commits. All data in the repository, the commits and
the table data, is stored in content-addressed <code>Chunk</code>s which in turn
can contain references to other <code>Chunk</code>s, forming a <a href="https://en.wikipedia.org/wiki/Merkle_tree">Merkle
DAG</a>. This was the example
of a three commit branch from our previous blog post on the commit
graph:</p>
<p><span>
      <a href="https://www.dolthub.com/blog/static/cbb97ed1114403fc268e56a4a12c67c1/4597d/dolt-commit-graph.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="Dolt Commit Graph" title="Dolt Commit Graph" src="https://www.dolthub.com/blog/static/cbb97ed1114403fc268e56a4a12c67c1/4597d/dolt-commit-graph.png" srcset="https://www.dolthub.com/blog/static/cbb97ed1114403fc268e56a4a12c67c1/a48b3/dolt-commit-graph.png 214w,
https://www.dolthub.com/blog/static/cbb97ed1114403fc268e56a4a12c67c1/47730/dolt-commit-graph.png 428w,
https://www.dolthub.com/blog/static/cbb97ed1114403fc268e56a4a12c67c1/4597d/dolt-commit-graph.png 631w" sizes="(max-width: 631px) 100vw, 631px" loading="lazy">
  </a>
    </span></p>
<p>And this was the example of how the data in a single table might be
broken down:</p>
<p><span>
      <a href="https://www.dolthub.com/blog/static/8b22553d249aa55cec98241019cf0d15/4ee7f/dolt-table-value.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="Dolt Table Value" title="Dolt Table Value" src="https://www.dolthub.com/blog/static/8b22553d249aa55cec98241019cf0d15/4ee7f/dolt-table-value.png" srcset="https://www.dolthub.com/blog/static/8b22553d249aa55cec98241019cf0d15/a48b3/dolt-table-value.png 214w,
https://www.dolthub.com/blog/static/8b22553d249aa55cec98241019cf0d15/47730/dolt-table-value.png 428w,
https://www.dolthub.com/blog/static/8b22553d249aa55cec98241019cf0d15/4ee7f/dolt-table-value.png 486w" sizes="(max-width: 486px) 100vw, 486px" loading="lazy">
  </a>
    </span></p>
<p>Dolt supports remotes, which means it can clone, push and pull branch
and tag references from a Dolt repository stored in
<a href="https://www.dolthub.com/">Dolthub</a> or in cloud storage like <a href="https://aws.amazon.com/s3/">AWS
S3</a> or <a href="https://cloud.google.com/storage">Google Cloud
Storage</a>. This blog post briefly
explores what Dolt remotes are and how they operate under the hood.</p>
<h2>A Dolt Remote</h2>
<p>A Dolt repository can have multiple remote repositories configured,
and each of these repositories can be fetched from and pushed to
separately. Each configured Dolt remote consists of three pieces of
configuration within a Dolt repository:</p>
<ol>
<li>The name of the remote. After a clone, this will be <code>origin</code>.</li>
<li>Configuration for a networked endpoint that implements a network
protocol that Dolt can use as a remote. Most commonly, this is the
GRPC API exported by <a href="https://doltremoteapi.dolthub.com/">https://doltremoteapi.dolthub.com</a> and a
Dolthub repository path like <code>Liquidata/image-net</code>.</li>
<li>Default fetch specs for the remote. After a clone, this will be
<code>refs/heads/*:refs/remotes/origin/*</code>, and most users never need to
interact directly with fetch specs.</li>
</ol>
<p>The fetch spec is the subtlest piece of the configuration, but it's
also fundamental to the way that remotes actually work. The above
fetch spec says: When we <code>fetch</code> from <code>origin</code>, create a new <code>ref</code> in
<code>refs/remotes/origin/...</code> for each ref we find in the remote at
<code>refs/heads/...</code>. <code>refs/heads/...</code> will be all the branches in the
remote, and so fetching from the remote will create corresponding refs
in our local repository for each branch in the remote repository. If
the remote had the branches <code>main</code>, <code>bh/agi</code> and <code>aaron/by-zip</code>, and
we fetched from it, Dolt would create the refs
<code>refs/remotes/origin/main</code>, <code>refs/remotes/origin/bh/agi</code> and
<code>refs/remotes/origin/aaron/by-zip</code>, each pointing at the corresponding
commits that the remote branches were pointing at when we ran the
<code>fetch</code>.</p>
<p>So the remotes <code>ref</code>s namespace is seperate from our local branches
namespace, and Dolt is keeping a copy of the branches that we fetch
from the remote locally. The only time that copy is updated, and the
only time we reference the remote generally, is when we run <code>dolt
fetch</code> (or <code>dolt pull</code>, which does a <code>fetch</code> and then <code>merge</code>). And
the fundamental operation involved in a <code>fetch</code> is:</p>
<ol>
<li>Contact the remote to list all the branches we will clone.</li>
<li>For each branch we will clone, update our local repository to
contain the referenced Commit <code>Chunk</code> and all <code>Chunk</code>s reachable from
it.</li>
<li>Set a corresponding <code>ref</code> in our local repository to point to the
newly fetched Commit <code>Chunk</code>.</li>
</ol>
<p>Step #2 is where all the missing data actually gets copied into our
local repository. Let's take a look at exactly how that happens.</p>
<h2>Chunk Stores and DAG Traversals</h2>
<p>As mentioned above, all the data in the repository, both Commits and
the table data, is stored in these content-addressed variable sized
blocks called <code>Chunk</code>s. A storage abstraction exists in the Dolt
storage layer called a <code>ChunkStore</code>, which is a place where we can
read, and potentially write, chunks.</p>
<div data-language="go"><pre><code><span>package</span> chunk

<span>type</span> Address <span>[</span><span>20</span><span>]</span><span>byte</span>

<span>type</span> Chunk <span>interface</span> <span>{</span>
    
    <span>Refs</span><span>(</span><span>)</span> <span>[</span><span>]</span>Address
    
    <span>Bytes</span><span>(</span><span>)</span> <span>[</span><span>]</span><span>byte</span>
<span>}</span>

<span>type</span> Store <span>interface</span> <span>{</span>
    <span>Has</span><span>(</span>addr Address<span>)</span> <span>bool</span>
    <span>Get</span><span>(</span>addr Address<span>)</span> Chunk
    <span>Put</span><span>(</span>contents Chunk<span>)</span>
<span>}</span></code></pre></div>
<p>We can create a <code>Store</code> implementation for a remote repository which
is hosted in DoltHub, and we have a <code>Store</code> implementation for our
local repository as well. A simple recursive DAG walk to copy a given
commit (or any <code>Chunk</code> with all of its children) into our local
repository looks like:</p>
<div data-language="go"><pre><code><span>func</span> <span>CopyChunks</span><span>(</span>to<span>,</span> from Store<span>,</span> a Address<span>)</span> <span>{</span>
	<span>if</span> <span>!</span>to<span>.</span><span>Has</span><span>(</span>a<span>)</span> <span>{</span>
		c <span>:=</span> from<span>.</span><span>Get</span><span>(</span>a<span>)</span>
		<span>for</span> <span>_</span><span>,</span> r <span>:=</span> <span>range</span> c<span>.</span><span>Refs</span><span>(</span><span>)</span> <span>{</span>
			<span>Fetch</span><span>(</span>to<span>,</span> from<span>,</span> r<span>)</span>
		<span>}</span>
		to<span>.</span><span>Put</span><span>(</span>c<span>)</span>
	<span>}</span>
<span>}</span></code></pre></div>
<p>This approach already has some nice properties. Ideally, if a <code>Chunk</code>
is in a <code>Store</code>, all the <code>Chunk</code>s it references would also be in the
<code>Store</code>. We don't want our algorithm to persist any <code>Chunk</code>s to the
<code>Store</code> whose children we haven't already fetched and persisted,
because if the algorithm gets aborted halfway through the <code>Store</code>
could then be in an inconsistent state. So we're careful not to <code>Put</code>
the fetched <code>Chunk</code> until its children are persisted.</p>
<h2>Better Performance With Batching</h2>
<p>In Go, the recursion is not much of a concern because goroutines have
on-heap growable stacks. But if it is a concern, it's easy to
translate the call stack state into an explicit stack with on-heap
state as well.</p>
<p>The above algorithm has one glaring issue: it's very slow. If <code>from</code>
is a remote <code>Store</code>, then every <code>Get</code> is a round-trip RPC, and as
written there's no capacity for pipelining or batching. The simplest
solution is to make the batching explicit. We can give <code>Store</code> batch
methods, and make <code>CopyChunks</code> take a slice of <code>Address</code>es instead:</p>
<div data-language="go"><pre><code><span>type</span> Store <span>interface</span> <span>{</span>
    
    
    <span>HasMany</span><span>(</span><span>[</span><span>]</span>Address<span>)</span> <span>(</span>present<span>,</span> missing <span>[</span><span>]</span>Address<span>)</span>
    
    
    <span>GetMany</span><span>(</span><span>[</span><span>]</span>Address<span>)</span> <span>[</span><span>]</span>Chunk
    
    <span>PutMany</span><span>(</span><span>[</span><span>]</span>Chunk<span>)</span>
<span>}</span>

<span>func</span> <span>CopyChunks</span><span>(</span>to<span>,</span> from Store<span>,</span> as <span>[</span><span>]</span>Address<span>)</span> <span>{</span>
	<span>_</span><span>,</span> missing <span>:=</span> to<span>.</span><span>HasMany</span><span>(</span>as<span>)</span>
	chunks <span>:=</span> from<span>.</span><span>GetMany</span><span>(</span>missing<span>)</span>
	nextlevel <span>:=</span> <span>[</span><span>]</span>Address<span>{</span><span>}</span>
	<span>for</span> <span>_</span><span>,</span> c <span>:=</span> <span>range</span> chunks <span>{</span>
		nextlevel <span>=</span> <span>append</span><span>(</span>nextlevel<span>,</span> c<span>.</span><span>Refs</span><span>(</span><span>)</span><span>...</span><span>)</span>
	<span>}</span>
	<span>CopyChunks</span><span>(</span>to<span>,</span> from<span>,</span> nextlevel<span>)</span>
	to<span>.</span><span>PutMany</span><span>(</span>chunks<span>)</span>
<span>}</span></code></pre></div>
<p>That improves the round-trips for remote clones substantially and
allows for better bandwidth utilization. But it introduces two new
flaws.</p>
<ol>
<li>Memory usage is potentially unwieldy. In the batched version, we're
holding a potentially large number of <code>Chunk</code>s in memory at every call
to <code>CopyChunks</code>, and we're making a call to <code>GetMany</code> with an
unbounded number of <code>Address</code>es. Previously we were only holding one
<code>Chunk</code> in memory at each level of the call.</li>
<li>It potentially fetches the same <code>Chunk</code>s from <code>from</code> multiple
times. Two different length paths through the DAG to the same <code>Chunk</code>
will have <code>to.HasMany()</code> returning <code>missing</code> for the same <code>Chunk</code>
multiple times, with consequent calls to <code>GetMany()</code> with the same
addresses.</li>
</ol>
<p>Addressing those actually gets somewhat complicated. In Dolt, for #1
we form explicit RPC batches and write the fetched <code>Chunk</code>s to
temporary chunk files so that they don't have to stay in memory. The
temporary files are constructed so that they can be cheaply integrated
into the <code>to</code> <code>Store</code> when all their dependencies are
persisted. Addressing #2 involves adding a little bit of book keeping
across recursive calls.  But perfect behavior with regards to case #2
is actually a tradeoff between the batch sizes and memory usage. Once
the chunk from a higher level leaves memory and goes into the
temporary chunk file, it needs to be refetched from the remote or from
the disk in order to be incorporated in the <code>to</code> <code>Store</code> earlier than
its peers.</p>
<h2>Fetch and Push</h2>
<p>It's neat that the above algorithm works great whether operation is a
<code>push</code> or a <code>fetch</code>. If the remote <code>Store</code> is <code>from</code>, we're doing a
<code>fetch</code> and we will get new chunks from the remote into our local
<code>Store</code>. But we can also make the remote <code>Store</code> <code>to</code>, in which case
its a <code>push</code>—the remote <code>Store</code> gets the new <code>Chunk</code>s that were
unique to our local <code>Store</code>. In either case, once all the <code>Chunk</code>s are
persisted in the <code>to</code> <code>Store</code>, we can update any <code>refs</code> appropriately,
setting them to point to the newly persisted commit <code>Chunk</code>s based on
the operation we're performing and the fetch/push specs as
appropriate.</p>
<h2>Conclusion</h2>
<p>Dolt remotes are a powerful feature that allows for data
synchronization, collaboration and easily maintaining local changes
while tracking upstreams. Underlying the feature is a simple model for
how to build up the commit graph and the table data as a merkle DAG of
content addressed chunks. Building on top of that model allows for
<code>push</code> and <code>fetch</code> to be both be implemented by the same elegant DAG
walk. At the same time, practical engineering and performance concerns
introduce an opportunity for tradeoffs and optimization. Hopefully
we've given you some insight into the ways that Dolt approaches and
solves the issues underlying its implementation.</p></div></div>]]>
            </description>
            <link>https://www.dolthub.com/blog/2020-09-09-push-pull-on-a-merkle-dag/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24424593</guid>
            <pubDate>Wed, 09 Sep 2020 19:06:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Zink (OpenGL on Vulkan) performance better than expected]]>
            </title>
            <description>
<![CDATA[
Score 161 | Comments 86 (<a href="https://news.ycombinator.com/item?id=24424462">thread link</a>) | @mfilion
<br/>
September 9, 2020 | http://www.supergoodcode.com/funday/ | <a href="https://web.archive.org/web/*/http://www.supergoodcode.com/funday/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <h2 id="just-for-fun">Just For Fun</h2>

<p>I finally managed to get a complete piglit run over the weekend, and, for my own amusement, I decided to check the timediffs against a reference run from the IRIS driver. Given that the Intel drivers are of extremely high quality (and are direct interfaces to the underlying hardware that I happen to be using), I tend to use ANV and IRIS as my references whenever I’m trying to debug things.</p>

<p>Both runs used the same base checkout from mesa, so all the core/gallium/nir parts were identical.</p>

<p>The results weren’t what I expected.</p>

<p>My expectation when I clicked into the timediffs page was that zink would be massively slower in a huge number of tests, likely to a staggering degree in some cases.</p>

<p>We were, but then also on occasion we weren’t.</p>

<p>As a final disclaimer before I dive into this, I feel like given the current state of people potentially rushing to conclusions I need to say that <strong>I’m not claiming zink is faster than a native GL driver</strong>, only that <strong>for some cases, our performance is oddly better than I expected</strong>.</p>

<h2 id="the-good">The Good</h2>
<p><img src="https://zmike.github.io/assets/piglit-misc-bench.png" alt="piglit-misc-bench.png"></p>

<p>The first thing to take note of here is that IRIS is massively better than zink in successful test completion, with a near-perfect 99.4% pass rate compared to zink’s measly 91%, and that’s across 2500 more tests too. This is important also since timediff only compares between passing tests.</p>

<p>With that said, somehow zink’s codepath is significantly faster when it comes to dealing with high numbers of varying outputs, and also, weirdly, a bunch of <code>dmat4</code> tests, even though they’re both using the same softfp64 path since my icelake hardware doesn’t support native 64bit operations.</p>

<p>I was skeptical about some of the numbers here, particularly the <code>ext_transform_feedback</code> <code>max-varying-arrays-of-arrays</code> cases, but manual tests were even weirder:</p>

<div><div><pre><code>time MESA_GLSL_CACHE_DISABLE=true MESA_LOADER_DRIVER_OVERRIDE=zink bin/ext_transform_feedback-max-varyings -auto -fbo

MESA_GLSL_CACHE_DISABLE=true MESA_LOADER_DRIVER_OVERRIDE=zink  -auto -fbo  2.13s user 0.03s system 98% cpu 2.197 total
</code></pre></div></div>

<div><div><pre><code>time MESA_GLSL_CACHE_DISABLE=true MESA_LOADER_DRIVER_OVERRIDE=iris bin/ext_transform_feedback-max-varyings -auto -fbo

MESA_GLSL_CACHE_DISABLE=true MESA_LOADER_DRIVER_OVERRIDE=iris  -auto -fbo  301.64s user 0.52s system 99% cpu 5:02.45 total
</code></pre></div></div>

<p>wat.</p>

<p>I don’t have a good explanation for this since I haven’t dug into it other than to speculate that ANV is just massively better at handling large numbers of varying outputs.</p>

<h2 id="the-bad">The Bad</h2>

<p>By contrast, zink gets thrashed pretty decisively in <code>arb_map_buffer_alignment-map-invalidate-range</code>, and we’re about <strong>150x slower</strong>.</p>

<p>Yikes. Looks like that’s going to be a target for some work since potentially an application might hit that codepath.</p>

<h2 id="the-weird">The Weird</h2>
<p><img src="https://zmike.github.io/assets/piglit-fp64-bench.png" alt="piglit-fp64-bench.png"></p>

<p>Somehow, zink is noticeably slower in a bunch of other fp64 tests (and this isn’t the full list, only a little over half). It’s strange to me that zink can perform better in certain fp64 cases but then also worse in others, but I’m assuming this is just the result of different shader optimizations happening between the drivers, shifting them onto slightly less slow parts of the softfp64 codepath in certain cases.</p>

<p>Possibly something to look into.</p>

<p>Probably not in too much depth since softfp64 is some pretty crazy stuff.</p>

<h2 id="in-closing">In Closing</h2>
<p>Tests (and especially piglit ones) are not indicative of real world performance.</p>

  </div></div>]]>
            </description>
            <link>http://www.supergoodcode.com/funday/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24424462</guid>
            <pubDate>Wed, 09 Sep 2020 18:56:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What are the legal issues around web scraping?]]>
            </title>
            <description>
<![CDATA[
Score 32 | Comments 18 (<a href="https://news.ycombinator.com/item?id=24424277">thread link</a>) | @neoflexycurrent
<br/>
September 9, 2020 | http://evan.law/2020/09/09/what-are-the-legal-issues-around-web-scraping/ | <a href="https://web.archive.org/web/*/http://evan.law/2020/09/09/what-are-the-legal-issues-around-web-scraping/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="page">
				<div id="content">
			
	<div id="primary">
		<main id="main">
			
<article id="post-5792" itemtype="https://schema.org/CreativeWork" itemscope="">
	<div>
		
		<!-- .entry-header -->

		
		<div itemprop="text">
			
<figure><p>
<iframe title="Web scraping - what are the legal issues? | Evan Brown" width="900" height="506" src="https://www.youtube.com/embed/YA4eDamJz24?feature=oembed" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
</p></figure>



<p>Web scraping is that activity where a party uses automated software to crawl the internet and copy data and other content, usually so that it can compile that together and make its own product offering.  This may be of concern to you because you are a company that does web scraping. Or you may be a web publisher and there are other parties that are scraping your content. Let’s examine some of the legal issues around web scraping.</p>



<h3>Breach of contract</h3>



<p>One of the questions that commonly arises around web scraping is whether the activity is a breach of contract. More specifically, the question is whether the use of automated software violates the terms of service of the website that is being scraped. You often see website terms of service prohibit the use of spider and other automated crawling software to access and use the site. Parties who own websites that are being scraped will often look to see whether the scraping of their site is a breach of contract. </p>



<h3>Copyright infringement</h3>



<p>Another common question arising when analyzing web scraping is lawful whether scraping constitutes copyright infringement. This is a difficult argument to make if all that is being scraped is data, because mere facts usually are not subject to copyright protection. But if there is other content being scraped, such as images or specific compilations of data, the question of copyright infringement becomes a bit easier to answer in that unauthorized copying is an likely an infringement.</p>



<h3>Computer Fraud and Abuse Act</h3>



<p>The <a href="https://www.law.cornell.edu/uscode/text/18/1030" target="_blank" rel="noreferrer noopener">Computer Fraud and Abuse Act</a> is another topic that often comes up in discussions about web scraping. This is a federal law that makes it unlawful for a person to access a protected computer without authorization, or in excess of a specific authorization. So the question becomes whether that access by the automated web scraper violates the Computer Fraud and Abuse Act. There are some important things that have to be proven for a plaintiff to succeed under the Computer Fraud and Abuse Act, and one of those is loss or damage that results from the unauthorized access. It is a very fact intensive inquiry that has to be made,  but the Computer Fraud and Abuse Act is one thing that parties should think about in the context of web scraping. </p>



<h3>Trade secrets</h3>



<p>The question of trade secrets is another good one to raise in the context of web scraping. A trade secret is any information that a company has that gives that company a commercial advantage in the marketplace because it is secret. The information also has to be the subject of protective efforts — the company has to try to keep the information secret. For example, if information on a website is put there in a way that is behind certain protective barrier,s and the party doing the scraping circumvents those barriers, it could be that there is a misappropriation of trade secrets, particularly if that information is used for some competitive purpose. </p>



<h3>Let’s talk</h3>



<p>Web scraping legal issues can be complex. Scraping presents certain legal risks to the ones doing it, and the law provides certain powerful remedies when web scraping runs afoul of the rules. If you have questions about web scraping, give me a call at (630) 362-7237, or send me an email at <a href="mailto:ebrown@internetcases.com" target="_blank" rel="noreferrer noopener">ebrown@internetcases.com</a>. </p>



<h3>About the author</h3>



<p>Evan Brown is a technology and intellectual property attorney in Chicago. This content originally appeared on <a href="http://evan.law/">evan.law</a>. </p>



<h3>See also:</h3>



<ul><li><a href="http://evan.law/2018/11/19/web-scraping-case-fails-under-dastar/" target="_blank" rel="noreferrer noopener">Web scraping case fails under Dastar</a></li><li><a href="http://evan.law/2012/11/01/terms-of-service-data-scraping/" target="_blank" rel="noreferrer noopener">Online terms of service were not effective to prohibit data scraping</a></li><li><a href="http://evan.law/2005/04/06/forum-selection-clause-upheld-in-content-scraping-case/" target="_blank" rel="noreferrer noopener">Forum selection clause upheld in content scraping case</a></li></ul>
		</div><!-- .entry-content -->

					<!-- .entry-meta -->
			</div><!-- .inside-article -->
</article><!-- #post-## -->

					

							</main><!-- #main -->
	</div><!-- #primary -->

	<!-- #secondary -->

	</div><!-- #content -->
</div></div>]]>
            </description>
            <link>http://evan.law/2020/09/09/what-are-the-legal-issues-around-web-scraping/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24424277</guid>
            <pubDate>Wed, 09 Sep 2020 18:43:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Hoarding critical knowledge is a way to stay employed]]>
            </title>
            <description>
<![CDATA[
Score 13 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24423857">thread link</a>) | @qrt
<br/>
September 9, 2020 | https://qatalog.com/blog/post/got-knowledge | <a href="https://web.archive.org/web/*/https://qatalog.com/blog/post/got-knowledge">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://qatalog.com/blog/post/got-knowledge</link>
            <guid isPermaLink="false">hacker-news-small-sites-24423857</guid>
            <pubDate>Wed, 09 Sep 2020 18:02:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Leading a dev team with data and not being a tyrant]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 3 (<a href="https://news.ycombinator.com/item?id=24423702">thread link</a>) | @necco908
<br/>
September 9, 2020 | https://linearb.io/blog/data-driven-dev-team/ | <a href="https://web.archive.org/web/*/https://linearb.io/blog/data-driven-dev-team/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-id="670d84f7" data-element_type="widget" data-widget_type="theme-post-content.default">
				<div>
			
<figure><img src="https://linearb.io/wp-content/uploads/2020/09/1a-Blog-Data-Driven-Dev-team-1024x488.png" alt="" srcset="https://linearb.io/wp-content/uploads/2020/09/1a-Blog-Data-Driven-Dev-team-1024x488.png 1024w, https://linearb.io/wp-content/uploads/2020/09/1a-Blog-Data-Driven-Dev-team-300x143.png 300w, https://linearb.io/wp-content/uploads/2020/09/1a-Blog-Data-Driven-Dev-team-768x366.png 768w, https://linearb.io/wp-content/uploads/2020/09/1a-Blog-Data-Driven-Dev-team.png 1386w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<h3><strong>Stack ranking is natural human behavior&nbsp;</strong></h3>



<p>I have a buddy from high school named Murph. His real name is <a href="https://www.linkedin.com/in/bfelt/" target="_blank" rel="noreferrer noopener">Ben Felt</a> but every legit teenage crew in Pitsford, New York in the 90s needed a Murph so Ben took one for the team.&nbsp;</p>



<p>He’s a quant. Like Taylor Mason from the show Billions.&nbsp;</p>







<figure><img src="https://lh5.googleusercontent.com/aLSHkNWCVa3tsooRGsEIn_ePCfPbm8q76JG1IFkqXgNr5XQ9UDaadhEWwDWx6PmnYKQbYUg3RejrISynwYZy21haJKT_N8O12TRFNBojxdP37hpOO80kmOoRc-ViIo2AWv2cJboF" alt=""></figure>







<p>It would have been easy to predict Murph would end up as a big shot on Wall Street. For starters, he got a perfect 1600 score on his SATs and was accepted early admission to Yale.&nbsp;</p>



<p>There was also his unique approach to fantasy football. I’ve been playing with the same group of guys since 1999. We started in my Mom’s basement.&nbsp;</p>



<p>When it came time for draft day, the regular nerds in our group like me would bring fantasy football magazines with last year’s stats and analyst opinions.&nbsp;</p>



<p>Murph brought his computer. He wrote a program that organized his draft board based on each player’s predicted performance correlated to his personal skill preferences. This is years before Daryl Morey founded <a href="http://www.sloansportsconference.com/" target="_blank" rel="noreferrer noopener">Sloan Conference</a>. Murph was ahead of his time.&nbsp;</p>



<p>People naturally want to quantify objects by ranking them in lists of best to worst, most expensive to least expensive, most important to least important. We do this throughout our personal and professional lives. Often subconsciously before we even realize we’re doing it.&nbsp;</p>



<p>Sometimes it makes sense to rank objects by performance. Like ranking athletes in your fantasy league. Murph won our league multiple times using his ranking algo.&nbsp;</p>



<p>Sometimes it even makes sense to rank real people by performance. Like on a sales team where there is a relatively direct link between the contribution of a sales rep and the outcomes (e.g. new customer, revenue) they deliver.</p>



<p><strong>When it comes to members of your dev team, it does not make sense to rank them using personal performance statistics.&nbsp;</strong></p>







<hr>



<div><figure><a href="https://linearb.io/trial/" target="_blank" rel="noopener noreferrer"><picture>
<source type="image/webp" srcset="https://linearb.io/wp-content/uploads/2020/09/CTACharacter.png.webp 502w" sizes="(max-width: 502px) 100vw, 502px">
<img src="https://linearb.io/wp-content/uploads/2020/09/CTACharacter.png" alt="" srcset="https://linearb.io/wp-content/uploads/2020/09/CTACharacter.png 502w, https://linearb.io/wp-content/uploads/2020/09/CTACharacter-202x300.png 202w" sizes="(max-width: 502px) 100vw, 502px">
</picture>
</a></figure></div>



<hr>







<h3><strong>Running a data-driven team does not mean stack ranking developers&nbsp;</strong></h3>



<p>A software development team is less like a sales team and more like a band. Everyone is highly dependent on one another to deliver a great result. If one person is off, it throws everyone off. And, like in a band, there are often unsung heroes (like the bass player or drummer) who make it possible for other stars (like the lead singer) to shine.&nbsp;&nbsp;</p>







<figure><img src="https://lh6.googleusercontent.com/-cqrL_fBle6dxY8DlVUhtTWbh54DZMympB2IVKA4EfMFLQ5y712qgwgXxHwVAsZH_8cxd3MCAmoRRGoIkbrpFVtpDrjTIWQqXjFijyhLLF2eRgjvCJmP7--6FkGXpmFnheNvtZyJ" alt=""></figure>







<p>The contributions of your most selfless team members may not show up if you just look at lines of code, number of commits or personal story point velocity.</p>



<p>The other big reason not to stack rank your devs is that they just don’t like it. Unlike sales people, your engineers did not sign up to work in a hyper competitive environment.</p>



<p>So why does stack ranking still happen? Some would say bad managers are the culprit. That’s probably true sometimes. Many bad managers want control and pitting teammates against each other in competition is certainly one way to get it.&nbsp;</p>



<p>Most of the time the reason is more nuanced. I believe most managers have good intentions and want their people to succeed. But they get caught in the “data-driven trap.”</p>



<p>I hear it from engineering leaders every day… “My CEO wants me to be more data-driven” or “Our company is rolling out a metrics initiative.” Pressure to become data-driven can lead to arbitrary use of data to show the boss metrics are being used. “Let’s use data to make better decisions” gets confused as “let’s use data for performance management.”</p>



<p>When this misconception occurs, one of two things happens. Performance stack ranking metrics are implemented and it damages the team culture. Or the manager knows performance management is bad and avoids using metrics all together. Both are bad outcomes for the team.&nbsp;</p>



<p><strong>You can run a highly data and metrics-driven dev organization with absolutely zero performance management statistics.&nbsp;</strong></p>







<h3><strong>Data-driven engineering leadership anti-patterns</strong></h3>



<p>To avoid the “data-driven trap”, watch out for these 5 anti-patterns:&nbsp;</p>







<p><strong>Not knowing your “why”</strong></p>



<p>Without the “why”, the metrics themselves can become the outcome everyone cares about instead of being an indicator of the actual outcome you are trying to achieve like faster innovation, more predictable delivery dates, happier customers, etc.&nbsp;</p>







<p><strong>Only measuring individual stats</strong></p>



<p>As leaders we preach that we’re all working together as a band (team) to make beautiful music. What we measure shows what matters to us. If we track tons of individual metrics, we’re showing our people that individual stats matter more than team accomplishments. To get around this, I’ve actually seen some engineering leaders maintain secret dashboards with individual performance data. Their rationale is that it’s helpful for management as long as its existence does not get out. Everything always comes out eventually so I don’t recommend this. Plus, if you’re measuring something you don’t want your team to know about, that’s a good indicator you’re measuring the wrong thing.&nbsp;</p>







<p><strong>Focusing on just 1 or 2 metrics&nbsp;</strong></p>



<p>I can’t tell you how many dev leads I meet that look only at velocity to determine the success of an iteration. <a href="https://linearb.io/blog/why-agile-velocity-is-the-most-dangerous-metric-for-software-development-teams/" target="_blank" rel="noreferrer noopener">Even if you think velocity is a useful indicator (I don’t)</a>, there is no silver bullet. Without a balanced approach to measuring each area of your team and process, it’s easy to lose sight of the big picture. For example, if you just focus on data that measures your delivery speed, you could encourage behavior that has a negative effect on quality.&nbsp;</p>







<p><strong>Thinking your new hammer (data) works for every nail (problem)&nbsp;</strong></p>



<p>When we first start experiencing how powerful data can be as a tool to quantify trends and diagnose problems, it’s really exciting. And this is precisely when we need to be careful. We can’t forget to seek out input from our people too. Reports and dashboards are at their best when they prompt penetrating questions and point us in the right direction. We can’t get lazy and base decisions exclusively on the numbers.&nbsp;</p>







<p><strong>Just using metrics that are easily available&nbsp;</strong></p>



<p>“Let’s use velocity to measure team performance. We get it from our project management system automatically.” Pulling the data you really need can be an initial large lift but the benefit overtime will pay back 100x. And it’s actually worse to force the wrong metrics than to use none at all.</p>







<h3><strong>14 ways to use data in your daily dev team practices without being a performance tyrant</strong></h3>



<p>Forget about individual performance management stats. There are many other ways to incorporate data into your team’s day to day routine that will have a positive impact on delivery efficiency, quality and predictability and actually improve your culture, not hurt it.&nbsp;</p>



<p>So what should we measure?&nbsp;</p>



<p>When I was a team lead, I answered that question for myself by taking a step back and looking at my personal leadership responsibility areas. After analyzing all of my important jobs, I found that they fit into three pillars.&nbsp;</p>







<figure><img src="https://lh5.googleusercontent.com/13hUMY4HlnRRfrtmq4bMgYWOYBAHk95xsSDCvXbi7FRgNp7vUckkpkgFONefECxyU7deWyn46tOXd6QKnSNvrbKGwuiRzlS8hOFbKe1mhwgHXrXW6GxPUTRFTQzgWSXS-BkB67e0" alt=""></figure>







<p>These pillars became my “why”. So instead of starting with metrics and looking for a place to apply them, I looked for data that would help me understand and improve these areas.&nbsp;</p>



<p>Here’s 14 ways we use data to run our team on a day-to-day basis at <a href="https://linearb.io/" target="_blank" rel="noreferrer noopener">LinearB</a>.&nbsp;</p>







<h4><strong>How we use data to accelerate project delivery</strong></h4>



<p>Project delivery is highly complicated because of the number of things happening in parallel. Even if your team is only 6-8 people. Technology, time constraints, priority shifts, developers, business stakeholders, customers… The only way to see across all of these dimensions is with data. Better yet, visual representations of data help distill complex things into manageable views and show you where to look and how to invest your time.&nbsp;</p>







<p><strong>1. Pull request throughput</strong></p>



<p>My friend <a href="https://linearb.io/coffee-talk/" target="_blank" rel="noreferrer noopener">Chris Downard</a>, the VP of Engineering at GigSmart, put it well.&nbsp;</p>



<p><em>“Knowing what to measure starts with aligning your team around what’s important to the business. In most companies, they want the dev team to deliver new value. So I care about metrics that are proxies for value delivery. I lean on merge requests because it helps me see throughput for work related to new features and bug fixes.”&nbsp;</em></p>



<p>We use our PR throughput dashboard the exact same way on our team. We like to see that the ratio of PRs opened to PRs merged stays in the 90-95% range otherwise we know we have a bottleneck in review.&nbsp;</p>







<figure><a href="https://linearb.io/get-started-linearb/" target="_blank" rel="noopener noreferrer"><img src="https://lh3.googleusercontent.com/dHWqhiCedjAb52oN1VY0S8uFUZ1cR7gJcHRrcRWQbb84XouHrTD21sRih0oQz9SwhywEdmp6ZHTaJ6niGMnWxReoMigGIieLXM2glZ5CUkCqc1HBGIrKM1vc7FKWCZCsBaTBqkwC" alt=""></a></figure>







<p><strong>2. Stuck pull requests&nbsp;</strong></p>



<p>We look for A) PRs that have not been picked up for review, B) PRs that have abnormally high back and forth interaction and C) PRs with long review time.&nbsp; Then we alert the team to these in Slack so we can start a conversation about how to help and click through to the PR directly in Git.&nbsp;</p>







<figure><a href="https://linearb.io/get-started-linearb/" target="_blank" rel="noopener noreferrer"><img src="https://lh5.googleusercontent.com/1JL97AoLYrbimIpkxfT405N-FxrCieSqchuaEn2Dh6dwlRe5OYYBCX6TlpsUDIQiSHiEtQPsa9Sl_iJRDS2845EB4DyMUm03OvDba3_ASMiKaBe7ToucIUMAgyhFZYPjD6ICAywB" alt=""></a></figure>







<p>We implemented this in <a href="https://linearb.io/blog/dev-productivity-is-way-down-at-linearb/" target="_blank" rel="noreferrer noopener">March when work-from-home started</a> and it’s become a critical part of our delivery process. Our devs love it because it’s one less thing they need to remember and they can jump in and help teammates more easily.&nbsp;</p>







<p><strong>3. PRs merged without review</strong></p>



<p>Our team is great about reviews but occasionally things slip. Flagging large PRs that have been merged without review has helped us catch a lot of mistakes before customers found them.&nbsp;</p>







<figure><a href="https://linearb.io/get-started-linearb/" target="_blank" rel="noopener noreferrer"><img src="https://lh4.googleusercontent.com/PsPxncxslm2V2acQox3pnFiR_nULYXN8FCXnvxjD-JLlVSiihieUMDayOELHpubE5aZ45QonVchJt9WhrDdD_M2TMyBlGCAp96lhU0BGVI2pzkRM6CB_j_pP4YivthPHVqgXs26N" alt=""></a></figure>







<p><strong>4. High risk branches</strong></p>



<p>About 15 months ago we analyzed all of our bugs and found a connection between bugs and large branches with a high rate of immediate rework (more than 30%). So now we look for those branches proactively and use our Slack alerts to get another set of eyes on them for review.&nbsp;</p>







<figure><a href="https://linearb.io/get-started-linearb/" target="_blank" rel="noopener noreferrer"><img src="https://lh6.googleusercontent.com/XuW12YJqhGmUTkMDRueIlTudnmil0P7uElElddlcDcc17COKUaporHhX7XhljQrRTWnjc2F1eHK1enijyKwIcppaIDnVnFpngbWYBYvslH0QI8U7W3uAK0-883deZ28d9cCN58Qq" alt=""></a></figure>







<hr>











<hr>







<p><strong>5. Days remaining to open work ratio&nbsp;</strong></p>



<p>We work in two week iterations. Once we’re about a week in, there’s a general equation our leads use to figure out if we’re on track to deliver the iteration: WIP + to-do ÷ days remaining = almost everything you need to know about whether or not you are going to finish on time.&nbsp;</p>







<figure><a href="https://linearb.io/get-started-linearb/" target="_blank" rel="noopener noreferrer"><img src="https://linearb.io/wp-content/uploads/2020/09/8-Data-Driven-Dev-team-v3-1024x488.png" alt="" srcset="https://linearb.io/wp-content/uploads/2020/09/8-Data-Driven-Dev-team-v3-1024x488.png 1024w, https://linearb.io/wp-content/uploads/2020/09/8-Data-Driven-Dev-team-v3-300x143.png 300w, https://linearb.io/wp-content/uploads/2020/09/8-Data-Driven-Dev-team-v3-768x366.png 768w, https://linearb.io/wp-content/uploads/2020/09/8-Data-Driven-Dev-team-v3.png 1386w" sizes="(max-width: 1024px) 100vw, 1024px"></a><figcaption>Devboard Envy? <a href="https://linearb.io/get-started-linearb/" target="_blank" rel="noreferrer noopener">Get this one for free</a></figcaption></figure>







<p>Our dev team uses a board that shows our Github activity on a timeline with the Jira …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://linearb.io/blog/data-driven-dev-team/">https://linearb.io/blog/data-driven-dev-team/</a></em></p>]]>
            </description>
            <link>https://linearb.io/blog/data-driven-dev-team/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24423702</guid>
            <pubDate>Wed, 09 Sep 2020 17:50:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Panther Labs Raises $15M to Reinvent SIEM for Cloud-First Teams]]>
            </title>
            <description>
<![CDATA[
Score 9 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24423524">thread link</a>) | @jacknagz
<br/>
September 9, 2020 | https://blog.runpanther.io/series-a-funding/ | <a href="https://web.archive.org/web/*/https://blog.runpanther.io/series-a-funding/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            

            <figure>
                <img srcset="https://blog.runpanther.io/content/images/size/w300/2020/09/patrick-tomasso-tN7fJdTaU40-unsplash.jpg 300w,
                            https://blog.runpanther.io/content/images/size/w600/2020/09/patrick-tomasso-tN7fJdTaU40-unsplash.jpg 600w,
                            https://blog.runpanther.io/content/images/size/w1000/2020/09/patrick-tomasso-tN7fJdTaU40-unsplash.jpg 1000w,
                            https://blog.runpanther.io/content/images/size/w2000/2020/09/patrick-tomasso-tN7fJdTaU40-unsplash.jpg 2000w" sizes="(max-width: 800px) 400px,
                            (max-width: 1170px) 700px,
                            1400px" src="https://blog.runpanther.io/content/images/size/w2000/2020/09/patrick-tomasso-tN7fJdTaU40-unsplash.jpg" alt="Panther Labs Series A Funding">
            </figure>

            <section>
                <div>
                    <p>Today, we're pleased to announce our <a href="https://www.prnewswire.com/news-releases/panther-labs-raises-15m-series-a-to-reinvent-siem-for-cloud-first-security-teams-301126303.html">$15M Series A financing led by Lightspeed Venture Partners</a>! </p><p>With this latest round of funding, we can double-down on our mission to re-invent the SIEM for modern and cloud-focused security teams. We're also excited to welcome <a href="https://www.linkedin.com/in/ggupta/">Gaurav Gupta</a> to our board of directors. Gaurav brings 10+ years of experience as a product leader at Splunk and Elastic to our leadership team.</p><p>Security teams are struggling to manage the unprecedented scale and growth of data in the cloud. Panther operationalizes massive volumes of scattered and unstructured security logs into real-time Python detections and helpful analytics with SQL over structured data. This new data-driven, developer-centric paradigm will power security teams for the next 10 years.</p><p>Panther’s guiding product principles are:</p><ul><li><strong><strong><strong>Open</strong> </strong></strong>and transparent data processing and storage.</li><li><strong><strong><strong>Scalable </strong></strong></strong>serverless infrastructure designed for Petabyte-scale.</li><li><strong>Powerful</strong> Python detections to identify complex behaviors in real-time.</li></ul><p>Panther Community Edition is a fully functional and open source project for teams to get started with analyzing their log data and cloud security posture. For production-level deployments, Panther Enterprise offers advanced features around querying and data storage, the ability to pull SaaS log data, customizable RBAC and SSO integrations, and options for SaaS and self-hosted deployments.</p><p>One new feature we’re excited to announce in Panther Enterprise is an Indicator Search. This feature enables lightning-fast searches across all collected logs for IPs, domains, hashes, cloud-specific values like ARNs, and <a href="https://docs.runpanther.io/log-analysis/panther-fields">more</a>. This is made possible by the <a href="https://blog.runpanther.io/panther-database-as-service-modern-serverless-architecture/">Panther’s Data Lake</a>, which enables scalable storage for huge amounts of security data.</p><p>Try <a href="https://github.com/panther-labs/panther">Panther Community Edition</a> today and join the discussion on <a href="http://slack.runpanther.io/">Slack</a> to learn how teams are using Panther to prevent breaches at cloud-scale. Also check out our public roadmap that includes planned, in-progress, and recently launched features. </p><p><strong>We’re also hiring!</strong> If you’re interested in contributing to our mission, check out our <a href="https://boards.greenhouse.io/pantherlabs">open roles on Greenhouse</a>. Panther is a remote-friendly workforce and aims to foster a culture of diversity.</p><figure><img src="https://blog.runpanther.io/content/images/2020/09/Zoom-Sept-2020.png" alt="" srcset="https://blog.runpanther.io/content/images/size/w600/2020/09/Zoom-Sept-2020.png 600w, https://blog.runpanther.io/content/images/size/w1000/2020/09/Zoom-Sept-2020.png 1000w, https://blog.runpanther.io/content/images/size/w1600/2020/09/Zoom-Sept-2020.png 1600w, https://blog.runpanther.io/content/images/size/w2400/2020/09/Zoom-Sept-2020.png 2400w" sizes="(min-width: 720px) 720px"><figcaption>Our Team at Panther Labs</figcaption></figure>
                </div>
            </section>


            


        </article>

    </div>
</div></div>]]>
            </description>
            <link>https://blog.runpanther.io/series-a-funding/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24423524</guid>
            <pubDate>Wed, 09 Sep 2020 17:36:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Backup PostgreSQL to Cloud]]>
            </title>
            <description>
<![CDATA[
Score 17 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24423208">thread link</a>) | @Abishek_Muthian
<br/>
September 9, 2020 | https://abishekmuthian.com/backup-postgresql-to-cloud/ | <a href="https://web.archive.org/web/*/https://abishekmuthian.com/backup-postgresql-to-cloud/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>This post will help you with easy, cost-effective and secure way to backup your PostgreSQL database to cloud.</p><h3 id="create-local-scheduled-backup-of-postgresql-database">Create local scheduled backup of PostgreSQL database</h3><ol><li><p>Login as <em>postgres</em> user on the console (<a href="https://www.howtogeek.com/671422/how-to-use-tmux-on-linux-and-why-its-better-than-screen/" target="_blank">tmux</a> is recommended).</p></li><li><p>Create .pgpass file to access database without entering credentials manually.</p><pre><code>$ nano .pgpass
</code></pre></li><li><p>Enter the credentials in the following format. Making changes according to the host if necessary.</p><pre><code>localhost:5432:dbname:dbusername:dbpassword
</code></pre></li><li><p>Set permissions to the file. login_username will be <em>postgres</em>, if you are logged in as that user.</p><pre><code>$ chmod 600 .pgpass
$ chown login_username:login_username .pgpass
</code></pre></li><li><p>Set the environment variable in the <em>.profile</em> file. Where /var/lib/pgsql is the home directory for the user <em>postgres</em> in my setup.</p><pre><code>$ nano .profile

export PGPASSFILE='/var/lib/pgsql/.pgpass'
</code></pre></li><li><p>Test the login. Making changes according to host if necessary.</p><pre><code>$ psql -h localhost -U dbusername dbname
</code></pre></li></ol><h3 id="setup-restic">Setup Restic</h3><p>Restic is a free open-source backup program available for multiple distributions. <a href="https://github.com/restic/restic/releases/" target="_blank">Download</a> the one appropriate to your operating system, extract it, move it to <em>/var/lib/pgsql/bin/</em> (home directory of user <em>postgres</em>) as <em>restic</em>, make it executable and set the PATH to that folder.</p><pre><code>$ bzip2 -d restic_*_linux_amd64.bz2
$ mv restic_*_linux_amd64 /usr/bin/restic
$ chmod u+x /var/lib/pgsql/bin/restic

$ nano .profile

export PATH=$PATH:/var/lib/pgsql/bin
</code></pre><p>Creat <em>restic-pw.txt</em> file with password for encrypting the Postgres database dump.</p><pre><code>$ nano restic-pw.txt
[Enter the password for encryption]

$ chmod 600 restic-pw.txt
$ chown postgres:postgres restic-pw.txt
</code></pre><h3 id="setup-backblaze">Setup Backblaze</h3><p>Backblaze is a cloud storage service, offering easy encrypted end-to-end cloud backup solutions for home and business users.</p><p>For backing up our PostgreSQL database to their cloud, we will use their <a href="https://www.backblaze.com/b2/sign-up.html?referrer=abishekmuthian" target="_blank">B2 service</a> for backing up our
data via their API. <strong>First 10GB of storage on B2 is free as of this writing</strong>, but charges may apply when we download those data and so read the pricing details carefully.</p><p>Create a B2 account to get the following credentials and export them in <em>.bashrc</em>.</p><pre><code>$ nano .bashrc

export B2_ACCOUNT_ID="XXXXX"
export B2_ACCOUNT_KEY="XXXXX"
export RESTIC_REPOSITORY="b2:bucket-name"
export RESTIC_PASSWORD_FILE="restic-pw.txt"
</code></pre><h3 id="setup-a-cron-job-to-schedule-the-backup-and-upload">Setup a cron job to schedule the backup and upload</h3><p>Setup a cronjob to create a PostgresSQL database dump using <em>pg_dump</em> tool, here it is done every day at 23:00 hours and is upload to B2 at 00:00 hours.</p><pre><code>$ crontab -e

0 23 * * * pg_dump -U dbusername -w -F t dbname &gt; /var/lib/pgsql/db.tar
0 0 * * * . /var/lib/pgsql/.bashrc; /usr/bin/restic backup -q /var/lib/pgsql/db.tar
</code></pre><p>Note: Depending upon the size of your database, how often it changes, you might need to change the schedule for the cron job accordingly.</p><h3 id="verify">Verify</h3><p>Check the Backblaze portal to verify that the snapshot was created in our b2 bucket.</p><h3 id="downloading-the-backup">Downloading the backup</h3><p>We can download the backup using restic again, when we need it.</p><p>Get the snapshot-ID.</p><pre><code>$ restic -r b2:bucket-name snapshots
</code></pre><p>Restore the snapshot to a folder using the snapshot_ID.</p><pre><code>$ restic -r b2:bucket-name restore snapshot_ID -t /tmp/restic-restore
</code></pre><p>Note: When downloading the snapshot in another machine, requisite credentials for restic and b2 should be provided as discussed earlier.</p><h3 id="retrieving-the-postgres-dump">Retrieving the Postgres dump</h3><p>Postgres dump would be available in the folder where the snapshot was restored.</p><pre><code>$ cd /tmp/restic-restore
</code></pre><h3 id="restoring-the-postgres-dump">Restoring the Postgres dump</h3><p>Create a database of the same name after logging in as the database user.</p><pre><code>$ CREATE DATABASE dbname;
</code></pre><p>Use the <em>pg_restore</em> tool to restore the database from the dump.</p><pre><code>$ pg_restore --dbname=dbname --verbose db.tar
</code></pre><p>That’s all, now we can have a safe and reliable backup postgres database in the cloud. You can <a href="https://twitter.com/heavyinfo" target="_blank">tweet</a> to me for queries and share this if you found it useful.</p><h3 id="backblaze-entire-storage-backup-solutions-for-home-and-business">Backblaze entire storage backup solutions for Home and Business</h3><p>If you would like unlimited automated backup your entire computer storage instead, then Backblaze has solutions for home and businesses users. Check them out using my affiliate links.</p><p><a href="https://www.backblaze.com/cloud-backup.html#af9vgw" target="_blank">Backblaze unlimited cloud backup for home users</a>.</p><p><a href="https://www.backblaze.com/business-backup.html#af9vgw" target="_blank">Backblaze business backup</a>.</p></div></div>]]>
            </description>
            <link>https://abishekmuthian.com/backup-postgresql-to-cloud/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24423208</guid>
            <pubDate>Wed, 09 Sep 2020 17:12:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Classes are a way of writing higher order functions]]>
            </title>
            <description>
<![CDATA[
Score 114 | Comments 130 (<a href="https://news.ycombinator.com/item?id=24422547">thread link</a>) | @stopachka
<br/>
September 9, 2020 | https://stopa.io/post/250 | <a href="https://web.archive.org/web/*/https://stopa.io/post/250">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p><span><p>Joe and I recently <a href="https://twitter.com/stopachka/status/1295411936625074178" target="_blank">kicked off a re-read of SICP</a>. I can say that it is <em>the</em> most interesting textbook I have gone through. Imagine, you begin with just 4 or 5 constructs, and you end up building algebraic equation solvers, circuit simulators, and even logic programming languages. Because you start off with such few constructs, the added benefit is that you begin to see the fundamentally simple, shared essence in programming. </p><p>I wanted to give you one example that surprised me in the book. We tend to think that <strong>classes belong in a</strong> <strong>fundamentally different category</strong> <strong>from functions.</strong> </p><p>But are they so different? </p><p>For example, let’s say we have a class like this:</p><pre><code>class Person { 
  constructor(firstName, lastName) {
    this.fName = firstName; 
    this.lName = lastName;
  }
  getFullName() { 
    return this.fName + ' ' + this.lName;
  }
  setFirstName(firstName) {
    this.fName = firstName;
  }
}</code></pre><p>Well, if we think about it, this is really just a higher order function. a <code>Person</code> higher order function accepts arguments (constructor), and returns a list of functions that can manipulate those arguments (methods). We could write <code>Person</code> like this: </p><pre><code> function Person(firstName, lastName) {
  let fName = firstName; 
  let lName = lastName;

  function getFullName() { 
    return fName + ' ' + lName;
  }
  
  function setFirstName(firstName) { 
    fName = firstName
  }

  return function(method) { 
    switch (method) { 
      case 'getFullName': 
        return getFullName;
      case 'setFirstName': 
        return setFirstName;  
    }
  }
}</code></pre><p>Now, </p><pre><code>const person = new Person("Ben", "Bitdiddle")
person.getFullName()</code></pre><p>becomes</p><pre><code>const person = Person("Ben", "Bitdiddle")
person('getFullName')()</code></pre><p>Here, instead of invoking a method, we are “passing” a message. This is why by the way, many classic OO folks talk about object orientation really being about message passing.  </p><p>Yup, really. Classes are just higher order functions, which accept arguments (constructor) and return a list of functions that can manipulate those arguments (methods). </p><p>When you previously thought two concepts were different, but they turn out to be the same, you’re ripe to discover new ideas: you can find the deeper abstractions between them, apply ideas from across those seemingly different categories, and move between concepts more fluidly. So, not only are epiphanies like this fun, but they’re much more useful than you’d think. </p><p>If you liked this, there are a <em>ton</em> of similar epiphanies in the textbook. To experience it best, I suggest picking a partner and working through the book together.</p><p><em>Thanks to Daniel Woelfel, Alex Reichert, Jacky Wang for reviewing drafts of this essay</em></p></span></p></div></div></div>]]>
            </description>
            <link>https://stopa.io/post/250</link>
            <guid isPermaLink="false">hacker-news-small-sites-24422547</guid>
            <pubDate>Wed, 09 Sep 2020 16:16:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[No-Code vs. Pro-Code: A New Hope]]>
            </title>
            <description>
<![CDATA[
Score 91 | Comments 18 (<a href="https://news.ycombinator.com/item?id=24421767">thread link</a>) | @ochiba
<br/>
September 9, 2020 | https://journeyapps.com/engineering-blog/no-code-vs-pro-code-a-new-hope/ | <a href="https://web.archive.org/web/*/https://journeyapps.com/engineering-blog/no-code-vs-pro-code-a-new-hope/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
              <p>When it comes to building apps, no-code is having its moment. Typeform is a shining example of how no-code is well suited for simple use cases, and here at JourneyApps we use it extensively. However, therein lies the problem: No-code’s sweet spot is simple use cases. This limitation of no-code tools has been well analyzed. [<a href="https://journeyapps.com/blog/low-code-road-to-software-enlightenment-part-1/">1</a>][<a href="https://www.alexhudson.com/2020/01/13/the-no-code-delusion/">2</a>]</p>

<p>If you want to build more sophisticated custom software, you essentially have two options:</p>

<ol>
  <li>
    <p>Use a no-code/low-code tool and jump through nasty hoops to implement the sophisticated parts of your app — which most often means writing actual code that needs to conform to the constraints of the tool.</p>
  </li>
  <li>
    <p>Use pro-code tools such as Swift/Objective-C, or frameworks like Xamarin/MAUI, etc.</p>
  </li>
</ol>

<p><img src="https://journeyapps.com/assets/images/blog/2020-09-08-no-code-vs-pro-code-a-new-hope/1.png" alt="image"></p>

<p><em>Image: building anything beyond basic logic with a visual programming language ends up looking like this</em></p>

<h3 id="a-big-problem-that-needs-solving">A Big Problem That Needs Solving</h3>

<p>Both of the above approaches (using pro-code, or using a low-code platform’s pro-code extensibility) are time-consuming, although for different reasons. Both also require senior developer talent, while senior developers are as scarce as hen’s teeth.</p>

<p>The result is that many companies are highly constrained while executing on ambitious software and digital initiatives.</p>

<p>These are the companies that we serve. Enterprise developers have been building custom apps using code on JourneyApps since 2009.</p>

<p>Towards the end of 2019 we wanted to up the ante. We wanted to offer a new app development paradigm for companies with a large app backlog, especially where a big chunk of that backlog consisted of ambitious B2E and B2B apps.</p>

<p>We set two high level goals for ourselves: help companies write great software much more productively (especially those whose core focus is not software), and let them do this using modern software technologies and best practices, without the typical barriers.</p>

<h3 id="key-tenets-of-what-we-set-out-to-build">Key Tenets of What We Set Out to Build</h3>

<p>We decided that the best thing we could do was to build a next-generation IDE (as a complement to our full-stack app platform) that has the <strong>power and flexibility of pro-code</strong> at its core, but also has the high <strong>development velocity and easy adoption of no-code/low-code platforms</strong>.</p>

<p>From the start, we decided that some things are non-negotiable:</p>

<h4 id="1-coding-should-be-easy">1. Coding should be easy</h4>

<ul>
  <li>Creating a new app shouldn’t require any configuration or setup.</li>
  <li>Developers should be able to start coding immediately.</li>
</ul>

<h4 id="2-coding-should-have-a-fast-feedback-loop">2. Coding should have a fast feedback loop</h4>

<ul>
  <li>We will have a first-class IDE with real-time error checking, keyboard shortcuts, IntelliSense, etc.</li>
  <li>Developers should have access to a real debugger.</li>
  <li>We will have live, stateful hot reload on an actual device in development mode — not a time-consuming compile &amp; deploy process.</li>
</ul>

<h4 id="3-coding-in-the-ide-should-be-fun-and-relevant">3. Coding in the IDE should be fun and relevant</h4>

<ul>
  <li>We will not use a <a href="https://en.wikipedia.org/wiki/Domain-specific_language">DSL</a>: We will support open-source programming languages – preferably those with gradual typing.</li>
  <li>We will not use convoluted proprietary visual interfaces.</li>
  <li>We will not use a proprietary “app store”. Developers must be able to import open source packages.</li>
  <li>The IDE should be easily accessible to junior developers.</li>
</ul>

<h4 id="4-coding-should-be-as-efficient-as-possible">4. Coding should be as efficient as possible</h4>

<ul>
  <li>We will provide developers with powerful functionality that can be used with minimal lines of code, and customized as required. This will include things like bi-directional relational offline data sync, dozens of UI components including Excel-like data grids, full audit trails, a cross-platform BLE engine, to name just a few.</li>
  <li>We will offer full git support with either hosted git, or external git providers (e.g. GitHub)</li>
  <li>We will support unit testing.</li>
  <li>We will support multiple environments, with easy portability of changes as new versions of software are moved from one environment to the next.</li>
</ul>

<h4 id="5-there-should-always-be-an-escape-hatch">5. There should always be an escape hatch</h4>

<ul>
  <li>There will be APIs for everything.</li>
  <li>We will allow developers to easily mix in fully custom HTML in their UIs, and allow those custom HTML components to communicate bidirectionally with the rest of the frontend stack, when required.</li>
  <li>There will be a Node.js environment in our cloud backend where developers can build any custom backend functionality, without any configuration or setup.</li>
</ul>

<h4 id="6-the-platform-should-be-secure-by-design">6. The platform should be secure by design</h4>

<h3 id="a-foundational-decision-building-a-web-ide">A Foundational Decision: Building a Web IDE</h3>

<p>We were taking the time to figure out a new approach to app development from first principles, so we had to make big design decisions with significant trade-offs. One major early decision was whether to build a web-based IDE or an installable desktop IDE.</p>

<p>The obvious question is: “Why an IDE on the web?”. We strongly believe that the recent developments across browser technology, transpiled languages and new approaches to software development (such as declarative UI) have made it possible to not only reach a desktop-grade level of quality in a web IDE, but also capitalize on the inherent benefits of the web paradigm.</p>

<p>Using this approach, we would have an IDE that is evergreen, cross-platform, cross-device, backed by modern UI and most importantly, ready for the future. Oh, and there would be nothing to install. Perhaps the biggest win, however, would be our ability to innovate quickly due to the open nature of web technologies and how quickly they evolve.</p>

<p>We’ll discuss other key design decisions in separate posts.</p>

<h3 id="unveiling-the-solution">Unveiling the Solution</h3>

<p>Today, we’re incredibly proud to announce <a href="https://journeyapps.com/platform/oxide/">OXIDE</a>. It’s the fruit of a lot of hard work by the JourneyApps team over the past year.</p>

<p>OXIDE helps both junior and senior developers build sophisticated cross-platform apps using JavaScript or TypeScript, complemented by visual tools. Apps can run natively on mobile and desktop operating systems, or in the browser as PWAs. Under the hood, OXIDE uses CRDTs [<a href="https://blog.kevinjahns.de/are-crdts-suitable-for-shared-editing/">3</a>] to enable live co-editing in teams, and it is deeply integrated with both GitHub and npm. In OXIDE, developers can switch between visual editing and coding for UI layout and schema design. Developers also have access to a first-class code debugging tool.</p>

<p>OXIDE is a fundamental pillar of the broader JourneyApps platform. Therefore, all apps inherit other flagship JourneyApps technologies out of the box — technologies that have seen around 10 years of R&amp;D and battle-hardening:</p>

<ul>
  <li>All apps ship with an enterprise-grade BaaS, and it’s easy to integrate with other data sources (in part because the platform is not based on a DSL).</li>
  <li>All apps are offline-first: Data is automatically synced to user devices, and loaded from the local database on each view. Querying data is fast. This avoids complicated state management and/or query cache systems. (What happens when data volumes scale? The platform provides highly configurable <a href="https://docs.journeyapps.com/reference/container/introduction-to-sync-rules">selective syncing.</a>)</li>
  <li>Each app is automatically provisioned with a Node.js serverless compute environment so that developers of all skill levels can add server-side logic and functionality.</li>
  <li>Developers have access to a rich built-in UI component set that is designed to work with data, with very little development overhead. No tweaking of styles or adding event listeners and state management to each component — this is handled for you.</li>
</ul>

<p>In general, JourneyApps takes the complexity out of the development cycle. We take care of the hard problems of enterprise software development (hosting, offline data sync, mobile app builds, backend APIs, deployment tooling, audit trails, and more) so that developers can focus on core app requirements and maximize the rate of innovation at their companies.</p>

<p>Working in OXIDE looks like this:</p>

<p><img src="https://journeyapps.com/assets/images/blog/2020-09-08-no-code-vs-pro-code-a-new-hope/2.png" alt="image"></p>

<p>And here’s a view of a debugging session. The app can be seen on the bottom right (running on macOS), the Chrome developer tools on the top right, and OXIDE on the left:</p>

<p><img src="https://journeyapps.com/assets/images/blog/2020-09-08-no-code-vs-pro-code-a-new-hope/3.png" alt="image"></p>

<p>Try it out and let us know what you think — <a href="https://accounts.journeyapps.com/portal/free-trial?utm_source=engineering-blog&amp;utm_medium=internal&amp;utm_campaign=engineering-blog">start building</a>.</p>


            </div></div>]]>
            </description>
            <link>https://journeyapps.com/engineering-blog/no-code-vs-pro-code-a-new-hope/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24421767</guid>
            <pubDate>Wed, 09 Sep 2020 15:01:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Designing New Cryptography for Non-Standard Threat Models]]>
            </title>
            <description>
<![CDATA[
Score 30 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24421073">thread link</a>) | @some_furry
<br/>
September 9, 2020 | https://soatok.blog/2020/09/09/designing-new-cryptography-for-non-standard-threat-models/ | <a href="https://web.archive.org/web/*/https://soatok.blog/2020/09/09/designing-new-cryptography-for-non-standard-threat-models/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

		<div>

			
<p>Since the IETF’s CFRG decided to recommend OPAQUE as a next-generation <a href="https://soatok.blog/2020/04/21/authenticated-key-exchanges/">Password Authenticated Key Exchange</a>, there has been a lot of buzz in the cryptography community about committing authenticated encryption (known to the more academically inclined as Random Key Robustness), because OPAQUE requires <a href="https://mailarchive.ietf.org/arch/msg/cfrg/2W9LoeeiRzAiTWVnDsyxvjYPPmo/">an RKR-secure AE scheme</a>.</p>



<p>Random Key Robustness is a property that some symmetric encryption modes have, where it’s not feasible to decrypt a valid (ciphertext, tag) pair into two different plaintexts if both recipients are using different keys.</p>



<p>To illustrate this visually:</p>



<div><figure><img data-attachment-id="1348" data-permalink="https://soatok.blog/robustness/" data-orig-file="https://soatok.files.wordpress.com/2020/09/robustness.png" data-orig-size="750,550" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="robustness" data-image-description="" data-medium-file="https://soatok.files.wordpress.com/2020/09/robustness.png?w=300" data-large-file="https://soatok.files.wordpress.com/2020/09/robustness.png?w=580" src="https://soatok.files.wordpress.com/2020/09/robustness.png" alt="An example of random key robustness: encrypting two different images, with two different keys, can produce an identical stream of bits (ciphertext + tag)."><figcaption>RKR-secure ciphers don’t let people produce the same ciphertext+tag from two different plaintexts, with two different keys. You might be able to create an identical ciphertext, but the authentication tag will differ. (Art by <a href="https://twitter.com/SwizzlestixUK">Swizz</a>.)</figcaption></figure></div>



<p>In the wake of the CFRG discussion, it became immediately clear that <a href="https://soatok.blog/2020/05/13/why-aes-gcm-sucks/">AES-GCM doesn’t meet this requirement</a>.</p>



<p>What wasn’t immediately clear is <a href="https://keymaterial.net/2020/09/07/invisible-salamanders-in-aes-gcm-siv/">that AES-GCM-SIV also falls short</a>. But don’t take my word for it, Sophie Schmieg worked out the math in the linked post, which I highly recommend reading.</p>



<p>This isn’t to say that AES-GCM or AES-GCM-SIV are doomed, or should be deprecated. You probably don’t even care about Random Key Robustness in most of the places you’d use either algorithm! But if you are doing something where RKR actually matters, you probably care a lot. And it certainly violates the principle of least astonishment.</p>



<p>ChaCha20-Poly1305 won’t save you here either, since this is a property that message authentication codes based on cryptographic hash functions (e.g. HMAC) provide, but polynomial MACs (GMAC, Poly1305, etc.) do not.</p>



<p>So, if every standardized and widely-supported AEAD construction fails to provide RKR security, what’s a software engineer to do?<em> <a href="https://vnhacker.blogspot.com/2020/08/so-you-want-to-roll-your-own-crypto.html">Roll their own crypto</a>?!</em></p>



<div><figure><img data-attachment-id="61" data-permalink="https://soatok.blog/glitch-ecb/" data-orig-file="https://soatok.files.wordpress.com/2020/04/glitch-ecb.png" data-orig-size="224,224" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="glitch-ecb" data-image-description="" data-medium-file="https://soatok.files.wordpress.com/2020/04/glitch-ecb.png?w=224" data-large-file="https://soatok.files.wordpress.com/2020/04/glitch-ecb.png?w=224" src="https://soatok.files.wordpress.com/2020/04/glitch-ecb.png" alt=""><figcaption>Don’t actually do that. (Art by <a href="https://twitter.com/SwizzlestixUK">Swizz</a>.)</figcaption></figure></div>



<p>If you’re always on a well-tread path with a well-defined, standard threat model (i.e. client-server application accessible via TLS 1.3, possibly storing hashed passwords server-side), then rolling your own crypto isn’t just dangerous; it’s wholly unnecessary.</p>



<h2 id="coping-with-nonstandard-threat-models">Coping with Non-Standard Threat Models</h2>



<p>Systems that require Random Key Robustness do not fall within the standard threat model of AEAD cipher constructions.</p>



<p>However, RKR is far from the only scenario in which application developers might find themselves without a clear solution. Another example that comes up a lot:</p>



<blockquote><p>“I need to encrypt data in a relational database, but still somehow use it in SELECT queries.”</p><cite>— Far too many damn developers who haven’t heard of <a href="https://ciphersweet.paragonie.com/">CipherSweet</a>.</cite></blockquote>



<p>The first thing that you should do is clearly document your requirements and what attacks your system must protect against. Any undefined attack vector in your model should be assumed to be a vulnerability in your design. (This gets into <a href="https://www.cryptofails.com/post/75204435608/write-crypto-code-dont-publish-it">Unknown Unknowns</a> territory quickly.)</p>



<p>And then you should have a cryptographer review your design, and then have a cryptography engineer build it for you.</p>



<p><strong><em>But where’s the fun in that?</em></strong></p>



<div><figure><img data-attachment-id="1332" data-permalink="https://soatok.blog/soatoktelegrams2020-07/" data-orig-file="https://soatok.files.wordpress.com/2020/09/soatoktelegrams2020-07.png" data-orig-size="512,512" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="SoatokTelegrams2020-07" data-image-description="" data-medium-file="https://soatok.files.wordpress.com/2020/09/soatoktelegrams2020-07.png?w=300" data-large-file="https://soatok.files.wordpress.com/2020/09/soatoktelegrams2020-07.png?w=512" src="https://soatok.files.wordpress.com/2020/09/soatoktelegrams2020-07.png?w=512" alt="" srcset="https://soatok.files.wordpress.com/2020/09/soatoktelegrams2020-07.png 512w, https://soatok.files.wordpress.com/2020/09/soatoktelegrams2020-07.png?w=150 150w, https://soatok.files.wordpress.com/2020/09/soatoktelegrams2020-07.png?w=300 300w" sizes="(max-width: 512px) 100vw, 512px"><figcaption>This would be a very boring blog post if I left it at that! (Art by <a href="https://twitter.com/lynxvsjackalope">Khia</a>.)</figcaption></figure></div>



<p>Instead of copping out with sane and reasonable advice, let’s actually walk through the process. At the end of this post, I’ll share a toy example I cooked up for this blog post.</p>



<h2 id="designing-new-cryptography">Designing New Cryptography</h2>



<h3 id="understand-the-problem">First, Understand the Problem</h3>



<p>Why don’t AES-GCM, etc. provide Random Key Robustness? Because they’re built with universal hash functions rather than cryptographic hash functions.</p>



<p>Cryptographic hash functions have different properties (i.e. preimage resistance and collision resistance) that make it significantly difficult to calculate two different authentication tags under two different keys. Attacking HMAC-SHA-256 in this way is about <a href="https://pthree.org/2016/06/19/the-physics-of-brute-force/">as expensive as brute forcing a 128-bit AES key</a>. (Good luck with that!)</p>



<p>However, cryptographic hash functions are much slower than polynomial MACs, and using them in a construction like HMAC approximately doubles the slowness.</p>



<p>You might be tempted to just hash they key and the message together to save on CPU cycles, but that’s actually <a href="https://blog.skullsecurity.org/2012/everything-you-need-to-know-about-hash-length-extension-attacks">not safe for the hash functions nearly everybody uses</a> (due to length extension attacks).</p>



<p>It logically follows that, <strong>if we had an AEAD cipher construction based on a hash function, we could have RKR security</strong>.</p>



<div><figure><img data-attachment-id="1331" data-permalink="https://soatok.blog/soatoktelegrams2020-06/" data-orig-file="https://soatok.files.wordpress.com/2020/09/soatoktelegrams2020-06.png" data-orig-size="512,512" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="SoatokTelegrams2020-06" data-image-description="" data-medium-file="https://soatok.files.wordpress.com/2020/09/soatoktelegrams2020-06.png?w=300" data-large-file="https://soatok.files.wordpress.com/2020/09/soatoktelegrams2020-06.png?w=512" src="https://soatok.files.wordpress.com/2020/09/soatoktelegrams2020-06.png?w=512" alt="OwO *notices your cryptogrpahic robustness*" srcset="https://soatok.files.wordpress.com/2020/09/soatoktelegrams2020-06.png 512w, https://soatok.files.wordpress.com/2020/09/soatoktelegrams2020-06.png?w=150 150w, https://soatok.files.wordpress.com/2020/09/soatoktelegrams2020-06.png?w=300 300w" sizes="(max-width: 512px) 100vw, 512px"><figcaption>Now we’re getting somewhere! (Art by <a href="https://twitter.com/lynxvsjackalope">Khia</a>.)</figcaption></figure></div>



<h3 id="prior-art">Look At Prior Art</h3>



<p>Before the days of AES-GCM and ChaCha20-Poly1305, there were a lot of ad hoc constructions used everywhere based on <a href="https://soatok.blog/2020/07/12/comparison-of-symmetric-encryption-methods/#aes-gcm-vs-aes-cbc">AES-CBC and HMAC</a>. (In that era, everyone used HMAC-SHA1, but don’t do that.)</p>



<p>However, there are a number of problems with ad hoc CBC+HMAC that we don’t want to reintroduce in modern systems:</p>



<ol><li>If you forget to include the initialization vector in the HMAC tag, you give attackers free reign over the first 16 bytes of the decrypted plaintext without having to break the MAC.</li><li>The order of operations (Encrypt-then-MAC, MAC-then-Encrypt, Encrypt and MAC) matters tremendously.</li><li>CBC+HMAC is usually implemented in application-layer code, but the security of such a construction depends heavily on the availability and utilization of <a href="https://soatok.blog/2020/08/27/soatoks-guide-to-side-channel-attacks/#string-comparison">constant-time functions</a>.</li><li>There is no standard format for CBC+HMAC, nor the order of operations for what gets fed into the MAC.<ul><li>IV + ciphertext? Ciphertext + IV?</li></ul><ul><li>Append the MAC, or prepend it?</li></ul></li><li>CBC+HMAC is only an AE mode, there is no room for additional authenticated data. If you try to naively shove extra data into the HMAC, <em>now you have to worry about canonicalization attacks</em>!</li><li>CBC mode requires padding (usually PKCS #7 padding), whereas cipher modes based on CTR do not.</li></ol>



<p>This is among the long list of reasons why cryptographers have spent the past decade (or longer) pushing developers towards AEAD modes.</p>



<p>Boring cryptography is good cryptography!</p>



<div><figure><img data-attachment-id="1210" data-permalink="https://soatok.blog/soatok_stickerpack_ind_cca2/" data-orig-file="https://soatok.files.wordpress.com/2020/08/soatok_stickerpack_ind_cca2.png" data-orig-size="512,512" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Soatok_STICKERPACK_IND_CCA2" data-image-description="" data-medium-file="https://soatok.files.wordpress.com/2020/08/soatok_stickerpack_ind_cca2.png?w=300" data-large-file="https://soatok.files.wordpress.com/2020/08/soatok_stickerpack_ind_cca2.png?w=512" src="https://soatok.files.wordpress.com/2020/08/soatok_stickerpack_ind_cca2.png?w=512" alt="This isn't IND-CCA2 Secure!" srcset="https://soatok.files.wordpress.com/2020/08/soatok_stickerpack_ind_cca2.png 512w, https://soatok.files.wordpress.com/2020/08/soatok_stickerpack_ind_cca2.png?w=150 150w, https://soatok.files.wordpress.com/2020/08/soatok_stickerpack_ind_cca2.png?w=300 300w" sizes="(max-width: 512px) 100vw, 512px"><figcaption>You never want to hear this about your design. (Art by <a href="https://twitter.com/lynxvsjackalope">Khia</a>.)</figcaption></figure></div>



<p>Make sure you clearly understand the risks of the components other constructions have used.</p>



<h3 id="sketch-first-draft">Sketch Out A First Draft</h3>



<p>By now, it should be clear that if we have an Encrypt-then-MAC construction, where the MAC is based on a cryptographic hash function (e.g. SHA-256), we may be able to attain RKR security.</p>



<p>With that in mind, our sketch will probably look something like this:</p>



<ul><li>Encrypt(K1, M, N) -&gt; C<ul><li>Where Encrypt() is AES-CTR or equivalent</li></ul></li><li>Auth(K2, C, A) -&gt; T<ul><li>Where Auth() wraps HMAC-SHA2 or equivalent</li><li>How we feed C and A into the underlying MAC is important</li></ul></li><li>???? -&gt; K1, K2</li></ul>



<p>We still have to define some way of splitting a key (K) into two distinct keys (K1, K2). You never want to use a cryptographic key for more than one purpose, after all.</p>



<h3>Key-Splitting and Robustness</h3>



<p>Your encryption key and authentication key should be different, but they should also derived from the same input key! This is mainly to protect implementors from having independent keys and accidentally creating a forgery vulnerability.</p>



<p>There are several different ways you can split keys:</p>



<ol><li>Just use SHA-512(k), then cut it in half. Use one half for encryption, the other for authentication.</li><li>Use HMAC-SHA256(k, c1) and HMAC-SHA256(k, c2), where c1 and c2 are distinct (yet arbitrary) constants.</li><li>Use HKDF. This works with any secure cryptographic hash function, and was specifically designed for situations like this. HKDF also supports salting, which can be used to randomize our derived keys.</li></ol>



<p>We can really pick any of these three and be safe, but I’d advise against the first option. HKDF uses HMAC under-the-hood, so either of the latter options is fine.</p>



<h3 id="speed">Can We Make it Faster?</h3>



<p>What if, instead of HMAC-SHA256, we used <a href="https://github.com/BLAKE3-team/BLAKE3">BLAKE3</a>?</p>



<div><figure><img data-attachment-id="1362" data-permalink="https://soatok.blog/blake3/" data-orig-file="https://soatok.files.wordpress.com/2020/09/blake3.png" data-orig-size="1251,913" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="blake3" data-image-description="" data-medium-file="https://soatok.files.wordpress.com/2020/09/blake3.png?w=300" data-large-file="https://soatok.files.wordpress.com/2020/09/blake3.png?w=580" src="https://soatok.files.wordpress.com/2020/09/blake3.png" alt=""><figcaption>BLAKE3’s performance compared with other hash functions.</figcaption></figure></div>



<p>BLAKE3’s advertised 6.8 GiB/s can be even faster than <a href="https://crypto.stackexchange.com/a/60269">Poly1305 or GHASH</a> (and BLAKE3’s speed really shines through with long messages, due to its extreme parallelism through Merkle trees).</p>



<h3 id="chacha-vs-aes">In Favor of ChaCha over AES</h3>



<p>It’s no secret that <a href="https://soatok.blog/2020/05/13/why-aes-gcm-sucks/">I’m not a fan of AES</a>. It’s not the mathematical properties of AES that bother me, it’s the 128-bit block size and the fact that software implementations have to decide between being fast or being secure.</p>



<div><figure><img data-attachment-id="116" data-permalink="https://soatok.blog/soatok_stickerpack-facepaw/" data-orig-file="https://soatok.files.wordpress.com/2020/04/soatok_stickerpack-facepaw.png" data-orig-size="512,512" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Facepaw!" data-image-description="<p>Facepaw!</p>
" data-medium-file="https://soatok.files.wordpress.com/2020/04/soatok_stickerpack-facepaw.png?w=300" data-large-file="https://soatok.files.wordpress.com/2020/04/soatok_stickerpack-facepaw.png?w=512" src="https://soatok.files.wordpress.com/2020/04/soatok_stickerpack-facepaw.png?w=512" alt="Facepaw" srcset="https://soatok.files.wordpress.com/2020/04/soatok_stickerpack-facepaw.png 512w, https://soatok.files.wordpress.com/2020/04/soatok_stickerpack-facepaw.png?w=150 150w, https://soatok.files.wordpress.com/2020/04/soatok_stickerpack-facepaw.png?w=300 300w" sizes="(max-width: 512px) 100vw, 512px"><figcaption>Me, whenever I find an insecure software AES implementation. (Art by <a href="https://twitter.com/lynxvsjackalope">Khia</a>.)</figcaption></figure></div>



<p>ChaCha’s 256-bit security level is easier to justify: The underlying PRF state is 512 bits (which implies an approximately 256-bit security level) and the keys are always 256 bits.</p>



<p><s>Furthermore, if you’re building ChaCha and BLAKE3 in the same codebase, you could reuse some components (i.e. the compression function, G). This is very desirable if you’re trying to ship a small amount of code (e.g. embedded systems).</s> EDIT: <a href="https://twitter.com/veorq">One of the BLAKE3 authors</a> informed me that I’m mistaken about this: “[N]ope, not exactly the same logic (rotations in different direction)”.</p>



<h3 id="other-desirable-properties">Other Desirable Security Properties</h3>



<h4 id="nonces">Nonce Nonsense</h4>



<p>One of the biggest problems with standard AEAD modes is that they explode gloriously when you reuse a nonce. There are two ways out of this peril:</p>



<ol><li>Use a nonce misuse resistant AEAD construction (AES-GCM-SIV, etc.).<ul><li>For prior art on nonce-misuse resistant cipher modes based on ChaCha, check out <a href="https://eprint.iacr.org/2020/067">DAENCE</a>.</li></ul></li><li>Use large nonces (e.g. XChaCha20 uses 192-bit nonces) and generate them randomly, so the probability of nonce reuse becomes negligible.</li></ol>



<p>Since we’re already planning on using a hash function to derive subkeys (one for encryption, one for authentication), it makes sense to also accept a longer nonce than our stream cipher demands. The excess bytes can be passed to our KDF without significant risk or additional overhead.</p>



<p>Since the IETF’s ChaCha20 variant expects a 96-bit nonce, designing our construction to support 256-bit nonces means we can pass the first 160 bits of the nonce to the KDF and the latter 96 bits to the stream cipher. You can expect a single KDF collision after 2^80 encryptions, but it will almost certainly occur with a different nonce.</p>



<h4 id="safe-mac-canonicalization">Safe MAC Canonicalization</h4>



<p>We want to ensure it’s …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://soatok.blog/2020/09/09/designing-new-cryptography-for-non-standard-threat-models/">https://soatok.blog/2020/09/09/designing-new-cryptography-for-non-standard-threat-models/</a></em></p>]]>
            </description>
            <link>https://soatok.blog/2020/09/09/designing-new-cryptography-for-non-standard-threat-models/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24421073</guid>
            <pubDate>Wed, 09 Sep 2020 14:03:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: XML Fiddler – tool for quick XML exploration]]>
            </title>
            <description>
<![CDATA[
Score 59 | Comments 17 (<a href="https://news.ycombinator.com/item?id=24419947">thread link</a>) | @masa331
<br/>
September 9, 2020 | https://masa331.github.io/xml_fiddler/ | <a href="https://web.archive.org/web/*/https://masa331.github.io/xml_fiddler/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://masa331.github.io/xml_fiddler/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24419947</guid>
            <pubDate>Wed, 09 Sep 2020 11:45:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Most annoying website features I face as a blind person]]>
            </title>
            <description>
<![CDATA[
Score 9 | Comments 3 (<a href="https://news.ycombinator.com/item?id=24419169">thread link</a>) | @gostsamo
<br/>
September 9, 2020 | https://bighack.org/5-most-annoying-website-features-i-face-as-a-blind-screen-reader-user-accessibility/ | <a href="https://web.archive.org/web/*/https://bighack.org/5-most-annoying-website-features-i-face-as-a-blind-screen-reader-user-accessibility/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p><span>These are the five most annoying inaccessible web elements I face as a blind screen reader user every day, and how to fix them.
</span>
					</p><div>
						<p><span>For blind and visually impaired people like me, accessibility is the difference between us being able to use a website and clicking off it.&nbsp;</span></p>
<h2>How screen readers work</h2>
<p><span>Screen readers allow blind and visually impaired people to use computers, phones and tablets independently. Most screen readers use software, and a Text To Speech (TTS) engine, which is what converts the text from the screen reader into speech. Screen readers convert the text displayed on screen into a format that blind users can process.</span></p>
<p><span>Screen readers read out loud everything that’s on the screen and allow people to navigate using touch gestures and shortcut keys. They also work with other output devices such as a braille display.</span></p>
<p><span>As a screen reader user, here are the most common issues I encounter on a daily basis.&nbsp;</span></p>
<h2>Unlabelled links and buttons</h2>
<p><span>Screen reader users rely on links and buttons to navigate around a website and to find the information we need. If links and buttons are not labelled correctly or if at all, then it makes it difficult for screen reader users to find the information they need. Ultimately, unlabelled links make it much harder to navigate the website easily, quickly and independently.</span></p>
<p><span>For example, when linking to an about page, ‘click here’ doesn’t give any clue as to where it leads to, but ‘find out more about who we are’ is clear.</span></p>
<p><span>If links and buttons are labelled correctly, screen readers can read the label out loud. It means that blind and visually impaired people don’t have to press the link or button without knowing where it will take them.</span></p>
<p><span>As well as unlabelled elements, links and buttons that do not have a clear description are also really frustrating. They must have a clear description of where they will lead to when pressed, rather than ‘click here’. Never make your users guess where a link will take them or force them into a trial-and-error situation. This makes for tedious user experience.</span></p>
<h2>No image descriptions</h2>
<p><span>This is probably the most common issue I encounter when browsing the web.&nbsp;</span><span>Using image descriptions is essential for accessibility. Image descriptions are also known as alt text (alternative text) which is a written description of an image.</span></p>
<p><span>Screen readers read image descriptions out loud. This means that blind and visually impaired people can understand the content of the image in an accessible way.&nbsp;</span><span>If images do not have alt text, then screen readers will simply say “image” or “graphic” which gives no context or meaning.</span></p>
<p><span>Images often convey valuable information. It’s therefore important that people with a visual impairment can access this information as well.&nbsp;</span><span>Alt text should be clearly written and give an accurate description of the image.</span></p>
<p><strong>Check out <a href="https://bighack.org/how-to-write-better-alt-text-descriptions-for-accessibility/">our tips for writing better alt text</a> to ensure your images are fully accessible.</strong></p>
<h2>Poor use of headings</h2>
<p><span>For quick and easy navigation, many screen reader users navigate using various elements on the page such as headings. They are a great way to find the information we need quickly and effectively. Especially when they follow a logical heading structure with H1s, H2s and H3s helping to prioritise the content.</span></p>
<p><img src="https://bighack.org/wp-content/uploads/2020/05/Headings@2x.jpg" alt="Logical heading structure begins with Heading 1, with Heading 2 sitting beneath heading 1. Heading 3 sits within heading 2 and so on." width="1958" height="1236" srcset="https://bighack.org/wp-content/uploads/2020/05/Headings@2x.jpg 1958w, https://bighack.org/wp-content/uploads/2020/05/Headings@2x-300x189.jpg 300w, https://bighack.org/wp-content/uploads/2020/05/Headings@2x-768x485.jpg 768w, https://bighack.org/wp-content/uploads/2020/05/Headings@2x-1536x970.jpg 1536w" sizes="(max-width: 1958px) 100vw, 1958px" data-srcset="https://bighack.org/wp-content/uploads/2020/05/Headings@2x.jpg 1958w, https://bighack.org/wp-content/uploads/2020/05/Headings@2x-300x189.jpg 300w, https://bighack.org/wp-content/uploads/2020/05/Headings@2x-768x485.jpg 768w, https://bighack.org/wp-content/uploads/2020/05/Headings@2x-1536x970.jpg 1536w" data-src="https://bighack.org/wp-content/uploads/2020/05/Headings@2x.jpg" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></p>
<p><span>If websites don’t use headings, it means screen reader users are unable to use the keyboard shortcuts to navigate through the webpage this way. If that’s the case, we have to resort to tabbing or arrowing through a long web page to find the information we need.</span></p>
<p>Headings also help to break up the web content visually and improve readability. Other elements that screen reader users use to navigate webpages include links, lists or landmarks.</p>
<h2>Inaccessible web forms</h2>
<p><span>Most websites use forms in one way or another. Whether it’s to help you search for a product or to get in touch through a contact form. However, when these forms are not labelled, or not labelled correctly, it means we cannot use them.</span></p>
<p><span>For example, if a search box is not labelled, it means screen reader users have no idea of the purpose of that box. It means people who use screen readers cannot access the same functionality.</span></p>
<p><span>Contact forms are an effective way for customers to get in touch with your brand or business. And as a screen reader user, there’s nothing more frustrating than these forms being labelled incorrectly.</span></p>
<p><span>Especially CAPTCHA checkout requirements. Without an option to hear the audio, it’s not accessible. It means we are unable to fill in the form independently. I often have to enlist help from a sighted person, but this isn’t possible for everyone.</span><b>&nbsp;</b></p>
<h2>Auto-playing audio and video</h2>
<p><span>Most people will know how annoying it is to load a web page with noisy adverts that start playing suddenly. But for screen reader users, it can be even more alarming. When video or audio starts playing automatically, it can drown out the voice of the screen reader. This makes it harder to find the pause or stop buttons.</span></p>
<p><span>(And if these buttons are unlabelled, then it’s practically impossible for me to stop the video quickly which causes extra frustration.) If I’m unable to stop the sound or video, I normally click off.</span></p>
<p><span>The solution? Make sure there’s no auto-playing video or audio when your website loads. If you really want to use video, make sure the audio is muted and the user can pause, stop or hide the media player.</span></p>
<p><span>These issues may seem small to sighted users. But they’re the difference between me being able to use a website independently or not. And they make a huge difference when implemented correctly.</span></p>
					</div></div>]]>
            </description>
            <link>https://bighack.org/5-most-annoying-website-features-i-face-as-a-blind-screen-reader-user-accessibility/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24419169</guid>
            <pubDate>Wed, 09 Sep 2020 09:39:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How WebAssembly Changes Software Distribution]]>
            </title>
            <description>
<![CDATA[
Score 82 | Comments 66 (<a href="https://news.ycombinator.com/item?id=24419081">thread link</a>) | @ingve
<br/>
September 9, 2020 | https://desiatov.com/why-webassembly/ | <a href="https://web.archive.org/web/*/https://desiatov.com/why-webassembly/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-reactid="51"><p>If you had any experience with Windows and Internet Explorer in the 90s,
quite probably you remember <a href="https://en.wikipedia.org/wiki/ActiveX">ActiveX</a> controls. Most
frequently this involved bulky popups on pages with these controls having to display something
more complex than a few blocks of text.</p>
<p><img src="https://desiatov.com/activex-0f260342e5426a0cc883966575235fe3.gif" alt="Internet Explorer displaying an alert that requires ActiveX controls to be installed"></p>
<p>Or, remember <a href="https://en.wikipedia.org/wiki/Java_applet">Java applets</a>? They became
available in 1995, and later they weren’t limited to just Windows and Internet Explorer. I remember
I had to use Java applets on macOS as recently as 2013, which chronologically is closer to the
present time than the 90s are. (Feeling so old anyway! 👴)</p>
<p>
  <a href="https://desiatov.com/static/java-d07ca75d3ee42f845ec400952480dcd3-86a48.jpg" target="_blank" rel="noopener">
  
  <span>
    <span>
      <img alt="Microsoft's Application and Network Access Portal that displays a warning about user's browser not
allowing Java applets to run" title="" src="https://desiatov.com/static/java-d07ca75d3ee42f845ec400952480dcd3-f8fb9.jpg" srcset="https://desiatov.com/static/java-d07ca75d3ee42f845ec400952480dcd3-e8976.jpg 148w,
https://desiatov.com/static/java-d07ca75d3ee42f845ec400952480dcd3-63df2.jpg 295w,
https://desiatov.com/static/java-d07ca75d3ee42f845ec400952480dcd3-f8fb9.jpg 590w,
https://desiatov.com/static/java-d07ca75d3ee42f845ec400952480dcd3-86a48.jpg 624w" sizes="(max-width: 590px) 100vw, 590px">
    </span>
  </span>
  
  </a>
    </p>
<p>Seems like ActiveX and Java applets were necessities mostly in the enterprise world, but
Macromedia Flash (later known as <a href="https://en.wikipedia.org/wiki/Adobe_Flash">Adobe Flash</a>)
was certainly much more widely known to consumers. It was a requirement in the early days of streaming
video (even <a href="https://www.theverge.com/2015/1/27/7926001/youtube-drops-flash-for-html5-video-default">YouTube required
Flash</a>
to work back then!), but also a major driver in browser gaming in late 2000s and early 2010s.
We certainly could blame Flash for making our browser windows look like this:</p>
<p>
  <a href="https://desiatov.com/static/flash-38961528058b4baa72341cf48381d93c-02110.jpg" target="_blank" rel="noopener">
  
  <span>
    <span>
      <img alt="Browser page warning about Adobe Flash Player not being installed" title="" src="https://desiatov.com/static/flash-38961528058b4baa72341cf48381d93c-f8fb9.jpg" srcset="https://desiatov.com/static/flash-38961528058b4baa72341cf48381d93c-e8976.jpg 148w,
https://desiatov.com/static/flash-38961528058b4baa72341cf48381d93c-63df2.jpg 295w,
https://desiatov.com/static/flash-38961528058b4baa72341cf48381d93c-f8fb9.jpg 590w,
https://desiatov.com/static/flash-38961528058b4baa72341cf48381d93c-02110.jpg 606w" sizes="(max-width: 590px) 100vw, 590px">
    </span>
  </span>
  
  </a>
    </p>
<p>While ActiveX has seemingly failed to reach a significant adoption, Microsoft made yet another
attempt with <a href="https://en.wikipedia.org/wiki/Microsoft_Silverlight">Silverlight</a>:</p>
<p>
  <a href="https://desiatov.com/static/silverlight-b8600e7fe201dbc24998a9aacecd3684-da6d6.jpg" target="_blank" rel="noopener">
  
  <span>
    <span>
      <img alt="Microsoft Silverlight page with an installation button" title="" src="https://desiatov.com/static/silverlight-b8600e7fe201dbc24998a9aacecd3684-f8fb9.jpg" srcset="https://desiatov.com/static/silverlight-b8600e7fe201dbc24998a9aacecd3684-e8976.jpg 148w,
https://desiatov.com/static/silverlight-b8600e7fe201dbc24998a9aacecd3684-63df2.jpg 295w,
https://desiatov.com/static/silverlight-b8600e7fe201dbc24998a9aacecd3684-f8fb9.jpg 590w,
https://desiatov.com/static/silverlight-b8600e7fe201dbc24998a9aacecd3684-da6d6.jpg 831w" sizes="(max-width: 590px) 100vw, 590px">
    </span>
  </span>
  
  </a>
    </p>
<p>In the meantime, Google was working on <a href="https://en.wikipedia.org/wiki/Google_Native_Client">its own thing for
Chrome</a>:</p>
<p>
  <a href="https://desiatov.com/static/chrome_nacl-14dd7527a35d3d99235e94e99ca4ae06-5d9c9.png" target="_blank" rel="noopener">
  
  <span>
    <span>
      <img alt="Google Native Client plug-in settings in the Chrome browser" title="" src="https://desiatov.com/static/chrome_nacl-14dd7527a35d3d99235e94e99ca4ae06-fb8a0.png" srcset="https://desiatov.com/static/chrome_nacl-14dd7527a35d3d99235e94e99ca4ae06-1a291.png 148w,
https://desiatov.com/static/chrome_nacl-14dd7527a35d3d99235e94e99ca4ae06-2bc4a.png 295w,
https://desiatov.com/static/chrome_nacl-14dd7527a35d3d99235e94e99ca4ae06-fb8a0.png 590w,
https://desiatov.com/static/chrome_nacl-14dd7527a35d3d99235e94e99ca4ae06-5d9c9.png 650w" sizes="(max-width: 590px) 100vw, 590px">
    </span>
  </span>
  
  </a>
    </p>
<p>It would be fair to say that these attempts failed to establish wide adoption, especially
after both consumers and businesses started shifting to mobile. Here’s how all these forays ended
according to Wikipedia:</p>
<blockquote>
<p>Microsoft dropped ActiveX support from the Windows Store edition of Internet Explorer 10 in
Windows 8. In 2015 Microsoft released Microsoft Edge, the replacement for Internet Explorer with
no support for ActiveX, this marked the end of the technology in Microsoft’s web browser
development.</p>
</blockquote>
<p><small><a href="https://en.wikipedia.org/w/index.php?title=ActiveX&amp;oldid=969259090#Platform_support">“ActiveX”</a>
article on Wikipedia.</small></p>
<blockquote>
<p>Beginning in 2013, major web browsers began to phase out support for the underlying technology
applets used to run, with applets becoming completely unable to be run by 2015–2017. Java applets
were deprecated since Java 9 in 2017 and removed from Java SE 11 (18.9), released in September
2018.</p>
</blockquote>
<p><small><a href="https://en.wikipedia.org/w/index.php?title=Java_applet&amp;oldid=972322018">“Java applet”</a>
article on Wikipedia.</small></p>
<blockquote>
<p>In July 2017, Adobe announced that it would declare Flash to be end-of-life at the end of 2020,
and will cease support, distribution, and security updates for Flash Player.</p>
</blockquote>
<p><small><a href="https://en.wikipedia.org/wiki/Adobe_Flash#End_of_life">“Adobe Flash”</a> article on
Wikipedia.</small></p>
<blockquote>
<p>There is no Silverlight plugin available for Microsoft Edge. It has not been supported by Google
Chrome since September 2015 or by Firefox since March 2017.</p>
</blockquote>
<p><small><a href="https://en.wikipedia.org/wiki/Microsoft_Silverlight#Demise">“Microsoft Silverlight”</a>
article on Wikipedia.</small></p>
<blockquote>
<p>On October 12, 2016, a comment on the Chromium issue tracker indicated that Google’s Pepper and
Native Client teams had been destaffed.</p>
</blockquote>
<p><small><a href="https://en.wikipedia.org/w/index.php?title=Google_Native_Client&amp;oldid=973604804">“Google Native
Client”</a> article on
Wikipedia.</small></p>
<h2>But JavaScript solved all these problems, didn’t it?</h2>
<p>Most of these browser add-ons were introduced before modern JavaScript and HTML5 became available,
so one could argue you no longer need browser add-ons at all. Well, <a href="https://daringfireball.net/linked/2017/06/27/web-without-javascript">some
purists</a> even say browsers
should have never supported JavaScript or any scripting whatsoever in the first place. Nevertheless,
there are enough use cases for browser scripting and browser apps in general that are hard to avoid.
When looking at the history of browser plugins in general, it’s hard not to notice a few themes:</p>
<ul>
<li>Distributing productivity apps via browsers is convenient in a lot of cases.</li>
<li>Browser gaming made a lot of sense, especially for casual games.</li>
<li>In both of these scenarios browsers had to display something more complex than text and a few
static images.</li>
</ul>
<p>
  <a href="https://desiatov.com/static/flashelementtd-d00aec3e17cce46cb27a2b1662672bcf-d5c50.jpg" target="_blank" rel="noopener">
  
  <span>
    <span>
      <img alt="Flash Element TD game screenshot with a classic tower defense battle field" title="" src="https://desiatov.com/static/flashelementtd-d00aec3e17cce46cb27a2b1662672bcf-d5c50.jpg" srcset="https://desiatov.com/static/flashelementtd-d00aec3e17cce46cb27a2b1662672bcf-399a3.jpg 148w,
https://desiatov.com/static/flashelementtd-d00aec3e17cce46cb27a2b1662672bcf-d5c50.jpg 288w" sizes="(max-width: 288px) 100vw, 288px">
    </span>
  </span>
  
  </a>
    </p>
<p><small>The modern casual <a href="https://en.wikipedia.org/wiki/Tower_defense">tower defense game genre</a>
arguably was reborn due to the popularity of Adobe Flash and browser gaming, with <a href="https://en.wikipedia.org/wiki/Flash_Element_TD">Flash Element
TD</a> being a classic example.</small></p>
<p>Even though native apps were (and in many situations still are) objectively better for users, early
browser apps were attempting to build their own ad-hoc app stores before the App Store existed.
You didn’t have to buy a CD with an application and install it and manage it on your disk. You
didn’t have to install updates manually and migrate your data. There was no need to uninstall apps,
you just close a corresponding browser tab and forget about it.</p>
<p>And when browser scripting capabilities became advanced enough, some people started seeing the
allure of making a browser version of their app the only version they provided. Browsers are
cross-platform, aren’t they? Just wrap your JavaScript app code in a browser-like container (say
<a href="https://en.wikipedia.org/wiki/Electron_(software_framework)">Electron</a>) and distribute that instead
of your native app. </p>
<p>But eventually not only the JavaScript APIs became more complex, the language itself could no longer
accommodate what developers wanted. Not everyone liked JavaScript syntax (remember
<a href="https://en.wikipedia.org/wiki/CoffeeScript">CoffeeScript</a>?) or semantics (I couldn’t help but
notice that <a href="https://en.wikipedia.org/wiki/TypeScript">TypeScript</a> has grown in popularity in recent
years). But it’s hard to transpile an arbitrary programming language to JavaScript, the latter was
not built with that goal in mind.</p>
<p>Corollary, the JavaScript interpreter itself has both memory and performance overhead. Having a
garbage collector built in makes it even harder to transpile languages with different memory models
to JavaScript. The allure of having only one language to write all your apps for all platforms is
still there, but why do you have to be confined to JavaScript itself, even as a target language?</p>
<h2>How WebAssembly actually started</h2>
<p>With the death of browser plugins, at least we can praise the interoperability efforts of browser
vendors. Some lowest common denominator of JavaScript is supported in all browsers, and there is a
clear incentive for the vendors to keep up. With the demand to go beyond JavaScript, there were
initial attempts to support low level programming with asm.js in 2013:</p>
<blockquote>
<p>Much of this performance gain over normal JavaScript [with asm.js was] due to 100% type consistency
and virtually no garbage collection (memory is manually managed in a large typed array).</p>
</blockquote>
<p><small><a href="https://en.wikipedia.org/wiki/Asm.js">“asm.js”</a> article on Wikipedia.</small></p>
<p>Syntactically this still looked pretty much like JavaScript, but when you have a lot of low level code,
the resulting file can get big pretty quickly, and the size of your code is pretty important when your
users download it frequently. As you weren’t supposed to write asm.js code manually most of the time,
and it was designed primarily as compilation target, it made sense to invent a binary format for it.
That’s basically how WebAssembly started:</p>
<blockquote>
<p>WebAssembly was first announced in 2015, and the first demonstration was executing Unity’s Angry
Bots in Firefox, Google Chrome, and Microsoft Edge. The precursor technologies were asm.js from
Mozilla and Google Native Client, and the initial implementation was based on the feature set of
asm.js.</p>
</blockquote>
<p><small><a href="https://en.wikipedia.org/wiki/WebAssembly#History">“WebAssembly”</a> article on
Wikipedia.</small></p>
<p>
  <a href="https://desiatov.com/static/angrybots-af143aa014afd3462b9ef4d25875af9f-5b672.png" target="_blank" rel="noopener">
  
  <span>
    <span>
      <img alt="Angry Bots is a 3rd-person shooter demo that features a marine-like character that walks
through some futuristic research base and defends from suicidal four-legged robots" title="" src="https://desiatov.com/static/angrybots-af143aa014afd3462b9ef4d25875af9f-fb8a0.png" srcset="https://desiatov.com/static/angrybots-af143aa014afd3462b9ef4d25875af9f-1a291.png 148w,
https://desiatov.com/static/angrybots-af143aa014afd3462b9ef4d25875af9f-2bc4a.png 295w,
https://desiatov.com/static/angrybots-af143aa014afd3462b9ef4d25875af9f-fb8a0.png 590w,
https://desiatov.com/static/angrybots-af143aa014afd3462b9ef4d25875af9f-526de.png 885w,
https://desiatov.com/static/angrybots-af143aa014afd3462b9ef4d25875af9f-fa2eb.png 1180w,
https://desiatov.com/static/angrybots-af143aa014afd3462b9ef4d25875af9f-08f6a.png 1770w,
https://desiatov.com/static/angrybots-af143aa014afd3462b9ef4d25875af9f-5b672.png 2567w" sizes="(max-width: 590px) 100vw, 590px">
    </span>
  </span>
  
  </a>
    </p>
<p><small>Angry Bots is still available to play on the <a href="https://beta.unity3d.com/jonas/AngryBots/">Unity
website</a>.</small></p>
<h2>What WebAssembly got right</h2>
<p>Now you’re no longer restricted to JavaScript as a target language for browser apps. As soon as
<a href="https://llvm.org/">LLVM</a> got WebAssembly backend more or less ready, it allowed compilers built
on top of LLVM (for C, C++, Rust, Swift and many more) to adopt it without rewriting everything from
scratch. This unlocked the browser environment to a huge amount of pre-existing software that can
also run close to native speed if optimized well.</p>
<p>Not only can you run fun little projects such as <a href="https://sandspiel.club/">Sandspiel</a> and
<a href="https://orb.farm/">orb.farm</a> in your browser tab, but complex games such as <a href="https://www.continuation-labs.com/projects/d3wasm/">Doom
3</a> (at least its demo version) are available too.
Both <a href="https://blogs.unity3d.com/2018/08/15/webassembly-is-here/">Unity</a> and <a href="https://twitter.com/unrealengine/status/932624595722559490">Unreal
Engine</a> announced their support for
WebAssembly, and while we may not see AAA games running in browsers on their initial release date,
this still gives enough confidence in the maturity of the platform.</p>
<p>
  <a href="https://desiatov.com/static/orbfarm-d5127e6241542d4c77ee0faf5d5e8d41-9c30a.png" target="_blank" rel="noopener">
  
  <span>
    <span>
      <img alt="A pixel-art spherical fish tank filled with water, sand, algae, daphnia and fish." title="" src="https://desiatov.com/static/orbfarm-d5127e6241542d4c77ee0faf5d5e8d41-fb8a0.png" srcset="https://desiatov.com/static/orbfarm-d5127e6241542d4c77ee0faf5d5e8d41-1a291.png 148w,
https://desiatov.com/static/orbfarm-d5127e6241542d4c77ee0faf5d5e8d41-2bc4a.png 295w,
https://desiatov.com/static/orbfarm-d5127e6241542d4c77ee0faf5d5e8d41-fb8a0.png 590w,
https://desiatov.com/static/orbfarm-d5127e6241542d4c77ee0faf5d5e8d41-526de.png 885w,
https://desiatov.com/static/orbfarm-d5127e6241542d4c77ee0faf5d5e8d41-fa2eb.png 1180w,
https://desiatov.com/static/orbfarm-d5127e6241542d4c77ee0faf5d5e8d41-08f6a.png 1770w,
https://desiatov.com/static/orbfarm-d5127e6241542d4c77ee0faf5d5e8d41-9c30a.png 3730w" sizes="(max-width: 590px) 100vw, 590px">
    </span>
  </span>
  
  </a>
    </p>
<p><small>According to its creator, <a href="https://orb.farm/">orb.farm</a> is “a virtual ecosystem where different
species of creature can live, grow and die as part of a self-contained food chain”.</small></p>
<p>It’s obviously not limited to games, as we can see Apple folks compiling their <a href="https://twitter.com/lrz/status/1250453967957561344">C++ and Objective-C
code from iWork</a> to Wasm<sup id="fnref-1"><a href="#fn-1">1</a></sup>, or
<a href="https://1password.com/">1Password</a> using it in their browser extension getting substantial
performance improvements as a result:</p>
<blockquote>
<p>With our move to WebAssembly, page filling and analysis now runs at least twice as fast as before,
and those websites with a large number of fields are up to 13x faster in Chrome and up to 39x
faster in Firefox! It’s blazing fast. 🔥</p>
</blockquote>
<p><small><a href="https://blog.1password.com/1password-x-may-2019-update/">“1Password X: May 2019 update”</a>
article on <a href="https://blog.1password.com/">the 1Password blog</a>.</small></p>
<h2>Wasm is a general purpose virtual machine</h2>
<p>Not only you get performance improvements with WebAssembly compared to JavaScript, as it was
designed to run arbitrary code in your browser, it’s one of the most widely available secure sandbox
environments. And as a general purpose virtual machine, Wasm is not limited only to browsers.
<a href="https://www.cloudflare.com/">Cloudflare</a> uses it for edge computing on their CDN:</p>
<blockquote>
<p>We’re excited by the possibilities that WebAssembly opens up. Perhaps, by integrating with
Cloudflare Spectrum, we could allow existing C/C++ server code to handle arbitrary TCP and UDP
protocols on the edge, like a sort of massively-distributed inetd. Perhaps game servers could
reduce latency by running on Cloudflare, as close to the player as possible. Maybe, with the help
of some GPUs and OpenGL bindings, you could do 3D rendering and real-time streaming directly from
the edge.</p>
</blockquote>
<p><small><a href="https://blog.cloudflare.com/webassembly-on-cloudflare-workers/">“WebAssembly on Cloudflare
Workers”</a> on <a href="https://blog.cloudflare.com/">the Cloudflare
blog</a>.</small></p>
<p>With people realizing the wide applicability of the Wasm tech stack, it was no surprise when
<a href="https://wasi.dev/">WASI</a> (stands for WebAssembly System Interface) appeared. Where WebAssembly
itself is a “bare metal” platform, it does not supply any primitives such as memory allocation or
filesystem access, which WASI does provide. As Solomon Hykes, creator of Docker, <a href="https://twitter.com/solomonstre/status/1111004913222324225">puts
it</a>:</p>
<blockquote>
<p>If WASM+WASI existed in 2008, we wouldn’t have needed to created Docker. That’s how important it
is. Webassembly on the server is the future of computing. A standardized system …</p></blockquote></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://desiatov.com/why-webassembly/">https://desiatov.com/why-webassembly/</a></em></p>]]>
            </description>
            <link>https://desiatov.com/why-webassembly/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24419081</guid>
            <pubDate>Wed, 09 Sep 2020 09:26:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why Bayesian Stats Needs Monte-Carlo Methods]]>
            </title>
            <description>
<![CDATA[
Score 177 | Comments 96 (<a href="https://news.ycombinator.com/item?id=24416908">thread link</a>) | @laplacesdemon48
<br/>
September 8, 2020 | https://www.countbayesie.com/blog/2020/8/16/why-bayesian-stats-need-monte-carlo-methods | <a href="https://web.archive.org/web/*/https://www.countbayesie.com/blog/2020/8/16/why-bayesian-stats-need-monte-carlo-methods">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site">
		<div id="canvas">

			<!-- / headerWrapper -->

			<div id="pageWrapper" role="main">
				<section id="page" data-content-field="main-content">
					<article id="article-5f3999dd551f15457784cec9" data-item-id="5f3999dd551f15457784cec9">

	<div>
  <!--SPECIAL CONTENT-->

    

    <div>

    <!--POST HEADER-->

			<header>
				
				
			</header>

    <!--POST BODY-->

      <div><div data-layout-label="Post Body" data-type="item" data-updated-on="1597610547002" id="item-5f3999dd551f15457784cec9"><div><div><div data-block-type="2" id="block-ce72701dbc5d55959e37"><div><div><p>This post emerged from a series of question surrounding a Twitter comment that brought up some very interesting points about how Bayesian Hypothesis testing works and the inability of analytic solutions to solve even some seemingly trivial problems in Bayesian statistics. </p><p>Comparing Beta distributed random variables is something that comes up pretty frequently on this blog (and in my book as well). The set up is fairly straight forward: model an A/B test as sampling from two beta distributions, sample from each distribution a lot, then compare the results.</p><p>This simulation approach often first appears as a clever little trick to solve a more complex math problem, but in fact is a primative form of Monte-Carlo Integration and turns out to one of the only ways to really solve this problem. By exploring this topic deeper in this post we'll see some of the myths that many people have about analytic solutions as well as demonstrating why Monte-carlo methods are so essential to Bayesian statistics.</p></div><h2>Background: A conversation about election results</h2><div><p>An interesting conversation happened on Twitter recently. It started with a retweet of mine regarding Nate Silver (well know author and election forecaster) posting his latest predictions for the 2020 presidential election showing that Biden has a 71% probability of winning versus Trump's 29%</p></div></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1597610689295_4659"><div><div><p>After the last election there was quite a lot of criticism about Nate Silver's forecasting since his company (538) predicted that <a href="https://projects.fivethirtyeight.com/2016-election-forecast/">Hilary Clinton would win with a probability of 71%</a> in the 2016 presidential election.</p><p>This criticism has always annoyed me personally since, in statistical terms, 71% is generally not considered a strong belief in anything. So it is not inconsistent, nor suprising for someone to believe a candidate has 71% chance of success and they still lose. Even when looking at typical p-values, we wait for 95% percent certainty before making claims (and many feel this is a pretty weak belief). But for some reason whenever election polls come up, it seems even very statistically minded people suddenly think that 51% chance is a high probability.</p><p>I retweeted Nate Silver's forecast, mentioned my annoyance and provided an example of another case with a similar probability of winning:</p></div></div></div><div data-block-json="{&quot;cache_age&quot;:&quot;3153600000&quot;,&quot;authorUrl&quot;:&quot;https://twitter.com/willkurt&quot;,&quot;width&quot;:550,&quot;height&quot;:null,&quot;hSize&quot;:null,&quot;resolveObject&quot;:&quot;Tweet&quot;,&quot;html&quot;:&quot;<blockquote class=\&quot;twitter-tweet\&quot;><p dir=\&quot;ltr\&quot; lang=\&quot;en\&quot;>This time can we all remember that rarely in statistics would we judge P(H|D) = 0.71 as a strong belief in anything. <br><br>For comparison if in an A/B test we had these results:<br><br>A has 2 successes in 15 trials<br>B has 3 successes in 14 trials<br><br>This roughly how strong our belief in B is <a href=\&quot;https://t.co/bB4PiB5Tao\&quot;>https://t.co/bB4PiB5Tao</a></p>\u2014 Will Kurt (@willkurt) <a href=\&quot;https://twitter.com/willkurt/status/1293575032975884288?ref_src=twsrc%5Etfw\&quot;>August 12, 2020</a></blockquote>\n<script async=\&quot;\&quot; src=\&quot;https://platform.twitter.com/widgets.js\&quot; charset=\&quot;utf-8\&quot;></script>&quot;,&quot;url&quot;:&quot;https://twitter.com/willkurt/status/1293575032975884288&quot;,&quot;resolvedBy&quot;:&quot;twitter&quot;,&quot;floatDir&quot;:null,&quot;authorName&quot;:&quot;Will Kurt&quot;,&quot;version&quot;:&quot;1.0&quot;,&quot;resolved&quot;:true,&quot;type&quot;:&quot;rich&quot;,&quot;providerName&quot;:&quot;Twitter&quot;,&quot;providerUrl&quot;:&quot;https://twitter.com&quot;}" data-block-type="22" id="block-yui_3_17_2_1_1597610689295_6372"><div><blockquote><div dir="ltr" lang="en"><p>This time can we all remember that rarely in statistics would we judge P(H|D) = 0.71 as a strong belief in anything. </p><p>For comparison if in an A/B test we had these results:</p><p>A has 2 successes in 15 trials<br>B has 3 successes in 14 trials</p><p>This roughly how strong our belief in B is <a href="https://t.co/bB4PiB5Tao">https://t.co/bB4PiB5Tao</a></p></div>— Will Kurt (@willkurt) <a href="https://twitter.com/willkurt/status/1293575032975884288?ref_src=twsrc%5Etfw">August 12, 2020</a></blockquote>
</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1597610689295_6436"><div><div><p>If you were running an A/B test and your A variant had 2 success in 15 trials and your B variant had 3 successes in 14 trails, you would be roughly 71% confident that B was the superior variant.</p><p>Even someone without much statistical training would likely be very skeptical of such a claim, but somehow during election forecasts even experience statisticians can look at Silver's post and think that Biden winning is a sure thing.</p></div><h2> How do we arrive at P(B &gt; A)?</h2><p><br>Twitter user <a href="https://twitter.com/mbarras_ing">@mbarras_ing</a> ask a really important follow up question, asking to explain this result:</p></div></div><div data-block-json="{&quot;cache_age&quot;:&quot;3153600000&quot;,&quot;authorUrl&quot;:&quot;https://twitter.com/mbarras_ing&quot;,&quot;width&quot;:550,&quot;height&quot;:null,&quot;hSize&quot;:null,&quot;resolveObject&quot;:&quot;Tweet&quot;,&quot;html&quot;:&quot;<blockquote class=\&quot;twitter-tweet\&quot;><p dir=\&quot;ltr\&quot; lang=\&quot;en\&quot;>I may be a bit slow but could you elaborate on how that is? How would one compute 0.71, from the info \&quot;A has 2 successes in 15 trials, B has 3 successes in 14 trials\&quot;?</p>\u2014 Matthew Rhys Barras (@mbarras_ing) <a href=\&quot;https://twitter.com/mbarras_ing/status/1293928326579589121?ref_src=twsrc%5Etfw\&quot;>August 13, 2020</a></blockquote>\n<script async=\&quot;\&quot; src=\&quot;https://platform.twitter.com/widgets.js\&quot; charset=\&quot;utf-8\&quot;></script>&quot;,&quot;url&quot;:&quot;https://twitter.com/mbarras_ing/status/1293928326579589121&quot;,&quot;resolvedBy&quot;:&quot;twitter&quot;,&quot;floatDir&quot;:null,&quot;authorName&quot;:&quot;Matthew Rhys Barras&quot;,&quot;version&quot;:&quot;1.0&quot;,&quot;resolved&quot;:true,&quot;type&quot;:&quot;rich&quot;,&quot;providerName&quot;:&quot;Twitter&quot;,&quot;providerUrl&quot;:&quot;https://twitter.com&quot;}" data-block-type="22" id="block-yui_3_17_2_1_1597610689295_7791"><div><blockquote><p dir="ltr" lang="en">I may be a bit slow but could you elaborate on how that is? How would one compute 0.71, from the info "A has 2 successes in 15 trials, B has 3 successes in 14 trials"?</p>— Matthew Rhys Barras (@mbarras_ing) <a href="https://twitter.com/mbarras_ing/status/1293928326579589121?ref_src=twsrc%5Etfw">August 13, 2020</a></blockquote>
</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1597610689295_7855"><div><div><p>I very strongly believe that all statistics, even quick off the cuff estimates, should be reproducible and explainable.</p><p>I've written a fair bit about approaching similar problems both <a href="https://www.countbayesie.com/blog/2015/4/25/bayesian-ab-testing">on this blog</a> and <a href="https://www.amazon.com/Bayesian-Statistics-Fun-Will-Kurt/dp/1593279566">in my book</a>. The big picture is that we're going to come up with parameter estimates for the rate that A and B convert users and then compute the probability that B is greater than A. </p><p>Since we're estimating conversion rates we're going to use <a href="https://www.countbayesie.com/blog/2015/3/17/interrogating-probability-distributions">the Beta distribution</a> as the distribution of our parameter estimate. In this example I'm also assume a \(\text{Beta}(1,1)\) prior for our A and B variants.</p><p>The likelihood for A is \(\text{Beta}(2,13)\) and for B is \(\text{Beta}(3,11)\) so we can represent A and B as two random variables samples form these posteriors:</p><p>$$A \sim \text{Beta}(2+1, 13+1)$$<br>$$B \sim \text{Beta}(3+1,11+1)$$</p></div><p>We can now represent this in R, and sample from these distributions:</p></div></div><div data-block-type="23" id="block-yui_3_17_2_1_1597610689295_9136"><div><pre><span>N</span> <span>&lt;</span><span>-</span> <span>10000</span>
<span>a_samples</span> <span>&lt;</span><span>-</span> <span>rbeta</span>(<span>N</span>,<span>2</span><span>+</span><span>1</span>,<span>13</span><span>+</span><span>1</span>)
<span>b_samples</span> <span>&lt;</span><span>-</span> <span>rbeta</span>(<span>N</span>,<span>3</span><span>+</span><span>1</span>,<span>11</span><span>+</span><span>1</span>)</pre></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1597610689295_9202"><p>And finally we can look at the results of this to compute the probability that B is greater than A:</p></div><div data-block-type="23" id="block-yui_3_17_2_1_1597610689295_10612"><div><pre><span>sum</span>(<span>b_samples</span> <span>&gt;</span> <span>a_samples</span>)<span>/</span><span>N</span></pre></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1597610689295_10678"><div><p>In this case we get 0.7028 pretty close to 71% for Nate Silver’s problem.</p><h2><p>Can we solve this without R?</p></h2><p><br>This explains where we get our probabilities from, but there is an obvious question that comes up when you see this result, one raised by <a href="https://twitter.com/little_rocko">@little_rocko</a></p></div></div><div data-block-json="{&quot;cache_age&quot;:&quot;3153600000&quot;,&quot;authorUrl&quot;:&quot;https://twitter.com/little_rocko&quot;,&quot;width&quot;:550,&quot;height&quot;:null,&quot;hSize&quot;:null,&quot;resolveObject&quot;:&quot;Tweet&quot;,&quot;html&quot;:&quot;<blockquote class=\&quot;twitter-tweet\&quot;><p dir=\&quot;ltr\&quot; lang=\&quot;en\&quot;>this is an awesome example. is there an easy way (as in non-brute force) to finding the beta parameters that'll match a probability?</p>\u2014 Rocko (@little_rocko) <a href=\&quot;https://twitter.com/little_rocko/status/1294938572299018242?ref_src=twsrc%5Etfw\&quot;>August 16, 2020</a></blockquote>\n<script async=\&quot;\&quot; src=\&quot;https://platform.twitter.com/widgets.js\&quot; charset=\&quot;utf-8\&quot;></script>&quot;,&quot;url&quot;:&quot;https://twitter.com/little_rocko/status/1294938572299018242&quot;,&quot;resolvedBy&quot;:&quot;twitter&quot;,&quot;floatDir&quot;:null,&quot;authorName&quot;:&quot;Rocko&quot;,&quot;version&quot;:&quot;1.0&quot;,&quot;resolved&quot;:true,&quot;type&quot;:&quot;rich&quot;,&quot;providerName&quot;:&quot;Twitter&quot;,&quot;providerUrl&quot;:&quot;https://twitter.com&quot;}" data-block-type="22" id="block-yui_3_17_2_1_1597610689295_12117"><div><blockquote><p dir="ltr" lang="en">this is an awesome example. is there an easy way (as in non-brute force) to finding the beta parameters that'll match a probability?</p>— Rocko (@little_rocko) <a href="https://twitter.com/little_rocko/status/1294938572299018242?ref_src=twsrc%5Etfw">August 16, 2020</a></blockquote>
</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1597610689295_12181"><div><div><p>This question is interesting because it asks two questions that don't necessarily have to be related:</p><p>- is there an easy way to solve this<br>- is there a non-"brute force" way solve this</p><p>Before moving on I want to mention that this little snippet of R involves a lot more abstraction then it seems at first glance. What we are really doing here is equalivant to using a Monte-Carlo simulation to integrate over the distribution of the difference between two Beta distributed random variables. After the next two sections it will be more clear that what's happening here is a surprisingly sophisticated operation that is, in my opinion, the easiest method of solving this problem as well as not truly a brute force solution.</p></div><h2><br>Analytic versus Easy</h2><div><p>When we see computational solutions to mathematical problems our first instinct is typically to feel that we are avoiding solving the problem <em>analytically.</em> An analytical solution is one that uses mathematical analysis to find a closed form solution.</p><p>A strivial example, suppose I wanted to find the value that minimized \(f(x) = (x+3)^2\)</p><p>In R I could brute force this by looking over a range of answers like this:</p></div></div></div><div data-block-type="23" id="block-yui_3_17_2_1_1597610689295_13626"><div><pre><span>f</span> <span>&lt;</span><span>-</span> <span>function</span>(<span>x</span>){  
  (<span>x</span><span>+</span><span>3</span>)<span>^</span><span>2</span>
}
<span>xs</span> <span>&lt;</span><span>-</span> <span>seq</span>(<span>-</span><span>6</span>,<span>6</span>,<span>by</span><span>=</span><span>0.031</span>)
<span>xs</span>[<span>which</span>.<span>min</span>(<span>f</span>(<span>xs</span>))]</pre></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1597610689295_13692"><div><div><p>As expected we get our answer of -3, but this solution takes a bit of work: we need to know how to code and we need a computer. It's also a bit messy because if we had iterated by an incredment that didn't include -3 exactly (say by 0.031) we would not get the exact answer.</p><p>If we know some basic calculus we know that our minimum has to be where the derivative is at 0. We can very easily work out that</p><p>$$f'(x) = 2(x+3)$$<br>And that</p><p>$$2(x + 3) = 0 $$</p><p>When</p><p>$$ x = -3 $$</p><p>Knowning basic calculus this later solution becomes much easier. </p><p>But even with the calculus is part is hard, often solving it once makes future solutions much easier. Take for example if you wanted to find the maximum likelihood for a normal distribution with a mean of \(\mu\) and standard deviation of \(\sigma\)</p><p>To solve this we start with our PDF for the normal distribution \(\varphi\):</p><p>$$\varphi(x) = \frac{1}{\sigma \sqrt{2\pi}}e^{-\frac{1}{2}(\frac{x-\mu}{\sigma})^2}$$</p><p>Now computing the derivative of this is not necessarily "easy" but it's certainly something we can do. All we really care about is when</p><p>$$\varphi'(x) = 0$$</p><p>Which we can find out happens when (computing the deriviative of course is left as an exercise for the reader):</p><p>$$\frac{\mu-x}{\sigma}$$</p></div><div><p>This allows us to reallize the amazing fact that for any normal distribution we come across, we know that the maximum likelihood estimate is the sample is when \(x = \mu\)!</p><p>Even though our calculus might take us a bit of work, once this is done the problem of doing maximum likelihood estimation for any Normal distribution truly does become easy!</p></div><h3><br>Proposing an Analytic solution to our problem</h3><div><p>Let's revisit our original problem this time attempting to find an analytic solution. This is a very interesting case because arguably this is the simplest Bayesian hypothesis test you can imagine.</p><p>Recall that we have two random variable representing our beliefs in each test. These are distributed according the the posterior which we described earlier.</p><p>$$A \sim \text{Beta}(2+1, 13+1)$$<br>$$B \sim \text{Beta}(3+1,11+1)$$</p><p>Here is where I skipped some steps in reasoning. What we want to know is:</p><p>$$P(B &gt;A)$$</p></div><div><p>Which is not expressed in a particularly useful mathematical way. A better way to solve this is to consider this as the sum (or difference in this case) of two random variables. What we really want to know is:</p><p>$$P(B - A &gt; 0)$$</p><p>In order to solve this problem we can think of a new random variable \(X\) which is going to be the difference between B and A:</p><p>$$X = B - A$$</p><p>Finally we'll suppose we have a probability density function for \(X\) we'll call \(\text{pdf}_X\). If we know \(\text{pdf}_X\) our solution is pretty close, we just need to integrate between 0 and the max domain of this distribution:</p><p>$$P(B &gt; A) = P(B - A &gt; 0) = \int_{x=0}^{\text{max}}\text{pdf}_{X}(x)$$</p><p>Already this is starting to look a bit complicated, but there's one big problem ahead. Unlike Normally distributed random variables, we have no equivalent of the Normal sum theorem (we'll cover this in a bit) for Beta distributed random variables. </p><p>What does \(\text{pdf}_X\) look like? For starters we know it's not a Beta distribution itself. We can see this because we know the domain (or support) of this distribution is not \([0,1]\). Because they are Beta distributed, A and B can both take on values from 0 to 1, which means the maximum result of this difference is 1 but the minimum is -1. So whatever this distribution is, its domain is \([-1,1]\) meaning it cannot be a Beta distribution.</p><p>We can use various rules about sum of random variables to determine the mean and variance of this distribution, but without knowing the exact form of this distribution we are unable to solve the integral analytically. </p><p>Here we can see that even in this profoundly simple problem the analytical solution is frustratingly …</p></div></div></div></div></div></div></div></div></div></article></section></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.countbayesie.com/blog/2020/8/16/why-bayesian-stats-need-monte-carlo-methods">https://www.countbayesie.com/blog/2020/8/16/why-bayesian-stats-need-monte-carlo-methods</a></em></p>]]>
            </description>
            <link>https://www.countbayesie.com/blog/2020/8/16/why-bayesian-stats-need-monte-carlo-methods</link>
            <guid isPermaLink="false">hacker-news-small-sites-24416908</guid>
            <pubDate>Wed, 09 Sep 2020 03:54:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[AMD PSB Vendor Locks EPYC CPUs for Enhanced Security at a Cost]]>
            </title>
            <description>
<![CDATA[
Score 337 | Comments 252 (<a href="https://news.ycombinator.com/item?id=24416005">thread link</a>) | @virgulino
<br/>
September 8, 2020 | https://www.servethehome.com/amd-psb-vendor-locks-epyc-cpus-for-enhanced-security-at-a-cost/ | <a href="https://web.archive.org/web/*/https://www.servethehome.com/amd-psb-vendor-locks-epyc-cpus-for-enhanced-security-at-a-cost/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <!-- image --><div><figure><a href="https://www.servethehome.com/wp-content/uploads/2020/09/AMD-Platform-Secure-Boot-Feature-Cover.jpg" data-caption="AMD Platform Secure Boot Feature Cover"><img width="696" height="465" src="https://www.servethehome.com/wp-content/uploads/2020/09/AMD-Platform-Secure-Boot-Feature-Cover-696x465.jpg" srcset="https://www.servethehome.com/wp-content/uploads/2020/09/AMD-Platform-Secure-Boot-Feature-Cover-696x465.jpg 696w, https://www.servethehome.com/wp-content/uploads/2020/09/AMD-Platform-Secure-Boot-Feature-Cover-400x268.jpg 400w, https://www.servethehome.com/wp-content/uploads/2020/09/AMD-Platform-Secure-Boot-Feature-Cover-628x420.jpg 628w, https://www.servethehome.com/wp-content/uploads/2020/09/AMD-Platform-Secure-Boot-Feature-Cover.jpg 800w" sizes="(max-width: 696px) 100vw, 696px" alt="AMD Platform Secure Boot Feature Cover" title="AMD Platform Secure Boot Feature Cover"></a><figcaption>AMD Platform Secure Boot Feature Cover</figcaption></figure></div>
            <!-- content --><p>Today we are going to discuss a change to server security that is going to make waves in the home lab and secondary markets for servers and components in the future. During our recent <a href="https://www.servethehome.com/dell-emc-poweredge-c6525-review-2u4n-amd-epyc-kilo-thread-server/">Dell EMC PowerEdge C6525 review</a> we briefly mentioned that AMD EPYC CPUs in the system are vendor locked to Dell EMC systems. This is not a Dell-specific concern. We have confirmed that other vendors are supporting the feature behind this. For the large vendors, their platform security teams are pushing to build more secure platforms for their customers, and that is going to have future impacts on the secondary server market and home labs.</p>
<p>In this article, we are going to cover the basics of what is happening. We are going to discuss the motivations, and why this is going to be more common in the future. Finally, we are going to discuss what those in the industry can do to keep the secondary server market operating well. If you work with partners or resellers who dip into used parts bins or even have the potential to purchase grey market CPUs, send them this article or accompanying video. The current market has a large disconnect between what some large customers are asking for, and large vendors are delivering on and what others in the market know is happening.<span id="more-46716"></span></p>
<h2>Accompanying Video</h2>
<p>This is an important topic. To ensure that we can cover those who like to read/ skim and those who like to get information via audio, we have an accompanying video:</p>
<p><iframe title="Vendor Locking AMD EPYC CPUs Great for Security at a Cost" width="696" height="392" src="https://www.youtube.com/embed/kNVuTAVYxpM?feature=oembed" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></p>
<p>Feel free to pop open that video on YouTube and check it out or to send to those who prefer not to read.</p>
<h2>Background: How we learned this was a “thing”</h2>
<p>In 2018 we did a <a href="https://www.servethehome.com/dell-emc-poweredge-r7415-review/">Dell EMC PowerEdge R7415 review</a> and as part of that review, we started our normal process of trying different CPUs in the system. Early in that process, we used an AMD EPYC 7251 CPU, the low-end 8-core model, and noticed something curious. It would not work in our other test systems after.</p>
<p>After a bit of research, we found it was because Dell EMC was vendor locking the chips to Dell systems. We did not know exactly why, but we were told was a security feature. At this point, and even to this day two years later, not every vendor takes advantage of all of the AMD EPYC security features. What that practically means is that what we saw with the Dell EMC system is not what we saw with other systems. For example, we were able to interchangeably use CPUs in Supermicro and Tyan systems, but we could not use those systems once they went into a Dell EMC server.</p>
<figure id="attachment_24514" aria-describedby="caption-attachment-24514"><a href="https://www.servethehome.com/dual-amd-epyc-7251-linux-benchmarks-least-expensive-2p-epyc/amd-epyc-7251-in-socket-and-carrier/" rel="attachment wp-att-24514"><img src="https://www.servethehome.com/wp-content/uploads/2017/09/AMD-EPYC-7251-in-Socket-and-Carrier.jpg" alt="AMD EPYC In Socket And Carrier" width="800" height="533" srcset="https://www.servethehome.com/wp-content/uploads/2017/09/AMD-EPYC-7251-in-Socket-and-Carrier.jpg 800w, https://www.servethehome.com/wp-content/uploads/2017/09/AMD-EPYC-7251-in-Socket-and-Carrier-400x267.jpg 400w, https://www.servethehome.com/wp-content/uploads/2017/09/AMD-EPYC-7251-in-Socket-and-Carrier-696x464.jpg 696w, https://www.servethehome.com/wp-content/uploads/2017/09/AMD-EPYC-7251-in-Socket-and-Carrier-630x420.jpg 630w" sizes="(max-width: 800px) 100vw, 800px"></a><figcaption id="caption-attachment-24514">AMD EPYC In Socket And Carrier</figcaption></figure>
<p>We found we were not alone. Laboratories, VARs, and other organizations were finding that transferring AMD EPYC CPUs from one vendor’s system to another, was not the simple process it was on the Intel Xeon side. It did not always work.</p>
<p>We knew it was a security feature and thought that most who are buying servers would be informed of this by their sales reps or channel partners. After I personally got a lot of texts, e-mails, instant messaging, and comments on our C6525 video and article, I realized that this actually may be a situation where many people do not know what is going on.</p>
<figure id="attachment_46531" aria-describedby="caption-attachment-46531"><a href="https://www.servethehome.com/dell-emc-poweredge-c6525-review-2u4n-amd-epyc-kilo-thread-server/dell-emc-poweredge-c6525-internal-view-nodes-partially-out/" rel="attachment wp-att-46531"><img src="https://www.servethehome.com/wp-content/uploads/2020/08/Dell-EMC-PowerEdge-C6525-Internal-View-Nodes-Partially-Out.jpg" alt="Dell EMC PowerEdge C6525 Internal View Nodes Partially Out" width="800" height="519" srcset="https://www.servethehome.com/wp-content/uploads/2020/08/Dell-EMC-PowerEdge-C6525-Internal-View-Nodes-Partially-Out.jpg 800w, https://www.servethehome.com/wp-content/uploads/2020/08/Dell-EMC-PowerEdge-C6525-Internal-View-Nodes-Partially-Out-400x260.jpg 400w, https://www.servethehome.com/wp-content/uploads/2020/08/Dell-EMC-PowerEdge-C6525-Internal-View-Nodes-Partially-Out-696x452.jpg 696w, https://www.servethehome.com/wp-content/uploads/2020/08/Dell-EMC-PowerEdge-C6525-Internal-View-Nodes-Partially-Out-647x420.jpg 647w" sizes="(max-width: 800px) 100vw, 800px"></a><figcaption id="caption-attachment-46531">Dell EMC PowerEdge C6525 Internal View Nodes Partially Out</figcaption></figure>
<p>This experience that we had, apparently is one that is not overly common yet. That makes sense because the systems that utilize the enhanced security levels are still largely new, and being used by their first buyers. Also, AMD still has a smaller market share than Intel. A big reason, by the way, that Intel Xeon does not have this issue is that they do not have the security feature that AMD has. Vendors have come out and stated that their AMD EPYC systems are more secure than their Intel Xeon systems, and this behavior is a byproduct of that enhanced security.</p>
<p>Next, we are going to dive into the feature of AMD processors (and what will be more common in future CPUs from other vendors.)</p>
<h2>AMD EPYC Secure Processor Platform Secure Boot (PSB)</h2>
<p>Let us start with the high-level slide. This is effectively the same slide on the AMD Secure Processor that we saw with the AMD EPYC 7001 series launch, but this is from the EPYC 7002 series. AMD EPYC CPUs may be x86, but they have an embedded Arm Cortex-A5 microcontroller that runs its own OS that is independent of the main system. This AMD Secure Processor is the backbone of AMD’s security push as it provides features such as key management and hardware root of trust for the platform.</p>
<figure id="attachment_36705" aria-describedby="caption-attachment-36705"><a href="https://www.servethehome.com/amd-epyc-7002-series-rome-delivers-a-knockout/amd-epyc-7002-platform-secure-processor/" rel="attachment wp-att-36705"><img src="https://www.servethehome.com/wp-content/uploads/2019/08/AMD-EPYC-7002-Platform-Secure-Processor.jpg" alt="AMD EPYC 7002 Platform Secure Processor" width="1792" height="918" srcset="https://www.servethehome.com/wp-content/uploads/2019/08/AMD-EPYC-7002-Platform-Secure-Processor.jpg 1792w, https://www.servethehome.com/wp-content/uploads/2019/08/AMD-EPYC-7002-Platform-Secure-Processor-400x205.jpg 400w, https://www.servethehome.com/wp-content/uploads/2019/08/AMD-EPYC-7002-Platform-Secure-Processor-800x410.jpg 800w, https://www.servethehome.com/wp-content/uploads/2019/08/AMD-EPYC-7002-Platform-Secure-Processor-696x357.jpg 696w, https://www.servethehome.com/wp-content/uploads/2019/08/AMD-EPYC-7002-Platform-Secure-Processor-1068x547.jpg 1068w, https://www.servethehome.com/wp-content/uploads/2019/08/AMD-EPYC-7002-Platform-Secure-Processor-820x420.jpg 820w" sizes="(max-width: 1792px) 100vw, 1792px"></a><figcaption id="caption-attachment-36705">AMD EPYC 7002 Platform Secure Processor</figcaption></figure>
<p>AMD spends time <a href="https://www.servethehome.com/amd-confirms-cts-labs-exploits-requiring-admin-access/">patching this solution</a>&nbsp;to make it more secure, but it is generally fairly hard to reach without some extremely low-level access in a system. We are going to come back to the “Enables hardware validated boot” line shortly, but it is important to understand that this secure processor underpins many of AMD’s best security features.</p>
<p>For example, at STH we use EPYC’s Secure Memory Encryption and Secure Encrypted Virtualization heavily. With AMD EPYC, we do not have to manually manage keys. Instead, the ephemeral keys are managed for us by the AMD Secure Processor. This is the basis for what is really the building wave of confidential computing offerings such as&nbsp;<a href="https://www.servethehome.com/google-cloud-confidential-computing-enabled-by-amd-epyc-sev/">Google Cloud Confidential Computing Enabled by AMD EPYC SEV</a>. Intel has its secure boot features and SGX that will be enhanced greatly with <a href="https://www.servethehome.com/the-2021-intel-ice-pickle-how-2021-will-be-crunch-time/">Ice Lake Xeons</a>, but for now, AMD has this capability while Intel does not. When big vendors say AMD is more secure, the AMD Secure Processor is a cornerstone of those offerings.</p>
<figure id="attachment_36704" aria-describedby="caption-attachment-36704"><a href="https://www.servethehome.com/amd-epyc-7002-series-rome-delivers-a-knockout/amd-epyc-7002-platform-secure-memory-encryption/" rel="attachment wp-att-36704"><img src="https://www.servethehome.com/wp-content/uploads/2019/08/AMD-EPYC-7002-Platform-Secure-Memory-Encryption.jpg" alt="AMD EPYC 7002 Platform Secure Memory Encryption" width="1769" height="890" srcset="https://www.servethehome.com/wp-content/uploads/2019/08/AMD-EPYC-7002-Platform-Secure-Memory-Encryption.jpg 1769w, https://www.servethehome.com/wp-content/uploads/2019/08/AMD-EPYC-7002-Platform-Secure-Memory-Encryption-400x201.jpg 400w, https://www.servethehome.com/wp-content/uploads/2019/08/AMD-EPYC-7002-Platform-Secure-Memory-Encryption-800x402.jpg 800w, https://www.servethehome.com/wp-content/uploads/2019/08/AMD-EPYC-7002-Platform-Secure-Memory-Encryption-696x350.jpg 696w, https://www.servethehome.com/wp-content/uploads/2019/08/AMD-EPYC-7002-Platform-Secure-Memory-Encryption-1068x537.jpg 1068w, https://www.servethehome.com/wp-content/uploads/2019/08/AMD-EPYC-7002-Platform-Secure-Memory-Encryption-835x420.jpg 835w" sizes="(max-width: 1769px) 100vw, 1769px"></a><figcaption id="caption-attachment-36704">AMD EPYC 7002 Platform Secure Memory Encryption</figcaption></figure>
<p>Let us discuss that “Enables hardware validated boot” line. While traditionally CPUs just fire up in whatever platform they are in, AMD has intelligence in their CPU due to the Arm-based AMD Secure Processor. EPYC CPUs are designed to be a bit more intelligent about the platforms they are in, and interact with server platform security to act as this root of trust that would not be possible if they effectively just booted up in any system.</p>
<p>Here is a statement from AMD describing the AMD Platform Secure Boot.</p>
<p><em>The AMD Platform Secure Boot Feature (PSB) is a mitigation for firmware Advanced Persistent Threats. It is a defense-in-depth feature. PSB extends AMD’s silicon root of trust to protect the OEM’s BIOS.&nbsp; This allows the OEM to establish an unbroken chain of trust from AMD’s silicon root of trust to the OEM’s BIOS using PSB, and then from the OEM’s BIOS to the OS Bootloader using UEFI secure boot. This provides a very powerful defense against remote attackers seeking to embed malware into a platform’s firmware.</em></p>
<p><em>An OEM who trusts only their own cryptographically signed BIOS code to run on their platforms will use a PSB enabled motherboard and set one-time-programmable fuses in the processor to bind the processor to the OEM’s firmware code signing key. AMD processors are shipped unlocked from the factory, and can initially be used with any OEM’s motherboard. But once they are used with a motherboard with PSB enabled, the security fuses will be set, and from that point on, that processor can only be used with motherboards that use the same code signing key. (<strong>Source</strong>: AMD statement to STH)</em></p>
<p>That is a lot to take in. We asked HPE about this. Their response mirrored what the above was describing. HPE firmware, when a system is first turned on, performs this binding process where the AMD EPYC CPU expects to see HPE signed firmware. If you alter the HPE firmware on the system, the check fails and the system will not work. That means if your HPE motherboard fails, you can replace it and put your CPU in another HPE motherboard with signed HPE firmware. It also means if the server platform’s firmware is not signed by HPE, the processor will see it as evidence of tampering and not work.</p>
<p><strong>Edit: 2020-09-09</strong> – HPE clarified that they are doing this in a different manner than Dell after initially confirming that they were using the AMD PSB feature. After this went live, HPE sent us the following:</p>
<p><em>HPE does not use the same security technique that Dell is using for a BIOS hardware root of trust. HPE does not burn, fuse, or permanently store our public key into AMD processors which ship with our products. HPE uses a unique approach to authenticate our BIOS and BMC firmware: HPE fuses our hardware – or silicon – root of trust into our own BMC silicon to ensure only authenticated firmware is executed.&nbsp; Thus, while we implement a hardware root of trust for our BIOS and BMC firmware, the processors that ship with our servers are not locked to our platforms. (<strong>Source</strong>: HPE)</em></p>
<p>What is at least interesting there is that HPE was initially claiming feature parity with Dell to us, and from the comments on this article were saying they used this feature in sales pitches, but now are saying they are not blowing the eFuses.</p>
<figure id="attachment_39258" aria-describedby="caption-attachment-39258"><a href="https://www.servethehome.com/pcie-gen4-hpe-proliant-dl325-gen10-plus-and-dl385-gen10-plus-amd-epyc-7002/hpe-proliant-dl325-gen10-plus-at-sc19-cpu-cover/" rel="attachment wp-att-39258"><img src="https://www.servethehome.com/wp-content/uploads/2019/11/HPE-ProLiant-DL325-Gen10-Plus-at-SC19-CPU-Cover.jpg" alt="HPE ProLiant DL325 Gen10 Plus At SC19 CPU Cover" width="800" height="600" srcset="https://www.servethehome.com/wp-content/uploads/2019/11/HPE-ProLiant-DL325-Gen10-Plus-at-SC19-CPU-Cover.jpg 800w, https://www.servethehome.com/wp-content/uploads/2019/11/HPE-ProLiant-DL325-Gen10-Plus-at-SC19-CPU-Cover-400x300.jpg 400w, https://www.servethehome.com/wp-content/uploads/2019/11/HPE-ProLiant-DL325-Gen10-Plus-at-SC19-CPU-Cover-80x60.jpg 80w, https://www.servethehome.com/wp-content/uploads/2019/11/HPE-ProLiant-DL325-Gen10-Plus-at-SC19-CPU-Cover-265x198.jpg 265w, https://www.servethehome.com/wp-content/uploads/2019/11/HPE-ProLiant-DL325-Gen10-Plus-at-SC19-CPU-Cover-696x522.jpg 696w, https://www.servethehome.com/wp-content/uploads/2019/11/HPE-ProLiant-DL325-Gen10-Plus-at-SC19-CPU-Cover-560x420.jpg 560w" sizes="(max-width: 800px) 100vw, 800px"></a><figcaption id="caption-attachment-39258">HPE ProLiant DL325 Gen10 Plus At SC19 CPU Cover</figcaption></figure>
<p>Here is where the concern develops, and not necessarily for AMD, the OEM, or most of the initial customer base. Customers want more security. The OEMs want to create a secure hardware environment because that is what their customers want. AMD is implementing an advanced security solution beyond what Intel Xeons have giving the OEMs and end-customers what they want. Effectively, when these are sold as new systems, this is exactly what everyone involved wants.</p>
<p>If everyone is getting what they want, then where is the concern, that is what we are going to cover next.</p>
        </div></div>]]>
            </description>
            <link>https://www.servethehome.com/amd-psb-vendor-locks-epyc-cpus-for-enhanced-security-at-a-cost/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24416005</guid>
            <pubDate>Wed, 09 Sep 2020 02:02:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Disney hit by backlash after thanking Xinjiang authorities in 'Mulan' credits]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24415532">thread link</a>) | @woranl
<br/>
September 8, 2020 | https://www.ctvnews.ca/mobile/entertainment/disney-hit-by-backlash-after-thanking-xinjiang-authorities-in-mulan-credits-1.5096476 | <a href="https://web.archive.org/web/*/https://www.ctvnews.ca/mobile/entertainment/disney-hit-by-backlash-after-thanking-xinjiang-authorities-in-mulan-credits-1.5096476">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <p>
	Disney has publicly thanked a Chinese government agency accused of human rights abuses in Xinjiang for its help in making "Mulan" — a revelation that has provoked a storm of criticism online.</p>
<p>
	Disney acknowledges several Chinese government bodies in the credits for the live-action remake of the 1998 animated picture of the same name, but a few in particular have raised red flags: The Xinjiang government's publicity department and the Public Security and Tourism bureaus for Turpan, a city of about <a href="http://www.tlf.gov.cn/zjtluf/rkyy/rkgk.htm" target="_blank">633,400 people</a> just outside Xinjiang's capital Urumqi.</p>
<p>
	Disney did not respond to a request for comment from CNN Business to its media inquiry line, and to U.S. press officers about the film and the credits. It's not clear how much of "Mulan" may have been shot in Xinjiang, though people who worked on the movie have said on social media and in interviews that they scouted and filmed locations there.</p>
<p>
	The U.S. State Department estimates that since 2015 as many as <a href="https://www.foreign.senate.gov/imo/media/doc/120418_Busby_Testimony.pdf" target="_blank">two million of the Muslim-majority Uyghurs and other Turkic minorities</a> have been imprisoned in enormous re-education camps in Xinjiang.</p>
<p>
	The Turpan Public Security Bureau has been listed by the U.S. government as an organization involved in <a href="https://www.federalregister.gov/documents/2019/10/09/2019-22210/addition-of-certain-entities-to-the-entity-list" target="_blank">"human rights violations and abuses"</a> in the region.</p>
<p>
	Beijing has long defended the crackdown in Xinjiang as necessary to tackle extremism and terrorism, and said it is in line with Chinese law and international practice, calling accusations of mass detentions a "groundless lie" and "sensational rumor." A spokesperson for the country's foreign ministry on Tuesday reiterated its defense of what it calls its Xinjiang "vocational skills education and training centers." CNN Business has reached out to the Xinjiang government and Turpan's tourism bureau, but Turpan's Public Security bureau could not be reached for comment.</p>
<p>
	"There are no so-called concentration camps in Xinjiang," said China's Foreign Ministry spokesperson Zhao Lijian. "The establishment of vocational skills education and training centers in Xinjiang in accordance with the law is a useful attempt and active exploration for preventive counter-terrorism and de-radicalization."</p>
<p>
	But the connections between Xinjiang and "Mulan" have ignited widespread criticism on social media since its release Friday on Disney+, the company's streaming service. Human rights advocates are now calling on Disney to make public any agreements with the Chinese government over filming in the region.</p>
<p>
	"[It's] deeply disturbing that Disney thought it was okay to partner with, and also thank, government departments, specifically propaganda departments, and a public security bureau from a region in China that is<a href="https://www.cnn.com/2020/07/30/asia/xinjiang-sterilization-women-human-rights-intl-hnk/index.html" target="_blank"> complicit with genocide," </a>said Isaac Stone Fish, senior fellow at the Asia Society, a New York based non-profit organization focused on raising awareness of Asia.</p>
<h3>
	A FILM PLAGUED BY SETBACKS</h3>
<p>
	Disney hoped that "Mulan" would be a major success at the lucrative Chinese box office, now the second-largest in the world. The company spoke last year about its dedication to making the film culturally accurate — remarks that were reported in Chinese state media.</p>
<p>
	"We spent a lot of time in the beginning with scholars, experts and people from the region. And we spent a great deal of time in China," said Sean Bailey, president of Walt Disney Studios Motion Picture Production, at a Disney expo event last year, reported the state-run news agency Xinhua. Bailey added that the studio "not only has a Chinese cast but also brought in a Chinese producer to make the movie with them," the outlet noted.</p>
<p>
	Eschewing the musicality of Disney's earlier animated feature of the same name, one box office analyst told CNN Business earlier this year that the live-action epic was <a href="https://www.cnn.com/2020/02/13/media/disney-mulan-coronavirus/index.html" target="_blank">"tailor-made for success."</a></p>
<p>
	But the film — which is based on a traditional Chinese legend about <a href="http://www.womenofchina.cn/womenofchina/html1/history/1706/4656-1.htm" target="_blank">a female warrior</a> who disguised herself as a man and took her father's place in the army — has already faced controversy and setbacks.</p>
<p>
	In August 2019, pro-democracy activists in Hong Kong called for a boycott of "Mulan" after the lead actor expressed support for Hong Kong police on her social media account.</p>
<p>
	"I support the Hong Kong police. You can all attack me now. What a shame for Hong Kong," Liu Yifei, a Chinese-born U.S. citizen who plays the titular Hua Mulan, <a href="https://www.cnn.com/2019/08/16/asia/china-mulan-actor-protests-intl-hnk-trnd/index.html" target="_blank">posted to her official Weibo account.</a> At the time, Hong Kong police faced allegations of excessive violence against protesters. (Hong Kong police <a href="https://www.cnn.com/2019/09/20/asia/hong-kong-protests-intl-hnk/index.html" target="_blank">defended their actions</a> in September 2019, saying they had been "so restrained.")</p>
<p>
	Then in March, Disney was forced to <a href="https://www.cnn.com/2020/03/12/media/mulan-delay-coronavirus/index.html" target="_blank">delay the film's release</a> as the coronavirus pandemic shuttered movie theaters.</p>
<p>
	Even now, its rollout has been stilted. The film was released as a US$30 <a href="https://www.cnn.com/2020/09/04/media/mulan-disney-china-international-release/index.html" target="_blank">video-on-demand </a>last Friday on Disney+, which is only available in certain markets, including the United States. It makes its debut in Chinese theaters this weekend. (Disney+ is not available in China.)</p>
<p>
	The release of the film has renewed the controversy surrounding it, however. Pro-democracy activists in Hong Kong, <a href="https://www.cnn.com/2020/09/04/entertainment/mulan-boycott-hong-kong-trnd/index.html" target="_blank">Thailand and Taiwan</a> have once again called on people to boycott the film because of Yifei's remarks last year.</p>
<p>
	And it's not even clear that the film will win over Chinese audiences, who were already chilly toward the original animated version because of its westernized flair and unfaithful retelling of the original legend.</p>
<p>
	After the release of the trailer in 2019, Chinese state-run media Global Times criticized the film for using<a href="http://www.globaltimes.cn/content/1157286.shtml" target="_blank"> Japanese "ninja gestures"</a> and Chinese stereotypes.</p>
<h3>
	CALLS FOR TRANSPARENCY</h3>
<p>
	Allegations of human rights abuses in Xinjiang stretch back years.</p>
<p>
	In recent years, the Xinjiang government has allegedly undertaken a large campaign to imprison and re-educate Muslim minorities in the region, especially the large Uyghur population.</p>
<p>
	Evidence of widespread human rights abuse has trickled out from inside the region, including <a href="https://www.cnn.com/interactive/2020/02/asia/xinjiang-china-karakax-document-intl-hnk/" target="_blank">lengthy detentions,</a> abuse, <a href="https://www.cnn.com/2019/11/26/asia/china-xinjiang-leaks-analysis-intl-hnk/index.html" target="_blank">indoctrination</a> and <a href="https://www.cnn.com/2020/07/30/asia/xinjiang-sterilization-women-human-rights-intl-hnk/index.html" target="_blank">mass birth control</a> — which experts have described as evidence of "genocide."</p>
<p>
	In 2017, Mulan director Niki Caro posted a photo from Urumqi, the capital of Xinjiang<strong> </strong>and said she was <a href="https://www.instagram.com/p/BZle-neFOc-/?utm_source=ig_embed" target="_blank">scouting out locations</a> for the film. And in an interview in September<strong> </strong>with Conde Nast traveler, Mulan production designer Grant Major discussed filming in Xinjiang's <a href="https://www.cntraveler.com/story/on-location-mulan" target="_blank">Taklamakan Desert</a>, in the region's far southwest.</p>
<p>
	Adrian Zenz, a leading academic<strong> </strong>at the Victims of Communism Foundation who has helped break major stories from Xinjiang, said that the earliest documented case of a re-education center in the region was in Turpan in 2013.</p>
<p>
	Zenz said that while it was possible Disney didn't know about the growing number of detention centers set up across Xinjiang, the widespread oppression in the region was impossible to miss.</p>
<p>
	"There were police stations and checkpoints all over Xinjiang by late 2016, not to be missed," he said.</p>
<p>
	Foreign ministry spokesperson Zhao dismissed Zenz's claims and accused him of making a living "through making Xinjiang-related rumors and slandering China." He also claimed there had been no cases of violence or terrorism in Xinjiang for "more than three consecutive years."</p>
<p>
	Turpan was also the setting for one of the worst outbreaks of ethnic violence in Xinjiang in recent years, when 35 people died during an attack on a police station in Lukqun township, in 2013, <a href="http://www.chinadaily.com.cn/kindle/2013-07/05/content_16731473.htm" target="_blank">according to state media.</a></p>
<p>
	Yaqiu Wang, a China researcher for Human Rights Watch, called for Disney to <a href="https://twitter.com/Yaqiu/status/1303002585155149825" target="_blank">disclose what assistance</a> it had received from Xinjiang authorities and what agreements it had made with the regional government.</p>
<p>
	And<strong> </strong>Asia Society fellow Stone Fish said that many companies were accustomed to making small concessions to the ruling Communist Party to access the Chinese market.</p>
<p>
	"Studios feel like they need to make these compromises to be in Beijing, but you can slightly censor your movies to get into the Chinese market, you can bring Chinese movies that shouldn't be in the States because of poor quality or because of propaganda elements into the States. And you can do that and maintain your integrity, mostly intact," he said.</p>
<p>
	"You don't need to take these extra steps that Disney is taking, and they're rightly getting excoriated for it."</p>

                                              </div></div>]]>
            </description>
            <link>https://www.ctvnews.ca/mobile/entertainment/disney-hit-by-backlash-after-thanking-xinjiang-authorities-in-mulan-credits-1.5096476</link>
            <guid isPermaLink="false">hacker-news-small-sites-24415532</guid>
            <pubDate>Wed, 09 Sep 2020 01:01:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Deep Diamond – Deep Learning in Clojure Is Fast, Simpler Than Keras]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24413881">thread link</a>) | @fnordsensei
<br/>
September 8, 2020 | https://dragan.rocks/articles/20/Deep-Diamond-Deep-Learning-in-Clojure-is-Fast-and-Simpler-than-Keras | <a href="https://web.archive.org/web/*/https://dragan.rocks/articles/20/Deep-Diamond-Deep-Learning-in-Clojure-is-Fast-and-Simpler-than-Keras">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
      
You can <a href="https://www.patreon.com/posts/22476035">adopt a pet function!</a>
Support my work <a href="https://patreon.com/draganrocks">on my Patreon page</a>, and access my <a href="https://www.patreon.com/posts/im-ditching-and-22476348">dedicated discussion server</a>. Can't afford to <a href="https://patreon.com/draganrocks">donate</a>? Ask for a free invite.
<p>September 5, 2020</p>
<p>
    Please share: .
</p>

<p>
    <a href="https://aiprobook.com/">New books are available for subscription.</a>
    </p><p><a href="https://aiprobook.com/deep-learning-for-programmers">
            <img src="http://aiprobook.com/img/dlfp-cover.png">
        </a>
        <a href="https://aiprobook.com/numerical-linear-algebra-for-programmers">
            <img src="http://aiprobook.com/img/lafp-cover.png">
        </a>
    </p>


<p>
through the direct equivalent of a fine Convolutional network example in Keras.
</p>

<p>
Good News: <a href="https://github.com/uncomplicate/deep-diamond">Deep Diamond</a>() preview release is in Clojars, and is already quite useful! And fast!
It is yet to be fully polished, but you can try it now and, I hope, you'll like it.
</p>

<p>
It now covers the functionality that is being explained from scratch in the <a href="http://aiprobook.com/">books that I'm writing</a>.
Convolutions work, too; at the speed of Road Runner!
</p>

<p>
In accordance with my philosophy, "less talk, more walk", I introduce Deep Diamond
through the direct equivalent of this fine <a href="https://github.com/keras-team/keras/blob/master/examples/mnist_cnn.py">MNIST CNN example in Keras</a>.
</p>

<div id="outline-container-org54ea652">
<h2 id="org54ea652">Specify the network blueprint</h2>
<div id="text-org54ea652">
<p>
We specify the network by plain Clojure vectors and functions, and create the blueprint.
No need for special compilers and whatnot. The structure of internal parts would be
picked up automatically, or we can specify these explicitly.
</p>

<div>
<pre><span>(</span><span>def</span> <span>net-spec</span> <span>[</span><span>(</span>convo <span>[</span>32<span>]</span> <span>[</span>3 3<span>]</span> <span>:relu</span><span>)</span>
               <span>(</span>convo <span>[</span>64<span>]</span> <span>[</span>3 3<span>]</span> <span>:relu</span><span>)</span>
               <span>(</span>pooling <span>[</span>2 2<span>]</span> <span>:max</span><span>)</span>
               <span>(</span>dropout<span>)</span>
               <span>(</span>dense <span>[</span>128<span>]</span> <span>:relu</span><span>)</span>
               <span>(</span>dropout<span>)</span>
               <span>(</span>dense <span>[</span>10<span>]</span> <span>:softmax</span><span>)</span><span>]</span><span>)</span>

<span>(</span><span>defonce</span> <span>net-bp</span>
  <span>(</span>network <span>(</span>desc <span>[</span>128 1 28 28<span>]</span> <span>:float</span> <span>:nchw</span><span>)</span>
           net-spec<span>)</span><span>)</span>
</pre>
</div>
</div>
</div>

<div id="outline-container-orgb8d8bce">
<h2 id="orgb8d8bce">Create the network</h2>
<div id="text-orgb8d8bce">
<p>
The blueprint is a Clojure function that can instantiate the network
object that holds the parameter tensors that the network should learn by using
one of the built-in optimization algorithms. In this case, I'll use adaptive moments,
<code>:adam</code>. Xavier initialization is, again, a plain function that initializes
the network with appropriate weights.
</p>

<div>
<pre><span>(</span><span>defonce</span> <span>net</span> <span>(</span>init! <span>(</span>net-bp <span>:adam</span><span>)</span><span>)</span><span>)</span>
</pre>
</div>

<p>
That's it! The network is ready to learn.
</p>
</div>
</div>

<div id="outline-container-orgae4dec0">
<h2 id="orgae4dec0">Train the network on MNIST data (CPU)</h2>
<div id="text-orgae4dec0">
<p>
The original MNIST data is distributed through four binary files that
you can download <a href="http://yann.lecun.com/exdb/mnist/">here</a>. To demonstrate how nice Clojure is, I'm not
using any special MNIST-specific code that is magically imported
from the framework's model Zoo. The complete code, from scratch, is at the
end of the article (I'm just pushing it there so it doesn't steal the spotlight :).
</p>

<div>
<pre><span>(</span>time <span>(</span>train net train-images y-train <span>:crossentropy</span> 12 <span>[]</span><span>)</span><span>)</span>
</pre>
</div>

<p>
The network learns in mini-batches of 128 images of the total of 60000,
with adaptive moments, through 12 full epochs. That makes 5625 forward/backward
update cycles.
</p>

<p>
The total time for that on my old 2013. i7-4790k CPU is: <b>368</b> seconds.
<b>6 minutes for 6000 cycles. A thousand cycles per minute.</b>
</p>

<p>
Isn't that a lot? You should try and run this in Keras with TensorFlow, and
see that we got a pretty nice performance! (I'll publish some comparisons soon,
and in the meantime you can try for yourself!).
</p>
</div>
</div>

<div id="outline-container-org7c0813e">
<h2 id="org7c0813e">Has it learned anything?</h2>
<div id="text-org7c0813e">
<p>
See the metrics:
</p>

<div>
<pre><span>(</span><span>-&gt;&gt;</span> <span>(</span>infer net test-images<span>)</span>
     <span>(</span>dec-categories<span>)</span>
     <span>(</span>classification-metrics test-labels-float<span>)</span>
     <span>:metrics</span><span>)</span>
</pre>
</div>

<pre>{:accuracy 0.9919,
 :f1 0.9918743606319073,
 :ba 0.9954941141884774,
 :sensitivity 0.9918944358825683,
 :specificity 0.9990937924943865,
 :precision 0.9918542861938476,
 :fall-out 9.062075056135655E-4}
</pre>

<p>
Accuracy is 99.2% which is in the ballpark of what the Keras example gives.
</p>
</div>
</div>


<div id="outline-container-org78cec4a">
<h2 id="org78cec4a">GPU</h2>
<div id="text-org78cec4a">
<p>
Want to go faster? No problem, Deep Diamond supports GPU, in the same process,
at the same time, with the same code!
</p>

<div>
<pre><span>(</span><span>defonce</span> <span>gpu</span> <span>(</span>cudnn-factory<span>)</span><span>)</span>

<span>(</span><span>def</span> <span>gpu-net-bp</span> <span>(</span>network gpu
                         <span>(</span>desc <span>[</span>128 1 28 28<span>]</span> <span>:float</span> <span>:nchw</span><span>)</span>
                         net-spec<span>)</span><span>)</span>

<span>(</span><span>defonce</span> <span>gpu-net</span> <span>(</span>init! <span>(</span>gpu-net-bp <span>:adam</span><span>)</span><span>)</span><span>)</span>

<span>(</span><span>def</span> <span>gpu-x-train</span>
  <span>(</span>transfer! train-images <span>(</span>tensor gpu <span>[</span>60000 1 28 28<span>]</span> <span>:float</span> <span>:nchw</span><span>)</span><span>)</span><span>)</span>

<span>(</span><span>def</span> <span>gpu-y-train</span>
 <span>(</span>transfer! y-train <span>(</span>tensor gpu <span>[</span>60000 10<span>]</span> <span>:float</span> <span>:nc</span><span>)</span><span>)</span><span>)</span>

<span>(</span>time <span>(</span>train gpu-net gpu-x-train gpu-y-train <span>:crossentropy</span> 12 <span>[]</span><span>)</span><span>)</span>
</pre>
</div>

<p>
Elapsed time? <b>20 seconds</b> on my Nvidia GTX 1080Ti (which is a few generations old)!
</p>
</div>
</div>

<div id="outline-container-org2c2d651">
<h2 id="org2c2d651">The books</h2>
<div id="text-org2c2d651">
<p>
Should I mention that the book <a href="https://aiprobook.com/deep-learning-for-programmers/">Deep Learning for Programmers: An Interactive Tutorial with
CUDA, OpenCL, DNNL, Java, and Clojure</a> teaches the nuts and bolts of neural networks and deep learning
by showing you how Deep Diamond is built, <b>from scratch</b>? In interactive sessions. Each line of code
can be executed and the results inspected in the plain Clojure REPL. The best way to master something is to build
it yourself!
</p>

<p>
It' simple. But fast and powerful!
</p>

<p>
Please subscribe, read the drafts, get the full book soon, and support my work on this free open source library.
</p>
</div>
</div>

<div id="outline-container-orga8b021d">
<h2 id="orga8b021d">Appendix: Reading, encoding, and decoding data</h2>
<div id="text-orga8b021d">
<p>
The code that reads the raw image data and converts it to proper tensors
should go up in the sequence of execution, but is not that interesting.
</p>

<div>
<pre><span>(</span><span>defonce</span> <span>train-images-file</span> <span>(</span>random-access <span>"data/mnist/train-images.idx3-ubyte"</span><span>)</span><span>)</span>
<span>(</span><span>defonce</span> <span>train-labels-file</span> <span>(</span>random-access <span>"data/mnist/train-labels.idx1-ubyte"</span><span>)</span><span>)</span>
<span>(</span><span>defonce</span> <span>test-images-file</span> <span>(</span>random-access <span>"data/mnist/t10k-images.idx3-ubyte"</span><span>)</span><span>)</span>
<span>(</span><span>defonce</span> <span>test-labels-file</span> <span>(</span>random-access <span>"data/mnist/t10k-labels.idx1-ubyte"</span><span>)</span><span>)</span>

<span>(</span><span>defonce</span> <span>train-images</span>
  <span>(</span>map-tensor train-images-file <span>[</span>60000 1 28 28<span>]</span> <span>:uint8</span> <span>:nchw</span> <span>:read</span> 16<span>)</span><span>)</span>
<span>(</span><span>defonce</span> <span>train-labels</span>
  <span>(</span>map-tensor train-labels-file <span>[</span>60000<span>]</span> <span>:uint8</span> <span>:x</span> <span>:read</span> 8<span>)</span><span>)</span>
<span>(</span><span>defonce</span> <span>test-images</span>
  <span>(</span>map-tensor test-images-file <span>[</span>10000 1 28 28<span>]</span> <span>:uint8</span> <span>:nchw</span> <span>:read</span> 16<span>)</span><span>)</span>
<span>(</span><span>defonce</span> <span>test-labels</span>
 <span>(</span>map-tensor test-labels-file <span>[</span>10000<span>]</span> <span>:uint8</span> <span>:x</span> <span>:read</span> 8<span>)</span><span>)</span>

<span>(</span><span>defn</span> <span>enc-categories</span> <span>[</span>val-tz<span>]</span>
  <span>(</span><span>let</span> <span>[</span>val-vector <span>(</span>view-vctr val-tz<span>)</span><span>]</span>
    <span>(</span><span>let-release</span> <span>[</span>cat-tz <span>(</span>tensor val-tz <span>[</span><span>(</span>first <span>(</span>shape val-tz<span>)</span><span>)</span> <span>(</span>inc <span>(</span>long <span>(</span>amax val-vector<span>)</span><span>)</span><span>)</span><span>]</span> <span>:flo</span><span>at</span><span> </span><span>:nc</span><span> </span><span>)</span>
                  cat-matrix <span>(</span>view-ge <span>(</span>view-vctr cat-tz<span>)</span> <span>(</span>second <span>(</span>shape cat-tz<span>)</span><span>)</span> <span>(</span>first <span>(</span>shape cat-t<span>z</span><span>)</span><span>)</span><span>)</span><span>]</span>
      <span>(</span><span>dotimes</span> <span>[</span>j <span>(</span>dim val-vector<span>)</span><span>]</span>
        <span>(</span>entry! cat-matrix <span>(</span>entry val-vector j<span>)</span> j 1.0<span>)</span><span>)</span>
      cat-tz<span>)</span><span>)</span><span>)</span>

<span>(</span><span>defn</span> <span>dec-categories</span> <span>[</span>cat-tz<span>]</span>
  <span>(</span><span>let</span> <span>[</span>cat-matrix <span>(</span>view-ge <span>(</span>view-vctr cat-tz<span>)</span> <span>(</span>second <span>(</span>shape cat-tz<span>)</span><span>)</span> <span>(</span>first <span>(</span>shape cat-tz<span>)</span><span>)</span><span>)</span><span>]</span>
    <span>(</span><span>let-release</span> <span>[</span>val-tz <span>(</span>tensor cat-tz <span>[</span><span>(</span>first <span>(</span>shape cat-tz<span>)</span><span>)</span><span>]</span> <span>:float</span> <span>:x</span><span>)</span>
                  val-vector <span>(</span>view-vctr val-tz<span>)</span><span>]</span>
      <span>(</span><span>dotimes</span> <span>[</span>j <span>(</span>dim val-vector<span>)</span><span>]</span>
        <span>(</span>entry! val-vector j <span>(</span>imax <span>(</span>col cat-matrix j<span>)</span><span>)</span><span>)</span><span>)</span>
      val-tz<span>)</span><span>)</span><span>)</span>

<span>(</span><span>defonce</span> <span>train-labels-float</span> <span>(</span>transfer! train-labels <span>(</span>tensor <span>[</span>60000<span>]</span> <span>:float</span> <span>:x</span><span>)</span><span>)</span><span>)</span>
<span>(</span><span>defonce</span> <span>y-train</span> <span>(</span>enc-categories train-labels-float<span>)</span><span>)</span>
<span>(</span><span>defonce</span> <span>test-labels-float</span> <span>(</span>transfer! test-labels <span>(</span>tensor <span>[</span>10000<span>]</span> <span>:float</span> <span>:x</span><span>)</span><span>)</span><span>)</span>
<span>(</span><span>defonce</span> <span>y-test</span> <span>(</span>enc-categories test-labels-float<span>)</span><span>)</span>
</pre>
</div>
</div>
</div>


    </article></div>]]>
            </description>
            <link>https://dragan.rocks/articles/20/Deep-Diamond-Deep-Learning-in-Clojure-is-Fast-and-Simpler-than-Keras</link>
            <guid isPermaLink="false">hacker-news-small-sites-24413881</guid>
            <pubDate>Tue, 08 Sep 2020 21:48:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Is the web getting slower?]]>
            </title>
            <description>
<![CDATA[
Score 264 | Comments 257 (<a href="https://news.ycombinator.com/item?id=24413705">thread link</a>) | @oedmarap
<br/>
September 8, 2020 | https://www.debugbear.com/blog/is-the-web-getting-slower | <a href="https://web.archive.org/web/*/https://www.debugbear.com/blog/is-the-web-getting-slower">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  
  <div>
    <div>
    
      
      

      

      <div>
        
        

        <p>A story on Hacker News recently argued that webpage speeds haven't improved, even as internet speeds have gone up.</p>
<p>This article explains why that conclusion can't be drawn from the original data.</p>
<p>We'll also look at how devices and the web have changed over the past 10 years, and what those changes have meant for web performance.</p>
<p><img src="https://www.debugbear.com/public/blog/is-the-web-getting-slower/hn-article.png" alt="Webpage speeds article on Hacker News"></p>
<ol>
<li><a href="#interpreting-the-http-archive-data">Interpreting the HTTP Archive data</a></li>
<li><a href="#how-have-mobile-networks-and-devices-changed-over-the-last-10-years">How have mobile networks and devices changed over the last 10 years?</a></li>
<li><a href="#how-have-websites-changed">How have websites changed?</a></li>
<li><a href="#data-from-the-chrome-user-experience-report">Data from the Chrome User Experience Report</a></li>
<li><a href="#modelling-page-load-times">Modelling page load times</a></li>
<li><a href="#conclusion">Conclusion</a></li>
</ol>
<h2 id="interpreting-the-http-archive-data">Interpreting the HTTP Archive data</h2>
<p>This chart from the <a href="https://www.nngroup.com/articles/the-need-for-speed/">Nielsen Norman Group article</a> suggested that increasing mobile network bandwidth hasn't resulted in faster page load times.</p>
<p><img src="https://www.debugbear.com/public/blog/is-the-web-getting-slower/nngroup-mobile-webperf-chart.png" alt="Chart showing increasing bandwidth along increasing page load times"></p>
<p>However, <strong>the connection speed used by HTTP Archive has not actually increased over time.</strong></p>
<p>Instead it went down in 2013, <a href="https://httparchive.org/faq#what-changes-have-been-made-to-the-test-environment-that-might-affect-the-data">switching from wifi to an emulated 3G connection</a>.</p>
<p><img src="https://www.debugbear.com/public/blog/is-the-web-getting-slower/nngroup-mobile-webperf-chart-annotated.png" alt="Annotation for page loads time showing when methodology changed"></p>
<p>The onLoad metric has increased 55% since 2013, from 12.7s to 19.7s. If you bought a phone in 2013 and have been on a 3G connection ever since, then the web has become slower for you.</p>
<p>Before looking at how devices and the web have changed over the last 10 years, here are a few notes on how to think about this data.</p>
<h3 id="why-look-at-on-load">Why look at onLoad?</h3>
<p>The <code>load</code> event is emitted by the page when all page resources like scripts or images have been downloaded.</p>
<p>If the top of a page renders quickly, but the page also loads 20 images further down, then the onLoad metric will suggest that the page is slow.</p>
<p>A different page might not initially render anything useful at all, and only start loading additional resources and rendering content long after the onLoad event. Yet this page will appear fast.</p>
<p>As a result, onLoad doesn't do a good job measuring whether a user experiences the page as fast.</p>
<p>So why do we even look at this metric? <strong>Because it's been around for a long time</strong>, and HTTP Archive has been tracking it since 2010. Newer metrics like <a href="https://www.debugbear.com/docs/metrics/first-contentful-paint">First Contentful Paint</a> or Time to Interactive were only added to HTTP Archive in 2017.</p>
<h3 id="should-we-expect-increasing-bandwidth-to-result-in-faster-page-load-times">Should we expect increasing bandwidth to result in faster page load times?</h3>
<p>Increasing bandwidth will only make a page load faster if bandwidth is the bottleneck at some point. It won't help if you're on a Gigabit connection with a 1s network roundtrip time.</p>
<p>However, the 1.6Mbps 3G connection emulated by HTTP Archive is very slow, so we should expect significant performance improvements as bandwidth improves. The average website downloads 1.7MB of data in 2020, which will take at least 9s to download on the HTTP Archive connection.</p>
<h3 id="some-more-http-archive-caveats">Some more HTTP Archive caveats</h3>
<p>I'll talk a lot about "the average website" in this article. It's worth noting that HTTP Archive only collects data on homepages, not pages deeper down in the site. The corpus of tested domains has also grown over time.</p>
<p>The tests weren't always run on the same device. Initially a physical iPhone 4 was used, today the tests are run on an emulated Android device.</p>
<p>We'll look at median metric values in this article. If most websites are fast but one in five websites freeze your phone for 20s we won't be able to pick this up.</p>
<h3 id="performance-on-desktop">Performance on desktop</h3>
<p>This article will focus on mobile performance in the US. However, if you're looking at the desktop data from the original article, it's worth noting that the test bandwidth was increased and latency was reduced in 2013.</p>
<p><img src="https://www.debugbear.com/public/blog/is-the-web-getting-slower/desktop-performance.png" alt="Chart showing desktop connection speeds and when emulated connection speed changed"></p>
<h2 id="how-have-mobile-networks-and-devices-changed-over-the-last-10-years">How have mobile networks and devices changed over the last 10 years?</h2>
<p>Let's look at 4 factors:</p>
<ul>
<li>network bandwidth</li>
<li>network latency</li>
<li>processor speeds</li>
<li>browser performance</li>
</ul>
<h3 id="mobile-network-bandwidth-in-the-us">Mobile network bandwidth in the US</h3>
<p>This chart shows average mobile bandwidth in the US by year, according to different sources. It increased from 1 Mbps to around 30 Mbps.</p>
<p><img src="https://www.debugbear.com/public/blog/is-the-web-getting-slower/us-mobile-bandwidth.png" alt="Mobile bandwidth in the US by year"></p>
<p>(I've not been very careful when collecting this data. For example, I didn't consistently distinguish when data was collected from when it was published. <a href="https://docs.google.com/spreadsheets/d/1ifZ_ngADpT3YzezNQLpXKCsr74-BvaBJUkYm6PGpv1g/edit?usp=sharing">You can find my sources here</a>.)</p>
<h3 id="mobile-network-latency-in-the-us">Mobile network latency in the US</h3>
<p>This was harder to find data on, but the results indicate that latency dropped from around 200ms in 2011 to 50ms in 2020.</p>
<p><img src="https://www.debugbear.com/public/blog/is-the-web-getting-slower/us-mobile-latency.png" alt="Mobile latency in the US by year, going down from 200ms in 2011 to 50ms in 2020"></p>
<h3 id="mobile-device-cpu-speeds">Mobile device CPU speeds</h3>
<p>I've not been able to find data on average mobile device speeds in the US. But <a href="https://infrequently.org/">Alex Russel</a> and <a href="https://surma.dev/">Surma</a> have published a <a href="https://twitter.com/slightlylate/status/1233275220275818498">chart showing GeekBench 4 scores alongside the release years of different phones</a>.</p>
<p>Even budget phones have become 4x faster, with iPhones now being up to 20x more powerful.</p>
<p><img src="https://www.debugbear.com/public/blog/is-the-web-getting-slower/mobile-cpu-benchmark.jpeg" alt="Mobile CPU performance over time"></p>
<h3 id="how-have-browsers-changed">How have browsers changed?</h3>
<p>A lot of work has been done on browsers over the last 10 years. JavaScript has become a larger part of the web, so many improvements have focussed here.</p>
<p>Looking at <a href="https://v8.dev/blog/10-years">this chart from the V8 blog</a>, page CPU usage for gone down by a factor of 4.</p>
<p><img src="https://www.debugbear.com/public/blog/is-the-web-getting-slower/v8-performance.png" alt="V8 Speedometer 1 benchmark results 2013 to 2018"></p>
<h4 id="networking">Networking</h4>
<p>Browser networking has also improved, for example with the introduction of HTTP/2 in 2015. 64% of requests are now served over HTTP/2.</p>
<p><img src="https://www.debugbear.com/public/blog/is-the-web-getting-slower/http2.png" alt="HTTP/2 adoption over time"></p>
<h2 id="how-have-websites-changed">How have websites changed?</h2>
<p>Let's look at some data from HTTP Archive to see how websites have changed.</p>
<h3 id="page-weight">Page weight</h3>
<p><a href="https://httparchive.org/reports/page-weight">Mobile page weight</a> increased by 337% between 2013 and 2020. This is primarily driven by an increase in images and JavaScript code.</p>
<p>Other resources also increased a lot –&nbsp;I suspect these are mostly videos.</p>
<p><img src="https://www.debugbear.com/public/blog/is-the-web-getting-slower/page-weight.png" alt="Page weight by resource type over time"></p>
<p>The chart starts in 2013 as HTTP Archive changed its methodology in October 2012. Before page weight was undercounted, as the test stopped when the page load event was triggered, even if more data was still being loaded.</p>
<h3 id="java-script-execution-time">JavaScript execution time</h3>
<p>JavaScript would be the most likely culprit if pages are getting slower despite faster mobile networks. Unfortunately, HTTP Archive only started collecting this data in late 2017, and it seems to have been mostly stable since then.</p>
<p><img src="https://www.debugbear.com/public/blog/is-the-web-getting-slower/javascript-execution-time.png" alt="HTTP Archive JavaScript execution time chart"></p>
<p>The drop in mid-2018 can probably be attributed to a URL corpus change.</p>
<p>Note that the absolute run duration (0.5s) is less than what you'd normally see in a tool like Lighthouse. These tools normally slow down JavaScript execution to emulate a mobile device, but <a href="https://almanac.httparchive.org/en/2019/methodology#lighthouse">this was broken for the HTTP Archive tests</a>. So while this number might be realistic for mid-range phones, a common assumption is that budget phones are around 4x slower.</p>
<h2 id="answering-whether-the-web-has-become-slower">Answering whether the web has become slower</h2>
<p>Has the web become slower? Well, it depends on what your device, network connection, and most-used websites are.</p>
<p>We'd need to weigh real-world performance data to get a distribution that shows how different users experienced the web over time. And should the experience of someone opening thousands of pages a day count as much as someone who only visits Facebook once a week?</p>
<p>I don't have detailed per-user data, but we can take a look at the question in a few different ways:</p>
<ol>
<li>Real-user data from the <a href="https://developers.google.com/web/tools/chrome-user-experience-report">Chrome UX Report (CrUX)</a></li>
<li>Naive modelling based on how websites and devices have changed</li>
</ol>
<p>I also tried downloading old page versions from archive.org and testing them with Lighthouse, but wasn't able to get meaningful results in the time I had available. For example, often some images are missing from the page archive.</p>
<h2 id="data-from-the-chrome-user-experience-report">Data from the Chrome User Experience Report</h2>
<p>The big limitation of CrUX data is that it's only been collected since late 2017. But we can still use it to see if the web has become slower in the last two and a half years.</p>
<p>Note that, unlike HTTP Archive, CrUX looks at the whole domain instead of just homepages.</p>
<p>The data we'll look at is the 75th percentile, meaning pages load at least this fast for 75% of users.</p>
<p>(I'm taking the average across websites rather than the median, which is not great.)</p>
<h3 id="us-page-load-times">US page load times</h3>
<p>CrUX data for the US does not show page performance getting worse.</p>
<p>The onLoad metric shows a slight improvement, maybe due to an increase in bandwidth. Or maybe more activity is now happening after the initial page load.</p>
<p><img src="https://www.debugbear.com/public/blog/is-the-web-getting-slower/crux-us.png" alt="Page load speeds in the US"></p>
<p>The paint metrics seem fairly stable. Largest Contentful Paint is a new metric that has only been collected since mid-2019.</p>
<h3 id="the-rest-of-the-world">The rest of the world</h3>
<p>The downward trend in the US onLoad metric is matched by the global data. There are however signifianct differences in page load times across countries, with onLoad timings in India being almost twice those in South Korea.</p>
<p><img src="https://www.debugbear.com/public/blog/is-the-web-getting-slower/crux-global.png" alt="Page load speeds globally, in the US, UK, Korea, and India"></p>
<p>We can use CrUX data to put HTTP Archive data into perspective. In January 2020 HTTP Archive reported a median (50% percentile) load time of 18.7s, based on its synthetic data.</p>
<p>In contrast, CrUX suggests a load time of just 5.8s –&nbsp;and this is the 75th percentile.</p>
<p>(Note that the Global values here just take an average and are not weighed by population.)</p>
<h2 id="modelling-page-load-times">Modelling page load times</h2>
<p>We can create a theoretical model of how changes in devices, networks, and websites might affect overall performance.</p>
<p>This won't be a great model, but hopefully it will still provide some insight.</p>
<h3 id="theoretical-page-download-time">Theoretical page download time</h3>
<p>Page weight has increased over time, but so has bandwidth. Round-trip latency has also gone down.</p>
<p>Downloading a file the size of the median mobile website would have taken 1.7s in 2013. If your connection hasn't improved since then downloading this much data would now take 4.4s. But with an average connection today it would only take 0.9s.</p>
<p><img src="https://www.debugbear.com/public/blog/is-the-web-getting-slower/minimum-page-download-time.png" alt="TCP download time"></p>
<p>In practice, a website wouldn't consist of just a single request, and other factors like CPU processing or server latency would also affect how quickly the page loads. The onLoad times reported by HTTP Archive are 2-3 times this lower bound.</p>
<p>But we can still use this as an indicator that reduced latency and increased bandwidth have helped make websites load faster overall.</p>
<p>(I'm starting in 2013 rather than 2011, as the HTTP Archive page weight metric has only been measured consistently since then.)</p>
<h3 id="cpu">CPU</h3>
<p>I'm not quite sure how to think about this, but I'll make some guesses anyway.</p>
<p>Someone who used a Galaxy S4 in 2013 and now uses a Galaxy S10 will have seen their CPU processing power go up by a factor of 5. Let's assume that browsers have become 4x more efficient since then. If we naively multiply these numbers we get an overall 20x improvement.</p>
<p>Since 2013, JavaScript page weight has increased 3.7x from 107KB to 392KB. Maybe minification and compression have improved a bit …</p></div></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.debugbear.com/blog/is-the-web-getting-slower">https://www.debugbear.com/blog/is-the-web-getting-slower</a></em></p>]]>
            </description>
            <link>https://www.debugbear.com/blog/is-the-web-getting-slower</link>
            <guid isPermaLink="false">hacker-news-small-sites-24413705</guid>
            <pubDate>Tue, 08 Sep 2020 21:33:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Non-Posix File Systems]]>
            </title>
            <description>
<![CDATA[
Score 377 | Comments 153 (<a href="https://news.ycombinator.com/item?id=24412970">thread link</a>) | @nsm
<br/>
September 8, 2020 | https://weinholt.se/articles/non-posix-filesystems/ | <a href="https://web.archive.org/web/*/https://weinholt.se/articles/non-posix-filesystems/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">
      <div>
        <article>
          <section><p>Operating systems and file systems have traditionally been developed
hand in hand. They impose mutual constraints on each other. Today we
have two major leaders in file system semantics: Windows and <span>POSIX</span>.
They are very close to each other when compared to the full set of
possibilities. Interesting things happened before POSIX monopolized
file system&nbsp;semantics.</p>

<p>When you use a file system through a library instead of going through
the operating system there are some extra possibilities. You are no
longer required to obey the host operating system’s semantics for
filenames. You get to decide if you use <code>/</code> or <code>\</code> to separate
directory components (or something else altogether). Maybe you don’t
even use strings for filenames. The <a href="https://gitlab.com/weinholt/fs-fatfs">fs-fatfs</a> library uses
a list of strings, so it’s up to the caller to define a directory
separator for themselves. While working on that library, I was driven
to write down some ideas that I’ve previously run across and found&nbsp;inspirational.</p>

<p>The very first hierarchical file system was developed for Multics. It
is described in the
paper
<a href="https://www.multicians.org/fjcc4.html">A General-Purpose File System For Secondary Storage</a> (1965)
by Robert C. Daley and Peter G. Neumann. There are several things that I find
astounding about this&nbsp;paper:</p>
<ul>
<li>There were apparently no hierarchical file systems before Multics.
The references do no cite any previous work on this and I haven’t
found&nbsp;any.</li>
<li>Privacy in computing was a big consideration even back&nbsp;then.</li>
<li>Modern hierarchical file system are essentially unchanged from 1965,
but some features disappeared along the&nbsp;way.</li>
<li>There’s a <em>very</em> interesting backup system described in this&nbsp;paper.</li>
</ul>
<p>The paper describes these concepts that we still use&nbsp;today:</p>
<ul>
<li>Files.</li>
<li>Directories.</li>
<li>Root&nbsp;directory.</li>
<li>Working&nbsp;directory.</li>
<li>Tree name, i.e. the name of a file or directory in the tree
structure. Akin to&nbsp;realpath(3).</li>
<li>Path name, which is like a tree name, but it is conceptually
different because components can be links. The paper used <code>":"</code>
instead of <code>"/"</code> to separate&nbsp;directories.</li>
<li>Relative paths. They used an initial <code>":"</code> in place of <code>"./"</code> (or
empty) and <code>"*"</code> in place of <code>".."</code>. Instead of <code>"cd .."</code> you used
<code>"CHANGEDIRECTORY :*"</code>.</li>
<li>Symbolic&nbsp;links.</li>
<li>Access control using access control lists (showed up relatively
recently in&nbsp;<span>POSIX</span>).</li>
<li>Read, execute and write modes on files and directories. Execute
on a directory means permission to search it, just as in&nbsp;<span>POSIX</span>.</li>
<li>Segments and segment numbers (file descriptions and file
descriptors, respectively, if I’m not&nbsp;mistaken).</li>
</ul>
<p>It is said that Unix took inspiration from Multics and simplified
things. What was lost? Whoever implemented the file system for Unix
stopped reading the paper somewhere around subsection 2.3. There are
at least these features we’re&nbsp;missing:</p>
<ul>
<li><p>Access control lists can define a <span>TRAP</span> for a user. Users can refuse
to use TRAPs and instead get an error. Otherwise TRAPs call a named
function at the time of the access. They can be used to implement
smart files that can e.g. monitor file usage or apply password-based
file&nbsp;locks.</p>
<p>(Someone will undoubtedly insert eBPF into the Linux <span>VFS</span> soon and we
will have invented TRAPs&nbsp;again).</p>
</li>
<li><p>Multics fully separated the append mode and the write mode and made
it available to users. You could actually have files and
<em>directories</em> that were writable but not appendable, or appendable
but not writable (or&nbsp;both).</p>
<p>(Append-only <em>files</em> exist on Linux through file attributes settable
by the super user or processes with <code>CAP_LINUX_IMMUTABLE</code>. This is
very weak sauce. Immutable directories exist, but not append-only
directories. And of course there is no way to have a writable file
or directory that can’t&nbsp;grow).</p>
</li>
<li>Directory entries that point to secondary storage. <em>This is a game
changer for file system management.</em> More on this&nbsp;below.</li>
</ul>
<h2 id="multiple-level-storage-and-backups">Multiple-level storage and&nbsp;backups</h2>
<p>Files in the Multics file system could have directory entries that
point to a secondary storage medium. At the time the secondary media
were tapes, but today they could be mechanical hard drives, <span>USB</span> drives
or network servers. But what is the point of having a file that isn’t
there? It’s really quite clever and it only gets more clever the more
you look at&nbsp;it.</p>
<p><strong>When a Multics system was running out of disk space it could remove
unused files from the primary medium, but keep the directory entries.</strong>
If you then tried to open such a file it would ask you to wait while
the file is being made available. It would issue instructions to the
operator (perhaps later a tape robot) to have them retrieve the
required tapes for restoring the file. Very useful when disks were
small and tapes were&nbsp;plentiful.</p>
<p>But it gets even better when you consider backups. Today if you need
to restore a Linux system from backups you do it this way: find the
oldest full backup and restore it, then restore each incremental
backup, going from oldest to newest. This means that the system can’t
be used until you’ve completely restored it from the backups. With
today’s disk sizes that could take a very, very long&nbsp;time.</p>
<p>Multics backups are done differently. To restore a completely hosed
system you first restore the system files, which will allow you to
boot. Then you restore the <em>latest</em> incremental backup. After this the
file system will contain the most current directory entries. <strong>Just
restore one incremental backup tape and all the files are already in
their right places. This is <em>much</em> faster than waiting for everything
to be&nbsp;restored!</strong></p>
<p>Why is only the latest incremental backup required to get everything
back in its place and working? The clever part is that the files might
not yet be on the disk. In fact, most files will probably be on
another backup medium. But the most recently used files have been
restored, so you can most likely do useful work already, and all other
files have their directory entries. If you try to open a file that
hasn’t been restored then you’re asked to wait and the operator is
told which tape to put in to get the file&nbsp;back.</p>
<p>Is something like this offered on <em>any</em> <span>POSIX</span>-compatible file&nbsp;system?</p>

<p>The Xerox Alto was also a system of many firsts. It is most famous for
having the first windowing <span>GUI</span>, which inspired Apple’s design, which
then inspired Microsoft’s design. Of course it had a hierarchical file
system with version numbers, and even a network file&nbsp;system.</p>
<p>I would like to highlight the interesting disk structure of the Alto
file system, which is described in the
paper
<a href="https://www.microsoft.com/en-us/research/publication/an-open-operating-system-for-a-single-user-machine/">An Open Operating System for a Single-User Machine</a> (1979)
by Butler Lampson and Robert F.&nbsp;Sproull.</p>
<p>The designers of the system were concerned about data loss caused by
hardware issues and buggy software. They came up with a feature to
protect the user’s data against loss of any block on the disk. (Unless
the user data was in that lost block, of&nbsp;course).</p>
<p>All blocks on the disk have a label that contains these&nbsp;fields:</p>
<ul>
<li>A file&nbsp;identifier</li>
<li>A version&nbsp;number</li>
<li>A page number (block&nbsp;index)</li>
<li>A&nbsp;length</li>
<li>A next link (pointer to the next block in the&nbsp;file)</li>
<li>A previous&nbsp;link</li>
</ul>
<p>The label means that each block is self-identifying. By my count this
type of disk had an additional 14 bytes of label per each 512 byte&nbsp;block.</p>
<p><strong>If the disk structure is damaged then a special program called the
<em>scavenger</em> will iterate over all blocks and recover the structure.</strong>
Contrast this to a file system like ext4 where a damaged structure can
mean that huge swathes of data are rendered&nbsp;inaccessible.</p>
<p><strong>The scavenger was also used to upgrade the disk structure.</strong> Imagine
converting in-place between ext4, btrfs or <span>ZFS</span> by just running a
scavenger for the new disk structure. It would e.g. regard the
existing ext4 metadata as nonsense and build a new disk structure
based on btrfs by using the labels. (It will not work with these
specific file systems, but it demonstrates the&nbsp;principle).</p>
<p>Why don’t we have this today? Nobody wants to build a <span>POSIX</span> file
system that uses labels because the disks we’re using have 512-byte or
4096-byte blocks and no room for a label. A label would have a very
small overhead for each block, but even a very small overhead like
this is not acceptable to file system designers. More seriously, it
would mess up mmap(2). There are disks with slightly larger blocks
meant to store a label, but they are more expensive and not very
common. So we’re left with fragile file system structures and the sage
advice that you’re supposed to have backups anyway (for which, see
previous&nbsp;section).</p>
<p>The best modern alternative is something like Btrfs or <span>ZFS</span>. Blocks are
checksummed and those checksums are stored next to the pointers in the
disk structure. A modern version of the Alto file system should
certainly have checksums, but not using labels gives weaker
protections than what the Alto file system provided. If you want to
see how relevant the Alto file system design is today, just read what
using ZFS protects against, but then remember that it doesn’t use&nbsp;labels.</p>

<p>Hydra is another historical operating system with innovations in the
file system. It is described in the
paper
<a href="https://research.cs.wisc.edu/areas/os/Qual/papers/hydra.pdf"><span>HYDRA</span>: The Kernel of a Multiprocessor Operating System</a> (1974)
by W. Wulf, E. Cohen, W. Corwin, A. Jones, R. Levin, C. Pierson, and
F. Pollack at Carnegie-Mellon&nbsp;University.</p>
<p>Hydra does away with the idea of ownership and a hierarchy of ever
more privileged components. It uses a fundamentally different concept
of protection and security than what <span>POSIX</span> is based&nbsp;on.</p>
<blockquote>
<p>“Technologists like hierarchical structures – they are elegant; but
experience from the real world shows they are not viable security
structures. The problem, then, which <span>HYDRA</span> attempts to face
squarely, is to maintain order in a nonhierarchical&nbsp;environment.”</p>
<p>– <span>HYDRA</span>: The Kernel of a Multiprocessor Operating System&nbsp;(1974)</p>
</blockquote>
<p>Resources that need protection, such as files, are called <em>objects</em>.
You can apply an <em>operation</em> to an object, such as reading or writing.
But to do so you need a reference to that object, which is called a
<em>capability</em>. You can even know a file’s identity, but without the
reference you can’t do&nbsp;anything.</p>
<p>This is similar, but not identical, to a safe programming …</p></section></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://weinholt.se/articles/non-posix-filesystems/">https://weinholt.se/articles/non-posix-filesystems/</a></em></p>]]>
            </description>
            <link>https://weinholt.se/articles/non-posix-filesystems/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24412970</guid>
            <pubDate>Tue, 08 Sep 2020 20:32:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Remotely Controlled Escape Room]]>
            </title>
            <description>
<![CDATA[
Score 79 | Comments 25 (<a href="https://news.ycombinator.com/item?id=24412881">thread link</a>) | @alexissantos
<br/>
September 8, 2020 | https://www.thebureauorlando.com/remote-games | <a href="https://web.archive.org/web/*/https://www.thebureauorlando.com/remote-games">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><h4>WILL&nbsp;I&nbsp;NEED&nbsp;ZOOM?</h4><p>No, just click the remote mission link you receive after booking and you'll automatically join an audio call.</p></div><div><h4>is this a vdeo call?</h4><p>Keep those pajamas on, operative. This is an audio-only chat. Be sure to have a working microphone.</p><p>‍</p><p>‍</p><p>‍</p><p>‍</p></div><div><h4>What happens if we miss our mission time?</h4><p>You can reschedule for another time slot.</p><p>‍</p><p>‍</p><p>‍</p><p>‍</p><p>‍</p></div><div id="w-node-20c05ba31358-0dfb5e62"><h4>What happens if we're late?</h4><p>If you're more than 5 minutes late to your game, we'll help you reschedule for another time slot.</p><p>‍</p><p>‍</p><p>‍</p><p>‍</p><p>‍</p></div><div><h4>What browsers are supported?</h4><p>Currently, we support Chrome on desktop and laptops, and both chrome and safari on tablets.</p><p>‍</p><p>‍</p><p>‍</p><p>‍</p><p>‍</p></div><div><h4>What DEvice Can I play this on?</h4><p>Currently, we support laptops, desktops, and tablets.</p><p>‍</p><p>‍</p><p>‍</p><p>‍</p><p>‍</p></div></div>]]>
            </description>
            <link>https://www.thebureauorlando.com/remote-games</link>
            <guid isPermaLink="false">hacker-news-small-sites-24412881</guid>
            <pubDate>Tue, 08 Sep 2020 20:27:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Recipe nutrition calculator focusing on micronutrients]]>
            </title>
            <description>
<![CDATA[
Score 13 | Comments 9 (<a href="https://news.ycombinator.com/item?id=24411315">thread link</a>) | @scxyz42
<br/>
September 8, 2020 | https://www.soupersage.com/recipe-nutrition-calculator | <a href="https://web.archive.org/web/*/https://www.soupersage.com/recipe-nutrition-calculator">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    
    <p>
      Calculate detailed nutrition for your favorite recipes, including calories, carbs, protein, and dozens of micronutrients (vitamins and minerals).<br>
      Adjust the amount of each ingredient and see how the nutrition changes.
    </p>
    <br>
    <div>
      <div>
        <div>
          <p>
            Use a recipe link
          </p>
          <div>
                        
            <form method="POST" action="/recipe-nutrition-calculator" name="parse_recipe_form" id="parse_recipe_form">
                            <label><strong>Recipe Link</strong></label>
              <div>
                
              </div>
            </form>
            <br>
          </div>
        </div>
        <br>
        <div>
          <p><span>OR</span> Copy and paste ingredients
          </p>
          <div>
                        
            <form method="POST" action="https://www.soupersage.com/recipe-nutrition-calculator/pasta/new" name="update_recipe_form" id="update_recipe_form">
        <div>
        
    </div>
    <div>
        <p><label><strong>Ingredients</strong></label>
            
        </p>
         
            <div>
                <br>
                </div>     
            </div>
</form>          </div>
        </div>
      </div>
      <div>
        <div>
          <div>
                        <p>Sample Recipe - Nutrition Analysis</p>
            <p><img src="https://www.soupersage.com/css/img/sample-recipe-nutrition-calculator.jpg" alt="Sample recipe nutrition calculator results">
          </p></div>
        </div>
      </div>
    </div>
    <div>
      <div>
        
        <p><small>
          Food nutritional data is sourced from USDA and NIH <sup><a href="https://fdc.nal.usda.gov/" target="_blank">[1]</a></sup><sup><a href="https://data.nal.usda.gov/dataset/usda-database-flavonoid-content-selected-foods-release-32-november-2015" target="_blank">[2]</a></sup>. The guest version for RDA is based Harvard Medical's adult female on a 2000 calorie diet.<sup><a href="https://www.health.harvard.edu/staying-healthy/listing_of_vitamins" target="_blank">[3]</a></sup> 
        </small></p></div>
    </div>
  </div></div>]]>
            </description>
            <link>https://www.soupersage.com/recipe-nutrition-calculator</link>
            <guid isPermaLink="false">hacker-news-small-sites-24411315</guid>
            <pubDate>Tue, 08 Sep 2020 18:28:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Leadership in crisis – why the West needs Plato more than ever]]>
            </title>
            <description>
<![CDATA[
Score 44 | Comments 55 (<a href="https://news.ycombinator.com/item?id=24410627">thread link</a>) | @deepbow
<br/>
September 8, 2020 | https://engelsbergideas.com/essays/leadership-in-crisis-why-the-west-needs-plato-more-than-ever/ | <a href="https://web.archive.org/web/*/https://engelsbergideas.com/essays/leadership-in-crisis-why-the-west-needs-plato-more-than-ever/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-id="9549bc7" data-element_type="widget" data-settings="{&quot;_animation&quot;:&quot;fadeIn&quot;,&quot;_animation_delay&quot;:500}" data-widget_type="theme-post-content.default">
				<div>
			
<p>Benjamin Disraeli, speaking in the House of Commons in 1872, said of then Prime Minister William Gladstone’s Cabinet: ‘Behold, a range of extinct volcanoes; not a flame flickers upon a single pallid crest.’ ‘Extinct volcanoes’ would be far too generous a phrase to describe the current crop of Western leaders – if political regimes could be said to decay from the head downwards, then we are in some trouble. The political scientist Wilfred Pareto said that leaders can be divided into two types – lions who are distinguished by their machismo and foxes who are distinguished by their intelligence. In world politics, the lions are on the rampage because the foxes have abandoned the public weal.</p>



<p>In America, the proportion of people who say that they trust government has fallen from about three-quarters in the early 1960s to less than a third today. Across the rest of the West, opinion is moving in the same direction if not quite as sharply.&nbsp;Governance has emerged as a central feature of the Covid-19 crisis: we have learnt that good government can make all the difference between living and dying. One problem with poor government is that it is self-sustaining. The lower government falls in public esteem the more likely it is that able people will shun it. And the more able people shun it the more government becomes a butt of jokes, even the object of outright contempt.</p>



<p>The problem of good government and leadership is nothing new. In the 18<sup>th</sup>&nbsp;and early 19<sup>th</sup>&nbsp;centuries, England’s political system was known as ‘Old Corruption’ because it was so self-serving. An entrenched elite treated the state as a source of jobs and benefits. The state was so disconnected from the forces of industry and commerce that were transforming society that many liberals wanted to reduce government to a night-watchman.&nbsp;These tensions are never far away from the contemporary scene. Modern politicians routinely take up lucrative jobs in the private sector when they leave office – often working for the industries that they once regulated. Indeed,&nbsp;‘reciprocal nepotism’ is now so commonplace on Capitol Hill, with members of Congress giving jobs to the children of friends in return for their friends giving jobs to their children, that Melanie Sloan, of Citizens for Responsibility and Ethics in Washington, comments: ‘Members of Congress basically are profit centres for their entire families’.</p>



<p>How did the Victorians shake themselves out of this cycle of decline? A cohort of reforming politicians and educators realised that a successful commercial society required a successful modern state. They suggested a solution: a collective immersion in the wisdom of Plato. They set about revitalising the patronage-ridden civil service and educational world by opening opportunities and jobs to competition.<strong> </strong>They treated Plato’s&nbsp;<em>Republic</em>  as a near deified talisman against&nbsp;the twin evils of self-indulgence and short-termism. In the present day, this spirit requires us to set down self-help guides and leadership manuals in favour of the same text that inspired the Victorians. Not only does Plato provide a comprehensive explanation of why a republic needs a leadership class, he also provides a guide to producing one.</p>



<p>The great philosopher’s starting point is that government&nbsp;<em>matters</em>. A republic is rather like a ship at sea, he says. Whether the ship can survive the ever-changing hazards that confront us – storms, pirates, jagged rocks – depends on the quality of the ship’s leadership. If the ship is well run, then at least it has a chance; if it is badly run, then it will flounder and everybody aboard will drown. What does being ‘well-run’ mean? Plato asks a simple question: should we give the job of steering the ship safely to the members of the crew at large, when they can’t agree on where they’re headed and most of them don’t know the rudiments of navigation? Or should we give it to a captain who has spent his entire life studying&nbsp;‘the seasons of the year, the sky, the stars, the winds and other professional subjects’?</p>



<p>The metaphor of the ship is a way of driving home Plato’s wider point about the importance of ‘guardians’. Plato argues that a successful republic is run by a class of people whose job it is to think about the long-term success of the polis. What threats are there on the horizon? What trade-offs do we need to make in order to ensure success? How might we be scuppered by known unknowns and unknown unknowns? Despite being an aristocrat, Plato argued that potential guardians – or men of gold as he described them – might occur in every class of society – and indeed might be women as well as men. If they are to escape decay, successful societies have to re-allocate leadership positions in each generation. The second job is to train the guardians through a prolonged education that involves not just academic education but also character-training designed to ensure that guardians put the public good above private interests. Morality is arguably even more important than intellect because the leaders possess so much power over everybody’s lives: if they are corrupt they will not only lead the country in the wrong direction – from the light to the darkness in Plato’s view – but will also set a model of corruption that the rest of society will only too happily follow.</p>



<p>If a society run by educated guardians is the best sort of society, in Plato’s view, a society run by the masses is the worst. Plato conceded that democracy is in many ways the most attractive form of society,&nbsp;because it combines the maximum of opportunity for the regular citizen with the maximum of freedom. But these attractions are purely superficial – democracy is like a ‘coat of many colours’, he says, that looks good when you see it in the market but turns out to be threadbare after you’ve worn it a couple of times. Voters invariably favour the short-term over the long-term and the exciting over the wise. And they are usually drawn towards bad leaders – demagogues who can weave wonderful fantasies about the state’s future but are really nothing more than charlatans, lying their way to power or buying votes with other people’s money. Plato was particularly scathing about aristocrat-demagogues who enjoy the advantage of the best education that money can buy but nevertheless prefer to pander to the mob rather than to guide it to the light.</p>



<p>Democracy’s fetishisation of freedom inevitably gives way to anarchy. Fathers pander to their sons, teachers to their pupils, humans to animals, and ‘the minds of the citizens become so sensitive that the least vestige of restraint is resented as intolerable’. Anarchy produces class struggle, as the poor attack the rich and the rich retaliate; class struggle produces war and disorder. When all this becomes intolerable the masses will turn to a dictator who can restore order.</p>



<p>If tyrants are the unavoidable consequence of democracy, they are also the antithesis of philosopher kings. They regard power as an end in itself rather than a means to an end, and they are governed by their passions rather than their reason. Thus the paradox at the heart of tyranny: even though tyrants have absolute power over other people, they have no power over themselves. Slaves to their own passions – ‘ill-governed’ in their own souls as Plato puts it – they use their positions to inflict those passions on the entire population. A tyranny is a psycho-drama in which everyone is caught up in the tyrant’s raging ego.</p>



<p>Many of Plato’s suggestions for producing successful guardians strike us today as at the minimum bizarre.&nbsp;He believed that the guardians should be banned from getting married or owning private property in order to focus their minds on the common good. He was so keen on producing the best guardians that he advocated eugenic breeding programmes (guardians would be compensated for not getting marred by being allowed to participate in regular orgies with women selected for their brains and beauty). But even if he was far-fetched in his solutions, he was right in the problems that he identified. Guardians will cease to be guardians if they put themselves and their families among the public good, degrading public offices and turning the people against them.</p>



<p>William Gladstone, the greatest liberal reformer of the 19<sup>th</sup>&nbsp;century, believed that, if the 17<sup>th</sup>&nbsp;century was the age of the rule of prerogative, and the 18<sup>th</sup>&nbsp;century one of rule by patronage, the 19<sup>th</sup>&nbsp;century should be ruled by virtue, and Plato was to be the new age’s guiding force.</p>



<p>Gladstone was so fluent in Classical Greek that, in 1858, he gave a speech to the inhabitants of the Ionian Islands (a British protectorate) in the language. Thomas Arnold, the headmaster of Rugby and the greatest school reformer of his age, adopted many of Plato’s signature ideas: that education was as much about shaping character as shaping intellect; that group loyalty should trump individual self-expression; and that physical education was as important as book learning. The two most influential civil servants of the age, Charles Trevelyan and Cyril Northcote, abolished patronage in the civil service and introduced open competition in order specifically to promote the rule of a Platonic ‘natural aristocracy’.</p>



<p>Benjamin Jowett, the master of Balliol from 1870 until his death in 1893, devoted his life to two great projects: producing a definitive edition of Plato&nbsp;and turning his college into a production line for Platonic guardians. Though he failed at his first task – his edition of&nbsp;<em>The Republic</em>&nbsp;was only completed after his death by his friend and biographer Lewis Campbell – he succeeded spectacularly at the second. Balliol became the leading educational institution in the empire.&nbsp;Jowett’s pupils included Lord Curzon, a future viceroy of India, Lord Grey, a future foreign secretary, Herbert Asquith, a future prime minister, Cosmo Gordon Lang, a future archbishop of Canterbury and Charles Gore, a future …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://engelsbergideas.com/essays/leadership-in-crisis-why-the-west-needs-plato-more-than-ever/">https://engelsbergideas.com/essays/leadership-in-crisis-why-the-west-needs-plato-more-than-ever/</a></em></p>]]>
            </description>
            <link>https://engelsbergideas.com/essays/leadership-in-crisis-why-the-west-needs-plato-more-than-ever/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24410627</guid>
            <pubDate>Tue, 08 Sep 2020 17:30:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Axial Brought DevOps into Slack Saving 1000s of Hours of Developer Time]]>
            </title>
            <description>
<![CDATA[
Score 15 | Comments 3 (<a href="https://news.ycombinator.com/item?id=24410267">thread link</a>) | @slajax
<br/>
September 8, 2020 | https://cto.ai/blog/how-axial-brought-devops-into-slack-saving-thousands-of-hours-of-developer-time-and-costs/ | <a href="https://web.archive.org/web/*/https://cto.ai/blog/how-axial-brought-devops-into-slack-saving-thousands-of-hours-of-developer-time-and-costs/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://cto.ai/blog/how-axial-brought-devops-into-slack-saving-thousands-of-hours-of-developer-time-and-costs/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24410267</guid>
            <pubDate>Tue, 08 Sep 2020 16:55:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Verne Edquist – Glenn Gould’s Piano Man]]>
            </title>
            <description>
<![CDATA[
Score 79 | Comments 27 (<a href="https://news.ycombinator.com/item?id=24410113">thread link</a>) | @bookofjoe
<br/>
September 8, 2020 | https://www.glenngould.ca/verne-edquist/ | <a href="https://web.archive.org/web/*/https://www.glenngould.ca/verne-edquist/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
				 <!-- .et_pb_column --><div>
				
				
				<div>
				
				
				<div><p><span>In the winter of 1938, deep into the Depression,&nbsp;eight-year-old Verne was put on a train and sent 2,000 miles east, to the Ontario School for the Blind. It was when Verne was in the school’s hospital for six weeks with scarlet fever that he first heard the sound of a piano being tuned – the intervals being stretched and shortened. It was a pinging sound, not quite musical, and hardly melodic.</span></p>
<p><span>Once he had recovered,Verne sought out the school’s tuning shop. As it happened, he had a near perfect ear, and he studied the craft of piano tuning with rigor and determination.</span></p>
<p><span>Years later, Verne often took to quoting his tuning teacher, J. D. Ansell, whose favorite aphorism was “The only place where success comes before work is in the dictionary.” To give Verne experience, Ansell started taking his young protégé into town to tune pianos in private homes. Verne was allowed to keep the money – $2.50 per piano, and sometimes, when he got lucky, $3.00 – which he put toward some basic tools: a tuning wrench, a tuning fork, needle-nose pliers, gauges for measuring the diameter of piano wire, and rubber wedges for muting strings.</span></p>
<p><span>After graduating from high school at age 19, Verne knew his best chance at a job was to find work as a chipper in one of the many piano factories in Toronto (in the early 20th century the city directory listed no fewer than sixteen piano manufacturers). The chippers were the first tuners to work on a newly strung piano, so incomplete in construction that it still had no keys. Those initial tunings are done, first with a pitch fork, then by ear, by plucking the strings with a small chip of wood.</span></p>
<p><span>Verne started out as an apprentice chipper in the factory of the Winter Company, one of piano manufacturers.</span></p>
<p><span>He had a fishing tackle box that he had converted to a tuner’s toolbox. Over the years Verne collected dozens of tools. Some he bought from old-timers, and others he adapted from other trades. He had surgical forceps and dental explorers, which made dandy hooks, opticians’ screwdrivers for adjusting harpsichords, barber scissors for trimming felt, and shoemaker pegs for plugging holes. From the welding trade he took soapstone, a dry lubricant for the buckskin that can squeak in the action of older pianos.</span></p>
<p><span>After being laid off, Verne decided to go door-to-door, tuning pianos. He was systematic, choosing a sequence of different neighborhoods around Toronto that he could reach by street car. Verne soon grew bolder and began cold-calling at sergeants’ messes,&nbsp;asylums, and prisons. He would walk a mile and a half in a snowstorm to tune a piano, and charge $3 for a tuning. He was lucky to get one tuning a day. “That’s how things were,” he recalled years later. “I was glad to get the work. During that time you did what you could.”</span></p>
<p><span>In 1952, at the age of 21, Verne was hired as a fine-tuner in the Heintzman factory, then the largest piano manufacturer in Canada.&nbsp;Verne’s tuning always stood out, even when he was tuning pianos for the first time. To trained ears, the quality of Verne’s tuning was always superior.</span></p>
<p><span>In 1961, he moved to the T. Eaton Co., to take over as the concert tuner. Verne liked to think he could take a piano beyond mere sound, into realms of color. And he liked to think he was giving people a glimpse of that color every time he tuned a piano. Muriel Mussen, who ran the concert department, sat in a small office off the showroom floor,&nbsp;and&nbsp;came to recognize Verne’s spare style of tuning whenever she heard it. Unlike many tuners, who banged a key as hard as they could, he kept it gentle, careful not to hit the key any harder than he had to. Halfway into a piano, Verne would often hear Miss Mussen call out, “I know it’s you tuning out there, Verne.”</span></p>
<p><span>One afternoon about a year after Verne started at Eaton’s,&nbsp;Miss Mussen sent him across town to Glenn Gould’s apartment to tune Gould’s old Chickering. All Gould wanted, he told Verne, was for the tuner to do what had been done hundreds of times before: get the piano into playable condition, if only for the time being. But Verne refused, telling Gould that the tuning pins were so loose they needed to be replaced.</span></p>
<p><span>Verne’s stubborn insistence on doing things his way had endeared him to Gould, and the encounter galvanized what was to become a decades-long association between a pianist and his technician.</span></p>
<p><span>Verne tuned for many famous musicians over the years, including Duke Ellington, Arthur Rubinstein, Rudolf Serkin, Victor Borge, and Liberace. But it was the business he got from Gould that eventually enabled him to quit Eaton’s employ and sustain his family for two decades.</span></p>
<p><span>Each tolerated the other’s idiosyncracies, which were in ample evidence in both men. Gould’s quirks, of course, were legion and legendary. One of their earliest conversations was about Verne’s physical limitations. “I can’t see very well, but I get the job done,” Verne told Gould. And Gould replied that of this he had no doubt. Nothing further on the topic was ever said.</span></p>
</div>
			</div> <!-- .et_pb_text -->
			</div> <!-- .et_pb_column --> <!-- .et_pb_column -->
				
				
			</div></div>]]>
            </description>
            <link>https://www.glenngould.ca/verne-edquist/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24410113</guid>
            <pubDate>Tue, 08 Sep 2020 16:40:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: TerminusHub, Distributed Revision Control for Structured Data]]>
            </title>
            <description>
<![CDATA[
Score 81 | Comments 19 (<a href="https://news.ycombinator.com/item?id=24409334">thread link</a>) | @LukeEF
<br/>
September 8, 2020 | https://terminusdb.com/hub/ | <a href="https://web.archive.org/web/*/https://terminusdb.com/hub/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://terminusdb.com/hub/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24409334</guid>
            <pubDate>Tue, 08 Sep 2020 15:25:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[An Embarrassing Oversight Helped Create Facebook's $167bn Mobile Ads Business]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24408961">thread link</a>) | @hackyio
<br/>
September 8, 2020 | https://www.developerecosystem.com/posts/how-facebook-created-their-mobile-advertising-business/ | <a href="https://web.archive.org/web/*/https://www.developerecosystem.com/posts/how-facebook-created-their-mobile-advertising-business/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><p>Half-way through 2012, you’d have been forgiven for thinking that Facebook was doing a MySpace. In other words, Facebook was on a fast path to slow, painful decline.</p>
<p>Yahoo had just sued Facebook <a href="https://www.reuters.com/article/us-yahoo-facebook-lawsuit/yahoo-sues-facebook-for-infringing-10-patents-idUSBRE82B18M20120312">for patent infringement</a>. Zuck - like Steve Jobs before him - had <a href="https://techcrunch.com/2012/09/11/mark-zuckerberg-our-biggest-mistake-with-mobile-was-betting-too-much-on-html5/">bet too early</a> on the mobile web, and Facebook’s HTML5-powered apps were slow and buggy. Some argued that Zuck had overpaid for Instagram - $1billion for a 12 person company with no revenue, valued at <a href="https://techcrunch.com/2012/04/09/right-before-acquisition-instagram-closed-50m-at-a-500m-valuation-from-sequoia-thrive-greylock-and-benchmark/">half that amount</a> a week before Facebook bought it.</p>
<p>The share price was tanking, having lost more than half its value just 3 months after going public. In Q3 2012 the company posted a net loss - it’s second quarter as a public company. And, though more than 50% of monthly active users visited Facebook on mobile, those users generated almost no advertising revenue.</p>
<p>If that wasn’t enough to finish Facebook off, advertisers weren’t exactly flocking to it, either.</p>
<p>Google’s search ads had earned a reputation as “the new standard” in the world of direct response advertising. They were easy to buy, easy to optimise, and it was easy enough to measure the impact of them. Google had tapped directly into a “standards-based” form of brand advertising, too. Adsense enabled advertisers to buy - through auction, at scale - display ads in standard IAB formats across hundreds of thousands of websites. Plug in your existing messages and creative, pick your audience, and go. SMBs loved it.</p>
<blockquote>
<p><span>
      <span></span>
  <img alt="questionad" title="questionad" src="https://www.developerecosystem.com/static/33e8704d7a0e185a6fc798a61cc1b7c9/797d9/questionad.jpg" srcset="https://www.developerecosystem.com/static/33e8704d7a0e185a6fc798a61cc1b7c9/5a8b5/questionad.jpg 173w,
https://www.developerecosystem.com/static/33e8704d7a0e185a6fc798a61cc1b7c9/19e5e/questionad.jpg 345w,
https://www.developerecosystem.com/static/33e8704d7a0e185a6fc798a61cc1b7c9/797d9/questionad.jpg 690w,
https://www.developerecosystem.com/static/33e8704d7a0e185a6fc798a61cc1b7c9/a598d/questionad.jpg 1035w,
https://www.developerecosystem.com/static/33e8704d7a0e185a6fc798a61cc1b7c9/a1da7/questionad.jpg 1380w,
https://www.developerecosystem.com/static/33e8704d7a0e185a6fc798a61cc1b7c9/c6ff8/questionad.jpg 1491w" sizes="(max-width: 690px) 100vw, 690px" loading="lazy">
    </span><br>
<em>Exactly how many questions could be a in a Question ad?</em></p>
</blockquote>
<p>In stark contrast, Facebook ads were almost impossible to buy. There were 27 different ad units to choose from. Facebook’s “Ads and Sponsored Stories Guide” was <a href="https://allfacebook.de/wp-content/uploads/2013/01/Facebook-Ads-and-Sponsored-Stories-Guide-Januar-2013.pdf">45 pages long</a>. To ensure maximum reach to Facebook’s audience on desktop and mobile, advertisers were required to create a gazillion images of various different dimensions and ratios. An infestation of bugs paused ad campaigns for no discernable reason (usually on Fridays, for entire weekends). Even worse, GM - one of the biggest brand advertisers on Facebook - publicly said <a href="https://www.wsj.com/articles/SB10001424052702304192704577406394017764460">Facebook ads didn’t work</a>.</p>
<p>For a newly-listed company, with an advertising-based business model, the situation looked pretty bleak. Facebook was surely destined to join MySpace and Friendster in the dot-com deadpool.</p>
<p>Of course, as we now know, that never actually happened. Less than a year later, when Facebook announced Q2 2013 earnings, the <a href="https://www.theverge.com/2013/7/24/4553942/facebooks-q2-2013-earnings-beat-expectations-on-revenue-and-profit">stock shot up 21% in after hours trading</a> after an earnings beat. Mobile accounted for 41% of revenue, up from 30% the quarter before. Facebook reported its first quarter with over 1 million active advertisers. Advertising revenue in “International” markets (EMEA, APAC, and LATAM) was doubling year-over-year. ARPU - a helpful metric to understand advertising auction demand - was growing faster than ever ($1.60 in Q2 2013, it’s $7.26 today).</p>
<p>How the heck did that happen? Simple answer: some good old <a href="https://www.developerecosystem.com/posts/wtf-is-a--platform/" title="What is a Platform?">platform thinking</a>. And rationalizing.</p>
<p>When Facebook’s Ads Product team solicited feedback from marketers, it came thick and fast. It wasn’t great. Creating campaigns was equally intimidating, confusing and time consuming. Marketers were already investing time and money to create “organic” content on Facebook, like Page Posts. Adding 27 ad formats to the mix would create additional “work-work” for them.</p>
<p>To build empathy with the people they were serving, Ads PMs started adding the likes of David Ogilvy and Marshall McLuhan to their “must read” lists. And they started talking to the Ads API ecosystem more. Turns out the “work-work” problem was affecting developers, too. There were multiple ways to do similar things - or the same thing - through Facebook’s Marketing APIs. Internal confusion had been externalised to them. Wasting time re-inventing the wheel and implementing a constant barrage of new, different ad formats ate up their innovation budget.</p>
<p>A simpler approach was required. Marketers, developers, and Facebook were counting on it.</p>
<blockquote>
<p><span>
      <span></span>
  <img alt="pasystems" title="pasystems" src="https://www.developerecosystem.com/static/6fc5c3816577d11aefb047a68ec8c34e/797d9/pasystems.jpg" srcset="https://www.developerecosystem.com/static/6fc5c3816577d11aefb047a68ec8c34e/5a8b5/pasystems.jpg 173w,
https://www.developerecosystem.com/static/6fc5c3816577d11aefb047a68ec8c34e/19e5e/pasystems.jpg 345w,
https://www.developerecosystem.com/static/6fc5c3816577d11aefb047a68ec8c34e/797d9/pasystems.jpg 690w,
https://www.developerecosystem.com/static/6fc5c3816577d11aefb047a68ec8c34e/635b8/pasystems.jpg 740w" sizes="(max-width: 690px) 100vw, 690px" loading="lazy">
    </span><br>
<em>Paul Adams (now SVP Product at Intercom) was a Facebook Ads PM around then, and used simple diagrams like this to explain the “messages, containers, channels” idea.</em></p>
</blockquote>
<p>Facebook’s Ads team quickly realised advertising on Facebook shouldn’t be all that different from advertising through any medium, old or new. It didn’t matter if was billboards, newspapers, magazines, leaflets, display ads, search ads, social ads, or emails, the basics were the same - marketers wanted to get messages in front of people, to drive a response.</p>
<p>The channels may vary, and containers within those channels may vary, but the messages and objectives were the same. And, of course, the best messages were those that started new relationships between businesses and customers.</p>
<p>This simple insight brought clarity to the conversation, and to the roadmap. Marketers were already creating “messages” on Facebook, after all - Page Posts. Instead of creating “ads” why not make it so that marketers could simply pay to get their existing messages in front of more people?</p>
<p>And, if these messages contained images - wasn’t that just the same thing as “ad creative?”</p>
<p>And, if these messages already appeared in users’ feeds, didn’t “feed” also mean “mobile feed”?</p>
<p>And, if marketers paid to promote these messages in “mobile feed,” aren’t they “mobile ads?”</p>
<p>The penny dropped.</p>
<p>For a self-proclaimed “platform company,” the approach to serving marketers and developers hadn’t been “platform-ey” at all. Lots of complexity, no consistency. Lots of distinct features were built, not rationalized capabilities. The feedback shared by marketers and developers was spot on - there <em>were</em> so many ways to do similar things - or the same thing - through every ads interface, not just Facebook’s APIs. An embarrassing oversight, but fixable with the right framework.</p>
<p>Changes came thick and fast. In June 2013, Fidji Simo penned - on behalf of the Ads Product team - “<a href="https://about.fb.com/news/2013/06/an-update-on-facebook-ads/">an update on Facebook Ads</a>.” She used words like <em>simplify</em>, <em>consistent</em>, <em>redundancies</em>, <em>streamline</em>, and <em>objectives</em> to describe what was changing. Messages and images would gracefully degrade, depending on where they were delivered to people. The number of ad units would be reduced from 27 to fewer than half of that. Her final sentence summarised the changes well:</p>
<p>“We think these updates will make it easier for them (marketers) to do what they do best: reach the right groups of people with the right message and drive the results they care most about.”</p>
<blockquote>
<p><span>
      <span></span>
  <img alt="containerschannels" title="containerschannels" src="https://www.developerecosystem.com/static/2c099bcf6c20f0f3df0ef051023d6f53/8a905/containerschannels.jpg" srcset="https://www.developerecosystem.com/static/2c099bcf6c20f0f3df0ef051023d6f53/5a8b5/containerschannels.jpg 173w,
https://www.developerecosystem.com/static/2c099bcf6c20f0f3df0ef051023d6f53/19e5e/containerschannels.jpg 345w,
https://www.developerecosystem.com/static/2c099bcf6c20f0f3df0ef051023d6f53/8a905/containerschannels.jpg 663w" sizes="(max-width: 663px) 100vw, 663px" loading="lazy">
    </span></p>
<p><em>Different containers, different channels, same message.</em></p>
</blockquote>
<p>To say that Fidji was right is a mild understatement. Since 2012, marketers have <a href="https://www.statista.com/chart/2496/facebook-revenue-by-segment/">invested over $167billion in mobile advertising through Facebook</a>. In the 3rd quarter of 2019, mobile advertising represented 94% of Facebook’s overall advertising revenue. And, not all of that revenue came from the “big blue” Facebook app.</p>
<p>By simplifying the concept of a “message” reaching the “right groups of people” to “drive results,” advertisers could extend their advertising campaigns to Instagram and Facebook Audience Network with no additional effort. The messages they created would simply be presented in different types of containers, on different channels. When ads on Facebook Messenger appeared, the same messages created for Facebook and Instagram “gracefully degraded” to fit the containers on that new channel.</p>
<p>Even better, ads could quite literally be a new way to start a conversation with customers - through Facebook Messenger or WhatsApp. It was easy. SMBs loved it.</p>
<p>It didn’t stop there - life for developers improved, too. The process of integrating with Facebook’s Ads APIs became easier, and - by rationalizing across interfaces, including APIs - developers had more headspace and capacity to innovate. New Facebook Marketing Partners emerged with innovative solutions. Some, like Wix, created solutions to <a href="https://venturebeat.com/2015/07/14/wixs-integration-with-facebook-lets-you-create-page-post-ad-campaigns-via-wix-shoutout-newsletters/">extend the reach of email marketing campaigns to Facebook</a>. Others, like StitcherAds and Smartly.io enabled marketers to create <a href="https://stitcherads.com/digital-circulars/">digital circulars</a> and <a href="https://www.smartly.io/">data-fuelled ad creative</a>. As of March 2019, <a href="https://www.forbes.com/sites/brucerogers/2019/05/17/helsinki-born-kristo-ovaska-built-smartly-io-for-a-facebook-driven-ad-world/#799bce6d23df">almost $2 billion of Facebook’s annual revenue</a> flows through Smartly.io - just one partner, based in Finland. There are more like them.</p>
<p>Facebook may have solved the “reach the right groups of people with the right message” problem well for advertisers within their own walled garden, but that doesn’t mean they’ve solved it for every business in the world. These days, the volume of inbound and outbound messages - emails, SMS, WhatsApp, and the rest - is ever increasing. A challenge for everyone, not just marketers.</p>
<p>Every team, in every business, wrestles with an infinite stream of inbound messages, and outbound messages that need to land in various apps and inboxes, on a myriad of devices, formatted in different ways. The number of “channels” is exploding, not consolidating. These days, TikTok is the new Tencent, Twilio is the new Telephone. <a href="https://www.developerecosystem.com/posts/browsers--not-apps--are-still-the-future-of-mobile/" title="Browsers, not apps, are still the future of mobile">WhatsApp and WeChat are the new browsers</a>. Email and SMS are alive and well. But, just like Facebook advertising back in the day, managing all of this can be equally intimidating, confusing and time consuming.</p>
<p>The likes of Twilio - now a $40billion market cap company - are using terms like <em>omni-channel</em>, <em>programmable conversations</em> and <em>conversational messaging</em> to describe their capability to process and route inbound messages to the right teams, and route outbound messages to recipients on the channels they are most engaged with. Channels they ingest from and output to include email, SMS, voice, WhatsApp, Line, WeChat, Telegram, and many, many more.</p>
<p>If this all sounds familiar, it’s because it should be. “Graceful degradation” and orchestration of inbound and outbound messages across channels is uncannily similar to the “platform thinking” Facebook applied to create an entirely new multi-billion dollar mobile ads business.</p>
<p>This challenge, by itself, creates a market opportunity far greater than Facebook or Google's market cap. These days, the opportunity can be sized in terms of $trillions, …</p></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.developerecosystem.com/posts/how-facebook-created-their-mobile-advertising-business/">https://www.developerecosystem.com/posts/how-facebook-created-their-mobile-advertising-business/</a></em></p>]]>
            </description>
            <link>https://www.developerecosystem.com/posts/how-facebook-created-their-mobile-advertising-business/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24408961</guid>
            <pubDate>Tue, 08 Sep 2020 14:50:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Abusing dynamic groups in Azure AD for privilege escalation]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24408648">thread link</a>) | @phigcch
<br/>
September 8, 2020 | https://www.mnemonic.no/blog/abusing-dynamic-groups-in-azure/ | <a href="https://web.archive.org/web/*/https://www.mnemonic.no/blog/abusing-dynamic-groups-in-azure/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
                                




<p><em>Written by Cody Burkard, Senior Security Consultant, mnemonic</em></p>

<h2>Tl;dr</h2>
<p>mnemonic researchers have discovered a new technique for escalating privileges within Azure environments through the abuse of dynamic groups in Azure Active Directory. Organizations that employ dynamic groups for assigning user roles and rights should review their Azure Active Directory configuration to ensure they are not susceptible to this attack.</p>

<h2>Cloud security != On-prem security</h2>
<p>As organizations continue to migrate parts or all of their infrastructure to the cloud, security personnel need to adapt and understand the threats related to this cloud transition. At first glance, this doesn’t appear all too complicated, and security teams can take similar approaches to networking security as they have in traditional on-premise networks: VPNs for connectivity, network segmentation, network security appliances, agents, hardened virtual machines, etc. While these are all valid security measures for cloud infrastructure, they don’t address security concerns related to the management of infrastructure and users in the cloud.</p>
<p>For example, consider an adversary that is targeting a VM on an internal Azure network. The adversary cannot gain network access to the private Azure VNet that the VM resides on, but finds the password to an account in Azure AD. If the compromised user account has access to modify the infrastructure within Azure, they can bypass network and host-level security controls. The adversary could simply update the VM so that they may access it, or directly execute code on it. This scenario is shown below:</p>



<div>
        <a href="https://www.mnemonic.no/contentassets/1e70019b2fd44c0eaba8f5e8a3a88fff/managementplaneattack-1.png?width=1600&amp;quality=60">
    <figure>
        <img src="https://www.mnemonic.no/contentassets/1e70019b2fd44c0eaba8f5e8a3a88fff/managementplaneattack-1.png?width=790&amp;factor=2&amp;quality=60" alt="" itemprop="image">
    </figure>
        </a>
</div>
<p>This is a very simple example of pivoting into infrastructure through Azure’s “management plane”, which is used by legitimate users to manage infrastructure. This scenario is dependent on an adversary compromising an account in AAD that has privileges to run commands on VMs within the Azure infrastructure.</p>
<p>This may seem like a somewhat naïve and simple example given the requirement for a pre-compromised AAD account with special permissions in Azure. However, commonly successful techniques such as phishing, password cracking or identification of leaked secrets can lead to the compromise of an AAD account. If an account compromised using one of those techniques does not have administrative permissions, then the goal of the adversary is to identify some privileged escalation that helps them gain higher permissions.</p>
<p>The remainder of this blog post focuses on the topic of elevating privileges in Azure infrastructure with a previously compromised Azure AD account. A full summary of previous work on this topic will be contained in a future post, whereas this post will focus on a new technique targeting AAD dynamic groups.</p>

<h2>Some background on Azure Active Directory</h2>
<p>Let’s start by clearing the air about Azure vs Azure Active Directory (Azure AD or AAD).</p>
<p>When we talk about Azure, many folks jump straight to thinking about Azure Active Directory, or even Office 365. This is a common point of confusion. Microsoft has a large cloud ecosystem that is tied together with identity management and authentication through Azure Active Directory.</p>
<p>Azure Active Directory uses “tenants” to represent different organizations and environments within a company’s Microsoft cloud ecosystem, and includes a collection of users, groups and rights.&nbsp; Any one tenant may be connected to a single Office365 account, any number of Azure subscriptions, Dynamics365, Outlook, and other Microsoft cloud services.</p>
<p>So while the same Azure AD users may be used for all of these services, Azure AD is <em>not</em> a part of Azure nor a part of Office 365. Azure AD is a separate entity that handles user management and authentication, and has tight integrations with other Microsoft services.</p>
<p>With this straight, let’s briefly cover a few other basic topics that are relevant for the privilege escalation technique.</p>
<h3><strong>Azure AD Roles</strong></h3>
<p>Roles in Azure AD are top-level roles in the Microsoft Azure AD tenant for Azure AD users. At the time of writing this article, the assignment of some admin roles to Service Principal objects is also in preview. Azure AD roles allow users or service principals to perform actions including, but not limited, to:</p>
<ul>
<li>Managing security groups</li>
<li>Managing users</li>
<li>Accessing Azure infrastructure</li>
<li>Creating and managing Azure AD applications (Service Principals)</li>
</ul>
<p>The following screenshot illustrates some of these Azure AD Roles in Azure Portal:&nbsp;</p>



<div>
        <a href="https://www.mnemonic.no/globalassets/blog-bilder/azure-2.png?width=1600&amp;quality=60">
    <figure>
        <img src="https://www.mnemonic.no/globalassets/blog-bilder/azure-2.png?width=790&amp;factor=2&amp;quality=60" alt="" itemprop="image">
    </figure>
        </a>
</div>
<h3><strong>Azure RBAC Roles</strong></h3>
<p>Azure RBAC (role-based access control) roles govern access to the infrastructure deployed within Azure. This is a large and complicated topic, but the important thing to understand here is that RBAC roles determine what actions an Azure AD principal can take on specific resources deployed in Azure. For example, to deploy a VM, a user must be assigned an RBAC role that includes that action, such as owner or contributor.</p>
<h3><strong>Azure AD Security Groups</strong></h3>
<p>In Azure AD, users can be added into logical groups to help with user and access management. Azure RBAC roles and Azure AD roles can then be assigned to these groups (Azure AD role assignments to groups is in preview at the time of writing). This means that any user that is added to a group will then inherit the roles assigned to that group.</p>

<h2>The technique – abusing dynamic groups</h2>
<p>While researching and testing Azure deployments, I stumbled upon an interesting privilege escalation vector: the abuse of dynamic groups in Azure AD.</p>
<h3><strong>What are dynamic groups?</strong></h3>
<p>Dynamic groups in Azure AD allow administrators to automatically assign group memberships to users based on attributes of that user. For example, if a company has two offices in Oslo and London, they may create security groups for each of their offices. They can use dynamic groups based on the user’s “city” attribute for this purpose, so that whenever a new user is added to Azure AD, they will automatically be added to one of these two groups.</p>
<p>The following picture shows how you would do this with a dynamic group rule:</p>



<div>
        <a href="https://www.mnemonic.no/globalassets/blog-bilder/dynamicgroup-3.png?width=1600&amp;quality=60">
    <figure>
        <img src="https://www.mnemonic.no/globalassets/blog-bilder/dynamicgroup-3.png?width=790&amp;factor=2&amp;quality=60" alt="" itemprop="image">
    </figure>
        </a>
</div>
<p>This use case is fairly innocent. But let’s think of a more security sensitive case.</p>
<h3><strong>A real-world scenario for the attack</strong></h3>
<p>An organization creates a dynamic group called VM Contributors, which has VM Contributor Access scoped to the subscription:</p>



<div>
        <a href="https://www.mnemonic.no/globalassets/blog-bilder/dynamicgroup-4.png?width=1600&amp;quality=60">
    <figure>
        <img src="https://www.mnemonic.no/globalassets/blog-bilder/dynamicgroup-4.png?width=790&amp;factor=2&amp;quality=60" alt="" itemprop="image">
    </figure>
        </a>
</div>
<p>Now, this organization outsources all VM management to a company called “Bluefish”, and Bluefish uses the following naming convention:</p>

<p>To automate the process of Bluefish users being assigned VM Contributor, a rule is added to dynamically add any user with “bluefish” in the userPrincipalName (UPN) to the VM Contributor group. Seems reasonable and innocuous, since users cannot modify their UPN without appropriate access rights, and the organization has locked these down.</p>



<div>
        <a href="https://www.mnemonic.no/globalassets/blog-bilder/dynamicgroup-5.png?width=1600&amp;quality=60">
    <figure>
        <img src="https://www.mnemonic.no/globalassets/blog-bilder/dynamicgroup-5.png?width=790&amp;factor=2&amp;quality=60" alt="" itemprop="image">
    </figure>
        </a>
</div>
<h3><strong>Time to escalate some privileges</strong></h3>
<p>Let’s assume for our scenario that an adversary gains access to a low-privileged user in Azure AD, which resides in no groups or Azure RBAC roles. The compromised user has the “Global Reader” role, so the attacker can read configurations in the directory, but cannot change settings, and therefore cannot use traditional methods to change access rights to their own user, or to other users.</p>
<p>The attacker finds the dynamic membership rule, and wants to find a way to trigger the dynamic rule for an account they control. In short, the attacker needs to get the name “bluefish” in the UPN attribute of their user:</p>



<div>
        <a href="https://www.mnemonic.no/globalassets/blog-bilder/userprofile-6.png?width=1600&amp;quality=60">
    <figure>
        <img src="https://www.mnemonic.no/globalassets/blog-bilder/userprofile-6.png?width=790&amp;factor=2&amp;quality=60" alt="" itemprop="image">
    </figure>
        </a>
</div>
<p>Since users with the Global Reader role cannot edit any configurations, the attacker cannot edit their own UPN and is stuck.</p>
<h3><strong>UPN</strong></h3>
<p>User Principal Names are based on user email addresses. I have identified dynamic groups based on this attribute in the past, and on the surface seems to be okay because users generally cannot change their own email addresses. This requires administrative privileges within Azure AD and a role such as “User Administrator”. However, there is a way around this…</p>
<h3><strong>Abusing Guest Accounts</strong></h3>
<p>By default, users in Azure AD can invite guest users to the directory. Since the UPN of a guest user is still based on email addresses, an adversary can simply create a new email address from any email provider, such as Gmail, that contains “bluefish” in the address. For example:</p>

<p>If the attacker invites this email to the azure tenant:</p>



<div>
        <a href="https://www.mnemonic.no/globalassets/blog-bilder/inviteguestuser-7.png?width=1600&amp;quality=60">
    <figure>
        <img src="https://www.mnemonic.no/globalassets/blog-bilder/inviteguestuser-7.png?width=790&amp;factor=2&amp;quality=60" alt="" itemprop="image">
    </figure>
        </a>
</div>
<p>And then accepts the invite, the user will become a user in the local directory with an interesting UPN:</p>



<div>
        <a href="https://www.mnemonic.no/globalassets/blog-bilder/newuser-8.png?width=1600&amp;quality=60">
    <figure>
        <img src="https://www.mnemonic.no/globalassets/blog-bilder/newuser-8.png?width=790&amp;factor=2&amp;quality=60" alt="" itemprop="image">
    </figure>
        </a>
</div>
<p>Now we can go into the portal and check our group assignments:</p>



<div>
        <a href="https://www.mnemonic.no/globalassets/blog-bilder/groupmembership-9.png?width=1600&amp;quality=60">
    <figure>
        <img src="https://www.mnemonic.no/globalassets/blog-bilder/groupmembership-9.png?width=790&amp;factor=2&amp;quality=60" alt="" itemprop="image">
    </figure>
        </a>
</div>
<p>Now the attacker has access to the testDynamicGroup, which assigns the VM contributor role through a dynamic group membership.</p>
<p>To summarize:</p>
<ol>
<li>The attacker starts with a Global Reader in Azure AD</li>
<li>The attacker finds a dynamic group with the VM Contributor role assigned
<ol>
<li>Membership is dynamic based on the string “bluefish” existing in the UPN</li>
</ol>
</li>
<li>The attacker can invite guests, as per the default setting</li>
<li>The attacker invites a guest Gmail account with bluefish in the address - <span data-e="B9D4D6DA97D5D0D8D4DEF9D1CAD0DFDCCCD5DBDDCBD8D2CBCCDBDDDA"></span></li>
<li>The guest account triggers the dynamic group after accepting, and inherits the VM Contributor role in Azure RBAC</li>
</ol>
<h3><strong>Notes on dynamic group abuse</strong></h3>
<p>In this example, we show how dynamic groups based on a UPN can be abused using a guest account. However, there are many other attributes for determining dynamic group membership, and different types of attackers could abuse each. <strong>When setting up dynamic groups, consider whether lower privileged users or external attackers could modify the attributes that define that group.</strong></p>
<p>The following are other potential attack paths to modify user attributes on dynamic groups:</p>
<ul>
<li>AD Connect Sync – An attacker may modify user attributes in an on-premise system, and Azure AD Connect …</li></ul></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.mnemonic.no/blog/abusing-dynamic-groups-in-azure/">https://www.mnemonic.no/blog/abusing-dynamic-groups-in-azure/</a></em></p>]]>
            </description>
            <link>https://www.mnemonic.no/blog/abusing-dynamic-groups-in-azure/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24408648</guid>
            <pubDate>Tue, 08 Sep 2020 14:21:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Vitamin D, part 3 – The Evidence]]>
            </title>
            <description>
<![CDATA[
Score 290 | Comments 204 (<a href="https://news.ycombinator.com/item?id=24408511">thread link</a>) | @usefulcat
<br/>
September 8, 2020 | https://www.devaboone.com/post/vitamin-d-part-3-the-evidence?postId=5f4e8bf673d853002ded6cd3 | <a href="https://web.archive.org/web/*/https://www.devaboone.com/post/vitamin-d-part-3-the-evidence?postId=5f4e8bf673d853002ded6cd3">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-hook="post-description"><article><div><div data-rce-version="7.19.2"><div dir="ltr"><div><div id="viewer-26bnd"><div><div data-hook="imageViewer" role="button" tabindex="0"><div role="img"><p><img data-pin-url="https://www.devaboone.com/post/vitamin-d-part-3-the-evidence?postId=5f4e8bf673d853002ded6cd3" data-pin-media="https://static.wixstatic.com/media/3e0600_9d834b06083a45db9984155f34157ea8~mv2.jpg/v1/fit/w_814,h_363,al_c,q_80/file.png" src="https://static.wixstatic.com/media/3e0600_9d834b06083a45db9984155f34157ea8~mv2.jpg/v1/fit/w_300,h_300,al_c,q_5/file.jpg"></p></div></div></div></div><h3 id="viewer-4bpvv">Vitamin D deficiency is linked to cancer, heart disease, respiratory infection, stroke, diabetes, and death. </h3><p id="viewer-4ds7a">It might seem reasonable that we should all be taking this supplement. But hold on. The argument for taking Vitamin D assumes a few things. First, that low Vitamin D actually causes all of the conditions it is associated with. This is not necessarily true. Low Vitamin D could cause (or contribute to) heart disease, but it could also be that heart disease causes low Vitamin D. Another possibility is that some third factor causes both low Vitamin D and heart disease. </p><p id="viewer-9g65f">Even if we can prove some causation, we then need to assume that correcting the Vitamin D deficiency will prevent the disease. This may not be true either. Low Vitamin D may be an indicator of overall poor health, which increases the risk for cardiac disease. It could appear that low Vitamin D contributes to the condition. But raising the Vitamin D will not help because it will just fix the symptom, not the underlying problem. </p><h3 id="viewer-399rj"><strong>Randomized Controlled Trials</strong></h3><p id="viewer-4p68a">Fortunately we have studies that can help figure this out. Currently the best way to answer a question of clinical relevance is with a large, well-executed <strong>randomized controlled trial (RCT).</strong> An RCT works like this: enroll the participants you want to study and randomly assign half of them to receive a treatment and the other half to receive a placebo. Those receiving the treatment are called the intervention group. The other group is the control group. Ideally, the two groups will be similar in every way except the treatment – they will have the same distribution in age, income, race, gender, and health status. They will even receive pills that look identical, though half will be placebos. If, at the end of the study, there are differences between the two groups, we can attribute those differences to the treatment. </p><div id="viewer-3aoj5"><div><div data-hook="imageViewer" role="button" tabindex="0"><div role="img" aria-label="Simple randomized controlled trial "><p><img data-pin-url="https://www.devaboone.com/post/vitamin-d-part-3-the-evidence?postId=5f4e8bf673d853002ded6cd3" data-pin-media="https://static.wixstatic.com/media/3e0600_70919e7b7a7d480c815f451bdce6cb09~mv2.png/v1/fit/w_1674,h_920,al_c,q_80/file.png" src="https://static.wixstatic.com/media/3e0600_70919e7b7a7d480c815f451bdce6cb09~mv2.png/v1/fit/w_300,h_300,al_c,q_5/file.png" alt="Simple randomized controlled trial "></p></div><p><span dir="auto">Simple randomized controlled trial</span></p></div></div></div><p id="viewer-fvrr">RCTs are costly and time intensive, so generally we will only be able to study the interventions and outcomes that have the highest chance of showing a benefit. We base this on prior studies; if several large observational studies show a correlation between Vitamin D and heart disease, then this is something we should study with an RCT. </p><p id="viewer-1ofc5">
We now have results for over 1500 RCTs on Vitamin D supplementation. Some of the largest and most significant trials are listed and summarized at the end of this article. When tested on its ability to prevent disease, <strong>Vitamin D has failed to live up to expectations</strong>. </p><div id="viewer-b7fav"><div><div data-hook="imageViewer" role="button" tabindex="0"><div role="img" aria-label="Results of Vitamin D Trials "><p><img data-pin-url="https://www.devaboone.com/post/vitamin-d-part-3-the-evidence?postId=5f4e8bf673d853002ded6cd3" data-pin-media="https://static.wixstatic.com/media/3e0600_a25ba8bbf26b47a096d2dc2ee7e41fcd~mv2.png/v1/fit/w_1206,h_878,al_c,q_80/file.png" src="https://static.wixstatic.com/media/3e0600_a25ba8bbf26b47a096d2dc2ee7e41fcd~mv2.png/v1/fit/w_300,h_300,al_c,q_5/file.png" alt="Results of Vitamin D Trials "></p></div><p><span dir="auto">For more details, see the list of high-quality RCTs at the bottom of this page</span></p></div></div></div><p id="viewer-en75e">One of the largest and best studies we have is called <a href="https://www.vitalstudy.org/" target="_blank" rel="noopener"><u>VITAL</u></a>, led by Dr. JoAnn Manson at Brigham and Women's Hospital in Boston. Over 25,000 adults (men age 50 and older, women age 55 and older) with no history of cardiovascular disease or cancer participated in the study. They received either 2,000 IUs of Vitamin D3 or placebo daily for five years. Researchers evaluated the rates of cancer and major cardiovascular events including stroke, heart attack, and cardiovascular death. </p><p id="viewer-f6k24"><strong>The result: Vitamin D failed to prevent cancer, stroke, heart attack, or cardiovascular death. </strong>These conditions occurred at the same rate in those receiving Vitamin D and those receiving placebo. There was one positive finding, though: in a post hoc analysis, it seemed that Vitamin D decreased the mortality from cancer when the initial two years were excluded. Post hoc (“after the event”) analyses can be quite useful, but need to be viewed with some skepticism. In high-quality RCTs (like VITAL), the outcome measures and statistical analyses are specified prior to data collection. Sometimes, as in VITAL’s case, an unexpected outcome may appear at the time the data are evaluated, prompting a post hoc analysis. In this case, when results from the first two years were excluded, the rate of cancer death was 1.2% in the placebo group, and 0.9% in the Vitamin D group - 25% reduction in cancer mortality, though the absolute numbers were low. It is not possible to draw too many conclusions from this, but it is something to note for future studies. </p><p id="viewer-3cooc"><strong>Even in studies of bone health, Vitamin D has been disappointing.</strong> We already know that Vitamin D is essential in calcium metabolism, and Vitamin D deficiency can lead to bone disorders like rickets and osteomalacia. Taking Vitamin D to treat severe Vitamin D deficiency is necessary for the treatment of these conditions. But in the large trials looking at Vitamin D's ability to prevent bone loss, the participants were taken from the general population, many of whom had normal Vitamin D levels. For severely deficient individuals (only a small percentage of the population), there are clear benefits to supplementation. These benefits do not appear to extend to those with normal levels or mild deficiencies.</p><h3 id="viewer-ct6r5"><strong>Meta-analyses of randomized controlled trials</strong></h3><p id="viewer-ek5t0">Large randomized controlled trials are currently the best way to evaluate a treatment, but they are difficult to do. If done well, an RCT is expensive, time intensive, and challenging to coordinate. It is worth it if we can answer our question adequately, but sometimes we realize after the trial that we needed to account for something else, or that we need more people in the study before we can really answer our question. In addition, RCTs will not always give definitive answers. Sometimes two or more small trials of the same treatment will show opposite results, and we need to reconcile those. Simply redoing an RCT is usually not an option. Instead, scientists have developed a method of combining similar RCTs and analyzing them together, in what is called a meta-analysis. </p><p id="viewer-ab05u">Meta-analyses have exploded in popularity over the last few decades.<span> If done well, a meta-analysis of a group of trials can reveal insights that cannot be seen in the individual trials. Unfortunately there are potential problems. The quality of the meta-analysis depends on the quality of the studies it includes, which can lead to erroneous results when poor quality studies are present (garbage in, garbage out).</span></p><p id="viewer-9nlvf"><span>In addition, <strong>publication bias</strong> may incorrectly amplify a treatment effect. Publication bias occurs when researchers decide to publish only “positive” findings – studies that show a treatment effect. Suppose ten small trials of Vitamin D are performed. Five show a benefit to Vitamin D and five do not. Researchers and journals are much more inclined to publish positive results than negative, so it is possible that only the five positive studies will make it into the medical literature. A meta-analysis on the five published positive studies will show a much stronger effect of Vitamin D than a meta-analysis that included all ten studies. </span></p><div id="viewer-9ul9t"><div><div data-hook="imageViewer" role="button" tabindex="0"><div role="img"><p><img data-pin-url="https://www.devaboone.com/post/vitamin-d-part-3-the-evidence?postId=5f4e8bf673d853002ded6cd3" data-pin-media="https://static.wixstatic.com/media/3e0600_1afb8b809c0446029010b53b0b7cdf14~mv2.jpg/v1/fit/w_900,h_373,al_c,q_80/file.png" src="https://static.wixstatic.com/media/3e0600_1afb8b809c0446029010b53b0b7cdf14~mv2.jpg/v1/fit/w_300,h_300,al_c,q_5/file.jpg"></p></div></div></div></div><p id="viewer-a6n1n"> <em>Where negative studies go to die. </em></p><p id="viewer-a6bj6"><a href="https://en.wikipedia.org/wiki/Robert_Rosenthal_(psychologist)" target="_blank" rel="noopener"><em><u>Robert Rosenthal </u></em></a><em>called publication bias "the file drawer problem" because important negative studies often end up here. Photo by </em><a href="https://www.bigstockphoto.com/search/?contributor=nirat" target="_blank" rel="noopener"><em><u>nirat</u></em></a><em> on </em><a href="http://bigstockphoto.com/" target="_blank" rel="noopener"><em><u>bigstockphoto.com.</u></em></a><em> </em></p><p id="viewer-7700d"><span>Not every related trial should be included in a meta-analysis, though. One of the major challenges in performing these analyses is deciding which studies to include or exclude. Ideally only high-quality, well-designed, well-executed studies will be included. Researchers do not always agree on which studies to include, and differences in inclusion criteria have led to similar meta-analyses producing opposite results. </span><a href="https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0115934" target="_blank" rel="noopener"><u>This has occurred</u></a> <span>in studies of Vitamin D and fracture risk in older adults, with some meta-analyses showing zero benefit to Vitamin D and others showing a decreased risk of fracture, even though they included many of the same studies. </span></p><p id="viewer-donuf"><span>In addition to being high quality, the included studies should all try to answer the same clinical question. Many meta-analyses can only be done by combining trials that differ in important details, like the age of participants, treatment dosages, or definition of endpoints. Combining these may be feasible, but the clinical relevance may change when disparate groups are lumped together. For example, suppose we want to know if Vitamin D prevents asthma attacks in children. If a meta-analysis shows a small benefit to Vitamin D when all ages are combined, but the individual small studies in children did not show a benefit, what do I advise a 10 year old with asthma?</span></p><p id="viewer-9le66">Despite these challenges, meta-analyses of RCTs can provide meaningful insights. Unfortunately, most high-quality meta-analyses show similar results to our individual randomized controlled trials: <strong>Vitamin D does not appear to prevent disease in healthy adults.</strong> </p><p id="viewer-9hssp">But there are a few promising areas identified in meta-analyses. Note that some of these findings are not consistent with the large RCTs and will need to be studied further before definitive recommendations can be made. </p><p id="viewer-25ike">The areas in which meta-analyses have identified benefits from Vitamin D:</p><ol><li id="viewer-f3qjq"><p><strong>Fracture prevention in elderly nursing home residents </strong>(when also given with calcium):   This is not surprising. We know that Vitamin D and calcium can prevent bone loss in severe Vitamin D deficiency. Elderly adults who are not getting outside are more likely to be severely deficient in Vitamin D, and supplements likely help.</p></li><li id="viewer-fa0a9"><p><strong>Asthma and respiratory infection</strong>: Vitamin D seems to reduce asthma attacks in adults with mild to moderate disease, and daily or weekly Vitamin D seems to prevent acute respiratory infection in those with Vitamin D less than 10 ng/ml (25 nmol/l). There is considerable excitement around Vitamin D's potential role in Covid treatment, though we do not yet have enough evidence to make a definitive conclusion. </p></li><li id="viewer-d7fj2"><p><strong>Cancer mortality</strong>: Vitamin D does not appear to prevent cancer, but may reduce death rates from cancer overall (when all cancers are combined) when Vitamin D is taken for several years. It is not known whether Vitamin D itself fights cancer. It could also be that individuals with cancer are more prone to developing severe Vitamin D deficiency, which leads to bone loss, fragility, and fractures, which increase mortality.</p></li><li id="viewer-cvias"><p><strong>Atopic dermatitis (eczema)</strong>: Vitamin D …</p></li></ol></div></div></div></div></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.devaboone.com/post/vitamin-d-part-3-the-evidence?postId=5f4e8bf673d853002ded6cd3">https://www.devaboone.com/post/vitamin-d-part-3-the-evidence?postId=5f4e8bf673d853002ded6cd3</a></em></p>]]>
            </description>
            <link>https://www.devaboone.com/post/vitamin-d-part-3-the-evidence?postId=5f4e8bf673d853002ded6cd3</link>
            <guid isPermaLink="false">hacker-news-small-sites-24408511</guid>
            <pubDate>Tue, 08 Sep 2020 14:10:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Treachery of Image Files]]>
            </title>
            <description>
<![CDATA[
Score 105 | Comments 28 (<a href="https://news.ycombinator.com/item?id=24408509">thread link</a>) | @kick
<br/>
September 8, 2020 | http://beyondloom.com/blog/images.html | <a href="https://web.archive.org/web/*/http://beyondloom.com/blog/images.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">

<p>I have recently come into possession of a series of exquisite miniatures which I pray are worthy of your esteemed attention. While my employers are familiar with your <em>unusual tastes</em>, they also appreciate your desire for privacy- this showing was arranged with the utmost discretion, I assure you.</p>

<p>To the untrained eye, the pieces might <em>appear</em> remarkably similar. Each canvas is a digitally-reproduced composition measuring ten pixels in height and ten pixels in width, illuminated in a strikingly intense blue.</p>

<p>To an, ahem, <em>avid collector</em> such as yourself, it is no doubt obvious that each print possesses unique <em>qualia</em>, as expounded upon by the artist’s extensive footnotes. Please, take as long as you need…</p>



<figure>
<img src="http://beyondloom.com/blog/images-figures/i.png" alt="Becoming and Unbecoming. Macintosh Operating System 10.14.6, Preview.App 10.1">
<figcaption>Becoming and Unbecoming. Macintosh Operating System 10.14.6, Preview.App 10.1</figcaption>
</figure>

<p>In this piece, the artist used a carefully selected vintage of the <em>Macintosh</em> operating system. The desktop wallpaper color was customized to consist entirely of the desired blue, and then the <em>Preview</em> application was employed to take a screenshot and perform the necessary trimming. Tragically, <em>Preview</em> cannot save files in the <em>Graphics Interchange Format</em> (GIF).</p>

<figure>
<img src="http://beyondloom.com/blog/images-figures/ii.gif" alt="Pointillism I. Sublime Text 3.2.2, ImageMagick 7.0.8-59">
<figcaption>Pointillism I. Sublime Text 3.2.2, ImageMagick 7.0.8–59</figcaption>
</figure>

<p>In this piece, the artist manually constructed the image in the <em>Portable PixMap</em> (PPM) format using the <em>Sublime</em> text editor, as follows:</p>

<pre><code>P3
# width, height, depth
10 10 1
0 0 1  0 0 1  0 0 1  0 0 1  0 0 1  0 0 1  0 0 1  0 0 1  0 0 1  0 0 1
0 0 1  0 0 1  0 0 1  0 0 1  0 0 1  0 0 1  0 0 1  0 0 1  0 0 1  0 0 1
0 0 1  0 0 1  0 0 1  0 0 1  0 0 1  0 0 1  0 0 1  0 0 1  0 0 1  0 0 1
0 0 1  0 0 1  0 0 1  0 0 1  0 0 1  0 0 1  0 0 1  0 0 1  0 0 1  0 0 1
0 0 1  0 0 1  0 0 1  0 0 1  0 0 1  0 0 1  0 0 1  0 0 1  0 0 1  0 0 1
0 0 1  0 0 1  0 0 1  0 0 1  0 0 1  0 0 1  0 0 1  0 0 1  0 0 1  0 0 1
0 0 1  0 0 1  0 0 1  0 0 1  0 0 1  0 0 1  0 0 1  0 0 1  0 0 1  0 0 1
0 0 1  0 0 1  0 0 1  0 0 1  0 0 1  0 0 1  0 0 1  0 0 1  0 0 1  0 0 1
0 0 1  0 0 1  0 0 1  0 0 1  0 0 1  0 0 1  0 0 1  0 0 1  0 0 1  0 0 1
0 0 1  0 0 1  0 0 1  0 0 1  0 0 1  0 0 1  0 0 1  0 0 1  0 0 1  0 0 1
</code></pre>

<p>The <em>ImageMagick</em> application was then used to convert it into a GIF file:</p>

<pre><code>$ convert ii.ppm ii.gif
</code></pre>

<figure>
<img src="http://beyondloom.com/blog/images-figures/iii.gif" alt="Pointillism II. Vim 8.0.1365, FFmpeg 4.1.4">
<figcaption>Pointillism II. Vim 8.0.1365, FFmpeg 4.1.4</figcaption>
</figure>

<p>For this piece, the artist once again created a PPM image, this time using the <em>Vi, Improved</em> text editor, giving the source code a subtly crisper affect:</p>

<pre><code>P3
# horizontal, vertical, perchannel
10 10 1
0 0 1  0 0 1  0 0 1  0 0 1  0 0 1  0 0 1  0 0 1  0 0 1  0 0 1  0 0 1
0 0 1  0 0 1  0 0 1  0 0 1  0 0 1  0 0 1  0 0 1  0 0 1  0 0 1  0 0 1
0 0 1  0 0 1  0 0 1  0 0 1  0 0 1  0 0 1  0 0 1  0 0 1  0 0 1  0 0 1
0 0 1  0 0 1  0 0 1  0 0 1  0 0 1  0 0 1  0 0 1  0 0 1  0 0 1  0 0 1
0 0 1  0 0 1  0 0 1  0 0 1  0 0 1  0 0 1  0 0 1  0 0 1  0 0 1  0 0 1
0 0 1  0 0 1  0 0 1  0 0 1  0 0 1  0 0 1  0 0 1  0 0 1  0 0 1  0 0 1
0 0 1  0 0 1  0 0 1  0 0 1  0 0 1  0 0 1  0 0 1  0 0 1  0 0 1  0 0 1
0 0 1  0 0 1  0 0 1  0 0 1  0 0 1  0 0 1  0 0 1  0 0 1  0 0 1  0 0 1
0 0 1  0 0 1  0 0 1  0 0 1  0 0 1  0 0 1  0 0 1  0 0 1  0 0 1  0 0 1
0 0 1  0 0 1  0 0 1  0 0 1  0 0 1  0 0 1  0 0 1  0 0 1  0 0 1  0 0 1
</code></pre>

<p>The <em>Fast Forward Moving Pictures Expert Group</em> application was then used to generate a GIF:</p>

<pre><code>$ ffmpeg -i iii.ppm iii.gif
</code></pre>

<figure>
<img src="http://beyondloom.com/blog/images-figures/iv.png" alt="Searing Light. Nano 2.0.6, POV-Ray 3.7.0">
<figcaption>Searing Light. Nano 2.0.6, POV-Ray 3.7.0</figcaption>
</figure>

<p>The artist composed this piece using the <em>Persistence of Vision Raytracer</em> language, composing the following script in the <em>Nano’s Another</em> text editor:</p>

<pre><code>background { rgb &lt;0, 0, 1&gt; }
</code></pre>

<p>The scene was then raytraced as follows:</p>

<pre><code>$ povray +Iiv.pov +W10 +H10 +Oiv
</code></pre>

<p>As with <em>Preview</em> above, the <em>Persistence of Vision Raytracer</em> is intentionally designed not to support the creation of GIF files; output is a <em>Portable Network Graphics</em> file instead.</p>

<figure>
<img src="http://beyondloom.com/blog/images-figures/v.gif" alt="The Cobbler. Sublime Text 3.2.2, as 10.0.1">
<figcaption>The Cobbler. Sublime Text 3.2.2, as 10.0.1</figcaption>
</figure>

<p>This image was composed by the <em>Macintosh Operating System X Mach-O Gnu’s Not Unix-based assembler</em>, a utility for the creation of binary files. The <em>Sublime</em> text editor was once again employed for its neutral tone:</p>

<pre><code>.ascii "GIF89a" # magic number
.short 10       # width
.short 10       # height
.byte  0xF0     # 2-entry global color table
.byte  0        # background color index
.byte  0        # 1:1 pixel aspect ratio

.byte  0x00     # color 0: blue
.byte  0x00
.byte  0xFF
.byte  0x00     # color 1: black
.byte  0x00
.byte  0x00

.ascii ","      # image descriptor
.long  0        # x/y offsets
.short 10       # width
.short 10       # height
.byte  0        # no local colortable
.byte  0        # minimum LZW code size
.byte  0        # end of frame

.ascii ";"      # finish
</code></pre>

<p>Curiously, the output of this assembler is prefaced with an entirely useless header, which must then be trimmed. (Hopefully future revisions of the tool will correct this obvious usability gaffe!) The composition was thus carried out as follows:</p>

<pre><code>$ as v.s -o assembled.o
$ dd bs=1 skip=208 if=assembled.o of=v.gif
</code></pre>

<figure>
<img src="http://beyondloom.com/blog/images-figures/vi.gif" alt="Camera Obscura. oK, iKe, Safari 12.1.2">
<figcaption>Camera Obscura. oK, iKe, Safari 12.1.2</figcaption>
</figure>

<p>Here, the artist employed the <em>Interactive K Environment</em> (iKe), a tool based around the unfathomably esoteric programming language <em>K</em>. The tool can be used to save animated GIF images of program output; in this case, a single frame as indicated by <code>fc:1</code>. Note that <em>iKe</em> automatically doubles the size of pixels within images when rendering.</p>

<pre><code>w:h:5
fc:1
draw:{,(;,"blue";5 5#0)}
</code></pre>

<figure>
<img src="http://beyondloom.com/blog/images-figures/vii.gif" alt="Mu. English, Homo Sapiens">
<figcaption>Mu. English, Homo Sapiens</figcaption>
</figure>

<p>For this work, the artist composed an electronic mail message to a colleague as follows:</p>

<pre><code>Dear [REDACTED],
I pray this letter finds you well.

I am in grave need of your assistance. I require an opaque image file in the .GIF format,
measuring precisely 10 pixels square, consisting entirely of the hexadecimal RGB color #0000FF.
If you could provide me with such a file as an attachment, I would be immensely grateful.

Warmest Regards,
[REDACTED]

(P.S. This will make more sense later.)
</code></pre>

<p>Some time later, the artist used their electronic mail client to save the final print.</p>

<!-- For the record, this GIF was created in the Windows version of Krita 4.30. Thanks, Michal! -->

<figure>
<img src="http://beyondloom.com/blog/images-figures/viii.gif" alt="A Desperate Agony. VirtualBox 6.0.6, Ubuntu 19.04, GIMP 2.10.20, Shouting">
<figcaption>A Desperate Agony. VirtualBox 6.0.6, Ubuntu 19.04, GIMP 2.10.20, Shouting</figcaption>
</figure>

<p>Here, the artist constructed a virtual machine- a sort of computing matryoshka, if you will- running the <em>Ubuntu</em> distribution of the <em>Linux</em> operating system. They then proceeded to install the <em>GIMP</em> application. Despite frequent threats by the developers to remove them, the <em>GIMP</em> application had (at time of composition) some obscure and infrequently-used features permitting the creation and manipulation of image files. After its painstaking creation, the file was then transferred between the virtual machine and its host by way of a physical Universal Serial Bus mass-storage device. The mass-storage device was prepared in advance by formatting it with the 32-bit <em>File Allocation Table</em> filesystem and labeling it <em>Charon</em>, in recognition of its role in transporting the soul of the artwork between worlds.</p>

<figure>
<img src="http://beyondloom.com/blog/images-figures/ix.gif" alt="Composition in Blue and Blue. Gnuplot 5.2, Sublime Text 3.2.2">
<figcaption>Composition in Blue and Blue. Gnuplot 5.2, Sublime Text 3.2.2</figcaption>
</figure>

<p>The artist generated this work using the <em>Gnu’s Not Unix Plotter</em>, based on the following description:</p>

<pre><code>set terminal gif size 10,10
set output 'ix.gif'
set margins 0,0,0,0
unset key
unset tics
unset border
unset label
set style rectangle fs border lc rgb 'blue'
set object 1 rectangle from screen 0,0 to screen 1,1 fillcolor rgb 'blue' behind
plot 1 lt rgb 'blue'
</code></pre>

<p>Note in particular how easily a user of the <em>Gnu’s Not Unix Plotter</em> may customize the background color of a plot. The plot description may then be rendered as follows:</p>

<pre><code>$ gnuplot ix.gp 
</code></pre>

<p><a href="http://beyondloom.com/blog/index.html">back</a></p>
</div>]]>
            </description>
            <link>http://beyondloom.com/blog/images.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24408509</guid>
            <pubDate>Tue, 08 Sep 2020 14:10:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Pick the Right Postgres for Your Application – A Build vs. Buy Analysis]]>
            </title>
            <description>
<![CDATA[
Score 12 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24408486">thread link</a>) | @ya_RIV
<br/>
September 8, 2020 | https://lakefs.io/2020/09/07/how-to-pick-the-right-postgres-for-your-application/ | <a href="https://web.archive.org/web/*/https://lakefs.io/2020/09/07/how-to-pick-the-right-postgres-for-your-application/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-382" itemtype="https://schema.org/CreativeWork" itemscope="itemscope"><div><div itemprop="text"><p>Lots of applications require a Postgres database. Before you can install them, you will need a Postgres database. How do you pick the right Postgres for your application? There are a bewildering variety of possible ways to acquire a database running on a Postgres instance, but the biggest choice is “build or buy”: whether to install a Postgres version on your own or to purchase it as a service.</p><p>lakeFS is yet another Postgres application, so it requires a Postgres database. At Treeverse we decided for now to buy Postgres as a service. I’ll explain the factors why we decided, and how you might decide to whether or not to follow us.</p><h2><a href="https://github.com/treeverse/blog-internal/blob/master/20200907-picking-postgres/20200907-picking-postgres.md#got-a-postgres"></a>Got a Postgres?</h2><p>If your organization already runs Postgres instances, they may well be the best choice: there can be extensive in-house experience and expertise already present. And you probably don’t need this guide.</p><h2><a href="https://github.com/treeverse/blog-internal/blob/master/20200907-picking-postgres/20200907-picking-postgres.md#expensive-as-a-service"></a>Expensive as a Service?</h2><p>The most common objection to buying a database as a service is sheer price: a DB instance from your cloud provider can cost more than&nbsp;<em>twice</em>&nbsp;the cost of the virtual machine instance that it runs on. Obviously you pay extra to get much more than just the virtualized resources: you get expertise, much of the ops, easier backup and clustering, sometimes even some features.</p><p>For pricing I believe we should prefer to&nbsp;<em>buy</em>&nbsp;what is not a core part of our business. Pricing can actually make this decision easy. If the cost of buying Postgres as a service is a significant expenditure, then necessarily it is a core part of business — and clearly we need to develop the requisite in-house capability to support it. Otherwise cost is not a driving factor in the decision.</p><p>Even if you decide Postgres is a core capability for your organization, you may wish buy Postgres as a service for an initial ramp-up period, planning to move away later. While migrating database installations generally requires some downtime, this too is often a good choice.</p><h2><a href="https://github.com/treeverse/blog-internal/blob/master/20200907-picking-postgres/20200907-picking-postgres.md#choices"></a>Choices</h2><p>Every cloud provider provides managed Postgres as a service:</p><ul><li>AWS provide RDS as well as clustered Postgres-compatible Aurora;</li><li>Azure provide Azure Database for PostgreSQL;</li><li>GCP provide Postgres on Cloud SQL</li></ul><p>Similarly, some hosting providers also have a Postgres as a service offering. If you are already using a hosting provider that offers Postgres — Heroku is one example — this can be a convenient choice.</p><p>Postgres maintain a page&nbsp;<a href="https://www.postgresql.org/support/professional_hosting/">PostgreSQL: Hosting Providers</a>&nbsp;that list a wide range of options for purchasing hosted solutions along with support. Additionally, many hosted application platforms offer Postgres.</p><h2><a href="https://github.com/treeverse/blog-internal/blob/master/20200907-picking-postgres/20200907-picking-postgres.md#expertise-and-ops"></a>Expertise and Ops</h2><p>Developing in-house expertise is often desirable, and not only as a means to save costs. For instance, by allowing rapid resolution of issues without having to go outside the organization, expertise reduces risk.</p><p>On the flip side, managing your in-house database carries an ops burden, which will include monitoring, backup, clustering, and versioning. The last can be particularly troubling: occasionally you&nbsp;<em>will</em>&nbsp;need to upgrade Postgres on a running system.</p><p>A middle ground between buying a service and building it yourself is to contract the setup but manage ops in-house. I believe that unless you do database-related development, databases are generally a poor fit for this middle ground alternative. Contracting only the setup means you will take longer to build expertise in the database. Meanwhile you already start carrying the ops burden of the database.</p><h2><a href="https://github.com/treeverse/blog-internal/blob/master/20200907-picking-postgres/20200907-picking-postgres.md#versions-and-extensions"></a>Versions and Extensions</h2><h3><a href="https://github.com/treeverse/blog-internal/blob/master/20200907-picking-postgres/20200907-picking-postgres.md#versions"></a>Versions</h3><p>Buying from a large service provider appears to limit available versions. Currently, for example, the latest supported Postgres version is 12.4; the major release Postgres 12 was on 2019-10-03. Service providers have been slow to provide version 12:</p><ul><li>AWS RDS started supporting Postgres version 12 on 2020-03-31, and supports Postgres versions 9.4, 9.5, 9.6, 10, and 11; however Aurora clusters do not support version 12 yet;</li><li>Azure still supports only versions 9.5, 9.6, 10.11, and 11.6;</li><li>GCP started providing Postgres version 12 on 2020-05-21;</li><li>ElephantSQL supports Postgres version 12, but the free tier provides version 11.9.</li></ul><p>At the same time service providers can upgrade Postgres (and underlying OS) versions more transparently. This can be particularly useful for receiving patch releases. So low availability of newer Postgres versions is&nbsp;<em>not</em>&nbsp;a significant detriment. Of course, certain applications may require an absolutely latest version of Postgres, which may make it impossible to buy Postgres service.</p><h3><a href="https://github.com/treeverse/blog-internal/blob/master/20200907-picking-postgres/20200907-picking-postgres.md#extensions"></a>Extensions</h3><p>Numerous extensions are available for Postgres. Service providers provide the most popular of these. But they cannot provide all of them, and typically it is not possible to install new extensions that require compilation.</p><h3><a href="https://github.com/treeverse/blog-internal/blob/master/20200907-picking-postgres/20200907-picking-postgres.md#applicability-to-lakefs"></a>Applicability to lakeFS</h3><p>To allow users flexibility, lakeFS requires only Postgres 11. So availability of versions and extensions does not influence choice of provider for a database intended to run only lakeFS.</p><h2><a href="https://github.com/treeverse/blog-internal/blob/master/20200907-picking-postgres/20200907-picking-postgres.md#provisioning"></a>Provisioning</h2><p>Creating a new database instance with a service provider requires plenty of time. For example, on AWS RDS creating a small empty database instance can take 10 minutes. This is very reasonable for one-time setup of long-lived production and even staging environments.</p><h3><a href="https://github.com/treeverse/blog-internal/blob/master/20200907-picking-postgres/20200907-picking-postgres.md#fast-setup-of-small-databases"></a>Fast setup of small databases</h3><p>For short-lived environments or for testing, it can take too long to set up a hosted database. Luckily Postgres is an isolated component and one installation may easily be replaced with another installation. If the database is small and the generated data is not particularly valuable then there are good alternatives with quick setup times. These include creating a new database on an existing Postgres database instance or even — when database instance performance is not critical — running a database instance inside a container. If you have permission to create a new database, both of these alternatives have equivalent setup times that are typically less than a second.</p><p>Using an existing database instance allows you to take advantage of existing setup and ops on that database instance. For example, it will be easy to backup your new database if the database already has backups, and clustering exists at the instance level. By the same token, an existing database instance will offer significantly lower isolation than a container.</p><h3><a href="https://github.com/treeverse/blog-internal/blob/master/20200907-picking-postgres/20200907-picking-postgres.md#examples"></a>Examples</h3><p>An example of creating new databases inside an existing database instance is the ElephantSQL free tier: you are allocated a database inside an existing instance and can see that other databases exist inside that instance. It uses Postgres roles to prevent data leakage (a side effect is that some operations are impossible, for instance any application that requires multiple roles).</p><p>An example of running a database instance inside a container is when running tests. Every test can create its own blank container running Postgres. This is probably the best solution for component testing: it offers complete isolation between tests, the database container is small, and it scales directly with the number of running tests.</p><h2><a href="https://github.com/treeverse/blog-internal/blob/master/20200907-picking-postgres/20200907-picking-postgres.md#what-did-we-pick"></a>What did we pick?</h2><p>All our lakeFS instances currently use plain or Aurora Postgres on RDS:</p><ul><li>Our database usage is currently not high enough to justify the cost savings of running our own instances..</li><li>We build lakeFS, and supporting Postgres as a service is important to the product. So by design, lakeFS does not require latest-version features or esoteric extensions.</li><li>Our core business is currently to develop rather than to operate lakeFS; this is essentially the “ramp-up” time above.</li></ul><p>For isolation and speed of setup, our unit and component testing use a containerized Postgres instance.</p><figure><img src="https://lakefs.io/wp-content/uploads/2020/09/img_20200904_234025-1024x768.jpg" alt="" width="542" height="407" srcset="https://lakefs.io/wp-content/uploads/2020/09/img_20200904_234025-1024x768.jpg 1024w, https://lakefs.io/wp-content/uploads/2020/09/img_20200904_234025-300x225.jpg 300w, https://lakefs.io/wp-content/uploads/2020/09/img_20200904_234025-768x576.jpg 768w, https://lakefs.io/wp-content/uploads/2020/09/img_20200904_234025-1536x1152.jpg 1536w, https://lakefs.io/wp-content/uploads/2020/09/img_20200904_234025-2048x1535.jpg 2048w, https://lakefs.io/wp-content/uploads/2020/09/img_20200904_234025-24x18.jpg 24w, https://lakefs.io/wp-content/uploads/2020/09/img_20200904_234025-36x27.jpg 36w, https://lakefs.io/wp-content/uploads/2020/09/img_20200904_234025-48x36.jpg 48w" sizes="(max-width: 542px) 100vw, 542px" data-old-src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://lakefs.io/wp-content/uploads/2020/09/img_20200904_234025-1024x768.jpg" data-srcset="https://lakefs.io/wp-content/uploads/2020/09/img_20200904_234025-1024x768.jpg 1024w, https://lakefs.io/wp-content/uploads/2020/09/img_20200904_234025-300x225.jpg 300w, https://lakefs.io/wp-content/uploads/2020/09/img_20200904_234025-768x576.jpg 768w, https://lakefs.io/wp-content/uploads/2020/09/img_20200904_234025-1536x1152.jpg 1536w, https://lakefs.io/wp-content/uploads/2020/09/img_20200904_234025-2048x1535.jpg 2048w, https://lakefs.io/wp-content/uploads/2020/09/img_20200904_234025-24x18.jpg 24w, https://lakefs.io/wp-content/uploads/2020/09/img_20200904_234025-36x27.jpg 36w, https://lakefs.io/wp-content/uploads/2020/09/img_20200904_234025-48x36.jpg 48w"><figcaption>Picking a database, like picking an elephant, can be hard but need not be intimidating</figcaption></figure></div><!-- .entry-content .clear --></div></article></div>]]>
            </description>
            <link>https://lakefs.io/2020/09/07/how-to-pick-the-right-postgres-for-your-application/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24408486</guid>
            <pubDate>Tue, 08 Sep 2020 14:08:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How can you not be romantic about programming?]]>
            </title>
            <description>
<![CDATA[
Score 11 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24407844">thread link</a>) | @azhenley
<br/>
September 8, 2020 | https://thorstenball.com/blog/2020/09/08/how-can-you-not-be-romantic-about-programming/ | <a href="https://web.archive.org/web/*/https://thorstenball.com/blog/2020/09/08/how-can-you-not-be-romantic-about-programming/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  
  <p>08 Sep 2020</p>

  <p>There’s <a href="https://www.youtube.com/watch?v=9rrAbLNePxU">a scene in Moneyball</a> in which Brad Pitt’s character, the
manager of the <a href="https://en.wikipedia.org/wiki/Oakland_Athletics">Oakland A’s</a>, is watching a recording of one of his
players trying so hard to run fast that he stumbles and falls. Lying on the
ground he’s angry at himself, because he doesn’t realize that right before he
started his run he hit a home run and scored the game-winning points. Watching
the scene, Pitt leans back, smiles a Brad Pitt smile and says: “how can you not
be romantic about baseball?”</p>

<p>There are moments in which I ask myself the same thing about programming.</p>

<p>We’re programming computers. We spend large parts of our days writing down
instructions for machines. Other parts of the day are spent making sure that we
chose the right instructions. Then we talk about those instructions: why and how
we picked the ones we picked, which ones we will consider in the future, what
those should do and why and how long it will probably take to write those down.</p>

<p>It can sound very serious and dry; a bureaucracy of computer instructions. And
yet.</p>

<p>And yet we, the ostensible bureaucrats, talk about magic as something that
exists —&nbsp;the good <em>and</em> the bad kind. There are <a href="https://dl.acm.org/doi/book/10.5555/547625">wizards</a>. Instructions
are <a href="https://mitpress.mit.edu/sites/default/files/sicp/full-text/book/book-Z-H-9.html">“like a sorcerer’s spells”</a>.</p>

<p>We don’t call them instructions, though, not when talking about what we produce
each day anyway. It’s code we write. Emotions are involved. Code, we say, can
be: neat, nice, clean, crafted, baroque, minimal, solid, defensive, hacky, <em>a
hack</em>, art, a piece of shit, the stupidest thing I’ve ever read, beautiful, like
a poem.</p>

<p>Some lines of code are a riddle to anyone but their author and the name code
serves as a warning. Other times, strangely, it’s a badge of honor.</p>

<p>Fantastic amounts of code have been written, from beginning to end, by a single
person, typing away night after night after night, for years, until one day the
code is fed to a machine and, <em>abracadabra</em>, a brightly coloured <a href="https://en.wikipedia.org/wiki/RollerCoaster_Tycoon_(video_game)#Development">amusement
park</a> appears on screen. Other code has been written, re-written, torn
apart and stitched back together across time zones, country borders and decades,
not by a single person, but by hundreds or even thousands of different people.</p>

<p>This world of programming is held together by code. Millions and millions of
lines of code. Nobody knows how much there is. Some of it is more than 30 years
old, some less than a week, and chances are you used parts of both yesterday.
There are lines of code floating around on our computers that haven’t been
executed by a machine in years and probably won’t be for another lifetime.
Others are the golden threads of this world, holding it together at the seams
without no more than a dozen people knowing about it. Remove one of these and it
all comes crashing down.</p>

<p>If you haven’t been here long enough and try to guess how much there is and how
many generations are layered on top of each other — you won’t even come close.
But stay around. After a while, more and more, you’ll find yourself in moments
of awe, stunned by the size and fragility of it all; the mountains of work and
talent and creativity and foresight and intelligence and luck that went into it.
And you’ll reach for the word “magic” because you won’t know how else to
describe it and then you lean back and smile, wondering how someone could not.</p>


</div></div>]]>
            </description>
            <link>https://thorstenball.com/blog/2020/09/08/how-can-you-not-be-romantic-about-programming/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24407844</guid>
            <pubDate>Tue, 08 Sep 2020 12:48:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Digital Banking, Now Halal]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24407821">thread link</a>) | @mtmail
<br/>
September 8, 2020 | https://restofworld.org/2020/now-serving-halal-apps/ | <a href="https://web.archive.org/web/*/https://restofworld.org/2020/now-serving-halal-apps/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
			
<p><span>T</span>he average fintech startup founder faces a taxing to-do list: raise seed funding, scope out a user base, recruit talent, build something people will actually use. For the Indonesian entrepreneur, the Muslim-majority market presents an additional hurdle: build an app that is compliant with Islamic religious law, or Sharia.</p>



<p>New fintech startups must present themselves before the Indonesian Ulema Council (Majelis Ulama Indonesia, or MUI, in Bahasa Indonesian), composed of religious clerics from across the archipelago, for Sharia certification, in order to reach Indonesia’s 220 million Muslim users, who generally seek out products that fit their faith.&nbsp;</p>



<p>MUI shapes much of Indonesian life. The body has <a href="https://www.vice.com/en_in/article/bjpwwm/indonesia-just-got-its-first-halal-fridge-heres-a-list-of-everything-else-that-needs-a-stamp">conducted halal audits on household products</a>, verifying that milk, moisturizer, and instant ramen meet strict religious criteria. Its <em>fatwa</em> commission also regularly intervenes in the moral life of Indonesians, promulgating headline-making rulings on <a href="https://www.rappler.com/world/regions/asia-pacific/indonesia/87440-bhimanto-suwastoyo-fatwa-homosexuality-indonesia-death-penalty">homosexuality</a> and <a href="https://academic.oup.com/jis/article-abstract/18/2/202/726927">secularism</a>. Since the late 1990s, when Indonesian politics began a turn toward Islamic conservatism, the council’s influence has grown, according to Syafiq Hasyim, a Jakarta-based scholar of MUI and the political economy.&nbsp;</p>



<p>Now MUI is using its policing power to shape a new sector of Indonesian society: consumer technology. In November 2019, Vice President Ma’ruf Amin declared the <a href="https://www.scmp.com/week-asia/economics/article/3044601/how-sharia-economy-shapes-democracy-indonesia">“Shariatization” of the economy</a> — i.e., the growth of digital financial services catering to Muslim users — a priority for the country’s development. Indonesian Muslim consumers currently spend $224 billion annually. When fintech companies build platforms for these users — whether peer-to-peer lending apps, mobile money services, or online stock-trading portals — MUI acts as the arbiter of their religious legitimacy. MUI’s National Sharia Council (Dewan Syariah Nasional, or DSN) issues certificates that verify platforms are compliant with Sharia. The chairman of DSN just happens to be the vice president himself.</p>



<p>To earn a certificate, new startups must adhere to the council’s combined 154 fatwas, a rule book for anyone attempting to build Sharia fintech. New fatwas are added every year on digital finance topics that now include commodities trading online and cryptocurrencies. In the certification process, MUI’s religious scholars become embedded in the early evolution of a company’s digital products, their background not in software engineering or UX design but the traditions and teachings of Islam.</p>


		<figure>
			<div>
				<p><img src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/09/LinkAja-Sharia-Services-introduction-e1599232724418-40x85.jpeg" data-src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/09/LinkAja-Sharia-Services-introduction-e1599232724418-541x1066.jpeg" data-srcset="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/09/LinkAja-Sharia-Services-introduction-e1599232724418-400x850.jpeg 400w, " sizes="300px" alt="">
					
				</p>
			</div>
						<figcaption itemprop="caption description">
				
				
			</figcaption>
		</figure>


<p>In Sharia, for example, <a href="https://www.investopedia.com/terms/r/riba.asp#:~:text=Riba%20is%20prohibited%20under%20Shari,and%20helping%20others%20through%20kindness.">charging interest, or <em>riba</em></a><em>,</em> is strictly prohibited. Sharia promotes charitable financial dealings and labels interest and guaranteed profits inherently unjust. Instead of a conventional credit model, Sharia lending platforms operate according to <a href="https://www.sciencedirect.com/science/article/pii/S187705091931230X"><em>mudarabah</em></a>. Under this model, rather than a lender extracting a profit from a borrower, the borrower and lender enter a more equitable contract. For a small-business loan, for example, the lender receives a predetermined share of profits but must also share in the losses, since the borrower has invested labor and knowledge in the business. This model underpins a host of peer-to-peer lending apps targeting Muslim users in Indonesia.</p>



<p>For Sharia stock trading, MUI mandates, under <a href="https://drive.google.com/file/d/0BxTl-lNihFyzZUxIbkR3RXV4TWc/view">Fatwa No. 80</a>, that traders invest only in halal companies. Online stock trading platforms like MNC Trade Syariah vet all potential listings accordingly, removing any that deal in gambling, alcohol, or pork products.</p>



<p>For some companies, compliance is more of a challenge. Take LinkAja. <a href="https://kr-asia.com/linkaja-ceo-danu-wicaksana-ready-to-be-the-biggest-mobile-payment-platform-in-indonesia">Launched in June 2019</a> and currently serving 45 million registered users, it’s one of the country’s largest mobile money services <a href="https://www.thejakartapost.com/adv-longform/2019/12/27/why-gojek-users-leave-their-cash-behind-and-turn-to-gopay.html">behind leaders like GoJek’s digital wallet</a> GoPay and OVO. Customers can send, store, or receive electronic money on the LinkAja app. </p>



<p>Late last year, the company announced it was building the first Sharia mobile money product in Indonesia, a digital wallet for Muslim consumers to be called LinkAja Sharia Services. Standard LinkAja app users would be able to go into their settings and switch to a parallel platform built for Sharia compliance. But before they even created a prototype, LinkAja’s team knew they needed to consult MUI.</p>



<p>Most Islamic fintech companies have an appointed head of Sharia, a taskmaster who manages the compliance process. At LinkAja, that person is Widjayanto Djaenudin. While he had no experience in Sharia technology per se, he spent more than a decade at Telkomsel, Indonesia’s largest telecoms operator, developing mobile products for the unbanked. His task at LinkAja was to liaise with MUI and guide the company through its certification process, a challenge, considering the tenuous status of Sharia scholarship on mobile money apps. </p>



<p>Some clerics have argued that <a href="http://www.ikim.gov.my/new-wp/index.php/2019/08/22/some-sharia-considerations-concerning-e-wallet/">digital wallets are a form of <em>haram</em></a>, a term for practices forbidden by Islamic law<em>. </em>The<em> </em>digital-only cash-back rebates and other discounts with partner retailers commonly found on these apps are considered, by some clerics, a form of interest payment between businesses — riba in disguise. MUI has ruled sending and storing money in digital wallets acceptable, but only under strict terms.&nbsp;</p>



<figure><blockquote><p>To earn a certificate, new startups must adhere to the council’s combined 154 fatwas, a rule book for anyone attempting to build Sharia fintech.</p></blockquote></figure>



<p>After conducting a rigorous product-proposal review, MUI appointed a three-member supervisory board to Djaenudin’s team well-versed in the nuances of its rulings. The board included Anwar Abbas, chairman of an Islamic reformist organization in Southern Java’s Yogyakarta and author of a national bestseller promoting the vice president’s “Shariatization” worldview, <a href="https://www.tokopedia.com/dojobuku/ma-ruf-amin-way-sahala-panggabean-by-anwar-abbas"><em>The Ma’ruf Amin Way</em></a><em>. </em>“They are all Sharia experts,” said Djaenudin. “They gave us guidance and consultations about the product.” </p>



<p>Starting in November 2019, shortly after the vice president’s Shariatization initiative, Djaenudin was required to brief these scholars on market research, product testing, and the ins and outs of engineering every month. MUI’s supervisory board would share their insights and ensure the technological infrastructure of the app followed MUI’s rulings.&nbsp;</p>



<p>An MUI fatwa issued in 2017 was of particular concern to Djaenudin. <a href="https://drive.google.com/file/d/1KPAvhhziJ61Pt8EFxxTFfDPNmRHJoQDG/view">Fatwa No. 116</a> begins with verses from the Quran published in both classical Arabic script and Bahasa Indonesian. “O you who have believed, when you contract a debt for a specified term, write it down. And let a scribe write it between you in justice,” reads one verse. They are followed closely by <a href="https://yaqeeninstitute.org/emadhamdeh/are-hadith-necessary/">quotations from books of <em>hadith</em></a>, records of the sayings of the Prophet Muhammad: “Do not sell gold for gold, and do not sell silver for silver, except in case of like for like.”</p>



<p>These threads of theological precedent are woven together to create a set of rulings reinterpreting classical verse for the new digital economy. According to the fatwa, these Quranic lines have a specific implication for fintech: floating funds must be housed in certified Islamic banks. Contracts between all parties — users, banking institutions, or the app itself — must be grounded in Sharia contract law. Any promotional campaign cannot include riba.</p>


		<figure>
			<div>
				<p><img src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/09/Fintech-40x23.png" data-src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/09/Fintech-768x432.png" data-srcset="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/09/Fintech-400x232.png 400w, https://restofworld.org/wp-content/uploads/2020/09/Fintech-600x348.png 600w, https://restofworld.org/wp-content/uploads/2020/09/Fintech-1000x580.png 1000w, https://restofworld.org/wp-content/uploads/2020/09/Fintech-1600x928.png 1600w, https://restofworld.org/wp-content/uploads/2020/09/Fintech-2800x1623.png 2800w, " sizes="(max-width: 640px) 100vw, (max-width: 992px) calc(100vw - 40px), (max-width: 1140px) calc(100vw - 290px), calc(100vw - ((100vw - 640px)/2))" alt="">
					
				</p>
			</div>
						<figcaption itemprop="caption description">
				
				
			</figcaption>
		</figure>


<p>The supervisory board had other suggestions for LinkAja’s parallel Sharia platform, Djaenudin told <em>Rest of World</em>. The new version of the app embedded a <em>zakat </em>payment feature, <a href="https://www.islamic-relief.org.uk/about-us/what-we-do/zakat/">a form of religious tithing and worship</a> performed through charitable donations, customarily amounting to 2.5% of one’s total savings. After the board signed off on the feature, LinkAja partnered with 240 MUI-approved charitable institutions and 1,000 mosques nationwide <a href="https://news.detik.com/adv-nhl-detikcom/d-5019749/wahai-umat-muslim-ini-cara-mudah-berzakat-lewat-layanan-syariah-linkaja">to launch the zakat feature</a>. Months of vetting culminated in a full audit of LinkAja’s operations at its Jakarta headquarters by MUI.&nbsp;</p>



<p>According to Widjayanto, LinkAja paid a $300 (4 million rupiah) charge to MUI for its Sharia certificate, which lasts three years, including a $20 transportation fee for the auditor.&nbsp;</p>



<p>LinkAja Sharia Services <a href="https://www.idnfinancials.com/news/33503/link-aja-launches-linkaja-sharia-services">launched on April 14</a>, just one week before the start of Ramadan. In its first month, it saw 100,000 user registrations. Djaenudin credits the MUI Sharia certificate for this first wave of customers. Most Indonesians prefer to use a Sharia-branded service, even if few understand the particulars of riba or mudarabah, according to LinkAja market research. “From the customer’s perspective, as long as they see the halal logo or Sharia certificate from a trusted body, which is MUI, it gives them clearance and trust,” said Djaenudin.</p>



<p>For Indonesian fintech entrepreneurs hoping to establish their Sharia credentials, the MUI certificate has become the gold standard. Ronald Yusuf Wijaya, the founder of two Sharia-compliant crowdfunding startups, converted to Islam while building his business. “It’s been almost nine years, and I’m learning all of this from the day I started my business,” he said. Wijaya is chairman of the <a href="https://fintechsyariah.id/en">Indonesian Sharia Fintech Association (AFSI)</a>, a trade association that lobbies on behalf of <a href="https://www.reuters.com/article/us-indonesia-digitalpayments-islam/sharia-fintech-startups-race-to-tap-indonesia-growth-by-aligning-with-islam-idUSKBN20Q0IA">this burgeoning pocket of the Indonesian economy</a>. Since converting, Wijaya has successfully navigated MUI Sharia certification with both his companies. “Some customers, they ask, ‘Are you certified, or are you just Sharia?’”&nbsp;</p>


		<figure>
			<div>
				<p><img src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/09/LinkAja-zakat-payments-portal-1-e1599232688949-40x86.jpeg" data-src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/09/LinkAja-zakat-payments-portal-1-e1599232688949-538x1066.jpeg" data-srcset="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/09/LinkAja-zakat-payments-portal-1-e1599232688949-400x857.jpeg 400w, " sizes="300px" alt="">
					
				</p>
			</div>
						<figcaption itemprop="caption description">
				
				
			</figcaption>
		</figure>


<p>For most Sharia fintech startups, MUI certificates are not only commercially advantageous but legally required by the Financial Services Authority of Indonesia (OJK), the state financial regulator. Other areas of the Sharia digital economy, like <a href="https://www.salaamgateway.com/story/indonesian-e-commerce-giant-tokopedia-aiming-for-10-of-total-transactions-to-come-from-new-islamic-m">halal e-commerce</a> and <a href="https://www.salaamgateway.com/story/indonesia-gets-first-diy-umrah-platform-e-commerce-giant-starts-selling-pilgrimage-packages"><em>umrah </em>sites</a>, travel-booking platforms for Islamic pilgrimages, do not require this certificate.&nbsp;</p>



<p>Dr. Ir. H. Nadratuzzaman Hosen, vice chair of DSN MUI, told <em>Rest of World</em> that MUI is a passive actor in the development of new apps — waiting idly for companies to seek its approval rather than imposing fatwas on companies as a theocratic …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://restofworld.org/2020/now-serving-halal-apps/">https://restofworld.org/2020/now-serving-halal-apps/</a></em></p>]]>
            </description>
            <link>https://restofworld.org/2020/now-serving-halal-apps/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24407821</guid>
            <pubDate>Tue, 08 Sep 2020 12:44:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Balalaika IT newsletter for web developers (Java, Node.js, React)]]>
            </title>
            <description>
<![CDATA[
Score 36 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24407761">thread link</a>) | @keenondrums
<br/>
September 8, 2020 | https://blog.balalaikait.com/balalaika-it-newsletter-9 | <a href="https://web.archive.org/web/*/https://blog.balalaikait.com/balalaika-it-newsletter-9">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><section itemprop="articleBody mainEntityOfPage"><meta itemprop="thumbnailUrl image" content="https://cdn.hashnode.com/res/hashnode/image/upload/v1599317301627/XYncjZMBx.jpeg?w=1600&amp;h=840&amp;fit=crop&amp;crop=entropy&amp;auto=format&amp;q=60"><div><div itemprop="text"><p><em>If you like this newsletter subscribe to our new issues at <a href="http://balalaikait.com/" target="_blank">balalaikait.com</a></em></p>

<ul>
<li>CPU caching 101 from Nick Evanson. A <a target="_blank" href="https://www.techspot.com/article/2066-cpu-l1-l2-l3-cache/">concise read</a> about the fundamentals to get you started on how it works and why we need it. </li>
<li>Over the last two years, Uber has attempted to reduce microservice complexity while still maintaining the benefits of a microservice architecture. With <a target="_blank" href="https://eng.uber.com/microservice-architecture/">this blog post</a> we hope to introduce our generalized approach to microservice architectures, which we refer to as “Domain-Oriented Microservice Architecture” (DOMA).</li>
<li>Distributed locks are infamous for being hard to use right. Some time ago Hazelcast team introduced locks as a part of CP Subsystem based on Raft, a well-known consensus algorithm. This <a target="_blank" href="https://hazelcast.com/blog/long-live-distributed-locks/">blog post</a> describes potential pitfalls of distributed lock and how FencedLock solves them.</li>
<li>Great engineers of the past have a lot to learn from. In <a target="_blank" href="https://youtu.be/bo5WL5IQAd0">this talk</a> explains how Erlang was designed to scale well on multicore machines.</li>
</ul>

<ul>
<li>ES6 introduced many nice built-in collections, such as Map, Set, WeakMap, and WeakSet. Unfortunately, the spec does not put many requirements for concrete implementations. If you want to learn practical details of Maps and Sets implementation in V8, read this <a target="_blank" href="https://itnext.io/v8-deep-dives-understanding-map-internals-45eb94a183df">blog post</a> by Andrey P.</li>
<li>JIT compiler is what makes V8 and other JS engines blazing fast. But exactly does it do? Watch this <a target="_blank" href="https://youtu.be/p-iiEDtpy6I">talk</a> by Franziska Hinkelmann to learn the answer.</li>
</ul>

<ul>
<li>Is it possible to build SPAs purely in Rust and without writing a single line of JavaScript? The short answer is YES! Read about the experiment <a target="_blank" href="http://www.sheshbabu.com/posts/rust-wasm-yew-single-page-application/">here</a>.</li>
</ul>

<ul>
<li>A <a target="_blank" href="https://httptoolkit.tech/blog/how-to-debug-node-segfaults">concise guide</a> on how to debug segmentation faults in Node.js.</li>
</ul>

<ul>
<li>Did you know that <code>java.security.SecureRandom</code> may be more or less secure depending on the configuration? This <a target="_blank" href="https://tersesystems.com/blog/2015/12/17/the-right-way-to-use-securerandom/">blog post</a> explains how to use it in the right way.</li>
</ul>
</div></div></section></div></div>]]>
            </description>
            <link>https://blog.balalaikait.com/balalaika-it-newsletter-9</link>
            <guid isPermaLink="false">hacker-news-small-sites-24407761</guid>
            <pubDate>Tue, 08 Sep 2020 12:35:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Free hosted open-source alternative to Zapier/Airflow]]>
            </title>
            <description>
<![CDATA[
Score 274 | Comments 77 (<a href="https://news.ycombinator.com/item?id=24407706">thread link</a>) | @newcrobuzon
<br/>
September 8, 2020 | https://cloud.titanoboa.io/index.html | <a href="https://web.archive.org/web/*/https://cloud.titanoboa.io/index.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <div>
        <div>
            <div>
                <p><span>public βeta</span></p><h2><b>Try a <u>free</u> hosted instance of Titanoboa!</b></h2>


                <p>You don't have to install Titanoboa on your computer - just try it straight away in your browser!</p>
                
                <dev>
                     <br>
                    <b>We are sorry, but Titanoboa server's GUI is not fully optimized for mobile devices yet. Feel free to watch the demo below or read our <a href="https://github.com/mikub/titanoboa/wiki">wiki</a> to learn more!</b>
                </dev>
                <p><br>
                If you are not familiar with Titanoboa you can watch a short demo here:<br>

                <video controls="">
                    <source src="https://www.titanoboa.io/demo.mp4" type="video/mp4">
                    Your browser does not support the video tag.
                </video>
                </p>

 </div>
        </div>
    </div>
</div></div>]]>
            </description>
            <link>https://cloud.titanoboa.io/index.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24407706</guid>
            <pubDate>Tue, 08 Sep 2020 12:26:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Ad Fraud on LinkedIn]]>
            </title>
            <description>
<![CDATA[
Score 484 | Comments 276 (<a href="https://news.ycombinator.com/item?id=24407432">thread link</a>) | @sbachman
<br/>
September 8, 2020 | https://www.samueljscott.com/2020/09/08/linkedin-ad-fraud/ | <a href="https://web.archive.org/web/*/https://www.samueljscott.com/2020/09/08/linkedin-ad-fraud/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
					<p>The LinkedIn Ads network is likely awash in mistaken clicks and bot traffic that make the platform’s value extremely dubious, according to a new study from global digital agency RMG that the company shared exclusively with me.</p>
<p>Three weeks ago, RMG founding partner Ryan Gellis <a href="https://www.linkedin.com/posts/ryan-gellis_theory-the-linkedin-ad-network-is-full-of-activity-6700077824360910848-LysO/" target="_blank" rel="noopener noreferrer">posted a thread</a> wondering if LinkedIn “is full of fraudulent accounts and unchecked misclicks that artificially inflate the cost of advertising and result in poor performance compared to other ad networks.” The ensuing discussion inspired him to look into the issue further.</p>
<center><iframe src="https://www.youtube.com/embed/jKuyxgWuiRM" width="560" height="315" frameborder="0" allowfullscreen="allowfullscreen"></iframe></center><p>Gellis goes through his findings <a href="https://www.youtube.com/watch?v=jKuyxgWuiRM" target="_blank" rel="noopener noreferrer">in this YouTube video</a>. For the test, RMG promoted a webinar by targeting c-certain c-suite executives at large companies in the United States based on their job titles. The ad encouraged them to click to sign up for for event for free.</p>
<p>The first issue the agency found was the projected versus actual cost per click. LinkedIn estimated a $25 average CPC. The actual campaign CPC was nearly $45.</p>
<p>“What’s the point of forecasting if you project one cost and then the actual cost ends up being 200% the projection?” Gellis asks in the video.</p>
<p>But the real issue was the source of the clicks themselves. LinkedIn’s ad platform reported 11 clicks. RMG’s logs showed ten clicks. <a href="https://www.fullstory.com/" target="_blank" rel="noopener noreferrer">FullStory</a>, the digital experience analytics platform that RMG uses, stated that eight people registered for the webinar. However, the true number of registrations was zero.</p>
<p>“Zero people signed up for the webinar from that specific campaign,” Gellis told me in an interview. “That’s kind of the punch line and why I believe this is newsworthy. Nobody signed up. In fact, nobody even exhibited what I believe is real user behavior on the site after clicking the ad. That is also true of all the other ads we ran on LinkedIn. We had a total of 0 people ever “sign up” on any ad we ran during our testing on LinkedIn — regardless of the ad format or messaging.”</p>
<p><a href="https://www.rmgmedia.com/" target="_blank" rel="noopener noreferrer">RMG</a> suspects bot activity or misattributed misclicks had been the cause because visitors would bounce away from the webinar’s landing page before it even had a chance to render — in other words, they would click the LinkedIn advertisement and then leave the website in less than 1.3 seconds. In addition, FullStory reported mouse movements that were nothing like what an actual human would do.</p>
<p>“As far as we’re concerned, the LinkedIn ad network basically has fraudulent clicks and/or misclicks that don’t get attributed to the users that are being passed through as leads in campaigns,” Gellis says in the video.</p>
<p>Of course, the simple size in RMG’s one-day test was extremely small. The target audience size was 16,000. The number of impressions would be between 680 and 2,000. The cost was $250. But Gellis told me that the results match a prior, larger test.</p>
<p><img src="https://www.samueljscott.com/wp-content/uploads/2020/09/linkedin-ads.png" alt="linkedin ads" width="660" height="197" data-eio="l" data-old-src="data:image/svg+xml,%3Csvg xmlns='http://www.w3.org/2000/svg' viewBox='0 0 660 197'%3E%3C/svg%3E" data-src="https://www.samueljscott.com/wp-content/uploads/2020/09/linkedin-ads.png"></p>
<p>During a $3,000 campaign in March, LinkedIn reported 256 clicks with an average CPC of $11. The company received zero leads from all of the clicks.</p>
<p>“You’ll see the call to action is ‘Request Demo,'” Gellis said. “So, arguably, a user who sees this ad and clicks legitimately on it will be looking to get a demo of the analytics tool we were marketing. If the ads were giving us behavior like this on a $3,000-per-month budget, it’s unlikely they would have performed any better with additional budget.”</p>
<p>RMG charges that LinkedIn’s advertising is on a closed network and does not follow the Interactive Advertising Bureau’s <a href="https://www.iab.com/guidelines/iab-measurement-guidelines/" target="_blank" rel="noopener noreferrer">standards for digital advertising</a>. (The IAB did not respond to a request for comment.)</p>
<p>After reviewing RMG’s findings, a LinkedIn spokesperson sent me the following company statement.</p>
<p>“LinkedIn is a members-first organization and our&nbsp;<u><a title="https://www.linkedin.com/legal/ads-policy" href="https://www.linkedin.com/legal/ads-policy" target="_blank" rel="noreferrer noopener" data-saferedirecturl="https://www.google.com/url?q=https://www.linkedin.com/legal/ads-policy&amp;source=gmail&amp;ust=1599566456486000&amp;usg=AFQjCNFFsmfrYAHwHhV6tM-nG54kogFWEw">Ads program</a></u>&nbsp;is designed to ensure that only high-quality, relevant ads are served to our members. We prohibit the use of bots or other automated fraudulent methods to access our services, as they are in violation of the&nbsp;<u><a title="https://www.linkedin.com/legal/user-agreement" href="https://www.linkedin.com/legal/user-agreement" target="_blank" rel="noreferrer noopener" data-saferedirecturl="https://www.google.com/url?q=https://www.linkedin.com/legal/user-agreement&amp;source=gmail&amp;ust=1599566456486000&amp;usg=AFQjCNErEgCF6J2mC2B2u6Rnd32Ialafiw">User Agreement.</a></u>&nbsp;Additionally, LinkedIn is a&nbsp;member of the IAB&nbsp;and works closely with the organization and its members to help develop standards for the digital advertising industry.”</p>
<p>But when summarizing his findings in the video, Gellis is skeptical of LinkedIn.</p>
<p>“As far as we can tell, LinkedIn is basically a money pit,” he says. “You’re not going to get the performance that you would expect out of the network.”</p>
<p><strong>(Note: For more, <a href="https://www.samueljscott.com/2019/02/26/fake-online-fake-internet/" target="_blank" rel="noopener noreferrer">see my recent talk on how much of the Internet is fake</a>.)</strong></p>
<p><b><i>Thanks for reading! Follow me on <a href="http://twitter.com/samueljscott">Twitter</a> and see my <a href="https://www.samueljscott.com/marketing-speaker/">marketing speaker</a> page to have me visit your conference or company.</i></b></p>
					</div></div>]]>
            </description>
            <link>https://www.samueljscott.com/2020/09/08/linkedin-ad-fraud/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24407432</guid>
            <pubDate>Tue, 08 Sep 2020 11:44:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Chef to be acquired by Progress]]>
            </title>
            <description>
<![CDATA[
Score 166 | Comments 142 (<a href="https://news.ycombinator.com/item?id=24407323">thread link</a>) | @snorlaxhugsy
<br/>
September 8, 2020 | https://blog.chef.io/the-fourth-chapter-of-chef-has-arrived-progress-to-purchase-chef/ | <a href="https://web.archive.org/web/*/https://blog.chef.io/the-fourth-chapter-of-chef-has-arrived-progress-to-purchase-chef/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">

	<div id="primary">
		<main id="main" role="main">

		
<article id="post-24840">
	<!-- .entry-header -->

	<div>
					
<p><span>Chefs,</span></p>
<p><span>We are excited to announce that Chef has signed a definitive agreement to be acquired by </span><a href="http://www.progress.com/"><span>Progress</span></a><span>. </span><span>We expect the transaction&nbsp;to be finalized over the next 30 days&nbsp;or so and, once completed,&nbsp;Chef&nbsp;will become an integral part of Progress.&nbsp;</span></p>
<p><span>Progress is a trusted provider of some of the best products to develop, deploy and manage high-impact business applications. Chef will bolster that position by providing continuous delivery, application delivery, dependable compliance, remediation automation, desktop management and more.</span> <span>You, our customers and community, will benefit from working with an established, publicly traded company with significantly greater resources that will provide extensive support for our open source projects and product roadmap.&nbsp;</span></p>
<p><span>Until the deal closes, Chef will remain independent and continue its normal business operations.&nbsp; </span><span>Once the deal is complete, Progress will be focused on continuing and executing on Chef’s business model and product roadmaps and supporting your business</span><span> and our combined communities. Our unwavering commitment to your success will continue and remains a top priority, as Chef enters this new phase as part of the global Progress Software family.&nbsp;</span></p>
<p><span>We look forward to the opportunities that lie ahead and to the benefits the acquisition will provide.</span></p>
<p><span>For more information on the transaction, please see <a href="https://www.progress.com/blogs/progress-to-acquire-chef">this great post</a></span><span>&nbsp;from Progress CEO Yogesh Gupta.</span></p>
<p><span>Barry Crist<br></span><span>Chief Executive Officer, Chef</span></p>
			</div><!-- .entry-content -->

	
	
				
	
		
<div>
							<div>
				<p><a href="#"><img src="https://secure.gravatar.com/avatar/4d50999463b9ae09ae36afd69f82397d?s=98&amp;d=mm&amp;r=g" width="98" height="98" alt="Avatar"></a></p><div>
					<p><strong>Barry Crist</strong></p><p>				
						Barry Crist has more than 20 years of experience in driving enterprise customer success with open source and DevOps software solutions and is a recognized leader in driving a culture of innovation. Barry joined Chef as CEO in 2013 and has been a leading force behind the company’s business operations, culture and technology innovation.					</p>
				</div>
			</div>
			</div>

		<a id="merch-banner" href="https://pages.chef.io/cloudmigrationwp.html" target="_blank">
			<img src="https://blog.chef.io/wp-content/uploads/2019/09/Blog-Merch-Bottom-Banner.jpg">
		</a>
	
	
	

</article><!-- #post-## -->

		</main><!-- #main -->
	</div><!-- #primary -->


<!-- #secondary -->

	</div></div>]]>
            </description>
            <link>https://blog.chef.io/the-fourth-chapter-of-chef-has-arrived-progress-to-purchase-chef/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24407323</guid>
            <pubDate>Tue, 08 Sep 2020 11:25:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Using Nvidia Jetson and OpenDataCam to Explore Computer Vision and IoT Analytics]]>
            </title>
            <description>
<![CDATA[
Score 14 | Comments 3 (<a href="https://news.ycombinator.com/item?id=24407272">thread link</a>) | @Dwolb
<br/>
September 8, 2020 | https://www.hologram.io/blog/using-nvidia-jetson-and-opendatacam | <a href="https://web.archive.org/web/*/https://www.hologram.io/blog/using-nvidia-jetson-and-opendatacam">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p>Computer vision is an incredibly fast growing field, and recent developments have made it possible to quickly start experimenting with almost no previous experience. In this post we’ll show you how to set up a practical computer vision analytic system using the $99 Nvidia Jetson Nano Developers Kit, running OpenDataCam. With OpenDataCam we can recognise, track and count people and a variety of vehicles from a USB webcam feed. We will send the collected data to InfluxDB for visualization and analysis, and set up the Jetson Nano for remote operation and management using a cellular modem and a Hologram SIM.<br></p><p>The video below shows a recording of a live field test I did outside a filling station, counting vehicles and pedestrians travelling in different directions.<br></p><p><a href="https://youtu.be/bjrMs8JFYdo">https://youtu.be/bjrMs8</a><br></p><p>To get started, you will need the following hardware:</p><ul role="list"><li>Jetson Nano Developers kit</li><li>5V 4A Power Supply with barrel connector</li><li>Micro SD Card, class 10 or better, 64 GB recommended</li><li>Wi-Fi adaptor (<a href="https://www.sparkfun.com/products/15449">Edimax N150</a> or <a href="https://www.sparkfun.com/products/15841">Intel 8265.NGWMG M.2 card</a> recommended) or Ethernet cable</li><li>USB Webcam</li><li>4G Modem - USB or Raspberry Pi Hat (Tested with D-Link DWM-222)</li><li>Hologram SIM Card</li><li>HDMI monitor</li><li>USB Mouse and Keyboard</li></ul><figure><p><img src="https://assets-global.website-files.com/5d716c2c4df04f586b7912e3/5f2c5dacd16d7c48f0c455f9_20200724_143026.jpg" alt=""></p></figure><h2>How to set up the Nvidia Jetson Nano<br></h2><p>The Nvidia Jetson Nano is a powerful little single board computer with a GPU for running neural networks to do things like image classification, object detection or speech processing. It’s size and low cost means that it’s perfect for edge computing applications like retail analytics or various industrial uses. Combined with a cellular modem and USB webcam, it allows for quick and easy remote deployments, with the only field requirement being a power supply.<br></p><p>The Jetson Nano has no shortage of documentation and online resources, with Nvidia really having put effort into making machine learning approachable for almost anyone. It’s possible to get a basic object demo running in <a href="https://news.developer.nvidia.com/realtime-object-detection-in-10-lines-of-python-on-jetson-nano/">10 lines of python code</a>.</p><ol role="list"><li>Download the latest <a href="https://developer.nvidia.com/embedded/downloads">SD card image</a> for the Jetson Nano</li><li>Flash the image to the SD Card from your computer. On a Windows PC I prefer <a href="https://www.balena.io/etcher/">BalenaEtcher</a>. If you haven’t done this before, complete instructions are on the <a href="https://developer.nvidia.com/embedded/learn/get-started-jetson-nano-devkit#write">Nvidia website</a>.</li><li>If you're using the barrel socket power supply, place a jumper on the J48 pins, just behind the barrel socket. This deactivates the micro USB port as a power supply.</li><li>Insert the micro SD card into the slot on the Nano</li><li>Plug in the power supply, mouse, keyboard, and Wi-Fi adaptor or network cable<br></li></ol><p>The Jetson should now start up, and direct you through the system and network configuration, and login credentials set up. On the user setup page select the “Log in automatically” to allow all services to start without user intervention.<br></p><p>Once done, you should see the desktop. Open a terminal window and do the following:</p><p>Check for updates, and update all packages. This might take a while.</p><p><code>
sudo apt update &amp;&amp; sudo apt upgrade
</code></p><p>‍</p><p>Install the Nano text editor and curl</p><p><code>
sudo apt install nano curl
</code></p><p>‍</p><p>For deployment a cellular connection is really convenient, but for testing and initial setup and ethernet or WiFi connection is quicker to set up. If you are using a Wi-Fi adaptor for testing, disable Wi-Fi power management to improve connection stability.</p><p><code>
sudo nano /etc/NetworkManager/conf.d/default-wifi-powersave-on.conf
</code></p><p>‍</p><p>It will open a file with the following file</p><p><code>
[connection]
wifi.powersave = 3
</code></p><p>Disable Wi-Fi power saving by changing <strong>3</strong> to <strong>2</strong>.<br></p><p>‍</p><p>Get the IP address of your Jetson Nano by running</p><p><code>
ifconfig
</code></p><p>Restart the Jetson before continuing. Any command line operation from this point forward can be done either directly on the Nano with the keyboard, mouse and monitor, or you can use SSH from any computer on the same network.&nbsp;</p><p>Now that you have a running Nano, it’s time to jump into the computer vision software.<br></p><h2>How to Install OpenDataCam</h2><p><a href="https://github.com/opendatacam/opendatacam">OpenDataCam</a> is an open source tool for computer vision analytics, that can track and count objects in almost any video feed. It is probably the easiest to use and setup tool that I have seen for this purpose. It is licensed under the permissive MIT license, which allows for use in commercial products.</p><p>‍<br>OpenDataCam runs on the Docker platform, and requires access to CUDA, Nvidia’s tool for running parallel processing tasks on GPUs. First we need to make sure CUDA is defined in the PATH on the Nano, by editing the <em>.bashrc</em> file</p><p><code>
sudo nano .bashrc
</code></p><p>‍<br></p><p>Add the following two lines to the end of the file, then save and close it.</p><p><code>
export PATH=${PATH}:/usr/local/cuda/bin
export LD_LIBRARY_PATH=${LD_LIBRARY_PATH}:/usr/local/cuda/lib64
</code></p><p>Increase swap partition size of the Jetson to 6 GB to improve performance and reliability</p><p><code>
git clone https://github.com/JetsonHacksNano/installSwapfile
cd installSwapfile
chmod 777 installSwapfile.sh
./installSwapfile.sh
</code></p><p>‍<br></p><p>Install Docker-compose and dependencies</p><p><code>
sudo apt install -y python3-pip libssl-dev libffi-dev python-openssl
sudo pip3 install docker-compose
</code></p><p>Allow docker to run on startup</p><p><code>
sudo systemctl enable docker
</code></p><p>Install OpenDataCam. You will be asked for your sudo password during this process, and it may take a while.</p><p><code>
mkdir ~/opendatacam
cd ~/opendatacam
wget -N https://raw.githubusercontent.com/opendatacam/opendatacam/v3.0.1/docker/install-opendatacam.sh
chmod 777 install-opendatacam.sh
./install-opendatacam.sh --platform nano
</code></p><h2>How to configure OpenDataCam</h2><p>Once the installation is complete, open Chromium and go to <em>localhost:1880</em> from the Jetson, or <em>*JetsonIP*:1880</em> from any computer on the same network. Once OpenDataCam has started, you will see the following video feed. It is a demo file included in OpenDataCam and demonstrates its object detection capabilities. We’ll use this as an example to get familiar with the interface before changing the video feed for our specific use case.</p><figure><p><img src="https://assets-global.website-files.com/5d716c2c4df04f586b7912e3/5f29889973b49b0b09f6e922_UFzR3FTem-uv1i--ef_6ImhdEpBDpt2KfhSRH-nKZV0pb-fzcXfRg8O0PQY3TbOj2PztqHk-4w3Vd2TxSfclRoaW-4s2Y4LzfuUgjATLtWqQF4bczSNDX8J6xo4QGwdqlm1tRpqq.png" alt=""></p></figure><p>Click on the “Pathfinder” button in the upper left corner, and you will see the “tracks” generated by each car as it’s identified and tracked.<br></p><p>To count the vehicles, click the “Counter” button to add counting lines as shown below. These lines act as checkpoints, counting objects that pass over them. In the example below, I’ve added lines for oncoming, leaving, and crossing traffic. You can also toggle the direction of travel for objects to be counted, by clicking on the arrow in the centre of the line. To start counting, click the “Start recording” button.</p><figure><p><img src="https://assets-global.website-files.com/5d716c2c4df04f586b7912e3/5f298899354fcf9d9df68f0d_GLWKyNi1Xs8Jq7lWGDHkCKCNnvh9syNBk2Lk-1gC1OEQEvHgJEs21VJ8oPYtk1Wc-nbns8Kj_GdcqaA25lKE2UaPU82ZRAQzUcFRCuBuUh23XW0RZsZaK3c3CIqIKH6-UhMRzuhd.png" alt=""></p></figure><p>To increase the reliability of the counters, it is important to place them in areas with high detection confidence. By clicking the hamburger menu in the upper right-hand corner, you can activate the tracker accuracy heatmap, which will highlight the areas with the <strong>lowest</strong> detection confidence levels.</p><figure><p><img src="https://assets-global.website-files.com/5d716c2c4df04f586b7912e3/5f2988983b96a20a4ae37c21_D6BXJhyf_Dj-V7Ee6Xfa5q2Np7CTB_E5WITOkrOwuLSi73JBZjK2gWLf5Iz36E1Bn71D6-om6ao_-lE2HugxczT_NT_y0ojc_2DHNJGRQnvQ3adJOsHddTUM8LhB3z7tXt8GVYzL.png" alt=""></p></figure><figure><p><img src="https://assets-global.website-files.com/5d716c2c4df04f586b7912e3/5f29889972d197251894544b_BuLB_wQ_upuv3Vg3rZMNuyXJmQ0GNx0UyaJB5cmIJ-uJbQEcKPVdKE56PmnNvJBW_ft_Dl2oio5QcaScWLRZoK506Yx-L4BfFnNc8uAo4cmMGXlW1jBLDMBAA_D5DD02V-ZifngK.png" alt=""></p></figure><p>This means that you should avoid these areas when placing counting lines. It might also be a good idea to move the camera to a different perspective, or even improve the detection model using <a href="https://towardsdatascience.com/training-yolo-for-object-detection-in-pytorch-with-your-custom-dataset-the-simple-way-1aa6f56cf7d9">transfer learning</a>.<br></p><p>If you have a sample video file that you want to test, you can simply drag and drop it into the OpenDataCam window and it will start playing the new file.<br></p><p>To use a webcam or IP camera stream, you need to <a href="https://github.com/opendatacam/opendatacam/blob/master/documentation/CONFIG.md#video-input">edit the config.json</a> file in ~/opendatacam/ to specify the desired video source. Complete details are available on the <a href="https://github.com/opendatacam/opendatacam/blob/master/documentation/CONFIG.md#video-input">OpenDataCam Github page</a>, including all the other settings you can change. For now will stick to the demo file while we link all the different parts of the project together, and I will describe the final setup I did for deployment at the end of the post.</p><p>To load and updated config file, restart the Docker container</p><p><code>
sudo docker-compose restart
</code></p><h2>How to Install Node-RED for Cloud Data Collection and Analysis</h2><p>I want to collect traffic data in set intervals and store it for analysis. InfluxDB is a database solution built specifically for time series data, which is exactly what we get from OpenDataCam. It also has some built-in visualisation tools. You can install and run InfluxDB locally on the Jetson, but in a production environment we will likely have multiple sources of data, so sending it to the cloud for analysis makes more sense.<br></p><p>OpenDataCam provides a simple but effective <a href="https://opendatacam.github.io/opendatacam/apidoc/">API </a>for interacting with it and extracting data, but we need to create a simple app to do this. I’ll be using Node-RED, flow-based GUI wrapper for Node.js, which also allows us to see at a glance how data flows through the app, and quickly make changes</p><figure><p><img src="https://assets-global.website-files.com/5d716c2c4df04f586b7912e3/5f298898cf4cb2839161f831_wUmPP-WAF2sNZpv2qt-pTAv6j4twJzsVmUR3MPQSDpX9roRV8JLq8PxcGqSejBnJc7z-RTxFWb7XIFEDAJNGIBgcPjBmHh4DDmMNuapQ3jL2agcDopb5UghwI4yRnsSB_TFLrEIp.png" alt=""></p></figure><p>The above screenshot gives you a good idea of how the flow works. First it checks the status of OpenDataCam (ODC), and starts it if it is not running yet, and if no recording is active, it starts one. If a recording is running, it retrieves the recording and then stop it, and immediately starts a new recording. The data from the completed recording is retrieved, and sent to InfluxDB.<br></p><p>This process is repeated at intervals set in the blue <em>timestamp</em> inject node. The dark green nodes provide output for debugging purposes.<br></p><p>To install Node-RED, open a terminal on your Jetson, and run:</p><p><code>
bash (curl -sL https://raw.githubusercontent.com/node-red/linux-installers/master/deb/update-nodejs-and-nodered)
</code></p><p>Install additional nodes for easy interaction with InfluxDB</p><p><code>
cd ~/.node-red &amp;&amp; npm install node-red-contrib-stackhero-influxdb-v2
</code></p><p>We want to let Node-RED start automatically when the Jetson starts</p><p><code>
sudo systemctl enable nodered.service
</code></p><p>Start Node-RED as a background service</p><p><code>
node-red-start
</code></p><p>Open the Node-RED UI by going to <em>localhost:1880</em> from the Jetson, or <em>*JetsonIP*:1880</em> from any computer on the same network.</p><p>To import the flow, click the menu icon in the upper right corner, and select <em>Import</em>.</p><p>Copy the flow code from this <a href="https://github.com/CuriousMongoose/opendatacam-nodered-influxdb/blob/master/nodered-flow.json">GitHub repo</a>, paste it into the import window, and click <em>Import</em>. The flow will now show in your Node-RED editor. Before we can deploy it, we need to set up InfluxDB to receive data, and get its authentication details.</p><h2>How to configure InfluxDB Cloud</h2><p>Now we need to set up a InfluxDB instance to receive the data. First go to the <a href="https://www.influxdata.com/products/influxdb-cloud/">InfluxDB Cloud page</a>, register for a free account, and create an instance on the cloud platform of your choice. I used AWS.&nbsp;</p><figure><p><img src="https://assets-global.website-files.com/5d716c2c4df04f586b7912e3/5f29889817f6f13ef9861283_iy66hKVJonggHuEE97zGCmEVwrBnvAR0HzJKug2-sTenFZKkAqmzCzpErKJZ_FLEBe6JGaS8v3kr9Kg05pUCwDJKJtK-cwoFw27Jr4ULD90M90_tiYSn5X5kffZhbMXp1udSCsFR.png" alt=""></p></figure><p>Once the instance is created and you are logged in, go to the <em>Buckets</em> tab on the <em>Dat…</em></p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.hologram.io/blog/using-nvidia-jetson-and-opendatacam">https://www.hologram.io/blog/using-nvidia-jetson-and-opendatacam</a></em></p>]]>
            </description>
            <link>https://www.hologram.io/blog/using-nvidia-jetson-and-opendatacam</link>
            <guid isPermaLink="false">hacker-news-small-sites-24407272</guid>
            <pubDate>Tue, 08 Sep 2020 11:15:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why secrets like API keys in Git are such a problem]]>
            </title>
            <description>
<![CDATA[
Score 14 | Comments 3 (<a href="https://news.ycombinator.com/item?id=24407232">thread link</a>) | @mackenzie-gg
<br/>
September 8, 2020 | https://blog.gitguardian.com/secrets-credentials-api-git/ | <a href="https://web.archive.org/web/*/https://blog.gitguardian.com/secrets-credentials-api-git/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
                <div>
                    <p>Secrets in version control systems (VCS) like git is the current state of the world <strong>despite widely being recognized as a bad practice</strong>. Once source code enters a git repository, it can organically spread into multiple locations. This includes any secrets that may be included within. But why then are secrets in git repositories so common? </p><!--kg-card-begin: html--><!--kg-card-end: html--><p><em>This is the second in a series of articles about secrets within source code and will look specifically at why secrets within git repositories is such a plague, why it is so dangerous and how to prevent it. </em></p><!--kg-card-begin: html--><hr id="1"><!--kg-card-end: html--><h2 id="why-secrets-end-up-in-git">Why secrets end up in git</h2><p>A seasoned developer may be scratching their heads wondering why anyone may put secrets inside a git repository. <strong>But the fact is, secrets inside git repositories is the current state of the world. </strong></p><p><a href="https://blog.gitguardian.com/secret-sprawl/">Last article</a> we talked about how it is common to choose the path of least resistance when it comes to accessing and distributing secrets. <strong>Git acts as the central point of truth for a project</strong>, so it makes sense, at least from a convenience point of view, that secrets are stored inside a private git repository to make distribution and access easy. </p><blockquote>But storing secrets like this is playing with fire, it only takes a very small incident to get burnt. </blockquote><p>In addition to intentionally storing secrets in git, <strong>when secrets are not managed properly, it is very easy to lose track of them</strong>. Secrets may be hardcoded into source code, stored as text file, shared over Slack or buried inside a debug application log. In addition, developers can be in large distributed teams with access to a plethora of secrets while being faced with reduced release cycles and an ever growing number of technologies to master. </p><!--kg-card-begin: html--><hr id="2"><!--kg-card-end: html--><h2 id="why-secrets-in-git-is-dangerous">Why secrets in git is dangerous</h2><p>Source code, we have to remember, is very leaky. Code is copied and transferred everywhere. Git is designed in a way that allows, even promotes, code to be freely distributed. </p><p>Projects can be cloned onto multiple machines, forked into new projects, &nbsp;distributed to customers, made public so on and so forth. <strong>Each time it’s duplicated on git, the entire history of that project is also duplicated.</strong></p><p>Why storing secrets in public repositories is bad will be obvious. They are freely available to everyone on the internet and it is very easy to monitor public repositories, GitHub has a public API to fetch all public commits for example. <br></p><p><strong>But what about private git repositories?</strong><br></p><p>Private repositories don’t publish your source code to the internet openly, but it doesn’t have adequate protection to store such sensitive information either. <strong>Imagine if there was a plain text file with all your credit card numbers within it, you hopefully wouldn’t put this into the companies git repository, secrets are just as sensitive. </strong></p><p><strong>A few things to consider when storing secrets in private repositories:</strong></p><ul><li>Everyone in the organization with access to the repo has access to the secrets within (one compromised account can provide an attacker access to a trove of secrets).</li><li>Repositories can be cloned onto multiple machines or forked into new projects.</li><li>Private repositories can be made public which can have secrets buried in the git history.</li></ul><p>Another important consideration is that <em><strong>code removed from a git repository is never actually gone.</strong></em></p><p>Git keeps track of all changes that are made. Code that is removed - or more technically correct: code that is committed over - still exists within the git history.</p><p>Interestingly enough, code is removed from a project at near equal volume that is added. This means that the code within repositories are much deeper than the first layer and secrets could be buried deep within the git history under a mass of commits that have been long forgotten. </p><figure><img src="https://lh6.googleusercontent.com/iPPNU4jrj_CRg3G1zdZ8dFranXUHL7uDUvUk3c3IoLgp-Ub4iNPrpxe8JGjXBl1ntarRIy1Izu5FByy8OFzOOQr8gQA5OCnnvaG_p20IOPQQmaDpHX2LyLJ6IRI0laPFlIs-Ez0O" alt="git history added files and deleted files"><figcaption>git contributions graph</figcaption></figure><p><a href="https://github.com/hashicorp/vault/graphs/code-frequency"><em>https://github.com/hashicorp/vault/graphs/code-frequency</em></a><em> </em><br></p><blockquote>Comment: The contributions graph that you see above from HashiCorp Vault repository is a typical view of a project's history. The regularity you find in project contribution graphs is both surprising and interesting (check out some projects graphs, it seems to be a rule of nature). <br></blockquote><!--kg-card-begin: html--><hr id="3"><!--kg-card-end: html--><h2 id="real-world-examples-recent-data-breaches">Real world examples: recent data breaches</h2><p>Secrets being leaked into public places happens with surprising regularity.</p><p>If you perform a search on GitHub for the commit message <em>‘removed aws key’</em>, you will find thousands of results. And that's just within public repositories.</p><figure><img src="https://lh4.googleusercontent.com/5WbkGwTV2zn3HJ-qtHQu8nJFOkjyd5zSdh2CRAemcZLaxw7N7KILSMhpjmdCKyxpwAjVokYUWKooWKJ4CYdK3_GmAgieNFx-5I7qDTXUcNCTsfwemi9Qum9-4qkKd5IV0bqEhqkZ" alt="Removed AWS keys search on GitHub"><figcaption>GitHub commit remove credential</figcaption></figure><p><a href="https://github.com/search?q=removed+aws+key&amp;type=Commits">https://github.com/search?q=removed+aws+key&amp;type=Commits</a></p><p>GitGuardian detects over 3,000 leaked secrets each day within public GitHub alone, there are thousands of examples for this but below are a couple recent or noteworthy examples.</p><p><em>Publicly disclosed examples of recent data breaches through leaked credentials.</em></p><blockquote><strong>Starbucks Data Breach - January 2020 </strong><br><a href="https://hackerone.com/reports/716292">JumpCloud API key found in GitHub repository</a></blockquote><blockquote><strong>Equifax Data Breach - April 2020</strong><br><a href="https://hackerone.com/reports/694931">leaked secrets in personal GitHub account granted access to sensitive data for equifax customers</a></blockquote><blockquote><strong>Uber Data Breach - October 2016</strong><br><a href="https://www.ftc.gov/system/files/documents/federal_register_notices/2018/04/152_3054_uber_revised_consent_analysis_pub_frn.pdf">Poor password hygiene allowed intruders to access Uber’s Amazon S3 Datastore using an AWS access key posted in a private GitHub repository.</a></blockquote><p>If this seems like an issue for only large companies to worry about, it’s not. Attackers are constantly exploiting personal services through secret keys too. In one example, <strong>bad actors scanned GitHub for AWS keys and used them to mine cryptocurrency, leaving <a href="https://www.theregister.com/2015/01/06/dev_blunder_shows_github_crawling_with_keyslurping_bots/">developers with thousands of dollars in debt</a></strong>.</p><figure><blockquote data-width="550"><p lang="en" dir="ltr">[RESEARCH IN PROGRESS] We "forgot" to hide AWS keys in the code of a public repo on <a href="https://twitter.com/github?ref_src=twsrc%5Etfw">@github</a> . In 10 minutes keys were exploited from two different IPs.</p>— Bob Diachenko (@MayhemDayOne) <a href="https://twitter.com/MayhemDayOne/status/1286230135885238273?ref_src=twsrc%5Etfw">July 23, 2020</a></blockquote>

</figure><!--kg-card-begin: html--><hr id="4"><!--kg-card-end: html--><h2 id="detecting-secrets-in-reviews-or-not-">Detecting secrets in reviews (or not)</h2><p>One great advantage of git is to be able to quickly and clearly see changes made and compare previous and proposed code states. It’s therefore common to believe that if secrets are leaked in source code, they of course will be detected within a code review or in a pull request.</p><blockquote>Code reviews are great for detecting logic flaws, maintaining good coding practices and keeping code quality high. But they are not adequate protection for detecting secrets. </blockquote><p>This is because reviews generally only consider the net difference between the current and proposed state. Not the entire history of a branch. Branches are commonly cleaned before being merged into the master branch, temporary code is added then deleted, unnecessary files added then removed.. But now these files, which are high risk candidates for containing secrets, are not visible to the reviewer (unless they want to go through the entire history of a branch). <br></p><figure><img src="https://lh6.googleusercontent.com/XZOq-SU3EwpmQM6YEo52h7jk1vUM99PL-IJSs5wbRfioPpiAqIl8Ss2zm6MhZPWGLQ8bv_52YMcMB-qPGhb98e0b52cYMNJQYJB8-FXTE1URxxa9g5_2gpwmqT2iqySjDYXhrfCe" alt="Looking for secrets in git history"><figcaption>Git code review diagram</figcaption></figure><p>Let's walk through the example above. While this is over simplified it tells a familiar story. </p><p><br>Commit B a file named main.py is added. A new branch is created to add a new function to main.py in commit C, this feature uses an API key so to save time for testing this is hardcoded. Once the feature is working the hardcoded API key is replaced with an env variable and the file is cleaned. Finally a pull request is made and accepted because the reviewer looks at the net difference between commit B and D, ignoring commit C. Now undetected secrets are buried in the git history of the project.</p><p>While this scenario is very basic, add in hundreds of commits and files between master and a development branch and you can see how easy it is to miss secrets in code reviews. </p><figure><blockquote data-width="550"><p lang="en" dir="ltr">Wow. Open sourced a private repo. Soon after I got notified from <a href="https://twitter.com/GitGuardian?ref_src=twsrc%5Etfw">@GitGuardian</a> that there is an old commit (where I removed a Terraform tfstate file). Thanks good people. You've got my back GG! 🙏 <a href="https://t.co/2rpvjjuXcI">https://t.co/2rpvjjuXcI</a></p>— Stefan Scherer (@stefscherer) <a href="https://twitter.com/stefscherer/status/1096353637540999169?ref_src=twsrc%5Etfw">February 15, 2019</a></blockquote>

</figure><!--kg-card-begin: html--><hr id="5"><!--kg-card-end: html--><h2 id="using-automated-detection-to-find-secrets-in-git">Using automated detection to find secrets in git</h2><p>Taking in consideration all we have just discussed about secrets inside git, it is clear that this is a problem that will persist and one we cannot solve with human code reviews. While automation is not always the answer, detecting secrets, in particular secrets inside git, automated secrets detection is a clear solution to this widespread problem. </p><p>Unfortunately detecting secrets in git is not quite as easy as it first seems because of the probabilistic nature of secrets. This makes it hard to distinguish between a true secret and other random-looking strings like database IDs or other hashes.</p><p>The good news however, is that <a href="https://dashboard.gitguardian.com/">GitGuardian</a> has built powerful tools for developers to detect secrets in git. A great dashboard with native GitHub and GitLab integrations, a CLI tool called <a href="https://github.com/GitGuardian/gg-shield">GG-Shield</a> or you can even build custom your own git secrets scanner using the <a href="https://api.gitguardian.com/">GitGuardian API</a>. </p><!--kg-card-begin: html--><!--kg-card-end: html--><h2 id="wrap-up">Wrap up</h2><p>Let’s have a quick review of what we have gone through. Git repositories are very common places to find secrets and they remain the perfect incubator for secrets to sprawl into multiple locations. Git keeps a track of a project's history which can be deep making finding secrets difficult. Because of the workflow git creates, it is common for any secrets to be missed during manual checking procedures and automated secrets detection should be introduced into the SDLC.</p><p>Curious of how secrets detection works? Next episode in the secrets in source code series we are going to dive into the mechanics of secrets detection including why probabilistic algorithms are so tricky and the secret sauce behind making them work.</p><!--kg-card-begin: html--><!-- Begin Mailchimp Signup Form -->





<!--End mc_embed_signup--><!--kg-card-end: html-->
                </div>
            </section></div>]]>
            </description>
            <link>https://blog.gitguardian.com/secrets-credentials-api-git/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24407232</guid>
            <pubDate>Tue, 08 Sep 2020 11:08:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Deep Diamond (Deep Learning in Clojure Is Fast, Simpler Than Keras)]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24406978">thread link</a>) | @tosh
<br/>
September 8, 2020 | https://dragan.rocks/articles/20/Deep-Diamond-Deep-Learning-in-Clojure-is-Fast-and-Simpler-than-Keras | <a href="https://web.archive.org/web/*/https://dragan.rocks/articles/20/Deep-Diamond-Deep-Learning-in-Clojure-is-Fast-and-Simpler-than-Keras">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
      
You can <a href="https://www.patreon.com/posts/22476035">adopt a pet function!</a>
Support my work <a href="https://patreon.com/draganrocks">on my Patreon page</a>, and access my <a href="https://www.patreon.com/posts/im-ditching-and-22476348">dedicated discussion server</a>. Can't afford to <a href="https://patreon.com/draganrocks">donate</a>? Ask for a free invite.
<p>September 5, 2020</p>
<p>
    Please share: .
</p>

<p>
    <a href="https://aiprobook.com/">New books are available for subscription.</a>
    </p><p><a href="https://aiprobook.com/deep-learning-for-programmers">
            <img src="http://aiprobook.com/img/dlfp-cover.png">
        </a>
        <a href="https://aiprobook.com/numerical-linear-algebra-for-programmers">
            <img src="http://aiprobook.com/img/lafp-cover.png">
        </a>
    </p>


<p>
through the direct equivalent of a fine Convolutional network example in Keras.
</p>

<p>
Good News: <a href="https://github.com/uncomplicate/deep-diamond">Deep Diamond</a>() preview release is in Clojars, and is already quite useful! And fast!
It is yet to be fully polished, but you can try it now and, I hope, you'll like it.
</p>

<p>
It now covers the functionality that is being explained from scratch in the <a href="http://aiprobook.com/">books that I'm writing</a>.
Convolutions work, too; at the speed of Road Runner!
</p>

<p>
In accordance with my philosophy, "less talk, more walk", I introduce Deep Diamond
through the direct equivalent of this fine <a href="https://github.com/keras-team/keras/blob/master/examples/mnist_cnn.py">MNIST CNN example in Keras</a>.
</p>

<div id="outline-container-org54ea652">
<h2 id="org54ea652">Specify the network blueprint</h2>
<div id="text-org54ea652">
<p>
We specify the network by plain Clojure vectors and functions, and create the blueprint.
No need for special compilers and whatnot. The structure of internal parts would be
picked up automatically, or we can specify these explicitly.
</p>

<div>
<pre><span>(</span><span>def</span> <span>net-spec</span> <span>[</span><span>(</span>convo <span>[</span>32<span>]</span> <span>[</span>3 3<span>]</span> <span>:relu</span><span>)</span>
               <span>(</span>convo <span>[</span>64<span>]</span> <span>[</span>3 3<span>]</span> <span>:relu</span><span>)</span>
               <span>(</span>pooling <span>[</span>2 2<span>]</span> <span>:max</span><span>)</span>
               <span>(</span>dropout<span>)</span>
               <span>(</span>dense <span>[</span>128<span>]</span> <span>:relu</span><span>)</span>
               <span>(</span>dropout<span>)</span>
               <span>(</span>dense <span>[</span>10<span>]</span> <span>:softmax</span><span>)</span><span>]</span><span>)</span>

<span>(</span><span>defonce</span> <span>net-bp</span>
  <span>(</span>network <span>(</span>desc <span>[</span>128 1 28 28<span>]</span> <span>:float</span> <span>:nchw</span><span>)</span>
           net-spec<span>)</span><span>)</span>
</pre>
</div>
</div>
</div>

<div id="outline-container-orgb8d8bce">
<h2 id="orgb8d8bce">Create the network</h2>
<div id="text-orgb8d8bce">
<p>
The blueprint is a Clojure function that can instantiate the network
object that holds the parameter tensors that the network should learn by using
one of the built-in optimization algorithms. In this case, I'll use adaptive moments,
<code>:adam</code>. Xavier initialization is, again, a plain function that initializes
the network with appropriate weights.
</p>

<div>
<pre><span>(</span><span>defonce</span> <span>net</span> <span>(</span>init! <span>(</span>net-bp <span>:adam</span><span>)</span><span>)</span><span>)</span>
</pre>
</div>

<p>
That's it! The network is ready to learn.
</p>
</div>
</div>

<div id="outline-container-orgae4dec0">
<h2 id="orgae4dec0">Train the network on MNIST data (CPU)</h2>
<div id="text-orgae4dec0">
<p>
The original MNIST data is distributed through four binary files that
you can download <a href="http://yann.lecun.com/exdb/mnist/">here</a>. To demonstrate how nice Clojure is, I'm not
using any special MNIST-specific code that is magically imported
from the framework's model Zoo. The complete code, from scratch, is at the
end of the article (I'm just pushing it there so it doesn't steal the spotlight :).
</p>

<div>
<pre><span>(</span>time <span>(</span>train net train-images y-train <span>:crossentropy</span> 12 <span>[]</span><span>)</span><span>)</span>
</pre>
</div>

<p>
The network learns in mini-batches of 128 images of the total of 60000,
with adaptive moments, through 12 full epochs. That makes 5625 forward/backward
update cycles.
</p>

<p>
The total time for that on my old 2013. i7-4790k CPU is: <b>368</b> seconds.
<b>6 minutes for 6000 cycles. A thousand cycles per minute.</b>
</p>

<p>
Isn't that a lot? You should try and run this in Keras with TensorFlow, and
see that we got a pretty nice performance! (I'll publish some comparisons soon,
and in the meantime you can try for yourself!).
</p>
</div>
</div>

<div id="outline-container-org7c0813e">
<h2 id="org7c0813e">Has it learned anything?</h2>
<div id="text-org7c0813e">
<p>
See the metrics:
</p>

<div>
<pre><span>(</span><span>-&gt;&gt;</span> <span>(</span>infer net test-images<span>)</span>
     <span>(</span>dec-categories<span>)</span>
     <span>(</span>classification-metrics test-labels-float<span>)</span>
     <span>:metrics</span><span>)</span>
</pre>
</div>

<pre>{:accuracy 0.9919,
 :f1 0.9918743606319073,
 :ba 0.9954941141884774,
 :sensitivity 0.9918944358825683,
 :specificity 0.9990937924943865,
 :precision 0.9918542861938476,
 :fall-out 9.062075056135655E-4}
</pre>

<p>
Accuracy is 99.2% which is in the ballpark of what the Keras example gives.
</p>
</div>
</div>


<div id="outline-container-org78cec4a">
<h2 id="org78cec4a">GPU</h2>
<div id="text-org78cec4a">
<p>
Want to go faster? No problem, Deep Diamond supports GPU, in the same process,
at the same time, with the same code!
</p>

<div>
<pre><span>(</span><span>defonce</span> <span>gpu</span> <span>(</span>cudnn-factory<span>)</span><span>)</span>

<span>(</span><span>def</span> <span>gpu-net-bp</span> <span>(</span>network gpu
                         <span>(</span>desc <span>[</span>128 1 28 28<span>]</span> <span>:float</span> <span>:nchw</span><span>)</span>
                         net-spec<span>)</span><span>)</span>

<span>(</span><span>defonce</span> <span>gpu-net</span> <span>(</span>init! <span>(</span>gpu-net-bp <span>:adam</span><span>)</span><span>)</span><span>)</span>

<span>(</span><span>def</span> <span>gpu-x-train</span>
  <span>(</span>transfer! train-images <span>(</span>tensor gpu <span>[</span>60000 1 28 28<span>]</span> <span>:float</span> <span>:nchw</span><span>)</span><span>)</span><span>)</span>

<span>(</span><span>def</span> <span>gpu-y-train</span>
 <span>(</span>transfer! y-train <span>(</span>tensor gpu <span>[</span>60000 10<span>]</span> <span>:float</span> <span>:nc</span><span>)</span><span>)</span><span>)</span>

<span>(</span>time <span>(</span>train gpu-net gpu-x-train gpu-y-train <span>:crossentropy</span> 12 <span>[]</span><span>)</span><span>)</span>
</pre>
</div>

<p>
Elapsed time? <b>20 seconds</b> on my Nvidia GTX 1080Ti (which is a few generations old)!
</p>
</div>
</div>

<div id="outline-container-org2c2d651">
<h2 id="org2c2d651">The books</h2>
<div id="text-org2c2d651">
<p>
Should I mention that the book <a href="https://aiprobook.com/deep-learning-for-programmers/">Deep Learning for Programmers: An Interactive Tutorial with
CUDA, OpenCL, DNNL, Java, and Clojure</a> teaches the nuts and bolts of neural networks and deep learning
by showing you how Deep Diamond is built, <b>from scratch</b>? In interactive sessions. Each line of code
can be executed and the results inspected in the plain Clojure REPL. The best way to master something is to build
it yourself!
</p>

<p>
It' simple. But fast and powerful!
</p>

<p>
Please subscribe, read the drafts, get the full book soon, and support my work on this free open source library.
</p>
</div>
</div>

<div id="outline-container-orga8b021d">
<h2 id="orga8b021d">Appendix: Reading, encoding, and decoding data</h2>
<div id="text-orga8b021d">
<p>
The code that reads the raw image data and converts it to proper tensors
should go up in the sequence of execution, but is not that interesting.
</p>

<div>
<pre><span>(</span><span>defonce</span> <span>train-images-file</span> <span>(</span>random-access <span>"data/mnist/train-images.idx3-ubyte"</span><span>)</span><span>)</span>
<span>(</span><span>defonce</span> <span>train-labels-file</span> <span>(</span>random-access <span>"data/mnist/train-labels.idx1-ubyte"</span><span>)</span><span>)</span>
<span>(</span><span>defonce</span> <span>test-images-file</span> <span>(</span>random-access <span>"data/mnist/t10k-images.idx3-ubyte"</span><span>)</span><span>)</span>
<span>(</span><span>defonce</span> <span>test-labels-file</span> <span>(</span>random-access <span>"data/mnist/t10k-labels.idx1-ubyte"</span><span>)</span><span>)</span>

<span>(</span><span>defonce</span> <span>train-images</span>
  <span>(</span>map-tensor train-images-file <span>[</span>60000 1 28 28<span>]</span> <span>:uint8</span> <span>:nchw</span> <span>:read</span> 16<span>)</span><span>)</span>
<span>(</span><span>defonce</span> <span>train-labels</span>
  <span>(</span>map-tensor train-labels-file <span>[</span>60000<span>]</span> <span>:uint8</span> <span>:x</span> <span>:read</span> 8<span>)</span><span>)</span>
<span>(</span><span>defonce</span> <span>test-images</span>
  <span>(</span>map-tensor test-images-file <span>[</span>10000 1 28 28<span>]</span> <span>:uint8</span> <span>:nchw</span> <span>:read</span> 16<span>)</span><span>)</span>
<span>(</span><span>defonce</span> <span>test-labels</span>
 <span>(</span>map-tensor test-labels-file <span>[</span>10000<span>]</span> <span>:uint8</span> <span>:x</span> <span>:read</span> 8<span>)</span><span>)</span>

<span>(</span><span>defn</span> <span>enc-categories</span> <span>[</span>val-tz<span>]</span>
  <span>(</span><span>let</span> <span>[</span>val-vector <span>(</span>view-vctr val-tz<span>)</span><span>]</span>
    <span>(</span><span>let-release</span> <span>[</span>cat-tz <span>(</span>tensor val-tz <span>[</span><span>(</span>first <span>(</span>shape val-tz<span>)</span><span>)</span> <span>(</span>inc <span>(</span>long <span>(</span>amax val-vector<span>)</span><span>)</span><span>)</span><span>]</span> <span>:flo</span><span>at</span><span> </span><span>:nc</span><span> </span><span>)</span>
                  cat-matrix <span>(</span>view-ge <span>(</span>view-vctr cat-tz<span>)</span> <span>(</span>second <span>(</span>shape cat-tz<span>)</span><span>)</span> <span>(</span>first <span>(</span>shape cat-t<span>z</span><span>)</span><span>)</span><span>)</span><span>]</span>
      <span>(</span><span>dotimes</span> <span>[</span>j <span>(</span>dim val-vector<span>)</span><span>]</span>
        <span>(</span>entry! cat-matrix <span>(</span>entry val-vector j<span>)</span> j 1.0<span>)</span><span>)</span>
      cat-tz<span>)</span><span>)</span><span>)</span>

<span>(</span><span>defn</span> <span>dec-categories</span> <span>[</span>cat-tz<span>]</span>
  <span>(</span><span>let</span> <span>[</span>cat-matrix <span>(</span>view-ge <span>(</span>view-vctr cat-tz<span>)</span> <span>(</span>second <span>(</span>shape cat-tz<span>)</span><span>)</span> <span>(</span>first <span>(</span>shape cat-tz<span>)</span><span>)</span><span>)</span><span>]</span>
    <span>(</span><span>let-release</span> <span>[</span>val-tz <span>(</span>tensor cat-tz <span>[</span><span>(</span>first <span>(</span>shape cat-tz<span>)</span><span>)</span><span>]</span> <span>:float</span> <span>:x</span><span>)</span>
                  val-vector <span>(</span>view-vctr val-tz<span>)</span><span>]</span>
      <span>(</span><span>dotimes</span> <span>[</span>j <span>(</span>dim val-vector<span>)</span><span>]</span>
        <span>(</span>entry! val-vector j <span>(</span>imax <span>(</span>col cat-matrix j<span>)</span><span>)</span><span>)</span><span>)</span>
      val-tz<span>)</span><span>)</span><span>)</span>

<span>(</span><span>defonce</span> <span>train-labels-float</span> <span>(</span>transfer! train-labels <span>(</span>tensor <span>[</span>60000<span>]</span> <span>:float</span> <span>:x</span><span>)</span><span>)</span><span>)</span>
<span>(</span><span>defonce</span> <span>y-train</span> <span>(</span>enc-categories train-labels-float<span>)</span><span>)</span>
<span>(</span><span>defonce</span> <span>test-labels-float</span> <span>(</span>transfer! test-labels <span>(</span>tensor <span>[</span>10000<span>]</span> <span>:float</span> <span>:x</span><span>)</span><span>)</span><span>)</span>
<span>(</span><span>defonce</span> <span>y-test</span> <span>(</span>enc-categories test-labels-float<span>)</span><span>)</span>
</pre>
</div>
</div>
</div>


    </article></div>]]>
            </description>
            <link>https://dragan.rocks/articles/20/Deep-Diamond-Deep-Learning-in-Clojure-is-Fast-and-Simpler-than-Keras</link>
            <guid isPermaLink="false">hacker-news-small-sites-24406978</guid>
            <pubDate>Tue, 08 Sep 2020 10:22:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Programming Is a Losers Game]]>
            </title>
            <description>
<![CDATA[
Score 10 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24406921">thread link</a>) | @todsacerdoti
<br/>
September 8, 2020 | https://tomgamon.com/posts/a-losers-game/ | <a href="https://web.archive.org/web/*/https://tomgamon.com/posts/a-losers-game/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><p>I recently read <a href="https://www.empirical.net/wp-content/uploads/2012/06/the_losers_game.pdf">this essay</a> which discusses changes in investment strategy in the 1970’s. In it, Charles Ellis talks about the difference between a <strong>winner’s game</strong> and a <strong>loser’s game</strong><sup id="fnref:1"><a href="#fn:1" role="doc-noteref">1</a></sup>.</p><blockquote><p>Expert tennis is what I call a Winner’s Game because the ultimate outcome is determined by the actions of the winner. Victory is due to winning more points than the opponent wins – not, as we shall see in a moment, simply to getting a higher score than the opponent, but getting that higher score by winning points.</p><p>Amateur tennis, Ramo found, is almost entirely different. Brilliant shots, long and exciting rallies and seemingly miraculous recoveries are few and far between. On the other hand, the ball is fairly often hit into the net or out of bounds, and double faults at service are not uncommon. The amateur duffer seldom beats his opponent, but he beats himself all the time. The victor in this game of tennis gets a higher score than the opponent, but he gets that higher score because his opponent is losing even more points.</p><p>…</p><p>In other words, professional tennis is a <strong>Winner’s Game</strong> – the final outcome is determined by the activities of the winner – and amateur tennis is a <strong>Loser’s Game</strong> – the final outcome is determined by the activities of the loser.</p></blockquote><p>What does it mean to talk about winning or losing in programming? What does success look like? I think that is a hard question, which could probably fill several blog posts, but I think a good working definition for us is “producing high quality code<sup id="fnref:2"><a href="#fn:2" role="doc-noteref">2</a></sup>, either by oneself or as part of a team, that helps to solve some problem for an end user”. Based on this definition, it seems to me that professional programming is somewhat of a losers game, at least for most of us.</p><p>I will concede that perhaps in fast moving startups, or for those involved in bleeding-edge research, there is an element of succeeding by “winning points”. Developing a faster algorithm, or determining some incredibly innovative way to implement a feature may help you succeed. However, I believe for a lot of professional programmers, succeeding comes from focusing on not “losing points” - causing bugs or producing unfathomable code, for example<sup id="fnref:3"><a href="#fn:3" role="doc-noteref">3</a></sup>.</p><p>When we consider programming with this in mind, it highlights the importance of some of the less glamorous elements of our field as a viable strategy for success. As you approach your next project, ask yourself, how can you avoid losing?</p><section role="doc-endnotes"><hr><ol><li id="fn:1" role="doc-endnote"><p>Which itself was taken from the work of Simon Ramo in his book <em>Extraordinary Tennis for the Ordinary Tennis Player</em>. <a href="#fnref:1" role="doc-backlink">↩︎</a></p></li><li id="fn:2" role="doc-endnote"><p>By “high quality code” I mean code that is clean, understandable and that produces few bugs in normal operation. <a href="#fnref:2" role="doc-backlink">↩︎</a></p></li><li id="fn:3" role="doc-endnote"><p>There has been some discussion on this piece on <a href="https://lobste.rs/s/iqctuy/programming_is_losers_game">lobste.rs</a> and it has highlighted a point that I need to clarify. I am not trying to claim that programming <em>is</em> a game, but rather it represents a scenario where we are working towards a goal, and perhaps one of the best strategies for achieving that goal is to avoid actions that frustrate your attempts to reach it. In tennis, that goal would be to win the match and a strategy you can pursue is to avoid hitting the net, rather than focussing on trying to outsmart your opponent with a clever backhand. For programmers, that goal may be to produce high quality software, and a strategy to pursue is to be extra careful to avoid bugs, rather than implement some very complex algorithm. <a href="#fnref:3" role="doc-backlink">↩︎</a></p></li></ol></section></section></div>]]>
            </description>
            <link>https://tomgamon.com/posts/a-losers-game/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24406921</guid>
            <pubDate>Tue, 08 Sep 2020 10:10:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[PandaDoc employees arrested in Belarus after founders protest against violence]]>
            </title>
            <description>
<![CDATA[
Score 443 | Comments 191 (<a href="https://news.ycombinator.com/item?id=24406366">thread link</a>) | @perch56
<br/>
September 8, 2020 | https://savepandadoc.org/en/ | <a href="https://web.archive.org/web/*/https://savepandadoc.org/en/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://savepandadoc.org/en/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24406366</guid>
            <pubDate>Tue, 08 Sep 2020 08:29:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why I link to Wayback Machine instead of original web content]]>
            </title>
            <description>
<![CDATA[
Score 573 | Comments 244 (<a href="https://news.ycombinator.com/item?id=24406193">thread link</a>) | @puggo
<br/>
September 8, 2020 | https://hawaiigentech.com/post/commentary/why-i-link-to-waybackmachine-instead/ | <a href="https://web.archive.org/web/*/https://hawaiigentech.com/post/commentary/why-i-link-to-waybackmachine-instead/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main">
      <div>
        <div id="content">
          <article>
    
    

    
    <div>
      <p><img src="https://hawaiigentech.com/post/commentary/why-i-link-to-waybackmachine-instead/wayback.jpg" alt="WayBackMachine"></p>
<hr>
<p>When linking to a page for the <strong>purpose of reference</strong>, it seems better to me to <em><strong>link to the <a href="https://archive.org/">archive</a> of a given page</strong></em>, rather than to the original site itself.</p>
<p>This ensures that after some years have gone by, <strong>my article is guaranteed to be consistent</strong>. Due the  changing nature of the web, there is a chance that after some years, the link could lead to a:</p>
<ul>
<li>404 /  Not Found (most common)</li>
<li>Changed or edited content, or entirely replaced content</li>
<li>Content that, due to a rise in popularity, is now shielded, demanding the user to make an account to read the entire article.</li>
</ul>
<hr>

<p>Take defensive measures. To future-proof your content, rather than reference the general web, its far more reliable to link to an archive.</p>
<h2 id="example">Example:</h2>
<p>The Epoch Times wrote an article on Smartphones data-mining their users. This is the archived article here:</p>
<p><a href="https://web.archive.org/web/20190214015500/https://www.theepochtimes.com/smartphone-app-users-are-data-mined-even-when-not-using-the-apps_2787202.html">The Archive Version (fully readable)</a></p>
<h3 id="article-content-before">Article Content Before</h3>
<p>You can see its perfectly “normal” readable useful  content.</p>
<p><img src="https://hawaiigentech.com/post/commentary/why-i-link-to-waybackmachine-instead/link-content-before.png" alt="Article Link Content Before"></p>
<h3 id="article-content-after">Article Content After</h3>
<p>Now it’s spam from a site suffering financial need.</p>
<p><img src="https://hawaiigentech.com/post/commentary/why-i-link-to-waybackmachine-instead/link-content-after.png" alt="Article Link Content Before"></p>
<p>So in Feb 14 2019 your users would have seen the content you intended. However in Sep 07 2020, your users are being asked to support independent Journalism instead.</p>
<h2 id="if-an-archive-record-doesnt-exist-make-one">If an Archive Record Doesn't Exist, Make One</h2>
<p>Its worth the extra moment, in referencing a site, to make an archive of the page you wish to reference, if one does not exist. After that, immediately use the link from the archive.org entry, rather than the blog, news, info, or forum site you wish to refer to.</p>
<h2 id="in-unstable-times-take-measures-for-stability">In Unstable Times, Take Measures for Stability</h2>
<p>The web is a fast changing place. Even more during the Covid pandemic and suffering financial markets. Since times are financially harder, websites are disappearing, heaping up advertising, demanding user response, and things like this.</p>
<p>To avoid your content losing quality due to these things, linking to a solid, unchanging static copy of the page is far more reliable.</p>

    </div>

    <div>
  <p>
    <span>Author</span>
    <span>Leo Blanchette</span>
  </p>
  <p>
    <span>LastMod</span>
    <span>
        2020-09-07
        
    </span>
  </p>
  
  
</div>

  </article>
        </div>
        

  

  

      </div>
    </div></div>]]>
            </description>
            <link>https://hawaiigentech.com/post/commentary/why-i-link-to-waybackmachine-instead/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24406193</guid>
            <pubDate>Tue, 08 Sep 2020 08:03:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why Past Attempts of Software Metrics Have Failed Us]]>
            </title>
            <description>
<![CDATA[
Score 12 | Comments 3 (<a href="https://news.ycombinator.com/item?id=24406030">thread link</a>) | @abyx
<br/>
September 8, 2020 | https://www.usehaystack.io/blog/software-development-metrics-pros-cons-and-why-past-attempts-have-failed | <a href="https://web.archive.org/web/*/https://www.usehaystack.io/blog/software-development-metrics-pros-cons-and-why-past-attempts-have-failed">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-w-id="0ea0c8ae-8333-a516-8908-f86a85ef9373"><p>TLDR; Software engineering is a black box. It's incredibly complex and nuanced. The industry makes attempts to stack rank and measure via simplified metrics. This is the wrong approach and hurts engineering culture. Software is complex, previous attempts don't take that into account. There is a better solution.</p><p>‍</p><p><strong>Software engineering is a black box because</strong></p><ol role="list"><li><a href="https://www.notion.so/usehaystack/Articles-f56dc18398104dca8534fc1e1ddd4ff2#990eff2e60e346b282c47abcb5687b96" target="_blank">Software engineering is complex and invisible</a></li><li><a href="https://www.notion.so/usehaystack/Articles-f56dc18398104dca8534fc1e1ddd4ff2#d32d356b92594f6cbb8a4993cdf1c2d0" target="_blank">The output of software development varies</a></li></ol><p>‍</p><p><strong>There have been several attempts at quantifying developer productivity. The limited content you'll find fits into a few categories.</strong></p><ol role="list"><li><a href="https://www.notion.so/usehaystack/Articles-f56dc18398104dca8534fc1e1ddd4ff2#128c578b6c9c489d8c53525166e0f932" target="_blank">KPIs used to measure software engineer performance</a></li><li><a href="https://www.notion.so/usehaystack/Articles-f56dc18398104dca8534fc1e1ddd4ff2#8d31dd02f20a42a6b1b586b955207ce4" target="_blank">Methods of measuring developer performance and their fall backs</a></li><li><a href="https://www.notion.so/usehaystack/Articles-f56dc18398104dca8534fc1e1ddd4ff2#dbf2216d7f134396bcfe69185e96c1a9" target="_blank">Opinion pieces on if measurement is even possible</a></li></ol><p>‍</p><p><strong>You'll notice a pattern prevalent in the space. The industry is obsessed with finding</strong></p><ol role="list"><li>Golden metrics to stack rank and compare teams and individuals.</li><li>KPIs to objectively determine an engineer's performance.</li></ol><p>‍</p><p><strong>The result?</strong></p><p>Attempts to measure software engineer and team productivity using the same, simplified metrics and KPIs.</p><p>‍</p><p><strong>But that's the wrong approach..</strong></p><ol role="list"><li><a href="https://www.notion.so/usehaystack/Articles-f56dc18398104dca8534fc1e1ddd4ff2#5f58624ed1f6432087fa3ef21378cf0b" target="_blank">Attempting to stack rank is fundamentally flawed</a></li><li><a href="https://www.notion.so/usehaystack/Articles-f56dc18398104dca8534fc1e1ddd4ff2#447680dd5e204f8a8bb526db55ebbe5c" target="_blank">'Successful outcomes' are situational</a></li><li><a href="https://www.notion.so/usehaystack/Articles-f56dc18398104dca8534fc1e1ddd4ff2#ea18251c7c0a4d50a1eb57e1e34f7ff8" target="_blank">Simplified metrics hurt engineering culture</a></li></ol><p>‍</p><p><strong>Focus on productivity, not yard sticks</strong></p><ol role="list"><li><a href="https://www.notion.so/usehaystack/Articles-f56dc18398104dca8534fc1e1ddd4ff2#c685ee9fc42c4c678d86b85f01006df8" target="_blank">Measure engineers and teams independently</a></li><li><a href="https://www.notion.so/usehaystack/Articles-f56dc18398104dca8534fc1e1ddd4ff2#dcd2a669df6a4e97afa9ec24e25fbc14" target="_blank">Compare relative to individual history</a></li><li><a href="https://www.notion.so/usehaystack/Articles-f56dc18398104dca8534fc1e1ddd4ff2#b0b75fb866ee44d29f9a5862be9e2579" target="_blank">Identify the main risks and bottlenecks of productivity</a></li></ol><p>‍</p><p><strong>Why is this better?</strong></p><ol role="list"><li><a href="https://www.notion.so/usehaystack/Footnotes-f56dc18398104dca8534fc1e1ddd4ff2#95433ef2f1cb46c5ac5b116b3221ac69" target="_blank">Accurately measures productivity</a></li><li><a href="https://www.notion.so/usehaystack/Articles-f56dc18398104dca8534fc1e1ddd4ff2#f20c40f07837457ea2dc431fbbeb4c6c" target="_blank">Handles situational outcomes</a></li><li><a href="https://www.notion.so/usehaystack/Articles-f56dc18398104dca8534fc1e1ddd4ff2#0f37d98374d64ea3a76d2b179cc16a74" target="_blank">Supports engineering culture</a></li><li><a href="https://www.notion.so/usehaystack/Footnotes-f56dc18398104dca8534fc1e1ddd4ff2#d09f4a9a554643139c1c3d9f0987e1a4" target="_blank">Enables early risk identification</a></li></ol><p>‍</p><p><strong>Main takeaway:</strong></p><p>From the nature of the work to the culture that supports it, engineering is incredibly complex and nuanced. Previous attempts at measuring engineering performance have done a poor job of taking this complexity into account. Making attempts to measure each engineer and team against the same yard stick not only hurts culture, but gives no true indication of productivity to begin with.</p><p>‍</p><p>To date, the industry has been attempting this 'holy grail' of software development metrics from the wrong perspective. By focusing on drivers and blockers of productivity rather than KPIs and stack ranking; we can start to measure engineers and teams in a healthy way. More importantly, this new perspective enables engineering leaders to introduce a software development metrics to help improve while maintaining the highest impact driver of productivity (culture).</p><p>‍</p><p>Check out Haystack's approach <a href="https://usehaystack.io/">here</a>!</p><figure><p><img src="https://uploads-ssl.webflow.com/5ed57622ee14fb96d022d544/5ef130052901e5cad8432b81_Haystack_Designed_Presentation.png" alt=""></p></figure><p><a href="https://usehaystack.io/?utm_source=blog&amp;utm_medium=3%20git%20signals%20to%20identify%20blockers&amp;utm_campaign=inside%20blog">Haystack</a> helps engineering leaders identify blockers and trends. Directly from Github. Instead of guessing if you're improving, or constantly bothering your team for progress updates, simply use Haystack to get alerts in your inbox every morning. Plus a dashboard to track improvements over time.</p><p><a href="https://usehaystack.io/?utm_source=blog&amp;utm_medium=3%20git%20signals%20to%20identify%20blockers&amp;utm_campaign=inside%20blog">Try it for free</a></p><p>‍</p><p>‍</p></div></div>]]>
            </description>
            <link>https://www.usehaystack.io/blog/software-development-metrics-pros-cons-and-why-past-attempts-have-failed</link>
            <guid isPermaLink="false">hacker-news-small-sites-24406030</guid>
            <pubDate>Tue, 08 Sep 2020 07:32:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Escape from Creek Fire]]>
            </title>
            <description>
<![CDATA[
Score 129 | Comments 75 (<a href="https://news.ycombinator.com/item?id=24405981">thread link</a>) | @twohey
<br/>
September 8, 2020 | https://www.jmeshe.co/escape-from-creek-fire | <a href="https://web.archive.org/web/*/https://www.jmeshe.co/escape-from-creek-fire">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<div>
<p><span>
By subscribing to the mailing list of
<strong>
Jaymie Shearer
</strong>
your email address is stored securely, opted into new post notifications and related communications. We respect your inbox and privacy, you may unsubscribe at any time.
</span></p><div>
<p><a href="https://www.exposure.co/privacy" rel="noopener" target="_blank" title="Link to Jaymie Shearer Privacy Policy">
Privacy Policy
</a>
<a href="https://www.exposure.co/terms" rel="noopener" target="_blank" title="Link to Jaymie Shearer Terms of Service">
Terms of Service
</a>
<a href="https://www.exposure.co/report" rel="noopener" target="_blank" title="Report a story or story">
Report
</a>
</p></div>

</div>
</div></div>]]>
            </description>
            <link>https://www.jmeshe.co/escape-from-creek-fire</link>
            <guid isPermaLink="false">hacker-news-small-sites-24405981</guid>
            <pubDate>Tue, 08 Sep 2020 07:22:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[URL query parameters and how laxness creates de facto requirements on the web]]>
            </title>
            <description>
<![CDATA[
Score 101 | Comments 73 (<a href="https://news.ycombinator.com/item?id=24404814">thread link</a>) | @oftenwrong
<br/>
September 7, 2020 | https://utcc.utoronto.ca/~cks/space/blog/web/DeFactoQueryParameters | <a href="https://web.archive.org/web/*/https://utcc.utoronto.ca/~cks/space/blog/web/DeFactoQueryParameters">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><h2>URL query parameters and how laxness creates de facto requirements on the web</h2>

	<p><small>September  7, 2020</small></p>
</div><div><p>One of the ways that <a href="https://utcc.utoronto.ca/~cks/space/dwiki/DWiki">DWiki</a> (the code behind <a href="https://utcc.utoronto.ca/~cks/space/blog/">Wandering Thoughts</a>) is unusual is that it strictly validates the query parameters
it receives on URLs, including on HTTP <code>GET</code> requests for ordinary
pages. If a HTTP request has unexpected and unsupported query
parameters, such a <code>GET</code> request will normally fail. When I made
this decision it seemed the cautious and conservative approach, but
<a href="https://utcc.utoronto.ca/~cks/space/blog/web/CautionIsAMistakeToday">this caution has turned out to be a mistake on the modern web</a>. In practice, all sorts of sites will
generate versions of your URLs with all sorts of extra query
parameters tacked on, give them to people, and expect them to work.
If your website refuses to play along, (some) people won't get to
see your content. <strong>On today's web, you need to accept (and then
ignore) arbitrary query parameters on your URLs</strong>.</p>

<p>(Today's new query parameter is 's=NN', for various values of NN
like '04' and '09'. I'm not sure what's generating these URLs, but
it may be Slack.)</p>

<p>You might wonder how we got here, and that is a story of lax behavior
(or, if you prefer, being liberal in what you accept). In the
beginning, both Apache (for static web pages) and early web
applications often ignored extra query parameters on URLs, at least
on <code>GET</code> requests. I suspect that other early web servers also
imitated Apache here, but I have less exposure to their behavior
than Apache's. My guess is that this behavior wasn't deliberate,
it was just the simplest way to implement both Apache and early
web applications; you paid attention to what you cared about and
didn't bother to explicitly check that nothing else was supplied.</p>

<p>When people noticed that this behavior was commonplace and widespread,
they began using it. I believe that one of the early uses was for
embedding 'where this link was shared' information for your own web
analytics (<a href="https://utcc.utoronto.ca/~cks/space/blog/web/AnalyticsVsSecurity">cf</a>), either based on your logs
or using JavaScript embedded in the page. In the way of things,
once this was common enough other people began helpfully tagging
the links that were shared through them for you, which is why I
began to see various 'utm_*' query parameters on inbound
requests to <a href="https://utcc.utoronto.ca/~cks/space/blog/">Wandering Thoughts</a> even though I never
published such URLs.
Web developers don't leave attractive nuisances alone for long, so
soon enough people were sticking on extra query parameters to your
URLs that were mostly for them and not so much for you. Facebook
may have been one of the early pioneers here with their 'fbclid'
parameter, but other websites have hopped on this particular train
since then (as I saw recently with these 's=NN' parameters).</p>

<p>At this point, the practice of other websites and services adding
random query parameters to your URLs that pass through them is so
wide spread and common that accepting random query parameters is
pretty much a practical requirement for any web content serving
software that wants to see wide use and not be irritating to the
people operating it. If, like <a href="https://utcc.utoronto.ca/~cks/space/dwiki/DWiki">DWiki</a>, you stick to your guns and
refuse to accept some or all of them, you will drop some amount of
your incoming requests from real people, disappointing would be
readers.</p>

<p>This practical requirement for URL handling is not documented in
any specification, and it's probably not in most 'best practices'
documentation. People writing new web serving systems that are
tempted to be strict and safe and cautious get to learn about it
the hard way.</p>

<p>In general, any laxness in actual implementations of a system can
create a similar spiral of de facto requirements. Something that
is permitted and is useful to people will be used, and then supporting
that becomes a requirement. This is especially the case in a
distributed system like the web, where any attempt to tighten the
rules would only be initially supported by a minority of websites.
These websites would be 'outvoted' by the vast majority of websites
that allow the lax behavior and support it, because that's what
happens when the vast majority work and the minority don't.</p>
</div></div>]]>
            </description>
            <link>https://utcc.utoronto.ca/~cks/space/blog/web/DeFactoQueryParameters</link>
            <guid isPermaLink="false">hacker-news-small-sites-24404814</guid>
            <pubDate>Tue, 08 Sep 2020 02:50:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Git/serve: A Git server for Plan 9]]>
            </title>
            <description>
<![CDATA[
Score 10 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24404681">thread link</a>) | @todsacerdoti
<br/>
September 7, 2020 | https://orib.dev/gitserve.html | <a href="https://web.archive.org/web/*/https://orib.dev/gitserve.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">


<p>A while ago, I released <a href="https://orib.dev/git9.html">git9</a>, a git client for
Plan 9. However, it always felt like it was missing something: A git server.
over a few weekends of work, I sat down and put one together. This Labor
Day weekend, I took the opportunity to labor on it, and got something working.</p>

<h3>usage</h3>

<p><code>Git/serve</code> is a git server designed to fit into the Plan
9 ecosystem, allowing hosting of, and interacting with, code on a Plan 9
server, while still allowing legacy clients running on Unix to get a copy
of the code.</p>

<p><code>Git/serve</code> only speaks the <code>git://</code> protocol.
But because it runs behind
<a href="http://man.9front.org/8/listen">aux/listen</a>
and 
<a href="http://man.9front.org/8/tlssrv"><code>tlssrv</code></a>, we
effectively get two additional protocols for free: <code>gits://</code>, or
TLS-encrypted <code>git://</code>, and <code>hjgit://</code>, which is
<code>git://</code> but with Plan 9 authentication to support user login
over TLS. Unfortunately, only the unencrypted <code>git://</code> protocol
is supported out of the box by upstream git. There may be ways to solve
this, using <a href="https://rovaughn.github.io/2015-2-9.html">custom
transports</a>, and a unix port of tlsclient</p>

<p>To start a <code>git://</code> server, just run it under aux/listen1.
To enable encryption and user authentication, run it under
<code>tlssrv -a</code>. This doesn't need a certificate, because
the Plan 9 authentication generates the secret used for TLS. And,
finally, if you just want encryption, you can use <code>tlsclient</code>
with a certificate.</p>

<pre># git:// server, serving every repository under the current directory
% aux/listen1 'tcp!*!9418' git/serve -r `{pwd}

# gits:// server, doing the same: But with encryption.
% aux/listen1 'tcp!*!9418' tlsclient -c /path/to/cert.pem git/serve -r `{pwd}

# hjgit:// server doing the same: Requires account on server to connect
% aux/listen1 'tcp!*!9418' tlsclient -a git/serve -r `{pwd}
</pre>

<p>If you want to allow people to write, you can just add the
<code>-w</code> flag to git/serve. While you can do this on
any of the protocols, keep in mind that only <code>hjgit://</code>
authenticates the users. Push to the world, but don't let the
world push to you!</p>



<p>All the protocols git uses are closely related. The <code>ssh://</code>
protocol is just the <code>git://</code> protocol, with the command selected
sightly differently. The smart <code>http://</code> protocols are the same
as the <code>git://</code> protocol, with a different handshake, and split
over multiple post requests.</p>

<p>Git9 implements the git protocol in under 500 lines of C. The
full code is available on github, in
<a href="https://github.com/oridb/git9/blob/24abe6c00b6f65e7241763399fc72c043b7d9bbf/serve.c">serve.c</a>.
</p>

<p>The protocol look something like this for pushing:</p>

<pre>&lt;=w= 0030:	"git-fetch-pack /oridb/git9\0host=github.com\n"
=r=&gt; 0086:	"747e9e80f710c0b8bbd928080745915ad2493322 HEAD\n"
=r=&gt; 009d:	"747e9e80f710c0b8bbd928080745915ad2493322 refs/heads/master\n"
&lt;=w= 0076:	"747e9e80f710c0b8bbd928080745915ad2493322 dc802c499dc7164aa208b919a07c5bd18701b0e1 refs/heads/master\0report-status\n"
&lt;=w= 0000
&lt;=w= <pack-data>
=r=&gt; 000e:	unpack ok
=r=&gt; 0019:	ok refs/heads/master
</pack-data></pre>

<p>And this for pulling:</p>

<pre>&lt;=w= 0030:	"git-upload-pack /oridb/git9\0host=github.com\n"
=r=&gt; 013b:	"dc802c499dc7164aa208b919a07c5bd18701b0e1 HEAD\n"
=r=&gt; 003f:	"dc802c499dc7164aa208b919a07c5bd18701b0e1 refs/heads/master\n"
=r=&gt; 0000
&lt;=w= 0032:	"want 5d761590cfdce23e4b17e94050b0776c8804d4a1\n"
&lt;=w= 0032:	"want 8f0eb1386a2c748cb7bf26917684479ff8c6d5b5\n"
&lt;=w= 0032:	"want dc4a9d467c6a28dab3927c8611a1bfbc571f1568\n"
&lt;=w= 0000
&lt;=w= 0033:	"have dc802c499dc7164aa208b919a07c5bd18701b0e1\n"
&lt;=w= 0009:	"done\n"
=r=&gt; 0031:	"ACK dc802c499dc7164aa208b919a07c5bd18701b0e1\n"
<pack-data>
</pack-data></pre>

<p>The git protocol consists of pkt-lines, which are strings with a
hex-formatted length prefix.  The length prefix includes itself.  So,
the string <code>"hi"</code> would be formatted as
<code>0006hi</code>. A zero lenth packet where the length prefix
is not included is special. This is called a 'flush packet', and
is used to terminate a phase of negotiation.</p>

<p> All negotiation is with these packet lines, at
which git flips over to pure binary mode to transfer a pack file
over.</p>

<p>In the <code>git://</code> protocol, the client always starts off
by saying which action it wants to do: Either it wants the server to
fetch a pack from the client, or it wants the server to upload a pack
to the client.  That's this line:</p><pre>&lt;=w= 0030:	"git-fetch-pack /oridb/git9\0host=github.com\n"
</pre>

<p>The upload side of this protocol is simpler on the server side so
we'll go through it first.</p>

<h3>pushing</h3>

<p>In the upload protocol, the server begins by sending a list of
references that the client may update. In <code>git/serve</code>
we grab all the refs in the repository, and filter down to just
the ones beginning with <code>heads/</code>.</p>

<pre>	if((nrefs = listrefs(&amp;refs, &amp;names)) == -1)
		sysfatal("listrefs: %r");
	for(i = 0; i &lt; nrefs; i++){
		if(strncmp(names[i], "heads/", strlen("heads/")) != 0)
			continue;
		if(fmtpkt(c, "%H refs/%s\n", refs[i], names[i]) == -1)
			goto error;
	}
	if(flushpkt(c) == -1)
		goto error;
</pre>

<p>With the first phase of the protocol, the client then
sends the list of references it wants to update. This
takes the form of:</p>

<pre>	OLDHASH NEWHASH heads/refs/updateme\n"
</pre>

<p>Because the client knows what the reference versions are on
the server, it can compute what commits are between the version
on the server and the version that it has. If the new hash
is the zero hash, this signals to the server that the reference
should be deleted. This list of updates is terminated with a
flush packet. The code in git9 that handles this is below:

</p><pre>	while(1){
		/* Did we get a packet? */
		if((n = readpkt(c, pkt, sizeof(pkt))) == -1)
			goto error;
		/* Was it a flush packet? */
		if(n == 0)
			break;
		/* Split it up into the 3 parts: old, new, reference */
		if(getfields(pkt, sp, nelem(sp), 1, " \t\n\r") != 3){
			fmtpkt(c, "ERR  protocol garble %s\n", pkt);
			goto error;
		}
		/* verify that these are valid hashes */
		if(hparse(&amp;old, sp[0]) == -1){
			fmtpkt(c, "ERR bad old hash %s\n", sp[0]);
			goto error;
		}
		if(hparse(&amp;new, sp[1]) == -1){
			fmtpkt(c, "ERR bad new hash %s\n", sp[1]);
			goto error;
		}
		/* and valid refs */
		if(!validref(sp[2])){
			fmtpkt(c, "ERR invalid ref %s\n", sp[2]);
			goto error;
		}
		/* and then remember them for when we do the update */
		*cur = erealloc(*cur, (*nupd + 1)*sizeof(Hash));
		*upd = erealloc(*upd, (*nupd + 1)*sizeof(Hash));
		*ref = erealloc(*ref, (*nupd + 1)*sizeof(Hash));
		(*cur)[*nupd] = old;
		(*upd)[*nupd] = new;
		(*ref)[*nupd] = estrdup(sp[2]);
		*nupd += 1;
	}
</pre>

<p>Next, the client uploads the pack. This is a blob containing
the commit data. It goes into <code>.git/objects/packs/recv-$pid.pack</code>,
at least until we can index it and rename it.</p>

<pre>	while(1){
		n = read(c-&gt;rfd, buf, sizeof(buf));
		if(n == 0)
			break;
		if(n == -1 || write(pfd, buf, n) != n)
			return -1;
		packsz += n;
	}
	if(checkhash(pfd, packsz, &amp;h) == -1){
		dprint(1, "hash mismatch\n");
		goto error1;
	}
	if(indexpack(packtmp, idxtmp, h) == -1){
		dprint(1, "indexing failed\n");
		goto error1;
	}
	if(rename(packtmp, idxtmp, h) == -1){
		dprint(1, "rename failed: %r\n");
		goto error2;
	}
</pre>

<p>Finally, we update the references. Note that we haven't
locked the repository yet. This is because none of the data
we have here can conflict: All objects are addressed by hash,
so a race would simply leave us with a duplicate hash in the
packfile. Eventually, a <code>git/repack</code> will clean
that up.</p>

<p>However, updating the references can conflict. So,
for updating the references, we acquire a lock file.
We then read all the references, make sure that they
match the old reference, and then write in the new
reference.</p>

<pre>	for(i = 0; i &lt; nupd; i++){
		if(resolveref(&amp;h, ref[i]) == 0 &amp;&amp; !hasheq(&amp;h, &amp;cur[i])){
			fmtpkt(c, "ERR old ref changed: %s", ref[i]);
			goto error;
		}
		if((o = readobject(upd[i])) == nil){
			fmtpkt(c, "ERR update to nonexistent hash %H", upd[i]);
			goto error;
		}
		if(o-&gt;type != GCommit){
			fmtpkt(c, "ERR not commit: %H", upd[i]);
			goto error;
		}
		unref(o);
		if(snprint(refpath, sizeof(refpath), ".git/%s", ref[i]) == sizeof(refpath)){
			fmtpkt(c, "ERR ref path too long: %s", ref[i]);
			goto error;
		}
		if((fd = create(refpath, OWRITE, 0644)) == -1){
			fmtpkt(c, "ERR open ref: %r");
			goto error;
		}
		if(fprint(fd, "%H", upd[i]) == -1){
			close(fd);
			fmtpkt(c, "ERR upate ref: %r");
			goto error;
		}
		close(fd);
	}
</pre>

<p>And that's pushing.

</p><h3>pulling</h3>

<p>Pulling takes more work on the server side, because the
server needs to compute a reasonable packfile to send to
the client. The protocol itself is still fairly simple.</p>

<p>It begins the same way as pushing, by sending all the
branches that a client may want to obtain from the git
repository.</p>

<pre>=r=&gt; 013b:	"dc802c499dc7164aa208b919a07c5bd18701b0e1 HEAD\n"
=r=&gt; 003f:	"dc802c499dc7164aa208b919a07c5bd18701b0e1 refs/heads/master\n"
=r=&gt; 0000
</pre>

<p>The client then starts telling us what commits they want,
and what commits they have. This lets us find a graph difference
between the server and client graph, and generate a pack file
that contains few, if any, extraneous commits. </p>

<pre>&lt;=w= 0032:	"want 5d761590cfdce23e4b17e94050b0776c8804d4a1\n"
&lt;=w= 0032:	"want 8f0eb1386a2c748cb7bf26917684479ff8c6d5b5\n"
&lt;=w= 0032:	"want dc4a9d467c6a28dab3927c8611a1bfbc571f1568\n"
&lt;=w= 0000
&lt;=w= 0033:	"have dc802c499dc7164aa208b919a07c5bd18701b0e1\n"
&lt;=w= 0009:	"done\n"
=r=&gt; 0031:	"ACK dc802c499dc7164aa208b919a07c5bd18701b0e1\n"
</pre>

<p>Computing the commits that go into a pack is not always trivial.
The comits that the client may be on may have "bubbles" in the graph,
so simply walking back from the start of the graph to the commits
that the client has may end up walking around the commit, leading
to nearly the whole history of the repository being sent, instead
of just one or two commits.</p>

<p>Consider a repo where the server is ahead of the client, and
now the client is trying to pull the changes. The client has commits
<code>c</code>, and we're trying to compute a pack with only the
commits <code>o</code>.</p>


<pre>                o---o
               /     \
    --c---c---c---c---o---o &lt;-- server
                  ^
                client
</pre>

<p>The client does a git/pull, and sends that it has the
commit marked <code>[c]</code>. Since the server has
every commit the client does, and more, it can look at
all ancestors of the client commit. If we're smart, we
would, but a naive …</p></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://orib.dev/gitserve.html">https://orib.dev/gitserve.html</a></em></p>]]>
            </description>
            <link>https://orib.dev/gitserve.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24404681</guid>
            <pubDate>Tue, 08 Sep 2020 02:19:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Seamus Heaney Experience]]>
            </title>
            <description>
<![CDATA[
Score 11 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24404595">thread link</a>) | @apollinaire
<br/>
September 7, 2020 | https://www.drb.ie/essays/the-seamus-heaney-experience | <a href="https://web.archive.org/web/*/https://www.drb.ie/essays/the-seamus-heaney-experience">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p><em>On Seamus Heaney</em>, by RF Foster, Princeton University Press (Writers on Writers series), 228 pp, £14.99, ISBN: 978-0691174372</p> <p>Karl Miller always disclaimed credit for being the first person – first in the UK anyway – to spot the merit in Seamus Heaney’s early work. Others had got there before him, he said. But, in 1964, and in defiance of opposition from colleagues at the <em>New Statesman</em>, where he was literary editor, Miller published three Heaney poems, including “Death of a Naturalist” and “Digging”. The poems were subsequently read and admired by Charles Monteith of Faber (coincidentally, a fellow Ulsterman), who wrote to Heaney inviting him to submit a manuscript. <em>Death of a Naturalist</em> duly appeared, and hindsight shows its publication to be a momentous event in literary history. From this point on, you might say, Heaney never looked back.</p> <p>But of course looking back was precisely what had brought him into the limelight, and looking back remained central to his literary impetus. However, as time went on, the process was negotiated with increasing virtuosity, density, and transformative power. “Remember everything and keep your head.” This line, attributed to the ghost of William Carleton in Section Two of the “Station Island” sequence, is advice the poet always abided by, with his new-minted “themes of locality and memory” and his rural minutiae, down to the ox-eye daisies and dandelions in the middle of the road to school, or the milk poured for cats in a rank puddle-place in a stone kitchen floor. The “scraggy farm and moss” aspect of Heaney’s Co Derry childhood is recreated with an intensity and assurance as far removed as possible from the picturesque or facile associations of country – and in particular, Northern Irish country – verse. If “bogs, bulls and buckets” persist in the Heaney lexicon (as one faintly sarcastic reviewer of <em>Wintering Out</em> had it), they are tied up with the observer’s complex motivations and visionary brevity of style.</p> <p>Indeed there was nothing about Seamus Heaney’s early life, or his wonderfully throughother boyhood environment, to indicate the route his astonishing career would follow. “By the 1990s,” writes RF Foster in his astute new study, Heaney’s “work and reputation were positioned at the centre of the English canon, while operating emphatically from a base in Ireland (North and South).” How Heaney arrived at this position is a story of steady progress, of an unparalleled gift for illumination and evocation, of a way of being orthodox and utterly independent at the same time. (“At once complete insider and odd man out” in Paul Muldoon’s words.) The independence in is the output, the orthodoxy in the list of honours, awards and academic posts which piled up over the years and culminated in the Nobel laureateship in 1995. It should be said that nothing about his immense celebrity went to the poet’s head: he remained calm and down-to-earth in the midst of all the brouhaha and kept a steadfast demeanour – though at what cost to his psychological wellbeing one can only surmise.</p> <p>It was not, of course, a matter of uninterrupted acclaim. There were stumbling blocks as well as stepping stones along the way, and some of these had a distinctly local character. It was felt in some Northern Irish circles – and especially while his career was taking off – that Heaney needed constant reminding not to get above himself. If he’d been singled out – well, it was a lucky chance: others existed who were equally deserving of fame. There were subtle, and not-so-subtle, put-downs. Even his future friend and admirer Brian Friel, Foster notes, took a somewhat acerbic line about Heaney’s “easy manipulation [at the time] of a new audience in England”. But Foster’s most searing criticism is directed at the poet and founder of <em>The Honest Ulsterman</em> James Simmons, whom he accuses of harbouring a “festering jealousy” and of being “lazily obtuse” in his assessments of the Heaney <em>oeuvre</em>. Foster really does not like Simmons, and nor is the <em>HU</em>’s brand of bare-faced irreverence greatly to his taste.</p> <p>He has a point – though perhaps he misses Simmons’s occasional elan and fluency in his own poetry – and he is right to draw attention to the various misreadings, including Simmons’s, of Heaney’s pivotal collection <em>North</em> (his fourth). Hailed internationally as “a vital achievement” and enshrining its author as “the best Irish poet since W.B. Yeats” (Robert Lowell’s phrase), the book encountered a certain disparagement, not to say outright hostility, in Heaney’s home territory. Some of this had a political dimension. On the strength of one or two poems (in particular the desolating and striking “Punishment”), some Irish critics chose to attribute to him an excessive solidarity with the Catholic North and republican grievances (just to even things out, he was later taken to task for eschewing a supportive role in relation to republicanism). In fact, of course, Heaney is far from condoning violence or dissociating himself from any of his inherited allegiances. He did, as a poet, want to stand apart from both sides, he said, while acknowledging the inescapable, and inspirational, circumstances of his early life and times. Terence Brown, reviewing <em>Stepping Stones</em> in 2008 (the remarkable series of questions posed by Dennis O’Driscoll and answered comprehensively by Heaney), sums up the ways in which poetry – any poetry ‑ is a product of “life situations … cultural contexts … intellectual preoccupations and involvement with public issues”. </p> <p>Cultural contexts and public issues. These, during Heaney’s lifetime, were emphatically bound up with the thirty-year conflict known as the Troubles; and part of the poet’s driving force involved a quest – as he famously put it – “for images and symbols adequate to our predicament” (echoing Yeats’s “befitting emblems of adversity”). Not obvious images and symbols, indeed, but those which would carry the utmost resonance and work their effect at different levels. Some he found in an enlarged idea of “Northernness”, taking in iron-age excavations and a pared-down Viking connection. When he was questioned by O’Driscoll, many years later, Heaney stood by the poems in <em>North</em>, which he judged to be appropriately “odd and hard and contrary”.</p> <p>It wasn’t only in Irish literary circles that the odd swipe was directed at Heaney and his poetry. Among prominent anti-Heaneyites Foster names Ian Hamilton of <em>The New Review</em>, for example, along with A Alvarez, who scrutinised <em>Field Work</em> for “verbal affectations” (he found a few), and blamed the poet for cultivating an overdone “charm and rhetoric”. And he didn’t stop there, going on to mock Heaney’s “fine way with the language” – a phrase suggesting a showiness and slickness of which the poet was incapable. Actually, the Alvarez appraisal (in the <em>New York Review of Books</em>), and others in the same mode, suggest nothing more than a wilful declaration of independence from the laudatory chorus. Some critics were exasperated by what they considered the undue elevation of Heaney – the “Heaney Phenomenon”, as they dubbed it, investing the phrase with a sardonic intonation.</p> <p>This is what Foster is referring to when he mentions “the half-suppressed current of begrudging comment”. But the expression of misgivings died away as Heaney’s place in the canon of contemporary literature became unassailable. Those who had spotted something strong and original and compelling in his work from the start – who had simply noticed “how good Heaney’s poems were” (Karl Miller) – could congratulate themselves on their discernment. For Michael Longley – for example – reviewing <em>Death of a Naturalist</em> in 1966, Heaney’s childhood landscapes had already acquired “the validity of myth”, while the collection as a whole announced the inauguration of “a true poet of considerable importance”. Heaney was not the only one, of course: there was Longley himself, and Derek Mahon; and, in the eyes of the poetry-reading public, the three newcomers on the scene were soon to coalesce into a poetic triumvirate, before its separate components went their separate, and superlative, ways. Things, in the cultural sphere, were astir in mid-1960s Belfast, after the doldrums of the previous decade; and the Heaney household, up until 1972, was a particular centre of ebullience and expansiveness.</p> <p><em>On Seamus Heaney</em> treats the poet’s life and work with thoroughness and dispassion. The story of what happened to Heaney is deftly retold by RF Foster, and retold in a way that makes sense of the poet’s prodigious journey, from Bellaghy to Belfast to Berkeley, and onwards and upwards thereafter to a kind of poetic apotheosis. The year Heaney spent (with his family) as a visiting professor at Berkeley in California was crucial to his development in all sorts of ways – “Something changed, all right,” he told Dennis O’Driscoll – and it’s likely that the experience deepened his dissatisfaction with goings-on in Belfast, once he had returned to the city. At any rate, within a year or so, Heaney had taken himself, with his wife and children, out of the North and into a cottage in Co Wicklow. The cottage at Glanmore was rented from the Canadian academic and Synge scholar Anne Saddlemyer, and – although the Heaneys bought it later – it represented a staging post on the way to Dublin, eventual international renown, and endless demands on the poet’s time and stamina.</p> <p>There were many distractions – but through it all, the poetry continued to work its spellbinding effect. It is wonderfully idiosyncratic in its rhythms and allusions and cross-currents. We have the celebrated sequences, the Bog Poems, the Glanmore Sonnets, the Station Island encounters with significant revenants. And the farm at Mossbawn in Co Derry, the childhood abundant in grace and exhilaration and plentiful food for thought, the sectarian dimension and neighbourly accommodations worked out expediently, the ultimate wreckage of the North, with – for the poet – …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.drb.ie/essays/the-seamus-heaney-experience">https://www.drb.ie/essays/the-seamus-heaney-experience</a></em></p>]]>
            </description>
            <link>https://www.drb.ie/essays/the-seamus-heaney-experience</link>
            <guid isPermaLink="false">hacker-news-small-sites-24404595</guid>
            <pubDate>Tue, 08 Sep 2020 01:59:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[On writing and selling science fiction stories (2018)]]>
            </title>
            <description>
<![CDATA[
Score 14 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24404555">thread link</a>) | @forrestbrazeal
<br/>
September 7, 2020 | https://forrestbrazeal.com/2018/11/08/on-writing-and-selling-science-fiction-stories/ | <a href="https://web.archive.org/web/*/https://forrestbrazeal.com/2018/11/08/on-writing-and-selling-science-fiction-stories/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <section>
          <section>
              

              
              
              <article>
                  

<p>Each year, I try to set a few personal goals that stretch me in some way.</p>

<p>In 2017, for example, I <a href="https://forrestbrazeal.com/2017/12/03/how-to-read-100-books-in-a-year-and-still-have-a-life/">read one hundred books</a>, which turned out to be more a test of endurance than skill.</p>

<p>This year, I decided to see if I could write a fictional short story and get it published somewhere. Though I do a fair amount of technical writing in the course of my work, I’d never seriously attempted to write and sell a short story before, or even taken a creative writing class.</p>

<p>This meant I had no knowledge of the market, no connections, and generally no idea what I was doing.</p>

<p>So, a challenge!</p>

<h2 id="goals">Goals</h2>

<p>I decided to focus on the <a href="https://en.wikipedia.org/wiki/Speculative_fiction">speculative fiction genre</a>, partly because it seemed more accessible and mostly because unlike literary journals, the best speculative fiction magazines still pay their authors.</p>

<p>My goals, in descending order of likelihood, were as follows:</p>

<ol>
<li><p>Get something published somewhere, even if unpaid</p></li>

<li><p>Get something published and get paid something for it, even a token amount</p></li>

<li><p>Get something published at <a href="https://www.sfwa.org/about/join-us/sfwa-membership-requirements/#short">Science Fiction Writers of America (SFWA) professional rates</a> (currently 6 cents a word)</p></li>

<li><p>Get at least 1000 words published at SFWA-qualifying markets (the standard for <a href="https://www.sfwa.org/about/join-us/sfwa-membership-requirements/#associate">SFWA associate member status</a>)</p></li>

<li><p>Get at least three stories published, totaling more than 10,000 words, at SFWA-qualifying professional markets (<a href="https://www.sfwa.org/about/join-us/sfwa-membership-requirements/#active">SFWA Active Member status</a>, my self-imposed standard for a legit “professional” science fiction writer)</p></li>
</ol>

<h2 id="results-through-nov-8">Results (through Nov. 8)</h2>

<p>After many form rejections on several terrible stories, I sold my <a href="https://dailysciencefiction.com/science-fiction/biotech/forrest-brazeal/memory-foam">first story</a> on March 23rd, 2018, to Daily Science Fiction (an SWFA pro market). At 1010 words, this sale actually crossed the first four goals off my list at once.</p>

<p>However, I continued to write and improve over the spring and summer of 2018, selling several more stories along the way, eventually totaling more than 16,000 words of fiction. Some publications have long wait times, but by the time “Empathy Bee” <a href="http://www.diabolicalplots.com/the-diabolical-plots-year-five-fiction-lineup/">is published</a> in March 2019, I should have the wordcount needed for active SFWA membership status, my most insane stretch goal.</p>

<h3 id="by-the-numbers">By the numbers</h3>

<ul>
<li><p>Stories Written: 22</p></li>

<li><p>Total Wordcount: ~60,000, the length of a medium-sized novel</p></li>

<li><p>Total Submissions: 70</p></li>

<li><p>Stories Sold: 8</p></li>

<li><p>SFWA-qualifying professional sales: 6</p></li>

<li><p>Rejections: 50 (15 personal)</p></li>

<li><p>Withdrawals: 2</p></li>

<li><p>Still Pending: 10</p></li>

<li><p>Other Results: <a href="https://www.writersofthefuture.com/writers-of-the-future-3rd-quarter-standings-for-year-35/">Honorable Mention, Writers of the Future</a></p></li>
</ul>

<h2 id="what-i-learned">What I Learned</h2>

<h3 id="have-no-ego">Have no ego</h3>

<p>It turns out writing short stories that sell is really, really hard. It’s hard to think of good ideas, it’s hard to write them down in a form that anyone would want to read, and it’s even harder when those readers are magazine editors who get literally hundreds of unsolicited submissions every month. Don’t attempt it if you have an easily bruised sense of self-worth, or you will be depressed a lot.</p>

<p>I’m grateful to have sold some stories this year, but my identity is not tied up in “being a writer”. It can’t be, because I have to…</p>

<h3 id="embrace-failure">Embrace failure</h3>

<p>I learned to view rejections as a badge of honor, which is a helpful mental trick to keep from going insane after a few dozen forms. As I told Jason Bougger in an <a href="http://www.themeofabsence.com/2018/11/author-interview-forrest-brazeal/">author interview</a> over at Theme of Absence, rejections are like the good soreness you feel after working out – it means you’re growing.</p>

<h3 id="keep-your-feedback-loop-short">Keep your feedback loop short</h3>

<p>Early on, when I was getting form rejections from big magazines with no accompanying feedback, I got really frustrated because I knew my work was obviously not up to par – I just didn’t know why. A submission to a smaller publication, Abyss and Apex (who I later ended up selling a different story to!) brought back a personalized rejection with a helpful piece of advice: try signing up for the <a href="https://sff.onlinewritingworkshop.com/">Online Writing Workshop</a>.</p>

<p>At the time I had never heard of writers’ workshops and didn’t really understand why they would be helpful. But I paid a few dollars and signed up. The other writers there provided generous feedback on how to improve my work, and I learned just as much from critiquing their pieces. The OWW membership more than paid for itself when several readers pointed out an obvious plot hole in my story “Empathy Bee”, which subsequently sold in revised form to Diabolical Plots.</p>

<p>Later, once I had professional credits, I was able to join the wonderful <a href="http://www.codexwriters.com/">Codex</a> writers’ community, which has hugely expanded my horizons and understanding of the industry. The more I write, the less I trust myself to be a good judge of my work’s quality, and the more I seek out and appreciate feedback from others.</p>

<h3 id="write-smart-not-just-hard">Write smart, not just hard</h3>

<p>Some writers recommend keeping insane writing regimens, cranking out thousands of words a day, saying it’s the only way to improve. And I wrote a fair amount this year. But stepping back and getting feedback on my work was just as important.</p>

<p>I had a music teacher who used to ask: “Did you practice ten hours, or just the same hour ten times?” When I took time to evaluate my work and deliberately build on it, I improved faster than just by vomiting words indiscriminately onto the page.</p>

<h3 id="keep-reading-good-prose">Keep reading good prose</h3>

<p>No, I didn’t read a hundred books again this year. But I did try to keep my ear filled with good prose. For example, this summer I got on a southern realist kick: Flannery O’Connor, Eudora Welty, Carson McCullers. Studying how those writers crafted characters and situations helped me nail down a couple of southern-set stories that ended up selling. My science fiction writing improved more from reading good writers, period, than from reading science fiction.</p>

<h3 id="just-because-you-wrote-something-good-enough-to-get-published-somewhere-that-doesn-t-mean-the-next-thing-you-write-won-t-be-terrible">Just because you wrote something good enough to get published somewhere, that doesn’t mean the next thing you write won’t be terrible</h3>

<p>This sounds stupid in hindsight, but for a long time I had it in my head that once I sold a story, I’d have figured out what it took to get published, and I wouldn’t have any trouble after that. Instead, I still get tons of rejections, and often my writing seems just as lifeless and terrible to me as it did before I sold my first story.</p>

<p>The good news is that with practice, the overall trend appears to be upward. At least, when I look back at my work from the beginning of the year, I can’t believe how bad it is. So I must be improving, right?</p>

<h2 id="what-s-next">What’s next?</h2>

<p>Like many people who start out in the short fiction game, I would love to publish a novel. So I think that might be a 2019 goal. But I’m sure I’ll continue to write short stories, too. There’s real satisfaction in creating something that you can hold in your head all at once, knowing how it will turn out and why it’s effective.</p>

<p><em>Some of the stories I sold this year are free to read online. You can check them out in my <a href="https://forrestbrazeal.com/bibliography/">bibliography</a></em></p>

              </article>
              <center>
              <p>
                      If you enjoy my articles, comics, and stories, why not sign up for the mailing list?
                  </p>
              
            </center>
              
          </section>
          <br>
          

      </section>

    </div></div>]]>
            </description>
            <link>https://forrestbrazeal.com/2018/11/08/on-writing-and-selling-science-fiction-stories/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24404555</guid>
            <pubDate>Tue, 08 Sep 2020 01:53:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Fast.ai and why Python is not the future of ML with Jeremy Howard]]>
            </title>
            <description>
<![CDATA[
Score 72 | Comments 107 (<a href="https://news.ycombinator.com/item?id=24404002">thread link</a>) | @tosh
<br/>
September 7, 2020 | https://www.wandb.com/podcast/jeremy-howard | <a href="https://web.archive.org/web/*/https://www.wandb.com/podcast/jeremy-howard">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Jeremy Howard is a founding researcher at fast.ai, a research institute dedicated to making Deep Learning more accessible. Previously, he was the CEO and Founder at Enlitic, an advanced machine learning company in San Francisco, California. </p><p>Howard is a faculty member at Singularity University, where he teaches data science. He is also a Young Global Leader with the World Economic Forum, and spoke at the World Economic Forum Annual Meeting 2014 on "Jobs For The Machines." </p><p>Howard advised Khosla Ventures as their Data Strategist, identifying the biggest opportunities for investing in data-driven startups and mentoring their portfolio companies to build data-driven businesses. Howard was the founding CEO of two successful Australian startups, FastMail and Optimal Decisions Group. Before that, he spent eight years in management consulting, at McKinsey &amp; Company and AT Kearney.</p><p><strong>TOPICS COVERED:</strong></p><p>0:00 Introduction</p><p>0:52 Dad things</p><p>2:40 The story of Fast.ai</p><p>4:57 How the courses have evolved over time</p><p>9:24 Jeremy’s top down approach to teaching</p><p>13:02 From Fast.ai the course to Fast.ai the library</p><p>15:08 Designing V2 of the library from the ground up</p><p>21:44 The ingenious type dispatch system that powers Fast.ai</p><p>25:52 Were you able to realize the vision behind v2 of the library</p><p>28:05 Is it important to you that Fast.ai is used by everyone in the world, beyond the context of learning</p><p>29:37 Real world applications of Fast.ai, including animal husbandry</p><p>35:08 Staying ahead of the new developments in the field</p><p>38:50 A bias towards learning by doing</p><p>40:02 What’s next for Fast.ai</p><p>40.35 Python is not the future of Machine Learning</p><p>43:58 One underrated aspect of machine learning</p><p>45:25 Biggest challenge of machine learning in the real world</p><p>Follow Jeremy on Twitter:</p><p><a href="https://twitter.com/jeremyphoward" target="_blank">https://twitter.com/jeremyphoward</a><br></p><p>Links:</p><p>Deep learning R&amp;D &amp; education: <a target="_blank" href="https://t.co/ZvDGNlehRt?amp=1">http://fast.ai</a></p><p>Software: <a target="_blank" href="https://t.co/GMYkPDXNW3?amp=1">http://docs.fast.ai</a></p><p>Book: <a target="_blank" href="https://t.co/1YSqXvWW87?amp=1">http://up.fm/book</a></p><p>Course: <a target="_blank" href="https://t.co/Q2qMl59EfH?amp=1">http://course.fast.ai</a></p><p>Papers:</p><p><a target="_blank" href="https://dl.acm.org/doi/10.1145/2487575.2491127"><strong>The business impact of deep learning</strong></a></p><p><a target="_blank" href="https://dl.acm.org/doi/10.1145/2487575.2491127">https://dl.acm.org/doi/10.1145/2487575.2491127</a></p><p><a target="_blank" href="https://www.linkedin.com/redir/redirect?url=http%3A%2F%2Fwww%2Ejmir%2Eorg%2F2012%2F1%2Fe33%2F&amp;amp;urlhash=gLU-&amp;trk=public_profile_publication-title"><strong>De-identification Methods for Open Health Data</strong></a></p><p><a href="https://www.jmir.org/2012/1/e33/">https://www.jmir.org/2012/1/e33/</a><br></p><p>Visit our podcasts homepage for transcripts and more episodes!</p><p><a target="_blank" href="https://www.wandb.com/podcast">www.wandb.com/podcast</a></p><p> Get our podcast on Soundcloud, Apple, and Spotify!</p><p>Soundcloud: <a target="_blank" href="https://bit.ly/2YnGjIq">https://bit.ly/2YnGjIq</a></p><p>Apple Podcasts: <a target="_blank" href="https://bit.ly/2WdrUvI">https://bit.ly/2WdrUvI</a></p><p>Spotify: <a target="_blank" href="https://bit.ly/2SqtadF">https://bit.ly/2SqtadF</a></p><p>We started Weights and Biases to build tools for Machine Learning practitioners because we care a lot about the impact that Machine Learning can have in the world and we love working in the trenches with the people building these models. One of the most fun things about these building tools has been the conversations with these ML practitioners and learning about the interesting things they’re working on. This process has been so fun that we wanted to open it up to the world in the form of our new podcast called Gradient Dissent. We hope you have as much fun listening to it as we had making it!</p><p>Weights and Biases:</p><p>We’re always free for academics and open source projects. Email carey@wandb.com with any questions or feature suggestions.</p><ul role="list"><li>Blog: <a target="_blank" href="https://www.wandb.com/articles">https://www.wandb.com/articles</a></li><li>Gallery: See what you can create with W&amp;B - <a target="_blank" href="https://app.wandb.ai/gallery">https://app.wandb.ai/gallery</a></li><li>Continue the conversation on our slack community - <a href="http://bit.ly/wandb-forum" target="_blank">http://bit.ly/wandb-forum</a><br></li></ul><p>Host: Lukas Biewald - <a href="https://twitter.com/l2k" target="_blank">https://twitter.com/l2k</a></p><p>Producer: Lavanya Shukla - <a href="https://twitter.com/lavanyaai" target="_blank">https://twitter.com/lavanyaai</a></p><p>TRANSCRIPT:</p><p><strong>Lukas: </strong>You're listening to Gradient Dissent, a show where we learn about making machine learning models work in the real world. I'm your host Lukas Biewald. Jeremy Howard created the Fast.ai course, which is maybe the most popular course to learn machine learning and there are a lot out there. He's also the author of the book Deep Learning for Coders with Fast.ai and PyTorch and in that process, he made the Fast.ai library which lots of people use independently to write deep learning. Before that, he was the CEO and co-founder of Enlitic, an exciting startup that applies deep learning to health care applications. And before that, he was the president of Kaggle, one of the most exciting earliest machine learning companies. I'm super excited to talk to him. So Jeremy, it's nice to talk to you. And in preparing the questions, I realized that every time I've talked to you there have been a few gems that I've remembered that I would never think to ask about. Like one time you told me about how you learned Chinese and another time you gave me Dad parenting advice, very specific advice and it's been actually super helpful. </p><p><strong>Jeremy: </strong>Oh great. Tell me what Dad parenting advice worked out?</p><p><strong>Lukas: </strong>Well, what you told me was when you change diapers, use a blow dryer to change a really frustrating experience to a really joyful experience and it's like such good advice. I don't know how you.. I guess I can imagine how you thought of it, but it's...</p><p><strong>Jeremy: </strong>Yeah, yeah, I know they love the whooshing sound, they love the warmth. I'm kind of obsessed about Dad things. So I'm always happy to talk about Dad things. That is this podcast.</p><p><strong>Lukas: </strong>Can we start with that? Now that my daughter is eight months old. Do you have any suggestions for her?</p><p><strong>Jeremy: </strong>Oh my goodness! Eight months old. You know, it's like the same with any kind of learning. It's all about consistency. So I think that the main thing we did right with Claire was just, you know, this delightful child now is we were just super consistent. Like if we said you can't have X unless you do Y, we would never give her X if she didn't do Y. If you want to take your scooter down to the bottom of the road, you have to carry it back up again. We read this great book that was saying if you're not consistent, it becomes like this thing, it's like a gambler. It's like sometimes you get the thing you want, so you just have to keep trying so that's my number one piece of advice. It's the same with teaching machine learning. We always tell people that tenacity is the most important thing for students. To stick with it, do it every day.</p><p><strong>Lukas: </strong>I guess just in the spirit of questions, I'm genuinely curious about, you know, you've built this amazing framework and teaching thing that I think is maybe the most popular and most appreciated framework. I was wondering if you could start by telling me the story of what inspired you to do that and what was the journey to making Fast.ai, the curriculum and Fast.ai, the ML framework.</p><p><strong>Jeremy: </strong>So it was something that my wife Rachel and I started together. Rachel has a math PhD, super technical background, early data scientist and engineer, Uber. I don't. I have just scraped by a philosophy undergrad and have no technical background. But from both of our different directions, we both had this frustration that neural networks in 2012 were super important, clearly going to change the world, but super inaccessible and so we would go to meetups and try to figure out like how do we... Like I knew the basic idea, I'd coded neural networks 20 years ago, but how do you make them really good? There wasn't any open source software at the time for running on GPUs. You know, Dan Seresen's thing was available, but you had to pay for it. There was no source code and we just thought, oh, we've got to change this, because the history of technology leaps has been that it generally increases inequality because the people with resources can access the new technology and then that leads to societal upheaval and a lot of unhappiness. So we thought, well, we should just do what we can. So we thought how are we going to fix this? Basically the goal was, and still is, to be able to use deep learning without requiring any code so that, you know, because the vast majority of the world can't code, we kind of thought, well, to get there, we should, first of all, see what exists right now? Learn how to use it as best as we can ourselves, teach people how to best use it as we can and then make it better, which requires doing research and then turning that into software and then changing the course to teach the hopefully slightly easier version and repeat that again and again for a few years. And so we're kind of in that process.</p><p><strong>Lukas: </strong>That's so interesting. Do you worry that the stuff you're teaching, you're sort of trying to make it obsolete, right? Because you're trying to build higher level abstractions? Like I think one of the things that people really appreciate your course is that it's really clear, in-depth explanations of how these things work. Do you think that that's eventually going to be not necessary or how do you think about that?</p><p><strong>Jeremy: </strong>Yeah, to some extent. I mean, so if you look at the new book and the new course, chapter one starts with really, really foundational stuff around what is a machine learning algorithm? What do we mean to learn an algorithm? What's the difference between traditional programming and machine learning to solve the same problem? And those kinds of basic foundations I think will always be useful, even at the point you're not using any code. I feel like even right now, if somebody is using like PlatformAI or some kind of code-free framework, you still need to understand these basics of an algorithm can only learn based on the data you provide. It's generally not going to be able to extrapolate to patterns it's not seen yet, stuff like that. Um, but yeah, I mean, we have so far released two new courses every year, you know, a part one and part two every year because every year, it's totally out of date. And we always say to our students at the start of part one, Look, you know, none of the details you're learning are going to be of any use in a year or two's time. There's a time when we're doing Piano and then TensorFlow and Keras, and then playing PyTorch. We always say, look, don't worry too much about the software we're using because none of it's still any good, you know, it's goal changing rapidly, you know, faster than JavaScript frameworks, but the concepts are important and yeah, you can pick up a new library and I don't know by weekend, I …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.wandb.com/podcast/jeremy-howard">https://www.wandb.com/podcast/jeremy-howard</a></em></p>]]>
            </description>
            <link>https://www.wandb.com/podcast/jeremy-howard</link>
            <guid isPermaLink="false">hacker-news-small-sites-24404002</guid>
            <pubDate>Tue, 08 Sep 2020 00:10:21 GMT</pubDate>
        </item>
    </channel>
</rss>
