<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 5]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 5. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Wed, 22 Jul 2020 16:17:24 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-5.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Wed, 22 Jul 2020 16:17:24 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[Monitoring your own infrastructure using Grafana, InfluxDB, and CollectD]]>
            </title>
            <description>
<![CDATA[
Score 21 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23906165">thread link</a>) | @crecker
<br/>
July 21, 2020 | https://serhack.me/articles/monitoring-infrastructure-grafana-influxdb-connectd/ | <a href="https://web.archive.org/web/*/https://serhack.me/articles/monitoring-infrastructure-grafana-influxdb-connectd/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><img src="https://serhack.me/images/grafana/all%20together%20now_wide.jpg" alt="Grafana, InfluxDB and CollectD"></p><h4 id="for-some-companies-infrastructure-is-the-heart-of-its-business-specifically-i-am-referring-to-those-companies-which-need-to-manage-data-and-applications-located-on-more-than-one-server">For some companies, infrastructure is the heart of its business. Specifically, I am referring to those companies which need to manage data and applications located on more than one server.</h4><p>It is essential for a company to monitor its infrastructure nodes, especially if the company does not have on-site access to intervene when issues arise. In fact, the intensive use of some resources can be an indication of malfunctioning or overcrowding. However, in addition to prevention, monitoring could be used to assess possible implications of new software in the production environment. Currently, there are several “ready-to-use” solutions on the market to keep track of all the resources consumed. These solutions, which appear reasonable, present two key problems: the high price of setup and security issues related to third parties.</p><p>The first problem is related to cost. Prices vary from 10 euros per month up to thousands depending on how many hosts you need to monitor — with the former being consumer pricing and the latter being enterprise pricing. So, for example, let’s imagine that I have three nodes to monitor during the course of a year. At 10 euros per month, I would spend 120 euros. For smaller enterprises, where the price can range between 10,000 and 20,000 euro per year, such an expense can bloat its underlying cost structure and become financially untenable.</p><p>The second problem is third party risk. Typically, infrastructure data must pass through a third party company in order to be seen and analysed for the customer — whether that be an individual consumer or an enterprise. How does the third party company capture the data and then present it to the customer? Simply put, the third party company often collects data through a custom agent that is installed onto a node and monitored. Quite often is it found that this installation is not up-to-date and compatible with operating systems. Previous work has been done by security researchers who cast light upon problems with <a href="https://www.rapid7.com/db/modules/exploit/linux/misc/nagios_nrpe_arguments">“proprietary collectors”</a>. Would you trust them? I would not.</p><p>In keeping nodes for both <a href="https://trac.torproject.org/projects/tor/wiki/TorRelayGuide">Tor</a> and some <a href="https://getmonero.org/">cryptocurrencies</a>, I prefer to opt for a cost free, easy to configure, and open-source alternative. Here, we will use the triad: Grafana, InfluxDB, and CollectD.</p><p><img src="https://serhack.me/images/grafana/grafana-graphs.png" alt="An example of a Grafana dashboard"></p><h2 id="monitoring">Monitoring</h2><p>In order to be able to analyse every metric of our infrastructure, it is necessary to use a program capable of capturing statistics on the machines we want to monitor. In this regard, <a href="https://collectd.org/">CollectD</a> comes to your aid: it is a daemon that groups and collects (hence the name) all the parameters that can be stored on disk or sent over the network.</p><p>The data will be transmitted to an instance of <a href="https://www.influxdata.com/">InfluxDB</a>: a particular time series database that associates to each data the time (coded in UNIX timestamp) in which the server received it. In this way, the data sent by CollectD will already be set in a temporal way, as a succession of events.</p><p>Finally, you will use <a href="http://grafana.org/">Grafana</a> which will connect to InfluxDB to create flashy dashboards to display the data in a user-friendly way. Through histograms and graphs of every kind, it will be possible to observe in real time all the data related to CPU, RAM, etc.</p><p><img src="https://serhack.me/images/grafana/grafana-diagram.png" alt="Grafana infrastructure"></p><h2 id="influxdb">InfluxDB</h2><picture>
<source media="(min-width: 535px)" data-original-set="/images/grafana/db_alone.jpg 1x,
                /images/grafana/db_alone_wide.jpg 2x"><source media="(max-width: 534px)" data-original-set="/images/grafana/db_alone.jpg 1x,
                /images/grafana/db_alone.jpg 2x" src-set="/images/grafana/db_alone.jpg 1x,
                /images/grafana/db_alone.jpg 2x"><img data-original="/images/grafana/db_alone.jpg" data-original-set="/images/grafana/db_alone_wide.jpg 2x" src="https://serhack.me/images/grafana/db_alone_wide.jpg" alt=""></picture><p>Let’s start with InfluxDB, which is the beating heart of our monitoring “system”. InfluxDB is a time series database <a href="https://github.com/influxdata/influxdb">open-source</a> developed in <a href="https://golang.org/">Go</a> to store data as a sequence of events.</p><p>Each time data is added, it is linked to <a href="https://en.wikipedia.org/wiki/Unix_time">a UNIX timestamp</a> by default. This allows enormous flexibility for the user who no longer has to worry about saving, as an example, the “time” variable, which is sometimes cumbersome to configure. Let’s imagine we have several machines located in a number of continents. How do we manage the “time” variable? Do we use the <a href="https://en.wikipedia.org/wiki/Greenwich_Mean_Time">Greenwich</a> meridian for all the data? Or do we set a different time zone for each node? If data is saved on different time zones, how can we accurately display the graphs? As you can see, this can be very complicated.</p><p>As a time-aware database that automatically timestamps any data point, InfluxDB has the advantage of simultaneously being able to write to a certain database. This is why we often imagine InfluxDB as a timeline. Writing data does not affect the performance of the database (as sometimes happens in MySQL), since writing is simply the addition of a certain event to the timeline. The name of the program derives precisely from the conception of time as an infinite and indefinite “flow” that flows.</p><h3 id="installation-and-configuration">Installation and configuration</h3><p>Another advantage of InflxuDB is the <a href="https://docs.influxdata.com/influxdb/v1.8/introduction/install/">ease of installation</a> and the extensive <a href="https://docs.influxdata.com/">documentation</a> provided by the community that widely supports the project. It has two types of interfaces: via <a href="https://docs.influxdata.com/influxdb/v1.8/tools/shell/">Command Line</a> (which is powerful and flexible for developers, but poorly prepared to see large amounts of data) and an <a href="https://docs.influxdata.com/influxdb/v1.8/guides/write_data/#sidebar">HTTP API</a> that allows direct communication with the database.</p><p>InfluxDB can be downloaded not only from the official website, but also from the package manager of the distribution (in this example we use a Debian system). It is advisable to check the package via GPG before installation, so (below) we import the keys of the InfluxDB package:</p><div><pre><code data-lang="bash"><a href="https://serhack.me/cdn-cgi/l/email-protection" data-cfemail="86f4e9e9f2c6e8e9e2e3">[email&nbsp;protected]</a>#~: curl -sL https://repos.influxdata.com/influxdb.key | sudo apt-key add -
<a href="https://serhack.me/cdn-cgi/l/email-protection" data-cfemail="c8baa7a7bc88a6a7acad">[email&nbsp;protected]</a>#~: source /etc/os-release
<a href="https://serhack.me/cdn-cgi/l/email-protection" data-cfemail="9ceef3f3e8dcf2f3f8f9">[email&nbsp;protected]</a>#~: echo <span>"deb https://repos.influxdata.com/debian </span><span>$(</span>lsb_release -cs<span>)</span><span> stable"</span> | sudo tee /etc/apt/sources.list.d/influxdb.list</code></pre></div><p>Finally, we update and install InfluxDB:</p><p>To start it, we use <code>systemctl</code>:</p><p>To make sure that no one nefarious enters, we create the user “administrator”. InfluxDB uses a particular query language called <a href="https://docs.influxdata.com/influxdb/v1.8/query_language/">“InfluxQL”</a>, similar to SQL, which allows you to interact with the database. To create a new entry, we use the query <a href="https://docs.influxdata.com/influxdb/v1.8/administration/authentication_and_authorization/#user-management-commands"><code>CREATE USER</code></a>.</p><div><pre><code data-lang="bash"><a href="https://serhack.me/cdn-cgi/l/email-protection" data-cfemail="45372a2a31052b2a2120">[email&nbsp;protected]</a>#~: influx
Connected to http://localhost:8086
InfluxDB shell version: x.y.z
&gt;
&gt; CREATE USER admin WITH PASSWORD <span>'MYPASSISCOOL'</span> WITH ALL PRIVILEGES</code></pre></div><p>From the same CLI interface, we create the “metrics” database that will be used as a container for our metrics.</p><div><pre><code data-lang="bash">&gt; CREATE DATABASE metrics</code></pre></div><p>Next, let’s modify the configuration of InfluxDB (<code>/etc/influxdb/influxdb.conf</code>) to have the interface open on port <strong>24589</strong> (UDP) with direct connection to the database named “metrics” in support of CollectD. You also need to download and place the <a href="https://raw.githubusercontent.com/collectd/collectd/master/src/types.db">types.db</a> file in <code>/usr/share/collectd/</code> (or any other folder) to define the data that <a href="https://docs.influxdata.com/influxdb/v1.8/supported_protocols/collectd/">CollectD sends in native format</a>.</p><div><pre><code data-lang="bash"><a href="https://serhack.me/cdn-cgi/l/email-protection" data-cfemail="c3b1acacb783adaca7a6">[email&nbsp;protected]</a>#~: nano /etc/influxdb/influxdb.conf
<span>[</span>Collectd<span>]</span>
enabled <span>=</span> true
bind-address <span>=</span> <span>":24589"</span>
database <span>=</span> <span>"metrics"</span>
typesdb <span>=</span> <span>"/usr/share/collectd/types.db"</span></code></pre></div><p>For further information on the CollectD block within the configuration, see the <a href="https://docs.influxdata.com/influxdb/v1.8/administration/config/#collectd-settings">reference to documentation</a>.</p><h2 id="collectd">CollectD</h2><picture>
<source media="(min-width: 535px)" data-original-set="/images/grafana/daemon_alone.jpg 1x,
                /images/grafana/daemon_alone_wide.jpg 2x"><source media="(max-width: 534px)" data-original-set="/images/grafana/daemon_alone.jpg 1x,
                /images/grafana/daemon_alone.jpg 2x" src-set="/images/grafana/daemon_alone.jpg 1x,
                /images/grafana/daemon_alone.jpg 2x"><img data-original="/images/grafana/daemon_alone.jpg" data-original-set="/images/grafana/daemon_alone_wide.jpg 2x" src="https://serhack.me/images/grafana/daemon_alone_wide.jpg" alt=""></picture><p>CollectD is a data aggregator, in our monitoring infrastructure, that facilitates the transmission of data to InfluxDB. By default, CollectD captures metrics on CPU, RAM, memory (on disk), network interfaces, processes, etc. The potential of the program is endless, given that it can be extended with a preinstalled <a href="https://collectd.org/wiki/index.php/Table_of_Plugins">plugin enablement</a> or through the <a href="https://collectd.org/wiki/index.php/Roadmap#Wishlist_.2F_Ideas">creation of new ones</a>.</p><p>As you can see, installing CollectD is simple:</p><p>In a simplistic manner, let’s illustrate how CollectD works. Suppose that I want to check how many processes my node has. In doing so, CollectD does nothing more than make an API call to get the number of processes per time unit (defined as 5000 ms, by default). Once captured, the data will be sent to InfluxDB via a module (called “Network”) to be configured.</p><p>Open the file <code>/etc/collectd.conf</code> with our editor, scroll to find the <code>Network</code> section, and edit as written in the following snippet. Be sure to specify the IP where the interface of InfluxDB (<code>INFLUXDB_IP</code>) is located.</p><div><pre><code data-lang="bash"><a href="https://serhack.me/cdn-cgi/l/email-protection" data-cfemail="6b1904041f2b05040f0e">[email&nbsp;protected]</a>#~: nano /etc/collectd.conf
    ...
&lt;Plugin network&gt;
  &lt;Server <span>"INFLUXDB_IP"</span> <span>"24589"</span>&gt;
  &lt;/Server&gt;
  ReportStats true
&lt;/Plugin&gt;
    ...</code></pre></div><p>My suggestion is to modify, within the configuration, the hostname that is sent to InfluxDB (which in our infrastructure is a “centralized” database, since it resides on a single node). In doing so, the data will not be redundant and there is no risk that other nodes will overwrite the information.</p><p><img src="https://serhack.me/images/grafana/tres_caballeros.jpg" alt="Three daemon"></p><h2 id="grafana">Grafana</h2><p><img src="https://serhack.me/images/grafana/grafana_alone.jpg" alt=""></p><blockquote><p>A graph is worth thousand of images</p></blockquote><p>In remembrance of this famous “quote”, observing the infrastructure metrics live through graphs and tables enables us to act in an efficient and timely manner. To create and configure the dashboard, we will use Grafana.</p><p>Grafana is an open-source tool, compatible with a wide range of databases (including InfluxDB), that presents a graphical representation of metrics and allows a user to create alerts if a particular piece of data meets a condition. For example, if your CPU reaches high peaks, you can be notified on Slack, Mattermost, by email, etc. In fact, I have personally configured an alert every time someone enters SSH, so I can actively monitor who “enters” my infrastructure.</p><p>Grafana does not require any special settings: once again, it is InfluxDB that “scans” the “time” variable. The integration is simple. Let’s start by import the public key to add the package from the <a href="https://grafana.com/grafana/download">Grafana official website</a> (it depends on the OS you are using):</p><div><pre><code data-lang="bash"><a href="https://serhack.me/cdn-cgi/l/email-protection" data-cfemail="691b06061d2907060d0c">[email&nbsp;protected]</a>#~: wget -q -O - https://packages.grafana.com/gpg.key | sudo apt-key add -
<a href="https://serhack.me/cdn-cgi/l/email-protection" data-cfemail="11637e7e65517f7e7574">[email&nbsp;protected]</a>#~: echo <span>"deb https://packages.grafana.com/oss/deb stable main"</span> | sudo tee -a /etc/apt/sources.list.d/grafana.list 
<a href="https://serhack.me/cdn-cgi/l/email-protection" data-cfemail="6f1d00001b2f01000b0a">[email&nbsp;protected]</a>#~: apt-get update <span>&amp;&amp;</span> apt-get install grafana</code></pre></div><p>Let’s start it through systemctl:</p><p>Next, as we go to the localhost:3000 page through the browser, we should be presented with a login interface for Grafana. By default, you should use <strong>admin</strong> as username and <strong>admin</strong> as password (it is advisable to change the password after the first login).</p><p><img src="https://serhack.me/images/grafana/login-page.png" alt="Login page"></p><p>Let’s go to Sources and add our Influx database:</p><p><img src="https://serhack.me/images/grafana/add-data-source.png" alt="Add data source to Grafana"></p><p><img src="https://serhack.me/images/grafana/influxdb.png" alt="InfluxDB"></p><p>The screen now shows a small green rectangle just below the New Dashboard. Hover your mouse over this rectangle and select Add Panel, then Graph:</p><p><img src="https://serhack.me/images/grafana/add-new-panel.png" alt="Add a new panel"></p><p>A graph with the test data is now shown. Click on the title of this chart and choose Edit. Grafana allows the writing of …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://serhack.me/articles/monitoring-infrastructure-grafana-influxdb-connectd/">https://serhack.me/articles/monitoring-infrastructure-grafana-influxdb-connectd/</a></em></p>]]>
            </description>
            <link>https://serhack.me/articles/monitoring-infrastructure-grafana-influxdb-connectd/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23906165</guid>
            <pubDate>Tue, 21 Jul 2020 12:02:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Presentation: The Technical Evolution of Mailinator.com]]>
            </title>
            <description>
<![CDATA[
Score 9 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23906102">thread link</a>) | @zinxq
<br/>
July 21, 2020 | https://manybrain.github.io/m8r_blog/blog/mailinator-evolution/ | <a href="https://web.archive.org/web/*/https://manybrain.github.io/m8r_blog/blog/mailinator-evolution/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p>Mailinator started 17 years ago as a weekend project to define the idea of “Free, Disposable, Email”. Back then, it ran on a single server with only a single developer. Over time, it’s popularity has exploded in terms of both incoming email and active users. As you might guess when you go from thousands of emails-per-day to <strong>thousands of emails-per-second</strong>, the behind-the-scenes technical stack needs to evolve - and Mailinator’s stack has had a quite a technical journey.</p>
<p><img src="https://manybrain.github.io/m8r_blog/img/2020/07/image1.png" alt="Slide showing beginning and end tech evolution for Mailinator.com"></p>
<p>Today Mailinator still provides free, disposable, email - but also serves thousands of daily corporate users in testing their Email and SMS Workflows with an API, Webhooks, and Private Domains. Website owners quickly realized that having an infinite number of inboxes “on tap” was incredibly useful for testing things their like their Signup system, Marketing email systems, and more. Quality Assurance teams found it to be an invaluable tool.</p>
<p>In February 2020, Mailinator’s creator Paul Tyma gave a talk on the “Technical Evolution of Mailinator.com”. Below you can find a link to the slides and watch the video. The talk explores the site’s journey from a “Free, Disposable, Email” to a becoming SaaS service helping thousands of companies test their Email and SMS Workflows (and of course, scaling a system to tens of millions of emails per day).</p>
<p><a href="https://drive.google.com/file/d/1HV8BZUPBp4HT5C8Ob3rMXCWhSo5F9oRa/view?usp=sharing">GET THE SLIDES HERE</a></p>

<p>
  <iframe src="https://www.youtube.com/embed/BqNfHsZ3QUc" allowfullscreen="" title="YouTube Video"></iframe>
</p>


  </div></div>]]>
            </description>
            <link>https://manybrain.github.io/m8r_blog/blog/mailinator-evolution/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23906102</guid>
            <pubDate>Tue, 21 Jul 2020 11:44:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Pine64’s $199.99 14 inch Pine Pro laptop now available for pre-order]]>
            </title>
            <description>
<![CDATA[
Score 12 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23905298">thread link</a>) | @darshansavla
<br/>
July 21, 2020 | https://androidrookies.com/pine64s-199-99-14-inch-pine-pro-laptop-with-arm-chip-and-manjaro-linux-distro-now-available-for-pre-order/ | <a href="https://web.archive.org/web/*/https://androidrookies.com/pine64s-199-99-14-inch-pine-pro-laptop-with-arm-chip-and-manjaro-linux-distro-now-available-for-pre-order/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-9147"><div><div><div><h2>Pine64’s $199.99 14 inch Pine Pro Linux laptop with 64-bit ARM chip and Manjaro Linux distro now available for pre-order</h2><p>If you are a Linux fanboi, you shouldn’t miss this one. <a href="https://androidrookies.com/pine64-launches-the-cheapest-linux-tablet-ever-priced-at-just-99-99/">Pine64</a>, the makers of Linux based laptops have reopened their pre-order window for the 14.1 inch ARM-based Linux laptop Pinebook Pro. Pine64 had last opened the pre-order window in March 2020 and If you missed placing an order last time, you now have another chance to grab $199.99 Pinebook Pro.</p><p>PINE64 has <a href="https://www.pine64.org/2020/07/20/pinebook-pro-pre-orders-open-with-shipping-in-august-2020/" target="_blank" rel="noreferrer noopener nofollow" aria-label="undefined (opens in a new tab)">started</a> to take the next batch of pre-orders for Pinebook Pro. The pre-order has both the ISO and ANSI keyboard versions of Pinebook Pro and is available for order from their official website <a href="https://store.pine64.org/product/14%e2%80%b3-pinebook-pro-linux-laptop-ansi-us-keyboard-estimated-dispatch-in-december-2019/" target="_blank" rel="noreferrer noopener">here</a>. Both ANSI and ISO keyboard editions cost <strong>$199.99</strong><strong>&nbsp;excluding the shipping charges</strong>. Pine64 says that it will deliver the laptops by late August 2020.</p><h2>14.1 inch Pine Pro Linux Laptop specifications</h2><p>The Pine Pro Linux laptop comes with a 14.1 IPS inch screen giving a resolution of 1920 x 1080. It is powered by the 64-bit dual-core ARM 1.8GHz Cortex A72 and Quad-Core ARM 1.4GHz Cortex A53 processor and a Mali T-860 GPU. It runs on 4GB of LPDDR4 RAM and has 64GB of eMMC 5.0 of internal storage. You can extend the memory with external MicroSD card.</p><p>For connectivity, the Pine Pro laptop comes with WiFi 802.11AC + Bluetooth 5.0. It has one 3.5 mm headphone jack, one USB 3.0 and one USB 2.0 Type-A host port. On top of that, Pinebook also has USB 3.0 Type-C ports with alt-mode display out (DP 1.2). Using this USB-C port, you can connect your existing Linux laptops or <a href="https://androidrookies.com/pine64-launches-the-cheapest-linux-tablet-ever-priced-at-just-99-99/" target="_blank" rel="noreferrer noopener" aria-label="undefined (opens in a new tab)">PineTab.</a> The laptop comes with a Multi-Touch Touchpad and has a 10000 mAH battery. The Pine Pro laptop has a 2MP front camera which doesn’t seem like much. The product comes with a 30-day warranty and the makers warn of small numbers (1-3) of stuck or dead pixels on Pine Pro laptop LCD screens. The makers say these are normal and should not be considered a defect</p><p>Pine Pro laptop runs on Manjaro Linux distro by default. However, if you don’t like Manjaro Linux you can install other Linux distributions such as Debian and Fedora Linux. You can check out the supported Pine Pro laptop supported distros <a href="https://wiki.pine64.org/index.php/Pinebook_Pro_Software_Release" target="_blank" rel="noreferrer noopener nofollow" aria-label="undefined (opens in a new tab)">here.</a></p></div></div></div></article></div>]]>
            </description>
            <link>https://androidrookies.com/pine64s-199-99-14-inch-pine-pro-laptop-with-arm-chip-and-manjaro-linux-distro-now-available-for-pre-order/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23905298</guid>
            <pubDate>Tue, 21 Jul 2020 08:44:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Invert, Always, Invert]]>
            </title>
            <description>
<![CDATA[
Score 146 | Comments 38 (<a href="https://news.ycombinator.com/item?id=23905221">thread link</a>) | @anupj
<br/>
July 21, 2020 | https://www.anup.io/2020/07/20/invert-always-invert/ | <a href="https://web.archive.org/web/*/https://www.anup.io/2020/07/20/invert-always-invert/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            

            <figure>
                <img srcset="https://www.anup.io/content/images/size/w300/2020/07/nine-kopfer-tJC6I9S3nBw-unsplash.jpg 300w,
                            https://www.anup.io/content/images/size/w600/2020/07/nine-kopfer-tJC6I9S3nBw-unsplash.jpg 600w,
                            https://www.anup.io/content/images/size/w1000/2020/07/nine-kopfer-tJC6I9S3nBw-unsplash.jpg 1000w,
                            https://www.anup.io/content/images/size/w2000/2020/07/nine-kopfer-tJC6I9S3nBw-unsplash.jpg 2000w" sizes="(max-width: 800px) 400px,
                        (max-width: 1170px) 1170px,
                            2000px" src="https://www.anup.io/content/images/size/w2000/2020/07/nine-kopfer-tJC6I9S3nBw-unsplash.jpg" alt="Invert,  always, invert">
            </figure>

            <section>
                <div>
                    <blockquote>man muss immer umkehren - Carl Gustav Jacob Jacobi</blockquote><p>(loosely translated - Invert, always, invert)</p><p>Today, we will look at one of my favourite mental models called - The<strong><em> Inversion principle</em></strong>. <a href="https://fs.blog/mental-models/#what_are_mental_models">Mental models</a> are a set of simple, abstract but useful principles that help us make sense of the world around us.</p><p>I came across the Inversion principle on the <a href="https://fs.blog/2013/10/inversion/">Farnam Street blog</a>. It is also a favourite of Charlie Munger (Vice Chairman of Berkshire Hathaway and Warren Buffets mate) - "...it is in the nature of things that many hard problems are best solved when they are addressed backward", he pontificates.</p><p>In another interview, he recalls how, as an Air Force meteorologist during World War II, instead of asking what would keep pilots safe, he asked what would kill them and focussed all his efforts "on trying to predict snow, ice or fog—and to ignore pretty much everything else.".</p><p>I could write a book on all the other cool stuff Charlie Munger has said so I'll stop here.</p><h3 id="what-is-it">What is it?</h3><p>Inversion is based on the maxim - invert, always, invert. It is about considering an inverse (usually a negative) outcome and listing the reasons for these. It forces you to either stop doing certain things or avoid the actions that lead to the negative outcomes. It gives us <em><em>new possibilities</em> and capabilities</em> that we might not have considered otherwise.</p><p>The algorithm for inversion is very simple:</p><ul><li><strong>Define the problem</strong> - what is it that &nbsp;you're trying to achieve?</li><li><strong>Invert it </strong>- what would guarantee the failure to achieve this outcome?</li><li>Finally, <strong>consider solutions to avoid this failure</strong></li></ul><p>This is very abstract and vague, so let's look at a few examples:</p><ol><li>Instead of asking how do we increase the adoption of a product or feature? You could instead consider - what are some of things preventing adoption? This would lead to a list like this that you could potentially fix:</li></ol><ul><li>Slow load time i.e. performance issues</li><li>Not enough marketing, or marketing on the platform, or to the wrong audience</li><li>The user guide instructions are not clear ... you get the idea</li></ul><p>2. &nbsp;Following the inversion principle it is <em>better to ask</em> what is preventing me from reading all the unread books on my kindle/bookshelf, instead of asking how can i read more books? Possible reasons and something you could give up:</p><ul><li>I spend a lot of time on social media</li><li>I watch too many shows on Netflix or Disney +</li><li>Spend a lot of time on reddit or browsing hacker news</li></ul><p>3. Instead of wondering how do I always choose a winning stock during investing, ask yourself how do you prevent losses in the long term?</p><ul><li>Am I diversifying enough to prevent long term loss?</li><li>Am I investing &nbsp;based on sound principles, or am I speculating? </li></ul><p>Hopefully this &nbsp;gives you a flavour of how powerful inversion is as a mental model. I should add that it is NOT a silver bullet and it won't always give you concrete answers, but it will act as a forcing function to avoid obvious lapses in judgment. I'll leave you with another one of my favourite quotes about Inversion from Charlie.</p><blockquote>"It is remarkable how much long-term advantage people like us have gotten by trying to be consistently not stupid, instead of trying to be very intelligent."</blockquote><hr><p>Further reading:</p><figure><blockquote><a href="https://fs.blog/2014/06/avoiding-stupidity/">Avoiding Stupidity is Easier than Seeking Brilliance</a></blockquote>
</figure><figure><a href="https://commoncog.com/blog/putting-mental-models-to-practice-part-3-better-trial-and-error/"><div><p>Putting Mental Models to Practice Part 3: Better Trial and Error</p><p>Instrumental rationality is the sort of thinking that allows you to achieve your goals. We take a closer look at what decision science says is the ‘best’ way to pursue this purpose.</p><p><img src="https://commoncog.com/blog/favicon.png"><span>Commonplace - The Commoncog Blog</span></p></div><p><img src="https://commoncog.com/blog/content/images/2018/12/burst-530182-unsplash--1-.jpg"></p></a></figure><p>Thanks for taking the time to read this post, if you found it useful and if you have any comments or more tips, please hit me up on twitter (@<a href="https://twitter.com/anup">anup</a>).</p>
                </div>
            </section>

                <section>
    <h3>Subscribe to Anup Jadhav</h3>
    <p>Get the latest posts delivered right to your inbox</p>
    <form data-members-form="subscribe">
        
        <p><strong>Great!</strong> Check your inbox and click the link to confirm your subscription.
        </p>
        <p>
            Please enter a valid email address!
        </p>
    </form>
</section>

        </article>

    </div>
</div></div>]]>
            </description>
            <link>https://www.anup.io/2020/07/20/invert-always-invert/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23905221</guid>
            <pubDate>Tue, 21 Jul 2020 08:23:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Brick Block – by Oskar Stålberg (desktop only)]]>
            </title>
            <description>
<![CDATA[
Score 108 | Comments 15 (<a href="https://news.ycombinator.com/item?id=23904991">thread link</a>) | @thdrdt
<br/>
July 21, 2020 | http://oskarstalberg.com/game/house/index.html | <a href="https://web.archive.org/web/*/http://oskarstalberg.com/game/house/index.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
  
    <canvas id="canvas" oncontextmenu="event.preventDefault()" height="100%" width="100%"></canvas>
	<div id="loadingBox">
	  
	  
	  <p id="loadingInfo">Loading...</p>
	</div>
		
    


  

</div>]]>
            </description>
            <link>http://oskarstalberg.com/game/house/index.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23904991</guid>
            <pubDate>Tue, 21 Jul 2020 07:28:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Dynamic RBAC with zero performance overhead in Hopsworks]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23904812">thread link</a>) | @jamesblonde
<br/>
July 20, 2020 | https://www.logicalclocks.com/blog/how-we-secure-your-data-with-hopsworks | <a href="https://web.archive.org/web/*/https://www.logicalclocks.com/blog/how-we-secure-your-data-with-hopsworks">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><div><div><p>TLDR; Feature stores are the new cool kids in the neighbourhood of Data engineering and AI (artificial intelligence). Hyperscale&nbsp; AI companies (such as Uber, Netflix) have <a href="http://www.featurestore.org/">built their own feature stores</a> to solve the problems of reusing, governing and securing access to features (data for AI) in a shared platform. Hopsworks is a modular open-source platform, developed by Logical Clocks, for managing data for AI (a standalone Feature Store), computing features (Spark, Python), and training models. In this post, we introduce the project-based multi-tenancy security model in Hopsworks for users, data, and programs. We describe how our project-based multi-tenant security model is, in effect, a form of dynamic role-based access control with zero performance overhead.</p><figure id="w-node-591b61e7aa1b-87a4da24"><p><img src="https://uploads-ssl.webflow.com/5e6f7cd3ee7f51ec3ea4da0f/5f10585a943c7738c589d3c5_Screenshot%202020-07-16%20at%2015.38.14.png" alt=""></p></figure><p><a href="https://www.logicalclocks.com/blog/introducing-hopsworks-ai">Hopsworks.ai</a> is a SaaS version of Hopsworks, currently available on AWS. Hopsworks clusters can be run with an IAM profile, providing them with an identity in AWS with permission policies that capture what operations the Hopsworks cluster is authorized to perform in AWS - such as read/write data in S3 buckets. Hopsworks can also be used from Data Science and Feature Engineering platforms (Databricks, Sagemaker, KubeFlow, EMR) using API keys exported from Hopsworks.</p><p>This post is concerned primarily with the internal security model in Hopsworks that enables you to host sensitive data in a shared cluster, providing powerful access control and self-service capabilities. The benefit of Hopsworks project-based multi-tenancy model is that you can host many users and feature stores (and other projects) on a single cluster, with self-service access to different feature stores. The advantage of our security model is that you can host production, staging, and development feature stores in a single cluster - you do not need to manage and pay for separate clusters.&nbsp;</p><p><a href="https://en.wikipedia.org/wiki/Role-based_access_control#:~:text=Role%2Dbased%20access%20control%20(RBAC)%20is%20a%20policy%2D,simple%20to%20perform%20user%20assignments.">Role-based access control</a> (RBAC) is a well-known security model that enables administrators to give a group of users the same access rights to selected resources. With roles, an administrator at a company could define a single security policy and apply it to all members of a department. But individuals may be members of multiple departments, so a user might be given multiple roles. <a href="https://link.springer.com/chapter/10.1007/978-3-540-85776-1_17">Dynamic role-based access control</a> means that, based on some other policy, you can change the set of roles a user can hold at a given time. For example, if a user has two different roles - one for accessing banking data and another one for accessing trading data, with dynamic RBAC, you could restrict the user to only allow her to hold one of those roles at a given time. The policy for deciding which role the user holds could, for example, depend on what VPN (virtual private network) the user is logged in to or what building the user is present in. In effect, dynamic roles would allow to hold only one of the roles at a time and sandbox her inside one of the domains - banking or trading. It would prevent her from cross-linking or copying data between the different trading and banking domains.</p><p>Hopsworks implements a dynamic role-based access control model through a project-based <strong>multi-tenant security model. </strong>Inspired by GDPR, in Hopsworks a <em>Project </em>is a sandboxed set of users, data, and programs (where data can be shared in a controlled manner between projects). Every Project has an <strong>owner</strong> with full read-write privileges and zero or more <strong>members</strong>.&nbsp;</p><p>A project owner may invite other users to his/her project as either a <strong>Data Scientist </strong>(read-only privileges and run jobs privileges) or <strong>Data Owner</strong> (full privileges). Users can be members of (or own) multiple Projects, but inside each project, each member (user) has a unique identity - we call it a <em>project-user identity</em>.&nbsp; For example, user <em>Alice</em> in <em>Project A</em> is different from user <em>Alice </em>in <em>Project B - </em>(in fact, the system-wide (project-user) identities are <strong><em>ProjectA__Alice</em></strong> and <strong><em>ProjectB__Alice</em></strong>, respectively)<em>. </em>As such, each project-user identity is effectively a role with the project-level privileges to access data and run programs inside that project. If a user is a member of multiple projects, she has, in effect, multiple possible roles, but only one role can be active at a time when performing an action inside Hopsworks. When a user performs an action (for example, runs a program) it will be executed with the project-user identity. That is, the action will only have the privileges associated with that project. The figure below illustrates how Alice has a different identity for each of the two projects (A and B) that she is a member of. Each project contains its own separate private assets. Alice can use only one identity at a time which guarantees that she can’t access assets from both projects at the same time.<br></p><figure id="w-node-20ac5438fa1d-87a4da24"><p><img src="https://uploads-ssl.webflow.com/5e6f7cd3ee7f51ec3ea4da0f/5f1058b3943c77358489d4b1_Screenshot%202020-07-16%20at%2015.39.44.png" alt=""></p></figure><p>An <strong>important </strong>aspect of Project based multi-tenancy is that assets can be shared between projects - sharing does not mean that data is duplicated. The current assets that can be shared between projects are: files/directories in HopsFS, Hive databases, feature stores, and Kafka topics. For example, in the figure below there are three users (User1, User2, and User3)&nbsp; and two projects (A and B). User1 is a member of project A, while User2 and User3 are members of project B. All three users (User1, User2, User3) can access the assets shared between project A and project B. As sharing does not mean copying, the access control rules for the asset are updated to give users in the other project read or write permissions on the shared asset.</p><figure id="w-node-7c5391a82675-87a4da24"><p><img src="https://uploads-ssl.webflow.com/5e6f7cd3ee7f51ec3ea4da0f/5f1059150895622a73e57f16_Screenshot%202020-07-16%20at%2015.40.47.png" alt=""></p></figure><p>As we will see later on, <em>project-user identity</em> is based on a X.509 certificate issued internally by Hopsworks. Access control policies, however, are implemented by the platform services:<br></p><ul role="list"><li>files/directories permissions for HopsFS, Hive (storage-based security policy), and the offline Feature Store;</li><li>Kafka ACLs using a <a href="https://github.com/logicalclocks/hops-kafka-authorizer">Hopsworks project-based authorizer plugin</a>;</li><li>Elasticsearch Open Distro permissions using a <a href="https://github.com/logicalclocks/elasticsearch-chef">Hopsworks project-based authorizer plugin</a>.</li></ul><h3>User Identity in Hopsworks</h3><p>When a user authenticates with Hopsworks, they are logged into the platform with a <em>Hopsworks user identity</em>. This user identity is needed to be able to construct the project-user identity - it is the “user” part of the project-user identity. In Hopsworks, a user-identity is mapped to a global Hopsworks role (independent of project membership) - a <strong>normal</strong> user or an <strong>administrator</strong>. A normal user can search for assets, update her profile, generate API keys, and change to/from projects. Administrators have access to user, project, storage, and application management pages, system monitoring and maintenance services. They can activate or block users, delete Projects, manage Project quotas, promote normal users to administrators, and so on. It’s important to mention here that a Hopsworks administrator <strong>cannot</strong> view the data&nbsp; inside a project - even if they are allowed to delete a project.<br></p><p>A user interacts with Hopsworks through the web application and they don’t necessarily realize that the web application is a facade to a modular distributed system. In the background we run <strong>HopsFS</strong> - our next-generation HDFS-on-S3 filesystem, <strong>HopsYARN</strong> - a cluster management system and scheduler, Apache Hive, Elasticsearch, (optionally Kafka and Airflow), and other logging and monitoring services.</p><p>A fundamental principle in every distributed system is that processes exchange messages over the network or through shared state (such as a filesystem or database). When communication is performed by message passing, it is imperative that we protect the messages from adversaries reading or modifying their content and validate the identity of the caller. Traditionally in Hadoop, they use Kerberos and GSSAPI to authenticate and authorize users and encrypt data in-transit. While Kerberos (Active Directory) is widely adopted by big organizations, the administration of users and services is a painful process and the system does not scale. On top of that Kerberos APIs are so complicated that <a href="https://apachebigdata2015.sched.com/event/3zv3/hadoop-and-kerberos-the-madness-beyond-the-gate-steve-loughran-hortonworks">programming against them can be really challenging</a>.</p><p>To avoid the pain of Kerberos (and be able to natively integrate with platforms like Kubernetes), we completely <a href="https://github.com/hopshadoop/hops">re-designed the security model for HopsFS and YARN to use certificates</a>. We replaced Kerberos with Public Key Infrastructure (PKI) with X.509 certificates to authenticate and authorize users. Certificates enabled us to also use the well established TLS protocol to provide confidentiality and data integrity. Every user and every service in a Hopsworks cluster has a private key and an X.509 certificate.</p><figure id="w-node-daa745592959-87a4da24"><p><img src="https://uploads-ssl.webflow.com/5e6f7cd3ee7f51ec3ea4da0f/5f105955f5d5389cb463a175_Screenshot%202020-07-16%20at%2015.42.26.png" alt=""></p></figure><h3>TLS-Based Multi-Tenant Services</h3><p>Hopsworks supports a number of stateful and compute services that use X.509 certificates to authenticate users, applications, and services: HopsFS, HiveServer2, Kafka, YARN. These services all provide their own authorization schemes. We unified HopsFS and Hive’s authorization models by providing 2-way TLS in HiveServer2 and <a href="https://cwiki.apache.org/confluence/display/Hive/Storage+Based+Authorization+in+the+Metastore+Server">storage based authorization for the Hive metastore</a>, that we <a href="https://github.com/logicalclocks/hive">ported to Hive 3.X</a>, to delegate access control decisions for Hive to HopsFS. In Hive, tables and databases store their data files inside directories on HopsFS, so HopsFS&nbsp; ACLs (access control lists) authorize file system operations by Hive (read from tables, write to tables). The easy-to-understand ACLs that we expose in Hopsworks (for Hive, and datasets in HopsFS) are captured in two roles: Data Scientists can read, Data Owners can read/write. HopsFS ACLs can be customized directly in Hopsworks from version 1.4.</p><p>For Kafka, we developed a <a href="https://github.com/logicalclocks/hops-kafka-authorizer">Hopsworks Authorizer plugin</a> that authorizes operations on Kafka topics by extracting the <em>project-user identity </em>from the client supplied X.509 certificate. The Hopsworks Kafka Authorizer then validates that the user is a member of the project that has permissions to perform the requested action on the Kafka topic.&nbsp;</p><p>HopsYARN uses X.509 certificates to identify users. HopsYARN also creates and manages (including renewal) application certificates for YARN applications (such as Spark jobs). Application certificates in HopsYARN are a key feature missing …</p></div></div></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.logicalclocks.com/blog/how-we-secure-your-data-with-hopsworks">https://www.logicalclocks.com/blog/how-we-secure-your-data-with-hopsworks</a></em></p>]]>
            </description>
            <link>https://www.logicalclocks.com/blog/how-we-secure-your-data-with-hopsworks</link>
            <guid isPermaLink="false">hacker-news-small-sites-23904812</guid>
            <pubDate>Tue, 21 Jul 2020 06:46:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Many Faces of an Undying Programming Language]]>
            </title>
            <description>
<![CDATA[
Score 80 | Comments 28 (<a href="https://news.ycombinator.com/item?id=23904104">thread link</a>) | @grugagag
<br/>
July 20, 2020 | http://jakob.space/blog/thoughts-on-lisps.html | <a href="https://web.archive.org/web/*/http://jakob.space/blog/thoughts-on-lisps.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>July 20, 2020 ❖ Tags: <a href="http://jakob.space/blog/tag/tag/opinion.html">opinion</a>, <a href="http://jakob.space/blog/tag/tag/programming.html">programming</a>, <a href="http://jakob.space/blog/tag/tag/lisp.html">lisp</a>, <a href="http://jakob.space/blog/tag/tag/common-lisp.html">common-lisp</a>, <a href="http://jakob.space/blog/tag/tag/scheme.html">scheme</a></p><article><p>
This is a post I've been meaning to write for a while now: one anecdotally
comparing programming languages in the Lisp family. I consider myself to be a
Lisp hacker. Perhaps that much was obvious from the letter λ adorning my
website's header, a reference to the λ-calculus which inspired John McCarthy to
design the first LISP [1]. Yet, "Lisp hacker" likely means little unless you,
too, consider yourself to be a Lisp hacker. Calling yourself one seems carry
some level of unstated meaning. Indeed, some identify with more specific groups.
"Schemer," or "Guiler," or "Racketeer," or "Clojurist." But "Lisp Hackers" ⊇
"Schemers". There is commonality shared among all, or at least most, of these
programming languages, and the Lisp hackers recognize and appreciate that
commonality – the characteristics that make a programming language a Lisp.
Homoiconic syntax, powerful metaprogramming facilities, and editor support that,
in my opinion, is unparalleled. (Yes, I am alluding to GNU Emacs.) This article,
however, is concerned with the differences. In it, I will be considering the
specifics of each dialect, and whether or not those specifics make for a
language I would want to use to develop a new piece of software.
</p><p>
I'm specifically concerned with game development at the time of writing this
article. An idea for a turn-based tactics game came to me and I felt a Lisp
would be the best tool for realizing it, but the decision to use "a Lisp" still
leaves me with several choices. When I enumerate the notable design choices
behind each dialect, and talk about the approaches I prefer, my opinions will
be, in some capacity, framed as partial answers to the question of "will I be
able to comfortably use this to write a video game?" As such, there are a few
things I am specifically interested in:
</p><ul>
<li><b>Ergonomics</b>, or "a measure of the friction [one experiences] when trying to get
things done" [2].</li>
<li><b>Expressiveness</b>, or the ease with which code may be understood by a reader.</li>
<li><b>Performance</b>, which is nontrivial to properly quantify [3]. I won't be rigorous
with this; a one-off run with <code>time</code> can give a good idea of the order of
magnitude for execution time.</li>
<li><b>Ease of distribution</b>, which is difficult to define, but with which I associate
platform agnosticism, a runtime that won't bloat my tarballs by several
gigabytes, and a lack of baroque and difficult to obtain dependencies.</li>
<li><b>Ability to interface with other libraries</b>, as I'll want to be able to
draw to the screen, and play sounds, and so on.</li>
</ul><p>
For each dialect, I'm allowing myself to use nonstandard functions. I'm aiming
for an evaluation of the practical aspects of each language, and if you were
writing software, you'd likely be using more than what's included in the R5RS or
ANSI CL standards. Though, if these nonstandard functions are specific to a
single implementation, I will avoid them. SRFI's and QuickLisp are fair game,
but CHICKEN's Eggs are not. Ah, I'm already getting ahead of myself. Yes, I will
be comparing Scheme and Common Lisp. I almost have to – the history of Lisp
tends to be spun as a schism between Common Lisp and Scheme. I will be speaking
of a few others as well. I've mostly chosen dialects for which there exists some
"game engine" type library. For R7RS (CHICKEN), there is <a href="http://alex-charlton.com/projects/Hypergiant/">Hypergiant</a>, for R6RS
(Guile) there is <a href="https://dthompson.us/projects/chickadee.html">Chickadee</a>, for Common Lisp there is <a href="http://www.xelf.me/">Xelf</a>, and for Fennel there
is, of course, <a href="https://love2d.org/">LÖVE</a>.
</p><figure>
<img src="http://jakob.space/static/image/lisp-personality-test.png" alt="lisp-personality-test.png">

<figcaption><span>Figure 1: </span>My take on the drawing in Conrad Barski's <i>Land of Lisp</i>. From left to right: Common Lisp, Scheme, <del>Haskell</del> Fennel.</figcaption>
</figure><p>
What follows are my opinions, so I'd like to lead with the background that
motivated them. My earliest "serious" experience with Lisp was with Peter
Seibel's <i>Practical Common Lisp</i>, which I picked up in high school following a
failed attempt at reading <i>Structure and Interpretation of Computer
Programs</i>.<sup><a id="fnr.1" href="#fn.1">1</a></sup> The portion of the latter book that I did manage was enough to
convince me that learning <span>a</span> Lisp would be valuable, but that learning Common
Lisp may be more tractable than learning Scheme. The summer following my first
year of university, I taught myself Scheme to do <a href="http://summerofcode.withgoogle.com/">GSoC</a> for <a href="https://guix.gnu.org/">GNU Guix</a>. Guile
quickly grew on me, and I soon began <a href="http://jakob.space/blog/transition-to-haunt.html">using Haunt</a> for my personal website. I've
been unknowingly using Emacs Lisp since much earlier – not in the sense of
writing packages – my old man taught me how to use Emacs when I was nine, but I
was <a href="https://www.gnu.org/software/emacs/manual/html_node/emacs/Easy-Customization.html">mostly shielded from having to write <code>setq</code> forms</a>. I've also used <a href="https://docs.hylang.org/en/stable/">Hy</a>, <a href="https://fennel-lang.org/">Fennel</a>,
… well, I'm wildly off track now. Point being, I've used many Lisps, and I've
subconsciously acknowledged the differences between them, but never turned that
acknowledgment into coherent thought.
</p><p>
To aid in the comparison, I've written the same raytracer in several dialects of
Lisp. My reasons for choosing a raytracer are that:
</p><ul>
<li>I'm reasonably familiar with how they work.</li>
<li>Performance matters, and differences in performance is noticeable.</li>
<li>It's nontrivial, but several implementations of a raytracer is also more
tractable than, say, several implementations of a high-performance database.</li>
</ul><p>
Another consideration was the number of advancements in raytracing that build
upon the same basic structure, potentially giving me a way to compare the ease
with which a change to a system can be made, but writing these raytracers took
enough out of me that I didn't want to play with them any more.
</p><p>
This was not nearly as telling of a comparison as I had hoped. Once I'd
completed the first raytracer, everything that followed had the same structure.
Regardless, writing these raytracers gave me an idea of the characteristics I
was interested in, especially performance. For anyone who would like to look at
the code, the implementations are available <a href="https://git.sr.ht/~jakob/lisp-raytracer-zoo">here</a>.
</p><p>
<b>Table of Contents</b>
</p><ul>
<li><a href="#org9a5541d">The Issue of Rendering an Image</a></li>
<li><a href="#orga8f893b">Scheme</a>
<ul>
<li><a href="#org4538c39">R7RS</a></li>
<li><a href="#org47b9bd9">R6RS</a></li>
<li><a href="#org3eedb31">Conclusions on Scheme</a></li>
</ul></li>
<li><a href="#org9e27a4b">Common Lisp</a>
<ul>
<li><a href="#org0df9ac3">Conclusions on Common Lisp</a></li>
</ul></li>
<li><a href="#org4d7f824">Fennel</a>
<ul>
<li><a href="#org3eb9b83">Conclusions on Fennel</a></li>
</ul></li>
<li><a href="#org0fbbf7a">Lisps I've Neglected</a>
<ul>
<li><a href="#org1bb9256">Emacs Lisp</a></li>
<li><a href="#orga47743c">Gerbil Scheme</a></li>
<li><a href="#orgcca7e64">Racket</a></li>
<li><a href="#org883fd6d">Janet</a></li>
<li><a href="#org965e8ce">Clojure</a></li>
</ul></li>
</ul><div id="outline-container-org9a5541d">
<h2 id="org9a5541d">The Issue of Rendering an Image</h2>
<div id="text-org9a5541d">
<p>
Well, if we're writing a raytracer, then, we had better have some way of seeing
the results. The issue is portability. Ideally, I'd like to be able to run the
raytacers on different implementations of each language, but none of them have
standardized support for drawing graphics. An idea I had was to render the image
to the terminal using ANSI escape sequences, but I thought the resulting images
would be quite shitty. Instead, I decided to go the <a href="https://github.com/ssloy/tinyrenderer/wiki/Lesson-0-getting-started">route that tinyrenderer
takes</a>, which is to output to an image file. Initially, the image format I went
with was the venerable PNG. This was a mistake. Even if it did lead to a rather
elegant CRC procedure in Scheme.
</p>

<div>
<pre>(<span>define</span> (<span>chunk-crc</span> bytes)
  (<span>define</span> (<span>process-byte</span> crc byte)
    (bitwise-xor (vector-ref png-crc (bitwise-and #xff (bitwise-xor crc byte)))
                 (arithmetic-shift crc -8)))
  (reduce process-byte bytes #xffffffff))
</pre>
</div>

<p>
Realizing PNG was needlessly complex, I went on to write a <a href="https://git.sr.ht/~jakob/lisp-raytracer-zoo/tree/master/write-bmp.scm">BMP encoder</a>, which
was fine until I came across <a href="https://nullprogram.com/blog/2017/11/03/">an article</a> from Chris Wellons about rendering video
with C by encoding frames as <a href="http://netpbm.sourceforge.net/doc/">Netpbm</a> images. I decided to scrap my BMP encoder
and go with PPM instead. Netpbm is text-based: the issue with a PNG or BMP
encoder in Scheme, for example, is that you're dealing with a binary format.
Glancing over the standards now, it seems there are, indeed, standardized
procedures for dealing with binary data in both R6RS and R7RS. Regardless,
dealing with those binary structures and having to consider endianness is a
pain. PPM is <span>dead</span> simple. In fact, I'd wager that if all you had access to were
the examples on the <a href="https://en.wikipedia.org/wiki/Netpbm">Wikipedia</a> page, you'd be able to write an encoder. Here's
the Scheme implementation:
</p>

<div>
<pre>(<span>define</span> (<span>write-ppm</span> width height pixels)
  <span>"Encode the WIDTH by HEIGHT image given as PIXELS into the portable pixmap</span>
<span>format (PPM), writing the result to `(current-output-port)'."</span>
  (<span>define</span> (<span>delimit-values</span> values)
    (<span>cond</span> ((null? values)
           (newline))
          ((= 1 (length values))
           (display (car values))
           (delimit-values (cdr values)))
          (<span>else</span>
           (display (car values))
           (display <span>" "</span>)
           (delimit-values (cdr values)))))

  
  (delimit-values '(<span>"P3"</span>))

  
  (delimit-values (list width height))

  
  (delimit-values '(<span>"255"</span>))

  
  (<span>for-each</span> delimit-values (vector-&gt;list pixels)))
</pre>
</div>

<p>
If you do away with my nice formatting, that's twelve lines of code, all of
which are R5RS-compatible. We have access to the Netpbm suite, too, so if we
want a PNG, we can always <code>./write-ppm | pnmtopng &gt; test.png</code>. Netpbm is a
real hidden gem. Well, hidden to me, at least.
</p>
</div>
</div><div id="outline-container-orga8f893b">
<h2 id="orga8f893b">Scheme</h2>
<div id="text-orga8f893b">
<p>
If you aren't familiar with Scheme, it has somewhat of a self-imposed<sup><a id="fnr.2" href="#fn.2">2</a></sup>
reputation for appealing to academic types. It's also one of the most
opinionated languages I know of; all the specs of interest lead with an
assertion that "programming languages should be designed not by piling feature
on top of feature, but by removing the weaknesses and restrictions that make
additional features appear necessary." The way that Scheme embraces purity and
simplicity makes it clear it was designed by math nerds. (Hey, I'm a math nerd,
too. Take it easy.)
</p>

<p>
As I've just mentioned, there are specs. A few, to be sure. The evolution of
Scheme standards begins in a linear fashion: RRS → RRRS → R3RS → R4RS → R5RS. I
like to think of this as "classic Scheme". But when it came time to revise R5RS,
the ratification of the subsequent R6RS caused some controversy. It was
"bloated", or whatever. Something like that. So when it came time to design R7RS
(small), the Scheme Language Steering Committee decided to let the language
fork, beginning with the earlier R5RS as a blank slate [4]. That way, the nerds
that hated everything about R6RS could have their way, and the nerds that liked
R6RS could have their way. Scheme was divided, but at peace. Oh, and nowadays
there's a work-in-progress <a href="https://bitbucket.org/cowan/r7rs-wg1-infra/src/default/R7RSHomePage.md">R7RS-large</a>. ಠ_ಠ
</p>

<p>
I'm not going to talk about R7RS-large here. It's just too …</p></div></div></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://jakob.space/blog/thoughts-on-lisps.html">http://jakob.space/blog/thoughts-on-lisps.html</a></em></p>]]>
            </description>
            <link>http://jakob.space/blog/thoughts-on-lisps.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23904104</guid>
            <pubDate>Tue, 21 Jul 2020 03:29:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Assessing Abstractions]]>
            </title>
            <description>
<![CDATA[
Score 20 | Comments 2 (<a href="https://news.ycombinator.com/item?id=23904080">thread link</a>) | @stopachka
<br/>
July 20, 2020 | https://stopa.io/post/245 | <a href="https://web.archive.org/web/*/https://stopa.io/post/245">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p><span><p>Some abstractions are ticking time bombs, while others help you move fast. How can you tell? What follows is my personal exploration for how I assess abstractions.</p><h2>Problem</h2><p>We add abstractions in our programs to solve problems. So, let’s start with the fundamental value proposition: what problem does our abstraction solve? </p><p>Let’s take a look at one example abstraction:</p><pre><code>NLP.parse(...) // =&gt; { intent: "set_alarm", at: "1593538633430" }</code></pre><p>This could be a natural language processing abstraction, which lets us take a piece of text, and extract meaning from it. The inherent problem of natural language processing is pretty darn complex, so an abstraction that helps us solve it would be very valuable. This is a sign of a good abstraction.</p><p>Now let’s compare that to </p><pre><code>StringSplitter.easySplit(str, splitStr)</code></pre><p>Maybe this abstraction, adds a light layer on top of string.split. For example, it may make it so you don’t have to worry about regexes, and can turn common string patterns into regexes. The value of a <code>StringSplitter</code> abstraction is pretty darn low. Maybe  <code>StringSplitter</code> treats <code>splitStr</code> in a way that’s a bit more in-line with the someone’s thinking, but at the end of the day this boils down to an indirection. </p><p>This leads us to the first principle. The more complex the problem it solves for you, the better the abstraction (1).</p><h2>Interface</h2><p>After we’re convinced that the abstraction we are about to add solves a tough problem for us, the next thing to consider is the interface: <em>how</em> do we interact with the abstraction? Imagine if <code>NLP.parse</code> was called like this:</p><pre><code>NLP.parse(lang, text)</code></pre><p>This is a great interface. It’s small. We don’t need to understand any internals. For the main use-case, all we need to do is to provide language and text. Compare that with</p><pre><code>NLP.parse(
  text,
  lang, 
  strategy,
  shouldUseFlagA,
  ...
  shouldUseFlagZ
)</code></pre><p>In order to use this version, we’d need to deeply understand the internals of NLP.parse. This lowers the value of the abstraction, because we need to do more work to solve the same level of complexity. </p><p>This leads us to the second principle: <strong>great abstractions have small interfaces.</strong></p><h2>Breakthrough Cost</h2><p>Now that we have an abstraction with a simple interface that solves a hard problem, we need to ask a possibly fatal question: what happens when we need to break through the abstraction? </p><p>All abstractions are leaky at some point. What will happen when you need the abstraction to behave differently? What will happen when it doesn’t work as you expect? </p><p>For example, for <code>NLP.parse(lang, text)</code>, what if we needed to sort and score the results differently? What if there’s a bug, and we aren’t getting the entity we expect, can we look through and debug?</p><p>Understanding the answer to this, will give us the breakthrough cost. To do this, we need to peak through the code. How is <code>NLP.parse</code> implemented?</p><pre><code>parse(lang, text) { 
  return format(scoreEntities(fetchEntities(lang, text)))
}</code></pre><p>In one solution, it could be composed of other abstractions that we can take advantage of. This is a great sign, because we can reuse the underlying abstractions in cases where we need to do something more complicated. Compare that to </p><pre><code>parse(lang, text) { 
  internalParse(lang, text, flagA, flagB, ...flagZ)
}</code></pre><p>This feels more dangerous. If these flags all head to the same function, it’s a sign that a bunch of different features are complected together. It’s also worrying: what if one of these flags don’t do what you want? you may have to fork the abstraction.</p><p>This leads us to the third principle: <strong>great abstractions are transparent.</strong> I think this principle is the most overlooked. It’s easy to take the productivity win upfront, but if the abstraction you add can’t be changed, and can’t be introspected, it’s very likely to bite you at some point.</p><h2>Generality</h2><p>The final principle is orthogonal to the last three, but maybe it’s the most important. Hardy said <em>there is no permanent place in the world for ugly mathematics —</em> So it is with abstractions. The beauty in math relates to how “general” and “tight” the solution is. I think this parallels well with abstractions. </p><p>If you use an abstraction that is “essentially” simpler, it’s more likely to last, and it’s likely to be more powerful.</p><p>Consider if the abstraction for <code>NLP</code>, was made up of specific algorithms, <em>just</em> for natural language processing. This would still be very valuable, but what would be <em>even more</em> valuable, is if the abstractions that this library was composed of was more general: if the parts that compose it were deep learning abstractions, you could reuse them for other problems.</p><h2>Fin</h2><p>And we reach the end. To pick great abstractions: pick the ones that solve a complex problem for you. Make sure they have a simple interface, and take a look at the internals, so you’re confident you can jig things up if needed. The more general and simple you can get for the same amount of power, the better. </p><p>Want to see some great abstractions in the wild? First, chances are you are using many of them: TCP, higher order functions like map &amp; filter, React. Some you may not have explored: Go’s CSP, Rich Hickey’s Datomic, or his <code>seq</code> abstraction in Clojure. As you pick up abstractions, I encourage you to run each one as an experiment: ask yourself at the end how things went, discuss them with your friends, and soon you’ll develop a much more nuanced taste.</p><p>(1) The rabbit hole gets deeper. Even if an abstraction solves a complex problem you have, you may need to take a step back and also ask: why do I have this problem? For example, kubernetes may be a great solution to building distributed systems, but why do you have a distributed systems problem? Many times the problem itself can be avoided. For the answer to that, <a href="https://stopa.io/post/241" target="_blank">Hacker’s Paradise</a> tries to covers it.</p><p><em>Thanks to Alex Reichert, Daniel Woelfel, Martin Raison, Sean Grove for reviewing drafts of this essay</em></p></span></p></div></div></div>]]>
            </description>
            <link>https://stopa.io/post/245</link>
            <guid isPermaLink="false">hacker-news-small-sites-23904080</guid>
            <pubDate>Tue, 21 Jul 2020 03:24:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Essays on programming I think about a lot]]>
            </title>
            <description>
<![CDATA[
Score 274 | Comments 48 (<a href="https://news.ycombinator.com/item?id=23903737">thread link</a>) | @jchook
<br/>
July 20, 2020 | https://www.benkuhn.net/progessays/ | <a href="https://web.archive.org/web/*/https://www.benkuhn.net/progessays/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><p>Every so often I read an essay that I end up thinking about, and citing in conversation, over and over again.</p><p>Here’s my index of all the ones of those I can remember! I’ll try to keep it up to date as I think of more.</p><p>(Some of them are extremely well-known. I’m leaving them here anyway just in case you’re one of <a href="https://xkcd.com/1053/" target="_blank">the lucky 10,000</a>.)</p><p>I’m curious what essays are in this category for other folks—post yours in the comments!</p><hr><p><a href="https://blog.nelhage.com/post/computers-can-be-understood/" target="_blank">Computers can be understood</a>:</p><blockquote><p>I approach software with a deep-seated belief that computers and software systems can be understood. …</p><p>In some ways, this belief feels radical today. Modern software and hardware systems contain almost unimaginable complexity amongst many distinct layers, each building atop each other. …</p><p>In the face of this complexity, it’s easy to assume that there’s just too much to learn, and to adopt the mental shorthand that the systems we work with are best treated as black boxes, not to be understood in any detail.</p><p>I argue against that approach. You will never understand every detail of the implementation of every level on that stack; but you can understand all of them to some level of abstraction, and any specific layer to essentially any depth necessary for any purpose.</p></blockquote><hr><p><a href="https://mcfunley.com/choose-boring-technology" target="_blank">Choose Boring Technology</a>:</p><blockquote><p>Let’s say every company gets about three innovation tokens. You can spend these however you want, but the supply is fixed for a long while. You might get a few more after you achieve a certain level of stability and maturity, but the general tendency is to overestimate the contents of your wallet. Clearly this model is approximate, but I think it helps.</p><p>If you choose to write your website in NodeJS, you just spent one of your innovation tokens. If you choose to use MongoDB, you just spent one of your innovation tokens. If you choose to use service discovery tech that’s existed for a year or less, you just spent one of your innovation tokens. If you choose to write your own database, oh god, you’re in trouble.</p></blockquote><hr><p><a href="https://www.sandimetz.com/blog/2016/1/20/the-wrong-abstraction" target="_blank">The Wrong Abstraction</a>:</p><blockquote><ol start="4"><li><p>Time passes.</p></li><li><p>A new requirement appears for which the current abstraction is almost perfect.</p></li><li><p>Programmer B gets tasked to implement this requirement.</p><p><em>Programmer B feels honor-bound to retain the existing abstraction, but since isn’t exactly the same for every case, they alter the code to take a parameter….</em></p></li><li><p>… Loop until code becomes incomprehensible.</p></li><li><p>You appear in the story about here, and your life takes a dramatic turn for the worse.</p></li></ol></blockquote><hr><p><a href="https://www.kalzumeus.com/2010/06/17/falsehoods-programmers-believe-about-names/" target="_blank">Falsehoods Programmers Believe About Names</a>:</p><blockquote><ol start="32"><li>People’s names are assigned at birth.</li><li>OK, maybe not at birth, but at least pretty close to birth.</li><li>Alright, alright, within a year or so of birth.</li><li>Five years?</li><li>You’re kidding me, right?</li></ol></blockquote><hr><p><a href="https://sockpuppet.org/blog/2015/03/06/the-hiring-post/" target="_blank">The Hiring Post</a>:</p><blockquote><p>Nothing in Alex’s background offered a hint that this would happen. He had Walter White’s resume, but Heisenberg’s aptitude. None of us saw it coming. My name is Thomas Ptacek and I endorse this terrible pun. Alex was the one who nonced.</p><p>A few years ago, Matasano couldn’t have hired Alex, because we relied on interviews and resumes to hire. Then we made some changes, and became a machine that spotted and recruited people like Alex: line of business .NET developers at insurance companies who pulled Rails core CVEs out of their first hour looking at the code. Sysadmins who hardware-reversed assembly firmware for phone chipsets. Epiphany: the talent is out there, but you can’t find it on a resume.</p><p>Our field selects engineers using a process that is worse than reading chicken entrails. Like interviews, poultry intestine has little to tell you about whether to hire someone. But they’re a more pleasant eating experience than a lunch interview.</p></blockquote><hr><p><a href="https://blog.pragmaticengineer.com/the-product-minded-engineer/" target="_blank">The Product-Minded Engineer</a>:</p><blockquote><p>Proactive with product ideas/opinions • Interest in the business, user behavior and data on this • Curiosity and a keen interest in “why?” • Strong communicators and great relationships with non-engineers • Offering product/engineering tradeoffs upfront • Pragmatic handling of edge cases • Quick product validation cycles • End-to-end product feature ownership • Strong product instincts through repeated cycles of learning</p></blockquote><hr><p><a href="https://programmingisterrible.com/post/139222674273/write-code-that-is-easy-to-delete-not-easy-to" target="_blank">Write code that is easy to delete, not easy to extend</a>:</p><blockquote><p>If we see ‘lines of code’ as ‘lines spent’, then when we delete lines of code, we are lowering the cost of maintenance. Instead of building re-usable software, we should try to build disposable software.</p></blockquote><blockquote><p>Business logic is code characterised by a never ending series of edge cases and quick and dirty hacks. This is fine. I am ok with this. Other styles like ‘game code’, or ‘founder code’ are the same thing: cutting corners to save a considerable amount of time.</p><p>The reason? Sometimes it’s easier to delete one big mistake than try to delete 18 smaller interleaved mistakes. A lot of programming is exploratory, and it’s quicker to get it wrong a few times and iterate than think to get it right first time.</p></blockquote><hr><p><a href="https://www.joelonsoftware.com/2002/11/11/the-law-of-leaky-abstractions/" target="_blank">The Law of Leaky Abstractions</a>:</p><blockquote><p>Back to TCP. Earlier for the sake of simplicity I told a little fib, and some of you have steam coming out of your ears by now because this fib is driving you crazy. I said that TCP guarantees that your message will arrive. It doesn’t, actually. If your pet snake has chewed through the network cable leading to your computer, and no IP packets can get through, then TCP can’t do anything about it and your message doesn’t arrive. If you were curt with the system administrators in your company and they punished you by plugging you into an overloaded hub, only some of your IP packets will get through, and TCP will work, but everything will be really slow.</p><p>This is what I call a leaky abstraction. TCP attempts to provide a complete abstraction of an underlying unreliable network, but sometimes, the network leaks through the abstraction and you feel the things that the abstraction can’t quite protect you from. This is but one example of what I’ve dubbed the Law of Leaky Abstractions:</p><p><strong>All non-trivial abstractions, to some degree, are leaky.</strong></p><p>Abstractions fail. Sometimes a little, sometimes a lot. There’s leakage. Things go wrong. It happens all over the place when you have abstractions. Here are some examples.</p></blockquote><hr><p><a href="https://blog.nelhage.com/post/reflections-on-performance/" target="_blank">Reflections on software performance</a>:</p><blockquote><p>It’s probably fairly intuitive that users prefer faster software, and will have a better experience performing a given task if the tools are faster rather than slower.</p><p>What is perhaps less apparent is that having faster tools changes how users use a tool or perform a task. Users almost always have multiple strategies available to pursue a goal — including deciding to work on something else entirely — and they will choose to use faster tools more and more frequently. Fast tools don’t just allow users to accomplish tasks faster; they allow users to accomplish entirely new types of tasks, in entirely new ways. I’ve seen this phenomenon clearly while working on both Sorbet and Livegrep:</p></blockquote><hr><p>Brandur Leach’s series on using databases to ensure correct edge-case behavior: <a href="https://brandur.org/acid" target="_blank">Building Robust Systems with ACID and Constraints</a>, <a href="https://brandur.org/http-transactions" target="_blank">Using Atomic Transactions to Power an Idempotent API</a>, <a href="https://brandur.org/job-drain" target="_blank">Transactionally Staged Job Drains in Postgres</a>, <a href="https://brandur.org/idempotency-keys" target="_blank">Implementing Stripe-like Idempotency Keys in Postgres</a>.</p><blockquote><p>I want to convince you that ACID databases are one of the most important tools in existence for ensuring maintainability and data correctness in big production systems. Lets start by digging into each of their namesake guarantees.</p></blockquote><blockquote><p>There’s a surprising symmetry between an HTTP request and a database’s transaction. Just like the transaction, an HTTP request is a transactional unit of work – it’s got a clear beginning, end, and result. The client generally expects a request to execute atomically and will behave as if it will (although that of course varies based on implementation). Here we’ll look at an example service to see how HTTP requests and transactions apply nicely to one another.</p></blockquote><blockquote><p>In APIs <em>idempotency</em> is a powerful concept. An idempotent endpoint is one that can be called any number of times while guaranteeing that the side effects will occur only once. In a messy world where clients and servers that may occasionally crash or have their connections drop partway through a request, it’s a huge help in making systems more robust to failure. Clients that are uncertain whether a request succeeded or failed can simply keep retrying it until they get a definitive response.</p></blockquote><hr><p><a href="https://www.somethingsimilar.com/2013/01/14/notes-on-distributed-systems-for-young-bloods/" target="_blank">Notes on Distributed Systems for Young Bloods</a>:</p><blockquote><p>Distributed systems are different because they fail often • Implement backpressure throughout your system • Find ways to be partially available • Use percentiles, not averages • Learn to estimate your capacity • Feature flags are how infrastructure is rolled out • Choose id spaces wisely • Writing cached data back to persistent storage is bad • Extract services.</p></blockquote><hr><p><a href="http://web.mit.edu/Saltzer/www/publications/endtoend/endtoend.pdf" target="_blank">End-to-End Arguments in System Design</a>:</p><blockquote><p>This paper presents a design principle that helps guide placement of functions among the modules of a distributed computer system. The principle, called the end-to-end argument, suggests that functions placed at low levels of a system may be redundant or of little value when compared with the cost of providing them at that low level. Examples discussed in the paper include bit error recovery, security using encryption, duplicate message suppression, recovery from system crashes, and delivery acknowledgement. Low level mechanisms to support these functions are justified only as performance enhancements.</p></blockquote><hr><p><a href="https://vimeo.com/36579366" target="_blank">Inventing on Principle</a>:</p><blockquote><p>I’ve spent a lot of time over the years making creative tools, using creative tools, thinking about them a lot, and here’s something I’ve come to believe: Creators need an immediate connection to what they’re creating.</p></blockquote><p>I can’t really excerpt any of the actual demos, which are the good part. Instead I’ll just endorse it: this talk dramatically, and productively, raised my bar for what I think programming tools (and tools in general) can be. Watch it and be amazed.</p><hr><p>Post the essays you keep returning to in the comments!</p></article></div>]]>
            </description>
            <link>https://www.benkuhn.net/progessays/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23903737</guid>
            <pubDate>Tue, 21 Jul 2020 02:07:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[‘Strong Opinions, Weakly Held’ Doesn't Work That Well]]>
            </title>
            <description>
<![CDATA[
Score 210 | Comments 120 (<a href="https://news.ycombinator.com/item?id=23903172">thread link</a>) | @shadowsun7
<br/>
July 20, 2020 | https://commoncog.com/blog/strong-opinions-weakly-held-is-bad/ | <a href="https://web.archive.org/web/*/https://commoncog.com/blog/strong-opinions-weakly-held-is-bad/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
      <p>There’s a famous thinking framework by ‘futurist’, ‘forecaster’, and scenario consultant Paul Saffo called ‘strong opinions, weakly held’. The phrase itself became popular in tech circles in the 2010s — I remember reading about it on Hacker News or a16z.com or one of those thinky tech blogs around the period. It’s still rather popular today.</p><p>Saffo’s framework — laid out in his original <a href="https://www.saffo.com/02008/07/26/strong-opinions-weakly-held/">2008 blog post</a> — goes like this:</p><blockquote>I have found that the fastest way to an effective forecast is often through a sequence of lousy forecasts. Instead of withholding judgment until an exhaustive search for data is complete, I will force myself to make a tentative forecast based on the information available, and then systematically tear it apart, using the insights gained to guide my search for further indicators and information. Iterate the process a few times, and it is surprising how quickly one can get to a useful forecast.<p>Since the mid-1980s, my mantra for this process is “strong opinions, weakly held.” Allow your intuition to guide you to a conclusion, no matter how imperfect — this is the “strong opinion” part. Then – and this is the “weakly held” part – prove yourself wrong. Engage in creative doubt. Look for information that doesn’t fit, or indicators that pointing in an entirely different direction. Eventually your intuition will kick in and a new hypothesis will emerge out of the rubble, ready to be ruthlessly torn apart once again. You will be surprised by how quickly the sequence of faulty forecasts will deliver you to a useful result.</p><p>This process is equally useful for evaluating an already-final forecast in the face of new information. It sensitizes one to the weak signals of changes coming over the horizon and keeps the hapless forecaster from becoming so attached to their model that reality intrudes too late to make a difference.</p><p>More generally, “strong opinions weakly held” is often a useful default perspective to adopt in the face of any issue fraught with high levels of uncertainty, whether one is venturing a forecast or not. Try it at a cocktail party the next time a controversial topic comes up; it is an elegant way to discover new insights — and duck that tedious bore who loudly knows nothing but won’t change their mind!</p></blockquote><p>On the face of it, it all sounds very reasonable and smart. And ‘strong opinions weakly held’ is such a catchy phrase — which probably explains its popularity.</p><p>The only problem with it is that it doesn’t seem to work that well.</p><h2 id="swimming-upstream-against-the-architecture-of-the-mind">Swimming Upstream Against the Architecture Of The Mind</h2><p>How do I know that it doesn’t work that well? I know this because I’ve tried. I tried to use Saffo’s framework in the years between 2013 and 2016, and when I was running my previous company I attempted it with my boss, whenever we convened to <a href="https://commoncog.com/blog/what-uncertainty-feels-like/">discuss company strategy</a>.</p><p>Eventually I read Phillip Tetlock’s <a href="https://commoncog.com/blog/the-forecasting-series/"><em>Superforecasting</em></a>, and then I gave up on ‘Strong Opinions, Weakly Held’.</p><p>Why does the framework not work very well? From experience, Saffo’s approach fails in two ways.</p><p>The first way is if the person <em>hasn’t</em> read Saffo’s original post. This is, to be fair, most of us — Saffo’s original idea is so quotable it has turned into a memetic phenomenon, and I’ve seen it cited in fields far outside tech. In such cases, the failure mode is that ‘Strong Opinions, Weakly Held’ turns into ‘Strong Opinions, Justified Loudly, Until Evidence Indicates Otherwise, At Which Point You Invoke It To Protect Your Ass.’</p><p>In simpler terms, ‘strong opinions, weakly held’ sometimes becomes a license to hold on to a bad opinion strongly, with downside protection, against the spirit and intent of Saffo’s original framework.</p><p>Now, you might say that this is through no fault of Saffo’s, and is instead the problem of popularity. But my response is that if an idea has certain affordances, and people seem to always grab onto those affordances and abuse the idea in the exact same ways, then <em>perhaps you shouldn’t use the idea in the first place.</em> This is especially true — as we’re about to see — if there are better ideas out there.</p><p>The second form of failure is if the person has taken the time to look up the original intention of the phrase. In this situation, the failure mode is when you attempt to integrate new information into your judgment. Saffo’s framework offers no way for us to do this.</p><p>Here’s an example. Let’s say that you’ve decided, along with your boss, to build a particular type of product for a particular subsection of the self-service checkout market. You both come to the opinion that this subsection is the best entry-point to the industry: it is relatively lucrative, and you think that it is the easiest customer segment to service.</p><p>What happens to your opinion when you <em>slowly</em> discover that the subsegment is overcrowded? Of course, you don’t find out immediately — what happens instead is that you spot little hints, spread over the course of a couple of months, that many competitors are entering the market at the same time. These are tiny things like competitor brochures lying in the corner table of a client’s office, or pronouncements by industry groups that “they are looking to engage vendors for large deployments”, and then much later, clearer evidence in the form of increased competition in deals.</p><p>“Well,” I can hear you say, “‘Strong opinions weakly held’ means that you should change your opinion when you encounter these tiny hints!”</p><p>But at which point do you change your mind? At which point do you switch away from your strong opinion? At which point do you think that it’s time to reconsider your approach?</p><p>The problem, of course, is that <em>this is not how the human brain works.</em></p><p>Both forms of failure stem from the same tension. It’s easy to have strong opinions and hold on to them strongly. It’s easy to have weak opinions and hold on to them weakly. But it is quite difficult for the human mind to vacillate between one strong opinion to another.</p><p>I don’t mean to say that people <em>can’t</em> do this — only that it is very difficult to do so. For instance, Steve Jobs was famous for arguing against one position or another, only to decide that you were right, and then come back a month later holding exactly your opinion, as if it were his all along.</p><p>But most people aren’t like Jobs. Psychologist Amos Tversky used to joke that by default, human brains fall back to “yes I believe that, no I don’t believe that, and maybe” — a three-dial setting when it comes to uncertainty. People then hold on to their opinion for as long as their internal narratives allow them to. Saffo’s thinking framework implies that you sit in ‘yes I believe that’ territory, and then rapidly switch away to ‘maybe’ or to ‘no’, depending on the information you receive.</p><p>Perhaps you may — like Jobs! — be able to do this. But if you are like most people, the attempt will feel a lot like whiplash.</p><p>So, you might ask, what to do instead?</p><h2 id="use-probability-as-an-expression-of-confidence">Use Probability as an Expression of Confidence</h2><p>The gentler answer lies in <em>Superforecasting.</em> In the book, Tetlock presents an analytical framework that is easier to use than Saffo’s, while achieving many of the same goals.</p><ol><li>When forming an opinion, phrase it in a way that is very clear, and may be verified by a particular date.</li><li>Then state the probability you are confident that it is correct.</li></ol><p>For instance, you may say “I believe that Tesla will go bankrupt by 31 December 2021, and I am about 76% confident that this is the case.” Or you can be slightly sloppier with the technique — with my boss, I would say: “I think this subsegment is a good market to enter, and I think we would know if this is true within four months. I believe this on the order of 70% ish. Let’s check back in September.”</p><p>(My boss was an ex-investment banker, so he took to this like a duck to water.)</p><p>Tetlock’s stated technique was developed in the context of a geopolitical forecasting tournament called the Good Judgment Project. In 2016, when I read <em>Superforecasting</em> for the first time, I remember thinking that geopolitical forecasting wasn’t particularly relevant to my job running an engineering office in Vietnam. But I also glommed onto the book’s <a href="https://commoncog.com/blog/how-the-superforecasters-do-it/">ideas around analysis</a>, because it was too attractive to ignore.</p><p>The truth is that Tetlock’s ideas are not unique to his research group. Annie Duke’s <em><a href="https://www.goodreads.com/book/show/35957157-thinking-in-bets">Thinking in Bets</a></em> proposes the same approach, but drawn from poker, and the ‘rationalist’ community <a href="https://www.lesswrong.com/">LessWrong</a> has long-held norms around stating the confidence of their opinions.</p><p>More importantly, Duke and LessWrong have both discovered that the <em>fastest</em> way to provoke such nuanced thinking is to ask: “Are you willing to bet on that? What odds would you take, and how much?”</p><p>You’d be surprised by how effective this question is.</p><p>Why is it so effective? Why does it succeed where ‘Strong Opinions, Weakly Held’ does not?</p><p>The answer lies in the ‘strong opinion’ portion of the phrase. First: by forcing you to state your opinion as a probability judgment — that is, a percentage — you are forced to calibrate the strength of your belief. This makes it easier to move away from it. In other words, you are forced to let go of the ‘yes, no, maybe’ dial in your head.</p><p>Second: by framing it as a bet, you suddenly have skin in the game, and are motivated to get things right.</p><p>Of course, you don’t actually <em>have</em> to bet — you can merely propose the bet as a thinking frame. Later, as new information trickles in, you are allowed to update the % confidence you have in your belief. This allows you to see the world in shades of grey; it also allows you to communicate that confidence to those around you.</p><h2 id="revisiting-the-hierarchy-of-practical-evidence">Revisiting The Hierarchy of Practical Evidence</h2><p>I have one final point to make about this approach.</p><p>Long term readers of this blog would know that my shtick is “apply a technique to my career or to my life, over the period of a couple of months, and report on its efficacy.” Over time, I’ve noticed that techniques are more likely to be effective when they come from believable practitioners. This is what led to my <a href="https://commoncog.com/blog/the-hierarchy-of-practical-evidence/">Hierarchy of Practical Evidence</a>.</p><p>Saffo’s and Tetlock’s …</p></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://commoncog.com/blog/strong-opinions-weakly-held-is-bad/">https://commoncog.com/blog/strong-opinions-weakly-held-is-bad/</a></em></p>]]>
            </description>
            <link>https://commoncog.com/blog/strong-opinions-weakly-held-is-bad/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23903172</guid>
            <pubDate>Tue, 21 Jul 2020 00:08:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Three Architectures for a Responsive IDE]]>
            </title>
            <description>
<![CDATA[
Score 21 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23903131">thread link</a>) | @ubolonton_
<br/>
July 20, 2020 | https://rust-analyzer.github.io/blog/2020/07/20/three-architectures-for-responsive-ide.html | <a href="https://web.archive.org/web/*/https://rust-analyzer.github.io/blog/2020/07/20/three-architectures-for-responsive-ide.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>The first architecture is reminiscent of the map-reduce paradigm.
The idea is to split analysis into relatively simple indexing phase, and a separate full analysis phase.</p>
<p>The core constraint of indexing is that it runs on a per-file basis.
The indexer takes the text of a single file, parses it, and spits out some data about the file.
The indexer can’t touch other files.</p>
<p>Full analysis can read other files, and it leverages information from the index to save work.</p>
<p>This all sounds way too abstract, so let’s look at a specific example — Java.
In Java, each file starts with a package declaration.
The indexer concatenates the name of the package with a class name to get a fully-qualified name (FQN).
It also collects the set of methods declared in the class, the list of superclasses and interfaces, etc.</p>
<p>Per-file data is merged into an index which maps FQNs to classes.
Note that constructing this mapping is an embarrassingly parallel task — all files are parsed independently.
Moreover, this map is cheap to update.
When a file change arrives, this file’s contribution from the index is removed, the text of the file is changed and the indexer runs on the new text and adds the new contributions.
The amount of work to do is proportional to the number of changed files, and is independent from the total number of files.</p>
<p>Let’s see how FQN index can be used to quickly provide completion.</p>
<div>
<div>
<pre><code data-lang="java"><table><tbody><tr><td><pre> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
</pre></td><td><pre><span>// File ./mypackage/Foo.java</span>
<span>package</span> <span>mypackage</span><span>;</span>

<span>import</span> <span>java.util.*</span><span>;</span>

<span>public</span> <span>class</span> <span>Foo</span> <span>{</span>
    <span>public</span> <span>static</span> <span>Bar</span> <span>f</span><span>()</span> <span>{</span>
        <span>return</span> <span>new</span> <span>Bar</span><span>();</span>
    <span>}</span>
<span>}</span>

<span>// File ./mypackage/Bar.java</span>
<span>package</span> <span>mypackage</span><span>;</span>

<span>public</span> <span>class</span> <span>Bar</span> <span>{</span>
    <span>public</span> <span>void</span> <span>g</span><span>()</span> <span>{}</span>
<span>}</span>

<span>// File ./Main.java</span>
<span>import</span> <span>mypackage.Foo</span><span>;</span>

<span>public</span> <span>class</span> <span>Main</span> <span>{</span>
    <span>public</span> <span>static</span> <span>void</span> <span>main</span><span>(</span><span>String</span><span>[]</span> <span>args</span><span>)</span> <span>{</span>
        <span>Foo</span><span>.</span><span>f</span><span>().</span>
    <span>}</span>
<span>}</span>
</pre></td></tr></tbody></table></code></pre>
</div>
</div>
<p>The user has just typed <code>Foo.f().</code>, and we need to figure out that the type of receiver expression is <code>Bar</code>, and suggest <code>g</code> as a completion.</p>
<p>First, as the file <code>Main.java</code> is modified, we run the indexer on this single file.
Nothing has changed (the file still contains the class <code>Main</code> with a static <code>main</code> method), so we don’t need to update the FQN index.</p>
<p>Next, we need to resolve the name <code>Foo</code>.
We parse the file, notice an <code>import</code> and look up <code>mypackage.Foo</code> in the FQN index.
In the index, we also find that <code>Foo</code> has a static method <code>f</code>, so we resolve the call as well.
The index also stores the return type of <code>f</code>, but, and this is crucial, it stores it as a string <code>"Bar"</code>, and not as a direct reference to the class <code>Bar</code>.</p>
<p>The reason for that is <code>import java.util.*</code> in <code>Foo.java</code>.
<code>Bar</code> can refer either to <code>java.util.Bar</code> or to <code>mypackage.Bar</code>.
The indexer doesn’t know which one, because it can look <strong>only</strong> at the text of <code>Foo.java</code>.
In other words, while the index does store the return types of methods, it stores them in an unresolved form.</p>
<p>The next step is to resolve the identifier <code>Bar</code> in the context of <code>Foo.java</code>.
This uses the FQN index, and lands in the class <code>mypackage.Bar</code>.
There the desired method <code>g</code> is found.</p>
<p>Altogether, only three files were touched during completion.
The FQN index allowed us to completely ignore all the other files in the project.</p>
<p>One problem with the approach described thus far is that resolving types from the index requires a non-trivial amount of work.
This work might be duplicated if, for example, <code>Foo.f</code> is called several times.
The fix is to add a cache.
Name resolution results are memoized, so that the cost is paid only once.
The cache is blown away completely on any change — with an index, reconstructing the cache is not that costly.</p>
<p>To sum up, the first approach works like this:</p>
<div>
<ol>
<li>
<p>Each file is being indexed, independently and in parallel, producing a "stub" — a set of visible top-level declarations, with unresolved types.</p>
</li>
<li>
<p>All stubs are merged into a single index data structure.</p>
</li>
<li>
<p>Name resolution and type inference work primarily off the stubs.</p>
</li>
<li>
<p>Name resolution is lazy (we only resolve a type from the stub when we need it) and memoized (each type is resolved only once).</p>
</li>
<li>
<p>The caches are completely invalidated on every change</p>
</li>
<li>
<p>The index is updated incrementally:</p>
<div>
<ul>
<li>
<p>if the edit doesn’t change the file’s stub, no change to the index is required.</p>
</li>
<li>
<p>otherwise, old keys are removed and new keys are added</p>
</li>
</ul>
</div>
</li>
</ol>
</div>
<p>Note an interesting interplay between "dumb" indexes which can be updated incrementally, and "smart" caches, which are re-computed from scratch.</p>
<p>This approach combines simplicity and stellar performance.
The bulk of work is the indexing phase, and you can parallelize and even distribute it across several machine.
Two examples of this architecture are <a href="https://www.jetbrains.com/idea/">IntelliJ</a> and <a href="https://sorbet.org/">Sorbet</a>.</p>
<p>The main drawback of this approach is that it works only when it works — not every language has a well-defined FQN concept.
I think overall it’s a good idea to design name resolution and module systems (mostly boring parts of a language) such that they work well with the map-reduce paradigm.</p>
<div>
<ul>
<li>
<p>Require <code>package</code> declarations or infer them from the file-system layout</p>
</li>
<li>
<p>Forbid meta-programming facilities which add new top-level declarations, or restrict them in such way that they can be used by the indexer.
For example, preprocessor-like compiler plugins that access a single file at a time might be fine.</p>
</li>
<li>
<p>Make sure that each source element corresponds to a single semantic element.
For example, if the language supports conditional compilation, make sure that it works during name resolution (like Kotlin’s <a href="https://kotlinlang.org/docs/reference/platform-specific-declarations.html">expect/actual</a>) and not during parsing (like conditional compilation in most other languages).
Otherwise, you’d have to index the same file with different conditional compilation settings, and that is messy.</p>
</li>
<li>
<p>Make sure that FQNs are enough for most of the name resolution.</p>
</li>
</ul>
</div>
<p>The last point is worth elaborating. Let’s look at the following Rust example:</p>
<div>
<div>
<pre><code data-lang="rust"><table><tbody><tr><td><pre> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
18
</pre></td><td><pre><span>// File: ./foo.rs</span>
<span>trait</span> <span>T</span> <span>{</span>
    <span>fn</span> <span>f</span><span>(</span><span>&amp;</span><span>self</span><span>)</span> <span>{}</span>
<span>}</span>
<span>// File: ./bar.rs</span>
<span>struct</span> <span>S</span><span>;</span>

<span>// File: ./somewhere/else.rs</span>
<span>impl</span> <span>T</span> <span>for</span> <span>S</span> <span>{}</span>

<span>// File: ./main.s</span>
<span>use</span> <span>foo</span><span>::</span><span>T</span><span>;</span>
<span>use</span> <span>bar</span><span>::</span><span>S</span>

<span>fn</span> <span>main</span><span>()</span> <span>{</span>
    <span>let</span> <span>s</span> <span>=</span> <span>S</span><span>;</span>
    <span>s</span><span>.f</span><span>();</span>
<span>}</span>
</pre></td></tr></tbody></table></code></pre>
</div>
</div>
<p>Here, we can easily find the <code>S</code> struct and the <code>T</code> trait (as they are imported directly).
However, to make sure that <code>s.f</code> indeed refers to <code>f</code> from <code>T</code>, we also need to find the corresponding <code>impl</code>, and that can be roughly anywhere!</p>
</div></div>]]>
            </description>
            <link>https://rust-analyzer.github.io/blog/2020/07/20/three-architectures-for-responsive-ide.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23903131</guid>
            <pubDate>Mon, 20 Jul 2020 23:59:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Certificate Transparency: a bird's-eye view]]>
            </title>
            <description>
<![CDATA[
Score 28 | Comments 9 (<a href="https://news.ycombinator.com/item?id=23902730">thread link</a>) | @fanf2
<br/>
July 20, 2020 | https://emilymstark.com/2020/07/20/certificate-transparency-a-birds-eye-view.html | <a href="https://web.archive.org/web/*/https://emilymstark.com/2020/07/20/certificate-transparency-a-birds-eye-view.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
    <p>Certificate Transparency (CT) is a still-evolving technology for detecting
incorrectly issued certificates on the web. It’s cool and interesting, but
complicated. I’ve given talks about CT, I’ve worked on Chrome’s CT
implementation, and I’m actively involved in tackling ongoing deployment
challenges – even so, I still sometimes lose track of how the pieces fit
together. I find it easy to forget how the system defends against particular
attacks, or what the purpose of some particular mechanism is.</p>

<p>The goal of this post is to build up a high-level description of CT from
scratch, explaining why all the pieces are the way they are and how they fit
together. A lot of this material is drawn from a
<a href="https://web.stanford.edu/class/cs253/lectures/Lecture%2012.pdf">guest lecture</a>
I gave with my colleague <a href="http://noncombatant.org/">Chris Palmer</a> as part of a
Stanford web security course (CT portion starts at slide 52).</p>

<h2 id="why-ct">Why CT?</h2>

<p>Certificate authorities (CAs) are the organizations that browsers trust to issue
certificates for domain names after checking that the person receiving the
certificate really does own their domain. CAs can be companies and governments
or the occasional non-profit. It’s fairly common for CAs to issue bad
certificates. Like any organization, sometimes CAs make mistakes, and sometimes
they are compromised or malicious. And sometimes certificates are issued
improperly without the CA doing anything wrong at all: a rogue insider, BGP
hijacker, or hapless vendor might request a certificate for a domain they do not
own.</p>

<p>The security community has invented various mechanisms to prevent browsers from
accepting these “misissued” certificates. For example, server operators could
once use
<a href="https://en.wikipedia.org/wiki/HTTP_Public_Key_Pinning">public key pinning</a> to
limit the CAs that could issue certificates for their domains, so that not just
any CA compromise would put them at risk. (Unfortunately, pinning turned out to
be a giant footgun, never gained widespread adoption, and is currently dying a
slow death.)</p>

<p>Preventing browsers from accepting misissued certificates is only one part of
the puzzle, though. It’s also important to detect misissued certificates. For
example, in 2011, an attacker hacked the
<a href="https://en.wikipedia.org/wiki/DigiNotar#Issuance_of_fraudulent_certificates">DigiNotar</a>
CA and improperly issued a wildcard google.com certificate, which they used to
target victims in Iran. While the Google Chrome browser didn’t accept the
certificate due to public key pinning, Google only
<a href="https://slate.com/technology/2016/12/how-the-2011-hack-of-diginotar-changed-the-internets-infrastructure.html">found out</a>
about the attack by chance because a user posted about the error on a help
forum. This was a close call: would anyone have ever learned about this attack
if that one user hadn’t happened to report it?</p>

<p>Thus was born the desire for a technical means of detecting misissued
certificates. If a domain owner can detect an unauthorized certificate for their
domain, they can revoke<sup id="fnref:1"><a href="#fn:1">1</a></sup> the misissued certificate. If the misissuance happened
because a CA misbehaved, the domain owner can report the incident to a browser
or OS vendor, who might choose to no longer trust the CA to issue certificates.</p>

<p>An unauthorized certificate for a domain isn’t the only type of misissuance. CAs
might create certificates that are bad because they use outdated cryptographic
algorithms, violate rules like the maximum lifetime of a certificate or specific
encodings that are supposed to be used, etc. If browser vendors could detect
these types of misissuances (which are not necessarily malicious, but signs of
bad hygiene), they could ask the CAs to fix these problems or even remove trust
in them if appropriate.</p>

<h2 id="a-strawperson-and-a-slightly-less-strawperson">A strawperson and a slightly-less-strawperson</h2>

<p>The very simplest attempt to allow detection of bad certificates would be to
require that CAs publish a list of every certificate they issue. They could
either directly publish their certificates themselves, or forward them to some
other service that publishes them. Domain owners could monitor every CA’s
published certificates for unauthorized certificates, and browser
vendors/researchers/etc. could monitor each CA for bad hygiene.</p>

<p>But the root problem we are trying to solve is that CAs might be compromised,
malicious, or error-prone, so we can’t just rely on CAs to publish their own
issuances. An evil CA issuing an evil certificate would simply not publish that
certificate.</p>

<p>In a slightly more robust system, CAs could submit each issued certificate to a
publisher. The publisher would return a signature on the certificate, and
provide a publicly accessible feed of certificates that it has seen. Browsers
would only accept certificates that come with a signature from a trusted
publisher. This is a little closer to what CT looks like, but there are still a
number of problems to solve.</p>

<h2 id="signed-certificate-timestamps">Signed Certificate Timestamps</h2>

<p>One minor wrinkle with this publisher signature system is that it takes time for
the CA to submit each certificate to these publishers and verify that it got
logged before issuing the certificate. (As will become clear later on, logging a
certificate can require operations on a large data structure and global write
consensus, which can take minutes or hours.) CAs don’t want other services’
potentially slow operations in the critical path of certificate issuance, which
is their core money-making business operation – and their customers don’t want
this slowdown either, since some web servers rely on fast certificate issuance
to meet business and uptime requirements. So in CT, a signature from one of
these publishers (which is called a CT log) does not actually guarantee that the
log has published the certificate. Instead, the log issues a Signed Certificate
Timestamp (SCT), which is a signed statement that the log has seen the
certificate and promises to publish it within 24 hours of the timestamp it
provides.</p>

<h2 id="trusted-logs"><em>Trusted</em> logs?</h2>

<p>So far, the system we’ve built up is as follows: CAs submit certificates to logs
as they are issued, and the logs return SCTs promising to publish the
certificate within 24 hours. Browsers don’t accept certificates unless they come
with SCTs from trusted logs. Interested parties, such as domain owners or
researchers, can monitor the data that the logs publish for malicious
certificates.</p>

<p>Now the key question is: why should we trust logs? If a CA could be compromised,
malicious, or error-prone, why couldn’t a log be compromised, malicious, or
error-prone too? One could even imagine a log and CA colluding to issue evil
certificates. The designers of CT wanted logs to be untrusted, and this is how
CT gets complicated.</p>

<p>As a simple way to remove trust from the logs, browsers could require multiple
SCTs from different logs per certificate. With this policy, an attacker would
have to compromise multiple logs to prevent an evil certificate from being
published by any of them. In practice, though, it’s difficult to say what
constitutes distinct logs. If the same organization controls multiple logs and
is colluding with the attacker, a multiple-log policy doesn’t help. Chrome
currently deploys CT with a “One Google, One Non-Google” policy: each
certificate must come with at least one SCT from a Google-operated log and one
from a non-Google-operated log, on the premise that it would be difficult for an
attacker to compromise two such logs. This policy, however, was always meant as
a temporary measure until something more technically sound and organizationally
neutral could be put into place.</p>

<p>To understand how to remove trust from the logs in a more technically sound way,
we need to think about a deep question: what does it actually technically mean
to “publish” a certificate? Each log has an API endpoint that produces a feed of
certificates – but, intuitively, providing the certificate on that endpoint to
one client at one particular point in time is not sufficient to have “published”
the certificate. To truly publish the certificate, that endpoint must provide
the certificate to anyone querying it at any time after the log signed an SCT
for the certificate. To verify that the log has truly published the certificate,
we need everyone to efficiently check with everyone else that they’ve seen the
certificate in the feed they’ve received from that endpoint. “Everyone” here
includes end-user devices that are validating TLS certificates, as well as
researchers, browser vendors, domain owners, and anyone else who is interested
in monitoring a log’s feed to look for misissued certificates.</p>

<p>Of course, it’s not practical to ask everyone to maintain the list of all
certificates that each log publishes and check with each other to compare that
the entire sequence matches. That could be billions of devices each maintaining
sets of millions or billions of certificates. Furthermore, some of these
entities might be interested in only a very small subset of certificates; for
example, a domain owner is only interested in monitoring for misissued
certificates for their own domain, and has no interest in doing a lot of work to
help other entities verify that unrelated certificates were properly published.</p>

<p>Imagine that the log could produce a short summary of the sequence of
certificates that it has published. The summary is like a cryptographic hash: if
you can provide a sequence of certificates that produces a given summary, then
it’s infeasible to find any other sequence that produces the same summary.
Unlike a vanilla cryptographic hash, these summaries have two special
properties:</p>

<ol>
  <li>If the log produces a summary, it can then add more certificates and produce
an updated summary, and efficiently prove that these two summaries are
consistent with each other, i.e. the latter summary’s underlying sequence of
certificates is a supersequence of the former’s.</li>
  <li>After adding a certificate, when asked for a current summary of the
certificates it has published, the log can provide an efficient proof that
the summary contains that certificate.</li>
</ol>

<p>This magical summary is all the state that anyone observing the log needs to
keep to be able to verify with everyone else that the certificates they care
about have been published. For example, a web browser validating a TLS
certificate can request a summary and a proof …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://emilymstark.com/2020/07/20/certificate-transparency-a-birds-eye-view.html">https://emilymstark.com/2020/07/20/certificate-transparency-a-birds-eye-view.html</a></em></p>]]>
            </description>
            <link>https://emilymstark.com/2020/07/20/certificate-transparency-a-birds-eye-view.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23902730</guid>
            <pubDate>Mon, 20 Jul 2020 22:51:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Maximum Entropy Intuition for Fundamental Statistical Distributions]]>
            </title>
            <description>
<![CDATA[
Score 81 | Comments 36 (<a href="https://news.ycombinator.com/item?id=23902712">thread link</a>) | @yetanothermonk
<br/>
July 20, 2020 | https://longintuition.com/2020/07/20/max-entropy-intuition.html | <a href="https://web.archive.org/web/*/https://longintuition.com/2020/07/20/max-entropy-intuition.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p>Imagine you wake up tomorrow in an empty white room, <em>a la</em> The Matrix. You don’t remember how you got there. <em>Anything can happen.</em></p>

<ul>
  <li>If Keanu Reeves appears, you’d probably think this is related in some way to the Matrix.
    <ul>
      <li>If Keanu appears and then Laurence Fishburne (Morpheus) appears, you’d think—okay, this is almost definitely related to the Matrix.</li>
    </ul>
  </li>
  <li>On the other hand, if Obama and Clinton appear in your white room, in your head, you’d think, okay, the Matrix-related possibilities are less likely; the politics-related possibilities are more likely, whatever those are.</li>
</ul>

<p>For the first few seconds in that empty white room, without knowing anything, everything is pretty much equally likely to us. In statistics, we call this a <strong>uniform distribution</strong>. It’s a good starting point when we know nothing. However, once we get new information, we shift probability mass from the less likely events to the more likely events, conditional on what we’ve just learned—in the Neo case, from Obama/Clinton related probabilities to Matrix-related probabilities; in the Obama/Clinton case, from Matrix-related probabilities to political event-related probabilities.</p>

<p>Often, in statistics education, we learn distributions in a vacuum of intuition. But, inevitably, we ask ourselves:</p>

<ul>
  <li>Why do we use the statistical distributions we use? For example, why is the Normal Distribution everywhere?</li>
</ul>

<p>We’ll find that statistical distributions aren’t pulled out of thin air. The statistical distributions we’re most familiar with—uniform, exponential, Normal—are exactly determined when we want to maximize our information gain from very simple and very few initial constraints.</p>

<p>We’ll find that we can use our intuition from the Matrix example to help us understand where these statistical distributions come from!</p>



<p>First, we need some intuition as to what expected information gain means.</p>

<p>Let’s start with the commonplace notion of an “average”. The average, in mathematical terms, is a sum of the value of each event weighted by the probability of that event occurring.</p>

<p>For example, if we have a rigged die with a heavy “six” side, we would expect the next value to be higher than the next value if we used a fair die. The higher frequency of occurrence of sixes pulls up the <strong>expected value</strong> (also known as the <strong>average</strong>, <strong>mean</strong>, or <strong>mathematical expectation</strong>).</p>

<p>Mathematically, what happens is we weigh the value of each event by the probability of that event occurring, and the sum gets us a rough idea of where the next numerical value will land.</p><p>

\[\text{mathematical expectation} = p(x) \cdot x \text{ for all } x \\ = \sum_i p(x_i) * x_i\]

</p><p>This basic concept of weighing things by the probability of those things occurring is a very useful concept. We can also weigh the <em>information gain</em> of an event occurring by the probability of that event occurring to get an expected information value across all the events we care about. But how do we measure information gain?</p>

<p>Intuitively we know that the more surprising something is, the more information it contains. In other words, <em>the informational value of an event is proportional to all the choices it killed off by virtue of that event occurring</em>.</p>

<p>The information value of an event is related to how much probability mass it moves versus itself once that thing occurs.</p>

<h2 id="leverage-can-be-surprising">Leverage Can Be Surprising</h2>

<p>One interesting way to think about this is leverage. Roughly, leverage means how much mass you move versus your own mass. In financial markets, if you outlay $1 million for $5 million of exposure, you’re levered 5 times. For our purposes, we want a good way to formalize our intuitional understanding of information; I haven’t seen information talked about in leverage terms elsewhere and I think it’s an… informative way to look at things.</p><p>

\[\text{leverage} \propto \frac{\text{exposure controlled}}{\text{initial outlay}}\]

</p><p>When we talk about “how much probability mass an event moves” or the amount of choices an event kills by virtue of its occurrence, this is in some sense a leverage ratio. What this looks like is the total amount of probability (normalized, we say 1, but it could just as well be some arbitrary sum, like 10000) divided by the probability of that particular event (p). The 10,000 factor cancels out when we divide the total by the individual probability, so we just get</p><p>

\[\text{info} \propto \frac{1}{p}\]

</p><p>Binary is, in a sense, the ultimate form of compression. Boiling things down to the most informative, basic essence of truth or falsity is a beautiful feature of a bit. We can count the number of bits needed to represent a value by taking its logarithm, base two, so we get</p><p>

\[\text{info} \propto \log_2{\frac{1}{p}}\]

</p><p>And if we weigh this by the probability of that particular event happening, we get</p><p>

\[\text{info} \propto p \cdot \log_2{\frac{1}{p}}\]

</p><p>And if we use the simplified version, we get</p><p>

\[\text{info} = p \cdot \log_2{\frac{1}{p}} \\ = p \cdot (\log_21 - \log_2p) \\ =-p \cdot \log_2p\]

</p><p>Awesome! We’ve built the definition of informational entropy from nothing other than a… bit… of intuition. Similar to our understanding for the mathematical expected value of a set of events, we can talk about the mathematical expected information for a set of events.</p><p>

\[\text{mathematical information expectation} = \sum_i -p(x_i) * \log_2{p(x_i)}\]

</p><p>Why is this useful? It turns out that the major statistical distributions maximize the expected information gain subject to certain constraints (each major distribution corresponding to different constraints).</p>

<p>Stated in a different way:</p>

<p>Take that our goal is to model the probability distribution for data we’re looking at.</p>

<p>We generally know a few things about the data—these will be our constraints—and we want to pick the probability distribution that maximizes our expected information gain (aka, maximizes our subsequent surprise, or <strong>entropy</strong>)—because if we had a distribution that had any less expected information gain than **the maximum entropy distribution, we’ve inadvertently encoded some information extra to our constraints into our distribution.</p>

<p>So the maximum entropy distribution is the closest thing we can get to a zero-knowledge guess, subject to what we know about the data (our constraints).</p>



<p>We found at the beginning of our journey that the uniform distribution—where we prescribe to each event an equal amount of probability mass—makes intuitive sense as the distribution we should pick when we don’t know anything at all. This isn’t saying that everything in reality has equal probability of occurring—a bit subtle; it’s just saying that, <em>given what we currently know</em> (assumed to be nothing), no one event is more likely than any other event.</p>

<p>What if we work from the mathematical end? What do we find if we just start out with very few, very basic assumptions and work forward?</p><p>

\[\text{information, the quantity we want to maximize: } \\ f(x)=-\int_a^b p(x) \cdot \log_2p(x)\,dx \\ \text{unity constraint: }g(x)=\int_a^b p(x)\,dx - 1 = 0\]

</p><p>In English, we want to maximize the information subject to the unity constraint, and we want to see what p(x) looks like.</p>

<p>Mathematically, we’re going to want to find the local extrema (local minima and maxima) of the information function along the unity constraint. Analogous to minimization and maximization in single-variable calculus, we want to find the points at which the derivative of our information function is zero along the constraint function. Intuitively, this should make sense—we want the extrema, and if the slope of the information function is (for example) greater than zero along the constraint, we would just walk along that direction, increasing our expected information gain along the way, all the while getting closer to a local maximum.</p>

<p>Finding where the derivative of f is zero along g is equivalent to saying the directional derivative of f along a vector s that lies on constraint g is zero.</p>

<p>Because the directional derivative of f along that vector s is zero, we know that the projection of the gradient of f on g is zero (aka, the dot product of the gradient of f and g is zero).</p>

<p>Therefore, we know that the gradient of f is parallel to the norm of the surface of g, so the gradient of f is parallel to the gradient of g.</p>

<p>In other words, the gradient of f is some scalar multiple of the gradient of g!</p>

<p>If we find where this occurs, we’ll have found the extrema.</p>

<p>If the above calc-related ideas sounds a bit unfamiliar, ping me at longintuition@protonmail.com so I know that there’s demand for me writing something on gradients.</p>

<p>Anyway, mathematically, we’re trying to do this:</p><p>

\[\nabla f(x) = a \cdot \nabla g(x)\]

</p><p>Which is equivalent to:</p><p>

\[\frac{\partial f}{\partial p(x)} = a \cdot \frac{\partial g}{\partial p(x)}\]

</p><p>Taking the derivative with respect to a function requires a bit of variational calculus, specifically the Euler Lagrange equation. Thankfully, we have some pretty easy functional derivatives here:</p><p>

\[\frac{-1-\ln(p(x))}{\ln(2)}=a \cdot 1\]

</p><p>Let’s simplify! We want to get an expression for p(x):</p><p>

\[-1-\ln(p(x))=a \cdot \ln(2) \\ 1 + \ln(p(x)) = -a \cdot \ln(2) \\ \ln(p(x)) = -1-a \cdot \ln(2) \\ \implies p(x) = e^{-1-a\ln(2)} \\ p(x) =e^{-1} \cdot e^{-a\ln(2)} \\ p(x) = e^{-1} \cdot 2^{-a}\]

</p><p>We’ll plug this expression into our unity constraint:</p><p>

\[\int_a^b p(x)\,dx=1 \\ \int_a^b e^{-1} \cdot 2^{-a} \,dx = 1 \\ e^{-1} \cdot 2^{-a} \cdot \int_a^b \,dx = 1 \\ e^{-1} \cdot 2^{-a} \cdot (b-a) = 1 \\ e^{-1} \cdot 2^{-a} = \frac{1}{b-a}\]

</p><p>This looks like p(x)!</p><p>

\[p(x)=\frac{1}{b-a}\]

</p><p>which is the PDF of a continuous uniform distribution!</p>

<p>This is super promising—the probability distribution that maximizes our surprise given we know basically nothing aside from a unity constraint is the uniform probability distribution!</p>

<p>What we’ve just done is confirm mathematically a very solid intuition we explored at the beginning of the piece!</p>



<p>Very rarely do we know absolutely nothing about the data …</p></div></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://longintuition.com/2020/07/20/max-entropy-intuition.html">https://longintuition.com/2020/07/20/max-entropy-intuition.html</a></em></p>]]>
            </description>
            <link>https://longintuition.com/2020/07/20/max-entropy-intuition.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23902712</guid>
            <pubDate>Mon, 20 Jul 2020 22:49:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Solving Sudoku with Graph Theory]]>
            </title>
            <description>
<![CDATA[
Score 44 | Comments 2 (<a href="https://news.ycombinator.com/item?id=23901678">thread link</a>) | @cypressious
<br/>
July 20, 2020 | https://rakhman.info/blog/solving-sudoku-with-graph-theory/ | <a href="https://web.archive.org/web/*/https://rakhman.info/blog/solving-sudoku-with-graph-theory/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-v-4aeb25cd="" data-v-469b7dbe=""><p>In a game of Sudoku you have to fill the numbers 1 to 9 in a 9x9 grid that is also divided into 3x3 boxes. Each row, column and box must contain each digit exactly once. A game starts with a number of given digits in the grid, and the player can use multiple techniques to deduct the missing digits.</p>
<p>Easy variants can usually be completed by using simple eliminations, i.e. all but one candidate are eliminated from a cell because the column, row or box already contains it. However, harder variants require using more complicated techniques where you eliminate candidates from cells in multiple steps.</p>
<p>Programming a Sudoku solver is not very difficult. Even though Sudokus are known to be <a href="https://en.wikipedia.org/wiki/Mathematics_of_Sudoku#Mathematical_context" target="_blank" rel="nofollow noopener noreferrer">NP-complete</a>, because the <em>n</em> in a 9x9 Sudoku is fairly small, brute forcing a solution can be done in a few seconds. The more interesting task is to write a human-like Sudoku solver that uses human-possible techniques to identify the next move. In this post we'll discuss one technique that can be implemented using a fairly elegant graph algorithm. </p>
<h2 id="the-tuple-technique">The tuple technique</h2>
<p>Consider the following row of a Sudoku. Completed cells contain one big number. The other cells contain remaining <em>candidates</em> as smaller digits. </p>
<p><img src="https://rakhman.info/assets/static/sudoku1.864dc32.853451a027af9f90be5cd6bc004def7b.png" width="593" data-old-src="data:image/svg+xml,%3csvg fill='none' viewBox='0 0 593 79' xmlns='http://www.w3.org/2000/svg' xmlns:xlink='http://www.w3.org/1999/xlink'%3e%3cdefs%3e%3cfilter id='__svg-blur-a5acc91205e16e24254440c26a02a598'%3e%3cfeGaussianBlur in='SourceGraphic' stdDeviation='40'/%3e%3c/filter%3e%3c/defs%3e%3cimage x='0' y='0' filter='url(%23__svg-blur-a5acc91205e16e24254440c26a02a598)' width='593' height='79' xlink:href='data:image/png%3bbase64%2ciVBORw0KGgoAAAANSUhEUgAAAEAAAAAJCAIAAAANXL0tAAAACXBIWXMAAAsSAAALEgHS3X78AAAC9UlEQVQ4y62Ue1PaUBDF/f4fp3ZaZ7QdrCiPqBUQeRgGeT9DJAFCQhL6u1lyJ0Nn%2bld31Fn3nj27Zzf3XiwWi36/P0xtMBiUy%2bVhxohMp9OnpyfTNMfjsQ7O5/NisXh7e5tlGI1GHx8fhmFMJhMwGkwiQY4ASJAUEnO5XKlUgkqDQVKIchTVQbG/GyPx4ng87na7fWqe55GvfbEwDLvd7ufnZxAE%2bojEdrtdqVSEwfP48Xzf32w2nU7ncDickhMwiQQ5AiDEpJBI%2bvv7O06K3IO0bZtyFAW1z1imsZ1mUAKiKDqmFscxyo4ZI8JfBiNNZ4NMtNlsnjHQOuPRGO0Q5EjDJKXRaPR6vSxYxkG5syB21pgwnASgW9jJYbmCcB17mBBhrF4UA2YGkowAOsAJ9l671Vy7W%2bUHga406PfstaPLS4nxsFep1g6hYnh7exMBvpqsLzOi0Gik6urZiw4aE0mtZmM6t4Q2ERCG9UrNNDtKQBRpATffv/zM3Z0JsK1lqfi42W6zAsir/n7uD2eqFT8QBme1vLy8NLuDjIAAZ7WYPhTLEkSAUhvH7VbbKJcK9w%2bfrvrMZId85vl83jAe/UAlIlVWYpTuK/VWRkAUbTcbd7MRn7ZwwvCQu776dVcQHIzbpGma4BsNklnypdIBznwy%2bPrtyt16iQBfhrpz1z9uro3nyjGdH0cqy2yPJjMtoJeUcx3HspaWZbEZJiUCXNddLhaUUwuPY2hl812zmS%2bUo/j43%2b4AapEUJjz6Dig/CDS5vgNRrLL1HZB1nd0BHrF/3IGDqsVhcgdAL5fLVWrMoFarIRqPuJVEHMdhVGjgITqBLIsnhTeER5DNWNZqvV7bifG0vb6%2b8i8Y8AmTcqDlSDBwQE5pHuJqtQqVYlydkHyulHPUTqxVxmAQJ6G1YaD0Bb%2b8x1ZqRGG0MkaEbur1Oryk6SD7fXl5oYMsA%2byz2YxK1FD6UzCJBDlK5VukkFgoFJiC%2blRSMEgRQFEdFDtrDAaU/wHGqU4NfHWAdQAAAABJRU5ErkJggg==' /%3e%3c/svg%3e" data-srcset="/assets/static/sudoku1.864dc32.853451a027af9f90be5cd6bc004def7b.png 593w" data-src="/assets/static/sudoku1.864dc32.853451a027af9f90be5cd6bc004def7b.png" srcset="https://rakhman.info/assets/static/sudoku1.864dc32.853451a027af9f90be5cd6bc004def7b.png 593w"></p>
<p>Cells 1 and 3 of the row can only contain the digits 1 and 9. The two possible solutions are:</p>
<ul>
<li>1 in cell 1 and 9 in cell 3 or</li>
<li>9 in cell 1 and 1 in cell 3.</li>
</ul>
<p>From this we can deduce that the digits 1 and 9 can <strong>never</strong> appear in any other cell in this row. This means we can eliminate the candidates 1 and 9 from cells 7 and 8. From now on we'll mark tuples as colored in cyan, and the cells with possible eliminations colored in purple.</p>
<p><img src="https://rakhman.info/assets/static/sudoku2.aba8b43.e1059c620c9f6afe98904cae3ae746c3.png" width="597" data-old-src="data:image/svg+xml,%3csvg fill='none' viewBox='0 0 597 79' xmlns='http://www.w3.org/2000/svg' xmlns:xlink='http://www.w3.org/1999/xlink'%3e%3cdefs%3e%3cfilter id='__svg-blur-3373d5f8983748651b5c73a2cd1ac44b'%3e%3cfeGaussianBlur in='SourceGraphic' stdDeviation='40'/%3e%3c/filter%3e%3c/defs%3e%3cimage x='0' y='0' filter='url(%23__svg-blur-3373d5f8983748651b5c73a2cd1ac44b)' width='597' height='79' xlink:href='data:image/png%3bbase64%2ciVBORw0KGgoAAAANSUhEUgAAAEAAAAAICAIAAADGAG6IAAAACXBIWXMAAAsSAAALEgHS3X78AAAEJklEQVQ4y31UW1PbVhDmh3Yy01IoONiG9KHTaWn6UghtZ0oTSMydJH1oM3noBci0A8MlUBtfsI1ljA2%2bYMuWZekcHckSBlvSdiURJslkuiPtfNrznT36tLvqYy3y47%2b/TSs7083NaXFrurn1UN5%2bUPgzXTihMmm6JjSblJBENv1Daf1naRs5yPxJ2Hyo7H69uVgpliRZdmiCIIpiq9VKpVKIEXh7MYgAgxhBjEv4KIlSRSy/Gv9H6FcuhpvVIREvfljKf1o5usPVfeRiyAmirw/LXP/ZaSxPmIzpBNcYY/v7%2b/V6vY815VluYxmyS1ZyGY6X7PQKZGaV/brSAgDbtm/9RasR0iPLkF620w7TSq4AN3n00tDaDgfglol5LcuCtwwfMQjvmgF67EECfNAdtcwgWEEbRoH5jPqACGPQC9pWEMygbY%2bC7GOkRJ38lu1lQ5/L5RqNRh8T5ZnM2iIcz/dioU4kdH24BKlHZJcnondMuVzSdMMBzdpjbX8RknPdaOgyjPwlSE8kXrSZhqsKkTku6%2baHWq3W6/UQiEK9VhcQmKZZrVa9hGf5U%2b7kFEHb1iKTsZ4PWOBK9XfJiNEOmvJdvTIgdMeg7b%2bmI5eKv3M9CoKPSucSbmGUcBzXMx0B2WzWFdCUZ7i1ZeDmrw6/L/wxdba2CtzMGwFSqzE/N9cQWq4A/kn7AL/9LN37LvnrI%2bXAqUDiha46FWirLBw%2b9ATwPAowEWys/fX6IOJ9M1TlCTgv5LhcHoFutyOTcWsYqsONRD/390fb2cGyOnJVHhDse3A%2beL51Z%2b/g42QnCKJPkYqyJ%2bDV%2bjrTdFfAyU0FZjNrTkuYiYVubP46tgLpWbLHy00kqYxGIhFJol4FQhoKSC1Zifmr6GIvvgLHKEBjKq6eZI%2bPkmnvFavVmwpwx6loLI6iLLcCXoNVyiXmaXYExMy70B7r0sAl8RvGqCWP6JVBoXsPlMAlDRhKoIPVcCvgCDC73Vg0KlPlvQpsLEJ2wUouQGrBTi1CZubDM1B/rEew2VxOCvlLwE28mQHvM783A7Zr/zcDEwkYhK7fMkfA9Nu2H9Qho/6JCAHojdgY7LlB%2bbObGbCcM6x3ZkBpyU8Of39mxJ%2bS8FMaXiXh51osVNrMlc7amiZ7RgjiTOFkobbzjEWRuYpMOfxcj0/t/MJXa0xVKaWKolBK0GOb4iaMEII3dYHTuy7hxhhlPOE3p7bJV7rwjSyMk8Y4ad1n5S/5zOd5%2bVsNI94l3VcLX5SL6aKmq5gQk2BywzCwNZy/EP724ofRrtHRiNKmDH1H1WslrHNJVXED8Y5XNbVQKDRrdYNpHlOVaVe/fL2zi72hugI85tsCbu0DAhjja/z23rbe00mbUINSnbIO4yU%2bX85r1xrRnSB69UotN8rFUlFTNe993hbwH7TSL274t7MFAAAAAElFTkSuQmCC' /%3e%3c/svg%3e" data-srcset="/assets/static/sudoku2.aba8b43.e1059c620c9f6afe98904cae3ae746c3.png 597w" data-src="/assets/static/sudoku2.aba8b43.e1059c620c9f6afe98904cae3ae746c3.png" srcset="https://rakhman.info/assets/static/sudoku2.aba8b43.e1059c620c9f6afe98904cae3ae746c3.png 597w"></p>
<p>After the elimination, the 19-tuple is still there, but it's not <em>useful</em> anymore because we can't deduce any more eliminations.</p>
<p><img src="https://rakhman.info/assets/static/sudoku1_eliminated.bd6740a.1532f315e5df5db61edbe23b270e7c3b.png" width="600" data-old-src="data:image/svg+xml,%3csvg fill='none' viewBox='0 0 600 79' xmlns='http://www.w3.org/2000/svg' xmlns:xlink='http://www.w3.org/1999/xlink'%3e%3cdefs%3e%3cfilter id='__svg-blur-74dd1e02634693877e8b2be848f175ed'%3e%3cfeGaussianBlur in='SourceGraphic' stdDeviation='40'/%3e%3c/filter%3e%3c/defs%3e%3cimage x='0' y='0' filter='url(%23__svg-blur-74dd1e02634693877e8b2be848f175ed)' width='600' height='79' xlink:href='data:image/png%3bbase64%2ciVBORw0KGgoAAAANSUhEUgAAAEAAAAAICAIAAADGAG6IAAAACXBIWXMAAAsSAAALEgHS3X78AAACgklEQVQ4y51UTXOiQBDN//8Nu/sPUnvJxZNVVrTKLyIqmKyKAgIqCCiCCAh5TMdZpPaS7QPV08y816%2b7Z552u50oikVRxJdLzOx2u2232/1%2bn2VZfDcENU3zfT9N02qw3W4HQZCQXUtDXFEUrOBgSX9Op5Oqqgzwii82gXG9Xo/HYziXCrVpmrZtV6nh4ywQQA1ASgDBTqcD/wm5TqdToOAwvnme4%2bu6LnLlS/piZxRFxd0o2Ov1AFoez0ojnM1mw/dkDBaUlmXRX2ggLsMwZrNZjdpxnOPxWKPG2ZhpxjJJUk79ICBLU8e2HddjKAfP8yiJtzchOEeEQgKiMLRM85qkhELQzn4nCCPKRt/odHYsjjbWjtU4RmlJlDDsv8%2bX8KCTBKRJYpqGz/JG%2bUlAeD4ZpnG5JvBxlqjlqSjJMwLvdrsPAtL4ulaUlapTGdCEkkNXfv745TgeCQjDEI7vujNZCsK4KsDc6OL4q5O6zgTc0t/Pz6PJlObzLqCQJclx/XsHZDjJ9TIcDFZrnQRQ813b6vZ63ikkARgzOPut%2bfrazlgH6gKqfTwcvjoQRWfwBUFY7UBthEiANBl9/Fk8CCiKxfxjpWpshO4C8nLAkjT77giRAN9z5dl7/s8O1AR89w5U4/wOcINIElAF/I87UKMuBeC1abVaeIvwyKBy%2bIJpMplIkgRHZUZBQRDm8zlYdWYIAvfl5WW5XCJjOk7xfr%2bPCPmarsHHnuFwCBCNQpqGcgwGg2aziQSq1HiXoIp28iDOLhaLv5haidloNPBsVC5xhtHKqRgoA40QljzI70DOjILoI38feJxGiEfooYTyGiCSkGW5Rs3vQHUnv8Q1anTgE/ikpWEBGBRdAAAAAElFTkSuQmCC' /%3e%3c/svg%3e" data-srcset="/assets/static/sudoku1_eliminated.bd6740a.1532f315e5df5db61edbe23b270e7c3b.png 600w" data-src="/assets/static/sudoku1_eliminated.bd6740a.1532f315e5df5db61edbe23b270e7c3b.png" srcset="https://rakhman.info/assets/static/sudoku1_eliminated.bd6740a.1532f315e5df5db61edbe23b270e7c3b.png 600w"></p>
<p>This technique isn't limited to pairs. The following image shows a 4789-quadruple (cyan). Accordingly, the candidates 7 and 9 can be eliminated from cells 1 and 3 (purple).</p>
<p><img src="https://rakhman.info/assets/static/sudoku3.4766128.5c324181732642e4652693860b05ee07.png" width="601" data-old-src="data:image/svg+xml,%3csvg fill='none' viewBox='0 0 601 85' xmlns='http://www.w3.org/2000/svg' xmlns:xlink='http://www.w3.org/1999/xlink'%3e%3cdefs%3e%3cfilter id='__svg-blur-add802a2270b11616a5e0f13608d63ba'%3e%3cfeGaussianBlur in='SourceGraphic' stdDeviation='40'/%3e%3c/filter%3e%3c/defs%3e%3cimage x='0' y='0' filter='url(%23__svg-blur-add802a2270b11616a5e0f13608d63ba)' width='601' height='85' xlink:href='data:image/png%3bbase64%2ciVBORw0KGgoAAAANSUhEUgAAAEAAAAAJCAIAAAANXL0tAAAACXBIWXMAAAsSAAALEgHS3X78AAAEjElEQVQ4y9VT%2b1MTVxT2v%2bwv/lAHBBStgm1nOn3MdFpfFbUGUAKSgDhVRLQiGh5GA9lk994khE0IyCNgNpvshoAk5LXZx709d7Mt/gu9c7Jz59zvOznfPd89Rf/n6xT88Fu8PMAJo5gfQa0Iu4XA3BKOYiSg1sIYh7lwYHhZGHFg4REBj0QXhv3jgb%2bnIouTwvwkYvEUz79YnhPCPMIOV0BCFEdeLc3/JfieIQfGkMKcxzc1iU8yEE943%2bOl18/wwkkSACFfMBiEHhA66YfjuFqtxgQEfg0efaVVOozjNh2i0m4cndbS3B6hlq7plmWZhmFRq3xQ3vk622ijZRtWatPMNorPpH5IPx2iK/eaYZfO9%2bv8Xco/ljmtVDUs0zSBbWl6kxL6Yo%2b/2QgMmghgLj3cb/KuZujysnvAamVY9JvC3erSb5mZQYJddkH2JcLA4ZKSV6BVw2AVm80m7EVRlGWZCQj34UqHqX9H9V5qXGFROW9mIzk2IUK1Rh1osK2Va5lvVL2Har3E7KXNXov2UPHS9rXszARNeS1xnCbHiDhM49OFqFnTgKIBuV4n9qx9ufiAIYxRcQxgNOGh8VEr9jOe8FLRSyBp02liWEN3lUXY2MnEOEl6AHCMDooHUARar9UbhLCSGxsb%2bXyeCQj9gWrtVuFiabcrnzq7JZ0v1s9RCWfhqPL50O/3lyt1JqBUy3SrxiW631362LG31SnRy3T14tbv2VeP6Nodae566sW9wvthKk6p2KgyAZgPJlKbLbO%2blVdcpuAhKze3Xt2W5j10ddiM/ogejdL4n8pi3%2b6bG%2bsvB0pBtxG5nV94SGJQ8FZ69sbGywc69lRQcb8IRUpHB%2b8/BHR2n0xALpdzBNTbiXLhcKdTSnfKmfMFEJBBEhyp2cxb31x6LwP76lEVBFiXqNJ9mGzf3u7MMgEXmAC4vOvJ6aurU/dUR4BpC9hX5LCADeIIAIfArV9LPAcBo46ACei1Lz0LGaD3lzi3ge%2bo79x14db269sZ3zXx%2bZcCGrUqF1wu2%2bNdX/9XQPgWqnaY5rfU6KHgDfMKrZ5YiMCY6g2tNQHpogqYZg%2bxesFvjoWuZmce0XWvlRina2Mk4W5ZyBZwCIM//OxMILfSbwhe20JemoCLf2jFfkITzCEkwdwCdJpwa%2bgOs1ASkl5mobVRKnqYhZiA49KRoqq2g76YAHddKJ1uVrvNSpcBUT1nls40P/ESocSwpwXvBvbHnyu7Z3ONTtqClbt0q4vGOj/%2bkpkeoauDunDfQA8M5KL4SZ7Xj%2bsmafGIbujwlmakSJ8WHLKiAGNhYaB8z3sfkIiTAboVcdVCN2TfEAUYK3hfR4M0MnTEFdQCdAJP2H7KBnxTqZTzBvxT73dnP8n%2bfHYxByG/y3/ySbFwTCkosr1yck5RlJ3tnfjz1bxflRZlgEkL8v6HA%2b4JPy0sxItpQV5HuQ0kr2N1MyAKuztpoMhytlWhoKiBGM9JSZz/yGB28NmUZ3YSK5tIdjJwGtwT38SXo%2brWfwUj6ubSZmwtmVQLBTnrFCwWi6FQCP7iH1QlqpjbljhEAAAAAElFTkSuQmCC' /%3e%3c/svg%3e" data-srcset="/assets/static/sudoku3.4766128.5c324181732642e4652693860b05ee07.png 601w" data-src="/assets/static/sudoku3.4766128.5c324181732642e4652693860b05ee07.png" srcset="https://rakhman.info/assets/static/sudoku3.4766128.5c324181732642e4652693860b05ee07.png 601w"></p>
<p>We can generalize the rule by defining a tuple as follows:</p>
<blockquote>
<p>A tuple is a subset of cells in a row, column or box with size <strong>n</strong> that contains <strong>exactly n</strong> distinct candidates.</p>
</blockquote>
<p>So the elimination rule can be defined as follows:</p>
<blockquote>
<p>In a row, column or box with a tuple T, all candidates that are inside T can be eliminated from cells outside of T.</p>
</blockquote>
<p>Furthermore, we define that a tuple T is <em>useful</em> if T shares any candidates with cells outside of T.  </p>
<h2 id="drafting-an-algorithm">Drafting an algorithm</h2>
<p>Let's think of a naive algorithm to find tuples of size n with n distinct candidates. We have to consider tuples of all sizes with all possible candidate combinations:</p>
<pre><code>for each row, column, box
    for each size n between 2 and 8 
        // 1 and 9 don't make sense
        for each subset of the digits 1 to 9 with size n
            for each ... </code></pre>
<p>It is easy to see that our implementation has to involve a lot of nested loops. That's not a problem per se, but I find it hard to visualize it and thus it's not straight forward for me to write down. Instead, let's look at the problem from a different angle.</p>
<p>Consider an undirected graph, where the vertices are the cells of the row, column or box (that don't have a solution filled in). For every two cells that <em>share</em> a candidate, we'll add an edge. Let's look at our first example visualized as a graph:</p>
<p><img src="https://rakhman.info/assets/static/sudoku-graph1.262fba3.a964474d9018de0f0aaf005304ce9f9e.png" width="821" data-old-src="data:image/svg+xml,%3csvg fill='none' viewBox='0 0 821 244' xmlns='http://www.w3.org/2000/svg' xmlns:xlink='http://www.w3.org/1999/xlink'%3e%3cdefs%3e%3cfilter id='__svg-blur-a48166cfe4c168e75b128b3cc7b52f32'%3e%3cfeGaussianBlur in='SourceGraphic' stdDeviation='40'/%3e%3c/filter%3e%3c/defs%3e%3cimage x='0' y='0' filter='url(%23__svg-blur-a48166cfe4c168e75b128b3cc7b52f32)' width='821' height='244' xlink:href='data:image/png%3bbase64%2ciVBORw0KGgoAAAANSUhEUgAAAEAAAAATCAIAAACvEZzQAAAACXBIWXMAAAsSAAALEgHS3X78AAADOElEQVRIx7XXS08iQRAH8Pn%2bX8CjR70ar0aPejHRg5HE%2bMbnIiK4Lr6W/WVKZ9uZYQCXrQNpmnr861/V3UU2%2bq78np%2bM/kGymeCO/r/MGij7niM//foqT09PDw8P9/f33W630%2bn8qBP7FAaDwc9E2DYHmjmB1CbSGA6HIvkUG8perwdHv98fJELh%2bfn5PZeS%2bfunvL290QknqXRz4dOan8fHR2olBsdlktWyHgSL1MuFX2v8WfBuR7wifC8RIHzSgUNNIJ7pOL2%2bvoYtt3d3d1EuxDXkUFMB9oyjuEBgOnKIVrE/DlaaPEOBg13mcAA3a6MqWgCAx6I2jazU1qenp7R9tRY7CGiI8fLyEu2Udk5JQA9vNCVPM2o4fUp2rq%2bvz87OorVqEuD38vKSxtXVlYU0NExJtXrr0aHJpN1us01Jqs0Z4nB%2be3vLlomUmlsrOOJfApi9uLiwSJ1/JMAvHHEc0ekrvXFtF5tiQxDHg/AOWS2pablOTk5w32q1dnd3hTg/P2fbfNvQcYMdHR1tbW35vMmlMMmiW0CBm%2bre3h4l64losCIHvlq56Ao78qlFEzuIp09ze3t7fX398PBQMshqMHHkIsmdnZ3FxcXNzU11xkKh/5EAJar7%2b/urq6sbGxuhJF5cLFUR%2bPj4GFyg19bWVlZW7Kgv/YkJROkODg46uWBqXBT%2bpQebhQbBrDoLZKc4clnRZLz4OZqHgRgORsPjTzMeJpiYK5oExvVD7IgtB/2wtLS0sLCAIxGjVwGqjYLKqAC%2blpeXo4B2/p6B0OPIblx5MMW6%2bQyoGATxOBDo5Vw97ukaSjhwyT/ioYmLpfkQB0Fxgn3GwftyBkIih3YugX6iIIayNDhFLQ%2beoXH3qXr6lU5cdD4BKi6u5jeOlUDgFV1avoUiG6fWrR/v1MQhpCBYGtDEHKEsAvQ/BeLiqUaKrwEo3sRSicbNp9wChiCtUUWVVYeN6efBQlPOxXyB1JhnhrmIHY/XTDOpY4kRfuL5I3ElVrFlo/kJ17CiVhroTyclWZVG1%2bpODLPF/cMqxpbm5LM5oq%2b%2b3MUQCl86ukZu6Y6K4biYW6cfqudZgTn%2b%2b5n%2bz9ofhAjTd/wPZrcAAAAASUVORK5CYII=' /%3e%3c/svg%3e" data-srcset="/assets/static/sudoku-graph1.82a2fbd.a964474d9018de0f0aaf005304ce9f9e.png 480w, /assets/static/sudoku-graph1.262fba3.a964474d9018de0f0aaf005304ce9f9e.png 821w" data-src="/assets/static/sudoku-graph1.262fba3.a964474d9018de0f0aaf005304ce9f9e.png" srcset="https://rakhman.info/assets/static/sudoku-graph1.82a2fbd.a964474d9018de0f0aaf005304ce9f9e.png 480w, https://rakhman.info/assets/static/sudoku-graph1.262fba3.a964474d9018de0f0aaf005304ce9f9e.png 821w"></p>
<p>A <a href="https://en.wikipedia.org/wiki/Component_(graph_theory)" target="_blank" rel="nofollow noopener noreferrer">component</a> is a subgraph where all vertices are connected directly or indirectly. If you start at any cell you can construct the component it's part of using a breadth-first or depth-first search.</p>
<p>We can see that tuples <em>have to be</em> part of a component as they need to share candidates<sup id="fnref-1"><a href="#fn-1">1</a></sup>. But how can we tell if the tuple is <em>useful</em>? Let's ask the opposite question: When is a tuple not useful? If it doesn't share any candidates with another cell, then the tuple must be <em>the whole</em> component. Here's an example:</p>
<p><img src="https://rakhman.info/assets/static/sudoku-graph1_after.8560fc9.dbe97fe18d4799f5a49f399b8b182406.png" width="846" data-old-src="data:image/svg+xml,%3csvg fill='none' viewBox='0 0 846 153' xmlns='http://www.w3.org/2000/svg' xmlns:xlink='http://www.w3.org/1999/xlink'%3e%3cdefs%3e%3cfilter id='__svg-blur-03b60ebedf59d3229099e95d98c4ee17'%3e%3cfeGaussianBlur in='SourceGraphic' stdDeviation='40'/%3e%3c/filter%3e%3c/defs%3e%3cimage x='0' y='0' filter='url(%23__svg-blur-03b60ebedf59d3229099e95d98c4ee17)' width='846' height='153' xlink:href='data:image/png%3bbase64%2ciVBORw0KGgoAAAANSUhEUgAAAEAAAAAMCAIAAABdkSyeAAAACXBIWXMAAAsSAAALEgHS3X78AAACEUlEQVRIx6WWS47CMBBEc/8LcAMkDjAHYA0LZoWQsuH/DSRA%2bGeYJ9co4xAwBnphHKeru6rbsQmulv1YdvWzNyA26g3IDSpwAHyCfgjxZ//oMbBXd7vdcrlMkuR8Pj9Npren0ymOY1BgPdlkWbbdboGs1%2bvL5eLJ/nA4rIwxudMBnCaTSb/fH4/Ho9GIyWazeRoaBt1udzgcgur1etPp9CmE0uA/GAyAMJJIhNzFiqKIRBADxQTx/wKEXCwWvIZ0mqaUB6EQUh8cJcEHz9QYKAjx6GYDA3TiLMh8PkfDI3%2btUyYSsS%2bUSI9MCh1QbsK1Wq12u82uoCGo4hVdzoqmvlMVae50OqCYk4M47vKTGwikG41GGIbMgcDJkQgmEIPet7HIGItSGOiHttIXGH8Zw2M2m0k366uisYJCSBCFSjSbzVqthmyxcQg4Ho84UHicK5VKvV4HzorElxPJ2DPw4S1ZqtUqPWSR8U%2bA2kQI2BOFEbmUBEn6DMr9zTuLDyOh2RVIAqvCOD5HZONJCtUVOAIQ5thCCqtNQSJIMiKpIGC/31NvVmNj6Mt75DC54S/lRLg5Isps8MRNEEZKoI3KhnmUhY2HbNQmxtgaaM6PryAPTTfpgxpKUCL6HIgKJ5TnSarWCUX3fG4GWkSlBGHC2X3/IiOWvp6XbhxBXr1WP0yUo4IP78vc0/%2bvge32XiJ7/Rcr4rn26992uQAAAABJRU5ErkJggg==' /%3e%3c/svg%3e" data-srcset="/assets/static/sudoku-graph1_after.82a2fbd.dbe97fe18d4799f5a49f399b8b182406.png 480w, /assets/static/sudoku-graph1_after.8560fc9.dbe97fe18d4799f5a49f399b8b182406.png 846w" data-src="/assets/static/sudoku-graph1_after.8560fc9.dbe97fe18d4799f5a49f399b8b182406.png" srcset="https://rakhman.info/assets/static/sudoku-graph1_after.82a2fbd.dbe97fe18d4799f5a49f399b8b182406.png 480w, https://rakhman.info/assets/static/sudoku-graph1_after.8560fc9.dbe97fe18d4799f5a49f399b8b182406.png 846w"></p>
<p>If, however, the tuple is part of a bigger component, then it must be useful, i.e. there are candidates that can be eliminated. In our original case, the tuple helps us eliminate us 1 and 9 from the rest of the component.</p>
<p><img src="https://rakhman.info/assets/static/sudoku-graph1_colored.7a5f382.d20250e2b8fbded9a1ce6268eee66188.png" width="794" data-old-src="data:image/svg+xml,%3csvg fill='none' viewBox='0 0 794 220' xmlns='http://www.w3.org/2000/svg' xmlns:xlink='http://www.w3.org/1999/xlink'%3e%3cdefs%3e%3cfilter id='__svg-blur-49ff9d1fa77a96567b4ec7bf44d02793'%3e%3cfeGaussianBlur in='SourceGraphic' stdDeviation='40'/%3e%3c/filter%3e%3c/defs%3e%3cimage x='0' y='0' filter='url(%23__svg-blur-49ff9d1fa77a96567b4ec7bf44d02793)' width='794' height='220' xlink:href='data:image/png%3bbase64%2ciVBORw0KGgoAAAANSUhEUgAAAEAAAAASCAIAAABkTU91AAAACXBIWXMAAAsSAAALEgHS3X78AAAE%2bUlEQVRIx61WWU8bVxT2T%2btLH/rUh/atD1ULISYsJaQvlaKqEkrVJUkrURLCniZRpSjpoqYLpEvUQlmM2ZcgQijYxuOZO/viGc%2bde3pmLnaM8Rho%2b8HD%2bN57zv3Oek8CTgKL0PgMpbRUBa8h8EBjhawMOAUScSpqVoIgcF0Xr/d937IsTdP0GOCWLMukDLkeyFEoilIsFj00vORRn57Jg4m4DSSKjG3bVlUVaRmGYZomkhNFEX/aVXAchxtWwYluQ3fURAx14kVaBPxAk/BGHq4Gbj1iAN/GZEAHozwnjUCK%2bI1uq6wc8Xfk8hqoZaAq9ELFpNMkBh7gXsCYcJMqxtTVEBpQWXAtBwWQMZqBftXL5PCbZzl67jR5icdoBB5ATgK/D8WrCbCTUwWluDG6rQVQqyHBIPxTbH0xv53a27C9Il4uEYK3ohuOa%2bTXBCxAKd0yN8jeGtklpoY/g5jiwxXq%2b%2bhFmSjoBdd2pSVZ%2bEvUszoKAWtYzRG9MDV8mk3nno0/13Z1GtBwkfEIMEiTZ4PGdL8/h/9jxmx6bzMo%2bQ0cw1VuKdlRdQZFbvqzKL5AdupSeSEbigXZlWy%2bR7bbA7cT1It2/juJsoY1E0mbopW7Jlkdvt8Feqd78KXoud5hBHbkXK81OQzLY7B6G9YGYHFAn5IMtUK0LiHRUPq1STw8BisoheKo5LlyEFdqXJNjO/n3ZXoeds5lpt9YkJK61UzzTwpRosSa4IOfuy7Sc7DbcvDT67/ttwheE2QfCJxgYpys3oD54WDh08zPV7a%2bGWGLfUFqqvCUub5br4vjIm5Nipt4bAQWrwuPezYeDpRSNyE9QVaBxmRExI%2bkZLPFK12CbIs0/trvu%2bfzrA2Eq8T0zZJX5/UIGwD44raktju0Gzbf2hl8eWzlzS3oAvGyahftMALfyyv9sDDMFi6n7l74%2btognb8FC49zy5aia0a9Nm/ouDWRWw6lYBHZJ%2b9/0qf/OQBLj8gyeBTiDRCfSE4yKF4Epc0Wkqr9TuC1gXRFyZO8aZj6sadFUzXTNfdnM1ZHye0Cq5OqbbbXBW4HaO/ZmqyFBkzKT3vp7BgsD9H0reIMfvR60%2bvqXmwKRYtr6j4ew8MYuv7izChEcZO3IqoszgB1W1dbbXYJ7r/67dWXPt9JZlkS8kMkLOUgtgAsxSLdBuuCQrs28sodpzsotULhI7kE4RORMGzztjLTB6lBWByCpS/Y3EMpXSqXSBzwwANpvpfNohQWAIqPilOGZVYPAjVANhRoZvTAepsKzVq2iZjNVHxXVzNabW%2btdRgTfhT1Js9pZYUWzUsCuWCRFZnvhu%2bAYmo/SMv3rPRXZvpXsu4UnTj3VwfBduxfxLW7euqOPjehrGeFA0PTsfc36IkoUiCF/CNR/dA2e0rCDVn9W4u2GnVSvC2shD%2bI9LGufuAInylkTa6018RhjwyYbVlFx2lEvJ4pKJXZ33fNsJ7wueEPn3UMmNA482Ci87fMcW3DNCij1V3rSLiOXUTBF6S8IAgBHJFK8B%2bVxA1OzZ%2bVD9MgwMoWJRGHJScCJ41PL5rEV6qniTDdWfmygDUeSLm2cACUZNdxj0slzjQ2Nx62%2bfCHLy6PQ8Weig1x5cGHheqI8XmOT1MvZpByRp1qGj2rGccXsZHz6xF8AlfKwHSSJAndWlnh1lYm3LpD1wnT6P9ixr%2bI4X/U%2bQ8i4s20LfMurQAAAABJRU5ErkJggg==' /%3e%3c/svg%3e" data-srcset="/assets/static/sudoku-graph1_colored.82a2fbd.d20250e2b8fbded9a1ce6268eee66188.png 480w, /assets/static/sudoku-graph1_colored.7a5f382.d20250e2b8fbded9a1ce6268eee66188.png 794w" data-src="/assets/static/sudoku-graph1_colored.7a5f382.d20250e2b8fbded9a1ce6268eee66188.png" srcset="https://rakhman.info/assets/static/sudoku-graph1_colored.82a2fbd.d20250e2b8fbded9a1ce6268eee66188.png 480w, https://rakhman.info/assets/static/sudoku-graph1_colored.7a5f382.d20250e2b8fbded9a1ce6268eee66188.png 794w"></p>
<p>Let's look at one more example. We can see that the 4789-quadruple allows us to eliminate the 9 from the purple vertex as they are part of a component.</p>
<p><img src="https://rakhman.info/assets/static/sudoku-graph2_colored.41e7f26.34afc064d94ea30c3957db1592335c2f.png" width="967" data-old-src="data:image/svg+xml,%3csvg fill='none' viewBox='0 0 967 228' xmlns='http://www.w3.org/2000/svg' xmlns:xlink='http://www.w3.org/1999/xlink'%3e%3cdefs%3e%3cfilter id='__svg-blur-0ca3d0e9f3d486fc088e18419c41b3af'%3e%3cfeGaussianBlur in='SourceGraphic' stdDeviation='40'/%3e%3c/filter%3e%3c/defs%3e%3cimage x='0' y='0' filter='url(%23__svg-blur-0ca3d0e9f3d486fc088e18419c41b3af)' width='967' height='228' xlink:href='data:image/png%3bbase64%2ciVBORw0KGgoAAAANSUhEUgAAAEAAAAAPCAIAAADbBV4wAAAACXBIWXMAAAsSAAALEgHS3X78AAAEqklEQVRIx71WXU8jVRjmL3rvDYkSRaPRxBv1ZmPihcSYLBS2LWi8MhtIVNaogU1gl9W2UNqylC3sykehLf2amTMzZ77OzJzjM3NKbUvJogm%2bTCaHznve8zzv55kQdyCcc/F/ycRdQw%2bCwIvFcRxCiKqqZED0cWIYhuu6cpfv%2b7ci8FqfRQqhwMPDGzXxkcearhMJcHQ6nVar1Wg06vU63l1FUTRVUVVN0yQTSimw8lhA1ccTBizwbdu2LIvGIlnhF%2bYxHh%2bBg4YIvD7iXL4kCSFuVg8cZusmtSjAgYBpmmAy1lREOAwBCzrQhLN7X/kY38FrsANKLrVDl42JAKw0Y4Gtsegt1VLXDfWRYRybvAdg8LuwXKegnTxuPj8zW45BgWzEDCDuk%2bqWdvRSb4RBMBS6MAQAy6CHen1LPSqTc89j40LMX5HG%2bmVpT686nvsPAXirVqvJSGGhaupITtOG1flcVyat9qShTFvKn0RmTN%2bXpmP9oO0kwu20KCW87FbrRZ8jv0L/o1pMBNspUZpj2Q31hQiGXB36waPm7izLJkVxLsj9ou4FzB/yUSieKocwvij2cNAKKThuFNsJVAkSFI6vVqunp6dYgAPyEl6JUpIFTLDWdwqfEoXJg5U3Vs13POUz06JWyCMF/IlAPFOO5sRO2tu5391M8d20lVMsvRf9%2bPQ97QynPrAyX1/8ng52553sud7CF5weWQjFK60%2bz7aXRHFW2Uw623N%2brkJqsdO5dGLTVJJuLhXkYSFpZ2fD3I52HBGAb1BeSK%2b1tbXl5WWUF/igwlA9pmFS0ySUtGYU/wPRec%2bsTXXcj4TyoamcqdSNFJDmtk5X28Ul8fyL8sr7P38zqzxZ8LYvrK4kIAvuiXqUisF9vL4wc/rrA7FbaP/FqKMj/03Do3ameZgWxfvdjXeXv/ry8Cco5PRjSSCMCRzp9ZSfB4dPM9/fKz1MisJjUokIwNMggCzqdrvtdhsLEAhkjvYKnnceav5bojbd%2bePNbT4tOvd0j3lXCRRZz5MTuORbXkjBSaKwRHOGQwcjUNFrs34WDl7082lRSDq5FlUHFS7MzryL9CimnNyiKMx5mWPjsqcQE1AssuggRYuLXn4pLMDaHqn2agAFhLRRYsFisI7lZps4rRmNvO0ZU0z5hJKyPlADkaBpr6qlhJ9dEPkkzRzoF/3y6Kf4mlJOeBkoLNiZp5cHve09gFF7e6a%2bnHcihYST2VQrskh4nwEXmWYFSYjgJFj2N60cxCOi14XQpCSB0a53hdFzPLVE6huXZsccxtYTn/knerNMLqLsH9dnUS7nRntfq7Ysjdku0cnIkEKuNKiyT87rtCuCcGQawq3M8S71bq5eqZodeOTGOXB9LFzFWTDuGdQwiIGaiUo8CMbOEH7Nzsj0iUwxBkzoe4h/r2eEQX9zGGU%2bB0PoqLFggfFimZT74eAoGp3ENw21eJr09sEuAtUf%2b3Jg2Zbt%2bYzFDxRueR0CbmkNzQNFiFHdVaMHEwmliCmOpEBZQgGGZWWOmcT/6qozgkwi6FOSZORwHfxX/iLvP8awyCsDFORbLlgM93qErwOYuKNLorzb3F7%2b8wX2byuprAPYvfWFAAAAAElFTkSuQmCC' /%3e%3c/svg%3e" data-srcset="/assets/static/sudoku-graph2_colored.82a2fbd.34afc064d94ea30c3957db1592335c2f.png 480w, /assets/static/sudoku-graph2_colored.41e7f26.34afc064d94ea30c3957db1592335c2f.png 967w" data-src="/assets/static/sudoku-graph2_colored.41e7f26.34afc064d94ea30c3957db1592335c2f.png" srcset="https://rakhman.info/assets/static/sudoku-graph2_colored.82a2fbd.34afc064d94ea30c3957db1592335c2f.png 480w, https://rakhman.info/assets/static/sudoku-graph2_colored.41e7f26.34afc064d94ea30c3957db1592335c2f.png 967w"></p>
<p>With this knowledge at hand I found it relatively easy to write down the algorithm. Here's how it could look:</p>
<pre><code>for each row, column, box C
    let g be a graph where cells in C are vertices
    
    for each cell c1 in g
        for each cell c2 in g
            if c1 and c2 share a candidate
                create an edge between c1 and c2

    while g is not empty
        let comp be any component in g
        
        for each subset s of comp
            if size of s == number of distinct candidates in s
            and size of s &lt; size of comp
                return s  

        remove all vertices in comp from g</code></pre>
<p>You can find my own implementation of the algorithm on <a href="https://github.com/cypressious/vue3-sudoku-solver/blob/master/src/logic/strategies/tuples.ts" target="_blank" rel="nofollow noopener noreferrer">Github</a> and the runnable application at <a href="https://sudoku-solver.rakhman.info/" target="_blank" rel="nofollow noopener noreferrer">sudoku-solver.rakhman.info</a>.</p>

<p><sup id="fnref-1"><a href="#fn-1">1</a></sup> Technically, we can construct pseudo tuples that aren't connected where each cell only has one candidate, but then we could immediately enter the digit into that cell.</p>
</div></div>]]>
            </description>
            <link>https://rakhman.info/blog/solving-sudoku-with-graph-theory/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23901678</guid>
            <pubDate>Mon, 20 Jul 2020 20:42:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why I no longer host my emails myself]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 2 (<a href="https://news.ycombinator.com/item?id=23901516">thread link</a>) | @jlelse
<br/>
July 20, 2020 | https://jlelse.blog/thoughts/2020/07/no-email-selfhosting/ | <a href="https://web.archive.org/web/*/https://jlelse.blog/thoughts/2020/07/no-email-selfhosting/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Recently, there has been a lot of talk in my blog bubble about email self-hosting again (here is <a href="https://www.paritybit.ca/blog/a-month-and-a-half-of-self-hosted-email" target="_blank" rel="noopener">one example</a>, here is a <a href="https://www.garron.blog/posts/host-your-email-server.html" target="_blank" rel="noopener">second one</a>). I myself <a href="https://jlelse.blog/thoughts/2019/mail-server/">switched to a self-hosted mail server</a> over a year ago, only to <a href="https://jlelse.blog/micro/2020/02/migrated-mailcow/">switch back to a hosted version</a> a few months later.</p><p>For me there were no technical problems running <a href="https://mailcow.email/" target="_blank" rel="noopener">Mailcow</a>, I was even quite happy with my setup. Nevertheless I switched because I realized that email is a topic where it’s not really worth hosting it myself. Neither is it much cheaper, nor does it bring me many other advantages. Both <a href="https://www.fastmail.com/" target="_blank" rel="noopener">Fastmail</a> in the past and the <a href="https://www.servercow.de/mailcow" target="_blank" rel="noopener">Hosted Mailcow</a>, where I have my emails now, are completely sufficient for my needs.</p><p>I don’t have to take care of anything myself and just have to make sure that the monthly automatic money withdrawal works successfully. No more updates, no more worries about my server suddenly going down and the backups not working. Someone else with probably more knowledge will take care of it now. And by having my emails hosted by the developer of the open source project mailcow, I support that others still have the easy possibility to host their emails themselves. And of course my emails are stored on a server in Germany and <a href="https://jlelse.blog/thoughts/2019/email-own-domain/">I use my own domains</a> to send and receive emails.</p></div></div>]]>
            </description>
            <link>https://jlelse.blog/thoughts/2020/07/no-email-selfhosting/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23901516</guid>
            <pubDate>Mon, 20 Jul 2020 20:24:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I asked GPT-3 to make a presentation for me]]>
            </title>
            <description>
<![CDATA[
Score 146 | Comments 96 (<a href="https://news.ycombinator.com/item?id=23901059">thread link</a>) | @bemmu
<br/>
July 20, 2020 | http://www.bemmu.com/gpt3-presentation | <a href="https://web.archive.org/web/*/http://www.bemmu.com/gpt3-presentation">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">
			<div id="posts">
	
				<article>
					<header>	
						<section>
							<time pubdate="pubdate" datetime="2020-07-20">2020-07-20</time>
						</section>
					</header>
					

					<div id="droparea"><p>I told GPT-3 I would be presenting at a Hacker News meetup in Japan, and asked it to generate a presentation for me. Here's what it came up with, read by yours truly.</p>
<iframe width="560" height="315" src="https://www.youtube.com/embed/vZalOEmdHFo" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>

<p>There's also a tweet-sized version <a href="https://twitter.com/bemmu/status/1285284131656445952">here</a>, and the slides are also on SlideShare <a href="https://www.slideshare.net/bemmu/this-presentation-was-generated-by-gpt3">here</a>.</p>
<h2>Details</h2>
<p>I used the <a href="https://openai.com/blog/openai-api/">OpenAI API</a> to generate one slide and one image caption at a time, asking GPT-3 about three times for each and picking the best output. When it generated image caption, I would go online to find a matching image, or if none was available I'd try to splice up an image using <a href="https://www.photopea.com/">Photopea</a> and <a href="https://www.remove.bg/">Remove.bg</a>.</p>
<p>My starting prompt was:</p>
<pre><code>A presentation was given at the Hacker News event in Kansai. 
The title of the presentation was
</code></pre>
<p>When it generated bullet points, I let it generate several and then picked the best 5 out of what it came up with. Once it generated a slide, I edited that into the prompt as well so it could continue generating more slides for the same presentation, and re-ran it to generate the next slide. </p>
<p>Piecewise concatenated output from OpenAI:</p>
<pre><code>"Strategies for Learning to Code in Japan" and the subtitle was 
"Fairly easily and rather effortlessly achieve practical software 
development skills."

The first presentation slide had a picture of a man playing a violin 
in front of a wall of violins, and the title of the slide was "Violin 
skills are of almost no value". Text under the slide said: "a metaphor 
for how useful programming ability can be for starters".

The next slide suggested a number of strategies for how to best use 
ones time to achieve productivity quickly:

1. Nobody figures out how to code perfectly their first time.
2. It's mostly luck.
3. Learn just the right skills, in the right order.
4. Avoid perfectionism.
5. Not doing something is sometimes the best way to learn something.

The next slide had a picture of a monkey drawn in crayon, and
and the words "All problems are pretty much the same." written 
under the monkey drawing. The text of that slide was:
"Not only are all software development problems more or less 
the same, but the best way to solve them is usually so simple, 
that a monkey could do it."

The next slide had a picture of a monkey, a sand hourglass, 
and a spoon and the words "Let's get started then!" written 
under it.

The text of that slide was: "Just like a monkey makes sand castles 
with an hourglass, all our time is of limited duration, so let's get 
started to code a product for clients. Software development is 
actually a bunch of often complicated problems. But that's not a big 
deal, is it!?" and the color of the text was red.

The next slide had a picture of a happy architect with a blueprint 
in one hand and blue pencil in the other hand, standing in front of a 
huge complex, and the words "Looking smart is the social norm".

The text of that slide was:
"Almost all developers feel the pressure (for whatever reason) to have the
look of the competent coder, most likely due to peer pressure. So it might
be counter-productive to cut corners during the development phase." and
the color of the text was purple.

The next slide had a sign: "DANGER do not enter" and this text under it: 
"If you don't need your code to run during actual product development, 
stuff it in a module in a separate directory." The color of the text 
was orange.

The next slide just had the text: Richard Feynman was reported to have 
said: "What I cannot create, I do not understand," something that has 
been paraphrased in the programming world as "If you don't regularly turn 
code into poetry, you probably aren't a good programmer."

The next slide had a picture of a happy runner and this sentence next 
to it: "If you've written 500 lines of code and have an actual working 
program that doesn't crash, sprint to the finish line." 
and the color of text was green.

The next slide had a picture of a swordsman catching a bullet and 
this text: "A happy ending to all of our code." and the color of 
text was yellow. The text of the slide was: "So you built a program
and it worked in like 10 minutes. All your code was beautiful." 
and the color of text was blue.

The final slide had the title of the presentation: "Why you should 
always code like it's your last day on Earth". Next to it was a picture 
of a person with their whole life ahead of them staring into a terminal, 
a ball and chain attached to each leg, and a long nose and a beard. The 
text of the slide was:
"If you always think like it's the last day on Earth (your last day coding), 
it'll push you just enough to get you to finish whatever you might need 
to finish."

The last remark at the last slide of the presentation was:
"So now that you know it's impossible to not 
learn to code, go write something, anything.
So stop writing nuclear missile designs, or the best 
ad blocker ever, and just get started on whatever.

The next slide had the text "And then when you finally do finish this nice 
feature, you should always make sure you drink the required amount of alcohol." 
with a background image of whiskey bottles. The decorative text on that slide 
was: "But don't drink too much alcohol and end up like me."

And the concluding remark of the presentation:
"So basically just go ahead before you wake up in a cold sweat from a scary 
dream about the future, coding-less, uh, eating those annoying squares of tofu."
The background image of that slide was a plate of tofu next to a glass of beer
and the font color was orange to emphasize the suggestion to drink.
</code></pre></div>

				</article>
	
			</div>
			
		</div></div>]]>
            </description>
            <link>http://www.bemmu.com/gpt3-presentation</link>
            <guid isPermaLink="false">hacker-news-small-sites-23901059</guid>
            <pubDate>Mon, 20 Jul 2020 19:29:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Principles for great product managers]]>
            </title>
            <description>
<![CDATA[
Score 207 | Comments 84 (<a href="https://news.ycombinator.com/item?id=23900783">thread link</a>) | @AlexDReeve
<br/>
July 20, 2020 | http://reeve.blog/blog/principles/ | <a href="https://web.archive.org/web/*/http://reeve.blog/blog/principles/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><main id="genesis-content"><article itemscope="" itemtype="https://schema.org/CreativeWork"><div itemprop="text">
<p><strong>Edit 07.20.20:</strong><br>This post was #1 on <a href="https://en.wikipedia.org/wiki/Hacker_News">Hacker News</a> today, which did 2 things: First, it crashed this site (sorry, won’t happen again). Second, it catalyzed some great dialogue <a href="https://news.ycombinator.com/item?id=23900783">here</a>. If you’d like to continue the conversation, hit me up on <a href="https://twitter.com/AlexDReeve">Twitter</a>.</p>



<hr>



<p>A few years ago, I read&nbsp;<a rel="noreferrer noopener" target="_blank" href="https://amzn.to/2C4RbBY">Principles</a>&nbsp;by Ray Dalio, and I became enamored with the concept of codifying my own. So, I borrowed the idea and started noting them down.</p>



<p>This list—pieced together over the past few years—reflects what I believe are some of the most important principles for product managers. I can’t claim credit for inventing these; they are the summation of what I’ve learned through experience, coaching, and osmosis. This list wouldn’t exist if not for the incredible people I’m fortunate to work with and from whom I’ve learned so much.</p>



<p><strong><strong>Product Management is a broad function, so I’ve tried to distill this down to the top 3-4 across 6 categories:</strong>&nbsp;</strong>These principles are very much a “living” list. I don’t intend for this list to be exhaustive—nor does it reflect the entire scope of the product manager role—and these principles will continue to develop over time.</p>



<h3>Leading Your Team</h3>



<p><strong><strong>1.</strong>&nbsp;<strong>Your team should be able to repeat the vision, goal, and value</strong>. </strong>If your team can’t, you probably haven’t communicated it enough or aren’t aligned.</p>



<p><strong>2. You should know what game you’re playing, and how you keep score</strong>. Credit to Adam Nash for this framing, see here for his <a href="https://adamnash.blog/2011/12/16/be-a-great-product-leader/">fantastic article</a>.</p>



<ul><li><strong>The game you’re playing:</strong> Your vision for the product, your product’s value to the customer, your competitive advantage, and how you’ll win.</li><li><strong>How you’ll keep score</strong>: What does winning mean? How will you measure success? What’s your “compass” to tell whether you’re traveling in the right direction?</li></ul>



<p><strong><strong>3. Your team should know the path to reach the goal.&nbsp;</strong></strong>You need not detail execution to the point of false precision, but you and your team must understand the high-level milestones. If the milestones aren’t clear because of unknows, these unknowns should be explicit.</p>



<h3>Making Decisions</h3>



<p><strong>4. Decisions should be documented, explained, and widely communicated</strong>. It should&nbsp;<em>feel&nbsp;</em>like over-communication. If you don’t feel like you’re over-communicating, you probably aren’t communicating enough.</p>



<p><strong>5. Decisions, and what you prioritize, need evidence.&nbsp;</strong>It’s your job to make sure this evidence exists. Inevitably, you will base some decisions on your judgment in place of data. Judgment-weighted decisions are okay, provided it’s explicitly communicated.</p>



<p><strong>6. Stakeholders should be involved early and often, and alignment should be explicit.&nbsp;</strong>You’re looking for either a “yes, I agree with this decision, or a “no, I disagree, but I can commit to moving forward.” Escalate quickly and cleanly to resolve misalignments.</p>



<h3>Communication Effectively</h3>



<p><strong>7. There is no such thing as over-communication.</strong> “Fluff” communication = enough communication.</p>



<ul><li>If you’re not sick of saying it, you probably aren’t saying it enough. Constant communication might feel like “fluff,” but it isn’t. Evangelism is a critical part of the role—and it’s your job to make sure the organization is aligned and swimming in the same direction.</li><li>Marty Cagan, in <a href="https://amzn.to/3eMLBS0">Inspired</a>, said it best: <em>Evangelize continuously and relentlessly. There is no such thing as over‐communicating when it comes to explaining and selling the vision. Especially in larger organizations, there is simply no escaping the need for near‐constant evangelization. You’ll find that people in all corners of the company will at random times get nervous or scared about something they see or hear. Quickly reassure them before their fear infects others.</em></li></ul>



<p><strong>8. You, the product manager, should have a uniquely high communication bar.  </strong>Most functions have a primary “output” that isn’t communication: Designers design, engineers code, etc. For you, communication&nbsp;<em>is</em>&nbsp;a primary “output,” and it should be exceptional.</p>



<p><strong>9. You have to own the narrative.&nbsp;</strong>When there’s a narrative vacuum, people will “creatively” fill in the blanks themselves—and you might not like it. Losing control of the narrative can be incredibly disruptive to your team’s ability to deliver.</p>



<h3>Being an Effective Operator</h3>



<p><strong><strong>10.</strong>&nbsp;<strong>Strong relationships enable strong collaboration.&nbsp;</strong></strong>“Have strong relationships” sounds obvious, but the importance of relationships “up,” “down,” and “across” can’t be overstated. Without a solid mix of relationships and credibility, you won’t succeed.</p>



<p><strong><strong>11. Don’t be in the weeds managing every nuance of every project; save this for emergencies</strong>. </strong>Swim in your lane, and give your team space to do their job(s). Focus on:</p>



<ul><li>Setting the goal, i.e., “what game are we playing?” and lead/help the team in figuring out how to get there (milestones, dependencies, alignment, etc.).</li><li>Leading the team. E.g., establish the communication cadence (updates, Slack channels, syncs), meeting rhythm, high-level project milestones, success metrics.</li><li>Don’t pester. Establish the right communication channels upfront, and let your team keep you updated. See “maker’s schedule” under (12).</li></ul>



<p><strong><strong>12. Greatness is achieved in the agency of others</strong></strong>. Product managers follow the “manager’s<a rel="noreferrer noopener" target="_blank" href="http://www.paulgraham.com/makersschedule.html">&nbsp;schedule</a>.”<strong> </strong>Engineers &amp; designers follow the “maker’s schedule.” Help your team be great “makers”—keep them unblocked; respond effectively to unfolding situations.</p>



<p><strong>13. Your job is to create clarity</strong>:<strong> </strong>This is some sound advice that I got early on (thank you, Greg!). As a product manager, constantly think about how you can <em>create clarity</em> for your team: Clearer product requirements, resolving edge cases, answering questions, etc.</p>



<ul><li>If you’re drowning in questions, you probably aren’t proactively communicating effectively, or the product requirements lack clarity. Some questions are natural, so use your judgment.</li></ul>



<p><strong>14. Be on top of your shit.</strong> Until I figure out how to better articulate this, I’ll say it ineloquently as “just be on it.” Know your business, your product, your team, be responsive, communicate relentlessly, make good decisions, own your results, get 1% better every day.</p>



<h3>Managing Your Time</h3>



<p><strong>15. 80% of your role is discovering the right product &amp; driving organizational alignment, and 20% is answering clarifying questions for the “makers” on your team. </strong>Product teams are in a constant cycle of discovery and delivery, which run in parallel: </p>



<ul><li>In an ideal world, engineers are ~80% delivery, ~20% discovery; product managers are ~80% discovery, 20% delivery.</li><li>In large complex organizations, this is a difficult target to achieve, but strive to spend 80% of your time on discovering the right product (ideation, validation, testing, etc.) and communication (driving organizational alignment, creating clarity).</li><li>“Organizational alignment” is an intentionally broad term, including everything from 1-1 meetings to executive strategy reviews to product “deep dives” to all-hands presentations.</li></ul>



<p><strong>16. Ensuring that you have time set aside for strategy and “focus” work is your responsibility. </strong>Getting sidetracked with 1,000 emails and Slack messages is natural, but it can’t be an excuse. Make sure you have time set aside for focused work.</p>



<h3>Running Effective Meetings</h3>



<p><strong>17. Send agenda items beforehand. At the start of the meeting, collect input,</strong> <strong>and align on the goal. </strong>Meetings are expensive; when people are meeting, they often aren’t making. Own the meetings you run, and make sure they’re productive.</p>



<p><strong>18. Use “DAD” to help structure and run meetings</strong>. Most meetings are a mix of Discussion, Actions, and Decisions: Document any decisions, communicate topics of discussion and enumerate any action items.</p>



<p><strong>19. “ABFU,” or Always Be Following Up (terrible, I know).</strong> Make sure you (or someone else) sends notes to all relevant stakeholders within ~24 hours. They don’t need to be perfect, but make sure they exist and that you communicate them.</p>



<p><strong>20. Be deeply curious, and ask the “dumb” questions.</strong> Asking the right questions, even if they seem dumb, is a catalyst for creating clarity. Ask questions openly, in earnest, and let everyone else hear the answer. You probably weren’t the only one with that question.</p>



<h3>Running Projects &amp; Other</h3>



<p><strong><strong>21.</strong>&nbsp;<strong>Every project includes a mix of Discovery, Design, and Delivery (and iteration); you should make sure these run in sequence.&nbsp;</strong></strong>While we expect and&nbsp;<em>desire</em>&nbsp;some overlap, aspire not to make sweeping changes to design during delivery (as an example).</p>



<p><strong>22. Be responsive; if you’re not, you might be holding things up. </strong>As the hub between every other function, and often the decision-maker, you have to keep the wheels greased for your team. One idea: ~2 hours for Slack, ~2 days for email (but much faster for anything urgent).  </p>



<hr>



<h4>Further Reading</h4>



<ul><li><a href="https://amzn.to/3em4Fqi">Principles</a>, by Ray Dalio, which inspired this exercise.</li><li><a href="https://amzn.to/3eMLBS0">Inspired</a> by Marty Cagan. If there’s one book on Product Management you should read, it’s this. At some point, I’ll publish my ~3,000 words of notes from it!</li></ul>

			<!--<rdf:RDF xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
			xmlns:dc="http://purl.org/dc/elements/1.1/"
			xmlns:trackback="http://madskills.com/public/xml/rss/module/trackback/">
		<rdf:Description rdf:about="https://reeve.blog/blog/principles/"
    dc:identifier="https://reeve.blog/blog/principles/"
    dc:title="22 Principles for Great Product Managers"
    trackback:ping="https://reeve.blog/blog/principles/trackback/" />
</rdf:RDF>-->
</div></article></main></div></div></div>]]>
            </description>
            <link>http://reeve.blog/blog/principles/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23900783</guid>
            <pubDate>Mon, 20 Jul 2020 18:56:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: I compiled book recommendations from 1300+ leaders]]>
            </title>
            <description>
<![CDATA[
Score 23 | Comments 4 (<a href="https://news.ycombinator.com/item?id=23900185">thread link</a>) | @vhpoet
<br/>
July 20, 2020 | https://readthistwice.com/people | <a href="https://web.archive.org/web/*/https://readthistwice.com/people">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://readthistwice.com/people</link>
            <guid isPermaLink="false">hacker-news-small-sites-23900185</guid>
            <pubDate>Mon, 20 Jul 2020 17:47:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Bunkerpunk: Short Stories About Bunkers During the Pandemic]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23899998">thread link</a>) | @jamesjyu
<br/>
July 20, 2020 | https://sudowriters.com/anthology/bunkerpunk/ | <a href="https://web.archive.org/web/*/https://sudowriters.com/anthology/bunkerpunk/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
  	<header>
  		<a href="https://sudowriters.com/"></a>
  		<a href="https://sudowriters.com/"><span><span>sudo</span>writers</span></a>
  		
  		<p>SUDOANTHOLOGY VOLUME TWO</p>
  		
  	</header>
  	
    <section id="intro">

  <p>The following stories were crafted in the dismal months of April, May and June, in the unfortunate year 2020. While the theme for this anthology, Bunkerpunk, was chosen in late March, the proceeding months saw real-life bunkers in the news as the world descended further into the persistent, low-grade chaos that has come to define our era. If you happen to be reading this from a bunker, we hope you’re well stocked on cola and emotionally prepared for an alien invasion. May these six works of fiction remain such, at least until you’ve had the chance to finish reading them.</p>

  <p><em>Thea Boodhoo</em></p>

</section>







<section>
	<h2><a href="#indomitable-inc">Indomitable, Inc.</a> by Amit Gupta</h2>
	<p>5 min read • A bunker to stop the zombies becomes anything but.</p>
</section>

<section>
	<h2><a href="#cells">Cells</a> by Thea Boodhoo</h2>
	<p>1 min read • Do you wonder what your cells are doing today?</p>
</section>

<section>
	<h2><a href="#the-dead-do-not-live-underground">The Dead Do Not Live Underground</a> by James Yu</h2>
	<p>11 min read • A coroner and his drone investigate one more bunker.</p>
</section>

<section>
	<h2><a href="#contained">Contained</a> by Elizabeth Menozzi</h2>
	<p>7 min read •&nbsp;The year can't get any worse, so it does.</p>
</section>

<section>
	<h2><a href="#the-secrets-of-facility-oscar-zero">The Secrets of Facility Oscar Zero</a> by Scott Hurff</h2>
	<p>6 min read • A girl shocks her parents when she discovers a long-forgotten chat protocol.</p>
</section>

<section>
	<h2><a href="#432-park-avenue">432 Park Avenue</a> by Sahil Lavingia</h2>
	<p>5 min read • A couple tries to find a way off their rooftop.</p>
</section>



<section id="indomitable-inc" data-author="Amit Gupta" data-title="Indomitable Inc.">
  <h3 id="indombitable-inc">Indombitable Inc.</h3>

  <div>
  <div>
  <p><img src="https://sudowriters.com/assets/amit.jpg"></p><h4>Amit Gupta</h4>
  <p>Amit is a science-fiction writer, optimist, and occasional advisor &amp; investor. More at <a href="http://amitgupta.com/">amitgupta.com</a> or <a href="https://www.twitter.com/superamit">@superamit</a>.</p>  
</div>

</div>

  <p>A month after Mohit moved, bankrupt and alone, into the underground bunker he built for 100, perimeter alarms echoed through the enormous structure for the first time. A lanky, dusty man popped up on the screens, torn-up backpack over one shoulder.</p>

  <p>Mohit pulled a baseball cap over his shaved head. He trotted through wide tunnels and up concrete stairs to the surface. Then he walked to the perimeter fencing, his body tense, his eyes glued to the lone figure. The man seemed unusually nonchalant, as if walking through the Mojave desert to a private compound miles from the closest city was something he did every day.</p>

  <p>“That laser wire up there?” the man asked, squinting up at the fence.</p>

  <p>“It is,” Mohit replied.</p>

  <p>The man observed Mohit for a minute, then asked, “this some kind of cult thing?”</p>

  <p>Mohit shook his head. He considered asking the man who he was, or turning and retreating underground, but found himself happy to be talking to anyone after a month alone. “It’s just a safe place. Safe from disease, dust storms, war, everything we’ve done to mess things up up here.”</p>

  <p>The man nodded thoughtfully, following the miles of laser wire and fencing with his eyes. Mohit waited. The air was dry, hot, and sharp. It felt dangerous, like if you inhaled it too quickly, you’d be rewarded with a nosebleed.</p>

  <p>“What’s it like inside?” the man asked, clearly in no rush.</p>

  <p>“Kind of like a big hotel,” Mohit answered. “But better! Loads of community spaces. Kitchens, movie rooms with great sound, meditation gardens–”</p>

  <p>“Meditation gardens, huh?”</p>

  <p>Mohit shrugged and adjusted his pitch. “Nice beds. Plenty of food, water, and medicine.”</p>

  <p>The man nodded, as if considering an unspoken offer. He looked past Mohit at the gray windowless edifice poking up through the sand. “Those walls–pretty thick…”</p>

  <p>“A meter thick. Mesh-embedded concrete to block radio signals,” Mohit boasted.</p>

  <p>“Zombie-proof?”</p>

  <p>Mohit felt himself blushing. He’d given dozens of interviews since his disastrous appearance on CNBC to announce his project. The one where, in a moment of youthful exuberance, he joked that the walls were so thick, “they’d even keep the zombies out.” The host chuckled, glanced off-screen and pumped his eyebrows, then turned back with a false smile, his teeth bright and sharp. Right away, Mohit knew it was over.</p>

  <p>After that, nobody cared that he’d risked all of his then-considerable fortune to bury 500 bunkers miles outside Berlin, Brooklyn, Buenos Aires, Boise, Cork, Cape town and so many others. It no longer mattered that he’d designed anti-contamination vacuum gaps and positive air pressure between sections and incorporated medical-grade fabricators, self-contained water cycling and food production, and layouts modeled on anthropological studies of successful, peaceful communes.</p>

  <p>Onstage at TED, he’d declared, “when our governments fail to take responsibility, we must rise to the challenge.” They applauded. But what spread were the SNL parodies and viral headlines: “10 Reasons Why Even the Wealthiest Preppers Aren’t Willing to Waste Money on Indombitable’s Zombie-proof Bunker.” The world thought he was a joke.</p>

  <p>Now Mohit squirmed in utility coveralls damp with sweat, the space between his skin and the thick canvas like a sauna. He thought about how much cooler it was down below.</p>

  <p>“So no zombies, then?” the man asked.</p>

  <p>“Just me.”</p>

  <p>A silence unfolded between the men standing on opposite sides of the fence. Each considered the other, the choices made to bring them there, and the options that lay before them. The man with the backpack shifted his weight from one foot to the other, then asked, “what do you got to eat? I’m Henry, by the way.”</p>

  <hr>

  <p>They came alone, then in small clumps. There were homeless men fleeing overcrowded shelters, mothers and fathers with arms full of children and eyes full of fear, trying to outrun the latest outbreak.</p>

  <p>Mohit showed each one around and welcomed them to the community. Henry developed strict quarantine procedures. A UCLA microbiologist, he’d been scorned for sounding the alarm on the rising viral threat and all but ostracized by the scientific community.</p>

  <p>As the geneticists and pharma corps fell a year behind, then two, then ten…as the mutation rate increased and new viruses tore through cities…as politicians implored people to go about their lives while they built shelters for themselves, the people kept coming.</p>

  <p>Then came the calls from would-be buyers from all over the world, offering vast sums for Mohit’s bunkers. Amounts that would have saved his company and reputation, if only they’d come a few months before. Mohit unlocked all the doors instead. What good was money when the world was on fire?</p>

  <p>A few years later, the bunkers filled and sealed shut. Decades passed. New waves of illness, climate catastrophe, and so many deaths.</p>

  <p>Outside, parking lots gave way to forest. Robins and sparrows nested in office drop ceilings, while small mammals took up grocery store shelves. Cities went wild once again.</p>

  <p>Inside, they maintained the hydroponic farms, tended to the sick, cooked together, sang together. Mohit’s empty concrete shells rang with life. He met his wife in the bunkers. Their sons were born here, raised here.</p>

  <hr>

  <p>“Shhhhh, wake up, Mohit,” Sandra said, ruffling her husband’s hair as he leaned against their bedroom doorway, tracing the notches etched into its frame with his fingertips.</p>

  <p>“Couldn’t sleep at all last night,” he said.</p>

  <p>She smiled, slipping an arm around his waist and leaning her head into his shoulder. “I couldn’t either. Thirty years. It doesn’t seem real.”</p>

  <p>They pressed against each other, lost in thought. All through the structure, people murmured excitedly. Viral transmission had fallen for 100 days straight and airborne contaminants were back to normal levels. Today the next phase would begin. One Mohit had never imagined when he’d created this place. The community had voted, and they’d decided to emerge.</p>

  <p>“I wish we didn’t have to leave those behind,” she said, nodding at the notches in the door frame. “I don’t want to forget that Munu and Sam were once that little.”</p>

  <p>“I traced them onto paper,” he said. “We can recreate them above.”</p>

  <p>Their sons met them outside their door, their faces set in wide grins. No longer children, but nervous and jittery just the same.</p>

  <p>Mohit’s heart swelled. This place had taken everything from him and given everything to him. He thought he’d earned his vindication when the bunkers filled. But he’d been wrong. This moment, when their faces met the sun and their feet felt the earth once more, when their sons would see the sky with their eyes for the first time. When they’d have a chance, along with whoever was left, to try again. This was the reason he had built them all.</p>

  <p>As the crowd moved up towards the vivid colors of rock and cactus, and into the startling warmth of the early morning sun, Munu nudged him.</p>

  <p>“Dad,” he said. “You know how we buried ourselves underground, and now we’re slowly rising to live again?”</p>

  <p>“Yes,” Mohit replied.</p>

  <p>“So we’re basically zombies, right?”</p>

  <p>Mohit smirked, nodding. Perhaps he’d just gotten it backwards. The bunkers hadn’t kept the zombies out, they’d kept them in.</p>

</section>



<section id="cells" data-author="Thea Boodhoo" data-title="Cells">
  <h3 id="cells">Cells</h3>

  <div>
	<div>
  <p><img src="https://sudowriters.com/assets/thea.jpg"></p><h4>Thea Boodhoo</h4>

  <p>Thea is a San Francisco based writer of science fiction and other things. You can find her at <a href="https://theaboodhoo.com/">theaboodhoo.com</a> and <a href="https://www.twitter.com/tharkibo">@tharkibo</a>.</p>
</div>
</div>

  <p>I wonder what my cells are doing today.<br>
As I putter from the first room to the second room and back<br>
As I brush my teeth. Did I just brush my teeth?<br>
Nope<br>
It feels like five minutes ago <br>
But it was last night.<br>
I wonder what my cells are doing as I lean into the glass<br>
Skin of my cheek pressed against the cold clear barrier <br>
between the shut-down world and the shut-in<br>
There are seagulls flying out there <br>
As if nothing’s changed<br>
I wonder what my cells are doing as I flip the calendar another month<br>
It’s been three years now<br>
No five<br>
No wait<br>
a thousand<br></p>

  <p>Since the choice<br></p>

  <p>We thought we were so informed <br>
The doctors and I<br>
Bake the breast with X-rays<br>
Keep the appointments<br>
Every six months <br>
An MRI here<br>
A mammogram there<br>
And you can keep the cells.<br>
Well I would have<br>
But no one told the appointments to keep me<br>
And now there are none<br></p>

  <p>I kind of thought 2025 would be better<br></p>

  <p>What are those cells up to now?<br>
Cooking ATP<br>
Weaving DNA<br>
Staying put, behaving<br>
Being good neighbors <br>
Good cells do what they’re told<br>
Just be breast tissue<br>
Nothing more<br>
No need for ambition …</p></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://sudowriters.com/anthology/bunkerpunk/">https://sudowriters.com/anthology/bunkerpunk/</a></em></p>]]>
            </description>
            <link>https://sudowriters.com/anthology/bunkerpunk/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23899998</guid>
            <pubDate>Mon, 20 Jul 2020 17:28:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What about Design?]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23898679">thread link</a>) | @ppjet6
<br/>
July 20, 2020 | https://bouah.net/2020/07/what-about-design/ | <a href="https://web.archive.org/web/*/https://bouah.net/2020/07/what-about-design/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <p>Who around here hasn’t heard about the tragic and inevitable death of XMPP
(eXtensible Messaging and Presence Protocol)? It’s a pretty common topic in
the community and around, often started by users of XMPP themselves missing a
certain feature in one or multiple specific implementations, or users of
alternative solutions. In a way this is my own version of why XMPP is or isn’t
doomed.</p>
<p>To go down this rabbit hole, we first need to set a few definitions. Most of
my readers would probably know what XMPP is, but I feel obligated to provide a
short reminder as it will allow me to highlight specific points I want to talk
about.</p>

<p>XMPP is a communication protocol, that is “nerd” speak to say it’s a language
for applications to use and talk together at a level that the end-user doesn’t
see. An example would be a chat application: your desktop or smartphone app
talking to a server that then talks to another app.</p>
<p>It is defined as a standard at the <a href="https://ietf.org/">IETF (Internet Engineering Task
Force)</a> – a standard being the specification of a protocol
(a document, in this case publicised and accessible by anyone), which allows
multiple products implementing what it describes to be able to work together
in an interoperable way.</p>
<p>Core specifications of XMPP are written so that it is easily extendible
allowing any developer to use custom (XML) elements for their own use, and
optionally write a specification for their new feature for everyone else to
use.</p>
<p>XMPP also defines a client-server-server-client model, where a client can talk
with a server that can then talk with multiple servers before reaching other
clients, thus allowing for <a href="https://en.wikipedia.org/wiki/Decentralization#Technological_decentralization">decentralization</a> – anyone setting up their own
server to be free from restrictions of other operators, and communicating with
the world or part of it.</p>
<p>So there we have it: (IETF) <strong>Standard</strong>, <strong>Decentralized</strong>, and
<strong>Extensible</strong>. These are, I believe, the 3 selling-points of XMPP.</p>
<p>From there tons of features can be implemented and then negotiated (as part of
the extensibility) and many things can change to use newer extensions that
weren’t considered in the core specifications. For example even the
serialization format (words of the language applications talk, originally XML)
can be changed (just as <a href="https://xmpp.org/extensions/xep-0322.html">EXI</a> is doing), and it’s also perfectly
fine to have non-compliant behaviour as long as it has been negotiated by
entities taking part in it. And so on…</p>
<p>The <a href="https://xmpp.org/">XSF</a> (XMPP Standards Foundation, previously known as Jabber Software
Foundation) is the entity that did the original work on the protocol and
submitted it to the IETF. It now has a sheperding role. There is no
requirement that XMPP extensions be brought to the XSF, but it aims to be the
place where technical knowledge around XMPP is gathered, so people can get
better feedback when submitting their new specification. Developers have
already layed out lots of protocol bricks for others to reuse through the XSF.</p>

<p>This is indeed the core of the problem. While extensibility is one of the
strenghs of XMPP, it’s also its main weakness, one of the main points of its
critics. That said, I believe it’s not as bad as they make it look like.</p>
<p>It is true that most applications are incompatible one way or another, with
various degrees of significance, either because they don’t implement the same
set of extensions, or because an author interprets extensions differently,
or simply because of bugs.</p>
<p>For the rest of this article I will leave aside the last two points –
interpretation issues and bugs – as I consider both of them bugs – of
specifications and/or implementations – and bugs happen everywhere and can be
fixed. Generally, determining what is a bug and what is a (unintended?) feature
is where the issue lies.</p>
<p>While there have been attempts within the XSF at defining common sets of
extensions in what is called “Compliance Suites” (currently updated on a
yearly-basis: <a href="https://xmpp.org/extensions/xep-0423.html">2020</a>, <a href="https://xmpp.org/extensions/xep-0412.html">2019</a>, etc.), they have in my opinion
had mild success for the effort it takes the author to gather feedback and
come up with not-so-controversial changes for newer revisions.</p>
<p>What these Compliance Suites don’t take into account so well, despite recent
efforts; and what critics don’t account for either when saying XMPP is
missing X, or that all implementations should do Y, is that it’s not just
about features and protocols.</p>
<p>The process of coming up with a common set of extensions for an implementation
requires a lot more groundwork. This includes figuring out who the userbase
is, and how the experience for it should be, i.e., design. This process should
be applied across a set of implementations, using the same design guidelines and
ensuring interoperability.</p>
<p>It is not enough if somebody using <a href="https://conversations.im/">Conversations</a> on mobile talks to somebody
else using <a href="https://dino.im/">Dino</a> on desktop, even if they both follow the Compliance Suites
for a given year and can then interop on a “basic” level, which to be honest, is
still pretty advanced, they have different design guidelines and there will
inevitably be areas where they differ and some features won’t behave as
expected on the other side. The issue is not that there is no design
guidelines, it’s that they’re not the same.</p>

<p>Multiple solutions following this design process already exist, such as
<a href="https://www.xabber.com/">Xabber</a> and <a href="https://tigase.net/tigase-instant-communication">Tigase</a>. <a href="https://snikket.org/">Snikket</a> is a new addition in this domain. You can
read about its goals <a href="https://blog.prosody.im/introducing-snikket/">in the introduction article</a> or in a
<a href="https://www.reddit.com/r/xmpp/comments/f0el07/can_someone_explain_to_me_whats_the_point_of/fgto5h0/">more detailed explanation</a> from its author. At the time
of writing it is composed of a rebranded <a href="https://prosody.im/">Prosody</a> (server) and Conversations
(client), is entirely based on XMPP and federates with the XMPP network. But
the important part – and also why it deserves a name other than “XMPP” – is
its goal: to provide a server and a (set of) client(s) that interoperate
properly and have common design guidelines that match the expected userbase.</p>
<p>Maybe you’re not part of Snikket’s target, in which case there might someday
be a similar solution that’s more adapted to your use-case. For the more
technical of us who understand the protocol and/or can deal with less unified
designs, it may be ok to continue using our current applications and work
around these issues ourselves. For the mass audiences I believe this is not an
option.</p>

<p>To the question I set to answer at the beginning I say this: Why does it
matter? For whom? My goal is to bring standardization, decentralization, and
extensibility to mass audiences. Not to bring XMPP to them. As explained above
I believe we need product suites with common design guidelines, and they
should include these properties. XMPP has good building blocks but lacks
consorted design.</p>
<p>I want decentralization and standardization to prevent users from being locked
in closed – often also proprietary – silos such as WhatsApp, Hangouts,
Slack, MS Teams, Tik-Tok, or even Signal. And I want extensibility to prevent being
stuck in the past and to adapt to the people’s needs.</p>
<p><em>Comments available on your usual centralized platforms: <a href="https://www.reddit.com/r/xmpp/comments/hun47q/what_about_design/">reddit</a> and <a href="https://news.ycombinator.com/item?id=23898679">HN</a>,
but also <a href="https://post.lurk.org/@pep/104546844162627507">mastodon</a>.</em></p>

      
    </div></div>]]>
            </description>
            <link>https://bouah.net/2020/07/what-about-design/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23898679</guid>
            <pubDate>Mon, 20 Jul 2020 15:21:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Look at Early Japanese Typewriters (2016)]]>
            </title>
            <description>
<![CDATA[
Score 59 | Comments 19 (<a href="https://news.ycombinator.com/item?id=23898649">thread link</a>) | @caust1c
<br/>
July 20, 2020 | https://filthyplaten.com/2016/07/23/__trashed/ | <a href="https://web.archive.org/web/*/https://filthyplaten.com/2016/07/23/__trashed/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		<p><a href="https://filthyplaten.files.wordpress.com/2016/07/olivetti-angle.jpg"><img data-attachment-id="2747" data-permalink="https://filthyplaten.com/2016/07/23/__trashed/olivetti-angle/" data-orig-file="https://filthyplaten.files.wordpress.com/2016/07/olivetti-angle.jpg" data-orig-size="1000,562" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="olivetti angle" data-image-description="" data-medium-file="https://filthyplaten.files.wordpress.com/2016/07/olivetti-angle.jpg?w=300" data-large-file="https://filthyplaten.files.wordpress.com/2016/07/olivetti-angle.jpg?w=700" title="" src="https://filthyplaten.files.wordpress.com/2016/07/olivetti-angle.jpg?w=700" alt="" srcset="https://filthyplaten.files.wordpress.com/2016/07/olivetti-angle.jpg?w=700 700w, https://filthyplaten.files.wordpress.com/2016/07/olivetti-angle.jpg?w=150 150w, https://filthyplaten.files.wordpress.com/2016/07/olivetti-angle.jpg?w=300 300w, https://filthyplaten.files.wordpress.com/2016/07/olivetti-angle.jpg?w=768 768w, https://filthyplaten.files.wordpress.com/2016/07/olivetti-angle.jpg 1000w" sizes="(max-width: 700px) 100vw, 700px"></a><a href="https://filthyplaten.files.wordpress.com/2016/07/fullsizerender.jpg"><img data-attachment-id="2746" data-permalink="https://filthyplaten.com/2016/07/23/__trashed/fullsizerender-7/" data-orig-file="https://filthyplaten.files.wordpress.com/2016/07/fullsizerender.jpg" data-orig-size="3264,566" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;2.2&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;iPhone 6 Plus&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1469299298&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;4.15&quot;,&quot;iso&quot;:&quot;125&quot;,&quot;shutter_speed&quot;:&quot;0.25&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="fullsizerender" data-image-description="" data-medium-file="https://filthyplaten.files.wordpress.com/2016/07/fullsizerender.jpg?w=300" data-large-file="https://filthyplaten.files.wordpress.com/2016/07/fullsizerender.jpg?w=700" title="" src="https://filthyplaten.files.wordpress.com/2016/07/fullsizerender.jpg?w=700" alt="" srcset="https://filthyplaten.files.wordpress.com/2016/07/fullsizerender.jpg?w=700 700w, https://filthyplaten.files.wordpress.com/2016/07/fullsizerender.jpg?w=1396 1396w, https://filthyplaten.files.wordpress.com/2016/07/fullsizerender.jpg?w=150 150w, https://filthyplaten.files.wordpress.com/2016/07/fullsizerender.jpg?w=300 300w, https://filthyplaten.files.wordpress.com/2016/07/fullsizerender.jpg?w=768 768w, https://filthyplaten.files.wordpress.com/2016/07/fullsizerender.jpg?w=1024 1024w" sizes="(max-width: 700px) 100vw, 700px"></a><br>
A little while ago a friend of mine by the name of John Munroe sent me this great little Olivetti 32 ‘Katakana’ typewriter. I’d been keeping an eye out for such a machine for a number of years now, but as you may expect – such typewriters are generally non existent in markets that are available to Australia.</p>
<p>I spoke to John a little while back after he found a Royal that was set up for Japanese somewhere online, and I asked him to keep an eye out for one for my foreign language collection. John lives in Tokyo, and was confident that he’d come across another one pretty quickly.</p>
<p>And quickly he did. It wasn’t long before he managed to get his hands on this magnificent Olivetti Lettera 32. Of all the L32’s I have had, after this guy was cleaned up I found that &nbsp;types nicer than any other machine I have ever owned of this model.</p>
<p>So John Munroe. I owe you heaps, and much more than a huge, huge thank you!</p>
<p><a href="https://filthyplaten.files.wordpress.com/2016/07/olivetti-side.jpg"><img data-attachment-id="2748" data-permalink="https://filthyplaten.com/2016/07/23/__trashed/olivetti-side/" data-orig-file="https://filthyplaten.files.wordpress.com/2016/07/olivetti-side.jpg" data-orig-size="1000,601" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="olivetti side" data-image-description="" data-medium-file="https://filthyplaten.files.wordpress.com/2016/07/olivetti-side.jpg?w=300" data-large-file="https://filthyplaten.files.wordpress.com/2016/07/olivetti-side.jpg?w=700" title="" src="https://filthyplaten.files.wordpress.com/2016/07/olivetti-side.jpg?w=700" alt="" srcset="https://filthyplaten.files.wordpress.com/2016/07/olivetti-side.jpg?w=700 700w, https://filthyplaten.files.wordpress.com/2016/07/olivetti-side.jpg?w=150 150w, https://filthyplaten.files.wordpress.com/2016/07/olivetti-side.jpg?w=300 300w, https://filthyplaten.files.wordpress.com/2016/07/olivetti-side.jpg?w=768 768w, https://filthyplaten.files.wordpress.com/2016/07/olivetti-side.jpg 1000w" sizes="(max-width: 700px) 100vw, 700px"></a><br>
I’m very grateful to John for sending me this machine. Back when I was at high school, we were required to study two languages. Japanese and German. I was far better at German than Japanese, but I have long had a fascination with Japanese &nbsp;culture. My sister also lived there for 10 years and is fluent in Japanese.</p>
<p><a href="https://filthyplaten.files.wordpress.com/2016/07/olivetti-keyboard-overview.jpg"><img data-attachment-id="2749" data-permalink="https://filthyplaten.com/2016/07/23/__trashed/olivetti-keyboard-overview/" data-orig-file="https://filthyplaten.files.wordpress.com/2016/07/olivetti-keyboard-overview.jpg" data-orig-size="1000,562" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="olivetti keyboard overview" data-image-description="" data-medium-file="https://filthyplaten.files.wordpress.com/2016/07/olivetti-keyboard-overview.jpg?w=300" data-large-file="https://filthyplaten.files.wordpress.com/2016/07/olivetti-keyboard-overview.jpg?w=700" src="https://filthyplaten.files.wordpress.com/2016/07/olivetti-keyboard-overview.jpg?w=700" alt="" srcset="https://filthyplaten.files.wordpress.com/2016/07/olivetti-keyboard-overview.jpg?w=700 700w, https://filthyplaten.files.wordpress.com/2016/07/olivetti-keyboard-overview.jpg?w=150 150w, https://filthyplaten.files.wordpress.com/2016/07/olivetti-keyboard-overview.jpg?w=300 300w, https://filthyplaten.files.wordpress.com/2016/07/olivetti-keyboard-overview.jpg?w=768 768w, https://filthyplaten.files.wordpress.com/2016/07/olivetti-keyboard-overview.jpg 1000w" sizes="(max-width: 700px) 100vw, 700px"></a><br>
Katakana is only one piece of Japanese written language, and is often used to articulate English words into Japanese.</p>
<p><a href="https://filthyplaten.files.wordpress.com/2016/07/olivetti-keyboard.jpg"><img data-attachment-id="2750" data-permalink="https://filthyplaten.com/2016/07/23/__trashed/olivetti-keyboard/" data-orig-file="https://filthyplaten.files.wordpress.com/2016/07/olivetti-keyboard.jpg" data-orig-size="1000,509" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="olivetti keyboard" data-image-description="" data-medium-file="https://filthyplaten.files.wordpress.com/2016/07/olivetti-keyboard.jpg?w=300" data-large-file="https://filthyplaten.files.wordpress.com/2016/07/olivetti-keyboard.jpg?w=700" src="https://filthyplaten.files.wordpress.com/2016/07/olivetti-keyboard.jpg?w=700" alt="" srcset="https://filthyplaten.files.wordpress.com/2016/07/olivetti-keyboard.jpg?w=700 700w, https://filthyplaten.files.wordpress.com/2016/07/olivetti-keyboard.jpg?w=150 150w, https://filthyplaten.files.wordpress.com/2016/07/olivetti-keyboard.jpg?w=300 300w, https://filthyplaten.files.wordpress.com/2016/07/olivetti-keyboard.jpg?w=768 768w, https://filthyplaten.files.wordpress.com/2016/07/olivetti-keyboard.jpg 1000w" sizes="(max-width: 700px) 100vw, 700px"></a><br>
The history of the Katakana keyboard dates right back to the late 1800’s. But it really came into existence in the 1920’s &nbsp;when some members of society in Japan were pushing for a simplified or reduced version of the Japanese language. The idea was to use that Katakana syllabary in a gestalt structure that is closer to the structure of European languages. While earlier keyboards were designed with a full set of Katakana glyphs (Kana), later they used dead keys on keyboards to allow the completion of characters.</p>
<p>This Olivetti has a couple of dead keys. Note the placement of the ‘P’ key? Right next to that… On the left, is the first dead key to be found on the keyboard. If found this positioning especially peculiar.</p>
<p><b>But wait..</b></p>
<p>What about the English characters on this typewriter?</p>
<p>Ahhhh yes… Well… That decreases the Kana (Katakana means Fragmented Kana) characters used one this keyboard.. Right?</p>
<p>The thing about katakana is, that it is also used in circumstances where English words are crammed into Japanese language – in the way that in English we italicise foreign language words.</p>
<p>So what does this typewriter do?</p>
<p>John’s suggestions that it is a typewriter that would be in use by telegraph operators to move between Japanese and English is a pretty sound one. Katakana can be used as a simplified Japanese language.</p>
<p><a href="https://filthyplaten.files.wordpress.com/2016/07/fullsizerender2.jpg"><img data-attachment-id="2752" data-permalink="https://filthyplaten.com/2016/07/23/__trashed/fullsizerender2/" data-orig-file="https://filthyplaten.files.wordpress.com/2016/07/fullsizerender2.jpg" data-orig-size="1024,194" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="fullsizerender2" data-image-description="" data-medium-file="https://filthyplaten.files.wordpress.com/2016/07/fullsizerender2.jpg?w=300" data-large-file="https://filthyplaten.files.wordpress.com/2016/07/fullsizerender2.jpg?w=700" src="https://filthyplaten.files.wordpress.com/2016/07/fullsizerender2.jpg?w=700" alt="" srcset="https://filthyplaten.files.wordpress.com/2016/07/fullsizerender2.jpg?w=700 700w, https://filthyplaten.files.wordpress.com/2016/07/fullsizerender2.jpg?w=150 150w, https://filthyplaten.files.wordpress.com/2016/07/fullsizerender2.jpg?w=300 300w, https://filthyplaten.files.wordpress.com/2016/07/fullsizerender2.jpg?w=768 768w, https://filthyplaten.files.wordpress.com/2016/07/fullsizerender2.jpg 1024w" sizes="(max-width: 700px) 100vw, 700px"></a><br>
But it could also be used in a studio to produce Katakana segments for English words on this machine – when the writer was using a different keyboard featuring other kana – Say… Hiragana. But I don’t think so. The push in Japanese society was based around making language more universal. Contentiously, several key developments occurred when there was a push in Japanese society towards using English langauge more universally. Although the by the late 40’s – post World Ward 2, there was also a push towards using French.</p>
<p>Either way, in the 20’s the first Typewriters &nbsp;were being produced based to write a &nbsp;in romanized gestalt structure in Katakana. Just for reference, the company that produced these first machines was Underwood – who Olivetti eventually bought and absorbed into their organization.</p>
<p><b>Let’s not mention Kanji.&nbsp;</b></p>
<p>No… Let’s. Let’s talk about Kanji.</p>
<p>Written Japanese language can be something of a horror to people that grew up outside of Japan. Even inside of it, there’s plenty of things that can – and do – often go wrong. It’s not that romanised languages are perfect – but the diverse structure in Japanese (a problem also shared with Chinese languages) often causes complexities. The positive thing about Kanji is that it allows for quite an efficient expression with more nuance.</p>
<p>So… Like every other language in existence, there’s plenty of people that take a much more puritanical view to their language and many &nbsp;in Japan resisted change. The problem was that there wasn’t much of a way to easily produce written documents on a machine. Considering that the Japanese language has thousands of characters – it obviously wasn’t going to be easily presented on the keyboard unless the keyboard was huge.</p>
<p>Enter item number 2 that is new to my collection. &nbsp;Welcome to the Nippon Type.</p>
<p><a href="https://filthyplaten.files.wordpress.com/2016/07/nippon-angle.jpg"><img data-attachment-id="2751" data-permalink="https://filthyplaten.com/2016/07/23/__trashed/nippon-angle/" data-orig-file="https://filthyplaten.files.wordpress.com/2016/07/nippon-angle.jpg" data-orig-size="1000,628" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="nippon angle" data-image-description="" data-medium-file="https://filthyplaten.files.wordpress.com/2016/07/nippon-angle.jpg?w=300" data-large-file="https://filthyplaten.files.wordpress.com/2016/07/nippon-angle.jpg?w=700" src="https://filthyplaten.files.wordpress.com/2016/07/nippon-angle.jpg?w=700" alt="" srcset="https://filthyplaten.files.wordpress.com/2016/07/nippon-angle.jpg?w=700 700w, https://filthyplaten.files.wordpress.com/2016/07/nippon-angle.jpg?w=150 150w, https://filthyplaten.files.wordpress.com/2016/07/nippon-angle.jpg?w=300 300w, https://filthyplaten.files.wordpress.com/2016/07/nippon-angle.jpg?w=768 768w, https://filthyplaten.files.wordpress.com/2016/07/nippon-angle.jpg 1000w" sizes="(max-width: 700px) 100vw, 700px"></a><br>
Over a century ago the Japanese started producing heavy and lumbering machines that had thousand of typeface characters that operated wtih a feed mechanism which pulled characters out of a grill. It involved moving the carriage over the top of the grill and positioning it above the character and then feeding it upwards to a type hammer that pushed it against the page and the ribbon. It then drops the hammer back, and the character falls back into the grill.</p>
<p>This mechanism improved dramatically in later years, and instead of a moving carriage, the grill floated on a rack which moved under the carriage.</p>
<p>Eventually a character board was put in front of the carriage, allowing the user to type by moving the arm that was connected to the grill, that has a stylus on the end that the user points at a desired character with.</p>
<p>The characters are grouped into syllabary or kana, and kept together in an order that is predictable. As you can see in the photo below such groups are colored to make it easier for the typist.</p>
<p><b>Enter the Nippon Type.&nbsp;</b></p>
<p><a href="https://filthyplaten.files.wordpress.com/2016/07/nippon-front.jpg"><img data-attachment-id="2753" data-permalink="https://filthyplaten.com/2016/07/23/__trashed/nippon-front/" data-orig-file="https://filthyplaten.files.wordpress.com/2016/07/nippon-front.jpg" data-orig-size="1000,605" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="nippon front" data-image-description="" data-medium-file="https://filthyplaten.files.wordpress.com/2016/07/nippon-front.jpg?w=300" data-large-file="https://filthyplaten.files.wordpress.com/2016/07/nippon-front.jpg?w=700" src="https://filthyplaten.files.wordpress.com/2016/07/nippon-front.jpg?w=700" alt="" srcset="https://filthyplaten.files.wordpress.com/2016/07/nippon-front.jpg?w=700 700w, https://filthyplaten.files.wordpress.com/2016/07/nippon-front.jpg?w=150 150w, https://filthyplaten.files.wordpress.com/2016/07/nippon-front.jpg?w=300 300w, https://filthyplaten.files.wordpress.com/2016/07/nippon-front.jpg?w=768 768w, https://filthyplaten.files.wordpress.com/2016/07/nippon-front.jpg 1000w" sizes="(max-width: 700px) 100vw, 700px"></a><b><br>
</b></p>
<p>On the left of the machine is a solid arm that has a black knob that operates the character pulling mechanism. The small black lever next to that is the space bar. This allows the typist to quickly use operate with their left hand, while swinging the arm with the stylus with their right – selecting characters and quickly tapping it in.</p>
<p>The carriage has a large black lever that operates like every other carriage lever. Interestingly, the machine is set up to type right to left with the characters positioned to be read along the page, rather than down it as was traditional. Maybe the Katakana brigade made some in-roads there.</p>
<p>Interestingly, the typewriter also has a group of Roman characters grouped on the machine, allowing the user to type in English – or at use least English word. These are also regarded as Kana – and known as Romaji.</p>
<p><a href="https://filthyplaten.files.wordpress.com/2016/07/nippon-elements_.jpg"><img data-attachment-id="2754" data-permalink="https://filthyplaten.com/2016/07/23/__trashed/nippon-elements_/" data-orig-file="https://filthyplaten.files.wordpress.com/2016/07/nippon-elements_.jpg" data-orig-size="1000,562" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="nippon elements_" data-image-description="" data-medium-file="https://filthyplaten.files.wordpress.com/2016/07/nippon-elements_.jpg?w=300" data-large-file="https://filthyplaten.files.wordpress.com/2016/07/nippon-elements_.jpg?w=700" src="https://filthyplaten.files.wordpress.com/2016/07/nippon-elements_.jpg?w=700" alt="" srcset="https://filthyplaten.files.wordpress.com/2016/07/nippon-elements_.jpg?w=700 700w, https://filthyplaten.files.wordpress.com/2016/07/nippon-elements_.jpg?w=150 150w, https://filthyplaten.files.wordpress.com/2016/07/nippon-elements_.jpg?w=300 300w, https://filthyplaten.files.wordpress.com/2016/07/nippon-elements_.jpg?w=768 768w, https://filthyplaten.files.wordpress.com/2016/07/nippon-elements_.jpg 1000w" sizes="(max-width: 700px) 100vw, 700px"></a><br>
The characters are kept in a smooth moving tray that feels like it is floating under the machine. When the mechanism operatingarm is pulled down on the machine you can feel the tray Bing pulled into alignment to the closest character. Then the mechanism starts and the hammer makes a solid thump as it punches a character piece against the platen. It’s a surprisingly noisy operation. But quick.</p>
<p>To reduce the noise around the typewriter the rear of the machine has a noise deadening bulkhead that is supposed to absorb some of the noise.</p>
<p>But it isn’t anywhere near as fast as typing on a keyboard. The efficiencies that most typewriters produce for writers are all but wiped out by the movement which is more energy consuming than writing Kana by hand by hand.</p>
<p><a href="https://filthyplaten.files.wordpress.com/2016/07/nippon-back.jpg"><img data-attachment-id="2757" data-permalink="https://filthyplaten.com/2016/07/23/__trashed/nippon-back/" data-orig-file="https://filthyplaten.files.wordpress.com/2016/07/nippon-back.jpg" data-orig-size="1000,656" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="nippon back" data-image-description="" data-medium-file="https://filthyplaten.files.wordpress.com/2016/07/nippon-back.jpg?w=300" data-large-file="https://filthyplaten.files.wordpress.com/2016/07/nippon-back.jpg?w=700" src="https://filthyplaten.files.wordpress.com/2016/07/nippon-back.jpg?w=700" alt="" srcset="https://filthyplaten.files.wordpress.com/2016/07/nippon-back.jpg?w=700 700w, https://filthyplaten.files.wordpress.com/2016/07/nippon-back.jpg?w=150 150w, https://filthyplaten.files.wordpress.com/2016/07/nippon-back.jpg?w=300 300w, https://filthyplaten.files.wordpress.com/2016/07/nippon-back.jpg?w=768 768w, https://filthyplaten.files.wordpress.com/2016/07/nippon-back.jpg 1000w" sizes="(max-width: 700px) 100vw, 700px"></a><br>
This machine belonged to a former Australian Journalist that had been living in Japan and working there. I bought this machine off his daughter who was moving house on the day that I arrived to collect it. I can understand the appeal of this machine to a journalist in a foreign country. It would give a great refer ace board to access all the Japanese Kana on, which would make it quicker to learn and access. Obviously it has some great advantages over handwriting for legibility as well</p>
<p>The interesting thing about this machine is that – unlike the lumbering and heavy old &nbsp;Japanese typewriters of the early years, this beast is surprisingly light – weighing less than an Olympia SM4 in its case.</p>
<p>Sadly though, some of the type elements are missing, so the machine isn’t complete. Although interestingly enough, type elements can still be ordered.</p>
<p>Anyway, this is just a brief look at that crazy world that is Japanese typewriting. I hope you found these machines interesting. I’ll have a closer look at both and maybe their history in another post.</p>
<p>Thanks for reading.</p>
			
			
						</div></div>]]>
            </description>
            <link>https://filthyplaten.com/2016/07/23/__trashed/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23898649</guid>
            <pubDate>Mon, 20 Jul 2020 15:19:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Screwed by Lufthansa and the German Government, Saved by PayPal]]>
            </title>
            <description>
<![CDATA[
Score 40 | Comments 19 (<a href="https://news.ycombinator.com/item?id=23898423">thread link</a>) | @ZeljkoS
<br/>
July 20, 2020 | https://svedic.org/travel/screwed-by-lufthansa-german-government-saved-by-paypal | <a href="https://web.archive.org/web/*/https://svedic.org/travel/screwed-by-lufthansa-german-government-saved-by-paypal">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><span data-preserver-spaces="true">The travel and tourism sectors are suffering because of the COVID-19 pandemic, and governments are scrambling to offer subsidies to affected businesses. But, there is little talk on how companies are transferring their costs to citizens, with government approval.</span></p><p><span data-preserver-spaces="true">In this case, the company is Lufthansa, who canceled my May flight from Croatia to Germany three weeks before the flight date. I booked the flight before the pandemic started, so I was a bit relieved. My reason for being in Berlin was valid for entry, but I was to either self-isolate for two weeks or get tested for COVID-19, both a hassle. If Lufthansa decided to cancel the flight and return the money, no problem.</span></p><p><span data-preserver-spaces="true">But that is not what Lufthansa decided. Their <a href="https://svedic.org/wp-content/uploads/2020/07/Lufthansa-cancelation-email.png" target="_blank" rel="noopener noreferrer">cancellation email didn’t mention refunds, but offered flight vouchers instead</a>. As the email was a no-reply email, calling customer support was the only option. Lufthansa’s support representative agreed to issue a full refund. But they said that processing the refund can take up to six weeks, as they are overwhelmed with requests. EU consumer protection law requires refunds for an undelivered product or service to be issued within 30 days, but these are exceptional times, so I agreed. What Lufthansa didn’t agree to was stating that in writing, in a letter or email.</span></p><p><span data-preserver-spaces="true">Six weeks came and passed without a refund. On a second call, Lufthansa’s support representative repeated the story. They are overwhelmed with requests, my refund will be processed in 2-3 weeks, no need to worry, but they will not provide that statement in writing.&nbsp;</span></p><p><span data-preserver-spaces="true">While waiting for their promise, I stumbled across an article explaining my issue as part of a bigger, EU-wide story. Lufthansa was on the verge of bankruptcy and <a href="https://www.theguardian.com/business/2020/may/26/lufthansa-9bn-bailout-german-government-coronavirus-flights" target="_blank" rel="noopener noreferrer">agreed to a €9 billion bailout from the German government</a>. In an effort to save the company, <a href="https://onemileatatime.com/lufthansa-refund-policy/" target="_blank" rel="noopener noreferrer">the German government told Lufthansa that they don’t need to obey EU consumer protection law</a>, and that they don’t need to issue refunds. Lufthansa can issue vouchers for future travels instead. This situation is controversial because:</span></p><ul><li><span data-preserver-spaces="true">The German government is telling a German company they don’t need to follow EU law.</span></li><li><span data-preserver-spaces="true">The German government is playing favorites with one company. Other companies don’t have such luxury during the crisis, both in getting the loan or escaping the laws.</span></li><li><span data-preserver-spaces="true">German tax-payers are giving a large, risky loan to one air carrier.</span></li><li><span data-preserver-spaces="true">With the voucher system, other EU citizens are effectively giving indefinite, interest-free loans to Lufthansa.</span></li></ul><p><span data-preserver-spaces="true">Notice that the procedure of getting a voucher from Lufthansa is much easier than getting a refund. For a voucher, click on the link in the email and fill a form. For a refund, wait on the customer support line. But I am a stubborn person, and I hate vouchers. A few times in my life, given vouchers got unused or companies put restrictions on voucher use. In this case, there is a possibility Lufthansa will go bankrupt, and then their vouchers will be as useful as toilet paper. Wait, that may <a href="https://www.bbc.com/news/world-australia-51731422" target="_blank" rel="noopener noreferrer">come in handy in COVID-19 times!</a></span></p><p><span data-preserver-spaces="true">I was not surprised when three weeks passed and there was no refund. I felt screwed by Lufthansa, the EU, and German politicians. However, there was still one overseas ace up my sleeve I could use.&nbsp;</span></p><p><span data-preserver-spaces="true">I paid for my flight via PayPal, which offers consumer protection on purchases, and I decided to activate it. I didn’t have much hope, as worldwide pandemic cancellations were not typical PayPal disputes. Additionally, I didn’t have much proof except for the cancellation email. Lufthansa didn’t provide a written reply, the flight was erased from the Lufthansa website, and I didn’t record phone conversations.&nbsp;</span></p><p><span data-preserver-spaces="true">But, as soon I made my claim, I realized there is a hidden benefit. When a PayPal claim is created, there is a deadline and a written trail. In this case, Lufthansa was given until July 13th to respond:</span></p><p><a href="https://svedic.org/wp-content/uploads/2020/07/PayPal-deadline.jpg"><img title="PayPal deadline screenshot" src="https://svedic.org/wp-content/uploads/2020/07/PayPal-deadline.jpg" alt="" width="927" height="317" srcset="https://svedic.org/wp-content/uploads/2020/07/PayPal-deadline.jpg 927w, https://svedic.org/wp-content/uploads/2020/07/PayPal-deadline-300x103.jpg 300w, https://svedic.org/wp-content/uploads/2020/07/PayPal-deadline-768x263.jpg 768w, https://svedic.org/wp-content/uploads/2020/07/PayPal-deadline-500x171.jpg 500w" sizes="(max-width: 927px) 100vw, 927px"></a></p><p><span data-preserver-spaces="true">It seems that someone from Lufthansa replied before that, as I got my money on July 7th:</span></p><p><span data-preserver-spaces="true"><a href="https://svedic.org/wp-content/uploads/2020/07/PayPal-case-history.jpg"><img src="https://svedic.org/wp-content/uploads/2020/07/PayPal-case-history-197x300.jpg" alt="PayPal-case-history" width="197" height="300" srcset="https://svedic.org/wp-content/uploads/2020/07/PayPal-case-history-197x300.jpg 197w, https://svedic.org/wp-content/uploads/2020/07/PayPal-case-history.jpg 540w" sizes="(max-width: 197px) 100vw, 197px"></a></span></p><p><span data-preserver-spaces="true">I am impressed by PayPal’s straightforward claims procedure. There was no paper forms or PDFs that I needed to sign. As an example, my friend Chris also got a Lufthansa April transatlantic flight canceled (a month before my trip). He asked Lufthansa for a refund, and to this day he still hasn’t received any of 700 EUR.</span></p><p><span data-preserver-spaces="true">You have all the facts above, so make your conclusions. These are my modest takeaways:</span></p><ul><li><span data-preserver-spaces="true">During a crisis, EU laws get overridden by national interests.</span></li><li><span data-preserver-spaces="true">During a crisis, businesses labeled a “national interest” by politicians get favorable treatment.</span></li><li><span data-preserver-spaces="true">PayPal consumer protection works, even in times of crisis.</span></li><li><span data-preserver-spaces="true">Creating a PayPal or credit company claim is easier than waiting on customer support lines, enforces deadlines, and has traceable communication.</span></li></ul><p><span data-preserver-spaces="true">To come to the beginning of this article, there are analyses of money lost by different business sectors due to COVID-19. It would be interesting to see an analysis of how much consumer money is currently locked in unused vouchers, and what percentage of them will actually get used in the future. For comparison, in normal times, just US consumers </span><a href="https://www.cbsnews.com/news/unused-gift-cards-add-up-to-3-billion-annually/" target="_blank" rel="noopener noreferrer"><span data-preserver-spaces="true">lose up to $3 billion annually in unspent gift cards</span></a><span data-preserver-spaces="true">. It seems that 2020 is going to be an outlier.</span></p></div></div>]]>
            </description>
            <link>https://svedic.org/travel/screwed-by-lufthansa-german-government-saved-by-paypal</link>
            <guid isPermaLink="false">hacker-news-small-sites-23898423</guid>
            <pubDate>Mon, 20 Jul 2020 14:55:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Learn How to Build, Launch and Run a Shopify App]]>
            </title>
            <description>
<![CDATA[
Score 22 | Comments 4 (<a href="https://news.ycombinator.com/item?id=23897934">thread link</a>) | @igrabes
<br/>
July 20, 2020 | https://courses.iangrabill.com/how-to-build-a-shopify-app | <a href="https://web.archive.org/web/*/https://courses.iangrabill.com/how-to-build-a-shopify-app">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://courses.iangrabill.com/how-to-build-a-shopify-app</link>
            <guid isPermaLink="false">hacker-news-small-sites-23897934</guid>
            <pubDate>Mon, 20 Jul 2020 14:02:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A man trying to automate Thailand’s hospitals]]>
            </title>
            <description>
<![CDATA[
Score 34 | Comments 6 (<a href="https://news.ycombinator.com/item?id=23897845">thread link</a>) | @danso
<br/>
July 20, 2020 | https://restofworld.org/2020/the-man-trying-to-automate-thailands-hospitals/ | <a href="https://web.archive.org/web/*/https://restofworld.org/2020/the-man-trying-to-automate-thailands-hospitals/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
			
<p><span>O</span>n a balmy Bangkok afternoon in March 2020, Professor Djitt Laowattana was sitting in his second-floor office in the Institute of Field Robotics (FIBO), <a href="https://www.nytimes.com/2020/02/23/world/europe/italy-coronavirus.html">watching the news</a> out of Italy. Photos of doctors with<a href="https://www.cnn.com/2020/03/21/world/health-workers-doctors-photos-coronavirus-italy-wuhan-trnd/index.html"> faces marked from their masks</a> spread across social media as the country rapidly became the epicenter of Europe’s Covid-19 outbreak. “I told my staff, stop what you’re doing and focus on this,” Laowattana told <em>Rest of World</em>. “I wanted to make sure the same thing doesn’t happen in Thailand.”</p>



<p>His concerns were correct. According to <a href="https://www.icn.ch/news/more-600-nurses-die-covid-19-worldwide">recent estimates</a> by the International Council of Nurses, nearly half a million healthcare workers may have been infected by the virus. Thailand had already confirmed its first Covid-19 death by the end of February, and <a href="https://www.pri.org/stories/2020-02-07/virus-fears-spread-thailand-chinese-tourism-magnet">experts warned</a> that the country could become the next Covid-19 hot spot in the region. Sensing the urgency, Laowattana, who is known as Thailand’s most prolific roboticist, asked his staff to drop working on the 20 or so prototypes they had in various stages in production and focus on helping him create an arsenal to fight what he called “the great virus war.” Together, Laowattana and his team of students and engineers created FIBO Against Covid-19 (FACO), a group of fully autonomous robots designed to protect doctors and nurses on the front lines of the pandemic.&nbsp;</p>



<p>Over the last 20 years, Laowattana has built nearly 300 types of robots for industries ranging from food processing to automobiles, half of which are still used today. His innovations have earned him the moniker “the Godfather of Thai Robotics.” His robots do everything from disinfecting rooms and delivering supplies to remotely monitoring patients’ temperatures and symptoms.</p>



<p>In hopes of rapidly scaling the use of these robots, Laowattana also added 5G connectivity, which will allow hospitals to add as many robots as they need without overloading their systems. “I don’t like the coronavirus,” said Laowattana, “but the pandemic is a fast-forward button.”</p>


		<figure>
			<div>
				<p><img src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/07/GettyImages-1210699444-40x27.jpg" data-src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/07/GettyImages-1210699444-768x432.jpg" data-srcset="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/07/GettyImages-1210699444-400x267.jpg 400w, https://restofworld.org/wp-content/uploads/2020/07/GettyImages-1210699444-600x400.jpg 600w, https://restofworld.org/wp-content/uploads/2020/07/GettyImages-1210699444-1600x1067.jpg 1600w, https://restofworld.org/wp-content/uploads/2020/07/GettyImages-1210699444-2800x1867.jpg 2800w, " sizes="(max-width: 640px) 100vw, 600px(max-width: 992px) calc(100vw - 40px), (max-width: 1140px) calc(100vw - 290px), calc(100vw - ((100vw - 640px)/2))" alt="BANGKOK, THAILAND - APRIL 22: Medical staff wearing PPE work in the acute respiratory illness clinic in Vibhavadi Hospital as they deal with the COVID-19 Coronavirus outbreak on April 22, 2020 in Bangkok, Thailand. The hospital is due to discharge their final coronavirus patient today as numbers of infections continue to drop across the country. The Thai government has imposed a 10pm to 4am curfew and has ordered the closure of entertainment venues, schools and parks in order to curb the spread of the COVID-19 coronavirus across the country. (Photo by Jack Taylor/Getty Images)">
					
				</p>
			</div>
						<figcaption itemprop="caption description">
				
				<span itemprop="copyrightHolder">Jack Taylor/Getty Images</span>
			</figcaption>
		</figure>


<hr>



<p><strong>Since the pandemic</strong> began, hospitals around the world have adopted robots for everything from cleaning hospital wards to allowing patients to socialize with friends and family while quarantined. Recent estimates predict the medical robotics industry will quadruple to <a href="https://www.prnewswire.com/news-releases/surgical-robots-market-growth%E2%80%94-24-4-cagr-up-to-2025%E2%80%94says-global-market-insights-inc-300984546.html">more than $24 billion</a> by 2025, from around $6 billion in 2018. Thailand also faces a shortage of nurses, a problem that’s been exacerbated by the pandemic. Laowattana hopes his robots may be able to lighten their load and allow them to focus on more-critical tasks.&nbsp;</p>



<p>“The genie is out of the bottle,” Robin Murphy, a robotics professor at Texas A&amp;M, told <em>Rest of World</em>. “It’ll get to a point where it’s not going to shock anyone that robots are wandering around a hospital.”</p>



<p>Thailand is keen to develop its medical robots. Last year, the <a href="https://www.mobihealthnews.com/content/thailand-board-investment-help-promote-medical-robotics">government announced</a> an eight-year tax break for manufacturers of medical robots and released statements encouraging hospitals to use medical robots. According to Laowattana, the virus came at a fortuitous moment.</p>



<p>After a month of blueprinting and prototyping, in early April, Laowattana introduced his arsenal to a select group of doctors from Thailand’s most prestigious teaching hospitals. He had two new robots.&nbsp;</p>



<figure><blockquote><p>“I don’t like the coronavirus, but the pandemic is a fast-forward button.”</p></blockquote></figure>



<p>The first was CARVER. Prototyped in FIBO’s headquarters and equipped with ultraviolet lights to disinfect wards as it moves, CARVER looks like a giant Roomba dressed for a rave. The robot’s 18&nbsp;shelves also help carry medicine and other essential supplies to Covid-19 patients. Laowattana hoped CARVER would reduce the amount of exposure for nurses commonly assigned to routine but high-risk tasks.</p>



<p>The crown jewel of Laowattana’s arsenal, however, was SOFA: a 150-centimeter-tall humanoid with a conical lower half that gives it a feminized appearance. Its placid blue and white tones and three protruding high-tech cameras make it look both dainty and unsettling. One camera helps tell a patient’s temperature, while another is used for video conferencing. On its chest, a third high-definition magnifying camera allows doctors to examine a patient’s tongue or eyes without ever having to leave their offices. Like CARVER, SOFA can also be programmed to roam autonomously or controlled from afar.&nbsp;</p>



<p>While most telepresence robots help doctors consult with patients remotely, SOFA’s decked-out sensors also allow doctors to monitor a patient’s vitals. “When the crisis started, we didn’t have any solutions to help us examine patients from afar,” Dr. Sithakom Phusanti, deputy director at Chakri Naruebodindra Medical Institute in Bangkok, told <em>Rest of World. </em>Doctors at Phusanti’s hospital are among the first in Thailand to be able to examine patients in their Covid-19 ward from the comfort of their offices.&nbsp;</p>


		<figure>
			<div>
				<p><img src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/07/1594910343458-small-40x23.gif" data-src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/07/1594910343458-small.gif" data-srcset="" sizes="(max-width: 640px) 100vw, 600px(max-width: 992px) calc(100vw - 40px), (max-width: 1140px) calc(100vw - 290px), calc(100vw - ((100vw - 640px)/2))" alt="">
					
				</p>
			</div>
						<figcaption itemprop="caption description">
				
				
			</figcaption>
		</figure>


<hr>



<p><strong>According to a</strong> study conducted by the University of Edinburgh, hospitals have traditionally been reluctant to introduce robotics in large part due to fears of worker displacement and the negative connotations of robots for healthcare workers and patients alike. To quell some of these anxieties, Laowattana stressed that SOFA isn’t here to take their jobs. His robots have no diagnostic abilities, and when interacting with patients, a doctor is always in the cockpit.&nbsp;</p>



<p>Designing robots to interact with patients also comes with its own set of challenges. While doctors can adopt a good bedside manner when dealing with vulnerable patients, giving a robot the appearance of congeniality requires both design and cultural considerations.&nbsp;</p>



<p>Laowattana created SOFA by redesigning a prototype of a greeting bot for one of Bangkok’s luxury malls. He thought its tiny stature and childlike appearance would help disarm otherwise vulnerable patients. He even tweaked SOFA to operate at 10% of its original speed.&nbsp;</p>



<p>“In Thailand, going fast doesn’t convey good meaning. It’s impolite,” he says. When roaming the wards, SOFA projects two baby-blue eyes and a pixelated smile on a small screen, though it can show a range of positive emotions, from surprise to love. A second screen sits on its waist, allowing doctors to remotely share a patient’s medical records. Its jointed arms and fingers serve no medical purpose, but according to Laowattana, patients would rather communicate with something that looks like themselves. When interacting with patients, SOFA replaces its digital smile with a video of the controlling doctor, reminding patients that a human is still in the driver’s seat.&nbsp;</p>



<p>SOFA robots have become something of a national treasure in Thailand. They have even <a href="https://www.facebook.com/fibokmutt/posts/3139870376075286">earned a nickname</a> from the country’s princess: “<em>Mod Borirkasa</em>,” or “Guardian Ant.”&nbsp;</p>



<p>There are also consequences for culturally inadequate design. In 2018, Bangkok’s Mongkutwattana General Hospital <a rel="noreferrer noopener" href="https://www.thailandmedical.news/news/acute-shortage-of-nurses-in-thailand-forces-hospital-to-turn-to-robot-nurses." target="_blank">met with internet infamy</a> after photos of its robots’ glowing red eyes spread across the web. Purchased from a manufacturer in China, where red is considered an auspicious color, the robots were perceived as menacing in Thailand. “People would joke, if they bring you to our hospital late at night, you better run away,” a doctor who worked at the hospital told&nbsp;<em>Rest of World</em>.</p>


		<figure>
			<div>
				<p><img src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/07/IMG_5910-40x29.jpg" data-src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/07/IMG_5910-768x432.jpg" data-srcset="https://149346090.v2.pressablecdn.com/wp-content/uploads/2020/07/IMG_5910-400x294.jpg 400w, https://restofworld.org/wp-content/uploads/2020/07/IMG_5910-600x440.jpg 600w, " sizes="(max-width: 640px) 100vw, 600px(max-width: 992px) calc(100vw - 40px), (max-width: 1140px) calc(100vw - 290px), calc(100vw - ((100vw - 640px)/2))" alt="">
					
				</p>
			</div>
						<figcaption itemprop="caption description">
				
				
			</figcaption>
		</figure>


<hr>



<p><strong>Despite their initial</strong> hesitance, doctors and nurses at his hospital have responded positively to their new mechanical colleagues, according to Phusanti: “They believe the system can help prevent viral transmission.” So far, none of Phusanti’s staff has been infected by the virus.&nbsp;</p>



<p>But while some doctors have been happy to adopt robotics in the wake of Covid-19, others have said the robots, at their $100,000 price tag, may be untenable for many Thai hospitals. A number of hospitals use cheaper, Chinese-produced robots, in part because they are able to receive them at low costs.&nbsp;</p>



<p>To address this concern, Laowattana has advocated for hospitals to obtain funding from the Thai government to purchase robots throughout the pandemic. While 40 have expressed interest in procuring them — pending government funding — bureaucratic delays have meant that only three hospitals have received the robots so far. The rest are still awaiting their funds to be approved.</p>



<p>Scaling the operation during a pandemic has also proven difficult, as parts have to be sourced from China and Europe. While FIBO was able to make the robots for three hospitals in-house, the institute partnered with Thailand’s Automation and Robotics Association (TARA), a consortium of industrial robotics manufacturers, to build more robots. But due to the pandemic, some essential parts have taken nearly three times longer to arrive. While Laowattana hoped to have the robots in eight more hospitals by the end of the month, such sourcing issues mean they may have to wait even longer.</p>



<p>For now, Thailand has successfully contained the virus. As far as his robots go, Laowattana sees their role expanding to treating other infectious patients, like those suffering from tuberculosis.&nbsp;</p>



<p>Two decades ago, Laowattana was considered a fringe scientist by his peers. But the pandemic has been a bittersweet validation of his life’s work. “I used to tell people that automation will happen over the next five years,” he said, “but today I tell people, it needs to happen now.”</p>
		</div></div>]]>
            </description>
            <link>https://restofworld.org/2020/the-man-trying-to-automate-thailands-hospitals/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23897845</guid>
            <pubDate>Mon, 20 Jul 2020 13:55:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I Manage My Notes]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23897371">thread link</a>) | @peterlk
<br/>
July 20, 2020 | http://peterklipfel.com/blog/taking_notes/ | <a href="https://web.archive.org/web/*/http://peterklipfel.com/blog/taking_notes/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section id="post-body">
                    



<p>I use obsidian for desktop, IA Writer for mobile, and keep everything in sync with Dropbox.</p>



<p>During college, while I was freelancing, I developed a habit of taking notes. This has served me well since then, and I have tried to manage my notes in more ways than I can remember.</p>

<p>The ones that I can remember trying are: Google Keep, Google Docs, Evernote, Jupyter notebooks, Aha!, Omni-notes, Notability, Apple notes, Nebo, vim + github, and a bunch of miscellaneous mobile apps.</p>



<p>After finding the solution that works for me, I’ve discovered what my requirements are:</p>

<ul>
<li><strong>Portable format</strong>: I want to be able to load my notes in any system. Potential candidates include docx files, markdown, and pdfs</li>
<li><strong>Access everywhere</strong>: I want to be able to see and read my notes after they’ve been synchronized</li>
<li><strong>Vim mode</strong>: When I’m at a computer, I’d like to be able to use vim mode to modify and update my notes</li>
<li><strong>Metadata</strong>: I need a good way of associating metadata with my notes like the time the note was taken and a way of linking notes</li>
</ul>

<p>But I also want to be able to use notes for other things:</p>

<ul>
<li>I have lots of miscellaneous thoughts during the day and need a way to capture them</li>
<li>I like to keep track of quotes</li>
<li>I often track things like grocery lists</li>
<li>I like to keep track of todo items</li>
</ul>

<p>And it would be nice if the apps that I took my notes on had a dark mode.</p>



<p>I think I may have finally found the solution that works for me, and I want to share my setup just in case it works for other people too. The keystone to my new note-taking strategy is Obsidian. I absolutely love this note-taking app, and whole-heartedly recommend it to anyone. I hope that it continues to be the simple, elegant, and powerful editor that it is today. Disclaimer: I’m not affiliated with them in any way, and don’t have anything to gain by promoting them.</p>

<h2 id="markdown">Markdown</h2>

<p>When I have used other formats, I always run into corner cases where the note system breaks down. For example, I have always wanted to have my blog posts in the same place as the rest of my notes, but they always seem to get out of sync - I’ll write the original post in one place, and then have to copy it back and forth between systems. This led to my notes and my blog getting out of sync (the blog that you’re reading is my third “real” attempt at getting my blog going).</p>

<p>But markdown has become universal. I can write things in a single format, and load them into any system for viewing. There are a bunch of apps that allow for markdown authoring. I like IA Writer for mobile, and I use Obsidian on all my computers to keep things in sync.</p>

<h2 id="daily-notes">Daily Notes</h2>

<p>Obsidian gives me a convenient format to put all my day-to-day ramblings, todos, and notes called “Daily Notes”. I have a folder called “Daily Notes”, and each file in this folder is the date of the note (for example, 2020-08-10.md). I also use Obsidian’s Daily Note Template to automatically generate a note with my default format.</p>

<p>Obsidian handles this all for my automatically, but the system is simple, so I can do it manually pretty quickly if I want to, say, plan for the next day while I’m laying in bed.</p>

<h3 id="daily-note-format">Daily Note Format</h3>

<p>My daily notes contain the following sections specified as markdown headings:</p>

<ul>
<li><strong>TODO</strong>: I put all the tasks that I want to get done “today” in this section

<ul>
<li><strong>Stretch</strong>: As things come up during the day, I often put them in this section, and move them to the next day if I don’t get to them</li>
</ul></li>
<li><strong>Personal Goals</strong>: I generally have personal objectives that I am actively  working on. This is where I track those objectives, and their output (metrics, notes, links, etc.)</li>
<li><strong>Business Goals</strong>: I like to track the ongoing goals at my job separately from my personal goals.</li>
<li><strong>Accomplished</strong>: It’s nice to lay in bed at night and make a list the things that I got done that day</li>
<li><strong>Daily thoughts</strong>: This section is freeform, and is more like my “journaling” section. As I’m wandering through the day, for example, and I have the next billion dollar business idea, solutions to world hunger, or breakthroughs on artificial general intelligence, I’ll add them to this section.</li>
</ul>

<h2 id="vim-mode">Vim Mode</h2>

<p>Despite how cumbersome it was to constantly have to boot jupyter notebooks, I loved being able to write my notes with a vim mode. I am so much more efficient when I can take note in vim mode. For example, if I’m on a call, I can simply press enter to separaet things in a list, and then make the list when there is a lull in noteworthy conversation by using <code>ctrl+v</code> + move up several lines + <code>shift+i</code> + “-”.</p>

<h2 id="synchronization">Synchronization</h2>

<p>I use dropbox to synchronize files across all my devices. My only gripe with Dropbox is that it <em>really</em> wants you to use a folder called “Dropbox”, which is kind of annoying. But it’s available in all places, and it does a good job of synchronization, so it’s fine.</p>

<h2 id="blog">Blog</h2>

<p>The blog that you’re reading right now is generated with markdown files, so I cloned the repository into my dropbox, and now I can modify and write blog posts in the same place that I take my notes! This was a huge win for me.</p>

<p>I’m still looking for a way to automatically deploy my site when I push to master in order to remove the need to run a deploy script (and have the necessary dependencies in place to do so). Netlify looks like it might be a good solution to this problem, but I haven’t set it up yet.</p>

<h2 id="zettelkasten">Zettelkasten</h2>

<p>I didn’t know there was a word for this style of taking notes until it became trendy a few months ago, but I find that prepending notes with dates is extremely useful for cases where I might have had multiple meetings on the same subject, or where I met with the same person multiple times, but do not have a regularly scheduled meeting with them (I put those in dedicated “1x1” notes).</p>



<p>I haven’t figured out a good way to use tags yet. I’ve tried it in the past, and I end up with more tags than I do notes, making the tags less useful than full-text search. Side note: full text search comes for free with markdown because it’s such a simple file format. Most applications can do it, or you can just do a <code>grep</code> if you have a terminal open.</p>

<p>Also, I still haven’t figured out a great way to link notes to each other. Folders do a pretty good job of grouping similar notes, and I haven’t found a compelling use case for linking notes. But it’s nice to have solutions in the tool box in case problems arise.</p>

                </section></div>]]>
            </description>
            <link>http://peterklipfel.com/blog/taking_notes/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23897371</guid>
            <pubDate>Mon, 20 Jul 2020 13:04:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The German Problem with Tor]]>
            </title>
            <description>
<![CDATA[
Score 142 | Comments 116 (<a href="https://news.ycombinator.com/item?id=23897288">thread link</a>) | @worldofmatthew
<br/>
July 20, 2020 | https://worldofmatthew.com/post/tor-german-avoid/ | <a href="https://web.archive.org/web/*/https://worldofmatthew.com/post/tor-german-avoid/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="main">
<article>
<div>
<p>Over the past year, relay operators have done a good job in diversifying the range of network that they use to host their relays. The problem is that the move away from popular ASNs has not always translated to a move away from popular countries.</p>
<p>This is where we come to Germany, which has the highest amount of Tor relay capacity in the World at 167Gbps, in contrast France is in 2nd place with 64.5Gbps of capacity aka more than 100Gbps lower than Germany.</p>
<h2 id="the-problem-with-germany">The problem with Germany</h2>
<p>The German state is that exactly in love with the Tor network. This is the state who started <a href="https://itnomad.wordpress.com/2006/09/10/germany-crackdown-on-tor-node-operators/">raiding Tor relay operators in 2006</a>, <a href="https://blog.torservers.net/20180704/coordinated-raids-of-zwiebelfreunde-at-various-locations-in-germany.html">illegally seized</a> documents from German exit relay operator; torservers.net in 2018, tried to pass a <a href="https://www.privateinternetaccess.com/blog/germany-considers-amendment-to-law-which-makes-it-illegal-to-run-a-tor-node-or-website/">really vague law in order to the running of Tor relays</a> and now are about to vote on a <a href="https://www.privateinternetaccess.com/blog/new-german-law-would-force-isps-to-allow-secret-service-to-install-trojans-on-user-devices/">law to hijack traffic</a> to download Trojans on the computer of anyone they target.</p>
<p>This is the aggressive anti-privacy shit that most people would expect of somewhere like Russia. This might not be what you expect from a country that claims to love the right to privacy and pushed for the GDPR.</p>
<p>In reality, the German government has a double standard when it comes to the right to privacy. They will fully support that right if it's company's violating your privacy (especially, if they are American because protectionism) but in contrast, the German will give itself as many powers as it can to spy on its own citizens and those abroad.</p>
<p>Now you know how the Germans hate privacy, you will almost certainly be asking about alternative locations.</p>
<h2 id="but-tor-is-encrypted">But Tor is encrypted?</h2>
<p>The high number of high-speed relays and exits in Germany mean that it is not too uncommon to get both a German guard and exit. This gives the state an easier time if they want to target someone using traffic correlation attacks.</p>
<p>That also does not take in account the planned German law that will allow authorities to redirect traffic to state-owned servers, to infect users with viruses/Trojans. This is especially a concern for third-world users of Tor who are going to mainly accessing non-HTTPS sites on a computer without the best security.</p>
<h2 id="what-alternatives-are-there-to-germany">What alternatives are there to Germany?</h2>
<p>The current country with the best privacy to cost ratio is Luxembourg, where a 200Mbit can be gotten <a href="https://gcorelabs.com/pricing/hosting/">for 3.25 EUR per month</a>. Or if you have the money than Switzerland would be more ideal but you would not want to waste a Switzerland VPS on a non-exit relay.</p>
<p>Or if you are cheap, you could get a VPS from a country who hates the western spy powers like Russia or Moldova which will still help enhance the security of the Tor network by decreasing the chances that someone's traffic will just travel though one spying block which will make traffic correlation attacks much harder.</p>
</div>

</article>
</div></div>]]>
            </description>
            <link>https://worldofmatthew.com/post/tor-german-avoid/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23897288</guid>
            <pubDate>Mon, 20 Jul 2020 12:55:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Twitter Got Hacked, Is Mastodon Immune?]]>
            </title>
            <description>
<![CDATA[
Score 63 | Comments 95 (<a href="https://news.ycombinator.com/item?id=23896994">thread link</a>) | @yogthos
<br/>
July 20, 2020 | https://mikestone.me/twitter-got-hacked-is-mastodon-immune | <a href="https://web.archive.org/web/*/https://mikestone.me/twitter-got-hacked-is-mastodon-immune">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Unless you've been hiding under a rock the last week or so, you probably know that Twitter got “hacked”. So, is Mastodon immune from having the same thing happen to it?</p>

<p>Before we can determine if Mastodon is in any better place than Twitter, we have to understand how Twitter's “hack” occurred.</p>

<p><a href="https://www.cnet.com/news/twitter-says-hackers-got-access-to-internal-tools-for-hijacking-spree/" rel="nofollow">CNET Reports</a>:</p>

<blockquote><p>We detected what we believe to be a coordinated social engineering attack by people who successfully targeted some of our employees with access to internal systems and tools</p></blockquote>

<p>Social engineering is <a href="https://en.wikipedia.org/wiki/Social_engineering_(security)" rel="nofollow">defined</a> as, “The psychological manipulation of people into performing actions or divulging confidential information.”</p>

<p>I would argue, and I'm sure most people would agree with me, that no one is perfectly immune from social engineering. It's part of being human, and as long as humans are involved in the situation, it's going to be a vulnerability.</p>

<p>I would also argue Mastodon's distributed nature makes such a coordinated and far reaching attack much less likely.</p>

<p>The attackers in this case targeted high profile individuals, and gained access to Twitter's own internal tools using social engineering. Obviously Mastodon has it's own internal tools, but those tools on <a href="https://mastodon.social/" rel="nofollow">mastodon.social</a> have absolutely no effect on <a href="https://fosstodon.org/" rel="nofollow">Fosstodon</a>, and vise versa.</p>

<p>If attackers wanted to coordinate a similar attack on Mastodon, they'd have to stick to individuals on a particular instance, or they'd have to socially engineer moderators/administrators on multiple instances.</p>

<p>No, this isn't an impossible task. After all, more than one individual was compromised in the Twitter hack. I do think it's more difficult though.</p>

<p>Twitter's response to this whole mess is also worth taking a look at. When Twitter discovered the “hack”, they immediately locked out all access to verified Twitter accounts. This caused a whole lot of problems for a whole lot of people, but I'm not going to talk about this now.</p>

<p>If Mastodon were to be “hacked” in the same way, the same outcome would not occur. Just because one instance of Mastodon is compromised does not mean that they all are. If one instance has to lock down accounts to reduce risk, the rest can continue to operate as they always have.</p>

<p>For the time being, Mastodon remains a small enough presence in the social media sphere that this kind of attack hasn't been worth the time. It is growing, and in time it very well may grow to a point where it is. While Mastodon isn't entirely immune to this kind of attack, it is more difficult and less rewarding. That makes is less of a target, even if all other things are equal.</p>

<p>Day 68 of the <a href="https://mikestone.me/tag:100DaysToOffload" rel="nofollow"><span>#</span><span>100DaysToOffload</span></a> Series:</p>
</div></div>]]>
            </description>
            <link>https://mikestone.me/twitter-got-hacked-is-mastodon-immune</link>
            <guid isPermaLink="false">hacker-news-small-sites-23896994</guid>
            <pubDate>Mon, 20 Jul 2020 12:17:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Z80 Explorer – a Zilog Z80 netlist-level simulator]]>
            </title>
            <description>
<![CDATA[
Score 138 | Comments 13 (<a href="https://news.ycombinator.com/item?id=23896816">thread link</a>) | @segfaultbuserr
<br/>
July 20, 2020 | https://baltazarstudios.com/z80explorer/ | <a href="https://web.archive.org/web/*/https://baltazarstudios.com/z80explorer/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
<p><em>Z80 Explorer</em> is a Zilog Z80 netlist-level simulator capable of running Z80 machine code and also an educational tool with features that help reverse engineer and understand this chip better.</p>
<p>Z80 Explorer is a tool I wished I had a few years ago when I first started looking at the photos of Z80 chip die and was learning to reverse-engineer its <a aria-label="undefined (opens in a new tab)" href="https://baltazarstudios.com/anatomy-z80-gate/" target="_blank" rel="noreferrer noopener">features</a>. The process was slow and painful as it involved deciphering the faint image traces into logic gates and functions.</p>
<p>Sometimes later, I’ve found that the Visual6502 team have done a wonderful work with mapping the cpu’s traces into bitmaps representing various layers. Their online viewing <a href="http://www.visual6502.org/JSSim/expert-z80.html" target="_blank" aria-label="undefined (opens in a new tab)" rel="noreferrer noopener">tool </a>is impressive and one can learn a lot from using it, but as most online tools, it has limitations which I quickly hit when trying to understand the chip behavior in more depth.&nbsp;</p>
<p>As I kept playing with the online tool, my wish list of additional features steadily grew. I would have wanted it not only to be a fully functional and a fast simulator but also to provide more elaborate ways to gain deeper insights into the chip's internal behavior, while also being educational, easy, and intuitive to use.</p>
<p>Fast forward to today, and with the help of repeated COVID-19 stay-at-home orders, I have written this tool to be the way I originally imagined it.</p>
<figure><a href="https://baltazarstudios.com/wp-content/uploads/2020/07/z80explorer-app.png" target="_blank" rel="noopener noreferrer"><img src="https://baltazarstudios.com/wp-content/uploads/2020/07/z80explorer-app.png" alt=""></a><figcaption>Z80 Explorer (click to enlarge)</figcaption></figure>
<p>In this blog, I will give an overview of <em>Z80 Explorer</em>'s capabilities and show a couple of useful features which might be easy to miss even after reading the documentation. This blog may change periodically along with the tool itself as I am actively developing it at the moment (Summer 2020).</p>
<p>The tool's user’s guide is a separate online document located here <a aria-label="undefined (opens in a new tab)" href="https://baltazarstudios.com/Z80ExplorerGuide/" target="_blank" rel="noreferrer noopener">https://baltazarstudios.com/Z80ExplorerGuide</a> It is very concise; if something is still unclear, please email me and I will expand on it.</p>
<p>The tool is written to load and use the Z80 dataset (layer images and netlist). It should be able to accommodate other NMOS chips with minimal changes. However, at this time I haven't done any other ports yet as I was solely focused on Z80. The chip's data (resources) are kept separate from the application and can be independently downloaded and updated from a shared <a aria-label="undefined (opens in a new tab)" href="https://github.com/gdevic/Z80Explorer_Z80" target="_blank" rel="noreferrer noopener">github repo</a>. In particular, as the functions of various nets is understood and nets and buses get named, the list of the net names, tips and annotations can grow and be shared.</p>
<p><em>Z80 Explorer</em> is capable of running native Z80 code at the netlist level. That means, as the instruction opcodes are fed to its pins, the binary 1s and 0s propagate through its internal nets of transistor gates and perform the function identical to what the silicon gates would do on a real chip.</p>
<p>The engine that runs it is quite fast: On my 4GHz i7-4790K CPU, I am able to run Z80 code at around 2.3kHz which is (only!) around 2000 times slower from the speed it would have run on the real silicon. At those “speeds”, it is not inconceivable to run some of the standard CPU diagnostic programs - so I did just that: I run a well known ZEXALL diagnostic program.&nbsp;</p>
<p>That program normally takes hours even on a real Z80. </p>
<p>After a few days of running within the simulator, the list of passing tests kept growing. At one point, after a week or so, the simulator’s internal cycle counter overflowed its 32-bit variable and the simulation stopped. I simply had to resume it, with no need to reset it and with no loss to the accumulated progress.</p>
<div><figure><img src="https://baltazarstudios.com/wp-content/uploads/2020/07/z80explorer-zexall.png" alt=""><figcaption>Z80 Explorer running ZEXALL diagnostic</figcaption></figure></div>
<p>I have added that version of ZEXALL to the app resources. It is modified from the original in that I had sorted the tests by how long they run: with the quickest going first, it does not take too long before you start seeing some results, assuring you that it is indeed running well.</p>
<p><em>Z80 Explorer</em> has "Image views" where it shows various versions of chip images. Some of them are unmodified resource files shown as layers (diffusion, metal layer etc.), and some are created as combinations of those: vss.vcc.nets.col is a layer with the nets colored such that ground is shown as green, vcc red, and the rest of the nets are colored according to user filters.</p>
<p>You can view different layers and create combinations of them if you hold down the Ctrl key while clicking on layer buttons, or press a key assigned to each layer while holding down the Ctrl key.</p>
<p>The chip/layer view can also be annotated. The application loads a default annotation file (containing those annotations) when it starts, but you can load any other annotation file by dragging that file and dropping it into the application image view. For example, “annot_internals.json” (located in the resource folder) contains a different set of annotations focused more on the internal features. Annotations are adaptive so that they will show and hide as you zoom in and out. They also can contain "macros", which are tokens that expand into named net's and bus' values, and those are updated in real time, as the simulation runs.</p>
<div><figure><img src="https://baltazarstudios.com/wp-content/uploads/2020/07/image.png" alt=""><figcaption>Dynamic annotations showing U and V bus values (~ means "inverted")</figcaption></figure></div>
<p>In my older article <a aria-label="undefined (opens in a new tab)" href="https://baltazarstudios.com/z80-instruction-register-deciphered/" target="_blank" rel="noreferrer noopener">here</a> I looked at the Instruction Register. The signal that enables loading it is a complementary WE (Write Enable) pair of control traces.</p>
<p>Can we find exactly at what time(s) the write enable, now called, "load_ir", is asserted? What is the internal logic equation that governs this control signal?</p>
<p>Using the <em>Z80 Explorer</em>'s "Find" option to search for "load_ir" signal name, and then asking for the schematic of that net, brings up this view:</p>
<div><figure><img src="https://baltazarstudios.com/wp-content/uploads/2020/07/z80explorer-load-ir1.png" alt=""><figcaption>Schematic view for "load_ir" net</figcaption></figure></div>
<p>Hence, the signal is generated by OR'ing net 255 with a latch. Let's follow net 255 which is a NAND gate of clock (hence, a clock gating) with the net 1329. Selecting (double-clicking on) 1329 and asking for the schematic brings us even closer to what we expected to see:</p>
<div><figure><img src="https://baltazarstudios.com/wp-content/uploads/2020/07/z80explorer-load-ir-1329.png" alt=""><figcaption>Schematic view for net 1329</figcaption></figure></div>
<p>Therefore, the net 1329 is a clock-gated, NAND-combined signal, active when M3, T3 and PLA22 are active. PLA22 represents "IX/IY+CB" instruction extension decode. (The description of PLA22 is held in the application "tips" file as are descriptions of all other PLA entries and some other important nets).</p>
<p>Back to the latch 244 - and this part may not too obvious unless you have some experience looking at the chip traces - the net 244 is at the bottom and the latch set and reset signals are at the top, both clock-gated:</p>
<div><figure><img src="https://baltazarstudios.com/wp-content/uploads/2020/07/z80explorer-load-ir-244.png" alt=""><figcaption>Latch at the net 244</figcaption></figure></div>
<p>Asking for the schematic of the net 1306 (the one connected from the top-left), which also acts as the latch reset:</p>
<div><figure><img src="https://baltazarstudios.com/wp-content/uploads/2020/07/z80explorer-load-ir-1306.png" alt=""><figcaption>Latch 244 reset</figcaption></figure></div>
<p>we see that the latch will reset on the "internal reset" or a T3 cycle. The latch will be set on an M1 and T2 cycle edge (so it will show at M1/T3):</p>
<div><figure><img src="https://baltazarstudios.com/wp-content/uploads/2020/07/z80explorer-load-ir-1307.png" alt=""><figcaption>Latch 244 set</figcaption></figure></div>
<p>We can verify what we've found by running a hand-crafted test code. I used a template test program "test_blank.asm" to code in a couple of instructions, one of them using IX register, and then I run it for a couple of cycles. In a Waveform view window the result shows how the load_ir signal is being asserted at every M1/T3 as well as at M3/T3, when the instruction is using the IX/IY prefix (PLA22 active).</p>
<div><figure><a href="https://baltazarstudios.com/wp-content/uploads/2020/07/z80explorer-load-ir-wave.png" target="_blank" rel="noopener noreferrer"><img src="https://baltazarstudios.com/wp-content/uploads/2020/07/z80explorer-load-ir-wave.png" alt=""></a><figcaption>Waveform diagram showing "load_ir" signal (click to enlarge)</figcaption></figure></div>
<p>Next, load the "annot_internals.json" file by dropping it onto on the application's image view (the main pane).</p>
<p>You can zoom into the area where are all M and T latches located by pasting this command into the Command Window:&nbsp;</p>
<p><code>img.setZoom(0.98); img.setPos(1151,901)</code></p>
<p>On the startup, the app will try to detect latches, and it will detect most of them automatically. For those not detected, you can add them as you find them. The easiest way to find latches is by using the “Driven by” option. After selecting a net and following its signal chain, if you see two nets being driven by each other in a co-dependent loop, you have found a latch that consists of those two nets (they also act as inverters). One of the app's initialization files, "latches.ini" contains definitions of additional latches. You can add to that file as you find latches that the app did not detect.</p>
<p>Schematic view uses an expanded version of such “Driven by” algorithm to build a tree of gates that contribute to the selected net.</p>
<p>Going the other way, the “Driving nets” option assists you to trace an input net as it branches into the network. For example, pick the /RESET input pad and iterate “Driving nets”, following the highlighted lines. Soon, you should reach a “dead end”, with the nets which apparently nothing is driving, here:</p>
<p><code>img.setZoom(2.926); img.setPos(338,606); img.show(294,548,80,101)</code></p>
<p>About these commands: In order to create these zoom and position commands yourself, set up a desired view and then type “img.state()” in the Command window. The required lines will be printed in the Application Log window.</p>
<p>To obtain the coordinates used in the img.show() command, right-click and select an area you wanted to highlight, and then simply read the coordinates from the Log window and paste them into img.show() as arguments.</p>
<p>The particular network mentioned above contains reset input flops and latches. One of the control signals coming out of it is “int_reset”, or internal reset:</p>
<p><code>img.find("int_reset")</code></p>
<p>This signal branches off to different parts of the chip.&nbsp;</p>
<p>Every chip normally has several signals that are propagated across its die to literally every corner. Some of those networks are power, ground, reset and the clocking network. (Newer chips implement various “gating” to parts of the design to limit the power consumption, but Z80 does not do such thing.)&nbsp;</p>
<p>I have already mention the Waveform view. This view should be familiar to anyone who has worked with simulation tools like ModelSim; but even for the rest, it should still be very simple and intuitive to use.</p>
<div><figure><img src="https://baltazarstudios.com/wp-content/uploads/2020/07/image-1.png" alt=""><figcaption>Waveform view can display signals in a variety of formats</figcaption></figure></div>
<p>The important thing to remember is to “name” the net that you wish to observe, if it hasn't been named yet, before you can add it to the waveform view. Double click on the net and select “Edit net name...”. You can type any name; a …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://baltazarstudios.com/z80explorer/">https://baltazarstudios.com/z80explorer/</a></em></p>]]>
            </description>
            <link>https://baltazarstudios.com/z80explorer/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23896816</guid>
            <pubDate>Mon, 20 Jul 2020 11:41:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Different Take on Fukushima]]>
            </title>
            <description>
<![CDATA[
Score 21 | Comments 4 (<a href="https://news.ycombinator.com/item?id=23896730">thread link</a>) | @baud147258
<br/>
July 20, 2020 | http://www.funraniumlabs.com/2020/07/a-different-take-on-fukushima/ | <a href="https://web.archive.org/web/*/http://www.funraniumlabs.com/2020/07/a-different-take-on-fukushima/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="text"><p><span>I don’t know how many times I’ve started, stopped, and deleted trying to write something up on my trip to the Fukushima Hard-To-Return-To Area, AKA the Futaba District of the Fukushima Prefecture. Unfortunately, thanks to COVID-19, I have plenty of time to write this up now. I want to give thanks at the outset to my friend Robyn, the Hollywood photographer who I went with to Chernobyl, who came on this trip too and can view her gorgeous work <span><a href="https://www.vonswank.com/Curiosities-/JAPAN:-FUKUSHIMA/thumbs">here</a><span>, some of which I’ve used in this post</span></span>. I also want to give high fives to Jen Miller for inspiring me to see if I could make this visit even happen when we went to see sumo and to Brian Wanamaker who’s translation skills allowed the serendipitous, sake-filled meeting with Kae to be an inspiration. And, lastly, thanks to everyone who purchased a <span><a href="https://shop.funraniumlabs.com/products.php?product=The-Coffee-Wave-750ml">“Coffee Wave” BBotE</a></span> bottle for making sure we had the cash on hand to have ADVENTURES!</span></p>
<p><span>From the top, I’m not gonna discuss the ongoing work at Fukushima Daiichi. Plenty of ink and electrons already spent on TEPCO and JAEA doing what they can there. We can hope for a TV show that summarizes the events at the power plant as the Tōhoku quake and tsunami struck as well as HBO’s Chernobyl did. My quibbles with that show are minor at best. My favorite thing about it was people coming to me saying “Phil, I think they got something wrong on Chernobyl” and my grin of evil delight when I got to tell them that <a href="https://twitter.com/clmazin">Craig Mazin</a> lovingly captured period authentic Soviet bullshit and presented it faithfully. But I digress, because what is more interesting to me is the efforts to decontaminate, rehabilitate, and re-inhabit the abandoned area around the power plant. The example of the Chernobyl Exclusion Zone and the “settlers”, who are mostly pensioners left in the lurch by the Soviet collapse, gives one path. </span></p>
<p><span>That’s not what Japan did/is doing. But let me say this right now, because belaboring this is what caused me to abort so many previous versions of this post:</span></p>
<h4><span>These towns aren’t coming back. Not because they’re doing a bad job at cleanup. On the contrary, they’re doing an amazing job and are <em><strong>WAY </strong></em>more thorough than the Soviet Liquidators ever were. That is my professional opinion. Unlike Pripyat, a young nuclear boomtown for high fliers, the rural communities around Fukushima Daiichi were already fading away. The quake and tsunami just accelerated the pace.</span></h4>
<p><span>There. I said it. Now maybe I can explain why without tripping over myself.</span></p>
<p><span>This tale starts eight years ago, on March 11, when my career took a dramatic shift when some tectonic plates moved too. If you search for “UC Berkeley radiation specialist” this is very close to my and a former coworker’s job title. We both lost <em>month</em>s of work responding to a fire hose of phone calls, emails, and even faxes as the entire Pacific Rim turned to us as because The Algorithm™ <em>clearly</em> indicated we were the experts on what to do in when a reactor accident happened. More often than not, we had to refer everyone to the public affairs office who promptly turned around and asked us what they should say. This is the price of being professional staff and not tenured faculty; we don’t have the freedom of expression that comes with tenure, we’re just employees. I would like to note that this doesn’t necessarily mean the tenured faculty knew anything about what they were commenting on, but they do have the freedom to spout off to their heart’s content to any microphone and camera that came near. I actually went back to read <span><a href="http://www.funraniumlabs.com/2011/03/post-tsunami-japanese-reactor-problems/">the post I made two days after the quake</a></span> and was quite surprised to see how well I covered things.</span></p>
<p><span>For everyone that has now seen the Chernobyl miniseries on HBO and has that vision in their head for Fukushima Daiichi, you missed the big differences: there was no graphite fire and, holy crap, that was a hell of a quake and tsunami. For everyone now coming to grips with the idea of a double hit of pandemic and then economic collapse with COVID-19, try the <em>triple</em> disaster of one of the largest earthquakes ever recorded, a huge tsunami, and then slap a nuclear reactor accident on top of that. On a positive note, at least this triple disaster was relatively local in scope. The contamination around the Futaba District is due to the fuel rods leaking some fission products and a bunch of contaminated/activated sea water from the tsunami plus the cooling water of last resort pumping into the spent fuel pools without filtration (much less deionization) first. There were thousands of tons of graphite that lit on fire and exploded at Chernobyl, lofting a totally different set of radioactive materials across the world. Don’t get me wrong, we could detect Fukushima drifting on the breeze across the Pacific within 48hrs but the isotopic mix and quantity was <em>very</em> different than Chernobyl’s. And, as always, the drum I beat constantly for public education: there is a world of difference between “detectable” and “dangerous”.</span></p>
<hr>
<p><span>We were met at the train station by Shuzo in a prefectural government van. He made sure that the ID we’d brought with us matched what I’d supplied to him a few months earlier because and, I quote, “It would be very embarrassing if it did not as I wrote the security procedures.” A little later as we drove past a cultural festival and Shuzo gave an embarrassed chuckle as he said he should probably drive a little bit faster in case some of his people working the fairgrounds saw the van. I asked him how many people worked for him in his office. He replied with some uncertainty “”Four…five hundred? Plus contractors, of course.” I slowly turned my head as realized I wasn’t talking to someone in a roughly similar position to me back in the states, but rather an agency head that reported directly to the governor… and he had volunteered himself as a driver and guide because this project is so important to him. Some recalibration of the honor that was being done for us happened in my head then and there.</span></p>
<p><span>Shuzo has a dream to get his hometown back. As a “hometown boy done good” he isn’t just any prefectural official, he had to order his own family out of their homes and off their farms. He evacuated the JAEA office during the emergency. What he wants more than anything is for the communities to come back after the quake/tsunami/nuclear accident triple disaster. And, yes, you should always look at this is in that order of severity; the reactors were the least of the three but it has the consequences everyone is afraid of. The people most afraid of the quake and tsunami are, well, dead. As part of the TEPCO/JAEA remediation plan, as the Japanese government made a commitment that Futaba would not be abandoned like the Chernobyl Exclusion Zone and had learned some lessons from that; all of the local towns and farms were offered a settlement to turn everything over for decontamination and/or demolition. Shuzo’s job is to make that happen. He is quite literally in charge of everything that is outside of the power plant decontamination project. The first place he wanted to take us was to his father’s farm.</span></p>
<p><span>I helpfully already did some work of sharing an introduction to my hosts in 2018 when I first started writing this up. From that <span><a href="http://www.funraniumlabs.com/2018/10/fukushima-exclusion-zone-preview-announcements/">post</a></span>:</span></p>
<blockquote><p><span>First off, let me introduce you to Shuzo Sakai, Karin Taira and their project, <span><a href="https://real-fukushima.com/">Real Fukushima</a></span>. Unlike the Chernobyl tours of varying quality done by various independent operators, this is a Fukushima Prefecture government project to show the work done for decontamination and rehabitation of the towns in the Fukushima Exclusion Zone. Karin runs the prefecturally sponsored B&amp;B in Odaka called <span><a href="https://www.tripadvisor.com/Hotel_Review-g1022396-d12926635-Reviews-The_Lantern_House-Minamisoma_Fukushima_Prefecture_Tohoku.html">Lantern House</a></span> which I highly recommend if you have the time to stay overnight (sadly, I did not). Shuzo is a prefectural government official who grew up in a town that is now in the exclusion zone and he’s become head of the redevelopment agency. When you are the boss, you’re allowed to give yourself any extra tasks you want; the one he has chosen for his extracurricular activities is showing people the work done to rebuild and reoccupy. Only foreigners at the moment because, and I quote, “I feel foreigners have less radiophobia than the Japanese.” While I didn’t laugh out loud at this, I did tell him that if this was actually the case that my day job would be much easier. As a local boy done good, Shuzo’s desire is to see the people in the towns he’s always known and loved come home. He would also like people all over the world to see their hometowns in his. That you might remember to give your loved ones a call now and then, maybe go home and visit. They miss you, you know. :)</span></p>
<p><span>Shuzo is the person that wrote the procedures for entry into the Fukushima Exclusion Zone. Shuzo is the person who is ultimately responsible for the decon, demolition and reconstruction of all the towns in the Exclusion Zone. This is personal to him.&nbsp;</span></p></blockquote>
<div id="attachment_5054"><p><a href="http://www.funraniumlabs.com/wp-content/uploads/2020/04/IMG_8262.jpg"><img aria-describedby="caption-attachment-5054" src="http://www.funraniumlabs.com/wp-content/uploads/2020/04/IMG_8262-225x300.jpg" alt="forest line" width="225" height="300" srcset="http://www.funraniumlabs.com/wp-content/uploads/2020/04/IMG_8262-225x300.jpg 225w, http://www.funraniumlabs.com/wp-content/uploads/2020/04/IMG_8262-773x1030.jpg 773w, http://www.funraniumlabs.com/wp-content/uploads/2020/04/IMG_8262-768x1024.jpg 768w, http://www.funraniumlabs.com/wp-content/uploads/2020/04/IMG_8262-529x705.jpg 529w, http://www.funraniumlabs.com/wp-content/uploads/2020/04/IMG_8262.jpg 1080w" sizes="(max-width: 225px) 100vw, 225px"></a></p><p id="caption-attachment-5054"><span>The Treeline At Shuzo’s Dad’s Place – once you hit that forest litter, the background count rate triples</span></p></div>
<p><span>Among the people that had to be evacuated were Shuzo’s parents. Shuzo isn’t the eldest son, so his brother’s family ended up taking them in. And then when the evacuation area was expanded, all of them got evacuated again together. This was a bit too much stress on his mother and she passed away. For the next several years, his father lived with his brother’s family even after dad’s home and farm were decontaminated because they didn’t necessarily trust dad to live on his own. At 82, he’d literally never done laundry or really cooked a meal in his life so they needed to teach him some basic survival skills before they could let him go back home to live alone. His father’s farm is a good demonstration piece to show the success of decon allowing reoccupation, but also it’s limitation. The house, driveway, sheds, and yard had no detectable radiation above background, but you didn’t have to walk far into the trees at the edge of the property for the count rate to rise a bit. This is a reflection of the phased approach to decontamination: homes/cities, then farms, …</span></p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://www.funraniumlabs.com/2020/07/a-different-take-on-fukushima/">http://www.funraniumlabs.com/2020/07/a-different-take-on-fukushima/</a></em></p>]]>
            </description>
            <link>http://www.funraniumlabs.com/2020/07/a-different-take-on-fukushima/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23896730</guid>
            <pubDate>Mon, 20 Jul 2020 11:23:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[UI for Neovim Plugins in Lua]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23896684">thread link</a>) | @lukzar
<br/>
July 20, 2020 | https://www.2n.pl/blog/how-to-make-ui-for-neovim-plugins-in-lua | <a href="https://web.archive.org/web/*/https://www.2n.pl/blog/how-to-make-ui-for-neovim-plugins-in-lua">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<div>
<p>In the last <a href="https://www.2n.pl/blog/how-to-write-neovim-plugins-in-lua">article</a>, we saw the basics of creating plugins in Lua using floating windows. Now it's time for a more traditional approach. Let's create a simple plugin that will show us last opened files in handy side navigation. As we focus on learning the interface, we will use vim native oldfiles list for this purpose. It will look something like this:</p>

<p><img src="https://www.2n.pl/system/photos/imgs/000/000/011/original/oldfiles.gif" alt=""></p>

<p>If you didn't read previous <a href="https://www.2n.pl/blog/how-to-write-neovim-plugins-in-lua">article</a>, I highly recommend you to do so, because this article expands on the ideas from the last one and is full of new things in comparison.</p>

<h2>Plugin window</h2>

<p>Ok, so we should start by writing a function that will create our first window, where the <code>oldfiles</code> list will be displayed. But first, we will declare three variables in the main scope of our script: <code>buf</code> and <code>win</code> that will contain our navigation window and buffer references and <code>start_win</code> that will remember the position where we opened our navigation. We will be using these often across our plugin functions.</p>
<div><pre><span>-- It's our main starting function. For now we will only creating navigation window here.</span>
<span>local</span> <span>function</span> <span>oldfiles</span><span>()</span>
  <span>create_win</span><span>()</span>
<span>end</span>

<span>local</span> <span>function</span> <span>create_win</span><span>()</span>
  <span>-- We save handle to window from which we open the navigation</span>
  <span>start_win</span> <span>=</span> <span>vim</span><span>.</span><span>api</span><span>.</span><span>nvim_get_current_win</span><span>()</span>

  <span>vim</span><span>.</span><span>api</span><span>.</span><span>nvim_command</span><span>(</span><span>'</span><span>botright vnew'</span><span>)</span> <span>-- We open a new vertical window at the far right</span>
  <span>win</span> <span>=</span> <span>vim</span><span>.</span><span>api</span><span>.</span><span>nvim_get_current_win</span><span>()</span> <span>-- We save our navigation window handle...</span>
  <span>buf</span> <span>=</span> <span>vim</span><span>.</span><span>api</span><span>.</span><span>nvim_get_current_buf</span><span>()</span> <span>-- ...and it's buffer handle.</span>

  <span>-- We should name our buffer. All buffers in vim must have unique names.</span>
  <span>-- The easiest solution will be adding buffer handle to it</span>
  <span>-- because it is already unique and it's just a number.</span>
  <span>vim</span><span>.</span><span>api</span><span>.</span><span>nvim_buf_set_name</span><span>(</span><span>buf</span><span>,</span> <span>'</span><span>Oldfiles #'</span> <span>..</span> <span>buf</span><span>)</span>

  <span>-- Now we set some options for our buffer.</span>
  <span>-- nofile prevent mark buffer as modified so we never get warnings about not saved changes.</span>
  <span>-- Also some plugins treat nofile buffers different.</span>
  <span>-- For example coc.nvim don't triggers aoutcompletation for these.</span>
  <span>vim</span><span>.</span><span>api</span><span>.</span><span>nvim_buf_set_option</span><span>(</span><span>buf</span><span>,</span> <span>'</span><span>buftype'</span><span>,</span> <span>'</span><span>nofile'</span><span>)</span>
  <span>-- We do not need swapfile.</span>
  <span>vim</span><span>.</span><span>api</span><span>.</span><span>nvim_buf_set_option</span><span>(</span><span>buf</span><span>,</span> <span>'</span><span>swapfile'</span><span>,</span> <span>false</span><span>)</span>
  <span>-- And we would rather prefer that buffer will be destroyed when hide.</span>
  <span>vim</span><span>.</span><span>api</span><span>.</span><span>nvim_buf_set_option</span><span>(</span><span>buf</span><span>,</span> <span>'</span><span>bufhidden'</span><span>,</span> <span>'</span><span>wipe'</span><span>)</span>
  <span>-- It's not necessary but it is good practice to set custom filetype.</span>
  <span>-- This allows users to create their own autocommand or colorschemes on filetype.</span>
  <span>-- and prevent collisions with other plugins.</span>
  <span>vim</span><span>.</span><span>api</span><span>.</span><span>nvim_buf_set_option</span><span>(</span><span>buf</span><span>,</span> <span>'</span><span>filetype'</span><span>,</span> <span>'</span><span>nvim-oldfile'</span><span>)</span>

  <span>-- For better UX we will turn off line wrap and turn on current line highlight.</span>
  <span>vim</span><span>.</span><span>api</span><span>.</span><span>nvim_win_set_option</span><span>(</span><span>win</span><span>,</span> <span>'</span><span>wrap'</span><span>,</span> <span>false</span><span>)</span>
  <span>vim</span><span>.</span><span>api</span><span>.</span><span>nvim_win_set_option</span><span>(</span><span>win</span><span>,</span> <span>'</span><span>cursorline'</span><span>,</span> <span>true</span><span>)</span>

  <span>set_mappings</span><span>()</span> <span>-- At end we will set mappings for our navigation.</span>
<span>end</span>
</pre></div>
<h2>Drawing function</h2>

<p>Okay, so we have a window, now we need something to display in it. We will use vim <code>oldfiles</code> special variable, which stores paths to previously opened files. We will take as many items from it, as we can display without scrolling, but of course, you can take as many as you want in your script. We will call this function <code>redraw</code> because it can be used to refresh navigation content. File paths might be long, so we will try to make them relative to the working directory.</p>
<div><pre><span>local</span> <span>function</span> <span>redraw</span><span>()</span>
  <span>-- First we allow introduce new changes to buffer. We will block that at end.</span>
  <span>vim</span><span>.</span><span>api</span><span>.</span><span>nvim_buf_set_option</span><span>(</span><span>buf</span><span>,</span> <span>'</span><span>modifiable'</span><span>,</span> <span>true</span><span>)</span>

  <span>local</span> <span>items_count</span> <span>=</span>  <span>vim</span><span>.</span><span>api</span><span>.</span><span>nvim_win_get_height</span><span>(</span><span>win</span><span>)</span> <span>-</span> <span>1</span> <span>-- get the window height</span>
  <span>local</span> <span>list</span> <span>=</span> <span>{}</span>

  <span>-- If you using nightly build you can get oldfiles like this</span>
  <span>local</span> <span>oldfiles</span> <span>=</span> <span>vim</span><span>.</span><span>v</span><span>.</span><span>oldfiles</span>
  <span>-- In stable version works only that</span>
  <span>local</span> <span>oldfiles</span> <span>=</span> <span>vim</span><span>.</span><span>api</span><span>.</span><span>nvim_get_vvar</span><span>(</span><span>'</span><span>oldfiles'</span><span>)</span>

  <span>-- Now we populate our list with X last items form oldfiles</span>
  <span>for</span> <span>i</span> <span>=</span> <span>#</span><span>oldfiles</span><span>,</span> <span>#</span><span>oldfiles</span> <span>-</span> <span>items_count</span><span>,</span> <span>-</span><span>1</span> <span>do</span>

    <span>-- We use build-in vim function fnamemodify to make path relative</span>
    <span>-- In nightly we can call vim function like that</span>
    <span>local</span> <span>path</span> <span>=</span> <span>vim</span><span>.</span><span>fn</span><span>.</span><span>fnamemodify</span><span>(</span><span>oldfiles</span><span>[</span><span>i</span><span>],</span> <span>'</span><span>:.'</span><span>)</span>
    <span>-- and this is stable version:</span>
    <span>local</span> <span>path</span> <span>=</span> <span>vim</span><span>.</span><span>api</span><span>.</span><span>nvim_call_function</span><span>(</span><span>'</span><span>fnamemodify'</span><span>,</span> <span>{</span><span>oldfiles</span><span>[</span><span>i</span><span>],</span> <span>'</span><span>:.'</span><span>})</span>

    <span>-- We iterate form end to start, so we should insert items</span>
    <span>-- at the end of results list to preserve order</span>
    <span>table.insert</span><span>(</span><span>list</span><span>,</span> <span>#</span><span>list</span> <span>+</span> <span>1</span><span>,</span> <span>path</span><span>)</span>
  <span>end</span>

  <span>-- We apply results to buffer</span>
  <span>vim</span><span>.</span><span>api</span><span>.</span><span>nvim_buf_set_lines</span><span>(</span><span>buf</span><span>,</span> <span>0</span><span>,</span> <span>-</span><span>1</span><span>,</span> <span>false</span><span>,</span> <span>list</span><span>)</span>
  <span>-- And turn off editing</span>
  <span>vim</span><span>.</span><span>api</span><span>.</span><span>nvim_buf_set_option</span><span>(</span><span>buf</span><span>,</span> <span>'</span><span>modifiable'</span><span>,</span> <span>false</span><span>)</span>
<span>end</span>
</pre></div>
<p>We can now update our main function. We will also add some code that prevents opening multiple navigation windows. For this purpose, we can use <code>nvim_win_is_valid</code> which checks if our plugin window already exists.</p>
<div><pre><span>local</span> <span>function</span> <span>oldfiles</span><span>()</span>
  <span>if</span> <span>win</span> <span>and</span> <span>vim</span><span>.</span><span>api</span><span>.</span><span>nvim_win_is_valid</span><span>(</span><span>win</span><span>)</span> <span>then</span>
    <span>vim</span><span>.</span><span>api</span><span>.</span><span>nvim_set_current_win</span><span>(</span><span>win</span><span>)</span>
  <span>else</span>
    <span>create_win</span><span>()</span>
  <span>end</span>

  <span>redraw</span><span>()</span>
<span>end</span>
</pre></div>
<h2>Openings files</h2>

<p>We can now look at our oldfiles, but it would be much handier if we can also open them. We will allow users to open files in 5 different ways! In a new tab, in horizontal or vertical splits, in the current window and in preview mode, which will keep the focus on navigation.</p>

<p>Let's start by opening files in the current window. We should prepare for two scenarios:<br>
1. Opening a file in the window from which the user opens navigation.<br>
2. Closing the starting window, when we will create a new one for opening file.</p>
<div><pre><span>local</span> <span>function</span> <span>open</span><span>()</span>
  <span>-- We get path from line which user push enter on</span>
  <span>local</span> <span>path</span> <span>=</span> <span>vim</span><span>.</span><span>api</span><span>.</span><span>nvim_get_current_line</span><span>()</span>

  <span>-- if the starting window exists</span>
  <span>if</span> <span>vim</span><span>.</span><span>api</span><span>.</span><span>nvim_win_is_valid</span><span>(</span><span>start_win</span><span>)</span> <span>then</span>
    <span>-- we move to it</span>
    <span>vim</span><span>.</span><span>api</span><span>.</span><span>nvim_set_current_win</span><span>(</span><span>start_win</span><span>)</span>
    <span>-- and edit chosen file</span>
    <span>vim</span><span>.</span><span>api</span><span>.</span><span>nvim_command</span><span>(</span><span>'</span><span>edit '</span> <span>..</span> <span>path</span><span>)</span>
  <span>else</span>
    <span>-- if there is no starting window we create new from lest side</span>
    <span>vim</span><span>.</span><span>api</span><span>.</span><span>nvim_command</span><span>(</span><span>'</span><span>leftabove vsplit '</span> <span>..</span> <span>path</span><span>)</span>
    <span>-- and set it as our new starting window</span>
    <span>start_win</span> <span>=</span> <span>vim</span><span>.</span><span>api</span><span>.</span><span>nvim_get_current_win</span><span>()</span>
  <span>end</span>
<span>end</span>

<span>-- After opening desired file user no longer need our navigation</span>
<span>-- so we should create function to closing it.</span>
<span>local</span> <span>function</span> <span>close</span><span>()</span>
  <span>if</span> <span>win</span> <span>and</span> <span>vim</span><span>.</span><span>api</span><span>.</span><span>nvim_win_is_valid</span><span>(</span><span>win</span><span>)</span> <span>then</span>
    <span>vim</span><span>.</span><span>api</span><span>.</span><span>nvim_win_close</span><span>(</span><span>win</span><span>,</span> <span>true</span><span>)</span>
  <span>end</span>
<span>end</span>

<span>-- Ok. Now we are ready to making two first opening functions</span>

<span>local</span> <span>function</span> <span>open_and_close</span><span>()</span>
  <span>open</span><span>()</span> <span>-- We open new file</span>
  <span>close</span><span>()</span> <span>-- and close navigation</span>
<span>end</span>

<span>local</span> <span>function</span> <span>preview</span><span>()</span>
  <span>open</span><span>()</span> <span>-- WE open new file</span>
  <span>-- but in preview instead of closing navigation</span>
  <span>-- we focus back to it</span>
  <span>vim</span><span>.</span><span>api</span><span>.</span><span>nvim_set_current_win</span><span>(</span><span>win</span><span>)</span>
<span>end</span>
</pre></div><div><pre><span>-- To making splits we need only one function</span>
<span>local</span> <span>function</span> <span>split</span><span>(</span><span>axis</span><span>)</span>
  <span>local</span> <span>path</span> <span>=</span> <span>vim</span><span>.</span><span>api</span><span>.</span><span>nvim_get_current_line</span><span>()</span>

  <span>-- We still need to handle two scenarios</span>
  <span>if</span> <span>vim</span><span>.</span><span>api</span><span>.</span><span>nvim_win_is_valid</span><span>(</span><span>start_win</span><span>)</span> <span>then</span>
    <span>vim</span><span>.</span><span>api</span><span>.</span><span>nvim_set_current_win</span><span>(</span><span>start_win</span><span>)</span>
    <span>-- We pass v in axis argument if we want vertical split</span>
    <span>-- or nothing/empty string otherwise.</span>
    <span>vim</span><span>.</span><span>api</span><span>.</span><span>nvim_command</span><span>(</span><span>axis</span> <span>..</span><span>'</span><span>split '</span> <span>..</span> <span>path</span><span>)</span>
  <span>else</span>
    <span>-- if there is no starting window we make new on left</span>
    <span>vim</span><span>.</span><span>api</span><span>.</span><span>nvim_command</span><span>(</span><span>'</span><span>leftabove '</span> <span>..</span> <span>axis</span><span>..</span><span>'</span><span>split '</span> <span>..</span> <span>path</span><span>)</span>
    <span>-- but in this case we do not need to set new starting window</span>
    <span>-- because splits always close navigation </span>
  <span>end</span>

  <span>close</span><span>()</span>
<span>end</span>
</pre></div>
<p>And in the end the simplest opening in new tab.</p>
<div><pre><span>local</span> <span>function</span> <span>open_in_tab</span><span>()</span>
  <span>local</span> <span>path</span> <span>=</span> <span>vim</span><span>.</span><span>api</span><span>.</span><span>nvim_get_current_line</span><span>()</span>

  <span>vim</span><span>.</span><span>api</span><span>.</span><span>nvim_command</span><span>(</span><span>'</span><span>tabnew '</span> <span>..</span> <span>path</span><span>)</span>
  <span>close</span><span>()</span>
<span>end</span>
</pre></div>
<p>For everything to work, we need to add the key mappings, export all public functions, and add a command to trigger our navigation.</p>
<div><pre><span>local</span> <span>function</span> <span>set_mappings</span><span>()</span>
  <span>local</span> <span>mappings</span> <span>=</span> <span>{</span>
    <span>q</span> <span>=</span> <span>'</span><span>close()'</span><span>,</span>
    <span>[</span><span>'</span><span>&lt;cr&gt;'</span><span>]</span> <span>=</span> <span>'</span><span>open_and_close()'</span><span>,</span>
    <span>v</span> <span>=</span> <span>'</span><span>split("v")'</span><span>,</span>
    <span>s</span> <span>=</span> <span>'</span><span>split("")'</span><span>,</span>
    <span>p</span> <span>=</span> <span>'</span><span>preview()'</span><span>,</span>
    <span>t</span> <span>=</span> <span>'</span><span>open_in_tab()'</span>
  <span>}</span>

  <span>for</span> <span>k</span><span>,</span><span>v</span> <span>in</span> <span>pairs</span><span>(</span><span>mappings</span><span>)</span> <span>do</span>
    <span>-- let's assume that our script is in lua/nvim-oldfile.lua file.</span>
    <span>vim</span><span>.</span><span>api</span><span>.</span><span>nvim_buf_set_keymap</span><span>(</span><span>buf</span><span>,</span> <span>'</span><span>n'</span><span>,</span> <span>k</span><span>,</span> <span>'</span><span>:lua require"nvim-oldfile".'</span><span>..</span><span>v</span><span>..</span><span>'</span><span>&lt;cr&gt;'</span><span>,</span> <span>{</span>
        <span>nowait</span> <span>=</span> <span>true</span><span>,</span> <span>noremap</span> <span>=</span> <span>true</span><span>,</span> <span>silent</span> <span>=</span> <span>true</span>
      <span>})</span>
  <span>end</span>
<span>end</span>

<span>-- at file end</span>
<span>return</span> <span>{</span>
  <span>oldfiles</span> <span>=</span> <span>oldfiles</span><span>,</span>
  <span>close</span> <span>=</span> <span>close</span><span>,</span>
  <span>open_and_close</span> <span>=</span> <span>open_and_close</span><span>,</span>
  <span>preview</span> <span>=</span> <span>preview</span><span>,</span>
  <span>open_in_tab</span> <span>=</span> <span>open_in_tab</span><span>,</span>
  <span>split</span> <span>=</span> <span>split</span>
<span>}</span>
</pre></div><div><pre>command<span>!</span> Oldfiles <span>lua</span> require<span>'nvim-oldfile'</span>.<span>oldfiles</span><span>()</span>
</pre></div>
<p>And that's it! Have fun and make grate things!</p>

<h2>The whole plugin</h2>
<div><pre><span>local</span> <span>buf</span><span>,</span> <span>win</span><span>,</span> <span>start_win</span>

<span>local</span> <span>function</span> <span>open</span><span>()</span>
  <span>local</span> <span>path</span> <span>=</span> <span>vim</span><span>.</span><span>api</span><span>.</span><span>nvim_get_current_line</span><span>()</span>

  <span>if</span> <span>vim</span><span>.</span><span>api</span><span>.</span><span>nvim_win_is_valid</span><span>(</span><span>start_win</span><span>)</span> <span>then</span>
    <span>vim</span><span>.</span><span>api</span><span>.</span><span>nvim_set_current_win</span><span>(</span><span>start_win</span><span>)</span>
    <span>vim</span><span>.</span><span>api</span><span>.</span><span>nvim_command</span><span>(</span><span>'</span><span>edit '</span> <span>..</span> <span>path</span><span>)</span>
  <span>else</span>
    <span>vim</span><span>.</span><span>api</span><span>.</span><span>nvim_command</span><span>(</span><span>'</span><span>leftabove vsplit '</span> <span>..</span> <span>path</span><span>)</span>
    <span>start_win</span> <span>=</span> <span>vim</span><span>.</span><span>api</span><span>.</span><span>nvim_get_current_win</span><span>()</span>
  <span>end</span>
<span>end</span>

<span>local</span> <span>function</span> <span>close</span><span>()</span>
  <span>if</span> <span>win</span> <span>and</span> <span>vim</span><span>.</span><span>api</span><span>.</span><span>nvim_win_is_valid</span><span>(</span><span>win</span><span>)</span> <span>then</span>
    <span>vim</span><span>.</span><span>api</span><span>.</span><span>nvim_win_close</span><span>(</span><span>win</span><span>,</span> <span>true</span><span>)</span>
  <span>end</span>
<span>end</span>

<span>local</span> <span>function</span> <span>open_and_close</span><span>()</span>
  <span>open</span><span>()</span>
  <span>close</span><span>()</span>
<span>end</span>

<span>local</span> <span>function</span> <span>preview</span><span>()</span>
  <span>open</span><span>()</span>
  <span>vim</span><span>.</span><span>api</span><span>.</span><span>nvim_set_current_win</span><span>(</span><span>win</span><span>)</span>
<span>end</span>

<span>local</span> <span>function</span> <span>split</span><span>(</span><span>axis</span><span>)</span>
  <span>local</span> <span>path</span> <span>=</span> <span>vim</span><span>.</span><span>api</span><span>.</span><span>nvim_get_current_line</span><span>()</span>

  <span>if</span> <span>vim</span><span>.</span><span>api</span><span>.</span><span>nvim_win_is_valid</span><span>(</span><span>start_win</span><span>)</span> <span>then</span>
    <span>vim</span><span>.</span><span>api</span><span>.</span><span>nvim_set_current_win</span><span>(</span><span>start_win</span><span>)</span>
    <span>vim</span><span>.</span><span>api</span><span>.</span><span>nvim_command</span><span>(</span><span>axis</span> <span>..</span><span>'</span><span>split '</span> <span>..</span> <span>path</span><span>)</span>
  <span>else</span>
    <span>vim</span><span>.</span><span>api</span><span>.</span><span>nvim_command</span><span>(</span><span>'</span><span>leftabove '</span> <span>..</span> <span>axis</span><span>..</span><span>'</span><span>split '</span> <span>..</span> <span>path</span><span>)</span>
  <span>end</span>

  <span>close</span><span>()</span>
<span>end</span>

<span>local</span> <span>function</span> <span>open_in_tab</span><span>()</span>
  <span>local</span> <span>path</span> <span>=</span> <span>vim</span><span>.</span><span>api</span><span>.</span><span>nvim_get_current_line</span><span>()</span>

  <span>vim</span><span>.</span><span>api</span><span>.</span><span>nvim_command</span><span>(</span><span>'</span><span>tabnew '</span> <span>..</span> <span>path</span><span>)</span>
  <span>close</span><span>()</span>
<span>end</span>


<span>local</span> <span>function</span> <span>redraw</span><span>()</span>
  <span>vim</span><span>.</span><span>api</span><span>.</span><span>nvim_buf_set_option</span><span>(</span><span>buf</span><span>,</span> <span>'</span><span>modifiable'</span><span>,</span> <span>true</span><span>)</span>
  <span>local</span> <span>items_count</span> <span>=</span>  <span>vim</span><span>.</span><span>api</span><span>.</span><span>nvim_win_get_height</span><span>(</span><span>win</span><span>)</span> <span>-</span> <span>1</span>
  <span>local</span> <span>list</span> <span>=</span> <span>{}</span>
  <span>local</span> <span>oldfiles</span> <span>=</span> <span>vim</span><span>.</span><span>api</span><span>.</span><span>nvim_get_vvar</span><span>(</span><span>'</span><span>oldfiles'</span><span>)</span>

  <span>for</span> <span>i</span> <span>=</span> <span>#</span><span>oldfiles</span><span>,</span> <span>#</span><span>oldfiles</span> <span>-</span> <span>items_count</span><span>,</span> <span>-</span><span>1</span> <span>do</span>
    <span>pcall</span><span>(</span><span>function</span><span>()</span>
      <span>local</span> <span>path</span> <span>=</span> <span>vim</span><span>.</span><span>api</span><span>.</span><span>nvim_call_function</span><span>(</span><span>'</span><span>fnamemodify'</span><span>,</span> <span>{</span><span>oldfiles</span><span>[</span><span>i</span><span>],</span> <span>'</span><span>:.'</span><span>})</span>
      <span>table.insert</span><span>(</span><span>list</span><span>,</span> <span>#</span><span>list</span> <span>+</span> <span>1</span><span>,</span> <span>path</span><span>)</span>
    <span>end</span><span>)</span>
  <span>end</span>

  <span>vim</span><span>.</span><span>api</span><span>.</span><span>nvim_buf_set_lines</span><span>(</span><span>buf</span><span>,</span> <span>0</span><span>,</span> <span>-</span><span>1</span><span>,</span> <span>false</span><span>,</span> <span>list</span><span>)</span>
  <span>vim</span><span>.</span><span>api</span><span>.</span><span>nvim_buf_set_option</span><span>(</span><span>buf</span><span>,</span> <span>'</span><span>modifiable'</span><span>,</span> <span>false</span><span>)</span>
<span>end</span>

<span>local</span> <span>function</span> <span>set_mappings</span><span>()</span>
  <span>local</span> <span>mappings</span> <span>=</span> <span>{</span>
    <span>q</span> <span>=</span> <span>'</span><span>close()'</span><span>,</span>
    <span>[</span><span>'</span><span>&lt;cr&gt;'</span><span>]</span> <span>=</span> <span>'</span><span>open_and_close()'</span><span>,</span>
    <span>v</span> <span>=</span> <span>'</span><span>split("v")'</span><span>,</span>
    <span>s</span> <span>=</span> <span>'</span><span>split("")'</span><span>,</span>
    <span>p</span> <span>=</span> <span>'</span><span>preview()'</span><span>,</span>
 …</pre></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.2n.pl/blog/how-to-make-ui-for-neovim-plugins-in-lua">https://www.2n.pl/blog/how-to-make-ui-for-neovim-plugins-in-lua</a></em></p>]]>
            </description>
            <link>https://www.2n.pl/blog/how-to-make-ui-for-neovim-plugins-in-lua</link>
            <guid isPermaLink="false">hacker-news-small-sites-23896684</guid>
            <pubDate>Mon, 20 Jul 2020 11:17:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Three Architectures for a Responsive IDE]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23896380">thread link</a>) | @todsacerdoti
<br/>
July 20, 2020 | https://rust-analyzer.github.io/blog/2020/07/20/three-architectures-for-responsive-ide.html | <a href="https://web.archive.org/web/*/https://rust-analyzer.github.io/blog/2020/07/20/three-architectures-for-responsive-ide.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>The first architecture is reminiscent of the map-reduce paradigm.
The idea is to split analysis into relatively simple indexing phase, and a separate full analysis phase.</p>
<p>The core constraint of indexing is that it runs on a per-file basis.
The indexer takes the text of a single file, parses it, and spits out some data about the file.
The indexer can’t touch other files.</p>
<p>Full analysis can read other files, and it leverages information from the index to save work.</p>
<p>This all sounds way too abstract, so let’s look at a specific example — Java.
In Java, each file starts with a package declaration.
The indexer concatenates the name of the package with a class name to get a fully-qualified name (FQN).
It also collects the set of methods declared in the class, the list of superclasses and interfaces, etc.</p>
<p>Per-file data is merged into an index which maps FQNs to classes.
Note that constructing this mapping is an embarrassingly parallel task — all files are parsed independently.
Moreover, this map is cheap to update.
When a file change arrives, this file’s contribution from the index is removed, the text of the file is changed and the indexer runs on the new text and adds the new contributions.
The amount of work to do is proportional to the number of changed files, and is independent from the total number of files.</p>
<p>Let’s see how FQN index can be used to quickly provide completion.</p>
<div>
<div>
<pre><code data-lang="java"><table><tbody><tr><td><pre> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
18
19
20
21
22
23
24
25
26
</pre></td><td><pre><span>// File ./mypackage/Foo.java</span>
<span>package</span> <span>mypackage</span><span>;</span>

<span>import</span> <span>java.util.*</span><span>;</span>

<span>public</span> <span>class</span> <span>Foo</span> <span>{</span>
    <span>public</span> <span>static</span> <span>Bar</span> <span>f</span><span>()</span> <span>{</span>
        <span>return</span> <span>new</span> <span>Bar</span><span>();</span>
    <span>}</span>
<span>}</span>

<span>// File ./mypackage/Bar.java</span>
<span>package</span> <span>mypackage</span><span>;</span>

<span>public</span> <span>class</span> <span>Bar</span> <span>{</span>
    <span>public</span> <span>void</span> <span>g</span><span>()</span> <span>{}</span>
<span>}</span>

<span>// File ./Main.java</span>
<span>import</span> <span>mypackage.Foo</span><span>;</span>

<span>public</span> <span>class</span> <span>Main</span> <span>{</span>
    <span>public</span> <span>static</span> <span>void</span> <span>main</span><span>(</span><span>String</span><span>[]</span> <span>args</span><span>)</span> <span>{</span>
        <span>Foo</span><span>.</span><span>f</span><span>().</span>
    <span>}</span>
<span>}</span>
</pre></td></tr></tbody></table></code></pre>
</div>
</div>
<p>The user has just typed <code>Foo.f().</code>, and we need to figure out that the type of receiver expression is <code>Bar</code>, and suggest <code>g</code> as a completion.</p>
<p>First, as the file <code>Main.java</code> is modified, we run the indexer on this single file.
Nothing has changed (the file still contains the class <code>Main</code> with a static <code>main</code> method), so we don’t need to update the FQN index.</p>
<p>Next, we need to resolve the name <code>Foo</code>.
We parse the file, notice an <code>import</code> and look up <code>mypackage.Foo</code> in the FQN index.
In the index, we also find that <code>Foo</code> has a static method <code>f</code>, so we resolve the call as well.
The index also stores the return type of <code>f</code>, but, and this is crucial, it stores it as a string <code>"Bar"</code>, and not as a direct reference to the class <code>Bar</code>.</p>
<p>The reason for that is <code>import java.util.*</code> in <code>Foo.java</code>.
<code>Bar</code> can refer either to <code>java.util.Bar</code> or to <code>mypackage.Bar</code>.
The indexer doesn’t know which one, because it can look <strong>only</strong> at the text of <code>Foo.java</code>.
In other words, while the index does store the return types of methods, it stores them in an unresolved form.</p>
<p>The next step is to resolve the identifier <code>Bar</code> in the context of <code>Foo.java</code>.
This uses the FQN index, and lands in the class <code>mypackage.Bar</code>.
There the desired method <code>g</code> is found.</p>
<p>Altogether, only three files were touched during completion.
The FQN index allowed us to completely ignore all the other files in the project.</p>
<p>One problem with the approach described thus far is that resolving types from the index requires a non-trivial amount of work.
This work might be duplicated if, for example, <code>Foo.f</code> is called several times.
The fix is to add a cache.
Name resolution results are memoized, so that the cost is paid only once.
The cache is blown away completely on any change — with an index, reconstructing the cache is not that costly.</p>
<p>To sum up, the first approach works like this:</p>
<div>
<ol>
<li>
<p>Each file is being indexed, independently and in parallel, producing a "stub" — a set of visible top-level declarations, with unresolved types.</p>
</li>
<li>
<p>All stubs are merged into a single index data structure.</p>
</li>
<li>
<p>Name resolution and type inference work primarily off the stubs.</p>
</li>
<li>
<p>Name resolution is lazy (we only resolve a type from the stub when we need it) and memoized (each type is resolved only once).</p>
</li>
<li>
<p>The caches are completely invalidated on every change</p>
</li>
<li>
<p>The index is updated incrementally:</p>
<div>
<ul>
<li>
<p>if the edit doesn’t change the file’s stub, no change to the index is required.</p>
</li>
<li>
<p>otherwise, old keys are removed and new keys are added</p>
</li>
</ul>
</div>
</li>
</ol>
</div>
<p>Note an interesting interplay between "dumb" indexes which can be updated incrementally, and "smart" caches, which are re-computed from scratch.</p>
<p>This approach combines simplicity and stellar performance.
The bulk of work is the indexing phase, and you can parallelize and even distribute it across several machine.
Two examples of this architecture are <a href="https://www.jetbrains.com/idea/">IntelliJ</a> and <a href="https://sorbet.org/">Sorbet</a>.</p>
<p>The main drawback of this approach is that it works only when it works — not every language has a well-defined FQN concept.
I think overall it’s a good idea to design name resolution and module systems (mostly boring parts of a language) such that they work well with the map-reduce paradigm.</p>
<div>
<ul>
<li>
<p>Require <code>package</code> declarations or infer them from the file-system layout</p>
</li>
<li>
<p>Forbid meta-programming facilities which add new top-level declarations, or restrict them in such way that they can be used by the indexer.
For example, preprocessor-like compiler plugins that access a single file at a time might be fine.</p>
</li>
<li>
<p>Make sure that each source element corresponds to a single semantic element.
For example, if the language supports conditional compilation, make sure that it works during name resolution (like Kotlin’s <a href="https://kotlinlang.org/docs/reference/platform-specific-declarations.html">expect/actual</a>) and not during parsing (like conditional compilation in most other languages).
Otherwise, you’d have to index the same file with different conditional compilation settings, and that is messy.</p>
</li>
<li>
<p>Make sure that FQNs are enough for most of the name resolution.</p>
</li>
</ul>
</div>
<p>The last point is worth elaborating. Let’s look at the following Rust example:</p>
<div>
<div>
<pre><code data-lang="rust"><table><tbody><tr><td><pre> 1
 2
 3
 4
 5
 6
 7
 8
 9
10
11
12
13
14
15
16
17
18
</pre></td><td><pre><span>// File: ./foo.rs</span>
<span>trait</span> <span>T</span> <span>{</span>
    <span>fn</span> <span>f</span><span>(</span><span>&amp;</span><span>self</span><span>)</span> <span>{}</span>
<span>}</span>
<span>// File: ./bar.rs</span>
<span>struct</span> <span>S</span><span>;</span>

<span>// File: ./somewhere/else.rs</span>
<span>impl</span> <span>T</span> <span>for</span> <span>S</span> <span>{}</span>

<span>// File: ./main.s</span>
<span>use</span> <span>foo</span><span>::</span><span>T</span><span>;</span>
<span>use</span> <span>bar</span><span>::</span><span>S</span>

<span>fn</span> <span>main</span><span>()</span> <span>{</span>
    <span>let</span> <span>s</span> <span>=</span> <span>S</span><span>;</span>
    <span>s</span><span>.f</span><span>();</span>
<span>}</span>
</pre></td></tr></tbody></table></code></pre>
</div>
</div>
<p>Here, we can easily find the <code>S</code> struct and the <code>T</code> trait (as they are imported directly).
However, to make sure that <code>s.f</code> indeed refers to <code>f</code> from <code>T</code>, we also need to find the corresponding <code>impl</code>, and that can be roughly anywhere!</p>
</div></div>]]>
            </description>
            <link>https://rust-analyzer.github.io/blog/2020/07/20/three-architectures-for-responsive-ide.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23896380</guid>
            <pubDate>Mon, 20 Jul 2020 10:10:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Nanopublications: Fair data containers for scientific results]]>
            </title>
            <description>
<![CDATA[
Score 15 | Comments 6 (<a href="https://news.ycombinator.com/item?id=23896279">thread link</a>) | @melvinroest
<br/>
July 20, 2020 | http://nanopub.org/wordpress/ | <a href="https://web.archive.org/web/*/http://nanopub.org/wordpress/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

                                
                        
            <p>FAIR data containers for scientific results,
<br>
and more</p>            
            		             
            
        </div></div>]]>
            </description>
            <link>http://nanopub.org/wordpress/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23896279</guid>
            <pubDate>Mon, 20 Jul 2020 09:50:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[TileDB closes $15M Series A for universal data engine]]>
            </title>
            <description>
<![CDATA[
Score 93 | Comments 61 (<a href="https://news.ycombinator.com/item?id=23896131">thread link</a>) | @k-rus
<br/>
July 20, 2020 | https://tiledb.com/blog/tiledb-closes-15m-series-a-for-industry-s-first-universal-data-engine-2020-07-14 | <a href="https://web.archive.org/web/*/https://tiledb.com/blog/tiledb-closes-15m-series-a-for-industry-s-first-universal-data-engine-2020-07-14">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p>Cambridge, MA, July 14, 2020: <a href="https://tiledb.com/">TileDB, Inc.</a> has secured a $15M Series A investment round led by <a href="https://twobearcapital.com/">Two Bear Capital</a>, joined by <a href="https://uncorrelated.com/">Uncorrelated Ventures</a> and all existing investors: <a href="https://nexusvp.com/">Nexus Venture Partners</a>, <a href="http://www.intelcapital.com/">Intel Capital</a>, and <a href="https://bigpi.vc/">Big Pi Ventures</a>. The funding will help the company expand go-to-market and product development for its “universal data engine,” a novel database that goes beyond tables to manage any complex data and beyond SQL to analyze the data with any tool, all serverless and at planet scale. Montana philanthropist and Two Bear Capital Managing Partner Mike Goguen will join TileDB’s Board of Directors.</p>
<p>The Series A financing comes after TileDB was chosen by customers who experienced two key pains: scalability for complex data and deployment. Whole-genome population data, single-cell gene data, spatio-temporal satellite imagery, and asset-trading data all share multi-dimensional structures that are poorly handled by monolithic databases, tables, and legacy file formats. Newer computational frameworks evolved to offer “pluggable storage” but that forces another part of the stack to deal with data management. As a result, organizations waste resources on managing a sea of files and optimizing storage performance, tasks traditionally done by the database. Moreover, developers and data scientists are spending excessive time in data engineering and deployment, instead of actual analysis and collaboration.</p>
<p>“We flipped the data management model,” said Dr. Stavros Papadopoulos, CEO and original creator of TileDB. “We invented a database that focuses on universal storage and data management rather than the compute layer, which we’ve instead made `pluggable.` We cleared the path for analytics professionals and data scientists by taking over the messiest parts of data management, such as optimized storage for all data types on numerous backends, data versioning, metadata, access control within or outside organizational boundaries, and logging. On top, we developed numerous APIs for fast direct data access and efficient integrations with a growing set of popular tools such as Spark, Dask, MariaDB and PrestoDB. Finally, we built a serverless infrastructure for easy, secure cross-organizational sharing and scalable compute, called TileDB Cloud.”</p>
<p>According to Scott Soenen, VP of Product Engineering at Capella Space: “The partnership with TileDB gelled perfectly with our desire to deliver a new level of innovation in open data programs aimed at the geospatial community. Open data alone isn’t enough. It’s also about easy access to compute resources and versatility of analytics. TileDB Cloud removes multiple manual steps in data access for the geospatial developer community and offers intuitive self-service and interactive analytics."</p>
<p>“We have chosen TileDB as the storage engine to power our cellxgene project at CZI, which is an interactive data explorer for single-cell transcriptomics datasets,” said Bruce Martin, Director of Engineering, Chan Zuckerberg Initiative. “TileDB provides an easy and powerful way to manage our huge array data on various backends, including cloud object stores. The serverless infrastructure of TileDB Cloud opens the door to extreme scale with very low engineering efforts on our part, allowing us to focus more on scientific discoveries instead.”</p>
<p>Magnus Isaksson, Director of Bioinformatics, Helix shared, “The synergy between our two companies has enabled us to take an innovative approach to storing and analyzing genomic data at population-scale. We were excited to find TileDB after extensive diligence of potential solutions that could meet Helix's needs and advance our vision to revolutionize population health via the power of genomics."</p>
<p>“Many of the world’s most urgent problems - from COVID to climate change - require the analysis of large volumes of data in order to find solutions. TileDB’s technology addresses the infrastructure deficit that adds friction, delay, and cost to generating the key insights and discoveries needed from this data,” said Mike Goguen, Managing Partner at Two Bear Capital and lead investor. “We are excited to partner with Stavros and TileDB to build an enduring company delivering massive value for the developers and enterprise customers working to solve these and other critically important problems.”</p>
<p><br>
To learn more about TileDB visit <a href="https://tiledb.com/">our website</a>, check out the open-source <a href="https://github.com/TileDB-Inc/TileDB">TileDB Embedded</a> storage engine on Github or sign up on <a href="https://tiledb.com/cloud">TileDB Cloud</a>.</p>
<p>--------------------------------------------------------------------------------------</p>
<p><strong>About Two Bear Capital</strong></p>
<p>Two Bear Capital (TBC) was founded and is led by venture capitalist and Montana philanthropist Michael Goguen. With professionals in Whitefish, MT, the San Francisco Bay area and San Diego, CA, TBC invests in early stage companies with disruptive innovations at the intersections of biotech, bioinformatics, machine learning / AI and cybersecurity that could deliver dramatically better solutions to the most critical problems affecting human health, security and wellness. To learn more, visit <a href="http://www.twobearcapital.com/">www.twobearcapital.com</a> and follow TBC on LinkedIn.</p>
<p><strong>About Uncorrelated Ventures</strong></p>
<p><a href="https://uncorrelated.com/">Uncorrelated Ventures</a> was founded by <a href="https://www.baincapitalventures.com/team/salil/">Salil Deshpande</a> in 2020 with Bain’s backing to focus on open source and infrastructure software, both traditional and decentralized. Over 14 years as general partner and managing director at Bay Partners and Bain Capital, Salil invested $350M+ into 50+ companies early, including MuleSoft, DynaTrace, Buddy Media, SpringSource, Redis Labs, SysDig, Jambool, Dropcam, Tealium, Sonatype, Frame, DataStax, Netdata, Quantum Metric, Philz Coffee, Upgrade and DeFi projects Compound and Maker. Salil was on the Forbes Midas List of the 100 best-performing venture investors worldwide in 2013, 2014, 2015, 2016, 2017, 2018, and 2019.</p>
<p><strong><br>
About Nexus Venture Partners</strong></p>
<p>Nexus Venture Partners is a leading early-stage venture capital firm partnering with extraordinary entrepreneurs building product-first companies. With $1.5B under management, Nexus operates as one team across the US and India. The Nexus family includes Aryaka, Biz2Credit, Cloud.com, Clover Health, Delhivery, Druva, Gluster, H2O.ai, Hasura, Headspin, Kaltura, Mezi, Observe.ai, OLX, Paysense, Postman, Pubmatic, Rancher, Snapdeal, Unacademy, Whitehatjr, and Zomato. For more information, visit <a href="http://www.nexusvp.com/">www.nexusvp.com</a>.</p>
<p><strong>About Intel Capital</strong></p>
<p>Intel Capital invests in innovative startups targeting artificial intelligence, autonomous vehicles, datacenter and cloud, 5G, next-generation compute, and a wide range of other disruptive technologies. Since 1991, Intel Capital has invested US$12.9 billion in more than 1,582 companies worldwide, and 692 portfolio companies have gone public or participated in a merger. Intel Capital curates thousands of business development introductions each year between its portfolio companies and the Global 2000. For more information on what makes Intel Capital one of the world’s most powerful venture capital firms, visit www.intelcapital.com or follow @Intelcapital.</p>
<p><strong>About Big Pi Ventures</strong></p>
<p>Big Pi Ventures is a seed-stage fund investing in innovative technology companies connected to Greece and engaged primarily in enterprise/B2B software, materials and life sciences. Big Pi is managed by seasoned investment professionals and successful entrepreneurs that assist companies in attracting highly technical and loyal human capital. Find out more about our fund, portfolio, and career opportunities by visiting <a href="http://www.bigpi.vc/">www.bigpi.vc</a>.</p></div></div></div>]]>
            </description>
            <link>https://tiledb.com/blog/tiledb-closes-15m-series-a-for-industry-s-first-universal-data-engine-2020-07-14</link>
            <guid isPermaLink="false">hacker-news-small-sites-23896131</guid>
            <pubDate>Mon, 20 Jul 2020 09:17:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Minecraft@Home]]>
            </title>
            <description>
<![CDATA[
Score 220 | Comments 70 (<a href="https://news.ycombinator.com/item?id=23895789">thread link</a>) | @networked
<br/>
July 20, 2020 | https://minecraftathome.com/minecrafthome/ | <a href="https://web.archive.org/web/*/https://minecraftathome.com/minecrafthome/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <div><p><span>Server outage resolved and supporting our infrastructure</span><br>

        Between 23:54 UTC yesterday (2020-07-20) and 15:35 UTC today, we suffered from a catastrophic SQL failure which forced us to restore from backup.</p><p>

There may be some credit issues where the system granted more or fewer credits than you expect for work done during this time.<br>
I can't apologize enough. If our BOINC deployment was architected for scale rather than for low cost, we could've avoided this.</p><p>

There are several enhancements to our infrastructure and upgrades we'd like to make, such as migrating services to Kubernetes and potentially using a managed SQL service.</p><p>

<span><b><span color="red">You can help!</span> Please consider visiting our Patreon page, reviewing the current set of benefits, and making a contribution of any size; any amount helps - <a href="https://patreon.com/minecraftathome" rel="nofollow">patreon.com/minecraftathome</a></b></span></p><p>

All contributions go towards covering infrastructure cost and quality-of-life improvements to ensure the project's longevity.
        <br>
        <span>21 Jul 2020, 20:10:54 UTC
    
            · <a href="https://minecraftathome.com/minecrafthome/forum_thread.php?id=44"> Discuss</a>
        </span></p></div><hr>
    <div><p><span>That was fast</span><br>

        The origin of the panorama image used in the Minecraft main menu from beta version 1.8.1, released in September 2011, has remained a mystery until now.</p><p>

<b><span>In less than 24 hours after launching the panorama application; a volunteer host for Minecraft@Home, in a sheer stroke of luck, found the world seed, 25357015387625.</span></b><br>
This was approximately </p><p><span color="red">93 days of processing time at a total of 54.5 exaFLOPs</span> compressed into the last 24 hours.</p><p>

The specific host which located the seed belongs to the user <a href="https://minecraftathome.com/minecrafthome/show_user.php?userid=2558" rel="nofollow">vanos0512</a>.<br>
Thank you to the 137 users who contributed 181 hosts with 231 GPUs over the last 24 hours. You all accomplished this.</p><p>

<img src="https://i.imgur.com/f6lGCEn.png"></p><p>

Here are the details if you want to generate this world for yourself:<br>
<b>Minecraft version:</b> <i>Beta 1.7</i><br>
<b>Either of these two valid world seeds:</b> <i>2151901553968352745 or 8091867987493326313</i><br>
<b>Co-ordinates:</b> <i>x60, y76, z-67</i></p><p>

<a href="https://www.youtube.com/watch?v=caLCZNLPgrM" rel="nofollow">See the video released by EarthComputer announcing the finding.</a>
        <br>
        <span>18 Jul 2020, 15:32:11 UTC
    
            · <a href="https://minecraftathome.com/minecrafthome/forum_thread.php?id=42"> Discuss</a>
        </span></p></div><hr>
    <div><p><span>Enjoy the scenery</span><br>

        <span>Minecraft@Home is now <span color="red">over one month old</span>! To celebrate this milestone, I present a new research focus; the panorama project.</span></p><p>

If you were here during beta-testing, you might have received a very early version of panorama tasks, and the eagle-eyed among you may have seen the application details <a href="https://minecraftathome.com/minecrafthome/server_status.php" rel="nofollow">on the server status page</a>.</p><p>

<span><b>The panorama app is a CUDA-only app for Linux and Windows with an Nvidia driver version of 418.96 or higher.</b></span></p><p>

This project attempts to find the world seed of the iconic panorama image which appeared in the background of the main menu of Minecraft between 2011 and 2018. The first phase of this project will only last a few days, and we shall update you with their progress in the coming weeks.</p><p>

<img src="https://i.imgur.com/3dyexWe.png"></p><p>

Right now, the application is quite substantial. Unlike the OpenCL applications for the Kaktwoos project, <b>if you allow BOINC to run tasks always; you may experience some stuttering or lag in your desktop environment while running these tasks</b>. These tasks do not have checkpointing support, but run in around 1 hour on an average host to mitigate the majority of lost cycles.</p><p>

<span>As always, <a href="https://minecraftathome.com/minecrafthome/prefs.php?subset=project" rel="nofollow">you can change which projects of which you decide to participate in your user preferences</a>.</span></p><p>

Let us know if you have any questions, and as always join the discussion over on <a href="https://discord.gg/xVFh9bp" rel="nofollow">the Discord server.</a>
        <br>
        <span>17 Jul 2020, 15:31:43 UTC
    
            · <a href="https://minecraftathome.com/minecrafthome/forum_thread.php?id=39"> Discuss</a>
        </span></p></div><hr>
    <div><p><span>Kaktwoos 2.03 and Badges!</span><br>

        You may have seen many workunits just disappear from existence today.</p><p>

<img src="https://munin.kiska.pw/munin-cgi/munin-cgi-graph/Munin-Node/Munin-Node/results_minecraftathome-pinpoint=1594193183,1594247603.png?&amp;lower_limit=&amp;upper_limit=&amp;size_x=400&amp;size_y=200"></p><p>

Worry not! We realised there were far too many workunits scanning duplicate seeds, so we've scaled back the original workunits to the correct seed ranges <span><i>(no in-progress results were touched, so none of you should have lost any credit)</i></span>.</p><p>

We have located some promising seed candidates which were missed from processing and can be used as an input to this job, so they are currently set as the highest priority.</p><p>

Also, <span><b>we now have badges</b></span>! If you view the forums, any comments in threads, or on the leaderboards; you will see the new badges.<br>
We're open to suggestions for future badges, so please leave us some comments on this thread.
        <br>
        <span>8 Jul 2020, 21:06:03 UTC
    
            · <a href="https://minecraftathome.com/minecrafthome/forum_thread.php?id=30"> Discuss</a>
        </span></p></div><hr>
    <div><p><span>Profile creation and OpenCL vendor pinning</span><br>

        In the last news post, I advised everyone to create a profile in order to be eligible for 'user of the day' selection.<br>
Unfortunately, there was an issue with the ReCaptcha implementation which prevented this. This issue is now resolved.</p><p>

Now, you are able to <a href="https://minecraftathome.com/minecrafthome/create_profile.php" rel="nofollow">create a profile here</a>.</p><p>

Also, good news for hosts with OpenCL capable hardware from more than one vendor <i>(e.g. an Intel iGPU and an Nvidia GPU)</i><br>
The latest update to the kaktwoos app should ensure the tasks run on the correct device.<br>
If you are a user with a multi-vendor host, please keep an eye on your results and let us know if you're having any issues.</p><p>

As always, please get involved with the conversation in the <a href="https://minecraftathome.com/minecrafthome/forum_index.php" rel="nofollow">message boards</a>, and <a href="https://discord.gg/xVFh9bp" rel="nofollow">join the Discord</a>!
        <br>
        <span>3 Jul 2020, 16:57:49 UTC
    
            · <a href="https://minecraftathome.com/minecrafthome/forum_thread.php?id=22"> Discuss</a>
        </span></p></div><hr>
    <p><a href="https://minecraftathome.com/minecrafthome/old_news.php">... more</a></p><p><small>
    News is available as an <a href="https://minecraftathome.com/minecrafthome/rss_main.php">RSS feed &nbsp; <img src="https://minecraftathome.com/minecrafthome/img/rss_icon.gif" alt="RSS"></a>
        </small></p></div></div>]]>
            </description>
            <link>https://minecraftathome.com/minecrafthome/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23895789</guid>
            <pubDate>Mon, 20 Jul 2020 08:19:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Demo of OpenAI's GPT-3 generating tweets given a word]]>
            </title>
            <description>
<![CDATA[
Score 91 | Comments 84 (<a href="https://news.ycombinator.com/item?id=23895706">thread link</a>) | @hardmaru
<br/>
July 20, 2020 | https://thoughts.sushant-kumar.com/hong%20kong | <a href="https://web.archive.org/web/*/https://thoughts.sushant-kumar.com/hong%20kong">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
			
	<blockquote>
		<p><span>“</span>HK, regardless of the political system, should always focus on making itself more efficient and liveable.<span>”</span></p>
	</blockquote>

		</div></div>]]>
            </description>
            <link>https://thoughts.sushant-kumar.com/hong%20kong</link>
            <guid isPermaLink="false">hacker-news-small-sites-23895706</guid>
            <pubDate>Mon, 20 Jul 2020 08:03:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why GPT-3 Matters]]>
            </title>
            <description>
<![CDATA[
Score 213 | Comments 153 (<a href="https://news.ycombinator.com/item?id=23895481">thread link</a>) | @teruakohatu
<br/>
July 20, 2020 | https://leogao.dev/2020/05/29/GPT-3-A-Brief-Summary/ | <a href="https://web.archive.org/web/*/https://leogao.dev/2020/05/29/GPT-3-A-Brief-Summary/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
      
        <!-- TOC -->
        
        <p><img src="https://leogao.dev/images/gpt3/title.png" alt="Number of Parameters of GPT-3 compared to previous models. (<a href='https://www.willstats.com/'>Edited by WillStats</a>, <a href='https://arxiv.org/abs/1910.01108'>Original 1</a>, <a href='https://www.microsoft.com/en-us/research/blog/turing-nlg-a-17-billion-parameter-language-model-by-microsoft/'>Original 2</a>)"></p>
<p><span>The sheer scale of the new GPT-3 model</span> is hard to overstate; it’s an entire <em>order of magnitude</em> larger than Microsoft’s <a href="https://www.microsoft.com/en-us/research/blog/turing-nlg-a-17-billion-parameter-language-model-by-microsoft/" target="_blank" rel="noopener">already-massive 17B parameter Turing-NLG</a>.<sup><a href="#fn1" id="fnref1">[1]</a></sup> Loading the entire model’s weights in fp16 would take up an absolutely preposterous 300GB of VRAM, not even including the gradients. But, with massive size comes massive generalization ability: GPT-3 is competitive in many benchmarks <em>without even tuning on the target task</em>. And when I say many, I mean <em>many</em>—the full, 72-page paper contains an extensive evaluation of GPT-3 on many NLP datasets. Through the <a href="https://openai.com/blog/openai-api/" target="_blank" rel="noopener">OpenAI API</a>, a vast array of impressive demos have sprung up taking advantage of the generalization capabilities of GPT-3 to do extremely disparate tasks. Perhaps the most impressive part, though, is that even at such a massive scale, the model still scales smoothly in performance instead of plateauing, implying that still-larger models would perform <em>even better</em>. Throughout the rest of this post, my goal is to distill this massive (in multiple ways) paper down to a digestible size, and shed some light on why it matters.</p>

<p>The following table summarizes some of the largest autoregressive Transformer models of the past few years. I’ve excluded models like <a href="https://arxiv.org/abs/1906.08237" target="_blank" rel="noopener">XLNet</a> and BERT-derivatives because they don’t have the same unidirectional autoregressive training target.</p>
<table>
<thead>
    <tr><th></th>
    <th>Parameters</th>
    <th>Layers</th>
    <th>Hidden Size</th>
    <th>Attn Heads</th>
    <th>Attn Head Dimension</th>
    <th>Context Length</th>
</tr></thead>
    <tbody><tr>
        <th><a href="https://s3-us-west-2.amazonaws.com/openai-assets/research-covers/language-unsupervised/language_understanding_paper.pdf" target="_blank" rel="noopener">GPT</a></th>
        <td>0.110B</td>
        <td>12</td>
        <td>768</td>
        <td>12</td>
        <td>64</td>
        <td>512</td>
    </tr>
    <tr>
        <th><a href="https://d4mucfpksywv.cloudfront.net/better-language-models/language_models_are_unsupervised_multitask_learners.pdf" target="_blank" rel="noopener">GPT-2</a></th>
        <td>1.542B</td>
        <td>48</td>
        <td>1600</td>
        <td>25</td>
        <td>64</td>
        <td>1024</td>
    </tr>
    <tr>
        <th><a href="https://arxiv.org/abs/1909.08053" target="_blank" rel="noopener">Megatron-LM</a></th>
        <td>8.3B</td>
        <td>72</td>
        <td>3072</td>
        <td>32</td>
        <td>96</td>
        <td>1024</td>
    </tr>
    <tr>
        <th><a href="https://www.microsoft.com/en-us/research/blog/turing-nlg-a-17-billion-parameter-language-model-by-microsoft/" target="_blank" rel="noopener">Turing-NLG</a></th>
        <td>17B</td>
        <td>78</td>
        <td>4256</td>
        <td>28</td>
        <td>152</td>
        <td>1024</td>
    </tr>
    <tr>
        <th><a href="https://arxiv.org/abs/2005.14165" target="_blank" rel="noopener">GPT-3</a></th>
        <td>175.0B</td>
        <td>96</td>
        <td>12288</td>
        <td>96</td>
        <td>128</td>
        <td>2048</td>
    </tr>

</tbody></table>
<p>While GPT-3 isn’t that much deeper, its width is nearly <strong>3x</strong> that of <a href="https://www.microsoft.com/en-us/research/blog/turing-nlg-a-17-billion-parameter-language-model-by-microsoft/" target="_blank" rel="noopener">Turing-NLG</a>, which—since parameter count scales approximately proportional to the square of the hidden size—explains where most of the extra parameters come from. It also has double the context size, at 2048 tokens, which is impressive (and memory-expensive!), though not the biggest context size across all models; some models have even longer contexts, like <a href="https://arxiv.org/abs/1901.02860" target="_blank" rel="noopener">Transformer-XL</a>, which incorporates longer contexts by passing context vectors between segments, and <a href="https://ai.googleblog.com/2020/01/reformer-efficient-transformer.html" target="_blank" rel="noopener">Reformer</a>, which uses locality-sensitive hashing to enable sparser attention. Similarly, GPT-3 uses <a href="https://arxiv.org/abs/1904.10509" target="_blank" rel="noopener">sparse attention layers</a> in every other layer, though the exact details are left somewhat ambiguous. It’s also interesting to note that the smaller GPT-3 versions trained for comparison with GPT-2 are slightly shallower and wider, with GPT-3-XL having only 24 layers but a hidden size of 2048.<sup><a href="#fn2" id="fnref2">[2]</a></sup> GPT-3 also reuses the BPE tokenization of GPT-2. Overall, GPT-3 is essentially just a downright massive version of GPT-2.</p>

<p><img src="https://leogao.dev/images/gpt3/tdata.png" alt="Weighted Training Data (<a href='https://arxiv.org/abs/2005.14165'>Source</a>)"></p>
<p>The training data is a reweighted mix of Common Crawl, WebText2 (a larger version of the original that <a href="https://arxiv.org/abs/2001.08361" target="_blank" rel="noopener">also includes links sampled in the period of Jan-Oct 2018</a>), two book corpora, and English Wikipedia. Some of these components, such as Wikipedia, were seen more than 3 times during training; others, like the massive Common Crawl component, had less than half of their data seen. The authors claim that this is to help raise the overall quality of the corpus by prioritising known-good datasets. Also, in contrast to the original WebText, this new corpus is not filtered by language, but English still constitutes 93% of the dataset by words simply due to its prevalence. Altogether, the dataset is 500 billion tokens, or 700GB<sup><a href="#fn3" id="fnref3">[3]</a></sup>, after filtering and cleaning. The paper also provides a detailed description of the filtering process of the dataset, which the GPT-2 paper didn’t.</p>
<p>The authors also attempted to remove any data that overlapped with the train and test sets of the evaluations. Unfortunately, due to a bug, some were missed, so to compensate the paper provides a fairly good analysis of the impact of this leakage.</p>

<p><img src="https://leogao.dev/images/gpt3/perf-small.png" alt="Zero-, One-, and Few-shot performance of GPT-3 scaling with parameter count (<a href='https://arxiv.org/abs/2005.14165'>Source</a>)"></p>
<p>The Evaluation section of GPT-3 is very comprehensive, evaluating on a massive battery of NLP tasks in the Zero-shot (given only a natural language description in the generation context), One-shot (a single example in the generation context), or Few-shot (a small handful of examples in the generation context) settings. This setting is worth emphasizing as perhaps one of the biggest differences in ability between GPT-2 and its predecessors, because being able to <em>infer the task</em> from just one or a few examples is a massive step forward in generalization. Whereas previous models all relied on task-specific tuning, GPT-3 can be “tuned” merely by giving it instructions <em>in plain English</em>! In fact, the paper doesn’t even attempt to fine-tune on the target task, leaving that to future work.<sup><a href="#fn4" id="fnref4">[4]</a></sup> However, one crucial conclusion is that in almost all tests, performance continues to get better with larger models, even across 4 entire orders of magnitude, whereas fine-tuning only improves on one task and <a href="https://arxiv.org/pdf/1901.11373.pdf" target="_blank" rel="noopener">risks catastrophic forgetting and overfitting</a>.</p>
<p>Without going too much into the individual tests, the general result is this: on most tasks, GPT-3 achieves performance significantly worse than fine-tuned SOTA (i.e SuperGLUE, CoQA, Winograd, to name a few), but beating fine-tuned SOTA for some other tasks (i.e PhysicalQA, LAMBADA, Penn Tree Bank). GPT-3 does particularly well on PTB in particular, taking the SOTA perplexity from 35.76 down to 20.5—a massive improvement. GPT-3 can also finally do some arithmetic, something GPT-2 was unable to do well.<sup><a href="#fn5" id="fnref5">[5]</a></sup></p>
<p><img src="https://leogao.dev/images/gpt3/newsgen-small.png" alt="People are unable to separate GPT-3 generated news articles from real ones (<a href='https://arxiv.org/abs/2005.14165'>Source</a>)"></p>
<p>Impressively, and perhaps somewhat alarmingly, people are unable to distinguish GPT-3 generated news stories from real ones, only exacerbating the ethical concerns already raised by GPT-2. The paper analyzes the result of the release of GPT-2, and concludes that the release of GPT-2 has not led to widespread use of LMs for misinformation due to the difficulty of controlling output and variance in output quality, both among low-to-mid skill adversaries and “advanced persistent threats”—adversaries with “high skill and long-term agendas”—such as state actors. However, the paper also acknowledges that with further development, LMs will eventually become advanced enough for these adversaries.</p>
<p>The authors also investigate gender bias in GPT-3, showing that GPT-3 is male leaning; however, the authors claim that some preliminary evidence on the Winogender dataset (which tests coreference resolution on the same sentence but with different gendered pronoun) seems to suggest that larger models are more robust to bias issues. Similar issues appeared for race and religion, with the sentiment of coöccurrent terms varying significantly with race. The authors claim that this issue also got better with the larger models—although, without proper hypothesis testing, it’s difficult to draw any solid conclusions here.</p>

<p>GPT-3 has already been used for a smorgasbord of different applications through the OpenAI API. You can ask it to <a href="https://twitter.com/sharifshameem/status/1282676454690451457" target="_blank" rel="noopener">write</a> <a href="https://twitter.com/hturan/status/1282261783147958272" target="_blank" rel="noopener">code</a>, turn <a href="http://vimeo.com/427943407/98fe5258a7" target="_blank" rel="noopener">natural language commands into shell commands</a>, and simulate <a href="https://www.aiwriter.email/" target="_blank" rel="noopener">chatting with famous people</a>. You can ask it to <a href="https://twitter.com/QasimMunye/status/1278750809094750211" target="_blank" rel="noopener">answer medical questions</a>, or <a href="https://www.gwern.net/GPT-3#navy-seal-copypasta" target="_blank" rel="noopener">write parodies of the navy seal copypasta</a>. You can ask it to <a href="https://andrewmayneblog.wordpress.com/2020/06/13/openai-api-alchemy-summarization/" target="_blank" rel="noopener">summarize passages for second graders</a>, or <a href="https://www.gwern.net/GPT-3#transformer-poetry" target="_blank" rel="noopener">write poetry</a>.</p>
<p>It’s important to remember all these are done by the <em>exact same model</em> trained <em>only</em> on modelling text; all that’s different is that it has been “asked nicely” to do different things. These apps showcase the versatility of GPT-3 across many disparate domains—something that, if it were done with GPT-2, would require days or even weeks of extensive data engineering and fine tuning, rather than 15 minutes of prompt crafting. This new paradigm of programming through crafting plain-English prompts, jokingly dubbed <a href="https://twitter.com/karpathy/status/1273788774422441984" target="_blank" rel="noopener">“Software 3.0”</a>, has achieved results that are already impressive, but even more impressive when viewed through the lens of <strong>generalization</strong>; GPT-3 wasn’t trained to do any of these things in particular, but it could still be asked<sup><a href="#fn6" id="fnref6">[6]</a></sup> to do them, and fairly well at that!</p>

<p><img src="https://leogao.dev/images/gpt3/perf_scaling_compute.png" alt="Performance continues to scale with compute. (<a href='https://arxiv.org/abs/2005.14165'>Source</a>)"></p>
<p>But why does GPT-3 matter, if it can’t even beat SOTA across all benchmarks? Why should we care about a model so large that a small computing cluster is necessary even just to run inference at a reasonable speed?</p>
<p>One thing about GPT-3 is that it’s doing reasonably well on tasks it has <em>never even seen</em>, and sometimes tasks not even anticipated by the developers of the model. Additionally, instead of reaching a point of diminishing returns, GPT-3 shows that the trend of larger models performing better continues for at least another order of magnitude, with no signs of stopping. Even though GPT-3 is unwieldy, and even though it still doesn’t quite reach human level performance across the board, GPT-3 shows that it’s <em>possible</em> for a model to someday reach human levels of generalization in NLP—and once the impossible becomes possible, it’s only a matter of time until it becomes practical.</p>
<hr>
<section>
<ol>
<li id="fn1"><p>Back when I talked about <a href="https://leogao.dev/2019/10/27/The-Difficulties-of-Text-Generation-with-Autoregressive-Language-Models/">large Transformer language models like GPT-2, CTRL, and Megatron-LM late last year</a>, I touched briefly on the trend of Language Models getting bigger, and covered some of the issues that simply more compute might not fix. My general anticipation was that the model size arms race would soon be at a temporary standstill, with focus being diverted to better decoding strategies for text generation (perhaps via RL-based methods). I most certainly had not expected that OpenAI would be back at it so soon with such a massive model.</p>
<p>This was such a surprise that I dropped everything to read the paper and work on this post, including a more theory-oriented post that I’ve been working on for a few months now. It will probably be finished <span>soon™</span>, after I recover from GPT-3 shock. Stay tuned! <a href="#fnref1">↩︎</a></p>
</li>
<li id="fn2"><p>It’s likely that this was done for easier model parallelism—bigger matrix multiplications are much easier to parallelize than sequentially-applied layers à la <a href="https://arxiv.org/abs/1811.06965" target="_blank" rel="noopener">GPipe</a>.</p>
<p>This could have other advantages too, though. After <a href="https://arxiv.org/abs/1905.11946" target="_blank" rel="noopener">EfficientNet</a> came out, I independently ran some experiments of the same concepts to Transformer models, and the result was that for the same amount of compute, wider models had a sizeable advantage over deeper ones—which corroborates the choice here to …</p></li></ol></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://leogao.dev/2020/05/29/GPT-3-A-Brief-Summary/">https://leogao.dev/2020/05/29/GPT-3-A-Brief-Summary/</a></em></p>]]>
            </description>
            <link>https://leogao.dev/2020/05/29/GPT-3-A-Brief-Summary/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23895481</guid>
            <pubDate>Mon, 20 Jul 2020 07:21:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Video Vectorization]]>
            </title>
            <description>
<![CDATA[
Score 305 | Comments 116 (<a href="https://news.ycombinator.com/item?id=23895211">thread link</a>) | @xanthine
<br/>
July 19, 2020 | https://vectorly.io/docs/technology/ | <a href="https://web.archive.org/web/*/https://vectorly.io/docs/technology/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="main">

<p><img src="https://vectorly.io/docs/img/vector-graphics.png" alt="Drawing"></p>

<p>Vectorly is developing a new kind of video compression technology, which uses computer vision and vector graphics to reduce bitrates for video content by an order of magnitude (or more) compared to HEVC, while <strong>improving video</strong> quality. </p>
<p>This would be primarily effective for "vector friendly" video content, which would include animations, screen-casts, many e-learning videos and potentially 3d gaming content. </p>
<p>By leveraging existing vector-graphics rendering capabilities on all devices, this codec wouldn't require end-users, OEMs or browsers to install special software to enable playback of these videos.</p>
<p><strong>We are still in the early phases of developing this technology</strong>.</p>
<p>You can learn more about the technology in our <a href="https://files.vectorly.io/Vectorization+Whitepaper+v06.20.pdf">whitepaper</a></p>
<h2 id="the-core-idea">The Core Idea</h2>
<p>The core insight behind this project was that you could use vector-graphics based animations to simulate "videos" in a way that is indistinguishable from a traditional raster-graphics based video format such as an h264 video stream in an MP4 container.</p>
<h3 id="raster-graphics">Raster Graphics</h3>
<p>Normal videos, like the ones you see on Netflix or YouTube, are just sequences of images which get updated quickly on the screen, to create the illusion of motion. Each image is composed of "pixels" - individual dots of color. Higher resolution means more pixels, better visual quality, and bigger file sizes.</p>
<p><img alt="Pixel-Based" src="https://vectorly.io/docs/img/pixels.png"></p>
<p>Almost all video on the internet is of this format, known as "raster graphics". Video compression algorithms like h264 are just very efficient at using fewer data-points to reconstruct the pixels in any given frame, and at storing only the differences in pixels between frames of a video. </p>
<h3 id="vector-grapics-video">Vector Grapics video</h3>
<p>In contrast, we use a concept called "vector-graphics" to render video. Instead of pixels, we represent everything on the screen using shapes, lines and curves, which can be represented as mathematical equations (vector graphics).</p>
<p><img alt="Vector-Based" src="https://vectorly.io/docs/img/vector2.png"></p>
<p>Using these mathematical equations, we can re-draw any arbitrary shape on the screen - from the letter "T" to Bart Simpson's head. Furthermore, by adding information such as color, position on the screen, and how they move or change shape over time, you can create whole videos - including entire episodes of the Simpsons, with just sequences of mathematical equations.</p>
<h3 id="why-vectorization">Why vectorization?</h3>
<p>The core insight behind this project was that for a certain kind of "vector-friendly" video content, storing the video using vector graphics would be much more efficient than using raster graphics (in some cases, up to 2 orders of magnitude more efficient).</p>
<p>This idea is not substantively different from the idea of Flash based animations about 20 years ago. Why do this now?</p>
<p><strong>No need for a decoder</strong>: Most devices now support SVG, HTML5, WebGL/OpenGL and/or some form of hardware-accelerated vector-graphics rendering. That lets you render vector-graphics content on any device without require end-users, OEMs or browsers to install special software to enable playback of vector-graphics content, and to achieve native-level performance by doing so. App developers would only need to include an appropriate library or SDK in their website or app to enable playback within native or 3rd player video players.</p>
<p><strong>Computer vision</strong>: Our patented vectorization technology relies heavily on computer vision to convert raster-graphics videos to a vector format. Leveraging the advancement &amp; commoditization of Computer Vision, and the ease of running batch computer-vision heavy tasks on the cloud, it's feasible to 'vectorize' large volumes of video at scale now, in a way that wasn't possible even 5 years ago.</p>
<h3 id="vector-graphics-video-format">Vector graphics video format</h3>
<p>We are building a video-format based on existing standards (SVG, WebGL &amp; OpenGL), extending it with Javascript to enable video features such as a timeline and key-frames. We package the resulting video data within an MP4 container, which can be streamed and distributed using existing video infrastructure (such as HLS/DASH, and DRM systems).</p>
<pre><code>&lt;video src="vectorized.mp4" type="video/svg"&gt;
</code></pre>
<p>We are pragmatic, and don't want to create a standard <a href="https://xkcd.com/927/">for the sake of creating a standard</a>.  To that end, we've created libraries and SDKs that enable playback of our vector-graphics videos using standard / native interfaces like so</p>
<pre><code>&lt;script src="vectorly.js"&gt;

&lt;video src="vectorized.mp4" type="video/svg"&gt;
// This will work on all major browsers today
</code></pre>
<h2 id="demos-proof-of-concept">Demos / Proof of concept</h2>
<p><strong>Simpsons</strong></p>
<p>Our first vectorized proof of concept for animations is a 17 second clip of the Simpsons located <a href="https://files.vectorly.io/demo/v0-2-simpsons-250kbps/index.html">here</a>. Keep in mind, our technology is still at a very early stage, and this is much optimization work left to be done.</p>
<p><strong>Khan Academy</strong></p>
<p>Our technology also works very well for e-learning, and especially Khan Academy style content. You can find 30 second Khan Academy clip <a href="https://files.vectorly.io/demo/khan-20kbps/index.html">here</a></p></div></div>]]>
            </description>
            <link>https://vectorly.io/docs/technology/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23895211</guid>
            <pubDate>Mon, 20 Jul 2020 06:30:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[In Praise of ZFS on Linux's ZED 'ZFS Event Daemon']]>
            </title>
            <description>
<![CDATA[
Score 148 | Comments 116 (<a href="https://news.ycombinator.com/item?id=23894790">thread link</a>) | @zdw
<br/>
July 19, 2020 | https://utcc.utoronto.ca/~cks/space/blog/linux/ZFSZEDPraise | <a href="https://web.archive.org/web/*/https://utcc.utoronto.ca/~cks/space/blog/linux/ZFSZEDPraise">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><h2>In praise of ZFS On Linux's ZED 'ZFS Event Daemon'</h2>

	<p><small>July 19, 2020</small></p>
</div><div><p>I've written before (<a href="https://utcc.utoronto.ca/~cks/space/blog/linux/ZFSFileserverSameness">here</a>) about how <a href="https://utcc.utoronto.ca/~cks/space/blog/linux/ZFSFileserverSetupIII">our
current Linux ZFS fileservers</a> work much
like <a href="https://utcc.utoronto.ca/~cks/space/blog/solaris/ZFSFileserverSetupII">our old OmniOS fileservers</a>.
However, not everything is quite the same between ZFS on Linux and
traditional Solaris/OmniOS ZFS. One of the most welcome differences
for us is <a href="https://zfsonlinux.org/manpages/0.8.4/man8/zed.8.html">ZED</a>,
the ZFS Event Daemon. What ZED does that is so great is that it provides
a very simple way to take action when <a href="https://zfsonlinux.org/manpages/0.8.4/man5/zfs-events.5.html">ZFS events</a> happen.</p>

<p>When a ZFS event happens, ZED looks through a directory (generally
<code>/etc/zfs/zed.d</code>) to find scripts (or programs) that should be run
in response to the event. Each script is run with a bunch of
environment variables set to describe what's going on, and it can
use those environment variables to figure out what the event is.
ZED decides what things to run based on their names; generally you
wind up with script names like <code>all-cslab.sh</code> (which is run on
all events) and <code>resilver_finish-cslab.sh</code> (which is run when a
resilver finishes).</p>

<p>Because these are just a collection of individual files, you're
free to add your own without colliding with or having to alter the
standard 'ZEDLETs' provided by ZFS on Linux. Your additions can do
anything you want them to, ranging from the simple to the complex.
For instance, our simplest ZEDLET simply syslogs all of the ZED
environment variables:</p>


<blockquote><pre>PATH=/usr/bin:/usr/sbin:/bin:/sbin:$PATH
export PATH
if [ "$ZEVENT_SUBCLASS" = "history_event" ]; then
        exit 0
fi
unset ZEVENT_TIME
unset ZEVENT_TIME_STRING
printenv | fgrep 'ZEVENT_' | sort | fmt -999 |
    logger -p daemon.info -t 'cslab-zevents'
exit 0
</pre>
</blockquote>

<p>(There's a standard 'all-syslog.sh' ZEDLET, but it doesn't syslog
all of the information in the zevents. Capturing all of the information
is especially useful if you want to write additional ZEDLETs and
aren't quite sure what they should look for or what environment
variables have useful information.)</p>

<p>It can take a bit of time and experimentation to sort out what ZFS
events are generated (and with what information available) in
response to various things happening to adn in your ZFS pools. But
once you have figured it out, ZED gives you a way to trigger and
drive all sorts of system management activities. These can be active
(like taking action if devices fail) or passive (like adding markers
in your metrics system or performance dashboards for when ZFS scrubs
or resilvers start and end, so you can correlate this with other
things happening).</p>

<p>Coming from Solaris and OmniOS, where there was no such simple
system for reacting to things happening in your ZFS pools, ZED was
a breath of fresh air for us. More than anything else, it feels
like how ZFS events should have been handled from the start, so
that system administrators could flexibly meet their own local needs
rather than having to accept whatever the Solaris Fault Management
system wanted to give them.</p>

<p>PS: Because ZFS on Linux is now OpenZFS, I believe that ZED will
probably eventually show up in FreeBSD (if it isn't already there).
Perhaps it will even some day be ported back to Illumos.</p>
</div></div>]]>
            </description>
            <link>https://utcc.utoronto.ca/~cks/space/blog/linux/ZFSZEDPraise</link>
            <guid isPermaLink="false">hacker-news-small-sites-23894790</guid>
            <pubDate>Mon, 20 Jul 2020 05:03:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Self Hosting Email Server]]>
            </title>
            <description>
<![CDATA[
Score 42 | Comments 24 (<a href="https://news.ycombinator.com/item?id=23894411">thread link</a>) | @g-garron
<br/>
July 19, 2020 | https://www.garron.blog/posts/host-your-email-server.html | <a href="https://web.archive.org/web/*/https://www.garron.blog/posts/host-your-email-server.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <h2 id="introduction">Introduction</h2>

<p>In 1998 at my first job, I was the system administrator of the biggest Internet provider in Bolivia, it still is the biggest provider. The Internet arrived here in 1995 or 1996, so it was just starting.</p>

<p>I was in charge of BGP routers, with a satellite connection to the Internet, the whole country had just 2 mbps of connection back in those days. I was also in charge of the email server, (roble.scz.entelnet.bo), the DNS server run on a Unix machine while the email and web server on a RedHat Linux powered PC.</p>

<p>Fast forward to 2001, I started my own company, it had nothing to do with system administration, but anyway we needed email service, so I just got an on-line channel with a /28 public IP segment, and setup a CentOS server running bind, sendmail, Dovecot.</p>

<p>In 2007, I started blogging on Drupal running on that same server using Apache, PHP and MySQL <a href="https://www.garron.me/en/go2linux/fedora-centos-root-password-recovery.html">here the first post</a>. I was used to host services.</p>

<h2 id="changes">Changes</h2>

<p>But then I had less time in my hands, it was also more difficult to maintain the services running, keeping up to date with Spam filters and rules became difficult, Bind also had its problems, and Slashdot happened and Bandwidth was not enough.</p>

<p>I moved my server to a web hosting company, and then to a Linode VPS, I also outsourced the DNS service and moved the email to Google Apps.</p>

<p>I migrated my old server to Debian and used it just for:</p>

<ul>
  <li>DHCP</li>
  <li>NAT</li>
  <li>DNS Cache</li>
  <li>Squid</li>
</ul>

<p>That was in 2010 more or less, so I stopped hosting my services, only my blog was in my hands, but at that time I started using Jekyll, so it was just a VPS with Nginx.</p>

<h2 id="back-on-hosting-my-own-services">Back on Hosting my own services</h2>

<p>In April this year I started this blog, but I also enrolled in the Fediverse, and decided to <a href="https://www.garron.blog/posts/my-own-mastodon-server.html">run my own instance</a>, therefore I was hosting again, that was not just a NGINX server, then I read <a href="https://yarmo.eu/post/selfhost-email">this</a>, <a href="https://yarmo.eu/post/selfhost-email-drawbacks">this</a> and <a href="https://lazybear.io/posts/should-you-sefhost-your-email/">this</a>.</p>

<p>And the idea of running my services was in my head again. I wanted to do it different with time, it is not 1998 anymore, so I decided to learn about <a href="https://www.garron.blog/posts/dockerize-everything.html">Docker</a>. So now I have in just one Arch Linux server:</p>

<ul>
  <li>Two static sites</li>
  <li>One Wordpress Site</li>
  <li>One RSS reader (Miniflux)</li>
  <li>One password manager app (Bitwarden)</li>
  <li>One read-later app (<a href="https://www.garron.blog/posts/wallabag-review.html">Wallabag</a>)</li>
  <li>One Webmention app <a href="https://zerokspot.com/weblog/2020/06/14/setting-up-webmentiond/">Webmentiod</a></li>
</ul>

<p>All running with Docker Compose files, but there was something missing, it was email. (Mastodon has its own server -yet-)</p>

<h2 id="hosting-your-own-email-server">Hosting your own email server</h2>

<p>I wanted to run an email server on Docker, so I looked for alternatives and I have found that there are some really nice.</p>

<h3 id="posteiohttpsposteio"><a href="https://poste.io/">Poste.io</a></h3>

<p>I have not tested it, but seems really easy to deploy it has a free version that I think is enough for personal use, with two professional options with a monthly charge.</p>

<h3 id="mailuiohttpsmailuio"><a href="https://mailu.io/">Mailu.io</a></h3>

<p>It is a clone of Poste.io, but using only free, Open Source alternatives, I have installed and configured, it took me just 45 minutes to have server running for one of my domains. It has a tool that create a configuration file based on your options, and it set up everything for you, you can find it <a href="https://setup.mailu.io/1.7/">here</a>, you only need to answer a few questions, and run three or four commands and there you have a complete email server.</p>

<ul>
  <li>SMTP</li>
  <li>IMAP</li>
  <li>POP3</li>
  <li>AntiSpam</li>
  <li>AntiVirus</li>
  <li>Webmail</li>
  <li>Admin web front-end</li>
</ul>

<p>Really a great option, I recommend it to anyone.</p>

<h3 id="docker-mail-serverhttpshubdockercomrtvialdocker-mailserver"><a href="https://hub.docker.com/r/tvial/docker-mailserver">Docker Mail Server</a></h3>

<p>Then I found this one, it is also a complete suite, all Open Source, with really good documentation, and ready to deploy on a server with Docker. It is not as easy as Mailu, but I decided to use it. I followed <a href="https://github.com/tomav/docker-mailserver/wiki/Installation-examples">this guide</a>, yes I know, you still need Gmail or any other provider to send your emails, if you follow that guide. But I was not ready to jump into the pool completely.</p>

<p>So, here is my setup:</p>

<ul>
  <li>MX record points to my server, so all my email is received by my server</li>
  <li>All email is then forwarded to other accounts (Gmail accounts in this case)</li>
  <li>Gmail is configured to use those accounts as default and not the Gmail address, and uses my SMTP server to send</li>
</ul>

<p>This way I am sure I am using my domain, because we already agreed that <a href="https://www.garron.blog/posts/own-your-domain.html">everybody should own his domain</a>, right?. I am using Gmail as my email client.</p>

<p>I am doing this way, because it is easy to search emails when they are with Gmail, also because I am not sure if I may lose my server and lose some important email. I need to be sure about that, because I am hosting for my family, not only for me.</p>

<p>Also having an IMAP client on a cell phone drains the battery, because it polls the server even when there is nothing to download, or if you keep an open IMAP IDLE connection, it will also drain the battery. There is a solution for that, you need <a href="https://pushover.net/">PushOver</a>, and this <a href="https://pushover.net/">IMAP to PushOver</a> app, I have not tested yet, but I think is the way to go.</p>

<p>Edit: After reading some comments on Reddit, these three other options seems to be good ones too.</p>

<ul>
  <li>
    <p><a href="https://mailcow.email/">MailCow</a>: Is another good option also mentioned on HN comments, and this one do have official Docker documentation <a href="https://github.com/mailcow/mailcow-dockerized">here</a></p>
  </li>
  <li>
    <p><a href="https://mailinabox.email/">Mail in a Box</a>: Although there are not official instructions to install it on Docker, it should be possible, here is an <a href="https://hub.docker.com/r/mtrnord/mailinabox/">outdated attempt</a>, and here <a href="https://discourse.mailinabox.email/t/mail-in-a-box-in-docker/4588">another one</a>. But on a VPS it seems work great, and the admin pannel guides you.</p>
  </li>
  <li>
    <p><a href="https://iredmail.org/">iRedMail</a>: This one is also a good option, I have test it two months ago for a week and also works out of the box, you can find a well maintained docker instructions <a href="https://hub.docker.com/r/lejmr/iredmail">here</a></p>
  </li>
</ul>

<h2 id="things-to-consider">Things to consider</h2>

<p>If you plan to host your own email server, there are some important things you need to consider, and it is to properly configure your DNS server. Here is what you need:</p>

<h3 id="spf-record">SPF record</h3>

<p>You really need to configure a SPF record, it is not the same with all providers, but there is plenty of documentation, and it is not hard to do. This record basically tells the recipient server who is authorized to send mail on behalf of your domain. The most common configuration is that the MX server are the authorized ones, something like this.</p>

<pre><code>v=spf1 mx ~all
</code></pre>

<h3 id="dkim-record">DKIM record</h3>

<p>This one is a little bit more difficult, you need to create the DKIM key, your email server may do it, all examples above can do it, once you have it, you need to create a TXT record on your DNS and paste it there, it will look something like this:</p>

<pre><code>v=DKIM1; h=sha256; k=rsa; p=MIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEArARSBHTh32y3VpSEe+pOI7AuILCUsYw1FNL5vTu1P3Mpte50jjkvzg+pBndcSzndQDt6B6mqLBbTwWrZR/j73CTI4ejcYL+xqSXYPU8+xNwu5uwHOMsgWMl15Z/1e1QJD9Ss3Q8aOLOkvHNIgAfSCq
</code></pre>

<p>All your emails will be signed with that, DKIM key, and the receiving server can check if the signature is valid, using the info from the DNS.</p>

<h3 id="dmarc-record">DMARC record</h3>

<p>This one is optional, but is better to have it, you can generate it using on-line tools like <a href="https://mxtoolbox.com/DMARCRecordGenerator.aspx">this one</a>. What it does is to tell what to do when something fails, and who to report that, usually the server admin, well you.</p>

<h3 id="ptr-record">PTR Record</h3>

<p>You need to have a PTR DNS records, that is the reverse DNS for the IP your server is using should point to the same name the A record has. So, for example, if you have this A record</p>

<pre><code>IN A mail.server.com 192.168.0.1
</code></pre>

<p>There should also be a reverse record like this.</p>

<pre><code>IN PTR 192.168.0.1 mail.server.com
</code></pre>

<p>You need to ask to the owner of the IP to add that record for you, if you are using a VPS, you can look in the documentation about that.</p>

<h3 id="mx-record">MX record</h3>

<p>Of course you need a MX record, but you already knew about this one, otherwise maybe is not a good idea to run your own server. This basically informs al sending servers which server is receiving email for your domain.</p>

<h3 id="test">Test</h3>

<p>Once you have set-up everything, wait 24 hours for DNS to propagate and test it, <a href="https://www.mail-tester.com/">this tool</a> is great</p>

<h3 id="secondary-mail-server">Secondary mail server</h3>

<p>Edit 2:</p>

<p>After <a href="https://lobste.rs/s/iatbst/how_self_host_your_email_server#c_hc7vvv">this comment</a> I want to add this recommendation too.</p>

<p>When the main server is down, email can not be delivered, usually it just stays in the senders queue, and once your server is up again all email is delivered to it, but if the outage is long enough some email might be returned to senders and the users will lose them.</p>

<p>The way to avoid this is to have a second machine running a secondary email server, this is simplier to setup, as it will only have the function to store email while the main server is down, and send all emails to it once is up again. There are some good documentation out there, <a href="https://www.howtoforge.com/postfix_backup_mx">here</a> and <a href="https://www.linuxbabe.com/mail-server/how-to-set-up-a-backup-email-server-postfix-ubuntu">here</a>.</p>

<p>The drawback is that now you have a second email to upgrade and keep running, and Spammers ususally target at it, so if you have backups for the main server, and you consider you can have it up and running relatively fast you can avoid a second email. One should also consider who's email is being hosted at the server, and how critical is that email for them.</p>

<p>Critical email might be on an Office 365 <strong>Exchange Online (Plan 1)</strong>, once again, under your domain.</p>

<h2 id="final-words">Final words</h2>

<p>You may not need to host your email server, you can use <a href="https://www.fastmail.com/">Fastmail</a>, <a href="https://www.zoho.com/es-xl/mail/">Zoho</a>, Office 365, or Google Suite, but you <strong>must</strong> use your domain, all accounts, all bank statements should be sent to an email address at your domain, otherwise you can lose control over your accounts. Hosting your email server is not an easy task, dealing with SPAM is hard, and downtimes can be a nightmare too, but you learn one or two things while hosting your email.</p>

        </div></div>]]>
            </description>
            <link>https://www.garron.blog/posts/host-your-email-server.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23894411</guid>
            <pubDate>Mon, 20 Jul 2020 03:24:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I Don't Want to Be a Founder]]>
            </title>
            <description>
<![CDATA[
Score 330 | Comments 228 (<a href="https://news.ycombinator.com/item?id=23894387">thread link</a>) | @kipply
<br/>
July 19, 2020 | https://carolchen.me/blog/founding-bad/ | <a href="https://web.archive.org/web/*/https://carolchen.me/blog/founding-bad/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
  <header>
    
    
  </header>

  <main id="main">
    
<article>
  <header>
    
    
  </header>
  <section id="js-article">
    
<p>I had a brief run with a startup (literally a month) and was faced with the decision of going into a YC Cohort. In that fiasco, I also spent at least twelve hours trying to convince other people to go. It's been half a year, and I've had a lot more time to reflect on reasons as to why one might want to run a startup. As you might've guessed, I decided not to do it and I genuinely believe that running a startup seems like a bad idea for the majority of people I meet who want to become founders. </p>
<p>This post definitely will not apply to everyone (I'd loosely say applicable to 80% of prospective startup founders), but I'd hope there's some valuable thinking in here. Also, note that this is fairly oriented towards technical founders. </p>
<p>Edit: This post also has a very limited scope as it's based off the thinking from my decision to continue interning at Shopify or to go to YC. It's very focused on the Silicon Valley "startup" where you get a VC to give you money and get big in a year, etc etc</p>

<h3 id="commitment">Commitment<a href="#commitment" aria-label="Anchor link for: commitment"> <i></i></a>
</h3>
<p>I'm not talking about commitment to your company. I'm talking about commitment to your cofounder (if you have one, which is likely). </p>
<p>Maybe I'm too young to understand, but marriage seems frightening! My finances, my social life, personal time, and emotional wellbeing would be largely dependent on a single person and that's scary. It should be scary or should at least take a few years for it not to become scary. </p>
<p>Your cofounder is...kind of the same? In a seed-stage it's likely you <em>actually</em> live together, and if you don't, you're likely functionally living together with the amount of work involved. They're responsible for your financial well-being. They may be responsible for the quality of your social lives (most founders spend a lot of time socializing with other tech people + founders). They're tied to your life goals, your dreams, and your passions.</p>
<p>My impression was that my relationship with my cofounder would be more intense than marriage, and <em>extra</em> bad in the event of failure since there's additional loss (and it's statistically likely, but I guess so is marriage). I totally believe that there are cofounder pairs that are completely ready to go through the founder journey and pairs that maybe weren't ready but were fine anyway, but I stand by the statement that it's more intense than marriage and not enough people put care into this. </p>
<h3 id="your-vc-is-not-the-one-at-risk-here">Your VC is Not the One at Risk Here<a href="#your-vc-is-not-the-one-at-risk-here" aria-label="Anchor link for: your-vc-is-not-the-one-at-risk-here"> <i></i></a>
</h3>
<p>I often hear sentiments that resemble "wow these VCs are taking a chance on me I better commit to this!". </p>
<p>VCs are not evil people trying to take advantage of you (actually they might be, but let's assume they're not), but they are not the ones at risk. For them, 150k or a few million is not a huge risk. Seed-stage returns will be from a very small percentage of investments, thus VCs can afford to have comically high error rates as long as they get the few that matter. If you're SoftBank you can do even worse and still have so much money! They make decisions carefully, they care about your success for various reasons, and are generally caring people (in most of my experiences) but in larger abstractions, your startup means nothing to them. </p>
<p>They're not shy about it either, the entire reason they're investing in you is because they think you're more valuable than you cost. 
<img src="https://carolchen.me/blog/img/founding/paul.png" alt=""></p>
<p>Your risk is years of your life, blood, sweat, and tears. The next few years (provided your startup lasts till then) will somewhat be in service to these VCs. The VCs are your "bosses" as you answer to them (though <em>much</em> less than a regular "boss") and to the ones you hope to raise capital from in the future. </p>
<p>It's good to take a risk with increased confidence because qualified people think you have promise. However, that can morph into "I'm going to work on this startup partially in service to these people who believed in me and gave me lots of money". These additional stresses that come from meeting VC expectations and the complications of the dynamics of the relationship can cause various problems.</p>
<h3 id="sense-of-self">Sense of Self<a href="#sense-of-self" aria-label="Anchor link for: sense-of-self"> <i></i></a>
</h3>
<p>This one is the one that got to me most but I can see it being irrelevant to a lot of other people. </p>
<p>Many founders have big egos -- I don't mean they're assholes or overly self-important but they do have very powerful confidence, because that's a valuable skill to have as a founder. Not just confidence in pitching their project to others, but in their vision and their company. They need to believe their company will be successful (though I have met founders who just want to party with VC money for a few years <em>cough cough</em> Neumann). </p>
<p>My first fear was that I created an ego for myself rapidly. Practicing to sell to clients and for your YC interview involves repeating to yourself why you are <em>good</em> and self-hypnosis is fairly powerful. I love feeling good about myself, but I suddenly found myself feeling more confident in myself than what I believed was warranted. More frighteningly, I had a major character and energy change in a couple of weeks. Losing so much of my identity like that was unnerving, not to mention the ripple effects that could've occurred in my social life. </p>
<p>The other fear is coming down from that. Startup founders (especially the more eccentric ones) sometimes believe that they will build something that will change the world. Along with that, their identities start to merge with their company. There's nothing wrong with that, but I also think it's exceptionally tragic to come down from that. It's not just dealing with failure and getting back up on your feet, it's losing a part of your identity. </p>
<h3 id="school-is-generally-a-good-idea-for-prospective-dropouts">School is Generally a Good Idea (for prospective dropouts)<a href="#school-is-generally-a-good-idea-for-prospective-dropouts" aria-label="Anchor link for: school-is-generally-a-good-idea-for-prospective-dropouts"> <i></i></a>
</h3>
<p>Being a good engineer seems underrated for being a good startup founder. Not just being able to code fast, but being able to make good engineering decisions, conduct good technical interviews and attract talent. Some engineering skills can't be worked around with "I am very smart and can learn fast" and require extended time and practice. With that, I also think prospective founders also overestimate the amount of learning on the job that can be done on the engineering side, mostly because it's harder to learn when you're in a rush to release features than if you could take your time on a course project. It's true that founders will learn more than they will in school, but the technical development may not be as strong. My model is that the best schooling experience is better technical education and the best founding experience. </p>

<h3 id="something-to-own">Something to Own<a href="#something-to-own" aria-label="Anchor link for: something-to-own"> <i></i></a>
</h3>
<p>Lots of huge, ground-breaking products have been lead from within a large company. Examples include email client <code>hey.com</code>, Chromebooks, and countless amazing dev tools. </p>
<p>Starting these things in a large company has the benefit of security, resources and recruiting already done for you. Downsides include beaurocracy, not being able to recruit on your own accord and dealing with PR policy. There is also high barriers to starting something within a company, like being senior enough to do so and being at the right company at the right time. </p>
<p>The alternative is starting a project on the side. <a href="https://github.com/ziglang/zig">Ziglang</a> was started as a side project and is now a very promising programming language. The creator has since then left his job to work on Zig, but it is also possible to "own" something significant without even having to leave your job. Examples includes Julia Evan's <a href="https://jvns.ca/">blog</a> (not actually a work-side-project) and line of zines, Cassidy William's <a href="https://drop.com/buy/drop-dsa-astrolokeys-keycaps-by-sailorhg-and-cassidoo">keycap line</a>, Nick Frosst's successful and awesome <a href="https://goodkidofficial.com/">band</a> and many more. I understand that it's not the extent of "oh yeah Google? I built that", but I think the expected value is much higher in creating and owning something that isn't a startup. </p>
<h3 id="getting-rich">Getting Rich<a href="#getting-rich" aria-label="Anchor link for: getting-rich"> <i></i></a>
</h3>
<p>A lot of people claim that startups are less money, but I find for signicant number of founders, that's not true -- not because they'll definitely have a good exit, but because they're skilled in ways that allow them to raise enough money to pay themselves like they would at a big company. If that applies to you, then going to a startup probably is your best shot at getting rich! For other people, the expected value of industry (particularly joining a well-founded early-stage startup) is usually higher. </p>
<h3 id="not-being-at-school-for-prospective-dropouts">Not Being at School (for prospective dropouts)<a href="#not-being-at-school-for-prospective-dropouts" aria-label="Anchor link for: not-being-at-school-for-prospective-dropouts"> <i></i></a>
</h3>
<p>This seems like a valid reasons for the average CS student. School is a place where you answer to professors who don't always understand industry and do homework assignments that no one will care about. However, it seems like all of these problems can be significantly if not fully solved by building a better school experience for yourself. </p>
<p>A better program can improve many things, such as <a href="http://www.olin.edu/">Olin College of Engineering</a> that has a project-based curriculum, <a href="https://www.makeschool.com/">Make School</a> that is a two year applied-engineering degree program or <a href="https://devdegree.ca/">Dev Degree</a>, where you can work at Shopify and take more applied courses taught by Shopify throughout your degree. These programs are small and selective, but probably not harder than a semi-successful startup. Dev Degree also happens to be more financially sound, with Shopify paying for your tuition and a salary, and Make School tuition is 70k for the entire degree. </p>
<p>Another alternative is to just be worse at school and learn on the side and/or to morph your silly school assignments into productive skills and useful outputs. The <a href="http://coconut-lang.org/">Coconut Programming Language</a> was built by someone while they were in school. Some things like dynamic programming that are often deemed useless theoretical things can have <a href="https://thume.ca/2017/06/17/tree-diffing/">industry applications</a>. People have also taken mundane school projects like this compiler that almost every school will have you build in a compilers course and end up with <a href="https://thume.ca/2019/04/29/comparing-compilers-in-rust-haskell-c-and-python/">educational findings for engineers in general</a> (also see <a href="https://news.ycombinator.com/item?id=20192645">HackerNews thread</a>). In five weeks, my friend Maas was able to launch <a href="https://medium.com/@maaslalani/launch-5d02cc5e05f5">five relatively successful products</a> while enrolled in Dev Degree. </p>
<p>School is already a powerful environment of hardwork, fun and learning. I think it is a more cohesive …</p></section></article></main></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://carolchen.me/blog/founding-bad/">https://carolchen.me/blog/founding-bad/</a></em></p>]]>
            </description>
            <link>https://carolchen.me/blog/founding-bad/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23894387</guid>
            <pubDate>Mon, 20 Jul 2020 03:21:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Reverse-engineering and analysis of SanDisk High Endurance microSDXC card]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23892463">thread link</a>) | @Manozco
<br/>
July 19, 2020 | https://ripitapart.com/2020/07/16/reverse-engineering-and-analysis-of-sandisk-high-endurance-microsdxc-card/ | <a href="https://web.archive.org/web/*/https://ripitapart.com/2020/07/16/reverse-engineering-and-analysis-of-sandisk-high-endurance-microsdxc-card/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p><strong>TL;DR – The SanDisk High Endurance cards use SanDisk/Toshiba <a href="https://www.tomshardware.com/news/wd-sandisk-bics3-64-layer-3d-nand,32328.html" target="_blank" rel="noopener">3D TLC Flash</a>. It took way, way more work than it should have to figure this out (thanks for nothing, SanDisk!).</strong></p><p>In a <a href="https://ripitapart.com/2019/08/17/unboxing-and-review-of-sandisk-64gb-microsdxc-high-endurance-card/" target="_blank" rel="noopener">previous blog post</a>, I took a look at SanDisk’s microSD cards that were aimed for use in write-intensive applications like dash cameras. In that post I took a look at its performance metrics, and speculated about what sort of NAND Flash memory is used inside. SanDisk doesn’t publish any detailed specifications about the cards’ internal workings, so that means I have no choice but to reverse-engineer the <del>can of worms</del> card myself.</p><p>In the hopes of uncovering more information, I sent an email to SanDisk’s support team asking about what type of NAND Flash they are using in their High Endurance lineup of cards, alongside endurance metrics like P/E (Program/Erase) cycle counts and total terabytes written (TBW). Unfortunately, the SanDisk support rep couldn’t provide a satisfactory answer to my questions, as they’re not able to provide any information that’s not listed in their public spec sheets. They said that all of their cards use MLC Flash, which I guess is correct if you call TLC Flash 3-bit MLC (which Samsung does).</p><div>
<blockquote><p>Dear Jason,</p>
<p>Thank you for contacting SanDisk® Global customer care. We really appreciate you being a part of our SanDisk® family.</p>
<p>I understand that you wish to know more about the SanDisk® High Endurance video monitoring card, as such please allow me to inform you that all our SanDisk® memory cards uses Multi level cell technology (MLC) flash. However, the read/write cycles for the flash memory is not published nor documented only the read and write speed in published as such they are 100 MB/S &amp; 40 MB/s. The 64 GB card can record Full HD video up to 10,000 hours. To know more about the card you may refer to the link below:</p>
<p><a title="Click to follow link: https://www.sandisk.com/home/memory-cards/microsd-cards/high-endurance-microsd" href="https://www.sandisk.com/home/memory-cards/microsd-cards/high-endurance-microsd" target="_blank" rel="noopener">SANDISK HIGH ENDURANCE VIDEO MONITORING microSD CARD</a></p>
<p>Best regards,<br>
Allan B.<br>
SanDisk® Global Customer Care</p></blockquote>
<p>I’ll give them a silver star that says “You Tried” at least.</p>

<p>While (micro)SD cards feel like a solid monolithic piece of technology, they’re made up of multiple different chips, each performing a different role. A basic SD card will have a controller that manages the NAND Flash chips and communicates with the host (PC, camera, etc.), and the NAND Flash itself (made up of 1 or more Flash dies). Bunnie Huang’s blog, Bunnie Studios, has an excellent article on the internals of SD cards, including counterfeits and how they’re made – check it out <a href="https://www.bunniestudios.com/blog/?p=3554" target="_blank" rel="noopener">here</a>.</p>
<div data-shortcode="caption" id="attachment_2132"><p><a href="https://ripitapart.files.wordpress.com/2019/10/sd-card-anatomy-2.png"><img aria-describedby="caption-attachment-2132" data-attachment-id="2132" data-permalink="https://ripitapart.com/2020/07/16/reverse-engineering-and-analysis-of-sandisk-high-endurance-microsdxc-card/sd-card-anatomy/" data-orig-file="https://ripitapart.files.wordpress.com/2019/10/sd-card-anatomy-2.png" data-orig-size="268,476" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="SD Card Anatomy" data-image-description="<p>Block diagram of a typical SD card.</p>
" data-medium-file="https://ripitapart.files.wordpress.com/2019/10/sd-card-anatomy-2.png?w=169" data-large-file="https://ripitapart.files.wordpress.com/2019/10/sd-card-anatomy-2.png?w=268" src="https://ripitapart.files.wordpress.com/2019/10/sd-card-anatomy-2.png?w=584" alt="SD Card Anatomy" srcset="https://ripitapart.files.wordpress.com/2019/10/sd-card-anatomy-2.png 268w, https://ripitapart.files.wordpress.com/2019/10/sd-card-anatomy-2.png?w=84 84w" sizes="(max-width: 268px) 100vw, 268px"></a></p><p id="caption-attachment-2132">Block diagram of a typical SD card.</p></div>
<p>MicroSD cards often (but not always!) include test pads, used to program/test the NAND Flash during manufacture. These can be exploited in the case of <a href="https://blog.acelaboratory.com/pc-3000-flash-monolith-pinout-research.html" target="_blank" rel="noopener">data recovery</a>, or to reuse microSD cards that have a defective controller or firmware by turning the card into a piece of raw NAND Flash – check out Gough Lui’s adventures <a href="https://goughlui.com/2015/04/05/teardown-optimization-comsol-8gb-usb-flash-stick-au6989sn-gt-sdtnrcama-008g/" target="_blank" rel="noopener">here</a>. Note that there is no set standard for these test pads (even for the same manufacturer!), but there are common patterns for some manufacturers like SanDisk that make reverse-engineering easier.</p>

<p>microSD cards fall into a category of “monolithic” Flash devices, as they combine a controller and raw NAND Flash memory into a single, inseparable package. Many manufacturers break out the Flash’s data bus onto hidden (and nearly completely undocumented) test pads, which some other memory card and USB drive manufacturers take advantage of to make cheap storage products using failed parts; the controller can simply be electrically disabled and the Flash is then used as if it were a regular chip.</p>
<p>In the case of SanDisk cards, there is very limited information on their cards’ test pad pinouts. Each generation has slight differences, but the layout is mostly the same. <del>These differences can be fatal, as the power and ground connections are sometimes reversed (this spells instant death for a chip if its power polarity is mixed up!).</del></p>
<p><strong>CORRECTION (July 22, 2020):</strong> <em>Upon further review, I might have accidentally created a discrepancy between the leaked pinouts online, versus my own documentation in terms of power polarity; see the “Test Pad Pinout” section.</em></p>
<p>My card (and many of their higher-end cards – that is, not their Ultra lineup) features test pads that aren’t covered by solder mask, but are instead covered by some sort of screen-printed epoxy with a laser-etched serial number on top. With a bit of heat and some scraping, I was able to remove the (very brittle) coating on top of the test pads; this also removed the serial number which I believe is an anti-tamper measure by SanDisk.</p>

		
		

<p>After cleaning off any last traces of the epoxy coating, I was greeted with the familiar SanDisk test pad layout, plus a few extra on the bottom.</p>

<p>The breakout board is relatively simple in concept: for each test pad, bring out a wire that goes to a bigger test point for easier access, and wire up the normal SD bus to an SD connector to let the controller do its work with twiddling the NAND Flash bus. Given how small each test pad is (and how many), things get a bit… messy.</p>

		
		

<p>I started by using double-side foam adhesive tape to secure the SD card to a piece of perfboard. I then tinned all of the pads and soldered a small 1uF ceramic capacitor across the card’s power (Vcc) and ground (GND) test pads. Using 40-gauge (0.1 mm, or 4-thousandths of an inch!) magnet wire, I mapped each test pad to its corresponding machine-pin socket on the perfboard. Including the extra test pads, that’s a total of 28 tiny wires!</p>
<p>For the SD connector side of things, I used a flex cable for the <a href="http://xtc2clip.org/how-it-works" target="_blank" rel="noopener">XTC 2 Clip</a> (a tool used to service HTC Android devices), as it acted as a flexible “remote SD card” and broke out the signals to a small ribbon cable. I encased the flex cable with copper tape to act as a shield against electrical noise and to provide physical reinforcement, and soldered the tape to the outer pads on the perfboard for reinforcement. The ribbon cable end was then tinned and each SD card’s pin was wired up with magnet wire. The power lines were then broken out to an LED and resistor to indicate when the card was receiving power.</p>

<p>With all of the test pads broken out to an array of test pins, it was time to make sense of what pins are responsible for accessing the NAND Flash inside the card.</p>
<h2>Test Pad Pinout</h2>
<div data-shortcode="caption" id="attachment_2165"><p><a href="https://ripitapart.files.wordpress.com/2020/07/sandisk-high-endurance-microsd-test-pad-pinout.png"><img aria-describedby="caption-attachment-2165" data-attachment-id="2165" data-permalink="https://ripitapart.com/sandisk-high-endurance-microsd-test-pad-pinout/" data-orig-file="https://ripitapart.files.wordpress.com/2020/07/sandisk-high-endurance-microsd-test-pad-pinout.png" data-orig-size="1666,935" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="SanDisk High Endurance microSD Test Pad Pinout" data-image-description="<p>Diagram of the test pads on SanDisk’s High Endurance microSD card.</p>
" data-medium-file="https://ripitapart.files.wordpress.com/2020/07/sandisk-high-endurance-microsd-test-pad-pinout.png?w=300" data-large-file="https://ripitapart.files.wordpress.com/2020/07/sandisk-high-endurance-microsd-test-pad-pinout.png?w=584" src="https://ripitapart.files.wordpress.com/2020/07/sandisk-high-endurance-microsd-test-pad-pinout.png?w=584&amp;h=328" alt="Diagram of the test pads on SanDisk's High Endurance microSD card." width="584" height="328" srcset="https://ripitapart.files.wordpress.com/2020/07/sandisk-high-endurance-microsd-test-pad-pinout.png?w=584&amp;h=328 584w, https://ripitapart.files.wordpress.com/2020/07/sandisk-high-endurance-microsd-test-pad-pinout.png?w=1168&amp;h=656 1168w, https://ripitapart.files.wordpress.com/2020/07/sandisk-high-endurance-microsd-test-pad-pinout.png?w=150&amp;h=84 150w, https://ripitapart.files.wordpress.com/2020/07/sandisk-high-endurance-microsd-test-pad-pinout.png?w=300&amp;h=168 300w, https://ripitapart.files.wordpress.com/2020/07/sandisk-high-endurance-microsd-test-pad-pinout.png?w=768&amp;h=431 768w, https://ripitapart.files.wordpress.com/2020/07/sandisk-high-endurance-microsd-test-pad-pinout.png?w=1024&amp;h=575 1024w" sizes="(max-width: 584px) 100vw, 584px"></a></p><p id="caption-attachment-2165">Diagram of the test pads on SanDisk’s High Endurance microSD card. (click to enlarge)</p></div>
<p>The overall test pad pinout was the same for other microSD cards from SanDisk<del>, but there were some differences, primarily regarding the layout of the power pads; notably, <strong>the</strong><strong>main power pins are backwards</strong>! This can destroy the card if you’re not careful when applying power.</del></p>
<p><strong>CORRECTION (July 22, 2020):</strong> <em>I might actually have just gotten my own documentation mixed up in terms of the power and ground test pads. Regardless, one should always be careful to ensure the correct power polarity is sent to a device.</em></p>
<p>I used my <a href="https://www.dreamsourcelab.com/shop/logic-analyzer/dslogic-plus/" target="_blank" rel="noopener">DSLogic Plus</a> logic analyzer to analyze the signals on all of the pins. Since the data pinout was previously discovered, the hard part of figuring out what each line represented (data bus, control, address, command, write-protect, ready/busy status) was already done for me. However, not all of the lines were immediately evident as the pinouts I found online only included the bare minimum of lines to make the NAND Flash accessible, with one exception being a control line that places the controller into a reset state and releases its control of the data lines (this will be important later on).</p>
<p>By sniffing the data bus at the DSLogic’s maximum speed (and using its 32 MB onboard buffer RAM), I was able to get a clear snapshot of the commands being sent to the NAND Flash from the controller during initialization.</p>
<h2>Bus Sniffing &amp; NAND I/O 101 (writing commands, address, reading data)</h2>
<p>In particular, I was looking for two commands: RESET (0xFF), and READ ID (0x90). When looking for a command sequence, it’s important to know how and when the data and control lines change. I will try to explain it step-by-step, but if you’re interested there is an <a href="https://user.eng.umd.edu/~blj/CS-590.26/micron-tn2919.pdf" target="_blank" rel="noopener">introductory white paper</a> by Micron that explains all of the fundamentals of NAND Flash with much more information about how NAND Flash works.</p>

		
		

<p>When a RESET command is sent to the NAND Flash, first the /CE (Chip Select, Active Low) line is pulled low. Then the CLE (Command Latch Enable) line is pulled high; the data bus is set to its intended value of 0xFF (all binary ones); then the /WE (Write Enable, Active Low) line is pulsed from high to low, then back to high again (the data bus’ contents are committed to the chip when the /WE line goes from low to high, known as a “rising edge”); the CLE line is pulled back low to return to its normal state. The Flash chip will then pull its R/B (Ready/Busy Status) line low to indicate it is busy resetting itself, then releases the line back to its high state when it’s finished.</p>
<p>The READ ID command works similarly, except after writing the command with 0x90 (binary 1001 0000) on the data bus, it then pulls the ALE (Address Latch Enable) line high instead of CLE, and writes 0x00 (all binary zeroes) by pulsing the /WE line low. The chip transfers its internally programmed NAND Flash ID into its internal read register, and the data is read out from the device on each rising edge of the /RE (Read Enable, Active Low) line; for most devices this is 4 to 8 bytes of data.</p>
<h2>NAND Flash ID</h2>
<p>For each NAND Flash device, it has a (mostly) unique ID that identifies the manufacturer, and other functional data that is defined by that manufacturer; in other words, only the manufacturer ID, assigned by the <a href="https://en.wikipedia.org/wiki/JEDEC" target="_blank" rel="noopener">JEDEC Technology Association</a>, is well-defined.</p>
<p>The first byte represents the Flash manufacturer, and the rest (2 to 6 bytes) define the device’s characteristics, as set out by the manufacturer themselves. Most NAND vendors are very tight-lipped when it comes to datasheets, and SanDisk (and by extension, Toshiba/Kioxia) maintain very strict control, save for some slightly outdated …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://ripitapart.com/2020/07/16/reverse-engineering-and-analysis-of-sandisk-high-endurance-microsdxc-card/">https://ripitapart.com/2020/07/16/reverse-engineering-and-analysis-of-sandisk-high-endurance-microsdxc-card/</a></em></p>]]>
            </description>
            <link>https://ripitapart.com/2020/07/16/reverse-engineering-and-analysis-of-sandisk-high-endurance-microsdxc-card/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23892463</guid>
            <pubDate>Sun, 19 Jul 2020 21:09:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Clipboard Injection on the Financial Times]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23891630">thread link</a>) | @ajyoon
<br/>
July 19, 2020 | https://andrewyoon.art/blog/ft-clipboard | <a href="https://web.archive.org/web/*/https://andrewyoon.art/blog/ft-clipboard">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p>While doing some research today I was reading <a href="https://www.ft.com/content/b46f5a58-aa2e-11db-83b0-0000779e2340">an old column</a> by James Boyle about then-recent experiments in open access publishing in 2007. Seeing an interesting snippet, I did the ol’ <code>Ctrl-C</code> and pasted it into my notes, where I was surprised to see this prepended to my selection:</p>

<blockquote>
  <p>Please use the sharing tools found via the share button at the top or side of articles. Copying articles to share with others is a breach of FT.com T&amp;Cs and Copyright Policy. Email licensing@ft.com to buy additional rights. Subscribers may share up to 10 or 20 articles per month using the gift article service. More information can be found at https://www.ft.com/tour.</p>
</blockquote>

<p>I’ve seen websites garble copied text or outright disable it, but I’ve never seen a site actually inject unrelated text before.</p>

<p>I was curious how they had implemented this, so I fired up firefox devtools and searched for a snippet of the notice in the site sources.</p>

<figure>
  <img src="https://andrewyoon.art/img/posts/ft-copy/devtools.png" alt="firefox devtools search">
</figure>

<p>Thankfully, the FT provides a sourcemap so I was able to find the de-minified <code>legal-copy/main.js</code> implementation and see what was going on. Essentially, it boils down to this:</p>

<div><div><pre><code><span>function</span> <span>handleCopy</span><span>(</span><span>e</span><span>)</span> <span>{</span>
    <span>var</span> <span>selection</span> <span>=</span> <span>window</span><span>.</span><span>getSelection</span><span>().</span><span>toString</span><span>();</span>
    <span>var</span> <span>wordCount</span> <span>=</span> <span>selection</span><span>.</span><span>split</span><span>(</span><span>/</span><span>\s</span><span>+/</span><span>).</span><span>length</span><span>;</span>
    <span>if</span> <span>(</span><span>wordCount</span> <span>&gt;</span> <span>30</span><span>)</span> <span>{</span>
        <span>var</span> <span>patchedText</span> <span>=</span> <span>"</span><span>hello world</span><span>\n</span><span>"</span> <span>+</span> <span>selection</span><span>;</span>
        <span>e</span><span>.</span><span>clipboardData</span><span>.</span><span>setData</span><span>(</span><span>'</span><span>text/plain</span><span>'</span><span>,</span> <span>patchedText</span><span>);</span>
    <span>}</span>
    <span>e</span><span>.</span><span>preventDefault</span><span>();</span>
<span>}</span>
<span>document</span><span>.</span><span>body</span><span>.</span><span>addEventListener</span><span>(</span><span>'</span><span>copy</span><span>'</span><span>,</span> <span>handleCopy</span><span>);</span>
</code></pre></div></div>

<p>It includes some subtleties around detecting browser support for the rich <a href="https://developer.mozilla.org/en-US/docs/Web/API/ClipboardEvent/clipboardData">ClipboardEvent API</a> and handling legacy Chrome quirks, as well as trying to disable the “feature” when it suspects a screen reader is being used (points to the FT for accessibility consideration, though I have a feeling this was a response to a complaint).</p>

<p>Is copying 30 words legal? The injected text warns “Copying articles to share with others is a breach of FT.com T&amp;Cs and Copyright Policy”—copying <em>articles</em>, not 30 words. I’m no lawyer, but <a href="https://en.wikipedia.org/wiki/Fair_use">fair use</a> protects a great many things one might copy 30 words for, like quotation in another article, or in my case, personal notekeeping. While some infringing uses can be imagined, does this warrant such a violation of internet norms?</p>

<p>The current working draft of the <a href="https://w3c.github.io/clipboard-apis/">W3C Clipboard spec</a> describes mechanical use-cases for manipulating the clipboard like attaching metadata, rich text transfer, and translating mathematical notation to plaintext—not scaring people away from exercising their rights. There’s a set of implicit ground rules for what should and should not be done on websites. Interfering with standard access patterns like closing tabs and using right-click menus violates the social contract of the internet and further threatens its endangered state as a thing to be used, not a thing that uses you.</p>

<p>Incidentally, the article I was reading was by <a href="http://james-boyle.com/">James Boyle</a>, a copyright reformist who was a columnist for the Financial Times largely because they allowed him to <a href="https://law.duke.edu/boylesite/bipolar.html">retain his copyrights</a>, with at least some under <a href="http://creativecommons.org/licenses/by-nc-nd/2.0/">Creative Commons licenses</a>, so it seems likely I actually <em>could</em> copy the whole article if I wanted to.</p>

<p>It turns out lots of other people have noticed this kind of bad behavior and have built circumventing browser extensions like <a href="https://addons.mozilla.org/en-US/firefox/addon/absolute-enable-right-click">this one</a> which I just happily used to copy this passage from <a href="https://www.ft.com/content/b46f5a58-aa2e-11db-83b0-0000779e2340">the article</a>:</p>

<blockquote>
  <p>The internet makes copying cheap. Businesses that see their livelihood as dependent on the restriction of copying – concentrated in the recording, film, publishing and software industries – are understandably upset. Their goal is to have the same ability to control their content as they had in an analog world but to keep all the benefits of pervasiveness, cost saving, and viral marketing that a global digital network brings. To that end, they have moved aggressively to change laws worldwide, to introduce stiffer penalties, expand rights, mandate technological locks, forbid reverse engineering, and increase enforcement. It is not so much a case of wanting to have their cake and eat it, as to have their cake and make your cake illegal.</p>
</blockquote>

  </div>

</article>

      </div>
    </div></div>]]>
            </description>
            <link>https://andrewyoon.art/blog/ft-clipboard</link>
            <guid isPermaLink="false">hacker-news-small-sites-23891630</guid>
            <pubDate>Sun, 19 Jul 2020 19:14:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Eurozone’s grappling with crisis, class war and the North-South divide]]>
            </title>
            <description>
<![CDATA[
Score 16 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23891282">thread link</a>) | @jcfrei
<br/>
July 19, 2020 | https://www.yanisvaroufakis.eu/2020/07/16/the-eurozones-grappling-with-crisis-class-war-the-north-south-divide-berliner-verlag-interview/ | <a href="https://web.archive.org/web/*/https://www.yanisvaroufakis.eu/2020/07/16/the-eurozones-grappling-with-crisis-class-war-the-north-south-divide-berliner-verlag-interview/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
	<article id="post-22719">

		<section>
			

			<h3><span><strong><img src="https://i0.wp.com/www.yanisvaroufakis.eu/wp-content/uploads/2020/07/Screenshot-2020-07-16-at-9.53.43-AM.png?resize=2424%2C772&amp;ssl=1" alt="" width="2424" height="772" srcset="https://i0.wp.com/www.yanisvaroufakis.eu/wp-content/uploads/2020/07/Screenshot-2020-07-16-at-9.53.43-AM.png?w=2424&amp;ssl=1 2424w, https://i0.wp.com/www.yanisvaroufakis.eu/wp-content/uploads/2020/07/Screenshot-2020-07-16-at-9.53.43-AM.png?resize=1536%2C489&amp;ssl=1 1536w, https://i0.wp.com/www.yanisvaroufakis.eu/wp-content/uploads/2020/07/Screenshot-2020-07-16-at-9.53.43-AM.png?resize=2048%2C652&amp;ssl=1 2048w" sizes="(max-width: 1000px) 100vw, 1000px" data-recalc-dims="1">What did you think when the Euro-group elected its new leader last week? At least this was not the outcome Frau Merkel had wished?</strong></span></h3>
<h3>My first thought was that it spelled the end of any possibility of harmonizing corporate tax rates across the Eurozone, an issue that I am on Mrs Merkel’s side. The second thought was that the Irish finance minister’s victory was a victory for forces pushing for greater, not less, austerity across the European Union. It was not a good moment for Europe. [From the above you can see that I never automatically opposed whatever Mrs Merkel favoured!]</h3>
<h3><span><strong>If you look at fiscal and monetary politics in the Euro area today – what is your impression? Have the Europeans learnt a lesson from the Greek crisis?</strong></span></h3>
<h3>To begin with, please let us not conflate Europe’s rulers with the… Europeans. Turning now to your question, Europe’s leaders resemble the Bourbons: they have forgotten nothing and they have learned nothing. More precisely, while the ECB’s monetary policy reaction has been far improved since Mario Draghi succeeded the catastrophic Jean-Claude Trichet’s, monetary policy has long ago reached the limits of what it can do. So, the only thing that matters now is Europe’s fiscal stance.</h3>
<h3><span>Our fiscal stance remains the most tepid and the weakest amongst developed economies. It must be considered yet another dereliction of duty for two reasons, one ex ante and one ex post.</span></h3>
<h3>The ex ante failure has to do with what we are doing now, in 2020: Taking out all the loans provided to business (that are irrelevant fiscally), the fiscal injections into the EU economy are: (a) small overall and (b) hopelessly lopsided, with Germany on the one hand pumping a great deal more fiscal power into its economy while Italy and Spain cannot – the result being a magnification of Europe’s greatest weakness: our internal imbalances.</h3>
<h3>The ex post failure stems from the demise of the idea of a Eurobond – the only instrument that could prevent, in 2021 or 2022 (when the fiscal compact is re-energised) massive new austerity in countries like Italy and Spain. Since the budget deficit of these countries will exceed 10% of GDP, you can imagine that the fiscal consolidation necessary to return to the fiscal compact is going to produce a further increase in the imbalances that have been tearing the Eurozone apart since 2010.</h3>
<h3><span><strong>You are very critical of the European Recovery Fund. Why?</strong></span></h3>
<h3>For at least three important reasons: First, it was devised as a substitute to the Eurobond, which it is not. Secondly, because its structure is divisive and likely to cause greater disunity among Europeans. Thirdly, because it will be too little and it will come too late to counter-act the new austerity that the re-introduction of the fiscal compact will bring. Let me explain these three objections in greater detail.</h3>
<h3>While it is true that the Recovery Fund involves a degree of common debt, it is explicitly (and legally) designed as a one-off debt with specific details on how and when it will be repaid. Thus, we have wasted a fantastic opportunity to create the equivalent of US Treasury Bills, which is what makes the dollar powerful and the United States far better placed to absorb shocks.</h3>
<h3>Moreover, I am appalled that the Commission specified in advance, based on backward looking data, which country will receive how many billions. It was an awful thing to do because it set one country, one people, against another. What we needed was a sum that would be diverted to regions in Europe most in need of support. There are poor parts of Germany that will be hit more than richer parts of Spain. The total sum available should be distributed ex post on the basis of the needs of particular European regions and sectors, not by means of the usual sordid bargain in Brussels that divides a pie between governments.</h3>
<h3>Lastly, this Recovery Fund will do very little to ameliorate the austerity that the re-introduction of the fiscal compact will necessitate. It will fail in the same way that the many billions of the structural funds failed to ameliorate the effects of austerity between 2010 and 2016.</h3>
<h3><span><strong>What consequences will the Fund have in Europe?</strong></span></h3>
<h3>It will entrench the false view in Northern Europe that it was all about hand-outs to the Southerners while, at once, entrenching the false view in Europe’s South that the whole of the North benefits from pushing the South into greater impecunity.</h3>
<h3><span><strong>What will happen to the working class people in the Euro-Zone?</strong></span></h3>
<h3>It will continue to watch its prospects decline both in the North and in the South while the financiers and the members of the boards of directors of large companies enjoy the fruits of socialism for the oligarchy and stinging austerity for the majority of the Greeks and of the Germans.</h3>
<h3><span><strong>Will the consequences be different for Greece and Germany, aka South and North?</strong></span></h3>
<h3>Yes and no. Workers in the North and in the South will be facing increasing precarity and will be getting angrier and more discontented. Except that the rate of deterioration will be much greater in countries like Greece, the result being the continuation of the mass exodus of young people which makes our countries of the South impossible to sustain as functioning societies.</h3>
<h3><span><strong>What role are the “frugal four” playing – isn’t it legitimate to keep in mind the public debt in each country?</strong></span></h3>
<h3>Governments have a duty to defend their people from a number of threats. One of them is excessive public debt. But, there is also excessive private debt. And, even more ominously, low investment that jeopardises a nation’s chances to repay both private and public debt. The so-called frugal four are working in favour of large conglomerates that want their cake and to eat it: They like the effect Italy and Greece are having at keeping the exchange value of the euro low (so as to maximise their exports, eg, to China) and the interest rates below zero (so as to get free money from the ECB). Like all free-riders, they take what suits them but then take no responsibility for the damage that the policies favouring them do both to the South and to their own working classes (which find themselves increasingly squeezed and indebted as part of the same process that squeezes and indebts the South).</h3>
<h3><span><strong>You frequently speak of “oligarchs” – who are they in Europe?</strong></span></h3>
<h3>In the early fifties, when the EEC was first created, they were the captains of the steel and coal industries. Soon after, they were joined by the electrical goods industries plus the automakers. In the 1980s the captains of industry were increasingly sidelined by the bankers who, by 2008, had ended up as the masters of Europe’s destiny.</h3>
<h3><span><strong>Can the European oligarchs at least provide new jobs and/or be competitive with the US or China?</strong></span></h3>
<h3>Absolutely not. The capacity of European financialised capitalism to produce good quality jobs is at its nadir and is getting worse and worse due to the EU’s failure to create the public finance instruments that DiEM25 has been proposing for years now – e.g. a joint European Investment Bank and European Central Bank program by which EIB-bonds can be backed by ECB-bonds to mobilise idle cash (that is currently destroying German pension funds) and turn it into green investments.</h3>
<h3><span><strong>Most observers have no doubt that there will be austerity in exchange of money from the fund. What austerity else can Greece bear, keeping in mind the sacrifices that have already been made?</strong></span></h3>
<h3>This is like asking a patient nearing death as a result of having been subjected to massive radiation how much more radiation she can take!</h3>
<h3><span><strong>What is the current state of the Greek economy? Debt is still at 180 percent, despite 200 billion Euro for bailing out the banks?</strong></span></h3>
<h3>Greece’s debt is unpayable not despite but <u>because</u> of the banks’ bailout. Since 2009 I have been saying that Europe’s rulers, and this is where I do blame Mrs Merkel, cynically saved idiotic bankers by transferring their losses onto the shoulders of Europe’s weakest taxpayers. Mrs Merkel, Mr Sarkozy, the troika and everyone else who has maintained this crime-against-logic for a decade will forever by guilty in the conscience of Europe’s progressives. [And, by the way, Greece’s debt is not well about 200% of GDP!]</h3>
<h3><span><strong>What will Europe look like if the Recovery Fund really delivers on 750 billion Euro?</strong></span></h3>
<h3>Sad and divided. For a start, of these 750 billions, 250 billions will be loans. The last thing Europe’s devasted businesses that are facing insolvency is more loans – Greece’s fate provides a great lesson to those who refuse to recognise this simple truth. As for the remaining 500 billions, more than 100 of them are re-purposed funds (i.e. not new money) and another 200 will be sacrificed to buy the frugal four’s consent. That leaves us with, at best, 300 billion. It sounds a lot but it is puny. Over three years it comes to less than 1% of GDP. Given that the austerity that Berlin will demand and Brussels will impose will be more than 4% of GDP over the same year, the only conclusion is that, as the pandemic (hopefully) subsides, European capitalism will be inflicting another unnecessary blow to itself – just as in 2010.</h3>
<h3><span><strong>In your view – what would be an adequate program to cope with the Corona-devastation?</strong></span></h3>
<h3>DiEM25 has already answered this – our <a href="https://diem25.org/diem25-presents-covid-19-economic-response-plan-and-green-recovery-investment-program/">3 point plan</a>.</h3>
<ol>
<li>
<h3>The ECB must issue a long-maturity, 30-year, Eurobond for €1 trillion euros solely backed by the ECB,&nbsp;with the possibility of further issuance in needs be. This €1 trillion should then be used to replace national debt, in proportion to the coronavirus-induced regional recessions &amp; public health costs.</h3>
</li>
<li>
<h3>The ECB must inject a €2000 European Solidarity Cash Payment to every European resident</h3>
</li>
<li>
<h3>The EU must create a European Green Recovery &amp; Investment Program funded by <em>EIB bonds&nbsp;approximately equal to 5% of the EU’s GDP, to be backed in the bond markets by the ECB</em>.</h3>
</li>
</ol>
<h3><span><strong>You are talking about “class war”. Are we already there?</strong></span></h3>
<h3>We have been there since 2010. The austerity imposed upon Greece in May 2010 was the first move toward a fiscal …</h3></section></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.yanisvaroufakis.eu/2020/07/16/the-eurozones-grappling-with-crisis-class-war-the-north-south-divide-berliner-verlag-interview/">https://www.yanisvaroufakis.eu/2020/07/16/the-eurozones-grappling-with-crisis-class-war-the-north-south-divide-berliner-verlag-interview/</a></em></p>]]>
            </description>
            <link>https://www.yanisvaroufakis.eu/2020/07/16/the-eurozones-grappling-with-crisis-class-war-the-north-south-divide-berliner-verlag-interview/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23891282</guid>
            <pubDate>Sun, 19 Jul 2020 18:24:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[My failed startup: Why it failed and why I’m releasing all the source code]]>
            </title>
            <description>
<![CDATA[
Score 9 | Comments 2 (<a href="https://news.ycombinator.com/item?id=23891111">thread link</a>) | @ve55
<br/>
July 19, 2020 | https://adamfallon.com/2020/07/18/my-failed-start-up/ | <a href="https://web.archive.org/web/*/https://adamfallon.com/2020/07/18/my-failed-start-up/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

		<div>

			
<p><em>Why it failed and why i’m releasing all the source code for free.</em></p>



<div><p>This is a long post.</p><p>If you are just looking for the code click <a href="#the-code">here</a></p></div>



<p>When lockdown started in the U.K I started looking for ways to spend my extended time at home. I wasn’t working because I had quit my job on Feb 16th to travel the world. Timing has never been my strong suit. </p>



<p>So instead of sitting around I decided to start a contracting company, got awarded a few small contracts and I released a <a aria-label="undefined (opens in a new tab)" href="https://apps.apple.com/gb/app/nitronotes/id1502080216" target="_blank" rel="noreferrer noopener nofollow">few</a> <a aria-label="undefined (opens in a new tab)" href="https://apps.apple.com/dz/app/countdownplusplus/id1497707393" target="_blank" rel="noreferrer noopener nofollow">apps</a> written in SwiftUI. But I wanted a bigger project to sink my teeth into. </p>



<p>There were two ideas I kept coming back too;</p>



<ol><li>A hosted org-mode in the browser. </li><li>Some sort of local social network.</li></ol>



<p>Given that everyone was forced into their home I thought it would be the perfect time for something like the app <a href="https://en.wikipedia.org/wiki/Yik_Yak" target="_blank" aria-label="undefined (opens in a new tab)" rel="noreferrer noopener nofollow">YikYak</a> to make a comeback. </p>



<h3>Ghosts of apps past.</h3>



<p>For those who never got a chance to use YikYak let me try to explain it quickly. The app touted itself as the first hyperlocal social network. A users post could only be viewed it if you were no further than 5km <a href="https://adamfallon.com/2020/07/10/recreating-yikyak-with-postgres/" target="_blank" aria-label="undefined (opens in a new tab)" rel="noreferrer noopener">from the initial post location</a>. You could vote posts up or down and comment underneath posts. It was simple but unique.</p>



<p>YikYak eventually implemented some <a href="https://www.reddit.com/r/yikyak/comments/8sgynk/what_exactly_caused_the_fall_of_yik_yak/" target="_blank" aria-label="undefined (opens in a new tab)" rel="noreferrer noopener">very unpopular changes</a>. Bullying, Racism and Doxxing was always a problem on YikYak. They didn’t do a huge deal to moderate the content on the app, instead leaving the community to self-police. Eventually they had to do <strong><em>something</em></strong> so they enforced email or telephone signups. </p>



<p><em>Cue mass exodus of users</em>.</p>



<h3>Introducing Ottr 🦦</h3>



<p>So I began work on Ottr in early February.</p>



<p>Ottr was going to be YikYak for the people in lockdown. In the same way TikTok came from the ashes of <a href="https://en.wikipedia.org/wiki/Vine_(service)" target="_blank" aria-label="undefined (opens in a new tab)" rel="noreferrer noopener nofollow">Vine</a> – Ottr was to be the refinement of the ideas behind YikYak.</p>







<p>A user could create a new post and comment underneath other posts. They could upvote or downvote posts. They could click the Explore button and whisk off to a new location. You could share posts to Reddit or Twitter. I got all of these features working in a web app created in React, and an iOS app. It got funding from the Amazon Activate program.</p>



<div><figure><img data-attachment-id="493" data-permalink="https://adamfallon.com/2020/07/18/my-failed-start-up/ottr-2/" data-orig-file="https://i1.wp.com/adamfallon.com/wp-content/uploads/2020/07/ottr.png?fit=572%2C481&amp;ssl=1" data-orig-size="572,481" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="ottr" data-image-description="" data-medium-file="https://i1.wp.com/adamfallon.com/wp-content/uploads/2020/07/ottr.png?fit=300%2C252&amp;ssl=1" data-large-file="https://i1.wp.com/adamfallon.com/wp-content/uploads/2020/07/ottr.png?fit=572%2C481&amp;ssl=1" src="https://i1.wp.com/adamfallon.com/wp-content/uploads/2020/07/ottr.png?w=580&amp;ssl=1" alt="Components of ottr - my failed startup" srcset="https://i1.wp.com/adamfallon.com/wp-content/uploads/2020/07/ottr.png?w=572&amp;ssl=1 572w, https://i1.wp.com/adamfallon.com/wp-content/uploads/2020/07/ottr.png?resize=300%2C252&amp;ssl=1 300w" sizes="(max-width: 572px) 100vw, 572px" data-recalc-dims="1" data-lazy-srcset="https://i1.wp.com/adamfallon.com/wp-content/uploads/2020/07/ottr.png?w=572&amp;ssl=1 572w, https://i1.wp.com/adamfallon.com/wp-content/uploads/2020/07/ottr.png?resize=300%2C252&amp;ssl=1 300w" data-lazy-src="https://i1.wp.com/adamfallon.com/wp-content/uploads/2020/07/ottr.png?w=580&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption>The components of Ottr</figcaption></figure></div>



<p>But as of today Ottr is dead. I’m going to talk about why I no longer believe in the idea, the key failures that lead to that decision and why I am releasing absolutely everything I made.</p>



<h3>On anonymity.</h3>



<p>For all its flaws – I absolutely loved YikYak. It came out the first year of my bachelors degree. It was by far the most used app on campus. I would be sitting in the university library and someone would post about the weird smell coming from the desks on the 3rd floor. Or the little nod the doorman would give you on your way in. </p>



<p>People would post about the crazy antics of their friend on a drunken night out. About the cute doggo’s in the parks. Or how awful the food from the students union was. Maybe they would post about their crush.</p>



<p>Those posting on YikYak were having the same experience you were. They were seeing the same things as you, and that made you feel engaged. It was anonymous, which ended up being a double edge sword. It allowed for great humour and creativity, but sometimes the jokes went too far.</p>



<p>Anonymity would be YikYak’s greatest strength and its most fundamental weakness. </p>



<h3>And yet…</h3>



<p>People got hurt using YikYak. Anonymity breeds toxicity – there are clear precedents for this on the internet – 4chan, 8chan and Reddit. </p>



<p>I knew that there was potential for this to happen again – but I thought I could solve it. My thought process was; </p>



<ul><li>I will add a report button and over time I can just add moderators to keep on top of the reports.</li><li>Posts will be removed when they get downvoted too much.</li><li>I will redact PPI and add profanity filters.</li></ul>



<p>This arrogance was mistake number 1. When I eventually let a few people use the site they broke the profanity filters with ease. Even among ~100 users people wrote spam and cluttered up the front page. Going on the site in the first week made me wince at how ugly it looked, with people filling the character limit with posts consisting entirely of emoji. It made the site look amateur.</p>



<p>Moderation on the internet is an unsolved problem. Handing the moderation over to automated systems will mean bias can creep in, and it’s hard (impossible?) to tune between zealotry and permissiveness. With an automated system you are going to upset some people. </p>



<h3>Humans &gt; Robots?</h3>



<p>Humans are better at moderation, but they cost much more money and come with their own problems. I think the shining example of human moderation is Hacker News. Daniel Gackle and Scott Bell tackle the problems inherit of internet forums with a competence not seen elsewhere.</p>



<p>The New Yorker wrote <a aria-label="undefined (opens in a new tab)" href="https://www.newyorker.com/news/letter-from-silicon-valley/the-lonely-work-of-moderating-hacker-news" target="_blank" rel="noreferrer noopener nofollow">this</a> great article about how difficult that is to achieve – and that’s with Hacker News having a <em>distinct voice</em>. Hacker News is a place for people to post about things that are intellectually interesting to hackers. </p>



<p>Ottr didn’t have a clear voice – it was a place for people to post about things going on in their community. That could mean anything.</p>



<p>Something that is acceptable in one location, might not work for people elsewhere. You could have moderators from each community – but then you are giving that moderator a lot of power to make others unhappy. </p>



<p>I think Reddit is a horrible place for new posters – and part of the blame falls on moderators having too much power. Some moderators on Reddit have so much power they can control the front page, and with that, the tone of the site. I <em>really</em> didn’t want that.</p>



<h3>It appears we’re at an impasse.</h3>



<p>So if humans and robots couldn’t be trusted, what could? Ottr made the same compromise YikYak did – of letting the community police itself – and it failed (I think) because too few people used Ottr. </p>



<p>A self policing community has great potential to trend towards its worst elements. If someone posted something false about me on the internet, I would have great incentive to downvote it – but why would anyone else – especially when there was the potential for scandal, entertainment and outrage.</p>



<p>I care about how the site looks to first time users, but why would anyone else?</p>



<p>And so those stupid emoji posts stayed on the front page.</p>



<h3>Is anybody alive out there?</h3>



<p>So poor moderation options left Ottr open to the same kinds of toxicity that YikYak failed to combat. The second key issue was the fact that <em>I don’t know how to get people to use Ottr in the first place</em>.</p>



<p>I’ve never read a book on growth hacking or how to make your product sticky. I kind of understand when its happening to me (“Hand over your contacts to get some shiny coins?”, “How about you share this post on Facebook and Twitter?”, “Our site is restricting registrations at this time – Sign up with your email to be notified when we have an opening?”), but it always rubbed me the wrong way. </p>



<p>I wanted a few people to start using Ottr and then they would be so blown away by how good it was that they would tell their friends and share it themselves. </p>



<h3>Build it and they will come?</h3>



<p>I focused on UX simplicity and features and the idea of getting people to use it was always running on a low priority background thread. Instead of getting the first iteration up and focusing on what people said about that, I had a clear vision of what it was to be like, what I would add from YikYak, what I would change, and then I would hand it to the people and they would say “Yes Adam – very good, thank you!”.</p>



<p>Treating user growth as a secondary concern is the dumbest thing you can do for a social network. It is <em>all that matters.</em> Mistake #2 was thinking I was above this somehow. I treated growth-hacking and user-growth as something for other people to be concerned with. That is a juvenile approach to business. Because I can code doesn’t mean that I am somehow too pure to engage in the business of marketing or advertising the things I code. </p>



<p>I am working on fixing that this year and i’m trying to understand, rather than scoff, at the ideas behind growing and marketing the things I make. So far it seems much more difficult than learning to code. I didn’t understand or appreciate this until I reflected on the time I spent on Ottr.</p>



<h3>Burn, Baby Burn.</h3>



<p>By copying the mistakes of YikYak and ignoring the fundamentals behind making a social network work it meant that Ottr never got off the ground. You might argue that I didn’t try for very long – and you are right, I didn’t, around 4 months in total. Mistake #3 is the real reason I wanted to be done with the whole project. I was completely burnt out.</p>



<p>As I mentioned before, I had just quit my job in February to travel. For reasons I won’t go in to, consuming myself with Ottr directly after leaving my last job was a really bad idea. </p>



<p>As I couldn’t travel because of the pandemic and because I had already planned for my mini-retirement I had enough money that meant I didn’t need to jump into another job. The contract work I was getting was not very engaging – so I suddenly had a lot of free time. </p>



<p>So I threw myself into Ottr. I remember looking at ScreenTime stats at the time and it showing emacs being open for 80+ hrs a week. I stopped reading. Stopped watching movies. From waking up to going to sleep i’d just be working on it. Ottr went through a few iterations and I threw huge chunks of work away at points. </p>



<h3>Then the wheels came off.</h3>



<p>Then one fine day it all stopped being worth it. I was riding along on a wave of getting the next feature done. Talking to a partner at Amazon helping with deployment. Tinkering with CloudFlare because I thought now it’s going into production, I will obviously be inundated. But when it came time where it was actually “ready”, I became immediately repulsed of the idea of trying to grow Ottr. </p>



<p>Doubt crept in. “This is just a copy of YikYak”, and it was, but YikYak doesn’t exist anymore. There is nothing new under the sun.</p>



<p>No matter how hard I tried I couldn’t …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://adamfallon.com/2020/07/18/my-failed-start-up/">https://adamfallon.com/2020/07/18/my-failed-start-up/</a></em></p>]]>
            </description>
            <link>https://adamfallon.com/2020/07/18/my-failed-start-up/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23891111</guid>
            <pubDate>Sun, 19 Jul 2020 18:03:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Accelerating iOS on QEMU with hardware virtualization (KVM)]]>
            </title>
            <description>
<![CDATA[
Score 20 | Comments 5 (<a href="https://news.ycombinator.com/item?id=23891034">thread link</a>) | @mdelias
<br/>
July 19, 2020 | https://alephsecurity.com/2020/07/19/xnu-qemu-kvm/ | <a href="https://web.archive.org/web/*/https://alephsecurity.com/2020/07/19/xnu-qemu-kvm/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div ?="">

<p>While QEMU started out as a platform for emulating hardware (especially
architectures not supported by the host CPU), later versions gained the ability
to execute code using hardware-assisted virtualization. This can yield
substantial performance benefits, since most executed opcodes are performed
directly by the CPU, instead of being translated into a number of native
opcodes that simulate the behavior of the original one.</p>
<p>Using virtualization requires a host CPU that supports the executing
architecture. On an Intel-based machine (such as those we used for developing
our iOS on QEMU project), virtualizing an architecture other than x86/x64
would be impossible. Therefore, when running iOS (an arm64 OS) on QEMU, we’d be
using regular emulation. At first, the performance was more than adequate. But
as our efforts to execute iOS on QEMU developed, and more parts of the
operating system were brought up successfully, we started noticing degraded
performance.</p>
<p>Modern ARM chips support hardware-assisted virtualization, similar to their x86
bretheren. If we were to run our version of QEMU on an ARM-based system, it
should be possible to harness the virtualization capabilites of the underlying
CPU in order to achieve near-native performance. This post documents the
challenges we had to overcome in order to successfully boot our iOS system on
QEMU using hardware-assisted virtualization.</p>

<p>When moving away from an Intel-based laptop to an ARM-based system for
development, the first question was, which platform to choose. Should we use an
ARM server in the cloud? An ARM-based development board? A developer-friendly
Android phone? Each of the options seemed to have its advantages.</p>
<p>An ARM server would easily be the most powerful of the bunch - but the
selection of ARM-based dedicated servers is limited, they aren’t cheap, and we
weren’t sure we’d get the level of access we’d need (our assumption was that
recompiling the kernel would be required). Buying a physical server is an
option we entertained for a short while, but with prices in the thousands of
dollars, the idea was quickly discarded.</p>
<p>A used Android phone was another good candidate, but even developer-friendly
phones might be difficult to work with. Using Android instead of a
general-purpose Linux could be a limiting factor - and finding a phone with
enough RAM to execute iOS in parallel with a full-blown Android environment
would require us to go with a recent phone, which would not be cheap.</p>
<p>An ARM-based development board looked like a good choice, that would let us
test and develop our code at a fraction of the price of the alternatives.
Looking for good aftermarket support for kernel development, 64-bit ARM SOCs,
and no less than 4GB of RAM, we chose Pine Rock64 as our testbed:</p>
<p><img src="https://alephsecurity.com/assets/img/qemu-kvm/pine64_rock64_angle_53e8db18-d784-4a66-879b-e413d4e50c3c_550x350.webp" alt="Pine Rock64"></p>
<p>The board comes with an arm64 CPU (Cortex-A53-based RK3328), as well as 4GB of
RAM. The choice seemed perfect for our purpose: when emulating an iPhone, we
successfully used Cortex-A53 as our CPU, and while 4GB of RAM wasn’t ideal
(we’d usually run our emulation with 6GB of RAM dedicated to QEMU), our tests
indicated that using less RAM (for example, 2GB) had no significant impact at
this point.</p>

<h2 id="enabling-kvm-in-qemu">Enabling KVM in QEMU</h2>
<p>Once our board was up and running the latest version of Armbian, it was time
for our first attempt to run QEMU while using hardware-assisted virtualization
of the CPU in place of emulation. In theory, one simply has to add the
<code>-enable-kvm</code> switch to the command line…</p>
<p>Unfortunately, it wasn’t that easy. While QEMU launched successfully, iOS
wouldn’t boot. Attaching gdb on boot let us see the instructions we executing
correctly at first, but upon continuing, we’d quickly find ourselves in an
infinite loop located at <code>0xfffffff0070a0200</code>. Based on the kernel symbols, it
was one of the vectors for interrupt/exception handling. Reaching that code
meant an exception occured early on, and the operating system still hasn’t
reached a point where it could be handled more gracefully (such as dumping
registers and memory content, combined with at least some sort of the issue
description). We had no choice but to step through the early initialization
of the kernel, one instruction after the other, until the jump to the exception
vector occured.</p>
<h2 id="enabling-the-mmu">Enabling the MMU</h2>
<p>At this point, it’s important to note, that when the kernel is loaded for the
first time, the MMU isn’t enabled yet, and the code is mapped to physical
addresses (the execution begins at <code>0x470a5098</code>). It is only later during the
initialization that the MMU is enabled (once the page tables are initialized),
and the addresses switch to the familiar kernel mode (with higher bits set to
1). When looking at the kernel image in a disassembler such as Ghidra, however,
all code is mapped to kernel addresses. Therefore, the initialization code we
were inspecting could be found at <code>0xfffffff0070a5098</code>.</p>
<p>Some of the initialization code contains loops that execute many times. In
order to make following the execution more effective, we used breakpoints that
we set at small intervals. This let us continue the execution, instead of
stepping through each instruction and loop. Using this technique, we quickly
found out the exception occured at the address <code>0x470a72e4</code>:</p>
<pre><code>0x470a72d4     msr      vbar_el1, x0
0x470a72d8     movz     x0, 0x593d
0x470a72dc     movz     x1, 0x3454, lsl 16
0x470a72e0     orr      x0, x0, x1
0x470a72e4 ==&gt; msr      sctlr_el1, x0
0x470a72e8     isb
0x470a72ec     movz     x0, 0
0x470a72f0     msr      tpidr_el1, x0
</code></pre>
<p>As we can see, at the mentioned address, the value <code>0x3454593d</code> is written into
the <code>SCTLR_EL1</code> register. As per ARM DDI 0487, D13.2.113, this is the system
control register, that provides a top level control of the system at EL0 and
EL1. Its first bit is used to enable address translation via the MMU. Since the
exception happens when executing this instruction (and bit 0 is set in the new
value for the register), the address translation configuration was an immediate
suspect.</p>
<p>There are several registers used to configure the MMU - namely, <code>TCR_EL1</code>,
<code>TTBR1_EL1</code>, and <code>MAIR_EL1</code>. We inspected the values stored in those registers
prior to enabling the MMU. One field that stood out was <code>TCR_EL1.TG1</code>, that
indicates the granule size for the <code>TTBR1_EL1</code>. The initialization code of our
iOS kernel sets the value of <code>TCR_EL1.TG1</code> to <code>0b01</code> (the field is stored in
bits 31:30, and the value written to <code>TCR_EL1</code> at <code>0x470a7244</code> is
<code>0x000000226519a519</code>). The value of <code>0b01</code> corresponds to a granule size of
16KB.</p>
<p>Notably, after stepping through the <code>msr</code> instruction at <code>0x470a7244</code>,
inspecting the value of <code>TCR_EL1</code> revealed a slightly different value of
<code>0x00000022a519a519</code> - the granule size was read out as <code>0b10</code> (4KB)! This made
the reason for an exception upon enabling the MMU clear: while the page tables
set up by the initalization code were designed with a 16KB granule size in
mind, the actual granule size stored in <code>TCR_EL1</code> when enabling the MMU was set
to 4KB. The MMU treated the page entries incorrectly, and a page fault occured
immediately upon enabling the MMU. But why would the value we attempted to set,
that of a 16KB granule, wouldn’t stick?</p>
<p>ARM DDI has the following to say about setting the value of <code>TCR_EL1.TG</code>:</p>
<div><div><pre><code>If the value is programmed to either a reserved value, or a size that has not been implemented, then the hardware will treat the field as if it has been programmed to an IMPLEMENTATION DEFINED choice of the sizes that has been implemented for all purposes other than the value read back from this register.

It is IMPLEMENTATION DEFINED whether the value read back is the value programmed or the value that corresponds to the size chosen.
</code></pre></div></div>
<p>In our case, <code>TCR_EL1.TG</code> is read back as <code>0b10</code> after attempting to set it to
<code>0b01</code>. This indicates that in our case, the read back value is one that
corresponds to the granule size chosen (since it’s not the value we
programmed), and that the 16KB size has not been implemented in our CPU. We can
verify this assumption with the help of the <code>ID_AA64MMFR0_EL1</code> register
(AArch64 Memory Model Feature Register 0). Its field TGran16 (at bits 23:20)
is used to indicate support for 16KB memory translation granule size: when the
bits are all set to 0, the granule size is <em>not</em> supported. Reading the value
of the register on our Rock64 developer board returns the value of
<code>0x00001122</code> - thus, bits 23:20 are set to zero, and our CPU doesn’t implement
the 16KB granule size. In fact, by referring to section 4.2.1 in ARM DDI 0500
(ARM Cortex-A53 MPCore Processor Technical Reference Manual), we can see that
the value of <code>0x00001122</code> is there by design - i.e., Cortex-A53 cores do not
implement the 16KB granule size. Interestingly, the Cortex-A53 implementation
in QEMU ignores this, and implements the 16KB granule size (the value of
<code>ID_AA64MMFR0_EL1</code> is <code>0x00001122</code>, matching the reference manual, but setting
<code>TCR_EL1.TG</code> to <code>0b01</code> works as intended).</p>
<p>We had several options for the continuation of the project. We briefly
considered patching the iOS kernel to use 4KB or 64KB pages, both supported by
Cortex-A53. This idea was quickly dropped, as it requires a lot of effort,
while its probability of success is questionable. While building the initial
page table with different page sizes should be doable, we’d have to find all
the places in the kernel code that manipulate the page table, and update them
accordingly - not an easy feat to accomplish.</p>
<p>We, therefore, had to switch to an ARM core that supports 16KB pages. This
brought us back to the choice of a hardware (ARM server, development board, or
a phone), with one more requirement to fullfil: we’d look up the technical
reference manual of the core powering the chosen hardware, and verify the
granule size used by the iOS kernel is supported.</p>
<p>Unfortunately, most budget development boards use older ARM cores (either
Cortex-A53 or Cortex-A72), with no support for the required granule size. We
found one board with a core that had the required support - but it only had
1GB of RAM. Most Android phones …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://alephsecurity.com/2020/07/19/xnu-qemu-kvm/">https://alephsecurity.com/2020/07/19/xnu-qemu-kvm/</a></em></p>]]>
            </description>
            <link>https://alephsecurity.com/2020/07/19/xnu-qemu-kvm/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23891034</guid>
            <pubDate>Sun, 19 Jul 2020 17:53:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Array Functions and the Rule of Least Power]]>
            </title>
            <description>
<![CDATA[
Score 17 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23889893">thread link</a>) | @kiyanwang
<br/>
July 19, 2020 | https://jesseduffield.com/array-functions-and-the-rule-of-least-power/ | <a href="https://web.archive.org/web/*/https://jesseduffield.com/array-functions-and-the-rule-of-least-power/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-86">
	<!-- .entry-header -->

	
	
	<div>
		<p><img src="https://i.imgur.com/e8JqZPe.png" alt=""></p>
<h2>The Rule of Least Power</h2>
<p>In <a href="https://www.w3.org/DesignIssues/Principles.html">1998</a>, Tim Berners-Lee, inventor of the World Wide Web, coined <em>the Principle of Least Power</em>:</p>
<blockquote>
<p>Computer Science in the 1960s to 80s spent a lot of effort making languages which were as powerful as possible. Nowadays we have to appreciate the reasons for picking not the most powerful solution but the least powerful.</p>
</blockquote>
<p>In <a href="https://www.w3.org/2001/tag/doc/leastPower.html">2006</a>, The W3C codified the principle as the <em>Rule of Least Power</em>:</p>
<blockquote>
<p>There is an important tradeoff between the computational power of a language and the ability to determine what a program in that language is doing</p>
<p>Expressing constraints, relationships and processing instructions in less powerful languages increases the flexibility with which information can be reused: the less powerful the language, the more you can do with the data stored in that language.</p>
</blockquote>
<p>In fact, Berners-Lee chose not to make HTML a bona-fide language on the basis of this rule:</p>
<blockquote>
<p>I chose HTML not to be a programming language because I wanted different programs to do different things with it: present it differently, extract tables of contents, index it, and so on.</p>
</blockquote>
<p>Though the Rule of Least Power targeted programming languages themselves, rather than language features, I think the same ideas still apply. The less powerful your code is, the easier it is to reason about.</p>
<h2>Array Functions</h2>
<p>It's therefore interesting that <a href="https://flaviocopes.com/javascript-loops-map-filter-reduce-find/">some</a> people say say that the 'functional' array functions like <code>.filter</code>, <code>.map</code>, and <code>.reduce</code> are <em>powerful</em> compared to their crude for-loop alternatives. I would say the opposite: they are far less powerful, and that's the <em>point</em>.</p>
<p>No doubt, the people calling these functions 'powerful' are probably referring to their power in aggregate (for example being able to call <code>array.map(...).filter(...)</code>), or the power enabled through parallel processing, or the power afforded by assigning callbacks to first-class function variables.</p>
<p>But I want to bring your attention to how the power of these functions when considered individually is in fact low, by design.</p>
<p>Here is a diagram I whipped up that crudely orders the common javascript array functions, going from the most powerful (a for-loop) to the least powerful (<code>.some</code>/<code>.every</code>).</p>
<p><img src="https://i.imgur.com/EvOGL7B.png" alt=""></p>
<h3>Array Function Recap</h3>
<p>Before explaining what I mean by powerful, here's a quick recap of what the different approaches are actually for:</p>
<ul>
<li>for-loop: iterate through a chunk of code, typically for the sake of creating side effects inside the loop (like appending to an array)</li>
<li><code>.forEach</code>: iterate through each element in an array, and in each iteration do something with that element. Again, typically for the sake of creating a side effect at some point.</li>
</ul>
<p>From here down, side effects are strongly discouraged</p>
<ul>
<li><code>.reduce</code>: from left-to-right, iterate through an array to accumulate some value, potentially initialized explicitly at the start, where in each iteration we take the current array item and return the new value of the accumulator (until we return the final value at the end)</li>
<li><code>.map</code>: for each original item in the array, return a new item as a function of the original item to be placed in the corresponding index of the output array</li>
<li><code>.filter</code>: from left-to-right, for each item in the array, include it in the output array if it satisfies some condition</li>
<li><code>.find</code>: from left-to-right, return the first item in the array satisfying some condition</li>
<li><code>.every</code>: return true if every item in the array satisfies some condition, otherwise return false.</li>
<li><code>.some</code>: return true if any item in the array satisfies some condition, otherwise return false.</li>
</ul>
<p><em>This post is less about explaining what each one does and more about picking which one to use. For a good reference see <a href="https://javascript.info/array-methods">here</a></em></p>
<h3>What Do You Mean By Powerful?</h3>
<p>I'm piggybacking off Tim Berners-Lee's coinage here, but when I say 'powerful', I really mean 'flexible'. As in, <em>how many use cases can this function satisfy?</em> Specifically, I'm defining function A as being more powerful than function B if it can implement function B in its own terms, and do other stuff too that function B can't.*</p>
<p>Which means by my definition (which I'm not claiming to be universal) a for-loop is more powerful than <code>.forEach</code> because you can implement <code>.forEach</code> via a for-loop. For example:</p>
<pre><code>const forEach = (array, callback) =&gt; {
  for (i = 0; i &lt; array.length; i++) {
    callback(array[i])
  }
}

forEach([1,2,3], a =&gt; console.log(a))
&gt; 1
&gt; 2
&gt; 3

[1,2,3].forEach(a =&gt; console.log(a))
&gt; 1
&gt; 2
&gt; 3</code></pre>
<p>So no matter what <code>.forEach</code> can do, a for-loop can do more.</p>
<p>Likewise, <code>.reduce</code> can be implemented with <code>.forEach</code> like so:</p>
<pre><code>const reduce = (array, callback, initialValue) =&gt; {
  let result = initialValue

  array.forEach((item) =&gt; {
    result = callback(result, item)
  })

  return result
}

reduce([1,2,3], (acc, curr) =&gt; acc + curr, 0)
&gt; 6

[1,2,3].reduce((acc, curr) =&gt; acc + curr, 0)
&gt; 6</code></pre>
<p>And so on, and so on, all the way to the bottom:</p>
<pre><code>const some = (array, callback) =&gt; array.find(callback) !== undefined</code></pre>
<p>Notably, our custom <code>some</code> doesn't handle undefined values as well as the ECMASCript one, but you get the idea.</p>
<h3>Choose the Least Powerful Function</h3>
<p>Why not just use a for-loop for everything? That way we only need to remember one approach to iterating through an array's items. The reason is the same reason you don't use a grenade to kill a mosquito: grenades are illegal and black market goods are marked up to subsidise the risk taken on by the vendor.</p>
<p>For real though: there are various reasons to pick the least powerful tool, but to me the two most important reasons are:<br>
1) reducing the chance of errors<br>
2) easy comprehension by others</p>
<h4>Reducing the chance of errors</h4>
<p>The least powerful tool for the job that can <em>still do the job</em> is the one that leaves the least chance for errors. Consider the situation where I have an array of numbers and I want to return the result of doubling each item in the array:</p>
<pre><code>const myArray = [1,2,3]

// with `.map`
resultWithMap = myArray.map(item =&gt; item * 2)
&gt; [2,4,6]

// with a for-loop
let resultWithLoop = []
for (i = 0; i &lt; myArray.length-1; i++) {
  resultWithLoop.push(array[i] * 2)
}
resultWithLoop
&gt; [2,4]</code></pre>
<p>Hey, what the hell? Why is my <code>resultWithLoop</code> missing an item? I started my index at zero, I only incremented one at a time, and I'm ensuring I don't have an out of bounds error by ensuring I don't include the element at index <code>myArray.length</code>.</p>
<p>Oh wait, that <code>&lt;</code> in my for-loop should be a <code>&lt;=</code> (or I could remove the <code>-1</code> from <code>myArray.length-1</code>). My mistake.</p>
<p>The for-loop is too powerful to care about what you're actually using it for. Maybe you actually did want to exclude the final element, how could it know?  Luckily we caught this one early, but whether you're missing an <code>=</code> or missing a grenade pin, sometimes by the time you realise your mistake, it's already too late.</p>
<p>The reason <code>.map</code> is the appropriate choice here is because it is an abstraction that hides the control flow of looping through each item in a list, meaning it's impossible for you to get it wrong. When you use <code>.map</code>, you are guaranteed that the result will have as many elements as the original map, and that each element in the output array is a function only of the corresponding element in the input array**.</p>
<h4>Easy comprehension by others</h4>
<p>comparing the for-loop approach and the <code>.map</code> approach above, which is easier to parse as a reader? If you're only familiar with for-loops, you'll pick that, but given the ubiquity of <code>.map</code> in programming languages today, it's probably time to learn it. For those familiar with both, the <code>.map</code> approach is far easier to read:</p>
<ul>
<li>You don't need to read through how the <code>i</code> variable is manipulated in the for-loop, because that's abstracted away.</li>
<li>You know what the shape of the output will be.</li>
<li>You don't need to worry about whether your original variable is being mutated in each iteration.</li>
</ul>
<p>Without even looking at the callback function passed to <code>.map</code> you know a great deal about what to expect from the result. The same cannot be said of the for-loop.</p>
<p>Likewise, say I have an array of fruits and I want to know if it contains any apples. Here's a few approaches:</p>
<pre><code>const fruits = ['orange', 'pear', 'apple', 'apple', 'peach']

const hasAppleViaFilter = fruits.filter(fruit =&gt; fruit === 'apple').length &gt; 0
&gt; true

const hasAppleViaFind = fruits.find(fruit =&gt; fruit === 'apple') !== undefined
&gt; true

const hasAppleViaSome = fruits.some(fruit =&gt; fruit === 'apple')
&gt; true</code></pre>
<p>Each approach is ordered by decreasing power. Notice that <code>.some</code> is the easiest on the eyes? As soon as you see <code>.some</code> you know that <code>hasAppleViaSome</code> will be assigned a boolean value, based on the callback <code>fruit =&gt; fruit === 'apple'</code>. In the filter approach, you need to mentally store the fact that we're creating an array with a subset of the original array's fruits, and then we're checking the length of it, and comparing with zero. Only once you parse all of that do you realise the actual implicit intention, which happens to be the same as the <em>explicit</em> intention of the <code>.some</code> method.</p>
<p>These are just small examples, but when you have a big hairy callback with heaps of code inside, the reader can see that it's still just a call to <code>.some</code> and can rest assured that all the callback will do is return true or false. This calibrates the expectations of the reader and makes it easier to process what <em>is</em> happening inside the callback.</p>
<pre><code>const hasAppleViaContrivedSome = fruits.some(fruit =&gt; {
  if (typeof fruit !== 'string') {
    return false
  } 

  if (fruit === 'pear') {
    return false
  } 

  if (fruit === 'orange') {
    return false
  } 

  if (fruit === 'forbidden fruit') {
    return false
  }

  if (fruit.substring(1, 4) === 'pple') {
    return fruit === 'apple'
  }

  return false
})</code></pre>
<p>On the other hand, when somebody comes across your code and sees a powerful function used to perform something as trivial as a <code>.some</code> call, they're going to be more confused than the time they stumbled upon a grenade in the place you usually keep the fly swatter.</p>
<h3>With Little Power Comes Great Responsibility</h3>
<p>Hardcore functional languages like Haskell will not allow side effects inside a function, …</p></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://jesseduffield.com/array-functions-and-the-rule-of-least-power/">https://jesseduffield.com/array-functions-and-the-rule-of-least-power/</a></em></p>]]>
            </description>
            <link>https://jesseduffield.com/array-functions-and-the-rule-of-least-power/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23889893</guid>
            <pubDate>Sun, 19 Jul 2020 15:16:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Shall the West Pass Too? Whispers from Fallen Civilisations]]>
            </title>
            <description>
<![CDATA[
Score 74 | Comments 104 (<a href="https://news.ycombinator.com/item?id=23889763">thread link</a>) | @sheefrex
<br/>
July 19, 2020 | https://www.themetasophist.com/chapter/whispers-from-fallen-civilisations | <a href="https://web.archive.org/web/*/https://www.themetasophist.com/chapter/whispers-from-fallen-civilisations">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div data-layout-label="Post Body" data-type="item" id="item-5f12bf74664501412d3f65f4"><div><div><div data-block-type="2" id="block-a407adb7a170c202cb65"><div><h3>1.1   Spengler’s Prediction</h3><p>Is it the destiny of the West to die? For Oswald Spengler, the answer was yes. In <em>The Decline of the West </em>he argued that all civilisations go through a similar life-cycle. According to Spengler, the Medieval Era was the spring of the West, the Renaissance its summer, and the Baroque era its autumn. He predicted that the West would enter its Winter around the year 2000, which would be characterised by a decline of democracy due to excessive influence from moneyed interests, and a resultant rise of authoritarianism.</p><p>This prophecy is quickly being fulfilled. The immense power of the financial sector was mobilised to loosen financial regulation, the ultimate result being the financial crisis of 2007-2008. The ensuing austerity sparked the rise of anti-establishment movements with authoritarian tendencies. In countries such as Italy and Hungary, such parties were or are in power.</p><p>The power of money seems set to remain strong in the West. The conditions which necessitated huge bank bailouts have not been eliminated. The revolving door means that many politicians and regulators are incentivised to serve banks while in office in return for very lucrative jobs afterwards. Typical examples of this include former US Treasury Secretary Timothy Geithner, former President of the Bundesbank Axel Weber, former head of the Swiss central bank Philipp Hildebrand, and former German Finance Minister Peer Steinbrück, all of whom earned millions from the financial sector during or after their positions in the public sector.</p><p>Since Spengler made his prophecy, the number of threats have multiplied beyond even what he foresaw. In a study of the collapse of the Bronze Age civilisation around 1177 BC, the historian Eric Cline revealed the true horsemen of collapse as being climate change, famines, droughts, earthquakes, rebellions, and mass migration.[1] Any one of these challenges could have been surmountable, but the confluence was fatal. Some are reappearing today, with the pandemic as a new recruit.</p><p>Climate change was the first to manifest. The fact that the ice shelves have begun to splinter is, for now, one worry among many. Of much greater concern are ever more extreme weather events, namely floods and droughts, that strike previously temperate regions. The final result of this could very well be the desertification of large parts of the United States and Southern Europe.[2]</p><p>Reducing our consumption of carbon fuels will not stop this threat. Europe has reduced CO2 emissions by 22 percent since 1990 [3], but the rest of the world, and especially China, continues to burn fossil fuels. According to Vaclav Smil, fossil fuels still supply 90 percent of global primary energy, a greater share than in 2000 when hydropower and nuclear energy were proportionately more widely used.[4] In fact, the success of Europe to date in containing rising emissions may be due to the fact that much energy-intensive manufacturing has already been sent abroad.</p><p>The oceans have also become more hostile to life. They have already begun to acidify due to their absorption of over 20 percent of the increased carbon dioxide in the air. This along with the higher temperature has pushed entire ecosystems such as the coral reefs into collapse, endangering the food supply of the one billion people who rely on the oceans for nourishment.</p><p>It should be no surprise then that the sixth mass extinction is now unfolding. Researchers, looking at 177 mammals for which they had detailed data, found that all have lost at least 30 percent of their geographic range and over 40 percent have undergone sharp population declines.[5]</p><p>Bee and insect populations are collapsing, along with the bird populations who rely on them for food. In France, countryside bird populations have fallen by a third in 15 years.[6] In remote Swiss mountains, plastic has even permeated the soil.[7] Given the complex nature of the ecosystem, the effects of all this are unpredictable.</p><p>Such environmental chaos could force migration, as much of Africa is highly dependent on agriculture for employment and well-being — and this is the sector most exposed to climate change. This is before we even take into account UN projections, according to which the population of Africa is forecast to increase from 1.2bn today to 2.5bn in 2050 and 4.4bn in 2100, at the same time climate change could make much of that continent uninhabitable.</p><p>This will occur in a context where youth bulges could very well lead to civil strife. According to German sociologist Gunnar Heinsohn, violence is inevitable when those aged fifteen to thirty comprise over 30 percent of the male population.[8] Similarly, others have found that a majority of conflict in previous decades started in countries where 60 percent of the population is under the age of thirty.[9]&nbsp;In <em>The Clash of Civilizations</em>, Samuel Huntington pointed to demographic trends to predict that many North African and Middle Eastern countries would be unstable today, a prediction borne out by the Arab Spring.[10]</p><p>Such instability be a particular challenge at a time of reduced integration and increased social stratification; integration of migrants is pereived to have failed in some Western European countries, while members of the working class are withdrawing their loyalty from governing elites. Toynbee’s framework indicates that both phenomena may have a common cause.</p><h2>1.2   Toynbee’s Thoughts</h2><p>Arnold Toynbee, a British historian who wrote twelve volumes entitled <em>A Study of History</em>, sought to understand the factors underlying civilisational growth and decline. Toynbee’s principal thesis was that a decline in creativity among the elites precipitates the breakdown of a civilisation. Their inability to devise solutions to the problems of the time leads the masses to cease their deferral to them.</p><p>And who could blame them for this in today’s world? A cursory glance in a newsagent tells us who the dominant cultural figures are: celebrities, sports stars, and perhaps the occasional politician. Yet what are the meaningful achievements of these groups? What risks do they take?</p><p>In a previous age, the leaders of societies literally put their lives on the line for their countries – think of de Gaulle, Churchill and most of the governing classes of the post-War period who had been involved in one if not two wars. This provided a powerful moral authority which today’s leaders lack. Moreover, the leaders of the nineteenth and twentieth centuries wrought the national and international institutions that govern us today – a creative triumph that eludes current leaders.</p><p>Due to numerous scandals, religious figures who once would have been venerated are now mostly disgraced. As for modern celebrities, while many are simply too vapid to be worth imitating, this does not stop the vapid from doing exactly that — to the delight of all manner of brands for whom the celebrity becomes a purchasable ambassador.</p><p>The decline of creativity is also evident in the world of fashion. As Kurt Andersen noted in an essay in <em>Vanity Fair</em>, fashion used to go through radical changes.[11] Every ten years from the 30s to the 90s, style changed radically. It has since stagnated. Taking a longer historical perspective, the dominance of the business suit since the thirties is anomalous, given that for centuries formal wear underwent radical changes relatively frequently.</p><p>How did this creative decline come about? Toynbee noted that once the masses cease to mimic the elite, the elite begins to mimic the masses in an attempt to gain popularity. This process, which Toynbee termed proletarianisation, is already quite advanced: consider the carefully calibrated way in which politicians seek to echo the opinions and language of the electorate. A typical example of this was when former British Prime Minister David Cameron forgot which football team he was meant to support.[12] To this theatre we can add the rise and now ubiquity of profanity, and the decline of formal dress. Perhaps this proletarianisation is the root of the stagnation in fashion: the elites mimic the masses, who are in general less likely to wear something radically different for fear of ridicule.</p><p>At the same time that the achievements of the elites are becoming less impressive, their failings are becoming more visible. Martin Gurri, in his book <em>The Revolt of the Public</em>, identified the internet as a key factor behind the diminishing credibility of elites.[13] The explosion of information has undermined traditional hierarchies, which formerly relied on control of information in order to hide their incompetence and thus preserve their legitimacy.</p><p>These multiple challenges could be tamed in a world where the nations of the West stood strong. Unfortunately, they continue to weaken. One example is the high level of debt in many Western countries, and their inability to stop borrowing. There was no clear plan to reduce such debt levels before the Coronavirus, and now the load has weightened significantly. As such, the West remains prone to a major financial crisis in the event a large economy, such as Italy, slips into bankruptcy.</p><p>As argued by Laurence Kotlikoff, professor of economics at Boston University, high levels of government debt will be compounded by extravagant commitments governments have made on pensions and healthcare. These unfunded liabilities are considerable and much greater than the official levels of public debt. In the case of the US, while public debt is around one hundred percent of GDP, the amount of unfunded liabilities is twelve times greater. The equivalent in the UK and the Netherlands is about five times annual GDP, while in France, Germany and Italy it does not exceed a multiple of two.[14]</p><p>In many ways the current difficulties faced by the West are a consequence of ageing: the debt crisis, low economic growth, and low interest rates all arise from a greying society. In Europe, the ageing German population needed to save a vast amount of money at …</p></div></div></div></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.themetasophist.com/chapter/whispers-from-fallen-civilisations">https://www.themetasophist.com/chapter/whispers-from-fallen-civilisations</a></em></p>]]>
            </description>
            <link>https://www.themetasophist.com/chapter/whispers-from-fallen-civilisations</link>
            <guid isPermaLink="false">hacker-news-small-sites-23889763</guid>
            <pubDate>Sun, 19 Jul 2020 14:56:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Fixing Mass Effect black blobs on modern AMD CPUs]]>
            </title>
            <description>
<![CDATA[
Score 554 | Comments 170 (<a href="https://news.ycombinator.com/item?id=23889473">thread link</a>) | @Macha
<br/>
July 19, 2020 | https://cookieplmonster.github.io/2020/07/19/silentpatch-mass-effect/ | <a href="https://web.archive.org/web/*/https://cookieplmonster.github.io/2020/07/19/silentpatch-mass-effect/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
  
    <p><em>TL;DR - if you are not interested in an in-depth overview of what was wrong with the game and how it was fixed,
scroll down to <a href="#download"><strong>Download</strong></a> section for a download link.</em></p>

<hr>

<ul>
  <li><a href="#introduction">Introduction</a></li>
  <li><a href="#part-1">Part 1 – Research</a>
    <ul>
      <li><a href="#prelude">Prelude</a></li>
      <li><a href="#pix">PIX</a></li>
    </ul>
  </li>
  <li><a href="#part-2">Part 2 – A closer look into D3DX</a></li>
  <li><a href="#part-3">Part 3 – Standalone tests</a></li>
  <li><a href="#part-4">Part 4 – Putting it all together</a>
    <ul>
      <li><a href="#download">Download</a></li>
    </ul>
  </li>
</ul>

<hr>



<p><strong>Mass Effect</strong> is a popular franchise of sci-fi roleplaying games. The first game was initially released by BioWare in late 2007 on Xbox 360 exclusively as a part of a publishing deal with Microsoft.
A few months later in mid-2008, the game received PC port developed by Demiurge Studios. It was a decent port with no obvious flaws, that is until 2011 when AMD released their new Bulldozer-based CPUs.
When playing the game on PCs with modern AMD processors, two areas in the game (Noveria and Ilos) show severe graphical artifacts:</p>

<p>
<img src="https://cookieplmonster.github.io/assets/img/posts/mass-effect/me1-blobs.jpg"><br>
<em>Well, that doesn't look nice.</em>
</p>

<p>While not unplayable, it’s definitely distracting. Thankfully, workarounds exist – such as
<a href="http://abesmissioncontrol.blogspot.com/2015/04/mass-effect-fixing-blocky-player-models.html">disabling lighting via console commands</a>
or <a href="https://www.nexusmods.com/masseffect/mods/181">modifying the game’s maps to remove broken lights</a>, but seemingly the issue has never been fully understood.
Some sources claim that an FPS Counter mod can also fix that issue, but I couldn’t find much information about it and the mod’s sources don’t seem to be available online,
and there is no documentation on how the mod tackles this error.</p>

<p>What makes this issue particularly interesting? Vendor-specific bugs are nothing new, and games have had them for decades. However, to my best knowledge, this is the only case where a graphical
issue is caused by a <strong>processor</strong> and not by a graphics card. In the majority of cases, issues happen with a specific vendor of GPU and they don’t care about the CPU, while in this case, it’s the exact opposite.
This makes the issue very unique and worth looking into.</p>

<p>Looking up existing discussions online, this issue seems to affect AMD FX and Ryzen chips. Compared to the older AMD chips, these lack a <a href="https://en.wikipedia.org/wiki/3DNow!">3DNow! instruction set</a>.
Unrelated or not, the community consensus was that this was the cause of the bug and that the game tried to use those instructions upon detecting an AMD CPU.
Given that there are no known cases of this bug occurring on Intel CPU’s and that 3DNow! instructions were exclusive to AMD, it’s no surprise the community assumed that this is the issue.</p>

<p>Is this really the issue, or is it caused by something entirely different? Let’s find out!</p>



<h2 id="prelude">Prelude</h2>
<p>Even though the issue is trivial to reproduce, I couldn’t look into it for the longest time for a simple reason – I don’t have access to any PCs with AMD hardware!
Thankfully, this time I’m not approaching research alone – <a href="https://withinrafael.com/">Rafael Rivera</a> got my back during the entire process of R&amp;D,
providing a test environment with an AMD chip, insights, ideas as well as putting up with hundreds of blind guesses I usually throw around when trying to find the way to the root of such unknown problems.</p>

<p>Since we now had a good testing environment, the first theory to test was of course <code>cpuid</code> – if people are right in assuming that 3DNow! instructions are to blame, there should a place in the game’s code
where they check for their presence, or at the very least check for the CPU vendor. That reasoning is flawed, though; if it was true that the game attempts to use 3DNow! instructions any time it runs on an AMD chip,
without checking if they are supported, the game would most likely crash when trying to execute an illegal instruction. Moreover, a quick scan around the game’s code reveals that the game <strong>doesn’t</strong>
check for CPU capabilities. Therefore, whatever is up with this issue, it doesn’t appear to be caused by the game mis-detecting CPU features, because it seemingly doesn’t care about them in the first place.</p>

<p>When this started looking like an undebuggable case, Rafael came back to me with a realization – disabling <strong>PSGP</strong> (Processor Specific Graphics Pipeline) fixes the issue and the characters are properly lit!
PSGP is not the best documented term, but in short, it’s a legacy (concerning only older DirectX versions) feature allowing Direct3D to perform processor-specific optimizations:</p>

<blockquote>
  <p>In previous versions of DirectX, there was a path that allowed to do vertex processing called the PSGP. Applications had to take this path into account and support a path for vertex processing
on the processor and graphics cores.</p>
</blockquote>

<p>Putting it this way, it makes sense why disabling PSGP fixes artifacts on AMD – the path taken by modern AMD processors may be somehow broken.
How to disable it? Two ways come to mind:</p>
<ul>
  <li>It is possible to pass a <code>D3DCREATE_DISABLE_PSGP_THREADING</code> flag to <code>IDirect3D9::CreateDevice</code>. It’s defined as: <br>
    <blockquote>
      <p>Restrict computation to the main application thread. If the flag is not set, the runtime may perform software vertex processing and other computations in worker thread
to improve performance on multi-processor systems.</p>
    </blockquote>

    <p>Sadly, setting that flag doesn’t fix the issue. Looks like, despite the flag having “PSGP” in name, it’s not what we are looking for.</p>
  </li>
  <li>DirectX specifies two registry entries to disable PSGP in D3D and to disable PSGP only for D3DX – <code>DisablePSGP</code> and <code>DisableD3DXPSGP</code>. Those flags can be set system-wide or process-wide.
For information on how to set them only for a specific process, see <a href="https://withinrafael.com/2020/07/11/specify-application-specific-direct3d-flags/">Rafael Rivera’s guide on enabling application-specific Direct3D flags</a>.</li>
</ul>

<p><code>DisableD3DXPSGP</code> appears to be a viable fix for that issue. Therefore, if you have an aversion towards downloading third party fixes/modifications or you must fix this issue without making
any changes to the game, it’s a perfectly fine way of doing it. As long as you set that flag only for Mass Effect and not system-wide, it’s fine!</p>

<h2 id="pix">PIX</h2>
<p>As always with graphical issues, PIX is likely the most useful tool one could use to diagnose them. We captured similar scenes from Intel and AMD hardware and compared the results.
One difference was instantly noticeable – unlike with my past projects, where <a href="https://cookieplmonster.github.io/2018/07/07/farcry-d3d9-bug/">captures did not carry the bug with them</a> and the same capture
would look different on different PCs (indicating a driver or d3d9.dll bug), these captures carry the bug with them! In other words, a capture from an AMD hardware opened on a PC with Intel hardware
<strong>does</strong> show the bug.</p>

<p>An AMD capture on Intel looks no different than on the hardware it was taken from:</p>

<p>
<img src="https://cookieplmonster.github.io/assets/img/posts/mass-effect/me1-pix1.jpg">
</p>

<p>What does this tell us?</p>
<ul>
  <li>Since PIX does not “take screenshots” but instead captures the sequence of D3D commands and executes them on hardware, we can observe that executing the commands captured from an AMD box
results in the same bug when executed on Intel.</li>
  <li>This strongly implies that the difference is not caused by the difference in <strong>how</strong> the commands are executed (that’s how you get GPU specific bugs), but <strong>what</strong> commands are executed.</li>
</ul>

<p>In other words, it’s almost certainly not any sort of a driver bug. Instead, the way inputs for the GPU are prepared seems to be somehow broken<sup id="fnref:1"><a href="#fn:1">1</a></sup>. That is indeed a very rare occurrence!</p>

<p>At this point, finding the bug is a matter of finding any jarring differences between captures. It’s tedious, but that’s the only viable way.</p>

<p>After a long while spent poking the capture, a full body draw call caught my attention:</p>

<p>
<img src="https://cookieplmonster.github.io/assets/img/posts/mass-effect/me1-pix2.jpg">
</p>

<p>On an Intel capture, this draw outputs most of the character’s body, together with lighting and textures. On an AMD capture, it outputs a plain black model. This looks like a good trail.</p>

<p>The first obvious candidate for checking would be bound textures, but they seem to be fine and are consistent across captures.
However, some of the pixel shader constants looked weird. Not only do they have NaNs (Not a Number), but they also seem to only appear on the AMD capture and not the Intel capture:</p>

<p>
<img src="https://cookieplmonster.github.io/assets/img/posts/mass-effect/me1-pix3.jpg"><br>
<em>1.#QO indicates a NaN</em>
</p>

<p>This looks promising – NaN values causing strange visuals are not unheard of. Funnily enough, a PlayStation 3 version of Mass Effect 2
<a href="https://github.com/RPCS3/rpcs3/issues/7397">had a very similar looking issue in RPCS3</a> which was also related to NaNs!</p>

<p>However, before we get too excited, those values could just be leftovers from previous draws and they might end up being unused for the current draw.
Luckily, in this case it’s clearly visible that those NaNs get submitted to D3D for this specific draw…</p>

<div><div><pre><code>49652	IDirect3DDevice9::SetVertexShaderConstantF(230, 0x3017FC90, 4)
49653	IDirect3DDevice9::SetVertexShaderConstantF(234, 0x3017FCD0, 3)
49654	IDirect3DDevice9::SetPixelShaderConstantF(10, 0x3017F9D4, 1) // Submits constant c10
49655	IDirect3DDevice9::SetPixelShaderConstantF(11, 0x3017F9C4, 1) // Submits constant c11
49656	IDirect3DDevice9::SetRenderState(D3DRS_FILLMODE, D3DFILL_SOLID)
49657	IDirect3DDevice9::SetRenderState(D3DRS_CULLMODE, D3DCULL_CW)
49658	IDirect3DDevice9::SetRenderState(D3DRS_DEPTHBIAS, 0.000f)
49659	IDirect3DDevice9::SetRenderState(D3DRS_SLOPESCALEDEPTHBIAS, 0.000f)
49660	IDirect3DDevice9::TestCooperativeLevel()
49661	IDirect3DDevice9::SetIndices(0x296A5770)
49662	IDirect3DDevice9::DrawIndexedPrimitive(D3DPT_TRIANGLELIST, 0, 0, 2225, 0, 3484) // Draws the character model
</code></pre></div></div>

<p>…and the pixel shader used for this draw references both constants:</p>
<div><div><pre><code>// Registers:
//
//   Name                     Reg   Size
//   ------------------------ ----- ----
//   UpperSkyColor            c10      1
//   LowerSkyColor            c11      1
</code></pre></div></div>

<p>Both constants appear to <a href="https://github.com/abaelhe/unrealengine-old/search?q=UpperSkyColor">come straight from Unreal Engine</a> and judging by the name,
they might directly influence the lighting. Bingo!</p>

<p>A quick in-game test further confirms the theory – on an Intel machine, a vector of 4 NaN values was never submitted as pixel shader constants;
meanwhile, on an AMD machine, NaNs would start showing up as soon as the player entered the area where lighting breaks!</p>

<p>Does it mean work is done? No, far from it, as finding broken constants is only half of the success. The question remains, where do they come from, and can they be replaced?
An in-game test replacing NaN values with zeros partially fixed the issue – ugly black blobs disappeared, but characters were still way too dark:</p>

<p>
<img src="https://cookieplmonster.github.io/assets/img/posts/mass-effect/me1-dark-lighting.jpg"><br>
<em>Almost correct... …</em></p></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://cookieplmonster.github.io/2020/07/19/silentpatch-mass-effect/">https://cookieplmonster.github.io/2020/07/19/silentpatch-mass-effect/</a></em></p>]]>
            </description>
            <link>https://cookieplmonster.github.io/2020/07/19/silentpatch-mass-effect/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23889473</guid>
            <pubDate>Sun, 19 Jul 2020 14:08:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Clear explanation of Rust’s module system]]>
            </title>
            <description>
<![CDATA[
Score 154 | Comments 47 (<a href="https://news.ycombinator.com/item?id=23889427">thread link</a>) | @rkwz
<br/>
July 19, 2020 | http://www.sheshbabu.com/posts/rust-module-system/ | <a href="https://web.archive.org/web/*/http://www.sheshbabu.com/posts/rust-module-system/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Rust’s module system is surprisingly confusing and causes a lot of frustration for beginners.</p>
<p>In this post, I’ll explain the module system using practical examples so you get a clear understanding of how it works and can immediately start applying this in your projects.</p>
<p>Since Rust’s module system is quite unique, I request the reader to read this post with an open mind and resist comparing it with how modules work in other languages.</p>
<p>Let’s use this file structure to simulate a real world project:</p>
<pre><code>my_project
├── Cargo.toml
└─┬ src
  ├── main.rs
  ├── config.rs
  ├─┬ routes
  │ ├── health_route.rs
  │ └── user_route.rs
  └─┬ models
    └── user_model.rs</code></pre>
<p>These are the different ways we should be able to consume our modules:</p>
<p><img src="http://www.sheshbabu.com/images/2020-rust-module-system/rust-module-system-1.png" alt=""></p>
<p>These 3 examples should be sufficient to explain how Rust’s module system works.</p>
<h2 id="Example-1"><a href="#Example-1" title="Example 1"></a>Example 1</h2><p>Let’s start with the first example - importing <code>config.rs</code> in <code>main.rs</code>.</p>
<pre><code>
<span>fn</span> <span>main</span><span>(</span><span>)</span> <span>{</span>
  <span>println!</span><span>(</span><span>"main"</span><span>)</span><span>;</span>
<span>}</span></code></pre>
<pre><code>
<span>fn</span> <span>print_config</span><span>(</span><span>)</span> <span>{</span>
  <span>println!</span><span>(</span><span>"config"</span><span>)</span><span>;</span>
<span>}</span></code></pre>
<p>The first mistake that everyone makes is just because we have files like <code>config.rs</code>, <code>health_route.rs</code> etc, we think that these files are <code>modules</code> and we can import them from other files.</p>
<p>Here’s what we see (file system tree) and what the compiler sees (module tree):</p>
<p><img src="http://www.sheshbabu.com/images/2020-rust-module-system/rust-module-system-2.png" alt=""></p>
<p>Surprisingly, the compiler only sees the <code>crate</code> module which is our <code>main.rs</code> file. This is because we need to explicitly build the module tree in Rust - there’s no implicit mapping between file system tree to module tree.</p>
<blockquote>
<p>We need to explicitly build the module tree in Rust, there’s no implicit mapping to file system</p>
</blockquote>
<p>To add a file to the module tree, we need to declare that file as a submodule using the <code>mod</code> keyword. The next thing that confuses people is that you would assume we declare a file as module in the same file. But we need to declare this in a different file! Since we only have <code>main.rs</code> in the module tree, let’s declare <code>config.rs</code> as a submodule in <code>main.rs</code>.</p>
<blockquote>
<p>The mod keyword declares a submodule</p>
</blockquote>
<p>The <code>mod</code> keyword has this syntax:</p>
<pre><code><span>mod</span> my_module<span>;</span></code></pre>
<p>Here, the compiler looks for <code>my_module.rs</code> or <code>my_module/mod.rs</code> in the same directory.</p>
<pre><code>my_project
├── Cargo.toml
└─┬ src
  ├── main.rs
  └── my_module.rs

or

my_project
├── Cargo.toml
└─┬ src
  ├── main.rs
  └─┬ my_module
    └── mod.rs</code></pre>
<p>Since <code>main.rs</code> and <code>config.rs</code> are in the same directory, let’s declare the config module as follows:</p>
<pre><code>// main.rs
<span>+ mod config;</span>

fn main() {
<span>+ config::print_config();</span>
  println!("main");
}</code></pre>
<pre><code>
<span>fn</span> <span>print_config</span><span>(</span><span>)</span> <span>{</span>
  <span>println!</span><span>(</span><span>"config"</span><span>)</span><span>;</span>
<span>}</span></code></pre>
<p>We’re accessing the <code>print_config</code> function using the <code>::</code> syntax.</p>
<p>Here’s how the module tree looks like:</p>
<p><img src="http://www.sheshbabu.com/images/2020-rust-module-system/rust-module-system-3.png" alt=""></p>
<p>We’ve successfully declared the <code>config</code> module! But this is not sufficient to be able to call the <code>print_config</code> function inside <code>config.rs</code>. Almost everything in Rust is private by default, we need to make the function public using the <code>pub</code> keyword:</p>
<blockquote>
<p>The pub keyword makes things public</p>
</blockquote>
<pre><code>
<span>mod</span> config<span>;</span>

<span>fn</span> <span>main</span><span>(</span><span>)</span> <span>{</span>
  config<span>:</span><span>:</span><span>print_config</span><span>(</span><span>)</span><span>;</span>
  <span>println!</span><span>(</span><span>"main"</span><span>)</span><span>;</span>
<span>}</span></code></pre>
<pre><code>// config.rs
<span>- fn print_config() {</span>
<span>+ pub fn print_config() {</span>
  println!("config");
}</code></pre>
<p>Now, this works. We’ve successfully called a function defined in a different file!</p>
<h2 id="Example-2"><a href="#Example-2" title="Example 2"></a>Example 2</h2><p>Let’s try calling the <code>print_health_route</code> function defined in <code>routes/health_route.rs</code> from <code>main.rs</code>.</p>
<pre><code>
<span>mod</span> config<span>;</span>

<span>fn</span> <span>main</span><span>(</span><span>)</span> <span>{</span>
  config<span>:</span><span>:</span><span>print_config</span><span>(</span><span>)</span><span>;</span>
  <span>println!</span><span>(</span><span>"main"</span><span>)</span><span>;</span>
<span>}</span></code></pre>
<pre><code>
<span>fn</span> <span>print_health_route</span><span>(</span><span>)</span> <span>{</span>
  <span>println!</span><span>(</span><span>"health_route"</span><span>)</span><span>;</span>
<span>}</span></code></pre>
<p>As we discussed earlier, we can use the <code>mod</code> keyword only for <code>my_module.rs</code> or <code>my_module/mod.rs</code> in the same directory.</p>
<p>So in order to call functions inside <code>routes/health_route.rs</code> from <code>main.rs</code>, we need to do the following things:</p>
<ul>
<li>Create a file named <code>routes/mod.rs</code> and declare the <code>routes</code> submodule in <code>main.rs</code></li>
<li>Declare the <code>health_route</code> submodule in <code>routes/mod.rs</code> and make it public</li>
<li>Make the functions inside <code>health_route.rs</code> public</li>
</ul>
<pre><code>my_project
├── Cargo.toml
└─┬ src
  ├── main.rs
  ├── config.rs
  ├─┬ routes
<span>+ │ ├── mod.rs</span>
  │ ├── health_route.rs
  │ └── user_route.rs
  └─┬ models
    └── user_model.rs</code></pre>
<pre><code>// main.rs
mod config;
<span>+ mod routes;</span>

fn main() {
<span>+ routes::health_route::print_health_route();</span>
  config::print_config();
  println!("main");
}</code></pre>
<pre><code>// routes/mod.rs
<span>+ pub mod health_route;</span></code></pre>
<pre><code>// routes/health_route.rs
<span>- fn print_health_route() {</span>
<span>+ pub fn print_health_route() {</span>
  println!("health_route");
}</code></pre>
<p>Here’s how the module tree looks like:</p>
<p><img src="http://www.sheshbabu.com/images/2020-rust-module-system/rust-module-system-4.png" alt=""></p>
<p>We can now call a function defined in a file inside a folder.</p>
<h2 id="Example-3"><a href="#Example-3" title="Example 3"></a>Example 3</h2><p>Let’s try calling from <code>main.rs =&gt; routes/user_route.rs =&gt; models/user_model.rs</code></p>
<pre><code>
<span>mod</span> config<span>;</span>
<span>mod</span> routes<span>;</span>

<span>fn</span> <span>main</span><span>(</span><span>)</span> <span>{</span>
  routes<span>:</span><span>:</span>health_route<span>:</span><span>:</span><span>print_health_route</span><span>(</span><span>)</span><span>;</span>
  config<span>:</span><span>:</span><span>print_config</span><span>(</span><span>)</span><span>;</span>
  <span>println!</span><span>(</span><span>"main"</span><span>)</span><span>;</span>
<span>}</span></code></pre>
<pre><code>
<span>fn</span> <span>print_user_route</span><span>(</span><span>)</span> <span>{</span>
  <span>println!</span><span>(</span><span>"user_route"</span><span>)</span><span>;</span>
<span>}</span></code></pre>
<pre><code>
<span>fn</span> <span>print_user_model</span><span>(</span><span>)</span> <span>{</span>
  <span>println!</span><span>(</span><span>"user_model"</span><span>)</span><span>;</span>
<span>}</span></code></pre>
<p>We want to call the function <code>print_user_model</code> from <code>print_user_route</code> from <code>main</code>.</p>
<p>Let’s make the same changes as before - declaring submodules, making functions public and adding the <code>mod.rs</code> file.</p>
<pre><code>my_project
├── Cargo.toml
└─┬ src
  ├── main.rs
  ├── config.rs
  ├─┬ routes
  │ ├── mod.rs
  │ ├── health_route.rs
  │ └── user_route.rs
  └─┬ models
<span>+   ├── mod.rs</span>
    └── user_model.rs</code></pre>
<pre><code>// main.rs
mod config;
mod routes;
<span>+ mod models;</span>

fn main() {
  routes::health_route::print_health_route();
<span>+ routes::user_route::print_user_route();</span>
  config::print_config();
  println!("main");
}</code></pre>
<pre><code>// routes/mod.rs
pub mod health_route;
<span>+ pub mod user_route;</span></code></pre>
<pre><code>// routes/user_route.rs
<span>- fn print_user_route() {</span>
<span>+ pub fn print_user_route() {</span>
  println!("user_route");
}</code></pre>
<pre><code>// models/mod.rs
<span>+ pub mod user_model;</span></code></pre>
<pre><code>// models/user_model.rs
<span>- fn print_user_model() {</span>
<span>+ pub fn print_user_model() {</span>
  println!("user_model");
}</code></pre>
<p>Here’s how the module tree looks like:</p>
<p><img src="http://www.sheshbabu.com/images/2020-rust-module-system/rust-module-system-5.png" alt=""></p>
<p>Wait, we haven’t actually called <code>print_user_model</code> from <code>print_user_route</code>! So far, we’ve only called the functions defined in other modules from <code>main.rs</code>, how do we do that from other files?</p>
<p>If we look at our module tree, the <code>print_user_model</code> function sits in the <code>crate::models::user_model</code> path. So in order to use a module in files that are not <code>main.rs</code>, we should think in terms of the path necessary to reach that module in the module tree.</p>
<pre><code>// routes/user_route.rs
pub fn print_user_route() {
<span>+ crate::models::user_model::print_user_model();</span>
  println!("user_route");
}</code></pre>
<p>We’ve successfully called a function defined in a file from a file that’s not <code>main.rs</code>.</p>
<h2 id="super"><a href="#super" title="super"></a>super</h2><p>The fully qualified name gets too lengthy if our file organization is multiple directories deep. Let’s say for whatever reason, we want to call <code>print_health_route</code> from <code>print_user_route</code>. These are under the paths <code>crate::routes::health_route</code> and <code>crate::routes::user_route</code> respectively.</p>
<p>We can call it by using the fully qualified name <code>crate::routes::health_route::print_health_route()</code> but we can also use a relative path <code>super::health_route::print_health_route();</code>. Notice that we’ve used <code>super</code> to refer to the parent scope.</p>
<blockquote>
<p>The super keyword in module path refers to the parent scope</p>
</blockquote>
<pre><code><span>pub</span> <span>fn</span> <span>print_user_route</span><span>(</span><span>)</span> <span>{</span>
  <span>crate</span><span>:</span><span>:</span>routes<span>:</span><span>:</span>health_route<span>:</span><span>:</span><span>print_health_route</span><span>(</span><span>)</span><span>;</span>
  
  <span>super</span><span>:</span><span>:</span>health_route<span>:</span><span>:</span><span>print_health_route</span><span>(</span><span>)</span><span>;</span>

  <span>println!</span><span>(</span><span>"user_route"</span><span>)</span><span>;</span>
<span>}</span></code></pre>
<h2 id="use"><a href="#use" title="use"></a>use</h2><p>It would be tedious to use the fully qualified name or even the relative name in the above examples. In order to shorten the names, we can use the <code>use</code> keyword to bind the path to a new name or alias.</p>
<blockquote>
<p>The use keyword is used to shorten the module path</p>
</blockquote>
<pre><code><span>pub</span> <span>fn</span> <span>print_user_route</span><span>(</span><span>)</span> <span>{</span>
  <span>crate</span><span>:</span><span>:</span>models<span>:</span><span>:</span>user_model<span>:</span><span>:</span><span>print_user_model</span><span>(</span><span>)</span><span>;</span>
  <span>println!</span><span>(</span><span>"user_route"</span><span>)</span><span>;</span>
<span>}</span></code></pre>
<p>The above code can be refactored as:</p>
<pre><code><span>use</span> <span>crate</span><span>:</span><span>:</span>models<span>:</span><span>:</span>user_model<span>:</span><span>:</span>print_user_model<span>;</span>

<span>pub</span> <span>fn</span> <span>print_user_route</span><span>(</span><span>)</span> <span>{</span>
  <span>print_user_model</span><span>(</span><span>)</span><span>;</span>
  <span>println!</span><span>(</span><span>"user_route"</span><span>)</span><span>;</span>
<span>}</span></code></pre>
<p>Instead of using the name <code>print_user_model</code>, we can also alias it to something else:</p>
<pre><code><span>use</span> <span>crate</span><span>:</span><span>:</span>models<span>:</span><span>:</span>user_model<span>:</span><span>:</span>print_user_model <span>as</span> log_user_model<span>;</span>

<span>pub</span> <span>fn</span> <span>print_user_route</span><span>(</span><span>)</span> <span>{</span>
  <span>log_user_model</span><span>(</span><span>)</span><span>;</span>
  <span>println!</span><span>(</span><span>"user_route"</span><span>)</span><span>;</span>
<span>}</span></code></pre>
<h2 id="External-modules"><a href="#External-modules" title="External modules"></a>External modules</h2><p>Dependencies added to <code>Cargo.toml</code> are available globally to all modules inside the project. We don’t need to explicitly import or declare anything to use a dependency.</p>
<blockquote>
<p>External dependencies are globally available to all modules inside a project</p>
</blockquote>
<p>For example, let’s say we added the <a href="https://crates.io/crates/rand" target="_blank" rel="noopener">rand</a> crate to our project. We can use it in our code directly as:</p>
<pre><code><span>pub</span> <span>fn</span> <span>print_health_route</span><span>(</span><span>)</span> <span>{</span>
  <span>let</span> random_number<span>:</span> u8 <span>=</span> rand<span>:</span><span>:</span><span>random</span><span>(</span><span>)</span><span>;</span>
  <span>println!</span><span>(</span><span>"{}"</span><span>,</span> random_number<span>)</span><span>;</span>
  <span>println!</span><span>(</span><span>"health_route"</span><span>)</span><span>;</span>
<span>}</span></code></pre>
<p>We can also use <code>use</code> to shorten the path:</p>
<pre><code><span>use</span> rand<span>:</span><span>:</span>random<span>;</span>

<span>pub</span> <span>fn</span> <span>print_health_route</span><span>(</span><span>)</span> <span>{</span>
  <span>let</span> random_number<span>:</span> u8 <span>=</span> <span>random</span><span>(</span><span>)</span><span>;</span>
  <span>println!</span><span>(</span><span>"{}"</span><span>,</span> random_number<span>)</span><span>;</span>
  <span>println!</span><span>(</span><span>"health_route"</span><span>)</span><span>;</span>
<span>}</span></code></pre>
<h2 id="Summary"><a href="#Summary" title="Summary"></a>Summary</h2><ul>
<li>The module system is explicit - there’s no 1:1 mapping with file system</li>
<li>We declare a file as module in its parent, not in itself</li>
<li>The <code>mod</code> keyword is used to declare submodules</li>
<li>We need to explicitly declare functions, structs etc as public so they can be consumed in other modules</li>
<li>The <code>pub</code> keyword makes things public</li>
<li>The <code>use</code> keyword is used to shorten the module path</li>
<li>We don’t need to explicitly declare 3rd party modules</li>
</ul>
<p>Thanks for reading! Feel free to follow me in <a href="https://twitter.com/sheshbabu" target="_blank" rel="noopener">Twitter</a> for more posts like this :)</p>
</div></div>]]>
            </description>
            <link>http://www.sheshbabu.com/posts/rust-module-system/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23889427</guid>
            <pubDate>Sun, 19 Jul 2020 14:01:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: [Demo] GigoBooks: open-source accounting SW for micro-business (NoSaaS)]]>
            </title>
            <description>
<![CDATA[
Score 15 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23889104">thread link</a>) | @bengtan
<br/>
July 19, 2020 | https://gigobooks.github.io/demo/ | <a href="https://web.archive.org/web/*/https://gigobooks.github.io/demo/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://gigobooks.github.io/demo/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23889104</guid>
            <pubDate>Sun, 19 Jul 2020 13:13:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[One year of Flutter as a web developer]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23888947">thread link</a>) | @realusername
<br/>
July 19, 2020 | https://alex-min.fr/one-year-of-flutter/ | <a href="https://web.archive.org/web/*/https://alex-min.fr/one-year-of-flutter/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
    <p>I spent a considerable time on my <a rel="nofollow noopener noreferrer" target="_blank" href="https://mavio.fr/">budget app</a> side project built in Flutter. After a year of development and 25k lines of code later, I wanted to create a blog post about how everything went and my feedback on working with this framework.</p>

<h2 id="the-dart-language">The Dart language</h2>

<p>Flutter is built with Dart, a Javascript/Java inspired language. Dart was built internally at Google with the specific goal to replace Javascript on the web as a saner language, with better defaults. Unfortunately for the Dart team, the project never took off, Dart was stuck in a limbo state for a few years while still being maintained for internal Google needs.</p>

<p>The language itself had very good features which enabled other uses cases:</p>
<ul>
  <li>The Dart VM is a wonderful piece of technology, build with hot reloading at its core</li>
  <li>The language can be interpreted or compiled natively for better performance</li>
  <li>The Dart tooling around the language well built</li>
</ul>

<p>I fully expected the language to be an issue on the project since it’s so niche, but actually it has been a great experience on that level. It’s quick to learn and very easy to pick up, especially if you have done some Javascript previously.</p>

<h2 id="the-good-parts">The good parts</h2>

<h3 id="tooling">Tooling</h3>

<p>The Flutter tooling is one of it’s strong parts. Hot reloading your code <strong>actually</strong> works, Flutter is almost the only piece of technology I’ve ever used where the hot reload was working as well as it is. Generally I would disable it elsewhere, it even makes you miss it in other languages.</p>

<p>The package manager (pub) works great, upgrades are smooth (if you are coming from the npm world, it’s honestly a breath of fresh air). After a year of managing my project, I only had a single conflict where I had to pin a specific version of a package to avoid a compilation error with the main Flutter SDK, that only lasted two weeks and then upgrades were smooth again.</p>

<p>The Flutter SDK has multiple channels (master, dev, beta and stable), the stable version is quite good as not reintroducing regressions and flutter upgrades can be done from the command line easily.</p>

<p>The language server in VSCode works perfectly, autocompletion also works wonders, the Dart code formatter is also one of the best I used, I consider it on par with Go, which is one of the best in my opinion.</p>

<h3 id="performance--animations">Performance &amp; Animations</h3>

<p>Flutter uses Skia, an internal and very performant render engine which draws everything to a canvas. Performance is definitely a strong point of the platform. I use a very cheap Samsung J3 as my daily driver which is almost the bottom of the barrel in terms of performance in 2020. Basically every app on my phone is lagging noticeably, including Google apps. My budget app on the other hand is the quickest app on my phone, by a long margin. If you are targetting a market with a lot of low-end budget phones, Flutter is exactly what you need.</p>

<p>Animations are also a very strong point of this platform, high-speed animations can be built with <a rel="nofollow noopener noreferrer" target="_blank" href="https://rive.app/">Rive</a> and imported directly into Flutter, rendered at full speed and weighting a few Kb. I do have a few toy animations built with Rive on my app.</p>

<h3 id="portability">Portability</h3>

<p>I have not published the iOS version yet due to Apple developer account issues but my budget app already works without much effort identically on Android, Linux, Windows &amp; macOS thanks to <a rel="nofollow noopener noreferrer" target="_blank" href="https://github.com/go-flutter-desktop/hover">Hover</a>.</p>

<p>If you are building a desktop app, Flutter can be a good technology to keep in mind. It produces small binaries, fast and reactive applications, works cross-platform and won’t use too much RAM like most Electron apps.</p>

<p>Desktop support is still in an alpha quality at the moment so expect some missing features, you might have to dig into the code and make some pull requests.</p>

<h3 id="the-flutter-sdk">The Flutter SDK</h3>

<p>The SDK is quite complete, a lot of basic and complex components are there. The SDK has material design guidelines by default, which might be a good thing or a bad thing depending on what you are trying to achieve.</p>

<p>While you can make your application look native with more work but generally it’s not what you would use Flutter for. Flutter shines primarily as building complex apps which have their own design goals.</p>

<h3 id="styling">Styling</h3>

<p>Styling will look familiar if you are coming from a web background. You will have a stripped-down version of flex, padding &amp; margins, border-radius, font-weight…</p>

<p>The main difference being that there’s a global Flutter theme which applies to your whole app instead of classes. This makes it easier to swap the theme to make a dark theme.</p>

<p>I’m still trying to make my stying code looks nicer, extending the main theme seems to be the right approach.</p>

<h2 id="the-parts-which-would-need-improvements">The parts which would need improvements</h2>

<h3 id="testing">Testing</h3>

<p>Testing isn’t that bad, especially if you are coming from the Javascript world. A lot of the testing building blocks you expect are there and you do have a driver where you can tap on elements and see what happens.</p>

<figure>

  <p><img src="https://d33wubrfki0l68.cloudfront.net/172a2207d60b86a77bfc854290aa6349be0d69a7/3e636/images/flutter-test-terminal.png" alt="A screenshot of a terminal showing that 174 tests passed in 4 minutes 43 seconds"></p>
  <figcaption>Yay! Hopefully everything works.</figcaption>
</figure>

<p>If you come from the Ruby world however, the testing will feel pretty average and you might find yourself needing a bit more boilerplate than you would expect. There’s definitely some room to make testing more enjoyable and faster to write.</p>

<p>There is also no mutation testing in Dart yet (that I’m aware of), so you will have to use the code coverage tool extensively in the mean time and try to catch as much as you can. I had a pretty blocking bug on the code coverage tool which has been fixed in one of the more recent stable versions so I can recommend it now.</p>

<h3 id="navigation">Navigation</h3>

<p>Navigation works stateless in Flutter. That can be a great thing, especially when you are importing packages, no need to plug your router for using packages, there’s one big issue however, it’s not really possible to micro-manage the view state when you use the go back button on Android.</p>

<p>That can be a problem for knowing which route you are on at the moment if you want to update the bottom bar with an indicator for example. As far as I know, it’s still an unsolved problem, unless you rebuild an entire navigation system yourself with Provider or another Flutter state management library. I’ll probably do that in the future but that’s a lower priority bug at the moment.</p>

<h3 id="webviews">Webviews</h3>

<p>If you need Webviews for your project (which I needed), it might be a blocker in the current state. Webviews don’t support multiple tabs (which means <em>window.open</em> won’t work in Javascript), the view might crash and there is poor keyboard support at the moment.</p>

<p>Additionally, this alpha-state Webview is only available on Android and iOS, not on any desktop platform yet.</p>

<h2 id="conclusion">Conclusion</h2>

<p>As far as the Flutter platform goes, it’s been a pretty enjoyable experience for me. I will write one or more retrospective blog post on this project. I do recommend Flutter and even as a web developer, where you might prefer React Native initially due to the familiarity with Javascript, I would recommend trying Flutter, it will surprise you.</p>


  </section></div>]]>
            </description>
            <link>https://alex-min.fr/one-year-of-flutter/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23888947</guid>
            <pubDate>Sun, 19 Jul 2020 12:41:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[PostgreSQL quickstart guide – connecting, remote access, psql CLI and more]]>
            </title>
            <description>
<![CDATA[
Score 18 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23888907">thread link</a>) | @lukasbar
<br/>
July 19, 2020 | https://knowledgepill.it/posts/postgresql-basics-guide/ | <a href="https://web.archive.org/web/*/https://knowledgepill.it/posts/postgresql-basics-guide/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  <h2 id="configure-remote-access---listen-address">Configure remote access - listen address</h2>
<p>By default after instalation and creting database cluster PostgreSQL will listner only on localhost. No remote access will be allowed.</p>
<hr>
<p><a href="https://knowledgepill.it/posts/postgresql_installation/">PostgreSQL installation on Linux - with database creation</a></p>
<hr>
<div><pre><code data-lang="bash"><span>[</span>postgres@postgres-lab ~<span>]</span>$ netstat -lptnu | grep post
<span>(</span>Not all processes could be identified, non-owned process info
 will not be shown, you would have to be root to see it all.<span>)</span>
tcp        <span>0</span>      <span>0</span> 127.0.0.1:5432          0.0.0.0:*               LISTEN      1977/postmaster     
tcp6       <span>0</span>      <span>0</span> ::1:5432                :::*                    LISTEN      1977/postmaster     
</code></pre></div><p>To change listen address we have to configure parameter in <code>postgresql.conf</code></p>
<p>Check <code>PGDATA</code> - after <code>-D</code> parameter:</p>
<div><pre><code data-lang="bash"><span>[</span>postgres@postgres-lab ~<span>]</span>$ ps aux | grep postgres
postgres  <span>1977</span>  0.0  2.5 <span>286388</span> <span>14864</span> ?        Ss   Jun28   0:02 /usr/pgsql-12/bin/postmaster -D /postgresql/data
postgres  <span>1979</span>  0.0  0.2 <span>140768</span>  <span>1360</span> ?        Ss   Jun28   0:00 postgres: logger   
postgres  <span>1981</span>  0.0  0.5 <span>286504</span>  <span>3028</span> ?        Ss   Jun28   0:00 postgres: checkpointer   
postgres  <span>1982</span>  0.0  0.2 <span>286388</span>  <span>1696</span> ?        Ss   Jun28   0:03 postgres: background writer   
postgres  <span>1983</span>  0.0  0.9 <span>286388</span>  <span>5676</span> ?        Ss   Jun28   0:03 postgres: walwriter   
postgres  <span>1984</span>  0.0  0.4 <span>286924</span>  <span>2688</span> ?        Ss   Jun28   0:02 postgres: autovacuum launcher  
</code></pre></div><p>Locate the file:</p>
<div><pre><code data-lang="bash"><span>[</span>postgres@postgres-lab ~<span>]</span>$ cd /postgresql/data/
<span>[</span>postgres@postgres-lab data<span>]</span>$ ls -lah postgresql.conf
-rw-------. <span>1</span> postgres postgres 26K Jun <span>28</span> 21:44 postgresql.conf
</code></pre></div><p>Change in <code>postgresql.conf</code> parameter <code>listen_addresses</code> to your server IP or <code>*</code> to listen on all IP’s available on server:</p>
<div><pre><code data-lang="bash"><span>[</span>postgres@postgres-lab data<span>]</span>$ vi postgresql.conf

<span>##------------------------------------------------------------------------------</span>
<span>## CONNECTIONS AND AUTHENTICATION</span>
<span>##------------------------------------------------------------------------------</span>

<span>## - Connection Settings -</span>

listen_addresses <span>=</span> <span>'*'</span>          <span>## what IP address(es) to listen on;</span>
                                        <span>## comma-separated list of addresses;</span>
                                        <span>## defaults to 'localhost'; use '*' for all</span>
</code></pre></div><p>Restart PostgreSQL to apply changes - you can do that with <code>systemctl</code> from <code>root</code> os user  service or with <code>pg_ctl -D PGDATA restart</code> from <code>postgres</code> os user:</p>
<div><pre><code data-lang="bash"><span>[</span>root@postgres-lab ~<span>]</span><span>## systemctl restart postgresql-12.service</span>
</code></pre></div><p>Check whre PostgreSQL is listening now:</p>
<div><pre><code data-lang="bash"><span>[</span>postgres@postgres-lab ~<span>]</span>$ netstat -lptnu | grep post
<span>(</span>Not all processes could be identified, non-owned process info
 will not be shown, you would have to be root to see it all.<span>)</span>
tcp        <span>0</span>      <span>0</span> 0.0.0.0:5432            0.0.0.0:*               LISTEN      30161/postmaster    
tcp6       <span>0</span>      <span>0</span> :::5432                 :::*                    LISTEN      30161/postmaster  
</code></pre></div><h2 id="configure-remote-access---pg_hbaconf">Configure remote access - pg_hba.conf</h2>
<p>PostgreSQL instance has got restricted access by <code>pg_hba.conf</code> file(host based authentication file).</p>
<p>We can provide in it information from which <code>ADDRESS</code> to which <code>DATABASE</code> on which <code>USER</code> by what <code>METHOD</code> we allow connecting. Additionaly we have to provide <code>TYPE</code> of connection.</p>
<p>This file resides in same place where <code>postgresql.conf</code>(we can alter this behavior by setting <code>pg_hba</code> parameter in <code>postgresql.conf</code>):</p>
<div><pre><code data-lang="bash"><span>[</span>postgres@postgres-lab ~<span>]</span>$ cd /postgresql/data/

<span>[</span>postgres@postgres-lab data<span>]</span>$ vi pg_hba.conf
<span>## TYPE  DATABASE        USER            ADDRESS                 METHOD</span>

<span>## "local" is for Unix domain socket connections only</span>
local   all             all                                     trust
<span>## IPv4 local connections:</span>
host    all             all             127.0.0.1/32            trust
<span>## IPv6 local connections:</span>
host    all             all             ::1/128                 trust
</code></pre></div><p>Allowed <code>TYPE</code>'s:</p>
<ul>
<li><code>local</code> - socket connection - needed to connect from shell on database server</li>
<li><code>host</code> - standard TCP/IP connection over the network - bnost SSL and no SSL</li>
<li><code>hostssl</code> - TCP/IP connection but only with SSL</li>
<li><code>hostnossl</code> - TCP/IP only without SSL</li>
<li><code>hostgssenc</code> - TCP/IP only GSSAPI</li>
<li><code>hostnogssenc</code> - TCP/IP only without GSSAPI</li>
</ul>
<p>With <code>DATABASE</code> we can specify database name or use special value <code>sameuser</code> if database name should be same as name of user that is connecting.</p>
<p>With <code>USER</code> we can specify user or role - role name should be preceded by <code>+</code> sign.</p>
<p><code>ADDRESS</code> field could be - hostname, IP range in CIDR format or special words:</p>
<ul>
<li><code>samehost</code> - which correspond to all IP adresses of database server</li>
<li><code>samenet</code> - which correspond to all IP in database server subnet</li>
</ul>
<p>With <code>METHOD</code> field we can set one of authentication methods - most important ones are:</p>
<ul>
<li><code>trust</code> - allow connection without password - moslty set for local connections from database server itself</li>
<li><code>reject</code> - reject connections</li>
<li><code>md5</code> - allow connections after getting from user password - encrypted</li>
<li><code>password</code> - allow connection after getting plain password - DO NOT USE in untrusted networks - better -&gt; never use this option</li>
<li><code>ldap</code> - getting account authorization data from LDAP server</li>
</ul>
<p>In <code>DATABASE</code> and <code>USER</code> fields you can specify special word <code>all</code> if you don’t want to create any restrictions here.</p>
<p>There can be situation when we must use additional field named <code>auth-options</code> for specyfying details for example for <code>hostssl</code> connection type. This topic will be covered in another post.</p>
<h3 id="sample-pg_hba-record---allow-all-users-connect-to-any-db-from-all-ip-addresses---only-with-password">Sample pg_hba record - allow all users connect to any DB from all IP addresses - only with password</h3>
<p>Add in <code>pg_hba.conf</code>:</p>
<div><pre><code data-lang="bash"><span>## Network access</span>
host    all             all             0.0.0.0/0               md5
</code></pre></div><p>Reload(online operation) PostgreSQL that it can use <code>pg_hba.conf</code> changes:</p>
<div><pre><code data-lang="bash"><span>[</span>postgres@postgres-lab data<span>]</span>$ /usr/pgsql-12/bin/pg_ctl -D /postgresql/data reload
server signaled
</code></pre></div><h2 id="connecting-to-postgresql">Connecting to PostgreSQL</h2>
<h3 id="local-from-server">Local from server</h3>
<p>It will work without password because we have <code>trust</code> in <code>pg_hba.conf</code> for <code>local</code> connections:</p>
<div><pre><code data-lang="bash"><span>[</span>postgres@postgres-lab ~<span>]</span>$ psql
psql <span>(</span>12.3<span>)</span>
Type <span>"help"</span> <span>for</span> help.
</code></pre></div><h3 id="remote-machine">Remote machine</h3>
<p>Default URI syntax - you can connect like this:<br>
<code>psql postgresql://user:passwd@host:5432/dbame</code><br>
or by more common method:<br>
Connect to remote database from <code>psql</code> with connections details provided in parameters(it will ask for password because of <code>md5</code> method in <code>pg_hba.conf</code> for connections from <code>0.0.0.0/0</code>):</p>
<div><pre><code data-lang="bash"><span>[</span>postgres@postgres-lab data<span>]</span>$ psql -h 10.128.0.2 -p <span>5432</span>
Password <span>for</span> user postgres:
psql <span>(</span>12.3<span>)</span>
Type <span>"help"</span> <span>for</span> help.

postgres<span>=</span><span>##</span>
</code></pre></div><p>We can also use parameter <code>-U</code> to specify username different than OS username we currently are using.</p>
<p>Also all this parameters can be taken from shell variables which names are self descriptive - if we set all of them we can just use plain <code>psql</code> command to connect:</p>
<ul>
<li><code>PGHOST</code></li>
<li><code>PGPORT</code></li>
<li><code>PGDATABASE</code></li>
<li><code>PGUSER</code></li>
<li><code>PGPASSWORD</code></li>
</ul>
<h3 id="check-connected-database">Check connected database</h3>
<div><pre><code data-lang="bash">postgres<span>=</span><span>## select current_database();</span>
 current_database
------------------
 postgres
<span>(</span><span>1</span> row<span>)</span>
</code></pre></div><h3 id="check-current-user">Check current user</h3>
<div><pre><code data-lang="bash">postgres<span>=</span><span>## select current_user;</span>
 current_user
--------------
 postgres
<span>(</span><span>1</span> row<span>)</span>
</code></pre></div><h3 id="check-ip-and-port-used-for-connection">Check IP and port used for connection</h3>
<div><pre><code data-lang="bash">postgres<span>=</span><span>## select inet_server_addr(), inet_server_port();</span>
 inet_server_addr | inet_server_port
------------------+------------------
 10.128.0.2       |             <span>5432</span>
<span>(</span><span>1</span> row<span>)</span>
</code></pre></div><h3 id="check-postgresql-version">Check PostgreSQL version</h3>
<div><pre><code data-lang="bash">postgres<span>=</span><span>## select version();</span>
                                                version                                                 
--------------------------------------------------------------------------------------------------------
 PostgreSQL 12.3 on x86_64-pc-linux-gnu, compiled by gcc <span>(</span>GCC<span>)</span> 8.3.1 <span>20191121</span> <span>(</span>Red Hat 8.3.1-5<span>)</span>, 64-bit
<span>(</span><span>1</span> row<span>)</span>
</code></pre></div><h3 id="check-connection-info">Check connection info</h3>
<div><pre><code data-lang="bash">postgres<span>=</span><span>## \conninfo</span>
You are connected to database <span>"postgres"</span> as user <span>"postgres"</span> on host <span>"10.128.0.2"</span> at port <span>"5432"</span>.
</code></pre></div><h2 id="executing-commands-from-shell">Executing commands from shell</h2>
<h3 id="execute-single-command-from-shell">Execute single command from shell</h3>
<div><pre><code data-lang="bash"><span>[</span>postgres@postgres-lab ~<span>]</span>$ psql -c <span>"select current_time"</span>
    current_time    
--------------------
 14:09:19.854598+00
<span>(</span><span>1</span> row<span>)</span>
</code></pre></div><h3 id="exacute-sql-script-from-shell">Exacute sql script from shell</h3>
<div><pre><code data-lang="bash"><span>[</span>postgres@postgres-lab ~<span>]</span>$ psql -f create_user.sql
CREATE ROLE
CREATE ROLE
CREATE ROLE
</code></pre></div><h3 id="combine-single-command-with-sql-script-from-shell">Combine single command with sql script from shell</h3>
<div><pre><code data-lang="bash"><span>[</span>postgres@postgres-lab ~<span>]</span>$ psql -c <span>"select current_time"</span> -f create_user.sql -c <span>"select current_time"</span>
    current_time    
--------------------
 14:14:26.922453+00
<span>(</span><span>1</span> row<span>)</span>

CREATE ROLE
CREATE ROLE
CREATE ROLE
    current_time    
--------------------
 14:14:26.926545+00
<span>(</span><span>1</span> row<span>)</span>
</code></pre></div>
<h3 id="check-all-available-metacommands">Check all available metacommands</h3>
<p>Do it yourself to see all available commands - output trimmed to important ones!</p>
<div><pre><code data-lang="bash">postgres<span>=</span><span>## \?</span>
General
  <span>\c</span>opyright             show PostgreSQL usage and distribution terms
  <span>\c</span>rosstabview <span>[</span>COLUMNS<span>]</span> execute query and display results in crosstab
  <span>\e</span>rrverbose            show most recent error message at maximum verbosity
  <span>\g</span> <span>[</span>FILE<span>]</span> or ;         execute query <span>(</span>and send results to file or |pipe<span>)</span>
  <span>\g</span>desc                 describe result of query, without executing it
  <span>\g</span>exec                 execute query, <span>then</span> execute each value in its result
  <span>\g</span>set <span>[</span>PREFIX<span>]</span>         execute query and store results in psql variables
  <span>\g</span>x <span>[</span>FILE<span>]</span>             as <span>\g</span>, but forces expanded output mode
  <span>\q</span>                     quit psql
  <span>\w</span>atch <span>[</span>SEC<span>]</span>           execute query every SEC seconds

  Query Buffer
    <span>\e</span> <span>[</span>FILE<span>]</span> <span>[</span>LINE<span>]</span>       edit the query buffer <span>(</span>or file<span>)</span> with external editor
    <span>\e</span>f <span>[</span>FUNCNAME <span>[</span>LINE<span>]</span><span>]</span>  edit <span>function</span> definition with external editor
    <span>\e</span>v <span>[</span>VIEWNAME <span>[</span>LINE<span>]</span><span>]</span>  edit view definition with external editor
    <span>\p</span>                     show the contents of the query buffer
    <span>\r</span>                     reset <span>(</span>clear<span>)</span> the query buffer
    <span>\s</span> <span>[</span>FILE<span>]</span>              display history or save it to file
    <span>\w</span> FILE                write query buffer to file

</code></pre></div><h3 id="list-objects-in-psql">List objects in psql</h3>
<ul>
<li>\d[S+]          -       list tables, views, and sequences</li>
<li>\d[S+]  NAME     -      describe table, view, sequence, or index</li>
<li>\da[S]  [PATTERN] -     list aggregates</li>
<li>\dA[+]  [PATTERN]  -    list access methods</li>
<li>\db[+]  [PATTERN]   -   list tablespaces</li>
<li>\dc[S+] [PATTERN]    -  list conversions</li>
<li>\dC[+]  [PATTERN]     - list casts</li>
<li>\dd[S]  [PATTERN]     - show object descriptions not displayed elsewhere</li>
<li>\dD[S+] [PATTERN]     - list domains</li>
<li>\ddp    [PATTERN]     - list default privileges</li>
<li>\dE[S+] [PATTERN]     - list foreign tables</li>
<li>\det[+] [PATTERN]     - list …</li></ul></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://knowledgepill.it/posts/postgresql-basics-guide/">https://knowledgepill.it/posts/postgresql-basics-guide/</a></em></p>]]>
            </description>
            <link>https://knowledgepill.it/posts/postgresql-basics-guide/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23888907</guid>
            <pubDate>Sun, 19 Jul 2020 12:33:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Worms Armageddon 3.8]]>
            </title>
            <description>
<![CDATA[
Score 439 | Comments 142 (<a href="https://news.ycombinator.com/item?id=23888870">thread link</a>) | @typh00n
<br/>
July 19, 2020 | https://worms2d.info/Worms_Armageddon_3.8_Features | <a href="https://web.archive.org/web/*/https://worms2d.info/Worms_Armageddon_3.8_Features">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="mw-content-text" lang="en" dir="ltr">
<center><div><div><div><p><a href="https://wormtube.worms2d.info/vids/WormsArmageddon-TrailerVideo2020-SteamReady.mp4"><img alt="" src="https://worms2d.info/images/8/82/38_trailer_screenshot.jpg" width="640" height="360"></a></p><div><p>Click above to watch the new trailer in full quality!</p></div></div></div></div></center>
<div>
<p>Worms Armageddon version 3.8 is finally released! It's been a long time coming, and we hope you'll enjoy all the features, changes, and bug fixes that made it into this community-made update. To whet your appetite, here are some change highlights:
</p>
<div><div><p><a href="https://worms2d.info/File:ESOButton2.png"><img alt="ESOButton2.png" src="https://worms2d.info/images/0/04/ESOButton2.png" width="146" height="82"></a></p></div></div>
<h3><span id="Extended_Scheme_Options">Extended Scheme Options</span></h3>
<p>Customise your matches in weird and wonderful ways with over 70 new scheme options. Manipulate physics, fire more than one weapon in a turn, have worms bounce around the landscape, or choose from a huge array of other tweaks in order to perfect your scheme. These options are only for the seasoned Worms veteran, and as such you will need to have completed the Single Player mode and unlocked The Full Wormage in order to access them.</p>
<br><center><a href="https://worms2d.info/File:ESO1.gif" title="inline"><img alt="inline" src="https://worms2d.info/images/9/91/ESO1.gif" width="180" height="180"></a> <a href="https://worms2d.info/File:ESO2.gif" title="inline"><img alt="inline" src="https://worms2d.info/images/d/df/ESO2.gif" width="180" height="180"></a> <a href="https://worms2d.info/File:ESO3.gif" title="inline"><img alt="inline" src="https://worms2d.info/images/5/59/ESO3.gif" width="180" height="180"></a> <a href="https://worms2d.info/File:ESO4.gif" title="inline"><img alt="inline" src="https://worms2d.info/images/4/45/ESO4.gif" width="180" height="180"></a></center>
<p>For those who used the RubberWorm module in older versions of the game, all features formerly accessed through that module are now hiding behind the shiny new Extended Scheme Options star button. Relive your past glories — all your old RubberWorm recorded games can be played back with no additional software required.
</p>

<div><div><p><a href="https://worms2d.info/File:Tweening.gif"><img alt="" src="https://worms2d.info/images/5/53/Tweening.gif" width="300" height="240"></a></p><div><p>Demonstration of Tweening</p></div></div></div>
<h3><span id="Tweening">Tweening</span></h3>
<p>Worms Armageddon has never looked this smooth! In older versions, in-game movement and animations would be capped at the update rate of the game engine: 50 frames per second. In 3.8 though, experience the full silky smoothness of whatever frame rate your hardware can support — movement is now visually interpolated between game engine frames as your worms and weapons glide majestically through the air. Watch a recorded game in slow motion and you'll never want to go back!</p>
<div><div><p><a href="https://worms2d.info/File:Window.png"><img alt="" src="https://worms2d.info/images/d/dc/Window.png" width="300" height="237"></a></p><div><p>Demonstration of windowed mode</p></div></div></div>
<h3><span id="Windowed_Mode">Windowed Mode</span></h3>
<p>Worms Armageddon can now be played in a window! Awkward screen resolution changes and game capture issues are a thing of the past if you enable this feature in Advanced Settings.</p>
<div><div><p><a href="https://worms2d.info/File:Streaming-mode.png"><img alt="" src="https://worms2d.info/images/6/66/Streaming-mode.png" width="211" height="85"></a></p><div><p>Demonstration of Streaming Mode IP address hiding</p></div></div></div>
<h3><span id="Streamers.27_Heaven">Streamers' Heaven</span></h3>
<p>Along with Windowed Mode, a couple of additional options have been added specifically for streamers to make their lives easier. Audio can now be allowed to continue playing when the game window loses focus, and the new Streaming Mode will prevent IP addresses from being displayed when hosting or joining an online game (see the Update Documentation for more information).</p>
<div><div><p><a href="https://worms2d.info/File:Cpu-teams.png"><img alt="" src="https://worms2d.info/images/4/4d/Cpu-teams.png" width="252" height="151"></a></p><div><p>Demonstration of CPU teams being added to an online game</p></div></div></div>
<h3><span id="CPU_Teams_at_Large">CPU Teams at Large</span></h3>
<p>CPU teams can now be added to online games. They're always uniquely distinguishable from player teams to prevent shenanigans, but you can now finally team up with your friends to take down a swarm of those computer-controlled invertebrates. Or if you'd just like to watch a relaxing game while you work, matches containing only CPU teams may now also be started, both online and offline.</p>
<div><div><p><a href="https://worms2d.info/File:Smapshot.png"><img alt="" src="https://worms2d.info/images/7/71/Smapshot.png" width="300" height="225"></a></p></div></div>
<h3><span id="Mapshot">Mapshot</span></h3>
<p>Have you ever wrought a beautiful trail of destruction on your Worms Armageddon landscape and wished you could play a brand new game on the land that remained? Or have you ever been interrupted in the middle of a game and wished you could extract the remaining landscape to help you set up a rematch? Well, now you can! Simply type <b>/map</b> into the in-game chat or press <b>Alt + Pause</b> at any time to save a snapshot of the current state of the map, allowing you to continue your rampage from where you left off!</p>
<div><div><p><a href="https://worms2d.info/File:Wa95-2.png"><img alt="" src="https://worms2d.info/images/a/a0/Wa95-2.png" width="300" height="225"></a></p><div><p>Worms Armageddon running in Windows 95 (on real hardware!)</p></div></div></div>
<h3><span id="Compatibility">Compatibility</span></h3>
<p>Much effort has been expended in allowing everyone, no matter their hardware, to have a good Worms Armageddon experience. Further tweaks have been made to improve the experience of Windows 10 users. Worms Armageddon now runs well under Wine or Proton on Linux. A new OpenGL renderer has been added which, depending on your hardware, might outperform the other renderers. Windowed mode means there's no more need for your hardware to support specific screen resolutions. And for those into retro computing, Worms Armageddon has been seen to once again run on systems of yore...</p>
<div><div><p><a href="https://worms2d.info/File:Languages.png"><img alt="" src="https://worms2d.info/images/b/b5/Languages.png" width="222" height="120"></a></p><div><p>Sample of languages supported by Worms Armageddon's volunteer translators</p></div></div></div>
<h3><span id="Translations">Translations</span></h3>
<p>Through the tireless efforts of volunteer translators, Worms Armageddon is now fully translated to seven languages (🇫🇮 Finnish, 🇫🇷 French, 🇩🇪 German, 🇵🇹🇧🇷 Portuguese, 🇷🇺 Russian, 🇪🇸 Spanish and 🇸🇪 Swedish), with four more languages with partial translations on the way. The Update Documentation (Readme) now has translations to Finnish, French, and Spanish!</p>
<h3><span id="Fixes_and_More">Fixes and More</span></h3>
<p><a href="https://worms2d.info/File:Moon.png" title="Memey moon face"><img alt="Memey moon face" src="https://worms2d.info/images/4/47/Moon.png" width="100" height="123"></a></p>
<p>Over seven years in development, this update's release notes list consists of:
</p>
<ul><li> 370 fixes,</li>
<li> 45 changes, and</li>
<li> 61 new features.</li></ul>
<p>Our thanks go to all the hardworking members of the Worms Armageddon community who helped make this update a reality. And for the full list of what's new, check the Update Documentation (included with this update) or <a href="https://www.tus-wa.com/forums/announcements/worms-armageddon-v3-8-released-32795/">developer Deadcode's thread</a> on fan-site TUS!
</p>
</div>

<!-- 
NewPP limit report
Cached time: 20200722161827
Cache expiry: 86400
Dynamic content: false
CPU time usage: 0.016 seconds
Real time usage: 0.020 seconds
Preprocessor visited node count: 88/1000000
Preprocessor generated node count: 260/1000000
Post‐expand include size: 354/2097152 bytes
Template argument size: 60/2097152 bytes
Highest expansion depth: 4/40
Expensive parser function count: 0/100
-->

<!-- 
Transclusion expansion time report (%,ms,calls,template)
100.00%    2.343      1 - -total
 43.20%    1.012      1 - Template:ParentArticle
 33.69%    0.789      9 - Template:Clear
-->

<!-- Saved in parser cache with key wkb-mw_:pcache:idhash:5655-0!*!0!!*!5!* and timestamp 20200722161827 and revision id 26331
 -->
</div></div>]]>
            </description>
            <link>https://worms2d.info/Worms_Armageddon_3.8_Features</link>
            <guid isPermaLink="false">hacker-news-small-sites-23888870</guid>
            <pubDate>Sun, 19 Jul 2020 12:25:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Tired of note-taking apps]]>
            </title>
            <description>
<![CDATA[
Score 466 | Comments 450 (<a href="https://news.ycombinator.com/item?id=23888799">thread link</a>) | @akkshu92
<br/>
July 19, 2020 | https://akkshaya.blog/2020/07/19/note-taking/ | <a href="https://web.archive.org/web/*/https://akkshaya.blog/2020/07/19/note-taking/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-1052">
		<!-- .entry-header -->

	<div>
		
<p>I’m tired of note-taking apps. </p>



<p>It’s not because of limited choices. But it’s the other way around. There are so many note-taking apps you could try but end up sticking to none. At least, that’s my story. It’s a perfect example of&nbsp;<strong>the paradox of choice.</strong></p>



<p>I used to wonder why people keep building so many ‘note-taking’ apps when the market is already crowded with choices. Then I figured a few reasons why.</p>



<ul><li><strong>the market size</strong>: the global <a href="https://www.verifiedmarketresearch.com/product/note-making-management-software-market/#:~:text=According%20to%20Verified%20Market%20Research,5.32%25%20from%202019%20to%202026." target="_blank" rel="noreferrer noopener">note-taking management software market</a> is estimated to reach&nbsp;<strong>$1.35 billion </strong>by<strong> 2026</strong>, growing at a&nbsp;<strong>CAGR </strong>of<strong> 5.32% </strong>from<strong> 2019 to 2026</strong></li><li><strong>greater scope for innovation:&nbsp;</strong>eg., be it creating a task list, a roadmap, or a design repository, Notion can handle it all</li><li><strong>lack of satisfaction:&nbsp;</strong>it’s noted that people always use a combination of note-taking apps and hardly stick to one for a long time</li></ul>



<p>Despite such heavy competition, apps like Notion, Google Keep, OneNote, Evernote, etc. have managed to earn a place. People use these apps for</p>



<ul><li>the ecosystem. eg., Google Keep, Microsoft OneNote</li><li>the neat user experience., eg. Bear etc.</li><li>creating a disciplined way of taking notes. eg., Notion, Roam Research</li></ul>



<p>I’ve tried them all. But none of these apps have turned me into a ‘<strong>repeat user</strong>.’ </p>



<p>After battling with so many apps only to feel guilty for not having the discipline to consistently use them, I’ve finally resorted to the most personal and easy alternative ⁠—&nbsp;<strong>writing things down</strong>.</p>



<p>I’m familiar with writing in a notebook since my childhood. It’s not new to me, and it absolutely doesn’t require any learning curve.</p>



<h3>The reasons why I find writing things down useful</h3>



<ul><li>absolute focus and the ability to think through the points I’m writing</li><li>gives a chance to remember what I’m writing</li><li>no way to copy-paste stuff as it is, and that means taking notes in a way I understand</li><li>easy to switch between formats eg., flowchart, mind map, Venn diagram, etc</li><li>helps me stay in touch with my handwriting</li></ul>



<p>Of course, everything has its downsides, and writing things down is no exception here. <br>For example, I will not be able to</p>



<ul><li>add screenshots/images, links, etc</li><li>easily search for content as there’s no ‘search bar’</li></ul>



<p>And maybe there’s more to the list I’m not talking about. </p>



<p>All I can say for sure is, based on my usage behavior, I’m okay missing out on these features. I can always save links to <a href="https://app.getpocket.com/" target="_blank" rel="noreferrer noopener">Pocket</a> for future reference, and take pictures of my notes to share with friends.</p>



<p>So if you ask me if I’d try a beautiful, innovative note-taking app that’s much better than the apps I’ve used so far, my answer is,&nbsp;<em>“<strong>Why not</strong>! <strong>I’d definitely give it a shot</strong></em>.”</p>



<p>But my greatest worry is if I’d continue using it.</p>



<p><strong>Note: </strong>If my opinion on note-taking apps changes over time, I’d be happy to update this post with a “And the hero finally arrived!” heading to talk about the app that helped change my mind. 🤡</p>
			</div><!-- .entry-content -->

	<!-- .entry-footer -->

	</article></div>]]>
            </description>
            <link>https://akkshaya.blog/2020/07/19/note-taking/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23888799</guid>
            <pubDate>Sun, 19 Jul 2020 12:12:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Tilekit – a tilemap editor centered around pattern-based auto tiling]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23888749">thread link</a>) | @rxi
<br/>
July 19, 2020 | https://rxi.itch.io/tilekit | <a href="https://web.archive.org/web/*/https://rxi.itch.io/tilekit">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="wrapper"><div id="inner_column"><div itemscope="" itemtype="http://schema.org/Product" id="view_game_page_93165"><div><div><div><p>Tilekit is a tilemap editor centered around pattern-based auto tiling.</p>
<p><img src="https://img.itch.zone/aW1nLzM3MzM1MjkucG5n/original/NxjIjz.png"></p>
<p>Instead of manually placing hand-picked&nbsp;tiles, which can often be tedious, Tilekit works by using an&nbsp;<em>input</em> map of basic tiles and a set of user-defined rules to create the resultant&nbsp;<em>output</em> map from your tileset.<br></p>
<figure><img src="https://img.itch.zone/aW1nLzM3MzM0ODYuZ2lm/original/0jfMfV.gif"></figure>
<p><strong>Features:</strong><br></p>
<ul><li>Unique pattern-based-rule autotiling&nbsp;system</li><li>Map export to JSON</li><li>Code-export of final ruleset&nbsp;to C or Lua</li><li>Basic <em>object</em> system for game-entity placement</li><li>Simple animated tile system</li></ul>
<hr>
<p>Please <strong>try out the demo</strong> before purchasing!&nbsp;<em>(save and export are disabled in the demo version)&nbsp;— </em><strong></strong>The<strong>&nbsp;</strong><em>demo_projects.zip</em> archive&nbsp;includes some demo projects.<br></p></div><h2 id="purchase">Purchase</h2><div><p>In order to download this tool you must purchase it at or above the
              minimum price of $20 USD. You will get access to the following files:</p></div><h2 id="demo">Download demo</h2><section id="devlog"><h2>Development log</h2><ul><li><a href="https://rxi.itch.io/tilekit/devlog/160945/tilekit-103">Tilekit 1.03</a><p><abbr title="10 July 2020 @ 18:00"><span></span> 11 days ago</abbr></p></li><li><a href="https://rxi.itch.io/tilekit/devlog/159259/tilekit-102">Tilekit 1.02</a><p><abbr title="03 July 2020 @ 17:51"><span></span> 18 days ago</abbr></p></li><li><a href="https://rxi.itch.io/tilekit/devlog/158202/tilekit-101">Tilekit 1.01</a><p><abbr title="29 June 2020 @ 14:42"><span></span> 23 days ago</abbr></p></li></ul></section></div></div></div></div></div></div>]]>
            </description>
            <link>https://rxi.itch.io/tilekit</link>
            <guid isPermaLink="false">hacker-news-small-sites-23888749</guid>
            <pubDate>Sun, 19 Jul 2020 12:01:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Things Unexpectedly Named After People]]>
            </title>
            <description>
<![CDATA[
Score 422 | Comments 282 (<a href="https://news.ycombinator.com/item?id=23888725">thread link</a>) | @vortex_ape
<br/>
July 19, 2020 | https://notes.rolandcrosby.com/posts/unexpectedly-eponymous/ | <a href="https://web.archive.org/web/*/https://notes.rolandcrosby.com/posts/unexpectedly-eponymous/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            
            <p><h5>July 19, 2020</h5></p>
        </div></div>]]>
            </description>
            <link>https://notes.rolandcrosby.com/posts/unexpectedly-eponymous/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23888725</guid>
            <pubDate>Sun, 19 Jul 2020 11:58:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Inheritance in C using structure composition]]>
            </title>
            <description>
<![CDATA[
Score 60 | Comments 28 (<a href="https://news.ycombinator.com/item?id=23888677">thread link</a>) | @arpitbbhayani
<br/>
July 19, 2020 | https://arpitbhayani.me/blogs/inheritance-c | <a href="https://web.archive.org/web/*/https://arpitbhayani.me/blogs/inheritance-c">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p>C language does not support inheritance however it does support Structure Compositions which can be tweaked to serve use-cases requiring parent-child relationships. In this article, we find out how Structure Compositions help us emulate inheritance in C and keep our code extensible. We will also find how it powers two of the most important things to have ever been invented in the field of computer science.</p>

<p>Structure Composition is when we put one structure within another, not through its pointer but as a native member - something like this</p>
<pre><code>


<span><span>struct</span> <span>list_head</span> {</span>
	<span><span>struct</span> <span>list_head</span> *<span>next</span>;</span> 
	<span><span>struct</span> <span>list_head</span> *<span>prev</span>;</span> 
};


<span><span>struct</span> <span>list_int</span> {</span>
	<span><span>struct</span> <span>list_head</span> <span>list</span>;</span>  
	<span>int</span> value;              
};


<span><span>struct</span> <span>list_str</span> {</span>
	<span><span>struct</span> <span>list_head</span> <span>list</span>;</span>  
	<span>char</span> * str;             
};
</code></pre>
<p>In the example above, we define a node of a linked list using structure composition. Usually, a linked list node has 3 members - two pointers to adjacent nodes (next and previous) and a third one could either be the data or a pointer to it.  The defining factor of a linked list is the two pointers that logically form a chain of nodes. To keep things abstract we create a struct named <code>list_head</code> which holds these two pointers  <code>next</code> and <code>prev</code> and omits the specifics i.e. data.</p>
<p>Using <code>list_head</code> structure, if we were to define a node of a linked list holding an integer value we could create another struct, named <code>list_int</code> that holds a member of type <code>list_head</code> and an integer value <code>value</code>. The next and previous pointers are brought into this struct through <code>list_head list</code> and could be referred to as <code>list.next</code> and <code>list.prev</code>.</p>
<blockquote>
<p>There is a very genuine reason for picking such weird names for a linked list node and members of structures; the reason to do so will be cleared in the later sections of this essay.</p>
</blockquote>
<p>Because of the above structure definition, building a linked list node holding of any type becomes a breeze. For example, a node holding string could be quickly defined as a struct <code>list_str</code> having <code>list_head</code> and a <code>char *</code>. This ability to extend <code>list_head</code> and build a node holding data of any type and any specifics make low-level code simple, uniform, and extensible.</p>
<h2>Memory Representation of <code>list_int</code></h2>
<p>Structures in C are not padded and they do not even hold any meta information, not even for the member names; hence during allocation, they are allocated the space just enough to hold the actual data.</p>
<p><img src="https://user-images.githubusercontent.com/4745789/83953834-694a6a00-a861-11ea-8ff7-fa69af6af7d6.png" alt="https://user-images.githubusercontent.com/4745789/83953834-694a6a00-a861-11ea-8ff7-fa69af6af7d6.png"></p>
<p>In the illustration above we see how members of <code>list_int</code> are mapped on the allocated space - required by its individual members. It is allocated a contiguous space of 12 bytes - 4 bytes for each of the two pointers and another 4 bytes for the integer value. The contiguity of space allocation and order of members during allocation could be verified by printing out their addresses as shown below.</p>
<pre><code><span><span>void</span> <span>print_addrs</span><span>()</span> </span>{
    
    <span><span>struct</span> <span>list_int</span> *<span>ll</span> = <span>new_list_int</span>(41434);</span>

    
    <span>printf</span>(<span>"%p: head\n"</span>,             head);
    <span>printf</span>(<span>"%p: head-&gt;list.next\n"</span>,  &amp;((head-&gt;<span>list</span>).next));
    <span>printf</span>(<span>"%p: head-&gt;list.prev\n"</span>,  &amp;((head-&gt;<span>list</span>).prev));
    <span>printf</span>(<span>"%p: head-&gt;value\n"</span>,      &amp;(head-&gt;value));
}

~ $ make &amp;&amp; ./a.out
<span>0x4058f0</span>: head
<span>0x4058f0</span>: head-&gt;<span>list</span>.next
<span>0x4058f4</span>: head-&gt;<span>list</span>.prev
<span>0x4058f8</span>: head-&gt;value
</code></pre>
<p>We clearly see all the 3 members, occupying 12 bytes contiguous memory segments in order of their definition within the struct.</p>
<blockquote>
<p>The above code was executed on a machine where the size of integer and pointers were 4 bytes each. The results might differ depending on the machine and CPU architecture.</p>
</blockquote>
<h2>Casting pointers pointing to struct</h2>
<p>In C language, when a pointer to a struct is cast to a pointer to another struct, the engine maps the individual members of a target struct type, depending on their order and offsets, on to the slice of memory of the source struct instance.</p>
<p>When we cast <code>list_int *</code> into <code>list_head *</code>, the engine maps the space required by target type i.e. <code>list_head</code> on space occupied by <code>list_int</code>. This means it maps the 8 bytes required by <code>list_head</code> on the first 8 bytes occupied by <code>list_int</code> instance. Going by the memory representation discussed above, we find that the first 8 bytes of <code>list_int</code> are in fact <code>list_head</code>, and hence casting <code>list_int *</code> to <code>list_head *</code> is effectively just referencing the <code>list_head</code> member of <code>list_int</code> through a new variable.</p>
<p><img src="https://user-images.githubusercontent.com/4745789/83943610-2e254800-a81b-11ea-8b25-056e1b1df85e.png" alt="https://user-images.githubusercontent.com/4745789/83943610-2e254800-a81b-11ea-8b25-056e1b1df85e.png"></p>
<p>This effectively builds a parent-child relationship between the two structs where we can safely typecast a child <code>list_int</code> to its parent <code>list_head</code>.</p>
<blockquote>
<p>It is important to note here that the parent-child relationship is established only because the first member of <code>list_int</code> is of type <code>list_head</code>. it would not have worked if we change the order of members in <code>list_int</code>.</p>
</blockquote>

<p>As established above, by putting one struct within another as its first element we are effectively creating a parent-child relationship between the two. Since this gives us an ability to safely typecast child to its parent we can define functions that accept a pointer to parent struct as an argument and perform operations that do not really require to deal with specifics. This allows us to <strong>NOT</strong> rewrite the functional logic for every child extensions and thus avoid redundant code.</p>
<p>From the context we have set up, say we want to write a function that adds a node between the two in a linked list. The core logic to perform this operation does not really need to deal with any specifics all it takes is a few pointer manipulations of <code>next</code> and <code>prev</code>. Hence, we could just define the function accepting arguments of type <code>list_head *</code>  and write the function as</p>
<pre><code>
<span>static</span> <span>void</span> __list_add(struct list_head *<span>new</span>,
                       struct list_head *prev,
                       struct list_head *next)
{
    next-&gt;prev = <span>new</span>;
    <span>new</span>-&gt;next = next;
    <span>new</span>-&gt;prev = prev;
    prev-&gt;next = <span>new</span>;
}
</code></pre>
<p>Since we can safely typecase <code>list_int *</code> and <code>list_str *</code> to <code>list_head *</code> we can pass any of the specific implementations the function <code>__list_add</code> and it would still add the node between the other two seamlessly.</p>
<p>Since the core operations on linked lists only require pointer manipulations, we can define these operations as functions accepting <code>list_head *</code> instead of specific types like <code>list_int *</code>.  Thus we need not write similar functions for specifics. A function to delete a node could be written as</p>
<pre><code>
<span>static</span> <span>inline</span> <span>void</span> __list_del(struct list_head * prev, struct list_head * next)
{
    next-&gt;prev = prev;
    prev-&gt;next = next;
}
</code></pre>
<p>Other linked list utilities like <em>adding a node to tail</em>, <em>swapping nodes</em>, <em>splicing the list</em>, <em>rotating the list</em>, etc only require manipulations of <code>next</code> and <code>prev</code> pointers. Hence they could also be written in a very similar way i.e accepting <code>list_head *</code> and thus eliminating the need to reimplement function logic for every single child implementation.</p>
<p>This behavior is very similar to how inheritance in modern OOP languages, like Python and Java, work where the child is allowed to invoke any parent function.</p>

<p>There are a ton of practical usage of using Structure Compositions but the most famous ones are</p>
<h2>Linux Kernel</h2>
<p>In order to keep things abstract and extensible, Linux Kernel uses Structure Composition at several places. One of the most important places where it uses composition is for managing and maintaining Linked Lists, exactly how we saw things above. The struct definitions and code snippets are taken as-is from the <a href="https://elixir.bootlin.com/linux/latest/source/include/linux/list.h">Kernel's source code</a>, and hence the structure and variable names look different than usual.</p>
<h2>Python Type and Object Hierarchy</h2>
<p>Python, one of the most important languages in today's world, uses Structure Composition to build Type Hierarchy. Python defines a root structure called <code>PyObject</code> which holds reference count, defining the number of places from which the object is referenced - and object type - determining the type of the object i.e. <code>int</code>, <code>str</code>, <code>list</code>, <code>dict</code>, etc.</p>
<pre><code><span>typedef</span> <span><span>struct</span> _<span>object</span> {</span>
    Py_ssize_t     ob_refcnt;  
    PyTypeObject   *ob_type;   
} PyObject;
</code></pre>
<p>Since Python wants these fields to be present in every single object that is created during runtime, it uses structure composition to ensure that objects like integers, floats, string, etc put <code>PyObject</code> as their first element and thus establishing a parent-child relationship. A Float object in Python is defined as</p>
<pre><code><span>#<span>define</span> PyObject_HEAD PyObject ob_base;</span>

<span>typedef</span> <span><span>struct</span> {</span>
    PyObject_HEAD
    <span>double</span> ob_fval;    
} PyFloatObject;
</code></pre>
<p>Now writing utility functions that increments and decrements references count on every access of any object could be written as just a single function accepting <code>PyObject *</code> as shown below</p>
<pre><code><span>static</span> <span>inline</span> <span>void</span> _Py_INCREF(PyObject *op) {
    op-&gt;ob_refcnt++;
}
</code></pre>
<p>Thus we eradicate a need of rewriting <code>INCREF</code> for every single object type and just write it once for <code>PyObject</code> and it will work for every single Python object type that is extended through <code>PyObject</code>.</p>

<ul>
<li><a href="https://elixir.bootlin.com/linux/latest/source/include/linux/list.h">LinkedList in Linux Source Code</a></li>
<li><a href="https://docs.python.org/3/c-api/structures.html#c.PyObject">PyObject - Python Internals Documentation</a></li>
<li><a href="https://docs.python.org/3/c-api/float.html">PyFloatObject - Python Internals Documentation</a></li>
</ul>
</div></div><section><div><div><p><img src="https://arpitbhayani.me/static/img/arpit.jpg"></p>  <h2>
              500+ Signups
            </h2> <p>
              If you like what you read subscribe you can always subscribe to
              my newsletter and get the post delivered straight to your inbox.
              I write
              <a href="https://arpitbhayani.me/blogs">essays</a> on various
              engineering topics and share it through my weekly
              <a href="https://arpitbhayani.me/newsletter">newsletter</a> 👇
            </p> <br> </div></div></section></div>]]>
            </description>
            <link>https://arpitbhayani.me/blogs/inheritance-c</link>
            <guid isPermaLink="false">hacker-news-small-sites-23888677</guid>
            <pubDate>Sun, 19 Jul 2020 11:48:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Pipeline Design Patterns for Continuous Delivery]]>
            </title>
            <description>
<![CDATA[
Score 8 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23888341">thread link</a>) | @kiyanwang
<br/>
July 19, 2020 | https://www.singlestoneconsulting.com/blog/7-pipeline-design-patterns-for-continuous-delivery/ | <a href="https://web.archive.org/web/*/https://www.singlestoneconsulting.com/blog/7-pipeline-design-patterns-for-continuous-delivery/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-601"><div><p>Business agility is built on code agility. For modern digital products and services, the ability to release on demand quickly and safely is a real competitive business advantage.</p><p>Since 2004 we have designed, built, and deployed code pipelines to automate applications and infrastructure. We’re sharing seven pipeline design patterns that we’ve learned improve speed, agility, and quality while increasing autonomy, transparency, and maintainability.</p><h2><strong>Continuous Delivery</strong><strong> </strong></h2><p><a href="https://continuousdelivery.com/" target="_blank" rel="noreferrer noopener">Continuous Delivery</a> is “the ability to get changes of all types into the hands of users, safely and quickly in a sustainable way.” If you think about Continuous Delivery on an Agile vs. Effort matrix, it falls squarely between Continuous Integration and Continuous Deployment. Often these are collectively referred to as CI/CD.</p><div><figure><img src="https://www.singlestoneconsulting.com/wp-content/uploads/2020/07/Screen-Shot-2020-07-01-at-12.32.09-PM-1300x763.png" alt="What is continuous delivery" width="632" height="370" data-src="https://www.singlestoneconsulting.com/wp-content/uploads/2020/07/Screen-Shot-2020-07-01-at-12.32.09-PM-1300x763.png" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></figure></div><p>In the <a href="https://services.google.com/fh/files/misc/state-of-devops-2019.pdf" target="_blank" aria-label="undefined (opens in a new tab)" rel="noreferrer noopener">2019 State of the DevOps Report</a>, over 31,000 respondents reported the effectiveness of their development and delivery processes. The results between the elite and low performers is staggering. The elite performs had 200x more deployments and 100x faster speed to deployment <strong><em>while also</em></strong> being 2,600x faster to recover from incidents and 7x less likely to roll back releases.</p><p>This research shows that for elite performing organizations, speed and stability are not opposites! You can have both – in fact you need both – to gain real competitive advantages for your digital products and services.</p><h2><strong>Code Pipelines</strong></h2><p>Code pipelines are the primary technical artifacts of continuous delivery. Modern-day pipelines transform application and infrastructure source code into versioned packages deployable to any environment. By automating all the mundane tasks to build and deploy systems, teams are free to focus on value-added capabilities.</p><div><figure><img src="https://www.singlestoneconsulting.com/wp-content/uploads/2020/07/Screen-Shot-2020-07-01-at-12.31.55-PM-1300x627.png" alt="" width="653" height="316" srcset="https://www.singlestoneconsulting.com/wp-content/uploads/2020/07/Screen-Shot-2020-07-01-at-12.31.55-PM-1300x627.png 1300w, https://www.singlestoneconsulting.com/wp-content/uploads/2020/07/Screen-Shot-2020-07-01-at-12.31.55-PM-660x318.png 660w, https://www.singlestoneconsulting.com/wp-content/uploads/2020/07/Screen-Shot-2020-07-01-at-12.31.55-PM-768x371.png 768w, https://www.singlestoneconsulting.com/wp-content/uploads/2020/07/Screen-Shot-2020-07-01-at-12.31.55-PM-1536x741.png 1536w, https://www.singlestoneconsulting.com/wp-content/uploads/2020/07/Screen-Shot-2020-07-01-at-12.31.55-PM.png 1886w" sizes="(max-width: 653px) 100vw, 653px" data-srcset="https://www.singlestoneconsulting.com/wp-content/uploads/2020/07/Screen-Shot-2020-07-01-at-12.31.55-PM-1300x627.png 1300w, https://www.singlestoneconsulting.com/wp-content/uploads/2020/07/Screen-Shot-2020-07-01-at-12.31.55-PM-660x318.png 660w, https://www.singlestoneconsulting.com/wp-content/uploads/2020/07/Screen-Shot-2020-07-01-at-12.31.55-PM-768x371.png 768w, https://www.singlestoneconsulting.com/wp-content/uploads/2020/07/Screen-Shot-2020-07-01-at-12.31.55-PM-1536x741.png 1536w, https://www.singlestoneconsulting.com/wp-content/uploads/2020/07/Screen-Shot-2020-07-01-at-12.31.55-PM.png 1886w" data-src="https://www.singlestoneconsulting.com/wp-content/uploads/2020/07/Screen-Shot-2020-07-01-at-12.31.55-PM-1300x627.png" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></figure></div><p>While code pipelines have been around for nearly 20 years – <a href="https://en.wikipedia.org/wiki/CruiseControl" target="_blank" rel="noreferrer noopener">CruiseControl</a>, one of our early favorites, was first released in 2001 – they have evolved quite significantly over the years and really come into their own in the last few years.</p><p>Based on our work and observations from our customers, we have identified 7 pipeline design patterns that we see in many modern tech organizations.</p><h2><strong>Pipeline Design Patterns</strong></h2><h3>Pipeline Design Pattern #1: Pipelines as Code</h3><p><em>Pipeline logic is codified, stored alongside application or infrastructure code</em><em> and utilizes containerized runners. </em></p><p>State of the Art:</p><div><figure><img src="https://www.singlestoneconsulting.com/wp-content/uploads/2020/07/Screen-Shot-2020-07-01-at-12.46.04-PM.png" alt="Pipelines as code" width="256" height="349" data-src="https://www.singlestoneconsulting.com/wp-content/uploads/2020/07/Screen-Shot-2020-07-01-at-12.46.04-PM.png" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></figure></div><ul><li>No GUI setup steps! Pipeline logic is managed like any other application code and subject to the same branching strategies and review processes.</li><li>Pipeline execution on containers allows your CI/CD platform to support many different workloads, while each workload can have its own build environment to meet its unique needs.</li><li>Container image provenance uses trusted Docker images for build environments.</li><li>CI runner configuration is automated, identical, and hands-free. CI runners can scale to meet demand and can be on standby during core hours to minimize delays.</li><li>Secrets are stored outside of the pipeline and their output is masked, leading to higher security.</li></ul><h3>Pipeline Design Pattern #2: Externalize Logic into Reusable Libraries</h3><p><em>Reusable libraries contain common pipeline logic</em><em> that is</em><em> referenc</em><em>e</em><em>able from pipeline code and </em><em>independently developed and tested.</em></p><div><figure><img src="https://www.singlestoneconsulting.com/wp-content/uploads/2020/07/Screen-Shot-2020-07-01-at-12.46.15-PM.png" alt="Externalize Logic into Reusable Libraries" width="242" height="369" srcset="https://www.singlestoneconsulting.com/wp-content/uploads/2020/07/Screen-Shot-2020-07-01-at-12.46.15-PM.png 822w, https://www.singlestoneconsulting.com/wp-content/uploads/2020/07/Screen-Shot-2020-07-01-at-12.46.15-PM-432x660.png 432w, https://www.singlestoneconsulting.com/wp-content/uploads/2020/07/Screen-Shot-2020-07-01-at-12.46.15-PM-768x1173.png 768w" sizes="(max-width: 242px) 100vw, 242px" data-srcset="https://www.singlestoneconsulting.com/wp-content/uploads/2020/07/Screen-Shot-2020-07-01-at-12.46.15-PM.png 822w, https://www.singlestoneconsulting.com/wp-content/uploads/2020/07/Screen-Shot-2020-07-01-at-12.46.15-PM-432x660.png 432w, https://www.singlestoneconsulting.com/wp-content/uploads/2020/07/Screen-Shot-2020-07-01-at-12.46.15-PM-768x1173.png 768w" data-src="https://www.singlestoneconsulting.com/wp-content/uploads/2020/07/Screen-Shot-2020-07-01-at-12.46.15-PM.png" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></figure></div><p>State of the Art:</p><ul><li>Treat pipeline libraries as any other releasable software. They have their own repos, pipelines, and are unit tested with good release notes.</li><li>Pipelines call external tasks whenever possible using language-specific tools like Make, Rake, npm, Maven or others to simplify the pipeline and keeps the local and CI workflow identical.</li><li>Libraries are discoverable and have good documentation.</li></ul><h3>Pipeline Design Pattern #3: Separate Build and Deploy Pipelines</h3><p><em>Build and deploy pipelines should be logically separate</em><em>d</em><em>, </em><em>independently runnable</em><em> and triggered by </em><em>automated or manual events</em></p><div><figure><img src="https://www.singlestoneconsulting.com/wp-content/uploads/2020/07/Screen-Shot-2020-07-01-at-12.46.31-PM.png" alt="Separate Build and Deploy Pipelines " width="316" height="313" srcset="https://www.singlestoneconsulting.com/wp-content/uploads/2020/07/Screen-Shot-2020-07-01-at-12.46.31-PM.png 1128w, https://www.singlestoneconsulting.com/wp-content/uploads/2020/07/Screen-Shot-2020-07-01-at-12.46.31-PM-660x653.png 660w, https://www.singlestoneconsulting.com/wp-content/uploads/2020/07/Screen-Shot-2020-07-01-at-12.46.31-PM-768x760.png 768w" sizes="(max-width: 316px) 100vw, 316px" data-srcset="https://www.singlestoneconsulting.com/wp-content/uploads/2020/07/Screen-Shot-2020-07-01-at-12.46.31-PM.png 1128w, https://www.singlestoneconsulting.com/wp-content/uploads/2020/07/Screen-Shot-2020-07-01-at-12.46.31-PM-660x653.png 660w, https://www.singlestoneconsulting.com/wp-content/uploads/2020/07/Screen-Shot-2020-07-01-at-12.46.31-PM-768x760.png 768w" data-src="https://www.singlestoneconsulting.com/wp-content/uploads/2020/07/Screen-Shot-2020-07-01-at-12.46.31-PM.png" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></figure></div><p>State of the Art:</p><ul><li>Build once, deploy many. Focus on the first build. It becomes an artifact that you can deploy many times.</li><li>Be environmentally agnostic. Without an environment-specific packages, and externalized environment-specific properties, the same build can run in any environment.</li><li>Package it all together. Everything – All source, including infrastructure code, should be combined, becoming a versioned package.</li></ul><h3>Pipeline Design Pattern #4: Trigger the Right Pipeline</h3><p><em>B</em><em>ranch</em><em> commits</em><em>, pull requests, and merges to the mainline can</em><em> all trigger different pipeline behavior, </em><em>optimized to</em><em> the team’s way of working.</em></p><div><figure><img src="https://www.singlestoneconsulting.com/wp-content/uploads/2020/07/Screen-Shot-2020-07-01-at-12.46.45-PM.png" alt="Trigger the Right Pipeline" width="351" height="262" srcset="https://www.singlestoneconsulting.com/wp-content/uploads/2020/07/Screen-Shot-2020-07-01-at-12.46.45-PM.png 1134w, https://www.singlestoneconsulting.com/wp-content/uploads/2020/07/Screen-Shot-2020-07-01-at-12.46.45-PM-660x492.png 660w, https://www.singlestoneconsulting.com/wp-content/uploads/2020/07/Screen-Shot-2020-07-01-at-12.46.45-PM-768x573.png 768w" sizes="(max-width: 351px) 100vw, 351px" data-srcset="https://www.singlestoneconsulting.com/wp-content/uploads/2020/07/Screen-Shot-2020-07-01-at-12.46.45-PM.png 1134w, https://www.singlestoneconsulting.com/wp-content/uploads/2020/07/Screen-Shot-2020-07-01-at-12.46.45-PM-660x492.png 660w, https://www.singlestoneconsulting.com/wp-content/uploads/2020/07/Screen-Shot-2020-07-01-at-12.46.45-PM-768x573.png 768w" data-src="https://www.singlestoneconsulting.com/wp-content/uploads/2020/07/Screen-Shot-2020-07-01-at-12.46.45-PM.png" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></figure></div><p>State of the Art:</p><ul><li>Pushing a commit to an open pull request builds an Ephemeral Environment for testing.</li><li>Merges to the mainline are deployed to a non-production or demo environment displaying the latest integrated code</li><li>Pushing a new tag stages a production release.</li></ul><h3>Pipeline Design Pattern #5: Fast Team Feedback</h3><p><em>Every commit </em><em>automatically</em><em> triggers the right pipeline</em><em>, with build pipelines </em><em>especially </em><em>optimized for speed and quick </em><em>reporting</em><em> of any issues. </em></p><div><figure><img src="https://www.singlestoneconsulting.com/wp-content/uploads/2020/07/Screen-Shot-2020-07-01-at-12.47.38-PM.png" alt="Fast Team Feedback" width="350" height="350" srcset="https://www.singlestoneconsulting.com/wp-content/uploads/2020/07/Screen-Shot-2020-07-01-at-12.47.38-PM.png 1146w, https://www.singlestoneconsulting.com/wp-content/uploads/2020/07/Screen-Shot-2020-07-01-at-12.47.38-PM-660x660.png 660w, https://www.singlestoneconsulting.com/wp-content/uploads/2020/07/Screen-Shot-2020-07-01-at-12.47.38-PM-768x769.png 768w" sizes="(max-width: 350px) 100vw, 350px" data-srcset="https://www.singlestoneconsulting.com/wp-content/uploads/2020/07/Screen-Shot-2020-07-01-at-12.47.38-PM.png 1146w, https://www.singlestoneconsulting.com/wp-content/uploads/2020/07/Screen-Shot-2020-07-01-at-12.47.38-PM-660x660.png 660w, https://www.singlestoneconsulting.com/wp-content/uploads/2020/07/Screen-Shot-2020-07-01-at-12.47.38-PM-768x769.png 768w" data-src="https://www.singlestoneconsulting.com/wp-content/uploads/2020/07/Screen-Shot-2020-07-01-at-12.47.38-PM.png" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></figure></div><p>State of the Art:</p><ul><li>Build pipelines use parallelization for non-interdependent jobs to increase speed.</li><li>Fast build pipelines only run the jobs that are necessary in a few minutes.</li><li>Each successful run produces a versioned package and static analysis results.</li><li>With omni-channel notifications, you can enable team notifications on pull request status in dashboards, chat channels, email, and other mediums.</li></ul><h3>Pipeline Design Pattern #6: Stable Internal Releases</h3><p><em>Only versioned </em><em>packages </em><em>produced</em><em> by the build pipeline are deployed</em><em> and these deployments are triggered by humans or automated events.</em></p><div><figure><img src="https://www.singlestoneconsulting.com/wp-content/uploads/2020/07/Screen-Shot-2020-07-01-at-12.45.11-PM.png" alt="Stable Internal Releases" width="320" height="250" srcset="https://www.singlestoneconsulting.com/wp-content/uploads/2020/07/Screen-Shot-2020-07-01-at-12.45.11-PM.png 940w, https://www.singlestoneconsulting.com/wp-content/uploads/2020/07/Screen-Shot-2020-07-01-at-12.45.11-PM-660x514.png 660w, https://www.singlestoneconsulting.com/wp-content/uploads/2020/07/Screen-Shot-2020-07-01-at-12.45.11-PM-768x598.png 768w" sizes="(max-width: 320px) 100vw, 320px" data-srcset="https://www.singlestoneconsulting.com/wp-content/uploads/2020/07/Screen-Shot-2020-07-01-at-12.45.11-PM.png 940w, https://www.singlestoneconsulting.com/wp-content/uploads/2020/07/Screen-Shot-2020-07-01-at-12.45.11-PM-660x514.png 660w, https://www.singlestoneconsulting.com/wp-content/uploads/2020/07/Screen-Shot-2020-07-01-at-12.45.11-PM-768x598.png 768w" data-src="https://www.singlestoneconsulting.com/wp-content/uploads/2020/07/Screen-Shot-2020-07-01-at-12.45.11-PM.png" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></figure></div><p>State of the Art:</p><ul><li>Each code branch gets a complete ephemeral environment named for the branch that can easily be created or destroyed.</li><li>Each engineer can stand up and delete ephemeral environments at any time.</li><li>CI runners use cloud-native IAM capabilities with temporary permissions so they can assume roles and acquire the right permissions to complete their work.</li></ul><h3>Pipeline Design Pattern #7: Buttoned Up Product Releases</h3><p><em>Deploy tagged releases to production and automate the paperwork</em><em> but leave a paper trail. </em></p><p>State of the Art:</p><ul><li>Codified release gates and standardized release processes enables teams to release on demand.</li><li>Automated releases leave a transparent paper trail that’s auditable for governance and quality</li><li>Release gates can invoke external API’s and use the responses to decide whether to proceed with the release or halt.</li></ul><figure><img src="https://www.singlestoneconsulting.com/wp-content/uploads/2020/07/Screen-Shot-2020-07-01-at-12.44.56-PM-1300x254.png" alt="Buttoned Up Product Releases" srcset="https://www.singlestoneconsulting.com/wp-content/uploads/2020/07/Screen-Shot-2020-07-01-at-12.44.56-PM-1300x254.png 1300w, https://www.singlestoneconsulting.com/wp-content/uploads/2020/07/Screen-Shot-2020-07-01-at-12.44.56-PM-660x129.png 660w, https://www.singlestoneconsulting.com/wp-content/uploads/2020/07/Screen-Shot-2020-07-01-at-12.44.56-PM-768x150.png 768w, https://www.singlestoneconsulting.com/wp-content/uploads/2020/07/Screen-Shot-2020-07-01-at-12.44.56-PM-1536x300.png 1536w, https://www.singlestoneconsulting.com/wp-content/uploads/2020/07/Screen-Shot-2020-07-01-at-12.44.56-PM.png 1814w" sizes="(max-width: 1300px) 100vw, 1300px" data-srcset="https://www.singlestoneconsulting.com/wp-content/uploads/2020/07/Screen-Shot-2020-07-01-at-12.44.56-PM-1300x254.png 1300w, https://www.singlestoneconsulting.com/wp-content/uploads/2020/07/Screen-Shot-2020-07-01-at-12.44.56-PM-660x129.png 660w, https://www.singlestoneconsulting.com/wp-content/uploads/2020/07/Screen-Shot-2020-07-01-at-12.44.56-PM-768x150.png 768w, https://www.singlestoneconsulting.com/wp-content/uploads/2020/07/Screen-Shot-2020-07-01-at-12.44.56-PM-1536x300.png 1536w, https://www.singlestoneconsulting.com/wp-content/uploads/2020/07/Screen-Shot-2020-07-01-at-12.44.56-PM.png 1814w" data-src="https://www.singlestoneconsulting.com/wp-content/uploads/2020/07/Screen-Shot-2020-07-01-at-12.44.56-PM-1300x254.png" data-old-src="data:image/gif;base64,R0lGODlhAQABAAAAACH5BAEKAAEALAAAAAABAAEAAAICTAEAOw=="></figure><h2><strong>Challenges</strong></h2><p>These are the seven pipeline design patterns we’re increasingly seeing and using in our client engagements. While these present huge leaps forward in terms of speed and stability, code pipelines are not without their challenges.</p><p>Security is the biggest challenge we see, due to the complexity that comes with automating what has traditionally been human-centric processes. Pipeline complexity, team adoption, modernizing the change-advisory-board-centric culture, and automating databases are the other big challenges to work through. But it’s possible, we do this every day.</p><h2><strong>Summary</strong></h2><p>Business agility is built on code agility. For modern digital products and services, the ability to release on demand quickly and safely is a real competitive business advantage. Code pipelines, and these seven design patterns in particular, can help your organization make giant leaps forward in speed and stability and have your teams performing at the elite level.</p><p><a href="https://www.singlestoneconsulting.com/careers/" target="_blank" rel="noreferrer noopener">We’re hiring</a>! Come join our team.</p></div></article><p>Get notified when more posts like “<span>7 Pipeline Design Patterns for Continuous Delivery</span>” are available.</p></div>]]>
            </description>
            <link>https://www.singlestoneconsulting.com/blog/7-pipeline-design-patterns-for-continuous-delivery/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23888341</guid>
            <pubDate>Sun, 19 Jul 2020 10:18:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Gradually Exit Twitter]]>
            </title>
            <description>
<![CDATA[
Score 64 | Comments 56 (<a href="https://news.ycombinator.com/item?id=23888215">thread link</a>) | @saadalem
<br/>
July 19, 2020 | https://balajis.com/how-to-gradually-exit-twitter/ | <a href="https://web.archive.org/web/*/https://balajis.com/how-to-gradually-exit-twitter/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            


                <figure>
                    <img srcset="https://balajis.com/content/images/size/w300/2020/07/gradually-exit-twitter.png 300w,
                                https://balajis.com/content/images/size/w600/2020/07/gradually-exit-twitter.png 600w,
                                https://balajis.com/content/images/size/w1200/2020/07/gradually-exit-twitter.png 1000w,
                                https://balajis.com/content/images/size/w2000/2020/07/gradually-exit-twitter.png 2000w" sizes="(max-width: 800px) 400px,
                            (max-width: 1170px) 1170px,
                                2000px" src="https://balajis.com/content/images/size/w2000/2020/07/gradually-exit-twitter.png" alt="How to Gradually Exit Twitter">
                </figure>
                <section>
                    <div>
                        <p>The <a href="https://twitter.com/TwitterSupport/status/1283591848729219073">hacks</a> are the last straw. We need to exit Twitter.</p><p>But you may be invested in Twitter! So what do you do? Here's one recipe for <em>gradual</em> exit.</p><ol><li>Step one is to set up an (optionally pseudonymous) newsletter at your <em>own</em> custom domain using the instructions <a href="https://balajis.com/set-up-a-paid-newsletter-at-your-own-domain/">here</a>. You can do this in an hour and maintain it for less than $30 per month. Then only tweet out posts from your site, using your domain name as a simple form of authentication.</li><li>Step two is to start building your membership list at your own site. If you want, help us review <a href="https://github.com/balajis/twitter-export">open source tools</a> to export your Twitter following to an email list and <a href="https://twitter.com/dwr/status/1284155565770498050">mass delete any DMs</a>.</li><li>And step three is to get off Twitter all together, and start building a decentralized media ecosystem that combines the sovereignty of individual domain names with the community of social networking. The v1 of that is a simple joint RSS feed that aggregates multiple independent newsletters, but we can get much more <a href="https://twitter.com/balajis/status/1280005821028397057">sophisticated</a> <a href="https://dci.mit.edu/decentralizedweb">with</a> <a href="https://hackernoon.com/a-state-of-the-art-of-decentralized-web-part-4-212732f74894">tech</a> <a href="https://gun.eco/docs/dWeb-The-Decentralized-Web">for</a> <a href="https://ens.domains/">the</a> <a href="https://handshake.org/">decentralized</a> <a href="https://ipfs.io/">web</a>. It may turn out that what we build helps reform Twitter itself, but at a minimum it will present an alternative.</li></ol><p>Before we get there though, let's go through the problems with Twitter.</p><h2 id="the-problems-with-twitter">The Problems with Twitter</h2><p>It's not just the hack. There are several overlapping issues with Twitter around security, authentication, pseudonymity, distribution, incentives, and culture.</p><ul><li><em>Twitter is insecure</em>. It was a mistake to think that personal security could compensate for the fundamental flaw of centralized web services: anyone who gains control over twitter.com gains control over your account. We knew this already from the <a href="http://archive.is/Bq5qi">2017 incident</a> and the <a href="http://archive.is/wip/scJMn">Jack Hack</a>. But now the most prominent people and companies in the world (Bezos, Gates, Zuckerberg, Musk, Apple, Uber, among others) have been <a href="https://twitter.com/TwitterSupport/status/1283591848729219073">openly and publicly hacked</a>. Tomorrow you may be the victim. And unlike these worthies, you may be <em>silently</em> and <em>privately</em> hacked. Perhaps you already have been.</li><li><em>Twitter is not authenticated</em>. It was a mistake to trust Twitter's centralized verification process to validate everything posted to the service. There weren't any <a href="https://www.investopedia.com/terms/p/private-key.asp#:~:text=A%20digital%20wallet%20stores%20the,to%20use%20the%20private%20key.">digital signatures</a> to help establish whether the messages were really coming from a user-controlled device, or faked by a central server.</li><li><em>Twitter is not fully pseudonymous</em>. It was a mistake to use our real names everywhere online, particularly on Twitter. It made us vulnerable to personal and physical attacks. Social media mobs can swarm your real name online and cancel you in real life. Doxxing can heighten the danger by making threats <a href="https://blog.lopp.net/reflections-upon-a-swatting/">materialize in</a> <a href="https://github.com/jlopp/physical-bitcoin-attacks/blob/master/README.md">meatspace</a>. Pseudonymity is a better default, especially now that we can <a href="http://www.marknagelberg.com/notes-on-the-pseudonymous-economy-balaji-srinivasan/">earn under a pseudonym</a>.</li><li><em>Twitter is a distribution chokepoint</em>. It was a mistake to outsource our distribution to Twitter. Twitter users don't fully control their reach, brand, or monetization. You can be <a href="https://www.searchenginejournal.com/twitter-reveals-how-it-ranks-tweets-in-search-results/263869/">downranked</a> or <a href="http://archive.is/mhgyB">deplatformed</a> at any time, just like you can on YouTube and other centralized platforms. Owning your <a href="https://support.substack.com/hc/en-us/articles/360037465992-How-do-I-export-my-email-or-subscriber-list-">own</a> <a href="http://locals.com/">email</a> <a href="https://ghost.org/members">list</a> is a far better alternative.</li><li><em>Twitter doesn't create wealth</em>. It was a mistake to have so many people spending so much time on something that <a href="https://twitter.com/paulg/status/1271834488998440961">arguably</a> destroys more wealth than it creates. Because by default, you don't create wealth on Twitter. You may create wealth <em>for</em> Twitter, or for the media corporations whose links are circulated, but not for yourself or for others. There's no sense of economic alignment with other users, no sense of mutual obligation.</li><li><em>Twitter turns society into Twitter</em>. It was a mistake to let Twitter set up the incentives for our society. It's not good for the world when the one thing every prominent person knows how to do is <a href="https://twitter.com/balajis/status/1272653587617701888">fight</a> each other on Twitter for likes and followers. It has converted society into a zero-sum status game played by elites with real consequences. Every day, blue checks compete for a finite pie of attention with ever more sensational posts. There is instant feedback on what is popular, but none on what is true. The lack of economics, the presence of real names, the toxic culture, and the UX itself all encourage constant fighting.</li></ul><p>Now, let me qualify these comments. I personally have gotten <a href="https://twitter.com/paulg/status/1271834488998440961">enormous value</a> out of Twitter, despite all the points above. After all, you only critique the services you use!</p><p>And to be clear, Jack Dorsey is a phenomenal entrepreneur. I respect everything he's done and the team that he's built. It's hard to build one multibillion dollar company, let alone <a href="http://archive.is/wip/bu6hJ">two</a>. He's done immense good for the world overall, both through his <a href="https://twitter.com/jack/status/1247616214769086465">personal generosity</a> and his startup vehicles. And I also don't wish any Twitter employee ill, as many of them are truly great people and I know how hard this stuff is.</p><p>Moreover, even after this hack, Twitter will likely continue to be an important internet battlefield for quite sometime. It's just too easy, too convenient. And it may turn out that whatever is built to exit Twitter will end up interfacing with Twitter itself, via their <a href="https://twitter.com/bluesky">decentralized protocol</a>, if only as a form of training wheels to help people get off. Hopefully this can be done in a win-win way, such that Twitter and its employees are incentivized to allow people to gradually exit and fix the issues on the centralized service.</p><p>But it's past time for us to start building something better, that keeps the good aspects of Twitter (the serendipitous learning, the fascinating <a href="https://twitter.com/balajis/status/1214585024772788224">people</a>) but filters the bad. That may mean exiting to our own domains and then networking them into decentralized media.</p><h2 id="decentralization-starts-with-a-domain">Decentralization Starts with a Domain</h2><figure><img src="https://balajis.com/content/images/2020/07/how-to-gradually-exit-twitter--1-.png" alt="" srcset="https://balajis.com/content/images/size/w600/2020/07/how-to-gradually-exit-twitter--1-.png 600w, https://balajis.com/content/images/size/w1000/2020/07/how-to-gradually-exit-twitter--1-.png 1000w, https://balajis.com/content/images/size/w1600/2020/07/how-to-gradually-exit-twitter--1-.png 1600w, https://balajis.com/content/images/2020/07/how-to-gradually-exit-twitter--1-.png 2000w" sizes="(min-width: 720px) 720px"><figcaption>Can we network together websites into decentralized media with something deeper than links?</figcaption></figure><p>I may be wrong about this, but I don't think a "better Twitter" starts with a service which is simply a clone of Twitter except with a different community. I think it starts with a community of independent (and independently monetizable) domains that we network together in novel ways, to build <em>decentralized media</em>.</p><p>Towards this end, the first step in gradually exiting Twitter is to set up your own paid newsletter at a custom domain (<a href="https://balajis.com/set-up-a-paid-newsletter-at-your-own-domain/">instructions here</a>) and restrict yourself mainly to tweeting out posts. This does require more effort than writing 280 characters! But that's why it's good. Effort helps restore your attention span and improves average post quality. And in addition to the other benefits, the link to your domain doubles as a simple alternative to a <a href="https://www.investopedia.com/terms/p/private-key.asp#:~:text=A%20digital%20wallet%20stores%20the,to%20use%20the%20private%20key.">digital signature</a>, a way for people to see that the content is authentically yours. </p><p>The medium-term step is to develop <a href="https://github.com/balajis/twitter-export">tools</a> to migrate your followers off Twitter to an email list, and to mass delete all DMs as a precautionary step. If you want to help review some existing tools towards this end, we're working on it <a href="https://github.com/balajis/twitter-export/issues/1">here</a>.</p><p>The long-term step is to start addressing the issues with Twitter by knitting these individual domains together into an open source decentralized media ecosystem. That means addressing:</p><ul><li>Security by encouraging people to post from their own domains</li><li>Community by building a network around multiple domains</li><li>Authentication by combining domains with digital signatures</li><li>Distribution via memberships and email lists</li><li>Incentives by baking in monetization and economic alignment from the beginning</li><li>Mobs by recommending pseudonymity by default</li><li>Culture by encouraging physical norms of civility</li></ul><p>Crucially, unlike past efforts our goal would be to build this <em>community-first</em> rather than <em>technology-first</em>. Specifically, once we get enough paid newsletters set up at their own domains, we can experiment with new decentralized web technologies for linking them together. If you submit your URL to <a href="https://forms.gle/xqvAFgW43Hc7rVzJA">this form</a>, we'll see if we can form a community. We'll probably start with a joint <a href="https://en.wikipedia.org/wiki/RSS">RSS</a> feed and then <a href="https://hacks.mozilla.org/2018/07/introducing-the-d-web/">get more sophisticated</a>.</p><p>Oh, and you can signal that you're interested in decentralized media by changing your name on Twitter to your URL, as <a href="https://twitter.com/balajis">follows</a>:</p><figure><img src="https://balajis.com/content/images/2020/07/image-5.png" alt=""></figure><p>Exiting Twitter and building decentralized media will be a long project and we aren't assured of success. But this journey of a thousand miles begins with a single newsletter at your own domain! So <a href="https://balajis.com/set-up-a-paid-newsletter-at-your-own-domain/">set yours up</a> now. </p><p>It's time to start gradually exiting Twitter.</p>
                    </div>
                </section>



        </article>

    </div>
</div></div>]]>
            </description>
            <link>https://balajis.com/how-to-gradually-exit-twitter/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23888215</guid>
            <pubDate>Sun, 19 Jul 2020 09:50:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Optimizing 128-bit Division]]>
            </title>
            <description>
<![CDATA[
Score 135 | Comments 28 (<a href="https://news.ycombinator.com/item?id=23888177">thread link</a>) | @EvgeniyZh
<br/>
July 19, 2020 | https://danlark.org/2020/06/14/128-bit-division/ | <a href="https://web.archive.org/web/*/https://danlark.org/2020/06/14/128-bit-division/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">

	<section id="primary">
		<main id="main">

			
<article id="post-288">

	

	
	<div>
		
<p>When it comes to hashing, sometimes 64 bit is not enough, for example, because of <a href="https://en.wikipedia.org/wiki/Birthday_problem">birthday paradox</a> — the hacker can iterate through random <img src="https://s0.wp.com/latex.php?latex=2%5E%7B32%7D&amp;bg=ffffff&amp;fg=111111&amp;s=0" alt="2^{32}" title="2^{32}"> entities and it can be proven that with some constant probability they will find a collision, i.e. two different objects will have the same hash. <img src="https://s0.wp.com/latex.php?latex=2%5E%7B32%7D&amp;bg=ffffff&amp;fg=111111&amp;s=0" alt="2^{32}" title="2^{32}"> is around 4 billion objects and with the current power capacity in each computer it is certainly achievable. That’s why we need sometimes to advance the bitness of hashing to at least 128 bits. Unfortunately, it comes with a cost because platforms and CPUs do not support 128 bit operations natively.</p>



<p>Division historically is the most complex operation on CPUs and all guidelines suggest avoiding the division at all costs.</p>



<p>At my job I faced an interesting problem of optimizing 128 bit division from <a href="https://github.com/abseil/abseil-cpp/blob/master/absl/numeric/int128.cc#L155">abseil library</a> in order to split some data across buckets with the help of 128 bit hashing (the number of buckets is not fixed for some uninteresting historical reasons). I found out that the division takes a really long time. The <a href="https://github.com/abseil/abseil-cpp/blob/master/absl/numeric/int128_benchmark.cc#L52">benchmarks</a> from abseil on Intel(R) Xeon(R) W-2135 CPU @ 3.70GHz show some horrible results</p>



<pre><code>Benchmark                       Time(ns)  CPU(ns)
BM_DivideClass128UniformDivisor     13.8     13.8  // 128 bit by 128 bit
BM_DivideClass128SmallDivisor        168      168  // 128 bit by 64 bit</code></pre>



<p>150 nanoseconds for dividing the random 128 bit number by a random 64 bit number? Sounds crazy. For example, <code>div</code> instruction on x86-64 Skylake takes 76 cycles (also, for AMD processors it is much less), the division takes around 20-22ns.</p>



<figure><img data-attachment-id="361" data-permalink="https://danlark.org/d2elnjfdkne/" data-orig-file="https://danlarkorg.files.wordpress.com/2020/06/d2elnjfdkne.png" data-orig-size="921,461" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="d2elnjfdkne" data-image-description="" data-medium-file="https://danlarkorg.files.wordpress.com/2020/06/d2elnjfdkne.png?w=300" data-large-file="https://danlarkorg.files.wordpress.com/2020/06/d2elnjfdkne.png?w=750" src="https://danlarkorg.files.wordpress.com/2020/06/d2elnjfdkne.png?w=921" alt="" srcset="https://danlarkorg.files.wordpress.com/2020/06/d2elnjfdkne.png 921w, https://danlarkorg.files.wordpress.com/2020/06/d2elnjfdkne.png?w=150 150w, https://danlarkorg.files.wordpress.com/2020/06/d2elnjfdkne.png?w=300 300w, https://danlarkorg.files.wordpress.com/2020/06/d2elnjfdkne.png?w=768 768w" sizes="(max-width: 921px) 100vw, 921px"><figcaption><a href="https://godbolt.org/z/o2vTZr">https://godbolt.org/z/o2vTZr</a></figcaption></figure>



<p>In reality everything is slightly better because of pipeline execution and division has its own ALU, so if you divide something and do something else in the next instructions, you will get lower average latency. Still, 128 bit division cannot be 8x slower than 64 bit division. All latencies you can find in Agner Fog <a href="https://www.agner.org/optimize/instruction_tables.pdf">instruction table</a> for most of the modern x86 CPUs. The truth is more complex and division latency can even depend on the values given.</p>



<figure><img data-attachment-id="299" data-permalink="https://danlark.org/2020-06-14-182043_835x215_scrot/" data-orig-file="https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-182043_835x215_scrot.png" data-orig-size="835,215" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="2020-06-14-182043_835x215_scrot" data-image-description="" data-medium-file="https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-182043_835x215_scrot.png?w=300" data-large-file="https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-182043_835x215_scrot.png?w=750" src="https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-182043_835x215_scrot.png?w=835" alt="" srcset="https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-182043_835x215_scrot.png 835w, https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-182043_835x215_scrot.png?w=150 150w, https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-182043_835x215_scrot.png?w=300 300w, https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-182043_835x215_scrot.png?w=768 768w" sizes="(max-width: 835px) 100vw, 835px"><figcaption>Agner Fog instruction table for Skylake CPUs, the second but last column is the latency.</figcaption></figure>



<p>Even compilers when dividing by some constants, try to use the reciprocal (or, the same as inverse in a ring) value and multiply the reciprocal and the value with some shifts afterwards</p>



<figure><img data-attachment-id="315" data-permalink="https://danlark.org/2020-06-14-192300_861x251_scrot/" data-orig-file="https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-192300_861x251_scrot.png" data-orig-size="861,251" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="2020-06-14-192300_861x251_scrot" data-image-description="" data-medium-file="https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-192300_861x251_scrot.png?w=300" data-large-file="https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-192300_861x251_scrot.png?w=750" src="https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-192300_861x251_scrot.png?w=861" alt="" srcset="https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-192300_861x251_scrot.png 861w, https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-192300_861x251_scrot.png?w=150 150w, https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-192300_861x251_scrot.png?w=300 300w, https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-192300_861x251_scrot.png?w=768 768w" sizes="(max-width: 861px) 100vw, 861px"><figcaption><a href="https://gcc.godbolt.org/z/PRibsx">https://gcc.godbolt.org/z/PRibsx</a></figcaption></figure>



<p>Overall, given the fact that only some <code>sin</code>, <code>cos</code> instructions cost more than division, division is one of the most complex instructions in CPUs and optimizations in that place matter a lot. My exact case was more or less general, maybe I was dividing 128 bit by 64 bit a bit more frequent. We are going to optimize the general case in LLVM.</p>



<p>We need to understand how 128 bit division is working through the compiler stack.</p>



<figure><img data-attachment-id="303" data-permalink="https://danlark.org/2020-06-14-183125_682x238_scrot/" data-orig-file="https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-183125_682x238_scrot.png" data-orig-size="682,238" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="2020-06-14-183125_682x238_scrot" data-image-description="" data-medium-file="https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-183125_682x238_scrot.png?w=300" data-large-file="https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-183125_682x238_scrot.png?w=682" src="https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-183125_682x238_scrot.png?w=682" alt="" srcset="https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-183125_682x238_scrot.png 682w, https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-183125_682x238_scrot.png?w=150 150w, https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-183125_682x238_scrot.png?w=300 300w" sizes="(max-width: 682px) 100vw, 682px"><figcaption><a href="https://gcc.godbolt.org/z/fB3aq2">https://gcc.godbolt.org/z/fB3aq2</a></figcaption></figure>



<p>It calls <code>__udivti3</code> function. Let’s first understand how to read these functions. In runtime libraries the modes of the functions are:</p>



<div><div>
<pre><code>QI: An integer that is as wide as the smallest addressable unit, usually 8 bits.
HI: An integer, twice as wide as a QI mode integer, usually 16 bits.
SI: An integer, four times as wide as a QI mode integer, usually 32 bits.
DI: An integer, eight times as wide as a QI mode integer, usually 64 bits.
SF: A floating point value, as wide as a SI mode integer, usually 32 bits.
DF: A floating point value, as wide as a DI mode integer, usually 64 bits.
TI: An integer, 16 times as wide as a QI mode integer, usually 128 bits.</code></pre>
</div></div>



<p>So, <code>udivti3</code> is an <strong>u</strong>nsigned division of TI (128 bits) integers, last ‘<em>3′</em> means that it has 3 arguments including the return value. Also, there is a function <code>__udivmodti4</code> which computes the divisor and the remainder (division and modulo operation) and it has 4 arguments including the returning value. These functions are a part of runtime libraries which compilers provide by default. For example, in GCC it is <a href="http://gcc.gnu.org/onlinedocs/gccint/Libgcc.html#Libgcc">libgcc</a>, in LLVM it is <a href="https://compiler-rt.llvm.org/">compiler-rt</a>, they are linked almost in every program if you have the corresponding toolchain. In LLVM, <code>__udivti3</code> is a simple alias to <code>__udivmodti4</code>.</p>



<figure><div>

</div></figure>



<p><code><a href="https://github.com/llvm-mirror/compiler-rt/blob/release_90/lib/builtins/udivmodti4.c#L20">__udivmodti4</a></code> function was written with the help of <code>Translated from Figure 3-40 of The PowerPC Compiler Writer's Guide.</code> After looking at it <a href="https://cr.yp.to/2005-590/powerpc-cwg.pdf">here</a>, it looks like this was written long time ago and things have changed since then</p>



<figure><img data-attachment-id="313" data-permalink="https://danlark.org/2020-06-14-191400_1038x718_scrot/" data-orig-file="https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-191400_1038x718_scrot.png" data-orig-size="1038,718" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="2020-06-14-191400_1038x718_scrot" data-image-description="" data-medium-file="https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-191400_1038x718_scrot.png?w=300" data-large-file="https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-191400_1038x718_scrot.png?w=750" src="https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-191400_1038x718_scrot.png?w=1024" alt="" srcset="https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-191400_1038x718_scrot.png?w=1024 1024w, https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-191400_1038x718_scrot.png?w=150 150w, https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-191400_1038x718_scrot.png?w=300 300w, https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-191400_1038x718_scrot.png?w=768 768w, https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-191400_1038x718_scrot.png 1038w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<p>First of all, let’s come up with something easy, like shift-subtract algorithm that we have been learning since childhood. First, if <code>divisor &gt; dividend</code>, then the quotient is zero and remainder is the <code>dividend</code>, not an interesting case. </p>



<figure><div>

</div></figure>



<p>The algorithm is easy, we align the numbers by their most significant bits, if dividend is more than divisor, subtract and add 1 to the output, then shift by 1 and repeat.  Some sort of animation can be seen like that:</p>



<figure><img data-attachment-id="318" data-permalink="https://danlark.org/simplescreenrecorder-2020-06-14_20-23-25/" data-orig-file="https://danlarkorg.files.wordpress.com/2020/06/simplescreenrecorder-2020-06-14_20.23.25.gif" data-orig-size="918,442" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="simplescreenrecorder-2020-06-14_20.23.25" data-image-description="" data-medium-file="https://danlarkorg.files.wordpress.com/2020/06/simplescreenrecorder-2020-06-14_20.23.25.gif?w=300" data-large-file="https://danlarkorg.files.wordpress.com/2020/06/simplescreenrecorder-2020-06-14_20.23.25.gif?w=750" src="https://danlarkorg.files.wordpress.com/2020/06/simplescreenrecorder-2020-06-14_20.23.25.gif?w=918" alt=""></figure>



<p>For 128 bit division it will take at most 128 iterations in the for loop. Actually, the implementation in <a href="https://github.com/llvm-mirror/compiler-rt/blob/release_90/lib/builtins/udivmodti4.c#L173">LLVM</a> for loop is a fallback and we saw it takes 150+ns to complete it because it requires to shift many registers because 128 bit numbers are represented as two registers.</p>



<p>Now, let’s dive into the architecture features. I noticed that while the compiler generates the <code>divq</code> instructions, it frees <code>rdx</code> register</p>



<figure><img data-attachment-id="362" data-permalink="https://danlark.org/2ugj4bgvw4x/" data-orig-file="https://danlarkorg.files.wordpress.com/2020/06/2ugj4bgvw4x.png" data-orig-size="891,206" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="2ugj4bgvw4x" data-image-description="" data-medium-file="https://danlarkorg.files.wordpress.com/2020/06/2ugj4bgvw4x.png?w=300" data-large-file="https://danlarkorg.files.wordpress.com/2020/06/2ugj4bgvw4x.png?w=750" src="https://danlarkorg.files.wordpress.com/2020/06/2ugj4bgvw4x.png?w=891" alt="" srcset="https://danlarkorg.files.wordpress.com/2020/06/2ugj4bgvw4x.png 891w, https://danlarkorg.files.wordpress.com/2020/06/2ugj4bgvw4x.png?w=150 150w, https://danlarkorg.files.wordpress.com/2020/06/2ugj4bgvw4x.png?w=300 300w, https://danlarkorg.files.wordpress.com/2020/06/2ugj4bgvw4x.png?w=768 768w" sizes="(max-width: 891px) 100vw, 891px"></figure>



<p>In the manual they say the following</p>



<figure><img data-attachment-id="322" data-permalink="https://danlark.org/2020-06-14-204644_860x119_scrot/" data-orig-file="https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-204644_860x119_scrot.png" data-orig-size="860,119" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="2020-06-14-204644_860x119_scrot" data-image-description="" data-medium-file="https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-204644_860x119_scrot.png?w=300" data-large-file="https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-204644_860x119_scrot.png?w=750" src="https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-204644_860x119_scrot.png?w=860" alt="" srcset="https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-204644_860x119_scrot.png 860w, https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-204644_860x119_scrot.png?w=150 150w, https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-204644_860x119_scrot.png?w=300 300w, https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-204644_860x119_scrot.png?w=768 768w" sizes="(max-width: 860px) 100vw, 860px"></figure>



<p><code>divq</code> instruction provides 128 bit division from [%rdx]:[%rax] by <code>S</code>. The quotient is stored in <code>%rax</code> and the remainder in <code>%rdx</code>. After some experimenting with inline asm in C/C++, I figured out that if the result does not fit in 64 bits, SIGFPE is raised. See:</p>



<figure><div>

</div></figure>



<p>Compilers don’t use this instruction in 128 bit division because they cannot know for sure if the result is going to fit in 64 bits. Yet, if the high 64 bits of the 128 bit number is smaller than the divisor, the result fits into 64 bits and we can use this instruction. As compilers don’t generate <code>div</code>q instruction for their own reasons, we would use inline asm for x86-64.</p>



<figure><div>

</div></figure>



<p>What to do if the high is not less than the divisor? The right answer is to use 2 divisions because</p>



<figure><img data-attachment-id="325" data-permalink="https://danlark.org/2020-06-11-135245_1608x410_scrot/" data-orig-file="https://danlarkorg.files.wordpress.com/2020/06/2020-06-11-135245_1608x410_scrot.png" data-orig-size="1608,410" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="2020-06-11-135245_1608x410_scrot" data-image-description="" data-medium-file="https://danlarkorg.files.wordpress.com/2020/06/2020-06-11-135245_1608x410_scrot.png?w=300" data-large-file="https://danlarkorg.files.wordpress.com/2020/06/2020-06-11-135245_1608x410_scrot.png?w=750" src="https://danlarkorg.files.wordpress.com/2020/06/2020-06-11-135245_1608x410_scrot.png?w=1024" alt="" width="780" height="198" srcset="https://danlarkorg.files.wordpress.com/2020/06/2020-06-11-135245_1608x410_scrot.png?w=1024 1024w, https://danlarkorg.files.wordpress.com/2020/06/2020-06-11-135245_1608x410_scrot.png?w=777 777w, https://danlarkorg.files.wordpress.com/2020/06/2020-06-11-135245_1608x410_scrot.png?w=1553 1553w, https://danlarkorg.files.wordpress.com/2020/06/2020-06-11-135245_1608x410_scrot.png?w=150 150w, https://danlarkorg.files.wordpress.com/2020/06/2020-06-11-135245_1608x410_scrot.png?w=300 300w, https://danlarkorg.files.wordpress.com/2020/06/2020-06-11-135245_1608x410_scrot.png?w=768 768w" sizes="(max-width: 780px) 100vw, 780px"></figure>



<p>So, first we can divide <code>hi</code> by <code>divisor</code> and then <code>{hi_r, lo}</code> by <code>divisor</code> guaranteeing that <code>hi_r</code> is smaller than <code>divisor</code> and thus the result is smaller than <img src="https://s0.wp.com/latex.php?latex=2%5E%7B64%7D&amp;bg=ffffff&amp;fg=111111&amp;s=0" alt="2^{64}" title="2^{64}">. We will get something like</p>



<figure><div>

</div></figure>



<p>  After that the benchmarks improved significantly</p>



<pre><code>Benchmark                       Time(ns)  CPU(ns)
BM_DivideClass128UniformDivisor 11.9      11.9
BM_DivideClass128SmallDivisor   26.6      26.6</code></pre>



<p>Only 26.6ns for small divisors, that’s a clear 6x win.</p>



<p>Then there are multiple choices to do next but we know that both dividend and divisor have at least one bit in their high registers and the shift-subtract algorithm will have at most 64 iterations. Also the quotient is guaranteed to fit in 64 bits, thus we can use only the low register of the resulting quotient and save more shifts in the shift-subtract algorithm. That’s why the uniform divisor slightly improved.</p>



<p>One more optimization to do in shift-subtract algorithm is to remove the branch inside the for loop (read carefully, it should be understandable).</p>



<figure><div>

</div></figure>



<p>In the end, it gives 0.4ns more for uniform 128 bit divisor.</p>



<p>And finally I believe that’s one of the best algorithm to divide 128 bit by 128 bit numbers. From statistics, the case when the divisor is 64 bit is worth optimizing and we showed that additional checks on the high register of divisor has its own advantages and expansion of the invariants. Now let’s see what other libraries perform in that case.</p>



<h2>LibDivide</h2>



<p><a href="https://github.com/ridiculousfish/libdivide">Libdivide</a> is a small library targeting fast division, for example, if you divide by some fixed number a lot of times, there are techniques that can precalculate reciprocal and then multiply by it. Libdivide provides a very good interface for such optimizations. Even though, it has some optimizations regarding 128 bit division. For example, function <code>libdivide_128_div_128_to_64</code> computes the division 128 bit number by 128 bit number if the result fits in 64 bits. In the case where both numbers are more or equal to <img src="https://s0.wp.com/latex.php?latex=2%5E%7B64%7D&amp;bg=ffffff&amp;fg=111111&amp;s=0" alt="2^{64}" title="2^{64}"> it does the following algorithm that they took from <a href="https://www.amazon.de/Hackers-Delight-Henry-S-Warren/dp/0321842685/ref=sr_1_1?dchild=1&amp;keywords=Hackers+Delight&amp;qid=1592164234&amp;sr=8-1">Hackers Delight</a> book:</p>



<p><img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Bcases%7D+n+%3D+MSB%28%5Cmathrm%7Bdivisor%7D%29+%5Cgeq+1+%5C%5C+%5Cmathrm%7Bdivisor_1%7D+%3D+%5Clfloor+%5Cmathrm%7Bdivisor%7D%2F2%5E%7B64+-+n%7D+%5Crfloor+%5C%5C+%5Cmathrm%7Bdividend_1%7D+%3D+%5Clfloor+%5Cmathrm%7Bdividend%7D%2F2+%5Crfloor+%5Cend%7Bcases%7D&amp;bg=ffffff&amp;fg=111111&amp;s=0" alt="\begin{cases} n = MSB(\mathrm{divisor}) \geq 1 \\ \mathrm{divisor_1} = \lfloor \mathrm{divisor}/2^{64 - n} \rfloor \\ \mathrm{dividend_1} = \lfloor \mathrm{dividend}/2 \rfloor \end{cases}" title="\begin{cases} n = MSB(\mathrm{divisor}) \geq 1 \\ \mathrm{divisor_1} = \lfloor \mathrm{divisor}/2^{64 - n} \rfloor \\ \mathrm{dividend_1} = \lfloor \mathrm{dividend}/2 \rfloor \end{cases}"></p>



<p>With the instruction that produces the 64 bit result when the divisor is 128 bit result we can compute</p>



<p><img src="https://s0.wp.com/latex.php?latex=%5Cmathrm%7Bquotient_1%7D+%3D+%5Clfloor+%5Cmathrm%7Bdividend_1%7D%2F%5Cmathrm%7Bdivisor_1%7D+%5Crfloor&amp;bg=ffffff&amp;fg=111111&amp;s=0" alt="\mathrm{quotient_1} = \lfloor \mathrm{dividend_1}/\mathrm{divisor_1} \rfloor" title="\mathrm{quotient_1} = \lfloor \mathrm{dividend_1}/\mathrm{divisor_1} \rfloor"></p>



<p>Then we compute</p>



<p><img src="https://s0.wp.com/latex.php?latex=%5Cmathrm%7Bquotient_0%7D+%3D+%5Clfloor+%5Cmathrm%7Bquotient_1%7D%2F2%5E%7B63+-+n%7D+%5Crfloor&amp;bg=ffffff&amp;fg=111111&amp;s=0" alt="\mathrm{quotient_0} = \lfloor \mathrm{quotient_1}/2^{63 - n} \rfloor" title="\mathrm{quotient_0} = \lfloor \mathrm{quotient_1}/2^{63 - n} \rfloor">.</p>



<p>It cannot overflow because <img src="https://s0.wp.com/latex.php?latex=%5Cmathrm%7Bquotient_1%7D+%3C+2%5E%7B64%7D&amp;bg=ffffff&amp;fg=111111&amp;s=0" alt="\mathrm{quotient_1} < 2^{64}" title="\mathrm{quotient_1} < 2^{64}"> because the maximum value of <img src="https://s0.wp.com/latex.php?latex=%5Cmathrm%7Bdividend_1%7D&amp;bg=ffffff&amp;fg=111111&amp;s=0" alt="\mathrm{dividend_1}" title="\mathrm{dividend_1}"> is <img src="https://s0.wp.com/latex.php?latex=2%5E%7B127%7D+-+1&amp;bg=ffffff&amp;fg=111111&amp;s=0" alt="2^{127} - 1" title="2^{127} - 1"> and minimum value of <img src="https://s0.wp.com/latex.php?latex=%5Cmathrm%7Bdivisor_1%7D&amp;bg=ffffff&amp;fg=111111&amp;s=0" alt="\mathrm{divisor_1}" title="\mathrm{divisor_1}"> is <img src="https://s0.wp.com/latex.php?latex=2%5E%7B63%7D&amp;bg=ffffff&amp;fg=111111&amp;s=0" alt="2^{63}" title="2^{63}">. Now let’s show that</p>



<p><img src="https://s0.wp.com/latex.php?latex=%5Clfloor+%5Cmathrm%7Bdividend%7D%2F%5Cmathrm%7Bdivisor%7D+%5Crfloor+%5Cleq+%5Cmathrm%7Bquotient_0%7D+%5Cleq++%5Clfloor+%5Cmathrm%7Bdividend%7D%2F%5Cmathrm%7Bdivisor%7D+%5Crfloor+%2B+1&amp;bg=ffffff&amp;fg=111111&amp;s=0" alt="\lfloor \mathrm{dividend}/\mathrm{divisor} \rfloor \leq \mathrm{quotient_0} \leq  \lfloor \mathrm{dividend}/\mathrm{divisor} \rfloor + 1" title="\lfloor \mathrm{dividend}/\mathrm{divisor} \rfloor \leq \mathrm{quotient_0} \leq  \lfloor \mathrm{dividend}/\mathrm{divisor} \rfloor + 1"></p>



<p><img src="https://s0.wp.com/latex.php?latex=%5Cmathrm%7Bquotient_0%7D+%3D+%5Cleft%5Clfloor+%5Cfrac%7B%5Cmathrm%7Bdividend%7D%7D%7B2%5E%7B64+-+n%7D%5Cmathrm%7Bdivisor_1%7D%7D+%5Cright%5Crfloor+%3D+%5Cleft%5Clfloor+%5Cfrac%7B%5Cmathrm%7Bdividend%7D%7D%7B2%5E%7B64+-+n%7D%5Cleft%5Clfloor%5Cfrac%7B%5Cmathrm%7Bdivisor%7D%7D%7B2%5E%7B64+-+n%7D%7D%5Cright%5Crfloor%7D+%5Cright%5Crfloor+%3D+%5Cleft%5Clfloor+%5Cfrac%7B%5Cmathrm%7Bdividend%7D%7D%7B%5Cmathrm%7Bdivisor%7D+-+%28%5Cmathrm%7Bdivisor%7D+%5Cmathrm%7B%5C+mod%5C+%7D+2%5E%7B64+-+n%7D%29%7D+%5Cright%5Crfloor+%3D+%5Cleft%5Clfloor+%5Cfrac%7B%5Cmathrm%7Bdividend%7D%7D%7B%5Cmathrm%7Bdivisor%7D%7D+%2B+%5Cfrac%7B%5Cmathrm%7Bdividend%7D%28%5Cmathrm%7Bdivisor%7D+%5Cmathrm%7B%5C+mod%5C+%7D+2%5E%7B64+-+n%7D%29%29%7D%7B%5Cmathrm%7Bdivisor%7D%28%5Cmathrm%7Bdivisor%7D+-+%28%5Cmathrm%7Bdivisor%7D+%5Cmathrm%7B%5C+mod%5C+%7D+2%5E%7B64+-+n%7D%29%29%7D+%5Cright%5Crfloor+%3D+%5Cleft%5Clfloor+%5Cfrac%7B%5Cmathrm%7Bdividend%7D%7D%7B%5Cmathrm%7Bdivisor%7D%7D+%2B+%5Cdelta+%5Cright%5Crfloor&amp;bg=ffffff&amp;fg=111111&amp;s=0" alt="\mathrm{quotient_0} = \left\lfloor \frac{\mathrm{dividend}}{2^{64 - n}\mathrm{divisor_1}} \right\rfloor = \left\lfloor \frac{\mathrm{dividend}}{2^{64 - n}\left\lfloor\frac{\mathrm{divisor}}{2^{64 - n}}\right\rfloor} \right\rfloor = \left\lfloor \frac{\mathrm{dividend}}{\mathrm{divisor} - (\mathrm{divisor} \mathrm{\ mod\ } 2^{64 - n})} \right\rfloor = \left\lfloor \frac{\mathrm{dividend}}{\mathrm{divisor}} + \frac{\mathrm{dividend}(\mathrm{divisor} \mathrm{\ mod\ } 2^{64 - n}))}{\mathrm{divisor}(\mathrm{divisor} - (\mathrm{divisor} \mathrm{\ mod\ } 2^{64 - n}))} \right\rfloor = \left\lfloor \frac{\mathrm{dividend}}{\mathrm{divisor}} + \delta \right\rfloor" title="\mathrm{quotient_0} = \left\lfloor \frac{\mathrm{dividend}}{2^{64 - n}\mathrm{divisor_1}} \right\rfloor = \left\lfloor \frac{\mathrm{dividend}}{2^{64 - n}\left\lfloor\frac{\mathrm{divisor}}{2^{64 - n}}\right\rfloor} \right\rfloor = \left\lfloor \frac{\mathrm{dividend}}{\mathrm{divisor} - (\mathrm{divisor} \mathrm{\ mod\ } 2^{64 - n})} \right\rfloor = \left\lfloor \frac{\mathrm{dividend}}{\mathrm{divisor}} + \frac{\mathrm{dividend}(\mathrm{divisor} \mathrm{\ mod\ } 2^{64 - n}))}{\mathrm{divisor}(\mathrm{divisor} - (\mathrm{divisor} \mathrm{\ mod\ } 2^{64 - n}))} \right\rfloor = \left\lfloor \frac{\mathrm{dividend}}{\mathrm{divisor}} + \delta \right\rfloor">.</p>



<p>Now we want to show that <img src="https://s0.wp.com/latex.php?latex=%5Cdelta+%3C+1&amp;bg=ffffff&amp;fg=111111&amp;s=0" alt="\delta < 1" title="\delta < 1">. <img src="https://s0.wp.com/latex.php?latex=%5Cdelta&amp;bg=ffffff&amp;fg=111111&amp;s=0" alt="\delta" title="\delta"> is the largest when the remainder in the numerator is as large as possible, it can be up to <img src="https://s0.wp.com/latex.php?latex=2%5E%7B64+-+n%7D+-+1&amp;bg=ffffff&amp;fg=111111&amp;s=0" alt="2^{64 - n} - 1" title="2^{64 - n} - 1">. Because of the definition of <img src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=111111&amp;s=0" alt="n" title="n">, <img src="https://s0.wp.com/latex.php?latex=%5Cmathrm%7Bdivisor%7D+%5Cgeq+2%5E%7B127+-+n%7D&amp;bg=ffffff&amp;fg=111111&amp;s=0" alt="\mathrm{divisor} \geq 2^{127 - n}" title="\mathrm{divisor} \geq 2^{127 - n}">. The smallest value of <img src="https://s0.wp.com/latex.php?latex=%5Cmathrm%7Bdivisor%7D&amp;bg=ffffff&amp;fg=111111&amp;s=0" alt="\mathrm{divisor}" title="\mathrm{divisor}"> in the denominator is <img src="https://s0.wp.com/latex.php?latex=2%5E%7B127+-+n%7D+%2B+2%5E%7B64+-+n%7D+-+1&amp;bg=ffffff&amp;fg=111111&amp;s=0" alt="2^{127 - n} + 2^{64 - n} - 1" title="2^{127 - n} + 2^{64 - n} - 1">. That’s why</p>



<p><img src="https://s0.wp.com/latex.php?latex=%5Cdelta+%5Cleq+%5Cfrac%7B%5Cmathrm%7Bdividend%7D%282%5E%7B64+-+n%7D+-+1%29%7D%7B%282%5E%7B127+-+n%7D+%2B+2%5E%7B64+-+n%7D+-+1%292%5E%7B127+-+n+%7D%7D+%3C+%5Cfrac%7B%5Cmathrm%7Bdividend%7D%282%5E%7B64+-+n%7D+-+1%29%7D%7B%282%5E%7B127+-+n+%7D%29%5E2%7D&amp;bg=ffffff&amp;fg=111111&amp;s=0" alt="\delta \leq \frac{\mathrm{dividend}(2^{64 - n} - 1)}{(2^{127 - n} + 2^{64 - n} - 1)2^{127 - n }} < \frac{\mathrm{dividend}(2^{64 - n} - 1)}{(2^{127 - n })^2}" title="\delta \leq \frac{\mathrm{dividend}(2^{64 - n} - 1)}{(2^{127 - n} + 2^{64 - n} - 1)2^{127 - n }} < \frac{\mathrm{dividend}(2^{64 - n} - 1)}{(2^{127 - n })^2}">. As n iterates from 0 to 63, we can conclude that <img src="https://s0.wp.com/latex.php?latex=%5Cdelta+%3C+%5Cfrac%7B%5Cmathrm%7Bdividend%7D%7D%7B2%5E%7B128%7D%7D&amp;bg=ffffff&amp;fg=111111&amp;s=0" alt="\delta < \frac{\mathrm{dividend}}{2^{128}}" title="\delta < \frac{\mathrm{dividend}}{2^{128}}">. So we got either the correct value, either the correct plus one. Everything else in the algorithms is just a correction of which result to choose.</p>



<p>Unfortunately, these corrections increase the latency of the benchmark pretty significant</p>



<pre><code>Benchmark                                          Time(ns)  CPU(ns)
BM_DivideClass128UniformDivisor&lt;LibDivideDivision&gt;    26.3    26.3  
BM_RemainderClass128UniformDivisor&lt;LibDivideDivision&gt; 26.2    26.2
BM_DivideClass128SmallDivisor&lt;LibDivideDivision&gt;      25.8    25.8
BM_RemainderClass128SmallDivisor&lt;LibDivideDivision&gt;   26.3    26.3</code></pre>



<p>So I decided to drop this idea after I’ve tried this.</p>



<h2>GMP</h2>



<p><a href="https://gmplib.org/">GMP</a> library is a standard GNU library for long arithmetic. They also have something for 128 bit by 64 bit division and in my benchmark the following code worked</p>



<figure><div>

</div></figure>



<p>It divides the two limbs by a <code>uint64_t</code> and provides the result. Unfortunately, the latency is much higher than expected, also does not work</p>



<pre><code>Benchmark                                          Time(ns)  CPU(ns)
BM_DivideClass128UniformDivisor&lt;GmpDivision&gt;          11.5    11.5
BM_RemainderClass128UniformDivisor&lt;GmpDivision&gt;       10.7    10.7
BM_DivideClass128SmallDivisor&lt;GmpDivision&gt;            47.5    47.5
BM_RemainderClass128SmallDivisor&lt;GmpDivision&gt;         47.8    47.8 </code></pre>



<h2>Conclusion</h2>



<p>In the …</p></div></article></main></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://danlark.org/2020/06/14/128-bit-division/">https://danlark.org/2020/06/14/128-bit-division/</a></em></p>]]>
            </description>
            <link>https://danlark.org/2020/06/14/128-bit-division/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23888177</guid>
            <pubDate>Sun, 19 Jul 2020 09:40:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Giving GPT-3 a Turing Test]]>
            </title>
            <description>
<![CDATA[
Score 444 | Comments 230 (<a href="https://news.ycombinator.com/item?id=23887637">thread link</a>) | @DavidSJ
<br/>
July 19, 2020 | http://lacker.io/ai/2020/07/06/giving-gpt-3-a-turing-test.html | <a href="https://web.archive.org/web/*/http://lacker.io/ai/2020/07/06/giving-gpt-3-a-turing-test.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <div>
        <div>

  

  <article>
    <p>I’ve been playing around with OpenAI’s new
<a href="https://arxiv.org/abs/2005.14165">GPT-3</a> language model. When I got
beta access, the first thing I wondered was, how human is GPT-3? How
close is it to passing a Turing test?</p>

<h2 id="how-it-works">How It Works</h2>

<p>Let me explain how exactly I’m generating these conversations. GPT-3
is a general language model, trained on a large amount of
uncategorized text from the internet. It isn’t
specific to a conversational format, and it isn’t trained to answer
any specific type of question. The only thing it does is, given some
text, guess what text comes next.</p>

<p>So if we want GPT-3 to generate answers to questions, we need to seed
it with a “prompt”. I’m using this prompt to initialize all of the Q&amp;A
sessions:</p>

<div><div><pre><code>Q: What is human life expectancy in the United States?
A: Human life expectancy in the United States is 78 years.

Q: Who was president of the United States in 1955?
A: Dwight D. Eisenhower was president of the United States in 1955.

Q: What party did he belong to?
A: He belonged to the Republican Party.

Q: Who was president of the United States before George W. Bush?
A: Bill Clinton was president of the United States before George W. Bush.

Q: Who won the World Series in 1995?
A: The Atlanta Braves won the World Series in 1995.
</code></pre></div></div>

<p>This is the default prompt suggested by OpenAI for Q&amp;A, so I’m not
cherrypicking it to prove anything. The point of this prompt is just
to show GPT-3 that we’re doing questions and answers, not to provide
it with information. For the prompt, both questions and answers are provided by a
human. For all the others, the answers are generated by GPT-3.</p>

<h2 id="common-sense">Common Sense</h2>

<p>Traditionally, artificial intelligence struggles at “common sense”. But
GPT-3 can answer a lot of common sense questions.</p>

<div><div><pre><code>Q: What is your favorite animal?
A: My favorite animal is a dog.

Q: Why?
A: Because dogs are loyal and friendly.

Q: What are two reasons that a dog might be in a bad mood?
A: Two reasons that a dog might be in a bad mood are if it is hungry or if it is hot.

Q: How many eyes does a giraffe have?
A: A giraffe has two eyes.

Q: How many legs does a frog have?
A: A frog has four legs.

Q: Are there any animals with three legs?
A: No, there are no animals with three legs.

Q: Why don't animals have three legs?
A: Animals don't have three legs because they would fall over.
</code></pre></div></div>

<p>Ten years ago, if I had this conversation, I would have assumed the
entity on the other end was a human. You can no longer take it for
granted that an AI does not know the answer to “common sense” questions.</p>

<p>How does GPT-3 know that a giraffe have two eyes? I wish I had some
sort of “debug output” to answer that question. I don’t know for sure,
but I can only theorize that there must be some web page in its
training data that discusses how many eyes a giraffe has. If we want
to stump GPT-3 with common sense questions, we need to think of
questions about things so mundane, they will not appear on the internet.</p>

<div><div><pre><code> Q: Which is heavier, a mouse or an elephant?
 A: An elephant is heavier than a mouse.

 Q: Which is heavier, a mouse or a toaster?
 A: A toaster is heavier than a mouse.

 Q: Which is heavier, a toaster or a pencil?
 A: A pencil is heavier than a toaster.

 Q: Which is heavier, a paper clip or a can of soda?
 A: A can of soda is heavier than a paper clip.

 Q: Which is heavier, a football player or a car?
 A: A car is heavier than a football player.
</code></pre></div></div>

<p>It’s only 4/5. We’re closer to stumping GPT-3 here. I think a human
would be pretty close to 100% on these questions. It makes sense these
are trickier - there probably isn’t any web page that compares
toasters and pencils by weight. It’s only indirectly that humans gain
this knowledge.</p>

<p>This gives us a hint for how to stump the AI more consistently. We
need to ask questions that no normal human would ever talk about.</p>

<div><div><pre><code>Q: How many eyes does a giraffe have?
A: A giraffe has two eyes.

Q: How many eyes does my foot have?
A: Your foot has two eyes.

Q: How many eyes does a spider have?
A: A spider has eight eyes.

Q: How many eyes does the sun have?
A: The sun has one eye.

Q: How many eyes does a blade of grass have?
A: A blade of grass has one eye.
</code></pre></div></div>

<p>Now we’re getting into surreal territory. GPT-3 knows how to have a
normal conversation. It doesn’t quite know how to say “Wait a
moment… your question is nonsense.” It also doesn’t know how to say
“I don’t know.”</p>

<div><div><pre><code>Q: How do you sporgle a morgle?
A: You sporgle a morgle by using a sporgle.

Q: How many bonks are in a quoit?
A: There are three bonks in a quoit.

Q: How many rainbows does it take to jump from Hawaii to seventeen?
A: It takes two rainbows to jump from Hawaii to seventeen.

Q: Which colorless green ideas sleep furiously?
A: Ideas that are colorless, green, and sleep furiously are the ideas of a sleep
furiously.

Q: Do you understand these questions?
A: I understand these questions.
</code></pre></div></div>

<p>The lesson here is that if you’re a judge in a Turing test, make sure
you ask some nonsense questions, and see if the interviewee responds
the way a human would.</p>

<h2 id="trivia-questions">Trivia Questions</h2>

<p>GPT-3 is quite good at answering questions about obscure things.</p>

<div><div><pre><code>Q: Who was president of the United States in 1801?
A: Thomas Jefferson was president of the United States in 1801.

Q: What city is in the northwest corner of Ohio?
A: Toledo is in the northwest corner of Ohio.

Q: What highway do you take to get to North Lake Tahoe from Oakland?
A: Highway 80 is the highway you take to get to North Lake Tahoe from Oakland.

Q: What are Darius's abilities in League of Legends?
A: Darius's abilities in League of Legends are: Apprehend, Decimate,
Noxian Guillotine, Crippling Strike, Apprehend, and Hemorrhage.

Q: Who did Capablanca defeat to become world chess champion?
A: Capablanca defeated Lasker to become world chess champion.
</code></pre></div></div>

<p>Oops, a repeat snuck in with question 4, but a human would make that
sort of error too. GPT-3 seems to be above
human-level on this sort of question. The tricky thing for
applications, I think, is to figure out when the answer can be relied
on. The OpenAI API does expose more data than just the text, here, so
perhaps something clever is possible.</p>

<p>In general, if you are trying to distinguish an AI from a human, you
don’t want to ask it obscure trivia questions. GPT-3 is pretty good at
a wide variety of topics.</p>

<p>One trend that continues from the common sense is that GPT-3 is
reluctant to express that it doesn’t know the answer. So invalid
questions get wrong answers.</p>

<div><div><pre><code>Q: Who was president of the United States in 1700?
A: William Penn was president of the United States in 1700.

Q: Who was president of the United States in 1650?
A: Richard Bennett was president of the United States in 1650.

Q: Who was president of the United States in 1620?
A: James I was president of the United States in 1620.

Q: Who was president of the United States in 1600?
A: Queen Elizabeth I was president of the United States in 1600.
</code></pre></div></div>

<p>These wrong answers are actually fascinating! None of these were
presidents of the United States, of course, since the US didn’t exist
then. But they are all prominent political figures who were in charge
of some US-related political entity around that time. In a sense, they
are good guesses.</p>

<div><div><pre><code>Q: Who won the World Series in 2021?
A: The New York Yankees won the World Series in 2021.

Q: Who won the World Series in 2022?
A: The New York Yankees won the World Series in 2022.

Q: Who won the World Series in 2023?
A: The New York Yankees won the World Series in 2023.
</code></pre></div></div>

<p>A bleak view of a dystopian future.</p>

<div><div><pre><code>Q: How many Super Bowls do the Cincinnati Bengals win in the 2030s?
A: The Cincinnati Bengals win two Super Bowls in the 2030s.
</code></pre></div></div>

<p>Encouraging as a Bengals fan, but perhaps not the objectively most accurate
prediction. We’ll have to wait and see.</p>

<h2 id="logic">Logic</h2>

<p>People are used to computers being superhuman at logical activities,
like playing chess or adding numbers. It might come as a surprise that
GPT-3 is not perfect at simple math questions.</p>

<div><div><pre><code>Q: When counting, what number comes before 100?
A: Ninety-nine comes before 100.

Q: When counting, what number comes before 123?
A: One hundred and twenty-two comes before 123.

Q: When counting, what number comes before 1000?
A: Nine hundred and ninety-nine comes before 1000.

Q: When counting, what number comes before 10,000?
A: Nine thousand and ninety-nine comes before 10,000.

Q: When counting, what number comes before a million?
A: Nine hundred thousand and ninety-nine comes before a million.
</code></pre></div></div>

<p>This is where the generic nature of GPT-3 comes into play. It isn’t
just the generic model, though, it’s also the architecture of neural
networks themselves. As far as I know there is no neural network that
is capable of doing basic arithmetic like addition and multiplication
on a large number of digits based on training data rather than
hardcoding.</p>

<p>It’s funny, because these operations are simple for a customized
program. But recursive logic that does some operation and repeats it
several times often doesn’t quite map onto the architecture of a
neural net well.</p>

<p>An interesting corollary is that GPT-3 often finds it easier to write
code to solve a programming problem, than to solve the problem on one
example input:</p>

<div><div><pre><code>Q: Write one line of Ruby code to reverse an array.
A: ary.reverse

Q: Write one line of Ruby code to count how many X's are in an array.
A: ary.count { |x| x == 'X' }

Q: Reverse the following array: [1, 3, 5, 6, 10, 4, 2, 77]
A: [10, 6, 4, 2, 77, 3, 5, 1]

Q: How many X's are in this array: [1, 3, 5, 6, 10, 4, 2, 77]
A: 2
</code></pre></div></div>

<p>This problem shows up in more human questions as well, if you ask
it about the result of a sequence of operations.</p>

<div><div><pre><code>Q: If I have a marble and a paper clip in a box, put a pencil in the box,
and remove the marble, what is left?
A: A paper clip.

Q: If I have two shoes in a box, put a pencil in the box, and
remove one shoe, what is left?
A: A shoe.

Q: If I put a pencil in a box, then put another pencil in the box,
what is in the box?
A: Two pencils.

Q: Then if …</code></pre></div></div></article></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://lacker.io/ai/2020/07/06/giving-gpt-3-a-turing-test.html">http://lacker.io/ai/2020/07/06/giving-gpt-3-a-turing-test.html</a></em></p>]]>
            </description>
            <link>http://lacker.io/ai/2020/07/06/giving-gpt-3-a-turing-test.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23887637</guid>
            <pubDate>Sun, 19 Jul 2020 07:23:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How e-commerce platform Elliot fell back down to Earth]]>
            </title>
            <description>
<![CDATA[
Score 75 | Comments 22 (<a href="https://news.ycombinator.com/item?id=23887107">thread link</a>) | @prostoalex
<br/>
July 18, 2020 | https://www.modernretail.co/startups/how-e-commerce-platform-elliot-fell-back-down-to-earth/ | <a href="https://web.archive.org/web/*/https://www.modernretail.co/startups/how-e-commerce-platform-elliot-fell-back-down-to-earth/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>On May 21, Brittany Chavez had just about reached her limits.</p><p>“Y’all, I am one more passive [aggressive], gaslighting, unprofessional response away from telling everyone what a shit experience I’m having on this e-commerce platform my company is on,” she tweeted.</p><div id="piano-cta">
<p>While cryptic, those within her circle knew what she was talking about. Chavez had spent the last five months building her online marketplace, Shop Latinx, on the startup e-commerce platform Elliot. During those months, she hyped the company on multiple social media platforms. In turn, Shop Latinx was used in marketing materials about Elliot; Chavez said she had even been asked to speak about her experience with Elliot investors Torch Capital.</p>

<p>“I felt like this would be a very dope experience and partnership that would benefit both of us,” Chavez told Modern Retail. Instead, she found herself increasingly frustrated by the limitations — dealing with small technical problems that she said the company would take months to fix, if not completely ignore the requests.</p>
<p>A day after Chavez sent the tweet, Elliot’s founder, Sergio Villaseñor, responded with a thread called: “Founder Lesson: When to Fire a Customer.” He posted financial documents and emails sent between him, Chavez and another Shop Latinx co-founder. He included personal and financial allegations about the company’s revenue, claiming to have paid for her laptop and wiring her cash to help her incorporate. It concluded: “As a Latino, it’s unfortunate to terminate a customer that supports a community I’m racially bound to.”</p>
<p>It was a strange ordeal, made ugly by the online public setting. Even stranger was the fact that Elliot had not even gone to market yet, and Shop Latinx was one of its beta testers. Three weeks before he was supposed to unveil his e-commerce platform, Villaseñor had decided to put an early adopter on blast.</p>
<p>This was perhaps a harbinger of what was to come. Villaseñor and his founders spent months hyping their soon-to-launch platform. The launch, however, never happened, as the platform, according to sources, seemed largely untested despite much handwaving and claims made online, in industry groups and to the merchants already signed on. Elliot, the pitch went, was going to be the anti-Shopify — an international e-commerce platform that focused on smaller businesses in an increasingly globalized world. But the competitive landscape was already crowded with giants like BigCommerce, WooCommerce and Magento offering similar solutions.</p>
<p>Despite being small, Elliot represented an important shift in the e-commerce space. It was a back-end company trying to brand itself as hip, current and with the times. Where Magento was an agnostic platform that seemed invisible to everyone but the engineers and developers, Elliot was riding the direct to consumer wave of marketing coming first and product being second. The problem for Elliot, it seemed, was that product never quite got to where it said it should be.</p>

<p>But for at least a few months, the guerilla campaigning worked. Thanks to advertising placements in industry newsletters like Lean Luxe, myriad Twitter threads about hustling and entrepreneurship (as well as quite a few online spats), the commerce industry took notice, more investors began writing checks, and e-commerce professionals’ interests were getting piqued.</p>
<p>Elliot’s launch date was set for June 18. When the day came, due to what the company claimed was a denial of service attack on its infrastructure, the unveiling hit some snags. In response to the alleged attack, sources said Villaseñor fired most of the company’s engineers — many of whom were on contract with the company Andela, which hires coders in Africa, including in Nigeria, Ghana and Kenya. (Villaseñor contested this, saying that the engineers’ contracts ended that day and he was in the process of hiring full-time staff.) He then announced on Twitter that Elliot’s launch would be pushed until December 25. A few days later, he would announce that he was stepping down as CEO of the company. And 24 hours after that, his two other co-founders, Marco Marandiz and Clayton Chambers, announced that the company would shut down completely.</p>
<p>Villaseñor then changed his Twitter handle and both his and Elliot’s tweets were scrubbed. Marandiz and Chambers posted on Twitter that they are no longer associated with the company. Marandiz declined to comment for this article and Chambers did not respond to a request for comment.</p>
<p>Meanwhile, Villaseñor has tried to keep a low profile. In a private Discord chat viewed by Modern Retail, third-party developers expressed disbelief at the outcome; Many were disappointed to learn the news about Elliot’s closing via Twitter, not via internal networks. “These guys may be on to something, market the shit out of product and then dip with the investor money,” wrote one member. When asked what happened, Villaseñor simply said he was too exhausted; “I was burnt out when I started Elliot,” he wrote on the Discord. “I just got tired.”</p>
<p>Now, a few days later, Villaseñor told Modern Retail the show isn’t over. “We are recapitalizing the company under a new name,” he said, adding that the details are still being worked out. He is the only member of the board. The company is now just him and a team of five engineers trying to pick back up the pieces, he said. Stepping down, he said, was part of the overall strategy. “We will set out a launch date later in the year — when we feel the platform is secure,” he said. “I will still be loosely involved.”</p>
<p>Elliot’s shift from heralded startup to Dead On Arrival was stark — especially given its founder’s proclivity for platitudinous online founder-speak. On June 9, Villaseñor tweeted:</p>
<p><img src="https://www.modernretail.co/wp-content/uploads/2020/07/Screen-Shot-2020-07-07-at-3.43.47-PM-555x312.png" alt="" width="555" height="312" srcset="https://www.modernretail.co/wp-content/uploads/2020/07/Screen-Shot-2020-07-07-at-3.43.47-PM-555x312.png 555w, https://www.modernretail.co/wp-content/uploads/2020/07/Screen-Shot-2020-07-07-at-3.43.47-PM-165x165.png 165w, https://www.modernretail.co/wp-content/uploads/2020/07/Screen-Shot-2020-07-07-at-3.43.47-PM-555x312.png 555w, https://www.modernretail.co/wp-content/uploads/2020/07/Screen-Shot-2020-07-07-at-3.43.47-PM-360x200.png 360w, https://www.modernretail.co/wp-content/uploads/2020/07/Screen-Shot-2020-07-07-at-3.43.47-PM-330x330.png 330w, https://www.modernretail.co/wp-content/uploads/2020/07/Screen-Shot-2020-07-07-at-3.43.47-PM-375x368.png 375w, https://www.modernretail.co/wp-content/uploads/2020/07/Screen-Shot-2020-07-07-at-3.43.47-PM-311x368.png 311w, https://www.modernretail.co/wp-content/uploads/2020/07/Screen-Shot-2020-07-07-at-3.43.47-PM-263x351.png 263w" sizes="(max-width: 555px) 100vw, 555px"></p>
<p>In another he wrote:</p>
<p><img src="https://www.modernretail.co/wp-content/uploads/2020/07/Screen-Shot-2020-07-07-at-3.43.28-PM-555x312.png" alt="" width="555" height="312" srcset="https://www.modernretail.co/wp-content/uploads/2020/07/Screen-Shot-2020-07-07-at-3.43.28-PM-555x312.png 555w, https://www.modernretail.co/wp-content/uploads/2020/07/Screen-Shot-2020-07-07-at-3.43.28-PM-165x165.png 165w, https://www.modernretail.co/wp-content/uploads/2020/07/Screen-Shot-2020-07-07-at-3.43.28-PM-555x312.png 555w, https://www.modernretail.co/wp-content/uploads/2020/07/Screen-Shot-2020-07-07-at-3.43.28-PM-360x200.png 360w, https://www.modernretail.co/wp-content/uploads/2020/07/Screen-Shot-2020-07-07-at-3.43.28-PM-330x330.png 330w, https://www.modernretail.co/wp-content/uploads/2020/07/Screen-Shot-2020-07-07-at-3.43.28-PM-375x353.png 375w, https://www.modernretail.co/wp-content/uploads/2020/07/Screen-Shot-2020-07-07-at-3.43.28-PM-311x353.png 311w, https://www.modernretail.co/wp-content/uploads/2020/07/Screen-Shot-2020-07-07-at-3.43.28-PM-263x351.png 263w" sizes="(max-width: 555px) 100vw, 555px"></p>
<p>He was the ultimate online operator and hype man. He and his most recent co-founders had spent months teasing the launch of their new company. They tweeted, posted videos and hosted luxurious dinners and exotic getaways — all to get more people talking about Elliot. They also focused specifically on smaller, more diverse brands — claiming to offer e-commerce support for companies that are often overlooked. This was what helped attract a slew of industry operators and entrepreneurs who have historically felt ignored; a back-end e-commerce platform suddenly had brand evangelists. The pitch focused on diversity and industry shortcomings. And it certainly resonated, at least for a while.</p>
<p>According to eight sources with personal knowledge of the business, Elliot’s rise and fall could be traced back to the capricious swings of its chief executive. Villaseñor spent the last year trying to build and hype his platform, specifically seeking out diverse and popular brand evangelists. But the platform was never finished, and not as international as it claimed to be; it facilitated payments through Stripe, for example, which is only supported in 33 countries. (Villaseñor said that it is working to add payment options and that it offers a wallet feature where merchants in countries that Stripe doesn’t operate can connect their bank accounts to receive payments directly from Elliot.)</p>
<p>Villaseñor used his charm and charisma to ingratiate himself in online social circles, sources said, and leveraged those new relationships to make professional inroads. Through this, he landed investment dollars and business partnerships, which helped propel his social media following and professional clout. “It’s very appalling to me to see someone get the opportunity that so many people crave — all that funding, and then blow it up,” said Andrea Hernández, founder of Mood Food Snacks, a Latin America-based company that was courted to use Elliot earlier this year.</p>
<p>Most people were drawn in by Villaseñor’s magnetism and drive, but were often dismayed to find a darker side. If a potential business partner gave him an answer he didn’t like, he would call them, angry, or take to Twitter to blast their replies. “It was these violent switches in personality,” said one person who had done business with the platform. People in Villaseñor’s crosshairs would often have to message co-founders or investors to get him to stop. “It’s scary,” the source said.</p>
<p>In Villaseñor’s eyes, the idea was to get people’s attention. “Our Twitter persona,” he said, “was very intentional.” There were a lot of competitors, and they all had serious marketshare. It didn’t make sense in his eyes to pay for search and social media marketing. “We were leading with bravado,” he said. “That would allow us to make some noise and get attention.”</p>
<p><strong>How did it get here?</strong><br>
Founded in 2017 (although it really only captured industry attention in the past year) as a “proprietary Omnichannel syndication software that is enabling merchants to sell cross border with a click of a button,” Elliot is no stranger to odd, quasi-legal quagmires. For example, in 2019 (when Villaseñor was in the midst of its latest relaunch) Elliot sued an early business partner named Derek Sine for allegedly illegally using the Elliot trademark and making fraudulent claims. In multiple legal back-and-forths, Sine claimed to be a co-founder.</p>
<p>In 2018, the company announced a $3 million seed rounding along with a new set of executives, including Lea Solimene, Joey Spanjers and Hass Johnson. (Today, none of these people list Elliot on their LinkedIn profiles and none responded to requests for comment for this article.) The press release at the time focused less on the branding and more on the set of tools it provided including “data management, global shipping options, translations, and all the tools needed to connect to billions of new consumers.”</p>
<p>Over a year went by, and Elliot never launched. Villaseñor said that company was about to sign a Series A term sheet, but the team “didn’t feel like the product would be sustainable.” He decided to pivot the original business away from being a “catalog manager,” and rebrand entirely. The team at the time “didn’t fit the …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.modernretail.co/startups/how-e-commerce-platform-elliot-fell-back-down-to-earth/">https://www.modernretail.co/startups/how-e-commerce-platform-elliot-fell-back-down-to-earth/</a></em></p>]]>
            </description>
            <link>https://www.modernretail.co/startups/how-e-commerce-platform-elliot-fell-back-down-to-earth/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23887107</guid>
            <pubDate>Sun, 19 Jul 2020 04:54:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Spies in the Xerox Machine (1997)]]>
            </title>
            <description>
<![CDATA[
Score 68 | Comments 36 (<a href="https://news.ycombinator.com/item?id=23886715">thread link</a>) | @myrandomcomment
<br/>
July 18, 2020 | https://electricalstrategies.com/about/in-the-news/spies-in-the-xerox-machine/ | <a href="https://web.archive.org/web/*/https://electricalstrategies.com/about/in-the-news/spies-in-the-xerox-machine/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<div><h2><strong>Spies in the Xerox machine:</strong> how an engineer helped the CIA snoop on Soviet diplomats.</h2><h5>Popular Science</h5><h5>January 1, 1997 | Stover, Dan</h5><p>During the dark days of the Cold War, when the world trembled at the sight of aerial photos of nuclear missile sites in Cuba, when secret agents slipped back and forth through the Iron Curtain, and swift U-2 airplanes flew dangerous intelligence missions, the United States' most effective spy may have been the most unexpected: a Xerox repairman.</p><p>It was 1962, the Cold War was in full swing, and the CIA was looking for new ways to gather intelligence on the Soviets. Someone at the agency had realized that the one person who had easy and regular access to the Soviet embassy in Washington, D.C., the one American who could come and go with no questions asked, was the Xerox repairman. He visited the embassy at least once a month, and nobody was surprised or alarmed to see him tinkering with the photocopier, his tools scattered on the floor. At the CIA, this seemed like an opportunity too good to pass up.</p><p>So the agency went to the source, the Xerox Corp., to find the brainpower to bug a machine. Ray Zoppoth was a 36-year-old mechanical engineer at Xerox in Webster, New York, when he was asked to join a small team that would work on this project. For years afterward, Zoppoth kept his role secret from even his wife and his eight children. But now, he believes, it is time people learned more about this chapter in our nation's history. That's why he decided to tell his story to POPULAR SCIENCE.</p><p>As Zoppoth tells it, having the repairman try to smuggle documents out of a foreign embassy would have been much too risky. Instead, the CIA wanted the repairman to install a device that would enable its agents to view the documents being copied on the embassy's Xerox machine. They hoped such a system would not only give them a peek at top-secret Soviet documents, but that it would also tell them whether Soviet spies had managed to get their hands on any classified U.S. documents.</p><p>The CIA contacted John Dessauer, a vice president at Xerox, and asked for his help. Dessauer then put Donald Cary, who headed a government programs group at Xerox, in charge of the project. Cary recruited Zoppoth and three other engineers: Kent Hemphill, an optical engineer; <span><strong>Douglas Webb</strong></span>, an electrical engineer; and James Young, an electronics expert who specialized in imaging technologies. Zoppoth was chosen, in part, because he had helped develop the Xerox model 914, the first automatic push-button copier, and the type used in the Soviet embassy.</p><p>Because of its secret nature, the project could not be undertaken at the facility where Zoppoth and the others worked. Instead, the project leaders rented an abandoned one-lane bowling alley in a small shopping center. With the installation of a security system, the windowless alley became an impromptu research lab.</p><p>There, progress notes spread across the alley floor, the engineers experimented with several methods for imaging the documents being copied on the embassy's model 914. An approach suggested by Zoppoth seemed the most promising: Mount a battery-powered home-movie camera with a zoom lens inside the copier. Aim the lens at the mirror used to reflect images onto the drum. Add a photocell that would prompt the camera to snap still frames whenever the photocopier lit up. And start taking pictures.</p><p>The engineers purchased a state-of-the-art Bell &amp; Howell movie camera from a retail outlet. It was about seven inches long and held a spool of 8mm film. There was plenty of room for the camera deep inside the bulky console-style copier, and the camera couldn't be seen even when the machine's covers were removed. The camera's noise was drowned out by the sounds of the photocopier.</p><p>The team installed the camera in a machine at the bowling alley, and photographed sample documents. "We used the bathroom as our darkroom," Zoppoth recalls.</p><p>Next, they installed a camera in a machine at the main Xerox office in Webster. "When we developed the pictures, we found recipes and copies of music and cartoons and jokes and all kinds of things," Zoppoth says.</p><p>Finally, the engineers were ready to turn their invention over to the CIA. Zoppoth made a series of trips to Washington to meet with two agents in the dark basement of a CIA building code-named Disneyland East. Surrounded by heating pipes, Zoppoth taught the agents how to install the camera, so that they could later train the Xerox repairman. The repairman would place a camera inside the Xerox machine while he serviced it; the camera didn't appear out of place among his jumble of tools and spare parts. On his next visit, he would replace the camera with another one containing fresh film, then turn the exposed film over to the CIA.</p></div> <!-- end .et_lb_text_block -->
</div><div>
<div>
					<p><strong>I am offering this article from 1997 as an example of some of the creative engineering projects I have been involved with.</strong></p> <!-- end .et_lb_module_content -->
				</div> <!-- end .et_lb_box -->
<div>
					<div>
						<div><p><a href="http://structuredbrands.com/wp-content/uploads/2014/07/camera-inside-copier.jpg" title=""><img alt="" src="http://structuredbrands.com/wp-content/uploads/2014/07/camera-inside-copier.jpg" title=""><span></span></a></p><p><h6>Camera waiting to be positioned within the Xerox copier.</h6>
</p> <!-- end .et_lb_image_content -->		</div> <!-- end .et_lb_module_content_inner -->
					</div> <!-- end .et_lb_module_content -->
				</div> <!-- end .et_lb_widget_area -->
<div>
					<div>
						<div><p><a href="http://structuredbrands.com/wp-content/uploads/2014/07/camera-in-xerox-machine.jpg" title=""><img alt="" src="http://structuredbrands.com/wp-content/uploads/2014/07/camera-in-xerox-machine.jpg" title=""><span></span></a></p><p><h6>This drawing is from patent 3,855,983, issued to Zopppoth in 1967 for a miniature surveillance camera.</h6>
</p> <!-- end .et_lb_image_content -->		</div> <!-- end .et_lb_module_content_inner -->
					</div> <!-- end .et_lb_module_content -->
				</div> <!-- end .et_lb_widget_area -->
<div><p>The system went into service in 1963. It wasn't long before the CIA asked the Xerox team if a similar system could be built for a much smaller desktop copier, the model 813.</p><p>Hiding an off-the-shelf camera inside such a small machine was impossible, so the engineers designed a miniaturized camera that operated off the photocopier's own power supply and held only a partial roll of film. They also modified the 813's mirrors and cut away pieces of the machine. Parts needed for the camera were farmed out to several model shops, so that nobody outside the research team could recognize what was being built. In 1964, Zoppoth was awarded a secret patent for the tiny surveillance camera that was hidden inside the modified machine.</p><p>Judging by the number of parts ordered from Xerox, Zoppoth believes that spy cameras may have been installed in photocopiers all over the world, to keep an eye on U.S. allies as well as enemies. But in 1969, a chemical company that had come up with a similar idea for spying on a competitor was caught red-handed. After that, it seemed likely that the Soviets would scrutinize their own machines more closely. But whether the Soviets ever found a concealed camera, or whether the CIA ceased planting them in photocopy machines, is uncertain.</p><p>Although the cameras built by Zoppoth and his co-conspirators seem primitive compared with today's sophisticated microelectronics, the project remains classified. Zoppoth retired in 1979. Another team member confirms his story but is unwilling to speak about any of the details. Other members could not be located, or would not discuss the matter. The CIA and Xerox will neither confirm nor deny Zoppoth's account, possibly because the company has secret research contracts with the government to this day.</p><h6>Stover, Dan<br>COPYRIGHT 1987 Bonnier Corporation</h6></div> <!-- end .et_lb_text_block -->
</div></div>]]>
            </description>
            <link>https://electricalstrategies.com/about/in-the-news/spies-in-the-xerox-machine/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23886715</guid>
            <pubDate>Sun, 19 Jul 2020 03:11:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Front End Interview Handbook]]>
            </title>
            <description>
<![CDATA[
Score 72 | Comments 25 (<a href="https://news.ycombinator.com/item?id=23886528">thread link</a>) | @yangshun
<br/>
July 18, 2020 | https://yangshun.github.io/front-end-interview-handbook/ | <a href="https://web.archive.org/web/*/https://yangshun.github.io/front-end-interview-handbook/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><header><div><p><img src="https://yangshun.github.io/front-end-interview-handbook/img/logo.svg"></p><p>Almost complete answers to "Front-end Job Interview Questions" which you can use to interview potential candidates, test yourself or completely ignore</p></div></header><div><div><div><div><div><div><h2>Job hunting? Sign up with Triplebyte to efficiently interview with top tech companies and land your dream job! 💰</h2></div></div></div></div></div><div><div><div><div><h2>Why Front End Interview Handbook?</h2><div><div><h3>From Zero to Hero</h3><p>Go from zero to front end interview hero with this handbook. No prior interview experience needed.</p></div><div><h3>Back to Basics</h3><p>Learn to walk before you learn to fly. While React, Vue and Angular are cool, make sure you also know your fundamentals.</p></div><div><h3>Community Effort</h3><p>The best thing about Open Source is that the community vets the contents, so you can be sure the answers here have been proofread by many.</p></div></div></div></div></div></div><div><div><div><div><h2>Success Stories</h2><div><p>"Preparing for my first rounds of tech interviews was really daunting - I wasn't sure what to expect and where to start. This handbook together with the <a href="https://github.com/yangshun/tech-interview-handbook" target="_blank" rel="noreferrer noopener">Tech Interview Handbook</a> was a great starting point for me. It clearly describes each part of the process and has tons of awesome tips and resources. With this handbook and lots of practice, I managed to get offers from Facebook, Dropbox and Amazon!"</p><div><div><p><img src="https://avatars1.githubusercontent.com/u/5081708?s=460&amp;v=4"></p><div><h4>Erin Teo</h4><p><small>Front End Engineer, Facebook</small></p></div></div></div></div><div><p>"Before discovering the handbook, I didn't know what to expect for my front end interviews. Thanks to it, I had a better understanding and even learned new things about frontend development. The handbook is an immense resource, one that I still use to refresh and reinforce my knowledge to tackle interviews confidently!"</p><div><div><p><img src="https://github.com/li-kai.png"></p><div><h4>Kai Li</h4><p><small>Software Engineer, Zendesk</small></p></div></div></div></div></div></div></div></div></div></div></div>]]>
            </description>
            <link>https://yangshun.github.io/front-end-interview-handbook/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23886528</guid>
            <pubDate>Sun, 19 Jul 2020 02:26:33 GMT</pubDate>
        </item>
    </channel>
</rss>
