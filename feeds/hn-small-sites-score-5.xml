<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 5]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 5. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Sat, 30 Jan 2021 08:40:17 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-5.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Sat, 30 Jan 2021 08:40:17 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[What If GitHub Is the Devil?]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25939541">thread link</a>) | @weinzierl
<br/>
January 28, 2021 | https://daniel.haxx.se/blog/2021/01/28/what-if-github-is-the-devil/ | <a href="https://web.archive.org/web/*/https://daniel.haxx.se/blog/2021/01/28/what-if-github-is-the-devil/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<p>Some critics think the curl project shouldn’t use GitHub. The reasons for being against GitHub hosting tend to be one or more of:</p>



<ol><li>it is an evil proprietary platform</li><li>it is run by Microsoft and they are evil</li><li> GitHub is American thus evil</li></ol>



<p>Some have insisted on craziness like “we let GitHub hold our source code hostage”.</p>



<h2>Why GitHub?</h2>



<p>The curl project <a href="https://daniel.haxx.se/blog/2010/03/23/curl-goes-git/">switched to GitHub</a> (from Sourceforge) almost eleven years ago and it’s been a smooth ride ever since.</p>



<p>We’re on GitHub not only because it provides a myriad of practical features and is a stable and snappy service for hosting and managing source code. GitHub is also a developer hub for millions of developers who already have accounts and are familiar with the GitHub style of developing, the terms and the tools. By being on GitHub, we reduce friction from the contribution process and we maximize the ability for others to join in and help. We lower the bar. This is good for us.</p>



<p>I like GitHub.</p>



<h2>Self-hosting is not better</h2>



<p>Providing even close to the same uptime and snappy response times with a self-hosted service is a challenge, and it would take someone time and energy to volunteer that work – time and energy we now instead can spend of developing the project instead. As a small independent open source project, we don’t have any “infrastructure department” that would do it for us. And trust me: we already have enough infrastructure management to deal with without having to add to that pile.</p>



<p>… and by running our own hosted version, we would lose the “network effect” and convenience for people that already are on and know the platform. We would also lose the easy integration with cool services like the many different CI and code analyzer jobs we run.</p>



<h2>Proprietary is not the issue</h2>



<p>While git is open source, GitHub is a proprietary system. But the thing is that even if we would go with a competitor and get our code hosting done elsewhere, our code would still be stored on a machine somewhere in a remote server park we cannot physically access – ever. It doesn’t matter if that hosting company uses open source or proprietary code. If they decide to switch off the servers one day, or even just selectively block our project, there’s nothing we can do to get our stuff back out from there.</p>



<p>We have to work so that we minimize the risk for it and the effects from it if it still happens.</p>



<p>A proprietary software platform holds our code just as much hostage as any free or open source software platform would, simply by the fact that we let someone else host it. They run the servers our code is stored on.</p>



<h2>If GitHub takes the ball and goes home</h2>



<p>No matter which service we use, there’s always a risk that they will turn off the light one day and not come back – or just change the rules or licensing terms that would prevent us from staying there. We cannot avoid that risk. But we can make sure that we’re smart about it, have a contingency plan or at least an idea of what to do when that day comes.</p>



<p>If GitHub shuts down immediately and we get zero warning to rescue anything at all from them, what would be the result for the curl project?</p>



<p><strong>Code.</strong> We would still have the entire git repository with all code, all source history and all existing branches up until that point. We’re hundreds of developers who pull that repository frequently, and many automatically, so there’s a very distributed backup all over the world.</p>



<p><strong>CI</strong>. Most of our CI setup is done with yaml config files in the source repo. If we transition to another hosting platform, we could reuse them.</p>



<p><strong>Issues</strong>. Bug reports and pull requests are stored on GitHub and a sudden exit would definitely make us lose some of them. We do daily “extractions” of all issues and pull-requests so a lot of meta-data could still be saved and preserved. I don’t think this would be a terribly hard blow either: we move long-standing bugs and ideas over to documents in the repository, so the currently open ones are likely possible to get resubmitted again within the nearest future.</p>



<p>There’s no doubt that it would be a significant speed bump for the project, but it would not be worse than that. We could bounce back on a new platform and development would go on <em>within days</em>.</p>



<h2>Low risk</h2>



<p>It’s a rare thing, that a service just suddenly with no warning and no heads up would just go black and leave projects completely stranded. In most cases, we get alerts, notifications and get a chance to transition cleanly and orderly.</p>



<h2>There are alternatives</h2>



<p>Sure there are alternatives. Both pure GitHub alternatives that look similar and provide similar services, and projects that would allow us to run similar things ourselves and host locally. There are many options.</p>



<p><strong>I’m not looking for alternatives. I’m not planning to switch hosting anytime soon!</strong> As mentioned above, I think GitHub is a net positive for the curl project.</p>



<h2>Nothing lasts forever</h2>



<p>We’ve switched services several times before and I’m expecting that we will change again in the future, for all sorts of hosting and related project offerings that we provide to the work and to the developers and participators within the project. Nothing lasts forever.</p>



<p>When  a service we use goes down or just turns sour, we will figure out the best possible replacement and take the jump. Then we patch up all the cracks the jump may have caused and continue the race into the future. Onward and upward. The way we know and the way we’ve done for over twenty years already. </p>



<h2>Credits</h2>



<p>Image by <a href="https://pixabay.com/users/eliassch-3372715/?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=2160321">Elias Sch.</a> from <a href="https://pixabay.com/?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=2160321">Pixabay</a></p>



<h2>Updates</h2>



<p>After this blog post went live, some users remarked than I’m “<a href="https://lobste.rs/s/bfxd28">disingenuous</a>” in the list of reasons at the top, that people have presented to me.  This, because I don’t mention the moral issues staying on GitHub present – like for example previously reported workplace conflicts and their association with hideous American immigration authorities.</p>



<p>This is rather the opposite of  disingenuous. This is the truth. Not a single person have <em>ever</em> asked me to leave GitHub for those reasons. Not me personally, and nobody has asked it out to the wider project either.</p>



<p>These are good reasons to discuss and consider if a service should be used. Have there been violations of “decency” significant enough that should make us leave? Have we crossed that line in the sand? I’m leaning to “no” now, but I’m always listening to what curl users and developers say. Where do you think the line is drawn?</p>
	</div></div>]]>
            </description>
            <link>https://daniel.haxx.se/blog/2021/01/28/what-if-github-is-the-devil/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25939541</guid>
            <pubDate>Thu, 28 Jan 2021 08:27:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Developers spend most of their time figuring the system out]]>
            </title>
            <description>
<![CDATA[
Score 14 | Comments 12 (<a href="https://news.ycombinator.com/item?id=25939122">thread link</a>) | @xkriva11
<br/>
January 27, 2021 | https://blog.feenk.com/developers-spend-most-of-their-time-figuri-7aj1ocjhe765vvlln8qqbuhto/ | <a href="https://web.archive.org/web/*/https://blog.feenk.com/developers-spend-most-of-their-time-figuri-7aj1ocjhe765vvlln8qqbuhto/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		<p>
I am often asked what I mean when I say that developers spend most of their time figuring the system out. Let’s unpack the statement.
</p>
<p>
The oldest reference on the topic I know of dates back to 1979 in a book by Zelkowitz, Shaw, and Gannon entitled <a href="https://www.amazon.com/Principles-software-engineering-design-Prentice-Hall/dp/013710202X">Principles of software engineering and design</a>. It said that most of the development time was spent on maintenance (67%).
</p>
<figure>
	<img src="https://blog.feenk.com/developers-spend-most-of-their-time-figuri-7aj1ocjhe765vvlln8qqbuhto/pictures/1979-graph-picture.png" alt="Software development costs (1979)">
	<figcaption>Software development costs (1979)</figcaption>
</figure>

<p>
Granted, the book does not specify how the figure was obtained. Still, it was deemed an important enough problem to attract significant research attention since then.
</p>
<p>
So, how far are we now, more than 4 decades later?
</p>
<p>
Let’s look at a recent paper by Xia, Bao, Lo, Xing, Hassan, &amp; Li entitled <a href="https://www.researchgate.net/publication/318811113_Measuring_Program_Comprehension_A_Large-Scale_Field_Study_with_Professionals">Measuring Program Comprehension: A Large-Scale Field Study with Professionals</a> and published in IEEE Transactions on Software Engineering, 44, 951-976, 2018. This paper is quite interesting in that it describes in great details how the figures are obtained. And it says that Comprehension took on average ~58%.
</p>
<p>
Now, take a closer look at the results table.
</p>
<figure>
	<img src="https://blog.feenk.com/developers-spend-most-of-their-time-figuri-7aj1ocjhe765vvlln8qqbuhto/pictures/2018-costs.png" alt="Software development costs (2018)">
	<figcaption>Software development costs (2018)</figcaption>
</figure>

<p>
In particular, take a look at the third column in the table: it says Navigation accounts for 24% of the effort, and that is considered separately from the Comprehension effort!
</p>
<p>
So, after 4 decades, we can observe that not much has changed beside learning how to measure the “figuring out” time.
</p>
<p>
So what?
</p>
<p>
Well, that is the single largest expense we have. If we want to optimize anything in our discipline we should look at this part first. We talk often about how we build systems, but how often do you talk about how you spend the “figuring out" time? If we do not talk about it, it’s not explicit. If it’s not explicit, it does not get optimized.
</p>
<p>
If we do talk about how the “figuring out the system” time is spent, we notice that people spend it reading. In fact, as the above paper also shows, comprehension is essentially measured as reading! The two are considered as mostly synonymous.
</p>
<p>
So, how should we talk about how we figure the system out?
</p>
<p>
Given that not much happened for 4 decades, we should entertain the idea that maybe we should frame the problem differently. 
</p>
<p>
Please, bear with me. This is where it gets interesting. So, why do developers read code? Because they want to figure the situation enough to know what to do next. The intent is important. This is decision making.
</p>
<figure>
	<img src="https://blog.feenk.com/developers-spend-most-of-their-time-figuri-7aj1ocjhe765vvlln8qqbuhto/pictures/decision-making.png" alt="The figuring out time is a decision making time">
	<figcaption>The figuring out time is a decision making time</figcaption>
</figure>

<p>
From this perspective, reading is just the means through which information is gathered from data. It also happens to be the most manual possible way to do that, so this lends itself to an important opportunity for optimization.
</p>
<p>
Before you can do something significant about anything, you have to name it. Otherwise it's like with Voldemort. <a href="http://humane-assessment.com/">Many winters ago</a>, I called the effort of “figuring the system out to know what to do next" assessment. And I claimed we should optimize development around it.
</p>
<figure>
	<img src="https://blog.feenk.com/developers-spend-most-of-their-time-figuri-7aj1ocjhe765vvlln8qqbuhto/pictures/assessment.png" alt="Assessment is the process of understanding a situation around a system enough to make a decision">
	<figcaption>Assessment is the process of understanding a situation around a system enough to make a decision</figcaption>
</figure>

<p>
For a whole decade my colleagues and I explored this idea. And it led us to what we now call moldable development.
</p>
<p>
What’s that?
</p>
<p>
Reading is the most manual way to extract information out of data. It does not scale and leads to incomplete information &amp; uncertainty.
</p>
<p>
Software is hard enough. Not knowing what the current system is like should not be an acceptable variable in the equation. A hand drawn picture about the current system is a belief. Decisions should never be based on beliefs. Not in engineering.
</p>
<p>
Once we accept that systems are data, it becomes obvious we should approach it like data, too. Data science tells us that you first start from the problem and then reason through a tool that matches the context.
</p>
<figure>
	<img src="https://blog.feenk.com/developers-spend-most-of-their-time-figuri-7aj1ocjhe765vvlln8qqbuhto/pictures/molding.png" alt="Tools should match the context">
	<figcaption>Tools should match the context</figcaption>
</figure>

<p>
 As software is highly contextual we cannot predict specific problems. We can only predict classes of problems. To handle this, the key idea of moldable development is that the tool should be moldable after knowing the problem. In this way it can deal with what's important in context, and because of it, it can take care of the boring part of reading. Of course, for this to be practical, the cost of creating custom tools must be small.
</p>
<p>
I see the flow of constructing custom tools during development, and, ideally, for every single development problem, as the next major leap in software development.
</p>
<p>
In a decade from now, we should not be measuring the "figuring the system out” in terms of reading. We should occupy our energy with solving actual problems. To get there we should start by talking about how not to read code. We cannot afford not to.
</p>
<p>
We created <a href="https://gtoolkit.com/">Glamorous Toolkit</a> to provide a concrete start for the "how not to read code" conversation. Glamorous Toolkit is a moldable development environment that makes it possible to create custom tools about software systems inexpensively.
</p>
<p>
So, go to <a href="https://gtoolkit.com/">gtoolkit.com</a>. Play with it. Feel #MoldableDevelopment.
</p>
<p>
And do engage with us: <a href="https://discord.gg/FTJr9gP">discord.gg/FTJr9gP</a>.
</p>
<p>
Let’s make that conversation happen.
</p>
		
  	</div></div>]]>
            </description>
            <link>https://blog.feenk.com/developers-spend-most-of-their-time-figuri-7aj1ocjhe765vvlln8qqbuhto/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25939122</guid>
            <pubDate>Thu, 28 Jan 2021 07:19:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Automated Driving: An overview of legislation, regulations, and standards]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25936351">thread link</a>) | @jpsamper
<br/>
January 27, 2021 | https://www.apex.ai/post/legislation-standards-taxonomy-overview | <a href="https://web.archive.org/web/*/https://www.apex.ai/post/legislation-standards-taxonomy-overview">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-hook="post-description"><article><div><div data-rce-version="8.17.5"><div dir="ltr"><div><p id="viewer-d8b1l"><span><em>This is the fourth in the series on <strong>a Brief History of Automated Driving</strong>. <span>The first three posts can be found </span></em><a href="https://www.apex.ai/post/the-history-of-automated-driving-part-one-the-driverless-car-era-began-100-years-ago" target="_blank" rel="noopener"><em><u>here</u></em></a><em><span>, </span></em><a href="https://www.apex.ai/post/a-brief-history-of-automated-driving-part-two-research-and-development" target="_blank" rel="noopener"><em><u>here</u></em></a><em><u>,</u> and </em><a href="https://www.apex.ai/post/a-brief-history-of-automated-driving-part-three-toward-product-development" target="_blank" rel="noopener"><em><u>here</u></em></a><em>. </em></span></p><p id="viewer-6hkp3"><span><em>I have been working on autonomous vehicles and driver assistance systems for </em><a href="http://www.apex.ai/bio-jan-becker" target="_blank" rel="noopener"><em><u>23 years</u></em></a><em>. During this time, I have had many touchpoints with legal and regulatory aspects as well as with functional safety and the respective certification. I helped writing the SAE levels of automated driving, and I cover many aspects in the </em><a href="https://explorecourses.stanford.edu/search?view=catalog&amp;filter-coursestatus-Active=on&amp;page=0&amp;catalog=&amp;q=ME+302B%3A+The+Future+of+the+Automobile-+Driver+Assistance+and+Automated+Driving&amp;collapse=" target="_blank" rel="noopener"><em><u>class I am teaching at Stanford University</u></em></a><em> as well. Discussion and publication often do not address these topics holistically. This post is an attempt to summarize all aspects in article. Comments, additions, suggestions are welcome. Contact info@apex.ai. Thanks. </em></span></p><h2 id="viewer-3ha7e"><span>Motivation </span></h2><p id="viewer-5vq7a"><span>Why are legislation, standards, and taxonomy for vehicle automation needed or at least useful in the first place? Well, obviously, for the same reasons that apply to other technology fields as well: </span></p><ul><li id="viewer-2unmb"><p>A <em>taxonomy</em> provides a common set of definitions and language to describe the technology. Terms are defined to mean the same thing when used accordingly. </p></li><li id="viewer-1vbml"><p><em>Standards</em> extend definitions and language to technical implementations and enable performance and safety minimums. In the course of progressing maturity of a technology, a standard is typically approved through expert consensus by a recognized standardization body. It provides for repeated and common use, rules, guidelines, or characteristics for products or related processes and production methods, with which compliance is not mandatory. Standards enable interoperability. </p></li><li id="viewer-9bscs"><p><em>Legislation</em> and <em>regulations</em> are issued by governments and define product characteristics or their related processes or production methods, including the applicable administrative provisions, with which compliance is mandatory. Regulations often make use of standards. Laws and regulations enable operability. </p></li></ul><p id="viewer-drkop"><span><span><strong>We have visualized the content of this article in a graphic. Click on the graphic to open in a separate tab. The article is best read with the graphic open next it. </strong></span></span></p><div id="viewer-c8ei5"><a href="https://drive.google.com/file/d/1efgJsJrSg-pjsjTZUzUWINK_lTdqPHkJ/view?usp=sharing" target="_blank" rel="noopener"><div data-hook="imageViewer"><div role="img"><p><img data-pin-url="https://www.apex.ai/post/legislation-standards-taxonomy-overview" data-pin-media="https://static.wixstatic.com/media/af56c2_605fa8eb234b41648bac23c74d625453~mv2.png/v1/fit/w_1000%2Ch_1000%2Cal_c/file.png" src="https://static.wixstatic.com/media/af56c2_605fa8eb234b41648bac23c74d625453~mv2.png/v1/fit/w_300,h_300,al_c,q_5/file.png"></p></div></div></a></div><h2 id="viewer-2u4al"><span>Taxonomy</span></h2><p id="viewer-51r50"><span>The purpose of a taxonomy is to provide a standardized classification system to define terms and terminology. Unfortunately, the attempt to establish common terminology has so far been only semi-successful. It seems that the world <!-- -->now <!-- -->has agreed on one taxonomy (the SAE levels, see below), but the world, including some <a href="https://cyberlaw.stanford.edu/blog/2018/04/teslas-fatal-crash" target="_blank" rel="noopener"><u>carmakers</u></a><u>,</u> has not been able to agree to use those consistently.</span></p><p id="viewer-20kg7"><span>The <a href="https://www.bast.de/BASt_2017/EN/Home/home_node.html" target="_blank" rel="noopener"><strong>German Federal Highway Research Institute</strong></a><strong> (BASt)</strong> was the first in 2010 to publish <a href="https://www.bast.de/BASt_2017/DE/Publikationen/Foko/Downloads/2017-2010/2012-11.pdf?__blob=publicationFile&amp;v=1" target="_blank" rel="noopener">a taxonomy for vehicle automation</a>. The result of the activity was rather short-sighted as a<!-- -->n equivalent to SAE level 5 does not exist in the BASt taxonomy—remember this was written<!-- --> three years after the DARPA Urban Challenge and one year after Google launched the project that is now known as Waymo. BASt defines five levels as follow:  </span></p><ul><li id="viewer-88dpo"><p>Level 0: driver only (equivalent to SAE level 0).</p></li><li id="viewer-5cgkb"><p>Level <!-- -->1<!-- -->:<!-- --> assisted (<!-- -->SAE <!-- -->level 1). </p></li><li id="viewer-duose"><p>Level <!-- -->2<!-- -->:<!-- --> partially automated (<!-- -->SAE <!-- -->level 2). </p></li><li id="viewer-cbrbs"><p>Level <!-- -->3<!-- -->:<!-- --> highly automated (<!-- -->SAE <!-- -->level 3). </p></li><li id="viewer-6r33p"><p>Level <!-- -->4<!-- -->:<!-- --> completely automated (more or less <!-- -->equivalent to SAE <!-- -->level 4). </p></li></ul><p id="viewer-7irdd"><span><strong>NHTSA</strong> issued <a href="https://www.nhtsa.gov/staticfiles/rulemaking/pdf/Automated_Vehicles_Policy.pdf" target="_blank" rel="noopener"><u>in 2013 a preliminary statement of policy concerning automated vehicles</u></a>, in which five levels of automation are defined: </span></p><ul><li id="viewer-bqlj6"><p>Level 0: No automation <!-- -->(equivalent to SAE level 0).</p></li><li id="viewer-5sks9"><p>Level 1: Function-specific automation <!-- -->(SAE level 1).</p></li><li id="viewer-48pce"><p>Level 2: Combined function automation<!-- --> (SAE level 2).</p></li><li id="viewer-7nea2"><p>Level 3: Limited self-driving automation<!-- --> (SAE level 3).</p></li><li id="viewer-ecrk1"><p>Level 4: Full self-driving automation<!-- --> (SAE level 4 and 5 combined).<!-- -->  </p></li></ul><p id="viewer-10mt2"><span>NHTSA deprecated their levels in 2016 to adopt the SAE levels. </span></p><p id="viewer-f0ot9"><span><strong>SAE</strong> launched their first <strong>Taxonomy and Definitions for Terms Related to Driving Automation Systems for On-Road Motor Vehicles</strong> in <a href="https://www.sae.org/standards/content/j3016_201401/" target="_blank" rel="noopener"><u>2014</u></a>, with updates in <a href="https://www.sae.org/standards/content/j3016_201609/" target="_blank" rel="noopener"><u>2016</u></a> and <a href="https://www.sae.org/standards/content/j3016_201806/" target="_blank" rel="noopener"><u>2018</u></a>. While the levels themselves did not change since 2014, the descriptive language in the standard has become significantly richer and more clarifying over time. </span></p><ul><li id="viewer-7n3vg"><p><strong>Level 0: No Driving Automation</strong>—The performance by the <em>driver </em>of the entire Dynamic Driving Task (<em>DDT)</em>, even when enhanced by <em>active safety systems</em>.</p></li><li id="viewer-f9bgj"><p><strong>Level 1: Driver Assistance</strong>—The <em>sustained</em> and <em>Operational Design Domain (ODD)</em>-specific execution by a <em>driving automation system</em> of either the <em>lateral</em> or the <em>longitudinal vehicle motion control</em> subtask of the DDT (but not both simultaneously) with the expectation that the <em>driver</em> performs the remainder of the <em>DDT</em>.</p></li><li id="viewer-62vck"><p><strong>Level 2: Partial Driving Automation</strong>—<!-- -->The <em>sustained</em> and <em>ODD</em>-specific execution by a <em>driving automation system</em> of both the <em>lateral</em> and <em>longitudinal vehicle motion control</em> subtasks of the <em>DDT</em> with the expectation that the <em>driver</em> completes the <em>Object and Event Detection and Response</em> (<em>OEDR)</em> subtask and <em>supervises</em> the <em>driving automation system</em>.</p></li><li id="viewer-ffstc"><p><strong>Level 3: Conditional Driving Automation</strong>—The <em>sustained</em> and <em>ODD</em>-specific performance by an <em>Automated Driving System (ADS) </em>of the entire DDT with the expectation that the <em>DDT fallback-ready user</em> is <em>receptive</em> to <em>ADS</em>-issued <em>requests to intervene</em>, as well as to <em>DDT performance-relevant system failures</em> in other <em>vehicle</em> systems, and will respond appropriately.</p></li><li id="viewer-a73vs"><p><strong>Level 4: High Driving Automation</strong>—The <em>sustained</em> and <em>ODD</em>-specific performance by an <em>ADS</em> of the entire <em>DDT</em> and <em>DDT fallback</em> without any expectation that a <em>user</em> will respond to a <em>request to intervene</em>.</p></li><li id="viewer-ca0f8"><p><strong>Level 5: Full Automation</strong>—The <em>sustained</em> and unconditional (i.e., not <em>ODD</em>- specific) performance by an <em>ADS</em> of the entire <em>DDT</em> and <em>DDT fallback</em> without any expectation that a <em>user</em> will respond to a <em>request to intervene</em>.</p></li></ul><p id="viewer-albrn"><span><a href="https://cyberlaw.stanford.edu/about/people/bryant-walker-smith" target="_blank" rel="noopener"><u>Bryant Walker Smith</u></a> has <a href="https://newlypossible.org/wiki/index.php?title=Automated_Driving_Definitions" target="_blank" rel="noopener"><u>published a<strong> simplified summary</strong></u></a> of the SAE levels:  </span></p><p id="viewer-cb8eh"><span><u>Assisted driving features</u></span></p><ul><li id="viewer-4dv4i"><p><strong>Level 0</strong>: You're driving.</p></li><li id="viewer-bmrc3"><p><strong>Level 1</strong>: You're driving, but you're assisted with either steering or speed.</p></li><li id="viewer-lmm1"><p><strong>Level 2</strong>: You're driving, but you're assisted with both steering and speed.</p></li></ul><p id="viewer-9baua"><span><u>Automated driving features</u></span></p><ul><li id="viewer-cabqj"><p><strong>Level 3</strong>: You're not driving, but you will need to drive if prompted in order to maintain safety.</p></li><li id="viewer-9mkgt"><p><strong>Level 4</strong>: You're not driving, but either a) you will need to drive if prompted in order to reach your destination (in a vehicle you can drive) or b) you will not be able to reach every destination (in a vehicle you can't drive).</p></li><li id="viewer-1712b"><p><strong>Level 5</strong>: You're not driving, and you can reach any destination.</p></li></ul><p id="viewer-cs639"><span>This <a href="http://cyberlaw.stanford.edu/blog/2013/12/sae-levels-driving-automation" target="_blank" rel="noopener"><u>table</u></a>, also created by Bryant, summaries the levels and compares SAE, BASt, and NHTSA levels:  </span></p><div id="viewer-6arr2"><a href="http://cyberlaw.stanford.edu/blog/2013/12/sae-levels-driving-automation" target="_blank" rel="noopener"><div data-hook="imageViewer"><div role="img"><p><img data-pin-url="https://www.apex.ai/post/legislation-standards-taxonomy-overview" data-pin-media="https://static.wixstatic.com/media/af56c2_028d5efc2cdf41519faaa97175472181~mv2.png/v1/fit/w_1000%2Ch_1000%2Cal_c/file.png" src="https://static.wixstatic.com/media/af56c2_028d5efc2cdf41519faaa97175472181~mv2.png/v1/fit/w_300,h_300,al_c,q_5/file.png"></p></div></div></a></div><p id="viewer-5gvm6"><span>There are some <strong>common misconceptions</strong> about the levels of vehicle automation. </span></p><ul><li id="viewer-atjoi"><p><em>The levels are numbered and therefore describe a sequence.</em> No, not necessarily. While traditional manufacturers of personally owned vehicles have gradually increased the level (i.e., level 0 with the invention of the modern automobile through the <a href="https://de.wikipedia.org/wiki/Benz_Patent-Motorwagen_Nummer_1" target="_blank" rel="noopener"><u>Benz Motorwagen</u></a>, <a href="https://de.wikipedia.org/wiki/Benz_Patent-Motorwagen_Nummer_1" target="_blank" rel="noopener"><u>ACC</u></a> in the 1990s at the first L1 system, Mercedes' Distronic Plus with Steering Assist (traffic jam assist) in the Mercedes-Benz S-Class in 2013 as the first level 2 system (yes, Tesla did not invent level 2 systems), Audi's A8 in 2017 with Traffic Jam Pilot as the first L3 system (<a href="https://www.wired.com/story/audi-self-driving-traffic-jam-pilot-a8-2019-availablility/" target="_blank" rel="noopener"><u>although that never became available in the US</u></a>), <a href="https://www.businessinsider.com/google-car-project-history-2018-8" target="_blank" rel="noopener"><u>Google jumped directly to developing L4 systems</u></a>. </p></li><li id="viewer-47seq"><p><em>L3 systems, in which the human is required to execute the fallback performance of the dynamic driving task, are insanely dangerous.</em> No, not necessarily. This is based on the incorrect assumption that an L3 system would drive with the 65mph on the freeway, then beep to request driver takeover, then<!-- -->—in the event the driver does not take over— give up and let the vehicle steer off the road. Obviously, in practice, any reasonable manufacturer would not build such a system—which would likely be subject to product <span>liability</span>—but rather build in a risk mitigation strategy if the driver does not take over, e.g. not allow activation at higher velocities or turn on the emergency signal and stop the vehicle in the lane in case the driver does not respond to a takeover request. On the other hand, manufacturers might also skip level 3 because of the resulting system complexity, cost, and lack of tangible user benefit.</p></li><li id="viewer-791g6"><p><em>Isn't that then an L4 system?</em> No, an L4 system needs to be able to lead the vehicle into a risk minimal state, e.g., by parking the vehicle on the shoulder of the road instead of in the lane of traffic. </p></li><li id="viewer-3e3k6"><p><em>L4 vehicles will take forever to be ready.</em> No, in fact, we already have self-driving vehicles today in limited ODDs (operational design domains), in <a href="https://www.forbes.com/sites/sebastianblanco/2020/02/06/columbus-is-first-city-in-us-with-autonomous-shuttles-in-residential-areas/#4e3147e86d7f" target="_blank" rel="noopener"><u>certain cities running driverless shuttles</u></a>, or in <a href="https://waymo.com/apply/" target="_blank" rel="noopener"><u>Phoenix</u></a>. </p></li><li id="viewer-dql97"><p><em>Tesla sells Autopilot with Full Self-Driving Capability. It must be level 4</em>.  Unfortunately not. It's a Level 2 driver assistance system, as stated in the fine print: "Autopilot is an advanced driver assistance system that enhances safety and convenience behind the wheel."</p></li></ul><p id="viewer-1tci1"><span>Bryant demystifies more misconceptions around automated driving in his article "<a href="https://futurist.law.umich.edu/how-reporters-can-evaluate-automated-driving-announcements" target="_blank" rel="noopener"><u>How Reporters Can Evaluate Automated Driving Announcements</u></a>." </span></p><p id="viewer-2j5vh"><span>Recently, manufacturers and suppliers are ramping up their use of the term <strong>Level 2 plus or L2+ or even Level 2 plus plus</strong>. According to the SAE taxonomy, this level obviously is not defined. Manufacturers use this term to show advances in technology, e.g., through the <a href="https://techcrunch.com/2018/01/08/intel-sets-the-stage-for-new-level-2-automated-driving/" target="_blank" rel="noopener"><u>inclusion of maps into driver assistance systems</u></a> or <a href="https://blogs.nvidia.com/blog/2019/02/06/what-is-level-2-automated-driving/" target="_blank" rel="noopener"><u>the addition of driver monitoring</u></a>. This doesn't change that <!-- -->— <!-- -->as Bryant puts it <!-- -->—<!-- --> "you're driving, but you're assisted with both steering and speed."</span></p><p id="viewer-b7m6g"><span>There has been continued <strong>criticism</strong> of the SAE levels. <a href="https://en.wikipedia.org/wiki/Brad_Templeton" target="_blank" rel="noopener"><u>Brad Templeton</u></a> published <a href="https://ideas.4brad.com/uncovered-nhtsa-levels-1900-satire" target="_blank" rel="noopener"><u>a satire of the NHTSA levels</u></a> in 2017 and <a href="https://ideas.4brad.com/nhtsasaes-levels-robocars-may-be-contributing-highway-deaths" target="_blank" rel="noopener"><u>pointed out in 2018</u></a>, that, in his opinion, <!-- -->defining automation by degrees of human input is the root flaw and that the levels as defined above "<!-- -->may be contributing to highway deaths."<!-- --> <a href="https://en.wikipedia.org/wiki/Alex_Roy" target="_blank" rel="noopener"><u>Alex Roy</u></a> went a step further <!-- -->in the same year <!-- -->writing "<a href="https://www.thedrive.com/opinion/20495/how-the-language-of-self-driving-is-killing-us" target="_blank" rel="noopener"><u>How the Language of Self-Driving Is Killing Us</u></a>" and "<a href="https://www.thedrive.com/tech/20553/the-language-of-self-driving-cars-is-dangerous-heres-how-to-fix-it" target="_blank" rel="noopener"><u>The Language of Self-Driving Cars Is Dangerous—Here's How To Fix It</u></a><u>,</u>" proposing to ditch the levels altogether, replacing them by two functionalities called "geotonomous" (autonomy limited by location) and Human-Assisted Systems (HAS). Alex then founded the <a href="http://humandriving.org/" target="_blank" rel="noopener"><u>Human Driving Association</u></a> in 2018 and published the <a href="http://humandriving.org/manifesto" target="_blank" rel="noopener"><u>Human Driving Manifesto</u></a>. To date, none of these approaches have gained significant traction. </span></p><p id="viewer-2bnho"><span><a href="https://www.forbes.com/sites/bradtempleton/2021/01/06/waymo-pushes-autonomous-as-the-right-generic-term-for-self-drivingrobocars/" target="_blank" rel="noopener"><u>Brad also …</u></a></span></p></div></div></div></div></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.apex.ai/post/legislation-standards-taxonomy-overview">https://www.apex.ai/post/legislation-standards-taxonomy-overview</a></em></p>]]>
            </description>
            <link>https://www.apex.ai/post/legislation-standards-taxonomy-overview</link>
            <guid isPermaLink="false">hacker-news-small-sites-25936351</guid>
            <pubDate>Thu, 28 Jan 2021 00:28:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Reddit Wallstreetbets Top Leaderboard]]>
            </title>
            <description>
<![CDATA[
Score 10 | Comments 4 (<a href="https://news.ycombinator.com/item?id=25936042">thread link</a>) | @vthallam
<br/>
January 27, 2021 | https://stonks.news/wsb/summary/ | <a href="https://web.archive.org/web/*/https://stonks.news/wsb/summary/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                        
                        
                        
                          <tr>
                            <td>
                              GME
                             </td>
                            
                            <td>
                             <p>GameStop Corporation Common Stock</p>
                            </td>
        
                            <td>
                              <p>325</p>
                             </td>
        
                             <td>
                              <p>197747</p>
                             </td>
                          </tr>
                        
                          <tr>
                            <td>
                              AMC
                             </td>
                            
                            <td>
                             <p>AMC Entertainment Holdings Inc. Class A Common Stock</p>
                            </td>
        
                            <td>
                              <p>13.3</p>
                             </td>
        
                             <td>
                              <p>147984</p>
                             </td>
                          </tr>
                        
                          <tr>
                            <td>
                              NOK
                             </td>
                            
                            <td>
                             <p>Nokia Corporation Sponsored American Depositary Shares</p>
                            </td>
        
                            <td>
                              <p>4.6</p>
                             </td>
        
                             <td>
                              <p>118425</p>
                             </td>
                          </tr>
                        
                          <tr>
                            <td>
                              NOW
                             </td>
                            
                            <td>
                             <p>ServiceNow Inc. Common Stock</p>
                            </td>
        
                            <td>
                              <p>543.2</p>
                             </td>
        
                             <td>
                              <p>83853</p>
                             </td>
                          </tr>
                        
                          <tr>
                            <td>
                              BB
                             </td>
                            
                            <td>
                             <p>BlackBerry Limited Common Stock</p>
                            </td>
        
                            <td>
                              <p>14.1</p>
                             </td>
        
                             <td>
                              <p>71568</p>
                             </td>
                          </tr>
                        
                          <tr>
                            <td>
                              OPEN
                             </td>
                            
                            <td>
                             <p>Opendoor Technologies Inc Common Stock</p>
                            </td>
        
                            <td>
                              <p>26.1</p>
                             </td>
        
                             <td>
                              <p>27310</p>
                             </td>
                          </tr>
                        
                          <tr>
                            <td>
                              REAL
                             </td>
                            
                            <td>
                             <p>The RealReal Inc. Common Stock</p>
                            </td>
        
                            <td>
                              <p>23.7</p>
                             </td>
        
                             <td>
                              <p>18731</p>
                             </td>
                          </tr>
                        
                          <tr>
                            <td>
                              TELL
                             </td>
                            
                            <td>
                             <p>Tellurian Inc. Common Stock</p>
                            </td>
        
                            <td>
                              <p>3.0</p>
                             </td>
        
                             <td>
                              <p>17721</p>
                             </td>
                          </tr>
                        
                          <tr>
                            <td>
                              WORK
                             </td>
                            
                            <td>
                             <p>Slack Technologies Inc. Class A Common Stock</p>
                            </td>
        
                            <td>
                              <p>42.2</p>
                             </td>
        
                             <td>
                              <p>15783</p>
                             </td>
                          </tr>
                        
                          <tr>
                            <td>
                              EVER
                             </td>
                            
                            <td>
                             <p>EverQuote Inc. Class A Common Stock</p>
                            </td>
        
                            <td>
                              <p>45.1</p>
                             </td>
        
                             <td>
                              <p>14417</p>
                             </td>
                          </tr>
                        
                          <tr>
                            <td>
                              PLAY
                             </td>
                            
                            <td>
                             <p>Dave &amp; Buster's Entertainment Inc. Common Stock</p>
                            </td>
        
                            <td>
                              <p>34.0</p>
                             </td>
        
                             <td>
                              <p>13972</p>
                             </td>
                          </tr>
                        
                          <tr>
                            <td>
                              TD
                             </td>
                            
                            <td>
                             <p>Toronto Dominion Bank (The) Common Stock</p>
                            </td>
        
                            <td>
                              <p>56.6</p>
                             </td>
        
                             <td>
                              <p>13903</p>
                             </td>
                          </tr>
                        
                          <tr>
                            <td>
                              TWO
                             </td>
                            
                            <td>
                             <p>Two Harbors Investment Corp</p>
                            </td>
        
                            <td>
                              <p>6.1</p>
                             </td>
        
                             <td>
                              <p>13046</p>
                             </td>
                          </tr>
                        
                          <tr>
                            <td>
                              LOW
                             </td>
                            
                            <td>
                             <p>Lowe's Companies Inc. Common Stock</p>
                            </td>
        
                            <td>
                              <p>166.9</p>
                             </td>
        
                             <td>
                              <p>12479</p>
                             </td>
                          </tr>
                        
                          <tr>
                            <td>
                              U
                             </td>
                            
                            <td>
                             <p>Unity Software Inc. Common Stock</p>
                            </td>
        
                            <td>
                              <p>149.8</p>
                             </td>
        
                             <td>
                              <p>12288</p>
                             </td>
                          </tr>
                        
                          <tr>
                            <td>
                              RIDE
                             </td>
                            
                            <td>
                             <p>Lordstown Motors Corp. Class A Common Stock</p>
                            </td>
        
                            <td>
                              <p>25.2</p>
                             </td>
        
                             <td>
                              <p>11393</p>
                             </td>
                          </tr>
                        
                          <tr>
                            <td>
                              WISH
                             </td>
                            
                            <td>
                             <p>ContextLogic Inc. Class A Common Stock</p>
                            </td>
        
                            <td>
                              <p>30.1</p>
                             </td>
        
                             <td>
                              <p>9025</p>
                             </td>
                          </tr>
                        
                          <tr>
                            <td>
                              PUMP
                             </td>
                            
                            <td>
                             <p>ProPetro Holding Corp. Common Stock</p>
                            </td>
        
                            <td>
                              <p>8.0</p>
                             </td>
        
                             <td>
                              <p>8899</p>
                             </td>
                          </tr>
                        
                          <tr>
                            <td>
                              BIT
                             </td>
                            
                            <td>
                             <p>BlackRock Multi-Sector Income Trust Common Shares of Beneficial Interest</p>
                         …</td></tr></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://stonks.news/wsb/summary/">https://stonks.news/wsb/summary/</a></em></p>]]>
            </description>
            <link>https://stonks.news/wsb/summary/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25936042</guid>
            <pubDate>Thu, 28 Jan 2021 00:06:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Twitter’s Birdwatch Is Fundamentally Flawed]]>
            </title>
            <description>
<![CDATA[
Score 14 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25935407">thread link</a>) | @Kye
<br/>
January 27, 2021 | https://soatok.blog/2021/01/27/twitters-birdwatch-is-fundamentally-flawed/ | <a href="https://web.archive.org/web/*/https://soatok.blog/2021/01/27/twitters-birdwatch-is-fundamentally-flawed/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

		<div>

			
<p>Earlier this week, Twitter announced an initiative to combat misinformation on their platform that they call <a href="https://blog.twitter.com/en_us/topics/product/2021/introducing-birdwatch-a-community-based-approach-to-misinformation.html">Birdwatch</a>.</p>



<p><a href="https://web.archive.org/web/20210126122026/https://twitter.github.io/birdwatch/about/overview/">How Birdwatch works</a>: Volunteers sign up (assuming they meet all the requirements) and can add notes to fill in context on misleading tweets. Other users can rate these contextual tweets as helpful or not helpful. All of these “notes” and ratings of notes are completely transparent.</p>











<p>At its face, Birdwatch is an attempt to scale up the existing fact-checking capability used during the 2020 U.S. Elections while also crowdsourcing this decision-making.</p>



<p>I will give Twitter credit for two things, and only two things, before I get into the problems with their design.</p>



<ol><li>They’re distributing the power to fact-check bad tweets to their users rather than hoarding it for themselves.</li><li>They correctly emphasized transparency as a goal for this tool.</li></ol>



<p>But it’s not all sunshine and rainbows.</p>



<h2>The Fatal Flaw of Birdwatch’s Design</h2>



<p>There’s an old essay titled <em><a href="https://www.ranum.com/security/computer_security/editorials/dumb/">The Six Dumbest Ideas in Computer Security</a></em>, that immediately identifies two problems with Birdwatch’s design. They also happen to be the first two items on the essay’s list!</p>



<ol><li><strong>Default Permit</strong></li><li><strong>Enumerating Badness</strong></li></ol>



<p>This is best illustrated by way of example.</p>



<p>Let’s assume there are two pathological liars hellbent on spreading misinformation on Twitter. They each tweet unsubstantiated claims about some facet of government or civil service. Birdwatch users catch only one of them, and correctly fact-check their tweet.</p>



<p>What happens to the other liar?</p>



<p>What happens if Birdwatch users can only identify one out of ten liars? One out of a hundred? One out of a thousand?! Et cetera.</p>







<p>To be clear: The biggest flaw in their product design is simply that their “notes” and “fact-checks” are negative indicators on known-bad tweets.</p>



<p>This will create a dark pattern: If a tweet slips past the Birdwatch users’ radars, it won’t be fact-checked. In turn, users won’t realize it’s misinformation. A popular term for the resulting conduct is <strong>coordinated inauthentic behavior</strong>.</p>



<p>This already happens to YouTube.</p>



<figure><p><span><iframe width="580" height="327" src="https://www.youtube.com/embed/1PGm8LslEb4?version=3&amp;rel=1&amp;showsearch=0&amp;showinfo=1&amp;iv_load_policy=1&amp;fs=1&amp;hl=en&amp;autohide=2&amp;wmode=transparent" allowfullscreen="true" sandbox="allow-scripts allow-same-origin allow-popups allow-presentation"></iframe></span>
</p></figure>



<p>Hell, this is already happening <em>to Twitter</em>:</p>



<figure><p><span><iframe width="580" height="327" src="https://www.youtube.com/embed/V-1RhQ1uuQ4?version=3&amp;rel=1&amp;showsearch=0&amp;showinfo=1&amp;iv_load_policy=1&amp;fs=1&amp;hl=en&amp;autohide=2&amp;wmode=transparent" allowfullscreen="true" sandbox="allow-scripts allow-same-origin allow-popups allow-presentation"></iframe></span>
</p></figure>



<h2>How To Fix Birdwatch</h2>



<p>I wrote an entire essay on <a href="https://medium.com/@soatok/defeating-coordinated-inauthentic-behavior-at-scale-a872badf721">Defeating Coordinated Inauthentic Behavior at Scale</a> in 2019. I <em>highly</em> recommend anyone at Twitter interested in actually solving the misinformation problem to give that a careful consideration.</p>







<p>But in a nutshell, the most important fix is to change the state machine underlying Birdwatch from:</p>



<ul><li>No notes -&gt; trustworthy</li><li>Notes -&gt; misinformation</li></ul>



<p>…to something <em>subtly</em> different:</p>



<ul><li>No notes -&gt; unvetted / be cautious</li><li>Notes -&gt;<ul><li>Negative notes -&gt; misinformation</li></ul><ul><li>Positive notes -&gt; verified by experts</li></ul></li></ul>



<p>This effectively creates a traffic light signal for users: Tweets start as yellow (exercise caution, which is the default) and may become green (affirmed by notes) or red (experts disagree).</p>



<h3>What Would This Change Accomplish?</h3>



<p>Malicious actors that accomplish Birdwatch evasion will only manage to encompass their message in caution tape. (Metaphorically speaking, anyway.)</p>



<p>If their goal is to spread misinformation while convincing the recipients of their message that they’re speaking the truth, they’ll have to get a green light–which is ideally more expensive to accomplish.</p>



<h3>Bonus Round</h3>



<p>I would also recommend some kind of “this smells fishy” button to signal Birdwatch contributors that this tweet needs fact-checking. Users might self-select into filter bubbles that Birdwatch users are totally absent from, and in turn come across things that are completely unvetted and possibly ambiguous.</p>



<p>While I have your attention, here’s a quality of life suggestion, on the house:</p>



<p>Being able to link claims together (e.g. reposted images with a false claim, n.b. like how the minions memes on Facebook) to deduplicate their claims about reality would save a lot of unnecessary headache.</p>



<p>(Anyone who has used Stack Overflow will appreciate the utility of being able to say “this is a duplicate of $otherThing”.)</p>



<h2>What If These Fundamental Flaws Remain Unfixed?</h2>



<p>Although Birdwatch will probably meet the immediate goal of scaling up the fact-checking efforts beyond what Twitter can provide (and satisfy the public relations requirements of tangibly doing <em>something</em> to combat this problem), propagandists and conspiracy theorists will simply become incentivized to evade Birdwatch contributors’ detection while spreading their lies.</p>



<p>As I said above, coordinated inauthentic behavior is already happening. This isn’t some abstract threat that only academics care about.</p>



<p>To the aid of the malicious, most users will confuse tweets that evaded detection with tweets that didn’t warrant correction. This might even lead to users trusting misinformation <em>more</em> than they would before Birdwatch. This would be a total self-own for the entire Birdwatch project.</p>

		</div><!-- .entry-content -->

	</div></div>]]>
            </description>
            <link>https://soatok.blog/2021/01/27/twitters-birdwatch-is-fundamentally-flawed/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25935407</guid>
            <pubDate>Wed, 27 Jan 2021 23:05:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Fleeing WhatsApp for Better Privacy? Don't Turn to Telegram]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25935177">thread link</a>) | @mercurialshark
<br/>
January 27, 2021 | https://www.wired.com./story/telegram-encryption-whatsapp-settings/ | <a href="https://web.archive.org/web/*/https://www.wired.com./story/telegram-encryption-whatsapp-settings/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><p><span>Last weekend, Raphael</span> Mimoun hosted a digital security training workshop via videoconference with a dozen activists. They belonged to one Southeast Asian country's pro-democracy coalition, a group at direct risk of surveillance and repression by their government. Mimoun, the founder of the digital security nonprofit Horizontal, asked the participants to list messaging platforms that they'd heard of or used, and they quickly rattled off  <a href="https://www.wired.com/story/facebook-messenger-end-to-end-encryption-default/">Facebook Messenger</a>, <a href="https://www.wired.com/story/whatsapp-facebook-data-share-notification/">WhatsApp</a>, <a href="https://www.wired.com/story/signal-tips-private-messaging-encryption/">Signal</a>, and <a href="https://www.wired.com/story/telegram-still-hasnt-removed-an-ai-bot-thats-abusing-women/">Telegram</a>. When Mimoun then asked them to name the <a href="https://www.wired.com/story/encrypted-messaging-isnt-magic/">security advantages</a> of each of those options, several pointed to Telegram's encryption as a plus. It had been <a href="https://www.wired.com/story/opinion-isis-is-now-harder-to-track-onlinebut-thats-good-news/">used by Islamic extremists</a>, one noted, so it must be secure.</p><p>Mimoun explained that yes, Telegram encrypts messages. But by default it encrypts data only between your device and Telegram's server; you have to turn on end-to-end encryption to prevent the server itself from seeing the messages. In fact, the group messaging feature that the Southeast Asian activists used most often offers no end-to-end encryption at all. They'd have to trust Telegram not to cooperate with any government that tries to compel it to cooperate in surveilling users. One of them asked where Telegram is located. The company, Mimoun explained, is based in the United Arab Emirates.</p><p>First laughter, then a more serious feeling of "awkward realization" spread through the call, says Mimoun. After a pause, one of the participants spoke: "We're going to have to regroup and think about what we want to do about this." In a follow-up session, another member of the group told Mimoun the moment was a "rude awakening."</p><p>Earlier this month, Telegram announced that it had hit a milestone of 500 million active monthly users and pointed to a single 72-hour period when 25 million people had joined the service. That surge of adoption seems to have had two simultaneous sources: First, right-wing Americans have sought less-moderated communications platforms after <a href="https://www.wired.com/story/plaintext-trump-ban-easy-fixing-facebook-twitter-hard/">many were banned</a> from Twitter or Facebook for hate speech and disinformation, and after Amazon dropped hosting for their preferred social media service <a href="https://www.wired.com/story/parler-app-free-speech-influencers/">Parler</a>, <a href="https://www.wired.com/story/parler-russia-privacy/">taking it offline</a>.</p><p>Telegram's founder, Pavel Durov, however, has attributed the boost more to WhatsApp's clarification of a privacy policy that includes sharing certain data—though not the content of messages—with its corporate parent, Facebook. Tens of millions of WhatsApp's users <a href="https://www.wired.com/story/whatsapp-facebook-data-share-notification/">responded to that restatement of its (years-old) info-sharing practices</a> by fleeing the service, and many went to Telegram, no doubt attracted in part by its claims of "heavily encrypted" messaging. "We've had surges of downloads before, throughout our 7-year history of protecting user privacy," Durov wrote from his Telegram account. "But this time is different. People no longer want to exchange their privacy for free services."</p><p>But ask Raphael Mimoun—or other security professionals who have analyzed Telegram and who spoke to WIRED about its security and privacy shortcomings—and it's clear that Telegram is far from the best-in-class privacy haven that Durov describes and that many at-risk users believe it to be. "People turn to Telegram because they think it's going to keep them safe," says Mimoun, who last week <a data-event-click="{&quot;element&quot;:&quot;ExternalLink&quot;,&quot;outgoingURL&quot;:&quot;https://hackernoon.com/7-reason-why-telegram-is-insecure-by-design-but-millions-still-flock-to-it-ignoring-privacy-concerns-qq1o344c&quot;}" href="https://hackernoon.com/7-reason-why-telegram-is-insecure-by-design-but-millions-still-flock-to-it-ignoring-privacy-concerns-qq1o344c" rel="nofollow noopener" target="_blank">published a blog post about Telegram's flaws</a> that he says was based on "five years of bottled up frustration" about the misperceptions of its security. "There is just a really big gap between what people feel and believe and the reality of the privacy and security of the app."</p><p>Telegram's privacy protections aren't necessarily faulty or broken on a fundamental level, says Nadim Kobeissi, a cryptographer and founder of the Paris-based cryptography consultancy Symbolic Software. But when it comes to encrypting users' communications so that they can't be surveilled, it simply doesn't measure up to WhatsApp—not to mention the <a href="https://www.wired.com/story/signal-encrypted-messaging-features-mainstream/">nonprofit secure messaging app Signal</a>, which Kobeissi and most other security professionals recommend. That's because WhatsApp and Signal end-to-end encrypt every message and call by default, so that their own servers never access the content of conversations. Telegram by default only uses "transport layer" encryption that protects the connection from the user to the server rather than from one user to another. "In terms of encryption, Telegram is just not as good as WhatsApp," says Kobeissi. "The fact that encryption is not enabled by default already puts it way behind WhatsApp."</p></div></div><div><div><p>Telegram does offer end-to-end encryption for one-to-one chats but requires users to enable a "secret chats" feature, which must be switched on for every contact individually. Starting that secret chat requires four menu taps that aren't particularly intuitive. (Tap the contact's name, then "more," then "start secret chat," and then confirm when a prompt asks whether you're sure.) Conversation history from the default chat doesn't carry over to the “secret” one, and you have to initiate that encryption option every time you pick a conversation back up with a contact.</p><p>"Would you rather go for the car where airbags work any time you get into a crash?" asks Kobeissi. "Or are you going to go for the car where, every time you turn it on you have to type in a PIN to enable airbags? Why not have them on by default? There's going to be a time where you're going to forget to type that PIN and you're going to get into a crash."</p><p>Worse still, Telegram doesn't offer its secret chats feature at all for group chats, where many of its most at-risk users congregate. It also stores all default chat histories on its servers. That adds a measure of convenience; threads conveniently reappear whenever you install the app on a new device. But the approach leaves them vulnerable to being read by everyone, from Telegram itself to hackers who manage to breach the company's network and legal authorities who compel it to share user data.</p><p>That threat of government coercion became more concrete when Telegram moved its development team—and the official headquarters of one company in the Telegram Group—from Berlin to Dubai three years ago. Though Telegram keeps its servers spread elsewhere around the world, that location nonetheless leaves the company particularly vulnerable to pressure from the United Arab Emirates, a country known for its record of aggressively <a href="https://www.wired.com/2016/08/hacking-group-selling-ios-vulnerabilities-state-actors/">hacking</a> and <a href="https://www.wired.com/story/totok-google-play-apple-app-store-uae-surveillance/">surveilling</a> human rights activists and dissidents.</p><p>When WIRED reached out to Telegram for comment on these criticisms, its head of marketing, Mike Ravdonikas, responded in a Telegram message that the company doesn't store data in the UAE and has never received a data request from the UAE government. He added that its "lean Dubai-based team is ready to move to a different location if it ever faces pressure." As for its lack of end-to-end encryption by default, Ravdonikas writes that Telegram's non-secret chats have features that "are not possible to implement in an end-to-end encrypted environment," such as persistent chat histories across devices, very large user groups, and sending large documents and video. "We are not going to cripple Telegram by throwing away dozens of its great features because some folks are misled by marketing tricks from our competitors or are too lazy to start Secret Chats when they think they need them," Telegram founder Durov wrote on his public Telegram channel earlier this month.</p><p>But many cryptographers remain wary of Telegram's encryption scheme, even in secret chats. The company uses its own unique encryption protocol known as MTProto. That preference for homebrewed encryption is widely considered deeply unwise by cryptographers who have long held that it's far safer to implement standard, well-tested protocols. After all, sussing out the vulnerabilities in any new protocol takes years of work and careful auditing, no matter how clever a company's in-house cryptographers may be.</p><p>Telegram's MTProto protocol isn't obviously broken in a practical way, concedes Matt Green, a cryptographer at Johns Hopkins University who has consulted for Facebook on encrypted messaging systems. But it's uniquely "weird," he says, in a way that suggests its inventors don't understand tried-and-true cryptography practices and raises his suspicions that it may yet have undiscovered vulnerabilities. "It's like if everyone else in the world has agreed that we're going to use drywall to do the walls in a house, and then you've got somebody who's using toothpaste," says Green. "Even if the toothpaste works and makes a nice wall, that's weird. How do you know they're not doing other weird, nonstandard things when they put the electrical wiring into the house? And that's what scares me."</p></div></div><div><div><p>Telegram's Ravdonikas argues that “Telegram encryption relies on classical algorithms, because we consider some approaches promoted by US-based cryptographers after 9-11/the Patriot Act (which your sources refer to as 'state of the art cryptography') questionable."</p><p>That rebuttal elicited an eye-roll emoji from Johns Hopkins' Green. "We use these standard approaches because they have public and verifiable mathematical proofs of security," Green says. The standard protocols that Telegram avoids have had plenty of scrutiny outside of the US, he adds in response to the allegation that the Patriot Act biases US cryptographers who have examined them. And Telegram itself uses standard crypto algorithms developed and certified by US government agencies, just in nonstandard ways.</p><p>But Green emphasizes that any criticism of Telegram's encryption protocol is almost academic. The real, overarching problem with Telegram's security protections is that it doesn't actually offer end-to-end encryption by default. "If you're not using secret chats, then Telegram and anyone who hacks into Telegram's servers sees all of your communications. And that's really the biggest problem," Green says. "Signal has default end-to-end encryption. WhatsApp has default end-to-end encryption. Telegram does not."</p><p>Raphael Mimoun, the digital security trainer, says …</p></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.wired.com./story/telegram-encryption-whatsapp-settings/">https://www.wired.com./story/telegram-encryption-whatsapp-settings/</a></em></p>]]>
            </description>
            <link>https://www.wired.com./story/telegram-encryption-whatsapp-settings/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25935177</guid>
            <pubDate>Wed, 27 Jan 2021 22:44:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Fix Terminals]]>
            </title>
            <description>
<![CDATA[
Score 111 | Comments 38 (<a href="https://news.ycombinator.com/item?id=25934367">thread link</a>) | @smartmic
<br/>
January 27, 2021 | http://www.leonerd.org.uk/hacks/fixterms/ | <a href="https://web.archive.org/web/*/http://www.leonerd.org.uk/hacks/fixterms/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="pagebody">



<p>
Keyboard input on Terminals has many deficiencies to it. I want them all fixed. I have a plan on how to do it but it Needs Your Help
</p>

<p>
I want terminal keypresses to Just Work. What do I mean Just Work? I mean programs in a simple orthogonal way, can determine the key that was pressed, and this model should easily map to the user's expectation.
</p>

<p>
Why doesn't it currently? Currently, there are a number of classes of physically-distinct key presses that terminals encode using the same bytes.

</p><ul>
<li>Special names for some ASCII characters collide with <tt>Ctrl</tt>-modified letters. For example, <tt>Tab</tt> is <tt>Ctrl-I</tt>.</li>
<li>The <tt>Ctrl</tt> modifier encodes lower or upper-case letters identically; <tt>Ctrl-I</tt> is <tt>Ctrl-Shift-I</tt>.</li>
<li>UTF-8 collides with 8bit-high characters; e.g. <tt>Alt-C</tt> might be encoded as <tt>0xc3</tt>, which is the first UTF-8 byte of many Unicode characters, such as Ã©.</li>
<li>Sometimes programs rely on timing information to distinguish, for example, <tt>Alt-C</tt> from the two separate keypresses of <tt>Escape</tt> followed by <tt>C</tt>. This results in delays to recognise a plain <tt>Escape</tt> key if the time is too long, or erroneously recognising <tt>Escape</tt> followed by a letter as an <tt>Alt</tt>-modified letter if typed too quickly, or if the time limit is too short.</li>
</ul><p>

Even when keys produce unique unambiguous byte sequences, it may be that some programs cannot recognise them.
</p><ul>
<li>The way terminals encode modified keypresses is an extension to the original methods used in the 1970s, and some older code cannot parse them correctly. Press <tt>Ctrl-Up</tt> on a modern xterm and watch a program fail and die in all sorts of interesting ways because they don't have real CSI parsers.</li>
</ul>



<h2>How can we fix this?</h2>

<p>
By having a sane and sensible model on BOTH ends of the terminal interaction, and a well-defined way of communicating.
How exactly we go about this really depends who you are:
</p>

<h3>Authors of Programs that Read Terminal Keypresses</h3>

<p>
The simplest way to go about this is to use the key input handling features of my terminal UI library, <a href="http://www.leonerd.org.uk/code/libtickit/">libtickit</a>.
Failing this, if you're using some existing system of keyboard input, such as GNU Readline, I suggest you apply pressure to the maintainers of that system until they adopt this method of reading extended keypresses.
</p>

<h3>Authors of Terminal Emulators</h3>

<p>
Making a terminal send the correct key encodings should be a relatively easy task, given the encoding scheme already splits modifiers and keysyms in a way likely to be similar to the underlying input system at work, such as X11 or Win32.
</p>

<h3>End-users of Programs</h3>

<p>Even if you're not the author of a program like this, you can still help fix the situation. Write to the maintainer of your program, report a bug. Explain that you wanted to use such a keybinding, or whatever the problem was. Explain that, because their program doesn't correctly handle these cases, it wasn't possible, but if they were to adopt this scheme, then it would be and your problem would be solved. With enough voices, even the most stubbon developer who believes it's 1970 and everyone lives behind a green-phosphor glass teletype on a 9,600 baud modem, can still change his ways.</p>

<h2>Encoding Specification</h2>

<p>
The primary motivation of this scheme is to encode any possible keypress uniquely; that a keypress maps to one possible sequence of bytes, and a valid sequence of bytes encodes only one keypress. For backward compability, it is also required that any keypress that can be represented without this scheme is also represented by the same bytes within it; that is, this scheme is an <em>extension</em> of existing encodings, not a replacement of.
</p>

<dl>

<dt>Modifiers</dt>
<dd>
The two encoding forms used by this specification to encode modifiers both put a number as their second parameter whose value is 1 + a bitmask encoding the modifiers. We add 1 because by convention, a missing CSI parameter is equivalent to 1, so in the "unmodified" state the modifier field would be 1 - we must add 1 to it so that no-bits-set (unmodified) is encoded as 1 (though, in practice, we rarely use the 1 form explicitly).<br>

Thus, the various encoding forms using these modifiers will look like:
<table>
<tbody><tr><td>unmodified</td><td>Shift+</td><td>Alt+</td><td>Alt+Shift+</td><td>Ctrl+</td><td>Ctrl+Shift+</td><td>Ctrl+Alt+</td><td>Ctrl+Alt+Shift+</td></tr>
<tr><td>(direct UTF-8)</td><td><tt>CSI ...;2 u</tt></td><td><tt>CSI ...;3 u</tt></td><td><tt>CSI ...;4 u</tt></td><td><tt>CSI ...;5 u</tt></td><td><tt>CSI ...;6 u</tt></td><td><tt>CSI ...;7 u</tt></td><td><tt>CSI ...;8 u</tt></td></tr>
<tr><td><tt>CSI ... ~</tt></td><td><tt>CSI ...;2 ~</tt></td><td><tt>CSI ...;3 ~</tt></td><td><tt>CSI ...;4 ~</tt></td><td><tt>CSI ...;5 ~</tt></td><td><tt>CSI ...;6 ~</tt></td><td><tt>CSI ...;7 ~</tt></td><td><tt>CSI ...;8 ~</tt></td></tr>
<tr><td><tt>CSI X</tt></td><td><tt>CSI 1;2 X</tt></td><td><tt>CSI 1;3 X</tt></td><td><tt>CSI 1;4 X</tt></td><td><tt>CSI 1;5 X</tt></td><td><tt>CSI 1;6 X</tt></td><td><tt>CSI 1;7 X</tt></td><td><tt>CSI 1;8 X</tt></td></tr>
</tbody></table>
These various forms are explained more below.
</dd>

<dt>Unicode Characters</dt>
<dd>
When unmodified, just send UTF-8 bytes as normal. No UTF-8 sequence of a regular character starts with a <tt>C0</tt> or <tt>C1</tt> byte, so these will be unique. The <tt>Shift</tt> key should not be considered as a modifier for Unicode characters, because it is most likely used to obtain the character in the first place (e.g. the shift key is often required to obtain the <tt>!</tt> symbol).<br>

Certain key presses have special behaviours with modifiers. <tt>Alt</tt> tends to prefix <tt>Escape</tt>. <tt>Ctrl</tt> tends to mask with <tt>0x1f</tt>. When the simplest form of these keys are pressed, they should be encoded as previously.
Existing schemes lack a way to encode more general modifiers with Unicode codepoints at present, so we are at liberty to invent something new for these. The CSI <tt>u</tt> command lies in the private-use area, so has no fixed meaning at present.
<pre>CSI [codepoint];[modifier] u</pre>
We can use this to represent the problematic combinations of keys; for example variations on the letter "A" (ASCII decimal value 65) and "a":
<table>
<tbody><tr><td></td><td>unmodified</td><td>Alt+</td><td>Ctrl+</td><td>Ctrl+Alt+</td></tr>
<tr><td>without Shift</td><td><tt>a</tt></td><td><tt>ESC a</tt></td><td><tt>0x01</tt></td><td><tt>ESC 0x01</tt></td></tr>
<tr><td>with Shift</td><td><tt>A</tt></td><td><tt>ESC A</tt></td><td><tt>CSI 65;5 u</tt></td><td><tt>CSI 65;7 u</tt></td></tr>
</tbody></table>
This same pattern is continued for the other letters, except for the awkward cases of 

We can now represent the usual problematic keys unambiguously:
<table>
<tbody><tr><td>Ctrl-I = <tt>CSI 105;5 u</tt></td><td>Ctrl-Shift-I = <tt>CSI  73;5 u</tt></td><td>Tab        = <tt>0x09</tt></td></tr>
<tr><td>Ctrl-M = <tt>CSI 109;5 u</tt></td><td>Ctrl-Shift-M = <tt>CSI  77;5 u</tt></td><td>Enter      = <tt>0x0d</tt></td></tr>
<tr><td>Ctrl-[ = <tt>CSI  91;5 u</tt></td><td>Ctrl-{       = <tt>CSI 123;5 u</tt></td><td>Escape     = <tt>0x1b</tt></td></tr>
<tr><td colspan="2">Ctrl-@ = <tt>CSI  64;5u</tt></td>                                 <td>Ctrl-Space = <tt>0x00</tt></td></tr>
</tbody></table>
Because other <tt>C0</tt> bytes do not have usual alternative names or keypresses, these can continue to be sent using the simple single-byte encoding. This is essential to ensuring that legacy systems continue to interpret them correctly (e.g. <tt>termios</tt> still sends <tt>SIGINT</tt> on Ctrl-C).
The <tt>Space</tt> key is unique among the printing Unicode keys in that its behaviour doesn't normally change as a result of the <tt>Shift</tt> modifier. We can capture this by encoding it using CSIu - uniquely, the only printing Unicode key for which we use this:
<table>
<tbody><tr><td>Ctrl-Space = <tt>0x00</tt></td><td>Ctrl-Shift-Space = <tt>CSI 32;6 u</tt></td></tr>
</tbody></table>
</dd>

<dt>Modified C0 controls</dt>
<dd>
The problematic keys listed above plus <tt>Backspace</tt> can be represented using the <tt>CSI u</tt> encoding when any modifiers are present. Because these symbols are almost universally found on their own physical keycap, there is no problem with encoding the <tt>Shift</tt> modifier as well, with the value 1. We encode these keys using their normal <tt>ASCII</tt> codepoint values.
<table>
<tbody><tr><td>Enter     = <tt>0x0d</tt></td><td>Shift-Enter     = <tt>CSI  13;2 u</tt></td><td>Ctrl-Enter     = <tt>CSI  13;5 u</tt></td><td rowspan="4">...</td></tr>
<tr><td>Escape    = <tt>0x1b</tt></td><td>Shift-Escape    = <tt>CSI  27;2 u</tt></td><td>Ctrl-Escape    = <tt>CSI  27;5 u</tt></td></tr>
<tr><td>Backspace = <tt>0x7f</tt></td><td>Shift-Backspace = <tt>CSI 127;2 u</tt></td><td>Ctrl-Backspace = <tt>CSI 127;5 u</tt></td></tr>
</tbody></table>
The <tt>Space</tt> key is trickier, because it's traditionally used with the <tt>Ctrl</tt> modifier to obtain the <tt>NUL</tt> byte encoding.
<table>
<tbody><tr><td>Space     = <tt>0x20</tt></td><td>Shift-Space     = <tt>CSI  32;2 u</tt></td><td>Ctrl-Space     = <tt>0x00</tt></td><td>Ctrl-Shift-Space = <tt>CSI  32;6 u</tt></td></tr>
</tbody></table>
Since most terminals repesent <tt>Shift-Tab</tt> as <tt>CSI Z</tt>, that needs handling specially as well.
<table>
<tbody><tr><td>Tab = <tt>0x09</tt></td><td>Shift-Tab = <tt>CSI  Z</tt></td><td>Ctrl-Tab = <tt>CSI 9;5 u</tt></td><td>Ctrl-Shift-Tab = <tt>CSI 1;5 Z</tt></td><td>...</td></tr>
</tbody></table>
</dd>

<dt>Special keys</dt>
<dd>
Existing schemes usually use <tt>CSI ~</tt> to encode special (i.e. non-Unicode) keypresses. XTerm and other terminals use the second CSI parameter to pass encoding the set of modifiers in effect.
<pre>CSI [number];[modifier] ~</pre>
If the modifier value is 1; i.e. there are no modifiers, then for backward-compatibility to send the same bytes as previously, it should be omitted, sending simply
<pre>CSI [number] ~</pre>
<table>
 <tbody><tr><th>Key</th><th>Number</th></tr>
 <tr><td>Insert   </td><td> 2</td></tr>
 <tr><td>Delete   </td><td> 3</td></tr>
 <tr><td>Page Up  </td><td> 5</td></tr>
 <tr><td>Page Down</td><td> 6</td></tr>
 <tr><td>Home (*) </td><td> 7</td></tr>
 <tr><td>End (*)  </td><td> 8</td></tr>
 <tr><td>F1 (*)   </td><td>11</td></tr>
 <tr><td>F2 (*)   </td><td>12</td></tr>
 <tr><td>F3 (*)   </td><td>13</td></tr>
 <tr><td>F4 (*)   </td><td>14</td></tr>
 <tr><td>F5       </td><td>15</td></tr>
 <tr><td>F6       </td><td>17 (**)</td></tr>
 <tr><td>F7       </td><td>18</td></tr>
 <tr><td>F8       </td><td>19</td></tr>
 <tr><td>F9       </td><td>20</td></tr>
 <tr><td>F10      </td><td>21</td></tr>
 <tr><td>F11      </td><td>23</td></tr>
 <tr><td>F12      </td><td>24</td></tr>
</tbody></table>
<b>(*)</b>: Note that some terminals prefer to encode <tt>Home</tt>, <tt>End</tt> and the <tt>F1</tt> to <tt>F4</tt> function keys using shorter <tt>CSI letter</tt> encodings. Parsers or other receiving programs should accept either encoding identically.
<b>(**)</b>: Note also the discontinuity of numbered function keys. After every group of 5 F keys there is a missing number; so every 6th number is not used by an F key (10, 16, 22, 28,...). This is purely for historic reasons; the numbered F keys on the original VTxx keyboards had physical gaps in these locations.
</dd>

<dt>Really special keypresses</dt>
<dd>
Some terminals encode certain keys outside of the <tt>CSI ~</tt> encoding, instead picking a different CSI command. This too can accomodate the modifier in its second position.
<pre>CSI 1;[modifier] {ABCDFHPQRS}</pre>
<table>
 <tbody><tr><th>Key</th><th>Code</th></tr>
 <tr><td>Up</td>   <td>A</td></tr>
 <tr><td>Down</td> <td>B</td></tr>
 <tr><td>Right</td><td>C</td></tr>
 <tr><td>Left</td> <td>D</td></tr>
 <tr><td>End</td>  <td>F</td></tr>
 <tr><td>Home</td> <td>H</td></tr>
 <tr><td>F1</td>   <td>P</td></tr>
 <tr><td>F2</td>   <td>Q</td></tr>
 <tr><td>F3</td>   <td>R</td></tr>
 <tr><td>F4</td>   <td>S</td></tr>
</tbody></table>
As before, if the modifier is 1 then the modifier parameter should be omitted. Since the leading number is also implied, this can be omitted too.
<pre>CSI {ABCDFHPQRS}</pre>
</dd>
</dl>

<p>
Advantages: solves above problems. <b>Can be fitted into existing programs with a minimum of fuss and without breaking back-compat</b>.
</p>

<p>
Extension: We can take it one step further, and require CSI to be sent as the single 8bit code <tt>0x9b</tt> and never as 7bit multibyte <tt>0x1b 0x4b</tt> (Escape [). This reserves the single <tt>0x1b</tt> byte exclusively for the Escape key. If this is known to be in effect, then it is no longer required to use timing information to recover accurate keypress information, as every possible keypress now has a unique encoding. Even if this is not known to be in effect, programs ought to accept the single <tt>0x9b</tt> byte encoding of CSI anyway, in anticipation of a time when terminals may send it encoded this way by default.
</p>

  </div></div>]]>
            </description>
            <link>http://www.leonerd.org.uk/hacks/fixterms/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25934367</guid>
            <pubDate>Wed, 27 Jan 2021 21:40:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[OO in Python is mostly pointless]]>
            </title>
            <description>
<![CDATA[
Score 323 | Comments 307 (<a href="https://news.ycombinator.com/item?id=25933121">thread link</a>) | @leontrolski
<br/>
January 27, 2021 | https://leontrolski.github.io/mostly-pointless.html | <a href="https://web.archive.org/web/*/https://leontrolski.github.io/mostly-pointless.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><a href="https://leontrolski.github.io/index.html"><img src="https://leontrolski.github.io/pic.png">â‡¦</a><p><em>Discussion <a href="https://news.ycombinator.com/item?id=25933121">here</a> and <a href="https://lobste.rs/s/ldzfsw/oo_python_is_mostly_pointless">here</a>. Call to arms for idiomatic OO code <a href="https://github.com/leontrolski/call-to-arms">here</a>.</em></p><p>People bash OO a lot these days, I'm increasingly coming to the opinion they're right, at least in Python. My point here is not to argue that OO is bad per se, more that its introduction is simply unnecessary, AKA not useful.</p><h2>Oli's Conjecture</h2><blockquote>All OO code can be refactored into equivalent non-OO code that's as easy or more easy to understand.</blockquote><p>Let's take an example that should pan out in OO's favour, we've all seen/written code somewhat like the following:</p><pre><code>class ApiClient:
    def __init__(self, root_url: str, session_cls: sessionmaker):
        self.root_url = root_url
        self.session_cls = session_cls

    def construct_url(self, entity: str) -&gt; str:
        return f"{self.root_url}/v1/{entity}"

    def get_items(self, entity: str) -&gt; List[Item]:
        resp = requests.get(self.construct_url(entity))
        resp.raise_for_status()
        return [Item(**n) for n in resp.json()["items"]]

    def save_items(self, entity: str) -&gt; None:
        with scoped_session(self.session_cls) as session:
            session.add(self.get_items(entity))


class ClientA(ApiClient):
    def construct_url(self, entity: str) -&gt; str:
        return f"{self.root_url}/{entity}"


class ClientB(ApiClient):
    def construct_url(self, entity: str) -&gt; str:
        return f"{self.root_url}/a/special/place/{entity}"


client_a = ClientA("https://client-a", session_cls)
client_a.save_items("bars")</code></pre><p>We chose OO it because we wanted to bind the <code>root_url</code> to something and we didn't want to pass around the <code>sessionmaker</code>. We also wanted to utilise inheritance to hook into a method halfway through the call stack.</p><p>But what if we do just pass data around, and write 'boring' functions, what happens then?</p><pre><code>@dataclass
class Client:
    root_url: str
    url_layout: str


client_a = Client(
    root_url="https://client-a",
    url_layout="{root_url}/{entity}",
)

client_b = Client(
    root_url="https://client-b",
    url_layout="{root_url}/a/special/place/{entity}",
)


def construct_url(client: Client, entity: str) -&gt; str:
    return client.url_layout.format(root_url=client.root_url, entity=entity)


def get_items(client: Client, entity: str) -&gt; List[Item]:
    resp = requests.get(construct_url(client, entity))
    resp.raise_for_status()
    return [Item(**n) for n in resp.json()["items"]]


def save_items(client: Client, session_cls: session_cls, entity: str) -&gt; None:
    with scoped_session(session_cls) as session:
        session.add(get_items(client, entity))


save_items(client_a, session_cls, "bars")</code></pre><p>We had to pass round the <code>Client</code> and the <code>session_cls</code> around.</p><p>ðŸ¤·</p><p>Who cares? We even wrote like 10% fewer characters. Also, the conjecture stands, the resulting code is at least as easy to understand and we didn't need any OO.</p><p>I've heard this style referred to as the <b>bag-of-functions</b> style. That is to say, all your code just consists of typed data and module-namespaced-bags-of-functions.</p><h2>What about long lived global-y things?</h2><p>Use <a href="https://leontrolski.github.io/sane-config.html">this pattern</a> to reuse config/db session classes over the lifetime of an application.</p><h2>What about interfaces/abstract base classes?</h2><p>Just try writing without them, I promise it's going to be OK. <em>(To be fair, it's only the introduction of type hints to Python that has made the <b>bag-of-functions</b> style so pleasant).</em></p><h2>What about impure things?</h2><p>If you've taken the pure-FP/hexagonal-architecture pill, you want to write pure classes that take impure 'adapter' instances for <code>getting-the-current-datetime/API-calls/talking-to-the-db/other-impure-stuff</code>. The idea is nice in principal - should be good for testing right? - in practice, you can just use <a href="https://github.com/spulec/freezegun">freezegun</a> / use <a href="https://github.com/getsentry/responses">responses</a> / <a href="https://dhh.dk/2014/slow-database-test-fallacy.html">test with the db</a> (the <code>other-impure-stuff</code> tends to not actually exist) and save yourself a lot of hassle.</p><h2>Exceptions:</h2><p>I'd like to make exceptions for the following:</p><ul><li>You'll notice I put <code>@dataclass</code>s in the refactored code, these are fine - they're just record types. Python 5 will only have these, not 'normal' classes.</li><li>It's fine to subclass <code>Exception</code>s.  The usage of <code>try: ... except SomeClass: ...</code> fundamentally ties you to a heirarchical worldview, this is fine, just don't make it too complicated.</li><li><code>Enum</code>s - same as above, they fit in well with the rest of Python.</li><li>Very, very occasionally (at least in application development), you come up with a core type that's used so often, it's nice to have the cutesy stuff - think something like a <code>pandas.DataFrame</code>/<code>sqlalchemy.Session</code>. In general though, don't kid yourself that you're building anything that exciting, it's just vanity getting the better of you.</li></ul><h2>I lied.</h2><blockquote>My point here is not to argue that OO is bad per se.</blockquote><p>OK, I lied, it's not just a case of OO being a largely futile addition to the language, it's that it often obscures the problem at hand and encourages bad behaviours:</p><ul><li>It encourages you to mutate. Bag-of-functions makes it feel icky to mutate arguments - as it should feel. (Feel free to mutate within the confines of your function BTW, let's not go mad FP).</li><li>It's somewhat just the return of global variables. Not being able to share data between functions with <code>self</code> forces you to write functions with a smaller state-space that are easier to test.</li><li>Smooshing in functions in with your data makes it harder to serialise anything - in a world of REST APIs, serialisability is super useful.</li><li>It encourages mad inheritance hierarchies - this has been talked about at length elsewhere.</li><li>Most importantly though, it adds nothing, it's just noise that distracts from the problem at hand and makes it harder to navigate/comprehend your code.</li></ul><h2>Notes</h2><ul><li><a href="https://leontrolski.github.io/poor-mans-object.html">I've written before about the poor man's object/closure thingy.</a></li><li><a href="https://www.youtube.com/watch?v=o9pEzgHorH0">A classic video in the OO-bashing genre.</a></li></ul>
</div>]]>
            </description>
            <link>https://leontrolski.github.io/mostly-pointless.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25933121</guid>
            <pubDate>Wed, 27 Jan 2021 19:58:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[So what's a microservice catalog?]]>
            </title>
            <description>
<![CDATA[
Score 16 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25932192">thread link</a>) | @joeyparsons
<br/>
January 27, 2021 | https://www.effx.com/blog/what-is-a-microservice-catalog | <a href="https://web.archive.org/web/*/https://www.effx.com/blog/what-is-a-microservice-catalog">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p><a href="https://www.linkedin.com/in/joeyparsons/"><strong><em>Joey Parsons</em></strong></a><em> is the Founder &amp; CEO of effx.&nbsp; He’s spent his career building cloud infrastructure, running microservices and managing platform &amp; reliability engineering teams at companies like Airbnb, Flipboard, SugarCRM, and Rackspace.</em></p><p>For engineering teams, getting product into the hands of customers as quickly and reliably as possible is top priority. A move to a “you build it, you run it” and <a href="https://www.effx.com/blog/the-evolution-into-devops-and-why-it-works-today"><strong>DevOps model</strong></a><strong> </strong>has helped.&nbsp;</p><p>Microservices have also been the go-to avenue to get there. Teams have clearly understood the benefits of microservices (speed, scale, flexibility, and resilience), but also for many, there’s definitely been some hesitation given the overhead and specialized engineering talent needed to migrate to, operate, and scale this environment.&nbsp;<br></p><p>As more organizations move to building their products and platforms using microservices, engineering teams need an overall view of everything running in their entire, complex infrastructure. This is <a href="https://www.effx.com/blog/why-nows-the-time-for-a-new-microservice-catalog"><strong>why now’s the time for a microservice catalog.</strong></a><strong>&nbsp;</strong><br></p><h2>‍<strong>So what’s a microservice catalog?</strong><br></h2><p>A microservice catalog is a flexible, portable, accurate, and intelligent view of all your microservices. It provides each engineer critical information like an aggregate of all microservices and their metadata,<strong> </strong><a href="https://www.effx.com/blog/service-ownership-in-a-microservices-world"><strong>service ownership</strong></a>, dependencies, how to operate, and take action on each service when an incident happens.&nbsp;</p><figure id="w-node-75d3ccd034cc-0ff58005"><p><img src="https://assets-global.website-files.com/5fd1d1ab54430e6b747263b2/601182e1db7c43f231c87381_iDFVjZUxBm26MUoBqJWvjlMW8d4F62EEafGxUyxB3en1gaEkpUk9gq7XN40zZiJ0jxZN490rc7jbSYAwaoL9MDHVTXNDqGj1NOeS_dAJz1Veb6LkRELpBlw87vOj0GiTC41dk_kL.png" alt=""></p><figcaption><em>A detailed service view in a microservice catalog</em></figcaption></figure><p>At effx, the microservice catalog is the basic building block of how we help our customers along their journey with microservices.&nbsp; Below are just some of the things it helps your engineering teams with based on a combination of what we’ve experienced as practitioners and working with hundreds of the top engineering organizations around the world.</p><ul role="list"><li>The ability to search for and discover all of your microservices no matter what infrastructure or platform they’re running on</li><li>Ensuring you build microservices with excellence in mind and emphasizing quality is consistent across your company</li><li>Keeping your microservices up-to-date through the constant change of migrations</li><li>Having confidence and necessary context during complex microservice incidents&nbsp;<br></li></ul><p>However, not all microservice catalogs are built the same.&nbsp; And since this isn’t our first time building a microservice catalog, we’ve found that there’s key tenets to how we’ve built ours that will help you get the most out of it.<br></p><h2>Flexibility<br></h2><p>There are common challenges that most engineering teams using microservices face on a regular basis.&nbsp; However, if you ask an engineer at two separate organizations for the most important metadata to track for a service, that commonality ends.&nbsp; The language used to describe what are seemingly common attributes may be completely different!<br></p><p>For example, what one organization may describe as a “tier” of service, another may call it a “priority”.&nbsp; A “group” versus “pod”.&nbsp; Some may care deeply about tags for compliance while others may not.</p><figure id="w-node-f4d9d698d04f-0ff58005"><p><img src="https://assets-global.website-files.com/5fd1d1ab54430e6b747263b2/6011840533a1c51a66480fcf_7TTT6OvZA1gFtcT3cZNFST0CIogTSyM6nYloYwCJ9OLTM9H3H43bOe4xUNcAdBkdeGNzHnZ7SuGLNqkHDcflYTF9Hrqb-QrW3n1zXqtS3eY6ghP11_8aT44GanEWrTiVXsliqk2A.png" alt=""></p><figcaption><em>The effx microservice catalog allows you to define your taxonomy in code</em></figcaption></figure><p>One team may prioritize dashboards that combine both time-series data and logs into one, while others may have a separate dashboard for each pillar of observability.&nbsp; Runbooks could be a separate entity or a team may have a culture of having that information directly in its alert descriptions.<br></p><p>Every company is different -- and at times, those differences exist on a team level!<br></p><p>A flexible taxonomy for how metadata is described and labeled allows your team to build a microservice catalog that makes sense for your cultural engineering norms, versus fitting a strongly-opinionated structure.<br></p><h2>Portability<br></h2><p>Imagine if you could only use data from another common catalog-like service, Wikipedia … on Wikipedia.&nbsp;&nbsp;<br></p><p>When developers build systems to send microservice metadata or events into a platform, they expect to be able to also retrieve it to use in their own applications.&nbsp; An API-first microservice catalog is a must.<br></p><p>Once the metadata for a service is aggregated into a single location, the applicability of that data in other platforms is nearly limitless.&nbsp; Source of truth information like service ownership can help drive priorities or roles and responsibilities in other platforms that require it.<br></p><p>Having a well-documented, easy-to-use API that has strong library support and follows common access patterns like REST helps ensure that your platform is both extensible and portable.<br></p><p><a href="https://effxhq.github.io/effx-api-v2/"><strong>Check out our effx API documentation</strong></a><br></p><h2>Accuracy<br></h2><p>In the sales world, folks describe CRMs as only being as useful as the data inside of it.&nbsp; A microservice catalog is no different.<br></p><p>Beyond being appropriately filled out, engineers need to feel confident that the data is up-to-date.&nbsp; A single pane of glass with incorrect information, whether it be broken links or out-of-date data can actually be more harmful than the absence of data.<br></p><p>How does one go about providing an accurate catalog?&nbsp; Most importantly, you want to make it simple and easy to keep up-to-date by having that process live where your engineers are every day: in code.<br></p><p><strong>Learn more about our </strong><a href="https://effx.com/help/#using-github-actions"><strong>Github Actions</strong></a><strong>, </strong><a href="https://effx.com/help/#using-gitlab-ci-cd-jobs"><strong>GitLab CI/CD Jobs</strong></a><strong>, and </strong><a href="https://github.com/effxhq/vcs-connect"><strong>vcs-connect</strong></a><strong>, our open source version control indexer.</strong><br></p><h2>Intelligence<br></h2><p>Last but not least, a microservice catalog needs to move beyond static, searchable information and help engineers derive unique insights to help them in their day-to-day.<br></p><p>Combining microservice event data with the overall connectedness of microservices to one another, you can provide intelligence where even your best engineers have a blind spot.<br></p><p>Dependencies, like which services are talking to one another, can change after a simple deploy.&nbsp; Having this information when the system goes awry and related to events within your infrastructure can up-level your frontline engineer’s incident response ability.</p><figure id="w-node-290509a34610-0ff58005"><p><img src="https://assets-global.website-files.com/5fd1d1ab54430e6b747263b2/601185835fbb904aff17dcc2_jkm2feaCkSBj4RDOJZoXpd1rHZuNUuE5eWYY0nJJVkug1GBB3kPGeR8_FehmEpngDucHrUTlgUzWCC6vcd2fpXvsym7S-fbw8IxKFbUGYIgLHaHooisfZZ8RepslPa18wKOABKWR.png" alt=""></p><figcaption><em>A microservice catalog activity feed with critical dependency events inline</em></figcaption></figure><p>The key benefits of microservices like speed, scale, autonomy and resilience are only unlocked by organizations that invest in their engineers’ abilities to better navigate, operate, and evolve its microservices day-to-day.&nbsp; The effx platform, and its unique approach to a microservice catalog, is here to help your team turn its pain into a competitive advantage.<br></p><p>Want to learn more?&nbsp; <a href="https://app.effx.com/sign_up"><strong>Sign up for a free trial</strong></a> and start building your microservice catalog today.</p></div></div></div>]]>
            </description>
            <link>https://www.effx.com/blog/what-is-a-microservice-catalog</link>
            <guid isPermaLink="false">hacker-news-small-sites-25932192</guid>
            <pubDate>Wed, 27 Jan 2021 18:51:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Most of the time, you don’t really need another MOOC]]>
            </title>
            <description>
<![CDATA[
Score 182 | Comments 108 (<a href="https://news.ycombinator.com/item?id=25931498">thread link</a>) | @7d7n
<br/>
January 27, 2021 | https://eugeneyan.com/writing/you-dont-need-another-mooc/ | <a href="https://web.archive.org/web/*/https://eugeneyan.com/writing/you-dont-need-another-mooc/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

<p>Donâ€™t get me wrong, I love <a href="https://en.wikipedia.org/wiki/Massive_open_online_course" target="_blank">MOOCs</a>. Theyâ€™re great for trying to learn a new programming language (e.g., Python, Scala) or framework (e.g., Spark, TensorFlow) or subject (e.g., statistics, machine learning). The structured learning environment, excellent teaching, and exercises (and solutions) guide us through the best way to learn new concepts.</p>
<p><strong>But most of the time, we donâ€™t really need it.</strong> If we <em>already</em> know machine learning, taking that shiny new MOOC wonâ€™t help with applying it more effectively. Doing another Python tutorial wonâ€™t help with writing better code. Most MOOCs follow the <a href="https://en.wikipedia.org/wiki/Pareto_principle" target="_blank">Pareto Principle</a> and teach students the 20% they need to achieve 80% results. Thus, past the first or second course, our learning tapers off. (Also see Susanâ€™s view on <a href="https://www.susanshu.com/should-i-take-more-online-courses-data-science#rule-of-thumb-diminishing-marginal-returns" target="_blank">diminishing returns</a>.)</p><p>
\[\text { Diminishing returns from similar MOOCs }=1+\frac{1}{2}+\frac{1}{4}+\frac{1}{8}+\frac{1}{16}+\cdots \approx 2\]
</p><p><strong>Sometimes, new MOOCs become a reason to procrastinate, or worse, a <a href="https://en.wikipedia.org/wiki/Self-handicapping" target="_blank">self-handicap</a>.</strong> You know this is happening when you hear yourself, or something else, having these thoughts:</p>
<ul>
<li>â€œIâ€™m not able to start building that <em>until</em> I finish this MOOC specialization.â€�</li>
<li>â€œMy resume isnâ€™t getting picked up <em>because</em> I donâ€™t have certs on Spark &amp; PyTorch.â€�</li>
<li>â€œI havenâ€™t studied enough about deep learning, <em>so</em> I wonâ€™t do well in the interview.â€�</li>
</ul>
<p><strong>Watching lecture videos isnâ€™t learningâ€”itâ€™s passive consumption.</strong> We sometimes equate taking an MOOC, or reading a technical book cover to cover, with learning the material. But how often do we struggle when we try to apply the technical knowledge or skills at work? Children donâ€™t learn to ride bicycles via how-to videos. Similarly, we canâ€™t learn how to program or apply technical knowledge just solely watching videos.</p>
<h2 id="go-off-the-happy-path">Go off the happy path</h2>
<p>Most good MOOCs or tutorials will provide hands-on practice. However, that hands-on practice will lie on the <a href="https://en.wikipedia.org/wiki/Happy_path" target="_blank">happy path</a>. We can copy-paste the code and itâ€™ll work. This makes sense as thereâ€™s a lot of material to cover and we donâ€™t want to spend time debugging, doing prep work, or solving problems via trial and error. Students will lose patience, causing <a href="https://www.ft.com/content/60e90be2-1a77-11e9-b191-175523b59d1d" target="_blank">completion rates to drop</a>.</p>
<p>Being on the happy path makes it easier to complete MOOC after MOOC. However, when we try to apply what weâ€™ve learnedâ€”either at work or on a personal projectâ€”it becomes much harder. This is because weâ€™re <em>now</em> off the happy path. And this is a good thing!</p>
<p><strong>Going off the happy path is how we further our learning <em>beyond the classroom</em>.</strong> This is especially so for our field of data science and machine learning, because:</p>
<ul>
<li>Real-world data is messy and dirty, but most MOOCs or YouTube classes start with clean, structured data.</li>
<li>Most of the skills we require are technical. Thus, hands-on coding (read: <a href="https://danluu.com/teach-debugging/" target="_blank">debugging</a>) is essential to master them.</li>
<li>Experimentation is fundamental in our field. We need to try different approaches, fail, and learn beyond what can be practically taught in an MOOC or online tutorial.</li>
</ul>
<blockquote>
<p>â€œI hear and I forget. I see and I remember. I do and I understand.â€� â€“ Confucius</p>
</blockquote>
<p><strong>We go off the happy path by doing real-world projects</strong>, dirty data, <a href="https://www.google.com/search?q=cuda+errors" target="_blank">CUDA errors</a>, and all. Through projects, we learn how to define problems, apply algorithms wrongly (and correctly), google error messages, and iterate until it works. We practice resourcefulness, grit, and how to learn. These are the lessons that push us towards excellence.</p>
<p>But, I donâ€™t know enough to start a personal project!</p>
<h2 id="just-in-time-learning">Just-in-time learning</h2>
<p><strong>You just need to know enough to start; the rest youâ€™ll pick up along the way.</strong> We donâ€™t need to know Python <a href="https://wiki.python.org/moin/Generators" target="_blank">generators</a> before developing your first Python program. We donâ€™t need to know Spark before processing 2 million rows of data. We donâ€™t need to know TensorFlow before training your first machine learning model.</p>
<p><strong>Just start, and let the challenges guide you towards your next learning needs.</strong> This way, you immediately apply what youâ€™ve learned. This reinforces learning, improves retention, and increases satisfaction. Similar to <a href="https://en.wikipedia.org/wiki/Just-in-time_manufacturing" target="_blank">just-in-time</a> manufacturing, just learn whateverâ€™s needed to make progress on your project. Technical skills are perishableâ€”if we donâ€™t apply what we learn, theyâ€™ll decay.</p>
<p><strong>Apply <a href="https://en.wikipedia.org/wiki/You_aren%27t_gonna_need_it" target="_blank">YAGNI</a> to learning.</strong> Just like we donâ€™t need to add functionality until itâ€™s required, we donâ€™t need to do every new MOOC or read every new textbook. No point overwhelming ourselves with all that information and knowledge which we wonâ€™t use or apply.</p>
<div>
<blockquote><p lang="en" dir="ltr">How to become expert at thing:<br>1 iteratively take on concrete projects and accomplish them depth wise, learning â€œon demandâ€� (ie donâ€™t learn bottom up breadth wise)<br>2 teach/summarize everything you learn in your own words<br>3 only compare yourself to younger you, never to others</p>— Andrej Karpathy (@karpathy) <a href="https://twitter.com/karpathy/status/1325154823856033793?ref_src=twsrc%5Etfw">November 7, 2020</a></blockquote> 
</div>
<p>To be clear, Iâ€™m not saying that we should stop exploring and learning new things. Iâ€™m saying that we should lean towards being more focused.</p>
<p>When learning about new domains, subjects, or skills, adopt a childlike <em>exploratory</em> mindset. Donâ€™t concern ourselves with the practicality of what we learn. However, if our intent is mastery, we should adopt a <em>focused</em> mindset and learn via hands-on projects, mistakes, and feedback.</p>
<h2 id="but-but-here-are-my-reasons-for-_____">But, butâ€¦ here are my reasons for _____</h2>
<p>I often get pushback when I suggest doing a personal project instead of another MOOC, Kaggle, or further education. Hereâ€™s how some conversations go:</p>
<p><strong>â€œIâ€™m very time-constrained and donâ€™t have time for a personal project. MOOCs are self-contained and need only 2-4 hours a weekâ€�</strong></p>
<p>Yes, MOOCs are great return on time-invested for getting up to speed on a subject. But past a certain threshold of knowledge and understanding, youâ€™re going to need hands-on practice to take your learning further. AFAIK, projects are the best way to do this.</p>
<p><strong>â€�I tried doing a personal project in the past. But I got a lot of errors and had to google a lotâ€”I donâ€™t think Iâ€™m ready for them until I do more MOOCs.â€�</strong></p>
<p>Getting errors and googling for help is perfectly normal! Even the instructors who created those MOOCs do that too. Thatâ€™s how we learnâ€”by trying, failing, and overcoming.</p>
<p><strong>â€�Personal projects are too difficult. Taking an MOOC is easier.â€�</strong></p>
<p>Thatâ€™s exactly why you need to do a personal project. The difficulty you experience is the learning curveâ€”without it, thereâ€™s no learning.</p>
<p>MOOCs <em>feel</em> easier because their tutorials and assignments are structured to follow the happy path. But this means youâ€™re deliberately steered away from the hairy issues that youâ€™ll face in the real world, unlike in a personal project.</p>
<p><img src="https://eugeneyan.com/assets/mooc-jackie.jpg" loading="lazy" title="Why I can't serve ML models?!" alt="Why I can't serve ML models?!"></p>
<p><strong>â€�Doing that MOOC/Masters gives me a certificate that helps my resume.â€�</strong></p>
<p>Perhaps. Nonetheless, companies are placing <a href="https://www.cnbc.com/2018/08/16/15-companies-that-no-longer-require-employees-to-have-a-college-degree.html" target="_blank">less emphasis on educational qualifications</a>, even for technical roles. Recruiters and hiring managers are also becoming more open-minded. And in the end, from a hiring managerâ€™s perspective, what <em>really</em> counts is if you can do the work, not that cert.</p>
<p><strong>â€�The recruiter said I would be tested on technical skills and knowledge. Thus, I need to do more technical MOOCs.â€�</strong></p>
<p>To an extent, MOOCs and YouTube videos are helpful, especially for questions that test your knowledge (read: memory) or require you to know the trick (e.g., leetcode type questions).</p>
<p>However, for most interviews, youâ€™ll likely get more nebulous tasks, like designing a data pipeline, whiteboarding a machine learning API, or coding up a basic k-nearest neighbors or decision tree. These assess your ability to design and develop maintainable systems, think through edge cases, and adapt based on feedback. The hands-on practice from projects will be more helpful in such interviews</p>
<p><img src="https://eugeneyan.com/assets/interview-board.jpg" loading="lazy" title="Lets just focus on the easy questions" alt="Lets just focus on the easy questions"></p>
<p><strong>â€�What personal project should I do?â€�</strong></p>
<p>Start with something youâ€™re interested in. If youâ€™re not intrinsically interested in it, you might find difficulty finishing.</p>
<p>Aim for something you can complete over the weekends in 12 weeks, ideally, 6 - 8 weeks. Any longer and it wonâ€™t seem urgent enough (and youâ€™ll lose momentum).</p>
<p><strong>â€�Iâ€™m familiar with web scraping/ruby/excel, can my personal project be about that?â€�</strong></p>
<p>Sure. Just start somewhere and evolve it along the way.</p>
<p>Nonetheless, if youâ€™re doing a personal project to learn, youâ€™ll probably want to deliberately pick something new and unfamiliar. Or if youâ€™re doing a personal project to build your portfolio (and get a job), youâ€™ll want to look over the job requirements to make sure you address them.</p>
<p><strong>â€�But, I canâ€™t think of any interesting personal projects!â€�</strong></p>
<p>Look back on the classes and material youâ€™ve covered. Iâ€™m sure youâ€™ll find something interesting that youâ€™ll want to dig deeper into.</p>
<p>This is also a good test of whether youâ€™re interested in a discipline. If you canâ€™t think of a personal project that interests you, do you <em>really</em> want it for a career? (And the answer might be yes, for various reasons such as compensation, prestige, etc.)</p>
<p><img src="https://eugeneyan.com/assets/project-drake.jpg" loading="lazy" title="Do a personal project? Nah..." alt="Do a personal project? Nah..."></p>
<p><strong>â€�Other than personal projects, anything else you would recommend?â€�</strong></p>
<p>Nope. My <em>sole</em> recommendation is to start a personal project and learn whatever you need to complete it.</p>
<p>â€¢ â€¢ â€¢</p>
<p>In 2021, instead of taking that MOOC or watching another YouTube machine learning playlist, <a href="https://en.wikipedia.org/wiki/Learning-by-doing" target="_blank">learn by doing</a> instead.</p>
<p>Learning a programming language? Build an app, any app. Share it online and get feedback. Iterate and add new features. Learning a new machine learning technique? Find some novel data and apply it. Understand where it fails, where it shines, and how to adapt it for different data sets. Share your findings via writing online or at a meetup.</p>
<p>Learning comes from doing. Not watching videos, or reading textbooks. Start doing now.</p>
<div>
<blockquote><div lang="en" dir="ltr"><p>I think we should do less MOOCs:<br>â€¢ Most of the time we don't need it<br>â€¢ Watching MOOC videos isn't learning<br>â€¢ MOOCs are a reason to procrastinate, or worse, a self-handicap</p><p>Instead, go off the happy path and adopt just-in-time learning ðŸ‘‡<a href="https://t.co/w8qAd639HM">https://t.co/w8qAd639HM</a></p></div>— Eugene Yan (@eugeneyan) <a href="https://twitter.com/eugeneyan/status/1353898874646065152?ref_src=twsrc%5Etfw">Janua…</a></blockquote></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://eugeneyan.com/writing/you-dont-need-another-mooc/">https://eugeneyan.com/writing/you-dont-need-another-mooc/</a></em></p>]]>
            </description>
            <link>https://eugeneyan.com/writing/you-dont-need-another-mooc/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25931498</guid>
            <pubDate>Wed, 27 Jan 2021 18:01:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[EVs are supposed to be green, but the truth is a bit murkier (2019)]]>
            </title>
            <description>
<![CDATA[
Score 9 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25931107">thread link</a>) | @mgh2
<br/>
January 27, 2021 | https://www.cbc.ca/news/technology/ev-electric-vehicle-carbon-footprint-1.5394126 | <a href="https://web.archive.org/web/*/https://www.cbc.ca/news/technology/ev-electric-vehicle-carbon-footprint-1.5394126">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>Mining lithium for batteries, plus the power source they're charged from, affects an EV’s impact on the environment.</p><div><figure><div><p><img loading="lazy" alt="" srcset="" sizes="" src="https://i.cbc.ca/1.5299078.1569537058!/fileImage/httpImage/image.jpg_gen/derivatives/16x9_780/ev-chargers.jpg"></p></div><figcaption>An electric vehicle may not have a tailpipe, but it still has a carbon footprint.<!-- --> <!-- -->(Ben Nelms/CBC)</figcaption></figure><p><span><p>At gatherings of electric vehicle enthusiasts, the curious surround Rob Spreitzer and his car. Both are celebrities in these circles —&nbsp;he's known as "High Mileage Rob," having driven more than 115,000 kilometres in his Tesla Model 3 in a little more than a year of ownership.</p>  <p>No other Model 3 in Canada is believed to have reached that milestone in such a short time, and it's possible no other battery-only electric vehicle has either.</p>  <p>And not once has he stopped for gas. Never changed the oil.&nbsp;</p>  <p>"I probably saved about $10,000 last year," Spreitzer says.</p>  <p>He's also trying to save the planet by eliminating greenhouse gas emissions. His car, like other zero-emission EVs, doesn't have a tailpipe and a popular online <a href="https://calculator.carbonfootprint.com/calculator.aspx?tab=4"><u>carbon calculator</u></a> shows it has a zero-carbon output.</p>  <p>But that doesn't mean there isn't a carbon footprint.</p>  <p><span><span><div><div title="How environmentally friendly are electric cars, really?" role="button" tabindex="0"><div><div aria-labelledby="1655700035759-metadata-" title="How environmentally friendly are electric cars, really?"><div><p><img src="https://thumbnails.cbc.ca/maven_legacy/thumbnails/1015/615/electric-vehicles-environment-friendly-common-101219.jpg" alt="" loading="lazy"></p></div></div></div></div></div><span>An electric car doesn't produce emissions, but its parts still have a carbon footprint. We look at all the components of EVs, from how they're charged to what's in the battery to see how environmentally friendly they are.<!-- --> <!-- -->7:25</span></span></span></p>  <h2><strong>Where does your power come from?</strong></h2>  <p>Some EV batteries today pack 10 times as much power as an average household uses in a day. And often, those electric vehicles are being charged at home.</p>  <p>Most of the electricity generated by North American grids has some greenhouse gas emissions connected to it. So even if a car isn't belching carbon, it doesn't mean it's perfectly clean.</p>  <p>For instance, coal is about the dirtiest way to generate electricity to recharge a car battery. Powering an EV with electricity generated from coal is marginally better than burning gasoline in an internal-combustion engine, according to numbers compiled by Jennifer Dunn at Northwestern University's Center for Engineering Sustainability and Resilience.</p>  <p><span><figure><div><p><img loading="lazy" alt="" srcset="https://i.cbc.ca/1.5396097.1576270362!/fileImage/httpImage/image.jpg_gen/derivatives/original_300/ghg-emissions-by-vehicles.jpg 300w,https://i.cbc.ca/1.5396097.1576270362!/fileImage/httpImage/image.jpg_gen/derivatives/original_460/ghg-emissions-by-vehicles.jpg 460w,https://i.cbc.ca/1.5396097.1576270362!/fileImage/httpImage/image.jpg_gen/derivatives/original_620/ghg-emissions-by-vehicles.jpg 620w,https://i.cbc.ca/1.5396097.1576270362!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/ghg-emissions-by-vehicles.jpg 780w,https://i.cbc.ca/1.5396097.1576270362!/fileImage/httpImage/image.jpg_gen/derivatives/original_1180/ghg-emissions-by-vehicles.jpg 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.5396097.1576270362!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/ghg-emissions-by-vehicles.jpg"></p></div></figure></span></p>  <p>Most North American grids are composed of a mix of generating sources, from coal to hydro to nuclear, though Canada has pledged to eliminate coal-burning plants by 2030. When that mix is taken into account, charging a car generally creates less than half the carbon emissions compared to gasoline, according to Dunn.</p>  <p>It's only when electricity comes from clean, renewable sources like wind and solar that you see the most pronounced drop in EV emissions generated to power the car.</p>  <h2>Where does your battery come from?</h2>  <p>Before an electric vehicle even charges for the first time, however, one key part of its power system already has a significant carbon footprint.</p>  <p>"One really important aspect of an EV to think about is its battery," explains Dunn.</p>  <p>"For example, the material that helps power the battery is produced from a number of different metals, things like nickel and cobalt and lithium."</p>    <p>Mining and processing the minerals, plus the battery manufacturing process, involve substantial emissions of carbon.</p>  <p>Lithium mining, needed to build the lithium ion batteries at the heart of today's EVs, has also been connected to other kinds of environmental harm. There have been mass fish kills related to lithium mining in Tibet, for example. The freshwater supply is being consumed by mines in South America's lithium-rich region. Even in North America, where mining regulations are strict, harsh chemicals are used to extract the valuable metal.</p>  <p><span><figure><div><p><img loading="lazy" alt="" srcset="https://i.cbc.ca/1.5399271.1576601860!/fileImage/httpImage/image.jpg_gen/derivatives/original_300/rockwood-lithium-plant.jpg 300w,https://i.cbc.ca/1.5399271.1576601860!/fileImage/httpImage/image.jpg_gen/derivatives/original_460/rockwood-lithium-plant.jpg 460w,https://i.cbc.ca/1.5399271.1576601860!/fileImage/httpImage/image.jpg_gen/derivatives/original_620/rockwood-lithium-plant.jpg 620w,https://i.cbc.ca/1.5399271.1576601860!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/rockwood-lithium-plant.jpg 780w,https://i.cbc.ca/1.5399271.1576601860!/fileImage/httpImage/image.jpg_gen/derivatives/original_1180/rockwood-lithium-plant.jpg 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.5399271.1576601860!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/rockwood-lithium-plant.jpg"></p></div><figcaption>An aerial view of the brine pools and processing areas of the Rockwood lithium plant on the Atacama salt flat in northern Chile, the largest lithium deposit currently in production.<!-- --> <!-- -->(Ivan Alvarado/Reuters)</figcaption></figure></span></p>  <p>And all the operations are energy intensive, sometimes running on diesel generators and relying on carbon-emitting heavy machinery.</p>  <p>Adding to the cumulative effects on the environment, lithium demand is expected to at least triple by 2025, pushing more exploration and extraction globally.</p>  <h2>Second life for lithium-ion batteries&nbsp;</h2>  <p>And all that extracted raw material —&nbsp;once the batteries are worn out —&nbsp;will land somewhere.</p>  <p>It's something Andrew MacDonald at Maritime Autoparts in Debert, N.S., is thinking about. His facility recycles car parts and he says it's only a few more years before his industry will start seeing EVs and their lithium-ion batteries in the scrapyard.</p>  <p>"As pure electric vehicles come onto the market, there's less wearable parts, so it's going to change what we sell," he says.</p>  <p><span><figure><div><p><img loading="lazy" alt="" srcset="https://i.cbc.ca/1.5405916.1576955772!/fileImage/httpImage/image.JPG_gen/derivatives/original_300/andrew-macdonald.JPG 300w,https://i.cbc.ca/1.5405916.1576955772!/fileImage/httpImage/image.JPG_gen/derivatives/original_460/andrew-macdonald.JPG 460w,https://i.cbc.ca/1.5405916.1576955772!/fileImage/httpImage/image.JPG_gen/derivatives/original_620/andrew-macdonald.JPG 620w,https://i.cbc.ca/1.5405916.1576955772!/fileImage/httpImage/image.JPG_gen/derivatives/original_780/andrew-macdonald.JPG 780w,https://i.cbc.ca/1.5405916.1576955772!/fileImage/httpImage/image.JPG_gen/derivatives/original_1180/andrew-macdonald.JPG 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.5405916.1576955772!/fileImage/httpImage/image.JPG_gen/derivatives/original_780/andrew-macdonald.JPG"></p></div><figcaption>Andrew MacDonald of Maritime Autoparts is expecting to start seeing lithium-ion batteries at his recycling facility within the next few years as electric vehicles age. Problem is, it’s not clear what he should do with them.<!-- --> <!-- -->(Jill English/CBC)</figcaption></figure></span></p>  <p>MacDonald adds that his company is already receiving nickel metal hydride batteries from early-model hybrids, and is figuring out what to do with them.</p>  <p>"We do our own research, but it would be nice to have better partnerships with the OEMs [original equipment manufacturers] to understand exactly what we're dealing with, what are the best methods and procedures and policies in handling them," MacDonald says.</p>  <p>"There's lots of stuff going on in the research labs around the world, trying to figure out what to do with these things. But certainly there's a big potential for what you can do with them," he says.</p>  <p>One of those research facilities is the U.K.'s Faraday Institution, and it's looking at ways to both reduce waste and extend the usefulness of all that lithium that's being mined.</p>  <p>"There are going to be a lot of batteries that reach end of life. Out of those batteries, you're going to find very valuable applications in second life," says Gavin Harper, a Faraday Institution research fellow and the lead author of <a href="https://www.nature.com/articles/s41586-019-1682-5"><u>last month's paper on battery recycling, published in the journal </u><em><u>Nature</u></em></a>.</p>  <p><span><figure><div><p><img loading="lazy" alt="" srcset="https://i.cbc.ca/1.5342057.1572483256!/cumulusImage/httpImage/image.jpg_gen/derivatives/original_300/ev-chargers.jpg 300w,https://i.cbc.ca/1.5342057.1572483256!/cumulusImage/httpImage/image.jpg_gen/derivatives/original_460/ev-chargers.jpg 460w,https://i.cbc.ca/1.5342057.1572483256!/cumulusImage/httpImage/image.jpg_gen/derivatives/original_620/ev-chargers.jpg 620w,https://i.cbc.ca/1.5342057.1572483256!/cumulusImage/httpImage/image.jpg_gen/derivatives/original_780/ev-chargers.jpg 780w,https://i.cbc.ca/1.5342057.1572483256!/cumulusImage/httpImage/image.jpg_gen/derivatives/original_1180/ev-chargers.jpg 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.5342057.1572483256!/cumulusImage/httpImage/image.jpg_gen/derivatives/original_780/ev-chargers.jpg"></p></div><figcaption>Beyond powering cars, researchers are developing new applications for high-density lithium-ion batteries, as well as for cells when they're recycled from older cars.<!-- --> <!-- -->(Ben Nelms/CBC)</figcaption></figure></span></p>  <p>He says if reuse is considered in the initial design, applications for batteries can be wide-ranging when their state of health —&nbsp;or charging capacity —&nbsp;is no longer adequate for an electric vehicle.&nbsp;</p>  <p>"The best option companies are looking at is to remanufacture cells into new battery packs for electric vehicles," he says.</p>  <p>That means taking apart the individual lithium-ion cells that make up an EV battery, removing the unhealthy ones, and reassembling them for continued EV-use.</p>  <p>Beyond powering cars, there are other second-life applications being explored for lithium-ion cells, primarily rooted in energy grid and mobile energy storage, which can include acting as a power reserve for electric vehicle charging stations.&nbsp;</p>  <p>"In the new energy economy, things go hand in hand," says Harper.&nbsp;</p>    <p>The challenge now is moving these kinds of applications beyond research labs and cottage industries.</p>  <p>Harper says batteries aren't necessarily designed for disassembly right now, and to make it economically feasible when EVs start to see mass adoption, there's still work to be done.</p>  <p>"We need to make sure we invest time and energy to find the right way of doing things, and solutions that are to scale of what's coming down the line," he says.&nbsp;&nbsp;</p>  <h2>Getting more out of batteries</h2>  <p>Across the ocean, a Canadian research lab is working on another aspect of lithium-ion research, and quite successfully.&nbsp;</p>  <p>Nova Scotia's Dalhousie University is finding ways to extend battery range and lifespan, led by Jeff Dahn, who is something of an icon to battery players worldwide. Tesla's Elon Musk has heralded his work, and Dahn himself led a group of researchers who proved the feasibility of a <a href="http://jes.ecsdl.org/content/166/13/A3031"><u>million-mile battery</u></a>.</p>  <p><span><figure><div><p><img loading="lazy" alt="" srcset="https://i.cbc.ca/1.5399254.1576601611!/fileImage/httpImage/image.jpg_gen/derivatives/original_300/jeff-dahn.jpg 300w,https://i.cbc.ca/1.5399254.1576601611!/fileImage/httpImage/image.jpg_gen/derivatives/original_460/jeff-dahn.jpg 460w,https://i.cbc.ca/1.5399254.1576601611!/fileImage/httpImage/image.jpg_gen/derivatives/original_620/jeff-dahn.jpg 620w,https://i.cbc.ca/1.5399254.1576601611!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/jeff-dahn.jpg 780w,https://i.cbc.ca/1.5399254.1576601611!/fileImage/httpImage/image.jpg_gen/derivatives/original_1180/jeff-dahn.jpg 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.5399254.1576601611!/fileImage/httpImage/image.jpg_gen/derivatives/original_780/jeff-dahn.jpg"></p></div><figcaption>Dalhousie University’s Jeff Dahn is considered a pioneer of lithium-ion battery research. His team continues to find ways to improve the technology. <!-- --> <!-- -->(Jill English/CBC)</figcaption></figure></span></p>  <p>He's trying to not only pack more power into batteries to boost the range of electric vehicles, he's also working to increase the number of recharges possible without efficiency loss.</p>  <p>"We're trying to help make lithium ion batteries last longer, in terms of years or decades … and lower their cost," Dahn says.</p>  <p>He's also thinking beyond cars —&nbsp;into home heating and electrical needs.</p>  <p>"If you want to use renewable energy for your source of power, the sun and the wind aren't there all the time. So it means you have to be able to store electrical energy. You have to be able to store it at scale affordably. And whatever you're using to store it better last a long, long time so you don't have to replace it all the time."</p>  <p>That was a hot topic of conversation at Canada's largest electric vehicle gathering recently in Cambridge, Ont. There were discussions about how long a modern EV's batteries will last, and the best practices to extend their lifespan (some tips: don't use rapid chargers too often, don't recharge unless you really need it).</p>  <p>High Mileage Rob is perhaps one of the people most consumed by these questions. He spends more time with his Tesla than his wife, he says. And he is intent on keeping both in his life for years to come.</p>  <hr>  <p><strong>WATCH | From The National, why it can be hard for buyers to find an electric vehicle:</strong></p>  <p><span><span><div><div title="Why it’s hard to sell electric cars" role="button" tabindex="0"><div><div aria-labelledby="1655169603679-metadata-" title="Why it’s hard to sell electric cars"><div><p><img src="https://thumbnails.cbc.ca/maven_legacy/thumbnails/509/759/electric-car-hard-sell-common-091219.jpg" alt="" loading="lazy"></p></div></div></div></div></div><span>The long-standing myths about electric vehicles one reason they aren’t everywhere and subject to months-long waits. David Common looks at why and some incentives that could boost supply of electric vehicles.<!-- --> <!-- -->9:24</span></span></span></p></span></p></div></div>]]>
            </description>
            <link>https://www.cbc.ca/news/technology/ev-electric-vehicle-carbon-footprint-1.5394126</link>
            <guid isPermaLink="false">hacker-news-small-sites-25931107</guid>
            <pubDate>Wed, 27 Jan 2021 17:35:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Review of End-to-End Architectures for Speech Recognition]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25931103">thread link</a>) | @dylanbfox
<br/>
January 27, 2021 | https://www.assemblyai.com/blog/a-survey-on-end-to-end-speech-recognition-architectures-in-2021 | <a href="https://web.archive.org/web/*/https://www.assemblyai.com/blog/a-survey-on-end-to-end-speech-recognition-architectures-in-2021">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><h2>Overview</h2><p>Accuracy is the most important characteristic of a speech recognition system. While AssemblyAI’s production end-to-end approach for speech recognition is able to provide better accuracy than other commercial grade speech recognition systems, improvements could still be made to achieve human performance. As part of our core research and development efforts to continue pushing the state of the art of speech recognition accuracy, in this post, we explore speech recognition architectures that are gaining new popularity in both research and industry settings.</p><h2>1. Introduction<br></h2><p>As we continue our core research and development efforts to push the boundaries of state of the art accuracy, we begin exploring architectures for end-to-end speech recognition that are gaining relative new popularity, not only in the research domain but also in production settings in industry ([1], [2]). We are specially interested in architectures that have shown production level accuracy matching or surpassing that of conventional hybrid DNN-HMM ([3], [4]) speech recognition systems. With that in mind, we survey the following two architectures: Listen Attend and Spell (LAS, [5]), and Recurrent Neural Network Transducers (RNNT, [6]).</p><p>We survey these new architectures from a production perspective. In section 2, we report on accuracy comparisons from some of the latest research done on both LAS and RNNT ([7], [8], [2]). We also do a comparison of these techniques against Connectionist Temporal Classification (CTC, [9]) ([7], [1]), which is a more widely known end-to-end approach, and is what early versions of AssemblyAI’s <a href="https://www.assemblyai.com/">speech recognition system</a> was based on. We also a look at recent research that combines RNNT and LAS into a single system ([8], [2]).</p><p>In section 3, keeping our focus on production grade speech recognition, we compare LAS and RNNT models from the perspective of feature parity. We focus on contextualization ([10], [1]), inverse text normalization ([11], [1], [8]), word timestamps, and the possibility of doing real time speech recognition ([1], [2]).</p><p>And we finish this post in section 4, with high level conclusions about our survey as well as next steps for future blog posts.</p><h2>2. Accuracy<br></h2><p>While human parity speech recognition accuracy has been reached for some research data sets ([12]), word error rates (WER) for industrial production grade applications in challenging acoustic environments is far from human level. One example of such domain is spontaneous telephone conversations, where, even in research datasets, human level parity has not yet been achieved ([13]).</p><p>We set our focus in this section on LAS and RNNT systems tested on production data, and not on research datasets. We avoid looking into research datasets as they are easily overfit by models that do not generalize well to real live audio signals. We want to keep our focus on datasets that contain challenging characteristics such as channel noise, compression, ambient noise, crosstalk, accents and speaker diversity.</p><h3>2.1 LAS vs RNNT<br></h3><p>When comparing accuracy of LAS and RNNT based architectures, the consensus seems to be that LAS has better accuracy than RNNT. [7] compares both LAS and RNNT models using 12500 hours of production voice-search traffic, artificially distorted by adding noise and by simulating room acoustics. WER is reported on both dictation as well as voice search utterances. Both LAS and RNNT use the same encoder neural network architecture and size. Their parameters however, are different and were initialized to those of a converged CTC trained network with the same encoder architecture. The decoders also have the same architecture, same number of layers, size and output the set of 26 lower case letters plus numerals, space and punctuation symbols. As a result, the only difference in terms of numbers of parameters lies in the RNNT joint network and the LAS attention mechanism. Neither the LAS nor the RNNT model use any sort of external language model. Table <a href="#">1</a> summarizes their results showing LAS performing better in general.</p><p>‍</p><figure><p><img src="https://assets-global.website-files.com/5fbd459f3b05914cf70496d7/601023b3c2415b14faf3fee3_Screen%20Shot%202021-01-26%20at%208.13.59%20AM.png" loading="lazy" alt=""></p><figcaption>Table 1:&nbsp;Accuracy of RNNT vs LAS</figcaption></figure><p>[8] also shows LAS performing better in general. They emphasize RNNT models lag in quality while LAS shows competitive performance when compared to hybrid DNN-HMM models ([11]). [8] also compares the WERs of LAS with RNNT. Similar to [7], the encoder and decoder networks are the same for both RNNT and LAS, differing only on the joint and attention networks. Both predict outputs from a set of 4096 word pieces. The training data used is the same for both models and consists of 30,000 hours of voice search training data, corrupted with added noise and room acoustics. The models are tested on two test sets: one made of utterances shorter than 5.5 seconds (Short Utts.) and another one made of utterances longer than 5.5 seconds (Long Utts.). Results showing LAS performing better can be seen in table 1. LAS shows degrading accuracy on long utterances, which is attributed to the attention mechanism as explained in [14].</p><p>While [2] does not explicitly compare the accuracy rates of LAS and RNNT models, they do mention, similar to [8], that under low latency constraints the accuracy of LAS outperforms conventional DNN-HMM models, while RNNT models do not.</p><h3>2.2 LAS and RNNT vs CTC<br></h3><p>Comparisons with <a href="https://www.assemblyai.com/blog/end-to-end-speech-recognition-pytorch">CTC based models</a> are not as simple as comparisons just between LAS and RNNT. The main reason being that a CTC model is highly dependent on the use of an external language model to have acceptable accuracy. LAS and RNNT models do not need an external language model due to the existence of a decoder component in the model.</p><p>[7] compares LAS, RNNT and CTC models without any external LM, where the encoder architecture and size is the same across all three models. CTC’s accuracy without any external LM, which is shown in table 2, is significantly lower than RNNT and LAS. The rest of the experimental details are the same as those described section 2.1.</p><p>[1] compares RNNT and CTC, but with significant differences in each architecture. The CTC model consists of 6 LSTM layers with each layer having 1200 cells and a 400 dimensional projection layer. The model outputs 42 phoneme targets through a softmax layer. Decoding is preformed with a 5gram first pass language model and a second pass LSTM LM rescoring model. The RNNT model’s encoder consists of 8 LSTM layers with 2048 cells each and a 640 dimensional projection layer. A time reduction layer of factor 2 is inserted after the second layer of the encoder. The prediction network has 2 LSTM layers each with 2048 cels and a 640 dimensional projection layer. The joint network has 640 hidden units. The output layer models 4096 word pieces. The size of the RNNT model is 120MB, while the size of the CTC model is 130MB.</p><p>[1] performs training with 27500 hours of voice search and dictation data, artificially corrupted to simulate room acoustics and noise. Table 2 shows the comparison between their CTC and RNNT models on both a voice search and a dictation test sets, showing the RNNT model being significantly better.</p><p>‍</p><figure><p><img src="https://assets-global.website-files.com/5fbd459f3b05914cf70496d7/6010241853756e7b2a8e4771_Screen%20Shot%202021-01-26%20at%208.15.41%20AM.png" loading="lazy" alt=""></p><figcaption>Table 2:&nbsp;Accuracy of RNNT and LAS&nbsp;vs CTC</figcaption></figure><h3>2.3 Combining LAS and RNNT<br></h3><p>While LAS is perceived as having better accuracy, RNNT models are perceived to have production quality features, such as streaming capabilities, that make them more desirable.</p><p>With the objective of bridging the accuracy gap between both architectures, [8] and [2] develop a combination of RNNT and LAS models. RNNT is used during first pass decoding, and LAS is used as a second pass rescoring model.</p><p>The experimental details of [8] with respect to separate RNNT and LAS models are described in section 2.1. The two pass experiments use the same architecture for both and LAS and RNNT. The number of parameters are the same as well but this time the encoder parameters are shared between them. Training is done in three steps. First an RNNT model is converged. Then the RNNT encoder is frozen and a LAS decoder is trained with it. Finally a combined loss is used to retrain both the RNNT and LAS models (with a shared encoder) together. Table <a href="#">3</a> shows the rescoring approach significantly improves the accuracy of the RNNT model. It also improves the LAS weakness with respect to longer utterances.</p><p>[2] also implements LAS rescoring on a second pass, where the first pass is an RNNT model. Besides using search data during training they also use data from multiple other domains (e.g.: far field, phone) and accented speech from countries other than the U.S. The number of hours used for training is not specified, but the model architecture details related to LAS rescoring are similar: A shared encoder is used between the RNNT model and the LAS model, and the LAS model is used to rescore hypotheses coming from the RNNT model. They add an additional LAS encoder layer in between the shared encoder and the LAS decoder. Table 3 shows that LAS rescoring significantly improves RNNT accuracy.</p><p>More importantly, table 3 shows the combination of RNNT and LAS beating a conventional HMM-RNN hybrid model. The acoustic model of the conventional model outputs context dependent phones, and uses a phonetic dictionary with close to 800,000 words. A 5-gram language model is used during first pass decoding and a MaxEnt language model is used for second pass rescoring. The total size of the conventional model is around 87 GBs. The RNNT+LASS model’s size is 0.18 GBs. The RNNT model has 120 million parameters and the LAS model (both the additional encoder and the decoder) have 57 million additional parameters. Parameters are quantized to be 8bit fixed point.</p><p>‍</p><figure><p><img src="https://assets-global.website-files.com/5fbd459f3b05914cf70496d7/6010247b5c33d430166ed715_Screen%20Shot%202021-01-26%20at%208.17.06%20AM.png" loading="lazy" alt=""></p><figcaption>Table 3:&nbsp;Accuracy of RNNT and&nbsp;LAS&nbsp;rescoring</figcaption></figure><h2>3. Feature Parity<br></h2><p>While accuracy is the most important characteristic of a speech recognition system, there are many other features that contribute to usability and cost. In this section we explore LAS and RNNT from the perspective of features such as contextualization, inverse text normalization, timestamps and real time speech recognition.<br></p><h3>3.1 Contextualization<br></h3><p>The words …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.assemblyai.com/blog/a-survey-on-end-to-end-speech-recognition-architectures-in-2021">https://www.assemblyai.com/blog/a-survey-on-end-to-end-speech-recognition-architectures-in-2021</a></em></p>]]>
            </description>
            <link>https://www.assemblyai.com/blog/a-survey-on-end-to-end-speech-recognition-architectures-in-2021</link>
            <guid isPermaLink="false">hacker-news-small-sites-25931103</guid>
            <pubDate>Wed, 27 Jan 2021 17:34:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[My bi-weekly newsletter on all things Elixir and Erlang]]>
            </title>
            <description>
<![CDATA[
Score 30 | Comments 12 (<a href="https://news.ycombinator.com/item?id=25930509">thread link</a>) | @p5v
<br/>
January 27, 2021 | https://www.getrevue.co/profile/this-week-in-elixir-and-erlang | <a href="https://web.archive.org/web/*/https://www.getrevue.co/profile/this-week-in-elixir-and-erlang">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="profile">
<div>
<section id="profile-info">
<section id="profile-image">
<figure title="This Week in Elixir and Erlang"><img alt="This Week in Elixir and Erlang" src="https://s3.amazonaws.com/revue/profiles/images/000/074/256/thumb/This_Week_in_Elixir_and_Erlang_Cover_Large.png?1611730657"></figure>
</section>
<section id="profile-signup">
<header>
<hgroup>

<address>By Preslav Rachev</address>
<h2 title="This Week in Elixir and Erlang - A curated bi-weekly portion of links, podcasts, and news shared by the Elixir and Erlang community. Now, directly in your inbox. ✉️

Feel free to check out past issues on my website: https://preslav.me/tag/this-week-in-elixir-and-erlang/"><p>A curated bi-weekly portion of links, podcasts, and news shared by the Elixir and Erlang community. Now, directly in your inbox. ✉️</p>

<p>Feel free to check out past issues on my website: <a href="https://preslav.me/tag/this-week-in-elixir-and-erlang/" rel="nofollow">https://preslav.me/tag/this-week-in-elixir-and-erlang/</a></p></h2>
</hgroup>
</header>
<section id="profile-stats">
<span><a href="#archive">1 issue</a></span>
<span><span>
<a target="_blank" href="https://preslav.me/"><span></span>
</a></span>
<span>
<a target="_blank" href="http://twitter.com/preslavrachev"><span></span>
</a></span>
</span>
<section>
<form id="new_member" action="/profile/this-week-in-elixir-and-erlang/add_subscriber" accept-charset="UTF-8" method="post">
<div id="profile-form">
<div id="profile-form-fields">
<p><label for="member_email">Subscribe to our newsletter</label>
<label>By subscribing, you agree with Revue’s <a target="_blank" href="https://www.getrevue.co/terms?ref=Revue+Profile">Terms</a> and <a target="_blank" href="https://www.getrevue.co/privacy?ref=Revue+Profile">Privacy Policy</a>.</label></p><div>

</div>


</div>
</div>
</form></section>

</section>
</section>
</section>
</div>
</article></div>]]>
            </description>
            <link>https://www.getrevue.co/profile/this-week-in-elixir-and-erlang</link>
            <guid isPermaLink="false">hacker-news-small-sites-25930509</guid>
            <pubDate>Wed, 27 Jan 2021 16:55:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Automating my job with GPT-3]]>
            </title>
            <description>
<![CDATA[
Score 418 | Comments 91 (<a href="https://news.ycombinator.com/item?id=25930190">thread link</a>) | @daolf
<br/>
January 27, 2021 | https://blog.seekwell.io/gpt3 | <a href="https://web.archive.org/web/*/https://blog.seekwell.io/gpt3">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><article id="block-gpt3"><h2 id="block-0b792f0a345649b8998578511252d5aa"><span id="0b792f0a345649b8998578511252d5aa"></span><span><span>Using GPT-3 to generate database-ready SQL to answer business questions</span></span></h2><p><span><span>As an analyst, I spend a lot of my time writing SQL (or other code) to answer questions about our business. These questions can range from simple customer support queries ("Does user X have the right plan?") to evaluating KPI's and growth metrics ("How many users signed up in the last month and what percent of those converted to paid?") to the more open-ended ("How much revenue will we have in 12 months?").</span></span></p><div id="block-3e9cd828f5334adda85fdbfb4b4cc69a"><div id="block-71f39a4ef039454287b8caa8e53eea89"><p><span><span>To make my job easier, I try to automate as many of these questions as I can. My company, </span><span><a href="https://seekwell.io/blog-gpt3" target="_blank" rel="noopener noreferrer">SeekWell</a></span><span>, builds awesome tools to help with this, like a unified team SQL repository and seamless scheduling of queries, reports, and alerts. Many things, though, like actually writing SQL code, are difficult to automateâ€”or at least have been. </span></span></p></div><div id="block-05f0094e96104a55b608aecb7c35791b"><div id="block-fd67e43c00754a16b725e54946093bb4"><p><img src="https://api.super.so/asset/blog.seekwell.io/74a62dc5-b3f1-45ba-a090-36e1f21cd166.gif" alt="image" width="100%" height="auto" objectfit="contain" objectposition="center" loading="lazy"></p></div></div></div><h3 id="block-f0f41f92c9ed46f88da1c7319c105013"><span id="f0f41f92c9ed46f88da1c7319c105013"></span><span><span>Enter GPT-3</span></span></h3><p><span><span><a href="https://openai.com/" target="_blank" rel="noopener noreferrer">Openai</a></span><span>'s </span><span><a href="https://beta.openai.com/docs/introduction" target="_blank" rel="noopener noreferrer">GPT-3</a></span><span> is starting to break the conventional wisdom of what tasks can and can't be automated. At the most basic level, GPT-3 is a text-completion engine, trained on huge swaths of the internet. It takes inputted text and returns the text that it thinks would appear next. Many have already used it to generate HTML and CSS </span><span><a href="https://twitter.com/sharifshameem/status/1282676454690451457?s=20" target="_blank" rel="noopener noreferrer">code</a></span><span> from specific design instructions. Others have made </span><span><a href="https://www.theverge.com/2020/8/16/21371049/gpt3-hacker-news-ai-blog" target="_blank" rel="noopener noreferrer">#1 trending blog posts</a></span><span> generated mostly by GPT-3 with some creative prompts.</span></span></p><p><span><span>In my case, since so much of my job is writing SQL, I want to be able to describe a question in plain English and have GPT-3 convert it into the SQL code that, if executed on my Postgres database, would answer the question. </span></span></p><p><span><span>To accomplish this, I found more success using </span><span><a href="https://beta.openai.com/docs/engines/the-instruct-series-beta" target="_blank" rel="noopener noreferrer">GPT-3 Instruct</a></span><span> (still in beta) than the more generalized GPT-3 engines. GPT-3 Instruct (in particular,</span><span><a href="https://beta.openai.com/playground?model=davinci-instruct-beta" target="_blank" rel="noopener noreferrer"> davinci-instruct</a></span><span>) lets you give specific instructions, like "Only respond in correct SQL syntax", that guides GPT-3's responses. If you're interested in trying it out, you can sign up for the waitlist for the GPT-3 API </span><span><a href="https://share.hsforms.com/1Lfc7WtPLRk2ppXhPjcYY-A4sk30" target="_blank" rel="noopener noreferrer">here</a></span><span>. </span></span></p><p><span><span>Below, I'll detail my experience with the API. In each example, I'll include a gif of asking GPT-3 a question. Below the gif will be the input question (generated by me, in green) and GPT-3's response translating it into SQL (generated by GPT-3, in blue). I'll also include my instructions to GPT-3 (in yellow) and examples I fed GPT-3 (in orange). </span></span></p><p><span><span>Here's the first instruction I gave it, a question, and the response from GPT-3:</span></span></p><div id="block-48ecab24b59a4404bae7f20fb8caf501"><p><img src="https://api.super.so/asset/blog.seekwell.io/d99a5fe5-1ca9-43f2-a233-818d878160ac.gif" alt="image" width="100%" height="auto" objectfit="contain" objectposition="center" loading="lazy"></p></div><p><span><span><strong>Instruction:</strong></span><span> Given an input question, respond with syntactically correct PostgreSQL. Be creative but the SQL must be correct.</span></span></p><p><span><span><strong>Input:</strong></span><span> how many users signed up in the past month?</span></span></p><p><span><span><strong>GPT-3 Response: </strong></span><span>SELECT COUNT(*) FROM users
WHERE signup_time &gt; now() - interval '1 month'</span></span></p><p><span><span>Woah. I never gave it my database schema but it assumes I have a table called "users" (which is accurate) and that there's a timestamp field called "signup_time" for when a user signed up. Pretty logical. It also knew the correct way to subtract a month from today's date in PostgreSQL (now() - interval '1 month') without seeing an example. Pretty cool!</span></span></p><p><span><span>To give GPT-3 a little more context, I'll add information about my database schema to the instruction. My new Instruction: </span></span></p><p><span><span><strong>Instruction:</strong></span><span> Given an input question, respond with syntactically correct PostgreSQL. Be creative but the SQL must be correct. Only use tables called "users" and "charges". The "users" table has columns: id (integer), signup_dt (timestamp), email (character varying), and plan_type (character varying). The "charges" table has columns: amount (bigint), user_id (integer), and charge_dt (timestamp).</span></span></p><p><span><span>Now I'll try asking another question, and see if GPT-3 can respond based on my actual database:</span></span></p><div id="block-a4da842d10ee45bdaee9837e612a0afb"><p><img src="https://api.super.so/asset/blog.seekwell.io/85ecbb57-3212-4ebd-8d13-534d98573a64.gif" alt="image" width="100%" height="auto" objectfit="contain" objectposition="center" loading="lazy"></p></div><p><span><span><strong>Input:</strong></span><span> how much revenue did we have in the past 7 days?</span></span></p><p><span><span><strong>GPT-3 Response:</strong></span><span> SELECT SUM(amount) FROM charges WHERE charge_dt &gt; now() - interval '7 days'</span></span></p><p><span><span>Nice. I gave it a little more information on the tables and columns in my database, and it correctly inferred that "amount" = "revenue" and knew to SUM() that amount for the past 7 days of charges to answer the question. Clearly, it already knows some basic SQL syntax, and can make inferences about what I mean.</span></span></p><h3 id="block-77e3952dbf77411c987d2139118a5c14"><span id="77e3952dbf77411c987d2139118a5c14"></span><span><span>Priming GPT-3 with examples</span></span></h3><p><span><span>I'll try another question but first it might make sense to explicitly tell GPT-3 the columns in my tables via a simple example. Examples are a great way to give GPT-3 context and flesh out subtleties that might not be obvious in just an instruction. I found this helpful for really hammering into it which columns and tables are eligible to use (GPT-3 sometimes likes to "invent" columns to make answering the question easier). Here are the examples I added to the prompt:</span></span></p><p><span><span><strong>Input:</strong></span><span> select all available columns from users table.
</span><span><strong>Output:</strong></span><span> SELECT id, signup_dt, email, plan_type FROM users</span></span></p><p><span><span><strong>Input:</strong></span><span> select all available columns from charges table.
</span><span><strong>Output:</strong></span><span> SELECT amount, user_id, and charge_dt FROM charges</span></span></p><p><span><span>Now with those examples fed to GPT-3, I'll ask another question:</span></span></p><div id="block-58c943723b154475bf698435c315d98d"><p><img src="https://api.super.so/asset/blog.seekwell.io/b349a134-f123-4451-bee0-b1ab88b3a3dc.gif" alt="image" width="100%" height="auto" objectfit="contain" objectposition="center" loading="lazy"></p></div><p><span><span><strong>Input:</strong></span><span> what was the largest payment amount made in the past 30 days?</span></span></p><p><span><span><strong>GPT-3 Response:</strong></span><span> SELECT MAX(amount) FROM charges WHERE charge_dt &gt; NOW() - INTERVAL '30 days'</span></span></p><p><span><span>It knew to use MAX(amount) to get the largest payment and set the date condition correctly without seeing an example on how to subtract a number of days from the current date. It's doing pretty well, but let's try something a little trickier now, using the same instruction and examples:</span></span></p><div id="block-1af088fb733248dc82c23d45d4f90707"><p><img src="https://api.super.so/asset/blog.seekwell.io/bc58b0bf-c5ab-46c6-903c-989e2d5bd0c0.gif" alt="image" width="100%" height="auto" objectfit="contain" objectposition="center" loading="lazy"></p></div><p><span><span><strong>Input:</strong></span><span> when did user with email </span><span><a href="mailto:brian@seekwell.io" target="_blank" rel="noopener noreferrer">brian@seekwell.io</a></span><span> make his last payment?</span></span></p><p><span><span><strong>GPT-3 Response:</strong></span><span> SELECT MAX(charge_dt) FROM charges WHERE user_id = 1 AND email = 'brian@seekwell.io'</span></span></p><p><span><span>Okay, not </span><span><em>quite </em></span><span>right. The "charges" table doesn't have a column for email, so this query would fail. I also never said the user with email = "brian@seekwell.io" has user_id = 1â€”don't know where it got that idea from. To answer the question correctly, you would have to join the "charges" table with the "users" table since only "users" has an email column. </span></span></p><p><span><span>Since it's a big leap to know to join those tables on </span><span><a href="http://users.id/" target="_blank" rel="noopener noreferrer">users.id</a></span><span> = charges.user_id (even if that seems perfectly logical to a human analyst), I'll give GPT-3 an example of a "join" so it has something to go off of:</span></span></p><p><span><span><strong>Input:</strong></span><span> when did jane</span><span><a href="mailto:mike@seekwell.io" target="_blank" rel="noopener noreferrer">@seekwell.io</a></span><span> make her first payment?
</span><span><strong>Output:</strong></span><span> SELECT MIN(charge_dt) as last_payment_dt from charges LEFT JOIN
users ON </span><span><a href="http://users.id/" target="_blank" rel="noopener noreferrer">users.id</a></span><span> = charges.user_id
WHERE users.email = 'jane</span><span><a href="mailto:mike@seekwell.io" target="_blank" rel="noopener noreferrer">@seekwell.io</a></span><span>'</span></span></p><p><span><span>Now I'll try again:</span></span></p><div id="block-f72440390edc4af5a45a8c530582b236"><p><img src="https://api.super.so/asset/blog.seekwell.io/a9502b6e-cadf-4c9f-bc2c-f52c6dfb1a15.gif" alt="image" width="100%" height="auto" objectfit="contain" objectposition="center" loading="lazy"></p></div><p><span><span><strong>Input:</strong></span><span> when did user with email </span><span><a href="mailto:brian@seekwell.io" target="_blank" rel="noopener noreferrer">brian@seekwell.io</a></span><span> make his last payment?</span></span></p><p><span><span><strong>GPT-3 Response:</strong></span><span> SELECT MAX(charge_dt) as last_payment_dt from charges LEFT JOIN users ON </span><span><a href="http://users.id/" target="_blank" rel="noopener noreferrer">users.id</a></span><span> = charges.user_id WHERE users.email = '</span><span><a href="mailto:brian@seekwell.io" target="_blank" rel="noopener noreferrer">brian@seekwell.io</a></span><span>'</span></span></p><p><span><span>So maybe this made it a little </span><span><em>too </em></span><span>easy based on the example, but it correctly changed MIN() â†’ MAX() and replaced the email with the one I asked forâ€”so it wasn't a total gimme. Let's try another level of difficulty, but first, I'll add in a few more examples to provide more context and improve the responses. New examples:</span></span></p><p><span><span><strong>Input: </strong></span><span>how many users signed up in the past 30 days?
</span><span><strong>Output:</strong></span><span> SELECT COUNT(*) FROM users WHERE signup_dt &gt;= now() - interval '30 days'</span></span></p><p><span><span>I</span><span><strong>nput:</strong></span><span> when did user with email </span><span><a href="mailto:brian@seekwell.io" target="_blank" rel="noopener noreferrer">brian@seekwell.io</a></span><span> sign up?
</span><span><strong>Output:</strong></span><span> SELECT signup_dt FROM users WHERE email = 'brian@seekwell.io'</span></span></p><p><span><span><strong>Input:</strong></span><span> how much revenue did we have in the past 7 days?
</span><span><strong>Output:</strong></span><span> SELECT SUM(amount) from charges WHERE charge_dt &gt;= now() - interval '7 days'</span></span></p><p><span><span><strong>Input:</strong></span><span> how much revenue did we have from 10-01-20 through 11-15-20?
</span><span><strong>Output:</strong></span><span> SELECT SUM(case when charge_dt&gt;= '10-01-20'::date and charge_dt &lt; '11-15-20'::date then amount else 0 end) as revenue
FROM charges</span></span></p><p><span><span><strong>Input:</strong></span><span> how much revenue have we had from users that signed up in the last 6 months?
</span><span><strong>Output:</strong></span><span> SELECT SUM(charges.amount) FROM users INNER JOIN
charges ON </span><span><a href="http://users.id/" target="_blank" rel="noopener noreferrer">users.id</a></span><span> = charges.user_id
WHERE users.signup_dt&gt;= now() - interval '6 months'</span></span></p><p><span><span><strong>Input:</strong></span><span> when did user with email </span><span><a href="mailto:brian@seekwell.io" target="_blank" rel="noopener noreferrer">brian@seekwell.io</a></span><span> make his first payment?
</span><span><strong>Output:</strong></span><span> SELECT MIN(charge_dt) as last_payment_dt from users INNER JOIN
charges ON </span><span><a href="http://users.id/" target="_blank" rel="noopener noreferrer">users.id</a></span><span> = charges.user_id
WHERE users.email = 'brian@seekwell.io'</span></span></p><p><span><span><strong>Input:</strong></span><span> how many new users signed up in each of the last 2 months?
</span><span><strong>Output:</strong></span><span> SELECT sum(case when signup_dt&gt;= now() - interval '1 month' then 1 else 0 end) as signups_this_month,
sum(case when signup_dt&gt;= now() - interval '2 months' and signup_dt &lt; now() - interval '1 month'  then 1 else 0 end) as signups_last_month
FROM users</span></span></p><p><span><span>These examples give it some basic queries so it's more familiar with my database and the specific terms and concepts of my use case (like that a "paid user" means their plan_type="pro"). I also gave it a taste of some more advanced concepts like aggregating a metric (revenue) between 2 dates. Now I'll try something harder:</span></span></p><div id="block-6441ce9d88ce4930a612ba57661ab84d"><p><img src="https://api.super.so/asset/blog.seekwell.io/7a7fdfbb-5a5e-40e3-8190-551be566af21.gif" alt="image" width="100%" height="auto" objectfit="contain" objectposition="center" loading="lazy"></p></div><div id="block-18b369cf81324662a709ad4fbb328dda"><p><span><span><strong>Input:</strong></span><span> how many payments has user with email </span><span><a href="mailto:joe@freshpizza.com" target="_blank" rel="noopener noreferrer">joe@freshpizza.com</a></span><span> made?</span></span></p></div><p><span><span><strong>GPT-3 Response:</strong></span><span> SELECT COUNT(*) FROM users INNER JOIN  charges ON </span><span><a href="http://users.id/" target="_blank" rel="noopener noreferrer">users.id</a></span><span> = charges.user_id WHERE users.email = 'joe@freshpizza.com'</span></span></p><p><span><span>Cool! GPT-3 intuited that COUNT() was the appropriate expression here, knew to join the "users" with the "charges" table, and correctly set the email to the one that I asked about. Another question for GPT-3:</span></span></p><div id="block-ffa8bb2d8599471281fb42c295d51031"><p><img src="https://api.super.so/asset/blog.seekwell.io/dc73f28b-a0c0-4ccd-9713-af5f77c72710.gif" alt="image" width="100%" height="auto" objectfit="contain" objectposition="center" loading="lazy"></p></div><p><span><span>I</span><span><strong>nput:</strong></span><span> how much revenue have we received from users with an email ending in '</span><span><a href="http://seekwell.io/" target="_blank" rel="noopener noreferrer">seekwell.io</a></span><span>' in the last 3 months?</span></span></p><p><span><span><strong>GPT-3 Response:</strong></span><span> SELECT SUM(charges.amount) FROM users INNER JOIN charges ON </span><span><a href="http://users.id/" target="_blank" rel="noopener noreferrer">users.id</a></span><span> = charges.user_id WHERE users.email LIKE '%</span><span><a href="http://seekwell.io/" target="_blank" rel="noopener noreferrer">seekwell.io</a></span><span>%' AND users.signup_dt&gt;= now() - interval '3 months'</span></span></p><p><span><span>Perfect! It knew that "email ending in seekwell.io" translated in SQL to "</span><span><a href="http://users.email/" target="_blank" rel="noopener noreferrer">users.email</a></span><span> LIKE '%seekwell.io%' " (even though it hadn't seen that before) and took the sum of all charges for users matching that condition. And another: </span></span></p><div id="block-1ee818b1773e4f0dbe354d9931e0cff2"><p><img src="https://api.super.so/asset/blog.seekwell.io/062641b3-8814-4823-8249-9d47690082bc.gif" alt="image" width="100%" height="auto" objectfit="contain" objectposition="center" loading="lazy"></p></div><p><span><span><strong>Input:</strong></span><span> how much revenue did we have between June 1st and August 1st 2020?</span></span></p><p><span><span><strong>GPT-3 Response:</strong></span><span> SELECT SUM(case when charge_dt &gt;= '06-01-2020'::date and charge_dt &lt; '08-01-2020'::date then amount else 0 end) as revenue FROM charges</span></span></p><p><span><span>This one was a little easier since I already taught it how to get revenue from 10-01-20 through 11-15-20, but it did know to convert June 1st and August 1st to their appropriate date formats in SQL ('06-01-2020' and '08-01-2020' respectively). If it had just replaced the dates from my example with "June 1st" and "August 1st" then I'd know …</span></span></p></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.seekwell.io/gpt3">https://blog.seekwell.io/gpt3</a></em></p>]]>
            </description>
            <link>https://blog.seekwell.io/gpt3</link>
            <guid isPermaLink="false">hacker-news-small-sites-25930190</guid>
            <pubDate>Wed, 27 Jan 2021 16:27:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Data fetching on the web still sucks]]>
            </title>
            <description>
<![CDATA[
Score 150 | Comments 83 (<a href="https://news.ycombinator.com/item?id=25930177">thread link</a>) | @bcherny
<br/>
January 27, 2021 | https://performancejs.com/post/hde6a90/Data-Fetching-on-the-Web-Still-Sucks | <a href="https://web.archive.org/web/*/https://performancejs.com/post/hde6a90/Data-Fetching-on-the-Web-Still-Sucks">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p>It’s 2021, and data fetching on the web still sucks. This is crazy!</p>
<p>If you’re building a web app at scale you have plenty of options for data management:</p>
<ul>
<li><code>fetch</code>, <code>XMLHTTPRequest</code>, etc. (REST)</li>
<li><a href="https://swagger.io/">Swagger</a> (REST)</li>
<li><a href="https://github.com/Netflix/falcor">Falcor</a> (REST)</li>
<li><a href="https://github.com/apollographql/apollo-client">Apollo</a> (GraphQL)</li>
<li><a href="https://github.com/facebook/relay">Relay</a> (GraphQL)</li>
<li><a href="https://github.com/protobufjs/protobuf.js">Protobuf</a></li>
<li><a href="https://github.com/grpc/grpc-node">gRPC</a></li>
<li>…</li>
</ul>
<p>But none of these do everything well. What do you need to do well to be a good data fetching library?</p>
<h2>Fetching Data</h2>
<ul>
<li><strong>Consistency when fetching data</strong>. When your app fetches new data, the UI should automatically update everywhere that data is used.</li>
<li><strong>Request batching</strong>. When multiple requests are made at the same time, they should be combined into one request, when reasonable, to avoid hitting browser-imposed concurrency limits.</li>
<li><strong>Avoiding network waterfalls</strong>. When fetching data for a component, you should make one request that includes data for all its descendents too, to avoid lots of network round trips. GraphQL solves this with fragments, but it’s still painful in modern clients (eg. Relay does this by requiring you  manually compose fragments up the React tree so they’re fetched together, then pass fragment pointers down the tree to tell Relay where to look for fetched data; it also requires a compilation step).</li>
<li><strong>UX when fetching data</strong>. It’s a big burden for engineers to have to manually add loading spinners and error states, and engineers often forget.</li>
<li><strong>Colocation</strong>. You should declare data dependencies close to where they’re used, ideally in the same file. Same principle as colocating CSS with your components.</li>
<li><strong>File size</strong>. You shouldn’t have to ship kilobytes of metadata describing your data schema to clients in order to fetch data.</li>
<li><strong>Type safety</strong>. Your code should know what type of data it got from the server.</li>
<li><strong>Versioning</strong>. Updating your data model should be backwards-compatible; clients should be forwards-compatible.</li>
<li><strong>Realtime updates</strong>. Sometimes, you want data to be pushed, not pulled (eg. for things like notifications). But the APIs for pushing and pulling data are often different, both on the client and on the server.</li>
</ul>
<h2>Updating Data</h2>
<ul>
<li><strong>Consistency when updating data</strong>. When you update a piece of data, your data fetching library should automatically refetch dependent data that will change after the request completes (eg. if you update <code>Person.FirstName</code>, <code>Person.FullName</code> should automatically be refetched).</li>
<li><strong>Optimistic updates</strong>. The UI should optimistically render the success state before a server response comes back, if there’s a high chance the request will succeed. This makes your UI feel snappy and fun to use. Today’s data fetching libraries make this a lot of manual work.</li>
<li><strong>Request queueing</strong>. Requests that depend on one another need to be queued; independent requests can be sent in parallel. Otherwise, network weather and server queuing can cause your client to end up in a state that’s inconsistent with the server.</li>
<li><strong>UX when updating data</strong>. Product engineers shouldn’t need to manually render loading spinners and success and error notifications.</li>
<li><strong>Durability when updating data</strong>. Exponential backoff for retrying idempotent requests and idempotence tokens for network failures; eager persistance to disk for client/server failures.</li>
<li><strong>Type safety</strong>. You shouldn’t be able to send invalid input to the server, for some definition of invalid.</li>
<li><strong>Versioning</strong>. Updates to your mutation APIs should be backwards-compatible; clients should be forwards-compatible.</li>
</ul>
<h2>Why?</h2>
<p>I think the reason this hasn’t been solved is it’s a hard problem that’s at the intersection of a bunch of fast-moving technologies:</p>
<ol>
<li>Programming languages (to infer what data depends on what)</li>
<li>Databases (client-side stores are small databases)</li>
<li>Server APIs and protocols (REST, GraphQL, RPC, etc.)</li>
<li><s>UI frameworks</s> (at this point, React has won)</li>
<li>User experience and perceived performance</li>
</ol>
<p>So far, every attempt at solving data fetching has either tightly coupled all of these layers, leading to trouble gaining mass adoption (think <a href="https://www.meteor.com/">Meteor</a>); other solutions have tackled just one layer, ignoring the rest. This smells to me like the abstractions &amp; APIs for each layer are wrong: you shouldn’t need tight coupling to solve data fetching. Instead, you need better abstractions.</p>
<p>Is this a problem that can be solved?</p>
</div></div></div>]]>
            </description>
            <link>https://performancejs.com/post/hde6a90/Data-Fetching-on-the-Web-Still-Sucks</link>
            <guid isPermaLink="false">hacker-news-small-sites-25930177</guid>
            <pubDate>Wed, 27 Jan 2021 16:26:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Syngen: A library for audio game development]]>
            </title>
            <description>
<![CDATA[
Score 50 | Comments 10 (<a href="https://news.ycombinator.com/item?id=25930148">thread link</a>) | @ClawsOnPaws
<br/>
January 27, 2021 | https://shiftbacktick.io/code/2020/10/31/introducing-syngen.html | <a href="https://web.archive.org/web/*/https://shiftbacktick.io/code/2020/10/31/introducing-syngen.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main">
      <div>
        <article>
          
          <div>
            <p>Over the past year I’ve used web technologies to create audio games like soundStrider and participate in numerous game jams.
With syngen I’m releasing my tools as open-source so folks can join me in crafting dynamic audio experiences and games for the web.
Continue reading to dive into its features, view example code, and learn more about its future.</p>

<!-- more -->

<h2 id="overview">Overview</h2>
<p>syngen is a game engine and synthesis toolkit that specializes in creating audio games with fully synthesized sounds.
If you’ve played any of my games before, then you might be familiar with its capabilities.</p>

<p>It provides a light wrapper around the <a href="https://developer.mozilla.org/en-US/docs/Web/API/Web_Audio_API" rel="nofollow noopener" target="_blank">Web Audio API</a> with tools for building synths and positioning them as props on a three-dimensional binaural soundstage.
Its event loop fires each frame to update props and core systems.
Additional utilities provide tools for engineering custom systems that hook into its API to deliver rich experiences.</p>

<h3 id="features">Features</h3>
<ul>
  <li>Wrapper for the Web Audio API with a domain-specific API</li>
  <li>Event-driven main loop and core systems</li>
  <li>Interfaces and utilities for building custom sounds and systems</li>
  <li>Binaural processing to position sounds on a realistic stage</li>
  <li>Virtualized mixer for advanced signal routing and mastering</li>
  <li>Built-in synthesizers, effects, and global reverb send</li>
</ul>

<h2 id="getting-started">Getting started</h2>
<p>Please <a href="https://github.com/nicross/syngen" rel="noopener" target="_blank">clone the repository</a> or install with your favorite package manager:</p>



<p>The library <em>must</em> be used within a browser environment so it can access the <code>window</code> object.
You may <code>require('syngen')</code> as a UMD module, or include <code>dist/syngen.min.js</code> to assign it to the <code>syngen</code> global.</p>

<h3 id="example-usage">Example usage</h3>
<p>This example demonstrates how to define a prop and instantiate one on the soundstage.
Here you’ll hear a relatively loud sine tone playing Middle C, centered in the stereo field:</p>

<div><div><pre><code><span>const</span> <span>prototype</span> <span>=</span> <span>syngen</span><span>.</span><span>prop</span><span>.</span><span>base</span><span>.</span><span>invent</span><span>({</span>
  <span>onConstruct</span><span>:</span> <span>function</span> <span>()</span> <span>{</span>
    <span>this</span><span>.</span><span>synth</span> <span>=</span> <span>syngen</span><span>.</span><span>audio</span><span>.</span><span>synth</span><span>.</span><span>createSimple</span><span>({</span>
      <span>frequency</span><span>:</span> <span>syngen</span><span>.</span><span>utility</span><span>.</span><span>midiToFrequency</span><span>(</span><span>60</span><span>),</span>
      <span>gain</span><span>:</span> <span>syngen</span><span>.</span><span>utility</span><span>.</span><span>fromDb</span><span>(</span><span>-</span><span>6</span><span>),</span>
    <span>}).</span><span>connect</span><span>(</span><span>this</span><span>.</span><span>output</span><span>)</span>
  <span>},</span>
  <span>onDestroy</span><span>:</span> <span>function</span> <span>()</span> <span>{</span>
    <span>this</span><span>.</span><span>synth</span><span>.</span><span>stop</span><span>()</span>
  <span>},</span>
<span>})</span>

<span>const</span> <span>instance</span> <span>=</span> <span>syngen</span><span>.</span><span>props</span><span>.</span><span>create</span><span>(</span><span>prototype</span><span>)</span>
</code></pre></div></div>

<h3 id="example-projects">Example projects</h3>
<p>The library ships with an <code>example</code> directory with simple demonstrations of its built-in capabilities.
For more advanced real-world examples, please play and tinker freely with the open-source projects below:</p>

<ul>
  <li><strong><a href="https://github.com/nicross/audo" rel="noopener" target="_blank">Audo</a>.</strong>
This endless audio racing game was developed with syngen for <em>GMTK Jam 2020</em> with the theme <q>out of control</q>.
Collect power-ups and dodge opponents on an expanding, non-euclidean track.</li>
  <li><strong><a href="https://github.com/nicross/auraboros" rel="noopener" target="_blank">Auraboros</a>.</strong>
This endless audio shooter was developed with syngen for <em>Ludum Dare 47</em> with the theme <q>stuck in a loop</q>.
Face endless waves of enemies with responsive movement and projectile physics.</li>
  <li><strong><a href="https://github.com/nicross/kaleidophone" rel="noopener" target="_blank">Kaleidophone</a>.</strong>
This generative audio toy was developed with syngen for <em>LOWREZJAM 2020</em> and <em>Brackeys Jam 2020.2</em> with the theme <q>rewind</q>.
Manipulate time to explore generative graphics and soundscapes.</li>
  <li><strong><a href="https://github.com/nicross/sea" rel="noopener" target="_blank">S.E.A.</a></strong>
This experimental watercraft simulator was developed with syngen for <em>No Video Jam</em> with the theme <q>waves</q>.
It leverages Perlin noise to procedurally generate its terrain and dynamic soundtrack.</li>
</ul>

<h3 id="further-reading">Further reading</h3>
<p>Additional resources have been provided to help you get started with your own audio projects:</p>

<ul>
  <li><strong><a href="https://syngen.shiftbacktick.io/" rel="noopener" target="_blank">API Documentation</a>.</strong>
The library ships with a <code>docs</code> directory containing detailed documentation.
It’s also accessible online.
Inside is an explanation of every namespace, interface, method, and type to expect when working with syngen.</li>
  <li><strong><a href="https://github.com/nicross/syngen-template" rel="noopener" target="_blank">syngen-template</a>.</strong>
Need a head start with creating your audio game?
This template repository provides a working directory structure and Electron wrapper for quick development and deployment.
Feel free to create a fork and start coding your own way.</li>
</ul>

<h2 id="the-future-of-syngen">The future of syngen</h2>
<p>This initial release reflects a year of learning with game development.
It contains some assumptions and vestiges that have remained since I first started this journey.
For this reason it’s been released as version 0.1.0 to indicate that it’s experimental and to be used at your own risk in production.
Hopefully the examples above demonstrate the rewards of that gamble.</p>

<p>Because I have games in production on this release branch, it needs to remain backwards compatible.
Therefore, minor version bumps and patch releases will only contain new features and bug fixes.
If it ever reaches the 1.0.0 milestone, then that will indicate a stabilization of this current API.</p>

<p>What I would like to do in a 2.0.0 release branch is reflect on my previous assumptions to rework it entirely.
This might include simplifications and optimizations that improve its power and usability.
Ideally it would empower me to build a new generation of audio games beyond what I’ve thought possible and learned this past year.</p>

<p>Please reach out or <a href="https://github.com/nicross/syngen/issues" rel="noopener" target="_blank">create an issue on GitHub</a> if you encounter any bugs or have any questions or projects to share.
I’m excited to hear your creations!</p>

          </div>
        </article>
        
          
        
      </div>
    </div></div>]]>
            </description>
            <link>https://shiftbacktick.io/code/2020/10/31/introducing-syngen.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25930148</guid>
            <pubDate>Wed, 27 Jan 2021 16:24:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[My 2 Year Journey to $10K MRR]]>
            </title>
            <description>
<![CDATA[
Score 585 | Comments 98 (<a href="https://news.ycombinator.com/item?id=25929259">thread link</a>) | @ronyfadel
<br/>
January 27, 2021 | https://www.bannerbear.com/journey-to-10k-mrr/ | <a href="https://web.archive.org/web/*/https://www.bannerbear.com/journey-to-10k-mrr/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><section><div><p>Bannerbear has <a href="https://www.bannerbear.com/open">hit 10K MRR</a> — this page documents the decisions and pivots that got me to this milestone</p><p><img src="https://d33wubrfki0l68.cloudfront.net/1ed17a3b3fabd4dac602adedb82c6d431eee9a00/4c01e/images/journey-og.png"></p></div></section><div><p><img src="https://d33wubrfki0l68.cloudfront.net/2da820372253f99cb768b77ef14171d128fbd77e/8999e/images/about/-04-2020-17-00-12.jpg"></p><p>I'm Jon (<a href="https://twitter.com/yongfook" target="_blank">@yongfook</a>) the founder of Bannerbear. <br>$10K MRR is considered something of a SaaS Bootstrapping milestone so I thought I should document how I got here. </p><p><small>This is not a secret formula / growth hack, it is just a personal account of growing a startup.</small></p><p><small>I hope this is useful if you're bootstrapping a SaaS — good luck! </small></p></div><section><div><p>January 2019 ~ August 2019</p><h2>Figuring Things Out</h2><p><span>$0 MRR</span></p><div><p><img src="https://d33wubrfki0l68.cloudfront.net/3fd67531a08e5359a505c1493914f6198d5b348e/5352d/images/journey/0mrr.png"></p></div></div></section><section><div><p>After leaving my job I spent almost a year burning through my savings as I attempted the 12 startups in 12 months challenge</p></div></section><section><div><p>I launched 7 startups but earned no direct revenue — none of them had a revenue model... which probably didn't help</p></div></section><section><div><p>One thing it was good for though, it helped me discover areas of tech that I was interested in exploring further <span data-id="The 12 Startups Challenge">i</span></p></div></section><section><div><div><p>Links from this period</p><p>Tweets from this period</p></div></div></section><section><div><p>Closing Thoughts</p><ul><li>🚢 Learning to ship consistently is a good muscle to exercise</li><li>💎 I was able to ship fast because I used tech that I knew well rather than fancy new tech</li><li>🔥 I had 2 years of savings but only got serious after burning 1 year of it</li></ul></div></section><section><div><p>September 2019 ~ December 2019</p><h2>Focus</h2><p><span>$400 MRR</span></p><div><p><img src="https://d33wubrfki0l68.cloudfront.net/e2244937b3351a7fe807aa88ef95fcc5b1fe28c2/a175c/images/journey/somemrr.png"></p></div></div></section><section><div><p>Juggling multiple startups wasn't working so I focused on one area that interested me — image generation</p></div></section><section><div><p>The new product was called Previewmojo and generated open graph-size images based on a narrow selection of templates</p></div></section><section><div><p>The response was still a bit lukewarm, but I had some sense of a North Star I wanted to reach, so I kept going <span data-id="The North Star">i</span></p></div></section><section><div><div><p>Links from this period</p><p>Tweets from this period</p></div></div></section><section><div><p>Closing Thoughts</p><ul><li>👨🏻 Never half-ass two things. Whole-ass one thing.</li><li>💰 Pricing is indeed HARD</li><li>🆙 Charge More ™</li></ul></div></section><section><div><p>January 2020 ~ February 2020</p><h2>Rebrand</h2><p><span>$472 MRR</span></p><div><p><img src="https://d33wubrfki0l68.cloudfront.net/9a6072d9e5a812dd643de3d8a0ce8a72e994beee/9b455/images/journey/rebrandmrr.png"></p></div></div></section><section><div><p>I rebranded to Bannerbear and redesigned the marketing site — although the app itself stayed largely the same</p></div></section><section><div><p>The rebrand helped to drive some traffic and renewed interest but this ultimately did not translate to many sales</p></div></section><section><div><p>I decided the product was aimed at too small a market — sometimes niching down is good, but not if you are too niche to be useful <span data-id="Not Solving a Top 50 Problem">i</span></p></div></section><section><div><div><p>Links from this period</p><p>Tweets from this period</p></div></div></section><section><div><p>Closing Thoughts</p><ul><li>🤏 The advice "Niche Down" means niche down your target market</li><li>😓 It doesn't mean niche down the pain point you solve</li></ul></div></section><section><div><p>March 2020 ~ April 2020</p><h2>API Launch</h2><p><span>$488 MRR</span></p><div><p><img src="https://d33wubrfki0l68.cloudfront.net/0c93802fc67b9811472db9eb1b2fe86541a5d565/19613/images/journey/apilaunchmrr.png"></p></div></div></section><section><div><p>I decided to go all-in on Bannerbear as an API product and launched a new template editor and a REST API</p></div></section><section><div><p>This opened up many new use cases, but meant that Bannerbear was aimed at a different target user than before <span data-id="New Uses Cases">i</span></p></div></section><section><div><p>At the same time, I decided to pull out of the Shopify app store as I was not getting traction there <span data-id="Shopify Exit">i</span></p></div></section><section><div><div><p>Links from this period</p><p>Tweets from this period</p></div></div></section><section><div><p>Closing Thoughts</p><ul><li>💖 I started to really enjoy work from this point</li><li>🧭 It was clear now that I could achieve something similar to my North Star vision <span data-id="The North Star">i</span></li><li>😎 I didn't have a grand marketing strategy, but "here are cool things you can do with my API" would suffice for now</li></ul></div></section><section><div><p>May 2020 ~ October 2020</p><h2>Getting into a Rhythm</h2><p><span>$6109 MRR</span></p><div><p><img src="https://d33wubrfki0l68.cloudfront.net/7f5a4f60b896b33237c992cae4119daa19a8e122/95b63/images/journey/growthmrr.png"></p></div></div></section><section><div><p>Over the next 6 months I divided my time into 50% coding and 50% marketing, shipping many new features and integrations</p></div></section><section><div><p>I would do one week of code, then spend the following week tweeting / blog posting about what I shipped — then repeat <span data-id="The Rhythm">i</span></p></div></section><section><div><p>I use a kanban system to manage my user stories and assign story points — this helps keep my output consistent </p></div></section><section><div><div><p>Links from this period</p><p>Newsletters from this period</p><p>Tweets from this period</p></div></div></section><section><div><p>Closing Thoughts</p><ul><li>💪 Find out what works for you then do more of it</li><li>📝 In my case, I found that the more documentation I wrote the more conversions I got</li></ul></div></section><section><div><p>November 2020 ~ January 2021</p><h2>Positioning Change</h2><p><span>$10,455 MRR</span></p><div><p><img src="https://d33wubrfki0l68.cloudfront.net/dc8fe3a41bd854a2bf868b655274e6971327259b/36709/images/journey/automate-and-scale-mrr.png"></p></div></div></section><section><div><p>Inspired by Jobs to be Done I repositioned Bannerbear around 2 jobs that it performs: automating / scaling your marketing <span data-id="Jobs to Be Done">i</span></p></div></section><section><div><p>These represent two different users: one uses Zapier to set up automations, the other uses the API for high volume integrations</p></div></section><section><div><p>The keywords Automate and Scale are everywhere on the marketing site, the pricing plans, the categorisation of tutorials etc</p></div></section><section><div><div><p>Links from this period</p><p>Newsletters from this period</p><p>Tweets from this period</p></div></div></section><section><div><p>Closing Thoughts</p><ul><li>🎯 Knowing your target market is good, knowing your target's Job to Be Done is better <span data-id="Jobs to Be Done">i</span></li><li>💬 Jobs to Be Done is only something you understand after talking to users</li><li>🔥 Upgrade your user, not your product <span data-id="Upgrade Your User">i</span></li></ul></div></section><div><p><img src="https://d33wubrfki0l68.cloudfront.net/2da820372253f99cb768b77ef14171d128fbd77e/8999e/images/about/-04-2020-17-00-12.jpg"></p><p>I hope that was useful! </p><p><small>I tweet about bootstrapping my startup <a href="https://twitter.com/yongfook" target="_blank">@yongfook</a></small></p></div><br><div><div><div><p><img src="https://d33wubrfki0l68.cloudfront.net/a52f6ead9a5dea3e35cbc632bd00c19f875ef8c6/65be4/images/transparent_icon.png"></p><p>Follow the Journey</p><p><a href="https://www.bannerbear.com/about">Hello I'm Jon</a> the founder of Bannerbear! <br>Every 2 weeks I send a newsletter with updates from the Product, Marketing and Business sides of my startup, subscribe below to follow along!</p></div></div></div><p><img src="https://d33wubrfki0l68.cloudfront.net/af7543e0a4f9bb6d3a741168ebb9335fe2a1459b/cab8a/images/general_arrow.png"></p><section><div><h2>Follow the Journey</h2><p><a href="https://www.bannerbear.com/about">Hello I'm Jon</a>, the founder of Bannerbear — every 2 weeks I send a newsletter with updates from the Product, Marketing and Business sides of my startup, subscribe below to receive it!</p></div></section><div id="journey_page_modal"><div><div><div><div data-id="The 12 Startups Challenge"><p>If I was to do the 12 startups challenge over, I would focus on one particular area of tech or industry and create several solutions in the same space.</p><p>The way I did it, I launched several totally-unrelated products. In retrospect I don't think this was a good idea, but it did have the unintended side-effect of allowing me to see what general space I enjoyed the most.</p><p>If you're direction-less (as I largely was) then the 12 Startups challenge can accelerate you towards a certain direction. But it can also be a fruitless waste of time, so be warned!</p></div><div data-id="The North Star"><p>It only really occurred to me part way through this journey, but the reason automated image generation resonated with me so much is because I had felt the pain before.</p><p>I had previously worked in an Ecommerce company where we would manually create visual assets every day for all the new products being uploaded to the store. It was a tedious process that I would have loved to automate at the time, but there was no solution.</p><p>My North Star became trying to create a product that would have solved that past problem, for companies in the future.</p></div><div data-id="Not Solving a Top 50 Problem"><p><a href="https://www.indiehackers.com/product/mojosaas/real-talk-time--LwDyKPEChHn02IlAgcL?commentId=-LwHCGp0rJ5hR0dZj8c4" target="_blank">This comment reply from the founder of Wavve</a> was a good wake-up call.</p><p>Ultimately, auto-generating Open Graph images is not a hair on fire problem. It's *part of* a hair on fire problem, that being "we need to automate some of our marketing because we don't have time" but it's a very niche part of that.</p><p>By now I was already thinking about how to pivot the tech so it could have a more universal application rather than being confined to this single use case.</p></div><div data-id="New Uses Cases"><p>This pivot away from a standalone Open Graph image tool was risky, as for existing customers, that's what they signed up for.</p><p>The API launch definitely alienated some of these early customers and they churned.</p><p>Note: early customers still had full access to the old product but I made it clear that the API would be the focus going forward.</p></div><p>YMMV but I did not have much good fortune as a Shopify app developer. I found the API to be a bit dated (I'm sure it has been improved now though) and the customer expectation on pricing was around $5 to $10 per month, it seemed. For me it was not the right place to launch a niche SaaS tool. </p><p>7 days of code, 7 days of marketing, and end the cycle with a newsletter report to subscribers on what's new. This rhythm worked well for me and is adapted from my previous experience working in Scrum Sprints.</p><div data-id="Jobs to Be Done"><p>You can Google some literature on the topic, there wasn't one particular resource that I found helpful.</p><p>But essentially the mindset shift is... everyone always says that you need to know your target market. Even better, is knowing what job your target market is trying to get done.</p><p>Once you have figured that out, use that language in how you market your solution.</p><p>I will add that, these "jobs to be done" for my app were not obvious in the beginning and it took months of looking at usage trends to understand what they were.</p></div><div data-id="Upgrade Your User"><p>This is maybe a bit of an abstract concept, especially if you're like me and you're a technical founder building a product. </p><p>But here's an illustration by <a href="https://twitter.com/SamuelHulick" target="_blank">@SamuelHulick</a> that I think captures the idea perfectly:</p><p><img src="https://d33wubrfki0l68.cloudfront.net/23f092c7da7ef6dcd0b36ada6d803bb25ec6c317/d7ae7/images/journey/mario.jpg"></p></div></div></div></div></div></div></div>]]>
            </description>
            <link>https://www.bannerbear.com/journey-to-10k-mrr/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25929259</guid>
            <pubDate>Wed, 27 Jan 2021 15:22:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The career-changing art of reading the docs]]>
            </title>
            <description>
<![CDATA[
Score 10 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25928553">thread link</a>) | @forrestbrazeal
<br/>
January 27, 2021 | https://acloudguru.com/blog/engineering/the-career-changing-art-of-reading-the-docs | <a href="https://web.archive.org/web/*/https://acloudguru.com/blog/engineering/the-career-changing-art-of-reading-the-docs">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-id="8a920a5" data-element_type="widget" data-widget_type="theme-post-content.default"><div><p>Every so often I get asked for advice on how to become an <a href="https://aws.amazon.com/developer/community/heroes/">AWS Hero</a>.</p><p>The specific answer isn’t that interesting – “get involved in the community and hope someone nominates you as a Hero” seems to be the process at AWS. I understand that the <a href="https://mvp.microsoft.com/en-us/overview">Microsoft MVP process</a> is a bit more transparent and better prescribed.</p><p>But the general question of “how do I become well-respected in my chosen technical specialty” is VERY interesting. Even if you don’t have any aspirations to build a public following, there is tremendous career value in becoming the go-to person within your technical niche.</p><p>The person who everybody on your team comes to with their toughest question about that language or framework. The person who knows where all the bodies are buried in ActiveDirectory or Typescript or DynamoDB. Those folks have great careers and job security because authoritative knowledge like that is rare.</p><p>To some extent, it’s rare because wisdom only comes with experience. But I know plenty of engineers who’ve sat in the same chair for ten years getting the same year of experience ten times. Heck, I’ve been there myself; I spent a couple of years as an “accidental DBA” who never really learned that much about SQL Server beyond what the daily firefighting required.</p><p>I used to spend a lot of time wondering how other people seemed to level up so quickly on new technologies. How do you break through that stagnant cycle of learning and forgetting stuff in bits and pieces, using the same technology for years without ever feeling like an expert?</p><p>A few years ago I learned a secret for doing this, a cheat code if you will, from my fellow AWS Hero <a href="https://acloudguru.com/blog/author/jared-short">Jared Short</a>. This is his secret recipe for leveling up in tech:</p><p><strong>Read the documentation for one job-relevant technology, cover-to-cover, every week. </strong></p><figure><div><blockquote data-width="500" data-dnt="true"><p lang="en" dir="ltr">Forrest is giving away my secrets, but it's true. I'd estimate around 700+ hours of just reading AWS docs over my career with intent to retain / learn (not just reference). It feels silly until you almost immediately understand some esoteric side-effect or behavior. <a href="https://t.co/juQ0b9mENI">https://t.co/juQ0b9mENI</a></p>— Jared Short (@ShortJared) <a href="https://twitter.com/ShortJared/status/1347629518312378369?ref_src=twsrc%5Etfw">January 8, 2021</a></blockquote> </div></figure><h2 id="h-reading-docs-the-wrong-way-and-the-right-way">Reading docs: the wrong way and the right way</h2><p>I get it, that doesn’t sound revolutionary. “<a href="https://en.wikipedia.org/wiki/RTFM">RTFM</a>” is literally as old as computing itself. It’s the classic kiss-off answer to questions you ought to be able to Google.</p><p>And that betrays a key limitation in how a lot of us think about documentation. We think of it tactically, as a resource to query when we have a specific question or encounter a particular error. We use docs to fill in our <em>known unknowns.</em></p><p>That’s how you can get stuck for years, say, administering a PostgresSQL cluster and never really becoming that deep of an expert on Postgres. If you only learn something new when the situation demands it, your mental model of Postgres (or whatever) will look like a gradually expanding version of this:</p><figure><img loading="lazy" width="2181" height="1647" src="https://res.cloudinary.com/acloud-guru/image/fetch/c_thumb,f_auto,q_auto/https://acg-wordpress-content-production.s3.us-west-2.amazonaws.com/app/uploads/2021/01/tactical.png" alt="" srcset="https://res.cloudinary.com/acloud-guru/image/fetch/c_thumb,f_auto,q_auto/https://acg-wordpress-content-production.s3.us-west-2.amazonaws.com/app/uploads/2021/01/tactical.png 2181w, https://res.cloudinary.com/acloud-guru/image/fetch/c_thumb,f_auto,q_auto/https://acg-wordpress-content-production.s3.us-west-2.amazonaws.com/app/uploads/2021/01/tactical.png 300w, https://res.cloudinary.com/acloud-guru/image/fetch/c_thumb,f_auto,q_auto/https://acg-wordpress-content-production.s3.us-west-2.amazonaws.com/app/uploads/2021/01/tactical.png 1024w, https://res.cloudinary.com/acloud-guru/image/fetch/c_thumb,f_auto,q_auto/https://acg-wordpress-content-production.s3.us-west-2.amazonaws.com/app/uploads/2021/01/tactical.png 768w, https://res.cloudinary.com/acloud-guru/image/fetch/c_thumb,f_auto,q_auto/https://acg-wordpress-content-production.s3.us-west-2.amazonaws.com/app/uploads/2021/01/tactical.png 1536w, https://res.cloudinary.com/acloud-guru/image/fetch/c_thumb,f_auto,q_auto/https://acg-wordpress-content-production.s3.us-west-2.amazonaws.com/app/uploads/2021/01/tactical.png 2048w" sizes="(max-width: 2181px) 100vw, 2181px"></figure><p>Over time, as you encounter more new use cases for the technology, you’ll burn more “never forget” bubbles into the mental model. But you’ll still have this heavy sense of unknown unknowns hanging over you, and you’ll never be sure if you’re really using the optimal approach to solve a new problem.</p><p>Instead, Jared’s approach is to read docs strategically<em>, </em>preemptively, curiously: as a way to fill in your <em>unknown unknowns</em>. The things you might not encounter in ten years, but that would cost you two days of troubleshooting if you ran into them tomorrow.</p><p>Read docs like novels (cover to cover), not like dictionaries (look up the term, cross-reference, and stop). Over time, that strategy will lead to a mental model of your professional domain that looks more like this:</p><figure><img loading="lazy" width="727" height="549" src="https://res.cloudinary.com/acloud-guru/image/fetch/c_thumb,f_auto,q_auto/https://acg-wordpress-content-production.s3.us-west-2.amazonaws.com/app/uploads/2021/01/strategic.png" alt="" srcset="https://res.cloudinary.com/acloud-guru/image/fetch/c_thumb,f_auto,q_auto/https://acg-wordpress-content-production.s3.us-west-2.amazonaws.com/app/uploads/2021/01/strategic.png 727w, https://res.cloudinary.com/acloud-guru/image/fetch/c_thumb,f_auto,q_auto/https://acg-wordpress-content-production.s3.us-west-2.amazonaws.com/app/uploads/2021/01/strategic.png 300w" sizes="(max-width: 727px) 100vw, 727px"></figure><p>(This is <a href="https://acloudguru.com/blog/engineering/how-many-certifications-do-i-need-to-get-a-cloud-job">the same benefit</a> you get from studying for certifications, by the way: you’re building a mental map of the domain, so you don’t have to stumble through the darkness on every new quest.)</p><p>On the surface, that sounds simple, but it’s far from easy. Here are three common objections people raise when I advise reading docs as a career-advancement strategy:</p><h4 id="h-i-don-t-have-a-photographic-memory-i-ll-never-remember-a-bunch-of-random-docs"><strong>“I don’t have a photographic memory. I’ll never remember a bunch of random docs.”</strong></h4><p>Back when I was in college, a well-meaning friend convinced me I should read a book on SAP. Forget today — I couldn’t have told you a single thing about SAP <em>ten minutes after finishing that book</em>. I’d never been inside an enterprise, much less understood the problems these ERP integrations I was reading about were supposed to solve. It was like trying to talk to the aliens in the movie <em>Arrival</em>: my brain was the wrong shape.</p><p>Likewise, you probably won’t get much value out of glancing through docs for a technology you don’t use and have no context for.</p><p>So do these two things:</p><p>1. <strong>Focus on docs for technologies you are already using</strong>. We’ve all had that mind-numbing feeling when plowing through some esoteric text that doesn’t relate to our daily lives, where you glaze over for three pages and then go, “what did I just read?”</p><p>Avoid this by focusing on docs for technologies or languages you’ve already got a vested stake in – say, because they’re on your plate at work or you’re trying to build them into a side project.</p><p>Encourage active reading and engagement with the information by asking yourself questions like these as you read:</p><ul id="block-ef7bb5e0-252c-434f-98de-116c8c0e2003"><li>Did I understand that? (If not, maybe read the section again)</li><li>Does what I just read match my existing mental model of how this technology works? (If not, do I need to go review a different doc and then come back to this?)</li><li>Could this feature or fact help me on my current project?</li><li>If I had known this six months ago, what would I have done differently? (“Chosen a different technology” is a totally acceptable answer!)</li></ul><p>Then, <strong>2. Read those docs repeatedly, on a schedule, over and over</strong>. Seriously. If you’re on a team that’s building out centralized CI/CD for Azure, maybe read the part of the Azure DevOps docs on pipelines this week and the part on build agents next week, and when you get to the end, start over. The cloud changes fast. You’ll fold in new information at the same time you’re reinforcing the old.</p><h4 id="h-i-don-t-have-time-to-read-a-bunch-of-documentation"><strong>“I don’t have time to read a bunch of documentation.”</strong></h4><p>Yes, and weeks of work can save you hours of planning. Maybe use some of the time you currently spend injecting “HERE” print statements into your code to figure out why it’s not working.</p><figure><img src="https://faasandfurious.com/pages/debugging-tactics.png" alt="Debugging Tactics"></figure><p>More seriously, it’s not a bad idea to block a bit of time on your calendar each day – 30 minutes, even –  for targeted doc-reading. You may find it hard to carve that time out of your workday, but defending time and setting expectations with your manager is its own skill, worth practicing. Call the block of time “deep work.” It is.</p><h4 id="h-the-docs-for-technology-x-are-no-good-trust-me-they-re-not-worth-reading"><strong>“The docs for [technology X] are no good. Trust me, they’re not worth reading.”</strong></h4><p>I don’t always buy this excuse. The docs might not be that bad; you might just have the wrong expectations.</p><p>For example, the AWS documentation gets <a href="https://twitter.com/IanColdwater/status/1347737875991777280">a terrible rap</a> for being wordy and poorly-organized. And it’s maybe even worse than you’ve heard – if you’re trying to look up the name of an IAM action or the syntax of a CLI command, that is.</p><p>But as an educational tool that dives deep on the architectural underpinnings and technical limitations of services, the AWS docs are <em>fantastic. </em>They’re better than any book you could ever buy about the cloud. (And the <a href="https://aws.amazon.com/builders-library/">Builder’s Library</a> is better still.) The AWS docs are designed not just to be referenced, but to be read. Read ’em!</p><p>On the other hand, some types of docs like step-by-step tutorials are very much designed to be referenced during hands-on builder time. It may not make sense to spend a lot of time reading those in the abstract. So bring your common sense.</p><p>However. There are also plenty of technologies out there where the docs are truly incomplete, out of date, or just plain wrong – many smaller open-source projects, in particular.</p><p>Turns out you have another option here, at least for OSS projects: <em>read the source code.</em> Not sure what a module does, what its edge cases are, what the error code means? Read the source code and find out! It might be faster than (and will definitely be at least as accurate as) looking for the answer in the docs, <em>even if the docs are pretty good. </em></p><p>If you write code for a living, reading other people’s shipped, battle-tested code — not just PRs from your own team — is genuinely one of the most transformative things you can do for your career. Because while you’re answering your immediate question, you’ll also be picking up style, organization, and technique from professional programmers operating under all kinds of interesting constraints. Seriously. Read code.</p><p>(And then, if it’s open-source, maybe consider contributing some docs!)</p><h2 id="h-what-do-i-get-out-of-all-this"><strong>What do I get out of all this?</strong></h2><p>If you read a targeted set of docs consistently over a sustained period — say, a couple of years — while actively practicing on that technology, you will be able to perform magic. That’s a promise.</p><p>Let’s go back to Jared Short again for an example. (Yes, I checked with Jared, he graciously agreed to let me spill his secrets in this piece.) As an engineer at an AWS shop, Jared …</p><ul><li>Reads the documentation for one AWS service, cover to cover, every week.</li><li>Blocks daily time for this on his calendar.</li><li>Focuses on services he’s actually using at work (he tells me that so far in 2021, he’s been through all the docs for Lambda, AppSync, and Step Functions).</li></ul><p>Jared’s been doing this week in, week out, for *years*. And that  unglamorous commitment lets him perform nerd magic like this:</p><figure><div><blockquote data-width="500" data-dnt="true"><p lang="en" dir="ltr">I needed to understand extensions better for a thing, read the docs cover to cover like an insane person.</p>— Jared Short (@ShortJared) <a href="https://twitter.com/ShortJared/status/1347612782389301249?ref_src=twsrc%5Etfw">January 8, 2021</a></blockquote> </div></figure><p>If you don’t want to take the time to read that whole Twitter thread, let me sum it up for you.</p><ol><li>An experienced AWS engineer encounters a weird behavior: AWS Lambda seems to be executing code when it should not be. He posts a plea for help on Twitter.</li><li>Other experienced engineers take a look and go, “huh. Weird.” To be clear, this is not a case of RTFM. The problem is nontrivial and the solution, if there is one, is not well-known. …</li></ol></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://acloudguru.com/blog/engineering/the-career-changing-art-of-reading-the-docs">https://acloudguru.com/blog/engineering/the-career-changing-art-of-reading-the-docs</a></em></p>]]>
            </description>
            <link>https://acloudguru.com/blog/engineering/the-career-changing-art-of-reading-the-docs</link>
            <guid isPermaLink="false">hacker-news-small-sites-25928553</guid>
            <pubDate>Wed, 27 Jan 2021 14:22:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[World’s Most Dangerous Malware Emotet Disrupted Through Global Action]]>
            </title>
            <description>
<![CDATA[
Score 10 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25927495">thread link</a>) | @doener
<br/>
January 27, 2021 | https://www.europol.europa.eu/newsroom/news/world%E2%80%99s-most-dangerous-malware-emotet-disrupted-through-global-action | <a href="https://web.archive.org/web/*/https://www.europol.europa.eu/newsroom/news/world%E2%80%99s-most-dangerous-malware-emotet-disrupted-through-global-action">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://www.europol.europa.eu/newsroom/news/world%E2%80%99s-most-dangerous-malware-emotet-disrupted-through-global-action</link>
            <guid isPermaLink="false">hacker-news-small-sites-25927495</guid>
            <pubDate>Wed, 27 Jan 2021 12:41:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Commercial dairy keeping calves with cows]]>
            </title>
            <description>
<![CDATA[
Score 68 | Comments 36 (<a href="https://news.ycombinator.com/item?id=25926058">thread link</a>) | @YeGoblynQueenne
<br/>
January 27, 2021 | https://www.theethicaldairy.co.uk/our-story | <a href="https://web.archive.org/web/*/https://www.theethicaldairy.co.uk/our-story">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <div><div><p>The intensification of dairy farming has been a concern of ours for many years, so we’ve been working hard to come up with a different solution. Our big idea? A new method of dairy farming that keeps the calves with their mothers to suckle. Our <a href="http://www.theethicaldairy.co.uk/blog/ethical-dairy-system">ethical dairy model</a> is based around treating the animals, the land, our environment and the people who work here with respect and kindness.</p></div></div>
<div>
  <div><div><div><div about="" typeof="">
  <div>
    <div><div><div><p>In traditional dairy farms calves are removed from their mothers within a few hours of their birth - the stress this places on the cow is clear. So we wanted to find a way to keep calves with the cows and still have a financially viable farm. Put simply, we don’t want to have to choose between doing what’s right and staying in business.</p>
<p>As an organic dairy farm for more than twenty years our cows have already benefitted from some of the highest welfare standards in the UK, but we knew we could do even better. We built a new dairy, specially designed to house calves with their mothers, and we trialled the full cow with calf system for the first time in 2012. It taught us a lot, but financially cost us an awful lot.</p>
<p><span>However, the impact it made on cow contentment was staggering. All the animals were noticeably calmer and far more confident. <span>&nbsp;</span>After two to three months the calves became like teenagers, they loved playing with their pals and really only came back to mum when they wanted food!</span></p>
<p><span></span>We are determined to make our radical new model of dairy farming work, and by purchasing cheese from The Ethical Dairy you are helping to support it.</p>
</div></div></div>  </div>
</div>
</div><div><div about="" typeof="">
  <div>
    <div>
    <p>
          <h2>The Ethical Journey So Far</h2>
      </p>
</div>
  </div>
</div>
</div><div><div about="" typeof="">
  <div>
    <div><div><div><p>Since October 2016 our calves have stayed with their mothers for 5 to 6 months. We still milk them in that period, but only once a day.</p>
<p>We are still at the early stages of The Ethical Dairy project, but our new approach to dairy farming has already led to huge reductions in the use of <a href="http://www.theethicaldairy.co.uk/blog/power-nature">antibiotics</a>, increases in <a href="http://www.theethicaldairy.co.uk/blog/biodiversity-ethical-dairy">biodiversity</a> and <a href="http://www.theethicaldairy.co.uk/blog/healthier-winter">healthier</a>, happier cows. Compared to an average dairy farm, already The Ethical Dairy has:&nbsp;</p>
<ul>
<li>Cut greenhouse gas emissions by more than half</li>
<li>Reduced <a href="http://www.theethicaldairy.co.uk/blog/coo-poo-power">energy</a> use by more than half</li>
<li>Cut <a href="http://www.theethicaldairy.co.uk/blog/power-nature">antibiotic</a> use by 90%</li>
<li>Cut agro-chemical use by 90%</li>
<li>Doubled the productive life of cows</li>
<li>Increased our farm <a href="http://www.theethicaldairy.co.uk/blog/biodiversity-ethical-dairy">biodiversity</a> five-fold</li>
<li>Increased the net amount of food in our <a href="http://www.theethicaldairy.co.uk/blog/politics-food-production">food system</a> by 80%</li>
<li>Exceeded the highest standards of animal welfare</li>
</ul>
<p>The Ethical Dairy has been supported in its journey by many individuals through our crowdfunding campaign in the autumn of 2018, and by public funding, such as Dumfries and Galloway LEADER which is helping us to attend trade shows, events, and to market and promote our products. We are also grateful for support from the Food Processing, Manufacturing and Cooperation grant which has supported the development of our new cheese dairy.&nbsp;</p>
<p>We hope you enjoy our cheese and we thank you for your support of The Ethical Dairy.</p>
</div></div></div>  </div>
</div>
</div><div><div about="" typeof="">
  <div>
    <div><div><div><p>Healthier, happier cows and calves are the goal of our radical new dairy system, alongside of course producing milk with which to make our delicious cheese. If you’re interested in helping us prove that commercial dairy farming can be ethical, sustainable and compassionate, then please sign up for our supporters newsletter below.</p>
<p>We email our members a few times each year to ask for your opinion on new ideas and to share our news.</p>
</div></div></div>  </div>
</div>
</div></div></div></div>
  </div></div>]]>
            </description>
            <link>https://www.theethicaldairy.co.uk/our-story</link>
            <guid isPermaLink="false">hacker-news-small-sites-25926058</guid>
            <pubDate>Wed, 27 Jan 2021 09:28:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Peek into the Future of Distros]]>
            </title>
            <description>
<![CDATA[
Score 44 | Comments 61 (<a href="https://news.ycombinator.com/item?id=25925012">thread link</a>) | @todsacerdoti
<br/>
January 26, 2021 | https://venam.nixers.net/blog/programming/2021/01/26/future-of-distros.html | <a href="https://web.archive.org/web/*/https://venam.nixers.net/blog/programming/2021/01/26/future-of-distros.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  <article>
    <p><img src="https://venam.nixers.net/blog/assets/hermetic_world.jpg" alt="The world description from an hermetic point of view was always convoluted and full of retrospective to enforce meaning" loading="lazy"></p>

<p><em>The year of the Linux desktop is coming</em>, and it looks like a piñata of
micro-services. Let’s break it and see the candies inside.</p>

<ul>
  <li>systemd core — the building block framework abstracting basic functionalities</li>
  <li>A universal package manager with a single reposotiry where anyone can push</li>
  <li>flatpak/appimage/snap — containarized applications</li>
  <li>polkit and apparmor — granular security</li>
  <li>systemd-homed — movable home with an immutable base system</li>
  <li>wayland compositors — the graphical environment</li>
  <li>pipewire — media pipeline</li>
</ul>

<p>If you’re bored you can leave now, that’s it. Otherwise, let me get more
ideas out, but nothing surprising to anyone that has been following RedHat,
the freedesktop.org, and systemd.</p>

<p>The key innovation of the picture I lay above is that every
layer in the system is now isolated and communicate with one
another through d-bus services. D-bus is <a href="https://venam.nixers.net/blog/unix/2020/07/06/dbus-polkit.html">fantastic in its own
right</a> and good at
abstracting functionalities.</p>

<p>All of these pieces need one another. Wayland compositors need pipewire
to be able to access media hardware, and pipewire needs polkit (or
similar mechanism) to select who can do that. Similarly, containarized
applications access the rest of the system through systemd services,
polkit, and pipewire.</p>

<p>What this leads to is a base system that is stable, a solid framework
to build on. The home is transportable inside a systemd-homed, along
with the containarized apps, proprietary or not.</p>

<p>The deep secret insider info I got tells me that this is a giant scheme
to get us all in a vendor lock-in. I can lie, this is the internet.<br>
Or better (or worse?), this is a new Android ecosystem.</p>

<p>Who’s going to nag when this is all done in the open; when the open
source movers are the implementers of the de-facto implementations;
when they keep piling the standards until nobody can follow them.</p>

<p>I believe the direction the Linux desktop is going towards will
bring more incentives for investments. Distributions uniqueness
won’t matter anymore as they’ll be centralized around a “store”
where devs will push directly. (<a href="https://venam.nixers.net/blog/unix/2020/03/29/distro-pkgs.html">see previous post about distros
roles</a>)</p>

<p>Leave a comment if you weren’t aware of this vision of how distros will
look in the future.</p>


	
<br>
<hr>

<p>
If you want to have a more in depth discussion I'm always available by <a href="https://venam.nixers.net/blog/about.html">email or irc</a>.
We can discuss and argue about what you like and dislike, about new ideas to consider, opinions, etc..<br>
If you don't feel like "having a discussion" or are intimidated by emails
then you can simply say something small in the comment sections below
and/or share it with your friends.
</p>
<br>






  </article>
</div></div>]]>
            </description>
            <link>https://venam.nixers.net/blog/programming/2021/01/26/future-of-distros.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25925012</guid>
            <pubDate>Wed, 27 Jan 2021 06:36:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why Create a New Unix Shell?]]>
            </title>
            <description>
<![CDATA[
Score 71 | Comments 60 (<a href="https://news.ycombinator.com/item?id=25924647">thread link</a>) | @tux1968
<br/>
January 26, 2021 | http://www.oilshell.org/blog/2021/01/why-a-new-shell.html | <a href="https://web.archive.org/web/*/http://www.oilshell.org/blog/2021/01/why-a-new-shell.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
  <!-- INSERT LATCH HTML -->
<p><a href="http://www.oilshell.org/blog/">blog</a> | <a href="http://www.oilshell.org/">oilshell.org</a></p>

<p>
  2021-01-27
</p>
<p>This is an update of <a href="http://www.oilshell.org/blog/2018/01/28.html">the popular 2018 FAQ</a>.  Details
have changed, but the spirit of the project is the same.  If you've already
read this, see <a href="http://www.oilshell.org/blog/2021/01/philosophy-design.html">yesterday's post</a> for more color.</p>
<p>Whenever I announce a new <a href="http://www.oilshell.org/blog/tags.html?tag=oil-release#oil-release">Oil release</a>, some readers are confused
by the project.</p>
<p>This post explains the project's motivation from several perspectives.  Because
Unix shell is an old and successful technology, there are many ways of looking
at it.</p>
 
<a name="introduction"></a>
<h2>Introduction</h2>
<p>Before explaining <em>why</em> I created Oil, let's review <em>what</em> it is.  You can
think of a Unix shell in two ways:</p>
<ol>
<li>As a text-based <strong>user interface</strong>.  You communicate with the operating
system by typing commands.</li>
<li>As a <strong>language</strong>.  It has variables, functions, and loops.  Shell programs
are text files that start with <code>#!/bin/sh</code>.</li>
</ol>
<p>In this document, we'll think of Unix shells as languages.  The Oil project
actually has <strong>two languages</strong>: OSH and Oil.  Let's define these terms, along with
two others for context:</p>
<ul>
<li><a href="http://www.oilshell.org/cross-ref.html?tag=posix-shell-spec#posix-shell-spec">POSIX shell</a> is a language defined by a standards body.
For example, Debian Linux and FreeBSD are both Unix operating systems that
provide POSIX shells.  Nearly all shells are POSIX-compatible: <code>bash</code>,
<code>dash</code>, <code>ksh</code>, etc.</li>
<li>GNU <a href="http://www.oilshell.org/cross-ref.html?tag=bash#bash">bash</a> is the most popular shell implementation in the world.
It was first released in 1989, and implements the POSIX standard plus many
extensions.  It's the default shell on most Linux distributions, runs on BSD
Unix variants, <a href="https://scriptingosx.com/2019/06/moving-to-zsh/">used to ship on Mac OS X</a>, and <a href="https://www.howtogeek.com/265900/everything-you-can-do-with-windows-10s-new-bash-shell/">runs on
Windows</a>.</li>
<li><a href="http://www.oilshell.org/cross-ref.html?tag=osh-language#osh-language">OSH</a> is a shell implementation that's part of the Oil project.
It's compatible with both POSIX and <code>bash</code>.  The goal is to run <strong>existing
shell scripts</strong>.  It's done so <a href="http://www.oilshell.org/blog/2018/01/15.html">since January 2018</a>, and has matured
in <a href="http://www.oilshell.org/releases.html">many regular releases</a> since then.</li>
<li>The <a href="http://www.oilshell.org/cross-ref.html?tag=oil-language#oil-language">Oil language</a> is a brand new, incompatible, shell
language.  The idea is to fix more than four decades of accumulated warts in
the Unix shell.  Many Unix users are angry that shell is so difficult, and
Oil aims to fix that.  (Example: Why is <code>x=1</code> different than <code>x = 1</code>?)</li>
</ul>
<p>More about the Oil language:</p>
<ul>
<li>Compared to POSIX shell and bash, Oil is <strong>easier to learn, write, and
debug</strong>.  It's designed for programmers who know Python, JavaScript, or Ruby,
but avoid shell.</li>
<li>Oil will do everything bash can, <strong>and more</strong>.  For example, it will have
dynamic types and structured data, not just strings.</li>
<li><a href="http://www.oilshell.org/blog/2020/01/simplest-explanation.html">The Simplest Explanation of Oil</a>
shows examples of the language.</li>
<li><a href="http://www.oilshell.org/release/latest/doc/idioms.html">Oil Language Idioms</a> compares
old shell code and new Oil code.  Importantly, the same interpreter runs both
styles.  It's useful to think of OSH and Oil separately, but there's a
<strong>gradual transition</strong> between the two.</li>
</ul>
<p>The best description of the project is on <a href="http://www.oilshell.org/">the home page</a>:</p>
<blockquote>
<p>Oil is our upgrade path from <a href="http://www.oilshell.org/cross-ref.html?tag=bash#bash">bash</a> to a better language and runtime.</p>
</blockquote>
<a name="frequently-asked-questions"></a>
<h2 id="faq">Frequently Asked Questions</h2>
<p>This section paraphrases questions I've received and summarizes the answers.
In most cases, I link to the original comment thread, which you can read for
details.</p>
<a name="how-is-oil-different-than-bash-or-zsh"></a>
<h3>How is Oil different than <code>bash</code> or <code>zsh</code>?</h3>
<p>Oil is taking shell seriously as a <strong>programming language</strong>, rather than
treating it as a text-based UI that can be abused to write programs.</p>
<p>To see why this is valuable, consider these two groups of shell users:</p>
<ol>
<li>People who use shell to type a few commands here and there.</li>
<li>People who write scripts, which may get into the hundreds or even thousands
of lines.</li>
</ol>
<p>Oil is aimed at group 2.  If you're in group 1, there's admittedly <strong>no
reason</strong> to use it right now.</p>
<p>However, group 2 writes scripts for group 1 to use!  So I believe the benefits
of Oil will eventually bubble up.</p>
<p>In other words, I'm building a <strong>solid foundation</strong> for a few more decades of
shell usage.</p>
<ul>
<li><a href="https://www.reddit.com/r/commandline/comments/7c3f9f/osh_02_parsing_one_million_lines_of_shell/dpodqpj/">Original question and answer</a> (reddit.com)</li>
<li><a href="https://www.reddit.com/r/commandline/comments/7lqcqo/osh_03_optimization_benchmarks_and_bug_fixes/dro9zmx/">Another comment</a> with more detail</li>
</ul>
<a name="i-dont-understand-why-not-use-a-different-a-programming-language"></a>
<h3>I don't understand.  Why not use a different a programming language?</h3>
<p>It's important to be compatible with existing code.  You might not personally
use shell as a programming language, but all Unix users still rely on big shell
programs.  It's often used at build time, but it's still used at runtime too,
e.g. on embedded Linux devices.</p>
<p>Some of this code is old, but much of it is <strong>new</strong>.  It's not a small amount
of code, either.  Examples:</p>
<ul>
<li><a href="https://kubernetes.io/">Kubernetes</a>, a popular cluster manager from Google (released around 2014),
has <a href="http://www.oilshell.org/release/0.3.0/test/wild.wwz/cloud/kubernetes/index.html">48,000+ lines</a> of shell in its repo.</li>
<li>Many distros use the <a href="https://github.com/scop/bash-completion">bash-completion</a> project for interactive completions,
and it has <a href="http://www.oilshell.org/release/0.3.0/test/wild.wwz/shell/bash-completion/index.html">26,000 lines</a> of shell.</li>
<li>More examples: <a href="https://github.com/oilshell/oil/wiki/The-Biggest-Shell-Programs-in-the-World">The Biggest Shell Programs in the
World</a>.</li>
</ul>
<p><a href="https://www.reddit.com/r/linux/comments/7lsajn/oil_shell_03_release/drom6q4/">Original question and answer</a> (reddit.com)</p>
<a name="shouldnt-we-discourage-people-from-writing-shell-scripts"></a>
<h3>Shouldn't we discourage people from writing shell scripts?</h3>
<p>There are three problems with that:</p>
<ol>
<li><strong>It won't work</strong>.  It would be like trying to convince people who are paid
to write PHP not to write PHP.  Many people have wasted breath on that, but
important sites like Wikipedia are still written in <a href="https://www.mediawiki.org/wiki/MediaWiki">hundreds of thousands
of lines of PHP</a>.</li>
<li>Even if a new line of shell never gets written, there will still be a <strong>huge
installed base</strong> of shell scripts that you may need to understand (e.g. when
they don't work).</li>
<li>Shell is <strong>still the best tool</strong> for many jobs.  Most new "cloud" projects
rely on Linux system images, in VMs or containers, and shell is the ideal
language for creating such images.   Even if you use a framework like Chef
or Docker, you're still using bits of shell.</li>
</ol>
<a name="shouldnt-scripts-over-100-lines-be-rewritten-in-python-or-ruby"></a>
<h3>Shouldn't scripts over 100 lines be rewritten in Python or Ruby?</h3>
<p>That's a reasonable choice in some circumstances.  If everyone on your dev team
knows Python, maintaining a shell script can be more costly than maintaining a
Python script.</p>
<p>However, Python and Ruby aren't good shell replacements in general.  Shell is a
domain-specific language for dealing with <strong>concurrent processes</strong> and the
<strong>file system</strong>.  But Python and Ruby have too much abstraction over these
concepts, sometimes in the name of portability (e.g. to Windows).  They hide
what's really going on.</p>
<p>I encountered a nice blog post, <a href="https://medium.com/capital-one-developers/bashing-the-bash-replacing-shell-scripts-with-python-d8d201bc0989">Replacing Shell Scripts with
Python</a>, which, in my opinion, inadvertently proves the
opposite point.  The Python version is longer and has more dependencies.  In
other words, it's more difficult to write and maintain.</p>
<p>Also see the <a href="http://www.oilshell.org/blog/2021/01/philosophy-design.html#the-biggest-misconception-shell-xor-python">The Biggest Misconception: Shell XOR Python</a> in <a href="http://www.oilshell.org/blog/2021/01/philosophy-design.html">yesterday's
post</a>.</p>

<a name="are-you-reinventing-perl"></a>
<h3>Are you reinventing Perl?</h3>
<p>It's true that Perl is closer to shell than Python and Ruby are.  For example,
the <code>perl -pie</code> idiom can take the place of <code>awk</code> and <code>sed</code>.  However, Perl isn't
an acceptable shell either:</p>
<ul>
<li>It doesn't have true pipelines (of processes).  I believe you have to "shell
out" for this.</li>
<li>It doesn't have a concept of file descriptor state.  How do you write the
equivalent of <code>my_shell_func 2&gt; err.txt</code>, where <code>my_shell_func</code> can invoke
both functions and external commands?</li>
<li>Perl has a function called <code>grep()</code>, but the real <code>grep</code> is better for many
problems.</li>
</ul>
<p>Also:</p>
<ul>
<li>Perl has been around for more than 30 years, and hasn't replaced shell.  It
hasn't replaced <code>sed</code> and <code>awk</code> either.</li>
<li>Perl 6 and Python 3 are both less-suited to shell-like problems than their
predecessors.  In other words, we still need a new shell.</li>
</ul>
<p>However, it's true that, in some respects, Oil is retreading the same ground as
Perl.  But Oil is more faithful to shell, and its syntax uses fewer punctuation
characters.  In other words, it's less like "line noise".</p>
<p>Threads:</p>
<ul>
<li><a href="https://www.reddit.com/r/linux/comments/7lsajn/oil_shell_03_release/drp7jv6/">Perl vs Shell</a> (reddit)</li>
<li><a href="https://news.ycombinator.com/item?id=16228941">Are you reinventing Perl?</a> (Hacker News)</li>
</ul>
<a name="im-still-angry-and-i-dont-want-you-to-create-a-new-shell"></a>
<h3>I'm still angry, and I don't want you to create a new shell.</h3>
<p>You might be angry because you had to maintain a nasty shell script written by
a coworker.</p>
<p>If that's the case, you should be helping Oil succeed!  The only way to "kill
bash" is to:</p>
<ol>
<li>Reimplement it, then</li>
<li>Gradually migrate away from it.</li>
</ol>
<p>This is analogous to how Facebook is moving away from PHP by developing a
similar, but cleaner, language called <a href="http://hacklang.org/">Hack</a>.</p>
<p>Perl, Python, and Ruby have all existed for over 25 years, but they haven't
replaced shell.  New shell scripts are being written every day.</p>
<ul>
<li><a href="https://news.ycombinator.com/item?id=16154891">Angry Comment</a> (Hacker News)</li>
<li><a href="https://news.ycombinator.com/item?id=16156689">My Response</a> (Hacker News)</li>
</ul>
<p>(Oil also has some similarity to <a href="http://coffeescript.org/">CoffeeScript</a>, which smoothed over some of
JavaScript's rough edges and added syntactic sugar, but didn't stray from its
core execution model.  CoffeeScript was a success because it influenced
subsequent versions of JavaScript.)</p>
<a name="should-i-limit-myself-to-posix-shell-scripts"></a>
<h3 id="limit-to-posix">Should I limit myself to POSIX shell scripts?</h3>
<p>I've seen this suggestion a lot, and there are entire books devoted to it.  If
your script is <strong>small</strong>, it may be a reasonable goal.</p>
<p>For bigger programs, limiting yourself to POSIX is not just inconvenient, it's
also an ill-defined and virtually untestable concept.  Evidence:</p>
<ul>
<li>
<p>The Debian project created a minimal shell variant called <a href="http://www.oilshell.org/cross-ref.html?tag=dash#dash">dash</a>, which
replaced <a href="http://www.oilshell.org/cross-ref.html?tag=bash#bash">bash</a>.  However, <code>dash</code> and the <a href="https://www.debian.org/doc/debian-policy/#scripts">Debian Policy on Shell
Scripts</a> both allow non-POSIX features, like <code>local</code>.  Local
variables are essential for writing maintainable shell scripts, but POSIX
doesn't mention them.</p>
</li>
<li>
<p>Most shells <a href="http://lists.gnu.org/archive/html/help-bash/2018-01/msg00000.html">parse assignment builtins differently than other
builtins</a>, but the <a href="http://www.oilshell.org/cross-ref.html?tag=posix-grammar#posix-grammar">POSIX shell grammar</a>
has no notion of an assignment.  This issue surfaced as early as 2010, but as
of 2018, it's not in a published spec.</p>
<p>This issue <strong>isn't theoretical</strong> — <a href="http://www.oilshell.org/cross-ref.html?tag=bash#bash">bash</a> and <a href="http://www.oilshell.org/cross-ref.html?tag=dash#dash">dash</a> differ in
practice, but POSIX doesn't specify which is correct.</p>
<p>In other words, POSIX is incomplete and out of date.  (However, I've
discovered that shells are highly conformant with respect to things the
standard <strong>does</strong> specify.)</p>
</li>
</ul>
<p>As of 2021, I believe that OSH is a "better POSIX".  POSIX is a <strong>descriptive</strong>
specification and not a <strong>normative</strong> one. That means that it's an observation
of how popular shells like <a href="http://www.oilshell.org/cross-ref.html?tag=ksh#ksh">ksh</a> and <a href="http://www.oilshell.org/cross-ref.html?tag=bash#bash">bash</a> happened to behave at a certain
time.  In other words, it's a compromise.</p>
<p>Similarly, OSH is based on <a href="http://www.oilshell.org/blog/2017/06/22.html">extensive testing</a> of the behavior of <a href="http://www.oilshell.org/cross-ref.html?tag=bash#bash">bash</a>,
<a href="http://www.oilshell.org/cross-ref.html?tag=dash#dash">dash</a>, <a href="http://www.oilshell.org/cross-ref.html?tag=mksh#mksh">mksh</a>, <a href="http://www.oilshell.org/cross-ref.html?tag=zsh#zsh">zsh</a>, and <a href="http://www.oilshell.org/cross-ref.html?tag=busybox#busybox">busybox</a> <code>ash</code>.  That is, it uses the
same philosophy as POSIX, but it specifies more of the language.  Roughly
speaking, <a href="http://www.oilshell.org/cross-ref.html?tag=spec-test#spec-test">spec tests</a> are an <strong>executable specification</strong>.</p>
<ul>
<li><a href="http://lists.gnu.org/archive/html/help-bash/2018-01/msg00002.html">Tilde Expansion</a>: Another case where shells diverge in practice, but
POSIX is silent.</li>
</ul>

<a name="how-can-you-design-a-good-language-on-top-of-shell"></a>
<h3>How can you design a good language on top of shell?</h3>
<p>POSIX shell has global options that affect parsing and execution like <code>set -o noglob</code>.  And <a href="http://www.oilshell.org/cross-ref.html?tag=bash#bash">bash</a> extends them with options like <code>shopt -s lastpipe</code>.</p>
<p>Oil continues in the same vein, adding several shell options under <code>s…</code></p></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://www.oilshell.org/blog/2021/01/why-a-new-shell.html">http://www.oilshell.org/blog/2021/01/why-a-new-shell.html</a></em></p>]]>
            </description>
            <link>http://www.oilshell.org/blog/2021/01/why-a-new-shell.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25924647</guid>
            <pubDate>Wed, 27 Jan 2021 05:26:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Culture War: Iain M. Banks’s Billionaire Fans]]>
            </title>
            <description>
<![CDATA[
Score 145 | Comments 270 (<a href="https://news.ycombinator.com/item?id=25924560">thread link</a>) | @captaincrowbar
<br/>
January 26, 2021 | https://bloodknife.com/culture-war-iain-m-banks-jeff-bezos/ | <a href="https://web.archive.org/web/*/https://bloodknife.com/culture-war-iain-m-banks-jeff-bezos/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                    
<h3 itemprop="name">
            The Culture War: Iain M. Banks’s Billionaire Fans    </h3>                    
<h4><strong>Why Elon Musk and Jeff Bezos love Iain M. Banks’ anarcho-communist space opera</strong>.</h4>



<p><strong>by Kurt Schiller</strong></p>



<p>Explicitly ideological fiction is as old as fiction itself. From ancient steles that boasted unconvincingly of the glorious defeat of the Sea Peoples to the biased histories of that ancient greek fabulist Herodotus, humans have always had a tendency to entangle ideology and entertainment.</p>



<p>And if anything, the last hundred years have only seen this tendency grow. Fiction—whether the written word or newer mediums—has remained a popular standard-bearer for ideologies as diverse as technocratic liberalism (<em>The West Wing</em>), free market right-libertarianism (<em>Atlas Shrugged</em>, <em>The Moon Is a Harsh Mistress</em>), socialism (<em>The Jungle</em>, <em>The Iron Heel</em>), and even violent white supremacy (<em>The Turner Diaries</em>, <em>The Camp of the Saints</em>). And in the 21st century, the ideological implications of media consumption have become as micro-targeted as the media themselves: if you are a “true American patriot”, you might consume such jingoistic potboilers as <em>13 Hours: The Secret Soldiers of Benghazi </em>or the suburbs-vs-antifa thriller <em>The Reliant</em>. If you are a god-fearing evangelical, perhaps <em>Assassin 33 A.D.</em> or the Kevin Sorbo-fronted <em>God’s Not Dead </em>series are more your speed. Seeking to seize the means? Perhaps you can first seize a controller and dig into <em>Tonight We Riot</em> or Disco Elysium.&nbsp;</p>



<div><figure><img loading="lazy" width="460" height="276" src="https://bloodknife.com/wp-content/uploads/2021/01/iain-banks.jpg" alt="" srcset="https://bloodknife.com/wp-content/uploads/2021/01/iain-banks.jpg 460w, https://bloodknife.com/wp-content/uploads/2021/01/iain-banks-300x180.jpg 300w" sizes="(max-width: 460px) 100vw, 460px"></figure></div>



<p>Meanwhile, the reverse has also become true: “If a particular piece of media reeks of ideological impurity,” the conventional wisdom seems to go, “why bother? Why would you let those toxic ideas into your head?”</p>



<p>For all that these notions of ideological contagion and symbology are hilariously overblown, there’s some truth to the matter. At times, reading or watching long-form fiction from someone to whom you are ideologically opposed can feel exhausting, draining, aggravating, and ultimately a bit futile—like being at a party where you simply don’t like anyone, don’t care about the discussions, and are annoyed at the food. There’s much to be gained by engaging with our rhetorical opponents… but, frankly, only up to a point.</p>



<p>What then are we to take from the distinct and quite public fascination of the two richest men in the world—Jeff Bezos and Elon Musk, together worth more than $375 billion—with the sci-fi works of Iain M. Banks, an avowedly socialist author who set his far-future fiction in what might best be described as a post-scarcity, anarcho-communist utopia; a world where your Bezoses and your Musks are not just irrelevant, but actively sought out and disempowered by a society comprised of property-less workers and all-caring, mostly-benevolent A.I.s?</p>



<p>*  *  *  *  *</p>



<p>Iain M. Banks’s <em>Culture </em>series—consisting of 10 largely standalone novels and a handful of short stories published between 1987 and the author’s death in 2013—charts the intrigues, impacts, and subterfuges of a group of space-faring, far-future transhumans called The Culture.&nbsp;</p>



<p>In some ways, it’s an almost archetypal space opera. Tough-as-nails soldiers and shady sci-fi diplomats wage war across a variety of fantastical planets and megastructures. Massive, high-tech ships piloted by ultra-powerful self-aware A.I. called Minds have super-science duels among the stars. There are assassinations, revolutions, mass battles with hundreds of ships that play out on a grand scale (while taking only a fraction of a second in objective time).</p>



<p>At first glance, it seems like exactly what you’re imagining when you hear the phrase “space opera,” and so of course two super-wealthy spaceflight-and-sci-fi aficionados would be fans, right? After all, both men own private spaceflight contractors (Musk’s SpaceX and Bezos’s Blue Origin) and speak often of mankind’s future among the stars, with Musk <a href="https://www.spacex.com/human-spaceflight/mars/"><strong>proposing a mission to Mars</strong></a> and Bezos <a href="https://www.theverge.com/2019/5/11/18564655/blue-origin-jeff-bezos-space-moon-new-glenn"><strong>pitching a return to the moon and other intrasystem exploration</strong></a>. Seeking the stars seems to be in their blood (assuming it hasn’t been completely replaced with <a href="https://bloodknife.com/buy-happiness-here/"><strong>Soylent and whatever nootropics billionaires get</strong></a>).</p>



<div><figure><img loading="lazy" src="https://bloodknife.com/wp-content/uploads/2021/01/Screen-Shot-2021-01-22-at-12.01.23-AM.png" alt="" width="438" height="576" srcset="https://bloodknife.com/wp-content/uploads/2021/01/Screen-Shot-2021-01-22-at-12.01.23-AM.png 536w, https://bloodknife.com/wp-content/uploads/2021/01/Screen-Shot-2021-01-22-at-12.01.23-AM-228x300.png 228w" sizes="(max-width: 438px) 100vw, 438px"></figure></div>



<p>Both men have found ways to conspicuously show their fandom: Musk by <a href="https://www.tor.com/2015/01/23/elon-musk-iain-m-banks-just-read-the-instructions/"><strong>naming SpaceX rockets after Banks’s tongue-in-cheek Culture ships</strong></a> (“Just Read The Instructions,” “Of Course I Still Love You”) and a “brain interface” loosely patterned after the Culture’s neural laces; Bezos by attempting to bankroll a big-budget TV series based on the books, although this latter effort was unceremoniously canceled after Banks’s estate abruptly backed out. (Probably a wise decision, given both the challenge of adapting the material and the absurdity of one of the most exploitative corporations in the world attempting to adapt proudly far-left sci-fi.)</p>



<p>Apart from official projects, both men have made public references to Banks’s work as well—not much, but enough to know that they either really have read it, or that they were well-briefed by their PR teams.</p>



<p>“The Culture series is certainly, in terms of more modern science fiction, one of my absolute favorites,” Jeff Bezos <a href="https://www.geekwire.com/2018/jeff-bezos-isdc-space-vision/"><strong>told GeekWire in 2018</strong></a>, when asked about his love for the series. ”We’re not quite at that level technologically, we’ve a lot of work to do before we get there, but there’s a utopian element to it that I find very attractive.”</p>



<p>*  *  *  *  *</p>



<p>There are ultimately two things that set the <em>Culture </em>series apart from many of its peers.</p>



<p>The first is the literary bent of the prose. Space opera (and genre fiction in general) has never <em>actually</em> looked like the “lasers and explosions” stereotype it was saddled with, but it’s worth emphasizing the depth of Banks’s characterization and strange depictions of an uncanny future.&nbsp;</p>



<p>Characters grapple with trauma, identity, and crisis, and they do so without losing sight of the visceral and pulpy thrill of space opera’s inherent adventure and intrigue. Moments of quiet contemplation and deep metaphysical quandaries abound, coupled with strange literary pretensions that wouldn’t seem out of place in magical realism or literary fiction—a vast machine the size of a planet made of interlocking, nested globes, each holding a separate society; a grief-sick partner who holds their pregnancy in stasis for the better part of a century in a strange act of penance and passive-aggression; a vast extra-dimensional object that resists all attempts to analyze, communicate, or attack it, nearly sparking an interstellar war. The stories of the Culture simultaneously have a very real sense of strangeness and a deep, complex humanist bent, as if picking the best bit from multiple genres without losing the sense and feel of each constituent part.</p>



<figure><blockquote><p><span><strong>Since he first came onto the literary scene in the mid-Eighties, Banks was an avowed and rather public socialist.&nbsp;</strong></span></p></blockquote></figure>



<p>Perhaps this savvy genre-bending should come as no surprise, considering Banks was an established author of literary fiction before he broke through as a sci-fi writer. While he had always dreamed of writing sci-fi (and indeed wrote at least one Culture novel before breaking through as a lit-fic author), it wasn’t until his break-out literary novel <em>The Wasp Factory</em> (1984) that he was able to start selling his sci-fi manuscripts, eventually settling into a rhythm where he danced more-or-less annually between mind-bending literary fiction published under the name Iain Banks and epic sci-fi novels published under the name “Iain <em>M.</em> Banks.” (His family, Banks explained, was offended he hadn’t used his middle name—Menzies—on <em>The Wasp Factory</em>.)</p>



<p>The other thing that sets both Banks and his <em>Culture </em>books apart is their overt and uncompromising politics.</p>



<p>Since he first came onto the literary scene in the mid-Eighties, Banks was an avowed and rather public socialist. He was a member of the Scottish Socialist Party and a frequent interviewee for magazines like <em>Socialist Worker</em>, as well as an outspoken opponent of the Iraq War who campaigned for the impeachment of Tony Blair and, when that failed, <a href="https://www.theguardian.com/books/2007/may/25/hayfestival2007.hayfestival"><strong>shredded his passport and mailed the remains to 10 Downing Street</strong>.</a> He spoke openly, and passionately, about labor exploitation, anti-imperialism, the environment, and a host of other now-popular issues, most of which still languished on the edge of the discourse when Banks first hit the scene.</p>



<p>He was also never shy about intermingling his politics and his work. Indeed, he saw them as being one and the same. Nowhere is this more clear than in a <a href="http://www.vavatch.co.uk/books/banks/cultnote.htm"><strong>1994 essay titled “A Few Notes on the Culture,”</strong></a> which Banks posted to the Usenet group rec.arts.sf.written. The sprawling document is both an overview of the Culture and an exegesis on Banks’s own worldview; between paragraphs delving into the society’s naming conventions, technology, and democratic apparatuses, Banks waxed poetic about the deleterious moral impact of capitalism and market forces:</p>



<blockquote><p><em>“The market, for all its (profoundly inelegant) complexities, remains a crude and essentially blind system, and is – without the sort of drastic amendments liable to cripple the economic efficacy which is its greatest claimed asset – intrinsically incapable of distinguishing between simple non-use of matter resulting from processal superfluity and the acute, prolonged and wide-spread suffering of conscious beings.</em></p><p><em>It is, arguably, in the elevation of this profoundly mechanistic (and in that sense perversely innocent) system to a position above all other moral, philosophical and political values and considerations that humankind displays most convincingly both its present intellectual [immaturity and] – through grossly pursued selfishness rather than the applied hatred of others – a kind of synthetic evil.”</em></p><cite>Iain M. Banks, “A Few Notes on the Culture”</cite></blockquote>



<p>These same politics have been front and center in Banks’s conception of the Culture, a group he affectionately described as “hippie commies with hyper-weapons and a deep distrust of both Marketolatry and Greedism.”</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://bloodknife.com/culture-war-iain-m-banks-jeff-bezos/">https://bloodknife.com/culture-war-iain-m-banks-jeff-bezos/</a></em></p>]]>
            </description>
            <link>https://bloodknife.com/culture-war-iain-m-banks-jeff-bezos/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25924560</guid>
            <pubDate>Wed, 27 Jan 2021 05:11:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A history of amulets in ten objects (2019)]]>
            </title>
            <description>
<![CDATA[
Score 14 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25923490">thread link</a>) | @benbreen
<br/>
January 26, 2021 | http://journal.sciencemuseum.ac.uk/browse/issue-11/a-history-of-amulets-in-ten-objects/ | <a href="https://web.archive.org/web/*/http://journal.sciencemuseum.ac.uk/browse/issue-11/a-history-of-amulets-in-ten-objects/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article itemscope="" itemtype="http://schema.org/Article">
    

        
        
    <img src="http://journal.sciencemuseum.ac.uk/ImageGen.ashx?image=/media/3924/fig-6-a666087_-0002-hero-b.jpg&amp;compression=90&amp;width=558" alt="Colour photograph of a number of holed stones threaded onto twine" title="Colour photograph of a number of holed stones threaded onto twine" data-image-med="/ImageGen.ashx?image=/media/3924/fig-6-a666087_-0002-hero-b.jpg&amp;compression=70&amp;width=558" data-image-large="/ImageGen.ashx?image=/media/3924/fig-6-a666087_-0002-hero-b.jpg&amp;compression=90&amp;width=558">
    

<section id="abstract">
    <h2>Abstract</h2>
    <p>What are amulets? How are they situated in the larger narrative of European healing? Varied and complex objects, amulets present both challenges and opportunities for historians and museums alike. Yet an examination of these often-overlooked items within a medical context can provide significant information about cure and protection over different times and geographies. This article analyses ten amulets from the Science Museum collections, and asks what we can learn from exploring these objects’ material features and varying functions. It argues for a re-consideration of amulets from their categorisation by nineteenth- and twentieth-century collectors and classification by modern museums, to their recognition as a significant part of the history of healing.</p>
    <p>
        Component DOI: <a href="http://dx.doi.org/10.15180/191103/001">http://dx.doi.org/10.15180/191103/001</a>
    </p> 
</section>        
    <section id="keywords">
        <h2>Keywords</h2>
        <p>Amulets, collecting, Europe, healing, history, material culture, medicine, museums, objects</p>
            
        <a id="link-show-all-tags" href="#tag-cloud">View tags for the article</a>
    </section>
        <section id="main-body">
                <div id="text-1">
                    


<h2>Introduction – a hare’s foot and a Billiken</h2>


<p>On his way home from running errands one morning in January 1665, Samuel Pepys stopped to buy a hare. Pepys was a Member of Parliament and administrator of the Navy, and is perhaps most famous for keeping a diary for almost a decade during his younger life. A few weeks earlier, despite ‘very cold weather’ he had celebrated a phase of good health, unsure whether to attribute it to his daily pill of turpentine, the fact that he had ‘left off the wearing of a gowne’, or simply his ‘hare’s foote’. Yet this good health did not last. The new year brought burning, pimples and pricks, bladder problems, headaches and ‘a great deal of pain’ to Pepys’ body (<a href="#reference-60">Pepys; Wheatley (ed), 1893</a>).<a href="#footnote-1">[1]</a> On this January morning, however, he had run into an acquaintance at Westminster Hall – Sir William Batten, Member of Parliament and surveyor to the Navy (<a href="#reference-59">Pepys, Latham (ed), 2003, p xlv</a>).<a href="#footnote-2">[2]</a> Batten had given Pepys medical advice regarding his latest ailment, a most painful bout of colic, for which he showed Pepys the mistake he had made with the hare’s foot and guaranteed the perfect modification to his remedy. Originally, the foot had not been cut properly, and ‘hath not the joynt to it’; this was where the problem lay.<a href="#footnote-3">[3]</a> Eager to try anything to alleviate his swollen belly and ‘grudgings of wind’, Pepys handled Batten’s correctly cut hare’s foot, and noted in wonder:</p>
<p>[Batten] assures me he never had his cholique since he carried it about him: and it is a strange thing how fancy works, for I no sooner almost handled his foote but my belly began to be loose and to break wind, and whereas I was in some pain yesterday and t’other day and in fear of more to-day, I became very well, and so continue.<a href="#footnote-4">[4]</a></p>
<p>The next day, having obtained a new animal and taken Batten’s advice, Pepys was finally convinced: ‘To my office till past 12, and then home to supper and to bed, being now mighty well, and truly I cannot but impute it to my fresh hare’s foote.’<a href="#footnote-5">[5]</a> One thing was clear; the hare’s foot had worked. Pepys was cured of colic.</p>
<section id="doi11704">
    <div>
            <h3>Figure 1</h3>
        <p><img src="http://journal.sciencemuseum.ac.uk/ImageGen.ashx?image=/media/3845/fig-1-a666124_-0001.jpg&amp;compression=90&amp;width=558" alt="Colour photograph of a fox paw amulet" title="Colour photograph of a fox paw amulet" data-image-med="/ImageGen.ashx?image=/media/3845/fig-1-a666124_-0001.jpg&amp;compression=70&amp;width=558" data-image-small="/ImageGen.ashx?image=/media/3845/fig-1-a666124_-0001.jpg&amp;compression=60&amp;width=558" data-image-large="/ImageGen.ashx?image=/media/3845/fig-1-a666124_-0001.jpg&amp;compression=90&amp;width=558"></p><p>
            © Science Museum/Science &amp; Society Picture Library
        </p> 

    </div> 
        <p>Amulet One – Hare’s foot, object number A666124</p>
        
    
    
</section>
<p>This object is not unfamiliar to us. This particular hare’s foot, which forms part of the Science Museum’s amulet collection, is originally from Norfolk and dated 1870–1920, but hares’ and rabbits’ feet can still be bought as ‘lucky charms’ and are widely available on the internet.<a href="#footnote-6">[6]</a>&nbsp; Populist literature similarly continues to reference the use of these items; <em>Scientific American</em> published an article on ‘What Makes a Rabbit’s Foot Lucky’ in 2011 (<a href="#reference-19">D’Costa, 2011</a>). Such objects remain a part of popular culture – that is, part of recognised cultural traditions – over three hundred years after being employed by Pepys. Yet we can observe a shift in function. In Pepys’ world, the various elements that constituted sickness and health were broad and wide-ranging. Illness, like health, could be affected by an extensive range of things from an imbalance of the bodily humours, environmental factors such as sleep, food, emotions and exercise, supernatural or preternatural forces, and even the stars.<a href="#footnote-7">[7]</a> Whilst Pepys sometimes consulted learned medical practitioners, the variety of people from whom he could seek counsel was extensive. In this case, he took the advice of his friend Sir William Batten.<a href="#footnote-8">[8]</a> Pepys’ story is part of a larger narrative of healing in which learned medicine, religion, astrology, magic, fate and fortune all played a role. As part of healing, objects could be invested with power from any one or more of these various sources, and employed to cure or protect. These objects have often been called amulets, both historically and today, although our interpretation of them has changed over time. The healing potency of amulets has not always been entirely understood, and their means of operation often hidden from comprehension. Yet within their own contexts, this functional complexity has not detracted from the items’ curative or protective effects. The narrative of healing that included amulets continued throughout the seventeenth, eighteenth and nineteenth centuries, and only when modern medicine necessitated ‘scientific’, empiric evidence of the mechanisms of objects’ efficacy did this change. In other words, amulets were relegated from the domain of authorised healing once it became a requirement to know and explain <em>how</em> cures worked, not just that they <em>did</em> work.</p>
<div><p>The word ‘amulet’ originates from the Latin ‘amulētum’, and was used by Pliny the Elder (23–79 CE) to denote an item worn on the body for therapeutic, apotropaic or exorcistic benefit (Skemer, 2006, pp 6–7). Whilst many have noted the belief that the word can be traced back to Arabic, the Oxford English Dictionary (OED) has refuted this (<a href="#reference-56">OED, 2018, ‘amulet’</a>). Whilst definitions vary, ‘charm’ is often used synonymously with ‘amulet’, whilst ‘talisman’ features less frequently. For instance, the Pitt Rivers Museum in Oxford has implied a semantic similarity between ‘amulets’ and ‘charms’, noting that an amulet is defined by the OED as: ‘Anything worn about the person as a charm preventative against evil, mischief, disease, witchcraft, etc.’, whilst a charm is described as ‘Anything worn about the person to avert evil or ensure prosperity’ – ‘though a charm may also be a spell or incantation believed to have a magical power’ (<a href="#reference-61">Pitt Rivers Museum, 2017</a>). ‘Amulets’ and ‘charms’ are also used synonymously by the Horniman Museum in London, and the Oxford English Dictionary’s definitions further allude to this; one entry noting that a charm is ‘Anything worn about the person to avert evil or ensure prosperity; an amulet’ (<a href="#reference-39">Horniman Museum, 2017</a>).<a href="#footnote-9">[9]</a></p><p>Evidently, amulets cannot be easily and simply defined, in part because the ways in which they have been used and understood have changed from antiquity to today. What, then, is the defining feature which makes an object an amulet? The answer to this is, its power. In the most basic and fundamental way, amulets are invested with the potency to heal. Healing centres around cure and protection, but where once these two actions were closely related, now they are more distinct. Historically, healing has not been monolithic and has taken many forms, relating to and deriving from faculties of fortune, fate, astrology, religion, magic, luck and more. Healing could therefore constitute anything from curing a specific disease, to averting a malevolent force, or fostering good fortune. This functional variation is valuable, as it can tell us a great deal about the practices and cultures in which objects are situated, as well as the objects themselves. For instance, around 250 years after Pepys cured his colic with our first amulet, the hare’s foot, an amusement park opened in Paris. As part of their brand <em>Luna Park</em> adopted a mascot known as a ‘Billiken’, a creature devised by an American artist who reportedly saw the mysterious figure in a dream and patented it in 1908. The Billiken, known as ‘God of Things as They Ought To Be’ was said to bring the customer luck, indicated by the inscription upon our second object, the park’s token: <em>Si tu me gardes je te porterai bonheur</em> (‘If you keep me I will bring you good luck/happiness’) / ‘I smile at you bad luck can’t harm you’.<a href="#footnote-10">[10]</a> This amulet offered protection and generated auspicious effects to the person who possessed it. Evidently, it had been considered important enough to be kept. Thus whilst culturally, temporally and materially distinct, the hare’s foot and the Luna Park Billiken are nevertheless united by their curative and protective potency, and demonstrate the wide spectrum of healing.</p></div>
<section id="doi11705">
    <div>
            <h3>Figure 2</h3>
        <p><img src="http://journal.sciencemuseum.ac.uk/ImageGen.ashx?image=/media/3846/fig-2.jpg&amp;compression=90&amp;width=558" alt="Colour photograph of the front and reverse side of a coin amulet for good luck" title="Colour photograph of the front and reverse side of a coin amulet for good luck" data-image-med="/ImageGen.ashx?image=/media/3846/fig-2.jpg&amp;compression=70&amp;width=558" data-image-small="/ImageGen.ashx?image=/media/3846/fig-2.jpg&amp;compression=60&amp;width=558" data-image-large="/ImageGen.ashx?image=/media/3846/fig-2.jpg&amp;compression=90&amp;width=558"></p><p>
            © Science Museum/Science &amp; Society Picture Library
        </p> 

    </div> 
        <p>Amulet Two – Luna Park Billiken, object number A665090/1</p>
        
    
    
</section>
<div><p>Yet where once healing and amulets went hand in hand, modern discussions tend to treat them as distinct. Labelling certain objects as ‘amulets’ questions their power to work, and when these items and their potency are challenged, they are ‘othered’, relegated and disassociated from the realms of healing. The hare’s foot provides an example of this. Whether situated in museum collections or referred to in common parlance, this amulet is not commonly recognised today as a curative object, nor regarded as an effective remedy for the colic. Instead, the feet of rabbits and hares are now bought, used and regarded often merely as ‘lucky’ items. This hare’s foot from the Science Museum’s collections is recorded as an amulet employed ‘for protection against cramp’.<a href="#footnote-11">[11]</a> To label something as prophylactic, an item ‘against’ a particular affliction exemplifies …</p></div></div></section></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://journal.sciencemuseum.ac.uk/browse/issue-11/a-history-of-amulets-in-ten-objects/">http://journal.sciencemuseum.ac.uk/browse/issue-11/a-history-of-amulets-in-ten-objects/</a></em></p>]]>
            </description>
            <link>http://journal.sciencemuseum.ac.uk/browse/issue-11/a-history-of-amulets-in-ten-objects/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25923490</guid>
            <pubDate>Wed, 27 Jan 2021 02:16:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Twelve Requests per Second in Python]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25923226">thread link</a>) | @delduca
<br/>
January 26, 2021 | https://suade.org/dev/12-requests-per-second-with-python/ | <a href="https://web.archive.org/web/*/https://suade.org/dev/12-requests-per-second-with-python/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

<article>

<figure>
<img src="https://suade.org/content/images/2021/01/The_Tortoise_and_the_Hare_-_Project_Gutenberg_etext_19993-1.jpeg" alt="12 requests per second">
</figure>
<section>
<div>
<blockquote>
<p>A realistic look at Python web frameworks</p>
</blockquote>
<p>If you take a look around the blogosphere at various benchmarks for Python web frameworks, you might start to feel pretty bad about your own setup. Or, alternatively, super-hyped about the possibilities.</p><p>Consider, for instance, the incredible work of the guys at <a href="https://magic.io/blog/uvloop-blazing-fast-python-networking/">magic stack</a>, getting <strong>100,000 requests per second</strong> from <a href="https://github.com/MagicStack/uvloop">uvloop</a> in a single thread. This is on par with compiled language like Go's performance.</p><p>But that benchmark doesn't really cover a fully fleshed out web framework, right? We need a lot more functionality and structure from our frameworks than reading and writing bytes. What about fully fleshed-out web-frameworks in python?</p><p>One such framework is <a href="https://github.com/sanic-org/sanic">Sanic</a>, which again has been shown to have similar performance: <strong>100,000</strong> requests per-second. Or there's <a href="https://vibora.io/">Vibora</a>. Not only does this claim to be a drop-in replacement for <a href="https://github.com/pallets/flask">Flask</a>, but it also has its own templating engine. And it handles <strong>350,000 requests per second</strong>!</p><p>Even more mind-blowing is <a href="https://github.com/squeaky-pl/japronto">Japronto</a> which claims an insane <strong>1.2 million requests per-second</strong> in a single thread 🤯 trouncing the performance of other languages and frameworks:</p><p><img src="https://raw.githubusercontent.com/squeaky-pl/japronto/master/benchmarks/results.png" alt="https://github.com/squeaky-pl/japronto"></p><p>Recently we've been doing a lot of work improving the performance of our Python APIs. Currently we're running <a href="https://github.com/pallets/flask">Flask</a>, and we initially had a single question: <em>how can we serve more requests from a single worker thread? </em>But looking at these benchmarks had us asking more:</p><ol><li>Can we meaningfully compare them to our setup?</li><li>How realistic are they for a full production application?</li><li>Would we be better using one of these frameworks over Flask?</li></ol><p>In other words, how much should we trust these benchmarks? And to what extent should they influence our choice of technology?</p><p>In order to answer these questions, in this post, I benchmark a realistic Flask application along with it's <a href="https://github.com/sanic-org/sanic">Sanic</a> equivalent. I'm going to guess that most readers come from a background with one of the more "traditional" Python frameworks (<a href="https://github.com/pallets/flask">Flask</a> or <a href="https://www.djangoproject.com/">Django</a>), and it's certainly more relevant to devs here at Suade Labs. For this reason, I run the Flask app in a number of different ways, to see what the best bang for our buck is: how performant can we make our application with (almost) zero changes to the code? Along the way we'll pick up some tips for the original question: <em>how can we serve more requests from a single worker thread?</em></p><p><strong>Sidenote: </strong>if you're new to Python's web frameworks, or its asynchronous libraries, take a look at [1] from the addenda at the bottom of this post for a quick explainer. This post mostly assumes you know these things.</p><h2 id="the-baseline">The baseline</h2><p>First let's run some simple "Hello, World!" benchmarks on our system to get a meaningful baseline for comparison. For reference, the Flask benchmarks on <a href="https://www.techempower.com/benchmarks/#section=data-r18&amp;hw=ph&amp;test=fortune&amp;l=zijzen-f">techempower</a> give 25,000 requests per second.</p><p>Here's our Flask app:</p><pre><code>app = Flask(__name__)

@app.route("/", methods=["GET", "POST"])
def hello():
    if request.method == "GET":
        return "Hello, World!"

    data = request.get_json(force=True)
    try:
        return "Hello, {id}".format(**data)
    except KeyError:
        return "Missing required parameter 'id'", 400</code></pre><p>I ran it under a variety of conditions. First "raw" via <code>python app.py</code>, and then under <a href="https://gunicorn.org/">Gunicorn</a> with a single <code>sync</code> worker via <code>gunicorn -k sync app:app</code> and finally Gunicorn with a single <a href="https://github.com/gevent/gevent">gevent</a> worker via <code>gunicorn -k gevent app:app</code>. In theory Gunicorn should handle concurrency and dropped connections much better than the raw python, and using the gevent worker should allow us to do asynchronous IO without changing our code [2a]. We also ran these benchmarks under <a href="https://www.pypy.org/">PyPy</a>, which in theory should speed up any CPU-bound code without making any changes (if you haven't heard of PyPy see [2b] in the addenda below for a quick explanation and some terminology).</p><p>And what about Sanic? Well, here's the "rewrite" of our app:</p><pre><code>app = Sanic(__name__)

@app.route("/", methods=["GET", "POST"])
async def hello(request):
    if request.method == "GET":
        return text("Hello, World!")

    data = request.json
    try:
        return text("Hello, {id}".format(**data))
    except KeyError:
        raise InvalidUsage("Missing required parameter 'id'")</code></pre><p>And here are the results:</p><figure><img src="https://suade.org/content/images/2021/01/hello_world-3.png" alt="" srcset="https://suade.org/content/images/size/w600/2021/01/hello_world-3.png 600w, https://suade.org/content/images/size/w1000/2021/01/hello_world-3.png 1000w, https://suade.org/content/images/2021/01/hello_world-3.png 1161w" sizes="(min-width: 720px) 720px"></figure><div><p>Some technical details: I used Python 3.7 with the regular CPython interpreter and Python 3.6 with PyPy 7.3.3. At the time of writing, running 3.6 is the latest PyPy interpreter, and their Python 2.7 interpreter is faster in some edge cases, but as Python 2 is <a href="https://www.python.org/doc/sunset-python-2/">officially dead</a>, I don't believe it productive to benchmark. My system details are available in the addenda [3]. I used <a href="https://github.com/wg/wrk">wrk</a> to actually execute the benchmarks.</p><p>I'll break the results down in two parts. First: Sanic dominates, with 23,000 requests a second, although running our Flask app under Guncorn + gevent and PyPy does a pretty good job at keeping up. Second: what's going on with the performance range for our Flask app?</p></div><p>Under CPython, we see that using Gunicorn quadruples the number of Flask requests per second from 1,000 to 4,000 and using a gevent worker adds a mild (sub 10%) speed boost to this. The PyPy results are more impressive. In the raw test, it is churning through 3,000 requests a second; it received the same 4x speed boost from Gunicorn, getting us to 12,000 requests a second; finally with the addition of gevent, it cranks up to 17,000 requests a second, 17x more than the raw CPython version without changing a single line of code.</p><p>I was quite struck by the fact that gevent had such little effect on the CPython process - probably this is because the CPU is maxed out at this point. On the other hand, it seems that PyPy's better speed means it is still spending time waiting on system calls / IO, even under Gunicorn. Adding gevent to the mix means that it switches between concurrent connections, processing them as fast as the CPU will let it.</p><p>To get a real sense of this, I ran the benchmark whilst monitoring CPU usage. Here's a short test against the raw app under PyPy:</p><figure><img src="https://suade.org/content/images/2021/01/sync_cpu_usage.png" alt="" srcset="https://suade.org/content/images/size/w600/2021/01/sync_cpu_usage.png 600w, https://suade.org/content/images/2021/01/sync_cpu_usage.png 919w" sizes="(min-width: 720px) 720px"></figure><p>You can see that the program hops between CPU cores and rarely utilises 100% of a given core. On the other hand, here's part of a much longer test against the Gunicorn gevent worker under PyPy:</p><figure><img src="https://suade.org/content/images/2021/01/gevent_cpu_usage.png" alt="" srcset="https://suade.org/content/images/size/w600/2021/01/gevent_cpu_usage.png 600w, https://suade.org/content/images/2021/01/gevent_cpu_usage.png 900w" sizes="(min-width: 720px) 720px"></figure><p>Now it's evident that there is no switching between CPU cores (the process has become "sticky") and the individual core is being utilised to a far higher degree.</p><p><strong>Key takeaways</strong>: Sanic wins. PyPy is fast. Run your "traditional" app under Gunicorn.</p><h2 id="realistic-benchmarks">Realistic benchmarks</h2><div><p>The benchmark above, while fun, is pretty meaningless for real-world applications. Let's add some more functionality to our app!</p><p>First, we'll allow users to actually store data in a database, which we'll retrieve via an ORM (in our case <a href="https://www.sqlalchemy.org/">SQLAlchemy</a>, the de-facto stand-alone ORM in python). Second, we'll add input-validation to make sure our users get meaningful error messages, and that we're not accepting junk that crashes our app. Finally we'll add a response marshaller to automate the process of converting our database object to JSON.</p></div><p>We'll write a simple book store app, for a publishing house. We have a number of authors each writing zero or more books in several genres. For simplicity, each book has only a single author, but can have multiple genres - for example we could have a book which is in both the "Existential Fiction" and "Beatnik Poetry" categories. We're going to add 1 million authors to our database and roughly 10 million books. [4]</p><p>Our SQLAlchemy models look a little like this:</p>
<pre><code>class Author(db.Model):
    id = db.Column(UUIDType, primary_key=True)
    name = db.Column(db.String, nullable=False)
    ... # snip!

class Book(db.Model):
    author_id = db.Column(
        UUIDType, db.ForeignKey("author.id"), nullable=False, index=True
    )
    author = db.relationship("Author", backref="books")
    ... # snip!
</code></pre>
<p>To marshal these, we use <a href="https://marshmallow.readthedocs.io/en/stable/">Marshmallow</a>, which is a popular Python marshalling library. Here's an example of the Marshmallow model for the Author overview:</p>
<pre><code>class Author(Schema):
    id = fields.Str(dump_only=True)
    name = fields.Str(required=True)
    country_code = EnumField(CountryCodes, required=True)
    email = fields.Str(required=True)
    phone = fields.Str(required=True)
    contact_address = fields.Str(required=True)
    contract_started = fields.DateTime(format="iso")
    contract_finished = fields.DateTime(format="iso")
    contract_value = fields.Integer()
</code></pre>
<p>In our endpoints these are used for validating input and returning results like so:</p>
<pre><code>@bp.route("/author", methods=["GET", "POST"])
def author():
    """View all authors, or create a new one."""

    if request.method == "GET":
        args = validate_get(marshallers.LimitOffsetSchema())
        limit = args["limit"]
        offset = args["offset"]

        authors = Author.query.limit(limit).offset(offset).all()
        return jsonify(marshallers.authors.dump(authors))

    if request.method == "POST":
        author = Author(**validate_post(marshallers.author))

        db.session.add(author)
        db.session.commit()

        return jsonify({"id": author.id})
</code></pre>
<p>The full source code can be viewed in the <a href="https://github.com/olliemath/async_python">GitHub repo</a>. Here, the thing to note is that <code>marshallers.foo</code> is an instance of a <a href="https://marshmallow.readthedocs.io/en/stable/">Marshmallow</a> schema, which can be used both to validate a Foo input, for instance in a POST request, as well as to marshal Foo instances ready for returning as JSON.</p>
<p>In order to actually perform asynchronous database requests, some fancy footwork is required with patching libraries, which depends on which postgres connector you use. SQLAlchemy does not support this out of the box, and in fact its primary developer has a great post arguing that <a href="https://techspot.zzzeek.org/2015/02/15/asynchronous-python-and-databases/">an async ORM is not always a great idea</a>. Juicy technical details in addenda [5], but beware that just using a Gunicorn gevent worker will not necessarily get you what you want.</p><p>PyPy tends to suffer a performance hit when using C-extensions and libraries instead of pure python, conversely CPython should get a performance boost from the C-based libs. To take account of this I tested two different underlying database connectors: both <a href="https://github.com/psycopg/psycopg2">psycopg2</a> and a …</p></div></section></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://suade.org/dev/12-requests-per-second-with-python/">https://suade.org/dev/12-requests-per-second-with-python/</a></em></p>]]>
            </description>
            <link>https://suade.org/dev/12-requests-per-second-with-python/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25923226</guid>
            <pubDate>Wed, 27 Jan 2021 01:36:27 GMT</pubDate>
        </item>
    </channel>
</rss>
