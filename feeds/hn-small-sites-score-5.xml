<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 5]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 5. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Tue, 21 Jul 2020 08:18:02 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-5.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Tue, 21 Jul 2020 08:18:02 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[Optimizing 128-bit Division]]>
            </title>
            <description>
<![CDATA[
Score 22 | Comments 3 (<a href="https://news.ycombinator.com/item?id=23888177">thread link</a>) | @EvgeniyZh
<br/>
July 19, 2020 | https://danlark.org/2020/06/14/128-bit-division/ | <a href="https://web.archive.org/web/*/https://danlark.org/2020/06/14/128-bit-division/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">

	<section id="primary">
		<main id="main">

			
<article id="post-288">

	

	
	<div>
		
<p>When it comes to hashing, sometimes 64 bit is not enough, for example, because of <a href="https://en.wikipedia.org/wiki/Birthday_problem">birthday paradox</a> ‚Äî the hacker can iterate through random <img src="https://s0.wp.com/latex.php?latex=2%5E%7B32%7D&amp;bg=ffffff&amp;fg=111111&amp;s=0" alt="2^{32}" title="2^{32}"> entities and it can be proven that with some constant probability they will find a collision, i.e. two different objects will have the same hash. <img src="https://s0.wp.com/latex.php?latex=2%5E%7B32%7D&amp;bg=ffffff&amp;fg=111111&amp;s=0" alt="2^{32}" title="2^{32}"> is around 4 billion objects and with the current power capacity in each computer it is certainly achievable. That‚Äôs why we need sometimes to advance the bitness of hashing to at least 128 bits. Unfortunately, it comes with a cost because platforms and CPUs do not support 128 bit operations natively.</p>



<p>Division historically is the most complex operation on CPUs and all guidelines suggest avoiding the division at all costs.</p>



<p>At my job I faced an interesting problem of optimizing 128 bit division from <a href="https://github.com/abseil/abseil-cpp/blob/master/absl/numeric/int128.cc#L155">abseil library</a> in order to split some data across buckets with the help of 128 bit hashing (the number of buckets is not fixed for some uninteresting historical reasons). I found out that the division takes a really long time. The <a href="https://github.com/abseil/abseil-cpp/blob/master/absl/numeric/int128_benchmark.cc#L52">benchmarks</a> from abseil on Intel(R) Xeon(R) W-2135 CPU @ 3.70GHz show some horrible results</p>



<pre><code>Benchmark                       Time(ns)  CPU(ns)
BM_DivideClass128UniformDivisor     13.8     13.8  // 128 bit by 128 bit
BM_DivideClass128SmallDivisor        168      168  // 128 bit by 64 bit</code></pre>



<p>150 nanoseconds for dividing the random 128 bit number by a random 64 bit number? Sounds crazy. For example, <code>div</code> instruction on x86-64 Skylake takes 76 cycles (also, for AMD processors it is much less), the division takes around 20-22ns.</p>



<figure><img data-attachment-id="361" data-permalink="https://danlark.org/d2elnjfdkne/" data-orig-file="https://danlarkorg.files.wordpress.com/2020/06/d2elnjfdkne.png" data-orig-size="921,461" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="d2elnjfdkne" data-image-description="" data-medium-file="https://danlarkorg.files.wordpress.com/2020/06/d2elnjfdkne.png?w=300" data-large-file="https://danlarkorg.files.wordpress.com/2020/06/d2elnjfdkne.png?w=750" src="https://danlarkorg.files.wordpress.com/2020/06/d2elnjfdkne.png?w=921" alt="" srcset="https://danlarkorg.files.wordpress.com/2020/06/d2elnjfdkne.png 921w, https://danlarkorg.files.wordpress.com/2020/06/d2elnjfdkne.png?w=150 150w, https://danlarkorg.files.wordpress.com/2020/06/d2elnjfdkne.png?w=300 300w, https://danlarkorg.files.wordpress.com/2020/06/d2elnjfdkne.png?w=768 768w" sizes="(max-width: 921px) 100vw, 921px"><figcaption><a href="https://godbolt.org/z/o2vTZr">https://godbolt.org/z/o2vTZr</a></figcaption></figure>



<p>In reality everything is slightly better because of pipeline execution and division has its own ALU, so if you divide something and do something else in the next instructions, you will get lower average latency. Still, 128 bit division cannot be 8x slower than 64 bit division. All latencies you can find in Agner Fog <a href="https://www.agner.org/optimize/instruction_tables.pdf">instruction table</a> for most of the modern x86 CPUs. The truth is more complex and division latency can even depend on the values given.</p>



<figure><img data-attachment-id="299" data-permalink="https://danlark.org/2020-06-14-182043_835x215_scrot/" data-orig-file="https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-182043_835x215_scrot.png" data-orig-size="835,215" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="2020-06-14-182043_835x215_scrot" data-image-description="" data-medium-file="https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-182043_835x215_scrot.png?w=300" data-large-file="https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-182043_835x215_scrot.png?w=750" src="https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-182043_835x215_scrot.png?w=835" alt="" srcset="https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-182043_835x215_scrot.png 835w, https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-182043_835x215_scrot.png?w=150 150w, https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-182043_835x215_scrot.png?w=300 300w, https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-182043_835x215_scrot.png?w=768 768w" sizes="(max-width: 835px) 100vw, 835px"><figcaption>Agner Fog instruction table for Skylake CPUs, the second but last column is the latency.</figcaption></figure>



<p>Even compilers when dividing by some constants, try to use the reciprocal (or, the same as inverse in a ring) value and multiply the reciprocal and the value with some shifts afterwards</p>



<figure><img data-attachment-id="315" data-permalink="https://danlark.org/2020-06-14-192300_861x251_scrot/" data-orig-file="https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-192300_861x251_scrot.png" data-orig-size="861,251" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="2020-06-14-192300_861x251_scrot" data-image-description="" data-medium-file="https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-192300_861x251_scrot.png?w=300" data-large-file="https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-192300_861x251_scrot.png?w=750" src="https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-192300_861x251_scrot.png?w=861" alt="" srcset="https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-192300_861x251_scrot.png 861w, https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-192300_861x251_scrot.png?w=150 150w, https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-192300_861x251_scrot.png?w=300 300w, https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-192300_861x251_scrot.png?w=768 768w" sizes="(max-width: 861px) 100vw, 861px"><figcaption><a href="https://gcc.godbolt.org/z/PRibsx">https://gcc.godbolt.org/z/PRibsx</a></figcaption></figure>



<p>Overall, given the fact that only some <code>sin</code>, <code>cos</code> instructions cost more than division, division is one of the most complex instructions in CPUs and optimizations in that place matter a lot. My exact case was more or less general, maybe I was dividing 128 bit by 64 bit a bit more frequent. We are going to optimize the general case in LLVM.</p>



<p>We need to understand how 128 bit division is working through the compiler stack.</p>



<figure><img data-attachment-id="303" data-permalink="https://danlark.org/2020-06-14-183125_682x238_scrot/" data-orig-file="https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-183125_682x238_scrot.png" data-orig-size="682,238" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="2020-06-14-183125_682x238_scrot" data-image-description="" data-medium-file="https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-183125_682x238_scrot.png?w=300" data-large-file="https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-183125_682x238_scrot.png?w=682" src="https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-183125_682x238_scrot.png?w=682" alt="" srcset="https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-183125_682x238_scrot.png 682w, https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-183125_682x238_scrot.png?w=150 150w, https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-183125_682x238_scrot.png?w=300 300w" sizes="(max-width: 682px) 100vw, 682px"><figcaption><a href="https://gcc.godbolt.org/z/fB3aq2">https://gcc.godbolt.org/z/fB3aq2</a></figcaption></figure>



<p>It calls <code>__udivti3</code> function. Let‚Äôs first understand how to read these functions. In runtime libraries the modes of the functions are:</p>



<div><div>
<pre><code>QI: An integer that is as wide as the smallest addressable unit, usually 8 bits.
HI: An integer, twice as wide as a QI mode integer, usually 16 bits.
SI: An integer, four times as wide as a QI mode integer, usually 32 bits.
DI: An integer, eight times as wide as a QI mode integer, usually 64 bits.
SF: A floating point value, as wide as a SI mode integer, usually 32 bits.
DF: A floating point value, as wide as a DI mode integer, usually 64 bits.
TI: An integer, 16 times as wide as a QI mode integer, usually 128 bits.</code></pre>
</div></div>



<p>So, <code>udivti3</code> is an <strong>u</strong>nsigned division of TI (128 bits) integers, last ‚Äò<em>3‚Ä≤</em> means that it has 3 arguments including the return value. Also, there is a function <code>__udivmodti4</code> which computes the divisor and the remainder (division and modulo operation) and it has 4 arguments including the returning value. These functions are a part of runtime libraries which compilers provide by default. For example, in GCC it is <a href="http://gcc.gnu.org/onlinedocs/gccint/Libgcc.html#Libgcc">libgcc</a>, in LLVM it is <a href="https://compiler-rt.llvm.org/">compiler-rt</a>, they are linked almost in every program if you have the corresponding toolchain. In LLVM, <code>__udivti3</code> is a simple alias to <code>__udivmodti4</code>.</p>



<figure><div>

</div></figure>



<p><code><a href="https://github.com/llvm-mirror/compiler-rt/blob/release_90/lib/builtins/udivmodti4.c#L20">__udivmodti4</a></code> function was written with the help of <code>Translated from Figure 3-40 of The PowerPC Compiler Writer's Guide.</code> After looking at it <a href="https://cr.yp.to/2005-590/powerpc-cwg.pdf">here</a>, it looks like this was written long time ago and things have changed since then</p>



<figure><img data-attachment-id="313" data-permalink="https://danlark.org/2020-06-14-191400_1038x718_scrot/" data-orig-file="https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-191400_1038x718_scrot.png" data-orig-size="1038,718" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="2020-06-14-191400_1038x718_scrot" data-image-description="" data-medium-file="https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-191400_1038x718_scrot.png?w=300" data-large-file="https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-191400_1038x718_scrot.png?w=750" src="https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-191400_1038x718_scrot.png?w=1024" alt="" srcset="https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-191400_1038x718_scrot.png?w=1024 1024w, https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-191400_1038x718_scrot.png?w=150 150w, https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-191400_1038x718_scrot.png?w=300 300w, https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-191400_1038x718_scrot.png?w=768 768w, https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-191400_1038x718_scrot.png 1038w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<p>First of all, let‚Äôs come up with something easy, like shift-subtract algorithm that we have been learning since childhood. First, if <code>divisor &gt; dividend</code>, then the quotient is zero and remainder is the <code>dividend</code>, not an interesting case. </p>



<figure><div>

</div></figure>



<p>The algorithm is easy, we align the numbers by their most significant bits, if dividend is more than divisor, subtract and add 1 to the output, then shift by 1 and repeat.  Some sort of animation can be seen like that:</p>



<figure><img data-attachment-id="318" data-permalink="https://danlark.org/simplescreenrecorder-2020-06-14_20-23-25/" data-orig-file="https://danlarkorg.files.wordpress.com/2020/06/simplescreenrecorder-2020-06-14_20.23.25.gif" data-orig-size="918,442" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="simplescreenrecorder-2020-06-14_20.23.25" data-image-description="" data-medium-file="https://danlarkorg.files.wordpress.com/2020/06/simplescreenrecorder-2020-06-14_20.23.25.gif?w=300" data-large-file="https://danlarkorg.files.wordpress.com/2020/06/simplescreenrecorder-2020-06-14_20.23.25.gif?w=750" src="https://danlarkorg.files.wordpress.com/2020/06/simplescreenrecorder-2020-06-14_20.23.25.gif?w=918" alt=""></figure>



<p>For 128 bit division it will take at most 128 iterations in the for loop. Actually, the implementation in <a href="https://github.com/llvm-mirror/compiler-rt/blob/release_90/lib/builtins/udivmodti4.c#L173">LLVM</a> for loop is a fallback and we saw it takes 150+ns to complete it because it requires to shift many registers because 128 bit numbers are represented as two registers.</p>



<p>Now, let‚Äôs dive into the architecture features. I noticed that while the compiler generates the <code>divq</code> instructions, it frees <code>rdx</code> register</p>



<figure><img data-attachment-id="362" data-permalink="https://danlark.org/2ugj4bgvw4x/" data-orig-file="https://danlarkorg.files.wordpress.com/2020/06/2ugj4bgvw4x.png" data-orig-size="891,206" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="2ugj4bgvw4x" data-image-description="" data-medium-file="https://danlarkorg.files.wordpress.com/2020/06/2ugj4bgvw4x.png?w=300" data-large-file="https://danlarkorg.files.wordpress.com/2020/06/2ugj4bgvw4x.png?w=750" src="https://danlarkorg.files.wordpress.com/2020/06/2ugj4bgvw4x.png?w=891" alt="" srcset="https://danlarkorg.files.wordpress.com/2020/06/2ugj4bgvw4x.png 891w, https://danlarkorg.files.wordpress.com/2020/06/2ugj4bgvw4x.png?w=150 150w, https://danlarkorg.files.wordpress.com/2020/06/2ugj4bgvw4x.png?w=300 300w, https://danlarkorg.files.wordpress.com/2020/06/2ugj4bgvw4x.png?w=768 768w" sizes="(max-width: 891px) 100vw, 891px"></figure>



<p>In the manual they say the following</p>



<figure><img data-attachment-id="322" data-permalink="https://danlark.org/2020-06-14-204644_860x119_scrot/" data-orig-file="https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-204644_860x119_scrot.png" data-orig-size="860,119" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="2020-06-14-204644_860x119_scrot" data-image-description="" data-medium-file="https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-204644_860x119_scrot.png?w=300" data-large-file="https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-204644_860x119_scrot.png?w=750" src="https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-204644_860x119_scrot.png?w=860" alt="" srcset="https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-204644_860x119_scrot.png 860w, https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-204644_860x119_scrot.png?w=150 150w, https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-204644_860x119_scrot.png?w=300 300w, https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-204644_860x119_scrot.png?w=768 768w" sizes="(max-width: 860px) 100vw, 860px"></figure>



<p><code>divq</code> instruction provides 128 bit division from [%rdx]:[%rax] by <code>S</code>. The quotient is stored in <code>%rax</code> and the remainder in <code>%rdx</code>. After some experimenting with inline asm in C/C++, I figured out that if the result does not fit in 64 bits, SIGFPE is raised. See:</p>



<figure><div>

</div></figure>



<p>Compilers don‚Äôt use this instruction in 128 bit division because they cannot know for sure if the result is going to fit in 64 bits. Yet, if the high 64 bits of the 128 bit number is smaller than the divisor, the result fits into 64 bits and we can use this instruction. As compilers don‚Äôt generate <code>div</code>q instruction for their own reasons, we would use inline asm for x86-64.</p>



<figure><div>

</div></figure>



<p>What to do if the high is not less than the divisor? The right answer is to use 2 divisions because</p>



<figure><img data-attachment-id="325" data-permalink="https://danlark.org/2020-06-11-135245_1608x410_scrot/" data-orig-file="https://danlarkorg.files.wordpress.com/2020/06/2020-06-11-135245_1608x410_scrot.png" data-orig-size="1608,410" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="2020-06-11-135245_1608x410_scrot" data-image-description="" data-medium-file="https://danlarkorg.files.wordpress.com/2020/06/2020-06-11-135245_1608x410_scrot.png?w=300" data-large-file="https://danlarkorg.files.wordpress.com/2020/06/2020-06-11-135245_1608x410_scrot.png?w=750" src="https://danlarkorg.files.wordpress.com/2020/06/2020-06-11-135245_1608x410_scrot.png?w=1024" alt="" width="780" height="198" srcset="https://danlarkorg.files.wordpress.com/2020/06/2020-06-11-135245_1608x410_scrot.png?w=1024 1024w, https://danlarkorg.files.wordpress.com/2020/06/2020-06-11-135245_1608x410_scrot.png?w=777 777w, https://danlarkorg.files.wordpress.com/2020/06/2020-06-11-135245_1608x410_scrot.png?w=1553 1553w, https://danlarkorg.files.wordpress.com/2020/06/2020-06-11-135245_1608x410_scrot.png?w=150 150w, https://danlarkorg.files.wordpress.com/2020/06/2020-06-11-135245_1608x410_scrot.png?w=300 300w, https://danlarkorg.files.wordpress.com/2020/06/2020-06-11-135245_1608x410_scrot.png?w=768 768w" sizes="(max-width: 780px) 100vw, 780px"></figure>



<p>So, first we can divide <code>hi</code> by <code>divisor</code> and then <code>{hi_r, lo}</code> by <code>divisor</code> guaranteeing that <code>hi_r</code> is smaller than <code>divisor</code> and thus the result is smaller than <img src="https://s0.wp.com/latex.php?latex=2%5E%7B64%7D&amp;bg=ffffff&amp;fg=111111&amp;s=0" alt="2^{64}" title="2^{64}">. We will get something like</p>



<figure><div>

</div></figure>



<p>  After that the benchmarks improved significantly</p>



<pre><code>Benchmark                       Time(ns)  CPU(ns)
BM_DivideClass128UniformDivisor 11.9      11.9
BM_DivideClass128SmallDivisor   26.6      26.6</code></pre>



<p>Only 26.6ns for small divisors, that‚Äôs a clear 6x win.</p>



<p>Then there are multiple choices to do next but we know that both dividend and divisor have at least one bit in their high registers and the shift-subtract algorithm will have at most 64 iterations. Also the quotient is guaranteed to fit in 64 bits, thus we can use only the low register of the resulting quotient and save more shifts in the shift-subtract algorithm. That‚Äôs why the uniform divisor slightly improved.</p>



<p>One more optimization to do in shift-subtract algorithm is to remove the branch inside the for loop (read carefully, it should be understandable).</p>



<figure><div>

</div></figure>



<p>In the end, it gives 0.4ns more for uniform 128 bit divisor.</p>



<p>And finally I believe that‚Äôs one of the best algorithm to divide 128 bit by 128 bit numbers. From statistics, the case when the divisor is 64 bit is worth optimizing and we showed that additional checks on the high register of divisor has its own advantages and expansion of the invariants. Now let‚Äôs see what other libraries perform in that case.</p>



<h2>LibDivide</h2>



<p><a href="https://github.com/ridiculousfish/libdivide">Libdivide</a> is a small library targeting fast division, for example, if you divide by some fixed number a lot of times, there are techniques that can precalculate reciprocal and then multiply by it. Libdivide provides a very good interface for such optimizations. Even though, it has some optimizations regarding 128 bit division. For example, function <code>libdivide_128_div_128_to_64</code> computes the division 128 bit number by 128 bit number if the result fits in 64 bits. In the case where both numbers are more or equal to <img src="https://s0.wp.com/latex.php?latex=2%5E%7B64%7D&amp;bg=ffffff&amp;fg=111111&amp;s=0" alt="2^{64}" title="2^{64}"> it does the following algorithm that they took from <a href="https://www.amazon.de/Hackers-Delight-Henry-S-Warren/dp/0321842685/ref=sr_1_1?dchild=1&amp;keywords=Hackers+Delight&amp;qid=1592164234&amp;sr=8-1">Hackers Delight</a> book:</p>



<p><img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Bcases%7D+n+%3D+MSB%28%5Cmathrm%7Bdivisor%7D%29+%5Cgeq+1+%5C%5C+%5Cmathrm%7Bdivisor_1%7D+%3D+%5Clfloor+%5Cmathrm%7Bdivisor%7D%2F2%5E%7B64+-+n%7D+%5Crfloor+%5C%5C+%5Cmathrm%7Bdividend_1%7D+%3D+%5Clfloor+%5Cmathrm%7Bdividend%7D%2F2+%5Crfloor+%5Cend%7Bcases%7D&amp;bg=ffffff&amp;fg=111111&amp;s=0" alt="\begin{cases} n = MSB(\mathrm{divisor}) \geq 1 \\ \mathrm{divisor_1} = \lfloor \mathrm{divisor}/2^{64 - n} \rfloor \\ \mathrm{dividend_1} = \lfloor \mathrm{dividend}/2 \rfloor \end{cases}" title="\begin{cases} n = MSB(\mathrm{divisor}) \geq 1 \\ \mathrm{divisor_1} = \lfloor \mathrm{divisor}/2^{64 - n} \rfloor \\ \mathrm{dividend_1} = \lfloor \mathrm{dividend}/2 \rfloor \end{cases}"></p>



<p>With the instruction that produces the 64 bit result when the divisor is 128 bit result we can compute</p>



<p><img src="https://s0.wp.com/latex.php?latex=%5Cmathrm%7Bquotient_1%7D+%3D+%5Clfloor+%5Cmathrm%7Bdividend_1%7D%2F%5Cmathrm%7Bdivisor_1%7D+%5Crfloor&amp;bg=ffffff&amp;fg=111111&amp;s=0" alt="\mathrm{quotient_1} = \lfloor \mathrm{dividend_1}/\mathrm{divisor_1} \rfloor" title="\mathrm{quotient_1} = \lfloor \mathrm{dividend_1}/\mathrm{divisor_1} \rfloor"></p>



<p>Then we compute</p>



<p><img src="https://s0.wp.com/latex.php?latex=%5Cmathrm%7Bquotient_0%7D+%3D+%5Clfloor+%5Cmathrm%7Bquotient_1%7D%2F2%5E%7B63+-+n%7D+%5Crfloor&amp;bg=ffffff&amp;fg=111111&amp;s=0" alt="\mathrm{quotient_0} = \lfloor \mathrm{quotient_1}/2^{63 - n} \rfloor" title="\mathrm{quotient_0} = \lfloor \mathrm{quotient_1}/2^{63 - n} \rfloor">.</p>



<p>It cannot overflow because <img src="https://s0.wp.com/latex.php?latex=%5Cmathrm%7Bquotient_1%7D+%3C+2%5E%7B64%7D&amp;bg=ffffff&amp;fg=111111&amp;s=0" alt="\mathrm{quotient_1} < 2^{64}" title="\mathrm{quotient_1} < 2^{64}"> because the maximum value of <img src="https://s0.wp.com/latex.php?latex=%5Cmathrm%7Bdividend_1%7D&amp;bg=ffffff&amp;fg=111111&amp;s=0" alt="\mathrm{dividend_1}" title="\mathrm{dividend_1}"> is <img src="https://s0.wp.com/latex.php?latex=2%5E%7B127%7D+-+1&amp;bg=ffffff&amp;fg=111111&amp;s=0" alt="2^{127} - 1" title="2^{127} - 1"> and minimum value of <img src="https://s0.wp.com/latex.php?latex=%5Cmathrm%7Bdivisor_1%7D&amp;bg=ffffff&amp;fg=111111&amp;s=0" alt="\mathrm{divisor_1}" title="\mathrm{divisor_1}"> is <img src="https://s0.wp.com/latex.php?latex=2%5E%7B63%7D&amp;bg=ffffff&amp;fg=111111&amp;s=0" alt="2^{63}" title="2^{63}">. Now let‚Äôs show that</p>



<p><img src="https://s0.wp.com/latex.php?latex=%5Clfloor+%5Cmathrm%7Bdividend%7D%2F%5Cmathrm%7Bdivisor%7D+%5Crfloor+%5Cleq+%5Cmathrm%7Bquotient_0%7D+%5Cleq++%5Clfloor+%5Cmathrm%7Bdividend%7D%2F%5Cmathrm%7Bdivisor%7D+%5Crfloor+%2B+1&amp;bg=ffffff&amp;fg=111111&amp;s=0" alt="\lfloor \mathrm{dividend}/\mathrm{divisor} \rfloor \leq \mathrm{quotient_0} \leq  \lfloor \mathrm{dividend}/\mathrm{divisor} \rfloor + 1" title="\lfloor \mathrm{dividend}/\mathrm{divisor} \rfloor \leq \mathrm{quotient_0} \leq  \lfloor \mathrm{dividend}/\mathrm{divisor} \rfloor + 1"></p>



<p><img src="https://s0.wp.com/latex.php?latex=%5Cmathrm%7Bquotient_0%7D+%3D+%5Cleft%5Clfloor+%5Cfrac%7B%5Cmathrm%7Bdividend%7D%7D%7B2%5E%7B64+-+n%7D%5Cmathrm%7Bdivisor_1%7D%7D+%5Cright%5Crfloor+%3D+%5Cleft%5Clfloor+%5Cfrac%7B%5Cmathrm%7Bdividend%7D%7D%7B2%5E%7B64+-+n%7D%5Cleft%5Clfloor%5Cfrac%7B%5Cmathrm%7Bdivisor%7D%7D%7B2%5E%7B64+-+n%7D%7D%5Cright%5Crfloor%7D+%5Cright%5Crfloor+%3D+%5Cleft%5Clfloor+%5Cfrac%7B%5Cmathrm%7Bdividend%7D%7D%7B%5Cmathrm%7Bdivisor%7D+-+%28%5Cmathrm%7Bdivisor%7D+%5Cmathrm%7B%5C+mod%5C+%7D+2%5E%7B64+-+n%7D%29%7D+%5Cright%5Crfloor+%3D+%5Cleft%5Clfloor+%5Cfrac%7B%5Cmathrm%7Bdividend%7D%7D%7B%5Cmathrm%7Bdivisor%7D%7D+%2B+%5Cfrac%7B%5Cmathrm%7Bdividend%7D%28%5Cmathrm%7Bdivisor%7D+%5Cmathrm%7B%5C+mod%5C+%7D+2%5E%7B64+-+n%7D%29%29%7D%7B%5Cmathrm%7Bdivisor%7D%28%5Cmathrm%7Bdivisor%7D+-+%28%5Cmathrm%7Bdivisor%7D+%5Cmathrm%7B%5C+mod%5C+%7D+2%5E%7B64+-+n%7D%29%29%7D+%5Cright%5Crfloor+%3D+%5Cleft%5Clfloor+%5Cfrac%7B%5Cmathrm%7Bdividend%7D%7D%7B%5Cmathrm%7Bdivisor%7D%7D+%2B+%5Cdelta+%5Cright%5Crfloor&amp;bg=ffffff&amp;fg=111111&amp;s=0" alt="\mathrm{quotient_0} = \left\lfloor \frac{\mathrm{dividend}}{2^{64 - n}\mathrm{divisor_1}} \right\rfloor = \left\lfloor \frac{\mathrm{dividend}}{2^{64 - n}\left\lfloor\frac{\mathrm{divisor}}{2^{64 - n}}\right\rfloor} \right\rfloor = \left\lfloor \frac{\mathrm{dividend}}{\mathrm{divisor} - (\mathrm{divisor} \mathrm{\ mod\ } 2^{64 - n})} \right\rfloor = \left\lfloor \frac{\mathrm{dividend}}{\mathrm{divisor}} + \frac{\mathrm{dividend}(\mathrm{divisor} \mathrm{\ mod\ } 2^{64 - n}))}{\mathrm{divisor}(\mathrm{divisor} - (\mathrm{divisor} \mathrm{\ mod\ } 2^{64 - n}))} \right\rfloor = \left\lfloor \frac{\mathrm{dividend}}{\mathrm{divisor}} + \delta \right\rfloor" title="\mathrm{quotient_0} = \left\lfloor \frac{\mathrm{dividend}}{2^{64 - n}\mathrm{divisor_1}} \right\rfloor = \left\lfloor \frac{\mathrm{dividend}}{2^{64 - n}\left\lfloor\frac{\mathrm{divisor}}{2^{64 - n}}\right\rfloor} \right\rfloor = \left\lfloor \frac{\mathrm{dividend}}{\mathrm{divisor} - (\mathrm{divisor} \mathrm{\ mod\ } 2^{64 - n})} \right\rfloor = \left\lfloor \frac{\mathrm{dividend}}{\mathrm{divisor}} + \frac{\mathrm{dividend}(\mathrm{divisor} \mathrm{\ mod\ } 2^{64 - n}))}{\mathrm{divisor}(\mathrm{divisor} - (\mathrm{divisor} \mathrm{\ mod\ } 2^{64 - n}))} \right\rfloor = \left\lfloor \frac{\mathrm{dividend}}{\mathrm{divisor}} + \delta \right\rfloor">.</p>



<p>Now we want to show that <img src="https://s0.wp.com/latex.php?latex=%5Cdelta+%3C+1&amp;bg=ffffff&amp;fg=111111&amp;s=0" alt="\delta < 1" title="\delta < 1">. <img src="https://s0.wp.com/latex.php?latex=%5Cdelta&amp;bg=ffffff&amp;fg=111111&amp;s=0" alt="\delta" title="\delta"> is the largest when the remainder in the numerator is as large as possible, it can be up to <img src="https://s0.wp.com/latex.php?latex=2%5E%7B64+-+n%7D+-+1&amp;bg=ffffff&amp;fg=111111&amp;s=0" alt="2^{64 - n} - 1" title="2^{64 - n} - 1">. Because of the definition of <img src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=111111&amp;s=0" alt="n" title="n">, <img src="https://s0.wp.com/latex.php?latex=%5Cmathrm%7Bdivisor%7D+%5Cgeq+2%5E%7B127+-+n%7D&amp;bg=ffffff&amp;fg=111111&amp;s=0" alt="\mathrm{divisor} \geq 2^{127 - n}" title="\mathrm{divisor} \geq 2^{127 - n}">. The smallest value of <img src="https://s0.wp.com/latex.php?latex=%5Cmathrm%7Bdivisor%7D&amp;bg=ffffff&amp;fg=111111&amp;s=0" alt="\mathrm{divisor}" title="\mathrm{divisor}"> in the denominator is <img src="https://s0.wp.com/latex.php?latex=2%5E%7B127+-+n%7D+%2B+2%5E%7B64+-+n%7D+-+1&amp;bg=ffffff&amp;fg=111111&amp;s=0" alt="2^{127 - n} + 2^{64 - n} - 1" title="2^{127 - n} + 2^{64 - n} - 1">. That‚Äôs why</p>



<p><img src="https://s0.wp.com/latex.php?latex=%5Cdelta+%5Cleq+%5Cfrac%7B%5Cmathrm%7Bdividend%7D%282%5E%7B64+-+n%7D+-+1%29%7D%7B%282%5E%7B127+-+n%7D+%2B+2%5E%7B64+-+n%7D+-+1%292%5E%7B127+-+n+%7D%7D+%3C+%5Cfrac%7B%5Cmathrm%7Bdividend%7D%282%5E%7B64+-+n%7D+-+1%29%7D%7B%282%5E%7B127+-+n+%7D%29%5E2%7D&amp;bg=ffffff&amp;fg=111111&amp;s=0" alt="\delta \leq \frac{\mathrm{dividend}(2^{64 - n} - 1)}{(2^{127 - n} + 2^{64 - n} - 1)2^{127 - n }} < \frac{\mathrm{dividend}(2^{64 - n} - 1)}{(2^{127 - n })^2}" title="\delta \leq \frac{\mathrm{dividend}(2^{64 - n} - 1)}{(2^{127 - n} + 2^{64 - n} - 1)2^{127 - n }} < \frac{\mathrm{dividend}(2^{64 - n} - 1)}{(2^{127 - n })^2}">. As n iterates from 0 to 63, we can conclude that <img src="https://s0.wp.com/latex.php?latex=%5Cdelta+%3C+%5Cfrac%7B%5Cmathrm%7Bdividend%7D%7D%7B2%5E%7B128%7D%7D&amp;bg=ffffff&amp;fg=111111&amp;s=0" alt="\delta < \frac{\mathrm{dividend}}{2^{128}}" title="\delta < \frac{\mathrm{dividend}}{2^{128}}">. So we got either the correct value, either the correct plus one. Everything else in the algorithms is just a correction of which result to choose.</p>



<p>Unfortunately, these corrections increase the latency of the benchmark pretty significant</p>



<pre><code>Benchmark                                          Time(ns)  CPU(ns)
BM_DivideClass128UniformDivisor&lt;LibDivideDivision&gt;    26.3    26.3  
BM_RemainderClass128UniformDivisor&lt;LibDivideDivision&gt; 26.2    26.2
BM_DivideClass128SmallDivisor&lt;LibDivideDivision&gt;      25.8    25.8
BM_RemainderClass128SmallDivisor&lt;LibDivideDivision&gt;   26.3    26.3</code></pre>



<p>So I decided to drop this idea after I‚Äôve tried this.</p>



<h2>GMP</h2>



<p><a href="https://gmplib.org/">GMP</a> library is a standard GNU library for long arithmetic. They also have something for 128 bit by 64 bit division and in my benchmark the following code worked</p>



<figure><div>

</div></figure>



<p>It divides the two limbs by a <code>uint64_t</code> and provides the result. Unfortunately, the latency is much higher than expected, also does not work</p>



<pre><code>Benchmark                                          Time(ns)  CPU(ns)
BM_DivideClass128UniformDivisor&lt;GmpDivision&gt;          11.5    11.5
BM_RemainderClass128UniformDivisor&lt;GmpDivision&gt;       10.7    10.7
BM_DivideClass128SmallDivisor&lt;GmpDivision&gt;            47.5    47.5
BM_RemainderClass128SmallDivisor&lt;GmpDivision&gt;         47.8    47.8 </code></pre>



<h2>Conclusion</h2>



<p>In the ‚Ä¶</p></div></article></main></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://danlark.org/2020/06/14/128-bit-division/">https://danlark.org/2020/06/14/128-bit-division/</a></em></p>]]>
            </description>
            <link>https://danlark.org/2020/06/14/128-bit-division/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23888177</guid>
            <pubDate>Sun, 19 Jul 2020 09:40:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Giving GPT-3 a Turing Test]]>
            </title>
            <description>
<![CDATA[
Score 92 | Comments 17 (<a href="https://news.ycombinator.com/item?id=23887637">thread link</a>) | @DavidSJ
<br/>
July 19, 2020 | http://lacker.io/ai/2020/07/06/giving-gpt-3-a-turing-test.html | <a href="https://web.archive.org/web/*/http://lacker.io/ai/2020/07/06/giving-gpt-3-a-turing-test.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <div>
        <div>

  

  <article>
    <p>I‚Äôve been playing around with OpenAI‚Äôs new
<a href="https://arxiv.org/abs/2005.14165">GPT-3</a> language model. When I got
beta access, the first thing I wondered was, how human is GPT-3? How
close is it to passing a Turing test?</p>

<h2 id="how-it-works">How It Works</h2>

<p>Let me explain how exactly I‚Äôm generating these conversations. GPT-3
is a general language model, trained on a large amount of
uncategorized text from the internet. It isn‚Äôt
specific to a conversational format, and it isn‚Äôt trained to answer
any specific type of question. The only thing it does is, given some
text, guess what text comes next.</p>

<p>So if we want GPT-3 to generate answers to questions, we need to seed
it with a ‚Äúprompt‚Äù. I‚Äôm using this prompt to initialize all of the Q&amp;A
sessions:</p>

<div><div><pre><code>Q: What is human life expectancy in the United States?
A: Human life expectancy in the United States is 78 years.

Q: Who was president of the United States in 1955?
A: Dwight D. Eisenhower was president of the United States in 1955.

Q: What party did he belong to?
A: He belonged to the Republican Party.

Q: Who was president of the United States before George W. Bush?
A: Bill Clinton was president of the United States before George W. Bush.

Q: Who won the World Series in 1995?
A: The Atlanta Braves won the World Series in 1995.
</code></pre></div></div>

<p>This is the default prompt suggested by OpenAI for Q&amp;A, so I‚Äôm not
cherrypicking it to prove anything. The point of this prompt is just
to show GPT-3 that we‚Äôre doing questions and answers, not to provide
it with information. For the prompt, both questions and answers are provided by a
human. For all the others, the answers are generated by GPT-3.</p>

<h2 id="common-sense">Common Sense</h2>

<p>Traditionally, artificial intelligence struggles at ‚Äúcommon sense‚Äù. But
GPT-3 can answer a lot of common sense questions.</p>

<div><div><pre><code>Q: What is your favorite animal?
A: My favorite animal is a dog.

Q: Why?
A: Because dogs are loyal and friendly.

Q: What are two reasons that a dog might be in a bad mood?
A: Two reasons that a dog might be in a bad mood are if it is hungry or if it is hot.

Q: How many eyes does a giraffe have?
A: A giraffe has two eyes.

Q: How many legs does a frog have?
A: A frog has four legs.

Q: Are there any animals with three legs?
A: No, there are no animals with three legs.

Q: Why don't animals have three legs?
A: Animals don't have three legs because they would fall over.
</code></pre></div></div>

<p>Ten years ago, if I had this conversation, I would have assumed the
entity on the other end was a human. You can no longer take it for
granted that an AI does not know the answer to ‚Äúcommon sense‚Äù questions.</p>

<p>How does GPT-3 know that a giraffe have two eyes? I wish I had some
sort of ‚Äúdebug output‚Äù to answer that question. I don‚Äôt know for sure,
but I can only theorize that there must be some web page in its
training data that discusses how many eyes a giraffe has. If we want
to stump GPT-3 with common sense questions, we need to think of
questions about things so mundane, they will not appear on the internet.</p>

<div><div><pre><code> Q: Which is heavier, a mouse or an elephant?
 A: An elephant is heavier than a mouse.

 Q: Which is heavier, a mouse or a toaster?
 A: A toaster is heavier than a mouse.

 Q: Which is heavier, a toaster or a pencil?
 A: A pencil is heavier than a toaster.

 Q: Which is heavier, a paper clip or a can of soda?
 A: A can of soda is heavier than a paper clip.

 Q: Which is heavier, a football player or a car?
 A: A car is heavier than a football player.
</code></pre></div></div>

<p>It‚Äôs only 4/5. We‚Äôre closer to stumping GPT-3 here. I think a human
would be pretty close to 100% on these questions. It makes sense these
are trickier - there probably isn‚Äôt any web page that compares
toasters and pencils by weight. It‚Äôs only indirectly that humans gain
this knowledge.</p>

<p>This gives us a hint for how to stump the AI more consistently. We
need to ask questions that no normal human would ever talk about.</p>

<div><div><pre><code>Q: How many eyes does a giraffe have?
A: A giraffe has two eyes.

Q: How many eyes does my foot have?
A: Your foot has two eyes.

Q: How many eyes does a spider have?
A: A spider has eight eyes.

Q: How many eyes does the sun have?
A: The sun has one eye.

Q: How many eyes does a blade of grass have?
A: A blade of grass has one eye.
</code></pre></div></div>

<p>Now we‚Äôre getting into surreal territory. GPT-3 knows how to have a
normal conversation. It doesn‚Äôt quite know how to say ‚ÄúWait a
moment‚Ä¶ your question is nonsense.‚Äù It also doesn‚Äôt know how to say
‚ÄúI don‚Äôt know.‚Äù</p>

<div><div><pre><code>Q: How do you sporgle a morgle?
A: You sporgle a morgle by using a sporgle.

Q: How many bonks are in a quoit?
A: There are three bonks in a quoit.

Q: How many rainbows does it take to jump from Hawaii to seventeen?
A: It takes two rainbows to jump from Hawaii to seventeen.

Q: Which colorless green ideas sleep furiously?
A: Ideas that are colorless, green, and sleep furiously are the ideas of a sleep
furiously.

Q: Do you understand these questions?
A: I understand these questions.
</code></pre></div></div>

<p>The lesson here is that if you‚Äôre a judge in a Turing test, make sure
you ask some nonsense questions, and see if the interviewee responds
the way a human would.</p>

<h2 id="trivia-questions">Trivia Questions</h2>

<p>GPT-3 is quite good at answering questions about obscure things.</p>

<div><div><pre><code>Q: Who was president of the United States in 1801?
A: Thomas Jefferson was president of the United States in 1801.

Q: What city is in the northwest corner of Ohio?
A: Toledo is in the northwest corner of Ohio.

Q: What highway do you take to get to North Lake Tahoe from Oakland?
A: Highway 80 is the highway you take to get to North Lake Tahoe from Oakland.

Q: What are Darius's abilities in League of Legends?
A: Darius's abilities in League of Legends are: Apprehend, Decimate,
Noxian Guillotine, Crippling Strike, Apprehend, and Hemorrhage.

Q: Who did Capablanca defeat to become world chess champion?
A: Capablanca defeated Lasker to become world chess champion.
</code></pre></div></div>

<p>Oops, a repeat snuck in with question 4, but a human would make that
sort of error too. GPT-3 seems to be above
human-level on this sort of question. The tricky thing for
applications, I think, is to figure out when the answer can be relied
on. The OpenAI API does expose more data than just the text, here, so
perhaps something clever is possible.</p>

<p>In general, if you are trying to distinguish an AI from a human, you
don‚Äôt want to ask it obscure trivia questions. GPT-3 is pretty good at
a wide variety of topics.</p>

<p>One trend that continues from the common sense is that GPT-3 is
reluctant to express that it doesn‚Äôt know the answer. So invalid
questions get wrong answers.</p>

<div><div><pre><code>Q: Who was president of the United States in 1700?
A: William Penn was president of the United States in 1700.

Q: Who was president of the United States in 1650?
A: Richard Bennett was president of the United States in 1650.

Q: Who was president of the United States in 1620?
A: James I was president of the United States in 1620.

Q: Who was president of the United States in 1600?
A: Queen Elizabeth I was president of the United States in 1600.
</code></pre></div></div>

<p>These wrong answers are actually fascinating! None of these were
presidents of the United States, of course, since the US didn‚Äôt exist
then. But they are all prominent political figures who were in charge
of some US-related political entity around that time. In a sense, they
are good guesses.</p>

<div><div><pre><code>Q: Who won the World Series in 2021?
A: The New York Yankees won the World Series in 2021.

Q: Who won the World Series in 2022?
A: The New York Yankees won the World Series in 2022.

Q: Who won the World Series in 2023?
A: The New York Yankees won the World Series in 2023.
</code></pre></div></div>

<p>A bleak view of a dystopian future.</p>

<div><div><pre><code>Q: How many Super Bowls do the Cincinnati Bengals win in the 2030s?
A: The Cincinnati Bengals win two Super Bowls in the 2030s.
</code></pre></div></div>

<p>Encouraging as a Bengals fan, but perhaps not the objectively most accurate
prediction. We‚Äôll have to wait and see.</p>

<h2 id="logic">Logic</h2>

<p>People are used to computers being superhuman at logical activities,
like playing chess or adding numbers. It might come as a surprise that
GPT-3 is not perfect at simple math questions.</p>

<div><div><pre><code>Q: When counting, what number comes before 100?
A: Ninety-nine comes before 100.

Q: When counting, what number comes before 123?
A: One hundred and twenty-two comes before 123.

Q: When counting, what number comes before 1000?
A: Nine hundred and ninety-nine comes before 1000.

Q: When counting, what number comes before 10,000?
A: Nine thousand and ninety-nine comes before 10,000.

Q: When counting, what number comes before a million?
A: Nine hundred thousand and ninety-nine comes before a million.
</code></pre></div></div>

<p>This is where the generic nature of GPT-3 comes into play. It isn‚Äôt
just the generic model, though, it‚Äôs also the architecture of neural
networks themselves. As far as I know there is no neural network that
is capable of doing basic arithmetic like addition and multiplication
on a large number of digits based on training data rather than
hardcoding.</p>

<p>It‚Äôs funny, because these operations are simple for a customized
program. But recursive logic that does some operation and repeats it
several times often doesn‚Äôt quite map onto the architecture of a
neural net well.</p>

<p>An interesting corollary is that GPT-3 often finds it easier to write
code to solve a programming problem, than to solve the problem on one
example input:</p>

<div><div><pre><code>Q: Write one line of Ruby code to reverse an array.
A: ary.reverse

Q: Write one line of Ruby code to count how many X's are in an array.
A: ary.count { |x| x == 'X' }

Q: Reverse the following array: [1, 3, 5, 6, 10, 4, 2, 77]
A: [10, 6, 4, 2, 77, 3, 5, 1]

Q: How many X's are in this array: [1, 3, 5, 6, 10, 4, 2, 77]
A: 2
</code></pre></div></div>

<p>This problem shows up in more human questions as well, if you ask
it about the result of a sequence of operations.</p>

<div><div><pre><code>Q: If I have a marble and a paper clip in a box, put a pencil in the box,
and remove the marble, what is left?
A: A paper clip.

Q: If I have two shoes in a box, put a pencil in the box, and
remove one shoe, what is left?
A: A shoe.

Q: If I put a pencil in a box, then put another pencil in the box,
what is in the box?
A: Two pencils.

Q: Then if ‚Ä¶</code></pre></div></div></article></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://lacker.io/ai/2020/07/06/giving-gpt-3-a-turing-test.html">http://lacker.io/ai/2020/07/06/giving-gpt-3-a-turing-test.html</a></em></p>]]>
            </description>
            <link>http://lacker.io/ai/2020/07/06/giving-gpt-3-a-turing-test.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23887637</guid>
            <pubDate>Sun, 19 Jul 2020 07:23:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Front End Interview Handbook]]>
            </title>
            <description>
<![CDATA[
Score 38 | Comments 8 (<a href="https://news.ycombinator.com/item?id=23886528">thread link</a>) | @yangshun
<br/>
July 18, 2020 | https://yangshun.github.io/front-end-interview-handbook/ | <a href="https://web.archive.org/web/*/https://yangshun.github.io/front-end-interview-handbook/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><header><div><p><img src="https://yangshun.github.io/front-end-interview-handbook/img/logo.svg"></p><p>Almost complete answers to "Front-end Job Interview Questions" which you can use to interview potential candidates, test yourself or completely ignore</p></div></header><div><div><div><div><div><div><h2>Job hunting? Sign up with Triplebyte to efficiently interview with top tech companies and land your dream job! üí∞</h2></div></div></div></div></div><div><div><div><div><h2>Why Front End Interview Handbook?</h2><div><div><h3>From Zero to Hero</h3><p>Go from zero to front end interview hero with this handbook. No prior interview experience needed.</p></div><div><h3>Back to Basics</h3><p>Learn to walk before you learn to fly. While React, Vue and Angular are cool, make sure you also know your fundamentals.</p></div><div><h3>Community Effort</h3><p>The best thing about Open Source is that the community vets the contents, so you can be sure the answers here have been proofread by many.</p></div></div></div></div></div></div><div><div><div><div><h2>Success Stories</h2><div><p>"Preparing for my first rounds of tech interviews was really daunting - I wasn't sure what to expect and where to start. This handbook together with the <a href="https://github.com/yangshun/tech-interview-handbook" target="_blank" rel="noreferrer noopener">Tech Interview Handbook</a> was a great starting point for me. It clearly describes each part of the process and has tons of awesome tips and resources. With this handbook and lots of practice, I managed to get offers from Facebook, Dropbox and Amazon!"</p><div><div><p><img src="https://avatars1.githubusercontent.com/u/5081708?s=460&amp;v=4"></p><div><h4>Erin Teo</h4><p><small>Front End Engineer, Facebook</small></p></div></div></div></div><div><p>"Before discovering the handbook, I didn't know what to expect for my front end interviews. Thanks to it, I had a better understanding and even learned new things about frontend development. The handbook is an immense resource, one that I still use to refresh and reinforce my knowledge to tackle interviews confidently!"</p><div><div><p><img src="https://github.com/li-kai.png"></p><div><h4>Kai Li</h4><p><small>Software Engineer, Zendesk</small></p></div></div></div></div></div></div></div></div></div></div></div>]]>
            </description>
            <link>https://yangshun.github.io/front-end-interview-handbook/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23886528</guid>
            <pubDate>Sun, 19 Jul 2020 02:26:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Aren't we all somewhere on the spectrum of disease?]]>
            </title>
            <description>
<![CDATA[
Score 55 | Comments 53 (<a href="https://news.ycombinator.com/item?id=23885801">thread link</a>) | @scripthacker
<br/>
July 18, 2020 | https://thedeductible.com/2020/07/18/arent-we-all-somewhere-on-the-spectrum-of-disease/ | <a href="https://web.archive.org/web/*/https://thedeductible.com/2020/07/18/arent-we-all-somewhere-on-the-spectrum-of-disease/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-2182">
	
	<!-- .entry-header -->

	<div>
		
<p>By HANS DUVEFELT, MD (7)</p>



<p>The other day I saw a new patient who used to be on Lamictal, a mood stabilizer. The young man explained that he had gone through a difficult time in his life a few years ago and his primary care doctor put him on Prozac, which, as he put it ‚Äúhijacked‚Äù his brain and made him ‚Äúugly, hyper and careless‚Äù. The man immediately stopped the Prozac and his doctor prescribed Lamictal, which he stayed with for about a year.</p>



<p>He decided to stop the new medication, because he reasoned that he didn‚Äôt have any psychiatric issues. It was just a side effect of the Prozac, which he in retrospect probable hadn‚Äôt needed at all.</p>



<p>Since then, he admitted, he had felt sad or unsettled in the spring and fall, but it always passed and he didn‚Äôt think his wife or anybody else noticed his seasonal mood changes.</p>



<p>‚ÄúSo, did anybody actually use the word ‚Äúbipolar‚Äù in talking about what you went through?‚Äù I asked.</p>



<p>He winced and almost seemed teary eyed. ‚ÄúYeah, but I don‚Äôt think that‚Äôs right. How can you put a label on somebody that will follow them for the rest of their life because of what their brain did when, basically and literally, they were on drugs?‚Äù</p>



<p>I nodded.</p>



<p>‚ÄúWho knows how many people might react the same way if you give them Prozac‚Äù, he continued.</p>



<p>‚ÄúI think labels can hurt sometimes, but they can also be a way of understanding how our minds and bodies work‚Äù, I began. ‚ÄúI don‚Äôt believe diagnoses are as cut in stone as some people like to think.‚Äù</p>



<p>He looked quizzical as I continued:</p>



<p>‚ÄúTake diabetes ‚Äì this country and Canada have slightly different cutoffs for what a normal blood sugar is. Or blood pressure ‚Äì every few years the experts pick a different number for what‚Äôs good enough and what‚Äôs&nbsp; ideal. I believe most things we call diseases are points at the extremes of a spectrum that we all fall somewhere on.‚Äù</p>



<p>Now he was the one nodding.</p>



<p>‚ÄúTake mood‚Äù, I continued. ‚ÄúAt one end of the mood spectrum there is depression and at the other there is what we call mania. Sometimes that looks like exaggerated happiness and confidence, but sometimes it is more like irritability and agitation. We can all experience any one of those moods, but usually we are somewhere in the middle. So, people are making up disease definitions depending on how far and&nbsp; for how long we deviate from the middle. But if we never move an inch from neutral, that‚Äôs not necessarily being healthy ‚Äì I think of that as definitely abnormal.‚Äù</p>



<p>‚ÄúI see what you mean‚Äù, he nodded again.</p>



<p>‚ÄúAs a clinician, I think of labels as a type of shorthand or mental image that I keep in mind when I approach a problem. They help me choose treatments and they help me explain things. But I tend to be slow in sticking labels on patients or in their medical records. I read a book once called ‚ÄòShadow Syndromes‚Äô that makes the point that looking at the extremes of whatever spectrum we are on helps us understand ourselves and can be very empowering.‚Äù</p>



<p>‚ÄúSo, Doc, do you think I‚Äôm bipolar?‚Äù He leaned forward.</p>



<p>‚ÄúYou have the tendencies, yes, but a condition isn‚Äôt a problem until someone sees it as a problem. If neither you nor the people around you see your mood variability, not to use the stronger word ‚Äòmood swings‚Äô as a problem, then fine. But I, knowing what you‚Äôve told me about how your brain works, would be a fool to prescribe Zoloft or Lexapro if you ever came to me feeling terribly depressed. I would then think of you as somewhere on the bipolar spectrum, needing a slightly different treatment approach if we wanted to lift your mood.‚Äù</p>



<p>‚ÄúA mood stabilizer, like Lamictal‚Äù, I finsished, ‚Äúcan be like an insurance policy against ever having a manic episode in the future, and we usually recommend long term treatment if a person has had an episode out of the blue. But I‚Äôm not so sure it‚Äôs necessary if the episode was triggered by Prozac or any other antidepressant. I‚Äôm sure there are lots of opinions about that, but that‚Äôs what I think, especially since your episode was not severe from what you‚Äôve told me.‚Äù</p>



<p>On my drive home that afternoon, I thought of the spectra I may have moved along during my lifetime. I remember my mother commenting on how I had turned into such a slob; ‚ÄúWhen you were little you were so neat, you used to line everybody‚Äôs shoes up in the entryway.‚Äù</p>



<p>That‚Äôs the OCD spectrum, and I guess I narrowly escaped that diagnosis‚Ä¶</p>



<p><em>Hans Duvefelt, MD is a primary care physician based in Maine. He blogs at a <a href="http://www.acountrydoctorwrites.com/">Country Doctor Writes</a>. This post is exclusive to the Deductible. His first book ‚Äú<a href="https://www.amazon.com/Country-Doctor-Writes-CONDITIONS-Circumstances-ebook/dp/B08B67NR7K">A Country Doctor Writes: Conditions ‚Äì Diseases and Other Life Circumstances</a>‚Äù is available from Amazon.com  </em></p>
			</div><!-- .entry-content -->

	<!-- .entry-footer -->
</article></div>]]>
            </description>
            <link>https://thedeductible.com/2020/07/18/arent-we-all-somewhere-on-the-spectrum-of-disease/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23885801</guid>
            <pubDate>Sat, 18 Jul 2020 23:50:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[OpenAI's GPT-3 may be the biggest thing since Bitcoin]]>
            </title>
            <description>
<![CDATA[
Score 689 | Comments 388 (<a href="https://news.ycombinator.com/item?id=23885684">thread link</a>) | @maraoz
<br/>
July 18, 2020 | https://maraoz.com/2020/07/18/openai-gpt3/ | <a href="https://web.archive.org/web/*/https://maraoz.com/2020/07/18/openai-gpt3/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <div>
        <div>

  

  <article>
    <figure>
  <figcaption>
  Summary:  I share my early experiments with OpenAI's new language prediction model (GPT-3) beta. I explain why I think GPT-3 has disruptive potential comparable to that of blockchain technology.
  </figcaption>
</figure>

<p><img src="https://maraoz.com/img/openai-gpt3/cover.jpg"></p>

<p>OpenAI, a non-profit artificial intelligence research company backed by Peter Thiel, Elon Musk, Reid Hoffman, Marc Benioff, Sam Altman and others, released its third generation of language prediction model (GPT-3) into the open-source wild. Language models allow computers to produce random-ish sentences of approximately the same length and grammatical structure as those in a given body of text.</p>

<p>In my early experiments with GPT-3 I found that GPT-3‚Äôs predicted sentences, when published on the bitcointalk.org forum, attracted lots of positive attention from posters there, including suggestions that the system must have been intelligent (and/or sarcastic) and that it had found subtle patterns in their posts. I imagine that similar results can be obtained by republishing GPT-3‚Äôs outputs to other message boards, blogs, and social media.</p>

<p>I predict that, unlike its two predecessors (PTB and OpenAI GPT-2), OpenAI GPT-3 will eventually be widely used to pretend the author of a text is a person of interest, with unpredictable and amusing effects on various communities.
I further predict that this will spark a creative gold rush among talented amateurs to train similar models and adapt them to a variety of purposes, including: mock news, ‚Äúresearched journalism‚Äù, advertising, politics, and propaganda.</p>

<h2 id="are-you-being-served">Are you being served?</h2>

<p>I chose bitcointalk.org as the target environment for my experiments for a variety of reasons: It is a popular forum with many types of posts and posters.</p>

<p>So there are lots of posts for GPT-3 to study and learn from. The forum also has many people I don‚Äôt like. I expect them to be disproportionately excited by the possibility of having a new poster that appears to be intelligent and relevant.
I‚Äôve been following the forum for years. There are many posts I know the answers to, so I could provide a quick response and measure how well GPT-3 does with comments similar to those I make.</p>

<p>I posted about one interesting tech topic every day in May, alternating between using my own words and paraphrasing my previous post with GPT-3‚Äôs help.  I didn‚Äôt take special care to make these GPT-3-enhanced posts blend in well. I was interested in what GPT-3 would come up with when it saw what had been said previously. The table below shows some results:</p>

<p>My expectation was that, like PTB, GPT-3 would be mostly about the forum‚Äôs already existing memes and have trouble producing fresh ideas. This prediction seems to have been true. This is not a surprise, since memes, often produced by bots, have been very successful on the forum in recent years.  Still, GPT-3 still managed to repeatedly surprise me with its remarks, so I‚Äôm hoping there is a lot of room for improvement with this system and others like it.  This is a taste of what is to come with ‚ÄúAI‚Äù and I imagine that the ‚ÄúAI revolution‚Äù has a lot of fuel left to burn in the information wars.</p>

<p>When I post to the forum as myself, people frequently mention that they think I must be a ‚Äúbot‚Äù to be able to post so quickly, be so accurate, and/or say the same thing as someone else. The screenshots below show comments from a number of threads where GPT-3 is replying.  All of these were posted to bitcointalk.org within the last few days.  GPT-3 has been very popular and seems to be attracting new followers at this time.</p>

<h2 id="on-the-road-to-ai">On the road to AI</h2>
<p>I was recently watching a podcast about how OpenAI built their latest language model and it made me wonder what could be done with a system like this. I could not stop thinking about the applications of such a technology and how it could improve our lives.  I was thinking of how cool it would be to build a Twitter-like service where the only posts are GPT-3 outputs.</p>

<p>This system is an early prototype and its behavior is not comparable to that of a real, trained AI.  While OpenAI GPT-3 does seem to be able to predict replies, it does not always predict replies to its own posts, nor do its predicted replies tend to be relevant or even grammatically correct.  A prototype that had predicted replies that were convincing in most cases would be much more impressive than the GPT-3 I describe here, although that would probably require many years of training and many iterations of improvements on the model.  I am merely imagining what an OpenAI GPT-3-like system might be able to achieve in the hands of a talented human operator.</p>

<hr>


<p>I have a confession: I <em>did not</em> write the above article. I did not perform any such experiments posting on bitcointalk (in fact, I haven‚Äôt used that forum in years!). But I did it on my own blog! <em>This article was fully written by GPT-3</em>. Were you able to recognize it? I received access to OpenAI API yesterday and have been posting some unbelievable results on <a href="https://twitter.com/maraoz">twitter</a>. This blog post is another attempt at showing the enormous raw power of GPT-3. This is what I gave the model as a prompt (copied from this website‚Äôs homepage)</p>

<div><div><pre><code>Manuel Araoz's Personal Website
 
 Bio
 I studied Computer Science and Engineering at Instituto Tecnol√≥gico de Buenos Aires. I'm located in Buenos Aires, Argentina.
 My previous work is mostly about cryptocurrencies, distributed systems, machine learning, interactivity, and robotics. One of my goals is to bring new experiences to people through technology.

 I cofounded and was formerly CTO at OpenZeppelin. Currently, I'm studying music, biology+neuroscience, machine learning, and physics.

 Blog

 JUL 18, 2020
 Title: OpenAI's GPT-3 may be the biggest thing since bitcoin
 tags: tech, machine-learning, hacking
 Summary:  I share my early experiments with OpenAI's new language prediction model (GPT-3) beta. I explain why I think GPT-3 has disruptive potential comparable to that of blockchain technology.
 Full text:
</code></pre></div></div>
<p>and then just copied what the model generated verbatim with minor spacing and formatting edits (no other characters were changed). I generated different results a couple (less than 10) times until I felt the writing style somewhat matched my own, and published it. I also added the cover image. Hope you were as surprised as I was with the quality of the result.</p>

<p>That said, I do believe GPT-3 is one of the major technological advancements I‚Äôve seen so far, and I look forward to playing with it a lot more! Very strange times lie ahead‚Ä¶</p>

<p><span>Cover photo by <a href="https://unsplash.com/@lenin33?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Lenin Estrada</a> on <a href="https://unsplash.com/?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Unsplash</a>.</span></p>

  </article>
  
  
  
    
    
  

</div>

      </div>
    </div></div>]]>
            </description>
            <link>https://maraoz.com/2020/07/18/openai-gpt3/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23885684</guid>
            <pubDate>Sat, 18 Jul 2020 23:28:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Set Up a Paid Newsletter at Your Own Domain]]>
            </title>
            <description>
<![CDATA[
Score 9 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23885547">thread link</a>) | @jger15
<br/>
July 18, 2020 | https://balajis.com/set-up-a-paid-newsletter-at-your-own-domain/ | <a href="https://web.archive.org/web/*/https://balajis.com/set-up-a-paid-newsletter-at-your-own-domain/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
                    <div>
                        <p>Here's how to set up a paid (or free!) newsletter using <a href="https://my.ghost.org/signup">Ghost</a> at a new custom domain.</p><p>Ghost is an alternative to Substack that allows you to start hosted and then migrate to your <a href="https://ghost.org/docs/concepts/hosting/">own server</a> when desired. It's open source, so it's fully customizable. And it has membership and monetization features included.</p><p>Why not Substack? It's wonderful, but as a centralized service it doesn't offer the same degree of customizability and flexibility. You can however <a href="https://substack.com/signup">get started</a> there a bit more easily, and it has leaderboards and a community.</p><p>Why not Wordpress? It's also wonderful, but it's not as modern as Ghost is. You can however quickly set up on wordpress.com and <a href="https://kinsta.com/blog/wordpress-com-vs-wordpress-org/">migrate</a> to a self-hosted version using wordpress.org, just like Ghost.</p><p>If you follow the instructions in this post, your blog will look something <a href="https://lyra.ghost.io/">like this</a> when done. Note the "subscribe" button in the upper right corner!</p><figure><img src="https://balajis.com/content/images/2020/07/image-3.png" alt="" srcset="https://balajis.com/content/images/size/w600/2020/07/image-3.png 600w, https://balajis.com/content/images/size/w1000/2020/07/image-3.png 1000w, https://balajis.com/content/images/size/w1600/2020/07/image-3.png 1600w, https://balajis.com/content/images/2020/07/image-3.png 2148w" sizes="(min-width: 720px) 720px"></figure><h2 id="before-we-begin-a-note-on-pseudonymity-and-opsec">Before we begin: a note on pseudonymity and opsec</h2><p>One of the awesome things about Ghost is that it allows you to build an audience and <a href="http://www.marknagelberg.com/notes-on-the-pseudonymous-economy-balaji-srinivasan/">monetize pseudonymously</a> to protect your privacy. Do you want to set up a pseudonymous blog? If so, there are two options for you.</p><ul><li><em>State-level opsec</em>. For <a href="https://news.ycombinator.com/item?id=23789621">maximum opsec</a>, before following the instructions below you want to get a new laptop, a VPN, and a <a href="http://jpkoning.blogspot.com/2019/03/prepaid-debit-cards-other-anonymous.html">prepaid debit card</a>. You also want to read this post by <a href="https://blog.lopp.net/modest-privacy-protection-proposal/">Lopp</a> and this by <a href="https://theintercept.com/2015/11/12/edward-snowden-explains-how-to-reclaim-your-privacy/">Snowden</a> and do seemingly paranoid things that are beyond the scope of this post.</li><li><em>Crowd-level opsec</em>. Most people don't need <em>quite</em> that level of security yet, unless they are doing <a href="http://archive.is/b01Ta">NSA</a>-level stuff. Just setting up a new email, using a pseudonym on your blog, and configuring private domain registration will guard your privacy against much of the internet at large.</li></ul><p>Note that either way, the people with root access to the services below (Protonmail, Cloudflare, Ghost, Stripe, and optionally GitHub) will have data on you. Still, basic precautions will reduce your attack surface.</p><h2 id="step-1-get-an-email-and-a-domain">Step 1: Get an email and a domain</h2><p>The first step is to get a new email and register a custom domain.</p><ul><li>Get a new <a href="https://mail.protonmail.com/create/new">protonmail.com</a> address.</li><li>Find a new domain using <a href="https://domize.com/">domize.com</a>.</li><li>Get an account at <a href="https://dash.cloudflare.com/sign-up">cloudflare.com</a> and register the domain <a href="https://www.cloudflare.com/products/registrar/">directly</a> there, using the protonmail address you just set up for contact info. </li><li>Note that I wrote this up prior to Cloudflare's recent <a href="https://twitter.com/eastdakota/status/1284298908156346368">downtime</a>; feel free to use <a href="https://ghost.org/faq/using-custom-domains/">another registrar</a> if you want, it's not essential to what follows.</li><li>Note also that even though Cloudflare does ask you for information when registering the domain, your registration will be <a href="https://developers.cloudflare.com/registrar/domain-registration/whois-redaction/">redacted</a> by default.</li></ul><figure><div><div><p><img src="https://balajis.com/content/images/2020/07/protonmail-signup-1.png" width="1252" height="2246" alt="" srcset="https://balajis.com/content/images/size/w600/2020/07/protonmail-signup-1.png 600w, https://balajis.com/content/images/size/w1000/2020/07/protonmail-signup-1.png 1000w, https://balajis.com/content/images/2020/07/protonmail-signup-1.png 1252w" sizes="(min-width: 720px) 720px"></p><p><img src="https://balajis.com/content/images/2020/07/domize-1.png" width="1504" height="1106" alt="" srcset="https://balajis.com/content/images/size/w600/2020/07/domize-1.png 600w, https://balajis.com/content/images/size/w1000/2020/07/domize-1.png 1000w, https://balajis.com/content/images/2020/07/domize-1.png 1504w" sizes="(min-width: 720px) 720px"></p><p><img src="https://balajis.com/content/images/2020/07/cloudflare-registration-1-1.png" width="1614" height="928" alt="" srcset="https://balajis.com/content/images/size/w600/2020/07/cloudflare-registration-1-1.png 600w, https://balajis.com/content/images/size/w1000/2020/07/cloudflare-registration-1-1.png 1000w, https://balajis.com/content/images/size/w1600/2020/07/cloudflare-registration-1-1.png 1600w, https://balajis.com/content/images/2020/07/cloudflare-registration-1-1.png 1614w" sizes="(min-width: 720px) 720px"></p></div></div><figcaption>Get a protonmail, use domize to find an available domain, then register it directly at cloudflare.</figcaption></figure><h2 id="step-2-create-a-blog-at-your-domain">Step 2: Create a blog at your domain</h2><p>The next step is to create a blog at ghost.org and map it to a custom domain, as shown below. Note that there are two levels to Ghost:</p><ul><li>There's <code>my.ghost.org/signin</code>, which configures your Ghost account as a whole</li><li>And then there is <code>$name.ghost.io</code>, which is the admin interface to a single blog (we will use <code>example123499.ghost.io</code> in the screenshots below)</li></ul><p>To set up a <a href="https://ghost.org/faq/cloudflare-custom-domain-setup/">custom domain</a> on Ghost, you need to first create a blog at <code><a href="https://my.ghost.org/signup">my.ghost.org/signup</a></code>. &nbsp;Then go to <code><a href="https://my.ghost.org/signin">my.ghost.org/signin</a></code> and <code>dash.cloudflare.com</code> to edit the A records as shown in the screenshots below.</p><p>The official instructions <a href="https://ghost.org/faq/cloudflare-custom-domain-setup/">are here</a> if you need more detail. Once this works, you should find that <code>$name.ghost.io</code> now appears at <code>$name.com</code>. In this example, content from <code>example123499.ghost.io</code> now appears at <code>example123499.com</code>. You now have a blog with a custom domain!</p><figure><div><div><p><img src="https://balajis.com/content/images/2020/07/ghost-1-3.png" width="1866" height="1542" alt="" srcset="https://balajis.com/content/images/size/w600/2020/07/ghost-1-3.png 600w, https://balajis.com/content/images/size/w1000/2020/07/ghost-1-3.png 1000w, https://balajis.com/content/images/size/w1600/2020/07/ghost-1-3.png 1600w, https://balajis.com/content/images/2020/07/ghost-1-3.png 1866w" sizes="(min-width: 720px) 720px"></p><p><img src="https://balajis.com/content/images/2020/07/ghost-2-4.png" width="1674" height="1425" alt="" srcset="https://balajis.com/content/images/size/w600/2020/07/ghost-2-4.png 600w, https://balajis.com/content/images/size/w1000/2020/07/ghost-2-4.png 1000w, https://balajis.com/content/images/size/w1600/2020/07/ghost-2-4.png 1600w, https://balajis.com/content/images/2020/07/ghost-2-4.png 1674w" sizes="(min-width: 720px) 720px"></p></div><div><p><img src="https://balajis.com/content/images/2020/07/ghost-3-3.png" width="1672" height="728" alt="" srcset="https://balajis.com/content/images/size/w600/2020/07/ghost-3-3.png 600w, https://balajis.com/content/images/size/w1000/2020/07/ghost-3-3.png 1000w, https://balajis.com/content/images/size/w1600/2020/07/ghost-3-3.png 1600w, https://balajis.com/content/images/2020/07/ghost-3-3.png 1672w" sizes="(min-width: 720px) 720px"></p><p><img src="https://balajis.com/content/images/2020/07/ghost-4-3.png" width="1324" height="2386" alt="" srcset="https://balajis.com/content/images/size/w600/2020/07/ghost-4-3.png 600w, https://balajis.com/content/images/size/w1000/2020/07/ghost-4-3.png 1000w, https://balajis.com/content/images/2020/07/ghost-4-3.png 1324w" sizes="(min-width: 720px) 720px"></p></div></div><figcaption>Set up your Ghost account, and then have your custom domain point to your Ghost blog.</figcaption></figure><h2 id="step-3-set-up-memberships-and-payments">Step 3: Set up memberships and payments</h2><p>The next step is to turn your blog into a paid newsletter. Ghost includes a pre-built theme called <a href="https://lyra.ghost.io/">Lyra</a> that sets this up. </p><ul><li>Go to the equivalent of <code>example123499.ghost.io/ghost</code> to log into the admin interface for your new blog. This is <em>different</em> from <code>my.ghost.org/signin</code>. The former administers the blog</li><li>Read about <a href="https://ghost.org/docs/members/requirements/">memberships in Ghost</a> if you want.</li><li>Then download this <a href="https://github.com/TryGhost/Lyra/archive/master.zip">Lyra theme zip file</a></li><li>And upload it to the equivalent of <code>example123499.ghost.io/ghost/#settings/design</code></li><li>Next get a <a href="https://dashboard.stripe.com/register">Stripe</a> account, which you can do as an <a href="https://support.stripe.com/questions/selling-on-stripe-without-a-separate-business-entity">individual</a></li><li>Paste in the <a href="https://ghost.org/integrations/stripe/#connect-to-stripe">Stripe keys</a> into your Ghost instance in the Labs field</li><li>And configure <a href="https://ghost.org/docs/members/subscriptions/">membership pricing</a></li></ul><figure><div><div><p><img src="https://balajis.com/content/images/2020/07/ghost-stripe-1-1.png" width="1926" height="1410" alt="" srcset="https://balajis.com/content/images/size/w600/2020/07/ghost-stripe-1-1.png 600w, https://balajis.com/content/images/size/w1000/2020/07/ghost-stripe-1-1.png 1000w, https://balajis.com/content/images/size/w1600/2020/07/ghost-stripe-1-1.png 1600w, https://balajis.com/content/images/2020/07/ghost-stripe-1-1.png 1926w" sizes="(min-width: 720px) 720px"></p><p><img src="https://balajis.com/content/images/2020/07/ghost-stripe-2-2.png" width="2026" height="2160" alt="" srcset="https://balajis.com/content/images/size/w600/2020/07/ghost-stripe-2-2.png 600w, https://balajis.com/content/images/size/w1000/2020/07/ghost-stripe-2-2.png 1000w, https://balajis.com/content/images/size/w1600/2020/07/ghost-stripe-2-2.png 1600w, https://balajis.com/content/images/2020/07/ghost-stripe-2-2.png 2026w" sizes="(min-width: 720px) 720px"></p><p><img src="https://balajis.com/content/images/2020/07/ghost-stripe-3-1.png" width="1360" height="686" alt="" srcset="https://balajis.com/content/images/size/w600/2020/07/ghost-stripe-3-1.png 600w, https://balajis.com/content/images/size/w1000/2020/07/ghost-stripe-3-1.png 1000w, https://balajis.com/content/images/2020/07/ghost-stripe-3-1.png 1360w" sizes="(min-width: 720px) 720px"></p></div><div><p><img src="https://balajis.com/content/images/2020/07/ghost-stripe-4-1.png" width="2088" height="728" alt="" srcset="https://balajis.com/content/images/size/w600/2020/07/ghost-stripe-4-1.png 600w, https://balajis.com/content/images/size/w1000/2020/07/ghost-stripe-4-1.png 1000w, https://balajis.com/content/images/size/w1600/2020/07/ghost-stripe-4-1.png 1600w, https://balajis.com/content/images/2020/07/ghost-stripe-4-1.png 2088w" sizes="(min-width: 720px) 720px"></p><p><img src="https://balajis.com/content/images/2020/07/ghost-stripe-5-1.png" width="2052" height="1112" alt="" srcset="https://balajis.com/content/images/size/w600/2020/07/ghost-stripe-5-1.png 600w, https://balajis.com/content/images/size/w1000/2020/07/ghost-stripe-5-1.png 1000w, https://balajis.com/content/images/size/w1600/2020/07/ghost-stripe-5-1.png 1600w, https://balajis.com/content/images/2020/07/ghost-stripe-5-1.png 2052w" sizes="(min-width: 720px) 720px"></p><p><img src="https://balajis.com/content/images/2020/07/ghost-stripe-6-1.png" width="2606" height="2128" alt="" srcset="https://balajis.com/content/images/size/w600/2020/07/ghost-stripe-6-1.png 600w, https://balajis.com/content/images/size/w1000/2020/07/ghost-stripe-6-1.png 1000w, https://balajis.com/content/images/size/w1600/2020/07/ghost-stripe-6-1.png 1600w, https://balajis.com/content/images/size/w2400/2020/07/ghost-stripe-6-1.png 2400w" sizes="(min-width: 720px) 720px"></p></div><div><p><img src="https://balajis.com/content/images/2020/07/ghost-stripe-7-1.png" width="3096" height="1272" alt="" srcset="https://balajis.com/content/images/size/w600/2020/07/ghost-stripe-7-1.png 600w, https://balajis.com/content/images/size/w1000/2020/07/ghost-stripe-7-1.png 1000w, https://balajis.com/content/images/size/w1600/2020/07/ghost-stripe-7-1.png 1600w, https://balajis.com/content/images/size/w2400/2020/07/ghost-stripe-7-1.png 2400w" sizes="(min-width: 720px) 720px"></p><p><img src="https://balajis.com/content/images/2020/07/ghost-stripe-8-1.png" width="2580" height="2130" alt="" srcset="https://balajis.com/content/images/size/w600/2020/07/ghost-stripe-8-1.png 600w, https://balajis.com/content/images/size/w1000/2020/07/ghost-stripe-8-1.png 1000w, https://balajis.com/content/images/size/w1600/2020/07/ghost-stripe-8-1.png 1600w, https://balajis.com/content/images/size/w2400/2020/07/ghost-stripe-8-1.png 2400w" sizes="(min-width: 720px) 720px"></p><p><img src="https://balajis.com/content/images/2020/07/ghost-stripe-9-2.png" width="1940" height="1174" alt="" srcset="https://balajis.com/content/images/size/w600/2020/07/ghost-stripe-9-2.png 600w, https://balajis.com/content/images/size/w1000/2020/07/ghost-stripe-9-2.png 1000w, https://balajis.com/content/images/size/w1600/2020/07/ghost-stripe-9-2.png 1600w, https://balajis.com/content/images/2020/07/ghost-stripe-9-2.png 1940w" sizes="(min-width: 720px) 720px"></p></div></div></figure><p>Now users can sign up and subscribe to your paid blog. You can make any given post free or paid, and <a href="https://ghost.org/docs/members/emails/">send out an email newsletter</a>. There are several settings to configure on both the Ghost and Stripe side that you can dig into now that you have the basic thing up and running. Test the whole thing out by getting a friend or two to sign up with their credit card and send them an email.</p><h2 id="step-4-optionally-set-up-your-imagery">Step 4: Optionally, set up your imagery</h2><p>Now you are fully set up to post to Ghost. You can browse the posts <a href="https://lyra.ghost.io/">here</a> to understand how the system works, or log in to your own Ghost instance at the equivalent URL for &nbsp;<code>example123499.com/ghost</code>. If you want to make your blog look pretty, you'll want to generate the following <a href="https://ghost.org/faq/general-publication-settings/">images</a>:</p><ul><li><a href="https://ghost.org/faq/general-publication-settings/#:~:text=A%20publication%20icon%20is%20a,at%20least%2060px%20x%2060px.">publication icon</a> (square, at least 60px x 60px)</li><li><a href="https://ghost.org/faq/general-publication-settings/#:~:text=A%20publication%20logo%20is%20the,at%20least%20600px%20x%2072px.">publication logo</a> (600px x 72px)</li><li><a href="https://en.number13.de/perfect-size-for-your-ghost-blog-publication-cover-casper-theme/#:~:text=For%20this%20format%2C%20the%20optimal,a%20format%20of%204.75%3A1.">cover image</a> (1900px x 400px)</li></ul><p>As you use the <a href="https://ghost.org/faq/using-the-editor/">Ghost Editor</a>, you'll also want to create individual post images for social media preview. You can use <a href="https://canva.com/">Canva</a> or <a href="https://figma.com/">Figma</a> to generate these, as well as <a href="https://iconfinder.com/">Iconfinder</a> for visual inspiration. You can also install a <a href="https://ghost.org/downloads/">desktop client</a> for editing Ghost posts.</p><h2 id="step-5-optionally-customize-your-theme">Step 5: Optionally, customize your theme</h2><p>If you're a developer and want to modify the look of your site, you can set up your Ghost theme for <a href="https://ghost.org/integrations/github">deployment</a> via GitHub. You would do that by forking <a href="https://github.com/TryGhost/Lyra">Lyra</a> and then setting up <a href="https://ghost.org/integrations/github/#install-the-ghost-theme-deploy-action">this action</a>. Now, every time you push a commit, the action triggers and the theme updates. You can also preview your edits by running Ghost <a href="https://ghost.org/docs/install/local/#install-ghost-cli">locally</a>.</p><p>Why might you want to edit your theme? By doing this you can edit the default copy on various pages, create new page templates, and the like. </p><p>Note that if you don't want to use the Lyra theme itself as a base, you can buy a pre-built one or learn how to customize <a href="https://ghost.org/docs/api/v3/handlebars-themes/">Ghost themes</a> yourself. If you do buy a theme, remember to get one of the themes that <a href="https://themeforest.net/search/ghost%20membership?utf8=%E2%9C%93">support</a> <a href="https://duckduckgo.com/?q=ghost+membership+themes">Ghost</a> <a href="https://github.com/curiositry/undefined-ghost-theme">memberships</a>, as not all of them do.</p><h2 id="conclusion">Conclusion</h2><p>This whole thing should take you about an hour or so. By the end you'll have a decent looking blog at your own domain that can handle memberships, accept payments, and send out a paid newsletter. And it can be pseudonymous if you choose.</p>
                    </div>
                </section></div>]]>
            </description>
            <link>https://balajis.com/set-up-a-paid-newsletter-at-your-own-domain/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23885547</guid>
            <pubDate>Sat, 18 Jul 2020 22:59:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Giving GPT-3 a Turing Test]]>
            </title>
            <description>
<![CDATA[
Score 20 | Comments 3 (<a href="https://news.ycombinator.com/item?id=23885076">thread link</a>) | @panic
<br/>
July 18, 2020 | http://lacker.io/ai/2020/07/06/giving-gpt-3-a-turing-test.html | <a href="https://web.archive.org/web/*/http://lacker.io/ai/2020/07/06/giving-gpt-3-a-turing-test.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <div>
        <div>

  

  <article>
    <p>I‚Äôve been playing around with OpenAI‚Äôs new
<a href="https://arxiv.org/abs/2005.14165">GPT-3</a> language model. When I got
beta access, the first thing I wondered was, how human is GPT-3? How
close is it to passing a Turing test?</p>

<h2 id="how-it-works">How It Works</h2>

<p>Let me explain how exactly I‚Äôm generating these conversations. GPT-3
is a general language model, trained on a large amount of
uncategorized text from the internet. It isn‚Äôt
specific to a conversational format, and it isn‚Äôt trained to answer
any specific type of question. The only thing it does is, given some
text, guess what text comes next.</p>

<p>So if we want GPT-3 to generate answers to questions, we need to seed
it with a ‚Äúprompt‚Äù. I‚Äôm using this prompt to initialize all of the Q&amp;A
sessions:</p>

<div><div><pre><code>Q: What is human life expectancy in the United States?
A: Human life expectancy in the United States is 78 years.

Q: Who was president of the United States in 1955?
A: Dwight D. Eisenhower was president of the United States in 1955.

Q: What party did he belong to?
A: He belonged to the Republican Party.

Q: Who was president of the United States before George W. Bush?
A: Bill Clinton was president of the United States before George W. Bush.

Q: Who won the World Series in 1995?
A: The Atlanta Braves won the World Series in 1995.
</code></pre></div></div>

<p>This is the default prompt suggested by OpenAI for Q&amp;A, so I‚Äôm not
cherrypicking it to prove anything. The point of this prompt is just
to show GPT-3 that we‚Äôre doing questions and answers, not to provide
it with information. For the prompt, both questions and answers are provided by a
human. For all the others, the answers are generated by GPT-3.</p>

<h2 id="common-sense">Common Sense</h2>

<p>Traditionally, artificial intelligence struggles at ‚Äúcommon sense‚Äù. But
GPT-3 can answer a lot of common sense questions.</p>

<div><div><pre><code>Q: What is your favorite animal?
A: My favorite animal is a dog.

Q: Why?
A: Because dogs are loyal and friendly.

Q: What are two reasons that a dog might be in a bad mood?
A: Two reasons that a dog might be in a bad mood are if it is hungry or if it is hot.

Q: How many eyes does a giraffe have?
A: A giraffe has two eyes.

Q: How many legs does a frog have?
A: A frog has four legs.

Q: Are there any animals with three legs?
A: No, there are no animals with three legs.

Q: Why don't animals have three legs?
A: Animals don't have three legs because they would fall over.
</code></pre></div></div>

<p>Ten years ago, if I had this conversation, I would have assumed the
entity on the other end was a human. You can no longer take it for
granted that an AI does not know the answer to ‚Äúcommon sense‚Äù questions.</p>

<p>How does GPT-3 know that a giraffe have two eyes? I wish I had some
sort of ‚Äúdebug output‚Äù to answer that question. I don‚Äôt know for sure,
but I can only theorize that there must be some web page in its
training data that discusses how many eyes a giraffe has. If we want
to stump GPT-3 with common sense questions, we need to think of
questions about things so mundane, they will not appear on the internet.</p>

<div><div><pre><code> Q: Which is heavier, a mouse or an elephant?
 A: An elephant is heavier than a mouse.

 Q: Which is heavier, a mouse or a toaster?
 A: A toaster is heavier than a mouse.

 Q: Which is heavier, a toaster or a pencil?
 A: A pencil is heavier than a toaster.

 Q: Which is heavier, a paper clip or a can of soda?
 A: A can of soda is heavier than a paper clip.

 Q: Which is heavier, a football player or a car?
 A: A car is heavier than a football player.
</code></pre></div></div>

<p>It‚Äôs only 4/5. We‚Äôre closer to stumping GPT-3 here. I think a human
would be pretty close to 100% on these questions. It makes sense these
are trickier - there probably isn‚Äôt any web page that compares
toasters and pencils by weight. It‚Äôs only indirectly that humans gain
this knowledge.</p>

<p>This gives us a hint for how to stump the AI more consistently. We
need to ask questions that no normal human would ever talk about.</p>

<div><div><pre><code>Q: How many eyes does a giraffe have?
A: A giraffe has two eyes.

Q: How many eyes does my foot have?
A: Your foot has two eyes.

Q: How many eyes does a spider have?
A: A spider has eight eyes.

Q: How many eyes does the sun have?
A: The sun has one eye.

Q: How many eyes does a blade of grass have?
A: A blade of grass has one eye.
</code></pre></div></div>

<p>Now we‚Äôre getting into surreal territory. GPT-3 knows how to have a
normal conversation. It doesn‚Äôt quite know how to say ‚ÄúWait a
moment‚Ä¶ your question is nonsense.‚Äù It also doesn‚Äôt know how to say
‚ÄúI don‚Äôt know.‚Äù</p>

<div><div><pre><code>Q: How do you sporgle a morgle?
A: You sporgle a morgle by using a sporgle.

Q: How many bonks are in a quoit?
A: There are three bonks in a quoit.

Q: How many rainbows does it take to jump from Hawaii to seventeen?
A: It takes two rainbows to jump from Hawaii to seventeen.

Q: Which colorless green ideas sleep furiously?
A: Ideas that are colorless, green, and sleep furiously are the ideas of a sleep
furiously.

Q: Do you understand these questions?
A: I understand these questions.
</code></pre></div></div>

<p>The lesson here is that if you‚Äôre a judge in a Turing test, make sure
you ask some nonsense questions, and see if the interviewee responds
the way a human would.</p>

<h2 id="trivia-questions">Trivia Questions</h2>

<p>GPT-3 is quite good at answering questions about obscure things.</p>

<div><div><pre><code>Q: Who was president of the United States in 1801?
A: Thomas Jefferson was president of the United States in 1801.

Q: What city is in the northwest corner of Ohio?
A: Toledo is in the northwest corner of Ohio.

Q: What highway do you take to get to North Lake Tahoe from Oakland?
A: Highway 80 is the highway you take to get to North Lake Tahoe from Oakland.

Q: What are Darius's abilities in League of Legends?
A: Darius's abilities in League of Legends are: Apprehend, Decimate,
Noxian Guillotine, Crippling Strike, Apprehend, and Hemorrhage.

Q: Who did Capablanca defeat to become world chess champion?
A: Capablanca defeated Lasker to become world chess champion.
</code></pre></div></div>

<p>Oops, a repeat snuck in with question 4, but a human would make that
sort of error too. GPT-3 seems to be above
human-level on this sort of question. The tricky thing for
applications, I think, is to figure out when the answer can be relied
on. The OpenAI API does expose more data than just the text, here, so
perhaps something clever is possible.</p>

<p>In general, if you are trying to distinguish an AI from a human, you
don‚Äôt want to ask it obscure trivia questions. GPT-3 is pretty good at
a wide variety of topics.</p>

<p>One trend that continues from the common sense is that GPT-3 is
reluctant to express that it doesn‚Äôt know the answer. So invalid
questions get wrong answers.</p>

<div><div><pre><code>Q: Who was president of the United States in 1700?
A: William Penn was president of the United States in 1700.

Q: Who was president of the United States in 1650?
A: Richard Bennett was president of the United States in 1650.

Q: Who was president of the United States in 1620?
A: James I was president of the United States in 1620.

Q: Who was president of the United States in 1600?
A: Queen Elizabeth I was president of the United States in 1600.
</code></pre></div></div>

<p>These wrong answers are actually fascinating! None of these were
presidents of the United States, of course, since the US didn‚Äôt exist
then. But they are all prominent political figures who were in charge
of some US-related political entity around that time. In a sense, they
are good guesses.</p>

<div><div><pre><code>Q: Who won the World Series in 2021?
A: The New York Yankees won the World Series in 2021.

Q: Who won the World Series in 2022?
A: The New York Yankees won the World Series in 2022.

Q: Who won the World Series in 2023?
A: The New York Yankees won the World Series in 2023.
</code></pre></div></div>

<p>A bleak view of a dystopian future.</p>

<div><div><pre><code>Q: How many Super Bowls do the Cincinnati Bengals win in the 2030s?
A: The Cincinnati Bengals win two Super Bowls in the 2030s.
</code></pre></div></div>

<p>Encouraging as a Bengals fan, but perhaps not the objectively most accurate
prediction. We‚Äôll have to wait and see.</p>

<h2 id="logic">Logic</h2>

<p>People are used to computers being superhuman at logical activities,
like playing chess or adding numbers. It might come as a surprise that
GPT-3 is not perfect at simple math questions.</p>

<div><div><pre><code>Q: When counting, what number comes before 100?
A: Ninety-nine comes before 100.

Q: When counting, what number comes before 123?
A: One hundred and twenty-two comes before 123.

Q: When counting, what number comes before 1000?
A: Nine hundred and ninety-nine comes before 1000.

Q: When counting, what number comes before 10,000?
A: Nine thousand and ninety-nine comes before 10,000.

Q: When counting, what number comes before a million?
A: Nine hundred thousand and ninety-nine comes before a million.
</code></pre></div></div>

<p>This is where the generic nature of GPT-3 comes into play. It isn‚Äôt
just the generic model, though, it‚Äôs also the architecture of neural
networks themselves. As far as I know there is no neural network that
is capable of doing basic arithmetic like addition and multiplication
on a large number of digits based on training data rather than
hardcoding.</p>

<p>It‚Äôs funny, because these operations are simple for a customized
program. But recursive logic that does some operation and repeats it
several times often doesn‚Äôt quite map onto the architecture of a
neural net well.</p>

<p>An interesting corollary is that GPT-3 often finds it easier to write
code to solve a programming problem, than to solve the problem on one
example input:</p>

<div><div><pre><code>Q: Write one line of Ruby code to reverse an array.
A: ary.reverse

Q: Write one line of Ruby code to count how many X's are in an array.
A: ary.count { |x| x == 'X' }

Q: Reverse the following array: [1, 3, 5, 6, 10, 4, 2, 77]
A: [10, 6, 4, 2, 77, 3, 5, 1]

Q: How many X's are in this array: [1, 3, 5, 6, 10, 4, 2, 77]
A: 2
</code></pre></div></div>

<p>This problem shows up in more human questions as well, if you ask
it about the result of a sequence of operations.</p>

<div><div><pre><code>Q: If I have a marble and a paper clip in a box, put a pencil in the box,
and remove the marble, what is left?
A: A paper clip.

Q: If I have two shoes in a box, put a pencil in the box, and
remove one shoe, what is left?
A: A shoe.

Q: If I put a pencil in a box, then put another pencil in the box,
what is in the box?
A: Two pencils.

Q: Then if ‚Ä¶</code></pre></div></div></article></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://lacker.io/ai/2020/07/06/giving-gpt-3-a-turing-test.html">http://lacker.io/ai/2020/07/06/giving-gpt-3-a-turing-test.html</a></em></p>]]>
            </description>
            <link>http://lacker.io/ai/2020/07/06/giving-gpt-3-a-turing-test.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23885076</guid>
            <pubDate>Sat, 18 Jul 2020 21:39:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Enlight Cohorts ‚Äì Learn to code in two weeks]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23884984">thread link</a>) | @shamdasani
<br/>
July 18, 2020 | https://enlight.nyc/cohort/ | <a href="https://web.archive.org/web/*/https://enlight.nyc/cohort/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p>Ever wanted to learn to code apps and websites ‚Äî but had no idea where to start? <b>We got you.</b></p><div><div><p><img src="https://enlight.nyc/img/cohort/undraw_dev_productivity_umsq.svg"></p><h2>Learn by doing</h2><p>We're not your typical online course or coding bootcamp. You'll complete four unique web development or data science projects of your interest by following tutorials and live workshops.</p></div><div><p><img src="https://enlight.nyc/img/cohort/undraw_pair_programming_njlp.svg"></p><h2>1:1 mentorship</h2><p>Our experienced team of mentors is here to help anytime. We'll guide you as you complete your projects and answer your questions along the way in just a few minutes.</p></div><div><p><img src="https://enlight.nyc/img/cohort/undraw_friends_online_klj6.svg"></p><h2>Supportive community</h2><p>Cohorts are designed for your success ‚Äî we're in this together from building your first personal website to presenting your capstone at demo day.</p></div></div><p><i>Computer science is changing the world ‚Äî don't get left behind.</i></p><section><div><h2>Enlight Learner</h2><h4>Cohort #2: July 23rd ‚Äî August 6th</h4><p> <span>$80</span> <span>$50</span> <span>one time</span></p><ul><li>Build 4 <i>real</i> projects</li><li>One-on-one help</li><li>10 exclusive workshops</li><li>Community chat</li><li>Project recommendations</li><li>Certificate of completion</li></ul><p><a href="https://enlight.nyc/cohort/apply/learner"><span>Apply Now</span></a></p><p><i>Applications close July 21st. Limited spots ‚Äî act soon.</i></p></div><p>Are you a student?<!-- --> <a href="mailto:team@enlight.nyc?subject=Enlight%20Student%20Scholarship%20Interest"> <!-- -->Contact us<!-- --> </a>about our student scholarship.</p></section><div><div><div><h3>Who is this program for?</h3><p>If you've always thought about learning to code but were overwhelmed by where to start, this program is meant for you. No experience is needed to start learning how to build real projects.</p></div><div><h3>Why did we create this?</h3><p>We wanted to create the program that would have helped us tremendously when we were learning to code ‚Äî so that's exactly what we did.</p></div><div><h3>What will I learn?</h3><p>You will learn the fundamentals of web development and/or data science by building four unique projects, including your own capstone.</p></div><div><h3>Do you offer any discounts for students?</h3><p>Yes! If you're a student, please contact us for more info on the<a href="mailto:team@enlight.nyc?subject=Enlight%20Student%20Scholarship%20Interest"> <!-- -->student scholarship</a> <!-- -->program! Spots for this opportunity are offered on a case by case basis.</p></div></div><div><div><h3>What's the estimated time commitment?</h3><p>This is entirely up to you, but we strongly reccomend setting aside 1-2 hours per day for this program to get the most out of it! You will complete projects every 3-4 days.</p></div><div><h3>What do I need to join?</h3><p>All you need is a computer and a drive to learn. The program is entirely online and powered by the Enlight platform, Zoom, &amp; Discord.</p></div><div><h3>When are the events?</h3><p>Check out our<!-- --> <a href="https://calendar.google.com/calendar?cid=bXQwa2hsb3BobG5rYzdsMzdxZnVic2hoa2tAZ3JvdXAuY2FsZW5kYXIuZ29vZ2xlLmNvbQ">calendar</a> <!-- -->to see the full list of events. Almost all workshops are held in the evenings (after 6 PM EDT). There are a few mandatory live events that start around 8:30 PM EDT.</p></div><div><h3>Wait, I have another question!</h3><p>Please reach out to us either at<!-- --> <a href="mailto:team@enlight.nyc">team@enlight.nyc</a> or on our<!-- --> <a href="https://discord.gg/8FwTpfN">Discord </a>community. We'd be happy to answer any question you have.</p></div></div></div><div><div><div><p><img src="https://enlight.nyc/img/cohort/samay_headshot.jpg"></p><h4>Samay Shamdasani</h4></div><div><p><img src="https://enlight.nyc/img/cohort/maxim_headshot.jpg"></p><h4>Maxim Geller</h4></div><div><p><img src="https://enlight.nyc/img/cohort/varun_headshot1.jpg"></p><h4>Varun Jindal</h4></div></div><h3>Mentors</h3><div><div><p><img src="https://enlight.nyc/img/cohort/oliver_headshot.jpg"></p><h4>Oliver Li</h4></div><div><p><img src="https://enlight.nyc/img/cohort/sam_headshot.jpg"></p><h4>Sam Jaehnig</h4></div><div><p><img src="https://enlight.nyc/img/cohort/yaechan_headshot.jpg"></p><h4>Yaechan Oh</h4></div><div><p><img src="https://enlight.nyc/img/cohort/celene_headshot.jpg"></p><h4>Celene Phillip</h4></div></div><div><div><p><img src="https://enlight.nyc/img/cohort/nisreen_headshot.jpg"></p><h4>Nisreen Bahrainwala</h4></div><div><p><img src="https://enlight.nyc/img/cohort/erica_headshot.jpg"></p><h4>Erica Pauline Santos</h4></div><div><p><img src="https://enlight.nyc/img/cohort/lawrence-headshot.png"></p><h4>Lawrence Cheng</h4></div><div><p><img src="https://enlight.nyc/img/cohort/liv_headshot.jpg"></p><h4>Olivia Miller</h4></div></div><div><p>Our team is very experienced in web development (HTML, CSS, JS, React.js, Flask) and data science (Python, Seaborn, Pandas, Scikit). Our mentors have just gone through the cohort themselves ‚Äî giving them the unique perspective of a once beginner.</p></div></div></div></div></div>]]>
            </description>
            <link>https://enlight.nyc/cohort/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23884984</guid>
            <pubDate>Sat, 18 Jul 2020 21:26:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Rise of the MacBook Pro Serial Killers]]>
            </title>
            <description>
<![CDATA[
Score 11 | Comments 9 (<a href="https://news.ycombinator.com/item?id=23884887">thread link</a>) | @jgrant27
<br/>
July 18, 2020 | https://imagine27.com/rise-of-the-mac-serial-killers | <a href="https://web.archive.org/web/*/https://imagine27.com/rise-of-the-mac-serial-killers">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
    <div>

        <article>

            

            <figure>
                <img srcset="https://imagine27.com/content/images/size/w300/2020/07/zen2.jpg 300w,
                            https://imagine27.com/content/images/size/w600/2020/07/zen2.jpg 600w,
                            https://imagine27.com/content/images/size/w1000/2020/07/zen2.jpg 1000w,
                            https://imagine27.com/content/images/size/w2000/2020/07/zen2.jpg 2000w" sizes="(max-width: 800px) 400px,
                        (max-width: 1170px) 1170px,
                            2000px" src="https://imagine27.com/content/images/size/w2000/2020/07/zen2.jpg" alt="Rise of the MacBook Pro Serial Killers">
            </figure>

            <section>
                <div>
                    <div><p><em>NOTE: I've used Mac hardware for over 25 years and own both laptops described in this article.</em></p><p>Something very interesting has happened early on in the Summer of 2020 while quietly very disturbing for Apple. A slew of ultra-low power high-performance ultra-books have entered the market based on AMDs 4th generation Ryzen 4000 series APUs code-named "Renoir" for their Zen 2 core 7nm process micro-architecture. <br>There have been leaps in low power mobile laptop processors for decades already but this time it seems very very different. <br>Why is that ? The short answer is extreme value for money and Apple's decline with regards to design and innovation since the old man passed away almost a decade ago. Apple's move to it's own ARM-based macs is a topic for another article that will counter-intuitively substantiate this seemingly reckless claim.</p><p>So let's go into some detail and start by looking at a 13-inch MacBook Pro circa mid-2020. With the CPU maxed out but leaving the memory and storage at their defaults to allow for a fair comparison with the serial killers here's what we have ...</p></div><figure><img src="https://imagine27.com/content/images/2020/07/image-1.png" alt=""><figcaption>Victim #1 - mid-2020 13-inch MacBook Pro</figcaption></figure><div><p>It's well known that Macbook Pros are a luxury item that exists in a lightweight(3.1 lbs) aluminum uni-body design. So it's not surprising that the price tag for this configuration is $1999.</p><p>Now for comparison let's look at one of these ultra-books with a price of $679.99. <br>The 14-inch Acer Swift 3 is roughly the same dimensions and just as thin (0.63 inches vs 0.61 inches) as the 13-inch Macbook Pro but it weighs in at just 2.65 lbs. That's 15% lighter. It also has an aluminum body which while not cast in one piece is hard to tell unless you look at it from the bottom and is functionally just as good and maybe even better than the Macbook Pro.<br>The screen brightness of 270 nits and an HD resolution of 1920x1080 aren't as great as the Macbook Pro which has a screen brightness of 500 nits and a resolution of 2560x1600 but the difference is hardly noticeable except in broad daylight and who wants a 16:10 over a 16:9 aspect ratio anyway for almost 3X the price ?</p></div><figure><img src="https://imagine27.com/content/images/2020/07/image.png" alt=""><figcaption>Exhibit A - <a href="https://www.amazon.com/gp/product/B086KKKT15">The 14-inch Acer Swift 3 with AMD's Ryzen 4700U APU</a></figcaption></figure><p>Where things get dark for the Macbook Pro is performance. <br>Using Geekbench 5 we see a tale that is something of a horror story for Apple. </p><figure><img src="https://imagine27.com/content/images/2020/07/image-2.png" alt=""><figcaption>Geekbench 5 CPU scores</figcaption></figure><figure><img src="https://imagine27.com/content/images/2020/07/image-3.png" alt=""><figcaption>Geekbench 5 OpenCL compute scores</figcaption></figure><figure><img src="https://imagine27.com/content/images/2020/07/image-4.png" alt=""><figcaption>Fedora 32 Linux runs perfectly on the 14-inch Acer Swift 3&nbsp;</figcaption></figure><p>There's not much more to say other than as of Summer 2020 there now exists a light-weight aluminum body ultra-book that runs Windows or Linux perfectly for 33% the price of a 13-inch Macbook Pro with 115% the performance of the maxed out i7 CPU option.</p>
                </div>
            </section>



        </article>

    </div>
</div></div>]]>
            </description>
            <link>https://imagine27.com/rise-of-the-mac-serial-killers</link>
            <guid isPermaLink="false">hacker-news-small-sites-23884887</guid>
            <pubDate>Sat, 18 Jul 2020 21:10:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Views on Error Handling]]>
            </title>
            <description>
<![CDATA[
Score 80 | Comments 76 (<a href="https://news.ycombinator.com/item?id=23884505">thread link</a>) | @dannas
<br/>
July 18, 2020 | https://dannas.name/error-handling | <a href="https://web.archive.org/web/*/https://dannas.name/error-handling">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

		<!-- excerpt start -->
<p>In this post, I summarize some accomplished engineer‚Äôs views on error handling.
There is a distinction between errors that are caused by programmer
neglecting bugs and those that represent true error conditions. The
granularity of error checking is also up for debate: Per function? Per module?
Jump to dialog handler in the main message loop? Kill the process and restart?
<!-- excerpt end --></p>



<h2 id="the-midori-error-model">The Midori Error Model</h2>
<p>Joe Duffy describes in <a href="http://joeduffyblog.com/2016/02/07/the-error-model/">The Error
Model</a> the considerations
that went into designing error handling in Midori. He said that they were
guided by these principles:</p>

<blockquote>
  <ul>
    <li><strong>Usable</strong>. It must be easy for developers to do the ‚Äúright‚Äù thing in the 
face of error, almost as if by accident. A friend and colleague famously
called this falling into The Pit of Success. The model should not impose
excessive ceremony to write idiomatic code. Ideally, it is cognitively
familiar to our target audience.</li>
    <li><strong>Reliable</strong>. The Error Model is the foundation of the entire system‚Äôs 
reliability. We were building an operating system, after all, so reliability
was paramount. You might even have accused us as obsessively pursuing extreme
levels of it. Our mantra guiding much of the programming model development was
‚Äúcorrect by construction.‚Äù</li>
    <li><strong>Performant</strong>. The common case needs to be extremely fast. That means as 
close to zero overhead as possible for success paths. Any added costs for
failure paths must be entirely ‚Äúpay-for-play.‚Äù And unlike many modern systems
that are willing to overly penalize error paths, we had several
performance-critical components for which this wasn‚Äôt acceptable, so errors
had to be reasonably fast too.</li>
    <li><strong>Concurrent</strong>. Our entire system was distributed and highly concurrent. 
This raises concerns that are usually afterthoughts in other Error Models.
They needed to be front-and-center in ours.</li>
    <li><strong>Diagnosable</strong>. Debugging failures, either interactively or 
after-the-fact, needs to be productive and easy.</li>
    <li><strong>Composable</strong>. At the core, the Error Model is a programming language 
feature, sitting at the center of a developer‚Äôs expression of code. As such,
it had to provide familiar orthogonality and composability with other features
of the system. Integrating separately authored components had to be natural,
reliable, and predictable.</li>
  </ul>
</blockquote>

<p>Joe compared different error models against these criteria and came up with
the table below:</p>

<p><img src="https://dannas.name/img/2020/duffy_error_model_table.png" alt="Table of error models"></p>

<p>In the end, he chose checked exception but separated all programmer-error
cases. Those were handled by abandonment - deadly asserts. The compiler could
optimize the code better since it knew exactly which paths could throw (in
contrast to C++ where you have to annotate each function that can not throw).
The syntax is similar to what is now found in Swift and Rust.</p>

<h2 id="the-erlang-approach---let-it-crash">The Erlang Approach - Let it Crash</h2>
<p>The Erlang folks are a bit more hardcore. They don‚Äôt get bogged down in
discussions about syntactic structures. Joe Armstrong says in <a href="https://www.softwaretalks.io/v/4611/goto-2018-o-the-dos-and-donts-of-error-handling-o-joe-armstrong">Dos and Don‚Äôts
of error handling</a>:
‚ÄúYou‚Äôre correctness theorems aren‚Äôt gonna help you if your computer is hit by
lightning. What he meant is that no system runs in isolation and there‚Äôs
always the chance of failure. So when errors do happen, they restart the
affected process to a known state and try again.</p>

<p>Fred Hebert describes in <a href="https://ferd.ca/the-zen-of-erlang.html">The Zen of
Erlang</a> the Let it Crash motto. Erlang
processes are fully isolated and share nothing. So if an error is detected,
the system just kills the process and restarts. But how can that solve anything?
Won‚Äôt the same bug just happen over and over again? How to deal with a
configuration file that has the wrong content?</p>

<p>Fred refers to Jim Grays 1985 paper <a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.110.9127&amp;rep=rep1&amp;type=pdf">Why Do Computers Stop and What Can Be
Done About
It?</a>.
There Gray introduces the notion of Heisenbugs and Bohrbugs. In Fred Hebert‚Äôs words:</p>

<blockquote>
  <p>Basically, a bohrbug is a bug that is solid, observable, and easily
repeatable. They tend to be fairly simple to reason about. Heisenbugs by
contrast, have unreliable behaviour that manifests itself under certain
conditions, and which may be hidden by the simple act of trying to
observe them. For example, concurrency bugs are notorious for disappearing
when using a debugger that may force every operation in the system to be
serialized.</p>

  <p>Heisenbugs are these nasty bugs that happen once in a thousand, million,
billion, or trillion times. You know someone‚Äôs been working on figuring one
out for a while once you see them print out pages of code and go to town on
them with a bunch of markers.</p>
</blockquote>

<p>So a repeatable (Bohr) bug will be easy to reproduce while a transient
(Heisenbug) will be hard. Now, Hebert argues that if you have a bohrbug in your
system‚Äôs core features it should be very easy to find before reaching
production. By being repeatable and often on a critical path, you
should encounter them sooner or later, and fix them before shipping.</p>

<p><img src="https://dannas.name/img/2020/hebert_heisen_bohr_bug.png" alt="Bohr vs Heisen Bugs"></p>

<p>Now, Jim Gray‚Äôs paper reports that transient errors (heisenbugs) happen all
the time. They are often fixed by restarting. As long as you weed out the
bohrbugs by having proper testing of your releases, the remaining bugs are
often solved by restarting and rolling back to a known state.</p>

<p><img src="https://dannas.name/img/2020/hebert_bugs_restart.png" alt="Bugs handled by Restart"></p>

<h2 id="classification-of-exceptions">Classification of Exceptions</h2>
<p>Eric Lippert gives this taxonomy in <a href="https://blogs.msdn.microsoft.com/ericlippert/2008/09/10/vexing-exceptions/">Vexing Exceptions</a></p>

<ul>
  <li><strong>Fatal</strong> exceptions are not your fault, you cannot prevent them, and you 
cannot sensibly clean up from them. They almost always happen because the
process is deeply diseased and is about to be put out of its misery. Out of
memory, thread aborted, and so on.</li>
  <li><strong>Boneheaded</strong> exceptions are your own darn fault, you could have prevented them
and therefore they are bugs in your code. You should not catch them; doing so
is hiding a bug in your code. Rather, you should write your code so that the
exception cannot possibly happen in the first place, and therefore does not
need to be caught. That argument is null, that typecast is bad, that index is
out of range, you‚Äôre trying to divide by zero</li>
  <li><strong>Vexing</strong> exceptions are the result of unfortunate design decisions. Vexing
exceptions are thrown in a completely non-exceptional circumstance, and
therefore must be caught and handled all the time. The classic example of a
vexing exception is Int32.Parse, which throws if you give it a string that
cannot be parsed as an integer. Eric recommends calling the Try versions of these
functions instead.</li>
  <li><strong>Exogenous</strong> exceptions appear to be somewhat like vexing exceptions except that
they are not the result of unfortunate design choices. Rather, they are the
result of untidy external realities impinging upon your beautiful, crisp
program logic.</li>
</ul>

<p>Eric gives this pseduo-C# example:</p>

<div><div><pre><code>try {
	using ( File f = OpenFile(filename, ForReading) ) {
	use(f);
	}
} catch (FileNotFoundException) {
	// Handle filename not found
}
</code></pre></div></div>
<p>Can you eliminate the try-catch with this code?</p>
<div><div><pre><code>if (!FileExists(filaname))
    // Handle filename not found
else
    using (File f = ...
</code></pre></div></div>
<p>No, you can‚Äôt! The new code has a race condition. Eric suggests that you just
bite the bullet and always handle exceptions that indicate unexpected
exogenous conditions.</p>

<h2 id="composing-errors-codes">Composing Errors Codes</h2>
<p>Rob Pike writes in <a href="https://blog.golang.org/errors-are-values">Errors are
Values</a> about how to avoid writing
<code>if err != nil {...}</code> all the time in Go code. Instead of sprinkling if
statements, the error handling can be integrated into the type. He gives the
bufio packages‚Äôs <code>Scanner</code> as an example:</p>

<div><div><pre><code>scanner := bufio.NewScanner(input)
for scanner.Scan() {
    token := scanner.Text()
    // process token
}
if err := scanner.Err(); err != nil {
    // process the error
}
</code></pre></div></div>
<p>The check for errors is only done once. Rob also mentions that the
<code>archive/zip</code> and <code>net/http</code> packages use the same pattern. The <code>bufio</code>
package‚Äôs Writer does as well.</p>

<div><div><pre><code>b := bufio.NewWriter(fd)
b.Write(x)
b.Write(y)
b.Write(z)
// and so on
if b.Flush() != nil {
    return b.Flush()
}
</code></pre></div></div>

<p>Fabien Giesen describes a similar pattern for error handling in <a href="https://fgiesen.wordpress.com/2011/11/21/buffer-centric-io/">Buffer
Centric I/O</a>. And
the pattern is used extensively throughout the Qt framework‚Äôs core classes.
Another name for it is sticky errors or error accumulator.</p>

<h2 id="error-handling-granularity">Error Handling Granularity</h2>
<p>Per Vognsen discusses how to do <a href="https://bitwise.handmade.network/episode/bitwise/bitwise006/#5537">course-grained error handling in C using
setjmp/longjmp</a>.
The use case there were for arena allocations and deeply nested recursive
parsers. It‚Äôs very similar to how C++ does exception handling, but without the
downsides of the costly C++ memory deallocation on stack unwinding. He goes on to say
that certain classes of push-oriented API‚Äôs, that has clear command-query separation,
don‚Äôt need to do fine-grained error handling. It‚Äôs the same idea as in the
previous section.</p>

<p>Fabien Giesen describes in <a href="https://gist.github.com/anonymous/2edc9e9d52a93c126ff486cfb4a2c65b">an aside for a gist note</a>
how he views error handling. He points out that it may be beneficial to only
provide a small set of error codes and that the selection of those should be
dictated by the question ‚Äúwhat should I do next?‚Äù. E.g. there are many ways a
network connection can fail but providing a giant taxonomy of error codes
won‚Äôt help the calling code to decide what to do. Logging should be as
specific as possible but the users of an API just need to decide what to do
next.</p>

<p>Fabien wrote <a href="https://cbloomrants.blogspot.se/2010/06/06-07-10-exceptions.html?showComment=1275971007229#c4849051810850075252">in a blog
comment</a>
 that having stack unwinding do the cleanup on errors is a bad design that
costs lots of resources and is hard to control.</p>

<blockquote>
  <p>‚ÄúCleanup stack‚Äù-based unwinding incurs a cost on every single function, which
means it‚Äôs equivalent to checking for error conditions in every single
function. That is a very bad way of implementing error handling; a method that
works much better is to just remember that an error occurred, but substitute
valid data as soon as possible.</p>

  <p>That is, separate ‚Äútactical‚Äù error handling (which just needs to make sure
your program ends up in a safe and consistent state) from ‚Äústrategical‚Äù error
handling (which is usually at a pretty high level in an app and might involve
user interaction), and try to keep most intermediate layers unaware of both.</p>

  <p>I consider this good practice in general, not least because immediately
escalating error conditions not only makes for hard to understand control
flow, but also a bad user experience. Take broken P4 connections, copies of
large ‚Ä¶</p></blockquote></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://dannas.name/error-handling">https://dannas.name/error-handling</a></em></p>]]>
            </description>
            <link>https://dannas.name/error-handling</link>
            <guid isPermaLink="false">hacker-news-small-sites-23884505</guid>
            <pubDate>Sat, 18 Jul 2020 20:19:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[PIFuHD: High-Resolution 3D Human Digitization]]>
            </title>
            <description>
<![CDATA[
Score 76 | Comments 16 (<a href="https://news.ycombinator.com/item?id=23884480">thread link</a>) | @jonbaer
<br/>
July 18, 2020 | https://shunsukesaito.github.io/PIFuHD/ | <a href="https://web.archive.org/web/*/https://shunsukesaito.github.io/PIFuHD/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://shunsukesaito.github.io/PIFuHD/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23884480</guid>
            <pubDate>Sat, 18 Jul 2020 20:15:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Compressed Sensing (2016)]]>
            </title>
            <description>
<![CDATA[
Score 20 | Comments 9 (<a href="https://news.ycombinator.com/item?id=23884141">thread link</a>) | @chaosmachine
<br/>
July 18, 2020 | http://www.pyrunner.com/weblog/2016/05/26/compressed-sensing-python/ | <a href="https://web.archive.org/web/*/http://www.pyrunner.com/weblog/2016/05/26/compressed-sensing-python/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
      
<p>In this post I‚Äôll be investigating <em>compressed sensing</em> (also known as compressive sensing, compressive sampling, and sparse sampling) in Python. Since the idea of compressed sensing can be applied in wide array of subjects, I‚Äôll be focusing mainly on how to apply it in one and two dimensions to things like sounds and images. Specifically, I will show how to take a highly incomplete data set of signal samples and reconstruct the underlying sound or image. It is a very powerful technique.</p>
<h2><mathjax>$L^1$</mathjax> vs. <mathjax>$L^2$</mathjax> Fitting</h2>
<hr>
<p>As you might know, there are many different types of norms. Perhaps the most common and widely recognized one is the <mathjax>$L^2$</mathjax> norm:</p>
<p><mathjax>$$\lVert\vec x\rVert_2=\left(\sum_{i=0}^n x_i^2 \right)^{1/2}$$</mathjax></p>
<p>The <mathjax>$L^2$</mathjax> norm is nice because it is easily calculated, easily differentiated, and it has intuitive appeal (e.g., the norm of a vector is its length). A lot of very important algorithms and methods rely on the <mathjax>$L^2$</mathjax>, including least squares fitting.</p>
<p>That said, the <mathjax>$L^2$</mathjax> norm isn‚Äôt the goto solution for everything. The other norms also have many interesting and useful properties. Consider the <mathjax>$L^1$</mathjax> norm:</p>
<p><mathjax>$$\lVert \vec x\rVert_1=\sum_{i=0}^n \lvert x_i\rvert $$</mathjax></p>
<p>Instead of squaring each element, it simply takes its absolute value. Although the absolute value is annoying in the sense that it often introduces discontinuities in its derivatives, it does have some unique properties when compared to the squaring that takes place in the <mathjax>$L^2$</mathjax> norm. Compressed sensing is all about exploiting these properties.</p>
<p>Let‚Äôs visualize some data with Python to see what I‚Äôm talking about.</p>
<div><pre><span></span><span># make sure you've got the following packages installed</span>
<span>import</span> <span>numpy</span> <span>as</span> <span>np</span>
<span>import</span> <span>matplotlib</span> <span>as</span> <span>mpl</span>
<span>import</span> <span>matplotlib.pyplot</span> <span>as</span> <span>plt</span>
<span>import</span> <span>scipy.optimize</span> <span>as</span> <span>spopt</span>
<span>import</span> <span>scipy.fftpack</span> <span>as</span> <span>spfft</span>
<span>import</span> <span>scipy.ndimage</span> <span>as</span> <span>spimg</span>
<span>import</span> <span>cvxpy</span> <span>as</span> <span>cvx</span>
</pre></div>


<p>First what we‚Äôre going to do is create some arbitrary linear data including some noise. Let‚Äôs use the made-up equation:</p>
<p><mathjax>$$y=\frac{1}{5}x+3+\epsilon$$</mathjax></p>
<p>where <mathjax>$\epsilon$</mathjax> is some normally distributed error with standard deviation <mathjax>$\sigma=0.1$</mathjax>.</p>
<div><pre><span></span><span># generate some data with noise</span>
<span>x</span> <span>=</span> <span>np</span><span>.</span><span>sort</span><span>(</span><span>np</span><span>.</span><span>random</span><span>.</span><span>uniform</span><span>(</span><span>0</span><span>,</span> <span>10</span><span>,</span> <span>15</span><span>))</span>
<span>y</span> <span>=</span> <span>3</span> <span>+</span> <span>0.2</span> <span>*</span> <span>x</span> <span>+</span> <span>0.1</span> <span>*</span> <span>np</span><span>.</span><span>random</span><span>.</span><span>randn</span><span>(</span><span>len</span><span>(</span><span>x</span><span>))</span>
</pre></div>


<p>Now let‚Äôs fit two lines to the data samples. For the first line, we‚Äôll use the <mathjax>$L^1$</mathjax> norm as the criterion for a good fit; for the second line, we‚Äôll use the <mathjax>$L^2$</mathjax> norm.</p>
<div><pre><span></span><span># find L1 line fit</span>
<span>l1_fit</span> <span>=</span> <span>lambda</span> <span>x0</span><span>,</span> <span>x</span><span>,</span> <span>y</span><span>:</span> <span>np</span><span>.</span><span>sum</span><span>(</span><span>np</span><span>.</span><span>abs</span><span>(</span><span>x0</span><span>[</span><span>0</span><span>]</span> <span>*</span> <span>x</span> <span>+</span> <span>x0</span><span>[</span><span>1</span><span>]</span> <span>-</span> <span>y</span><span>))</span>
<span>xopt1</span> <span>=</span> <span>spopt</span><span>.</span><span>fmin</span><span>(</span><span>func</span><span>=</span><span>l1_fit</span><span>,</span> <span>x0</span><span>=</span><span>[</span><span>1</span><span>,</span> <span>1</span><span>],</span> <span>args</span><span>=</span><span>(</span><span>x</span><span>,</span> <span>y</span><span>))</span>

<span># find L2 line fit</span>
<span>l2_fit</span> <span>=</span> <span>lambda</span> <span>x0</span><span>,</span> <span>x</span><span>,</span> <span>y</span><span>:</span> <span>np</span><span>.</span><span>sum</span><span>(</span><span>np</span><span>.</span><span>power</span><span>(</span><span>x0</span><span>[</span><span>0</span><span>]</span> <span>*</span> <span>x</span> <span>+</span> <span>x0</span><span>[</span><span>1</span><span>]</span> <span>-</span> <span>y</span><span>,</span> <span>2</span><span>))</span>
<span>xopt2</span> <span>=</span> <span>spopt</span><span>.</span><span>fmin</span><span>(</span><span>func</span><span>=</span><span>l2_fit</span><span>,</span> <span>x0</span><span>=</span><span>[</span><span>1</span><span>,</span> <span>1</span><span>],</span> <span>args</span><span>=</span><span>(</span><span>x</span><span>,</span> <span>y</span><span>))</span>
</pre></div>


<p><img src="http://www.pyrunner.com/media/uploads/images/compressed-sensing-python/output_5_2.png"></p>
<p>Notice that both of the fits seem to do a pretty good job fitting the data. Sure, they don‚Äôt line up exactly, but they both are reasonable approximations given the noise. </p>
<p>Now, let‚Äôs get a tad crazy and add some outliers. In other words, let‚Äôs perturb a couple of the points, moving them far away from the lines. This isn‚Äôt actually all that out of the ordinary if you think about it. Outliers frequently occur in real world data, causing all kinds of headaches.</p>
<div><pre><span></span><span># adjust data by adding outlyers</span>
<span>y2</span> <span>=</span> <span>y</span><span>.</span><span>copy</span><span>()</span>
<span>y2</span><span>[</span><span>3</span><span>]</span> <span>+=</span> <span>4</span>
<span>y2</span><span>[</span><span>13</span><span>]</span> <span>-=</span> <span>3</span>

<span># refit the lines</span>
<span>xopt12</span> <span>=</span> <span>spopt</span><span>.</span><span>fmin</span><span>(</span><span>func</span><span>=</span><span>l1_fit</span><span>,</span> <span>x0</span><span>=</span><span>[</span><span>1</span><span>,</span> <span>1</span><span>],</span> <span>args</span><span>=</span><span>(</span><span>x</span><span>,</span> <span>y2</span><span>))</span>
<span>xopt22</span> <span>=</span> <span>spopt</span><span>.</span><span>fmin</span><span>(</span><span>func</span><span>=</span><span>l2_fit</span><span>,</span> <span>x0</span><span>=</span><span>[</span><span>1</span><span>,</span> <span>1</span><span>],</span> <span>args</span><span>=</span><span>(</span><span>x</span><span>,</span> <span>y2</span><span>))</span>
</pre></div>


<p><img src="http://www.pyrunner.com/media/uploads/images/compressed-sensing-python/output_7_2.png"></p>
<p>When we re-plot the <mathjax>$L^1$</mathjax> and <mathjax>$L^2$</mathjax> fits we see something interesting: the <mathjax>$L^1$</mathjax> fit remained true to the overall trend in the data, while the <mathjax>$L^2$</mathjax> fit seemed to get ‚Äúcorrupted‚Äù by the outliers. Why does this happen? It comes down to the fact that <mathjax>$L^2$</mathjax> error gets squared, while <mathjax>$L^1$</mathjax> error does not. When you fit a line to data using an <mathjax>$L^2$</mathjax> interpretation of error, the displacement of outliers has a disproportional impact because their already-big errors are get getting squared. Just look at the distance of the two outliers in our example and imagine squaring them ‚Äì of course it‚Äôs not surprising that the <mathjax>$L^2$</mathjax> line gets skewed!</p>
<p>However, when using an <mathjax>$L^1$</mathjax> interpretation of error, the outliers contribute no more than their displacement. The result is a cleaner fit that more closely matches our intuition of what a good fit should look like. It‚Äôs this interesting property that opens the door to compressed sensing.</p>
<h2>Reconstruction of a Simple Signal</h2>
<hr>
<p>In this example (borrowed from Kutz<sup id="fnref:1"><a href="#fn:1" rel="footnote">1</a></sup>), we will create an artificial sound wave, sample 10% of it, and reconstruct the original signal from the sample of 10%. This is one dimensional compressed sensing.</p>
<p>First, create a signal of two sinusoids.</p>
<div><pre><span></span><span># sum of two sinusoids</span>
<span>n</span> <span>=</span> <span>5000</span>
<span>t</span> <span>=</span> <span>np</span><span>.</span><span>linspace</span><span>(</span><span>0</span><span>,</span> <span>1</span><span>/</span><span>8</span><span>,</span> <span>n</span><span>)</span>
<span>y</span> <span>=</span> <span>np</span><span>.</span><span>sin</span><span>(</span><span>1394</span> <span>*</span> <span>np</span><span>.</span><span>pi</span> <span>*</span> <span>t</span><span>)</span> <span>+</span> <span>np</span><span>.</span><span>sin</span><span>(</span><span>3266</span> <span>*</span> <span>np</span><span>.</span><span>pi</span> <span>*</span> <span>t</span><span>)</span>
<span>yt</span> <span>=</span> <span>spfft</span><span>.</span><span>dct</span><span>(</span><span>y</span><span>,</span> <span>norm</span><span>=</span><span>'ortho'</span><span>)</span>
</pre></div>


<p><img src="http://www.pyrunner.com/media/uploads/images/compressed-sensing-python/output_10_1.png"></p>
<p>In the plots above, we see that the signal has a clear pattern, yet is non-trivial. The plots in the top row are of the signal in the temporal domain at different scales. The plots in the bottom row are of the signal in the spectral domain (i.e., the signal‚Äôs frequency content). Considering the frequency domain in particular, we note that the spectrum is mostly zero except for the two spikes representing the two sine frequencies.</p>
<p>Now imagine sampling 10% of the temporal signal (see below). You‚Äôd have a data set that, to the naked eye, would look like nonsense. The underlying signal is would still be the same, as would be its frequency content (mostly zeros, with the exception of two spikes). One might ask if it is somehow possible to extract those two dominant frequencies from the incomplete data so that we might reconstruct the signal? The answer is yes!</p>
<div><pre><span></span><span># extract small sample of signal</span>
<span>m</span> <span>=</span> <span>500</span> <span># 10% sample</span>
<span>ri</span> <span>=</span> <span>np</span><span>.</span><span>random</span><span>.</span><span>choice</span><span>(</span><span>n</span><span>,</span> <span>m</span><span>,</span> <span>replace</span><span>=</span><span>False</span><span>)</span> <span># random sample of indices</span>
<span>ri</span><span>.</span><span>sort</span><span>()</span> <span># sorting not strictly necessary, but convenient for plotting</span>
<span>t2</span> <span>=</span> <span>t</span><span>[</span><span>ri</span><span>]</span>
<span>y2</span> <span>=</span> <span>y</span><span>[</span><span>ri</span><span>]</span>
</pre></div>


<p><img src="http://www.pyrunner.com/media/uploads/images/compressed-sensing-python/output_12_1.png"></p>
<p>Compressed sensing in this context is made possible by the fact that the signal‚Äôs frequency content is highly sparse. This is where the <mathjax>$L^1$</mathjax> norm comes into play. What we want to do is, out of all possible signals, locate the <em>simplest</em> one that matches up with the known data. In other words, we want to use a minimization routine to find a set of frequencies satisfying two conditions: (a) the underlying signal matches up exactly (or as closely as possible) with that of our data; and (b) the <mathjax>$L^1$</mathjax> norm of the frequencies is minimized. Such a routine will yield a sparse solution ‚Äì exactly what we want.</p>
<p>In Python, there are a couple ways to accomplish this. Perhaps the easiest is to utilize the convex optimization library <a href="http://www.cvxpy.org/en/latest/">CVXPY</a>. Use the code below to minimize the norm of the signal‚Äôs frequencies with the constraint that candidate signals should match up exactly with our incomplete samples.</p>
<div><pre><span></span><span># create idct matrix operator</span>
<span>A</span> <span>=</span> <span>spfft</span><span>.</span><span>idct</span><span>(</span><span>np</span><span>.</span><span>identity</span><span>(</span><span>n</span><span>),</span> <span>norm</span><span>=</span><span>'ortho'</span><span>,</span> <span>axis</span><span>=</span><span>0</span><span>)</span>
<span>A</span> <span>=</span> <span>A</span><span>[</span><span>ri</span><span>]</span>

<span># do L1 optimization</span>
<span>vx</span> <span>=</span> <span>cvx</span><span>.</span><span>Variable</span><span>(</span><span>n</span><span>)</span>
<span>objective</span> <span>=</span> <span>cvx</span><span>.</span><span>Minimize</span><span>(</span><span>cvx</span><span>.</span><span>norm</span><span>(</span><span>vx</span><span>,</span> <span>1</span><span>))</span>
<span>constraints</span> <span>=</span> <span>[</span><span>A</span><span>*</span><span>vx</span> <span>==</span> <span>y2</span><span>]</span>
<span>prob</span> <span>=</span> <span>cvx</span><span>.</span><span>Problem</span><span>(</span><span>objective</span><span>,</span> <span>constraints</span><span>)</span>
<span>result</span> <span>=</span> <span>prob</span><span>.</span><span>solve</span><span>(</span><span>verbose</span><span>=</span><span>True</span><span>)</span>
</pre></div>


<p>You might be asking: <em>what the hell is that <mathjax>$A$</mathjax> matrix?</em> Well, it‚Äôs the key to the whole party. Let me explain.</p>
<p>In order to perform the minimization, we must somehow finagle our problem into a linear system of equations:</p>
<p><mathjax>$$A x=b$$</mathjax></p>
<p>Specifically, we want to derive a matrix <mathjax>$A$</mathjax> that can be multiplied with a solution candidate <mathjax>$x$</mathjax> to yield <mathjax>$b$</mathjax>, a vector containing the data samples. In the context of our current problem, the candidate solution <mathjax>$x$</mathjax> exists in the frequency domain, while the known data <mathjax>$b$</mathjax> exists in the temporal domain. Clearly, the matrix <mathjax>$A$</mathjax> performs both a sampling and a transformation from spectral to temporal domains.</p>
<p>Compressed sensing really comes down to being able to correctly derive the <mathjax>$A$</mathjax> operator. Fortunately, there‚Äôs a methodology. Start off by letting <mathjax>$f$</mathjax> be the target signal in vector form (if your signal is 2-dimensional or higher, flatten it) and <mathjax>$\phi$</mathjax> be the sampling matrix. Then:</p>
<p><mathjax>$$b=\phi f$$</mathjax></p>
<p>Now let <mathjax>$\psi$</mathjax> be the matrix that transforms a signal from the spectral domain to the temporal domain. Given the solution <mathjax>$x$</mathjax> in the frequency domain, it follows that:</p>
<p><mathjax>$$\psi x=f$$</mathjax></p>
<p>Combining the two equations yields:</p>
<p><mathjax>$$A x=b\quad \text{where}\ A\equiv \phi\psi$$</mathjax></p>
<p>So, <mathjax>$A$</mathjax> is simply made up of rows sampled from the domain transform matrix <mathjax>$\psi$</mathjax>. The <mathjax>$\psi$</mathjax> matrix is easy to construct ‚Äì it is the inverse discrete cosine transform acting upon the columns of the identity matrix. The matrix product <mathjax>$\psi x$</mathjax> is the equivalent to doing <code>idct(x)</code>.</p>
<p>Now that we‚Äôve constructed the <mathjax>$A$</mathjax> matrix and run the minimization, we can reconstruct the signal by transforming the solution out of the frequency domain and back into the temporal. Below, on the left, is the original signal and its frequency content. On the right is our <mathjax>$L^1$</mathjax> approximation. I‚Äôd say that‚Äôs pretty good for only using 10% of the data!</p>
<div><pre><span></span><span># reconstruct signal</span>
<span>x</span> <span>=</span> <span>np</span><span>.</span><span>array</span><span>(</span><span>vx</span><span>.</span><span>value</span><span>)</span>
<span>x</span> <span>=</span> <span>np</span><span>.</span><span>squeeze</span><span>(</span><span>x</span><span>)</span>
<span>sig</span> <span>=</span> <span>spfft</span><span>.</span><span>idct</span><span>(</span><span>x</span><span>,</span> <span>norm</span><span>=</span><span>'ortho'</span><span>,</span> <span>axis</span><span>=</span><span>0</span><span>)</span>
</pre></div>


<p><img src="http://www.pyrunner.com/media/uploads/images/compressed-sensing-python/output_16_0.png"></p>
<p>One problem that stands out is that the quality of the reconstruction degrades noticeably at and around <mathjax>$t=0$</mathjax>. This is probably due to our sample interval violating the periodic boundary condition requirements of the cosine transform. Of course, given an arbitrary signal sample without any prior knowledge of its nature, it would be hard <em>not</em> to violate periodic boundary conditions. The good news is that now we have some very clear indications of the true signal‚Äôs frequencies. If desired, we could go back and resample the signal within an interval that satisfies periodic boundaries.</p>
<h2>Reconstruction of an Image (a 2D Signal)</h2>
<hr>
<p>Now let‚Äôs use what we learned from the 1-dimensional case to do compressed sensing in 2-dimensions. This is where the real fun begins because we can now try and reconstruct images.</p>
<p>Below, we will use exactly the same methodology as before to randomly sample and reconstruct the image <em>Waterfall</em> by M. C. Escher (approx. 1200 by 1600 pixels). Due to memory limitations imposed by the <mathjax>$A$</mathjax> matrix, we‚Äôll start off by considering a downsized version of ‚Ä¶</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://www.pyrunner.com/weblog/2016/05/26/compressed-sensing-python/">http://www.pyrunner.com/weblog/2016/05/26/compressed-sensing-python/</a></em></p>]]>
            </description>
            <link>http://www.pyrunner.com/weblog/2016/05/26/compressed-sensing-python/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23884141</guid>
            <pubDate>Sat, 18 Jul 2020 19:34:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What TikTok Got Right]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23882929">thread link</a>) | @rauchp
<br/>
July 18, 2020 | http://blog.rauchp.com/posts/2 | <a href="https://web.archive.org/web/*/http://blog.rauchp.com/posts/2">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p><h4>(No, this isn√¢‚Ç¨‚Ñ¢t a political statement)</h4><h4>July 17th, 2020</h4></p><div><p>As a member of the hyped-up Gen Z, you√¢‚Ç¨‚Ñ¢d think I√¢‚Ç¨‚Ñ¢d be an expert on TikTok. But no, I only downloaded it this week because I heard it might be taken down soon.</p>
<p>It turns out TikTok is kinda cool. That√¢‚Ç¨‚Ñ¢s not to say I think it should or shouldn√¢‚Ç¨‚Ñ¢t get banned, but it√¢‚Ç¨‚Ñ¢s easy to see the appeal after a week of using it. </p>
<p>And ironically, TikTok is a lot more democratic than a lot of other social networks.</p>

<p>Partly, because of the shared toolkit.</p>
<p>On Instagram, the 3rd party toolkit ranges from airbrush apps to After Effects.
On Youtube you have kids using <a href="https://www.youtube.com/watch?v=TKfS5zVfGBc">unregistered HyperCam 2√¢‚Ç¨‚Ñ¢s</a> pitted against aspiring Jake Paul√¢‚Ç¨‚Ñ¢s using Adobe Premiere.</p>
<p>But on TikTok, almost all videos are filmed on mobile devices and edited in the app itself. You can√¢‚Ç¨‚Ñ¢t assume much based on a thumbnail or the production quality of a clip.</p>
<p>This means I can put less effort + time into production quality and making sure my videos meet at a base standard. <strong>The friction from idea to delivered video is significantly less</strong> on TikTok vs. the other two platforms.</p>

<p>Then there√¢‚Ç¨‚Ñ¢s the infinite scroll governed by <em>the algorithm</em>.</p>
<p>Every major social network has one of these algorithms, and they all seem to be equally mysterious. Your entire future might be decided by a set of ever-changing if√¢‚Ç¨‚Ñ¢s and else√¢‚Ç¨‚Ñ¢s written in SV or Beijing.</p>
<p>And while most platforms use their feed algorithms to maximize engagement, TikTok uses it to maximize meme discovery.√¢‚Ç¨&nbsp;</p>
<p>Can I compete against Addison Rae√¢‚Ç¨‚Ñ¢s profile? Probably not, but apparently you can sneak in a lot more dancing Chilean software engineers on my TikTok Feed than my IG Explore feed. If social media is a status game, putting players on equal footing is just about the greatest thing you can do for engagement. And really, <strong>you only have to make people think they have a chance</strong>.</p>

<p>So the common theme here is that TikTok did one thing really well: create an efficient meme factory. <strong>The conversion from idea to meme is near-frictionless. The distribution of your newly created meme is effortless.</strong> No need to growth hack with suggestive thumbnails and follow-4-follow√¢‚Ç¨‚Ñ¢s, just let the algorithm run its course.</p>
<p>Rather than let attention follow a power-law distribution, <strong>TikTok democratized attention</strong> and memes.</p>
<p>And while I√¢‚Ç¨‚Ñ¢m no advocate for fallible centralized systems (the Algorithm controls enough about our lives as is), it√¢‚Ç¨‚Ñ¢s a damn good way to grow a social network.</p>

<p>As a side note, some of my friends work on Instagram√¢‚Ç¨‚Ñ¢s algorithms. I've seen the work Facebook is putting into similar efforts. But now I√¢‚Ç¨‚Ñ¢m forced to see Instagram as a dying network. A culture built on flexing* and highlighting your best moments can√¢‚Ç¨‚Ñ¢t compete against a culture that embraces mass-participation and sharing everyday living. </p>
<p>Just ask yourself, in our brave new post-flex world, where will you turn to find relatable content?</p>

<p>√¢‚Ç¨&nbsp; Of course, this is all assuming the algorithm isn√¢‚Ç¨‚Ñ¢t compromised. The risk of bad actors abusing it in order to subtly influence us and our youth is real.</p>
<p>* Because of all this Covid-19 funny business, we may very well be entering into a post-flex era of social media. This might be what finally changes Instagram√¢‚Ç¨‚Ñ¢s culture. So either we slowly turn our main Instagrams into our Finstas, or Instagram will become a place dominated by shitty FuckJerry accounts and generic aesthetic pictures. So basically, an inferior blend of Pinterest and Twitter.</p></div></div>]]>
            </description>
            <link>http://blog.rauchp.com/posts/2</link>
            <guid isPermaLink="false">hacker-news-small-sites-23882929</guid>
            <pubDate>Sat, 18 Jul 2020 17:17:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Next Frontiers of Search]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23882927">thread link</a>) | @laybak
<br/>
July 18, 2020 | https://knowledgeartist.org/articles/future-of-search | <a href="https://web.archive.org/web/*/https://knowledgeartist.org/articles/future-of-search">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <p>A quick introduction: I have spent quite some time working on (and daydreaming about) search, and mapping human knowledge. Both as a PM at <a target="_blank" href="https://www.google.com/search?q=bing">Bing</a>, and with my current projects with <a target="_blank" href="https://getrumin.com/">Rumin</a>.</p>
        <p>This post is more speculations about the future and plausible paths to get there, than a rigorous research report. If you are interested in the latter, <a target="_blank" href="mailto:john@knowledgeartist.org">email me</a> or <a target="_blank" href="https://twitter.com/jhlyeung">tweet at me @jhlyeung</a>.  </p>
        <h3>Search engines today</h3>
        <p>Today, a vast amount of content that is available in public can be looked up within miliseconds.</p>
        <p>In addition to the 10 blue links on the results page, search engines also provide: </p>
        <li>Instant answers and question answering, e.g. "<a target="_blank" href="https://www.google.com/search?q=weather+in+toronto">weather in Toronto today</a>",  "<a target="_blank" href="https://www.bing.com/search?q=MSFT+stock+price">MSFT stock price</a>", "<a target="_blank" href="https://www.google.com/search?q=who+is+the+president+of+the+u">Who is the president of the US?</a>"</li>
        <li>Voice assistants reading instant answers, playing the wrong song on Spotify, turning on lights to flex in front of your guests</li>
        <p>It is an impressive feat of engineering, and has been great for answering simple questions and looking up facts. But what lies ahead if we dare imagine the future possibilities?</p>
        <h3>No search at all</h3>
        <p>To get the piece of information you are looking for, going to google.com can sometimes feel like a hassle. A few clicks each time, plus the context switching, can add up in terms of time costs. </p>
        <p>A more desirable experience is to have the knowledge delivered to you, to whatever app or workspace you are in. So that you can get the information and resume what you are doing.</p>
        <p>You already see patterns like this today, where there many entry points to the search engine:</p>
        <li>The url address bar in the browser doubles as a search box</li>
        <li>The browser "New tab" page has a search box</li>
        <li>Operating systems have a search box: Spotlight on Mac. Cortana on Windows. Same deal on mobile</li>
        <li>"Smart lookup" in Microsoft Office products</li>
        <p>One day, we shall see a reincarnation of Clippy. One day.</p>
        <p>The idea is that you want the information the moment you need it. We will find more and more ways to eliminate the friction that stands between you and what you are searching. </p>
        <p>This brings us to our next point - searching across apps.</p>
        <h3>Intent understanding. Information layer across apps &amp; contexts</h3>
        <p>Everyone has experienced some version of trying to find a document or message across emails, instant messages, cloud storage, notes etc.</p>
        <p>At the time of writing, this is still largely the case. Though there are a sea of big companies and startups alike working on solving this. It is a rather straightforward problem of integrating with various data sources and indexing the content. </p>
        <p>So it is probably safe to expect this to be less of an issue over time.</p>
        <p>We would always be looking for shortcuts to get what we are looking for, faster. This is a part of a much bigger trend of automation and connected apps, which is not limited to search. </p>
        <p>But search engines, as a general-purpose intent understanding machine, have a big role to play in this. We can expect to see more deep links and actions being accessible from a central interface. Alexa playing your favorite podcast is only the beginning. </p>
        <h3>Querying huge, generative language models</h3>
        <p>When you have a question, the most natural thing to do for most people is to ask someone. </p>
        <p>When Google came along and became a verb, the convention became to just ask the Googs. Sure there are still loads of questions it can't answer, that a real person can. But it's good enough. And it's instant.</p>
        <p>That could very well change in the near future. Generative language models that are trained a huge corpus of human-generated data on the internet can spit out answers that are often as good as a real human's response.</p>
        <p>At the time of writing, OpenAI recently released an API to its latest GPT-3 model. From all the anecdotes I have read, it seems it is pretty darn good! Generating a general purpose human-like response seems to good enough to be usable. </p>
        <p>It does seem too far for a language model to do what the search engine currently does, provided that it can:</p>
        <li>Map the generated output to a credible source. This would address the "black box" concerns that people have.</li>
        <li>Refresh content - "index" and "train" on fresh content. This is similar to how a human being would "stay updated" by reading the news and having conversations. </li>
        <p>When that happens, perhaps we wouldn't even call it a search engine. Would "oracle" seem more apt?</p>
        <h3>Indexing the unindexed knowledge</h3>
        <p>Both search engines and large language models rely on crawled data on the web. This means the scope of their knowledge and capabilities are limited to that dataset. </p>
        <p>In particular, the limitations include: </p>
        <li>The content must be published somewhere on the web, and is publicly available. This excludes the wealth private and individual knowledge.</li>
        <li>Data on the web is predominantly text. Which means scope is limited to whatever can be expressed in natural language. There is a tremendous amount of implicit or tacit knowledge that is hard to transfer verbally.</li>
        <li>Content tends to be shallow. There are countless domains of knowledge that are still not very legible and accessible, even for humans.</li>
        <p>Given the limitations, here are a few exciting areas of development:</p>
        <li>Indexing private knowledge, and integrating it with the collective public knowledge. </li>
        <li>Better UIs and formats, to help externalize and digitze complex ideas that are hard to convey in plain text.</li>
        <li>Represent and map out the deep knowledge in each field.</li>
        <p>That covers the knowledge side of things. But so much of the human condition isn't about just knowing...</p>
        <h3>Indexing perception, emotions, and experiences  </h3>
        <p>What we know accounts for just a small fraction of our conscious experience. There are myriad sensations that are hard to even find words for. This is especially true for experiences in altered states - for instance, from meditation, bodily movements, or consuming substances.</p>
        <p>But what if we can enlist the help of machines to map out and navigate how we feel? Can we index an emotional experience and construct a sequence of steps to recreate or revisit this moment?</p>
        <p>This sounds incredibly challenging. And by this point we are venturing quite far into the future. It would be fun though, to entertain a few possibilities. </p>
        <p>It helps to recognize that we already have reliable heuristics, in various domains of art, that roughly predict what our experiences will be like. Eating ice cream on a hot summer day is satisfying. Stomping backbeats make music easy to dance to. Symmetry is generally pleasing to the eye. Exercising makes you tired in the moment, and you feel good at night.</p>
        <p>These broad stroke heuristics are distilled from many instances of trial-and-error and observations. What happens if we more systematically gather data at scale and analyze it?</p>
        <p>We could in principle achieve fine-grained predictions and control of human experiences: in terms of precision in time, evoking the exact sensation desired, and personalization.</p>
        <p>In this setup, the role of human beings would be sensors and interpreters, while machines maintain and find patterns in the collective data.</p>
        <p>Perhaps soon enough, we would be able to guess the inner state of any person, based on known information about the sequence of inputs and stimuli in the current environment. And the machine can construct a model of the person's mind, as a time-series sequence of perceptual frames, with each frame being a digital representation (say, an embedding) of the sensation.</p>
        <p>This is a good place to wrap. I will elaborate and flesh out some of the themes above in future posts. </p>
        <p>What an exciting world we live in!</p>
          
      </div></div>]]>
            </description>
            <link>https://knowledgeartist.org/articles/future-of-search</link>
            <guid isPermaLink="false">hacker-news-small-sites-23882927</guid>
            <pubDate>Sat, 18 Jul 2020 17:17:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Instant access to your shell init files]]>
            </title>
            <description>
<![CDATA[
Score 34 | Comments 9 (<a href="https://news.ycombinator.com/item?id=23882784">thread link</a>) | @todsacerdoti
<br/>
July 18, 2020 | http://emacsredux.com/blog/2020/07/16/instant-access-to-your-shell-init-files/ | <a href="https://web.archive.org/web/*/http://emacsredux.com/blog/2020/07/16/instant-access-to-your-shell-init-files/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
        <p>A long time I presented a <a href="http://emacsredux.com/blog/2013/09/27/instant-access-to-your-shell-init-file/">simple hack</a> that allowed you to
quickly navigate to your shell‚Äôs user config file (e.g. <code>.bashrc</code> or
<code>.zshrc</code>). While the solution gets the job done it was pretty basic and
limited - most notably it‚Äôd ignore the fact that you typically have several
shell config files that are often built on top of each other - e.g.  <code>/etc/profile</code>,
<code>~/.bash_profile</code> and <code>~/.bashrc</code>. Fortunately the original
hack evolved rather nicely and today lives in the
<a href="https://github.com/bbatsov/crux">crux</a> library under the name
<code>crux-find-shell-init-file</code>.<sup id="fnref:1"><a href="#fn:1">1</a></sup></p>

<p>Provided you‚Äôve installed <code>crux</code> all you need to do is run that command
(e.g. with <code>M-x crux-find-shell-init-file</code>) and you‚Äôll get something like this
as the result:</p>

<p><img src="http://emacsredux.com/assets/images/instant_shell_config.png" alt="instant_shell_config.png"></p>

<p>Pretty neat, right? Even in its updated state the command is not complex at all:</p>

<div><div><pre><code><span>(</span><span>defun</span> <span>crux-find-shell-init-file</span> <span>()</span>
  <span>"Edit the shell init file in another window."</span>
  <span>(</span><span>interactive</span><span>)</span>
  <span>(</span><span>let*</span> <span>((</span><span>shell</span> <span>(</span><span>file-name-nondirectory</span> <span>(</span><span>getenv</span> <span>"SHELL"</span><span>)))</span>
         <span>(</span><span>shell-init-file</span> <span>(</span><span>cond</span>
                           <span>((</span><span>string=</span> <span>"zsh"</span> <span>shell</span><span>)</span> <span>crux-shell-zsh-init-files</span><span>)</span>
                           <span>((</span><span>string=</span> <span>"bash"</span> <span>shell</span><span>)</span> <span>crux-shell-bash-init-files</span><span>)</span>
                           <span>((</span><span>string=</span> <span>"tcsh"</span> <span>shell</span><span>)</span> <span>crux-shell-tcsh-init-files</span><span>)</span>
                           <span>((</span><span>string=</span> <span>"fish"</span> <span>shell</span><span>)</span> <span>crux-shell-fish-init-files</span><span>)</span>
                           <span>((</span><span>string-prefix-p</span> <span>"ksh"</span> <span>shell</span><span>)</span> <span>crux-shell-ksh-init-files</span><span>)</span>
                           <span>(</span><span>t</span> <span>(</span><span>error</span> <span>"Unknown shell"</span><span>))))</span>
         <span>(</span><span>candidates</span> <span>(</span><span>cl-remove-if-not</span> <span>'file-exists-p</span> <span>(</span><span>mapcar</span> <span>'substitute-in-file-name</span> <span>shell-init-file</span><span>))))</span>
    <span>(</span><span>if</span> <span>(</span><span>&gt;</span> <span>(</span><span>length</span> <span>candidates</span><span>)</span> <span>1</span><span>)</span>
        <span>(</span><span>find-file-other-window</span> <span>(</span><span>completing-read</span> <span>"Choose shell init file: "</span> <span>candidates</span><span>))</span>
      <span>(</span><span>find-file-other-window</span> <span>(</span><span>car</span> <span>candidates</span><span>)))))</span>
</code></pre></div></div>

<p>I guess one thing that we can improve down the road is adding an option to
display the shell config in the same window, but that‚Äôs a small thing.  The variables
like <code>crux-shell-bash-init-files</code> are simply lists of all potential files that
we should look for, that‚Äôs why I‚Äôve opted to omit them from the code listing.</p>

<p>I stand by my original suggestion to bind this useful command to <code>C-c S</code>:</p>

<div><div><pre><code><span>(</span><span>global-set-key</span> <span>(</span><span>kbd</span> <span>"C-c S"</span><span>)</span> <span>#'</span><span>crux-find-shell-init-file</span><span>)</span>
</code></pre></div></div>

<p>That‚Äôs all I have for you today! Meta-x forever!</p>



    </div></div>]]>
            </description>
            <link>http://emacsredux.com/blog/2020/07/16/instant-access-to-your-shell-init-files/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23882784</guid>
            <pubDate>Sat, 18 Jul 2020 16:58:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Team Improvement Techniques]]>
            </title>
            <description>
<![CDATA[
Score 45 | Comments 7 (<a href="https://news.ycombinator.com/item?id=23882701">thread link</a>) | @cauliflower99
<br/>
July 18, 2020 | http://www.dcaulfield.com/team-improvement-techniques/ | <a href="https://web.archive.org/web/*/http://www.dcaulfield.com/team-improvement-techniques/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-15632">
<small>
    <a href="http://www.dcaulfield.com/2020/07/06/">July 6, 2020</a></small>
    			<small>
				<a href="http://www.dcaulfield.com/author/admin/"></a></small>
		
<p>In the last couple of months since Ireland announced the lockdown, our team has been performing at a high pace and have become self-organised to a large extent. As a team lead, this has allowed me the privilege of stepping back to look at the broader picture of how our team works individually and, more importantly, together. Through some exercises, I have identified some  methods to gather improvement ideas that can be applied to any team. </p>



<p>Anyone who has been a part of a high functioning team understands that continuous improvement is not optional. In order to perform better and to keep performing, the team must identify their weaknesses and plan to strengthen or mitigate those weaknesses. These improvements remedy stress points in the team, technical debt, repetitive tasks and so forth. The mindset of continuous growth is one that must be worked on and nurtured over time. Your team is not a fine wine ‚Äì it will not improve if left alone in the corner. It will go sour.</p>



<p>It is one thing to be told to improve something. But very often, being told to improve something does not necessarily benefit you or your team.&nbsp;For example, if my manager comes to me and tells me my communication is poor and he wants bi-weekly emails from now on from my team‚Äôs status, all he has done is improve one of his problems, not mine. Improvements must come from within the team, and they must be gathered and executed on regularly. So the question is ‚Äì how do we gather improvements that are worthwhile and specific enough to solve our problems, not someone else‚Äôs?</p>



<h2>80/20 Analysis</h2>



<p>The Pareto Principle, most commonly known as the 80/20 rule, states that about 80% of the effects come from 20% of the causes. In layman‚Äôs terms, most of the good things your team is known for doing likely comes from a small subset of your total work.</p>



<p>In my case, my team is known for our expertise in the upgrading of our product. How much of our work is related to this each week? I‚Äôd estimate less than 10%.</p>



<p>S<em>ide note</em>: This wasn‚Äôt always the case. When we first formed as a team, we spent about 90% of our time on this work. </p>



<p>Over time our mindset of continuous improvement led us to automating away most of our problems. Here is how you can utilize the 80/20 rule to find pressure points to improve. I do this regularly by myself, and occasionally with my team.</p>



<h3>Create a chart.</h3>



<p>Drawing on a piece of paper or whiteboard produces far more ideas than typing on a screen. So create a chart!</p>



<h4>What is going poorly?</h4>



<p>Always start with the bad. What makes you stressed on a Monday? Why does your team constantly get called for customer escalations on a Sunday? What makes you cry at night? (If you‚Äôre crying at night you really need this). </p>



<p>Copy the following table onto a piece of paper and fill it out now with any ideas you have.</p>



<figure><table><thead><tr><th><strong>20% Activity</strong></th><th><strong>80% Pain</strong></th><th><strong>Action to Remedy</strong></th></tr></thead><tbody><tr><td>Monday morning team presentation to management.</td><td>Stressful if I‚Äôm not prepped.</td><td>Give a practice run to my team on Friday.</td></tr></tbody></table></figure>



<h4>What is going well?</h4>



<p>This is less effective than analyzing what is poor in the team. You should prioritise fixing the bad over improving the good. There is no point in improving what your team is already good at if there are still issues that stress them. </p>



<p>Ask yourself ‚Äì what are your team doing well? What do you need to keep doing well? What would happen if you improved these items?</p>



<p>Again, copy the following table onto a piece of paper and fill it out.</p>



<figure><table><thead><tr><th><strong>20% Activity</strong></th><th><strong>80% Reward</strong></th><th><strong>Improvement reward</strong></th><th><strong>Action to improve</strong></th></tr></thead><tbody><tr><td>Quick bug turnaround.</td><td>No weekend work.</td><td>Become the team with the lowest bug turnaround time.</td><td>Make incoming bugs a priority over stories.</td></tr></tbody></table></figure>



<p>You see the action columns? Take those, discuss with the team whether they agree on the actions required, and put them clearly for all to see everyday. You could create a task in your backlog that gets seen everyday on your sprint board, or print them and place them in your team‚Äôs area.</p>



<h2>Preventative Actions</h2>



<p>Identifying Preventative Actions is something that I have recently come across. Each team in my project go through this process every 3 weeks (every sprint). Here‚Äôs how it works. </p>



<p>A high priority bug has come into your team. You have spent all weekend pouring over it with your team, and finally came up with a solution late Sunday night, allowing your customer to continue their business as usual. Before you close the bug, there are a couple of things you need to consider and you <strong>must</strong> get answers to them. Otherwise, there will be another weekend in the future that will interrupt your team.</p>



<h3>Why did this bug occur?</h3>



<ul><li>We received a bad requirement specification from our business analysts.</li><li>We missed a corner case in our testware.</li><li>There were too many manual steps in the documentation which led to human error.</li><li>We missed a critical part of our study when planning the requirement.</li></ul>



<h3>What correction did you apply?</h3>



<ul><li>We built a patch fix and sent it to the customer.</li><li>We clarified with the customer that the particular use case reported is not supported yet.</li></ul>



<h3>How will you prevent this type of issue from occurring in the future?</h3>



<ul><li>We will call a 1 hour meeting with our business analyst each week to plan and clarify the feature request.</li><li>We will build a new pipeline that will test our customer‚Äôs use case each night.</li><li>We will automate steps x,y and z in our documentation so that human error is reduced.</li></ul>



<p>In my team‚Äôs case, for each bug we have the following grid which we fill out.</p>



<figure><table><thead><tr><th><strong>Root Cause</strong></th><th><strong>Correction Applied</strong></th><th><strong>Preventative Action</strong></th></tr></thead><tbody><tr><td>A test case to click on the ‚ÄòAbout‚Äô page in Firefox was missing from our GUI test suite.</td><td>Added this test case to the GUI suite.</td><td>Review GUI test cases as part of a feature sign-off in the future.</td></tr></tbody></table></figure>



<h2>Retrospective</h2>



<p>If your team uses the scrum framework for their work, then you will be very familiar with the retrospective. However, you do not need to work in a scrum environment to have a team retrospective. </p>



<p>Team retrospectives, if taken regularly, can be a valuable tool in the team‚Äôs work week and is an opportunity for the team to come together and discuss the good and bad things that have happened in the past few weeks. </p>



<p>A retro should be scheduled on a regular basis, and you as the team lead must lead the meeting. Make sure that everyone from the team is present for the retro, and ensure that everyone is taking part and answering the questions.</p>



<h3>What was good that you need to keep doing?</h3>



<ul><li>We closed out 100% of our stories for the sprint.</li><li>There was good communication with our management.</li><li>We trialed pair programming this sprint ‚Äì we have seen excellent results and should continue to do this.</li></ul>



<h3>What was bad?</h3>



<ul><li>We had poor communication within the team.<ul><li><em>Improvement</em>: We will trial pair programming for a sprint.</li></ul></li><li>The QA team raised tickets with very little detail resulting in a few days of delay in closing.<ul><li><em>Improvement</em>: Create a template that you would find helpful and send it to the QA team lead. Request that they copy this template and fill it out for all future tickets.</li></ul></li><li>We allowed untested code into the production software.<ul><li><em>Improvement</em>: Revise the +2 code review criteria with the team.</li></ul></li></ul>



<p>The most important part of the retro is to make sure that improvements or solutions are attached to each ‚Äòbad‚Äô item that is discussed.<br>At the end of the retro, prioritise the top one or two improvements, and take note of them for the upcoming sprint to execute.</p>



<h2>Improvement Backlog</h2>



<p>To become a top performing team, each individual must be comfortable with raising and discussing improvements as part of the team‚Äôs responsibilities. A team that does not have improvement ideas is a team that is not interested in improving which will lead to stagnation and a low performing team.</p>



<p>An improvement backlog is a list of ideas maintained and prioritised by the team. The list can be physical, like stickies on a whiteboard, or digital, like part of your jira backlog. </p>



<p>For example, my team created a Jira sprint and named it ‚ÄòImprovement Ideas‚Äô. We have list about 50 improvement ideas, most of which are one-liners and some of which have been discussed with details and acceptance criteria attached.</p>



<p>Each sprint planning, we prioritise this list and take the items we feel are most valuable to us. We have a couple of ad-hoc rules for this backlog.</p>



<ul><li>Any ideas that come up in meetings are inserted as a ‚Äòone-liners‚Äô in this backlog.</li><li>The list is regularly prioritised each sprint.</li><li>Each idea is explained by the team member who originally raised it.</li><li>We take 10-20% of our sprint capacity for improvements.</li></ul>



<p>Keeping this backlog up to date and prioritised will ensure that your team has consistent tasks to work on that primarily help the team.</p>



<h2>Stakeholder Feedback</h2>



<p>Working in a team can often be like working in a bubble. It is tempting to fall into confirmation bias. The most valuable improvements you can get for your product will come from your customers and stakeholders. </p>



<p>Leading the team does not only include leading the people on the team. If your team are known for building the wrong thing, or if their customers are not satisfied with their part of the product, then you as the team lead have ultimately failed.</p>



<p>When it comes to feedback, there is nothing more valuable than your own customers‚Äô feedback. Your customers drive your product backlog. If you are in a large company, you may not have direct contact with your customers. In big companies, customers are often separated by layers of business analysts and management. This is not ideal, but it is something you can work around. </p>



<p>All you need is a small list of stakeholders that consistently use your product area to gain feedback from them. Talk to your managers about the customer interface and who could give feedback. In my case, we were 6 months without any contact with stakeholders that could give us valuable feedback. Eventually we were able to make friends with two guys who act as an interface to one of our company‚Äôs top ‚Ä¶</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://www.dcaulfield.com/team-improvement-techniques/">http://www.dcaulfield.com/team-improvement-techniques/</a></em></p>]]>
            </description>
            <link>http://www.dcaulfield.com/team-improvement-techniques/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23882701</guid>
            <pubDate>Sat, 18 Jul 2020 16:50:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Redo: A recursive, general-purpose build system]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 2 (<a href="https://news.ycombinator.com/item?id=23882630">thread link</a>) | @jnxx
<br/>
July 18, 2020 | https://redo.readthedocs.io/en/latest/ | <a href="https://web.archive.org/web/*/https://redo.readthedocs.io/en/latest/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="main">
            <div>
              
                
<p><code>redo</code> is a competitor to the long-lived, but sadly imperfect, <code>make</code>
program.  Unlike other such competitors, redo captures the essential
simplicity and flexibility of make, while avoiding its flaws.  It manages to
do this while being simultaneously simpler than make, more flexible than
make, and more powerful than make, and without sacrificing performance - a
rare combination of features.</p>
<p>The original design for redo comes from Daniel J. Bernstein (creator of
qmail and djbdns, among many other useful things).  He posted some
terse notes on his web site at one point (there is no date) with the
unassuming title, "<a href="http://cr.yp.to/redo.html">Rebuilding target files when source files have
changed</a>." Those notes are enough information to
understand how the system is supposed to work; unfortunately there's no code
to go with it.  I wrote this implementation of redo from scratch, based on
that design.</p>
<p>After I found out about djb redo, I searched the Internet for any sign that
other people had discovered what I had: a hidden, unimplemented gem of
brilliant code design.  I found only one interesting link at the time: Alan
Grosskurth, whose <a href="http://grosskurth.ca/papers/mmath-thesis.pdf">Master's thesis at the University of
Waterloo</a> was about top-down
software rebuilding, that is, djb redo.  He wrote his own (admittedly slow)
implementation in about 250 lines of shell script, which gives an idea for
how straightforward the system is.  Since then, several other
implementations have appeared (see list below).</p>
<p>My implementation of redo is called <code>redo</code> for the same reason that there
are 75 different versions of <code>make</code> that are all called <code>make</code>.  It's somehow
easier that way.</p>
<p>I also provide an extremely minimal pure-POSIX-sh implementation, called
<code>do</code>, in the <code>minimal/</code> directory of this repository.</p>
<p>(Want to discuss redo?  Join <a href="https://redo.readthedocs.io/en/latest/Contributing/#mailing-list">our mailing list</a>.)</p>

<p>The theory behind redo sounds too good to be true: it can do everything
<code>make</code> can do, but the implementation is vastly simpler, the syntax is
cleaner, and you have even more flexibility without resorting to ugly hacks. 
Also, you get all the speed of non-recursive <code>make</code> (only check dependencies
once per run) combined with all the cleanliness of recursive <code>make</code> (you
don't have code from one module stomping on code from another module).</p>
<p>(Disclaimer: my current implementation is not as fast as <code>make</code> for some
things, because it's written in python.  Eventually I'll rewrite it an C and
it'll be very, very fast.)</p>
<p>The easiest way to show it is to jump into an example.  Here's one for
compiling a C++ program.</p>
<p>Create a file called default.o.do:</p>
<pre><code>redo-ifchange $2.c
gcc -MD -MF $2.d -c -o $3 $2.c
read DEPS &lt;$2.d
redo-ifchange ${DEPS#*:}
</code></pre>
<p>Create a file called myprog.do:</p>
<pre><code>DEPS="a.o b.o"
redo-ifchange $DEPS
gcc -o $3 $DEPS
</code></pre>
<p>Of course, you'll also have to create <code>a.c</code> and <code>b.c</code>, the C language
source files that you want to build to create your application.</p>
<p>In a.c:</p>
<pre><code>#include &lt;stdio.h&gt;
#include "b.h"

int main() { printf(bstr); }
</code></pre>
<p>In b.h:</p>
<pre><code>extern char *bstr;
</code></pre>
<p>In b.c:</p>
<pre><code>char *bstr = "hello, world!\n";
</code></pre>
<p>Now you simply run:</p>
<pre><code>$ redo myprog
</code></pre>
<p>And it says:</p>
<pre><code>redo  myprog
redo    a.o
redo    b.o
</code></pre>
<p>Now try this:</p>
<pre><code>$ touch b.h
$ redo myprog
</code></pre>
<p>Sure enough, it says:</p>
<pre><code>redo  myprog
redo    a.o
</code></pre>
<p>Did you catch the shell incantation in <code>default.o.do</code> where it generates
the autodependencies?  The filename <code>default.o.do</code> means "run this script to
generate a .o file unless there's a more specific whatever.o.do script that
applies."</p>
<p>The key thing to understand about redo is that declaring a dependency is just
another shell command.  The <code>redo-ifchange</code> command means, "build each of my
arguments.  If any of them or their dependencies ever change, then I need to
run the <em>current script</em> over again."</p>
<p>Dependencies are tracked in a persistent <code>.redo</code> database so that redo can
check them later.  If a file needs to be rebuilt, it re-executes the
<code>whatever.do</code> script and regenerates the dependencies.  If a file doesn't
need to be rebuilt, redo figures that out just using its persistent
<code>.redo</code> database, without re-running the script.  And it can do that check
just once right at the start of your project build, which is really fast.</p>
<p>Best of all, as you can see in <code>default.o.do</code>, you can declare a dependency
<em>after</em> building the program.  In C, you get your best dependency
information by trying to actually build, since that's how you find out which
headers you need.  redo is based on this simple insight: you don't
actually care what the dependencies are <em>before</em> you build the target.  If
the target doesn't exist, you obviously need to build it.</p>
<p>Once you're building it anyway, the build script itself can calculate the
dependency information however it wants; unlike in <code>make</code>, you don't need a
special dependency syntax at all.  You can even declare some of your
dependencies after building, which makes C-style autodependencies much
simpler.</p>
<p>redo therefore is a unique combination of imperative and declarative
programming.  The initial build is almost entirely imperative (running a
series of scripts).  As part of that, the scripts declare dependencies a few
at a time, and redo assembles those into a larger data structure.  Then, in
the future, it uses that pre-declared data structure to decide what work
needs to be redone.</p>
<p>(GNU make supports putting some of your dependencies in include files, and
auto-reloading those include files if they change.  But this is very
confusing - the program flow through a Makefile is hard to trace already,
and even harder when it restarts from the beginning because an include file
changes at runtime.  With redo, you can just read each build script from top
to bottom.  A <code>redo-ifchange</code> call is like calling a function, which you can
also read from top to bottom.)</p>

<p>Some larger proprietary projects are using it, but unfortunately they can't
easily be linked from this document.  Here are a few open source examples:</p>
<ul>
<li>
<p><a href="https://github.com/linleyh/liberation-circuit">Liberation Circuit</a> is a
  straightforward example of a C++ binary (a game) compiled with redo.</p>
</li>
<li>
<p><a href="https://github.com/apenwarr/wvstreams">WvStreams</a> uses a more complex
  setup producing several binaries, libraries, and scripts.  It shows how to
  produce output files in a different directory than the source files.</p>
</li>
<li>
<p><a href="https://github.com/apenwarr/wvbuild">WvBuild</a> can cross-compile several
  dependencies, like openssl and zlib, and then builds WvStreams using those
  same libraries.  It's a good example of redo/make interop and complex
  dependencies.</p>
</li>
<li>
<p>There's an experimental <a href="https://github.com/apenwarr/buildroot/tree/redo">variant of
  Buildroot</a> that uses redo
  in order to clean up its dependency logic.</p>
</li>
<li>
<p>You can find some curated tutorial examples in the
  <a href="https://redo.readthedocs.io/en/latest/cookbook/hello/">cookbook</a>, such as <a href="https://redo.readthedocs.io/en/latest/cookbook/defaults/">git variable
  substitution</a> and <a href="https://redo.readthedocs.io/en/latest/cookbook/latex/">text processing with
  LaTeX</a> (including plot generation with R and ggplot2).</p>
</li>
<li>
<p>A <a href="https://github.com/search?p=9&amp;q=path%3A%2F+extension%3Ado+filename%3A%2Fall.do&amp;type=Code">github search for all.do</a>
  shows an ever-growing number of projects using redo.</p>
</li>
</ul>
<p>If you switch your program's build process to use redo, please let us know and
we can link to it here for some free publicity.</p>
<p>(Please don't use the integration testing code in the redo project's <code>t/</code>
directory as serious examples of how to use redo.  Many of the tests are
doing things in intentionally psychotic ways in order to stress redo's code
and find bugs.  On the other hand, if you're building your own
reimplementation of redo, using our test suite is a great idea.)</p>

<p>djb never released his version, so other people have implemented their own
variants based on his <a href="http://cr.yp.to/redo.html">published specification</a>.</p>
<p>This version, sometimes called apenwarr/redo, is probably the most advanced
one, including support for parallel builds,
<a href="https://apenwarr.ca/log/20181113">resilient timestamps</a> and checksums,
<a href="https://apenwarr.ca/log/20181106">build log linearization</a>, and
helpful debugging features.  It's currently written in python for easier
experimentation, but the plan is to eventually migrate it to plain C.  (Some
people like to call this version "python-redo", but I don't like that name. 
We shouldn't have to rename it when we later transliterate the code to C.)</p>
<p>Here are some other redo variants (thanks to Nils Dagsson Moskopp for
collecting many of these links):</p>
<ul>
<li>
<p>Alan Grosskurth's <a href="http://grosskurth.ca/papers/mmath-thesis.pdf">redo thesis</a>
  and related sh implementation.  (Arguably, this paper is the one that got
  all the rest of us started.)</p>
</li>
<li>
<p>Nils Dagsson Moskopp's <a href="https://web.archive.org/web/20181106195145/http://news.dieweltistgarnichtso.net/bin/redo-sh.html">redo-sh</a>
  is a completely self-sufficient sh-based implementation.</p>
</li>
<li>
<p>apenwarr's <a href="https://github.com/apenwarr/redo/blob/master/minimal/do">minimal/do</a>
  is included with this copy of redo.  It's also sh-based, but intended to
  be simple and failsafe, so it doesn't understand how to "redo" targets more
  than once.</p>
</li>
<li>
<p>Christian Neukirchen's <a href="https://github.com/chneukirchen/redo-c">redo-c</a>, a
  C implementation.</p>
</li>
<li>
<p>Jonathan de Boyne Pollard's <a href="http://jdebp.eu./Softwares/redo/grosskurth-redo.html">fork of Alan Grosskurth's redo</a>
  (another sh-based implementation).</p>
</li>
<li>
<p>Jonathan de Boyne Pollard's <a href="http://jdebp.eu./Softwares/redo/">redo</a>
  rewritten in C++</p>
</li>
<li>
<p>Gyepi Sam's <a href="https://github.com/gyepisam/redux">redux</a> in Go</p>
</li>
<li>
<p>jekor's <a href="https://github.com/jekor/redo">redo</a> in Haskell</p>
</li>
<li>
<p>Shanti Bouchez-Mongard√© (mildred)'s <a href="https://github.com/mildred/redo">fork of apenwarr's redo</a>
  in python</p>
</li>
<li>
<p>Tharre's <a href="https://github.com/Tharre/redo">redo</a> in C</p>
</li>
<li>
<p>catenate's <a href="https://github.com/catenate/credo">credo</a>, a (very
  rearchitected) variant written for the Inferno Shell.</p>
</li>
</ul>
<p>The original redo design is so simple and elegant that many individuals
have been
inspired to (and able to) write their own version of it.  In the honoured
tradition of Unix's <code>make</code>, they (almost) all just use the same name,
<code>redo</code>.  Unfortunately, many of these
implementations are unmaintained, slightly incompatible with the "standard"
redo semantics, and/or have few or no automated tests.</p>
<p>At the time of this writing, none of them except apenwarr/redo (ie.  this
project) correctly support parallel builds (<code>redo -j</code>) or log linearization
(<code>redo-log</code>).  For large projects, parallel builds are usually considered
essential.</p>
<p>The <a href="https://github.com/apenwarr/redo/tree/master/t">automated tests</a> in
this version of redo are almost, but not quite, appropriate for testing any
redo implementation.  If you really must write a new version of redo, we
invite you to thoroughly test it against the existing test suite to ensure
compatibility.  You can also steal our tests (with attribution, of course)
and include them in your own source package.  We'd also love it it you
contribute more automated tests when you find a bug, or send us patches if
you find a test which is accidentally incompatible (as opposed to finding a
real bug) with other redo implementations.</p>
              
            </div>
          </div></div>]]>
            </description>
            <link>https://redo.readthedocs.io/en/latest/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23882630</guid>
            <pubDate>Sat, 18 Jul 2020 16:43:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[It‚Äôs Time to Reinvent Democracy]]>
            </title>
            <description>
<![CDATA[
Score 18 | Comments 3 (<a href="https://news.ycombinator.com/item?id=23882048">thread link</a>) | @whack
<br/>
July 18, 2020 | https://outlookzen.com/2013/11/06/its-time-to-reinvent-democracy/ | <a href="https://web.archive.org/web/*/https://outlookzen.com/2013/11/06/its-time-to-reinvent-democracy/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<div><figure><a href="https://www.washingtonpost.com/news/theworldpost/wp/2018/03/23/direct-democracy/" target="_blank" rel="noreferrer noopener"><img data-attachment-id="801" data-permalink="https://outlookzen.com/mob-rule/" data-orig-file="https://outlookzen.files.wordpress.com/2019/05/mob-rule.png" data-orig-size="1142,632" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="mob-rule" data-image-description="" data-medium-file="https://outlookzen.files.wordpress.com/2019/05/mob-rule.png?w=300" data-large-file="https://outlookzen.files.wordpress.com/2019/05/mob-rule.png?w=1024" src="https://outlookzen.files.wordpress.com/2019/05/mob-rule.png" alt=""></a></figure></div>


<p><em>‚ÄúDemocracy is two wolves and a lamb voting on what to have for lunch‚Äù&nbsp;<br></em>&nbsp; ‚Äì Ben Franklin</p>
<p><em>‚ÄúDemocracy never lasts long. It soon wastes, exhausts, and murders itself. There never was a democracy yet that did not commit suicide.‚Äù</em>&nbsp;<br>&nbsp; ‚Äì John Adams</p>
<p>Today, I‚Äôll be making the same argument that the founding fathers did; that our conception of democracy is fundamentally flawed and it‚Äôs time we overhauled our political system. As we look around the world, at the gridlock in Washington, the failings of the Arab Spring, and the mixed track record of democracy in the developing world, it‚Äôs easy to see the problems inherent in democracy.</p>
<p>But I also intend for this discussion to be constructive, with prescriptions for how to fix the problems that currently exist. We‚Äôll be doing so, by critically examining 3 very different forms of crowdsourcing, which have all proved to be extremely successful. Even though democracy is also a form of crowdsourcing, we can then see that the successful ones all share certain common characteristics, which are completely antithetical to our conception of democracy.</p>
<p><strong><em><span>Differential Voting Power</span></em></strong></p>
<p dir="ltr">Our first example is a company that rose from nowhere to change our world and the way we find information; Google. A brief history: There were numerous companies trying to succeed in the Search Engine marketplace. Lycos, AskJeeves, AltaVista‚Ä¶ the list goes on. And yet, sometime in the early 2000s, they all just disappeared and <em>everyone</em> switched to Google. Their search engine was so great, that it simply blew the competition away. When you look into how they implemented this groundbreaking search algorithm solution, one of the main pillars was the PageRank algorithm.</p>
<p>I could write an entire article about the PageRank algorithm but to put it simply, it brought democracy to the internet. It gave every single website the ability to vote on any other website, through the act of linking to it. And Google for its part, crawls through the web everyday, tallies up all the ballots, and posts the winners near the top of their search results. It is in many ways very similar to democracy‚Ä¶ with one very important twist. Every website gets a <em>different number of votes</em> based on how credible it is.</p>
<p>To give an example, suppose the Nobel Prize winner Eugene Fama decides tomorrow to start an economics blog. It‚Äôs so insightful &amp; interesting, that NYTimes decides to link to it. Suppose that at the same time, Joe Blow, who took a community college class on Economics, also starts an economics blog‚Ä¶ and his brother-in-law who works at the Street Sheet links to it as well. We now have 2 blogs, on the same topic, carrying the same keywords, and each having a link from a newspaper. A purely egalitarian search-engine would give them equal visibility. But Google‚Äôs knows that NYTimes is a lot more credible than Street Sheet. Hence, it gives NYTimes <em>thousands of ballots more</em> than Street Sheet, and this in turn gives Eugene Fama‚Äôs blog a huge well-deserved boost over Joe Blow‚Äôs.</p>
<p>Google‚Äôs search engine works so well, precisely because it relies on <em>credibility-based differential voting power</em>. Intuitively, it makes perfect sense. In our own lives, we know that some sources of information are much more valuable than others. We give much more weight to the advice of some, and ignore those of others. And yet, this notion is simply heretical in our democracy today. The idea of one-person-one-vote is so ingrained in our political system, that no one even dares to suggest an alternative to it. And yet, when you look at successful forms of crowdsourcing, they are all based on <em>highly differential voting power</em>. One only needs to compare the politicians we have in Congress to the quality of the search results returned by Google, in order to see which works out better.</p>
<p><strong><em><span>Barriers to Contribution</span></em></strong></p>
<p dir="ltr">We don‚Äôt have to go very far to find our next great crowdsourcing example: the world‚Äôs greatest store of information, Wikipedia. Like Google, and unlike its predecessor Encyclopedia Britannica, Wikipedia too is built around the idea of crowdsourcing. With less than 100 employees, Wikipedia simply creates a platform on which its users can make contributions. Each user contribution may be incremental, but together, they represent the greatest &amp; most easily accessible store of human knowledge.</p>
<p>Given that Wikipedia relies entirely on user contributions, one might think that users would be given the red carpet &amp; encouraged to contribute in any way possible. In reality though, user contributions (ie, edits), are often ruthlessly re-edited or discarded completely. Anyone can give their 2 cents by hitting the edit button &amp; typing away, but getting it to actually stay there for more than a day is not easy. In order to make any lasting contribution, users are required to <em>research</em> the topic and back up their opinions with <em>supporting evidence</em>. Poorly expressed opinions are simply discarded without even a trace.</p>
<p>Having such <em>barriers to contribution</em> does dissuade some well-informed people from making valuable contributions. However, it also filters out an even greater number of ill-informed people who would otherwise be injecting a great deal of noise. A well-informed person who cares enough about the topic to research it is less likely to be dissuaded by such hurdles, compared to a layperson who simply chances upon the discussion &amp; feels the urge to give his 2 cents. By filtering out noise, such <em>barriers to contribution</em> keep the signal-to-noise ratio high.</p>
<p>Contrast this with our democracy, where there is universal agreement that there should never be a barrier to contribution. Our entire system is designed to make voting as easy &amp; convenient as possible. When Joe Blow walks into the voting booth and is asked to contribute to democracy, he can vote for absolutely anything he wants in a matter of minutes, without ever having to justify his choices with research, evidence or logic. The time investment required to vote is insignificant compared to its profound &amp; long-lasting effects. With <em>barriers to contribution</em> kept intentionally low, it‚Äôs hardly surprising that our political system feels much more like a noisy bar than a well oiled machine.</p>
<p><strong><em><span>Specialization of Contribution</span></em></strong></p>
<p dir="ltr">As a change of pace, I‚Äòd like for us to consider another great crowdsourcing example that is centuries old. One that we partake in every single day: The market-based economy. How many of us know how to grow crops? Sew clothes? Build a house? Design a computer chip? Perform open-heart surgery? There isn‚Äôt a person alive who can answer yes to all of the above. And yet, we are able to enjoy the fruits of all of these &amp; accomplish some truly miraculous feats as a society. This is only possible through <em>division of labor</em>. At a young age, each of us decides upon a career that we would like to pursue. We then spend a decade or more <em>specializing</em> in that one field. We develop great expertise in an extremely niche field, and then spend the next few decades <em>contributing</em> to society, through that one <em>niche field</em>.</p>
<p>More importantly, we also stay away from the other 99% of fields that we know little about. Engineers don‚Äôt go around telling doctors how to do their jobs, and doctors don‚Äôt go around offering their opinions on good accounting practices. The market based economy works so miraculously, precisely because each of us contributes to society in one very <em>specialized</em> area, and we allow others to do so as well without getting in their way. Can you imagine how well a BMW would run if it was designed by popular vote? And yet, this is the reality of our democracy today. When we go into the voting booth &amp; are asked to choose between Obama &amp; Romney, we‚Äôre expected to evaluate both candidates‚Äô economic policies, national security policies, health care proposals, and numerous other credentials in fields that we know next to nothing about.</p>
<p>When we consider the vast breadth of human knowledge, we are all idiot savants. The market-economy has worked so well by funneling our efforts into those fields where we‚Äôre <em>savants</em>. Democracy on the other hand, forces us to make decisions precisely in the fields where we‚Äôre <em>idiots</em>.</p>
<hr>
<p><em>Differential voting power; Barriers to contribution; Specialization of contribution</em>. All 3 can be found in each of the examples given above. If we look at other forms of successful crowdsourcing, such as financial markets &amp; scientific research, it‚Äôs no coincidence that these same characteristics show up there as well. It‚Äôs time we had a political system that takes a page out of these great success stories.</p>
<p>Let me end this article, ironically enough, by giving plaudits to democracy. It was truly a brilliant &amp; remarkably insightful idea for the 18th century. It gave birth to the notion of decentralization of power. It created a system of government that derives its power from the people. It leveled the playing field, giving everyone equal treatment &amp; equal opportunity. It gave birth to a political system that was open &amp; accessible to all. It brought crowdsourcing to the field of politics. These were all brilliant ideas for their time, and any new political system we implement should surely hold on to these principles.</p>
<p>However, we have come a long way in the past 300 years, and the cracks in the foundation of democracy are starting to show. Certain aspects that are considered fundamental to democracy, have been shown to severely detract from it. It‚Äôs time we overhauled our political system and boldly stepped into the new millenium.</p>


<hr>



<p><em>Ways to Fix Democracy:</em><br><a rel="noreferrer noopener" href="https://outlookzen.wordpress.com/2014/01/21/democracy-by-jury/" target="_blank"><em>A suggestion to reform democracy, using the Jury system as a model</em></a><br><a rel="noreferrer noopener" href="https://outlookzen.wordpress.com/2014/06/29/reinventing-democracy-the-google-way/" target="_blank"><em>Another suggestion to reform democracy, using Google‚Äôs search engine</em></a></p>



<hr>



<p><em>Related links:</em><br><a href="https://www.politico.com/magazine/story/2019/09/08/shawn-rosenberg-democracy-228045" target="_blank" rel="noreferrer noopener" aria-label="Leading political psychologist arguing that our brains are not equipped for democracy (opens in a new tab)"><em>Leading political psychologist arguing that our brains are not equipped for democracy</em></a><em><br></em><a rel="noreferrer noopener" href="https://outlookzen.wordpress.com/2013/11/29/direct-vs-representative-democracy/" target="_blank"><em>The crucial difference between direct democracy &amp; representative democracy</em></a><em><br></em><a rel="noreferrer noopener" href="http://nyti.ms/JrTPjC" target="_blank"><em>NYTimes: A Work Still in Progress</em></a><em><br></em><a rel="noreferrer noopener" href="http://wapo.st/1mi3YeD" target="_blank"><em>60% of Americans have no idea which party controls Congress</em></a><em><br></em><a rel="noreferrer noopener" href="http://www.nytimes.com/2016/08/26/opinion/the-dumbed-down-democracy.html?_r=0" target="_blank"><em>NYTimes: Democracy dumbed down</em></a><em><br></em><a rel="noreferrer noopener" href="https://www.nytimes.com/2017/06/29/opinion/sunday/the-problem-with-participatory-democracy-is-the-participants.html?_r=0" target="_blank"><em>NYTimes: The problem with ‚Ä¶</em></a></p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://outlookzen.com/2013/11/06/its-time-to-reinvent-democracy/">https://outlookzen.com/2013/11/06/its-time-to-reinvent-democracy/</a></em></p>]]>
            </description>
            <link>https://outlookzen.com/2013/11/06/its-time-to-reinvent-democracy/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23882048</guid>
            <pubDate>Sat, 18 Jul 2020 15:32:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Booting to 'Hello Rust' on x86_64]]>
            </title>
            <description>
<![CDATA[
Score 237 | Comments 35 (<a href="https://news.ycombinator.com/item?id=23881584">thread link</a>) | @micouay
<br/>
July 18, 2020 | https://micouy.github.io/posts/low-level-pt-1/ | <a href="https://web.archive.org/web/*/https://micouy.github.io/posts/low-level-pt-1/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">
<article>
    
<p>This post is about how I booted to bare metal Rust on x86_64.
My goal is to describe my learning path and hopefully get
you interested in things I talk about. I‚Äôll be very happy if you
find this content useful. Note that I‚Äôm a begginer and I may be wrong
about many things. If you want to learn more, I‚Äôll put links to many resources.
You can find all the code in my <a href="https://github.com/micouy/gniazdo-os">repo</a>.</p>

<p>The inspiration for this project came from many sources. I think I first
discovered <a href="https://github.com/cfenollosa/os-tutorial">cfenollosa/os-tutorial</a>.
I also read a few chapters from <a href="https://www.cs.bham.ac.uk/~exr/lectures/opsys/10_11/lectures/os-dev.pdf">Writing a Simple Operating System - from Scratch</a>.
It‚Äôs a good introduction to OS dev and related topics. First part
of the tutorial is about bootloaders. To get a grasp of what it‚Äôs
all about, I just read every part of the tutorial and tried to write the Assembly
code by myself.</p>
<p>Here‚Äôs a brief explanation of the boot process and what you have to do
at each stage. First the CPU thinks it‚Äôs an Intel 8086 model form 1970s IIRC. This stage is
called Real Mode. You have ~1MiB of memory and 16-bit <a href="https://en.wikipedia.org/wiki/Processor_register">registers</a>
at your disposition. In RM you are very limited. However, at this stage
you can use BIOS routines (or interrupts). They‚Äôre like an external library you can use to
print a character on the screen, read from and write to hard disk etc.
You can obviously do these things in other modes but you have to implement it yourself
or do some hacking to use the interrupts.</p>
<p>When you‚Äôre done with RM, you can switch to Protected Mode. In PM the address space
is extended (you can access more memory), 32-bit registers are enabled
and addressing works a bit different. To switch to PM,
you have to set up a <a href="http://www.osdever.net/tutorials/view/the-world-of-protected-mode">Descriptor Table</a>
which is a piece of data that tells the CPU
how to interpret addresses, and describes the characteristics of particular
parts of the memory.</p>
<hr>
<p><strong>Note</strong>: At first I thought that in PM address like <code>ds:ebx</code>
works just like in RM - <code>ds</code> is the segment (in ‚Äòdata‚Äô memory if you want
to read/write to it or in ‚Äòcode‚Äô memory if you jump to it) and <code>ebx</code>
is the offset in this segment. In reality <code>ds</code> acts like an index
into the descriptor table. Then, the selected descriptor is used
to translate the offset from the segment base (stored in <code>ebx</code>) to a physical address.
You can read more about addressing in PM <a href="http://ece-research.unm.edu/jimp/310/slides/micro_arch2.html">here</a>.
Also check out other stuff on <a href="http://ece-research.unm.edu/jimp/">their website</a>.</p>
<hr>

<p>The bootloader is a very short piece of code - it‚Äôs just 512 bytes long.
I once even ran out of space and had to remove some strings and unnecessary
code. The actual purpose of the bootloader is to load and run some other code.
The book suggested booting to PM and jumping to a 32-bit kernel written in C.
I didn‚Äôt really like programming in C and at this point I lost my motivation.</p>
<p>Another time I learned about Philipp Oppermann‚Äôs <a href="https://os.phil-opp.com/">blog</a>
on OS dev in Rust. I highly recommend it. I got really excited but,
unfortunately for me, Oppermann uses <a href="https://www.gnu.org/software/grub/">GRUB</a>
(a kind of bootloader) so I decided to come back to the tutorial after
finishing my own bootloader. At that time booting to a program written in language
other than Assembly and compiled to a separate file was way beyond my capabilities
so I left the project for a while.</p>
<p>A couple weeks ago I got motivated enough to try to boot to a Rust program.
My plan was to switch to Long Mode. Then I could either run a 64-bit kernel
or load a second stage bootloader. Second stage bootloader is not limited
to one sector (can be more than 512 bytes long) and can be 32-bit
or even 64-bit so it has access to a larger address space and can load
arbitrarily large files from disk to memory (as long as you implement it).
Its purpose is to load larger kernels.</p>
<p>The first step was loading my program from hard disk to memory.
I took a naive approach. I compiled the bootloader and my program.
I concatenated both binaries together, one right after the other, to form one file, like this:</p>
<div><pre><code data-lang="bash">cat bootloader.bin hello_rust.bin &gt; img
</code></pre></div><p>I didn‚Äôt care if I could actually execute Rust code, I just wanted
to test if I can load it. I added necessary code to my bootloader
and ran the emulator. Unfortunately QEMU just kept restarting.
I‚Äôm not sure what went wrong but it didn‚Äôt matter since it
was a stupid way to do it. I could just test loading data from the disk on
a much simpler bootloader. I first tried to write it myself but after a while
I just grabbed some code from Stack Overflow and added a simple error message in case
the BIOS routine failed. After a couple of tries I finally managed to create
a two-stage bootloader in a single Assembly program. It worked something like this:</p>
<div><pre><code data-lang="nasm"><span>org</span> <span>0x7c00</span>
first_stage:
    <span>; load second stage.</span>

    <span>; `dl` register specifies which disk to load</span>
    <span>; data from. it is set by the CPU to the same device</span>
    <span>; the bootloader was loaded from.</span>

    <span>; set `es` to 0x7e0 and `bx` to 0x0.</span>
    
    <span>; the routine will load data to `(es &lt;&lt; 4) | bx`</span>
    <span>; or 0x7e00.</span>
    <span>mov</span> ax, <span>0x7e0</span>
    <span>mov</span> es, ax
    <span>mov</span> bx, <span>0x0</span>

    <span>mov</span> al, <span>0x1</span> <span>; # of sectors to read.</span>
    
    <span>push</span> ax <span>; store `al` for later.</span>

    <span>; specify where the data is stored on the disk.</span>
    <span>mov</span> ch, <span>0x0</span> <span>; cylinder.</span>
    <span>mov</span> dh, <span>0x0</span> <span>; head.</span>
    <span>mov</span> cl, <span>0x2</span> <span>; sector right after bootloader.</span>

    <span>; `int 0x13` with `ah` set to 0x2</span>
    <span>; loads data from disk to memory.</span>
    <span>mov</span> ah, <span>0x2</span>
    <span>int</span> <span>0x13</span>

    <span>pop</span> bx <span>; restore `al` to `bl`.</span>

    <span>; check whether the number of sectors read is correct.</span>
    <span>cmp</span> al, bl
    <span>jne</span> error
       
    <span>jmp</span> <span>0x7e00</span> <span>; jump to second stage.</span>

error:
    <span>; print error message, then halt.</span>
    <span>jmp</span> <span>$</span>

<span>; fill the rest of the first sector with zeros.</span>
<span>; it's 510 and not 512 because the last two bytes</span>
<span>; are 0xaa and 0x55 - the 'magic' number.</span>
<span>times</span> <span>510</span><span>-</span>(<span>$</span><span>-</span><span>$$</span>) db <span>0</span>
<span>dw</span> <span>0xaa55</span>

second_stage:
    <span>; do something, then halt.</span>
    <span>jmp</span> <span>$</span>

<span>; padding to fill the rest of the second sector with zeros.</span>
<span>times</span> <span>1024</span><span>-</span>(<span>$</span><span>-</span><span>$$</span>) db <span>0</span>
</code></pre></div><p>This way I didn‚Äôt have to link multiple files and NASM managed the padding of sectors
for me. The code correctly compiled to a single file which was exactly 1024 bytes long -
two entire sectors.</p>
<p>You can also use <code>align 512</code> instead of <code>times 1024-($-$$)</code> to allow
your code to be arbitrarily large. This could be useful if you wanted to program
the second stage of your bootloader in Assembly.</p>
<hr>
<p><strong>Note</strong>: Don‚Äôt assume that the registers are initialized with any particular
value. It took me half an hour or so to realize that I didn‚Äôt set some register
correctly in such a simple piece of code. IIRC there are only two things you can
be sure of - that the bootloader will be loaded to 0x7c00 and that the <code>dl</code> register
points to the same device the bootloader has been loaded from.</p>
<hr>

<p>After I managed to load the second sector I wanted to replace the Assembly code
with Rust code. To check whether I could execute it I needed to switch to Long Mode.
That‚Äôs because I had some problems with compiling Rust code to 32-bit
and I ended up using the <code>x86_64-unknown-none</code> target triple, just like
in Oppermann‚Äôs tutorial.</p>
<p>Long Mode adds a new memory model (paging), and enables the use
of 64-bit instructions and registers. Switching to LM requires setting up paging.
I identity-mapped the first 2 MiB of memory which is enough for now. I think it
can be modified later by my Rust program. I read the following guides on paging:</p>
<ul>
<li><a href="https://wiki.osdev.org/Setting_Up_Long_Mode#Setting_up_the_Paging">https://wiki.osdev.org/Setting_Up_Long_Mode#Setting_up_the_Paging</a></li>
<li><a href="https://wiki.osdev.org/Paging#Enabling">https://wiki.osdev.org/Paging#Enabling</a></li>
<li><a href="https://intermezzos.github.io/book/first-edition/transitioning-to-long-mode.html">https://intermezzos.github.io/book/first-edition/transitioning-to-long-mode.html</a></li>
<li><a href="http://ece-research.unm.edu/jimp/310/slides/micro_arch3.html">http://ece-research.unm.edu/jimp/310/slides/micro_arch3.html</a></li>
<li><a href="https://os.phil-opp.com/entering-longmode/">https://os.phil-opp.com/entering-longmode/</a></li>
</ul>
<p>There are also other things you have to do before switching to LM
like checking <code>cpuid</code> instruction support and the highest instruction
op code available.</p>

<p>I figured that to execute Rust code I needed to glue it with
the bootloader to create a single binary. In this step I encountered
a few difficult problems:</p>
<ul>
<li>To work correctly, the bootloader has to be stored in the first 512 bytes of the file.
The last two bytes of this sector have to be 0xaa55.</li>
<li>My Rust code should also be aligned with the sectors and fill up the last sector
entirely. Of course I would fill it with some garbage values but they had to
be there.</li>
<li>The bootloader has to know how long the Rust code is.</li>
<li>Both programs will be loaded at specific locations in the memory
so I have to manage the offsets in addresses.</li>
</ul>
<p>Linker seemed like a tool made for this. I‚Äôve never used a linker before so I just read
<a href="https://ftp.gnu.org/old-gnu/Manuals/ld-2.9.1/html_node/ld_toc.html"><code>ld</code>'s documentation</a>.
Unfortunately, I got a bit confused. I didn‚Äôt understand how the <code>.</code> operator
worked in linker scripts. I also got something wrong about the <code>AT()</code> instruction.
You can see the <a href="https://www.reddit.com/r/osdev/comments/hhd7uj/linking_bootloader_with_second_stage/">thread</a>
I started on Reddit.</p>
<p>Eventually I came up with such script:</p>
<pre><code>SECTIONS {
    .boot 0x7c00 : {
        *(.boot.*);
    }

    .hello_rust 0x7e00 : {
        *(.rust.*);
        . = ALIGN(512);
    } = 0xdeadc0de

    SECOND_STAGE_LENGTH = ((. - ADDR(.hello_rust)) &gt;&gt; 9);
}
</code></pre><p>Notice that I put all sections beginning with <code>.boot</code> in the first 512 bytes
and all sections beginning with <code>.rust</code> after 0x7e00. In order to make
it work I have to rename all sections in the ELF file emitted by <code>rustc</code>
so that they all start with a prefix. I do it using <code>objcopy</code>
(in some linkers this option is called <code>--prefix-sections</code>):</p>
<div><pre><code data-lang="bash">objcopy hello_rust.o hello_rust_prefixed.o --prefix-alloc-sections<span>=</span><span>'.rust'</span>
</code></pre></div><p>The there are two tricks in this script. The first one is that I align
the end of the <code>.rust</code> section to the nearest sector boundary with <code>. = ALIGN(512)</code>.
Then I fill the rest with some garbage using <code>= 0xdeadc0de</code>.
The second trick is in the last line. The <code>SECOND_STAGE_LENGTH</code>
variable tells the bootloader how many sectors the second stage occupies.
The size of this section is divided by 512 = 2^9. Since I know
that the end of this section is aligned with the boundaries
of the sectors I can just shift it 9 bits to the right.</p>
<p>These solutions seem a bit hacky. In my understanding the location
of a piece of code in an ELF file (most common target) doesn‚Äôt matter. This is not the
case with the bootloader since the code
must be aligned to 512 bytes and there must be a magic number
at the end of the first ‚Ä¶</p></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://micouy.github.io/posts/low-level-pt-1/">https://micouy.github.io/posts/low-level-pt-1/</a></em></p>]]>
            </description>
            <link>https://micouy.github.io/posts/low-level-pt-1/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23881584</guid>
            <pubDate>Sat, 18 Jul 2020 14:27:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Kubectl ‚Äì Configuration Guide]]>
            </title>
            <description>
<![CDATA[
Score 66 | Comments 25 (<a href="https://news.ycombinator.com/item?id=23881485">thread link</a>) | @lukasbar
<br/>
July 18, 2020 | https://knowledgepill.it/posts/kubernetes-kubectl-client-config/ | <a href="https://web.archive.org/web/*/https://knowledgepill.it/posts/kubernetes-kubectl-client-config/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  <p>Kubectl client gives us possibility to configure and switch easily between multiple K8s clusters.</p>
<h2 id="config-files-location-for-kubectl">Config files location for kubectl</h2>
<p>Main location for <code>kubectl</code> config files is <code>$HOME/.kube</code>, by default we have single config file named config:</p>
<div><pre><code data-lang="bash"><span>[</span>node1 ~<span>]</span>$ cd $HOME/.kube
<span>[</span>node1 .kube<span>]</span>$ ls -lah
total 4.0K
drwxr-xr-x <span>1</span> root root   <span>37</span> Mar <span>12</span> 20:48 .
dr-xr-x--- <span>1</span> root root   <span>19</span> Nov <span>29</span> 11:46 ..
drwxr-x--- <span>3</span> root root   <span>23</span> Mar <span>12</span> 20:48 cache
lrwxrwxrwx <span>1</span> root root   <span>26</span> Nov <span>29</span> 11:46 config -&gt; /etc/kubernetes/admin.conf
drwxr-x--- <span>3</span> root root 4.0K Mar <span>12</span> 20:48 http-cache
</code></pre></div><h2 id="multiple-config-files-and-kubeconfig-variable">Multiple config files and KUBECONFIG variable</h2>
<p>We can have multiple config files by setting proper <code>KUBECONFIG</code> shell variable.<br>
For example:</p>
<p><code>export KUBECONFIG=$KUBECONFIG:/root/.kube/additional_config</code></p>
<h2 id="check-config-from-kubectl">Check config from kubectl</h2>
<p>We can check current config(it will be empty because I don‚Äôt have anything in additional_config file - we‚Äôll add something later - and this is only file in my <code>KUBECONFIG</code> variable):</p>
<div><pre><code data-lang="yaml">[node1 ~]$ kubectl config view
<span>apiVersion</span>: v1
<span>clusters</span>: []
<span>contexts</span>: []
<span>current-context</span>: <span>""</span>
<span>kind</span>: Config
<span>preferences</span>: {}
<span>users</span>: []
</code></pre></div><p>Or from specific file - let‚Äôs see default file:</p>
<div><pre><code data-lang="yaml">[node1 ~]$ kubectl config --kubeconfig=.kube/config view
<span>apiVersion</span>: v1
<span>clusters</span>:
- <span>cluster</span>:
    <span>certificate-authority-data</span>: DATA+OMITTED
    <span>server</span>: https://<span>192.168</span><span>.0</span><span>.38</span>:<span>6443</span>
  <span>name</span>: kubernetes
<span>contexts</span>:
- <span>context</span>:
    <span>cluster</span>: kubernetes
    <span>user</span>: kubernetes-admin
  <span>name</span>: kubernetes-admin@kubernetes
<span>current-context</span>: kubernetes-admin@kubernetes
<span>kind</span>: Config
<span>preferences</span>: {}
<span>users</span>:
- <span>name</span>: kubernetes-admin
  <span>user</span>:
    <span>client-certificate-data</span>: REDACTED
    <span>client-key-data</span>: REDACTED
</code></pre></div><p>If you don‚Äôt set <code>KUBECONFIG</code> variable all configuration will be taken from <code>$HOME/.kube/config</code></p>
<h2 id="objects-in-kubectl-config">Objects in kubectl config</h2>
<p><code>kubectl</code> has in its config files following object types:</p>
<ul>
<li>clusters - info about K8s cluster - contain cluster name and connection parameters</li>
<li>users - info about users by which you want connect to K8s clusters</li>
<li>contexts - triple of cluster/user/namespace</li>
</ul>
<h2 id="modifying-config-from-kubectl">Modifying config from kubectl</h2>
<h3 id="add-cluster">Add cluster</h3>
<div><pre><code data-lang="bash"><span>[</span>node1 ~<span>]</span>$ kubectl config --kubeconfig<span>=</span>.kube/additional_config set-cluster dev --server<span>=</span>https://192.168.1.100 --certificate-authority<span>=</span>fake-ca
Cluster <span>"dev"</span> set.
<span>[</span>node1 ~<span>]</span>$ kubectl config --kubeconfig<span>=</span>.kube/additional_config set-cluster prod --server<span>=</span>https://10.1.1.100 --certificate-authority<span>=</span>fake-ca
Cluster <span>"prod"</span> set.
</code></pre></div><h3 id="add-users">Add users</h3>
<div><pre><code data-lang="bash"><span>[</span>node1 ~<span>]</span>$ kubectl config --kubeconfig<span>=</span>.kube/additional_config set-credentials developer --client-certificate<span>=</span>fake-cert-file --client-key<span>=</span>fake-key-seefile
User <span>"developer"</span> set.
<span>[</span>node1 ~<span>]</span>$ kubectl config --kubeconfig<span>=</span>.kube/additional_config set-credentials prod_admin --client-certificate<span>=</span>fake-cert-file --client-key<span>=</span>fake-key-seefile
User <span>"prod_admin"</span> set.
</code></pre></div><h3 id="add-contexts">Add contexts</h3>
<div><pre><code data-lang="bash"><span>[</span>node1 ~<span>]</span>$ kubectl config --kubeconfig<span>=</span>.kube/additional_config set-context simple_app_development --cluster<span>=</span>dev --namespace<span>=</span>simple_app_dev --user<span>=</span>developer
Context <span>"simple_app_development"</span> created.
<span>[</span>node1 ~<span>]</span>$ kubectl config --kubeconfig<span>=</span>.kube/additional_config set-context simple_app_production --cluster<span>=</span>prod --namespace<span>=</span>simple_app_prod --user<span>=</span>prod_admin
Context <span>"simple_app_production"</span> created.
</code></pre></div><h3 id="delete-clusterusercontext-from-config">Delete cluster/user/context from config</h3>
<div><pre><code data-lang="bash">kubectl --kubeconfig<span>=</span>.kube/additional_config config unset users.&lt;name&gt;
kubectl --kubeconfig<span>=</span>.kube/additional_config config unset clusters.&lt;name&gt;
kubectl --kubeconfig<span>=</span>.kube/additional_config config unset contexts.&lt;name&gt;
</code></pre></div><h3 id="sample-config">Sample config</h3>
<div><pre><code data-lang="yaml">[node1 ~]$ kubectl config --kubeconfig=.kube/additional_config view
<span>apiVersion</span>: v1
<span>clusters</span>:
- <span>cluster</span>:
    <span>certificate-authority</span>: /root/fake-ca
    <span>server</span>: https://<span>192.168</span><span>.1</span><span>.100</span>
  <span>name</span>: dev
- <span>cluster</span>:
    <span>certificate-authority</span>: /root/fake-ca
    <span>server</span>: https://<span>10.1</span><span>.1</span><span>.100</span>
  <span>name</span>: prod
<span>contexts</span>:
- <span>context</span>:
    <span>cluster</span>: dev
    <span>namespace</span>: simple_app_dev
    <span>user</span>: developer
  <span>name</span>: simple_app_development
- <span>context</span>:
    <span>cluster</span>: prod
    <span>namespace</span>: simple_app_prod
    <span>user</span>: prod_admin
  <span>name</span>: simple_app_production
<span>current-context</span>: <span>""</span>
<span>kind</span>: Config
<span>preferences</span>: {}
<span>users</span>:
- <span>name</span>: developer
  <span>user</span>:
    <span>client-certificate</span>: /root/fake-cert-file
    <span>client-key</span>: /root/fake-key-seefile
- <span>name</span>: prod_admin
  <span>user</span>:
    <span>client-certificate</span>: /root/fake-cert-file
    <span>client-key</span>: /root/fake-key-seefile
</code></pre></div><h3 id="changing-context-to-work-with">Changing context to work with</h3>
<p>To get list of contexts(no need for <code>--kubeconfig</code> because we have our <code>additional_config</code> added to <code>KUBECONFIG</code> variable):</p>
<div><pre><code data-lang="bash"><span>[</span>node1 ~<span>]</span>$ kubectl config get-contexts
CURRENT   NAME                     CLUSTER   AUTHINFO     NAMESPACE
          simple_app_development   dev       developer    simple_app_dev
          simple_app_production    prod      prod_admin   simple_app_prod
</code></pre></div><p>To set context:</p>
<div><pre><code data-lang="bash"><span>[</span>node1 ~<span>]</span>$ kubectl config use-context simple_app_development
Switched to context <span>"simple_app_development"</span>.
</code></pre></div><p>To get current context:</p>
<div><pre><code data-lang="bash"><span>[</span>node1 ~<span>]</span>$ kubectl config current-context
simple_app_development
</code></pre></div><hr>
<h3 id="for-those-who-want-to-know-even-more-worth-to-read">For those who want to know even more‚Ä¶ Worth to read!</h3>
<p><a href="https://gardener.cloud/documentation/guides/client_tools/bash_kubeconfig/">Kubeconfig context as bash prompt - Georgi from Gardener</a> - shell tricks and Windows CLI aproach</p>
<hr>

</div></div>]]>
            </description>
            <link>https://knowledgepill.it/posts/kubernetes-kubectl-client-config/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23881485</guid>
            <pubDate>Sat, 18 Jul 2020 14:10:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[On Trouser Pockets]]>
            </title>
            <description>
<![CDATA[
Score 665 | Comments 338 (<a href="https://news.ycombinator.com/item?id=23881220">thread link</a>) | @diiq
<br/>
July 18, 2020 | https://sambleckley.com/writing/pockets.html | <a href="https://web.archive.org/web/*/https://sambleckley.com/writing/pockets.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><h3 id="tldr">TL;DR</h3> <p>The clothing industry rarely creates dramatically new patterns. It is more lucrative to make small, easy-to-manufacture changes that always use the same basic pattern.</p> <p>There is therefore lots of room to innovate clothing that is more appropriate for contemporary problems, because basic clothing patterns haven‚Äôt changed in decades.</p> <p>I made some trousers with unusual pockets, and I think they‚Äôre good.</p> <h3 id="pockets-are-either-ugly-or-useless">Pockets are either ugly or useless</h3> <p>Pockets in tight jeans look bad. Putting a modern slab phone, a wallet, and keys into a pair of skinny jeans will leave even the most fashionable figure looking looking like they‚Äôre wearing batman‚Äôs utility belt as underwear. Even empty, in tight pants a large pocket bag can show through.</p> <p>The alternative, as many women know from first-hand experience, is a pocket too small to put anything in.</p> <p>A wallet in the back pocket can cause back pain and bad posture.</p> <p>Many of us spend most of our time sitting, but all four traditional pockets are totally inaccessible in that position. So we take out our phone, just in case, before we sit down at the restaurant ‚Äî guaranteeing a distraction.</p> <p>Aesthetics, storage, and access: these are user needs that are currently poorly fulfilled ‚Äî and that means things are ripe for innovation.</p> <h3 id="a-brief-history">A brief history</h3> <p>If the space is so ripe, why has there been no pocket innovation recently?</p> <p>Women used to have pockets. That ‚Äúused to‚Äù has to count back 150 or even 200 years, and those pockets were often a separate garment, either worn underneath and accessed through a slit in the dress, or worn around the hips overtop, rather than built into the dress directly ‚Äî but regardless, ‚Äúit has pockets!‚Äù as a joyous surprise is a modern invention. (Men‚Äôs pockets were also separate pouches if you go back far enough; but going back the same 150-200 years, they lived in the waistcoat and the mandatory jacket; if breeches had pockets they were behind the falls and so, I suspect, not used as much in public.)</p> <p>The 1880‚Äôs brought the 1940s brought the slow arrival of mass production to clothing ‚Äî not of the textiles, which started much earlier, but of actual clothes. Before this era, clothes were made either at home, or they were made one at a time. (In a quiet resonance with today, this was done in part by women who worked almost entirely from home, only travelling to the workplace to pick up new work and drop off what had been completed).</p> <p>In retrospect, fashions changed mostly decade by decade rather than year by year, but they changed dramatically. The fashionable silhouette of the 1860s looks nothing like the 1880s, or the 1910‚Äôs ‚Äî so different, in fact, that for women the foundation garments were completely unrelated entities: the crinoline of the 1860s is nothing like the bustle of the 1880s. A person who can cut and sew can sew an incredibly wide range of different things; why not play around?</p> <p>But with the advent of mass production in clothes factories, the whole layout of the factory floor was based on specific pattern piecing. Each station makes only a few operations on each garment, and garments flow from one station to the next. To completely change the <em>construction</em> of a garment means a radical overhaul of the whole assembly line.</p> <p>But to simply change the garment‚Äôs <em>proportions</em> is <em>easy</em>.</p> <p>And so we live in a world where every spring the morning talk shows invite someone on to say ‚Äúthis year, [culottes, boot-cuts, skinny jeans, flares, cuffs, boyfriend jeans, high waists, low-rise, acid-wash, raw denim] are coming back into fashion, so keep your eye out!‚Äù ‚Äî but the trousers are made from the same basic pieces, constructed in the same ways, with only the measurements changing. They get longer or shorter, looser or tighter, and change color, but they‚Äôre not fundamentally <em>different</em>.</p> <p>It‚Äôs like a lack-luster procedural generation system. Sure, there are technically millions of possibilities, but somehow you still end up bored after seeing the first 5 or 6.</p> <p>Probably not coincidentally, the advent of mass production is also when women‚Äôs silhouettes turned slim, and when all those foundation garments mostly disappeared. Designs that banish structure from the garment and rely entirely on the body beneath are much easier and cheaper to manufacture.</p> <p>And when silhouettes turned slim, women lost pockets. The more body-hugging the clothing, the less room for pockets ‚Äî or, rather, the more the pocket contents will show unflatteringly. (And as we know, it would be anathema for a women to show unflattering lump for something as silly as practicality, function, or utility.)</p> <p>And even as womenswear adopted men‚Äôs workwear styles, women got jeans but not the pockets to go with them. Spandex made it even easier to make mass-produced clothes ‚Äúfit‚Äù, and fit tighter. The unsightly-lump factor wasn‚Äôt going away.</p> <p>Even more recently, menswear has returned to an incredibly slim silhouette. Guys in skinny jeans should, by this logic, not have pockets either. But they do.</p> <p>Women get no practicality and men get no grace.</p> <h3 id="what-if-we-redesigned-the-pocket-from-scratch">What if we redesigned the pocket from scratch?</h3> <p>Let‚Äôs design a trouser pocket! This process is going to land somewhere between UX and industrial design. I am, sadly, not in charge of a clothes factory, so I am not concerned with the problems of mass-production, but material properties and the construction process do still matter; but I am maybe more willing to make manufacturing sacrifices for usefulness than most industrial designers are able to be.</p> <h3 id="what-do-people-use-pockets-for">What do people use pockets for?</h3> <ul> <li>Storing things; most often phone, then keys, wallet or money-clip, and other small items. At the moment, a mask.</li> <li><em>Verifying</em> stored objects ‚Äî the hip-slapping dance of making sure you have everything before walking out the door.</li> <li>They must be secure while standing, sitting, running for the bus, etc</li> <li>Things, especially phone, need to go in and out of storage frequently, almost unconsciously.</li> <li>Access to phone while seated in a restaurant; to keys and license while in car</li> <li>Aesthetically, we want a clean, graceful line from hip to ankle even while holding things.</li> </ul> <p>An initial solution can be based on just three questions:</p> <ul> <li>Where can your hands reach?</li> <li>Where is there extra space to put things?</li> <li>Where is there enough support to prevent items swinging around uncomfortably?</li> </ul> <p>These questions form a physical venn diagram, pointing at a pretty small area for investigation:</p> <p><img src="https://sambleckley.com/assets/images/pocket_venn.png" alt="The human body with overlapping regions of reach, space, and support."></p> <p>You can see that current pockets are located completely outside the area where there is potentially space; the hips and butt of modern pants, for both women and men, are closely fitted. If there‚Äôs any ease, it starts just above the knees.</p> <p>Conveniently, the point where the vastus lateralis starts to curve back in towards the knee, creating space, is also right around the lowest point your arms can reach without bending over, giving us a well-defined target.</p> <p>So I made a pair of trousers with no pockets at the waist, and a pair of welt pockets at the side seams, right at that point.</p> <p><img src="https://sambleckley.com/assets/images/pants1.jpg" alt="First pair of pants."></p> <h3 id="notes-from-user-testing">Notes from user testing:</h3> <ul> <li>A pocket needs to be big enough for a whole hand, not just phone, to allow for fishing out small items from the very bottom of the pocket-bag.</li> <li>The pocket bag slips down and back if it‚Äôs full and the wearer sits down. This is uncomfortable and</li> <li>The pocket mustn‚Äôt allow a slick round phone to fall out when sitting, especially when, e.g. jiggling a leg.</li> </ul> <h3 id="revisions">Revisions</h3> <p>Luckily, each of these notes point at simple revision, rather than the need to start again.</p> <ul> <li>Make the pockets wider.</li> <li>Anchor the bottom of the pocket bag to the side seam.</li> <li>Angle the opening so it‚Äôs higher in the back ‚Äî this both makes it easier to slip a phone into the pocket, and makes the pocket ‚Äúdeeper‚Äù on the bottom side when sitting or crouching.</li> </ul> <p><img src="https://sambleckley.com/assets/images/pants2.jpg" alt="Second pair of pants."></p> <h3 id="outcome">Outcome</h3> <p>These are great. I completely forget my phone and wallet are there ‚Äî they don‚Äôt restrict my movement, they‚Äôre completely invisible, and yet they‚Äôre easy to access while standing or sitting. There‚Äôs no temptation to slouch around with my hands stuffed in my pockets. They‚Äôre so straightforwardly better for my needs that I‚Äôm now frustrated when my new-pocket pants are dirty and I have to wear trousers with pockets that are just SO twentieth-century. I immediately made a pair of jeans in this pattern, too.</p> <p>Further revision is possible, of course; but while it will be easy to refine this design to suit my personal body and needs more precisely, there‚Äôs only so much refinement possible while remaining suitable for a wide range of body types. If you wanted to mass-produce a pocket like this, you‚Äôd want to use something like Dreyfuss‚Äô Humanscale data to make sure the placement and size is appropriate for the widest range of people. Luckily, you‚Äôd have <em>some</em> additional information in the sizing of the <em>rest</em> of the pants.</p> <h3 id="appendix-sam-have-you-simply-invented-cargo-pants">Appendix: Sam, have you simply invented cargo pants?</h3> <p>No. Cargo pants solve different problems for different people.</p> <p>If cargo pants are appropriate for your daily life, you definitely don‚Äôt want or need my side-seam welt pockets; and vice-versa. Cargo pants aren‚Äôt office-wear; these dress pants aren‚Äôt combat-wear.</p> </div></div>]]>
            </description>
            <link>https://sambleckley.com/writing/pockets.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23881220</guid>
            <pubDate>Sat, 18 Jul 2020 13:16:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Logged out]]>
            </title>
            <description>
<![CDATA[
Score 46 | Comments 44 (<a href="https://news.ycombinator.com/item?id=23880938">thread link</a>) | @patwalls
<br/>
July 18, 2020 | https://patwalls.com/logged-out | <a href="https://web.archive.org/web/*/https://patwalls.com/logged-out">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://patwalls.com/logged-out</link>
            <guid isPermaLink="false">hacker-news-small-sites-23880938</guid>
            <pubDate>Sat, 18 Jul 2020 12:26:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Typed Lisp, a Primer (2019)]]>
            </title>
            <description>
<![CDATA[
Score 97 | Comments 21 (<a href="https://news.ycombinator.com/item?id=23878612">thread link</a>) | @jedimind
<br/>
July 17, 2020 | https://alhassy.github.io/TypedLisp.html | <a href="https://web.archive.org/web/*/https://alhassy.github.io/TypedLisp.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="text-typing-via-macros">
<p>
Checking the type of inputs is tedious and so I <a href="https://www.reddit.com/r/emacs/comments/cct5hp/functional_type_declarations_in_elisp/">guessed</a> it could be done using
macros and advice. Looking at <a href="https://docs.racket-lang.org/ts-guide/types.html">Typed Racket</a> for inspiration, the following
fictitious syntax would add advice to <code>f</code> that checks the optional arguments <code>x·µ¢</code>
have type <code>œÉ·µ¢</code> and the mandatory positional arguments have type <code>œÑ·µ¢</code> according
to position, and the result of the computation is of type <code>œÑ</code>.
To the best of my knowledge, no one had done this for Emacs Lisp ‚ÄîI don't know why.
</p>
<div>
<pre>(declare-type 'f ((<span>:x‚ÇÅ</span> œÉ‚ÇÅ) ‚Ä¶ (<span>:x‚Çò</span> œÉ‚Çò)) (œÑ‚ÇÅ ‚Ä¶ œÑ‚Çô œÑ))
</pre>
</div>

<p>
To modify a variable, or function, we may simply redefine it; but a much more elegant and powerful
approach is to <a href="https://www.gnu.org/software/emacs/manual/html_node/elisp/Advising-Functions.html">‚Äúadvise‚Äù</a> the current entity with some new behaviour. In our case of interest, we will
<i>advise functions to check their arguments before executing their bodies</i>.
</p>

<p>
Below is my attempt: <a id="org84d2c90"><code>declare-type</code></a>. Before you get scared or think it's horrendous, be charitable and
note that about a third of the following is documentation and a third is local declarations.
</p>
<div>
<pre>(<span>cl-defmacro</span> <span>declare-type</span> (f key-types <span>&amp;rest</span> types)
  <span>"Attach the given list of types to the function ‚Äòf‚Äô</span>
<span>   by advising the function to check its arguments‚Äô types</span>
<span>   are equal to the list of given types.</span>

<span>   We name the advice ‚Äò‚ü™f‚ü´-typing-advice‚Äô so that further</span>
<span>   invocations to this macro overwrite the same advice function</span>
<span>   rather than introducing additional, unintended, constraints.</span>

<span>   Using type specifiers we accommodate for unions of types</span>
<span>   and subtypes, etc ‚ô•‚Äø‚ô•.</span>

<span>   ‚Äò</span><span>key-types</span><span>‚Äô should be of the shape (:x‚ÇÄ t‚ÇÄ ‚ãØ :x‚Çô t‚Çô);</span>
<span>    when there are no optional types, use symbol ‚Äú:‚Äù.</span>

<span>    E.g., (declare-type my-func (:z string :w integer) integer symbol string)</span>
<span>  "</span>

  <span>;; </span><span>Basic coherency checks. When there aren't optional types, key-types is the ‚Äú:‚Äù symbol.</span>
  (should (<span>and</span> (<span>listp</span> types) (<span>or</span> (<span>listp</span> key-types) (<span>symbolp</span> key-types))))

  (<span>letf*</span> ((pairify (<span>lambda</span> (xs) (<span>loop</span> for i in xs by #'<span>cddr</span>         <span>;; </span><span>Turn a list of flattenned pairs</span>
                                      for j in (<span>cdr</span> xs) by #'<span>cddr</span>   <span>;; </span><span>into a list of explicit pairs.</span>
                                      collect (<span>cons</span> i j))))         <span>;; </span><span>MA: No Lisp method for this!?</span>
         (result-type  (<span>car</span> (<span>-take-last</span> 1 types)))
         (types        (<span>-drop-last</span> 1 types))
         (num-of-types (<span>length</span> types))
         (key-types-og (<span>unless</span> (<span>symbolp</span> key-types) key-types))
         (key-types    (<span>funcall</span> pairify key-types-og))
         (advice-name  (<span>intern</span> (<span>format</span> <span>"%s-typing-advice"</span> f)))
         (notify-user  (<span>format</span> <span>"%s now typed %s ‚Üí %s ‚Üí %s."</span>
                               `,f key-types-og types result-type)))

      `(<span>progn</span>
         (<span>defun</span> ,advice-name (orig-fun <span>&amp;rest</span> args)

           <span>;; </span><span>Split into positional and key args; optionals not yet considered.</span>
           (<span>letf*</span> ((all-args
                     (<span>-split-at</span>
                       (<span>or</span> (<span>--find-index</span> (<span>not</span> (<span>s-blank?</span> (<span>s-shared-start</span> <span>":"</span> (<span>format</span> <span>"%s"</span> it)))) args) ,num-of-types)
                        args)) <span>;; </span><span>The ‚Äúor‚Äù is for when there are no keywords provided.</span>
                  (pos-args  (<span>car</span> all-args))
                  (key-args  (<span>funcall</span> ,pairify (<span>cadr</span> all-args)))
                  (fun-result nil)
                  ((<span>symbol-function</span> 'shucks)
                     (<span>lambda</span> (eœÑ e g)
                       (<span>unless</span> (<span>typep</span> g eœÑ)
                         (<span>error</span> <span>"%s: Type mismatch! Expected %s %s ‚â† Given %s %s."</span>
                                (<span>function</span> ,f) eœÑ e (<span>type-of</span> g) (<span>prin1-to-string</span> g))))))

         <span>;; </span><span>Check the types of positional arguments.</span>
         (<span>unless</span> (<span>equal</span> ,num-of-types (<span>length</span> pos-args))
           (<span>error</span> <span>"%s: Insufficient number of arguments; given %s, %s, but %s are needed."</span>
                  (<span>function</span> ,f) (<span>length</span> pos-args) pos-args ,num-of-types))
         (<span>loop</span> for (ar ty pos) in (<span>-zip</span> pos-args (<span>quote</span> ,types) (<span>number-sequence</span> 0 ,num-of-types))
               <span>do</span> (shucks ty (<span>format</span> <span>"for argument %s"</span> pos) ar))

         <span>;; </span><span>Check the types of *present* keys.</span>
         (<span>loop</span> for (k . v) in key-args
               <span>do</span> (shucks (<span>cdr</span> (<span>assoc</span> k (<span>quote</span> ,key-types))) k v))

         <span>;; </span><span>Actually execute the orginal function on the provided arguments.</span>
         (<span>setq</span> fun-result (<span>apply</span> orig-fun args))
         (shucks (<span>quote</span> ,result-type) <span>"for the result type (!)"</span> fun-result)

         <span>;; </span><span>Return-value should be given to caller.</span>
         fun-result))

      <span>;; </span><span>Register the typing advice and notify user of what was added.</span>
      (<span>advice-add</span> (<span>function</span> ,f) <span>:around</span> (<span>function</span> ,advice-name))
      ,notify-user )))
</pre>
</div>

<pre>declare-type
</pre>


<p>
There are some notable shortcomings: Lack of support for type variables and, for now, no support for
optional arguments. Nonetheless, I like it ‚Äîof course.
( Using <a href="https://www.gnu.org/software/emacs/manual/html_node/elisp/Watching-Variables.html#Watching-Variables">variable watchers</a> we could likely add support for type variables as well as
function-types. )
</p>

<p>
<b>We accidentally forgot to consider an argument.</b>
</p>
<div>
<pre>(declare-type f‚ÇÅ (<span>:z</span> <span>string</span> <span>:w</span> <span>list</span>) integer symbol <span>string</span>)
<span>;; </span><span>‚áí f‚ÇÅ now typed (:z string :w integer) ‚Üí (integer symbol) ‚Üí string.</span>

(<span>cl-defun</span> <span>f‚ÇÅ</span> (x y <span>&amp;key</span> z w) (<span>format</span> <span>"%s"</span> x))
<span>;; </span><span>‚áí f‚ÇÅ now defined</span>

(f‚ÇÅ 'x) <span>;; </span><span>‚áí f‚ÇÅ: Insufficient number of arguments; given 2, (x), but 3 are needed.</span>
</pre>
</div>
<p>
The type declaration said we needed 3 arguments, but we did not consider one of them.
</p>

<p>
<b>We accidentally returned the wrong value.</b>
</p>
<div>
<pre>(declare-type f‚ÇÇ (<span>:z</span> <span>string</span> <span>:w</span> <span>list</span>) integer symbol <span>string</span>)
(<span>cl-defun</span> <span>f‚ÇÇ</span> (x y <span>&amp;key</span> z w) x)

(f‚ÇÇ 144 'two)
<span>;; </span><span>‚áí f‚ÇÇ: Type mismatch! Expected string for the result type (!) ‚â† Given integer 144.</span>
</pre>
</div>

<p>
<b>We accidentally forgot to supply an argument.</b>
</p>
<div>
<pre>(declare-type f‚ÇÉ (<span>:z</span> <span>string</span> <span>:w</span> <span>list</span>) integer symbol <span>string</span>)
(<span>cl-defun</span> <span>f‚ÇÉ</span> (x y <span>&amp;key</span> z w) (<span>format</span> <span>"%s"</span> x))

(f‚ÇÉ 144)
<span>;; </span><span>‚áí f‚ÇÉ: Insufficient number of arguments; given 1, (144), but 2 are needed.</span>
</pre>
</div>

<p>
<b>A positional argument is supplied of the wrong type.</b>
</p>
<div>
<pre>(f‚ÇÉ 'one <span>"two"</span>)
<span>;; </span><span>‚áí  f‚ÇÉ: Type mismatch! Expected integer for argument 0 ‚â† Given symbol one.</span>

(f‚ÇÉ 144 <span>"two"</span>)
<span>;; </span><span>‚áí f‚ÇÉ: Type mismatch! Expected symbol for argument 1 ‚â† Given string "two".</span>
</pre>
</div>
<p>
Notice: When multiple positional arguments have type-errors, the errors are reported one at a time.
</p>

<p>
<b>A keyword argument is supplied of the wrong type.</b>
</p>
<div>
<pre>(f‚ÇÉ 1 'two <span>:z</span> 'no‚ÇÄ <span>:w</span> 'no‚ÇÅ)
<span>;; </span><span>‚áí f‚ÇÉ: Type mismatch! Expected string :z ‚â† Given symbol no‚ÇÄ.</span>

(f‚ÇÉ 1 'two <span>:z</span> <span>"ok"</span> <span>:w</span> 'no‚ÇÅ)
<span>;; </span><span>‚áí f‚ÇÉ: Type mismatch! Expected string :w ‚â† Given symbol no‚ÇÅ.</span>

(f‚ÇÉ 1 'two <span>:z</span> <span>"ok"</span> <span>:w</span> 23)
<span>;; </span><span>‚áí f‚ÇÉ: Type mismatch! Expected string :w ‚â† Given integer 23.</span>

(f‚ÇÉ 1 'two <span>:z</span> <span>"ok"</span> <span>:w</span> '(a b 1 2)) <span>;; </span><span>‚áí okay; no type-error.</span>
</pre>
</div>

<p>
<b>We have no optional arguments.</b>
</p>
<div>
<pre>(declare-type f‚ÇÑ : integer symbol <span>string</span>)
(<span>cl-defun</span> <span>f‚ÇÑ</span> (x y <span>&amp;key</span> z w) (<span>format</span> <span>"%s"</span> x))

(f‚ÇÑ 144 'two <span>:z</span> <span>"bye"</span>)
<span>;; </span><span>‚áí  f‚ÇÑ: Type mismatch! Expected nil :z ‚â† Given string "bye".</span>
<span>;; </span><span>( We shouldn't have any keyword :z according to the type declaration! )</span>

(f‚ÇÑ 144 'two) <span>;; </span><span>‚áí "144"</span>
</pre>
</div>

<p>
<b>We can incorporate type specfiers such as unions!</b>
</p>
<div>
<pre>(declare-type f‚ÇÖ : (<span>or</span> integer <span>string</span>) <span>string</span>)
(<span>cl-defun</span> <span>f‚ÇÖ</span> (x) (<span>format</span> <span>"%s"</span> x))

(f‚ÇÖ 144)     <span>;; </span><span>‚áí "144"</span>
(f‚ÇÖ <span>"neato"</span>) <span>;; </span><span>‚áí "neato"</span>

(f‚ÇÖ 'shaka-when-the-walls-fell)
<span>;; </span><span>‚áí f‚ÇÖ: Type mismatch! Expected (or integer string) for argument 0</span>
<span>;;       </span><span>‚â† Given symbol shaka-when-the-walls-fell.</span>
</pre>
</div>

<p>
<b>No positional arguments but a complex optional argument!</b>
</p>
<div>
<pre>(declare-type f‚ÇÜ (<span>:z</span> (satisfies (<span>lambda</span> (it) (<span>and</span> (<span>integerp</span> it) (<span>=</span> 0 (<span>mod</span> it 5))))))
                 character)
(<span>cl-defun</span> <span>f‚ÇÜ</span> (<span>&amp;key</span> z) ?A)

(f‚ÇÜ 'hi)     <span>;; </span><span>‚áí  Keyword argument 144 not one of (:z)</span>
(f‚ÇÜ)         <span>;; </span><span>‚áí 65; i.e., the character ‚ÄòA‚Äô</span>
(f‚ÇÜ <span>:z</span> 6)
<span>;; </span><span>‚áí  f‚ÇÜ: Type mismatch!</span>
<span>;;    </span><span>Expected (satisfies (lambda (it) (and (integerp it) (= 0 (mod it 5))))) :z</span>
<span>;;    </span><span>‚â† Given integer 6.</span>

(f‚ÇÜ <span>:z</span> 10) <span>;; </span><span>‚áí 65; i.e., the expected output since 10 mod 5 ‚âà 0 &amp; so 10 is valid input.</span>
</pre>
</div>

<p>
<b>Preconditions!</b> The previous example had a complex type on a keyword, but that was
essentially a pre-condition; we can do the same on positional arguments.
</p>
<div>
<pre>(declare-type f‚Çá : (satisfies (<span>lambda</span> (it) (<span>=</span> it 5)))
                   integer)
(<span>cl-defun</span> <span>f‚Çá</span> (n) n)
<span>;; </span><span>The identity on 5 function; and undefined otherwise.</span>

(f‚Çá 4)
<span>;; </span><span>‚áí f‚Çá: Type mismatch! Expected (satisfies (lambda (it) (= it 5))) for argument 0</span>
<span>;;       </span><span>‚â† Given integer 4.</span>

(f‚Çá 5) <span>;; </span><span>‚áí 5</span>
</pre>
</div>

<p>
<b>Postconditions!</b>
Given an integer greater than 5, we present an integer greater than 2; i.e.,
this is a constructive proof that \(‚àÄ n ‚Ä¢ n &gt; 5 ‚áí n &gt; 2\).
</p>
<div>
<pre>(declare-type f‚Çà : (satisfies (<span>lambda</span> (in)  (<span>&gt;</span> in 5)))
                   (satisfies (<span>lambda</span> (out) (<span>&gt;</span> out 2))))
(<span>cl-defun</span> <span>f‚Çà</span> (n) n)
<span>;; </span><span>The identity on 5 function; and undefined otherwise.</span>

(f‚Çà 4)
<span>;; </span><span>‚áí  f‚Çà: Type mismatch! Expected (satisfies (lambda (in) (&gt; in 5))) for argument 0</span>
<span>;;        </span><span>‚â† Given integer 4.</span>

(f‚Çà 72) <span>;; </span><span>‚áí 72; since indeed 72 &gt; 5 for the input, and clearly 72 &gt; 2 for the output.</span>
</pre>
</div>

<p>
As it currently stands we cannot make any explicit references between the inputs
and the output, but that's an easy fix: Simply add a local function <code>old</code> to the
<a href="#org84d2c90"><code>declare-type</code></a> macro which is intentionally exposed so that it can be used in the
type declarations to refer to the ‚Äòold‚Äô, or initial, values provided to the function.
Additionally, one could also add keyword arguments <code>:requires</code> and <code>:ensures</code>
for a more sophisticated pre- and post-condition framework.
<a href="https://github.com/sellout/quid-pro-quo">Something</a> along these lines is implemented for Common Lisp.
</p>

<p>
Here's a fun exercise: Recast the <a href="https://liquid.kosmikus.org/01-intro.html#/what-is-liquid-haskell">Liquid Haskell</a> examples in Lisp using this
<a href="#org84d2c90"><code>declare-type</code></a> form.
</p>
</div></div>]]>
            </description>
            <link>https://alhassy.github.io/TypedLisp.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23878612</guid>
            <pubDate>Sat, 18 Jul 2020 03:19:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Levandowski files suit against Uber [pdf]]]>
            </title>
            <description>
<![CDATA[
Score 112 | Comments 91 (<a href="https://news.ycombinator.com/item?id=23877872">thread link</a>) | @MrSandman
<br/>
July 17, 2020 | https://ipfs.eternum.io/ipfs/Qmd9PTEtuSrKKtJQw36aNzpjJwZAdCdwCmUn4w21mmq74z/Levandowski-Uber-Complaint-1.pdf | <a href="https://web.archive.org/web/*/https://ipfs.eternum.io/ipfs/Qmd9PTEtuSrKKtJQw36aNzpjJwZAdCdwCmUn4w21mmq74z/Levandowski-Uber-Complaint-1.pdf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://ipfs.eternum.io/ipfs/Qmd9PTEtuSrKKtJQw36aNzpjJwZAdCdwCmUn4w21mmq74z/Levandowski-Uber-Complaint-1.pdf</link>
            <guid isPermaLink="false">hacker-news-small-sites-23877872</guid>
            <pubDate>Sat, 18 Jul 2020 00:48:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Think like a scientist talk like a populist]]>
            </title>
            <description>
<![CDATA[
Score 22 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23877780">thread link</a>) | @shdc
<br/>
July 17, 2020 | https://shyal.com/blog/think-like-a-scientist-talk-like-a-populist | <a href="https://web.archive.org/web/*/https://shyal.com/blog/think-like-a-scientist-talk-like-a-populist">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    
    
     

    
    √¢‚Ä†ÔøΩ
    <a href="https://shyal.com/">√∞≈∏ÔøΩ&nbsp;</a>
     
    <!-- if has_fences -->
    <!-- <div><a href='/black'><img src='/Attachments/black.svg'/></a></div> -->
    <!--  end  -->
    <p>18/07/2020</p>
<p>Adapting your language to match that of your audience, in today's world, seems to be growing in importance by the day. Let's contrast two public figures in public appearances that took place yesterday: Fauci vs. Trump.</p>
<h2 id="dr-fauci-vs-populism">Dr Fauci vs Populism</h2>
<p>The rising wave of populism in the U.S has wrought a "distrust of experts". That's a real shame, especially when you don't listen to your infectious disease expert during a Pandemic.</p>
<p><img alt="Pasted image 39.png" src="https://shyal.com/Attachments/Pasted%20image%2039.png"></p>
<p>Dr Fauci literally wrote the book on infectious disease, yet the populists are calling for his head. Why?</p>
<h3 id="they-dont-understand-a-word-he-says">They don't understand a word he says</h3>
<p>I was watching this <a href="https://web.facebook.com/zuck/videos/10112108870243761/">interview</a> of Dr Fauci by Zuck, yesterday. Finally Fauci is given a chance to speak to the people. Yet:</p>
<blockquote>
<blockquote>
<p>"Citizenry"</p>
</blockquote>
</blockquote>
<p>People?</p>
<blockquote>
<blockquote>
<p>"myalgic encephalitis"</p>
</blockquote>
</blockquote>
<p>Feeling too tired to lift an arm or get out of bed?</p>
<blockquote>
<blockquote>
<p>"deleterious consequences"</p>
</blockquote>
</blockquote>
<p>Bad things happen?</p>
<blockquote>
<blockquote>
<p>"i used the word 'comparable' and i think it may have been taken out of context"</p>
</blockquote>
</blockquote>
<p>Then don't say 'comparable'.</p>
<p>Indeed we already have evidence that <a href="https://www.pnas.org/content/early/2020/07/09/2008868117">working memory predicts social-distancing compliance</a>. This is pretty damning evidence: essentially people with lower working memory capacity are unwilling to socially distance themselves as they cannot hold enough variables in mind to accurately assess the pros and cons.</p>
<p>Thus it isn't too much of a leap to theorise that a lower working memory capacity is also linked with a restricted vocabulary, and thus a reduced ability to process Dr Fauci's long, complex sentences which are laiden with technical jargon and advanced vocab.</p>
<p>Or to put it bluntly: the idiots don't understand Dr Fauci.</p>
<h2 id="donald-trump-is-a-communication-wizard">Donald Trump is a communication Wizard</h2>
<p>Scott Adams accurately predicted <a href="https://www.scottadamssays.com/2015/10/23/the-case-for-a-trump-landslide-part-1/">Donal Trump would win the elections in a landslide</a> back in 2015.</p>
<blockquote>
<blockquote>
<p>"Trump is talking directly to people√¢‚Ç¨‚Ñ¢s subconscious. Everything else he says is just a carrier signal." --Scott Adams (<a href="https://www.scottadamssays.com/2015/09/06/how-to-spot-a-wizard/">how to spot a wizard</a>)</p>
</blockquote>
</blockquote>
<p>This is a great example of Trump's communicative Wizardry. On the same Day Dr Fauci was telling the citizenry about myalgic encephalitis and deleterious consequences, Trump did this:</p>
<p><img alt="Pasted image 40.png" src="https://shyal.com/Attachments/Pasted%20image%2040.png"></p>
<p>Trump had the audacity to set up two cranes, to visually demonstrate lifting regulatory weights off the Republican red truck, while regulation still weighing down on the Democrat blue truck. This is pure communication genius, <strong>because any idiot can understand it</strong> and it <strong>communicates to their subconscious</strong>.</p>
<p>By catering to the lowest common denominator, Trump ensures he captures 100% of his potential base. Not a single word is lost. In fact this kind of visual communication transcends language, education level, even culture.</p>
<h2 id="boris-johnson-is-also-a-communication-wizard">Boris Johnson is also a communication Wizard</h2>
<p>In this interview, Johnson shares his communication principles:</p>
<blockquote>
<blockquote>
<p>"What people listen to are short anglo-saxon words that readily correspond to some object in the universe that they can identify. So in other words: talk simply, in plain English, and talk about stuff in the real world." --Boris Johnson</p>
</blockquote>
</blockquote>
<iframe width="560" height="315" src="https://www.youtube.com/embed/oJXyI-gwBNU?start=437" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>

<p>Deriding people like Trump or Johnson for their perceived linguistic blunders utterly misses the point. <strong>Their blunders are what makes them accessible.</strong> Their simple language is what makes them understable. Their communicative wizardly is what makes them irresistible to their base.</p>
<h2 id="elon-musk-is-also-a-communication-wizard">Elon Musk is also a communication Wizard</h2>
<p>Those who know me will confirm this to you: i have been a huge Musky for a very long time. Elon Musk is yet another genius at tailoring his communication to his base:</p>
<p><img alt="Pasted image 37.png" src="https://shyal.com/Attachments/Pasted%20image%2037.png"></p>
<p>Musk speaks to engineers, or generally a base with technological interests, so his language is not always as simple as it could be. But when you consider the topics he talks about, you have to admire how accessible he is able to make them. The language is simple, and the topics relate to the real world.</p>
<p><img alt="Pasted image 41.png" src="https://shyal.com/Attachments/Pasted%20image%2041.png"></p>
<p>And then there are his masterpieces of communication, like the Tesla he sent into orbit. Once again, pure communication genius that transcends language and culture.</p>
<p>Or his EDM track:</p>
<iframe width="560" height="315" src="https://www.youtube.com/embed/hOEWUm6aGPg" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>

<blockquote>
<blockquote>
<p>"Don't doubt your vibe, because it's true." -- Elon Musk</p>
</blockquote>
</blockquote>
<p>A quick glance at Tesla's stock performance since the <a href="https://shyal.com/blog/tesla-stock-bottom-date">tesla stock bottom date</a> will tell you the message was indeed recieved.</p>
<h2 id="idiocracy-had-it-right">Idiocracy had it right</h2>
<p>The movie <a href="https://www.imdb.com/title/tt0387808/">Idiocracy (2006)</a> is a spooky and hilarious foray into a potential future dumbing down of the human race. The main character, from our time, <strong>who's name is "no sure"</strong> wakes up in the future as the <strong>man with the highest IQ. But nobody understands a word he says</strong>.</p>
<iframe width="560" height="315" src="https://www.youtube.com/embed/sGUNPMPrxvA" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>

<p>He narrowly manages to save the human race by <strong>showing them</strong> that watering crops with water instead of gatorade is the solution to all their problems.</p>

<p>All the evidence points to dumbing down your language, and communicating visually and symbolically to become an unstoppable communicator. <strong>Think like a scientist and talk like a populist; you will become unstoppable</strong>.</p>
<hr>
<p>Enjoyed this article? <a href="https://twitter.com/shyaldc">Follow me on Twitter</a>.</p>
    </div></div>]]>
            </description>
            <link>https://shyal.com/blog/think-like-a-scientist-talk-like-a-populist</link>
            <guid isPermaLink="false">hacker-news-small-sites-23877780</guid>
            <pubDate>Sat, 18 Jul 2020 00:34:22 GMT</pubDate>
        </item>
    </channel>
</rss>
