<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 5]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 5. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Sun, 21 Feb 2021 04:35:44 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-5.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Sun, 21 Feb 2021 04:35:44 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[Where Everything Went Wrong: Error Handling and Error Messages in Rust]]>
            </title>
            <description>
<![CDATA[
Score 37 | Comments 10 (<a href="https://news.ycombinator.com/item?id=26191006">thread link</a>) | @lukastyrychtr
<br/>
February 19, 2021 | https://msirringhaus.github.io/Where-everything-went-wrong/ | <a href="https://web.archive.org/web/*/https://msirringhaus.github.io/Where-everything-went-wrong/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p><strong>Today you are frustrated.</strong></p>

<p>This is so annoying. YouÃ¢â‚¬â„¢ve written a Rust crate and now that you want to test it for the very first time, <em>it doesnÃ¢â‚¬â„¢t work!</em></p>

<p>Come on, Rust! How dare you? You promised that once one gets past the compiler, it.<br>
<em>Just.<br>
<strong>Works!</strong></em><br>
And now this!</p>

<p>Ok, ok. You calm yourself down. Lets start from the beginning. You want to create so called <a href="https://docs.sentry.io/platforms/native/guides/minidumps/">minidumps</a>. This is a file that contains information about a crashed program (like stacks of all threads, CPU registers, system info, etc.).
The minidump consists of various sections, such as the minidump header (including time of day, versions and basically a table of contents), a thread section (including all threads of the process and their stacks), memory mappings and libraries, etc. [Just to give some context, as all of this is actually not really important.]</p>

<p>For this, you created a <a href="https://github.com/msirringhaus/minidump_writer_linux">crate</a>. One section gets written after the other, while information about the targeted process is retrieved from the system. You even created a nice, simple API. You hand in a process ID and an open file, where the minidump should be written to. like this:</p>

<div><div><pre><code>    <span>MinidumpWriter</span><span>::</span><span>new</span><span>(</span><span>pid</span><span>,</span> <span>blamed_thread</span><span>)</span>
        <span>.dump</span><span>(</span><span>&amp;</span><span>mut</span> <span>dump_file</span><span>)</span>
        <span>.expect</span><span>(</span><span>"Dumping failed!"</span><span>)</span>
</code></pre></div></div>

<p>You can also hand in user specified memory regions that should be included in the dump, like so:</p>

<div><div><pre><code>    <span>let</span> <span>app_memory</span> <span>=</span> <span>AppMemory</span> <span>{</span>
        <span>ptr</span><span>:</span> <span>some_address</span><span>,</span>
        <span>length</span><span>:</span> <span>memory_size</span><span>,</span>
    <span>};</span>

    <span>MinidumpWriter</span><span>::</span><span>new</span><span>(</span><span>pid</span><span>,</span> <span>pid</span><span>)</span>
        <span>.set_app_memory</span><span>(</span><span>vec!</span><span>[</span><span>app_memory</span><span>])</span>
        <span>.dump</span><span>(</span><span>&amp;</span><span>mut</span> <span>tmpfile</span><span>)</span>
        <span>.expect</span><span>(</span><span>"Dumping failed"</span><span>);</span>
</code></pre></div></div>



<p>But when you run your nice library code in an application, you get <code>'Dumping failed: "Failed in ptrace::read: Sys(EIO)"'</code>.</p>

<p><em>How useless is that?!</em></p>

<p>Okay, maybe you could enhance your library error handling, a little. And by enhance, you mean Ã¢â‚¬Å“implement one in the first placeÃ¢â‚¬ï¿½.</p>

<h2 id="state-of-the-dart">State of the dart</h2>

<p>Your current approach is to define</p>

<div><div><pre><code><span>type</span> <span>Error</span> <span>=</span> <span>Box</span><span>&lt;</span><span>dyn</span> <span>error</span><span>::</span><span>Error</span> <span>+</span> <span>std</span><span>::</span><span>marker</span><span>::</span><span>Send</span> <span>+</span> <span>std</span><span>::</span><span>marker</span><span>::</span><span>Sync</span><span>&gt;</span><span>;</span>
<span>pub</span> <span>type</span> <span>Result</span><span>&lt;</span><span>T</span><span>&gt;</span> <span>=</span> <span>result</span><span>::</span><span>Result</span><span>&lt;</span><span>T</span><span>,</span> <span>Error</span><span>&gt;</span><span>;</span>
</code></pre></div></div>

<p>and using <code>Result&lt;T&gt;</code> in all of your functions as the return value and handing all of them to the parent function using <code>?</code>. Thus the original error pierces through your callstack like a dart throughÃ¢â‚¬Â¦.jelly (Yes, you are good with words and you know it.).</p>

<div><div><pre><code>    <span>pub</span> <span>fn</span> <span>init</span><span>(</span><span>&amp;</span><span>mut</span> <span>self</span><span>)</span> <span>-&gt;</span> <span>Result</span><span>&lt;</span><span>()</span><span>&gt;</span> <span>{</span>
        <span>self</span><span>.read_auxv</span><span>()</span><span>?</span><span>;</span>
        <span>self</span><span>.enumerate_threads</span><span>()</span><span>?</span><span>;</span>
        <span>self</span><span>.enumerate_mappings</span><span>()</span><span>?</span><span>;</span>
        <span>Ok</span><span>(())</span>
    <span>}</span>
</code></pre></div></div>

<p>In Rust parlance, this is also called bubbling up errors.</p>

<p>Usually, you just bubble up errors from libraries you use, but for the rare errors you have to define yourself, you currently just do</p>
<div><div><pre><code><span>Err</span><span>(</span><span>"Found no auxv entry"</span><span>.into</span><span>())</span>
</code></pre></div></div>

<p>Well, now you know there is an error, at least. And that it has <em>something</em> to do with your usage of <code>ptrace</code>. But you have no idea where that happens. You use that functionality in various places. Is it during the init-phase? During one of the sections? And if so, which one? What are you trying to read? And from where? Or in short: <strong>What is going on?!</strong></p>

<h2 id="shoes-off-get-some-tea-research-time">Shoes off, get some tea: Research time!</h2>

<p>Well, Rust has been around for quite some time now and they always boast about how error handling is a first class citizen and all that. So error handling should be a done deal, right? With a canonical way of dealing with errors, officially documented and all that should be right there, correct?</p>

<p>Oh boy, were you wrong.</p>

<p>Turns out, this is a very active field ofÃ¢â‚¬Â¦mhÃ¢â‚¬Â¦experimentation, lets say. There has been <a href="https://blog.yoshuawuyts.com/error-handling-survey/">a survey</a> recently, listing and quickly describing most the different libraries and ways for error handling that emerged, fallen out of favor, got forked, died anyways, got superseded, fallen out of favor again, etc.
And the opinions seem to change frequently, if you should use <code>error-chain</code> or <code>failure</code> or <code>fehler</code> or <code>snafu</code> or <code>thiserror</code> or <code>anyhow</code> or <code>eyre</code> orÃ¢â‚¬Â¦</p>

<p>You opened a can of hornets there, or whatever that saying is.</p>

<p>Then you find <a href="https://blog.rust-lang.org/inside-rust/2020/11/23/What-the-error-handling-project-group-is-working-on.html">this gem</a> and donÃ¢â‚¬â„¢t know if you should laugh or cry. Almost six years after Rust hit 1.0 an error handling project group is formed. Six. Years. <em>(heavy breathing)</em></p>

<p>Well, okay. At least they are sorting it out now. Problem is, you needÃ¢â‚¬Â¦.<em>SIX YEARS? Are you serious?</em>Ã¢â‚¬Â¦ahem, sorryÃ¢â‚¬Â¦Problem is, you need helpful error messages now.</p>

<p>After reading a few decent blogs on the topic (like <a href="http://www.sheshbabu.com/posts/rust-error-handling/">this</a> or <a href="https://nick.groenen.me/posts/rust-error-handling/">that</a>), there seems to emerge a consensus, at least for libraries: Return something that derives from <code>std::error::Error</code>. Either implement them by hand, or use a crate that does it for you, using macro magic. like <code>thiserror</code>. Which method you use depends on your level of laziness plus your patience regarding compile times.</p>

<h2 id="examples-vs-reality">Examples vs. Reality</h2>

<p>Another post highlighted <a href="https://doc.rust-lang.org/rust-by-example/error/multiple_error_types/wrap_error.html">error wrapping</a>, a particularly intriguing idea to you.</p>

<p>Unfortunately, all the articles have the understandable, but rather annoying tendency to use very simple example code for illustration purposes. Unrealistically simple, you might even say. They have callstacks of depth 1, return only three kinds of error in total in their API, and their errors are obvious and easily describable (e.g. Ã¢â‚¬Å“Input file XY not found in your Ã¢â‚¬Ëœcounting wordsÃ¢â‚¬â„¢ programÃ¢â‚¬ï¿½).</p>

<p>You have a more complicated callstack, with tons of different errors and code reuse in different places. For example, the function you think is to blame for the above error is <code>copy_from_process()</code>, which calls <code>ptrace::read()</code>, which probably returns something like <code>Failed in ptrace::read: Sys(EIO)</code>.
This function is used in multiple places in your code, e.g.:</p>

<div><div><pre><code>Ã¢â€Å“Ã¢â€â‚¬ init()
Ã¢â€â€š   Ã¢â€Å“Ã¢â€â‚¬ read_auxv()
Ã¢â€â€š   Ã¢â€â€š  Ã¢â€Å“Ã¢â€â‚¬ open(format!("/proc/{}/auxv", self.pid))
Ã¢â€â€š   Ã¢â€â€š  Ã¢â€â€Ã¢â€â‚¬ some_parsing()
Ã¢â€â€š   Ã¢â€Å“Ã¢â€â‚¬ ...
Ã¢â€â€š   Ã¢â€Å“Ã¢â€â‚¬ enumerate_mappings()
Ã¢â€â€š   Ã¢â€â€š  Ã¢â€Å“Ã¢â€â‚¬ open(format!("/proc/{}/maps", self.pid))
Ã¢â€â€š   Ã¢â€â€š  Ã¢â€â€Ã¢â€â‚¬ some_parsing()
Ã¢â€â€š   Ã¢â€â€š
Ã¢â€â€š   Ã¢â€â€Ã¢â€â‚¬ some_more_checks()
Ã¢â€â€š      Ã¢â€â€Ã¢â€â‚¬ copy_from_process()
Ã¢â€â€š
Ã¢â€â€Ã¢â€â‚¬ dump()
   Ã¢â€â€š
   Ã¢â€Å“Ã¢â€â‚¬ sections::header::write()
   Ã¢â€â€š
   Ã¢â€Å“Ã¢â€â‚¬ sections::thread_list_stream::write()
   Ã¢â€â€š  Ã¢â€â€Ã¢â€â‚¬ copy_from_process()
   Ã¢â€â€š
   Ã¢â€Å“Ã¢â€â‚¬ sections::mappings::write()
   Ã¢â€â€š  Ã¢â€â€Ã¢â€â‚¬ elf_identifier_for_mapping()
   Ã¢â€â€š     Ã¢â€â€Ã¢â€â‚¬ copy_from_process()
   Ã¢â€â€š
   Ã¢â€Å“Ã¢â€â‚¬ sections::app_memory::write()
   Ã¢â€â€š  Ã¢â€â€Ã¢â€â‚¬ copy_from_process()
   Ã¢â€â€š
   Ã¢â€â€Ã¢â€â‚¬ ...
</code></pre></div></div>

<p>Same goes for opening files, which happens in multiple places (two examples of which are shown in <code>init()</code>), so getting <code>FileNotFound</code> without context is going to be equally fun, and so on.</p>



<p>Wrapping errors still sounds like a nice idea, but one layer alone is not going to <del>wrap it</del> cut it.
Going with <code>copy_from_process()</code> as an example, you see a few possibilities:</p>
<ol>
  <li>Wrapping the <code>ptrace</code> error into an <code>CopyFromProcessError</code>, but that gives you nothing (except maybe some context, if you add some)</li>
  <li>With <code>InitError</code>s and <code>DumpingError</code>s that wrap the <code>ptrace</code> errors, you will still not know which section failed and why, but know if it was during <code>init()</code> or not.</li>
</ol>

<p>You might add context to option 2 as well (see below on how), but each section has a variety of reasons why it could fail. Some unique to the section, some shared among a few, some among all of them.</p>

<p>Complex problems sometimes require complex solutions, maybe?</p>

<h2 id="inc-err-ption">Inc <em>Err()</em> ption</h2>

<p>Using <code>thiserror</code> and the fabulous <code>#[from]</code> macro, you quickly define a plethora of errors and wrappers, starting from the deepest, darkest places in your callstack, wrapping your way up:</p>

<div><div><pre><code><span>#[derive(Debug,</span> <span>Error)]</span>
<span>pub</span> <span>enum</span> <span>PtraceDumperError</span> <span>{</span>
    <span>#[error(</span><span>"nix::ptrace() error"</span><span>)]</span>
    <span>PtraceError</span><span>(</span><span>#[from]</span> <span>nix</span><span>::</span><span>Error</span><span>),</span>
    <span>...</span>
<span>}</span>

<span>#[derive(Debug,</span> <span>Error)]</span>
<span>pub</span> <span>enum</span> <span>SectionAppMemoryError</span> <span>{</span>
    <span>#[error(</span><span>"Failed to copy memory from process"</span><span>)]</span>
    <span>CopyFromProcessError</span><span>(</span><span>#[from]</span> <span>PtraceDumperError</span><span>),</span>
    <span>...</span>
<span>}</span>

<span>#[derive(Debug,</span> <span>Error)]</span>
<span>pub</span> <span>enum</span> <span>DumpError</span> <span>{</span>
    <span>#[error(</span><span>"Error during init phase"</span><span>)]</span>
    <span>InitError</span><span>(</span><span>#[from]</span> <span>InitError</span><span>),</span>
    <span>#[error(transparent)]</span>
    <span>PtraceDumperError</span><span>(</span><span>#[from]</span> <span>PtraceDumperError</span><span>),</span>
    <span>#[error(</span><span>"Failed when writing section AppMemory"</span><span>)]</span>
    <span>SectionAppMemoryError</span><span>(</span><span>#[from]</span> <span>SectionAppMemoryError</span><span>),</span>
    <span>...</span>
</code></pre></div></div>

<p>The fun part is: You have to touch very little of your existing code, thanks to the automatic conversion from one error to the other, conveniently provided by <code>#[from]</code>:</p>
<div><div><pre><code><span>- pub fn init(&amp;mut self) -&gt; Result&lt;()&gt; {
</span><span>+ pub fn init(&amp;mut self) -&gt; Result&lt;(), InitError&gt; {
</span>     self.read_auxv()?;
     self.enumerate_threads()?;
     self.enumerate_mappings()?;
     Ok(())
 }
</code></pre></div></div>

<p>or</p>

<div><div><pre><code><span>- pub fn get_stack_info(&amp;self, int_stack_pointer: usize) -&gt; Result&lt;(usize, usize)&gt; {
</span><span>+ pub fn get_stack_info(&amp;self, int_stack_pointer: usize) -&gt; Result&lt;(usize, usize), DumperError&gt; {
</span> // snip

    let mapping = self
        .find_mapping(stack_pointer)
<span>-        .ok_or("No mapping for stack pointer found")?;
</span><span>+        .ok_or(DumperError::NoStackPointerMapping)?;
</span>    let offset = stack_pointer - mapping.start_address;
    let distance_to_end = mapping.size - offset;
  // snip
</code></pre></div></div>

<p>If you run your test binary again, you now get</p>
<div><div><pre><code>Failed when writing section AppMemory
</code></pre></div></div>
<p>which isÃ¢â‚¬Â¦.<em>(Throws a stack of papers from the desk)</em>Ã¢â‚¬Â¦short. Too short, and not that much more helpful, actually. Well, you know which section is failing. Thats good. But where are all the nice error messages you specified in your errors?</p>

<p>Hm, you do only use <code>println!("{}", error);</code>. Maybe <code>{:?}</code> is better?</p>
<div><div><pre><code>SectionAppMemoryError(CopyFromProcessError(PtraceError(Sys(EIO))))
</code></pre></div></div>

<p>Aha! Now you are getting somewhere! Tiny, tiny, painfully <strong>tiny</strong> steps, but you are getting somewhere! No error texts, but at least a chain!</p>

<p>Normal printing doesnÃ¢â‚¬â„¢t seem to recursively go through all the wrapped errors, but stop at the top most. For this, you need to either go through all the errors yourself by hand, or use a crate that does this for you. There are a number of them that provide this, but <code>anyhow</code> will do (its by the same author as <code>thiserror</code>, so interoperability shouldnÃ¢â‚¬â„¢t be an issue).</p>

<div><div><pre><code>    <span>println!</span><span>(</span><span>"{:#}"</span><span>,</span> <span>anyhow</span><span>::</span><span>Error</span><span>::</span><span>new</span><span>(</span><span>error</span><span>));</span>
</code></pre></div></div>

<p>aaaaand:</p>

<div><div><pre><code>Failed when writing section AppMemory: Failed to copy memory from process: nix::ptrace() error: EIO: I/O error
</code></pre></div></div>

<p><em>Collects papers from the â€¦</em></p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://msirringhaus.github.io/Where-everything-went-wrong/">https://msirringhaus.github.io/Where-everything-went-wrong/</a></em></p>]]>
            </description>
            <link>https://msirringhaus.github.io/Where-everything-went-wrong/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26191006</guid>
            <pubDate>Fri, 19 Feb 2021 08:57:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[12 requests per second: A realistic look at Python web frameworks]]>
            </title>
            <description>
<![CDATA[
Score 267 | Comments 105 (<a href="https://news.ycombinator.com/item?id=26188765">thread link</a>) | @gilad
<br/>
February 18, 2021 | https://suade.org/dev/12-requests-per-second-with-python/ | <a href="https://web.archive.org/web/*/https://suade.org/dev/12-requests-per-second-with-python/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

<article>

<figure>
<img src="https://suade.org/content/images/2021/01/The_Tortoise_and_the_Hare_-_Project_Gutenberg_etext_19993-1.jpeg" alt="12 requests per second">
</figure>
<section>
<div>
<blockquote>
<p>A realistic look at Python web frameworks</p>
</blockquote>
<p>If you take a look around the blogosphere at various benchmarks for Python web frameworks, you might start to feel pretty bad about your own setup. Or, alternatively, super-hyped about the possibilities.</p><p>Consider, for instance, the incredible work of the guys at <a href="https://magic.io/blog/uvloop-blazing-fast-python-networking/">magic stack</a>, getting <strong>100,000 requests per second</strong> from <a href="https://github.com/MagicStack/uvloop">uvloop</a> in a single thread. This is on par with compiled language like Go's performance.</p><p>But that benchmark doesn't really cover a fully fleshed out web framework, right? We need a lot more functionality and structure from our frameworks than reading and writing bytes. What about fully fleshed-out web-frameworks in python?</p><p>One such framework is <a href="https://github.com/sanic-org/sanic">Sanic</a>, which again has been shown to have similar performance: <strong>100,000</strong> requests per-second. Or there's <a href="https://vibora.io/">Vibora</a>. Not only does this claim to be a drop-in replacement for <a href="https://github.com/pallets/flask">Flask</a>, but it also has its own templating engine. And it handles <strong>350,000 requests per second</strong>!</p><p>Even more mind-blowing is <a href="https://github.com/squeaky-pl/japronto">Japronto</a> which claims an insane <strong>1.2 million requests per-second</strong> in a single thread ğŸ¤¯ trouncing the performance of other languages and frameworks:</p><p><img src="https://raw.githubusercontent.com/squeaky-pl/japronto/master/benchmarks/results.png" alt="https://github.com/squeaky-pl/japronto"></p><p>Recently we've been doing a lot of work improving the performance of our Python APIs. Currently we're running <a href="https://github.com/pallets/flask">Flask</a>, and we initially had a single question: <em>how can we serve more requests from a single worker thread? </em>But looking at these benchmarks had us asking more:</p><ol><li>Can we meaningfully compare them to our setup?</li><li>How realistic are they for a full production application?</li><li>Would we be better using one of these frameworks over Flask?</li></ol><p>In other words, how much should we trust these benchmarks? And to what extent should they influence our choice of technology?</p><p>In order to answer these questions, in this post, I benchmark a realistic Flask application along with it's <a href="https://github.com/sanic-org/sanic">Sanic</a> equivalent. I'm going to guess that most readers come from a background with one of the more "traditional" Python frameworks (<a href="https://github.com/pallets/flask">Flask</a> or <a href="https://www.djangoproject.com/">Django</a>), and it's certainly more relevant to devs here at Suade Labs. For this reason, I run the Flask app in a number of different ways, to see what the best bang for our buck is: how performant can we make our application with (almost) zero changes to the code? Along the way we'll pick up some tips for the original question: <em>how can we serve more requests from a single worker thread?</em></p><p><strong>Sidenote: </strong>if you're new to Python's web frameworks, or its asynchronous libraries, take a look at [1] from the addenda at the bottom of this post for a quick explainer. This post mostly assumes you know these things.</p><h2 id="the-baseline">The baseline</h2><p>First let's run some simple "Hello, World!" benchmarks on our system to get a meaningful baseline for comparison. For reference, the Flask benchmarks on <a href="https://www.techempower.com/benchmarks/#section=data-r18&amp;hw=ph&amp;test=fortune&amp;l=zijzen-f">techempower</a> give 25,000 requests per second.</p><p>Here's our Flask app:</p><pre><code>app = Flask(__name__)

@app.route("/", methods=["GET", "POST"])
def hello():
    if request.method == "GET":
        return "Hello, World!"

    data = request.get_json(force=True)
    try:
        return "Hello, {id}".format(**data)
    except KeyError:
        return "Missing required parameter 'id'", 400</code></pre><p>I ran it under a variety of conditions. First "raw" via <code>python app.py</code>, and then under <a href="https://gunicorn.org/">Gunicorn</a> with a single <code>sync</code> worker via <code>gunicorn -k sync app:app</code> and finally Gunicorn with a single <a href="https://github.com/gevent/gevent">gevent</a> worker via <code>gunicorn -k gevent app:app</code>. In theory Gunicorn should handle concurrency and dropped connections much better than the raw python, and using the gevent worker should allow us to do asynchronous IO without changing our code [2a]. We also ran these benchmarks under <a href="https://www.pypy.org/">PyPy</a>, which in theory should speed up any CPU-bound code without making any changes (if you haven't heard of PyPy see [2b] in the addenda below for a quick explanation and some terminology).</p><p>And what about Sanic? Well, here's the "rewrite" of our app:</p><pre><code>app = Sanic(__name__)

@app.route("/", methods=["GET", "POST"])
async def hello(request):
    if request.method == "GET":
        return text("Hello, World!")

    data = request.json
    try:
        return text("Hello, {id}".format(**data))
    except KeyError:
        raise InvalidUsage("Missing required parameter 'id'")</code></pre><p>And here are the results:</p><figure><img src="https://suade.org/content/images/2021/01/hello_world-3.png" alt="" srcset="https://suade.org/content/images/size/w600/2021/01/hello_world-3.png 600w, https://suade.org/content/images/size/w1000/2021/01/hello_world-3.png 1000w, https://suade.org/content/images/2021/01/hello_world-3.png 1161w" sizes="(min-width: 720px) 720px"></figure><div><p>Some technical details: I used Python 3.7 with the regular CPython interpreter and Python 3.6 with PyPy 7.3.3. At the time of writing, running 3.6 is the latest PyPy interpreter, and their Python 2.7 interpreter is faster in some edge cases, but as Python 2 is <a href="https://www.python.org/doc/sunset-python-2/">officially dead</a>, I don't believe it productive to benchmark. My system details are available in the addenda [3]. I used <a href="https://github.com/wg/wrk">wrk</a> to actually execute the benchmarks.</p><p>I'll break the results down in two parts. First: Sanic dominates, with 23,000 requests a second, although running our Flask app under Guncorn + gevent and PyPy does a pretty good job at keeping up. Second: what's going on with the performance range for our Flask app?</p></div><p>Under CPython, we see that using Gunicorn quadruples the number of Flask requests per second from 1,000 to 4,000 and using a gevent worker adds a mild (sub 10%) speed boost to this. The PyPy results are more impressive. In the raw test, it is churning through 3,000 requests a second; it received the same 4x speed boost from Gunicorn, getting us to 12,000 requests a second; finally with the addition of gevent, it cranks up to 17,000 requests a second, 17x more than the raw CPython version without changing a single line of code.</p><p>I was quite struck by the fact that gevent had such little effect on the CPython process - probably this is because the CPU is maxed out at this point. On the other hand, it seems that PyPy's better speed means it is still spending time waiting on system calls / IO, even under Gunicorn. Adding gevent to the mix means that it switches between concurrent connections, processing them as fast as the CPU will let it.</p><p>To get a real sense of this, I ran the benchmark whilst monitoring CPU usage. Here's a short test against the raw app under PyPy:</p><figure><img src="https://suade.org/content/images/2021/01/sync_cpu_usage.png" alt="" srcset="https://suade.org/content/images/size/w600/2021/01/sync_cpu_usage.png 600w, https://suade.org/content/images/2021/01/sync_cpu_usage.png 919w" sizes="(min-width: 720px) 720px"></figure><p>You can see that the program hops between CPU cores and rarely utilises 100% of a given core. On the other hand, here's part of a much longer test against the Gunicorn gevent worker under PyPy:</p><figure><img src="https://suade.org/content/images/2021/01/gevent_cpu_usage.png" alt="" srcset="https://suade.org/content/images/size/w600/2021/01/gevent_cpu_usage.png 600w, https://suade.org/content/images/2021/01/gevent_cpu_usage.png 900w" sizes="(min-width: 720px) 720px"></figure><p>Now it's evident that there is no switching between CPU cores (the process has become "sticky") and the individual core is being utilised to a far higher degree.</p><p><strong>Key takeaways</strong>: Sanic wins. PyPy is fast. Run your "traditional" app under Gunicorn.</p><h2 id="realistic-benchmarks">Realistic benchmarks</h2><div><p>The benchmark above, while fun, is pretty meaningless for real-world applications. Let's add some more functionality to our app!</p><p>First, we'll allow users to actually store data in a database, which we'll retrieve via an ORM (in our case <a href="https://www.sqlalchemy.org/">SQLAlchemy</a>, the de-facto stand-alone ORM in python). Second, we'll add input-validation to make sure our users get meaningful error messages, and that we're not accepting junk that crashes our app. Finally we'll add a response marshaller to automate the process of converting our database object to JSON.</p></div><p>We'll write a simple book store app, for a publishing house. We have a number of authors each writing zero or more books in several genres. For simplicity, each book has only a single author, but can have multiple genres - for example we could have a book which is in both the "Existential Fiction" and "Beatnik Poetry" categories. We're going to add 1 million authors to our database and roughly 10 million books. [4]</p><p>Our SQLAlchemy models look a little like this:</p>
<pre><code>class Author(db.Model):
    id = db.Column(UUIDType, primary_key=True)
    name = db.Column(db.String, nullable=False)
    ... # snip!

class Book(db.Model):
    author_id = db.Column(
        UUIDType, db.ForeignKey("author.id"), nullable=False, index=True
    )
    author = db.relationship("Author", backref="books")
    ... # snip!
</code></pre>
<p>To marshal these, we use <a href="https://marshmallow.readthedocs.io/en/stable/">Marshmallow</a>, which is a popular Python marshalling library. Here's an example of the Marshmallow model for the Author overview:</p>
<pre><code>class Author(Schema):
    id = fields.Str(dump_only=True)
    name = fields.Str(required=True)
    country_code = EnumField(CountryCodes, required=True)
    email = fields.Str(required=True)
    phone = fields.Str(required=True)
    contact_address = fields.Str(required=True)
    contract_started = fields.DateTime(format="iso")
    contract_finished = fields.DateTime(format="iso")
    contract_value = fields.Integer()
</code></pre>
<p>In our endpoints these are used for validating input and returning results like so:</p>
<pre><code>@bp.route("/author", methods=["GET", "POST"])
def author():
    """View all authors, or create a new one."""

    if request.method == "GET":
        args = validate_get(marshallers.LimitOffsetSchema())
        limit = args["limit"]
        offset = args["offset"]

        authors = Author.query.limit(limit).offset(offset).all()
        return jsonify(marshallers.authors.dump(authors))

    if request.method == "POST":
        author = Author(**validate_post(marshallers.author))

        db.session.add(author)
        db.session.commit()

        return jsonify({"id": author.id})
</code></pre>
<p>The full source code can be viewed in the <a href="https://github.com/olliemath/async_python">GitHub repo</a>. Here, the thing to note is that <code>marshallers.foo</code> is an instance of a <a href="https://marshmallow.readthedocs.io/en/stable/">Marshmallow</a> schema, which can be used both to validate a Foo input, for instance in a POST request, as well as to marshal Foo instances ready for returning as JSON.</p>
<p>In order to actually perform asynchronous database requests, some fancy footwork is required with patching libraries, which depends on which postgres connector you use. SQLAlchemy does not support this out of the box, and in fact its primary developer has a great post arguing that <a href="https://techspot.zzzeek.org/2015/02/15/asynchronous-python-and-databases/">an async ORM is not always a great idea</a>. Juicy technical details in addenda [5], but beware that just using a Gunicorn gevent worker will not necessarily get you what you want.</p><p>PyPy tends to suffer a performance hit when using C-extensions and libraries instead of pure python, conversely CPython should get a performance boost from the C-based libs. To take account of this I tested two different underlying database connectors: both <a href="https://github.com/psycopg/psycopg2">psycopg2</a> and a â€¦</p></div></section></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://suade.org/dev/12-requests-per-second-with-python/">https://suade.org/dev/12-requests-per-second-with-python/</a></em></p>]]>
            </description>
            <link>https://suade.org/dev/12-requests-per-second-with-python/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26188765</guid>
            <pubDate>Fri, 19 Feb 2021 02:21:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Dismantling Racism in Mathematics Instruction [pdf]]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 3 (<a href="https://news.ycombinator.com/item?id=26188717">thread link</a>) | @kofejnik
<br/>
February 18, 2021 | https://equitablemath.org/wp-content/uploads/sites/2/2020/11/1_STRIDE1.pdf | <a href="https://web.archive.org/web/*/https://equitablemath.org/wp-content/uploads/sites/2/2020/11/1_STRIDE1.pdf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>Ã¥,Â®kÂ´yX=â„¢:Â§â€™Ã‹Â§fâ€¦-@rÃ¯P
Â¢â€
Â´Å¾Ã’Ã›â€ ~hÃ”AÃ™â€œo
UÃsÂ»Ã‘Â²@mÃˆ3Â±lAÃ™Ë†2@XÃ¥Ã¸Â©1MÃ²H&amp;ï¿½Ã‚	TÃ–Ã—Â¹Ã¤Å“ Â¡Ã¨Â¹
ÃšÃ¶Â²Â±Ã™Â©Ã–CÃ…]Ã¶Ã‡Ã©â€šÃ– Â§&nbsp;VECÃÂ£CTÃºÂ£Ã³Å¾\Ã‹â‚¬!ToÃ„SL#Ã¢	y(7^Ã…2
:ÂºdÂ¥Ã—a$}AÃ¥â€¹Â¸Ã£gBERÂº Â£â€¦Â²Ã·Å’Â¥=Â¤â€â‚¬â€|Ã—â€œÂ¦l&nbsp;aÃŒâ€Å“â€¦T1
Å¡Â­hâ€ºâ€¢Ã‘ÃƒÃ·Â­Ã•U=Â¦â€“vâ€ºÂ§Ã¨
Ã²P.	Â¹7Ã˜Å½!ÃÃ”JEÃºÂ¾|*Â½Æ’Ã¹â€šÃ³â€šJï¿½Âµâ€œÃ“ÃÃ±Ã’+Ã¤HÃ¾{M~Ã’&gt;Ã»Ã­Â¾#5â€¢&nbsp;â€°Â¥Å¡Ãšâ€°.^â€˜ÃºÃ”Ã§	9#G~â€™Ã¹TÃ´KÃ˜Ã¿Â¨	Æ’	ï¿½â€¹ËœÅ¡BNâ€ SÂ§Â´BÂ©Â¥cs6HCÃ•2Ã‘VÂ·Ãµ'_QÃ¿XÂ»Ã²LÃ’u_	â€”Æ’)Â²lÃ»â‚¬fÂ½Ã¯Å½Â£Ã„c Ã¤â€ºYÃ›Ã’ÃªÃ™,uÃœbjÂªLÃµcÅ’Ã Ã¯Ã»<rf8jâ€œ3Â¹'yÃ—Â³ÃŠz2ï¿½):8gl{bucï¿½Ã…:Ã¨Å Å¾Å“â‚¬â€™*eÃ†2ÃÃºv9ÃµÂ¦;@Ã¬qÂ¥ï¿½bËœÃÃŠÂªÂ©zÂºÂ©Ã‘ Ã¤8vÃ¤tÂ°wsqÃc!fÂ¯â€zsÃ•Ã¤ï¿½{Â¸}Â°Ã¹Ãƒâ€œ="Ã­ÃšÃ»Ã²FÃªÃŠâ€”:cÂ¤&nbsp;O&quot;Â¶UÃ€H8Â»/Â´Ã®AÃ·ÂºÅ’Ã¢&amp;ÃÃ†kPÂ°\â€™Â¹Ã‰(â€¢Ã•$Ã¡#Ã»TÃ£4Ã“Å’;']â€¦&quot;_Ã‡Ã«$â€¹â€˜ï¿½Â²Ã­FKÂ½;0iÃ¢Â¸Ã YÃ´Ã¶m){Ã²h0" â€“qÂ»'$Â·zÃ¦bÃ¶â€°Â´ÃœÃ°.Â¹!Â¢k]Ã²sÃ!Ã‹!!oÂ¤Â¥Ã´Ã‘Ã°ÃÃ©&Ã¨1%mÃ´Â¤â€˜fzÂ©="" yÅ¾="Câ€œï¿½7Ã£Å¡ËœpSÃ”Â¥" Ã´fÂ½`b5ÃÂ¼Ã“udÂ²pÃ›Ã…Å¸#Ã¤ï¿½9Âª^Â¦Ã–vmÃ‘xâ€Â¹Å“Â Ã‘Ã¯Æ’â€“'â€¦="}Ã¸QPÃ·Ã¤<`9â€“Ã…Ã­,ÃqÂ®|ÃÂ²Ã‚AÂ©â€¦Â«Ã´{â€”Ã‹â€ÃœÅ¸ÃƒKÂº<Ã–,ÃJ2%&nbsp;ï¿½.dumÂ±ÃŠÂ¢â€°<â€¡â€ºâ€¢Â·Li+â€™+ÃŠ1Ãªï¿½Ã“Â²â€šÃ¶ÂµÃ–?ÃŒâ€˜sYuÃµÃµyk|ÂµÃ“Â¤\Ã‡Â±Lâ€¹Ã‘Eâ€¡ÃµÃ¶" Ã¤lÃŒÃ…Ã¹8Ã“Å¾â€œzuÃ»3ÃŸÃ™vÃ²Ã…#Â°}Ã„Ã¤â€ kÃ¥sgÂ¯Â¬Ã^Ã¤ÃÂ¨Â²Å¸d5Â©_Ã¼rÂ»â€a="" uÃ’dnÃmÆ’tË†Ã­Ã\Â­Â¹(pr.Â¼"ÂµÃŒiÃ•<Ã–qÃ»"Å Ã¦kÅ½Â¨Ã–ÃsÃâ€œÃŠâ€˜Ã¶Â±Ã²hÃ–Ã’Ã›Â¥<xcÃ¸(`="" Ã«Â¥â€™*iÃ‚yÃ¶Ã—:ÃŒâ€”[49rÃ­Â±%="" uwÃ±Ã¦oÂµsâ€¢â€™0â‚¬8â€ â€ºËœÃ•Ã‘Ã¤yÃ´â€šÂ¦[!â€“gÃ‰Ã—Â¼Ã–ÃˆiÂ«Â¿Ã»qâ€šÃ»Ã½?Ã§â€ idÃµâ€œï¿½Â«vÂ«jqabâ€¹"Â¨Ã–0Â©Âµ\Â²j?(Ã‘.ÃŒÃ‘#Ã¤Ã¡\Â«]$Ãâ€°{="">:Âªâ€“R[m{Ã¯c
#Ã¤ÃŒHÂ´A`jm_&gt;MÃ‚ï¿½{ÂµÂ¤}ÃƒTBÂ¹Ã±ÂªÂ²ÂºÃ¥ï¿½Ã‰ÃÃ¸Ã±_//?Ã¼Ã¦Ã¿Â³OÃ¿Ã€Â£`Ã§Ã’Ã·J3â€¹Ã¶SÂ·Ã¼ï¿½Ã“â€¦Â¢ÃÂ¸Ãâ€“DÃœOcÃ¾ÃÃŸÃ¼Ã»oÅ½ÃÃŸâ€¦ÃŸÃ½)Ã¼â€Å¸ï¿½Ã¿ÃºÃ¡Ã‡Â½Ã’Ã³â€¢ÃªÃ‚pÂ¡_Â¨â€º|ï¿½Ã‡Å¡GÂ½VRsÃ¤Âµâ€”Ã„-AÃ¤Ã¼Ã¾Â»%&gt;~ÃºÃ¸Ã«Ã·Ãâ€¡ï¿½Ã¯Ã¿|Ã»Ã¯Â¾Ã—c8â€“ÃµNÅ¸Ã°Ã«q}bwâ€¹Â¾Ã¶Ã©Å½Ã‡Â¢Å¸Ã¿â€œÂ¿?Â¼hxÃ¹Ã›OÂ¾Ã¯BÃ¸Â®DÃ½5Ã‡Ã¾Ã£iÂ¯yÂ²Å’qï¿½`.{ÃŸÂ­â€œï¿½â€K#Â±JÂ¹Ã‚Y*Â¦@LÃÃ¦Â¥Ã—Ã€Ã¯~Ã¹Ã°Ã²Â¾Å’?Ã¼ÃºÃŸÃ¸Ã®ÃƒgÃ½Ã©Å¸Ã¿Ã´â€”Ã°Ã½Ã‹Ã±â€¡Ã°Ã¾Ã³Â§OÃ¡â€”mÃ¸Ã³3^Ã¼Ã R/!Â¡iÂ¾ÃŒQRE?Ã”Å¾â€¹Âµ7_Å’Ã«Ã‹Ã¸Ã¿Â³_Â¶Â°q3AÂ¶VÂ£( Ã€
	
2+
â€¹Å½W:Vx 8Â¸Ã¸T\Ã¼Ã¡Ãª``Ã Â±â€™â‚¬TÅ tUÃ•Ã¼Ã˜Ã»ï¿½Ã­Â³Â½Â»Ã]Â¯vÃ§â€™ÃÂ£Ã¶ÃÃ?Ã»&amp;Ã¯Â»3Kâ€“Ã±ÃŠÂ¿&gt;â€¹Â¾Â¿Ã¦â€”Ã§Â¿8Å¸EEÂ³ÃªË†ÃœYâ€˜5Ã®â€”sË†Å¾N#XÃ¥Â·gÂ·Ã¼Ã¹ÃÃ›{Â¡Â¥ÃµÃŠâ€™YÃ‚Ã„Ã¾Âªï¿½5g-$Ã¶=`Ã¶pzÃ„Ã¹Å¸â€ºÃÃ¸Ã¶Ã¼p{zEOkï¿½%vâ€¦OeÂ³eÃ†Å¸Å Ã›tÃ‰_gÃ˜Â¿ÃbÃSÃ	&nbsp;n+`ÃªTh2Â¯:ÃªÃ‘Â»Ã¯DC`Ã³xqâ€”Ã‰Å Ã¿Ã¹ÃµÃ¼Ã«Â­Ã‘eÂ¶Ã¸uâ€™Ã¾nÃ¹*Â¹9Ã†Ã¾%Â£ï¿½ï¿½Âªâ„¢n:ÃŠÃ½9@+Ã·Â¦BcÂºÂµÃˆxÂ¼h5oÂ·Ã§wâ€°ÃšÂ°Ã„Ã¾!~(â€™aâ‚¬%Ã‚ï¿½Ã­ÂªÂªâ€”Ã„Ã©ÃÃ²GÃ›&nbsp;Â¶â€œ?Ã‹.Ã±;Ã³Å Ã½[Fï¿½(Ã·,ÃŸÃ€Uâ€˜3Ã¡Â³Â¼Â¬Â´Â»Ã»Â«'ï¿½â€“DÃ•Å’Ã„Ã§6Â³5ÃfbjÂ®Â²Ã®lÃÆ’Ã»Ã·Ã˜â€°Ã]vu5YÃµÂ¬Ã’oÂ­ÃµÂºÂªO
PNÃ–Å“Fv7Â­Ã´ Ãµ[ 7xâ€šMhâ€¡â€šÃ¯Â«Â»eÅ’Ã½Â«Ã¼Ã²)AÃ’$kï¿½Â®Å½Uâ€˜$H=oIÃ¤%Ã€Â¼Ëœiâ€œDÃ‰Â¾Ã†Ã˜Â¿Ã‹LÂ¥CU~Â¶Ã³mÃ“Ã‡Ã¢Ãªâ€š5evPÃ·~Ãµ@Ã‘^Ã”.â€¡ÃÂ¿uÃŠ Â¦&amp;Ã·Ãƒâ€“yâ€rÃ¬65M!$Â¥Å Â¢ÂªÃ¾â„¢2*Ã’ËœAÃˆ5\`-Å¾ÃˆÃ8]pÂ¾L|X"ÃÃ°wg	MQ#Â¦h5WÃ‚Ã™ÃµÂ­xÃ€ï¿½Â¦*â€”Ã–#1!&gt;ÃŒÃÃ°â€šÃ½Ã³ÃŒÅ’Ã™fÃ‹Â¹Ã¹Aâ‚¬)mÃ‚H9DÅ¡Ã¯Ã‹Ã„Â¢8ÃÃ°bÃ¢â€°Æ’Râ€7NRÂ¿â€“Ã wÃ˜?Ã‘â€°Â¦Ã’pÃ’Ã¬â€ï¿½Å¸ [Â¥â€¢Â¥Ã¥ i=hÃ»/qÃ•9Ã¹Ã/Å¾Ã`Ã¿@'ZÃ•ï¿½Â®Â»Ã¸â€Ã´BoÃ©i
TiÃ”RhgÅ¾Ã–	C}Å¡yÃ¼Ã¬Ã›/â€¡UÃµÅ’Ã¼[{Â¡{YÃ–Ã¶ÃnSÂ´-xÂ§ï¿½$ÃŠÃÂ­ËœÃ„Ã•0ÃÂ£â€ºÂ¶7Ã„7ÃƒÃ±Ã®Ã»(J~Ã»6Ã„â€“Ãrï¿½Ãº{Ã»Â¢
_-â‚¬â€~E&nbsp;Ã€&nbsp;Ã²Æ’yÃ©RÃÂ»ÃÂº'VFÂ¶Â¤O^Ã°Ã‡Ã©ÃÃ¶Â°ZÃÅ¸Ã·Â¾ï¿½5Â«sÃ¬_Ã­DSÂ¹&nbsp;Ã®Ã³Ã…Â¡"â€“Ã»ÃµÂ»;hÃ³f]8i&lt;Ã•QÃ—c8_Ã±pVhÃ˜Ã¾Â¥9ÃÃ–IÃ·Ã†Ã…&nbsp;Ã¹Ã’ÃcuÃ«XXZÃ…tÂ¤hÃ¾Sâ€™Ã°ÃƒÃ¹UÂ¢RÃ’Ã±Â°ÃÅ Ã¯[Ã¬Â¤KhÂµ6Ã¹Ã€]Â½Ã›â€˜â€°t'ÃµQfÃ°Ã»â„¢n6Hâ€“Â¨Ëœ`GaÃšBGtâ€¦xÂ¼Â¨Ã«Â¯ÃšÃBÅ“7Å½&gt;Ã’Â¾AÃ”Ã‹â€¡DÃƒÃ‘%Â²Â¶Â¬oÃ¶Â¯tjÃ“Ã¨â€¹Ã•zÃfï¿½Ã¤Â±Ã…oËœÃÃ‚PÃ¥ehÃ›$x/,Â°DÃ‰zï¿½Dy[iâ€°Âµ(Ã½!Ã’â€¢TÃ‚Ã™@Ãˆ:(vpsÃ¹Â¦?Ã¾`[aKÃ¶+}Ã™Ã°5v,Ãœ`Å¡+Â±Â¥jÂ­T^Â¶Â±RÃ°Â±nÃ…jdÃµ%Ã•OFHÃ¨~x~Ã…Â¶Æ’v4Â¨uÂºÂ¶râ€°â€¹;Â¥Â²*Ã¯â€œÂ¼\*Â®]Ã’K~Ã¨ï¿½e?Â¸-GÃ´bÅ¾bÂ»@bÂ¿ï¿½Ã‚fuÆ’4Vuï¿½\Â©Â«ÃŸÂ±Ã”Ã…ÃªSÂµD9cNâ€œÃ›Ã™ÃŸÃ¼Â­bÃ¤Â¨tRnÃ&nbsp;â€”!Â«Ã¤)PÃ²\ÃÂ¼Â²Â¤:bÂ±SÂªÂ»Ã‘;â€š|Ã’â€ºÃ³Â¶	T.Â°CbÃâ€“!@Â¾lj$ï¿½Â»â„¢vÅ Â®)Â¿Å½ï¿½Ã¯Ã¢ï¿½eEâ€¡.Â¢Ã¡Ã¸Ã³-Â¶Tâ€“Ã˜AÃ‘#Vt6uÃ…Ã‚5Ã‹Ã¥ÃÃ²â€¦Ã²Â«m7TKï¿½fÃ¯ÃŸÂ¶Ã…Ã€ÃšKu&gt;Ëœ?
'Â³oÃ»U7Ã¥$Ã±Ã¶Ã…Â°#cGÂ¯?ÃÃ¾_Â©Âª{â„¢#Ãµâ€”â€”ISâ€¡
â€ÃŒÃ¢ÃŠÃ‘MÃ­]Å½(Â¸Ã§Â§IÃ·Ã»#QkÂ¶&lt;8ÃªM&gt;[Ã˜eÅ¡H&nbsp;râ€¡X(9Ã–JD?Ã¦â€”Ã‰lÂ½9Â¢ ]Ã¤Â©biÃ‹Ã&nbsp;â€˜Ã¦Â®i[?uW&lt;&nbsp;9Å¡~Ã™Æ’ Ã£tÃ²Ã©"Â½N~Â¼bkÃŸÃˆrÃÃ²â€]R,Ã¯râ‚¬q4ÃˆÂ½Ã‚8hÂ¬Â¡sâ€¡`
h.Â¼*Â¡Ã¥0^&gt;Ã¾Â¾Ã§Â±â€¦o!]`GÃ‰Å &nbsp;Â»Ã³â€šzWï¿½gÂµâ€¹Â¤Z(O:]kÂ¥NÃºÅ¸â€ CÂ¾Ã,Ã˜Â¢Ã¯Ã¤Ã¾NxÃŒ23Â«_Å¾ÃƒL=â€¡Ã½â€™Â¾OÃ Ãª'Ã§Ã™Ã½&gt;Â§Ë†â€™tâ€°*YÃœm:â€ÂªÃ©nÂ­Ã²7HyÃ„Ã´9Â«Ã˜_â€šÃ¨fï¿½akÃâ€¢Ã¬Ã¾M)Ã¬Â¶aâ€“Â»Å“xÃ¸Ã›â€œ0Ã‡Ã–y?Ã¦Ã³;b*ÃÂ»rkD,Â¶0yÂ«Â§â€ Â®â€¡RÅ¡Ã…Ã‘â€ºI;Â²Ãµjâ€¦Â®Ã²aÃªQ@ÃŒÅ¡Â¹`Ã­%&lt;Ã°Ã–QpÅ¸Å“aÃ‡Mâ€¹ ÃšÂ¸jï¿½ÃÃÅ’Â±Ã¤ï¿½Ã–â€™Â¶|ALÃŒÂ¶Â¼â€™bNA=hwÃ·ÃºÅ 5Ã‰AÃ‘Â¼Â¨Ã²Ã5Ã€Ã®Â²?tâ€“Sâ€#	Â¶Â¶â€¡Ã²Ã§Ã¯ÃŸÃ¯Â¡Ã¥Ã¨Ãš.ÂªoÃ¤uÂ½;â€™fÂ¸ÃºVÅ¸CÃ€â€“Ã¶`Â¶%ÃŸÃµ]Â°09iMw0MlÂ·kqÂ«EÃŠTOy[Ã™cxÃ¾yË†&gt; Ã¯Ã»b&gt;0gâ€vÃ…W6HÃ£Ã¬Â«Ã½xÂ³uSÃ‰Å¡Ã…Å½&nbsp;R)ï¿½â€°8H_Ã¿Ã«VdrÂ±5^Ã @&amp;qeÆ’-ÃªÃ‘câ€¡ÃBÂ¡Ã«\Ã¡zâ€Ã–â€¦Ã’Ã™Â­hRÃ¼$Å“`Ã‹y&gt;ÃŸ=bGÃ’â€š&nbsp;UfÃ¬1Å½Qâ€ ZÂ½Ã“ÃEtÂ²Ã†VÃ³T&lt;=-CÃ‡ÃÂ®<vÃ¼â€¡Ãºâ€ Ã©'â€°ï¿½k]â€“'ÂªÃ¨|9Ã‚ÃˆÂ·[ÃŠr"bâ€ #Ãƒâ€œ[mÃµÂ¦_ql]yÂ¨Â¾Ã‰Â½9ÃƒvÃ±Â¤<\Â­ï¿½#(â€°Å½ÂµzÂ¤qÃ¹â€˜b>Ã¨Â°$Ã›Ã¿Ã›Ã»Ã„ÃµMË†Ã<cÃ‹xj>!Â´Âªoeâ€™ÃÃ†"eÃˆÃ&nbsp;TÂ¨Å“dÂ´(Câ€°&gt;\Â¾;KÃ°02Â´%Wâ€œZÂ¯Ã¨Â´Å¡f%â€ Ã©Ã‰Â°Ã¬ï¿½â€” â€˜kmÃ©_BÃ»Å½Â³ï¿½â„¢DÃ²Ã¤Å¡~Â°Ã‡;lÃ»=Â¬Ã’â€¢)mÂ©~Â°Ã£Ã-â€â€ Â£â€”[Â¾Ã“Ã³p|ÃˆÂ¢8hÂ»ÃµÂ©ÃŠÂ¿uï¿½PÃ®ÃªÂ«Â¤Ã—Æ’Ã‰(Ã£8â€¹Â¢Ã˜Ãºï¿½Å¾O|v:â€™&nbsp;Â£E&nbsp;LÂ½S=Ã“ÃŒï¿½ï¿½â€”%CÅ’Ã¤Ã¦1Å¡?bxzÅ¾Ã¹Ã¦<dÃ›:â€ÃªsmlÃºryÂªÃ¯ï¿½b Ã‘Ã‰Ã_lÃ½zaâ€ z-a;â€”="ï¿½]#Ë†Ã±|XFÃ‘Eâ€ Â­^Ã¼]ï¿½Â¤iÃ“â€”Ã¤Z1Wi#â€°Å¾CvÃ°ÃŒbï¿½bkÃ—Yzwâ€°Ãš0zEâ€6â€œÂ¯@vÅ½Ãâ€°yYbÂ³Ã¥[Â¾">ÃˆÂ®ï¿½Â±CÃ«â‚¬Ã–-PÃŠÂªÂ»VÂ·q&amp;1Ã¼Ã¥]fâ€°Å“oWÃ˜Ã5&nbsp;Ãˆ9ÃŸÃ¦EH6&nbsp;M?$ï¿½â€“Ã˜Ã‚ÃµÃˆ+vâ€{Â°â€œÂ¾ÃƒÃ¦ÃTâ€”ï¿½kÂ¦Ã¢cÂ´LÃâ€™Ã·l	Ã¾Ã¥1Â¾Ã²Ã†oâ€â€“â€°mÂ¬4â€¦ËœÅ¾ÃWkÃ¾ryï¿½Â­ZÂ¯dâ€ºÃ™Â§)cÃ¦ÂªFâ€”qÃ­1Ã–Ã¡Å¸KÂ¾=DÂ¼Ã›sDÃ…Ã¢;Ã-XY
=â„¢Ã…Å¸Â±Ã•â€?WÃb	Fï¿½ÃªÃÂ¦Ã³â€šEÃ¬GÂ°Â¼Ã¡ÃŒÃ¥olÂ¹â€ !ÃƒÂ´hÂ®vw&nbsp;f[Ã‚Â¾.YÂ¤?â€¹[Â¬Ã¾Ã™â€”8Â¿Ã°BiÃ¯vÃ•&nbsp;ÂºÃ¡'ÃµlR12lÂ½Ã Ã¶rÂµÃ¼Ã '|VÃ½j:k'x)qÃˆMSâ‚¬-Ã—dÃ.â€“ÃŸÂ£x.Â®=Ã”Ã©&lt;Â´{ ybÂ°Ã¥Å’Ã´.Ã,Â°Â£mâ€/V	;Ã†yâ€”lÂ¥dÃµâ€°sÂ¤(Æ’rÂ§ÃÃÂ¡uÃ€Â°TWâ€“|@Â©bÃ˜:
ÃˆbÃ»?[ÃºÃ¥)6SWÃ„ÃºÃ Ãâ€¢$ÃƒOË†Ã„Ã˜B
GZ|^ÃªÂ¨}ZMÂ¦Ã•AÂ¾5\Ã½AÃ–ip&gt;c\ÃªOÂ¡ï¿½$ï¿½ÃŠ/lï¿½&amp;Ã†Â¸â€¢fÃ«wpÂ´.Ë†)xÃ€Ã–h`Â¯Â°CÃ®Â´Â´ÃYUÃ£Ã¹Ã—Â²Ã„Ã“,L\Â­Ã¢Ã•oÃ«ÃŒÃÃo1b0GÃ˜
Lvt<y ;dÃ©ÂªÃ™zsÅ¾cvËœÅ¾Ã£glï¿½â€ fï¿½Ã²ÃˆÂ¦dï¿½'Ã»8Ã±Ã¼[Â¡ÃÂ¹Å¡:â€ Â Â½$Ã(Ã™?â€”$8Ã‡Å½ymÃ‹@ÃŒzï¿½!â€šï¿½aÃ«ï¿½$hdu="" Ã´wlÃ¸$ï¿½iÂ°Ã¥â€°Ã‚â€tâ€¢Â¯6Ã¬fï¿½Ã˜"ÃœÂ¬Â¶:Â§q7â‚¬Ã“â€¢Ã“Ã²$â€¦â€¡ï¿½[â€ºhÃ¸lÃ¿"Â¨<â€ºtÃ¼dÂ¤~â„¢ckâ€¡â€¡â€œÃ·$â€wÃ´sÃÂ¹ÃºgÃ‹&Ãbâ€¡Â¾Â£ÃŒÃ»gÃ‚ï¿½yÂ¶Ãâ€“&qÃ´1\Â uÃº6iâ€ºÂ¶|lÃ˜ÂºÃ„Ã£="">Nn}â€¡Ã— Ã®~Ã 6\cï¿½lsÃ¬%Â¤ÂªÂ¼Fâ€”9Â¤Ã—&nbsp;,Â±â€¦â€°Å OL
Y"(	Â¶*QÃ¹4Ã–Â£Ã“â€[â€“Â¨`GÂ¿?â€2Â¼sâ€¦Â­JTÃ¾cÆ’Å’GÂ«â€ºÃ¬Ã¡lUbrÂ®â€“Â±Ã‰wÃ[ï¿½Â¼ï¿½-KLfÃ¡Ã‚Ãœ[Ã&nbsp;|ÃËœcÃ«â€˜Ã•Ã¸Ã°9Ã®Ã°zaÃ·iÃ¶b3l]"â€™.â€œâ€˜Ã‘Æ’ÃºCjâ„¢â€™8?Â°uâ€°ÃŠÃ£ ^Ã’Ã»&gt;Æ’-J\Ã¾ÃƒHÃˆË†n`â€¹â€¢ï¿½0Ã·Å“9Â¶(QÃ‰HÅ¸â€ÃŠ3Â¶*qÂ¹ÃƒÅ½Â¿
Ã²+
Ã˜Å¡Ã„&amp;X&nbsp;'Ã•7â„¢Ã…Â±%â€°ÃŒwÃ¬?Â±o&lt;`kÅ“Â°Â³A]DÂ°â€°ÃÂ³â€¡ËœÃ®ÂªÅ¡1ÃšÃ¥â€ºÃ†[â€™ÃˆÂ¤Â£Â¢Ã§ XÃ’Ã´[câ€ Â­I\~OP*{Ã&lt;Ã˜Â¢D;Ã¼f(Â½`â€˜bâ€¹â€”Ã‹`ï¿½6JÃœÂª}2FxÃ¾`â€¹â€¢Ã—3Ã¯(jÃ²Ã—Ã˜ÂªÃ„eï¿½bÃ¯8Ã„Ã¥Ã¿Ã¬Ã—/lIÃ†qÂ«ZUÂ«ï¿½Câ€¡ÃŒBÃƒNfÃÃ…Â¯dvÃ´Ã°AÆ’Ã¢Ã¢`Â«Ã¸ppexÂ°Ã,Â¤Ã€â€¢*9Âªnâ€œÃŒÃ¬Ã¿Ã·&amp;^{7Ãâ„¢Ã¯ÃŒÃºÃ¹HÃ­Âµï¿½Â½Ã«{~ÃxfQÃ‡7Ã¸mÃ¾Â®Â¹KÃ‰1Ã¨VÂ¢Ã’.Â¾Å½GÂºÂ¦[Ã‰Å¡Å¾Ã‹FkÃ&nbsp;Ãï¿½Â¤&nbsp;Â¾Ã¨Ã›â€ Â®$Ã­ÃŠ]Â´Z,QÅ¡Ã’â€¢Â¤Â¹zËœÃzË†ÃH=â‚¬Âª*,1Â­Ã‚FXÂºâ€™Â¸=	]Ãˆ|ÃªÃÃ’SÂ¨HÃ›â‚¬tCÃÂ«kÂ²vMÃ·1â€”Ã´$$t`?Ãï¿½Ht"
ÃÃ‡Ã¼CÃ@â€šÃ²â€¦.dÃ¨HPÃ¨&gt;â‚¬Å¾ï¿½Â¥GÃ·1.rÃ•Ã£AÂ´~Ã‘}=	
]GÅ¾Ã­v:gï¿½Ã¥Â©Ã!zt!pÅ¸vzÃ´$Âºï¿½Â¼Ã‘ÃÃ©)H@.Ã©BÃ²&gt;Å¾Ã½qIï¿½AÃ‚1Â¢	Å½oÃ­ï¿½â€šâ€â€Â®$-Â»Ã‹s=HÃˆ=KÃ´3zÂºâ€˜Â¸â€Å¾â‚¬â€Ã¥wÂºâ€˜Â¬Ã¯6Â§' Â¡Â¡KIÃ»â€œÃ€ÃºÂ´RJWvF@B3Â¥;	ÃºuIÂ§/Â¢kIÃºAâ€¡/!Â¢kIÂ¢Â³â€”ï¿½Ã²Â£Ã„ï¿½_Bâ€ÃÂ½5bcWÃ)Ã¯_Ã¨Ã°%DCÂºâ€”&nbsp;{:|	Ã‘)/â€°?Ã©Ã°%D#Âºâ€” :{	Ã’/Âºâ€”ËœÃ«3:{	]LLÂ³1&amp;Ã^N@t3)tÃ®,ÂºÅ¡â€”â€˜jÃ‡Ë†ÃMÃ†g:v	]NÃ„
ï¿½ÂºÅ’n'Ã¢;â€œÂµNTQ&nbsp;Ã›â€°8Â§Sâ€”â‚¬Ã‘Ã­DÂ¸R[@[ÃÃ­DÃÂ¡KÃ€Âºï¿½:u	Ëœâ€“D!6|=!Â¥t;tÃªÂ°ÃNï¿½ÂºLKBÂ¤&nbsp;GÂ·â€œ`Ã©Ã”%`}ÂºÅ¾â€otÃªÂ°â€œ&lt;8Ã½Ã›`â‚¬IÆ’Ã—â€™LÃ¨zÃÃ©Ã”%`]OÂºâ€LKBÂ¤`HÃ—`Ã¨Ã%dÂºÅ¸â‚¬Âºâ€Ã¬â€”ï¿½Â¹MKBÂ¤`LÃ·@g.AÃ‘Ã½Ã´oJg.AÃ’ÃµoDg.A;ÃÆ’Ã“ËœÃ\â€švâ€šÂ§â€Ã\â€švâ€šKâ€šÅ½\Ã‚Â¦%!RpzÃÃŸÃ¨Ãˆ%l}ÂºÂ¡Ã}Â¤#â€”Â°uÃ©â€ zG'.ï¿½KÃ©â€ Ãº6Â¦â€”Ã€%tE}KÃ©Ã„%ttE}Â£Ã³â€“Ã Ã‘ÃµlHÃ§-ÃÂ£;ÃªYJÃ§-ÃÂ£;Ãªâ€”Â¡Ã£â€“Ã°Ã‘%ÃµÂ«OÃ‡-Ã¡Â£KÃªï¿½Â¶Dâ‚¬.Â©W7tÃšÂ¾â€nÂ©W	Â·Dâ‚¬nÂ©O?Ã¨Â°%}ÂºÂ¦&gt;iâ€œï¿½ÃƒtM}Â¢Ãƒâ€“Å’Ã¨Å¡z4Â¤Ãƒâ€“Å“Ã’.Ag-QÃˆÃ¨Å¾Ãºâ€œÃ‘YKÃ¨Å¾zÃ”Â£Â³â€“(Ã=ÃµË†Å½ZÃ¢@Ã·Ã”Å¸Ã¯tÃ”â€¦â€.Âª?tÃ”â€¡]TÃ¨Â¨%Â§Â³$Ã¾Â¦Â£â€“8ÃEÃµâ€¡NZ"AÃ•â€º':iâ€°CJ7Ã•â€ºÂ³â€ÃZÂ¢0Â¢â€ºÃª
ï¿½Â´Dâ€š.Âª7Ã¯ÂµIH%tSÂ½Â¡Æ’â€“HÃ´Ã©Â¦ÃºÃ’Ã‘&amp;!â€¢ÃMÃµâ€ ZbA7Ã•:gâ€°EBWÃ•â€œ)ï¿½Â´DÃ‚Ã’]Ãµâ€ÃYÂ¢AWÃ•â€œNB-Â±&nbsp;Â»Ãªï¿½Â²Ã„#Â£Ã‹Ãªï¿½Â²Dâ€.Â«?Ã¡Å’%&amp;	]WÃº)ï¿½Â²DÃ„Ã’}uÂ¯Ã“Â¥Câ€“ËœÃ}uÂ¯â€œÃ’KLRÂºÂ°Â®ÃÃ‘	KdÃš~n:Â§â€“Ã˜Ãâ€¢uÂ¬â€ºÃ’KdztgÃÃ’câ€Ã”EwÃ–Â­ÃŸÃ¨x%&gt;tiï¿½Â²tÂºÅ¸&gt;ÃZÂ§Ã¨t%Btiï¿½Ãª%tÂ¼ÂºÂµNÃ‘Ã¡Jâ€Ftk]JÂµIHmtkï¿½Â¢Ãƒâ€¢Ã‘Â­uÅ W"4Â¦[Ã«Ã’HÃ§&amp;Â©ï¿½nÂ­SZRÃZÂ§Ã¨p%B=ÂºÂµNÃ‘Ã©Jâ€Ã¨Ã’ÂºEÂ§+Â¢KÃ«ï¿½Â®Ã„Â§Kâ€”Ã–-:^â€°OFâ€”Ã–-:^â€°ÃYÃ‡Ã¨x%:-?7iIH]-?7iIH]te]Â£Ã³â€¢Ã˜Â´Ã½ÃœÂ¤%!5ÂµÃ½ÃœÂ¤%!5Ã‘ï¿½uÅ½XbC7Ã–Â¹â€NXÃ¢2Â¦Ã«Å“â€“â€Ã”BÃ–=:aâ€°]XÃ·Ã¨â€%.SÂºÂ°Ã®Ã©Ã $uÃ}Ãµ&nbsp;Kg,1Ã©Ã‘}Ãµ@KBj&nbsp;Ã«ÃªCÅ¸YbBÃ—Ã•â€¡Â¡Â¿8ÃµÃ˜Â½)]W&amp;tÃŠÂºÂ­^:eâ€°Gï¿½nÂ«tÃŒÂºÂ«Å¾Ã1K&lt;Ã¨Â®zÃ¢:Ã†Ã„Ãµ
Ã„â€”Å’Ã®Âª'tÃ
ÂºÂªÂ¾Ã9K,Ã¨Â¦zC-Â±&nbsp;â€ºÃª
Â´Dâ€š.Âª?	ÂµÃ„ï¿½.Âª?tÃ’ÂºÂ§Ã‘QKtO=Â¢Â³â€“Æ’~Ã«
Ãº_Ã¯_Ã¿Â¹|ï¿½}ÂºÂ¦ï¿½Â±ï¿½Â¥â€™Ã¾hbmfÃ²ÃœÃšÃ§q=}Â½Ã¹ÃÃ Ã…â€œÃ®hZÃ©â€¦tM}JXÃ—ï¿½ËœÃ§Ã¥`Å 3Â»Â½&lt;Ã¾Ã‚Â£Ã¢%{&gt;â€ Â¿BÃ²Å½WÅ“y7Å“&gt;Ã¤vÂ±?}Ã»Ã­Ë†Ã‹Ã¶wWaÃ~Ã¡Â¸â€A9"XqÂ­7y^
Ã³Ã¥Ã°zMÃ¤Ã¦Ã¯ÃšÃ—KzÃ“u0Â»ÃŸÃ¨&nbsp;xÃ94qh4ï¿½=@&lt;Ã®XKÃ¿UÂ¾Ã”Â¤F'ÃºÂ¯ÃÃ;Â¾hÃ‘xÃ½/ÃËœËœÃƒÃ¬VÂ¸ÃÃ¨Ã°e^zÂ±YÃ”Â¿@Â´<s5+Ã±yÂ³ÃÅ¾!Å’)ÃŸ#Ã¦Ã¾Ãšâ€˜:Â»ÃƒÆ’ÃµÃ€Ã~ï¿½Ã˜Å’ÃtÅ½â€˜eâ€¹)xÃ¹Ã§Ã²kÃÃ.38Ãº2Ã·Ã“nÃšl&Â£aÅ¡zÂ­Â¼Ã‰07Ã³Ã¥` ÂµlÅ¸Ã°qÂ¨Ã¨uv'Ãdâ€¡ËœÃ€%ynÃÃ³ÃÃ‰ÃÃ­Â·sÅ¸Ã°rÂ¨Ã¸Ã¹Å¾Â«Â¼Ã™xÂ±lÅ¾â„¢ÃƒsÃ½Ã´ÃªÃ­Å½â€¹Ã”Ã¾'+oÃ³Â¼"Ã¦kÃ¢ÃÂ±ty|Â·Ã‹Âµ="" 3^Â©Â­kÃ³Â§Ã¹Ã„lveÂ®Â¿Ã®?lÂ½Ã™iâ€¦ÃšÂ±Ã”cjÃ­6Â³Â·Ã«Â·ÂºÃ¬oï¿½câ€“v6Â¯Ã°="" â€˜ÃÅ¸8="">/ÃÃ©Â²=mdÃ™AKECÂ»Âµ?TÃš)Ã¬bÂ¶ÃÅ¡Ã“Z?Ã‘AK5WÃ“Ã™Â¬Ã¬r1TÃ›&amp;Ã¤ï¿½Â¦Ã´Â´Ã¥&nbsp;ï¿½?L6â€ºUÃ…Ã‡9ÃÃˆÃ¥,â€”?Ã¯Ã¯Ã²,â€ºmÃšÃ¼Ã“â€”Ã½Ã®LnÂ²WÂ«Aâ€ ;FÃŸÃ¤!Ã»cÃ–}kÃ§Â¿Â£51Ã“oâ€ºu9Ã»&lt;6kÃ­Â²Â¤â€¡.Ã¥ÃOÃ§#2Ã…Ã¥@TÃ±~Å¡aÃ·Ã¶Å½Â»â€Âº_LhÃ±uÅ’â€“qâ€™ï¿½Ã§Å¸aÂ±QÂ´Ã½Â¡â€ Å¾Â»â€Ã¸k1Â»Â»â‚¬^WÃˆÃ´n{-Ëœâ€“/â€°	=yÃ™Ã©bÃ•yÃ¾ÃˆÂ¾Ã¸â€“ÃŸÂ«<iÃ¨Ã™Ã‹.Ã£Ã¥xÂ¬ÃkÂ¸Â½&Â³ÃÃ±ÃÃ¥jok"@Å¸vÃ£yÃ€vÃ„ÃºÂ¾Â³ÃÃlÃ¾1[Ã¼Ã‡Â´vixzÃ¸Â²Ãƒh=â€œÃ­â€ºÅ¾cÃ«Ã›Ã¥ 3Ã¿ÃµÃ¼Ã»sÂ¾y#-d_^Â»^o'+[Â®Â¿Â¡Ã­Ã£tvzâ€ºmÃmÃ»Ã·Ã–ny="">&nbsp;Ã‡//]&lt;Â®Â§c2Ã´Ã‹Ã˜."Ã†f~\2Ã‹SSNm\^&lt;Ã‘Ã³â€”â€”Â¾Â¬â€¡cÂ­ÃŸaâ€¹Â´vÂ¹6Â³Â§Ã‚ÃMfÃ³Ã¯)])ÂºxXÃ&amp;3ÃÃÂµPÃ³K1+â€¢VÂ²Â¦Â½Ã«!HÃ¨HÃ‘Â·ÃµlÂ¬Ã‰Ã˜Ã¢=Â­Ã¾Â°^Ã‹j<o^Å¾Å’Ã‡6Å¸Â¤tÂ¤Ã¨ÃÃ·Ã•|Ã¬Ã¼Ã Ã®â€¹]Ã¿Ã—Â¼<Ã™Ã¢ÃÃ§ÃÃ–<Ã¤Ã­c_vÂ¸xÂ·Ã‘d.Ã&Â¶Ã¤kÃÃ®Ã¸Ã‰ÃÃ•!jÃ½g go_^Ã»Â±Å½Ã2â€¡â€¡Â¦Ã¬iÃ³%_Ã½.oâ€¡_Ã¢Ãƒgâ€”Â¾Â£Ã§="" ÃÂ¯fcÅ’}Ã¦jÃ²Ã–Â¿ÃµÃ£Ã²Â¡Ã£nmÃï¿½Â¢Ã³_Â«Ã‰Ã˜Ã§sâ€œâ€Å“Ã­fq9ÂºÂ£Â¥+="" Ã—Ã«Ã‰de'Ã½fÃ¦Å¾â€”Â¶-wÂ³Â¬ÃÃ\Ã»Å¾Ã®â‚¬lÂ»yÃ†fÃÃ›dcÃ‡â„¢â€”Â±Â»Ã¿9h;â€“Ã®"Â­?Å“ÃœÃ®â€ Â­â‚¬Ã¼\ÃÂ¥Â±Ã¥Ã;â€“Ã„Ã¯â€¹Â¼Â®\ÃœÂ®Ã‡v@Â¶ï¿½7-Ãâ€™Ã˜Ã¬bÂ»xÃ‹Ã„.ÃœÂ­â‚¬Ãœoâ€¢Ãd|ÃoÃŠ{~Ã¶kâ„¢Ã™â€”Ã†Ã¯:e;="" [ÃÃ—sÂ±Ã±Å“Ã³9oâ€¹Ã˜="">}Â¡NÃ‡Ã¿*a8Ã›Å¡â€¹Ã–CQVÃ²Ã¯Ã³Ã &gt;yÃ±^Ã’Ã©lÃ½ÃµÃ®ï¿½Â¬\iâ€*ï¿½Ã¦|Ãâ€˜ÃÃ³Ã¸Ã—â€¹Â®â€¡Â¶@6Âºâ€ºÃ©!Â¢â€ nÃ§SÂ§Ã°%_[Â²Å“Ã€Ã”Ã˜&lt;â€šï¿½â€šï¿½â€º/Ã‚LÃ›Ã…3ï¿½CLLY*fÅ¾ÃŸwâ‚¬'/Â»Ã½oÂ³3Â«%Â±bf;Â¦9Ã°%q6OÃ°ÃÂ¡Ãâ€œâ€”ÃÂ®Â·Z&nbsp;Â±fÃ†Ã“*a,C|Ã£MÃÃKâ€°â€º7NÂ³ÃµÂ¦Ã“J_Ã‹ÃŸtâ€¹ï¿½Ã¨Ã¤eÂ·Ã±â€ºfÃ™~?Â¬1Â¹ï¿½-Å Ã«Ã¢bâ€¢Ã¤nB^JÃœÂ®Ã‡Â£#SÃÃ³Å Ãˆ6Ã™Ã·ÃŠuâ€“WÂµo^J|Â«ÃŸâ€¢Ã“Â±YÃ–Ã¬yÃ™VÅ“Ã½z78Ã‡Ã¦.enÃŸTâ€¢Â´oIÂ¿Ã«Ã·Â¾rÃŸ%ï¿½GEÃ¦^Â¤ZyÂ«Â¸Bâ€ .{|uÃ™â€œâ€“Ã™Ã·4a_%â€ºVÂº&amp;0rÃ™Ã«K3e9{Ã…Â®tG/ËœÃ¸Â¸Ã°OÆ’u9Ã·Ã¥?ÃšÃ°ï¿½Ã”ÃÃ¯Â¸Ã¥&nbsp;Â¿â€º-ÃŒI+â€°8Ã™Ã·Å¾GÂ¯Ã“â€“ÃƒÂ®}Ã•Â¥EÃŠï¿½Ne)ÃŠÂ¯Ã¥sÃ˜Rï¿½NMï¿½*ÂºÃ¤
_Ã½ï¿½Z*Ã¹sÃÂ³Â¢â€2e?xÂ¿'Ã«]Â¯O}
Z*:sÃ—Å¡Ã¶Â°Yï¿½Ã¯ï¿½Ã»Ã…JÃŠOcâ€“Ãª&amp;ï¿½vÂ§Â¥Â²Â¬Ã†Vz0Ã²in&amp;Æ’Ã‘x&lt;zËœÂ¯Ã”ÃµÃ“]ï¿½ÃšÃƒÃ®&lt;&amp;â€¢ï¿½Ã¨â€˜ÃŠQÃÂ»lR[Xâ€ºÃ—yÃÂ¢g*GÂ¹wÃ–Â£Â©Â³Å¾}&nbsp;â€¡*GÂ¸tÃ“Â¡Â¶ÂªÂ¶6nÃ©Â©ÃŠWÂ¨%Â³Ã¿Â³_Â¿Â¡uÃuÃ‡Ã¡pÂ¸\ÃŠ%\.%eâ€Ãâ€”	Â¡â€šÂ¬â€â€¹PFÆ’JEBh)Æ’
#Ã‚P&amp;-Ãˆ
tPÅ¸â€ÃºÃ€ÃŠZVÂ¬8Â¬s&nbsp;Â¨ÃƒÂ©â€œÂªLÂ«Râ€°6Å“Â³6Ã’ÂµMâ€”MÃš{Â®Â¡UÃ©Â¿$Ã·Å“ÃœÃ³{Â¿ÃŸÃ§Ã(Ã¬Ã‘Ã·Ã³&gt;;Ã§vÃ®Ã¹ÃÂ°Ã®sâ€˜Ã‘Â«JqgÃ‹)ZÃ¨YÂ¥8:Â¿,ÃµÃ¸â€ºbâ€Å¾U
;YnBÃY^ZÃ¹jÃŠVÂ¾Â¡:kÃ¾gÃ´Â¬RÅ“Â£â€™Ã‚Â²Ã²8dkÂ¿.Ã¨YÂ¥0Ã½â€™Ã˜ËœÃ•zW)ÃŒi?AÃ‰Ã®&gt;Â«&lt;Ã´Â®RTÃ›eDï¿½YÃ³Ã‹â€°VÅ ZÃ»7Â¢F+ï¿½Ã“Ã¥â€jâ€˜^V
ZÂ¤Ã“	Ã•&lt;&lt;Â¬ÂµÃ¦Ã§Â°wÅ“^VÅ Â©ÃÃ¥Â«BO+Ã…Â¥Ã‹	VJO+Ã…ÃœÂ¤Ã‹	Â½Â¬Dâ€¡.zY)F?%JCO+Ã…LÃ‘Ã¡â€â€¹Å¾VÅ Â¹@â€¡Â¬Å’Å¾VÅ Â¹Mâ€”Â¬)zZ)â€ '\Ã´Â²RNÂ¸Ã¨eÂ¥ :Å“pÃ‘Ã‹J1St8Ã¡Â¢Â§â€¢bfÃ©pÃ‚EO+Ã…ÃŒÃ“Ã¡â€â€¹Å¾VÅ Â¡Â»	XBo+â€¦ÃÃâ€Å’ÃV
Â¡Â³	Ã™Mz\)`Å“Ã&amp;h5z^Ã‰oâ€Â®&amp;lÃ´Â¼â€™Å¸â€°RÃ½Æ’ÃWrÃ“#Q.z_Ã‰Â­I7:z`Ã‰kÅ N&amp;t
zaÃ‰Ã©$ï¿½LÃ°Ã¨â€¦%Â§Ã³t1Ãâ€ºÂ¢'â€“|Â¾H&gt;zbÃ‰gÅ“&amp;|OÃK.Â¯Ã“ÃDâ‚¬ÃXrÃ¹ÃKvÃ‘#Kâ€¹t/1&nbsp;Gâ€“&lt;Ã¨ZÂ¢@ï¿½,yÃÂµD!Â£Wâ€“Ã¨ZÃ¢@Â¯,9ÃÂ±Ã„Ã¡=Â³Ã´Å½Å½%Ã´ÃŒÃ’;Âºâ€¢H$Ã´ÃÃ’3Âºâ€¢HdÃ´ÃÃ’3Âºâ€¢XÃ;KÃÃ¨Tb1N-Â½Å¡Â¥[â€°=Â´Ã´ÂªAÂ§Â®Ã»Ã¿oC-=Æ’zâ€°Ã€Ã’}kÃ’CKÂ¯&nbsp;^bÂ°pÃ¯_:Ã´ÃÃ’â€œÃªâ€“Ã±y*ËœÃ˜Ã[Ã‹Âºâ€™ÃªÃ–Ã–Ã”WÃŸÃ¸+ï¿½JÃ€Ã®{MÃ{Ã‹ÃšVÅ¾â€¡'&gt;{Ãª7Ã—â€“3*â€”Ã¨ÃŒÃ’â€ºÃ‹jâ€™Â´1Ã´Ã¸Â¾#/Ã¿Ã¶Ãš-Âºâ€™Â¸ÃÃƒÃ‹Â£Â¤ï¿½Ã¡Å¸?Ã»Ã³woÃ¨ypï¿½_â€Ã–Â¶Ã®|jÃºÃ”Ã¸&nbsp;Ã›Ã•Ã§â‚¬@Ã®â€œ4?ÃºÃœKÃ§Â¯Ã’YÃ„L?&amp;ÃŒHÂª[Ã†&gt;vÃ¤ÃŒÃ…ktÂ±Â£Cï¿½;â€™ÃªÃÃÃ½Ã‡Â¾OÃ— ]=Â¬Â¼&gt;|Ã°Ã¸[t
rï¿½CÃ´*ÃµÂ­Â»Ã¶Ã¥/tÃ’Ã­fwÃ¿Ã•Â¤â€œË†ZÂºylÃ¯Ã¡Ã“Â¿Â¸Å½â€“ Ã¿sÃ·â„¢8OWÂ³FÃ«ÃˆÂ¹?ÃÃˆCÃ¨,Ã¢U;Ã¼Ã¦=Â¿ÃœÂ«sÃ§Å¸tÂ±JÅ¡Ã»Â¿= ï¿½DÂ§Â§ÃŠcÃ»Â¾vï¿½Å¾^rÃ§5AÃ‡Â£dÃ‹Å¾Ã¨Ã±Ã¥â€˜VÃ¾Ã”Ã¨&gt;Â¢â€œ4Ã¿&lt;Â½Â¼Â¬"[Ã¹sâ€.$6â€ºFÅ¸Ã½=Â¼Â¬jÂ©Ã›Ã½ï¿½H\â€™ÃÂ§ÃdÃ´Ã¬Â²6:â€™Â¨TFÃšÃ©Ãe=t%1Iwâ€ºÂ£Ã·â€“uÃ‘â„¢D$9vâ€¦Å¾[Ã–â€œÃ©â€˜pgxÅ¡Å¾[zpâ€ºÃ®$Ã©Â±Â¥Ã­â€.%Ã©NzkÃ©IFâ€”ï¿½AzjÃ©]J,*Ã´ÃÃ’Â«Âºâ€¢HÃ;KÃ¯Ã¨VÃ¢@Â¯,9Ã”Ã©ZbÂ°@Â¯,yÃÂ¹D`Ë†ÃXrÂ¡{	_JO,Ã¹tÃ¨bâ€šG/,yÃ‘Ã…â€-Â©Ã‘Ã»JnzMâ€Â©AÃ+ÃÃ•â€Â¬Ã’Â¦Ã—â€¢Å¡t7Â¡Ã‡â€¢BÃ¨nÃ‚â€¢ÃÃ“J1t8Ã¡zÅ’Å¾VÅ Ã©ÃÃ¥â€J/	oÃ‘Ã©â€ÂªA+EÂ¥t;aJÃ©aÂ¥Â¨Å’Å½'LCÃ´Â®ROï¿½jÃ´ÂªÂ²-:Å¸Uâ€“Ã©Ue#Ã¨~Ã‚â€œu3zUÃ™:&nbsp;Ã°Ã”&lt;Â±Â¿LÃ’â€¦&amp;Ã½TÂ·sÃŸâ€¦;Â«\^Â¬Â¢
ÃÃ Ã·Ã•;Ã‚;tBï¿½Â©,Ã’Æ’ÃŠF-Ãâ€¦eÂ°{â€¹^T6Å Å½((	Â½Â¦Ã´AJgâ€™â€ ~;â€â‚¬Ã( )Â½Â¥Ã´ÃQ@nÃª%â€:Â¤`Â¤Ã=Â¦Ã´]R(zHÃ©:Â¥@$[Ã¨!Â¥oÃ¨ËœÃ‚PÂ¿AÃ¯(}CÃ‡â€Ãšâ€œÃ´Å’Ã’?tM!Â¨OdÃ´Å’Ã’?Ãâ€œÃ¿?Ã¾CzEÃ©':(Ã¯5&gt;Ã±zCÃ©Â«I:)ÃUwÂ¿Â¶Do(Ã½E7Ã¥Â·Â¤yÃ¢zAÃ©3:*Â¿Ã•Å¸~;Â£â€&gt;â€ºÂ¥Â«Ã²YÂºÃ£â€ºÃ‹Ã´â‚¬Ã’wtV&gt;Â«O]Â¢Ã§â€œÃ¾Â£Â³Ã²XÂ²Ã½Ã•[Ã´|Ã’stXÃ¾ÃšÃ´ÃŒez=)â€“Â¿FÂ¿Â¡_AÂ¢ÃƒÃ²VÃ­Ã€Â»Ã´vR:-O%c__Â¢Â§â€œrÃmyÂª&gt;ÃµÂ½Å“â€dÅ½Å½Ã‹KÃ©Ã¸Â«Ã´pRÂº./
|zÅ½ÃMJCÃ—Ã¥Â£tÃ¬=â€ºâ€Â§MÃ·Ã¥Â¡ï¿½CÂ§gâ€œÃ‘}Ã¹'ÃÃ¾-z4)Ëœ6Â¾Bï¿½&amp;ejÃ’â€¦Ã¹&amp;mÃ½â€ÃLÃŠE'Ã¦â€ºÃ/ÃÂ¤'â€œrÃ‘â€°yÂ¦2Ã±Kz1)YJGÃ¦â€”Â¡Â£Ã´bRÂ²Å’Å½ÃŒ+â€¢=oÃ‘Æ’IÃ©Ã¨ÃŠÂ¼2Ã´=â€”â€ï¿½Â®ÃŒ'Ã•Â½Â¿Â£Ã§â€™Ã²-Ã‘ï¿½Ã¹#iÂ¾HÂ¯%.ÃÂ¡Ã¹Â£~hÅ¾K\&nbsp;CÃ³FÂºÃ³{Ã´VÃ¢Ã„ï¿½Å¡/â€ Å¾Â§Â§GÃ¨Ã”<qÃ»Ã¤ez)qâ€nÃÃ‰Ã˜Ã‹Ã´pÃ¢jï¿½Â®Ãsz(qÂ¥cÃ—Ã¦Æ’dÃ¼5z'qâ€¡ÃÃ[Â¦Â¯Ã’3â€°;tnÂ¨Ã­Ã½â€¢Â¾â€º"Ã’Â¤Æ’3 ÃÃ¾Ã’Â¿Ã©â€¢Ã„Â¡9Âº8Ã³6?7gï¿½$nÃ‘Ã…yâ€”Ã®Ã¾â„¢="">â€ºÃ¢B'gÃÃ°	}6Eâ€ NÃÂ¸M.Ã“â€°c3ttÂ¦%Â£Â¯gÃ´BÃ¢]ï¿½iÃµÃ©%zqÅ½Â®ÃÂ²Ã¤#Ã¯Ã‘Ã³Ë†{tvâ€“
ÃŒÃ¨Â³)BmÂº;ÃƒvÃ&nbsp;Ã—Ã€Ãï¿½]â€º^Â¡Ã‡Å¾]{nÃ’Ã›â€šÃÂ¬ÃšiÃ½â€™Ë†]Å¾Y;Â¯ÃÃ“câ€ NÃÂ¨ÃŠâ€”;Ã´4Â¡Ã›3jÃ«Ã©aâ€BÂ·gSÃ²Â¬^Ã‘Â¢Ã£Â³iâ€º~IÃ„Â«EÃ—gQÃµhFÃ¯"Ëœ:?â€¹Zâ€”Ã©YDÃ§gP}F/â€°ËœÃ‘Ã½Ã™â€œÃ¬Â»Nï¿½"$:@{â€ Â¾Ko"Â¨&amp;]&nbsp;5Ã‰Ã“Ã¿Â¢7TF'hMÃ³Ã—Ã´$Â£4Â¦rÂ¤C/"0ÂºAcÅ¡Ã¯ÃÆ’mâ€“Å½Ãâ€Ã´3Ã´Ã‚Â£+4eÃ°MzÃ¡Ã‘Å¡2râ€°Å¾Cxtâ€¦Â¦Å’Ã“kË†tâ€¦Â¦l[Â¦Ã§^ï¿½ÃÃâ€™3Ã´b@â€ºÃÃâ€™msÃ´Ã‚â€ºÂ¤34d?=â€ X0GwhÃˆÃ¦Ã›Ã´bÃÂ¡Ã‰Ã±[Ã´bÂ¢WÃ¨)Ã„:D3j?ÃÃ¨-Ã„ÂºD+â€™Ã©%Ã„Ë†â€nÃ‘Ë†ÃºÅ¸Ãµâ€™ï¿½;Ztâ€¹F<i!vdtâ€¹64nÃ©%!Ã¿eÃ‡hÃƒÂ®ez1Æ’Å½Ã‘â€Ãª%zÂ±Æ’Â®Ã‘â€ }6Ã‰Ã¿Ã‘5zp}Å¸^a="" Ã‰Ã¨="" Ã˜Ã±Â½â€šxbÃ·ÃˆÂ«~ï¿½Ã@liÃ©"qzÂ¤7s&Ã©"iÃ©="" zÂ±eâ€ nâ€™6ÃœÂ¡'cÃ¨$aÃ‰Ã¡Å’^@Å’Â¡â€ºâ€5ÃµdÃˆÃ¨&yÃ©3Ã´Ã½Ã…Å“:]%jÃ°Å¸Ã´Ã½Ã…Å“yÂºjÃ”="">}7Ã‰CÃ¨*IÃ•Ã“Ã´ÃµÃ… :KÃ’Ã¨UÃºÃºbï¿½%(ï¿½Â¼E__JÃ©09Ã•sÃ´Ã±Ã…Â¢&amp;gÃ¤}ÃºÃ¸bÃ‘$&amp;&amp;â„¢&nbsp;o/6Ã‘eb*â€¡Ã¨Ã“â€¹Mtâ„¢ËœÃŠ%ÃºÃ´b]&amp;&amp;]Â¤O/6Ã‘ebÃšÃ´Ã¥Ã…(ÂºLLâ€¡Â¾Â¼Eâ€”â€°Ã‘#!ï¿½Ã–Â¤Ã“â€Å“Â¤/VÂµÃ©6!Ã­ÃºÃ²bTFÂ·	â„¢Â¥/fÃ‘m2ZÃ´Ã™Ã….:NÃ†}vÂ±â€¹Å½â€œA_]Â£Ã£DLÃ’WÃƒÃ¨:Ã´Ã‘Ã…Â²â€Ãï¿½ÃGÃ‹fÃ¨&gt;Ã³Ã´Ã‘Ã…Â²9ÂºO@7Â£Â¯.â€ etÅ¸Ã®Â¥o.Â¶Ã‘ï¿½ÂºG_\Å’Â£uï¿½Â¾Â¸GÃªÅ“~HÃˆÃšÃ¨Bï¿½Â£.Ã–5Ã©D;I\Â¬â€ºÂ¥ulÅ¡&gt;Â¸ËœG7Ãª}nÂ±ï¿½nÃ”Â­Ã‘Ã§Ã»Ã¨HÃZ&nbsp;Ã-Ã¶Ã‘â€˜:Â¥'BÃ–GWÃªTwâ„¢&gt;Â·Ã˜Ã—Â¦3uÂ¨N[Â¼@wÃªPÂ·C[|@wÃªï¿½	Ã©Eâ€¡Ã•â„¢}jÃ±]Âª3Ã´Â¡Ã…tÂªÂ®ÃwÃÂ­Âº1Ã™Â½NZ|AÃ‡Ãª}eÃ±	]Â«Ã´â€˜Ã…'tÂ­.Ã”Ã©#â€¹OÃ¨\]&nbsp;o,^Â¡su`}cÃ±
ÃÂ«ÃƒÃ´ï¿½Ã…+tÂ¯Ã'Â¿ÃÂ½â€“/Â¡O,~iÃ“Ã…â€“Â®JÅ¸X<c[ÂºÃÃ´â€¦Ã…3tÂ±Â¥Â¢ ,Â¾Â¡â€œ-Ã›}`Ã±="" ï¿½lÃ™Ã†Ã©â€¹oÃ¨dÃ‹Â¶ï¿½="">Â°Ã¸Â¦E7[Â®Ã´ÃºÃ€Ã¢:ÃšrÃ•Ã©Ã³Å Ã¨hÃ‹Âµï¿½&gt;Â¯Ã¸Â§CW[Âª	ÃºÂ¼Ã¢!ÂºÃš2U&gt;G_W<dg[Â¦ï¿½Â³Ã´uÃ…gtÂ·%Ã¾=}\Ã±Ãmâ€°Â¶_Â£ï¿½+^Â¢Ãƒ-ÃÃ®%ÃºÂ¶Ã¢%:ÃœÃ’$Ã¨Ã“Å Å¸Ã¾ÃƒnÂ£Ã„@qn&â€“ÃšÂ¤â€¹ï¿½ Ë†="" "ÂºÃ›Ã¬$hi9â€¦a-,Ã¬,dÂ°1Ã•"zÂ¦ËœdÂ°0rÃ¿ï¿½jÂ¸Ã®ÃÃ¹â€“pÂ¸Ãâ€Å¾nÃŠÃ†:Â­jÃ‘Ã“mÃ™<Â§Ã‹Âª="Ãâ€ï¿½Â·tYâ€¢zÂ¢Â·Â²Â³Â¤Ã‹ÂªÂ½Ãï¿½Ã©VÂ­Ã¨Ã­â€ ÃŒ~Ã‘aÃ•Å ÃnÃˆÃ®Å Â«Vâ€”Ã´x3Ã¦k:Â¬Zï¿½Ã‘Ã£ÃËœÃ“]UkÂ¤'qHwUÂ­â€˜Å¾Ã„ÃUÂµ<" iÃ€â€œï¿½fzsÂºÂ«j}Â£Ã‡â€ºÂ±owuÂ­zÂ¼{twÃ•Ã²$Â¤ï¿½â€˜Å¾Ã„Å’Ã®Âªz#="â€°)ÃUÂµÃ´x3Â¦tWÃ•ÂºÂ¢Ã‡â€ºqOwUÂ­Ã´x3Ã–tWÃ•ÂºÂ¡Ã‡â€ºAgUÂ¯;zÂ¼tVÃµz&nbsp;Ã‡â€ºAgUÂ¯gzÂ¼tVÃµÃºMï¿½7Æ’ÃÂªbÅ¸Ã¨ÃµFÃUUÃ¬Ëœ^o]UÃ…Â¾Ã’Ã«ï¿½&nbsp;Â«ÂªÃ˜wzÂ½tUÃ»IÂ¯7â€šÂ®ÂªbKzÂ½" 3ÂºÂªÅ yÃ’Ã€(obbwuÂ±qÅ¾Ã„â€šÂ®ÂªbÅ¾â€4Ã°hÃ7ÃÃ‡iÃ¯Â·Â¢Ã§awuÂ±wzÂ½tu5Ã»@Ã7ï¿½Å½Âªf[Ã´|Ã¨Â¦jÃ¶gbÃ¯7â‚¬Å½ÂªfkzÂ¾="" tt5[ÃÃ³mÂ Â£ÂªÃ™gzÂ¾="" tt{Ã›Â¦Ã§â€º@wuÂ±szÂ½tuÃµÃº{dÂ¯7Ã¡â€šÃÂª^Ã—Ã´zÃ¿Ã£Å¸ï¿½ï¿½â€°Ã¡Â§="" endstream="" endobj="" 5917="" 0="" obj="" <<="" bitspercomponent="" 8="" colorspace="" devicegray="" filter="" jpxdecode="" height="" 765="" intent="" relativecolorimetric="" length="" 30351="" name="" x="" smask="" 5916="" r="" subtype="" image="" type="" xobject="" width="" 787="">&gt;stream
jP  
â€¡
ftypjp2 jp2 jpxbjpx rreqÃ¸Ã¸â‚¬@ .-jp2hihdrÃ½colrvjp2cÃ¿OÃ¿Q)Ã½Ã¿RÃ¿\#B@HHPHHPHHPHHPHHPÃ¿ï¿½
?Ã¿â€œÃ&nbsp;Ãˆ\Â®Fâ€˜Ã¬â€“ÂªQv~}Ã &nbsp;M!â€ Ã¿Ã‰Ã±cÃŒCÅ½Ã¨GÃ¨Ã‹â‚¬Ã£W	S Ã¸Ã‹â‚¬â‚¬Ã¿ï¿½
5Ã¿â€œÃŸpÃ¨Y.:)Â¯Ã³|Ã½Â½â„¢Â¹AÃ¢GÃšï¿½ÃƒÃ¾/Â³&amp;Ã¾ÃšÃƒÃ â‚¬tâ‚¬â‚¬â‚¬â‚¬Ã¿ï¿½
SÃ¿â€œÃŸY`gÃ¥Ã´Ã¥	e~;Ã•jÃÃ¶LpCÂ¶q'Ã£Â¿ÃŠ9@vÃŒÃ„u)â€”Ãš2ï¿½Â«FÃ¡FÅ¡qâ€ºÃ™Ã¤Â­Æ’qÃµ+Ãaâ‚¬Ã°Ã â„¢ï¿½Ã—ÃŒO!Aâ‚¬â‚¬Ã¿ï¿½
Ã¿â€œÃÂ´Pâ‚¬â‚¬â‚¬â‚¬â‚¬Ã¿ï¿½
1Ã¿â€œÃŸXÂ°[Ã†Å¡7â€â‚¬.Å¡Ã»Ã¸44ÃµÂ´cÂ¼bÃ½^ÂªÃ¸@TÂ·Ã¯Ãœâ‚¬â‚¬â‚¬â‚¬Ã¿ï¿½
[Ã¿â€œÃŸYÂ¨$6Â¼Ã¯!aÂ¹9TÂ¡^&gt;Ã•Å“Â¤Ã«_"-Ã™$Å½KÃ¦ÃœaÅ¸dqÅ“hâ‚¬Ã¾â€”'eYQ/Â¦Wy1Â¿â€ºÃˆÃºÅ¸Ã«ssÃ±Â¯4Ã§XÃ±Ëœ+Ã£Å½Ã¯Ã–Â·oIâ‚¬â‚¬â‚¬Ã¿ï¿½
\Ã¿â€œÃŸYÂ¨31ue	Å“ÃÃ°\Ã®Â©ZU6MÃŠÃ†Â¡ÃºÂ²CÅ¸Â¯Ã¶Ã³mQÃ¿TÂ·oâ€¹Â»Ã‰lÃ¶!NÂ®c6Â¡Â£ÃŠSÂ¾EÃ±Â¤aÃœ^â€™ÃŠâ‚¬Ã£â‚¬Ã§,xZ.â‚¬â‚¬Ã¿ï¿½
Ã¿â€œÃÂ´Pâ‚¬â‚¬â‚¬â‚¬â‚¬Ã¿ï¿½
TÃ¿â€œÃŸYx#Å¡â€¡ÃŒ+ÃŠbjÃ®Æ’Ã¥!Ã¦Â®?ï¿½Â§V}Ã*Ã‡Ã”&gt;Ãƒâ€ LÃ½Å¾â„¢LGÃ‰
x6=cÃ‚Ã¹gÃ±â€¹wÃÃ¾,Ã—1â‚¬Ã¢â‚¬Ã§Sâ€˜"â‚¬â‚¬Ã¿ï¿½
	[Ã¿â€œÃŸBÂ°Â¯ )&nbsp;Å¸â€º
Â¬Ãƒw%Â¬
Â·Ã¬|Ã¨Ëœ(ÂµÂ¶AÃ‘Ã¢&amp;Â©Ã•â€Ãœâ€”ÃÃ¼Â³Å¸
Ã¹PÅ’Ã™Â·Ã‰Ãâ€˜`GÃŠÃ§Ã»â‚¬Ã£â‚¬`1â€”lâ€ â‚¬â‚¬Ã¿ï¿½

LÃ¿â€œÃŸY@Ã‡â€â€¡&gt;56Â¬`OÅ¸â‚¬Ã˜ÂºÂ¢1jÃ“ÃµÃµUÃÃ›â€šÂ¶Â±mÃ‡YsÂ¬CÃ·Ã³Ã¦Ã®7ÃºÃ°Ã ;gwvoï¿½Ã³Ã¢â‚¬UÃšdÃ˜â‚¬â‚¬â‚¬Ã¿ï¿½
Ã¿â€œÃÂ´Pâ‚¬â‚¬â‚¬â‚¬â‚¬Ã¿ï¿½
IÃ¿â€œâ‚¬Ã€Ã¡Ã tâ‚¬ ?Â°Â³Ã|,â€¹BPV1pÅ½Ã±(	â‚¬Å“Ã¨VÃ«0NÆ’H+^{Â¶Ãƒâ€¹Å â€¹Ã»Ã¥â€¹ÃƒÃ†yNÃ—â‚¬Â¢Â¦&amp;Ã¿ï¿½
HÃ¿â€œÃâ€ZÃ€]Â¾KÂ¤#Ã­â€ºwÃ´Gâ€š_Â®Â¸Ã„Ã¸8&gt; Ã¸@C(Ã¡_Ã™^2â€!Ã´Å“ =Ã¨â€”Ã°lGbÂ¥Ã‰Â¡Âµâ‚¬Ã¿ï¿½
Â£Ã¿â€œÃ‡Ã†F&gt;#Ã²@[Ã–&gt;Ã¬Â¨ÃÃŸRxtÂ®tlFÃ§1Ã¸Â¼ï¿½eÃ·Ã©Ã’Â­C&lt;Ã¨â€°I
GÃ«Â«)AÃŸqÂ¢1Ã‰Â«|Å½Â¢KÃ‰Ã³ÃœRÃ´Â¯Ã°Ã¡Ã´RÂ±ï¿½ÃMxâ€¹Ã„8Â±#ZÃªu#pâ€Ã’Å â€˜Å¡Â¾Å’oÂ½â‚¬Ã±'Ã¼Â¦â€¡lÃ­ÃŒlÃ–Å½lÂ¡
â€™â€”ÃÃ³jâ€ºwÂ°Ã£Å¸Ã¡xÂ­1Ã°Ã€]Â¾_09ÃŒÃ¿ï¿½
Ã¿â€œâ‚¬â‚¬â‚¬â‚¬â‚¬â‚¬Ã¿ï¿½
EÃ¿â€œÃï¿½D&lt;,&gt;Ã€`â€”â„¢Ã¶Ã†U]Oâ„¢Ã–E\Ã§Â¢Âº#Ã©Ã¼Ã´//Ã–sÃÅ“Â³PQÂ°â‚¬ÃŠ+Â°@Ã•Ã°H@
Ã­â‚¬Ã¿ï¿½
Â°Ã¿â€œÃ‡Ã„^&gt;#QÃ±1[EkÂ­Ã™Â¹BÃŒâ€Âª.â€¹`Ãªâ‚¬â€“ï¿½geMÃ½m3.VÅ Å Â»tÃšÃ¹Å¡Ã¥MÂ¿kÅ¸4-Ã³vGF3kÃ¬\oH,,Ã¥ÃÅ½1Å’nÃ¸ÃÃ¢Ã€HÂµ,Å¾Ã‘ÃÃ­S\Ã'Âº 7.]Ã¯Ã­Â«â„¢EÂ¤Ã» 
Â½C_Ã†Ã²Ã˜&lt;Ã¢Ã°Ã¼@D5â€ºT.Ã‰"TÅ¸p\MÂ¥;JÅ Ã†â€“Â¦Ã„ÃµNÃ¢E*Ã›&nbsp;OwÃ¿ï¿½
Â­Ã¿â€œÃ‡Ã„b&gt;"Ã±Ã±â€¢1`â€”Âµâ€œC4Â¼Ã¥ÂºÃ™ÂºÃ…XÅ¡Ã„Â«:Â¶â€šÃ â€¦ÃšÅ“?ÃÃ–Ã„2;Ã‘dÃ„Ã¢Ã¸Ã™Ã¬Ã·Ã·?Â¨(Ã‡ÃŠTÃ‡Â¶Ã¸XGÃ¶â€˜!Â¡8?ÃŠÃ¼Ã¸Â®â€™Ã—â€ºoÃ»Ã±
-9qÂ«â€ 7Mâ€”UÂ³ÃšÂ±EÃ¢(Ã³ï¿½Å¡Â»UÃ¬DÃ·Â¹Â°Â¤ËœÃ â€ºÃ‚Ãâ€˜â€¦Â¤Â²Ã£caâ‚¬{Ã¸ÃÃšOÃœÃ’VÆ’"4\
ÃˆÂ¢Å’BÃƒPÃ€0Â±â€Ã²Â­&amp;Ã¿ï¿½</dg[Â¦ï¿½Â³Ã´uÃ¥gtÂ·%Ã¾=}\Ã±Ã½mâ€°Â¶_Â£ï¿½+^Â¢Ã£-Ã¯Ã®%ÃºÂ¶Ã¢%:Ã¼Ã²$Ã¨Ã³Å¡Ã¿Ã¾Ã£nÂ£Ã¤@qn&â€“ÃºÂ¤â€¹ï¿½></c[ÂºÃ­Ã´â€¦Ã¥3tÂ±Â¥Â¢></i!vdtâ€¹64nÃ©%!Ã¿eÃ§hÃ£Â®ez1Æ’Å¾Ã±â€Ãª%zÂ±Æ’Â®Ã±â€></qÃ»Ã¤ez)qâ€nÃ­Ã©Ã¸Ã«Ã´pÃ¢jï¿½Â®Ã­sz(qÂ¥cÃ—Ã¦Æ’dÃ¼5z'qâ€¡Ã®Ã­[Â¦Â¯Ã²3â€°;tnÂ¨Ã­Ã½â€¢Â¾â€º"Ã²Â¤Æ’3></o^Å¾Å“Ã§6Ã¿Â¤tÂ¤Ã¨Ã½Ã·Ãµ|Ã¬Ã¼Ã Ã®â€¹]Ã¿Ã—Â¼<Ã¹Ã¢Ã¯Ã§Ã¯Ã¶<Ã¤Ã­c_vÂ¸xÂ·Ã±d.Ã¯&Â¶Ã¤kÃ¾Ã®Ã¸Ã©Ã¯Ãµ!jÃ½g></iÃ¨Ã¹Ã«.Ã£Ã¥xÂ¬Ã¡kÂ¸Â½&Â³Ã­Ã±Ã¯Ã¥jok"@Ã¿vÃ£yÃ vÃ¤ÃºÂ¾Â³Ã½Ã¡lÃ¾1[Ã¼Ã§Â´vixzÃ¸Â²Ã£h=â€œÃ­â€ºÅ¾cÃ«Ã»Ã¥></s5+Ã±yÂ³Ã¯Å¾!Å“)ÃŸ#Ã¦Ã¾Ãºâ€˜:Â»Ã£Æ’ÃµÃ Ã¾~ï¿½Ã¸Å“Ã¯tÅ¾â€˜eâ€¹)xÃ¹Ã§Ã²kÃ¾Ã¯.38Ãº2Ã·Ã³nÃºl&Â£aÅ¡zÂ­Â¼Ã©07Ã³Ã¥`></y></dÃ»:â€ÃªsmlÃºryÂªÃ¯ï¿½b></cÃ«xj></vÃ¼â€¡Ãºâ€ Ã©'â€°ï¿½k]â€“'ÂªÃ¨|9Ã¢Ã¨Â·[Ãªr"bâ€ #Ã£â€œ[mÃµÂ¦_ql]yÂ¨Â¾Ã©Â½9Ã£vÃ±Â¤<\Â­ï¿½#(â€°Å¾ÂµzÂ¤qÃ¹â€˜b></rf8jâ€œ3Â¹'yÃ—Â³Ãªz2ï¿½):8gl{bucï¿½Ã¥:Ã¨Å¡Å¾Å“â‚¬â€™*eÃ¦2Ã½Ãºv9ÃµÂ¦;@Ã¬qÂ¥ï¿½bËœÃ¾ÃªÂªÂ©zÂºÂ©Ã±></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://equitablemath.org/wp-content/uploads/sites/2/2020/11/1_STRIDE1.pdf">https://equitablemath.org/wp-content/uploads/sites/2/2020/11/1_STRIDE1.pdf</a></em></p>]]>
            </description>
            <link>https://equitablemath.org/wp-content/uploads/sites/2/2020/11/1_STRIDE1.pdf</link>
            <guid isPermaLink="false">hacker-news-small-sites-26188717</guid>
            <pubDate>Fri, 19 Feb 2021 02:15:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Squad: Forth on Chip-8]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26188165">thread link</a>) | @RodgerTheGreat
<br/>
February 18, 2021 | https://internet-janitor.itch.io/squad | <a href="https://web.archive.org/web/*/https://internet-janitor.itch.io/squad">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://internet-janitor.itch.io/squad</link>
            <guid isPermaLink="false">hacker-news-small-sites-26188165</guid>
            <pubDate>Fri, 19 Feb 2021 01:06:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Texas power outage is a nation-wide problem]]>
            </title>
            <description>
<![CDATA[
Score 241 | Comments 395 (<a href="https://news.ycombinator.com/item?id=26186645">thread link</a>) | @gwoplock
<br/>
February 18, 2021 | https://garrettbattaglia.com/post/texas-power/ | <a href="https://web.archive.org/web/*/https://garrettbattaglia.com/post/texas-power/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div>
        <p>Let me preface this with an explanation. Over the last few days I read online people saying that Texas' power outages had been caused by Texas being on its own gridâ€¦ deregulationâ€¦ Not following national standardsâ€¦  had Texas been connected to the Eastern Interconnection or the Western Interconnection none of this would have happened. But not one post shows any evidence or requirements that backed up these claims. So, I went looking for proof and instead of finding requirements, I found a nationwide problem with winterization. As an aside I am not an expert in the grid or electricity, I am a software developer, and this is my best interpretation of the requirements I could find.</p>
<p>Letâ€™s start off with how the electrical grid works in the US. The grid is made up of 3 interconnections: the Eastern Interconnection, the Western Interconnection, and the Texas Interconnect. Each of these interconnections operate in (near) isolation with their own frequency, voltage, and phase. There are several high voltage DC interconnects (HVDC or DC-DC) between them. In each of these interconnections there is at least one grid operators, for example ERCOT in Texas. These grid operators manage the generation and load of their interconnection, acting as almost as an electric clearing house. They are also responsible for keeping voltage and frequency within range and directing distributors (like ONCOR in north Texas) to shed load during Electrical Emergency Alerts (EEA). An important thing to note for later, from the best I can tell the different grid operators in the Eastern Interconnect share power in a â€œnon-firm, as-available basisâ€.</p>
<p>What happened in Texas, starting 12:30 AM February 15. The long and short of it is an estimated 34GW of generation went offline in about 2 hours[1]. Looking at ERCOTâ€™s tweets [2,3,4], generation was starting to have an issue at 00:17:45 and some load needed to be shed so ERCOT issued the first EEA (EEA1). In the February EEA tools document[5] EEA1 can open up around 1.6GW of â€œpeekerâ€ generation and importation from the Eastern and Western Interconnections. But by 1:12:06 that wasnâ€™t enough and additional load had to be shed.  A second EEA was issued (EEA2) shedding another 1.6GW. But just a few minutes later the house came crashing down and at 1:25:40 the third EEA (EEA3) was issued. In addition to starting rolling blackouts to shed most of the load it also allowed for other actions to free .1-.2GW of load.</p>
<p>The 34GW of generation lost was from every fuel source used. Most of it was frozen-off natural gas (gas) wells, some of it was frozen wind turbines, solar panels that had snow on them and even a nuclear plant had to go offline due to issues with feedwater pressure sensing issues related to the cold.
What do the North American Electric Reliability Corporation (NERC) standards say about protecting any of these sources? Not much.</p>
<p>Letâ€™s start by looking at the least complex, wind turbines. On September 12, 2012 NERC published a Lesson Learned document in regards to Texasâ€™s issues with some of the wind farms freezing in extreme winter weather[6]. According to the document the event that was predicted over a week beforehand brought 4 days of low temperature, high winds and wind chills, ice and snow that limited the generation facility to just 25% of capacity. The facility did have a SOP for icing conditions that was implemented. However, the facility never defined itâ€™s minimum operating temperature. When lightning knocked out some of the sensing equipment, the turbines had to be stop for safety. The repair crews couldnâ€™t immediately get to the turbines and they had to sit, this gave the oil a chance to cool and partly freeze. When the turbines were returned to service, they tripped back off due to high oil pressure. Eventually after working with the manufacturer they were able to safely heat the oil and restart the turbines. One of the big lessons from this was to install cold weather packs for wind turbines and watch the oil temperature. Youâ€™d think that would solve future outage, but no, in 2019 in the midwestwind turbines failed due to exceptionally low temperatures, around -21. Again the cold weather package hadnâ€™t been installed and was one of the root causes of the failure[7].</p>
<p>The nuclear plantâ€™s sensing problems had happened before too. Although it wasnâ€™t a nuclear plant, there are several documented cases on NERCâ€™s website citing cold weather and sensor issues [8,9]. This repeated in Texas (2011) and in the south east (2018)[10].</p>
<p>Letâ€™s discuss natural gas next. It appears that most of the issues in the problematic natural gas fired facilities was due to low gas supplies. In 2012 NERC warned of the interconnectivity of natural gas and electric[11]. Natural gas coming out of the ground has a naturally high water content. This water can freeze the extraction equipment during sub-freezing weather in improperly winterized wells creating what is know as a freeze-off. businesses, residential customers, and powerplants all run off the same supply, once wells start freezing off the supply dwindles for all. Natural gas companies prioritize residential customers as needed and will cut businesses and powerplants. This obviously creates issues in electrical generation.</p>
<p>In this latest case, much of the gas generation loss was due to under pressure conditions at the generation site. When generation sites detect this kind of fault, they are taken offline for safety. Not only is this what happened this year, but it has happened many, many times before</p>
<p>The most resent case I could find was 2018 in the south east[10]. Starting on January 18, 2018 a large area in the south east US experienced unusually cold weather. This caused 183 generation facilities to go offline or operate with greatly reduced output. At the peak there was nearly 30GW of production lost. This caused several grid operators to issue EEAs and begin rolling blackouts. In the â€œevent areaâ€ 14% of the failures could be directly attributed to the cold weather. And another 30% could be indirectly linked to weather, including mechanical failures know to happen in cold weather and gas supply issues. NERC found that more than 33% of the failed powerplants didnâ€™t have a winterization plan.</p>
<p>Why didnâ€™t these plants have a winterization plan? Because it wasnâ€™t required[10,12].</p>
<p>This wouldnâ€™t be so bad if this wqs the first time it happened, it wasnâ€™t even the second time it happened. In 2014 a polar vortex hit the US. bringing temperatures well below normal. During this event 55% of the outages were at gas power plants and in all 90GW of generation was lost[13].</p>
<p>The earliest report I could find was from the 2011 winter event in Texas[14]. A very strong cold front hit Texas (and other parts of the south central US) bringing temperatures below freezing for over 4 days and winds over 30 MPH. Leading up to the event, ERCOT and other grid operators in surrounding areas felt that there wouldnâ€™t be a need for rolling blackouts. At the beginning of the event ERCOT had 3.1GW of reserve, nearly 1GW over the minimum required. However, over the next 2 days ERCOT lost nearly 30GW of production in 193 generation facilities. ERCOT was able to stabilize the grid with rolling blackouts and the other EEA methods[5]. Other grids suffered problems as well, EPE (El Paso) and SRP (Arizona) lost nearly 1.4GW due to cold weather. Another issue in ERCOTâ€™s region was nearly 50% of the â€œblack startâ€ facilities were either down for scheduled maintenance or failed on startup. One of the main causes again was the loss of gas during this blackout period. 14.8 Bcf of natural gas production was lost due to freeze-offs, electrical outages (ironically) and customer curtailments. following the previous equivalent storm in 1989, the PUCT (Public Utility Commission of Texas) issued several recommendations and guidelines for winterization of power plants and gas wells. However, due to the infrequency of these storms the implementation lacked. With many of the same facilities that failed in 1989 also failed in 2011.  My guess is these same sites failed again in 2021. Interestingly the NERC found that it is quite possible that gas production in these unusually cold conditions may be impossible.</p>
<p>What has been done since 2011? Not a whole lot. A request for a new standard was issued to NERC in late 2012, however a few months later it was denied.[15] Also in 2012 NERC put out a set of guidelines for developing a plan for winter weather[16]. In 2017 NERC put out a special reliability report on the relationship between gas and electricity[17]. Finally, after the 2018 event NERC received another standard request that was approved[23], however it wonâ€™t be finalized until late 2021[18,19,20].</p>
<p>From what I can see, ERCOT has more restrictive rules in their Generator Winter Weatherization Workshop than NERC[21]. All generation stations must have plans for emergencies, address abnormal weather, critical failure points, weather design limits, alternative fuels and testing[21,22]. ERCOT reports that there were 80 spot checks done in the 2019/2020 season with 71 being gas plants and 6 being black start gas plants. 23 had to improve and would be reinspected in early 2021 the rest passed.</p>
<p>The issue of extreme cold weather and electrical outages is a national issue that needs to be addressed. However, after repeated failings it hasnâ€™t really been addressed. Hopefully with the new NERC requirements and the Texas legislature in session progress can be made.</p>
<hr>
<p>[1] <a href="http://www.ercot.com/news/releases/show/225244">http://www.ercot.com/news/releases/show/225244</a><br>
[2] <a href="https://twitter.com/ERCOT_ISO/status/1361197991659503618">https://twitter.com/ERCOT_ISO/status/1361197991659503618</a><br>
[3] <a href="https://twitter.com/ERCOT_ISO/status/1361211669788176384">https://twitter.com/ERCOT_ISO/status/1361211669788176384</a><br>
[4] <a href="https://twitter.com/ERCOT_ISO/status/1361215084010352644">https://twitter.com/ERCOT_ISO/status/1361215084010352644</a><br>
[5] <a href="http://www.ercot.com/content/wcm/lists/219692/EEA_Tools_One_Pager_Winter_2021_2-13-2021.pdf">http://www.ercot.com/content/wcm/lists/219692/EEA_Tools_One_Pager_Winter_2021_2-13-2021.pdf</a><br>
[6] <a href="https://www.nerc.com/pa/rrm/ea/Lessons%20Learned%20Document%20Library/LL20120901_Wind_Farm_Winter_Storm_Issues.pdf">https://www.nerc.com/pa/rrm/ea/Lessons%20Learned%20Document%20Library/LL20120901_Wind_Farm_Winter_Storm_Issues.pdf</a><br>
[7] <a href="https://www.nerc.com/pa/rrm/ea/Lessons%20Learned%20Document%20Library/LL20200601_Unanticipated_Wind_Generation_Cutoffs_during_a_Cold_Weather_Event.pdf">https://wâ€¦</a></p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://garrettbattaglia.com/post/texas-power/">https://garrettbattaglia.com/post/texas-power/</a></em></p>]]>
            </description>
            <link>https://garrettbattaglia.com/post/texas-power/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26186645</guid>
            <pubDate>Thu, 18 Feb 2021 22:26:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Gleam 0.14 â€“ type-safe language for the Erlang VM]]>
            </title>
            <description>
<![CDATA[
Score 244 | Comments 38 (<a href="https://news.ycombinator.com/item?id=26185690">thread link</a>) | @lpil
<br/>
February 18, 2021 | https://gleam.run/news/gleam-v0.14-released/ | <a href="https://web.archive.org/web/*/https://gleam.run/news/gleam-v0.14-released/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
  <div>
<p>Hot on the heels of Gleam v0.13 comes another release, <a href="https://github.com/gleam-lang/gleam/releases/tag/v0.14.0">Gleam v0.14</a>!
As always, letâ€™s take a look at some of the highlights.</p>

<h2 id="dialyzer--erlang-typespecs">Dialyzer &amp; Erlang typespecs</h2>

<p>Many dynamically typed BEAM languages support Erlangâ€™s typespecs, type
annotations that can be analysed with the <a href="https://erlang.org/doc/man/dialyzer.html">Dialyzer</a> tool. While
not as powerful or reliable as Gleamâ€™s type system it can be a useful tool
for finding problems with your Erlang or Elixir code. Dialyzer doesnâ€™t
require typespecs but it can work better if they are added to the code.</p>

<p>Starting with this release Gleam will generate typespecs for all functions
and Erlang type definitions for all declared types within a Gleam program,
giving you one extra tool to help you write robust and reliable code when
using Gleam alongside Elixir or Erlang.</p>

<p>For a quick example, hereâ€™s some code in Gleam:</p>

<div><div><pre><code><span>pub</span> <span>type</span> <span>LinkedList</span><span>(</span><span>element</span><span>)</span> <span>{</span>
  <span>Empty</span>
  <span>Node</span><span>(</span><span>element</span><span>,</span> <span>LinkedList</span><span>(</span><span>element</span><span>))</span>
<span>}</span>

<span>pub</span> <span>fn</span> <span>is_empty</span><span>(</span><span>list</span><span>)</span> <span>{</span>
  <span>list</span> <span>==</span> <span>Empty</span>
<span>}</span>

<span>pub</span> <span>fn</span> <span>map</span><span>(</span><span>list</span><span>,</span> <span>fun</span><span>)</span> <span>{</span>
  <span>case</span> <span>list</span> <span>{</span>
    <span>Empty</span> <span>-&gt;</span> <span>Empty</span>
    <span>Node</span><span>(</span><span>i</span><span>,</span> <span>list</span><span>)</span> <span>-&gt;</span> <span>Node</span><span>(</span><span>fun</span><span>(</span><span>i</span><span>),</span> <span>map</span><span>(</span><span>list</span><span>,</span> <span>fun</span><span>))</span>
  <span>}</span>
<span>}</span>
</code></pre></div></div>

<p>And hereâ€™s the Erlang code and typespecs it compiles to:</p>

<div><div><pre><code><span>-</span><span>module</span><span>(</span><span>linked_list</span><span>).</span>
<span>-</span><span>compile</span><span>(</span><span>no_auto_import</span><span>).</span>

<span>-</span><span>export</span><span>([</span><span>is_empty</span><span>/</span><span>1</span><span>,</span> <span>map</span><span>/</span><span>2</span><span>]).</span>
<span>-</span><span>export_type</span><span>([</span><span>linked_list</span><span>/</span><span>1</span><span>]).</span>

<span>-</span><span>type</span> <span>linked_list</span><span>(</span><span>H</span><span>)</span> <span>::</span> <span>empty</span> <span>|</span> <span>{</span><span>node</span><span>,</span> <span>H</span><span>,</span> <span>linked_list</span><span>(</span><span>H</span><span>)}.</span>

<span>-</span><span>spec</span> <span>is_empty</span><span>(</span><span>linked_list</span><span>(</span><span>any</span><span>()))</span> <span>-&gt;</span> <span>boolean</span><span>().</span>
<span>is_empty</span><span>(</span><span>List</span><span>)</span> <span>-&gt;</span>
    <span>List</span> <span>=:=</span> <span>empty</span><span>.</span>

<span>-</span><span>spec</span> <span>map</span><span>(</span><span>linked_list</span><span>(</span><span>R</span><span>),</span> <span>fun</span><span>((</span><span>R</span><span>)</span> <span>-&gt;</span> <span>U</span><span>))</span> <span>-&gt;</span> <span>linked_list</span><span>(</span><span>U</span><span>).</span>
<span>map</span><span>(</span><span>List</span><span>,</span> <span>Fun</span><span>)</span> <span>-&gt;</span>
    <span>case</span> <span>List</span> <span>of</span>
        <span>empty</span> <span>-&gt;</span>
            <span>empty</span><span>;</span>

        <span>{</span><span>node</span><span>,</span> <span>I</span><span>,</span> <span>List</span><span>@</span><span>1</span><span>}</span> <span>-&gt;</span>
            <span>{</span><span>node</span><span>,</span> <span>Fun</span><span>(</span><span>I</span><span>),</span> <span>map</span><span>(</span><span>List</span><span>@</span><span>1</span><span>,</span> <span>Fun</span><span>)}</span>
    <span>end</span><span>.</span>
</code></pre></div></div>

<p>No annotations are required at all in your Gleam code to get full typespec
coverage, Gleamâ€™s compiler reuses the type information from its powerful type
inference algorithm to determine the correct typespecs.</p>

<p>Thank you <a href="https://gitlab.com/greggreg">Greg</a> for this brilliant new feature!</p>

<h2 id="erlang-escripts">Erlang escripts</h2>

<p>Erlang projects are unusual in that typically instead of having a <code>main</code>
function as the entrypoint of your application you define a tree of actors to
come online and process items of work while your program is running.</p>

<p>This can be a powerful way to write long-lived services that make use of the
runtimeâ€™s fault tolerance features, but it does not lend itself well to
short-lived programs such as command line scripts. It can be confusing to
newcomers from other languages too.</p>

<p>For these short lived programs Erlang <a href="https://erlang.org/doc/man/escript.html">escripts</a> are typically used.
These are lightweight Erlang programs that have a <code>main</code> function as an entrypoint.</p>

<p>To make it easier to use these from Gleam the <code>gleam new</code> command now has an
escript template that can be used to create an escript project without any
further configuration required.</p>

<div><div><pre><code>gleam new my_script <span>--template</span> escript
</code></pre></div></div>

<p>A world class developer experience is a key goal of the Gleam project.
Further tooling improvements are right around the corner!</p>

<h2 id="night-mode">Night mode</h2>

<p>Gleam has the ability to render <a href="https://hexdocs.pm/gleam_stdlib/">HTML documentation</a> 
for your code, ready to upload to Hexdocs.</p>

<p>Thanks to <a href="https://github.com/tynanbe">Tynan Beatty</a> the documentation is
looking better than ever! Thereâ€™s too many improvements to list but the big
one is they now have a night mode! If youâ€™re a night owl like me Iâ€™m sure you
will enjoy the lower contrast dark tones when doing some late evening coding.</p>

<p><img src="https://gleam.run/images/news/gleam-v0.14-released/night-mode.png" alt="A screenshot of Gleam's rendered docs showing a beautiful dark theme"></p>

<h2 id="better-errors-again">Better errors, again</h2>

<p>At the risk of sounding like a broken record Gleamâ€™s error messages have been
improved yet again. Hereâ€™s an example of one of the improvements:</p>

<p>Before:</p>

<div><div><pre><code>error: Syntax error
    â”Œâ”€ /src/thing.gleam:115:18
    â”‚
115 â”‚ pub fn overlappedBy(compare, a, b) -&gt; Bool {
    â”‚                  ^^ I was not expecting this.

Expected one of: "("
</code></pre></div></div>

<p>Now:</p>

<div><div><pre><code>error: Syntax error
    â”Œâ”€ /src/thing.gleam:115:18
    â”‚
115 â”‚ pub fn overlappedBy(compare, a, b) -&gt; Bool {
    â”‚                  ^^ This is not a valid name.

Hint: Names start with a lowercase letter and contain a-z, 0-9, or _.
Try: overlapped_by
</code></pre></div></div>

<p>Thank you to <a href="https://github.com/samontea">Samuel Mercier</a> and <a href="https://github.com/pd-andy">Andy
Thompson</a> for these.</p>

<h2 id="static-bit-string-validation">Static bit string validation</h2>

<p>Bit string syntax is a feature that Gleam inherits from Erlang. It provides a
way to declartively and concisely construct and manipulate raw bits of data
through literals and pattern matching.</p>

<p>With this Gleam release we apply further static analysis to bit string
literals and patterns used in Gleam programs to catch invalid or incorrect
code.</p>

<p>Hereâ€™s an example of one of the errors that may be reported:</p>

<div><div><pre><code>error: Syntax error
  â”Œâ”€ /Users/a/parser_test/src/a.gleam:2:20
  â”‚
2 â”‚   &lt;&lt;1:size(1)-unit(0)&gt;&gt;
  â”‚                    ^ This is not a valid BitString unit value.

Hint: unit must be an integer literal &gt;= 1 and &lt;= 256
See: https://gleam.run/book/tour/bit-strings
</code></pre></div></div>

<p>Thank you <a href="https://gitlab.com/greggreg">Greg</a> for this bit string safety net.</p>

<h2 id="docker-images">Docker images</h2>

<p>Up until now <a href="https://github.com/CrowdHailer">Peter Saxton</a> has been very kindly
building Gleam docker images for use in <a href="https://sendmemo.app/">Memo</a> and the
wider community.</p>

<p>With this release he has ported his build automation over to the Gleam repo
so we have automation creation of OCI/Docker images built and published
automatically with each release.</p>

<p>We are building these variants:</p>

<ul>
  <li><code>gleam-erlang</code>: Gleam and the Erlang tooling on Ubuntu Linux</li>
  <li><code>gleam-erlang-slim</code>: Gleam and the Erlang tooling on slim Debian Linux</li>
  <li><code>gleam-erlang-alpine</code>: Gleam and the Erlang tooling on Alpine Linux</li>
  <li><code>gleam-elixir</code>: Gleam and the Elixir tooling on Ubuntu Linux</li>
  <li><code>gleam-elixir-slim</code>: Gleam and the Elixir tooling on slim Debian Linux</li>
  <li><code>gleam-elixir-alpine</code>: Gleam and the Elixir tooling on Alpine Linux</li>
</ul>

<p>For all the images see the <a href="https://github.com/orgs/gleam-lang/packages/container/package/gleam">Gleam image registry</a>. Thanks Peter!</p>

<h2 id="other-stuff">Other stuff</h2>

<p>These are just some of the highlights, but thereâ€™s plenty more improvements
made to the compiler and the standard library since the last release. For all
the details check out the changelog files:</p>

<ul>
  <li><a href="https://github.com/gleam-lang/gleam/blob/main/CHANGELOG.md">Gleamâ€™s changelog</a></li>
  <li><a href="https://github.com/gleam-lang/stdlib/blob/main/CHANGELOG.md">Gleam stdlibâ€™s changelog</a></li>
</ul>

<h2 id="discord-chat">Discord chat</h2>

<p>Itâ€™s time to plug the Gleam Discord server again! The community continues to
grow and it would be great to have you there too, so please click on the
button below.</p>

<center>
  <a href="https://discord.gg/Fm8Pwmy"><img src="https://img.shields.io/discord/768594524158427167?color=blue" alt="Discord chat"></a>
</center>

<h2 id="try-it-out">Try it out</h2>

<p>If you want to try out the new version of Gleam head over to the <a href="https://gleam.run/getting-started/">getting started
page</a>. Iâ€™d love to hear how you find it and get your feedback so
Gleam can continue to improve.</p>

<p>Want to view some existing Gleam projects? Head on over to the
<a href="https://github.com/gleam-lang/awesome-gleam">awesome-gleam</a> list. Looking for something to build in
Gleam? Check out <a href="https://github.com/gleam-lang/suggestions/issues">the suggestions tracker</a>.</p>

<h2 id="supporting-gleam">Supporting Gleam</h2>

<p>If you would like to help make strongly typed programming on the Erlang
virtual machine a production-ready reality please consider <strong><a href="https://github.com/sponsors/lpil">sponsoring
Gleam</a></strong> via the GitHub Sponsors program.</p>

<p>â­ Or alternatively give us a star on <a href="https://github.com/gleam-lang/gleam">GitHub</a>! â­</p>

<p>This release would not have been possible without the support of all the
people who have <a href="https://github.com/sponsors/lpil">sponsored</a> and contributed
to it, so a huge thank you to them.</p>

<ul>
  <li><a href="https://github.com/adamnbowen">Adam Bowen</a></li>
  <li><a href="https://github.com/amokan">Adam Mokan</a></li>
  <li><a href="https://github.com/aditya7iyengar">Adi Iyengar</a></li>
  <li><a href="https://github.com/scripttease">Al Dee</a></li>
  <li><a href="https://github.com/mudriyjo">Alexander Babin</a></li>
  <li><a href="https://github.com/farhadi">Ali Farhadi</a></li>
  <li><a href="https://github.com/pd-andy">Andy Thompson</a></li>
  <li><a href="https://github.com/bees">Arian Daneshvar</a></li>
  <li><a href="https://github.com/arnodirlam">Arno Dirlam</a></li>
  <li><a href="https://github.com/benmyles">Ben Myles</a></li>
  <li><a href="https://github.com/nono">Bruno Michel</a></li>
  <li><a href="https://github.com/brightly-salty">Caden Haustein</a></li>
  <li><a href="https://github.com/choonkeat">Chew Choon Keat</a></li>
  <li><a href="https://github.com/chrislloyd">Chris Lloyd</a></li>
  <li><a href="https://github.com/worldofchris">Chris Young</a></li>
  <li><a href="https://github.com/tlvenn">Christian Meunier</a></li>
  <li><a href="https://github.com/clangley">clangley</a></li>
  <li><a href="https://github.com/cleverbunny">Clever Bunny LTD</a></li>
  <li><a href="https://github.com/codec-abc">codec-abc</a></li>
  <li><a href="https://github.com/colelawrence">Cole Lawrence</a></li>
  <li><a href="https://github.com/connorlay">Connor Lay (Clay)</a></li>
  <li><a href="https://github.com/cschembor3">Connor Schembor</a></li>
  <li><a href="https://github.com/unthought">Dan Mueller</a></li>
  <li><a href="https://github.com/davydog187">Dave Lucia</a></li>
  <li><a href="https://github.com/rawkode">David McKay</a></li>
  <li><a href="https://github.com/davidpdrsn">David Pedersen</a></li>
  <li><a href="https://github.com/dangdennis">Dennis Dang</a></li>
  <li><a href="https://github.com/lostbean">Edgar Gomes</a></li>
  <li><a href="https://github.com/ericmj">Eric Meadows-JÃ¶nsson</a></li>
  <li><a href="https://github.com/eterps">Erik Terpstra</a></li>
  <li><a href="https://github.com/floriank">Florian Kraft</a></li>
  <li><a href="https://github.com/itsgreggreg">greggreg</a></li>
  <li><a href="https://github.com/ggpasqualino">Guilherme Pasqualino</a></li>
  <li><a href="https://github.com/hendi">Hendrik Richter</a></li>
  <li><a href="https://github.com/hhandoko">Herdy Handoko</a></li>
  <li><a href="https://github.com/human154">human154</a></li>
  <li><a href="https://github.com/Ian-GL">Ian GonzÃ¡lez</a></li>
  <li><a href="https://github.com/igagen">Ingmar Gagen</a></li>
  <li><a href="https://github.com/ivarvong">Ivar Vong</a></li>
  <li><a href="https://github.com/gampleman">Jakub Hampl</a></li>
  <li><a href="https://github.com/jamesmacaulay">James MacAulay</a></li>
  <li><a href="https://github.com/janpieper">Jan Pieper</a></li>
  <li><a href="https://github.com/jechol">Jechol Lee</a></li>
  <li><a href="https://github.com/jeffkreeftmeijer">Jeff Kreeftmeijer</a></li>
  <li><a href="https://github.com/jiangplus">jiangplus</a></li>
  <li><a href="https://github.com/joecorkerton">Joe Corkerton</a></li>
  <li><a href="https://github.com/Jwsonic">John Palgut</a></li>
  <li><a href="https://github.com/josevalim">JosÃ© Valim</a></li>
  <li><a href="https://github.com/jveiga">JoÃ£o Veiga</a></li>
  <li><a href="https://github.com/jmn">Jussi Norlund</a></li>
  <li><a href="https://github.com/kapp-technology">Kapp Technology</a></li>
  <li><a href="https://github.com/kodeFant">Lars Lillo Ulvestad</a></li>
  <li><a href="https://github.com/lawik">Lars Wikman</a></li>
  <li><a href="https://github.com/leandrocp">Leandro Cesquini Pereira</a></li>
  <li><a href="https://github.com/malcolmseyd">Malcolm Seyd</a></li>
  <li><a href="https://github.com/mario-mazo">mario</a></li>
  <li><a href="https://github.com/mvellandi">Mario Vellandi</a></li>
  <li><a href="https://github.com/markmark206">Mark Markaryan</a></li>
  <li><a href="https://github.com/markusfeyh">Markus</a></li>
  <li><a href="https://github.com/derhechi">Markus Hechenberger</a></li>
  <li><a href="https://github.com/MattCheely">Matthew Cheely</a></li>
  <li><a href="https://github.com/bausano">Michael Bausano</a></li>
  <li><a href="https://github.com/michaeljones">Michael Jones</a></li>
  <li><a href="https://github.com/michallepicki">MichaÅ‚ ÅÄ™picki</a></li>
  <li><a href="https://github.com/mroach">Mike Roach</a></li>
  <li><a href="https://github.com/slashmili">Milad</a></li>
  <li><a href="https://github.com/ndreynolds">Nick Reynolds</a></li>
  <li><a href="http://www.ninefx.com/">NineFX</a></li>
  <li><a href="https://github.com/jraregris">Oddmund StrÃ¸mme</a></li>
  <li><a href="https://github.com/sorentwo">Parker Selbert</a></li>
  <li><a href="https://github.com/phiat">Patrick Ryan</a></li>
  <li><a href="https://github.com/PeteJodo">Pete Jodo</a></li>
  <li><a href="https://github.com/CrowdHailer">Peter Saxton</a></li>
  <li><a href="https://github.com/praveenperera">Praveen Perera</a></li>
  <li><a href="https://github.com/qingliangcn">qingliangcn</a></li>
  <li><a href="https://github.com/happysalada">Raphael Megzari</a></li>
  <li><a href="https://github.com/chouzar">RaÃºl  Humberto Chouza Delgado</a></li>
  <li><a href="https://github.com/redmar">Redmar Kerkhoff</a></li>
  <li><a href="https://github.com/reneklacan">RenÃ© KlaÄan</a></li>
  <li><a href="https://github.com/romatthe">Robin Mattheussen</a></li>
  <li><a href="https://github.com/rvcas">rvcas</a></li>
  <li><a href="https://github.com/samaaron">Sam Aaron</a></li>
  <li><a href="https://github.com/samontea">samontea</a></li>
  <li><a href="https://github.com/mrgleam">Santi</a></li>
  <li><a href="https://github.com/sascha-wolf">Sascha Wolf</a></li>
  <li><a href="https://github.com/sasa1977">SaÅ¡a JuriÄ‡Ã§</a></li>
  <li><a href="https://github.com/scottwey">Scott Wey</a></li>
  <li><a href="https://github.com/seanjensengrey">Sean Jensen-Grey</a></li>
  <li><a href="https://github.com/sporto">Sebastian</a></li>
  <li><a href="https://github.com/shanesveller">Shane Sveller</a></li>
  <li><a href="https://github.com/shritesh">Shritesh Bhattarai</a></li>
  <li><a href="https://github.com/simonewebdesign">Simone Vittori</a></li>
  <li><a href="https://github.com/syukronrm">Syukron Rifail M</a></li>
  <li><a href="https://github.com/terkiterje">Terje Bakken</a></li>
  <li><a href="https://github.com/timbuchwaldt">Tim Buchwaldt</a></li>
  <li><a href="https://github.com/tomekowal">Tomasz Kowal</a></li>
  <li><a href="https://github.com/thara">Tomochika Hara</a></li>
  <li><a href="https://github.com/topherhunt">Topher Hunt</a></li>
  <li><a href="https://github.com/tsloughter">Tristan Sloughter</a></li>
  <li><a href="https://github.com/twilco">Tyler Wilcock</a></li>
  <li><a href="https://github.com/tynanbe">tynanbe</a></li>
  <li><a href="https://github.com/wojtekmach">Wojtek Mach</a></li>
</ul>

<p>Thanks for reading! Have fun! ğŸ’œ</p>

</div>

</article></div>]]>
            </description>
            <link>https://gleam.run/news/gleam-v0.14-released/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26185690</guid>
            <pubDate>Thu, 18 Feb 2021 21:16:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Over 140K virus species identified in human gut, 50% never seen before]]>
            </title>
            <description>
<![CDATA[
Score 10 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26185338">thread link</a>) | @finphil
<br/>
February 18, 2021 | https://nuadox.com/post/643491384977948672/140k-virus-species-in-human-gut | <a href="https://web.archive.org/web/*/https://nuadox.com/post/643491384977948672/140k-virus-species-in-human-gut">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div> 
                 
                    
                    <article id="643491384977948672">
                        <div>
                            <div>
                                <a href="https://nuadox.com/post/643491384977948672/140k-virus-species-in-human-gut"><h2>Over 140K virus species identified in human gut, 50% never seen before</h2></a>
                                <figure data-orig-width="1280" data-orig-height="904"><img src="https://64.media.tumblr.com/1a0215a61c5578609506d640223a0ec8/5275df9a1bb2e1fe-38/s1280x1920/64f1e6d38b7d741e57ff618b396d3322a825dc76.jpg" alt="image" data-orig-width="1280" data-orig-height="904" width="1280" height="904"></figure><p><b>- By <a href="https://href.li/?https://www.sanger.ac.uk/">Wellcome Sanger Institute</a> -</b></p><p>

Viruses are the most numerous biological entities on the planet. Now researchers at the Wellcome Sanger Institute and EMBLâ€™s European Bioinformatics Institute (EMBL-EBI) have identified over 140,000 viral species living in the human gut, more than half of which have never been seen before.

<br></p><p>The paper, published today in <i><a href="https://href.li/?https://doi.org/10.1016/j.cell.2021.01.029">Cell</a></i>, contains an analysis of over 28,000 gut microbiome samples collected in different parts of the world. The number and diversity of the viruses the researchers found was surprisingly high, and the data opens up new research avenues for understanding how viruses living in the gut affect human health.</p><p>The human gut is an incredibly biodiverse environment. In addition to bacteria, hundreds of thousands of viruses called bacteriophages, which can infect bacteria, also live in the human gut.</p><p>It is known that imbalances in our gut microbiome can contribute to diseases and complex conditions such as Inflammatory Bowel Disease, allergies and obesity. But relatively little is known about the role our gut bacteria, and the bacteriophages that infect them, play in human health and disease.</p><p>Using a DNA-sequencing method called metagenomics*, researchers at the Wellcome Sanger Institute and EMBLâ€™s European Bioinformatics Institute (EMBL-EBI) explored and catalogued the biodiversity of the viral species found in 28,060 public human gut metagenomes and 2,898 bacterial isolate genomes cultured from the human gut.</p><p>The analysis identified over 140,000 viral species living in the human gut, more than half of which have never been seen before.</p><h2>â€œItâ€™s important to remember that not all viruses are harmful, but represent an integral component of the gut ecosystem. For one thing, most of the viruses we found have DNA as their genetic material, which is different from the pathogens most people know, such as SARS-CoV-2 or Zika, which are RNA viruses. Secondly, these samples came mainly from healthy individuals who didnâ€™t share any specific diseases. Itâ€™s fascinating to see how many unknown species live in our gut, and to try and unravel the link between them and human health.â€<b><br></b></h2><p><b>Dr Alexandre Almeida, Postdoctoral Fellow at EMBL-EBI and the Wellcome Sanger Institute</b><br></p><p>Among the tens of thousands of viruses discovered, a new highly prevalent clade â€“ or group of viruses believed to have a common ancestor â€“ was identified, which the authors refer to as the Gubaphage. This was found to be the second most prevalent virus clade in the human gut, after the crAssphage, which was discovered in 2014.</p><p>Both of these viruses seem to infect similar types of human gut bacteria, but without further research itâ€™s very difficult to know the exact functions of the newly discovered Gubaphage.</p><h2>â€œAn important aspect of our work was to ensure that the reconstructed viral genomes were of the highest quality. A stringent quality control pipeline coupled with a machine learning approach enabled us to mitigate contamination and obtain highly complete viral genomes. High-quality viral genomes pave the way to better understand what role viruses play in our gut microbiome, including the discovery of new treatments such as antimicrobials from bacteriophage origin.â€<br></h2><p><b><a href="https://href.li/?https://www.sanger.ac.uk/person/camarillo-guerrero-luis-fernando/">Dr Luis F. Camarillo-Guerrero,</a>&nbsp;first author of the study from the Wellcome Sanger Institute</b></p><p>

The results of the study form the basis of the Gut Phage Database (GPD), a highly curated database containing 142,809 non-redundant phage genomes that will be an invaluable resource for those studying bacteriophages and the role they play on regulating the health of both our gut bacteria and ourselves.

<br></p><h2>â€œBacteriophage research is currently experiencing a renaissance. This high-quality, large-scale catalogue of human gut viruses comes at the right time to serve as a blueprint to guide ecological and evolutionary analysis in future virome studies.â€</h2><p><b><a href="https://href.li/?https://www.sanger.ac.uk/person/lawley-trevor/">Dr Trevor Lawley,</a>&nbsp;senior author of the study from the Wellcome Sanger Institute</b></p><p>â€“</p><p><i>

* Metagenomics is the study of a collection of genetic material (genomes) from a mixed community of organisms. Metagenomics usually refers to the study of microbial communities. The NIH National Human Genome Research Institute has more information here: <a href="https://href.li/?https://www.genome.gov/genetics-glossary/Metagenomics" title="* this link opens in a new window/tab">https://www.genome.gov/genetics-glossary/Metagenomics</a></i><br></p><p><b>Source:&nbsp;<a href="https://href.li/?https://www.sanger.ac.uk/news_item/scientists-identify-over-140000-virus-species-in-the-human-gut-half-of-which-are-new-to-science/">Wellcome Sanger Institute</a></b></p><p><b>Full study:</b>&nbsp;â€œMassive expansion of human gut bacteriophage diversityâ€,&nbsp;<i>Cell</i>.</p><p><a href="https://href.li/?https://doi.org/10.1016/j.cell.2021.01.029">https://doi.org/10.1016/j.cell.2021.01.029</a><br></p><h2><b>Read Also</b></h2><p><a href="https://nuadox.com/post/611601599114231808/fruit-fly-gut-microbiome">We could perhaps learn a lot by looking into a fruit flyâ€™s gut</a></p>
                    
                      
                    
                    
                    
                    
                    
                    
                    
                    
                                             
                                <p><span>
                                    <p>
                                    
                                        <a href="https://nuadox.com/tagged/virus">virus</a>
                                    
                                        <a href="https://nuadox.com/tagged/gut">gut</a>
                                    
                                        <a href="https://nuadox.com/tagged/biology">biology</a>
                                    
                                        <a href="https://nuadox.com/tagged/microbiology">microbiology</a>
                                    
                                        <a href="https://nuadox.com/tagged/bacteriophage">bacteriophage</a>
                                    
                                        <a href="https://nuadox.com/tagged/molecular-biology">molecular biology</a>
                                    
                                        <a href="https://nuadox.com/tagged/dna">dna</a>
                                    
                                        <a href="https://nuadox.com/tagged/genomics">genomics</a>
                                    
                                    </p>
                                </span></p>
                                
                            </div>
                        </div>
                    </article>
                 
                </div></div>]]>
            </description>
            <link>https://nuadox.com/post/643491384977948672/140k-virus-species-in-human-gut</link>
            <guid isPermaLink="false">hacker-news-small-sites-26185338</guid>
            <pubDate>Thu, 18 Feb 2021 20:52:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Bad Software and Expensive Mistakes]]>
            </title>
            <description>
<![CDATA[
Score 9 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26185082">thread link</a>) | @mattmarcus
<br/>
February 18, 2021 | https://www.moderntreasury.com/journal/bad-software-and-expensive-mistakes | <a href="https://web.archive.org/web/*/https://www.moderntreasury.com/journal/bad-software-and-expensive-mistakes">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p>Recently, thereâ€™s been discussion about an accidental $900 million wire that Citibank sent out while Revlon was restructuring some of its debt. You can read the details <a href="https://www.bloomberg.com/opinion/articles/2021-02-17/citi-can-t-have-its-900-million-back" target="_blank">here</a>, but in short, the payment escaped controls and was completed, and when the team realized their mistake they asked for their money back. But they <a href="https://arstechnica.com/tech-policy/2021/02/citibank-just-got-a-500-million-lesson-in-the-importance-of-ui-design/" target="_blank">couldnâ€™t</a> get it all back.<br></p><p>Although $900 million is an astonishing number, Citibank is not alone. In 2018 Deutsche Bank accidentally wired an exchange <a href="https://money.cnn.com/2018/04/19/investing/deutsche-bank-35-billion-mistake/index.html" target="_blank">$35 billion</a> â€” $5 billion more than the bank was worth at the time. The worst â€œfat-fingerâ€ mistake I know of happened in Tokyo in 2005, when a trader filed a share order worth <a href="https://spectrum.ieee.org/riskfactor/computing/it/japan-traders-617-billion-fat-finger-nearmiss-rattles-tokyo-market" target="_blank">$617 billion</a> and sent it to the exchange.<br></p><p>These types of errors happen all the time, and theyâ€™re entirely the fault of software, not people.&nbsp;<br></p><p>The Citibank case goes to the heart of why we started Modern Treasury.&nbsp;<br></p><p>In 2015, Sam and I started building a marketplace for individuals to invest in the renovation loans that LendingHome was making. Building a â€œfractionalâ€ marketplace <a href="#1">[1]</a> increases the number of transactions in a system. When it really started working, it exploded the number of payments we made â€” from hundreds to tens of thousands per month â€” and thatâ€™s when we started uncovering the many issues that we now call â€œpayment operations.â€<br></p><p>In spite of being the lifeblood of every business, there has been a dearth of modern software built for payment operations in the past half century. So I wanted to share a few of our near misses and provide a perspective on why we believe so passionately that payment operations deserves great software.&nbsp;</p><h4>Could Citiâ€™s Mistake Have been Prevented?&nbsp;<br></h4><p>There are several levels.<br></p><p>Hereâ€™s a screenshot of the <a href="https://www.oracle.com/industries/financial-services/banking/flexcube-universal-banking/" target="_blank">Flexcube</a> product that the team at Citibank used for this transaction. The team wanted to pay out interest but not loan principal, but in order to do so the software required an internal â€œwashâ€ account, and a process that involved checking three boxes (and no less: checking only one doesnâ€™t trigger any alerts.) I think we can agree that this product is less than intuitive to use.<br></p><figure><p><img src="https://assets.website-files.com/5d7e7bbbcad517dd46cb55d3/602ec598b91eff48eb08f141_flexcube.png" loading="lazy" alt=""></p></figure><p>In addition to being simple to use, a payment ops product needs to be flexible. For this team, there is no API, so the workflow had been hard-coded years before. It was so out of date that the team had to have a <a href="https://www.bloomberg.com/opinion/articles/2021-02-17/citi-can-t-have-its-900-million-back" target="_blank">manual</a> to instruct how to work around it. The reason the high amount was being typed in at all was that this â€œsoftware will only let you pay principal to some lenders if you pretend to pay it to every lenderâ€ (<a href="https://www.bloomberg.com/opinion/articles/2021-02-17/citi-can-t-have-its-900-million-back" target="_blank">source</a>). The workflow is so rigid itâ€™s all or nothing.</p><p>Finally, controls. The Citibank team went through three levels of approvals over email. A good payment operations system should dynamically route payments to the right person or persons for release, but only if those users get the information they need to make an informed decision. Over email, that doesnâ€™t happen.&nbsp;</p><p>Good people operating bad software will eventually make a mistake.&nbsp;<br>â€<br></p><h3>How Software Like This Gets Built</h3><h4>Act One: The Tech Team Wants to Talk to the Bank</h4><p>The first realization we had when we set out to solve this problem at LendingHome was that in order to make payments, you must do so through your bank. But banks do not have clean APIs. To compensate, we had to build a custom bank integration.&nbsp;</p><p>The US has a single system for wire transfers, the Fedwire system, and that is the common denominator across all banks. But each bank then operates its own â€œbank coreâ€ software on top of the Fedwire system, and that software maintains accounts and ledgers, records transactions, and so on. The bank therefore actually has a separate interface. So we now have two interfaces:&nbsp;</p><p>Customer -- Bank -- Fedwire</p><p>Building on these interfaces takes investment of time and resources, because bank cores are challenging to integrate with and understand. Some banks use <a href="https://www.moderntreasury.com/journal/what-is-direct-transmission" target="_blank">Direct Transmission</a> over SFTP while others provide SOAP APIs. Timings <a href="https://docs.moderntreasury.com/reference#ach-timings" target="_blank">vary</a>. There are different, competing, data exchange formats for things like reporting on errors, and the configurations can vary from banks on identical cores.&nbsp;<br></p><p>When pressed for resources, teams cut corners. Itâ€™s hard to justify investing in wonderful design and robust systems for internal processes, so much of whatâ€™s out there is half-built, inflexible, and non-intuitive, and rarely gets any attention from the design team.&nbsp;<br></p><p>The result of poor software is workarounds. We had finance colleagues who had Excel wizard skills and a tolerance for manual process pain at which we marveled, but at some point even they would come down to the engineering floor and, in a desperate cry for help, ask us to â€œJUST COMPUTER IT!â€<br></p><p>(We registered that domain a couple of years later. Check out <a href="http://www.justcomputerit.com/" target="_blank">www.justcomputerit.com</a> the next time youâ€™re frustrated with a payment ops problem.)</p><h4>Act Two: Itâ€™s Not One Bank, Itâ€™s Many</h4><p>Itâ€™s not just a single bank integration problem. Itâ€™s many.<br></p><p>Most companies, once they become somewhat large, operate on more than one bank. So not only does the engineering team have to understand and integrate with one bank, they have to repeat that process for each subsequent bank from scratch, and as we have seen, thatâ€™s a scary proposition.<br></p><p>Now we have many integrations:<br></p><p>Customer&nbsp;<br>-- Bank 1 -- Fedwire<br>-- Bank 2 -- Fedwire<br>-- Bank 3 -- Fedwire<br>-- Bank 4 -- Fedwire<br></p><div><p>Every bank is a unique filter on the Fedwire system, making it even harder to make it flexible, intuitive software. The challenges of a single bank integration are now proliferating, and the engineering team tasked with this has to grow.</p></div><h4>Act Three: The Controller Wants Control</h4><p>Thereâ€™s good reasons why bank relationships are sensitive. After all, the executive team has a fiduciary responsibility to make sure company funds are safe and secure at all times. The CFO and their team are concerned about the prospect of the engineering team building an integration to talk to the bank and move money around whenever they want. Not to mention that with each money movement, the accounting team has to track, tag, and reconcile every dollar that moves in and out of every bank account.<br></p><p>â€œMove fast and break thingsâ€ is quite literally the worst way to sell software to CFOs.&nbsp;<br></p><p>So now we discover the next layer of issues: a good bank integration is necessary but not sufficient. There must be a smart, easy-to-use, and intuitive app for the controller that allows them to manage the process. Some of the features this app must have include the ability to create rules to manage the API, to monitor what is happening, and to provide context and trigger approvals for actions that are unexpected.&nbsp;<br></p><p>One such surprise happened to us when we were subleasing office space from Salesforce. The accounting team saw a giant payment to Salesforce and came over to us, angry and flustered that someone irresponsible had sent Salesforce several salariesâ€™ worth of cash for what should have been a few CRM seats. We were amused as we had to explain that indeed, the payment was made to Salesforce, yes, that Salesforce, but no, it wasnâ€™t for software. It was rent.&nbsp;<br></p><h4>Bonus Act: Idempotency and Reversibility</h4><p>There are some very specific engineering concerns that anyone building a payment ops system has to keep in mind.&nbsp;<br></p><p>The first one is idempotency, or doing things only once. We put together a post on <a href="https://www.moderntreasury.com/journal/why-idempotency-matters-in-payments" target="_blank">â€œWhy Idempotency Matters in Payments</a>,â€ which I highly encourage anyone working in payments to read, because the only thing worse than sending the wrong amount is sending it twice.&nbsp;<br></p><p>We lived this. One day we accidentally double-funded every mortgage: many millions of dollars, paid out twice. That was not a good day. Mercifully, because mortgages are disbursed to <a href="https://www.moderntreasury.com/journal/how-to-build-an-escrow-product" target="_blank">escrow</a>, we got all the funds back, but we never forgot idempotency matters in payments after that day.&nbsp;<br></p><div><p>Wires are not reversible, which makes mistakes particularly scary. There are other payment types, such as ACH, that are. If you sent an ACH and you didnâ€™t mean to, or if someone debits your account without your permission, you can reverse it.<a href="#2">[2]</a> Approvals are important, but theyâ€™re particularly important for irreversible transactions, such as the wire Citi sent and couldnâ€™t recall after sending.&nbsp;</p></div><h4>Thinking About Payment Ops as a Single Continuous Process</h4><p>Steve Jobs said, â€œDesign is not just what it looks like and feels like. Design is how it works.â€&nbsp;<br></p><p>This sums up how we believe payment operations should run. Rather than have many silos for information â€” from a database to a CSV to a bank portal to an accounting system â€” we believe in a single piece of payment operations software. This software crosses systems and, perhaps most importantly, it crosses teams. The tech team wants to live in the <a href="https://www.moderntreasury.com/developer-solutions" target="_blank">API</a>, the finance team wants to live in the <a href="https://www.moderntreasury.com/finance-solutions" target="_blank">app</a>, accountants need <a href="https://www.moderntreasury.com/journal/introducing-continuous-accounting" target="_blank">continuous accounting</a>, and customer service teams need to <a href="https://www.moderntreasury.com/journal/how-customer-support-teams-use-modern-treasury" target="_blank">answer customer requests</a>.&nbsp;<br></p><p>Weâ€™ve written at length in the <a href="https://www.moderntreasury.com/journal" target="_blank">Modern Treasury Journal</a> about these issues. ACH, wire, and paper check account for the <a href="https://www.moderntreasury.com/journal/b2b-payments-vs-c2b-payments-what-makes-them-so-different" target="_blank">vast majority</a> of payments in the US, and yet have seen very little innovation in the last fifty years.&nbsp;<br></p><p>We believe that will change this decade. <a href="https://angel.co/company/moderntreasury/jobs" target="_blank">Join us</a>, <a href="https://app.moderntreasury.com/sign_up" target="_blank">build with us</a>, and <a href="https://www.moderntreasury.com/journal" target="_blank">learn with us</a>.&nbsp;<br></p></div></div><div><h4>References</h4><div><div id="1"><p>A fractional loan marketplace is one where each loan is sold not to one institutional investor but to many individuals. This means that every repayment of that loan has to be split between all the investors that &nbsp;invested in each loan, and therefore number of individual transactions in the system balloons.</p></div><div id="2"><div><p>There are lots of ACH return codes, and you can check out our post on <a href="https://www.moderntreasury.com/journal/what-happens-when-you-ach-a-dead-person" target="_blank">What Happens When You ACH a Dead Person </a>to learn more about those.</p></div></div></div></div></div>]]>
            </description>
            <link>https://www.moderntreasury.com/journal/bad-software-and-expensive-mistakes</link>
            <guid isPermaLink="false">hacker-news-small-sites-26185082</guid>
            <pubDate>Thu, 18 Feb 2021 20:32:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Series A to Revolutionize Computing]]>
            </title>
            <description>
<![CDATA[
Score 22 | Comments 5 (<a href="https://news.ycombinator.com/item?id=26184594">thread link</a>) | @tosh
<br/>
February 18, 2021 | https://blog.repl.it/seriesa | <a href="https://web.archive.org/web/*/https://blog.repl.it/seriesa">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		<p>Our mission is to give everyone in the world <strong>computer superpowers</strong>. We build powerful yet approachable tools &amp; platforms for developers, students, and educators.</p>
<p>We see a new generation of hackers and entrepreneurs rising to seize the power of computers and the internet to create software that empowers them and their communities. They refuse to be programmed by the software priesthood that wants them to endlessly consume ads. Instead, they build a more free society where computers work for and under human users, not the other way around. The world we're describing is coming, and we exist to accelerate the shift.</p>
<p><img src="https://repl.art/replit.png" alt="art"></p>
<p>Replit is a multiplayer computing environment that makes it <a href="https://blog.replit.com/internet-of-fun">fun</a> to learn how to code, build, and <a href="https://repl.it/talk/share">share apps</a> with other people. You can create a cloud-powered computer in milliseconds -- we call them "repls" -- and you can create as many of them as you'd like, all for free. Repls come with storage for your code and files, a <a href="https://blog.repl.it/database">database</a> for your data, and a <a href="https://repl.it/site/multiplayer">multiplayer editor</a> &amp; console to code with your friends. For <a href="https://repl.it/pricing">$7/month</a>, you'll get more powerful machines and, with one-click, make them <a href="https://blog.repl.it/alwayson">run forever</a>.</p>
<p><img src="https://blog.repl.it/images/database/database1.gif" alt="db"></p>
<p>When you invite a friend to your repl, you can see them in your editor and talk to them <a href="https://blog.repl.it/annotations-for-education">right in your code</a>. You can make <a href="https://docs.repl.it/repls/http-servers">web</a>, <a href="https://blog.repl.it/native-graphics-love">desktop</a>, and even command-line apps. Replit takes care of the entire process of <a href="https://docs.repl.it/repls/web-hosting">publishing and hosting apps</a> so you can focus on your ideas.</p>
<p><img src="https://venturebeat.com/wp-content/uploads/2021/02/Live-Code-Editing.gif?resize=800%2C450&amp;strip=all" alt="multiplayer"></p>
<p>When you've built something you want to share, you can share the <a href="https://blog.replit.com/spotlight">repl URL</a>, and your users can play with your app, react to it, comment on it, and even fork and remix it. Replit gives you a profile to keep and showcase all your apps and repls. You can make <a href="https://repl.it/site/teams">shared team profiles</a> for your class, friends, or company to collaborate on repls.</p>
<p><img src="https://blog.repl.it/images/spotlight/ios-demo.gif" alt="share"></p>
<p>Because you can make a repl in milliseconds, Replit makes it fun and safe to experiment with ideas. Learning comes naturally as a side effect of playing in the Replit ecosystem.</p>
<p>Millions of people have learned how to code with Replit and built great apps with thousands of happy users. Some have even built businesses and become rich &amp; famous.</p>
<p>Replit's design principles:</p>
<ul>
<li><p><strong>Learnable yet scalable interfaces</strong>: Interfaces today present the same UI to vastly different users, from children to adults, from novices to experts. Our mission demands that we make computing environments more accessible to novices while making it possible to transition to more powerful interfaces. Replit starts with a simple editor and console, which gets learners very far. The UI, however, is adaptable and presents different faces to different users and use-cases.</p>
</li>
<li><p><strong>Infrastructure as legos</strong>: A core part of commanding computer power is to be able to build for the modern internet-connected world. Despite progress in cloud computing, infrastructure remains inaccessible to novices, hobbyists, and educators. We change this by designing simple and scalable components, like cloud-hosted servers accessible right from the repl, storage, databases, etc., that require little configuration and maintenance by the programmer. Coders can then mix and match components to create endless possibilities.</p>
</li>
<li><p><strong>People-centric technology</strong>: It's more exciting and fun to create and learn with other people. The future demands that computers and the internet have human interconnectedness as a core primitive. From our multiplayer computing protocol to our community spaces for sharing software, we build support for human beings, and we put collaboration right at the heart of our technology.</p>
</li>
</ul>
<h2 id="series-a">Series A</h2>
<p>As a team, we've always thought about the long-term, and we've grown Replit responsibly. We have so much conviction in our mission and our plan that we're willing to take our time. </p>
<p>Last year, with rapid growth in all aspects of our business, we felt it was a good time to raise a sizeable round to make faster progress our mission. We raised <a href="https://venturebeat.com/2021/02/18/replit-raises-20-million-for-collaborative-browser-based-coding/">$20M in Series A</a> financing led by <a href="https://acapital.com/">A.Capital</a> with strong participation from our seed investors: Andreessen Horowitz, Bloomberg Beta, Y Combinator, and Reach Capital. </p>
<p>Since then, thanks to the new capital and to <a href="https://amasad.me/moad">Engelbartian Bootstrapping</a>, we've accelerated feature development, and there's so much more on the horizon: extra resources for more complex projects, support for any language or package, further dev ops simplifications for novices and pros, business collaboration features, improvements to <a href="https://repl.it/teams-for-education">teacher workflows</a>, high quality content, a game development library, and more breakthroughs in collaborative coding. We're excited to see all the amazing things you build with the tools we provide!</p>
<p>Finally, we're hiring for multiple roles and want to bring on people who share our vision and passion. If you're interested in making computing more accessible while working with a creative and hardworking team building fantastic technology, <a href="https://repl.it/careers">join us</a>!</p>

	</div></div>]]>
            </description>
            <link>https://blog.repl.it/seriesa</link>
            <guid isPermaLink="false">hacker-news-small-sites-26184594</guid>
            <pubDate>Thu, 18 Feb 2021 19:53:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[BioNTech/Pfizer sought 54.08 Euro per vaccine dose from EU (de)]]>
            </title>
            <description>
<![CDATA[
Score 20 | Comments 41 (<a href="https://news.ycombinator.com/item?id=26184301">thread link</a>) | @_Microft
<br/>
February 18, 2021 | https://www.tagesschau.de/investigativ/ndr-wdr/corona-impfstoff-biontech-105.html | <a href="https://web.archive.org/web/*/https://www.tagesschau.de/investigativ/ndr-wdr/corona-impfstoff-biontech-105.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
                <div>
    
    
    <div>
        <div>
            <p><span>
                    Exklusiv
                </span>
            </p>
            
            <p>
                Stand: 18.02.2021 17:00 Uhr
            </p>
        </div>
    </div>
</div>
                
                    

    
    
        
    
    <p>
        <strong>Die Pharmaunternehmen Pfizer und BioNTech wollten nach Informationen von </strong><strong><em>NDR, WDR</em></strong><strong> und "SZ" im Juni von der EU fÃ¼r eine Dosis Impfstoff 54,08 Euro. Der Arzneimittelchef der Ã„rztekammer spricht von "unseriÃ¶sem Profitstreben".</strong>
    </p>

    

    




    

                
                    

    
    
        <div>

    

    
        <div>
            <p>
                    <span><em>Von Markus Grill und Georg Mascolo,  </em></span><em>
                    <span>NDR/WDR</span></em>
                </p>
        </div>
    
</div>
    

    




    

                
                    

    
    
        
    
    <p>
        Im Juni des vergangenen Jahres ging bei der EU-Kommission ein streng vertrauliches Angebot der Pharmahersteller Pfizer und BioNTech ein. Darin boten sie nach Informationen von <em>NDR, WDR</em> und "SÃ¼ddeutscher Zeitung" ihren Impfstoff zum Preis von 54,08 Euro pro Dosis an, bei einer Abnahme von 500 Millionen Dosen. Insgesamt wollten BioNTech/Pfizer also 27 Milliarden Euro fÃ¼r so viel Impfstoff, dass man damit gut die HÃ¤lfte der EU-BevÃ¶lkerung impfen kÃ¶nnte. Der Preis, so versicherten Pfizer/BioNTech, beinhalte bereits "den hÃ¶chsten prozentualen Rabatt", der einem Industrieland weltweit angeboten worden sei.
    </p>

    

    




    

                
                    

    
    
        
    
    <p>
        Mit 54,08 Euro wÃ¤re der BioNTech-Impfstoff allerdings mehr als 20-mal so teuer gewesen wie eine Dosis jenes Impfstoffs, den AstraZeneca gemeinsam mit der UniversitÃ¤t Oxford entwickelt hat. "Ich halte den Preis fÃ¼r unseriÃ¶s", kritisiert der Vorsitzende der Arzneimittelkommission der Deutschen Ã„rzteschaft, Wolf Dieter Ludwig, das Angebot von Pfizer/BioNTech. "Ich sehe darin ein Profitstreben, das in der jetzigen Situation der Pandemie in keiner Weise gerechtfertigt ist."
    </p>

    

    




    

                
                    

    
    
        
    

    




    
        
        
            
            
            
            
            
            
                
    
    

        
    

            
            
            
            
            
        
    

                
                    

    
    
        
    

    




    
        
        
            
            
            
            
            
                
            
            
            
            
            
            
        
    

                
                    

    
    
        

    

    <h2>VerstÃ¤ndnis fÃ¼r ZÃ¶gern der EU</h2>


    

    




    

                
                    

    
    
        
    
    <p>
        WomÃ¶glich werfen diese vergleichsweise hohen Preisvorstellungen auch ein neues Licht auf die ZurÃ¼ckhaltung mancher EU-LÃ¤nder im Sommer gegenÃ¼ber dem BioNTech-Impfstoff. Ludwig jedenfalls sagt, dass er die EU verstehe: "Ich denke, sie hat mit Recht gezÃ¶gert bei einem derartig hohen Preis."
    </p>

    

    




    

                
                    

    
    
        
    
    <p>
        In einem Interview mit dem "Spiegel" Anfang des Jahres kritisierte BioNTech-Chef Ugur Sahin die Verhandlungen mit der EU: "Der Prozess in Europa lief sicherlich nicht so schnell und geradlinig ab wie mit anderen LÃ¤ndern", sagte der Firmenchef. "Offenbar herrschte der Eindruck: Wir kriegen genug, es wird alles nicht so schlimm, und wir haben das unter Kontrolle. Mich hat das gewundert."
    </p>

    

    




    

                
                    

    
    
        
    
    <p>
        Eine Anfrage zu einem GesprÃ¤ch Ã¼ber das hohe Preisangebot lieÃŸ Sahin diese Woche unbeantwortet. Eine Firmensprecherin beantwortete konkrete Fragen zum Angebot nicht, wies aber darauf hin, dass der Preis fÃ¼r den Impfstoff "von verschiedenen Faktoren abhÃ¤ngig" sei. Er liege "in einer gewissen Spanne fÃ¼r alle LÃ¤nder mit hÃ¶herem Einkommen". Bisher habe das Unternehmen jedoch keine Gewinne gemacht. Wenn man aber Gewinne aus dem Vertrieb des Covid-19-Impfstoffs mache, wolle man diese "in die Weiterentwicklung dieser Technologie reinvestieren". Ein Sprecher der EU-Kommission teilte per E-Mail mit, dass die EU-Kommission aus vertragsrechtlichen GrÃ¼nden keine Angaben Ã¼ber die Preise machen dÃ¼rfe.
    </p>

    

    




    

                
                    

    
    
        
    

    




    
        
        
            
            
            
            
            
                
            
            
            
            
            
            
        
    

                
                    

    
    
        

    

    <h2>Offenbar deutlich niedrigeren Preis durchgesetzt</h2>


    

    




    

                
                    

    
    
        
    
    <p>
        Erst im November kam die EU zu einem Vertragsabschluss mit Pfizer/BioNTech. Der endgÃ¼ltige Preis wird bis heute zwar geheim gehalten, doch nach Informationen von <em>NDR, WDR</em> und "SZ" soll er bei 15,50 Euro pro Dosis liegen. Als erste hatte auch die Nachrichtenagentur Reuters diesen Preis erfahren. Die EU hÃ¤tte damit also eine deutliche Preissenkung gegenÃ¼ber dem Angebot im Juni erreicht.
    </p>

    

    




    

                
                    

    
    
        
    
    <p>
        Auch die USA zahlen in etwa gleich viel. Sie hatten im Juli bereits einen Vertrag mit Pfizer geschlossen, der ihnen 100 Millionen Dosen fÃ¼r 1,95 Milliarden Dollar sicherte. Umgerechnet ergibt das rund 16 Euro pro Dosis.
    </p>

    

    




    

                
                    

    
    
        
    

    




    
        
        
            
            
            
            
            
                
            
            
            
            
            
            
        
    

                
                    

    
    
        

    

    <h2>Staatliche Subventionierung in MillionenhÃ¶he</h2>


    

    




    

                
                    

    
    
        
    
    <p>
        Ãœberraschend ist aber nicht nur der hohe Preis, den Pfizer/BioNTech von der EU kassieren wollten, sondern auch die Behauptung in dem Angebot an die EU, man hÃ¤tte die Entwicklung des Impfstoffes "komplett selbst finanziert".
    </p>

    

    




    

                
                    

    
    
        
    
    <p>
        Das mag vielleicht fÃ¼r Pfizer gelten. Nicht aber fÃ¼r die deutsche Firma BioNTech, die den Impfstoff entwickelt hatte - auch wenn manche derzeit glauben, dass BioNTech allein mit dem Geld der Hexal-GrÃ¼nder Andreas und Thomas StrÃ¼ngmann aufgebaut wurde. 
    </p>

    

    




    

                
                    

    
    
        
    
    <p>
        TatsÃ¤chlich war ihr Engagement entscheidend - aber BioNTech wurde auch mit mehreren Millionen Euro staatlich subventioniert. So teilt das Bundesministerium fÃ¼r Bildung und Forschung (BMBF) auf Anfrage von <em>NDR, WDR</em> und "SZ" mit, dass das Ministerium "die GrÃ¼ndungsphase von Biontech maÃŸgeblich unterstÃ¼tzt und die entscheidenden ersten Jahre der AusgrÃ¼ndung finanziell und auch strukturell gefÃ¶rdert hat".
    </p>

    

    




    

                
                    

    
    
        
    
    <p>
        Einen weiteren Schub hatte BioNTech demnach von 2012 bis 2017 als Gewinner des Spitzencluster-Wettbewerbs erhalten, das vom Forschungsministerium mit 12,9 Millionen Euro gefÃ¶rdert worden sei, wie BMBF-Sprecher Stephan KÃ¼gele mitteilte. Auf Nachfrage teilt auch die BioNTech-Sprecherin mit, das Unternehmen habe "wÃ¤hrend der ersten Jahre nach GrÃ¼ndung ca. 50 Millionen Euro FÃ¶rdergelder durch die Clusterinitiative und EU-Programme erhalten." Im Sommer 2020 bekam die Firma weitere 375 Millionen Euro vom Bundesforschungsministerium fÃ¼r die mRNA-basierte Impfstoffentwicklung zugesagt.
    </p>

    

    




    

                
                    

    
    
        
    

    




    
        
        
            
            
            
            
            
                
            
            
            
            
            
            
        
    

                
                    

    
    
        

    

    <h2>Impfschutz wichtiger als AktionÃ¤rsinteressen</h2>


    

    




    

                
                    

    
    
        
    
    <p>
        "Die pharmazeutische Industrie sagt ja immer, die hohen Kosten entstehen aufgrund der Forschungs- und Entwicklungskosten, aber auch, weil der Nutzen so groÃŸ ist", sagt Wolf Dieter Ludwig. TatsÃ¤chlich kÃ¶nne man den Nutzen derzeit aber nicht endgÃ¼ltig beurteilen und die Forschung und Entwicklung sei zum Teil mit staatlichen Geldern subventioniert worden. Allein die US-Regierung zahlte mehrere Milliarden US-Dollar an verschiedene Hersteller. 
    </p>

    

    




    

                
                    

    
    
        
    
    <p>
        "Von daher sind diese hohen Preisforderungen aus meiner Sicht nicht berechtigt", sagt Ludwig. Er verstehe zwar, dass die AktionÃ¤re dieser Firmen auch ihren Anteil wollen. "Aber wir sind derzeit in einer Krisensituation, wo es das Ziel sein muss, nicht nur in den IndustrielÃ¤ndern, sondern weltweit zu impfen. Vor diesem Hintergrund, denke ich, haben die Interessen der AktionÃ¤re weniger Bedeutung als die Interessen der BevÃ¶lkerungen, die von dieser Pandemie befreit werden wollen."
    </p>

    

    




    

                
                    

    
    
        
    

    




    
        
        
            
            
            
            
            
            
            
                

    

        

        
    

            
            
            
            
        
    

                
                    

    
    
        
    

    




    
        
        
            
            
            
            
            
                
            
            
     â€¦</article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.tagesschau.de/investigativ/ndr-wdr/corona-impfstoff-biontech-105.html">https://www.tagesschau.de/investigativ/ndr-wdr/corona-impfstoff-biontech-105.html</a></em></p>]]>
            </description>
            <link>https://www.tagesschau.de/investigativ/ndr-wdr/corona-impfstoff-biontech-105.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26184301</guid>
            <pubDate>Thu, 18 Feb 2021 19:26:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Designing a RISC-V CPU, Part 1]]>
            </title>
            <description>
<![CDATA[
Score 20 | Comments 1 (<a href="https://news.ycombinator.com/item?id=26184136">thread link</a>) | @newswasboring
<br/>
February 18, 2021 | https://mcla.ug/blog/risc-v-cpu-part-1.html#fnref:3 | <a href="https://web.archive.org/web/*/https://mcla.ug/blog/risc-v-cpu-part-1.html#fnref:3">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<div>
	
	<p><span>Tue 16 February 2021</span></p><p>I have no experience in digital logic design. That is, I didn't until I
recently decided that I would like to try designing my own CPU and running it
on an FPGA! If you too are a software engineer with a vague interest in
hardware design, I hope this series of posts about what I've learnt will be
helpful and interesting. In this first installment, I hope to answer these
questions:</p>
<ul>
<li>
<p>What is digital logic design?</p>
</li>
<li>
<p>How do I get started, and what tools might I use?</p>
</li>
</ul>
<p>In future installments, I will go into more detail about my CPU design and the
RISC-V architecture, as well as hopefully answering these questions:</p>
<ul>
<li>
<p>What about digital logic design is fundamentally different from software
  design?</p>
</li>
<li>
<p>What about digital logic design is similar to software design?</p>
</li>
</ul>
<p>You can see the code for my CPU at the time of writing
<a href="https://github.com/lochsh/riscy-boi/tree/47e94dc6e9665f73c871add002c34d1516fd5106">here</a>
or an up to date version <a href="https://github.com/lochsh/riscy-boi">here</a>.</p>
<h2>What is digital logic design?</h2>
<p>Digital logic design is designing logic circuits that operate on binary values.
The elementary components are logic gates: an AND gate, for example, has two
inputs and one output. The output is 1 iff<sup id="fnref:1"><a href="#fn:1">1</a></sup> both inputs are 1.</p>
<p>Typically, we design synchronous circuits which use flip-flops to store state,
and thereby synchronise the operation of the circuit to a common clock.
Flip-flops are composed of logic gates.</p>
<p>Analogue circuit design is concerned with the electronic components that make
up logic gates, like transistors and diodes. This level of abstraction is often
needed for applications dealing directly with signals derived from analogue
sensors, like radio receivers. When designing a CPU, this level of abstraction
would not be feasible: modern CPUs can have billions of transistors!</p>
<p>Instead, we use tools that can translate our digital logic design into
different useful formats: the configuration of an FPGA (see below); a
simulation; silicon layout.</p>
<h2>What is an FPGA and why are they used?</h2>
<p>We noted above that the same digital logic design tools can be used whether we
are creating a custom ASIC to be made into silicon, or configuring an FPGA. A
Field-Programmable Gate Array is an integrated circuit containing an array of
programmable logic blocks. You could imagine it is as a big array of logic
gates that can be connected together in various ways.</p>
<p>Making a custom chip generally costs millions, and of course once your chip is
manufactured it cannot be changed. Thus, generally FPGAs are used when:</p>
<ul>
<li>
<p>You cannot afford to create a custom ASIC due to lack of capital (e.g. if
  you're just some hacker like me and not ARM or Intel)</p>
</li>
<li>
<p>You cannot afford to create a custom ASIC because your volume is too low to
  make it worth the high one-off costs (e.g. if you are making a small quantity
  of MRI machines with custom data acquisition hardware)</p>
</li>
<li>
<p>You need the flexibility</p>
</li>
</ul>
<p>The downsides? FPGAs have a much higher per-chip cost, and they are generally
much slower as a consequence of being able to connect logic blocks together in
very flexible ways. In contrast, a custom design can be reduced to the minimum
number of transistors, with no concern for flexibility.</p>
<p>I think it's helpful context to compare the custom ASIC design process against
that of an FPGA design:</p>
<ul>
<li>
<p><span>Logic design</span>: just like we'd do for an FPGA, the logic design of an ASIC is
  done in a hardware description language.</p>
</li>
<li>
<p><span>Verification</span>: FPGA designs may well be verified, but you might expect the
  process for an ASIC design to be more rigorous â€“ after all, the design
  can't be changed once manufactured! Often verification will involve formally
  verifying<sup id="fnref:2"><a href="#fn:2">2</a></sup> parts of the design.</p>
</li>
<li>
<p><span>Synthesis</span>: This creates a <em>netlist</em>: a list of logic blocks and their
  connections. The connections are called <em>nets</em>, and the blocks are called
  <em>cells</em>. For both FPGAs and ASICs, the cells are vendor-specific.</p>
</li>
<li>
<p><span>Placement and routing</span> (P&amp;R): for an FPGA, this involves mapping the logic
  blocks described in the netlist to actual blocks in the FPGA. The resulting
  binary is often called a <em>bitstream</em>.  For an ASIC, this involves deciding
  where to place the cells on the silicon, and how to connect them up. Both
  applications generally use automated optimisation tools for this.</p>
</li>
</ul>
<h2>What tools do I need?</h2>
<h3>A hardware description language: I am using <a href="https://github.com/nmigen/nmigen">nMigen</a><sup id="fnref:3"><a href="#fn:3">3</a></sup></h3>
<p>You may have heard of Verilog or VHDL: both popular hardware description
languages (HDLs). I use "popular" here to mean widely used, not widely loved.</p>
<p>I won't pretend to know much about these tools: I only know that smarter people
than me with vast logic design experience have a lot of hate for them.
Due to the problems with Verilog and other similar tools, there have been
various attempts at making more useful and friendlier alternatives.  nMigen is
one such project, which creates a domain-specific language in Python. In their
own words:</p>
<blockquote>
<p>Despite being faster than schematics entry, hardware design with Verilog and
VHDL remains tedious and inefficient for several reasons. The event-driven
model introduces issues and manual coding that are unnecessary for
synchronous circuits, which represent the lion's share of today's logic
designs. Counterintuitive arithmetic rules result in steeper learning curves
and provide a fertile ground for subtle bugs in designs. Finally, support for
procedural generation of logic (metaprogramming) through "generate"
statements is very limited and restricts the ways code can be made generic,
reused and organized.</p>
<p>To address those issues, we have developed the nMigen FHDL, a library that
replaces the event-driven paradigm with the notions of combinatorial and
synchronous statements, has arithmetic rules that make integers always behave
like mathematical integers, and most importantly allows the design's logic to
be constructed by a Python program. This last point enables hardware
designers to take advantage of the richness of the Python languageâ€”object
oriented programming, function parameters, generators, operator overloading,
libraries, etc.â€”to build well organized, reusable and elegant designs.</p>
</blockquote>
<p>If, like me, you've never used Verilog, then not all of this will have more
than abstract meaning to you. But it certainly sounds promising,
and I can attest that it has been very straightforward to get started with
logic design without the reportedly large barrier of grappling with Verilog. I
would recommend it, particularly if you are already familiar with Python!</p>
<p>The only downside I can think of is that nMigen is still in development, and
in particular the documentation is not complete. There is a helpful community
at #nmigen on <a href="https://mcla.ug/blog/chat.freenode.net">chat.freenode.net</a>.</p>
<h3>A wave viewer for inspecting simulations: I am using <a href="http://gtkwave.sourceforge.net/">GTKWave</a></h3>
<p>nMigen provides simulation tooling: I use it in my tests, written using
<code>pytest</code>. I record the signals during these tests and view them in a wave
viewer to help debug.</p>
<p><img alt="gtkwave" src="https://mcla.ug/blog/images/gtkwave.png" title="A screenshot of GTKWave"></p>
<h3>Optional: An FPGA dev board. I am using a myStorm BlackIce II</h3>
<p>You don't need an FPGA dev board to create your own CPU. You could do
everything in simulation! The fun of having a board to work with, for me, is
being able to flash LEDs and see my design in action.</p>
<p>Of course, if you were creating something more useful than my very basic CPU,
then you would probably want some hardware to run it on, and this would be less
"optional"!</p>
<h2>Getting started with nMigen</h2>
<p>Rather than immediately trying to design a CPU, I started by making an
Arithmetic Logic Unit (ALU) in nMigen. The ALU is a key piece of any CPU design
that I have seen: it performs arithmetic operations.</p>
<p>Why start with this? I knew I would need an ALU for my CPU; I knew I could make
a simple one; I knew that the feeling of making something is an important
motivator when starting a new project!</p>
<p>My design looked something like this:</p>

<div>
<pre id="vimCodeElement"><span id="L1"> 1 </span><span>"""</span><span>Arithmetic Logic Unit</span><span>"""</span>
<span id="L2"> 2 </span><span>import</span> enum
<span id="L3"> 3 </span>
<span id="L4"> 4 </span><span>import</span> nmigen <span>as</span> nm
<span id="L5"> 5 </span>
<span id="L6"> 6 </span>
<span id="L7"> 7 </span><span>class</span> <span>ALUOp</span><span>(</span>enum<span>.</span>IntEnum<span>)</span><span>:</span>
<span id="L8"> 8 </span>    <span>"""</span><span>Operations for the ALU</span><span>"""</span>
<span id="L9"> 9 </span>    ADD <span>=</span> <span>0</span>
<span id="L10">10 </span>    SUB <span>=</span> <span>1</span>
<span id="L11">11 </span>
<span id="L12">12 </span>
<span id="L13">13 </span><span>class</span> <span>ALU</span><span>(</span>nm<span>.</span>Elaboratable<span>)</span><span>:</span>
<span id="L14">14 </span>    <span>"""</span>
<span id="L15">15 </span><span>    Arithmetic Logic Unit</span>
<span id="L16">16 </span>
<span id="L17">17 </span><span>    * op (in): the opcode</span>
<span id="L18">18 </span><span>    * a (in): the first operand</span>
<span id="L19">19 </span><span>    * b (in): the second operand</span>
<span id="L20">20 </span>
<span id="L21">21 </span><span>    * o (out): the output</span>
<span id="L22">22 </span><span>    </span><span>"""</span>
<span id="L23">23 </span>
<span id="L24">24 </span>    <span>def</span> <span>__init__</span><span>(</span>self<span>,</span> width<span>)</span><span>:</span>
<span id="L25">25 </span>        <span>"""</span>
<span id="L26">26 </span><span>        Initialiser</span>
<span id="L27">27 </span>
<span id="L28">28 </span><span>        Args:</span>
<span id="L29">29 </span><span>            width (int): data width</span>
<span id="L30">30 </span><span>        </span><span>"""</span>
<span id="L31">31 </span>        self<span>.</span>op <span>=</span> nm<span>.</span>Signal<span>()</span>
<span id="L32">32 </span>        self<span>.</span>a <span>=</span> nm<span>.</span>Signal<span>(</span>width<span>)</span>
<span id="L33">33 </span>        self<span>.</span>b <span>=</span> nm<span>.</span>Signal<span>(</span>width<span>)</span>
<span id="L34">34 </span>        self<span>.</span>o <span>=</span> nm<span>.</span>Signal<span>(</span>width<span>)</span>
<span id="L35">35 </span>
<span id="L36">36 </span>    <span>def</span> <span>elaborate</span><span>(</span>self<span>,</span> _<span>)</span><span>:</span>
<span id="L37">37 </span>        m <span>=</span> nm<span>.</span>Module<span>()</span>
<span id="L38">38 </span>
<span id="L39">39 </span>        <span>with</span> m<span>.</span>Switch<span>(</span>self<span>.</span>op<span>)</span><span>:</span>
<span id="L40">40 </span>            <span>with</span> m<span>.</span>Case<span>(</span>ALUOp<span>.</span>ADD<span>)</span><span>:</span>
<span id="L41">41 </span>                m<span>.</span>d<span>.</span>comb <span>+=</span> self<span>.</span>o<span>.</span>eq<span>(</span>self<span>.</span>a <span>+</span> self<span>.</span>b<span>)</span>
<span id="L42">42 </span>            <span>with</span> m<span>.</span>Case<span>(</span>ALUOp<span>.</span>SUB<span>)</span><span>:</span>
<span id="L43">43 </span>                m<span>.</span>d<span>.</span>comb <span>+=</span> self<span>.</span>o<span>.</span>eq<span>(</span>self<span>.</span>a <span>-</span> self<span>.</span>b<span>)</span>
<span id="L44">44 </span>        <span>return</span> m
</pre>
</div>

<p>As you can see, we've created a lot of nMigen <code>Signal</code> instances to represent
well...the signals that define the interface to our ALU! But what is this
<code>elaborate</code> method? My understanding is that "elaboration" is the name for the
first step in synthesising the netlist (see above). The idea in the nMigen code
above is that we've created some <em>elaboratable</em> structure (by inheriting from
<code>nm.Elaboratable</code>), i.e. something that describes digital logic we want to
synthesise. The <code>elaborate</code> method describes that digital logic. It has to
return an nMigen <code>Module</code>.</p>
<p>Let's have a closer look at the contents of the <code>elaborate</code> method. The
<code>Switch</code> will create some kind of decision logic in the synthesised design.
But what is <code>m.d.comb</code>? nMigen has the concept of synchronous (<code>m.d.sync</code>)
and combinatorial<sup id="fnref:4"><a href="#fn:4">4</a></sup> (<code>m.d.comb</code>) control domains. From the nMigen
<a href="https://nmigen.info/nmigen/latest/lang.html#lang-domains">docs</a>:</p>
<blockquote>
<p>A control domain is a named group of signals that change their value in
identical conditions.</p>
<p>All designs have a single predefined <em>combinatorial domain</em>, containing all
signals that change immediately when any value used to compute them changes.
The name comb is reserved for the combinatorial domain.</p>
<p>A design can also have any amount of user-defined <em>synchronous domains</em>, also
called clock domains, containing signals that change when a specific edge
occurs on the domainâ€™s â€¦</p></blockquote></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://mcla.ug/blog/risc-v-cpu-part-1.html#fnref:3">https://mcla.ug/blog/risc-v-cpu-part-1.html#fnref:3</a></em></p>]]>
            </description>
            <link>https://mcla.ug/blog/risc-v-cpu-part-1.html#fnref:3</link>
            <guid isPermaLink="false">hacker-news-small-sites-26184136</guid>
            <pubDate>Thu, 18 Feb 2021 19:11:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Scala 3.0.0-RC1 â€“ first release candidate is here]]>
            </title>
            <description>
<![CDATA[
Score 21 | Comments 4 (<a href="https://news.ycombinator.com/item?id=26184110">thread link</a>) | @tmfi
<br/>
February 18, 2021 | https://dotty.epfl.ch/blog/2021/02/17/scala3-rc1.html | <a href="https://web.archive.org/web/*/https://dotty.epfl.ch/blog/2021/02/17/scala3-rc1.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content-wrapper"> 
   <main> 
    <header> 
      
      
    </header> 
    <p>Greetings from the Scala 3 team! We are delighted to announce the first release candidate of the stable version of Scala 3 â€“ Scala 3.0.0-RC1.</p> 
    <p>This release brings some last-minute polishings, clean-ups and changes before the big release. There were a few language changes to improve the user experience, as well as the polishings of the metaprogramming framework. We have also worked on the issues that had to be fixed before the stable release.</p> 
    <p>Overall, more than <a href="https://github.com/lampepfl/dotty/pulls?q=is%3Apr+is%3Aclosed+closed%3A%3E2020-12-02+sort%3Acomments-desc">400 PRs</a> were merged after the M3 release and until today! Read more below!</p> <!--more--> 
     
    <p>Type parameters on extensions can now be combined with type parameters on the methods themselves. E.g.:</p> 
    <pre><code>List(1, 2, 3).second[Int]
extension [A](xs: List[A])
   def sumBy[B](f: A =&gt; B)(using Numeric[B]): B = ...
</code></pre> 
    <p>Type arguments matching method type parameters are passed as usual:</p> 
    <pre><code>List("a", "bb", "ccc").sumBy[Int](_.length)
</code></pre> 
    <p>By contrast, type arguments matching type parameters following <code>extension</code> can be passed only if the method is referenced as a non-extension method:</p> 
    <pre><code>sumBy[String](List("a", "bb", "ccc"))(_.length)
</code></pre> 
    <p>Or, when passing both type arguments:</p> 
    <pre><code>sumBy[String](List("a", "bb", "ccc"))[Int](_.length)
</code></pre> 
    <p>For discussion, see <a href="https://github.com/lampepfl/dotty/pull/10940">PR #10940</a>. For more information about the extension methods, see <a href="https://dotty.epfl.ch/docs/reference/contextual/extension-methods.html">documentation</a>.</p> 
     
    <p>The following are the changes to the <code>import</code> syntax made in this release.</p> 
    <p>Wildcard import <code>_</code> is replaced by <code>*</code>. The motivation is that the majority of other languages use <code>*</code>. For example:</p> 
    <pre><code>import scala.annotation.*  // imports everything in the annotation package
</code></pre> 
    <p>Renaming operator <code>=&gt;</code> is replaced by a soft keyword <code>as</code>. <code>as</code> is also allowed outside braces. For example:</p> 
    <pre><code>import scala.collection.mutable as mut
import NumPy as np
</code></pre> 
    <p>For the details and discussion, see <a href="https://github.com/lampepfl/dotty/pull/11244">PR #11244</a>. Read more about this change in the <a href="https://dotty.epfl.ch/docs/reference/changed-features/imports.html">documentation</a>.</p> 
     
    <p><a href="https://github.com/lampepfl/dotty/pull/11240">PR #11240</a> changed the syntax of vararg splices in patterns and function arguments. The new syntax uses a postfix <code>*</code>, instead of <code>: _*</code>, analogously to how a vararg parameter is declared.</p> 
     
    <p>An obscure use of <code>_</code> occurs in var definitions:</p> 
    <pre><code>var x: T = _
</code></pre> 
    <p>It defines a concrete variable x without an initial value, or rather the default initial value that the JVM assigns to object fields. It can only be used in a class or object, not to initialize a local variable.</p> 
    <p>We came up with an arguably better way to express this idiom: the special <code>uninitialized</code> value in the <code>scala.compiletime</code> object. To get an uninitialized field, you now write:</p> 
    <pre><code>import scala.compiletime.uninitialized

var x: A = uninitialized
</code></pre> 
    <p>This way expresses the intent of the idiom in a more verbose and easy to read way than simply writing an underscore.</p> 
    <p>For discussion, see <a href="https://github.com/lampepfl/dotty/pull/11231">PR #11231</a>, and the <a href="https://dotty.epfl.ch/docs/reference/dropped-features/wildcard-init.html">documentation</a> is available on our website.</p> 
     
    <p>Starting from RC1, we no longer generate a function parent for companions of case classes. Which means, for example, that given <code>case class Foo(x: Int)</code>, you won't be able to use <code>Foo</code> in a position where a function is expected:</p> 
    <pre><code>case class Foo(x: Int)
def f(g: Int =&gt; Foo) = g(10)

f(Foo)
</code></pre> 
    <p>Results in:</p> 
    <pre><code>1 |f(Foo)
  |  ^^^
  |The method `apply` is inserted. The auto insertion will be deprecated, please write `Foo.apply` explicitly.
</code></pre> 
    <p>As the warning suggests, now you should write <code>Foo.apply</code> instead of <code>Foo</code>. See <a href="https://github.com/lampepfl/dotty/issues/6190">Issue #6190</a> and <a href="https://github.com/lampepfl/dotty/pull/7207">PR #7207</a> for discussion.</p> 
     
    <p>We have settled on using the well-known <code>scaladoc</code> as a name for the documentation tool for Scala 3 (known previously as <code>scala3doc</code>).. The obsolete <code>dotty-doc</code> (or <code>scala3-doc</code>) is removed in RC1. We have also removed all the Kotlin dependencies (Dokka, etc.) from scaladoc. For details, see <a href="https://github.com/lampepfl/dotty/pull/11349">PR #11349</a>. To read more about <code>scaladoc</code>, see <a href="https://dotty.epfl.ch/docs/usage/scaladoc/index.html">documentation</a></p> 
     
    <p><a href="https://github.com/lampepfl/dotty/pull/11355">PR #11355</a> changes the <code>-source</code> specifier for the Scala version(s) after 3.0 from <code>3.1</code> to <code>future</code>. I.e. it is now <code>-source future</code> and <code>-source future-migration</code> instead of <code>-source 3.1</code> and <code>-source 3.1-migration</code>. Language imports are changed analogously. The reason for the change is that we want to keep the possibility open to ship a <code>3.1</code> version that does not yet contain all the changes enabled under <code>-source future</code>.</p> 
     
    <ul> 
     <li>Warn when matching against an opaque type <a href="https://github.com/lampepfl/dotty/pull/10664">#10664</a></li> 
     <li>Fix <a href="https://github.com/lampepfl/dotty/issues/8634">#8634</a>: Support -release option <a href="https://github.com/lampepfl/dotty/pull/10746">#10746</a> â€“ the same way Scala 2 does. This setting allows you to specify a version of the Java platform (8, 9 etc) and compile the code with classes specific to the that Java platform, and emit the bytecode for that version.</li> 
    </ul> 
     
    <p>A lot of work has been done on the metaprogramming side of things. Mostly we are cleaning up and polishing the API to prepare it for the stable release. The following are the important metaprogramming changes that took place:</p> 
    <ul> 
     <li>Add <code>scala.quoted.Expr.unapply</code> as dual of <code>Expr.apply</code> <a href="https://github.com/lampepfl/dotty/pull/10580">#10580</a></li> 
     <li>Remove <code>Expr.StringContext.unapply</code> <a href="https://github.com/lampepfl/dotty/pull/10675">#10675</a></li> 
     <li>Add reflect <code>MatchCase</code> <code>TypeRepr</code> <a href="https://github.com/lampepfl/dotty/pull/10735">#10735</a></li> 
     <li>Rename <code>scala.quoted.staging.{Toolbox =&gt; Compiler}</code> <a href="https://github.com/lampepfl/dotty/pull/11129">#11129</a></li> 
     <li>Fix <a href="https://github.com/lampepfl/dotty/issues/10863">#10863</a>: Make show <code>AnyKind</code>ed <a href="https://github.com/lampepfl/dotty/pull/10988">#10988</a></li> 
     <li>Add ParamClause to allow multiple type param clauses <a href="https://github.com/lampepfl/dotty/pull/11074">#11074</a></li> 
     <li>Rework reflect Symbol fields API <a href="https://github.com/lampepfl/dotty/pull/10705">#10705</a></li> 
     <li>Rename <code>Liftable</code> to <code>ToExpr</code> and <code>Unliftable</code> to <code>FromExpr</code> <a href="https://github.com/lampepfl/dotty/pull/10618">#10618</a></li> 
     <li>Expand non-transparent macros after Typer <a href="https://github.com/lampepfl/dotty/pull/9984">#9984</a></li> 
     <li>Rework TastyInspector API to allow inspection of all files <a href="https://github.com/lampepfl/dotty/pull/10792">#10792</a></li> 
     <li>Allow leading context parameters in extension methods <a href="https://github.com/lampepfl/dotty/pull/10940">#10940</a></li> 
     <li>Rename <code>Not</code> to <code>NotGiven</code> to make its purpose clearer <a href="https://github.com/lampepfl/dotty/pull/10720">#10720</a></li> 
     <li>Fix <a href="https://github.com/lampepfl/dotty/issues/10709">#10709</a>: Add missing level check before inlining <a href="https://github.com/lampepfl/dotty/pull/10781">#10781</a></li> 
    </ul> 
     
    <p>If you have questions or any sort of feedback, feel free to send us a message on our <a href="https://gitter.im/lampepfl/dotty">Gitter channel</a>. If you encounter a bug, please <a href="https://github.com/lampepfl/dotty/issues/new">open an issue on GitHub</a>.</p> 
    <h2><a href="#contributors" id="contributors"></a>Contributors</h2> 
    <p>Thank you to all the contributors who made this release possible ğŸ‰</p> 
    <p>According to <code>git shortlog -sn --no-merges 3.0.0-M3..3.0.0-RC1</code> these are:</p> 
    <pre><code>   183  Martin Odersky
   138  Nicolas Stucki
    36  Krzysztof Romanowski
    25  Filip ZybaÅ‚a
    25  Liu Fengyun
    24  Lan, Jian
    22  Jamie Thompson
    19  Tom Grigg
    17  Andrzej Ratajczak
    16  StÃ©phane Micheloud
    15  Guillaume Martres
    11  PaweÅ‚ Marks
     9  Phil
     6  Aleksander Boruch-Gruszecki
     6  Jonathan BrachthÃ¤user
     6  Natsu Kagami
     6  odersky
     4  Jasper Moeys
     4  Adrien Piquerez
     3  SÃ©bastien Doeraene
     3  MichaÅ‚ PaÅ‚ka
     3  Albert Chen
     2  Alexandre Archambault
     2  Som Snytt
     2  kenji yoshida
     2  Luc Henninger
     2  Ayush
     2  Raphael Jolly
     2  Anatolii Kmetiuk
     2  Olivier Blanvillain
     2  changvvb
     1  ysthakur
     1  Ang Hao Yang
     1  Ang9876
     1  AngAng
     1  August Nagro
     1  Ciara O'Brien
     1  Dale Wijnand
     1  Florian Cassayre
     1  Florian Schmaus
     1  Iltotore
     1  Jason Zaugg
     1  Julien Richard-Foy
     1  Katrix
     1  Master-Killer
     1  Michael Pilquist
     1  Mikael Blomstrand
     1  Mike Samuel
     1  Philippus
     1  Philippus Baalman
     1  Rick M
     1  Stephane MICHELOUD
     1  Timur Abishev
     1  Tomas
     1  ansvonwa
     1  ayush
     1  costa100
     1  iroha168
     1  noti0na1
     1  riiswa
     1  tanishiking
</code></pre> 
    <p>If you want to get your hands dirty and contribute to Scala 3, now is a good time to get involved! Head to our <a href="https://dotty.epfl.ch/docs/contributing/getting-started.html">Getting Started page for new contributors</a>, and have a look at some of the <a href="https://github.com/lampepfl/dotty/issues?q=is%3Aissue+is%3Aopen+label%3Aexp%3Anovice">good first issues</a>. They make perfect entry points into hacking on the compiler.</p> 
    <p>We are looking forward to having you join the team of contributors.</p> 
    <hr> 
    <p><img id="author-img" src="https://dotty.epfl.ch/images/anatolii.png"> <span id="author-signature"> Anatolii Kmetiuk </span> 
    </p> 
   </main> 
  </div></div>]]>
            </description>
            <link>https://dotty.epfl.ch/blog/2021/02/17/scala3-rc1.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26184110</guid>
            <pubDate>Thu, 18 Feb 2021 19:09:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Rockset is up to 9.4 times faster than Druid on Star Schema Benchmark queries]]>
            </title>
            <description>
<![CDATA[
Score 15 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26184105">thread link</a>) | @box2A1
<br/>
February 18, 2021 | https://rockset.com/blog/rockset-up-to-9x-faster-than-apache-druid-star-schema-benchmark/ | <a href="https://web.archive.org/web/*/https://rockset.com/blog/rockset-up-to-9x-faster-than-apache-druid-star-schema-benchmark/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Real-time analytics is all about deriving insights and taking actions as soon as data is produced. When broken down into its core requirements, real-time analytics means two things: access to fresh data and fast responses to queries. These are essentially two measures of latency, which we term data latency and query latency, respectively.</p>
<p>Data latency is the time from when data is produced to when it can be queried, and is a function of how efficiently a database can sustain writes. As it usually gets less focus in benchmarks, we released <a href="https://rockset.com/blog/rockset-1-billion-events-in-a-day-with-1-second-data-latency/">RockBench</a>, a data latency benchmark, last September. Using RockBench, we ascertained Rocksetâ€™s suitability for many real-time analytics applications due to its ability to keep data latency to under 1 second, while ingesting 1 billion events per day, on a standard 4XLarge Virtual Instance.</p>
<h3>Query Latency and the Star Schema Benchmark</h3>
<p>Query latency is the second key measure of real-time analytics performance and is the focus of the rest of this post.
To evaluate query latency, we turned to the Star Schema Benchmark (SSB), an industry-standard benchmark to measure database performance on analytical applications. The SSB was designed for a batch analytics scenario, rather than real-time analytics, but will still yield useful insight into Rocksetâ€™s performance on analytical queries.</p>
<p>The SSB has also been used for performance measurements of other modern data technologies. In June 2020, Imply released a <a href="https://go.imply.io/rs/910-OTN-223/images/Apache-Druid-and-Google-BigQuery-performance-evaluation.pdf">study</a> of Apache Druid and Google BigQuery performance on the SSB. For the Rockset benchmark, we used the same hardware resources that were used in the Druid benchmark to provide greater context for our SSB evaluation.</p>
<h3>Up to 9.4x Faster than Druid</h3>
<p>From the benchmarking results, we observed one SSB query execute 9.4x faster on Rockset than on Druid, with many queries running 2x to 4x faster. The entire SSB suite ran 1.5x faster on <a href="https://rockset.com/comparisons/rockset-vs-apache-druid">Rockset compared to Druid</a>. This demonstrates better performance with resource parity, since pricing was not available for a true price-performance comparison.</p>
<p>In making these comparisons, we recognize we are not experts in configuring Druid, so we relied on a benchmark report from those who have the most knowledge about their system and can tune it best. In addition, benchmarks represent a snapshot in time, and systems will get faster with each new release. We are using the most recent benchmark published by Imply for comparison, but we expect Druid performance will continue to improve, as will Rocksetâ€™s.</p>
<h3>Running the Star Schema Benchmark on Rockset</h3>
<p><strong>Benchmark Overview</strong></p>
<p>The SSB comprises a suite of 13 analytical SQL queries that provide a good combination of functional and selectivity coverage.</p>
<p>We conducted the benchmark using SSB data at scale factor 100, which corresponds to 100GB and 600M rows of data. We denormalized the generated data prior to loading to provide a more direct comparison to the Druid benchmark, which avoided query-time joins, since Druid only recently added some limited join support.</p>
<p><span>
        <span>
          <picture>
          <source srcset="https://images.ctfassets.net/1d31s1aajogl/6wQnA481EPGFKQEBq9jqlD/c385adf28f987ec64149ee5ce6b6af4c/rockset-ssb-diagram.png?w=560&amp;fm=webp 560w,
https://images.ctfassets.net/1d31s1aajogl/6wQnA481EPGFKQEBq9jqlD/c385adf28f987ec64149ee5ce6b6af4c/rockset-ssb-diagram.png?w=1120&amp;fm=webp 1120w,
https://images.ctfassets.net/1d31s1aajogl/6wQnA481EPGFKQEBq9jqlD/c385adf28f987ec64149ee5ce6b6af4c/rockset-ssb-diagram.png?w=2240&amp;fm=webp 2240w" sizes="(max-width: 590px) 100vw, 590px" type="image/webp">
          <source srcset="https://images.ctfassets.net/1d31s1aajogl/6wQnA481EPGFKQEBq9jqlD/c385adf28f987ec64149ee5ce6b6af4c/rockset-ssb-diagram.png?w=560 560w,
https://images.ctfassets.net/1d31s1aajogl/6wQnA481EPGFKQEBq9jqlD/c385adf28f987ec64149ee5ce6b6af4c/rockset-ssb-diagram.png?w=1120 1120w,
https://images.ctfassets.net/1d31s1aajogl/6wQnA481EPGFKQEBq9jqlD/c385adf28f987ec64149ee5ce6b6af4c/rockset-ssb-diagram.png?w=2240 2240w" sizes="(max-width: 590px) 100vw, 590px">
          <img alt="rockset-ssb-diagram" title="" src="https://images.ctfassets.net/1d31s1aajogl/6wQnA481EPGFKQEBq9jqlD/c385adf28f987ec64149ee5ce6b6af4c/rockset-ssb-diagram.png" loading="lazy">
        </picture>
        </span>
      </span>
<em>Figure 1: Performance harness used to generate and load SSB data, run queries and measure query runtimes</em></p>
<p>Loading into Rockset was straightforward and required zero configuration, apart from specifying some keys for column-based clustering. Once the SSB data was loaded into Rockset, we ran a load-generator query script, based on the Rockset Python client, that issued queries and measured runtimes.</p>
<p><strong>Benchmark Results</strong></p>
<p>We recorded the following runtimes across the 13 SSB queries.</p>
<p><span>
        <span>
          <picture>
          <source srcset="https://images.ctfassets.net/1d31s1aajogl/gtyqIwjx5kKG2PxpXGrJk/2842c3354e855724fee008c2a252a1da/rockset-ssb-results.png?w=281&amp;fm=webp 281w,
https://images.ctfassets.net/1d31s1aajogl/gtyqIwjx5kKG2PxpXGrJk/2842c3354e855724fee008c2a252a1da/rockset-ssb-results.png?w=562&amp;fm=webp 562w,
https://images.ctfassets.net/1d31s1aajogl/gtyqIwjx5kKG2PxpXGrJk/2842c3354e855724fee008c2a252a1da/rockset-ssb-results.png?w=1124&amp;fm=webp 1124w" sizes="(max-width: 590px) 100vw, 590px" type="image/webp">
          <source srcset="https://images.ctfassets.net/1d31s1aajogl/gtyqIwjx5kKG2PxpXGrJk/2842c3354e855724fee008c2a252a1da/rockset-ssb-results.png?w=281 281w,
https://images.ctfassets.net/1d31s1aajogl/gtyqIwjx5kKG2PxpXGrJk/2842c3354e855724fee008c2a252a1da/rockset-ssb-results.png?w=562 562w,
https://images.ctfassets.net/1d31s1aajogl/gtyqIwjx5kKG2PxpXGrJk/2842c3354e855724fee008c2a252a1da/rockset-ssb-results.png?w=1124 1124w" sizes="(max-width: 590px) 100vw, 590px">
          <img alt="rockset-ssb-results" title="" src="https://images.ctfassets.net/1d31s1aajogl/gtyqIwjx5kKG2PxpXGrJk/2842c3354e855724fee008c2a252a1da/rockset-ssb-results.png" loading="lazy">
        </picture>
        </span>
      </span>
<em>Figure 2: Benchmark results when running SSB on Rockset (600M rows, 100GB data set)</em></p>
<p>All queries in the SSB suite executed in under 1 second on Rockset, with a median runtime of 254 ms. This result demonstrates Rocksetâ€™s ability to run complex analytics with sub-second performance, a common requirement for real-time analytics applications.</p>
<p>When comparing to these results with Druidâ€™s, we observe that 9 out of the 13 queries ran faster on Rockset. Rockset was 9.4x faster on the query with the largest speedup, with many queries in the 2x to 4x range, whereas Druidâ€™s largest advantage was a 3.2x speedup. The suite of 13 queries completed in 4,146 ms on Rockset compared to 6,043 ms on Druid, corresponding to a 1.5x speedup overall. The following figures show Rocksetâ€™s query runtimes compared to those reported in Implyâ€™s Druid and BigQuery paper.</p>
<p><span>
        <span>
          <picture>
          <source srcset="https://images.ctfassets.net/1d31s1aajogl/3iI6RKmdNIU1LMPZADHr4L/c85c70cd8a53d8a2e25f1359e210f5ab/rockset-druid-ssb.png?w=408&amp;fm=webp 408w,
https://images.ctfassets.net/1d31s1aajogl/3iI6RKmdNIU1LMPZADHr4L/c85c70cd8a53d8a2e25f1359e210f5ab/rockset-druid-ssb.png?w=815&amp;fm=webp 815w,
https://images.ctfassets.net/1d31s1aajogl/3iI6RKmdNIU1LMPZADHr4L/c85c70cd8a53d8a2e25f1359e210f5ab/rockset-druid-ssb.png?w=1630&amp;fm=webp 1630w" sizes="(max-width: 590px) 100vw, 590px" type="image/webp">
          <source srcset="https://images.ctfassets.net/1d31s1aajogl/3iI6RKmdNIU1LMPZADHr4L/c85c70cd8a53d8a2e25f1359e210f5ab/rockset-druid-ssb.png?w=408 408w,
https://images.ctfassets.net/1d31s1aajogl/3iI6RKmdNIU1LMPZADHr4L/c85c70cd8a53d8a2e25f1359e210f5ab/rockset-druid-ssb.png?w=815 815w,
https://images.ctfassets.net/1d31s1aajogl/3iI6RKmdNIU1LMPZADHr4L/c85c70cd8a53d8a2e25f1359e210f5ab/rockset-druid-ssb.png?w=1630 1630w" sizes="(max-width: 590px) 100vw, 590px">
          <img alt="rockset-druid-ssb" title="" src="https://images.ctfassets.net/1d31s1aajogl/3iI6RKmdNIU1LMPZADHr4L/c85c70cd8a53d8a2e25f1359e210f5ab/rockset-druid-ssb.png" loading="lazy">
        </picture>
        </span>
      </span>
<em>Figure 3: Comparing Rockset and Druid SSB results</em></p>
<p><span>
        <span>
          <picture>
          <source srcset="https://images.ctfassets.net/1d31s1aajogl/2nTaKbhcNK407P8T9r15ye/477be128e68d9a5535629d2cbccbbb7f/rockset-ssb-graph.png?w=429&amp;fm=webp 429w,
https://images.ctfassets.net/1d31s1aajogl/2nTaKbhcNK407P8T9r15ye/477be128e68d9a5535629d2cbccbbb7f/rockset-ssb-graph.png?w=857&amp;fm=webp 857w,
https://images.ctfassets.net/1d31s1aajogl/2nTaKbhcNK407P8T9r15ye/477be128e68d9a5535629d2cbccbbb7f/rockset-ssb-graph.png?w=1714&amp;fm=webp 1714w" sizes="(max-width: 590px) 100vw, 590px" type="image/webp">
          <source srcset="https://images.ctfassets.net/1d31s1aajogl/2nTaKbhcNK407P8T9r15ye/477be128e68d9a5535629d2cbccbbb7f/rockset-ssb-graph.png?w=429 429w,
https://images.ctfassets.net/1d31s1aajogl/2nTaKbhcNK407P8T9r15ye/477be128e68d9a5535629d2cbccbbb7f/rockset-ssb-graph.png?w=857 857w,
https://images.ctfassets.net/1d31s1aajogl/2nTaKbhcNK407P8T9r15ye/477be128e68d9a5535629d2cbccbbb7f/rockset-ssb-graph.png?w=1714 1714w" sizes="(max-width: 590px) 100vw, 590px">
          <img alt="rockset-ssb-graph" title="" src="https://images.ctfassets.net/1d31s1aajogl/2nTaKbhcNK407P8T9r15ye/477be128e68d9a5535629d2cbccbbb7f/rockset-ssb-graph.png" loading="lazy">
        </picture>
        </span>
      </span>
<em>Figure 4: Graph showing Rockset, Druid and BigQuery runtimes on SSB queries</em></p>
<h3>How Rockset Accelerates Real-Time Analytics</h3>
<p>Several Rockset features work in concert to accelerate these SSB queries and real-time analytics in general.</p>
<ul>
<li>Converged Indexâ„¢</li>
<li>Column-based clustering</li>
<li>Vectorization</li>
</ul>
<p><strong>Converged Index</strong></p>
<p>Rockset stores all ingested data in a <a href="https://rockset.com/blog/how-rocksets-converged-index-powers-real-time-analytics/">Converged Index</a>, which is a combination of: </p>
<ul>
<li>Inverted index</li>
<li>Column-based index</li>
<li>Row-based index</li>
</ul>
<p>Each query can take advantage of the index that is best suited for it and leads to the fastest execution. For instance, highly selective queries typically benefit from using the inverted index, while queries that require aggregations over large numbers of records will benefit from using the column-based index. By indexing data in three different ways, multiple types of queries can be executed efficiently without any manual intervention.</p>
<p><strong>Column-based clustering</strong></p>
<p>Users can configure column-based clustering so as to colocate data according to a clustering key they specify. This maximizes the opportunity for sequential access and reduces the amount of data that needs to be scanned for each query.</p>
<p><strong>Vectorization</strong></p>
<p>Rockset uses columnar data chunks to exchange data between query execution operators. This allows vectorized processing, where operations are performed on many values, instead of one value, at a time, resulting in more efficient query execution.</p>
<h3>What This Means for Developers of Real-Time Analytics</h3>
<p>With this SSB performance evaluation, we determined that Rockset is capable of delivering the sub-second query latency needed for real-time analytics, with better performance than alternatives like Druid. Coupled with the earlier RockBench evaluation that established Rocksetâ€™s ability to analyze data being written in real time, we see that Rockset can be a good fit for real-time analytics applications that require fast queries on the latest data. These include many use cases like logistics tracking, security analytics, e-commerce personalization, gaming leaderboards and customer-facing SaaS analytics.</p>
<p>While this evaluation was performed on a denormalized data set, Rockset's design also allows it to execute joins efficiently, so applications are not limited to operating on denormalized data. Future work would include running Rockset performance evaluations involving joins on normalized data.</p>
<p>Additionally, SSB data is well structured and therefore less representative of the real-life semi-structured data sets we commonly come across. It should be noted that Rockset can support the same analytical SQL queries on complex, nested data as well.</p>
<p>Given Rocksetâ€™s ability to provide both the write and read performance required for real-time analytics, we invite you to include Rockset in your consideration if you are developing real-time analytics features or products. Read the <a href="http://rockset.com/star-schema-benchmark">Rockset Performance Evaluation on the Star Schema Benchmark</a> white paper to get the details on how we ran the SSB evaluation. Or, <a href="https://console.rockset.com/create">sign up for a free Rockset account</a> to try running your own queries on Rockset!</p></div></div>]]>
            </description>
            <link>https://rockset.com/blog/rockset-up-to-9x-faster-than-apache-druid-star-schema-benchmark/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26184105</guid>
            <pubDate>Thu, 18 Feb 2021 19:09:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Cutting Build Time in Half with Dockerâ€™s Buildx Kubernetes Driver]]>
            </title>
            <description>
<![CDATA[
Score 9 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26183334">thread link</a>) | @jeremy_k
<br/>
February 18, 2021 | https://releaseapp.io/blog/cutting-build-time-in-half-docker-buildx-kubernetes | <a href="https://web.archive.org/web/*/https://releaseapp.io/blog/cutting-build-time-in-half-docker-buildx-kubernetes">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><div><p>At Release, environments are our main focus, but we canâ€™t create environments without builds. Recently we undertook a project to revisit our build infrastructure and determine if it needed to be upgraded. Build times had become a big factor in our service delivery and we needed a way to improve our customersâ€™ experiences. One of the main areas that we wanted to improve upon was the parallelism of building multiple docker images for a single application.</p><p>The title of the article already spoiled the solution, and the alternative â€˜Release Did This One Thing To Cut Their Build Time In Half!â€™ didnâ€™t quite fly with the rest of the company, but Dockerâ€™s new <a href="https://github.com/docker/buildx" target="_blank" rel="noreferrer">buildx</a> project fit the bill. First, weâ€™ll cover what our original infrastructure looked like and how long builds on an example project were taking. Then, weâ€™ll describe the changes we made to use buildx and the speed increases we observed.</p><p>Letâ€™s start off with a diagram of what our original infrastructure looked like.</p><p><img src="https://images.ctfassets.net/qf96nnjfyr2y/75WoaAxoZMIL73zK0JKPId/f98ff948f97c0cc7b979c4b4352a032c/release-builder-architecture.png" alt="release-builder-architecture"></p><p>As you can see, the requests for builds would flow into our main Rails application and then divvied out to the different builder instances through Sidekiq. The <code>builder</code> container is Ruby code that would authenticate to Github, clone the repository, check out the correct SHA, and then execute the <code>docker build</code>. Due to the way we built the authentication to pull the code from Github, a single <code>builder</code> container could only clone one repository at a time. Which meant that the container could only do a single build request at a time. We added threading in the Ruby code to be able to execute multiple <code>docker build</code> commands at a time, but the number of builder containers we had spun up limited our concurrent builds. While itâ€™s not hard to horizontally scale with Kubernetes, we saw this authentication setup as a major bottleneck. </p><p>Another issue we encountered was that we had no mechanism for attempting to place builds on servers where they had been previously built, instead opting for grabbing the first free server. This meant there was very little chance to land on the same server and get the full benefit of Docker caching. While this isnâ€™t a deal breaker for us, we still believed we could do better when creating the version of our build infrastructure. Enough of the theoretical, letâ€™s actually build something!</p><p>Release Applications can contain many docker images and one of our favorite example repositories to showcase this is our fork of <a href="https://github.com/awesome-release/release-example-voting-app" target="_blank" rel="noreferrer">example-voting-app</a>. Looking at the <a href="https://github.com/awesome-release/release-example-voting-app/blob/master/docker-compose.yml" target="_blank" rel="noreferrer">docker-compose</a> we see that there are 3 different Docker images that we have to build, <code>result</code>, <code>vote</code>, and <code>worker</code>. Now that we have an understanding of Releaseâ€™s original infrastructure and the application we want to build, letâ€™s start up a fresh build and see the results.</p><p><em>NOTE</em> I forked the <code>awesome-release</code> repo to my own Github, <code>jer-k</code> for the following results.</p><p><img src="https://images.ctfassets.net/qf96nnjfyr2y/21reYa1lgqocT6MTojva4J/0d6826574fb8718d76bfcf6c855dd490/uncached-release.png" alt="uncached-release"></p><p>We can see that this brand new build with no cache hits took two minutes and 15 seconds to complete. Next, we want to make a few changes to ensure that each Docker image needs to be rebuilt. The changes are listed below.</p><div><pre><p><span>1</span><span>git status</span></p><p><span>2</span><span>On branch release_builders</span></p><p><span>3</span><span>Changes to be committed:</span></p><p><span>4</span><span>  (use "git restore --staged &lt;file&gt;..." to unstage)</span></p><p><span>5</span><span>    modified:   result/views/index.html</span></p><p><span>6</span><span>    modified:   vote/app.py</span></p><p><span>7</span><span>    modified:   worker/src/main/java/worker/Worker.java</span></p></pre></div><p>For the purpose of this blog post, I ensured the following build ran on the same builder as the first and that we will have cache hits. As noted before, this wasnâ€™t always the case in our production environment.</p><p><img src="https://images.ctfassets.net/qf96nnjfyr2y/69tKlV3mBuV6S6c7BhSaay/c51464f443c1888cd4f74fe3394b32f4/cached-release.png" alt="cached-release"></p><p>The caching helps and cuts 45 seconds off the build! The uncached build took almost twice as long as the second build with caching, but our assumption was that we could do a lot better (cached and uncached) with some new technology.</p><h2 id="enter-dockers-buildx-kubernetes-driver">Enter Dockerâ€™s Buildx Kubernetes Driver</h2><p>One of the first things we wanted to solve was the concurrency issue and we set out to ensure that Docker itself was able to handle a larger workload. We came across the issue <a href="https://github.com/moby/moby/issues/9656" target="_blank" rel="noreferrer">Concurrent â€œdocker buildâ€ takes longer than sequential builds</a> where people were describing what we feared; Docker slowed down when many builds were being run at the same time. Lucky for us, that issue was opened in 2014 and plenty of work had been done to resolve this issue. The final comment, by a member of the Docker team, was <a href="https://github.com/moby/moby/issues/9656#issuecomment-610476810" target="_blank" rel="noreferrer">â€œClosing this. BuildKit is highly optimized for parallel workloads. If you see anything like this in buildkit or buildkit compared to legacy builder please report a new issue with a repro case.â€</a> Thus we set out to learn more about <a href="https://docs.docker.com/develop/develop-images/build_enhancements/" target="_blank" rel="noreferrer">BuildKit</a> (the Github repository is located <a href="https://github.com/moby/buildkit" target="_blank" rel="noreferrer">here</a>). While researching, we came across <a href="https://github.com/docker/buildx" target="_blank" rel="noreferrer">buildx</a>, which ended up having three key features we believed would resolve many of our issues. These three features were the <a href="https://github.com/docker/buildx#buildx-bake-options-target" target="_blank" rel="noreferrer">bake</a> command, the <a href="https://github.com/docker/buildx#--driver-driver" target="_blank" rel="noreferrer">buildx kubernetes driver</a>, and the ability for the Kubernetes driver to consistently send builds to the same server. Letâ€™s cover each of these, first up the <code>bake</code> command.</p><div><pre><p><span>1</span><span>buildx bake [OPTIONS] [TARGET...]</span></p><p><span>2</span><span>Bake is a high-level build command.</span></p><p><span>3</span><span></span></p><p><span>4</span><span>Each specified target will run in parallel as part of the build.</span></p></pre></div><p><code>bake</code> intrigued us because it seemed to be a built-in command for us to avoid using Ruby threading for our parallelism. <code>bake</code> takes an input of a file, which can either be in the form of a <code>docker-compose</code>, <code>.json</code>, or <code>.hcl</code>. We initially tested <code>bake</code> with the docker-compose from example-voting-app and we were blown away at how smoothly it built directly out of the box and how quickly it was able to build the three images! However, we opted to create our own <code>.json</code> file generator in Ruby, parsing our <a href="">Application Template</a> into an output. Here is our generated file for example-voting-app.</p><div><pre><p><span>1</span><span>{</span><span></span></p><p><span>2</span><span>  </span><span>"group"</span><span>:</span><span> </span><span>{</span><span></span></p><p><span>3</span><span>    </span><span>"default"</span><span>:</span><span> </span><span>{</span><span></span></p><p><span>4</span><span>      </span><span>"targets"</span><span>:</span><span> </span><span>[</span><span></span></p><p><span>5</span><span>        </span><span>"vote"</span><span>,</span><span></span></p><p><span>6</span><span>        </span><span>"result"</span><span>,</span><span></span></p><p><span>7</span><span>        </span><span>"worker"</span><span></span></p><p><span>8</span><span>      </span><span>]</span><span></span></p><p><span>9</span><span>    </span><span>}</span><span></span></p><p><span>10</span><span>  </span><span>}</span><span>,</span><span></span></p><p><span>11</span><span>  </span><span>"target"</span><span>:</span><span> </span><span>{</span><span></span></p><p><span>12</span><span>    </span><span>"vote"</span><span>:</span><span> </span><span>{</span><span></span></p><p><span>13</span><span>      </span><span>"context"</span><span>:</span><span> </span><span>"./vote"</span><span>,</span><span></span></p><p><span>14</span><span>      </span><span>"tags"</span><span>:</span><span> </span><span>[</span><span></span></p><p><span>15</span><span>        </span><span>"&lt;REDACTED&gt;.dkr.ecr.us-west-2.amazonaws.com/jer-k/release-example-voting-app/vote:latest"</span><span>,</span><span></span></p><p><span>16</span><span>        </span><span>"&lt;REDACTED&gt;.dkr.ecr.us-west-2.amazonaws.com/jer-k/release-example-voting-app/vote:buildx-builders"</span><span></span></p><p><span>17</span><span>      </span><span>]</span><span></span></p><p><span>18</span><span>    </span><span>}</span><span>,</span><span></span></p><p><span>19</span><span>    </span><span>"result"</span><span>:</span><span> </span><span>{</span><span></span></p><p><span>20</span><span>      </span><span>"context"</span><span>:</span><span> </span><span>"./result"</span><span>,</span><span></span></p><p><span>21</span><span>      </span><span>"tags"</span><span>:</span><span> </span><span>[</span><span></span></p><p><span>22</span><span>        </span><span>"&lt;REDACTED&gt;.dkr.ecr.us-west-2.amazonaws.com/jer-k/release-example-voting-app/result:latest"</span><span>,</span><span></span></p><p><span>23</span><span>        </span><span>"&lt;REDACTED&gt;.dkr.ecr.us-west-2.amazonaws.com/jer-k/release-example-voting-app/result:buildx-builders"</span><span></span></p><p><span>24</span><span>      </span><span>]</span><span></span></p><p><span>25</span><span>    </span><span>}</span><span>,</span><span></span></p><p><span>26</span><span>    </span><span>"worker"</span><span>:</span><span> </span><span>{</span><span></span></p><p><span>27</span><span>      </span><span>"context"</span><span>:</span><span> </span><span>"./worker"</span><span>,</span><span></span></p><p><span>28</span><span>      </span><span>"tags"</span><span>:</span><span> </span><span>[</span><span></span></p><p><span>29</span><span>        </span><span>"&lt;REDACTED&gt;.dkr.ecr.us-west-2.amazonaws.com/jer-k/release-example-voting-app/worker:latest"</span><span>,</span><span></span></p><p><span>30</span><span>        </span><span>"&lt;REDACTED&gt;.dkr.ecr.us-west-2.amazonaws.com/jer-k/release-example-voting-app/worker:buildx-builders"</span><span></span></p><p><span>31</span><span>      </span><span>]</span><span></span></p><p><span>32</span><span>    </span><span>}</span><span></span></p><p><span>33</span><span>  </span><span>}</span><span></span></p><p><span>34</span><span></span><span>}</span></p></pre></div><p>There are other inputs which can make their way into this file, such as build args, but since example-voting-app does not have any, they are omitted.</p><p>Next, we wanted to find more information on the Kubernetes driver and we found this blog post <a href="https://medium.com/nttlabs/buildx-kubernetes-ad0fe59b0c64" target="_blank" rel="noreferrer">Kubernetes driver for Docker BuildX</a> from the author of the <a href="https://github.com/docker/buildx/pull/167" target="_blank" rel="noreferrer">Pull Request</a>. We encourage you to read the latter as it covers getting up and running with the Kubernetes driver as well how the caching works, which is exactly what we needed. With that information in hand, we were able to start work on adding the buildx servers to our cluster. We created a generic way to deploy the servers into different clusters and adjust the number of replicas with the final command being</p><div><pre><p><span>1</span><span>docker buildx create --name #{name} --driver kubernetes --driver-opt replicas=#{num_replicas},namespace=#{builder_namespace} --use</span></p></pre></div><p>For us, we created a <code>release-builder</code> namespace with five replicas, in our development cluster. We can see the output by querying for the pods</p><div><pre><p><span>1</span><span>kubectl get pods --namespace=release-builder</span></p><p><span>2</span><span>NAME                            READY   STATUS    RESTARTS   AGE</span></p><p><span>3</span><span>development0-86d99fcf46-26j9f   1/1     Running   0          6d10h</span></p><p><span>4</span><span>development0-86d99fcf46-5scpq   1/1     Running   0          6d13h</span></p><p><span>5</span><span>development0-86d99fcf46-jkk2b   1/1     Running   0          15d</span></p><p><span>6</span><span>development0-86d99fcf46-llkgq   1/1     Running   0          18d</span></p><p><span>7</span><span>development0-86d99fcf46-mr9jt   1/1     Running   0          20d</span></p></pre></div><p>Since we have five replicas, we wanted to ensure that when we build applications, they end up on the same server so that we get the greatest amount of caching possible (distributed caching is a topic for another day). Luckily for us, <code>buildx</code>, with the Kubernetes driver, has an option for where to send the builds called <code>loadbalance</code>.</p><div><pre><p><span>1</span><span>loadbalance=(sticky|random) - Load-balancing strategy. </span></p><p><span>2</span><span>If set to "sticky", the pod is chosen using the hash of the context path. Defaults to "sticky"</span></p></pre></div><p>The default <code>sticky</code> means that the builds should always end up on the same server due to the hashing (more detailed information on this is described in the aforementioned blog post). With all of that in place, we are ready to test out our new setup!</p><p>Using the same example-voting-app repository as before, I created a new branch <code>buildx_builders</code> and pointed the code to the buildx servers. </p><p><img src="https://images.ctfassets.net/qf96nnjfyr2y/3gqbExE2XQMNqyUQ60m27m/9e215fc99510b5a18bb6792eba5679ec/uncached-buildx.png" alt="uncached-buildx"></p><p>What we see is that this uncached build was more than twice as fast as the other uncached build and even faster than the cached build on the old infrastructure! But uncached builds should be a thing of the past with the sticky load balancing, so letâ€™s make the same changes as the previous branch and see the results.</p><p><img src="https://images.ctfassets.net/qf96nnjfyr2y/2MxDyCqaSrOnffVSNC3SFu/abc0896e3eef27b927394b12fc9e1e29/cached-buildx.png" alt="cached-buildx"></p><p>This build finished three times faster than the previous cached build! These types of speed increases are the reason we set out to redo our build infrastructure. The faster the builds complete, the faster we can create environments and help our customers deliver their products.</p><p>Weâ€™re still experimenting with <code>buildx</code> and learning as we go, but the initial results were more than enough for us to migrate our own production builds to the new infrastructure. Weâ€™re going to continue to blog about this topic as we learn more and scale so check back in with the Release blog in the future!</p></div></article></div>]]>
            </description>
            <link>https://releaseapp.io/blog/cutting-build-time-in-half-docker-buildx-kubernetes</link>
            <guid isPermaLink="false">hacker-news-small-sites-26183334</guid>
            <pubDate>Thu, 18 Feb 2021 18:11:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[GPT-3, Esq? Evaluating AI Legal Summaries [pdf]]]>
            </title>
            <description>
<![CDATA[
Score 49 | Comments 37 (<a href="https://news.ycombinator.com/item?id=26183114">thread link</a>) | @gavelin
<br/>
February 18, 2021 | http://www.davidvictorrodriguez.com/uploads/2/6/4/2/26420847/gpt-3_esq_-_evaluating_ai_legal_summaries.pdf | <a href="https://web.archive.org/web/*/http://www.davidvictorrodriguez.com/uploads/2/6/4/2/26420847/gpt-3_esq_-_evaluating_ai_legal_summaries.pdf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>http://www.davidvictorrodriguez.com/uploads/2/6/4/2/26420847/gpt-3_esq_-_evaluating_ai_legal_summaries.pdf</link>
            <guid isPermaLink="false">hacker-news-small-sites-26183114</guid>
            <pubDate>Thu, 18 Feb 2021 17:53:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Turn an Idea into a Business]]>
            </title>
            <description>
<![CDATA[
Score 9 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26183057">thread link</a>) | @davidkolodny
<br/>
February 18, 2021 | https://www.wilburlabs.com/blueprints/how-to-turn-an-idea-into-a-business | <a href="https://web.archive.org/web/*/https://www.wilburlabs.com/blueprints/how-to-turn-an-idea-into-a-business">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p>Turning an idea into a business can be one of the most fulfilling and rewarding challenges of a lifetime. ItÃ¢â‚¬â„¢s not easy, but the skills and experiences required to start a business are learnable. </p><p>Great entrepreneurs are made, not born. Hard work, drive, and absolute determination can make up for gaps in skills and experience. The rest is learned by doing, making mistakes, and adapting along the way.</p><p>Wilbur Labs is a startup studio turning bold ideas into market-leading companies. Since 2016 we have launched and invested in 15 technology companies, including <a href="https://www.vacationrenter.com/">VacationRenter</a>, <a href="https://www.vitabox.com/">Vitabox</a>, <a href="https://www.joblist.com/">Joblist</a>, and <a href="https://www.barkbus.com/">Barkbus</a>. Today, our portfolio companies have hundreds of millions of users from around the world, and have generated billions of dollars in sales. We plan to launch several companies every year.</p><p>One question that weÃ¢â‚¬â„¢re constantly asked is: <br></p></div><h2>How do you turn an idea into a business?</h2><div><p>Launching a business is typically a one-time event. At Wilbur Labs, itÃ¢â‚¬â„¢s a repeatable and systematized process. Turning a bold idea into a business Ã¢â‚¬â€œ over and over Ã¢â‚¬â€œ is what we do. Over time, we have defined several critical steps that are key to effectively turn any idea into a business. WeÃ¢â‚¬â„¢re sharing that playbook with you to help you on your journey.</p><p><em>Note: This guide assumes that you already have an idea for a business. Coming up with an idea for a company is a separate topic covered in our <a href="https://www.wilburlabs.com/blueprints/how-to-get-startup-ideas">How to Get Startup Ideas</a> Blueprint.</em></p></div><h2>Step 1: Research</h2><div><p>The research stage is where you pair your initial idea with independent and external information. This should include first-hand research, speaking with industry experts, and talking with target customers to answer key questions:</p><ul><li>What problem are you trying to solve? </li><li>How big is this problem?</li><li>How would this make people's lives better?</li><li>Why are the current solutions not optimal?</li><li>Who are the competitors?</li><li>What is the business model?</li><li>How big of a business could you build?</li><li>Are you the right person to solve this problem?</li><li>What advantages do you have in solving this problem?</li><li>Do you care about this enough to work on it for 5+ years?</li><li>What are the outstanding challenges or questions?</li></ul><p>During this stage, you should talk with as many people as possible. You will be surprised how many target customers and industry experts are receptive to cold outreach to discuss a business idea. We recommend using LinkedIn or Twitter to source experts who know the problem you are trying to solve, and ask if theyÃ¢â‚¬â„¢re open to having a quick chat to discuss your idea. Many people passionate about an industry or a problem love talking with others who are equally as interested.</p><p>In addition to cold outreach, you should also use your personal network to reach out to any existing industry contacts who may be helpful Ã¢â‚¬â€œ or know people who might be helpful Ã¢â‚¬â€œ in researching this idea.</p><p>Be cautious about asking business advice from people close to you, because itÃ¢â‚¬â„¢s unlikely that you will get truly honest and critical feedback. Expect pushback because itÃ¢â‚¬â„¢s unlikely that everyone will love your idea, and thatÃ¢â‚¬â„¢s okay. Some of our boldest ideas received mixed feedback in the beginning. The point here is that you hear multiple viewpoints and use feedback to guide your research and planning. </p><p>Make sure to go very deep on your research during this stage. Some of our ideas remain in this stage for 6 to 12 months. Ideas are easy and everyone has them. This stage helps filter out the so-so ideas to prevent you from wasting time in a later stage. Frontloading research and due diligence here can also reduce risk and expedite future stages.</p><p>The best business ideas will bring a sense of urgency and motivation, pushing you to keep moving forward. If you are able to gain significant momentum through research, it makes sense to move into the planning stage.</p></div><h2>Step 2: Plan</h2><div><p>In the planning stage you should focus on taking your learnings and creating an executable plan. This will require diving deeper into the areas you looked into during the research phase, as well as answering new questions.</p><p>At Wilbur Labs, we create a Ã¢â‚¬Å“Concept EvaluationÃ¢â‚¬ï¿½ which is our own version of a business plan. Whatever format you choose, itÃ¢â‚¬â„¢s important to have a written plan that organizes all your research into an actionable plan that looks at every angle of your idea.</p><p>We like to work backwards during this stage, thinking about how we want the business to look 3 to 5 years ahead and then build a roadmap to get there. In our Concept Evaluation, we answer a number of questions, including but not limited to:</p><ul><li>What does the product look like at launch, year 1, year 2, etc?</li><li>How will you get customers (marketing/distribution)? How much will it cost?</li><li>What are the sources of revenue?</li><li>WhatÃ¢â‚¬â„¢s the expected lifetime value of a customer?</li><li>How will you retain customers long term to boost lifetime value?</li><li>Where is the break-even point (cost) of this business?</li><li>Where is the break-even point (time) of this business?</li><li>How do you solve the challenges you identified in the research phase?</li><li>What initial investment is required to get this off the ground?</li><li>How much time will it take to get this off the ground?</li><li>What investment is required over the next 3-5 years?</li><li>WhatÃ¢â‚¬â„¢s the optimal funding source?</li><li>What partnership(s) will you need?</li><li>What type of infrastructure will this company need?</li><li>What team is needed to build and grow this business?</li><li>What advisors could you reach out to for help?</li></ul><p>In addition to answering the questions above, our Concept Evaluations also include a product roadmap/gantt chart, financial model, and start-up checklist.<strong><br></strong></p><h3><strong>Product Roadmap</strong></h3><p>The product roadmap and corresponding gantt chart provide a simple, but tangible way to look at the different work streams that will be a part of each phase of the business. The key here is to plan out dependencies, so you can parallel process and avoid bottlenecks.</p><p>You wonÃ¢â‚¬â„¢t be able to do everything on day one. The important question to ask yourself during this planning stage is: what is the Minimum Viable Product (MVP) that you can launch with and how do you build on that MVP post launch? We are believers in launching as soon as possible to collect real customer feedback and use that to evolve the product along the way. <strong><br></strong></p><h3><strong>Financial Model</strong></h3><p>Our financial model is built using assumptions we find on our own, or inputs from industry experts. While this model is likely to change in the real world, we want to keep a close eye on the economics and the break even point. This is used to forecast the growth plan, timing, and investment level required. </p><p>Funding is a separate topic on its own and there is no universal best practice to finance a business. As an entrepreneur, you will need to look at a number of factors, including your personal situation, business cash requirements, and long term plan. ItÃ¢â‚¬â„¢s worth spending time with advisors or mentors to discuss the best funding option for your situation. <strong><br></strong></p><h3><strong>Startup Checklist</strong></h3><p>We love checklists and have a checklist for everything. Checklists ensure consistency and completeness in carrying out a task. Checklists also allow you to frontload all the planning so you can focus on executing at the next stage. For our startup checklist, we include everything required to get from day zero to launch day. This includes corporate structuring and entity formation; legal and accounting prep; compliance, hiring, product building; distribution and marketing; operations, partnerships, and business development. We are extremely thorough and write out every critical task, corresponding notes, status, and owner.</p><p>Before moving on to the next stage you should ask yourself, <em>Ã¢â‚¬Å“Do I want to spend the next 5+ years of my life building this business?Ã¢â‚¬ï¿½ </em></p><p>More often than not, entrepreneurship is not a way to get rich quickly. You will likely need to work harder and longer, with higher stress and more at stake than working a regular day job. The journey is absolutely worth it for the right person, but itÃ¢â‚¬â„¢s important that you go into it knowing what to expect. Many companies die early due to missed expectations on what it takes to start a company. If possible, you can start out part-time and build traction before diving in full-time. </p><p>If you want to dedicate years of your life solving this problem, and building a business along the way, then move on to the execute phase.</p></div><h2>Step 3: Execute</h2><div><p>Every single person has ideas, but very few take the jump and start a company. The execution stage is where you leave the planning stage and take that jump. You have spent time researching, putting together a plan, and you are now ready to dedicate time to building a business.</p><p>Depending on the type of business, this stage will look very different. In all cases, this stage involves working through your plan, roadmap, and startup checklist to begin getting your idea off the ground. </p><p>The primary focus of this stage is prioritization. Prioritizing often will allow you to manage bottlenecks and work in parallel across different areas of your business. The goal is to align your input (time &amp; money) with the activities that will yield the highest output (progress on your plan). This is easier said than done, but it is absolutely critical to execute your plan in an efficient way.</p><p>If you need to raise money or get funding, this is the stage where that could happen. This is also the stage where you may need to start building your team by hiring contractors or employees. </p></div><h2>Step 4: Adapt</h2><div><p>Roughly 90% of businesses fail, and this is the stage where that usually happens. One thingÃ¢â‚¬â„¢s for certain in starting a business: you will never be able to create and follow a bulletproof plan. As your business takes off, youÃ¢â‚¬â„¢ll need to constantly adapt and change your plan. The best entrepreneurs are comfortable being uncomfortable, adapting as they go.</p><p>The optimal Ã¢â‚¬Å“go liveÃ¢â‚¬ï¿½ point will vary by business. At Wilbur Labs, we strongly believe that getting customers to vote for products and services with their wallet or with their time is by far the best measure of product-market fit. If customers wonÃ¢â‚¬â„¢t spend time or money on your â€¦</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.wilburlabs.com/blueprints/how-to-turn-an-idea-into-a-business">https://www.wilburlabs.com/blueprints/how-to-turn-an-idea-into-a-business</a></em></p>]]>
            </description>
            <link>https://www.wilburlabs.com/blueprints/how-to-turn-an-idea-into-a-business</link>
            <guid isPermaLink="false">hacker-news-small-sites-26183057</guid>
            <pubDate>Thu, 18 Feb 2021 17:50:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Open Terms Archive: Terms and Conditions of popular services tracked on GitHub]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 1 (<a href="https://news.ycombinator.com/item?id=26182878">thread link</a>) | @sirffuzzylogik
<br/>
February 18, 2021 | https://disinfo.quaidorsay.fr/en/open-terms-archive | <a href="https://web.archive.org/web/*/https://disinfo.quaidorsay.fr/en/open-terms-archive">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
			<div class="page">
				<div>
					

<nav>
	<ol itemscope="" itemtype="https://schema.org/BreadcrumbList">
		<li itemprop="itemListElement" itemscope="" itemtype="https://schema.org/ListItem">	
			<a href="https://disinfo.quaidorsay.fr/en" itemprop="item">Home</a>
			
		</li>

		
			<li itemprop="itemListElement" itemscope="" itemtype="https://schema.org/ListItem">	
				<a href="https://disinfo.quaidorsay.fr/en/our-tools" itemprop="item">Our tools</a>
				
			</li>
		
		
		<li itemprop="itemListElement" itemscope="" itemtype="https://schema.org/ListItem">
			Open Terms Archive
		</li>
	</ol>
</nav>

<p><img src="https://disinfo.quaidorsay.fr/assets/img/open-terms-archive/thumb.jpg" alt=""></p>

<p>Services have terms that can change over time. Open Terms Archive enables users rights advocates, regulatory bodies and any interested citizen to <strong>follow the changes to these terms</strong>.</p>

<h3 id="follow-the-changes-to-the-terms-of-service">Follow the changes to the Terms of Service</h3>

<p>Services are declared within Open Terms Archive with a declaration file listing all the documents that, together, constitute <strong>the terms under which this service can be used</strong>. These documents all have a type, such as â€œterms and conditionsâ€, â€œprivacy policyâ€, â€œdeveloper agreementâ€.</p>

<p>The practices described regarding information manipulation can lead to a <strong>better understanding of the vulnerabilities</strong> of these actors and the transcription of legislative constraints, recommendations from public authorities or voluntary measures implemented enables us to <strong>appreciate their loyalty</strong>.</p>

<h3 id="case-studies">Case studies</h3>

<ul>
  <li>Google has changed its Review Guidelines to prohibit apps that hat mislead users by impersonating someone else or another app or falsely imply a relationship to another company / developer. These measures thus close certain vulnerabilities exploited for information manipulation. <a href="https://github.com/ambanum/CGUs-versions/commit/98f6c">See the change</a>.</li>
</ul>

<p><img src="https://disinfo.quaidorsay.fr/assets/img/open-terms-archive/google-case-studie.png" alt=""></p>

<ul>
  <li>TikTok refers to Comminuty Guidelines to offer its users the opportunity to report content that would be considered inappropriate. <a href="https://github.com/ambanum/CGUs-versions/commit/0d2f0386">See the change</a>.</li>
</ul>

<p><img src="https://disinfo.quaidorsay.fr/assets/img/open-terms-archive/tiktok-case-studie.png" alt=""></p>

<ul>
  <li>Google AdSense has changed its Acceptable Use Policy to add a reference to Coordinated Deceptive Practices to prohibit (i) practices that seek to coordinate with other sites or accounts and concealing or misrepresenting identity or other material details, when content relates to politics, social issues or matters of public concern and (ii) directe content about politics, social issues, or matters of public concern to users in a country other than oneâ€™s own, if you misrepresent or conceal oneâ€™s country of origin or other material details. <a href="https://github.com/ambanum/CGUs-versions/commit/c62b7">See the change</a>.</li>
</ul>

<p><img src="https://disinfo.quaidorsay.fr/assets/img/open-terms-archive/google-case-studie.png" alt=""></p>

<p><a href="https://github.com/ambanum/CGUs/wiki/%C3%89tudes-de-cas">Discover more case studies</a></p>

<h2 id="how-it-works">How it works</h2>

<p><em>Words in bold are <a href="https://en.wikipedia.org/wiki/Domain-driven_design">business domain names</a>.</em></p>

<p><strong>Services</strong> are <strong>declared</strong> within <em>Open Terms Archive</em> with a <strong>declaration file</strong> listing all the <strong>documents</strong> that, together, constitute the <strong>terms</strong> under which this <strong>service</strong> can be used. These <strong>documents</strong> all have a <strong>type</strong>, such as â€œterms and conditionsâ€, â€œprivacy policyâ€, â€œdeveloper agreementâ€â€¦</p>

<p>In order to track their <strong>changes</strong>, <strong>documents</strong> are periodically obtained by fetching a web location and selecting content within the web page to remove the noise (ads, navigation menu, login fieldsâ€¦).</p>

<p>Anyone can run their own private instance and track changes on their own. However, we also publish each version on a <a href="https://github.com/ambanum/CGUs-versions"><strong>public</strong> instance</a> that makes it easy to explore the entire history and enables notifying over email whenever a new version is recorded.
Users can <a href="#be-notified"><strong>subscribe</strong> to <strong>notifications</strong></a>.</p>

<p><em>For now, when multiple versions coexist, <strong>terms</strong> are only <strong>tracked</strong> in their English version and for the European jurisdiction.</em></p>

<h3 id="exploring-the-versions-history">Exploring the versions history</h3>

<p>From the <strong>repository homepage</strong> <a href="https://github.com/ambanum/CGUs-versions">CGUs-versions</a>, open the folder of the service of your choice. You will see the set of documents tracked for that service, now click on the document of your choice. The latest version (updated hourly) will be displayed.</p>

<p><em>For more details, see our <a href="https://github.com/ambanum/CGUs#exploring-the-versions-history">wiki</a></em>.</p>

<h3 id="be-notified">Be notified</h3>

<p>You can <a href="https://59692a77.sibforms.com/serve/MUIEAKuTv3y67e27PkjAiw7UkHCn0qVrcD188cQb-ofHVBGpvdUWQ6EraZ5AIb6vJqz3L8LDvYhEzPb2SE6eGWP35zXrpwEFVJCpGuER9DKPBUrifKScpF_ENMqwE_OiOZ3FdCV2ra-TXQNxB2sTEL13Zj8HU7U0vbbeF7TnbFiW8gGbcOa5liqmMvw_rghnEB2htMQRCk6A3eyj">subscribe</a> to receive an email whenever a document is updated in the database.</p>

<p><strong>Beware, this service is in beta and you are likely to receive a large amount of notifications!</strong> You can unsubscribe by replying to any email you will receive.</p>

<p><em>For more details, see our <a href="https://github.com/ambanum/CGUs#be-notified">wiki</a></em>.</p>

<h2 id="scripta-manent">Scripta Manent</h2>

<p>Scripta Manent lists 637 Terms of Services (in French, Conditions GÃ©nÃ©rales dâ€™Utilisation or CGU) and legal documents coming from 174 digital service providers and gives simple tools to compare changes between two dates of your choice.</p>

<p><a href="https://disinfo.quaidorsay.fr/en/open-terms-archive/scripta-manent">Compare</a></p>

<h2 id="experiments">Experiments</h2>

<p>Experiments are ongoing so as to produce use cases using Open Terms Archive data.</p>

<p><a href="https://disinfo.quaidorsay.fr/en/open-terms-archive/experiments">See ours experiments</a></p>

<h2 id="api">API</h2>

<p>An API endpoint to find specific terms in the Open Terms Archive dataset is available.</p>

<p><a href="https://disinfo.quaidorsay.fr/api/open-terms-archive/">Access the API</a></p>

<h2 id="contributing">Contributing</h2>

<p>The tool is built as an <strong>open source and collaborative software</strong>, which means that everyone can contribute to its improvement and to the addition of documents and service providers to be tracked.</p>

<ul>
  <li>
    <p>Terms of Service Didnâ€™t Read (ToSDR)
The association Terms of Service Didnâ€™t Read (ToSDR) had developed a similar tool, <a href="https://tosback.org/">TOSBack</a> and thus transferred its resources and documents followed for several years to our tool.</p>
  </li>
  <li>
    <p>Direction GÃ©nÃ©rale des Entreprises<br>
The Direction GÃ©nÃ©rale des Entreprises (DGE), through the Digital Regulation Expertise Center (PEReN), contributes to the tool by developing new functionalities, such as tracking images and documents in PDF format.</p>
  </li>
</ul>

<div>
	<h3>Help us to improve Open Terms Archive</h3>
	<p>You can add service providers or documents that you would like to follow or suggest ways to add value to the case studies.</p>
	<p><a href="https://github.com/ambanum/CGUs">Contribute</a>
</p></div>

				</div>
			</div>
		</div></div>]]>
            </description>
            <link>https://disinfo.quaidorsay.fr/en/open-terms-archive</link>
            <guid isPermaLink="false">hacker-news-small-sites-26182878</guid>
            <pubDate>Thu, 18 Feb 2021 17:37:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Ruby Garbage Collection Deep Dive: Tri-Color Mark and Sweep]]>
            </title>
            <description>
<![CDATA[
Score 132 | Comments 15 (<a href="https://news.ycombinator.com/item?id=26182796">thread link</a>) | @mooreds
<br/>
February 18, 2021 | https://jemma.dev/blog/gc-mark-and-sweep | <a href="https://web.archive.org/web/*/https://jemma.dev/blog/gc-mark-and-sweep">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p>In the <a href="https://jemma.dev/blog/gc-internal">first post</a> in the Ruby Garbage Collection Deep Dive series, we went through a few definitions to give us a picture of how Ruby stores values in memory. If you havenâ€™t read it yet, <a href="https://jemma.dev/blog/gc-internal">read it first</a>! Weâ€™ll build on those definitions in this post. Particularly, weâ€™ll talk more about the Ruby Heap, Pages, Slots and RVALUES.</p>

<p>Okay, now that we have those baseline definitions out of the way, this post is going to explain the algorithm Rubyâ€™s garbage collector uses to determine which objects it can collect: the Tri-Color Mark and Sweep algorithm. There are two phases to this algorithm. You guessed it: marking and sweeping. In the marking phase, the garbage collector marks all slots which contain accessible RVALUES. In the sweeping phase, the garbage collector clears the RVALUES out of all slots which are not marked. Letâ€™s dig in!</p>

<h2 id="tri-color-mark-and-sweep">Tri-Color Mark and Sweep</h2>

<h3 id="marking">Marking</h3>

<p>Weâ€™ll start off by discussing the marking phase. This is most straightforward to understand if we imagine the <a href="https://ruby-doc.org/core-3.0.0/ObjectSpace.html">Ruby ObjectSpace</a> to be a directed graph with root nodes. All of the nodes in the graphs are RVALUES. All of the edges in the graph are references from one RVALUE to another.</p>

<p>Rubyâ€™s garbage collector starts at the root nodes and traces every edge it can access from these root nodes, marking every RVALUE it sees through this process. At the end, any RVALUE which was not traced, and therefore not accessible from a root RVALUE will be garbage collected.</p>

<h4 id="tri-color">Tri-Color</h4>

<p>Okay, but the algorithm Ruby uses for garbage collection is called a Tri-Color Mark and Sweep algorithm, so whatâ€™s the Tri-Color part all about? The Tri-Color algorithm is a model we can use to understand what Rubyâ€™s garbage collector is doing, and how tracks its progress. The three colors in the Tri-Color algorithm (three shades, really) are white, black and grey.</p>

<p>At the beginning of garbage collection, every slot in the Ruby Heap is white. Then, as part of the initial setup, all slots which contain root RVALUEs are marked as grey.</p>

<p>Root RVALUES are all of the RVALUES that a Ruby program knows it will need to run. Examples of these are RVALUES that exist on the stack of instructions that the program is following, or protected global variables.</p>

<p>With all root slots grey, and all other slots white, we then get to the crux of the algorithm:</p>

<div><div><pre><code><span>while</span> <span>(</span><span>!</span><span>grey_slots</span><span>.</span><span>empty?</span><span>)</span>
  <span>current_slot</span> <span>=</span> <span>grey_slots</span><span>.</span><span>pop</span>
  <span>grey_slots</span> <span>+=</span> <span>current_slot</span><span>.</span><span>referenced_slots</span>
  <span>black_slots</span> <span>&lt;&lt;</span> <span>current_slot</span>
<span>end</span>
</code></pre></div></div>

<p>We iterate over all grey slots, coloring the slots that their RVALUES reference grey, and coloring themselves black. The algorithm continues until there are no grey slots left. At this point, any black slots contain RVALUES which were reachable by the RVALUEs in the root slots, and any white slots do not contain RVALUES which were reachable so can be swept away!</p>

<p>For the visual learners, hereâ€™s a gif of what the algorithm is doing:</p>

<p><img src="https://jemma.dev/assets/mark.gif" alt="mark-gif"></p>

<h4 id="references">References</h4>

<p>There is one detail which needs further explanation here: how does an RVALUE know which other RVALUES it references?</p>

<p>It depends on the type of object. For Ruby builtins, tracing the references are just baked into the garbage collector code itself. For example, to find all references from an array RVALUE, the collector iterates each element in the array and finds its references. For a hash, it will do this for both the keys and the values. This all happens in the garbage collectorâ€™s <a href="https://github.com/ruby/ruby/blob/296a2cab07ce530809ee74dee61180fbb3ca6f91/gc.c#L6269"><code>mark_children</code></a> method.</p>

<p>But, when objects are defined by C extensions, the C extensions must mark all child objects on their own. Weâ€™ll dive more into this in a future C extensions post (which Iâ€™ll backlink here).</p>

<p>Okay, so now that we understand how we find all accessbile objects, we need to learn how to dispose of all unaccessible objects.</p>

<h3 id="sweeping">Sweeping</h3>

<p>At this point, we have two sets: black slots and white slots. Internally, these are represented as a <code>marked</code> bitmap. Every Page on the Ruby Heap has its own <code>marked</code> bitmap with one bit per slot. A <code>1</code> bit means the slot is accessible, or Black in our Tri-Color scheme. A <code>0</code> bit means that the slot is no longer accessible, or White in our Tri-Color scheme.</p>

<p>In addition to holding this <code>marked</code> bitmap, each page also has a <code>freelist</code> which represents slots on that page which do not have live objects. The garbage collector iterates over all pages, finding all slots which are not marked. Where applicable, the garbage collector then adds the unmarked slots to each pageâ€™s freelist. If the RVALUES which were occupying these slots are also taking up space in the operating system heap, it also frees this memory.</p>

<p>Once pages have been swept, there might be pages which are now completely unallocated; they have no slots which contain RVALUES. These pages are referred to as â€œTomb Pages.â€ Tomb pages have their memory completely returned to the operating systemâ€™s heap. This is really helpful for memory management. It means that sweeping can result in freeing memory, or diminishing the overall size of the Ruby Heap.</p>

<p>Any pages with at least one occupied slot are called â€œEden Pagesâ€. The sweeping phase might reduce the number of occupied slots in an Eden Page. The garbage collector will use the freelists from Eden Pages for future object allocations. That is to say, if you instantiate an object, the garbage collector will look for one of these free slots in an Eden Page and place the RVALUE representing your object in there.</p>

<p><img src="https://jemma.dev/assets/eden-and-tomb.png" alt="eden-and-tomb"></p>

<p>There is one more nuance here. As of Ruby 3.0, if auto-compaction is enabled, compaction will actually happen as part of the sweeping phase. A more in depth explanation of how and why this happens will follow in a later post about compaction in this Garbage Collection Deep Dive Series.</p>

<h3 id="tldr">TL;DR</h3>

<p>The Tri-Color mark and sweep algorithm is what Rubyâ€™s garbage collector uses to determine which slots hold objects which no longer have accessible references. It marks all of the slots it has references to by following the Tri-Color algorithm in which it follows all references from root RVALUES. Once the garbage collector knows which objects are accessible from the roots, it can begin the sweep phase, where it will add the unoccupied slots to each pageâ€™s freelist, and release any operating system memory those RVALUES held. This enables the slots to be reused for new object allocation.</p>

<p>Here are a few new definitions we learned:</p>

<ul>
  <li><strong>Eden page</strong>: A page which contains slots with RVALUES, might also have empty slots</li>
  <li><strong>Tomb page</strong>: A page which contains only empty slots</li>
  <li><strong>Free list</strong>: A linked list per Heap Page of empty slots</li>
</ul>

<p>And thatâ€™s it for this post! Iâ€™m going to continue writing blog posts in this series, and am also writing a book about managed garbage collection, with a focus on Ruby. If this interests you, join the newsletter below or follow me <a href="https://twitter.com/jemmaissroff">on twitter</a> for updates!</p>


  </div>
</article>

      </div>
    </div></div>]]>
            </description>
            <link>https://jemma.dev/blog/gc-mark-and-sweep</link>
            <guid isPermaLink="false">hacker-news-small-sites-26182796</guid>
            <pubDate>Thu, 18 Feb 2021 17:32:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[SSH Certificates Security]]>
            </title>
            <description>
<![CDATA[
Score 9 | Comments 1 (<a href="https://news.ycombinator.com/item?id=26181568">thread link</a>) | @alexk
<br/>
February 18, 2021 | https://goteleport.com/blog/ssh-certificates | <a href="https://web.archive.org/web/*/https://goteleport.com/blog/ssh-certificates">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
      
      <a href="https://goteleport.com/blog/index.xml"><i></i></a>
      
      

        

<p><img src="https://goteleport.com/blog/images/2021/ssh-certs-security.png" width="100%" alt="SSH Certificates Security"></p>

<h2 id="ssh-access-hardening">SSH Access Hardening</h2>

<p>SSH certificates, when deployed properly, improve security.
A half-baked access system using certs is more vulnerable than a public-key-based one if a user or host gets hacked.</p>

<p>SSH is hard. Our team learned this at Rackspace, a large managed hosting and cloud provider.
We started with deploying public keys to every server. We added a jump server with a second factor login to prevent
hacks using stolen keys. Soon, infosec team asked us to log into a web portal to match SSH logins with emails.
Evolution does not produce the most efficient result, and our system did not turn out great either.
We were missing keys on some servers and found stale keys on others.
No one liked login screens popping up multiple times a day.
We received only one one-time password token, and some folks pointed their home webcam to it.</p>

<p>In 2015 we left Rackspace to build <a href="https://github.com/gravitational/teleport" data-size="large" aria-label="Star gravitational/teleport on GitHub">Teleport</a> â€” a unified access plane
for infrastructure, and we started with SSH. We chose SSH certificates as the main cryptography engineering primitive. Since then our customers and open source users have deployed Teleport at most impressive systems, and Teleport went through
several security audits.</p>

<p>I would like to share some of the lessons we learned with you.
We will start with the SSH authentication basics, dig into SSH certificates
and learn what it takes to build a secure SSH certificate-based authentication.</p>

<h3 id="ssh-public-key-authentication">SSH Public Key Authentication</h3>

<p>An SSH public key is distributed openly, and anyone holding it can verify messages
signed using its private key counterpart.</p>

<p><img src="https://goteleport.com/blog/images/2021/ssh-certs-public-key-auth.png" width="100%" alt="SSH Public Key Authentication"></p>

<p>An SSH server generates a random string â€” a challenge â€” and asks a client to sign it.
The server verifies clientsâ€™ signature to prove that the client has the private key associated with
the trusted public key. Here is how it looks on the wire:</p>

<p><img src="https://goteleport.com/blog/images/2021/ssh-certs-public-key-protocol.png" width="100%" alt="SSH Public Key Challenge"></p>

<p>Public keys constitute a solid way to authenticate and are used to secure both Web and SSH.</p>

<p>The problems with public key authentication are caused by key management: trust on first use (a.k.a. TOFU)
and rotating and revoking trusted public keys.</p>

<h3 id="trust-on-first-use">Trust On First Use</h3>

<p>When an SSH connection is first established, an SSH server sends its public key to identify
itself to a user.</p>

<p><img src="https://goteleport.com/blog/images/2021/ssh-certs-host-auth.png" width="100%" alt="SSH Host Authentication"></p>

<p>The user can accept the public key offered by the SSH server and assume that the host is trusted
if the user connects to it first time. This authentication scheme is called â€œtrust on first useâ€ or TOFU.</p>

<p>If the hostâ€™s IP, name or public key change, the user can no longer trust this combination
of the hostname, the IP and the public key.</p>

<p>The user sees a scary warning.</p>

<p><img src="https://goteleport.com/blog/images/2021/ssh-certs-tofu.png" width="100%" alt="SSH TOFU"></p>

<p>The user can alert security folks or ignore the warning by removing the old key.
For cloud environments, however, an IP address and a hostname can be
reused many times. Users learn to ignore those warnings, because there is no way to learn whether itâ€™s an attack or an IP or a hostname change. Letâ€™s call it TOFU fatigue.</p>

<h3 id="problems-with-public-keys">Problems With Public Keys</h3>

<p>A second problem of public keys for security is caused by complexities of public key distribution.
Imagine a deployment with 100 servers and 10 users, where every user has 2 public keys.
You have to build a system that distributes 20 userâ€™s public keys on each server and
100 public keys to every userâ€™s computer, and keep those up to date.</p>

<p>Directory services like LDAP are used to store userâ€™s and hostâ€™s public keys.
Every host runs an agent that connects to an LDAP server and updates public keys.
Sysadmin folks have been deploying this Keycloak and FreeIPA pair for years.</p>

<p>This system breaks down at a small and a large scale. Sysadmins of small systems
rarely deploy key management software. Itâ€™s not worth setting up FreeIPA and Keycloak for 3 nodes.
They use tools like Ansible and end up with keys going out of sync when someone loses their key, computer, or leaves the company. Sometimes, letâ€™s face it, there is no Ansible and everyone uses the same shared key.</p>

<p>Admins of large clusters learn that the system of moving the key around stops working beyond the 1K nodes or 100 users mark â€”
there are just too many keys to keep track of.</p>

<h2 id="ssh-certificates">SSH Certificates</h2>

<p>SSH certificates are built using public keys and donâ€™t offer anything extra from a cryptography engineering standpoint.</p>

<p>A certificate authority (CA) is a trusted party that holds its own public and private key pair.
SSH CA keys are used to sign user and host SSH certificates.
An SSH certificate consists of fields signed by the certificate authority.</p>

<p><img src="https://goteleport.com/blog/images/2021/ssh-certs-certificate.png" width="100%" alt="SSH Certificate"></p>

<p>Clients cannot modify these fields without breaking the signature.</p>

<p>SSH certificate authentication extends public-key-based auth and uses the same protocol messages.
In addition to verifying the public key signature, SSH server will check whether
the certificate is signed by the trusted certificate authority.</p>

<h3 id="solving-the-tofu-problem">Solving the TOFU Problem</h3>

<p>Clients use metadata in SSH certificates to verify host identities too.
When an SSH connection is established, a host sends a signed SSH certificate to a client to verify
the hostâ€™s identity. The hostâ€™s certificate is signed by a trusted CA.
It includes information about the hostname, and has an expiration date.
Here Alice checks if she can trust the hostâ€™s cert:</p>

<p><img src="https://goteleport.com/blog/images/2021/ssh-certs-host-certs.png" width="100%" alt="SSH Host Certificates"></p>

<p>As an extra precaution, SSH clients check if the hostname or the IP matches the certificate.
It makes it harder for a malicious host to impersonate another host.
If the signature check has failed or the CA is not trusted, either a serious misconfiguration
has happened or someone is attempting a man-in-the-middle attack.</p>

<p>Even if the public key of the host has been changed because the hostname has been reused in a cloud environment
during instance re-provisioning, the certificate will still match; there will be no conflict between different
public keys.</p>

<p>Sysadmins can replace the complex system of moving hundreds of public keys around
with two files â€” a host and a user SSH certificatesâ€™ authority public keys.
But in practice if we had stopped at this point, we would have made SSH security much, much worse.</p>

<h3 id="compromised-users-and-hosts">Compromised Users and Hosts</h3>

<p>If a user or a host gets compromised, we have to revoke their certs.
We are back to building a system of keeping track and distributing revocation lists to users and hosts.
Even worse, if a private key of a SSH user or a host certificate authority gets compromised,
all users and hosts certificates have to be invalidated and reissued.</p>

<p>This realization hits at the worst possible moment â€” when someone is hacked, there is no time to waste.
Time works against us because with every issued cert, the potential for compromise
increases. At least with public keys, we test the rotation on a regular basis. Revocation is so rare,
that it could be broken for all this time and no one would notice. This problem reminds me of backup restore â€”
you either test backup and restore regularly, or all bets are off.</p>

<h2 id="making-time-work-for-you">Making Time Work for You</h2>

<p>There is one trick that makes time work in favor of security.
SSH certificates include an optional expiry date that can be verified
by a server in addition to a signature.</p>

<p><img src="https://goteleport.com/blog/images/2021/ssh-certs-short-lived.png" width="100%" alt="SSH Short Lived Certs"></p>

<p>Organizations ca issue certificates that are good for a few hours before they auto-expire
without any action. The shorter the duration for these certificates, the better.
Ideally, certs should be issued only for the duration of a session.
In practice, several hours or the duration of the workday are OK too.</p>

<p>Instead of distributing revocation lists, we can rely on time to do the job for us.</p>

<h3 id="user-certificates-and-sso">User Certificates and SSO</h3>

<p>How would users get a short-lived certificate? The best way is to use SSO
with GitHub, Okta or any other identity provider and get a cert.
Teleport opens login screen, issues a cert and delivers it back to a userâ€™s computer:</p>

<p><img src="https://goteleport.com/blog/images/2021/ssh-certs-sso.png" width="100%" alt="SSH certs SSO"></p>

<p>Here is an example of Teleportâ€™s CLI tool <code>tsh</code> issuing a certificate
based on my GitHub credentials.</p>

<video autoplay="" loop="" muted="" playsinline="">
  <source src="https://goteleport.com/blog/images/2021/ssh-certs-github.mp4" type="video/mp4">
  <source src="https://goteleport.com/blog/images/2021/ssh-certs-github.webm" type="video/webm">
Your browser does not support the video tag.
</video>

<p>The cert is valid for 12 hours and has my GitHub identity encoded in it.</p>

<h2 id="rotate-ca-keys">Rotate CA Keys</h2>

<p>An attacker getting access to a private key of a certificate authority can impersonate
any user or host. Thatâ€™s why admins store CA private keys in the most secure place possible.
What happens if a user, a host, or a CA gets compromised? Youâ€™d need to replace certificate authority
and reissue all certs for hosts and users. Any system dealing with certs should support this out of the box.</p>

<p>Take a look at how I rotate a user CA in less than a minute with Teleport:</p>

<video autoplay="" loop="" muted="" playsinline="">
  <source src="https://goteleport.com/blog/images/2021/ssh-certs-rotation.mp4" type="video/mp4">
  <source src="https://goteleport.com/blog/images/2021/ssh-certs-rotation.webm" type="video/webm">
Your browser does not support the video tag.
</video>

<p>With user certificate authority updated, all certificates issued by the old CA become invalid.
Itâ€™s not a problem if you use SSO; users have to re-login to get new certs.
The same command rotates hosts CA as well. Instead of waiting for the compromise
to happen, we should be rotating certificate authorities every day turning
them from a precious secret to a replaceable commodity. Here again, time
will work in our favor, not against us.</p>

<h2 id="wrapping-up">Wrapping Up</h2>

<p>Use certs with caution, and beware of long-lived certificates. Rotate your CA regularly
and use SSO to get user certs. And maybe, give <a href="https://github.com/gravitational/teleport" data-size="large" aria-label="Star gravitational/teleport on GitHub">Teleport</a> a try.</p>


        
        
        <p><strong>Related Posts</strong></p>
          <ul>
            
            <li><a href="https://goteleport.com/blog/how-to-ssh-properly/">How to SSH Properly | SSH Security Best Practices</a></li>
            
            <li><a href="https://goteleport.com/blog/ssh-handshake-explained/">SSH Handshake Explained | What is SSH Handshake?</a></li>
            
            <li><a href="https://goteleport.com/blog/ssh-restricted-shells/">Restricted Shell | Restricted commands for SSH</a></li>
            
          </ul>
        

        
        
        <a href="https://goteleport.com/tags/ssh/">ssh</a>
        
        <a href="https://goteleport.com/tags/teleport/">teleport</a>
        
        <a href="https://goteleport.com/tags/security/">security</a>
        

      
      
      &nbsp;
      </article></div>]]>
            </description>
            <link>https://goteleport.com/blog/ssh-certificates</link>
            <guid isPermaLink="false">hacker-news-small-sites-26181568</guid>
            <pubDate>Thu, 18 Feb 2021 16:09:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Coq 8.13]]>
            </title>
            <description>
<![CDATA[
Score 113 | Comments 38 (<a href="https://news.ycombinator.com/item?id=26180078">thread link</a>) | @infruset
<br/>
February 18, 2021 | https://coq.inria.fr/news/coq-8-13-0-is-out.html | <a href="https://web.archive.org/web/*/https://coq.inria.fr/news/coq-8-13-0-is-out.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>





<p>
The Coq development team is proud to announce the immediate availability of
<a href="https://github.com/coq/coq/releases/tag/V8.13.0">Coq 8.13.0</a>
</p>

<p>
Highlights:
</p><ul>
<li>Introduction of primitive persistent arrays in the core language, implemented using imperative persistent arrays. </li>
<li>Introduction of definitional proof irrelevance for the equality type defined in the SProp sort. </li>
<li>Many improvements to the handling of notations, including number notations, recursive notations and notations with bindings. A new algorithm chooses the most precise notation available to print an expression, which might introduce changes in printing behavior.</li>
</ul>



<p>Please see <a href="https://coq.github.io/doc/v8.13/refman/changes.html#version-8-13" rel="nofollow">the changelog</a> to learn more about this release.</p>




</div></div>]]>
            </description>
            <link>https://coq.inria.fr/news/coq-8-13-0-is-out.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26180078</guid>
            <pubDate>Thu, 18 Feb 2021 14:23:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Browsers eating RAM]]>
            </title>
            <description>
<![CDATA[
Score 131 | Comments 134 (<a href="https://news.ycombinator.com/item?id=26179817">thread link</a>) | @todsacerdoti
<br/>
February 18, 2021 | https://www.flotato.com/post/memory-chrome-safari-flotato | <a href="https://web.archive.org/web/*/https://www.flotato.com/post/memory-chrome-safari-flotato">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>I reached a point where I could barely hear the podcast I was trying to listen to. That's how loud the fan was. Then I&nbsp;closed down all open Chrome windows, and a few minutes after, the fan went silent. So I decided to see if it was just me.</p><div href=""><h3>How I&nbsp;measured</h3><p>I&nbsp;ran the 2-tab test in a completely fresh macOS install on a virtual machine. Then I ran the 54-tabs test on my own Big Sur installation, but with all extensions disabled. To record a usage snapshot ~250 times per second, I&nbsp;used <a href="https://github.com/astrofrog/psrecord">psrecord.</a></p></div><div><h2>2&nbsp;tabs:&nbsp;Twitter, then Gmail</h2><p>To simulate a realistic environment, I&nbsp;did the same steps on Safari, then Chrome:&nbsp;Go to twitter.com, scroll around, then open a new tab with Gmail and open an email. A dot means I interacted with the system. You can hover a dot to see what I&nbsp;did. </p></div><div><h3>Putting Flotato to the test</h3><p>To be light-weight, Flotato doesn't just run a stripped down, Safari-backed web view, it also defaults to the mobile version if one is available. Here's Flotato compared to a regular session in Safari. Note the slightly lower CPU usage. It's kind of hard to put a finger on what exactly the mobile version isn't calculating that the desktop version is; the two versions are almost identical when you use them.</p></div><div><h2>54 tabs:&nbsp;the stress test</h2><p>I&nbsp;bet you have more than 2 tabs open right now, I&nbsp;sure have more. So here's a stress test where I&nbsp;open 54 tabs while measuring the impact on my Mac's RAM and CPU. A dot means I&nbsp;opened a new tab. Hover the dot to see which site I&nbsp;opened.</p></div><div><h2>Is it bad?</h2><p>When I saw the results I got suspicious. Chrome was using way more memory than I thought it would. Maybe it was the virtual machine blocking Chrome's direct access to my Macbook's* GPU?&nbsp;I&nbsp;decided to run the next test, the one with 54 tabs directly on my own Big Sur installation. The results were, well, slightly worse.</p><h3>The graphs don't tell the full story</h3><p>But it's probably not as bad as it looks. It's not a terrible thing that an app actually <em>uses</em> your computer. And you've got to hand it to Chrome:&nbsp;it is fast! </p><p>I'm sure Chrome is going out of its way to manage its memory usage across tabs, keeping the current tab fast and responsive. That's great if you're not running any other macOS apps than Chrome, effectively using Chrome as your operating system, and macOS&nbsp;as a kind of bootloader. </p><p>But when you're using Sketch, Final Cut, Photoshop next to Chrome, that seems to be a problem. MacOS&nbsp;likely tries to tell Chrome to take it easy, and Chrome likely <em>does</em> take it easy. These graphs don't tell that story. </p><p>So no, it's most likely not as bad as it looks, but that doesn't change the fact since switching to Safari, I almost forgot what my fan sounds like.</p><p>And then there's <em>this</em> chart. As we can see, the two browsers heat up the computer almost to the exact same level - Safari even getting slightly warmer. This probably points to psutil not being able to see all Safari's child processes, but only the main ones â€” despite the fact that Activity Monitor is able to group them. That's a little confusing. </p><figure><p><img src="https://uploads-ssl.webflow.com/5e78c687e58e25134b3fb751/602feb36d1388bb94f881998_EumcL7jXYAEBG_4.png" alt="Image"></p></figure><p>â€</p><p>â€</p><p><em>*&nbsp;Macbook 16" from 2019 with2.4 GHz, 8-Core Intel Core i9 with 32&nbsp;GB&nbsp;2667 MHz DDR4 RAM and an AMD&nbsp;Radeon Pro 5500M 8GB GPU</em></p></div></div>]]>
            </description>
            <link>https://www.flotato.com/post/memory-chrome-safari-flotato</link>
            <guid isPermaLink="false">hacker-news-small-sites-26179817</guid>
            <pubDate>Thu, 18 Feb 2021 13:56:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Curl is C (2017)]]>
            </title>
            <description>
<![CDATA[
Score 81 | Comments 65 (<a href="https://news.ycombinator.com/item?id=26179601">thread link</a>) | @taf2
<br/>
February 18, 2021 | https://daniel.haxx.se/blog/2017/03/27/curl-is-c/ | <a href="https://web.archive.org/web/*/https://daniel.haxx.se/blog/2017/03/27/curl-is-c/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<p>For some reason, this post got picked up again and is <a href="https://news.ycombinator.com/item?id=26179601">debated today</a> in 2021, almost 4 years since I wrote it. Some things have changed in the mean time and I mightâ€™ve phrased a few things differently if I had written this today. But still, whatâ€™s here below is what I wrote back then. Enjoy!</p>



<div><figure><a href="https://daniel.haxx.se/blog/wp-content/uploads/2017/01/The_C_Programming_Language_cover.svg_.png"><img loading="lazy" width="348" height="450" src="https://daniel.haxx.se/blog/wp-content/uploads/2017/01/The_C_Programming_Language_cover.svg_-348x450.png" alt="" srcset="https://daniel.haxx.se/blog/wp-content/uploads/2017/01/The_C_Programming_Language_cover.svg_-348x450.png 348w, https://daniel.haxx.se/blog/wp-content/uploads/2017/01/The_C_Programming_Language_cover.svg_-155x200.png 155w, https://daniel.haxx.se/blog/wp-content/uploads/2017/01/The_C_Programming_Language_cover.svg_-768x992.png 768w, https://daniel.haxx.se/blog/wp-content/uploads/2017/01/The_C_Programming_Language_cover.svg_.png 792w" sizes="(max-width: 348px) 100vw, 348px"></a></figure></div>



<p>Every once in a while someone suggests to me that curl and libcurl would do better if rewritten in a â€œsafe languageâ€. Rust is one such alternative language commonly suggested. This happens especially often when we publish new security vulnerabilities. (Update: I think Rust is a fine language! This post and my stance here has nothing to do with what I think about Rust or other languages, safe or not.)</p>



<h2>curl is written in C</h2>



<p>The curl code guidelines mandate that we stick to using C89 for any code to be accepted into the repository. C89 (sometimes also called C90) â€“ the oldest possible ANSI C standard. Ancient and conservative.</p>



<h2>C is everywhere</h2>



<p>This fact has made it possible for projects, companies and people to adopt curl into things using basically any known operating system and whatever CPU architecture you can think of (at least if it was 32bit or larger). No other programming language is as widespread and easily available for <em>everything</em>. This has made curl one of the most portable projects out there and is part of the explanation for curlâ€™s success.</p>



<p>The curl project was also started in the 90s, even long before most of these alternative languages youâ€™d suggest, existed. Heck, for a truly stable project it wouldnâ€™t be responsible to go with a language that isnâ€™t even old enough to start school yet.</p>



<h2>Everyone knows C</h2>



<p>Perhaps not necessarily true anymore, but at least the knowledge of C is very widespread, where as the current existing alternative languages for sure have more narrow audiences or amount of people that master them.</p>



<h2>C is not a safe language</h2>



<p>Does writing safe code in C require more carefulness and more â€œtricksâ€ than writing the same code in a more modern language better designed to be â€œsafeâ€ ? Yes it does. But weâ€™ve done most of that job already and maintaining that level isnâ€™t as hard or troublesome.</p>



<p>We keep scanning the curl code regularly with static code analyzers (we maintain a <em>zero <a href="https://scan.coverity.com/projects/curl">Coverity</a> problems</em> policy) and we run the test suite with <a href="http://valgrind.org/">valgrind</a> and <a href="https://en.wikipedia.org/wiki/AddressSanitizer">address sanitizers</a>.</p>



<h2>C is not the primary reason for our past vulnerabilities</h2>



<p>There. The simple fact is that most of our past vulnerabilities happened because of logical mistakes in the code. Logical mistakes that arenâ€™t really language bound and they would not be fixed simply by changing language.</p>



<p>Of course that leaves a share of problems that couldâ€™ve been avoided if we used another language. Buffer overflows, double frees and out of boundary reads etc, but the bulk of our security problems has not happened due to curl being written in C.</p>



<h2>C is not a new dependency</h2>



<p>It is easy for projects to add a dependency on a library that is written in C since thatâ€™s what operating systems and system libraries are written in, still today in 2017. Thatâ€™s the default. Everyone can build and install such libraries and theyâ€™re used and people know how they work.</p>



<p>A library in another language will add that language (and compiler, and debugger and whatever dependencies a libcurl written in that language would need) as a new dependency to a large amount of projects that are themselves written in C or C++ today. Those projects would in many cases downright ignore and reject projects written in â€œan alternative languageâ€.</p>



<h2>curl sits in the boat</h2>



<p>In the curl project weâ€™re deliberately conservative and we stick to old standards, to remain a viable and reliable library for everyone. Right now and for the foreseeable future. Things that worked in curl 15 years ago still work like that today. The same way. Users can rely on curl. We stick around. We donâ€™t knee-jerk react to modern trends. We sit still in the boat. We donâ€™t rock it.</p>



<h2>Rewriting means adding heaps of bugs</h2>



<p>The plain fact, that also isnâ€™t really about languages but is about plain old software engineering: translating or rewriting curl into a new language will introduce a lot of bugs. Bugs that we donâ€™t have today.</p>



<p>Not to mention how rewriting would take a huge effort and a lot of time. That energy can instead today be spent on improving curl further.</p>



<h2>What if</h2>



<p><em>If I would start the project today, would Iâ€™ve picked another language?</em> Maybe. Maybe not. If memory safety and related issues was the primary concern I had, then sure. But as Iâ€™ve mentioned above there are several others concerns too so it would really depend on my priorities.</p>



<h2>Finally</h2>



<p>At the end of the day the question that remains is: would we gain more than we would pay, and over which time frame? Who would gain and who would lose?</p>



<p>Iâ€™m sure that there will be or it may even already exist, curl and libcurl competitors and potent alternatives written in most of these new alternative languages. Some of them are absolutely really good and will get used and reach fame and glory. Some of them will be crap. Just like software always work. Let a thousand curl competitors bloom!</p>



<p>Will curl be rewritten at some point in the future? I wonâ€™t rule it out, but I find it unlikely. I find it even more unlikely that it will happen in the short term or within the next few years.</p>



<p>Discuss this post on <a href="https://news.ycombinator.com/item?id=13966241">Hacker news</a> or <a href="https://www.reddit.com/r/programming/comments/61rh9j/curl_is_c/">Reddit</a>!</p>



<p><strong>Followup-post: </strong><a href="https://daniel.haxx.se/blog/2017/03/30/yes-c-is-unsafe-but/">Yes, C is unsafe, butâ€¦</a></p>
	</div></div>]]>
            </description>
            <link>https://daniel.haxx.se/blog/2017/03/27/curl-is-c/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26179601</guid>
            <pubDate>Thu, 18 Feb 2021 13:34:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[OpenZFS â€“ dRAID, Finally]]>
            </title>
            <description>
<![CDATA[
Score 161 | Comments 46 (<a href="https://news.ycombinator.com/item?id=26179566">thread link</a>) | @throw0101a
<br/>
February 18, 2021 | https://klarasystems.com/articles/openzfs-draid-finally/ | <a href="https://web.archive.org/web/*/https://klarasystems.com/articles/openzfs-draid-finally/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>




<div>
<h3><em>This is part of our article series published as â€œOpenZFS in Depthâ€. <a href="https://klarasystems.com/articles/"><strong><span>Subscribe to our article series</span></strong> </a>to find out more about the secrets of OpenZFS</em></h3>



<hr>



<p><strong><em>Isaac Huangâ€™s <a href="https://www.youtube.com/watch?v=xPU3rIHyCTs">talk at the OpenZFS 2017 developers summit</a> witnessed the expansion of the ZFS storage endurance envelope for large installations.&nbsp; dRAID or distributed RAID is a new vdev type that complements existing ZFS data protection capabilities for very large storage arrays.&nbsp; Starting with the RAID-Z-like underpinnings, dRAID permutes, or mixes, disk blocks together in a way where accesses are evenly spread across all the drives. Fast spindle replacement is accomplished by using all members of the pool, using pre-allocated virtual spares, spread evenly over all the spindles. Contributors include Intel, Lawrence Livermore Labs, and HP Enterprise, which have material interest in storage at datacenter scale and high reliability. The OpenZFS user community are the benefactors of this enhancement if we apply it well.</em></strong></p>



<h3><strong>Avoiding the Death Spiral</strong></h3>



<p>Admins will often use wide RAID stripes to maximize usable storage given a number of spindles. RAID-Z deployments with large stripe widths, ten or larger, are subject to poor resilver performance for a number of reasons. Resilvering a full vdev means reading from every healthy disk and continuously writing to the new spare. This will saturate the replacement disk with writes while scattering seeks over the rest of the vdev. For 14 wide RAID-Z2 vdevs using 12TB spindles, rebuilds can take weeks. Resilver I/O activity is deprioritized when the system has not been idle for a minimum period. Full zpools get fragmented and require additional I/Oâ€™s to recalculate data during reslivering. A pool can degenerate into a never ending cycle of rebuilds or loss of the pool Aka: the Death Spiral.</p>



<p>As spindles age together, disks may fail in groups as defect counts and mechanical failure are not independent random processes with respect to age. SSDâ€™s further complicate this math as the wear leveling endurance will be very closely matched and clusters of devices under identical load may fail together.&nbsp; Manufacturer provided mean time to failure is a forward-looking statement and is not suitable for replenishment planning. One manufacturer claims 1.2 Million hour MTBF: a dubious 137 year commitment to quality. Itâ€™s poor planning to assume any drive isnâ€™t going to pick today to dramatically fail.&nbsp;</p>



<p>dRAID is an option providing rapid parity rebuild that can mitigate the death spiral behaviour of wide RAIDZ stripes, but as reflected in its default width setting of eight, it does not encourage wide stripes. Dedicating sufficient parity increases the durability of the ZFS pool and the investment in parity should be informed by the risk of losing the pool.</p>



<h3><strong>Distributed Spares?</strong></h3>



<p>Spare disks are a way of keeping a disk warm and ready to replace a failed member. Usually, a spareâ€™s life is leisurely idle until they are scrammed into action during a rebuild. That idleness is a wasted opportunity to do useful work. There are no specific spare disks in a dRAID. Rather, enough blocks are allocated throughout out the vdev to act as spares. The distributed spare is a clever redistribution of work so that all disks are always in use. A disk failure precipitates a rebuild into that dedicated space. After replacement disks are available, the vdev can be re-balanced to return the spare block and put the replacement disk in to use.</p>



<h3><strong><strong><strong>Fixed Stripe Width</strong></strong></strong></h3>



<p>Unlike RAID-Z, an entire stripe in dRAID is allocated at once, no matter how many disk blocks are needed to store the object. The stripe width is determined by the disk sector size multiplied by the number of data drives in the RAID group.</p>



<div data-columns="3" data-layout="50-25-25"><div>




<div><div>
<p>Did you know?</p>



<h2>You can maximize the <strong>power of your FreeBSD</strong> infrastructure with our <strong>Support Subscription!</strong></h2>




</div></div>




</div></div>



<p>RAID-Z has a method of optimizing block layout to minimize block allocations for small files. dRAID however priorities the speed of rebuilding parity and does not make the same space preserving attempt. If your files are a small fraction of the stripe size, dRAID will not be able to use all the disk blocks fully. For example, a default dRAID vdev has a stripe with of 32k (4k per disk, 8 disks); any allocation will require at least 32k. Internal padding is allocated to fill out the stripe width after the request object is stored. Using a smaller stripe width or providing a special mirror vdev will suit smaller allocations and improve drive utilization.</p>



<h3><strong>A Tale of Two Resilvers</strong></h3>



<p>After a failure, the real or distributed spare is written to in sequence, following only the parity layout in the space map to rebuild the drive according to parity data. Sequential reconstruction can be accomplished rapidly by issuing large I/O blocks, reducing seeks, and avoiding tree indirection overhead. The rebuilt diskâ€™s contents are not necessarily consistent with the Merkle tree that proves the zpools data is intact.&nbsp; Itâ€™s important to reconstruct this bitwise copy of the disk first, allowing the system to return to mostly intact state and return to service. That is to say, the sequential reconstruction process restores the redundancy level of the pool, but without being able to verify the checksums of the data. The advantage to this is that it can be completed much more quickly, reducing the window during which additional disk failures might put the pool at risk.</p>



<p>A healing resilver is triggered automatically after a sequential resilver, it is a final operation that verifies that all the contents of the drives match their initial checksums via block pointer traversal. The healing resilver has a number of optimizations to quickly find and reconstruct writes to the failed disk. When a replacement drive can be added to the pool, the rebalance operation is another sequential resilver followed by a healing resilver.</p>



<p>A scrub is the gold standard for a pool health; however, a scrub might be a prohibitive amount of work, visiting every block allocated in the pool. The healing resilver allows a practical return to operation in an environment where failures must be repaired routinely.</p>



<h3><strong><em>â€œAre We There Yet? When Can I Play With it?â€</em></strong></h3>



<p>According to a report from the January OpenZFS leadership meeting, OpenZFS 2.1 will support dRAID in early 2021. If you must have it now; the head branch of the OpenZFS build against recently supported operating systems: FreeBSD 12.1+, Linux 5.10+, Illumos, NetBSD et al. The OpenZFS regression test suite ztest is a good indication that dRAID satisfies the ZFS commitment to data protection. Corporate customers at IBM and Panasas have been flogging other distributed RAID systems for more than ten years. Itâ€™s a mature concept that complements the ZFS tool set.</p>



<h4><strong>Quick Start</strong></h4>



<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; There is no better way to learn software than to run headlong into mistakes.&nbsp;</p>



<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Weâ€™ll install ZFS head from source and gin up some â€˜mdâ€™ file backed disks.</p>



<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; â€˜zpool create r2dRAID dRAID2:3d:1s:14c /dev/md1 /dev/md2 â€¦.&nbsp; /dev/md13 /dev/md14â€™</p>



<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; There it is, a zpool with a dRAID vdev, ready to go to work.</p>



<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; The OpenZFS wiki has a good description of <a href="https://openzfs.github.io/openzfs-docs/Basic%20Concepts/dRAID%20Howto.html">dRAID care, resilvering and rebalancing</a></p>



<p>Following the life cycle of failure and replacement in the documentation is recommended before those skills are tested in production.</p>



<h4><strong>dRAID Nomenclature</strong></h4>



<p>Letâ€™s decode the nomenclature that describes the geometry of a dRAID vdev. A string such as â€œdRAID2:3d:14c:1sâ€ encodes the following about a dRAID vdev.</p>



<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; -dRAID[&lt;parity&gt;][:&lt;data&gt;d][:&lt;children&gt;c][:&lt;spares&gt;s]</p>



<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; -parity: Required, the number of spindles to use to store parity information. Eg: A dRAID3 can survive until a fourth disk failure without losing data. Parity may be 1,2 or 3.</p>



<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; -[d] data: (spindles per RAID group): Determines the width of the data stripe, 8 is the default. Larger values will increase the stripe width and reduce total parity.</p>



<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; -[c] children: This parameter should match the number of device entries that you feed to the vdev. A helpful check will warn you if you donâ€™t get the right number of disks named correctly: â€œinvalid number of dRAID children; 14 required but 13 providedâ€</p>



<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; -[s] spares: The number of disk areas to mix in as distributed spares. No spares are created by default, a maximum of four are welcome. Each spare will remove a fraction of space from every disk.</p>



<h2><strong>Parting Short</strong></h2>



<p>The dRAID offers a solution for large arrays, vdevs with fewer than 20 spindles will have limited benefits from the new option. The performance and resilver result will be similar to RAIDZ for small numbers of spindles. Installations with many spindles will see the best results with regards to performance, fast spare activation and replacement. The benefits come with the associated cost of whole stripe at a time allocation for small objects in the pool. This overhead should be calculated in the design of the pool before itâ€™s an operational surprise.</p>



<p>There is no free lunch with dRAID for in saving parity or spare drives, they are your defense against data loss. As drives increase in size, their time to resilver increases and the amount of data they can destroy increases.</p>



<h2><strong>Like this article? Share it!</strong></h2>


</div>




</div></div>]]>
            </description>
            <link>https://klarasystems.com/articles/openzfs-draid-finally/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26179566</guid>
            <pubDate>Thu, 18 Feb 2021 13:31:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I am a heroin user. I do not have a drug problem]]>
            </title>
            <description>
<![CDATA[
Score 261 | Comments 625 (<a href="https://news.ycombinator.com/item?id=26179003">thread link</a>) | @CapitalistCartr
<br/>
February 18, 2021 | http://m.nautil.us/issue/96/rewired/i-am-a-heroin-user-i-do-not-have-a-drug-problem | <a href="https://web.archive.org/web/*/http://m.nautil.us/issue/96/rewired/i-am-a-heroin-user-i-do-not-have-a-drug-problem">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
			<p><span>C</span>arl Hart is a neuroscientist and Ziff Professor of Psychology at Columbia Universityâ€”he was the first tenured African-American professor of sciences at Columbia. His research focuses on the â€œbehavioral and neuropharmacological effects of psychoactive drugs in humans.â€ Hartâ€™s new book, <i>Drug Use For Grown-Ups</i>, is a bold and engaging effort to counter what he sees as generations of misinformation and moral grandstanding about drug use. Todayâ€™s â€œsensationalistic media coverage of the opioid crisis continues a long, awful tradition of exploiting ignorance and fear to vilify certain members of our society,â€ Hart writes. The media is not the only problem. Scientists, he states, â€œhave frequently overinterpreted and distortedâ€ drugsâ€™ effects on the brain.</p><p>Hart reports that more than 70 percent of drug usersâ€”whether they use alcohol, cocaine, prescription medications, or heroinâ€”do not meet the health criteria for drug addiction. In <i>Drug Use for Grown-Ups</i>, Hart strives to â€œpresent a more realistic image of the typical drug user: a responsible professional who happens to use drugs in his pursuit of happiness.â€ With genial candor, Hart presents himself as a model drug user. â€œI am now entering my fifth year as a regular heroin user,â€ he writes. â€œI do not have a drug-use problem. Never have. Each day, I meet my parental, personal, and professional responsibilities. I pay my taxes, serve as a volunteer in my community on a regular basis, and contribute to the global community as an informed and engaged citizen. I am better for my drug use.â€</p><p><i>Nautilus</i> caught up with Hart to discuss his drug use and his sharp points about science and society. He was as casually bold in conversation as he is in <i>Drug Use for Grown-Ups</i>.</p><figure data-alt="MacNamara_BREAKER"><img src="http://static.nautil.us/18174_0f004440ba0c8f1ccc5c355f3d77207f.png" width="733" alt=""><figcaption><span><strong>HABIT OF A HIGHLY EFFECTIVE PERSON:</strong> â€œMy heroin use is as rational as my alcohol use,â€ Carl Hart writes. â€œLike vacation, sex, and the arts, heroin is one of the tools that I use to maintain my work-life balance.â€</span><span>Courtesy of Carl Hart</span></figcaption></figure><p><b>You say â€œmost drug-use scenarios cause little or no harm and that some responsible drug-use scenarios are actually beneficial for human health and functioning.â€ How so?</b></p><p>Letâ€™s just talk about alcohol first. When youâ€™re at a wedding reception, alcohol serves as a social lubricant. People are more gregarious. They talk, they interact. The same is true with cocaine at parties, heroin among friends, or opium among friends, NDMA among lovers. It enhances empathy, openness, and forgiveness, all of these pro-social attributes.</p><p><b>Drug research, you write, is full of bad science. If you had to name one example, what would it be?</b></p><p>The notion that drug addiction is a brain disease. That encapsulates all thatâ€™s wrong with todayâ€™s science in this area. There is absolutely no data in humans to show that drug addiction is a brain disease. Yet the narrative, the dogma, the dominant perspective is that it does. Even though nobody will dispute that, thereâ€™s absolutely no data in humans to support that statement.</p><p><b>Yet opioids do change the brain biologically, do they not?</b></p><p>Yes, opioids bind to a class of receptors called endogenous opioids, which you find in endorphins, for example. Opioids bind to these receptorsâ€”just like natural chemicals doâ€”which results in a response. In some cases, because of decreased sensitivities and certain types of pain, they may enhance a sense of euphoria. So itâ€™s really just facilitating whatâ€™s already in the body naturally, a system that helps in our survival. Think of fructose or glucose. We add sugar to our tea, our coffee, whatever we have, we add more and more because we like it, it tastes good, and it enhances pleasure. It can give you energy. It can make life more interesting. Humans do not live on logic alone. And so sometimes we do these things, and thatâ€™s OK.</p><blockquote><p>People become addicted because they once had a middle-class-paying job that made them someone in their community.</p> </blockquote><p><b>How have scientists â€œoverinterpreted and distortedâ€ the effects of drugs on the brain?</b><br></p><p>Take brain imaging. People often show one image of someoneâ€™s brain. Letâ€™s say this person is addicted to methamphetamine, according to DSM criteria, versus the brain of someone whoâ€™s not addicted. If you see some difference, some researchers have a propensity to make more out of the differences than are there. Thereâ€™s a wide range of brain structural sizes, such that when we think about one personâ€™s size of their nucleus accumbens, it may be smaller or larger than somebody elseâ€™s nucleus accumbens. But both of the nucleus accumbens, despite their sizes, are within the normal range of human variability. Itâ€™s like height. One guy might be 5â€™10â€, another guy might be 6â€™2â€. But we donâ€™t say the guy whoâ€™s 5â€™10â€ is height deficient. We just say that heâ€™s in a normal range, and heâ€™s not as tall as the other guy. We wouldnâ€™t say one is deficient versus the other. In neuroscience, one of the things that has happened, particularly when it comes to drugs, people have over-interpreted the differences to mean pathology, when, in fact, both of the brain structures are within the normal range of human variability. The overinterpretation is to interpret it as being pathological.</p><p><b>You say the opioid crisis has been sensationalized, and write, â€œPeople are not dying because of opioids; they are dying because of ignorance.â€ What do you mean?</b></p><p>Some people donâ€™t know not to mix specific sedatives with opioids. For example, they donâ€™t know not to mix large amounts of alcohol or large amounts of antihistamines. Specific combinations can lead to respiratory depression, which can lead to death. Another point of ignorance involves people who buy street drugs and donâ€™t necessarily know if the drugs contain contaminants. Thatâ€™s the kind of ignorance Iâ€™m talking about.</p><div>
<article>
<p><a href="http://m.nautil.us/issue/15/Turbulence/ingenious-robert-sapolsky" data-trval="ingenious-robert-sapolsky" data-trlbl="foc_rec" data-tract="internal_art">
<img src="http://static.nautil.us/3786_34306d99c63613fad5b2a140398c0420.png" alt="Sapolsky_TH-F1" width="314" height="177">
</a>
</p>
<div>
<p><span>
<span>

<span><a href="http://m.nautil.us/term/f/Neuroscience">Also in Neuroscience</a></span>&nbsp;&nbsp;</span>
</span></p><h4><a href="http://m.nautil.us/issue/15/Turbulence/ingenious-robert-sapolsky" data-trval="ingenious-robert-sapolsky" data-trlbl="foc_rec" data-tract="internal_art">Ingenious: Robert Sapolsky</a></h4>
<p>By Kevin Berger</p>
<p>
When we asked Robert Sapolsky what he might like to write about for the Nautilus Turbulence issue, he responded, â€œadolescence.â€ We had to laugh because the idea just seemed so perfect. Is there a more turbulent time in our lives?...<strong><a href="http://m.nautil.us/issue/15/Turbulence/ingenious-robert-sapolsky" data-trval="ingenious-robert-sapolsky" data-trlbl="foc_rec" data-tract="internal_art">READ MORE</a></strong>
</p>

</div>

</article>
</div><p><b>So itâ€™s the mix of drugs that is the problem, not opioids like heroin themselves?&nbsp;</b></p><p>Yes, the majority of opioid deaths occur as a result of combining opioids with multiple sedatives. But there are certain opioids that do concern us if taken alone and the person isnâ€™t aware that they have this particular opioid. Those are fentanyl and the fentanyl analogs. These drugs are a lot more potent than something like heroin, meaning they require less of it to produce the effect. Most of the public arenâ€™t seeking fentanyl or its analogs, but people are tainting things like heroin and oxycodone pills with fentanyl or an analog.</p><p>One way to deal with this tainting, this contamination, is to have free drug-checking facilities, where people can submit samples of their drug and get a chemical readout of what is contained in the substance. That way theyâ€™ll know whether to take the substance or how much of it to take. The public also needs to know that most people who use these drugs are not addicts. If you understand that, then you know that for the people who do become addicted, we have to look beyond the drug and look at the personâ€™s environment, their life. Do they have co-occurring psychiatric illnesses? Do they have pain that is not treated? All of these kinds of issues become important.</p><p><b>At what point does biological change in the brain lead to physical addiction?</b></p><p>Physical addiction occurs as a result of opioidsâ€”or any other drug, alcohol tooâ€”being in the body for consecutive weeks or periods, in particularly high doses. And then the body tries to compensate. For example, with opioids, one of the things that happens is that your gut, your gastrointestinal system, slows down the receptors. Your body is trying to compensate by speeding up the gastrointestinal tract. So when the drug abruptly leaves after several weeks of constant administration of the opioid, now the body is unprepared for the drug not being there and it overcompensates. It really ramps up the motility of the gastrointestinal tract, which causes diarrhea, among other things.</p><blockquote><p>It can give you energy. It can make life more interesting. Humans do not live on logic alone.</p> </blockquote><p><b>Why do some people get addicted and not others?</b><br></p><p>The amount of drugs they take, the period at which they take it. Some people can take opioids for extended periods of time. As long as they keep the doses fairly low and they donâ€™t take multiple doses a day, they probably wonâ€™t experience physical dependence. Itâ€™s just like with alcohol. Most people drink alcohol on a regular basis, but they donâ€™t become physically dependent. Whereas others drink every day in large amounts, and they will become physically dependent.</p><p><b>Why canâ€™t people overcome addiction?</b></p><p>One of the major reasons people canâ€™t overcome it is because weâ€™re not very good at treating addiction in this country. Just think about why people become addicted. A large number become addicted because of co-occurring psychiatric illnesses, because of pain issues, because they once had a middle-class-paying job that made them someone in their home, someone in their community. Those jobs are gone. Then thereâ€™s no healthcare or thereâ€™s poor education. If your treatment is not addressing these issues, people are not going to overcome it. But if we have treatments that are holistic, and theyâ€™re looking at the individual, and not so much the drug, then weâ€™re good. But if weâ€™re just talking about the drug, then weâ€™re already behind the eight ball, then we will lose that battle.</p><p><b>Your definition of addiction follows the DSM-5, which refers to a â€œsubstance use disorderâ€ and values functioning over regular ingestion of a substance. How do you define â€œfunctioningâ€?</b></p><p>Functioning is determined by whether a user is happy in meeting their obligations, whatever they may be, whether theyâ€™re work-related, whether theyâ€™re family-related, or other social sorts of things. The person is not stressed out about their substance use. In fact, â€¦</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://m.nautil.us/issue/96/rewired/i-am-a-heroin-user-i-do-not-have-a-drug-problem">http://m.nautil.us/issue/96/rewired/i-am-a-heroin-user-i-do-not-have-a-drug-problem</a></em></p>]]>
            </description>
            <link>http://m.nautil.us/issue/96/rewired/i-am-a-heroin-user-i-do-not-have-a-drug-problem</link>
            <guid isPermaLink="false">hacker-news-small-sites-26179003</guid>
            <pubDate>Thu, 18 Feb 2021 12:23:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The frame rate of the universe (2009)]]>
            </title>
            <description>
<![CDATA[
Score 69 | Comments 55 (<a href="https://news.ycombinator.com/item?id=26178259">thread link</a>) | @codesections
<br/>
February 18, 2021 | https://www.librador.com/2009/01/16/The-frame-rate-of-the-universe/ | <a href="https://web.archive.org/web/*/https://www.librador.com/2009/01/16/The-frame-rate-of-the-universe/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">
      
<div id="page-2009-2009-01-16-The-frame-rate-of-the-universe-">
  
  <p><abbr title="2009-01-16T01:04:00+01:00">16 Jan 2009</abbr></p><div>
    <p>

    I stumbled upon <a href="http://www.newscientist.com/article/mg20126911.300-our-world-may-be-a-giant-hologram.html?full=true">this
article</a> which presents the hypothesis that the universe is a 3D projection of a 2D
surface, like a giant hologram. I like to read about modern physics. It is so weird and I can't say
I really understand very much of it. But the descriptions provoke strange and fascinating images
and thoughts in my head. Like this one:</p><p>The article mentions the <a href="http://en.wikipedia.org/wiki/Planck_length">Planck length</a>, which as I understand it is
the smallest distance there is. It's extremely small: 1.6 Ã— 10<sup>-35</sup> meters, which makes
it billions and billions of times smaller than an atom (or even a proton). I'm used to thinking
about computer graphics, so I imagine the Planck length as the size of one "pixel" of the universe.
Nothing can be smaller than a pixel. (The pixels of the universe are small, I calculate the
resolution to correspond to 2.19 Ã— 10<sup>33</sup> DPI.) The radius of the observable universe is
4.4 Ã— 10<sup>26</sup> meters. If we want to fit the universe into a box, its sides would have to
be twice that size. That is 5.4 Ã— 10<sup>61</sup> Planck lengths. So that's the width, height and
depth of the universe in pixels. Quite a good resolution. (Actually since they are 3D cubes instead
of 2D squares, I should call them voxels instead of pixels. All 1.61 Ã— 10<sup>185</sup> of
them.)</p><p>There is also the <a href="http://en.wikipedia.org/wiki/Planck_time">Planck time</a>
which is the time it takes for light to travel one Planck length. As light is fast and the Planck
length is tiny (tiniest there is!), you can image that it's a very short period of time. Certainly.
The Planck time is 5.39 Ã— 10<sup>-44</sup> seconds. No measurable time can be shorter than that
according to quantum physics. Thinking about graphics again, this is like a limit on the frame rate
of the universe. Inverting the Planck time, I get 1.855 Ã— 10<sup>43</sup>. So by my surely
incorrect logic, we get the value of the universe's frame rate:</p><p>One thousand eight hundred
and fifty-five billion billion billion billion frames per second.</p><p>I'll say that
again:</p><p>18.55 septillion FPS!</p><p>Video cameras won't be perfect until they can record at
that speed.</p><p>I hope I got the calculations right, but I'm pretty sure my interpretation of the
quantum physics behind this are way off. It's still fascinating to think of the universe as a
computer simulation. Modern physics make it seem more like a video game than ever.<br>


</p>
  </div>
  
  
  <p><a href="http://disqus.com/">blog comments powered by </a>
</p></div>

    </div></div>]]>
            </description>
            <link>https://www.librador.com/2009/01/16/The-frame-rate-of-the-universe/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26178259</guid>
            <pubDate>Thu, 18 Feb 2021 10:37:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Lithuania plans to hold drills in case of accident at the Belarus nuclear plant]]>
            </title>
            <description>
<![CDATA[
Score 156 | Comments 132 (<a href="https://news.ycombinator.com/item?id=26178235">thread link</a>) | @maury91
<br/>
February 18, 2021 | https://www.lrt.lt/en/news-in-english/19/1346034/lithuania-plans-to-hold-evacuation-drills-after-belarus-launches-nuclear-plant | <a href="https://web.archive.org/web/*/https://www.lrt.lt/en/news-in-english/19/1346034/lithuania-plans-to-hold-evacuation-drills-after-belarus-launches-nuclear-plant">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<article id="article1346034">    

    
    
    <div>

        <div id="article_text1346034">
            <p>Lithuaniaâ€™s Interior Ministry plans to hold drills and assess the need to evacuate Vilniusâ€™ residents in case of an accident at the Astravyets nuclear plant in Belarus, located some 50 kilometres from the Lithuanian capital.</p>
            
            <p>"That will be one of the key questions during the drafting of the exercises schedule and probably going back to the scenarios: do we or do we not need to evacuate Vilnius residents,â€ Vitalij Dmitrijev, vice minister of the interior, told LRT RADIO.</p>
            <p>The so-called Astravyets drill was held in October 2019 in Vilnius and SvenÄionys districts, which are located close to the Belarusian border. During the exercises, authorities prepared to evacuate people from radiation-affected territories, distribute iodine pills, as well as simulated a resident cleanup and monitoring operation.</p>
            <p>The exercise involved around 300 officers, troops and civil servants from six municipalities and 24 institutions. Due to a dispute over the exercise scenario with the Vilnius authorities, officers from the capital did not take part in the drills.</p>
                

            <p><em>Read more: <a href="https://www.lrt.lt/en/news-in-english/19/1103053/lithuanians-stage-mock-evacuations-to-train-for-nuclear-accident-photos">Lithuanians stage mock evacuations to train for nuclear accident â€“ photos</a></em></p>
            <!--googleoff: all--><!--googleon: all-->            <p>Previously, the Vilnius authorities cancelled another exercise, planned in early September, to simulate an accident at the nuclear power plant in Belarus.</p>
            <p>Based on the information available to BNS, Vilnius Municipality faced resistance from the government at the time.</p>
            <p>Lithuanian officials say that the nuclear power plant built by the Russian state atomic corporation Rosatom and funded by a loan from the Kremlin was built in breach of international safety standards. Minsk denies all accusations.</p>
            <p>Estonia, Latvia, and Lithuania are also due to unplug from the Moscow-controlled energy grid that links them with Belarus. Vilnius says that the Kremlin may use the plant to derail the move.</p>
<!--googleoff: all--><div>
            
<div id="mlb2-1612938">
    <div>
        <div>
            <div>
                <div>
                    <p><img src="https://bucket.mlcdn.com/a/1239/1239192/templates/39/39540/5dcc95ea35753170c2955994a6fea7c948ffb283.png"></p><p>LRT English Newsletter<span><span><br></span><span><span>Every Friday morning.</span></span></span></p>
                    
                </div>
            </div>
            
        </div>
    </div>
</div>

<p><img src="https://track.mailerlite.com/webforms/o/1612938/i0s8k2?v4a60e9ef938a7fa0240ac9ba567062cb" width="1" height="1">
</p></div><!--googleon: all-->        </div>
    </div>
    <!--googleoff: all-->
        <!--googleon: all-->
        

<div data-id="gallery1346034"><div>
            <div>
                <div>
                    <div>
<p><img data-src="/img/2019/10/02/522637-581058-1287x836.jpg" alt="â€˜Astravyets drillâ€™ in Lithuania" title="â€˜Astravyets drillâ€™ in Lithuania" src="https://www.lrt.lt/img/2019/10/02/522637-581058-1287x836.jpg"></p>
<div>
    <div>
        <div>
<p>â€˜Astravyets drillâ€™ in Lithuania</p>            <p><span>1 / 5</span><span>D. Umbrasas / LRT</span></p>
        </div></div>
</div>
                    </div>
                    <div>
<p><img data-src="/img/2019/12/23/573047-835055-1287x836.jpg" alt="Lithuania has staged 'Astravyets drills' to prepare for nuclear emergencies" title="Lithuania has staged 'Astravyets drills' to prepare for nuclear emergencies" src="https://www.lrt.lt/img/2019/12/23/573047-835055-1287x836.jpg"></p>
<div>
    <div>
        <div>
<p>Lithuania has staged 'Astravyets drills' to prepare for nuclear emergencies</p>            <p><span>2 / 5</span><span>D. Umbrasas/LRT</span></p>
        </div></div>
</div>
                    </div>
                    <div>
<p><img data-src="/img/2019/10/02/522627-981621-1287x836.jpg" alt="â€˜Astravyets drillâ€™ in Lithuania" title="â€˜Astravyets drillâ€™ in Lithuania" src="https://www.lrt.lt/img/2019/10/02/522627-981621-1287x836.jpg"></p>
<div>
    <div>
        <div>
<p>â€˜Astravyets drillâ€™ in Lithuania</p>            <p><span>3 / 5</span><span>D. Umbrasas / LRT</span></p>
        </div></div>
</div>
                    </div>
                    <div>
<p><img data-src="/img/2019/10/02/522623-306261-1287x836.jpg" alt="â€˜Astravyets drillâ€™ in Lithuania" title="â€˜Astravyets drillâ€™ in Lithuania" src="https://www.lrt.lt/img/2019/10/02/522623-306261-1287x836.jpg"></p>
<div>
    <div>
        <div>
<p>â€˜Astravyets drillâ€™ in Lithuania</p>            <p><span>4 / 5</span><span>D. Umbrasas / LRT</span></p>
        </div></div>
</div>
                    </div>
                    <div>
<p><img data-src="/img/2019/10/02/522612-821132-1287x836.jpg" alt="â€˜Astravyets drillâ€™ in Lithuania" title="â€˜Astravyets drillâ€™ in Lithuania" src="https://www.lrt.lt/img/2019/10/02/522612-821132-1287x836.jpg"></p>
<div>
    <div>
        <div>
<p>â€˜Astravyets drillâ€™ in Lithuania</p>            <p><span>5 / 5</span><span>D. Umbrasas / LRT</span></p>
        </div></div>
</div>
                    </div>
                </div>
                
            </div>
        </div>
        
    </div>
 

    
    
</article>

        
    </div></div>]]>
            </description>
            <link>https://www.lrt.lt/en/news-in-english/19/1346034/lithuania-plans-to-hold-evacuation-drills-after-belarus-launches-nuclear-plant</link>
            <guid isPermaLink="false">hacker-news-small-sites-26178235</guid>
            <pubDate>Thu, 18 Feb 2021 10:34:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Urbit: The Good, the Bad, and the Insane]]>
            </title>
            <description>
<![CDATA[
Score 6 | Comments 2 (<a href="https://news.ycombinator.com/item?id=26177720">thread link</a>) | @wcerfgba
<br/>
February 18, 2021 | https://wejn.org/2021/02/urbit-good-bad-insane/ | <a href="https://web.archive.org/web/*/https://wejn.org/2021/02/urbit-good-bad-insane/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <div>
  <p><span>Written</span>
    

    
      <span>on&nbsp;</span><time datetime="2021-02-17 19:02:00 +0100">2021-02-17</time>
    
    
  </p>

  

  

  

  <p>In this post Iâ€™m gonna be making all kinds of fun of <a href="https://urbit.org/">Urbit</a>.
And all that after spending just a few hours poking around it.</p>
<p>Originally, I wanted to write in the layout of the good, the bad, and the ugly,
but Iâ€™m not entirely sure how that would pan out.<sup><a href="#fn1" id="fnref1">1</a></sup></p>
<p>Before I begin, Iâ€™ll somewhat oversimplify and explain Urbit to those of you not
in the know.</p>
<p><em>And before I do that, hereâ€™s a PSA: thereâ€™s a <a href="#tldr">tl;dr at the end</a>. So you
donâ€™t need to read all this drivel. Youâ€™re welcome.</em></p>
<h2 id="urwhat">Urâ€¦what?</h2>
<p>According to its own webpage, Urbit is an â€œoverlay OSâ€ and network for the 21st
century.</p>
<p>What that means at the time of writing<sup><a href="#fn2" id="fnref2">2</a></sup> is that itâ€™s a single-threaded
interpreter running as a unix process that speaks udp protocol to a meshed
network (and http to your browser).</p>
<p>And all of that in the name of delivering you flaky, unreliable, and feature-poor
implementation of an internet forum. (in a nutshell)<sup><a href="#fn3" id="fnref3">3</a></sup></p>
<p>An additional component of Urbit is its â€œdistributedâ€ identity component, where
your identity is uniquely tied to a 32-bit integer. And to go with the zeitgeist,
itâ€™s backed by Ethereum blockchain. Naturally.</p>
<p>All we need is quantum computing and ML, and we have all the latest buzzwords.
<a href="https://groups.google.com/a/urbit.org/g/dev/c/a6hdQdzIgqo">Oh, wait.</a></p>
<p>But to better explain whatâ€™s going on, letâ€™s look atâ€¦</p>
<h2 id="a-bit-of-history">A bit of history</h2>
<p>Iâ€™m going to take Urbitâ€™s history page on authority here.</p>
<p>This project started in 2002 as a PhD thesis to reinvent computing. Over the
next 6 years the progress was a language specification (Nock) for
a turing-complete language with ~11 instructions.</p>
<p>Then, over 10+ years other people ran with it, took it further, and implemented:</p>
<ul>
<li>(more than one) VM interpreting that language</li>
<li>a higher level language â€“ Hoon (to make Nock â€œpracticalâ€)</li>
<li>an encrypted mesh protocol</li>
<li>a versioned control system</li>
<li>an application layer</li>
<li>a web frontend (several apps, actually)</li>
<li>an identity layer</li>
<li>â€¦</li>
</ul>
<p>If this smells like a bad case of <a href="https://en.wikipedia.org/wiki/Not_invented_here">NIH</a>,
itâ€™s probably because thatâ€™s exactly the case.</p>
<h2 id="urbit-as-an-ideal-good-and-insane-at-the-same-time">Urbit as an ideal: good and insane at the same time</h2>
<p>But letâ€™s talk about Urbit as an ideal for a moment.</p>
<p>Letâ€™s assume that when <a href="https://youtu.be/M04AKTCDavc">the marketing materials</a>
speak of</p>
<blockquote>
<p>defining an operating system on a single piece of paper</p>
</blockquote>
<p>and</p>
<blockquote>
<p>throwing away every line of code from the 1970s</p>
</blockquote>
<p>they mean well. Given some sort of hardware implementation of Nock (the low level
language) you theoretically <em>could</em> throw away everything and start from scratch.</p>
<p>And it would be all kinds of awesome, if you could have decent control over your
personal computing without all the cruft accumulated since â€™70s.</p>
<p>Onlyâ€¦ with Urbit this ideal would be so slow as to be useless. See, Nock has
one arithmetic operation, increment (<code>x+1</code>). So if you want to decrement <code>x</code>,
you have to loop from <code>0</code> to <code>x-1</code>. Or you can break your promise of throwing
away all the code from â€™70sâ€¦ and implement decrement in C.</p>
<p>And the same story (of replacing godawfully ineffective implementation of native
code with C implementation) goes pretty much for any reasonable functionality you
might expect. Crypto? Sorting? Basic math and string ops? All of it.</p>
<p>The entire frickinâ€™ peer to peer protocol is written in C, too. So are vast
swaths of the OS: db, ames, http, terminal, database, event processing, â€¦</p>
<p>Is it possible to truly throw away every line of code from the 1970s up until
nowâ€¦ and start from clean slate? Hell yeah. Only, probably not with Nock.</p>
<p>So we have the pivot to â€œoverlay OSâ€ (mentioned on urbit.org), in other words:
<strong>letâ€™s not throw away any lines of code, but instead build on top of them</strong>.
And then access the UI using a conventional browser over http, that will
interpret the React-based javascript (among other things).</p>
<p>So far so good.</p>
<p>Ubitâ€™s core promise:reality â€“ 0:1.</p>
<h2 id="hoon-as-a-language-amazing">Hoon as a language: amazing</h2>
<p>Letâ€™s move on to the Hoon language<sup><a href="#fn4" id="fnref4">4</a></sup>, the workhose of the platform.</p>
<p>Once you start diggin in, you will be constantly met with such <a href="https://github.com/urbit/urbit/blob/master/pkg/arvo/gen/cat.hoon">vomit inducing
beauty</a>:</p>
<pre><code>::  ConCATenate file listings
::
::::  /hoon/cat/gen
  ::
/?    310
/+    pretty-file, show-dir
::
::::
  ::
:-  %say
|=  [^ [arg=(list path)] vane=?(%g %c)]
=-  tang+(flop `tang`(zing -))
%+  turn  arg
|=  pax=path
^-  tang
=+  ark=.^(arch (cat 3 vane %y) pax)
?^  fil.ark
  ?:  =(%sched -:(flop pax))
    [&gt;.^((map @da cord) (cat 3 vane %x) pax)&lt;]~
  [leaf+(spud pax) (pretty-file .^(noun (cat 3 vane %x) pax))]
?-     dir.ark                                          ::  handle ambiguity
    ~
  [rose+[" " `~]^~[leaf+"~" (smyt pax)]]~
::
    [[@t ~] ~ ~]
  $(pax (welp pax /[p.n.dir.ark]))
::
    *
  =-  [palm+[": " ``~]^-]~
  :~  rose+[" " `~]^~[leaf+"*" (smyt pax)]
      `tank`(show-dir vane pax dir.ark)
  ==
==
</code></pre>
<p>that makes Perl the world champion of readable languages by comparison.</p>
<p>Iâ€™m not being entirely fair here, because Iâ€™m sure you can memorize the digraphs
in a few weeks<sup><a href="#fn5" id="fnref5">5</a></sup>, and eventually you get the hang of writing this.
But in the grand scheme of thingsâ€¦ why the heck would you want to?!</p>
<p>It is hard enough to write bug free code in a language that you can find
tens of thousands of top notch coders for (that would give you an honest
code review). Itâ€™s quite another thing doing basic reading of Hoon.</p>
<p>But letâ€™s say Iâ€™m biased, this is the future, and 5 years down the road it
will be the gold standard for personal computing dev<sup><a href="#fn6" id="fnref6">6</a></sup>.</p>
<p>What can you expect in terms of features, then?</p>
<p>Well, since youâ€™re essentially supposed to run on top of Nock, and itâ€™s
all supposed to be strictly deterministic on top of an event stream, my
imagination is failing me as to how itâ€™s going to support some sort of
parallel processing, because you probably donâ€™t want to be stuck humping
one core of your CPU.</p>
<p>Letâ€™s say you try to make it work in parallel using message passing.
Hmm, there goes determinism.</p>
<p>Or shared memory? There goes using â€œNockâ€ (as youâ€™re poking yet another
hole in the substrate).</p>
<p>Iâ€™m sure thereâ€™s a solution, but Iâ€™d bet you a doughnut itâ€™s not going
to be as pure as the marketing.</p>
<p>Hoon:reality â€“ draw (it works, but sigh)</p>
<h2 id="urbit-as-an-os--capable">Urbit as an OS â€“ capable?</h2>
<p>Do you remember how we were supposed to throw away all that code from â€™70s?</p>
<p>So thatâ€™s not happening (as described above).</p>
<p>But at least the OS is a shiny awesome thing capable of real tasks, yes?</p>
<p>Okay.</p>
<p>Given my short exposure to Urbit Iâ€™m sure Iâ€™m missing some dark corners
where clumps of awesome lurk, but if you expect more than a Weather app,
half-assed web forum, simple shared notebooks, and a weird ass terminal,
you will be sorely disappointed.</p>
<p>Again, this will be rectified in the future (of that Iâ€™m actually and
honestly sure).</p>
<p>There are already some third party Hoon implementations of bit torrent,
chat bots, etc.</p>
<p>And thereâ€™s some plans for bitcoin integration, 3rd party apps, etc.</p>
<p>So if the ecosystem takes off, it could be rich and wondrous.</p>
<p>Exceptâ€¦ most of it wonâ€™t be written in Hoon or Nock. Since Urbitians
are hard at work providing language bindings for well known languages.</p>
<p>So what are you gaining by using Urbit that you couldnâ€™t get elsewhere?
No, seriouslyâ€¦ I have yet to figure this one out.</p>
<p>Letâ€™s move onâ€¦</p>
<h2 id="hosted-urbit--only-if-you-want-to-wash-your-dirty-laundry-in-public">Hosted Urbit â€“ only if you want to wash your dirty laundry in public</h2>
<p>Now, letâ€™s think about hosting Urbit for just a moment.</p>
<p>You can run it on your Raspberry (and it will work). You even own your
data that way. <em>(duh? donâ€™t you always, in that case?)</em></p>
<p>But letâ€™s suppose you want to host it elsewhere. I mean, thereâ€™s this
awesome peer-to-peer encrypted protocol in Urbit, so itâ€™s secure, right?</p>
<p>Well, thereâ€™s encryption during transit, and then thereâ€™s encryption at
rest.</p>
<p>And the failboat comes in the latter case.</p>
<p><strong>Nothing in Urbit is encrypted at rest</strong>.</p>
<p>No, seriously, all the chat logs, events, everythingâ€¦ is dumped into
a journal on disk<sup><a href="#fn7" id="fnref7">7</a></sup> in cleartext form.</p>
<p>So, hey, also the whole â€œa vault for secretsâ€ from the marketing video?
Hmmâ€¦ are you going to risk it?</p>
<p>And are you going to risk storing your bitcoin wallet on Urbit,
unencrypted?</p>
<p>In other words, <strong>when hosting urbit at any 3rd party, you better be the
only one with access to the underlying OS</strong> (and have it fully encrypted),
lest you want your entire history worth of data readable by the company
running the instance for you. Or anyone with access to the system.</p>
<p>So, running this on GCP? Digital Ocean? Tlonâ€™s hosting? Only if youâ€™re
comfortable [potentially] washing your dirty laundry in public.</p>
<p>Urbit:real world â€“ 0:1</p>
<h2 id="lets-fail-together-over-the-air">Letâ€™s fail together over the air</h2>
<p>So say you run your Urbit securely on your Pi, you love the platform,
the UI, the whole shebang.</p>
<p>Great.</p>
<p>Nothing to fear then?</p>
<p>Yeah, maybe except the teeny tiny detail that if you want to stay up
to date, you need to configure OTA<sup><a href="#fn8" id="fnref8">8</a></sup>.</p>
<p>So you will be receiving updates to your Urbit instance from one of your
neighbors (one that you configure).</p>
<p>And you talk to your neighbors over an end to end encrypted channel.</p>
<p>Sounds great, since this is 2021, and surely the updates are signed.</p>
<p>Well, no. They are not. The transmission is, though. Big help!</p>
<p>So â€“ I guess it wouldnâ€™t be that hard for one rotten apple somewhere
on higher ranks of the network<sup><a href="#fn9" id="fnref9">9</a></sup> <em>(rogue operator, hacked machine, hacked
core devâ€™s machine)</em> to push a code update that exfiltrates all your data,
possibly including all your secrets (hey, remember the BTC integration)?</p>
<p>And imagine the fun of auditing Hoon for potential security holes in
an update, if you were paranoid. Just the thought is hilarious.</p>
<p>Urbit:security â€“ 0:1</p>
<h2 id="urbit-id--scarcity-creates-value-and-you-pay-a-premium-for-that">Urbit ID â€“ scarcity creates value, and you pay a premium for that</h2>
<p>So I watch in great amazement the booming ecosystem of cryptocurrencies
of different shapes and colors, and of all things blockchain.</p>
<p>Urbit ID is even better than all of them, though.</p>
<p>You see, the entire identity address space is artificially constrained
to 32bit integers<sup><a href="#fn10" id="fnref10">10</a></sup>.</p>
<p>And according to the Urbit promoters and backers, <em>scarcity creates value</em>.</p>
<p>Just like that.</p>
<p>No need for demand or anything. Itâ€™s scarce, hence it has value. Done<sup><a href="#fn11" id="fnref11">11</a></sup>.</p>
<p>The fact that a desperate enough person could do an equivalent of a hard
fork, and run it independently with a different Identity root isâ€¦
impossible?</p>
<p>Whatever.</p>
<p>But anyway, letâ€™s say you â€¦</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://wejn.org/2021/02/urbit-good-bad-insane/">https://wejn.org/2021/02/urbit-good-bad-insane/</a></em></p>]]>
            </description>
            <link>https://wejn.org/2021/02/urbit-good-bad-insane/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26177720</guid>
            <pubDate>Thu, 18 Feb 2021 09:22:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Reflections on Using Haskell for My Startup]]>
            </title>
            <description>
<![CDATA[
Score 41 | Comments 16 (<a href="https://news.ycombinator.com/item?id=26176940">thread link</a>) | @_query
<br/>
February 17, 2021 | https://alistairb.dev/reflections-on-haskell-for-startup/ | <a href="https://web.archive.org/web/*/https://alistairb.dev/reflections-on-haskell-for-startup/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p>Almost exactly one year ago I quit my job to create a Haskell startup as a solo developer. I had about 20 ideas, but eventually settled on the idea of dependency project health tracking with <a href="https://deadpendency.com/" target="_blank" rel="noopener">Deadpendency</a>.</p>

<p>This post describes the experience and evaluates Haskell and its ecosystem.</p>

<p><small>Disclaimer: This blog post contains a bunch of memes. They are trying to be humorous, not accurate or fair ğŸ˜‰.</small></p>

<h2 id="why-haskell">Why Haskell?</h2>

<p>Since about 2016 I have had a strong <del>obsession</del> love of Haskell. Prior to learning Haskell, I was an experienced OO style developer but I didnâ€™t really know how to keep improving my raw programming ability. Haskell introduced me to the world of functional programming (FP) which has an almost infinite depth of concepts to learn, which do actually help improve code quality and application architecture.</p>

<p><img width="400" src="https://i.imgflip.com/4x9eeq.jpg" alt="I should learn functional programming meme"></p>

<p>Haskell is challenging to learn, but extremely fun to write. For my own learning and pleasure, if my startup succeeds, I want to be doing Haskell.</p>

<p>Additionally, I think Haskell is the best general purpose programming language (that you can use in production). In particular, Haskell excels at writing â€˜boringâ€™ business applications which is typically what I work on. <a href="https://www.foxhound.systems/blog/why-haskell-for-production/" target="_blank" rel="noopener">â€˜Why Haskell For Productionâ€™</a> goes into more detail on the benefits Haskell offers.</p>

<p><img width="400" src="https://i.imgflip.com/4x9fwz.jpg" alt="Haskell is the best change my mind meme"></p>

<h2 id="the-setup-phase">The Setup Phase</h2>

<p>Probably the most challenging part was building out a skeleton architecture to hang my business logic on. I decided to go with, even within Haskell, fairly advanced libraries of <a href="https://docs.servant.dev/en/stable/" target="_blank" rel="noopener"><code>servant</code></a> and <a href="https://hackage.haskell.org/package/fused-effects" target="_blank" rel="noopener"><code>fused-effects</code></a>.</p>

<p>I spent a fair amount of time banging my head against a wall trying to get these libraries to work nicely together. This was primarily from a lack of Haskell ability on my part. I had prepared as best I could, but Haskell is deep and I needed to learn more to work day to day with it. I was lucky enough to eventually find <a href="https://github.com/mitchellwrosen/hspolls" target="_blank" rel="noopener">an example</a> that marries these two libraries together, which was a life saver. Iâ€™m sure I would have gotten there eventually, but I was in a bit over my head at that point.</p>

<p><img width="400" src="https://i.imgflip.com/4x9j14.jpg" alt="Haskell with servant fused-effects is hard meme"></p>

<p>Haskell is awesome, but like most languages there is cruft and legacy to be avoided. Haskell has a standard library known as <a href="https://hackage.haskell.org/package/base" target="_blank" rel="noopener"><code>base</code></a> which unfortunately has a fair amount of unsafe or unperformant functions included. As such I went with an alternative standard library <a href="https://hackage.haskell.org/package/relude" target="_blank" rel="noopener"><code>relude</code></a> that builds on and improves <code>base</code>. On top of this, there are many core libraries that are not part of the standard library I wanted to use and have nice patterns around.</p>

<p>Additionally, I was <a href="https://alistairb.dev/haskell-on-google-cloud-is-great">deploying to google cloud</a> and so needed to figure out good patterns for that integration from Haskell.</p>

<p>This setup effort was quite challenging. I spent most of it squinting at compiler errors. Yet it only took about 2 weeks to have a good foundation of code to start building my business logic upon.</p>

<h2 id="building-it-out">Building it Out</h2>

<p>This is when it started to get really fun. I had my core patterns set out and I could focus on building a pipeline. The day in day out of writing out my logic as small pure functions that I composed together was very nice.</p>

<p>Haskell has such impressive auto-magic code generation techniques that you spend much more time focused on the interesting logic of your application rather than boilerplate.</p>

<div><div><pre><code><span>data</span> <span>HappinessLevel</span> <span>=</span>
    <span>Miserable</span>
  <span>|</span> <span>Sad</span>
  <span>|</span> <span>Average</span>
  <span>|</span> <span>Happy</span>
  <span>|</span> <span>HaskellDeveloper</span>
  <span>deriving</span> <span>(</span><span>Show</span><span>,</span> <span>Eq</span><span>,</span> <span>Ord</span><span>,</span> <span>Bounded</span><span>,</span> <span>Enum</span><span>,</span> <span>ToJSON</span><span>,</span> <span>FromJSON</span><span>)</span> <span>-- magic code generation</span>

<span>-- ok not really magic, think 'convention over configuration'</span>
<span>-- where you can have generated sane defaults, or customise if you like</span>
</code></pre></div></div>

<p>And personally I think Haskell is quite beautiful to read and write. #notbiased</p>

<h3 id="parsing-libraries">Parsing Libraries</h3>

<p>A lot of the logic of Deadpendency is parsing. Either parsing dependency files or parsing various API responses. Haskell has many excellent parsing libraries, most notably <a href="https://hackage.haskell.org/package/aeson" target="_blank" rel="noopener"><code>aeson</code></a> for JSON.</p>

<p>Why is this nice in Haskell? The â€˜monadâ€™ abstraction is excellent for dealing with code with a lot of failure conditions (ie. parsing) and avoids â€˜pyramid of doomâ€™ type code. Haskell worked out really well in this key area.</p>

<p><img width="400" src="https://alistairb.dev/images/hadouken.jpeg" alt="Pyramid of doom meme"></p>

<h3 id="testing">Testing</h3>

<p>Another strong positive for writing Deadpendency was testing. Haskell has a lesser-known style of testing libraries that do â€˜property based testingâ€™ (PBT).</p>

<p>PBT allows you to write value generators for your data types, which you use to generate 100s or 1000s of test cases. Then, you run these generated values against some function and check that certain properties hold.</p>

<p>For example, part of the Deadpendency logic is generating an HTML report at the end. I had some <code>toHtml :: Report -&gt; HTML</code> function that I wanted to test. So I wrote a <code>fromHtml :: HTML -&gt; Report</code> function where it goes the other way (ok writing that was pretty painful). Then my PBT test will generate 100s of <code>Report</code> values and check that <code>report == fromHtml (toHtml report)</code> (this is known as â€˜roundtrip testingâ€™). With this single test I was able to find many edge case bugs with my HTML report generation logic.</p>

<p><img width="400" src="https://i.imgflip.com/4x9tqj.jpg" alt="Haskell with servant fused-effects is hard meme"></p>

<p>PBT exists in some other languages, but it originated (I believe?) in Haskell so the libraries are excellent.</p>

<h3 id="not-actively-maintained-libraries">Not Actively Maintained Libraries</h3>

<p>A big challenge of working with Haskell was the lack of well-maintained libraries. Ironically, of the 75 (!) packages I depend upon 19 are flagged by Deadpendency as unhealthy (deprecated or inactive). This means I often donâ€™t have the luxury of asking library maintainers to fix bugs. Even if I PR a fix, sometimes that PR will be ignored for months.</p>

<p>This I think is the reality of using a niche language like Haskell. To be clear, I do not think library developers owe me anything, but it is nonetheless a downside when compared to more popular languages.</p>

<p><img width="400" src="https://i.imgflip.com/4x9xjq.jpg" alt="Haskell not actively maintained meme"></p>

<p>Thankfully Haskell build tools have good support for loading a package from git. This means you can PR some bug fix or feature and immediately use your fork to work around the problem.</p>

<h3 id="compile-times-were-fine">Compile Times.. Were Fine</h3>

<p>I thought Iâ€™d call this out as it is a common complaint I see around Haskell. I followed some <a href="https://www.parsonsmatt.org/2019/11/27/keeping_compilation_fast.html" target="_blank" rel="noopener">good advice</a> which kept compilation fast (aside from <a href="https://twitter.com/AlistairBuzz/status/1253507016242294784" target="_blank" rel="noopener">one interesting edge case I resolved</a>).</p>

<ul>
  <li>Number of modules (Haskell source files) - 509</li>
  <li>Number of lines of Haskell - 20090</li>
  <li>Number of dependencies - 75</li>
  <li>Dell 9570 XPS Laptop - (Hex core - 8th-gen Intel Core i7-8750H CPU), 32GB memory</li>
</ul>

<p>So what are the numbers?</p>

<h4 id="compile-dependencies-from-scratch">Compile dependencies from scratch</h4>

<p>Time: 17m44s</p>

<p>This is compiling all application dependencies, which needs to be done before you can compile your application code. Rebuilding all from scratch rarely happens as both my dev machines and CI will cache and only rebuild what has changed.</p>

<p>You do sometimes update a very core package which triggers a lot of dependent packages to recompile which can take a while. Although, I usually do dependency updates at the start of the day while Iâ€™m sipping my coffee, so usually donâ€™t notice.</p>

<h4 id="compile-app-including-tests-in-development">Compile app (including tests) in development</h4>

<p>Time: 1m1s</p>

<p>Likewise, due to caching a full recompilation rarely happens. As such, most code edits do not trigger many modules to be recompiled and it is fast.</p>

<p>Additionally, Haskell has nice â€˜continuous compilationâ€™ tools that fire on save. Usually by the time I actually look at my terminal compilation is already done.</p>

<h4 id="compile-app-for-deployment">Compile app for deployment</h4>

<p>with <a href="https://downloads.haskell.org/~ghc/latest/docs/html/users_guide/using-optimisation.html" target="_blank" rel="noopener">full optimisations</a> (-02).</p>

<p>Time: 2m53s</p>

<p>This typically runs in CI. It runs in parallel with a host of other checks such as running my tests, which also take a few minutes. Due to this, the time doesnâ€™t really impact the build + deploy time too much.</p>

<p><img width="400" src="https://i.imgflip.com/4xp4zu.jpg" alt="Compile times meme"></p>

<h3 id="refactoring-pain">Refactoring Pain</h3>

<p>Deadpendency is relatively simple in what it does, but there is a lot of hidden complexity to the problem. Which is to say, it is like 99% of applications ğŸ˜‰. When developing it I was constantly realising I had modelled things a bit too simplistically and would need to refactor.</p>

<p>Haskell is very safe to refactor thanks to the type safety the compiler brings, which is probably the most important thing. However, Haskell does not have great tools to help with refactoring, at least in terms of the restructuring changes I kept making. The <a href="https://hackage.haskell.org/package/apply-refact" target="_blank" rel="noopener">existing</a> <a href="https://hackage.haskell.org/package/retrie" target="_blank" rel="noopener">tools</a> seem more geared towards complex rewriting of common code, not restructuring modules or renaming identifiers.</p>

<p>As such I did it all manually with text search replace, or just change something and fix all the new compiler errors. This was a bit of a grind and it caused me to delay needed refactoring sometimes.</p>

<p>Itâ€™s a pity Haskell doesnâ€™t have the refactoring tools to help in this situation. The dream would be these tools integrated into an IDE.</p>

<p><img width="400" src="https://i.redd.it/dbdshzzflgd31.jpg" alt="Haskell had an IDE meme"></p>

<p>(Stolen from <a href="https://www.reddit.com/r/ProgrammerHumor/comments/cjtbfj/society_if_haskell_has_ide/" target="_blank" rel="noopener">reddit</a>)</p>

<p>Having said that, it should be noted that Haskell does have an excellent IDE now in the form of <a href="https://github.com/haskell/haskell-language-server" target="_blank" rel="noopener">Haskell Language Server</a> (HLS). The momentum around the project is insane and I applaud the developers. One fixed pain point from HLS is it does auto imports now, which used to greatly contribute to the friction of working with Haskell. Iâ€™m sure Haskell will get there eventually.</p>

<h3 id="waiting-for-new-ghc-versions-to-be-usable">Waiting for New GHC Versions to be Usable</h3>

<p>This is mostly me complaining for the sake of it, but as someone pretty obsessed with both new shiny versions of things and Haskell, waiting for new GHC (GHC is the Haskell compiler) versions to be usable has been painful. There is a long tail of libraries and platforms that need to be updated before I can use a new GHC version. Sometimes these updates can drag a lot.</p>

<p>For example GHC 9 was just released, but I still havenâ€™t been able to upgrade to GHC 8.10 yet which was first released in March 2020.</p>

<p><img width="500" src="https://i.imgflip.com/4xebid.jpg" alt="GHC releases meme"></p>

<h2 id="launching">Launching</h2>

<p>So after about 8 months of work I was ready to start getting users. I slowly soft launched, promoting it in a few small channels. How did my Haskell fair in prod?</p>

<h3 id="very-few-logic-bugs">Very Few Logic Bugs</h3>

<p>My core Haskell had very few logic bugs. This is because Haskell is very safe by default and I had opted into strict types that help catch edge cases.</p>

<p>For example, I was using a lot of <a href="https://hackage.haskell.org/package/base-4.14.1.0/docs/Data-List-NonEmpty.html" target="_blank" rel="noopener"><code>NonEmpty</code></a> lists which the compiler will guarantee is not empty. To use them you must specify how to handle the empty case. ie. what do I do if Deadpendency canâ€™t find any dependencies to check?</p>

<p>And of course, I had â€¦</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://alistairb.dev/reflections-on-haskell-for-startup/">https://alistairb.dev/reflections-on-haskell-for-startup/</a></em></p>]]>
            </description>
            <link>https://alistairb.dev/reflections-on-haskell-for-startup/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26176940</guid>
            <pubDate>Thu, 18 Feb 2021 07:17:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[TLS certificates specifying hosts via the CommonName field is more or less gone]]>
            </title>
            <description>
<![CDATA[
Score 62 | Comments 21 (<a href="https://news.ycombinator.com/item?id=26176448">thread link</a>) | @zdw
<br/>
February 17, 2021 | https://utcc.utoronto.ca/~cks/space/blog/tech/TLSCertificateCNMostlyGone | <a href="https://web.archive.org/web/*/https://utcc.utoronto.ca/~cks/space/blog/tech/TLSCertificateCNMostlyGone">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><h2>TLS certificates specifying hosts via their CommonName field is more or less gone</h2>

	<p><small>February 17, 2021</small></p>
</div><div><p><a href="https://en.wikipedia.org/wiki/Transport_Layer_Security">TLS</a>
certificates for hosts and domains must somehow identify what
hostname (or names) they're for. Historically <a href="https://utcc.utoronto.ca/~cks/space/blog/tech/TLSCertificatesNamingHosts">there have been two
ways to do this</a>. The first way was a
specific sub-field, the <em>CN</em> or CommonName, of the certificate's
overall <em>Subject Name</em>. This had the problem that it could only
have one name. When people started wanting to have TLS certificates
that covered more than one name, they invented another mechanism,
the <em>Subject Alternative Name</em> (SAN) extension.</p>

<p>As a practical matter, all vaguely modern software that wants to
properly validate TLS certificates has supported (and often preferred)
Subject Alternative Names for some time. A great many TLS certificates
in the wild are for multiple hosts and it's generally unlikely that the
host you're connecting to is the one name that the system chose to put
in the CN field; software that only supports CN cannot validate those
TLS certificates. As a matter of timing, SANs have been theoretically
mandatory since 2002 and checking only SANs has been theoretically
required since 2011 (which means that since 2011 or earlier, the CN was
supposed to always be one of the SANs).</p>

<p>These days, any remaining support for looking at TLS certificate
CommonName to validate TLS certificates is getting more and more
extinct (and more so than I expected when I started writing this
entry). In the browser realm, <a href="https://www.chromestatus.com/feature/4981025180483584">Chrome apparently turned it off in
58, released in 2017</a>, and then
threw out the option to check it again in Chrome 65 (from the comment
on <a href="https://utcc.utoronto.ca/~cks/space/blog/tech/TLSCertificatesNamingHosts">my old entry</a>, which was ironically
written shortly before Chrome did this). Firefox is said to have
removed support in version 48, from August of 2016. <a href="https://support.apple.com/en-ca/HT210176">Safari
apparently stopped looking at CommonName in iOS 13 and macOS 10.15</a>, which I believe date
from late 2019. <a href="https://go-review.googlesource.com/c/go/+/231379">This Go change</a> also talks about
how browsers removed it in 2019 ('last year' for a mid 2020 change).</p>

<p>In non-browser TLS code, Go started ignoring CN by default in
Go 1.15 (released in August of 2020) and this will be the only
option starting in Go 1.17 (to be released in August of 2021),
per <a href="https://golang.org/doc/go1.16#crypto/x509">here</a>. Since
Firefox doesn't support CN any more, I assume that <a href="https://en.wikipedia.org/wiki/Network_Security_Services">NSS</a> doesn't
either, since NSS is basically Firefox's underlying TLS implementation.
I have no idea what other TLS libraries are doing, but I would expect
that many of them will support CommonName for some time to come; TLS
libraries are historically behind browser practices.  Hopefully they
are all following the 2011 requirement to check only SANs when SANs are
present (which they should always be in public certificates).</p>

<p>Probably TLS certificates will continue to contain CommonName fields
for a long time to come. Having a <em>Subject Name</em> in general is
common (although apparently not actually required) and the CN is a
standard (although not required) part of the Subject Name, so you
might as well throw it in. Even Mozilla and Let's Encrypt (still)
have TLS certificates with CNs. However, since I checked this now,
the current <a href="https://cabforum.org/">CA/Browser Forum</a> <a href="https://cabforum.org/baseline-requirements-documents/">baseline
requirements</a>
(version 1.7.3) allow but don't require CommonName (section 7.1.4.2.2,
which says that it's 'discouraged, but not prohibited'). Given how
conservative most Certificate Authorities are, I expect them to be
issuing TLS certificates with CommonName fields until they're
required to stop.</p>

<p>(An interested party could scan Certificate Transparency logs to see if
there were very many issued certificates without CNs. Probably there are
some; someone must have tried it out at some point through an official
CA.)</p>

<p>PS: <a href="https://no-common-name.badssl.com/">no-common-name.badssl.com</a>
has a TLS certificate without a CN, or at least it's supposed to
(<a href="https://community.letsencrypt.org/t/how-to-obtain-a-cert-without-a-common-name/72807/6">via</a>),
but the TLS certificate is expired right now as I write this entry
so it's hard to test how client software behaves. <a href="https://community.letsencrypt.org/t/compatibility-testing-of-no-common-name/72863">See also</a>,
which pointed me to <a href="https://no-subject.labs.vu.nl/">no-subject.labs.vu.nl</a>,
which has a currently valid TLS certificate with no <em>Subject Name</em> at all.</p>
</div></div>]]>
            </description>
            <link>https://utcc.utoronto.ca/~cks/space/blog/tech/TLSCertificateCNMostlyGone</link>
            <guid isPermaLink="false">hacker-news-small-sites-26176448</guid>
            <pubDate>Thu, 18 Feb 2021 05:54:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Extract Tables by Docsumo]]>
            </title>
            <description>
<![CDATA[
Score 13 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26175273">thread link</a>) | @amitness
<br/>
February 17, 2021 | https://docsumo.com/free-tools/extract-tables-from-pdf-images | <a href="https://web.archive.org/web/*/https://docsumo.com/free-tools/extract-tables-from-pdf-images">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content-tool"><div><div><p>Automated table extraction from pdf &amp; images</p><div><div><p>Thank you! Your submission has been received!</p></div><div><p>Oops! Something went wrong while submitting the form.</p></div></div><div><p>It doesn't support in mobile view. <br>You can copy the link and view it in your desktop.</p></div><div id="rating-section"><div id="rating-block"><div><div><p>Thank you! Your submission has been received!</p></div><div><p>Oops! Something went wrong while submitting the form.</p></div></div></div></div></div></div><div><p>How it works?</p><div><div><p><img src="https://assets.website-files.com/5f605b07a820602f886fc4ba/5faa7831743ca77a6aa3ee11_Choose%20File.png" loading="lazy" width="93" alt=""></p><div><p>1. Choose File</p><p>Select or drop the files you want to convert.<br></p></div></div><div><p><img src="https://assets.website-files.com/5f605b07a820602f886fc4ba/5faa628aeb96926ffa789a4f_edit%20%20and%20review.png" loading="lazy" width="101" alt=""></p><div><p>2. Edit &amp; Review</p><p>Review the extracted information in the review panel and make changes if needed.</p></div></div><div><p><img src="https://assets.website-files.com/5f605b07a820602f886fc4ba/5faa629ae8714b4bf57f0719_Convert%20%26%20Download.png" loading="lazy" width="101" alt=""></p><div><p>3. Convert &amp; Download</p><p>Download the converted file. Right after that, the input file is removed from our server.</p></div></div></div></div><div><p>Extract tables from PDF/Images</p><p>Save your crucial time and prevent any error from occurring with Docsumo's free table extraction from a PDF/Image tool. With this tool, extract tables from PDF documents and images in real-time with 100% accuracy.</p></div><div><p>Questions we often hear</p><p>Let's look at the answers</p><div><div role="list"><div role="listitem"><div><div><div><h4>Why do I need to extract tables from a PDF document?</h4></div><p>Tables are cleaner data format, and often you need only the data from tables embedded in a pdf document. That's why, businesses find it useful to extract tables from pdf documents and process the data.</p></div></div></div><div role="listitem"><div><div><div><h4>Do I need to train this free table extractor from pdf tool?</h4></div><p>The efficiency of Artificial Intelligence and Machine Learning technology improves with number of sample documents processed. So, it is highly recommended to have at least couple of sample documents ready for training.</p></div></div></div><div role="listitem"><div><div><div><h4>What fields does it capture?</h4></div><p>The tool lets you capture any text based field. The tool allows you to review the extracted data before downloading the output.</p></div></div></div><div role="listitem"><div><div><div><h4>Can I convert my document without installing the software?</h4></div><p>Documo's free online OCR tool is capable of processing any document online with complete accuracy. So, there is no need to install the tool on your system.</p></div></div></div><div role="listitem"><div><div><div><h4>Is my data secure with Docsumo?</h4></div><p>Docsumo doesn't sell or share your data to any third-party person or organization. Your data is completely secure and confidential.</p></div></div></div><div role="listitem"><div><div><div><h4>Is there any limit on using the tool?</h4></div><p>There's no usage limit on our free tool. No payment required and no credit card details needed. Sign up with us to get access to more of our resources.</p></div></div></div></div></div></div><div><h2>What Our Customers Are Saying</h2><div><div data-animation="slide" data-nav-spacing="4" data-duration="500" data-infinite="1"><div><div><div><p><img src="https://assets.website-files.com/5f605b07a820602f886fc4ba/5f61bd1ba58812799fe2bd13_paysense.svg" loading="lazy" height="" alt=""></p><p>â€œWe are using Docsumoâ€™s APIs for automating data capture from bank statements and identity cards while on-boarding customers. It has reduced the time our operations team spends on data entry by manifolds while providing a much better customer experience.â€</p><p>Prashanth Ranganathan</p><p>CEO, Paysense.com</p></div></div><div><div><p><img src="https://assets.website-files.com/5f605b07a820602f886fc4ba/5f61bd1b531b085edc6c1cbf_Onez.jpeg" loading="lazy" height="" width="25" alt=""></p><p>Since the very beginning everything was fine, they always say â€œAsk anything even if you need support from our developers. The support for initial user was exceptional, even for small users like me.</p><div><p>Dario G</p><p>Operations Manager, Onerz</p></div></div></div><div><div><p><img src="https://assets.website-files.com/5f605b07a820602f886fc4ba/5f61bd1bf817cf304f90e758_dhanwise.svg" loading="lazy" height="" alt=""></p><p>"With Docsumo we were able to automate invoice processing completely. It has reduced invoice processing time from hours to minutes. Since there is no data entry required, our data extraction accuracy has improved. We highly recommend Docsumo to everyone. "</p><p>Subodh Malgonde</p><p>CEO, DhanWise.com</p></div></div></div></div></div><a href="https://docsumo.com/case-studies"><p>View more Customers Stories</p><img src="https://assets.website-files.com/5f605b07a820602f886fc4ba/5f62f7ab382b1fa34db4108a_arrow.svg" loading="lazy" height="" alt=""></a></div><div id="free-trial-form"><div><div><div><h2>Start your free trial</h2><p>Weâ€™d love to show you how you can increase your productivity, process your documents faster and save operations cost!</p></div></div><div><div><div id="formId"><div><p>Thank you! Your submission has been received!</p></div><div><p>Oops! Something went wrong while submitting the form.</p></div></div></div></div></div></div></div></div>]]>
            </description>
            <link>https://docsumo.com/free-tools/extract-tables-from-pdf-images</link>
            <guid isPermaLink="false">hacker-news-small-sites-26175273</guid>
            <pubDate>Thu, 18 Feb 2021 03:29:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[40 Year History of Opposition to Nuclear Power in California]]>
            </title>
            <description>
<![CDATA[
Score 47 | Comments 39 (<a href="https://news.ycombinator.com/item?id=26175253">thread link</a>) | @Lammy
<br/>
February 17, 2021 | https://www.energy-net.org/01NUKE/CALIF.HTM | <a href="https://web.archive.org/web/*/https://www.energy-net.org/01NUKE/CALIF.HTM">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div width="49%"> 
	  <p><span face="Verdana, Arial, Helvetica, sans-serif" size="2" color="#CC6600"><b><span size="3" color="#000000">40 
		Year History of Opposition to Nuclear Power in California </span></b></span> 
		<br>
	  </p>
	  <p><span face="Verdana, Arial, Helvetica, sans-serif" size="2">California 
		citizens have made a unique stand concerning the attempts by Nuclear proponents 
		to make the state a premiere model for commercial nuclear energy. California's major 
		utilities, in particular Pacific Gas and Electric (PG&amp;E) has spent an
		enormous amount of money and political muscle in attempts to build reactors 
		across California but have mostly failed. PG&amp;E was supposedly involved in 
		the Atoms for Peace proposal made in 1953 and was 
		part of a coalition of american utilities that investigated the technical 
		potentials for building nuclear reactors as a source of electricity.</span></p>
	  <p><span face="Verdana, Arial, Helvetica, sans-serif" size="2">The following 
		is a brief summary of the battles against nuclear power that started here 
		in California in 1958.</span></p>
	  <p><span face="Verdana, Arial, Helvetica, sans-serif" size="2">Northern 
		California is the home of the first successful opposition to the promotion 
		and development of commercial nuclear reactors in the U.S. In the 1950's 
		northern and central California's privately Owned utility company, PG&amp;E 
		was planning to be one of the giants in the new field of nuclear energy. 
		It had helped design and build the Dresden I reactor in Illinois with 
		a consortium of 5 major companies, including General Electric(GE).</span></p>
	  <p><span face="Verdana, Arial, Helvetica, sans-serif" size="2">In conjunction 
		with GE, it built the vallecitos nuclear complex south of San Francisco 
		and then went it alone with their Humboldt reactor near Arcata. But their 
		luck took a turn for the worse when they tried to build the world's largest 
		nuclear facility 1000 feet from the fault that caused the 1906 earthquake.</span></p>
	  <p><span face="Verdana, Arial, Helvetica, sans-serif" size="2">Yes, PG&amp;E 
		even said they could build a reactor in downtown San Francisco! In 
		fact they were planning the construction of 63 reactors in California 
		during the early 1960's, one every 25 miles along the coast They even 
		 planned to build a floating reactor!!</span></p>
	  <h2><span face="Verdana, Arial, Helvetica, sans-serif" size="2"><b>The 
		Bodega Bay Duck Pond</b><br>
		</span></h2>
	  <p><span face="Verdana, Arial, Helvetica, sans-serif" size="2">When PG&amp;E 
		started pushing plans to build the reactors at Bodega Pay in 1958 a literal 
		groundswell of opposition erupted during the next 6 years to stop them 
		dead cold. The site they had chosen near the San Andreas Fault Zone was 
		just a few miles from the epicenter of the Great San Francisco Quake where 
		ground shifts of over 20 feet had occurred in 1906.</span></p>
	  <p><span face="Verdana, Arial, Helvetica, sans-serif" size="2">PG&amp;E's 
		unethical plans to build the reactor is not new for this company, as they 
		have a history of unfair tactics that goes back to the company's birth. 
		Upon deciding that the Bodega Headlands would be an excellent site for the largest nuclear 
		facility in the world, PG&amp;E simply beat the state out in its plans 
		to make the area a state park. </span></p>
	  <p><span face="Verdana, Arial, Helvetica, sans-serif" size="2">The battle 
		started in 1958 when the Santa Rosa Press Democrat published the first 
		story on PG&amp;E's plans. The company's ignored their own geologist, who had warned 
		that the area was likely to be effected by strong shaking during a quake. 
		Concerned citizens started getting involved as PG&amp;E refused to acknowledge 
		publicly that they were actually going to build nuclear reactors at the 
		proposed site.</span></p>
	  <p><span face="Verdana, Arial, Helvetica, sans-serif" size="2">The 1957 
		windscale accident in England, where a small reactor had burned out of 
		control for more than a day, helped focus concerns about safety on this 
		new idea of nuclear power.</span></p>
	  <p><span face="Verdana, Arial, Helvetica, sans-serif" size="2">In 1961, 
		after nearly 3 years of pushing their plan behind the scenes, PG&amp;E 
		announced plans to build the Atomic Park at the Bodega site. The ensuing battle 
		and PG&amp;E's nasty style started to backfire though as public concerns 
		grew.</span></p>
	  <p><span face="Verdana, Arial, Helvetica, sans-serif" size="2">Major opposition 
		came from within the ranks of the Sierra Club, but the board refused to 
		allow its active members the right to oppose the reactors on the issue 
		of earthquakes. When it came out that PG&amp;E had doctored fault maps 
		of the site, all hell broke loose.</span></p>
	  <p><span face="Verdana, Arial, Helvetica, sans-serif" size="2">One of PG&amp;E's 
		major claims at the time was that they could build reactors that would 
		survive a great Earthguake. At one point they said that the reactors could 
		survive a quake 50 per cent bigger than the O6' quake by floating the 
		reactors on 3 feet of compressable material but when the public and the 
		Atomic Energy Commission (AEC) got a close-up view of the devastation 
		from the air of the quake in Alaska during the spring of 1964, support 
		for the reactor complex dried up.</span></p>
	  <p><span face="Verdana, Arial, Helvetica, sans-serif" size="2">Opponents 
		had "infiltrated" the federal government and were pushing 
		for closure. With the disclosure of the AEC's WASH 740 report, which documented 
		potential dangers to the bay area residents in case of an accident, opposition 
		finally reached all government levels.</span></p>
	  <p><span face="Verdana, Arial, Helvetica, sans-serif" size="2">California 
		governor Pat Brown asked that PG&amp;E abandon the reactors. Two days 
		later PG&amp;E caved in and called the project off. The battle ended in 
		1964 with a $7 million duck pond as a living monunent to the future. (It 
		is still there today)</span></p>
	  <p><span face="Verdana, Arial, Helvetica, sans-serif" size="2">This experience 
		gave PG&amp;E a deadly lesson on how to overcome public concerns at their 
		next reactor site--Diablo Canyon.</span></p>
	  <h2><span face="Verdana, Arial, Helvetica, sans-serif" size="2"><b>The 
		Diablo Canyon Nightmare:</b><br>
		</span></h2>
	  <p><span face="Verdana, Arial, Helvetica, sans-serif" size="2">The 25 year 
		battle over Diablo Canyon is a classic case of courage in the face of 
		the political power this utility unleashed in its drive to build a major 
		nuclear facility in California.</span></p>
	  <p><span face="Verdana, Arial, Helvetica, sans-serif" size="2">PG&amp;E's 
		plans to build a mega facility shifted south to the less populated coastal 
		area near San Luis Obispo. The company purchased the Nipomo Dunes and 
		told environmental leaders that unless an acceptable site was chosen that 
		they would go ahead and build a facility at the popular beach area. The 
		wife of the Sierra Club president was selected to come up with an acceptable 
		site in secrecy with the company. </span></p>
	  <p><span face="Verdana, Arial, Helvetica, sans-serif" size="2">The site 
		chosen, Diablo Canyon, was California's second to last coastal wilderness 
		area, an area that had been proposed as a National Park due to its beauty. 
		Besides being a sacred Chumash burial ground, it was the home of one of 
		a kind 1,000 year old Oak trees (the largest in the world). It was also 
		the home of one of the state's largest populations of abalone and sea 
		otters.</span></p>
	  <p><span face="Verdana, Arial, Helvetica, sans-serif" size="2">In the process 
		of getting permission to go ahead with Diablo, PG&amp;E suceeded in selling 
		the site to key members of the Sierra Club's board of directors. The Utility 
		had sympathetic board members flown over the Diablo site in Frank Sinatra's 
		Lear jet, with entertainment by Danny Kaye (Danny later came out against 
		the reactors).</span></p>
	  <p><span face="Verdana, Arial, Helvetica, sans-serif" size="2">The first 
		slam-dunk by PG&amp;E came against the local farmer who had the right 
		of way access rights over the Diablo property. The company went to court 
		and had his rights removed. The beligerant act made the man a life-long 
		opponent of PG&amp;E's plan.</span></p>
	  <h2><span face="Verdana, Arial, Helvetica, sans-serif" size="2"><b>PG&amp;E 
		gets Cozy with Sierra Club Board Members</b><br>
		</span></h2>
	  <p><span face="Verdana, Arial, Helvetica, sans-serif" size="2">The biggest 
		tactical plan was to focus on the Sierra Club. The company and the electric 
		industry already had the board's ear with their claims that nuclear power 
		could reduce air pollution that was caused by coal power plants. The utility, 
		with inside help then sought official support for Diablo Canyon when club's 
		only board member who knew about the site's natural value was in Europe. 
		The board went along with PG&amp;E, and in fact voted to block any Club 
		members or chapters opposition to the facility. This move enraged David 
		Brower, eventually resulting in the split up of the club and the creation 
		of Friends of the Earth by embittered Sierra Club members who were angered 
		by the actions of key Sierra Club Board members.</span></p>
	  <p><span face="Verdana, Arial, Helvetica, sans-serif" size="2">PG&amp;E's 
		success within the Sierra Club was the culmination of 2 years of behind 
		the scenes work by Doris Leonard. She was the wife of the president of 
		the club. Her role in exchanging the Nipomo Dunes site for Diablo Canyon 
		was rewarded later when she was elected to PG&amp;E's board of directors. 
		</span></p>
	  <p><span face="Verdana, Arial, Helvetica, sans-serif" size="2">The Sierra 
		Club refused to allow its local chapter near Diablo to use the club nane 
		in opposing the five proposed reactors at the site. The group was forced 
		to take on another name in 1966, the Shoreline Preservation Conference.</span></p>
	  <p><span face="Verdana, Arial, Helvetica, sans-serif" size="2">The group 
		was concerned about earthquake faults along the coast as locals were fully 
		aware of the 1927 quake that completely destroyed a nearby city. They 
		called for a full investigation into potential fault areas. Their efforts 
		were ignored by the government and the media.</span></p>
	  <p><span face="Verdana, Arial, Helvetica, sans-serif" size="2">News of the 
		reactor siting was poorly covered by the Bay area's conservative media, 
		a tactic that made the issue invisible to bay area residents who had stopped 
		PG&amp;E's Bodega reactor plans.</span></p>
	  <p><span face="Verdana, Arial, Helvetica, sans-serif" size="2">Oil companies 
		chart the Hosgri Fault The Hosgri fault had been mapped by Shell oil geologists 
		during the 1960's, but not published until 1970. PG&amp;E claims to have 
		not found out about the fault until late 1972. The information was finally 
		publicized in November 1973 by an investigative reporter in Los Angeles. 
		In a suspicious turn of events, the lawyer who had been fighting the case 
		since 1965 was found dead in his car just after the announcement. Authorities 
		claimed it was suicide, with no other investigation to follow up.</span></p>
	  <p><span face="Verdana, Arial, Helvetica, sans-serif" size="2">P&amp;GE's 
		bad memories of Bodega Bay helped fuel their push to ignore earthquake 
		concerns at Diabl Canyon. The same Seismic experts who had been involved 
		with the Bodega Bay facility were brought in to review the site for seismicity. 
		They pointed out major flaws in PG&amp;E's own $2,000 seismic study. A 
		state of the art study at the time would have cost $100,000)</span></p>
	  <h2><span face="Verdana, Arial, Helvetica, sans-serif" size="2"><b>The 
		Hosgri Fault Forces PG&amp;E to Rebuild Diablo Again</b><br>
		</span></h2>
	  <p><span face="Verdana, Arial, Helvetica, sans-serif" size="2">A storm of 
		controversy erupted around the facility as one of the units was reaching 
		completion. Even with the help of the Nuclear Regulatory Commission's 
		(NRC) predecessor, the AEC, PG&amp;E was finally forced after 3 years 
		of federal in-fighting to rebuild seismic bracing in 1976.</span></p>
	  <p><span face="Verdana, Arial, Helvetica, sans-serif" size="2">In attempts 
		to stop a seismic retrofit, PG&amp;E even coined the Tao Effect which 
		said that the bigger the structure, the less damage a quake would have.</span></p>
	  <p><span face="Verdana, Arial, Helvetica, sans-serif" size="2">Seismic experts 
		for the concerned activists remained uninpressed, â€¦</span></p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.energy-net.org/01NUKE/CALIF.HTM">https://www.energy-net.org/01NUKE/CALIF.HTM</a></em></p>]]>
            </description>
            <link>https://www.energy-net.org/01NUKE/CALIF.HTM</link>
            <guid isPermaLink="false">hacker-news-small-sites-26175253</guid>
            <pubDate>Thu, 18 Feb 2021 03:28:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Building products â€“ Things I wish I knew when I started building products]]>
            </title>
            <description>
<![CDATA[
Score 9 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26173963">thread link</a>) | @gmays
<br/>
February 17, 2021 | https://amiltonpaglia.com/writing/building-products | <a href="https://web.archive.org/web/*/https://amiltonpaglia.com/writing/building-products">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="__next"><div><main><header></header><div><p>Nov 7, 2020, 21:00<!-- --> <svg width="16" height="16" style="position:relative;top:2px"><line x1="4" y1="16" x2="12" y2="2" style="stroke:#ccc"></line></svg> <time datetime="1604782800000">3 months ago</time></p></div><p>It's not a step by step guide but rather an attempt to synthesize my thinking about what it really matters to build great products.</p><p>I've been building products for the last 12 years. On this journey, I have been fortunate to have the opportunity to wear a lot of different hats in the making of a digital product.&nbsp;</p><p>I've worked as Interface designer, Front-end developer, UX Designer, Product Designer and lastly, as a Product Manager. All along the way, I've always had a close relationship with engineers, learning everything I could about development and understanding all the effort and creativity necessary to bring products to life.</p><p>To keep this valuable for a wider audience and range of professionals, I've tried to extract the essence of I believe to be essential to keep in mind when building products.</p><p>Loading...</p><h2>Purpose</h2><p><strong>Everything starts with a clear purpose.</strong></p><p>When building products, you have to be an<!-- --> <strong>eternal optimist about your missionâ€Š</strong> â€“ â€Što help you get through the rough times, and<!-- --> <strong>very pessimist about executionâ€Š</strong> â€“ â€Šit always takes way more time and effort to nail it.</p><p><strong>Build great products takes time; it's a long-term commitment.</strong> <!-- -->It's almost impossible (in my experience) to immerse yourself in a work whose purpose isn't aligned with your beliefs.</p><p>Without a clear purpose for you (and your team), it's tough to find an intrinsic motivation to keep iterating your product on a problem space.</p><p>Loading...</p><h2>Constraints</h2><blockquote>"...Here is one of the few effective keys to the Design problem: the ability of the Designer to recognize as many of the constraints as possible; his willingness and enthusiasm for working within these constraints. Constraints of price, of size, of strength, of balance, of surface, of time, and so forth. Each problem has its own peculiar list."<p>Charles &amp; Ray Eames</p></blockquote><p>I love this excerpt from an<!-- --> <a href="https://www.hermanmiller.com/stories/why-magazine/design-q-and-a-charles-and-ray-eames/">interview with Charles and Ray Eames</a> <!-- -->in 1972 about Design. This quote stayed on my mind since the first time I've read it.</p><p><strong>Embracing constraints is essential to creativity.</strong> The primary fuel to your problem-solving is to identify what restrictions you're dealing with.</p><p>Your purpose is what drives your "willingness and enthusiasm for working within these constraints." Once you have a clear purpose and goal in mind, you have to "identify as many constraints as possible" to have a clear problem space to tackle, and sometimes you need to enforce additional constraints.</p><p>I like to think about constraints in two spectrums:</p><ul><li>From <strong>hard constraints</strong> to<!-- --> <strong>self-imposed constraints</strong>;</li><li>From <strong>under constraint</strong> to<!-- --> <strong>over constraint</strong>;</li></ul><h3>Hard &amp; Self-imposed constraints</h3><p><strong>Hard constraints</strong> are the ones that you have little to no influence under it. It's time, resources, team, skills, funding, knowledge, market conditions, laws, available technology, and so on. It's the constraints that you'll have to work within, no matter what.</p><p><strong>Self-imposed constraints</strong> are the ones you set to have a clear problem space and increase your focus. It could come in different shapes. It could be your values, product principles, strategy, and everything else you and your team agree on that helps you stay on the right path. It's your conscious trade-offs.</p><h3>Under &amp; Over Constraints</h3><p><strong>An under constrained problem space will be too broad and challenging to narrow down what really matters.</strong> <!-- -->You'll see yourself drowned in the endless possibilities to solve problems. When you find yourself in this scenario, it's better to enforce new constraints and make trade-offs to eliminate noise.</p><p>On the other hand,<!-- --> <strong>when you over constrain it, you won't leave room for improvisation, innovation, and adaption when it's needed.</strong> <!-- -->You have to find a sweet spot on this spectrum to have the freedom to experiment.</p><p><strong>Identifying the right constraints and balancing them is an ongoing challenge.</strong> <!-- -->Your team will grow, new technologies will enable new solutions, markets, and users will continuously evolve.</p><p>You have to keep your eyes open to see what stays true and what helps you stay focused on what matters.<!-- --> </p><p>Loading...</p><h3>Shaping friction</h3><p><strong>Your goal when designing a product is to shape friction.</strong> <!-- -->You'll have to shape as many frictions as possible from your user's journey to achieve the desired outcome. Here are some examples:</p><ul><li><strong>Optimize your user acquisitionâ€Š</strong> â€“ remove friction from each step of the funnel;</li><li><strong>Improve engagementâ€Š</strong> â€“ remove friction to make core actions more intuitive and accessible;</li><li><strong>Reduce churnâ€Š</strong> â€“ â€Šremove friction that is keeping users away from their goals;</li><li><strong>Avoid unintended behaviorsâ€Š</strong> â€“â€Š Instagram adding features to avoid users (adding friction) to pos offensive content;</li><li>You got the pointâ€¦</li></ul><p><mark><strong>To identify which friction worth solving/shaping, you have to have a deep understating of your product and the people using it.</strong></mark> <!-- -->You'll have to know product goals and the user's job-to-be-done (context, objectives, functional and emotional needs).</p><p>In essence, your job is to continuously iterate, shape, and balance the right amount of friction on each part of the product.</p><h3>Prioritization &amp;&nbsp;Judgment</h3><p>Loading...</p><p><strong><mark>Prioritization is one of the most essential subjects in building products.</mark></strong></p><p>There are endless techniques, frameworks, mental models, and tools to help you make the right decisions when prioritizing your next move.</p><p>The truth is that it's tough to make the "best" decisions, even when you have lots of qualitative and quantitative insights (not the case for early-stage products) to inform your prioritization.</p><p><strong>Confident decision making takes time</strong>. When working on a high-growth startup, you'll have to be comfortable with the uncertainty, lack of time, data, and resources to make the right call.</p><p>Another critical factor to keep in mind is your (and your team's) biases. Even when you have plenty of data at your disposal, you and your team are always influenced by some bias (<a href="https://en.wikipedia.org/wiki/List_of_cognitive_biases" title="Cognitive biases" target="_blank">confirmation bias and others</a>).</p><p>There will be times when you won't have enough data, other times you won't have enough time, and most of the time, you won't be aware of your biases.</p><p>That leads me to my last point, <strong>judgment</strong>. Good judgment is extremely underrated these days, but I find it one of the most valuable traits.</p><blockquote>"Good Judgment depends mostly on experience, and experience usually comes from poor judgment."<p>Old saying</p></blockquote><p>Good judgment is also impossible to measure upfront, but<!-- --> <strong>it will be your judgment</strong> to assess the risk and time needed to make each decision<strong>that will lead you towards the best possible outcomes</strong> <!-- -->in times of uncertainty.</p></main></div></div></div>]]>
            </description>
            <link>https://amiltonpaglia.com/writing/building-products</link>
            <guid isPermaLink="false">hacker-news-small-sites-26173963</guid>
            <pubDate>Thu, 18 Feb 2021 00:44:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Decoding Mars 2020]]>
            </title>
            <description>
<![CDATA[
Score 34 | Comments 1 (<a href="https://news.ycombinator.com/item?id=26172593">thread link</a>) | @followben
<br/>
February 17, 2021 | https://destevez.net/2020/08/decoding-mars-2020/ | <a href="https://web.archive.org/web/*/https://destevez.net/2020/08/decoding-mars-2020/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-8920">

	

	<div>
		
<p><a href="https://en.wikipedia.org/wiki/Mars_2020">Mars 2020</a>, NASAâ€™s latest mission to Mars, was launched a couple weeks ago. However, with all the Tianwen-1 work down the pipeline, until now I havenâ€™t had time to dedicate an appropriate post to this mission (though I showed some <a href="https://twitter.com/ea4gpz/status/1289322621360730113">sneak peek on Twitter</a>). This mission consists of a <a href="https://en.wikipedia.org/wiki/Perseverance_(rover)">rover</a> and <a href="https://en.wikipedia.org/wiki/Mars_Helicopter_Ingenuity">helicopter</a> (a real novelty in space exploration). Both were launched with the cruise stage and the entry, descent and landing system on July 30 from <a href="https://en.wikipedia.org/wiki/Cape_Canaveral_Space_Launch_Complex_41">Cape Canaveral</a>, an are currently on their transfer orbit to Mars, as Tianwen-1 and Emirates Mars Mission.</p>



<p>In this post I will be working with some recordings made by <a href="https://amsat-dl.org/">AMSAT-DL</a> using the <a href="https://amsat-dl.org/en/20-meter-antenna/">20m radio telescope at Bochumâ€™s observatory</a>. These feature the low rate safe mode telemetry, which was very strong and caused some anecdotes as it <a href="https://twitter.com/nascom1/status/1288828268552916992">saturated some NASA DSN receivers</a>, and the nominal 10kbps telemetry signal that was switched on later. Here I will describe the modulation and coding, giving <a href="https://www.gnuradio.org/">GNU Radio</a> decoders, and also take a look at the data. <a href="http://www.r00t.cz/?action=home">r00t.cz</a> has also written a <a href="http://www.r00t.cz/Sats/Mars2020">post</a> where he shows similar information.</p>



<h4>Safe mode modulation and coding</h4>



<p>Mars 2020â€™s X-band downlink is at approximately 8414.9 MHz. When in safe mode, a baudrate of only 80 baud is transmitted using PCM/PSK/PM (see <a href="https://deepspace.jpl.nasa.gov/files/phase1.pdf">this document</a> for the terminology). This means that the telemetry is a PSK signal modulated onto a subcarrier which is then phase modulated onto a residual carrier. The subcarrier in this case is a 25kHz square wave.</p>



<p>The figure below shows the spectrum of the signal, as recorded in Bochum on 2020-07-30 20:25 UTC. We see the central residual carrier at a slight offset from 0Hz, and then the data sidebands and their odd harmonics. We have only odd harmonics because of the square wave subcarrier. A sine wave subcarrier produces both even and odd harmonics when phase modulated.</p>



<figure><a href="https://destevez.net/wp-content/uploads/2020/08/mars2020_safe_mode_spec.png"><img width="644" height="382" src="https://destevez.net/wp-content/uploads/2020/08/mars2020_safe_mode_spec-644x382.png" alt="" srcset="https://destevez.net/wp-content/uploads/2020/08/mars2020_safe_mode_spec-644x382.png 644w, https://destevez.net/wp-content/uploads/2020/08/mars2020_safe_mode_spec-300x178.png 300w, https://destevez.net/wp-content/uploads/2020/08/mars2020_safe_mode_spec-768x455.png 768w, https://destevez.net/wp-content/uploads/2020/08/mars2020_safe_mode_spec.png 837w" sizes="(max-width: 644px) 100vw, 644px"></a></figure>



<p>If we zoom in to the centre of the modulation, we see that the data sidebands are very narrow, owing to the low baudrate.</p>



<figure><a href="https://destevez.net/wp-content/uploads/2020/08/mars2020_safe_mode_spec_zoom.png"><img width="644" height="385" src="https://destevez.net/wp-content/uploads/2020/08/mars2020_safe_mode_spec_zoom-644x385.png" alt="" srcset="https://destevez.net/wp-content/uploads/2020/08/mars2020_safe_mode_spec_zoom-644x385.png 644w, https://destevez.net/wp-content/uploads/2020/08/mars2020_safe_mode_spec_zoom-300x179.png 300w, https://destevez.net/wp-content/uploads/2020/08/mars2020_safe_mode_spec_zoom-768x460.png 768w, https://destevez.net/wp-content/uploads/2020/08/mars2020_safe_mode_spec_zoom.png 829w" sizes="(max-width: 644px) 100vw, 644px"></a></figure>



<p>The coding is CCSDS Turbo frames as described in the <a href="https://public.ccsds.org/Pubs/131x0b3e1.pdf">TM Synchronization and Channel Coding blue book</a>. A rate of 1/2 and frame size of 223 bytes is used. Note that each frame takes 45.5 seconds to transmit, due to the low baudrate.</p>



<p>The GNU Radio decoder flowgraph is shown in the figure below (click on it to view in full size). Its structure is very similar to other PCM/PSK/PM demodulators Iâ€™ve shown in previous posts, such as <a href="https://destevez.net/2020/07/tianwen-1-telemetry-modulation-and-coding/" data-type="post" data-id="8747">the one for Tianwen-1</a>. The residual carrier is locked with a PLL (here using a bandwidth of 200Hz), the imaginary part of the signal is taken to extract the data sideband, the subcarrier is moved down to baseband, and then clock recovery and subcarrier recovery using a Costas loop are done. Finally, Turbo decoding is done with the blocks from <a href="https://github.com/daniestevez/gr-dslwp/tree/maint38">gr-dslwp</a>. The flowgraph can be found <a href="https://github.com/daniestevez/jupyter_notebooks/blob/master/Mars2020/mars2020_safemode.grc">here</a>.</p>



<figure><a href="https://destevez.net/wp-content/uploads/2020/08/mars2020_safemode.png"><img width="644" height="592" src="https://destevez.net/wp-content/uploads/2020/08/mars2020_safemode-644x592.png" alt="" srcset="https://destevez.net/wp-content/uploads/2020/08/mars2020_safemode-644x592.png 644w, https://destevez.net/wp-content/uploads/2020/08/mars2020_safemode-300x276.png 300w, https://destevez.net/wp-content/uploads/2020/08/mars2020_safemode-768x706.png 768w, https://destevez.net/wp-content/uploads/2020/08/mars2020_safemode.png 1232w" sizes="(max-width: 644px) 100vw, 644px"></a><figcaption>Mars 2020 safe mode GNU Radio decoder flowgraph</figcaption></figure>



<p>The figure below shows the decoder running. The signal is very strong, so the constellation is quite clean. We can see in the spectrum of the BPSK subcarrier that the data symbols are not filtered, since some sidelobes are visible.</p>



<figure><a href="https://destevez.net/wp-content/uploads/2020/08/mars2020_safemode_running.png"><img width="644" height="355" src="https://destevez.net/wp-content/uploads/2020/08/mars2020_safemode_running-644x355.png" alt="" srcset="https://destevez.net/wp-content/uploads/2020/08/mars2020_safemode_running-644x355.png 644w, https://destevez.net/wp-content/uploads/2020/08/mars2020_safemode_running-300x166.png 300w, https://destevez.net/wp-content/uploads/2020/08/mars2020_safemode_running-768x424.png 768w, https://destevez.net/wp-content/uploads/2020/08/mars2020_safemode_running-1536x848.png 1536w, https://destevez.net/wp-content/uploads/2020/08/mars2020_safemode_running.png 1600w" sizes="(max-width: 644px) 100vw, 644px"></a><figcaption>Mars 2020 safe mode decoder running</figcaption></figure>



<h4>10kbps modulation and coding</h4>



<p>The nominal 10kbps signal replaces the safe mode modulation during normal spacecraft operations. The modulation is 60kbaud PCM/PM/NRZ. This means that the data is directly phase-modulated onto the residual carrier.</p>



<p>The figure below shows the spectrum of the signal as recorded by Bochum on 2020-07-31 20:04 UTC. We can see the residual carrier and the data modulation, which can be approximated by a BPSK modulation in quadrature with the carrier.</p>



<figure><a href="https://destevez.net/wp-content/uploads/2020/08/mars2020_10kbps_spec.png"><img width="644" height="382" src="https://destevez.net/wp-content/uploads/2020/08/mars2020_10kbps_spec-644x382.png" alt="" srcset="https://destevez.net/wp-content/uploads/2020/08/mars2020_10kbps_spec-644x382.png 644w, https://destevez.net/wp-content/uploads/2020/08/mars2020_10kbps_spec-300x178.png 300w, https://destevez.net/wp-content/uploads/2020/08/mars2020_10kbps_spec-768x455.png 768w, https://destevez.net/wp-content/uploads/2020/08/mars2020_10kbps_spec.png 837w" sizes="(max-width: 644px) 100vw, 644px"></a></figure>



<p>The coding is CCSDS Turbo frames as in the safe mode signal, but here a rate of 1/6 and frame size of 1115 bytes are used to improve the low Eb/N0 performance. As such, frames take around 0.9 seconds to transmit.</p>



<p>The figure below shows the GNU Radio decoder flowgraph for the 10kbps signal. A slightly different approach from the <a href="https://destevez.net/2020/07/decoding-emirates-mars-mission-hope/" data-type="post" data-id="8670">Emirates Mars Mission decoder</a> (which is also PCM/PM/NRZ) is used here. The residual carrier is locked with a PLL (with 50Hz bandwidth) and then the imaginary part of the signal is taken to obtain the BPSK modulation. Clock recovery is made with an ML TED and polyphase root-raised cosine filter. Turbo decoding is done with the gr-dslwp blocks, as for the safe mode signal. The decoder can be found <a href="https://github.com/daniestevez/jupyter_notebooks/blob/master/Mars2020/mars2020.grc">here</a>.</p>



<figure><a href="https://destevez.net/wp-content/uploads/2020/08/mars2020_10kbps.png"><img src="https://destevez.net/wp-content/uploads/2020/08/mars2020_10kbps-644x592.png" alt="" width="644" height="592" srcset="https://destevez.net/wp-content/uploads/2020/08/mars2020_10kbps-644x592.png 644w, https://destevez.net/wp-content/uploads/2020/08/mars2020_10kbps-300x276.png 300w, https://destevez.net/wp-content/uploads/2020/08/mars2020_10kbps-768x706.png 768w, https://destevez.net/wp-content/uploads/2020/08/mars2020_10kbps.png 1232w" sizes="(max-width: 644px) 100vw, 644px"></a><figcaption>Mars 2020 10kbps mode GNU Radio decoder flowgraph</figcaption></figure>



<p>The decoder is shown below running. The signal is not very strong, and there are many bit errors, but the Turbo decoder is still able to correct most of them, so the frame error rate is low.</p>



<figure><img width="644" height="355" src="https://destevez.net/wp-content/uploads/2020/08/mars2020_10kbps_running-644x355.png" alt="" srcset="https://destevez.net/wp-content/uploads/2020/08/mars2020_10kbps_running-644x355.png 644w, https://destevez.net/wp-content/uploads/2020/08/mars2020_10kbps_running-300x166.png 300w, https://destevez.net/wp-content/uploads/2020/08/mars2020_10kbps_running-768x424.png 768w, https://destevez.net/wp-content/uploads/2020/08/mars2020_10kbps_running-1536x848.png 1536w, https://destevez.net/wp-content/uploads/2020/08/mars2020_10kbps_running.png 1600w" sizes="(max-width: 644px) 100vw, 644px"><figcaption>Mars 2020 safe mode GNU Radio decoder flowgraph</figcaption></figure>



<h4>Framing</h4>



<p>The framing is the same for the safe mode and 10kbps signals, so it is described here for both. The frames are AOS Space Data Link frames as described in the CCSDS <a href="https://public.ccsds.org/Pubs/732x0b3e1.pdf">AOS Space Data Link Protocol blue book</a>. The frames contain a CRC-16 used to discard frames with uncorrected errors.</p>






<p>In the recordings I have examined, only spacecraft ID 168 and virtual channel 0 are used in the AOS frames. The payload of the frames contains Space Packets (see the CCSDS <a href="https://public.ccsds.org/Pubs/133x0b2.pdf">Space Packet protocol blue book</a>) using the M_PDU protocol.</p>



<p>The Space Packets contain a secondary header which is a 6 byte timestamp using the CUC format (see the <a href="https://public.ccsds.org/Pubs/301x0b4e1.pdf">Time Code Formats blue book</a>). This means that the timestamp is a 48 bit counter, which in this case uses units of \(2^{-16}\) seconds. The epoch for the counter is the J2000 epoch, which is 2000-01-01 12:00:00. I am not sure about the timescale used (UTC, TAI, etc.), since the timestamps are somewhat off with respect to the timestamp in the recording filename.</p>



<h4>Safe mode frames</h4>



<p>Since safe mode frames take so long to transmit, I have only 4 frames extracted from the short recording. The last of them is partly corrupted, due to the signal fading out, so it has incorrect CRC. The frames are shown below, with one frame per row. As we will see later, the blue bands correspond to ASCII text.</p>



<figure><a href="https://destevez.net/wp-content/uploads/2020/08/safe_mode_frames.png"><img width="644" height="130" src="https://destevez.net/wp-content/uploads/2020/08/safe_mode_frames-644x130.png" alt="" srcset="https://destevez.net/wp-content/uploads/2020/08/safe_mode_frames-644x130.png 644w, https://destevez.net/wp-content/uploads/2020/08/safe_mode_frames-300x61.png 300w, https://destevez.net/wp-content/uploads/2020/08/safe_mode_frames-768x155.png 768w, https://destevez.net/wp-content/uploads/2020/08/safe_mode_frames.png 1161w" sizes="(max-width: 644px) 100vw, 644px"></a><figcaption>Mars 2020 safe mode frames</figcaption></figure>



<p>There are 7 space packets in these frames. The first four belong to APID 8, and the remaining three to the idle APID 2047. The packet timestamps, shown below, are quite interesting. We see that the first four packets (which are those in APID 8 having useful data) were generated almost simultaneously and are sent when possible, due to the low data rate. According to the filename, the recording starts on 20:25:19 UTC. The last three packets are idle and presumable have real-time timestamps. The timestamp spacing for these is 45.5 seconds, which is precisely the duration of the frames.</p>



<pre>2020-07-30T20:17:01.899688704
2020-07-30T20:17:01.899719296
2020-07-30T20:17:01.900863616
2020-07-30T20:17:02.899047808
2020-07-30T20:25:58.403961216
2020-07-30T20:26:43.904830976
2020-07-30T20:27:29.405853312</pre>



<p>The APID 2047 idle packets are filled in with an ASCII text as an Easter egg. However, the safe mode frames are too short to contain the full text, so it will be shown later in the 10kbps frames.</p>



<p>The packets in APID 8 contain the following ASCII strings, as well as some binary data</p>



<pre>seqengv
tsfp_15000
seqbg
cbm</pre>



<h4>10kbps mode frames</h4>



<p>A total of 950 frames were extracted from the recording. From these, only 4 have incorrect CRC. The frames can be seen in the figure below. Most of the frames have an idle packet with the Easter egg ASCII text, as shown by the blue bars (the deep blue blocks are ASCII spaces). The more irregular block near the top is a transmission of old telemetry data.</p>



<figure><a href="https://destevez.net/wp-content/uploads/2020/08/10kbps_frames.png"><img width="644" height="549" src="https://destevez.net/wp-content/uploads/2020/08/10kbps_frames-644x549.png" alt="" srcset="https://destevez.net/wp-content/uploads/2020/08/10kbps_frames-644x549.png 644w, https://destevez.net/wp-content/uploads/2020/08/10kbps_frames-300x256.png 300w, https://destevez.net/wp-content/uploads/2020/08/10kbps_frames-768x654.png 768w, https://destevez.net/wp-content/uploads/2020/08/10kbps_frames.png 1156w" sizes="(max-width: 644px) 100vw, 644px"></a></figure>



<p>Below we show the number of frames lost according to the virtual channel frame count.</p>



<figure><a href="https://destevez.net/wp-content/uploads/2020/08/mars2020_frame_loss.png"><img width="644" height="348" src="https://destevez.net/wp-content/uploads/2020/08/mars2020_frame_loss-644x348.png" alt="" srcset="https://destevez.net/wp-content/uploads/2020/08/mars2020_frame_loss-644x348.png 644w, https://destevez.net/wp-content/uploads/2020/08/mars2020_frame_loss-300x162.png 300w, https://destevez.net/wp-content/uploads/2020/08/mars2020_frame_loss.png 717w" sizes="(max-width: 644px) 100vw, 644px"></a></figure>



<p>There are three APIDs active in this recording: APID 2047, which contains idle packets and has 741 packets, APID 9, which contains some real time telemetry and has 58 packets, and APID 247, which contains old telemetry and has 14 packets. The distribution of the packets can be seen well in the figure below, which shows the timestamps classified by APID. We see that most of the time an idle packet is transmitted, with occasional real-time telemetry in APID 9. For some time, old data is transmitted in APID 247, while the real-time APID 9 data continues.</p>



<figure><img width="644" height="333" src="https://destevez.net/wp-content/uploads/2020/08/mars2020_timestamps-644x333.png" alt="" srcset="https://destevez.net/wp-content/uploads/2020/08/mars2020_timestamps-644x333.png 644w, https://destevez.net/wp-content/uploads/2020/08/mars2020_timestamps-300x155.png 300w, https://destevez.net/wp-content/uploads/2020/08/mars2020_timestamps.png 749w" sizes="(max-width: 644px) 100vw, 644px"></figure>



<p>The packets in APID 9 contain data in a format which is difficult to parse. It is a tag-value format in which there is a 2 byte tag describing the type of field and then the field itself. The problem is that the field length is implicit. This can be seen in the block below, which shows the first 64 bytes of the payload of some APID 9 packets in hex. Most of them start by the tag <code>0x027a</code>, then there is a <code>float64</code> value, then the tag <code>0x027d</code> followed by a 32 bit field, the the tag <code>0x027e</code>, etc.</p>



<pre>027a3fc4b0a55e22a0db027d00000000027e00000000027f00007724028000000000028100000000028200000000028300007724
027a3fd487d0f660cd9b027d00000000027e00000000027f00007724028000000000028100000000028200000000028300007724
027a3fd0d90f1448995f027d00000000027e00000000027f00007724028000000000028100000000028200000000028300007724
01f50000000101f60000000001f70000000101f80000000001f90000000101fa0000000001fb0000000101fc0000000001fd0000
027a3fce8f20f40f8c44027d00000000027e00000000027f00007724028000000000028100000000028200000000028300007724
027a3fe1b4b7d417ae74027d00000000027e00000000027f00007724028000000000028100000000028200000000028300007724
027a3fde55f7e8aff142027d00000000027e00000000027f00007724028000000000028100000000028200000000028300007724
027a3fc8294de5246b73027d00000000027e00000000027f00007724028000000000028100000000028200000000028300007724
027a3fd0a779c031d70c027d00000000027e00000000027f00007724028000000000028100000000028200000000028300007724
027a3fd9871585b5416d027d00000000027e00000000027f00007724028000000000028100000000028200000000028300007724</pre>



<p>The problem with parsing this kind of data is guessing the length of each field. However, I have made a heuristic algorithm that doesnâ€™t do such a bad job. It is based on the fact that often one tag and the next one are related: the second tag â€¦</p></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://destevez.net/2020/08/decoding-mars-2020/">https://destevez.net/2020/08/decoding-mars-2020/</a></em></p>]]>
            </description>
            <link>https://destevez.net/2020/08/decoding-mars-2020/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26172593</guid>
            <pubDate>Wed, 17 Feb 2021 22:20:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[68% of the top links on Facebook since September are in support of Donald Trump]]>
            </title>
            <description>
<![CDATA[
Score 49 | Comments 76 (<a href="https://news.ycombinator.com/item?id=26172471">thread link</a>) | @smalera
<br/>
February 17, 2021 | https://www.businessofbusiness.com/articles/alt-right-media-thrives-on-facebook-dan-bongino-ben-shapiro/ | <a href="https://web.archive.org/web/*/https://www.businessofbusiness.com/articles/alt-right-media-thrives-on-facebook-dan-bongino-ben-shapiro/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main-section">
    <!-- .sidebar -->

    <section>
      
      

      <p><span>Dan Bongino is, in many ways, the perfect conservative strongman. Muscular and imposing, his mere existence as a voice on the right scores culture war points against the perceived droves of left-wing soyboys. His profiles boast that he is a New York Times bestselling author and former Secret Service agent, a former proximity to the presidency which affords him an air of credibility when talking politics.&nbsp;</span></p>
<p><span>He is also a rampant purveyor of misinformation. His bestselling book, </span><i><span>Spygate: The Attempted Sabotage of Donald Trump</span></i><span> proliferates the disproven conspiracy theory that Barack Obama and Hillary Clinton used spies to attempt to sabotage Trumpâ€™s 2016 campaign. He cast doubt over the effectiveness of masks at the start of the COVID-19 pandemic. His page was a hub of 2020 election conspiracy theories. As recently as February 10, Bongino posted on his Facebook page claiming that Democrats used doctored footage in Trumpâ€™s impeachment trial, a claim which was </span><a href="https://www.politifact.com/factchecks/2021/feb/11/blog-posting/no-house-democrats-impeachment-video-did-not-viola/"><span>quickly disproved</span></a><span>.&nbsp;</span></p>
<p>Despite, or&nbsp;more likely because of all these things, Bongino is one of the most popular figures on Facebook. His page has over 2 million likes and over 3.4 million followers, and its posts, which link to his live show and website, consistently rank among the top-performing links on the site. But Bongino is not the only conservative figure posting misinformation and thriving on Facebook.&nbsp;</p>
<p><span>Kevin Roose, a columnist at the New York Times </span><a href="https://www.nytimes.com/2020/10/29/technology/dan-bongino-has-no-idea-why-facebook-loves-him.html"><span>who has covered Bongino</span></a><span>, has been using the Facebook-owned analytics service Crowdtangle to share the top 10 highest-performing links on Facebook since July 22, 2020 </span><a href="https://twitter.com/FacebooksTop10"><span>on Twitter</span></a><span>. Using Rooseâ€™s data, the Business of Business tracked the top-performing link since September 28 â€” the day before the first televised debate between Donald Trump and Joe Biden took place. The data revealed that throughout the election season and as recently as last week, posts from conservative media figures with histories of spreading misinformation have consistently ranked among the best performing links on the site.</span></p>
<p>In fact, posts from conservative media pages â€” including&nbsp;figures like Bongino and Ben Shapiro, news outlets such as Fox News and Newsmax, and pages in support of Donald Trump such as USA Patriots for Donald Trump â€” made up for 68% of the 880 top performing links on Facebook during the recorded period.</p>
<p>Not every single day since September 28 has been tracked; of the last 137 days since our count began, the list of top-performing links was only provided for 88. The race chart below shows which pages had top-performing links on every recorded day, as well as how many posts from that page were in the top 10.</p>

<p><a href="https://public.flourish.studio/visualisation/4637294/?utm_source=embed&amp;utm_campaign=visualisation/4637294" target="_top"><img alt="Made with Flourish" src="https://public.flourish.studio/resources/made_with_flourish.svg"> </a></p>
<p>Conservative pages performed well throughout the entire recorded period â€” most notably on the days of or after major political events took place.</p>
<p>On September 29, the day of the first Presidential debate, nine of the top 10 performing links came from conservative pages including Fox News, Dan Bongino, Ben Shapiro, Donald Trump and USA Patriots for Donald Trump â€” a trend which continued for the following two debates. On the day of the Vice Presidential Debate, posts from Bongino made up half of the top-performing links on Facebook. By the second Presidential debate, Bongino had eight of the top performing links with the other two belonging to Fox News and CNN.</p>
<p>On election day, posts from Bongino, Trump, Dr. Ben &amp; Candy Carson, and Fox News had seven of the top performing links, with the other three belonging to CNN and Alexandria Ocasio-Cortez. On November 7 â€” the day the Associated Press and several other media outlets began calling the election for Joe Biden â€” Donald Trump was the lone conservative figure with a link in the top 10, with the others belonging to news outlets like CNN, NPR, The New York Times and liberal pundit Rachel Maddow.&nbsp;</p>
<p>However, it only took one day for conservative media to reclaim its spot with the majority of the top-performing posts. By November 9, Donald Trump dominated the top 10 with five posts, with others belonging to Dan Bongino, religious conservative and Trump supporter Franklin Graham, and Newsmax â€” the only odd one out was a single post from then Vice President-Elect Kamala Harris. Twitter and Facebook's suspensions of Donald Trump's accounts and other conservative accounts on January 8&nbsp;only added fuel to&nbsp;the fire â€” just one day later on January 9, Bongino, Shapiro, Fox News, Brietbart and Brigitte Gabriel had seven of the top 10 performing links.</p>
<div><table>
<tbody>
<tr>
<td><b>Facebook Page</b></td>
<td><b>Links in the top 10</b></td>
</tr>
<tr>
<td><strong></strong>Dan Bongino</td>
<td>197</td>
</tr>
<tr>
<td>Fox News</td>
<td>116</td>
</tr>
<tr>
<td>Ben Shapiro</td>
<td>70</td>
</tr>
<tr>
<td>CNN</td>
<td>67</td>
</tr>
<tr>
<td>Donald J. Trump</td>
<td>56</td>
</tr>
<tr>
<td>Franklin Graham</td>
<td>46</td>
</tr>
<tr>
<td>NPR</td>
<td>33</td>
</tr>
<tr>
<td>The New York Times</td>
<td>20</td>
</tr>
<tr>
<td>Newsmax</td>
<td>17</td>
</tr>
<tr>
<td>Occupy Democrats</td>
<td>17</td>
</tr>
<tr>
<td>The Dodo</td>
<td>16</td>
</tr>
<tr>
<td>USA Patriots for Donald Trump</td>
<td>14</td>
</tr>
<tr>
<td>Donald Trump for President</td>
<td>12</td>
</tr>
<tr>
<td>Breitbart</td>
<td>11</td>
</tr>
<tr>
<td>Robert Reich</td>
<td>10</td>
</tr>
<tr>
<td>ForAmerica</td>
<td>9</td>
</tr>
<tr>
<td>Joe Biden</td>
<td>8</td>
</tr>
<tr>
<td>Dios Es Bueno</td>
<td>8</td>
</tr>
<tr>
<td>Dinesh D'Souza</td>
<td>7</td>
</tr>
</tbody>
</table></div>

<p>Though 103 pages had links in the top 10 during the recorded period, a table of the&nbsp;20 pages with the highest volume of top-performing links&nbsp;on Facebook shows the chokehold conservative media has on the platform. Bongino dominates the&nbsp;list not just among conservative figures but across all of Facebook. Links from Bonginoâ€™s page appeared in 84 of the 88 recorded days, with a total count of 197 links. The page with the next-highest volume of links in the top 10 was Fox News with 117, followed by Ben Shapiro with 70.&nbsp;Of the 103 pages with top-performing links, 67 of them only had one or two links appear in a daily top 10.</p>
<p><span>The majority&nbsp;of the top-performing conservative media links came from pundits like Bongino and Shapiro as well as from politicians like Ted Cruz, with slightly less</span><span>&nbsp;coming from conservative media outlets and pages in explicit support of Donald Trump. CNN, NPR and The New York Times are the only non-conservative media outlets to be among the top 10 performing pages during the recorded period with </span>67, 33 and 20<span>&nbsp;of the top-performing links respectively.&nbsp;</span><span>Robert Reich was the top-performing Democratic pundit with only </span>10<span> top-performing posts during the 88 recorded days.</span></p>
<p><span>Ben Shapiro, former editor-at-large of Brietbart and creator of conservative media site The Daily Wire, is well-known across social media for his controversial beliefs, books and show, </span><i><span>The Ben Shapiro Show</span></i><span>. In the past, Shapiro has made several dubious claims, such as when he </span><a href="https://www.politifact.com/factchecks/2014/nov/05/ben-shapiro/shapiro-says-majority-muslims-are-radicals/"><span>falsely argued</span></a><span> that over half of the worldâ€™s Muslim population was radicalized. Shapiro is one of many creators including Steven Crowder, Dave Rubin and others&nbsp;who make up what was once referred to as the "intellectual dark web," a group of right-wing pundits who challenged liberal and democratic beliefs. Many of these creators including Shapiro himself have disavowed the alt-right movement and white supremacist movements, yet <a href="https://arxiv.org/pdf/1908.08313.pdf">studies show</a>&nbsp;their content is often a direct pipeline to online alt-right communities.&nbsp;</span>Conservative media outlet Newsmax also recently received warning that it could face a defamation lawsuit from Dominion Voting Systems for false claims that the company helped rig the election against Donald Trump.</p>
<p>Facebook has made repeated attempts to curb misinformation on the platform, from implementing machine learning to identify false stories to investigating the accuracy of viral stories like the Hunter Biden laptop scandal itself, but to little avail. Misinformation and extreme content is as prevalent on the platform under the new Biden administration as it was during election season last year, and Facebook is <a href="https://about.fb.com/news/2021/02/reducing-political-content-in-news-feed/">only now beginning to restrict</a> the presence of political content in users' newsfeeds overall.</p>
<p>On Wednesday, Facebook announced that it would <a href="https://about.fb.com/news/2021/02/changes-to-sharing-and-viewing-news-on-facebook-in-australia/">remove all news content</a> from the platform in Australia in response to a proposed law which would require the company to pay publishers for every article posted on Facebook. In it, Facebook stated that the company's business gain is minimal, and that news makes up less than 4% of what appears in users' news feeds. However, Facebook did not provide a definition of what it considers to be "news" content. Posts from Bongino, Shapiro and others may not be considered strictly "news" by Facebook, but they often dress themselves up as&nbsp;such, looking nearly indistinguishable visually from average news articles. To their followers, Bongino's and Shapiro's posts are viewed as more credible than if they came from a mainstream media outlet â€” A 2020 survey from Pew Research Center found that one in five U.S. adults get their news primarily through social media, and that these adults are typically less informed or more susceptible&nbsp;to misinformation.&nbsp;</p>
<p>Regardless of whether the 4% figure is correct, Facebook pages that post political or news content made up for 17 of the top 20 performing pages during the recorded period. Fox News, which can be considered a&nbsp;news source by most standards, is the second-most popular page on Facebook in terms of link performance. Regardless of whether Facebook has a significant business benefit from news content or not, the prevalence and success of it on the platform is enough to support entire businesses and ecosystems, like Bongino's and other "intellectual dark web" figures.</p>
<p>Bongino himself isnâ€™t sure why heâ€™s so popular on Facebook. â€œWe donâ€™t use bots. We donâ€™t even advertise much on Facebook,â€ Bongino told Roose in an October interview. â€œIf I told you I spent 10 minutes on analytics over the past year, Iâ€™d be lying.â€</p>
<p>Much of Bonginoâ€™s content plays into the narrative that conservatives are being silenced by politicians and tech platforms. When Twitter banned Donald Trumpâ€™s account on January 8, Bongino was wrapped up in the crossfire. His account was suspended for 12 hours, which prompted him to leave the platform entirely in an act of protest. Bongino told Roose that he is preparing to be removed from Facebook for ideological reasons as well, and Facebook's recent decision to curb the amount of political content in newsfeeds may end up denting Bongino's empire. But in the meantime, he and his fellow pundits are thriving and have a near-complete control over which links get the â€¦</p></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.businessofbusiness.com/articles/alt-right-media-thrives-on-facebook-dan-bongino-ben-shapiro/">https://www.businessofbusiness.com/articles/alt-right-media-thrives-on-facebook-dan-bongino-ben-shapiro/</a></em></p>]]>
            </description>
            <link>https://www.businessofbusiness.com/articles/alt-right-media-thrives-on-facebook-dan-bongino-ben-shapiro/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26172471</guid>
            <pubDate>Wed, 17 Feb 2021 22:08:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Team building with â€œI dare youâ€ challenge]]>
            </title>
            <description>
<![CDATA[
Score 14 | Comments 9 (<a href="https://news.ycombinator.com/item?id=26171895">thread link</a>) | @delebe
<br/>
February 17, 2021 | https://danlebrero.com/2021/02/17/cto-diary-team-buidling-i-dare-you/ | <a href="https://web.archive.org/web/*/https://danlebrero.com/2021/02/17/cto-diary-team-buidling-i-dare-you/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p id="entry-summary">A fun(???) exercise to gel a team by challenging them to achieve the impossible within a day.</p><div><p>For a change of scenery and pace.</p><p>To do something different and fun. </p><p>To push the remote team to work together and gel. </p><p>To do some important but not urgent platform workâ€¦</p><p>I dared the team to enlist for an unknown challenge that they will know nothing about until the very last minute.</p><h2>I dare you â€¦</h2><p>The enlisting email:</p>
<blockquote><p>Hi all,</p><p>The Dev brown-bag session of Feb 20th has been postponed.</p><p>Instead of finding a replacement, I am going to dare the whole Dev team to start and finish a work related challenge within a working day.</p><p>This is not a hackathon. You will be expected to work 8 hours, and it is actual work.</p><p>But you will need to work as a team, so if you decide to sign up for the challenge, you will need to make yourself available to the team 8am to 5pm Amsterdam time on Feb 20th, with a 12pm-1pm lunch break. Your colleges will expect that you accommodate your personal live chores around the team schedule.</p><p>The schedule will be:</p>
  <ul>
    <li>0800: Everybody is ready in the â€œwar roomâ€, coffee in hand.<br></li>
    <li>0801-0830: Dan dares you to â€¦ I will explain the challenge here and then disappear.<br></li>
    <li>0831-1640: Team argues about approach.</li>
    <li>1641-1644: Team rushes to finish something.</li>
    <li>1645-1700: Dan shows up again. We celebrate/cry/curse together.</li>
  </ul><p>I happen to be in Amsterdam that day, so I will jump in and out, and generally not available.</p><p>The activity is voluntary, but if you sign up for it, you are making a commitment to the team. Note that the challenge is not known until the day. Do not ask me beforehand â€œWould my skill set be useful? Would this be the best use of my time?â€. I dare you to help the team achieve the challenge in the best way you can.</p><p>If you are willing to participate please reply with â€œHow do you dare!â€.</p><p>As always, open for questions/suggestions/comments or other pledges.</p><p>Cheers,</p><p>Dan</p>
</blockquote><h2>People</h2><p>Out of 13 people in the Dev team, seven replied with:</p><p><img src="https://danlebrero.com/images/blog/cto/day4/how-dare-you.gif" alt="how dare you"></p><p>Neither UX nor the Product Managers enlisted. <em>Why not?</em></p><p>Seven people joined, two dropped the day before, and when the challenge was revealed, one silently disappeared. </p><p>Four brave souls to face the challengeâ€¦</p><p><img src="https://danlebrero.com/images/blog/cto/day4/four-musketeers.jpg" alt="four musketeers"></p><h2>Challenge</h2><p>The proposed challenge was to move one of our existing applications to <a href="https://martinfowler.com/bliki/BlueGreenDeployment.html">blue/green deployments</a>.</p><p>We already had the blue/green experience with another application, and we loved it. This will be an opportunity to spread the love to other teams.</p><p>The main piece of work was changing how the application stored user uploaded images. We were using a Kubernetes PersistentDisk, which at that point in Google Kubernetes Engine meant that we could not have more than one instance of the application running at a given time. </p><p>The app was build on Django which has a nice <a href="https://docs.djangoproject.com/en/3.1/ref/files/storage/">File storage abstraction</a> with a <a href="https://django-storages.readthedocs.io/en/latest/backends/gcloud.html">Google Cloud Storage implementation</a> implementation. So in theory, the work was to change the Django configuration and migrate the existing user images to Google Cloud Storage. </p><p>As this was the most risky part, the previous week I did a proof of concept to make sure that it actually worked.</p><p>And it did. Hooray for abstractions!</p><p>The other big pieces of work were:</p>
<ol>
  <li>Create a migration plan and script for the files.</li>
  <li>Copy and paste a bunch of Kubernetes yaml from the other blue/green application. A piece of cake.</li>
</ol><h2>The result</h2><p>The day was an astounding success, if the objective was to experiment all the dysfunctions of a software project within one day:</p>
<ol>
  <li>The work was poorly estimated:
  <ul>
    <li>We finished the work afterwards, and it was way more work than a team of four can handle in a day.</li>
  </ul></li>
  <li>The work was estimated by the â€œProduct Ownerâ€ (myself), not the team executing it.</li>
  <li>Jump to doing, not enough planning:
  <ul>
    <li>The team had to restart once because there was no initial plan and all was too confusing.</li>
    <li>I have the feeling that a product manager would have pushed for a proper plan before starting.</li>
  </ul></li>
  <li>One person was late to the kickoff meeting:
  <ul>
    <li>Required the rest of the team to explain the job again, wasting valuable time.</li>
    <li>The late person got the requirements second hand, which ended up causing â€¦</li>
  </ul></li>
  <li>Unclear requirements (and strong personalities):
  <ul>
    <li>The person that was late single-handedly transformed the objective of the challenge from <em>â€œlets do something productive in one dayâ€</em> to <em>â€œlets learn about mob programming and Python. There is no need to deliver.â€</em></li>
    <li>This one still baffles me, but I wrote the requirements, so maybe is what Product Owners feel every day.</li>
  </ul></li>
  <li>Devs <a href="https://danlebrero.com/2020/04/15/on-the-importance-of-clear-communication-in-devops/#content">not asking for clarification</a>, just assume what the client wants:
  <ul>
    <li>Nobody asked the Product Owner about the unclear requirements.</li>
  </ul></li>
  <li><a href="https://en.wikipedia.org/wiki/Brooks%27s_law">Adding people to a late project â€¦</a>:
  <ul>
    <li>I am happy that several people that has not signed up for the challenge jumped during the day to see if they could help, but given that none stayed, they were just a distraction that delayed the team further.</li>
  </ul></li>
  <li><a href="https://www.joelonsoftware.com/2002/11/11/the-law-of-leaky-abstractions/">Leaky abstractions</a> and unexpected technical issues:
  <ul>
    <li>Djangoâ€™s File storage abstraction happens to be a leaky abstraction, which means that the Google Cloud Storage worked slightly differently than the Local Storage implementation.</li>
    <li>The proof of concept tested the file upload code path that worked in Google Cloud Storage.</li>
    <li>The team stumbled on the file upload code path that did not work.</li>
    <li>The team completely derailed here:
    <ul>
      <li>It spent several hours mob debugging a piece of Python code.</li>
      <li>Did I mention that out of four, there was just one Python developer?</li>
    </ul></li>
    <li>I have the feeling that a product manager would have cut losses and moved to team past this hurdle.</li>
    <li>Why the team did not ask the Product Owner about the proof of concept?</li>
  </ul></li>
  <li>Improvement work not important enough:
  <ul>
    <li>Not caused by the challenge, but the shortcomings of our development workflow became painfully obvious, specially in two ways:
    <ul>
      <li>No easy way of creating a new test environment to experiment safely.</li>
      <li>Builds taking 20 minutes are not fine if you have 8 hours to do the work.</li>
    </ul></li>
  </ul></li>
  <li>Siloed knowledge:
  <ul>
    <li>Copy and pasting a bunch of Kubernetes yaml files from an existing blue/green application is a piece of cake â€¦ if you have designed the original solution, implemented it, and debugged it in production.</li>
    <li>Tweaking a <a href="https://helm.sh/">Helm chart</a> to deploy a custom-built version of the application is a piece of cake â€¦ if you have designed the original Helm chart, implemented it, and debugged it in production.</li>
    <li>Reminder for all of us: programming is easy, if you have been doing it for 20 years.</li>
  </ul></li>
</ol><h3>Was it really that bad?</h3><p>Well, at least there was no scope creep!</p><p>The fix for the leaky abstraction was useful when we later implemented the work.</p><p>Three of the participants said that they would do it again. I did not need to ask the forth one: </p><p><img src="https://danlebrero.com/images/blog/cto/day4/gosh.png" alt="gosh"></p><p>Several hours of mob debugging on an unknown language and platform can do this to anybody. </p><h2>Doing it again?</h2><p>Not how it is explained here. </p><p>First, I would not mix people from different teams. This can be a great tool to debug a dysfunctional team, as the team can see within a day what their pain points are, and the feedback loop is fast (daily).</p>
<blockquote><p>If it hurts, do it more frequently, and bring the pain forward.â€ <cite><a href="https://twitter.com/jezhumble">Jez Humble</a>, <a href="https://www.amazon.com/Continuous-Delivery-Deployment-Automation-Addison-Wesley/dp/0321601912">Continuous Delivery: Reliable Software Releases Through Build, Test, and Deployment Automation</a></cite></p>
</blockquote><p>Second, our teams are remote and in different time zones and/or schedules. Everybody working a whole day together is an exception, not the norm. Collocated teams may be required.</p><p>One year later, I have not dared to run it again.</p><h2>Lessons</h2><p>As usual, if you have time to reflect, you can find plenty of lessons:</p>
<ol>
  <li>There is nothing new under the sun. <a href="https://twitter.com/johncutlefish">John Cutler</a> blogged about <a href="https://cutle.fish/blog/one-day-sprints">One Day Sprints</a> in 2017.</li>
  <li>The experiment made obvious the value of cross-functional teams, an <a href="http://www.extremeprogramming.org/rules/customer.html">on-site customer</a> should be part of that team.</li>
  <li>Work in progress of one is very difficult.</li>
  <li>Communication is messy, repeating things twice is not enough.</li>
  <li>Short feedback loops are precious.</li>
</ol><p>But the most important lesson (or should I say reminder?) is that you cannot throw a bunch of people into a project and call them a <a href="https://danlebrero.com/2021/01/20/team-topologies-summary/#content">team</a>.</p></div></div>]]>
            </description>
            <link>https://danlebrero.com/2021/02/17/cto-diary-team-buidling-i-dare-you/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26171895</guid>
            <pubDate>Wed, 17 Feb 2021 21:16:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Keep Sensitive Values out of your logs with types]]>
            </title>
            <description>
<![CDATA[
Score 12 | Comments 1 (<a href="https://news.ycombinator.com/item?id=26171664">thread link</a>) | @giacaglia
<br/>
February 17, 2021 | https://transcend.io/blog/keep-sensitive-values-out-of-your-logs-with-types | <a href="https://web.archive.org/web/*/https://transcend.io/blog/keep-sensitive-values-out-of-your-logs-with-types">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><div><p>Logs are inherently risky: small mistakes can lead to sensitive data appearing in plaintext in places they shouldnâ€™t. No organization can eliminate the possibility that secrets will be logged, but they can better manage the risk by adding safeguards into their systems. </p><p>This post details one approach we took at Transcend to help attack this problem, by declaring fields as sensitive or not in our type system. </p><p>We found that many avenues for making mistakes with handling secrets have disappeared, and our confidence in the safety of our logs has gone up considerably. </p><p>Building in protections like these can add extra work for developers, but they can be powerful tools for increasing developer confidence that when they make mistakes the damage can be minimized.</p><h2 id="starting-from-a-place-of-acceptance">Starting from a place of acceptance</h2><p>In the past few years, weâ€™ve seen <a href="https://blog.twitter.com/official/en_us/topics/company/2018/keeping-your-account-secure.html" target="_blank" rel="noreferrer">Twitter log unhashed user passwords</a>, <a href="https://about.fb.com/news/2019/03/keeping-passwords-secure/" target="_blank" rel="noreferrer">Facebook logged tens of millions of unhashed user passwords</a>, <a href="https://news.ycombinator.com/item?id=19975378" target="_blank" rel="noreferrer">Google logged unhashed GSuite user passwords</a>, <a href="https://bugs.launchpad.net/ubuntu/+source/subiquity/+bug/1878115" target="_blank" rel="noreferrer">Ubuntuâ€™s server installer logged passwords</a>, and many other cases of similar incidents occurred. These incidents are extremely damaging to user trust and can require extensive cleanup to prevent identity theft.</p><p>Despite the severity, it seems that whenever these incidents occur, online forums are filled with comments from developers who couldnâ€™t possibly let this sort of mistake happen in their systems, and that Twitter, Facebook, Google, Ubuntu, and others must be worse at architecting systems than they are. </p><p>This could be true in some instances, but brushing off these cases as elementary feels disingenuous to the brilliant DevOps work each of these companies has contributed to the open source community. </p><p>If we can accept that developers occasionally make mistakes while also accepting that these breaches are unacceptable, we can conclude that safeguards that would protect against similar mistakes while simultaneously minimizing the damage would be beneficial.</p><h2 id="how-does-log-redaction-happen-now">How does log redaction happen now?</h2><div><p><img src="https://images.ctfassets.net/zp9m00phuodm/6FzW1Zpljf19ug17t8pezc/57f83cba34a05df9ea8fd9d12c225471/logblog_Log_Lifecycle__1_.jpg" alt="Log Lifecycle"></p><figcaption>The Log Lifecycle</figcaption></div><p>The above diagram shows how many production systems manage logs at a high level, across a variety of stacks and languages. </p><p>There is some application code that contains log statements, and those logs are picked up and enhanced by a daemon service, which then forwards the logs to a log collection service, that allows you to interact with those logs.</p><p>Throughout this pipeline, redaction can happen at a number of stages:</p><ul><li>Application code that determines what values should be logged.</li><li>Logging libraries <a href="https://github.com/winstonjs/winston#logging-levels" target="_blank" rel="noreferrer">offer log levels to discard debug-level log statments</a></li><li>Many log libraries <a href="https://github.com/pinojs/pino/blob/master/docs/redaction.md" target="_blank" rel="noreferrer">offer APIs to redact certain log paths of structured logs</a></li><li>Log Aggregation services <a href="https://docs.fluentbit.io/manual/pipeline/filters/modify" target="_blank" rel="noreferrer">offer APIs for rewriting or removing keys that could have sensitive values</a></li><li>Log collection services <a href="https://docs.datadoghq.com/logs/guide/control-sensitive-logs-data/#make-sensitive-logs-un-queryable-in-datadog-until-they-age-out" target="_blank" rel="noreferrer">offer ways to make existing logs unsearchable if they have sensitive data</a></li></ul><p>All of these levels offer a filtering system where logs that make it to the collection services shouldnâ€™t contain any sensitive data, but holes are still possible in each step:</p><ul><li>In your application code, your team could approve a PR that adds a sensitive field to an object that previously did not have sensitive data, without being aware of where that data is logged or consumed.</li><li>While many companies review all of their own code used in production, they may not stay up to date on all logging changes in third party dependencies. A three-level deep npm dependency that changed its error message to include more information may end up unintentionally logging more of an object than you thought it would.</li><li>The third party libraries you use can have different definitions of what information is acceptable to log at certain log levels.</li><li>Your log aggregation redaction regexes might miss user emails or other fields that use non-standard or international formats.</li><li>A misspelling in a field name or log level could lead to fields not being redacted when you think they should have.</li><li>Sometimes error messages or stack traces can add wrappers around your structured logs making path-based redaction difficult.</li><li>Log collection services de-indexing sensitive data should only be used as a last resort. If your data is in plaintext in an external system, it could have already been compromised.</li></ul><p>As you move to the right in the diagram, getting closer to the log collection services, the filtering becomes more of a last resort approach. They are still good to have, but ultimately, itâ€™s as you move to the left towards application code where the most effective best practices live. Your application code is where you likely have the most robust code reviews and can most easily enforce best practices like only logging the minimum number of fields.</p><p>By carefully picking what fields we want to log in structured log formats, we can have quite strong confidence that we wonâ€™t log sensitive data. </p><p>After all, the easiest way to ensure your fluentd regex that redacts social security numbers doesnâ€™t miss a value is to just not log social security numbers!</p><p>But weâ€™d be foolish to think that Google, Facebook, Twitter, and others donâ€™t use structured logs with typed fields. Thereâ€™s still one problem left: many structured logs have <code>string</code> as some field types. And strings can contain sensitive data.</p><p>This last step, and the one the rest of the article will focus on, is adding secret metadata to our typing system so that we can try to prevent these freeform <code>string</code> fields from presenting any data we donâ€™t explicitly mention should be presented.</p><h2 id="redacting-at-the-type-declaration-level">Redacting at the type declaration level</h2><p><em>A quick note: In this blog, weâ€™ll be focusing on Typescript and <a href="https://github.com/transcend-io/secret-value" target="_blank" rel="noreferrer">our open-source <code>@transcend-io/secret-value</code> library available on npm/Github Packages</a>, but the concepts can be used across a variety of languages.</em></p><p>In order to help ensure that sensitive values are not included in log statements, weâ€™ve created a new type <code>Secret</code> that prevents its values from being added to logs. The easiest way to show how is with this example:</p><div><pre><p><span>1</span><span>import</span><span> </span><span>{</span><span> </span><span>Secret</span><span> </span><span>}</span><span> </span><span>from</span><span> </span><span>`@transcend-io/secret-value`</span><span>;</span><span></span></p><p><span>2</span><span></span></p><p><span>3</span><span></span><span>const</span><span> secret </span><span>=</span><span> </span><span>new</span><span> </span><span>Secret</span><span>(</span><span>`some secret value`</span><span>)</span><span></span></p><p><span>4</span><span></span><span>console</span><span>.</span><span>log</span><span>(</span><span>secret</span><span>)</span><span>;</span></p></pre></div><p>We wrap the string <code>some secret value</code> into a <code>Secret&lt;string&gt;</code> type that will appear as <code>[redacted]</code> whether you <code>console.log</code> it, <code>JSON.stringify</code> it, <code>secret.valueOf()</code> it, interpolate it into a string, or do just about anything else to it you could imagine in JavaScript.</p><p>If you want to modify the value of the secret without unwrapping it, you can use the <code>map</code> function common to many functional wrappers like <code>const secretLenth = secret.map(rawValue =&gt; rawValue.length)</code>.</p><p>When you want to use the value stored inside the secret, you can use <code>secret.release()</code> to get the value <code>some secret value</code> back out.</p><p>The API is minimal, but itâ€™s meant to be this way. This wrapper provides a few benefits:</p><ul><li>It provides internal documentation to your developers that a value is sensitive, in an enforceable way that comments cannot do.</li><li>It ensures that if the <code>Secret</code> value is included in any log statement, its value will not appear.</li><li>It shifts the responsibility to determine if a value is sensitive or not from the person writing the log statements to the person defining the field.</li><li>It encourages developers to consider if it is safe to release secrets and pass their raw values to external systems, as most external libraries wonâ€™t take <code>Secret&lt;T&gt;</code> types. As an example, you might be fine sending most of your values to the <code>left-pad</code> library on npm, but maybe you should stick to mutating your Secret values in-house to prevent cases where a deep dependency on npm could add a log statement that would log out your sensitive value.</li></ul><p>This paradigm can also be extended in a couple of different ways:</p><ul><li>You could add telemetry to track who is releasing secret values, when they did it, and why they did it.</li><li>Instead of printing <code>[redacted]</code> you could hash the secret values, which is what <a href="https://www.vaultproject.io/docs/audit#sensitive-information" target="_blank" rel="noreferrer">Hashicorp does with their Vault audit logs</a>.</li></ul><h2 id="summing-up">Summing up</h2><p>At Transcend, our business is protecting usersâ€™ personal data. This requires careful thought and care to go into our application code, infrastructure, and end-to-end encryption pipelines. Keeping sensitive information out of logs is just one part of this process, but using <code>Secret&lt;T&gt;</code> has made this one part much easier.</p></div></article></div>]]>
            </description>
            <link>https://transcend.io/blog/keep-sensitive-values-out-of-your-logs-with-types</link>
            <guid isPermaLink="false">hacker-news-small-sites-26171664</guid>
            <pubDate>Wed, 17 Feb 2021 20:57:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Serverless Kubernetes]]>
            </title>
            <description>
<![CDATA[
Score 14 | Comments 2 (<a href="https://news.ycombinator.com/item?id=26170612">thread link</a>) | @jacksonpollock
<br/>
February 17, 2021 | https://cto.ai/blog/announcing-cto-ai-kubernetes-paas/ | <a href="https://web.archive.org/web/*/https://cto.ai/blog/announcing-cto-ai-kubernetes-paas/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
			<!-- .cover -->
			<div>
				<p>Last year we announced <a href="https://techcrunch.com/2019/11/04/cto-ai/">SlackOps</a> which enabled development teams to bring the power of the CLI directly to where communication &amp; collaboration happen; Slack.</p><div><p>After releasing SlackOps our power users kept asking us when we were going to expand our platform to help them simplify the rest of their developer workflow. This was especially common when it came to managing Kubernetes and CI/CD systems.</p><p>When we looked deeper into this request, we saw lots of teams who were being pressured to move off their PaaS vendor, as the cost to scale became untenable.</p><p>As these customers looked at how they could move their infrastructure to existing Kubernetes offerings, they saw a challenge in front of them that required specialized hiring. It also required significant re-tooling in order to maintain the same level of agility that their development teams needed to deliver on product milestones. This was hard to justify for their decision makers, leaving our users in a difficult position.</p></div><p>Anyone who has worked with Kubernetes knows that it's a wonderful &amp; powerful tool for abstracting your application workloads from your underlying cloud infrastructure to help make your system portable &amp; modular so that your operations team can easily scale up the underlay capacity needed to support a growing product...</p><!--kg-card-begin: html--><center><blockquote><p lang="en" dir="ltr">Kubernetes is a platform for building platforms. It's a better place to start; not the endgame.</p>â€” Kelsey Hightower (@kelseyhightower) <a href="https://twitter.com/kelseyhightower/status/935252923721793536?ref_src=twsrc%5Etfw">November 27, 2017</a></blockquote> </center><!--kg-card-end: html--><div><p>However, what you also know is that even the experts recognize that there is a lot of work that your team will have to take on to deploy Kubernetes so that your developers can maintain the highly agile delivery workflow they love about PaaS.</p><p>Over the last few years, our team has worked very hard to create developer workflows that enable 10x productivity by simplifying complex concepts while helping developers to have an enjoyable experience delivering great products. </p></div><p>We're big fans of Kubernetes and all things Cloud Native. We want to see more developers leverage these tools in their workflow, so we went heads down for the last year and built the Serverless Kubernetes experience we always hoped for...</p><blockquote>Today we are announcing a brand new Serverless Kubernetes Platform that allows every development team to easily consolidate all of their workflows on Kubernetes &amp; deploy Cloud Native Apps instantly.</blockquote><!--kg-card-begin: embed--><figure><iframe width="200" height="113" src="https://www.youtube.com/embed/y2l2a_sHdY0?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></figure><!--kg-card-end: embed--><p>With the release of CTO.ai's Serverless Kubernetes we've made our platform available using a public cloud SaaS/PaaS pricing model so any developer can easily start deploying Cloud Native Applications, without worrying about Operations.</p><div><p>Customers who sign up today will be able to start instantly using our Serverless Kubernetes to host their Applications, CI/CD Pipelines &amp; GitOps / ChatOps while also measuring their delivery in real time using <a href="https://cto.ai/insights">Delivery Insights</a>. </p><p>By simply installing our CLI, we give anyone the ability to instantly build and release a containerized application on our managed Kubernetes. In the coming weeks we'll make it so you can connect our Github App to your organization and easily configure event driven workflows that go way beyond your CI/CD builds.</p><p>We also continue to support secrets, logging, configurations &amp; of course; Slack, too!</p><p>Enterprise teams can also contact us to setup a Service Mesh with their existing private cloud Kubernetes clusters, to enable them to manage their infrastructure in house using the infrastructure tooling of their choice, while activating our intuitive control plane and data plane, for their developers, as well. This enables our larger customers to manage their infrastructure directly but still empower all of their developers with the agility that is at the core of every digital transformation strategy.</p></div><div><p>With this expanded platform, our goal is to help advance the adoption of Cloud Native for developers around the world, on teams of any size, by focusing on creating an intuitive on-ramp that drives deep insight into the positive business impact that DevOps can have in any organization, but in a directly measurable way.</p><p>Our Service Mesh is designed to to support larger organizations as they seek to scale beyond the limitations of traditional PaaS. Helping them get higher leverage on their large and complex private cloud systems through 10x developer agility.</p></div><p>With this, we hope to solve for a large portion of the $300B of developer productivity that is lost in corporations every year according to <a href="https://stripe.com/en-ca/reports/developer-coefficient-2018#:~:text=a%20%24300B%20opportunity%20for,they%20could%20be%20doing%20differently.">The Stripe Developer Coefficient</a>.</p><p>Developing this unique platform would not have been possible without support and input from the DevOps teams at venture funded startups such as Axial, TrueBill, Cedar, YellowDig, and Remine, as well as other experts in the DevOps community.</p><p>A big thank you to all of those who have contributed to this important milestone.</p><p>We'd love to hear what you think. Feedback is always welcome &amp; encouraged.</p><p><a href="https://cto.ai/">Sign up to try out the platform</a>, and share your thoughts on <a href="https://www.producthunt.com/posts/cto-ai-kubernetes-cloud">ProductHunt</a> today.</p><!--kg-card-begin: hr--><hr><!--kg-card-end: hr--><!--kg-card-begin: image--><figure><img src="https://cto.ai/blog/content/images/2021/02/header.png"><figcaption>-</figcaption></figure><!--kg-card-end: image--><!--kg-card-begin: image--><figure><img src="https://cto.ai/blog/content/images/2021/02/services.png"></figure><!--kg-card-end: image--><!--kg-card-begin: image--><figure><img src="https://cto.ai/blog/content/images/2021/02/pipelines.png"></figure><!--kg-card-end: image--><!--kg-card-begin: image--><figure><img src="https://cto.ai/blog/content/images/2021/02/commands.png"></figure><!--kg-card-end: image--><!--kg-card-begin: image--><figure><img src="https://cto.ai/blog/content/images/2021/02/insights.png"></figure><!--kg-card-end: image--><!--kg-card-begin: image--><figure><img src="https://cto.ai/blog/content/images/2021/02/Services@2x.png"></figure><!--kg-card-end: image--><!--kg-card-begin: image--><figure><img src="https://cto.ai/blog/content/images/2021/02/Trio-Shot@2x.png"></figure><!--kg-card-end: image-->
			</div><!-- .post-content -->
			<!-- .post-footer -->
		</article></div>]]>
            </description>
            <link>https://cto.ai/blog/announcing-cto-ai-kubernetes-paas/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26170612</guid>
            <pubDate>Wed, 17 Feb 2021 19:41:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Guesbook for my static site using GitHub Gist and Netlify Functions]]>
            </title>
            <description>
<![CDATA[
Score 19 | Comments 9 (<a href="https://news.ycombinator.com/item?id=26170376">thread link</a>) | @_fat_santa
<br/>
February 17, 2021 | https://sunnygolovine.com/guestbook | <a href="https://web.archive.org/web/*/https://sunnygolovine.com/guestbook">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="__next"><div><header><div><a href="https://github.com/sgolovine"></a><a href="https://linkedin.com/in/SunnyGolovine"></a><a href="https://instagram.com/sgolovine"></a><p><a href="https://sunnygolovine.com/guestbook">Guestbook</a></p></div><div><div><p><a href="https://sunnygolovine.com/">Home</a><a href="https://sunnygolovine.com/blog">Blog</a><a href="https://sunnygolovine.com/resume">Resume</a><a href="https://sunnygolovine.com/contact">Contact</a></p></div></div></header><main><p>Sign the guestbook!</p><div><p>0<!-- -->/160</p><hr></div></main></div></div></div>]]>
            </description>
            <link>https://sunnygolovine.com/guestbook</link>
            <guid isPermaLink="false">hacker-news-small-sites-26170376</guid>
            <pubDate>Wed, 17 Feb 2021 19:25:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Link Preview (Unfurl/Expand) API]]>
            </title>
            <description>
<![CDATA[
Score 13 | Comments 5 (<a href="https://news.ycombinator.com/item?id=26170209">thread link</a>) | @dyoder
<br/>
February 17, 2021 | https://www.dashkite.com/products/link-preview | <a href="https://web.archive.org/web/*/https://www.dashkite.com/products/link-preview">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.dashkite.com/products/link-preview</link>
            <guid isPermaLink="false">hacker-news-small-sites-26170209</guid>
            <pubDate>Wed, 17 Feb 2021 19:10:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The 5 Stages of Engineering Effectiveness]]>
            </title>
            <description>
<![CDATA[
Score 9 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26170024">thread link</a>) | @tomasrb
<br/>
February 17, 2021 | https://www.okayhq.com/blog/the-5-stages-of-engineering-effectiveness | <a href="https://web.archive.org/web/*/https://www.okayhq.com/blog/the-5-stages-of-engineering-effectiveness">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p>Over the last decade, <a href="https://www.linkedin.com/in/tomasrb/" rel="nofollow noopener noreferrer" target="_blank">my cofounder</a> and <a href="https://www.linkedin.com/in/antoineboulanger/" rel="nofollow noopener noreferrer" target="_blank">I</a> have engaged in hundreds of conversations with engineering leaders on our journey to improve engineering. We talked with Silicon Valley startups just getting started as well as established enterprises with thousand-person headcounts.</p>
<p>What we discovered surprised us: <strong>Not only can software engineering effectiveness be measured; most engineering teams follow the exact same evolution.</strong></p>
<p>From a two-person startup to a thousand-person team, engineering success always comes from the same fundamentals: 1) Hire excellent engineers and 2) <a href="https://www.okayhq.com/blog/engineering-productivity-can-be-measured" rel="nofollow noopener noreferrer" target="_blank">Remove the blockers that prevent their success</a>.</p>
<p>Different team sizes, however, change the ways these fundamentals manifest. Broadly, they fit into five stages:</p>
<ul>
<li>Qualitative</li>
<li>Data-Curious</li>
<li>People-Driven Engineering Effectiveness</li>
<li>Software-Driven Effectiveness</li>
<li>Engineering Effectiveness as a Strategic Advantage</li>
</ul>
<p><img src="https://www.okayhq.com/assets/img/5_stages_o.a91f2d0.png" alt="The 5 stages of Engineering Effectiveness"></p><p>While you're perusing these stages, keep in mind that every engineering org starts somewhere and every org can reach stage 5. Regardless of the size or age of your team, your engineering effectiveness would benefit from:</p>
<ol>
<li>Objectively assessing your current engineering org: What stage are you in and why?Ã‚&nbsp;</li>
<li>Solidifying a strong foundation: Ensure you've built all the components of your current and lower stages.Ã‚&nbsp;</li>
<li>Aiming higher: Add advanced functions to accelerate your achievement.Ã‚&nbsp;Ã‚&nbsp;</li>
</ol>
<p>Of course, individual organizations have their own unique traits, so you should feel free to make this framework your own. On the whole, however, here's how to grow:Ã‚&nbsp;</p>
<h2 id="stage-1-qualitative">Stage 1: Qualitative</h2>
<p>Most engineering teams start small. At this point (usually around 1-20 people), the team is evolving rapidly and there aren't many objective metrics to measure success.</p>
<p><strong>In stage 1, the most successful engineering organizations build a strong social, cultural, and behavioral foundation.</strong> This foundation should include implementing widely-known best practices like:</p>
<ul>
<li><a href="https://www.scrum.org/resources/what-is-a-sprint-retrospective" rel="nofollow noopener noreferrer" target="_blank">Sprint retrospectives</a> to identify patterns of effectiveness</li>
<li><a href="https://en.wikipedia.org/wiki/Test-driven_development" rel="nofollow noopener noreferrer" target="_blank">Test-driven development</a> and version control with small, frequent commits</li>
<li>Flexible hours with high employee autonomy</li>
</ul>
<p>With stage 1 being almost metric-free, engineering success relies almost entirely on your first-line managers.  We've found these managers to be the differentiators between successful stage 1 orgs and those that flounder. If your org is in stage 1, be on the lookout for strong managers: ones who are either experienced and well-trained or inexperienced but exceptionally fast learners.</p>
<p>To support a stage 1 engineering org, company leadership should create a high-trust environment in team meetings/all hands (to encourage feedback) and keep a pulse on morale through high-quality one-on-ones. It's also helpful for long-term culture to invest in manager growth and development, particularly around people skills and EQ. (We've found <a href="https://rework.withgoogle.com/guides/managers-develop-and-support-managers/steps/introduction/" rel="nofollow noopener noreferrer" target="_blank">Google's framework</a> to be particularly effective at helping managers become <a href="https://en.wikipedia.org/wiki/Servant_leadership" rel="nofollow noopener noreferrer" target="_blank">servant leaders</a>.)</p>
<p>In stage 1, engineering revolves around culture: you'll succeed if your managers can support and align your team.Ã‚&nbsp;Ã‚&nbsp;</p>
<h2 id="stage-2-data-curious-and-reactive">Stage 2: Data-Curious and Reactive</h2>
<p><strong>Stage 2 is when most orgs first become aware of engineering effectiveness as an area to improve, so they start dabbling in data.</strong></p>
<p>As most stage 2 orgs are small and fast-growing (20-50 people), they must still rely heavily on first-line managers for qualitative measures like:Ã‚&nbsp;</p>
<ul>
<li><a href="https://en.wikipedia.org/wiki/OKR" rel="nofollow noopener noreferrer" target="_blank">OKR</a> completion</li>
<li>Team engagement</li>
<li>Hiring targets</li>
</ul>
<p>Stage 2 will also bring your first quantitative measures, typically in the form of ad hoc metrics like:Ã‚&nbsp;</p>
<ul>
<li>Bug counts</li>
<li>Alert rates</li>
<li>Employee satisfaction surveys</li>
</ul>
<p>On the dev ops side, successful stage 2 orgs typically begin investing in a pipeline aimed at achieving continuous delivery. These investments often include custom scripts or open-source tools that provide snapshots of their DORA metrics.</p>
<p>These instantaneous measurements and metrics help make stage 2 engineering orgs more effective than those in stage 1. That said, these stage 2 improvements are typically ad hoc, one-off, and isolated. Instead of a comprehensive, real-time dashboard or even a long-term feedback loop, stage 2 orgs act on instantaneous information as it arises, necessarily making the org's improvements reactive.</p>
<h2 id="stage-3-people-driven-engineering-effectiveness">Stage 3: People-Driven Engineering Effectiveness Ã‚&nbsp;</h2>
<p>The typical stage 3 engineering org will have 50-250 engineers and feel like it's in a transition stage between independent qualitative assessments and fully-automated metrics.Ã‚&nbsp;</p>
<p><strong>In stage 3, the best engineering teams establish a dedicated function for engineering effectiveness</strong>, most frequently through a dedicated internal team or by hiring an engineering chief of staff. This dedicated function will begin to make:</p>
<ul>
<li>A regular cadence of investments in dev tech, processes, and tooling</li>
<li>Looker dashboards to capture DORA metrics in real time</li>
<li><a href="https://cloud.google.com/blog/products/gcp/sre-fundamentals-slis-slas-and-slos" rel="nofollow noopener noreferrer" target="_blank">SLAs/SLOs</a> for engineering effectiveness</li>
<li>Tangible, objectively-verifiable effectiveness metrics that will hold managers accountableÃ‚&nbsp;</li>
</ul>
<p><strong>While stage 3 brings both long-term metrics and systems that provide a holistic view, most of these activities will be performed by hand.</strong> For example, the engineering Chief of Staff or program manager might ask directors to fill out a spreadsheet, which will then evolve into a powerpoint presentation that prompts the VP to make adjustments.</p>
<p><strong>A successful stage 3 engineering org will implement a dedicated engineering effectiveness team to measure metrics and incorporate adjustments at a reliable cadence.</strong></p>
<h2 id="stage-4-software-driven-effectiveness">Stage 4: Software-Driven Effectiveness</h2>
<p><strong>In stage 4, dedicated software enters the picture, bringing continuous improvement to every engineering stage.</strong></p>
<p>The typical stage 4 engineering org will have hundreds or thousands of engineers. At this scale, treating engineering like a black box is no longer acceptable. Instead, managers will require precise, quantitative assessments instead of qualitative or imprecise measures.</p>
<blockquote>
<p>The most successful stage 4 teams automate a high variety of engineering metrics, either through dashboards built by a full-time engineering effectiveness team or by leveraging <a href="https://www.okayhq.com/" rel="nofollow noopener noreferrer" target="_blank">third-party software</a></p>
</blockquote>
<p>These dashboards gather actionable, real-time effectiveness metrics at every level of management:</p>
<ol>
<li>The CTO sets high-level metrics and goals, typically through a dashboard they share with the other executives.Ã‚&nbsp;</li>
<li>Directors/mid-level managers set goals for their sub-orgs and monitor their metrics for early signs of issues.</li>
<li>First-line managers provide root-cause analysis on the specific factors contributing to high-level metrics.</li>
<li>Every engineering OKR includes goals around effectiveness and improvement.</li>
</ol>
<p>Before stage 4, engineering teams often aim to measure everything. In stage 4, they aim more precisely at high-value metrics like engineer utilization, <a href="https://www.okayhq.com/blog/engineering-productivity-can-be-measured" rel="nofollow noopener noreferrer" target="_blank">blockers</a>, and work-life balance. Stage 4 brings the ability for an org to diagnose specific symptoms all the way down to their root causes, where they can form coherent, data-backed stories that inform pinpointed improvements. The most successful stage 4 teams will even start uncovering personalized metrics that they find particularly correlate to their success.</p>
<p><strong>By combining automated, real-time metrics with the culture of continuous improvement built in stages 1-3, stage 4 teams can evolve their effectiveness into an always-running, well-oiled improvement machine.</strong></p>
<h2 id="stage-5-engineering-effectiveness-as-a-strategic-advantage">Stage 5: Engineering Effectiveness as a Strategic Advantage</h2>
<p><strong>Stage 5 turns engineering effectiveness into a strategic lever that helps the company achieve precise business goals.</strong></p>
<p>Even though a typical stage 5 team will contain hundreds or thousands of engineers all around the world, the best stage 5 orgs run like a well-coordinated symphony: individual contributions come together to create a single unit that's much more than the sum of its parts.</p>
<p>On top of stage 4's software-based measurement and org-wide culture of improvement, stage 5 adds a strategic lens. The best stage 5 organizations can make calculated risks involving conscious trade-offs. Perhaps the org extrapolates a concerning quality trend and adjusts its features long before engineers or customers start to complain. The best stage 5 organizations can calculate specific risk levels and readjust without unpleasant surprises.</p>
<p>High-performing stage 5 teams typically engage in:</p>
<ul>
<li>Industry/peer-group <a href="https://dealstruck.com/resources/the-power-of-peer-benchmarking/" rel="nofollow noopener noreferrer" target="_blank">benchmarking</a> (to understand their effectiveness compared to other companies)</li>
<li>Automatic implementation of the latest effectiveness research (to accelerate constant improvement)</li>
<li>Anticipatory activities at every stage in the org (to predict potential problems before they arise)Ã‚&nbsp;</li>
<li>Thought leadership on new best practices of engineering effectiveness (naturally uncovered as a result of their experience)Ã‚&nbsp;</li>
<li>Full transparency/understanding of engineering metrics, even outside of the engineering org (to aid company-wide improvement)</li>
<li>Calculated risks (to achieve precise business aims)</li>
</ul>
<p>From the outside, a stage 5 team looks like a strong engineering brand. It can accelerate and adjust, attract top talent while achieving business aims.</p>
<h2 id="toward-engineering-effectiveness">Toward Engineering EffectivenessÃ‚&nbsp;</h2>
<p>Engineering effectiveness is too expensive to be left to chance. Start by assessing where your team currently is. Are you:Ã‚&nbsp;</p>
<ul>
<li>Sufficiently small that metrics are still a "nice to have"?</li>
<li>Data-curious and ready to react?</li>
<li>In need of a dedicated effectiveness team?</li>
<li>Positioned to produce a continuously improving organizationÃ‚&nbsp;?</li>
<li>Able to precisely tune your priorities to enable the company's long-term strategy?</li>
</ul>
<p><strong>Then, solidify your position at your current stage, building a solid foundation on which you can expand.</strong></p>
<p>While every engineering team has its own individual nuance, most will follow this consistent evolution. We uncovered these stages through years of observation, but there's still more improvement to be applied to engineering.</p>
<p>We've made it our mission to improve engineering effectiveness. If you've uncovered your own trends or if you're curious for more, <a href="https://okayhq.typeform.com/to/O47Fx3Q7" rel="nofollow noopener noreferrer" target="_blank">let us know</a>. We'd love to improve engineering effectiveness for everyone.</p></div></div></div>]]>
            </description>
            <link>https://www.okayhq.com/blog/the-5-stages-of-engineering-effectiveness</link>
            <guid isPermaLink="false">hacker-news-small-sites-26170024</guid>
            <pubDate>Wed, 17 Feb 2021 18:54:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Visualization of 40M Cell Towers]]>
            </title>
            <description>
<![CDATA[
Score 481 | Comments 135 (<a href="https://news.ycombinator.com/item?id=26169747">thread link</a>) | @alprc
<br/>
February 17, 2021 | https://alpercinar.com/open-cell-id/ | <a href="https://web.archive.org/web/*/https://alpercinar.com/open-cell-id/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

<!-- <hr> -->

<p>
	
	<a href="https://www.opencellid.org/">OpenCelliD</a> is the world's largest 
	open database of cell towers with a license
	<a href="https://creativecommons.org/licenses/by-sa/4.0/">CC BY-SA 4.0</a>
</p>

<p>
	Data has full world coverage and freely available for
	<a href="https://www.opencellid.org/">download.</a>
</p>

<p>
	This tabular data[1] has ~40 million rows and 6 columns in it but only 3
	columns (latitude, longitude, and type) are used in this visualization.
</p>

<p><a href="https://alpercinar.com/open-cell-id/csv.png" target="_blank">
	<img src="https://alpercinar.com/open-cell-id/csv.png" alt="">
</a>

<em>[1] Structure of input data.</em></p><p>
	Above table data is read line by line and grouped by their location info.
	Grouping is done as if they were <a href="https://developers.planet.com/planetschool/xyz-tiles-and-slippy-maps/">XYZ Tiles.</a></p>


<p>
	First, empty 2d integer arrays for each tile are created and its elements are 
	initialized with value = 0. 
	Those values hold a counter that shows the number of rows that 
	geographically contained in that pixel.
	Every row increases the relevant counter by one[2]. 
	After iterating all rows with this method, we end up with a bunch of
	integer values (in different 2d arrays) that represent row counts per region.
</p>

<p><a href="https://alpercinar.com/open-cell-id/step2.png" target="_blank">
	<img src="https://alpercinar.com/open-cell-id/step2.png" alt="">
</a>
<em>[2] Each row increases relevant counter.</em></p><p>
	In order to achieve city-level resolution for visualization, tiles up to
	zoom level 9 should be generated. 
	<a href="https://www.maptiler.com/google-maps-coordinates-tile-bounds-projection/">
	For XYZ tiles, the number of tiles per zoom level is 4^zoom.</a>
	Therefore, for zoom levels between 0 to 9, the number of tiles that should be generated 
	becomes 4^0 + 4^1 + 4^2 + .. + 4^9 which equals to 349525.
	Every tile has 256x256 integer values.
	Even with using 32 bit-sized integer values, 
	one tile occupies 256 * 256 * 32 bit = 256 kilobytes of storage,
	and <b>349525 tiles</b> occupies <b>87 gigabytes of storage</b> which is 
	definitely not acceptable.
</p>

<p>
	To solve this size problem every tile blob is compressed independently
	with a modern compression algorithm 
	<a href="https://github.com/google/brotli">brotli</a>.
	Despite being slow to encode, brotli has a fast decoding speed and high compression ratio
	compared to older compression methods like gzip. Additionally, 
	brotli-compressed-data is <a href="https://caniuse.com/#search=brotli">
	natively decodable with all modern browsers</a>.
	Since there are no cell towers in oceans or uninhabitable areas, tiles for those regions 
	are full of zero values or very sparse. Due to this high redundancy,
	compression performed extremely well for those regions (256kb compressed to 20~100bytes).
</p>

<p>
    In order to simplify the algorithm, it is described as if there was only one 
    counter value in each pixel, but there are 4 counter values per pixel each
    holding number of row counts for different cell tower types[3]
</p>


<p><a href="https://alpercinar.com/open-cell-id/step3.png" target="_blank">
	<img src="https://alpercinar.com/open-cell-id/step3.png" alt="">
</a>
<em>[3] Every pixel stores more than one channels (counter)</em></p><p>
    Even though these tiles are stored like XYZ tiles, they are not 
    valid XYZ tiles.Since these blobs are just brotli-compressed-integer-arrays.
    Visualization requires a blob to image conversion. This conversion is
    done by client side javascript and HTML5 Canvas API.
</p>

<p>
    Underlying map displaying library in this visualization is
    <a href="https://leafletjs.com/" target="_blank">leaflet</a>.
    Kudos to leaflet author(s) for writing such a well documented and extendable
    map library, I was able to write a custom tile layer for leaflet that 
    intercepts the image tile requests made by leaflet and redirects those
    image tile requests to an image generating (client-side) web worker that 
    works like a tile server. Web worker follows a simple algorithm for image generation.

    It reads the row count values pixel by pixel and generates a color for that
    pixel (higher the row count lighter and more opaque the pixel color).
</p>
<p>
    To summarize, this was a fun project for me to work on and I learned a lot 
    about data compression and multi-threading while working on this. 
    By off-loading compute-intensive tasks to web-workers, very impressive visualizations
    can be made even without sacrificing a single FPS drop on UI thread. 
</p>


</div></div>]]>
            </description>
            <link>https://alpercinar.com/open-cell-id/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26169747</guid>
            <pubDate>Wed, 17 Feb 2021 18:29:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Passwordless Logins with Yubikey]]>
            </title>
            <description>
<![CDATA[
Score 98 | Comments 64 (<a href="https://news.ycombinator.com/item?id=26169369">thread link</a>) | @adl1995
<br/>
February 17, 2021 | https://adl1995.github.io/passwordless-logins-with-yubikey.html | <a href="https://web.archive.org/web/*/https://adl1995.github.io/passwordless-logins-with-yubikey.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Yubikey is currently the de facto device for <span>U2F</span> authentication. It enables adding an extra layer of security on top of <span>SSH</span>, system login, signing <span>GPG</span> keys, and so on. It is also compatible with several other authentication methods, such as WebAuthn and <span>PAM</span>.</p>
<p>This post will show how to leverage your Yubikey for unlocking the system lock-screen, both with and without using a password. It will then delve into how to automatically lock the screen when the Yubikey is&nbsp;unplugged.</p>
<p>To achieve logins with Yubikeys we require a <span>PAM</span> configuration. <span>PAM</span> or Pluggable Authentication Modules define the authentication flow for common Linux utilities, such as <code>sudo</code>, <code>su</code>, and <code>passwd</code>. We will override the default authentication flow for the <a href="https://linux.die.net/man/1/xlock">xlock</a> lock manager to allow logins with&nbsp;Yubikey.</p>
<blockquote>
<p>Note: The above process should be similar across most lock managers, such as <code>i3lock</code> or <code>xscreensaver</code>.</p>
</blockquote>
<h2>Creating a <span>PAM</span>&nbsp;configuration</h2>
<p>We shall first replicate the default authentication provided with xlock using <span>PAM</span>. With this configuration the user should only be able to log in with their&nbsp;password.</p>
<p>All <span>PAM</span> configuration files lie under the <code>/etc/pam.d/</code> directory. We create a file named <code>xlock</code> which replicates the default&nbsp;authentication:</p>
<div><pre><span></span><code>$ cat /etc/pam.d/xlock
<span>#%PAM-1.0</span>
auth            include         system-auth
</code></pre></div>
<blockquote>
<p>Note: For the above configuration file to take effect the tool (<code>xlock</code>) must be <span>PAM</span> compatible. We can confirm that <code>xlock</code> is <span>PAM</span> compatible by inspecting the output of <code>ldd /usr/bin/xlock | grep libpam.so</code>.</p>
</blockquote>
<p>The first comment line indicates the <span>PAM</span> version. The lines that follow define the authentication&nbsp;flow:</p>
<ul>
<li><code>auth</code> is the module interface responsible for verifying the userâ€™s&nbsp;password.</li>
<li><code>include</code> is the <span>PAM</span> control flag which <em>includes</em> the <code>system-auth</code> configuration file (this file defines the default authentication flow). This flag can also be used to load modules, as we shall see&nbsp;later.</li>
</ul>
<blockquote>
<p>Note: There is an excellent <a href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/6/html/managing_smart_cards/pam_configuration_files">documentation</a> provided by RedHat on <span>PAM</span> configuration&nbsp;files.</p>
</blockquote>
<h3>Supporting Yubikey&nbsp;logins</h3>
<p>We shall now add Yubikey login functionality to our <span>PAM</span> configuration, but we first need to install the Yubico module for <span>PAM</span> and set it&nbsp;up.</p>
<p>Yubico, the company behind Yubikeys, exposes the <a href="https://developers.yubico.com/yubico-pam/">pam_yubico.so</a> module which can be used for Yubikey&nbsp;authentication.</p>
<p>It provides two authentication mechanisms, the <code>client</code> mode and the <code>challenge-response</code> mode. The <code>client</code> mode sends a request to the Yubico server for verifying the userâ€™s <span>OTP</span>, and requires an active Internet connection for the user to login. As this is inconvenient we shall only explore the <code>challenge-response</code> mode in this&nbsp;post.</p>
<p>Before proceeding with the configuration the <code>pam_yubico</code> package must be installed manually. This package is easily available across most Linux distributions. On Arch Linux it can be installed&nbsp;with:</p>

<p>We next add Yubikey mappings before setting the challenge-response&nbsp;credential.</p>
<blockquote>
<p>Warning: It is recommended that you use a secondary account to perform the next steps as there is a risk of permanently locking your account (in case of <span>PAM</span>&nbsp;misconfiguration).</p>
</blockquote>
<h4>Adding&nbsp;mappings</h4>
<p>Each Yubikey must be paired with a unique public <span>ID</span> which the <code>pam_yubico</code> module uses to uniquely identify the user. The public <span>ID</span> consists of the first 12 characters extracted from the <span>OTP</span>&nbsp;token.</p>
<p>To obtain your Yubikeyâ€™s public <span>ID</span> open up your shell and press the Yubikey button. You will see a similar output as&nbsp;below:</p>
<div><pre><span></span><code><span>vvctffbvkhdnliklfhbbfiecudthfvrvuhnhtirehidr</span>
</code></pre></div>
<p>Now copy take the first 12 characters (<code>vvctffbvkhdn</code>) and add them to a file named <code>yubikey_mappings</code> in the <code>/etc/</code> directory, along with your username. In our case this will&nbsp;be:</p>
<div><pre><span></span><code>$ cat /etc/yubikey_mappings
adeel:vvctffbvkhdn
</code></pre></div>
<blockquote>
<p>Note: This file also allows specifying multiple Yubikey mappings, each separated by a new&nbsp;line.</p>
</blockquote>
<h4>Setting the challenge response&nbsp;credential</h4>
<p>Yubikey needs to somehow verify the generated <span>OTP</span> (One Time Password) when it tries to authenticate the user. It does so by using the <code>challenge-response</code> mode.</p>
<p>To set up the <code>challenge-response</code> mode, we first need to install the Yubikey manager tool called <code>ykman</code>. On Arch Linux it can be installed&nbsp;with:</p>
<div><pre><span></span><code>$ pacman -S yubikey-manger
</code></pre></div>
<p>The <code>ykman</code> tool will generate a secret credential and store it in a local file. Whenever the user tries to login with <code>xlock</code>, the <code>pam_yubico</code> module will verify the generated <span>OTP</span> against the stored&nbsp;credential.</p>
<p>The challenge response credential can be set on slot 2 of the Yubikey&nbsp;with:</p>
<div><pre><span></span><code>$ ykman otp chalresp --generate <span>2</span>
Using a randomly generated key: 29eb38b6f50b246c46f954af9710a77c78792114
Program a challenge-response credential in slot <span>2</span>? <span>[</span>y/N<span>]</span>: y
</code></pre></div>
<blockquote>
<p>Warning: Ensure that the slot youâ€™re writing the data to doesnâ€™t already contain any credential, as it might not be&nbsp;recoverable!</p>
</blockquote>
<p>After the <code>challenge-response</code> credential is set it needs to be written to a local file which will be later read by <code>pam_yubico</code>.</p>
<p>Yubico provides another tool called <code>ykpamcfg</code> (which should be bundled with the <code>yubikey-manger</code> package) to write this file to disk. It takes the Yubikey slot number as its parameter and writes the secret to a&nbsp;file:</p>
<div><pre><span></span><code>$ ykpamcfg -2
Stored initial challenge and expected response in <span>'/home/adeel/.yubico/challenge-&lt;Serial ID&gt;'</span>.
</code></pre></div>
<h3>Updating the Linux <span>PAM</span>&nbsp;configuration</h3>
<p>We shall now update the <code>/etc/pam.d/xlock</code> file and add the Yubico <span>PAM</span> at the very&nbsp;beginning.</p>
<div><pre><span></span><code>$ cat /etc/pam.d/xlock
<span>#%PAM-1.0</span>

auth  sufficient  pam_yubico.so debug <span>mode</span><span>=</span>challenge-response <span>authfile</span><span>=</span>/etc/yubikey_mappings
auth  include     system-auth
</code></pre></div>
<p>We pass three parameters to the <code>pam_yubico.so</code> module:</p>
<ul>
<li><code>debug</code> prints all the authentication steps to the console when the â€˜Enterâ€™ key is&nbsp;pressed.</li>
<li><code>mode</code> specifies which mode the module will use for authentication (<code>challenge-response</code> or <code>client</code>).</li>
<li><code>authfile</code> points to the credential file written by the <code>ykpamcfg</code> tool. </li>
</ul>
<p>Setting the module type to <code>sufficient</code> means that if Yubikey authentication succeeds, no further steps will be processed and the user will get logged in. This is the key point which enables passwordless logins. However, in the event of authentication failure, remaining authentication steps will still be applied, i.e. the user can still log in with their password if the Yubikey is not plugged&nbsp;in.</p>
<p>If the module type is set to <code>required</code> instead of <code>sufficient</code> it will enable Two-Factor Authentication (<span>2FA</span>) which will require the user to plug in their Yubikey <em>and</em> enter their password to&nbsp;login.</p>
<blockquote>
<p>Note: For passwordless logins the user will need to press the <code>Enter</code> with their Yubikey plugged in to unlock their&nbsp;screen.</p>
</blockquote>
<p>At this stage you should be able unlock your screen with they&nbsp;Yubikey.</p>
<blockquote>
<p>Note: You may need to replug your Yubikey for the changes to take&nbsp;effect.</p>
</blockquote>
<h2>Automatically locking the screen when Yubikey is&nbsp;unplugged</h2>
<p>Up till locking the screen still requires manually invoking the <code>xlock</code> command. It would be nice if we can somehow automatically lock the screen whenever our Yubikey is unplugged. We can achieve this with&nbsp;Udev.</p>
<p>Udev is the device manager used in Linux which can be used for a myriad of tasks. It tracks the state changes for all external devices, for example, it can be used to identify when a <span>USB</span> device is plugged or unplugged. Each device outputs a series of attributes which can be used to uniquely identify&nbsp;it.</p>
<p>We shall use these attributes to create a Udev rule which triggers an <code>xlock.service</code> Systemd service when the Yubikey is&nbsp;unplugged.</p>
<blockquote>
<p>Note: We can also achieve this with a Shell script instead of Systemd, but Udev discourages executing long-running programs using scripts as it terminates them after a certain time&nbsp;period.</p>
</blockquote>
<h3>Creating the Systemd&nbsp;service</h3>
<p>Systemd is the Linux service manager which can be used to launch user processes. We create a file named <code>xlock.service</code> in the <code>/etc/systemd/system/</code> directory:</p>
<div><pre><span></span><code>$ cat /etc/systemd/system/xlock.service
<span>[</span>Unit<span>]</span>
<span>Description</span><span>=</span>xlock

<span>[</span>Service<span>]</span>
<span>User</span><span>=</span>adeel
<span>Type</span><span>=</span>simple
<span>Environment</span><span>=</span><span>DISPLAY</span><span>=</span>:0
<span>ExecStart</span><span>=</span>/usr/bin/xlock 

<span>[</span>Install<span>]</span>
<span>WantedBy</span><span>=</span>multi-user.target
</code></pre></div>
<ul>
<li>The <code>Type=simple</code> implies that this service does not exit after&nbsp;execution.</li>
<li>The <code>Environment</code> tag specifies which display should be locked (<code>0</code> is the default&nbsp;display).</li>
<li>The <code>ExecStart</code> tag takes a path of the binary or script it will&nbsp;execute.</li>
</ul>
<blockquote>
<p>Note: Consult the <a href="https://www.freedesktop.org/software/systemd/man/systemd.service.html">official docs</a> to explore Systemd in&nbsp;detail.</p>
</blockquote>
<h3>Creating the Udev&nbsp;rule</h3>
<p>We first need to identify a set of unique attributes for our device (Yubikey). The <code>udevadm</code> tool allows monitoring Udev output whenever a device state changes. We shall invoke the following command and then remove our&nbsp;Yubikey:</p>
<div><pre><span></span><code>$ udevadm monitor --environment --udev 
monitor will print the received events <span>for</span>:
UDEV - the event which udev sends out after rule processing

UDEV  <span>[</span><span>461872</span>.738673<span>]</span> remove   /devices/pci0000:00/0000:00:14.0/usb1/1-2/1-2.1/1-2.1:1.0/0003:1050:0407.0157/input/input294/event18 <span>(</span>input<span>)</span>
<span>ACTION</span><span>=</span>remove
<span>ID_VENDOR</span><span>=</span>Yubico
<span>SUBSYSTEM</span><span>=</span>input
<span>DEVNAME</span><span>=</span>/dev/input/event18
<span>ID_INPUT_KEY</span><span>=</span><span>1</span>
...
</code></pre></div>
<p>We only show a truncated output above, but once you have identified the attributes you would like to use, create a file named <code>yubikey-actions.rules</code> in the <code>/etc/udev/rules.d/</code> directory:</p>
<div><pre><span></span><code>$ cat /etc/udev/rules.d/yubikey-actions.rules 
<span>ACTION</span><span>==</span><span>"remove"</span>, ENV<span>{</span>ID_MODEL_ID<span>}==</span><span>"0407"</span>, ENV<span>{</span>ID_VENDOR_ID<span>}==</span><span>"1050"</span>, <span>RUN</span><span>+=</span><span>"/usr/bin/systemctl start xlock.service"</span>
</code></pre></div>
<p>It might be worthwhile to reload the configuration for both Systemd and&nbsp;Udev:</p>
<div><pre><span></span><code>$ systemctl daemon-reload
$ udevadm control --reload
</code></pre></div>
<p>If everything worked out fine your screen should now get locked whenever you remove your&nbsp;Yubikey.</p>
<h2>References:</h2>
<ul>
<li><a href="https://fedoraproject.org/wiki/Using_Yubikeys_with_Fedora#Using_a_Yubikey_to_authenticate_to_a_machine_running_Fedora">Using a Yubikey to authenticate to a machine running&nbsp;Fedora</a></li>
<li><a href="https://ocramius.github.io/blog/yubikey-for-ssh-gpg-git-and-local-login/">YubiKey for <span>SSH</span>, Login, <span>2FA</span>, <span>GPG</span> and Git&nbsp;Signing</a></li>
<li><a href="http://blog.fraggod.net/2015/01/12/starting-systemd-service-instance-for-device-from-udev.html">Starting systemd service instance for device from&nbsp;udev</a></li>
</ul></div></div>]]>
            </description>
            <link>https://adl1995.github.io/passwordless-logins-with-yubikey.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26169369</guid>
            <pubDate>Wed, 17 Feb 2021 17:59:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Dapr v1.0]]>
            </title>
            <description>
<![CDATA[
Score 9 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26168887">thread link</a>) | @tevlon
<br/>
February 17, 2021 | https://blog.dapr.io/posts/2021/02/17/announcing-dapr-v1.0/ | <a href="https://web.archive.org/web/*/https://blog.dapr.io/posts/2021/02/17/announcing-dapr-v1.0/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
	
	<p>The distributed application runtime is now production ready</p>
	
	
	<p>Today we are excited to announce the <a href="https://github.com/dapr/dapr/releases/tag/v1.0.0">v1.0 release</a> of the Distributed Application Runtime (<a href="https://dapr.io/">Dapr</a>), which has achieved the stability and enterprise readiness to be designated production ready. Dapr is an open source, portable, event-driven runtime that makes it easy for developers to build resilient, microservice, stateless and stateful applications that run on the cloud and edge. Dapr enables developers to focus on writing business logic and not solving distributed system challenges, thereby significantly improving their productivity, and reducing development time. Dapr lowers the bar for entry to build modern cloud native applications based on a microservices architecture and with this v1.0 release, Dapr applications can be deployed to self-hosted infrastructure or Kubernetes clusters in production scenarios.</p>
<p>Since its <a href="https://cloudblogs.microsoft.com/opensource/2019/10/16/announcing-dapr-open-source-project-build-microservice-applications/">first release in Oct 2019</a>, Dapr has had <a href="https://github.com/dapr/dapr/tags">14 releases</a>, each one building on tremendous community and user feedback to drive improvements, stability and performance. These releases were grounded in building real applications that reflect what developers are doing today when developing cloud native applications; whether on cloud, edge or private infrastructure, and with the community stepping up to contribute Dapr components that integrate with Azure, AWS, Alibaba and Google clouds.</p>
<h2 id="solving-distributed-application-challenges-in-real-world-scenarios">Solving distributed application challenges in real world scenarios</h2>
<p>From its founding, the Dapr open source project is for developers who are building new real world greenfield applications as well as those migrating and leveraging existing applications and components in cloud-native architectures. Key to Daprâ€™s approach is to meet developers and enterprises where they are today, helping to modernize their applications, and leverage their existing skills in cloud native and micro-services architecture. In the v1.0 release we have focused on Kubernetes as the primary hosting environment to run production applications, and as Dapr matures further we expect to see Dapr in serverless environments. Weâ€™ve worked closely with early adopters and partners over the past one and half years, and as a result Dapr is now at the core of several production and pre-production Kubernetes-based applications. In this user driven journey, the Dapr community has improved the native language experiences of the Java, .NET and Python SDKs, tested scale and performance with real workloads, added security features, and proven that Daprâ€™s actor programming model is the best choice for workflow and IoT scenarios. Here are some of the early adopter stories to highlight how Dapr is being used today.</p>
<h3 id="zeiss-an-international-technology-leader-in-optics-and-opto-electronics">ZEISS, an international technology leader in optics and opto-electronics</h3>
<p>The challenge for ZEISS was maintaining and updating a 20-year-old back-end system with hard-coded business rules. The original order validation and routing solution was based on a monolithic architecture with fixed capacities where developers couldnâ€™t easily update, reroute, or track orders without reconfiguring tables directly in the system. In addition, business units had no direct control over their order processing flow. With so many system dependencies, changes always required costly, time-consuming developer intervention. To overcome this, ZEISS developed a new application using Azure and Dapr to fulfill orders faster for customers, while also speeding up development and improving business continuity for the company. You can read more about their story <a href="https://customers.microsoft.com/en-us/story/1336089737047375040-zeiss-accelerates-cloud-first-development-on-azure-and-streamlines-order-processing">here</a>.</p>
<p><img src="https://blog.dapr.io/posts/2021/02/17/announcing-dapr-v1.0/zeiss-diagram.png" width="2000"></p><h3 id="ignition-group-a-south-africa-based-technology-business-focusing-on-customer-engagement-and-sales-support-tools">Ignition Group, a South Africa-based technology business focusing on customer engagement and sales-support tools</h3>
<p>Ignition Group builds order processing software to track products, manage subscriptions, and handle payments from a variety of sources. Order processing involves many dependencies with a purchase tracking mechanism that invokes a customer subscription, triggers accounting and billing processes, and determines the appropriate payment channel. Ignition Group wanted the benefits that microservices would bring to its workflow logicâ€”high availability, resiliency, scalability, and performance. Using Dapr and .NET Core, Ignition Group built a new, more scalable, maintainable order processing and payment system which is now running in production. Ignition Group are running in production today and you can read more about their story <a href="https://customers.microsoft.com/en-us/story/1335733425802443016-ignition-group-speeds-development-and-payment-processing-using-dapr-and-azure">here</a>.</p>
<h3 id="roadwork-data-gathering-to-gain-insights">Roadwork, data gathering to gain insights</h3>
<p>Roadwork is a startup that provides an end-to-end platform for autonomous systems, enabling users to generate actionable insights and act on them. Currently they are focused on data extraction techniques, with a path towards fully integrated autonomous systems. By combing Dapr with <a href="https://keda.sh/">KEDA</a> they created a production service on Kubernetes that automatically scales both the application and the cluster based on the incoming customer load requests. Dapr provided the abstraction and integration with pub/sub using RabbitMQ and its ability to easily have a <a href="https://docs.dapr.io/developing-applications/building-blocks/pubsub/pubsub-overview/#consumer-groups-and-competing-consumers-pattern">competing consumer pattern</a>. Roadworkâ€™s first product, <a href="https://scraper.ai/">Scraper.ai</a> is already running in production today. Learn more <a href="https://blog.dapr.io/posts/2021/02/09/running-dapr-in-production-at-roadwork/">here</a>.</p>
<h2 id="community-and-ecosystem">Community and ecosystem</h2>
<p>Getting Dapr to the v1.0 has been a community effort. It has been amazing to see the open source community rally around Dapr and grow since it was first announced â€“ growing from a little over 114 contributors in October 2019 to 700 today. A growth of over six-fold in only 16 months!</p>
<p>Community contributions to the project have gone to every Dapr repo and have ranged from opening issues, commenting on feature proposals, providing samples, and of course contributing code. The parts of the project community members have contributed to the most include the Dapr runtime, docs, CLI and SDKs. One additional key area of contribution has been the creation of a rich ecosystem of components. Having over 70 components available to developers makes Dapr a solution for a wide range of scenarios and includes both open source technologies and cloud provider specific integrations. These make Dapr an appealing choice for developers looking to create cloud agnostic applications with high portability.</p>
<p>Contributions have not been limited to individuals, but also included organizations such as Alibaba Cloud, HashiCorp, Microsoft and the early adopters like ZEISS and Ignition Group mentioned above. The Dapr ecosystem also includes partner technology stacks that provide added value to developers who use them with Dapr. For example, New Relic has provided <a href="https://blog.dapr.io/posts/2021/01/26/observing-dapr-applications-with-new-relic-one/">guidance</a> on how their monitoring tools seamlessly work with Dapr thanks to Daprâ€™s use of standard tracing protocols that easily instrument your application without any code changes.</p>
<p>Fostering an open and inclusive community is a primary goal for the Dapr project. As part of that commitment, we shared the <a href="https://blog.dapr.io/posts/2020/09/30/transitioning-the-dapr-project-to-open-governance/">transition to an open governance model</a> which is how we aim to keep Dapr open, vendor neutral and inclusive. Our vision is to continue this journey and intend to have Dapr join an open software foundation in the near future. In the meantime, we invite you to engage with the Dapr community over <a href="https://github.com/dapr">GitHub</a>, the regular Dapr <a href="https://github.com/dapr/community#community-meetings">community calls</a> and the recently launched <a href="https://aka.ms/dapr-discord">Discord server</a>.</p>
<blockquote>
<p><em>â€œAt Alibaba Cloud, we believe Dapr will lead the evolution of microservices. By adopting Dapr, our customers now enjoy increased velocity for building portable and robust distributed systems."</em>
<strong>-	Xiang Li, Senior Staff Engineer, Alibaba Cloud</strong></p>
</blockquote>
<h2 id="release-highlights">Release highlights</h2>
<p>Over the last few months we have published three v1.0 release candidates to focus on getting feedback from the community and preparing for the v1.0 release. This included a deeper focus on production readiness, in areas such as performance, security, High Availability (HA) and conformance. The full release notes are available <a href="https://github.com/dapr/dapr/releases/tag/v1.0.0">here</a>, these are some of the highlights:</p>
<h3 id="kubernetes-as-a-production-environment">Kubernetes as a production environment</h3>
<p>For the v1.0 release, Kubernetes is the primary hosting environment, and it is <a href="https://docs.dapr.io/operations/hosting/kubernetes/kubernetes-overview/">deeply integrated with both the Dapr control plane and Dapr sidecar architecture</a>. For example, operationally installing and upgrading Dapr to Kubernetes is simplified with Dapr CLI â€œinitâ€ and â€œupgradeâ€ commands that pull down the correct Dapr runtime versions and ensure that these are rolled out in a controlled manner, including migrating certificates that are in use. You can install the Dapr control plan in HA mode ensuring that multiple instances are running and the Dapr side car has a health endpoint that enable Kubernetes readiness and liveness probes to determine its health state. Throughout the release candidate process, we have worked closely with early adopters to ensure that they can operationally migrate to each Dapr runtime release, rather than building new clusters. See these <a href="https://docs.dapr.io/operations/hosting/kubernetes/kubernetes-production/">guidelines for production deployment</a> for more information.</p>
<h3 id="performance-conformance-and-support">Performance, conformance, and support</h3>
<p>Performance is critical in cloud native applications and Dapr puts a premium on high performance. A topic that often gets raised are the implications of having a side car model doing all the heavy lifting for your application and the trade off with data plane performance. One area of particular focus is with the service invocation building block, and here, when calling between two applications through two Dapr sidecars and receiving a response back, <a href="https://docs.dapr.io/operations/performance-and-scalability/perf-service-invocation/">Dapr adds ~1.2ms end-to-end latency at the 90th percentile and ~2ms at the 99th percentile</a>. This shows that Dapr has extremely low service-to-service latency and has been optimized for high throughput scenarios. Dapr has over 70 components developed by the community and to ensure confidence in the usage of these, they go through a set of conformance tests. Components first start in an alpha status and eventually get to GA status, which requires users to be using them in production. Only a subset of components are GA approved for v1.0 release, with these having been used extensively in production, with others joining them as they meet the criteria. As with many open source cloud native technologies, changes, fixes and improvements are â€¦</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.dapr.io/posts/2021/02/17/announcing-dapr-v1.0/">https://blog.dapr.io/posts/2021/02/17/announcing-dapr-v1.0/</a></em></p>]]>
            </description>
            <link>https://blog.dapr.io/posts/2021/02/17/announcing-dapr-v1.0/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26168887</guid>
            <pubDate>Wed, 17 Feb 2021 17:26:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[RetroForth 2021.1]]>
            </title>
            <description>
<![CDATA[
Score 130 | Comments 52 (<a href="https://news.ycombinator.com/item?id=26168640">thread link</a>) | @mindcrime
<br/>
February 17, 2021 | http://forthworks.com/retro | <a href="https://web.archive.org/web/*/http://forthworks.com/retro">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>[DIR] <a href="http://forthworks.com/">Forthworks</a>
______________________________________________________________________

RETRO is a clean, elegant, and pragmatic dialect of Forth. It provides
a simple alternative for those willing to make a break from legacy
systems.

The language draws influences from many sources including traditional 
Forth systems, cmForth, colorForth, Factor, and Parable. It was
designed to be easy to grasp and adapt to specific uses.

The basic language is very portable. It runs on a tiny virtual
machine (Nga), which is written in C. There are multiple interface
options, the main one (rre) is buildable with just the standard C
compiler and libraries on most systems.
______________________________________________________________________

Source Code

These include source code, documentation, and examples.

 BIN  <a href="http://forthworks.com/retro/r/latest.tar.gz">Nightly Snapshot (.tar.gz)</a>

 BIN  <a href="http://forthworks.com/retro/r/RETRO12-2021.2.tar.gz">Latest Release (2021.2, .tar.gz)</a>
 TXT  <a href="http://forthworks.com/retro/r/RETRO12-2021.2.tar.gz.sig">Signature for Latest Release</a>
 TXT  <a href="http://forthworks.com/retro/r/RETRO12-2021.2.tar.gz.pub">Public Key for Latest Release</a>

[DIR] <a href="http://forthworks.com/retro/r">Prior Versions</a>
______________________________________________________________________

Documentation

 TXT  <a href="http://forthworks.com/retro/r/RETRO12-2021.2.epub">RETRO Handbook (epub)</a>

You can view the glossary via Gopher or HTTP. This is served off the
latest documentation in the repository by a server written in RETRO.

[DIR] <a href="http://forthworks.com/">Glossary Browser (gopher)</a>
 HTM  <a href="http://forthworks.com:9999/">Glossary Browser (http)</a>
 TXT  <a href="http://forthworks.com/retro/s/doc/Glossary.txt">Glossary (text)</a>
______________________________________________________________________

Repository

Development is tracked using a Fossil repository.

Clone the repo:

  fossil clone http://forthworks.com:8000 retro.fossil

And open it:

  mkdir retro
  cd retro
  fossil open /path/to/retro.fossil

Mirrors of the repo are available via git.

 HTM  <a href="https://git.sr.ht/~crc_/retroforth">https://git.sr.ht/~crc_/retroforth</a>
 HTM  <a href="https://github.com/crcx/retroforth">https://github.com/crcx/retroforth</a>

I generate nightly snapshots of the development version.

 BIN  <a href="http://forthworks.com/retro/r/latest.tar.gz">Nightly Snapshot</a>
 TXT  <a href="http://forthworks.com/retro/changes.txt">Latest Changes (updates hourly)</a>
______________________________________________________________________

Packages &amp; Ports

NetBSD pkgsrc: lang/forth-retro
LiteBSD: lang/retro12
FreeBSD: lang/retro12
Milis Linux: "mps kur retro12" (or build-install "mps derle retro12")
______________________________________________________________________

Commercial Versions

I develop and maintain versions for iOS and macOS. These run the same
image and virtual machine as all of the other systems, but add a
custom editor-centric interface and some additional words to make
them more useful on their respective platforms.

 HTM  <a href="https://itunes.apple.com/us/app/retro-forth/id1317494014?ls=1&amp;mt=12">RETRO for macOS</a>
 HTM  <a href="https://itunes.apple.com/us/app/retro-forth-12/id1170943580?ls=1&amp;mt=8">RETRO for iOS</a>
______________________________________________________________________

Patreon

I have a Patreon at https://www.patreon.com/_crc for those that want
to financially support development. All funds raised are put into
development related expenses (server expenses, app store fees,
hardware, etc).

Thanks go out to my current and past patrons:

- Kiyoshi YONEDA
- Krinkleneck
- Rick Carlino
- Scott McCallum
______________________________________________________________________

Discussion

I can be reached:

- @crcx on Twitter
- @crc@mastodon.social on Mastodon
- /r/forth on reddit (/u/_crc)
- /u/crc_ on lobste.rs
- #retro on irc.freenode.net (look for crc)

The IRC channel is logged at http://tunes.org/~nef/logs/retro and a
mirror is provided via gopher:

[DIR] <a href="http://forthworks.com/retro/irc-logs">IRC Channel Logs</a>
</p></div>]]>
            </description>
            <link>http://forthworks.com/retro</link>
            <guid isPermaLink="false">hacker-news-small-sites-26168640</guid>
            <pubDate>Wed, 17 Feb 2021 17:06:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[QCovid: Personal Covid-19 risk calculator developed by Oxford University]]>
            </title>
            <description>
<![CDATA[
Score 29 | Comments 13 (<a href="https://news.ycombinator.com/item?id=26168403">thread link</a>) | @bananapear
<br/>
February 17, 2021 | https://qcovid.org/Calculation | <a href="https://web.archive.org/web/*/https://qcovid.org/Calculation">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <header>
            <nav>
                <div>
                    <div>
                        <p><a href="https://qcovid.org/">
                            <img src="https://qcovid.org/img/oxweb-logo-rect.svg" alt="University of Oxford">
                            <img src="https://qcovid.org/img/Logo_qcovid.svg" alt="QCovid">
                        </a>
                        </p>
                    </div>
                </div>
            </nav>
        </header>
        <div>
            <main role="main">
                
<h2>Please scroll to accept licence</h2>



<p>
    These licence terms apply to all licences granted by THE CHANCELLOR, MASTERS
    AND SCHOLARS OF THE UNIVERSITY OF OXFORD whose administrative offices are at
    University Offices, Wellington Square, Oxford OX1 2JD, United Kingdom ("the
    University") for use of or access to the QCovid Algorithm ("the Algorithm") through this website.
</p>

<p>
    By requesting access to the Algorithm through this Website
    <a href="https://qcovid.org/">https://qcovid.org/</a>
    ("the Website"), you ("the User") agree that
    your use of the Algorithm is subject to these licence terms and that you will
    use the Algorithm only in accordance with these licence terms.

</p>

<div>

    <p>
        Please read these licence terms carefully before using the algorithm.  If
        you do not agree to these licence terms you must not request access and
        you must not use the algorithm.
    </p>

    <p>
        The algorithm may be used only for academic research or for the purpose of
        peer review. The algorithm must not be used for any of the following:
    </p>

    <ul>
        <li>carrying out any clinical trial;</li>
        <li>
            carrying out any research with a view to commercialising or exploiting
            the algorithm or any derivative work, variation or adaptation of
            the algorithm;
        </li>
        <li>any other commercial purpose; or</li>
        <li>creating any derivative work, variation or adaptation of the algorithm.</li>
    </ul>

    <p>
        You must not distribute or share the use of the algorithm or any derivative
        work, variation or adaptation of the algorithm with any other person
    </p>

</div>

<ol>
    <li><b>ACADEMIC USE LICENCE</b>
        <ol>
            <li>The User is granted a non-exclusive, non-transferable, royalty 
                free licence to access and use the Algorithm provided that the User:
                <ol>
                    <li>uses the Algorithm only for academic research or for 
                        the purpose of peer review;</li>
                    <li>does not use the Algorithm for carrying out any clinical trial;</li>
                    <li>does not use the Algorithm for carrying out any 
                        research with a view to commercialising or exploiting
                        the Algorithm or any derivative work, variation or 
                        adaptation of the Algorithm;</li>
                    <li>does not use the Algorithm for any other commercial purpose;</li>
                    <li>does not, and does not attempt to, use the Algorithm to 
                        create any derivative work, variation, modification or 
                        adaptation of the Algorithm;</li>
                    <li>does not distribute or share the use of the Algorithm or 
                        any derivative work, variation or adaptation of the Algorithm 
                        with any other person.</li>
                    <li>does not use the Algorithm for or on behalf of any third party
                        or to provide any service;</li>
                    <li>does not integrate all or part of the Algorithm into any product;</li>
                    <li>uses the Algorithm only in accordance with any instructions 
                        and guidance for use of the Algorithm given on the Website;</li>
                    <li>complies with the procedures on the Website in relation to 
                        user identification, authentication and access to the 
                        Algorithm or the Website;</li>
                    <li>complies with all applicable laws and regulations relating 
                        to the use of the Algorithm and the Website (or either of them);</li>
                    <li>does not, and does not attempt to, create any derivative work 
                        from, or any variation, modification or of adaptation of, or frame,
                        mirror, republish, download, display, transmit, or distribute all
                        or any part of the Website in any form or media or by any means; 
                        and</li>
                    <li>ensures that, whenever the Algorithm is referred to in any peer 
                        review, research publication or other document or other material,
                        the Copyright Notice "Copyright Â© 2020, University of Oxford" 
                        appears prominently.</li>
                </ol>
            </li>
            <li>The University reserves the right, at any time and without liability 
                and without giving notice to the User, to: cease publishing the Algorithm;
                to revise, modify or replace the Algorithm; to change the operation of 
                the Website; and to deny or suspend access to the Algorithm and the 
                Website (or either of them).
            </li>
            <li>The University reserves the right, at any time and without liability, 
                to change these licence terms.
            </li>
            <li>The User acknowledges and agrees that the University owns any and all
                intellectual property rights in the Algorithm and in any and all results
                or other output from the use of the Algorithm (except any peer review or
                research publication).
            </li>
            <li>The licence granted in clause 1.1 above will terminate automatically and
                immediately, and the User will no longer have any right to use the Algorithm,
                on any breach of the licence terms.
            </li>
        </ol>
    </li>
    <li><b>INDEMNITY AND LIABILITY</b>
        <ol>
            <li>The User shall defend, indemnify and hold harmless the University against
                any and all claims, actions, proceedings, losses, damages, expenses and 
                costs (including, without limitation, court costs and reasonable legal fees)
                arising out of or in connection with the User's possession or use of the 
                Algorithm, or any breach of these licence terms by the User.
            </li>
            <li>The Algorithm and the Website are provided on an Ã¢â‚¬Ëœas isÃ¢â‚¬â„¢ basis and the
                User uses the Algorithm at their at their own risk. No representations, 
                conditions, warranties or other terms of any kind are given in respect of
                the Algorithm and all statutory warranties and conditions are excluded to
                the fullest extent permitted by law. Without affecting the generality of 
                the previous sentences, the University gives no implied or express warranty
                and makes no representation that the Algorithm: (a) will enable specific results
                to be obtained; or (b) meets a particular specification or is comprehensive 
                within its field or that it is error free or will operate without 
                interruption; or (c) is suitable for any particular, or the User's 
                specific, purpose.
            </li>
            <li>Except in relation to fraud, and death or personal injury caused by 
                negligence, the University will not be liable to the User in 
                connection with the Algorithm or the Website, in negligence or 
                arising in any other way, for: (a) any indirect or consequential 
                damage or loss; or (b) for any loss of profits, loss of revenue, 
                loss of data, loss of contracts or loss of opportunity, in each case 
                whether direct or indirect.
            </li>
            <li>The User irrevocably undertakes to the University not to bring any 
                claim against any employee, student, researcher or other individual 
                engaged by the University, that seeks to enforce against any of them 
                any liability whatsoever in connection with the Algorithm or the Website.
            </li>
        </ol>
    </li>
    <li><b>GENERAL</b>
        <ol>
            <li>Severability - If any provision (or part of a provision) of these licence 
                terms is found by any court or other body of competent jurisdiction to be
                invalid, unenforceable or illegal, the other provisions (or the other 
                parts of that provision) shall remain in full force and effect.
            </li>
            <li>Entire Agreement - These licence terms constitute the entire agreement 
                between the University and the User and supersede all previous arrangements,
                understandings and agreements between them relating to the Algorithm. The
                User acknowledges that it has not been induced to agree to these licence 
                terms or to use the Algorithm or the Website by any representation, statement
                or warranty (whether oral, or in writing) made by or on behalf of the 
                University and waives all claims for breach of any warranty and all
                claims for any misrepresentation, (negligent or of any other kind, 
                unless made by the University fraudulently).
            </li>
            <li>Law and Jurisdiction - These licence terms and their validity and any
                dispute or claim arising out of or in connection with them or the 
                Algorithm or the Website (including any non-contractual dispute or 
                claim) shall be governed by, and shall be construed in accordance 
                with, the laws of England and Wales. The User irrevocably submits 
                to the exclusive jurisdiction of the English courts in respect of 
                any dispute or claim that arises out of or in connection with these
                licence terms or the Algorithm or the Website.
            </li>
        </ol>
    </li>
</ol>

<p>
    If you are interested in using the Algorithm in a way not permitted by these licence terms,
    please contact Oxford University Innovation Limited to discuss obtaining an appropriate licence.
    Contact details are 
    <a href="mailto:enquiries@innovation.ox.ac.uk">enquiries@innovation.ox.ac.uk</a> 
    quoting reference [17939].
</p>


            </main>
        </div>

        
    </div></div>]]>
            </description>
            <link>https://qcovid.org/Calculation</link>
            <guid isPermaLink="false">hacker-news-small-sites-26168403</guid>
            <pubDate>Wed, 17 Feb 2021 16:45:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Moneto â€“ Cash planning tool for running a profitable business]]>
            </title>
            <description>
<![CDATA[
Score 14 | Comments 9 (<a href="https://news.ycombinator.com/item?id=26167631">thread link</a>) | @davidbistiak
<br/>
February 17, 2021 | https://monetohq.com/producthunt | <a href="https://web.archive.org/web/*/https://monetohq.com/producthunt">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="landing-0">  <div id="notification"> <div role="alert"> <p>Get Product Hunt <strong>LIFETIME DEAL</strong> just for $89&nbsp;ğŸ‰. Ends this week!</p>  </div> </div>  <header> <a href="#main">Skip to content</a>  </header>   <div> <main id="main"></main> <div> <div> <div> <div> <div> <div> <div> <p> <h2> INTRODUCING MONETO </h2> </p>  <p>Simple cash projections to monitor, optimize, and&nbsp;plan your companyâ€™s financial future.</p> </div> </div> </div> </div> </div> </div> </div>   <div> <div> <div> <div> <p><img src="https://bucket.mlcdn.com/a/2176/2176463/images/d18c63d1970149af2035898173226d3f59c8b050.png"> </p> </div> </div> </div> </div> <div> <div> <div> <p>Moneto is a visual day-to-day cash forecasting tool specifically designed for forward-thinking decision-makers.</p> </div> </div> </div> <div> <div> <div> <p><span>âœ“ Simple to setup&nbsp; &nbsp;âœ“ Simple to use&nbsp; &nbsp;âœ“ Highly secured</span></p> </div> </div> </div>  <div> <div> <div> <p>We know how complicated and&nbsp;confusing finances are.&nbsp;Balance sheets, P&amp;L, Cash Flow&nbsp;statements. Moneto transforms financial data into a chart that helps you immediately understand your business numbers in the past, present, and future with just a look..</p> </div> </div> </div> <div> <div> <div> <p><img src="https://bucket.mlcdn.com/a/2176/2176463/images/c543a1f1baad3f7a95c87a4f69c6aa795f45931e.png" alt="" width="855.741935483871"> </p> </div> </div> </div>  <div> <div> <div> <div> <p>You don't have to be a financial wizard or need an expensive CFO. You can take care of your company's finances while you enjoy your morning cup of coffee.<br></p>  </div> </div> </div> </div> <div> <div> <div> <div> <div> <div> <div> <div> <div> <div> <div> <div> <p><img src="https://bucket.mlcdn.com/a/2176/2176463/images/f6adfd64d2f7bcd1a5c2c180db31c67337ec7c5d.png" alt="" width="588"> </p> </div> </div> </div> <div> <div> <p><strong><span></span></strong><strong><span><strong>#1</strong></span><strong><span>:&nbsp;Track Transactions</span></strong></strong></p> <p><span><span><span>Enter your current and potential&nbsp;revenues and expenses</span></span></span><br></p> </div> </div> </div> </div> </div> </div> <div> <div> <div> <div> <div> <div> <div> <p><img src="https://bucket.mlcdn.com/a/2176/2176463/images/ea656108013cea69953a97ef0b2719918c038d46.png" alt="" width="588"> </p> </div> </div> </div> <div> <div> <p><span><span></span></span><span><span><strong>#2: Get&nbsp;</strong><strong>holistic overview</strong></span></span></p> <p><span><span>Moneto transforms your financial data into a simple action-ready dashboard</span></span></p> </div> </div> </div> </div> </div> </div> <div> <div> <div> <div> <div> <div> <div> <p><img src="https://bucket.mlcdn.com/a/2176/2176463/images/515579886ebbec9e3b0f8c6c5947a197df1b778f.png" alt="" width="588"> </p> </div> </div> </div> <div> <div> <p><strong><span><span></span></span></strong><strong><span><strong>#3</strong></span><strong><span><span>: Confident decision-making</span></span></strong></strong></p> <p><span><span>Run business based on sound financial data, not just a hunch</span></span></p> </div> </div> </div> </div> </div> </div> </div> </div> </div> </div> </div>  <div> <div> <div> <p> <h3><span><strong>MADE TO&nbsp;EMPOWER YOUR DECISIONS</strong></span></h3> </p> </div> </div> </div> <div> <div> <div> <p>Making business decisions&nbsp;is stressful and&nbsp;difficult. One bad decision can put you out for a long time.&nbsp;With Moneto you don't have to&nbsp;play a dangerous guessing game with your money anymore.</p> </div> </div> </div> <div> <div> <div> <div> <div> <div> <div> <div> <div> <p><img src="https://bucket.mlcdn.com/a/2176/2176463/images/8f82ee169cebccd00cb372d0e202277ca4f4e4cc.png" alt="" width="443.11898734177214"> </p> </div> </div> <div> <div> <div aria-label="content" role="contentinfo"> <h3><span><strong>MONITOR</strong></span></h3> <h3><span><span><strong>Know your cash position</strong></span></span></h3> <p>Monitor your cash inflows and outflows to know where you stand compared to your plan. Are you heading the right way or the wrong way?</p> <p><span><span><a href="https://app.monetohq.com/register">Monitor my cash flow â†’</a></span></span></p> </div> </div> </div> </div> </div> </div> </div> </div> </div> </div> <div> <div> <div> <div> <div> <div> <div> <div> <div> <p><img src="https://bucket.mlcdn.com/a/2176/2176463/images/8ae1218887987f0e2bbeffc7610e444811ac4731.png" alt="" width="442.5323741007194"> </p> </div> </div> <div> <div> <div aria-label="content" role="contentinfo"> <h3><span><strong>OPTIMIZE</strong></span></h3> <h3><span><span><strong>Spend money wisely</strong></span></span></h3> <p>Get a clear breakdown of how every dollar of your companyâ€™s money is being spent. Save more, spend wisely, and your cash reserve will grow.</p> <p><span><span><a href="https://app.monetohq.com/register">Budget my expenses&nbsp;â†’</a></span></span></p> </div> </div> </div> </div> </div> </div> </div> </div> </div> </div> <div> <div> <div> <div> <div> <div> <div> <div> <div> <p><img src="https://bucket.mlcdn.com/a/2176/2176463/images/0d814ea26ecc9535858b75b01879d171c7ec525b.png" alt="" width="442.6332046332047"> </p> </div> </div> <div> <div> <div aria-label="content" role="contentinfo"> <h3><span><strong>FORECAST</strong></span></h3> <h3><span><span><strong>Plan for a profitable future</strong></span></span></h3> <p>Enter all your current and potential revenues and expenses to see how each transaction impacts your cash on hand.</p> <p><span><span><a href="https://app.monetohq.com/register">Plan my financial future â†’</a></span></span></p> </div> </div> </div> </div> </div> </div> </div> </div> </div> </div> <div> <div> <div> <div> <div> <div> <div> <div> <div> <p><img src="https://bucket.mlcdn.com/a/2176/2176463/images/db37fd57d9153f4501cc2a30ce006a36346316be.png" alt="" width="442.6332046332047"> </p> </div> </div> <div> <div> <div aria-label="content" role="contentinfo"> <h3><span><strong>CHALLENGE</strong></span></h3> <h3><span><span><strong>Set realistic financial goals</strong></span></span></h3> <p>Entrepreneurs like to dream big. But it's not always a smooth ride. Set realistic goals based on financial information.</p> <p><span><span><a href="https://app.monetohq.com/register">Set my goals&nbsp;â†’</a></span></span></p> </div> </div> </div> </div> </div> </div> </div> </div> </div> </div> <div> <div> <div> <div> <div> <div> <div> <div> <div> <p><img src="https://bucket.mlcdn.com/a/2176/2176463/images/71e5f2442a57c3aed683af3c939094b874d05c2a.png" alt="" width="442.88161209068005"> </p> </div> </div> <div> <div> <div aria-label="content" role="contentinfo"> <h3><span><strong>VALIDATE</strong></span></h3> <h3><span><span><strong>Make profitable decisions</strong></span></span></h3> <p>Play around with multiple scenarios and financially validate your business decisions before you make them. Understand the impact on your cash on hand.&nbsp;</p> <p><span><span><a href="https://app.monetohq.com/register">Test my decisions&nbsp;â†’</a></span></span></p> </div> </div> </div> </div> </div> </div> </div> </div> </div> </div>  <div> <div> <div> <p> <h3><span><strong>IS MONETO A GREAT FIT FOR YOU?</strong></span></h3> </p> </div> </div> </div> <div> <div> <div> <p>&nbsp;Make a great business decision and validate if Moneto is a great fit for you. We want to make sure that this exclusive deal&nbsp;lands in the right hands.</p> </div> </div> </div> <div> <div> <div> <div> <div> <div> <div> <div> <div> <div> <div> <p><strong><span>MONETO IS FOR YOU IF:</span></strong></p> <p><span><strong></strong></span><span>You're a forward-thinking <strong><span>entrepreneur, CEO, founder</span></strong> who cares about his business and wants to grow a cash reserve.<br></span></p> <p><span>You want to <strong><span>master the fundamentals</span></strong> of finance but don't have a background in finance.<br></span></p> <p><span>You're a beginner at finance and want to <strong><span>start business the right way</span></strong>, and get advice specific to your goals and situation.<br></span></p> <p><span>You're an <strong><span>action-taker</span></strong> who is willing to turn financials from a source of pain to power.</span><br></p> </div> </div> </div> </div> </div> </div> <div> <div> <div> <div> <div> <div> <p><strong><span>MONETO IS NOT FOR YOU IF:</span></strong><br></p> <p>You <strong><span>are not</span></strong> willing to commit to putting into work (you wonâ€™t fix your cash flow just by buying Moneto!)</p> <p>You're looking for a tool that <strong><span>does everything for you</span></strong> without your action.<br></p> <p>You&nbsp;<strong><span>don't really care</span></strong> about your financial future!&nbsp;</p> </div> </div> </div> </div> </div> </div> </div> </div> </div> </div> </div>  <div> <div> <div> <p>Nobody cares about your business more than you do! It's your responsibility to protect your company.&nbsp;Take your business finances into your hands and empower running your business&nbsp;with Moneto.</p> </div> </div> </div> <div> <div> <div> <div> <div> <div> <div> <div> <div data-date="2021-02-22 00:00:00" id="timer-109" data-zone="user_timezone" data-user_timezone="Europe/Bratislava" data-account_timezone="Europe/London"> <p><span id="ml-days">00</span> <small>Days</small> </p> <p><span id="ml-hrs">00</span> <small>Hours</small> </p> <p><span id="ml-mins">00</span> <small>Mins</small> </p> <p><span id="ml-secs">00</span> <small>Secs</small> </p> </div> </div> </div> </div> </div> </div> </div> </div> </div> <div> <div> <div xp-if="[object Object]"> <div> <p> Something went wrong. Try again. </p> <div> <div> <p> This is a preview mode. Product purchase available only in published pages. </p> </div> </div> <div> <div> <div> <div> <p><img src="https://files.stripe.com/links/fl_live_YVXSluQEPEhIo0QfSRus0Rrh" alt="" width="245.11475409836063"> </p> </div> <div> <div> <div> <h2> GET LIMITED PRODUCT HUNT LIFETIME DEAL ï»¿ğŸ‰ </h2> <p> You have an exclusive opportunity to get Moneto for a special price. Buy Moneto now and manage up to 5 companies, create unlimited transactions, categories, partners, and projects. </p> <p> 89.00 USD </p> </div> </div>  </div> </div> </div> </div> <div> <div> <div> <div> <p><strong>Thank you for your purchase</strong></p> <p>Have a great day!</p> </div> </div>  </div> </div> </div> </div> </div> </div>    <div> <div> <div> <p><span>ğŸ’ª&nbsp; lifetime updates&nbsp; &nbsp;ğŸ’¯&nbsp; 7-day money-back guarantee&nbsp; &nbsp;ğŸ”’&nbsp; highly secured</span></p> </div> </div> </div>  <div> <div> <div> <p>Sign up now and get&nbsp;Moneto a 7-day FREE trial with helpful "how-to" video tutorials, informational articles, and an actionable worksheet.&nbsp;</p> </div> </div> </div>   <div> <div> <div> <p> <h3><span><strong>FREQUENTLY ASKED QUESTIONS</strong></span></h3> </p> </div> </div> </div> <div> <div> <div> <p>Everything you need to know about the lifetime deal offer and how to utilize it.</p> </div> </div> </div> <div> <div> <div> <div> <div> <div> <div> <div> <div> <div> <div> <p><span><strong><span><span><span>What is a lifetime deal? </span></span></span></strong></span><br></p> <p><span>Once you purchase a lifetime deal and sign up, you have access to that tool for the lifetime of the product. As long as the tool is still available, youâ€™ll have access to it.</span></p> </div> </div> </div> </div> </div> </div> <div> <div> <div> <div> <div> <div> <p><span><strong><span><span><span>How much does it cost?</span></span></span></strong></span><br></p> <p><span>Itâ€™s only for $89. When the deal is gone it will be $99 per month. We reward action takers. Are you one of them?</span></p> </div> </div> </div> </div> </div> </div> </div> </div> </div> </div> </div> <div> <div> <div> <div> <div> <div> <div> <div> <div> <div> <div> <p><span><strong><span><span>Can I get a refund? </span></span></strong></span><br></p> <p><span>If you ever decide that Moneto isnâ€™t the best cash flow tool for your business, simply write us at <span>login@monetohq.com</span> and ask for a refund. Your request will be valid for 7 days after purchase. Weâ€™ll give you a 100% refund â€“ no questions asked.</span></p> </div> </div> </div> </div> </div> </div> <div> <div> <div> <div> <div> <div> <p><span><span><strong><span>What support do you offer?</span></strong></span><br></span></p> <p><span>All plans include email support. Send us your query at <span>login@monetohq.com</span>.&nbsp;We typically reply the same day.</span></p> </div> </div> </div> </div> </div> </div> </div> </div> </div> </div> </div> <div> <div> <div> <div> <div> <div> <div> <div> <div> <div> <div> <p><span><strong><span><span>Can I change my plan later?</span></span></strong></span></p> <p><span><span><strong></strong></span>Yes. You can change your plan from lifetime deal to any plan available.&nbsp;</span></p> </div> </div> </div> </div> </div> </div> <div> <div> <div> <div> <div> <div> <p><span><span><strong><span>What happens to my data after I delete my account?</span></strong></span><br></span></p> <p><span>Once you deactivate your account all your information is automatically deleted. We do not retain any information.</span></p> </div> </div> </div> </div> </div> </div> </div> </div> </div> </div> </div> <div> <div> <div> <div> <div> <div> <div> <div> <div> <div> <div> <p><span><strong><span><span>Is my financial data secured?</span></span></strong></span></p> <p><span><span><span><span></span>We take privacy seriously and are committed to protecting your financial data through:</span></span></span></p> <ul><li><span><span><span>Secure Socket Layer (SSL) encryption</span></span></span></li><li><span><span><span>Multiple backups</span></span></span></li><li><span><span><span>Multiple levels of authentication</span></span></span></li></ul> <p><span><span><span>You are always in control of your data and can opt out anytime.</span></span></span></p> </div> </div> </div> </div> </div> </div> <div> <div> <div> <div> <div> <div> <p><span><span><strong><span>What are you planning next?</span></strong></span><br></span></p> <p><span>We are constantly planning to add new and exciting features! But before that, we always ask what will help you the most? We are here for you&nbsp;want to&nbsp;help as much as we can.<br></span></p> <p><span> Other possible features include integrations to banks, Xero, QuickBooks or Stripe, scenario planning, smart alerts, due dates emails etc. </span></p>  </div> </div> </div> </div> </div> </div> </div> </div> </div> </div> </div>  <div> <div> <div> <p>Email us at <span>login@monetohq.com</span></p> </div> </div> </div> <div> <div> <div> <div> <div> <div> <div> <p> <h2> TRY MONETO FOR FREE </h2> </p>  <p>Don't play a guessing game with your money and manage your cash flow properly.</p> </div> </div> </div> </div> </div> </div> </div>    </div>    <p><img src="https://track.mailerlite.com/webforms/o/3232993/v2x8s2" alt="." width="1" height="1">     </p></div></div>]]>
            </description>
            <link>https://monetohq.com/producthunt</link>
            <guid isPermaLink="false">hacker-news-small-sites-26167631</guid>
            <pubDate>Wed, 17 Feb 2021 15:45:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Managing Up: How Developers Can Better Communicate to Management]]>
            </title>
            <description>
<![CDATA[
Score 9 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26167368">thread link</a>) | @KaiserSanchez
<br/>
February 17, 2021 | https://www.7pace.com/blog/managing-up | <a href="https://web.archive.org/web/*/https://www.7pace.com/blog/managing-up">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
							
<p>Everyoneâ€™s had a bad boss.</p>



<p>And then there are the bosses that arenâ€™t necessarily <em>bad</em>, but who are overworked, overextended, disorganized, or just straight up disengaged with their work. Those bosses are a dime a dozen.</p>



<p>Dealing with bad bosses is something that we all have to learn, regardless of the industry we work in. The same goes for dealing with mediocre bosses, and even dealing with good bosses who, for whatever reason, arenâ€™t doing the best job at being bosses. One secret? Itâ€™s something called â€œmanaging up,â€ and itâ€™s gotten a lot of attention in business circles in recent years.</p>



<p>Managing up isnâ€™t just for the corporate world, though. Developers can <a href="https://www.reddit.com/r/ITManagers/comments/ccoyud/managing_up/" target="_blank" rel="noreferrer noopener"><u>make use of this tactic</u></a>&nbsp;to better deal with their managers, too. Read on to learn all you need to know.</p>



<h2>What Is Managing Up?</h2>



<p>A lot of different experts and publications define managing up in different ways. But at the core of what they all say it means, managing up is doing everything you can to make your bossâ€™s job easier â€”&nbsp;basically, itâ€™s managing your manager.</p>



<p>The <em>Harvard Business Review</em>&nbsp;has <a href="https://hbr.org/topic/managing-up" target="_blank" rel="noreferrer noopener"><u>written a lot about managing up</u></a>&nbsp;in recent years, and says that doing so effectively takes a combination of these five steps:</p>



<figure><img loading="lazy" width="2560" height="1378" src="https://www.7pace.com/wp-content/uploads/2021/01/01-Image-3-scaled.jpg" alt="What Is Managing Up?" srcset="https://www.7pace.com/wp-content/uploads/2021/01/01-Image-3-scaled.jpg 2560w, https://www.7pace.com/wp-content/uploads/2021/01/01-Image-3-300x162.jpg 300w, https://www.7pace.com/wp-content/uploads/2021/01/01-Image-3-1024x551.jpg 1024w, https://www.7pace.com/wp-content/uploads/2021/01/01-Image-3-768x414.jpg 768w, https://www.7pace.com/wp-content/uploads/2021/01/01-Image-3-1536x827.jpg 1536w, https://www.7pace.com/wp-content/uploads/2021/01/01-Image-3-2048x1103.jpg 2048w" sizes="(max-width: 2560px) 100vw, 2560px"></figure>



<ul><li>Communicating your priorities to your manager, and seeking their feedback;</li><li>Being able to anticipate your managerâ€™s needs;</li><li>Understanding what makes your manager tick;</li><li>Knowing the right way to approach your manager to discuss problems; and</li><li>Learning how to be a well-rounded employee who can help out in a variety of different roles.</li></ul>



<h3>Why Would Anyone Want To Manage Up?</h3>



<p>We know how this sounds: Like itâ€™s a <em>lot</em>&nbsp;of work. In fact, one of the most prominent criticisms of managing up is that it asks lower level employees to essentially do their bossâ€™s job â€”&nbsp;without getting their bossâ€™s pay.</p>



<p>But managing up gives workers more control over their work environment and conditions. It allows them an active voice in setting expectations at work, and establishing norms for the workplace. For developers specifically, managing up can be an effective way to protect your autonomy at work, and minimize conflict with your boss, other members of your team, and anyone else at work.</p>



<p>And while managing up is a great tool for dealing with a less-than-stellar boss, these tactics offer other benefits, too. Regardless of the quality of your boss, managing up establishes you to be capable, efficient, and a self-starter â€”&nbsp;someone who can be trusted to manage their work without any hand-holding or micro-managing, and someone who will likely be able to rise in the ranks of their organization quickly.</p>



<h2>How Can Developers Manage Up?</h2>



<p>Managing up is a little bit different for software developers.</p>



<p>Why? Modern software teams have to work together in a fast-paced, highly collaborative, experimental, and iterative environment. In order for teams to succeed across the organization, everyone involved in any given software project needs to be good at communication, collaboration, coordination, planning, and prioritization.</p>



<p>In other words? Everyone â€”&nbsp;not just managers â€”&nbsp;needs to have â€œmanagement skills.â€</p>



<p>That means that members of software teams arenâ€™t as able to just show up and do their jobs as workers in some other industries. Because developers are required to have these skills, itâ€™s common for more of the management load to shift as everyone on the team becomes deputized to help out â€”&nbsp;particularly in cases where managers are overworked or overextended.</p>



<p>But that doesnâ€™t preclude developers from consciously managing up to make their own lives easier, or to advance their careers. Hereâ€™s how to get started, one step at a time.</p>



<h3>Your First Managing Up Experiment: Step By Step</h3>



<p>For a developer who hasnâ€™t tried managing up before, it can be intimidating to figure out how to get started. Here are some easy steps to follow to get the hang of managing up. Once youâ€™ve gone through these steps a few times, you should be able to manage your manager effectively on the day-to-day, and on large projects.</p>



<figure><img loading="lazy" width="2220" height="2560" src="https://www.7pace.com/wp-content/uploads/2021/01/02-Image-2-scaled.jpg" alt="Your First Managing Up Experiment: Step By Step" srcset="https://www.7pace.com/wp-content/uploads/2021/01/02-Image-2-scaled.jpg 2220w, https://www.7pace.com/wp-content/uploads/2021/01/02-Image-2-260x300.jpg 260w, https://www.7pace.com/wp-content/uploads/2021/01/02-Image-2-888x1024.jpg 888w, https://www.7pace.com/wp-content/uploads/2021/01/02-Image-2-768x886.jpg 768w, https://www.7pace.com/wp-content/uploads/2021/01/02-Image-2-1332x1536.jpg 1332w, https://www.7pace.com/wp-content/uploads/2021/01/02-Image-2-1776x2048.jpg 1776w" sizes="(max-width: 2220px) 100vw, 2220px"></figure>



<p><strong>Step 1</strong>: Try to pick a skill area that requires little to no investment. When youâ€™re first learning how to manage up, itâ€™s a good idea to do so in an area where youâ€™re already skilled and comfortable. It gives you better odds of knocking your experiment out of the park.</p>



<p><strong>Step 2: </strong>Baseline the current state well before you start making changes. A key to being successful at managing up is to show that your autonomous work is of good quality and improves the teamâ€™s work or moves the team forward. So before you start, make sure you document the baseline youâ€™re working with so youâ€™ll be able to show improvement.</p>



<p><strong>Step 3: </strong>Based on the current metrics and perception, create a plan that will improve KPIs. This is where the baseline you established will come in handy. Figure out how to improve beyond that baseline, and then take your plan to your boss to show them how you can make the desired improvements.</p>



<p><strong>Step 4: </strong>Execute the plan with your bossâ€™s blessing. Managing up isnâ€™t about going behind your bossâ€™s back. Itâ€™s about presenting your plan to improve metrics in such a way that even your boss will see how this makes your life, their life, and the lives of everyone on the team easier. You want them to have no choice but to give you their blessing.</p>



<p><strong>Step 5: </strong>Measure for success. Track whatever KPIs are important and compare them against the baseline you established in Step 2 so you can clearly show improvement.</p>



<p><strong>Step 6: </strong>Move on to another item to build more trust. Once youâ€™ve shown you can improve one area of your or your teamâ€™s work, choose another to focus on. This shows your boss that you can replicate your autonomous success.</p>



<p><strong>Step 7: </strong>Run this for at least 3 cycles before you ask your manager for anything big. As you establish yourself as someone who can deliver on your promises and make improvements at work, youâ€™ll eventually build the trust needed to take on bigger and bigger projects â€”&nbsp;and more and more control over your work environment.</p>



<h2>Best Practices for Managing Up</h2>



<p>Like any other skill, though, managing up is easier said than done. These are some of the best practices that will help you succeed at managing your manager.</p>



<h3>Dos and Donâ€™ts</h3>



<p>Letâ€™s start with the things you <strong>should and should not do</strong>&nbsp;when managing up.</p>



<figure><img loading="lazy" width="2560" height="1025" src="https://www.7pace.com/wp-content/uploads/2021/01/03-Image-2-scaled.jpg" alt="Best Practices for Managing Up" srcset="https://www.7pace.com/wp-content/uploads/2021/01/03-Image-2-scaled.jpg 2560w, https://www.7pace.com/wp-content/uploads/2021/01/03-Image-2-300x120.jpg 300w, https://www.7pace.com/wp-content/uploads/2021/01/03-Image-2-1024x410.jpg 1024w, https://www.7pace.com/wp-content/uploads/2021/01/03-Image-2-768x307.jpg 768w, https://www.7pace.com/wp-content/uploads/2021/01/03-Image-2-1536x615.jpg 1536w, https://www.7pace.com/wp-content/uploads/2021/01/03-Image-2-2048x820.jpg 2048w" sizes="(max-width: 2560px) 100vw, 2560px"></figure>



<p><strong>Do:</strong><strong></strong></p>



<ul><li>Be curious. Get to know your role, your boss, and your bossâ€™s role. Ask a lot of questions. Show an interest in everything about your work and your company.</li><li>Anticipate needs. As you get to know your boss and their job better, you might be able to deliver on what they need before they even ask you for it.</li><li>Jump in. Always be willing to help out wherever and whenever you can.</li><li>Think about the big picture. Try to see beyond your role, and what the goals and direction are for your entire organization. Then, align your own goals and priorities with the bigger picture.</li></ul>



<p><strong>Donâ€™t:</strong><strong></strong></p>



<ul><li>Manipulate. Thereâ€™s a very big difference between managing up and sucking up, brown-nosing, or being a yes man. You want to be seen as positive, helpful, and self-starting, not as someone who sucks up to their boss to win favor.</li><li>Get involved in politics. Just about any time a group of people works together, thereâ€™s bound to be office politics. Avoid getting involved in them by not talking about other people, but instead focusing on doing your job well and delivering quality and results.</li><li>Cover up your mistakes. As you take on new projects and strive to lead and work autonomously, youâ€™re bound to make mistakes. Own up to them when they happen, and be reflective about how you can learn from them to get better and avoid making similar mistakes in the future. Thatâ€™s the mark of a real leader.</li></ul>



<h2>Getting Better At Managing Up</h2>



<p>Like any workplace skill, getting better at managing up takes work and practice. Here are some ways to continue to improve at managing your manager.</p>



<h3>Come With Solutions, Not Just Problems</h3>



<p>When you run into problems at work, yes you should present those to your boss. But when you come to your manager with a problem, try to also bring a potential solution or two. It shows initiative and mastery.</p>



<h3>Take Small Things Off Your Bossâ€™s Plate</h3>



<p>Managing up doesnâ€™t have to be all about big, grand projects that propel your entire organization forward. It can be as simple as looking for small things you can volunteer to handle for your boss so theyâ€™re off their plate. Look for tasks like scheduling meetings, booking meeting rooms, doing basic research, and other administrative tasks that can save a lot of time for your boss.</p>



<h3>Adjust Your Work Style to Fit Your Bossâ€™s Needs</h3>



<p>One of the best tips for successfully managing up is to adjust your work and communication styles to fit what your boss prefers. For example, if they prefer emails over face-to-face meetings, try to shoot off messages to them throughout the day rather than stopping by their office with questions and updates.</p>



<h3>Lead New Changes That Meet Big Picture Goals</h3>



<p>Look for ways to change your workplace processes or innovate, and when you present those to your boss, volunteer to lead the work that it will take to implement those changes. This shows a few things: That youâ€™re aware of and thinking about the big-picture goals of your organization, and that youâ€™re willing to put in the work it takes to move toward those goals.</p>



<p>Learning how to manage up will take time and work â€” this is definitely a long-term strategy for gaining autonomy and control over your work environment.</p>



<p>But that work will pay off when youâ€™re a trusted part of your organization, known for being able to tackle any problem without being micromanaged. Give your boss better things to do than breathe down your neck â€”&nbsp;start managing up today.</p>
						</div></div>]]>
            </description>
            <link>https://www.7pace.com/blog/managing-up</link>
            <guid isPermaLink="false">hacker-news-small-sites-26167368</guid>
            <pubDate>Wed, 17 Feb 2021 15:27:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: An Event Sourced Minesweeper]]>
            </title>
            <description>
<![CDATA[
Score 83 | Comments 24 (<a href="https://news.ycombinator.com/item?id=26166595">thread link</a>) | @david-farr
<br/>
February 17, 2021 | https://dfarr.github.io/minesweeper | <a href="https://web.archive.org/web/*/https://dfarr.github.io/minesweeper">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://dfarr.github.io/minesweeper</link>
            <guid isPermaLink="false">hacker-news-small-sites-26166595</guid>
            <pubDate>Wed, 17 Feb 2021 14:28:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Coronavirus human challenge study gets green light in UK]]>
            </title>
            <description>
<![CDATA[
Score 113 | Comments 184 (<a href="https://news.ycombinator.com/item?id=26166556">thread link</a>) | @timthorn
<br/>
February 17, 2021 | https://www.politico.eu/article/worlds-first-coronavirus-human-challenge-study-gets-green-light-in-uk/ | <a href="https://web.archive.org/web/*/https://www.politico.eu/article/worlds-first-coronavirus-human-challenge-study-gets-green-light-in-uk/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
									<p>The U.K. is set to begin the worldâ€™s first trial of healthy volunteers being intentionally infected with coronavirus, after the study received ethics approval.&nbsp;</p>
<p>The so-called human challenge study will begin within a month, said the U.K. Department for Business, Energy and Industrial Strategy in a statement Wednesday, with up to 90 people being exposed to a very small amount of coronavirus in a safe and controlled environment. These kinds of trials are controversial as they expose healthy volunteers to diseases that may be deadly.&nbsp;</p>
<p>The next stage of the study, which has not yet been approved, will involve giving a coronavirus vaccine to different volunteers and then exposing them to coronavirus. Only vaccines that â€œhave proven to be safe in clinical trialsâ€ will be used. However, researchers are still a â€œlong wayâ€ from this stage of the study, according to Terence Stephenson, chair of the Health Research Authority, which gave ethics approval.</p>

<p>Proponents say these studies provide the fastest way to evaluate new vaccines, especially when the world emerges from an active pandemic, said Robert Read, head of clinical and experimental sciences within medicine at the University of Southampton, who belongs to this camp and is part of the team involved in the study.</p>
<p>This initial part of the study will help doctors understand how the immune system reacts to the virus and identify what affects transmission. The drug&nbsp;Remdesivir will be used as soon as volunteers start developing symptoms. </p>
<p>The volunteers, who are being encouraged to come forward for the study, will be between 18 and 30 and will be exposed to the variant circulating in the U.K. since March 2020. </p>
<p><em>This article is part of </em><span>POLITICO</span><em>â€™s premium policy service: Pro Health Care. From drug pricing, EMA, vaccines, pharma and more, our specialized journalists keep you on top of the topics driving the health care policy agenda. Email <a href="https://www.politico.eu/article/worlds-first-coronavirus-human-challenge-study-gets-green-light-in-uk/%E2%80%9Cmailto:pro@politico.eu%E2%80%9D" target="_blank"><span data-cfemail="90e0e2ffd0e0fffcf9e4f9f3ffbef5e5">[email&nbsp;protected]</span></a> for a complimentary trial.</em></p>
								</div></div>]]>
            </description>
            <link>https://www.politico.eu/article/worlds-first-coronavirus-human-challenge-study-gets-green-light-in-uk/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26166556</guid>
            <pubDate>Wed, 17 Feb 2021 14:24:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Python Concurrency: The Tricky Bits]]>
            </title>
            <description>
<![CDATA[
Score 39 | Comments 15 (<a href="https://news.ycombinator.com/item?id=26166232">thread link</a>) | @rbanffy
<br/>
February 17, 2021 | https://python.hamel.dev/concurrency/ | <a href="https://web.archive.org/web/*/https://python.hamel.dev/concurrency/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <p><strong>An exploration of threads, processes, and coroutines in Python, with interesting examples that illuminate the differences between each.</strong></p>
<p><img src="https://python.hamel.dev/cpu.jpg" alt=""> Credit:<sup id="fnref:1"><a href="#fn:1" role="doc-noteref">1</a></sup></p>

<p>As <a href="https://hamel.dev/">a data scientist who is spending more time on software engineering</a>, I was recently forced to confront an ugly gap in my knowledge of Python: concurrency.  To be honest, I never completely understood how the terms async, threads, pools and coroutines were different and how these mechanisms could work together.  Every time I tried to learn about the subject, the examples were a bit too abstract for me, and I hard time internalizing how everything worked.</p>
<p>This changed when a friend of mine<sup id="fnref:2"><a href="#fn:2" role="doc-noteref">2</a></sup> recommended <a href="https://youtu.be/MCs5OvhV9S4">a live coding talk</a> by <a href="https://www.dabeaz.com/">David Beazley</a>, an accomplished Python educator.</p>
<p><em>Because of restrictions with this YouTube video, I couldnâ€™t embed <a href="https://youtu.be/MCs5OvhV9S4">the video</a> in this article, so you will have to open it in a different window</em>.</p>
<p>This talk is incredibly intimidating at first.  Not only is it coded live from scratch, but it also jumps immediately into socket programming, something that I had never encountered as a data scientist.  However, if you go through it slowly and understand all the components (as we do in this blog post) it turns out to be the best educational material on Python concurrency I have ever encountered.  This blog post documents what I learned along the way so others can benefit, too.</p>

<p>Before getting started, David sets up the following infrastructure that is used to demonstrate concurrency.</p>
<h2 id="a-cpu-bound-task-fibonacci">A cpu-bound task: Fibonacci</h2>
<p>To demonstrate concurrency, it is useful to create a task that can saturate your CPU (such as mathematical operations) for a noticeable period of time.  David uses a function that computes a <a href="https://en.wikipedia.org/wiki/Fibonacci_number">Fibonacci number</a>.</p>
<div><div>
<table><tbody><tr><td>
<pre><code><span>1
</span><span>2
</span><span>3
</span><span>4
</span></code></pre></td>
<td>
<pre><code data-lang="py3"><span>#fib.py</span>
<span>def</span> <span>fib</span><span>(</span><span>n</span><span>):</span>
    <span>if</span> <span>n</span> <span>&lt;=</span> <span>2</span><span>:</span> <span>return</span> <span>1</span>
    <span>else</span><span>:</span> <span>return</span> <span>fib</span><span>(</span><span>n</span><span>-</span><span>1</span><span>)</span> <span>+</span> <span>fib</span><span>(</span><span>n</span><span>-</span><span>2</span><span>)</span>
</code></pre></td></tr></tbody></table>
</div>
</div><p>This function takes much longer for large inputs versus smaller inputs<sup id="fnref:3"><a href="#fn:3" role="doc-noteref">3</a></sup>, which allows us to profile different workloads.</p>
<h2 id="a-simple-web-server">A Simple Web Server</h2>
<p>A web server is one of the best ways to illustrate different types of concurrency.  However, to really demonstrate how things work it is useful to use something that is sufficiently low level enough to see how all the pieces work.  For this, David sets up a web server using socket programming.  If you arenâ€™t familiar with socket programming, Iâ€™ll explain the important bits below, but feel free to dive deeper <a href="https://ruslanspivak.com/lsbaws-part1/">with this tutorial</a> later if you like.</p>
<p>To begin with, David starts with the below code (Iâ€™ve highlighted the most interesting bits):</p>
<div><div>
<table><tbody><tr><td>
<pre><code><span> 1
</span><span> 2
</span><span> 3
</span><span> 4
</span><span> 5
</span><span> 6
</span><span> 7
</span><span> 8
</span><span> 9
</span><span>10
</span><span><span>11
</span></span><span>12
</span><span><span>13
</span></span><span>14
</span><span>15
</span><span>16
</span><span><span>17
</span></span><span>18
</span><span>19
</span><span>20
</span><span><span>21
</span></span><span>22
</span><span>23
</span><span>24
</span></code></pre></td>
<td>
<pre><code data-lang="python3"><span># server-1.py</span>
<span>from</span> <span>socket</span> <span>import</span> <span>*</span>
<span>from</span> <span>fib</span> <span>import</span> <span>fib</span> 

<span>def</span> <span>fib_server</span><span>(</span><span>address</span><span>):</span>
    <span>sock</span> <span>=</span> <span>socket</span><span>(</span><span>AF_INET</span><span>,</span> <span>SOCK_STREAM</span><span>)</span>
    <span>sock</span><span>.</span><span>setsockopt</span><span>(</span><span>SOL_SOCKET</span><span>,</span> <span>SO_REUSEADDR</span><span>,</span><span>1</span><span>)</span>
    <span>sock</span><span>.</span><span>bind</span><span>(</span><span>address</span><span>)</span>
    <span>sock</span><span>.</span><span>listen</span><span>(</span><span>5</span><span>)</span>
    <span>while</span> <span>True</span><span>:</span>
<span>        <span>client</span><span>,</span><span>addr</span> <span>=</span> <span>sock</span><span>.</span><span>accept</span><span>()</span>  <span># waits for a connection to be established</span>
</span>        <span>print</span><span>(</span><span>"Connection"</span><span>,</span> <span>addr</span><span>)</span>
<span>        <span>fib_handler</span><span>(</span><span>client</span><span>)</span> <span># passes the client to a handler which will listen for input data.</span>
</span>        
<span>def</span> <span>fib_handler</span><span>(</span><span>client</span><span>):</span>
    <span>while</span> <span>True</span><span>:</span>
<span>        <span>req</span> <span>=</span> <span>client</span><span>.</span><span>recv</span><span>(</span><span>100</span><span>)</span>  <span># waits for data that sent by the client.</span>
</span>        <span>if</span> <span>not</span> <span>req</span><span>:</span> <span>break</span>
        <span>result</span> <span>=</span> <span>fib</span><span>(</span><span>int</span><span>(</span><span>req</span><span>))</span>
        <span>resp</span> <span>=</span> <span>str</span><span>(</span><span>result</span><span>)</span><span>.</span><span>encode</span><span>(</span><span>'ascii'</span><span>)</span> <span>+</span> <span>b</span><span>'</span><span>\n</span><span>'</span>
<span>        <span>client</span><span>.</span><span>send</span><span>(</span><span>resp</span><span>)</span> <span># sends data back to the client.</span>
</span>    <span>print</span><span>(</span><span>"Closed"</span><span>)</span>
    
<span>fib_server</span><span>((</span><span>''</span><span>,</span> <span>25000</span><span>))</span>
</code></pre></td></tr></tbody></table>
</div>
</div><p>Here is an explanation of this code:</p>
<ul>
<li>Lines 6-9 are socket programming boilerplate.  Itâ€™s ok to just take this for granted as a reasonable way to set up a socket server.  This also matches the <a href="https://ruslanspivak.com/lsbaws-part1/">the tutorial</a> I linked to above.</li>
<li>Line 11 waits for an incoming connection from a client.  Once a connection is made, the server can begin receiving data from a client.  The code will stop execution on this line until a connection is made.</li>
<li>Line 13: Once a connection is established, the client object is passed to a function which can handle data sent by the client.</li>
<li>Line 17: waits for data to be sent by the client.  The code will stop execution on this line until data is received from the client.</li>
<li>Line 21: The server sends a response back to the client.  The code <em>could</em> stop execution on this line if the send buffers are full, but unlikely in this toy example.</li>
</ul>

<p>In the above example, the server will only be able to accept a connection from a single client, because the call to <code>fib_handler</code> will never return (because it will run in an infinite loop unless a kill signal is received).  This means that <code>sock.accept()</code> can only be called once.</p>
<p>You can test this out by first running the server:</p>
<p>Then establish a client:</p>
<p>You can type numbers in <a href="https://youtu.be/MCs5OvhV9S4?t=293">as David does in his video</a> and verifies that fibonacci numbers are returned.  However, if you try to connect with another client at the same time from a different terminal session:</p>
<p>You will notice that the second client just hangs and doesnâ€™t return anything from the server.  This is because the server is only able to accept a single connection.  Next, we explore how to tackle this issue.</p>

<p>We can solve this issue with threads.  You can add threads to the handler so that more connections can be accepted with the following code highlighted in yellow:</p>
<div><div>
<table><tbody><tr><td>
<pre><code><span> 1
</span><span> 2
</span><span><span> 3
</span></span><span> 4
</span><span> 5
</span><span> 6
</span><span> 7
</span><span> 8
</span><span> 9
</span><span>10
</span><span>11
</span><span>12
</span><span><span>13
</span></span><span>14
</span><span>15
</span><span>16
</span><span>17
</span><span>18
</span><span>19
</span><span>20
</span><span>21
</span><span>22
</span><span>23
</span><span>24
</span></code></pre></td>
<td>
<pre><code data-lang="py3"><span>from</span> <span>socket</span> <span>import</span> <span>*</span>
<span>from</span> <span>fib</span> <span>import</span> <span>fib</span>
<span><span>from</span> <span>threading</span> <span>import</span> <span>Thread</span>
</span>
<span>def</span> <span>fib_server</span><span>(</span><span>address</span><span>):</span>
    <span>sock</span> <span>=</span> <span>socket</span><span>(</span><span>AF_INET</span><span>,</span> <span>SOCK_STREAM</span><span>)</span>
    <span>sock</span><span>.</span><span>setsockopt</span><span>(</span><span>SOL_SOCKET</span><span>,</span> <span>SO_REUSEADDR</span><span>,</span><span>1</span><span>)</span>
    <span>sock</span><span>.</span><span>bind</span><span>(</span><span>address</span><span>)</span>
    <span>sock</span><span>.</span><span>listen</span><span>(</span><span>5</span><span>)</span>
    <span>while</span> <span>True</span><span>:</span>
        <span>client</span><span>,</span><span>addr</span> <span>=</span> <span>sock</span><span>.</span><span>accept</span><span>()</span>
        <span>print</span><span>(</span><span>"Connection"</span><span>,</span> <span>addr</span><span>)</span>
<span>        <span>Thread</span><span>(</span><span>target</span><span>=</span><span>fib_handler</span><span>,</span> <span>args</span><span>=</span><span>(</span><span>client</span><span>,))</span><span>.</span><span>start</span><span>()</span>
</span>        
<span>def</span> <span>fib_handler</span><span>(</span><span>client</span><span>):</span>
    <span>while</span> <span>True</span><span>:</span>
        <span>req</span> <span>=</span> <span>client</span><span>.</span><span>recv</span><span>(</span><span>100</span><span>)</span> 
        <span>if</span> <span>not</span> <span>req</span><span>:</span> <span>break</span>
        <span>result</span> <span>=</span> <span>fib</span><span>(</span><span>int</span><span>(</span><span>req</span><span>))</span>
        <span>resp</span> <span>=</span> <span>str</span><span>(</span><span>result</span><span>)</span><span>.</span><span>encode</span><span>(</span><span>'ascii'</span><span>)</span> <span>+</span> <span>b</span><span>'</span><span>\n</span><span>'</span>
        <span>client</span><span>.</span><span>send</span><span>(</span><span>resp</span><span>)</span>
    <span>print</span><span>(</span><span>"Closed"</span><span>)</span>
    
<span>fib_server</span><span>((</span><span>''</span><span>,</span> <span>25000</span><span>))</span>
</code></pre></td></tr></tbody></table>
</div>
</div><p>You can verify that this works by connecting two separate clients to the server by running the following command in two separate terminal windows:</p>
<p>By executing the <code>fib_handler</code> in a thread, the main while loop in <code>fib_server</code> will continue, allowing <code>sock.accept()</code> to receive additional clients.  If you havenâ€™t encountered threads before <a href="https://realpython.com/intro-to-python-threading/">this tutorial</a> provides a good introduction to the topic.</p>
<h2 id="thread-performance--the-gil">Thread performance &amp; the GIL</h2>
<p>When code stops execution and waits for an external event to occur (like a connection to be made, or data to be sent), this is often referred to as <a href="https://stackoverflow.com/questions/2407589/what-does-the-term-blocking-mean-in-programming">blocking</a>.</p>
<p>One important utility of threads is that it allows blocking tasks to release control of the CPU when the CPU is not being used.  However, the Python interpreter can only run on one thread at a time due to the <a href="https://wiki.python.org/moin/GlobalInterpreterLock">Global Interpreter Lock</a>.  Because Python can only run a single thread at any given time, any CPU-bound work in threads must take turn running one after the other.</p>
<p>Therefore, you have to think carefully about what kind of tasks you execute in threads with Python.  If you try to execute CPU bound tasks, these tasks will slow each other down.  David demonstrates this with the below script that sends requests to our threaded server:</p>
<div><div>
<table><tbody><tr><td>
<pre><code><span> 1
</span><span> 2
</span><span> 3
</span><span> 4
</span><span> 5
</span><span> 6
</span><span> 7
</span><span> 8
</span><span> 9
</span><span>10
</span><span>11
</span><span>12
</span><span>13
</span></code></pre></td>
<td>
<pre><code data-lang="py"><span>#perf1.py</span>
<span>from</span> <span>socket</span> <span>import</span> <span>*</span>
<span>import</span> <span>time</span>

<span>sock</span> <span>=</span> <span>socket</span><span>(</span><span>AF_INET</span><span>,</span> <span>SOCK_STREAM</span><span>)</span>
<span>sock</span><span>.</span><span>connect</span><span>((</span><span>'localhost'</span><span>,</span> <span>25000</span><span>))</span>

<span>while</span> <span>True</span><span>:</span>
    <span>start</span> <span>=</span> <span>time</span><span>.</span><span>time</span><span>()</span>
    <span>sock</span><span>.</span><span>send</span><span>(</span><span>b</span><span>'30'</span><span>)</span>
    <span>resp</span> <span>=</span> <span>sock</span><span>.</span><span>recv</span><span>(</span><span>100</span><span>)</span>
    <span>end</span> <span>=</span> <span>time</span><span>.</span><span>time</span><span>()</span>
    <span>print</span><span>(</span><span>end</span><span>-</span><span>start</span><span>)</span>
</code></pre></td></tr></tbody></table>
</div>
</div><p>If you run several instances of this script (after starting the server first):</p>
<p>You will see the execution times for each script linearly increase as you increase the number of these scripts running in parallel.  <strong>For this particular task, adding threads does not make anything faster.  But why?</strong>  This is because the fibonacci task is CPU bound so threads will compete with each other for resources.</p>
<p>Python threads work by interleaving the execution of different tasks on your CPU.<sup id="fnref:4"><a href="#fn:4" role="doc-noteref">4</a></sup>  Only one thread runs at a time, and have the ability to take turns executing in small bits until all threads are done.  The details of how thread processing is interleaved is carried out by the GIL and your operating system, so you need not worry about this detail (with one exception mentioned below).  Interleaving a bunch of CPU bound tasks will not speed up the total runtime of those tasks.  However, if your tasks involve lots of non-CPU time, such as waiting for network connections, or disk I/O, threading tasks may result in a considerable speedup.  A canonical way of simulating a non-cpu bound task in python is to use the built-in function <code>time.sleep()</code>.</p>
<p>To check my understanding about threads and performance, I ran the below experiment<sup id="fnref:5"><a href="#fn:5" role="doc-noteref">5</a></sup> and changed <code>time.sleep(2)</code> to <code>fib(20)</code> and back again:</p>
<div><div>
<table><tbody><tr><td>
<pre><code><span> 1
</span><span> 2
</span><span> 3
</span><span><span> 4
</span></span><span> 5
</span><span> 6
</span><span> 7
</span><span><span> 8
</span></span><span> 9
</span><span>10
</span><span>11
</span><span>12
</span><span>13
</span><span>14
</span><span>15
</span><span>16
</span><span>17
</span><span>18
</span><span>19
</span><span>20
</span><span>21
</span><span>22
</span><span>23
</span><span>24
</span><span>25
</span><span>26
</span><span>27
</span><span>28
</span><span>29
</span></code></pre></td>
<td>
<pre><code data-lang="py"><span>import</span> <span>logging</span>
<span>import</span> <span>threading</span>
<span>import</span> <span>time</span>
<span><span>import</span> <span>fib</span>
</span>
<span>def</span> <span>thread_function</span><span>(</span><span>name</span><span>):</span>
    <span>logging</span><span>.</span><span>info</span><span>(</span><span>"Thread </span><span>%s</span><span>: starting"</span><span>,</span> <span>name</span><span>)</span>
<span>    <span>time</span><span>.</span><span>sleep</span><span>(</span><span>2</span><span>)</span>  <span>## Change this line of code to fib(20)</span>
</span>    <span>logging</span><span>.</span><span>info</span><span>(</span><span>"Thread </span><span>%s</span><span>: finishing"</span><span>,</span> <span>name</span><span>)</span>

<span>if</span> <span>__name__</span> <span>==</span> <span>"__main__"</span><span>:</span>
    <span>format</span> <span>=</span> <span>"</span><span>%(asctime)s</span><span>: </span><span>%(message)s</span><span>"</span>
    <span>start</span> <span>=</span> <span>time</span><span>.</span><span>time</span><span>()</span>
    <span>logging</span><span>.</span><span>basicConfig</span><span>(</span><span>format</span><span>=</span><span>format</span><span>,</span> <span>level</span><span>=</span><span>logging</span><span>.</span><span>INFO</span><span>,</span>
                        <span>datefmt</span><span>=</span><span>"%H:%M:%S"</span><span>)</span>

    <span>threads</span> <span>=</span> <span>list</span><span>()</span>
    <span>for</span> <span>index</span> <span>in</span> <span>range</span><span>(</span><span>3</span><span>):</span>
        <span>logging</span><span>.</span><span>info</span><span>(</span><span>"Main    : create and start thread </span><span>%d</span><span>."</span><span>,</span> <span>index</span><span>)</span>
        <span>x</span> <span>=</span> <span>threading</span><span>.</span><span>Thread</span><span>(</span><span>target</span><span>=</span><span>thread_function</span><span>,</span> <span>args</span><span>=</span><span>(</span><span>index</span><span>,))</span>
        <span>threads</span><span>.</span><span>append</span><span>(</span><span>x</span><span>)</span>
        <span>x</span><span>.</span><span>start</span><span>()</span>

    <span>for</span> <span>index</span><span>,</span> <span>thread</span> <span>in</span> <span>enumerate</span><span>(</span><span>threads</span><span>):</span>
        <span>logging</span><span>.</span><span>info</span><span>(</span><span>"Main    : before joining thread </span><span>%d</span><span>."</span><span>,</span> <span>index</span><span>)</span>
        <span>thread</span><span>.</span><span>join</span><span>()</span>
        <span>logging</span><span>.</span><span>info</span><span>(</span><span>"Main    : thread </span><span>%d</span><span> done"</span><span>,</span> <span>index</span><span>)</span>
    <span>end</span> <span>=</span> <span>time</span><span>.</span><span>time</span><span>()</span>
    <span>print</span><span>(</span><span>f</span><span>'total time: {end-start}'</span><span>)</span>
</code></pre></td></tr></tbody></table>
</div>
</div><p>As expected, increasing the number of threads while running <code>time.sleep(2)</code> did not increase the programâ€™s overall execution time (the program runs in roughly 2 seconds).  On the other hand, replacing <code>time.sleep(2)</code> with <code>fib(20)</code> causes this programâ€™s running time to increase as more threads are added. This is because <code>fib(20)</code> is a cpu bound task so interleaving the â€¦</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://python.hamel.dev/concurrency/">https://python.hamel.dev/concurrency/</a></em></p>]]>
            </description>
            <link>https://python.hamel.dev/concurrency/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26166232</guid>
            <pubDate>Wed, 17 Feb 2021 13:51:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Declassified spacecrafts and orbital weapons of the USSR (2018)]]>
            </title>
            <description>
<![CDATA[
Score 306 | Comments 96 (<a href="https://news.ycombinator.com/item?id=26166204">thread link</a>) | @eternalban
<br/>
February 17, 2021 | https://www.xissufotoday.space/2018/04/declassified-spacecrafts-and-orbital.html | <a href="https://web.archive.org/web/*/https://www.xissufotoday.space/2018/04/declassified-spacecrafts-and-orbital.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="post-body-8701437466444498891" itemprop="description articleBody">
<p><a href="https://1.bp.blogspot.com/-hR9EPgdNTO0/V6igmMBuAsI/AAAAAAAABPs/RyK0eKmYbkor6nNer0HytjJN5OsSST14QCLcB/s1600/skif-20.jpg"><img alt="" height="296" src="https://1.bp.blogspot.com/-hR9EPgdNTO0/V6igmMBuAsI/AAAAAAAABPs/RyK0eKmYbkor6nNer0HytjJN5OsSST14QCLcB/s640/skif-20.jpg" width="640"></a></p><br>

<p>Fighting orbital laser station â€œPolyusâ€ / â€œSkifâ€</p>
<p>(THE USSR)</p>
<p><a href="https://3.bp.blogspot.com/-vRb_iAi4sj8/V6igjYWZOKI/AAAAAAAABPo/6LaxidVk0dI_X7swTaVcqIBXuXhq_xqAACLcB/s1600/pole%2B16.gif"><img alt="Space program of Star Wars, and the technology that you have not seen before." src="https://3.bp.blogspot.com/-vRb_iAi4sj8/V6igjYWZOKI/AAAAAAAABPo/6LaxidVk0dI_X7swTaVcqIBXuXhq_xqAACLcB/s1600/pole%2B16.gif" title="Space program of Star Wars"></a></p>
<p>Specifications</p>
<p>Length: 37.00 m (121.39 ft)</p>
<p>Maximum Diameter: 4.10 m (13.5 ft)</p>
<p>Mass: 80,000 kg (180,000 lb)</p>
<p>Associated Launch Vehicle: Energia.</p>
<p>Intended orbit: altitude 280 km (170 mi), inclination 64Â°</p>
<p>Targeting system: optical, radar, with low-yield laser for final targeting</p>
<p>Armament: 1-megawatt carbon-dioxide laser</p>
<p><a href="https://2.bp.blogspot.com/-ITAhROrlH5w/V6igsIb3bjI/AAAAAAAABPw/EEm94HDTt7sCoOJYU8ClpAGYHgefGZqsQCLcB/s1600/skif-11.jpg"><img alt="" height="296" src="https://2.bp.blogspot.com/-ITAhROrlH5w/V6igsIb3bjI/AAAAAAAABPw/EEm94HDTt7sCoOJYU8ClpAGYHgefGZqsQCLcB/s640/skif-11.jpg" title="Armament: 1-megawatt carbon-dioxide laser" width="640"></a></p><br>

<p>The&nbsp;Polyus&nbsp;spacecraft (<a title="Russian language" href="https://en.wikipedia.org/wiki/Russian_language">Russian</a>:&nbsp;<span lang="ru" xml:lang="ru">ĞŸĞ¾Ğ»ÑÑ</span>,&nbsp;<a title="Geographical pole" href="https://en.wikipedia.org/wiki/Geographical_pole">pole</a>), also known as&nbsp;Polus,&nbsp;Skif-DM,&nbsp;<a title="GRAU" href="https://en.wikipedia.org/wiki/GRAU">GRAU</a>&nbsp;index&nbsp;17F19DM, was a prototype<a title="Space weapon" href="https://en.wikipedia.org/wiki/Space_weapon">orbital weapons platform</a>&nbsp;designed to destroy&nbsp;<a title="Strategic Defense Initiative" href="https://en.wikipedia.org/wiki/Strategic_Defense_Initiative">SDI satellites</a>&nbsp;with a megawatt&nbsp;<a title="Carbon dioxide laser" href="https://en.wikipedia.org/wiki/Carbon_dioxide_laser">carbon-dioxide laser</a>.<a href="https://en.wikipedia.org/wiki/Polyus_(spacecraft)#cite_note-starwars-1">[1]</a>&nbsp;It had a Functional Cargo Block derived from a&nbsp;<a title="TKS spacecraft" href="https://en.wikipedia.org/wiki/TKS_spacecraft">TKS spacecraft</a>&nbsp;to control its orbit and it could fire test targets to demonstrate the fire control system.</p>
<p>The Polyus spacecraft was launched 15 May 1987 from&nbsp;<a title="Baikonur Cosmodrome" href="https://en.wikipedia.org/wiki/Baikonur_Cosmodrome">Baikonur Cosmodrome</a>&nbsp;<a title="Baikonur Cosmodrome Site 250" href="https://en.wikipedia.org/wiki/Baikonur_Cosmodrome_Site_250">Site 250</a>&nbsp;as part of the first flight of the&nbsp;<a title="Energia" href="https://en.wikipedia.org/wiki/Energia">Energia</a>system,<a href="https://en.wikipedia.org/wiki/Polyus_(spacecraft)#cite_note-2">[2]</a>&nbsp;but failed to reach orbit.</p>
<p>According to&nbsp;<a title="Yuri Kornilov (page does not exist)" href="https://en.wikipedia.org/w/index.php?title=Yuri_Kornilov&amp;action=edit&amp;redlink=1">Yuri Kornilov</a>, Chief Designer of the Salyut Design Bureau, shortly before Polyusâ€™ launch,&nbsp;<a title="Mikhail Gorbachev" href="https://en.wikipedia.org/wiki/Mikhail_Gorbachev">Mikhail Gorbachev</a>&nbsp;visited the Baikonur Cosmodrome and expressly forbade the in-orbit testing of its capabilities. Kornilov claims that Gorbachev was worried that it would be possible for Western governments to view this activity as an attempt to create a weapon in space and that such an attempt would contradict the countryâ€™s previous statements on the USSRâ€™s peaceful intent.<a href="https://en.wikipedia.org/wiki/Polyus_(spacecraft)#cite_note-kornilov-3">[3]</a></p>
<p>For technical reasons, the payload was launched upside down. It was designed to separate from the Energia, rotate 180 degrees in yaw, then 90 degrees in roll and then fire its engine to complete its boost to orbit. The Energia functioned perfectly. However, after disconnecting from Energia, the Polyus spun a full 360 degrees instead of the planned 180 degrees. When the rocket fired, it slowed and burned up in the atmosphere over the south Pacific ocean. This failure was attributed to a faulty<a title="Inertial guidance system" href="https://en.wikipedia.org/wiki/Inertial_guidance_system">inertial guidance system</a>&nbsp;that had not been rigorously tested due to the rushed production schedule.<a href="https://en.wikipedia.org/wiki/Polyus_(spacecraft)#cite_note-grondine-4">[4]</a></p><br>
<br>
<br>

<p><a href="https://3.bp.blogspot.com/-teiFsqZWb7A/V6ihr9TtXaI/AAAAAAAABP8/HzSWNCrGZZQnx6BbBREK4OTHhQYh6skAACLcB/s1600/pole12.jpg"><img alt="Space program of Star Wars, and the technology that you have not seen before." height="348" src="https://3.bp.blogspot.com/-teiFsqZWb7A/V6ihr9TtXaI/AAAAAAAABP8/HzSWNCrGZZQnx6BbBREK4OTHhQYh6skAACLcB/s640/pole12.jpg" title="Space program of Star Wars, and the technology that you have not seen before." width="640"></a></p>
<p>NPO&nbsp;Energia&nbsp;received orders from the&nbsp;<a title="Government of the Soviet Union" href="https://en.wikipedia.org/wiki/Government_of_the_Soviet_Union">Soviet government</a>&nbsp;to begin research on space-based strike weapons in the mid-70s. Even before, the USSR had been developing maneuverable satellites for the purpose of satellite interception. By the beginning of the 1980s,&nbsp;Energia&nbsp;had proposed two programs: laser-equipped&nbsp;Skif&nbsp;and guided missiles platform&nbsp;Kaskad&nbsp;(where&nbsp;Skif&nbsp;would cover the low-orbit targets,&nbsp;Kaskad&nbsp;engaged targets in high and geosynchronous orbits). Together with NPO&nbsp;Astrofizika&nbsp;and KBSalyut, they began developing their orbital weapons platform based on the&nbsp;<a title="Salyut program" href="https://en.wikipedia.org/wiki/Salyut_program">Salyut</a>&nbsp;DOS-17K frame.</p>
<p>Later, when the objective of ICBM interception proved too difficult, the aims of the project were shifted towards anti-satellite weapons. The 1983 announcement by the US of their SDI program prompted further political and financial support for the satellite interceptor program. In the nuclear exchange scenario, the interceptors would destroy the SDI satellites, followed by a so-called â€œpre-emptive retaliationâ€ large-scale Soviet ICBM launch.</p>
<p><a href="https://4.bp.blogspot.com/-Hi0M3Kqk2yU/V6ih91L_cxI/AAAAAAAABQA/hQqNjrWW5-syquXFC5bw8VN7v7Wz33VVgCLcB/s1600/pole13.jpg"><img alt="Skif spacecraft was the 1-megawatt carbon-dioxide laser, developed for the Beriev A-60 aircraft (an Il-76 flying laboratory with a combat laser)" height="332" src="https://4.bp.blogspot.com/-Hi0M3Kqk2yU/V6ih91L_cxI/AAAAAAAABQA/hQqNjrWW5-syquXFC5bw8VN7v7Wz33VVgCLcB/s640/pole13.jpg" title="Skif a combat laser)" width="640"></a></p><br>

<p>The laser chosen for the&nbsp;Skif&nbsp;spacecraft was the 1-megawatt carbon-dioxide laser, developed for the&nbsp;<a title="Beriev A-60" href="https://en.wikipedia.org/wiki/Beriev_A-60">Beriev A-60</a>&nbsp;aircraft (an Il-76 flying laboratory with a combat laser). The introduction of the&nbsp;Energia, capable of launching about 95 tonnes into orbit, finally allowed the spacecraft to accommodate the massive laser. The massive exhaust of the carbon-dioxide laser precipitated the objective of making the laser â€œrecoil-lessâ€. The&nbsp;zero-torque exhaust system&nbsp;(SBM) was developed to that end. Its testing in orbit meant the release of a large cloud of carbon dioxide, which would hint at the satelliteâ€™s purpose. Instead, the xenon-krypton mix would be used to simultaneously test the SBM and perform an innocent experiment on Earthâ€™s&nbsp;<a title="Ionosphere" href="https://en.wikipedia.org/wiki/Ionosphere">ionosphere</a>.</p>
<p>In 1985, the decision was made to test-launch the new&nbsp;Energia&nbsp;launch vehicle, which was still in the&nbsp;<a title="Testbed" href="https://en.wikipedia.org/wiki/Testbed">testbed</a>&nbsp;phase. A 100-ton dummy payload was initially considered for the launch, but in a series of last-minute changes, it was decided that the almost-completed&nbsp;Skif&nbsp;spacecraft would be launched instead for a 30-day mission.</p>
<p>The launch May 15, 1987, shot by 24 cameras from different angles.</p>
<p>Prelaunch installation&nbsp;04.02.1987</p>
<p>The development of the real&nbsp;Skif&nbsp;was completed in just one year, from September 1985 to September 1986. Testing and tweaking the&nbsp;Energia&nbsp;launch vehicle, the launch pad and the&nbsp;Skif&nbsp;itself moved the launch to February, and later to May 1987. According to Boris Gubanov, the head designer of the&nbsp;Energia&nbsp;launch vehicle, the work schedule of the preceding years was exhausting, and at the point of Mikhail Gorbachevâ€™s visit on 11 May, he asked the Soviet premier to clear the launch now, because â€œthere will be heart attacksâ€.</p>
<p><a href="https://4.bp.blogspot.com/-CwxOEC0MP1o/V6ij0CpjnyI/AAAAAAAABQQ/EkKtncbH2OM8cwUp419gnVtycH86sGcZACLcB/s1600/gud_anim.gif"><img alt="Prelaunch installation 04.02.1987" src="https://4.bp.blogspot.com/-CwxOEC0MP1o/V6ij0CpjnyI/AAAAAAAABQQ/EkKtncbH2OM8cwUp419gnVtycH86sGcZACLcB/s1600/gud_anim.gif" title="Prelaunch installation 04.02.1987"></a></p>
<p>The catastrophic malfunction that led to&nbsp;Skif&nbsp;entering the atmosphere in the same area as&nbsp;Energiaâ€™s&nbsp;second stage was successfully investigated. It was found that 568 seconds after launch, the timing control device gave the logical block a command to discard the side modulesâ€™ covers and laser exhaust covers. Unknowingly, the same command was earlier used to open the solar panels and disengage the maneuvering thrusters. This wasnâ€™t discovered because of the logistics of the testing process and overall haste. Main thrusters engaged while the&nbsp;Skif&nbsp;kept turning, overshooting the intended 180-degree turn. The spacecraft lost speed and reverted to the&nbsp;<a title="Ballistic trajectory" href="https://en.wikipedia.org/wiki/Ballistic_trajectory">ballistic trajectory</a>.</p><br>

<p>Air-orbital plane â€œSpiralâ€</p>
<p><a href="https://1.bp.blogspot.com/-STY5S6KFa5A/V6imrd6R8MI/AAAAAAAABQc/0vSgs5_ceE03HJFT6TPu2zTt2tC1GwG_ACLcB/s1600/spiral7.gif"><img alt="Air-orbital plane &quot;Spiral&quot;" src="https://1.bp.blogspot.com/-STY5S6KFa5A/V6imrd6R8MI/AAAAAAAABQc/0vSgs5_ceE03HJFT6TPu2zTt2tC1GwG_ACLcB/s1600/spiral7.gif" title="Air-orbital plane &quot;Spiral&quot;"></a></p>
<p><a href="https://1.bp.blogspot.com/-awSlGVXU2MM/V6inOZK9REI/AAAAAAAABQk/4CO-uHtBTngwWFReSMGI1ihvVKlMaSK0ACLcB/s1600/bor4_13.gif"><img alt="Air-orbital plane &quot;Spiral&quot;" height="400" src="https://1.bp.blogspot.com/-awSlGVXU2MM/V6inOZK9REI/AAAAAAAABQk/4CO-uHtBTngwWFReSMGI1ihvVKlMaSK0ACLcB/s640/bor4_13.gif" title="Air-orbital plane &quot;Spiral&quot;" width="640"></a></p><br>
<br>
<div>
<p>Aerospace System â€œSpiralâ€ â€“ space application system consisting of the orbital plane, which is the start of the air technology was displayed in hypersonic space plane, overclockers, and then stage rocket into orbit.</p>
<p><a href="https://4.bp.blogspot.com/-Sdl49qj8rKg/V6inZw8e77I/AAAAAAAABQo/WSA3ZjZaT1w9wuc6Zq-uBKZAXLDqErORwCLcB/s1600/MiG-105-11a.jpg"><img alt="Aerospace System &quot;Spiral&quot; - space application system consisting of the orbital plane" height="426" src="https://4.bp.blogspot.com/-Sdl49qj8rKg/V6inZw8e77I/AAAAAAAABQo/WSA3ZjZaT1w9wuc6Zq-uBKZAXLDqErORwCLcB/s640/MiG-105-11a.jpg" title="Aerospace System &quot;Spiral&quot; - space application system consisting of the orbital plane" width="640"></a></p>
<p>Source of image WIKIPEDIA</p>
<p>The â€œSpiralâ€, launched in 1960, was a response to the creation of the US space program interceptor reconnaissance-bomber, the X-20, â€œthe Dyna Soarâ€</p><br>
<br>
<div>
<p>Plane-overclockers</p>
<p>Powerful airship overclockers (weight 52 tons, length 38 meters, wingspan of 16.5 m) was dispersed to six times the speed of sound (6M), then with his â€œbackâ€ at an altitude of 28-30 km was supposed to start a 10-ton manned orbital plane 8 m long and 7.4 m span.</p>
<p><a href="https://2.bp.blogspot.com/-oSes4d9bcsg/V6inJIfNtfI/AAAAAAAABQg/lqy4GYfzDyk1Pp_vJyG_SIqnIVVrvhkzgCLcB/s1600/spiral1.gif"><img alt="Plane-overclockers" height="262" src="https://2.bp.blogspot.com/-oSes4d9bcsg/V6inJIfNtfI/AAAAAAAABQg/lqy4GYfzDyk1Pp_vJyG_SIqnIVVrvhkzgCLcB/s640/spiral1.gif" title="Plane-overclockers" width="640"></a></p><br>

<p>â€œThe plane-overclockers to 6 Mach suggests the possibility of use as a passenger plane, airliner, which, of course, was rational: its high speed characteristics would allow to raise the rate of civil aviation.â€</p>
<p>Plane-overclockers was the first technologically revolutionary detailed design of hypersonic aircraft with jet engines. At the 40th Congress of the International Aeronautical Federation (the FAI), which took place in 1989 in Malaga (Spain), representatives of the US National Aeronautics and Space Administration (NASAâ€™s) gave the plane-overclockers high praise, noting that he â€œwas designed in accordance with the modern requirements. â€œ</p><br>

<p>In view of the requirements of a lot of money for brand new motor, aerodynamic and material science technologies for the creation of such a hypersonic-overclockers aircraft in the latest versions of the project was considered less costly and more quickly achievable possibility of creating not a hypersonic and supersonic overclockers, as is considered modified shock-reconnaissance aircraft T-4 ( â€œ100â€), however it was not realized.</p><br>
</div>
<p><a href="https://4.bp.blogspot.com/-f56Ka-Kmgx4/V6ing6SrPHI/AAAAAAAABQw/wSvcahmzZrUuhoyTc6KunO_st0HMdJsRwCLcB/s1600/spiral%2B1.gif"><img alt="hypersonic-overclockers aircraft" height="168" src="https://4.bp.blogspot.com/-f56Ka-Kmgx4/V6ing6SrPHI/AAAAAAAABQw/wSvcahmzZrUuhoyTc6KunO_st0HMdJsRwCLcB/s640/spiral%2B1.gif" title="hypersonic-overclockers aircraft" width="640"></a></p>
<p><a href="https://4.bp.blogspot.com/-ntrWcYZ1jMY/V6ing_kTtCI/AAAAAAAABQs/vzqLBGTn4AEoWQ_7w-FnT3bYQFDpNslWACLcB/s1600/spiral%2B2%2B%25281%2529.gif"><img alt="hypersonic-overclockers aircraft" height="458" src="https://4.bp.blogspot.com/-ntrWcYZ1jMY/V6ing_kTtCI/AAAAAAAABQs/vzqLBGTn4AEoWQ_7w-FnT3bYQFDpNslWACLcB/s640/spiral%2B2%2B%25281%2529.gif" title="hypersonic-overclockers aircraft" width="640"></a></p><br>
<br>

<p>BOR&nbsp;space drone</p>
<p><a href="https://3.bp.blogspot.com/-vYoT5DevGH4/V6ipam0sBYI/AAAAAAAABRo/V6aXqq5FKt8-46cakc0zzbqGkH3Hr-yiwCLcB/s1600/i1053rp.jpg"><img height="194" src="https://3.bp.blogspot.com/-vYoT5DevGH4/V6ipam0sBYI/AAAAAAAABRo/V6aXqq5FKt8-46cakc0zzbqGkH3Hr-yiwCLcB/s640/i1053rp.jpg" width="640"></a></p><br>

<p><a href="https://4.bp.blogspot.com/-wLcFH5YIyno/V6ipKJ5PMVI/AAAAAAAABRM/Lut7B63tcT08_Kqvl82jsFVW-H4-p1x8ACLcB/s1600/bor4-15.gif"><img alt="Unpiloted Orbital Rocketplane 4" height="412" src="https://4.bp.blogspot.com/-wLcFH5YIyno/V6ipKJ5PMVI/AAAAAAAABRM/Lut7B63tcT08_Kqvl82jsFVW-H4-p1x8ACLcB/s640/bor4-15.gif" title="Unpiloted Orbital Rocketplane 4" width="640"></a></p><br>
<br>
<div>
<p>The&nbsp;BOR-4&nbsp;(<span lang="ru" xml:lang="ru">Bespilotnyi Orbitalâ€™nyi Raketoplan 4</span>, â€œUnpiloted Orbital Rocketplane 4â€) flight vehicle is a scaled (1:2) prototype of the Soviet&nbsp;<a title="Spiral spaceplane" href="https://en.wikipedia.org/wiki/Spiral_spaceplane">Spiral</a>&nbsp;<a title="VTHL" href="https://en.wikipedia.org/wiki/VTHL">VTHL</a>&nbsp;(vertical takeoff, horizontal landing)<a title="Spaceplane" href="https://en.wikipedia.org/wiki/Spaceplane">spaceplane</a>. An unmanned, subscale&nbsp;<a title="Spacecraft" href="https://en.wikipedia.org/wiki/Spacecraft">spacecraft</a>, its purpose was to test the heatshield tiles and reinforced carbon-carbon for the&nbsp;<a title="Buran (spacecraft)" href="https://en.wikipedia.org/wiki/Buran_(spacecraft)">Buran space shuttle</a>, then under development.<a href="https://en.wikipedia.org/wiki/BOR-4#cite_note-1">[1]</a></p>
<p>Several of them were built and flown between 1982 and 1984 from the&nbsp;<a title="Kapustin Yar" href="https://en.wikipedia.org/wiki/Kapustin_Yar">Kapustin Yar</a>&nbsp;launch site at speeds of up to Mach 25. After reentry, they were designed to parachute to an ocean splashdown for recovery by the&nbsp;<a title="Soviet Navy" href="https://en.wikipedia.org/wiki/Soviet_Navy">Soviet Navy</a>. The testing was nearly identical to that carried out by the&nbsp;<a title="US Air Force" href="https://en.wikipedia.org/wiki/US_Air_Force">US Air Force</a>&nbsp;<a title="ASSET (spaceplane)" href="https://en.wikipedia.org/wiki/ASSET_(spaceplane)">ASSET program</a>&nbsp;in the 1960s, which tested the heatshield design for the&nbsp;<a title="X-20 Dyna-Soar" href="https://en.wikipedia.org/wiki/X-20_Dyna-Soar">X-20 Dyna-Soar</a>. On June 3, 1982 a&nbsp;<a title="Royal Australian Air Force" href="https://en.wikipedia.org/wiki/Royal_Australian_Air_Force">Royal Australian Air Force</a>&nbsp;<a title="P-3 Orion" href="https://en.wikipedia.org/wiki/P-3_Orion">P-3 Orion</a>&nbsp;reconnaissance aircraft captured the first Western images of the craft as it was recovered by a Soviet ship near the&nbsp;<a title="Cocos Islands" href="https://en.wikipedia.org/wiki/Cocos_Islands">Cocos Islands</a>.<a href="https://en.wikipedia.org/wiki/BOR-4#cite_note-2">[2]</a></p>
<p><a href="https://1.bp.blogspot.com/-HAbZbRnqeZ4/V6ipQtSw7HI/AAAAAAAABRQ/ZzElR0QP8iQPgvjpcaG761a29F3tTdFVQCLcB/s1600/bor4-7.gif"><img height="640" src="https://1.bp.blogspot.com/-HAbZbRnqeZ4/V6ipQtSw7HI/AAAAAAAABRQ/ZzElR0QP8iQPgvjpcaG761a29F3tTdFVQCLcB/s640/bor4-7.gif" width="96"></a></p>
<p><a href="https://3.bp.blogspot.com/-EfUE1OWo-q8/V6ipQ5Jsr9I/AAAAAAAABRY/lf6Bx_Idsg8PG1gu2i0r46PFAZ-imiQ0QCLcB/s1600/bor4-81.gif"><img src="https://3.bp.blogspot.com/-EfUE1OWo-q8/V6ipQ5Jsr9I/AAAAAAAABRY/lf6Bx_Idsg8PG1gu2i0r46PFAZ-imiQ0QCLcB/s1600/bor4-81.gif"></a></p>
<p><a href="https://2.bp.blogspot.com/-pQX430XulG0/V6ipQitpQII/AAAAAAAABRU/SEG93Sg14nwtZBsQci-UTdqaWowXrCDHACLcB/s1600/i0865rp.jpg"><img height="304" src="https://2.bp.blogspot.com/-pQX430XulG0/V6ipQitpQII/AAAAAAAABRU/SEG93Sg14nwtZBsQci-UTdqaWowXrCDHACLcB/s640/i0865rp.jpg" width="640"></a></p>
<p><a href="https://3.bp.blogspot.com/-vCQ4NhAyzF4/V6ipQ9YS97I/AAAAAAAABRc/VucBuBk__mgOtRDAI3ayI70kg1vaQ-aAwCLcB/s1600/i0937rp.jpg"><img height="300" src="https://3.bp.blogspot.com/-vCQ4NhAyzF4/V6ipQ9YS97I/AAAAAAAABRc/VucBuBk__mgOtRDAI3ayI70kg1vaQ-aAwCLcB/s400/i0937rp.jpg" width="400"></a></p>
<p><a href="https://4.bp.blogspot.com/-4ecLgpjXV38/V6ipRJYXmZI/AAAAAAAABRg/08wrJ-l3LY0f6aG_xaaSOv3vrUwTeGw8ACLcB/s1600/i1040rp.jpg"><img height="640" src="https://4.bp.blogspot.com/-4ecLgpjXV38/V6ipRJYXmZI/AAAAAAAABRg/08wrJ-l3LY0f6aG_xaaSOv3vrUwTeGw8ACLcB/s640/i1040rp.jpg" width="478"></a></p>
<p><a href="https://1.bp.blogspot.com/-z39-2F9dR44/V6ipRQ0HF0I/AAAAAAAABRk/1J2wISGkfnIwKtECHQX7SODuAfjmsMO-gCLcB/s1600/i1043rp.jpg"><img height="640" src="https://1.bp.blogspot.com/-z39-2F9dR44/V6ipRQ0HF0I/AAAAAAAABRk/1J2wISGkfnIwKtECHQX7SODuAfjmsMO-gCLcB/s640/i1043rp.jpg" width="478"></a></p><br>
<br>
<br>
<br>

<p><a href="https://2.bp.blogspot.com/-329Ztj6nwh0/V6io8aeDcfI/AAAAAAAABRE/RAwaJyioMJ8V0dxgtXEHAZVAc0YhZDpBACLcB/s1600/bor13_11.gif"><img height="300" src="https://2.bp.blogspot.com/-329Ztj6nwh0/V6io8aeDcfI/AAAAAAAABRE/RAwaJyioMJ8V0dxgtXEHAZVAc0YhZDpBACLcB/s400/bor13_11.gif" width="400"></a></p>
<p><a href="https://3.bp.blogspot.com/-eS6bZ2WgV4E/V6io8grD54I/AAAAAAAABRI/4vMejPNeBKQODrUBQ7B15-7uR3t1nlJbQCLcB/s1600/bor13_10.gif"><img height="300" src="https://3.bp.blogspot.com/-eS6bZ2WgV4E/V6io8grD54I/AAAAAAAABRI/4vMejPNeBKQODrUBQ7B15-7uR3t1nlJbQCLcB/s400/bor13_10.gif" width="400"></a></p><br>

<p>Russian Aerospace Plane</p><br>
</div>
<p><a href="https://1.bp.blogspot.com/-qBYyz-vcWwc/V6irQnxpysI/AAAAAAAABR0/Y9E9GfdOROAy0Pz-s4v6yvZCV2iJnPVbACLcB/s1600/6803551.jpg"><img alt="Russian Aerospace Plane" height="427" src="https://1.bp.blogspot.com/-qBYyz-vcWwc/V6irQnxpysI/AAAAAAAABR0/Y9E9GfdOROAy0Pz-s4v6yvZCV2iJnPVbACLcB/s640/6803551.jpg" title="Russian Aerospace Plane RAKS" width="640"></a></p><br>
<br>
<div>
<p>Possible Features</p>
<p>&nbsp; &nbsp;Length 7900 mm</p>
<p>&nbsp; &nbsp;Wingspan mm 3600</p>
<p>&nbsp; &nbsp;Starting weight, kg 2200</p>
<p>&nbsp; &nbsp;The stock of liquid oxygen, 18 kg</p>
<p>&nbsp; &nbsp;Speed range, Max 6 â€¦ 14</p><br>
</div>
<p><a href="https://1.bp.blogspot.com/-Id1G8Ai3FHk/V6irWH6acmI/AAAAAAAABSA/7Tq_By2nMfQp4R_0el1V0uAB6SkEsJjpgCLcB/s1600/3587219.jpg"><img alt="Russian Aerospace Plane (RAKS) is created as part of the research work &quot;Eagle&quot; by order of the Russian Aerospace Agency in 1993." height="318" src="https://1.bp.blogspot.com/-Id1G8Ai3FHk/V6irWH6acmI/AAAAAAAABSA/7Tq_By2nMfQp4R_0el1V0uAB6SkEsJjpgCLcB/s640/3587219.jpg" title="Russian Aerospace Plane" width="640"></a></p>
<p>Russian Aerospace Plane (RAKS) is created as part of the research work â€œEagleâ€ by order of the Russian Aerospace Agency in 1993.</p>
<p><a href="https://2.bp.blogspot.com/-ls7d5uPaNL8/V6irV7m1QEI/AAAAAAAABR8/eeGSYmibxNAM7JsA05O0p5SwrodovDUrwCLcB/s1600/8450700.jpg"><img height="244" src="https://2.bp.blogspot.com/-ls7d5uPaNL8/V6irV7m1QEI/AAAAAAAABR8/eeGSYmibxNAM7JsA05O0p5SwrodovDUrwCLcB/s640/8450700.jpg" width="640"></a></p>
<p><a href="https://1.bp.blogspot.com/-DXSuq544CWo/V6irWQKDKiI/AAAAAAAABSE/hVzjAmz0vLoXJyiHuddT5r3rSp2BiwEJgCLcB/s1600/vks-4.jpg"><img height="305" src="https://1.bp.blogspot.com/-DXSuq544CWo/V6irWQKDKiI/AAAAAAAABSE/hVzjAmz0vLoXJyiHuddT5r3rSp2BiwEJgCLcB/s400/vks-4.jpg" width="400"></a></p>
<p><a href="https://2.bp.blogspot.com/-Wx9dP_DpcJk/V6irWTOUtYI/AAAAAAAABSI/Tm0kUSc5vFgPXRYnwiN3TLgxtOqMOqI9ACLcB/s1600/vks-7.jpg"><img height="320" src="https://2.bp.blogspot.com/-Wx9dP_DpcJk/V6irWTOUtYI/AAAAAAAABSI/Tm0kUSc5vFgPXRYnwiN3TLgxtOqMOqI9ACLcB/s320/vks-7.jpg" width="316"></a></p>
<p><a href="https://4.bp.blogspot.com/--w6856Ho57Y/V6irWvdAPII/AAAAAAAABSM/1gAUY-GV0voWH-WJ5jf4BNGfJ2Eo_7fzgCLcB/s1600/vks-8.jpg"><img height="176" src="https://4.bp.blogspot.com/--w6856Ho57Y/V6irWvdAPII/AAAAAAAABSM/1gAUY-GV0voWH-WJ5jf4BNGfJ2Eo_7fzgCLcB/s400/vks-8.jpg" width="400"></a></p><br>
<div>
<p>Main targets:</p>
<p>â€“ The integration of scramjet and airframe;</p>
<p>â€“ Study questions work ramjet engine in real hypersonic flight at cruising speed up to M = 14;</p>
<p>â€“ The study of the thermal problems associated with operating ramjet engine and aerodynamic heating of the airframe;</p>
<p>â€“ Dynamic throttling in a hypersonic scramjet flight;</p>
<p>â€“ Check ground flight test experiments</p><br>
</div><br>
<br>

<p>Kliper</p>
<p><a href="https://1.bp.blogspot.com/-nM6wVrsBtIw/V6itl14uJtI/AAAAAAAABSc/M5lmXznMma4YD02HQ6vUv2moH-Xw_wO-ACLcB/s1600/%25D0%259A%25D0%25BB%25D0%25B8%25D0%25BF%25D0%25B5%25D1%2580_Infografia.jpg"><img alt="Kliper (ĞšĞ»Ğ¸Ğ¿ĞµÑ€, English: Clipper) was a proposed partly reusable manned spacecraft by RSC Energia. Due to lack of funding from the ESA and RSA, the project has been indefinitely postponed as of 2006." height="398" src="https://1.bp.blogspot.com/-nM6wVrsBtIw/V6itl14uJtI/AAAAAAAABSc/M5lmXznMma4YD02HQ6vUv2moH-Xw_wO-ACLcB/s640/%25D0%259A%25D0%25BB%25D0%25B8%25D0%25BF%25D0%25B5%25D1%2580_Infografia.jpg" title="spacecraft by RSC Energia." width="640"></a></p><br>
<br>
<div>
<p>Kliper&nbsp;was a proposed partly&nbsp;<a title="Reusable launch system" href="https://en.wikipedia.org/wiki/Reusable_launch_system">reusable</a>&nbsp;manned&nbsp;<a title="Spacecraft" href="https://en.wikipedia.org/wiki/Spacecraft">spacecraft</a>&nbsp;by&nbsp;<a title="S.P. Korolev Rocket and Space Corporation Energia" href="https://en.wikipedia.org/wiki/S.P._Korolev_Rocket_and_Space_Corporation_Energia">RSC Energia</a>. Due to lack of funding from the ESA and RSA, the project has been indefinitely postponed as of 2006. <a href="https://en.wikipedia.org/wiki/Kliper" target="_blank" rel="nofollow">Source</a></p>
<p>Designed primarily to replace the&nbsp;<a title="Soyuz spacecraft" href="https://en.wikipedia.org/wiki/Soyuz_spacecraft">Soyuz spacecraft</a>, Kliper was proposed in two versions: as a pure&nbsp;<a title="Lifting body" href="https://en.wikipedia.org/wiki/Lifting_body">lifting body</a>&nbsp;design and as<a title="Spaceplane" href="https://en.wikipedia.org/wiki/Spaceplane">spaceplane</a>&nbsp;with small&nbsp;<a title="Wing" href="https://en.wikipedia.org/wiki/Wing">wings</a>. In either case, the craft would have been able to glide into the atmosphere at an angle that produces much less stress on the human occupants than the current Soyuz. Kliper was intended to be designed to be able to carry up to six people and to perform ferry services between Earth and the&nbsp;<a title="International Space Station" href="https://en.wikipedia.org/wiki/International_Space_Station">International Space Station</a>.</p>
<p><a href="https://2.bp.blogspot.com/-YBFudwoXK3Q/V6iuRRYYdOI/AAAAAAAABS0/C6Me6merYrY-ciSKCcGxOkMx-CabSkeQQCLcB/s1600/cliperan2.gif"><img alt="Kliper (ĞšĞ»Ğ¸Ğ¿ĞµÑ€, English: Clipper) was a proposed partly reusable manned spacecraft by RSC Energia." height="173" src="https://2.bp.blogspot.com/-YBFudwoXK3Q/V6iuRRYYdOI/AAAAAAAABS0/C6Me6merYrY-ciSKCcGxOkMx-CabSkeQQCLcB/s400/cliperan2.gif" title="Kliper (ĞšĞ»Ğ¸Ğ¿ĞµÑ€, English: Clipper) was a proposed partly reusable manned spacecraft by RSC Energia." width="400"></a></p>
<p><a href="https://3.bp.blogspot.com/-aalzuaqor_8/V6iuIEwP4xI/AAAAAAAABSg/7J4fzKwYq-8xHUTn7PBkoZmN3oygLP8LgCLcB/s1600/cliper05.gif"><img height="227" src="https://3.bp.blogspot.com/-aalzuaqor_8/V6iuIEwP4xI/AAAAAAAABSg/7J4fzKwYq-8xHUTn7PBkoZmN3oygLP8LgCLcB/s400/cliper05.gif" width="400"></a></p>
<p><a href="https://2.bp.blogspot.com/-2fm-a4DRCOg/V6iuIOu-FgI/AAAAAAAABSk/iBERytjejZAx0SR_pVzGyPovDNhCquSuACLcB/s1600/cliper07.gif"><img height="162" src="https://2.bp.blogspot.com/-2fm-a4DRCOg/V6iuIOu-FgI/AAAAAAAABSk/iBERytjejZAx0SR_pVzGyPovDNhCquSuACLcB/s640/cliper07.gif" width="640"></a></p>
<p><a href="https://3.bp.blogspot.com/-71vQS8q3AtQ/V6iuKHoZdoI/AAAAAAAABSo/8ssaVZSXKwAQimgqlWlfVn3nVePBVrxGwCLcB/s1600/cliper09.gif"><img alt="Kliper (ĞšĞ»Ğ¸Ğ¿ĞµÑ€, English: Clipper) was a proposed partly reusable manned spacecraft by RSC Energia." height="417" src="https://3.bp.blogspot.com/-71vQS8q3AtQ/V6iuKHoZdoI/AAAAAAAABSo/8ssaVZSXKwAQimgqlWlfVn3nVePBVrxGwCLcB/s640/cliper09.gif" title="Kliper RSC Energia." width="640"></a></p>
<p><a href="https://2.bp.blogspot.com/-4RaU28U7s8Y/V6iuOuvWlHI/AAAAAAAABSs/SepEgtWvjVEdsvrOGsAalTmO6W3R3MHVQCLcB/s1600/clipeani.gif"><img height="180" src="https://2.bp.blogspot.com/-4RaU28U7s8Y/V6iuOuvWlHI/AAAAAAAABSs/SepEgtWvjVEdsvrOGsAalTmO6W3R3MHVQCLcB/s400/clipeani.gif" width="400"></a></p><br>
<br>
</div><br>
</div><br>

</div></div>]]>
            </description>
            <link>https://www.xissufotoday.space/2018/04/declassified-spacecrafts-and-orbital.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26166204</guid>
            <pubDate>Wed, 17 Feb 2021 13:48:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why did I leave Google or, why did I stay so long?]]>
            </title>
            <description>
<![CDATA[
Score 789 | Comments 794 (<a href="https://news.ycombinator.com/item?id=26165809">thread link</a>) | @mrowland
<br/>
February 17, 2021 | https://paygo.media/p/25171 | <a href="https://web.archive.org/web/*/https://paygo.media/p/25171">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://paygo.media/p/25171</link>
            <guid isPermaLink="false">hacker-news-small-sites-26165809</guid>
            <pubDate>Wed, 17 Feb 2021 12:59:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How I started believing in Cycle Time over Estimation]]>
            </title>
            <description>
<![CDATA[
Score 50 | Comments 20 (<a href="https://news.ycombinator.com/item?id=26165779">thread link</a>) | @snorberhuis
<br/>
February 17, 2021 | https://www.norberhuis.nl/how-i-started-believing-in-cycle-time-over-estimation/ | <a href="https://web.archive.org/web/*/https://www.norberhuis.nl/how-i-started-believing-in-cycle-time-over-estimation/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
                <div>
                    <p>Cycle time is the time it takes to produce value. In software engineering, this is the time between a team starting to develop a feature and delivering this to the customer. Most backlog tools track this data and show it in control charts. You can use cycle time data to predict how long an individual item will take. You can find more explanation <a href="https://www.youtube.com/watch?v=QVBlnCTu9Ms">here</a>.</p><p>I keep telling the following story over and over when I see teams trying to do Estimation while everyone knows that Estimation is a charade. So I thought I could write it down and share it. I believe a story like this will explain the theory how Cycle Time works better than Estimation in a much more lively way.</p><h2 id="background"><strong>Background</strong></h2><p>At the time of the story, I worked with a team that had a hard time planning. I joined after a Lift &amp; Shift to AWS and the company asked me to help get into control. The platform consisted of multiple legacy systems, all working together in complex ways. Before the migration, the hosting of the platform was outsourced resulting in &nbsp;developers not spending any time on pipelines and maintainability in the decade before.</p><p>We had trouble supporting other development teams consuming our platform due to the many operational incidents. Most of the work on new features stalled. We could never estimate when we would finish new features because work could be disrupted by sudden firefighting in production. After some time and by applying engineering to increase reliability, we started to build features again and people began requesting expected dates again. We estimated those dates, but we did not make those dates time and time again due to unforeseen complexity.</p><figure><img src="https://www.norberhuis.nl/content/images/2021/01/andrew-gaines-s76S64umXpo-unsplash.jpg" alt="" srcset="https://www.norberhuis.nl/content/images/size/w600/2021/01/andrew-gaines-s76S64umXpo-unsplash.jpg 600w, https://www.norberhuis.nl/content/images/size/w1000/2021/01/andrew-gaines-s76S64umXpo-unsplash.jpg 1000w, https://www.norberhuis.nl/content/images/size/w1600/2021/01/andrew-gaines-s76S64umXpo-unsplash.jpg 1600w, https://www.norberhuis.nl/content/images/size/w2400/2021/01/andrew-gaines-s76S64umXpo-unsplash.jpg 2400w" sizes="(min-width: 720px) 720px"><figcaption>Fire Fighting can happen in DevOps teams.</figcaption></figure><p>That we had a major problem became apparent to me when the team started to talk about a new project. I asked what it was about, and the team said they were already refining it for over a year but never came to it. The company expected the team to deliver this big project that would be strategical to the future. But it was unthinkable that we would make any headway in this in the coming time.</p><p>So I proposed we push out this project and have a new team work on it. The new team started delivering after some ramp-up time, but this new team still needed some support from us for some small features on our platform.</p><h2 id="predicting-a-feature-toggle">Predicting a Feature Toggle</h2><p>This new team requested a significant feature in our platform's critical component. We already built this feature and were running it on Acceptance for months. It was turned off in production by a feature flag. Producing this feature would be a simple change in our Configuration as Code and push it to production.</p><p>At the end of a Friday afternoon, the project manager asked our team when we would deliver this feature. The weeks before, he already gave some estimations that we didn't make. So he was reluctant to provide an estimate. At the time, I was telling the team that we should stop with estimation and do more in-depth data-driven planning. So he asked me over: "Hey, what would you say?"</p><figure><img src="https://www.norberhuis.nl/content/images/2021/01/viva-luna-studios-y3qrbAgm7q8-unsplash.jpg" alt="" srcset="https://www.norberhuis.nl/content/images/size/w600/2021/01/viva-luna-studios-y3qrbAgm7q8-unsplash.jpg 600w, https://www.norberhuis.nl/content/images/size/w1000/2021/01/viva-luna-studios-y3qrbAgm7q8-unsplash.jpg 1000w, https://www.norberhuis.nl/content/images/size/w1600/2021/01/viva-luna-studios-y3qrbAgm7q8-unsplash.jpg 1600w, https://www.norberhuis.nl/content/images/size/w2400/2021/01/viva-luna-studios-y3qrbAgm7q8-unsplash.jpg 2400w" sizes="(min-width: 720px) 720px"><figcaption>Estimation can feel like drawing Tarot cards.</figcaption></figure><p>I answered: "Let's pull up the Control Chart to see our Cycle Time.". There we are leaned over the display: the project manager, the team lead, and me. I moved the mouse over the control chart. A pop-up showed our rolling average: '5d 6hr. I stood up straight and said: "Our average is five days 6 hours with a standard deviation of up to two weeks.".</p><p>I could tell confusion from the look of my team lead. How could I say it would take over five days for a change that we estimate to take 10 minutes! I didn't really have the answer, but I just said that it takes us that time to deliver on average. But somehow, it did feel right. We agreed that it would be the first thing picked up on Monday. Satisfied that we at least would work on it, the project manager accepted the answer. Probably this was his goal anyway, not expecting any real date from us seeing our previous performance.</p><h2 id="delivering-a-feature-toggle">Delivering a feature toggle</h2><p>On Monday, we started with the stand-up and discussed picking up this task. Another engineer proposed fixing a bug on another component first before turning on the flag. We would generate a lot of extra load by turning on the feature flag. We could not test this in our acceptance environment. This bug was related to load. The component would make it more likely to handle it by fixing it. We decided to do this because if that component fails, the whole platform will go down. So that is already a day delay.</p><p>At the end of the day, I looked at the board and didn't see the bug moving to the release column. I gathered the team and asked if the bug fix is ready to be deployed after hours. The bug fix was reviewed and tested, ready to be deployed. But as it is such a crucial component for the whole platform, someone reminded us that we had to ask the release manager.</p><p>So we asked the release manager if we could deploy this. He exploded: "No way we can deploy this! We need to request all teams to test this change! I have to notify management if we deploy any changes to that component! That takes a full day." So we planned to release it the next day.</p><p>Tuesday, we notified all teams of our change and asked them to test it. They tested it on Acceptance during the day. They found no problem, so the bug fix was ready to be released in the combined release. Little did we know that a feature by another team was also in the combined changeset. This feature would break on production. After the release, customers started calling, so the release engineer reverted the release. The other team had to fix this bug the next day.</p><p>On Wednesday, the other team saw that the release failed due to their new bug and started to fix it. That evening a new release was scheduled with their and our bug fix. So our bug fix was finally in production.</p><p>So our bug fix was finally in production on Thursday. We turned on the feature flag. The feature started to be available on production and it worked.</p><figure><img src="https://www.norberhuis.nl/content/images/2021/01/spacex--p-KCm6xB9I-unsplash.jpg" alt="" srcset="https://www.norberhuis.nl/content/images/size/w600/2021/01/spacex--p-KCm6xB9I-unsplash.jpg 600w, https://www.norberhuis.nl/content/images/size/w1000/2021/01/spacex--p-KCm6xB9I-unsplash.jpg 1000w, https://www.norberhuis.nl/content/images/size/w1600/2021/01/spacex--p-KCm6xB9I-unsplash.jpg 1600w, https://www.norberhuis.nl/content/images/size/w2400/2021/01/spacex--p-KCm6xB9I-unsplash.jpg 2400w" sizes="(min-width: 720px) 720px"></figure><h2 id="capturing-complexity-in-data">Capturing Complexity in Data</h2><p>Our estimation of 10 minutes resulted in a Cycle Time of 4 days and 5 hours. The combination of the level of practices, the complexity of systems, and collaboration between teams caused this delay and are present in any sociotechnical system. These can all be improved, but that is not the point of this story. That takes time and work, while some features need to be delivered in the meantime. As humans, it is impossible to consider all the potential complexity. That is why we cannot estimate correctly. But Cycle Time data can and does.</p><p>We did not consider a legacy system with bugs and scaling problems. But we have run into this before while delivering other tasks. That complexity is captured in the data.</p><p>We did not consider a combined release process with a Release Manager. But previous releases failed before due to bugs introduced by other teams. But the tracking tools do measure these delays in previous task completion times.</p><p>This story is how I turned into a firm believer in using Cycle Time as a planning tool. Afterward, I have seen the same story play out time and time again but due to different complexities: the maturity of third parties, CISO, and so much more. I now never give any estimations anymore. Not using estimation require training. But planning is so important that using a charade like estimation is harmful.</p><p>If you liked this story, I would recommend to follow me on twitter: <a href="https://twitter.com/SNorberhuis">@snorberhuis</a>. I regularly tweet about Software Development. If you need any help to get into control in Agile or DevOps, feel free to contact me!</p><p>A major thank you goes out to <a href="https://twitter.com/pogrebnyak">Stanislav Pogrebnyak</a> to introduce me to <a href="https://www.youtube.com/watch?v=QVBlnCTu9Ms">#NoEstimates</a>. All photos are from <a href="https://unsplash.com/">unsplash</a>.</p>
                </div>
            </section></div>]]>
            </description>
            <link>https://www.norberhuis.nl/how-i-started-believing-in-cycle-time-over-estimation/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26165779</guid>
            <pubDate>Wed, 17 Feb 2021 12:53:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Python resources for everybody]]>
            </title>
            <description>
<![CDATA[
Score 17 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26165316">thread link</a>) | @asicsp
<br/>
February 17, 2021 | https://learnbyexample.github.io/py_resources/ | <a href="https://web.archive.org/web/*/https://learnbyexample.github.io/py_resources/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><nav id="sidebar" aria-label="Table of contents"></nav><div id="page-wrapper"><div class="page"><div id="content"><main><h2><a href="#about" id="about">About</a></h2><p>This is a collection of Python <strong>learning</strong> resources. Many of the resources, especially the beginner ones, are free.</p><p><img src="https://learnbyexample.github.io/py_resources/images/info.svg" alt="info"> For a curated list of frameworks, libraries, software, etc, see <a href="https://github.com/vinta/awesome-python">awesome-python</a></p><h2><a href="#img-srcimageswarningsvg-altwarning--disclaimer-and-disclosure" id="img-srcimageswarningsvg-altwarning--disclaimer-and-disclosure"><img src="https://learnbyexample.github.io/py_resources/images/warning.svg" alt="warning"> Disclaimer and Disclosure</a></h2><p>I don't have personal experience with majority of the resources mentioned here. I have collected them from various recommendation threads on Reddit, Hacker News, Stackexchange sites, Twitter, GitHub, etc.</p><p><a href="https://learnbyexample.github.io/py_regular_expressions/">Python re(gex)?</a> and <a href="https://learnbyexample.github.io/100_page_python_intro/">100 Page Python Intro</a> are my own books.</p><h2><a href="#table-of-contents" id="table-of-contents">Table of Contents</a></h2><ul><li><a href="https://learnbyexample.github.io/py_resources/beginners.html">Beginner resources</a> <ul><li><a href="https://learnbyexample.github.io/py_resources/beginners.html#new-to-programming">New to programming</a></li><li><a href="https://learnbyexample.github.io/py_resources/beginners.html#new-to-python">New to Python</a></li><li><a href="https://learnbyexample.github.io/py_resources/beginners.html#courses-with-certificates">Courses with certificates</a></li><li><a href="https://learnbyexample.github.io/py_resources/beginners.html#exercises">Exercises</a></li><li><a href="https://learnbyexample.github.io/py_resources/beginners.html#projects">Projects</a></li><li><a href="https://learnbyexample.github.io/py_resources/beginners.html#debugging">Debugging</a></li><li><a href="https://learnbyexample.github.io/py_resources/beginners.html#tools-ide-and-text-editors">Tools, IDE and Text Editors</a></li><li><a href="https://learnbyexample.github.io/py_resources/beginners.html#cheatsheets">Cheatsheets</a></li><li><a href="https://learnbyexample.github.io/py_resources/beginners.html#documentation-and-getting-help">Documentation and getting help</a></li></ul></li><li><a href="https://learnbyexample.github.io/py_resources/specific.html">Specific features</a> <ul><li><a href="https://learnbyexample.github.io/py_resources/specific.html#async-and-concurrency">Async and concurrency</a></li><li><a href="https://learnbyexample.github.io/py_resources/specific.html#command-line-applications">Command line applications</a></li><li><a href="https://learnbyexample.github.io/py_resources/specific.html#context-managers">Context managers</a></li><li><a href="https://learnbyexample.github.io/py_resources/specific.html#decorators-and-closures">Decorators and closures</a></li><li><a href="https://learnbyexample.github.io/py_resources/specific.html#iterables-generators-yield-itertools">Iterables, Generators, Yield, Itertools</a></li><li><a href="https://learnbyexample.github.io/py_resources/specific.html#lambda">Lambda</a></li><li><a href="https://learnbyexample.github.io/py_resources/specific.html#lists-and-comprehensions">Lists and comprehensions</a></li><li><a href="https://learnbyexample.github.io/py_resources/specific.html#memoization">Memoization</a></li><li><a href="https://learnbyexample.github.io/py_resources/specific.html#os-interaction">OS interaction</a></li><li><a href="https://learnbyexample.github.io/py_resources/specific.html#profiling-code-and-speeding-up-python">Profiling code and speeding up Python</a></li><li><a href="https://learnbyexample.github.io/py_resources/specific.html#regular-expressions">Regular Expressions</a></li><li><a href="https://learnbyexample.github.io/py_resources/specific.html#virtual-environments-and-packaging">Virtual Environments and Packaging</a></li></ul></li><li><a href="https://learnbyexample.github.io/py_resources/intermediate.html">Intermediate to Advanced resources</a> <ul><li><a href="https://learnbyexample.github.io/py_resources/intermediate.html#intermediate">Intermediate</a></li><li><a href="https://learnbyexample.github.io/py_resources/intermediate.html#testing">Testing</a></li><li><a href="https://learnbyexample.github.io/py_resources/intermediate.html#algorithms-and-data-structures">Algorithms and data structures</a></li><li><a href="https://learnbyexample.github.io/py_resources/intermediate.html#design-patterns">Design patterns</a></li><li><a href="https://learnbyexample.github.io/py_resources/intermediate.html#advanced">Advanced</a></li></ul></li><li><a href="https://learnbyexample.github.io/py_resources/domain.html">Domain specific resources</a> <ul><li><a href="https://learnbyexample.github.io/py_resources/domain.html#bioinformatics">Bioinformatics</a></li><li><a href="https://learnbyexample.github.io/py_resources/domain.html#data-science">Data Science</a></li><li><a href="https://learnbyexample.github.io/py_resources/domain.html#gui-and-games">GUI and Games</a></li><li><a href="https://learnbyexample.github.io/py_resources/domain.html#machine-learning">Machine Learning</a></li><li><a href="https://learnbyexample.github.io/py_resources/domain.html#robotics-and-computer-vision">Robotics and Computer Vision</a></li><li><a href="https://learnbyexample.github.io/py_resources/domain.html#scientific-computing">Scientific computing</a></li><li><a href="https://learnbyexample.github.io/py_resources/domain.html#web-development">Web development</a></li></ul></li></ul><h2><a href="#acknowledgements" id="acknowledgements">Acknowledgements</a></h2><ul><li><a href="https://github.com/rust-lang/mdBook">mdBook</a></li><li><a href="https://github.com/JorelAli/mdBook-pagetoc">mdBook-pagetoc</a></li><li><a href="https://github.com/wilsonzlin/minify-html">minify-html</a></li><li><a href="https://commons.wikimedia.org/wiki/File:Warning_icon.svg">Warning</a> and <a href="https://commons.wikimedia.org/wiki/File:Info_icon_002.svg">Info</a> icons by <a href="https://commons.wikimedia.org/wiki/User:Amada44">Amada44</a> under public domain</li><li><a href="https://inkscape.org/">Inkscape</a></li><li><a href="https://github.com/RazrFalcon/svgcleaner">svgcleaner</a></li></ul><h2><a href="#license" id="license">License</a></h2><p>This work is licensed under a <a href="https://github.com/learnbyexample/py_resources/blob/master/LICENSE">Creative Commons Zero v1.0 Universal License</a></p></main><nav aria-label="Page navigation"><a rel="next" href="https://learnbyexample.github.io/py_resources/beginners.html" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right"> <i></i> </a></nav></div></div><nav aria-label="Page navigation"><a rel="next" href="https://learnbyexample.github.io/py_resources/beginners.html" title="Next chapter" aria-label="Next chapter" aria-keyshortcuts="Right"> <i></i> </a></nav></div></div>]]>
            </description>
            <link>https://learnbyexample.github.io/py_resources/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26165316</guid>
            <pubDate>Wed, 17 Feb 2021 11:42:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Designing a RISC-V CPU, Part 1: Learning hardware design as a software engineer]]>
            </title>
            <description>
<![CDATA[
Score 35 | Comments 3 (<a href="https://news.ycombinator.com/item?id=26164574">thread link</a>) | @lochsh
<br/>
February 17, 2021 | https://mcla.ug/blog/risc-v-cpu-part-1.html | <a href="https://web.archive.org/web/*/https://mcla.ug/blog/risc-v-cpu-part-1.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<div>
	
	<p><span>Tue 16 February 2021</span></p><p>I have no experience in digital logic design. That is, I didn't until I
recently decided that I would like to try designing my own CPU and running it
on an FPGA! If you too are a software engineer with a vague interest in
hardware design, I hope this series of posts about what I've learnt will be
helpful and interesting. In this first installment, I hope to answer these
questions:</p>
<ul>
<li>
<p>What is digital logic design?</p>
</li>
<li>
<p>How do I get started, and what tools might I use?</p>
</li>
</ul>
<p>In future installments, I will go into more detail about my CPU design and the
RISC-V architecture, as well as hopefully answering these questions:</p>
<ul>
<li>
<p>What about digital logic design is fundamentally different from software
  design?</p>
</li>
<li>
<p>What about digital logic design is similar to software design?</p>
</li>
</ul>
<p>You can see the code for my CPU at the time of writing
<a href="https://github.com/lochsh/riscy-boi/tree/47e94dc6e9665f73c871add002c34d1516fd5106">here</a>
or an up to date version <a href="https://github.com/lochsh/riscy-boi">here</a>.</p>
<h2>What is digital logic design?</h2>
<p>Digital logic design is designing logic circuits that operate on binary values.
The elementary components are logic gates: an AND gate, for example, has two
inputs and one output. The output is 1 iff<sup id="fnref:1"><a href="#fn:1">1</a></sup> both inputs are 1.</p>
<p>Typically, we design synchronous circuits which use flip-flops to store state,
and thereby synchronise the operation of the circuit to a common clock.
Flip-flops are composed of logic gates.</p>
<p>Analogue circuit design is concerned with the electronic components that make
up logic gates, like transistors and diodes. This level of abstraction is often
needed for applications dealing directly with signals derived from analogue
sensors, like radio receivers. When designing a CPU, this level of abstraction
would not be feasible: modern CPUs can have billions of transistors!</p>
<p>Instead, we use tools that can translate our digital logic design into
different useful formats: the configuration of an FPGA (see below); a
simulation; silicon layout.</p>
<h2>What is an FPGA and why are they used?</h2>
<p>We noted above that the same digital logic design tools can be used whether we
are creating a custom ASIC to be made into silicon, or configuring an FPGA. A
Field-Programmable Gate Array is an integrated circuit containing an array of
programmable logic blocks. You could imagine it is as a big array of logic
gates that can be connected together in various ways.</p>
<p>Making a custom chip generally costs millions, and of course once your chip is
manufactured it cannot be changed. Thus, generally FPGAs are used when:</p>
<ul>
<li>
<p>You cannot afford to create a custom ASIC due to lack of capital (e.g. if
  you're just some hacker like me and not ARM or Intel)</p>
</li>
<li>
<p>You cannot afford to create a custom ASIC because your volume is too low to
  make it worth the high one-off costs (e.g. if you are making a small quantity
  of MRI machines with custom data acquisition hardware)</p>
</li>
<li>
<p>You need the flexibility</p>
</li>
</ul>
<p>The downsides? FPGAs have a much higher per-chip cost, and they are generally
much slower as a consequence of being able to connect logic blocks together in
very flexible ways. In contrast, a custom design can be reduced to the minimum
number of transistors, with no concern for flexibility.</p>
<p>I think it's helpful context to compare the custom ASIC design process against
that of an FPGA design:</p>
<ul>
<li>
<p><span>Logic design</span>: just like we'd do for an FPGA, the logic design of an ASIC is
  done in a hardware description language.</p>
</li>
<li>
<p><span>Verification</span>: FPGA designs may well be verified, but you might expect the
  process for an ASIC design to be more rigorous â€“ after all, the design
  can't be changed once manufactured! Often verification will involve formally
  verifying<sup id="fnref:2"><a href="#fn:2">2</a></sup> parts of the design.</p>
</li>
<li>
<p><span>Synthesis</span>: This creates a <em>netlist</em>: a list of logic blocks and their
  connections. The connections are called <em>nets</em>, and the blocks are called
  <em>cells</em>. For both FPGAs and ASICs, the cells are vendor-specific.</p>
</li>
<li>
<p><span>Placement and routing</span> (P&amp;R): for an FPGA, this involves mapping the logic
  blocks described in the netlist to actual blocks in the FPGA. The resulting
  binary is often called a <em>bitstream</em>.  For an ASIC, this involves deciding
  where to place the cells on the silicon, and how to connect them up. Both
  applications generally use automated optimisation tools for this.</p>
</li>
</ul>
<h2>What tools do I need?</h2>
<h3>A hardware description language: I am using <a href="https://github.com/nmigen/nmigen">nMigen</a><sup id="fnref:3"><a href="#fn:3">3</a></sup></h3>
<p>You may have heard of Verilog or VHDL: both popular hardware description
languages (HDLs). I use "popular" here to mean widely used, not widely loved.</p>
<p>I won't pretend to know much about these tools: I only know that smarter people
than me with vast logic design experience have a lot of hate for them.
Due to the problems with Verilog and other similar tools, there have been
various attempts at making more useful and friendlier alternatives.  nMigen is
one such project, which creates a domain-specific language in Python. In their
own words:</p>
<blockquote>
<p>Despite being faster than schematics entry, hardware design with Verilog and
VHDL remains tedious and inefficient for several reasons. The event-driven
model introduces issues and manual coding that are unnecessary for
synchronous circuits, which represent the lion's share of today's logic
designs. Counterintuitive arithmetic rules result in steeper learning curves
and provide a fertile ground for subtle bugs in designs. Finally, support for
procedural generation of logic (metaprogramming) through "generate"
statements is very limited and restricts the ways code can be made generic,
reused and organized.</p>
<p>To address those issues, we have developed the nMigen FHDL, a library that
replaces the event-driven paradigm with the notions of combinatorial and
synchronous statements, has arithmetic rules that make integers always behave
like mathematical integers, and most importantly allows the design's logic to
be constructed by a Python program. This last point enables hardware
designers to take advantage of the richness of the Python languageâ€”object
oriented programming, function parameters, generators, operator overloading,
libraries, etc.â€”to build well organized, reusable and elegant designs.</p>
</blockquote>
<p>If, like me, you've never used Verilog, then not all of this will have more
than abstract meaning to you. But it certainly sounds promising,
and I can attest that it has been very straightforward to get started with
logic design without the reportedly large barrier of grappling with Verilog. I
would recommend it, particularly if you are already familiar with Python!</p>
<p>The only downside I can think of is that nMigen is still in development, and
in particular the documentation is not complete. There is a helpful community
at #nmigen on <a href="https://mcla.ug/blog/chat.freenode.net">chat.freenode.net</a>.</p>
<h3>A wave viewer for inspecting simulations: I am using <a href="http://gtkwave.sourceforge.net/">GTKWave</a></h3>
<p>nMigen provides simulation tooling: I use it in my tests, written using
<code>pytest</code>. I record the signals during these tests and view them in a wave
viewer to help debug.</p>
<p><img alt="gtkwave" src="https://mcla.ug/blog/images/gtkwave.png" title="A screenshot of GTKWave"></p>
<h3>Optional: An FPGA dev board. I am using a myStorm BlackIce II</h3>
<p>You don't need an FPGA dev board to create your own CPU. You could do
everything in simulation! The fun of having a board to work with, for me, is
being able to flash LEDs and see my design in action.</p>
<p>Of course, if you were creating something more useful than my very basic CPU,
then you would probably want some hardware to run it on, and this would be less
"optional"!</p>
<h2>Getting started with nMigen</h2>
<p>Rather than immediately trying to design a CPU, I started by making an
Arithmetic Logic Unit (ALU) in nMigen. The ALU is a key piece of any CPU design
that I have seen: it performs arithmetic operations.</p>
<p>Why start with this? I knew I would need an ALU for my CPU; I knew I could make
a simple one; I knew that the feeling of making something is an important
motivator when starting a new project!</p>
<p>My design looked something like this:</p>

<div>
<pre id="vimCodeElement"><span id="L1"> 1 </span><span>"""</span><span>Arithmetic Logic Unit</span><span>"""</span>
<span id="L2"> 2 </span><span>import</span> enum
<span id="L3"> 3 </span>
<span id="L4"> 4 </span><span>import</span> nmigen <span>as</span> nm
<span id="L5"> 5 </span>
<span id="L6"> 6 </span>
<span id="L7"> 7 </span><span>class</span> <span>ALUOp</span><span>(</span>enum<span>.</span>IntEnum<span>)</span><span>:</span>
<span id="L8"> 8 </span>    <span>"""</span><span>Operations for the ALU</span><span>"""</span>
<span id="L9"> 9 </span>    ADD <span>=</span> <span>0</span>
<span id="L10">10 </span>    SUB <span>=</span> <span>1</span>
<span id="L11">11 </span>
<span id="L12">12 </span>
<span id="L13">13 </span><span>class</span> <span>ALU</span><span>(</span>nm<span>.</span>Elaboratable<span>)</span><span>:</span>
<span id="L14">14 </span>    <span>"""</span>
<span id="L15">15 </span><span>    Arithmetic Logic Unit</span>
<span id="L16">16 </span>
<span id="L17">17 </span><span>    * op (in): the opcode</span>
<span id="L18">18 </span><span>    * a (in): the first operand</span>
<span id="L19">19 </span><span>    * b (in): the second operand</span>
<span id="L20">20 </span>
<span id="L21">21 </span><span>    * o (out): the output</span>
<span id="L22">22 </span><span>    </span><span>"""</span>
<span id="L23">23 </span>
<span id="L24">24 </span>    <span>def</span> <span>__init__</span><span>(</span>self<span>,</span> width<span>)</span><span>:</span>
<span id="L25">25 </span>        <span>"""</span>
<span id="L26">26 </span><span>        Initialiser</span>
<span id="L27">27 </span>
<span id="L28">28 </span><span>        Args:</span>
<span id="L29">29 </span><span>            width (int): data width</span>
<span id="L30">30 </span><span>        </span><span>"""</span>
<span id="L31">31 </span>        self<span>.</span>op <span>=</span> nm<span>.</span>Signal<span>()</span>
<span id="L32">32 </span>        self<span>.</span>a <span>=</span> nm<span>.</span>Signal<span>(</span>width<span>)</span>
<span id="L33">33 </span>        self<span>.</span>b <span>=</span> nm<span>.</span>Signal<span>(</span>width<span>)</span>
<span id="L34">34 </span>        self<span>.</span>o <span>=</span> nm<span>.</span>Signal<span>(</span>width<span>)</span>
<span id="L35">35 </span>
<span id="L36">36 </span>    <span>def</span> <span>elaborate</span><span>(</span>self<span>,</span> _<span>)</span><span>:</span>
<span id="L37">37 </span>        m <span>=</span> nm<span>.</span>Module<span>()</span>
<span id="L38">38 </span>
<span id="L39">39 </span>        <span>with</span> m<span>.</span>Switch<span>(</span>self<span>.</span>op<span>)</span><span>:</span>
<span id="L40">40 </span>            <span>with</span> m<span>.</span>Case<span>(</span>ALUOp<span>.</span>ADD<span>)</span><span>:</span>
<span id="L41">41 </span>                m<span>.</span>d<span>.</span>comb <span>+=</span> self<span>.</span>o<span>.</span>eq<span>(</span>self<span>.</span>a <span>+</span> self<span>.</span>b<span>)</span>
<span id="L42">42 </span>            <span>with</span> m<span>.</span>Case<span>(</span>ALUOp<span>.</span>SUB<span>)</span><span>:</span>
<span id="L43">43 </span>                m<span>.</span>d<span>.</span>comb <span>+=</span> self<span>.</span>o<span>.</span>eq<span>(</span>self<span>.</span>a <span>-</span> self<span>.</span>b<span>)</span>
<span id="L44">44 </span>        <span>return</span> m
</pre>
</div>

<p>As you can see, we've created a lot of nMigen <code>Signal</code> instances to represent
well...the signals that define the interface to our ALU! But what is this
<code>elaborate</code> method? My understanding is that "elaboration" is the name for the
first step in synthesising the netlist (see above). The idea in the nMigen code
above is that we've created some <em>elaboratable</em> structure (by inheriting from
<code>nm.Elaboratable</code>), i.e. something that describes digital logic we want to
synthesise. The <code>elaborate</code> method describes that digital logic. It has to
return an nMigen <code>Module</code>.</p>
<p>Let's have a closer look at the contents of the <code>elaborate</code> method. The
<code>Switch</code> will create some kind of decision logic in the synthesised design.
But what is <code>m.d.comb</code>? nMigen has the concept of synchronous (<code>m.d.sync</code>)
and combinatorial<sup id="fnref:4"><a href="#fn:4">4</a></sup> (<code>m.d.comb</code>) control domains. From the nMigen
<a href="https://nmigen.info/nmigen/latest/lang.html#lang-domains">docs</a>:</p>
<blockquote>
<p>A control domain is a named group of signals that change their value in
identical conditions.</p>
<p>All designs have a single predefined <em>combinatorial domain</em>, containing all
signals that change immediately when any value used to compute them changes.
The name comb is reserved for the combinatorial domain.</p>
<p>A design can also have any amount of user-defined <em>synchronous domains</em>, also
called clock domains, containing signals that change when a specific edge
occurs on the domainâ€™s â€¦</p></blockquote></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://mcla.ug/blog/risc-v-cpu-part-1.html">https://mcla.ug/blog/risc-v-cpu-part-1.html</a></em></p>]]>
            </description>
            <link>https://mcla.ug/blog/risc-v-cpu-part-1.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26164574</guid>
            <pubDate>Wed, 17 Feb 2021 09:45:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Dear Email Industry, We've Got a GDPR Problem]]>
            </title>
            <description>
<![CDATA[
Score 58 | Comments 88 (<a href="https://news.ycombinator.com/item?id=26164553">thread link</a>) | @iamacyborg
<br/>
February 17, 2021 | https://www.jacquescorbytuech.com/writing/gdpr-email-tracking | <a href="https://web.archive.org/web/*/https://www.jacquescorbytuech.com/writing/gdpr-email-tracking">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section id="content">
<article>
<header>

</header>
<p><small><time datetime="2019-06-10T13:37:00+01:00">
      Mon 10 June 2019
    </time></small>
</p>
<div>
<p><strong>The email industry's got a GDPR problem.</strong></p>
<p>Some of you reading this might have seen me talk about this problem in the very excellent <a href="https://email.geeks.chat/">Email Geeks Community</a>, but if you're new, let me break it down for you.</p>
<p>Last year, the GDPR came into effect, which put in place some rigorous laws around data processing and how personally identifiable information (PII) has to be handled. This stressed out a lot of email marketers, who quite rightly realised that the new regulations would have a significant effect on their ability to acquire and market to customers via their email address (which counts as PII). </p>
<p>Now if you're reading this, you're probably familiar with how that's gone, so I won't bore you with the details.</p>

<h2>So What's the Problem?</h2>
<p>The overwhelming majority of commercial email sent today contains tracking pixels and tracking links, these are used to uniquely identify individuals so that opens and clicks can be correctly attributed to them. This isn't strictly a problem, the GDPR does not ban processing of personal data for tracking purposes, however email tracking frequently fails to meet a number of criteria necessary to be legal under the GDPR.</p>
<p><strong>We're not collection consent to track user behaviour</strong> - That means we're probably relying on good old Legitimate Interest and that's frought with a number of risks.</p>
<p>Firstly, most brands aren't disclosing in their privacy policies or at moment of signup that they're tracking user behaviour in marketing emails. That's a problem. <a href="https://gdpr-info.eu/art-5-gdpr/">Article 5</a> clearly states that to be legally compliant, personal data should be processed in the following manner:</p>
<blockquote>
<p>processed lawfully, fairly and in a transparent manner in relation to the data subject (â€˜lawfulness, fairness and transparencyâ€™);</p>
</blockquote>
<p>This is further expanded upon in <a href="https://gdpr-info.eu/recitals/no-39/">Recital 39</a>:</p>
<blockquote>
<p>It should be transparent to natural persons that personal data concerning them are collected, used, consulted or otherwise processed and to what extent the personal data are or will be processed.</p>
</blockquote>
<p>Failure to adequately disclose email tracking within your brand's privacy policy is a clear breach of the regulation.</p>
<p>Secondly, when Legitimate Interest is used as the legal basis for processing of personal data, the data subject has the <a href="https://gdpr-info.eu/art-21-gdpr/">Right to Object</a>.</p>
<blockquote>
<p>The data subject shall have the right to object, on grounds relating to his or her particular situation, at any time to processing of personal data concerning him or her which is based on point (e) or (f) of Article 6(1), including profiling based on those provisions.</p>
</blockquote>
<p>This means that when processing data under a Legitimate Interest basis, the data subject has the right to object to your tracking, this brings us round to our second problem.</p>

<h2>Email Marketing Platforms Are Not GDPR Compliantâ€ </h2>
<p>Take a look at your ESP, does it allow you to, on a per individual basis, opt-out of email tracking?</p>
<p>If the answer to that is no, and in most cases the answer will be no, you're in breach of the GDPR as soon as a customer objects to your data processing. That is assuming you disclose the tracking in your privacy policy, if you don't you're already in breach.</p>
<p>This becomes even more of a legal quagmire as soon as we start looking at tracking in emails sent on a legal basis other than Consent or Legitimate Interest.</p>
<p>So what can you do about it?</p>
<p><strong>Complain to your ESP!</strong> Complain frequently and loudly. Make them do something about it. Ultimately the GDPR is here to stay, and ESP's must put in the work to allow marketers to comply with the law.</p>

<h2>Where Does That Leave Email Marketing?</h2>
<p>Email marketing isn't going anywhere, email remains one of the most valuable channels for reaching your customers and losing the ability to track behavioural data isn't going to change that fundamental fact. What is going to change is our ability to act upon vast swathes of personal data.</p>
<p>You know what?</p>
<p>That's not a problem, personal data is not a crucial part of gauging the success of a campaign and anonymised data is more than good enough for us to achieve our objectives.</p>
<p>I'll leave you with a parting note; as marketers, we've become entirely too comfortable handling vast swathes of personal data, it's time we get used to a world where that option isn't always going to be available to us. </p>
<hr>
<p>Usual caveats apply. I am not a lawyer.</p>
<p>â€  <em>Yes, I know a small minority are, but they're a small minority. This might be one of the very few instances in which I'd recommend SFMC</em></p>
<p>Cheers,</p>
<p><img alt="signature" src="https://www.jacquescorbytuech.com/images/jacques.png">
</p></div>
<div>
<h4>Subscribe for updates</h4>

<p>Updates, whenever I've got something valuable to say.</p>
</div>
</article>
</section></div>]]>
            </description>
            <link>https://www.jacquescorbytuech.com/writing/gdpr-email-tracking</link>
            <guid isPermaLink="false">hacker-news-small-sites-26164553</guid>
            <pubDate>Wed, 17 Feb 2021 09:42:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Easy Forth: Learn forth with REPL in the browser]]>
            </title>
            <description>
<![CDATA[
Score 100 | Comments 30 (<a href="https://news.ycombinator.com/item?id=26164275">thread link</a>) | @guerrilla
<br/>
February 17, 2021 | https://skilldrick.github.io/easyforth | <a href="https://web.archive.org/web/*/https://skilldrick.github.io/easyforth">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>

        

<h2 id="introduction">Introduction</h2>

<p>This small ebook is here to teach you a programming language called Forth. Forth is a
language unlike most others. Itâ€™s not functional <em>or</em> object oriented, it doesnâ€™t
have type-checking, and it basically has zero syntax. It was written in the 70s, but
is still used today for
<a href="http://www.forth.com/resources/apps/more-applications.html">certain applications</a>.</p>

<p>Why would you want to learn such an odd language? Every new programming
language you learn helps you think about problems in new ways. Forth is very
easy to learn, but it requires you to think in a different way than youâ€™re used
to. That makes it a perfect language to broaden your coding horizons.</p>

<p>This book includes a simple implementation of Forth I wrote in JavaScript. Itâ€™s by
no means perfect, and is missing a lot of the functionality youâ€™d expect in a real
Forth system. Itâ€™s just here to give you an easy way to try out the examples. (If
youâ€™re a Forth expert, please
<a href="https://github.com/skilldrick/easyforth">contribute here</a> and make it better!)</p>

<p>Iâ€™m going to assume that you know at least one other programming language, and have
a basic idea of how stacks work as a data structure.</p>

<h2 id="adding-some-numbers">Adding Some Numbers</h2>

<p>The thing that separates Forth from most other languages is its use of the
stack. In Forth, everything revolves around the stack. Any time you type a
number, it gets pushed onto the stack. If you want to add two numbers together,
typing <code>+</code> takes the top two numbers off the stack, adds them, and puts
the result back on the stack.</p>

<p>Letâ€™s take a look at an example. Type (donâ€™t copy-paste) the following into the
interpreter, typing <code>Enter</code> after each line.</p>

<pre><code>1
2
3
</code></pre>



<p>Every time you type a line followed by the <code>Enter</code> key, the Forth interpreter
executes that line, and appends the string <code>ok</code> to let you know there were no
errors. You should also notice that as you execute each line, the area at the
top fills up with numbers. That area is our visualization of the stack. It
should look like this:</p>

<p>1 2 3 &lt;- Top</p>

<p>Now, into the same interpreter, type a single <code>+</code> followed by the <code>Enter</code> key. The top two
elements on the stack, <code>2</code> and <code>3</code>, have been replaced by <code>5</code>.</p>

<p>1 5 &lt;- Top</p>

<p>At this point, your editor window should look like this:</p>

<p>1  <span>ok</span>
2  <span>ok</span>
3  <span>ok</span>
+  <span>ok</span>
</p>

<p>Type <code>+</code> again and press <code>Enter</code>, and the top two elements will be replaced by 6. If
you type <code>+</code> one more time, Forth will try to pop the top two elements off the
stack, even though thereâ€™s only <em>one</em> element on the stack! This results in a
<code>Stack underflow</code> error:</p>

<p>1  <span>ok</span>
2  <span>ok</span>
3  <span>ok</span>
+  <span>ok</span>
+  <span>ok</span>
+  <span>Stack underflow</span>
</p>

<p>Forth doesnâ€™t force you to type every token as a separate line. Type the
following into the next editor, followed by the <code>Enter</code> key:</p>

<pre><code>123 456 +
</code></pre>



<p>The stack should now look like this:</p>

<p>579 &lt;- Top</p>

<p>This style, where the operator appears after the operands, is known as
<a href="https://en.wikipedia.org/wiki/Reverse_Polish_notation">Reverse-Polish
notation</a>. Letâ€™s try
something a bit more complicated, and calculate <code>10 * (5 + 2)</code>. Type the
following into the interpreter:</p>

<pre><code>5 2 + 10 *
</code></pre>



<p>One of the nice things about Forth is that the order of operations is
completely based on their order in the program. For example, when executing <code>5
2 + 10 *</code>, the interpreter pushes 5 to the stack, then 2, then adds them and
pushes the resulting 7, then pushes 10 to the stack, then multiplies 7 and 10.
Because of this, thereâ€™s no need for parentheses to group operators with lower
precedence.</p>

<h3 id="stack-effects">Stack Effects</h3>

<p>Most Forth words affect the stack in some way. Some take values off the stack,
some leave new values on the stack, and some do a mixture of both. These â€œstack
effectsâ€ are commonly represented using comments of the form <code>( before -- after
)</code>. For example, <code>+</code> is <code>( n1 n2 -- sum )</code> - <code>n1</code> and <code>n2</code> are the top two numbers
on the stack, and <code>sum</code> is the value left on the stack.</p>

<h2 id="defining-words">Defining Words</h2>

<p>The syntax of Forth is extremely straightforward. Forth code is interpreted as
a series of space-delimited words. Almost all non-whitespace characters are valid
in words. When the Forth interpreter reads a word, it checks to see if a
definition exists in an internal structure known as the Dictionary. If it is
found, that definition is executed. Otherwise, the word is assumed to be a
number, and it is pushed onto the stack. If the word cannot be converted to a
number, an error occurs.</p>

<p>You can try that out yourself below. Type <code>foo</code> (an unrecognized word)
and press enter.</p>



<p>You should see something like this:</p>

<p>foo  <span>foo ?</span></p>

<p><code>foo ?</code> means that Forth was unable to find a definition for <code>foo</code>, and it
wasnâ€™t a valid number.</p>

<p>We can create our own definition of <code>foo</code> using two special words called <code>:</code>
(colon) and <code>;</code> (semicolon).  <code>:</code> is our way of telling Forth we want to create
a definition. The first word after the <code>:</code> becomes the definition name, and the
rest of the words (until the <code>;</code>) make up the body of the definition. Itâ€™s
conventional to include two spaces between the name and the body of the
definition. Try entering the following:</p>

<pre><code>: foo  100 + ;
1000 foo
foo foo foo
</code></pre>

<p><strong>Warning:</strong> A common mistake is to miss out the space before the <code>;</code> word. Because Forth
words are space delimited and can contain most characters, <code>+;</code> is a perfectly
valid word and is not parsed as two separate words.</p>



<p>As youâ€™ve hopefully figured out, our <code>foo</code> word simply adds 100 to the value on
top of the stack. Itâ€™s not very interesting, but it should give you an idea of
how simple definitions work.</p>

<h2 id="stack-manipulation">Stack Manipulation</h2>

<p>Now we can start taking a look at some of Forthâ€™s predefined words. First,
letâ€™s look at some words for manipulating the elements at the top of the stack.</p>

<h3 id="dup--n----n-n-"><code>dup ( n -- n n )</code></h3>

<p><code>dup</code> is short for â€œduplicateâ€ â€“ it duplicates the top element of the stack. For example,
try this out:</p>

<pre><code>1 2 3 dup
</code></pre>



<p>You should end up with the following stack:</p>

<p>1 2 3 3 &lt;- Top</p>

<h3 id="drop--n----"><code>drop ( n -- )</code></h3>

<p><code>drop</code> simply drops the top element of the stack. Running:</p>

<pre><code>1 2 3 drop
</code></pre>

<p>gives you a stack of:</p>

<p>1 2 &lt;- Top</p>



<h3 id="swap--n1-n2----n2-n1-"><code>swap ( n1 n2 -- n2 n1 )</code></h3>

<p><code>swap</code>, as you may have guessed, swaps the top two elements of the stack. For example:</p>

<pre><code>1 2 3 4 swap
</code></pre>

<p>will give you:</p>

<p>1 2 4 3 &lt;- Top</p>



<h3 id="over--n1-n2----n1-n2-n1-"><code>over ( n1 n2 -- n1 n2 n1 )</code></h3>

<p><code>over</code> is a bit less obvious: it takes the second element from the top of the
stack and duplicates it to the top of the stack. Running this:</p>

<pre><code>1 2 3 over
</code></pre>

<p>will result in this:</p>

<p>1 2 3 2 &lt;- Top</p>



<h3 id="rot--n1-n2-n3----n2-n3-n1-"><code>rot ( n1 n2 n3 -- n2 n3 n1 )</code></h3>

<p>Finally, <code>rot</code> â€œrotatesâ€ the top <em>three</em> elements of the stack. The third
element from the top of the stack gets moved to the top of the stack, pushing
the other two elements down.</p>

<pre><code>1 2 3 rot
</code></pre>

<p>gives you:</p>

<p>2 3 1 &lt;- Top</p>



<h2 id="generating-output">Generating Output</h2>

<p>Next, letâ€™s look at some words for outputting text to the console.</p>

<h3 id="n-----period"><code>. ( n -- )</code> (period)</h3>

<p>The simplest output word in Forth is <code>.</code>. You can use <code>.</code> to output the top of
the stack in the output of the current line. For example, try running this
(make sure to include all the spaces!):</p>

<pre><code>1 . 2 . 3 . 4 5 6 . . .
</code></pre>



<p>You should see this:</p>

<p>1 . 2 . 3 . 4 5 6 . . . <span>1 2 3 6 5 4  ok</span></p>

<p>Going through this in order, we push <code>1</code>, then pop it off and output it. Then
we do the same with <code>2</code> and <code>3</code>. Next we push <code>4</code>, <code>5</code>, and <code>6</code> onto the stack.
We then pop them off and output them one-by-one. Thatâ€™s why the last three
numbers in the output are reversed: the stack is last in, first out.</p>

<h3 id="emit--c----"><code>emit ( c -- )</code></h3>

<p><code>emit</code> can be used to output numbers as ascii characters. Just like <code>.</code> outputs
the number at the top of the stack, <code>emit</code> outputs that number as an ascii
character. For example:</p>

<pre><code> 33 119 111 87 emit emit emit emit
</code></pre>



<p>I wonâ€™t give the output here so as to not ruin the surprise. This could also be
written as:</p>

<pre><code>87 emit 111 emit 119 emit 33 emit
</code></pre>

<p>Unlike <code>.</code>, <code>emit</code> doesnâ€™t output any space after each character, enabling you
to build up arbitrary strings of output.</p>

<h3 id="cr-----"><code>cr ( -- )</code></h3>

<p><code>cr</code> is short for carriage return â€“ it simply outputs a newline:</p>

<pre><code>cr 100 . cr 200 . cr 300 .
</code></pre>



<p>This will output:</p>

<p>cr 100 . cr 200 . cr 300 .<span>
100
200
300  ok</span></p>

<h3 id="section"><code>." ( -- )</code></h3>

<p>Finally we have <code>."</code> â€“ a special word for outputting strings. The <code>."</code> word works
differently inside definitions to interactive mode. <code>."</code> marks the beginning of
a string to output, and the end of the string is marked by <code>"</code>. The closing <code>"</code>
isnâ€™t a word, and so doesnâ€™t need to be space-delimited. Hereâ€™s an example:</p>

<pre><code>: say-hello  ." Hello there!" ;
say-hello
</code></pre>



<p>You should see the following output</p>

<p>say-hello <span>Hello there! ok</span></p>

<p>We can combine <code>."</code>, <code>.</code>, <code>cr</code>, and <code>emit</code> to build up more complex output:</p>

<pre><code>: print-stack-top  cr dup ." The top of the stack is " .
  cr ." which looks like '" dup emit ." ' in ascii  " ;
48 print-stack-top
</code></pre>



<p>Running this should give you the following output:</p>

<p>48 print-stack-top <span>
The top of the stack is 48
which looks like '0' in ascii   ok</span></p>

<h2 id="conditionals-and-loops">Conditionals and Loops</h2>

<p>Now onto the fun stuff! Forth, like most other languages, has conditionals and
loops for controlling the flow of your program. To understand how they work,
however, first we need to understand booleans in Forth.</p>

<h3 id="booleans">Booleans</h3>

<p>Thereâ€™s actually no boolean type in Forth. The number <code>0</code> is treated as false,
and any other number is true, although the canonical true value is <code>-1</code> (all
boolean operators return <code>0</code> or <code>-1</code>).</p>

<p>To test if two numbers are equal, you can use <code>=</code>:</p>

<pre><code>3 4 = .
5 5 = .
</code></pre>

<p>This should output:</p>

<p>3 4 = . <span>0  ok</span>
5 5 = . <span>-1  ok</span></p>



<p>You can use <code>&lt;</code> and <code>&gt;</code> for less than and greater than. <code>&lt;</code> checks to see if the
second item from the top of the stack is less than the top item of the stack, and
vice versa for <code>&gt;</code>:</p>

<pre><code>3 4 &lt; .
3 4 &gt; .
</code></pre>

<p>3 4 &lt; . <span>-1  ok</span>
3 4 &gt; . <span>0  ok</span></p>



<p>The boolean operators And, Or, and Not are available as <code>and</code>, <code>or</code>, and <code>invert</code>:</p>

<pre><code>3 4 &lt; 20 30 &lt; and .
3 4 &lt; 20 30 &gt; or .
3 4 &lt; invert .
</code></pre>

<p>The first line is the equivalent of <code>3 &lt; 4 &amp; 20 &lt; 30</code> in a C-based language.
The second line is the equivalent of <code>3 &lt; 4 | 20 &gt; 30</code>. The third line is the
equivalent of <code>!(3 &lt; 4)</code>.</p>

<p><code>and</code>, <code>or</code>, and <code>invert</code> are all bitwise operations. For well-formed flags
(<code>0</code> and <code>-1</code>) theyâ€™ll work as expected, but theyâ€™ll give incorrect results for
arbitrary numbers.</p>



<h3 id="if-then"><code>if then</code></h3>

<p>Now we can finally get onto conditionals. Conditionals in Forth can only be
used inside definitions. The simplest conditional statement in Forth is <code>if
then</code>, which is equivalent to a standard <code>if</code> statement in most languages.
Hereâ€™s an example of a definition using â€¦</p></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://skilldrick.github.io/easyforth">https://skilldrick.github.io/easyforth</a></em></p>]]>
            </description>
            <link>https://skilldrick.github.io/easyforth</link>
            <guid isPermaLink="false">hacker-news-small-sites-26164275</guid>
            <pubDate>Wed, 17 Feb 2021 09:03:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[CTO Headaches: Top cloud-to-cloud migration woes (and how to solve them)]]>
            </title>
            <description>
<![CDATA[
Score 66 | Comments 30 (<a href="https://news.ycombinator.com/item?id=26163970">thread link</a>) | @llarsson
<br/>
February 17, 2021 | https://www.cncf.io/blog/2021/02/15/cto-headaches-top-5-cloud-to-cloud-migration-woes-and-how-to-solve-them/ | <a href="https://web.archive.org/web/*/https://www.cncf.io/blog/2021/02/15/cto-headaches-top-5-cloud-to-cloud-migration-woes-and-how-to-solve-them/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
			
<p><em>Guest post originally published on <a href="https://elastisys.com/top-5-cloud-to-cloud-migration-woes-and-how-to-solve-them/">Elastisysâ€™s blog</a> by Lars Larsson, Senior Cloud Architect and Branch Manager</em> at <em>Elastisys</em></p>



<p>All companies that use cloud services do so for a reason. But those reasons may change. Whether motivated by the need for a multi-cloud strategy, expenditure minimization, legislative or regulatory demands, or simply to get closer to end users, many organizations find themselves migrating from one cloud to another. Cloud-to-cloud migration for a non-trivial application contains a lot of unknown unknowns. This causes stress and uncertainty for a CTO. To help shed some light based on years of experience in the field, we have asked senior cloud architect Lars Larsson at Elastisys, to list some of these issues.</p>



<h2>Executive summary</h2>



<ul><li>Cloud providers offer a wide range of services, each with their own associated costs. Make sure to fully understand the situation as you make your calculations.</li><li>Providers tend to lock in customers via well-integrated services. These may make migration more difficult.</li><li>Make clear inventory of features and functionality your application requires of a managed service. These may or may not match what other cloud providers offer.</li><li>Also make an inventory of the tools and services supporting your organizational processes.</li><li>Take all these inventories into account to calculate your total cost of ownership for any cloud-to-cloud migration.</li><li>Use cloud native technologies to decouple your application and organization from the services offered by a particular cloud provider. This makes migration easier in the future.</li></ul>



<h2>1. Pricing models vary wildly</h2>



<p>Most companies have been hit by that one cloud bill that surprised them. Some services or features wound up costing far more than originally anticipated.&nbsp;</p>



<p>Are you considering a cloud-to-cloud migration to reduce operational costs? If so, please take a long and hard look at the various costs in each of the clouds. Because each service has a different cost model, making it very difficult to compare accurately. You really need to get to the bottom of it.</p>



<p>Compute and storage costs are often easy enough to compare, because those are the most obvious two. But what about other services? How much are you spending on, e.g., log handling or monitoring? Good services such as AWS CloudWatch come at a cost, especially if you use it for log handling too (AWS CloudWatch Logs). Are you heavily using a managed database service? A queueing or pub/sub service?</p>



<p>Avoid feeling like that one time the surprise cloud bill hit you in the face by doing your homework this time. You are wiser from the experience, after all.</p>



<p>Network transfers in and out of the cloud can also vary by quite a large amount. The three major providers will give you incoming network traffic for free, but charge you for the outgoing traffic. Smaller, regional, cloud providers will often have higher compute and storage costs, but not charge you for network traffic. Or include a much larger amount of it in a free tier offering.</p>



<p>Overwhelming? I get it. It sure looks that way at first glance! But it doesnâ€™t have to be. My trick is to look at your past few detailed billing statements, and map those costs to your new cloud provider options.</p>



<ul><li><em>Key takeaway: Deeply take all aspects of your current cloud billing into account. Find the differences between offerings, and make a more informed decision.</em></li></ul>



<h2>2. Cloud vendor-specific integrations</h2>



<p>Tell me, did you adopt Kubernetes to make yourself less dependent on cloud providers? Reduce vendor lock-in? Are you now surprised at finding out that you are still locked in, but on a different level?</p>



<p>What Iâ€™ve seen is that most organizations will make sure they have highly portable application definitions. By relying on Kubernetes, the application definitions work across cloud providers.&nbsp;</p>



<p>But what Iâ€™ve also seen is that if you are using a managed Kubernetes service, your users and permissions handling is perhaps tied not to Kubernetes role-based access control (RBAC) features, but rather, to cloud-specific offerings. Like AWS Identity and Access Management (IAM). Great service, but ties you to the AWS platform.</p>



<p>Fully-managed Kubernetes services, if offered by cloud vendors themselves, serve to offer a highly integrated experience. The cost of that integration is that migration to another cloud provider becomes just that certain amount more difficult.</p>



<p>As a community, weâ€™ve tried to fix this. But as a community of engineers, those fixes are technical. Kubernetes dictates standards for certain components or aspects. Networking has to work according to the Container Network Interface (CNI) standard. Storage according to Container Storage Interface (CSI). And so on. Great. But the business people have put in much more clever ways of locking you to the platform. This means that other less obvious aspects are more difficult to freely migrate from one cloud to another.</p>



<p>So what is the option? Do you have to manage Kubernetes yourself? No. Of course not. But it may make sense to investigate managed Kubernetes offerings that are not tied to a particular cloud provider to reduce the risk of vendor lock-in. Without having to take on the task of day-to-day operations on your own, of course.</p>



<ul><li><em>Key takeaway: Investigate the ways in which cloud providers make migration more difficult due to incompatible integrations. Choose third-party vendors that are not tied to any particular cloud provider, and can offer their services on top of other cloud providers if need be.</em></li></ul>



<h2>3. The devil is in the (technical) details</h2>



<p>Almost all organizations Iâ€™ve talked to say the same thing. They went to the cloud because they wanted to get infrastructure or platform functionality on an as-a-Service basis. That is the whole point of the cloud, is it not?</p>



<p>So, of course, all cloud providers will offer certain services. It used to be just infrastructure as a service (virtual machines, network, and storage) but we are starting to also take, e.g., object storage and queuing services for granted. Many such services will claim to offer an â€œS3 compatible APIâ€ or similar. And that is a great starting point! But beware, because what does such a compatibility claim really mean?&nbsp;</p>



<p>AWS S3, for example, was, until December 2020, merely eventually consistent. Since&nbsp;<a href="https://www.infoq.com/news/2020/12/aws-s3-strong-consistency/">their announcement</a>, it is read-after-write consistent (strong consistency). Which level of consistency would a service that is â€œS3 compatibleâ€ have? The old one? Or the new one? And do you have aspects of your applications that depend on that answer being one or the other? Would you know off-hand?</p>



<p>If you donâ€™t, by the way, youâ€™re in excellent company. Most peopleâ€™s eyes gloss over when consistency guarantees are discussed. But then again, you donâ€™t want to get bitten by a bug caused by wrongful assumptions, so somebody has to stay awake to figure this stuff out. Hopefully not past midnight!</p>



<p>Ready for another unexciting example? Queuing services, such as AWS SQS, offer certain delivery guarantees. SQS standard queues offer â€œat least onceâ€ guarantees. That means that a message can be delivered to your application more than once, and must have logic in place for dealing with duplicates. An application that is not prepared for this will start showing strange behavior. Especially under heavy load, because that is when the risk for multiple deliveries is higher. This is because high load means there is less time to do housekeeping for the queuing service. (Note that while SQS offers FIFO queues that have â€œexactly onceâ€&nbsp;<strong>processing</strong>&nbsp;guarantees, however, that&nbsp;<a href="https://www.ably.io/blog/sqs-fifo-queues-message-ordering-and-exactly-once-processing-guaranteed">does not imply exactly once delivery</a>.) So confusing for an application that was coded with assumptions of RabbitMQâ€™s â€œat most onceâ€ delivery guarantees!</p>



<figure><div>
<blockquote data-width="500" data-dnt="true"><div lang="en" dir="ltr"><p>Most people's eyes gloss over when consistency guarantees are discussed</p><p>Read the whole article "CTO Headaches: Top 5 cloud-to-cloud migration woes" for more<a href="https://t.co/exLGZu5SZG">https://t.co/exLGZu5SZG</a></p></div>â€” elastisys (@elastisys) <a href="https://twitter.com/elastisys/status/1358795732132769794?ref_src=twsrc%5Etfw">February 8, 2021</a></blockquote>
</div></figure>



<p>The point I am making here is that you must make an inventory of all the cloud services you use, and what features in these are key to your applications working the way they are intended. Because&nbsp;<strong>your</strong>&nbsp;use case is the one that matters.</p>



<p>Cloud providers offer services that make certain trade-offs to ensure the scalability and availability&nbsp;<em>of their service</em>. From the perspective of individual customers and applications, the ideal trade-off choice might have been different. If you use a software such as RabbitMQ, you can configure it perfectly for your use case and requirements. Not the ones of the cloud providers. There are companies that offer managed services in a cloud-agnostic way. Especially on top of Kubernetes, which deserve your consideration.</p>



<ul><li><em>Key takeaway: Make a clear inventory of all cloud services you use, along with the required features of each for your use case. To make a cloud-to-cloud migration easier, start depending on software not tied to any particular provider.</em></li></ul>



<h2>4. Tools supporting your processes (may) change</h2>



<p>Industry wisdom and rule of thumb says that&nbsp;<a href="https://www.econnectivity.se/app-maintenance-cost-can-be-three-times-higher-than-development-cost/">about 70% of software costs</a>&nbsp;are in maintenance. Not development. Just keeping the thing running as intended. How do you address that? My take on it is to rely on smart tools and automation as much as possible. The less your staff has to work on rote menial tasks, the better. Everything they do is a process. So letâ€™s talk about those processes.</p>



<p>Operating your mission-critical cloud application? A bunch of processes. And most, if not all, of these are supported by tools. Continuous integration and deployment, monitoring, notifications and alerting. These are the tools your operations staff is using to analyze and optimize your application deployment.</p>



<p>Great tools like AWS CloudWatch offer insight into monitoring, logging (CloudWatch Logs), and containerized workloads (CloudWatch Container Insights). Your team probably depends on them. But they are specific to a particular cloud vendor.</p>



<p>If you â€¦</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.cncf.io/blog/2021/02/15/cto-headaches-top-5-cloud-to-cloud-migration-woes-and-how-to-solve-them/">https://www.cncf.io/blog/2021/02/15/cto-headaches-top-5-cloud-to-cloud-migration-woes-and-how-to-solve-them/</a></em></p>]]>
            </description>
            <link>https://www.cncf.io/blog/2021/02/15/cto-headaches-top-5-cloud-to-cloud-migration-woes-and-how-to-solve-them/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26163970</guid>
            <pubDate>Wed, 17 Feb 2021 08:20:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Kill the Alarm Clock (2017)]]>
            </title>
            <description>
<![CDATA[
Score 110 | Comments 168 (<a href="https://news.ycombinator.com/item?id=26163691">thread link</a>) | @aminozuur
<br/>
February 16, 2021 | https://supermemo.guru/wiki/Kill_the_alarm_clock | <a href="https://web.archive.org/web/*/https://supermemo.guru/wiki/Kill_the_alarm_clock">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="mw-content-text" lang="en" dir="ltr"><p><small>This text is part of: "<i><a href="https://supermemo.guru/wiki/Science_of_sleep" title="Science of sleep">Science of sleep</a></i>" by <a href="https://supermemo.guru/wiki/Piotr_Wozniak" title="Piotr Wozniak">Piotr Wozniak</a> (2017)</small>
</p>


<h2><span id="Kill_the_alarm_clock.21">Kill the alarm clock!</span></h2>
<h3><span id="Alarm_clock_epidemic">Alarm clock epidemic</span></h3>
<p>Few upwardly mobile people in the modern rat-race society can live without an alarm clock. With a shot of strong coffee and round-the-clock stress, most people learn to live and survive with an alarm clock. Half of the population wakes up with an alarm, 9% are woken by a partner, 4% by pets, 3% by children, etc. That leaves a minority that wake up naturally. Increasingly, time becomes the most precious commodity in society where achievement is often associated with speed and perfect time-management. However, alarm clocks introduce harmful side effects: stress, sleep debt, and worst of all, disruption of the natural physiological sleep function. At worst, those factors will result in physical damage to the brain (e.g. such sensitive structures as the hippocampus, your memory switchboard, may literally <a href="https://supermemo.guru/wiki/If_you_do_not_sleep,_you_die!" title="If you do not sleep, you die!">lose neurons as a result of disrupted sleep</a>).
</p><p>The art of time-management makes it possible to live at a high speed with an alarm clock at your side, and still be free from <a href="https://supermemo.guru/wiki/Factors_that_affect_sleep#Stress" title="Factors that affect sleep">stress</a>. However, the societal damage inflicted by alarm clocks and <a href="https://supermemo.guru/wiki/Sleep_deprivation" title="Sleep deprivation">sleep deprivation</a> is unforgivable. An alarm clock that interrupts your sleep damages your memories, your ability to learn, your creativity, your mood and temper, your relationships with other people, your ability to focus, and your overall intellectual performance!
</p><p>Dr Robert Stickgold has shown that people who learn a skill during the day do not show significant improvement until they get 7-8 hours of good sleep<sup id="cite_ref-stickgold-2005_1-0"><a href="#cite_note-stickgold-2005-1">[1]</a></sup>. There was a noticeable correlation between the degree of improvement and the quality of sleep received. My own work with <a href="https://supermemo.guru/wiki/Sleep_habits#SleepChart_in_SuperMemo" title="Sleep habits">SleepChart</a> also shows that the <a href="https://supermemo.guru/wiki/Sleep_and_learning#Alarm_clock_vs._learning" title="Sleep and learning">use of alarm clocks can dramatically reduce memory recall and consolidation</a>. Forgetting is so painless that we rarely notice its effects. In a natural way, forgetting will proceed even if you get as much sleep as you need, and it is difficult to point to specific memories lost as a result of not sleeping enough. Moreover, <a href="https://supermemo.guru/wiki/Memory_optimization_in_sleep#Neural_optimization_in_sleep" title="Memory optimization in sleep">sleep deprivation may leave your memories intact while their storage will be sub-optimum</a>. The difference may be impossible to spot without measurement. We are more likely to notice sleepiness, reduced mental agility, or bad mood.
</p><p>Disrespect for sleep has reached biblical proportions. This is most noticeable in the US and other highly industrialized nations. <i>Men's Health's</i> Dan Vergano writing for <i>ABC News</i> in <i>"No More Rude Awakenings"</i> suggests a seven-day system for fighting sleepiness: <i>"The secret is to fuel that arousal system so it can <b>beat the pants off the sleep system</b>. By creating the kind of feel-good expectations that trigger hormones to wake the brain, youâ€™ll override the need to sleep and be able to jump out of bed like a man on fire"</i>. The article suggests a "fresh" mind method that capitalizes on the fact that stress hormones help keep you alert. However, the only rational remedy for <i>"rude awakenings"</i> is simple: get enough sleep! Jumping <i>like a man on fire</i> is not likely to have a positive effect on your creative potential!
</p><p>You may often notice that waking up with an alarm clock gives you a jumpstart for the day. You may then come to believe that using the alarm clock might help you stay alert later in the day. This is not the case. The alarm signal simply scares your brain into wakefulness, disrupting the carefully planned process of <a href="https://supermemo.guru/wiki/Memory_optimization_in_sleep#Neural_optimization_in_sleep" title="Memory optimization in sleep">neural optimization</a> that occurs in sleep. As a result, you get an immediate injection of <a href="http://en.wikipedia.org/wiki/Adrenaline">adrenaline</a> and your levels of <a href="http://en.wikipedia.org/wiki/ACTH">ACTH</a> and <a href="http://en.wikipedia.org/wiki/Cortisol">cortisol</a> also increase. This is cortisol that peaks at awakening in natural sleeping rhythm that provides you with the fresh-mind impression. With passing time, this cheaply gained alertness will wear thin unless you continue abusing your physiology with more "remedies". You may use more scare tactics for keeping yourself alert, abuse caffeine, or even get a more profound effect with <a href="http://en.wikipedia.org/wiki/Modafinil">modafinil</a>, <a href="http://en.wikipedia.org/wiki/Cocaine">cocaine</a>, or <a href="http://en.wikipedia.org/wiki/Amphetamines">amphetamines</a>. Alertness should be achieved with the help of sufficient sleep, not despite the lack of sleep! Apart from your reduced ability to learn new things, all unnatural anti-drowsiness methods will produce a great deal of side effects that can be pretty damaging to your health in the long run.
</p><p>All efforts to overcome sleepiness by means other than sleep itself can be likened to a chase of the first high in the use of psychoactive substances. If you drink buckets of coffee, do pushups, pour cold water over your head, or slap your face, you only dip into the last reserves of your alertness hormones that only worsen the effects of deprivation after the effects of the stimulation wear off, which is usually a matter of minutes. Rarely can you get a boost lasting more than an hour, and the more you perk up, the lower you fall in the aftermath.
</p>
<h3><span id="Insomnia_trap">Insomnia trap</span></h3>
<p>If your life without an alarm clock may seem like an impossibility, you will probably need to use all methods in the book to be sure you get enough sleep and minimize the damage. If you need to wake up early at the cost of your brain, avoid the <b><a href="https://supermemo.guru/wiki/Insomnia" title="Insomnia">insomnia trap</a></b>! Insomnia trap is a vicious circle of:
</p>
<ol><li> going to sleep too early to get more sleep,</li>
<li> failing to fall asleep in time (or worse, waking up prematurely),</li>
<li> feeling even more tired on the next day, and</li>
<li> going to sleep even earlier on the next day to catch up with the lost sleep.</li></ol>
<p>It is better to go to sleep at a natural hour (i.e. a bit later), wake up early, suffer a degree of sleep deprivation, and hope for a phase reset that will make it possible to continue on the <a href="http://www.stevepavlina.com/blog/2005/05/how-to-become-an-early-riser/">designer schedule</a>. For a solution to the insomnia trap see: <a href="https://supermemo.guru/wiki/Curing_DSPS_and_insomnia" title="Curing DSPS and insomnia">Curing DSPS and insomnia</a>.
</p><p>If you cannot reset your phase and still feel tired when getting up early on a regular basis, consider choosing a job that is acceptable for your body, not the other way around. Your long-term health and well-being is at stake. If you absolutely cannot live without an alarm clock, you can at least start from changing your mindset about the importance of sleep and ensure you do not impose wrong habits on your children. Perhaps the young ones will be lucky enough to work in a flex-time system that will make it possible to get sufficient amount of undisturbed sleep. At least, do not set a bad example!
</p>
<h3><span id="Wake_up_the_President">Wake up the President</span></h3>
<p>President Bill Clinton was woken up twice by telephone during the night of April 22, 2000 before the infamous I.N.S. raid on the home of Miami relatives of the young Cuban exile Elian Gonzales. He was probably the most often disrupted and sleep deprived president in history. Only after a heart surgery did Clinton take diet, sleep and (real) exercise seriously. Those interrupted nights would definitely influence his performance and the quality of his decisions! Has anybody thought of a rule: <i>Do not wake up the president?</i> A rule that could only be revoked in a true national emergency? President G. W. Bush (b. 1946) was woken up when an American spy plane landed in China in 2001. He was also woken up after a suicide bombing in Jerusalem in 2002. George H. W. Bush (b. 1924) and Hilary Clinton made "waking up in the middle of the night" part of their presidential campaign and prowess. It seems that only Ronald Reagan had pretty strong rules for protecting his own sleep. He also famously napped during some cabinet meetings. He slept through a couple of international events without an apparent negative impact on his somewhat delayed decision-making. Critics would say he slept through the entire <a href="http://en.wikipedia.org/wiki/Iran%E2%80%93Contra_affair">Iran-Contra affair</a>. Was Reagan so protective of sleep because he understood the role of sleep better, or perhaps he was just a bit lazier than other presidents? I don't know. However, he sure set a good example.
</p>
<h3><span id="Alarm_clock_monsters">Alarm clock monsters</span></h3>
<p>Andrea K. wrote to me with skepticism: 
</p>
<blockquote><p><i>"Take the alarm clock away from a typical person and they won't just wake up on their own at their desired time and they will miss work, school, or whatever. An alarm clock can't be that bad for you because of the simple fact that most people use it and I never noticed any problem with them&nbsp;:) Everyone in my family has been using one since they were children, and no one suddenly went crazy or began to mutate into a monster (yet)!"</i></p></blockquote> 
<p>When you use an alarm early in the morning in order to get to work or to school, you cut off the later stages of sleep. If the intrusion into natural sleep is not large (e.g. from minutes to an hour), the damage may be limited and hard to notice. Alarm clock will do far more damage if it cuts deep into the middle of the night sleep. You can compare the use of alarm clocks to smoking or eating hot dogs. The harm is not great enough to be instantly noticeable. It took the public many years to largely accept that "smoking is bad" or "fast food is bad". It is hard to quantify the degree of damage. However, as we move to knowledge society where our intellectual performance becomes increasingly important, the effects of <a href="https://supermemo.guru/wiki/Sleep_deprivation" title="Sleep deprivation">sleep deprivation</a> will come under closer scrutiny and alarm clocks are bound to gradually fall out of favor. Unlike hot dogs, they are already universally hated by their users. Most people are able to somewhat adapt their sleep to their schedules if their routines are regular enough. When those people need to resort to the use of the alarm clock, they cut less of their sleep and the damage is proportionally smaller. Nevertheless, we should always strive at eliminating alarm clocks altogether. Most of all, we should protect our kids from suffering interrupted sleep!
</p>
<h2><span id="References">References</span></h2>
<ol>
<li id="cite_note-stickgold-2005-1"><span><a href="#cite_ref-stickgold-2005_1-0">â†‘</a></span> <span>Stickgold R., "<a href="http://www.nature.com/nature/journal/v437/n7063/full/nature04286.html">Sleep-dependent memory consolidation</a>," Nature / Volume 437 (October 27, 2005): 1272-1278</span>
</li>
</ol>

<!-- 
NewPP limit report
Cached time: 20210220073322
Cache expiry: 86400
Dynamic content: false
CPU time usage: 0.032 seconds
Real time usage: 0.058 seconds
Preprocessor visited node count: 56/1000000
Preprocessor generated node count: 158/1000000
Postâ€expand include size: 1541/2097152 bytes
Template argument size: 438/2097152 bytes
Highest expansion depth: 4/40
Expensive parser function count: 0/100
-->

<!-- 
Transclusion expansion time report (%,ms,calls,template)
100.00%   40.352      1 - -total
 62.60%   25.261      1 - ArticleSleep
 17.15%    6.921      1 - Template:Excerpt
-->

<!-- Saved in parser cache with key supermem_kool_kids:pcache:idhash:1062-0!*!0!!en!*!* and timestamp 20210220073322 and revision id 14432
 -->
</div></div>]]>
            </description>
            <link>https://supermemo.guru/wiki/Kill_the_alarm_clock</link>
            <guid isPermaLink="false">hacker-news-small-sites-26163691</guid>
            <pubDate>Wed, 17 Feb 2021 07:28:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Introduction to ARM Semihosting]]>
            </title>
            <description>
<![CDATA[
Score 7 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26163374">thread link</a>) | @parsecs
<br/>
February 16, 2021 | https://interrupt.memfault.com/blog/arm-semihosting | <a href="https://web.archive.org/web/*/https://interrupt.memfault.com/blog/arm-semihosting">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

        <p>Firmware developers are generally accustomed to using logging for execution
information. On microcontrollers, this is usually done through a serial
interface attached to a terminal on the host.</p>

<p>But one might need more advanced features from the host! I was in this position
not long ago ğŸ¤¨.</p>

<p>When working on camera firmware, and particularly on the image processing
algorithm, I constantly needed to transfer images from the camera to my host
machine to make sure everything was working fine. So I started using
semi-hosting! It has greatly facilitated not only my development but also the
debugging of my embedded software.</p>

<p><strong>Semihosting</strong> is one of the many interesting features available on ARM Cortex
microcontrollers. It allows an embedded program to take advantage of the
capabilities of an attached computer when the debugger is running.</p>

<!-- excerpt start -->
<p>This post introduces semihosting and shows how to use it and integrate it into
your own embedded projects.
<!-- excerpt end --></p>



<h2 id="what-is-semihosting">What Is Semihosting</h2>

<p>According to ARM documentation<sup id="fnref:1"><a href="#fn:1">1</a></sup>, <strong>semihosting</strong> is <em>a mechanism that enables
code running on an ARM target to communicate and use the Input/Output facilities
on a host computer that is running a debugger</em>.</p>

<p>In other words, an ARM based MCU can run C library functions, such as
<code>printf()</code>, <code>scanf</code>, or even <code>fopen</code>, and have these interact directly with the
host computer attached to the device. By doing so, it can benefit from the
screen, the keyboard, or the disk of the host.</p>

<p>
  <img width="600" src="https://interrupt.memfault.com/blog/img/semihosting/semihosting_overview.png">
</p>

<h2 id="how-it-works">How It Works</h2>

<p>This is done by halting the CPU target by the debugger agent, either by running
into a breakpoint instruction (<code>BKPT 0xAB</code>  for ARMv6-M or ARMv7-M) or by
sending a supervisor call instruction (<code>SVC 0xAB</code> or <code>SVC 0x123456</code>) depending
on the target architecture or processor.</p>

<p>This indicates to the host that the target is requesting a semihosting
operation.</p>

<p>The debugger agent then figures out the operation requested by the target by
reading the content of <code>r0</code>, and, if necessary, accesses all other function
parameters pointed by <code>r1</code>.</p>

<p>While the CPU is still halted, the host will execute the requested operation and
return the result in <code>r0</code> before allowing the processor to continue running its
program.</p>

<p>The following is a list of the semihosting operations defined by ARM<sup id="fnref:2"><a href="#fn:2">2</a></sup>:</p>

<div><div><pre><code><span>/* File operations */</span>
<span>SYS_OPEN</span>        <span>EQU</span> <span>0x01</span> <span>//Open a file or stream on the host system.</span>
<span>SYS_ISTTY</span>       <span>EQU</span> <span>0x09</span> <span>//Check whether a file handle is associated with a file or a stream/terminal such as stdout.</span>
<span>SYS_WRITE</span>       <span>EQU</span> <span>0x05</span> <span>//Write to a file or stream.</span>
<span>SYS_READ</span>        <span>EQU</span> <span>0x06</span> <span>//Read from a file at the current cursor position.</span>
<span>SYS_CLOSE</span>       <span>EQU</span> <span>0x02</span> <span>//Closes a file on the host which has been opened by SYS_OPEN.</span>
<span>SYS_FLEN</span>        <span>EQU</span> <span>0x0C</span> <span>//Get the length of a file.</span>
<span>SYS_SEEK</span>        <span>EQU</span> <span>0x0A</span> <span>//Set the file cursor to a given position in a file.</span>
<span>SYS_TMPNAM</span>      <span>EQU</span> <span>0x0D</span> <span>//Get a temporary absolute file path to create a temporary file.</span>
<span>SYS_REMOVE</span>      <span>EQU</span> <span>0x0E</span> <span>//Remove a file on the host system. Possibly insecure!</span>
<span>SYS_RENAME</span>      <span>EQU</span> <span>0x0F</span> <span>//Rename a file on the host system. Possibly insecure!</span>

<span>/* Terminal I/O operations */</span>
<span>SYS_WRITEC</span>      <span>EQU</span> <span>0x03</span> <span>//Write one character to the debug terminal.</span>
<span>SYS_WRITE0</span>      <span>EQU</span> <span>0x04</span> <span>//Write a 0-terminated string to the debug terminal.</span>
<span>SYS_READC</span>       <span>EQU</span> <span>0x07</span> <span>//Read one character from the debug terminal.</span>

<span>/* Time operations */</span>
<span>SYS_CLOCK</span>       <span>EQU</span> <span>0x10</span>
<span>SYS_ELAPSED</span>     <span>EQU</span> <span>0x30</span>
<span>SYS_TICKFREQ</span>    <span>EQU</span> <span>0x31</span>
<span>SYS_TIME</span>        <span>EQU</span> <span>0x11</span>

<span>/* System/Misc. operations */</span>
<span>SYS_ERRNO</span>       <span>EQU</span> <span>0x13</span> <span>//Returns the value of the C library errno variable that is associated with the semihosting implementation.</span>
<span>SYS_GET_CMDLINE</span> <span>EQU</span> <span>0x15</span> <span>//Get commandline parameters for the application to run with (argc and argv for main())</span>
<span>SYS_HEAPINFO</span>    <span>EQU</span> <span>0x16</span>
<span>SYS_ISERROR</span>     <span>EQU</span> <span>0x08</span>
<span>SYS_SYSTEM</span>      <span>EQU</span> <span>0x12</span>
</code></pre></div></div>

<h2 id="how-to-use-it">How to Use It</h2>

<p>In this example, I run the program on an STM32 and use the <code>arm-none-eabi</code>
toolchain along with <strong>openOCD</strong> <code>gdbserver</code>. Other tools may be used instead
depending on your hardware, for more details on which debug interface to use, it
would be wise to read <a href="https://interrupt.memfault.com/blog/a-deep-dive-into-arm-cortex-m-debug-interfaces">this article</a>.</p>

<p>Once you are all set, we can start coding.</p>

<p>First, to enable semihosting, you need to link:</p>
<ul>
  <li>
<code>libc.a</code>, the standard C library (<em>newlib</em><sup id="fnref:3"><a href="#fn:3">3</a></sup> for <code>arm-none-eabi-gcc</code>),</li>
  <li>and <code>librdimon.a</code>, a part of the <em>libgloss</em><sup id="fnref:4"><a href="#fn:4">4</a></sup> library (for platform-specific
code) to your project.</li>
</ul>

<p>This is done by adding a few options to the ARM linker:</p>
<ul>
  <li>removing <code>-nostartfiles</code> flag to allow linking standards libraries,</li>
  <li>adding <code>-lc -lrdimon</code> flags,</li>
  <li>and changing the <em>spec strings</em> file<sup id="fnref:5"><a href="#fn:5">5</a></sup> to <code>--specs=rdimon.specs</code> to use the
semihosted version of the <em>syscalls</em>.</li>
</ul>

<p>The last point essentially means that the system calls can be used when a
debugger is attached (note that the CPU may crash if a debugger is not present).</p>

<p>Now on the C code side, you need to call <code>initialise_monitor_handles()</code> before
starting a semihosting operation.</p>

<div><div><pre><code><span>#ifdef SEMIHOSTING
</span><span>extern</span> <span>void</span> <span>initialise_monitor_handles</span><span>(</span><span>void</span><span>);</span>
<span>#endif
</span>
<span>int</span> <span>main</span><span>(</span><span>void</span><span>)</span> <span>{</span>
<span>#ifdef SEMIHOSTING
</span>  	<span>initialise_monitor_handles</span><span>();</span>
<span>#endif
</span>
  	<span>// other tasks ...</span>

<span>#ifdef SEMIHOSTING
</span>    <span>printf</span><span>(</span><span>"hello world!</span><span>\n</span><span>"</span><span>);</span>
    <span>printf</span><span>(</span><span>"hello world!</span><span>\n</span><span>"</span><span>);</span>
<span>#endif
</span>
    <span>// other tasks ...</span>

  	<span>return</span> <span>0</span><span>;</span>
<span>}</span>
</code></pre></div></div>

<p>If you are using <code>crt0</code> initialization function, <code>initialise_monitor_handles()</code>
has already been called for you before <code>main()</code>.</p>

<p>Once you have done this, you can compile and program your microcontroller as
usual, however, once the microcontroller flashed it should be halted and not run
yet.</p>

<p>In my case, I launch <em>OpenOCD</em> <code>gdbserver</code> in one terminal, to flash, reset and
halt the CPU. And run <code>gdb</code> from another terminal to connect to the server, and
enable the semihosting in the server side<sup id="fnref:6"><a href="#fn:6">6</a></sup>.</p>

<div><div><pre><code><span>$ </span>arm-none-eabi-gdb <span>-ex</span> <span>"target extended-remote localhost:3333"</span> <span>-ex</span> <span>"monitor reset halt"</span> <span>-ex</span> <span>"monitor arm semihosting enable"</span>
</code></pre></div></div>

<blockquote>
  <p>If <code>initialise_monitor_handles()</code> is called before enabling the semihosting in
the server, a <code>HardFault</code> may occur due to an unexpected debug event.</p>
</blockquote>

<p>Once semihosting is enabled, you can run your program from <code>gdb</code>, and the
semihosting operation will be handled by the <code>gdbserver</code>.</p>

<p>Isnâ€™t it great? ğŸ˜‹</p>

<h2 id="conclusion">Conclusion</h2>

<p>I hope it was fun reading this post, semihosting is not commonly used in
embedded development because it slows down the execution speed, but
nevertheless, it can be very handy in some cases.</p>

<p>I look forward to your remarks, tips, and comments.</p>

<!-- Interrupt Keep START -->
<p>Like Interrupt? <a href="https://go.memfault.com/interrupt-subscribe" target="_blank">Subscribe</a> to get our latest posts straight to your mailbox.</p>

<p>See anything you'd like to change? Submit a pull request or open an issue at <a href="https://github.com/memfault/interrupt" target="_blank">GitHub</a></p>

<!-- Interrupt Keep END -->

<h2 id="useful-links">Useful links</h2>

<!-- prettier-ignore-start -->
<!-- prettier-ignore-end -->



    </div><p><img src="https://interrupt.memfault.com/blog/img/author/ael-mess.jpg">
            
            <span>
                <a href="https://interrupt.memfault.com/blog/authors/ael-mess">Amine El Messaoudi</a> is an embedded software and firmware engineer, passionate about low-level programming.<br>
                
<span>
    
    
    <a href="https://www.linkedin.com/in/ael-mess/" target="_blank"><svg><use xlink:href="/blog/img/social-icons.svg#linkedin"></use></svg></a>
    
    
    <a href="https://github.com/ael-mess" target="_blank"><svg><use xlink:href="/blog/img/social-icons.svg#github"></use></svg></a>
    
</span>

            </span>

        </p></div>]]>
            </description>
            <link>https://interrupt.memfault.com/blog/arm-semihosting</link>
            <guid isPermaLink="false">hacker-news-small-sites-26163374</guid>
            <pubDate>Wed, 17 Feb 2021 06:30:39 GMT</pubDate>
        </item>
    </channel>
</rss>
