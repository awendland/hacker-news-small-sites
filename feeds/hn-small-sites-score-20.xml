<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 20]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 20. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Fri, 05 Feb 2021 08:34:14 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-20.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Fri, 05 Feb 2021 08:34:14 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[Mastodon is crumbling – and it will only get worse]]>
            </title>
            <description>
<![CDATA[
Score 30 | Comments 29 (<a href="https://news.ycombinator.com/item?id=26011818">thread link</a>) | @todsacerdoti
<br/>
February 3, 2021 | https://sporks.space/2021/02/02/mastodon-really-is-crumbling-and-it-will-only-get-worse/ | <a href="https://web.archive.org/web/*/https://sporks.space/2021/02/02/mastodon-really-is-crumbling-and-it-will-only-get-worse/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-297">
	<!-- .entry-header -->

	
		<div>
			
<p>I am 100% serious with the title, despite the appearance of click-bait. Mastodon has a serious structural rot that is only worsening as time gets on. I think this is for a few reasons which I will outline below.</p>



<p>Ironically, I don’t feel safe posting this directly to the fediverse because of the very forces I’m about to describe. I’m not worried about the cancel crew, I just don’t want to deal with hostile interactions right now. I might link to this post but it’s less likely to get hate mail I suspect if I do it that way rather than write this all up in a giant thread on fedi.</p>



<p>What I am presenting is largely anecdotal opinion, although it has been gathered from countless others (I’m not going to name any names, they deserve better than harassment or people trying to change their views and in the process merely reinforcing them).</p>



<h2>Background on myself</h2>



<p>I’ve been on Mastodon since April 2017. I was on “fedi” (well, the ostatus fediverse) before that, on long-gone instances I forgot the name of. I was on Mastodon in the very early days of its development, when content warnings were brand new, blocking/silencing was seriously broken, and fedi was just getting exciting due to press coverage. Before this, I was on IRC since 2005 and an IRC operator on a small network (it’s not glamorous, trust me).</p>



<h2>The problem</h2>



<p>Fedi has a problem as the title says: it’s crumbling. It’s a lot less vibrant than when I joined up, even back when GNUSocial roamed the earth (it was a pile of shit trying to imitate Twitter and mostly filled with people banned from Twitter for GamerGate and going too far, even for Twitter’s lax standards of the day).</p>



<p>It actually baffles me why so much of the Mastodon userbase can be traced back to the Tumblr/Twitter leftist crowd, when Fedi’s beginnings were on a network largely consisting of ultra-right people thrown off Twitter. I can only speculate, but I suspect the main reasons are they believed they would be safer (which is a joke), and many themselves (or their friends at least) were banned from those platforms for similarly shitty behaviour.</p>



<p>But it’s a mistake to believe that Fedi is safer at all. In fact, in many ways, it’s worse.</p>



<h3>Fedi is the least safe place around</h3>



<p>The thing about Fedi is that due to its nature, it has a low bar to entry. Anyone can make an instance at any time for not a whole lot of money. There are tons of far-right instances littering the place, and few admins can truly keep up (the worst-kept secret amongst Mastodon admins I would say). Most of the userbase just blocks them on an ad-hoc basis and moves on (or doesn’t notice them), but the fact that the Nazis haven’t really taken over the place is only by their mere incompetence.</p>



<p>To illustrate the problem, I will tell you about this: the largest instance on the Fediverse.</p>



<p>Oh, no, not mastodon.social. They’re big, but not as big as the largest. The largest is Pawoo, with around a million users last I checked. It’s owned by Pixiv, a Japanese company (think Japanese DeviantArt). And if Fedi knew even a rudimentary level of Japanese (this would require widespread non-Western cultural awareness they do not possess), they wouldn’t have joined in the first place. Japanese nationalism is everywhere on Pawoo, and the admins largely don’t care (granted: I don’t pay much attention to it and filtered it a long time ago, this may not be the case any longer). There is a certain irony I love about the largest Fedi instance being a commercial entity, despite the English speakers of the Fediverse largely eschewing corporations and brands. They also allow loli and (fictional) artwork of children, which is not banned in Japan but is a grey area in the US as advised by legal counsel for IF (I personally don’t want to test it, if you want to, have fun, leave me out of it).</p>



<p>Pawoo mostly sits there, under the radar, because they don’t speak English, and many instances blocked them a long time ago (I remember the great Pawoo discourse of 2017). There are tons and tons of other instances that most people don’t even know about that spew things that are far worse.  We at mst3k actually have <a href="https://mst3k.interlinked.me/about/more" target="_blank" rel="noreferrer noopener">a pretty big list</a>, and it ain’t even close to how many are actually out there. I just block them as I see them. Granted, many of those instances are long-gone, but there are many more to replace them.</p>



<h3>The faux-woke crowd is making fedi less safe</h3>



<p>I know this one is going to get me flamed and called racist or whatever the fuck, but so be it.</p>



<p>Now, full disclosure: I am partially Romani, Native American, but mostly (and certainly culturally raised) white, but <a href="https://weirder.earth/@WeirderAdmin/105640549522292568" target="_blank" rel="noreferrer noopener">I’ve listened to what other PoC have to say on this matter.</a></p>



<p>Fedi has a really bad problem: race-based trolling. There is a huge contingent on Fedi that is taking advantage of white guilt to troll the ever-loving fuck out of people.</p>



<p>I know this sounds like an amusing thing and is very much a “so what, they’re white” moment.  But I assure you, it’s anything but funny, and it’s causing minorities to be shed from Fedi.</p>



<p>Let me give a specific example: in mid-2020, a Jewish non-binary person was harassed by a member of one of the instances that host many of these trolls. People were still reluctant to do the right thing and block the instance, because they didn’t want to be called racist. The thing is, you can be a minority and still be a fucking dickhead, and you can also still be racist (without even realising it!) and act in bigoted ways against other minorities (go look up the Cherokee freedmen controversy for a really, really, really bad look into how far this can go). But nothing about your skin colour or ethnicity says “I can troll whoever I want.” Anyone who tells you otherwise is a troll and you should block and report them. If their admin won’t do anything, remove them.</p>



<p>The thing is, these kinds of games cheapen real racial justice. These people are less interested in racial justice for all and more interested in getting a rise out of people. And people are too afraid to stand up to it. This is a cancer silently driving people back to Twitter. I don’t think it’s the only thing stacked against Fedi, but it’s a huge one.</p>



<h3>The cancel crowd</h3>



<p>I’m going to say it: the canceldon crowd are obnoxious. They’re a holdover from Twitter and Tumblr. I won’t go into the whole “why cancelling is a waste of time” thing, but suffice it to say: cancelling doesn’t really fucking work, and it’s just a nice way of saying “doing what 4chan does to people it hates, but poorly.” Which is to say, harassment and trolling people. And of course people think it’s okay, even when they fuck up and sometimes cancel the wrong person or have bad info or got led on (this is never discussed, of course, and there is never an apology).</p>



<p>These people are literally making Fedi inherently less safe for everyone, and are no better than the crowd that used to be on Fedi (and still are to an extent) before Gargron decided to co-opt the Fediverse for his own gain.</p>



<h3>The people who write the software are fucking dickheads</h3>



<p>I’m going to be honest with you: Gargron (the guy who makes Mastodon) is an asshole. His reputation precedes him, so I won’t go into detail. However, I found out from a former IRL friend of mine (who will remain nameless) that he once asked her if he could continue to refer to her by her dead name. Said friend referred to Gargron as a “shitty liberal,” and I do not mean in the US sense.</p>



<p>The people at Pleroma are not much better. I mean, Alex Gleeson, enough said.</p>



<p>The only two relevant pieces of Fedi software are Pleroma and Mastodon. ActivityPub is such a horrible protocol, and Mastodon has butchered it so much, it’s impossible to make an interoperable implementation without man-months of work. To reimplement Mastodon from the ground up would be a nightmare. And forking Mastodon sounds great, but you’re up against a huge pile of technical debt. You could fork Pleroma, but then you’d have to know Elixir (a language few people know).</p>



<p>Also, the last time a major fork happened in Mastodon (aside from Glitch), it was mostly a group of non-developers who hoped they could cult their way into a dev team. It didn’t work.</p>



<p>I wanted to fix this problem but I decided it wasn’t worth it, and you’d have to be up against a community who is watching your every mistake and will find a reason to pillory you if you fuck up.</p>



<h3>“Mastodon” never developed a culture of its own</h3>



<p>You know, if you leave a container of yoghurt out for 4 years, it develops a culture. That’s more than can be said for the Mastodon part of Fedi, which has never outgrown being an offshoot of Twitter and Tumblr.</p>



<p>This is to its detriment, as it’s not a compelling place on the surface. People come in waves, and most leave again when Twitter and Tumblr rights its wrongs. I’ve seen this happen multiple times.</p>



<p>Mastodon users would do well to stop treating Fedi as Twitter, but of course, Mastodon and Pleroma as platforms basically both treat Fedi as Twitter expanded universe. It’s no coincidence <a href="https://techcrunch.com/2021/01/15/twitters-vision-of-decentralization-could-also-be-the-far-rights-internet-endgame/" target="_blank" rel="noreferrer noopener">Gargron has joined Twitter’s federation initative.</a> I have no hopes Fedi will develop a meaningful distinct culture before its too late.</p>



<h3>The tools to protect users are rotten fruit in an opaque bag</h3>



<p><em>Note: this was edited in after the fact. I meant to include it in the original.</em></p>



<p>I’m going to say what many admins lack the bravery or vision to say: the tools to protect the users of Mastodon are inadequate. Pleroma got this better, but many Mastodon users cancel any Pleroma user on sight (as I explain below).</p>



<p>The filtering sucks (it displays “filtered” unless you choose to permanently delete any posts containing a keyword). The default guide for setting up ElasticSearch (the thing that enables search) had (may still have for all I know) no mention of using a firewall or listening only on localhost (Gargron pushed back on requests to mention this), which would enable anyone in theory to connect to …</p></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://sporks.space/2021/02/02/mastodon-really-is-crumbling-and-it-will-only-get-worse/">https://sporks.space/2021/02/02/mastodon-really-is-crumbling-and-it-will-only-get-worse/</a></em></p>]]>
            </description>
            <link>https://sporks.space/2021/02/02/mastodon-really-is-crumbling-and-it-will-only-get-worse/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26011818</guid>
            <pubDate>Wed, 03 Feb 2021 08:47:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Everything you never wanted to know about ANSI escape codes]]>
            </title>
            <description>
<![CDATA[
Score 40 | Comments 11 (<a href="https://news.ycombinator.com/item?id=26011198">thread link</a>) | @brendanfalk
<br/>
February 2, 2021 | https://notes.burke.libbey.me/ansi-escape-codes/ | <a href="https://web.archive.org/web/*/https://notes.burke.libbey.me/ansi-escape-codes/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
<header>

<p>2019-02-13</p>
</header>
<p><strong>See also: <a href="https://ankiweb.net/shared/info/1616925913">Flash cards (Anki deck) for memorization</a></strong></p>
<p>My team writes a lot of command line tools, and we like to assume that people aren’t using a literal <a href="https://en.wikipedia.org/wiki/VT100">VT100</a> (meaning: we liberally use colours, italics, and basically every other terminal feature available to us). This tends to result in strings in our code that look a little like this:</p>
<pre><code>"\x1b[A\r\x1b[K\x1b[1;32mopened \x1b[1;4;34m%s\x1b[0;1;32m in your browser.\x1b[0m\n"</code></pre>
<p>If you’re like most people, your face just melted, but it’s actually really simple. This page is a crash course in what all of these things mean, and how to learn to read and write them effectively.</p>
<h3 id="x1b"><code>\x1b</code></h3>
<p>ANSI escapes always start with <code>\x1b</code>, or <code>\e</code>, or <code>\033</code>. These are all the same thing: they’re just various ways of inserting the byte 27 into a string. If you look at an <a href="http://www.asciitable.com/">ASCII table</a>, <code>0x1b</code> is literally called <code>ESC</code>, and this is basically why.</p>
<h3 id="control-sequences">Control sequences</h3>
<p>The majority of these escape codes start with <code>\x1b[</code>. This pair of bytes is referred to as <code>CSI</code>, or “Control Sequence Introducer”. By and large, a control sequence looks like:</p>
<pre><code>0x1B + "[" + &lt;zero or more numbers, separated by ";"&gt; + &lt;a letter&gt;</code></pre>
<p>It’s helpful to think of it this way: the terminating letter is a function name, and the intervening numbers as function arguments, delimited by semicolons rather than the typical commas.</p>
<p>If you see <code>\x1b[0;1;34m</code>, you can read it like this:</p>
<pre><code>\x1b[  # call a function
0;1;34 # function arguments (0, 1, 34)
m      # function name</code></pre>
<p>In effect, this is <code>m(0, 1, 34)</code>. Similarly, <code>\x1b[A</code> is just <code>A()</code>.</p>
<h3 id="available-functions">Available functions</h3>
<p>So with that mental model—reading escape sequences as function invocations—here’s an abridged documentation of the “standard library”, as it were:</p>
<table>
<colgroup>
<col>
<col>
<col>
<col>
</colgroup>
<thead>
<tr>
<th></th>
<th>name</th>
<th>signature</th>
<th>description&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</th>
</tr>
</thead>
<tbody>
<tr>
<td>A</td>
<td>Cursor Up</td>
<td>(n=1)</td>
<td>Move cursor up by <code>n</code></td>
</tr>
<tr>
<td>B</td>
<td>Cursor Down</td>
<td>(n=1)</td>
<td>Move cursor down by <code>n</code></td>
</tr>
<tr>
<td>C</td>
<td>Cursor Forward</td>
<td>(n=1)</td>
<td>Move cursor forward by <code>n</code></td>
</tr>
<tr>
<td>D</td>
<td>Cursor Back</td>
<td>(n=1)</td>
<td>Move cursor back by <code>n</code></td>
</tr>
<tr>
<td>E</td>
<td>Cursor Next Line</td>
<td>(n=1)</td>
<td>Move cursor to the beginning of the line <code>n</code> lines down</td>
</tr>
<tr>
<td>F</td>
<td>Cursor Previous Line</td>
<td>(n=1)</td>
<td>Move cursor to the beginning of the line <code>n</code> lines up</td>
</tr>
<tr>
<td>G</td>
<td>Cursor Horizontal Absolute</td>
<td>(n=1)</td>
<td>Move cursor to the the column <code>n</code> within the current row</td>
</tr>
<tr>
<td>H</td>
<td>Cursor Position</td>
<td>(n=1, m=1)</td>
<td>Move cursor to row <code>n</code>, column <code>m</code>, counting from the top left corner</td>
</tr>
<tr>
<td>J</td>
<td>Erase in Display</td>
<td>(n=0)</td>
<td>Clear part of the screen. 0, 1, 2, and 3 have various specific functions</td>
</tr>
<tr>
<td>K</td>
<td>Erase in Line</td>
<td>(n=0)</td>
<td>Clear part of the line. 0, 1, and 2 have various specific functions</td>
</tr>
<tr>
<td>S</td>
<td>Scroll Up</td>
<td>(n=1)</td>
<td>Scroll window up by <code>n</code> lines</td>
</tr>
<tr>
<td>T</td>
<td>Scroll Down</td>
<td>(n=1)</td>
<td>Scroll window down by <code>n</code> lines</td>
</tr>
<tr>
<td>s</td>
<td>Save Cursor Position</td>
<td>()</td>
<td>Save current cursor position for use with <code>u</code></td>
</tr>
<tr>
<td>u</td>
<td>Restore Cursor Position</td>
<td>()</td>
<td>Set cursor back to position last saved by <code>s</code></td>
</tr>
<tr>
<td>f</td>
<td>…</td>
<td>…</td>
<td>(same as G)</td>
</tr>
<tr>
<td>m</td>
<td>SGR</td>
<td>(*)</td>
<td>Set graphics mode. More below</td>
</tr>
</tbody>
</table>
<p>For practice, you might try interpreting the following string:</p>
<pre><code>\x1b[3A\x1b[4D\x1b[shello\x1b[J\x1b[1;3Hworld\x1b[u\x1b[13T</code></pre>
<h3 id="sgr">SGR</h3>
<p>The SGR (“Select Graphics Rendition”) function (<code>m</code>) has a much more complex signature than the other functions. An—again, abridged—guide to SGR arguments:</p>
<table>
<colgroup>
<col>
<col>
</colgroup>
<thead>
<tr>
<th>value</th>
<th>name&nbsp;/&nbsp;description&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</th>
</tr>
</thead>
<tbody>
<tr>
<td>0</td>
<td>Reset: turn off all attributes</td>
</tr>
<tr>
<td>1</td>
<td>Bold (or bright, it’s up to the terminal and the user config to some extent)</td>
</tr>
<tr>
<td>3</td>
<td>Italic</td>
</tr>
<tr>
<td>4</td>
<td>Underline</td>
</tr>
<tr>
<td>30–37</td>
<td>Set text colour from the basic colour palette of 0–7</td>
</tr>
<tr>
<td>38;5;<em>n</em></td>
<td>Set text colour to index <code>n</code> in a <a href="https://commons.wikimedia.org/wiki/File:Xterm_256color_chart.svg">256-colour palette</a> (e.g.&nbsp;<code>\x1b[38;5;34m</code>)</td>
</tr>
<tr>
<td>38;2;<em>r</em>;<em>g</em>;<em>b</em></td>
<td>Set text colour to an RGB value (e.g.&nbsp;<code>\x1b[38;2;255;255;0m</code>)</td>
</tr>
<tr>
<td>40–47</td>
<td>Set background colour</td>
</tr>
<tr>
<td>48;5;<em>n</em></td>
<td>Set background colour to index <code>n</code> in a 256-colour palette</td>
</tr>
<tr>
<td>48;2;<em>r</em>;<em>g</em>;<em>b</em></td>
<td>Set background colour to an RGB value</td>
</tr>
<tr>
<td>90–97</td>
<td>Set text colour from the <strong>bright</strong> colour palette of 0–7</td>
</tr>
<tr>
<td>100–107</td>
<td>Set background colour from the <strong>bright</strong> colour palette of 0–7</td>
</tr>
</tbody>
</table>
<p>Multiple SGR arguments can always be concatenated using another <code>;</code>, and they will be applied in the order they are encountered. It’s especially common to see <code>0;</code> before some other argument, in order to reset the state before applying our own.</p>
<h3 id="colour-palettes">Colour Palettes</h3>
<p>The basic colour palette has 8 entries:</p>
<ul>
<li>0: black</li>
<li>1: red</li>
<li>2: green</li>
<li>3: yellow</li>
<li>4: blue</li>
<li>5: magenta</li>
<li>6: cyan</li>
<li>7: white</li>
</ul>
<p>A useful way to help remember this, or at least to select colours for use, is that, with the exception of 0/black, the colours are ordered by usefulness, with highest first: red text is very useful for indicating failures, green is useful for indicating extreme success, yellow for warnings, and then blue, magenta, and cyan for progressively more obscure conditions or decoration.</p>
<p>0 and 7 are less useful for text because one or the other will generally look nearly-unreadable depending on whether the user has a light or a dark background.</p>
<p>Terminals will also have a “bright” version of this palette (activated using 90–97 / 100–107). These are the same (black/red/green/etc.) but generally noticeably brighter than their regular counterparts.</p>
<p>For practice, you might try to figure out how this string would display:</p>
<pre><code>\x1b[38;2;255;255;0mH\x1b[0;1;3;35me\x1b[95ml\x1b[42ml\x1b[0;41mo\x1b[0m</code></pre>
<h3 id="miscellany">Miscellany</h3>
<p>Another pair of useful escapes is <code>\x1b[?25h</code> and <code>\x1b[?25l</code>. These show and hide the cursor, respectively. Try not to think too hard about the syntax here: <code>?25</code> means something to do with the cursor and <code>h</code> and <code>l</code> stand for “high” and “low”: imagine a bit indicating whether the cursor should be visible. The “high” value (1) would indicate “show”; the “low” value (0) would indicate “hide”.</p>
<p>Show/hide is useful when you’re going to draw some stuff that’ll cause the cursor to jump around like crazy, for example, repainting a couple of the last few lines to update them with new content.</p>
<p>One other thing that we use frequently is <code>\r</code>, or Carriage Return, which is functionally similar or identical to <code>\x1b[1G</code>. It just moves the cursor to the start of the line.</p>
<h3 id="summary">Summary</h3>
<p>That was a lot of information, but that’s essentially everything you need to know in order to competently read and write ANSI escape codes in a terminal.</p>
<p>If you want to learn this more thoroughly, <a href="https://ankiweb.net/shared/info/1616925913">I’ve put together a set of flash cards to help</a>.</p>



</div>]]>
            </description>
            <link>https://notes.burke.libbey.me/ansi-escape-codes/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26011198</guid>
            <pubDate>Wed, 03 Feb 2021 06:41:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Lose Money]]>
            </title>
            <description>
<![CDATA[
Score 127 | Comments 45 (<a href="https://news.ycombinator.com/item?id=26010977">thread link</a>) | @maverik
<br/>
February 2, 2021 | https://www.getrevue.co/profile/andrewtye/issues/how-to-lose-money-323332 | <a href="https://web.archive.org/web/*/https://www.getrevue.co/profile/andrewtye/issues/how-to-lose-money-323332">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><!--[if mso | IE]>
<table role="presentation" border="0" cellpadding="0" cellspacing="0"><tr><td style="vertical-align:top;width:600px;">
<![endif]--><div aria-labelledby="mj-column-per-100"><div><div>
      <p><strong>1. Trade Options</strong></p><p><em>Fastest</em></p><p>No doubt you have heard all about how easy it is for people to lose their life savings trading securities in the stock market. But there is actually a much faster way – options. I’m not going to get into the nuts and bolts of trading options (actually, most people who lose money with options don’t understand how they work anyway) but I will give you a quick definition and then show how efficient these instruments-of-wealth-destruction really are.&nbsp;</p><p>There are two types of options – calls and puts. If you buy a call option, you are purchasing the right to but the underlying stock at a specified price. So, you might pay $3,000 dollars for the right to buy 100 shares Microsoft stock at $200 per share. Then, if the stock goes up to $300 you can either buy 100 shares at $200, or you can sell the option to some other idiot and they can use it to buy the shares. But, as you might imagine, that options contract is worth a lot more than $3,000 now, and you can sell it for a premium. This is how leverage works to make money. But we’re concerned about how to use leverage to lose money.&nbsp;</p><p>The nice thing about options is that there isn’t just one way to lose money. No, you can lose money in many different ways – far more than I can write on this page. But, if you’re looking to lose money don’t bother to read up on the different ways to trade options. Just go for it, and I’m certain you will lose everything. I’ll give you a few real-life examples of how I’ve lost money in options. First, buy options that are about ready to expire. In the previous example, if you bought the Microsoft options for $3,000, but the stock went to $195 instead of $300, you could lose all your money. Another easy way to lose money with options is to buy contracts that are way out of the money (OTM). This simply means you might buy Microsoft options that give you the right to buy stock at $200 – except this time, the stock is at $150 per share. If you do this, you won’t find anyone willing to buy the option contract back from you (after all, why would someone pay for the right to buy stock at $200 if it’s already at $150). And if you can’t find anyone to buy the contract from you it will expire worthless and you’ll lose all your money. Another favorite is not cutting your losses. If your contract is losing money (this often happens if you think the stock is going to go up but it goes down) and you want to lose more money, just hold it and don’t sell. Options decay with time so the longer you hold it the more likely it is that you will lose all your money. So, simply hold your position when it starts to go south and you’ll lose way more money.</p><p>Pro tip – Make sure to buy a bunch of contracts (say 10 of them) so you lose $30,000 instead of $3,000.</p><p>I could go on but I think you get the point. I have personally lost thousands of dollars using these methods and would highly recommend them to anyone looking for a fast way to lose it all. I’d recommend you try losing a small amount in stocks first to get your feet wet – then dive into options. If you’re anxious to give it a go, <a href="https://cash.app/app/TDZWWPC?utm_campaign=UA-188825179-1&amp;utm_medium=email&amp;utm_source=Revue%20newsletter" target="_blank">use this link to start trading with Cash App</a> and you’ll get free money to lose right away.</p><p>The only options trader who doesn’t lose money is the one who never starts.</p><p><em>- Andrew Tye</em></p><p><strong>2. Write a Book</strong></p><p><em>Most consistent</em></p><p>You might think writing a book is a great way to make a bunch of cash – and you’d be wrong. In spite of the many books that will tell you how to make money writing a book, I’m here to let you in on a secret –writing a book is actually a fantastic way to lose money. I’ve written four short books and they have literally grossed hundreds of dollars. Now – hearing that I’ve sold some books might make you think you should write one also. But it’s a trap – you will spend hundreds of hours writing a book and then make hundreds of dollars in return. Not sure about you, but if I’m working for $1/hour I’m losing money fast. My latest book probably has more pages than it has copies sold – <a href="https://gum.co/getajob?utm_campaign=UA-188825179-1&amp;utm_medium=email&amp;utm_source=Revue%20newsletter" target="_blank">take a look here</a> if you want a quick reference on how to get a job.</p><p><strong>3. Teach Online Courses</strong></p><p><em>Most helpful</em>&nbsp;</p><p>Aw, I love this one. You can help other people learn a skill and lose your money at the same time. Win-lose. Some folks think they can make a great online course and it will make them a nice living or side income. Most of those nice people are wrong. News flash – more people lose money creating online courses than make money from them. The good news for you is that there really aren’t many barriers to entry here. Get yourself a cheap mic (who needs quality audio anyway) and an inexpensive webcam. And go to town without bothering to make an outline. I’ve found a couple approaches that both work well. Option A - read the script from a piece of paper. Option B – don’t plan at all and just wing the recording.&nbsp;</p><p>This is a strategy that I’ve already proven out for you. I created a few classes online and over the past 5 years they have actually generated thousands of dollars. But net returns are certainly negative because for those thousands of dollars I spent hundreds of hours creating content, answering questions, and buying likes. If you’d like a good idea of what to expect, I have over 40,000 students taking my online courses and they have generated a few thousand in gross revenues.</p><p>Pro tip – make your courses free from the start – you will recoup less of your investment this way, and end up losing quite a bit more overall.</p><p><strong>4. Get a Degree</strong></p><p><em>Most socially acceptable</em></p><p>This tactic is harder to lose money with, but when you lose you lose big. Books and courses are more consistent losers, but they don’t add up as fast as big tuition debt combined with time off work. As mentioned, you do have to be careful with this one because it is possible to get a degree and actually make money. But here is what you do to ensure loss. First, choose a degree that you aren’t passionate about, or that doesn’t have high paying jobs, or that doesn’t really have any jobs (<a href="https://lunarjobs.co/radar?utm_campaign=UA-188825179-1&amp;utm_medium=email&amp;utm_source=Revue%20newsletter" target="_blank">research here</a>). Second, don’t get a side job during school and take all of the student loans you can get your hands on. Third, be very picky about which of the few jobs you take and only take ones that are in fact low paying (high cost of living is also preferred when choosing location). </p><p>Pro tip – fail a few classes to extend your time to graduation – that way you can take on more debt.&nbsp;</p><p>One thing to watch out for is accidentally choosing a degree that can actually make you money. Like engineering or computer science. But even this caution is less important now than when I went to college because places like Lambda School are making four year university degrees more certain losers. I’ve been on both sides of this one. I spent two years studying software development and about 4 years studying engineering. Both of those degrees were inexpensive, I worked part-time while studying, and have made money with both of them. But, thankfully I learned my lesson and managed to lose a lot of money by the time I got an MBA. I could have started a company with the money, or just worked my way up in an engineering role. But by taking on a bunch of debt and forgoing a salary for a couple years I was able to lose way more money than if I’d simply started a company. I think I actually lost more by going to business school than if I’d started a company and lost all of the investors’ money!</p><p><strong>5. Become an Inventor</strong></p><p><em>Most fun</em></p><p>Okay people, this has to be one of the most enjoyable ways to lose money! I have drummed up all sorts of new inventions. Of course, they don’t make any money but that’s sort of the point right! Most of my awesome inventions failed make money because someone else took them to market before me. Other times it was because they were so stupid nobody wanted to buy them (or even look at them actually).</p><p>I’ve invented lots of awesome products that lost money, but here is one of my favorite no-hits:</p><p><em>Barking Bulb</em>: Scare away intruders with a bark</p><p>Don’t want a dog in your backyard? Fine, get a bulb that barks when intruders are detected. Light, motion sensing and sound in one bulb. I thought this was so brilliant. Safe as having a guard dog, but you don’t have to clean up after it. Literally the best of both worlds. Coming soon to a Home Depot near you!&nbsp;</p><p>Pro tip: Go straight for all of the full, non-provisional patents you can before you know if anyone wants the idea. Don’t wait to see if it’s manufacturable. Don’t do market research to see if competitive products exist. Just talk to an attorney and get the patents drawn up. This shortcut will let you lose $20,000 to $40,000 upfront before you even start doing hardcore R&amp;D or go to production.</p><p><strong>6. Do Internet Advertising </strong></p><p><em>Most controversial&nbsp;</em></p><p>Another interesting way to lose money is with online advertising. What I like most about this one is you can lose money consistently and sound smart to your friends at the same time. Where do you spend your money they ask? Oh, I have a website with ads. Wow. That is so cool. What you do is setup a website with some content (e.g. a blog about how to lose money) and you put some ads (from Google AdSense or affiliates) on it that will generate money for you. Then, to get more people to your blog you also buy ads from Google Ads or Facebook. If you do it just right there is arbitrage here – for every dollar you spend buying ads to get traffic to your site you can get 70 cents of income from the ads on your blog. You can consistently lose $0.30 for every $1.00 you spend. The downside is nearly unlimited as long as you pick a topic that has significant search traffic.</p><p>This one is somewhat controversial because a lot of people think that putting ads on your site and then buying other ads to get more traffic is actually a good way to make money. I’ve proven that it’s much easier to lose money with this method than it is to make money. So you can ignore the doubters.</p><p><strong>7. Stop finishing Projects</strong></p><p><em>Biggest loss</em></p><p>I have completely mastered this one. It has a sweet combination of money lost from working for …</p></div></div></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.getrevue.co/profile/andrewtye/issues/how-to-lose-money-323332">https://www.getrevue.co/profile/andrewtye/issues/how-to-lose-money-323332</a></em></p>]]>
            </description>
            <link>https://www.getrevue.co/profile/andrewtye/issues/how-to-lose-money-323332</link>
            <guid isPermaLink="false">hacker-news-small-sites-26010977</guid>
            <pubDate>Wed, 03 Feb 2021 05:53:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Product Manager vs. Product Marketing Manager vs. Product Owner]]>
            </title>
            <description>
<![CDATA[
Score 64 | Comments 35 (<a href="https://news.ycombinator.com/item?id=26010927">thread link</a>) | @DamilolaA
<br/>
February 2, 2021 | https://www.damilolaa.xyz/Product-Manager-vs-Product-Marketing-Manager-vs-Product-Owner | <a href="https://web.archive.org/web/*/https://www.damilolaa.xyz/Product-Manager-vs-Product-Marketing-Manager-vs-Product-Owner">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><div><p>This is a question that often arises in the product world and it requires our time to unpack it. Though these roles are somewhat similar and they work towards achieving the same set of goals, we then ought to look at the clear line distinction in the line of duty of the individuals and performance metric used to evaluate the success achieved by each role to help us understand them better and also help you figure out the most suitable for you.</p><p>These roles vary from company to company as in the case of a startup, a product manager is often tasked with the duty of these 3 roles while in larger or enterprise companies, there are 3 or more different roles in the product team working at different capacities to ensure that the right product is shipped and meet the demands of users.</p><p>While the product manager’s role is one that has come to limelight, the product marketing manager and product owner role have also been adopted by a lot of companies depending on their product and company culture. In this article, we will explain the difference between these roles and the job requirement of the individual involved.</p><h3 id="the-product-manager">The Product Manager</h3><p>These individuals are often referred to as mini CEOs of a product. They conduct customer surveys to figure out the customer’s pain and build solutions to address it. The PM also prioritizes what features are to be built next and prepares and manages a cohesive and digital product roadmap and strategy.</p><h3 id="the-product-marketing-manager">The Product Marketing Manager</h3><p>The PMM communicates vital product value — the “why”, “what” and “when” of a product to intending buyers. He manages the go-to-market strategy/roadmap and also oversees the pricing model of the product. The primary goal of a PMM is to create demand for the products through effective messaging and marketing programs so that the product has a shorter sales cycle and higher revenue.</p><h3 id="the-product-owner">The Product Owner</h3><p>This role exists in a scrum environment — <em><a href="https://www.scrum.org/resources/what-is-scrum" title="Scrum" target="_blank" rel="noreferrer">Scrum</a> is a framework for project management that emphasizes teamwork, accountability, and iterative progress toward a well-defined goal.</em></p><p>A product owner (PO) maximizes the value of a product through the creation and management of the product backlog, creation of user stories for the development team. The product owner is the customer’s representative to the development team. He addresses customer’s pain points by managing and prioritizing a visible product backlog. The PO is the first point of call when the development team needs clarity about interpreting a product feature to be implemented.</p><p><span>
      <span></span>
  <picture>
        <source srcset="https://www.damilolaa.xyz/static/0b33b68ff9b4c94d698dd11d756d6319/06fd5/pm.webp 700w" sizes="(max-width: 700px) 100vw, 700px" type="image/webp">
        <source srcset="https://www.damilolaa.xyz/static/0b33b68ff9b4c94d698dd11d756d6319/f6cdf/pm.png 700w" sizes="(max-width: 700px) 100vw, 700px" type="image/png">
        <img tabindex="0" src="https://www.damilolaa.xyz/static/0b33b68ff9b4c94d698dd11d756d6319/f6cdf/pm.png" alt="Product Manager vs Product Marketing Manager vs Product Owner" title="Photo by Marvin Meyer on Unsplash" loading="lazy">
      </picture>
    </span></p><p>Going more practical, we will use a hypothetical case study of a tech company, Slyde, to explain these roles to clearly understand their day-to-day duties.</p><p>Slyde is a financial technology company based in Lagos, Nigeria with coverage in other African countries. The company has been providing payment solutions through its web-based application but has noticed a large churn rate in areas with poor internet connection which in turn delay users from completing their transaction. The product team made this observation and has been tasked to come up with a solution.</p><h3 id="where-does-the-product-manager-product-marketing-manager-and-the-product-owner-come-in">Where does the Product Manager, Product Marketing Manager, and the Product Owner come in?</h3><p><strong>PM</strong>: The Product Manager will interface with the users through user interviews/feedback surveys or other means to hear directly from the users. They will come up with hypotheses alongside the team and validate them through prototyping and user testing. They will then create a strategy on the feature and align the team and stakeholders around it. The PM who is also the chief custodian of the entire product roadmap will, therefore, be tasked with the duty of prioritization. Before going ahead to carry out research and strategy, they will have to convince the stakeholders if it is a good choice to build the feature in context at that particular time or wait a bit longer based on the content of the roadmap.</p><p><strong>PMM</strong>: The product marketing manager is tasked with market feasibility and discovering if the features being built align with the company’s sales and revenue plan for the period. They also make research on how sought-after the feature is being anticipated and how it will impact the budget. They communicate the values of the feature; the why, what, and when to potential buyers — In this case users in countries with poor internet connection.</p><p><strong>PO</strong>: The product owner will first have to prioritize the backlog to see if there are no important tasks to be executed and if this new feature is worth leaving whatever is being built currently. They will also consider the development effort required to build the feature i.e the time, tools, and skill set that will be required. They will be the one to tell if the expertise of the current developers is enough or if more engineers or designers are needed to be able to deliver at the scheduled time. The product owner is also armed with the task of interpreting the product/feature requirements for the development team. They serve as the interface between the stakeholders and the development team.</p><hr><p>Lastly,</p><p>The goal of a product team is to delight its user by providing an excellent solution to their pain points regardless of the job title/role. Irrespective of your job role on a product team, you should always be driven by user empathy and the company’s goal as this will in-turn make you collaborate better among the team. A product person should first and foremost see themselves as a product leader — one who makes sure the user’s need is always advocated for, despite top executive declination, the product person is to persuasively align the executive to this.</p><blockquote><blockquote><p>Product Owner is a role you play on a Scrum team. Product Manager is the job. — Melissa Perri</p></blockquote></blockquote><p>So, regardless of your job role, a great product person will always act in the stead of a product manager and never streamline herself to the JD only but be actively involved directly or indirectly in every phase of the product development cycle. When the role is clearly understood and the duties implemented collaboratively as a team, every aspect of the product comes together in one beautiful piece.</p><p>This article first appeared on my <a href="https://blog.usejournal.com/product-manager-vs-product-marketing-manager-vs-product-owner-8ab08bc45662" title="Medium" target="_blank" rel="noreferrer">Medium</a></p><p>Thanks to <a href="https://www.linkedin.com/in/olufisayo-babalola/" target="_blank" rel="noreferrer">Olufisayo Babalola</a> for reviewing this article.</p><hr><h3 id="sources">Sources:</h3><ul><li><a href="https://unsplash.com/s/photos/product-manager?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" target="_blank" rel="noreferrer">Hero Image by airfocus on Unsplash</a></li></ul></div></article></div>]]>
            </description>
            <link>https://www.damilolaa.xyz/Product-Manager-vs-Product-Marketing-Manager-vs-Product-Owner</link>
            <guid isPermaLink="false">hacker-news-small-sites-26010927</guid>
            <pubDate>Wed, 03 Feb 2021 05:39:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Sputnik V vaccine peer reviewed with efficacy of 91.6%]]>
            </title>
            <description>
<![CDATA[
Score 66 | Comments 64 (<a href="https://news.ycombinator.com/item?id=26009932">thread link</a>) | @The_rationalist
<br/>
February 2, 2021 | https://sputnikvaccine.com/newsroom/pressreleases/a-vaccine-for-all-mankind-sputnik-v-s-efficacy-in-fighting-covid-19-is-validated-by-internationally-/ | <a href="https://web.archive.org/web/*/https://sputnikvaccine.com/newsroom/pressreleases/a-vaccine-for-all-mankind-sputnik-v-s-efficacy-in-fighting-covid-19-is-validated-by-internationally-/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<ul>
<li>
<p>
In an interim analysis of a Phase III clinical trial, Sputnik V <b>showed strong efficacy, immunogenicity and safety results.</b>
</p>
</li>
<li>
<p>
<b>Efficacy of Sputnik V against COVID-19 was reported at 91.6%.</b>
</p>
<ul>
<li>
<p>
Analysis included data on 19,866 volunteers, who received both the first and second doses of the Sputnik V vaccine or placebo at the final control point of 78 confirmed COVID-19 cases.
</p>
</li>
<li>
<p>
Efficacy in the elderly group of 2,144 volunteers over 60 years old was 91.8% and did not differ statistically from the 18-60 group.
</p>
</li>
</ul>
</li>
<li>
<p>
<b>Sputnik V provides full protection against severe cases of COVID-19.</b>
</p>
</li>
<li>
<p>
<b>Among the cases analyzed, over 98% of volunteers developed humoral immune response and 100% - cellular immune response.</b>
</p>
</li>
<li>
<p>
<b>The level of virus neutralizing antibodies of volunteers vaccinated with Sputnik V is 1.3-1.5 times higher</b> than the level of antibodies of patients who recovered from COVID-19.
</p>
</li>
<li>
<p>
<b>Excellent safety profile. Most adverse events (94%) were mild</b> and included flu-like syndromes, injection site reactions, headache and asthenia.
</p>
<ul>
<li>
<p>
<b>No serious adverse events associated with vaccination, as confirmed by Independent Data Monitoring Committee.</b>
</p>
</li>
<li>
<p>
<b>No strong allergies, no anaphylactic shock.</b>
</p>
</li>
</ul>
</li>
<li>
<p>
<b>Sputnik V is one of the three vaccines in the world with efficacy of over 90%. Furthermore, Sputnik V stands out among these vaccines thanks to a number of key advantages:</b>
</p>
<ul>
<li>
<p>
<b>Based on a platform of human adenoviral vectors proven to be safe over decades of use.</b>
</p>
</li>
<li>
<p>
<b>Easy distribution worldwide: storage temperature of between two and eight degrees Celsius.</b>
</p>
</li>
<li>
<p>
<b>One of the most affordable vaccines in the world with a price of less than $10 per shot.</b>
</p>
</li>
</ul>
</li>
<li>
<p>
<b>Sputnik V is already registered in 16 countries:</b> Russia, Belarus, Serbia, Argentina, Bolivia, Algeria, Palestine, Venezuela, Paraguay, Turkmenistan, Hungary, UAE, Iran, Republic of Guinea, Tunisia and Armenia.
</p>
</li>
<li>
<p>
<b>In the first week of February, vaccination with Sputnik V will start in the following 12 countries:</b> Bolivia, Kazakhstan, Turkmenistan, Palestine, UAE, Paraguay, Hungary, Armenia, Algeria, Bosnian Serb Republic, Venezuela and Iran.
</p>
<ul>
<li>
<p>
<b>In 10 countries out of 12, Sputnik V will be the first coronavirus vaccine approved for civil circulation.</b>
</p>
</li>
</ul>
</li>
</ul>
<p>
<b>Moscow, February 2, 2021</b> – The Gamaleya National Research Center of Epidemiology and Microbiology of the Ministry of Health of the Russian Federation and the Russian Direct Investment Fund (RDIF, Russia’s sovereign wealth fund) announce that the Lancet, one of the world's oldest and most respected medical journals, has published interim results of a Phase III clinical trial of Sputnik V, confirming the vaccine’s high efficacy and safety. Sputnik V, which is based on a well-studied human adenoviral vectors platform, is the world’s first registered vaccine against coronavirus.
</p>
<p>
In the interim efficacy analysis of the randomized, double-blind, placebo-controlled clinical trial, where data on 19,866 volunteers were included in the efficacy analysis (14,964 of whom received the vaccine and 4,902 the placebo), the two-dose treatment of Sputnik V administered 21 days apart demonstrated efficacy of 91.6% against COVID-19. The calculation is based on the analysis of 78 confirmed cases of COVID-19 identified in the placebo group (62 cases) and in the vaccine group (16 cases). Sputnik V generated a robust humoral and cell mediated immune response.
</p>
<p>
<b>Alexander Gintsburg, Director of the Gamaleya Research Institute of Epidemiology and Microbiology,</b> said:
</p>
<p>
“The publication of internationally peer reviewed data on Sputnik V’s clinical trial results is a great success in the global battle against the COVID-19 pandemic. The Russian vaccine’s safety and high efficacy are shown by the hard scientific data presented and I congratulate the entire team of Gamaleya National Research Center for this monumental achievement. Several vaccines have already been created based on human adenoviruses and this tool is one of the most promising for development of new vaccines in the future.”
</p>
<p>
<b>Kirill Dmitriev, CEO of the Russian Direct Investment Fund,</b> commented:
</p>
<p>
“This is a great day in the fight against the COVID-19 pandemic. The data published by The Lancet proves that not only Sputnik V is the world’s first registered vaccine, but also one of the best. It fully protects against severe COVID-19 according to data which has been independently compiled and reviewed by peers and then published in The Lancet. Sputnik V is one of only three vaccines in the world with efficacy of over 90% but outperforms them in terms of safety, ease of transportation due to storage requirements of +2 to +8 degrees and a more affordable price. Sputnik V is a vaccine for all mankind.”
</p>
<p>
<b>Hildegund C.J. Ertl, M.D., Professor, Vaccine &amp; Immunotherapy Center, The Wistar Institute, USA,</b> said:
</p>
<p>
“The vaccine is 100% effective in preventing serious disease or death, which in the end is the most crucial parameter; we can all deal with the sniffles as long as we stay out of the hospital or the graveyard. Even after a single dose of this prime-boost regimen protection against disease was at 87.6%. Sputnik V is thus more effective than the AstraZeneca or Johnson&amp;Johnson. Sputnik V, which, unlike the equally efficacious RNA vaccines of Pfizer and Moderna, can be stored in the fridge, will be of tremendous value to combat the global COVID-19 pandemic.”
</p>
<p>
<b>Cecil Czerkinsky, PhD, M.D., Research Director, National Institute of Health and Medical research (Inserm), France,</b> said:
</p>
<p>
“The interim results of the phase 3 clinical trial of Sputnik V COVID adenovirus vector vaccine are fairly impressive. This vaccine appears to be highly efficacious and immunogenic across age groups. This is clearly good news as this dual formulation vaccine is comparatively easy to manufacture and to deploy amid the anticipated global shortage of vaccines and logistical problems in vaccination roll-out of temperature-sensitive vaccines recently authorized for emergency use.”
</p>
<p>
<b>Omar Sued, President of the Society of infectologists, Argentina,</b> said:
</p>
<p>
“The paper, published in The Lancet, confirms successful results and provides additional information about the efficacy and the safety of this vaccine in different subgroups. From the public health´s point of view, the efficacy of the vaccine was very high. The safety profile was very good. The dissemination of this information is vital for informing the scaling up and rollout of this vaccine worldwide.”
</p>
<p>
<b>David Livermore, Professor of Medical Microbiology at the University of East Anglia, UK,</b> said:
</p>
<p>
“Presently the world needs all the good vaccines that it can get against COVID-19. And these are impressive results: Sputnik V is the first adenovirus vector vaccine to achieve the 90% efficacy seen with the two mRNA vaccines.”
</p>
<p>
According to the peer-reviewed study results, the vaccine provides full protection against severe cases of the novel coronavirus infection. Among the confirmed severe cases of COVID-19, 20 were recorded in the placebo group, while none were recorded in the vaccine group. Due to the time needed for the immune response to develop, in the first week after vaccination there was no significant difference in protection against severe cases of COVID-19 between the vaccine and placebo groups, while in the period from 7 to 14 days the vaccine’s efficacy rose to 50%, in the period from 14 to 21 days to 74.1%, and to 100% from the 21st day, giving full protection against severe cases of the coronavirus.
</p>
<p>
Importantly, the study included 2,144 volunteers over 60 years old with the maximum ages of 87 years (vaccine group) and 84 years (placebo group), showing great safety results for the elder age strata. The vaccine’s efficacy for the elderly was shown at 91.8% and did not differ statistically from the group of 18-60 years old, also demonstrating great safety and immunogenicity results.
</p>
<p>
Sputnik V has demonstrated an excellent safety profile: 70 episodes of serious adverse events (SAE) not related to COVID-19 were recorded in 68 study participants: in 45 volunteers from the vaccine group and 23 volunteers from the placebo group. None of these events were associated with the vaccination as confirmed by Independent Data Monitoring Committee. Most adverse events (94%) were mild and were limited to flu-like syndromes, injection site reactions, headache and asthenia.
</p>
<p>
Sputnik V is one of only three vaccines in the world to have demonstrated efficacy of over 90%. Sputnik V stands out among these vaccines thanks to a number of key advantages, namely: a well-studied and highly efficient human adenoviral vector mechanism proven safe over decades; the vaccine’s low cost in comparison to other approaches; and fewer logistics requirements with a storage temperature of between two to eight degrees Celsius allowing for easier distribution worldwide.
</p>
<p>
The safety of vaccines based on human adenoviruses has been confirmed in more than 75 international publications and more than 250 clinical trials conducted during the past two decades - while the history of use of human adenoviruses in vaccine development started in 1953. Adenovirus vectors are genetically modified viruses of the regular flu that cannot reproduce in a human body. When the Sputnik V vaccine is used, the coronavirus itself does not enter the body as the vaccine only contains genetic information about part of its outer protein coat, the so called "spikes" forming its crown. This completely eliminates the possibility of getting infected as a result of vaccination while also causing the body to generate a stable immune response.
</p>
<p>
In addition, Sputnik V uses two different vectors - based on human adenovirus serotypes Ad5 and Ad26 - in two separate shots, allowing for a more effective defense against the coronavirus than vaccines using the same vector for both shots. By deploying two different vectors, Sputnik V avoids a possible neutralizing effect and generates a durable and longer-lasting immune response.
</p>
<p>
***
</p>
<p>
<b>The …</b></p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://sputnikvaccine.com/newsroom/pressreleases/a-vaccine-for-all-mankind-sputnik-v-s-efficacy-in-fighting-covid-19-is-validated-by-internationally-/">https://sputnikvaccine.com/newsroom/pressreleases/a-vaccine-for-all-mankind-sputnik-v-s-efficacy-in-fighting-covid-19-is-validated-by-internationally-/</a></em></p>]]>
            </description>
            <link>https://sputnikvaccine.com/newsroom/pressreleases/a-vaccine-for-all-mankind-sputnik-v-s-efficacy-in-fighting-covid-19-is-validated-by-internationally-/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26009932</guid>
            <pubDate>Wed, 03 Feb 2021 02:38:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Four books professional developers should read (and a few you don't need to)]]>
            </title>
            <description>
<![CDATA[
Score 26 | Comments 6 (<a href="https://news.ycombinator.com/item?id=26007626">thread link</a>) | @eatonphil
<br/>
February 2, 2021 | https://notes.eatonphil.com/books-developers-should-read.html | <a href="https://web.archive.org/web/*/https://notes.eatonphil.com/books-developers-should-read.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <div>
        <p>These are the books I recommend to developers wanting to improve their
skills as professional programmers because of high information
density, believable premises/examples, and being well edited.</p>
<p>You don't need to read books to improve as a developer but
they are unparalleled in quickly helping you gain depth in a subject.</p>
<h3 id="effective-python:-90-specific-ways-to-write-better-python">Effective Python: 90 Specific Ways to Write Better Python</h3><p>If you're a Python developer wanting to improve your craft you should
read this. Good Python starts with a deep understanding of the
standard library and language.</p>
<h3 id="high-performance-browser-networking">High Performance Browser Networking</h3><p>If your code is triggered by a desktop or mobile browser you should
read this. It is a thorough high level introduction to mobile
networks, browser network protocols, and fundementals of networking.</p>
<h3 id="designing-data-intensive-applications">Designing Data-Intensive Applications</h3><p>If your databases and APIs are a bottleneck you should read this. A
solid introduction to distributed computing, data transfer, indexing,
etc.</p>
<h3 id="site-reliability-engineering:-how-google-runs-production-services">Site Reliability Engineering: How Google Runs Production Services</h3><p>If you are responsible for services in production you should read
this. It's Google specific but is an excellent background on practices
for monitoring and maintaining production environments.</p>
<h3 id="that's-it!">That's it!</h3><p>Generic software books conspicuously not on this list for
me:</p>
<ul>
<li>Clean Code</li>
<li>JavaScript the Good Parts</li>
<li>Design Patterns/Gang of Four</li>
<li>Structure and Interpretation of Computer Programs</li>
<li>A Philosophy of Software Design</li>
</ul>
<p>They're not all bad but give nowhere near as much return for the
investment of your time.</p>
<h4 id="feedback">Feedback</h4><p>As always, I'd love to <a href="mailto:me@eatonphil.com">hear from you</a> with
questions or ideas.</p>
<blockquote><p lang="en" dir="ltr">Four books I recommend to professional developers wanting to improve their craft, and a few I'd not<a href="https://t.co/1aTrfqZ9bd">https://t.co/1aTrfqZ9bd</a></p>— Phil Eaton (@phil_eaton) <a href="https://twitter.com/phil_eaton/status/1356391931274756096?ref_src=twsrc%5Etfw">February 2, 2021</a></blockquote> 

      </div>
    </div></div>]]>
            </description>
            <link>https://notes.eatonphil.com/books-developers-should-read.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26007626</guid>
            <pubDate>Tue, 02 Feb 2021 22:13:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Silence Is a Commons (1983)]]>
            </title>
            <description>
<![CDATA[
Score 63 | Comments 7 (<a href="https://news.ycombinator.com/item?id=26007100">thread link</a>) | @cardamomo
<br/>
February 2, 2021 | http://www.davidtinapple.com/illich/1983_silence_commons.html | <a href="https://web.archive.org/web/*/http://www.davidtinapple.com/illich/1983_silence_commons.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
			<div><span size="+2">Silence is a Commons by Ivan Illich</span><p>
						
						Computers are doing to communication<br>
						what fences did to pastures<br>
						and cars did to streets.</p><p>
						
						by Ivan Illich</p><p>
						
						
						
						
						Minna-san, gladly I accept the honour of addressing this forum on Science and Man. The theme that Mr. Tsuru proposes, "The Computer-Managed Society," sounds an alarm. Clearly you foresee that machines which ape people are tending to encroach on every aspect of people's lives, and that such machines force people to behave like machines. The new electronic devices do indeed have the power to force people to "communicate" with them and with each other on the terms of the machine. Whatever structurally does not fit the logic of machines is effectively filtered from a culture dominated by their use.</p><p>
						
						The machine-like behaviour of people chained to electronics constitutes a degradation of their well-being and of their dignity which, for most people in the long run, becomes intolerable. Observations of the sickening effect of programmed environments show that people in them become indolent, impotent, narcissistic and apolitical. The political process breaks down, because people cease to be able to govern themselves; they demand to be managed.</p><p>
						
						I congratulate Asahi Shimbun on its efforts to foster a new democratic consensus in Japan, by which your more than seven million readers become aware of the need to limit the encroachment of machines on the style of their own behaviour. It is important that precisely Japan initiate such action. Japan is looked upon as the capital of electronics; it would be marvellous if it became for the entire world the model of a new politics of self-limitation in the field of communication, which, in my opinion, is henceforth necessary if a people wants to remain self-governing.</p><p>
						
						Electronic management as a political issue can be approached in several ways. I propose, at the beginning of this public consultation, to approach the issue as one of political ecology. Ecology, during the last ten years, has acquired a new meaning. It is still the name for a branch of professional biology, but the term now increasingly serves as the label under which a broad, politically organized general public analyzes and influences technical decisions. I want to focus on the new electronic management devices as a technical change of the human environment which, to be benign, must remain under political (and not exclusively expert) control. I have chosen this focus for my introduction, because I thus continue my conversation with those three Japanese colleagues to whom I owe what I know about your country - Professors Yoshikazu Sakamoto, Joshiro Tamanoi and Jun Ui.</p><p>
						
						In the 13 minutes still left to me on this rostrum I will clarify a distinction that I consider fundamental to political ecology. I shall distinguish the environment as commons from the environment as resource. On our ability to make this particular distinction depends not only the construction of a sound theoretical ecology, but also - and more importantly - effective ecological jurisprudence Minna-san, how I wish, at this point, that I were a pupil trained by your Zen poet, the great Basho. Then perhaps in a bare 17 syllables I could express the distinction between the commons within which people's subsistence activities are embedded, and resources that serve for the economic production of those commodities on which modem survival depends. If I were a poet, perhaps I would make this distinction so beautifully and incisively that it would penetrate your hearts and remain unforgettable. Unfortunately I am not a Japanese poet. I must speak to you in English, a language that during the last 100 years has lost the ability to make this distinction, and - in addition - I must speak through translation. Only because I may count on the translating genius of Mr. Muramatsu do I dare to recover Old English meanings with a talk in Japan.</p><p>
						
						"Commons" is an Old English word. According to my Japanese friends, it is quite close to the meaning that iriai still has in Japanese "Commons," like iriai, is a word which, in preindustrial times, was used to designate certain aspects of the environment. People called commons those parts of the environment for which customary law exacted specific forms of community respect. People called commons that part of the environment which lay beyond their own thresholds and outside of their own possessions, to which, however, they had recognized claims of usage, not to produce commodities but to provide for the subsistence of their households. The customary law which humanized the environment by establishing the commons was usually unwritten. It was unwritten law not only because people did not care to write it down, but because what it protected was a reality much too complex to fit into paragraphs. The law of the commons regulates the right of way, the right to fish and to hunt, to graze, and to collect wood or medicinal plants in the forest.</p><p>
						
						An oak tree might be in the commons. Its shade, in summer, is reserved for the shepherd and his flock; its acorns are reserved for the pigs of the neighbouring peasants; its dry branches serve as fuel for the widows of the village; some of its fresh twigs in springtime are cut as ornaments for the church - and at sunset it might be the place for the village assembly. When people spoke about commons, iriai, they designated an aspect of the environment that was limited, that was necessary for the community's survival, that was necessary for different groups in different ways, but which, in a strictly economic sense, was not perceived as scarce.</p><p>
						
						When today, in Europe, with university students I use the term "commons" (in German Almende or Gemeinheit, in Italian gli usi civici) my listeners immediately think of the eighteenth century. They think of those pastures in England on which villagers each kept a few sheep, and they think of the "enclosure of the pastures" which transformed the grassland from commons into a resource on which commercial flocks could be raised. Primarily, however, my students think of the innovation of poverty which came with enclosure: of the absolute impoverishment of the peasants, who were driven from the land and into wage labour, and they think of the commercial enrichment of the lords.</p><p>
						
						In their immediate reaction, my students think of the rise of a new capitalist order. Facing that painful newness, they forget that enclosure also stands for something more basic. The enclosure of the commons inaugurates a new ecological order: Enclosure did not just physically transfer the control over grasslands from the peasants to the lord. Enclosure marked a radical change in the attitudes of society towards the environment. Before, in any juridical system, most of the environment had been considered as commons from which most people could draw most of their sustenance without needing to take recourse to the market. After enclosure, the environment became primarily a resource at the service of "enterprises" which, by organizing wage-labor, transformed nature into the goods and services on which the satisfaction of basic needs by consumers depends. This transformation is in the blind spot of political economy.</p><p>
						
						This change of attitudes can be illustrated better if we think about roads rather than about grasslands. What a difference there was between the new and the old parts of Mexico City only 20 years ago. In the old parts of the city the streets were true commons. Some people sat on the road to sell vegetables and charcoal. Others put their chairs on the road to drink coffee or tequila. Others held their meetings on the road to decide on the new headman for the neighbourhood or to determine the price of a donkey. Others drove their donkeys through the crowd, walking next to the heavily loaded beast of burden; others sat in the saddle. Children played in the gutter, and still people walking could use the road to get from one place to another.</p><p>
						
						Such roads were not built for people. Like any true commons, the street itself was the result of people living there and making that space liveable. The dwellings that lined the roads were not private homes in the modern sense - garages for the overnight deposit of workers. The threshold still separated two living spaces, one intimate and one common. But neither homes in this intimate sense nor streets as commons survived economic development.</p><p>
						
						In the new sections of Mexico City, streets are no more for people. They are now roadways for automobiles, for buses, for taxis, cars, and trucks. People are barely tolerated on the streets unless they are on their way to a bus stop. If people now sat down or stopped on the street, they would become obstacles for traffic, and traffic would be dangerous to them. The road has been degraded from a commons to a simple resource for the circulation of vehicles. People can circulate no more on their own. Traffic has displaced their mobility. They can circulate only when they are strapped down and are moved. </p><p>
						
						The appropriation of the grassland by the lords was challenged, but the more fundamental transformation of grassland (or of roads) from commons to resource has happened, until recently, without being subjected to criticism. The appropriation of the environment by the few was clearly recognized as an intolerable abuse By contrast, the even more degrading transformation of people into members of an industrial labour force and into consumers was taken, until recently, for granted. For almost a hundred years the majority of political parties has challenged the accumulation of environmental resources in private hands. However, the issue was argued in terms of the private utilization of these resources, not the distinction of commons. Thus …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://www.davidtinapple.com/illich/1983_silence_commons.html">http://www.davidtinapple.com/illich/1983_silence_commons.html</a></em></p>]]>
            </description>
            <link>http://www.davidtinapple.com/illich/1983_silence_commons.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26007100</guid>
            <pubDate>Tue, 02 Feb 2021 21:35:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Engineering productivity can be measured, just not how you'd expect]]>
            </title>
            <description>
<![CDATA[
Score 135 | Comments 88 (<a href="https://news.ycombinator.com/item?id=26005758">thread link</a>) | @tomasrb
<br/>
February 2, 2021 | https://www.okayhq.com/blog/engineering-productivity-can-be-measured | <a href="https://web.archive.org/web/*/https://www.okayhq.com/blog/engineering-productivity-can-be-measured">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p>From each of our <a href="https://www.linkedin.com/in/antoineboulanger/" rel="nofollow noopener noreferrer" target="_blank">two</a>  <a href="https://www.linkedin.com/in/tomasrb/" rel="nofollow noopener noreferrer" target="_blank">experiences</a> starting out as introductory-level engineers at Box, to becoming first-time managers overseeing five-person teams, then directors overseeing 30-50, and ultimately VPs managing hundreds, we've experienced software engineering from every angle.</p>
<p>At every step of the way, we asked ourselves: "how do we know if we are bringing value as engineering leaders?" Effective leadership uniquely blends human qualities - influence, empathy, courage, and <strong>results</strong>. This latter quality always brings the question of productivity - how effective are you at producing results through enabling others?</p>
<p>Since the advent of the software industry, most engineering teams have seen productivity as a black box. Only recently have people even begun to build internal tools that optimize performance. Unfortunately, most of these tools measure the wrong metrics and are shockingly similar across companies. We even built some of these tools and made mistakes. Now, we'd like to share the way forward.Â&nbsp;</p>
<h2 id="engineering-effectiveness-is-behind-the-times">Engineering Effectiveness is Behind the TimesÂ&nbsp;</h2>
<p>Engineering teams are both the most expensive and most fundamental part of tech companies. As <a href="https://www.wsj.com/articles/every-company-is-now-a-tech-company-1543901207" rel="nofollow noopener noreferrer" target="_blank">more companies become tech-enabled</a>, the importance of engineering will only increase. Yet today, a full three decades after the advent of the internet, most engineering departments still rely exclusively on qualitative signals of performance.</p>
<p><strong>The evolution of engineering effectiveness is paralleling the spirit of sales' recent transformation</strong>. In the early 2000s, sales was considered an art, so sales leaders could skate by on charisma alone. Today, with tools like <a href="https://www.salesforce.com/" rel="nofollow noopener noreferrer" target="_blank">Salesforce</a>, <a href="https://www.clari.com/" rel="nofollow noopener noreferrer" target="_blank">Clari</a>, and <a href="https://people.ai/get-demo/?utm_campaign=demorequest&amp;utm_source=google&amp;utm_medium=ppc&amp;utm_term=se-goog-1089&amp;utm_content=demorequest&amp;gclid=CjwKCAiAxp-ABhALEiwAXm6Iye9qQZaeojCPMvXn73zi-TRqbT93l7waQz3_uSadhOtpXncm8OLtvBoClTkQAvD_BwE" rel="nofollow noopener noreferrer" target="_blank">People.ai</a>, sales has fully executed the transition toward scientific, metric-based leadership for analyzing and improving performance.</p>
<p>In the coming years, engineering will adopt a similar, data-driven mode of management. In making this transition, however, most engineering teams are making these mistakes:</p>
<h3 id="mistake-1-measuring-approximations-of-output">Mistake #1: Measuring Approximations of Output</h3>
<p>In their haste to become more data-driven, many engineering leaders are measuring their team's performance based on metrics intended to approximate output. <strong>These metrics fail because they encourage engineers to game the system.</strong></p>
<p>If you measure a fixed metric like lines of code or number of tickets closed, your engineers will begin splitting code into more lines or breaking bug fixes into multiple tickets. Even sprint points, which attempt to convert engineering work into a standard unit, suffer from this pitfall: Some engineers will slow down after reaching their sprint points for the week while others will strategically inflate their tasks to be awarded additional points.</p>
<p><strong>Experienced engineers will recognize that this type of measurement is fake</strong>. While they may not be as influenced to "play the game," their morale will plummet and they will self-select out. By rewarding approximated metrics of output, you're encouraging engineers to increase them regardless of how they correlate with software development success.</p>
<blockquote>
<p>No matter which metrics you choose, abstract output approximations will distract engineers from their actual jobs, ultimately decreasing both your team's effectiveness and morale.</p>
</blockquote>
<h3 id="mistake-2-not-measuring-anything">Mistake #2: Not Measuring Anything</h3>
<p>On the other end of the spectrum sit engineering leaders who avoid measurement entirely. Many of these leaders have heard about the dangers of measuring the wrong metrics and therefore <strong>ricochet to the other extreme</strong>. They may emphasize the artisanal and social dimensions of engineering, claiming "software engineering is too complex to measure."</p>
<p>Non-measurement can even be self-reinforcing, because it places the leader into the position of being "the good guy." Instead of being a metrics-obsessed big brother, the leader can be the <strong>friendly older brother exclusively focused on keeping their team happy</strong>.</p>
<p><strong>Non-measurement fails because it prioritizes politics over productivity.</strong> If you don't measure any metrics, your engineering leaders will simply justify failures, telling stories like "The customer didn't give us the right requirements" or "We were surprised by unexpected vacations." Software development is complex enough that something always goes wrong; if you don't measure any data, you're at the mercy of individual stories.</p>
<blockquote>
<p>Non-measurement unfairly rewards people with charisma while productive but less-persuasive engineers wallow in frustration.</p>
</blockquote>
<p>At some point, your top performers will see through these political machinations and quit because your culture lacks accountability.</p>
<p>In the short term, non-measurement can have a positive effect on team morale but it destroys morale in the long-term, especially among high performers.Â&nbsp;</p>
<h2 id="the-solution-measure-blockers-at-the-team-level">The Solution: Measure Blockers at the Team LevelÂ&nbsp;</h2>
<p>Instead of measuring some approximation of engineering output, software teams should measure actual, observable metrics that directly correlate to effectiveness.</p>
<p>Productivity is a relationship between inputs and output. In software development, the inputs are a blend of factors--technical, individual, human, etc.--while the output should be functional software that creates value for customers. <strong>Productivity in engineering therefore naturally increases when you remove the blockers getting in the way of your team.</strong></p>
<h3 id="why-you-should-measure-blockers">Why You Should Measure Blockers</h3>
<p>Even at the beginning of the software revolution, there existed the notion that engineers should be nurtured. Starting with Microsoft in the '80s, tech companies gave engineers free resources (like <a href="https://www.businessinsider.com/free-food-silicon-valley-tech-employees-apple-google-facebook-2018-7#google-has-so-much-free-food-employees-worry-about-gaining-the-google-15-4" rel="nofollow noopener noreferrer" target="_blank">food</a> and <a href="https://www.businessinsider.com/companies-amazing-health-and-fitness-benefits-2019-8" rel="nofollow noopener noreferrer" target="_blank">gyms</a>) that would remove blockers to their work. Empirical management practices over the last forty years have reinforced the importance of "<a href="https://www.axelos.com/news/blogs/january-2020/the-importance-of-servant-leadership" rel="nofollow noopener noreferrer" target="_blank">servant leadership</a>" and "<a href="https://www.mugo.ca/Blog/The-most-important-web-project-management-skill-the-ability-to-unblock-others" rel="nofollow noopener noreferrer" target="_blank">unblocking your team</a>," while <a href="https://puppet.com/resources/report/2020-state-of-devops-report/" rel="nofollow noopener noreferrer" target="_blank">recent research</a> emphasizes the importance of optimized inputs and best practices.</p>
<p>For engineers, these inputs include:</p>
<ul>
<li>Quality of developer tools</li>
<li>Frequency and quality of internal activities (like meetings or code reviews)Â&nbsp;</li>
<li>Focused <a href="http://www.paulgraham.com/makersschedule.html" rel="nofollow noopener noreferrer" target="_blank">maker time</a> (free from disruptive meetings)</li>
<li>Easy access to documentation</li>
<li>Psychological safety on the team</li>
<li>Work-life balance</li>
<li>Presence of other high-performersÂ&nbsp;</li>
<li>A fair system of rewards</li>
</ul>
<p>The blockers to these inputs already exist and can be quantified, such as:</p>
<ul>
<li>How much free, uninterrupted time does an engineer have to code?</li>
<li>How long is an engineer waiting on a response from another engineer's review?</li>
<li>How often do dev tools get in the way instead of helping accelerate work?Â&nbsp;</li>
<li>How often are engineers required to <a href="https://en.wikipedia.org/wiki/Context_switch" rel="nofollow noopener noreferrer" target="_blank">context switch</a>, preventing <a href="https://www.calnewport.com/books/deep-work/" rel="nofollow noopener noreferrer" target="_blank">deep work</a>?</li>
<li>How often do engineers receive pages outside of business hours, interrupting their sleep or family life?</li>
</ul>
<p><strong>An engineering leader exists to enable their team to achieve their goals.</strong> Together, these quantified blockers allow engineering leaders to answer key questions like:</p>
<ul>
<li>What is preventing the engineers from building faster?</li>
<li>What issues are arising in real time?Â&nbsp;Â&nbsp;</li>
<li>What technology or process investments would increase team engagement?</li>
</ul>
<p>Each engineering team is unique, so its blockers will be specific. It's not so simple as "more maker time is better." If your engineering team is new or temporarily misaligned on key goals, more meeting time might be the answer. What never changes is the need for measurement and well-considered, deliberate decisions.</p>
<p>Over the last year, COVID-19 has helped demonstrate the value of measuring blockers. For many leaders running newly remote teams, <a href="https://www.ventureharbour.com/remote-work-challenges-solutions/" rel="nofollow noopener noreferrer" target="_blank">new blockers have arisen</a> that would never have been noticed if managers were only focusing on the desired outcome.</p>
<blockquote>
<p>If your team is full of competent, driven engineers, removing their blockers is the fastest way to enable forward movement.</p>
</blockquote>
<h3 id="why-team-is-the-right-level-to-improve">Why "Team" is the Right Level to Improve</h3>
<p>Since software development requires complex interaction between team members, it would be inappropriate to assign individuals their own metrics: Some engineers are effective individual contributors while others enable their teammates to perform. Engineers also <a href="https://techcrunch.com/2020/12/02/okay-nabs-funding-from-sequoia-to-build-performance-dashboards-for-engineering-managers/" rel="nofollow noopener noreferrer" target="_blank">hate being micromanaged</a>, so tracking individual activity can make them feel untrusted.</p>
<p><strong>Just as a sports team wins or loses together, so too should the engineering team be treated as the fundamental unit of success.</strong></p>
<p>Approaching engineering at the team level also places the proper accountability on the manager. It raises helpful questions like "What behaviors, structures, and work habits are preventing us from succeeding?"</p>
<p>Looking at the team level also enables managers to catch blockers as they evolve. Small issues, for instance, may not be apparent when the company is young, but can evolve into 10,000 papercuts only apparent at the team level. If code reviews take days instead of hours, at first one engineer complains, then two, then three... and if you don't pay attention, years later the engineering culture is shot. By compiling these small quantifications and observing their trends, a manager can understand whether a report is one individual's experience or truly relevant to the overall performance of the team.</p>
<p>Perhaps most important, if blockers follow a constant evolution (e.g. one person is often the canary in the coalmine), an engineering leader can map how the new blockers are likely to evolve and prioritize which should be solved first.</p>
<p>Just as an airplane pilot must monitor dozens of different metrics to keep the plane flying, so too would an engineering leader benefit from viewing their team's metrics to understand overall performance.</p>
<blockquote>
<p>In an optimal engineering dashboard, a leader would be able to assess the blockers that prevent the ultimate success of their team.Â&nbsp;</p>
</blockquote>
<h2 id="toward-engineering-effectiveness">Toward Engineering EffectivenessÂ&nbsp;</h2>
<p>"Productivity" is an appropriate measure for someone making widgets at a factory: "How many products did you produce in an hour?"</p>
<p>Engineering should instead be about effectiveness: "How able is this engineer to effect positive impact?"</p>
<p>Looking forward, engineering effectiveness will have three parts:</p>
<ol>
<li>Measuring the experience of engineering teams in their most frequent activities. (Think<a href="https://www.scalyr.com/blog/distributed-tracing-important-2019/" rel="nofollow noopener noreferrer" target="_blank"> distributed tracing</a>, but for human activities.)</li>
<li>Using the …</li></ol></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.okayhq.com/blog/engineering-productivity-can-be-measured">https://www.okayhq.com/blog/engineering-productivity-can-be-measured</a></em></p>]]>
            </description>
            <link>https://www.okayhq.com/blog/engineering-productivity-can-be-measured</link>
            <guid isPermaLink="false">hacker-news-small-sites-26005758</guid>
            <pubDate>Tue, 02 Feb 2021 19:57:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Bad TypeScript Habits]]>
            </title>
            <description>
<![CDATA[
Score 221 | Comments 215 (<a href="https://news.ycombinator.com/item?id=26005330">thread link</a>) | @jgwil2
<br/>
February 2, 2021 | https://startup-cto.net/10-bad-typescript-habits-to-break-this-year/ | <a href="https://web.archive.org/web/*/https://startup-cto.net/10-bad-typescript-habits-to-break-this-year/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
            <!--kg-card-begin: markdown--><p>TypeScript and JavaScript have steadily evolved over the last years, and some of the habits we built over the last decades have become obsolete. Some might never have been meaningful. Here's a list of 10 habits that we all should break.</p>
<p>If you are interested in more articles and news about web product development and entrepreneurship, please feel free to <a href="https://twitter.com/intent/follow?original_referer=https%253A%252F%252Fstartup-cto.net%252F&amp;ref_src=twsrc%5Etfw&amp;region=follow_link&amp;screen_name=The_Startup_CTO&amp;tw_p=followbutton">follow me on Twitter</a>.</p>
<p>Onto the examples! Please note that each "What it should look like" only fixes the issue discussed, even if there are further code smells that should be addressed.</p>
<h2 id="1notusingstrictmode">1. Not using <code>strict</code> mode</h2>
<h3 id="whatitlookslike">What it looks like</h3>
<p>Using a <code>tsconfig.json</code> without strict mode.</p>
<pre><code>{
  "compilerOptions": {
    "target": "ES2015",
    "module": "commonjs"
  }
}
</code></pre>
<h3 id="whatitshouldlooklike">What it should look like</h3>
<p>Just enable <code>strict</code> mode:</p>
<pre><code>{
  "compilerOptions": {
    "target": "ES2015",
    "module": "commonjs",
    "strict": true
  }
}
</code></pre>
<h3 id="whywedoit">Why we do it</h3>
<p>Introducing stricter rules in an existing codebase takes time.</p>
<h3 id="whyweshouldnt">Why we shouldn't</h3>
<p>Stricter rules will make it easier to change code in the future, so the time spent on fixing the code is returned and then some when working on the repository in the future.</p>
<h2 id="2definingdefaultvalueswith">2. Defining default values with <code>||</code></h2>
<h3 id="whatitlookslike">What it looks like</h3>
<p>Falling back with <code>||</code> for optional values:</p>
<pre><code>function createBlogPost (text: string, author: string, date?: Date) {
  return {
    text: text,
    author: author,
    date: date || new Date()
  }
}
</code></pre>
<h3 id="whatitshouldlooklike">What it should look like</h3>
<p>Use the new <code>??</code> operator, or, even better, define the fallback right at the parameter level.</p>
<pre><code>function createBlogPost (text: string, author: string, date: Date = new Date())
  return {
    text: text,
    author: author,
    date: date
  }
}
</code></pre>
<h3 id="whywedoit">Why we do it</h3>
<p>The <code>??</code> operator has just been introduced last year, and when using values in the middle of a long function it might be hard to set them already as parameter defaults.</p>
<h3 id="whyweshouldnt">Why we shouldn't</h3>
<p><code>??</code>, unlike <code>||</code>, falls back only for <code>null</code> or <code>undefined</code>, not for all falsy values. Also, if your functions are so long that you cannot define defaults at the beginning, then splitting them might be a good idea.</p>
<h2 id="3usinganyastype">3. Using <code>any</code> as type</h2>
<h3 id="whatitlookslike">What it looks like</h3>
<p>Using <code>any</code> for data when you are unsure about the structure.</p>
<pre><code>async function loadProducts(): Promise&lt;Product[]&gt; {
  const response = await fetch('https://api.mysite.com/products')
  const products: any = await response.json()
  return products
}
</code></pre>
<h3 id="whatitshouldlooklike">What it should look like</h3>
<p>In almost every situation where you type something as <code>any</code>, you should type it as <code>unknown</code> instead.</p>
<pre><code>async function loadProducts(): Promise&lt;Product[]&gt; {
  const response = await fetch('https://api.mysite.com/products')
  const products: unknown = await response.json()
  return products as Product[]
}
</code></pre>
<h3 id="whywedoit">Why we do it</h3>
<p><code>any</code> is convenient, as it basically disables all type-checks. Often, <code>any</code> is used even in official typings (e. g. <code>response.json()</code> from the example above is typed as <code>Promise&lt;any&gt;</code> by the TypeScript team).</p>
<h3 id="whyweshouldnt">Why we shouldn't</h3>
<p>It basically disables all type-checks. Anything that comes in via <code>any</code> will completely forego any type-checks. This leads to hard to catch bugs, as code will fail only when our assumptions about type structure are relevant to the runtime code.</p>
<h2 id="4valassometype">4. <code>val as SomeType</code></h2>
<h3 id="whatitlookslike">What it looks like</h3>
<p>Forcefully telling the compiler about a type that it cannot infer.</p>
<pre><code>async function loadProducts(): Promise&lt;Product[]&gt; {
  const response = await fetch('https://api.mysite.com/products')
  const products: unknown = await response.json()
  return products as Product[]
}
</code></pre>
<h3 id="whatitshouldlooklike">What it should look like</h3>
<p>That's what type guards are for.</p>
<pre><code>function isArrayOfProducts (obj: unknown): obj is Product[] {
  return Array.isArray(obj) &amp;&amp; obj.every(isProduct)
}

function isProduct (obj: unknown): obj is Product {
  return obj != null
    &amp;&amp; typeof (obj as Product).id === 'string'
}

async function loadProducts(): Promise&lt;Product[]&gt; {
  const response = await fetch('https://api.mysite.com/products')
  const products: unknown = await response.json()
  if (!isArrayOfProducts(products)) {
    throw new TypeError('Received malformed products API response')
  }
  return products
}
</code></pre>
<h3 id="whywedoit">Why we do it</h3>
<p>When converting from JavaScript to TypeScript, the existing codebase often makes assumptions about types that cannot be deduced automatically by the TypeScript compiler. In these cases, throwing in a quick <code>as SomeOtherType</code> can speed up the conversion without having to loosen the settings in tsconfig.</p>
<h3 id="whyweshouldnt">Why we shouldn't</h3>
<p>Even if the assertion might be save right now, this might change when someone moves code around. The type guard will ensure that all checks are explicit.</p>
<h2 id="5asanyintests">5. <code>as any</code> in tests</h2>
<h3 id="whatitlookslike">What it looks like</h3>
<p>Creating incomplete stand-ins when writing tests.</p>
<pre><code>interface User {
  id: string
  firstName: string
  lastName: string
  email: string
}

test('createEmailText returns text that greats the user by first name', () =&gt; {
  const user: User = {
    firstName: 'John'
  } as any
  
  expect(createEmailText(user)).toContain(user.firstName)
}
</code></pre>
<h3 id="whatitshouldlooklike">What it should look like</h3>
<p>If you need to mock data for your tests, move the mocking logic next to the thing you mock and make it reusable.</p>
<pre><code>interface User {
  id: string
  firstName: string
  lastName: string
  email: string
}

class MockUser implements User {
  id = 'id'
  firstName = 'John'
  lastName = 'Doe'
  email = 'john@doe.com'
}

test('createEmailText returns text that greats the user by first name', () =&gt; {
  const user = new MockUser()

  expect(createEmailText(user)).toContain(user.firstName)
}
</code></pre>
<h3 id="whywedoit">Why we do it</h3>
<p>When writing tests in a codebase that doesn't have great test coverage yet, there are often complicated big data structures, but only parts of it are needed for the specific functionality under test. Not having to worry about the other properties is easier in the short term.</p>
<h3 id="whyweshouldnt">Why we shouldn't</h3>
<p>Foregoing the creation of a mock will bite us, latest when one of the properties changes and we need to change it in all tests instead of one central location. Also, there will be situations where the code under test relies on properties that we did not deem important before, and then all tests for that functionality need to be updated.</p>
<h2 id="6optionalproperties">6. Optional properties</h2>
<h3 id="whatitlookslike">What it looks like</h3>
<p>Marking properties as optional that are sometimes there and sometimes not.</p>
<pre><code>interface Product {
  id: string
  type: 'digital' | 'physical'
  weightInKg?: number
  sizeInMb?: number
}
</code></pre>
<h3 id="whatitshouldlooklike">What it should look like</h3>
<p>Explicitly model which combinations exist and which don't.</p>
<pre><code>interface Product {
  id: string
  type: 'digital' | 'physical'
}

interface DigitalProduct extends Product {
  type: 'digital'
  sizeInMb: number
}

interface PhysicalProduct extends Product {
  type: 'physical'
  weightInKg: number
}
</code></pre>
<h3 id="whywedoit">Why we do it</h3>
<p>Marking properties as optional instead of splitting out types is easier and produces less code. It also requires a deeper understanding of the product being build and might limit usage of code if assumptions about the product change.</p>
<h3 id="whyweshouldnt">Why we shouldn't</h3>
<p>The big benefit of type systems is that they can replace runtime checks with compile-time checks. With more explicit typing, it is possible to get compile-time checks for bugs that otherwise might have gotten unnoticed, e. g. by making sure that every <code>DigitalProduct</code> has a <code>sizeInMb</code>.</p>
<h2 id="7onelettergenerics">7. One letter generics</h2>
<h3 id="whatitlookslike">What it looks like</h3>
<p>Naming a generic with one letter</p>
<pre><code>function head&lt;T&gt; (arr: T[]): T | undefined {
  return arr[0]
}
</code></pre>
<h3 id="whatitshouldlooklike">What it should look like</h3>
<p>Giving a full descriptive type name.</p>
<pre><code>function head&lt;Element&gt; (arr: Element[]): Element | undefined {
  return arr[0]
}
</code></pre>
<h3 id="whywedoit">Why we do it</h3>
<p>This habit grew I guess because <a href="https://www.typescriptlang.org/docs/handbook/generics.html">even the official docs use one-letter names</a>. It is also quicker to type and requires less thinking to press <code>T</code> instead of writing a full name.</p>
<h3 id="whyweshouldnt">Why we shouldn't</h3>
<p>Generic type variables are variables, like any other. We have abandoned the idea of describing the technicalities of variables in their names when IDEs started to just show us these technicalities. E. g. instead of <code>const strName = 'Daniel'</code> we now only write <code>const name = 'Daniel'</code>. Also, one letter variable names are generally frowned upon because it can be hard to decipher what they mean without looking at their declaration.</p>
<h2 id="8nonbooleanbooleanchecks">8. Non-boolean boolean checks</h2>
<h3 id="whatitlookslike">What it looks like</h3>
<p>Checking whether a value is defined by passing the value directly to an <code>if</code> statement.</p>
<pre><code>function createNewMessagesResponse (countOfNewMessages?: number) {
  if (countOfNewMessages) {
    return `You have ${countOfNewMessages} new messages`
  }
  return 'Error: Could not retrieve number of new messages'
}
</code></pre>
<h3 id="whatitshouldlooklike">What it should look like</h3>
<p>Explicitly checking for the condition we care about.</p>
<pre><code>function createNewMessagesResponse (countOfNewMessages?: number) {
  if (countOfNewMessages !== undefined) {
    return `You have ${countOfNewMessages} new messages`
  }
  return 'Error: Could not retrieve number of new messages'
}
</code></pre>
<h3 id="whywedoit">Why we do it</h3>
<p>Writing the check in short looks more succinct and allows us to avoid thinking about what we actually want to check.</p>
<h3 id="whyweshouldnt">Why we shouldn't</h3>
<p>Maybe we should think about what we actually want to check. The examples above for example handle the case of <code>countOfNewMessages</code> being <code>0</code> differently.</p>
<h2 id="9thebangbangoperator">9. The Bang Bang operator</h2>
<h3 id="whatitlookslike">What it looks like</h3>
<p>Converting a non-boolean value to boolean.</p>
<pre><code>function createNewMessagesResponse (countOfNewMessages?: number) {
  if (!!countOfNewMessages) {
    return `You have ${countOfNewMessages} new messages`
  }
  return 'Error: Could not retrieve number of new messages'
}
</code></pre>
<h3 id="whatitshouldlooklike">What it should look like</h3>
<p>Explicitly checking for the condition we care about.</p>
<pre><code>function createNewMessagesResponse (countOfNewMessages?: number) {
  if (countOfNewMessages !== undefined) {
    return `You have ${countOfNewMessages} new messages`
  }
  return 'Error: Could not retrieve number of new messages'
}
</code></pre>
<h3 id="whywedoit">Why we do it</h3>
<p>To some, understanding <code>!!</code> is like an initiation ritual to the world of JavaScript. It looks short and succinct, and if you are already used to it, then you know what it is about. It is a shortcut to convert any value to a boolean. Especially if, in a codebase, there is no clear semantic separation between falsy values like <code>nu…</code></p></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://startup-cto.net/10-bad-typescript-habits-to-break-this-year/">https://startup-cto.net/10-bad-typescript-habits-to-break-this-year/</a></em></p>]]>
            </description>
            <link>https://startup-cto.net/10-bad-typescript-habits-to-break-this-year/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26005330</guid>
            <pubDate>Tue, 02 Feb 2021 19:22:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Revolut has stopped trading GME and AMC]]>
            </title>
            <description>
<![CDATA[
Score 74 | Comments 34 (<a href="https://news.ycombinator.com/item?id=26003731">thread link</a>) | @powerandr
<br/>
February 2, 2021 | https://www.mrhack.io/blog/revolut-stops-trading-gme-amc-stocks-statement/ | <a href="https://web.archive.org/web/*/https://www.mrhack.io/blog/revolut-stops-trading-gme-amc-stocks-statement/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="page-content" itemprop="mainContentOfPage">
	<section><div><div><div><div><div><div><p><i></i>3,981<span> views</span></p><p><time datetime="2021-02-02T17:20:03+00:00" title="2 February 2021 at 17:20:03 +00:00" itemprop="datePublished">2 Feb at 5:20 pm</time></p></div><div><div><p><iframe title="Breaking - Revolut STOPS TRADING $GME &amp; $AMC stocks" width="640" height="360" src="https://www.youtube.com/embed/1d2bB1PfSTI?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></p></div></div><div itemprop="text"><p>Here is a full statement from Revolut.</p>
<p>Revolut customers in Europe received this email around 4.54PM CET.</p>
<h2>Trading Update for GME &amp; AMC</h2>
<div>
<div>
<div>
<div>
<div>
<div>
<p>Hi …,</p>
<p>From today, we will only be able to facilitate the selling of GameStop (NYSE: <strong>GME</strong>) and AMC Entertainment (NYSE: <strong>AMC</strong>) stocks for the time being. Unfortunately, our broker-dealer in the US, DriveWealth, can no longer offer Buys on these stocks due to increased capital requirements set by the Depository Trust Company (DTC) in the US.</p>
<h3>What does this mean for me?</h3>
<p>You can only sell out your existing holdings in these stocks. Any outstanding buy orders on these two symbols made after Monday’s (1 February) close will automatically be cancelled prior to market open on February 2 2021.</p>
<p>None of our other stocks are affected at this time and are available to trade as normal.</p>
<p>For customers with no holdings in these 2 stocks, neither GME, nor AMC will appear when searched. This is a standard practice when a position moves to sell only, as we don’t want to show you stocks you’re not able to buy at that time. As soon as they become available to buy again, you’ll be able to see them in the app.</p>
</div>
</div>
</div>
</div>
</div>
</div>
<div>
<div>
<div>
<div>
<div>
<div>
<h3>Why is this happening?</h3>
<p>When a stock is traded, it takes two days for the proceeds to go from the broker to the clearing house. This is known as T+2 settlement. Within this time, the clearing house requires the broker to front cash or capital guarantees to ensure funds are available through the settlement process.</p>
<p>The required amount of capital is usually around 10-15% of the value of a security’s holdings on broker’s books. However, this percentage can vary based on stock volatility. In the case of GME and AMC, the DTC has enforced an increase of capital requirements by 250% upon DriveWealth’s clearing partners.</p>
<p>This increase means that DriveWealth is now obligated to restrict trading in GME and AMC, as each stock has its own capital requirement rather than a broker wide requirement.</p>
</div>
</div>
</div>
</div>
</div>
</div>
<div>
<div>
<div>
<div>
<div>
<div>
<h3>When will they be available again to buy?</h3>
<p>This is not a decision Revolut has made, simply one that we are obligated to carry out. We are monitoring the situation very closely and will update you when our partner, DriveWealth, re-enables Buys for GME and AMC. We apologise for any inconvenience caused.</p>
<p>Team Revolut</p>
</div>
</div>
</div>
</div>
</div>
</div>
<div>
<div>
<div>
<div>
<div>
<div>
<p><strong>Capital at Risk</strong></p>
<p>The value of a stock may fall as well as rise and you may get back less than what you initially paid, and in some cases the stock may lose its entire value and you may lose your initial investment. This is not investment advice. It is strongly recommended that you seek professional investment advice before making any investment decision.</p>
<p><strong>Disclaimer:</strong> Revolut Trading Ltd. is an appointed representative of Resolution Compliance Ltd which is authorised and regulated by the Financial Conduct Authority (FRN:574048).</p>
</div>
</div>
</div>
</div>
</div>
</div>
<p>Revolut is one of the most popular investing apps in Europe. Maybe it is not that well-known in US yet.</p>
<p>But, until recently, it was one of possible alternatives to Robinhood to buy $GME and $AMC stocks.<br>
<iframe title="How to buy $GME &amp; $AMC stock in Revolut app?" width="640" height="360" src="https://www.youtube.com/embed/82uUmO9L80o?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><br>
What are alternatives to Revolut in Europe – to buy $GME and $AMC stocks?</p>
<p>According to <a href="https://invezz.com/news/2021/02/02/revolut-competitors/" target="_blank" rel="noopener">Invezz</a>, you can still buy these stocks in:</p>
<ul>
<li>Saxo</li>
<li>BlackBull markets</li>
<li>AvaTrade</li>
</ul>


<blockquote>
<p lang="en" dir="ltr">Revolut in the UK. WOW. <a href="https://twitter.com/wsbmod?ref_src=twsrc%5Etfw">@wsbmod</a> <a href="https://t.co/ypLOGVsMLl">pic.twitter.com/ypLOGVsMLl</a></p>
<p>— Nakamoto Plaza (@NakamotoPlaza) <a href="https://twitter.com/NakamotoPlaza/status/1356626544173711360?ref_src=twsrc%5Etfw">February 2, 2021</a></p></blockquote>

<blockquote>
<p lang="en" dir="ltr">The GameStop stock is tanking. Who knows where it goes from here, but if you're someone who's been trying to hang on, curious to hear what the ride has been like for you. My DMs are open, email is patrick.klepek@vice.com</p>
<p>— Patrick Klepek (@patrickklepek) <a href="https://twitter.com/patrickklepek/status/1356636750471389190?ref_src=twsrc%5Etfw">February 2, 2021</a></p></blockquote>

<blockquote>
<p lang="en" dir="ltr"><a href="https://twitter.com/freetrade?ref_src=twsrc%5Etfw">@freetrade</a> deciding to mysteriously limit stock purchases for <a href="https://twitter.com/hashtag/GME?src=hash&amp;ref_src=twsrc%5Etfw">#GME</a> and <a href="https://twitter.com/hashtag/AMC?src=hash&amp;ref_src=twsrc%5Etfw">#AMC</a> but still letting you put in sell orders before market open today.</p>
<p>Going the way of <a href="https://twitter.com/RobinhoodApp?ref_src=twsrc%5Etfw">@RobinhoodApp</a> are we? 🤔🤔🤔</p>
<p>— Vall Syrene – Legendary Hunts Out Now! #BLM (@Valldoesdnd) <a href="https://twitter.com/Valldoesdnd/status/1356249868675780612?ref_src=twsrc%5Etfw">February 1, 2021</a></p></blockquote>

<blockquote>
<p lang="en" dir="ltr">Now <a href="https://twitter.com/hashtag/revolut?src=hash&amp;ref_src=twsrc%5Etfw">#revolut</a> is also not allowing GME or AMC… :/ <a href="https://twitter.com/search?q=%24gme&amp;src=ctag&amp;ref_src=twsrc%5Etfw">$gme</a> <a href="https://twitter.com/search?q=%24amc&amp;src=ctag&amp;ref_src=twsrc%5Etfw">$amc</a> <a href="https://t.co/X68sL8y24X">pic.twitter.com/X68sL8y24X</a></p>
<p>— Michael (@MykeJD1) <a href="https://twitter.com/MykeJD1/status/1356609588569726977?ref_src=twsrc%5Etfw">February 2, 2021</a></p></blockquote>


</div></div></div></div></div></div></section>
</div></div>]]>
            </description>
            <link>https://www.mrhack.io/blog/revolut-stops-trading-gme-amc-stocks-statement/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26003731</guid>
            <pubDate>Tue, 02 Feb 2021 17:22:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Recovering a Bricked SSD with JTAG and a Raspberry Pi]]>
            </title>
            <description>
<![CDATA[
Score 45 | Comments 4 (<a href="https://news.ycombinator.com/item?id=26003176">thread link</a>) | @fanf2
<br/>
February 2, 2021 | https://fmad.io/blog-ssd-bricked-restore.html | <a href="https://web.archive.org/web/*/https://fmad.io/blog-ssd-bricked-restore.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

			<p>
				SSD`s are the life blood of our fmadio 10G, 40G, 100G ethernet capture systems. They provide backing storage that well exceeds that of conventional RAM, are super fast and light weight. Thus its prudent to keep the SSD farms in top nick, optimal health, and occasionally perform emergency room brain surgery on them. Unfortunately today is one of those days.
			</p>
			<br>

			<div>                        
				<ul>                            
					<li><img width="60%" src="https://fmad.io/images/blog/20141229_ssd_jtag_close.jpg" alt="ssd connected to jtag"></li>
				</ul>                        
			</div>


		<p>
As with all things, it happened late on a Friday night when I was adding a new feature to the system that wipes all capture data from the system. This is simple button click on the web UI page as our clients data is quite sensitive thus needs to be deleted when the box moves internally or externally. The wipe is implemented using the "Secure Erase" ATA-8 command, you can read all about it <a href="https://ata.wiki.kernel.org/index.php/ATA_Secure_Erase">here</a>. Its essentially a restore-to-factory-setting operation. Meaning after the SecureErase the drive`s internal state is the same as "just left the factory". 
		</p>
		
		<p>
Which is great when it works, but this kind of low level drive formatting is pretty complicated with many (presumably) asynchronous operations going on in parallel... and doing 100 of these operations back to back at high speed is probably something the vendor did not expect (I was testing dammit!). In our case this bricked 6 SSD`s rendering them completely useless causing myself quite the stress as I now have several thousand dollars worth of inventory destroyed!  - not a good day.
</p>


				<p><img width="1024px" src="https://fmad.io/images/blog/money_burn.jpg" alt="fmadio ssd lost"></p><p>
The result is a wall of rather intimidating errors indicating imminent doom with the disk is for all intensive purposes <a href="https://en.wikipedia.org/wiki/Brick_%28electronics%29"><b>BRICKED</b></a>.

<code>

kernel: [18633.754193] ata2.00: exception Emask 0x0 SAct 0x0 SErr 0x0 action 0x0
kernel: [18633.754204] ata2.00: irq_stat 0x40000001
kernel: [18633.754206] ata2.00: failed command: READ DMA
kernel: [18633.754209] ata2.00: cmd c8/00:08:00:00:00/00:00:00:00:00/e0 tag 0 dma 4096 in
kernel: [18633.754209]          res 51/04:00:00:00:00/00:00:00:00:00/60 Emask 0x1 (device error)
kernel: [18633.754210] ata2.00: status: { DRDY ERR }
kernel: [18633.754211] ata2.00: error: { ABRT }
kernel: [18633.754515] ata2.00: supports DRM functions and may not be fully accessible
kernel: [18633.754614] ata2.00: failed to get NCQ Send/Recv Log Emask 0x1
kernel: [18633.759150] ata2.00: supports DRM functions and may not be fully accessible
kernel: [18633.759215] ata2.00: failed to get NCQ Send/Recv Log Emask 0x1
kernel: [18633.763495] ata2.00: configured for UDMA/133
kernel: [18633.770136] ata2: EH complete
kernel: [18633.770278] ata2.00: exception Emask 0x0 SAct 0x0 SErr 0x0 action 0x0
kernel: [18633.770280] ata2.00: irq_stat 0x40000001
kernel: [18633.770281] ata2.00: failed command: READ DMA
kernel: [18633.770284] ata2.00: cmd c8/00:08:00:00:00/00:00:00:00:00/e0 tag 1 dma 4096 in
kernel: [18633.770284]          res 51/04:00:00:00:00/00:00:00:00:00/60 Emask 0x1 (device error)
kernel: [18633.770286] ata2.00: status: { DRDY ERR }
kernel: [18633.770286] ata2.00: error: { ABRT }
kernel: [18633.770572] ata2.00: supports DRM functions and may not be fully accessible
kernel: [18633.770641] ata2.00: failed to get NCQ Send/Recv Log Emask 0x1
kernel: [18633.775164] ata2.00: supports DRM functions and may not be fully accessible
kernel: [18633.775210] ata2.00: failed to get NCQ Send/Recv Log Emask 0x1
kernel: [18633.779527] ata2.00: configured for UDMA/133
kernel: [18633.786094] ata2: EH complete
kernel: [18633.786205] ata2.00: exception Emask 0x0 SAct 0x0 SErr 0x0 action 0x0
kernel: [18633.786207] ata2.00: irq_stat 0x40000001
kernel: [18633.786208] ata2.00: failed command: READ DMA
</code>


</p><p>
The usual suspects to recover were tried and failed, leaving only a few options.
<br>
</p>

<h5>a) RMA the boards back to the seller<br>
b) Contact vendor support<br>
c) Perform surgery</h5>


<p>
Option a) of RMA`ing the boards was the safest option, tho usually you get some other previously recycled RMA`ed device back. Option b) of contacting the vendor is always such a brutally painful experience. It would likely end up with some random "Customer Support" person with a strange accent... giving the default completely useless response of RMA the device and get a replacement kind of thing... ho hum. Which leaves surgery! Now I usually don't go messing with hardware like this (anymore... :) ) because it takes up quite a bit time. However SSD health and prosperity is directly linked to our profitability thus deemed it a worth while time investment to have a more intimate relationship with our SSD models of choice. 
</p>
<br>

<div><p>
The process starts with a general reconnaissance mission of what pins are accessible, and what those pins are for. First up was finding the UART / serial interface but it was silent and likely disabled by the firmware. Next up was what most likely looked like a JTAG interface and... bingo, full JTAG interface connecting and operating as expected.
</p><p>

 JTAG is a hardware based system debugger that for CPU`s let you control instruction execution and read/write memory anywhere. You can see in the picture below some soldering of header pins was required, that is then wired to a breadboard which is wired to a Raspberry PI.
</p></div>


	<p><img width="1024px" src="https://fmad.io/images/blog/20141229_ssd_jtag.jpg" alt="fmadio ssd with jtag connected"></p><div><p>
Raspberry PI? wtf ? In this case the Raspberry PI was converted into a JTAG debugger using the outstanding software over at <a href="http://openocd.sourceforge.net/">OpenOCD</a>. As "real" JTAG debuggers are quite expensive ranging from $100 - $1000+ making OCD coupled with the PI an excellent low cost alternative. 
</p><p>

At this point you get a small rush as you gain access and poke the device, after which the vastness of having no idea what anything does starts to weigh you down. Then slowly bit by bit, instruction after instruction, string after string you gain some intuition on the memory map, what the code does, how its setup and eventually find something interesting.
</p></div> 

<p>

The first entry point to look for is the classic printf / trace / debug operation which gives you insight into what the software is doing. And eventually managed to track down the code that`s basically

<code>
void trace(char* Message, ...)
{ 
	va_arg list;
	va_start(arglist, Message);

	char buf[1024];
	vsprintf(buf, Message, arglist);

	if (debug_enable)
	{
		fwrite(output, buf, strlen(buf));
	}
}
</code>

which writes out a string to a console to tell the developer on whats going on. Note that the code has to "flatten" the string first before even deciding to output or not, which gives us a nice window to sniff the string with JTAG even if nothing is written to the console. 
</p>


<p>
After sniffing strings for a while and getting a better feel for whats happening noticed that the SSD is receiving commands from the SATA host no problem. But there`s some sort of funkyness going on that causes the SSD to send no response back - kind of a one-way-street. One idea to resolve this is: in theory the security erase operation restores everything back to good health. The question tho, is the device actually processing a security erase request ?  
</p>


<p>
... and using our printf JTAG sniffer... it most certainly is processing the request! But failing miserably due to an incorrect password. You can see the sniffed printf jtag string in the output below. Hint: <i>"&lt;SED&gt; Credential Comparison Failed"</i> ASCIIZ string.
</p>


	<p><img width="1024px" src="https://fmad.io/images/blog/20141229_ssd_security_erase_fail.jpg" alt="fmadio ssd security erase fail"></p><p>
Which makes it clear why the security erase / factory reset failed but more importantly you can track down the offending bit of code from this string. That results in the following snippet of assembler courtesy of the IDA toolset below.
</p> 

<p><img width="1024px" src="https://fmad.io/images/blog/20141229_ssd_security_check.jpg" alt="fmadio ssd security erase password check"></p><p>
To decode that for you its doing a 32 byte long compare against some expected cryptographic hash key. Then the <i>"magic compare"</i> aka instruction <b>CMP R5, #1</b> is testing if the keys matched. Then doing a conditional jump to a printf routine based on that comparison result <b>BLNE sub_80...</b>. And finally  the functions return value is the result of the comparison <b>MOV R0, R5</b>. Nothing particularly fancy going on.
</p> 


<p>
There`s a few ways to go from here. One would be to reverse engineer how the 32B key is generated and create  a general purpose exploit. The other would be to just patch the binary such that it thinks it passed the security check. eg Fake a correct password response. We chose the latter as it only takes a few minutes and all I want is to restore the SSD farm`s health. Patching the binary with JTAG is trivial, console output is shown below.
</p> 


<p><img width="1024px" src="https://fmad.io/images/blog/20141229_ssd_security_erase_patch.jpg" alt="fmadio ssd security erase password fake"></p><div><p>
The above shows disassembling the patched code first, the "before" section. This is to check we overwrite the correct bit of code. Then patch it using the command <b>cpu0 arm mww</b> with the value 0xe3a05001. Then disassemble again "after section" to confirm the patch worked and has the correct instruction. 
</p><p>

In this case we replaced <b>BLNE</b> instruction (print error message to the console) with <b>MOV r5, #1</b> at address 0x8009abe4 (shown in blue). The result of the "magic check" is 0 for fail, 1 for pass and write it to register r5. All we did is ignore the whole comparison and simply override it and say the security check always passes (r5 = 1).
</p></div> 

<p>
...
</p>

<p>
Now its patched, with cpu`s resumed its the moment of truth. Issuing the security erase operation from the host system via hdparm. 
<br>
<code>
$ sudo hdparm --security-erase 1234  /dev/sdb
security_password="1234"

/dev/sdb:
 Issuing SECURITY_ERASE command, password="1234, user=user
$
</code>
<br>
... and it worked! the SSD is back to life, working as normal and running at high speed!  ... with <b>several thousand dollars worth of SSD`s back in business</b> making our 10G, 40G, 100G network capture systems more resilient than ever. Now if the SSD vendor (who shall remain nameless) would fix the dam bug so excessive back-to-back security password/erase does NOT brick the device, life would be so much better. 
</p>


	</div></div>]]>
            </description>
            <link>https://fmad.io/blog-ssd-bricked-restore.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26003176</guid>
            <pubDate>Tue, 02 Feb 2021 16:43:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Generating Text with Markov Chains]]>
            </title>
            <description>
<![CDATA[
Score 66 | Comments 21 (<a href="https://news.ycombinator.com/item?id=26002911">thread link</a>) | @healeycodes
<br/>
February 2, 2021 | https://healeycodes.com/generating-text-with-markov-chains/ | <a href="https://web.archive.org/web/*/https://healeycodes.com/generating-text-with-markov-chains/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><p>I wanted to write a program that I could feed a bunch of novels and then produce similar text to the author’s writing.</p>
<p>One method of generating fake but familiar looking text is to use a Markov chain generator. There is a fantastic Python library for doing this called <a href="https://github.com/jsvine/markovify">jsvine/markovify</a> but I wanted to learn more about how it works under the hood so I implemented the algorithms from scratch!</p>
<p>Before we get to text generation, let’s start by generating some fake weather. Skip the following section if you’re familiar with Markov chains.</p>
<h2 id="fake-weather-generation"><a href="#fake-weather-generation" aria-label="fake weather generation permalink"></a>Fake Weather Generation</h2>
<p>I have some historical weather data from my town. The weather here is either sunny or rainy. When it’s sunny, there’s a good chance that it remains sunny the next day. It rarely rains but when it does it often rains for a few days.</p>
<p>Rather than using a naive probability (e.g. there’s an ~83% chance it is sunny vs. rainy on any given day) we’ll use a Markov chain to generate more realistic looking data. Our generated data will have streaks of weather which will more closely resemble real life patterns.</p>
<p>To be specific, if it’s sunny there’s a 10% chance it will be rainy the next day and a 90% chance it will stay sunny. If it’s rainy then there’s 50% chance it will be sunny the next day and a 50% chance it will stay rainy.</p>
<p>Here’s a diagram of this two-state Markov process.</p>
<p><span>
      <a href="https://healeycodes.com/static/e4ae284c37dcdeb9323b73b3637b6709/b6699/weather-markov-chain.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="A Markov chain with the sunny/rainy values as described above." title="A Markov chain with the sunny/rainy values as described above." src="https://healeycodes.com/static/e4ae284c37dcdeb9323b73b3637b6709/b6699/weather-markov-chain.png" srcset="https://healeycodes.com/static/e4ae284c37dcdeb9323b73b3637b6709/a8a0d/weather-markov-chain.png 300w,
https://healeycodes.com/static/e4ae284c37dcdeb9323b73b3637b6709/b6699/weather-markov-chain.png 405w" sizes="(max-width: 405px) 100vw, 405px" loading="lazy">
  </a>
    </span></p>
<p>Instead of using weights to describe probability, let’s distribute the states in a list that we randomly pick from. I find that defining Markov chains like this (while far more computationally expensive) is easier to debug.</p>
<div data-language="python"><pre><code>weather_chain <span>=</span> <span>{</span>
    <span>'sun'</span><span>:</span> <span>[</span><span>'sun'</span><span>,</span> <span>'sun'</span><span>,</span> <span>'sun'</span><span>,</span> <span>'sun'</span><span>,</span> <span>'sun'</span><span>,</span> <span>'sun'</span><span>,</span> <span>'sun'</span><span>,</span> <span>'sun'</span><span>,</span> <span>'sun'</span><span>,</span> <span>'rain'</span><span>]</span><span>,</span>
    <span>'rain'</span><span>:</span> <span>[</span><span>'sun'</span><span>,</span> <span>'rain'</span><span>]</span>
<span>}</span></code></pre></div>
<p>We consume this model by picking a random starting state and using the current state to choose randomly from the possible future states. We do this over and over to generate a sequence.</p>
<div data-language="python"><pre><code><span>import</span> random


weather <span>=</span> <span>[</span>random<span>.</span>choice<span>(</span><span>list</span><span>(</span>weather_chain<span>.</span>keys<span>(</span><span>)</span><span>)</span><span>)</span><span>]</span>

<span>for</span> i <span>in</span> <span>range</span><span>(</span><span>10</span><span>)</span><span>:</span>
    weather<span>.</span>append<span>(</span>random<span>.</span>choice<span>(</span>weather_chain<span>[</span>weather<span>[</span>i<span>]</span><span>]</span><span>)</span><span>)</span></code></pre></div>
<p>In this example output, we can see that rainy days are ‘sticky’ as we would expect from the model. </p>
<div data-language="python"><pre><code><span>[</span><span>'rain'</span><span>,</span> <span>'rain'</span><span>,</span> <span>'rain'</span><span>,</span> <span>'sun'</span><span>,</span> <span>'sun'</span><span>,</span> <span>'sun'</span><span>,</span> <span>'sun'</span><span>,</span> <span>'sun'</span><span>,</span> <span>'rain'</span><span>,</span> <span>'rain'</span><span>,</span> <span>'sun'</span><span>]</span></code></pre></div>
<h2 id="fake-text-generation"><a href="#fake-text-generation" aria-label="fake text generation permalink"></a>Fake Text Generation</h2>
<p>Instead of having a predefined Markov chain like we saw in the previous section, let’s build one from real data. The full source code for this article and the text corpuses can be found at <a href="https://github.com/healeycodes/markov-chain-generator">healeycodes/markov-chain-generator</a>.</p>
<p>The code excerpts assume that we’re generating fiction. So the source text must have capital letters at the start of sentences and full stops at the end of sentences. We can use these two markers to generate text chunks that have a beginning and an end.</p>
<p>In our weather example, the state size was one — to decide the next step in the sequence, we only considered one previous day of weather. When it comes to generating language, a state size of one sometimes isn’t big enough and the arrangement of words can be too random to be interesting. A state size of two is a good starting point. Going higher than two can produce text that is too similar to the original text corpus.</p>
<p>The following function builds a Markov chain in the same format as our weather example. It takes a source text and a state size and returns a dictionary where the keys are the current state and their values are a list of possible future states. The lists contain duplicates and this is how we handle the probabilities of future states.</p>
<div data-language="python"><pre><code><span>def</span> <span>build_model</span><span>(</span>source<span>,</span> state_size<span>)</span><span>:</span>
    <span>'''
    Given a corpus and a state size, build a Markov chain.
    '''</span>
    source <span>=</span> source<span>.</span>split<span>(</span><span>)</span>
    model <span>=</span> <span>{</span><span>}</span>
    <span>for</span> i <span>in</span> <span>range</span><span>(</span>state_size<span>,</span> <span>len</span><span>(</span>source<span>)</span><span>)</span><span>:</span>
        current_word <span>=</span> source<span>[</span>i<span>]</span>
        previous_words <span>=</span> <span>' '</span><span>.</span>join<span>(</span>source<span>[</span>i<span>-</span>state_size<span>:</span>i<span>]</span><span>)</span>
        <span>if</span> previous_words <span>in</span> model<span>:</span>
            model<span>[</span>previous_words<span>]</span><span>.</span>append<span>(</span>current_word<span>)</span>
        <span>else</span><span>:</span>
            model<span>[</span>previous_words<span>]</span> <span>=</span> <span>[</span>current_word<span>]</span>

    <span>return</span> model</code></pre></div>
<p>Given a tiny source of <code>'An apple is very good. An orange is very bad.'</code> and a state size of <code>2</code> it will produce the following Markov chain. Since the source was so small there are only four possible complete sentences.</p>
<div data-language="json"><pre><code><span>{</span>
  <span>"An apple"</span><span>:</span><span>[</span>
    <span>"is"</span>
  <span>]</span><span>,</span>
  <span>"apple is"</span><span>:</span><span>[</span>
    <span>"very"</span>
  <span>]</span><span>,</span>
  <span>"is very"</span><span>:</span><span>[</span>
    <span>"good."</span><span>,</span>
    <span>"bad."</span>
  <span>]</span><span>,</span>
  <span>"very good."</span><span>:</span><span>[</span>
    <span>"An"</span>
  <span>]</span><span>,</span>
  <span>"good. An"</span><span>:</span><span>[</span>
    <span>"orange"</span>
  <span>]</span><span>,</span>
  <span>"An orange"</span><span>:</span><span>[</span>
    <span>"is"</span>
  <span>]</span><span>,</span>
  <span>"orange is"</span><span>:</span><span>[</span>
    <span>"very"</span>
  <span>]</span>
<span>}</span></code></pre></div>
<p>The following function consumes the Markov chain model and generates some fake text for us. To achieve a minimum length, we keep generating until we hit the minimum length and then keep going until we reach a token that ends with a full stop. To find a correct starting point, we pick a random key (two words) where the first character is a capital letter.</p>
<div data-language="python"><pre><code><span>def</span> <span>generate_text</span><span>(</span>model<span>,</span> state_size<span>,</span> min_length<span>)</span><span>:</span>
    <span>'''
    Consume a Markov chain model (make sure to specify the &lt;state_size&gt; used)
    to generate text that is at least &lt;min_length&gt; size long.
    '''</span>
    <span>def</span> <span>get_new_starter</span><span>(</span><span>)</span><span>:</span>
        <span>return</span> random<span>.</span>choice<span>(</span><span>[</span>s<span>.</span>split<span>(</span><span>' '</span><span>)</span> <span>for</span> s <span>in</span> model<span>.</span>keys<span>(</span><span>)</span> <span>if</span> s<span>[</span><span>0</span><span>]</span><span>.</span>isupper<span>(</span><span>)</span><span>]</span><span>)</span>
    text <span>=</span> get_new_starter<span>(</span><span>)</span>

    i <span>=</span> state_size
    <span>while</span> <span>True</span><span>:</span>
        key <span>=</span> <span>' '</span><span>.</span>join<span>(</span>text<span>[</span>i<span>-</span>state_size<span>:</span>i<span>]</span><span>)</span>
        <span>if</span> key <span>not</span> <span>in</span> model<span>:</span>
            text <span>+=</span> get_new_starter<span>(</span><span>)</span>
            i <span>+=</span> <span>1</span>
            <span>continue</span>

        next_word <span>=</span> random<span>.</span>choice<span>(</span>model<span>[</span>key<span>]</span><span>)</span>
        text<span>.</span>append<span>(</span>next_word<span>)</span>
        i <span>+=</span> <span>1</span>
        <span>if</span> i <span>&gt;</span> min_length <span>and</span> text<span>[</span><span>-</span><span>1</span><span>]</span><span>[</span><span>-</span><span>1</span><span>]</span> <span>==</span> <span>'.'</span><span>:</span>
            <span>break</span>
    <span>return</span> <span>' '</span><span>.</span>join<span>(</span>text<span>)</span></code></pre></div>
<p>Here are those four possible complete sentences from our previous Markov chain. These can be combined infinitely by our function.</p>
<div data-language="text"><pre><code>'An apple is very bad.'
'An orange is very bad.'
'An orange is very good.'
'An apple is very good.'</code></pre></div>
<h2 id="some-examples"><a href="#some-examples" aria-label="some examples permalink"></a>Some Examples</h2>
<p>We can now feed in large amounts of text from an author and generate fake writing! In fact, any corpus that uses sentences will work with our program. For example, here is the result of feeding in a few Wikipedia articles.</p>
<blockquote>
<p>Cricket is more similar to dust devils and landspouts. They form when a homicide rate of 34.2 per 100,000 was reported. This included 15 officer-involved shootings. One shooting led to the latest hour of it; and lately, I know of but love, desperate love, the worst of all the more remote islands. At around the field. One of Wollstonecraft’s most popular metaphors draw on military concepts: Disease is an early type of fiction that were quick to resort to violence. One of Wollstonecraft’s favorite arguments.</p>
</blockquote>
<p>Here’s some Edgar Allen Poe.</p>
<blockquote>
<p>Count could recollect, it was never worth the trouble of the stranger. But, as usual, enveloped in frequent rolls, or bandages, of linen; but, in place of conference with the whole matter as a natural result of the river, and, plunging through a single slender gold chain, and throws a tranquil but magical radiance over all. I cannot enter into details just now: but it was found, on Sunday morning, that he was forced to allow, had ever suspected of existing in the heathen is unwonted; and fickle-mindedness has ever thought of this life and of cutting him off with a layer of plaster, thickly gilt and painted.</p>
</blockquote>
<h2 id="further-resources"><a href="#further-resources" aria-label="further resources permalink"></a>Further Resources</h2>
<p>The sun/rain example was taken from <a href="https://en.wikipedia.org/wiki/Examples_of_Markov_chains#A_simple_weather_model">Wikipedia</a>. Victor Powell’s article, <a href="https://setosa.io/ev/markov-chains/">Markov Chains</a>, was also helpful for my initial understanding and is worth checking out for the interactive graphics alone.</p>
<p>Some of the articles about Markov chains are a little inaccessible to those without a maths background. However, there’s a Simple English version of Wikipedia. Many articles have an alternative page which you can find by replacing the <code>en</code> in the URL bar with <code>simple</code>. For example, the <a href="https://simple.wikipedia.org/wiki/Markov_chain">simple version</a> of the Markov chain page.</p>
<p>Daniel Shiffman also covered Markov chains in a Coding Challenge on <a href="https://www.youtube.com/watch?v=eGFJ8vugIWA">The Coding Train</a>.</p></section></div>]]>
            </description>
            <link>https://healeycodes.com/generating-text-with-markov-chains/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26002911</guid>
            <pubDate>Tue, 02 Feb 2021 16:24:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Behaviours to avoid in a software architecture role]]>
            </title>
            <description>
<![CDATA[
Score 204 | Comments 126 (<a href="https://news.ycombinator.com/item?id=26002543">thread link</a>) | @geidies
<br/>
February 2, 2021 | https://www.danielwatts.info/post/7-behaviours-to-avoid-software-architect/ | <a href="https://web.archive.org/web/*/https://www.danielwatts.info/post/7-behaviours-to-avoid-software-architect/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <p>Over the years, I’ve had the opportunity to work in architecture roles alongside experienced software/technical/solution architects. Through observing others and my own trial and error, I’ve learned a little bit about what <em>not</em> to do in these roles (because it’s often easier to reflect on what didn’t work rather than what did). Even though I lean towards the idea that everyone should be architecting the system rather than having architects solely responsible - I recognise that some organisations are far from that ideal, and it’s those folks I hope find this list helpful. So here it is, 7 behaviours to avoid if you’re in a software architecture role:</p>
<h2 id="1-dont-ignore-the-engineering-team">1. Don’t ignore the engineering team</h2>
<p>If you’re not “hands-on” with the engineering team either through writing or reviewing code or deep in the technical discussions, then the likelihood is you aren’t close enough to the problems and the individuals on the team. If you’re not feeling their pain, then you are probably lacking the empathy and understanding to provide effective guidance. If you find yourself in this position, I would consider beginning with one-on-ones and pairing with engineers as the quickest way to increase empathy and understanding. Then look to participate in feature kick-offs, technical design discussions and code reviews where necessary.</p>
<h2 id="2-dont-ignore-the-domain">2. Don’t ignore the domain</h2>
<p>It’s part of the role to become a domain expert. This knowledge can be used to act as an effective translator between business and engineering. That said, you’ll want to avoid being a communication bottleneck too, so it’s important to teach, translate and document domain context and business value for the engineering team. This is where techniques like <a href="https://www.atlassian.com/continuous-delivery/principles/value-stream-mapping">value-stream mapping</a>, <a href="https://en.wikipedia.org/wiki/Event_storming">event storming</a> and <a href="https://twitter.com/ntcoding/status/1342805885224177666">domain-driven design</a> can really help.</p>
<h2 id="3-dont-prescribe-or-mandate-architectures">3. Don’t prescribe or mandate architectures</h2>
<p>For the most part, our industry has moved past the notion that a system’s architecture is designed in isolation (or in an ivory tower) and handed-off to engineers to deliver. However, it definitely still happens. Software architecture and development should be inter-weaving activities, with feedback from one influencing the other. Keeping that feedback loop as short as possible will likely lead to better outcomes. So if you would like to design and create more resilient systems and your organisation tends to mandate or prescribe architectures; consider how you can best empower engineers to make sound architecture decisions instead. Working with the engineers to agree on a foundation of architectural principles and accepting that architecture is never done, it should evolve and change over time are good places to begin (see the <a href="https://www.thoughtworks.com/books/building-evolutionary-architectures">Building Evolutionary Architectures</a> book for more on this).</p>
<h2 id="4-dont-just-seek-architectural-consistency">4. Don’t just seek architectural consistency</h2>
<p>Consistency certainly has a place in organisations that build and maintain many systems in order to to help prevent complexity. In my opinion, it’s better to see it as a guideline that will likely have exceptions. Simply seeking or worse, enforcing consistency is a sure-fire way to slow the team down, squash innovation and reduce learning opportunities.</p>
<h2 id="5-dont-forget-about-the-current-architectural-state">5. Don’t forget about the current architectural state</h2>
<p>It can be useful to model a target architecture based on agreed principles and in collaboration with engineers (see #1 and #3 above). However, it must be founded in all the nuance and understanding of the current architecture. Anything else could lead towards a doomed rewrite, an unhappy team or a failed pitch to some confused engineers.</p>
<p>On a similar note, I’ve seen many conversations where stakeholders begin to assume the target state is in fact the current state. This can have significant downsides for the engineering team, for example; a sense of moving too slow, missed tasks that were presumed completed or a lack of appreciation upon completing a large chunk of technical work. Stakeholder discussions about target state may need to include regular reminders about the current state.</p>
<h2 id="6-dont-get-too-attached-to-the-desired-architecture">6. Don’t get too attached to the desired architecture</h2>
<p>It can be easy to fall into the trap of attaching an opinion to your identity, particularly if you’ve got the task of providing a technical direction for an engineering team. New information and unforeseen circumstances will emerge, so any target state will 100% change. As these scenarios surface, you will need to keep an open mind to adapt your view and the direction. A fixed view will only hold back progress. As mentioned in #3, the architecture should be going through constant, incremental change.</p>
<h2 id="7-dont-let-review-processes-stagnate">7. Don’t let review processes stagnate</h2>
<p>As an architect in a large organisation you are likely to be responsible for or actively involved in architectural and security review processes, either as a reviewer or seeking a review. These processes are often change approval reviews that give the green-light for a production release. They can be long and drawn out, unclear in their value, involve reviewers who have zero context, and result in unwanted or unnecessary outcomes; making them the perfect candidates for resisting change. As a more senior figure, an architect should be working hard against that intuition. They should seek to understand the purpose and value of the review process and relay it to others. They should be leading or guiding engineering teams through these processes, particularly for the first time. But most importantly, they should be constantly pushing to <a href="https://cloud.google.com/solutions/devops/devops-process-streamlining-change-approval">improve, reduce or potentially remove a review process</a> depending on its purpose and added value.</p>
<p>There you have it! Hopefully I’ll learn even more things to avoid in future but for now, avoid these and you should be good; or at the very least better than a bunch of scenarios I’ve witnessed. For more advice on the topic of software architecture, check out these excellent reads too:</p>
<ul>
<li><a href="https://martinfowler.com/articles/architect-elevator.html">The  Architect Elevator</a> - Visiting the upper floors</li>
<li><a href="https://martinfowler.com/articles/value-architectural-attribute.html">The Elephant in the Architecture</a> - Why business value should be treated as an architectural attribute</li>
<li><a href="https://mailchi.mp/4aeb4085ec6a/17-dear-architects?e=65367d58cd">This book reading list</a> by <a href="https://www.deararchitects.xyz/">Dear Architects,</a> has five books worth reading, including <a href="https://www.thoughtworks.com/de/books/building-evolutionary-architectures">Building Evolutionary Architectures</a>, and sums them up better than I could. It’s also an excellent newsletter.</li>
</ul>
<p><em>Thanks to Vivek Jain, Hugo Nogueira and Robin Weston for reviewing various versions of this post.</em></p>

    </div></div>]]>
            </description>
            <link>https://www.danielwatts.info/post/7-behaviours-to-avoid-software-architect/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26002543</guid>
            <pubDate>Tue, 02 Feb 2021 16:00:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Getting better at Linux with mini-projects]]>
            </title>
            <description>
<![CDATA[
Score 892 | Comments 111 (<a href="https://news.ycombinator.com/item?id=26002335">thread link</a>) | @carltheperson
<br/>
February 2, 2021 | https://carltheperson.com/posts/10-things-linux | <a href="https://web.archive.org/web/*/https://carltheperson.com/posts/10-things-linux">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p><i>2020-11-28<!-- --> Carl Riis</i></p><hr><h3>How do you advance your Linux skills when you are already comfortable with the basics? My solution was to come up with 10 subjects to learn and create an accompanying mini-project.</h3><p>All the source code for the projects can be found in <a href="https://github.com/carltheperson/10-things-linux">this</a> GitHub repository.</p><h2>1. UNIX - <a href="https://github.com/carltheperson/10-Things-Linux/tree/master/1_UNIX__Recat">Recat</a></h2><p>The first thing I wanted to learn more about was UNIX since Linux is a UNIX-like operating system. I also never really felt that I fully understood what exactly UNIX was, besides being a family of fairly similar operating systems.</p><p>The first thing I did was to read the entire Wikipedia page on UNIX. I also read <a href="https://people.eecs.berkeley.edu/~brewer/cs262/unix.pdf">this</a> original paper written by Dennis Ritchie and Ken Thompson from 1974, which was really interesting though I can’t say I understood all of it. After some more reading and some Youtube videos, I felt comfortable that I understood what UNIX was, and what makes it interesting.</p><p>For the project, I decided to try and write my first C program. Following the Unix philosophy, I made sure that it did one thing only. That thing ended up being a program that reverses the contents of a text file. Since this is just a reverse version of <em>cat</em>, I called the program <em>recat</em>.</p><p><img src="https://carltheperson.com/media/10-things-linux/1_UNIX__Recat/screenshot.png" alt=""></p><h2>2. What is a shell? - <a href="https://github.com/carltheperson/10-Things-Linux/tree/master/2_What_is_a_shell__SeaShell">SeaShell</a></h2><p>For this project, I was curious to find out what exactly a shell was. Even though it is something that I use often, I was still confused about what differentiates it from the terminal. Turns out it’s really not that complicated. I learned this by rereading the <em>shell</em> part of <a href="https://people.eecs.berkeley.edu/~brewer/cs262/unix.pdf">the paper</a> from the previous project, and some explanations online like <a href="https://www.tutorialspoint.com/unix/unix-what-is-shell.htm">this</a> and <a href="https://linuxcommand.org/lc3_lts0010.php">this one</a>. The Unix shell Wikipedia entry was also very informative.</p><p>Since this project is about the shell, I found it appropriate to try and write my own. I settled on the name <em>SeaShell</em>, which I found way too funny. It’s not very advanced, but it does the job.</p><p><img src="https://carltheperson.com/media/10-things-linux/2_What_is_a_shell__SeaShell/screenshot.png" alt=""></p><h2>3. Ownership and permissions - <a href="https://github.com/carltheperson/10-Things-Linux/tree/master/3_Ownership_and_permissions__Tellaccess">Tellaccess</a></h2><p>This is one of the things that I know is really important for Linux, but have never really understood. I have tried before but never been able to get the knowledge to stick, maybe because I didn't really care about security until now.</p><p>The ownership and permission system turned out to be really intuitive, and I was able to understand the basics from <a href="https://www.thegeekdiary.com/understanding-basic-file-permissions-and-ownership-in-linux/">this</a> one article. I later discovered <a href="https://linuxhandbook.com/linux-file-permissions/">this one</a> from Linux Handbook which was more comprehensive.</p><p>For the project, I decided to create a program that tells you in human-readable form, the ownership and permissions of a file. I called the project <em>tellaccess</em> because it tells you who can access the file in what ways.</p><p><img src="https://carltheperson.com/media/10-things-linux/3_Ownership_and_permissions__Tellaccess/screenshot.png" alt=""></p><h2>4. Grep - <a href="https://github.com/carltheperson/10-Things-Linux/tree/master/4_Grep__Grep_detective">Grep detective</a></h2><p>Grep is the sort of UNIX magic I have always wanted to learn. Since <em>grep</em> is all about regular expressions I would have to learn that first. This was actually quite difficult because grep uses the <em>POSIX Basic Regular Expressions</em>, which is not that common. The <a href="https://en.wikibooks.org/wiki/Regular_Expressions/POSIX_Basic_Regular_Expressions">Wikipedia entry</a> was a lifesaver. Besides that, I also used the man page for <em>grep</em> as a reference.</p><p>For the project, I thought that a fun idea might be to create a detective game. In the game, you get a folder full of files, and it’s your job to extract information. I called the game <em>Grep detective</em>.</p><p><img src="https://carltheperson.com/media/10-things-linux/4_Grep__Grep_detective/screenshot.png" alt=""></p><h2>5. Awk and sed - <a href="https://github.com/carltheperson/10-Things-Linux/tree/master/5_Awk_and_sed__Passwdinfo">Passwdinfo</a></h2><p><em>Awk</em> and <em>sed</em> are more of the UNIX magic that I have always thought was really cool, though I never really understood what they were used for. I often saw answers on Stack Overflow with people using them in crazy one-liners, but I always copy-pasted them without much thought. Well, time to unravel the mystery.</p><p>I primarily used <a href="https://www-users.york.ac.uk/~mijp1/teaching/2nd_year_Comp_Lab/guides/grep_awk_sed.pdf">this</a> paper to learn about them. For the project, I wanted to create my own one-liner that shows information about the users on your system in a clear way. I found just reading the <em>/etc/passwd</em> a little too messy, so the project <em>passwdinfo</em>, displays the most important information in a neat table. I found information about the <em>/etc/passwd</em> file <a href="https://www.cyberciti.biz/faq/understanding-etcpasswd-file-format/">here</a>.</p><p><img src="https://carltheperson.com/media/10-things-linux/5_Awk_and_sed__Passwdinfo/screenshot.png" alt=""></p><h2>6. Find - <a href="https://github.com/carltheperson/10-Things-Linux/tree/master/6_Find__Find_treasure_hunt">Find treasure hunt</a></h2><p>Another important tool I never really got around to learning. Learning how to use <em>find</em> was fairly easy, it was mostly about memorizing the different flags, and the format you set the flags in. I used <a href="https://kb.iu.edu/d/admm">this</a> as a reference.</p><p>For the project, I created a treasure hunt where you look for clues in files with different attributes. I first wrote a script that created a bunch of small files and directories as noise. Then a selected few of the files got clues to the whereabouts of the other ones. In the end, you find the treasure, which I won’t tell you what is.</p><p><img src="https://carltheperson.com/media/10-things-linux/6_Find__Find_treasure_hunt/screenshot.png" alt=""></p><h2>7. File system - <a href="https://github.com/carltheperson/10-Things-Linux/tree/master/7_File_system__Root_tour">Root tour</a></h2><p>Ever since I executed my first <em>ls /</em> I have wondered what all those directories were for. Time to unveil the mystery. The first thing I did was read <a href="https://www.linux.com/training-tutorials/linux-filesystem-explained/">this</a> article as it explained each directory in root and provided a nice graph. <a href="https://tldp.org/LDP/intro-linux/html/sect_03_01.html">This</a> resource was also nice since it had a table that summed up each directory in one or two sentences.</p><p>The project ended up being a program that gives you descriptions for directories in your own root folder.</p><p><img src="https://carltheperson.com/media/10-things-linux/7_File_system__Root_tour/screenshot.png" alt=""></p><h2>8. Processes - <a href="https://github.com/carltheperson/10-Things-Linux/tree/master/8_Processes__Stranger_danger">Stranger danger</a></h2><p>Processes are another important element of Linux that I have never gotten around to learning. Like many other subjects I have covered here, it turned out to be fairly intuitive. <a href="https://www.geeksforgeeks.org/processes-in-linuxunix/">This</a> article was really easy to understand.</p><p>I was contemplating for a while what kind of project I could create but ultimately came up with a command that prints all processes that don’t belong to you or root. That way, you can keep a close eye on who is creating processes. Note, there are many legitimate reasons that other users would run processes on your system, and it rarely means someone has gained access to your computer.</p><p><img src="https://carltheperson.com/media/10-things-linux/8_Processes__Stranger_danger/screenshot.png" alt=""></p><h2>9. Systemd services - <a href="https://github.com/carltheperson/10-Things-Linux/tree/master/9_Systemd_services__Createservice">Createservice</a></h2><p>Whenever I try to set up a database on a Linux machine I have been confused about how to configure the <em>systemd</em> service. I have also been in situations where I needed to create a service from a binary but always struggled. The struggle ends now.
As with any new subject, it’s always a good idea to read the Wikipedia page, so that is where I started. Surprisingly, I learned that <em>systemd</em> is a quite controversial piece of software, but I still wanted to learn it and judge it for myself.
For understanding the basics of <em>systemd</em> I read <a href="https://www.digitalocean.com/community/tutorials/how-to-use-systemctl-to-manage-systemd-services-and-units">this</a> and for understanding how to create a new service I read <a href="https://www.tecmint.com/create-new-service-units-in-systemd/">this</a>.</p><p>For the project, I made <em>createservice</em>, which allows you to make a <em>systemd</em> service from any executable that will automatically start up on boot. Here I test it out on Prometheus:</p><p><img src="https://carltheperson.com/media/10-things-linux/9_Systemd_services__Createservice/screenshot.png" alt=""></p><h2>10. Bash scripting - <a href="https://github.com/carltheperson/10-Things-Linux/tree/master/10_Bash_scripting__Penguin_cipher">Penguin cipher</a></h2><p>Bash scripting is something I have been avoiding for a long time. Partly because I believe that my programming language of choice, Go, is almost as handy when it comes to scripting, and partly because I think that Bash syntax looks horrible. Can’t knock it till you try it, so here I am trying to learn Bash scripting.</p><p><a href="https://www.howtogeek.com/67469/the-beginners-guide-to-shell-scripting-the-basics/">This</a> was a nice introduction, and after finding <a href="https://devhints.io/bash">this</a> cool cheatsheet I felt comfortable trying to create a project.</p><p>The project ended up being a cipher program I called <em>Penguin cipher</em> after Linux’s mascot. It allows you to encrypt text into something like this: <em>MTExIDIxMSAzMTMgNDAyIDQ2OCA0NjQgMTU5IDI0MSAyMzAgMzY3IDM3NCA1MjYgMTM3IDIyMiAyOTUgMzYzIDQzNCA0MzUg</em></p><p><img src="https://carltheperson.com/media/10-things-linux/10_Bash_scripting__Penguin_cipher/screenshot.png" alt=""></p><hr><p>Follow me on <a href="https://twitter.com/carltheperson">Twitter</a></p><div><p>Email me at: <!-- -->  </p><div><p>c</p><p>a</p><p>r</p><p>l</p><p>t</p><p>h</p><p>e</p><p>p</p><p>e</p><p>r</p><p>s</p><p>o</p><p>n</p><p>_</p><p>p</p><p>r</p><p>o</p><p>t</p><p>o</p><p>n</p><p>m</p><p>a</p><p>i</p><p>l</p><p>:</p><p>c</p><p>o</p><p>m</p></div></div></div></div></div>]]>
            </description>
            <link>https://carltheperson.com/posts/10-things-linux</link>
            <guid isPermaLink="false">hacker-news-small-sites-26002335</guid>
            <pubDate>Tue, 02 Feb 2021 15:47:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Software Development Outsourcing: Our Story]]>
            </title>
            <description>
<![CDATA[
Score 54 | Comments 107 (<a href="https://news.ycombinator.com/item?id=26002217">thread link</a>) | @eagle323
<br/>
February 2, 2021 | https://ascendixtech.com/software-development-outsourcing-our-story/ | <a href="https://web.archive.org/web/*/https://ascendixtech.com/software-development-outsourcing-our-story/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p><span data-contrast="none">Nowadays, there are thousands of well-known companies with hundreds&nbsp;</span><span data-contrast="none">of corporate</span><span data-contrast="none">&nbsp;offices in multiple&nbsp;</span><span data-contrast="none">countries. It is hard to imagine and believe that many years</span><span data-contrast="none">&nbsp;ago there&nbsp;</span><span data-contrast="none">was</span><span data-contrast="none">&nbsp;only the idea and motivation of founders to create something big. </span></p><p><span data-contrast="none">Ascendix&nbsp;</span><span data-contrast="none">Technologies&nbsp;</span><span data-contrast="none">is no exception</span><span data-contrast="none">&nbsp;and</span><span data-contrast="none">&nbsp;</span><span data-contrast="none">today we want to tell you our story&nbsp;</span><span data-contrast="none">of&nbsp;</span><span data-contrast="none">becom</span><span data-contrast="none">ing&nbsp;</span><span data-contrast="none">a&nbsp;</span><span data-contrast="none">leading&nbsp;</span><span data-contrast="none">software</span><span data-contrast="none">&nbsp;development company</span><span data-contrast="none">&nbsp;with&nbsp;</span><span data-contrast="none">diverse</span><span data-contrast="none">&nbsp;expertise</span><span data-contrast="none">.</span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:259}">&nbsp;</span></p><p><span data-contrast="none">In order to&nbsp;</span><span data-contrast="none">leave no detail to chance, we asked our Chief Technical Officer and Managing Partner&nbsp;</span><span data-contrast="none">Todd Terry to describe the Ascendix journey into software development</span><span data-contrast="none">&nbsp;in first person</span><span data-contrast="none">.</span><span data-contrast="none">&nbsp;So, let’s get down to business.</span></p></div><div data-anchor="Birth of an Idea "><h2><strong>Birth of an Idea</strong></h2><p><span lang="EN-US" xml:lang="EN-US" data-contrast="none"><span>It was a Saturday afternoon in October, about 25 years ago, when my longtime friend Wes Snow and I were grabbing a beer during&nbsp;</span></span><span lang="EN-US" xml:lang="EN-US" data-contrast="none"><span>halftime of the</span></span><span lang="EN-US" xml:lang="EN-US" data-contrast="none"><span>&nbsp;Texas/OU game in Dallas. </span></span></p><p><span lang="EN-US" xml:lang="EN-US" data-contrast="none"><span>The way I remember the conversation, we were wondering out loud how cool it would be to start our own business of sorts. I’m not sure we knew exactly what we would do – no defining idea, no special market opportunity</span></span><span lang="EN-US" xml:lang="EN-US" data-contrast="none"><span>. </span></span></p><p><span lang="EN-US" xml:lang="EN-US" data-contrast="none"><span>We were</span></span><span lang="EN-US" xml:lang="EN-US" data-contrast="none"><span>&nbsp;just two recent university grads, still suffering from a terrible economy and generally dissatisfied with our current career options. </span></span></p><p><span lang="EN-US" xml:lang="EN-US" data-contrast="none"><span>Wes was working&nbsp;</span></span><span lang="EN-US" xml:lang="EN-US" data-contrast="none"><span>on a helpdesk</span></span><span lang="EN-US" xml:lang="EN-US" data-contrast="none"><span>&nbsp;for a financial services company and I was working on a helpdesk for an oil and gas exploration company.</span></span></p><div id="attachment_2017"><p><img aria-describedby="caption-attachment-2017" title="Todd and Wes on the Texas-OU game | Ascendix" src="https://ascendixtech.com/wp-content/uploads/2020/12/Screenshot_1.jpg" data-src="https://ascendixtech.com/wp-content/uploads/2020/12/Screenshot_1.jpg" alt="Todd and Wes on the Texas-OU game" width="799" height="603" data-srcset="https://ascendixtech.com/wp-content/uploads/2020/12/Screenshot_1.jpg 799w, https://ascendixtech.com/wp-content/uploads/2020/12/Screenshot_1-300x226.jpg 300w, https://ascendixtech.com/wp-content/uploads/2020/12/Screenshot_1-768x580.jpg 768w" data-sizes="(max-width: 799px) 100vw, 799px" srcset="https://ascendixtech.com/wp-content/uploads/2020/12/Screenshot_1.jpg 799w, https://ascendixtech.com/wp-content/uploads/2020/12/Screenshot_1-300x226.jpg 300w, https://ascendixtech.com/wp-content/uploads/2020/12/Screenshot_1-768x580.jpg 768w"></p><p id="caption-attachment-2017">Todd Terry and Wes Snow</p></div><p><span lang="EN-US" xml:lang="EN-US" data-contrast="none"><span>A few weeks (or maybe a few months) later, Wes calls me with a proposition of sorts. A company that had implemented a contact management system for his current employer had been acquired by a startup out of Arizona and was looking for reseller/implementation partners. </span></span></p><p><span lang="EN-US" xml:lang="EN-US" data-contrast="none"><span>Wes had become a good acquaintance of&nbsp;</span></span><span lang="EN-US" xml:lang="EN-US" data-contrast="none"><span>the&nbsp;</span></span><span lang="EN-US" xml:lang="EN-US" data-contrast="none"><span>acquired company</span></span><span lang="EN-US" xml:lang="EN-US" data-contrast="none"><span>’s owner</span></span><span lang="EN-US" xml:lang="EN-US" data-contrast="none"><span>, and he was now trying to recruit partners in Dallas. </span></span></p><p><span lang="EN-US" xml:lang="EN-US" data-contrast="none"><span>So, <strong>Wes called me with the idea that we would fly to Scottsdale, get trained, and certified to start selling and supporting productivity software for salespeople (now known as CRM). </strong></span></span></p><p><span lang="EN-US" xml:lang="EN-US" data-contrast="none"><span>It seemed like a terrible idea to me at the time, but I was up for a junket to Scottsdale with my good buddy, so I agreed.</span></span></p></div><div><div><div><div><p> <iframe data-data-cli-class="cli-blocker-script" data-cli-label="Youtube embed" data-cli-script-type="" data-cli-block="true" data-cli-block-if-ccpa-optout="false" data-cli-element-position="body" data-cli-placeholder="Accept consent to view this" data-cli-src="https://www.youtube.com/embed/to5BRgwlHr0?rel=0&amp;autoplay=1" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></p></div></div></div></div><div data-bg="https://ascendixtech.com/wp-content/uploads/2020/12/cta-background.jpg"><div><div><div><div><h4>Get Our Software Development Hourly Rates</h4><p>Looking for a software development partner? Answer our quick quiz to get a ball-park cost of developing your software</p></div></div></div></div></div><div data-anchor="First Steps Towards the Launch "><h2><strong>First Steps Towards the Launch</strong></h2><p><span data-contrast="none">In retrospect, the trip was life-changing. </span></p><p><span data-contrast="none">In less than two weeks, we both learned how to implement and customize a </span><span data-contrast="none">rather sophisticated</span><span data-contrast="none">&nbsp;client-server system that had&nbsp;</span><span data-contrast="none">cutting edge</span><span data-contrast="none">&nbsp;remote database synchronization capabilities (in 1996)</span><span data-contrast="none">. </span></p><p><span data-contrast="none">They were</span><span data-contrast="none">&nbsp;perfect for a remote field sales team, as connectivity&nbsp;</span><span data-contrast="none">wasn’t</span><span data-contrast="none">&nbsp;so ubiquitous then. </span></p><p><span data-contrast="none">Wes and I both had some technical background from our university&nbsp;</span><span data-contrast="none">coursework</span><span data-contrast="none">, so we understood&nbsp;</span><span data-contrast="none">high-level</span><span data-contrast="none"> concepts, but this was our first jump into the realm of business software solutions.</span></p></div><div><div><p> <span>“</span> We didn’t understand fully at the time, but to be successful with what would&nbsp;become today’s CRM software, we needed to become experts at “sudden expertise:”&nbsp;the idea that a consultant can drop into your business, learn it in a matter of a few days, then propose how to tailor a productivity system to help them do business…&nbsp;better.&nbsp; <span>”</span></p></div></div><div><p>We had no typical client – they were small, medium, and large, financial, hospitality, manufacturing, healthcare, construction, and heavy equipment, but they were all&nbsp;trying to solve the same pains.</p><p>They wanted to&nbsp;help their customer-facing workers make better-informed decisions, and somehow gain visibility into what was happening with their sales pipeline.</p></div><div data-anchor="Primary Ups and Downs "><h2><strong>Primary Ups and Downs</strong></h2><p><span data-contrast="none">We had some early successes that helped fund our business. </span></p></div><div data-bg="https://ascendixtech.com/wp-content/uploads/2020/10/cta-background.jpg"><div><div><div><p><h4><strong>Our second customer, a member of the Fortune 500, found us on the Internet and never asked us for references.</strong></h4></p></div></div></div></div><div><p>They just liked us, our presentation (we flew to their&nbsp;headquarters&nbsp;to present), and our price, and accepted our proposal for a&nbsp;200-user system that was meant to be temporary while their department waited in line for an upcoming Siebel implementation.</p><p><span data-contrast="none">We&nbsp;</span><span data-contrast="none">maneuvered</span><span data-contrast="none">, worked with the administrative assistant of the department head, and in a matter of&nbsp;</span><span data-contrast="none">10</span><span data-contrast="none">-12 weeks had this department of a Fortune 500 company with a new, successfully running system that they used for years. </span></p><p><strong>(Funny fact, their server sat under the desk of the admin assistant, unknown and untouched by the IT team for more than a year before it was finally brought into the server room.) </strong></p><p><span data-contrast="none">This referenceable Fortune 500 client (whose name exists </span><span data-contrast="none">in</span><span data-contrast="none">&nbsp;NFL stadiums) would help us continue our success for many more years.</span></p><p><span data-contrast="none">We also had our share of failures, and from these, we really learned about what makes good software and a successful project, and this became part of our company DNA. </span></p><p><span data-contrast="none">Our failures were primarily due to taking on projects with compromises – projects where we didn’t focus on the user’s needs, but the needs of those managing the users. </span></p><p><span data-contrast="none">This&nbsp;</span><span data-contrast="none">experience&nbsp;</span><span data-contrast="none">allowed us to&nbsp;</span><span data-contrast="none">learn how to advocate for the user in order to help their managers and stakeholders achieve their objectives as well.</span></p></div><div data-anchor="Defining Our Competitive Advantage "><h2><strong>Defining Our Competitive Advantage</strong></h2><p><span data-contrast="none">Enterprise business software is not user friendly. </span></p><p><span data-contrast="none">It’s generally not well-liked by users (especially salespeople, who are typically successful for reasons other than good computer skills). </span></p><p><span data-contrast="none">It’s usually hard to find information, </span><span data-contrast="none">difficult</span><span data-contrast="none">&nbsp;to act on this&nbsp;</span><span data-contrast="none">data,</span><span data-contrast="none">&nbsp;and&nbsp;</span><span data-contrast="none">tough&nbsp;</span><span data-contrast="none">to use this information in a way that helps you be a more effective professional.</span></p></div><div data-bg="https://ascendixtech.com/wp-content/uploads/2020/10/cta-background.jpg"><div><div><div><p><h4><strong>Comparing today’s business productivity software to what we used 25 years ago, in my opinion,&nbsp;evolution has been slow and unremarkable.</strong></h4></p></div></div></div></div><div><p><span data-contrast="none">Yes, that remote database syncing client-server system Wes and I learned to implement and customize back in 1996 is quite ugly and out-of-date looking compared to today’s interface in Salesforce or Dynamics, but the functionality is remarkably unchanged. </span></p><p><strong>Moreover,&nbsp;the challenges we faced&nbsp;then&nbsp;are still real today:&nbsp;user adoption, user stickiness.</strong></p><p><span data-contrast="none">I</span><span data-contrast="none">’ll never forget the day, about 10 years ago, I was sitting in a conference room in Seattle for a global commercial real estate client (400+ offices and 15K people). </span></p><p><span data-contrast="none">We had just wrapped phase 1 of the project and completed a full day’s training for our first wave of users. </span></p><p><span data-contrast="none">The president, who was deeply involved in the project since the vendor selection stage looked at me and said: “Todd, you guys have done a great job building exactly what we’ve looked for, but I still wonder why CRM software still has to be so hard to use.” </span></p><p><span data-contrast="none">I was a bit taken aback, as 75% of our solution for commercial real estate was more about usability, and the other 25% specifically about real estate, and he just said it was still hard to use.</span></p></div><div><div><p> "<strong>You should build your products like Apple. Like LinkedIn. Like Amazon.</strong> If I can network on LinkedIn, or build my playlist on Apple, or find the products I need on Amazon without going through a full day of training, then I should be able to do the same with your software. While yours is the best I’ve seen, I think it can be better!"</p><p><h6>- Ascendix client</h6></p></div></div><div><p><span data-contrast="none">I made my informed excuses about enterprise software – that you must give up some usability in order to have flexibility and customizability. </span></p><p><span data-contrast="none">He reluctantly agreed, but I got his point.</span></p><p><span data-contrast="none">Our differentiator over these 25 years started by advocating for the user and making our client’s software easier to use. </span></p><p><span data-contrast="none">We hired&nbsp;</span><span data-contrast="none">really smart</span><span data-contrast="none"> and talented developers who could develop and implement seamlessly integrated usability solutions to otherwise hard-to-use software.</span></p></div><div data-bg="https://ascendixtech.com/wp-content/uploads/2020/10/cta-background.jpg"><div><div><div><p><h4><strong>We made it easier for users to search for information, easier for users to organize the information, easier to act on it.</strong></h4></p></div></div></div></div><div><p><span data-contrast="none">We put ourselves in our users’ shoes and mapped end-to-end process flow with the system, and then built plug-ins to plug the holes in those end-to-end flows. </span></p><p><span data-contrast="none">We started using these solutions for all our implementations, then started to use it as a framework to combine it with our growing business experience in certain industries (Commercial Real Estate, Financial Services, Professional Services) as modules and industry solutions. </span></p><p><span data-contrast="none">The first industry solution we built for companies who sold private REIT products to registered representatives, which fueled our start in software development until the global financial crisis arrived in 2007.</span><span data-ccp-props="{&quot;201341983&quot;:0,&quot;335559739&quot;:160,&quot;335559740&quot;:259}">&nbsp;</span></p><p><iframe data-cli-class="cli-blocker-script" data-cli-label="Youtube embed" data-cli-script-type="" data-cli-block="true" data-cli-block-if-ccpa-optout="false" data-cli-element-position="body" data-cli-placeholder="Accept consent to view this" data-cli-src="https://www.youtube.com/embed/Vcq0PQVwnIQ" width="100%" height="515" frameborder="0" allowfullscreen="allowfullscreen"></iframe></p></div><div data-anchor="Outsourcing Software Development"><h2><strong>Starting a Software Development Outsource Story </strong></h2><p><span data-contrast="none">Our journey also took us to different parts of the world.&nbsp;</span></p><p><span data-contrast="none">Wes and I decided to bootstrap our product development with a combination of reinvestment of profits and debt vehicles.</span></p><p><strong> This&nbsp;meant a model where we develop software that may not bring us revenue for months, or sometimes even years after an investment&nbsp;of&nbsp;capital. </strong></p><p><span data-contrast="none">We looked for ways to stretch the dollar, which inevitably means outsourcing. </span></p><p><span data-contrast="none">Our vendor&nbsp;</span><span data-contrast="none">search</span><span data-contrast="none">&nbsp;took us to China and India. Then, hurting from the lost hours due to cultural and time differences, we&nbsp;</span><span data-contrast="none">near-shored</span><span data-contrast="none"> in Argentina and Mexico.</span></p><p><strong>It wasn’t&nbsp;successful&nbsp;until we worked&nbsp;on a&nbsp;special pilot project with a company in Ukraine that we became real believers that outsourcing could work so effectively. </strong></p><p><span data-contrast="none">After a couple of very successful years working&nbsp;</span><span data-contrast="none">as</span><span data-contrast="none"> a partner, we decided it was time to continue our growth by acquiring our team and establishing our own location there.</span></p></div><div data-bg="https://ascendixtech.com/wp-content/uploads/2020/10/cta-background.jpg"><div><div><div><p><h4><strong>Our team,&nbsp;from&nbsp;our original 8 members,&nbsp;was around 30 when they made the transition, and now we are on our way to 200.</strong></h4></p></div></div></div></div><p><span data-contrast="none">The original team architected our search and big data solutions, and now we have 6 separate product offerings: from industry-specific solutions on Salesforce and Dynamics to mobile, desktop, marketing, and publishing solutions architected with various technologies in </span><a href="https://ascendixtech.com/technologies/net-application-development/"><span data-contrast="none">.NET</span></a><span data-contrast="none">, <a href="https://ascendixtech.com/technologies/java-software-development/">Java</a>, <a href="https://ascendixtech.com/technologies/javascript-app-development/">JavaScript</a>, and <a href="https://ascendixtech.com/technologies/xamarin-app-development/">Xamarin</a>, leveraging search and data platforms like Elasticsearch, Couchbase, Cosmos DB and deployed through Azure and Amazon cloud.</span></p><div><div><p> <span>“</span> We have evolved our services/custom&nbsp;software&nbsp;development practice largely based on our experiences with more than 20 years of user-centric advocacy and best practices for product development and support. <span>”</span></p><p><h6>Todd Terry, CTO &amp; Managing Partner</h6></p></div></div><div><p>We have&nbsp; Agile project teams, dedicated client teams, or anything in between.</p><p><strong>We’ve evolved a great practice where we can run a project in the US, blend a team from Ukraine, or run it entirely out of Ukraine with personnel who have very …</strong></p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://ascendixtech.com/software-development-outsourcing-our-story/">https://ascendixtech.com/software-development-outsourcing-our-story/</a></em></p>]]>
            </description>
            <link>https://ascendixtech.com/software-development-outsourcing-our-story/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26002217</guid>
            <pubDate>Tue, 02 Feb 2021 15:39:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[RISC-V isn’t as interesting as you think]]>
            </title>
            <description>
<![CDATA[
Score 120 | Comments 145 (<a href="https://news.ycombinator.com/item?id=26001972">thread link</a>) | @glhaynes
<br/>
February 2, 2021 | https://sporks.space/2021/02/01/risc-v-isnt-as-interesting-as-you-think/ | <a href="https://web.archive.org/web/*/https://sporks.space/2021/02/01/risc-v-isnt-as-interesting-as-you-think/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-47">
	<!-- .entry-header -->

	
		<div>
			
<p><em>I had wrote this before the Unleashed was revealed, so some of the bits on economics have changed. As of writing this, I still stand by my other beliefs. </em>One of the most hyped things in hardware design is RISC-V, the open ISA available without license fees. Many organizations including <a href="https://www.westerndigital.com/company/innovations/risc-v">Western Digital</a> have pledged support for RISC-V, and the open source community has a lot of faith in it, and with <a href="https://www.anandtech.com/show/16080/nvidia-to-acquire-arm-for-40-billion">Nvidia’s recent purchase of Arm</a>, people are concerned. However, I feel these hopes are somewhat misleading, as RISC-V’s openness is less at the benefit of the user and more for CPU vendors.</p>

<p><strong>Royalties</strong>. One of the biggest benefits of RISC-V is not having to pay any royalties for a CPU using it. You might pay SiFive or someone else for a realization of their cores on hard silicon, but that’s for the design, not an abstract implementation of the ISA. Openness here means there’s more profit margin on the tiny chips running washing machines, since they don’t have to pay ARM or Synopsys. While the savings could be passed onto you, the ISA’s openness will never be of concern when the program is on a one-time-programmable ROM.</p>



<p><strong>ISA fragmentation</strong>. RISC-V intentionally defines a small ISA with extensions (for example, multiplication, which actually encompasses divide too… which is even more expensive to implement than multiply, but it’s a package deal). While most larger implementations will implement a common set of extensions, having basic functionality in extensions could make software compatibility for binary distributions harder. This is made worse by RISC-V explicitly encouraging custom instructions for task-specific tweaks on vendor silicon – great for embedded, not so hot for general purpose computers and operating systems supporting them.</p>



<p><strong>Economics</strong>. RISC-V has actively courted embedded, which makes sense as a niche. Much of the hype of RISC-V is hoping for laptop/desktop/server class silicon. This is unlikely, because the economics of embedded are different. ISA doesn’t matter as much in embedded programming (code reuse matters, but it’s not like you’re running arbitrary binaries), whereas user/enterprise focused computing usually lives and dies by binary compatibility (to protect investments in existing applications) and performance gained by things most RISC-V implementations don’t have yet like superscalar execution (To say nothing how these impact implementation complexity and security!).</p>



<p><strong>Openness doesn’t tickle down</strong>. The openness of an ISA doesn’t have much impact on the implementation. A design with restricted signing keys is completely acceptable under their licensing – and is very likely, considering the embedded dominance RISC-V is likely to have. There are no guarantees of openness in ways that impact a user (i.e controlling the root of trust), since a user doesn’t exactly have access to a fab.</p>



<p><strong>Design flaws</strong>. RISC-V seems like it hasn’t learned anything from CPUs designed after 1991. Between some <a href="https://gist.github.com/erincandescent/8a10eeeea1918ee4f9d9982f7618ef68">rookie mistakes</a> like few <a href="https://lobste.rs/s/yqqhxu/llvm_for_m68k_completed_not_merged">addressing modes</a> (register churn, code density) and <a href="https://lobste.rs/s/icegvf/will_risc_v_revolutionize_computing#c_8wbb6t">blowing out the encoding space</a>. However, despite its flaws, it’s poised to take over embedded and possibly beyond anyways – worse truly is better.</p>



<p>Overall, RISC-V will lead in a revolution for nationalist vanity CPUs (think Loongson; no one will run them but for show and perhaps a niche of radical ideologues) , academic projects, and embedded vendors wanting to save on their balance sheets, but it probably won’t affect users or developers.</p>
					</div><!-- .entry-content -->

	
	<!-- .entry-footer -->
</article></div>]]>
            </description>
            <link>https://sporks.space/2021/02/01/risc-v-isnt-as-interesting-as-you-think/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26001972</guid>
            <pubDate>Tue, 02 Feb 2021 15:24:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Reshaped Mac Experience]]>
            </title>
            <description>
<![CDATA[
Score 86 | Comments 71 (<a href="https://news.ycombinator.com/item?id=26001540">thread link</a>) | @yannovitch
<br/>
February 2, 2021 | http://morrick.me/archives/9150 | <a href="https://web.archive.org/web/*/http://morrick.me/archives/9150">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
			<p>Yesterday, a short <a href="https://twitter.com/lapcatsoftware/status/1355514848717791234">Twitter thread</a> by the excellent <a href="https://lapcatsoftware.com/articles/">Jeff Johnson</a> caught my eye. Since he often deletes past tweets, I’ll quote the relevant ones here (emphasis mine):</p>
<blockquote><p><strong>The selling point of the Macintosh was never the hardware, it was the user interface. So if the selling point now is the hardware, that’s a damning indictment of the current user interface.</strong></p>

<p><strong>I cannot emphasize enough how everyone seems to have lowered their standards with regard to the user interface.</strong> The “<a href="https://en.wikipedia.org/wiki/Overton_window">Overton window</a>” has moved. The Overton window now has rounded rects.</p>

<p>We’ve gone from “insanely great” and “It just works” to “Catalyst is good enough for most people.”</p>
<p>That’s fucking BS, and I won’t tolerate it.</p>

<p>Windows is “good enough for most people”. That’s why Windows has a 90% market share. Why should we aspire to that level, shouldn’t we have much higher aspirations? Mac is a niche. “Most people” are not even using Macs, so the majority is not even relevant. Mac is a premium brand.</p>

<p>The way I see it, the Mac now is merely milking the brand reputation and loyalty it previously built. That Jobs previously built. But neither Cook nor the current Mac deserves that reputation or loyalty.</p>

<p>Steve Jobs wasn’t an engineer. Not a hardware engineer, not a software engineer. At Apple, his role was as “proxy” for the&nbsp;users.</p>
<p>Apple no longer has a proxy for the users. Tim Cook is a proxy for the shareholders, nothing more.</p></blockquote>
<p>Jeff himself says that this criticism is hardly new, that these are things he already pointed out “a thousand times, to no effect”. While I am in no position to affect Apple or Mac development, this short Twitter rant had the effect of reminding me of something I, too, believe in; something I myself should emphasise more frequently. It’s those first two tweets I’ve quoted above.</p>
<p>As someone who still puts vintage Macs and older computers and devices to good use, the Mac’s user interface and user experience are in large part what still makes using 15–20-year-old machines enjoyable. This, by the way, also applies to other products of course. It’s thanks to well-designed user interfaces that we enjoy driving a classic car, or shooting with a 50-year-old film camera, or listening to vinyl records on a 40-year-old record-player and hi-fi stereo.</p>
<p>A couple of weeks ago I was on a group videochat with some friends and when I said that, frankly, using my 12-inch PowerBook G4 (2003) with Mac OS X 10.5 Leopard was more enjoyable than using my 13-inch retina MacBook Pro (2015) with Mac OS 11 Big Sur, the common reaction was that I was just being ‘nostalgic’; that surely my MacBook Pro was the better choice because it is orders of magnitude faster, with a ‘more modern’ OS, and that the sum of those parts was a better Mac experience. That I should ‘be rational’ and accept that.</p>
<p>Here, bringing up nostalgia is missing the point. And the point is that an admittedly faster hardware plus a purportedly ‘more modern’ operating system <em>do not necessarily</em> equal a better Mac experience. It’s interesting that my friends’ reaction was not to ask me <em>why</em> I was finding using an 18-year-old machine more enjoyable than an up-to-date Mac, but to promptly want to readjust my enjoyment, implying that there was something ‘wrong’ with&nbsp;it.</p>
<p>I’m finding that many people not only have lowered their standards with regard to the user interface, but more and more often when I bring up the subject, they seem to consider it a somewhat secondary aspect, something that’s only good for ‘geek talk’. The same kind of amused reaction laymen have to wine or coffee connoisseurs when they describe flavours and characteristics using specific lingo. Something that makes sense only to wine or coffee geeks but has little to no meaning or impact for the regular person.</p>
<p>The problem is that if an increasing number of people start viewing user interface design as an afterthought, or something that isn’t fundamental to the design of a product or experience — it’s all just ‘geek talk’ — then there is a reduced incentive to care about it on the part of the maker of the product. It’s more like a vicious circle, really; if Apple software’s quality declines but only a bunch of professional users and enthusiasts point that out, then Apple isn’t particularly incentivised to do a better job at it — the “good enough for most people” is really a dangerous, self-indulgent excuse. And in turn most people are fine with it, and in turn Apple think they’re on a ‘good’ path, and so&nbsp;forth.</p>
<p>At the very end of my piece <a href="http://morrick.me/archives/9141"><em> What about the M1 Macs?</em></a>, I&nbsp;wrote:</p>
<blockquote><p>They’re unbelievably good machines, and everything that is genuinely good about them and future Apple Silicon-based Macs — sheer performance, astounding power-efficiency, and great backward compatibility with Intel software thanks to Rosetta 2 — will also allow Apple to get away with a lot of things with regard to platform control, design decisions, and so&nbsp;forth.</p></blockquote>
<p>If you take a look at Jason Snell’s <a href="https://sixcolors.com/post/2021/01/apple-in-2020-the-six-colors-report-card/"><em>Apple in 2020: The Six Colors report card</em></a>, the Mac scored very good points overall, 4.7 out of 5, with a year-over-year increment of 1.1 points. The main reason has been of course the M1 Macs and Apple Silicon. Don’t get me wrong, Apple Silicon <em>is</em> groundbreaking, and Rosetta 2 is really an incredible performer on the software side. But what I contend is that a leap in hardware architecture and performance doesn’t necessarily mean that suddenly all is fine with the Mac as a platform or as an experience.</p>
<p>The Mac’s user interface is undergoing plastic surgery by the hand of surgeons who have studied on iOS books. The result is pretty much the same as when you see a favourite celebrity after a procedure. They look ‘younger’ but there’s also something weird about their appearance. Their traits have changed a bit. In certain cases you almost fail to recognise the person at first glance.</p>
<p>Similarly, the Mac experience today feels disjointed. The hardware has unquestionably improved with the introduction of Apple Silicon, and yes, it’s something worth celebrating and it’s something worth praising. On the other hand, the software that drives this hardware is a bit of a paradox: Big Sur and Apple Silicon Macs fit and work together well from a technical, architectural standpoint. From a user interface standpoint, however, Big Sur embodies what I’ve been fearing in recent years — a progressive iOS-ification of Mac OS. Big Sur provides a general user experience that is the least Mac-like in the history of the Mac. Going through Big Sur’s user interface with a fine-tooth comb reveals arbitrary design decisions that prioritise looks over function, and therefore reflect an un-learning of tried-and-true user interface and usability mechanics that used to make for a seamless, thoughtful, enjoyable Mac experience.</p>
<p>iOS was born as a ‘spinoff’ of Mac OS X, a sort of Lite version aimed at mobile devices like the iPhone and the iPod touch. The two platforms have maintained their separate paths and trajectories for years, and for a while using a Mac and an iPhone (or iPad) felt like having the best experience of each world. Then Apple became obsessed with thoughts of convergence, and features, UI ideas, paradigms, started bleeding through both platforms and in turn the respective experiences have become less clear-cut over time, with the software not fully capable of bringing out all that hardware power and potential.</p>
<p>This convergence will continue, of course, with Macs becoming more and more like ‘senior iOS devices’ from a UI and user experience standpoint. It seems clear to me that Apple is prioritising ecosystem experience because, let’s be honest, having a unified ‘operating system core’ underlying all platforms means having fewer framework-specific headaches and probably a faster, streamlined process when deploying new features. But this loss of differentiation is especially detrimental to Mac OS, which is being reduced to the lowest common denominator and loses an increasing amount of user interface ideas and conventions that were central to its superior user experience and ease of&nbsp;use.</p>
<p>I’m not annoyed because I see pieces of UI history fading away. I’m annoyed because I see pieces of <em>good</em> UI design fading away and being replaced by decisions that are puzzling and arbitrary, or the product of a trial-and-error process, rather than a meaningful, purposeful design.</p>
<p>You want an example that I find particularly glaring? Big Sur’s UI features a general increase of space between elements — icons, menus, labels, toolbars, sidebars, pretty much everywhere. On the surface it doesn’t seem like a bad decision. If you zoom in on certain parts of the user interface, you could say that more space between elements means that things looks cleaner, airier, sleeker.</p>
<p>But you’re looking at it on a 27-inch retina display. What about a display half that size? What about an 11-inch, non-retina display, like the one of the older 2013–2015 MacBook Airs that can be updated to Big Sur? It’s less pretty.</p>
<p><a href="https://i0.wp.com/morrick.me/wp-content/uploads/2021/01/Big-Sur-13-MBP-2.png"><img loading="lazy" src="https://i0.wp.com/morrick.me/wp-content/uploads/2021/01/Big-Sur-13-MBP-2.png?resize=960%2C600" alt="" width="960" height="600" srcset="https://i0.wp.com/morrick.me/wp-content/uploads/2021/01/Big-Sur-13-MBP-2.png?w=2560 2560w, https://i0.wp.com/morrick.me/wp-content/uploads/2021/01/Big-Sur-13-MBP-2.png?resize=260%2C163 260w, https://i0.wp.com/morrick.me/wp-content/uploads/2021/01/Big-Sur-13-MBP-2.png?resize=640%2C400 640w, https://i0.wp.com/morrick.me/wp-content/uploads/2021/01/Big-Sur-13-MBP-2.png?resize=768%2C480 768w, https://i0.wp.com/morrick.me/wp-content/uploads/2021/01/Big-Sur-13-MBP-2.png?resize=1536%2C960 1536w, https://i0.wp.com/morrick.me/wp-content/uploads/2021/01/Big-Sur-13-MBP-2.png?resize=2048%2C1280 2048w, https://i0.wp.com/morrick.me/wp-content/uploads/2021/01/Big-Sur-13-MBP-2.png?resize=1194%2C746 1194w, https://i0.wp.com/morrick.me/wp-content/uploads/2021/01/Big-Sur-13-MBP-2.png?w=1920 1920w" sizes="(max-width: 960px) 100vw, 960px" data-recalc-dims="1"></a></p>
<p>I usually work with a lot of app windows and Finder windows, but when I’m using my 13-inch retina MacBook Pro with Big Sur, the workspace constantly feels cramped, while on the other hand I have no problems using High Sierra on my 11-inch MacBook Air. Sometimes it feels like looking at a zoomed-in interface. That increased space between elements becomes less of a good idea because it doesn’t scale gracefully when the overall screen real estate is reduced. It becomes an interference. Before installing Big Sur, the amount of icons on the right of the menu bar had never really been a concern. Now, the simple addition of a couple of third-party apps like Dropbox and iStat Menus — both essential for me — is enough to make that menu bar look crowded. (And thankfully Apple has been reducing the space between menu icons, because in the first Big Sur betas icon padding was so bad I had to remove a few icons and use Control Centre to check on their status).</p>
<p>This, like other UI design decisions in Big Sur, feels like …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://morrick.me/archives/9150">http://morrick.me/archives/9150</a></em></p>]]>
            </description>
            <link>http://morrick.me/archives/9150</link>
            <guid isPermaLink="false">hacker-news-small-sites-26001540</guid>
            <pubDate>Tue, 02 Feb 2021 14:49:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[CompilerGym: A toolkit for reinforcement learning for compiler optimization]]>
            </title>
            <description>
<![CDATA[
Score 133 | Comments 16 (<a href="https://news.ycombinator.com/item?id=26001480">thread link</a>) | @azhenley
<br/>
February 2, 2021 | https://facebookresearch.github.io/CompilerGym/getting_started.html | <a href="https://web.archive.org/web/*/https://facebookresearch.github.io/CompilerGym/getting_started.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    
    <nav data-toggle="wy-nav-shift">
      
    </nav>

    <section data-toggle="wy-nav-shift">

      
      <nav aria-label="top navigation">
        
          <i data-toggle="wy-nav-top"></i>
          <a href="https://facebookresearch.github.io/CompilerGym/index.html">CompilerGym</a>
        
      </nav>


      <div>
        
        <div>
        
          
















          <div role="main" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  <div id="getting-started">

<p><a href="https://colab.research.google.com/github/facebookresearch/CompilerGym/blob/development/examples/getting-started.ipynb"><img alt="https://colab.research.google.com/assets/colab-badge.svg" src="https://colab.research.google.com/assets/colab-badge.svg"></a></p><p>CompilerGym is a toolkit for applying reinforcement learning to compiler
optimization tasks. This document provides a short walkthrough of the key
concepts, using the codesize reduction task of a production-grade compiler
as an example. It will take about 20 minutes to work through. Lets get
started!</p>

<div id="key-concepts">
<h2><a href="#id3">Key Concepts</a><a href="#key-concepts" title="Permalink to this headline">¶</a></h2>
<p>CompilerGym exposes compiler optimization problems as environments for
reinforcement learning. It uses the <a href="https://gym.openai.com/">OpenAI Gym</a>
interface to expose the “agent-environment loop” of reinforcement learning:</p>
<p><img alt="_images/overview.png" src="https://facebookresearch.github.io/CompilerGym/_images/overview.png"></p><p>The ingredients for reinforcement learning that CompilerGym provides are:</p>
<ul>
<li><p><strong>Environment</strong>: a compiler optimization task. For example,
<em>optimizing a C++ graph-traversal program for codesize using LLVM</em>. The
environment encapsulates an instance of a compiler and a particular program
that is being compiled. As an agent interacts with the environment, the state
of the program, and the compiler, can change.</p></li>
<li><p><strong>Action Space</strong>: the actions that may be taken at the current environment
state. For example, this could be a set of optimization transformations that
the compiler can apply to the program.</p></li>
<li><p><strong>Observation</strong>: a view of the current environment state. For example, this
could be the Intermediate Representation (IR) of the program that is being
compiled. The types of observations that are available depend on the compiler.</p></li>
<li><p><strong>Reward</strong>: a metric indicating the quality of the previous action. For
example, for a codesize optimization task this could be the change to the
number of instructions of the previous action.</p></li>
</ul>
<p>A single instance of this “agent-environment loop” represents the compilation of
a particular program. The goal is to develop an agent that maximises the
cumulative reward from these environments so as to produce the best programs.</p>
</div>
<div id="installation">
<h2><a href="#id4">Installation</a><a href="#installation" title="Permalink to this headline">¶</a></h2>
<p>Install the latest CompilerGym release using:</p>
<div><div><pre><span></span>$ pip install compiler_gym
</pre></div>
</div>
<p>The binary works on macOS and Linux (on Ubuntu 18.04, Fedora 28, Debian
10 or newer equivalents).</p>
<div id="building-from-source">
<h3><a href="#id5">Building from Source</a><a href="#building-from-source" title="Permalink to this headline">¶</a></h3>
<p>If you prefer, you may build from source. This requires a modern C++
toolchain. On macOS you can use the system compiler. On linux, install
the required toolchain using:</p>
<div><div><pre><span></span>$ sudo apt install clang libtinfo5 patchelf
$ export CC=clang
$ export CXX=clang++
</pre></div>
</div>
<p>We recommend using
<a href="https://docs.conda.io/projects/conda/en/latest/user-guide/install/">conda</a>
to manage the remaining build dependencies. First create a conda
environment with the required dependencies:</p>
<div><div><pre><span></span>$ conda create -n compiler_gym python=3.8 bazel=3.1.0 cmake pandoc
$ conda activate compiler_gym
</pre></div>
</div>
<p>Then clone the CompilerGym source code using:</p>
<div><div><pre><span></span>$ git clone https://github.com/facebookresearch/CompilerGym.git
$ cd CompilerGym
</pre></div>
</div>
<p>Install the python development dependencies using:</p>

<p>Then run the test suite to confirm that everything is working:</p>

<p>To build and install the python package, run:</p>

<p>When you are finished, you can deactivate and delete the conda
environment using:</p>
<div><div><pre><span></span>$ conda deactivate
$ conda env remove -n compiler_gym
</pre></div>
</div>
</div>
</div>
<div id="using-compilergym">
<h2><a href="#id6">Using CompilerGym</a><a href="#using-compilergym" title="Permalink to this headline">¶</a></h2>
<p>Begin by firing up a python interpreter:</p>

<p>To start with we import the gym module and the CompilerGym environments:</p>
<div><div><pre><span></span><span>&gt;&gt;&gt; </span><span>import</span> <span>gym</span>
<span>&gt;&gt;&gt; </span><span>import</span> <span>compiler_gym</span>
</pre></div>
</div>
<p>Importing <a href="https://facebookresearch.github.io/CompilerGym/compiler_gym/compiler_gym.html#module-compiler_gym" title="compiler_gym"><code><span>compiler_gym</span></code></a> automatically registers the compiler environments.</p>
<p>We can see what environments are available using:</p>
<div><div><pre><span></span><span>&gt;&gt;&gt; </span><span>compiler_gym</span><span>.</span><span>COMPILER_GYM_ENVS</span>
<span>['llvm-v0', 'llvm-ic-v0', 'llvm-autophase-ic-v0', 'llvm-ir-ic-v0']</span>
</pre></div>
</div>
<div id="selecting-an-environment">
<h3><a href="#id7">Selecting an environment</a><a href="#selecting-an-environment" title="Permalink to this headline">¶</a></h3>
<p>CompilerGym environments are named using one of the following formats:</p>
<ol>
<li><p><code><span>&lt;compiler&gt;-&lt;observation&gt;-&lt;reward&gt;-&lt;version&gt;</span></code></p></li>
<li><p><code><span>&lt;compiler&gt;-&lt;reward&gt;-&lt;version&gt;</span></code></p></li>
<li><p><code><span>&lt;compiler&gt;-&lt;version&gt;</span></code></p></li>
</ol>
<p>Where <code><span>&lt;compiler&gt;</span></code> identifiers the compiler optimization task,
<code><span>&lt;observation&gt;</span></code> is the default type of observations that are provided,
and <code><span>&lt;reward&gt;</span></code> is the reward signal.</p>
<div>
<p>Note</p>
<p>A key concept is that
CompilerGym environments enables <strong>lazy evaluation</strong> of observations and
reward signals. This makes the environment much more computationally
efficient for scenarios in which you do not need to compute a reward or
observation for every step. If an environment omits a <code><span>&lt;observation&gt;</span></code>
or <code><span>&lt;reward&gt;</span></code> tag, this means that no observation or reward is
provided by default. See <a href="https://facebookresearch.github.io/CompilerGym/compiler_gym/views.html"><span>compiler_gym.views</span></a> for
further details.</p>
</div>
<p>For this tutorial, we will use the following environment:</p>
<ul>
<li><p><strong>Compiler</strong>: <a href="https://facebookresearch.github.io/CompilerGym/llvm/index.html"><span>LLVM</span></a>.</p></li>
<li><p><strong>Observation Type</strong>: <a href="https://facebookresearch.github.io/CompilerGym/llvm/index.html#autophase"><span>Autophase</span></a>.</p></li>
<li><p><strong>Reward Signal</strong>: <a href="https://facebookresearch.github.io/CompilerGym/llvm/index.html#codesize"><span>IR Instruction count relative to -Oz</span></a>.</p></li>
</ul>
<p>Create an instance of this environment using:</p>
<div><div><pre><span></span><span>&gt;&gt;&gt; </span><span>env</span> <span>=</span> <span>gym</span><span>.</span><span>make</span><span>(</span><span>"llvm-autophase-ic-v0"</span><span>)</span>
</pre></div>
</div>
</div>
<div id="installing-benchmarks">
<h3><a href="#id8">Installing benchmarks</a><a href="#installing-benchmarks" title="Permalink to this headline">¶</a></h3>
<p>A compiler requires a program as input. For the purposes of CompilerGym we call
these input programs <em>benchmarks</em>, and collections of benchmarks are assembled
into <em>datasets</em>. You may provide your own programs to use as benchmarks, or
download one of our pre-assembled datasets.</p>
<p>The benchmarks that are available to an environment can be queried using
<a href="https://facebookresearch.github.io/CompilerGym/compiler_gym/envs.html#compiler_gym.envs.CompilerEnv.benchmarks" title="compiler_gym.envs.CompilerEnv.benchmarks"><code><span>env.benchmarks</span></code></a>:</p>

<p>As you can see, there are no benchmarks installed by default. We have provided
a collection of pre-assembled
<a href="https://facebookresearch.github.io/CompilerGym/llvm/index.html#datasets"><span>LLVM benchmark datasets</span></a> that can be
installed using
<a href="https://facebookresearch.github.io/CompilerGym/compiler_gym/envs.html#compiler_gym.envs.CompilerEnv.require_dataset" title="compiler_gym.envs.CompilerEnv.require_dataset"><code><span>env.require_dataset()</span></code></a>.
For this tutorial we will use the
<a href="https://www.nas.nasa.gov/publications/npb.html">NAS Parallel Benchmarks</a>
dataset:</p>
<div><div><pre><span></span><span>&gt;&gt;&gt; </span><span>env</span><span>.</span><span>require_dataset</span><span>(</span><span>"npb-v0"</span><span>)</span>
</pre></div>
</div>
<p>Now, <a href="https://facebookresearch.github.io/CompilerGym/compiler_gym/envs.html#compiler_gym.envs.CompilerEnv.benchmarks" title="compiler_gym.envs.CompilerEnv.benchmarks"><code><span>env.benchmarks</span></code></a> lists
the 123 benchmarks that comprise the dataset we just installed:</p>
<div><div><pre><span></span><span>&gt;&gt;&gt; </span><span>env</span><span>.</span><span>benchmarks</span>
<span>['benchmark://npb-v0/46', 'benchmark://npb-v0/17', ...]</span>
</pre></div>
</div>
</div>
<div id="the-compiler-environment">
<h3><a href="#id9">The compiler environment</a><a href="#the-compiler-environment" title="Permalink to this headline">¶</a></h3>
<p>If you have experience using <a href="https://gym.openai.com/">OpenAI Gym</a>, the
CompilerGym environments will be familiar. If not, you can call <code><span>help()</span></code>
on any function, object, or method to query the documentation:</p>

<p>The action space is described by
<a href="https://facebookresearch.github.io/CompilerGym/compiler_gym/envs.html#compiler_gym.envs.CompilerEnv.action_space" title="compiler_gym.envs.CompilerEnv.action_space"><code><span>env.action_space</span></code></a>.
The <a href="https://facebookresearch.github.io/CompilerGym/llvm/index.html#action-space"><span>LLVM Action Space</span></a> is discrete:</p>
<div><div><pre><span></span><span>&gt;&gt;&gt; </span><span>env</span><span>.</span><span>action_space</span><span>.</span><span>dtype</span>
<span>dtype('int64')</span>
<span>&gt;&gt;&gt; </span><span>env</span><span>.</span><span>action_space</span><span>.</span><span>n</span>
<span>138</span>
</pre></div>
</div>
<p>The observation space is described by
<a href="https://facebookresearch.github.io/CompilerGym/compiler_gym/envs.html#compiler_gym.envs.CompilerEnv.observation_space" title="compiler_gym.envs.CompilerEnv.observation_space"><code><span>env.observation_space</span></code></a>.
The <a href="https://facebookresearch.github.io/CompilerGym/llvm/index.html#autophase"><span>Autophase</span></a> observation space is a 56-dimension
vector of integers:</p>
<div><div><pre><span></span><span>&gt;&gt;&gt; </span><span>env</span><span>.</span><span>observation_space</span><span>.</span><span>shape</span>
<span>(56,)</span>
<span>&gt;&gt;&gt; </span><span>env</span><span>.</span><span>observation_space</span><span>.</span><span>dtype</span>
<span>dtype('int64')</span>
</pre></div>
</div>
<p>The upper and lower bounds of the reward signal are described by
<code><span>env.reward_range</span></code>:</p>
<div><div><pre><span></span><span>&gt;&gt;&gt; </span><span>env</span><span>.</span><span>reward_range</span>
<span>(0.0, inf)</span>
</pre></div>
</div>
<p>As with other Gym environments,
<a href="https://facebookresearch.github.io/CompilerGym/compiler_gym/envs.html#compiler_gym.envs.CompilerEnv.reset" title="compiler_gym.envs.CompilerEnv.reset"><code><span>reset()</span></code></a>
must be called before a CompilerGym environment may be used:</p>
<div><div><pre><span></span><span>&gt;&gt;&gt; </span><span>env</span><span>.</span><span>reset</span><span>()</span>
<span>array([   0,    0,  399,  381,   10,  399,  147,    8,  137,  147,    0,</span>
<span>          0,    0,  556,    0,  546,    0,   15,  693,  574, 1214, 1180,</span>
<span>        384,  399,  214,    0,  120,  116,    0,   88,  468,    8,  546,</span>
<span>         16, 1073,  147,    0, 1551,    0,    0,    0,   10,  766,    0,</span>
<span>          0,  505,   46,    0,    0,    0,  556, 5075, 3261,   13,    0,</span>
<span>       2441])</span>
</pre></div>
</div>
<p>The numpy array that is returned here is the initial
<a href="https://facebookresearch.github.io/CompilerGym/llvm/index.html#autophase"><span>Autophase</span></a> observation. Calling
<a href="https://facebookresearch.github.io/CompilerGym/compiler_gym/envs.html#compiler_gym.envs.CompilerEnv.reset" title="compiler_gym.envs.CompilerEnv.reset"><code><span>env.reset()</span></code></a> starts an
instance of the compiler and selects a random benchmark to use. You can see
which benchmark is currently being used by an environment using
<a href="https://facebookresearch.github.io/CompilerGym/compiler_gym/envs.html#compiler_gym.envs.CompilerEnv.benchmark" title="compiler_gym.envs.CompilerEnv.benchmark"><code><span>env.benchmark</span></code></a>:</p>
<div><div><pre><span></span><span>&gt;&gt;&gt; </span><span>env</span><span>.</span><span>benchmark</span>
<span>'benchmark://npb-v0/90'</span>
</pre></div>
</div>
<p>If we want to force the environment to use a specific benchmark, we can pass the
name of the benchmark as an argument to
<a href="https://facebookresearch.github.io/CompilerGym/compiler_gym/envs.html#compiler_gym.envs.CompilerEnv.reset" title="compiler_gym.envs.CompilerEnv.reset"><code><span>env.reset()</span></code></a>:</p>
<div><div><pre><span></span><span>&gt;&gt;&gt; </span><span>env</span><span>.</span><span>reset</span><span>(</span><span>benchmark</span><span>=</span><span>"benchmark://npb-v0/50"</span><span>)</span>
<span>array([   0,    0,   26,   25,    1,   26,   10,    1,    8,   10,    0,</span>
<span>          0,    0,   37,    0,   36,    0,    2,   46,  175, 1664, 1212,</span>
<span>        263,   26,  193,    0,   59,    6,    0,    3,   32,    0,   36,</span>
<span>         10, 1058,   10,    0,  840,    0,    0,    0,    1,  416,    0,</span>
<span>          0,  148,   60,    0,    0,    0,   37, 3008, 2062,    9,    0,</span>
<span>       1262])</span>
</pre></div>
</div>
</div>
<div id="interacting-with-the-environment">
<h3><a href="#id10">Interacting with the environment</a><a href="#interacting-with-the-environment" title="Permalink to this headline">¶</a></h3>
<p>Once an environment has been initialized, you interact with it in the same way
that you would with any other <a href="https://gym.openai.com/">OpenAI Gym</a>
environment. <a href="https://facebookresearch.github.io/CompilerGym/compiler_gym/envs.html#compiler_gym.envs.LlvmEnv.render" title="compiler_gym.envs.LlvmEnv.render"><code><span>env.render()</span></code></a> prints
the Intermediate Representation (IR) of the program in the current state:</p>
<div><div><pre><span></span><span>&gt;&gt;&gt; </span><span>env</span><span>.</span><span>render</span><span>()</span>
<span>; ModuleID = 'benchmark://npb-v0/83'</span>
<span>target datalayout = "e-m:e-p270:32:32-p271:32:32-p272:64:64-i64:64-f80:128-n8:16:32:64-S128"</span>
<span>target triple = "x86_64-pc-linux-gnu"</span>
<span>...</span>
</pre></div>
</div>
<p><a href="https://facebookresearch.github.io/CompilerGym/compiler_gym/envs.html#compiler_gym.envs.CompilerEnv.step" title="compiler_gym.envs.CompilerEnv.step"><code><span>env.step()</span></code></a> runs an action:</p>
<div><div><pre><span></span><span>&gt;&gt;&gt; </span><span>observation</span><span>,</span> <span>reward</span><span>,</span> <span>done</span><span>,</span> <span>info</span> <span>=</span> <span>env</span><span>.</span><span>step</span><span>(</span><span>0</span><span>)</span>
</pre></div>
</div>
<p>This returns four values: a new observation, a reward, a boolean value
indicating whether the episode has ended, and a dictionary of additional
information:</p>
<div><div><pre><span></span><span>&gt;&gt;&gt; </span><span>observation</span>
<span>array([   0,    0,   26,   25,    1,   26,   10,    1,    8,   10,    0,</span>
<span>          0,    0,   37,    0,   36,    0,    2,   46,  175, 1664, 1212,</span>
<span>        263,   26,  193,    0,   59,    6,    0,    3,   32,    0,   36,</span>
<span>         10, 1058,   10,    0,  840,    0,    0,    0,    1,  416,    0,</span>
<span>          0,  148,   60,    0,    0,    0,   37, 3008, 2062,    9,    0,</span>
<span>       1262])</span>
<span>&gt;&gt;&gt; </span><span>reward</span>
<span>0.3151595744680851</span>
<span>&gt;&gt;&gt; </span><span>done</span>
<span>False</span>
<span>&gt;&gt;&gt; </span><span>info</span>
<span>{'action_had_no_effect': True, 'new_action_space': False}</span>
</pre></div>
</div>
<p>For this environment, reward represents the reduction in code size of the
previous action, scaled to the total codesize reduction achieved with LLVM’s
<code><span>-Oz</span></code> optimizations enabled. A cumulative reward greater than one means
that the sequence of optimizations performed yields better results than LLVM’s
default optimizations. Let’s run 100 random actions and see how close we can
get:</p>
<div><div><pre><span></span><span>&gt;&gt;&gt; </span><span>env</span><span>.</span><span>reset</span><span>(</span><span>benchmark</span><span>=</span><span>"benchmark://npb-v0/50"</span><span>)</span>
<span>&gt;&gt;&gt; </span><span>episode_reward</span> <span>=</span> <span>0</span>
<span>&gt;&gt;&gt; </span><span>for</span> <span>i</span> <span>in</span> <span>range</span><span>(</span><span>1</span><span>,</span> <span>101</span><span>):</span>
<span>... </span>    <span>observation</span><span>,</span> <span>reward</span><span>,</span> <span>done</span><span>,</span> <span>info</span> <span>=</span> <span>env</span><span>.</span><span>step</span><span>(</span><span>env</span><span>.</span><span>action_space</span><span>.</span><span>sample</span><span>())</span>
<span>... </span>    <span>if</span> <span>done</span><span>:</span>
<span>... </span>        <span>break</span>
<span>... </span>    <span>episode_reward</span> <span>+=</span> <span>reward</span>
<span>... </span>    <span>print</span><span>(</span><span>f</span><span>"Step </span><span>{</span><span>i</span><span>}</span><span>, quality=</span><span>{</span><span>episode_reward</span><span>:</span><span>.3%</span><span>}</span><span>"</span><span>)</span>
<span>...</span>
<span>Step 1, quality=44.299%</span>
<span>Step 2, quality=44.299%</span>
<span>Step 3, quality=44.299%</span>
<span>Step 4, quality=44.299%</span>
<span>Step 5, quality=44.299%</span>
<span>Step 6, quality=54.671%</span>
<span>Step 7, quality=54.671%</span>
<span>Step 8, quality=54.608%</span>
<span>Step 9, quality=54.608%</span>
<span>Step 10, quality=54.608%</span>
<span>Step 11, quality=54.608%</span>
<span>Step 12, quality=54.766%</span>
<span>Step 13, quality=54.766%</span>
<span>Step 14, quality=53.650%</span>
<span>Step 15, quality=53.650%</span>
<span>...</span>
<span>Step 97, quality=88.104%</span>
<span>Step 98, quality=88.104%</span>
<span>Step 99, quality=88.104%</span>
<span>Step 100, quality=88.104%</span>
</pre></div>
</div>
<p>Not bad, but clearly there is room for improvement! Because at each step we are
taking random actions, your results will differ with every run. Try running it
again. Was the result better or worse? Of …</p></div></div></div></div></div></div></div></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://facebookresearch.github.io/CompilerGym/getting_started.html">https://facebookresearch.github.io/CompilerGym/getting_started.html</a></em></p>]]>
            </description>
            <link>https://facebookresearch.github.io/CompilerGym/getting_started.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26001480</guid>
            <pubDate>Tue, 02 Feb 2021 14:43:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[On the Security of WhatsApp and Telegram]]>
            </title>
            <description>
<![CDATA[
Score 42 | Comments 18 (<a href="https://news.ycombinator.com/item?id=26001191">thread link</a>) | @tyrion
<br/>
February 2, 2021 | https://germano.dev/whatsapp-vs-telegram/ | <a href="https://web.archive.org/web/*/https://germano.dev/whatsapp-vs-telegram/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div>

<p>Many people, even among security experts and privacy advocates, hold the firm
belief that WhatsApp is more <em>secure</em> and privacy-wise better than Telegram.
After having thoroughly studied the issue, I do not believe this to be true.
In this article I will try to highlight the necessary facts to enable the
reader to form a more informed opinion on the matter.</p>
<section>
<h2 id="contents">Contents</h2>
<ol>
<li><a href="#prologue">Prologue</a></li>
<li><a href="#fallacies">The fallacies</a></li>
<li><a href="#threat-modeling">Threat modeling</a></li>
<li><a href="#e2ee">End-to-end encryption</a><ol>
<li><a href="#app-trust">Trust in the app</a></li>
<li><a href="#secure-backups">Secure backups</a></li>
<li><a href="#auth">Authentication</a></li>
<li><a href="#sync">Device synchronization</a></li>
</ol></li>
<li><a href="#telegram">Criticism of Telegram</a><ol>
<li><a href="#default-e2ee">No end-to-end encryption by default</a></li>
<li><a href="#rolled-their-own">They rolled their own crypto</a></li>
<li><a href="#vulns">History of Telegram vulnerabilities</a></li>
<li><a href="#defamation">Defamation</a></li>
</ol></li>
<li><a href="#conclusion">Conclusion</a></li>
</ol>
</section>
<h2 id="prologue">Prologue</h2>
<p>Most sources which praise WhatsApp and criticize Telegram make bold claims,
presenting them as objective truth, without
sufficiently motivating them or backing them up with facts. In many cases they
rely on <a href="https://en.wikipedia.org/wiki/Argument_from_authority" target="_blank" rel="nofollow noopener noreferrer">arguments from authority</a>:</p>
<blockquote>
<p>[Telegram] By default, it is less safe than @WhatsApp, which makes [it] dangerous
for non-experts. — <a href="https://twitter.com/Snowden/status/778597417797226496" target="_blank" rel="nofollow noopener noreferrer">Ed. Snowden (Sep, 2016)</a></p>
</blockquote>
<p>I realize that many of you will be sceptical now. After all, if Edward Snowden
said so, it <em>must</em> be true. Why would you question it? And why, above all, should we <em>believe</em> you instead?</p>
<p>Well, the point is exactly this. I am not asking you to believe <em>me</em>, but to
evaluate the facts, with an open mind, before forming an opinion.
Moreover, even if it might be hard to accept, even heroes and geniuses like Edward
Snowden can be wrong from time to time!</p>
<p>I made a good faith attempt to research all the facts and present them as
objectively as possible, without including personal biases. However, please
keep in mind that I do not consider myself infallible, and thus there might be
some mistakes. Feel free to let me know what you think.</p>




<h2 id="fallacies">The fallacies</h2>
<p>The vast majority of things I read on this topic can be reduced to a combination
of the following factors:</p>

<ol>
<li>Not considering a <a href="https://en.wikipedia.org/wiki/Threat_model" target="_blank" rel="nofollow noopener noreferrer">threat model</a>.</li>
<li>The <a href="https://en.wikipedia.org/wiki/False_premise" target="_blank" rel="nofollow noopener noreferrer">false premise</a> that end-to-end encryption alone is a necessary and
sufficient condition for good security and privacy.</li>
<li>The erroneous conclusion that everything that is not end-to-end encrypted is
inherently less secure and must be avoided at all cost.</li>
<li>The huge respect for <a href="https://en.wikipedia.org/wiki/Moxie_Marlinspike" target="_blank" rel="nofollow noopener noreferrer">Moxie Marlinspike</a>, one of the authors of the
<a href="https://en.wikipedia.org/wiki/Signal_Protocol" target="_blank" rel="nofollow noopener noreferrer">end-to-end encryption protocol</a> used by WhatsApp and
Signal, leading to <a href="https://en.wikipedia.org/wiki/Argument_from_authority" target="_blank" rel="nofollow noopener noreferrer">arguments from authority</a>.</li>
<li>Outright lies about the insecurity of the cryptographic protocol used by
Telegram.</li>
</ol>
<p>The rest of the article is dedicated to amply clarify each of the points
above. In <a href="#threat-models">section 3</a> I will articulate the importance of considering threat
models when trying to determine if a system is <em>secure</em>. In <a href="">section 4</a>
I will discuss end-to-end encryption, the challenges that it entails and how it
is implemented in WhatsApp and Telegram. In <a href="#telegram">section 5</a> I will address the most
common criticisms of Telegram, and finally, in <a href="#conclusion">section 6</a>, I will draw some conclusions.</p>


<h2 id="threat-modeling">Threat modeling</h2>
<blockquote>
<p>Threat modeling answers questions like “Where am I most vulnerable to attack?”, “What are the most relevant threats?”, and “What do I need to do to safeguard against these threats?”. — <a href="https://en.wikipedia.org/wiki/Threat_model" target="_blank" rel="nofollow noopener noreferrer">Wikipedia</a></p>
</blockquote>
<p>Searching on Hacker News for <a href="https://hn.algolia.com/?dateRange=all&amp;page=0&amp;prefix=false&amp;query=%22whatsapp%20is%20more%20secure%22&amp;sort=byPopularity&amp;type=all" target="_blank" rel="nofollow noopener noreferrer">“WhatsApp is more secure”</a>
yields some typical comments from people arguing that WhatsApp is more secure
than Telegram</p>
<blockquote>
<p>Telegram is more fun (bots and stickers), but <strong>WhatsApp is more secure</strong>
(no messages on server, no rolled-your-own-crypto). — <a href="https://news.ycombinator.com/item?id=14374644" target="_blank" rel="nofollow noopener noreferrer">hn</a></p>
</blockquote>
<p>Or even that Telegram is the least secure</p>
<blockquote>
<p>How can anyone call “Telegram” secure? Those days are over. It’s the least
secure messaging app of them all now. <strong>Even WhatsApp is more secure than
Telegram</strong> (let alone Threema). — <a href="https://news.ycombinator.com/item?id=13032192" target="_blank" rel="nofollow noopener noreferrer">hn</a></p>
</blockquote>
<p>But, what does it really mean that WhatsApp is <em>more secure</em>? Secure against the
government? Secure against your friendly neighbourhood hacker snooping on
the Wi-Fi at Starbucks?
Secure against throwing rocks at your phone? Secure against your mom trying to
read your messages?</p>
<p>Defending from an adversary with practically unlimited budget and computational
resources, such as a powerful government, is going to be much harder than
defending against a curious neighbour sniffing on your Wi-Fi.</p>
<p><strong>Saying that WhatsApp is more secure than Telegram,
without specifying against what kind of adversary or against what kind of threat,
does not mean much.</strong></p>

<p>Without considering these questions and only craving for <em>“more security”</em>, <strong>is
not necessarily a smart thing</strong> either.
In the same way that putting your possessions in a nuclear bunker
might be more secure, in
case of a nuclear war, than locking them in a small safe in your room, but could
not be the best choice if all you are trying to do is protect your Blu-ray
collection from your flatmate!
Moreover, <strong>increasing security is often not free</strong>, because
it increases complexity, thus development cost, and can decrease usability. Exactly like a nuclear bunker
is going to be much more expensive than a small safe and is also not going to be
as easy to use.
Lastly, it is important to note that <strong>you are as secure as the weakest link in your system</strong>.
Therefore, if you want a nuclear bunker, with all the challenges and costs that
it entails, but then forget to put a lock on its door, it might not protect you that
much after all.</p>


<p>Consequently, let us now try to examine which of the <em>components</em> involved in
using a messaging app can be potentially attacked by a malicious agent,
compromising our security.
For each of these, <em>you</em> need to establish if you blindly trust it to function
correctly, or if you believe it could be compromised and thus need to find a way
to defend it from the potential threat.</p>

<ul>
<li><strong>The companies running the servers needed by the app to work</strong>. That is,
Facebook, Telegram and whatever other third party services they decide to
use or share your data with.<ol>
<li>Are you OK with them being able to read your messages?</li>
<li>Do you trust them on keeping your data safe? So that it does not get
stolen, for example.</li>
<li>Are you OK with them selling your data or meta-data to advertisers?</li>
</ol></li>
<li><strong>The app itself</strong>. That is, the WhatsApp or Telegram apps on your
phone.<ol>
<li>Do you trust that it does exactly what it says and is not malicious? For
example that it is always encrypting your messages.</li>
<li>Do you trust its developers to be good citizens and not insert backdoors?</li>
</ol></li>
<li><strong>The communication medium</strong>. That is, the Internet.<ol>
<li>Do you trust the connection between you and the app’s servers to be
secure?</li>
<li>Do you trust your ISP?</li>
</ol></li>
<li><strong>The distribution and update process</strong>. For example, the Play Store, App
Store or F-Droid. Do you trust Google and Apple to give you the real app,
and not a specially crafted one to spy on you?</li>
<li><strong>The other apps on your phone</strong>. Do you trust all the other apps on your
phone, or do you think some of them might be malware?</li>
<li><strong>The OS</strong>. That is, Android or iOS. Do you trust your
operative system and its developers (e.g. Google, Samsung, Apple)? For example,
do you trust that no malicious actor can remotely <a href="https://www.tripwire.com/state-of-security/latest-security-news/gaps-in-google-play-store-xfo-allow-attackers-to-remotely-install-malware-on-android-devices/" target="_blank" rel="nofollow noopener noreferrer">install</a>
or <a href="https://android-developers.googleblog.com/2010/06/exercising-our-remote-application.html" target="_blank" rel="nofollow noopener noreferrer">uninstall</a> software on your device?</li>
<li><strong>The firmware and the hardware</strong>. Do you trust your phone is not running
malware at the firmware or hardware level,
<a href="https://redmine.replicant.us/projects/replicant/wiki/SamsungGalaxyBackdoor" target="_blank" rel="nofollow noopener noreferrer">like it was discovered on Samsung phones in 2014</a>?</li>
</ul>
<p>Whew, that was quite a list!</p>
<p>But, <strong>do we really need to care about all of this stuff?</strong> Well, not many
people do.
However, if you want to evaluate which messaging app best suits your needs and
you care a bit about security and privacy, then it is essential.
This process will enable you to decide for yourself, without basing your decision
on some tweet saying that one app is <em>more secure</em> than the other.</p>

<p>Nonetheless, it is important to reiterate that if you are worried that a powerful
adversary, like a government, might want to directly target you (as opposed to
compromise you as part of a mass surveillance program), you cannot defend only
against one attack vector and ignore the others.
You can have the most secure messaging app in the world, but if your phone can be hacked
with an SMS, there is not much of a difference.</p>


<p>You might wonder why couldn’t we just try to defend ourselves against all possible
threats and attacks. It is because, as we said before and as we will show in more
detail in the next section, increasing security is not free but comes
with the cost of increased complexity and very often decreased usability.</p>

<h2 id="e2ee">End-to-end encryption</h2>
<p>Let us now address the most common reason that induces people to believe that
WhatsApp is a better choice: <a href="https://en.wikipedia.org/wiki/End-to-end_encryption" target="_blank" rel="nofollow noopener noreferrer">end-to-end encryption</a>.</p>

<p>WhatsApp describes end-to-end encryption (or E2EE for short) in the following way:</p>
<blockquote>
<p>End-to-end encryption ensures only you and the person you’re communicating
with can read or listen to what is sent, and nobody in between, not even
WhatsApp. This is because with end-to-end encryption, your messages are
secured with a lock, and only the recipient and you have the special key
needed to unlock and read them. All of this happens automatically: no need to
turn on any special settings to secure your messages. — <a href="https://faq.whatsapp.com/general/security-and-privacy/end-to-end-encryption/?lang=en" target="_blank" rel="nofollow noopener noreferrer">WhatsApp FAQ</a></p>
</blockquote>
<p>WhatsApp nowadays has end-to-end encryption enabled by default for all chats,
while Telegram has not enabled it by default and does not support it on group
chats.</p>
<p>This is undoubtedly a very nice property to have. If implemented correctly it
allows us to communicate securely, even in the case in which the server (i.e.
WhatsApp or Telegram) cannot be trusted and is considered malicious.
However, if we decide to go down this road and not trust any more the companies
running our app, we introduce a series of new complications.</p>
<p>However, one could argue that even in the case in which we decide to trust the
Service, it is beneficial to have end-to-end encryption. This is a valid point because, while
we might trust the Service, for sure we do not trust some potential malicious
actors compromising the Service’s infrastructure and getting access to our data. In
this scenario our data should still be safe because not even the Service has
access to it, and therefore an attacker cannot steal the decryption key nor
coerce the Service to disclose it. This is the major strength of
E2EE.
Nonetheless, it is worth to stress that in this scenario we assumed to trust
the …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://germano.dev/whatsapp-vs-telegram/">https://germano.dev/whatsapp-vs-telegram/</a></em></p>]]>
            </description>
            <link>https://germano.dev/whatsapp-vs-telegram/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26001191</guid>
            <pubDate>Tue, 02 Feb 2021 14:19:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[AirPods Max: An Audiophile Review]]>
            </title>
            <description>
<![CDATA[
Score 299 | Comments 358 (<a href="https://news.ycombinator.com/item?id=26000698">thread link</a>) | @drclau
<br/>
February 2, 2021 | https://mariusmasalar.me/airpods-max | <a href="https://web.archive.org/web/*/https://mariusmasalar.me/airpods-max">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <div>
        <div>
          <p><a href="https://mariusmasalar.me/airpods-max">December 18, 2020</a></p>

		 <h4>Surprising sound let down by serious comfort problems</h4>

		 
<p><img src="https://marius.imgix.net/AirPodsMax-1.jpg?auto=compress&amp;q=75&amp;fit=clip&amp;w=1500&amp;s=6b8a0daf46384709fee2520ad544cdff"></p>
<p>I’m conflicted about Apple’s latest foray into audio products, the AirPods Max over-ear headphones.</p>
<p>In striking opposition to every other review I’ve seen so far, I get to begin mine by stating that I <em>am</em> an audiophile. A friendly, reasonable one, but still—<a href="https://mariusmasalar.me/plague-inc-the-cure">audio is my jam</a>. I’ve been writing music for games and film for over 10 years, so one would hope that I’ve learned a thing or two about audio production in that time. It is, therefore, my sworn duty to be skeptical of consumer technology companies encroaching on the territory of high-end audio equipment built by companies with decades of experience.</p>

<p>Apple has had a long and fruitful relationship with music, but their track record with audio hardware is inconsistent. Somehow, the company that makes the HomePod—a marvel of mono speaker engineering—is also the company that continues to make and sell Beats products. Beats are a common entry point into the world of audio, but they’re priced the way they are because of their brand power, not because their quality justifies it. You can get much better sound, comfort, features, and build for less money.</p>
<p>Today, I find myself wondering to what extent that is also true for the AirPods Max.</p>
<p>Having forked over just under $900 <span>CAD</span> for the privilege of owning a pair, I wanted to see whether Apple is aiming to establish itself as a purveyor of quality audio gear—deserving of a high price tag—or whether we’ll once again be paying for style over substance.</p>
<p><img src="https://marius.imgix.net/AirPodsMax-5.jpg?auto=compress&amp;q=75&amp;fit=clip&amp;w=1500&amp;s=3b6c49e79651f9f936486a7886ff54db"></p>

<p>I laughed when I pulled the AirPods Max out of their box. I knew they would be heavy, but the experience of that weight is really something else.</p>
<p>For context, the Sennheiser <span>PXC</span> 550—my current headphone choice for travel—weigh 227g. The famously comfortable Bose 700 weigh 254g, a weight that’s matched by the popular Sony WH-1000XM4. Premium pairs like the Bang &amp; Olufsen <span>H9</span> (third generation) weigh 295g, and the Bowers &amp; Wilkins <span>PX7</span> just barely crest the 300g mark.</p>
<p>The AirPods Max weigh <em>385g</em>.</p>
<p>In the same way that the iPhone 12’s aluminum build <em>looks</em> less fancy but <em>feels</em> nicer in use than its Pro counterparts and their stainless steel, the mostly-metal build of the AirPods Max is a choice that favours fashion over comfort.</p>
<p>The reason that other high-end headphone manufacturers lean heavily on plastic and even wood in their builds isn’t that they can’t afford metal. It’s because they’re interested in having human beings wear these products on their heads for hours at a time.</p>
<p>As one such human being with a head, I wish Apple had taken some cues from the competition on this front. Even after adjusting the way I wear them, I can’t escape the fact that these are just plain <em>uncomfortable</em> for long listening sessions. The mesh headband and foam ear cups do their best to mitigate this, but they can’t compensate for the sheer weight.</p>
<p>The headband is terrific. It may be my favourite approach to one that I’ve seen on a headphone. I have to wear the band further back on my head than I do with other headphones, but once I figured that out I was able to wear them for longer before needing a break. The ear cups are less impressive. They’re spacious and fairly well padded, but the material that’s used feels somewhat cheap and scratchy in texture. I suspect it’s more breathable than typical leather or vinyl ear cups, but the physical impression isn’t as good and I don’t particularly like how they feel on my face.</p>
<p>Then there’s the clamping force, which is <em>very</em> strong; AirPods Max squeeze your head like a musical bear hug. This is a common problem with heavy headphones, so I wasn’t surprised to see it here, but it accounts for the majority of the comfort problems I have.</p>
<p>The pressure points will differ depending on your fit, but I offered these to two other people in my vicinity for some extended listening and both reported discomfort; one on the top of their head, the other around their ears where the clamp force put pressure on the jaw. Personally, I experience it mainly as a headache after about the half hour to one hour mark.</p>
<p>Let’s disregard weight for a moment, though. These are fine for shorter listening sessions and everyone’s head is different, so I’m sure there are folks out there who will find them to be perfectly comfortable. The problems with metal go beyond weight: by prioritizing fashion value over practical value, Apple has committed a series of unforced errors.</p>
<p>Anodized aluminum feels nice and soft, but that softness means they scuff easily…like, say, when you fold them flat and notice that the ear cups bump and scratch against each other. This happens all the time and it makes me cringe every time; it’s like the horrible scraping that iMac users will be familiar with from trying to plug something into the rear ports. Also, parts of the world experience a season called winter, where the temperature drops and metal surfaces become dangerous things your skin will stick to.</p>
<p>Now, about that<span></span> <span>“</span>protective case”.</p>
<p><img src="https://marius.imgix.net/AirPodsMax-8.jpg?auto=compress&amp;q=75&amp;fit=clip&amp;w=1500&amp;s=392ed93e8e6a65298b215cf68f228603"></p>
<p>I want to save myself some typing and point you to <a href="https://youtu.be/Gvvo6vUpJRc?t=639" target="_blank">the part of <span>MKBHD</span><span></span><span>’</span>s review video</a> where he talks about the storage solution that these $900 headphones ship with. Go ahead and give that a watch. Back? Great. What he said. Before getting these, I thought the hate for the case was hyperbolic, but the truth is it really <em>does</em> feel cheap and pointless, particularly after <a href="https://support.apple.com/en-us/HT211886" target="_blank">Apple clarified</a> that it isn’t necessary for putting the headphones into standby mode.</p>
<p>Before we leave the topic of their physical design, I want to share one last complaint about the AirPods Max: the buttons. I don’t mind the feel of them myself (though a friend felt they were cheap and unpleasant), but I <em>do</em> mind the way they work. The Digital Crown, which controls volume, is also the button that controls playback and Siri. The other, larger button is used to switch between the listening modes: Active Noise Cancellation (<span>ANC</span>), Transparency mode, and none.</p>
<p>I appreciate having physical controls for these things, but I intuitively expected that all the audio-related functions would be accessed from one button and that the playback and feature controls would be accessed from the other. Tying playback controls to the volume knob feels strange to me, and increases the chances of unintentional volume changes when you’re trying to execute a double or triple press—something made even trickier if you’re wearing gloves.</p>
<p>There is, naturally, no way to configure these button assignments. At best, you’re able to change the scrolling direction of the volume knob and restrict which listening modes the other button switches between, but that’s about it. That latter feature also seems to be buggy in the current firmware (<span>3C16</span>) because despite enabling all three, I find that it defaults back to just Noise Cancellation or Transparency whenever I reconnect.</p>
<p>Deal-breaker? No.&nbsp;But another strange design choice to wrap up this section.</p>
<p><img src="https://marius.imgix.net/AirPodsMax-7.jpg?auto=compress&amp;q=75&amp;fit=clip&amp;w=1500&amp;s=f6b19d4c7ef961a06df1a759fc2f45b5"></p>
<p>Wait, one more complaint: the battery life is the shortest of any headphone in this category. This isn’t an issue in and of itself considering they’ll still last through a full day of listening. Still, I hoped that some of that excess size and weight would translate into battery capacity.</p>
<p>On the topic of power, Apple has indicated that the AirPods Max have two low-power states and you <em>don’t</em> need the case to access them—great news since I refuse to use that stupid thing. Here’s <a href="https://support.apple.com/en-us/HT211886" target="_blank">what they say</a>:</p>
<blockquote>
<p>If you set your AirPods Max down and leave them stationary for 5 minutes, they go into a low power mode to preserve battery charge. After 72 stationary hours out of the Smart Case, your AirPods Max go into a lower power mode that turns off Bluetooth and Find My to preserve battery charge further. If you put your AirPods Max in the Smart Case when you’re not using them, they go into a low power mode immediately to preserve battery charge. After 18 hours in the Smart Case, your AirPods Max go into an ultralow power mode that turns off Bluetooth and Find My and maximizes battery life.</p>
</blockquote>
<p>Okay, <em>now</em> I’m done talking about the physical characteristics.</p>
<h2 id="sonic-boom">Sonic Boom</h2>
<p>So there I was, shaking my head at the weight and the design while I got them connected. I was already looking up Apple’s holiday return policy when I hit play on my usual suite of test material and…oh.</p>
<p><em>Oh</em>.</p>
<p><img src="https://marius.imgix.net/AirPodsMax-4.jpg?auto=compress&amp;q=75&amp;fit=clip&amp;w=1500&amp;s=a34de6bb9c7c71b5c5ccbfad05e1c8f6"></p>
<p>I was reminded of <a href="http://toolsandtoys.net/reviews/the-bowers-wilkins-p7-wireless-headphones-review/" target="_blank">the first time</a> a pair of wireless headphones impressed me. I put them on and somehow found myself lying on the floor of my room, two hours later, having become completely lost in the music. Since then, <a href="https://mariusmasalar.me/bang-olufsen-h9i">other headphones</a> have achieved this magical time-dilation effect, but I didn’t expect to feel it coming from an Apple product.</p>
<p>Don’t get me wrong, Apple has amazing audio engineers. <a href="https://mariusmasalar.me/airpods-pro">I adore my AirPods Pro</a>. They’re not the best value for money in terms of sound, but they have a pleasant, relatively neutral profile and have become my daily listening companions. Similarly, the HomePod is my favourite smart speaker for sound because it manages to provide a remarkably full and dynamic listening experience for a compact mono sound source.</p>
<p>In a word, the AirPods Max sound <em>sublime</em>.</p>
<p>They have a beautiful way of making you feel immersed and enveloped by the music, with a tremendously wide soundstage, solid instrument placement, and some of the most articulate dynamics I’ve heard from consumer equipment. They remind me of my open-back studio headphone and amp setup (the geeky audiophile equipment) more than other wireless headphones.</p>
<p>Several hours of listening later, I wanted to make sure I wasn’t just experiencing some sort of hallucination caused by the extreme clamping force of these metallic behemoths, so I called up my friend and had him bring over his pair of Bang &amp; Olufsen H9i—<a href="https://thesweetsetup.com/articles/a-roundup-of-the-best-wireless-active-noise-cancelling-headphones/" target="_blank">my previous benchmark</a> for best wireless <span>ANC</span> headphones—to do some critical listening.</p>
<p>We cruised through our respective music libraries, selecting favourite tracks and listening, each of us with one of the pairs on. Then we’d swap <a href="https://atp.fm/409" target="_blank">(as others have pointed …</a></p></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://mariusmasalar.me/airpods-max">https://mariusmasalar.me/airpods-max</a></em></p>]]>
            </description>
            <link>https://mariusmasalar.me/airpods-max</link>
            <guid isPermaLink="false">hacker-news-small-sites-26000698</guid>
            <pubDate>Tue, 02 Feb 2021 13:28:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Unofficial DynASM Documentation]]>
            </title>
            <description>
<![CDATA[
Score 33 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25998833">thread link</a>) | @lelf
<br/>
February 2, 2021 | https://corsix.github.io/dynasm-doc/index.html | <a href="https://web.archive.org/web/*/https://corsix.github.io/dynasm-doc/index.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
              <p>DynASM is a preprocessor and tiny runtime library for creating assemblers and JIT compilers in C or C++.</p>
        <p>DynASM was written for, and is maintained as part of, <a href="http://luajit.org/">LuaJIT</a>. LuaJIT 1 used
           DynASM in a JIT role. LuaJIT 2 doesn't use DymASM in a JIT role, but LuaJIT 2's interpreter is hand-written in assembly,
           and it uses DynASM as a powerful cross-platform assembler.</p>
        <p>To get the latest copy of DymASM, run the following:</p>
        <pre><span>git clone http://luajit.org/git/luajit-2.0.git</span>
<span>cd luajit-2.0/dynasm</span></pre>
        <p>The <a href="http://luajit.org/dynasm.html">official documentation</a> for DynASM is extremely spartan, which can
           make it difficult to get started with DynASM. For using DynASM in a JIT role, this unofficial documentation's
           <strong><a href="https://corsix.github.io/dynasm-doc/tutorial.html">tutorial</a></strong> is recommended as a starting point. Once you're more familiar with DynASM,
           the <strong><a href="https://corsix.github.io/dynasm-doc/reference.html">reference</a></strong> and <strong><a href="https://corsix.github.io/dynasm-doc/instructions.html">instruction listing</a></strong>
           pages are recommended reading for fleshing out your DynASM knowledge.</p>
        <p>Note that DynASM supports the x86, x64, ARM, PowerPC, and MIPS instruction sets, but this unofficial documentation
           only covers x86 and x64.</p>
      </div></div>]]>
            </description>
            <link>https://corsix.github.io/dynasm-doc/index.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25998833</guid>
            <pubDate>Tue, 02 Feb 2021 09:14:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Fixing a Bricked SSD with JTAG]]>
            </title>
            <description>
<![CDATA[
Score 35 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25998328">thread link</a>) | @drudru11
<br/>
February 1, 2021 | https://fmad.io/blog-ssd-bricked-restore.html | <a href="https://web.archive.org/web/*/https://fmad.io/blog-ssd-bricked-restore.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

			<p>
				SSD`s are the life blood of our fmadio 10G, 40G, 100G ethernet capture systems. They provide backing storage that well exceeds that of conventional RAM, are super fast and light weight. Thus its prudent to keep the SSD farms in top nick, optimal health, and occasionally perform emergency room brain surgery on them. Unfortunately today is one of those days.
			</p>
			<br>

			<div>                        
				<ul>                            
					<li><img width="60%" src="https://fmad.io/images/blog/20141229_ssd_jtag_close.jpg" alt="ssd connected to jtag"></li>
				</ul>                        
			</div>


		<p>
As with all things, it happened late on a Friday night when I was adding a new feature to the system that wipes all capture data from the system. This is simple button click on the web UI page as our clients data is quite sensitive thus needs to be deleted when the box moves internally or externally. The wipe is implemented using the "Secure Erase" ATA-8 command, you can read all about it <a href="https://ata.wiki.kernel.org/index.php/ATA_Secure_Erase">here</a>. Its essentially a restore-to-factory-setting operation. Meaning after the SecureErase the drive`s internal state is the same as "just left the factory". 
		</p>
		
		<p>
Which is great when it works, but this kind of low level drive formatting is pretty complicated with many (presumably) asynchronous operations going on in parallel... and doing 100 of these operations back to back at high speed is probably something the vendor did not expect (I was testing dammit!). In our case this bricked 6 SSD`s rendering them completely useless causing myself quite the stress as I now have several thousand dollars worth of inventory destroyed!  - not a good day.
</p>


				<p><img width="1024px" src="https://fmad.io/images/blog/money_burn.jpg" alt="fmadio ssd lost"></p><p>
The result is a wall of rather intimidating errors indicating imminent doom with the disk is for all intensive purposes <a href="https://en.wikipedia.org/wiki/Brick_%28electronics%29"><b>BRICKED</b></a>.

<code>

kernel: [18633.754193] ata2.00: exception Emask 0x0 SAct 0x0 SErr 0x0 action 0x0
kernel: [18633.754204] ata2.00: irq_stat 0x40000001
kernel: [18633.754206] ata2.00: failed command: READ DMA
kernel: [18633.754209] ata2.00: cmd c8/00:08:00:00:00/00:00:00:00:00/e0 tag 0 dma 4096 in
kernel: [18633.754209]          res 51/04:00:00:00:00/00:00:00:00:00/60 Emask 0x1 (device error)
kernel: [18633.754210] ata2.00: status: { DRDY ERR }
kernel: [18633.754211] ata2.00: error: { ABRT }
kernel: [18633.754515] ata2.00: supports DRM functions and may not be fully accessible
kernel: [18633.754614] ata2.00: failed to get NCQ Send/Recv Log Emask 0x1
kernel: [18633.759150] ata2.00: supports DRM functions and may not be fully accessible
kernel: [18633.759215] ata2.00: failed to get NCQ Send/Recv Log Emask 0x1
kernel: [18633.763495] ata2.00: configured for UDMA/133
kernel: [18633.770136] ata2: EH complete
kernel: [18633.770278] ata2.00: exception Emask 0x0 SAct 0x0 SErr 0x0 action 0x0
kernel: [18633.770280] ata2.00: irq_stat 0x40000001
kernel: [18633.770281] ata2.00: failed command: READ DMA
kernel: [18633.770284] ata2.00: cmd c8/00:08:00:00:00/00:00:00:00:00/e0 tag 1 dma 4096 in
kernel: [18633.770284]          res 51/04:00:00:00:00/00:00:00:00:00/60 Emask 0x1 (device error)
kernel: [18633.770286] ata2.00: status: { DRDY ERR }
kernel: [18633.770286] ata2.00: error: { ABRT }
kernel: [18633.770572] ata2.00: supports DRM functions and may not be fully accessible
kernel: [18633.770641] ata2.00: failed to get NCQ Send/Recv Log Emask 0x1
kernel: [18633.775164] ata2.00: supports DRM functions and may not be fully accessible
kernel: [18633.775210] ata2.00: failed to get NCQ Send/Recv Log Emask 0x1
kernel: [18633.779527] ata2.00: configured for UDMA/133
kernel: [18633.786094] ata2: EH complete
kernel: [18633.786205] ata2.00: exception Emask 0x0 SAct 0x0 SErr 0x0 action 0x0
kernel: [18633.786207] ata2.00: irq_stat 0x40000001
kernel: [18633.786208] ata2.00: failed command: READ DMA
</code>


</p><p>
The usual suspects to recover were tried and failed, leaving only a few options.
<br>
</p>

<h5>a) RMA the boards back to the seller<br>
b) Contact vendor support<br>
c) Perform surgery</h5>


<p>
Option a) of RMA`ing the boards was the safest option, tho usually you get some other previously recycled RMA`ed device back. Option b) of contacting the vendor is always such a brutally painful experience. It would likely end up with some random "Customer Support" person with a strange accent... giving the default completely useless response of RMA the device and get a replacement kind of thing... ho hum. Which leaves surgery! Now I usually don't go messing with hardware like this (anymore... :) ) because it takes up quite a bit time. However SSD health and prosperity is directly linked to our profitability thus deemed it a worth while time investment to have a more intimate relationship with our SSD models of choice. 
</p>
<br>

<div><p>
The process starts with a general reconnaissance mission of what pins are accessible, and what those pins are for. First up was finding the UART / serial interface but it was silent and likely disabled by the firmware. Next up was what most likely looked like a JTAG interface and... bingo, full JTAG interface connecting and operating as expected.
</p><p>

 JTAG is a hardware based system debugger that for CPU`s let you control instruction execution and read/write memory anywhere. You can see in the picture below some soldering of header pins was required, that is then wired to a breadboard which is wired to a Raspberry PI.
</p></div>


	<p><img width="1024px" src="https://fmad.io/images/blog/20141229_ssd_jtag.jpg" alt="fmadio ssd with jtag connected"></p><div><p>
Raspberry PI? wtf ? In this case the Raspberry PI was converted into a JTAG debugger using the outstanding software over at <a href="http://openocd.sourceforge.net/">OpenOCD</a>. As "real" JTAG debuggers are quite expensive ranging from $100 - $1000+ making OCD coupled with the PI an excellent low cost alternative. 
</p><p>

At this point you get a small rush as you gain access and poke the device, after which the vastness of having no idea what anything does starts to weigh you down. Then slowly bit by bit, instruction after instruction, string after string you gain some intuition on the memory map, what the code does, how its setup and eventually find something interesting.
</p></div> 

<p>

The first entry point to look for is the classic printf / trace / debug operation which gives you insight into what the software is doing. And eventually managed to track down the code that`s basically

<code>
void trace(char* Message, ...)
{ 
	va_arg list;
	va_start(arglist, Message);

	char buf[1024];
	vsprintf(buf, Message, arglist);

	if (debug_enable)
	{
		fwrite(output, buf, strlen(buf));
	}
}
</code>

which writes out a string to a console to tell the developer on whats going on. Note that the code has to "flatten" the string first before even deciding to output or not, which gives us a nice window to sniff the string with JTAG even if nothing is written to the console. 
</p>


<p>
After sniffing strings for a while and getting a better feel for whats happening noticed that the SSD is receiving commands from the SATA host no problem. But there`s some sort of funkyness going on that causes the SSD to send no response back - kind of a one-way-street. One idea to resolve this is: in theory the security erase operation restores everything back to good health. The question tho, is the device actually processing a security erase request ?  
</p>


<p>
... and using our printf JTAG sniffer... it most certainly is processing the request! But failing miserably due to an incorrect password. You can see the sniffed printf jtag string in the output below. Hint: <i>"&lt;SED&gt; Credential Comparison Failed"</i> ASCIIZ string.
</p>


	<p><img width="1024px" src="https://fmad.io/images/blog/20141229_ssd_security_erase_fail.jpg" alt="fmadio ssd security erase fail"></p><p>
Which makes it clear why the security erase / factory reset failed but more importantly you can track down the offending bit of code from this string. That results in the following snippet of assembler courtesy of the IDA toolset below.
</p> 

<p><img width="1024px" src="https://fmad.io/images/blog/20141229_ssd_security_check.jpg" alt="fmadio ssd security erase password check"></p><p>
To decode that for you its doing a 32 byte long compare against some expected cryptographic hash key. Then the <i>"magic compare"</i> aka instruction <b>CMP R5, #1</b> is testing if the keys matched. Then doing a conditional jump to a printf routine based on that comparison result <b>BLNE sub_80...</b>. And finally  the functions return value is the result of the comparison <b>MOV R0, R5</b>. Nothing particularly fancy going on.
</p> 


<p>
There`s a few ways to go from here. One would be to reverse engineer how the 32B key is generated and create  a general purpose exploit. The other would be to just patch the binary such that it thinks it passed the security check. eg Fake a correct password response. We chose the latter as it only takes a few minutes and all I want is to restore the SSD farm`s health. Patching the binary with JTAG is trivial, console output is shown below.
</p> 


<p><img width="1024px" src="https://fmad.io/images/blog/20141229_ssd_security_erase_patch.jpg" alt="fmadio ssd security erase password fake"></p><div><p>
The above shows disassembling the patched code first, the "before" section. This is to check we overwrite the correct bit of code. Then patch it using the command <b>cpu0 arm mww</b> with the value 0xe3a05001. Then disassemble again "after section" to confirm the patch worked and has the correct instruction. 
</p><p>

In this case we replaced <b>BLNE</b> instruction (print error message to the console) with <b>MOV r5, #1</b> at address 0x8009abe4 (shown in blue). The result of the "magic check" is 0 for fail, 1 for pass and write it to register r5. All we did is ignore the whole comparison and simply override it and say the security check always passes (r5 = 1).
</p></div> 

<p>
...
</p>

<p>
Now its patched, with cpu`s resumed its the moment of truth. Issuing the security erase operation from the host system via hdparm. 
<br>
<code>
$ sudo hdparm --security-erase 1234  /dev/sdb
security_password="1234"

/dev/sdb:
 Issuing SECURITY_ERASE command, password="1234, user=user
$
</code>
<br>
... and it worked! the SSD is back to life, working as normal and running at high speed!  ... with <b>several thousand dollars worth of SSD`s back in business</b> making our 10G, 40G, 100G network capture systems more resilient than ever. Now if the SSD vendor (who shall remain nameless) would fix the dam bug so excessive back-to-back security password/erase does NOT brick the device, life would be so much better. 
</p>


	</div></div>]]>
            </description>
            <link>https://fmad.io/blog-ssd-bricked-restore.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25998328</guid>
            <pubDate>Tue, 02 Feb 2021 07:51:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Exploring FPGA Graphics (2020)]]>
            </title>
            <description>
<![CDATA[
Score 134 | Comments 38 (<a href="https://news.ycombinator.com/item?id=25998154">thread link</a>) | @rbanffy
<br/>
February 1, 2021 | https://projectf.io/posts/fpga-graphics/ | <a href="https://web.archive.org/web/*/https://projectf.io/posts/fpga-graphics/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <p>Welcome to <em>Exploring FPGA Graphics</em>. In this series, we explore graphics at the hardware level and get a feel for the power of FPGAs. We start by learning how displays work, before racing the beam with Pong, starfields and sprites, simulating life with bitmaps, drawing lines and triangles, and finally creating simple 3D models. I’ll be writing and revising this series throughout 2020 and 2021.</p>
<p>In this first post, we learn how computer displays work and animate simple shapes with an FPGA.</p>
<p><em>Updated 2021-01-28. Get in touch with <a href="https://twitter.com/WillFlux">@WillFlux</a> or open an <a href="https://github.com/projf/projf-explore/issues">issue on GitHub</a>.</em></p>
<blockquote>
<p>In all beginnings dwells a magic force<br>
<em>Herman Hesse, Stages from <a href="https://en.wikipedia.org/wiki/The_Glass_Bead_Game">The Glass Bead Game</a></em></p>
</blockquote>
<h3 id="series-outline">Series Outline</h3>
<ul>
<li>Exploring FPGA Graphics (this post) - learn how displays work and animate simple shapes</li>
<li><a href="https://projectf.io/posts/fpga-pong/">FPGA Pong</a> - race the beam to create the arcade classic</li>
<li><a href="https://projectf.io/posts/hardware-sprites/">Hardware Sprites</a> - fast, colourful, graphics with minimal resources</li>
<li><a href="https://projectf.io/posts/fpga-ad-astra/">FPGA Ad Astra</a> - demo with hardware sprites and animated starfields</li>
<li><a href="https://projectf.io/posts/framebuffers/">Framebuffers</a> - driving the display from a bitmap in memory</li>
<li><a href="https://projectf.io/posts/life-on-screen/">Life on Screen</a> - the screen comes alive with Conway’s Game of Life</li>
<li><a href="https://projectf.io/posts/lines-and-triangles/">Lines and Triangles</a> - drawing lines and triangles with a framebuffer</li>
</ul>
<p><em>More parts to follow.</em></p>
<h3 id="requirements">Requirements</h3>
<p>For this series, you need an FPGA board with video output. We’ll be working at 640x480, so pretty much any video output will work. It helps to be comfortable with programming your FPGA board and reasonably familiar with Verilog.</p>
<p>We’ll be demoing the designs with two boards:</p>
<ul>
<li><strong><a href="https://docs.icebreaker-fpga.org/hardware/icebreaker/">iCEBreaker</a></strong> (Lattice iCE40) with <strong><a href="https://docs.icebreaker-fpga.org/hardware/pmod/dvi/">12-Bit DVI Pmod</a></strong></li>
<li><strong><a href="https://reference.digilentinc.com/reference/programmable-logic/arty-a7/reference-manual">Digilent Arty A7-35T</a></strong> (Xilinx Artix-7) with <strong><a href="https://reference.digilentinc.com/reference/pmod/pmodvga/reference-manual">Pmod VGA</a></strong></li>
</ul>
<h3 id="source">Source</h3>
<p>The SystemVerilog designs featured in this series are available from the <a href="https://github.com/projf/projf-explore/">projf-explore</a> repo on GitHub. The designs are open source hardware under the permissive MIT licence, but this blog is subject to normal copyright restrictions.</p>
<blockquote>
<p><strong>Quick Aside: SystemVerilog?!</strong><br>
We’ll be using a few choice features from SystemVerilog to make Verilog a little more pleasant (no laughing at the back). If you’re familiar with Verilog, you’ll have no trouble.</p>
</blockquote>
<h2 id="space-and-time">Space and Time</h2>
<p>The screen you’re looking at is a little universe with its own rules of space and time.</p>
<p>Looking at a screen from afar, you see a smooth two-dimensional image. Look more closely, and you see many individual blocks: these are <strong>pixels</strong>, made up of red, green, and blue components. A typical high-definition image is 1920 pixels across and 1080 lines down: over 2 million pixels in total. Even a 640x480 image has over 300,000 pixels. The need to handle so much information so quickly is a big part of the challenge of working with graphics at a hardware level.</p>
<p>A VGA cable has five main signals: red, green, blue, horizontal sync, and vertical sync. There are no addressing signals to tell the screen where to draw pixels; the secret is time, defined by the sync signals. The red, green, and blue wires carry the colour of each pixel in turn. Each pixel lasts a fixed length of time; when the display receives a <strong>horizontal sync</strong>, it starts a new line; when it receives a <strong>vertical sync</strong>, it begins a new frame. Showing many frames in quick succession provides the illusion of a moving image.</p>
<p>The sync signals are part of <strong>blanking</strong> intervals. Originally designed to allow an electron gun to move to the next line or top of the screen, blanking intervals have been retained and repurposed in contemporary displays: HDMI uses them to transmit audio. The blanking interval has three parts: <strong>front porch</strong>, <strong>sync</strong>, and <strong>back porch</strong>.</p>
<p><img src="https://projectf.io/img/posts/fpga-graphics/display-timings.png" alt="Display Timings" title="Display Timings"></p>
<h2 id="display-timings">Display Timings</h2>
<p>In this series, we’re going to use <strong>640x480</strong> as our display resolution. Almost all displays support 640x480, and its low resource requirements make it simple to work with on small FPGAs. All the same principles apply at higher resolutions, such as 1280x720 or 4K.</p>
<p>We’ll use traditional horizontal and vertical timings, based on the original VGA monitor and adapter:</p>
<div><pre><code data-lang="plaintext">    640x480 Timings      HOR    VER
    -------------------------------
    Active Pixels        640    480
    Front Porch           16     10
    Sync Width            96      2
    Back Porch            48     33
    Blanking Total       160     45
    Total Pixels         800    525
    Sync Polarity        neg    neg
</code></pre></div><p><em>Learn more from <a href="https://projectf.io/posts/video-timings-vga-720p-1080p/">Video Timings: VGA, SVGA, 720p, 1080p</a>.</em></p>
<p>Taking blanking into account, we have a total of 800x525 pixels. A typical LCD refreshes 60 times a second, so the number of pixels per second is <code>800 x 525 x 60 = 25,200,000</code>, which equates to a <strong>pixel clock</strong> of 25.2 MHz.</p>
<blockquote>
<p><strong>CAUTION: CRT Monitors</strong><br>
Any modern display, including <a href="https://en.wikipedia.org/wiki/Multisync_monitor">multisync CRTs</a>, should be fine with a 25.2 or 25 MHz pixel clock. Fixed-frequency CRTs, such as the original IBM 85xx series, could be damaged by an out-of-spec signal. Use these designs at your own risk.</p>
</blockquote>
<h2 id="running-to-time">Running to Time</h2>
<p>We’ve decided we need a pixel clock of 25.2 MHz pixel clock, but neither of our demo boards has such a clock. To reach the required frequency, we’re going to use a <strong><a href="https://en.wikipedia.org/wiki/Phase-locked_loop">phase-locked loop</a></strong> (PLL). Almost all FPGAs include one or more PLLs, but there isn’t a standard way to configure them in Verilog, so we have to use vendor-specific designs.</p>
<p>We have provided implementations for Xilinx 7 Series (XC7) and Lattice iCE40; for other FPGAs, you’ll need to consult your vendor documentation. If you can’t reach 25.2 MHz exactly, then 25 MHz or thereabouts should be fine (but see note about CRTs, above). The iCE40 can’t generate 25.2 MHz using the oscillators on iCEBreaker but works fine at 25.125 MHz.</p>
<h3 id="clock-generator-modules">Clock Generator Modules</h3>
<ul>
<li>Xilinx 7 Series: <strong><a href="https://github.com/projf/projf-explore/blob/master/common/xc7/clock_gen.sv">xc7/clock_gen.sv</a></strong></li>
<li>Lattice iCE40: <strong><a href="https://github.com/projf/projf-explore/blob/master/common/ice40/clock_gen.sv">ice40/clock_gen.sv</a></strong></li>
</ul>
<h2 id="display-timings-module">Display Timings Module</h2>
<p>Using our ~25 MHz pixel clock, we can generate timings for our 640x480 display. Creating display timings is straightforward: there’s one counter for horizontal position and one for vertical. We use these counters to decide on the correct time for sync signals.</p>
<p>640x480 display timings generator <strong>[<a href="https://github.com/projf/projf-explore/blob/master/common/display_timings_480p.sv">display_timings_480p.sv</a>]</strong>:</p>
<div><pre><code data-lang="verilog"><span>module</span> display_timings_480p (
    <span>input</span>  <span>wire</span> <span>logic</span> clk_pix,   <span>// pixel clock
</span><span></span>    <span>input</span>  <span>wire</span> <span>logic</span> rst,       <span>// reset
</span><span></span>    <span>output</span>      <span>logic</span> [<span>9</span><span>:</span><span>0</span>] sx,  <span>// horizontal screen position
</span><span></span>    <span>output</span>      <span>logic</span> [<span>9</span><span>:</span><span>0</span>] sy,  <span>// vertical screen position
</span><span></span>    <span>output</span>      <span>logic</span> hsync,     <span>// horizontal sync
</span><span></span>    <span>output</span>      <span>logic</span> vsync,     <span>// vertical sync
</span><span></span>    <span>output</span>      <span>logic</span> de         <span>// data enable (low in blanking interval)
</span><span></span>    );

    <span>// horizontal timings
</span><span></span>    <span>parameter</span> HA_END <span>=</span> <span>639</span>;           <span>// end of active pixels
</span><span></span>    <span>parameter</span> HS_STA <span>=</span> HA_END <span>+</span> <span>16</span>;   <span>// sync starts after front porch
</span><span></span>    <span>parameter</span> HS_END <span>=</span> HS_STA <span>+</span> <span>96</span>;   <span>// sync ends
</span><span></span>    <span>parameter</span> LINE   <span>=</span> <span>799</span>;           <span>// last pixel on line (after back porch)
</span><span></span>
    <span>// vertical timings
</span><span></span>    <span>parameter</span> VA_END <span>=</span> <span>479</span>;           <span>// end of active pixels
</span><span></span>    <span>parameter</span> VS_STA <span>=</span> VA_END <span>+</span> <span>10</span>;   <span>// sync starts after front porch
</span><span></span>    <span>parameter</span> VS_END <span>=</span> VS_STA <span>+</span> <span>2</span>;    <span>// sync ends
</span><span></span>    <span>parameter</span> SCREEN <span>=</span> <span>524</span>;           <span>// last line on screen (after back porch)
</span><span></span>
    <span>always_comb</span> <span>begin</span>
        hsync <span>=</span> <span>~</span>(sx <span>&gt;=</span> HS_STA <span>&amp;&amp;</span> sx <span>&lt;</span> HS_END);  <span>// invert: negative polarity
</span><span></span>        vsync <span>=</span> <span>~</span>(sy <span>&gt;=</span> VS_STA <span>&amp;&amp;</span> sy <span>&lt;</span> VS_END);  <span>// invert: negative polarity
</span><span></span>        de <span>=</span> (sx <span>&lt;=</span> HA_END <span>&amp;&amp;</span> sy <span>&lt;=</span> VA_END);
    <span>end</span>

    <span>// calculate horizontal and vertical screen position
</span><span></span>    <span>always_ff</span> @ (<span>posedge</span> clk_pix) <span>begin</span>
        <span>if</span> (sx <span>==</span> LINE) <span>begin</span>  <span>// last pixel on line?
</span><span></span>            sx <span>&lt;=</span> <span>0</span>;
            sy <span>&lt;=</span> (sy <span>==</span> SCREEN) <span>?</span> <span>0</span> <span>:</span> sy <span>+</span> <span>1</span>;  <span>// last line on screen?
</span><span></span>        <span>end</span> <span>else</span> <span>begin</span>
            sx <span>&lt;=</span> sx <span>+</span> <span>1</span>;
        <span>end</span>
        <span>if</span> (rst) <span>begin</span>
            sx <span>&lt;=</span> <span>0</span>;
            sy <span>&lt;=</span> <span>0</span>;
        <span>end</span>
    <span>end</span>
<span>endmodule</span>
</code></pre></div><p><em>ProTip: The last assignment wins in Verilog, so the reset overrides the existing <code>sx</code> and <code>sy</code>.</em></p>
<p><strong>sx</strong> and <strong>sy</strong> store the horizontal and vertical position; their maximum values are 800 and 525 respectively, so we need 10 bits to hold them (2<sup>10</sup> = 1024). <strong>de</strong> is <em>data enable</em>, which is low during the blanking interval: we use it to decide when to draw pixels.</p>
<p>Display modes vary in the polarity of their sync signals; for traditional 640x480, the polarity is negative for both <strong>hsync</strong> and <strong>vsync</strong>. Negative polarity means the voltage is mostly high, with low voltage indicating a sync signal.</p>
<p>The following simulation shows the vertical sync starting at the 490th line (counting starts at zero):</p>
<p><img src="https://projectf.io/img/posts/fpga-graphics/hsync-vsync-vga.png" alt="Sync Signal Simulation" title="Simulating VGA horizontal &amp; vertical sync signals"></p>
<h2 id="test-benches">Test Benches</h2>
<p>You can exercise the designs with the included test benches (Xilinx only):</p>
<ul>
<li><strong><a href="https://github.com/projf/projf-explore/tree/master/common/xc7/clock_gen_tb.sv">Clock Gen Test Bench</a></strong> (Xilinx 7 Series)</li>
<li><strong><a href="https://github.com/projf/projf-explore/tree/master/common/xc7/display_timings_tb.sv">Display Timings Test Bench</a></strong> (Xilinx 7 Series)</li>
</ul>
<p>Some things to check:</p>
<ul>
<li>What is the pixel clock period?</li>
<li>How long does the pixel clock take to lock?</li>
<li>Does a frame last exactly 1/60th of a second?</li>
<li>How much time does a single line last?</li>
<li>What is the maximum values of <code>sx</code> and <code>sy</code> when <code>de</code> is low?</li>
</ul>
<p><em>You can find instructions for running the simulation in the source <a href="https://github.com/projf/projf-explore/tree/master/fpga-graphics">README</a>.</em></p>
<h2 id="top-display">Top Display</h2>
<p>Now we have our display signals we’re ready to start drawing. To begin, we’re going to keep it simple and draw a coloured square. When the screen x and y coordinates are both less than 32 we draw in orange; otherwise, we use blue. Because our colour output has 4 bits per channel, we can use a single hex digit from 0-F to represent the intensity of red, green, and blue.</p>
<p>There are two versions of this top module, one for each demo board:</p>
<ul>
<li>Xilinx XC7: <strong><a href="https://github.com/projf/projf-explore/blob/master/fpga-graphics/xc7/top_square.sv">xc7/top_square.sv</a></strong></li>
<li>Lattice iCE40: <strong><a href="https://github.com/projf/projf-explore/blob/master/fpga-graphics/ice40/top_square.sv">ice40/top_square.sv</a></strong></li>
</ul>
<h3 id="arty-vga">Arty VGA</h3>
<p>Shown below is the version for Arty A7-35T (XC7) with Pmod VGA:</p>
<div><pre><code data-lang="verilog"><span>module</span> top_square (
    <span>input</span>  <span>wire</span> <span>logic</span> clk_100m,     <span>// 100 MHz clock
</span><span></span>    <span>input</span>  <span>wire</span> <span>logic</span> btn_rst,      <span>// reset button (active low)
</span><span></span>    <span>output</span>      <span>logic</span> vga_hsync,    <span>// horizontal sync
</span><span></span>    <span>output</span>      <span>logic</span> vga_vsync,    <span>// vertical sync
</span><span></span>    <span>output</span>      <span>logic</span> [<span>3</span><span>:</span><span>0</span>] vga_r,  <span>// 4-bit VGA red
</span><span></span>    <span>output</span>      <span>logic</span> [<span>3</span><span>:</span><span>0</span>] vga_g,  <span>// 4-bit VGA green
</span><span></span>    <span>output</span>      <span>logic</span> [<span>3</span><span>:</span><span>0</span>] vga_b   <span>// 4-bit VGA blue
</span><span></span>    );

    <span>// generate pixel clock
</span><span></span>    <span>logic</span> clk_pix;
    <span>logic</span> clk_locked;
    clock_gen clock_640x480 (
       .clk(clk_100m),
       .rst(<span>!</span>btn_rst),  <span>// reset button is active low
</span><span></span>       .clk_pix,
       .clk_locked
    );

    <span>// display timings
</span><span></span>    <span>localparam</span> CORDW <span>=</span> <span>10</span>;  <span>// screen coordinate width in bits
</span><span></span>    <span>logic</span> [CORDW<span>-</span><span>1</span><span>:</span><span>0</span>] sx, sy;
    <span>logic</span> hsync, vsync, de;
    …</code></pre></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://projectf.io/posts/fpga-graphics/">https://projectf.io/posts/fpga-graphics/</a></em></p>]]>
            </description>
            <link>https://projectf.io/posts/fpga-graphics/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25998154</guid>
            <pubDate>Tue, 02 Feb 2021 07:13:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Go 1.16 will make system calls through Libc on OpenBSD]]>
            </title>
            <description>
<![CDATA[
Score 291 | Comments 172 (<a href="https://news.ycombinator.com/item?id=25997506">thread link</a>) | @lladnar
<br/>
February 1, 2021 | https://utcc.utoronto.ca/~cks/space/blog/programming/Go116OpenBSDUsesLibc | <a href="https://web.archive.org/web/*/https://utcc.utoronto.ca/~cks/space/blog/programming/Go116OpenBSDUsesLibc">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><h2>Go 1.16 will make system calls through libc on OpenBSD</h2>

	<p><small>February  1, 2021</small></p>
</div><div><p>One of the unusual things about <a href="https://golang.org/">Go</a> is that
it started out with the approach of directly making system calls
on Unix, instead of calling the standard C library functions that
correspond to those system calls. <a href="https://utcc.utoronto.ca/~cks/space/blog/programming/GoCLibraryAPIIssues">There are reasonably good reasons
for Go to make direct system calls</a> and this
works well on Linux, but other Unixes are different. The official
API for Illumos and Solaris system calls requires you to use their
C library, and OpenBSD wants you to do this as well for security
reasons (for <a href="https://lwn.net/Articles/806776/">OpenBSD system call origin verification</a>). Go has used the C library on
Solaris and Illumos for a long time, but through Go 1.15 it made
direct system calls on OpenBSD and so current released versions of
OpenBSD had a special exemption from their system call origin
verification because of it.</p>

<p>The news of the time interval for Go 1.16 is that this is changing. To
quote from the current draft release notes (which are probably soon to
be the official release notes):</p>

<blockquote><p>On the 64-bit x86 and 64-bit ARM architectures on OpenBSD (the
<code>openbsd/amd64</code> and <code>openbsd/arm64</code> ports), system calls are now
made through <code>libc</code>, instead of directly using the <code>SYSCALL/SVC</code>
instruction. This ensures forward-compatibility with future versions
of OpenBSD. In particular, OpenBSD 6.9 onwards will require system
calls to be made through <code>libc</code> for non-static Go binaries.</p>
</blockquote>

<p>As far as I know, Go programs that look up host names or do a few other
operations are very likely to not be statically linked. You can force
static linking (and you'll normally get it if you cross-build), but it
has some drawbacks for hostname lookups in some configurations and you
can't do some other operations at all.</p>

<p>At one level everything is okay with this situation. OpenBSD 6.9 will
almost certainly include Go 1.16 in its ports collection, since it will
be the only version of Go that works on it, and from there you can build
Go programs that will run fine on 6.9. At another level, any dynamically
linked Go program you have will need to be rebuilt with Go 1.16 before
you can run it on OpenBSD 6.9. Hopefully you have the source code and
can still build it (in what will be a 'modular by default' world in Go
1.16). This is nothing really new for OpenBSD, which has always made it
clear that they don't promise ABI or even API compatibility; you always
need to be prepared to rebuild your programs for new OpenBSD versions,
and perhaps to update them to more secure APIs.</p>

<p>(Statically linked Go programs built by Go 1.15 or earlier will likely
keep working on OpenBSD 6.9, assuming that there are no other ABI
changes that affect them. But you should probably plan to rebuild them
with Go 1.16 just to be sure. I don't know what the situation will be
if you want to create Go binaries that work across a range of OpenBSD
versions.)</p>

<p>As the release notes say, Go 1.16 will make system calls through libc
for all programs, whether they're dynamically linked or statically
linked. Right now OpenBSD only requires this for dynamically linked
programs (well, will require it), but always calling via libc is simpler
than to maintain two sets of system call code. And someday OpenBSD may
do something more elaborate so that making system calls via libc is
required even for statically linked programs.</p>
</div></div>]]>
            </description>
            <link>https://utcc.utoronto.ca/~cks/space/blog/programming/Go116OpenBSDUsesLibc</link>
            <guid isPermaLink="false">hacker-news-small-sites-25997506</guid>
            <pubDate>Tue, 02 Feb 2021 04:39:35 GMT</pubDate>
        </item>
    </channel>
</rss>
