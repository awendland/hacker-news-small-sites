<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 20]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 20. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Wed, 25 Nov 2020 20:22:28 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-20.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Wed, 25 Nov 2020 20:22:28 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[Guide to OOMKill Alerting in Kubernetes Clusters]]>
            </title>
            <description>
<![CDATA[
Score 60 | Comments 26 (<a href="https://news.ycombinator.com/item?id=25192733">thread link</a>) | @draganm
<br/>
November 23, 2020 | https://www.netice9.com/blog/guide-to-oomkill-alerting-in-kubernetes-clusters | <a href="https://web.archive.org/web/*/https://www.netice9.com/blog/guide-to-oomkill-alerting-in-kubernetes-clusters">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>   <span>Monday 23 Nov 2020, 18:30</span> <h2>Intro</h2> <p>RAM is most likely the scarcest resource that is first exhausted on your servers. If you‚Äôre serious about running software under Linux/Unix, you‚Äôre certainly aware of what an OOMKill is.</p> <p>Short refresher: when a program requests a new memory page from the kernel two things can happen.</p> <ul><li>There is a free memory page: The kernel page assigns the page to the process and everything is great.</li> <li>The system is Out Of Memory (OOM): The kernel chooses a process based on its ‚Äòbadness‚Äô (mainly by how much ram it uses). It sends a SIGKILL to the process. This forces the receiving process to exit with exit code <code>137</code>. All the memory pages belonging to that process are free and now the kernel can fulfill the memory request.</li></ul> <p>Lately, I had a task to add alerting to a sizeable Kubernetes cluster. The cluster has ~100 active Deployments with autoscaling of nodes up to ~50 nodes at peak times. The cluster is well maintained and has a robust autoscaling strategy. All deployments have resource limits defined. Sometimes, some of the deployed pods would breach the memory limits. In those cases, it would be nice to find out when that happens and investigate the cause of it.</p> <p>Prometheus and Alertmanager were already deployed. So I‚Äôve thought that alerting on OOMKills will be as easy. I just had to find the right metric(s) indicating that OOMKill has happened and write an alerting rule for it. Given the length of this post, you could imagine how wrong I was!</p> <h2>First Attempt</h2> <p>A brief Google search has led me to the <a href="https://github.com/kubernetes/kube-state-metrics/blob/master/docs/pod-metrics.md" rel="nofollow">kube pod state metric</a>. It turns out it has a metric called <code>kube_pod_container_status_last_terminated_reason</code>. The value of the metric is <code>1</code> when a container in a pod has terminated with an error. Based on the exit code, the <code>reason</code> label will be set to <code>OOMKilled</code> if the exit code was <code>137</code>. That sounded promising! So I‚Äôve created an alert for that.</p> <p>As usual, things are rarely straightforward. As soon as the container restarts, the value of this metric will be <code>1</code>. For alerting purposes, one has to combine it with another metric that will change when a pod restarts. <code>kube_pod_container_status_restarts_total</code> does that. Combine the two - and Bingo! It Worked!</p> <h2>‚ÄúInvisible‚Äù OOMKills</h2> <p>For a brief moment, I‚Äôve thought that I was done. I was about to declare victory over OOMKills in production! But then a puzzle came my way: One of our software developers has come forward. He claimed that one of his pods was running out of memory and he couldn‚Äôt see any alerts for it.</p> <p>At first, I wasn‚Äôt inclined to believe that his diagnosis of running out of memory was correct. Mainly because his Pod didn‚Äôt even restart! But then I looked at the graph of the memory use of the Pod. It did show the usual pattern: Memory usage would grow, reach its peak at the memory limit, and then suddenly drop.</p> <p>I‚Äôve asked the developer for the gory details of the implementation. It turned out that the init process in the container would start a child process and wait for the result of it. If the child process would exit with an error, it would return an error to the requester and not terminate (because - why should it?).</p> <p>That is when it dawned to me - my alerting is effective only if container exits. This is usually the case when the init process of the container is OOMKilled. But there is no guarantee this will happen if a child of the init is OOMKilled. In the case where the container‚Äôs init tries to handle OOMKill by itself, my alerting is not triggering!</p> <h2>Trying the Existing Solutions</h2> <p>Given that OOMKills are as old as Unix, I thought: surely someone will have a solution for this already.</p> <p>I‚Äôve ensued onto a frantic search for some kind of metric exporter for this. I just needed the number of OOMKill events in a pod, or at least in a Docker container. Here is what I‚Äôve found:</p> <h3>cAdvisor</h3> <p>My first stop was cAdvisor itself. It turns out that cAdvisor is <a href="https://github.com/google/cadvisor/issues/1837" rel="nofollow">getting the OOMKill events, but not exporting them as a Prometheus metric and no one really seems to care.</a> So that was a dead-end.</p> <h3>kubernetes-oomkill-exporter</h3> <p>My second stop was <a href="https://github.com/sapcc/kubernetes-oomkill-exporter" rel="nofollow">kubernetes-oomkill-exporter</a>. A very promising-sounding project with two huge disadvantages:</p> <ul><li>There is really no documentation for it, literally anywhere.</li> <li>It does not work.</li></ul> <p>I‚Äôve tried the latest version of <a href="https://hub.docker.com/layers/sapcc/kubernetes-oomkill-exporter/0.3.0/images/sha256-b80875b903635f0336ea0b122b332e086da51ec5cd797de5d682dd14c3910b9f?context=explore" rel="nofollow">the Docker image</a>, but once started it crashes and burns with:</p> <pre><code>standard_init_linux.go:211: exec user process caused "no such file or directory"</code></pre> <p>Going <a href="https://hub.docker.com/layers/sapcc/kubernetes-oomkill-exporter/0.2.0/images/sha256-5e1b57f4ac0b57406ef067da3e83f743d70ff89aa1db717d41af2c699dc12f3a?context=explore" rel="nofollow">back one minor version</a> one gets the following output:</p> <pre><code>F1120 22:04:21.571246       1 main.go:73] Could not create log watcher
I1120 22:04:21.572066       1 main.go:64] Starting prometheus metrics</code></pre> <p>As it seems no one has committed any code to in over a year. It has a low number of stars (14). All that meant that I was back to square one.</p> <h2>Rolling my Own: <code>missing-container-metrics</code></h2> <p>Having a hard time finding an existing solution meant only one thing: I will have to write my own.</p> <p>A cursory look at <a href="https://docs.docker.com/engine/reference/commandline/events/" rel="nofollow">Docker‚Äôs events</a> delivered everything I needed. There is an event called <code>oom</code>. Docker emits this event every time the OOMKiller process gets active in the container. Now I was only missing a piece of code that will listen to those events and export them as Prometheus metrics.</p> <p>This is how <a href="https://github.com/draganm/missing-container-metrics" rel="nofollow">missing-container-metrics</a> was born. What it does is to connect to a local Docker instance (via <code>/var/run/docker.sock</code>). It lists all existing containers as a starting point. And then it listens to Docker events. Using those events, it keeps track of the currently running containers. It also gathers the basic stats of each container it knows about:</p> <ul><li>Number of restarts</li> <li>Last exit code</li> <li>Number of OOMKills</li></ul> <p>By design, it is not Kubernetes specific. This means it can be used with a plain Docker. But it also has a couple of very convenient Kubernetes specific features.</p> <p>Whenever it finds a container label for the pod name or namespace, it adds them as a label to the exported metrics. Also, label naming is compatible with <code>kube-state-metrics</code>.</p> <p>This keeps things simple for metric joins in PromQL.</p> <h2>Running it in the Cluster</h2> <p>In a Kubernetes cluster, <code>missing-container-metrics</code> needs to run on every node. The simplest way to achieve this is to use a daemon-set. The source code comes with an example <a href="https://github.com/draganm/missing-container-metrics#kubernetes" rel="nofollow">daemon set</a> deployment.</p> <h2>An Interesting Find Using <code>missing-container-metrics</code></h2> <p>The most interesting issue I‚Äôve found was where I‚Äôve least expected it: Fluentd!</p> <p>Fluentd log forwarder for node/pod/kubelet logs to the log aggregator. When the volume of logs was very high, Fluentd is OOMKilled.</p> <p>Looking at the details of how Fluentd works, it becomes clear what is going on.</p> <p>Fluentd has one main process (that ends up being init process in the container). This main process forks a worker process that forwards the logs. When the worker process dies for some reason (for example OOMKill), the main process starts a new one. This leads to an endless loop of spawn/OOMKill.</p> <p>The fact that Fluentd is the log forwarder is very unfortunate. OOMKill loop would stop the log forwarding, so you could not ‚Äòsee‚Äô what is going on by inspecting the logs.</p> <h2>Epilogue</h2> <p>If you want to make sure that your Kubernetes cluster is healthy, it is essential to alert on OOMKills. This enables you to know when processes hit their memory limits. Be it because of memory leaks or wrongly configured memory limits.</p> <p>It turns out that monitoring for OOMKills in Kubernetes is not as an easy task as one might think. Using <a href="https://github.com/draganm/missing-container-metrics" rel="nofollow">missing-container-metrics</a> makes it much easier though.</p> <p>So go ahead, deploy <a href="https://github.com/draganm/missing-container-metrics" rel="nofollow">missing-container-metrics</a> to your cluster. You might be surprised how many of OOMKills you have not been noticing.</p> <p>I hope that it will be useful to you, and will save you the time that I‚Äôve spent searching for the solution.</p></article></div>]]>
            </description>
            <link>https://www.netice9.com/blog/guide-to-oomkill-alerting-in-kubernetes-clusters</link>
            <guid isPermaLink="false">hacker-news-small-sites-25192733</guid>
            <pubDate>Mon, 23 Nov 2020 22:31:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Walmart Exclusive Wi-Fi Router Contains Backdoor to Control Devices]]>
            </title>
            <description>
<![CDATA[
Score 281 | Comments 12 (<a href="https://news.ycombinator.com/item?id=25189673">thread link</a>) | @wikus
<br/>
November 23, 2020 | https://hfet.org/walmart-exclusive-wi-fi-router-contains-backdoor-to-control-devices/ | <a href="https://web.archive.org/web/*/https://hfet.org/walmart-exclusive-wi-fi-router-contains-backdoor-to-control-devices/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">

			
	<main id="main" role="main">

		
<article id="post-1238">

	<!-- .entry-header -->

	
		<figure>
			<img width="1080" height="540" src="https://hfet.org/wp-content/uploads/2020/11/wallmart_router_backdoor_humans_for_ethical_technology_hfet-1080x540.jpg" alt="" loading="lazy" srcset="https://hfet.org/wp-content/uploads/2020/11/wallmart_router_backdoor_humans_for_ethical_technology_hfet-1080x540.jpg 1080w, https://hfet.org/wp-content/uploads/2020/11/wallmart_router_backdoor_humans_for_ethical_technology_hfet-20x11.jpg 20w" sizes="(max-width: 1080px) 100vw, 1080px">		</figure>

		
	
<div>

	<h4>A Walmart-exclusive Wi-Fi router, and others sold on Amazon &amp; eBay contain hidden backdoors to control devices <a href="https://cybernews.com/security/walmart-exclusive-routers-others-made-in-china-contain-backdoors-to-control-devices/" target="_blank" rel="noopener noreferrer">reports CyberNews</a>.</h4>
<ul>
<li>Researchers discovered that many low cost, Chinese-made Wi-Fi routers contain a hidden backdoor which is being actively exploited to create botnet attacks.</li>
</ul>
<p>CyberNews researchers discovered suspicious backdoors in a Chinese made router sold under the name ‚ÄòJetstream‚Äô. This router is part of Walmart‚Äôs new line of affordable Wi-Fi routers.</p>
<blockquote><p>This backdoor would allow an attacker the ability to remotely control not only the routers, but also any devices connected to that network.</p></blockquote>
<p><img loading="lazy" src="https://hfet.org/wp-content/uploads/2020/11/pexels-brett-sayles-2881232-1024x681.jpg" alt="" width="800" height="532" srcset="https://hfet.org/wp-content/uploads/2020/11/pexels-brett-sayles-2881232-1024x681.jpg 1024w, https://hfet.org/wp-content/uploads/2020/11/pexels-brett-sayles-2881232-300x199.jpg 300w, https://hfet.org/wp-content/uploads/2020/11/pexels-brett-sayles-2881232-768x511.jpg 768w, https://hfet.org/wp-content/uploads/2020/11/pexels-brett-sayles-2881232-20x13.jpg 20w, https://hfet.org/wp-content/uploads/2020/11/pexels-brett-sayles-2881232-36x24.jpg 36w, https://hfet.org/wp-content/uploads/2020/11/pexels-brett-sayles-2881232-48x32.jpg 48w, https://hfet.org/wp-content/uploads/2020/11/pexels-brett-sayles-2881232-272x182.jpg 272w, https://hfet.org/wp-content/uploads/2020/11/pexels-brett-sayles-2881232.jpg 1280w" sizes="(max-width: 800px) 100vw, 800px"></p>
<p>The researchers contacted Walmart to get a statement, and a Walmart spokesperson had this to say:</p>
<blockquote><p>‚ÄúThank you for bringing this to our attention. We are looking into the issue to learn more. The item in question is currently out of stock and we do not have plans to replenish it.‚Äù</p></blockquote>
<p>CyberNews researchers also discovered that ‚ÄòWavlink‚Äô branded routers, often sold on Amazon or eBay, <a href="https://cybernews.com/security/walmart-exclusive-routers-others-made-in-china-contain-backdoors-to-control-devices/" target="_blank" rel="noopener noreferrer">contain similar backdoors</a>.</p>
<p>Worryingly, they also discovered that these <strong>backdoors are being actively exploited</strong>, and there have been attempts to add the routers to a botnet with malware that allows them to be used in large scale DDoS attacks, which have <a href="https://cybernews.com/security/walmart-exclusive-routers-others-made-in-china-contain-backdoors-to-control-devices/" target="_blank" rel="noopener noreferrer">in the past taken down major websites</a> such as Reddit, Netflix, CNN, GitHub, Twitter, AirBnb and more.</p>
<h4><strong>Read more of the <a href="https://cybernews.com/security/walmart-exclusive-routers-others-made-in-china-contain-backdoors-to-control-devices/" target="_blank" rel="noopener noreferrer">full report on CyberNews</a>.</strong></h4>
<p><strong><a href="https://james-clee.com/2020/04/18/multiple-wavlink-vulnerabilities/" target="_blank" rel="noopener noreferrer">James Clee‚Äôs Report</a> on ‚ÄòWavlink‚Äô routers‚Äô backdoors.<br>
</strong></p>
<p><a href="https://hfet.org/feed/"><img src="https://hfet.org/wp-content/uploads/2020/11/rss_button_hfet-1.png" alt="" width="219" height="30"></a><a href="https://hfet.org/support/"><img src="https://hfet.org/wp-content/uploads/2020/11/support_button_hfet.png" alt="" width="165" height="30"></a></p>
    <div itemtype="http://schema.org/Person" itemscope="" itemprop="author"><p><img width="100" height="100" src="https://hfet.org/wp-content/uploads/2020/11/karl-swanepoel-150x150.jpg" alt="" loading="lazy" srcset="https://hfet.org/wp-content/uploads/2020/11/karl-swanepoel-150x150.jpg 150w, https://hfet.org/wp-content/uploads/2020/11/karl-swanepoel-300x300.jpg 300w, https://hfet.org/wp-content/uploads/2020/11/karl-swanepoel-20x20.jpg 20w, https://hfet.org/wp-content/uploads/2020/11/karl-swanepoel-36x36.jpg 36w, https://hfet.org/wp-content/uploads/2020/11/karl-swanepoel-48x48.jpg 48w, https://hfet.org/wp-content/uploads/2020/11/karl-swanepoel-24x24.jpg 24w, https://hfet.org/wp-content/uploads/2020/11/karl-swanepoel-96x96.jpg 96w, https://hfet.org/wp-content/uploads/2020/11/karl-swanepoel.jpg 640w" sizes="(max-width: 100px) 100vw, 100px"></p><div><p>I‚Äôm an AI &amp; Robotics Student interested in FOSS, Tech Sustainability and Data Rights. I‚Äôm also the founder of Humans For Ethical Technology.</p></div></div>	
</div><!-- .entry-content -->


</article>

	</main><!-- #main -->

	


	</div></div>]]>
            </description>
            <link>https://hfet.org/walmart-exclusive-wi-fi-router-contains-backdoor-to-control-devices/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25189673</guid>
            <pubDate>Mon, 23 Nov 2020 18:10:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Selling to unicorns from my parents basement]]>
            </title>
            <description>
<![CDATA[
Score 39 | Comments 19 (<a href="https://news.ycombinator.com/item?id=25188716">thread link</a>) | @timjones
<br/>
November 23, 2020 | https://www.themvpsprint.com/p/selling-to-unicorns-from-my-parents | <a href="https://web.archive.org/web/*/https://www.themvpsprint.com/p/selling-to-unicorns-from-my-parents">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><h2>‚öîÔ∏è David selling to Goliath</h2><p><strong>Me</strong> - a <a href="https://www.themvpsprint.com/about">bootstrapped solopreneur</a> with a laptop and a dream.</p><p><strong>Them</strong> - a billion dollar unicorn with 10,000+ employees.</p><h4><strong>Will I really be able to sell into their corporate web of bureaucracy?</strong></h4><h2>üí∏ From idea to revenue</h2><p><em><a href="https://www.themvpsprint.com/about">I‚Äôm a solo, bootstrapped founder</a></em> building a SaaS startup in public.</p><p>Over the last 4 weeks, I‚Äôve <a href="https://mvpsprint.substack.com/p/choose-a-problem">chosen a problem to solve</a>, <a href="https://mvpsprint.substack.com/p/step-2-even-unicorns-walk-before-they-run">picked a niche</a>, <a href="https://www.themvpsprint.com/p/step-3-seeking-validation">validated my problem</a>, and <a href="https://www.themvpsprint.com/p/how-and-when-to-acquire-saas-users">created a top-of-the-funnel distribution strategy</a>.</p><p>This week I create a strategy for selling <a href="https://www.hellohailey.io/">HelloHailey</a> into companies of all sizes - from small startups to billion dollar unicorns.</p><div><figure><a target="_blank" href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Ff35cb8c0-fa57-49c8-8fbf-07073ac66533_971x2774.png"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Ff35cb8c0-fa57-49c8-8fbf-07073ac66533_971x2774.png" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/f35cb8c0-fa57-49c8-8fbf-07073ac66533_971x2774.png&quot;,&quot;height&quot;:2774,&quot;width&quot;:971,&quot;resizeWidth&quot;:368,&quot;bytes&quot;:277261,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null}" alt=""></a></figure></div><p>I‚Äôm sharing all my product decisions, metrics, successes, and failures in public.</p><p><strong>Next Monday, I‚Äôll (finally) describe the product I‚Äôm building.</strong> Want to read it in your inbox?</p><p data-attrs="{&quot;url&quot;:&quot;https://www.themvpsprint.com/subscribe&quot;,&quot;text&quot;:&quot;Get my real-time case study&quot;,&quot;class&quot;:null}"><a href="https://www.themvpsprint.com/subscribe"><span>Get my real-time case study</span></a></p><h2>üöÄ Land and expand</h2><p>The traditional SaaS sales process follows a <strong>top-down approach</strong>. A sales rep targets a high-level decision maker for a high-priced deal.</p><p>After a long sales process, a company slowly integrates a piece of software. <strong>The command comes from high in the org chart and makes its way down.</strong></p><div><figure><a target="_blank" href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F2651c983-567a-4996-b90d-6c2eef084537_2692x2200.png"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F2651c983-567a-4996-b90d-6c2eef084537_2692x2200.png" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/2651c983-567a-4996-b90d-6c2eef084537_2692x2200.png&quot;,&quot;height&quot;:1190,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:303429,&quot;alt&quot;:&quot;Top-down sales strategy&quot;,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null}" alt="Top-down sales strategy"></a><figcaption>A top-down sales approach targets the top of the org chart.</figcaption></figure></div><h3><strong>But I‚Äôll be selling bottom-up</strong> </h3><p><strong>I‚Äôll scale the corporate walls via product managers (PMs) and engineering managers (EMs)</strong>. </p><p>I‚Äôll look unintimidating - a low price product that eats up a small chunk of a budget these team leads control.</p><p><strong>Then I‚Äôll spread through the company like wildfire </strong>via growth mechanisms built into the product.</p><p>One team will adopt me.</p><p>Then two.</p><p>Then the entire department. </p><p>Then the entire company.</p><div><figure><a target="_blank" href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F4bc6903c-6bbd-488c-b89f-516ba14a08a8_2057x3006.png"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F4bc6903c-6bbd-488c-b89f-516ba14a08a8_2057x3006.png" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/4bc6903c-6bbd-488c-b89f-516ba14a08a8_2057x3006.png&quot;,&quot;height&quot;:2128,&quot;width&quot;:1456,&quot;resizeWidth&quot;:546,&quot;bytes&quot;:348487,&quot;alt&quot;:&quot;\&quot;Land and Expand\&quot; sales strategy&quot;,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null}" alt="&quot;Land and Expand&quot; sales strategy"></a><figcaption>A ‚ÄúLand and Expand‚Äù strategy starts at the bottom of the org chart; then expands via growth mechanisms built into the product.</figcaption></figure></div><p>I know what you‚Äôre thinking - <em>all this sounds great on paper. But how are you so confident it will work?</em></p><p><strong>I‚Äôm not </strong>üò≥</p><p><strong>Honestly, I don‚Äôt even know if I‚Äôll be able to ‚Äúland‚Äù, much less expand</strong>.</p><h3>It‚Äôs time to test out my landing gear</h3><p>‚Ä¶so I don‚Äôt build a product that crashes and burns on the runway.</p><p><strong>In <a href="https://www.themvpsprint.com/p/how-and-when-to-acquire-saas-users">last week‚Äôs article</a>, I outlined my top-of-the-funnel strategy</strong> - how to get PM and EM eyeballs on <a href="https://www.hellohailey.io/">HelloHailey</a>.</p><p><strong>This week I‚Äôm focusing on the bottom of the funnel</strong> - converting those eyeballs into paid users.</p><p><strong>Here‚Äôs what that funnel looks like for a PM or EM:</strong></p><ol><li><p><strong>Discover</strong> through top-of-the-funnel distribution channels.</p></li><li><p><strong>Try for free</strong> with their team.</p></li><li><p><strong>Get value - </strong>signaled by high engagement and retention.</p></li><li><p><strong>Convert to paid tier</strong> - to unlock premium features or exceed maximum number of seats (users) in free tier.</p></li><li><p><strong>Expand </strong>- add more seats within their company.</p><div><figure><a target="_blank" href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F5d8f40ce-fff5-494d-b754-e0696f648de6_2329x2815.png"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F5d8f40ce-fff5-494d-b754-e0696f648de6_2329x2815.png" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/5d8f40ce-fff5-494d-b754-e0696f648de6_2329x2815.png&quot;,&quot;height&quot;:1760,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:308211,&quot;alt&quot;:&quot;HelloHailey user acquisition funnel&quot;,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null}" alt="HelloHailey user acquisition funnel"></a><figcaption>HelloHailey user acquisition funnel</figcaption></figure></div></li></ol><h4><strong>My go-to-market strategy fails if I can‚Äôt convert free users into paid users.</strong></h4><p>But I know very little about B2B purchasing processes for low-ticket ($25-$50 / month) SaaS products:</p><ol><li><p><em>Will users have to fight tooth and nail for approval?</em></p></li><li><p><em>Who has a company credit card?</em></p></li><li><p><em>What budget will the money come from?</em></p></li></ol><p>To avoid this suc-SaaS story turning into a dis-SaaS-ter (üôÑ sorry, couldn‚Äôt resist), <strong>I‚Äôm going to invest a few days now into understanding what the purchasing process will look like.</strong></p><h2>üí∞ How low-ticket SaaS products get purchased</h2><p>I probed into my network of EMs and PMs for answers. </p><p><em>Big shoutout to all those who helped me! </em>üôè</p><p>It turns out that my fears of a long chain of approvals with stringent criteria were unfounded.</p><h3><strong>The approval and purchase process is just two steps:</strong></h3><h4>1. Ask a manager</h4><p>Approval is loose and informal. PMs and EMs briefly mention it to their managers over email or their regular check-in.</p><p>Managers won‚Äôt require much justification for approval. Why? Its an immaterial amount of money and they trust their employees‚Äô judgment.</p><h4>2. Find a credit card</h4><p>With very few exceptions, PMs and EMs (at the levels I‚Äôm targeting) don‚Äôt have company credit cards. So how do they pay after getting approval?</p><h5>Pay with personal credit card</h5><p>This is a common practice for team meals, social events, and one-off software purchases. A senior team member will pay with a personal card and file an expense report.</p><p>But people are more hesitant to pay for a <em><strong>recurring</strong></em> team subscription with a personal card.</p><h5>Find a company credit card</h5><p>This varies from company to company, but the most common places people go are:</p><ol><li><p><strong>Finance</strong> (manages budgets)</p></li><li><p><strong>IT</strong> (manages access to company subscriptions)</p></li><li><p><strong>Lowest person above them in the org chart with a company card</strong> (usually a Director or VP, depending on company size)</p></li></ol><h2>üòÅ Why my strategy will work</h2><h5>‚úÖ  Loose approval process</h5><p>I mentioned this before, but it‚Äôs worth restating. <strong>This means that the PM or EM using <a href="https://www.hellohailey.io/">HelloHailey</a> is the primary decision maker.</strong></p><p>No bureaucracy. No long, complex sales cycles.</p><p><strong>I just need to build a great product.</strong></p><h5>‚úÖ  Fits into an existing budget</h5><p>It‚Äôs my hypothesis that teams will pay for HelloHailey using their team ‚Äúsocial‚Äù budgets. These budgets cover expenses like meals, games, or team events.</p><h5>‚úÖ  Takes a small percentage of that budget</h5><p>Team social budgets range from $10-$100 / person / month, with a median somewhere in the middle.</p><p>With a price of $2-$3 / person / month, HelloHailey would eat up only 5% of that budget on average.</p><h5>‚úÖ  Social budgets have been underutilized with sudden shift to remote work</h5><p>Half the people I talked to haven‚Äôt used their social budgets at all since being forced into remote work.</p><p>Most of the other half has used it sparingly for virtual team events.</p><h2>üò¢ Why it might not work</h2><p>Until companies <em>actually</em> start paying me, my strategy will be full of uncertainty.</p><p>Here are some ways it might fail:</p><h5>üí©  Doesn‚Äôt fit into an existing budget</h5><p>Maybe companies don‚Äôt think it‚Äôs appropriate to pull from team social budgets for this kind of purchase.</p><p>If it doesn‚Äôt fit nicely into <em>any</em> existing category, it‚Äôll be much harder for companies to buy it.</p><h5>üí©  Hard to budget for a product with expanding price</h5><p><a href="https://www.hellohailey.io/">HelloHailey</a> will get more expensive as more users and teams are added within a company. </p><h5>üí©  <strong>What happens when a product purchased with Team A‚Äôs social budget adds users from Team B and gets more expensive? </strong></h5><p>I don‚Äôt know ü§∑‚Äç‚ôÇÔ∏è (<em>Do you? <a href="https://twitter.com/AnotherTimJones">Share your wisdom and help me out</a> </em>üôÇ ).</p><p>But I‚Äôm not the first person to face this problem. There are precedents in place and I‚Äôm confident I‚Äôll figure it out.</p><h5>üí©  Approval process is more difficult than expected</h5><p>The people I interviewed could be outliers. Maybe a typical manager requires more convincing to approve this kind of purchase.</p><h2>What about expanding?</h2><p>I now feel confident about landing. <strong>So how will I expand?</strong></p><p>I have some ideas for how I can build growth mechanisms into a product like this.</p><p>But if I‚Äôm being honest, I‚Äôm not sure yet ü§∑‚Äç‚ôÇÔ∏è. And I‚Äôm OK with that.</p><p><strong>With a successful ‚Äúland‚Äù strategy, and low to moderate expansion revenue, I can build a great business.</strong></p><p>Intra-company virality would be a must if I wanted to become a VC-backed rocket ship.</p><p><strong>But that‚Äôs not my goal.</strong></p><p><strong>I want to build a small, profitable company that solves a problem I‚Äôm passionate about.</strong></p><p>I can sell to unicorns. But I don‚Äôt want to <em>become</em> one.</p><h2>What did I get wrong?</h2><p>I learned a lot this week, but I‚Äôve never done this before. </p><p><strong>Do you have SaaS sales experience?</strong></p><p>Don‚Äôt pull your punches! Help me out on my Twitter thread:</p><p>Don‚Äôt have any tips for me? <strong>Maybe you could help me out with a like or a retweet.</strong></p><p><strong>As a solopreneur with no funding or income, I‚Äôll take all the help I can get üòÅ</strong></p><h2>ü§î Reducing uncertainty one week at a time</h2><div><figure><a target="_blank" href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fcac3da08-e921-4064-b421-eebf46ef563b_920x248.png"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fcac3da08-e921-4064-b421-eebf46ef563b_920x248.png" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/cac3da08-e921-4064-b421-eebf46ef563b_920x248.png&quot;,&quot;height&quot;:248,&quot;width&quot;:920,&quot;resizeWidth&quot;:490,&quot;bytes&quot;:29061,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null}" alt=""></a></figure></div><div><figure><a target="_blank" href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fd00e39b8-5136-450c-b442-675c0cd2fd7f_478x184.png"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fd00e39b8-5136-450c-b442-675c0cd2fd7f_478x184.png" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/d00e39b8-5136-450c-b442-675c0cd2fd7f_478x184.png&quot;,&quot;height&quot;:184,&quot;width&quot;:478,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:23531,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/png&quot;,&quot;href&quot;:null}" alt=""></a></figure></div><p>I‚Äôm finally feeling confident about my go-to-market strategy. Now it‚Äôs time to define the product I‚Äôll be going to market with‚Ä¶</p><p><strong>Over the next two weeks, I‚Äôll define my product vision and finalize requirements for an MVP (minimum viable product).</strong></p><p><strong>Curious to find out what I‚Äôll be building?</strong> </p><p>I‚Äôll tell you next Monday:</p><p data-attrs="{&quot;url&quot;:&quot;https://www.themvpsprint.com/subscribe&quot;,&quot;text&quot;:&quot;Send me next week's update&quot;,&quot;class&quot;:null}"><a href="https://www.themvpsprint.com/subscribe"><span>Send me next week's update</span></a></p><p><em>I‚Äôll be documenting my startup journey from idea to paying users over the coming weeks and months. I‚Äôd love to have you along for the ride.</em></p><p><em>Icons made by&nbsp;<a href="https://www.freepik.com/">Freepik</a>,&nbsp;<a href="https://www.flaticon.com/authors/icongeek26">Icongeek26</a>, and&nbsp;<a href="https://www.flaticon.com/authors/pixel-perfect">Pixel perfect</a>&nbsp;from&nbsp;<a href="https://www.flaticon.com/">Flaticon</a></em></p></div></div>]]>
            </description>
            <link>https://www.themvpsprint.com/p/selling-to-unicorns-from-my-parents</link>
            <guid isPermaLink="false">hacker-news-small-sites-25188716</guid>
            <pubDate>Mon, 23 Nov 2020 16:53:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[On Small Games]]>
            </title>
            <description>
<![CDATA[
Score 159 | Comments 72 (<a href="https://news.ycombinator.com/item?id=25188542">thread link</a>) | @polm23
<br/>
November 23, 2020 | https://lorenzo.itch.io/on-small-games | <a href="https://web.archive.org/web/*/https://lorenzo.itch.io/on-small-games">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p><em>I wanted to write a Small Games Manifesto for the Manifesto Jam, but I&nbsp;was too tired, so I collected&nbsp;other people's thoughts about small games instead.</em></p>

<p><em>See also: <a href="http://ebeth.itch.io/small-games-manifesto" target="_blank">Small Games Manifesto</a> by Ebeth.</em><br></p>

<p><em>Looking for some small games to play? Check out my <a href="https://itch.io/c/6160/small-is-beautiful" target="_blank">Small is Beautiful</a> and&nbsp;<a href="https://itch.io/c/232207/bitsy-faves-pt2-20192020" target="_blank">Bitsy Faves</a>&nbsp;collections.</em></p>

<p><em>Follow me on Twitter <a href="https://twitter.com/LorenzoPilia" target="_blank" rel="nofollow noopener">@LorenzoPilia</a></em></p>

<p>‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢</p>

<p>Make short and intense games:<br>think haiku, not epic.<br>Think poetry, not prose.<br><strong>‚Äî Auriea Harvey &amp; Micha√´l Samyn: Realtime Art Manifesto</strong><br><a href="http://tale-of-tales.com/tales/RAM.html" rel="nofollow noopener">http://tale-of-tales.com/tales/RAM.html</a></p>

<p>‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢<br></p>

<p>things i will never do in this lifetime:&nbsp;<br>play a game for a few straight hours<br>play a game with more than a few hours worth of content<br><strong>‚Äî @moshboy</strong><br><a href="https://twitter.com/moshboy/status/607408540496465922" rel="nofollow noopener">https://twitter.com/moshboy/status/607408540496465922</a></p>

<p>‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢<br></p>

<p>Hell, you'd be surprised at how many people buy games with a moderate length and never finish them. On PC over 50 percent of the people who bought the latest Wolfenstein, a game you can beat in under 15 hours, never earned the achievement for finishing the story. Only 31 percent of Dishonored players on the PC beat the game. People think game length is mandatory, but even shorter games aren't finished by the majority of players.
<br><strong>‚Äî Ben Kuchera: To hell with longer games, tell me how SHORT your game is</strong><br><a href="https://www.polygon.com/2014/10/14/6974791/short-games-review" rel="nofollow noopener">https://www.polygon.com/2014/10/14/6974791/short-games-review</a></p>

<p>‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢<br></p>

<p>Especially if you're starting out, try to do small projects and don't worry too much about polishing them, don't worry about shipping the perfect game, embrace the messiness of getting into games for the first time, embrace not knowing what you're doing exactly yet. (...) If you just put your heart into it in that way, and embrace the messiness of small games, people will really connect with that.<br><strong>‚Äî Nina Freeman: Keynote at A MAZE. / Johannesburg 2017<br></strong><a href="https://twitter.com/AMazeFest/status/908032352953217038" rel="nofollow noopener">https://twitter.com/AMazeFest/status/908032352953217038</a></p>

<p>‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢<br></p>

<p>Duration doesn't need to be a burden. It can be a tool to wield.<br><strong>‚Äî Thomas McMullan: Inside and the rise of short games</strong><br><a href="http://www.alphr.com/games/1003958/inside-and-the-rise-of-short-games" rel="nofollow noopener">http://www.alphr.com/games/1003958/inside-and-the-rise-of-short-games</a></p>

<p>‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢<br></p>

<p>Small-scale works are often derided for feeling embryonic or unfinished, throwaway motifs or fledgling ideas that the artist failed to integrate into a sufficiently ambitious whole. Game designer Jake Elliott, who drew the title of his Ruins from Schumann‚Äôs appraisal of Chopin‚Äôs preludes, defended their proportion in an interview: ‚ÄúMaybe [Chopin] felt like they were complete objects, but there wasn‚Äôt a vocabulary for talking about pieces of music that were short at the time. Their length is what drew me ‚Ä¶ there is a lot that‚Äôs unspoken.‚Äù Having conventionally privileged length, magnitude, and formal unity, games too have left critics bereft of a clear rubric for evaluating intentionally abbreviated, serialized, even disorderly exercises in interactive design.<br><strong>‚Äî Peter Lido: Undertale, one year later</strong><br><a href="https://killscreen.com/articles/undertale-one-year-later/" rel="nofollow noopener">https://killscreen.com/articles/undertale-one-year-later/</a></p>

<p>‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢<br></p>

<p>The final idea that we brought over as gamers, the final idea that we had to let go of, was that a longer game makes a better game. We felt that the sense of completion and catharsis that you get when you watch our ending was so critical to the experience, that we decided that we had to help as many people as possible to complete Monument Valley. And that was more important than making the game longer or more difficult.<br><strong>‚Äî Ken Wong: Games Without Gamers (#DICE2014 Europe)</strong><br><a href="http://youtu.be/YdSClYHDow0?t=13m37s" rel="nofollow noopener">https://youtu.be/YdSClYHDow0?t=13m37s</a></p>

<p>‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢<br></p>

<p>I value games being short, it makes them easier to fit into life, they get to the point sooner, it's possible to play them more times, trying out different possibilities, there's a clearer connection between decisions and outcome.<br><strong>‚Äî Michael Brough: imbroglio notes 6 - meditation</strong><br><a href="http://mightyvision.blogspot.de/2016/08/imbroglio-notes-6-meditation.html?m=1" rel="nofollow noopener">http://mightyvision.blogspot.de/2016/08/imbroglio-notes-6-meditation.html?m=1</a></p>

<p>‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢ ‚Ä¢<br></p>

<p>Small games must be protected from their own defenders!! They must be defended against a rhetoric of convenience, as if fitting helpfully into the meagre free time allotted us by rentiers was something to be proud of rather than something to grind against - they must be defended against the meagre virtues of "minimalism", parsimony, elegance, the values of those with enough cultural cachet that they can afford to speak softly, and which hold the same relation to an actual human economy of wants and needs as does a millionaire who doesn't tip.<br><strong>‚Äî thecathamites: Small Game Manifesto (part of&nbsp;Buttertown, 10 manifestos for groups of no people)</strong><br><a href="https://thecatamites.itch.io/buttertown">https://thecatamites.itch.io/buttertown</a></p>


</div></div>]]>
            </description>
            <link>https://lorenzo.itch.io/on-small-games</link>
            <guid isPermaLink="false">hacker-news-small-sites-25188542</guid>
            <pubDate>Mon, 23 Nov 2020 16:38:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Getting Started with Firecracker on Raspberry Pi]]>
            </title>
            <description>
<![CDATA[
Score 82 | Comments 25 (<a href="https://news.ycombinator.com/item?id=25187965">thread link</a>) | @sairamkunala
<br/>
November 23, 2020 | https://dev.l1x.be/posts/2020/11/22/getting-started-with-firecracker-on-raspberry-pi/ | <a href="https://web.archive.org/web/*/https://dev.l1x.be/posts/2020/11/22/getting-started-with-firecracker-on-raspberry-pi/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><h2 id="abstract">Abstract</h2><p>Traditionally services were deployed on bare metal and in the last decades we have seen the rise of virtualisation (running additional operating systems in a operating system process) and lately containerisation (running an operating system process in a separate security context from the rest of processes on the same host). Virtualisation and containerisation offers different levels of isolation by moving some operating system functionality to the guest systems.</p><p>The following chart illustrates that pretty well:</p><p><img src="https://dev.l1x.be/img/isolation.png" alt="OS functionality location"></p><p>Source: <a href="https://research.cs.wisc.edu/multifacet/papers/vee20_blending.pdf">https://research.cs.wisc.edu/multifacet/papers/vee20_blending.pdf</a></p><p>In this article, I perform a deep dive into Firecracker and how it can be used for deploying services on Raspberry Pi (4B).</p><h2 id="getting-started">Getting started</h2><p>There are few paths to take here. First I am going to try the easy one, using Ubuntu. Later on we can investigate the use of Alpine Linux which is much more lightweight than Ubuntu, ideal for devices like RPI.</p><h3 id="installing-the-image-on-a-microsd-card">Installing the image on a microSD card</h3><p>We need a 64 bit Ubuntu image and a microsd card. For the imaging I use <a href="https://www.balena.io/etcher/">Balena Etcher</a> that makes the imaging process super easy.</p><p>Getting the pre-installed image:</p><div><pre><code data-lang="bash">wget https://cdimage.ubuntu.com/releases/20.04/release/<span>\
</span><span></span>ubuntu-20.04.1-preinstalled-server-arm64+raspi.img.xz
</code></pre></div><p>Preinstalled means that we get a fully working operating system and there is no need for additional installation steps after booting up. With Balena Etcher it is super easy to write the compressed image file to the sd card and boot the system up once ready. SSHD starts up after the installation and we can log in via ssh if we know the IP address that the DHCP server issues to our device (assuming DHCP server is present in our LAN).</p><p>There are few mildly annoying things with Ubuntu (snaps, unattended-upgrades) that I usually remove. I also prefer to use Chrony over the systemd equivalent. Ansible repo for these is available here: <a href="https://github.com/l1x/rpi/blob/main/ubuntu.20/ansible/roles/os/tasks/main.yml">https://github.com/l1x/rpi/blob/main/ubuntu.20/ansible/roles/os/tasks/main.yml</a></p><h3 id="installing-firecracker-jailer-and-firectl">Installing Firecracker, Jailer and Firectl</h3><ul><li>Firecracker: The main component, it is a virtual machine monitor (VMM) that uses the Linux Kernel Virtual Machine (KVM) to create and run microVMs.</li><li>Jailer: For starting Firecracker in production mode, applies a cgroup/namespace isolation barrier and then drops privileges. There</li><li>Firectl: A command line utility for convenience</li></ul><h4 id="getting-firecracker-and-jailer">Getting Firecracker and Jailer</h4><p>For the first two it is possible to download the release binaries from Github.</p><div><pre><code data-lang="bash"><span>version</span><span>=</span><span>'v0.23.0'</span>

wget https://github.com/firecracker-microvm/firecracker/<span>\
</span><span></span>releases/download/<span>${</span><span>version</span><span>}</span>/firecracker-<span>${</span><span>version</span><span>}</span>-aarch64
wget https://github.com/firecracker-microvm/firecracker/<span>\
</span><span></span>releases/download/<span>${</span><span>version</span><span>}</span>/jailer-<span>${</span><span>version</span><span>}</span>-aarch64

mv firecracker-<span>${</span><span>version</span><span>}</span>-aarch64 firecracker
mv jailer-<span>${</span><span>version</span><span>}</span>-aarch64 jailer

chmod +x firecracker jailer

./firecracker --help
./jailer --help
</code></pre></div><h4 id="firectl">Firectl</h4><p>Firectl is a bit trickier to install because there is no release binary and it requires Golang 1.14 to compile. We can do these in two steps.</p><div><pre><code data-lang="bash">wget https://golang.org/dl/go1.14.12.linux-arm64.tar.gz
tar xzvf go1.14.12.linux-arm64.tar.gz
</code></pre></div><p>After getting go we can get the source of firectl and compile it:</p><div><pre><code data-lang="bash">git clone https://github.com/firecracker-microvm/firectl.git
<span>cd</span> firectl/
 ~/go/bin/go build -x
</code></pre></div><p>Testing Firectl:</p><p>We have all the tools we need for running our first microVM the only thing is missing: something to run.</p><h3 id="downloading-our-first-image">Downloading our first image</h3><p>For a microVM there are two things necessary to have:</p><ul><li>an uncompressed linux kernel (vmlinux)</li><li>a filesystem</li></ul><p>Later on we are going to investigate how we could create our own version of these, but for now we are going to use images from</p><div><pre><code data-lang="bash">wget https://s3.amazonaws.com/spec.ccfc.min/<span>\
</span><span></span>img/aarch64/ubuntu_with_ssh/kernel/vmlinux.bin
wget https://s3.amazonaws.com/spec.ccfc.min/<span>\
</span><span></span>img/aarch64/ubuntu_with_ssh/fsfiles/xenial.rootfs.ext4
</code></pre></div><h3 id="configuring-network">Configuring network</h3><p>For the microVM to function properly we need a networking device. For this scenario we are going to use tap and create a device:</p><div><pre><code data-lang="bash">sudo ip tuntap add dev tap0 mode tap
sudo ip addr add 172.16.0.1/24 dev tap0
sudo ip link <span>set</span> tap0 up
ip addr show dev tap0
</code></pre></div><p>If we want to give access to our VM we have to enable IP forwarding:</p><div><pre><code data-lang="bash"><span>DEVICE_NAME</span><span>=</span>eth0
sudo sh -c <span>"echo 1 &gt; /proc/sys/net/ipv4/ip_forward"</span>
sudo iptables -t nat -A POSTROUTING -o <span>$DEVICE_NAME</span> -j MASQUERADE
sudo iptables -A FORWARD -m conntrack --ctstate RELATED,ESTABLISHED -j ACCEPT
sudo iptables -A FORWARD -i tap0 -o <span>$DEVICE_NAME</span> -j ACCEPT
</code></pre></div><h3 id="running-our-first-microvm">Running our first microVM</h3><p>This is how we can start up our first microVM. I usually start it in screen so I can open a new session easily because it will use the standard input and output for the newly started of console (unless you redirect it).</p><p>This is for debug mode, starting with sudo:</p><div><pre><code data-lang="bash">sudo ./firectl/firectl <span>\
</span><span></span>--firecracker-binary<span>=</span>./firecracker <span>\
</span><span></span>--kernel<span>=</span>vmlinux.bin <span>\
</span><span></span>--tap-device<span>=</span>tap0/aa:fc:00:00:00:01 <span>\
</span><span></span>--kernel-opts<span>=</span><span>\
</span><span></span><span>"console=ttyS0 reboot=k panic=1 pci=off \
</span><span>ip=172.16.0.42::172.16.0.1:255.255.255.0::eth0:off"</span> <span>\
</span><span></span>--root-drive<span>=</span>./xenial.rootfs.ext4
</code></pre></div><p>If everything went well you can see something like this:</p><pre><code>Ubuntu 18.04.2 LTS fadfdd4af58a ttyS0

fadfdd4af58a login:
</code></pre><p>User and password is root:root.</p><h3 id="testing-networking">Testing networking</h3><p>For this we need to have a bit bigger image.</p><div><pre><code data-lang="bash">dd <span>if</span><span>=</span>/dev/zero <span>bs</span><span>=</span>1M <span>count</span><span>=</span><span>800</span> &gt;&gt; xenial.rootfs.ext4
resize2fs -f xenial.rootfs.ext4
</code></pre></div><p>After starting up the usual way and logging in we need to fix few things:</p><p>Adding some working nameserver:</p><div><pre><code data-lang="bash"><span>echo</span> <span>'nameserver 1.1.1.1'</span> &gt;  /etc/resolv.conf
</code></pre></div><p>Now trying to update:</p><div><pre><code data-lang="bash">root@fadfdd4af58a:~# apt update
Get:1 http://ports.ubuntu.com/ubuntu-ports bionic InRelease <span>[</span><span>242</span> kB<span>]</span>
Get:2 http://ports.ubuntu.com/ubuntu-ports bionic-updates InRelease <span>[</span>88.7 kB<span>]</span>
Hit:3 http://ports.ubuntu.com/ubuntu-ports bionic-backports InRelease
Hit:4 http://ports.ubuntu.com/ubuntu-ports bionic-security InRelease
Get:5 http://ports.ubuntu.com/ubuntu-ports bionic/universe arm64 Packages <span>[</span>11.0 MB<span>]</span>
Get:6 http://ports.ubuntu.com/ubuntu-ports bionic/multiverse arm64 Packages <span>[</span><span>153</span> kB<span>]</span>
Get:7 http://ports.ubuntu.com/ubuntu-ports bionic/main arm64 Packages <span>[</span><span>1285</span> kB<span>]</span>
Get:8 http://ports.ubuntu.com/ubuntu-ports bionic/restricted arm64 Packages <span>[</span><span>572</span> B<span>]</span>
Get:9 http://ports.ubuntu.com/ubuntu-ports bionic-updates/universe arm64 Packages <span>[</span><span>1865</span> kB<span>]</span>
Get:10 http://ports.ubuntu.com/ubuntu-ports bionic-updates/restricted arm64 Packages <span>[</span><span>2262</span> B<span>]</span>
Get:11 http://ports.ubuntu.com/ubuntu-ports bionic-updates/main arm64 Packages <span>[</span><span>1431</span> kB<span>]</span>
Get:12 http://ports.ubuntu.com/ubuntu-ports bionic-updates/multiverse arm64 Packages <span>[</span><span>5758</span> B<span>]</span>
Fetched 16.1 MB in 6s <span>(</span><span>2543</span> kB/s<span>)</span>
Reading package lists... Error!
E: flAbsPath on /var/lib/dpkg/status failed - realpath <span>(</span>2: No such file or directory<span>)</span>
E: Could not open file  - open <span>(</span>2: No such file or directory<span>)</span>
E: Problem opening
E: The package lists or status file could not be parsed or opened.
</code></pre></div><p>Fixing the apt issues:</p><div><pre><code data-lang="bash">mkdir -p /var/lib/dpkg/<span>{</span>info,alternatives<span>}</span>
touch /var/lib/dpkg/status
apt install apt-utils -y
</code></pre></div><p>Enjoy!</p><p>Next time we can go through how to compile a new kernel and have a different rootfs (potentially using Alpine).</p></div></div>]]>
            </description>
            <link>https://dev.l1x.be/posts/2020/11/22/getting-started-with-firecracker-on-raspberry-pi/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25187965</guid>
            <pubDate>Mon, 23 Nov 2020 15:48:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Somfy blinds automated via MQTT and Home Assistant]]>
            </title>
            <description>
<![CDATA[
Score 30 | Comments 3 (<a href="https://news.ycombinator.com/item?id=25187945">thread link</a>) | @ggambetta
<br/>
November 23, 2020 | https://mwitkow.me/posts/2020-11-08_somfy/ | <a href="https://web.archive.org/web/*/https://mwitkow.me/posts/2020-11-08_somfy/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>In this post I‚Äôll show you how to use a Raspberry Pi and some soldering skills to automate old Somfy blinds via the MQTT protocol exposed to Home Assistant and Google Home.</p><p>We‚Äôve moved to a new apartment and one of its features are external blinds (a.k.a. covers) that are controlled through a dedicated remote of the Somfy brand. However, just like with a TV, finding the remote is often tricky, so I decided to try and automate the external blind movements through Home Assistant and further voice commands of Google Home.</p><p>The system in place is a Somfy‚Äôs Telis 4 RTS Pure remote, with two remotes, each being able to program 5 channels (4 individual ones and combined). The system uses a legacy, proprietary radio protocol called <a href="https://service.somfy.com/downloads/nam_v4/rts_pocket_guide_dec_2017.pdf">RTS</a>, which only Somfy and Telis use.</p><p>Somfy offers a RTS bridge called <a href="https://www.somfysystems.com/en-us/products/1811403/mylink">Somfy MyLink</a> for a wooping ~300CHF, which is a little steep for something that is not necessary and just scratching an itch. Also, there‚Äôs not much fun in that.</p><p>Turns out, <a href="https://github.com/Nickduino/">Nickduino</a> had a similar itch to scratch. Using 3-4 CHF-worth of hardware components, it is quite easy to build a software radio that will immitate a Somfy Telis remote and control the blinds.</p><p>There‚Äôs an bare-bones <a href="https://github.com/Nickduino/Somfy_Remote/blob/master/Somfy_Remote.ino">Somfy Remote Arduino sketch</a> that shows how the protocol works. I originally wanted make the blind controller as small as possible and base it on an <a href="https://en.wikipedia.org/wiki/ESP32">ESP32</a>, taking that sketch and controlling it via <a href="https://github.com/256dpi/arduino-mqtt">arduino-mqtt</a>.</p><p>Turns out there is a full MQTT/web interface script <a href="https://github.com/Nickduino/Pi-Somfy">Nickduino/Pi-Somfy</a> that also only goes into the details of how to solder things, and connect things onto a Raspberry Pi. Laziness won the day, especially as I wanted to use my spare Pi for something anyway.</p><h2 id="the-hardware">The hardware</h2><p>Usually for 433MHz signals you could easily use a ready-made module such us <a href="https://www.berrybase.ch/raspberry-pi-co/raspberry-pi/module-sensoren/433mhz-sender-empf-228-nger-superregeneration-modul-fs1000a-xy-fst-xy-mk-5v">this 2CHF sender-receiver pair</a>. However, in order for Somfy to make their RTS even more proprietary than it already was, it is not using the typical <code>433.93MHz</code> frequency but <code>433.42MHz</code> ü§¶‚Äç‚ôÇÔ∏è. This means one will need to do some soldering.</p><p>The PiSomfy <a href="https://github.com/Nickduino/Pi-Somfy#2-hardware">hardware guide</a> is excellent in telling you what you need. I got:</p><ul><li><a href="https://www.ebay.com/itm/5x-433Mhz-RF-transmitter-and-receiver-kit-Module-Arduino-ARM-WL-MCU-Raspberry-Fc-/254607185239?hash=item3b47c55557">5 ready <code>433.93MHz</code> sender circuits</a></li><li><a href="https://www.ebay.com/itm/10pcs-433-42m-433-42mhz-r433-f433-saw-resonator-crystals-to-39-/331637441887?hash=item4d3721c55f">10 pieces of the <code>433.42MHz</code> oscilator</a> - because my soldering is terrible</li><li><a href="https://www.ebay.com/itm/40PCS-20cm-2-54MM-FF-FM-MM-Dupont-wire-jumper-cables-male-to-female-For-Arduino/312724733910?hash=item48cfd8bfd6:g:05sAAOSwlbZdSZ6E">male-male jumper cables</a> - to avoid soldering üòâ</li><li>(already had it) a solid copper cable to use as an antenna</li></ul><p>After 4 weeks, all the eBay items were in place, and I could start soldering. Turns out de-soldering things off is much harder than soldering things on. I managed to peel away the original oscillator with by applying leverage underneath it using a swiss army knife and heating its connectors one by one. Soldering the new one was quite easy in comparison.</p><figure><img src="https://mwitkow.me/posts/2020-11-08_somfy/soldering.jpg" alt="It&amp;rsquo;s not pretty but it worked." width="600"><figcaption><p>It‚Äôs not pretty but it worked.</p></figcaption></figure><p>I then took a 17cm piece of solid copper cable, and wrapped it into a small coil. Turns out soldering a think 1mm cable to a tiny connector was the trickiest bit, but with the right amount of patience, things will stick eventually.</p><p>Eventually, the fully connected sender fits nicely into a Raspberry Pi enclosure after connecting everything to the GPIO 4 pin:</p><figure><img src="https://mwitkow.me/posts/2020-11-08_somfy/final_side_by_side.jpg" alt="All fits nicely into a standard Pi enclosure. The remote we&amp;rsquo;ll be replacing are on the left." width="700"><figcaption><p>All fits nicely into a standard Pi enclosure. The remote we‚Äôll be replacing are on the left.</p></figcaption></figure><h2 id="programming">Programming</h2><p>Installing Pi-Somfy is super easy, just follow <a href="https://github.com/Nickduino/Pi-Somfy#3-software">these steps</a>. It assume you install it under the default <code>pi</code> user in <code>/home/pi</code>, and comes with a handy <code>systemctl</code> service for auto-starting the system.</p><p>By default it will come up on port <code>:80</code> of your Pi. Programming the blinds takes a little bit of time. The procedure is as follows:</p><ul><li>Set the right channel (individual blind, or all) on the remote you‚Äôre programming from.</li><li>Measure the time in seconds it takes for each blind to come fully down.</li><li>Click <em>Add new</em> to put in the name (this will be your MQTT name by the way) and add in the time.</li><li>Using a pen, press the ‚Äúhole‚Äù on the other side of the remote. This sends the signal to the blind to accept programming a new remote.</li><li>Press <em>Save</em> and follow the instructions. The blind should ‚Äúwiggle‚Äù once programmed.</li></ul><p><strong>Note</strong>: The system relies on time to figure out where the blind is percentage-wise. It can often get things wrong (e.g. if you stopped it mid-through), or on the all-channel if blinds have different lengths (e.g. balcony). But in practice it works remarkably well.</p><figure><img src="https://mwitkow.me/posts/2020-11-08_somfy/pi_remote.png" alt="Fully programmed blinds." width="700"><figcaption><p>Fully programmed blinds.</p></figcaption></figure><p><a href="https://en.wikipedia.org/wiki/MQTT">MQTT</a> is a standard protocol for message brokers, and finds a lot of use in home IoT. For most use cases, it has a simple publish-subscribe mechanic based on topics.</p><h2 id="installing-mosquitto">Installing Mosquitto</h2><p>Home Assistant has an embedded MQTT broker, but it is <em>highly advised</em> to use an external one, such as Mosquitto. You should install it on the same machine that runs Home Assistant, as it will act as a hub for other MQTT-connected services. To do that on Ubuntu:</p><div><pre><code data-lang="bash">sudo apt-get update
sudo apt-get install mosquitto mosquitto-clients
</code></pre></div><p>Now let‚Äôs set up a password file in <code>/etc/mosquitto/passwd</code> with a user for <code>homeassistant</code> and <code>pisomfy</code>.</p><pre><code>sudo mosquitto_passwd -c /etc/mosquitto/passwd homeassistant
Password: YourHomeAssistantPassword
sudo mosquitto_passwd -c /etc/mosquitto/passwd pisomfy
Password: YourPiSomfyPassword
</code></pre><p>Then, enforce use of passwords in mosquitto by editing <code>/etc/mosquitto/conf.d/default.conf</code> and changing it to:</p><pre><code>allow_anonymous false
password_file /etc/mosquitto/passwd
</code></pre><p>For debugging purposes, open a separate tab on the same machine and subscribe to all messages under the <code>home-assistant/#</code> topic via:</p><pre><code>mosquitto_sub -u homeassistant -P YourHomeAssistantPassword -p 1883 -h 127.0.0.1 -v -t "home-assistant/#"
</code></pre><p>This will come in handy to check things are working.</p><h2 id="configuring-home-assistant">Configuring Home Assistant</h2><p>Update your <code>/etc/homeassistant/configuration.yaml</code> to add:</p><div><pre><code data-lang="yaml"><span>mqtt</span><span>:</span><span>
</span><span>  </span><span>broker</span><span>:</span><span> </span><span>127.0.0.1</span><span>
</span><span>  </span><span>username</span><span>:</span><span> </span><span>homeassistant</span><span>
</span><span>  </span><span>password</span><span>:</span><span> </span><span>"YourHomeAssistantPassword"</span><span>
</span><span>  </span><span>discovery</span><span>:</span><span> </span><span>true</span><span>
</span></code></pre></div><p>Restart Home Assistant</p><pre><code>sudo systemctl restart homeassistant
</code></pre><h3 id="configure-pisomfy">Configure PiSomfy</h3><p>On your Pi machine, open <code>/home/pi/operateShutters.conf</code> and edit the `[MQTT] section to look as follows</p><div><pre><code data-lang="ini"><span>[MQTT]</span>
<span># Location (IP Address of DNS Name) of the MQTT Server</span>
<span>MQTT_Server</span> <span>=</span> <span>myHAmachine # or hostname of your home assistant machine</span>
<span># Port of the MQTT Server</span>
<span>MQTT_Port</span> <span>=</span> <span>1883</span>
<span># Username for the MQTT Server</span>
<span>MQTT_User</span> <span>=</span> <span>pisomfy</span>
<span># Password of the MQTT Server</span>
<span>MQTT_Password</span> <span>=</span> <span>YourPiSomfyPassword</span>
<span># Enable auto discovery</span>
<span>EnableDiscovery</span> <span>=</span> <span>true</span>
</code></pre></div><p>And restart the service:</p><pre><code>sudo systemctl restart shutters.conf`
</code></pre><p>At this point the tab with the subscriptions should be full of messages. These are auto-discovery messages over MQTT for each of the programmed covers. This will cause Home Assistant to automatically add the entities.</p><p>They should show up with the same names as in PiSomfy.</p><figure><img src="https://mwitkow.me/posts/2020-11-08_somfy/home_assistant_entities.png" alt="Home Assistant Entities auto discovered via MQTT." width="800"><figcaption><p>Home Assistant Entities auto discovered via MQTT.</p></figcaption></figure><p>Adding them to a dashboard is relatively trivial, for example:</p><div><pre><code data-lang="yaml"><span>type</span><span>:</span><span> </span><span>entities</span><span>
</span><span></span><span>entities</span><span>:</span><span>
</span><span>  </span>- <span>entity</span><span>:</span><span> </span><span>cover.lr_all</span><span>
</span><span>    </span><span>name</span><span>:</span><span> </span><span>Living Room Covers</span><span>
</span></code></pre></div><p>In order to simplify things, I wanted to only expose the <code>_all</code> blinds (a.k.a. covers) to Google Home/Assistant. For that I added an explicit section in the <code>/etc/homeassistant/configuration.yaml</code> section of <code>google_assistant</code>:</p><div><pre><code data-lang="yaml"><span>google_assistant</span><span>:</span><span>
</span><span>  </span><span># ...</span><span>
</span><span>  </span><span>exposed_domains</span><span>:</span><span>
</span><span>    </span>- <span>fan</span><span>
</span><span>  </span><span>entity_config</span><span>:</span><span>
</span><span>    </span><span>cover.br_all</span><span>:</span><span>
</span><span>      </span><span>expose</span><span>:</span><span> </span><span>true</span><span>
</span><span>      </span><span>aliases</span><span>:</span><span>
</span><span>        </span>- <span>"Bedroom Covers"</span><span>
</span><span>    </span><span>cover.lr_all</span><span>:</span><span>
</span><span>      </span><span>expose</span><span>:</span><span> </span><span>true</span><span>
</span><span>      </span><span>aliases</span><span>:</span><span>
</span><span>        </span>- <span>"Living Room Covers"</span><span>
</span></code></pre></div><p>After restarting Home Assistant, and uttering the magical <em>Ok Google, Sync All Devices</em>, the covers will show up in your Home App:</p><figure><img src="https://mwitkow.me/posts/2020-11-08_somfy/google_home.jpg" alt="Looks like a blind, acts as a blind." width="300"><figcaption><p>Looks like a blind, acts as a blind.</p></figcaption></figure><p>This means you can controll it using keywords:</p><ul><li><em>Ok Google, close Bedroom covers</em></li><li><em>Ok Google, open Bedroom covers</em></li><li><em>Ok Google, set Bedroom covers to 50%</em></li></ul><p>The killer feature is setting this up as a routine to open/close the blind as you wake up, go to sleep.</p><p>Happy hacking :)</p></div></div>]]>
            </description>
            <link>https://mwitkow.me/posts/2020-11-08_somfy/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25187945</guid>
            <pubDate>Mon, 23 Nov 2020 15:46:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Django refactoring game ‚Äì can you fix all the Models anti-patterns?]]>
            </title>
            <description>
<![CDATA[
Score 79 | Comments 53 (<a href="https://news.ycombinator.com/item?id=25187507">thread link</a>) | @rikatee
<br/>
November 23, 2020 | https://django.doctor/challenge | <a href="https://web.archive.org/web/*/https://django.doctor/challenge">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://django.doctor/challenge</link>
            <guid isPermaLink="false">hacker-news-small-sites-25187507</guid>
            <pubDate>Mon, 23 Nov 2020 15:11:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Tech Stack of a One-Man SaaS]]>
            </title>
            <description>
<![CDATA[
Score 432 | Comments 235 (<a href="https://news.ycombinator.com/item?id=25186342">thread link</a>) | @amzans
<br/>
November 23, 2020 | https://panelbear.com/blog/tech-stack/ | <a href="https://web.archive.org/web/*/https://panelbear.com/blog/tech-stack/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p>Being an engineer at heart, each time I see a company write about their tech stack, I brew a fresh cup of coffee, sit back and enjoy reading the newfound little treat.</p><p>There‚Äôs just something fascinating about getting to know what‚Äôs under the hood of other people‚Äôs businesses. It‚Äôs like gossip, but about software.</p><p>A couple of months ago I started working on <a href="https://panelbear.com/blog/why-panelbear/" target="_blank" rel="noopener">yet another private analytics service</a>, a project which has gone through numerous iterations, and I feel lucky that 400+ websites have already integrated with it, even though it's still in the early stages.</p><p>That‚Äôs why, in the same spirit as Jake Lazaroff‚Äôs <a href="https://jake.nyc/words/tools-and-services-i-use-to-run-my-saas/" target="_blank" rel="noopener">Tools and Services I Use to Run My SaaS</a>, I thought it‚Äôs now my turn to do a short write up of the technologies I‚Äôm using to run this new service.</p><h2>Languages</h2><p>Over the years I have added many programming languages to my toolbelt, but for solo projects I have converged to two in particular that strike a good balance of productivity and reliability.</p><ul><li><p><a href="https://python.org/" target="_blank" rel="noopener">Python</a>: Most of the backend code is in Python. Which has enabled me to ship features incredibly fast. Additionally, I use <a href="http://mypy-lang.org/" target="_blank" rel="noopener">mypy</a> for optional type hints, which helps keep the codebase manageable.</p></li><li><p><a href="https://www.typescriptlang.org/" target="_blank" rel="noopener">Typescript</a>: I used to avoid working on the frontend as much as I could. That is until I discovered Typescript about 4 years ago. It just makes the whole experience a lot better, and I now use it for all my projects together with React.</p></li></ul><h2>Frameworks and libraries</h2><p>This list could have been huge, as I stand on the shoulders of giants who have published the vast amount of open-source code which I rely on. But I'd like to highlight only a handful due to their major role in the stack:</p><ul><li><a href="https://www.djangoproject.com/" target="_blank" rel="noopener">Django</a>: It's like a superpower for solo developers. The longer you work in this industry, the more you appreciate not having to reinvent the wheel for the 100th time. A monolithic framework can get you <a href="https://instagram-engineering.com/web-service-efficiency-at-instagram-with-python-4976d078e366" target="_blank" rel="noopener">really</a>, <a href="https://github.com/getsentry/sentry" target="_blank" rel="noopener">really</a> <a href="https://djangostars.com/blog/10-popular-sites-made-on-django/" target="_blank" rel="noopener">far</a>. To me, it's about predictable software that's fast in every way that matters. In case you're interested, I talk more about this topic on <a href="https://panelbear.com/blog/boring-tech/" target="_blank" rel="noopener">Choose Boring Technology</a>.</li><li><a href="https://reactjs.org/" target="_blank" rel="noopener">React</a>: The web app for the dashboards is built using React + Webpack. After using Angular for a long time, I switched to React because it's just a pluggable view layer that doesn't get in the way. I use the fantastic <a href="https://github.com/Frojd/django-react-templatetags" target="_blank" rel="noopener">django-react-templatetags</a> to embed the React components in my Django templates.</li><li><a href="https://nextjs.org/" target="_blank" rel="noopener">NextJS</a>: I use it for the landing pages, documentation and the blog which you are currently reading. It enables me to re-use various React components, and still reap the performance and SEO benefits of a statically generated site.</li><li><a href="https://docs.celeryproject.org/" target="_blank" rel="noopener">Celery</a>: I use it for any kind of background/scheduled tasks. It does have a learning curve for more advanced use-cases, but it's quite reliable once you understand how it works, and more importantly when it fails.</li><li><a href="https://getbootstrap.com/" target="_blank" rel="noopener">Bootstrap 4</a>: I built a custom theme on top of Bootstrap. It has saved me a lot of time, and there's lots of documentation around it. That's why I picked it.</li></ul><h2>Databases</h2><p>I originally stored all data in a single SQLite database, doing backups meant making a copy of this file to an object storage like S3. At the time, it was more than enough for the small sites I tested Panelbear with. But as I added more features and websites, I needed more specialized software to support those features:</p><ul><li><a href="https://clickhouse.tech/" target="_blank" rel="noopener">Clickhouse</a>: I believe this is one of those technologies that over time will become ubiquitous. It's honestly a fantastic piece of software that enabled me to build features that initially seemed impossible on low-cost hardware. I do intend to write a future blog post on some lessons learned from running Clickhouse on Kubernetes. So stay tuned!</li><li><a href="https://www.postgresql.org/" target="_blank" rel="noopener">PostgreSQL</a>: My go-to relational database. Sane defaults, battle-tested, and deeply integrated with Django. For Panelbear, I use it for all application data that is not analytics related. For the analytics data, I instead wrote a simple interface for querying Clickhouse within Django.</li><li><a href="https://redis.io/" target="_blank" rel="noopener">Redis</a>: I use it for many things: caching, rate-limiting, as a task queue, and as a key/value store with TTL for various features. Rock-solid, and great documentation.</li></ul><h2>Deployment</h2><p>I treat my infrastructure as <a href="https://joachim8675309.medium.com/devops-concepts-pets-vs-cattle-2380b5aab313" target="_blank" rel="noopener">cattle instead of pets</a>, things like servers and clusters are meant to come and go. So if one server gets "sick", I just replace it with another one. That means everything is described as code in a git repo, and I do not change things by SSH'ing into the servers. You can think of it like a template to clone my entire infrastructure with one command into any AWS region/environment.</p><p>This also helps me in case of disaster recovery. I just run a few commands, and some minutes later my stack has been re-created. This was particularly useful when I moved from DigitalOcean, to Linode, and recently to AWS. Everything is described in code, so it's easy to keep track of what components I own, even years later (all companies have some AWS IAM policy or VPC subnet lurking around which was created via clicky-clicky on the UI, and now everyone depends on it).</p><ul><li><a href="https://www.terraform.io/" target="_blank" rel="noopener">Terraform</a>: I manage most of my cloud infrastructure with Terraform. Things like EKS clusters, S3 buckets, roles, and RDS instances are declared in my Terraform manifests. The state is synced to an encrypted S3 bucket to avoid getting in trouble in case something happens to my development laptop.</li><li><a href="https://www.docker.com/" target="_blank" rel="noopener">Docker</a>: I build everything as Docker images. Even stateful components like Clickhouse or Redis are packaged and shipped as Docker containers to my cluster. It also makes my stack very portable, as I can run it anywhere I can run Docker.</li><li><a href="https://kubernetes.io/" target="_blank" rel="noopener">Kubernetes</a>: Allowed me to simplify the operational aspects tremendously. However, I wouldn‚Äôt bindly recommend it to everyone, as I already felt comfortable working with it after having the pleasure of putting down multiple production fires for my employer over the years. I also rely on managed offerings, which helps reduce the burden too.</li><li><a href="https://github.com/features/actions" target="_blank" rel="noopener">GitHub Actions</a>: Normally I‚Äôd use <a href="https://circleci.com/" target="_blank" rel="noopener">CircleCI</a> in the past (which is also great), but for this project I prefer to use GitHub Actions as it removes yet another service which needs to have access to my repositories, and deployment secrets. However, CircleCI has plenty of good features, and I still recommend it.</li></ul><h2>Infrastructure</h2><p>I started in a single $5/mo instance in DigitalOcean, then moved to the managed Kubernetes offering as I was reinventing the wheel for a lot of things Kubernetes already gives me out of the box (service discovery, TLS certs, load balancing, log rotation, rollout, scaling, fault-tolerance, among others).</p><p>Unfortunately, I had <a href="https://www.digitalocean.com/community/questions/kubernetes-unable-to-connect-to-the-server" target="_blank" rel="noopener">reliability issues</a> with DigitalOcean's Kubernetes offering, even on larger instances. The cluster API would often go down randomly and no longer recover, this disrupted a lot of cluster services including the load balancer, which translated into downtime for me. I had to create a new cluster each time this happened, and while Terraform made it trivial, this was not something that inspired a lot of confidence about their managed service. I suspect their control plane was underprovisioned, which would be kind of understandable given the price tag.</p><p>Unfortunately I was not able to resolve the issue after several weeks. That's why I decided to move to <a href="https://www.linode.com/" target="_blank" rel="noopener">Linode</a>, and had exactly 0 problems during the 1.5 month-long honeymoon that followed.</p><p>However, I recently moved once again, this time to AWS due to a pretty good deal I received. It also enabled me to use managed services like RDS to offload managing PostgreSQL, which is a big plus. What made all these migrations relatively easy, was that all my infrastructure was described via Terraform and Kubernetes manifests. The migrations essentially consisted of an evening, some tea, and patience. But that's for another post.</p><ul><li><a href="https://aws.amazon.com/" target="_blank" rel="noopener">AWS</a>: Predictable, and lots of managed services. However, I use it at my full-time job, so I didn't have to spend too much time figuring things out. The main services I use are EKS, ELB, S3, RDS, IAM and private VPCs. I might also add Cloudfront and Kinesis in the future.</li><li><a href="https://www.cloudflare.com/" target="_blank" rel="noopener">Cloudflare</a>: I mainly use it for DDoS protection, serving DNS, and offloading edge caching of various static assets (currently shaves off 80% of the egress charges from AWS - their bandwidth pricing is insane!).</li><li><a href="https://letsencrypt.org/" target="_blank" rel="noopener">Let‚Äôs Encrypt</a>: Free SSL certificate authority. I use cert-manager in my Kubernetes cluster to automatically issue and renew certificates based on my ingress rules.</li><li><a href="https://www.namecheap.com/" target="_blank" rel="noopener">Namecheap</a>: My domain name registrar of choice. Allows MFA for login which is an important security feature. Unlike other registrars, they haven't surprised me with an expensive renewal every few years. I like them.</li></ul><h2>Kubernetes components</h2><p>The following components automate most of the devops work for me. I use several others too, but some of the main ones I use are:</p><ul><li><a href="https://github.com/kubernetes/ingress-nginx/" target="_blank" rel="noopener">ingress-nginx</a>: Rock-solid ingress controller for Kubernetes using NGINX as a reverse proxy, and load balancer. Sits behind the NLB which controls ingress to the cluster nodes.</li><li><a href="https://github.com/jetstack/cert-manager" target="_blank" rel="noopener">cert-manager</a>: Automatically issue/renew TLS certs as defined in my ingress rules.</li><li><a href="https://github.com/kubernetes-sigs/external-dns" target="_blank" rel="noopener">external-dns</a>: Synchronizes exposed Kubernetes Services and Ingresses with DNS providers (such as Cloudflare).</li><li><a href="https://github.com/prometheus-operator/prometheus-operator" target="_blank" rel="noopener">prometheus-operator</a>: Automatically monitors most of my services, and exposes dashboards via Grafana.</li><li><a href="https://fluxcd.io/" target="_blank" rel="noopener">flux</a>: GitOps way to do continuous delivery in Kubernetes. Basically pulls and deploys new Docker images when I release them.</li></ul><h2>CLI tools</h2><p>There‚Äôs plenty here, but frequently used include:</p><ul><li><a href="https://kubernetes.io/" target="_blank" rel="noopener">kubectl</a>: To interact with the Kubernetes cluster to watch logs, pods and services, SSH into a running container, and so on.</li><li><a href="https://github.com/wercker/stern" target="_blank" rel="noopener">stern</a>: Multi pod log tailing for Kubernetes. Really handy.</li><li><a href="https://htop.dev/" target="_blank" rel="noopener">htop</a>: Interactive system process viewer. Better than ‚Äútop‚Äù if you ask me.</li><li><a href="https://curl.se/" target="_blank" rel="noopener">cURL</a>: Issue HTTP requests locally, inspect headers.</li><li><a href="https://httpie.io/" target="_blank" rel="noopener">HTTPie</a>: Like cURL, but simpler for JSON APIs.</li><li><a href="https://github.com/rakyll/hey" target="_blank" rel="noopener">hey</a>: Load testing HTTP endpoints. Gives a nice latency distribution summary.</li></ul><h2>Monitoring</h2><ul><li><a href="https://prometheus.io/" target="_blank" rel="noopener">Prometheus</a>: Efficient storage of time series data for monitoring. Tracks all the cluster and app metrics. It was a lot cheaper than using Cloudwatch for app metrics.</li><li><a href="https://grafana.com/" target="_blank" rel="noopener">Grafana</a>: Nice dashboards for the Prometheus monitoring data. All dashboards are described in JSON files and versioned in the ‚Ä¶</li></ul></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://panelbear.com/blog/tech-stack/">https://panelbear.com/blog/tech-stack/</a></em></p>]]>
            </description>
            <link>https://panelbear.com/blog/tech-stack/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25186342</guid>
            <pubDate>Mon, 23 Nov 2020 13:06:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Use Netlify Functions and the Twitter API v2 as a CMS for Your Gatsby Blog]]>
            </title>
            <description>
<![CDATA[
Score 54 | Comments 21 (<a href="https://news.ycombinator.com/item?id=25186006">thread link</a>) | @pauliescanlon
<br/>
November 23, 2020 | https://paulie.dev/posts/2020/11/gatsby-netlify-twitter/ | <a href="https://web.archive.org/web/*/https://paulie.dev/posts/2020/11/gatsby-netlify-twitter/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><img src="https://res.cloudinary.com/www-paulie-dev/image/upload/v1605613346/paulie.dev/2020/11/gatsby-netlify-twitterjpg_ok1k0q.jpg"></p><div><div><div><p>Date published: </p><!-- --><p>17-Nov-2020</p></div></div></div><hr><p>JavaScript</p><p>React</p><p>Gatsby</p><p>Netlify Functions</p><p>Twitter API v2</p><hr><p>Apologies in advance for the rather long-winded blog title but as it suggests in this post i'm going to explain how you can use <a href="https://www.netlify.com/products/functions/">Netlify Functions</a> to access your Twitter profile data using the <a href="https://developer.twitter.com/en/docs/twitter-api/early-access">Twitter v2 API</a> and display it on your Gatsby blog.</p><h2>A rather unique requirement</h2><p>This might be a specific to me but I wanted to solve a little problem I was having with my "digital footprint". As you can see I have this blog: <a href="https://paulie.dev/">https://paulie.dev</a> and a commercial portfolio: <a href="https://www.pauliescanlon.io/">https://www.pauliescanlon.io</a></p><p>Both sites are built on top of my Gatsby theme: <a href="https://gatsby-theme-terminal.netlify.app/">gatsby-theme-terminal</a> which is Open source and can be found on my <a href="https://github.com/PaulieScanlon/gatsby-theme-terminal">GitHub</a></p><p>Using a Gatsby Theme solves one of my issues as I'm able to have two sites that look and work pretty much the same way and any changes I make to the theme are inherited by both my sites. It's kind of like managing your own multi brand design system, but just for yourself.</p><p>There was one other problem though. ü§î</p><p>I wanted both sites to have the same "intro" section, but every time I made a change to one I had to make the same change to the other site to ensure they were both displaying the same intro text.</p><p>This might be fine if I weren't a developer but doing something twice is one time too many IMO.</p><p>It was also a little frustrating because I also wanted my Twitter profile description to be in sync with both the sites so, again another place to remember to update my personal blurb.</p><p>One option I considered would have been to hook up a Content Management System, and this would have been fine and it would have kept both my sites in sync but it wouldn't have been able to update my Twitter profile blurb...</p><p>So, I've decided to reverse engineer the Twitter API and use that as a CMS to populate both my sites. The idea is quite simple. I'll use the Twitter profile description as though it were a field from a CMS. Naturally any changes I make to this will appear on my Twitter profile and below is how I pull that same info into both of my sites.</p><h2>Demo</h2><p>Here's what I'll be showing you how to build:</p><ul><li>App / API <a href="https://gatsby-netlify-twitter.netlify.app/">https://gatsby-netlify-twitter.netlify.app</a></li><li>GitHub repo <a href="https://github.com/PaulieScanlon/gatsby-netlify-twitter">https://github.com/PaulieScanlon/gatsby-netlify-twitter</a></li></ul><p>... but the actual API I use for my blog and site is here: <a href="https://paulie-api.netlify.app/">https://paulie-api.netlify.app</a></p><h2>Tech</h2><h3>Netlify Functions</h3><p>"Power your site without managing servers" is how Netlify describe Functions and for all intents and purposes thats exactly what they are. Similar to how you might create an <a href="https://expressjs.com/">Express</a> app and deploy it somewhere but without the hassle of having to setup server side environments and more crucially any really dweeby server uptime monitoring.</p><h3>Twitter API v2</h3><p>A set of endpoints that can be used to get data from Twitter. Any Twitter requests must be done server side and use a set of keys and tokens. You can't unfortunately hit the Twitter API from the browser so we need a "server" or as mentioned above, a Netlify Function</p><p>Using both of the above i've made my own API endpoint which goes off and hits the Twitter API and returns my Profile information which I can then display in the intro section of my blog and site. I've deployed this API to Netlify and it's completely de-coupled from either of my sites but will return data which can be fetched from client side "fetch" request from within my site and blog. That url again is here: <a href="https://paulie-api.netlify.app/">https://paulie-api.netlify.app</a></p><h2>Before we start</h2><p>Before we get started there's a couple of things you'll need to have in place.</p><h3>Twitter API v2</h3><p>Apply for access to the <a href="https://developer.twitter.com/en/products/twitter-api">Twitter API</a>. This is quite a lengthy process so strap in and also bookmark this post as it might take a few days for Twitter to accept your application.</p><p>Once you have access you can head over to the <a href="https://developer.twitter.com/en/portal/dashboard">Developer Portal</a> and create a new project, and within the project you can create an "app", I called mine "paulie-api".</p><p>In here you'll find all the API keys and tokens required to access the Twitter API. Make a note of them somewhere as we'll be using them later.</p><h3>Netlify CLI</h3><p>To run Netlify Functions we'll be using <code>netlify dev</code> rather than <code>gatsby develop</code> or <code>yarn develop</code> so you'll need to install the <a href="https://docs.netlify.com/cli/get-started/">Netlify CLI</a></p><h2>The Build</h2><p>In order to develop you own API I found it easiest to have some kind of "site" running at the same time which will access the API endpoint and render the response on the page. In the demo repo you'll see i've set up a really simple Gatsby Site with one page that uses "fetch" to, er fetch and then render the data.</p><p>I've used <a href="https://theme-ui.com/home">Theme UI</a> for the style but naturally you can choose whatever you like to do this.</p><p>Whether you're starting from scratch or adding Netlify Functions to an existing project you'll need to start by adding a <code>functions</code> dir to the root of your project.</p><hr><pre><p><span>|</span><span>-- functions</span></p><p><span>  </span><span>|</span><span>-- package.json</span></p><p><span></span><span>|</span><span>-- src</span></p><p><span>package.json</span></p></pre><hr><p><code>functions</code> is kind of it's own application so it'll need it's own <code>package.json</code> and will have one dependency on <a href="https://github.com/HunterLarco/twitter-v2">twitter-v2</a></p><hr><pre><p><span></span><span>{</span><span></span></p><p><span>  </span><span>"name"</span><span>:</span><span> </span><span>"gatsby-netlify-twitter-api"</span><span>,</span><span></span></p><p><span>  </span><span>"version"</span><span>:</span><span> </span><span>"1.0.0"</span><span>,</span><span></span></p><p><span>  </span><span>"description"</span><span>:</span><span> </span><span>"An api for the Twitter v2 api"</span><span>,</span><span></span></p><p><span>  </span><span>"main"</span><span>:</span><span> </span><span>"index.js"</span><span>,</span><span></span></p><p><span>  </span><span>"scripts"</span><span>:</span><span> </span><span>{</span><span></span></p><p><span>    </span><span>"test"</span><span>:</span><span> </span><span>"echo \"Error: no test specified\" &amp;&amp; exit 1"</span><span></span></p><p><span>  </span><span>}</span><span>,</span><span></span></p><p><span>  </span><span>"keywords"</span><span>:</span><span> </span><span>[</span><span>]</span><span>,</span><span></span></p><p><span>  </span><span>"author"</span><span>:</span><span> </span><span>""</span><span>,</span><span></span></p><p><span>  </span><span>"license"</span><span>:</span><span> </span><span>"ISC"</span><span>,</span><span></span></p><p><span>  </span><span>"dependencies"</span><span>:</span><span> </span><span>{</span><span></span></p><p><span>    </span><span>"twitter-v2"</span><span>:</span><span> </span><span>"^0.1.2"</span><span></span></p><p><span>  </span><span>}</span><span></span></p><p><span></span><span>}</span></p></pre><hr><p>Next have a look at <a href="https://github.com/PaulieScanlon/gatsby-netlify-twitter/blob/main/.env.example">.env.example</a>. You'll need to create your own <code>.env</code> file and add the environment variables as seen in the <code>.env.example</code>. Naturally you'll want to change the <code>GATSBY_TWITTER_USERNAME</code> to your own Twitter username and the Twitter keys and tokens will be what I referenced earlier which are provided by the Twitter Developer Portal</p><hr><pre><p><span></span><span>GATSBY_API_URL</span><span>=</span><span>.</span><span>/</span><span>.</span><span>netlify</span><span>/</span><span>functions</span></p><p><span></span><span>GATSBY_TWITTER_USERNAME</span><span>=</span><span></span></p><p><span></span><span>TWITTER_API_KEY</span><span>=</span><span></span></p><p><span></span><span>TWITTER_API_KEY_SECRET</span><span>=</span><span></span></p><p><span></span><span>TWITTER_ACCESS_TOKEN</span><span>=</span><span></span></p><p><span></span><span>TWITTER_ACCESS_TOKEN_SECRET</span><span>=</span></p></pre><hr><p>Next create a Twitter client, this is what we'll use to pass the keys and tokens onto the Twitter API when we make a request</p><hr><pre><p><span></span><span>const</span><span> </span><span>Twitter</span><span> </span><span>=</span><span> </span><span>require</span><span>(</span><span>"twitter-v2"</span><span>)</span><span></span></p><p><span>module</span><span>.</span><span>exports</span><span> </span><span>=</span><span> </span><span>{</span><span></span></p><p><span>  client</span><span>:</span><span> </span><span>new</span><span> </span><span>Twitter</span><span>(</span><span>{</span><span></span></p><p><span>    consumer_key</span><span>:</span><span> process</span><span>.</span><span>env</span><span>.</span><span>TWITTER_CONSUMER_KEY</span><span>,</span><span></span></p><p><span>    consumer_secret</span><span>:</span><span> process</span><span>.</span><span>env</span><span>.</span><span>TWITTER_CONSUMER_KEY_SECRET</span><span>,</span><span></span></p><p><span>    access_token</span><span>:</span><span> process</span><span>.</span><span>env</span><span>.</span><span>TWITTER_ACCESS_TOKEN</span><span>,</span><span></span></p><p><span>    access_token_secret</span><span>:</span><span> process</span><span>.</span><span>env</span><span>.</span><span>TWITTER_ACCESS_TOKEN_SECRET</span><span>,</span><span></span></p><p><span>  </span><span>}</span><span>)</span><span>,</span><span></span></p><p><span></span><span>}</span></p></pre><hr><p>You should now be looking at something similar to the below</p><hr><pre><p><span>..</span><span>.</span></p><p><span></span><span>|</span><span>-- functions</span></p><p><span>  </span><span>|</span><span>-- client.js</span></p><p><span>  </span><span>|</span><span>-- package.json</span></p><p><span></span><span>|</span><span>-- src</span></p><p><span>package.json</span></p><p><span>.env</span></p><p><span></span><span>..</span><span>.</span></p></pre><hr><p>Now we need to create the "endpoint" that our frontend will hit, which in turn goes off and grabs the data from the Twitter API.</p><p>I created a dir called <code>twitter-user</code> and inside I create a new file and called it <code>twitter-user.js</code></p><hr><pre><p><span>..</span><span>.</span></p><p><span></span><span>|</span><span>-- functions</span></p><p><span>  </span><span>|</span><span>-- client.js</span></p><p><span>  </span><span>|</span><span>-- twitter-user</span></p><p><span>    </span><span>|</span><span>-- twitter-user.js</span></p><p><span>  </span><span>|</span><span>-- package.json</span></p><p><span></span><span>|</span><span>-- src</span></p><p><span>package.json</span></p><p><span>.env</span></p><p><span></span><span>..</span><span>.</span></p></pre><hr><p>It's in here where we can use the <code>client.js</code> to hit a Twitter API endpoint and pass with it the required keys and tokens from the <code>client</code></p><hr><pre><p><span></span><span>const</span><span> </span><span>{</span><span> client </span><span>}</span><span> </span><span>=</span><span> </span><span>require</span><span>(</span><span>"../client"</span><span>)</span><span></span></p><p><span>exports</span><span>.</span><span>handler</span><span> </span><span>=</span><span> </span><span>async</span><span> </span><span>(</span><span>event</span><span>,</span><span> context</span><span>,</span><span> callback</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>{</span><span></span></p><p><span>  </span><span>const</span><span> </span><span>{</span><span> data </span><span>}</span><span> </span><span>=</span><span> </span><span>await</span><span> client</span><span>.</span><span>get</span><span>(</span><span></span></p><p><span>    </span><span>`</span><span>users/by/username/</span><span>${</span><span>process</span><span>.</span><span>env</span><span>.</span><span>GATSBY_TWITTER_USERNAME</span><span>}</span><span>`</span><span>,</span><span></span></p><p><span>    </span><span>{</span><span></span></p><p><span>      user</span><span>:</span><span> </span><span>{</span><span></span></p><p><span>        fields</span><span>:</span><span></span></p><p><span>          </span><span>"created_at,description,entities,id,location,name,pinned_tweet_id,profile_image_url,protected,public_metrics,url,username,verified,withheld"</span><span>,</span><span></span></p><p><span>      </span><span>}</span><span>,</span><span></span></p><p><span>    </span><span>}</span><span></span></p><p><span>  </span><span>)</span><span></span></p><p><span>  </span><span>callback</span><span>(</span><span>null</span><span>,</span><span> </span><span>{</span><span></span></p><p><span>    headers</span><span>:</span><span> </span><span>{</span><span></span></p><p><span>      </span><span>"Access-Control-Allow-Origin"</span><span>:</span><span> </span><span>"*"</span><span>,</span><span></span></p><p><span>    </span><span>}</span><span>,</span><span></span></p><p><span>    statusCode</span><span>:</span><span> </span><span>200</span><span>,</span><span></span></p><p><span>    body</span><span>:</span><span> </span><span>JSON</span><span>.</span><span>stringify</span><span>(</span><span>{</span><span> user</span><span>:</span><span> data </span><span>}</span><span>)</span><span>,</span><span></span></p><p><span>  </span><span>}</span><span>)</span><span></span></p><p><span></span><span>}</span></p></pre><hr><p>In the above you can see we use our <code>client</code> to hit the <code>users/by/username</code> Twitter API endpoint which you can read more about <a href="https://developer.twitter.com/en/docs/twitter-api/users/lookup/introduction">here</a>, which returns a <code>data</code> object which I pass on to the callback body as <code>{ user: data }</code></p><p>This is the object that'll we receive in our frontend</p><p>The next bit will greatly depend on how you've set up your frontend but in the <a href="https://github.com/PaulieScanlon/gatsby-netlify-twitter/blob/main/src/pages/index.js">Demo</a> I have one <code>page</code> called <code>index.js</code> which uses a <code>useEffect</code> to "fetch" the data from the Netlify Function.</p><p>The example file contains a few extra bits for <code>isLoading</code> and <code>hasError</code> but the below should be enough to allow you hit to the Netlify Function which in turn hits the Twitter API and returns your profile information data.</p><hr><pre><p><span></span><span>import</span><span> </span><span>React</span><span>,</span><span> </span><span>{</span><span> useState </span><span>}</span><span> </span><span>from</span><span> </span><span>"react"</span><span></span></p><p><span></span><span>const</span><span> </span><span>IndexPage</span><span> </span><span>=</span><span> </span><span>(</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>{</span><span></span></p><p><span>  </span><span>const</span><span> </span><span>[</span><span>response</span><span>,</span><span> setResponse</span><span>]</span><span> </span><span>=</span><span> </span><span>useState</span><span>(</span><span>{</span><span> user</span><span>:</span><span> </span><span>null</span><span> </span><span>}</span><span>)</span><span></span></p><p><span>  </span><span>useEffect</span><span>(</span><span>(</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>{</span><span></span></p><p><span>    </span><span>fetch</span><span>(</span><span>`</span><span>${</span><span>process</span><span>.</span><span>env</span><span>.</span><span>GATSBY_API_URL</span><span>}</span><span>/twitter-user</span><span>`</span><span>)</span><span></span></p><p><span>      </span><span>.</span><span>then</span><span>(</span><span>(</span><span>response</span><span>)</span><span> </span><span>=&gt;</span><span> response</span><span>.</span><span>text</span><span>(</span><span>)</span><span>)</span><span></span></p><p><span>      </span><span>.</span><span>then</span><span>(</span><span>(</span><span>response</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>{</span><span></span></p><p><span>        </span><span>console</span><span>.</span><span>log</span><span>(</span><span>JSON</span><span>.</span><span>parse</span><span>(</span><span>response</span><span>)</span><span>)</span><span></span></p><p><span>        </span><span>setResponse</span><span>(</span><span>JSON</span><span>.</span><span>parse</span><span>(</span><span>response</span><span>)</span><span>)</span><span></span></p><p><span>      </span><span>}</span><span>)</span><span></span></p><p><span>      </span><span>.</span><span>catch</span><span>(</span><span>(</span><span>error</span><span>)</span><span> </span><span>=&gt;</span><span> </span><span>{</span><span></span></p><p><span>        </span><span>console</span><span>.</span><span>error</span><span>(</span><span>{</span><span> error </span><span>}</span><span>)</span><span></span></p><p><span>      </span><span>}</span><span>)</span><span></span></p><p><span>  </span><span>}</span><span>,</span><span> </span><span>[</span><span>]</span><span>)</span><span></span></p><p><span>  </span><span>const</span><span> </span><span>{</span><span> user </span><span>}</span><span> </span><span>=</span><span> response</span></p><p><span>  </span><span>return</span><span> </span><span>(</span><span></span></p><p><span>    </span><span>&lt;</span><span>pre</span><span>&gt;</span><span></span></p><p><span>      </span><span>&lt;</span><span>code</span><span>&gt;</span><span>{</span><span>JSON</span><span>.</span><span>stringify</span><span>(</span><span>user</span><span>,</span><span> </span><span>null</span><span>,</span><span> </span><span>2</span><span>)</span><span>}</span><span>&lt;</span><span>/</span><span>code</span><span>&gt;</span><span></span></p><p><span>    </span><span>&lt;</span><span>/</span><span>pre</span><span>&gt;</span><span></span></p><p><span>  </span><span>)</span><span></span></p><p><span></span><span>}</span><span></span></p><p><span></span><span>export</span><span> </span><span>default</span><span> </span><span>IndexPage</span></p></pre><hr><p><code>process.env.GATSBY_API_URL</code> is the path to the Netlify Function we added earlier to <code>.env</code> and i've hard-coded <code>/twitter-user</code> in the component / page as you might want to create different endpoints that return different data on different pages.</p><p>You might be wondering why this environment variable is prefixed with <code>GATSBY_</code>. This is so Gatsby can access it from the frontend. You can read more about Gatsby environment variables <a href="https://www.gatsbyjs.com/docs/environment-variables/#client-side-javascript">here</a></p><h3>IMPORTANT</h3><p>In order for Netlify Functions to work both locally and when deployed we need to ensure we've got <code>netlify-lambda</code> installed and have added both a <code>"start"</code> and <code>"postinstall"</code> script to the root <code>package.json</code> (not the <code>package.json</code> in <code>./functions</code>)</p><hr><pre><p><span>npm</span><span> </span><span>install</span><span> netlify-lambda --save -dev</span></p></pre><hr><pre><p><span>// ./package.json</span></p><p><span>...</span></p><p><span></span><span>  "scripts": {</span></p><p><span>    "develop": "gatsby develop",</span></p><p><span>    "build": "gatsby build",</span></p><p><span>    "clean": "gatsby clean",</span></p><p><span>    "serve": "gatsby serve",</span></p><p><span></span><span>+    "start": "npm run develop",</span></p><p><span>+    "postinstall": "netlify-lambda install"</span></p><p><span></span><span>  },</span></p><p><span>   "devDependencies": {</span></p><p><span></span><span>+   "netlify-lambda": "^1.6.3",</span></p><p><span></span><span>  }</span></p><p><span></span><span>...</span></p></pre><hr><p>Before we get too carried away, it's important to note that we'll no longer be using <code>gatsby develop</code> or <code>yarn develop</code> to start the Gatsby app, if you do that our Netlify Function won't be running and you'll get an error.</p><p>Instead, run <code>netlify dev</code> this is so both the Gatsby site and the Netlify Function are run at the same time.</p><p>Instead of visiting the usual <code>http://localhost:8000/</code> we'll now be visiting <code>http://localhost:8888/</code></p><p>And to ensure when we deploy everything works as it should you'll need to modify your <a href="https://github.com/PaulieScanlon/gatsby-netlify-twitter/blob/main/netlify.toml"><code>netlify.toml</code></a></p><p>For ‚Ä¶</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://paulie.dev/posts/2020/11/gatsby-netlify-twitter/">https://paulie.dev/posts/2020/11/gatsby-netlify-twitter/</a></em></p>]]>
            </description>
            <link>https://paulie.dev/posts/2020/11/gatsby-netlify-twitter/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25186006</guid>
            <pubDate>Mon, 23 Nov 2020 12:27:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Detective Game Design Problems]]>
            </title>
            <description>
<![CDATA[
Score 37 | Comments 11 (<a href="https://news.ycombinator.com/item?id=25185571">thread link</a>) | @jsnell
<br/>
November 23, 2020 | https://digitales.games/blog/detective-game-design-problems | <a href="https://web.archive.org/web/*/https://digitales.games/blog/detective-game-design-problems">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section id="blog">
            <div>
                <div>
					
                    <div>

                        <div>


    <div>

                    <p>Game design is such a wide and varied discipline that job titles in the field have become increasingly granular over the years ‚Äì and ever since we started working on our debut title Lacuna, I've become more and more convinced that "detective game designer" merits its own denomination as well. Detective gameplay (or "investigation gameplay") poses a number of unique challenges centered around two main problems: the <strong>struggle between story and puzzles</strong> (or "cases") as well as <strong>communication between the player and the game</strong>.</p>
<p>Since some of the explanations will be using our own game as an example, let me give you a quick rundown: Lacuna is a story-driven adventure with platformer controls and investigation elements. Its four fundamental gameplay types are dialogs (with choices), moving around, examining objects, and solving puzzles. All of them are staples of the point &amp; click genre, but their execution is quite unique; I don't want to go into more detail here because it's not pertinent to the topic, but you can <a href="http://lacuna.game/">check out the game on Steam</a> if you want to know more.</p>
<p><img alt="Gameplay" src="https://digitales.games/user/pages/03.blog/detective-game-design-problems/gameplay-movement.gif"><br>
<em>This is what the game looks like</em></p>
<h2>Story vs. puzzles</h2>
<p>A handful of abstract game design principles lie at Lacuna's core. For instance, "no takebacks" dictates that the player only get one shot at every decision, dialog, and puzzle. The game auto-saves and doesn't allow you to go back if you performed poorly or regret an earlier decision. There's also "limited feedback", which means that the player often isn't told immediately whether a solution was correct and what the consequences of their actions and decisions will be.</p>
<p>However, there's one in particular I want to highlight here because it concerns the above mentioned divide between story and puzzling in detective games: <strong>No getting stuck.</strong></p>
<p>The thought process behind it was simple: In games with both a story and puzzles (e.g. most P&amp;C games), story progress is almost always tied directly to puzzle progress. Until you solve the puzzle at hand, you don't get to see the next part of the story. For some players, especially those most interested in the story, this can become a problem. If they're stuck for too long, there's a chance they'll just drop out and never pick the game up again. Even if that doesn't happen, hard puzzles always run the risk of messing up the story's pacing and interrupting your immersion in the game ‚Äì because you're becoming frustrated or, even worse, because you decide to tab out and Google the solution. To avoid people getting stuck, we considered a number of solutions:</p>
<p><strong>Solution 1: Make the puzzles very easy?</strong><br>
This isn't our favorite since it somewhat defeats the purpose of puzzles. They'd still play a role as a change of pace now and then, but if puzzles aren't a little hard, nobody will feel like a detective solving them. Some early puzzles in Lacuna are easy, but most aren't.</p>
<p><strong>Solution 2: Provide hints?</strong><br>
Hint systems can be found in many adventures featuring puzzles. Unfortunately, they often take the player out of the experience in one of three ways: In some cases, the hint is provided by extradiegetic UI (e.g. in the pause menu) and therefore seems to come out of nowhere in the game world. In other cases, the player character is the one giving the hint, disconnecting the player from their avatar‚Äôs perspective. The third option of NPCs providing hints is a little better; however, it is often hard to justify <em>why</em> an NPC would be able to point the player in the right direction without possessing the rest of the solution to the ongoing puzzle (and why they didn't volunteer it in the first place). The two types of (sort-of) hint systems we went with in Lacuna are <em>Highlight Mode</em>, which displays optional outlines around objects and NPCs that hold new information, and <em>redundant information</em>, meaning that sometimes the player is given two ways of obtaining an important clue.</p>
<p><img alt="Hints" src="https://digitales.games/user/pages/03.blog/detective-game-design-problems/solutions-hints.png"><br>
<em>"YOU ARE PLAYING A GAME RIGHT NOW"</em></p>
<p><strong>Solution 3: Decouple story progress from puzzle progress?</strong><br>
Why not simply make a story-driven game throughout which the player can solve the occasional puzzle if they feel like it? Well, because it would require that puzzles be somewhat detached from the story. As a result, they run the risk of feeling meaningless since solving them is not rewarding and failing is not punishing. However, this <em>can</em> work quite well when combined with...</p>
<p><strong>Solution 4: Make branching content for different solutions?</strong><br>
Instead of impeding the player‚Äôs progress, wrong or missing puzzle solutions could lead to a less desirable continuation and/or outcome of the story. Unfortunately, creating a new story branch for each and every wrong solution to a puzzle is hardly feasible. However, there are less extreme ways of realizing this. For instance, the game could account for the player‚Äôs <em>overall</em> puzzling performance at certain points in the game, e.g. trigger the ‚Äúgood‚Äù finale to an act if they got more than x% of the puzzles right, and the ‚Äúbad‚Äù one if not. There could also be cascading consequences of sorts, e.g. solving one case correctly may give the player an edge in a later one. These approaches have similar downsides as optional puzzles do, but to a lesser degree; puzzle success no longer being required for progress makes them feel more detached from the story and removes immediate feedback. Regardless, we have found this to be the best solution, which is why we employ it quite a bit in Lacuna (while trying to avoid all the pitfalls). By the way, if all of this is becoming too abstract for you, bear with us! The second half of this post is all about a real example from the game.</p>
<p><img alt="Detroit: Become Human" src="https://digitales.games/user/pages/03.blog/detective-game-design-problems/solutions-branching-content.jpg"><br>
<em>Detroit: Become Human offers an astonishing number of different outcomes depending on player action, but not everybody has that kind of money to burn</em></p>
<p>Despite all of these measures being taken to make sure that the player won't get stuck, Lacuna can still be called a hard game. While it's not difficult to get <em>to</em> the end, it's pretty difficult to get a <em>good</em> ending and not mess things up on your way there. In other words, rushing through the whole story is possible if you don't mind bringing it to a terrible conclusion.</p>
<h2>Communicating with the game</h2>
<p>While the previous chapter only concerns detective games that also prominently feature a story, this next one is relevant to pretty much every detective game every made. It addresses the topic of communication between the player and the game, and especially how the player can express their thoughts to it. Several principles have proven to make for a good experience across countless approaches to this problem over the years:</p>
<p><strong>Principle 1: Many channels out, few channels back in.</strong><br>
If the game conveys information to the player on many different channels and in many different ways, the process of piecing the solution together tends to feel more interesting and rewarding. In Lacuna, the player picks up clues from dialogs, objects, environments, the news, and e-mails (with all sorts of attachments). At the same time, the channels via which the player communicates that solution back to the game are kept to a minimum, namely cloze texts we like to call "Case Sheets" and (to a lesser degree) dialog choices. Having one or two central mechanics for player input makes the experience more coherent and transparent and facilitates designing the mysteries around it.</p>
<p><img alt="Obra Dinn" src="https://digitales.games/user/pages/03.blog/detective-game-design-problems/solutions-obra-dinn.jpg"><br>
<em>Return of the Obra Dinn by Lucas Pope provides a bunch of different sources of information, but just one central mechanic for the player to communicate back to the game</em></p>
<p><strong>Principle 2: Have the player communicate only the solution.</strong><br>
It is near impossible to create a system through which the player communicates to the game <em>how</em> they arrived at a solution. Luckily, this is not necessary. A well-designed puzzle provides all the information, then moves the entire solution process solely <em>into the player‚Äôs head</em>, and finally prompts the player to input only their answer. The player‚Äôs objective should be stated clearly, but in a very general way at the start of a case (e.g. ‚Äúfind the culprit‚Äù).</p>
<p><strong>Principle 3: Give the player maximum freedom in communicating the solution.</strong><br>
The way in which the player communicates the answer to the game is the most crucial part to get right. One aspect is to give the player many choices (or a large combination of choices) to pick from. Two things should be avoided: 1. Giving the player a high probability to succeed by picking a random answer. 2. Making it easy for the player to guess correctly because only one or a few of the available answers appear plausible. An example for a bad solution like this would be to give the player three dialog choices to solve the puzzle; even worse would be if one of them obviously made the most sense. A better approach would be to give the player a cloze text with a bunch of plausible options for each gap. Another possibility is to have the solution be an unguessable string of characters that the player needs to enter manually. Both ideas utilize combinatorial explosion to make guessing and brute-forcing nearly impossible.</p>
<p><img alt="Detective Grimoire" src="https://digitales.games/user/pages/03.blog/detective-game-design-problems/solutions-case-sheets.jpg"><br>
<em>Good luck brute-forcing your way through Detective Grimoire's cloze texts</em></p>
<h2>Puzzle example</h2>
<p>Hopefullly all this will become crystal clear when put to concrete use! The following is an early level in Lacuna. It doesn't contain some of the difficulties added later (like a large number of channels communicating potential evidence). In harder cases, the player will need to have paid attention to testimonies, news articles etc. from earlier levels to arrive at the correct conclusion, and some cases span multiple levels. Not this one, though; all the information required to solve it is directly contained in the clues and dialogs of the one level where it starts and ends.</p>
<p>This chapter won't reveal much of importance about the story, but it will spoil the solution to this one puzzle, so consider yourself warned.</p>
<h3>The puzzle</h3>
<p>Here's what happens: Our protagonist Neil is called to a ‚Ä¶</p></div></div></div></div></div></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://digitales.games/blog/detective-game-design-problems">https://digitales.games/blog/detective-game-design-problems</a></em></p>]]>
            </description>
            <link>https://digitales.games/blog/detective-game-design-problems</link>
            <guid isPermaLink="false">hacker-news-small-sites-25185571</guid>
            <pubDate>Mon, 23 Nov 2020 11:11:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Are pixie fairies behind Bitcoin's latest bubble?]]>
            </title>
            <description>
<![CDATA[
Score 73 | Comments 92 (<a href="https://news.ycombinator.com/item?id=25180563">thread link</a>) | @amycastor
<br/>
November 22, 2020 | https://amycastor.com/2020/11/21/are-pixie-fairies-behind-bitcoins-latest-bubble/ | <a href="https://web.archive.org/web/*/https://amycastor.com/2020/11/21/are-pixie-fairies-behind-bitcoins-latest-bubble/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-4780">
		<div>
		
<p>Are the pixie fairies sprinkling gold dust on bitcoin‚Äôs market again? By the looks of things, you might think so. </p>



<p>Like in the bubble days of 2017, the price of bitcoin is headed ever upward. On Wednesday morning, it surpassed $18,000 ‚Äî a number not seen since December 2017 when bitcoin, at its all-time peak, scratched $20,000.</p>



<p>Of course, the market <a href="https://www.bloomberg.com/news/articles/2018-09-12/crypto-s-crash-just-surpassed-dot-com-levels-as-losses-reach-80">crashed spectacularly</a> the following year, and retailers lost their shirts. But here we are once again, trying to unravel the mysteries of bitcoin‚Äôs latest price movements. </p>



<p>Several factors may explain it ‚Äî Tether, PayPal, and China‚Äôs crackdown on over-the-counter desks ‚Äî but before we get into that, let me reiterate how critical it is for bitcoin‚Äôs price to stay at or above a certain <em>magic number</em>.&nbsp;</p>



<p>Bitcoin miners ‚Äî those responsible for securing the bitcoin network by ‚Äúmining‚Äù the next block of transactions on the blockchain ‚Äî need to sell their newly minted bitcoins for real money, so they can pay their <a href="https://news.bitcoin.com/the-bitcoin-network-now-consumes-7-nuclear-plants-worth-of-power/#:~:text=Today%2C%20the%20CBECI%20says%20the,terawatt%2Dhours%20of%20energy%20consumption.">massive energy bills.</a>&nbsp;&nbsp;</p>



<p>Roughly $8 million to $10 million in cash gets sucked out of the bitcoin ecosystem this way every day. So, in order for the miners ‚Äî the majority of whom are in China ‚Äî to turn a profit, bitcoin needs to be priced accordingly. Otherwise, if too many miners were to decide to call it quits and unplug from the network all at once, that would leave bitcoin vulnerable to attacks. The entire system, and its current $345 billion market cap, literally depends on keeping the miners happy.</p>



<p>Now let‚Äôs jump to May 11, an important day for bitcoin. That was the day of the ‚Äúhalvening,‚Äù an event hardwired into bitcoin‚Äôs code where the block reward gets slashed in half. A halvening occurs once every four years.</p>



<p>Before May 11, miners received 1,800 bitcoin a day in the form of block rewards, which meant they needed to cash in each bitcoin for $5,000. But <em>after</em> the halvening, the network would produce only 900 bitcoins per day, so miners knew they needed to sell each precious bitcoin for at least $10,000.&nbsp;&nbsp;</p>



<p>But trouble loomed. Just months before the halvening, the price of bitcoin went into free fall. Between February and March, when the world was first gripped by the COVID crisis, bitcoin lost half its value, sliding to $5,000 ‚Äî barely enough to pay the system‚Äôs energy costs post-halvening. Miners were likely pacing, wringing their hands, wondering how they would stay in business. Who would guarantee their profits?</p>



<p>That is when Tether ‚Äî a company that produces a dollar-pegged stablecoin of the same name ‚Äî sprung into action and started issuing tethers in amounts far greater than it ever had before in its five years of existence.</p>



<p>Tethers, for the uninitiated, are the main source of liquidity for unbanked crypto exchanges, which account for most of bitcoin‚Äôs trading volume. Currently, there are $18 billion (notional value) worth of tethers sloshing around in the crypto markets. And nobody is quite sure what‚Äôs backing them.</p>



<p>Due to Tether‚Äôs lack of transparency, its failure to provide a long promised audit, and the fact that the New York Attorney General is <a href="https://www.wsj.com/articles/bitfinex-used-tether-reserves-to-mask-missing-850-million-probe-finds-11556227031">currently probing</a> the firm along with Tether‚Äôs sister company, crypto exchange Bitfinex, for fraud, a good guess is nothing. Tethers, many suspect, are being minted out of thin air.&nbsp;</p>



<p>(Tethers were initially promised as an IOU where one tether was supposed to represent a redeemable dollar. But that was long before the British Virgin Island-registered firm began issuing tethers in massive quantities. And no tethers, to anyone‚Äôs knowledge, have ever been redeemed‚Äîexcept for when Tether <a href="https://www.coindesk.com/tether-just-burned-500-million-usdt-stablecoin-tokens">burned 500 million tethers</a> in October 2018, following the <a href="https://amycastor.com/2019/04/26/new-york-attorney-general-bitfinex-is-hiding-850-million-in-losses/">seizure of $850 million</a> from its payment processor Crypto Capital.)</p>



<p>According to data from <a href="https://amycastor.com/2020/11/21/are-pixie-fairies-behind-bitcoins-latest-bubble/blank">Nomics</a>, at the beginning of 2020, there were only $4.3 billion worth of tethers in circulation. That number remained stable through January and February and into March. But starting on March 18, just five days after bitcoin dipped below $5,000, the tether printer kicked in.</p>



<figure><img src="https://lh4.googleusercontent.com/wquSWQQ2kEfLCnshYnCiE7RZY2tuh9JtkWwPvnSsImvegfwkMzdhboJKFhSdpxqc5CtbcOh-5xqaro5F5DQAupoThjDcw6DYUf9wQTPBgfSMOV2TObswcJbuZoiOi2z46e9AR4Wg" alt=""><figcaption><em>BTC price and USDT supply. </em><a href="https://nomics.com/"><em>Image: Nomics.com</em></a></figcaption></figure>



<p>Tether minted $1.9 billion worth of tethers in March, and another $1.5 billion worth in April ‚Äî crypto‚Äôs own version of an economic stimulus package. The price of bitcoin rose in tandem back up to $10,000, just in time for the halvening. Yet the Tether printer kept printing, pushing the price of bitcoin ever skyward and giving bag holders an opportunity to cash out.&nbsp;</p>



<p>In May, June and July, Tether issued a combined total of $6 billion in tethers. In August, when the price of bitcoin reached $12,000, it spun out $2.5 billion in tethers. And in September, when BTC slid to $10,000, Tether infused the markets with another $2 billion in tethers, although, even that couldn‚Äôt lift bitcoin up to $12,000 again. It just hovered in the $10,000 range.&nbsp;</p>



<p>And then in October ‚Äî just after US prosecutors <a href="https://www.justice.gov/usao-sdny/pr/founders-and-executives-shore-cryptocurrency-derivatives-exchange-charged-violation">charged the founders of BitMEX,</a> a Seychelles-registered, Hong Kong-based bitcoin derivatives exchange, for failing to maintain an adequate anti-money laundering program ‚Äî the price of BTC started to soar. What happened?</p>



<h2><strong>Tether‚Äôs frenzied pumping</strong></h2>



<p>One theory is that Tether just kept issuing tethers, billions and billions of them, and those tethers were used to buy up bitcoin. A high demand drives up the price ‚Äî even if it‚Äôs fake money.&nbsp;</p>



<p>Only unlike in 2017, the effort to drive up bitcoin‚Äôs price is requiring a lot more tethers than ever before. (At the end of 2017, before the last bitcoin bubble popped, there were only $1.3 billion worth of tethers in circulation, a fraction of what there are today.)</p>



<p>Nicholas Weaver, a bitcoin skeptic and a researcher at the International Computer Science Institute in Berkeley, is convinced&nbsp;bitcoin‚Äôs latest price moves are 100% synthetic.</p>



<p>‚ÄúThe amount of tether flooding into the system is more than enough explanation for the price as it is well more than the amount needed to buy up all the newly minted bitcoin,‚Äù he told me. ‚ÄúIf it was organic, there would at least be some significant increase in the outstanding amount of non-fraudulent stablecoins.‚Äù</p>



<p>What he means is, if real money was behind tether, we‚Äôd be seeing a similar demand for regulated stablecoins. But that is not the case. Only one regulated stablecoin has seen substantial growth ‚Äî <a href="https://www.theblockcrypto.com/linked/81422/stablecoin-supply-has-surged-past-20-billion-driven-by-derivatives-market">Circle‚Äôs USDC</a> ‚Äî but that growth is far overshadowed by Tether, and mainly a result of the growing decentralized finance (DeFi) market ‚Äî a topic for another time.</p>



<p>Jorge Stolfi, a professor of computer science at the State University of Campinas in Brazil, who in 2016 wrote a <a href="https://www.sec.gov/comments/sr-batsbzx-2016-30/batsbzx201630-2.htm">letter to the SEC</a> advising about the risks of a bitcoin ETF, which the SEC published, agrees.</p>



<p>‚ÄúAs long as fake money can be used to buy BTC, the price can be pumped to whatever levels to keep the miners happy,‚Äù he told me. He went on to <a href="https://twitter.com/JorgeStolfi/status/1329952095286472711">explain</a> in a Twitter thread that the higher the bitcoin price, the faster real money flows out of the system ‚Äî assuming miners sell <em>all</em> their bitcoin for cash. Multiply bitcoin‚Äôs current price of $18,600 times 900, and that‚Äôs nearly $17 million a day. Investors will never get that money back, he said.</p>



<p>Klyith (not his real name) from Something Awful, a predecessor site to 4Chan, <a href="https://forums.somethingawful.com/showthread.php?noseen=0&amp;threadid=3838405&amp;perpage=40&amp;pagenumber=797#post505143737">explains Tether</a> this way:</p>



<p>‚ÄúA bunch of pixies show up and start flooding the parchment market with fairy gold, driving prices to amazing new heights. But when any of the player characters try to spend the fairy gold in other towns or to pay tithes to the king, it turns into worthless rocks.</p>



<div><figure><a href="https://amyhcastor.files.wordpress.com/2020/11/fairy.jpg"><img loading="lazy" data-attachment-id="4784" data-permalink="https://amycastor.com/fairy/" data-orig-file="https://amyhcastor.files.wordpress.com/2020/11/fairy.jpg" data-orig-size="564,775" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="fairy" data-image-description="" data-medium-file="https://amyhcastor.files.wordpress.com/2020/11/fairy.jpg?w=218" data-large-file="https://amyhcastor.files.wordpress.com/2020/11/fairy.jpg?w=564" src="https://amyhcastor.files.wordpress.com/2020/11/fairy.jpg?w=564" alt="" width="291" height="400" srcset="https://amyhcastor.files.wordpress.com/2020/11/fairy.jpg?w=291 291w, https://amyhcastor.files.wordpress.com/2020/11/fairy.jpg?w=109 109w, https://amyhcastor.files.wordpress.com/2020/11/fairy.jpg?w=218 218w, https://amyhcastor.files.wordpress.com/2020/11/fairy.jpg 564w" sizes="(max-width: 291px) 100vw, 291px"></a></figure></div>



<p>‚ÄúIf you denounce the pixies to the peasants or start using dispel magic to reveal that fairy gold is rocks, the price of parchments will collapse and the peasants may stop using them altogether. But if you ignore the pixies and keep the parchment economy going, you will end up with more and more worthless rocks instead of gold. The pixies can of course tell the difference between fairy gold and real gold at a glance. So they will quickly drain all the real gold from the whole township if you don‚Äôt act. What do you do?‚Äù</p>



<p>Still, it is hard to imagine that outside events don‚Äôt have some impact on bitcoin‚Äôs price. Two other events are being talked about right now as reasons behind bitcoin‚Äôs price gains‚Äîand they are getting a lot more media attention than Tether.</p>



<h2><strong>PayPal‚Äôs shilling</strong></h2>



<p>One of the biggest companies in the world is now <a href="https://www.ft.com/content/826eedac-b0cd-4591-897a-9e83cf697060">promoting crypto</a>, giving retail buyers the impression that bitcoin is a safe investment. After all, if bitcoin were a Ponzi or a scam, why would such a well-known, respectable company embrace it? I should add that <a href="https://www.coindesk.com/microstrategy-ceo-bitcoin-better-than-antiquated-gold">MicroStrategy</a>, <a href="https://squareup.com/us/en/press/2020-bitcoin-investment">Square</a>, <a href="https://decrypt.co/48252/wall-streets-fidelity-mounts-defense-for-bitcoin">Fidelity Investment</a> and Mexico‚Äôs third-richest person, <a href="https://www.bloomberg.com/news/articles/2020-11-18/billionaire-salinas-has-10-of-liquid-portfolio-in-bitcoin">Ricardo Salinas Pliego</a>, are also currently shilling bitcoin on the internet. </p>



<p>On Oct. 21, PayPal <a href="https://newsroom.paypal-corp.com/2020-10-21-PayPal-Launches-New-Service-Enabling-Users-to-Buy-Hold-and-Sell-Cryptocurrency">announced a new service</a> for its users to buy and sell crypto for cash. And on Nov. 12, the service <a href="https://techcrunch.com/2020/11/12/paypal-says-all-users-in-u-s-can-now-buy-hold-and-sell-cryptocurrencies/">became available to U.S. customers</a>, who can now buy and sell bitcoin, bitcoin cash, ether, and litecoin via their PayPal wallet.&nbsp;</p>



<p>If you are a PayPal user, you have already gone through the process of proving you are who you say you are. And that removes the hassle of having to sign up with an crypto exchange, like Coinbase in the U.S., and take selfies of yourself holding up your driver‚Äôs license or passport.</p>



<p>Of course, there are limitations. You can‚Äôt transfer crypto into or out of your wallet, like you can on a centralized exchange. But you can pay PayPal‚Äôs 26 million merchants with crypto ‚Äî although, not really, because what they receive on their end is cash. And the transaction is subject to high fees, like <a href="https://techcrunch.com/2020/10/21/paypal-to-let-you-buy-and-sell-cryptocurrencies-in-the-us/">2.3% for anything under $100</a>, so what is the point? All you are doing is taking out a bet against PayPal that the price of bitcoin is going to rise.&nbsp;</p>



<p>Stolfi describes PayPal <a href="https://twitter.com/JorgeStolfi/status/1330207860484153347">on Twitter</a> as ‚Äúa meta-casino where you can choose to use special in-house chips with a randomly variable value.‚Äù</p>



<p>The broader point is that PayPal makes it easy to buy crypto for people who are less likely to understand how crypto really works or know about ‚Ä¶</p></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://amycastor.com/2020/11/21/are-pixie-fairies-behind-bitcoins-latest-bubble/">https://amycastor.com/2020/11/21/are-pixie-fairies-behind-bitcoins-latest-bubble/</a></em></p>]]>
            </description>
            <link>https://amycastor.com/2020/11/21/are-pixie-fairies-behind-bitcoins-latest-bubble/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25180563</guid>
            <pubDate>Sun, 22 Nov 2020 20:03:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Mark Zuckerberg's Ponzi Scheme (2019)]]>
            </title>
            <description>
<![CDATA[
Score 51 | Comments 22 (<a href="https://news.ycombinator.com/item?id=25180420">thread link</a>) | @annadane
<br/>
November 22, 2020 | http://www.aarongreenspan.com/writing/20190723/mark-zuckerbergs-ponzi-scheme/ | <a href="https://web.archive.org/web/*/http://www.aarongreenspan.com/writing/20190723/mark-zuckerbergs-ponzi-scheme/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>
Mark Zuckerberg's Ponzi Scheme<br>
<span color="#A0A0A0">Congress and the FTC brought a knife to a gun fight.</span></p><div>

<p>It's already a campaign issue for the next presidential election: should we, or should we not, break up the big tech companies? Elizabeth Warren says yes. Beto O'Rourke wants "stronger regulations."  Kamala Harris would rather talk about privacy. Everyone else√¢‚Ç¨‚Äùeven Donald Trump√¢‚Ç¨‚Äùgenerally agrees that something needs to be done. But what?</p><p>There are plenty of law professors, think tanks and political consultants eager to share their ideas, but none of them are asking the right questions. In the case of Facebook, distractions are understandable when the company arguably has the worst track record of any major technology company in history (and will soon pay a record, if toothless, $5 billion fine). Yet the unspoken issue at the center of it all remains: although Wall Street, Congress and the Federal Trade Commission haven't figured it out, Mark is running a Ponzi scheme.</p><p>At this point it should come as no surprise to anyone paying attention that Mark is a bad-faith actor. He has no appreciation for the rule of law, or the role of a free press, and he has a dangerous tendency to view himself as infallible. After discovering a gaping security flaw in his product that revealed bulk information about friends of friends, exactly like Cambridge Analytica, I warned Mark in writing about the way his sloppy code would inevitably lead him to cross paths with the FTC and cause massive privacy and security concerns√¢‚Ç¨‚Äùin <a href="http://www.thinkpress.com/authoritas/timeline.pdf" target="_new">April 2005</a>. His response: problems with the "Mark Zuckerberg production" were actually someone else's responsibility and "not worth arguing about."</p><p>Clearly, Mark can no longer argue that his decisions as Facebook's CEO are immaterial (though he has <a href="https://www.vox.com/2016/11/11/13596792/facebook-fake-news-mark-zuckerberg-donald-trump" target="_new">tried</a>). Many have already lost their lives, whether through avoidable suicides or avoidable genocidal acts in Myanmar, due to his string of increasingly tone-deaf and spectacularly dishonest decisions. Now, fifteen years and approximately as many false apologizes after my classmate started a grand social experiment that first captivated the media, then locked it in a profitless box, and then played a major supporting role in bringing fascism to America, the general consensus is that the best way to handle Mark and his tech brethren is through the Sherman Anti-Trust Act. But the consensus is wrong, based on a mountain of misapprehensions.</p><p>In a nutshell, the argument in favor of anti-trust action is that in the midst of the longest economic expansion in U.S. history, it's the Progressive Era all over again. A recent New York Times op-ed penned by Mark's former roommate and co-founder, Chris Hughes, made essentially this point, relying heavily on input from the Roosevelt Institute. The Open Markets Institute agrees. In a <a href="https://www.youtube.com/watch?v=xM9GMGDsKUU&amp;t=24m40s" target="_new">talk at Harvard Law School</a>, Matt Stoller argued that Facebook, Google and Amazon were "born as monopolists."</p><p>It's a compelling story, so long as one is willing to ignore the reality on the ground. For one thing, software products are not railroads, which require significant physical capital and labor to establish. Were he determined to do so, it would take Mark a few weeks to re-build Instagram and WhatsApp, and there really isn't any way the government could stop him. For another, I know that on this particular issue, Stoller is incorrect, because I was there when The Facebook was born on my hard drive on September 19, 2003, in Lowell House. It hardly resembled a monopoly. Monopolies are what happen as the result of prolonged neglect by law enforcement. They're not born; they're nourished by years and years of perverse incentives.</p><p>The biggest problem with treating Facebook as a monopoly, as opposed to the byproduct of what Jesse Eisenger calls "The Chickenshit Club," is that it wrongly affirms Mark's infallibility and fails to see through him and his scheme, let alone the reality that he's not even in control anymore because no one is. On October 26, 2012, Mark's friend and lieutenant, Sam Lessin, wrote, "we are running out of humans (and have run-out of valuable humans from an advertiser perspective)."  At the time, it was far from clear that Facebook even had a viable business model, and according to Frontline, Sheryl Sandberg was panicking due to the company's poor revenue numbers.</p><p>How times have changed; now there's a different source of panic. Facebook now has a market capitalization approaching $600 billion, making it nominally one of the most valuable companies on earth. It's a true business miracle: a company that was out of users in 2012 managed to find a wellspring of nearly infinite and sustained growth that has lasted it, so far, half of the way through 2019. So what is that magical ingredient, that secret sauce, that "genius" trade secret, that turned an over-funded money-losing startup into one of America's greatest business success stories? It's one that Bernie Madoff would recognize instantly: fraud, in the form of fake accounts.</p><p>Old money goes out, and new money comes in to replace it. That's how a traditional Ponzi scheme works. Madoff kept his going for decades, managing to attain the rank of Chairman of the NASDAQ while he was at it. Zuckerberg's version is slightly different, but only slightly: old users leave after getting bored, disgusted and distrustful, and new users come in to replace them. Except that as Sam Lessin told us, the "new users" part of the equation was already getting to be a problem in 2012. To balance it out and keep "growth" on the rise, all Facebook had to do was turn a blind eye. And did it ever.</p><p>In <a href="https://www.plainsite.org/dockets/3bvv82ier/california-northern-district-court/singer-v-facebook-inc/" target="_new"><i>Singer v. Facebook, Inc.</i></a>√¢‚Ç¨‚Äùa lawsuit filed in the Northern District of California alleging that Facebook has been telling advertisers that it can "reach" more people than actually exist in basically every major metropolitan area√¢‚Ç¨‚Äùthe plaintiffs quote former Facebook employees, understandably identified only as Confidential Witnesses, as stating that Facebook's "Potential Reach" statistic was a "made-up PR number" and "fluff."  Also, that "those who were responsible for ensuring the accuracy √¢‚Ç¨Àúdid not give a shit.'"  Another individual, "a former Operations Contractor with Facebook, stated that Facebook was not concerned with stopping duplicate or fake accounts."</p><p>That's probably because according to its <a href="https://s21.q4cdn.com/399680738/files/doc_financials/2019/Q1/Q1-2019-Earnings-Presentation.pdf" target="_new">last investor slide deck</a> and basic subtraction, Facebook is not growing anymore in the United States, with zero million new accounts in Q1 2019, and only four million new accounts since Q1 2017. That leaves the rest of the world, where Facebook is growing fastest "in India, Indonesia, and the Philippines," according to Facebook CFO David Wehner. Wehner didn't mention the fine print on page 18 of the slide deck, which highlights the Philippines, Indonesia and Vietnam as countries where there are "meaningfully higher" percentages of, and "episodic spikes" in, fake accounts. In other words, Facebook is growing the fastest in the locations worldwide where one finds the most fraud. In other other words, Facebook isn't growing anymore at all√¢‚Ç¨‚Äùit's shrinking. Even India, Indonesia and the Philippines don't register as many searches for Facebook as they used to. Many of the "new" users on Instagram are actually old users from the core platform looking to escape the deluge of fakery.</p><p>The last time Mark suggested that Facebook's growth heyday might be behind it, in July 2018, the stock took a nosedive that ended up being the single largest one-day fall of any company's stock in the history of the United States. In about an hour, it <a href="https://www.marketwatch.com/story/facebook-stock-crushed-after-revenue-user-growth-miss-2018-07-25" target="_new">plunged 20%</a> from around $220 per share to about $165. Needless to day, the loss of about $120 billion in market capitalization in an hour provided a sufficient disincentive for Mark to avoid a repeat performance.</p><p>Having narrowly escaped the ire of Wall Street, Mark knows he cannot get off the growth treadmill he set in motion years ago. The only solution: lying to investors about growth in an attempt to convince them that everything is fine. Yet signs that Mark's fake account problem is no different than Madoff's fake account statement problem are everywhere. Google Trends shows worldwide "Facebook" queries down 80% from their November 2012 peak. (Instagram doesn't even come close to making up for the loss.)  Mobile metrics measuring use of the Facebook mobile app are down. And the company's own disclosures about fake accounts stand out mostly for their internal inconsistency√¢‚Ç¨‚Äùone set of numbers, measured in percentages, is disclosed to the SEC, while another, with absolute figures, appears on its "transparency portal."  While they reveal a problem escalating at an alarming rate and are constantly being revised upward√¢‚Ç¨‚ÄùFacebook claims that false accounts are at 5% and duplicate accounts at 11%, up from 1% and 6% respectively in Q2 2017√¢‚Ç¨‚Äùthey don't measure quite the same things, and are <a href="https://www.plainsite.org/realitycheck/facebook.html" target="_new">impossible to reconcile</a>. At the end of 2017, Facebook decided to stop releasing those percentages on a quarterly basis, opting for an annual basis instead. Out of sight, out of mind.</p><p>One could argue that SEC disclosures are subject to strict regulations under the Securities Exchange Act and that Facebook would never be so bold as to lie to investors in black and white. That's true: it qualifies its fake account disclosures with the quizzical legal phrase "significant judgment" and it chose the color orange instead of black (insert Netflix joke here) for its transparency portal graph disclaimers that read, "These metrics are in development."  And one could further argue that the transparency portal metrics are reviewed by a team of academics, known as the Data Transparency Advisory Group (DTAG), who are supposed to vouch for their validity. But the DTAG academics√¢‚Ç¨‚Äùnot one of whom is a statistician, despite Facebook's direct claim to the contrary, now erased√¢‚Ç¨‚Äùfully admit that they are paid by Facebook, and even after months of hard work, their <a href="https://law.yale.edu/system/files/area/center/justice/document/dtag_report_5.22.2019.pdf" target="_new">final report</a> released in April mentioned fake accounts only three times, and all three ‚Ä¶</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://www.aarongreenspan.com/writing/20190723/mark-zuckerbergs-ponzi-scheme/">http://www.aarongreenspan.com/writing/20190723/mark-zuckerbergs-ponzi-scheme/</a></em></p>]]>
            </description>
            <link>http://www.aarongreenspan.com/writing/20190723/mark-zuckerbergs-ponzi-scheme/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25180420</guid>
            <pubDate>Sun, 22 Nov 2020 19:47:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Month of Terraform]]>
            </title>
            <description>
<![CDATA[
Score 99 | Comments 76 (<a href="https://news.ycombinator.com/item?id=25180355">thread link</a>) | @ingve
<br/>
November 22, 2020 | https://jeremywsherman.com/blog/2020/11/21/a-month-of-terraform/ | <a href="https://web.archive.org/web/*/https://jeremywsherman.com/blog/2020/11/21/a-month-of-terraform/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p>I took Heroku for granted, and a month into setting up my own infra, I now know how much it bought me.</p>
<p>A lot of my past work has been infrastructure-adjacent.
I often find myself filling in the Build &amp; Integration role - the person that gets continuous integration off the ground and keeps it actually continuing rather than falling flat on its face.
But often I‚Äôve just been building one of a constellation of services, so the core infrastructure was already there,
or I‚Äôve been targeting something like Heroku, where you basically pick your poison, git push, and bob‚Äôs your uncle.</p>
<p>This time, I‚Äôm putting the pieces together using the AWS toolkit.
And to smoosh them all together, I‚Äôm using Terraform,
because heck if I‚Äôm going to be hand-writing YAML or JSON and praying it‚Äôs formatted right.
Plus there‚Äôs more I want to orchestrate than just AWS, like, say, GitLab.</p>
<p>I don‚Äôt wanna talk about AWS just now.
It reminds me of learning Foundation &amp; Cocoa - you look at one piece, and it can do so much, and then you gotta put all those individually deep &amp; complex pieces together to do more stuff.
I figure if I put in the hours reading docs, learning what‚Äôs all there, and getting stabbed by the pointy bits, it‚Äôll probably all come out fine in the end.</p>
<p>So, Terraform.</p>
<h2 id="the-good">The Good</h2>
<ul>
<li>It mostly works!</li>
<li>When it doesn‚Äôt, it generally fails in a useful way, and then I can fix it and try again.</li>
<li>There are docs for most things.</li>
<li>Autoformatting works great.</li>
<li>Linting works pretty well.</li>
<li><em>Terraform: Up &amp; Running</em> is excellent, and Terragrunt makes it even easier. Huge thanks to their team for providing the <a href="https://rachelbythebay.com/w/2018/03/23/ducttape/">duct tape</a> we need. üôå</li>
</ul>
<h2 id="the-not-so-good">The Not So Good</h2>
<ul>
<li>terraform-lsp is supposed to provide autocomplete, but it mostly doesn‚Äôt, in my experience. First it flipped its lid that I dared to have a repo with multiple root modules in it, so I just aimed VS Code at the folder with a single root module. Then the language server says it‚Äôs all hunky dory AFAICT, and yet it autocompletes nothing beyond bare language syntax. As a result,  I‚Äôm manually referencing docs and writing stuff down and wasting tons of time that tools like autocomplete and integrated linting ought to be saving me from.</li>
<li>State files contain secrets in plaintext. (You might enjoy the <a href="https://github.com/hashicorp/terraform/issues/516">six-year-old GitHub issue about the plaintext secrets problem</a>.) You can mark outputs as secret, so they don‚Äôt get printed at the end of applying your infra spec, but run <code>terraform show</code> instead of <code>terraform apply</code>, and there they are, staring back at you. At least you can lock down and encrypt the S3 bucket holding the state.
<ul>
<li><a href="https://www.pulumi.com/docs/intro/concepts/config/#secrets">Pulumi‚Äôs secrets management</a> is far more satisfying. But Pulumi is even more cutting-edge than v0.whatever Terraform, and I expect Hashicorp to keep TF running for a good while, while I‚Äôm not so confident in Pulumi, so I‚Äôm using TF. (Hashicorp of course would recommend <a href="https://www.hashicorp.com/products/vault">Vault</a>.)</li>
</ul>
</li>
<li>Annoying asymmetries in the language about how you *<em>declare and reference</em> things in slightly variant ways - I trip over these over and over as a beginner:
<ul>
<li>You declare locals in a <code>locals</code> block, but you reference them as <code>local.thing</code>, not <code>locals.thing</code>.</li>
<li>You declare a variable in a <code>variable</code> block, but you reference it as <code>var.thing</code>.</li>
<li>You declare data sources as <code>data "provider_thingy" "my_name_for_this_data"</code>, and then you have to access it as <code>data.provider_thingy.my_name_for_this_data</code>. (This is actually pretty darn consistent, at least. Though, like, why the quotes around the provider thingy?)</li>
<li>You declare resources as <code>resource "provider_thingy" "my_name"</code>. But you do NOT reference them as <code>resource.provider_thingy.my_name</code>. Nope, you just reference them as bare <code>provider_thingy.my_name</code>.</li>
</ul>
</li>
<li>For that matter, there are other oddities as well. Pieces of syntax that seem like they should be orthogonal just aren‚Äôt. <code>for_each</code> stands out here:
<ul>
<li>You can generate multiple resources by just dropping a <code>for_each</code> in the block: <code>resource "provider_thing" "mine" {}</code> becomes <code>resource "provider_thing" "mine" { for_each = of_these }</code></li>
<li>But nested <em>argument</em> blocks require conversion from like <code>setting { namespace = "blah" }</code> to <code>dynamic "setting" { for_each = thingy; content { namespace = "blah" }}</code>. Have fun looking that up a few times.</li>
<li>And you can‚Äôt even use the <code>for_each</code> trick with module imports. It just isn‚Äôt supported. Sorry, sucks to be you.</li>
</ul>
</li>
<li>Annoying gaps in the docs:
<ul>
<li><strong>Required vs optional parameters</strong> are not very clearly called out and are not at all segregated. So you get to play the game of ‚Äúwhat is the minimal skeleton to declare this resource‚Äù. Actually running it a few times to see what you screwed up takes longer than just looking at the docs and puzzling it out, due to the lengthy iteration times in infra-land (see below).</li>
<li><strong>Types are not shown in the docs!!!</strong> All the outputs and arguments are typed. You have to declare those types. It‚Äôs right there in the code. But the docs don‚Äôt say what any of the types are. You just hit a type error at runtime. Fun fun!</li>
<li><strong>The HCL language is doc‚Äôd under the CLI tool, not in and of itself.</strong> It was really hard to actually find the docs since my first thought when I have syntax questions isn‚Äôt ‚Äúlet‚Äôs look at the docs for the tool.‚Äù It‚Äôd be like pulling up the manpage for GCC (carefully draw your triangle of art first) when you have a question about C syntax.</li>
</ul>
</li>
<li>Annoying asymmetries in the AWS provider:
<ul>
<li><strong>Missing links:</strong> Sometimes you get into a ‚Äúcan‚Äôt get there from here‚Äù situation. Like trying to find the zone ID for an Elastic Beanstalk environment‚Äôs CNAME so you can aim a Route 53 alias at it. (Hint, you need a completely different resource, the <code>aws_elastic_beanstalk_hosted_zone</code>.)</li>
<li><strong>Irregular naming:</strong>
<ul>
<li>Sometimes something is <code>zone_id</code>, but other times it‚Äôs maybe just <code>id</code>.</li>
<li>Sometimes you can fish stuff out by <code>arn</code>, or maybe by <code>id</code>, or maybe it‚Äôs by <code>name</code> - good luck. Keep the docs close to hand.</li>
<li>(It‚Äôs totally possible this is inherited from the AWS APIs themselves, but the whole point of an abstraction layer is to make things better and more usable, dangit.)</li>
</ul>
</li>
</ul>
</li>
</ul>
<h2 id="the-different">The Different</h2>
<ul>
<li><strong>Iteration times are way longer than with even mobile apps.</strong> Like, ‚Äúyou‚Äôre liable to task-switch while waiting to see plan output‚Äù longer.</li>
<li><strong>Testing is a pain.</strong> I haven‚Äôt pulled in <a href="https://terratest.gruntwork.io/">Terratest</a> yet, because anyone maintaining this after me is unlikely to have Go experience, and my focus here isn‚Äôt builing reusable infra anyway - it‚Äôs building <em>this</em> infra ‚Äì so I‚Äôve just been using <code>bats</code> and Bash shell scripts (with <a href="https://github.com/koalaman/shellcheck/blob/master/README.md">shellcheck</a>, which is amazing) for some after-the-fact sanity checking using the AWS CLI. (Pro tip: Use the community-maintained fork <a href="https://github.com/bats-core/bats-core"><code>bats-core</code></a> rather than the no-longer-maintained sstephenson original.)
<ul>
<li>Policy assertions feel like a different flavor of test, but the tooling here seems to be fairly immature, with perhaps the exception of if you‚Äôre targeting Kubernetes.</li>
</ul>
</li>
</ul>
<h2 id="summary">Summary</h2>
<p>I expect I‚Äôll get used to most of the rough edges of the syntax in another month. And Terraform is stil v0, so hey, maybe some breaking changes will clear all this mess away. ü§û</p>
<p>I‚Äôm intentionally not getting sucked into hacking around the docs frustrations just now. Or even the <a href="https://github.com/gruntwork-io/terragrunt/issues/432#issuecomment-371467507">very tempting open issue about silencing all the Terragrunt logspew</a>.</p>
<p>I do plan to spend a bit of time trying to get autocomplete working for resource and data source types and their arguments/attributes from the language server, at least. That would be a huge help.</p>
<p>It still feels like magic to run a command and have infrastructure just‚Ä¶happen.
You hit return, wait a bit, and suddenly servers are serving and domains are aliasing and a whole constellation of systems are interoperating.
It kinda reminds me of the magic of home automation with blinkenlights, only without any of that messy ‚Äúhardware‚Äù stuff to break on you.</p>

    </div></div>]]>
            </description>
            <link>https://jeremywsherman.com/blog/2020/11/21/a-month-of-terraform/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25180355</guid>
            <pubDate>Sun, 22 Nov 2020 19:39:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[We‚Äôre Optimizing Ourselves to Death (2019)]]>
            </title>
            <description>
<![CDATA[
Score 266 | Comments 180 (<a href="https://news.ycombinator.com/item?id=25180229">thread link</a>) | @thread_id
<br/>
November 22, 2020 | https://zandercutt.com/2019/02/18/were-optimizing-ourselves-to-death/ | <a href="https://web.archive.org/web/*/https://zandercutt.com/2019/02/18/were-optimizing-ourselves-to-death/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<h4>Burnout is the inevitable result of our endlessly accelerating pace of&nbsp;life</h4>



<figure><img data-attachment-id="552" data-permalink="https://zandercutt.com/screen-shot-2019-03-06-at-5-32-05-pm/" data-orig-file="https://zandernethercutt.files.wordpress.com/2019/03/screen-shot-2019-03-06-at-5.32.05-pm.png" data-orig-size="564,744" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="screen-shot-2019-03-06-at-5.32.05-pm" data-image-description="" data-medium-file="https://zandernethercutt.files.wordpress.com/2019/03/screen-shot-2019-03-06-at-5.32.05-pm.png?w=227" data-large-file="https://zandernethercutt.files.wordpress.com/2019/03/screen-shot-2019-03-06-at-5.32.05-pm.png?w=564" src="https://zandernethercutt.files.wordpress.com/2019/03/screen-shot-2019-03-06-at-5.32.05-pm.png" alt=""><figcaption>Illustration: Jutta Kuss/Getty Images</figcaption></figure>



<p><strong>Author‚Äôs Note</strong>: I‚Äôve recently partnered with <a href="https://diginthere.com/">Project DigInThere</a>, an online project to help people get more out of the articles they read. <a href="https://diginthere.com/">Project DigInThere</a> enables authors (in this case, me) to create 3-4 question ‚Äúquests‚Äù that readers (in this case, you) can review prior to reading an article. Doing so primes you with what to look for in the article, and then you can take the quest at the end of the article to test your recall. If you‚Äôre interested, you can review the quest I‚Äôve built by <a href="https://diginthere.com/quests/zandercutt-2019-02-17-were-optimizing-ourselves-to-death-2447316663cd/view">clicking here</a>, then take it after reading the article and see how you do. Or you can just read the article ‚Äî it‚Äôs up to you ;).</p>



<hr>



<p><strong>pro¬∑cel¬∑er¬∑a¬∑tion</strong></p>



<p>/pr≈çÀåsel…ôÀàrƒÅSH(…ô)n/</p>



<p><em>noun</em></p>



<ol><li>The acceleration of acceleration</li></ol>



<p>‚Äî excerpt from <em>The Age of Earthquakes</em>, by Shannon Basar, Douglas Coupland, and Hans Ulrich Obrist</p>



<hr>



<p>There‚Äôs a famous thought experiment in economics known as the ‚Äúprisoner‚Äôs dilemma.‚Äù In it, two men have been caught committing a crime. Each of them is placed in a separate interrogation room and effectively has two options: confess or lie. There are three possible outcomes (the payoffs of which are illustrated in the payoff matrix below):</p>



<p><strong>Outcome 1</strong>: Both confess, and both serve eight years in prison (illustrated by payoff ‚Äú-8, -8‚Äù in Figure A).</p>



<figure><img src="https://zandernethercutt.files.wordpress.com/2019/02/cec19-1vvzfhu09tthxuusxda1zeg.png" alt=""><figcaption>Figure A: The Prisoner‚Äôs Dilemma. Credit:&nbsp;Author</figcaption></figure>



<p><strong>Outcome 2</strong>: Both men lie, and both serve one year in prison (illustrated by payoff ‚Äú-1, -1‚Äù in Figure A).</p>



<p><strong>Outcome 3</strong>: One man confesses while the other lies. The liar serves the longest possible sentence, 10 years, while the confessor goes free (illustrated by payoff ‚Äú-10, 0‚Äù in Figure A).</p>



<p>So, if both men lie, they both get off with a lighter sentence. That appears to be the full story‚Ää‚Äî‚Ääexcept it isn‚Äôt.</p>



<p>The importance of the prisoner‚Äôs dilemma is understanding that in selecting a strategy, each player should account for the effectiveness of that strategy given what the other player might do.</p>



<p>Knowing this, consider the game from the perspective of Prisoner 1. If he thinks Prisoner 2 will lie, he should confess, because serving zero years in prison is better than serving one. If he thinks Prisoner 2 will confess, he should also confess, because serving eight years in prison is better than serving 10. In this situation, confessing is both players‚Äô dominant strategy, the strategy they should play regardless of what the other player does.</p>



<p>This thought experiment illustrates how two self-interested individuals with a clear way to maximize their collective utility fail to do so. It also happens to be a fantastic way to understand our current moment. Millennials‚Ää‚Äî‚Äänot all of us, but many of us‚Ää‚Äî‚Ääare burned out, and the prisoner‚Äôs dilemma can shed light on why.</p>



<p>Unfortunately, it also sheds light on a distressing conclusion: Barring some miracle of human coordination, our quest to optimize our lives will never slow, let alone stop. If anything, it will accelerate.</p>



<hr>



<p>Imagine a two-player labor market represented by the prisoner‚Äôs dilemma matrix. Now imagine both players encountered a service that would help optimize their lives. For a real-world example (and one I use), let‚Äôs take the premade meal delivery service Freshly.</p>



<p>Freshly claims to save people approximately two hours a week in the time they don‚Äôt have to spend grocery shopping, meal prepping, or cooking. Now imagine that both players had two choices of how they could spend those hours: either on extra leisure (e.g., sleep, Netflix, a book, etc.,) or on productivity (e.g., optimization/work).</p>



<p>What would each player choose?</p>



<p>Well, if wealth is considered freedom from busyness, or freedom to spend your time as you wish, the hour would be best spent on leisure. When forming a strategy, however‚Ää‚Äî‚Äälike with the prisoner‚Äôs dilemma‚Ää‚Äî‚Ääplayers must consider those strategies in the context of what the other players in the game might do. Consider the adjusted payoff matrix below:</p>



<p><strong>Outcome 1</strong>: Both players use the time afforded by the service‚Äôs convenience to optimize/work harder and thus remain in a state of constant acceleration (illustrated by payoff ‚Äú1, 1‚Äù in Figure B).</p>



<figure><img src="https://zandernethercutt.files.wordpress.com/2019/02/92958-1qccvg4lbzz4zmcjpbuhs6w.png" alt=""><figcaption>Figure B: The Millennial Dilemma (leisure vs. work). Credit:&nbsp;Author.</figcaption></figure>



<p><strong>Outcome 2</strong>: Both players use the time afforded by the service‚Äôs convenience to relax (illustrated by payoff ‚Äú8, 8‚Äù in Figure A).</p>



<p><strong>Outcome 3</strong>: Player 1 uses the time afforded by the service‚Äôs convenience to optimize/work harder, while Player 2 uses it to relax. Player 1 reaps the benefits of being the only provider of labor in a market and corners it. Player 2 languishes as the world accelerates endlessly and leaves him behind (illustrated by payoff ‚Äú10, 0‚Äù in Figure A).</p>



<p>Borrowing earlier analysis, it‚Äôs clear that given the payoffs, both players have a dominant strategy: work. If Player 2 relaxes, Player 1 should work because a payoff of 10 is better than a payoff of 8. If the Player 2 works, Player 1 should also work because a payoff of 1 is better than a payoff of zero.</p>



<p>Now, remember, these payoffs‚Ää‚Äî‚Ääand their explanations‚Ää‚Äî‚Ääare completely made up. In the modern era, there is no reason to be convinced that torturing yourself with additional employment is associated with any improvement in your lifestyle. And yet this is exactly how most people behave.</p>



<p>Thus, we arrive at our new Nash equilibrium: Both players use a service‚Ää‚Äî‚Äämind you, a service built to supposedly make their lives easier and more relaxing‚Ää‚Äî‚Ääthat ends up making their lives more stressful and complex. Put another way, both players burn out.</p>



<hr>



<p>In a recent viral BuzzFeed article, ‚Äú<a href="https://www.buzzfeednews.com/article/annehelenpetersen/millennials-burnout-generation-debt-work" rel="noreferrer noopener" target="_blank">How Millennials Became The Burnout Generation</a>,‚Äù Anne Helen Petersen notes this seeming paradox of leisure, specifically as it pertains to freed up time. She writes:</p>



<blockquote><p>Attempts [by companies] to discourage working ‚Äúoff the clock‚Äù misfire, as millennials read them not as permission to stop working, but a means to further distinguish themselves by being available anyway.</p></blockquote>



<p>In other words: Attempts by companies like Google or Freshly to create services that save you time misfire, as millennials see them not as services that will give them more time to relax, but as services that will increase the amount of time they‚Äôre available to work.</p>



<p>As employees in a hyperproductive, work-obsessed world, we‚Äôve become acutely aware of any opportunity for optimization. Our Instagram feeds are filled with every possible combination of meal delivery service and online shopper that exists. Startups emerge daily to automate every mundane activity ever scrawled on and scratched off a legal pad.</p>



<p>The escalators I take to work are filled with the same desperate faces and vacant eyes I feel staring through me on the subway, except instead of standing still, they‚Äôre bounding up it, subconsciously aware that below their feet is yet another opportunity to optimize on an existing convenience. This, if anything, is a symptom of our current moment: People ignoring the luxury of a moving staircase in favor of whatever sprinting up it can transport them to faster.</p>



<p>There‚Äôs a kind of sick satisfaction derived from optimizing one‚Äôs own life, and there‚Äôs a good reason: Being able to do so is a status symbol. Only the most successful are free enough to spend their time finding better ways to spend their time. For those at the very top, I imagine these methods of optimization can actually exist in a vacuum; billionaires can optimize for the sake of optimizing, rather than to keep their head above water. For the rest of the world, optimization is a survival mechanism. To them, the tools that are luxuries to those at the top are good for one thing and one thing only: freeing up time that is only ever used to get more done.</p>



<hr>



<p>The one bright side to all this productivity should be that everyone makes more money, but that‚Äôs all too often not the case. The popular narrative is that we‚Äôre all working harder, but ‚Äúwages haven‚Äôt risen in 40 years,‚Äù and ‚Äúpurchasing power is lower now than any point in recent memory.‚Äù The economist in me has always struggled with this line of thinking. Wages are only truly relevant indicators of wealth in the sense that they allow you increased control over how you spend your time. If you‚Äôre earning a wage and a service comes along that saves you the time and effort you‚Äôd normally have to expend to access a certain good (read: Freshly for meals), that service effectively increases the value of your existing wage. Thus, even though you‚Äôre not earning any more money, you‚Äôre now wealthier.</p>



<p>For consumers, services like Google and Freshly do exactly this.</p>



<p>The media, though‚Ää‚Äî‚Ääand a select few politicians‚Ää‚Äî‚Ääprefer a different narrative. ‚ÄúThere‚Äôs a finite amount of money in the world,‚Äù they effectively claim, ‚Äúand since we‚Äôre making less, and tech companies are making more, it follows that tech companies are to blame for wage stagnation, which is a net bad, always.‚Äù</p>



<p>Reality, though, isn‚Äôt that simple.</p>



<p>Though companies like Google and Amazon do generate healthy‚Ää‚Äî‚Ääand yes, <a href="https://tradingeconomics.com/united-states/corporate-profits" rel="noreferrer noopener" target="_blank">quite frankly absurd</a>‚Ää‚Äî‚Ääreturns for their executive teams and shareholders, they‚Äôre valuable because people find whatever they offer to be worth more than whatever they‚Äôre being asked to pay for it. In the case of Google, that offering is time (via frictionless access to information), and its price is effectively zero. The partial rationalization I make for stagnant wages, then, is that Google and services like it allow people to get more out of the same wage.</p>



<p>In this world, Google and its contemporaries are to blame for wage stagnation, but only because they‚Äôre creating a world where wages are no longer necessarily synonymous with wealth. Ergo, wage stagnation at the hands of tech companies‚Ää‚Äî‚Ääeveryone‚Äôs favorite narrative‚Ää‚Äî‚Ääis a feature, not a bug.</p>



<p>The problem with this line of thinking, though, gets at the root of both the millennial ‚Ä¶</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://zandercutt.com/2019/02/18/were-optimizing-ourselves-to-death/">https://zandercutt.com/2019/02/18/were-optimizing-ourselves-to-death/</a></em></p>]]>
            </description>
            <link>https://zandercutt.com/2019/02/18/were-optimizing-ourselves-to-death/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25180229</guid>
            <pubDate>Sun, 22 Nov 2020 19:25:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What Makes a Great Product Manager]]>
            </title>
            <description>
<![CDATA[
Score 157 | Comments 50 (<a href="https://news.ycombinator.com/item?id=25179296">thread link</a>) | @laybak
<br/>
November 22, 2020 | https://informedpm.com/posts/great-product-manager | <a href="https://web.archive.org/web/*/https://informedpm.com/posts/great-product-manager">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
          <p><span>What sets great product managers apart from merely good ones? </span></p> <p><span>It is a difficult question to answer because there are so many things that "great" product managers do. And because the discipline itself is changing very quickly. There is no universal answer. But it is a question worth asking.</span></p> <p><span>I tackled this question by interviewing industry leaders, drawing on my own experience, and research. </span></p> <p><span>Here are the top traits, principles, and tactics I collected, that great product managers tend to share.</span></p>  <p><h3><span>Data + Intuition</span></h3></p> <p><span>As product managers, we face many decisions every day. But what does "effective decision making" mean?</span></p> <p><span>Being "data-driven" is a good start. But the term is so overused that it has lost its meaning. It also has its blind spots. </span></p> <p><span>Here is how </span> <a href="https://twitter.com/trevin" target="_blank"><span>Trevin Chow</span></a> <span>, Director of Product at Nike, put it:</span></p> <div><blockquote><span>Great product managers are able to find the right balance between data and intuition at any given moment to inform and drive their decision making. This could be something as small a bug fix, or something much larger such as which features to include in a v1 vs what to cut.

The best product managers I've worked with are able to do this very well, balancing all sorts of inputs of "data" and combining it with their intuition to find the right balance of any given moment on what to index on.</span></blockquote></div>  <p><h3><span>Truth-Seeking</span></h3></p> <p><span>Both scientists and product managers play a truth-seeking game ‚Äî scientists test their ideas in the natural world; product managers test theirs in the market.</span></p> <p><span>Ôªø</span> <a href="https://www.linkedin.com/in/danielfalabella" target="_blank"><span>Daniel Falabella</span></a> <span>, Director of Product at Duolingo, believes that "90% of a Product Manager‚Äôs job is to find 'truth'". And this is one reason why Daniel thinks that entrepreneurs make the best PMs. He added,</span></p> <div><blockquote><span>Lots of PMs go through the motions: they talk to teammates, become familiar with vanity metrics, talk to 2 users, or assume that their managers are right. They give the illusion of having the right inputs, only to pay up the price when it's time to discuss outputs.</span></blockquote></div>  <p><h3><span>Adaptable</span></h3></p> <p><span>Product managers are responsible for the success of their products. But the path to get there is rarely straight-forward.  </span></p>  <div><blockquote><span>Great PMs are adaptable. They know when to go into execution mode, and when to step back and work on strategy. They make everyone around them feel heard. At the end of the day, they make their customers and business successful, and their teams and cross functional partners want to work with them over and over again.</span></blockquote></div>   <div><blockquote><span>Underrated skill for founders: Altitude shifting. 

People are often either good at high-level strategy or atomic-level execution, but rarely both.

It's the ability to zoom out &amp; paint the 5 yr vision, and then drop down into the weeds of day-to-day, &amp; see how the two connect.</span></blockquote></div>  <p><h3><span>First Principles</span></h3></p> <p><span>Ôªø</span> <a href="https://blackboxofpm.com/" target="_blank"><span>Brandon Chu</span></a> <span>, VP Product &amp; GM of Platform at Shopify, </span> <a href="https://blackboxofpm.com/the-first-principles-of-product-management-ea0e2f2a018c" target="_blank"><span>wrote in an article</span></a> <span> that some of the best PMs he knows make their decisions based on first principles. He explained,</span></p> <div><blockquote><span>First principle thinking helps PMs because as companies scale, communicating the rationale behind historical, current, and future decisions can be simplified in a way that their team and stakeholders can rally around. </span></blockquote></div> <div><blockquote><span>This enables people around the PM to move quickly in the same direction, decouple, and make smart trade offs without their presence.</span></blockquote></div>    <p><h3><span>Deep Understanding of the Problem</span></h3></p> <p><span>It is tempting, especially for the technically-minded folks, to start with an idea for a solution and run with it. But building a great product requires understanding the problem, and understanding the person behind the problem.</span></p>  <div><blockquote><span>If you get on the ground and hear what people are suffering from, then you can have a deeper understanding of what needs to be done. It‚Äôs not just empathy. It‚Äôs being specific and zoning in on the areas of improvement based on people‚Äôs real experiences."</span></blockquote></div>  <p><span>Ôªø</span> <a href="https://twitter.com/lissijean" target="_blank"><span>Melissa Perri</span></a> <em>, </em> <span>CEO and founder of Produx Labs, </span> <a href="https://roadmunk.com/blog/melissa-perri/" target="_blank"><span>said in an interview</span></a> <span> that "
what sets a decent product manager apart from a really great product manager, is really the way they think and approach problems". She continued,</span></p> <div><blockquote><span>To me, thinking like a product manager is about problem solving. It‚Äôs about synthesizing a lot of information, understanding the system, trying to piece together what is the problem, breaking it down into small manageable chunks so you can analyze it, and then figuring out what is the right solution from there.</span></blockquote></div>  <p><h3><span>Humble and Coachable</span></h3></p> <p><span>Being humble/coachable is what Daniel (from earlier) considers the other important trait of a great product manager.</span></p> <p><span>Related to the truth-seeking point, you will be wrong a lot throughout your career. This may be a tough pill to swallow for the smart and ambitious ones. But it is an important part of growing as a person and learning to make better decisions over time.</span></p>  <p><h3><span>Evangelize</span></h3></p> <p><span>Your work isn't done when the requirements are defined, or even when the product gets shipped. </span></p>  <div><blockquote><span>If you‚Äôre not sick of saying it, you probably aren‚Äôt saying it enough. Constant communication might feel like ‚Äúfluff,‚Äù but it isn‚Äôt. Evangelism is a critical part of the role‚Äîand it‚Äôs your job to make sure the organization is aligned and swimming in the same direction.</span></blockquote></div> <p><span>And that,</span></p> <div><blockquote><span>For you [product managers], communication&nbsp;</span> <em>is</em> <span>&nbsp;a primary ‚Äúoutput,‚Äù and it should be exceptional.</span></blockquote></div>  <p><h3><span>Resourceful</span></h3></p> <p><span>There are always more things to build than there is time for. And often, you don't get as many people working on your product as you would like.</span></p> <p><span>Mastering the art of stretching resources given a tight budget is valuable.</span></p> <p><span>This could mean finding cheaper technical workarounds. This could mean ruthlessly focusing on the small number of things that will really move the needle.</span></p>  <p><h3><span>Love of Making Things</span></h3></p> <p><span>Ôªø</span> <a href="https://www.ellenchisa.com/" target="_blank"><span>Ellen Chisa</span></a> <span>, Co-founder of Dark and former VP of Product at Lola, </span> <a href="https://mokriya.com/blog/the-new-product-manager-a-conversation-with-ellen-chisa/" target="_blank"><span>said in an interview</span></a> <span> that, "You have to really love making things, but you have to be okay with not being the person actually making the thing."</span></p> <p><span>Having a genuine love for making things is powerful. This intrinsic motivation can keep you going, especially when things get difficult.</span></p> <p><span>This genuine interest also translates to you noticing other cool products in your life and building things outside of work.</span></p>  <p><h3><span>At the End of the Day</span></h3></p> <p><span>Ultimately, your responsibility as a product manager to ship successful products. To help your business and customers succeed. </span></p> <p><span>Being on top of things. Delivering results. These are attributes of a great PM that few would disagree.</span></p>  <p><h3><span>Further Readings</span></h3></p>  <p><span>Ôªø</span> <a href="https://blackboxofpm.com/the-first-principles-of-product-management-ea0e2f2a018c" target="_blank"><span>The First Principles of Product Management</span></a> <span> by Brandon Chu. It boils down product management to maximizing impact to the mission given a set of inputs and accomplishing everything through others.&nbsp;</span></p>  <p><span>Ôªø</span> <a href="https://www.lewis-lin.com/blog/2019/4/11/introducing-the-esteem-method" target="_blank"><span>ESTEEM Method</span></a> <span> by Lewis C. Lin: Execution, Superior communication skills, Tactical awareness, Extraordinary mental toughness, Exceptional team builder, Moonshot vision.</span></p>        
          
          
          <p><em>Every two weeks, I send out a newsletter with the latest product learnings and insights.</em></p>
          <p><em>Enter your email below to subscribe.</em></p>

          
        </div></div>]]>
            </description>
            <link>https://informedpm.com/posts/great-product-manager</link>
            <guid isPermaLink="false">hacker-news-small-sites-25179296</guid>
            <pubDate>Sun, 22 Nov 2020 17:41:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Opinion: On Google‚Äôs ReCAPTCHA Privacy Nightmare]]>
            </title>
            <description>
<![CDATA[
Score 46 | Comments 21 (<a href="https://news.ycombinator.com/item?id=25179248">thread link</a>) | @wikus
<br/>
November 22, 2020 | https://hfet.org/google-recaptcha-privacy-nightmare/ | <a href="https://web.archive.org/web/*/https://hfet.org/google-recaptcha-privacy-nightmare/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

	<h2>Opinion ‚Äì Google ReCAPTCHA</h2>
<p>You‚Äôre no doubt familiar with clicking on a box declaring that you are not a robot, that looks something like this:</p>
<p><img loading="lazy" src="https://hfet.org/wp-content/uploads/2020/11/e62.gif" alt="" width="383" height="102"></p>
<p>For most people, this only takes a few seconds, validates, and lets them continue on their way. However, if you‚Äôre not signed into your Google Account, don‚Äôt use Google Chrome and have any kind of tracking protection in your browser, there‚Äôs a good chance you‚Äôll be <em>treated</em> with the opportunity of helping train Google‚Äôs Machine Learning image recognition algorithms:</p>
<figure id="attachment_395" aria-describedby="caption-attachment-395"><img loading="lazy" src="https://hfet.org/wp-content/uploads/2020/11/google-recaptcha-issue-1024x707.png" alt="" width="800" height="552" srcset="https://hfet.org/wp-content/uploads/2020/11/google-recaptcha-issue-1024x707.png 1024w, https://hfet.org/wp-content/uploads/2020/11/google-recaptcha-issue-300x207.png 300w, https://hfet.org/wp-content/uploads/2020/11/google-recaptcha-issue-768x530.png 768w, https://hfet.org/wp-content/uploads/2020/11/google-recaptcha-issue.png 1200w" sizes="(max-width: 800px) 100vw, 800px"><figcaption id="caption-attachment-395"><a href="https://www.digitalinformationworld.com/2019/06/internet-users-unite-to-speak-up-against-the-inconveniences-caused-by-recaptcha.html">Image Source</a></figcaption></figure>
<p>Google has a history of mass-outsourcing free labour to the global population of internet users, with ReCAPTCHA v2, they employed the involuntarily help of millions to <a href="https://www.techradar.com/news/captcha-if-you-can-how-youve-been-training-ai-for-years-without-realising-it" target="_blank" rel="noopener noreferrer">transcribe scanned books</a>, which lead to <a href="https://www.wired.com/2013/11/google-books-2/" target="_blank" rel="noopener noreferrer">large copyright cases</a>.</p>
<p>With ReCAPTCHA v3, or the <em>I‚Äôm not a robot</em> checkbox, <a href="https://developers.google.com/recaptcha/docs/v3" target="_blank" rel="noopener noreferrer">Google tracks your usage around the website</a> it is embedded on before you even get to the Captcha form.</p>
<h3>You agree to Google‚Äôs Privacy Policy</h3>
<p>Ever clicked <em>I‚Äôm not a robot</em>? In doing so, you agree to Google‚Äôs Terms of Service and Privacy Policy.</p>
<p>Perhaps you‚Äôre thinking it‚Äôs easy to avoid, but let me assure you it isn‚Äôt ‚Äì once you start paying attention to every place using Google ReCAPTCHA v3, you‚Äôll be shocked!</p>
<p>I choose to use Firefox and DuckDuckGo, and to avoid Google services as much as possible. But if I want to do something like track a package, I have to agree to Google‚Äôs Privacy Policy.</p>
<p>Google‚Äôs tracking code is <a href="https://w3techs.com/technologies/details/ta-googleanalytics" target="_blank" rel="noopener noreferrer">on more websites than any other</a>, including Facebook.</p>
<h3>Alternatives</h3>
<p>In my opinion, Google clearly holds monopolies in many areas least of all this, and needs to be broken up. Failing this, ReCAPTCHA needs to be redesigned such that it doesn‚Äôt serve as tracking and free labour for image recognition, and instead purely serves as a validation tool. A good start to this would be making the code FOSS, and allowing webmasters to self host it, rather than relying on Google‚Äôs black box proprietary cloud services.</p>
<p><strong>If you‚Äôre a website owner and looking to replace Google ReCAPTCHA, here is a <a href="https://switching.software/replace/google-recaptcha/" target="_blank" rel="noopener noreferrer">fantastic guide</a>.<br>
</strong></p>
<p>Additionally, <a href="https://www.hcaptcha.com/" target="_blank" rel="noopener noreferrer">hCaptcha</a> is a much more privacy friendly, drop in replacement for Google ReCAPTCHA.</p>
<p><a href="https://hfet.org/feed/"><img src="https://hfet.org/wp-content/uploads/2020/11/rss_button_hfet-1.png" alt="" width="219" height="30"></a><a href="https://hfet.org/support/"><img src="https://hfet.org/wp-content/uploads/2020/11/support_button_hfet.png" alt="" width="165" height="30"></a></p>
    <div itemtype="http://schema.org/Person" itemscope="" itemprop="author"><p><img width="100" height="100" src="https://hfet.org/wp-content/uploads/2020/11/karl-swanepoel-150x150.jpg" alt="" loading="lazy" srcset="https://hfet.org/wp-content/uploads/2020/11/karl-swanepoel-150x150.jpg 150w, https://hfet.org/wp-content/uploads/2020/11/karl-swanepoel-300x300.jpg 300w, https://hfet.org/wp-content/uploads/2020/11/karl-swanepoel-20x20.jpg 20w, https://hfet.org/wp-content/uploads/2020/11/karl-swanepoel-36x36.jpg 36w, https://hfet.org/wp-content/uploads/2020/11/karl-swanepoel-48x48.jpg 48w, https://hfet.org/wp-content/uploads/2020/11/karl-swanepoel-24x24.jpg 24w, https://hfet.org/wp-content/uploads/2020/11/karl-swanepoel-96x96.jpg 96w, https://hfet.org/wp-content/uploads/2020/11/karl-swanepoel.jpg 640w" sizes="(max-width: 100px) 100vw, 100px"></p><div><p>I‚Äôm an AI &amp; Robotics Student interested in FOSS, Tech Sustainability and Data Rights. I‚Äôm also the founder of Humans For Ethical Technology.</p></div></div>	
</div></div>]]>
            </description>
            <link>https://hfet.org/google-recaptcha-privacy-nightmare/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25179248</guid>
            <pubDate>Sun, 22 Nov 2020 17:35:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The dubiousness of digitized signature services]]>
            </title>
            <description>
<![CDATA[
Score 36 | Comments 67 (<a href="https://news.ycombinator.com/item?id=25177349">thread link</a>) | @Edmond
<br/>
November 22, 2020 | https://blog.certisfy.com/2020/11/the-dubiousness-of-digitized-signature.html | <a href="https://web.archive.org/web/*/https://blog.certisfy.com/2020/11/the-dubiousness-of-digitized-signature.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<h3>
The dubiousness of digitized signature services
</h3>
</div><div>
<div id="post-body-8553362812323687543">
<div><p>Notice I referred to "digitized" instead of digital, this is a very important distinction. These services essentially offer ways to transport handwritten scribbles into digital processes. They can be anything from attaching a Microsoft paint scribble or a scan of one written on a piece of paper, to custom font generation that makes&nbsp; your signature look like you are a former president of the united states. </p><p>I wont mention any such services by name but if you've purchased a house or engaged in any sort of contract paperwork activity (leases..etc) you have likely encountered these services. Last I checked, one of these companies is worth north of $40B, no doubt reflecting the size of the market for such services.</p><p>First, what is the purpose of any signature? as the name suggests, it is primarily to ascribe provenance to something, be it an abstract thing such as a legal agreement expressed in writing or a physical object such as a painting. We also use the notion of signature to refer to a manifestation that serves as a tell-tale sign of some fact (or the truthfulness thereof) without necessarily observing the actual manifestation of the fact itself.</p><p>What is the purpose of signing a paper then? Well, it is suppose to first, attest to the fact that the entity whose identity is associated with the document is consenting to whatever it is that the paper implies. Second, your scribbles are supposed to be unique, such that someone could not forge them and fool others into accepting an agreement that the identified entity is in fact not a party to.</p><p>Hand written signatures even in the days of king Henry were more of an intellectual pretense than an effective mechanism for genuine projection of trust. That they have persisted into the 21st century is more than distressing. </p><p>We now have even the democratic franchise of voting citizens tethered to matching variations of such scribbles. My handwritten signature varies based on what I had for breakfast, so the idea that anyone would want to judge the authenticity of any document based on it would be hilarious if it weren't such a serious matter.</p><p>The entire edifice of affixing handwritten scribbles (or their digital imitations) to documents is quite mindless if the aim of signatures as described above is to be achieved.</p><p>Obviously the need for entities to affirmatively agree to conditions and to have that recorded in a way that is tamper-proof and indisputable has not gone away. However, given the purpose of signatures, it is clear that scribbles on paper or their digitized cousins are certainly not an answer. At best one can consider these services as ceremonial, in as far as they facilitate the continuation of the pre-digital processes that demand handwritten signatures.</p><p>What then is the solution to signatures in the digital era? The answer is simple and well understood (hard to believe perhaps), PKI certificates. Given that Certisfy is about leveraging PKI for trust on the internet, this is a self-serving answer but it is also a true answer.</p><p>A digital signature (not a digitized one) of a document, along with the certificate whose private key was used to generate such a signature is all that is needed to achieve the intended goal of handwritten signatures. </p><p>From a purely technical requirement perspective, you would need to add no more than two new entries to your data model to support this, a field to store the cryptographic signature and a field to store the cryptographic certificate-chain that can verify that signature. If a dispute were to emerge a century from now, you wouldn't need to hire medieval forensic experts to authenticate the document, you would simply run the signature and document through the appropriate cryptographic verification function to authenticate it.</p><p>There are of course legitimate arguments to make against PKI (some favor blockchain contracts..etc), but when the alternative is handwritten scribbles, such arguments diminish towards meaninglessness.</p></div>
</div>

</div></div>]]>
            </description>
            <link>https://blog.certisfy.com/2020/11/the-dubiousness-of-digitized-signature.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25177349</guid>
            <pubDate>Sun, 22 Nov 2020 13:39:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[When science was the best show in America]]>
            </title>
            <description>
<![CDATA[
Score 134 | Comments 158 (<a href="https://news.ycombinator.com/item?id=25177334">thread link</a>) | @CapitalistCartr
<br/>
November 22, 2020 | http://m.nautil.us/issue/93/forerunners/when-science-was-the-best-show-in-america | <a href="https://web.archive.org/web/*/http://m.nautil.us/issue/93/forerunners/when-science-was-the-best-show-in-america">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
			<p><span>O</span>n May 29, 1810, Katherine Fritsch, a sister in the Moravian Church, boarded a coach in Lititz, Pennsylvania, along with a group of her friends and began the 75-mile trek to Philadelphia. Fritsch noted in her diary the one city site she most wished to see: Peale‚Äôs Museum. On the grounds of the museum, whose two buildings sat on State House Square, with rows of trees and manicured lawns, Fritsch passed through a menagerie that included a large cage with a live eagle sitting ‚Äúright majestically on his perch‚Äîabove his head a placard with this petition on it: feed me daily for 100 years.‚Äù</p><figure data-alt="Dugatkin_BREAKER-1"><img src="http://static.nautil.us/17940_1221132d8390ea66832cf2eabd8eb668.png" width="733" alt=""><figcaption><span><strong>THE MET OF ITS TIME:</strong> Charles Willson Peale painted this self-portrait to celebrate his pioneering museum. Its goal, he wrote his friend Thomas Jefferson, was to collect subjects in nature and ‚Äúenlighten the minds of my countrymen.‚Äù</span><span>Charles Willson Peale; <i>The Artist in His Museum</i>, 1822; Oil on canvas; Courtesy of the Pennsylvania Academy of the Fine Arts, Philadelphia.&nbsp;Gift of Mrs. Sarah Harrison (The Joseph Harrison, Jr. Collection), 1878.1.2</span></figcaption></figure><p>From the yard, Fritsch went into the Peale Museum proper, through a door with ‚ÄúWhoso would learn Wisdom, let him enter here!‚Äù posted above. Fritsch walked past a turnstile that rang chimes to announce visitors. She walked up the stairs and into the Quadruped Room, which included a moose, llama, bear, bison, prong-horned antelope, hyena, and a jackal. She explored the Marine Room, overflowing with fish, amphibians, lizards, sponges, and corals. In the Long Room, glass cases were filled with hundreds of birds set against backdrops matching their natural environments; she saw insect cases in which the specimens could be rotated under a microscope. Fritsch didn‚Äôt get to see the museum‚Äôs mammoth skeleton, but noted in her diary that ‚Äúall our talk was of how delightful had been our visit to the museum.‚Äù<br></p><p>Fritsch was not the only one who felt that way. From the time Peale‚Äôs Museum had opened its doors in 1786, annual attendance had averaged more than 10,000 people. Born both of science and art, it was the first true museum in the fledgling United States and the first must-see attraction not only for Philadelphians but for visitors from around the U.S. and the world. The museum‚Äôs creator, Charles Willson Peale, saw the museum as a national good. The ‚Äúvery sinews of government are made strong by a diffused knowledge of this science,‚Äù he wrote. The museum‚Äôs success made Peale a proud man for many years. It embodied the age of Enlightenment in the new world. After a visit, the French philosopher Comte de Volney proclaimed the museum housed ‚Äúnothing but truth and reason.‚Äù But national funding for truth and reason foundered on the shore of politics. And then the circus came to town.</p><p><span>P</span>eale was born in Maryland in 1741. When he was 9, his father, a schoolteacher, died, leaving the family in poverty. Peale was apprenticed to a saddler at age 13, but spent almost as much time tinkering with mechanical devices of all sorts as he did saddling. His other interest lay in paint brushes and sketching pads. Ambitious as could be, Peale became the Colony‚Äôs most famous portrait painter. In 1771, Peale met Martha Washington and convinced her that Colonel Washington should sit for him‚Äîthe first of 25 portraits, miniatures, mezzotints, or sculptures he would do of the soon-to-be general. Peale also painted portraits of Thomas Jefferson, Benjamin Franklin, and Alexander Hamilton. He named most of his 17 children after famous painters, including Rembrandt, Rubens, and Titian.</p><p>A true autodidact, Peale saw himself as a naturalist and scientist. And any self-respecting deist of the Enlightenment should have a museum. Fortunately, Peale knew all the right people. Robert Patterson, professor of mathematics at the University of the State of Pennsylvania, gave Peale his first specimen for the museum, ‚Äúa curious fish called the paddle fish caught in the Allegheny River,‚Äù Peale wrote. Ben Franklin sent his friend the body of an angora cat that Madame Helv√©tius had given him when he departed Paris, and Washington sent the body of a just-deceased golden pheasant from the aviary of Louis XVI that the general had received as a gift from the Marquis de Lafayette. Other specimens soon came flooding in.</p><blockquote><p>Peale wrote that society raised roadblocks to women, which didn‚Äôt allow them to pursue science.</p> </blockquote><p>In a letter to Jefferson, Peale explained that his goal for the museum was to bring together ‚Äúa variety of interesting subjects of Nature ‚Ä¶ collected in one view as would enlighten the minds of my countrymen, and, demonstrate the importance of diffusing a knowledge of the wonderful and various beauties of Nature, more powerful to humanize the mind, promote harmony, and aid virtue than any ‚Ä¶ yet imagined.‚Äù<br></p><p>Peale, a former member of the Philadelphia Militia, was a true-blooded patriot. He created an effigy of a double-faced model of Benedict Arnold in a carriage, dressed in a red coat and holding a letter to Beelzebub with the devil standing behind him shaking a purse full of money. When it came to his museum, he had no intent of curating the sort of European hall that catered only to ‚Äúparticular classes of society only, or open at such turns or at such portions of time, as effectually to debar the mass of society, from participating in the improvement, and the pleasure resulting from a careful visitation,‚Äù he wrote. His museum would be open to all‚Äî‚Äúthe unwise as well as the learned.‚Äù</p><p>Peale held progressive views on women and children, and because he knew that a family-friendly venue would attract more visitors, he reached out to bring women and children into his museum. Women were not only encouraged to visit the museum, Peale wanted them to contribute to the enterprise, sending in samples and sharing ideas. Society, he believed, raised roadblocks to women ‚Äúwhich allow no time for them to devote in the arduous pursuits of science,‚Äù but, he was quick to point out, ‚Äúwhen females have devoted themselves to these pursuits they have given every demonstration of the intensity and depth of their intellectual powers.‚Äù He wanted to tap into those powers to better the museum and the plight of women.</p><figure data-alt="Dugatkin_BREAKER"><img src="http://static.nautil.us/17932_bbc90218e55a81732f0f78c16cbf2b6f.png" width="733" alt=""><figcaption><span><strong>TOM THUMB‚ÄôS BLUES:</strong> Charles Stratton (right) was a child when P.T. Barnum (left) first hired him to perform in his museum. Barnum publicized Stratton as ‚ÄúGeneral Tom Thumb,‚Äù a character who became a major attraction for the circus impresario for decades.</span><span>Wikimedia</span></figcaption></figure><p>Reverend Manasseh Cutler, a respected naturalist of the day, who had gained fame for his bravery as a chaplain during the Revolution, was an early visitor to Peale‚Äôs Museum in 1787 and was struck by the exhibits ‚Äúarranged in a most romantic and amusing manner.‚Äù He describes two dioramas‚Äîa mound with trees and an artificial pond, each the result of Peale having spent many a morning ‚Äúdressing the museum in moss.‚Äù The pond was stocked with fish, geese, ducks, cranes, and herons, ‚Äúall having the appearance of life, for their skins were admirably preserved.‚Äù On the beach around the pond Cutler was dazzled by an assortment of ‚Äúshells of different kinds, turtles, frogs, toads, lizards, water snakes, etc.‚Äù Cutler‚Äôs diary ends: ‚ÄúMr. Peale‚Äôs animals reminded me of Noah‚Äôs Ark, into which was received every kind of beast and creeping thing in which there was life. But I can hardly conceive that even Noah could have boasted of a better collection.‚Äù<br></p><p>From the outset, the museum was meant to be a collaborative effort. Jefferson, Hamilton, James Madison, Gouverneur Morris, famed astronomer David Rittenhouse, and naturalists Benjamin Smith Barton and William Barton, sat on the museum‚Äôs board of directors. But this museum was not to be some highfalutin society club. Peale turned more often to his fellow citizens than to his board of directors to contribute what they could, be it specimen or knowledge. Each year, he would publish dozens of newspaper advertisements that included not just a call for specimens, but lists of new specimens received of late, information about new exhibits, changes to museum hours of operation, and perhaps strangest to our eyes, praise or admonitions of the way the public was responding to activities at the museum.</p><p>A few years after it opened, in a series of parades, young boys (and older men) moved all the exhibits to the museum‚Äôs new home in the American Philosophical Society‚Äôs Philosophical Hall. Peale and his family moved their own home to the basement of the museum, so as to better manage the ever-growing enterprise. Soon, the museum outgrew even Philosophical Hall and moved to the State House (what we now call Independence Hall), above the rooms where the Declaration of Independence were signed, and below where a soon to be rather famous bell rang each day.</p><p><span>I</span>n 1801, Peale and a team undertook the first major paleontological excavation in the U.S. Near Newburgh, New York they dug up, and then painstakingly reconstructed, the complete skeleton of a mammoth (technically, it was a mastodon, but that distinction did not yet exist). It was quite the sight and caught the fancy of locals. ‚ÄúEvery farmer with his wife and children, for twenty miles round in every direction flocked to see the operation,‚Äù wrote Peale‚Äôs son Rembrandt. The <i>Mercantile Advertiser</i> soon ran tantalizing headlines like ‚ÄúBones of a Mammoth or some other Wonderful Animal,‚Äù titillating readers with tales of ‚Äúa monster so vastly disproportionate to every creature; as to induce a momentary suspension of every animal faculty but admiration and wonder.‚Äù</p><blockquote><p>Ben Franklin sent his friend the body of an angora cat and George Washington sent a golden pheasant.</p> </blockquote><p>In <i>Skeleton of the Mammoth</i>, a broadside that Peale posted across Philadelphia in 1802, he informed readers that though ‚Äúnumerous have been the attempts of scientific characters of all nations to procure a satisfactory collection of bones,‚Äù he and his museum had at last done just that. Peale even had one of the museum employees distribute the broadside throughout the city while on horseback ‚Ä¶</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://m.nautil.us/issue/93/forerunners/when-science-was-the-best-show-in-america">http://m.nautil.us/issue/93/forerunners/when-science-was-the-best-show-in-america</a></em></p>]]>
            </description>
            <link>http://m.nautil.us/issue/93/forerunners/when-science-was-the-best-show-in-america</link>
            <guid isPermaLink="false">hacker-news-small-sites-25177334</guid>
            <pubDate>Sun, 22 Nov 2020 13:37:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Sengi ‚Äì A FLOSS multi-account Mastodon and Pleroma desktop client]]>
            </title>
            <description>
<![CDATA[
Score 51 | Comments 11 (<a href="https://news.ycombinator.com/item?id=25177330">thread link</a>) | @blindm
<br/>
November 22, 2020 | https://nicolasconstant.github.io/sengi/ | <a href="https://web.archive.org/web/*/https://nicolasconstant.github.io/sengi/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <section>

            <p>
                    Sengi will let you use all your accounts<br> easily and seamlessly<br>
                </p>

        </section>

        

        <section>
            <h2>Quick Overview</h2>

            <video controls="">
                <source src="https://nicolasconstant.github.io/sengi/videos/Quick_overview.mp4" type="video/mp4">
                Your browser does not support the video tag.
            </video>
        </section>

        

        <section>
            <h2>Main Functionalities</h2>

            <h4>Seamless account switch</h4>
            <div>
                <p>
                        Just click on the account's avatar, <br>
                        and all your next actions will be performed by it.
                    </p>
                <p>
                    <video width="326" height="260" controls="">
                        <source src="https://nicolasconstant.github.io/sengi/videos/Clip_account_switch.mp4" type="video/mp4">
                        Your browser does not support the video tag.
                    </video>
                </p>
            </div>

            <h4>All instances timelines in one place</h4>
            <div>
                <p>
                        Add timelines and lists from all your accounts in the same
                        interface.
                    </p>
                <p><img src="https://nicolasconstant.github.io/sengi/images/timelines.png">
                </p>
            </div>

            <h4>Don't lose your focus</h4>
            <div>
                <p>
                        Opening a profile, thread, hashtag or even just replying to someone will always take place in the
                        current Timeline.
                    </p>
                <p>
                    <video width="326" height="260" controls="">
                        <source src="https://nicolasconstant.github.io/sengi/videos/Clip_timelines.mp4" type="video/mp4">
                        Your browser does not support the video tag.
                    </video>
                </p>
            </div>

            <h4>Labels</h4>
            <div>
                <p>
                        Get a quick insight if a status is part of a thread, has replies, is from a bot, is old, is
                        cross-posted (limited to local TL) or is remotely fetched.<br>
                        <a href="https://github.com/NicolasConstant/sengi/wiki/Labels">more details</a>
                    </p>
                <p><img src="https://nicolasconstant.github.io/sengi/images/labels.png">
                </p>
            </div>

            <h4>Auto-remove Thread's Content-Warnings</h4>
            <div>
                <p>
                        Easily remove all CW from a thread<br>
                        with one single click!
                    </p>
                <p>
                    <video width="326" height="260" controls="">
                        <source src="https://nicolasconstant.github.io/sengi/videos/Clip_cw_button.mp4" type="video/mp4">
                        Your browser does not support the video tag.
                    </video>
                </p>
            </div>

            <h4>And many more!</h4>

            <p>
                    There is a lot more things to discover<br> and more to come too!
                </p>

        </section>
        
    </div></div>]]>
            </description>
            <link>https://nicolasconstant.github.io/sengi/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25177330</guid>
            <pubDate>Sun, 22 Nov 2020 13:36:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Building a roam-like, networked, heavily-customized realtime editor, part 1]]>
            </title>
            <description>
<![CDATA[
Score 122 | Comments 33 (<a href="https://news.ycombinator.com/item?id=25177290">thread link</a>) | @namiheike
<br/>
November 22, 2020 | https://namiwang.github.io/2020/11/12/building-a-roam-like-networked-heavily-customized-realtime-editor-part-1.html | <a href="https://web.archive.org/web/*/https://namiwang.github.io/2020/11/12/building-a-roam-like-networked-heavily-customized-realtime-editor-part-1.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      
        <header>
          
          

  <p>
    
      
      <span>
        
        <time datetime="2020-11-12T12:21:42+00:00">November 12, 2020</time>
      </span>
    

    

    
  </p>


        </header>
      

      <section itemprop="text">
        
        

<blockquote>
  <p>I can build this.</p>

  <p>‚Äî <cite>every developer at least once</cite></p>
</blockquote>

<p>Knowledge is hard to manage, as mind is hard to materialize and visualize.</p>

<p>Bi-directional networked tools like <code>roam-research</code> and <code>obsidian</code> are on the trend for a while now. <a href="https://en.wikipedia.org/wiki/Knowledge_graph">The idea behind them</a> is not brand new, yet the much evolved web-based tech makes them possible.</p>

<h2 id="what-i-want-to-build">what I want to build</h2>

<p>I record my building of <code>fiber-note</code> in this series of dev posts, what I want to build is:</p>

<ul>
  <li>tag-based bi-directional networked note-taking</li>
  <li>web-based real-time experience
    <ul>
      <li>constantly auto-saving</li>
      <li>real-time reactive interface
        <ul>
          <li>updating components other than the editor (related notes, navigation, tags network, calendar, etc.)</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>a highly-customized editor
    <ul>
      <li>enforce a custom schema to control the layout of the documents
        <ul>
          <li>say everything is a list item, there may be only text and tags in a paragraph, etc.</li>
        </ul>
      </li>
      <li>handle meta-data like tags, assigning unique ids for the block</li>
      <li>complex UI like inline drop-down menu</li>
      <li>‚Ä¶</li>
    </ul>
  </li>
  <li>visualize data as a network and a calendar</li>
  <li>open-sourced and self-hosted</li>
</ul>

<h2 id="code--demo">code &amp; demo</h2>

<p><a href="https://github.com/namiwang/fiber-note" target="_blank">
  <img src="https://namiwang.github.io/assets/images/fiber-note.gif" width="480" alt="fiber note screenshot">
</a></p>

<p>I placed the source <a href="https://github.com/namiwang/fiber-note">here</a>, which could be hosted by yourself. There‚Äôs even a configured deploy-to-heroku button for one-click hosting.</p>

<p>I also put up a public demo running at <a href="https://fiber-note-demo.herokuapp.com/session/new">fiber-note-demo.herokuapp.com</a> (password is <code>password</code>).</p>

<h2 id="naming-the-project">naming the project</h2>

<p>I always use rails as my first choice for web projects, and the first code name for this project is <code>roam-on-rails</code>, which is a bad joke since I‚Äôve already got a project called <a href="https://github.com/ruby-on-rust/ruby-on-rust">ruby on rust</a>.</p>

<p>I‚Äôm bad at this, so I just picked the word <code>fiber</code> as a synonym for <code>network</code> from the thesaurus.</p>



<h2 id="a-prototype-on-paper">a prototype on paper</h2>

<p><a href="https://namiwang.github.io/assets/images/fiber-note-series/fiber-note-diagram.png" target="_blank">
  <img src="https://namiwang.github.io/assets/images/fiber-note-series/fiber-note-diagram.png" alt="fiber note data structure">
</a></p>

<h2 id="a-data-structure-in-mind">a data structure in mind</h2>

<p>The whole database is structured as a directed graph. The basic unit is a <code>block</code>, a node in the graph, representing a paragraph, bearing data like its content and optional tags.</p>

<p>Every block-node may have one parent. Thus a note, spawning from the root (a parent-free block-node), forms a tree and the whole database forms a forest.</p>

<p>There‚Äôre some edge cases to consider</p>

<ul>
  <li>have to avoid cycles in the graph</li>
  <li>a tag may points to the same note</li>
</ul>

<h2 id="a-data-structure-on-disk">a data structure on disk</h2>

<p>Apparently we need to maintain a graph, yet I didn‚Äôt choose a graph-oriented database like <code>neo4j</code>. Using good old SQL to simulate one is good enough for now.</p>

<p>There‚Äôre both plugins to do graph on database level (<a href="https://www.postgresql.org/about/news/announcing-age-a-multi-model-graph-database-extension-for-postgresql-2050/">AGE</a> for postgresql), and rails level (like <a href="https://github.com/jackc/edge">edge</a>). For the initial implementation, I chose to hand-written everything from the grounded up for faster iteration because I was constantly changing things.</p>



<p>This is gonna be a front-end-heavy project, I have to choose an editor as one of the first steps.</p>

<h2 id="requirements">requirements</h2>

<ul>
  <li>restrict the doc to a special set of content types
    <ul>
      <li>e.g. allow list, list item, and inline tags; disallow individual paragraphs or images</li>
    </ul>
  </li>
  <li>render existing data into the editor</li>
  <li>inspect and manipulate input from the user
    <ul>
      <li>enforce input rules like properly wrapping/indenting list items</li>
      <li>assign unique ids to created blocks</li>
    </ul>
  </li>
  <li>implement drop-down menu to auto-complete tags</li>
  <li>send updated content to the server</li>
  <li>features we may need in the future
    <ul>
      <li>copy-and-paste, drag-and-drop, image, etc.</li>
    </ul>
  </li>
</ul>

<h2 id="comparision">comparision</h2>

<table>
  <thead>
    <tr>
      <th>&nbsp;</th>
      <th>trix</th>
      <th>quill</th>
      <th>prose-mirror</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>integrating</td>
      <td>easy</td>
      <td>moderate</td>
      <td>moderate-to-high</td>
    </tr>
    <tr>
      <td>customization</td>
      <td>minimal</td>
      <td>moderate</td>
      <td>high</td>
    </tr>
    <tr>
      <td>custom schema</td>
      <td>no</td>
      <td>no</td>
      <td>yes</td>
    </tr>
    <tr>
      <td>plugins</td>
      <td>no</td>
      <td>yes</td>
      <td>yes</td>
    </tr>
    <tr>
      <td>themes</td>
      <td>no</td>
      <td>yes</td>
      <td>no</td>
    </tr>
    <tr>
      <td>docs</td>
      <td>minimal</td>
      <td>detailed</td>
      <td>detailed</td>
    </tr>
    <tr>
      <td>typescript</td>
      <td>no</td>
      <td>yes</td>
      <td>yes</td>
    </tr>
    <tr>
      <td>scenario</td>
      <td>adding rich-text editing to your rails app in 10 minutes</td>
      <td>building editor email client with some cool features like markdown syntax</td>
      <td>building editor for an collaborative encyclopaedia with custom schema.</td>
    </tr>
  </tbody>
</table>

<p>I tried a few options. At the end I settled with <a href="https://prosemirror.net/">prose-mirror</a> to build fiber-note due to thorough guides and references, up-to-date maintaining, and <a href="https://discuss.prosemirror.net/">a friendly forum</a>.</p>

<h2 id="trix">trix</h2>

<p>As a rails user, my first thought are <code>actiontext</code> and <a href="https://trix-editor.org/">trix</a>. Trix is perfect for adding out-of-box rich-text editing to a normal rails app, like rails, it just works.</p>

<p>It‚Äôs just hard to tweak for more custom features.</p>

<ul>
  <li>it completely intertwined with rails‚Äô components like <code>actionview</code> (rendering) and <code>activestorage</code> (image uploading), it‚Äôs hard to mutate the saved content without hacking into hidden methods.</li>
  <li>it saves content as raw HTML fragment, which is bad because
    <ul>
      <li>unique content have multiple legit representations</li>
      <li>it‚Äôs slow to parse and manipulate the content (say tags detection, image processing, table mutation, etc.)</li>
    </ul>
  </li>
  <li>it doesn‚Äôt come with detailed docs/specs about the format of generated HTML docs, which is not reliable when you system relies on processing the content on-the-fly.</li>
  <li>minimal events not enough to compose complex logic around the user‚Äôs operation</li>
</ul>

<h2 id="quill">quill</h2>

<p><a href="https://quilljs.com/">quill</a> is another competitive  candidate, regarding elaborated docs, data format specs, themes, and typescript support.</p>

<p>It‚Äôs easy to integrate the library, tweak some configurations, and apply different themes. You can add markdown syntax support in like 10 minutes.</p>

<p>It‚Äôs not easy to limit what kind of content is allowed in the document, or what would happen if a special formatted text is pasted.</p>

<p>It‚Äôs hard to pragmatically control the mutation of the data to manually implement functions like ‚Äúcreate another list item with the same indent when <em>return</em> is pressed and current cursor on the end of a list item, including the end of an inline span of a list item‚Äù.</p>

<p>It‚Äôs not impossible, yet it will get over-complicated if you need many mutations like this.</p>

<h2 id="prose-mirror">prose-mirror</h2>

<p><code>prose-mirror</code> has the most complicated structure.  You have to import <strong>at least ten packages</strong> to build a simple demo, each managing a single aspect of the editor (model, view, schema definitions, keymaps, etc.).</p>

<p>There‚Äôs a starter kit kind of package (<code>prosemirror-example-setup</code>) which makes the journey a little bit easier. I‚Äôd recommend that kit to users who demand only basic features, while for complex functions you‚Äôll have to compose each part and piece them together for better control. It‚Äôs like how advanced users almost never want the pre-set default preferences or <code>rails scaffold</code>.</p>

<p>Verbosity and redundancy means total control and vice versa, it just have to be like this. You posses the ability to custom the schema, listen to each key press, oversee every transaction of the model, and to arrange how to create (also parse, and wrap, and truncate during drag-n-drop, etc.) different kind of element.</p>

<p>You‚Äôll spend a lot of time jumping between the <a href="https://prosemirror.net/docs/guide/">guides</a>, the <a href="https://prosemirror.net/docs/ref/">references for individual packages</a>, and even the source code. I can promise you that the guide will be a great read about the designing of a complicated modular system.</p>



<p>Thanks for reading. In the next post, I‚Äôll discuss how I built and tweaked the editor.</p>

        
      </section>

      

      

      
  

    </div></div>]]>
            </description>
            <link>https://namiwang.github.io/2020/11/12/building-a-roam-like-networked-heavily-customized-realtime-editor-part-1.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25177290</guid>
            <pubDate>Sun, 22 Nov 2020 13:31:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Booting from a vinyl record]]>
            </title>
            <description>
<![CDATA[
Score 940 | Comments 156 (<a href="https://news.ycombinator.com/item?id=25177045">thread link</a>) | @ruik
<br/>
November 22, 2020 | http://boginjr.com/it/sw/dev/vinyl-boot/ | <a href="https://web.archive.org/web/*/http://boginjr.com/it/sw/dev/vinyl-boot/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>http://boginjr.com/it/sw/dev/vinyl-boot/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25177045</guid>
            <pubDate>Sun, 22 Nov 2020 12:51:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[S230 is a censorship law masquerading as a friend of free speech]]>
            </title>
            <description>
<![CDATA[
Score 52 | Comments 70 (<a href="https://news.ycombinator.com/item?id=25177003">thread link</a>) | @mikerthomsen
<br/>
November 22, 2020 | https://mikethomsen.github.io/posts/2020/11/16/s230-the-two-faced-free-speech-law | <a href="https://web.archive.org/web/*/https://mikethomsen.github.io/posts/2020/11/16/s230-the-two-faced-free-speech-law">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://mikethomsen.github.io/posts/2020/11/16/s230-the-two-faced-free-speech-law</link>
            <guid isPermaLink="false">hacker-news-small-sites-25177003</guid>
            <pubDate>Sun, 22 Nov 2020 12:44:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Swizzle Clogging]]>
            </title>
            <description>
<![CDATA[
Score 26 | Comments 7 (<a href="https://news.ycombinator.com/item?id=25176931">thread link</a>) | @mkj
<br/>
November 22, 2020 | https://apple.github.io/foundationdb/testing.html | <a href="https://web.archive.org/web/*/https://apple.github.io/foundationdb/testing.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="correctness-and-performance">
<h2>Correctness and Performance</h2>
<p>Rigorous testing is central to our engineering process. The <a href="https://apple.github.io/foundationdb/features.html"><span>features of our core</span></a> are challenging, requiring us to meet exacting standards of correctness and performance. Data guarantees and transactional integrity must be maintained not only during normal operations but over a broad range of failure scenarios. At the same time, we aim to achieve performance goals such as low latencies and near-linear scalability. To meet these challenges, we use a combined regime of robust simulation, live performance testing, and hardware-based failure testing.</p>
</div><div id="simulation">
<h2>Simulation</h2>
<p>Simulation is a powerful tool for testing system correctness. Our simulation technology, called Simulation, is enabled by and tightly integrated with <a href="https://apple.github.io/foundationdb/flow.html"><span>Flow</span></a>, our programming language for actor-based concurrency. In addition to generating efficient production code, Flow works with Simulation for simulated execution.</p>
<p>The major goal of Simulation is to make sure that we find and diagnose issues in simulation rather than the real world. Simulation runs tens of thousands of simulations every night, each one simulating large numbers of component failures. Based on the volume of tests that we run and the increased intensity of the failures in our scenarios, we estimate that we have run the equivalent of roughly one trillion CPU-hours of simulation on FoundationDB.</p>
<p>Simulation is able to conduct a <em>deterministic</em> simulation of an entire FoundationDB cluster within a single-threaded process. Determinism is crucial in that it allows perfect repeatability of a simulated run, facilitating controlled experiments to home in on issues. The simulation steps through time, synchronized across the system, representing a larger amount of real time in a smaller amount of simulated time. In practice, our simulations usually have about a 10-1 factor of real-to-simulated time, which is advantageous for the efficiency of testing.</p>
<p>We run a broad range of simulations testing various aspects of the system. For example, we run a cycle test that uses key-values pairs arranged in a ring that executes transactions to change the values in a manner designed to maintain the ring‚Äôs integrity, allowing a clear test of transactional isolation.</p>
<p>Simulation simulates all physical components of a FoundationDB system, beginning with the number and type of machines in the cluster. For example, Simulation models drive performance on each machine, including drive space and the possibility of the drive filling up. Simulation also models the network, allowing a small amount of code to specify delivery of packets.</p>
<p>We use Simulation to simulate failures modes at the network, machine, and datacenter levels, including connection failures, degradation of machine performance, machine shutdowns or reboots, machines coming back from the dead, etc. We stress-test all of these failure modes, failing machines at very short intervals, inducing unusually severe loads, and delaying communications channels.</p>
<p>For a while, there was an informal competition within the engineering team to design failures that found the toughest bugs and issues the most easily. After a period of one-upsmanship, the reigning champion is called ‚Äúswizzle-clogging‚Äù. To swizzle-clog, you first pick a random subset of nodes in the cluster. Then, you ‚Äúclog‚Äù (stop) each of their network connections one by one over a few seconds. Finally, you unclog them in a random order, again one by one, until they are all up. This pattern seems to be particularly good at finding deep issues that only happen in the rarest real-world cases.</p>
<p>Simulation‚Äôs success has surpassed our expectation and has been vital to our engineering team. It seems unlikely that we would have been able to build FoundationDB without this technology.</p>
</div><div id="performance-testing-with-circus">
<h2>Performance testing with Circus</h2>
<p>In addition to simulation, we continually run systematic performance tests on FoundationDB. Every night, we run an automated suite of performance tests using our ‚ÄúCircus‚Äù environment.</p>
<p>For each Circus test, we specify the characteristics of the database to be used, e.g., 2 billion key-value pairs with 16 byte keys and randomly generated 8-100 byte values. The test selects the workloads to run and the cluster to run them on. Workloads specify the characteristics and proportions of reads and writes to be performed. (See our <a href="https://apple.github.io/foundationdb/performance.html"><span>Performance</span></a> page for representative examples.) A test can run workloads either in parallel or sequentially. Workloads are specified using the same code as for simulation, which benefits the productivity of our testing.</p>
<p>This process give us a daily comparison of the performance of the current code base to previous days. Performance is measured across many dimensions derived from the output of many tests. Our data exploration technology allows this output to be graphically explored, with the ability to isolate and examine key performance indicators.</p>
</div></div>]]>
            </description>
            <link>https://apple.github.io/foundationdb/testing.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25176931</guid>
            <pubDate>Sun, 22 Nov 2020 12:31:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Linux Applications Performance: Introduction (2019)]]>
            </title>
            <description>
<![CDATA[
Score 37 | Comments 4 (<a href="https://news.ycombinator.com/item?id=25176637">thread link</a>) | @todsacerdoti
<br/>
November 22, 2020 | http://unixism.net/2019/04/linux-applications-performance-introduction/ | <a href="https://web.archive.org/web/*/http://unixism.net/2019/04/linux-applications-performance-introduction/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-8">
		
	
	<div>
		
<h4>Articles in this series</h4>



<ol><li><a href="https://unixism.net/2019/04/28/linux-applications-performance-part-i-iterative-servers/">Part I. Iterative Servers</a></li><li><a href="https://unixism.net/2019/04/28/linux-applications-performance-part-ii-forking-servers/">Part II. Forking Servers</a></li><li><a href="https://unixism.net/2019/04/28/linux-applications-performance-part-iii-preforked-servers/">Part III. Pre-forking Servers</a></li><li><a href="https://unixism.net/2019/04/28/linux-applications-performance-part-iv-threaded-servers/">Part IV. Threaded Servers</a></li><li><a href="https://unixism.net/2019/04/28/linux-applications-performance-part-v-pre-threaded-servers/">Part V. Pre-threaded Servers</a></li><li><a href="https://unixism.net/2019/04/28/linux-applications-performance-part-vi-polling-servers/">Part VI: poll-based server</a></li><li><a href="https://unixism.net/2019/04/28/linux-applications-performance-part-vii-epoll-servers/">Part VII: epoll-based server</a></li></ol>



<h4>On HackerNews</h4>



<p>There are several interesting takeaways from the <a href="https://news.ycombinator.com/item?id=20081488#20088463">HackerNews thread</a> for this article series. Do check it out.</p>



<p>Web apps are the staple of consumers and enterprises. Among the many existing protocols that are used to move and make sense of bits, HTTP has an overwhelming mind share. As you encounter and learn the nuances of web application development, most of you might pay very little  attention to the operating system that finally runs your applications. The separation of Dev and Ops only made this worse. But with the DevOps culture becoming common place and developers becoming responsible for running their apps in the cloud, it is a clear advantage to better understand backend operating system nitty-gritty. You don‚Äôt really have to bother with Linux and how your backend will scale if you are deploying your backend as a system for personal use or for use by a few concurrent users. If you are trying to deploy for thousands or tens of thousands of concurrent users, however, having a good understanding of how the operating system figures out in your whole stack will be incredibly useful. </p>



<p>The constraints we are up against in the web services we write are very similar to those in other applications that are required to make a web service or application work. Be those load balancers or the database servers. All these classes of applications have similar challenges in high-performance environments. Understanding these fundamental constraints and how to work around them will in general make you appreciate what performance and scalability of your web applications or services are up against.</p>



<p>I am writing this series in response to the questions I get asked by young developers who want to become well‚Äìinformed system architects. Without diving down into the basics of what makes Linux applications tick and the different ways of structuring Linux or Unix network applications, it is not possible to gain a through and clear understanding of Linux application performance. While there are many types of Linux applications, what I want to explore here are Linux networking‚Äìoriented applications as opposed to say, a desktop application like a browser or a text editor. This is because the audience for this series are web services/application developers and architects who want to understand how Linux or Unix applications work and how to structure these services for high performance. </p>



<p>Linux is <em>the</em> server operating system and more often than not, your applications probably run on Linux finally. Although I say Linux, most of the time you can safely assume I also include other Unix‚Äìlike operating systems in general. However, I haven‚Äôt extensively tested the accompanying code on other Unix‚Äìlike systems. So, if you are interested in FreeBSD or OpenBSD, your mileage may vary. Where I attempt anything Linux-specific, I‚Äôve done my best to point it out.</p>



<p>While you can certainly use this knowledge to choose the best possible structure for a new network application you want to write from scratch, you might not be firing up your favorite text editor and writing a web server in C or C++ to solve the problem of having to deliver the next business app in your organization. That might be a guaranteed way to get yourself fired. Having said that, knowing these application structures will help you tremendously in choosing one among a few existing applications, if you know how they are structured. After understanding this article series, you will be able to appreciate process‚Äìbased vs. thread‚Äìbased vs. event‚Äìbased systems. You will get to understand and appreciate why Nginx performs better than Apache httpd or why a Tornado based Python application might be able to serve more concurrent users compared to a Django based Python application.</p>



<h3>ZeroHTTPd: A learning tool</h3>



<p><a href="https://github.com/shuveb/zerohttpd">ZeroHTTPd</a> is a web server I wrote from scratch in C as a teaching tool. It has no external dependencies, including for Redis access. We roll our own Redis routines‚Äìread more below.</p>



<p>While we could talk a whole lot of theory, there is nothing like writing code, running it, benchmarking it to compare each of server architectures we evolve. This should cement your understanding like no other method. To this end, we will develop a simple web server called ZeroHTTPd using process‚Äìbased, thread‚Äìbased and event‚Äìbased models. We will benchmark our each of these servers and see how they perform relative to one another. ZeroHTTPd is a simple‚Äìas‚Äìpossible HTTP server written from scratch in pure C with no external library dependencies. It is implemented in a single C file. For event-based servers, I include <a href="https://troydhanson.github.io/uthash/">uthash</a>, an excellent hash table implementation, which is comes in a single header file. Otherwise, there are no dependencies and this is to keep things simple.</p>



<p>I‚Äôve heavily commented the code to aid understanding. ZeroHTTPd is also a bare minimal web development framework apart from being a simple web server written in a couple of hundred lines of C. It doesn‚Äôt do a lot. But, it can server static files and  very simple ‚Äúdynamic‚Äù pages. Having said this, ZeroHTTPd is well-suited for you to understand how to architect your Linux applications for high-performance. At the end of the day, most web services wait around for requests, look into what that request is and process them. This is exactly what we will be doing with ZeroHTTPd as well. It is a learning tool, not something you‚Äôll use in production. It is also not going to win awards for error handling, security best practices (oh yes, I‚Äôve used <code>strcpy</code>) or for clever tricks and shortcuts of the C language, of which there are several. But, it‚Äôll hopefully serve its purpose well (pun unintended).</p>



<div data-carousel-extra="{&quot;blog_id&quot;:1,&quot;permalink&quot;:&quot;https:\/\/unixism.net\/2019\/04\/linux-applications-performance-introduction\/&quot;}"><figure><img data-attachment-id="59" data-permalink="https://unixism.net/2019/04/linux-applications-performance-introduction/zerohttpd_static/" data-orig-file="https://unixism.net/wp-content/uploads/2019/02/ZeroHTTPd_static.png" data-orig-size="868,666" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="ZeroHTTPd_static" data-image-description="" data-medium-file="https://unixism.net/wp-content/uploads/2019/02/ZeroHTTPd_static.png" data-large-file="https://unixism.net/wp-content/uploads/2019/02/ZeroHTTPd_static.png" src="https://unixism.net/wp-content/uploads/2019/02/ZeroHTTPd_static.png" alt="" data-lazy-src="https://unixism.net/wp-content/uploads/2019/02/ZeroHTTPd_static.png?is-pending-load=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption>Here we see ZeroHTTPd‚Äôs index page. It can serve various file types, including images.<br></figcaption></figure></div>



<h4>The Guestbook App</h4>



<p>Modern web applications hardly serve just static files. They have complex interactions with various databases, caches, etc. To that end, we build a simple web app named ‚ÄúGuestbook‚Äù that lets guests lovingly leave their name and remarks. Guestbook also lists remarks previously left by various guests as well. There is also a visitor counter towards the bottom of the page.</p>



<div data-carousel-extra="{&quot;blog_id&quot;:1,&quot;permalink&quot;:&quot;https:\/\/unixism.net\/2019\/04\/linux-applications-performance-introduction\/&quot;}"><figure><img data-attachment-id="63" data-permalink="https://unixism.net/2019/04/linux-applications-performance-introduction/zerohttpd_guestbook/" data-orig-file="https://unixism.net/wp-content/uploads/2019/02/ZeroHTTPd_Guestbook.png" data-orig-size="913,1250" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="ZeroHTTPd_Guestbook" data-image-description="" data-medium-file="https://unixism.net/wp-content/uploads/2019/02/ZeroHTTPd_Guestbook.png" data-large-file="https://unixism.net/wp-content/uploads/2019/02/ZeroHTTPd_Guestbook.png" src="https://unixism.net/wp-content/uploads/2019/02/ZeroHTTPd_Guestbook.png" alt="" data-lazy-src="https://unixism.net/wp-content/uploads/2019/02/ZeroHTTPd_Guestbook.png?is-pending-load=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption>The ZeroHTTPd ‚ÄúGuestbook‚Äù web app</figcaption></figure></div>



<p>We store the visitor counter and the guest book entries in Redis. To talk to Redis, we do not depend on an external library. We have our own custom C routines to talk to Redis. I‚Äôm not big fan of rolling out your own stuff when you can use something that is already available and well tested. But the goal of ZeroHTTPd is to teach Linux performance and accessing external services while in the middle of serving an HTTP request has a huge implications as far as performance goes. We need to be in full control of the way we talk to Redis in each of the server architectures we are building. While in one architecture we use blocking calls, in others we use event-based routines. Using an external Redis client library won‚Äôt allow us this control. Also, we will be implementing our own Redis client only to the extent we will use Redis (Getting, setting and incrementing a key. Getting and appending to an array). Moreover, the Redis protocol is super elegant and simple. Something to even learn about deliberately. The very fact that you can implement a super-fast protocol that does its job in about 100 lines of codes goes to say a lot about how well thought out the protocol is. </p>



<p>The following figure illustrates the steps we follow in order to get the HTML ready to serve when a client (browser) requests the <code>/guestbook</code>URL.</p>



<div data-carousel-extra="{&quot;blog_id&quot;:1,&quot;permalink&quot;:&quot;https:\/\/unixism.net\/2019\/04\/linux-applications-performance-introduction\/&quot;}"><figure><img data-attachment-id="81" data-permalink="https://unixism.net/2019/04/linux-applications-performance-introduction/guestbook-flow/" data-orig-file="https://unixism.net/wp-content/uploads/2019/04/Guestbook-Flow.png" data-orig-size="944,88" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Guestbook Flow" data-image-description="" data-medium-file="https://unixism.net/wp-content/uploads/2019/04/Guestbook-Flow.png" data-large-file="https://unixism.net/wp-content/uploads/2019/04/Guestbook-Flow.png" src="https://unixism.net/wp-content/uploads/2019/04/Guestbook-Flow.png" alt="" data-lazy-src="https://unixism.net/wp-content/uploads/2019/04/Guestbook-Flow.png?is-pending-load=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption>Guestbook app flow</figcaption></figure></div>



<p>When a Guestbook page needs to be served, there is one file-system call to read the template into memory and three network-related calls to Redis. The template file has most of the HTML content that makes up the Guestbook page you see in the screenshot above. It also has special placeholders where the dynamic part of the content which comes from Redis like guest remarks and the visitor counter go. We fetch these from Redis, replace these for the placeholders in the template file and finally, the fully formed content is written out to the client. The third call to Redis could have been avoided since Redis returns the new value of any incremented key. However, for our purposes, as we move our server to asynchronous, event-based architectures, having a server that is busy blocking on a bunch of network calls is a good way to learn about things. So, we discard the return value that Redis returns when we increment the visitor count and read it back in a separate call.</p>



<h3>ZeroHTTPd Server Architectures</h3>



<p>We will build ZeroHTTPd, retaining the same functionality, using 7 different architectures:</p>



<ul><li>Iterative</li><li>Forking (one child process per request)</li><li>Pre-forked server (pre-forked processes)</li><li>Threaded (one thread per request)</li><li>Pre-threaded (threads pre-created)</li><li><code>poll()</code>-based </li><li><code>epoll</code> based</li></ul>



<p> We shall also measure the performance of each architecture loading them each with 10,000 HTTP requests. However, as we move on to comparisons with architectures that can handle a lot more concurrency, we will switch to testing with 30,000 requests. We test 3 times and consider the average.</p>



<h3>Testing Methodology</h3>



<div data-carousel-extra="{&quot;blog_id&quot;:1,&quot;permalink&quot;:&quot;https:\/\/unixism.net\/2019\/04\/linux-applications-performance-introduction\/&quot;}"><figure><img data-attachment-id="83" data-permalink="https://unixism.net/2019/04/linux-applications-performance-introduction/zerohttpd-testing-2/" data-orig-file="https://unixism.net/wp-content/uploads/2019/04/ZeroHTTPd-Testing-1.png" data-orig-size="614,198" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="ZeroHTTPd Testing" data-image-description="" data-medium-file="https://unixism.net/wp-content/uploads/2019/04/ZeroHTTPd-Testing-1.png" data-large-file="https://unixism.net/wp-content/uploads/2019/04/ZeroHTTPd-Testing-1.png" src="https://unixism.net/wp-content/uploads/2019/04/ZeroHTTPd-Testing-1.png" alt="" data-lazy-src="https://unixism.net/wp-content/uploads/2019/04/ZeroHTTPd-Testing-1.png?is-pending-load=1" srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption>The ZeroHTTPd load testing setup</figcaption></figure></div>



<p>It is important that these tests not be run with all components on the same machine. If that is done, the operating system will have the extra overhead of scheduling between all those components, as they vie for CPU. Measuring operating system overhead with each of the chosen server architectures is one of the most important aims of this exercise. Adding more variables will be detrimental to the process. Hence, a setup described in the illustration above will work best.</p>



<h4>Here is what each of these servers do:</h4>



<ul><li>load.unixism.net‚Ä¶</li></ul></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://unixism.net/2019/04/linux-applications-performance-introduction/">http://unixism.net/2019/04/linux-applications-performance-introduction/</a></em></p>]]>
            </description>
            <link>http://unixism.net/2019/04/linux-applications-performance-introduction/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25176637</guid>
            <pubDate>Sun, 22 Nov 2020 11:29:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How much is YouTube worth today?]]>
            </title>
            <description>
<![CDATA[
Score 137 | Comments 161 (<a href="https://news.ycombinator.com/item?id=25176451">thread link</a>) | @elephant_burger
<br/>
November 22, 2020 | https://mannhowie.com/youtube-valuation | <a href="https://web.archive.org/web/*/https://mannhowie.com/youtube-valuation">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><blockquote>
<p><strong>How much is YouTube worth today?</strong>
<img src="https://images.ctfassets.net/vwq10xzbe6iz/6LQGeFMMp2z9YMRiOurO4g/9489b18efefac13f387cdc116c7b5ff1/IMG_CB7ACB71DC8B-1.jpeg" alt="howmuchyoutubeworth"></p>
</blockquote>
<p>Google acquired YouTube for US$1.6 billion back in 2006. We estimate YouTube to be worth up to US$170 billion in 2020, delivering Google a +100x return in under 15 years.
<img src="https://images.ctfassets.net/vwq10xzbe6iz/6YrHqLoRpqCr5w4JwDJvtI/b5a86d3af5149953770bf1814a9c473c/IMG_18657804259D-1.jpeg" alt="youtube-valuation-comparison"></p>
<p>This article will cover in-depth how we arrive at this valuation and the steps you can follow to build your own model for YouTube and to value any technology company:</p>
<p><strong>Key Sections:</strong></p>
<ol>
<li><a href="#1">5 key questions to understand YouTube‚Äôs business model</a></li>
<li><a href="#2">Building a YouTube financial forecast model</a></li>
<li><a href="#3">Preparing a final YouTube valuation</a></li>
</ol>
<p>Skip to the following links for a valuation checklist and complete financial model:</p>
<ul>
<li><a href="#4">6 Step Valuation Checklist</a></li>
<li><a href="#5">Download Free YouTube Valuation Model</a></li>
<li><a href="#alphabet">Alphabet SOTP Valuation</a></li>
</ul>
<h2><a name="1"></a>5 Key Questions to Answer</h2>
<p>To reach a valuation for YouTube, we must firstly answer 5 questions about the business:</p>
<ol>
<li><strong>Industry</strong>: What industry does it compete in?</li>
<li><strong>Customer</strong>: Who are its customers and how does it deliver them value?</li>
<li><strong>Revenue</strong>: What is its revenue model and key drivers?</li>
<li><strong>Costs</strong>: What are its major costs and how are they managed?</li>
<li><strong>Growth</strong>: What is the growth thesis?</li>
</ol>
<h3>1. What industry does YouTube compete in?</h3>
<p>YouTube is the world‚Äôs largest online video service and competes for user viewership in order to compete for digital advertising spend from businesses. YouTube‚Äôs parent is Google/ Alphabet and operates globally except China where Google is banned.</p>
<p>Global ad spend (ex China) is over half a trillion dollars annually, of which half is spent on digital (web and mobile). The lion‚Äôs share of this is dominated by Google and Facebook which capture over 80% of digital ad spend.</p>
<p><img src="https://images.ctfassets.net/vwq10xzbe6iz/4kzjexfgsxFPhJOyyo2jS0/9b06d17b7cc5d7e0a6b080ec5beb7bf2/globaladshare.png" alt="globaladshare"></p>
<p>Splitting up Google and Facebook‚Äôs major ad platforms we reveal YouTube is the 5th largest digital ad platform with 6% share, behind Google Search, Facebook, Google Display and Instagram.</p>
<p><img src="https://images.ctfassets.net/vwq10xzbe6iz/2EbkvWiatOFXQYBVoqNlE5/03b1f3088e0b11f783116028d2682985/globaladfbyoutube.png" alt="globaladbyproduct"></p>
<p>Future growth of the digital ad market is any oracle‚Äôs guess. But if we assume digital remains a dominant advertising medium industry, then digital spend could reach over half a trillion by 2030 (assumes 7% annual growth).</p>
<blockquote>
<p>When looking at the industry a company operates in, focus on how the company generates revenue and compare against competitors and alternative mediums. Research industry statistics and competitor annual reports to get a rough estimate of how large the current industry is.</p>
</blockquote>
<h3>2. Who are YouTube‚Äôs customers and how do they deliver them value?</h3>
<p>YouTube is an online video platform that allows content creators (individuals and businesses) to publish videos for users to watch. YouTube sells ads to businesses placed within video content and shares the revenue with publishers.</p>
<p>YouTube delivers value to 3 key stakeholders:</p>
<ul>
<li><strong>Creators</strong>: monetize their video content on the platform with the widest reach. Allows creators to focus on producing quality content and outsource hosting and marketing costs to YouTube</li>
<li><strong>Users</strong>: free, targeted and relevant video content and entertainment (for better or worse)</li>
<li><strong>Advertisers</strong>: brand impressions and targeted reach across a global audience</li>
</ul>
<p>YouTube ultimately competes for global viewership and monetizes this by selling ads to businesses. YouTube has over 2 billion monthly active users and is the second largest social media platform in the world. The chart below compares the monthly active users across major ad supported social media platforms and video platforms:</p>
<p><img src="https://images.ctfassets.net/vwq10xzbe6iz/yQISXiQ5Gh5jgiQWcYKLu/61903f1edd297535079c73c0d7b17d22/mausocial.png" alt="mausocial"></p>
<p>Whilst each player competes for viewership, their target audience and monetization models differ:</p>
<ul>
<li>Facebook, Snapchat, Instagram and Twitter  sell ads placed in a user‚Äôs social media feed of images, video, news, articles</li>
<li>Netflix sells subscription services to users for its original and purchased content</li>
<li>TikTok is early in its monetization strategy</li>
</ul>
<blockquote>
<p>When understanding how a company generates revenue, ask yourself: Who is the customer and why would they pay for the offering? For technology platform companies, understand the ecosystem of stakeholders and the benefit each of them receive from using the platform.</p>
</blockquote>
<h3>3. What is YouTube‚Äôs revenue model and key drivers?</h3>
<p>YouTube has two primary revenue streams:</p>
<ul>
<li><strong>Ad sales</strong> (90% revenue): YouTube sells targeted ads within video content across its 2 billion monthly active users. It shares ad revenue with content publishers via a 45/55 split in favour of publishers; and</li>
<li><strong>Subscription</strong> (10% revenue): YouTube premium offers an ad free video experience and music service offered at ~$10 per month. There are currently 20 million premium subscribers representing ~1% of YouTube‚Äôs total monthly active user base</li>
</ul>
<p>YouTube‚Äôs key revenue driver is its ability to monetize its monthly active user base. We can assess its performance vs peers by comparing the average annual ad spend generated by each provider divided by its monthly active user base.</p>
<p><img src="https://images.ctfassets.net/vwq10xzbe6iz/5SzsrFRvxXSiFttWKHFSxm/596bb1ecbda955f39031a46059e20178/arputitle.png" alt="arpu"></p>
<p>Facebook currently generates 2x higher ad revenue per active user than YouTube across both Facebook and Instagram platforms. This could be explained by Facebook‚Äôs greater variety of ad formats and granular audience targeting (interests, age, behaviour, lookalike audience) and being further along its journey of ad monetization.</p>
<p>The biggest driver of revenue for YouTube will likely be its ability to drive higher ad spend to its already large audience via product innovation (e.g. new ad formats, improved targeting) rather than growing its audience. YouTube is also earlier in its monetization strategy and has also invested significant resources to clean up the quality of content published.</p>
<blockquote>
<p>The key to understanding any revenue model is to identify the key revenue drivers: 1) volume (e.g. customers, users, businesses), 2) pricing (ARPU, new products, upsell) and 3) churn (% customers leaving each month, non-renewals). Try and understand the narrative of how the company can influence these drivers.</p>
</blockquote>
<h3>4. What are YouTube‚Äôs biggest cost drivers?</h3>
<p>YouTube‚Äôs major costs can be separated across 3 categories:</p>
<ul>
<li><strong>Cost of Revenue</strong>: variable costs associated with delivery of services and revenue. Includes ad share revenue paid to creators and data-centre operation and hosting costs;</li>
<li><strong>Operating Costs</strong>: largely staff and support related costs to drive platform and product development (R&amp;D), revenue growth and creator support (Sales &amp; Marketing), content moderation, finance, admin (General &amp; Admin); and</li>
<li><strong>Capex &amp; Acquisitions</strong>: investments in data-centre infrastructure, acquisitions of businesses and supporting tech. These are cash outflows not captured in the income statement</li>
</ul>
<p><img src="https://images.ctfassets.net/vwq10xzbe6iz/7yjEplwqk3bj6K9lfULGQm/2fa7a97f21a0ff6821ead4e0fb0a5918/opextitle.png" alt="youtubeopex"></p>
<p><strong>Cost of Revenue</strong>
YouTube‚Äôs largest cost base is the revenue it shares with content publishers. It splits ad and subscription revenue attached to content viewership in the ratio 45/ 55% in the favour of publishers.</p>
<p>YouTube‚Äôs other major variable costs are the delivery and data-centre operation costs for the 500 hours of video content that gets uploaded every minute. These costs largely include depreciation charges following major upfront capex investments in data-centres. We estimate 7% in line with Alphabet‚Äôs overall depreciation charge as % of revenue.</p>
<p><strong>Operating Costs</strong>
Alphabet does not publicly disclose YouTube‚Äôs other operating expenses so we will need to estimate.</p>
<p>YouTube‚Äôs major fixed costs are its operating costs which are largely staff related and associated with sales and marketing, supporting creators, research &amp; development (software and product roles), content moderation (outsourced contractors), finance, admin and support.</p>
<p>We can estimate YouTube‚Äôs opex margins by comparing against peers. Netflix has a total opex/ revenue of 20% and Facebook at ~35-45%. We can estimate that YouTube may currently operate within the range at 35% opex/ revenue. We can assume given scale benefits that this will lower over time in line with Netflix at 20% opex as % of revenue.</p>
<p>This analysis highlights that YouTube‚Äôs profitability is lower than other social media platforms and Google‚Äôs other ad businesses. This is largely due to YouTube‚Äôs reliance on ad sharing with content publishers.</p>
<p><strong>Capex &amp; Acquisitions</strong>
Alphabet does not separate YouTube‚Äôs cashflow financials so we must estimate capex figures.</p>
<p>In our methodology, depreciation is already accounted for in the operating expenses hence we must estimate the incremental net capital expenditure (e.g. capex less depreciation) in order to estimate the total cash outflows associated with investment in infrastructure.</p>
<p>We will adopt the Godfather of Valuation‚Äôs (Aswath Damodaran) approach of using the <a href="https://www.informit.com/articles/article.aspx?p=2928207&amp;seqNum=5">sales to capital ratio</a> to estimate the required net capex to support revenue growth. This is calculated as the net change in revenue divided by the net capex of each year.</p>
<p>Alphabet has an average sales to capital ratio of 1.9x (annual change in revenue divided by change in invested capital (debt + equity less cash)). This implies that for every $100 of incremental revenue Alphabet generates each year it reinvests $50 as capital to support growth.</p>
<blockquote>
<p>When estimating costs, identify the major drivers across cost of revenue, operating costs and capex costs. Go through annual financial reports to identify the major line items and review notes to understand what is included and not included and understand the main drivers.</p>
</blockquote>
<h3>5. What is the growth thesis for YouTube?</h3>
<p>Based on our above analysis and understanding we can base our growth thesis for YouTube on two key drivers: ad monetization and stable user growth.</p>
<p><strong>Ad Monetization</strong>
YouTube is early in its monetization strategy and has largely relied on ad revenue from high quality in-video ad formats driven by impressions. It has begun to experiment with new formats including direct response display ads within homepage recommendation feeds and direct text search ads. These new formats support greater ability to sell more ads to its user base.</p>
<p>We can estimate that YouTube over the next 10 years will increase its ad monetization from $8 ARPU to $23 ARPU in line with Facebook currently.</p>
<p><strong>Stable User Growth</strong>
YouTube shares a majority of ad revenue to content publishers which is negative for gross profit margins but positive for supporting high quality content creation. This will likely attract amateur and ‚Ä¶</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://mannhowie.com/youtube-valuation">https://mannhowie.com/youtube-valuation</a></em></p>]]>
            </description>
            <link>https://mannhowie.com/youtube-valuation</link>
            <guid isPermaLink="false">hacker-news-small-sites-25176451</guid>
            <pubDate>Sun, 22 Nov 2020 10:44:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Books for Programmers]]>
            </title>
            <description>
<![CDATA[
Score 38 | Comments 15 (<a href="https://news.ycombinator.com/item?id=25176423">thread link</a>) | @nickyvanurk
<br/>
November 22, 2020 | https://codingwizardry.com/2020/11/13/10-best-books-for-programmers-in-2020/ | <a href="https://web.archive.org/web/*/https://codingwizardry.com/2020/11/13/10-best-books-for-programmers-in-2020/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		<div id="penci-post-entry-inner">
			
<p>Most programmers I know started programming out of sheer curiosity and joy. Joy is what keeps one motivated to keep up with the changing landscape of technology. It‚Äôs what keeps one happy. That is why I am recommending these 10 best books for programmers, books I really enjoyed reading. These are the books that I keep picking up and coming back to or have fond memories of. These are also the books that I hardly see recommended elsewhere, except for a few classics that are certainly worth repeating. And now I would like to share these books with you.</p>



<p><em>This post contains affiliate links where applicable. If you‚Äôre planning to buy any of these books yourself you can support this blog by buying it with the links</em> provided in the titles.</p>



<div><div>
<h2><a href="https://amzn.to/36ALozx" target="_blank" rel="noreferrer noopener nofollow">The Pragmatic Programmer<br></a><sub>Your Journey to Mastery, 20th Anniversary Edition</sub></h2>



<div><figure><img loading="lazy" width="230" height="300" src="https://codingwizardry.com/wp-content/uploads/2020/11/the-pragmatic-programmer-230x300.jpg" alt=""></figure></div>



<p>I would recommend any programmer to read this book. It contains a lot of wisdom, tips, and advice. Most of it is pretty basic but therein lies the beauty. The first edition released in 1999 and was getting pretty dated. Despite it being old it was still highly recommended. To my surprise they released a new edition 20 years later, all up-to-date! Now you‚Äôve got no excuses left to not read this book. A wonderful book that you surely will be referring back to over and over again, I know I do.</p>




</div></div>



<div><div>
<h2><a href="https://www.learninpublic.org/" target="_blank" rel="noreferrer noopener nofollow">The Coding Career Handbook<br></a><sub>Guides, Principles, Strategies, and Tactics ‚Äì from Code Newbie to Senior Dev</sub></h2>



<div><figure><img src="https://codingwizardry.com/wp-content/uploads/2020/11/the-coding-career-handbook-196x300.jpg" alt="" width="200" srcset="https://codingwizardry.com/wp-content/uploads/2020/11/the-coding-career-handbook-196x300.jpg 196w, https://codingwizardry.com/wp-content/uploads/2020/11/the-coding-career-handbook.jpg 311w" sizes="(max-width: 196px) 100vw, 196px"></figure></div>



<p>Similar to the The Pragmatic Programmer, I consider this book a must-read. It focuses on the bigger picture and your career, not just about writing code. This book is the reason I started this blog in the first place! A great book for any ambitious programmer and want to take your career to the next level.</p>




</div></div>



<div><div>
<h2><a href="https://amzn.to/36ulPQI">Apprenticeship Patterns<br></a><sub>Guidance for the Aspiring Software Craftsman</sub></h2>



<div><figure><img loading="lazy" width="229" height="300" src="https://codingwizardry.com/wp-content/uploads/2020/11/apprenticeship-patterns-229x300.jpeg" alt="" srcset="https://codingwizardry.com/wp-content/uploads/2020/11/apprenticeship-patterns-229x300.jpeg 229w, https://codingwizardry.com/wp-content/uploads/2020/11/apprenticeship-patterns.jpeg 260w" sizes="(max-width: 229px) 100vw, 229px"></figure></div>



<p>If you‚Äôre new to programming, making the same mistakes as the programmers that have gone before you can be costly and detrimental for your career. Let this book guide you on avoiding these same mistakes. This book is similar to the ones mentioned above and makes for a nice addition. It‚Äôs split up into smaller sections that can be read in any order you‚Äôd like, this makes it a fun and easy read.</p>




</div></div>



<div><div>
<h2><a href="https://amzn.to/3prQVAU">Beginning C++ Through Game Programming</a></h2>



<div><figure><img loading="lazy" width="243" height="300" src="https://codingwizardry.com/wp-content/uploads/2020/11/beginning-c-through-game-programming-243x300.jpg" alt="" srcset="https://codingwizardry.com/wp-content/uploads/2020/11/beginning-c-through-game-programming-243x300.jpg 243w, https://codingwizardry.com/wp-content/uploads/2020/11/beginning-c-through-game-programming.jpg 405w" sizes="(max-width: 243px) 100vw, 243px"></figure></div>



<p>This is the book that taught me how code and was the first book I read on the subject of programming. It made learning new programming languages that much easier. Ever since I read this book it seems I‚Äôve always been one step ahead of the herd. This book is about learning the fundamentals of programming and C++ and less about games. It merely uses games as an example to reinforce programming concepts. This book was a lot of fun to read and because it uses games as a theme it keeps one motivated.</p>




</div></div>



<div><div>
<h2><a href="https://amzn.to/35sQDSE" target="_blank" rel="noreferrer noopener nofollow">Programming Game AI by Example</a></h2>



<div><figure><img loading="lazy" width="201" height="300" src="https://codingwizardry.com/wp-content/uploads/2020/11/programming-game-ai-by-example-201x300.jpg" alt="" srcset="https://codingwizardry.com/wp-content/uploads/2020/11/programming-game-ai-by-example-201x300.jpg 201w, https://codingwizardry.com/wp-content/uploads/2020/11/programming-game-ai-by-example.jpg 335w" sizes="(max-width: 201px) 100vw, 201px"></figure></div>



<p>To be honest I have not read this book in it‚Äôs entirety yet as I currently lack the time to do so. But I am really excited about this one and can‚Äôt wait to read it in combination with learning a new programming language: Rust. This book makes use of C++ but I‚Äôd figure these languages are similar enough as to implement the same ideas in Rust. I‚Äôve put this book on this list because of the pure excitement it makes me feel. I would recommend to at least peruse this book to see if it resonates with you.</p>




</div></div>



<div><div>
<h2><a href="https://amzn.to/3nrDlfj" target="_blank" rel="noreferrer noopener nofollow">The Phoenix Project<br></a><sub>A Novel about IT, Devops, and Helping Your Business Win</sub></h2>



<div><figure><img loading="lazy" width="201" height="300" src="https://codingwizardry.com/wp-content/uploads/2020/11/the-phoenix-project-201x300.jpg" alt="" srcset="https://codingwizardry.com/wp-content/uploads/2020/11/the-phoenix-project-201x300.jpg 201w, https://codingwizardry.com/wp-content/uploads/2020/11/the-phoenix-project.jpg 334w" sizes="(max-width: 201px) 100vw, 201px"></figure></div>



<p>This is a book I got recommended, I read it, I loved it. I recommended it to a friend, and he loved it. And now I recommend it to you! It‚Äôs a really fun read and I could hardly put it down. This book really is written like a novel and packed with great lessons. Go read it! There is also a part two of sorts: The Unicorn Project. I hear it contains much of the same lessons, only told with a different story. I have yet to read it but will certainly do so in the near future.</p>




</div></div>



<div><div>
<h2><a href="https://amzn.to/3ktXAae" target="_blank" rel="noreferrer noopener nofollow">Designing Data-Intensive Applications<br></a><sub>The Big Ideas Behind Reliable, Scalable, and Maintainable Systems</sub></h2>



<div><figure><img loading="lazy" src="https://codingwizardry.com/wp-content/uploads/2020/11/designing-data-intensive-applications-229x300.jpg" alt="" width="229" height="300" srcset="https://codingwizardry.com/wp-content/uploads/2020/11/designing-data-intensive-applications-229x300.jpg 229w, https://codingwizardry.com/wp-content/uploads/2020/11/designing-data-intensive-applications.jpg 381w" sizes="(max-width: 229px) 100vw, 229px"></figure></div>



<p>So you‚Äôve learned how to code and now can write decent software. It‚Äôs time to focus on the bigger picture and learn about systems architecture and scaling, where do you start? This book is the answer. It will teach you all about designing data-intensive applications and serves as a great resource to prep for your systems design interviews.</p>




</div></div>



<div><div>
<h2><a href="https://amzn.to/2UqPpRg" target="_blank" rel="noreferrer noopener nofollow">Game Programming Patterns</a></h2>



<div><figure><img loading="lazy" width="244" height="300" src="https://codingwizardry.com/wp-content/uploads/2020/11/game-programming-patterns-244x300.jpg" alt="" srcset="https://codingwizardry.com/wp-content/uploads/2020/11/game-programming-patterns-244x300.jpg 244w, https://codingwizardry.com/wp-content/uploads/2020/11/game-programming-patterns.jpg 406w" sizes="(max-width: 244px) 100vw, 244px"></figure></div>



<p>I adore this book. It‚Äôs a book I keep coming back to over and over. It‚Äôs about programming patterns with a game theme once again. Note that the patterns here are not only for games! Some of them are game specific but most of them aren‚Äôt. It‚Äôs a fun read with beautiful hand drawn diagrams. Bob Nystrom clearly has put a lot of love in his book. You can read the web version for free <a href="https://gameprogrammingpatterns.com/contents.html" target="_blank" rel="noreferrer noopener nofollow">here</a>!</p>




</div></div>



<div><div>
<h2><a href="https://amzn.to/35s2hgo" target="_blank" rel="noreferrer noopener nofollow">The Web Application Hacker‚Äôs Handbook<br></a><sub>Finding and Exploiting Security Flaws</sub></h2>



<div><figure><img loading="lazy" width="241" height="300" src="https://codingwizardry.com/wp-content/uploads/2020/11/the-web-application-hackers-handbook-241x300.jpg" alt="" srcset="https://codingwizardry.com/wp-content/uploads/2020/11/the-web-application-hackers-handbook-241x300.jpg 241w, https://codingwizardry.com/wp-content/uploads/2020/11/the-web-application-hackers-handbook.jpg 402w" sizes="(max-width: 241px) 100vw, 241px"></figure></div>



<p>You‚Äôre a back-end developer and are responsible for fending of hackers? This is the book for you. It will arm you with the knowledge of how hackers actually hack your web applications and what you can do about it! And if you ever want to make a career switch to become a <a href="https://en.wikipedia.org/wiki/Bug_bounty_program" target="_blank" rel="noreferrer noopener nofollow">Bug Bounty Hunter</a>, this is the #1 book recommendation within that field.</p>




</div></div>



<div><div>
<h2><a href="https://amzn.to/3ly5xfO" target="_blank" rel="noreferrer noopener nofollow">Cracking the Coding Interview<br></a><sub>189 Programming Questions and Solutions</sub></h2>



<div><figure><img loading="lazy" width="211" height="300" src="https://codingwizardry.com/wp-content/uploads/2020/11/cracking-the-coding-interview-211x300.jpeg" alt="" srcset="https://codingwizardry.com/wp-content/uploads/2020/11/cracking-the-coding-interview-211x300.jpeg 211w, https://codingwizardry.com/wp-content/uploads/2020/11/cracking-the-coding-interview.jpeg 243w" sizes="(max-width: 211px) 100vw, 211px"></figure></div>



<p>A classic for coding interview prep. I‚Äôve read this book after seeing it recommended everywhere and I must say I‚Äôm glad I did. It teaches you all about data-structures and has a ton of example coding interview questions and their answers. This is a must-read for any programmer.</p>




</div></div>
			
			
			
					</div>
	</div></div>]]>
            </description>
            <link>https://codingwizardry.com/2020/11/13/10-best-books-for-programmers-in-2020/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25176423</guid>
            <pubDate>Sun, 22 Nov 2020 10:37:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Birth of Unix with Brian Kernighan]]>
            </title>
            <description>
<![CDATA[
Score 369 | Comments 78 (<a href="https://news.ycombinator.com/item?id=25176318">thread link</a>) | @rodrigo975
<br/>
November 22, 2020 | https://corecursive.com/058-brian-kernighan-unix-bell-labs/ | <a href="https://web.archive.org/web/*/https://corecursive.com/058-brian-kernighan-unix-bell-labs/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><span>When you work on your computer, there are so many things you take for granted: operating systems, programming languages, they all have to come from somewhere. </span></p><p><span>In the late 1960s and 1970s, that somewhere was Bell Labs, and the operating system they were building was UNIX. </span></p><p><span>They were building more than just an operating system though. They were building a way to work with computers that had never existed before.&nbsp; </span></p><p><span>In today‚Äôs episode I talk to Brian Kernighan about the history of Unix.</span></p><h3><b>Quotes</b></h3><p><em><span>‚ÄúIf you wanted, you could go sit in your office and think deep thoughts or program, or write on your own blackboard or whatever, but then come back to the common space when you wanted to.‚Äú&nbsp;</span></em></p><p><em><span>‚ÄúI found it easier to program when I was trying to figure out the logic for myself rather than trying to figure out where in the infinite stack of documentation was the function I needed. So for me, programming is more like creating something rather than looking it up, and too much of today‚Äôs programming is more like looking it up.‚Äù</span></em></p><p><em><span>‚ÄúIf what I find challenging or hard or whatever is also something that other people find hard or challenging or whatever, then if I do something that will improve my lot, I‚Äôm perhaps improving their lot at the same time.‚Äù</span></em></p><h2><b>Transcript:</b></h2><p><i><span>Note:&nbsp; This podcast is designed to be heard. If you are able, we strongly encourage you to listen to the audio, which includes emphasis that‚Äôs not on the page.&nbsp; The podcast page for</span></i><a href="https://corecursive.com/brian-kernighan-unix-bell-labs/" target="_blank" rel="noopener noreferrer"><i><span> this episode is here</span></i></a></p><p><strong>Adam:&nbsp;</strong></p><p><span>When you work on your computer, there are so many things you take for granted: operating systems, programming languages, they all have to come from somewhere. In the 1960s, that somewhere was Bell Labs, and the operating system they were building was Unix. They were building more than just an operating system though. They were building a way to work with computers that had never existed before. To find out more, I reached out to this guy.</span></p><p><strong>Brian:&nbsp;</strong></p><p><span>I‚Äôm Brian Kernighan, and at the moment, I teach computer science at Princeton University.</span></p><p><strong>Adam:&nbsp;</strong></p><p><span>He‚Äôs the K in K&amp;R, the famous book about C that still tops most recommended book lists. He was part of this computer science research group at Bell Labs for 30 years. He‚Äôs going to share the story of the creation of Unix, and hopefully, I‚Äôm going to try to figure out some of their secrets to being so impactful. Along the way, we‚Äôre going to have to learn about the Unix philosophy and printing patent applications, but we‚Äôre also going to have to learn about 10-kilo chocolate bars and fake demos to the CIA, and of course, British satirical magazines.</span></p><p><strong>Adam:</strong></p><p><span>The story of Unix is a story about Bell Labs, so let‚Äôs start at the beginning when Brian is a grad student and he gets an internship to work there for the summer.</span></p><p><strong>Brian:</strong></p><p><span>Bell Labs is a very big building, a sequence of connected buildings, and probably 3,000 people working over these long multi-story buildings. The thing that I remember most clearly about the first day, and I think it was the first day of the first internship, so call it the summer of 1967, and I got an office, and if I recall correctly, I had an office to myself. So this is something that‚Äôs unheard of in the modern era.</span></p><p><strong>Brian:</strong></p><p><span>But I had an office to myself, and I was sitting there in my office at probably 11:00 or something like that in my first morning, I wondered, ‚ÄúWhat the heck do I do? I have no idea what‚Äôs going on.‚Äù And this older gentleman came past my office and he said, ‚ÄúHi, I‚Äôm Dick‚Ä¶ Let‚Äôs go to lunch.‚Äù I thought, ‚ÄúWell, okay.‚Äù I went off to lunch with Dick‚Ä¶, whose name I hadn‚Äôt caught. We had a good lunch, he was an interesting kind of curmudgeonly, but intriguing guy. Then after lunch, he went off somewhere else.</span></p><p><strong>Brian:</strong></p><p><span>I snuck past my office to his office on the same corridor to see who the heck he was because everybody had name tags on the doors. It turns out it was Dick Hamming, the inventor of error-correcting codes.</span></p><p><strong>Adam:</strong></p><p><span>Dick Hamming is aka Richard Hamming. His Wikipedia page is huge. He worked on the Manhattan project programming computers to calculate the equations needed to develop nuclear weapons. One year after this lunch with Brian, he would win the Turing Award, the so-called Nobel Prize of Computing for his work on error-correcting codes. Hamming is also famous for this talk he gave on the secret to having impact in your professional life.</span></p><p><strong>Brian:</strong></p><p><span>The talk was called You and Your Research, and it was basically a retrospective on his career, thinking whether there were general lessons that would help other people in some way to have a better career. He was very, very interesting, and I think a good example of somebody with clearly lots of talent, but not a super genius type, who made the most of what he had. Who in every way, amplified so that he compounded his effect on the world. The other thing that‚Äôs maybe is appropriate for today, he used to say that he would reserve Friday afternoons for thinking great thoughts.</span></p><p><strong>Brian:</strong></p><p><span>He would sit in his office, he would put his feet on the desk, and he would think great thoughts, whatever that might be. It was usually introspection on himself or on where was the field going, or what might happen in the future? What might you do to take advantage of that or deal with it in some way or other? This is Friday morning when we‚Äôre talking, and I don‚Äôt get that luxury on Friday afternoons very often, but it‚Äôs a useful way to think of it. You say, ‚ÄúI‚Äôm going to stop and do it regularly to take stock of what‚Äôs going on, and in some way, think about, ‚ÄòWhat could I be doing that in some way would be better, that would be more useful for me or my family or the world or whatever?'‚Äù</span></p><p><strong>Brian:</strong></p><p><span>He did that quite religiously, you went in after lunch on Friday, you‚Äôd find him sitting in his office thinking great thoughts. So he‚Äôs fun.</span></p><p><strong>Adam:</strong></p><p><span>I love this advice, it presupposes that if I just had my Fridays free, and I wrote thinking great thoughts on my calendar, I would upgrade thoughts. I mean, maybe that‚Äôs the case, I‚Äôll give it a try. There‚Äôs one concept though that Hamming is most famous for, and that is about how you choose what to work on.</span></p><p><strong>Brian:</strong></p><p><span>The way he told it to me and probably lots of others was that he used to eat with some group of people like chemists, I think the specific thing was, and he would eat at their table at lunchtime, big cafeteria setting. He would sit down with chemists and talk to them and he would ask them what they were working on, and whether what they‚Äôre working on could possibly lead to a Nobel Prize. The answer was often no, not a chance, and that was the point where he‚Äôd say, ‚ÄúWell, then why are you working on it? Because if it couldn‚Äôt at least potentially lead to a Nobel Prize, it isn‚Äôt important. Why are you wasting your time on something that isn‚Äôt important?‚Äù</span></p><p><strong>Adam:</strong></p><p><span>Whether intentionally or not, Brian followed this advice. When he returned to Princeton to work on his thesis, he was working on graph partitioning, which we now know is in some sense, equivalent to the traveling salesman problem. You have to find an optimum route that the salesman would travel from city to city minimizing travel distance. To complete his thesis, Brian had to work on the computers of Princeton at the time. Computers today are a lot different than they were in 1967 and ‚Äô68 at Princeton. At the time, computers were all about Fortran and punch cards.</span></p><p><strong>Brian:</strong></p><p><span>Fortran was designed in a card environment very definitely, and I assume the cards came before Fortran, but in my mind, they‚Äôre very strongly linked. And so yes, it was basically one statement per line, which was, therefore, one physical card. And so, when you wrote a program, you had to punch it on these punch cards, and then make sure you kept them in order and things like that and then you handed them to somebody who operated a very big, expensive machine. And a while later, back would come to your results, very often where it‚Äôs just something like there was a syntax error somewhere, and you had to find the cards that were wrong, replace them with new cards that were right and repeat the process, but with a very, very long latency that could be often measured in hours or sometimes even days.</span></p><p><strong>Brian:</strong></p><p><span>It‚Äôs not exactly like an instant compilation. And Fortran itself is a kind of clunky language as well in part reflecting those early days in computing, and partly just the fact that we didn‚Äôt understand a lot, and the computers themselves were not particularly sophisticated. Then finally, Fortran was intended for scientific computing. It was not intended for, let‚Äôs say, general-purpose system programming or anything like that. All of those things meant that although the program was a lot of fun, it‚Äôs not the same as it became five or 10 years later, and it has continued to evolve.</span></p><p><strong>Adam:</strong></p><p><span>I had to watch a couple of YouTube videos to get a sense of this punch card world. A punch card is like an index card, but it‚Äôs wider because it has 80 columns. And each of these columns corresponds to a single character. You punch holes in that column to indicate what letters should go there, and so each punch card represents one line of Fortran code. People build the programs this way, punching these cards, putting them into big boxes in order that they would carry around, then you take someplace to give them to a computer operator who would give them to the computer that would read all this in and run the program.</span></p><p><strong>Adam:</strong></p><p><span>So if you had a 1,000-line program, you would have 1,000 cards. There were no screens, no interactive output. You gave your cards to the computer operator and waited for your printout that was the result of your program. Computers were expensive and giant, so they wanted to maximize the throughput. Your program might be doing expensive mathematical calculations, but you could also just be doing word processing. One card might say, ‚ÄúIn bold, print my thesis,‚Äù and the next would say, ‚ÄúPrint, by Brian Kernighan,‚Äù and so on. It‚Äôs like a verbose way of using a typewriter, except the advantage is you could change the cards around and have it reprinted.</span></p><p><strong>Brian:</strong></p><p><span>T‚Ä¶</span></p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://corecursive.com/058-brian-kernighan-unix-bell-labs/">https://corecursive.com/058-brian-kernighan-unix-bell-labs/</a></em></p>]]>
            </description>
            <link>https://corecursive.com/058-brian-kernighan-unix-bell-labs/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25176318</guid>
            <pubDate>Sun, 22 Nov 2020 10:14:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Israeli Queues]]>
            </title>
            <description>
<![CDATA[
Score 30 | Comments 14 (<a href="https://news.ycombinator.com/item?id=25176282">thread link</a>) | @arpitbbhayani
<br/>
November 22, 2020 | https://arpitbhayani.me/blogs/israeli-queues | <a href="https://web.archive.org/web/*/https://arpitbhayani.me/blogs/israeli-queues">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p>A queue is a data structure that holds up elements for a brief period of time until a peripheral processing system is ready to process them. The most common implementation of a queue is a FIFO queue - First In First Out - that evicts the element that was inserted the first i.e. it evicts the one that has spent the most time in the queue. There are other variations of Queues one of which is called Priority Queue.</p>
<p>In Priority Queue, every element is associated with a priority, usually provided by the user during enqueueing; This associated priority is used during eviction where the element with the highest priority is evicted first during dequeuing.</p>
<p>In this essay, we take a detailed look into a variation of Priority Queue, fondly called Israeli Queues, where the priority of the element is defined by the affinity of it with one of its "friends" in the queue. Israeli Queues were first introduced in the paper <a href="https://pure.tue.nl/ws/files/2152975/632939.pdf">Polling with batch service</a> by Boxma, O. J., Wal, van der, J., &amp; Yechiali, U in the year 2007.</p>

<p>Queues in Israel are usually unorganized, due to which people tend to find their friends, who are already waiting, and instead of adhering to the usual protocol of joining at the back end, they cut through and directly join their friends. Israeli Queues mimic this behavior and hence get this <a href="https://www.tandfonline.com/doi/abs/10.1080/15326340802427497">punny name</a>.</p>
<p><img src="https://user-images.githubusercontent.com/4745789/99894937-fddc4380-2cac-11eb-8a73-a4dc5c490d2b.png" alt="https://user-images.githubusercontent.com/4745789/99894937-fddc4380-2cac-11eb-8a73-a4dc5c490d2b.png"></p>
<p>Israeli Queues are a variation of <a href="https://en.wikipedia.org/wiki/Priority_queue">Priority Queues</a> where instead of associating priority with the element to be enqueued, the priority is implicitly derived using the "friend" element and it joins right at the back end of the group that the friend belongs to. The function signature of the enqueue operation is as shown below, while other operations like <code>dequeue</code> and <code>peek</code> remains fairly similar.</p>
<pre><code>

<span><span>void</span> <span>enqueue</span><span>(israeli_queue * q, element * e, element * f)</span></span>;
</code></pre>
<h2>How could this help?</h2>
<p>Every Data Structures is designed to solve a niche use case efficiently and Israeli Queues are no different as they prove to be super-efficient where one could batch and process similar elements or where the <em>set-up</em> cost for a task is high.</p>
<p>Consider a system where a queue is used to hold up heterogeneous tasks and there is a single machine taking care of processing. Now if some of these tasks are similar and have a high <em>set-up or preparation cost</em>, for example downloading large metafiles, or spinning up a parallel infrastructure, or even setting up persistent connections with device farms, queuing them closer and processing them sequentially or in batch helps in reducing redundant processing and computation by promoting reuse.</p>
<h2>Issue of starvation</h2>
<p>By enqueuing elements in between Israeli Queues reduces redundant processing, but by doing that it makes itself vulnerable to the classical case of starvation. Elements stuck at the rear end of the list could potentially starve for longer durations if elements having "friends" in the queue keep coming in at high frequency.</p>
<p>The original implementation of Israeli Queues suggests batch processing where instead of processing tasks one at a time, it processes a batch (a group of friends) in one go. This proves to be super-handy when the time required to processes a single task is much lower than the set-up cost for it.</p>
<h2>Implementation Guidelines</h2>
<p>The best way to implement Israeli Queues is by using a <a href="https://en.wikipedia.org/wiki/Doubly_linked_list">Doubly Linked List</a> with a bunch of pointers pointing to the head and tail of groups within it. Insertion to an existing group happens at the tail of it while if the element has no friend element, then it goes at the tail end of the list and forms its own group.</p>
<p>A constraint that could be added during implementation is that the friend element should always be the leader (head) element of the group. Details of the implementation could be tweaked so long the core concept remains unaltered.</p>

<p>Israeli Queues were the outcome of a problem statement dealing with Polling Systems. Polling System usually contains <code>N</code> queues <code>Q1</code>, <code>Q2</code>, ..., <code>Qn</code> where the processing unit visits each queue in cyclic order processing one element at a time i.e. <code>Q1</code>, <code>Q2</code>, ..., <code>Qn</code>, <code>Q1</code>, <code>Q2</code>, ..., <code>Qn</code>, etc.</p>
<p>When the server attends a queue instead of processing just one element from it, it processes the entire batch present in the queue utilizing the setup-cost efficiently assuming that time to process an element from a queue is much lesser than the set-up cost.</p>

<ul>
<li><a href="https://pure.tue.nl/ws/files/2152975/632939.pdf">Polling with batch service</a></li>
<li><a href="http://www.math.tau.ac.il/~uriy/Papers/IQ-with-Priorities.pdf">The Israeli Queue with priorities</a></li>
<li><a href="https://rapidapi.com/blog/israeli-queues-exploring-a-bizarre-data-structure/">Israeli Queues: Exploring a bizarre data structure</a></li>
</ul>
</div></div><div><p>
          If my work adds value, consider supporting me
        </p>  <p><a href="https://www.buymeacoffee.com/arpitbhayani" target="_blank"><img src="https://cdn.buymeacoffee.com/buttons/v2/default-yellow.png" alt="Buy Me A Coffee"></a></p> <br></div><section><div><div><p><img src="https://arpitbhayani.me/static/img/arpit.jpg"></p>  <h2>
              700+ Signups
            </h2> <p>
              If you like what you read subscribe you can always subscribe to
              my newsletter and get the post delivered straight to your inbox.
              I write
              <a href="https://arpitbhayani.me/blogs">essays</a> on various
              engineering topics and share it through my weekly
              <a href="https://arpitbhayani.me/newsletter">newsletter</a> üëá
            </p> <br> </div></div></section></div>]]>
            </description>
            <link>https://arpitbhayani.me/blogs/israeli-queues</link>
            <guid isPermaLink="false">hacker-news-small-sites-25176282</guid>
            <pubDate>Sun, 22 Nov 2020 10:05:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Having Fun with Signal Handlers]]>
            </title>
            <description>
<![CDATA[
Score 44 | Comments 14 (<a href="https://news.ycombinator.com/item?id=25175911">thread link</a>) | @edward
<br/>
November 22, 2020 | https://www.giovannimascellani.eu/having-fun-with-signal-handlers.html | <a href="https://web.archive.org/web/*/https://www.giovannimascellani.eu/having-fun-with-signal-handlers.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p>As every C and C++ programmer knows far too well, if you dereference a
pointer that points outside of the space mapped on your process'
memory, you get a segmentation fault and your programs crashes. As far
as the language itself is concerned, you don't have a second chance
and you cannot know in advance whether that dereferencing operation is
going to set a bomb off or not. In technical terms, you are invoking
<em>undefined behaviour</em>, and you should never do that: you are
responsible for knowing in advance if your pointers are valid, and if
they are not you keep the pieces.</p>
<p>However, turns out that most actual operating system give you a second
chance, although with a lot of fine print attached. So I tried to
implement a function that tries to dereference a pointer: if it can,
it gives you the value; if it can't, it tells you it couldn't. Again,
I stress this should never happen in a real program, except possibly
for debugging (or for having fun).</p>
<p>The prototype is</p>
<div><pre><span></span><code><span>word_t peek(word_t *addr, int *success);</span>
</code></pre></div>

<p>The function is basically equivalent to <code>return *addr</code>, except that if
<code>addr</code> is not mapped it doesn't crash, and if <code>success</code> is not NULL it
is set to <code>0</code> or <code>1</code> to indicate that <code>addr</code> was not mapped or
mapped. If <code>addr</code> was not mapped the return value is meaningless.</p>
<p>I won't explain it in detail to leave you some fun. Basically the idea
is to install a handler for <code>SIGSEGV</code>: if the address is invalid, the
handler is called, which basically fixes everything by advancing a
little bit the instruction pointer, in order to skip the faulting
instruction. The dereferencing instruction is written as hardcoded
Assembly bytes, so that I know exactly how many bytes I need to skip.</p>
<p>Of course this is very architecture-dependent: I wrote the <code>i386</code> and
<code>amd64</code> variants (no <code>x32</code>). And I don't guarantee there are no bugs
or subtelties!</p>
<p>Another solution would have been to just parse <code>/proc/self/maps</code>
before dereferencing and check whether the pointer is in a mapped
area, but it would have suffered of a
<a href="https://en.wikipedia.org/wiki/Time-of-check_to_time-of-use">TOCTTOU</a>
problem: another thread might have changed the mappings between the
time when <code>/proc/self/maps</code> was parsed and when the pointer was
dereferenced (also, parsing that file can take a relatively long
amount of time). Another less architecture-dependent but still not
pure-C approach would have been to establish a <code>setjmp</code> before
attempting the dereference and <code>longjmp</code>-ing back from the signal
handler (but again you would need to use different <code>setjmp</code> contexts
in different threads to exclude race conditions).</p>
<p>Have fun! (and again, don't try this in real programs)</p>
<div><pre><span></span><code><span>#define</span><span> </span><span>_GNU_SOURCE</span><span></span>
<span>#include</span><span> </span><span>&lt;</span><span>stdint</span><span>.</span><span>h</span><span>&gt;</span><span></span>
<span>#include</span><span> </span><span>&lt;</span><span>signal</span><span>.</span><span>h</span><span>&gt;</span><span></span>
<span>#include</span><span> </span><span>&lt;</span><span>assert</span><span>.</span><span>h</span><span>&gt;</span><span></span>
<span>#include</span><span> </span><span>&lt;</span><span>stdlib</span><span>.</span><span>h</span><span>&gt;</span><span></span>
<span>#include</span><span> </span><span>&lt;</span><span>stdio</span><span>.</span><span>h</span><span>&gt;</span><span></span>
<span>#include</span><span> </span><span>&lt;</span><span>ucontext</span><span>.</span><span>h</span><span>&gt;</span><span></span>

<span>#ifdef</span><span> </span><span>__i386__</span><span></span>
<span>typedef</span><span> </span><span>uint32_t</span><span> </span><span>word_t</span><span>;</span><span></span>
<span>#define</span><span> </span><span>IP_REG</span><span> </span><span>REG_EIP</span><span></span>
<span>#define</span><span> </span><span>IP_REG_SKIP</span><span> </span><span>3</span><span></span>
<span>#define</span><span> </span><span>READ_CODE</span><span> </span><span>__asm__</span><span> </span><span>__volatile__</span><span>(</span><span>".byte 0x8b, 0x03\n"</span><span>  </span><span>/* mov (%ebx), %eax */</span><span> </span><span>\</span><span></span>
<span>                                       </span><span>".byte 0x41\n"</span><span>        </span><span>/* inc %ecx */</span><span> </span><span>\</span><span></span>
<span>                                       </span><span>:</span><span> </span><span>"=a"</span><span>(</span><span>ret</span><span>),</span><span> </span><span>"=c"</span><span>(</span><span>tmp</span><span>)</span><span> </span><span>:</span><span> </span><span>"b"</span><span>(</span><span>addr</span><span>),</span><span> </span><span>"c"</span><span>(</span><span>tmp</span><span>));</span><span></span>
<span>#endif</span><span></span>

<span>#ifdef</span><span> </span><span>__x86_64__</span><span></span>
<span>typedef</span><span> </span><span>uint64_t</span><span> </span><span>word_t</span><span>;</span><span></span>
<span>#define</span><span> </span><span>IP_REG</span><span> </span><span>REG_RIP</span><span></span>
<span>#define</span><span> </span><span>IP_REG_SKIP</span><span> </span><span>6</span><span></span>
<span>#define</span><span> </span><span>READ_CODE</span><span> </span><span>__asm__</span><span> </span><span>__volatile__</span><span>(</span><span>".byte 0x48, 0x8b, 0x03\n"</span><span>  </span><span>/* mov (%rbx), %rax */</span><span> </span><span>\</span><span></span>
<span>                                       </span><span>".byte 0x48, 0xff, 0xc1\n"</span><span>  </span><span>/* inc %rcx */</span><span> </span><span>\</span><span></span>
<span>                                       </span><span>:</span><span> </span><span>"=a"</span><span>(</span><span>ret</span><span>),</span><span> </span><span>"=c"</span><span>(</span><span>tmp</span><span>)</span><span> </span><span>:</span><span> </span><span>"b"</span><span>(</span><span>addr</span><span>),</span><span> </span><span>"c"</span><span>(</span><span>tmp</span><span>));</span><span></span>
<span>#endif</span><span></span>

<span>static</span><span> </span><span>void</span><span> </span><span>segv_action</span><span>(</span><span>int</span><span> </span><span>sig</span><span>,</span><span> </span><span>siginfo_t</span><span> </span><span>*</span><span>info</span><span>,</span><span> </span><span>void</span><span> </span><span>*</span><span>ucontext</span><span>)</span><span> </span><span>{</span><span></span>
<span>    </span><span>(</span><span>void</span><span>)</span><span> </span><span>sig</span><span>;</span><span></span>
<span>    </span><span>(</span><span>void</span><span>)</span><span> </span><span>info</span><span>;</span><span></span>
<span>    </span><span>ucontext_t</span><span> </span><span>*</span><span>uctx</span><span> </span><span>=</span><span> </span><span>(</span><span>ucontext_t</span><span>*</span><span>)</span><span> </span><span>ucontext</span><span>;</span><span></span>
<span>    </span><span>uctx</span><span>-&gt;</span><span>uc_mcontext</span><span>.</span><span>gregs</span><span>[</span><span>IP_REG</span><span>]</span><span> </span><span>+=</span><span> </span><span>IP_REG_SKIP</span><span>;</span><span></span>
<span>}</span><span></span>

<span>struct</span><span> </span><span>sigaction</span><span> </span><span>peek_sigaction</span><span> </span><span>=</span><span> </span><span>{</span><span></span>
<span>    </span><span>.</span><span>sa_sigaction</span><span> </span><span>=</span><span> </span><span>segv_action</span><span>,</span><span></span>
<span>    </span><span>.</span><span>sa_flags</span><span> </span><span>=</span><span> </span><span>SA_SIGINFO</span><span>,</span><span></span>
<span>    </span><span>.</span><span>sa_mask</span><span> </span><span>=</span><span> </span><span>0</span><span>,</span><span></span>
<span>}</span><span>;</span><span></span>

<span>word_t</span><span> </span><span>peek</span><span>(</span><span>word_t</span><span> </span><span>*</span><span>addr</span><span>,</span><span> </span><span>int</span><span> </span><span>*</span><span>success</span><span>)</span><span> </span><span>{</span><span></span>
<span>    </span><span>word_t</span><span> </span><span>ret</span><span>;</span><span></span>
<span>    </span><span>int</span><span> </span><span>tmp</span><span>,</span><span> </span><span>res</span><span>;</span><span></span>
<span>    </span><span>struct</span><span> </span><span>sigaction</span><span> </span><span>prev_act</span><span>;</span><span></span>

<span>    </span><span>res</span><span> </span><span>=</span><span> </span><span>sigaction</span><span>(</span><span>SIGSEGV</span><span>,</span><span> </span><span>&amp;</span><span>peek_sigaction</span><span>,</span><span> </span><span>&amp;</span><span>prev_act</span><span>);</span><span></span>
<span>    </span><span>assert</span><span>(</span><span>res</span><span> </span><span>==</span><span> </span><span>0</span><span>);</span><span></span>

<span>    </span><span>tmp</span><span> </span><span>=</span><span> </span><span>0</span><span>;</span><span></span>
<span>    </span><span>READ_CODE</span><span></span>

<span>    </span><span>res</span><span> </span><span>=</span><span> </span><span>sigaction</span><span>(</span><span>SIGSEGV</span><span>,</span><span> </span><span>&amp;</span><span>prev_act</span><span>,</span><span> </span><span>NULL</span><span>);</span><span></span>
<span>    </span><span>assert</span><span>(</span><span>res</span><span> </span><span>==</span><span> </span><span>0</span><span>);</span><span></span>

<span>    </span><span>if</span><span> </span><span>(</span><span>success</span><span>)</span><span> </span><span>{</span><span></span>
<span>        </span><span>*</span><span>success</span><span> </span><span>=</span><span> </span><span>tmp</span><span>;</span><span></span>
<span>    </span><span>}</span><span></span>

<span>    </span><span>return</span><span> </span><span>ret</span><span>;</span><span></span>
<span>}</span><span></span>

<span>int</span><span> </span><span>main</span><span>()</span><span> </span><span>{</span><span></span>
<span>    </span><span>int</span><span> </span><span>success</span><span>;</span><span></span>
<span>    </span><span>word_t</span><span> </span><span>number</span><span> </span><span>=</span><span> </span><span>22</span><span>;</span><span></span>
<span>    </span><span>word_t</span><span> </span><span>value</span><span>;</span><span></span>

<span>    </span><span>number</span><span> </span><span>=</span><span> </span><span>22</span><span>;</span><span></span>
<span>    </span><span>value</span><span> </span><span>=</span><span> </span><span>peek</span><span>(</span><span>&amp;</span><span>number</span><span>,</span><span> </span><span>&amp;</span><span>success</span><span>);</span><span></span>
<span>    </span><span>printf</span><span>(</span><span>"%d %d\n"</span><span>,</span><span> </span><span>success</span><span>,</span><span> </span><span>value</span><span>);</span><span></span>

<span>    </span><span>value</span><span> </span><span>=</span><span> </span><span>peek</span><span>(</span><span>NULL</span><span>,</span><span> </span><span>&amp;</span><span>success</span><span>);</span><span></span>
<span>    </span><span>printf</span><span>(</span><span>"%d %d\n"</span><span>,</span><span> </span><span>success</span><span>,</span><span> </span><span>value</span><span>);</span><span></span>

<span>    </span><span>value</span><span> </span><span>=</span><span> </span><span>peek</span><span>((</span><span>word_t</span><span>*</span><span>)</span><span>0x1234</span><span>,</span><span> </span><span>&amp;</span><span>success</span><span>);</span><span></span>
<span>    </span><span>printf</span><span>(</span><span>"%d %d\n"</span><span>,</span><span> </span><span>success</span><span>,</span><span> </span><span>value</span><span>);</span><span></span>

<span>    </span><span>return</span><span> </span><span>0</span><span>;</span><span></span>
<span>}</span><span></span>
</code></pre></div>
  </div><p><em>Comment will be manually reviewed before being published.</em></p></div>]]>
            </description>
            <link>https://www.giovannimascellani.eu/having-fun-with-signal-handlers.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25175911</guid>
            <pubDate>Sun, 22 Nov 2020 08:26:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Loopy C Puzzle (2011)]]>
            </title>
            <description>
<![CDATA[
Score 43 | Comments 24 (<a href="https://news.ycombinator.com/item?id=25175769">thread link</a>) | @susam
<br/>
November 21, 2020 | https://susam.in/blog/loopy-c-puzzle/ | <a href="https://web.archive.org/web/*/https://susam.in/blog/loopy-c-puzzle/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

<p>By <b>Susam Pal</b> on 01 Oct 2011</p>
<h2 id="integer-underflow"><a href="#integer-underflow">Integer Underflow</a></h2>
<p>
Let us talk a little bit about integer underflow and undefined behaviour
in C before we discuss the puzzle I want to share in this post.
</p>

<pre><code>#include &lt;stdio.h&gt;

int main()
{
    int i;
    for (i = 0; i &lt; 6; i--)
        printf(".");
    return 0;
}</code>
</pre>

<p>
This code invokes undefined behaviour. The value in variable
<code>i</code> decrements to <code>INT_MIN</code> after
<code>|INT_MIN| + 1</code> iterations. In the next iteration, there is a
negative overflow which is undefined for signed integers in C. On many
implementations though, <code>INT_MIN - 1</code> wraps around to
<code>INT_MAX</code>. Since <code>INT_MAX</code> is not less than
<code>6</code>, the loop terminates. With such implementations, this
code prints <code>|INT_MIN| + 1</code> dots. With 32-bit integers,
that amounts to 2147483649 dots. Here is one such example output:
</p>

<pre><samp>$ <kbd>gcc -std=c89 -Wall -Wextra -pedantic foo.c &amp;&amp; ./a.out | wc -c</kbd>
2147483649</samp>
</pre>

<p>
It is worth noting that the above behaviour is only one of the many
possible ones. The code invokes undefined behaviour and the ISO standard
imposes no requirements on a specific implementation of the compiler
regarding what the behaviour of such code should be. For example, an
implementation could also exploit the undefined behaviour to turn the
loop into an infinite loop. In fact, GCC does optimize it to an infinite
loop if we compile the code with the <code>-O2</code> option.
</p>

<pre><samp><kbd># This never terminates!</kbd>
$ <kbd>gcc -O2 -std=c89 -Wall -Wextra -pedantic foo.c &amp;&amp; ./a.out</kbd>
</samp></pre>


<h2 id="puzzle"><a href="#puzzle">Puzzle</a></h2>
<p>
Let us take a look at the puzzle now.
</p>

<div>
<p>
Add or modify exactly one operator in the following code such that it
prints exactly 6 dots.
</p>

<pre><code>for (i = 0; i &lt; 6; i--)
    printf(".");</code>
</pre></div>

<p>
An obvious solution is to change <code>i--</code> to <code>i++</code>.
</p>

<pre><code>for (i = 0; i &lt; 6; i++)
    printf(".");</code>
</pre>

<p>
There are a few more solutions to this puzzle. One of the solutions is
very interesting. We will discuss the interesting solution in detail
below.
</p>


<h2 id="solutions"><a href="#solutions">Solutions</a></h2>
<p>
<em><strong>Update on 02 Oct 2011:</strong> The puzzle has been solved
in the <a href="https://susam.in/blog/loopy-c-puzzle/comments/">comments</a> section. We will discuss the
solutions now. If you want to think about the problem before you see the
solutions, this is a good time to pause and think about it. There are
spoilers ahead.</em>
</p>

<p>
Here is a list of some solutions:
</p>

<ul>
  <li>
    <code>for (i = 0; i &lt; 6; i++)</code>
  </li>
  <li>
    <code>for (i = 0; i &lt; 6; ++i)</code>
  </li>
  <li>
    <code>for (i = 0; -i &lt; 6; i--)</code>
  </li>
  <li>
    <code>for (i = 0; i + 6; i--)</code>
  </li>
  <li>
    <code>for (i = 0; i ^= 6; i--)</code>
  </li>
</ul>

<p>
The last solution involving the bitwise XOR operation is not immediately
obvious. A little analysis is required to understand why it works. 
</p>


<h2 id="generalization"><a href="#generalization">Generalization</a></h2>
<p>
Let us generalize the puzzle by replacing \( 6 \) in the loop with an
arbitrary positive integer \( n. \) The loop in the last solution now
becomes:
</p>

<pre><code>for (i = 0; i ^= n; i--)
    printf(".");</code>
</pre>

<p>
If we denote the value of the variable <code>i</code> set by the
execution of <code>i ^= n</code> after \( k \) dots are printed as
\( f(k), \) then

\[
  f(k) =
    \begin{cases}
      n                       &amp; \text{if } n = 0, \\
      n \oplus (f(k - 1) - 1) &amp; \text{if } n &gt; 1
    \end{cases}
\]

where \( k \) is a nonnegative integer, \( n \) is a positive integer,
and the symbol \( \oplus \) denotes bitwise XOR operation on two
nonnegative integers.

Note that \( f(0) \) represents the value of <code>i</code> set by the
execution of <code>i ^= n</code> when no dots have been printed yet.
</p>

<p>
If we can show that \( n \) is the least value of \( k \) for which \(
f(k) = 0, \) it would prove that the loop terminates after printing
\( n \) dots.
</p>

<p>
We will see in the next section that for odd values of \( n, \)

\[
f(k) =
\begin{cases}
n &amp; \text{if } k \text{ is even}, \\
1 &amp; \text{if } k \text{ is odd}.
\end{cases}
\]

Therefore there is no value of \( k \) for which \( f(k) = 0 \) when \(
n \) is odd. As a result, the loop never terminates when \( n \) is odd.
</p>

<p>
We will then see that for even values of \( n \) and
\( 0 \leq k \leq n, \)

\[
f(k) = 0 \iff k = n.
\]

Therefore the loop terminates after printing \( n \) dots when \( n \)
is even.
</p>


<h2 id="lemmas"><a href="#lemmas">Lemmas</a></h2>
<p>
We will first prove a few lemmas about some interesting properties of
the bitwise XOR operation. We will then use it to prove the claims made
in the previous section.
</p>

<!-- Lemma 1 -->
<p>
<strong>Lemma 1.</strong>
<em>
For an odd positive integer \( n, \)

\[
n \oplus (n - 1) = 1
\]

where the symbol \( \oplus \) denotes bitwise XOR operation on two
nonnegative integers.
</em>
</p>

<p>
<em>Proof.</em>
Let the binary representation of \( n \) be \( b_m \dots b_1 b_0 \)
where \( m \) is a nonnegative integer and \( b_m \) represents the most
significant nonzero bit of \( n. \) Since \( n \) is an odd number,
\( b_0 = 1. \)

Thus \( n \) may be written as

\[ b_m \dots b_1 1. \]

As a result \( n - 1 \) may be written as

\[ b_m \dots b_1 0. \]

The bitwise XOR of both binary representations is \( 1. \)
</p>

<!-- Lemma 2 -->
<p>
<strong>Lemma 2.</strong>
<em>
For a nonnegative integer \( n, \)

\[
n \oplus 1 =
  \begin{cases}
    n + 1 &amp; \text{if } n \text{ is even}, \\
    n - 1 &amp; \text{if } n \text{ is odd}.
  \end{cases}
\]

where the symbol \( \oplus \) denotes bitwise XOR operation on two
nonnegative integers.
</em>
</p>

<p>
<em>Proof.</em>
Let the binary representation of \( n \) be \( b_m \dots b_1 b_0 \)
where \( m \) is a nonnegative integer and \( b_m \) represents the most
significant nonzero bit of \( n. \)
</p>
<p>
If \( n \) is even, \( b_0 = 0. \) In this case, \( n \) may be written
as \( b_m \dots b_1 0. \) Thus \( n \oplus 1 \) may be written as \( b_m
\dots b_1 1. \) Therefore \( n \oplus 1 = n + 1. \)
</p>

<p>
If \( n \) is odd, \( b_0 = 1. \) In this case, \( n \) may be written
as \( b_m \dots b_1 1. \) Thus \( n \oplus 1 \) may be written as \( b_m
\dots b_1 0. \) Therefore \( n \oplus 1 = n - 1. \)
</p>

<p>
Note that for odd \( n, \) lemma 1 can also be derived as a corollary of
lemma 2 in this manner:

\[
k \oplus (k - 1)
= k \oplus (k \oplus 1)
= (k \oplus k) \oplus 1
= 0 \oplus 1
= 1.
\]
</p>


<!-- Lemma 3 -->
<p>
<strong>Lemma 3.</strong>
<em>
If \( x \) is an even nonnegative integer and \( y \) is an odd positive
integer, then \( x \oplus y \) is odd, where the symbol \( \oplus \)
denotes bitwise XOR operation on two nonnegative integers.
</em>
</p>

<p>
<em>Proof.</em>
Let the binary representation of \( x \) be \( b_{xm_x} \dots b_{x1}
b_{x0} \) and that of \( y \) be \( b_{ym_y} \dots b_{y1} b_{y0} \)
where \( m_x \) and \( m_y \) are nonnegative integers and \( b_{xm_x}
\) and \( b_{xm_y} \) represent the most significant nonzero bits of \(
x \) and \( y, \) respectively.
</p>

<p>
Since \( x \) is even, \( b_{x0} = 0. \) Since \( y \) is odd,
\( b_{y0} = 1. \)
</p>

<p>
Let \( z = x \oplus y \) with a binary representation of \( b_{zm_z}
\dots b_{z1} b_{z0} \) where \( m_{zm_z} \) is a nonnegative integer and
\( b_{zm_z} \) is the most significant nonzero bit of \( z. \)
</p>

<p>
We get \( b_{z0} = b_{x0} \oplus b_{y0} = 0 \oplus 1 = 1. \) Therefore
\( z \) is odd.
</p>


<h2 id="theorems"><a href="#theorems">Theorems</a></h2>

<!-- Theorem 1 -->
<p>
<strong>Theorem 1.</strong>
<em>
Let \( \oplus \) denote bitwise XOR operation on two nonnegative
integers and

\[
  f(k) =
    \begin{cases}
      n                        &amp; \text{if } n = 0, \\
      n \oplus (f(n - 1) - 1)  &amp; \text{if } n &gt; 1.
    \end{cases}
\]

where \( k \) is a nonnegative integer and \( n \) is an odd positive
integer. Then

\[
  f(k) =
    \begin{cases}
      n &amp; \text{if } k \text{ is even}, \\
      1 &amp; \text{if } k \text{ is odd}.
    \end{cases}
\]
</em>
</p>

<p>
<em>Proof.</em>
This is a proof by mathematical induction. We have \( f(0) = n \) by
definition. Therefore the base case holds good.
</p>

<p>
Let us assume that \( f(k) = n \) for any even \( k \) (induction
hypothesis). Let \( k' = k + 1 \) and \( k'' = k + 2. \)
</p>

<p>
If \( k \) is even, we get

\begin{align*}
f(k')  &amp; = n \oplus (f(k) - 1)  &amp;&amp; \text{(by definition)} \\
       &amp; = n \oplus (n - 1)     &amp;&amp; \text{(by induction hypothesis)} \\
       &amp; = 1                    &amp;&amp; \text{(by lemma 1)},\\
f(k'') &amp; = n \oplus (f(k') - 1) &amp;&amp; \text{(by definition)} \\
       &amp; = n \oplus (1 - 1)     &amp;&amp; \text{(since \( f(k') = 1\))} \\
       &amp; = n \oplus 0 \\
       &amp; = n.
\end{align*}
</p>

<p>
Since \( f(k'') = n \) and \( k'' \) is the next even number after
\( k, \) the induction step is complete. The induction step shows that
for every even \( k, \) \( f(k) = n \) holds good. It also shows that as
a result of \( f(k) = n \) for every even \( k, \) we get \( f(k') = 1
\) for every odd \( k'. \)
</p>

<!-- Theorem 2 -->
<p>
<strong>Theorem 2.</strong>
<em>
Let \( \oplus \) denote bitwise XOR operation on two nonnegative
integers and

\[
  f(k) =
    \begin{cases}
      n                        &amp; \text{if } n = 0, \\
      n \oplus (f(n - 1) - 1)  &amp; \text{if } n &gt; 1.
    \end{cases}
\]

where \( k \) is a nonnegative integer, \( n \) is an even positive
integer, and \( 0 \leq k \leq n. \) Then

\[
  f(k) = 0 \iff k = n.
\]
</em>
</p>

<p>
<em>Proof.</em>
We will first show by the principle of mathematical induction that for
even \( k, \) \( f(k) = n - k. \) We have \( f(0) = n \) by definition,
so the base case holds good. Now let us assume that \( f(k) = n - k \)
holds good for any even \( k \) where \( 0 \leq k \leq n \) (induction
hypothesis).
</p><p>
Since \( n \) is even (by definition) and \( k \) is even (by induction
hypothesis), \( f(k) = n - k \) is even. As a result, \( f(k) - 1 \) is
odd. By lemma 3, we conclude that \( f(k + 1) = n \oplus (f(k) - 1) \)
is odd.
</p>

<p>
Now we perform the induction step as follows:

\begin{align*}
f(k + 2) &amp; = n \oplus (f(k + 1) - 1)
                 &amp;&amp; \text{(by definition)} \\
         &amp; = n \oplus (f(k + 1) \oplus 1)
                 &amp;&amp; \text{(by lemma 2 for odd \( n \))} \\
         &amp; = n \oplus ((n \oplus (f(k) - 1)) \oplus 1)
                 &amp;&amp; \text{(by definition)} \\
         &amp; = (n \oplus n ) \oplus ((f(k) - 1) \oplus 1)
                 &amp;&amp; \text{(by associativity of XOR)} \\
         &amp; = 0 \oplus ((f(k) - 1) \oplus 1) \\
         &amp; = (f(k) - 1) \oplus 1 \\
         &amp; = (f(k) - 1) - 1
                 &amp;&amp; \text{(from lemma 2 for odd \( n \))} \\
         &amp; = f(k) - 2 \\
         &amp; = n - k - 2
                 &amp;&amp; \text{(by induction hypothesis).}
\end{align*}

This completes the induction step and proves that \( f(k) = n - k \)
for even \( k \) where \( 0 \leq k \leq n. \)
</p>

<p>
We have shown above that \( f(k) \) is even for every even \( k \) where
\( 0 \leq k \leq n \) which results in \( ‚Ä¶</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://susam.in/blog/loopy-c-puzzle/">https://susam.in/blog/loopy-c-puzzle/</a></em></p>]]>
            </description>
            <link>https://susam.in/blog/loopy-c-puzzle/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25175769</guid>
            <pubDate>Sun, 22 Nov 2020 07:47:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Build a Minimum Loveable Product]]>
            </title>
            <description>
<![CDATA[
Score 48 | Comments 26 (<a href="https://news.ycombinator.com/item?id=25175220">thread link</a>) | @grwthckrmstr
<br/>
November 21, 2020 | https://www.preetamnath.com/micro-saas/minimum-loveable-product-micro-saas | <a href="https://web.archive.org/web/*/https://www.preetamnath.com/micro-saas/minimum-loveable-product-micro-saas">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>You've validated your micro-SaaS idea and are ready to start building the product.</p><p>The obvious next questions are</p><ol start="" role="list"><li>Which features should the product include in its first version?</li><li>How long should you take to build it?</li></ol><p>Through this post, I provide you with a framework to identify your initial product features, how to decide what to include or exclude from the first versions, and continue building upon it.</p><p>Before jumping into MLP, let's first understand what MVP&nbsp;is and why it's not enough in today's times.</p><h2>What is a Minimum Viable Product (MVP)?</h2><p><a href="https://twitter.com/ericries" target="_blank">Eric Ries</a> popularized the term <a href="https://en.wikipedia.org/wiki/Minimum_viable_product" target="_blank">minimum viable product</a> in his book <a href="http://theleanstartup.com/" target="_blank">The Lean Startup</a> as that version of a new product that is just usable enough by early customers who can then provide feedback to the team. This feedback should help the team generate validated learnings and guide them on future product development and features.</p><h4>When MVP still works</h4><p>MVP is not dead though. It still works, given the right kind of problem statements.</p><p>Suppose you're building something that simply doesn't exist in the world, and it's something that people really want and have no alternative to getting it except from you.</p><p>At this time, people will accept a textbook MVP, simply because they have no frame of reference to compare it with. Or better yet, because they have no alternative to replace your MVP with.</p><h4>Why MVP&nbsp;is not enough in 2021</h4><p>Over the past few years as smartphone penetration boomed, products matured, product design and user experience matured, people's expectations have increased.</p><p>No longer does a quickly thrown together prototype cut it. People expect a minimum level of good UX and ease-of-use, else they'll leave your app before even giving it a proper try.</p><p>In fact, in 2021 great UX might be one strong reason people pick your product over incumbents. That's what happened with <a href="https://transistor.fm/" target="_blank">Transistor.fm</a>, who made podcast hosting simple and easy.</p><p>People expect good aesthetics that make a first impression, simply because that's what they have become used to from the plethora of beautiful and well-designed apps out there in the world.</p><p>People expect products to be fully functional as advertised. Buggy products are not acceptable, and in fact people might quickly take to Twitter or social media to let others know that a product is unreliable.</p><p>The MVP mindset intensely focuses on building the bare minimum, and that often leaves users frustrated and drives them to seek alternative solutions. Stiffer competition means that people WILL compare your product to alternatives in the market, it's inevitable. And unless you provide something unique and valuable that nobody else does, people are likely to leave.</p><p>All these reasons and more make MVP&nbsp;a dated concept, especially in the context of SaaS products. But above all, I think the MVP mindset makes product builders think too heavily about the "minimum" and often so at the cost of "viable".</p><p>That's a common pitfall and to avoid that, I propose the MLP framework.</p><h2>What is a Minimum Loveable Product (MLP)?</h2><p>A great new concept that I've fallen in love with and personally follow in every product I build is MLP, or Minimum Loveable Product.</p><p>The term MLP was first coined by Brian de Haaff, the co-founder of Aha!, in his book <a href="https://www.aha.io/lovability" target="_blank">Lovability</a>.</p><p>Its definition is an extension of what Eric Ries already introduced to the world with MVP. With MLP though, you are trying to build the minimum "loveable" product, with a focus on no matter how small or feature-stripped the first version of your product is, it is sufficient to deliver a delightful experience to your user.</p><h4>Minimum Viable Product and the burnt pizza analogy</h4><p><a href="https://www.linkedin.com/in/jiaona/" target="_blank">Jiaona Zhang</a>, who is currently VP&nbsp;of Product at Webflow (this blog is built using Webflow) introduced the <a href="https://firstround.com/review/dont-serve-burnt-pizza-and-other-lessons-in-building-minimum-lovable-products/" target="_blank">burnt pizza analogy</a> to her students at Stanford.</p><p>‚Äú<em>Say you‚Äôre trying to test whether people like pizza. If you serve them burnt pizza, you‚Äôre not getting feedback on whether they like pizza. You only know that they don‚Äôt like burnt pizza. Similarly, when you‚Äôre only relying on the MVP, the fastest and cheapest functional prototype, you risk not actually testing your product, but rather a poor or flawed version of it.</em>"</p><p>A great practical example of Minimum Loveable Product is the Apple iPad. All the tablets that came before Apple's tablet were MVPs.</p><h2>MLP vs MVP</h2><p>If you're new to all these terminologies, I understand that it can be confusing. Bear with me, you'll wrap your head around it soon enough.</p><p>Build an MLP when you are solving a problem that's already understood by people, and an MVP when people don't easily understand a problem.</p><p>Build an MLP when you can clearly define and understand a market and you are trying to stand out from the existing tools. Build an MVP when you're trying to gauge if there even exists a market to serve.</p><p>An&nbsp;MLP can be built when you know exactly what customers want. An MVP is when you don't know what customers want, and therefore you want to throw things at the wall as quickly as possible and see what sticks.</p><p>An MLP is necessary if you are building in a market where several large and well-known alternatives already exist. An MVP is the right approach for a new market with barely any alternatives, or those solutions are not yet known by the masses.</p><p>While building an MLP, you make a dedicated effort to succeed with that idea. With MVP, you are trying to determine quickly whether the idea can succeed or whether it will fail.</p><p>Building an&nbsp;MVP means you're ready for failure and also ready to pivot quickly as you learn more about the market. Which means you should make tech and architecture decisions that help you move fast above anything else. Scalability or good architecture design is a concern to pay attention to while building an MLP.</p><p>Finally, the end goal of an MLP is that the customers who use it find it sufficient in functionality and experience to be able to "love" it. With an MLP, you're building just enough that a customer with (hopefully) a real pain point would "tolerate" and continue using your product while you validate your assumptions.</p><h2>Minimum Marketable Product, Minimum Remarkable Product, Minimum Launchable Product</h2><p>The what?</p><p>I know, I know. I came across these terms for the first time today while researching to write this post. And I went through the literature so that I can tell you to safely ignore it.</p><p>If you understand and embody the concept of MLP, you don't need to think about any other frameworks or terminologies that you may discover while researching on Google.</p><h2>How to build an MLP for your Micro SaaS idea</h2><p>Alright, let's put aside theory and dive right in.</p><p>Here are the steps you should loosely follow to building an MLP.</p><h4>1. Understand the #1 problem you're trying to solve</h4><p>What's the #1 reason someone would want to use your Micro SaaS product over existing alternatives?</p><p>Is it that existing options have poor UX?&nbsp;Great, create a well designed and easy-to-use product. You'd be surprised to know how often people switch to an easier to use tool, simply because they are fed up of the poor UX that they encounter repeatedly.</p><p>Is it that existing alternatives are very expensive?&nbsp;Carve out a minimum set of features that people are paying a lot of money for and charge 1/10th for your v1 product. This might not work for very large customers, but vast majority of customers who are small or mid-sized are always looking for affordable alternatives.</p><p>It might not just be raw quantum of pricing, but certain companies targeting Enterprise customers have very complicated pricing slabs and tiers that are designed to give their sales person more room. In such a case, coming out with a competitor product which has a simple, easy-to-understand pricing is how you attract customers.</p><p>Are existing alternatives lacking certain features that leaves a subset of users very dissatisfied?&nbsp;Great, your MLP should specifically address that problem by building functionality that attracts these dissatisfied users. Side note - This is perhaps one of the best ways to go about building a new product.</p><p>In all cases, it involves understanding the problem you are solving and the exact reason why someone would use your product.</p><h4>2. Design a simple product that solves the top customer needs satisfactorily</h4><p>Once you have identified the #1 reason, it's time to decide on a feature set for your product that solves your customer's top pain points satisfactorily.</p><p><strong>Let's take an example</strong> - People want to add a feedback tracking tool inside their product, so that they can collect user feedback automatically. However, the existing solutions don't allow them to embed the feedback tracker within their tool.</p><p>That's your entry point into providing value that customers seek, but are not getting as of today.</p><p>Having understood the #1 problem, you also have to understand other requirements that fall under the "minimum" set of things you need to do to build a "loveable" product.</p><p>These could be:</p><ul role="list"><li>existing solutions are all well designed and aesthetically pleasing =&gt;&nbsp;your minimum loveable product needs to be well designed too</li><li>existing solutions are affordably priced with a easy to understand pricing structure =&gt; your MLP also needs a simple pricing structure that's affordable</li></ul><p>In general, you want to analyze your competitors and understand </p><ol start="" role="list"><li>What they are doing well</li><li>What users value from among those things</li></ol><p>In your MLP, you need to cover the intersection of (what they are doing well) x (what users value from among those).</p><h4>3. Set a short timeline for building your MLP</h4><p>No matter what you build, building in isolation for too long is dangerous. The main reason for that is - you get to know too late whether your assumptions about what the user really values are on point or off course.</p><p><strong>"But Preetam, you just told me to build a Minimum Loveable Product. And now you're saying I got to build it quickly?"</strong></p><p>Yes, that's exactly what I'm saying.</p><p>Short timeframe depends on what you are building, and the size of your team.</p><p>For example - with SuperLemon (WhatsApp plugin for Shopify), Sankalp and I built a MLP in 2 weeks time.</p><p>How?</p><p>We identified precisely the way we could do better - ‚Ä¶</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.preetamnath.com/micro-saas/minimum-loveable-product-micro-saas">https://www.preetamnath.com/micro-saas/minimum-loveable-product-micro-saas</a></em></p>]]>
            </description>
            <link>https://www.preetamnath.com/micro-saas/minimum-loveable-product-micro-saas</link>
            <guid isPermaLink="false">hacker-news-small-sites-25175220</guid>
            <pubDate>Sun, 22 Nov 2020 05:40:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Using Python's Bisect Module]]>
            </title>
            <description>
<![CDATA[
Score 29 | Comments 13 (<a href="https://news.ycombinator.com/item?id=25174048">thread link</a>) | @kaunta
<br/>
November 21, 2020 | https://johnlekberg.com/blog/2020-11-21-stdlib-bisect.html | <a href="https://web.archive.org/web/*/https://johnlekberg.com/blog/2020-11-21-stdlib-bisect.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><a href="https://johnlekberg.com/blog.html">Return to Blog
</a></p><p>By John Lekberg on November 21, 2020.
</p><hr>
<p><a href="https://news.ycombinator.com/item?id=25174048">Hacker News discussion.</a></p>
<hr>
<p>This week's post is about Python's <a href="https://docs.python.org/3/library/bisect.html">bisect</a> module. You will learn:</p>
<ul>
<li><a href="https://en.wikipedia.org/wiki/Data_binning">Statistical data binning</a> with <a href="https://docs.python.org/3/library/bisect.html#bisect.bisect">bisect.bisect</a>.</li>
<li>Adding new data to a sorted list with <a href="https://docs.python.org/3/library/bisect.html#bisect.insort">bisect.insort</a>.</li>
</ul>
<p>The goal of the <a href="https://docs.python.org/3/library/bisect.html">bisect</a> module is to allow you to efficiently search and
update sorted lists. To this end, it provides:</p>
<ul>
<li>A <a href="https://en.wikipedia.org/wiki/Binary_search_algorithm">binary search</a> implementation, <a href="https://docs.python.org/3/library/bisect.html#bisect.bisect">bisect.bisect</a>.</li>
<li>An "insert" -- as in <a href="https://en.wikipedia.org/wiki/Insertion_sort">insertion sort</a> -- implementation, <a href="https://docs.python.org/3/library/bisect.html#bisect.insort">bisect.insort</a>.</li>
</ul>

<p>In <a href="https://en.wikipedia.org/wiki/Data_binning">statistical data binning</a>, you have data that you want to group into "bins". E.g.</p>
<ul>
<li>You have data on different fruits and want to group "lemon" and "orange" into
"citrus".</li>
<li>You have data on students' grades and want to group scores between 80 and 90
into "B", scores between 90 and 100 into "A", etc.</li>
</ul>
<p>To me, a straightforward approach is to write a function that computes the bin.
E.g., binning fruits:</p>
<blockquote>
<pre><code>def bin_fruit(fruit):
    if fruit in ["lemon", "orange"]:
        return "citrus"
    elif fruit in ["apple", "pear"]:
        return "malinae"


import random

data = random.choices(
    ["lemon", "orange", "apple", "pear"], k=10
)
data
</code></pre>
</blockquote>
<pre><code>['lemon',
 'lemon',
 'apple',
 'apple',
 'apple',
 'lemon',
 'apple',
 'apple',
 'lemon',
 'pear']
</code></pre>
<blockquote>
<pre><code>[bin_fruit(x) for x in data]
</code></pre>
</blockquote>
<pre><code>['citrus',
 'citrus',
 'malinae',
 'malinae',
 'malinae',
 'citrus',
 'malinae',
 'malinae',
 'citrus',
 'malinae']
</code></pre>
<p>E.g., turning test scores into <a href="https://en.wikipedia.org/wiki/Academic_grading_in_the_United_States">letter grades</a>:</p>
<blockquote>
<pre><code>def bin_score(score):
    if 90 &lt;= score &lt;= 100:
        return "A"
    elif 80 &lt;= score &lt; 90:
        return "B"
    elif 70 &lt;= score &lt; 80:
        return "C"
    elif 60 &lt;= score &lt; 70:
        return "D"
    elif score &lt; 60:
        return "F"


import random

data = [random.randint(50, 100) for _ in range(10)]
data
</code></pre>
</blockquote>
<pre><code>[78, 87, 93, 78, 53, 92, 64, 70, 75, 60]
</code></pre>
<blockquote>
<pre><code>[bin_score(x) for x in data]
</code></pre>
</blockquote>
<pre><code>['C', 'B', 'A', 'C', 'F', 'A', 'D', 'C', 'C', 'D']
</code></pre>
<p>For a dataset of <var>n</var> records and <var>m</var> bins, the <a href="https://en.wikipedia.org/wiki/Time_complexity">time
complexity</a> of this approach tends to be</p>
<blockquote>
<p><a href="https://en.wikipedia.org/wiki/Big_O_notation">O</a>(<var>m</var><var>n</var>)</p>
</blockquote>
<p>Because binning one record takes O(<var>m</var>) time -- O(<var>m</var>)
if-statements are checked -- and <var>n</var> records need to be binned.</p>
<p>If the number of bins <var>m</var> is constant, then the overall time
complexity is simply O(<var>n</var>).</p>
<p>But what if the number of bins <var>m</var> is large enough that the
straightforward approach is too slow?</p>
<ul>
<li>
<p>For <a href="https://en.wikipedia.org/wiki/Continuous_or_discrete_variable">discrete data</a>, you can use <a href="https://docs.python.org/3/library/stdtypes.html#mapping-types-dict">dictionaries</a>. E.g., binning
fruits:</p>
<blockquote>
<pre><code>bins = {
    "lemon": "citrus",
    "orange": "citrus",
    "apple": "malinae",
    "pear": "malinae",
}

def bin_fruit(fruit):
    return bins[fruit]


import random

data = random.choices(
    ["lemon", "orange", "apple", "pear"], k=10
)
data
</code></pre>
</blockquote>
<pre><code>['lemon',
 'pear',
 'lemon',
 'lemon',
 'apple',
 'orange',
 'apple',
 'orange',
 'pear',
 'apple']
</code></pre>
<blockquote>
<pre><code>[bin_fruit(x) for x in data]
</code></pre>
</blockquote>
<pre><code>['citrus',
 'malinae',
 'citrus',
 'citrus',
 'malinae',
 'citrus',
 'malinae',
 'citrus',
 'malinae',
 'malinae']
</code></pre>
<p>Binning one record this way takes O(1) time -- regardless of the number of
bins <var>m</var> -- because <a href="https://docs.python.org/3/library/stdtypes.html#mapping-types-dict">dictionaries</a> are implemented using
<a href="https://en.wikipedia.org/wiki/Hash_table">hash tables</a>. And creating the <a href="https://docs.python.org/3/library/stdtypes.html#mapping-types-dict">dictionary</a> take O(<var>m</var>) time --
one entry for each bin. Thus, the overall time complexity, for <var>n</var>
records and <var>m</var> bins, is</p>
<blockquote>
<p>O(<var>m</var> + <var>n</var>).</p>
</blockquote>
</li>
<li>
<p>And, for <a href="https://en.wikipedia.org/wiki/Continuous_or_discrete_variable">continuous data</a>, you can use <a href="https://docs.python.org/3/library/bisect.html#bisect.bisect">bisect.bisect</a>. E.g., turning
test scores into <a href="https://en.wikipedia.org/wiki/Academic_grading_in_the_United_States">letter grades</a>:</p>
<blockquote>
<pre><code>score_bins = [60, 70, 80, 90]
score_letters = ["F", "D", "C", "B", "A"]

import bisect


def bin_score(score):
    i = bisect.bisect(score_bins, score)
    return score_letters[i]


import random

data = [random.randint(50, 100) for _ in range(10)]
data
</code></pre>
</blockquote>
<pre><code>[60, 100, 88, 98, 55, 52, 52, 94, 71, 85]
</code></pre>
<blockquote>
<pre><code>[bin_score(x) for x in data]
</code></pre>
</blockquote>
<pre><code>['D', 'A', 'B', 'A', 'F', 'F', 'F', 'A', 'C', 'B']
</code></pre>
<p>Binning one record this way takes O(log√Ç&nbsp;<var>m</var>) time, because
<a href="https://docs.python.org/3/library/bisect.html#bisect.bisect">bisect.bisect</a> uses <a href="https://en.wikipedia.org/wiki/Binary_search_algorithm">binary search</a> to navigate <code>score_bins</code>. And
creating <code>score_bins</code> takes O(<var>m</var>) time. Thus, the overall time
complexity, for <var>n</var> records and <var>m</var> bins, is</p>
<blockquote>
<p>O(<var>m</var> + <var>n</var> log <var>m</var>)</p>
</blockquote>
<p>NOTE: If you are able to use 3rd-party libraries, such as <a href="https://numpy.org/">NumPy</a> or
<a href="https://pandas.pydata.org/">Pandas</a>, then look at these functions: <a href="https://numpy.org/doc/stable/reference/generated/numpy.digitize.html">numpy.digitize</a>,
<a href="https://numpy.org/doc/stable/reference/generated/numpy.searchsorted.html#numpy.searchsorted">numpy.searchsorted</a>, <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.searchsorted.html">pandas.Series.searchsorted</a>, <a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.qcut.html#pandas.qcut">pandas.qcut</a>,
<a href="https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.cut.html">pandas.cut</a>.</p>
</li>
</ul>

<p>In this scenario, you have a sorted list of data and you want to:</p>
<ul>
<li>Compute <a href="https://en.wikipedia.org/wiki/Order_statistic">order statistics</a> (e.g. compute the <a href="https://en.wikipedia.org/wiki/Median">median</a>).</li>
<li>Add new data.</li>
</ul>
<p>For example, you can imagine having a temperature sensor that regularly reports
the temperature. You want to regularly report the median temperature, as well
as be able to incorporate new temperature data as it arrives.</p>
<p>To me, a straightforward approach is to use <a href="https://docs.python.org/3/library/stdtypes.html#mutable-sequence-types">list.append</a> and
<a href="https://docs.python.org/3/library/statistics.html#statistics.median">statistics.median</a>. E.g., monitoring temperatures:</p>
<blockquote>
<pre><code>def add_new_measurement(data, temperature):
    data.append(temperature)


def median(data):
    return statistics.median(data)


import random
import statistics

data = [random.randint(93, 100) for _ in range(10)]
data
</code></pre>
</blockquote>
<pre><code>[98, 94, 97, 94, 94, 98, 98, 94, 94, 95]
</code></pre>
<blockquote>
<pre><code>median(data)
</code></pre>
</blockquote>
<pre><code>94.5
</code></pre>
<blockquote>
<pre><code>add_new_measurement(data, 97)
data
</code></pre>
</blockquote>
<pre><code>[98, 94, 97, 94, 94, 98, 98, 94, 94, 95, 97]
</code></pre>
<blockquote>
<pre><code>median(data)
</code></pre>
</blockquote>
<pre><code>95
</code></pre>
<p>For a dataset of <var>n</var> records, the <a href="https://en.wikipedia.org/wiki/Time_complexity">time complexity</a> of this approach
tends to be</p>
<ul>
<li><strong>Computing median:</strong> O(<var>n</var>) or O(<var>n</var> log <var>n</var>) --
depending on how the median is computed.</li>
<li><strong>Adding new data:</strong> O(1).</li>
</ul>
<p>So if the workload requires frequently adding new data and infrequently
computing the median, this approach works well.</p>
<p>But what if the workload is inverted? For example, if temperature measurements
are received every couple of minutes, but the median must be computed every
couple of seconds.</p>
<p>In that scenario, I think we would be better suited by speeding up computing
the median, even at the expense of slowing down adding new data.</p>
<p>Computing order statistics can be done in O(1) time if the data is already
sorted. So a straightforward way to handle this workload would be to sort the
data after appending and use the fact that the data is sorted to efficiently
compute the median:</p>
<blockquote>
<pre><code>def add_new_measurement(data, temperature):
    data.append(temperature)
    data.sort()


def median(data):
    n = len(data)
    if n % 2 == 0:
        return (data[(n // 2) - 1] + data[n // 2]) / 2
    else:
        return data[n // 2]


import random

data = sorted(random.randint(93, 100) for _ in range(10))
data
</code></pre>
</blockquote>
<pre><code>[93, 94, 94, 96, 96, 97, 98, 99, 100, 100]
</code></pre>
<blockquote>
<pre><code>median(data)
</code></pre>
</blockquote>
<pre><code>96.5
</code></pre>
<blockquote>
<pre><code>add_new_measurement(data, 97)
data
</code></pre>
</blockquote>
<pre><code>[93, 94, 94, 96, 96, 97, 97, 98, 99, 100, 100]
</code></pre>
<blockquote>
<pre><code>median(data)
</code></pre>
</blockquote>
<pre><code>97
</code></pre>
<p>For a dataset of <var>n</var> records, the <a href="https://en.wikipedia.org/wiki/Time_complexity">time complexity</a> of this approach
tends to be</p>
<ul>
<li><strong>Computing median:</strong> O(1).</li>
<li><strong>Adding new data:</strong> O(<var>n</var> log <var>n</var>).</li>
</ul>
<p>But I think that the <a href="https://en.wikipedia.org/wiki/Time_complexity">time complexity</a> for adding new data can further be
improved by using <a href="https://docs.python.org/3/library/bisect.html#bisect.insort">bisect.insort</a>, which runs in</p>
<blockquote>
<p>O(<var>n</var>)</p>
</blockquote>
<p>Here's Python code that does that:</p>
<pre><code>import bisect


def add_new_measurement(data, temperature):
    bisect.insort(data, temperature)
</code></pre>
<p>Doing this changes the <a href="https://en.wikipedia.org/wiki/Time_complexity">time complexity</a> of adding new data from</p>
<blockquote>
<p>O(<var>n</var> log <var>n</var>)</p>
</blockquote>
<p>to</p>
<blockquote>
<p>O(<var>n</var>)</p>
</blockquote>

<p>In this week's post you learned how to use the <a href="https://docs.python.org/3/library/bisect.html">bisect</a> module for
statistical data binning and adding new data to sorted lists.</p>
<p>For further reading:</p>
<ul>
<li>Algorithms that process input piece-by-piece -- like the temperature sensor
scenario -- are called <a href="https://en.wikipedia.org/wiki/Online_algorithm">online algorithms</a>.</li>
<li><a href="https://docs.python.org/3/library/bisect.html#bisect.insort">bisect.insort</a> can be used to implement an <a href="https://en.wikipedia.org/wiki/Insertion_sort">Insertion sort</a>. Insertion
sort is an <a href="https://en.wikipedia.org/wiki/Online_algorithm">online algorithm</a> and -- along with Python's built-in
<a href="https://en.wikipedia.org/wiki/Timsort">timsort</a> -- is an <a href="https://en.wikipedia.org/wiki/Adaptive_sort">adaptive sorting algorithm</a> because it takes
advantage of data that is partially sorted.</li>
</ul>
<p>My challenge to you:</p>
<blockquote>
<p>The <a href="https://docs.python.org/3/library/bisect.html">bisect</a> module provides "left"- and "right"-variants of
<a href="https://docs.python.org/3/library/bisect.html#bisect.insort">bisect.insort</a> and <a href="https://docs.python.org/3/library/bisect.html#bisect.bisect">bisect.bisect</a>: <a href="https://docs.python.org/3/library/bisect.html#bisect.insort_left">bisect.insort_left</a>,
<a href="https://docs.python.org/3/library/bisect.html#bisect.insort_right">bisect.insort_right</a>, <a href="https://docs.python.org/3/library/bisect.html#bisect.bisect_left">bisect.bisect_left</a>, <a href="https://docs.python.org/3/library/bisect.html#bisect.bisect_right">bisect.bisect_right</a>.</p>
<p>Read the documentation and figure out what the difference between the "left"-
and "right"-variants is.</p>
</blockquote>
<p>If you enjoyed this week's post, share it with your friends and stay tuned for
next week's post. See you then!</p>

<hr>
<p>(If you spot any errors or typos on this post, contact me via my
<a href="https://johnlekberg.com/contact.html">contact page</a>.)
</p></div></div>]]>
            </description>
            <link>https://johnlekberg.com/blog/2020-11-21-stdlib-bisect.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25174048</guid>
            <pubDate>Sun, 22 Nov 2020 01:20:06 GMT</pubDate>
        </item>
    </channel>
</rss>
