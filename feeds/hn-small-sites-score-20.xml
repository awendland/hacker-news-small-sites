<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 20]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 20. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Mon, 22 Feb 2021 01:08:04 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-20.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Mon, 22 Feb 2021 01:08:04 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[Draw an iceberg and see how it would float in water]]>
            </title>
            <description>
<![CDATA[
Score 695 | Comments 88 (<a href="https://news.ycombinator.com/item?id=26201160">thread link</a>) | @raldi
<br/>
February 19, 2021 | https://joshdata.me/iceberger.html | <a href="https://web.archive.org/web/*/https://joshdata.me/iceberger.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

    
    <p>Draw an iceberg and see how it will float.</p>
    <p>(Inspired by a <a href="https://twitter.com/GlacialMeg/status/1362557149147058178?ref_src=twsrc%5Etfw">tweet by @GlacialMeg</a>)</p>

    <canvas id="canvas">
    </canvas>

    <p>In reality, an iceberg wouldn’t float <i>exactly</i> like this. Its three-dimensional distribution of mass and its relative density compared to the water are both significant factors that are only approximated here.</p>

    <hr>

    <p>Inspired by a tweet by @GlacialMeg:</p>
    <blockquote data-partner="tweetdeck"><div lang="en" dir="ltr"><p>Today I channeled my energy into this very unofficial but passionate petition for scientists to start drawing icebergs in their stable orientations. I went to the trouble of painting a stable iceberg with my watercolors, so plz hear me out.</p><p>(1/4) <a href="https://t.co/rtkCYub38b">pic.twitter.com/rtkCYub38b</a></p></div>— Megan Thompson-Munson (@GlacialMeg) <a href="https://twitter.com/GlacialMeg/status/1362557149147058178?ref_src=twsrc%5Etfw">February 19, 2021</a></blockquote>
    


    </div></div>]]>
            </description>
            <link>https://joshdata.me/iceberger.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26201160</guid>
            <pubDate>Sat, 20 Feb 2021 03:16:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[My Life in E-Ink]]>
            </title>
            <description>
<![CDATA[
Score 143 | Comments 77 (<a href="https://news.ycombinator.com/item?id=26200630">thread link</a>) | @HaoZeke
<br/>
February 19, 2021 | https://rgoswami.me/posts/my-life-in-eink/ | <a href="https://web.archive.org/web/*/https://rgoswami.me/posts/my-life-in-eink/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><blockquote><p>Collection of odds and ends relating to e-readers including personal reminisces</p></blockquote><h2 id="background">Background</h2><p>Reading has been a huge part of my life. The written word has had arguably more of an impact on my life than anything I have experienced in person. As a kid back in early 2000’s; this meant a lot of library trips and saving for paperbacks. I also caught the first wave of the e-ink revolution. Nothing beats a real book, in terms of textures and scents; but e-ink devices and the fantastic tools outlined here should make reading digital books much more palpable&nbsp;<sup id="fnref:1"><a href="#fn:1" role="doc-noteref">1</a></sup>.</p><p>I have been reading on my <a href="https://en.wikipedia.org/wiki/Kobo%5FAura%5FHD">Kobo Aura HD</a> for almost a decade now, ever since its release. This means my setup is about as stable as its going to get in the near future. As good a time as any to collect my thoughts&nbsp;<sup id="fnref:2"><a href="#fn:2" role="doc-noteref">2</a></sup>. The focus is on e-ink devices and auxiliary tools; not on all digital content; so there are no mentions of syncing or reading on the go (with a phone) or of monitors which are good for reading on.</p><h3 id="the-content">The Content</h3><p>In general; my e-ink reading habits can be broadly broken into the following categories:</p><dl><dt>Light Reading</dt><dd>Practically this includes <a href="https://www.goodreads.com/user/show/33462912-rohit-goswami">anything I review on Goodreads</a>; these are not often re-read; nor read very deeply; since they are read for pleasure. They are however, rarely deleted</dd><dt>Required Reading</dt><dd>Anything which typically requires me to take notes or practice / write out proofs; these are most often considered to be either coursework (for someone somewhere) or research monographs. These are typically large (in size) and unwieldy (in that they often lack TOCs) and are read multiple times; with a focus on highlights and notes</dd><dt>Active Research</dt><dd>These are the most ephemeral of my reading habits; and also the most numerous; I do not typically store these on my e-reader; and rarely need to make notes on the reader&nbsp;<sup id="fnref:3"><a href="#fn:3" role="doc-noteref">3</a></sup>. These are often tiny; but require special work due to the metadata involved</dd></dl><table><thead><tr><th>Content Type</th><th>Software Stack</th><th>Deletion Rate</th></tr></thead><tbody><tr><td>Light Reading</td><td>Calibre</td><td>Rare</td></tr><tr><td>Required Reading</td><td>Calibre</td><td>Never</td></tr><tr><td>Active Research</td><td>Calibre + Zotero</td><td>Frequent</td></tr></tbody></table><p>Though I am a huge proponent of RSS feeds (with <a href="https://gitlab.com/news-flash/news%5Fflash%5Fgtk">Newsflash</a>) and read online content voraciously with both a <a href="https://app.getpocket.com/">Pocket</a> and <a href="https://www.diigo.com/user/rgoswami">Diigo</a> subscription<sup id="fnref:4"><a href="#fn:4" role="doc-noteref">4</a></sup>; I sincerely do not believe blog stuff or anything tailored for the web should have a presence on an e-ink device; so there shall be no mention of those parts of my reading habits<sup id="fnref:5"><a href="#fn:5" role="doc-noteref">5</a></sup>.</p><h2 id="hardware">Hardware</h2><p>My primary e-reader is still my <a href="https://www.kobo.com/koboaurahd?%5F%5F%5Fstore=au&amp;style=onestore">Kobo Aura HD</a> (complete with a snazzy <a href="https://www.amazon.com/Cover-Up-eReader-Natural-Cover-Function/dp/B00DZJ5VM0">hemp sleep-cover</a>), and has been my go to for almost a decade now since its release. Recently I have augmented my workflow with the <a href="https://remarkable.com/store/remarkable-2">reMarkable 2</a>; though I have yet to break it in very well; mostly because I tend to gravitate towards typing out my thoughts&nbsp;<sup id="fnref:6"><a href="#fn:6" role="doc-noteref">6</a></sup> instead of writing.</p><p>The Kobo Aura HD is still the pinnacle of reading technology to me; mostly because the firmware is easy to bypass; and there is a vibrant community of developers on the <a href="https://www.mobileread.com/forums/showthread.php?t=210800">MobileRead Forums</a>. Display and spec aside; the biggest reason for never replacing it has been been the simple fact that most modern e-readers no longer support SD cards; and much of my workflow depends on storing insane amounts of material offline&nbsp;<sup id="fnref:7"><a href="#fn:7" role="doc-noteref">7</a></sup>.</p><figure><img src="https://d33wubrfki0l68.cloudfront.net/d393a91160884052b7717a31a565283336a03ccf/eb437/ox-hugo/2021-02-20_01-39-20_screenshot.png" alt="Figure 1: Primary reading device with Koreader"><figcaption><p>Figure 1: Primary reading device with Koreader</p></figcaption></figure><p>Personally, I never use Nickel (the default Kobo interface), and it would probably choke trying to scan my 200 GB of content; so I haven’t updated the firmware in forever. My interactions are almost always in <a href="https://koreader.rocks/">Koreader</a>; and my launching poison of choice is the now no longer developed <a href="https://www.mobileread.com/forums/showthread.php?t=293804">Kobo start menu</a>&nbsp;<sup id="fnref:8"><a href="#fn:8" role="doc-noteref">8</a></sup>.</p><h2 id="software">Software</h2><p>Broadly speaking; the main parts of the software pipeline from digital book to brain are simply the syncing mechanism and the UI/UX/OS of the device in question; though it is often best to consider pre-processing books for devices too. These are covered in the order used.</p><h3 id="k2pdfopt">k2pdfopt</h3><p>The thought of reflowing text for an optimal reading experience, especially given the slightly limited processing power of my primary reading device is an enticing prospect. <a href="https://www.willus.com/k2pdfopt/">K2pdfopt or the Kindle 2 PDF Optimizer</a> is as criminally underrated as it is fantastic. An approach which works well for my device involves setting up <a href="https://github.com/HaoZeke/Dotfiles/blob/master/dotfiles/common/.local/bin/fileHelpers/docK2pdf">a simple shell script</a> (part <a href="https://github.com/HaoZeke/Dotfiles">of my Dotfiles</a>) for optimizing files on the fly before sending them through <code>calibre</code>.</p><div><pre><code data-lang="bash"><span>#!/usr/bin/env bash
</span><span></span><span># Get a filename</span>
<span>case</span> <span>"</span><span>$#</span><span>"</span> in
0<span>)</span>
      <span>echo</span> <span>"No arguments, so enter the filename, WITH the extension"</span>
      <span>read</span> -p <span>'Document: '</span> docfile
      <span>;;</span>
1<span>)</span>
      <span>echo</span> <span>"OK, using the filename"</span>
      <span>docfile</span><span>=</span><span>"</span><span>$1</span><span>"</span>
      <span>;;</span>
*<span>)</span>
      <span>echo</span> <span>"Illegal number of parameters"</span>
      <span>exit</span>
      <span>;;</span>
<span>esac</span>
<span># Get basename</span>
<span>basename</span><span>=</span><span>"</span><span>${</span><span>docfile</span><span>%.*</span><span>}</span><span>"</span>
<span>ext</span><span>=</span><span>"</span><span>${</span><span>docfile</span><span>##*</span><span>\.</span><span>}</span><span>"</span>
<span>echo</span> <span>"Basename </span><span>${</span><span>basename</span><span>}</span><span> with </span><span>$ext</span><span> from </span><span>$docfile</span><span>"</span>
<span>echo</span> <span>"Making a local store for the outputs"</span>
mkdir -p <span>"</span><span>$HOME</span><span>/auraHDopt"</span>

<span>case</span> <span>"</span><span>$ext</span><span>"</span> in
<span>"djvu"</span><span>)</span>
      <span>echo</span> <span>"Converting djvu to pdf via ps and running k2pdfopt"</span>
      djvups <span>"</span><span>${</span><span>basename</span><span>}</span><span>.djvu"</span> <span>"</span><span>${</span><span>basename</span><span>}</span><span>.ps"</span>
      ps2pdf <span>"</span><span>${</span><span>basename</span><span>}</span><span>.ps"</span> <span>"</span><span>${</span><span>basename</span><span>}</span><span>.pdf"</span>
      <span># The newline is for simulating the Enter key</span>
      <span>echo</span> <span>|</span> k2pdfopt <span>"</span><span>${</span><span>basename</span><span>}</span><span>.pdf"</span> -wrap -hy -ws -0.2 -dev kbhd -x
      <span>echo</span> <span>"Cleaning up"</span>
      mv <span>"</span><span>${</span><span>basename</span><span>}</span><span>_k2opt.pdf"</span> <span>"</span><span>$HOME</span><span>/auraHDopt"</span>
      rm -rf <span>"</span><span>${</span><span>basename</span><span>}</span><span>.{ps,pdf}"</span>
      <span>;;</span>
<span>"pdf"</span><span>)</span>
      <span>echo</span> <span>"Converting pdf with gs and running k2pdfopt"</span>
      gs -sDEVICE<span>=</span>pdfwrite -dCompatibilityLevel<span>=</span>1.4 -dPDFSETTINGS<span>=</span>/screen <span>\
</span><span></span>              -dNOPAUSE -dQUIET -dBATCH -sOutputFile<span>=</span><span>"</span><span>${</span><span>basename</span><span>}</span><span>gs.pdf"</span> <span>"</span><span>${</span><span>basename</span><span>}</span><span>.pdf"</span>
      <span>echo</span> <span>|</span> k2pdfopt <span>"</span><span>${</span><span>basename</span><span>}</span><span>gs.pdf"</span> -wrap -hy -ws -0.2 -dev kbhd -x
      <span>echo</span> <span>"Cleaning up"</span>
      rm <span>"</span><span>${</span><span>basename</span><span>}</span><span>gs.pdf"</span> -rf
      mv <span>"</span><span>${</span><span>basename</span><span>}</span><span>gs_k2opt.pdf"</span> <span>"</span><span>$HOME</span><span>/auraHDopt"</span>
      <span>;;</span>
*<span>)</span>
      <span>echo</span> <span>"Illegal file type"</span>
      <span>exit</span>
      <span>;;</span>
<span>esac</span>
</code></pre></div><p>The outputs can also be further processed with an <a href="https://github.com/HaoZeke/Dotfiles/blob/master/dotfiles/common/.local/bin/fileHelpers/isOcr">OCR (Optical Character Recognition) script</a> if required, and then edited in <a href="https://code-industry.net/masterpdfeditor/">Master PDF Editor</a> or something similar to add the table of contents interactively as well.</p><div><pre><code data-lang="bash"><span>#!/bin/bash
</span><span></span><span># Use as  find . -type f -name "*.pdf" -exec isOcr '{}' \;</span>

<span># Shamelessly kanged from here:</span>
<span># https://stackoverflow.com/questions/7997399/bash-script-to-check-pdfs-are-ocrd</span>
<span># Only searches for text on the first 5 pages</span>
<span># Modified to have red text. Also to possibly ocr the thing.</span>

<span># -*- mode: shell-script-mode -*-</span>

<span>MYFONTS</span><span>=</span><span>$(</span>pdffonts -l <span>15</span> <span>"</span><span>$1</span><span>"</span> <span>|</span> tail -n +3 <span>|</span> cut -d<span>' '</span> -f1 <span>|</span> sort <span>|</span> uniq<span>)</span>
<span>if</span> <span>[</span> <span>"</span><span>$MYFONTS</span><span>"</span> <span>=</span> <span>''</span> <span>]</span> <span>||</span> <span>[</span> <span>"</span><span>$MYFONTS</span><span>"</span> <span>=</span> <span>'[none]'</span> <span>]</span><span>;</span> <span>then</span>
    <span>echo</span> <span>"</span><span>$(</span>tput setaf 1<span>)</span><span>NOT OCR'ed: </span><span>$1</span><span>"</span>
    <span>if</span> <span>[[</span> -x <span>"</span><span>$(</span>which ocrmypdf<span>)</span><span>"</span> <span>]]</span><span>;</span> <span>then</span>
        <span>echo</span> <span>"</span><span>$(</span>tput setaf 4<span>)</span><span>"</span>
        <span>echo</span> <span>"Converting to </span><span>${</span><span>1</span><span>%.*</span><span>}</span><span>_ocr.pdf with ocrmypdf"</span>
        <span>echo</span> <span>"</span><span>$(</span>tput setaf 7<span>)</span><span>"</span>
        ocrmypdf --deskew --clean --rotate-pages <span>\
</span><span></span>            --jobs <span>4</span> -v --output-type pdfa <span>"</span><span>$1</span><span>"</span> <span>"</span><span>${</span><span>1</span><span>%.*</span><span>}</span><span>_ocr.pdf"</span>
    <span>elif</span> <span>[[</span> -x <span>"</span><span>$(</span>which pypdfocr<span>)</span><span>"</span> <span>]]</span><span>;</span> <span>then</span>
        <span>echo</span> <span>"</span><span>$(</span>tput setaf 2<span>)</span><span> Looking for config files at </span><span>$XDG_CONFIG_HOME</span><span>/pypdfocr/config.yml"</span>
        <span>echo</span> <span>"</span><span>$(</span>tput setaf 3<span>)</span><span>"</span>
        <span>if</span> <span>[[</span> -e <span>$XDG_CONFIG_HOME</span>/pypdfocr/config.yml <span>]]</span><span>;</span> <span>then</span>
            <span>echo</span> <span>"Using configuration settings"</span>
            <span>echo</span> <span>"</span><span>$(</span>tput setaf 4<span>)</span><span>"</span>
            pypdfocr -c <span>$XDG_CONFIG_HOME</span>/pypdfocr/config.yml <span>"</span><span>$1</span><span>"</span>
        <span>else</span>
            <span>echo</span> <span>"Using default settings"</span>
            <span>echo</span> <span>"</span><span>$(</span>tput setaf 4<span>)</span><span>"</span>
            pypdfocr <span>"</span><span>$1</span><span>"</span>
        <span>fi</span>
        <span>echo</span> <span>"</span><span>$(</span>tput setaf 2<span>)</span><span> You might want to get pypdfocr"</span>
    <span>fi</span>
<span>else</span>
    <span>echo</span> <span>"</span><span>$1</span><span> is OCR'ed."</span>
<span>fi</span>
</code></pre></div><p>The end result is:</p><ul><li>A directory with perfectly <code>pdf</code> files re-flowed text<ul><li>Possibly OCR’ed for string searches</li></ul></li></ul><p>TOC editing is still rather janky; but this is also because the OCR process is still rather spotty.</p><h3 id="calibre">Calibre</h3><p><a href="https://calibre-ebook.com/">Calibre</a> is an excellent library software, and there are very few alternatives which offer all the salient features:</p><dl><dt>Syncing</dt><dd>Apart from working well with a plethora of official devices, Koreader is also pretty well supported, and mounting folders allows for easy management of a secret library (e.g. <code>.Library</code>) on an SD card to prevent Nickel from reading and choking on large libraries</dd><dt>Multiple Libraries</dt><dd>I personally keep one for fiction, one for non-fiction, and one (transiently populated) one for papers</dd><dt>Good metadata collection</dt><dd>Nothing beats rich metadata, and with third party plugins, all the best content providers can be leveraged for blurbs; plus most purchased books come with metadata which <code>calibre</code> can read</dd></dl><p>It isn’t perfect, there are far better <a href="https://opds.io/">OPDS (Open Publication Distribution System)</a> servers like the fantastic <a href="https://github.com/seblucas/cops">COPS (Calibre OPDS)</a> project, and there have been <a href="https://anarc.at/software/desktop/calibre/">some security concerns in the past</a>, but it is really usable and is <a href="https://github.com/kovidgoyal/calibre">under active development</a>; plus it has a <a href="https://kovidgoyal.net/">fun developer</a>. I also personally find the file conversion lacking, compared to <code>k2pdfopt</code>, but as a library management system it is really good.</p><h3 id="zotero-sync">Zotero Sync</h3><p>Calibre provides a handy <a href="https://www.mobileread.com/forums/showthread.php?p=3339191#poststop">ZMI (Zotero Metadata Importer) plugin</a> which allows for exported papers to be imported into <code>calibre</code> and from then into the e-reader as expected. Combined with the folder mounts facilitated by <code>calibre</code> this allows for a painless way to ensure a quick export; optimize; sync; read and delete workflow.</p><h3 id="koreader">Koreader</h3><p>Koreader is probably the best thing to happen to e-ink devices since sliced bread. It replaces the need to use any cables with an e-reader; since newer versions have a nice SSH server, and can also update itself. Since this is mostly used as is; and all the information required is on the <a href="https://github.com/koreader/koreader/wiki">Github Wiki</a>, there’s not much else to say here.</p><p>It is probably worth noting that the in-built re-flow options do tend to cause major artifacts on older hardware, and is best avoided. Almost equivalently, and at a far lower cost in terms of performance, page contents can be fit to width and zoomed in automatically, which is almost as good as working with <code>k2pdfopt</code> in some special cases.</p><h2 id="conclusions">Conclusions</h2><p>Given my unfortunate separation from my library back home; it is likely that my e-ink devices will continue to be my primary source of reading material. Plus the long retarded color e-ink market finally seems to be moving out of its stupor&nbsp;<sup id="fnref:9"><a href="#fn:9" role="doc-noteref">9</a></sup>. The only possible addendum to this methodology would probably involve integrating <code>orgmode</code> and the reMarkable 2 sometime. E-ink is here to stay. This setup would probably need revisions involving <code>rclone</code> or <code>syncthing</code> if I ever gave …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://rgoswami.me/posts/my-life-in-eink/">https://rgoswami.me/posts/my-life-in-eink/</a></em></p>]]>
            </description>
            <link>https://rgoswami.me/posts/my-life-in-eink/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26200630</guid>
            <pubDate>Sat, 20 Feb 2021 01:46:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A request for Pinboard old-timers]]>
            </title>
            <description>
<![CDATA[
Score 225 | Comments 104 (<a href="https://news.ycombinator.com/item?id=26199676">thread link</a>) | @Alex3917
<br/>
February 19, 2021 | https://www.prettyfwd.com/t/XiK8ArVIT6uVItPGeH3lzA/ | <a href="https://web.archive.org/web/*/https://www.prettyfwd.com/t/XiK8ArVIT6uVItPGeH3lzA/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.prettyfwd.com/t/XiK8ArVIT6uVItPGeH3lzA/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26199676</guid>
            <pubDate>Fri, 19 Feb 2021 23:56:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[F’: Flight Software and Embedded Systems Framework]]>
            </title>
            <description>
<![CDATA[
Score 135 | Comments 26 (<a href="https://news.ycombinator.com/item?id=26199346">thread link</a>) | @zeristor
<br/>
February 19, 2021 | https://nasa.github.io/fprime/ | <a href="https://web.archive.org/web/*/https://nasa.github.io/fprime/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main_content_wrap">
      <section id="main_content">
        <p>F´ is a software framework for rapid development and deployment of embedded systems and spaceflight applications.
Originally developed at NASA’s Jet Propulsion Laboratory, F´ is open source software that has been successfully deployed
for several space applications. It has been used for, but is not limited to, CubeSats, SmallSats, instruments, and
deployables.</p>

<p>F´ has the following features:</p>
<ul>
  <li>Component architecture with well-defined interfaces</li>
  <li>C++ framework providing core capabilities like queues, threads, and operating-system abstraction</li>
  <li>Tools for designing systems and automatically generating code from systems design</li>
  <li>A standard library of flight-worthy components</li>
  <li>Testing tools for unit and system-level testing</li>
</ul>

<table>
  <thead>
    <tr>
      <th>F´ Resources</th>
      <th>&nbsp;</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Features</td>
      <td><a href="https://nasa.github.io/fprime/features.html">Features</a></td>
    </tr>
    <tr>
      <td>Projects</td>
      <td><a href="https://nasa.github.io/fprime/projects.html">Projects</a></td>
    </tr>
    <tr>
      <td>Installation</td>
      <td><a href="https://nasa.github.io/fprime/INSTALL.html">INSTALL.md</a></td>
    </tr>
    <tr>
      <td>Tutorials</td>
      <td><a href="https://nasa.github.io/fprime/Tutorials/README.html">Tutorials</a></td>
    </tr>
    <tr>
      <td>User Guide</td>
      <td><a href="https://nasa.github.io/fprime/UsersGuide/guide.html">User Guide</a></td>
    </tr>
    <tr>
      <td>Repository</td>
      <td><a href="https://github.com/nasa/fprime">https://github.com/nasa/fprime</a></td>
    </tr>
    <tr>
      <td>Community Forum and Mailing List</td>
      <td><a href="https://groups.google.com/d/forum/fprime-community">https://groups.google.com/d/forum/fprime-community</a></td>
    </tr>
    <tr>
      <td>Community GitHub Organization</td>
      <td><a href="https://github.com/fprime-community">https://github.com/fprime-community</a></td>
    </tr>
    <tr>
      <td>Standard Reference Application</td>
      <td><a href="https://github.com/nasa/fprime/blob/master/Ref/README.md">Ref</a></td>
    </tr>
    <tr>
      <td>Raspberry PI Reference Application</td>
      <td><a href="https://github.com/nasa/fprime/blob/master/RPI/README.md">RPI</a></td>
    </tr>
    <tr>
      <td>Architecture Overview</td>
      <td><a href="https://nasa.github.io/fprime/Architecture/FPrimeArchitectureShort.pdf">Architecture</a></td>
    </tr>
  </tbody>
</table>

<h2 id="f-system-requirements">F´ System Requirements</h2>

<p>In order to develop applications with F´, the following requirements of the user’s system must be met.</p>

<ol>
  <li>Linux or Mac OS X operating system (or Windows Subsystem for Linux on Windows)</li>
  <li>CMake <a href="https://cmake.org/download/">https://cmake.org/download/</a> available on the system path</li>
  <li>Bash or Bash compatible shell</li>
  <li>CLang or GCC compiler</li>
  <li>Python 3 and PIP <a href="https://www.python.org/downloads/">https://www.python.org/downloads/</a></li>
</ol>

<h2 id="quick-installation-guide">Quick Installation Guide</h2>

<p>F´ can be quickly installed and ready to use by cloning the GitHub repository, installing Python code (typically in a
virtual environment), and building on of our reference applications. For full install instructions please see:
<a href="https://nasa.github.io/fprime/INSTALL.html">INSTALL.md</a>.</p>

<p><strong>Clone and Install</strong></p>
<div><div><pre><code>git clone https://github.com/nasa/fprime.git
cd fprime
pip install --upgrade wheel setuptools pip
pip install Fw/Python Gds/
</code></pre></div></div>
<p><strong>Build the Ref Application</strong></p>
<div><div><pre><code>cd Ref
fprime-util generate
fprime-util install
</code></pre></div></div>
<p><strong>Run the Ref Application</strong></p>


<h2 id="further-references">Further References</h2>

<p>Full information on the code and F´ are available at our Github page:
<a href="http://github.com/nasa/fprime">http://github.com/nasa/fprime</a>.</p>

<p>To start with, follow the <a href="https://nasa.github.io/fprime/INSTALL.html">installation guide</a>. Then inspect
either the <a href="https://github.com/nasa/fprime/blob/master/Ref/README.md">reference application</a>, 
<a href="https://github.com/nasa/fprime/blob/master/RPI/README.md">rapberry pi reference</a>, or the
<a href="https://nasa.github.io/fprime/Tutorials/README.html">tutorials</a>.</p>

      </section>
    </div></div>]]>
            </description>
            <link>https://nasa.github.io/fprime/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26199346</guid>
            <pubDate>Fri, 19 Feb 2021 23:16:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[IDOM – It's React, but in Python]]>
            </title>
            <description>
<![CDATA[
Score 22 | Comments 1 (<a href="https://news.ycombinator.com/item?id=26199008">thread link</a>) | @xdze2
<br/>
February 19, 2021 | https://rmorshea.github.io/articles/2021/idom-react-but-its-python/article/ | <a href="https://web.archive.org/web/*/https://rmorshea.github.io/articles/2021/idom-react-but-its-python/article/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-md-component="container">
      
      
        
      
      <main data-md-component="main">
        <div>
          
            
              
            
            
              
            
          
          <div>
            <article><a download="" href="https://rmorshea.github.io/articles/2021/idom-react-but-its-python/article/article.pdf" title="PDF Export"><svg style="height: 1.2rem; width: 1.2rem;" viewBox="0 0 384 512" xmlns="http://www.w3.org/2000/svg"><path d="M224 136V0H24C10.7 0 0 10.7 0 24v464c0 13.3 10.7 24 24 24h336c13.3 0 24-10.7 24-24V160H248c-13.2 0-24-10.8-24-24zm76.45 211.36l-96.42 95.7c-6.65 6.61-17.39 6.61-24.04 0l-96.42-95.7C73.42 337.29 80.54 320 94.82 320H160v-80c0-8.84 7.16-16 16-16h32c8.84 0 16 7.16 16 16v80h65.18c14.28 0 21.4 17.29 11.27 27.36zM377 105L279.1 7c-4.5-4.5-10.6-7-17-7H256v128h128v-6.1c0-6.3-2.5-12.4-7-16.9z"></path></svg></a>
              
                
                
                
<p><a href="https://github.com/idom-team/idom" target="_blank">IDOM</a> is a new declarative Python
package for building highly interactive user interfaces.</p>
<ul>
<li><a href="https://github.com/idom-team/idom"><span><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 496 512"><path d="M165.9 397.4c0 2-2.3 3.6-5.2 3.6-3.3.3-5.6-1.3-5.6-3.6 0-2 2.3-3.6 5.2-3.6 3-.3 5.6 1.3 5.6 3.6zm-31.1-4.5c-.7 2 1.3 4.3 4.3 4.9 2.6 1 5.6 0 6.2-2s-1.3-4.3-4.3-5.2c-2.6-.7-5.5.3-6.2 2.3zm44.2-1.7c-2.9.7-4.9 2.6-4.6 4.9.3 2 2.9 3.3 5.9 2.6 2.9-.7 4.9-2.6 4.6-4.6-.3-1.9-3-3.2-5.9-2.9zM244.8 8C106.1 8 0 113.3 0 252c0 110.9 69.8 205.8 169.5 239.2 12.8 2.3 17.3-5.6 17.3-12.1 0-6.2-.3-40.4-.3-61.4 0 0-70 15-84.7-29.8 0 0-11.4-29.1-27.8-36.6 0 0-22.9-15.7 1.6-15.4 0 0 24.9 2 38.6 25.8 21.9 38.6 58.6 27.5 72.9 20.9 2.3-16 8.8-27.1 16-33.7-55.9-6.2-112.3-14.3-112.3-110.5 0-27.5 7.6-41.3 23.6-58.9-2.6-6.5-11.1-33.3 2.6-67.9 20.9-6.5 69 27 69 27 20-5.6 41.5-8.5 62.8-8.5s42.8 2.9 62.8 8.5c0 0 48.1-33.6 69-27 13.7 34.7 5.2 61.4 2.6 67.9 16 17.7 25.8 31.5 25.8 58.9 0 96.5-58.9 104.2-114.8 110.5 9.2 7.9 17 22.9 17 46.4 0 33.7-.3 75.4-.3 83.6 0 6.5 4.6 14.4 17.3 12.1C428.2 457.8 496 362.9 496 252 496 113.3 383.5 8 244.8 8zM97.2 352.9c-1.3 1-1 3.3.7 5.2 1.6 1.6 3.9 2.3 5.2 1 1.3-1 1-3.3-.7-5.2-1.6-1.6-3.9-2.3-5.2-1zm-10.8-8.1c-.7 1.3.3 2.9 2.3 3.9 1.6 1 3.6.7 4.3-.7.7-1.3-.3-2.9-2.3-3.9-2-.6-3.6-.3-4.3.7zm32.4 35.6c-1.6 1.3-1 4.3 1.3 6.2 2.3 2.3 5.2 2.6 6.5 1 1.3-1.3.7-4.3-1.3-6.2-2.2-2.3-5.2-2.6-6.5-1zm-11.4-14.7c-1.6 1-1.6 3.6 0 5.9 1.6 2.3 4.3 3.3 5.6 2.3 1.6-1.3 1.6-3.9 0-6.2-1.4-2.3-4-3.3-5.6-2z"></path></svg></span> https://github.com/idom-team/idom</a></li>
<li><a href="https://idom-docs.herokuapp.com/"><span><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><path d="M448 360V24c0-13.3-10.7-24-24-24H96C43 0 0 43 0 96v320c0 53 43 96 96 96h328c13.3 0 24-10.7 24-24v-16c0-7.5-3.5-14.3-8.9-18.7-4.2-15.4-4.2-59.3 0-74.7 5.4-4.3 8.9-11.1 8.9-18.6zM128 134c0-3.3 2.7-6 6-6h212c3.3 0 6 2.7 6 6v20c0 3.3-2.7 6-6 6H134c-3.3 0-6-2.7-6-6v-20zm0 64c0-3.3 2.7-6 6-6h212c3.3 0 6 2.7 6 6v20c0 3.3-2.7 6-6 6H134c-3.3 0-6-2.7-6-6v-20zm253.4 250H96c-17.7 0-32-14.3-32-32 0-17.6 14.4-32 32-32h285.4c-1.9 17.1-1.9 46.9 0 64z"></path></svg></span> https://idom-docs.herokuapp.com</a></li>
<li><a href="https://github.com/idom-team/idom/discussions"><span><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path d="M504 256c0 136.997-111.043 248-248 248S8 392.997 8 256C8 119.083 119.043 8 256 8s248 111.083 248 248zM262.655 90c-54.497 0-89.255 22.957-116.549 63.758-3.536 5.286-2.353 12.415 2.715 16.258l34.699 26.31c5.205 3.947 12.621 3.008 16.665-2.122 17.864-22.658 30.113-35.797 57.303-35.797 20.429 0 45.698 13.148 45.698 32.958 0 14.976-12.363 22.667-32.534 33.976C247.128 238.528 216 254.941 216 296v4c0 6.627 5.373 12 12 12h56c6.627 0 12-5.373 12-12v-1.333c0-28.462 83.186-29.647 83.186-106.667 0-58.002-60.165-102-116.531-102zM256 338c-25.365 0-46 20.635-46 46 0 25.364 20.635 46 46 46s46-20.636 46-46c0-25.365-20.635-46-46-46z"></path></svg></span> https://github.com/idom-team/idom/discussions</a></li>
</ul>
<p><a href="https://github.com/idom-team/idom"><img alt="idom logo" src="https://github.com/idom-team/idom/raw/929d07ff4a643320a6148336613621242284f8d2/docs/source/branding/idom-logo.png"></a></p>
<p>IDOM takes inspiration from <a href="https://reactjs.org/" target="_blank">React</a>, and wherever
possible, attempts to achieve parity with the features it copies more directly. Nowhere
is this more evident than the version of React's often lauded
<a href="https://reactjs.org/docs/hooks-intro.html" target="_blank">"Hooks"</a> that IDOM
implements in Python.</p>
<p>At a glance, the similarities between IDOM and React are rather striking. Below is a
React component which defines a simple <code>Counter</code> displaying the number of times a button
has been clicked:</p>
<div><pre><span></span><code><span>import</span> <span>React</span><span>,</span> <span>{</span> <span>useState</span> <span>}</span> <span>from</span> <span>"react"</span><span>;</span>
<span>import</span> <span>ReactDOM</span> <span>from</span> <span>"react-dom"</span><span>;</span>

<span>function</span> <span>Counter</span><span>()</span> <span>{</span>
  <span>const</span> <span>[</span><span>count</span><span>,</span> <span>setCount</span><span>]</span> <span>=</span> <span>useState</span><span>(</span><span>0</span><span>);</span>
  <span>return</span> <span>(</span>
    <span>&lt;</span><span>div</span><span>&gt;</span>
      <span>&lt;</span><span>button</span> <span>onClick</span><span>=</span><span>{()</span> <span>=&gt;</span> <span>setCount</span><span>(</span><span>count</span> <span>+</span> <span>1</span><span>)}&gt;</span><span>Click</span> <span>me</span><span>!</span><span>&lt;/</span><span>button</span><span>&gt;</span>
      <span>&lt;</span><span>p</span><span>&gt;{</span><span>`Click count: </span><span>${</span><span>count</span><span>}</span><span>`</span><span>}&lt;/</span><span>p</span><span>&gt;</span>
    <span>&lt;/</span><span>div</span><span>&gt;</span>
  <span>);</span>
<span>}</span>

<span>ReactDOM</span><span>.</span><span>render</span><span>(&lt;</span><span>Counter</span> <span>/&gt;,</span> <span>document</span><span>.</span><span>getElementById</span><span>(</span><span>"root"</span><span>));</span>
</code></pre></div>

<p>And this is the same component implemented in Python using IDOM:</p>
<div><pre><span></span><code><span>import</span> <span>idom</span>

<span>@idom</span><span>.</span><span>component</span>
<span>def</span> <span>Counter</span><span>():</span>
    <span>count</span><span>,</span> <span>set_count</span> <span>=</span> <span>idom</span><span>.</span><span>hooks</span><span>.</span><span>use_state</span><span>(</span><span>0</span><span>)</span>
    <span>return</span> <span>idom</span><span>.</span><span>html</span><span>.</span><span>div</span><span>(</span>
        <span>idom</span><span>.</span><span>html</span><span>.</span><span>button</span><span>(</span>
            <span>{</span><span>"onClick"</span><span>:</span> <span>lambda</span> <span>event</span><span>:</span> <span>set_count</span><span>(</span><span>count</span> <span>+</span> <span>1</span><span>)},</span>
            <span>"Click me!"</span>
        <span>),</span>
        <span>idom</span><span>.</span><span>html</span><span>.</span><span>p</span><span>(</span><span>f</span><span>"Click count: </span><span>{</span><span>count</span><span>}</span><span>"</span><span>)</span>
    <span>)</span>

<span>idom</span><span>.</span><span>run</span><span>(</span><span>Counter</span><span>)</span>
</code></pre></div>

<p>Which, when displayed in your browser, should look something like this:</p>
<p><img alt="click-counter-example" src="https://rmorshea.github.io/articles/2021/idom-react-but-its-python/click-counter.gif"></p>
<h2 id="why-do-we-need-idom">Why Do We Need IDOM?</h2>
<p>Over the <a href="https://www.npmtrends.com/react-vs-angular-vs-vue" target="_blank">past 5
years</a> front-end
developers seem to have concluded that programs written with a
<a href="https://www.youtube.com/watch?v=yGh0bjzj4IQ" target="_blank">declarative</a> style or
framework tend to be easier to understand and maintain than those done imperatively. Put
more simply, mutable state in programs can quickly lead to unsustainable complexity.
This trend is largely evidenced by the
<a href="https://gist.github.com/tkrotoff/b1caa4c3a185629299ec234d2314e190" target="_blank">rise</a>
of Javascript frameworks like <a href="https://vuejs.org/" target="_blank">Vue</a> and
<a href="https://reactjs.org/" target="_blank">React</a> which describe the logic of computations
without explicitly stating their control flow.</p>
<p><img alt="npm download trends" src="https://rmorshea.github.io/articles/2021/idom-react-but-its-python/npm-download-trends.png"></p>
<p>So what does this have to do with Python and IDOM? Well, because browsers are the de
facto "operating system of the internet", even back-end languages like Python have had
to figure out clever ways to integrate with them. While standard
<a href="https://en.wikipedia.org/wiki/Representational_state_transfer">REST</a> APIs are well
suited to applications built using HTML templates, modern browser users expect a higher
degree of interactivity than this alone can achieve.</p>
<p>A variety of Python packages have since been created to help solve this problem:</p>
<ul>
<li><a href="https://github.com/jupyter-widgets/ipywidgets" target="_blank">IPyWidgets</a> - Adds
  interactive widgets to <a href="https://jupyter.org/" target="_blank">Jupyter Notebooks</a></li>
<li><a href="https://plotly.com/dash/" target="_blank">Dash</a> - Allows data scientists to produces
  enterprise-ready analytic apps</li>
<li><a href="https://www.streamlit.io/" target="_blank">Streamlit</a> - Turns simple Python scripts
  into interactive dashboards</li>
<li><a href="https://docs.bokeh.org/" target="_blank">Bokeh</a> - An interactive visualization
  library for modern web browsers</li>
</ul>
<p>However they each have drawbacks that can make them difficult to use.</p>
<ol>
<li>
<p><strong>Restrictive ecosystems</strong> - UI components developed for one framework cannot be
   easily ported to any of the others because their APIs are either too complex,
   undocumented, or are structurally inaccesible.</p>
</li>
<li>
<p><strong>Imperative paradigm</strong> - IPyWidgets and Bokeh have not embraced the same declarative
   design principles pioneered by front-end developers. Streamlit and Dash on the
   otherhand, are declarative, but fall short of the features provided by React or Vue.</p>
</li>
<li>
<p><strong>Limited layouts</strong> - At their initial inception, the developers of these libraries
   were driven by the visualization needs of data scientists so the ability to create
   complex UI layouts may not have been a primary engineering goal.</p>
</li>
</ol>
<p>A future article will address specific comparisons to each of the projects mentioned
above, but for now, we'll just focus on IDOM and its solutions to these problems.</p>
<h2 id="ecosystem-independence">Ecosystem Independence</h2>
<p>IDOM has a flexible set of core abstractions that allow it to interface with its peers.
At the time of writing, both Jupyter and Dash are supported, while Streamlit and Bokeh
are in the works:</p>
<ul>
<li><a href="https://github.com/idom-team/idom-jupyter" target="_blank">idom-jupyter</a> (try it now
  with
  <a href="https://mybinder.org/v2/gh/idom-team/idom-jupyter/main?filepath=notebooks%2Fintroduction.ipynb" target="_blank">Binder</a>)</li>
<li><a href="https://github.com/idom-team/idom-dash" target="_blank">idom-dash</a></li>
</ul>
<p>By providing well defined interfaces and straighforward protocols, IDOM makes it easy to
swap out any part of the stack with an alternate implementation if you want to. For
example, if you need a different web server for your application, IDOM already has 3
options to choose from or, use as blueprints to create your own:</p>
<ul>
<li><a href="https://github.com/sanic-org/sanic" target="_blank">Sanic</a></li>
<li><a href="https://github.com/pallets/flask" target="_blank">Flask</a></li>
<li><a href="https://github.com/tornadoweb/tornado" target="_blank">Tornado</a></li>
</ul>
<p>You can even target your usage of IDOM in your production-grade applications with IDOM's
Javascript <a href="https://github.com/idom-team/idom-client-react" target="_blank">React client library</a>. Just install
it in your front-end app and connect to a back-end websocket that's serving up IDOM
models. IDOM's own
<a href="https://idom-docs.herokuapp.com/docs/index.html" target="_blank">documentation</a> acts as
a prime example for this targeted usage - most of the page is static HTML, but embedded
in it are interactive examples that feature live views being served from a web socket:</p>
<p><img alt="live-examples-in-docs" src="https://rmorshea.github.io/articles/2021/idom-react-but-its-python/live-examples-in-docs.gif"></p>
<h2 id="declarative-components">Declarative Components</h2>
<p>IDOM, by adopting the hook design pattern from React, inherits many of its aesthetic and
functional characteristics. For those unfamiliar with hooks, user interfaces are
composed of basic <a href="https://en.wikipedia.org/wiki/HTML_element" target="_blank">HTML elements</a> that are
constructed and returned by special functions called "components". Then, through the
magic of hooks, those component functions can be made to have state. Consider the
component below which displays a basic representation of an
<a href="https://en.wikipedia.org/wiki/AND_gate" target="_blank">AND-gate</a>:</p>
<div><pre><span></span><code><span>import</span> <span>idom</span>

<span>@idom</span><span>.</span><span>component</span>
<span>def</span> <span>AndGate</span><span>():</span>
    <span>input_1</span><span>,</span> <span>toggle_1</span> <span>=</span> <span>use_toggle</span><span>()</span>
    <span>input_2</span><span>,</span> <span>toggle_2</span> <span>=</span> <span>use_toggle</span><span>()</span>
    <span>return</span> <span>idom</span><span>.</span><span>html</span><span>.</span><span>div</span><span>(</span>
        <span>idom</span><span>.</span><span>html</span><span>.</span><span>input</span><span>(</span>
            <span>{</span><span>"type"</span><span>:</span> <span>"checkbox"</span><span>,</span> <span>"onClick"</span><span>:</span> <span>lambda</span> <span>event</span><span>:</span> <span>toggle_1</span><span>()}</span>
        <span>),</span>
        <span>idom</span><span>.</span><span>html</span><span>.</span><span>input</span><span>(</span>
            <span>{</span><span>"type"</span><span>:</span> <span>"checkbox"</span><span>,</span> <span>"onClick"</span><span>:</span> <span>lambda</span> <span>event</span><span>:</span> <span>toggle_2</span><span>()}</span>
        <span>),</span>
        <span>idom</span><span>.</span><span>html</span><span>.</span><span>pre</span><span>(</span><span>f</span><span>"</span><span>{</span><span>input_1</span><span>}</span><span> AND </span><span>{</span><span>input_2</span><span>}</span><span> = </span><span>{</span><span>input_1</span> <span>and</span> <span>input_2</span><span>}</span><span>"</span><span>),</span>
    <span>)</span>

<span>def</span> <span>use_toggle</span><span>():</span>
    <span>state</span><span>,</span> <span>set_state</span> <span>=</span> <span>idom</span><span>.</span><span>hooks</span><span>.</span><span>use_state</span><span>(</span><span>False</span><span>)</span>

    <span>def</span> <span>toggle_state</span><span>():</span>
        <span>set_state</span><span>(</span><span>lambda</span> <span>old_state</span><span>:</span> <span>not</span> <span>old_state</span><span>)</span>

    <span>return</span> <span>state</span><span>,</span> <span>toggle_state</span>

<span>idom</span><span>.</span><span>run</span><span>(</span><span>AndGate</span><span>)</span>
</code></pre></div>

<p><img alt="and-gate-demo" src="https://rmorshea.github.io/articles/2021/idom-react-but-its-python/and-gate.gif"></p>
<p>Here's a very high level summary of how it works... the first time a view of the
component above is rendered, the <code>AndGate</code> function is called where its initial <code>state</code>
for <code>input_1</code> and <code>input_2</code> is <code>False</code>. The function then returns a series of HTML
elements with callbacks that respond to client-side events. Machinery behind the scenes
subsequently realizes that declaration and displays two checkbox buttons with the text
<code>False AND False = False</code>. Later, when a user clicks the now visible checkbox buttons,
client-side events are triggered, the associated callbacks respond by inverting the old
<code>state</code> from <code>False</code> to <code>True</code>, and a re-render of the component is scheduled. When
re-rendering, the function is again called, this time though, where <code>input_1</code> and
<code>input_2</code> have been updated to reflect the new <code>state</code>, thus causing the displayed text
to change.</p>
<p>In the code above, consider the fact that it never explicitely describes how to evolve
the frontend view when events occur. Instead, it declares that, given a particular
state, this is how the view should look. It's then IDOM's responsibility to figure out
how to bring that declaration into being. This behavior of defining outcomes without
stating the means by which to achieve them is what makes components in IDOM and React
"declarative". For comparison, a hypothetical, and a more imperative approach to
defining the same interface might look similar to the following:</p>
<div><pre><span></span><code><span>layout</span> <span>=</span> <span>Layout</span><span>()</span>

<span>def</span> <span>make_and_gate</span><span>():</span>
    <span>state</span> <span>=</span> <span>{</span><span>"input_1"</span><span>:</span> <span>False</span><span>,</span> <span>"input_2"</span><span>:</span> <span>False</span><span>}</span>
    <span>output_text</span> <span>=</span> <span>html</span><span>.</span><span>pre</span><span>()</span>
    <span>update_output_text</span><span>(</span><span>output_text</span><span>,</span> <span>state</span><span>)</span>

    <span>def</span> <span>toggle_input</span><span>(</span><span>index</span><span>):</span>
      <span>state</span><span>[</span><span>f</span><span>"input_</span><span>{</span><span>index</span><span>}</span><span>"</span><span>]</span> <span>=</span> <span>not</span> <span>state</span><span>[</span><span>f</span><span>"input_</span><span>{</span><span>index</span><span>}</span><span>"</span><span>]</span>
      <span>update_output_text</span><span>(</span><span>output_text</span><span>,</span> <span>state</span><span>)</span>

    <span>return</span> <span>html</span><span>.</span><span>div</span><span>(</span>
        <span>html</span><span>.</span><span>input</span><span>(</span>
            <span>{</span><span>"type"</span><span>:</span> <span>"checkbox"</span><span>,</span> <span>"onClick"</span><span>:</span> <span>lambda</span> <span>event</span><span>:</span> <span>toggle_input</span><span>(</span><span>1</span><span>)}</span>
        <span>),</span>
        <span>html</span><span>.</span><span>input</span><span>(</span>
            <span>{</span><span>"type"</span><span>:</span> <span>"checkbox"</span><span>,</span> <span>"onClick"</span><span>:</span> <span>lambda</span> <span>event</span><span>:</span> <span>toggle_input</span><span>(</span><span>2</span><span>)}</span>
        <span>),</span>
        <span>output_text</span>
    <span>)</span>

<span>def</span> <span>update_output_text</span><span>(</span><span>text</span><span>,</span> <span>state</span><span>):</span>
    <span>text</span><span>.</span><span>update</span><span>(</span>
        <span>children</span><span>=</span><span>"</span><span>{input_1}</span><span> AND </span><span>{input_2}</span><span> = </span><span>{output}</span><span>"</span><span>.</span><span>format</span><span>(</span>
            <span>input_1</span><span>=</span><span>state</span><span>[</span><span>"input_1"</span><span>],</span>
            <span>input_2</span><span>=</span><span>state</span><span>[</span><span>"input_2"</span><span>],</span>
            <span>output</span><span>=</span><span>state</span><span>[</span><span>"input_1"</span><span>]</span> <span>and</span> <span>state</span><span>[</span><span>"input_2"</span><span>],</span>
        <span>)</span>
    <span>)</span>

<span>layout</span><span>.</span><span>add_element</span><span>(</span><span>make_and_gate</span><span>())</span>
<span>layout</span><span>.</span><span>run</span><span>()</span>
</code></pre></div>

<p>In this imperative incarnation there are several disadvantages:</p>
<ol>
<li>
<p><strong>Refactoring is difficult</strong> - Functions are much more specialized to their
   particular usages in <code>make_and_gate</code> and thus cannot be easily generalized. By
   comparison, <code>use_toggle</code> from the declarative implementation could be applicable to
   any scenario where boolean indicators are toggled on and off.</p>
</li>
<li>
<p><strong>No clear static relations</strong> - There is no one section of code through which to
   discern the basic structure and behaviors of the view. This issue is exemplified by
   the fact that we must call <code>update_output_text</code> from two different locations. Once in
   the body of <code>make_and_gate</code> and again in the body of the callback <code>toggle_input</code>.
   This means that, to understand what the <code>output_text</code> might contain, we must also
   understand all the business logic that surrounds it.</p>
</li>
<li>
<p><strong>Referential links cause complexity</strong> - To evolve the view, various callbacks must
   hold references to all the elements that they will update. At the outset this makes
   writing programs difficult since elements must be passed up and down the call stack
   wherever they are needed. Considered further though, it also means that a function
   layers down in the call stack can accidentally or intentionally impact the behavior
   of ostensibly unrelated parts of the program.</p>
</li>
</ol>
<h2 id="virtual-document-object-model">Virtual Document Object Model</h2>
<p>To communicate between their back-end Python servers and Javascript clients, IDOM's
peers take an approach that aligns fairly closely with the
<a href="https://en.wikipedia.org/wiki/Model%E2%80%93view%E2%80%93controller" target="_blank">Model-View-Controller</a>
design pattern - the controller lives server-side (though not always), the model is
what's synchronized between the server and client, and the view is run client-side in</p></article></div></div></main></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://rmorshea.github.io/articles/2021/idom-react-but-its-python/article/">https://rmorshea.github.io/articles/2021/idom-react-but-its-python/article/</a></em></p>]]>
            </description>
            <link>https://rmorshea.github.io/articles/2021/idom-react-but-its-python/article/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26199008</guid>
            <pubDate>Fri, 19 Feb 2021 22:43:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Koo, India’s free-speech Twitter alternative]]>
            </title>
            <description>
<![CDATA[
Score 97 | Comments 168 (<a href="https://news.ycombinator.com/item?id=26196588">thread link</a>) | @donohoe
<br/>
February 19, 2021 | https://restofworld.org/2021/how-koo-became-a-right-wing-darling-in-india/ | <a href="https://web.archive.org/web/*/https://restofworld.org/2021/how-koo-became-a-right-wing-darling-in-india/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

			<!-- Article Start -->
			
<p>It hasn’t been a quiet few weeks on Twitter in India. The country’s capital city has seen over four months of protest after Prime Minister Narendra Modi’s government enacted agricultural laws that would adversely affect farmers across India. <a href="https://www.bbc.com/news/world-asia-india-55899754">The farmer protests</a>, as the movement has come to be known, has taken to social media platforms like Twitter and Facebook to make the cause heard globally — and it’s worked. Earlier this month, celebrities like <a href="https://www.dw.com/en/greta-thunberg-under-fire-for-tweeting-about-indian-farmers-toolkit/a-56458306">Greta Thunberg</a> and <a href="https://www.bbc.com/news/world-asia-india-55931894">Rihanna</a> weighed in with their tweets of support. Backlash <a href="https://www.bbc.com/news/world-asia-india-55931894">soon followed</a>.&nbsp;</p>



<p>But the government’s ire against global critics of Modi’s Hindu nationalist party has turned to Twitter itself. Citing threats to public order, on February 1, Indian authorities <a href="https://www.buzzfeednews.com/article/pranavdixit/indian-government-block-critics">appeared to have requested Twitter to suspend or remove</a> dozens of accounts on its platform. Twitter briefly complied but, after public outcry, reinstated the accounts and then <a href="https://www.cjr.org/the_media_today/twitter-stands-up-to-india-and-refuses-to-block-journalists.php">refused to remove</a> hundreds more.</p>



<p>It’s in the middle of this battle that Aprameya Radhakrishna’s 10-month-old social media platform was thrust into the spotlight. Soft-spoken and studious, Radhakrishna is a serial entrepreneur: in 2015, <a href="https://economictimes.indiatimes.com/magazines/panache/taxiforsure-founder-aprameya-radhakrishnas-life-after-sell-off/articleshow/48078627.cms">he sold his first company</a>, a ride-sharing app called TaxiForSure, to local giant Ola for $200 million. His latest venture is an app called Koo, <a href="https://www.kooapp.com/">a microblogging platform similar to Twitter</a> but for local-language speakers in India, a country with more than 20 languages and over 700 dialects.&nbsp;</p>



<p>After weeks of battling with Twitter, some of India’s most prominent Hindu nationalist politicians took to their social accounts and instructed their followers to leave Western social networks for Koo, a local, free-speech platform. “I am now on Koo,” <a href="https://twitter.com/PiyushGoyal/status/1359058583934013442">tweeted</a> India’s minister of commerce and industry, Piyush Goyal. “Connect with me on this Indian micro-blogging platform for real-time, exciting and exclusive updates.” Many of his <a href="https://twitter.com/PiyushGoyal">9.6 million followers</a> obliged. More right-wing politicians <a href="https://twitter.com/rsprasad/status/1360067772571545606?s=20">followed suit</a>, as did some of <a href="https://twitter.com/KanganaTeam/status/1361421114220576768">Bollywood</a>’s biggest stars.&nbsp;</p>



<p>Overnight, the platform went from a relatively obscure app to <a href="https://timesofindia.indiatimes.com/business/india-business/koo-lines-up-indian-investors-as-popularity-surges/articleshow/80867206.cms">headline news</a> and bagged <a href="https://economictimes.indiatimes.com/tech/funding/microblogging-platform-koo-bags-4-1-million-in-funding/articleshow/80685024.cms">$4.1 million in series A funding</a>.&nbsp;</p>



<p>Radhakrishna and his platform are in a curious position. The founder insists he’s apolitical — he’s appeared in both <a href="https://www.ndtv.com/video/news/news/koo-app-everything-you-need-to-know-about-koo-the-indian-alternative-to-twitter-575160">left-leaning</a> and <a href="https://www.opindia.com/2021/02/rahul-roushan-aprameya-radhakrishna-koo-co-founder-twitter-alternative-made-in-india-interview/">right-wing</a> outlets in the days since Koo has found the limelight — but is happily embracing the sudden rush to his app: Koo crossed <a href="https://www.livemint.com/technology/apps/koo-sees-10-fold-increase-in-downloads-this-week-crosses-3-million-users-11613038170243.html">3 million users </a>this month, fueled in large part by Modi’s party.&nbsp;</p>



<p>And while it’s unclear whether Koo will follow in the path of other social platforms <a href="https://www.usatoday.com/story/tech/2020/11/11/parler-mewe-gab-social-media-trump-election-facebook-twitter/6232351002/">that espouse “free speech” ideology</a>, it’s likely more Indian apps like Radhakrishna’s will follow. Prominent among Modi’s mantras for his vision of India is <em>Atmanirbhar Bharat: </em>a self-sufficient India. That vision <a href="https://restofworld.org/2021/indias-hashtag-war/">extends to the internet and social media</a>.&nbsp;</p>



<p>Six months before prominent right-wing politicians began heralding his app as India’s Twitter, Radhakrishna and his team submitted Koo to a government <em>atmanirbhar </em>social media challenge, <a href="https://navbharattimes.indiatimes.com/business/business-news/koo-app-wins-pm-modi-aatm-nirbhar-app-innovation-challenge/articleshow/77432196.cms">and won</a>.</p>



<p>Radhakrishna spoke to <em>Rest Of World </em>over Google Meet from Bangalore. This conversation has been edited for length and clarity.</p>



<hr>



<h4><strong>Tell me a bit about how you came up with the idea for Koo.&nbsp;</strong></h4>



<p>We started building it in November 2019 and launched it in March 2020. The idea behind it was that Twitter is existing in English in India, but the language speakers of India are not on Twitter. Let’s build a deeper experience for the language speakers. And because we built a deeper experience for the language speakers, we were able to make a very localized community.&nbsp;</p>



<p>We started with Kannada, then we did Hindi, then Telugu, Marathi, then Tamil: we launched all of these languages. Then, we started noticing Twitter was getting into trouble in the U.S. We said, Maybe we should just have English as well as the local languages, if ever Twitter gets into trouble or users want a separate option.&nbsp;</p>


		<figure>
			<div>
				<p><img src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/02/IMG-20210218-WA0009-1-40x71.jpg" data-src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/02/IMG-20210218-WA0009-1-600x1066.jpg" data-srcset="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/02/IMG-20210218-WA0009-1-400x711.jpg 400w, https://restofworld.org/wp-content/uploads/2021/02/IMG-20210218-WA0009-1-600x1067.jpg 600w, " sizes="(max-width: 640px) 100vw, 300px" alt="Aprameya Radhakrishna, a serial entrepreneur sold his first company, a ride-sharing app called TaxiForSure, for $200 million.">
					
				</p>
			</div>
						<figcaption itemprop="caption description">
				
				<span itemprop="copyrightHolder">Aprameya Radhakrishna</span>
			</figcaption>
		</figure>


<h4><strong>When you started Koo, how soon were you approached by government officials who saw the </strong><a href="http://www.makeinindia.com/about"><strong>“Make in India”</strong></a><strong> potential for the app?&nbsp;</strong></h4>



<p>We were a two-month-old app when we applied to the <a href="https://innovate.mygov.in/app-challenge/">[<em>Atmanibhar Bharat</em>]</a> challenge. We got into that challenge at the last minute, almost. Nobody approached us or anything. We applied just like any other startup — there were something like 7,000 social media startups that applied. We won that challenge, so that put us into the limelight: Oh, there’s an alternative microblogging platform that promotes local language<em>.&nbsp;</em></p>



<h4><strong>Walk me through how the last two or three weeks have been for you. Did you know that Piyush Goyal and the Ministry of Electronics and Technology would be encouraging their followers on Twitter to move to Koo en masse?&nbsp;</strong></h4>



<p>No. It’s been totally surreal for us. It’s totally welcome at Koo. We as a company are benefiting from the love that users who are shifting [from Twitter] are showing us. We weren’t expecting it, but it’s a pleasant surprise. We’re happy this move is happening.&nbsp;</p>



<h4><strong>Were you prepared for the sudden influx of users on the back end?&nbsp;</strong></h4>



<p>Not at all. Scaling 10x suddenly, in a week, is a challenge for any company, especially a 10-month-old startup. But we’ve come through it; we are able to scale faster.&nbsp;</p>



<h4><strong>What were the user numbers like? Can you tell me how quickly they grew after the events of this month?&nbsp;</strong></h4>



<p>We were very small, we were sub-100,000 DAU [daily active users]. Now we’re close to a million DAU. Close, not a million yet but close.&nbsp;</p>



<h4><strong>By virtue of chance, or deliberate action, there’s an ideological framework under which Koo has been positioned. You don’t seem bothered by the fact that Koo is heralded </strong><a href="https://www.bbc.com/news/world-asia-india-56037901"><strong>as the right-wing’s answer to Twitter</strong></a><strong>. Politics has played a role in the sudden attention that Koo has received. Have you considered the risks of embracing the way your app has been politicized?&nbsp;</strong></h4>



<p>It depends on the actions on the app. That first community [we built] in Kannada was built in a slower manner, and it has people from all parties in Karnataka.&nbsp;</p>



<p>What we are seeing is that India wants to be more self-reliant. India includes everybody. Our app doesn’t understand “left” or “right.” <em>I </em>don’t understand “left” or “right.” I’m an entrepreneur; I’m extremely apolitical. And I’m all for the development of the country. If Koo as a statement can make us self-reliant on our own social networks and technology, then we should be cheering for it. We shouldn’t unnecessarily politicize it.</p>



<h4><strong>Social media is shaped by its users and early adopters. Most of Koo’s early video content partnerships with, say, Republic TV [a channel </strong><a href="https://www.theguardian.com/media/2020/dec/23/indian-news-channel-fined-in-uk-for-hate-speech-about-pakistan"><strong>notorious for its allegiance</strong></a><strong> with the ruling Hindu nationalist party] or Mitron [a short-form video app that Modi supporters </strong><a href="https://www.techradar.com/news/mitron-app-gives-tiktok-a-challenge-will-it-sustain-though"><strong>have embraced after the ban on TikTok</strong></a><strong>] have come to associate the app with a particular ideology. Are you worried Koo might get too polarized too quickly?&nbsp;</strong></h4>



<p>Not at all. In Karnataka, we have everybody [on Koo], as I said. As a business, we keep looking for partners to grow our business. Now, the partners who come aggressively and see the vision that we’re seeing as a free-expression platform and embrace the platform, we’re happy to welcome them. Why would I say no to somebody who wants to use our platform? Republic [TV] came first, that doesn’t mean I don’t want everybody else.&nbsp;</p>


    <figure>
      <div>
				<ul>
					<li>		<figure>
			<div>
				<p><img src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/02/KooPhone1-40x67.png" data-src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/02/KooPhone1-600x1066.png" data-srcset="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/02/KooPhone1-400x667.png 400w, https://restofworld.org/wp-content/uploads/2021/02/KooPhone1-600x1000.png 600w, " sizes="(max-width: 640px) calc(100vw + 40px), 50vw" alt="">
					
				</p>
			</div>
						<figcaption itemprop="caption description">
				
				
			</figcaption>
		</figure></li><li>		<figure>
			<div>
				<p><img src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/02/KooPhone3-40x67.png" data-src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/02/KooPhone3-600x1066.png" data-srcset="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/02/KooPhone3-400x667.png 400w, https://restofworld.org/wp-content/uploads/2021/02/KooPhone3-600x1000.png 600w, " sizes="(max-width: 640px) calc(100vw + 40px), 50vw" alt="">
					
				</p>
			</div>
						<figcaption itemprop="caption description">
				
				
			</figcaption>
		</figure></li><li>		<figure>
			<div>
				<p><img src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/02/KooPhone4-40x67.png" data-src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/02/KooPhone4-600x1066.png" data-srcset="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/02/KooPhone4-400x667.png 400w, https://restofworld.org/wp-content/uploads/2021/02/KooPhone4-600x1000.png 600w, " sizes="(max-width: 640px) calc(100vw + 40px), 50vw" alt="">
					
				</p>
			</div>
						<figcaption itemprop="caption description">
				
				
			</figcaption>
		</figure></li><li>		<figure>
			<div>
				<p><img src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/02/KooPhone2-40x67.png" data-src="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/02/KooPhone2-600x1066.png" data-srcset="https://149346090.v2.pressablecdn.com/wp-content/uploads/2021/02/KooPhone2-400x667.png 400w, https://restofworld.org/wp-content/uploads/2021/02/KooPhone2-600x1000.png 600w, " sizes="(max-width: 640px) calc(100vw + 40px), 50vw" alt="">
					
				</p>
			</div>
						<figcaption itemprop="caption description">
				
				
			</figcaption>
		</figure></li>
				</ul>
			</div>
      <figcaption>On Koo’s Hindi language setting, it’s easy to find the accounts of several of India’s biggest Hindu nationalist politicians next to celebrities and right-leaning media channels. The majority of the app’s top trending hashtags in Hindi are pro-Modi.</figcaption>
    </figure>


<h4><strong>In a recent BBC report about your app, there’s a rhetorical question, </strong><a href="https://www.bbc.com/news/world-asia-india-56037901"><strong>“Is Koo India’s Parler?”</strong></a><strong> What do you make of that comparison?&nbsp;</strong></h4>



<p>Each platform comes into being for different reasons. I’ve already explained my story. We were doing this irrespective of whether Twitter existed, got banned, got into trouble, or flourished in India.&nbsp;</p>



<p>We started in November 2019 because we said the voice of the Indian user who doesn’t speak English is not there. We are building an inclusive social media network for India. So what was your question?&nbsp;</p>



<h4><strong>My question was what do you make of Parler and—</strong></h4>



<p>Parler came into existence because there was an anti-Trump thing, and they wanted to do a pro-Trump thing. We don’t exist because of some anti or pro thing. We are existing today irrespective of whether Twitter gets into trouble or not, irrespective of one ideology being there or not. We exist because we want to give a voice to every Indian. The purpose of our existence is very different from what a Parler is.&nbsp;</p>



<h4><strong>What do you make of the “Make in India” push, considering Facebook and Twitter have </strong><a href="https://www.nytimes.com/2021/01/14/technology/trump-facebook-twitter.html"><strong>an undeniable influence</strong></a><strong> in our current political discourse?</strong></h4>



<p>Every social media [platform] has to be responsible, to a certain extent, of what they bring into a country because it defines a lot of things in the country, like youth culture or how citizens of a country react to a situation.&nbsp;</p>



<p>When a company is registered elsewhere and doesn’t take into consideration the nuances of the local culture, I think it can be dangerous. Indian entrepreneurs building for Indian cultural nuances is better than somebody who doesn’t understand the cultural nuances trying to build for India.</p>



<figure><blockquote><p>“Indian entrepreneurs building for Indian cultural nuances is better than somebody who doesn’t understand the cultural nuances trying to build for India.”</p></blockquote></figure>



<h4><strong>The way Indian internet is shaping, </strong><a href="https://restofworld.org/2021/indias-hashtag-war/"><strong>an extreme version of “Indian apps for India”</strong></a><strong> is an entire separate internet for India, the way China has Weibo and its own social network. Do you think that kind of internet would be a good thing for India as a whole?&nbsp;</strong></h4>



<p>Absolutely, we should have our own <em>atmanirbhar</em> platforms. We …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://restofworld.org/2021/how-koo-became-a-right-wing-darling-in-india/">https://restofworld.org/2021/how-koo-became-a-right-wing-darling-in-india/</a></em></p>]]>
            </description>
            <link>https://restofworld.org/2021/how-koo-became-a-right-wing-darling-in-india/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26196588</guid>
            <pubDate>Fri, 19 Feb 2021 18:58:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Cleaner parallel curves with Euler spirals]]>
            </title>
            <description>
<![CDATA[
Score 124 | Comments 12 (<a href="https://news.ycombinator.com/item?id=26196470">thread link</a>) | @raphlinus
<br/>
February 19, 2021 | https://raphlinus.github.io/curves/2021/02/19/parallel-curves.html | <a href="https://web.archive.org/web/*/https://raphlinus.github.io/curves/2021/02/19/parallel-curves.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <!-- I should figure out a cleaner way to do this include, rather than cutting and pasting. Ah well.-->




<p><img src="https://raphlinus.github.io/assets/euler-parallel-flower.svg" alt="Many parallel curve of an Euler spiral, resembling a flower"></p>

<p>Determining <a href="https://en.wikipedia.org/wiki/Parallel_curve">parallel curves</a> is one of the basic 2D geometry operations. It has obvious applications in graphics, being the basis of creating a stroke outline from a path, but also in computer aided manufacturing (determining the path of a milling tool with finite radius) and path planning for robotics. There are plenty of solutions in the literature by now, but in this post I propose a cleaner solution.</p>

<p>A good survey paper is <a href="https://www.semanticscholar.org/paper/Comparing-Offset-Curve-Approximation-Methods-Elber-Lee/9ac1978746ec54bdd555b906e2ea1eb922cd6ffd">Comparing Offset Curve Approximation Methods</a>. The main difference between these approaches is the choice of curve representation. An example of a curve representation highly specialized for deriving parallel curves is the <a href="https://www.semanticscholar.org/paper/Pythagorean-hodographs-Farouki-Sakkalis/e20aeb60de908061797b6eaf3af79fdc7e5acdd7">Pythagorean Hodograph</a>. This parallel curve of a Pythagorean Hodograph is an exact parametric polynomial curve, but approximation techniques are still needed in practice, both to convert the source curve into the representation, and because the resulting curves are higher order rational polynomials, which require further approximation to convert into, say, cubic Béziers.</p>

<p>Specifically, this blog proposes piecewise Euler spirals as a curve representation particularly well suited to the parallel curve problem.</p>

<p>There’s an implementation of many of these ideas (currently still in PR stage) in <a href="https://github.com/linebender/kurbo/pull/169">kurbo</a>. I also used a colab notebook to explore a bunch of the math, and I’ve made a <a href="https://github.com/raphlinus/raphlinus.github.io/blob/master/assets/Euler_spiral_scratchpad.ipynb">copy of that available</a> as well.</p>

<h2 id="the-cusp">The cusp</h2>

<p>One of the things that makes parallel curves special is that cusps often appear. In particular, a cusp appears whenever the radius of curvature of the source curve matches the offset. This is classified as an <a href="https://en.wikipedia.org/wiki/Cusp_(singularity)">ordinary cusp</a> and is a feature of many curve families – we’ll quantify that a bit more below.</p>

<p><img src="https://raphlinus.github.io/assets/euler-parallel-cusp.svg" alt="Parallel curve of an Euler spiral, showing the cusp"></p>

<p>A common feature of algorithms for computing parallel curves is identifying the location of the cusp, and subdividing there. That basically means solving for the specific value of curvature (the reciprocal of the offset distance). If the source curve is a cubic Bézier, there can be up to four such cusps, and finding them requires some nontrivial numerical solving.</p>

<h2 id="curvature-as-a-function-of-arclength">Curvature as a function of arclength</h2>

<p>A theme of my approach to parallel curves (and much of my curve work in general, including my <a href="https://www.levien.com/phd/phd.html">thesis</a>), is to consider the relationship of curvature to arclength. A concrete intuition is that it is the position of the steering wheel as a car drives along the curve at constant speed. For some curves, curvature can be represented as a closed-form analytical formula as a function of arclength (the <a href="https://en.wikipedia.org/wiki/Ces%C3%A0ro_equation">Cesàro equation</a>), but in general determining the relation requires numerical techniques. For example, in the <a href="https://levien.com/euler_explorer/">Euler explorer</a>, there’s a plot of curvature as a function of arclength below the interactive cubic Bézier. Experimenting with that is an excellent way to develop intuition.</p>

<p>One curve that <em>does</em> have an especially simple Cesàro equation is the Euler spiral. An Euler spiral segment has this formula:</p><p>

\[\kappa(s) = \kappa_0 + \kappa_1 s\]

</p><p>(A note for those trying to follow along with the detailed math and code: most of the math and numerical code uses $-0.5 \leq s \leq 0.5$ because it helps exploit even/odd symmetries, but the convention for parametrized curves, including the <a href="https://docs.rs/kurbo/0.8.0/kurbo/trait.ParamCurve.html">ParamCurve</a> trait in kurbo, is $0 \leq s \leq 1$. Thus, you’ll frequently see offsets of 0.5. Similarly, you’ll see various scaling to the actual arc length, while the parametrized curve convention assumes an arc length of 1. In this blog, we’ll skim over such details, as the goal is to provide intuition without too much clutter from details.)</p>

<h2 id="the-parallel-curve-of-an-euler-spiral">The parallel curve of an Euler spiral</h2>

<p>In general, most curves do not have a simple formula for their parallel curve. The obvious exception is a circular arc, for which the parallel curve is another circular arc. Another curve family with tractable representation for its parallel curve is Pythagorean Hodographs.</p>

<p>Thanks to its exceptionally simple formulation as a Cesàro equation, the Euler spiral is one of the rare curves with a simple closed-form equation for its parallel curve. That equation was first published in a 1906 paper by Heinrich Wieleitner, <a href="https://books.google.com/books?id=UvpZAAAAYAAJ&amp;pg=PA373&amp;lpg=PA373&amp;dq=%22Die+Parallelkurve+der+Klothoide%22&amp;source=bl&amp;ots=fuY39VdPpd&amp;sig=K0AbL03rXAm_g4J9KsheQbbxyaA&amp;hl=en&amp;sa=X&amp;ved=2ahUKEwiUrcD1poTfAhVvFjQIHVthBPoQ6AEwAnoECAMQAQ#v=onepage&amp;q=%22Die%20Parallelkurve%20der%20Klothoide%22&amp;f=false">Die Parallelkurve der Klothoide</a>. For those who don’t read German, <a href="https://github.com/Rahix">Rahix</a> has kindly provided a translation into English: <a href="https://raphlinus.github.io/assets/clothoids.pdf">PDF</a>, <a href="https://raphlinus.github.io/assets/clothoids.text">TeX source</a>.</p>

<p>Going over this math, I see Wieleitner missed an opportunity for further simplification. The style at the time was to write the Cesàro equation in terms of the <em>radius</em> of curvature (the reciprocal of curvature), but especially for the Euler spiral and its parallel curve, using curvature directly yields a much simpler equation. With the cusp located at $s_0$, the equation is gratifyingly simple:</p><p>

\[\kappa(s) = \frac{c}{\sqrt{s - s_0}} + \frac{1}{l}\]

</p><p>The equation is graphed below, and clicking on it links to a <a href="https://www.desmos.com/calculator/qznzk9xnac">Desmos calculator graph</a> with sliders for the parameters.</p>

<p><a href="https://www.desmos.com/calculator/qznzk9xnac"><img src="https://raphlinus.github.io/assets/euler-spiral-parallel-cesaro.png" width="400" height="400"></a></p>

<p>Here $c$ is a coefficient dependent on the parameters of the spiral. To connect it to the notation in the Wieleitner paper, $c = a / \sqrt{2 l^3}$, and $s_0 = -a^2/{2l}$. I’ve also made a <a href="https://www.desmos.com/calculator/imvqywsb8o">Desmos calculator graph</a> that interactively demonstrates the equivalence of this equation and the more involved one from the Wieleitner paper.</p>

<p>There are a number of other curves that have a cusp similar to the above, with characteristic inverse-square root curvature. The clearest connection is the <a href="https://en.wikipedia.org/wiki/Involute">circle involute</a>, which is the same but without the $1/l$ term, or in other words the Euler spiral parallel curve approaches the circle involute as the offset goes to infinity. This provides intuition for the fact that a circle involute is its own parallel curve. The circle involute is perhaps most famous as the optimized profile for meshing <a href="https://ciechanow.ski/gears/">gear</a> teeth, transferring force smoothly with no slop or friction.</p>

<p>Other curves with a similar cusp include the <a href="https://en.wikipedia.org/wiki/Cycloid">cycloid</a> (as well as its many variants including epicycloid, hypocycloid, astroid, deltoid, cardioid, and nephroid), as well as the <a href="https://en.wikipedia.org/wiki/Semicubical_parabola">semicubical parabola</a>. The latter is of particular interest because it can be exactly represented as a case of a cubic Bézier (it is when the control arms form a symmetrical X).</p>

<p><img src="https://raphlinus.github.io/assets/semicubical_parabola.svg" alt="semicubical parabola"></p>

<p>The parallel curve of the Euler spiral is perfectly cromulent, and, following the tradition of Pythagorean Hodograph curves and their higher-order rational polynomials, we could simply require everything downstream to simply deal with them. But to make that downstream processing easier, we will convert back to piecewise Euler spirals, a more tractable representation.</p>

<h2 id="geometric-hermite-interpolation">Geometric Hermite interpolation</h2>

<p><a href="https://en.wikipedia.org/wiki/Hermite_interpolation">Hermite interpolation</a> is a well known technique. In its simplest form, it is used to generate a piecewise polynomial approximation to some function, where the parameters for each polynomial segment are determined from the values and derivatives of the endpoints. For example, in cubic Hermite interpolation, a cubic polynomial is determined from the values and first derivatives at the endpoints – four values, corresponding to four coefficients for the polynomial. The result is C1 continuous as the derivatives exactly match (and are equal to the source curve).</p>

<p>In 2D, there is a distinction between C1 and G1 (geometric) continuity. In C1 continuity, the full derivatives must match, both direction and magnitude. For applications such as animating motion curves, the magnitude is important (it represents speed of motion), but for curves, it is not. G1 continuity requires that the tangents match, but does not specify the magnitude of the derivatives.</p>

<p>In these applications, geometric Hermite interpolation is more efficient, as all parameters of the curve are available to make the shape fit. The Euler spiral is especially well suited to geometric Hermite interpolation, and there is literature on this topic. For reasonable assumptions of smoothness (excluding fractal curves but including simple cusps), the accuracy scales as $O(n^4)$ – a doubling of the number of subdivisions reduces the error by a factor of 16. This scaling is the same as cubic Hermite interpolation of a 1D function, not surprising as an Euler spiral segment approximates a cubic polynomial when $y$ values are small.</p>

<p>Section 8.2 of my <a href="https://www.levien.com/phd/phd.html">thesis</a> provides a secant method for determining the Euler spiral parameters from the G1 Hermite constraints, and that’s implemented in the <code>fit_euler</code> method in the <a href="https://github.com/linebender/kurbo/pull/169">kurbo PR</a>. That’s a good technique and its convergence is excellent (quadratic, as typical for Newton-style solvers for near-linear problems), but I’ve also been experimenting with ways to do it better. The linked notebook explores a polynomial approximation (based on 2D Taylor’s series) that is much faster – 7ns vs 240ns in my measurements, and should be very accurate over a wide range of parameters. I’m not quite done making the error bounds rigorous, but this approach should help make the overall algorithm lightning-fast.</p>

<p>Geometric Hermite interpolation works well to approximate the parallel curve of an Euler spiral segment with another Euler spiral segment:</p>

<p><img src="https://raphlinus.github.io/assets/euler-parallel-approx.svg" alt="Approximation of the parallel curve of an Euler spiral segment"></p>

<p>The true parallel curve is in blue, and the approximation in red. It has the same rough shape, but bulges out in the middle. We need to be able to estimate that error in order to make a more accurate approximation.</p>

<h3 id="a-simple-accurate-error-metric">A simple, accurate error metric</h3>

<p>The most common approach to approximation given a target error bound is adaptive subdivision: approximate the error, and if it exceeds the target, subdivide. Evaluating the error is not always easy; most generally, it’s based on numerical techniques such as evaluating the curve at several points along its length and testing how near those points lie to the source curve.</p>

<p>Fortunately, for approximating an Euler spiral parallel curve using an Euler spiral, there is an extremely simple formula for the error. In fact, it’s possible to avoid the adaptive subdivision altogether, and precisely predict how many subdivisions are needed to meet an error bound, as well as analytically place the subdivisions so each segment has the same error.</p>

<p>Normalized to a chord length of 1, where the arc …</p></div></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://raphlinus.github.io/curves/2021/02/19/parallel-curves.html">https://raphlinus.github.io/curves/2021/02/19/parallel-curves.html</a></em></p>]]>
            </description>
            <link>https://raphlinus.github.io/curves/2021/02/19/parallel-curves.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26196470</guid>
            <pubDate>Fri, 19 Feb 2021 18:49:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Researchers looking for mRNA were ridiculed by colleagues]]>
            </title>
            <description>
<![CDATA[
Score 292 | Comments 99 (<a href="https://news.ycombinator.com/item?id=26196372">thread link</a>) | @fortran77
<br/>
February 19, 2021 | https://www.macleans.ca/society/science/scientists-mrna-covid-vaccines/ | <a href="https://web.archive.org/web/*/https://www.macleans.ca/society/science/scientists-mrna-covid-vaccines/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>Sixty years ago, the scientists who were pioneering the technology that would make today's COVID-19 vaccines possible were mocked and dismissed</p><div>
																		<p>A few days before Christmas, Matthew Meselson, a 90-year-old professor at Harvard, called his university’s health service to inquire about being vaccinated against COVID-19. He was eager for his shot. Meselson felt imprisoned in his Cambridge apartment, just blocks from the campus where he’d worked for six decades. He’d officially retired from teaching at the beginning of 2020, but continued his research as much as possible throughout the pandemic, wearing a K95 mask to work in his lab.</p>
<p>He longed to re-engage in the world around him. He missed his weekly date with close friends over lunch at Boston’s best French restaurant; they’d switched to Zoom, but staring into a computer screen is no replacement for lingering at linen-covered tables. He longed for his wife of 32 years, Jeanne Guillemin, who died from cancer late in 2019. Meselson was still figuring out how his world worked without her, and isolation made this hard task harder.</p>
<p>The person on the other end of the phone apologized to the professor. “We don’t have a vaccine schedule yet,” she told him.</p>
<p>The first two COVID-19 vaccines to be approved for use in North America were developed, tested and delivered into freezers before many jurisdictions figured out how to administer them. The vaccines from Pfizer-BioNTech and Moderna are the first approved vaccines ever to employ modified mRNA, which is delivered sealed in a lipid shell. The mRNA slips into our cells, carrying instructions to make antibodies that target SARS-CoV-2. The vaccines function almost like a wanted poster: if you see these guys, get ’em. Then, the mRNA degrades, leaving no trace.</p>
<blockquote><p><strong>READ:&nbsp;<a href="https://www.macleans.ca/news/covid-19-vaccines-curbing-pandemic-vaxx-populi/">How quickly will the COVID-19 vaccines start curbing the pandemic in Canada?</a></strong></p></blockquote>
<p>The fact that mRNA is the basis of these vaccines contributed to their rapid development. In November, the <em>New York Times</em> reported that within two days of China releasing the genetic sequence of SARS-CoV-2, scientists at Moderna Inc., a 10-year-old company headquartered not far from Meselson’s home in Cambridge, “plugged that data into its computers and came up with a design for an mRNA vaccine.” Meanwhile, BioNTech, a small biotech company in Germany that had been working on mRNA flu vaccines with the pharmaceutical powerhouse Pfizer, soon similarly turned its resources to generating an mRNA COVID vaccine.</p>
<p>But these fastest vaccines in history have been decades in the making. They’re the product of generations of scientists who built on one idea after another, and kept at it despite failed experiments, rejections, threats of deportation, a lack of funding and skepticism from contemporaries. They were inspired by the discovery of DNA: in 1951, a young English physical chemist named Rosalind Franklin took X-ray photographs that captured DNA’s helical shape; two years later, James Watson and Francis Crick of Cambridge University published the first report describing DNA’s double helix, for which they received the Nobel Prize. (Franklin died of ovarian cancer in 1958; her contributions were largely overlooked in her lifetime.) And they were driven not by a race to halt a raging pathogen or by the chance to patent a multi-billion-dollar drug, but by one big, irresistible question: What makes life?</p>
<p>“These weren’t people who wanted to solve little problems,” says Meselson. “These were people who wanted to solve a great big problem.”</p>
<p>He was one of them.</p>
<p>***</p>
<p>Born in Colorado in 1930, Meselson zipped through the sciences at a young age. By 16, he enrolled at the University of Chicago. In 1957, while doing post-doctoral work at the California Institute of Technology (Caltech), Meselson and Frank Stahl demonstrated how DNA replicates itself, a model that had been suggested but never shown. Science historian Frederic Lawrence Holmes later characterized their work as “the most beautiful experiment in biology,” having revealed how life worked.</p>
<p>But many unanswered questions remained about what happens inside our cells. Meselson and colleagues knew that DNA resides in the nucleus, a compartment barricaded off from the rest of the cell by a membrane. On the other side of the membrane is the cytoplasm, a gelatinous liquid that fills the remainder of the cell. This is the home of tiny granules called ribosomes, which house RNA.</p>
<p>Around the same time that Meselson and Stahl published their groundbreaking work on DNA, French scientists discovered that cells made proteins through the ribosomes. DNA, despite holding the critical codes for life, is a relatively passive molecule. Ribosomes do the busy labour, building proteins to carry out the biological processes of survival. The question was how?</p>
<p>One of the French scientists, Dr. François Jacob, theorized that there must be an “unstable intermediary” that went between the DNA and the RNA—sending messages from the DNA to the RNA, and then disappearing.</p>
<p>Jacob, a physician who’d been forced from medical school when Germany invaded France in 1940 and spent the war years fighting with Charles de Gaulle’s Free French Forces, called this theoretical intermediary “X.” Other researchers “rolled their eyes in horror” when he presented his theory, Jacob recalled in his memoir, <em>The Statue Within</em>. “With a little encouragement, my audience would have jeered and left,” he wrote.</p>
<div id="attachment_1216833"><p><img data-sizes="auto" src="https://www.macleans.ca/wp-content/uploads/2021/02/MATTHEW-MESELSON-DNA-FRANGOU-FEB02-766x431.jpg" alt="Meselson at Caltech in 1958 (Courtesy of the Caltech Archives)" width="766" height="431"></p><p>Meselson at Caltech in 1958 (Courtesy of the Caltech Archives)</p></div>
<p>In spring 1960, Jacob wrote to Meselson with a proposal: he and Sydney Brenner, a South African biologist at the University of Cambridge, would meet at Meselson’s lab at Caltech to find X. Meselson, who was in his first year on faculty, had developed a technique to track smaller molecules inside a cell. Jacob believed this technique would help identify X. That summer, with Jacob and Brenner in his lab, Meselson set up initial cultures and tests. Brenner took over the operations, while Jacob sat in a chair taking notes—pain from bomb fragments in his legs was worsened by the California humidity, says Meselson. For three weeks, they met with one failure after another. The ribosomes kept falling apart. Other scientists poked their heads in periodically and asked sarcastically for news of X. Jacob wrote that they “came to visit as one would visit the zoo.” On the trio’s very last scheduled day in the lab, Meselson, having given up on X, left. He flew to Boston to propose to his first wife.</p>
<p>Dejected, Jacob and Brenner went to Malibu Beach. The duo lay on the beach, watching huge waves of the Pacific crashing onto the sand and contemplating where their idea had gone wrong. Jacob wrote in his memoir: “Suddenly, Sydney gives a hoot. He leaps up, yelling, ‘The magnesium! It’s the magnesium!’ ” They raced back to the lab to run the experiment one last time, with additional magnesium. The result was spectacular. X existed.</p>
<blockquote><p><strong>READ:&nbsp;<a href="https://www.macleans.ca/news/theres-a-new-strain-of-covid-19-will-the-vaccines-work-against-it/">There’s a new strain of COVID-19. Will the vaccines work against it?</a></strong></p></blockquote>
<p>The pair gave a seminar the same day at Caltech to demonstrate X. Even then, no one believed them. They contacted Meselson in Boston that night to tell him. He was delighted. “It didn’t occur to me that they would figure out what was going wrong on the very last day,” he says. When the trio published their findings in 1961, they renamed X as messenger RNA.</p>
<p>They did not imagine that their finding would be used for therapeutics or a vaccine. Their questions were more philosophical. Meselson says, “We wondered what is it that allows you to put together the atoms of the ordinary periodic chart and end up with something that’s alive?”</p>
<p>Their work became the central tenet of molecular biology: DNA makes RNA makes protein makes life. It took another generation of scientists to find a way to harness RNA to treat and prevent illness.</p>
<p>***</p>
<p>As a kid in Kisújszállás, Hungary, Katalin Karikó watched her father, a butcher, dismember the carcasses of pigs. It was her first introduction to science. In the 1970s, while studying biochemistry at the University of Szeged, Karikó heard about a new report from London: interferon, a type of protein made by the body to trigger a defence against a virus, was mediated by an RNA called 2-5A. Karikó remembers a mentor talking to her about the discovery and being thrilled by the possibilities. He suggested to her that if they could make a synthetic version of a 2-5A molecule, they might be able to treat cancer or viral disease. “I immediately thought that what I was doing was tremendously important,” she says. It was the start of a 40-year quest to make synthetic RNA that could cure illness.</p>
<p>But she couldn’t secure funding in Hungary. Married with a two-year-old daughter, Karikó saw no way to continue her work in her home country. She wrote to professors throughout Europe about joining their labs, but no one could hire her. In 1985, she received an offer from Temple University in Philadelphia. If she could get to the United States, a job was waiting for her.</p>
<p>At the time, Hungarian money could not legally be converted to another currency and taken out of the country. Worried about how their family would survive until her first paycheque, Karikó and her husband, Bela Francia, sold their Russian-made car and converted the proceeds on the black market for a total of 900 British pounds. They sewed the money into their daughter’s teddy bear to smuggle it out of the country. The teddy bear’s owner, their daughter, Susan Francia, grew up to become a two-time Olympic gold medallist for the United States in rowing.</p>
<div id="attachment_1216834"><p><img data-sizes="auto" src="https://www.macleans.ca/wp-content/uploads/2021/02/KATALIN-KARIKO-MRNA-COVID-19-FRANGOU-FEB02.jpg" alt="Karikó at home in Pennsylvania (Rachel Wisniewski)" width="820" height="547"></p><p>Karikó at home in Pennsylvania (Rachel Wisniewski)</p></div>
<p>In their new home, things did not go as planned. Karikó’s bosses changed, she couldn’t get funding and she lost her job. Her supervisor cited her for deportation. Desperate to stay in the United States as her daughter entered first grade, Karikó accepted a researcher post in Bethesda, Maryland. She commuted from Philadelphia every Monday morning at 3 a.m. and …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.macleans.ca/society/science/scientists-mrna-covid-vaccines/">https://www.macleans.ca/society/science/scientists-mrna-covid-vaccines/</a></em></p>]]>
            </description>
            <link>https://www.macleans.ca/society/science/scientists-mrna-covid-vaccines/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26196372</guid>
            <pubDate>Fri, 19 Feb 2021 18:41:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Nyan Cat on the Blockchain]]>
            </title>
            <description>
<![CDATA[
Score 89 | Comments 88 (<a href="https://news.ycombinator.com/item?id=26196027">thread link</a>) | @awaxman11
<br/>
February 19, 2021 | https://foundation.app/NyanCat/nyan-cat-219 | <a href="https://web.archive.org/web/*/https://foundation.app/NyanCat/nyan-cat-219">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Nyan Cat is the name of an animation uploaded on April 2 2011, and became a viral internet sensation. The design of Nyan Cat was inspired by my cat Marty, who crossed the Rainbow Bridge but lives on in spirit.</p><p>I am the original artist behind the iconic GIF and have remastered the image for its 10 year anniversary.  Owning this piece grants the following stats:</p><p>Charisma +10<br>Luck +10<br>Happiness +15</p><hr><p>1400x1400 - 12 Frames</p></div></div>]]>
            </description>
            <link>https://foundation.app/NyanCat/nyan-cat-219</link>
            <guid isPermaLink="false">hacker-news-small-sites-26196027</guid>
            <pubDate>Fri, 19 Feb 2021 18:12:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Brave Browser leaks your Tor / Onion service requests through DNS]]>
            </title>
            <description>
<![CDATA[
Score 341 | Comments 84 (<a href="https://news.ycombinator.com/item?id=26194764">thread link</a>) | @todsacerdoti
<br/>
February 19, 2021 | https://ramble.pw/f/privacy/2387/brave-browser-leaks-your-tor-onion-service-requests-through | <a href="https://web.archive.org/web/*/https://ramble.pw/f/privacy/2387/brave-browser-leaks-your-tor-onion-service-requests-through">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
              <div lang="en" dir="ltr"><p>Edit: (Since this is gaining traction elsewhere.) I'm not trying to shit on Brave. I'm just wanting to help protect end-users who may use Brave for it's Tor feature to do stuff over Tor that should only be done with the actual Tor browser. If you're using Brave you probably use it because you expect a certain level of privacy/anonymity. Piping .onion requests through DNS where your ISP or DNS provider can see that <em>you</em> made a request for an .onion site defeats that purpose.</p>
<p>I'm also no NetSec expert but you don't have to be to replicate this. I'm just a dude with some websites and projects and I'm not certain I would have taken notice of this if it wasn't reported to me by a partner on another project who witnessed this behavior when monitoring his local requests leaving his network. He'll be doing his own write-up and is more equipped to discuss this in length than me.</p>
<hr><p>Testing out something that was noted a week or so ago, and wanting to replicate it for the purpose of this post.</p>
<p>Some of you know I'm working on an ad, tracker, and other BS blocking VPN service for an unrelated project to this site. Go to <a href="https://ramble.pw/f/incoghost">/f/incoghost</a> (<a href="https://incog.host/" rel="nofollow">website</a>) for more because I try to keep these things separated.</p>
<p>Anyhow, it was reported by a partner that Brave was leaking DNS requests for onion sites and I was able to confirm it at the time. Decided to spin up a VM with Brave and test with this site's Onion service (though it will do this for any .onion)</p>
<p>Example:</p>
<pre><code> Feb 18 12:02:25: query[A] rambleeeqrhty6s5jgefdfdtc6tfgg4jj6svr4jpgk4wjtg3qshwbaad.onion from 104.244.xx.xxx
</code></pre>
<p>What this entry shows (simply) is that the request made for the domain rambleeeqrhty6s5jgefdfdtc6tfgg4jj6svr4jpgk4wjtg3qshwbaad.onion made it to the DNS server and is tagged with the IP of the requester, which in this case is just the test / dev VPN. This shouldn't happen. There isn't any reason for Brave to attempt to resolve a .onion domain through traditional means as it would with a regular clearnet site.</p>
<p>This is especially worrisome for those of you who use Brave browser from your normal residential IP and (for whatever reason) use the Tor feature built into the browser to access Tor sites. Your ISP or DNS provider <em>will</em> know that a request made to a specific Tor site was made by <em>your</em> IP. With Brave, your ISP would know that you accessed <em>somesketchyonionsite.onion</em> .</p>
<p>TL;DR: If you're going to use Tor, use the Tor Browser and not Brave. The Tor browser itself doesn't leak these requests like Brave does.</p>
<hr><p>Edit: To clarify, the VPN service we're working on is no-logging but during this dev and testing period we're logging DNS requests while we work out the kinks in the blocklists. This has also allowed us to witness .onions being passed through which is a fault of Brave.</p>
<hr><p>Edit 2: Screenshot: <a href="https://images2.imgbox.com/98/46/1i084PbC_o.png" rel="nofollow">https://images2.imgbox.com/98/46/1i084PbC_o.png</a></p>
<p>That was me loading duckduckgo in a different container, with brave, while live fetching DNS requests made to the DNS server. I blurred out the non-onion requests. (Different VPN test location than in the above example so 209.x.x.x IP instead of the 104.x.x.x one in the original example.</p>
<hr><h3>EDIT 2: The mods of /r/privacy won't let this be posted. They say:</h3>
<blockquote>
<p>While we (vastly) prefer the Tor Browser over the Brave one, you'll need a better source than the one you found. Can you find something from a more widely recognized NetSec expert? Something along the lines of Bruce Schneier's blog or something at that level of credibility?</p>
</blockquote>
<p>and</p>
<blockquote>
<p>The problem with screenshots is that they can be faked, trivially. There are also a host of approaches that credible writers/reporters do in the NetSec space do before a line of text appears in print. It's this kind of journalism that we have to trust, since we humble Mods don't have the time or resources to vet. So, we'll need something better sourced. Sorry!</p>
</blockquote>
<p>and</p>
<blockquote>
<p>There are new posts everyday "warning" people of things that aren't legitimate, hence the caution. This is not a "security" subreddit. A moderator's job is to ensure that the subreddit doesn't devolve into conspiracy theories and misinformation. Security announcements should be vetted and confirmed, not independent claims that the mods have no time to independently verify.</p>
<blockquote>
<p>I can post the steps on how to easily replicate this by using pi-hole on their local networks. Anyone is capable of verifying this.</p>
</blockquote>
<p>Great. Please do so on r/brave, r/netsec, r/infosec, and other places where this is both directly relevant and appropriate to seek others confirmation. Once vetted by the community (and republished by professionals), you're welcome to post those official responses.</p>
</blockquote>
<p>/r/brave is private, invite only. I posted on netsec and infosec so we'll see. I guess /r/privacy must love Brave and not allow anything against it since it's so god damned easy to verify this...</p>
<p>All you have to do to VERIFY that this is happening is A.) Use Brave B.) Go to an Onion site C.) Observe DNS traffic. Install Pi-Hole on a Raspberry Pi or in a Virtual Machine on your desktop and run your DNS requests through it for ease of use and you can verify it. Not sure why they're so hesitant to inform their subscribers of this.</p>
<hr><p>Edit 3: Tested on both a Debian 10 and Ubuntu desktop. I'm not esteemed NetSec researcher and I'm not setting up a 100 different scenarios.</p>
</div>
            </div></div>]]>
            </description>
            <link>https://ramble.pw/f/privacy/2387/brave-browser-leaks-your-tor-onion-service-requests-through</link>
            <guid isPermaLink="false">hacker-news-small-sites-26194764</guid>
            <pubDate>Fri, 19 Feb 2021 16:27:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[We are starting to operate our CNC machines remotely]]>
            </title>
            <description>
<![CDATA[
Score 119 | Comments 93 (<a href="https://news.ycombinator.com/item?id=26193769">thread link</a>) | @Sharapolas
<br/>
February 19, 2021 | https://1d.works/how-we-started-operating-our-cnc-machines-remotely/ | <a href="https://web.archive.org/web/*/https://1d.works/how-we-started-operating-our-cnc-machines-remotely/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
                <div>
                    <h2 id="introduction"><strong>Introduction</strong></h2><p>Not only COVID-19 has brought many challenges to our daily lives, but it also has inspired a lot of change in how we work and do things. Some professions transitioned to remote work more easily than others. Factory workers and machine operators have been less lucky in this regard and that also applies to us in our CNC-based micro-factory.</p><p>Allowing more people to work remotely opens up many opportunities for businesses. Not only you can bring talent from anywhere in the world, but also you have more choices where to house the hardware allowing to optimise on cost. Furthermore, reaction times can be reduced if travel to the worksite can be eliminated. Quite a few IT professionals have been doing a good job from spectacular locations and we should strive to let more people experience that.</p><p>Another important aspect of structuring work such that it can be done remotely is that it is the first step to automating it. Local to remote, and remote to autonomous allows for a smoother transition than local to autonomous straight away. In the future, we plan on coupling our remote system to AI so if you’re interested, make sure to follow us on LinkedIn or Facebook!</p><p><strong>WARNING! </strong>Running machinery unsupervised is dangerous and must be avoided. This article is elaborating on how to operate machines more efficiently with more staff working remote, but does not suggest running machines without supervision or people on-site.</p><h2 id="how-corona-showed-us-an-opportunity"><strong>How Corona showed us an opportunity</strong></h2><p>Before the COVID-19 hit our workflow for a CNC job has been as follows:</p><ol><li>Make CAD/ CAM in the office;</li><li>Finalise CAM in the shop;</li><li>Run CNC jobs in the shop.</li></ol><p>However, during the quarantine at times it has become difficult to proceed this way because of the travel restrictions ( our CNC lab and office are based in different districts and district travel is cumbersome during quarantine ). We took up this challenge and used it as an opportunity to do the first step towards our micro-factory automation by doing more of the shop work remotely.</p><h2 id="the-cnc-lab-problem"><strong>The CNC lab problem</strong></h2><p>Running a CNC job required:</p><ol><li>Prepare the CAD/CAM files;</li><li>Setup the CNC machine for the job;</li><li>Loop: place the material, run the program, take out the cut parts, clean the table</li></ol><p>In our team, a single person has been doing all of these things. However, is it wise to use a skilled designer/ operator to be in charge of moving material and parts? Not really, because those skills could be invested in something with a much better return on investment (ROI).</p><p>Why don’t we have an unskilled person doing that work? Because CNC jobs are prone to small and costly mistakes, so to ensure high quality and safe operation, that person has to have some skills. Those skills need to either be brought in or be taught and as soon as a person has those skills we are back at having a skilled person doing a large amount of unskilled work.</p><h3 id="iteration-1">Iteration 1</h3><p>Our first step towards a solution was finding an unskilled person to be at the shop while we remote into the PC which controls the CNC machine. This has greatly improved our ROI and created a truly win-win situation because not only we are more efficiently using our time resources, but also created a new job position.</p><p>Still, there were issues to be solved. Coordination was done by phone and in order to operate the machine safely, we had to do multiple repeated questions making sure that it is safe to run the machine. Setup was particularly tricky because misunderstandings led to tool breakage and material waste. Lastly, making sure that the operation is proceeding smoothly was tricky as well since it required experienced evaluation and experience we did not have on-site.</p><h3 id="iteration-2">Iteration 2</h3><p>Having drawn conclusions from iteration 1, we’ve decided to upgrade the CNC lab with a camera for more efficient and higher quality feedback. And it is surprising how much easier work became then!</p><figure><img src="https://cdn-images-1.medium.com/max/1600/1*ukzIoHs74MRrQd9Xu3ZBJQ.png" alt=""><figcaption>Figure 1. CNC shop&nbsp;camera</figcaption></figure><p>Much less coordination was required and we were much more confident operating the CNC machine knowing that the site was safe for operation. Setups became easier because we could verify that the right measurements were made.</p><p>Soon enough we’ve found many things that could be improved:</p><ul><li>Running cameras in one window and remoting in on another tended to be inconvenient on a single screen workstation;</li><li>Although monitoring was much better, the single-camera setup did not allow to evaluate the quality of the finish or how smoothly the work was progressing;</li><li>When we were executing tool adjustments (eg. changing a bit in the tool chuck ) it was still hard to be sure that the right tool was where it needed to be;</li><li>It has become very apparent that some of the tasks could be semi-automated using feedback from the on-site worker. For example, at the beginning of each session, the machine needs to be initialised by moving it to reference and calibrating all the tools which involved checking if the site was clear for action and then going through a sequence of clicks;</li><li>Measurements still took a while to explain and then took a while to do properly.</li></ul><h3 id="iteration-3">Iteration 3</h3><p>Taking into account the inefficiencies we’ve identified, we’ve decided to work on a cohesive platform with an intuitive dashboard which would merge all the systems we have and provide the base for automation to be built upon.</p><p>First, was the network setup. We needed to merge multi-site networks into a mesh topology network where all the nodes could be interconnected which was solved using a hub and spoke topology VPN. Although, it does have its own drawbacks it had a good cost-benefit ratio when it comes to setup and deployment and is working for us for now.</p><p>Next, was building the dashboard which not only required the making of the UI but required figuring out how we’re going to expose and manage resources in our shop network. We decided to build the backend in the spirit of Kubernetes, so it is easy to manage at scale with the addition of new sensors, machines and full-blown sites themselves.</p><figure><img src="https://cdn-images-1.medium.com/max/1600/1*JYyqKIXsBTgfg8A-ENR-xw.png" alt=""><figcaption>Figure 2. CNC shop dashboard prototype</figcaption></figure><p>For the GUI we choose to go with Python’s Tkinter package in order to be able to rapidly iterate and once it reaches a stable state we’re planning to move it into a web app for easy access from any device. The dashboard is set up such that one could interface with the embedded CNC software by just doing the relevant actions on the dashboard.</p><h3 id="conclusions">Conclusions</h3><p>Based on our experience using the shop dashboard, it has helped us improve our process in the CNC shop by a mile. We are significantly more confident running remote jobs, have more oversight and control and the process is much more efficient with time.</p><p>It has also opened the possibility to (semi)-automate processes involved in running a CNC shop, which we are continuing to work with and will be posting later. We have a few ideas on how to couple the camera and control system with AI and that is an exciting prospect!</p><p>One key feature that the system requires is being able to remotely access the CNC control software. We are lucky to have it running on a PC which we can easily remote-in, but in case of embedded software, some middleware might be needed to control it remotely.</p><p>Allowing the machine operator to work remote adds value to our business as we could easier relocate the shop to cheaper areas, further from the cities or have talented engineers from nearly anywhere in the world away from work with us. That is why we will continue on this journey and will share it with you as we go!</p><hr><h3 id="check-out-more-">Check out more:</h3><ol><li><a href="https://1d.works/welcome-to-1d-works-cnc-lab/" rel="noopener">Welcome to 1D.works CNC Lab</a></li><li><a href="https://1d.works/object-oriented-computer-assisted-machining/" rel="noopener">Simplifying CAM workflow with Fusion 360</a></li><li><a href="https://1d.works/unique-products-at-scale-with-ai-infused-cad/" rel="noopener">Unique products at scale with AI-infused CAD</a></li></ol><p>and more in our <a href="https://1d.works/blog/" rel="noopener">blog</a></p><hr><h3 id="connect-">Connect!</h3><p>At <a href="https://1d.works/" rel="noopener nofollow noopener noopener">1D.works</a> we’re excited about the potential of AI to improve businesses and people’s lives. CAD and CAM are two of the largely unexplored territories we’re invested in. If you think you can benefit from a decade-long experience of applying machine learning to business processes, <a href="https://1d.works/" rel="noopener nofollow noopener noopener">get in touch</a>!</p><hr><figure><img src="https://cdn-images-1.medium.com/max/1600/1*ZttLaS6wTmFLgKZ6_9LeeA.png" alt=""></figure>
                </div>
            </section></div>]]>
            </description>
            <link>https://1d.works/how-we-started-operating-our-cnc-machines-remotely/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26193769</guid>
            <pubDate>Fri, 19 Feb 2021 14:53:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Brave Browser leaks your Tor / Onion service requests through DNS]]>
            </title>
            <description>
<![CDATA[
Score 27 | Comments 14 (<a href="https://news.ycombinator.com/item?id=26192574">thread link</a>) | @input_sh
<br/>
February 19, 2021 | https://ramble.pw/f/privacy/2387 | <a href="https://web.archive.org/web/*/https://ramble.pw/f/privacy/2387">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
              <div lang="en" dir="ltr"><p>Edit: (Since this is gaining traction elsewhere.) I'm not trying to shit on Brave. I'm just wanting to help protect end-users who may use Brave for it's Tor feature to do stuff over Tor that should only be done with the actual Tor browser. If you're using Brave you probably use it because you expect a certain level of privacy/anonymity. Piping .onion requests through DNS where your ISP or DNS provider can see that <em>you</em> made a request for an .onion site defeats that purpose.</p>
<p>I'm also no NetSec expert but you don't have to be to replicate this. I'm just a dude with some websites and projects and I'm not certain I would have taken notice of this if it wasn't reported to me by a partner on another project who witnessed this behavior when monitoring his local requests leaving his network. He'll be doing his own write-up and is more equipped to discuss this in length than me.</p>
<hr><p>Testing out something that was noted a week or so ago, and wanting to replicate it for the purpose of this post.</p>
<p>Some of you know I'm working on an ad, tracker, and other BS blocking VPN service for an unrelated project to this site. Go to <a href="https://ramble.pw/f/incoghost">/f/incoghost</a> (<a href="https://incog.host/" rel="nofollow">website</a>) for more because I try to keep these things separated.</p>
<p>Anyhow, it was reported by a partner that Brave was leaking DNS requests for onion sites and I was able to confirm it at the time. Decided to spin up a VM with Brave and test with this site's Onion service (though it will do this for any .onion)</p>
<p>Example:</p>
<pre><code> Feb 18 12:02:25: query[A] rambleeeqrhty6s5jgefdfdtc6tfgg4jj6svr4jpgk4wjtg3qshwbaad.onion from 104.244.xx.xxx
</code></pre>
<p>What this entry shows (simply) is that the request made for the domain rambleeeqrhty6s5jgefdfdtc6tfgg4jj6svr4jpgk4wjtg3qshwbaad.onion made it to the DNS server and is tagged with the IP of the requester, which in this case is just the test / dev VPN. This shouldn't happen. There isn't any reason for Brave to attempt to resolve a .onion domain through traditional means as it would with a regular clearnet site.</p>
<p>This is especially worrisome for those of you who use Brave browser from your normal residential IP and (for whatever reason) use the Tor feature built into the browser to access Tor sites. Your ISP or DNS provider <em>will</em> know that a request made to a specific Tor site was made by <em>your</em> IP. With Brave, your ISP would know that you accessed <em>somesketchyonionsite.onion</em> .</p>
<p>TL;DR: If you're going to use Tor, use the Tor Browser and not Brave. The Tor browser itself doesn't leak these requests like Brave does.</p>
<hr><p>Edit: To clarify, the VPN service we're working on is no-logging but during this dev and testing period we're logging DNS requests while we work out the kinks in the blocklists. This has also allowed us to witness .onions being passed through which is a fault of Brave.</p>
<hr><p>Edit 2: Screenshot: <a href="https://images2.imgbox.com/98/46/1i084PbC_o.png" rel="nofollow">https://images2.imgbox.com/98/46/1i084PbC_o.png</a></p>
<p>That was me loading duckduckgo in a different container, with brave, while live fetching DNS requests made to the DNS server. I blurred out the non-onion requests. (Different VPN test location than in the above example so 209.x.x.x IP instead of the 104.x.x.x one in the original example.</p>
<hr><h3>EDIT 2: The mods of /r/privacy won't let this be posted. They say:</h3>
<blockquote>
<p>While we (vastly) prefer the Tor Browser over the Brave one, you'll need a better source than the one you found. Can you find something from a more widely recognized NetSec expert? Something along the lines of Bruce Schneier's blog or something at that level of credibility?</p>
</blockquote>
<p>and</p>
<blockquote>
<p>The problem with screenshots is that they can be faked, trivially. There are also a host of approaches that credible writers/reporters do in the NetSec space do before a line of text appears in print. It's this kind of journalism that we have to trust, since we humble Mods don't have the time or resources to vet. So, we'll need something better sourced. Sorry!</p>
</blockquote>
<p>and</p>
<blockquote>
<p>There are new posts everyday "warning" people of things that aren't legitimate, hence the caution. This is not a "security" subreddit. A moderator's job is to ensure that the subreddit doesn't devolve into conspiracy theories and misinformation. Security announcements should be vetted and confirmed, not independent claims that the mods have no time to independently verify.</p>
<blockquote>
<p>I can post the steps on how to easily replicate this by using pi-hole on their local networks. Anyone is capable of verifying this.</p>
</blockquote>
<p>Great. Please do so on r/brave, r/netsec, r/infosec, and other places where this is both directly relevant and appropriate to seek others confirmation. Once vetted by the community (and republished by professionals), you're welcome to post those official responses.</p>
</blockquote>
<p>/r/brave is private, invite only. I posted on netsec and infosec so we'll see. I guess /r/privacy must love Brave and not allow anything against it since it's so god damned easy to verify this...</p>
<p>All you have to do to VERIFY that this is happening is A.) Use Brave B.) Go to an Onion site C.) Observe DNS traffic. Install Pi-Hole on a Raspberry Pi or in a Virtual Machine on your desktop and run your DNS requests through it for ease of use and you can verify it. Not sure why they're so hesitant to inform their subscribers of this.</p>
<hr><p>Edit 3: Tested on both a Debian 10 and Ubuntu desktop. I'm not esteemed NetSec researcher and I'm not setting up a 100 different scenarios.</p>
</div>
            </div></div>]]>
            </description>
            <link>https://ramble.pw/f/privacy/2387</link>
            <guid isPermaLink="false">hacker-news-small-sites-26192574</guid>
            <pubDate>Fri, 19 Feb 2021 12:51:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[“I will slaughter you”]]>
            </title>
            <description>
<![CDATA[
Score 516 | Comments 225 (<a href="https://news.ycombinator.com/item?id=26192025">thread link</a>) | @ingve
<br/>
February 19, 2021 | https://daniel.haxx.se/blog/2021/02/19/i-will-slaughter-you/ | <a href="https://web.archive.org/web/*/https://daniel.haxx.se/blog/2021/02/19/i-will-slaughter-you/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<p>You might know that I’ve posted funny emails I’ve received on my blog several times in the past. The kind of emails people send me when they experience problems with some device they own (like a <a href="https://daniel.haxx.se/blog/2018/02/16/why-is-your-email-in-my-car/" data-type="post" data-id="10856">car</a>) and they contact me because my email address happens to be visible somewhere.</p>



<p>People sometimes say I should get a different email address or use another one in the curl license file, but I’ve truly never had a problem with these emails, as they mostly remind me about the tough challenges the modern technical life bring to people and it gives me insights about what things that run curl.</p>



<p>But not all of these emails are “funny”.</p>



<h2>Category: not funny</h2>



<p>Today I received the following email</p>



<pre>From: Al Nocai &lt;[redacted]@icloud.com&gt;
Date: Fri, 19 Feb 2021 03:02:24 -0600
Subject: I will slaughter you</pre>



<p>That subject.</p>



<p>As an open source maintainer since over twenty years, I know flame wars and personal attacks and I have a fairly thick skin and I don’t let words get to me easily. It took me a minute to absorb and realize it was actually meant as a direct physical threat. It found its ways through and got to me. This level of aggressiveness is not what I’m prepared for.</p>



<p>Attached in this email, there were seven images and no text at all. The images all look like screenshots from a phone and the first one is clearly showing <a href="https://github.com/curl/curl/blob/master/include/curl/multi.h">source code I wrote</a> and my copyright line:</p>



<div><figure><a href="https://daniel.haxx.se/blog/wp-content/uploads/2021/02/image0.png"><img loading="lazy" width="295" height="640" src="https://daniel.haxx.se/blog/wp-content/uploads/2021/02/image0.png" alt=""></a></figure></div>



<p>The <a href="https://daniel.haxx.se/al/">other images</a> showed other source code and related build/software info of other components, but I couldn’t spot how they were associated with me in any way.</p>



<p>No explanation, just that subject and the seven images and I was left to draw my own conclusions.</p>



<p>I presume the name in the email is made up and the email account is probably a throw-away one. The time zone used in the <code>Date:</code> string might imply US <a href="https://www.timeanddate.com/time/zones/cst">central standard time</a> but could of course easily be phony as well. </p>



<h2>How I responded</h2>



<p>Normally I don’t respond to these confused emails because the distance between me and the person writing them is usually almost interplanetary. This time though, it was so far beyond what’s acceptable to me and in any decent society I couldn’t just let it slide. After I took a little pause and walked around my house for a few minutes to cool off, I wrote a really angry reply and sent it off.</p>



<blockquote><p>This was a totally and completely utterly unacceptable email and it hurt me deep in my soul. You should be ashamed and seriously reconsider your manners.</p><p>I have no idea what your screenshots are supposed to show, but clearly something somewhere is using code I wrote. Code I have written runs in virtually every Internet connected device on the planet and in most cases the users download and use it without even telling me, for free.</p><p>Clearly you don’t deserve my code.</p></blockquote>



<p>I don’t expect that it will be read or make any difference.</p>



<p>Update below, added after my initial post.</p>



<h2>Al Nocai’s response</h2>



<p>Contrary to my expectations above, he responded. It’s not even worth commenting but for transparency I’ll include it here.</p>



<p><em>I do not care. Your bullshit software was an attack vector that cost me a multimillion dollar defense project.</em></p>



<p><em>Your bullshit software has been used to root me and multiple others. I lost over $15k in prototyping alone from bullshit rooting to the charge arbitrators.</em></p>



<p><em>I have now since October been sandboxed because of your bullshit software so dipshit google kids could grift me trying to get out of the sandbox because they are too piss poor to know shat they are doing.</em></p>



<p><em>You know what I did to deserve that? I tried to develop a trade route in tech and establish project based learning methodologies to make sure kids aren’t left behind. You know who is all over those god damn files? You are. Its sickening. I got breached in Oct 2020 through federal server hijacking, and I owe a great amount of that to you.</em></p>



<p><em>Ive had to sit and watch as i reported:</em></p>



<ol><li><em>fireeye Oct/2020</em></li><li><em>Solarwinds Oct/2020</em></li><li><em>Zyxel Modem Breach Oct/2020</em></li><li><em>Multiple Sigover attack vectors utilizing favicon XML injection</em></li><li><em>JS Stochastic templating utilizing comparison expressions to write to data registers</em></li><li><em>Get strong armed by $50billion companies because i exposed bullshit malware</em></li></ol>



<p><em>And i was rooted and had my important correspondence all rerouted as some sick fuck dismantled my life with the code you have your name plastered all over. I cant even leave the country because of the situation; qas you have so effectively built a code base to shit all over people, I dont give a shit how you feel about this.</em></p>



<p><em>You built a formula 1 race car and tossed the keys to kids with ego problems. Now i have to deal with Win10 0-days because this garbage.</em></p>



<p><em>I lost my family, my country my friends, my home and 6 years of work trying to build a better place for posterity. And it has beginnings in that code. That code is used to root and exploit people. That code is used to blackmail people.</em></p>



<p><em>So no, I don’t feel bad one bit. You knew exactly the utility of what you were building. And you thought it was all a big joke. Im not laughing. I am so far past that point now.</em></p>



<p><em>/- Al</em></p>



<h2>Al continues</h2>



<p>Nine hours after I first published this blog post , Al replied again with two additional emails. His third and forth emails to me.</p>



<h3>Email 3:</h3>



<p><em><a href="https://davidkrider.com/i-will-slaughter-you-daniel-haxx-se/">https://davidkrider.com/i-will-slaughter-you-daniel-haxx-se/</a><br>Step up. You arent scaring me. What led me here? The 5th violent attempt on my life. Apple terms of service? gtfo, thanks for the platform.</em></p>



<p>Amusingly he has found a blog post about my blog post.</p>



<h3>Email 4:</h3>



<p><em>There is the project: MOUT Ops Risk Analysis through Wide Band Em Spectrum analysis through different fourier transforms.<br>You and whoever the fuck david dick rider is, you are a part of this.<br>Federal server breaches-<br>Accomplice to attempted murder-<br>Fraud-<br>just a few.</em></p>



<p><em>I have talked to now: FBI FBI Regional, VA, VA OIG, FCC, SEC, NSA, DOH, GSA, DOI, CIA, CFPB, HUD, MS, Convercent, as of today 22 separate local law enforcement agencies calling my ass up and wasting my time.</em></p>



<p><em>You and dick ridin’ dave are respinsible. I dont give a shit, call the cops. I cuss them out wheb they call and they all go silent.</em></p>



<p>I’ve kept his peculiar formatting and typos. In email 4 there was also a PDF file attached named <code>BustyBabes 4.pdf</code>. It is apparently a 13 page document about the “NERVEBUS NERVOUS SYSTEM” described in the first paragraph as “NerveBus Nervous System aims to be a general utility platform that provides comprehensive and complex analysis to provide the end user with cohesive, coherent and “real-time” information about the environment it monitors.”. There’s no mention of curl or my name in the document.</p>



<p>Since I don’t know the status of this document I will not share it publicly, but here’s a screenshot of the front page:</p>



<div><figure><a href="https://daniel.haxx.se/blog/wp-content/uploads/2021/02/Screenshot_2021-02-20-BustyBabes-4-pdf.png"><img loading="lazy" src="https://daniel.haxx.se/blog/wp-content/uploads/2021/02/Screenshot_2021-02-20-BustyBabes-4-pdf.png" alt="" width="358" height="462"></a></figure></div>



<h2>Related</h2>



<p>This topic on <a href="https://news.ycombinator.com/item?id=26192025">hacker news</a> and <a href="https://www.reddit.com/r/programming/comments/lnhcrc/i_will_slaughter_you_daniel_stenberg_got_a_quite/">reddit</a>.</p>



<p>I have reported the threat to the Swedish police (where I live).</p>
	</div></div>]]>
            </description>
            <link>https://daniel.haxx.se/blog/2021/02/19/i-will-slaughter-you/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26192025</guid>
            <pubDate>Fri, 19 Feb 2021 11:36:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to be more productive without forcing yourself]]>
            </title>
            <description>
<![CDATA[
Score 248 | Comments 120 (<a href="https://news.ycombinator.com/item?id=26191516">thread link</a>) | @vitabenes
<br/>
February 19, 2021 | https://www.deprocrastination.co/blog/how-to-be-productive-without-forcing-yourself | <a href="https://web.archive.org/web/*/https://www.deprocrastination.co/blog/how-to-be-productive-without-forcing-yourself">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><p><img src="https://www.deprocrastination.co/assets/illustrations/work_bad_rect.png" referrerpolicy="no-referrer" alt="How to be more productive without forcing yourself"></p><p>Imagine you could work more and be wildly productive. And the best thing about it? You wouldn’t need to force yourself to work.</p><p>There are people exactly like that who sit down and work without pushing themselves to do it. They even look forward to working. The good news is that you can learn to do it too.</p><p>Let’s get to it.</p><p>Most people have a negative mindset about work. People see work as an annoyance that keeps them from doing whatever they really want to do. They also think that resting and having nothing to do is an ideal state they’d like to be in forever. This leads to thinking that you need to push yourself to work. You need to use willpower to get yourself to do it.</p><p>It’s simple to understand where this attitude comes from:</p><ol><li>People usually want things they don’t have and think that grass is greener on the other side.</li><li>Everyone talks about how work is hard.</li><li>In comparison to dead-end or corporate jobs without impact or freedom, neverending leisure looks like paradise.</li></ol><p>In reality, most people who try to be in this nothing-to-do state for a long time become unhappy, depressed, and bored. Rich people who “made it” report how soon they become restless again.&nbsp;<a href="https://www.reddit.com/r/StopGaming/">People who game all the time</a>&nbsp;realize how empty it feels. Too much leisure isn’t satisfying for long.</p><p>On the other hand, there is a certain group of people who work a lot and enjoy it. Let’s call this group&nbsp;<em>producers</em>. By this, we don’t mean workaholics who escape from their whole life by working all the time. Producers have a healthy work-life balance. So what do they do that people who hate work don’t?</p><p>First, they tend to think about work differently.</p><p>For them, work is&nbsp;<a href="https://www.deprocrastination.co/blog/what-is-a-positive-feedback-loop-and-why-it-matters">a virtuous cycle of positive feedback loops</a>. Producers see&nbsp;<strong>work as a source of meaning and satisfaction</strong>. They see work as something that allows them to savor deserved leisure. They see rest as something that increases their life happiness and fuels their motivation towards work.</p><p>Second, their work is usually:</p><ul><li>Interesting</li><li>Meaningful</li><li>Well-defined</li></ul><p>If you check at least 1 or 2 boxes somehow, something magical happens:</p><p><strong>You don’t have to push yourself towards work anymore.</strong></p><p>Well-defined, meaningful, and especially interesting work is easy to look forward to.</p><p>Non-producers often think that these producers are lucky because they stumbled upon work like this. In reality, producers often go a long way to make their work fun.</p><h2>How to make work more interesting</h2><p>This is the crucial factor in whether work gets done.</p><p>You don’t have to see any meaning in your work for it to be interesting.</p><p>Even if the task is totally undefined, complex, and difficult, curiosity can carry you to its completion.</p><p>So how can you develop this curiosity towards work?</p><p>You have to give the work a chance to become interesting. How? By combining these 3 steps:</p><h3>1. Have less exposure towards super fun things</h3><p>Video games, surfing the internet, porn, alcohol, and drugs etc. make work significantly more difficult. Why?</p><p>They establish a certain standard of mental stimulation. Anything that’s not super fun will seem boring.</p><p><img src="https://www.deprocrastination.co/assets/illustrations/stimulation_standard.png" referrerpolicy="no-referrer" alt="We develop a Stimulation Standard"></p><p>Unfortunately, work often falls in the “feels bad” category. In comparison to games or social media, work can feel uninteresting or annoying.</p><p><img src="https://www.deprocrastination.co/assets/illustrations/stimulation_work_distractions.png" referrerpolicy="no-referrer" alt="Switching from distractions to work is hard"></p><p>You might argue that there are people who work just fine even while drinking alcohol, playing video games etc.</p><p>However, consider that there are two types of people: ones who can moderate their consumption and others who can’t. The latter society often describes as addicts.</p><p>Basically, if you’re addicted to any of the high-dopamine, low-effort activity, please quit it. At least temporarily so you can reestablish a healthy relationship to work. The more experienced we’re about the topic, the more obvious this is. There is no other way than to temporarily quit the addiction. If your vice is gaming, we’ve covered&nbsp;<a href="https://www.deprocrastination.co/blog/should-i-quit-video-games">video gaming addiction here</a>.</p><p>Some can have a healthy relationship with, for example, gaming.</p><p>However, for some people gaming is kryptonite. Here are some signs that super-fun activities have a detrimental effect on your work:</p><ol><li>You rush and half-ass everything else in order to get to your super-fun activity.         When I (Mat) was addicted to gaming, everything during the day was half-assed so I could finally start playing.</li><li>You keep postponing or forgetting everything that isn’t urgent in order to get to your super fun activity. You have this book that you want to read but you never get to actually reading it.</li><li>Your orderliness suffers once you start with the super fun activity.        Most people who come back to gaming report how their sense of orderliness starts to depreciate rather quickly. Their room gets messy, they start skipping workouts, stop meal-prepping, start eating more junk food, stop organizing their days.</li></ol><p>If the points above describe you, it might be time to quit your super fun activity. At least for a while.</p><p>Once your brain is not constantly hyper-stimulated, it’s easier to find mundane activities like work or tidying more interesting.</p><h3>2. Get bored more often</h3><p>When you get bored, everything else becomes more interesting.</p><p>Don’t believe us? Try this little experiment. Turn everything off. Set a timer for 15 minutes. Sit on a chair and stare at a wall. Don’t move. Don’t consume any information. Don’t talk. Don’t write anything down. Just stare at the wall.</p><p>Except for zen masters, most of us will become restless after a few minutes. Often, our brain starts dreaming and imagining things. For the first few minutes, you might feel alright, thinking about your day. However, after 5 or 10 minutes, you’ll be itching to do something, anything really. Suddenly, creating a website, writing an article, or drawing a picture sounds like more interesting, more fun.</p><p><img src="https://www.deprocrastination.co/assets/illustrations/stimulation_work_boredom.png" referrerpolicy="no-referrer" alt="Switching from boredom to work is easier"></p><p>If you feel like you never stop scrolling and consume content all the time, schedule a 15 minute boredom window for tomorrow right before you want to start working.&nbsp;<a href="https://www.deprocrastination.co/blog/how-to-use-boredom-to-procrastinate-less">Use boredom strategically.</a></p><h3>3. Dive deep into a topic</h3><p>It’s fun when we can connect the dots. When we can draw new connections between ideas, we get a rush.&nbsp;<em>Oh, I can see how this historical event contributed to an uprising…</em></p><p>The more connections we can draw within a topic, the more interested we become. This is what curiosity is all about.</p><p>If you take the time to watch a documentary related to what you’re working on, read a book about it, or find a couple relevant articles. You’ll collect more dots to connect. You’ll see how everything fits together.</p><p>When you do feel like watching something or have a free evening, instead of watching random videos or reruns of old TV shows, steer your attention to something related to what you need to do.</p><p>Give yourself time to develop an interest.</p><h2>How to make work more meaningful</h2><p>It's hard to feel motivated when you don't have a personal reason to do something.</p><p>However, “meaningful work” has become something of a buzzword.</p><p>Everyone is trying to find meaning in their work. This can be wasted energy, especially if you work in a corporate or a dead-end job. We say this so you don’t dwell on it and don’t feel frustrated because you can’t figure out how to save the world by doing what you do.</p><p>In any case, whatever your work is, you can make it meaningful enough to start.</p><p>Let’s say you have to study for an exam. You don’t find this particular class enjoyable. If you remind yourself why you chose to take the class and why studying is important for you, you will have an easier time persuading yourself to push through.</p><p>The fact is that some things simply need to be done. It's better if you find a compelling and personal reason to do them and get them over with as soon as possible, instead of putting them off forever.</p><p>When something is boring, ask yourself: Why do I need to do this? Find and reinforce the why behind the work.</p><h2>How to make work well-defined</h2><p>If you have a recipe that tells you step-by-step how to cook a meal, it is usually quite easy to follow. You know exactly where to start and how.</p><p>In today’s creative work, this often isn’t the case. There are no recipes for the work we need to do, or they don’t make the work any easier because the recipe would be too complex to understand.</p><p>Additionally, we often hamper our enthusiasm towards work by ourselves. How often do you find yourself with vague and unhelpful to-dos like “write the essay” or “make a video.”</p><p>There are so many steps in “make a video” that this vague task definition only causes anxiety and procrastination.</p><p>We always say that it’s more difficult to start working than to keep working. Therefore we should make starting easier by defining well&nbsp;<em>how</em>&nbsp;to begin and&nbsp;<em>what</em>&nbsp;to begin with.</p><p>The better you can define how to start working, the easier it’ll be to actually do it.</p><p>Basically, you do this in 3 steps:</p><h3>1. Always define exactly where you’ll start</h3><p>This means you write down the next physical action to take.</p><p>Do you need to write an essay?</p><p>The next physical action is: Open the scientific study and start reading</p><p>Or: Create a document → Create a rough draft in the next 15 minutes</p><p>Do you want to start learning coding?</p><p>The next physical action should be: Open freecodecamp.org → Start solving the first challenge</p><p>It might sound silly to define the next physical action, but it isn’t. Finding it is easy, and you can do it immediately.</p><p>What’s the next physical action you need to take?</p><h3>2. Start with only having to work for 5/15 minutes</h3><p>You probably don't feel like creating a 20 slide presentation right now from scratch, and then presenting it in 2 hours.</p><p>You don't feel like writing a whole final thesis on a topic you barely know.</p><p>You don't feel like running a marathon.</p><p>But you might feel like looking up a couple pictures or articles for the presentation.</p><p>Or feel like writing a paragraph or two before lunch break.</p><p>Or feel like taking a 1km walk.</p><p>Those are the small steps along the longer journey.</p><p>We often underestimate the power of small steps, but they are essential because they help us get into the right routine.</p><p>If you start running a couple miles every other day, you'll get familiar with the routine and then you'll naturally want to start increasing the …</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.deprocrastination.co/blog/how-to-be-productive-without-forcing-yourself">https://www.deprocrastination.co/blog/how-to-be-productive-without-forcing-yourself</a></em></p>]]>
            </description>
            <link>https://www.deprocrastination.co/blog/how-to-be-productive-without-forcing-yourself</link>
            <guid isPermaLink="false">hacker-news-small-sites-26191516</guid>
            <pubDate>Fri, 19 Feb 2021 10:27:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Where Everything Went Wrong: Error Handling and Error Messages in Rust (2020)]]>
            </title>
            <description>
<![CDATA[
Score 148 | Comments 181 (<a href="https://news.ycombinator.com/item?id=26191006">thread link</a>) | @lukastyrychtr
<br/>
February 19, 2021 | https://msirringhaus.github.io/Where-everything-went-wrong/ | <a href="https://web.archive.org/web/*/https://msirringhaus.github.io/Where-everything-went-wrong/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p><strong>Today you are frustrated.</strong></p>

<p>This is so annoying. Youâ€™ve written a Rust crate and now that you want to test it for the very first time, <em>it doesnâ€™t work!</em></p>

<p>Come on, Rust! How dare you? You promised that once one gets past the compiler, it.<br>
<em>Just.<br>
<strong>Works!</strong></em><br>
And now this!</p>

<p>Ok, ok. You calm yourself down. Lets start from the beginning. You want to create so called <a href="https://docs.sentry.io/platforms/native/guides/minidumps/">minidumps</a>. This is a file that contains information about a crashed program (like stacks of all threads, CPU registers, system info, etc.).
The minidump consists of various sections, such as the minidump header (including time of day, versions and basically a table of contents), a thread section (including all threads of the process and their stacks), memory mappings and libraries, etc. [Just to give some context, as all of this is actually not really important.]</p>

<p>For this, you created a <a href="https://github.com/msirringhaus/minidump_writer_linux">crate</a>. One section gets written after the other, while information about the targeted process is retrieved from the system. You even created a nice, simple API. You hand in a process ID and an open file, where the minidump should be written to. like this:</p>

<div><div><pre><code>    <span>MinidumpWriter</span><span>::</span><span>new</span><span>(</span><span>pid</span><span>,</span> <span>blamed_thread</span><span>)</span>
        <span>.dump</span><span>(</span><span>&amp;</span><span>mut</span> <span>dump_file</span><span>)</span>
        <span>.expect</span><span>(</span><span>"Dumping failed!"</span><span>)</span>
</code></pre></div></div>

<p>You can also hand in user specified memory regions that should be included in the dump, like so:</p>

<div><div><pre><code>    <span>let</span> <span>app_memory</span> <span>=</span> <span>AppMemory</span> <span>{</span>
        <span>ptr</span><span>:</span> <span>some_address</span><span>,</span>
        <span>length</span><span>:</span> <span>memory_size</span><span>,</span>
    <span>};</span>

    <span>MinidumpWriter</span><span>::</span><span>new</span><span>(</span><span>pid</span><span>,</span> <span>pid</span><span>)</span>
        <span>.set_app_memory</span><span>(</span><span>vec!</span><span>[</span><span>app_memory</span><span>])</span>
        <span>.dump</span><span>(</span><span>&amp;</span><span>mut</span> <span>tmpfile</span><span>)</span>
        <span>.expect</span><span>(</span><span>"Dumping failed"</span><span>);</span>
</code></pre></div></div>



<p>But when you run your nice library code in an application, you get <code>'Dumping failed: "Failed in ptrace::read: Sys(EIO)"'</code>.</p>

<p><em>How useless is that?!</em></p>

<p>Okay, maybe you could enhance your library error handling, a little. And by enhance, you mean â€œimplement one in the first placeâ€�.</p>

<h2 id="state-of-the-dart">State of the dart</h2>

<p>Your current approach is to define</p>

<div><div><pre><code><span>type</span> <span>Error</span> <span>=</span> <span>Box</span><span>&lt;</span><span>dyn</span> <span>error</span><span>::</span><span>Error</span> <span>+</span> <span>std</span><span>::</span><span>marker</span><span>::</span><span>Send</span> <span>+</span> <span>std</span><span>::</span><span>marker</span><span>::</span><span>Sync</span><span>&gt;</span><span>;</span>
<span>pub</span> <span>type</span> <span>Result</span><span>&lt;</span><span>T</span><span>&gt;</span> <span>=</span> <span>result</span><span>::</span><span>Result</span><span>&lt;</span><span>T</span><span>,</span> <span>Error</span><span>&gt;</span><span>;</span>
</code></pre></div></div>

<p>and using <code>Result&lt;T&gt;</code> in all of your functions as the return value and handing all of them to the parent function using <code>?</code>. Thus the original error pierces through your callstack like a dart throughâ€¦.jelly (Yes, you are good with words and you know it.).</p>

<div><div><pre><code>    <span>pub</span> <span>fn</span> <span>init</span><span>(</span><span>&amp;</span><span>mut</span> <span>self</span><span>)</span> <span>-&gt;</span> <span>Result</span><span>&lt;</span><span>()</span><span>&gt;</span> <span>{</span>
        <span>self</span><span>.read_auxv</span><span>()</span><span>?</span><span>;</span>
        <span>self</span><span>.enumerate_threads</span><span>()</span><span>?</span><span>;</span>
        <span>self</span><span>.enumerate_mappings</span><span>()</span><span>?</span><span>;</span>
        <span>Ok</span><span>(())</span>
    <span>}</span>
</code></pre></div></div>

<p>In Rust parlance, this is also called bubbling up errors.</p>

<p>Usually, you just bubble up errors from libraries you use, but for the rare errors you have to define yourself, you currently just do</p>
<div><div><pre><code><span>Err</span><span>(</span><span>"Found no auxv entry"</span><span>.into</span><span>())</span>
</code></pre></div></div>

<p>Well, now you know there is an error, at least. And that it has <em>something</em> to do with your usage of <code>ptrace</code>. But you have no idea where that happens. You use that functionality in various places. Is it during the init-phase? During one of the sections? And if so, which one? What are you trying to read? And from where? Or in short: <strong>What is going on?!</strong></p>

<h2 id="shoes-off-get-some-tea-research-time">Shoes off, get some tea: Research time!</h2>

<p>Well, Rust has been around for quite some time now and they always boast about how error handling is a first class citizen and all that. So error handling should be a done deal, right? With a canonical way of dealing with errors, officially documented and all that should be right there, correct?</p>

<p>Oh boy, were you wrong.</p>

<p>Turns out, this is a very active field ofâ€¦mhâ€¦experimentation, lets say. There has been <a href="https://blog.yoshuawuyts.com/error-handling-survey/">a survey</a> recently, listing and quickly describing most the different libraries and ways for error handling that emerged, fallen out of favor, got forked, died anyways, got superseded, fallen out of favor again, etc.
And the opinions seem to change frequently, if you should use <code>error-chain</code> or <code>failure</code> or <code>fehler</code> or <code>snafu</code> or <code>thiserror</code> or <code>anyhow</code> or <code>eyre</code> orâ€¦</p>

<p>You opened a can of hornets there, or whatever that saying is.</p>

<p>Then you find <a href="https://blog.rust-lang.org/inside-rust/2020/11/23/What-the-error-handling-project-group-is-working-on.html">this gem</a> and donâ€™t know if you should laugh or cry. Almost six years after Rust hit 1.0 an error handling project group is formed. Six. Years. <em>(heavy breathing)</em></p>

<p>Well, okay. At least they are sorting it out now. Problem is, you needâ€¦.<em>SIX YEARS? Are you serious?</em>â€¦ahem, sorryâ€¦Problem is, you need helpful error messages now.</p>

<p>After reading a few decent blogs on the topic (like <a href="http://www.sheshbabu.com/posts/rust-error-handling/">this</a> or <a href="https://nick.groenen.me/posts/rust-error-handling/">that</a>), there seems to emerge a consensus, at least for libraries: Return something that derives from <code>std::error::Error</code>. Either implement them by hand, or use a crate that does it for you, using macro magic. like <code>thiserror</code>. Which method you use depends on your level of laziness plus your patience regarding compile times.</p>

<h2 id="examples-vs-reality">Examples vs. Reality</h2>

<p>Another post highlighted <a href="https://doc.rust-lang.org/rust-by-example/error/multiple_error_types/wrap_error.html">error wrapping</a>, a particularly intriguing idea to you.</p>

<p>Unfortunately, all the articles have the understandable, but rather annoying tendency to use very simple example code for illustration purposes. Unrealistically simple, you might even say. They have callstacks of depth 1, return only three kinds of error in total in their API, and their errors are obvious and easily describable (e.g. â€œInput file XY not found in your â€˜counting wordsâ€™ programâ€�).</p>

<p>You have a more complicated callstack, with tons of different errors and code reuse in different places. For example, the function you think is to blame for the above error is <code>copy_from_process()</code>, which calls <code>ptrace::read()</code>, which probably returns something like <code>Failed in ptrace::read: Sys(EIO)</code>.
This function is used in multiple places in your code, e.g.:</p>

<div><div><pre><code>â”œâ”€ init()
â”‚   â”œâ”€ read_auxv()
â”‚   â”‚  â”œâ”€ open(format!("/proc/{}/auxv", self.pid))
â”‚   â”‚  â””â”€ some_parsing()
â”‚   â”œâ”€ ...
â”‚   â”œâ”€ enumerate_mappings()
â”‚   â”‚  â”œâ”€ open(format!("/proc/{}/maps", self.pid))
â”‚   â”‚  â””â”€ some_parsing()
â”‚   â”‚
â”‚   â””â”€ some_more_checks()
â”‚      â””â”€ copy_from_process()
â”‚
â””â”€ dump()
   â”‚
   â”œâ”€ sections::header::write()
   â”‚
   â”œâ”€ sections::thread_list_stream::write()
   â”‚  â””â”€ copy_from_process()
   â”‚
   â”œâ”€ sections::mappings::write()
   â”‚  â””â”€ elf_identifier_for_mapping()
   â”‚     â””â”€ copy_from_process()
   â”‚
   â”œâ”€ sections::app_memory::write()
   â”‚  â””â”€ copy_from_process()
   â”‚
   â””â”€ ...
</code></pre></div></div>

<p>Same goes for opening files, which happens in multiple places (two examples of which are shown in <code>init()</code>), so getting <code>FileNotFound</code> without context is going to be equally fun, and so on.</p>



<p>Wrapping errors still sounds like a nice idea, but one layer alone is not going to <del>wrap it</del> cut it.
Going with <code>copy_from_process()</code> as an example, you see a few possibilities:</p>
<ol>
  <li>Wrapping the <code>ptrace</code> error into an <code>CopyFromProcessError</code>, but that gives you nothing (except maybe some context, if you add some)</li>
  <li>With <code>InitError</code>s and <code>DumpingError</code>s that wrap the <code>ptrace</code> errors, you will still not know which section failed and why, but know if it was during <code>init()</code> or not.</li>
</ol>

<p>You might add context to option 2 as well (see below on how), but each section has a variety of reasons why it could fail. Some unique to the section, some shared among a few, some among all of them.</p>

<p>Complex problems sometimes require complex solutions, maybe?</p>

<h2 id="inc-err-ption">Inc <em>Err()</em> ption</h2>

<p>Using <code>thiserror</code> and the fabulous <code>#[from]</code> macro, you quickly define a plethora of errors and wrappers, starting from the deepest, darkest places in your callstack, wrapping your way up:</p>

<div><div><pre><code><span>#[derive(Debug,</span> <span>Error)]</span>
<span>pub</span> <span>enum</span> <span>PtraceDumperError</span> <span>{</span>
    <span>#[error(</span><span>"nix::ptrace() error"</span><span>)]</span>
    <span>PtraceError</span><span>(</span><span>#[from]</span> <span>nix</span><span>::</span><span>Error</span><span>),</span>
    <span>...</span>
<span>}</span>

<span>#[derive(Debug,</span> <span>Error)]</span>
<span>pub</span> <span>enum</span> <span>SectionAppMemoryError</span> <span>{</span>
    <span>#[error(</span><span>"Failed to copy memory from process"</span><span>)]</span>
    <span>CopyFromProcessError</span><span>(</span><span>#[from]</span> <span>PtraceDumperError</span><span>),</span>
    <span>...</span>
<span>}</span>

<span>#[derive(Debug,</span> <span>Error)]</span>
<span>pub</span> <span>enum</span> <span>DumpError</span> <span>{</span>
    <span>#[error(</span><span>"Error during init phase"</span><span>)]</span>
    <span>InitError</span><span>(</span><span>#[from]</span> <span>InitError</span><span>),</span>
    <span>#[error(transparent)]</span>
    <span>PtraceDumperError</span><span>(</span><span>#[from]</span> <span>PtraceDumperError</span><span>),</span>
    <span>#[error(</span><span>"Failed when writing section AppMemory"</span><span>)]</span>
    <span>SectionAppMemoryError</span><span>(</span><span>#[from]</span> <span>SectionAppMemoryError</span><span>),</span>
    <span>...</span>
</code></pre></div></div>

<p>The fun part is: You have to touch very little of your existing code, thanks to the automatic conversion from one error to the other, conveniently provided by <code>#[from]</code>:</p>
<div><div><pre><code><span>- pub fn init(&amp;mut self) -&gt; Result&lt;()&gt; {
</span><span>+ pub fn init(&amp;mut self) -&gt; Result&lt;(), InitError&gt; {
</span>     self.read_auxv()?;
     self.enumerate_threads()?;
     self.enumerate_mappings()?;
     Ok(())
 }
</code></pre></div></div>

<p>or</p>

<div><div><pre><code><span>- pub fn get_stack_info(&amp;self, int_stack_pointer: usize) -&gt; Result&lt;(usize, usize)&gt; {
</span><span>+ pub fn get_stack_info(&amp;self, int_stack_pointer: usize) -&gt; Result&lt;(usize, usize), DumperError&gt; {
</span> // snip

    let mapping = self
        .find_mapping(stack_pointer)
<span>-        .ok_or("No mapping for stack pointer found")?;
</span><span>+        .ok_or(DumperError::NoStackPointerMapping)?;
</span>    let offset = stack_pointer - mapping.start_address;
    let distance_to_end = mapping.size - offset;
  // snip
</code></pre></div></div>

<p>If you run your test binary again, you now get</p>
<div><div><pre><code>Failed when writing section AppMemory
</code></pre></div></div>
<p>which isâ€¦.<em>(Throws a stack of papers from the desk)</em>â€¦short. Too short, and not that much more helpful, actually. Well, you know which section is failing. Thats good. But where are all the nice error messages you specified in your errors?</p>

<p>Hm, you do only use <code>println!("{}", error);</code>. Maybe <code>{:?}</code> is better?</p>
<div><div><pre><code>SectionAppMemoryError(CopyFromProcessError(PtraceError(Sys(EIO))))
</code></pre></div></div>

<p>Aha! Now you are getting somewhere! Tiny, tiny, painfully <strong>tiny</strong> steps, but you are getting somewhere! No error texts, but at least a chain!</p>

<p>Normal printing doesnâ€™t seem to recursively go through all the wrapped errors, but stop at the top most. For this, you need to either go through all the errors yourself by hand, or use a crate that does this for you. There are a number of them that provide this, but <code>anyhow</code> will do (its by the same author as <code>thiserror</code>, so interoperability shouldnâ€™t be an issue).</p>

<div><div><pre><code>    <span>println!</span><span>(</span><span>"{:#}"</span><span>,</span> <span>anyhow</span><span>::</span><span>Error</span><span>::</span><span>new</span><span>(</span><span>error</span><span>));</span>
</code></pre></div></div>

<p>aaaaand:</p>

<div><div><pre><code>Failed when writing section AppMemory: Failed to copy memory from process: nix::ptrace() error: EIO: I/O error
</code></pre></div></div>

<p><em>Collects papers from the …</em></p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://msirringhaus.github.io/Where-everything-went-wrong/">https://msirringhaus.github.io/Where-everything-went-wrong/</a></em></p>]]>
            </description>
            <link>https://msirringhaus.github.io/Where-everything-went-wrong/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26191006</guid>
            <pubDate>Fri, 19 Feb 2021 08:57:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[12 requests per second: A realistic look at Python web frameworks]]>
            </title>
            <description>
<![CDATA[
Score 473 | Comments 227 (<a href="https://news.ycombinator.com/item?id=26188765">thread link</a>) | @gilad
<br/>
February 18, 2021 | https://suade.org/dev/12-requests-per-second-with-python/ | <a href="https://web.archive.org/web/*/https://suade.org/dev/12-requests-per-second-with-python/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://suade.org/dev/12-requests-per-second-with-python/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26188765</guid>
            <pubDate>Fri, 19 Feb 2021 02:21:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Squad: Forth on Chip-8]]>
            </title>
            <description>
<![CDATA[
Score 69 | Comments 8 (<a href="https://news.ycombinator.com/item?id=26188165">thread link</a>) | @RodgerTheGreat
<br/>
February 18, 2021 | https://internet-janitor.itch.io/squad | <a href="https://web.archive.org/web/*/https://internet-janitor.itch.io/squad">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><h2>Squad</h2>
<p>Squad is a <a href="https://en.wikipedia.org/wiki/Forth_(programming_language)" rel="nofollow noopener">Forth</a> interpreter that runs on the <a href="https://en.wikipedia.org/wiki/CHIP-8" rel="nofollow noopener">SCHIP</a> virtual machine. It extends the 8-bit operations of this host machine to 16 bit "cells", per tradition, which also allows pointers to be easily transported and manipulated on the stacks. The parameter and return stacks have room for 32 cells apiece, and at startup there is a bit over 1kb of free space available for user definitions.</p>
<p>While many niceties are missing from the built-in lexicon, due to space constraints, Squad is a fairly complete Forth environment, with a conventional outer and inner interpreter, immediate words, and a mutable return stack.&nbsp;Squad's functionality compares favorably to&nbsp;<a href="https://github.com/JohnEarnest/chip8Archive/blob/master/src/applejak" rel="nofollow noopener"></a><a href="https://internet-janitor.itch.io/applejak">Applejak</a>&nbsp;and&nbsp;<a href="https://internet-janitor.itch.io/bulb">Bulb</a>.</p>
<p>Dictionary entries consist of a pointer to the previous entry (or 0 for the root entry), a "type" cell (see "&gt;type") which distinguishes immediate words with its high byte and word classes with its low byte, the name of the word as a string (see "&gt;name"), and the body of the word itself (see "&gt;body"). Strings are represented with a custom encoding in which each character is a byte, and strings are null-terminated by the byte 0xFF. Properly-formed characters should be multiples of 5, and represent indices into the following alphabet:</p>
<pre>0123456789abcdefghijklmnopqrstuvwxyz+-&lt;&gt;=!@.,:;[]
</pre>
<p>Source code and other materials are also available on <a href="https://github.com/JohnEarnest/chip8Archive/tree/master/src/squad" rel="nofollow noopener">the CHIP-8 Archive</a>.</p>
<h2>Controls</h2>
<p>The ASWD keys and E are always interchangeable with the arrow keys and space.</p>
<p>The outer interpreter will prompt the user for a token at a time, and then either append it to the current definition or execute it, based on "mode". Whenever text is drawn with an inverted background, it is a pending input. Pressing right-arrow or space will confirm a selection, while the up and down arrows cycle between available options.</p>
<p>First, the outer interpreter will ask the user to choose between several coarse categories- a number ("num"), or one of six categories of word, described in detail below. Numbers are always shown in 16-bit hexadecimal. The up and down arrows will increment or decrement the number, while 2 and X will increment or decrement the the number by 256 at a time, to ease entering pointers and large values. If the user is ever prompted to enter a previously unused word name (see "name"), the entry can be terminated by choosing a space character (which will confirm the name up to but not including the space), or by pressing space (which will confirm the name up to and including the present pending character). Pressing Q while entering a new name will back up one character.</p>
<p>At the top level of the outer interpreter, the user may also press `Z`, which is a shorthand for entering ".s"; it will print the current contents of the parameter stack on a new line without modifying it.</p>
<h2>Simple Examples</h2>
<p>Bump allocator:</p>
<pre>: allot here @ + here ! ;</pre>
<p>Calculate and print some terms of the Fibonacci sequence imperatively:</p>
<pre>: fib  0 1 loop dup . swap over + dup 100 &gt; until ;</pre>
<h2>Vocabulary</h2>
<p>The following word lists include stack effects in parentheses. The names to the left of the "--" sign are the input arguments, bottom to top,&nbsp;and the names to the right are the results, if any, bottom to top.</p>
<h3>IO</h3>
<p>Input and output words. Type code 1.</p>
<ul><li>emit ( char -- ) print a single character to the terminal. The high byte of "char" is ignored.</li><li>space ( -- ) print a space to the terminal.</li><li>cr ( -- ) advance terminal output to a new line.</li><li>erase ( -- ) un-print a single character from the current line of terminal output.</li><li>type ( str -- ) given a string (as described above), print it to the terminal.</li><li>untype ( str -- ) erase a string, by issuing "erase" for each character.</li><li>num ( -- n ) prompt the user to enter a 16-bit number.</li><li>name ( -- ) prompt the user to enter a string for a new word name, appending this string to "here".</li><li>word ( type -- xt ) prompt the user to select the name of an existing word. If "type" is 0, any word. Otherwise, it should be the type code of one of these categories.</li><li>token ( -- x flag ) prompt the user for a token, as in the outer interpreter. If "flag" is 0, "x" is a number. Otherwise it's a dictionary entry ("xt").</li></ul>
<h3>Core</h3>
<p>Fundamental forth primitives. Type code 2.</p>
<ul><li>dup ( x -- x x ) copy the top of the parameter stack.</li><li>drop ( x -- ) discard the top of the parameter stack.</li><li>over ( x y -- x y x ) copy the second item on the parameter stack.</li><li>swap ( x y -- y x ) exchange the top two items on the parameter stack.</li><li>r&gt; ( | x -- x | ) move an item from the parameter stack to the return stack.</li><li>&gt;r ( x | -- | x ) move an item from the return stack to the parameter stack.</li><li>! ( x addr -- ) write a 16-bit value x to "addr".</li><li>c! ( x addr -- ) write an 8-bit value (the low byte of x) to "addr".</li><li>@ ( addr -- x ) read a 16-bit value from addr.</li><li>c@ ( addr -- x ) read an 8-bit value from addr.</li><li>not ( x -- flag ) logically invert the flag x.</li><li>&gt; ( x y -- flag ) is x greater than y?</li><li>&lt; ( x y -- flag ) is x less than y?</li><li>= ( x y -- flag ) is x equal to y?</li><li>xor ( x y -- z ) bitwise XOR of x and y.</li><li>and ( x y -- z ) bitwise AND of x and y.</li><li>or ( x y -- z ) bitwise OR of x and y.</li><li>- ( x y -- z ) difference of x and y.</li><li>+ ( x y -- z ) sum of x and y.</li></ul>
<h3>Mem</h3>
<p>Words concerning working with memory and dictionary entries. Type code 3.</p>
<ul><li>here ( -- addr ) a variable containing the address of the first available cell of memory.</li><li>head ( -- addr ) a variable containing the xt of the most recent dictionary entry.</li><li>mode ( -- addr ) a variable containing 0 during interpretation or 1 during compilation.</li><li>, ( x -- ) write a cell to here, incrementing here by 2.</li><li>,c ( x -- ) write a byte to here, incrementing here by 1.</li><li>,ret ( -- ) append an exit to the current definition. This word performs tail-call elimination if the exit follows a threaded code subroutine call.</li><li>,lit ( x -- ) append a literal (push a number) to the current definition.</li><li>,jump ( addr -- ) append an unconditional branch to threaded code at addr to the current definition.</li><li>,jump0 ( addr -- ) append a conditional branch (branch if top of parameter stack is 0) to threaded code at addr to the current definition.</li><li>,call ( xt -- ) append a subroutine call to the current definition. This word will do the right thing whether the provided xt is a "native" (built-in) or threaded code subroutine.</li><li>&gt;type ( xt -- n ) given a dictionary entry, get its category. High byte is the immediate flag, low byte is the category type code.</li><li>&gt;name ( xt -- str ) given a dictionary entry, get the address of its name (suitable for "type").</li><li>&gt;body ( xt -- addr ) given a dictionary entry, get the address where its body begins.</li><li>create ( -- ) prompt for a name, and create a new dictionary entry with that name.</li><li>exec ( xt -- ) given a dictionary entry, execute the word. interpretation counterpart to ",call".</li></ul>
<h3>Flow</h3>
<p>Immediate words, mostly for dealing with control flow and compilation state. Type code 4.</p>
<ul><li>if ... (else) ... then: basic conditional control structure. if consumes a boolean flag.</li><li>loop ... (again | until | while): basic infinite and conditional loops. until and while consume a boolean flag.</li><li>:imm ( -- )&nbsp;prompt for a new name, and then begin defining an immediate word. Counterpart to ":".</li><li>: &nbsp;( -- )&nbsp;prompt for a new name, and then begin defining an ordinary word.</li><li>; &nbsp;( -- )&nbsp;terminate a word and stop compiling.</li><li>exit ( -- )&nbsp;early return from a word; do not stop compiling.</li><li>[ &nbsp;&nbsp;( -- )&nbsp;switch to interpreting. Use with "]" and ",lit" to pre-evaluate constant expressions, for example.</li><li>] ( --&nbsp;)&nbsp;switch to compiling.</li></ul>
<h3>Env</h3>
<p>Helper words for maintaining and inspecting the Forth environment. Type code 5.</p>
<ul><li>free ( -- x ) how many bytes of memory are available?</li><li>forget ( -- ) prompt for a word name, and destroy that dictionary entry as well as all later definitions. This can really donk up your interpreter if you apply it to internal bits of Squad.</li><li>.s ( -- ) display the contents of the parameter stack without altering it.</li><li>words ( -- ) list all available words.</li></ul>
<h3>User</h3>
<p>"User-defined" (non-primitive) words. Type code 6.</p>
<pre>:    1+     1 +    ; ( x -- y )
:imm quote  0 word ; ( -- xt )</pre>
</div></div>]]>
            </description>
            <link>https://internet-janitor.itch.io/squad</link>
            <guid isPermaLink="false">hacker-news-small-sites-26188165</guid>
            <pubDate>Fri, 19 Feb 2021 01:06:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Texas power outage is a nation-wide problem]]>
            </title>
            <description>
<![CDATA[
Score 290 | Comments 486 (<a href="https://news.ycombinator.com/item?id=26186645">thread link</a>) | @gwoplock
<br/>
February 18, 2021 | https://garrettbattaglia.com/post/texas-power/ | <a href="https://web.archive.org/web/*/https://garrettbattaglia.com/post/texas-power/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div>
        <p>Let me preface this with an explanation. Over the last few days I read online people saying that Texas' power outages had been caused by Texas being on its own grid… deregulation… Not following national standards…  had Texas been connected to the Eastern Interconnection or the Western Interconnection none of this would have happened. But not one post shows any evidence or requirements that backed up these claims. So, I went looking for proof and instead of finding requirements, I found a nationwide problem with winterization. As an aside I am not an expert in the grid or electricity, I am a software developer, and this is my best interpretation of the requirements I could find.</p>
<p>Let’s start off with how the electrical grid works in the US. The grid is made up of 3 interconnections: the Eastern Interconnection, the Western Interconnection, and the Texas Interconnect. Each of these interconnections operate in (near) isolation with their own frequency, voltage, and phase. There are several high voltage DC interconnects (HVDC or DC-DC) between them. In each of these interconnections there is at least one grid operators, for example ERCOT in Texas. These grid operators manage the generation and load of their interconnection, acting as almost as an electric clearing house. They are also responsible for keeping voltage and frequency within range and directing distributors (like ONCOR in north Texas) to shed load during Electrical Emergency Alerts (EEA). An important thing to note for later, from the best I can tell the different grid operators in the Eastern Interconnect share power in a “non-firm, as-available basis”.</p>
<p>What happened in Texas, starting 12:30 AM February 15. The long and short of it is an estimated 34GW of generation went offline in about 2 hours[1]. Looking at ERCOT’s tweets [2,3,4], generation was starting to have an issue at 00:17:45 and some load needed to be shed so ERCOT issued the first EEA (EEA1). In the February EEA tools document[5] EEA1 can open up around 1.6GW of “peeker” generation and importation from the Eastern and Western Interconnections. But by 1:12:06 that wasn’t enough and additional load had to be shed.  A second EEA was issued (EEA2) shedding another 1.6GW. But just a few minutes later the house came crashing down and at 1:25:40 the third EEA (EEA3) was issued. In addition to starting rolling blackouts to shed most of the load it also allowed for other actions to free .1-.2GW of load.</p>
<p>The 34GW of generation lost was from every fuel source used. Most of it was frozen-off natural gas (gas) wells, some of it was frozen wind turbines, solar panels that had snow on them and even a nuclear plant had to go offline due to issues with feedwater pressure sensing issues related to the cold.
What do the North American Electric Reliability Corporation (NERC) standards say about protecting any of these sources? Not much.</p>
<p>Let’s start by looking at the least complex, wind turbines. On September 12, 2012 NERC published a Lesson Learned document in regards to Texas’s issues with some of the wind farms freezing in extreme winter weather[6]. According to the document the event that was predicted over a week beforehand brought 4 days of low temperature, high winds and wind chills, ice and snow that limited the generation facility to just 25% of capacity. The facility did have a SOP for icing conditions that was implemented. However, the facility never defined it’s minimum operating temperature. When lightning knocked out some of the sensing equipment, the turbines had to be stop for safety. The repair crews couldn’t immediately get to the turbines and they had to sit, this gave the oil a chance to cool and partly freeze. When the turbines were returned to service, they tripped back off due to high oil pressure. Eventually after working with the manufacturer they were able to safely heat the oil and restart the turbines. One of the big lessons from this was to install cold weather packs for wind turbines and watch the oil temperature. You’d think that would solve future outage, but no, in 2019 in the midwestwind turbines failed due to exceptionally low temperatures, around -21. Again the cold weather package hadn’t been installed and was one of the root causes of the failure[7].</p>
<p>The nuclear plant’s sensing problems had happened before too. Although it wasn’t a nuclear plant, there are several documented cases on NERC’s website citing cold weather and sensor issues [8,9]. This repeated in Texas (2011) and in the south east (2018)[10].</p>
<p>Let’s discuss natural gas next. It appears that most of the issues in the problematic natural gas fired facilities was due to low gas supplies. In 2012 NERC warned of the interconnectivity of natural gas and electric[11]. Natural gas coming out of the ground has a naturally high water content. This water can freeze the extraction equipment during sub-freezing weather in improperly winterized wells creating what is know as a freeze-off. businesses, residential customers, and powerplants all run off the same supply, once wells start freezing off the supply dwindles for all. Natural gas companies prioritize residential customers as needed and will cut businesses and powerplants. This obviously creates issues in electrical generation.</p>
<p>In this latest case, much of the gas generation loss was due to under pressure conditions at the generation site. When generation sites detect this kind of fault, they are taken offline for safety. Not only is this what happened this year, but it has happened many, many times before</p>
<p>The most resent case I could find was 2018 in the south east[10]. Starting on January 18, 2018 a large area in the south east US experienced unusually cold weather. This caused 183 generation facilities to go offline or operate with greatly reduced output. At the peak there was nearly 30GW of production lost. This caused several grid operators to issue EEAs and begin rolling blackouts. In the “event area” 14% of the failures could be directly attributed to the cold weather. And another 30% could be indirectly linked to weather, including mechanical failures know to happen in cold weather and gas supply issues. NERC found that more than 33% of the failed powerplants didn’t have a winterization plan.</p>
<p>Why didn’t these plants have a winterization plan? Because it wasn’t required[10,12].</p>
<p>This wouldn’t be so bad if this wqs the first time it happened, it wasn’t even the second time it happened. In 2014 a polar vortex hit the US. bringing temperatures well below normal. During this event 55% of the outages were at gas power plants and in all 90GW of generation was lost[13].</p>
<p>The earliest report I could find was from the 2011 winter event in Texas[14]. A very strong cold front hit Texas (and other parts of the south central US) bringing temperatures below freezing for over 4 days and winds over 30 MPH. Leading up to the event, ERCOT and other grid operators in surrounding areas felt that there wouldn’t be a need for rolling blackouts. At the beginning of the event ERCOT had 3.1GW of reserve, nearly 1GW over the minimum required. However, over the next 2 days ERCOT lost nearly 30GW of production in 193 generation facilities. ERCOT was able to stabilize the grid with rolling blackouts and the other EEA methods[5]. Other grids suffered problems as well, EPE (El Paso) and SRP (Arizona) lost nearly 1.4GW due to cold weather. Another issue in ERCOT’s region was nearly 50% of the “black start” facilities were either down for scheduled maintenance or failed on startup. One of the main causes again was the loss of gas during this blackout period. 14.8 Bcf of natural gas production was lost due to freeze-offs, electrical outages (ironically) and customer curtailments. following the previous equivalent storm in 1989, the PUCT (Public Utility Commission of Texas) issued several recommendations and guidelines for winterization of power plants and gas wells. However, due to the infrequency of these storms the implementation lacked. With many of the same facilities that failed in 1989 also failed in 2011.  My guess is these same sites failed again in 2021. Interestingly the NERC found that it is quite possible that gas production in these unusually cold conditions may be impossible.</p>
<p>What has been done since 2011? Not a whole lot. A request for a new standard was issued to NERC in late 2012, however a few months later it was denied.[15] Also in 2012 NERC put out a set of guidelines for developing a plan for winter weather[16]. In 2017 NERC put out a special reliability report on the relationship between gas and electricity[17]. Finally, after the 2018 event NERC received another standard request that was approved[23], however it won’t be finalized until late 2021[18,19,20].</p>
<p>From what I can see, ERCOT has more restrictive rules in their Generator Winter Weatherization Workshop than NERC[21]. All generation stations must have plans for emergencies, address abnormal weather, critical failure points, weather design limits, alternative fuels and testing[21,22]. ERCOT reports that there were 80 spot checks done in the 2019/2020 season with 71 being gas plants and 6 being black start gas plants. 23 had to improve and would be reinspected in early 2021 the rest passed.</p>
<p>The issue of extreme cold weather and electrical outages is a national issue that needs to be addressed. However, after repeated failings it hasn’t really been addressed. Hopefully with the new NERC requirements and the Texas legislature in session progress can be made.</p>
<hr>
<p>[1] <a href="http://www.ercot.com/news/releases/show/225244">http://www.ercot.com/news/releases/show/225244</a><br>
[2] <a href="https://twitter.com/ERCOT_ISO/status/1361197991659503618">https://twitter.com/ERCOT_ISO/status/1361197991659503618</a><br>
[3] <a href="https://twitter.com/ERCOT_ISO/status/1361211669788176384">https://twitter.com/ERCOT_ISO/status/1361211669788176384</a><br>
[4] <a href="https://twitter.com/ERCOT_ISO/status/1361215084010352644">https://twitter.com/ERCOT_ISO/status/1361215084010352644</a><br>
[5] <a href="http://www.ercot.com/content/wcm/lists/219692/EEA_Tools_One_Pager_Winter_2021_2-13-2021.pdf">http://www.ercot.com/content/wcm/lists/219692/EEA_Tools_One_Pager_Winter_2021_2-13-2021.pdf</a><br>
[6] <a href="https://www.nerc.com/pa/rrm/ea/Lessons%20Learned%20Document%20Library/LL20120901_Wind_Farm_Winter_Storm_Issues.pdf">https://www.nerc.com/pa/rrm/ea/Lessons%20Learned%20Document%20Library/LL20120901_Wind_Farm_Winter_Storm_Issues.pdf</a><br>
[7] <a href="https://www.nerc.com/pa/rrm/ea/Lessons%20Learned%20Document%20Library/LL20200601_Unanticipated_Wind_Generation_Cutoffs_during_a_Cold_Weather_Event.pdf">https://w…</a></p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://garrettbattaglia.com/post/texas-power/">https://garrettbattaglia.com/post/texas-power/</a></em></p>]]>
            </description>
            <link>https://garrettbattaglia.com/post/texas-power/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26186645</guid>
            <pubDate>Thu, 18 Feb 2021 22:26:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Gleam 0.14 – Type-safe language for the Erlang VM]]>
            </title>
            <description>
<![CDATA[
Score 275 | Comments 48 (<a href="https://news.ycombinator.com/item?id=26185690">thread link</a>) | @lpil
<br/>
February 18, 2021 | https://gleam.run/news/gleam-v0.14-released/ | <a href="https://web.archive.org/web/*/https://gleam.run/news/gleam-v0.14-released/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
  <div>
<p>Hot on the heels of Gleam v0.13 comes another release, <a href="https://github.com/gleam-lang/gleam/releases/tag/v0.14.0">Gleam v0.14</a>!
As always, let’s take a look at some of the highlights.</p>

<h2 id="dialyzer--erlang-typespecs">Dialyzer &amp; Erlang typespecs</h2>

<p>Many dynamically typed BEAM languages support Erlang’s typespecs, type
annotations that can be analysed with the <a href="https://erlang.org/doc/man/dialyzer.html">Dialyzer</a> tool. While
not as powerful or reliable as Gleam’s type system it can be a useful tool
for finding problems with your Erlang or Elixir code. Dialyzer doesn’t
require typespecs but it can work better if they are added to the code.</p>

<p>Starting with this release Gleam will generate typespecs for all functions
and Erlang type definitions for all declared types within a Gleam program,
giving you one extra tool to help you write robust and reliable code when
using Gleam alongside Elixir or Erlang.</p>

<p>For a quick example, here’s some code in Gleam:</p>

<div><div><pre><code><span>pub</span> <span>type</span> <span>LinkedList</span><span>(</span><span>element</span><span>)</span> <span>{</span>
  <span>Empty</span>
  <span>Node</span><span>(</span><span>element</span><span>,</span> <span>LinkedList</span><span>(</span><span>element</span><span>))</span>
<span>}</span>

<span>pub</span> <span>fn</span> <span>is_empty</span><span>(</span><span>list</span><span>)</span> <span>{</span>
  <span>list</span> <span>==</span> <span>Empty</span>
<span>}</span>

<span>pub</span> <span>fn</span> <span>map</span><span>(</span><span>list</span><span>,</span> <span>fun</span><span>)</span> <span>{</span>
  <span>case</span> <span>list</span> <span>{</span>
    <span>Empty</span> <span>-&gt;</span> <span>Empty</span>
    <span>Node</span><span>(</span><span>i</span><span>,</span> <span>list</span><span>)</span> <span>-&gt;</span> <span>Node</span><span>(</span><span>fun</span><span>(</span><span>i</span><span>),</span> <span>map</span><span>(</span><span>list</span><span>,</span> <span>fun</span><span>))</span>
  <span>}</span>
<span>}</span>
</code></pre></div></div>

<p>And here’s the Erlang code and typespecs it compiles to:</p>

<div><div><pre><code><span>-</span><span>module</span><span>(</span><span>linked_list</span><span>).</span>
<span>-</span><span>compile</span><span>(</span><span>no_auto_import</span><span>).</span>

<span>-</span><span>export</span><span>([</span><span>is_empty</span><span>/</span><span>1</span><span>,</span> <span>map</span><span>/</span><span>2</span><span>]).</span>
<span>-</span><span>export_type</span><span>([</span><span>linked_list</span><span>/</span><span>1</span><span>]).</span>

<span>-</span><span>type</span> <span>linked_list</span><span>(</span><span>H</span><span>)</span> <span>::</span> <span>empty</span> <span>|</span> <span>{</span><span>node</span><span>,</span> <span>H</span><span>,</span> <span>linked_list</span><span>(</span><span>H</span><span>)}.</span>

<span>-</span><span>spec</span> <span>is_empty</span><span>(</span><span>linked_list</span><span>(</span><span>any</span><span>()))</span> <span>-&gt;</span> <span>boolean</span><span>().</span>
<span>is_empty</span><span>(</span><span>List</span><span>)</span> <span>-&gt;</span>
    <span>List</span> <span>=:=</span> <span>empty</span><span>.</span>

<span>-</span><span>spec</span> <span>map</span><span>(</span><span>linked_list</span><span>(</span><span>R</span><span>),</span> <span>fun</span><span>((</span><span>R</span><span>)</span> <span>-&gt;</span> <span>U</span><span>))</span> <span>-&gt;</span> <span>linked_list</span><span>(</span><span>U</span><span>).</span>
<span>map</span><span>(</span><span>List</span><span>,</span> <span>Fun</span><span>)</span> <span>-&gt;</span>
    <span>case</span> <span>List</span> <span>of</span>
        <span>empty</span> <span>-&gt;</span>
            <span>empty</span><span>;</span>

        <span>{</span><span>node</span><span>,</span> <span>I</span><span>,</span> <span>List</span><span>@</span><span>1</span><span>}</span> <span>-&gt;</span>
            <span>{</span><span>node</span><span>,</span> <span>Fun</span><span>(</span><span>I</span><span>),</span> <span>map</span><span>(</span><span>List</span><span>@</span><span>1</span><span>,</span> <span>Fun</span><span>)}</span>
    <span>end</span><span>.</span>
</code></pre></div></div>

<p>No annotations are required at all in your Gleam code to get full typespec
coverage, Gleam’s compiler reuses the type information from its powerful type
inference algorithm to determine the correct typespecs.</p>

<p>Thank you <a href="https://gitlab.com/greggreg">Greg</a> for this brilliant new feature!</p>

<h2 id="erlang-escripts">Erlang escripts</h2>

<p>Erlang projects are unusual in that typically instead of having a <code>main</code>
function as the entrypoint of your application you define a tree of actors to
come online and process items of work while your program is running.</p>

<p>This can be a powerful way to write long-lived services that make use of the
runtime’s fault tolerance features, but it does not lend itself well to
short-lived programs such as command line scripts. It can be confusing to
newcomers from other languages too.</p>

<p>For these short lived programs Erlang <a href="https://erlang.org/doc/man/escript.html">escripts</a> are typically used.
These are lightweight Erlang programs that have a <code>main</code> function as an entrypoint.</p>

<p>To make it easier to use these from Gleam the <code>gleam new</code> command now has an
escript template that can be used to create an escript project without any
further configuration required.</p>

<div><div><pre><code>gleam new my_script <span>--template</span> escript
</code></pre></div></div>

<p>A world class developer experience is a key goal of the Gleam project.
Further tooling improvements are right around the corner!</p>

<h2 id="night-mode">Night mode</h2>

<p>Gleam has the ability to render <a href="https://hexdocs.pm/gleam_stdlib/">HTML documentation</a> 
for your code, ready to upload to Hexdocs.</p>

<p>Thanks to <a href="https://github.com/tynanbe">Tynan Beatty</a> the documentation is
looking better than ever! There’s too many improvements to list but the big
one is they now have a night mode! If you’re a night owl like me I’m sure you
will enjoy the lower contrast dark tones when doing some late evening coding.</p>

<p><img src="https://gleam.run/images/news/gleam-v0.14-released/night-mode.png" alt="A screenshot of Gleam's rendered docs showing a beautiful dark theme"></p>

<h2 id="better-errors-again">Better errors, again</h2>

<p>At the risk of sounding like a broken record Gleam’s error messages have been
improved yet again. Here’s an example of one of the improvements:</p>

<p>Before:</p>

<div><div><pre><code>error: Syntax error
    ┌─ /src/thing.gleam:115:18
    │
115 │ pub fn overlappedBy(compare, a, b) -&gt; Bool {
    │                  ^^ I was not expecting this.

Expected one of: "("
</code></pre></div></div>

<p>Now:</p>

<div><div><pre><code>error: Syntax error
    ┌─ /src/thing.gleam:115:18
    │
115 │ pub fn overlappedBy(compare, a, b) -&gt; Bool {
    │                  ^^ This is not a valid name.

Hint: Names start with a lowercase letter and contain a-z, 0-9, or _.
Try: overlapped_by
</code></pre></div></div>

<p>Thank you to <a href="https://github.com/samontea">Samuel Mercier</a> and <a href="https://github.com/pd-andy">Andy
Thompson</a> for these.</p>

<h2 id="static-bit-string-validation">Static bit string validation</h2>

<p>Bit string syntax is a feature that Gleam inherits from Erlang. It provides a
way to declartively and concisely construct and manipulate raw bits of data
through literals and pattern matching.</p>

<p>With this Gleam release we apply further static analysis to bit string
literals and patterns used in Gleam programs to catch invalid or incorrect
code.</p>

<p>Here’s an example of one of the errors that may be reported:</p>

<div><div><pre><code>error: Syntax error
  ┌─ /Users/a/parser_test/src/a.gleam:2:20
  │
2 │   &lt;&lt;1:size(1)-unit(0)&gt;&gt;
  │                    ^ This is not a valid BitString unit value.

Hint: unit must be an integer literal &gt;= 1 and &lt;= 256
See: https://gleam.run/book/tour/bit-strings
</code></pre></div></div>

<p>Thank you <a href="https://gitlab.com/greggreg">Greg</a> for this bit string safety net.</p>

<h2 id="docker-images">Docker images</h2>

<p>Up until now <a href="https://github.com/CrowdHailer">Peter Saxton</a> has been very kindly
building Gleam docker images for use in <a href="https://sendmemo.app/">Memo</a> and the
wider community.</p>

<p>With this release he has ported his build automation over to the Gleam repo
so we have automation creation of OCI/Docker images built and published
automatically with each release.</p>

<p>We are building these variants:</p>

<ul>
  <li><code>gleam-erlang</code>: Gleam and the Erlang tooling on Ubuntu Linux</li>
  <li><code>gleam-erlang-slim</code>: Gleam and the Erlang tooling on slim Debian Linux</li>
  <li><code>gleam-erlang-alpine</code>: Gleam and the Erlang tooling on Alpine Linux</li>
  <li><code>gleam-elixir</code>: Gleam and the Elixir tooling on Ubuntu Linux</li>
  <li><code>gleam-elixir-slim</code>: Gleam and the Elixir tooling on slim Debian Linux</li>
  <li><code>gleam-elixir-alpine</code>: Gleam and the Elixir tooling on Alpine Linux</li>
</ul>

<p>For all the images see the <a href="https://github.com/orgs/gleam-lang/packages/container/package/gleam">Gleam image registry</a>. Thanks Peter!</p>

<h2 id="other-stuff">Other stuff</h2>

<p>These are just some of the highlights, but there’s plenty more improvements
made to the compiler and the standard library since the last release. For all
the details check out the changelog files:</p>

<ul>
  <li><a href="https://github.com/gleam-lang/gleam/blob/main/CHANGELOG.md">Gleam’s changelog</a></li>
  <li><a href="https://github.com/gleam-lang/stdlib/blob/main/CHANGELOG.md">Gleam stdlib’s changelog</a></li>
</ul>

<h2 id="discord-chat">Discord chat</h2>

<p>It’s time to plug the Gleam Discord server again! The community continues to
grow and it would be great to have you there too, so please click on the
button below.</p>

<center>
  <a href="https://discord.gg/Fm8Pwmy"><img src="https://img.shields.io/discord/768594524158427167?color=blue" alt="Discord chat"></a>
</center>

<h2 id="try-it-out">Try it out</h2>

<p>If you want to try out the new version of Gleam head over to the <a href="https://gleam.run/getting-started/">getting started
page</a>. I’d love to hear how you find it and get your feedback so
Gleam can continue to improve.</p>

<p>Want to view some existing Gleam projects? Head on over to the
<a href="https://github.com/gleam-lang/awesome-gleam">awesome-gleam</a> list. Looking for something to build in
Gleam? Check out <a href="https://github.com/gleam-lang/suggestions/issues">the suggestions tracker</a>.</p>

<h2 id="supporting-gleam">Supporting Gleam</h2>

<p>If you would like to help make strongly typed programming on the Erlang
virtual machine a production-ready reality please consider <strong><a href="https://github.com/sponsors/lpil">sponsoring
Gleam</a></strong> via the GitHub Sponsors program.</p>

<p>⭐ Or alternatively give us a star on <a href="https://github.com/gleam-lang/gleam">GitHub</a>! ⭐</p>

<p>This release would not have been possible without the support of all the
people who have <a href="https://github.com/sponsors/lpil">sponsored</a> and contributed
to it, so a huge thank you to them.</p>

<ul>
  <li><a href="https://github.com/adamnbowen">Adam Bowen</a></li>
  <li><a href="https://github.com/amokan">Adam Mokan</a></li>
  <li><a href="https://github.com/aditya7iyengar">Adi Iyengar</a></li>
  <li><a href="https://github.com/scripttease">Al Dee</a></li>
  <li><a href="https://github.com/mudriyjo">Alexander Babin</a></li>
  <li><a href="https://github.com/farhadi">Ali Farhadi</a></li>
  <li><a href="https://github.com/pd-andy">Andy Thompson</a></li>
  <li><a href="https://github.com/bees">Arian Daneshvar</a></li>
  <li><a href="https://github.com/arnodirlam">Arno Dirlam</a></li>
  <li><a href="https://github.com/benmyles">Ben Myles</a></li>
  <li><a href="https://github.com/nono">Bruno Michel</a></li>
  <li><a href="https://github.com/brightly-salty">Caden Haustein</a></li>
  <li><a href="https://github.com/choonkeat">Chew Choon Keat</a></li>
  <li><a href="https://github.com/chrislloyd">Chris Lloyd</a></li>
  <li><a href="https://github.com/worldofchris">Chris Young</a></li>
  <li><a href="https://github.com/tlvenn">Christian Meunier</a></li>
  <li><a href="https://github.com/clangley">clangley</a></li>
  <li><a href="https://github.com/cleverbunny">Clever Bunny LTD</a></li>
  <li><a href="https://github.com/codec-abc">codec-abc</a></li>
  <li><a href="https://github.com/colelawrence">Cole Lawrence</a></li>
  <li><a href="https://github.com/connorlay">Connor Lay (Clay)</a></li>
  <li><a href="https://github.com/cschembor3">Connor Schembor</a></li>
  <li><a href="https://github.com/unthought">Dan Mueller</a></li>
  <li><a href="https://github.com/davydog187">Dave Lucia</a></li>
  <li><a href="https://github.com/rawkode">David McKay</a></li>
  <li><a href="https://github.com/davidpdrsn">David Pedersen</a></li>
  <li><a href="https://github.com/dangdennis">Dennis Dang</a></li>
  <li><a href="https://github.com/lostbean">Edgar Gomes</a></li>
  <li><a href="https://github.com/ericmj">Eric Meadows-Jönsson</a></li>
  <li><a href="https://github.com/eterps">Erik Terpstra</a></li>
  <li><a href="https://github.com/floriank">Florian Kraft</a></li>
  <li><a href="https://github.com/itsgreggreg">greggreg</a></li>
  <li><a href="https://github.com/ggpasqualino">Guilherme Pasqualino</a></li>
  <li><a href="https://github.com/hendi">Hendrik Richter</a></li>
  <li><a href="https://github.com/hhandoko">Herdy Handoko</a></li>
  <li><a href="https://github.com/human154">human154</a></li>
  <li><a href="https://github.com/Ian-GL">Ian González</a></li>
  <li><a href="https://github.com/igagen">Ingmar Gagen</a></li>
  <li><a href="https://github.com/ivarvong">Ivar Vong</a></li>
  <li><a href="https://github.com/gampleman">Jakub Hampl</a></li>
  <li><a href="https://github.com/jamesmacaulay">James MacAulay</a></li>
  <li><a href="https://github.com/janpieper">Jan Pieper</a></li>
  <li><a href="https://github.com/jechol">Jechol Lee</a></li>
  <li><a href="https://github.com/jeffkreeftmeijer">Jeff Kreeftmeijer</a></li>
  <li><a href="https://github.com/jiangplus">jiangplus</a></li>
  <li><a href="https://github.com/joecorkerton">Joe Corkerton</a></li>
  <li><a href="https://github.com/Jwsonic">John Palgut</a></li>
  <li><a href="https://github.com/josevalim">José Valim</a></li>
  <li><a href="https://github.com/jveiga">João Veiga</a></li>
  <li><a href="https://github.com/jmn">Jussi Norlund</a></li>
  <li><a href="https://github.com/kapp-technology">Kapp Technology</a></li>
  <li><a href="https://github.com/kodeFant">Lars Lillo Ulvestad</a></li>
  <li><a href="https://github.com/lawik">Lars Wikman</a></li>
  <li><a href="https://github.com/leandrocp">Leandro Cesquini Pereira</a></li>
  <li><a href="https://github.com/malcolmseyd">Malcolm Seyd</a></li>
  <li><a href="https://github.com/mario-mazo">mario</a></li>
  <li><a href="https://github.com/mvellandi">Mario Vellandi</a></li>
  <li><a href="https://github.com/markmark206">Mark Markaryan</a></li>
  <li><a href="https://github.com/markusfeyh">Markus</a></li>
  <li><a href="https://github.com/derhechi">Markus Hechenberger</a></li>
  <li><a href="https://github.com/MattCheely">Matthew Cheely</a></li>
  <li><a href="https://github.com/bausano">Michael Bausano</a></li>
  <li><a href="https://github.com/michaeljones">Michael Jones</a></li>
  <li><a href="https://github.com/michallepicki">Michał Łępicki</a></li>
  <li><a href="https://github.com/mroach">Mike Roach</a></li>
  <li><a href="https://github.com/slashmili">Milad</a></li>
  <li><a href="https://github.com/ndreynolds">Nick Reynolds</a></li>
  <li><a href="http://www.ninefx.com/">NineFX</a></li>
  <li><a href="https://github.com/jraregris">Oddmund Strømme</a></li>
  <li><a href="https://github.com/sorentwo">Parker Selbert</a></li>
  <li><a href="https://github.com/phiat">Patrick Ryan</a></li>
  <li><a href="https://github.com/PeteJodo">Pete Jodo</a></li>
  <li><a href="https://github.com/CrowdHailer">Peter Saxton</a></li>
  <li><a href="https://github.com/praveenperera">Praveen Perera</a></li>
  <li><a href="https://github.com/qingliangcn">qingliangcn</a></li>
  <li><a href="https://github.com/happysalada">Raphael Megzari</a></li>
  <li><a href="https://github.com/chouzar">Raúl  Humberto Chouza Delgado</a></li>
  <li><a href="https://github.com/redmar">Redmar Kerkhoff</a></li>
  <li><a href="https://github.com/reneklacan">René Klačan</a></li>
  <li><a href="https://github.com/romatthe">Robin Mattheussen</a></li>
  <li><a href="https://github.com/rvcas">rvcas</a></li>
  <li><a href="https://github.com/samaaron">Sam Aaron</a></li>
  <li><a href="https://github.com/samontea">samontea</a></li>
  <li><a href="https://github.com/mrgleam">Santi</a></li>
  <li><a href="https://github.com/sascha-wolf">Sascha Wolf</a></li>
  <li><a href="https://github.com/sasa1977">Saša Jurićç</a></li>
  <li><a href="https://github.com/scottwey">Scott Wey</a></li>
  <li><a href="https://github.com/seanjensengrey">Sean Jensen-Grey</a></li>
  <li><a href="https://github.com/sporto">Sebastian</a></li>
  <li><a href="https://github.com/shanesveller">Shane Sveller</a></li>
  <li><a href="https://github.com/shritesh">Shritesh Bhattarai</a></li>
  <li><a href="https://github.com/simonewebdesign">Simone Vittori</a></li>
  <li><a href="https://github.com/syukronrm">Syukron Rifail M</a></li>
  <li><a href="https://github.com/terkiterje">Terje Bakken</a></li>
  <li><a href="https://github.com/timbuchwaldt">Tim Buchwaldt</a></li>
  <li><a href="https://github.com/tomekowal">Tomasz Kowal</a></li>
  <li><a href="https://github.com/thara">Tomochika Hara</a></li>
  <li><a href="https://github.com/topherhunt">Topher Hunt</a></li>
  <li><a href="https://github.com/tsloughter">Tristan Sloughter</a></li>
  <li><a href="https://github.com/twilco">Tyler Wilcock</a></li>
  <li><a href="https://github.com/tynanbe">tynanbe</a></li>
  <li><a href="https://github.com/wojtekmach">Wojtek Mach</a></li>
</ul>

<p>Thanks for reading! Have fun! 💜</p>

</div>

</article></div>]]>
            </description>
            <link>https://gleam.run/news/gleam-v0.14-released/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26185690</guid>
            <pubDate>Thu, 18 Feb 2021 21:16:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Series A to Revolutionize Computing]]>
            </title>
            <description>
<![CDATA[
Score 22 | Comments 5 (<a href="https://news.ycombinator.com/item?id=26184594">thread link</a>) | @tosh
<br/>
February 18, 2021 | https://blog.repl.it/seriesa | <a href="https://web.archive.org/web/*/https://blog.repl.it/seriesa">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		<p>Our mission is to give everyone in the world <strong>computer superpowers</strong>. We build powerful yet approachable tools &amp; platforms for developers, students, and educators.</p>
<p>We see a new generation of hackers and entrepreneurs rising to seize the power of computers and the internet to create software that empowers them and their communities. They refuse to be programmed by the software priesthood that wants them to endlessly consume ads. Instead, they build a more free society where computers work for and under human users, not the other way around. The world we're describing is coming, and we exist to accelerate the shift. <a href="https://repl.it/careers">Join us</a>! </p>
<p><img src="https://repl.art/replit.png" alt="art"></p>
<p>Replit is a multiplayer computing environment that makes it <a href="https://blog.replit.com/internet-of-fun">fun</a> to learn how to code, build, and <a href="https://repl.it/talk/share">share apps</a> with other people. You can create a cloud-powered computer in milliseconds -- we call them "repls" -- and you can create as many of them as you'd like, all for free. Repls come with storage for your code and files, a <a href="https://blog.repl.it/database">database</a> for your data, and a <a href="https://repl.it/site/multiplayer">multiplayer editor</a> &amp; console to code with your friends. For <a href="https://repl.it/pricing">$7/month</a>, you'll get more powerful machines and, with one-click, make them <a href="https://blog.repl.it/alwayson">run forever</a>.</p>
<p><img src="https://blog.repl.it/images/database/database1.gif" alt="db"></p>
<p>When you invite a friend to your repl, you can see them in your editor and talk to them <a href="https://blog.repl.it/annotations-for-education">right in your code</a>. You can make <a href="https://docs.repl.it/repls/http-servers">web</a>, <a href="https://blog.repl.it/native-graphics-love">desktop</a>, and even command-line apps. Replit takes care of the entire process of <a href="https://docs.repl.it/repls/web-hosting">publishing and hosting apps</a> so you can focus on your ideas.</p>
<p><img src="https://venturebeat.com/wp-content/uploads/2021/02/Live-Code-Editing.gif?resize=800%2C450&amp;strip=all" alt="multiplayer"></p>
<p>When you've built something you want to share, you can share the <a href="https://blog.replit.com/spotlight">repl URL</a>, and your users can play with your app, react to it, comment on it, and even fork and remix it. Replit gives you a profile to keep and showcase all your apps and repls. You can make <a href="https://repl.it/site/teams">shared team profiles</a> for your class, friends, or company to collaborate on repls.</p>
<p><img src="https://blog.repl.it/images/spotlight/ios-demo.gif" alt="share"></p>
<p>Because you can make a repl in milliseconds, Replit makes it fun and safe to experiment with ideas. Learning comes naturally as a side effect of playing in the Replit ecosystem.</p>
<p>Millions of people have learned how to code with Replit and built great apps with thousands of happy users. Some have even built businesses and become rich &amp; famous.</p>
<p>Replit's design principles:</p>
<ul>
<li><p><strong>Learnable yet scalable interfaces</strong>: Interfaces today present the same UI to vastly different users, from children to adults, from novices to experts. Our mission demands that we make computing environments more accessible to novices while making it possible to transition to more powerful interfaces. Replit starts with a simple editor and console, which gets learners very far. The UI, however, is adaptable and presents different faces to different users and use-cases.</p>
</li>
<li><p><strong>Infrastructure as legos</strong>: A core part of commanding computer power is to be able to build for the modern internet-connected world. Despite progress in cloud computing, infrastructure remains inaccessible to novices, hobbyists, and educators. We change this by designing simple and scalable components, like cloud-hosted servers accessible right from the repl, storage, databases, etc., that require little configuration and maintenance by the programmer. Coders can then mix and match components to create endless possibilities.</p>
</li>
<li><p><strong>People-centric technology</strong>: It's more exciting and fun to create and learn with other people. The future demands that computers and the internet have human interconnectedness as a core primitive. From our multiplayer computing protocol to our community spaces for sharing software, we build support for human beings, and we put collaboration right at the heart of our technology.</p>
</li>
</ul>
<h2 id="series-a">Series A</h2>
<p>As a team, we've always thought about the long-term, and we've grown Replit responsibly. We have so much conviction in our mission and our plan that we're willing to take our time. </p>
<p>Last year, with rapid growth in all aspects of our business, we felt it was a good time to raise a sizeable round to make faster progress our mission. We raised <a href="https://venturebeat.com/2021/02/18/replit-raises-20-million-for-collaborative-browser-based-coding/">$20M in Series A</a> financing led by <a href="https://acapital.com/">A.Capital</a> with strong participation from our seed investors: Andreessen Horowitz, Bloomberg Beta, Y Combinator, and Reach Capital. </p>
<p>Since then, thanks to the new capital and to <a href="https://amasad.me/moad">Engelbartian Bootstrapping</a>, we've accelerated feature development, and there's so much more on the horizon: extra resources for more complex projects, support for any language or package, further dev ops simplifications for novices and pros, business collaboration features, improvements to <a href="https://repl.it/teams-for-education">teacher workflows</a>, high quality content, a game development library, and more breakthroughs in collaborative coding. We're excited to see all the amazing things you build with the tools we provide!</p>
<p>Finally, we're hiring for multiple roles and want to bring on people who share our vision and passion. If you're interested in making computing more accessible while working with a creative and hardworking team building fantastic technology, <a href="https://repl.it/careers">join us</a>!</p>

	</div></div>]]>
            </description>
            <link>https://blog.repl.it/seriesa</link>
            <guid isPermaLink="false">hacker-news-small-sites-26184594</guid>
            <pubDate>Thu, 18 Feb 2021 19:53:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Scala 3.0.0-RC1 – first release candidate is here]]>
            </title>
            <description>
<![CDATA[
Score 23 | Comments 7 (<a href="https://news.ycombinator.com/item?id=26184110">thread link</a>) | @tmfi
<br/>
February 18, 2021 | https://dotty.epfl.ch/blog/2021/02/17/scala3-rc1.html | <a href="https://web.archive.org/web/*/https://dotty.epfl.ch/blog/2021/02/17/scala3-rc1.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content-wrapper"> 
   <main> 
    <header> 
      
      
    </header> 
    <p>Greetings from the Scala 3 team! We are delighted to announce the first release candidate of the stable version of Scala 3 – Scala 3.0.0-RC1.</p> 
    <p>This release brings some last-minute polishings, clean-ups and changes before the big release. There were a few language changes to improve the user experience, as well as the polishings of the metaprogramming framework. We have also worked on the issues that had to be fixed before the stable release.</p> 
    <p>Overall, more than <a href="https://github.com/lampepfl/dotty/pulls?q=is%3Apr+is%3Aclosed+closed%3A%3E2020-12-02+sort%3Acomments-desc">400 PRs</a> were merged after the M3 release and until today! Read more below!</p> <!--more--> 
     
    <p>Type parameters on extensions can now be combined with type parameters on the methods themselves. E.g.:</p> 
    <pre><code>List(1, 2, 3).second[Int]
extension [A](xs: List[A])
   def sumBy[B](f: A =&gt; B)(using Numeric[B]): B = ...
</code></pre> 
    <p>Type arguments matching method type parameters are passed as usual:</p> 
    <pre><code>List("a", "bb", "ccc").sumBy[Int](_.length)
</code></pre> 
    <p>By contrast, type arguments matching type parameters following <code>extension</code> can be passed only if the method is referenced as a non-extension method:</p> 
    <pre><code>sumBy[String](List("a", "bb", "ccc"))(_.length)
</code></pre> 
    <p>Or, when passing both type arguments:</p> 
    <pre><code>sumBy[String](List("a", "bb", "ccc"))[Int](_.length)
</code></pre> 
    <p>For discussion, see <a href="https://github.com/lampepfl/dotty/pull/10940">PR #10940</a>. For more information about the extension methods, see <a href="https://dotty.epfl.ch/docs/reference/contextual/extension-methods.html">documentation</a>.</p> 
     
    <p>The following are the changes to the <code>import</code> syntax made in this release.</p> 
    <p>Wildcard import <code>_</code> is replaced by <code>*</code>. The motivation is that the majority of other languages use <code>*</code>. For example:</p> 
    <pre><code>import scala.annotation.*  // imports everything in the annotation package
</code></pre> 
    <p>Renaming operator <code>=&gt;</code> is replaced by a soft keyword <code>as</code>. <code>as</code> is also allowed outside braces. For example:</p> 
    <pre><code>import scala.collection.mutable as mut
import NumPy as np
</code></pre> 
    <p>For the details and discussion, see <a href="https://github.com/lampepfl/dotty/pull/11244">PR #11244</a>. Read more about this change in the <a href="https://dotty.epfl.ch/docs/reference/changed-features/imports.html">documentation</a>.</p> 
     
    <p><a href="https://github.com/lampepfl/dotty/pull/11240">PR #11240</a> changed the syntax of vararg splices in patterns and function arguments. The new syntax uses a postfix <code>*</code>, instead of <code>: _*</code>, analogously to how a vararg parameter is declared.</p> 
     
    <p>An obscure use of <code>_</code> occurs in var definitions:</p> 
    <pre><code>var x: T = _
</code></pre> 
    <p>It defines a concrete variable x without an initial value, or rather the default initial value that the JVM assigns to object fields. It can only be used in a class or object, not to initialize a local variable.</p> 
    <p>We came up with an arguably better way to express this idiom: the special <code>uninitialized</code> value in the <code>scala.compiletime</code> object. To get an uninitialized field, you now write:</p> 
    <pre><code>import scala.compiletime.uninitialized

var x: A = uninitialized
</code></pre> 
    <p>This way expresses the intent of the idiom in a more verbose and easy to read way than simply writing an underscore.</p> 
    <p>For discussion, see <a href="https://github.com/lampepfl/dotty/pull/11231">PR #11231</a>, and the <a href="https://dotty.epfl.ch/docs/reference/dropped-features/wildcard-init.html">documentation</a> is available on our website.</p> 
     
    <p>Starting from RC1, we no longer generate a function parent for companions of case classes. Which means, for example, that given <code>case class Foo(x: Int)</code>, you won't be able to use <code>Foo</code> in a position where a function is expected:</p> 
    <pre><code>case class Foo(x: Int)
def f(g: Int =&gt; Foo) = g(10)

f(Foo)
</code></pre> 
    <p>Results in:</p> 
    <pre><code>1 |f(Foo)
  |  ^^^
  |The method `apply` is inserted. The auto insertion will be deprecated, please write `Foo.apply` explicitly.
</code></pre> 
    <p>As the warning suggests, now you should write <code>Foo.apply</code> instead of <code>Foo</code>. See <a href="https://github.com/lampepfl/dotty/issues/6190">Issue #6190</a> and <a href="https://github.com/lampepfl/dotty/pull/7207">PR #7207</a> for discussion.</p> 
     
    <p>We have settled on using the well-known <code>scaladoc</code> as a name for the documentation tool for Scala 3 (known previously as <code>scala3doc</code>).. The obsolete <code>dotty-doc</code> (or <code>scala3-doc</code>) is removed in RC1. We have also removed all the Kotlin dependencies (Dokka, etc.) from scaladoc. For details, see <a href="https://github.com/lampepfl/dotty/pull/11349">PR #11349</a>. To read more about <code>scaladoc</code>, see <a href="https://dotty.epfl.ch/docs/usage/scaladoc/index.html">documentation</a></p> 
     
    <p><a href="https://github.com/lampepfl/dotty/pull/11355">PR #11355</a> changes the <code>-source</code> specifier for the Scala version(s) after 3.0 from <code>3.1</code> to <code>future</code>. I.e. it is now <code>-source future</code> and <code>-source future-migration</code> instead of <code>-source 3.1</code> and <code>-source 3.1-migration</code>. Language imports are changed analogously. The reason for the change is that we want to keep the possibility open to ship a <code>3.1</code> version that does not yet contain all the changes enabled under <code>-source future</code>.</p> 
     
    <ul> 
     <li>Warn when matching against an opaque type <a href="https://github.com/lampepfl/dotty/pull/10664">#10664</a></li> 
     <li>Fix <a href="https://github.com/lampepfl/dotty/issues/8634">#8634</a>: Support -release option <a href="https://github.com/lampepfl/dotty/pull/10746">#10746</a> – the same way Scala 2 does. This setting allows you to specify a version of the Java platform (8, 9 etc) and compile the code with classes specific to the that Java platform, and emit the bytecode for that version.</li> 
    </ul> 
     
    <p>A lot of work has been done on the metaprogramming side of things. Mostly we are cleaning up and polishing the API to prepare it for the stable release. The following are the important metaprogramming changes that took place:</p> 
    <ul> 
     <li>Add <code>scala.quoted.Expr.unapply</code> as dual of <code>Expr.apply</code> <a href="https://github.com/lampepfl/dotty/pull/10580">#10580</a></li> 
     <li>Remove <code>Expr.StringContext.unapply</code> <a href="https://github.com/lampepfl/dotty/pull/10675">#10675</a></li> 
     <li>Add reflect <code>MatchCase</code> <code>TypeRepr</code> <a href="https://github.com/lampepfl/dotty/pull/10735">#10735</a></li> 
     <li>Rename <code>scala.quoted.staging.{Toolbox =&gt; Compiler}</code> <a href="https://github.com/lampepfl/dotty/pull/11129">#11129</a></li> 
     <li>Fix <a href="https://github.com/lampepfl/dotty/issues/10863">#10863</a>: Make show <code>AnyKind</code>ed <a href="https://github.com/lampepfl/dotty/pull/10988">#10988</a></li> 
     <li>Add ParamClause to allow multiple type param clauses <a href="https://github.com/lampepfl/dotty/pull/11074">#11074</a></li> 
     <li>Rework reflect Symbol fields API <a href="https://github.com/lampepfl/dotty/pull/10705">#10705</a></li> 
     <li>Rename <code>Liftable</code> to <code>ToExpr</code> and <code>Unliftable</code> to <code>FromExpr</code> <a href="https://github.com/lampepfl/dotty/pull/10618">#10618</a></li> 
     <li>Expand non-transparent macros after Typer <a href="https://github.com/lampepfl/dotty/pull/9984">#9984</a></li> 
     <li>Rework TastyInspector API to allow inspection of all files <a href="https://github.com/lampepfl/dotty/pull/10792">#10792</a></li> 
     <li>Allow leading context parameters in extension methods <a href="https://github.com/lampepfl/dotty/pull/10940">#10940</a></li> 
     <li>Rename <code>Not</code> to <code>NotGiven</code> to make its purpose clearer <a href="https://github.com/lampepfl/dotty/pull/10720">#10720</a></li> 
     <li>Fix <a href="https://github.com/lampepfl/dotty/issues/10709">#10709</a>: Add missing level check before inlining <a href="https://github.com/lampepfl/dotty/pull/10781">#10781</a></li> 
    </ul> 
     
    <p>If you have questions or any sort of feedback, feel free to send us a message on our <a href="https://gitter.im/lampepfl/dotty">Gitter channel</a>. If you encounter a bug, please <a href="https://github.com/lampepfl/dotty/issues/new">open an issue on GitHub</a>.</p> 
    <h2><a href="#contributors" id="contributors"></a>Contributors</h2> 
    <p>Thank you to all the contributors who made this release possible 🎉</p> 
    <p>According to <code>git shortlog -sn --no-merges 3.0.0-M3..3.0.0-RC1</code> these are:</p> 
    <pre><code>   183  Martin Odersky
   138  Nicolas Stucki
    36  Krzysztof Romanowski
    25  Filip Zybała
    25  Liu Fengyun
    24  Lan, Jian
    22  Jamie Thompson
    19  Tom Grigg
    17  Andrzej Ratajczak
    16  Stéphane Micheloud
    15  Guillaume Martres
    11  Paweł Marks
     9  Phil
     6  Aleksander Boruch-Gruszecki
     6  Jonathan Brachthäuser
     6  Natsu Kagami
     6  odersky
     4  Jasper Moeys
     4  Adrien Piquerez
     3  Sébastien Doeraene
     3  Michał Pałka
     3  Albert Chen
     2  Alexandre Archambault
     2  Som Snytt
     2  kenji yoshida
     2  Luc Henninger
     2  Ayush
     2  Raphael Jolly
     2  Anatolii Kmetiuk
     2  Olivier Blanvillain
     2  changvvb
     1  ysthakur
     1  Ang Hao Yang
     1  Ang9876
     1  AngAng
     1  August Nagro
     1  Ciara O'Brien
     1  Dale Wijnand
     1  Florian Cassayre
     1  Florian Schmaus
     1  Iltotore
     1  Jason Zaugg
     1  Julien Richard-Foy
     1  Katrix
     1  Master-Killer
     1  Michael Pilquist
     1  Mikael Blomstrand
     1  Mike Samuel
     1  Philippus
     1  Philippus Baalman
     1  Rick M
     1  Stephane MICHELOUD
     1  Timur Abishev
     1  Tomas
     1  ansvonwa
     1  ayush
     1  costa100
     1  iroha168
     1  noti0na1
     1  riiswa
     1  tanishiking
</code></pre> 
    <p>If you want to get your hands dirty and contribute to Scala 3, now is a good time to get involved! Head to our <a href="https://dotty.epfl.ch/docs/contributing/getting-started.html">Getting Started page for new contributors</a>, and have a look at some of the <a href="https://github.com/lampepfl/dotty/issues?q=is%3Aissue+is%3Aopen+label%3Aexp%3Anovice">good first issues</a>. They make perfect entry points into hacking on the compiler.</p> 
    <p>We are looking forward to having you join the team of contributors.</p> 
    <hr> 
    <p><img id="author-img" src="https://dotty.epfl.ch/images/anatolii.png"> <span id="author-signature"> Anatolii Kmetiuk </span> 
    </p> 
   </main> 
  </div></div>]]>
            </description>
            <link>https://dotty.epfl.ch/blog/2021/02/17/scala3-rc1.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26184110</guid>
            <pubDate>Thu, 18 Feb 2021 19:09:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[GPT-3, Esq? Evaluating AI Legal Summaries [pdf]]]>
            </title>
            <description>
<![CDATA[
Score 50 | Comments 39 (<a href="https://news.ycombinator.com/item?id=26183114">thread link</a>) | @gavelin
<br/>
February 18, 2021 | http://www.davidvictorrodriguez.com/uploads/2/6/4/2/26420847/gpt-3_esq_-_evaluating_ai_legal_summaries.pdf | <a href="https://web.archive.org/web/*/http://www.davidvictorrodriguez.com/uploads/2/6/4/2/26420847/gpt-3_esq_-_evaluating_ai_legal_summaries.pdf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>http://www.davidvictorrodriguez.com/uploads/2/6/4/2/26420847/gpt-3_esq_-_evaluating_ai_legal_summaries.pdf</link>
            <guid isPermaLink="false">hacker-news-small-sites-26183114</guid>
            <pubDate>Thu, 18 Feb 2021 17:53:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Ruby Garbage Collection Deep Dive: Tri-Color Mark and Sweep]]>
            </title>
            <description>
<![CDATA[
Score 137 | Comments 15 (<a href="https://news.ycombinator.com/item?id=26182796">thread link</a>) | @mooreds
<br/>
February 18, 2021 | https://jemma.dev/blog/gc-mark-and-sweep | <a href="https://web.archive.org/web/*/https://jemma.dev/blog/gc-mark-and-sweep">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p>In the <a href="https://jemma.dev/blog/gc-internal">first post</a> in the Ruby Garbage Collection Deep Dive series, we went through a few definitions to give us a picture of how Ruby stores values in memory. If you haven’t read it yet, <a href="https://jemma.dev/blog/gc-internal">read it first</a>! We’ll build on those definitions in this post. Particularly, we’ll talk more about the Ruby Heap, Pages, Slots and RVALUES.</p>

<p>Okay, now that we have those baseline definitions out of the way, this post is going to explain the algorithm Ruby’s garbage collector uses to determine which objects it can collect: the Tri-Color Mark and Sweep algorithm. There are two phases to this algorithm. You guessed it: marking and sweeping. In the marking phase, the garbage collector marks all slots which contain accessible RVALUES. In the sweeping phase, the garbage collector clears the RVALUES out of all slots which are not marked. Let’s dig in!</p>

<h2 id="tri-color-mark-and-sweep">Tri-Color Mark and Sweep</h2>

<h3 id="marking">Marking</h3>

<p>We’ll start off by discussing the marking phase. This is most straightforward to understand if we imagine the <a href="https://ruby-doc.org/core-3.0.0/ObjectSpace.html">Ruby ObjectSpace</a> to be a directed graph with root nodes. All of the nodes in the graphs are RVALUES. All of the edges in the graph are references from one RVALUE to another.</p>

<p>Ruby’s garbage collector starts at the root nodes and traces every edge it can access from these root nodes, marking every RVALUE it sees through this process. At the end, any RVALUE which was not traced, and therefore not accessible from a root RVALUE will be garbage collected.</p>

<h4 id="tri-color">Tri-Color</h4>

<p>Okay, but the algorithm Ruby uses for garbage collection is called a Tri-Color Mark and Sweep algorithm, so what’s the Tri-Color part all about? The Tri-Color algorithm is a model we can use to understand what Ruby’s garbage collector is doing, and how tracks its progress. The three colors in the Tri-Color algorithm (three shades, really) are white, black and grey.</p>

<p>At the beginning of garbage collection, every slot in the Ruby Heap is white. Then, as part of the initial setup, all slots which contain root RVALUEs are marked as grey.</p>

<p>Root RVALUES are all of the RVALUES that a Ruby program knows it will need to run. Examples of these are RVALUES that exist on the stack of instructions that the program is following, or protected global variables.</p>

<p>With all root slots grey, and all other slots white, we then get to the crux of the algorithm:</p>

<div><div><pre><code><span>while</span> <span>(</span><span>!</span><span>grey_slots</span><span>.</span><span>empty?</span><span>)</span>
  <span>current_slot</span> <span>=</span> <span>grey_slots</span><span>.</span><span>pop</span>
  <span>grey_slots</span> <span>+=</span> <span>current_slot</span><span>.</span><span>referenced_slots</span>
  <span>black_slots</span> <span>&lt;&lt;</span> <span>current_slot</span>
<span>end</span>
</code></pre></div></div>

<p>We iterate over all grey slots, coloring the slots that their RVALUES reference grey, and coloring themselves black. The algorithm continues until there are no grey slots left. At this point, any black slots contain RVALUES which were reachable by the RVALUEs in the root slots, and any white slots do not contain RVALUES which were reachable so can be swept away!</p>

<p>For the visual learners, here’s a gif of what the algorithm is doing:</p>

<p><img src="https://jemma.dev/assets/mark.gif" alt="mark-gif"></p>

<h4 id="references">References</h4>

<p>There is one detail which needs further explanation here: how does an RVALUE know which other RVALUES it references?</p>

<p>It depends on the type of object. For Ruby builtins, tracing the references are just baked into the garbage collector code itself. For example, to find all references from an array RVALUE, the collector iterates each element in the array and finds its references. For a hash, it will do this for both the keys and the values. This all happens in the garbage collector’s <a href="https://github.com/ruby/ruby/blob/296a2cab07ce530809ee74dee61180fbb3ca6f91/gc.c#L6269"><code>mark_children</code></a> method.</p>

<p>But, when objects are defined by C extensions, the C extensions must mark all child objects on their own. We’ll dive more into this in a future C extensions post (which I’ll backlink here).</p>

<p>Okay, so now that we understand how we find all accessbile objects, we need to learn how to dispose of all unaccessible objects.</p>

<h3 id="sweeping">Sweeping</h3>

<p>At this point, we have two sets: black slots and white slots. Internally, these are represented as a <code>marked</code> bitmap. Every Page on the Ruby Heap has its own <code>marked</code> bitmap with one bit per slot. A <code>1</code> bit means the slot is accessible, or Black in our Tri-Color scheme. A <code>0</code> bit means that the slot is no longer accessible, or White in our Tri-Color scheme.</p>

<p>In addition to holding this <code>marked</code> bitmap, each page also has a <code>freelist</code> which represents slots on that page which do not have live objects. The garbage collector iterates over all pages, finding all slots which are not marked. Where applicable, the garbage collector then adds the unmarked slots to each page’s freelist. If the RVALUES which were occupying these slots are also taking up space in the operating system heap, it also frees this memory.</p>

<p>Once pages have been swept, there might be pages which are now completely unallocated; they have no slots which contain RVALUES. These pages are referred to as “Tomb Pages.” Tomb pages have their memory completely returned to the operating system’s heap. This is really helpful for memory management. It means that sweeping can result in freeing memory, or diminishing the overall size of the Ruby Heap.</p>

<p>Any pages with at least one occupied slot are called “Eden Pages”. The sweeping phase might reduce the number of occupied slots in an Eden Page. The garbage collector will use the freelists from Eden Pages for future object allocations. That is to say, if you instantiate an object, the garbage collector will look for one of these free slots in an Eden Page and place the RVALUE representing your object in there.</p>

<p><img src="https://jemma.dev/assets/eden-and-tomb.png" alt="eden-and-tomb"></p>

<p>There is one more nuance here. As of Ruby 3.0, if auto-compaction is enabled, compaction will actually happen as part of the sweeping phase. A more in depth explanation of how and why this happens will follow in a later post about compaction in this Garbage Collection Deep Dive Series.</p>

<h3 id="tldr">TL;DR</h3>

<p>The Tri-Color mark and sweep algorithm is what Ruby’s garbage collector uses to determine which slots hold objects which no longer have accessible references. It marks all of the slots it has references to by following the Tri-Color algorithm in which it follows all references from root RVALUES. Once the garbage collector knows which objects are accessible from the roots, it can begin the sweep phase, where it will add the unoccupied slots to each page’s freelist, and release any operating system memory those RVALUES held. This enables the slots to be reused for new object allocation.</p>

<p>Here are a few new definitions we learned:</p>

<ul>
  <li><strong>Eden page</strong>: A page which contains slots with RVALUES, might also have empty slots</li>
  <li><strong>Tomb page</strong>: A page which contains only empty slots</li>
  <li><strong>Free list</strong>: A linked list per Heap Page of empty slots</li>
</ul>

<p>And that’s it for this post! I’m going to continue writing blog posts in this series, and am also writing a book about managed garbage collection, with a focus on Ruby. If this interests you, join the newsletter below or follow me <a href="https://twitter.com/jemmaissroff">on twitter</a> for updates!</p>


  </div>
</article>

      </div>
    </div></div>]]>
            </description>
            <link>https://jemma.dev/blog/gc-mark-and-sweep</link>
            <guid isPermaLink="false">hacker-news-small-sites-26182796</guid>
            <pubDate>Thu, 18 Feb 2021 17:32:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Coq 8.13]]>
            </title>
            <description>
<![CDATA[
Score 115 | Comments 40 (<a href="https://news.ycombinator.com/item?id=26180078">thread link</a>) | @infruset
<br/>
February 18, 2021 | https://coq.inria.fr/news/coq-8-13-0-is-out.html | <a href="https://web.archive.org/web/*/https://coq.inria.fr/news/coq-8-13-0-is-out.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>





<p>
The Coq development team is proud to announce the immediate availability of
<a href="https://github.com/coq/coq/releases/tag/V8.13.0">Coq 8.13.0</a>
</p>

<p>
Highlights:
</p><ul>
<li>Introduction of primitive persistent arrays in the core language, implemented using imperative persistent arrays. </li>
<li>Introduction of definitional proof irrelevance for the equality type defined in the SProp sort. </li>
<li>Many improvements to the handling of notations, including number notations, recursive notations and notations with bindings. A new algorithm chooses the most precise notation available to print an expression, which might introduce changes in printing behavior.</li>
</ul>



<p>Please see <a href="https://coq.github.io/doc/v8.13/refman/changes.html#version-8-13" rel="nofollow">the changelog</a> to learn more about this release.</p>




</div></div>]]>
            </description>
            <link>https://coq.inria.fr/news/coq-8-13-0-is-out.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26180078</guid>
            <pubDate>Thu, 18 Feb 2021 14:23:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Browsers eating RAM]]>
            </title>
            <description>
<![CDATA[
Score 138 | Comments 148 (<a href="https://news.ycombinator.com/item?id=26179817">thread link</a>) | @todsacerdoti
<br/>
February 18, 2021 | https://www.flotato.com/post/memory-chrome-safari-flotato | <a href="https://web.archive.org/web/*/https://www.flotato.com/post/memory-chrome-safari-flotato">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>I reached a point where I could barely hear the podcast I was trying to listen to. That's how loud the fan was. Then I&nbsp;closed down all open Chrome windows, and a few minutes after, the fan went silent. So I decided to see if it was just me.</p><div href=""><h3>How I&nbsp;measured</h3><p>I&nbsp;ran the 2-tab test in a completely fresh macOS install on a virtual machine. Then I ran the 54-tabs test on my own Big Sur installation, but with all extensions disabled. To record a usage snapshot ~250 times per second, I&nbsp;used <a href="https://github.com/astrofrog/psrecord">psrecord.</a></p></div><div><h2>2&nbsp;tabs:&nbsp;Twitter, then Gmail</h2><p>To simulate a realistic environment, I&nbsp;did the same steps on Safari, then Chrome:&nbsp;Go to twitter.com, scroll around, then open a new tab with Gmail and open an email. A dot means I interacted with the system. You can hover a dot to see what I&nbsp;did. </p></div><div><h3>Putting Flotato to the test</h3><p>To be light-weight, Flotato doesn't just run a stripped down, Safari-backed web view, it also defaults to the mobile version if one is available. Here's Flotato compared to a regular session in Safari. Note the slightly lower CPU usage. It's kind of hard to put a finger on what exactly the mobile version isn't calculating that the desktop version is; the two versions are almost identical when you use them.</p></div><div><h2>54 tabs:&nbsp;the stress test</h2><p>I&nbsp;bet you have more than 2 tabs open right now, I&nbsp;sure have more. So here's a stress test where I&nbsp;open 54 tabs while measuring the impact on my Mac's RAM and CPU. A dot means I&nbsp;opened a new tab. Hover the dot to see which site I&nbsp;opened.</p></div><div><h2>Is it bad?</h2><p>When I saw the results I got suspicious. Chrome was using way more memory than I thought it would. Maybe it was the virtual machine blocking Chrome's direct access to my Macbook's* GPU?&nbsp;I&nbsp;decided to run the next test, the one with 54 tabs directly on my own Big Sur installation. The results were, well, slightly worse.</p><h3>The graphs don't tell the full story</h3><p>But it's probably not as bad as it looks. It's not a terrible thing that an app actually <em>uses</em> your computer. And you've got to hand it to Chrome:&nbsp;it is fast! </p><p>I'm sure Chrome is going out of its way to manage its memory usage across tabs, keeping the current tab fast and responsive. That's great if you're not running any other macOS apps than Chrome, effectively using Chrome as your operating system, and macOS&nbsp;as a kind of bootloader. </p><p>But when you're using Sketch, Final Cut, Photoshop next to Chrome, that seems to be a problem. MacOS&nbsp;likely tries to tell Chrome to take it easy, and Chrome likely <em>does</em> take it easy. These graphs don't tell that story. </p><p>So no, it's most likely not as bad as it looks, but that doesn't change the fact since switching to Safari, I almost forgot what my fan sounds like.</p><p>And then there's <em>this</em> chart. As we can see, the two browsers heat up the computer almost to the exact same level - Safari even getting slightly warmer. This probably points to psutil not being able to see all Safari's child processes, but only the main ones — despite the fact that Activity Monitor is able to group them. That's a little confusing. </p><figure><p><img src="https://uploads-ssl.webflow.com/5e78c687e58e25134b3fb751/602feb36d1388bb94f881998_EumcL7jXYAEBG_4.png" alt="Image"></p></figure><p>‍</p><p>‍</p><p><em>*&nbsp;Macbook 16" from 2019 with2.4 GHz, 8-Core Intel Core i9 with 32&nbsp;GB&nbsp;2667 MHz DDR4 RAM and an AMD&nbsp;Radeon Pro 5500M 8GB GPU</em></p></div></div>]]>
            </description>
            <link>https://www.flotato.com/post/memory-chrome-safari-flotato</link>
            <guid isPermaLink="false">hacker-news-small-sites-26179817</guid>
            <pubDate>Thu, 18 Feb 2021 13:56:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Curl is C (2017)]]>
            </title>
            <description>
<![CDATA[
Score 83 | Comments 79 (<a href="https://news.ycombinator.com/item?id=26179601">thread link</a>) | @taf2
<br/>
February 18, 2021 | https://daniel.haxx.se/blog/2017/03/27/curl-is-c/ | <a href="https://web.archive.org/web/*/https://daniel.haxx.se/blog/2017/03/27/curl-is-c/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<p>For some reason, this post got picked up again and is <a href="https://news.ycombinator.com/item?id=26179601">debated today</a> in 2021, almost 4 years since I wrote it. Some things have changed in the mean time and I might’ve phrased a few things differently if I had written this today. But still, what’s here below is what I wrote back then. Enjoy!</p>



<div><figure><a href="https://daniel.haxx.se/blog/wp-content/uploads/2017/01/The_C_Programming_Language_cover.svg_.png"><img loading="lazy" width="348" height="450" src="https://daniel.haxx.se/blog/wp-content/uploads/2017/01/The_C_Programming_Language_cover.svg_-348x450.png" alt="" srcset="https://daniel.haxx.se/blog/wp-content/uploads/2017/01/The_C_Programming_Language_cover.svg_-348x450.png 348w, https://daniel.haxx.se/blog/wp-content/uploads/2017/01/The_C_Programming_Language_cover.svg_-155x200.png 155w, https://daniel.haxx.se/blog/wp-content/uploads/2017/01/The_C_Programming_Language_cover.svg_-768x992.png 768w, https://daniel.haxx.se/blog/wp-content/uploads/2017/01/The_C_Programming_Language_cover.svg_.png 792w" sizes="(max-width: 348px) 100vw, 348px"></a></figure></div>



<p>Every once in a while someone suggests to me that curl and libcurl would do better if rewritten in a “safe language”. Rust is one such alternative language commonly suggested. This happens especially often when we publish new security vulnerabilities. (Update: I think Rust is a fine language! This post and my stance here has nothing to do with what I think about Rust or other languages, safe or not.)</p>



<h2>curl is written in C</h2>



<p>The curl code guidelines mandate that we stick to using C89 for any code to be accepted into the repository. C89 (sometimes also called C90) – the oldest possible ANSI C standard. Ancient and conservative.</p>



<h2>C is everywhere</h2>



<p>This fact has made it possible for projects, companies and people to adopt curl into things using basically any known operating system and whatever CPU architecture you can think of (at least if it was 32bit or larger). No other programming language is as widespread and easily available for <em>everything</em>. This has made curl one of the most portable projects out there and is part of the explanation for curl’s success.</p>



<p>The curl project was also started in the 90s, even long before most of these alternative languages you’d suggest, existed. Heck, for a truly stable project it wouldn’t be responsible to go with a language that isn’t even old enough to start school yet.</p>



<h2>Everyone knows C</h2>



<p>Perhaps not necessarily true anymore, but at least the knowledge of C is very widespread, where as the current existing alternative languages for sure have more narrow audiences or amount of people that master them.</p>



<h2>C is not a safe language</h2>



<p>Does writing safe code in C require more carefulness and more “tricks” than writing the same code in a more modern language better designed to be “safe” ? Yes it does. But we’ve done most of that job already and maintaining that level isn’t as hard or troublesome.</p>



<p>We keep scanning the curl code regularly with static code analyzers (we maintain a <em>zero <a href="https://scan.coverity.com/projects/curl">Coverity</a> problems</em> policy) and we run the test suite with <a href="http://valgrind.org/">valgrind</a> and <a href="https://en.wikipedia.org/wiki/AddressSanitizer">address sanitizers</a>.</p>



<h2>C is not the primary reason for our past vulnerabilities</h2>



<p>There. The simple fact is that most of our past vulnerabilities happened because of logical mistakes in the code. Logical mistakes that aren’t really language bound and they would not be fixed simply by changing language.</p>



<p>Of course that leaves a share of problems that could’ve been avoided if we used another language. Buffer overflows, double frees and out of boundary reads etc, but the bulk of our security problems has not happened due to curl being written in C.</p>



<h2>C is not a new dependency</h2>



<p>It is easy for projects to add a dependency on a library that is written in C since that’s what operating systems and system libraries are written in, still today in 2017. That’s the default. Everyone can build and install such libraries and they’re used and people know how they work.</p>



<p>A library in another language will add that language (and compiler, and debugger and whatever dependencies a libcurl written in that language would need) as a new dependency to a large amount of projects that are themselves written in C or C++ today. Those projects would in many cases downright ignore and reject projects written in “an alternative language”.</p>



<h2>curl sits in the boat</h2>



<p>In the curl project we’re deliberately conservative and we stick to old standards, to remain a viable and reliable library for everyone. Right now and for the foreseeable future. Things that worked in curl 15 years ago still work like that today. The same way. Users can rely on curl. We stick around. We don’t knee-jerk react to modern trends. We sit still in the boat. We don’t rock it.</p>



<h2>Rewriting means adding heaps of bugs</h2>



<p>The plain fact, that also isn’t really about languages but is about plain old software engineering: translating or rewriting curl into a new language will introduce a lot of bugs. Bugs that we don’t have today.</p>



<p>Not to mention how rewriting would take a huge effort and a lot of time. That energy can instead today be spent on improving curl further.</p>



<h2>What if</h2>



<p><em>If I would start the project today, would I’ve picked another language?</em> Maybe. Maybe not. If memory safety and related issues was the primary concern I had, then sure. But as I’ve mentioned above there are several others concerns too so it would really depend on my priorities.</p>



<h2>Finally</h2>



<p>At the end of the day the question that remains is: would we gain more than we would pay, and over which time frame? Who would gain and who would lose?</p>



<p>I’m sure that there will be or it may even already exist, curl and libcurl competitors and potent alternatives written in most of these new alternative languages. Some of them are absolutely really good and will get used and reach fame and glory. Some of them will be crap. Just like software always work. Let a thousand curl competitors bloom!</p>



<p>Will curl be rewritten at some point in the future? I won’t rule it out, but I find it unlikely. I find it even more unlikely that it will happen in the short term or within the next few years.</p>



<p>Discuss this post on <a href="https://news.ycombinator.com/item?id=13966241">Hacker news</a> or <a href="https://www.reddit.com/r/programming/comments/61rh9j/curl_is_c/">Reddit</a>!</p>



<p><strong>Followup-post: </strong><a href="https://daniel.haxx.se/blog/2017/03/30/yes-c-is-unsafe-but/">Yes, C is unsafe, but…</a></p>
	</div></div>]]>
            </description>
            <link>https://daniel.haxx.se/blog/2017/03/27/curl-is-c/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26179601</guid>
            <pubDate>Thu, 18 Feb 2021 13:34:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[OpenZFS – dRAID, Finally]]>
            </title>
            <description>
<![CDATA[
Score 165 | Comments 47 (<a href="https://news.ycombinator.com/item?id=26179566">thread link</a>) | @throw0101a
<br/>
February 18, 2021 | https://klarasystems.com/articles/openzfs-draid-finally/ | <a href="https://web.archive.org/web/*/https://klarasystems.com/articles/openzfs-draid-finally/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>




<div>
<h3><em>This is part of our article series published as “OpenZFS in Depth”. <a href="https://klarasystems.com/articles/"><strong><span>Subscribe to our article series</span></strong> </a>to find out more about the secrets of OpenZFS</em></h3>



<hr>



<p><strong><em>Isaac Huang’s <a href="https://www.youtube.com/watch?v=xPU3rIHyCTs">talk at the OpenZFS 2017 developers summit</a> witnessed the expansion of the ZFS storage endurance envelope for large installations.&nbsp; dRAID or distributed RAID is a new vdev type that complements existing ZFS data protection capabilities for very large storage arrays.&nbsp; Starting with the RAID-Z-like underpinnings, dRAID permutes, or mixes, disk blocks together in a way where accesses are evenly spread across all the drives. Fast spindle replacement is accomplished by using all members of the pool, using pre-allocated virtual spares, spread evenly over all the spindles. Contributors include Intel, Lawrence Livermore Labs, and HP Enterprise, which have material interest in storage at datacenter scale and high reliability. The OpenZFS user community are the benefactors of this enhancement if we apply it well.</em></strong></p>



<h3><strong>Avoiding the Death Spiral</strong></h3>



<p>Admins will often use wide RAID stripes to maximize usable storage given a number of spindles. RAID-Z deployments with large stripe widths, ten or larger, are subject to poor resilver performance for a number of reasons. Resilvering a full vdev means reading from every healthy disk and continuously writing to the new spare. This will saturate the replacement disk with writes while scattering seeks over the rest of the vdev. For 14 wide RAID-Z2 vdevs using 12TB spindles, rebuilds can take weeks. Resilver I/O activity is deprioritized when the system has not been idle for a minimum period. Full zpools get fragmented and require additional I/O’s to recalculate data during reslivering. A pool can degenerate into a never ending cycle of rebuilds or loss of the pool Aka: the Death Spiral.</p>



<p>As spindles age together, disks may fail in groups as defect counts and mechanical failure are not independent random processes with respect to age. SSD’s further complicate this math as the wear leveling endurance will be very closely matched and clusters of devices under identical load may fail together.&nbsp; Manufacturer provided mean time to failure is a forward-looking statement and is not suitable for replenishment planning. One manufacturer claims 1.2 Million hour MTBF: a dubious 137 year commitment to quality. It’s poor planning to assume any drive isn’t going to pick today to dramatically fail.&nbsp;</p>



<p>dRAID is an option providing rapid parity rebuild that can mitigate the death spiral behaviour of wide RAIDZ stripes, but as reflected in its default width setting of eight, it does not encourage wide stripes. Dedicating sufficient parity increases the durability of the ZFS pool and the investment in parity should be informed by the risk of losing the pool.</p>



<h3><strong>Distributed Spares?</strong></h3>



<p>Spare disks are a way of keeping a disk warm and ready to replace a failed member. Usually, a spare’s life is leisurely idle until they are scrammed into action during a rebuild. That idleness is a wasted opportunity to do useful work. There are no specific spare disks in a dRAID. Rather, enough blocks are allocated throughout out the vdev to act as spares. The distributed spare is a clever redistribution of work so that all disks are always in use. A disk failure precipitates a rebuild into that dedicated space. After replacement disks are available, the vdev can be re-balanced to return the spare block and put the replacement disk in to use.</p>



<h3><strong><strong><strong>Fixed Stripe Width</strong></strong></strong></h3>



<p>Unlike RAID-Z, an entire stripe in dRAID is allocated at once, no matter how many disk blocks are needed to store the object. The stripe width is determined by the disk sector size multiplied by the number of data drives in the RAID group.</p>



<div data-columns="3" data-layout="50-25-25"><div>




<div><div>
<p>Did you know?</p>



<h2>You can maximize the <strong>power of your FreeBSD</strong> infrastructure with our <strong>Support Subscription!</strong></h2>




</div></div>




</div></div>



<p>RAID-Z has a method of optimizing block layout to minimize block allocations for small files. dRAID however priorities the speed of rebuilding parity and does not make the same space preserving attempt. If your files are a small fraction of the stripe size, dRAID will not be able to use all the disk blocks fully. For example, a default dRAID vdev has a stripe with of 32k (4k per disk, 8 disks); any allocation will require at least 32k. Internal padding is allocated to fill out the stripe width after the request object is stored. Using a smaller stripe width or providing a special mirror vdev will suit smaller allocations and improve drive utilization.</p>



<h3><strong>A Tale of Two Resilvers</strong></h3>



<p>After a failure, the real or distributed spare is written to in sequence, following only the parity layout in the space map to rebuild the drive according to parity data. Sequential reconstruction can be accomplished rapidly by issuing large I/O blocks, reducing seeks, and avoiding tree indirection overhead. The rebuilt disk’s contents are not necessarily consistent with the Merkle tree that proves the zpools data is intact.&nbsp; It’s important to reconstruct this bitwise copy of the disk first, allowing the system to return to mostly intact state and return to service. That is to say, the sequential reconstruction process restores the redundancy level of the pool, but without being able to verify the checksums of the data. The advantage to this is that it can be completed much more quickly, reducing the window during which additional disk failures might put the pool at risk.</p>



<p>A healing resilver is triggered automatically after a sequential resilver, it is a final operation that verifies that all the contents of the drives match their initial checksums via block pointer traversal. The healing resilver has a number of optimizations to quickly find and reconstruct writes to the failed disk. When a replacement drive can be added to the pool, the rebalance operation is another sequential resilver followed by a healing resilver.</p>



<p>A scrub is the gold standard for a pool health; however, a scrub might be a prohibitive amount of work, visiting every block allocated in the pool. The healing resilver allows a practical return to operation in an environment where failures must be repaired routinely.</p>



<h3><strong><em>“Are We There Yet? When Can I Play With it?”</em></strong></h3>



<p>According to a report from the January OpenZFS leadership meeting, OpenZFS 2.1 will support dRAID in early 2021. If you must have it now; the head branch of the OpenZFS build against recently supported operating systems: FreeBSD 12.1+, Linux 5.10+, Illumos, NetBSD et al. The OpenZFS regression test suite ztest is a good indication that dRAID satisfies the ZFS commitment to data protection. Corporate customers at IBM and Panasas have been flogging other distributed RAID systems for more than ten years. It’s a mature concept that complements the ZFS tool set.</p>



<h4><strong>Quick Start</strong></h4>



<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; There is no better way to learn software than to run headlong into mistakes.&nbsp;</p>



<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; We’ll install ZFS head from source and gin up some ‘md’ file backed disks.</p>



<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; ‘zpool create r2dRAID dRAID2:3d:1s:14c /dev/md1 /dev/md2 ….&nbsp; /dev/md13 /dev/md14’</p>



<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; There it is, a zpool with a dRAID vdev, ready to go to work.</p>



<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; The OpenZFS wiki has a good description of <a href="https://openzfs.github.io/openzfs-docs/Basic%20Concepts/dRAID%20Howto.html">dRAID care, resilvering and rebalancing</a></p>



<p>Following the life cycle of failure and replacement in the documentation is recommended before those skills are tested in production.</p>



<h4><strong>dRAID Nomenclature</strong></h4>



<p>Let’s decode the nomenclature that describes the geometry of a dRAID vdev. A string such as “dRAID2:3d:14c:1s” encodes the following about a dRAID vdev.</p>



<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; -dRAID[&lt;parity&gt;][:&lt;data&gt;d][:&lt;children&gt;c][:&lt;spares&gt;s]</p>



<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; -parity: Required, the number of spindles to use to store parity information. Eg: A dRAID3 can survive until a fourth disk failure without losing data. Parity may be 1,2 or 3.</p>



<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; -[d] data: (spindles per RAID group): Determines the width of the data stripe, 8 is the default. Larger values will increase the stripe width and reduce total parity.</p>



<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; -[c] children: This parameter should match the number of device entries that you feed to the vdev. A helpful check will warn you if you don’t get the right number of disks named correctly: “invalid number of dRAID children; 14 required but 13 provided”</p>



<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; -[s] spares: The number of disk areas to mix in as distributed spares. No spares are created by default, a maximum of four are welcome. Each spare will remove a fraction of space from every disk.</p>



<h2><strong>Parting Short</strong></h2>



<p>The dRAID offers a solution for large arrays, vdevs with fewer than 20 spindles will have limited benefits from the new option. The performance and resilver result will be similar to RAIDZ for small numbers of spindles. Installations with many spindles will see the best results with regards to performance, fast spare activation and replacement. The benefits come with the associated cost of whole stripe at a time allocation for small objects in the pool. This overhead should be calculated in the design of the pool before it’s an operational surprise.</p>



<p>There is no free lunch with dRAID for in saving parity or spare drives, they are your defense against data loss. As drives increase in size, their time to resilver increases and the amount of data they can destroy increases.</p>



<h2><strong>Like this article? Share it!</strong></h2>


</div>




</div></div>]]>
            </description>
            <link>https://klarasystems.com/articles/openzfs-draid-finally/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26179566</guid>
            <pubDate>Thu, 18 Feb 2021 13:31:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Split Keyboards Gallery]]>
            </title>
            <description>
<![CDATA[
Score 189 | Comments 106 (<a href="https://news.ycombinator.com/item?id=26179311">thread link</a>) | @Symbiote
<br/>
February 18, 2021 | https://aposymbiont.github.io/split-keyboards/ | <a href="https://web.archive.org/web/*/https://aposymbiont.github.io/split-keyboards/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://aposymbiont.github.io/split-keyboards/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26179311</guid>
            <pubDate>Thu, 18 Feb 2021 13:01:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I am a heroin user. I do not have a drug problem]]>
            </title>
            <description>
<![CDATA[
Score 277 | Comments 651 (<a href="https://news.ycombinator.com/item?id=26179003">thread link</a>) | @CapitalistCartr
<br/>
February 18, 2021 | http://m.nautil.us/issue/96/rewired/i-am-a-heroin-user-i-do-not-have-a-drug-problem | <a href="https://web.archive.org/web/*/http://m.nautil.us/issue/96/rewired/i-am-a-heroin-user-i-do-not-have-a-drug-problem">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
			<p><span>C</span>arl Hart is a neuroscientist and Ziff Professor of Psychology at Columbia University—he was the first tenured African-American professor of sciences at Columbia. His research focuses on the “behavioral and neuropharmacological effects of psychoactive drugs in humans.” Hart’s new book, <i>Drug Use For Grown-Ups</i>, is a bold and engaging effort to counter what he sees as generations of misinformation and moral grandstanding about drug use. Today’s “sensationalistic media coverage of the opioid crisis continues a long, awful tradition of exploiting ignorance and fear to vilify certain members of our society,” Hart writes. The media is not the only problem. Scientists, he states, “have frequently overinterpreted and distorted” drugs’ effects on the brain.</p><p>Hart reports that more than 70 percent of drug users—whether they use alcohol, cocaine, prescription medications, or heroin—do not meet the health criteria for drug addiction. In <i>Drug Use for Grown-Ups</i>, Hart strives to “present a more realistic image of the typical drug user: a responsible professional who happens to use drugs in his pursuit of happiness.” With genial candor, Hart presents himself as a model drug user. “I am now entering my fifth year as a regular heroin user,” he writes. “I do not have a drug-use problem. Never have. Each day, I meet my parental, personal, and professional responsibilities. I pay my taxes, serve as a volunteer in my community on a regular basis, and contribute to the global community as an informed and engaged citizen. I am better for my drug use.”</p><p><i>Nautilus</i> caught up with Hart to discuss his drug use and his sharp points about science and society. He was as casually bold in conversation as he is in <i>Drug Use for Grown-Ups</i>.</p><figure data-alt="MacNamara_BREAKER"><img src="http://static.nautil.us/18174_0f004440ba0c8f1ccc5c355f3d77207f.png" width="733" alt=""><figcaption><span><strong>HABIT OF A HIGHLY EFFECTIVE PERSON:</strong> “My heroin use is as rational as my alcohol use,” Carl Hart writes. “Like vacation, sex, and the arts, heroin is one of the tools that I use to maintain my work-life balance.”</span><span>Courtesy of Carl Hart</span></figcaption></figure><p><b>You say “most drug-use scenarios cause little or no harm and that some responsible drug-use scenarios are actually beneficial for human health and functioning.” How so?</b></p><p>Let’s just talk about alcohol first. When you’re at a wedding reception, alcohol serves as a social lubricant. People are more gregarious. They talk, they interact. The same is true with cocaine at parties, heroin among friends, or opium among friends, NDMA among lovers. It enhances empathy, openness, and forgiveness, all of these pro-social attributes.</p><p><b>Drug research, you write, is full of bad science. If you had to name one example, what would it be?</b></p><p>The notion that drug addiction is a brain disease. That encapsulates all that’s wrong with today’s science in this area. There is absolutely no data in humans to show that drug addiction is a brain disease. Yet the narrative, the dogma, the dominant perspective is that it does. Even though nobody will dispute that, there’s absolutely no data in humans to support that statement.</p><p><b>Yet opioids do change the brain biologically, do they not?</b></p><p>Yes, opioids bind to a class of receptors called endogenous opioids, which you find in endorphins, for example. Opioids bind to these receptors—just like natural chemicals do—which results in a response. In some cases, because of decreased sensitivities and certain types of pain, they may enhance a sense of euphoria. So it’s really just facilitating what’s already in the body naturally, a system that helps in our survival. Think of fructose or glucose. We add sugar to our tea, our coffee, whatever we have, we add more and more because we like it, it tastes good, and it enhances pleasure. It can give you energy. It can make life more interesting. Humans do not live on logic alone. And so sometimes we do these things, and that’s OK.</p><blockquote><p>People become addicted because they once had a middle-class-paying job that made them someone in their community.</p> </blockquote><p><b>How have scientists “overinterpreted and distorted” the effects of drugs on the brain?</b><br></p><p>Take brain imaging. People often show one image of someone’s brain. Let’s say this person is addicted to methamphetamine, according to DSM criteria, versus the brain of someone who’s not addicted. If you see some difference, some researchers have a propensity to make more out of the differences than are there. There’s a wide range of brain structural sizes, such that when we think about one person’s size of their nucleus accumbens, it may be smaller or larger than somebody else’s nucleus accumbens. But both of the nucleus accumbens, despite their sizes, are within the normal range of human variability. It’s like height. One guy might be 5’10”, another guy might be 6’2”. But we don’t say the guy who’s 5’10” is height deficient. We just say that he’s in a normal range, and he’s not as tall as the other guy. We wouldn’t say one is deficient versus the other. In neuroscience, one of the things that has happened, particularly when it comes to drugs, people have over-interpreted the differences to mean pathology, when, in fact, both of the brain structures are within the normal range of human variability. The overinterpretation is to interpret it as being pathological.</p><p><b>You say the opioid crisis has been sensationalized, and write, “People are not dying because of opioids; they are dying because of ignorance.” What do you mean?</b></p><p>Some people don’t know not to mix specific sedatives with opioids. For example, they don’t know not to mix large amounts of alcohol or large amounts of antihistamines. Specific combinations can lead to respiratory depression, which can lead to death. Another point of ignorance involves people who buy street drugs and don’t necessarily know if the drugs contain contaminants. That’s the kind of ignorance I’m talking about.</p><div>
<article>
<p><a href="http://m.nautil.us/issue/59/Connections/how-the-fencing-reflex-connects-life-and-death" data-trval="how-the-fencing-reflex-connects-life-and-death" data-trlbl="foc_rec" data-tract="internal_art">
<img src="http://static.nautil.us/14500_a8442efac020cf971575de816beb459e.png" alt="Sapolsky_TH-F1" width="314" height="177">
</a>
</p>


</article>
</div><p><b>So it’s the mix of drugs that is the problem, not opioids like heroin themselves?&nbsp;</b></p><p>Yes, the majority of opioid deaths occur as a result of combining opioids with multiple sedatives. But there are certain opioids that do concern us if taken alone and the person isn’t aware that they have this particular opioid. Those are fentanyl and the fentanyl analogs. These drugs are a lot more potent than something like heroin, meaning they require less of it to produce the effect. Most of the public aren’t seeking fentanyl or its analogs, but people are tainting things like heroin and oxycodone pills with fentanyl or an analog.</p><p>One way to deal with this tainting, this contamination, is to have free drug-checking facilities, where people can submit samples of their drug and get a chemical readout of what is contained in the substance. That way they’ll know whether to take the substance or how much of it to take. The public also needs to know that most people who use these drugs are not addicts. If you understand that, then you know that for the people who do become addicted, we have to look beyond the drug and look at the person’s environment, their life. Do they have co-occurring psychiatric illnesses? Do they have pain that is not treated? All of these kinds of issues become important.</p><p><b>At what point does biological change in the brain lead to physical addiction?</b></p><p>Physical addiction occurs as a result of opioids—or any other drug, alcohol too—being in the body for consecutive weeks or periods, in particularly high doses. And then the body tries to compensate. For example, with opioids, one of the things that happens is that your gut, your gastrointestinal system, slows down the receptors. Your body is trying to compensate by speeding up the gastrointestinal tract. So when the drug abruptly leaves after several weeks of constant administration of the opioid, now the body is unprepared for the drug not being there and it overcompensates. It really ramps up the motility of the gastrointestinal tract, which causes diarrhea, among other things.</p><blockquote><p>It can give you energy. It can make life more interesting. Humans do not live on logic alone.</p> </blockquote><p><b>Why do some people get addicted and not others?</b><br></p><p>The amount of drugs they take, the period at which they take it. Some people can take opioids for extended periods of time. As long as they keep the doses fairly low and they don’t take multiple doses a day, they probably won’t experience physical dependence. It’s just like with alcohol. Most people drink alcohol on a regular basis, but they don’t become physically dependent. Whereas others drink every day in large amounts, and they will become physically dependent.</p><p><b>Why can’t people overcome addiction?</b></p><p>One of the major reasons people can’t overcome it is because we’re not very good at treating addiction in this country. Just think about why people become addicted. A large number become addicted because of co-occurring psychiatric illnesses, because of pain issues, because they once had a middle-class-paying job that made them someone in their home, someone in their community. Those jobs are gone. Then there’s no healthcare or there’s poor education. If your treatment is not addressing these issues, people are not going to overcome it. But if we have treatments that are holistic, and they’re looking at the individual, and not so much the drug, then we’re good. But if we’re just talking about the drug, then we’re already behind the eight ball, then we will lose that battle.</p><p><b>Your definition of addiction follows the DSM-5, which refers to a “substance use disorder” and values functioning over regular ingestion of a substance. How do you define “functioning”?</b></p><p>Functioning is determined by whether a user is happy in meeting their obligations, whatever they may be, whether they’re work-related, whether they’re family-related, or other social sorts of things. The person is not stressed out about their substance use. In fact, they’re cool with it. That’s functioning. The person’s happiness is more important. That supersedes any other thing.</p><p><b>You write that, contrary to the cultural myth, regular use of recreational drugs doesn’t damage the brain. What’s the frequency associated with recreational?</b></p><p>Yeah, I’m sorry. I couldn’t think of a …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://m.nautil.us/issue/96/rewired/i-am-a-heroin-user-i-do-not-have-a-drug-problem">http://m.nautil.us/issue/96/rewired/i-am-a-heroin-user-i-do-not-have-a-drug-problem</a></em></p>]]>
            </description>
            <link>http://m.nautil.us/issue/96/rewired/i-am-a-heroin-user-i-do-not-have-a-drug-problem</link>
            <guid isPermaLink="false">hacker-news-small-sites-26179003</guid>
            <pubDate>Thu, 18 Feb 2021 12:23:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The frame rate of the universe (2009)]]>
            </title>
            <description>
<![CDATA[
Score 74 | Comments 64 (<a href="https://news.ycombinator.com/item?id=26178259">thread link</a>) | @codesections
<br/>
February 18, 2021 | https://www.librador.com/2009/01/16/The-frame-rate-of-the-universe/ | <a href="https://web.archive.org/web/*/https://www.librador.com/2009/01/16/The-frame-rate-of-the-universe/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">
      
<div id="page-2009-2009-01-16-The-frame-rate-of-the-universe-">
  
  <p><abbr title="2009-01-16T01:04:00+01:00">16 Jan 2009</abbr></p><div>
    <p>

    I stumbled upon <a href="http://www.newscientist.com/article/mg20126911.300-our-world-may-be-a-giant-hologram.html?full=true">this
article</a> which presents the hypothesis that the universe is a 3D projection of a 2D
surface, like a giant hologram. I like to read about modern physics. It is so weird and I can't say
I really understand very much of it. But the descriptions provoke strange and fascinating images
and thoughts in my head. Like this one:</p><p>The article mentions the <a href="http://en.wikipedia.org/wiki/Planck_length">Planck length</a>, which as I understand it is
the smallest distance there is. It's extremely small: 1.6 × 10<sup>-35</sup> meters, which makes
it billions and billions of times smaller than an atom (or even a proton). I'm used to thinking
about computer graphics, so I imagine the Planck length as the size of one "pixel" of the universe.
Nothing can be smaller than a pixel. (The pixels of the universe are small, I calculate the
resolution to correspond to 2.19 × 10<sup>33</sup> DPI.) The radius of the observable universe is
4.4 × 10<sup>26</sup> meters. If we want to fit the universe into a box, its sides would have to
be twice that size. That is 5.4 × 10<sup>61</sup> Planck lengths. So that's the width, height and
depth of the universe in pixels. Quite a good resolution. (Actually since they are 3D cubes instead
of 2D squares, I should call them voxels instead of pixels. All 1.61 × 10<sup>185</sup> of
them.)</p><p>There is also the <a href="http://en.wikipedia.org/wiki/Planck_time">Planck time</a>
which is the time it takes for light to travel one Planck length. As light is fast and the Planck
length is tiny (tiniest there is!), you can image that it's a very short period of time. Certainly.
The Planck time is 5.39 × 10<sup>-44</sup> seconds. No measurable time can be shorter than that
according to quantum physics. Thinking about graphics again, this is like a limit on the frame rate
of the universe. Inverting the Planck time, I get 1.855 × 10<sup>43</sup>. So by my surely
incorrect logic, we get the value of the universe's frame rate:</p><p>One thousand eight hundred
and fifty-five billion billion billion billion frames per second.</p><p>I'll say that
again:</p><p>18.55 septillion FPS!</p><p>Video cameras won't be perfect until they can record at
that speed.</p><p>I hope I got the calculations right, but I'm pretty sure my interpretation of the
quantum physics behind this are way off. It's still fascinating to think of the universe as a
computer simulation. Modern physics make it seem more like a video game than ever.<br>


</p>
  </div>
  
  
  <p><a href="http://disqus.com/">blog comments powered by </a>
</p></div>

    </div></div>]]>
            </description>
            <link>https://www.librador.com/2009/01/16/The-frame-rate-of-the-universe/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26178259</guid>
            <pubDate>Thu, 18 Feb 2021 10:37:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Lithuania plans to hold drills in case of accident at the Belarus nuclear plant]]>
            </title>
            <description>
<![CDATA[
Score 156 | Comments 139 (<a href="https://news.ycombinator.com/item?id=26178235">thread link</a>) | @maury91
<br/>
February 18, 2021 | https://www.lrt.lt/en/news-in-english/19/1346034/lithuania-plans-to-hold-evacuation-drills-after-belarus-launches-nuclear-plant | <a href="https://web.archive.org/web/*/https://www.lrt.lt/en/news-in-english/19/1346034/lithuania-plans-to-hold-evacuation-drills-after-belarus-launches-nuclear-plant">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<article id="article1346034">    

    
    
    <div>

        <div id="article_text1346034">
            <p>Lithuania’s Interior Ministry plans to hold drills and assess the need to evacuate Vilnius’ residents in case of an accident at the Astravyets nuclear plant in Belarus, located some 50 kilometres from the Lithuanian capital.</p>
            
            <p>"That will be one of the key questions during the drafting of the exercises schedule and probably going back to the scenarios: do we or do we not need to evacuate Vilnius residents,” Vitalij Dmitrijev, vice minister of the interior, told LRT RADIO.</p>
            <p>The so-called Astravyets drill was held in October 2019 in Vilnius and Svenčionys districts, which are located close to the Belarusian border. During the exercises, authorities prepared to evacuate people from radiation-affected territories, distribute iodine pills, as well as simulated a resident cleanup and monitoring operation.</p>
            <p>The exercise involved around 300 officers, troops and civil servants from six municipalities and 24 institutions. Due to a dispute over the exercise scenario with the Vilnius authorities, officers from the capital did not take part in the drills.</p>
                

            <p><em>Read more: <a href="https://www.lrt.lt/en/news-in-english/19/1103053/lithuanians-stage-mock-evacuations-to-train-for-nuclear-accident-photos">Lithuanians stage mock evacuations to train for nuclear accident – photos</a></em></p>
            <!--googleoff: all--><!--googleon: all-->            <p>Previously, the Vilnius authorities cancelled another exercise, planned in early September, to simulate an accident at the nuclear power plant in Belarus.</p>
            <p>Based on the information available to BNS, Vilnius Municipality faced resistance from the government at the time.</p>
            <p>Lithuanian officials say that the nuclear power plant built by the Russian state atomic corporation Rosatom and funded by a loan from the Kremlin was built in breach of international safety standards. Minsk denies all accusations.</p>
            <p>Estonia, Latvia, and Lithuania are also due to unplug from the Moscow-controlled energy grid that links them with Belarus. Vilnius says that the Kremlin may use the plant to derail the move.</p>
<!--googleoff: all--><div>
            
<div id="mlb2-1612938">
    <div>
        <div>
            <div>
                <div>
                    <p><img src="https://bucket.mlcdn.com/a/1239/1239192/templates/39/39540/5dcc95ea35753170c2955994a6fea7c948ffb283.png"></p><p>LRT English Newsletter<span><span><br></span><span><span>Every Friday morning.</span></span></span></p>
                    
                </div>
            </div>
            
        </div>
    </div>
</div>

<p><img src="https://track.mailerlite.com/webforms/o/1612938/i0s8k2?v4a60e9ef938a7fa0240ac9ba567062cb" width="1" height="1">
</p></div><!--googleon: all-->        </div>
    </div>
    <!--googleoff: all-->
        <!--googleon: all-->
        

<div data-id="gallery1346034"><div>
            <div>
                <div>
                    <div>
<p><img data-src="/img/2019/10/02/522637-581058-1287x836.jpg" alt="‘Astravyets drill’ in Lithuania" title="‘Astravyets drill’ in Lithuania" src="https://www.lrt.lt/img/2019/10/02/522637-581058-1287x836.jpg"></p>
<div>
    <div>
        <div>
<p>‘Astravyets drill’ in Lithuania</p>            <p><span>1 / 5</span><span>D. Umbrasas / LRT</span></p>
        </div></div>
</div>
                    </div>
                    <div>
<p><img data-src="/img/2019/12/23/573047-835055-1287x836.jpg" alt="Lithuania has staged 'Astravyets drills' to prepare for nuclear emergencies" title="Lithuania has staged 'Astravyets drills' to prepare for nuclear emergencies" src="https://www.lrt.lt/img/2019/12/23/573047-835055-1287x836.jpg"></p>
<div>
    <div>
        <div>
<p>Lithuania has staged 'Astravyets drills' to prepare for nuclear emergencies</p>            <p><span>2 / 5</span><span>D. Umbrasas/LRT</span></p>
        </div></div>
</div>
                    </div>
                    <div>
<p><img data-src="/img/2019/10/02/522627-981621-1287x836.jpg" alt="‘Astravyets drill’ in Lithuania" title="‘Astravyets drill’ in Lithuania" src="https://www.lrt.lt/img/2019/10/02/522627-981621-1287x836.jpg"></p>
<div>
    <div>
        <div>
<p>‘Astravyets drill’ in Lithuania</p>            <p><span>3 / 5</span><span>D. Umbrasas / LRT</span></p>
        </div></div>
</div>
                    </div>
                    <div>
<p><img data-src="/img/2019/10/02/522623-306261-1287x836.jpg" alt="‘Astravyets drill’ in Lithuania" title="‘Astravyets drill’ in Lithuania" src="https://www.lrt.lt/img/2019/10/02/522623-306261-1287x836.jpg"></p>
<div>
    <div>
        <div>
<p>‘Astravyets drill’ in Lithuania</p>            <p><span>4 / 5</span><span>D. Umbrasas / LRT</span></p>
        </div></div>
</div>
                    </div>
                    <div>
<p><img data-src="/img/2019/10/02/522612-821132-1287x836.jpg" alt="‘Astravyets drill’ in Lithuania" title="‘Astravyets drill’ in Lithuania" src="https://www.lrt.lt/img/2019/10/02/522612-821132-1287x836.jpg"></p>
<div>
    <div>
        <div>
<p>‘Astravyets drill’ in Lithuania</p>            <p><span>5 / 5</span><span>D. Umbrasas / LRT</span></p>
        </div></div>
</div>
                    </div>
                </div>
                
            </div>
        </div>
        
    </div>
 

    
    
</article>

        
    </div></div>]]>
            </description>
            <link>https://www.lrt.lt/en/news-in-english/19/1346034/lithuania-plans-to-hold-evacuation-drills-after-belarus-launches-nuclear-plant</link>
            <guid isPermaLink="false">hacker-news-small-sites-26178235</guid>
            <pubDate>Thu, 18 Feb 2021 10:34:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Reflections on Using Haskell for My Startup]]>
            </title>
            <description>
<![CDATA[
Score 124 | Comments 98 (<a href="https://news.ycombinator.com/item?id=26176940">thread link</a>) | @_query
<br/>
February 17, 2021 | https://alistairb.dev/reflections-on-haskell-for-startup/ | <a href="https://web.archive.org/web/*/https://alistairb.dev/reflections-on-haskell-for-startup/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p>Almost exactly one year ago I quit my job to create a Haskell startup as a solo developer. I had about 20 ideas, but eventually settled on the idea of dependency project health tracking with <a href="https://deadpendency.com/" target="_blank" rel="noopener">Deadpendency</a>.</p>

<p>This post describes the experience and evaluates Haskell and its ecosystem.</p>

<p><small>Disclaimer: This blog post contains a bunch of memes. They are trying to be humorous, not accurate or fair 😉.</small></p>

<h2 id="why-haskell">Why Haskell?</h2>

<p>Since about 2016 I have had a strong <del>obsession</del> love of Haskell. Prior to learning Haskell, I was an experienced OO style developer but I didn’t really know how to keep improving my raw programming ability. Haskell introduced me to the world of functional programming (FP) which has an almost infinite depth of concepts to learn, which do actually help improve code quality and application architecture.</p>

<p><img width="400" src="https://i.imgflip.com/4x9eeq.jpg" alt="I should learn functional programming meme"></p>

<p>Haskell is challenging to learn, but extremely fun to write. For my own learning and pleasure, if my startup succeeds, I want to be doing Haskell.</p>

<p>Additionally, I think Haskell is the best general purpose programming language (that you can use in production). In particular, Haskell excels at writing ‘boring’ business applications which is typically what I work on. <a href="https://www.foxhound.systems/blog/why-haskell-for-production/" target="_blank" rel="noopener">‘Why Haskell For Production’</a> goes into more detail on the benefits Haskell offers.</p>

<p><img width="400" src="https://i.imgflip.com/4x9fwz.jpg" alt="Haskell is the best change my mind meme"></p>

<h2 id="the-setup-phase">The Setup Phase</h2>

<p>Probably the most challenging part was building out a skeleton architecture to hang my business logic on. I decided to go with, even within Haskell, fairly advanced libraries of <a href="https://docs.servant.dev/en/stable/" target="_blank" rel="noopener"><code>servant</code></a> and <a href="https://hackage.haskell.org/package/fused-effects" target="_blank" rel="noopener"><code>fused-effects</code></a>.</p>

<p>I spent a fair amount of time banging my head against a wall trying to get these libraries to work nicely together. This was primarily from a lack of Haskell ability on my part. I had prepared as best I could, but Haskell is deep and I needed to learn more to work day to day with it. I was lucky enough to eventually find <a href="https://github.com/mitchellwrosen/hspolls" target="_blank" rel="noopener">an example</a> that marries these two libraries together, which was a life saver. I’m sure I would have gotten there eventually, but I was in a bit over my head at that point.</p>

<p><img width="400" src="https://i.imgflip.com/4x9j14.jpg" alt="Haskell with servant fused-effects is hard meme"></p>

<p>Haskell is awesome, but like most languages there is cruft and legacy to be avoided. Haskell has a standard library known as <a href="https://hackage.haskell.org/package/base" target="_blank" rel="noopener"><code>base</code></a> which unfortunately has a fair amount of unsafe or unperformant functions included. As such I went with an alternative standard library <a href="https://hackage.haskell.org/package/relude" target="_blank" rel="noopener"><code>relude</code></a> that builds on and improves <code>base</code>. On top of this, there are many core libraries that are not part of the standard library I wanted to use and have nice patterns around.</p>

<p>Additionally, I was <a href="https://alistairb.dev/haskell-on-google-cloud-is-great">deploying to google cloud</a> and so needed to figure out good patterns for that integration from Haskell.</p>

<p>This setup effort was quite challenging. I spent most of it squinting at compiler errors. Yet it only took about 2 weeks to have a good foundation of code to start building my business logic upon.</p>

<h2 id="building-it-out">Building it Out</h2>

<p>This is when it started to get really fun. I had my core patterns set out and I could focus on building a pipeline. The day in day out of writing out my logic as small pure functions that I composed together was very nice.</p>

<p>Haskell has such impressive auto-magic code generation techniques that you spend much more time focused on the interesting logic of your application rather than boilerplate.</p>

<div><div><pre><code><span>data</span> <span>HappinessLevel</span> <span>=</span>
    <span>Miserable</span>
  <span>|</span> <span>Sad</span>
  <span>|</span> <span>Average</span>
  <span>|</span> <span>Happy</span>
  <span>|</span> <span>HaskellDeveloper</span>
  <span>deriving</span> <span>(</span><span>Show</span><span>,</span> <span>Eq</span><span>,</span> <span>Ord</span><span>,</span> <span>Bounded</span><span>,</span> <span>Enum</span><span>,</span> <span>ToJSON</span><span>,</span> <span>FromJSON</span><span>)</span> <span>-- magic code generation</span>

<span>-- ok not really magic, think 'convention over configuration'</span>
<span>-- where you can have generated sane defaults, or customise if you like</span>
</code></pre></div></div>

<p>And personally I think Haskell is quite beautiful to read and write. #notbiased</p>

<h3 id="parsing-libraries">Parsing Libraries</h3>

<p>A lot of the logic of Deadpendency is parsing. Either parsing dependency files or parsing various API responses. Haskell has many excellent parsing libraries, most notably <a href="https://hackage.haskell.org/package/aeson" target="_blank" rel="noopener"><code>aeson</code></a> for JSON.</p>

<p>Why is this nice in Haskell? The ‘monad’ abstraction is excellent for dealing with code with a lot of failure conditions (ie. parsing) and avoids ‘pyramid of doom’ type code. Haskell worked out really well in this key area.</p>

<p><img width="400" src="https://alistairb.dev/images/hadouken.jpeg" alt="Pyramid of doom meme"></p>

<h3 id="testing">Testing</h3>

<p>Another strong positive for writing Deadpendency was testing. Haskell has a lesser-known style of testing libraries that do ‘property based testing’ (PBT).</p>

<p>PBT allows you to write value generators for your data types, which you use to generate 100s or 1000s of test cases. Then, you run these generated values against some function and check that certain properties hold.</p>

<p>For example, part of the Deadpendency logic is generating an HTML report at the end. I had some <code>toHtml :: Report -&gt; HTML</code> function that I wanted to test. So I wrote a <code>fromHtml :: HTML -&gt; Report</code> function where it goes the other way (ok writing that was pretty painful). Then my PBT test will generate 100s of <code>Report</code> values and check that <code>report == fromHtml (toHtml report)</code> (this is known as ‘roundtrip testing’). With this single test I was able to find many edge case bugs with my HTML report generation logic.</p>

<p><img width="400" src="https://i.imgflip.com/4x9tqj.jpg" alt="Haskell with servant fused-effects is hard meme"></p>

<p>PBT exists in some other languages, but it originated (I believe?) in Haskell so the libraries are excellent.</p>

<h3 id="not-actively-maintained-libraries">Not Actively Maintained Libraries</h3>

<p>A big challenge of working with Haskell was the lack of well-maintained libraries. Ironically, of the 75 (!) packages I depend upon 19 are flagged by Deadpendency as unhealthy (deprecated or inactive). This means I often don’t have the luxury of asking library maintainers to fix bugs. Even if I PR a fix, sometimes that PR will be ignored for months.</p>

<p>This I think is the reality of using a niche language like Haskell. To be clear, I do not think library developers owe me anything, but it is nonetheless a downside when compared to more popular languages.</p>

<p><img width="400" src="https://i.imgflip.com/4x9xjq.jpg" alt="Haskell not actively maintained meme"></p>

<p>Thankfully Haskell build tools have good support for loading a package from git. This means you can PR some bug fix or feature and immediately use your fork to work around the problem.</p>

<h3 id="compile-times-were-fine">Compile Times.. Were Fine</h3>

<p>I thought I’d call this out as it is a common complaint I see around Haskell. I followed some <a href="https://www.parsonsmatt.org/2019/11/27/keeping_compilation_fast.html" target="_blank" rel="noopener">good advice</a> which kept compilation fast (aside from <a href="https://twitter.com/AlistairBuzz/status/1253507016242294784" target="_blank" rel="noopener">one interesting edge case I resolved</a>).</p>

<ul>
  <li>Number of modules (Haskell source files) - 509</li>
  <li>Number of lines of Haskell - 20090</li>
  <li>Number of dependencies - 75</li>
  <li>Dell 9570 XPS Laptop - (Hex core - 8th-gen Intel Core i7-8750H CPU), 32GB memory</li>
</ul>

<p>So what are the numbers?</p>

<h4 id="compile-dependencies-from-scratch">Compile dependencies from scratch</h4>

<p>Time: 17m44s</p>

<p>This is compiling all application dependencies, which needs to be done before you can compile your application code. Rebuilding all from scratch rarely happens as both my dev machines and CI will cache and only rebuild what has changed.</p>

<p>You do sometimes update a very core package which triggers a lot of dependent packages to recompile which can take a while. Although, I usually do dependency updates at the start of the day while I’m sipping my coffee, so usually don’t notice.</p>

<h4 id="compile-app-including-tests-in-development">Compile app (including tests) in development</h4>

<p>Time: 1m1s</p>

<p>Likewise, due to caching a full recompilation rarely happens. As such, most code edits do not trigger many modules to be recompiled and it is fast.</p>

<p>Additionally, Haskell has nice ‘continuous compilation’ tools that fire on save. Usually by the time I actually look at my terminal compilation is already done.</p>

<h4 id="compile-app-for-deployment">Compile app for deployment</h4>

<p>with <a href="https://downloads.haskell.org/~ghc/latest/docs/html/users_guide/using-optimisation.html" target="_blank" rel="noopener">full optimisations</a> (-02).</p>

<p>Time: 2m53s</p>

<p>This typically runs in CI. It runs in parallel with a host of other checks such as running my tests, which also take a few minutes. Due to this, the time doesn’t really impact the build + deploy time too much.</p>

<p><img width="400" src="https://i.imgflip.com/4xp4zu.jpg" alt="Compile times meme"></p>

<h3 id="refactoring-pain">Refactoring Pain</h3>

<p>Deadpendency is relatively simple in what it does, but there is a lot of hidden complexity to the problem. Which is to say, it is like 99% of applications 😉. When developing it I was constantly realising I had modelled things a bit too simplistically and would need to refactor.</p>

<p>Haskell is very safe to refactor thanks to the type safety the compiler brings, which is probably the most important thing. However, Haskell does not have great tools to help with refactoring, at least in terms of the restructuring changes I kept making. The <a href="https://hackage.haskell.org/package/apply-refact" target="_blank" rel="noopener">existing</a> <a href="https://hackage.haskell.org/package/retrie" target="_blank" rel="noopener">tools</a> seem more geared towards complex rewriting of common code, not restructuring modules or renaming identifiers.</p>

<p>As such I did it all manually with text search replace, or just change something and fix all the new compiler errors. This was a bit of a grind and it caused me to delay needed refactoring sometimes.</p>

<p>It’s a pity Haskell doesn’t have the refactoring tools to help in this situation. The dream would be these tools integrated into an IDE.</p>

<p><img width="400" src="https://i.redd.it/dbdshzzflgd31.jpg" alt="Haskell had an IDE meme"></p>

<p>(Stolen from <a href="https://www.reddit.com/r/ProgrammerHumor/comments/cjtbfj/society_if_haskell_has_ide/" target="_blank" rel="noopener">reddit</a>)</p>

<p>Having said that, it should be noted that Haskell does have an excellent IDE now in the form of <a href="https://github.com/haskell/haskell-language-server" target="_blank" rel="noopener">Haskell Language Server</a> (HLS). The momentum around the project is insane and I applaud the developers. One fixed pain point from HLS is it does auto imports now, which used to greatly contribute to the friction of working with Haskell. I’m sure Haskell will get there eventually.</p>

<h3 id="waiting-for-new-ghc-versions-to-be-usable">Waiting for New GHC Versions to be Usable</h3>

<p>This is mostly me complaining for the sake of it, but as someone pretty obsessed with both new shiny versions of things and Haskell, waiting for new GHC (GHC is the Haskell compiler) versions to be usable has been painful. There is a long tail of libraries and platforms that need to be updated before I can use a new GHC version. Sometimes these updates can drag a lot.</p>

<p>For example GHC 9 was just released, but I still haven’t been able to upgrade to GHC 8.10 yet which was first released in March 2020.</p>

<p><img width="500" src="https://i.imgflip.com/4xebid.jpg" alt="GHC releases meme"></p>

<h2 id="launching">Launching</h2>

<p>So after about 8 months of work I was ready to start getting users. I slowly soft launched, promoting it in a few small channels. How did my Haskell fair in prod?</p>

<h3 id="very-few-logic-bugs">Very Few Logic Bugs</h3>

<p>My core Haskell had very few logic bugs. This is because Haskell is very safe by default and I had opted into strict types that help catch edge cases.</p>

<p>For example, I was using a lot of <a href="https://hackage.haskell.org/package/base-4.14.1.0/docs/Data-List-NonEmpty.html" target="_blank" rel="noopener"><code>NonEmpty</code></a> lists which the compiler will guarantee is not empty. To use them you must specify how to handle the empty case. ie. what do I do if Deadpendency can’t find any dependencies to check?</p>

<p>And of course, I had …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://alistairb.dev/reflections-on-haskell-for-startup/">https://alistairb.dev/reflections-on-haskell-for-startup/</a></em></p>]]>
            </description>
            <link>https://alistairb.dev/reflections-on-haskell-for-startup/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26176940</guid>
            <pubDate>Thu, 18 Feb 2021 07:17:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[TLS certificates specifying hosts via the CommonName field is more or less gone]]>
            </title>
            <description>
<![CDATA[
Score 70 | Comments 22 (<a href="https://news.ycombinator.com/item?id=26176448">thread link</a>) | @zdw
<br/>
February 17, 2021 | https://utcc.utoronto.ca/~cks/space/blog/tech/TLSCertificateCNMostlyGone | <a href="https://web.archive.org/web/*/https://utcc.utoronto.ca/~cks/space/blog/tech/TLSCertificateCNMostlyGone">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><h2>TLS certificates specifying hosts via their CommonName field is more or less gone</h2>

	<p><small>February 17, 2021</small></p>
</div><div><p><a href="https://en.wikipedia.org/wiki/Transport_Layer_Security">TLS</a>
certificates for hosts and domains must somehow identify what
hostname (or names) they're for. Historically <a href="https://utcc.utoronto.ca/~cks/space/blog/tech/TLSCertificatesNamingHosts">there have been two
ways to do this</a>. The first way was a
specific sub-field, the <em>CN</em> or CommonName, of the certificate's
overall <em>Subject Name</em>. This had the problem that it could only
have one name. When people started wanting to have TLS certificates
that covered more than one name, they invented another mechanism,
the <em>Subject Alternative Name</em> (SAN) extension.</p>

<p>As a practical matter, all vaguely modern software that wants to
properly validate TLS certificates has supported (and often preferred)
Subject Alternative Names for some time. A great many TLS certificates
in the wild are for multiple hosts and it's generally unlikely that the
host you're connecting to is the one name that the system chose to put
in the CN field; software that only supports CN cannot validate those
TLS certificates. As a matter of timing, SANs have been theoretically
mandatory since 2002 and checking only SANs has been theoretically
required since 2011 (which means that since 2011 or earlier, the CN was
supposed to always be one of the SANs).</p>

<p>These days, any remaining support for looking at TLS certificate
CommonName to validate TLS certificates is getting more and more
extinct (and more so than I expected when I started writing this
entry). In the browser realm, <a href="https://www.chromestatus.com/feature/4981025180483584">Chrome apparently turned it off in
58, released in 2017</a>, and then
threw out the option to check it again in Chrome 65 (from the comment
on <a href="https://utcc.utoronto.ca/~cks/space/blog/tech/TLSCertificatesNamingHosts">my old entry</a>, which was ironically
written shortly before Chrome did this). Firefox is said to have
removed support in version 48, from August of 2016. <a href="https://support.apple.com/en-ca/HT210176">Safari
apparently stopped looking at CommonName in iOS 13 and macOS 10.15</a>, which I believe date
from late 2019. <a href="https://go-review.googlesource.com/c/go/+/231379">This Go change</a> also talks about
how browsers removed it in 2019 ('last year' for a mid 2020 change).</p>

<p>In non-browser TLS code, Go started ignoring CN by default in
Go 1.15 (released in August of 2020) and this will be the only
option starting in Go 1.17 (to be released in August of 2021),
per <a href="https://golang.org/doc/go1.16#crypto/x509">here</a>. Since
Firefox doesn't support CN any more, I assume that <a href="https://en.wikipedia.org/wiki/Network_Security_Services">NSS</a> doesn't
either, since NSS is basically Firefox's underlying TLS implementation.
I have no idea what other TLS libraries are doing, but I would expect
that many of them will support CommonName for some time to come; TLS
libraries are historically behind browser practices.  Hopefully they
are all following the 2011 requirement to check only SANs when SANs are
present (which they should always be in public certificates).</p>

<p>Probably TLS certificates will continue to contain CommonName fields
for a long time to come. Having a <em>Subject Name</em> in general is
common (although apparently not actually required) and the CN is a
standard (although not required) part of the Subject Name, so you
might as well throw it in. Even Mozilla and Let's Encrypt (still)
have TLS certificates with CNs. However, since I checked this now,
the current <a href="https://cabforum.org/">CA/Browser Forum</a> <a href="https://cabforum.org/baseline-requirements-documents/">baseline
requirements</a>
(version 1.7.3) allow but don't require CommonName (section 7.1.4.2.2,
which says that it's 'discouraged, but not prohibited'). Given how
conservative most Certificate Authorities are, I expect them to be
issuing TLS certificates with CommonName fields until they're
required to stop.</p>

<p>(An interested party could scan Certificate Transparency logs to see if
there were very many issued certificates without CNs. Probably there are
some; someone must have tried it out at some point through an official
CA.)</p>

<p>PS: <a href="https://no-common-name.badssl.com/">no-common-name.badssl.com</a>
has a TLS certificate without a CN, or at least it's supposed to
(<a href="https://community.letsencrypt.org/t/how-to-obtain-a-cert-without-a-common-name/72807/6">via</a>),
but the TLS certificate is expired right now as I write this entry
so it's hard to test how client software behaves. <a href="https://community.letsencrypt.org/t/compatibility-testing-of-no-common-name/72863">See also</a>,
which pointed me to <a href="https://no-subject.labs.vu.nl/">no-subject.labs.vu.nl</a>,
which has a currently valid TLS certificate with no <em>Subject Name</em> at all.</p>
</div></div>]]>
            </description>
            <link>https://utcc.utoronto.ca/~cks/space/blog/tech/TLSCertificateCNMostlyGone</link>
            <guid isPermaLink="false">hacker-news-small-sites-26176448</guid>
            <pubDate>Thu, 18 Feb 2021 05:54:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[40 Year History of Opposition to Nuclear Power in California]]>
            </title>
            <description>
<![CDATA[
Score 47 | Comments 40 (<a href="https://news.ycombinator.com/item?id=26175253">thread link</a>) | @Lammy
<br/>
February 17, 2021 | https://www.energy-net.org/01NUKE/CALIF.HTM | <a href="https://web.archive.org/web/*/https://www.energy-net.org/01NUKE/CALIF.HTM">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div width="49%"> 
	  <p><span face="Verdana, Arial, Helvetica, sans-serif" size="2" color="#CC6600"><b><span size="3" color="#000000">40 
		Year History of Opposition to Nuclear Power in California </span></b></span> 
		<br>
	  </p>
	  <p><span face="Verdana, Arial, Helvetica, sans-serif" size="2">California 
		citizens have made a unique stand concerning the attempts by Nuclear proponents 
		to make the state a premiere model for commercial nuclear energy. California's major 
		utilities, in particular Pacific Gas and Electric (PG&amp;E) has spent an
		enormous amount of money and political muscle in attempts to build reactors 
		across California but have mostly failed. PG&amp;E was supposedly involved in 
		the Atoms for Peace proposal made in 1953 and was 
		part of a coalition of american utilities that investigated the technical 
		potentials for building nuclear reactors as a source of electricity.</span></p>
	  <p><span face="Verdana, Arial, Helvetica, sans-serif" size="2">The following 
		is a brief summary of the battles against nuclear power that started here 
		in California in 1958.</span></p>
	  <p><span face="Verdana, Arial, Helvetica, sans-serif" size="2">Northern 
		California is the home of the first successful opposition to the promotion 
		and development of commercial nuclear reactors in the U.S. In the 1950's 
		northern and central California's privately Owned utility company, PG&amp;E 
		was planning to be one of the giants in the new field of nuclear energy. 
		It had helped design and build the Dresden I reactor in Illinois with 
		a consortium of 5 major companies, including General Electric(GE).</span></p>
	  <p><span face="Verdana, Arial, Helvetica, sans-serif" size="2">In conjunction 
		with GE, it built the vallecitos nuclear complex south of San Francisco 
		and then went it alone with their Humboldt reactor near Arcata. But their 
		luck took a turn for the worse when they tried to build the world's largest 
		nuclear facility 1000 feet from the fault that caused the 1906 earthquake.</span></p>
	  <p><span face="Verdana, Arial, Helvetica, sans-serif" size="2">Yes, PG&amp;E 
		even said they could build a reactor in downtown San Francisco! In 
		fact they were planning the construction of 63 reactors in California 
		during the early 1960's, one every 25 miles along the coast They even 
		 planned to build a floating reactor!!</span></p>
	  <h2><span face="Verdana, Arial, Helvetica, sans-serif" size="2"><b>The 
		Bodega Bay Duck Pond</b><br>
		</span></h2>
	  <p><span face="Verdana, Arial, Helvetica, sans-serif" size="2">When PG&amp;E 
		started pushing plans to build the reactors at Bodega Pay in 1958 a literal 
		groundswell of opposition erupted during the next 6 years to stop them 
		dead cold. The site they had chosen near the San Andreas Fault Zone was 
		just a few miles from the epicenter of the Great San Francisco Quake where 
		ground shifts of over 20 feet had occurred in 1906.</span></p>
	  <p><span face="Verdana, Arial, Helvetica, sans-serif" size="2">PG&amp;E's 
		unethical plans to build the reactor is not new for this company, as they 
		have a history of unfair tactics that goes back to the company's birth. 
		Upon deciding that the Bodega Headlands would be an excellent site for the largest nuclear 
		facility in the world, PG&amp;E simply beat the state out in its plans 
		to make the area a state park. </span></p>
	  <p><span face="Verdana, Arial, Helvetica, sans-serif" size="2">The battle 
		started in 1958 when the Santa Rosa Press Democrat published the first 
		story on PG&amp;E's plans. The company's ignored their own geologist, who had warned 
		that the area was likely to be effected by strong shaking during a quake. 
		Concerned citizens started getting involved as PG&amp;E refused to acknowledge 
		publicly that they were actually going to build nuclear reactors at the 
		proposed site.</span></p>
	  <p><span face="Verdana, Arial, Helvetica, sans-serif" size="2">The 1957 
		windscale accident in England, where a small reactor had burned out of 
		control for more than a day, helped focus concerns about safety on this 
		new idea of nuclear power.</span></p>
	  <p><span face="Verdana, Arial, Helvetica, sans-serif" size="2">In 1961, 
		after nearly 3 years of pushing their plan behind the scenes, PG&amp;E 
		announced plans to build the Atomic Park at the Bodega site. The ensuing battle 
		and PG&amp;E's nasty style started to backfire though as public concerns 
		grew.</span></p>
	  <p><span face="Verdana, Arial, Helvetica, sans-serif" size="2">Major opposition 
		came from within the ranks of the Sierra Club, but the board refused to 
		allow its active members the right to oppose the reactors on the issue 
		of earthquakes. When it came out that PG&amp;E had doctored fault maps 
		of the site, all hell broke loose.</span></p>
	  <p><span face="Verdana, Arial, Helvetica, sans-serif" size="2">One of PG&amp;E's 
		major claims at the time was that they could build reactors that would 
		survive a great Earthguake. At one point they said that the reactors could 
		survive a quake 50 per cent bigger than the O6' quake by floating the 
		reactors on 3 feet of compressable material but when the public and the 
		Atomic Energy Commission (AEC) got a close-up view of the devastation 
		from the air of the quake in Alaska during the spring of 1964, support 
		for the reactor complex dried up.</span></p>
	  <p><span face="Verdana, Arial, Helvetica, sans-serif" size="2">Opponents 
		had "infiltrated" the federal government and were pushing 
		for closure. With the disclosure of the AEC's WASH 740 report, which documented 
		potential dangers to the bay area residents in case of an accident, opposition 
		finally reached all government levels.</span></p>
	  <p><span face="Verdana, Arial, Helvetica, sans-serif" size="2">California 
		governor Pat Brown asked that PG&amp;E abandon the reactors. Two days 
		later PG&amp;E caved in and called the project off. The battle ended in 
		1964 with a $7 million duck pond as a living monunent to the future. (It 
		is still there today)</span></p>
	  <p><span face="Verdana, Arial, Helvetica, sans-serif" size="2">This experience 
		gave PG&amp;E a deadly lesson on how to overcome public concerns at their 
		next reactor site--Diablo Canyon.</span></p>
	  <h2><span face="Verdana, Arial, Helvetica, sans-serif" size="2"><b>The 
		Diablo Canyon Nightmare:</b><br>
		</span></h2>
	  <p><span face="Verdana, Arial, Helvetica, sans-serif" size="2">The 25 year 
		battle over Diablo Canyon is a classic case of courage in the face of 
		the political power this utility unleashed in its drive to build a major 
		nuclear facility in California.</span></p>
	  <p><span face="Verdana, Arial, Helvetica, sans-serif" size="2">PG&amp;E's 
		plans to build a mega facility shifted south to the less populated coastal 
		area near San Luis Obispo. The company purchased the Nipomo Dunes and 
		told environmental leaders that unless an acceptable site was chosen that 
		they would go ahead and build a facility at the popular beach area. The 
		wife of the Sierra Club president was selected to come up with an acceptable 
		site in secrecy with the company. </span></p>
	  <p><span face="Verdana, Arial, Helvetica, sans-serif" size="2">The site 
		chosen, Diablo Canyon, was California's second to last coastal wilderness 
		area, an area that had been proposed as a National Park due to its beauty. 
		Besides being a sacred Chumash burial ground, it was the home of one of 
		a kind 1,000 year old Oak trees (the largest in the world). It was also 
		the home of one of the state's largest populations of abalone and sea 
		otters.</span></p>
	  <p><span face="Verdana, Arial, Helvetica, sans-serif" size="2">In the process 
		of getting permission to go ahead with Diablo, PG&amp;E suceeded in selling 
		the site to key members of the Sierra Club's board of directors. The Utility 
		had sympathetic board members flown over the Diablo site in Frank Sinatra's 
		Lear jet, with entertainment by Danny Kaye (Danny later came out against 
		the reactors).</span></p>
	  <p><span face="Verdana, Arial, Helvetica, sans-serif" size="2">The first 
		slam-dunk by PG&amp;E came against the local farmer who had the right 
		of way access rights over the Diablo property. The company went to court 
		and had his rights removed. The beligerant act made the man a life-long 
		opponent of PG&amp;E's plan.</span></p>
	  <h2><span face="Verdana, Arial, Helvetica, sans-serif" size="2"><b>PG&amp;E 
		gets Cozy with Sierra Club Board Members</b><br>
		</span></h2>
	  <p><span face="Verdana, Arial, Helvetica, sans-serif" size="2">The biggest 
		tactical plan was to focus on the Sierra Club. The company and the electric 
		industry already had the board's ear with their claims that nuclear power 
		could reduce air pollution that was caused by coal power plants. The utility, 
		with inside help then sought official support for Diablo Canyon when club's 
		only board member who knew about the site's natural value was in Europe. 
		The board went along with PG&amp;E, and in fact voted to block any Club 
		members or chapters opposition to the facility. This move enraged David 
		Brower, eventually resulting in the split up of the club and the creation 
		of Friends of the Earth by embittered Sierra Club members who were angered 
		by the actions of key Sierra Club Board members.</span></p>
	  <p><span face="Verdana, Arial, Helvetica, sans-serif" size="2">PG&amp;E's 
		success within the Sierra Club was the culmination of 2 years of behind 
		the scenes work by Doris Leonard. She was the wife of the president of 
		the club. Her role in exchanging the Nipomo Dunes site for Diablo Canyon 
		was rewarded later when she was elected to PG&amp;E's board of directors. 
		</span></p>
	  <p><span face="Verdana, Arial, Helvetica, sans-serif" size="2">The Sierra 
		Club refused to allow its local chapter near Diablo to use the club nane 
		in opposing the five proposed reactors at the site. The group was forced 
		to take on another name in 1966, the Shoreline Preservation Conference.</span></p>
	  <p><span face="Verdana, Arial, Helvetica, sans-serif" size="2">The group 
		was concerned about earthquake faults along the coast as locals were fully 
		aware of the 1927 quake that completely destroyed a nearby city. They 
		called for a full investigation into potential fault areas. Their efforts 
		were ignored by the government and the media.</span></p>
	  <p><span face="Verdana, Arial, Helvetica, sans-serif" size="2">News of the 
		reactor siting was poorly covered by the Bay area's conservative media, 
		a tactic that made the issue invisible to bay area residents who had stopped 
		PG&amp;E's Bodega reactor plans.</span></p>
	  <p><span face="Verdana, Arial, Helvetica, sans-serif" size="2">Oil companies 
		chart the Hosgri Fault The Hosgri fault had been mapped by Shell oil geologists 
		during the 1960's, but not published until 1970. PG&amp;E claims to have 
		not found out about the fault until late 1972. The information was finally 
		publicized in November 1973 by an investigative reporter in Los Angeles. 
		In a suspicious turn of events, the lawyer who had been fighting the case 
		since 1965 was found dead in his car just after the announcement. Authorities 
		claimed it was suicide, with no other investigation to follow up.</span></p>
	  <p><span face="Verdana, Arial, Helvetica, sans-serif" size="2">P&amp;GE's 
		bad memories of Bodega Bay helped fuel their push to ignore earthquake 
		concerns at Diabl Canyon. The same Seismic experts who had been involved 
		with the Bodega Bay facility were brought in to review the site for seismicity. 
		They pointed out major flaws in PG&amp;E's own $2,000 seismic study. A 
		state of the art study at the time would have cost $100,000)</span></p>
	  <h2><span face="Verdana, Arial, Helvetica, sans-serif" size="2"><b>The 
		Hosgri Fault Forces PG&amp;E to Rebuild Diablo Again</b><br>
		</span></h2>
	  <p><span face="Verdana, Arial, Helvetica, sans-serif" size="2">A storm of 
		controversy erupted around the facility as one of the units was reaching 
		completion. Even with the help of the Nuclear Regulatory Commission's 
		(NRC) predecessor, the AEC, PG&amp;E was finally forced after 3 years 
		of federal in-fighting to rebuild seismic bracing in 1976.</span></p>
	  <p><span face="Verdana, Arial, Helvetica, sans-serif" size="2">In attempts 
		to stop a seismic retrofit, PG&amp;E even coined the Tao Effect which 
		said that the bigger the structure, the less damage a quake would have.</span></p>
	  <p><span face="Verdana, Arial, Helvetica, sans-serif" size="2">Seismic experts 
		for the concerned activists remained uninpressed, …</span></p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.energy-net.org/01NUKE/CALIF.HTM">https://www.energy-net.org/01NUKE/CALIF.HTM</a></em></p>]]>
            </description>
            <link>https://www.energy-net.org/01NUKE/CALIF.HTM</link>
            <guid isPermaLink="false">hacker-news-small-sites-26175253</guid>
            <pubDate>Thu, 18 Feb 2021 03:28:15 GMT</pubDate>
        </item>
    </channel>
</rss>
