<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 20]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 20. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Sun, 04 Oct 2020 12:32:08 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-20.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Sun, 04 Oct 2020 12:32:08 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[Flatpak: A security nightmare – two years later]]>
            </title>
            <description>
<![CDATA[
Score 69 | Comments 13 (<a href="https://news.ycombinator.com/item?id=24661126">thread link</a>) | @krimeo
<br/>
October 2, 2020 | https://www.flatkill.org/2020/ | <a href="https://web.archive.org/web/*/https://www.flatkill.org/2020/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">


<p>Two years ago I <a href="https://flatkill.org/">wrote</a> about then heavily-pushed Flatpak, self-proclaimed "Future of Apps on Linux". The article criticized the following three major flows in Flatpak:</p><ul>
<li>Most of the apps have full access to the host system but users are misled to believe the apps are sandboxed
</li><li>The flatpak runtimes and apps do not get security updates
</li><li>Flatpak breaks many aspects of desktop integration
</li></ul>

<!-- <p>A lot has changed in the 2 years (the company behind Flatpak is now just another IBM's brand for one thing) so let's see how Flatpak developers addressed these fundamental issues.</p> -->
<p>So let's see how Flatpak developers addressed these fundamental issues.</p>

<h2>The sandbox is STILL a lie</h2>

<p>Almost all popular apps on Flathub still come with <span>filesystem=host</span> or <span>filesystem=home</span> permissions, in other words, <b>write access to the user home directory</b> (and more) so all it takes to escape the sandbox is trivial <span>echo download_and_execute_evil &gt;&gt; ~/.bashrc</span>. That's it.</p>


<p>The most popular applications on Flathub still suffer from this - Gimp, VSCodium, PyCharm, Octave, Inkscape, Audacity, VLC are still not sandboxed.</p>

<p>And, indeed, users are still mislead by the reassuring blue "sandboxed" icon. Two years is not enough to add a warning that an application is <b>not</b> sandboxed if it comes with dangerous permissions (like full access to your home directory)? Seriously?</p>

<img src="https://www.flatkill.org/2020/sandboxlie.png" alt="sandboxlie">

<h2>Flatpak apps and runtimes STILL contain long known security holes</h2>
<p>It took me about 20 minutes to find the first vulnerability in a Flathub application with full host access and I didn't even bother to use a vulnerability scanner.</p>

A perfect example is <a href="https://www.cvedetails.com/cve/CVE-2019-17498">CVE-2019-17498</a> with public exploit <a href="https://github.com/github/securitylab/tree/main/SecurityExploits/libssh2/out_of_bounds_read_disconnect_CVE-2019-17498">available</a> for some 8 months. The first app on Flathub I find to use libssh2 library is Gitg and, indeed, it does ship with unpatched libssh2.

<p>But is it just this one application? Let's look at the <b>official runtimes</b> at the heart of Flatpak (org.freedesktop.Platform and org.gnome.Platform <b>3.36</b> - as of time of writing used by most of the applications on Flathub). The first unpatched vulnerable dependency I found in the offical runtime is ffmpeg in version 4.2.1 with no security patches backported, <a href="https://www.cvedetails.com/cve/CVE-2020-12284">CVE-2020-12284</a>.</p><p>Recently I stumbled upon an article from 2011 which started what is today known as flatpak, <a href="https://people.gnome.org/~alexl/glick2">in the words of the project founder:</a></p>

<p><a href="https://people.gnome.org/~alexl/glick2"><b><i>"Another problem is with security (or bugfix) updates in bundled libraries. With bundled libraries its much harder to upgrade a single library, as you need to find and upgrade each app that uses it. Better tooling and upgrader support can lessen the impact of this, but not completely eliminate it."</i></b></a></p>

<p>After reading that it comes as no surprise flatpak still suffers from the same security issues as 2 years ago because flatpak developers knew about these problems from the beginning.</p>

<h2>Local root exploits are NOT considered a minor issue anymore!</h2>
<p>Great! Two years ago I wrote about a trivial local root exploit using flatpak to install suid binaries (<a href="https://www.cvedetails.com/cve/CVE-2017-9780/">CVE-2017-9780</a>) and how it was downplayed by Flatpak developers as a minor security issue <a href="https://github.com/flatpak/flatpak/releases/tag/0.8.7">here</a>. I am happy to see at least the attitude to local root exploits has changed and today <a href="https://github.com/containers/bubblewrap/security/advisories/GHSA-j2qp-rvxj-43vj">local root exploits</a> are considered high severity.

</p><h2>Desktop integration</h2>
<p>System and user fonts are now available to flatpak applications and basic font rendering settings are respected as well, however do not expect your changes in /etc/fonts, typically setting a proper fallback font for CJK characters, to work with flatpak.  KDE applications in flatpak are still ignoring themes, fonts and icon settings (tested with Qt5ct). Applications installed from the distribution sources do not have these problems, of course. <a href="https://www.flatkill.org/2020/desktopbrokenation.mp4">A quick screen capture to demonstrate</a>.</p>

<p>More importantly, fcitx, <i>the</i> IME for Chinese is still broken - it has been 2 years. Here is the <a href="https://github.com/flatpak/flatpak/issues/2031">issue</a> I linked 2 years ago - especially of interest is <a href="https://github.com/flatpak/flatpak/issues/2031#issuecomment-655134889">the following comment</a> directly from fcitx developer:

</p><p><i>"Because fcitx im module in flatpak is from 4.2.97 and using a different dbus object path. <b>It need to be the same version of fcitx on your host</b>."</i></p>

So I need to run multiple fcitx daemons on my desktop and switch between them as I switch flatpak apps depending on which fcitx libraries are bundled with that app or maybe in the future of linux apps it's not possible to type chinese anymore and it's fine?

<p>While the "bundle everything" approach has proven very useful on servers it clearly does not work for desktop applications, let's keep linking system libraries in desktop applications (and use the bundled libraries as a fallback only) to avoid introducing all these problems to Linux desktop.</p>



</div>]]>
            </description>
            <link>https://www.flatkill.org/2020/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24661126</guid>
            <pubDate>Fri, 02 Oct 2020 10:35:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Please Stop Imposing American Views about Race on Us]]>
            </title>
            <description>
<![CDATA[
Score 297 | Comments 214 (<a href="https://news.ycombinator.com/item?id=24660682">thread link</a>) | @dgellow
<br/>
October 2, 2020 | https://www.persuasion.community/p/please-stop-imposing-american-views | <a href="https://web.archive.org/web/*/https://www.persuasion.community/p/please-stop-imposing-american-views">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><a target="_blank" href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fe3a4a8fb-963e-4611-8bc2-448a875dfb14_5184x3456.jpeg"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fe3a4a8fb-963e-4611-8bc2-448a875dfb14_5184x3456.jpeg" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/e3a4a8fb-963e-4611-8bc2-448a875dfb14_5184x3456.jpeg&quot;,&quot;height&quot;:971,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:18107111,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/jpeg&quot;,&quot;href&quot;:null}" alt=""></a></p><p><em>Construction workers reopen Winston Churchill statue in Parliament Square after it was covered with metal panels to protect it against defacement by protestors.</em></p><p>Over the past couple of months, many Britons have imported American discourse on race wholesale. When asked to analyze the experiences of black people in the United Kingdom, we now talk with an American accent.</p><p>Take a look, for instance, at a meme that has been circulating among some of my white friends on Facebook and Instagram:</p><blockquote><p>I have privilege as a White person because I can do all of these things without thinking twice about it … I can go jogging (#AmaudArbery). I can relax in the comfort of my own home (#BothemSean and #AtatianaJefferson). I can ask for help after being in a car crash (#Jonathan Ferrell and #RenishaMcBride). I can have a cellphone (#StephonClark). I can leave a party to get to safety (#JordanEdwards). I can play loud music (#JordanDavis). I can sell CDs (#AltonSterling). I can sleep (#AiyanaJones). I can walk from the corner store (#MikeBrown).</p></blockquote><p>The post goes on and on, like an interminable spoken-word poem. All the individuals listed are American, but most of the people who have shared this on my timeline are British. In trying to express their solidarity with black Britons, they are affirming a supposedly transcendental truth: to be black is to live in perpetual terror of being murdered by the state. </p><p>But Britain is not America. And importing American race discourse into the United Kingdom not only prevents us from recognizing the specific ways in which racial injustice manifests in this country—it cloaks the reality of black British lives behind an abstraction that flattens our humanity. </p><p>Britain has a long and painful history of anti-black racism. In the twentieth century alone, the growing black presence led to a long catalogue of abuses: the 1919 race riots in Liverpool, Cardiff and London; the 1958 race riots in Nottingham and Notting Hill; the 1969 police murder of David Oluwale, a Nigerian immigrant who was tortured, pissed on and finally drowned in a river in Leeds. I could list other examples. It is not hard to see why the horrific killing of George Floyd has evoked such strong feelings in this country as well.</p><p>But for all of the country’s flaws, Britain is not America. Trying to understand its racial dynamics through the lens of another country’s does more to obscure than to illuminate the situation that black Britons like myself actually face.</p><p>The average black American in the United States can trace his ancestry further back than the average white American. Most black Americans are descended from enslaved Africans. Their forebears suffered through the segregation and racial terror of the Jim Crow era. The majority of black people in the United Kingdom, by contrast, are immigrants or the children of immigrants. Though many of them have certainly had harrowing experiences with injustice or discrimination, they do not have the same history of racist disadvantage.</p><p>To understand the experience of black Britons, it is not only necessary to grasp how different their history is from that of black Americans: we need to understand the diversity captured by the label “black British.” For example, around two out of every three students with Congolese or Somali origins get free school meals, a standard indicator that their parents are poor. Among students with Nigerian or Ghanaian origins, only one in five do. It is also noteworthy that black Caribbean students are twice as likely to be excluded from school as black African students. </p><p>The discrepancy in educational attainment is just as stark. On average, 58% of black African students graduate from middle school at grade level (defined as achieving A* to C grades at GCSE)—about the same number as white students. But black Caribbean students are significantly less likely to do so—while those whose parents hail from Nigeria actually outperform their white peers by a considerable margin. </p><p>None of this is to disavow the label “black British.” But we need to invest it with the nuance consonant with its reality—and to cast doubt on the idea that every discrepancy in representation must be explained by structural injustice or white supremacy.</p><p>There has, for example, been a lot of concern about the underrepresentation of black Britons in professions like the arts and publishing. But why would you choose to go into theater or journalism—rather than law, medicine or finance—if you are a talented child of ambitious but not well off immigrants? </p><p>This is not a flippant question. While representation can be important, anybody who actually wants to improve the condition of black Britons should at least be a little curious about why they are overrepresented in some prestigious professions and underrepresented in others. In a country in which black people make up only three percent of the population, for example, six percent of junior doctors are black. Would the country—or the black community—really benefit if more black Britons chose to ditch medicine for the theater? The debate is worth having. But in the place of that debate, there have only been pious paeans to diversity.</p><p>The stereotype of the West African parent who wants their child to study law or medicine bears some relation to reality; but the widespread view of black people as perennial victims devoid of agency is a defamatory abstraction. The black person in Britain, like Ralph Ellison’s iconic protagonist, is “invisible because no one wants to see him.”</p><p>So much of the British reaction to the death of George Floyd has constituted a failure of nerve. Desperately seeking to assuage their feelings of guilt, to do <em>something</em>, many Britons have sacrificed their critical faculties to a narrative that does not actually help black people—a narrative that, by reducing us to passive abstractions, only makes us more invisible.</p><p>Racists assume that black people are all the same. Ironically, anti-racists sometimes do so too. But anybody who is truly committed to racial equality needs to recognize that this kind of simplification neither serves justice nor reflects the truth.</p><p><strong>Tomiwa Owolade is a writer who lives in London.</strong></p></div></div>]]>
            </description>
            <link>https://www.persuasion.community/p/please-stop-imposing-american-views</link>
            <guid isPermaLink="false">hacker-news-small-sites-24660682</guid>
            <pubDate>Fri, 02 Oct 2020 09:20:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Interview with Transport Tycoon creator Chris Sawyer]]>
            </title>
            <description>
<![CDATA[
Score 40 | Comments 7 (<a href="https://news.ycombinator.com/item?id=24658958">thread link</a>) | @wizardfeet
<br/>
October 1, 2020 | https://lifeandtimes.games/episodes/files/28 | <a href="https://web.archive.org/web/*/https://lifeandtimes.games/episodes/files/28">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><a href="https://pdcn.co/e/traffic.megaphone.fm/ADL8847793182.mp3" target="_blank">Click/tap here to download this episode.</a></p><p><a href="https://ratethispodcast.com/ltvg" target="_blank"><img src="https://storage.googleapis.com/rtp-assets/buttons/lifetimevideogames.png" width="198" height="56" alt="Rate This Podcast"></a></p>
<p><img alt="A screenshot of the main menu from Transport Tycoon for DOS" src="https://lifeandtimes.games/episodes/files/transport-tycoon-dos-screenshot-main-menu.png" width="276" height="212"></p><p>On the rise and, um...<em>fade out(?)</em> of Chris Sawyer, the genius creator of bestselling, critically-acclaimed simulation games Transport Tycoon and RollerCoaster Tycoon — who made a career out of working at the cutting-edge, in bare metal assembly code that he wrote and optimised (and optimised again) on his own.</p><p>Until the cutting-edge left him behind.</p><p><strong>Hello Hacker News readers! As of this update, the post there erroneously labels this as an interview. It's not. Chris doesn't do interviews, except via an intermediary (which doesn't really work in an audio format), so the story is based entirely on my in-depth research and analysis. I hope you still enjoy it and learn something interesting. (I have stories on many other things that do involve interviews, though, like </strong><strong><a href="https://lifeandtimes.games/episodes/files/27" title="Episodes:27 - Links">1990 golf game Links</a></strong><strong>, Bungie's </strong><strong><a href="https://lifeandtimes.games/episodes/files/25" title="Episodes:25 - Pimps at Sea">fake game Pimps at Sea</a></strong><strong>, and </strong><strong><a href="https://lifeandtimes.games/episodes/files/22" title="Episodes:22 - Wololo">the "Wololo" sound effect</a></strong><strong> from Age of Empires.)</strong></p><p>Chris was only a design consultant on 2004 game RollerCoaster Tycoon 3, but its remastered "Complete" edition has just come out on Nintendo Switch and the PC version is free on the Epic Games Store right now (until October 2). The original two games are also still sold via the likes of Steam and GOG.</p><p>Transport Tycoon, meanwhile, lives on in open-source project <a href="https://www.openttd.org/" target="_blank">OpenTTD</a> and in a mobile port (<a href="https://play.google.com/store/apps/details?id=com.thirtyonex.TransportTycoon&amp;hl=en_US" target="_blank">Android</a>, <a href="https://apps.apple.com/us/app/transport-tycoon/id634013256" target="_blank">iOS</a>) of the original game by Chris's company 31X. You can see a snippet of his source code in the image below:</p><div><p><img alt="cstg_code1" src="https://lifeandtimes.games/episodes/files/cstg_code1.jpg" width="1262" height="1775"></p></div><div><p>Thanks as always to my supporters on Patreon — especially my $10+ backers Carey Clanton, Rob Eberhardt, Simon Moss, Vivek Mohan, Wade Tregaskis, and Seth Robinson. If you'd like to become a supporter, for as little as $1 a month, head to <a href="https://www.patreon.com/lifeandtimesofvideogames">my Patreon page</a> and sign up. Or for one-off donations you can use <a href="https://paypal.me/mossrc">paypal.me/mossrc</a>.</p><p>Please remember to tell other people about the show, and to leave a review by following the links at <a href="https://ratethispodcast.com/ltvg">ratethispodcast.com/ltvg</a>.</p><p>I'm currently writing a new book called Shareware Heroes: Independent Games at the Dawn of the Internet. You can learn more and/or pre-order your copy <a href="https://unbound.com/books/shareware-heroes/" target="_blank">from Unbound</a>.</p></div><hr>
<h3>(Partial) Transcript</h3>
<p><strong><em>[Most episode transcripts/scripts are reserved for my Patreon supporters (at least for the time being), but I like to give you at least a taster here — or in this case, the first half of the episode.]</em></strong></p><p><em>Welcome to the Life and Times of Video Games, an audio series about video games and the video game industry, as they were in the past and how they’ve come to be the way they are today. I'm Richard Moss, and this is episode 28, Transport Tycoon, or the tale of the great optimiser and his two greatest works.</em></p><p>We’ll get going in just a moment. </p><p>*pause for pre-roll ad/cross-promo slot*</p><p>***</p><p>You may have heard the expression that every overnight sensation is a decade in the making — a decade of hard work, toiling in obscurity…or <em>relative</em> obscurity, honing a talent, perfecting a craft, <em>optimising</em> a skill set and envisioning whatever it is that breaks through.</p><p>In reality the actual duration is rarely a decade — it’s five years or eight years or eighteen years, or however long it takes for the pieces to all fall into place: the talent, timing, and product. But the idea bears repeating: the greatest accolades, the greatest achievements, the greatest games are the product of hard work built atop years of invisible labour.</p><p>And such it was that Chris Sawyer, like John Romero, Carol Shaw, Gunpei Yokoi, and many others before and since — such it was that in 1994 Chris Sawyer suddenly shifted from a little-known (though well-respected) figure in the games industry, a programmer who converted Amiga games to the PC, to become an industry icon.</p><p>Nineteen-ninety-four was the year when his first original game was published, the year when big-name PC game publisher Microprose put his transportation-focused business simulation game Transport Tycoon, an incredible solo development effort, in a box and sold it in stores to widespread acclaim. </p><p><img alt="SCR1" src="https://lifeandtimes.games/episodes/files/scr1.jpg" width="866" height="362"><br><em>Transport Tycoon, the game that made Chris Sawyer into a games industry icon (</em><em><a href="https://www.tt-forums.net/viewtopic.php?f=47&amp;t=29058" target="_blank">image source</a></em><em>)</em><br></p><div><p>The game itself had taken Chris just a year to develop, but the journey to making it had begun much earlier.</p><p>Chris had started programming as a teenager in 1981, largely out of curiosity, through trying to make things appear on the screen on a range of different computers he’d encountered. There was the Commodore PET at his high school, the Sinclair ZX81 demonstration unit in a W H Smiths store, and the Texas Instruments TI99/4A one of his neighbours owned, as well as the Commodore VIC-20 a different neighbour had. And eventually, after diligently saving up his pocket money, he’d become engrossed in a machine of his own, a Camputers Lynx, a now-forgotten, obscure-even-then 8-bit computer with fancier graphics and more horsepower than the leading systems of its day (the leading systems at the time being the Apple II, ZX Spectrum, and Commodore 64).</p><p>Here, in 1983, is where the journey really starts — where Chris set off towards the lands where he’d make his name. And I find it fascinating how serendipitous this was — for, you see, Chris’s two great successes, Transport Tycoon and RollerCoaster Tycoon, were both made possible by his phenomenal systems knowledge; by his immense capacity to hand-code complex interactions of data at low levels of abstraction.</p><p>And here is where he began to learn those skills, to internalise them to the point of becoming natural talents. He later told Arcade Attack in an interview that he’d not had access to an assembler for that Lynx computer, so when he’d wanted to move beyond coding in BASIC he’d needed to write his programs byte-by-byte in machine code — the lowest-level programming language, the numerical instructions that computers themselves use. And with scant resources available to teach him these skills, he mostly figured it out on his own, just trying different things until he got his ideas to work. Always chasing the next exhilarating breakthrough.</p><p>Chris continued to dabble in machine code, though somewhat less than before, when he upgraded to a similarly-obscure machine called the Memotech MTX500, which actually did come with a built-in assembler, which enabled him to write programs in the abbreviation-heavy Z80 assembly language. Programs that, beginning in 1984, he very often had published commercially.</p></div><p><img alt="Memotech_MTX500-wide" src="https://lifeandtimes.games/episodes/files/memotech_mtx500-wide.jpg" width="1020" height="584"><br><em>The Memotech MTX500 (</em><em><a href="https://en.wikipedia.org/wiki/File:Memotech_MTX500.jpg" target="_blank">Image source</a></em><em>)</em><br></p><div><p>Chris had sent Memotech cassette tapes of some games he’d made through copying the designs of popular titles, like Missile Kommand, which was the 1980 Atari arcade game converted to the capabilities of the MTX500, using a mix of BASIC and machine code, with the name intentionally misspelled (a ‘k’ rather than a ‘c’) as though that somehow made his unapologetic, blatant clone of another’s work okay. </p><p>But this was the wild west of the computer games business, and Memotech weren’t much concerned. Or at least their games guy Jim Wills wasn’t much concerned, neither at this point nor a few months later when he left to start a company called Megastar Games. Jim liked Chris’s work enough to publish it, for meagre royalties but invaluable experience. And so Chris was commercially published with his unlicensed MTX500 versions of Missile Command, Q*bert, Manic Miner, and a few others.</p><p>After high school he enrolled in a computer science and microprocessor systems degree, where he studied the fundamentals of both software and hardware design in computers — an experience he found invaluable, as it taught him how to push computers further by learning how their hardware worked. And it taught him the theories behind the sorts of nitty-gritty software-systems things he’d already been practising at home: optimisation, sorting, algorithms, and even more varieties of machine code.</p></div><p><img alt="escape-from-zarcos-memotech-mtx500" src="https://lifeandtimes.games/episodes/files/escape-from-zarcos-memotech-mtx500.png" width="1044" height="788"><em><br>Escape from Zarcos, Chris Sawyer clone of Manic Miner for the Memotech MTX500</em><br></p><div><p>At home, meanwhile, he’d shifted over to the Amstrad CPC, which technologically-speaking wasn’t hugely different to the Memotech system he’d been on before — but it was a modest upgrade, and unlike his previous computers it was actually a popular system. And for Chris it was a gateway to the PC, because in the course of studying at university and making computer games on the side he wound up getting an Amstrad-made IBM-PC clone.</p><p>Chris had during this period been getting his games published through Ariolasoft, a German company with a UK subsidiary that promised him a job programming games for them once he graduated. Except some promises can’t be kept, especially in an industry that moves as fast as computer games publishing.</p><p>The home computer business was by that point deep into its transition from 8-bit to 16-bit hardware, and that transition came with adjustments to the standard of game graphics and design required, and to the way marketing and sales worked, and the cost of publishing, and so on, and Ariolasoft wasn’t doing too well at managing the transition. </p><p>So Chris didn’t have a job waiting for him after all, and he’d missed out on all the great electronics engineering jobs his classmates applied for. (Oops!) But not to worry — he’d made enough connections and enough headway as a programmer that he could get himself a business agent, and that agent in turn connected him to the booming Amiga-to-PC games porting industry.</p><p>He later said he’d thought it a “stop-gap” measure, just “a bit of fun” while he looked for more permanent employment in the electronics industry. But Chris took to his new conversions work like a duck to water. The kid who’d had to get creative and remain patient to make anything work on his Camputers Lynx machine now excelled in an environment where he had to contend with the vast gap in multimedia capabilities between the Amiga and the PC.</p><p>PCs of the day were pathetically inept as games machines, compared to a system like the Amiga. Whereas the PC had just a CPU, and maybe, in a minority of machines, a dedicated sound card like the SoundBlaster 16, every Amiga came with a custom chipset that contained audio and video co-processors that could take some strain off the …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://lifeandtimes.games/episodes/files/28">https://lifeandtimes.games/episodes/files/28</a></em></p>]]>
            </description>
            <link>https://lifeandtimes.games/episodes/files/28</link>
            <guid isPermaLink="false">hacker-news-small-sites-24658958</guid>
            <pubDate>Fri, 02 Oct 2020 04:45:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Asteroids: By the Numbers]]>
            </title>
            <description>
<![CDATA[
Score 43 | Comments 16 (<a href="https://news.ycombinator.com/item?id=24655752">thread link</a>) | @rbanffy
<br/>
October 1, 2020 | http://www.retrogamedeconstructionzone.com/2019/10/asteroids-by-numbers.html?m=1 | <a href="https://web.archive.org/web/*/http://www.retrogamedeconstructionzone.com/2019/10/asteroids-by-numbers.html?m=1">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<div id="post-body-3855344372715435262"><p>
By 1979, arcade games were rapidly becoming more complex and colorful, and a game like <i>Asteroids </i>might have seemed quaint by comparison to the likes of <i><a href="http://www.retrogamedeconstructionzone.com/2019/09/galaxian-aesthetics-of-simple-patterns.html">Galaxian</a>, <a href="http://www.retrogamedeconstructionzone.com/2019/09/star-fire-weirdness-of-pseudo-3d.html">Star Fire</a></i>, or <i>Radar Scope.&nbsp; </i>But beneath its simple exterior lies a challenging shooter with surprisingly complex physics.&nbsp; The image below shows a sample still from it, including the player's ship (the triangle on the left), three sizes of asteroids, and an alien ship.</p><p><a href="https://1.bp.blogspot.com/-XOyg91qwUV4/XZwhbHR4tnI/AAAAAAAAOXs/DJ89MzjAODU3mAoraZKUaq6vl9nKvdsSACLcBGAsYHQ/s1600/Asteroids_sample%2B%25282%2529.png"><img data-original-height="461" data-original-width="598" height="492" src="https://1.bp.blogspot.com/-XOyg91qwUV4/XZwhbHR4tnI/AAAAAAAAOXs/DJ89MzjAODU3mAoraZKUaq6vl9nKvdsSACLcBGAsYHQ/s640/Asteroids_sample%2B%25282%2529.png" width="640"></a></p>

<p>
The goal of the game is to maximize your score, destroying as many asteroids and aliens as possible before you run out of ships.&nbsp; When an asteroid is hit by something (usually the player's bullets), large asteroids turn into two medium ones and medium asteroids turn into two small ones, while small asteroids and aliens are destroyed when hit.</p><p><a href="https://1.bp.blogspot.com/-cEzHmkcz3bA/XaU1zGl7IBI/AAAAAAAAObY/2GDlGaxtEc0ytzWpyQRinUxnbioeVsTbQCLcBGAsYHQ/s1600/Asteroids%2BPlay.gif"><img data-original-height="357" data-original-width="600" height="237" src="https://1.bp.blogspot.com/-cEzHmkcz3bA/XaU1zGl7IBI/AAAAAAAAObY/2GDlGaxtEc0ytzWpyQRinUxnbioeVsTbQCLcBGAsYHQ/s400/Asteroids%2BPlay.gif" width="400"></a></p>
<p>
For the designers of the game, balancing the relative sizes of the objects would have been important in such a dense field, because it determines how often things run into one another other.&nbsp; The table below outlines the sizes of the objects in <i>Asteroids</i>, expressed relative to the length of the player's ship.</p><table>
<caption>The approximate horizontal lengths of objects in <i>Asteroids</i></caption>
    <tbody>
<tr>
    <th>Object</th>
    <th>Length (in player ship lengths)</th>
    </tr>
<tr>
    <td>Screen</td>
    <td>25 x 36</td>
    </tr>
<tr>
    <td>Large Asteroids</td>
    <td>2.4</td>
    </tr>
<tr>
    <td>Medium Asteroid</td>
    <td>1.2</td>
    </tr>
<tr>
    <td>Small Asteroid</td>
    <td>0.6</td>
    </tr>
<tr>
    <td>Alien Ship (large)</td>
    <td>1.5</td>
    </tr>
<tr>
    <td>Alien Ship (small)</td>
    <td>0.75</td>
    </tr>
</tbody>
    </table>
<p>
Notice how the medium asteroid is twice the size of the small one, and the large is twice the size of the medium.&nbsp; If you think about it, this doesn't actually make much physical sense -- you can break a two-dimensional object into four pieces half its size, not two.&nbsp; But the size ratios do make game sense, because what really matters to the player is not how much area an asteroid takes up, but how likely it is to hit them.</p><p><a href="https://1.bp.blogspot.com/-5wVPSIS6W_M/XZwmjsjcYII/AAAAAAAAOX4/a7MThKiGRH8vhydf83eCiOmmJuKUULHIwCLcBGAsYHQ/s1600/Asteroids_cross_section%2B%25282%2529.png"><img data-original-height="281" data-original-width="170" src="https://1.bp.blogspot.com/-5wVPSIS6W_M/XZwmjsjcYII/AAAAAAAAOX4/a7MThKiGRH8vhydf83eCiOmmJuKUULHIwCLcBGAsYHQ/s1600/Asteroids_cross_section%2B%25282%2529.png"></a></p>

<p>
In the picture above, you can see that while the four small asteroids take up less area on the screen than the big one, they present the same cross section to your ship.&nbsp; This means that breaking up the asteroids doesn't greatly increase the probability that the player will be struck by one.&nbsp; If the asteroids had been broken up into four half-sized pieces at each blow, each large asteroid would result in sixteen small ones (that's four times the cross section!) and the player would be quickly overwhelmed.&nbsp; Note that the small asteroids do move faster than the large ones, and speed increases the chance of getting hit, but I'll return to that in a moment.</p>

<p>
Another big reason that size matters in <i>Asteroids</i>&nbsp;is that it determines how close something has to be before you're likely to be able to hit it.&nbsp; In 1979, vector arcade cabinet screens had an effective resolution of 1024 x 768, and the player's ship was only connected graphically by about 20 points.&nbsp; This meant, in turn, that there were only a limited number of orientations that they could render for the ship, in this case intervals of 5 degrees.&nbsp; To see how this might affect gameplay, imagine your ship is located at the fixed position shown in the picture below.&nbsp; Anything located entirely between the two solid lines will not be accessible by your bullets because your ship can't turn to the appropriate angle to hit it.&nbsp; This restriction isn't a big deal for large asteroids, which are still accessible over most of the screen, but small asteroids can be out of reach of your guns at relatively close range, sometimes as close as 7 ship lengths away!&nbsp; So even if you aim as accurately as possible, chances are you won't be able to hit a small asteroid on the other side of the screen, at least not on your first shot.&nbsp; This is probably one of the reasons that <i>Asteroids</i>&nbsp;allows you to fire up to four bullets in succession: even if you can't hit an object right away, it will eventually move into your line of fire.</p>

<p><a href="https://1.bp.blogspot.com/-EX2V1tAwdnM/XZvKFmnQZoI/AAAAAAAAOXI/cd411AFReLcKkCQGooANzsmxVD7QV3ikgCLcBGAsYHQ/s1600/Asteroids_hittable%2B%25285%2529.png"><img data-original-height="397" data-original-width="1024" height="248" src="https://1.bp.blogspot.com/-EX2V1tAwdnM/XZvKFmnQZoI/AAAAAAAAOXI/cd411AFReLcKkCQGooANzsmxVD7QV3ikgCLcBGAsYHQ/s640/Asteroids_hittable%2B%25285%2529.png" width="640"></a></p>
<p>
And what about speed?&nbsp; There is some variability in the speeds of individual asteroids, but small asteroids can move as much as 63% faster than large ones (see the table below), meaning that even if four small asteroids present the same cross section for hitting your ship as a large one does, their higher speed means they're more likely to hit you.&nbsp; The reasoning for this is simple: the faster something moves, the longer the path it can traverse in a given amount of time, and the larger the likelihood that you'll be in that path.&nbsp; Fortunately, even the fastest asteroids are much slower than your ship, which can traverse the screen in about two seconds; so if you're skilled enough, you should be able to maneuver around the asteroid field without a problem.</p><table>
<caption>The approximate speeds of objects in <i>Asteroids</i></caption>
    <tbody>
<tr>
    <th>Object</th>
    <th>Speed (in ship lengths per second)</th>
    </tr>
<tr>
    <td>Your ship</td>
    <td>0 - 17</td>
    </tr>
<tr>
    <td>Asteroids</td>
    <td>4 - 6.5</td>
    </tr>
<tr>
    <td>Alien ships (both sizes)</td>
    <td>4 - 6.5 (depending on your score)</td>
    </tr>
<tr>
    <td>Bullets</td>
    <td>17 (ship at rest)&nbsp;</td></tr>
</tbody></table>
<p>
One other interesting thing about speed: notice in the table above that the speed of a bullet, when fired at rest, is the same as your ship's maximum speed.&nbsp; This means that when you're moving rapidly and fire a bullet in the opposite direction of your motion, the two speeds should cancel for a stationary observer and the bullet should appear roughly stationary.</p>

<p><a href="https://1.bp.blogspot.com/-pRIxsTPNfSY/XaD7O0foijI/AAAAAAAAOZQ/JWZGFR26JEY3UM43RiruPhhGfHOCW21DgCLcBGAsYHQ/s1600/Asteroids_bullet_stationary.gif"><img data-original-height="175" data-original-width="468" height="239" src="https://1.bp.blogspot.com/-pRIxsTPNfSY/XaD7O0foijI/AAAAAAAAOZQ/JWZGFR26JEY3UM43RiruPhhGfHOCW21DgCLcBGAsYHQ/s640/Asteroids_bullet_stationary.gif" width="640"></a></p>


<div><p>
Sure enough, when I fire a bullet while moving quickly in the opposite direction, it just floats near where I fired it, allowing me to place bullets like mines for the asteroids to run into.</p>
<p>
The developers of <i>Asteroids </i>wanted the game to simulate the real laws of physics (<a href="http://www.technologyuk.net/computing/computer-gaming/gaming-landmarks-1960-1985/asteroids.shtml">see here</a>), and I think in many respects they succeeded, at least compared to most other arcade games of the time.&nbsp; It's not entirely realistic, however.&nbsp; In my article on <a href="http://www.retrogamedeconstructionzone.com/2019/10/impossible-motion-in-video-games.html">motion in early arcade games</a>, I discussed how the acceleration of the ship in <i>Asteroids</i> is too rapid for a human-occupied vehicle.&nbsp; We might suppose that the vehicle is automated, but even then, engineering spacecraft to withstand 30+ g's of acceleration is a non-trivial challenge.</p><p><a href="https://1.bp.blogspot.com/-eBpcOCL_1a0/XaU-bXjLJjI/AAAAAAAAObk/N_FxduJSebIMaqzrq7BhDmNFufzmyBRfgCLcBGAsYHQ/s1600/Acceleration%2BAsteroids.gif"><img data-original-height="175" data-original-width="634" height="176" src="https://1.bp.blogspot.com/-eBpcOCL_1a0/XaU-bXjLJjI/AAAAAAAAObk/N_FxduJSebIMaqzrq7BhDmNFufzmyBRfgCLcBGAsYHQ/s640/Acceleration%2BAsteroids.gif" width="640"></a></p>
<p>
Another issue is the way the asteroids break up.&nbsp; In physics, there's a principle called the conservation of momentum that says that when objects interact with one another or break apart, the total mass times the velocity must remain the same after the interaction as it was before.&nbsp; In layman's terms, this means that things can't suddenly go from moving one direction to moving in another unless there is something else carry its previous momentum.&nbsp; In the example shown below, an asteroid does just that, and the only thing that could have absorbed its previous momentum is the bullet.&nbsp; But the bullet is so tiny that it's difficult to imagine how that would be possible.</p><p><a href="https://1.bp.blogspot.com/-vsDHHIPNXrQ/XaEAAKYXRII/AAAAAAAAOZc/-lhbXy0TSV4nEiLvOf-pe7zyt9sPGLcEACLcBGAsYHQ/s1600/Asteroids_momentum.gif"><img data-original-height="248" data-original-width="533" height="185" src="https://1.bp.blogspot.com/-vsDHHIPNXrQ/XaEAAKYXRII/AAAAAAAAOZc/-lhbXy0TSV4nEiLvOf-pe7zyt9sPGLcEACLcBGAsYHQ/s400/Asteroids_momentum.gif" width="400"></a></p>

<p>
These are mere quibbles, however, and shouldn't dissuade you from giving the game a try.&nbsp; <i>Asteroids </i>ended up being one of Atari's biggest arcade hits, selling over 70,000 cabinets, and remains one of their most recognizable games to this day.&nbsp; Many gamers who grew up in the '80s, myself included, are more familiar with the Atari 2600 version of the game.&nbsp; Unfortunately, the designers had to make a lot of sacrifices in game physics in order to make it work on a home console, so I think the arcade version is really the way to go.&nbsp; Outside of visiting a vintage arcade, your best bet is probably the <a href="https://www.mamedev.org/">Multiple Arcade Machine Emulator</a> (MAME).&nbsp; Happy hunting!</p></div><div><p><span>NOTE: &nbsp;A previous version of this article stated that the game has limited pixel resolution, but <i>Asteroids </i>uses a vector display that is not composed of pixels. &nbsp;The resolution of the <i>Asteroids </i>vector display is 1024 x 768.</span></p><p><a href="https://1.bp.blogspot.com/-7gLKzZ6gULM/XaDx0uT70-I/AAAAAAAAOYo/aLUcLQJkl9AY1k2OYsewuUHydaxbkT0gwCLcBGAsYHQ/s1600/Asteroids_loop_transparent.gif"><img data-original-height="151" data-original-width="600" height="160" src="https://1.bp.blogspot.com/-7gLKzZ6gULM/XaDx0uT70-I/AAAAAAAAOYo/aLUcLQJkl9AY1k2OYsewuUHydaxbkT0gwCLcBGAsYHQ/s640/Asteroids_loop_transparent.gif" width="640"></a></p>
<br></div>
</div>
</div></div>]]>
            </description>
            <link>http://www.retrogamedeconstructionzone.com/2019/10/asteroids-by-numbers.html?m=1</link>
            <guid isPermaLink="false">hacker-news-small-sites-24655752</guid>
            <pubDate>Thu, 01 Oct 2020 20:19:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Programmers need to think like hackers]]>
            </title>
            <description>
<![CDATA[
Score 28 | Comments 15 (<a href="https://news.ycombinator.com/item?id=24654136">thread link</a>) | @gexos
<br/>
October 1, 2020 | https://gexos.org/2020/10/01/Programmers-need-to-think-like-hackers!/ | <a href="https://web.archive.org/web/*/https://gexos.org/2020/10/01/Programmers-need-to-think-like-hackers!/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://gexos.org/2020/10/01/Programmers-need-to-think-like-hackers!/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24654136</guid>
            <pubDate>Thu, 01 Oct 2020 18:01:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[AWS Is Not Your Ideal]]>
            </title>
            <description>
<![CDATA[
Score 26 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24653013">thread link</a>) | @amortize
<br/>
October 1, 2020 | https://sujithjay.com/not-aws | <a href="https://web.archive.org/web/*/https://sujithjay.com/not-aws">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <div>
  
  <p><span> 01 Oct 2020  • <span>
  
    
    
    <a href="https://sujithjay.com/tag/product"><code><nobr>PRODUCT</nobr></code>&nbsp;</a>
  
    
    
    <a href="https://sujithjay.com/tag/management"><code><nobr>MANAGEMENT</nobr></code>&nbsp;</a>
  
</span></span></p><p>Let me start with an assertion. Every platform engineering team <sup id="fnref:1" role="doc-noteref"><a href="#fn:1">1</a></sup> in every organisation aspires to be like AWS <sup id="fnref:2" role="doc-noteref"><a href="#fn:2">2</a></sup>.</p>

<p>Every platform team wants to be like AWS, because like AWS, they provide infrastructure abstractions to users. AWS provides infrastructure via the abstractions of VMs and disks and write-capacity-units, while platform teams provide infrastructure using higher abstractions which solve service definitions, database or message queue provisioning, and service right-sizing <sup id="fnref:3" role="doc-noteref"><a href="#fn:3">3</a></sup>.</p>

<p>This similarity prompts leaders of platform engineering teams to model their teams as agnostic providers of universal, non-leaky (within SLO bounds), self-served abstractions for their engineering organisation. Platform teams structured as such detached units struggle to define cohesive roadmaps which provide increasing value to business. But how does your platform differ from AWS?</p>

<h2 id="your-platform-vs-the-platform">Your Platform vs. The Platform</h2>

<h3 id="1-the-middle-ground">1. The Middle Ground</h3>
<p>As an agnostic service provider, AWS can afford to cater to median use-cases. The reason platform engineering teams exist is to bridge the gap between PaaS abstractions which work for the median use-case to your business’ specific use-cases. AWS can afford to target the median (economy of scale etc.), but you cannot.</p>

<p><img src="https://sujithjay.com/public/notaws/Median.jpeg" alt="AWS can afford to stay within a single σ. You cannot."></p>
<p><span> AWS can afford to stay within a single σ. You cannot.</span>
</p>

<p>Agnostic platform engineering teams which emulate AWS try to get away from this responsibility by proposing abstractions which target the median use-case. A tell-tale sign of this is when the lack in wide usability of internal abstractions is compensated for by extensive onboarding &amp; repeated training. This is also a side-effect of the relative valuation of engineering time vs. the time of another function <sup id="fnref:4" role="doc-noteref"><a href="#fn:4">4</a></sup>.</p>

<h3 id="2-follow-the-money">2. Follow the Money</h3>
<p>The dictum ‘follow the money’ works beautifully for customer-front products. When faced with a choice between two competing features to prioritise, a common tactical play is to make something which leads to more (immediate &amp; long-term) revenue. The proxy for increased revenue could be increased acquisition conversion, better retention or improved user experience – metrics which ensure increased revenue for the company over time. In short, revenue growth is the north star <sup id="fnref:5" role="doc-noteref"><a href="#fn:5">5</a></sup>.</p>

<p>Not so much in platform engineering. There is no revenue since your customers are internal, captive ones. Captive audiences are forced to use a solution by the force of dictum and lack of choice. The metrics used in platform products are proxies for usability and user satisfaction – but there are no foolproof ways to measure it for captive audiences. For captive audiences, solutions can not compete and better solutions cannot win. Like a command economy, platform products are designed rather than evolved. Design takes priority over market economy. So why is design bad?</p>

<h2 id="bad-design">Bad Design</h2>
<p>For design to work, there has to be an objective function against which we can design. A specification is an objective function against which engineering teams design a solution. Since we do not have reliable metrics <sup id="fnref:6" role="doc-noteref"><a href="#fn:6">6</a></sup> to rely on for platform engineering, how do we come up with specifications? And without rigorous specifications, new features created by the platform run a high risk of not solving worthwhile problems for the users.The current accepted methodology among platform engineering leaders to solve this paucity of specifications is to rely on user-interviews. This is, as mentioned before, an unreliable source since captive users do not have the best view of the ideal state of tooling and abstractions that could be available to them.</p>

<p>The only way to flip this situation is to let go of command-economy-style designed abstractions, and to let your platform self-organise along the principle of markets. How does that look in practice?</p>

<h3 id="1-market-ftw">1. Market, FTW</h3>
<p>Camille Fournier mentions in <a href="https://medium.com/@skamille/product-for-internal-platforms-9205c3a08142">Product for Internal Platforms</a> how her team partners with customer teams to develop prototypes for specific problems. These specific solutions are later honed and iterated on to become general solutions provided by your team. I would go a step further on this route, where possible. Partner to prototype with multiple teams facing related problems to develop multiple specific solutions. These specific solutions can be seen as competing candidates to solve a general problem. Bring in user-interviews at this point to gauge pain-points, and iterate individually on these specific solutions. This switches the economy of your team to a self-organised market. Once considerable thought and iteration has gone into each solution, it is time to assimilate. Assimilate the best solution(s) while migrating the rest to the chosen solution. As emphasised in <a href="https://medium.com/@skamille/product-for-internal-platforms-9205c3a08142">Product for Internal Platforms</a>, an early investment of time into migration strategies is essential for such a scheme to sustain.</p>

<p>In platforms designed with experimentation, you will find that innovation continues to thrive at the edges of the platform’s domain while the stable core of the platform is subject to periodic rework or maintenance. The use-cases a platform supports grows in a controlled manner to address an ever-growing percent of the consumers, and does not stagnate after addressing just the median users.</p>

<h3 id="2-overloaded-use-cases">2. Overloaded Use-cases</h3>
<p>Although agnostic platform engineering teams might only be catering to very specific median use-cases, the customer teams with specific needs cannot afford to be blocked and they cannot stop delivering their deliverables. These teams sometimes create their own solutions, and in such cases the above strategy of assimilation works wonders. You get a prototype for free on which the team can iterate on. However, this scenario is rarer in cases where it requires specific skills to build such solutions, such as in data platforms. One common pattern in such knowledge-constricted situations is that users find ways to overload the existing solutions with minor tweaks to fit their use-case. Look out for such overloaded use-cases within your platform, for they are excellent guides to unmet needs of the users. You can leverage them to advocate for newer features to explicitly support those use-cases.</p>

<h3 id="3-listen-to-them-only-at-the-start">3. Listen To Them (Only At The Start!)</h3>
<p>As a parting note, I will take a jab at user-interviews again. The above tactics work when you are trying to scale your platform from 1 to N. When taking a platform from 0 to 1, the only solution to creating specifications is to listen to the users. Give them exactly what they want. Listen to their exact demands. A propensity of platform product managers is to rely on this excessively at a much later stage in the product’s lifecycle. User-interviews have their place in evolving products, but the over-reliance on the methodology is a bane to platform product management.</p>

<p><strong>P.S.</strong> As I read back the above essay, the heavy influence of <a href="https://medium.com/@skamille/product-for-internal-platforms-9205c3a08142">Product for Internal Platforms</a> is clear. I would like to say that was the intention: to reassert the ideas in it which resounded with me, while stating a few of my own.</p>

<h3 id="footnotes">Footnotes</h3>


  </div>









      </div></div>]]>
            </description>
            <link>https://sujithjay.com/not-aws</link>
            <guid isPermaLink="false">hacker-news-small-sites-24653013</guid>
            <pubDate>Thu, 01 Oct 2020 16:37:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Compiling a Lisp to x86-64: Let expressions]]>
            </title>
            <description>
<![CDATA[
Score 127 | Comments 30 (<a href="https://news.ycombinator.com/item?id=24652842">thread link</a>) | @todsacerdoti
<br/>
October 1, 2020 | https://bernsteinbear.com/blog/compiling-a-lisp-7/ | <a href="https://web.archive.org/web/*/https://bernsteinbear.com/blog/compiling-a-lisp-7/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <p><em><a href="https://bernsteinbear.com/blog/compiling-a-lisp-0/">first</a></em> – <em><a href="https://bernsteinbear.com/blog/compiling-a-lisp-6/">previous</a></em></p>

<p>Welcome back to the “Compiling a Lisp” series. Last time we added a reader
(also known as a parser) to our compiler. This time we’re going to compile a
new form: <em>let</em> expressions.</p>

<p>Let expressions are a way to bind variables to values in a particular scope.
For example:</p>

<div><div><pre><code><span>(</span><span>let</span> <span>((</span><span>a</span> <span>1</span><span>)</span> <span>(</span><span>b</span> <span>2</span><span>))</span>
  <span>(</span><span>+</span> <span>a</span> <span>b</span><span>))</span>
</code></pre></div></div>

<p>Binds <code>a</code> to <code>1</code> and <code>b</code> to <code>2</code>, but only for the body of the <code>let</code> — the
rest of the S-expression — and then executes the body.</p>

<p>This is similar in C to opening a new block:</p>

<div><div><pre><code><span>int</span> <span>result</span><span>;</span>
<span>{</span>
  <span>int</span> <span>a</span> <span>=</span> <span>1</span><span>;</span>
  <span>int</span> <span>b</span> <span>=</span> <span>2</span><span>;</span>
  <span>result</span> <span>=</span> <span>a</span> <span>+</span> <span>b</span><span>;</span>
<span>}</span>
</code></pre></div></div>

<p>but it’s a little different because C has a divide between <em>statements</em> and
<em>expressions</em>, whereas Lisp does not.</p>

<p>It’s <em>also</em> different because let-expressions do not make previous binding
names available to expressions being bound. For example, the following program
should fail because it cannot find the name <code>a</code>:</p>



<p>There is a form that makes bindings available serially, but that is called
<code>let*</code> and we are not implementing that today.</p>

<p>For completeness’ sake, there is also <code>let rec</code>, which makes names available
serially and also within the same binding. This is useful for binding recursive
or mutually recursive functions. Again, we are not implementing that today.</p>

<h3 id="name-binding-implementation-strategy">Name binding implementation strategy</h3>

<p>You’ll notice two new things about let expressions:</p>

<ol>
  <li>They introduce ways to bind names to values, something we have to figure out
how to keep track of</li>
  <li>In order to use those names we have to figure out how to look up what the
name means</li>
</ol>

<p>In more technical terms, we have to add <em>environments</em> to our compiler. We can
then use those environments to map <em>names</em> to <em>stack locations</em>.</p>

<p>“Environment” is just a fancy word for “look-up table”. In order to implement
this table, we’re going to make an <em>association list</em>.</p>

<p>An <em>association list</em> is a list of <code>(key value)</code> pairs. Adding a pair means
tacking it on at the end (or beginning) of the list. Searching through the
table involves a linear scan, checking if keys match.</p>

<blockquote>
  <p>You may be wondering why we’re using this data structure to implement
environments. Didn’t I even take a data structures course in college?
Shouldn’t I know that <em>linear</em> equals <em>slow</em> and that I should <em>obviously</em>
use a hash table?</p>

  <p>Well, hash tables have costs too. They are hard to implement right; they have
high overhead despite being technically constant time; they incur higher
space cost per entry.</p>

  <p>For a compiler as small as this, a tuned hash table could easily be as long
as the rest of the compiler. Since we’re also compiling small <em>programs</em>,
we’ll worry about time complexity later. It is only an implementation detail.</p>
</blockquote>

<p>In order to do this, we’ll first draw up an association list. We’ll use a
linked list, just like cons cells:</p>

<div><div><pre><code><span>// Env</span>

<span>typedef</span> <span>struct</span> <span>Env</span> <span>{</span>
  <span>const</span> <span>char</span> <span>*</span><span>name</span><span>;</span>
  <span>word</span> <span>value</span><span>;</span>
  <span>struct</span> <span>Env</span> <span>*</span><span>prev</span><span>;</span>
<span>}</span> <span>Env</span><span>;</span>
</code></pre></div></div>

<p>I’ve done the usual thing and overloaded <code>Env</code> to mean both “a node in the
environment” and “a whole environment”. While one little <code>Env</code> struct only
holds a one name and one value, it also points to the rest of them, eventually
ending with <code>NULL</code>.</p>

<p>This <code>Env</code> will map names (symbols) to <em>stack offsets</em>. This is because we’re
going to continue our strategy of <em>not doing register allocation</em>.</p>

<p>To manipulate this data structure, we will also have two functions<sup id="fnref:1" role="doc-noteref"><a href="#fn:1">1</a></sup>:</p>

<div><div><pre><code><span>Env</span> <span>Env_bind</span><span>(</span><span>const</span> <span>char</span> <span>*</span><span>name</span><span>,</span> <span>word</span> <span>value</span><span>,</span> <span>Env</span> <span>*</span><span>prev</span><span>);</span>
<span>bool</span> <span>Env_find</span><span>(</span><span>Env</span> <span>*</span><span>env</span><span>,</span> <span>const</span> <span>char</span> <span>*</span><span>key</span><span>,</span> <span>word</span> <span>*</span><span>result</span><span>);</span>
</code></pre></div></div>

<p><code>Env_bind</code> creates a new node from the given name and value, borrowing a
reference to the name, and prepends it to <code>prev</code>. Instead of returning an
<code>Env*</code>, it returns a whole struct. We’ll learn more about why later, but the
“TL;DR” is that I think it requires less manual cleanup.</p>

<p><code>Env_find</code> takes an <code>Env*</code> and searches through the linked list for a <code>name</code>
matching the given <code>key</code>. If it finds a match, it returns <code>true</code> and stores the
<code>value</code> in <code>*result</code>. Otherwise, it returns <code>false</code>.</p>

<p>We can stop at the first match because Lisp allows name <em>shadowing</em>. Shadowing
occurs when a binding at a inner scope has the same name as a binding at an
outer scope. The inner binding takes precedence:</p>

<div><div><pre><code><span>(</span><span>let</span> <span>((</span><span>a</span> <span>1</span><span>))</span>
  <span>(</span><span>let</span> <span>((</span><span>a</span> <span>2</span><span>))</span>
    <span>a</span><span>))</span>
<span>; =&gt; 2</span>
</code></pre></div></div>

<p>Let’s learn about how these functions are implemented.</p>

<h3 id="name-binding-implementation">Name binding implementation</h3>

<p><code>Env_bind</code> is a little silly looking, but it’s equivalent to prepending a
node onto a chain of linked-list nodes. It returns a struct <code>Env</code> containing
the parameters passed to the function. I opted <em>not</em> to return a heap pointer
(allocated with <code>malloc</code>, etc) so that this can be easily stored in a
stack-allocated variable.</p>

<div><div><pre><code><span>Env</span> <span>Env_bind</span><span>(</span><span>const</span> <span>char</span> <span>*</span><span>name</span><span>,</span> <span>word</span> <span>value</span><span>,</span> <span>Env</span> <span>*</span><span>prev</span><span>)</span> <span>{</span>
  <span>return</span> <span>(</span><span>Env</span><span>){.</span><span>name</span> <span>=</span> <span>name</span><span>,</span> <span>.</span><span>value</span> <span>=</span> <span>value</span><span>,</span> <span>.</span><span>prev</span> <span>=</span> <span>prev</span><span>};</span>
<span>}</span>
</code></pre></div></div>

<p><em>Note</em> that we’re <strong>pre</strong>pending, not <strong>ap</strong>pending, so that names we add deeper
in a let chain shadow names from outside.</p>

<p><code>Env_find</code> does a recursive linear search through the linked list nodes. It may
look familiar to you if you’ve already written such a function in your life.</p>

<div><div><pre><code><span>bool</span> <span>Env_find</span><span>(</span><span>Env</span> <span>*</span><span>env</span><span>,</span> <span>const</span> <span>char</span> <span>*</span><span>key</span><span>,</span> <span>word</span> <span>*</span><span>result</span><span>)</span> <span>{</span>
  <span>if</span> <span>(</span><span>env</span> <span>==</span> <span>NULL</span><span>)</span>
    <span>return</span> <span>false</span><span>;</span>
  <span>if</span> <span>(</span><span>strcmp</span><span>(</span><span>env</span><span>-&gt;</span><span>name</span><span>,</span> <span>key</span><span>)</span> <span>==</span> <span>0</span><span>)</span> <span>{</span>
    <span>*</span><span>result</span> <span>=</span> <span>env</span><span>-&gt;</span><span>value</span><span>;</span>
    <span>return</span> <span>true</span><span>;</span>
  <span>}</span>
  <span>return</span> <span>Env_find</span><span>(</span><span>env</span><span>-&gt;</span><span>prev</span><span>,</span> <span>key</span><span>,</span> <span>result</span><span>);</span>
<span>}</span>
</code></pre></div></div>

<p>We search for the node with the string <code>key</code> and return the stack offset associated
with it.</p>

<p>Alright, now we’ve got names and data structures. Let’s implement some name
resolution and name binding.</p>

<h3 id="compiling-name-resolution">Compiling name resolution</h3>

<p>Up until now, <code>Compile_expr</code> could only compile integers, characters, booleans,
<code>nil</code>, and some primitive call expressions (via <code>Compile_call</code>). Now we’re
going to add a new case: symbols.</p>

<p>When a symbol is compiled, the compiler will look up its stack offset in the
current environment and emit a load. This opcode, <code>Emit_load_reg_indirect</code>, is
very similar to <code>Emit_add_reg_indirect</code> that we implemented for primitive
binary functions.</p>

<div><div><pre><code><span>int</span> <span>Compile_expr</span><span>(</span><span>Buffer</span> <span>*</span><span>buf</span><span>,</span> <span>ASTNode</span> <span>*</span><span>node</span><span>,</span> <span>word</span> <span>stack_index</span><span>,</span>
                 <span>Env</span> <span>*</span><span>varenv</span><span>)</span> <span>{</span>
  <span>// ...</span>
  <span>if</span> <span>(</span><span>AST_is_symbol</span><span>(</span><span>node</span><span>))</span> <span>{</span>
    <span>const</span> <span>char</span> <span>*</span><span>symbol</span> <span>=</span> <span>AST_symbol_cstr</span><span>(</span><span>node</span><span>);</span>
    <span>word</span> <span>value</span><span>;</span>
    <span>if</span> <span>(</span><span>Env_find</span><span>(</span><span>varenv</span><span>,</span> <span>symbol</span><span>,</span> <span>&amp;</span><span>value</span><span>))</span> <span>{</span>
      <span>Emit_load_reg_indirect</span><span>(</span><span>buf</span><span>,</span> <span>/*dst=*/</span><span>kRax</span><span>,</span> <span>/*src=*/</span><span>Ind</span><span>(</span><span>kRbp</span><span>,</span> <span>value</span><span>));</span>
      <span>return</span> <span>0</span><span>;</span>
    <span>}</span>
    <span>return</span> <span>-</span><span>1</span><span>;</span>
  <span>}</span>
  <span>assert</span><span>(</span><span>0</span> <span>&amp;&amp;</span> <span>"unexpected node type"</span><span>);</span>
<span>}</span>
</code></pre></div></div>

<p>If the variable is not in the environment, this is a compiler error and we
return <code>-1</code> to signal that. This is not a tremendously helpful signal. Maybe
soon we will add more helpful error messages.</p>

<p>Ah, yes, <code>varenv</code>. You will, like I had to, go and add an <code>Env*</code> parameter to
all relevant <code>Compile_XYZ</code> functions and then plumb it through the recursive
calls. Have fun!</p>

<h3 id="compiling-let-finally">Compiling let, finally</h3>

<p>Now that we can resolve the names, let’s go ahead and compile the expressions
that bind them.</p>

<p>We’ll have to add a case in <code>Compile_expr</code>. We could add it in the body of
<code>Compile_expr</code> itself, but there is some helpful setup in <code>Compile_call</code>
already. It’s a bit of a misnomer, since it’s not a call, but oh well.</p>

<div><div><pre><code><span>int</span> <span>Compile_call</span><span>(</span><span>Buffer</span> <span>*</span><span>buf</span><span>,</span> <span>ASTNode</span> <span>*</span><span>callable</span><span>,</span> <span>ASTNode</span> <span>*</span><span>args</span><span>,</span>
                 <span>word</span> <span>stack_index</span><span>,</span> <span>Env</span> <span>*</span><span>varenv</span><span>)</span> <span>{</span>
  <span>if</span> <span>(</span><span>AST_is_symbol</span><span>(</span><span>callable</span><span>))</span> <span>{</span>
    <span>// ...</span>
    <span>if</span> <span>(</span><span>AST_symbol_matches</span><span>(</span><span>callable</span><span>,</span> <span>"let"</span><span>))</span> <span>{</span>
      <span>return</span> <span>Compile_let</span><span>(</span><span>buf</span><span>,</span> <span>/*bindings=*/</span><span>operand1</span><span>(</span><span>args</span><span>),</span>
                         <span>/*body=*/</span><span>operand2</span><span>(</span><span>args</span><span>),</span> <span>stack_index</span><span>,</span>
                         <span>/*binding_env=*/</span><span>varenv</span><span>,</span>
                         <span>/*body_env=*/</span><span>varenv</span><span>);</span>
    <span>}</span>
  <span>}</span>
  <span>assert</span><span>(</span><span>0</span> <span>&amp;&amp;</span> <span>"unexpected call type"</span><span>);</span>
<span>}</span>
</code></pre></div></div>

<p>We have two cases to handle: no bindings and some bindings. We’ll tackle these
recursively, with no bindings being the base case. For that reason, I added a
helper function <code>Compile_let</code>.</p>

<p>As with all of the other compiler functions, we pass it an machine code buffer,
a stack index, and an environment. Unlike other functions, we passed it two
expressions and two environments.</p>

<p>I split up the bindings and the body so we can more easily recurse on the
bindings as we go through them. When we get to the end (the base case), the
bindings will be <code>nil</code> and we can just compile the <code>body</code>.</p>

<p>We have two environments for the reason I mentioned above: when we’re
evaluating the expressions that we’re binding the names to, we can’t add
bindings iteratively. We have to evaluate them in the parent environment. It’ll
be come clearer in a moment how that works.</p>

<p>We’ll tackle the simple case first — no bindings:</p>

<div><div><pre><code><span>int</span> <span>Compile_let</span><span>(</span><span>Buffer</span> <span>*</span><span>buf</span><span>,</span> <span>ASTNode</span> <span>*</span><span>bindings</span><span>,</span> <span>ASTNode</span> <span>*</span><span>body</span><span>,</span>
                <span>word</span> <span>stack_index</span><span>,</span> <span>Env</span> <span>*</span><span>binding_env</span><span>,</span> <span>Env</span> <span>*</span><span>body_env</span><span>)</span> <span>{</span>
  <span>if</span> <span>(</span><span>AST_is_nil</span><span>(</span><span>bindings</span><span>))</span> <span>{</span>
    <span>// Base case: no bindings. Compile the body</span>
    <span>_</span><span>(</span><span>Compile_expr</span><span>(</span><span>buf</span><span>,</span> <span>body</span><span>,</span> <span>stack_index</span><span>,</span> <span>body_env</span><span>));</span>
    <span>return</span> <span>0</span><span>;</span>
  <span>}</span>
  <span>// ...</span>
<span>}</span>
</code></pre></div></div>

<p>In that case, we compile the body using the <code>body_env</code> as the environment. This
is the environment that we will have added all of the bindings to.</p>

<p>In the case where we <em>do</em> have bindings, we can take the first one off and pull
it apart:</p>

<div><div><pre><code>  <span>// ...</span>
  <span>assert</span><span>(</span><span>AST_is_pair</span><span>(</span><span>bindings</span><span>));</span>
  <span>// Get the next binding</span>
  <span>ASTNode</span> <span>*</span><span>binding</span> <span>=</span> <span>AST_pair_car</span><span>(</span><span>bindings</span><span>);</span>
  <span>ASTNode</span> <span>*</span><span>name</span> <span>=</span> <span>AST_pair_car</span><span>(</span><span>binding</span><span>);</span>
  <span>assert</span><span>(</span><span>AST_is_symbol</span><span>(</span><span>name</span><span>));</span>
  <span>ASTNode</span> <span>*</span><span>binding_expr</span> <span>=</span> <span>AST_pair_car</span><span>(</span><span>AST_pair_cdr</span><span>(</span><span>binding</span><span>));</span>
  <span>// ...</span>
</code></pre></div></div>

<p>Once we have the <code>binding_expr</code>, we should compile it. The result will end up
in <code>rax</code>, per our internal compiler convention. We’ll then store it in the next
available stack location:</p>

<div><div><pre><code>  <span>// ...</span>
  <span>// Compile the binding expression</span>
  <span>_</span><span>(</span><span>Compile_expr</span><span>(</span><span>buf</span><span>,</span> <span>binding_expr</span><span>,</span> <span>stack_index</span><span>,</span> <span>binding_env</span><span>));</span>
  <span>Emit_store_reg_indirect</span><span>(</span><span>buf</span><span>,</span> <span>/*dst=*/</span><span>Ind</span><span>(</span><span>kRbp</span><span>,</span> <span>stack_index</span><span>),</span>
                          <span>/*src=*/</span><span>kRax</span><span>);</span>
  <span>// ...</span>
</code></pre></div></div>

<p>We’re compiling this binding expression in <code>binding_env</code>, the parent
environment, because we don’t want the previous bindings to be visible.</p>

<p>Once we’ve generated code to store it on the stack, we should register that
stack location with the binding name in the environment:</p>

<div><div><pre><code>  <span>// ...</span>
  <span>// Bind the name</span>
  <span>Env</span> <span>entry</span> <span>=</span> <span>Env_bind</span><span>(</span><span>AST_symbol_cstr</span><span>(</span><span>name</span><span>),</span> <span>stack_index</span><span>,</span> <span>body_env</span><span>);</span>
  <span>// ...</span>
</code></pre></div></div>

<p>Note that we’re binding it in the <code>body_env</code> because we want this to be
available to the body, but not the other bindings.</p>

<p>At this point we’ve done all the work required for …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://bernsteinbear.com/blog/compiling-a-lisp-7/">https://bernsteinbear.com/blog/compiling-a-lisp-7/</a></em></p>]]>
            </description>
            <link>https://bernsteinbear.com/blog/compiling-a-lisp-7/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24652842</guid>
            <pubDate>Thu, 01 Oct 2020 16:26:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Ontario police used Covid-19 database illegally, civil rights groups find]]>
            </title>
            <description>
<![CDATA[
Score 248 | Comments 70 (<a href="https://news.ycombinator.com/item?id=24650515">thread link</a>) | @seigando
<br/>
October 1, 2020 | https://www.cbc.ca/news/canada/toronto/covid-police-database-1.5745481 | <a href="https://web.archive.org/web/*/https://www.cbc.ca/news/canada/toronto/covid-police-database-1.5745481">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>Police forces across&nbsp;Ontario&nbsp;engaged in broad, illegal searches&nbsp;of a now-defunct COVID-19 database, two civil rights groups alleged Wednesday, claiming the use of the portal violated individual privacy rights for months.</p><div><figure><div><p><img alt="" srcset="" sizes="" src="https://i.cbc.ca/1.5704129.1598642644!/cumulusImage/httpImage/image.jpg_gen/derivatives/16x9_780/shutterstock-medium-file-typing-on-laptop.jpg"></p></div><figcaption>The Canadian Civil Liberties Association and the Canadian&nbsp;Constitution Foundation say in separate reports that many services used the database to look at COVID-19 test results for wide geographic areas and sometimes pulled up personal information unrelated to active calls.<!-- --> <!-- -->(maradon 333 / Shutterstock)</figcaption></figure><p><span><p>Police forces across&nbsp;Ontario&nbsp;engaged in broad, illegal searches&nbsp;of a now-defunct COVID-19 database, two civil rights groups alleged Wednesday, claiming the use of the portal violated individual privacy rights for months.</p>  <p>The Canadian Civil Liberties Association (CCLA) and the Canadian&nbsp;Constitution Foundation (CCF) said in separate reports that many services used the database to look at COVID-19 test results for wide geographic areas and sometimes pulled up personal information unrelated to active calls.</p>  <p>"People weren't told that when they went for COVID tests that&nbsp;this information was being shared with police and they certainly weren't asked for their consent," said Abby Deshman, the criminal&nbsp;justice program director for the CCLA.&nbsp;</p>  <p>"That should be a decision every person makes about what they&nbsp;want to do with their own personal medical information."</p>  <p>In early April, the&nbsp;Ontario&nbsp;government passed an emergency order&nbsp;that allowed police to obtain the names, addresses and dates of birth of Ontarians who had tested positive for COVID-19. The portal was aimed at helping to protect first responders.</p>  <p>Police access to that database ended on Aug. 17, after a legal&nbsp;challenge was filed by a group of human rights&nbsp; organizations.</p>  <p>The group, which included the CCLA, argued that allowing police&nbsp;to access personal health records violated individuals'<br> constitutional rights to privacy and equality.</p>  <h2>Police conducted 95,000 searches of database</h2>  <p>Data released in the context of the legal action showed that&nbsp; Ontario&nbsp;police services conducted over 95,000 searches of the&nbsp;database while it was active.</p>  <p>The CCF filed a freedom of information act request to the&nbsp;province related to police use of the database.&nbsp;</p>    <blockquote><span><span><svg version="1.1" focusable="false" x="0px" y="0px" width="30px" height="25px" viewBox="0 0 52.157 39.117" enable-background="new 0 0 52.157 39.117" space="preserve"><g><g><path fill="000000" d="M22.692,10.113c-5.199,1.4-8.398,4.4-8.398,8.801c0,2.4,2,3,3.6,4.199c2.2,1.602,3.4,3.4,3.4,6.602   c0,3.799-3.4,6.799-7.4,6.799c-4.6,0-8.8-3.199-8.8-10.6c0-13.6,7-20,17.599-21.799V10.113z M45.692,10.113   c-5.199,1.4-8.399,4.4-8.399,8.801c0,2.4,2,3,3.601,4.199c2.2,1.602,3.399,3.4,3.399,6.602c0,3.799-3.399,6.799-7.399,6.799   c-4.601,0-8.8-3.199-8.8-10.6c0-13.6,7-20,17.599-21.799V10.113z"></path></g></g><g display="none"><g display="inline"> <path fill="000000" d="M6.648,29.759c5.199-1.4,8.398-4.4,8.398-8.801c0-2.398-2-3-3.599-4.199c-2.2-1.6-3.399-3.4-3.399-6.6   c0-3.801,3.399-6.801,7.399-6.801c4.599,0,8.8,3.201,8.8,10.6c0,13.6-7,20-17.6,21.801V29.759z M29.648,29.759   c5.199-1.4,8.398-4.4,8.398-8.801c0-2.398-2-3-3.599-4.199c-2.2-1.6-3.401-3.4-3.401-6.6c0-3.801,3.401-6.801,7.401-6.801   c4.599,0,8.8,3.201,8.8,10.6c0,13.6-7,20-17.6,21.801V29.759z"></path></g></g></svg>Police were caught using the COVID-19 database to look up names&nbsp;unrelated to active calls, to do wholesale postal&nbsp; code searches for COVID-19 cases, and to even do broad based searches outside officers' own cities.<svg focusable="false" x="0px" y="0px" width="23px" height="22px" viewBox="0 0 52.157 39.117" enable-background="new 0 0 52.157 39.117" space="preserve"><g display="none"><g display="inline"><path fill="000000" d="M22.692,10.113c-5.199,1.4-8.398,4.4-8.398,8.801c0,2.4,2,3,3.6,4.199c2.2,1.602,3.4,3.4,3.4,6.602   c0,3.799-3.4,6.799-7.4,6.799c-4.6,0-8.8-3.199-8.8-10.6c0-13.6,7-20,17.599-21.799V10.113z M45.692,10.113   c-5.199,1.4-8.399,4.4-8.399,8.801c0,2.4,2,3,3.601,4.199c2.2,1.602,3.399,3.4,3.399,6.602c0,3.799-3.399,6.799-7.399,6.799   c-4.601,0-8.8-3.199-8.8-10.6c0-13.6,7-20,17.599-21.799V10.113z"></path></g></g><g><g><path fill="000000" d="M6.648,29.759c5.199-1.4,8.398-4.4,8.398-8.801c0-2.398-2-3-3.599-4.199c-2.2-1.6-3.399-3.4-3.399-6.6   c0-3.801,3.399-6.801,7.399-6.801c4.599,0,8.8,3.201,8.8,10.6c0,13.6-7,20-17.6,21.801V29.759z M29.648,29.759   c5.199-1.4,8.398-4.4,8.398-8.801c0-2.398-2-3-3.599-4.199c-2.2-1.6-3.401-3.4-3.401-6.6c0-3.801,3.401-6.801,7.401-6.801   c4.599,0,8.8,3.201,8.8,10.6c0,13.6-7,20-17.6,21.801V29.759z"></path></g></g></svg></span><cite>- Christine Van Geyn, Canadian Constitution Foundation</cite></span></blockquote>    <p>On Wednesday, the CCF made public a June memo from the Solicitor&nbsp;General's office to chiefs of police that warned against using the&nbsp;database beyond the "express purpose" of the emergency order.</p>  <p>The CCF said the memo revealed a "shocking misuse" of personal&nbsp;health information by police.</p>  <p>"Police were caught using the COVID-19 database to look up names&nbsp;unrelated to active calls, to do wholesale postal&nbsp; code searches for COVID-19 cases, and to even do broad based searches outside officers' own cities," said CCF litigation director, Christine Van&nbsp;Geyn.&nbsp;<span><ul><li><a href="https://www.cbc.ca/news/canada/toronto/covid-ont-police-database-1.5690220" data-contentid="" flag="" text="Ontario ends police access to COVID-19 database after legal challenge"><span>Ontario ends police access to COVID-19 database after legal challenge</span></a></li></ul></span></p>  <p>The CCF said it has filed a complaint with&nbsp;Ontario's privacy&nbsp;commissioner over violations of the Personal Health Information Protection Act, and with the&nbsp;Ontario&nbsp;Independent Police Review Director for officer misconduct.</p>  <p>Meanwhile, the CCLA sent letters to 37 police forces, asking them&nbsp;for details of how the database was used and if any information was retained from it.</p>  <p>Twenty-three responded and Deshman said she expects more to do&nbsp;so.</p>  <h2>Thunder Bay, Durham police conducted more than 40% of searches</h2>  <p>Many forces found the database difficult to use and resorted to&nbsp;problematic broad searches in an attempt to find workarounds, the CCLA said.</p>  <p>The association notes that more than 40 per cent of the 95,000&nbsp;searches of the database were conducted by either the Thunder Bay police or Durham Region police.&nbsp;</p>    <p>In Durham Region, police continued to run unauthorized searches&nbsp;even after provincial audits called attention to the inappropriate&nbsp;searches taking place, the CCLA said. The force's access to the portal was cut off by the province as a result, the CCLA said.</p>  <p>"Durham is a particularly concerning example," said Deshman.&nbsp;"In those cases there needs to be disclosure (to citizens whose information was accessed) and accountability by following up with the individuals in the police service that looked up information inappropriately."</p>  <h2>Anyone concerned can contact police, privacy commissioner&nbsp;</h2>  <p>Holly Walbourne, the legal counsel for Thunder Bay police, said&nbsp;in a letter sent to the groups that filed the legal challenge that&nbsp;the force understood their concerns but that police had "lawful authority" to use the database to protect first responders.</p>    <p>Durham police Supt. Peter Cousins wrote a report to the force's&nbsp;police services board on the issue on Sept. 1 saying&nbsp; access to theportal and its information was treated "seriously and with due care."&nbsp;</p>  <p>Toronto police never used the database because of "issues with&nbsp;the accuracy and reliability of the information," the CCLA reported. York Region police said they asked the province to revoke access to the database after an internal review found the risks associated with accessing personal health information outweighed any benefits.</p>  <p>Deshman said anyone concerned about police access to the province's COVID-19 database should contact their local police force&nbsp;and the&nbsp;Ontario&nbsp;Privacy Commissioner.</p></span></p></div></div>]]>
            </description>
            <link>https://www.cbc.ca/news/canada/toronto/covid-police-database-1.5745481</link>
            <guid isPermaLink="false">hacker-news-small-sites-24650515</guid>
            <pubDate>Thu, 01 Oct 2020 13:23:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Web Neural Network API]]>
            </title>
            <description>
<![CDATA[
Score 48 | Comments 20 (<a href="https://news.ycombinator.com/item?id=24649616">thread link</a>) | @rajveermalviya
<br/>
October 1, 2020 | https://webmachinelearning.github.io/webnn/ | <a href="https://web.archive.org/web/*/https://webmachinelearning.github.io/webnn/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
   <h2 data-level="1" id="intro"><span>1. </span><span>Introduction</span><a href="#intro"></a></h2>
   <p>We’re working on this section. Meanwhile, please take a look at the <a href="https://github.com/webmachinelearning/webnn/blob/master/explainer.md">explainer</a>.</p>
   <h2 data-level="2" id="usecases"><span>2. </span><span>Use cases</span><a href="#usecases"></a></h2>
   <h3 data-level="2.1" id="usecases-application"><span>2.1. </span><span>Application Use Cases</span><a href="#usecases-application"></a></h3>
   <p>This section illustrates application-level use cases for neural network
inference hardware acceleration. All applications in those use cases can be
built on top of pre-trained deep neural network (DNN) models.</p>
   <h4 data-level="2.1.1" id="usecase-person-detection"><span>2.1.1. </span><span>Person Detection</span><a href="#usecase-person-detection"></a></h4>
   <p>A user opens a web-based video conferencing application, but she temporarily
leaves from her room. The application is watching whether she is in front of her
PC by using object detection (for example, using object detection approaches
such as <a data-link-type="biblio" href="#biblio-ssd">[SSD]</a> or <a data-link-type="biblio" href="#biblio-yolo">[YOLO]</a> that use a single DNN) to detect regions in a camera
input frame that include persons.</p>
   <p>When she comes back, the application automatically detects her and notifies
other online users that she is active now.</p>
   <h4 data-level="2.1.2" id="usecase-segmentation"><span>2.1.2. </span><span>Semantic Segmentation</span><a href="#usecase-segmentation"></a></h4>
   <p>A user joins a teleconference via a web-based video conferencing application at
her desk since no meeting room in her office is available. During the
teleconference, she does not wish that her room and people in the background are
visible. To protect the privacy of the other people and the surroundings, the
application runs a machine learning model such as <a data-link-type="biblio" href="#biblio-deeplabv3">[DeepLabv3+]</a> or <a data-link-type="biblio" href="#biblio-maskr-cnn">[MaskR-CNN]</a> to semantically split an image into segments and replaces
segments that represent other people and background with another picture.</p>
   <h4 data-level="2.1.3" id="usecase-skeleton-detection"><span>2.1.3. </span><span>Skeleton Detection</span><a href="#usecase-skeleton-detection"></a></h4>
   <p>A web-based video conferencing application tracks a pose of user’s skeleton by
running a machine learning model, which allows for real-time human pose
estimation, such as <a data-link-type="biblio" href="#biblio-posenet">[PoseNet]</a> to recognize her gesture and body language. When
she raises her hand, her microphone is automatically unmuted and she can start
speaking on the teleconference.</p>
   <h4 data-level="2.1.4" id="usecase-face-recognition"><span>2.1.4. </span><span>Face Recognition</span><a href="#usecase-face-recognition"></a></h4>
   <p>There are multiple people in the conference room and they join an online meeting
using a web-based video conferencing application. The application detects faces
of participants by using object detection (for example, using object detection
approaches such as <a data-link-type="biblio" href="#biblio-ssd">[SSD]</a>) and checks whether each face was present at the
previous meeting or not by running a machine learning model such as <a data-link-type="biblio" href="#biblio-facenet">[FaceNet]</a>,
which verifies whether two faces would be identical or not.</p>
   <h4 data-level="2.1.5" id="usecase-facial-landmarks"><span>2.1.5. </span><span>Facial Landmark Detection</span><a href="#usecase-facial-landmarks"></a></h4>
   <p>A user wants to find new glasses that beautifully fits her on an online glasses
store. The online store offers web-based try-on simulator that runs a machine
learning model such as Face Alignment Network <a data-link-type="biblio" href="#biblio-fan">[FAN]</a> to detect facial landmarks
like eyes, nose, mouth, etc. When she chooses a pair of glasses, the simulator
properly render the selected glasses on the detected position of eyes on her
facial image.</p>
   <h4 data-level="2.1.6" id="usecase-style-transfer"><span>2.1.6. </span><span>Style Transfer</span><a href="#usecase-style-transfer"></a></h4>
   <p>A user is looking for cosmetics on an online store and wondering which color may
fit her face. The online store shows sample facial makeup images of cosmetics,
and offers makeup simulator that runs a machine learning model like <a data-link-type="biblio" href="#biblio-contextualloss">[ContextualLoss]</a> or <a data-link-type="biblio" href="#biblio-pairedcyclegan">[PairedCycleGAN]</a> to transfer the makeup style of the
sample makeup image to her facial image. She can check how the selected makeup
looks like on her face by the simulator.</p>
   <h4 data-level="2.1.7" id="usecase-super-resolution"><span>2.1.7. </span><span>Super Resolution</span><a href="#usecase-super-resolution"></a></h4>
   <p>A web-based video conferencing is receiving a video stream from its peer, but
the resolution of the video becomes lower due to network congestion. To prevent
degradation of the perceived video quality, the application runs a machine
learning model for super-resolution such as <a data-link-type="biblio" href="#biblio-srgan">[SRGAN]</a> to generate
higher-resolution video frames.</p>
   <h4 data-level="2.1.8" id="usecase-image-captioning"><span>2.1.8. </span><span>Image Captioning</span><a href="#usecase-image-captioning"></a></h4>
   <p>For better accessibility, a web-based presentation application provides
automatic image captioning by running a machine learning model such as <a data-link-type="biblio" href="#biblio-im2txt">[im2txt]</a> which predicts explanatory words of the presentation slides.</p>
   <h4 data-level="2.1.9" id="usecase-translation"><span>2.1.9. </span><span>Machine Translation</span><a href="#usecase-translation"></a></h4>
   <p>Multiple people from various countries are talking via a web-based real-time
text chat application. The application translates their conversation by using a
machine learning model such as <a data-link-type="biblio" href="#biblio-gnmt">[GNMT]</a> or <a data-link-type="biblio" href="#biblio-opennmt">[OpenNMT]</a>, which translates every
text into different language.</p>
   <h4 data-level="2.1.10" id="usecase-emotion-analysis"><span>2.1.10. </span><span>Emotion Analysis</span><a href="#usecase-emotion-analysis"></a></h4>
   <p>A user is talking to her friend via a web-based real-time text chat application,
and she is wondering how the friend feels because she cannot see the friend’s
face. The application analyses the friend’s emotion by using a machine learning
model such as <a data-link-type="biblio" href="#biblio-deepmoji">[DeepMoji]</a>, which infers emotion from input texts, and displays
an emoji that represents the estimated emotion.</p>
   <h4 data-level="2.1.11" id="usecase-video-summalization"><span>2.1.11. </span><span>Video Summarization</span><a href="#usecase-video-summalization"></a></h4>
   <p>A web-based video conferencing application records received video streams, and
it needs to reduce recorded video data to be stored. The application generates
the short version of the recorded video by using a machine learning model for
video summarization such as <a data-link-type="biblio" href="#biblio-video-summarization-with-lstm">[Video-Summarization-with-LSTM]</a>.</p>
   <h4 data-level="2.1.12" id="usecase-noise-suppression"><span>2.1.12. </span><span>Noise Suppression</span><a href="#usecase-noise-suppression"></a></h4>
   <p>A web-based video conferencing application records received audio streams, but
usually the background noise is everywhere. The application leverages real-time 
noise suppression using Recurrent Neural Network such as <a data-link-type="biblio" href="#biblio-rnnoise">[RNNoise]</a> for 
suppressing background dynamic noise like baby cry or dog barking to improve 
audio experiences in video conferences.</p>
   <h3 data-level="2.2" id="usecases-framework"><span>2.2. </span><span>Framework Use Cases</span><a href="#usecases-framework"></a></h3>
   <p>This section collects framework-level use cases for a dedicated low-level API
for neural network inference hardware acceleration. It is expected that Machine
Learning frameworks will be key consumers of the Web Neural Network API (WebNN
API) and the low-level details exposed through the WebNN API are abstracted out
from typical web developers. However, it is also expected that web developers
with specific interest and competence in Machine Learning will want to interface
with the WebNN API directly instead of a higher-level ML framework.</p>
   <h4 data-level="2.2.1" id="usecase-custom-layer"><span>2.2.1. </span><span>Custom Layer</span><a href="#usecase-custom-layer"></a></h4>
   <p>A web application developer wants to run a DNN model on the WebNN API. However,
she has found that some of activation functions like <a data-link-type="biblio" href="#biblio-leakyrelu">[LeakyReLU]</a>, <a data-link-type="biblio" href="#biblio-elu">[ELU]</a>,
etc. are not included in the WebNN API. To address this issue, she constructs
custom layers of the additional activation functions on top of the WebNN API.
Note that the scope of custom layers may include convolution, normalization,
etc. as well as activation.</p>
   <h4 data-level="2.2.2" id="usecase-network-concat"><span>2.2.2. </span><span>Network Concatenation</span><a href="#usecase-network-concat"></a></h4>
   <p>A web application uses a DNN model, and its model data of upper convolutional
layers and lower fully-connected layers are stored in separate files, since
model data of the fully-connected layers are periodically updated due to fine
tuning at the server side.</p>
   <p>Therefore, the application downloads both partial model files at first and
concatenates them into a single model. When the model is updated, the
application downloads fine-tuned part of the model and replace only the
fully-connected layers with it.</p>
   <h4 data-level="2.2.3" id="usecase-perf-adapt"><span>2.2.3. </span><span>Performance Adaptation</span><a href="#usecase-perf-adapt"></a></h4>
   <p>A web application developer has a concern about performance of her DNN model on
mobile devices. She has confirmed that it may run too slow on mobile devices
which do not have GPU acceleration. To address this issue, her web application
refers to the WebNN API to confirm whether acceleration is available or not, so
that the application can display the warning for devices without acceleration.</p>
   <p>After several weeks, she has developed a tiny DNN model that can even run on
CPU. In order to accommodate CPU execution, she modifies the application
so that the application loads the tiny model in the case of CPU-only devices.</p>
   <h2 data-level="3" id="api"><span>3. </span><span>API</span><a href="#api"></a></h2>
   <h3 data-level="3.1" id="api-navigator"><span>3.1. </span><span>Navigator</span><a href="#api-navigator"></a></h3>
<pre><c- b="">partial</c-> <c- b="">interface</c-> <a data-link-type="interface" href="https://html.spec.whatwg.org/multipage/system-state.html#navigator" id="ref-for-navigator"><c- g="">Navigator</c-></a> {
  <c- b="">readonly</c-> <c- b="">attribute</c-> <a data-link-type="idl-name" href="#ml" id="ref-for-ml"><c- n="">ML</c-></a> <dfn data-dfn-for="Navigator" data-dfn-type="attribute" data-export="" data-readonly="" data-type="ML" id="dom-navigator-ml"><code><c- g="">ml</c-></code><a href="#dom-navigator-ml"></a></dfn>;
};
</pre>
   <h3 data-level="3.2" id="api-ml"><span>3.2. </span><span>ML</span><a href="#api-ml"></a></h3>
<pre><c- b="">interface</c-> <dfn data-dfn-type="interface" data-export="" id="ml"><code><c- g="">ML</c-></code></dfn> {
  <a data-link-type="idl-name" href="#neuralnetworkcontext" id="ref-for-neuralnetworkcontext"><c- n="">NeuralNetworkContext</c-></a> <dfn data-dfn-for="ML" data-dfn-type="method" data-export="" data-lt="getNeuralNetworkContext()" id="dom-ml-getneuralnetworkcontext"><code><c- g="">getNeuralNetworkContext</c-></code><a href="#dom-ml-getneuralnetworkcontext"></a></dfn>();
};
</pre>
   <h3 data-level="3.3" id="api-operanddescriptor"><span>3.3. </span><span>OperandDescriptor</span><a href="#api-operanddescriptor"></a></h3>
<pre><c- b="">enum</c-> <dfn data-dfn-type="enum" data-export="" id="enumdef-operandlayout"><code><c- g="">OperandLayout</c-></code></dfn> {
  <dfn data-dfn-for="OperandLayout" data-dfn-type="enum-value" data-export="" id="dom-operandlayout-nchw"><code><c- s="">"nchw"</c-></code><a href="#dom-operandlayout-nchw"></a></dfn>,
  <dfn data-dfn-for="OperandLayout" data-dfn-type="enum-value" data-export="" id="dom-operandlayout-nhwc"><code><c- s="">"nhwc"</c-></code><a href="#dom-operandlayout-nhwc"></a></dfn>
};

<c- b="">enum</c-> <dfn data-dfn-type="enum" data-export="" id="enumdef-operandtype"><code><c- g="">OperandType</c-></code></dfn> {
  <dfn data-dfn-for="OperandType" data-dfn-type="enum-value" data-export="" id="dom-operandtype-float32"><code><c- s="">"float32"</c-></code><a href="#dom-operandtype-float32"></a></dfn>,
  <dfn data-dfn-for="OperandType" data-dfn-type="enum-value" data-export="" id="dom-operandtype-float16"><code><c- s="">"float16"</c-></code><a href="#dom-operandtype-float16"></a></dfn>,
  <dfn data-dfn-for="OperandType" data-dfn-type="enum-value" data-export="" id="dom-operandtype-int32"><code><c- s="">"int32"</c-></code><a href="#dom-operandtype-int32"></a></dfn>,
  <dfn data-dfn-for="OperandType" data-dfn-type="enum-value" data-export="" id="dom-operandtype-uint32"><code><c- s="">"uint32"</c-></code><a href="#dom-operandtype-uint32"></a></dfn>,
  <dfn data-dfn-for="OperandType" data-dfn-type="enum-value" data-export="" id="dom-operandtype-tensor-float32"><code><c- s="">"tensor-float32"</c-></code><a href="#dom-operandtype-tensor-float32"></a></dfn>,
  <dfn data-dfn-for="OperandType" data-dfn-type="enum-value" data-export="" id="dom-operandtype-tensor-float16"><code><c- s="">"tensor-float16"</c-></code><a href="#dom-operandtype-tensor-float16"></a></dfn>,
  <dfn data-dfn-for="OperandType" data-dfn-type="enum-value" data-export="" id="dom-operandtype-tensor-int32"><code><c- s="">"tensor-int32"</c-></code><a href="#dom-operandtype-tensor-int32"></a></dfn>,
  <dfn data-dfn-for="OperandType" data-dfn-type="enum-value" data-export="" id="dom-operandtype-tensor-quant8-asymm"><code><c- s="">"tensor-quant8-asymm"</c-></code><a href="#dom-operandtype-tensor-quant8-asymm"></a></dfn>
};

<c- b="">dictionary</c-> <dfn data-dfn-type="dictionary" data-export="" id="dictdef-operanddescriptor"><code><c- g="">OperandDescriptor</c-></code></dfn> {
  // The operand type.
  <c- b="">required</c-> <a data-link-type="idl-name" href="#enumdef-operandtype" id="ref-for-enumdef-operandtype"><c- n="">OperandType</c-></a> <dfn data-dfn-for="OperandDescriptor" data-dfn-type="dict-member" data-export="" data-type="OperandType " id="dom-operanddescriptor-type"><code><c- g="">type</c-></code><a href="#dom-operanddescriptor-type"></a></dfn>;

  // The dimensions field is only required for tensor operands.
  // The negative value means an unknown dimension.
  <c- b="">sequence</c->&lt;<a data-link-type="interface" href="https://heycam.github.io/webidl/#idl-long" id="ref-for-idl-long"><c- b="">long</c-></a>&gt; <dfn data-dfn-for="OperandDescriptor" data-dfn-type="dict-member" data-export="" data-type="sequence<long> " id="dom-operanddescriptor-dimensions"><code><c- g="">dimensions</c-></code><a href="#dom-operanddescriptor-dimensions"></a></dfn>;

  // The following two fields are only required for quantized operand.
  // scale: an non-negative floating point value
  // zeroPoint: an integer, in range [0, 255]
  // The real value is (value - zeroPoint) * scale
  <a data-link-type="interface" href="https://heycam.github.io/webidl/#idl-float" id="ref-for-idl-float"><c- b="">float</c-></a> <dfn data-dfn-for="OperandDescriptor" data-dfn-type="dict-member" data-export="" data-type="float " id="dom-operanddescriptor-scale"><code><c- g="">scale</c-></code><a href="#dom-operanddescriptor-scale"></a></dfn>;
  <a data-link-type="interface" href="https://heycam.github.io/webidl/#idl-long" id="ref-for-idl-long①"><c- b="">long</c-></a> <dfn data-dfn-for="OperandDescriptor" data-dfn-type="dict-member" data-export="" data-type="long " id="dom-operanddescriptor-zeropoint"><code><c- g="">zeroPoint</c-></code><a href="#dom-operanddescriptor-zeropoint"></a></dfn>;
};
</pre>
   <h3 data-level="3.4" id="api-operand"><span>3.4. </span><span>Operand</span><a href="#api-operand"></a></h3>
<pre><c- b="">interface</c-> <dfn data-dfn-type="interface" data-export="" id="operand"><code><c- g="">Operand</c-></code></dfn> {};
</pre>
   <h3 data-level="3.5" id="api-neuralnetworkcontext"><span>3.5. </span><span>NeuralNetworkContext</span><a href="#api-neuralnetworkcontext"></a></h3>
   <p>The <code><a data-link-type="idl" href="#neuralnetworkcontext" id="ref-for-neuralnetworkcontext①">NeuralNetworkContext</a></code> defines a set of operations derived from the first-wave models <a data-link-type="biblio" href="#biblio-models">[Models]</a> that address identified <a href="#usecases">§ 2 Use cases</a>.</p>
<pre><c- b="">typedef</c-> <a data-link-type="interface" href="https://heycam.github.io/webidl/#idl-double" id="ref-for-idl-double"><c- b="">double</c-></a> <dfn data-dfn-type="typedef" data-export="" id="typedefdef-number"><code><c- g="">number</c-></code></dfn>;

<c- b="">dictionary</c-> <dfn data-dfn-type="dictionary" data-export="" id="dictdef-namedoperand"><code><c- g="">NamedOperand</c-></code></dfn> {
  <c- b="">required</c-> <a data-link-type="interface" href="https://heycam.github.io/webidl/#idl-DOMString" id="ref-for-idl-DOMString"><c- b="">DOMString</c-></a> <dfn data-dfn-for="NamedOperand" data-dfn-type="dict-member" data-export="" data-type="DOMString " id="dom-namedoperand-name"><code><c- g="">name</c-></code><a href="#dom-namedoperand-name"></a></dfn>;
  <c- b="">required</c-> <a data-link-type="idl-name" href="#operand" id="ref-for-operand"><c- n="">Operand</c-></a> <dfn data-dfn-for="NamedOperand" data-dfn-type="dict-member" data-export="" data-type="Operand " id="dom-namedoperand-operand"><code><c- g="">operand</c-></code><a href="#dom-namedoperand-operand"></a></dfn>;
};

<c- b="">interface</c-> <dfn data-dfn-type="interface" data-export="" id="neuralnetworkcontext"><code><c- g="">NeuralNetworkContext</c-></code></dfn> {
  // Create an Operand object that represents a model input.
  <a data-link-type="idl-name" href="#operand" id="ref-for-operand①"><c- n="">Operand</c-></a> <dfn data-dfn-for="NeuralNetworkContext" data-dfn-type="method" data-export="" data-lt="input(name, desc)" id="dom-neuralnetworkcontext-input"><code><c- g="">input</c-></code><a href="#dom-neuralnetworkcontext-input"></a></dfn>(<a data-link-type="interface" href="https://heycam.github.io/webidl/#idl-DOMString" id="ref-for-idl-DOMString①"><c- b="">DOMString</c-></a> <dfn data-dfn-for="NeuralNetworkContext/input(name, desc)" data-dfn-type="argument" data-export="" id="dom-neuralnetworkcontext-input-name-desc-name"><code><c- g="">name</c-></code><a href="#dom-neuralnetworkcontext-input-name-desc-name"></a></dfn>, <a data-link-type="idl-name" href="#dictdef-operanddescriptor" id="ref-for-dictdef-operanddescriptor"><c- n="">OperandDescriptor</c-></a> <dfn data-dfn-for="NeuralNetworkContext/input(name, desc)" data-dfn-type="argument" data-export="" id="dom-neuralnetworkcontext-input-name-desc-desc"><code><c- g="">desc</c-></code><a href="#dom-neuralnetworkcontext-input-name-desc-desc"></a></dfn>);

  // Create an Operand object that represents a model constant.
  <a data-link-type="idl-name" href="#operand" id="ref-for-operand②"><c- n="">Operand</c-></a> <dfn data-dfn-for="NeuralNetworkContext" data-dfn-type="method" data-export="" data-lt="constant(desc, value)" id="dom-neuralnetworkcontext-constant"><code><c- g="">constant</c-></code><a href="#dom-neuralnetworkcontext-constant"></a></dfn>(<a data-link-type="idl-name" href="#dictdef-operanddescriptor" id="ref-for-dictdef-operanddescriptor①"><c- n="">OperandDescriptor</c-></a> <dfn data-dfn-for="NeuralNetworkContext/constant(desc, value)" data-dfn-type="argument" data-export="" id="dom-neuralnetworkcontext-constant-desc-value-desc"><code><c- g="">desc</c-></code><a href="#dom-neuralnetworkcontext-constant-desc-value-desc"></a></dfn>, <a data-link-type="idl-name" href="https://heycam.github.io/webidl/#ArrayBufferView" id="ref-for-ArrayBufferView"><c- n="">ArrayBufferView</c-></a> <dfn data-dfn-for="NeuralNetworkContext/constant(desc, value)" data-dfn-type="argument" data-export="" id="dom-neuralnetworkcontext-constant-desc-value-value"><code><c- g="">value</c-></code><a href="#dom-neuralnetworkcontext-constant-desc-value-value"></a></dfn>);

  // Create a single-value tensor from the specified number of the specified type.
  <a data-link-type="idl-name" href="#operand" id="ref-for-operand③"><c- n="">Operand</c-></a> <dfn data-dfn-for="NeuralNetworkContext" data-dfn-type="method" data-export="" data-lt="constant(value, type)|constant(value)" id="dom-neuralnetworkcontext-constant-value-type"><code><c- g="">constant</c-></code><a href="#dom-neuralnetworkcontext-constant-value-type"></a></dfn>(<a data-link-type="idl-name" href="#typedefdef-number" id="ref-for-typedefdef-number"><c- n="">number</c-></a> <dfn data-dfn-for="NeuralNetworkContext/constant(value, type), NeuralNetworkContext/constant(value)" data-dfn-type="argument" data-export="" id="dom-neuralnetworkcontext-constant-value-type-value"><code><c- g="">value</c-></code><a href="#dom-neuralnetworkcontext-constant-value-type-value"></a></dfn>, <c- b="">optional</c-> <a data-link-type="idl-name" href="#enumdef-operandtype" id="ref-for-enumdef-operandtype①"><c- n="">OperandType</c-></a> <dfn data-dfn-for="NeuralNetworkContext/constant(value, type), NeuralNetworkContext/constant(value)" data-dfn-type="argument" data-export="" id="dom-neuralnetworkcontext-constant-value-type-type"><code><c- g="">type</c-></code><a href="#dom-neuralnetworkcontext-constant-value-type-type"></a></dfn> = "float32");

  // Create a Model object by identifying output operands.
  <c- b="">Promise</c->&lt;<a data-link-type="idl-name" href="#model" id="ref-for-model"><c- n="">Model</c-></a>&gt; <dfn data-dfn-for="NeuralNetworkContext" data-dfn-type="method" data-export="" data-lt="createModel(outputs)" id="dom-neuralnetworkcontext-createmodel"><code><c- g="">createModel</c-></code><a href="#dom-neuralnetworkcontext-createmodel"></a></dfn>(<c- b="">sequence</c->&lt;<a data-link-type="idl-name" href="#dictdef-namedoperand" id="ref-for-dictdef-namedoperand"><c- n="">NamedOperand</c-></a>&gt; <dfn data-dfn-for="NeuralNetworkContext/createModel(outputs)" data-dfn-type="argument" data-export="" id="dom-neuralnetworkcontext-createmodel-outputs-outputs"><code><c- g="">outputs</c-></code><a href="#dom-neuralnetworkcontext-createmodel-outputs-outputs"></a></dfn>);
};
</pre>
   <h4 data-level="3.5.1" id="api-neuralnetworkcontext-batchnorm"><span>3.5.1. </span><span>batchNormalization</span><a href="#api-neuralnetworkcontext-batchnorm"></a></h4>
    Normalize the tensor values across dimensions in a batch through a specialized <a data-link-type="biblio" href="#biblio-batchnorm">[BatchNorm]</a> <a href="https://en.wikipedia.org/wiki/Batch_normalization#Batch_Normalizing_Transform">transform</a>. The <em>mean</em> and <em>variance</em> tensors are previously calculated during model training pass. 
<pre><c- b="">partial</c-> <c- b="">interface</c-> <a data-link-type="interface" href="#neuralnetworkcontext" id="ref-for-neuralnetworkcontext②"><c- g="">NeuralNetworkContext</c-></a> {
  <a data-link-type="idl-name" href="#operand" id="ref-for-operand④"><c- n="">Operand</c-></a> <dfn data-dfn-for="NeuralNetworkContext" data-dfn-type="method" data-export="" data-lt="batchNormalization(input, mean, variance, scale, bias, axis, epsilon)|batchNormalization(input, mean, variance, scale, bias, axis)|batchNormalization(input, mean, variance, scale, bias)|batchNormalization(input, mean, variance, scale)|batchNormalization(input, mean, variance)" id="dom-neuralnetworkcontext-batchnormalization"><code><c- g="">batchNormalization</c-></code><a href="#dom-neuralnetworkcontext-batchnormalization"></a></dfn>(<a data-link-type="idl-name" href="#operand" id="ref-for-operand⑤"><c- n="">Operand</c-></a> <dfn data-dfn-for="NeuralNetworkContext/batchNormalization(input, mean, variance, scale, bias, axis, epsilon), NeuralNetworkContext/batchNormalization(input, mean, variance, scale, bias, axis), NeuralNetworkContext/batchNormalization(input, mean, variance, scale, bias), NeuralNetworkContext/batchNormalization(input, mean, variance, scale), NeuralNetworkContext/batchNormalization(input, mean, variance)" data-dfn-type="argument" data-export="" id="dom-neuralnetworkcontext-batchnormalization-input-mean-variance-scale-bias-axis-epsilon-input"><code><c- g="">input</c-></code><a href="#dom-neuralnetworkcontext-batchnormalization-input-mean-variance-scale-bias-axis-epsilon-input"></a></dfn>, <a data-link-type="idl-name" href="#operand" id="ref-for-operand⑥"><c- n="">Operand</c-></a> <dfn data-dfn-for="NeuralNetworkContext/batchNormalization(input, mean, variance, scale, bias, axis, epsilon), NeuralNetworkContext/batchNormalization(input, mean, variance, scale, bias, axis), NeuralNetworkContext/batchNormalization(input, mean, variance, scale, bias), NeuralNetworkContext/batchNormalization(input, mean, variance, scale), NeuralNetworkContext/batchNormalization(input, mean, variance)" data-dfn-type="argument" data-export="" id="dom-neuralnetworkcontext-batchnormalization-input-mean-variance-scale-bias-axis-epsilon-mean"><code><c- g="">mean</c-></code><a href="#dom-neuralnetworkcontext-batchnormalization-input-mean-variance-scale-bias-axis-epsilon-mean"></a></dfn>, <a data-link-type="idl-name" href="#operand" id="ref-for-operand⑦"><c- n="">Operand</c-></a> <dfn data-dfn-for="NeuralNetworkContext/batchNormalization(input, mean, variance, scale, bias, axis, epsilon), NeuralNetworkContext/batchNormalization(input, mean, variance, scale, bias, axis), NeuralNetworkContext/batchNormalization(input, mean, variance, scale, bias), NeuralNetworkContext/batchNormalization(input, mean, variance, scale), NeuralNetworkContext/batchNormalization(input, mean, variance)" data-dfn-type="argument" data-export="" id="dom-neuralnetworkcontext-batchnormalization-input-mean-variance-scale-bias-axis-epsilon-variance"><code><c- g="">variance</c-></code><a href="#dom-neuralnetworkcontext-batchnormalization-input-mean-variance-scale-bias-axis-epsilon-variance"></a></dfn>, 
                             <c- b="">optional</c-> <a data-link-type="idl-name" href="#operand" id="ref-for-operand⑧"><c- n="">Operand</c-></a> <dfn data-dfn-for="NeuralNetworkContext/batchNormalization(input, mean, variance, scale, bias, axis, epsilon), NeuralNetworkContext/batchNormalization(input, mean, variance, scale, bias, axis), NeuralNetworkContext/batchNormalization(input, mean, variance, scale, bias), NeuralNetworkContext/batchNormalization(input, mean, variance, scale), NeuralNetworkContext/batchNormalization(input, mean, variance)" data-dfn-type="argument" data-export="" id="dom-neuralnetworkcontext-batchnormalization-input-mean-variance-scale-bias-axis-epsilon-scale"><code><c- g="">scale</c-></code><a href="#dom-neuralnetworkcontext-batchnormalization-input-mean-variance-scale-bias-axis-epsilon-scale"></a></dfn>, <c- b="">optional</c-> <a data-link-type="idl-name" href="#operand" id="ref-for-operand⑨"><c- n="">Operand</c-></a> <dfn data-dfn-for="NeuralNetworkContext/batchNormalization(input, mean, variance, scale, bias, axis, epsilon), NeuralNetworkContext/batchNormalization(input, mean, variance, scale, bias, axis), NeuralNetworkContext/batchNormalization(input, mean, variance, scale, bias), NeuralNetworkContext/batchNormalization(input, mean, variance, scale), NeuralNetworkContext/batchNormalization(input, mean, variance)" data-dfn-type="argument" data-export="" id="dom-neuralnetworkcontext-batchnormalization-input-mean-variance-scale-bias-axis-epsilon-bias"><code><c- g="">bias</c-></code><a href="#dom-neuralnetworkcontext-batchnormalization-input-mean-variance-scale-bias-axis-epsilon-bias"></a></dfn>, 
                             <c- b="">optional</c-> <a data-link-type="interface" href="https://heycam.github.io/webidl/#idl-long" id="ref-for-idl-long②"><c- b="">long</c-></a> <dfn data-dfn-for="NeuralNetworkContext/batchNormalization(input, mean, variance, scale, bias, axis, epsilon), NeuralNetworkContext/batchNormalization(input, mean, variance, scale, bias, axis), NeuralNetworkContext/batchNormalization(input, mean, variance, scale, bias), NeuralNetworkContext/batchNormalization(input, mean, variance, scale), NeuralNetworkContext/batchNormalization(input, mean, variance)" data-dfn-type="argument" data-export="" id="dom-neuralnetworkcontext-batchnormalization-input-mean-variance-scale-bias-axis-epsilon-axis"><code><c- g="">axis</c-></code><a href="#dom-neuralnetworkcontext-batchnormalization-input-mean-variance-scale-bias-axis-epsilon-axis"></a></dfn> = 1, <c- b="">optional</c-> <a data-link-type="interface" href="https://heycam.github.io/webidl/#idl-float" id="ref-for-idl-float①"><c- b="">float</c-></a> <dfn data-dfn-for="NeuralNetworkContext/batchNormalization(input, mean, variance, scale, bias, axis, epsilon), NeuralNetworkContext/batchNormalization(input, mean, variance, scale, bias, axis), NeuralNetworkContext/batchNormalization(input, mean, variance, scale, bias), NeuralNetworkContext/batchNormalization(input, mean, variance, scale), NeuralNetworkContext/batchNormalization(input, mean, variance)" data-dfn-type="argument" data-export="" id="dom-neuralnetworkcontext-batchnormalization-input-mean-variance-scale-bias-axis-epsilon-epsilon"><code><c- g="">epsilon</c-></code><a href="#dom-neuralnetworkcontext-batchnormalization-input-mean-variance-scale-bias-axis-epsilon-epsilon"></a></dfn> = 1e-5);
};
</pre>
   <div data-algorithm="batchnorm">
     <p><strong>Arguments:</strong></p><ul>
     <li data-md="">
      <p><em>input</em>: an <code><a data-link-type="idl" href="#operand" id="ref-for-operand①⓪">Operand</a></code>. The input N-D tensor.</p>
     </li><li data-md="">
      <p><em>mean</em>: an <code><a data-link-type="idl" href="#operand" id="ref-for-operand①①">Operand</a></code>. The 1-D tensor of the batch mean values
whose length is equal to the size of the input dimension denoted by <em>axis</em>.</p>
     </li><li data-md="">
      <p><em>variance</em>: an <code><a data-link-type="idl" href="#operand" id="ref-for-operand①②">Operand</a></code>. The 1-D tensor of the batch variance values
whose length is equal to the size of the input …</p></li></ul></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://webmachinelearning.github.io/webnn/">https://webmachinelearning.github.io/webnn/</a></em></p>]]>
            </description>
            <link>https://webmachinelearning.github.io/webnn/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24649616</guid>
            <pubDate>Thu, 01 Oct 2020 11:18:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Baremetal programming on the tinyAVR 0 micro-controllers]]>
            </title>
            <description>
<![CDATA[
Score 101 | Comments 94 (<a href="https://news.ycombinator.com/item?id=24648397">thread link</a>) | @unwind
<br/>
October 1, 2020 | https://www.omzlo.com/articles/baremetal-programming-on-the-tinyavr-0-micro-controllers | <a href="https://web.archive.org/web/*/https://www.omzlo.com/articles/baremetal-programming-on-the-tinyavr-0-micro-controllers">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><section><div><h4>All you need is a text editor, a makefile and a USB-serial cable.</h4></div></section><section><div><p><img src="https://www.omzlo.com/uploads/std_attiny-406-macro.jpg" alt=""></p>

<h2 id="introduction">Introduction</h2>

<p>Are you an 8-bit or a 32-bit programmer? </p>

<p>At OMZLO, we have been mainly focussing our development efforts on newer 32-bit Arm-Cortex chips (STM32 and SAMD), which typically offer more RAM, more speed, more peripherals, at a similar or lower price-point than older 8-bit MCUs. But 8-bit MCUs are far from dead. Microchip has notably released a new series of chips, collectively branded as the "tinyAVR 0-series", which offer more modern peripherals than the older AVR chips at a very competitive price point. They seem like the perfect candidate for simple products that don't need all the features and fine-tuning capabilities of the newer 32-bit MCUs. 8-bit MCUs are also substantially simpler to program, which translates into faster development time. </p>

<p>Thanks to the success of the Arduino UNO, there are tons of tutorials online that explain how to program 8-bit Atmega328 microcontrollers and their cousins like the Attiny85 using direct register access, without the Arduino language or any vendor IDE such as Atmel Studio. Just google "atmega328 blinky". All you need is an AVR C-compiler, a text editor, <a href="https://www.nongnu.org/avrdude/">avrdude</a>, and an AVR programmer. Some <a href="https://www.instructables.com/id/Getting-Started-With-the-ATMega328P/">resources</a> even show how to also build the electronics needed to get a basic atmega328 running on a breadboard. However, it's hard to find the same information for these newer "tinyAVR 0" chips.</p>

<p>Of course, Microchip offers all the tools necessary to program these newer "TinyAVR" MCUs with their windows-only IDE. There are also "Arduino cores" for some of these newer "TinyAVR" MCUs that let you program them with the Arduino IDE. But again, if you like to write code for MCUs in "baremetal" style, with your favorite text editor, a makefile, and a c-compiler, there are few resources available online. </p>

<p>In this blog post, we will describe how to program a <a href="https://www.ladyada.net/learn/proj1/blinky.html">blinky</a> firmware on an <strong>Attiny406</strong>, from the ground up, using the simplest tools. Most of the things described here can be easily transposed to other TinyAVR MCUs. Our approach is generally guided toward macOS or Linux users, but should also be applicable in an MS-Windows environment with a few minor changes.</p>

<h2 id="hardware">Hardware</h2>

<p>We decided to play with the <a href="https://www.microchip.com/wwwproducts/en/ATTINY406">Attiny406</a>, with a view of using it in the future to replace the Attiny45 we currently use on the <a href="https://www.omzlo.com/articles/the-piwatcher">PiWatcher</a>, our Raspberry-Pi watchdog. The Attiny406 has 4K of flash space, 256 bytes of RAM, and can run at 20Mhz without an external clock source.</p>

<p>One of the most important differences between the new TinyAVR MCUs and the older classic AVR MCU like the Attiny85 is that the newer chips use a different programming protocol called UPDI, which requires only 3 pins, as opposed to the 6-pin ISP on the classic AVRs.</p>

<p>A little research shows that programming TinyAVRs with UPDI can be achieved with a simple USB-to-serial cable and a resistor, thanks to a python tool called <a href="https://github.com/mraardvark/pyupdi">pyupdi</a>, which suggests the following connection diagram for firmware upload:</p>
<pre>                        Vcc                     Vcc
                        +-+                     +-+
                         |                       |
 +---------------------+ |                       | +--------------------+
 | Serial port         +-+                       +-+  AVR device        |
 |                     |      +----------+         |                    |
 |                  TX +------+   4k7    +---------+ UPDI               |
 |                     |      +----------+    |    |                    |
 |                     |                      |    |                    |
 |                  RX +----------------------+    |                    |
 |                     |                           |                    |
 |                     +--+                     +--+                    |
 +---------------------+  |                     |  +--------------------+
                         +-+                   +-+
                         GND                   GND
</pre>
<h3 id="shematic">shematic</h3>

<p>We created a minimalistic breakout board for the Attiny406. The board can be powered by 5V through USB or a lower 3.3V through dedicated VCC/GND pins. An LED and a button were also fitted on the board. For testing purposes, we decided to embed the 4.7K resistor needed for the UPDI programming directly in the hardware (i.e. resistor <em>R2</em>). 
This gives us the following schematic:</p>

<p><img src="https://www.omzlo.com/uploads/attiny406-schematic.png" alt="schematic"></p>

<h3 id="board">Board</h3>

<p>The resulting breakout board is tiny and fits conveniently on a small breadboard. The design files are <a href="https://aisler.net/p/SIEGFIYL">shared on aisler.net</a>.</p>

<p><img src="https://www.omzlo.com/uploads/std_attiny-406-breadboard.jpg" alt=""></p>

<p>Programming the Attiny406 on the board with a USB-serial cable is done by connecting the headers on the board edge:</p>

<p><img src="https://www.omzlo.com/uploads/attiny406-prog.png" alt=""></p>

<h2 id="software">Software</h2>

<h3 id="pyudpi">pyudpi</h3>

<p>We installed <strong>pyupdi</strong> following the instructions provided on <a href="https://github.com/mraardvark/pyupdi">their webpage</a>. </p>

<p>We connected our USB-Serial cable to the board with the 4 dedicated UPDI pins available on the board. Our USB-Serial converter shows up as the file <code>/dev/tty.usbserial-FTF5HUAV</code> on a MacOS system.</p>

<p>To test that the programmer recognizes the Attiny406, you can issue a command similar to the following, adapting the path for the USB-serial converter to your setup:</p>
<pre>pyupdi -d tiny406 -c /dev/tty.usbserial-FTF5HUAV -i
</pre>
<p>This should result in the following output if all goes well:</p>
<pre>Device info: {'family': 'tinyAVR', 'nvm': 'P:0', 'ocd': 'D:0', 'osc': '3', 'device_id': '1E9225', 'device_rev': '0.1'}
</pre>
<h3 id="the-c-compiler">The C compiler</h3>

<p>The typical <strong>avr-gcc</strong> available on macOS with <a href="https://brew.sh/">homebrew</a> did not seem to recognize the Attiny406 as a compiler target, so we went off to install the avr-gcc compiler provided by Microchip, which is available <a href="https://www.microchip.com/mplab/avr-support/avr-and-arm-toolchains-c-compilers">here</a>. Downloading the compiler requires you to create an account on the Microchip website, which is a bit annoying. </p>

<p><img src="https://www.omzlo.com/uploads/avr-toolchain.png" alt="AVR toolchain link"></p>

<p>Once downloaded, we extracted the provided archive in a dedicated directory. The <code>bin</code> directory in the archive should be added to the <code>PATH</code> variable to make your life easier. Assuming the downloaded compiler is stored in the directory <code>$HOME/Src/avr8-gnu-toolchain-darwin_x86_64</code>, the PATH can be altered by adding the following line to your <code>.bash_profile</code> file:</p>
<pre>export PATH=$PATH:$HOME/Src/avr8-gnu-toolchain-darwin_x86_64/bin/
</pre>
<p>Newer Attiny MCUs are not supported out of the box by the Microchip <strong>avc-gcc</strong> compiler. You need to download a dedicated <em>Attiny Device Pack</em> from <a href="http://packs.download.atmel.com/">their website</a>, as shown below:</p>

<p><img src="https://www.omzlo.com/uploads/microchip-pack-repository.png" alt="AVR toolchain link"></p>

<p>The resulting downloaded <em>Device Pack</em> is named <code>Atmel.ATtiny_DFP.1.6.326.atpack</code> (or similar depending on versioning). Though the extension is <code>.atpack</code>, the file is actually a zip archive. We changed the extension to <code>.zip</code> and extracted the package in the directory <code>$HOME/Src/Atmel.ATtiny_DFP.1.6.326</code> next to the compiler files. </p>

<h3 id="c-program">C program</h3>

<p>We created the following program that blinks the LED on pin PB5 of our Attiny board at a frequency of 1Hz.</p>
<pre><span>#include &lt;avr/io.h&gt;
#include &lt;util/delay.h&gt;
</span>
<span>int</span> <span>main</span><span>()</span> <span>{</span>
    <span>_PROTECTED_WRITE</span><span>(</span><span>CLKCTRL</span><span>.</span><span>MCLKCTRLB</span><span>,</span> <span>0</span><span>);</span> <span>// set to 20Mhz (assuming fuse 0x02 is set to 2)</span>

    <span>PORTB</span><span>.</span><span>DIRSET</span> <span>=</span> <span>(</span><span>1</span><span>&lt;&lt;</span><span>5</span><span>);</span>
    <span>for</span> <span>(;;)</span> <span>{</span>
        <span>PORTB</span><span>.</span><span>OUTSET</span> <span>=</span> <span>(</span><span>1</span><span>&lt;&lt;</span><span>5</span><span>);</span>
        <span>_delay_ms</span><span>(</span><span>500</span><span>);</span>
        <span>PORTB</span><span>.</span><span>OUTCLR</span> <span>=</span> <span>(</span><span>1</span><span>&lt;&lt;</span><span>5</span><span>);</span>
        <span>_delay_ms</span><span>(</span><span>500</span><span>);</span>
    <span>}</span>
<span>}</span>
</pre>
<p>The code looks very similar to what you would see on a classic AVR "blinky" program. One visible change is the use of structures to access various registers of the MCU: e.g instead of setting bits in <code>PORTB</code>, you access <code>PORTB.DIRSET</code>.</p>

<p>The other visible change is the clock setup code <code>_PROTECTED_WRITE(CLKCTRL.MCLKCTRLB, 0)</code>. Out of the box, at reset, the Attiny406 runs at 3.33Mhz, which corresponds to a base frequency of 20Mhz with a 6x clock divider applied. To enable the full 20Mhz speed, the register <code>CLKCTRL.MCLKCTRLB</code> is cleared. Because this register needs to be protected against accidental changes, the Attiny406 requires a specific programming sequence to modify it. Fortunately, this is natively offered by the macro <code>_PROTECTED_WRITE</code>. More details are available in the <a href="http://ww1.microchip.com/downloads/en/DeviceDoc/ATtiny406-DataSheet-DS40001976B.pdf">Attiny406 datasheet</a>.</p>

<p>In comparison with an STM32 or a SAMD21, the code is blissfully simple. </p>

<h3 id="makefile">Makefile</h3>

<p>We assume the following directory structure where:</p>

<ul>
<li><code>Src/Atmel.ATtiny_DFP.1.6.326/</code> is the location of the Microchip <em>Device Pack</em></li>
<li><code>Src/attiny406-test/</code> is the directory where the code above is stored in a file called <code>main.c</code></li>
</ul>

<p>Compiling the code can be done by issuing the following command within <code>attiny406-test/</code> directory,:</p>
<pre>avr-gcc -mmcu=attiny406 -B ../Atmel.ATtiny_DFP.1.6.326/gcc/dev/attiny406/ -O3 -I ../Atmel.ATtiny_DFP.1.6.326/include/ -DF_CPU=20000000L -o attiny406-test.elf main.c
</pre>
<p>An <code>-O</code> optimization flag is required to make the <code>_delay_ms()</code> function calls work successfully, as well as defining the variable F_CPU to reflect the expected chip clock speed. The rest of the parameters provide the location of the Attiny406 device-specific files we previously extracted from the <em>Device Pack</em>.</p>

<p>Uploading the firmware to the MCU requires a conversion to the intel HEX format and a call to the <strong>pyupdi</strong> tool. To address all these steps, we created a simple Makefile.</p>
<pre><span>OBJS</span><span>=</span>main.o
<span>ELF</span><span>=</span><span>$(</span>notdir <span>$(</span>CURDIR<span>))</span>.elf  
<span>HEX</span><span>=</span><span>$(</span>notdir <span>$(</span>CURDIR<span>))</span>.hex
<span>F_CPU</span><span>=</span>20000000L


<span>CFLAGS</span><span>=</span><span>-mmcu</span><span>=</span>attiny406 <span>-B</span> ../Atmel.ATtiny_DFP.1.6.326/gcc/dev/attiny406/ <span>-O3</span>
CFLAGS+<span>=</span><span>-I</span> ../Atmel.ATtiny_DFP.1.6.326/include/ <span>-DF_CPU</span><span>=</span><span>$(</span>F_CPU<span>)</span>
<span>LDFLAGS</span><span>=</span><span>-mmcu</span><span>=</span>attiny406 <span>-B</span> ../Atmel.ATtiny_DFP.1.6.326/gcc/dev/attiny406/
<span>CC</span><span>=</span>avr-gcc
<span>LD</span><span>=</span>avr-gcc

all:    <span>$(</span>HEX<span>)</span>  

<span>$(</span>ELF<span>)</span>: <span>$(</span>OBJS<span>)</span>
                <span>$(</span>LD<span>)</span> <span>$(</span>LDFLAGS<span>)</span> <span>-o</span> <span>$@</span> <span>$(</span>OBJS<span>)</span> <span>$(</span>LDLIBS<span>)</span>

<span>$(</span>HEX<span>)</span>: <span>$(</span>ELF<span>)</span>
                avr-objcopy <span>-O</span> ihex <span>-R</span> .eeprom <span>$&lt;</span> <span>$@</span>

flash:  <span>$(</span>HEX<span>)</span>
                pyupdi <span>-d</span> tiny406 <span>-c</span> /dev/tty.usbserial-FTF5HUAV <span>-f</span> attiny406-test.hex

read-fuses:
                pyupdi <span>-d</span> tiny406 <span>-c</span> /dev/tty.usbserial-FTF5HUAV <span>-fr</span>

clean:
                <span>rm</span> <span>-rf</span> <span>$(</span>OBJS<span>)</span> <span>$(</span>ELF<span>)</span> <span>$(</span>HEX<span>)</span>
</pre>
<p>To compile the code, we simply type <code>make</code>. Uploading is done with <code>make flash</code>. This Makefile can be further enhanced as needed.</p>

<h2 id="conclusion">Conclusion</h2>

<p>With the right tools, baremetal programming on the new TinyAVR MCUs is as simple as on its older AVR cousins. </p>

<p>If you have programming tips for the AVRTiny, please share them with us on <a href="https://twitter.com/OmzloElec">on Twitter</a> or in the comments below.</p>
</div></section><section><div><h4>Comments</h4><div><div><p>Hi, </p>

<p>It's great that …</p></div></div></div></section></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.omzlo.com/articles/baremetal-programming-on-the-tinyavr-0-micro-controllers">https://www.omzlo.com/articles/baremetal-programming-on-the-tinyavr-0-micro-controllers</a></em></p>]]>
            </description>
            <link>https://www.omzlo.com/articles/baremetal-programming-on-the-tinyavr-0-micro-controllers</link>
            <guid isPermaLink="false">hacker-news-small-sites-24648397</guid>
            <pubDate>Thu, 01 Oct 2020 07:37:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[MobX 6]]>
            </title>
            <description>
<![CDATA[
Score 139 | Comments 59 (<a href="https://news.ycombinator.com/item?id=24648363">thread link</a>) | @nikivi
<br/>
October 1, 2020 | https://michel.codes/blogs/mobx6 | <a href="https://web.archive.org/web/*/https://michel.codes/blogs/mobx6">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="___gatsby"><div tabindex="-1" role="group"><div><section><center><br><small>September 24, 2020</small></center><div><h2>Five years of MobX</h2>
<p>Time flies, and it has been 5.5 years since the first commit to MobX was made to build <a href="https://www.mendix.com/">Mendix Studio</a>.
In those years MobX has been adopted by well-known Software companies like Microsoft (Outlook), Netflix, Amazon and, my personal favorite, it runs in the Battlefield games by EA.
<a href="https://www.amazon.co.uk/MobX-Quick-Start-Guide-Supercharge/dp/1789344832/ref=sr_1_1?crid=BRUIHPUQL64D&amp;dchild=1&amp;keywords=mobx&amp;qid=1600809874&amp;s=books&amp;sprefix=mobx%2Caps%2C138&amp;sr=1-1">Books</a> and video courses have been written, and so have implementations in other languages.</p>
<p><span>
    <span></span>
    <img alt="Battlefield &amp; MobX" title="" src="https://michel.codes/static/5e0cc6842fdf39e4a7bf69a61fa15151/128ae/dice.jpg" srcset="https://michel.codes/static/5e0cc6842fdf39e4a7bf69a61fa15151/08cbc/dice.jpg 160w,
https://michel.codes/static/5e0cc6842fdf39e4a7bf69a61fa15151/37ac5/dice.jpg 320w,
https://michel.codes/static/5e0cc6842fdf39e4a7bf69a61fa15151/128ae/dice.jpg 640w,
https://michel.codes/static/5e0cc6842fdf39e4a7bf69a61fa15151/52793/dice.jpg 800w" sizes="(max-width: 640px) 100vw, 640px">
  </span></p>
<p>Yet, since that first commit the philosophy of the MobX hasn't changed: <em>Anything that can be derived from the application state, should be derived. Automatically.</em>.
The API hasn't changed too much since those days either,
and you will find the original <a href="https://www.mendix.com/blog/making-react-reactive-pursuit-high-performing-easily-maintainable-react-apps/">introduction of MobX</a> still pretty recognizable.
If <code>React.createClass</code> still rings a bell that is.</p>
<p>In contrast, the JavaScript eco-system has changed significantly over the years.
TypeScript and Babel have become the de-facto standards.
React went from <code>createClass</code> to classes to hook-based function components.
Yet, relevant JavaScript proposals for observables, Object.observe and decorators have never materialized.</p>
<p>MobX 6 is a new major version that doesn't bring many new features, but is rather a consolidation of MobX on the current state of affairs in JavaScript.
That doesn't come without a few plot twists, so if you are an existing MobX user, please read till the end!</p>
<h2>Bye bye decorators</h2>
<p>Let's start with the bad news: Using decorators is no longer the norm in MobX.
This is good news to some of you, but others will hate it.
Rightfully so, because I concur that the declarative syntax of decorators is still the best that can be offered.
When MobX started, it was a TypeScript only project, so decorators were available.
Still experimental, but obviously they were going to be standardized soon.
That was my expectation at least (I did mostly Java and C# before).
However, that moment still hasn't come yet, and two decorators proposals have been cancelled in the mean time.
Although they still can be transpiled.</p>
<p>So why did we stop using decorators by default?</p>
<p>First of all, the current experimental decorator implementations are incompatible with the soon-to-be-standardized class-fields proposal.
The legacy (Babel) and experimental (TypeScript) decorator implementations will no longer be able to <a href="https://github.com/tc39/proposal-class-fields/issues/151">trap class fields initializations</a>.</p>
<p>Secondly, using decorators has always been a serious hurdle in adopting and advocating MobX.
In Babel, it is quite fragile to set up.
<code>create-react-app</code> doesn't support it out of the box, and many developers rightfully don't like to use non-standard features.
Even though decorators have always been optional in MobX, the fact that they were prominent in the docs left many confused.
Or as one MobX fan <a href="https://github.com/mobxjs/mobx/issues/2325#issuecomment-693130586">puts it</a>:</p>
<p><em>I am guessing this choice [to drop decorators] was probably a good call. Maybe now without decorators I am hopeful I will be able to convey to people how amazing Mobx is and at least I won't hear the decorators excuse anymore. I have never seen an "@" sign scare so many people.</em></p>
<p>So, what does MobX after decorators look like?
Simply put, instead of decorating class members during the class definition, instance members need to be annotated in the constructor instead, using the new <code>makeObservable</code> utility:</p>
<div data-language="typescript"><pre><code><span>import</span> <span>{</span>observable<span>,</span> computed<span>,</span> action<span>,</span> makeObservable<span>}</span> <span>from</span> <span>"mobx"</span>


<span>class</span> <span>TodoStore</span> <span>{</span>
    @observable
    todos<span>:</span> Todo<span>[</span><span>]</span> <span>=</span> <span>[</span><span>]</span>

    @computed
    <span>get</span> <span>unfinishedTodoCount</span><span>(</span><span>)</span> <span>{</span>
        <span>return</span> <span>this</span><span>.</span>todos<span>.</span><span>filter</span><span>(</span>todo <span>=&gt;</span> <span>!</span>todo<span>.</span>done<span>)</span><span>.</span>length
    <span>}</span>

    @action
    <span>addTodo</span><span>(</span>todo<span>:</span> Todo<span>)</span> <span>{</span>
        <span>this</span><span>.</span>todos<span>.</span><span>push</span><span>(</span>todo<span>)</span>
    <span>}</span>
<span>}</span>


<span>class</span> <span>TodoStore</span> <span>{</span>
    todos<span>:</span> Todo<span>[</span><span>]</span> <span>=</span> <span>[</span><span>]</span>

    <span>constructor</span><span>(</span><span>)</span> <span>{</span>
        <span>makeObservable</span><span>(</span><span>this</span><span>,</span> <span>{</span>
            todos<span>:</span> observable<span>,</span>
            unfinishedTodoCount<span>:</span> computed<span>,</span>
            addTodo<span>:</span> action
        <span>}</span><span>)</span>
    <span>}</span>

    <span>get</span> <span>unfinishedTodoCount</span><span>(</span><span>)</span> <span>{</span>
        <span>return</span> <span>this</span><span>.</span>todos<span>.</span><span>filter</span><span>(</span>todo <span>=&gt;</span> <span>!</span>todo<span>.</span>done<span>)</span><span>.</span>length
    <span>}</span>

    <span>addTodo</span><span>(</span>todo<span>:</span> Todo<span>)</span> <span>{</span>
        <span>this</span><span>.</span>todos<span>.</span><span>push</span><span>(</span>todo<span>)</span>
    <span>}</span>
<span>}</span></code></pre></div>
<p>Admittedly, this is a slightly worse DX than before, since member and annotation are no longer co-located.
But the good news is that using <code>makeObservable</code> doesn't require any fancy build setup.
It should work everywhere out of the box.</p>
<p>Migrating an entire code-base from decorators to <code>makeObservable</code> might be challenging, so that is why we released a <a href="https://www.npmjs.com/package/mobx-undecorate">code-mod</a> together with MobX 6 to do that automatically!
Just run the command <code>npx mobx-undecorate</code> inside the folder where your source files live, and after that all decorators should have been magically rewritten!
After that, make sure to <a href="https://mobx.js.org/migrating-from-4-or-5.html#getting-started">update your TypeScript / babel config</a>, and you should be good to go!</p>
<h2>Introducing <code>makeAutoObservable</code></h2>
<p>We realize it is easier to make mistakes now that the annotations are no longer adjacent to the fields they are decorating.
Hence a convenience utility has been introduced that automates the annotation process by picking sane defaults: <code>makeAutoObservable</code>.
It will automatically pick the best annotation for every member of a class, thereby simplifying the above listing to:</p>
<div data-language="typescript"><pre><code><span>class</span> <span>TodoStore</span> <span>{</span>
    todos<span>:</span> Todo<span>[</span><span>]</span> <span>=</span> <span>[</span><span>]</span>

    <span>constructor</span><span>(</span><span>)</span> <span>{</span>
        <span>makeAutoObservable</span><span>(</span><span>this</span><span>)</span>
    <span>}</span>

    <span>get</span> <span>unfinishedTodoCount</span><span>(</span><span>)</span> <span>{</span>
        <span>return</span> <span>this</span><span>.</span>todos<span>.</span><span>filter</span><span>(</span>todo <span>=&gt;</span> <span>!</span>todo<span>.</span>done<span>)</span><span>.</span>length
    <span>}</span>

    <span>addTodo</span><span>(</span>todo<span>:</span> Todo<span>)</span> <span>{</span>
        <span>this</span><span>.</span>todos<span>.</span><span>push</span><span>(</span>todo<span>)</span>
    <span>}</span>
<span>}</span></code></pre></div>
<p>Note that it is possible to pass a map of <em>overrides</em> as second argument, in case you want to use a modifier.
For example: <code>makeAutoObservable(this, { todos: observable.shallow })</code>.
Pass <code>member: false</code> to have MobX ignore that member entirely.
(Technical fineprint: class methods will not be decorated with <code>action</code>, but with the new <code>autoAction</code>, this annotation will make methods suitable to be used both as a state updating action, or as function that derives information from state).</p>
<p>What I personally like about <code>makeAutoObservable</code> is that it plays really nice with factory functions.
Which is great if you prefer to not use classes (factory functions make it is easy to hide members and prevent issues with <code>this</code> and <code>new</code>. And they compose more easily).
The same store expressed as factory function will look as follows. Pick the style that suits you:</p>
<div data-language="typescript"><pre><code><span>function</span> <span>createTodoStore</span><span>(</span><span>)</span> <span>{</span>
    <span>const</span> store <span>=</span> <span>makeAutoObservable</span><span>(</span><span>{</span>
        todos<span>:</span> <span>[</span><span>]</span> <span>as</span> Todo<span>[</span><span>]</span><span>,</span>
        <span>get</span> <span>unfinishedTodoCount</span><span>(</span><span>)</span> <span>{</span>
            <span>return</span> store<span>.</span>todos<span>.</span><span>filter</span><span>(</span>todo <span>=&gt;</span> <span>!</span>todo<span>.</span>done<span>)</span><span>.</span>length
        <span>}</span><span>,</span>
        <span>addTodo</span><span>(</span>todo<span>:</span> Todo<span>)</span> <span>{</span>
            store<span>.</span>todos<span>.</span><span>push</span><span>(</span>todo<span>)</span>
        <span>}</span>
    <span>}</span><span>)</span>
    <span>return</span> store
<span>}</span></code></pre></div>
<h2>Fresh docs!</h2>
<p>Since decorators are no longer the norm, <a href="https://twitter.com/faassen">Martijn Faassen</a>, <a href="https://twitter.com/zangornjak">Žan Gornjak</a> and yours truly went over all the documentation.
We updated all examples and significantly restructured the docs that have grown quite organically over the years.
We feel the current docs are shorter, have less repetition, and better discuss common scenarios.
Also, we marked all non-essential knowledge in the docs with a {🚀} rocket emoji, to make it clear which knowledge is optional.
Hopefully it is much quicker now to find your way around in MobX!</p>
<p>On a similar note, we've updated all <a href="https://mobx.js.org/react-integration.html">React related documentation</a> to use function components instead of class components. And added documentation on how to use MobX with hooks, context and effects.
This knowledge existed before (little has changed technically), but was scattered all over the place.
As a result, we now recommend <code>mobx-react-lite</code> over <code>mobx-react</code> for (greenfield) projects that don't use class components.
As a result the separate mobx-react.js.org/ website has been deprecated.
All credits go to <a href="https://twitter.com/danielk_cz">Daniel K</a> for maintaining those two projects!</p>
<p>And finally, there is now a <a href="https://gum.co/fSocU">one pager MobX 6 cheat sheet 👨‍🎓</a> covering all the import mobx / mobx-react(-lite) API's.
(It is a great way to one-time sponser the project in an invoicable way).</p>
<h2>Improved browser support</h2>
<p>A probably little surprising improvement in MobX 6 is that it supports <em>more</em> JavaScript engines than MobX 5.
MobX 5 required proxy support, making MobX unsuitable for Internet Explorer or React Native (depending on the engine).
For this reason MobX 4 was still actively maintained.
However, MobX 6 replaces both at once.</p>
<p>By default MobX 6 will still require Proxies, but it is possible to opt-out from Proxy usage in case you need to support older engines.
And, as a result, it is now possible for MobX 6 to warn in development mode when features that would require proxies are used.
See the documentation for more <a href="https://mobx.js.org/configuration.html#proxy-support">details</a>.</p>
<div data-language="typescript"><pre><code><span>import</span> <span>{</span> configure <span>}</span> <span>from</span> <span>"mobx"</span>

<span>configure</span><span>(</span><span>{</span>
    
    
    
    useProxies<span>:</span> <span>"never"</span>
<span>}</span><span>)</span></code></pre></div>
<h2>Decorators are back!</h2>
<p>Ok, time for the plot twist. MobX 6 stills supports decorators!
The decorator implementation in MobX 6 is entirely different from the one in earlier versions, but does work with the current implementations in TypeScript and Babel.
It basically provides an alternative way to construct the annotations map for <code>makeObservable</code>, and allows us to rewrite the first example as:</p>
<div data-language="typescript"><pre><code><span>class</span> <span>TodoStore</span> <span>{</span>
    @observable
    todos<span>:</span> Todo<span>[</span><span>]</span> <span>=</span> <span>[</span><span>]</span>

    <span>constructor</span><span>(</span><span>)</span> <span>{</span>
        <span>makeObservable</span><span>(</span><span>this</span><span>)</span>
    <span>}</span>

    @computed
    <span>get</span> <span>unfinishedTodoCount</span><span>(</span><span>)</span> <span>{</span>
        <span>return</span> <span>this</span><span>.</span>todos<span>.</span><span>filter</span><span>(</span>todo <span>=&gt;</span> <span>!</span>todo<span>.</span>done<span>)</span><span>.</span>length
    <span>}</span>

    @action
    <span>addTodo</span><span>(</span>todo<span>:</span> Todo<span>)</span> <span>{</span>
        <span>this</span><span>.</span>todos<span>.</span><span>push</span><span>(</span>todo<span>)</span>
    <span>}</span>
<span>}</span></code></pre></div>
<p>Note that we still need to add a constructor to the class, but this time we omit the second argument to <code>makeObservable</code>, so that it will rely on the decorators instead.
We don't recommend this set up for greenfield projects, after all decorators are still experimental, but this is a great compromise for
existing code bases.
Generating constructors without removing decorators is supported by <code>mobx-undecorate</code> as well, and can be achieved by running <code>npx mobx-undecorate --keepDecorators</code>.</p>
<p>And here is even more good news: There is a fresh <a href="https://github.com/tc39/proposal-decorators">decorators proposal</a> being championed by the tireless hero <a href="https://twitter.com/littledan">Daniel Ehrenberg</a>.
I've been a bit involved in it, and the MobX use case has inspired the proposal.
So the benefits of the fresh decorator implementation are that it a) solves the compatibility issue with the class fields spec discussed above, and
b) it also paves the way …</p></div></section></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://michel.codes/blogs/mobx6">https://michel.codes/blogs/mobx6</a></em></p>]]>
            </description>
            <link>https://michel.codes/blogs/mobx6</link>
            <guid isPermaLink="false">hacker-news-small-sites-24648363</guid>
            <pubDate>Thu, 01 Oct 2020 07:33:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[You're Allowed to Write Slow Rust Code]]>
            </title>
            <description>
<![CDATA[
Score 32 | Comments 54 (<a href="https://news.ycombinator.com/item?id=24647910">thread link</a>) | @ingve
<br/>
September 30, 2020 | https://blog.jonstodle.com/youre-allowed-to-write-slow-rust-code/ | <a href="https://web.archive.org/web/*/https://blog.jonstodle.com/youre-allowed-to-write-slow-rust-code/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="blog-post">
    
    
    <article>
        <p>There's a thing that comes up from time to time in the Rust community: people wanting to optimize their code. Make the code run faster. Make it allocate less memory. These are worthy goals, but maybe not necessary for all projects. Just because your program is written in Rust, it doesn't have to be optimized to the moon and back to do it's job. In a lot of cases, you'll be fine using <code>.clone()</code>.</p>
<p>There's a fantastic quote from a discussion on the <a href="https://users.rust-lang.org/">Rust user forums</a> which I always think of when these discussions emerge:</p>
<blockquote>
<p>Just because Rust allows you to write super cool non-allocating zero-copy algorithms safely, doesn't mean every algorithm you write should be super cool, zero-copy and non-allocating.<br>
-- <a href="https://users.rust-lang.org/t/feeling-rust-is-so-difficult/29962/15">trentj on The Rust Programming Language Forum</a></p>
</blockquote>
<p>Of course there's a time and place for <em>super cool no-allocating zero-copy algorithms</em>, but very often it's not the time, nor the place. You can write fantastically effective code with Rust, but <strong>you don't have to</strong>! A lot of the time it's entirely fine to just write code that works with minimal effort. You don't have to spend 4 days trying to figure out how lifetimes work just to avoid calling <code>.clone()</code> a few times.</p>
<p>Don't spend time trying to make micro optimizations now. Take the easy route. You'll probably come back to that piece of code in a few months time, smile, and change that <code>.clone()</code> to something more efficient.</p>
<p>Happy coding!</p>
<p><small>NB: Watch this <a href="https://youtu.be/rAl-9HwD858">video by Jon Gjengset</a> if you want a good, pragmatic walk through of lifetimes in Rust.</small></p>

    </article>
</div></div>]]>
            </description>
            <link>https://blog.jonstodle.com/youre-allowed-to-write-slow-rust-code/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24647910</guid>
            <pubDate>Thu, 01 Oct 2020 06:19:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Running GitHub Actions for Certain Commit Messages]]>
            </title>
            <description>
<![CDATA[
Score 76 | Comments 29 (<a href="https://news.ycombinator.com/item?id=24647722">thread link</a>) | @kiyanwang
<br/>
September 30, 2020 | https://ryangjchandler.co.uk/articles/running-github-actions-for-certain-commit-messages | <a href="https://web.archive.org/web/*/https://ryangjchandler.co.uk/articles/running-github-actions-for-certain-commit-messages">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <div>
            
                <section>
        
        <p>A quick look at how you can configure your GitHub Actions workflows to only run when a certain phrase is present in the commit message.</p>
                    <small>Published 5 days ago</small>
                            <span>|</span>
                <small>Updated 4 days ago</small>
                                                <p><span>
    Tooling
</span>
 
                                     <span>
    GitHub Actions
</span>
 
                            </p>
                        <article>
            <p>I'm going to be honest with you all for a second. I write a lot of <code>wip</code> commits. These commits are normally small changes that I want to push up to GitHub so that:</p>
<ol>
<li>I don't lose things if anything goes wrong and my backup hasn't picked it up.</li>
<li>If I can't describe the change I have just made.</li>
<li>If I'm demonstrating something to somebody on a pull-request.</li>
</ol>
<p>The problem is, my actions are setup to run on <code>push</code>, so every single <code>wip</code> commit gets run through the CI process, whether it be running tests, linting or formatting.</p>
<p>After doing some research, I found a way of preventing these from running on every single commit.</p>
<pre><code data-lang="yml"><span>jobs:</span>
  <span>format:</span>
    <span>runs-on:</span> <span>ubuntu-latest</span>
    <span>if:</span> <span>"! contains(github.event.head_commit.message, 'wip')"</span>
</code></pre>
<p>Now, whenever I push a <code>wip</code> commit or any commit that contains the word <code>wip</code>, it will be marked as skipped inside of GitHub actions.</p>
<p>You could also flip the logic and perhaps do something like:</p>
<pre><code data-lang="yml"><span>jobs:</span>
  <span>format:</span>
    <span>runs-on:</span> <span>ubuntu-latest</span>
    <span>if:</span> <span>"contains(github.event.head_commit.message, '[build]')"</span>
</code></pre>
<p>Any commit that contains <code>[build]</code> will now trigger these jobs, everything else will be skipped.</p>
<p>You can thank me later! 😉</p>

        </article>
    </section>
        </div>
    </div></div>]]>
            </description>
            <link>https://ryangjchandler.co.uk/articles/running-github-actions-for-certain-commit-messages</link>
            <guid isPermaLink="false">hacker-news-small-sites-24647722</guid>
            <pubDate>Thu, 01 Oct 2020 05:41:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Computer Dungeon Slash Postmortem]]>
            </title>
            <description>
<![CDATA[
Score 30 | Comments 4 (<a href="https://news.ycombinator.com/item?id=24646063">thread link</a>) | @panic
<br/>
September 30, 2020 | https://museumofzzt.com/article/496/a-computer-dungeon-slash-postmortem | <a href="https://web.archive.org/web/*/https://museumofzzt.com/article/496/a-computer-dungeon-slash-postmortem">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article data-article_id="496">


    

<p><img src="https://museumofzzt.com/static/images/articles/cl/2020/cdslash/image2.png"></p>


        

    


<p>I consider <a href="https://museumofzzt.com/file/c/CDZ20MOZ.ZIP" target="_blank"><i>Computer Dungeon Slash: ZZT 2.0</i></a> my personal best for ZZT games. I've now released two versions, one in September of 2019 and then another with some updates and optimizations in May of 2020. Aside from a couple of smaller errors and special-thanks additions, there's not much more to fix, so this will probably be the final version with any major changes.</p>

<p>Like some of my previous ZZT games, it relies heavily on procedural generation, with apparently such complexity that Dr. Dos called it "basically sorcery" during their <a href="https://museumofzzt.com/article/479/livestream-computer-dungeon-slash-zzt-20">playthrough on Twitch</a>, which I took as a great compliment. He also mentioned that this game, its generators in particular, could use a write-up. So I wrote one!</p>

<p><img src="https://museumofzzt.com/static/images/articles/cl/2020/cdslash/image24.png"></p>

<p>In case you're reading this and unfamiliar with this game, it concerns a player finding themselves in the town of Habeas Corpus, where almost everyone and everything has been swallowed by the dungeon.</p>

<p>The player's task is to brave the randomly-generated dungeon, rescuing the town and townspeople from its clutches.</p>

<p>There's not much more plot or lore than the above, since I focused mainly on characterization in my worldbuilding and most of the actual plot isn't revealed until the end.</p>

<p>So what about the workings of this game?</p>

<p>I'll start with "sorcery"--there's something to that, for sure. When I work with procedural generation it feels a bit like alchemy. Scientific, but also a little bit mysterious and magical. I hope this article helps you better understand the scientific side of that coin.</p>

<p>For readers not intimately familiar with ZZT, one reason a veteran ZZTer would call my level generation "sorcery"  is its limitations. ZZT is a 1991 DOS game-creation-system, after all, simple enough for 8-year-old me to use. So if you don't know anything about ZZT coming in, I hope this write-up helps you better understand the absurdity and appeal of working in it and pushing its limits.</p>

<p>Further, if you came into this wanting to know how this stuff works so that you can experiment with it or even improve on it, I want you to be empowered to do so.</p>

<h2>Goals</h2>

<p>With <i>Computer Dungeon Slash: ZZT</i> (called <i>CDZ</i> here for short) I had three goals for generation. I wanted levels to be interesting to look at, fun to play, and fair. What does fair mean?</p>

<p>Most previous ZZT releases with procedural generation would probably not soft-lock players (block them off from finishing the game). In the early 2000s when this fad hit, most ZZTers involved were in high school and "probably not" was enough. But that small chance of soft-locking players with my generators annoyed me even then.</p>

<p>With <i>CDZ</i>, I wanted some certainty that my algorithms absolutely would not soft-lock players.</p>

<p>With these goals in mind, let's look at the tools I had to accomplish them.</p>

<h2>Building Blocks for Procedural Level Generation in ZZT</h2>

<p>ZZT is tile-based, so making it create its own levels is kind of like generating dungeons for classic ASCII roguelikes, except with much more restrictive tools and limits than, for example, C++ or Python. There's no way to easily store level layout data outside of "in the level", and ZZT boasts precious few variables and only ten true-or-false flags. In addition, the entire game is made up of "boards" of only 60x25 tiles! Despite being such a limited system, ZZT lets us do a fair amount.</p>

<p><img src="https://museumofzzt.com/static/images/articles/cl/2020/cdslash/image4.png">
<img src="https://museumofzzt.com/static/images/articles/cl/2020/cdslash/image7.gif"></p>

<p>Almost any element (terrain or other object) that takes up a space on a board is helpful, but a few basic ones are laid out in a reference image on the left. Fake walls prove pretty invaluable because they don't block objects but help the engine easily keep track of where another terrain type <i>will</i> later appear.</p>

<p>While <i>CDZ</i> uses sliders and boulders to some extent, the classic examples of ZZT level generators using sliders and boulders are probably WiL's <i>Run-On</i> and Benco's <i>Lost</i>.</p>

<p>And of course, one of the elements of play is actually <i>called</i> an object, and can run little scripts in ZZT-OOP, the engine's default "language." ZZT-OOP has a number of helpful commands for procedural generation.</p>

<p>The <code>#change</code> command can change almost any ZZT gameplay element into almost any other, which is invaluable both for structuring and theming levels. <code>#put THING DIRECTION</code> and <code>#become THING</code> allow for level builder objects to modify environments directly, and they have a more complex use we'll go into later.</p>

<p>Procedural level generation in <i>CDZ</i> is random. Appropriately, ZZT-OOP's random directions proved immensely useful in making it happen. A number of situations call for a "four-sided" dice-roll, and ZZT does have an <i>rnd</i> direction (randomly north, south, east, or west), but as the reader may know, <i>rnd</i> is twice as likely to give an east-west result as a north-south. So what to do?</p>

<p>Well, there are also <i>rndne</i> (north or east) and <i>rndp DIRECTION</i> (one of two directions perpendicular to <i>DIRECTION</i>). Because <i>rndne</i> is a valid direction in itself, you can use <i>rndp rndne</i> to get a random cardinal direction with equal probability of each. (I'm ashamed that I didn't realize that one until reading Anna Anthropy's <i>ZZT</i> a few years back.)</p>

<p><img src="https://museumofzzt.com/static/images/articles/cl/2020/cdslash/image14.gif"></p>

<p>In ZZT, <code>#if blocked DIRECTION</code> tells an object whether it is blocked in a given direction. And <code>#send OBJECTNAME:LABEL</code> tells another object, <i>OBJECTNAME</i>, to immediately begin executing code starting with <i>:LABEL</i>.</p>

<p>Slime enemies move erratically and leave breakable walls behind, so you can change their color frequently to fill empty spaces with different colors of breakable walls.</p>

<p>One last limitation and one last "coding" trick deserves mention. ZZT has a limit of about 20 kilobytes per board (including code) before the board misbehaves or gets corrupted at runtime. Objects can use the command <code>#bind OBJECTNAME</code> to work from the same exact instance of the same code as the other object <i>OBJECTNAME</i>, saving valuable code space.</p>

<p>Nowadays, one can "pre-bind" objects with external editors, causing them to share identical labels and behaviors but eliminating the need for the 5+ bytes of space that a <code>#bind</code> command needs.</p>

<h2>Two Big Insights</h2>

<p><img src="https://museumofzzt.com/static/images/articles/cl/2020/cdslash/image18.png">
<img src="https://museumofzzt.com/static/images/articles/cl/2020/cdslash/image20.png"></p>

<p>In addition to the more concrete "tools" above, two big conceptual insights greatly impacted this project. The first is about level connectedness, and it hit me after reading Rabbitboots's musings on house generation in <a href="https://museumofzzt.com/file/d/dood2018.zip" target="_blank"><i>Doodads 2018</i></a>.</p>

<p>Say I have a house with four rooms, and I block off only one doorway in the house, as on the left. Any room in the house can still visit any other.</p>

<p>Rabbitboots goes on to note that if we make a larger house out of smaller ones, the large house remains fully connected.</p>

<p>If House A connects to House B and B connects to House C, then A connects to C.</p>

<p>This was huge for me. It gave me hope that I could avoid soft-locks while also making more interesting, varied levels.</p>

<p>Shortly after the 2019 release, while looking at TriphEd's maze generation in <a href="https://museumofzzt.com/file/b/BACKTRAX.zip" target="_blank"><i>Backtrax</i></a>, I had another "Aha!" moment.</p>


<p>The algorithm is best explained step-by-step, and you can follow along with the following roughly equivalent method if you have a pencil and paper.</p>

<p>(1) Start with a grid of dots. Any size 3 x 3 or up will do.</p>

<p>(2) Connect all the outer dots along the edge so that they make a rectangle.</p>

<p>(3) For each "middle dot" within the square, draw <i>exactly one line</i> from that dot to any dot directly above, below, left, or right of it. Edge dots can receive lines.</p>

<p>If you used a 3 x 3 grid of dots, the end result will resemble the 2 x 2 house above.</p>

<p><img src="https://museumofzzt.com/static/images/articles/cl/2020/cdslash/backtrax-levels.gif"></p>

<p>Any edge tile can access any other edge tile in this algorithm. It can leave some squares inaccessible from the edges, but this is acceptable if nothing essential to player progress is placed in those tiles.</p>

<p>In ZZT, you can accomplish this by having objects use <code>#put rndp rndne ELEMENT</code> on a grid, and that's exactly what <i>Backtrax</i> is doing.</p>

<p>A <i>very</i> small set of soft-lock possibilities does exist in <i>Backtrax</i>. Because there's a blocking linewall diagonally southeast of the lower-right-hand wall generator object, the wrong combinations of walls <i>could</i> block the player, but it is <i>incredibly</i> unlikely and easily remedied.</p>

<p>This is the most elegant level generator in ZZT to date--and also, in case it wasn't already elegant enough, it weighs in at only 10.9 kilobytes and re-uses its "grid" after you reach the exit, using a separate trick (that I won't discuss in detail here) to teleport the player back to the start for a new level.</p>

<p>Recognize TriphEd's genius.</p>

<p>After the initial <i>CDZ</i> release, I experimented a lot with this algorithm. Several generators in version 2.0 benefited from its use. We can now move slowly but surely into the actual inner workings of this game.</p>

<h2>Primary Generators</h2>

<p><img src="https://museumofzzt.com/static/images/articles/cl/2020/cdslash/image6.png"></p>

<p><i>Computer Dungeon Slash</i> level generators have a "primary generator" object that handles a lot of needed dice-rolls and uses <code>#send</code> to communicate its randomization to different groups of objects. It's usually set up as on the left, or similar.</p>

<p>This particular setup involves fake walls placed north, south, east, and west of the primary generator and water (a blocking terrain) in the four corners. To make a four-direction roll, it uses <code>#put rndp rndne gem</code> and then iterates over some variation of:</p>

<code>#if blocked n #send object:option1
#if blocked e #send object:option2
#if blocked s #send object:option3
#if blocked w #send object:option4</code>

<p><img src="https://museumofzzt.com/static/images/articles/cl/2020/cdslash/image16.png"></p>

<p>The objects referred to in the <code>#send object:option</code> commands  are pre-bound objects with exactly the same code, and positioned so that only one of them will place a wall, generate an important key, etc. at the time they're called. In this example, the pre-bound group of objects has this code:</p><p>

<code>@object
#cycle 1
#end
:option1
#if blocked n become solid
#die
:option2
#if blocked e become solid
#die
:option3
#if blocked s become solid
#die
:option4
#if blocked w become solid
#die</code></p><p>There is a fake wall in the middle of the house, so that only one object becomes a wall, and the rest die. Then the primary generator turns the fake into a solid wall.</p>

<p><img src="https://museumofzzt.com/static/images/articles/cl/2020/cdslash/image23.gif"></p>

<p>This method also extends to larger houses similar to those in the <i>Doodads 2018</i> example, and can …</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://museumofzzt.com/article/496/a-computer-dungeon-slash-postmortem">https://museumofzzt.com/article/496/a-computer-dungeon-slash-postmortem</a></em></p>]]>
            </description>
            <link>https://museumofzzt.com/article/496/a-computer-dungeon-slash-postmortem</link>
            <guid isPermaLink="false">hacker-news-small-sites-24646063</guid>
            <pubDate>Thu, 01 Oct 2020 00:59:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Ontario doctors sign letter to Premier advising against sweeping lockdowns]]>
            </title>
            <description>
<![CDATA[
Score 108 | Comments 175 (<a href="https://news.ycombinator.com/item?id=24645821">thread link</a>) | @mrfusion
<br/>
September 30, 2020 | https://beta.ctvnews.ca/local/ottawa/2020/9/30/1_5126193.html | <a href="https://web.archive.org/web/*/https://beta.ctvnews.ca/local/ottawa/2020/9/30/1_5126193.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <div>



<div>
    
        <p>Published Sept. 30, 2020 9:40 a.m. ET</p>
        <p>Updated  Sept. 30, 2020 7:26 p.m. ET</p>
    
</div>



  


    
        
        
    
    
    <amp-iframe resizable="" width="16" height="17" layout="responsive" sandbox="allow-scripts allow-same-origin allow-popups allow-presentation" allowfullscreen="" frameborder="0" src="https://ampvideo.ctvnews.ca/content/ctvnews/en/local/ottawa/2020/9/30/1_5126193.vidi.root-responsivegrid-vidicomponent.html?preventDefault=true">
        
        <p>Click to Expand</p>
    </amp-iframe>





    <p>OTTAWA -- 	Twenty-one Ontario doctors have signed a joint letter to Premier Doug Ford, urging him not to issue a new lockdown this fall because of rising COVID-19 case numbers.</p><p>	Daily numbers of new cases have risen dramatically in recent days, with Ontario recording <a href="https://toronto.ctvnews.ca/new-covid-19-cases-in-ontario-reach-highest-mark-ever-1.5122863" target="_blank">700 new cases of COVID-19 on Monday</a> – the highest number of new cases recorded in a single day.</p><p>	However, the 21 doctors who signed the letter to the premier say another provincewide lockdown—similar to what was in place in the spring—would not be helpful.</p><ul>	<li>		<a href="#Full letter"><i>Read the full letter below</i></a></li></ul><p>	"We are writing this letter in support of the governments’ plan to use a tactical localized approach, rather than sweeping new lockdown measures, to deal with the increasing COVID case numbers in Ontario," the letter says.&nbsp;</p><p>	"Lockdowns have been shown not to eliminate the virus. While they slow the spread of the virus, this only lasts as long as the lockdown lasts. This creates a situation where there is no way to end the lockdown, and society cannot move forward in vitally important ways including in the health sector, the economy and other critically important instrumental goods including education, recreation, and healthy human social interactions."</p><p>	Speaking on Newstalk 580 CFRA's "The Morning Rush with Bill Carroll" in Ottawa, CTV's infectious disease specialist Dr. Neil Rau—a signatory of the letter—pointed to two data points to consider when looking at the spread of COVID-19.</p><p>	"We're reacting to increased aggregate case numbers, but the percentage positive is not really as bad as it used to be," he said. "We're testing more people, so we're finding more cases […] We're driving our numbers up, it's worse than it was in the summer, but it's not what it was last winter and life has to go on."</p><ul>	<li>		<a href="https://www.iheartradio.ca/580-cfra/podcasts/the-morning-rush-dr-neil-rau-interview-why-we-don-t-want-another-lockdown-1.13612912?mode=Article" target="_blank"><strong>LISTEN NOW: "The Morning Rush": Dr. Neil Rau - Why we don't want another lockdown</strong></a></li></ul><p>	Monday's 700 cases in Ontario came from 41,111 total tests, for a positive percentage rate of 1.7 per cent. On April 24, <a href="https://toronto.ctvnews.ca/highest-number-of-new-covid-19-cases-in-a-single-day-reported-by-ontario-health-officials-1.4910216" target="_blank">the previous watermark of 640 new cases in a single day</a>, the result came from 12,295 tests, for a positive percentage rate of 5.2 per cent.</p><p>	Testing capacity was lower in the spring than it is now, and testing criteria has changed over time; however, Dr. Rau and the other signatories of the letter said the increasing case numbers are not leading to unmanageable levels of hospitalizations.</p><p>	"In Ontario and other parts of the world, such as the European Union, increasing case loads are not necessarily translating into unmanageable levels of hospitalizations and ICU admissions," the letter says.</p><p>	The letter also points to other health impacts linked to the lockdown.</p><p>	"Hard data now exist showing the significant negative health effects shutting down society has caused. Overdoses have risen 40% in some jurisdictions. Extensive morbidity has been experienced by those whose surgery has been cancelled, and the ramifications for cancer patients whose diagnostic testing was delayed has yet to be determined," the letter states.</p><p>	"Economic harms are health harms," Dr. Rau told CFRA. "It sounds horrible to say, but it's true. Health is wealth. We all know this."</p><h2>	<strong>LETTER POINTS TO DISAGREEMENT AMONG HEALTH PROFESSIONALS</strong></h2><p>	Other Ontario health professionals have been arguing for increased restrictions as cases rise.</p><p>	Last week, the Ontario Hospital Association released a letter signed by 38 health professionals which <a href="https://ottawa.ctvnews.ca/ontario-hospital-association-calls-for-return-to-restrictions-on-non-essential-businesses-1.5119832" target="_blank">called for immediate restrictions to be re-imposed on non-essential businesses</a>, such as gyms, dine-in restaurants and bars, nightclubs, and theatres. It also calls on restrictions on other places where people can gather, such as places of worship.</p><p>	The letter from the OHA said regions where the speed of transmission was underestimated are “now facing the consequence of increased hospitalization rates, including a rise in intensive care unit (ICU) admissions and more deaths.”</p><p>	Hospitalizations in Ontario have been increasing, but have not yet reached the same level that was seen in the spring.</p><p>	According to <a href="https://covid-19.ontario.ca/data" target="_blank">data from the Ontario government</a>, there were 128 people in hospital in Ontario with COVID-19 complications on Monday—the day 700 new cases were recorded—up from 65 a week before; however, on April 24—when 640 new cases were recorded—government data shows that there were 910 people in hospital. The peak for hospitalizations in Ontario came in May, when there were days when more than 1,000 people were hospitalized. That number steadily decreased from May through the summer before it began going up again in September.</p><p>	Speaking on CTV Morning Live Ottawa, infectious disease specialist Dr. Abdu Sharkawy suggested t<a href="https://ottawa.ctvnews.ca/video?clipId=2045684" target="_blank">emporary restrictions on gathering would help curb the spread of COVID-19</a>.&nbsp;</p><p>	"We don't want to see our hospitals overwhelmed," he said. "We're still waiting for flu season and a whole bunch of other respiratory viruses to hit us and our capacity to be challenged. We don't want that to happen. We need everybody to try and simplify their lives and minimize anything that's non-essential."</p><p>	Dr. Sharkawy said regions where cases are rapidly rising may need to impose new restrictions to get the spread of the virus under control.</p><p>	"I think it's abundantly clear that, particularly in hot spots like Ottawa, Toronto and Peel region, the situation is not well controlled," he said. "Sometimes you need blunt instruments, even if they're temporary in nature, to make sure that you curtail the spread of this virus because it gets away from us a lot more quickly than many of us can anticipate sometimes."</p><p>	Dr. Sharkawy suggested hot spots follow the lead of Quebec, which imposed <a href="https://montreal.ctvnews.ca/life-in-the-red-zone-here-s-what-you-can-and-can-t-do-1.5125093" target="_blank">harsh restrictions on three areas in the province</a>, including Montreal and Quebec City, banning private gatherings and closing bars and restaurant dining rooms.</p><p>	"I think we should do it now," Dr. Sharkawy said of Ontario. "I think we all need to adopt an attitude and an approach that recognizes that we have to do what's absolutely necessary to keep everybody safe."</p><h2>	<strong>FULL LETTER FROM ONTARIO DOCTORS TO THE PREMIER</strong></h2><p>	Dear Premier Ford,</p><p>	We are writing this letter in support of the governments’ plan to use a tactical localized approach, rather than sweeping new lockdown measures, to deal with the increasing COVID case numbers in Ontario. Lockdowns have been shown not to eliminate the virus. While they slow the spread of the virus, this only lasts as long as the lockdown lasts. This creates a situation where there is no way to end the lockdown, and society cannot move forward in vitally important ways including in the health sector, the economy and other critically important instrumental goods including education, recreation, and healthy human social interactions.</p><p>	In Ontario the increase in cases at this time are in people under 60 years of age who are unlikely to become very ill. At the peak of the pandemic in Ontario in mid-April, 56% of cases were in ≥60 year olds, now in Sept only 14% of cases are in ≥60 year olds. In Ontario and other parts of the world, such as the European Union, increasing case loads are not necessarily translating into unmanageable levels of hospitalizations and ICU admissions. This is not a result of a lag in reporting of severe and fatal cases. While we understand the concerns that these cases could spill into vulnerable communities, we also need to balance the actual risk. As the virus circulates at manageable levels within the community, we need to continue the gains we have made in the protection of the vulnerable in long-term care and retirement institutions, and continue to educate other people about their individual risk, so that they can observe appropriate protective measures.</p><p>	Lockdowns have costs that have, to this point, not been included in the consideration of further measures. A full accounting of the implications on health and well-being must be included in the models, and be brought forward for public debate. Hard data now exist showing the significant negative health effects shutting down society has caused. Overdoses have risen 40% in some jurisdictions. Extensive morbidity has been experienced by those whose surgery has been cancelled, and the ramifications for cancer patients whose diagnostic testing was delayed has yet to be determined. A huge concern is the implication of closure of schools, and the ongoing reluctance we have seen in the large urban centers of sending children back to the classroom due to safety concerns. Global data clearly now show that children have an extremely low risk of serious illness, but they are disproportionately harmed by precautions. Children’s rights to societal care, mental health support and education must be protected. This cannot be achieved with ongoing or rotating lockdown.</p><p>	The invitation and involvement of other health experts to advise the government’s response beside individuals in Public Health and Infectious Diseases in addition to leaders in the business, securities and arts communities is essential. We also call for increased open debate, in the public forum, that hears voices from outside the medical and public health communities, in order to consider all points of view from society. This is a fundamental principle upon which democratic societies are built. All stakeholders should have an equal right to participation in public discourse when it comes to setting such fundamental and sweeping societal interventions.</p><p>	All have the right to feel their voices have been heard, and moreover to ensure factual credible data is openly debated, in contrast to the personal and political slants that have had apparent significant impacts on the management of the virus to date. Our society has borne enormous pain over the past 6 months. It’s time to do something different.</p><p>	Sincerely,</p><p>	Jane Batt MD, PhD, FRCPC. Respirologist, Associate Professor, Department of …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://beta.ctvnews.ca/local/ottawa/2020/9/30/1_5126193.html">https://beta.ctvnews.ca/local/ottawa/2020/9/30/1_5126193.html</a></em></p>]]>
            </description>
            <link>https://beta.ctvnews.ca/local/ottawa/2020/9/30/1_5126193.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24645821</guid>
            <pubDate>Thu, 01 Oct 2020 00:23:56 GMT</pubDate>
        </item>
    </channel>
</rss>
