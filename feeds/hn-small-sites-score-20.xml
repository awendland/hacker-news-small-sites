<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 20]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 20. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Sat, 17 Oct 2020 08:29:14 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-20.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Sat, 17 Oct 2020 08:29:14 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[LDM: My Favorite ARM Instruction]]>
            </title>
            <description>
<![CDATA[
Score 84 | Comments 74 (<a href="https://news.ycombinator.com/item?id=24785357">thread link</a>) | @one_and_only
<br/>
October 14, 2020 | https://keleshev.com/ldm-my-favorite-arm-instruction/ | <a href="https://web.archive.org/web/*/https://keleshev.com/ldm-my-favorite-arm-instruction/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
  


  

<center>Vladimir Keleshev • 2020-10-13</center>


<p>LDM—or <em>load multiple</em>—is my favorite assembly instruction of the ARM instruction set. Here’s why.</p>
<p>First, let’s discuss what LDM does. An example:</p>
<pre><code>ldm r4, {r0, r1, r2, r3}</code></pre>
<p>Here, it takes a <em>base register</em> (in this case, <code>r4</code>) and a <em>register set</em> (in this case, <code>{r0, r1, r2, r3}</code>). It loads consecutive words from the address in the base register into the registers in the set. In this example, the effect could be described using the following C-like pseudo-code:</p>
<pre><code>r0 = r4[0];
r1 = r4[1];
r2 = r4[2];
r3 = r4[3];</code></pre>
<p>That’s quite a few assignments for a single instruction! And that’s why it’s called <em>load multiple</em>.</p>
<p>The set notation also allows for ranges. We can rewrite the previous example as follows:</p>
<pre><code>ldm r4, {r0-r3}</code></pre>
<p>Any and all of the 16 ARM registers are allowed in the set. So, the following is legal:</p>
<pre><code>ldm r0, {r0, r1, r2, r3, r4, r5, r6, r7, r8, r9, r10, r11, r12, r13, r14, r15}</code></pre>
<p>The register set is encoded as a 16-bit mask in a 32-bit instruction. Here’s a simplified encoding of the original example:</p>
<figure>
<img src="https://keleshev.com/ldm-my-favorite-arm-instruction/ldm-encoding-arm.svg" alt=""><figcaption>Simplified encoding of the LDM instruction</figcaption>
</figure>
<p>Such instruction is a perfect fit for a <a href="https://en.wikipedia.org/wiki/Load%E2%80%93store_architecture">load-store architecture</a> like ARM, where the primary workflow is:</p>
<ul>
<li>load many values from memory into registers,</li>
<li>perform operations exclusively on registers,</li>
<li>store results back from registers into memory.</li>
</ul>
<p>The opposite of LDM is STM—<em>store multiple</em>.</p>
<!---Since both of them operate on *sets* of registers (which are implemented as bit masks), you can't directly select the order in which the values are loaded or stored.
The set `{r0, r1, r2}` is the same as `{r2, r1, r0}`.
That's why-->
<h2 id="block-copy">Block copy</h2>
<p>With these two, you can copy large blocks of memory fast. You can copy eight words (or 32 bytes!) of memory in just two instructions:</p>
<pre><code>ldm r0, {r4-r11}
stm r1, {r4-r11}</code></pre>
<p>LDM and STM also have auto-increment variants (denoted with “!”) where the base register is incremented by the number of words loaded/stored so that you can do the copying in a fast loop:</p>
<pre><code>ldm r0!, {r4-r11}
stm r1!, {r4-r11}</code></pre>
<h2 id="implementing-stacks">Implementing stacks</h2>
<p>ARM’s POP instruction is simply an alias for LDM with a stack pointer (and auto-increment). The following two are exactly the same:</p>
<pre><code>ldm sp!, {r0-r3}
pop {r0-r3}</code></pre>
<p>And the PUSH instruction is an alias for an STM variant (STMDB).</p>
<p>You can push and pop large quantities to and from the stack in one go. And if you replace SP by another register you can implement efficient stacks in other regions of memory. For example, you can implement a <a href="https://en.wikipedia.org/wiki/Shadow_stack">shadow stack</a> in the heap.</p>
<h2 id="saving-registers">Saving registers</h2>
<p>Are you hesitating to use the call-preserved registers because you need to save them, and you might as well use a stack slot anyway? Not any more, because you can save all call-preserved registers you want to use in one go:</p>
<pre><code>push {r4-r11}</code></pre>
<h2 id="prologue-and-epilogue">Prologue and epilogue</h2>
<p>On ARM, the first four arguments, the return address (LR) and the frame pointer (FP) are all passed in registers. That’s why it’s especially important to have efficient prologues and epilogues. Fortunately, you can save FP and LR in one go, using a fairly standard ARM prologue:</p>
<pre><code>push {fp, lr}</code></pre>
<p>And then restore both and return (for the epilogue):</p>
<pre><code>pop {fp, lr}
bx lr</code></pre>
<p>Even better, you can restore both and return in one go!</p>
<pre><code>pop {fp, pc}</code></pre>
<p>This works by popping the return address value (LR) into the program counter register (PC), so you don’t need an explicit return!</p>
<p>This is good enough in itself, but you can—<em>at the same time</em>—spill some arguments onto the stack (for example, if their address is taken):</p>
<pre><code>push {r0-r3, fp, lr}</code></pre>
<p>Or, you can save FP and LR and—<em>at the same time</em>—allocate some space on the stack:</p>
<pre><code>push {r0-r3, fp, lr}</code></pre>
<p>In this case, we push <code>r0-r3</code> not for their value but to advance the stack pointer by four words.</p>
<h2 id="arm64">ARM64</h2>
<p>I suspect it was a difficult trade-off, but when it was time to design the 64-bit version of the ARM instruction set, the decision was made to double the number of registers to 32. I remember reading a paper saying that this change improves the performance by about 6% across the board. With 32 registers it is no longer possible to encode a bitmask of all registers into a 32-bit long instruction. So, instead, ARM64 has LDP and STP: load pair and store pair, which are the spiritual successors of LDM and STM.</p>
<hr>
<p>This blog post started out originally as a <a href="https://twitter.com/keleshev/status/1285654345988673536">Twitter thread</a>. <a href="https://keleshev.com/" title="Home">■</a></p>
<hr>
<p><em>Did you like this blog post? If so, check out my new book:</em> Compiling to Assembly from Scratch. <em>It teaches you enough assembly programming and compiler fundamentals to implement a compiler for a small programming language. </em></p>


      
  <p><a href="https://keleshev.com/compiling-to-assembly-from-scratch">
       <img alt="Compiling to Assembly from Scratch, the book by Vladimir Keleshev" src="https://keleshev.com/compiling-to-assembly-from-scratch.jpg" width="200" height="300">
      </a>
  </p>
  <hr>


</div>]]>
            </description>
            <link>https://keleshev.com/ldm-my-favorite-arm-instruction/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24785357</guid>
            <pubDate>Thu, 15 Oct 2020 06:04:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Eric Yuan's Visa Application Was Rejected 8 Times]]>
            </title>
            <description>
<![CDATA[
Score 60 | Comments 64 (<a href="https://news.ycombinator.com/item?id=24783979">thread link</a>) | @shsachdev
<br/>
October 14, 2020 | https://www.careerfair.io/reviews/eric-yuan-effect | <a href="https://web.archive.org/web/*/https://www.careerfair.io/reviews/eric-yuan-effect">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <p>
I’ve been reading about Eric Yuan, founder of Zoom.
</p>
<p>
Yuan migrated to the USA from China in the 80s. He had heard Bill Gates speak about the internet and he wanted to be a part of the digital revolution. 
</p>
<p>
So he applied for his visa. He was rejected. He applied again. Rejected again.
</p>
<p>
9 tries. It took Eric Yuan 9 tries to finally get his visa for the USA.
</p>
<p>
Once in the USA, he started working at the video conferencing software company WebEx. 
</p>
<p>
He worked there for a decade and rose up the ranks to become the VP of Engineering. 
</p>
<p>
Under Yuan’s leadership, WebEx grew to more than 750 engineers and had an annual revenue of around $1B (and was later acquired by Cisco). Safe to say the company was doing well. 
</p>
<p>
But there was a problem. 
</p>
<p>
The video conferencing software <em>sucked</em>. 
</p>
<p>
Yuan would meet with customers and they would be unhappy. They’d complain about video and audio lag. Connectivity issues. All sorts of stuff. 
</p>
<p>
In Yuan’s own words:
</p>

<blockquote>
  Before I left Cisco I spent a lot of time talking to WebEx customers and every time I talked to them I felt very embarrassed because I did not see a single happy customer, and I tried to understand why that was.
    <span>Eric Yuan</span>
</blockquote>

<p>
So in 2011, Yuan left. He decided to start his own company with the mission of building the best video conferencing software in the world. 
</p>
<p>
After he left, 40 of the 800 engineers he worked with immediately joined him at Zoom. 
</p>
<p>
And according to <a href="https://twitter.com/dscheinm/status/1300544031458553859">this tweet</a>, almost all of the others sent in resumes to work with him. He had something like 1000 job inquiries within a week of announcing his leaving.
</p>
<p>
Talk about engineering loyalty. 
</p>
<p>
Today Zoom is valued at more than $40 billion. The pandemic may have accelerated the company’s growth but make no mistake: this was an overnight success 9 years in the making. 
</p>
<h2>Takeaway</h2>
<p>
I think the part that stands out the most to me is that Yuan actually had the courage to leave Cisco and go on to start Zoom. 
</p>
<p>
There is often great inertia that prevents us from leaving jobs we’re unhappy with. 
</p>
<p>
In Yuan’s case, he had by all measures a very successful career ever since he immigrated to the US. Most people in his shoes wouldn’t even bother resigning from a comfortable VP of Engineering position. 
</p>
<p>
So he could have settled and just resigned himself to the fact that maybe video conferencing software was supposed to be like this. After all, there was very little competition in the market. 
</p>
<p>
But he didn’t. He chose discomfort and hundreds of other engineers believed in him. 
</p>
<p>
Keep moving forward and don’t settle. You might be surprised at how many people follow you. 
</p>
          </div></div>]]>
            </description>
            <link>https://www.careerfair.io/reviews/eric-yuan-effect</link>
            <guid isPermaLink="false">hacker-news-small-sites-24783979</guid>
            <pubDate>Thu, 15 Oct 2020 01:59:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why software engineering processes and tools don’t work for machine learning]]>
            </title>
            <description>
<![CDATA[
Score 79 | Comments 70 (<a href="https://news.ycombinator.com/item?id=24781490">thread link</a>) | @ChefboyOG
<br/>
October 14, 2020 | https://www.comet.ml/site/why-software-engineering-processes-and-tools-dont-work-for-machine-learning/ | <a href="https://web.archive.org/web/*/https://www.comet.ml/site/why-software-engineering-processes-and-tools-dont-work-for-machine-learning/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		    <div>
			
<p>“AI is the new electricity.” At least, that’s what <a href="https://www.coursera.org/instructor/andrewng">Andrew Ng</a> suggested at this year’s <a href="https://remars.amazon.com/">Amazon re:MARS</a> conference. In his <a href="https://www.youtube.com/watch?v=j2nGxw8sKYU">keynote address</a>, Ng discussed the rapid growth of artificial intelligence (AI) — its steady march into industry after industry; the unrelenting presence of AI breakthroughs, technologies, or fears in the headlines each day; the tremendous amount of investment, both from established enterprises seeking to modernize (see: <a href="https://www.engadget.com/2019/11/19/sony-ai/">Sony</a>, a couple of weeks ago) as well as from venture investors parachuting into the market riding a wave of AI-focused founders.&nbsp;</p>



<p>“AI is the next big transformation,” Ng insists, and we’re watching the transformation unfold.</p>



<p>While AI may be the new electricity (and as a Data Scientist at <a href="http://comet.ml/">Comet</a>, I don’t need much convincing), significant challenges remain for the field to realize this potential.<strong> In this blog post, I’m going to talk about why data scientists and teams can’t rely on the tools and processes that software engineering teams have been using for the last 20 years for machine learning</strong> <strong>(ML).&nbsp;</strong></p>



<p>The reliance on the tools and processes of software engineering makes sense – data science and software engineering are both disciplines whose principal tool is<em> code</em>. Yet <em>what is being done</em> in data science teams is radically different from what is being done in software engineering teams. An inspection of the core differences between the two disciplines is a helpful exercise in clarifying how we should think about structuring our tools and processes for doing AI.&nbsp;</p>



<p>At Comet, we believe the adoption of tools and processes designed specifically for AI will help practitioners unlock and enable the type of revolutionary transformation Ng is speaking about.</p>



<h2>Different Disciplines, Different Processes</h2>



<p>Software engineering is a discipline whose aim is, considered broadly, the design and implementation of programs that a computer can execute to perform a defined function. Assuming the input to a software program is within the expected (or constrained) range of inputs, its behavior is knowable. In a <a href="https://leon.bottou.org/talks/2challenges">talk</a> at ICML in 2015, Leon Bottou formulated this well: in software engineering an algorithm or program can be proven <em>correct</em>, in the sense that given particular assumptions about the input, certain properties will be true when the algorithm or program terminates.</p>
<figure id="attachment_2550" aria-describedby="caption-attachment-2550"><img src="https://www.comet.ml/site/app/uploads/2019/12/Screen-Shot-2020-03-27-at-9.56.18-AM-1024x863.png" alt="ml vs software eng" width="500" height="422" srcset="https://www.comet.ml/site/app/uploads/2019/12/Screen-Shot-2020-03-27-at-9.56.18-AM-1024x863.png 1024w, https://www.comet.ml/site/app/uploads/2019/12/Screen-Shot-2020-03-27-at-9.56.18-AM-300x253.png 300w, https://www.comet.ml/site/app/uploads/2019/12/Screen-Shot-2020-03-27-at-9.56.18-AM-768x648.png 768w, https://www.comet.ml/site/app/uploads/2019/12/Screen-Shot-2020-03-27-at-9.56.18-AM.png 1110w" sizes="(max-width: 500px) 100vw, 500px" data-old-src="https://www.comet.ml/site/app/ewww/lazy/placeholder-1024x863.png" data-src="https://www.comet.ml/site/app/uploads/2019/12/Screen-Shot-2020-03-27-at-9.56.18-AM-1024x863.png" data-srcset="https://www.comet.ml/site/app/uploads/2019/12/Screen-Shot-2020-03-27-at-9.56.18-AM-1024x863.png 1024w, https://www.comet.ml/site/app/uploads/2019/12/Screen-Shot-2020-03-27-at-9.56.18-AM-300x253.png 300w, https://www.comet.ml/site/app/uploads/2019/12/Screen-Shot-2020-03-27-at-9.56.18-AM-768x648.png 768w, https://www.comet.ml/site/app/uploads/2019/12/Screen-Shot-2020-03-27-at-9.56.18-AM.png 1110w"><figcaption id="caption-attachment-2550">Source: Futurice</figcaption></figure>
<p>

The provable correctness of software programs has shaped the tools and processes we have built for doing software engineering. Consider one corollary characteristic of software programming that follows from provable correctness: if a program is provably correct for some input values, then the program contains sub-programs that are also provably correct for those input values. This is why engineering processes like <a href="https://en.wikipedia.org/wiki/Scaled_agile_framework">Agile</a> are, broadly speaking, successful and productive for software teams. Breaking apart these projects into sub-tasks works. Most <a href="https://en.wikipedia.org/wiki/Waterfall_model">waterfall</a> and <a href="https://en.wikipedia.org/wiki/Scrum_(software_development)">scrum</a> implementations also include sub-tasking as well.</p>


<figure>
<figure id="attachment_2552" aria-describedby="caption-attachment-2552"><img src="https://www.comet.ml/site/app/uploads/2019/12/Screen-Shot-2020-03-27-at-9.57.24-AM-1024x550.png" alt="" width="700" height="376" srcset="https://www.comet.ml/site/app/uploads/2019/12/Screen-Shot-2020-03-27-at-9.57.24-AM-1024x550.png 1024w, https://www.comet.ml/site/app/uploads/2019/12/Screen-Shot-2020-03-27-at-9.57.24-AM-300x161.png 300w, https://www.comet.ml/site/app/uploads/2019/12/Screen-Shot-2020-03-27-at-9.57.24-AM-768x413.png 768w, https://www.comet.ml/site/app/uploads/2019/12/Screen-Shot-2020-03-27-at-9.57.24-AM-1536x825.png 1536w, https://www.comet.ml/site/app/uploads/2019/12/Screen-Shot-2020-03-27-at-9.57.24-AM.png 1694w" sizes="(max-width: 700px) 100vw, 700px" data-old-src="https://www.comet.ml/site/app/ewww/lazy/placeholder-1024x550.png" data-src="https://www.comet.ml/site/app/uploads/2019/12/Screen-Shot-2020-03-27-at-9.57.24-AM-1024x550.png" data-srcset="https://www.comet.ml/site/app/uploads/2019/12/Screen-Shot-2020-03-27-at-9.57.24-AM-1024x550.png 1024w, https://www.comet.ml/site/app/uploads/2019/12/Screen-Shot-2020-03-27-at-9.57.24-AM-300x161.png 300w, https://www.comet.ml/site/app/uploads/2019/12/Screen-Shot-2020-03-27-at-9.57.24-AM-768x413.png 768w, https://www.comet.ml/site/app/uploads/2019/12/Screen-Shot-2020-03-27-at-9.57.24-AM-1536x825.png 1536w, https://www.comet.ml/site/app/uploads/2019/12/Screen-Shot-2020-03-27-at-9.57.24-AM.png 1694w"><figcaption id="caption-attachment-2552">Software Engineering vs. Machine Learning Lifecycle</figcaption></figure>
</figure>

<p>We see a lot of data science teams using workflow processes that are identical or broadly similar to these software methodologies. Unfortunately, they don’t work very well. The reason? The provable correctness of software engineering does not extend to AI and machine learning. In (supervised) machine learning, the only guarantee we have about a model we’ve built is that if the training set is an <a href="https://en.wikipedia.org/wiki/Independent_and_identically_distributed_random_variables">iid</a> (independent and identically distributed) sample from some distribution, then performance on another iid sample from the same distribution will be <em>close</em> to the performance on the training set. Because uncertainty is an intrinsic property of machine learning, sub-tasking can lead to unforeseeable downstream effects.&nbsp;</p>

<h2><strong>Why is uncertainty intrinsic to machine learning?</strong>&nbsp;</h2>

<p>Part of the answer lies in the fact that the problems that are both (a) interesting to us and (b) amenable to machine learning solutions (self-driving cars, object recognition, labeling images, and generative language models, to name a few) do not have a clear reproducible mathematical or programmatic specification. In place of specifications, machine learning systems feed in lots of data in order to detect patterns and generate predictions. Put another way, the <em>purpose of machine learning is to create a statistical proxy that can serve as a specification for one of these tasks</em>. We hope our collected data is a representative subsample of the real-world distribution, but in practice we cannot know exactly how well this condition is met. Finally, the algorithms and model architectures we use are complex, sufficiently complex that we cannot always break them apart into sub-models to understand precisely what is happening.&nbsp;</p>

<p>From this description, obstacles to the <em>knowability</em> of machine learning systems should be somewhat obvious. Inherent to the types of problems amenable to machine learning is a lack of a clear mathematical specification. The statistical proxy we use in the absence of a specification is accumulating lots of environmental data we <em>hope</em> is iid and representative. And the models we use to extract patterns from this collected data are sufficiently complex that we cannot reliably break them apart and understand precisely how they work. My colleague at Comet, Dhruv Nair, has written a three-part series on uncertainty in machine learning (here’s a link to <a href="https://www.comet.ml/blog/?p=662">Part I</a>) if you’d like to dig deeper into this topic.&nbsp;</p>

<p>Consider, then, the implications for something like the Agile methodology used on a machine learning project. We cannot possibly hope to break machine learning tasks into <em>sub-tasks</em>, tackled as part of some larger sprint and then pieced together like legos into a whole product, platform, or feature, because we cannot reliably predict how the sub-models, or the model itself, will function.&nbsp;</p>

<figure>
<figure id="attachment_2553" aria-describedby="caption-attachment-2553"><img src="https://www.comet.ml/site/app/uploads/2019/12/Screen-Shot-2020-03-27-at-9.58.40-AM-1024x738.png" alt="" width="700" height="504" srcset="https://www.comet.ml/site/app/uploads/2019/12/Screen-Shot-2020-03-27-at-9.58.40-AM-1024x738.png 1024w, https://www.comet.ml/site/app/uploads/2019/12/Screen-Shot-2020-03-27-at-9.58.40-AM-300x216.png 300w, https://www.comet.ml/site/app/uploads/2019/12/Screen-Shot-2020-03-27-at-9.58.40-AM-768x553.png 768w, https://www.comet.ml/site/app/uploads/2019/12/Screen-Shot-2020-03-27-at-9.58.40-AM.png 1252w" sizes="(max-width: 700px) 100vw, 700px" data-old-src="https://www.comet.ml/site/app/ewww/lazy/placeholder-1024x738.png" data-src="https://www.comet.ml/site/app/uploads/2019/12/Screen-Shot-2020-03-27-at-9.58.40-AM-1024x738.png" data-srcset="https://www.comet.ml/site/app/uploads/2019/12/Screen-Shot-2020-03-27-at-9.58.40-AM-1024x738.png 1024w, https://www.comet.ml/site/app/uploads/2019/12/Screen-Shot-2020-03-27-at-9.58.40-AM-300x216.png 300w, https://www.comet.ml/site/app/uploads/2019/12/Screen-Shot-2020-03-27-at-9.58.40-AM-768x553.png 768w, https://www.comet.ml/site/app/uploads/2019/12/Screen-Shot-2020-03-27-at-9.58.40-AM.png 1252w"><figcaption id="caption-attachment-2553">Source: Youtube</figcaption></figure>
<figcaption></figcaption>
</figure>

<p>Ng discussed this topic at re:MARS as well. He revealed how his team adopted a workflow system designed specifically for ML: <strong>1 day sprints</strong>, structured as follows:</p>

<ol>
<li>Build models and write code each day</li>
<li>Set up training and run experiments overnight</li>
<li>Analyze results in the morning and…</li>
<li>Repeat</li>
</ol>

<p>Ng’s 1 day sprints methodology reflects something crucial to understanding and designing teams that practice machine learning: it is an inherently <strong>experimental science</strong>. Because the systems being built lack a clear specification, because data collection is an imperfect science, and because machine learning models are incredibly complex, <em>experimentation is necessary</em>. Rather than structuring team processes around a multi-week sprint, it is usually more fruitful to test out many different architectures, feature engineering choices, and optimization methods rapidly until a rough image of what is working and what isn’t starts to emerge. 1 day sprints allow teams to move quickly, test many hypotheses in a short amount of time, and begin building intuition and knowledge around a modeling task.&nbsp;</p>

<h2><strong>Tools for ML: Experiment Management&nbsp;</strong></h2>

<p>Let’s say you adopt Andrew Ng’s 1 day sprints methodology or something similar (<em>and you should</em>). You’re setting new hyperparameters, tweaking your feature selections, and running experiments each night. What tool are you using to keep track of these decisions for each model training? How are you comparing experiments to see how different configurations are working? How are you sharing experiments with co-workers? Can your manager or co-worker reliably reproduce an experiment you ran yesterday?</p>

<p>In addition to processes, the tools you use to do machine learning matter as well. At Comet, our mission is to help companies extract business value from machine learning by providing a tool that does this for you. Most of the data science teams we speak to are stuck using a combination of git, emails, and (believe it or not) spreadsheets to record all of the artifacts around each experiment.&nbsp;</p>
<figure id="attachment_1994" aria-describedby="caption-attachment-1994"><img src="https://www.comet.ml/site/app/uploads/2020/01/Screen-Shot-2020-01-30-at-11.45.53-AM-1024x459.jpg" alt="" width="700" height="314" srcset="https://www.comet.ml/site/app/uploads/2020/01/Screen-Shot-2020-01-30-at-11.45.53-AM-1024x459.jpg 1024w, https://www.comet.ml/site/app/uploads/2020/01/Screen-Shot-2020-01-30-at-11.45.53-AM-300x134.jpg 300w, https://www.comet.ml/site/app/uploads/2020/01/Screen-Shot-2020-01-30-at-11.45.53-AM-768x344.jpg 768w, https://www.comet.ml/site/app/uploads/2020/01/Screen-Shot-2020-01-30-at-11.45.53-AM.jpg 1794w" sizes="(max-width: 700px) 100vw, 700px" data-old-src="https://www.comet.ml/site/app/ewww/lazy/placeholder-1024x459.png" data-src="https://www.comet.ml/site/app/uploads/2020/01/Screen-Shot-2020-01-30-at-11.45.53-AM-1024x459.jpg" data-srcset="https://www.comet.ml/site/app/uploads/2020/01/Screen-Shot-2020-01-30-at-11.45.53-AM-1024x459.jpg 1024w, https://www.comet.ml/site/app/uploads/2020/01/Screen-Shot-2020-01-30-at-11.45.53-AM-300x134.jpg 300w, https://www.comet.ml/site/app/uploads/2020/01/Screen-Shot-2020-01-30-at-11.45.53-AM-768x344.jpg 768w, https://www.comet.ml/site/app/uploads/2020/01/Screen-Shot-2020-01-30-at-11.45.53-AM.jpg 1794w"><figcaption id="caption-attachment-1994">Comet: Hyperparameter space visualization for 20+ experiments.</figcaption></figure>
<p>

Consider a modeling task where you’re keeping track of 20 hyperparameters, 10 metrics, dozens of architectures and feature engineering techniques, all while iterating quickly and running dozens of models a day. It can become incredibly tedious to manually track all of these artifacts. Building a good ML model can oftentimes resemble tuning a radio with 50 knobs. If you don’t keep track of all of the configurations you’ve tried, the combinatorial complexity of finding the signal in your modeling space can become cumbersome.</p>
<figure id="attachment_2554" aria-describedby="caption-attachment-2554"><img src="https://www.comet.ml/site/app/uploads/2019/12/Screen-Shot-2020-03-27-at-10.01.14-AM-1024x544.png" alt="comet exp UI" width="700" height="372" srcset="https://www.comet.ml/site/app/uploads/2019/12/Screen-Shot-2020-03-27-at-10.01.14-AM-1024x544.png 1024w, https://www.comet.ml/site/app/uploads/2019/12/Screen-Shot-2020-03-27-at-10.01.14-AM-300x160.png 300w, https://www.comet.ml/site/app/uploads/2019/12/Screen-Shot-2020-03-27-at-10.01.14-AM-768x408.png 768w, https://www.comet.ml/site/app/uploads/2019/12/Screen-Shot-2020-03-27-at-10.01.14-AM-1536x817.png 1536w, https://www.comet.ml/site/app/uploads/2019/12/Screen-Shot-2020-03-27-at-10.01.14-AM.png 1862w" sizes="(max-width: 700px) 100vw, 700px" data-old-src="https://www.comet.ml/site/app/ewww/lazy/placeholder-1024x544.png" data-src="https://www.comet.ml/site/app/uploads/2019/12/Screen-Shot-2020-03-27-at-10.01.14-AM-1024x544.png" data-srcset="https://www.comet.ml/site/app/uploads/2019/12/Screen-Shot-2020-03-27-at-10.01.14-AM-1024x544.png 1024w, https://www.comet.ml/site/app/uploads/2019/12/Screen-Shot-2020-03-27-at-10.01.14-AM-300x160.png 300w, https://www.comet.ml/site/app/uploads/2019/12/Screen-Shot-2020-03-27-at-10.01.14-AM-768x408.png 768w, https://www.comet.ml/site/app/uploads/2019/12/Screen-Shot-2020-03-27-at-10.01.14-AM-1536x817.png 1536w, https://www.comet.ml/site/app/uploads/2019/12/Screen-Shot-2020-03-27-at-10.01.14-AM.png 1862w"><figcaption id="caption-attachment-2554">Comet: Single experiment live metric tracking and dashboard</figcaption></figure>
<p><span>We’ve built Comet based on these needs (and what we wanted when we were working on data science and machine learning ourselves, at Google, IBM, and as part of research groups at Columbia University and Yale University). Every time you train a model, there should be </span><em>something</em><span> to capture all of the artifacts of your experiment and save them in some central ledger where you can look up, compare, and filter through all of your (or your team’s) work. Comet was built to provide this function to practitioners of machine learning.&nbsp;</span></p>

<p>Measuring workflow efficiency is a <a href="https://gravityflow.io/articles/measure-workflow-automations-roi/">notoriously difficult</a> thing to do, but on average our users report&nbsp;<em>20-30% time savings by using Comet</em> (note: Comet is free for individuals and researchers – <a href="https://www.comet.ml/pricing?opensignup=true&amp;utm_source=Software%20Eng%20vs%20ML&amp;utm_medium=Blog&amp;utm_campaign=Software%20Eng%20vs%20ML%20Blog%20Post">you can sign-up here</a>). This doesn’t take into account unique insights and knowledge that arise from having access to a visual understanding of your hyperparameter space, real-time metric tracking, team-wide collaboration and experiment comparison. Access to this knowledge enables time savings as well as, and perhaps more importantly, the ability to <em>build better models</em>.</p>

<h2><strong>Looking Ahead</strong></h2>

<p>It is tempting to ignore questions about ML tools and processes altogether. In a field responsible for self-driving cars, voice assistants, facial recognition, and many more groundbreaking technologies, one may be forgiven for leaping into the fray of building these tools themselves and not considering how best to build them.&nbsp;</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.comet.ml/site/why-software-engineering-processes-and-tools-dont-work-for-machine-learning/">https://www.comet.ml/site/why-software-engineering-processes-and-tools-dont-work-for-machine-learning/</a></em></p>]]>
            </description>
            <link>https://www.comet.ml/site/why-software-engineering-processes-and-tools-dont-work-for-machine-learning/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24781490</guid>
            <pubDate>Wed, 14 Oct 2020 20:55:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Efficient Evenly Distributed Sampling of Time Series Records in PostgreSQL]]>
            </title>
            <description>
<![CDATA[
Score 22 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24781057">thread link</a>) | @mooreds
<br/>
October 14, 2020 | https://blog.joshsoftware.com/2020/10/14/efficient-evenly-distributed-sampling-of-time-series-records-in-postgresql/ | <a href="https://web.archive.org/web/*/https://blog.joshsoftware.com/2020/10/14/efficient-evenly-distributed-sampling-of-time-series-records-in-postgresql/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-6304">
	
	
	<div>
		
<h2>The Problem</h2>



<p>I have been working on an application that, at it’s heart, stores a large amount of data that is organized primarily through the use of a foreign key and a timestamp field. The table’s own primary key is UUID based, combining the foreign key with a UUID for the individual record itself, and it has a single primary data field that utilizes a JSONB type since it can receive arbitrary data. The table sees frequent, regular inserts, and periodic deletions, with old data being thinned out over time, but for each foreign key, there may be tens of thousands of records distributed amongst hundreds of thousands, or millions of other records for other foreign keys.</p>



<figure><table><thead><tr><th>Column</th><th data-align="center">Type</th></tr></thead><tbody><tr><td>id</td><td data-align="center">uuid</td></tr><tr><td>server_id</td><td data-align="center">uuid</td></tr><tr><td>data</td><td data-align="center">jsonb</td></tr><tr><td>created_at</td><td data-align="center">timestamp(6) without time zone</td></tr></tbody></table><figcaption>Basic Table Schema</figcaption></figure>



<p>This was all very simple, but when the time came to start writing the code that generates data graphs from this table, I encountered a puzzle.</p>



<p>How does one ensure that the API doesn’t return too much data? Too many data points just means sending more data than the user probably needs, and it results in the graphing tool having to work with more data than it wants for quick, responsive performance, as well.</p>



<p>And how does one, efficiently, find that data without running a query take takes a burdensome amount of time? In our case, the data is being returned to a React based front end by an API, and snappy application performance hinges on snappy API performance.</p>



<h2>THe first solution</h2>



<p>Early in the history of the application, I arrived at a solution. If I had a maximum cap on the number of data points to query, such as 500, I could query the total count of records which matched my query, and then a little integer division would give me an interval to use when querying.</p>



<p>Counting the data points is simple. It looks something like this:</p>


<pre title="">sql = &lt;&lt;-ESQL
SELECT
  COUNT(*)
FROM
  telemetries
WHERE
  server_id = $1
  AND created_at BETWEEN $2 AND $3
  AND data ? 'load_avg'
ESQL

count = 0_64
DBH.using_connection do |conn|
  count = conn.query_one(sql, uuid, start_date, end_date, as: {Int64})
end
</pre>


<p>Once the count of records is determined, an interval can be calculated which will be used to query the sample of records.</p>



<p>i.e. if there are 5000 data points, and I want to sample 500 of them, then I need to query every 10th record. It looks something like this to find that interval:</p>


<pre title="">row_modulo = count // limit
row_modulo = 1 if row_modulo == 0
</pre>


<p>Once one has an interval, there is a technique that can be used with Postgresql to select records on that interval. The <code><a rel="noreferrer noopener" href="https://www.postgresql.org/docs/12/functions-window.html" target="_blank">row_number()</a></code> is a <a rel="noreferrer noopener" href="https://www.postgresql.org/docs/12/tutorial-window.html" target="_blank">window function</a> that assigns a sequential number to each row in a result set. Once each record has a monotonically increasing sequential number assigned to it, that number can be used in a <code>WHERE</code> clause.</p>


<pre title="">SELECT
  stuff,
  ROW_NUMBER()
    OVER (ORDER BY created_at ASC)
    AS row
FROM
  mytable
WHERE
  row % 10 = 0
</pre>


<p>This example would <code>select</code>, for every 10th record from <code>mytable</code>, the <code>stuff</code> field. </p>



<p>In the context of full, working code, assembling that query looked like this:</p>


<pre title="">sql = &lt;&lt;-ESQL
SELECT
  t.*
FROM (
  SELECT
    data,
    created_at,
    row_number()
      OVER (ORDER BY created_at ASC)
      AS row
  FROM
    telemetries
  WHERE
    server_id = $1
    AND created_at BETWEEN $2 AND $3
    AND data ? 'load_avg'
) 
AS t
WHERE
  t.row %#{row_modulo} = 0
ESQL
</pre>


<p>This worked! It’s a viable general technique when you want to select every nth record from some result set, and you want to make the database do the work instead of your application. It’s also almost always faster and less resource intensive to do data management like this inside the database than it is to pull all of the data into your application and make it responsible for sorting through the data and pruning unneeded rows.</p>



<h2>A Wrinkle: Counting Isn’t Cheap!</h2>



<p>There are a couple of performance problems with this approach that become apparent when the table starts significantly growing.</p>



<p>First, pulling a <code>count</code> is not cheap. MySQL maintains a global record count for tables as part of it’s MyISAM data format. PostgreSQL, however, uses something called a multi-version concurrency control strategy with its tables, which essentially means that different views of a database may see different sets of rows. Thus there is no one single, simple count of records for it to fall back on. Thus, when you count records in a table in PostgreSQL, the database is required to actually walk through the data and count all of the visible records.</p>



<p>This is a relatively intense, and thus slow process.</p>



<p>If you simply want an estimate of the number of total rows in a  table, there is a way to get that very cheaply:</p>


<pre title="">SELECT
  reltuples::bigint
    AS estimated_count
FROM
  pg_class
WHERE
  relname = 'mytable'
</pre>


<div><p>This doesn’t work when you want to count only a subset of records, though, and this value is only an estimate. It is the estimate that the query planner uses, so it should generally always be within about 10% of the real value, but it is unlikely to ever match exactly unless the table size changes only rarely.</p><p>There are other counting strategies, but they all have tradeoffs or inherent inaccuracies, so for this use case, there is no getting around paying that up-front time and resource cost just to get a count of records to use when calculating the query interval that is needed.</p></div>



<p>The second expensive part of this technique is the use of <code>row_number()</code> in combination with a modulo (%) in the <code>WHERE</code> clause. This means that the database must traverse every possible record when running the query in order to figure out which ones satisfy the <code>WHERE</code> clause. So if there are 150000 records, but one only wants 500 of them, all 150000 will still be scanned.</p>



<p>These factors combine to make this approach brutally, unusably slow for queries that are intended to be ran ad hoc, and quickly, as part of an API driving a UI.</p>


<pre title="">                                                                      QUERY PLAN                                                                      
------------------------------------------------------------------------------------------------------------------------------------------------------
 Subquery Scan on t  (cost=105.19..2583.85 rows=1 width=387) (actual time=418.318..26002.490 rows=545 loops=1)
   Filter: ((t."row" % '49'::bigint) = 0)
   Rows Removed by Filter: 26198
   -&gt;  WindowAgg  (cost=105.19..2582.55 rows=87 width=387) (actual time=210.259..25995.686 rows=26743 loops=1)
         -&gt;  Bitmap Heap Scan on telemetries  (cost=105.19..2581.46 rows=87 width=379) (actual time=210.248..25959.166 rows=26743 loops=1)
               Recheck Cond: (data ? 'load_avg'::text)
               Filter: (server_id = 'a0dcc312-0623-af60-4dc0-238301cc9bf8'::uuid)
               Rows Removed by Filter: 178886
               Heap Blocks: exact=39489
               -&gt;  Bitmap Index Scan on telemetries_data_idx  (cost=0.00..105.17 rows=689 width=0) (actual time=101.188..101.188 rows=205629 loops=1)
                     Index Cond: (data ? 'load_avg'::text)
 Planning Time: 1.860 ms
 Execution Time: 26006.389 ms

</pre>


<p>This is a real example of a query on a real database using the prior technique, and this example had the advantage that the index that it uses (a <code>BTREE</code> index across the data field, since in production we are limiting results to fields that have one specific type of data) was already warm and cached in the database’s working set when I ran this example, so this result was a best case for this technique, on this database. If that index were not available, or were not used, it would have been even slower given that this index filter rejected almost 180,000 rows. That’s too slow to be triggered directly via an API request, as the user will be waiting a half-minute for data to even begin to show up in their browser.</p>



<h2>There has to be a better way</h2>



<p>It turns out that Postgresql offers a high performance option to sample a random set of data in a table. There is a <code><a href="https://www.postgresql.org/docs/9.6/sql-select.html#SQL-FROM" target="_blank" rel="noreferrer noopener">TABLESAMPLE</a></code> clause that can be placed in the <code>FROM</code> section of a query that will sample a subset of a table.</p>


<pre title="">SELECT
  data
FROM
  mytable
  TABLESAMPLE SYSTEM(5)
</pre>


<p>This would return a roughly random set of about 5% of <code>mytable</code>‘s rows. If one wants a specific number of rows, there is an extension that can provide that, <code><a rel="noreferrer noopener" href="https://www.postgresql.org/docs/9.6/tsm-system-rows.html" target="_blank">tsm_system_rows</a></code>.</p>


<pre title="">SELECT
  data
FROM
  mytable
  TABLESAMPLE SYSTEM_ROWS(500)
</pre>


<p>This would return a random-ish set of 500 rows from the table. A <code>WHERE</code> clause can be used in a query that uses <code>TABLESAMPLE</code> in order to select only the rows of interest, but the <code>TABLESAMPLE</code> is applied before the <code>WHERE</code> clause, which makes this method unsuitable for my use case. As an example:</p>


<pre title="">SELECT
  data,
  created_at
FROM
  telemetries
  TABLESAMPLE SYSTEM_ROWS(500)
WHERE
  server_id = $1
</pre>


<p>This would first select 500 random rows from the entire data set, and would then try to find records from that set which matched the <code>WHERE</code> clause. This would probably result in the query only returning a very small, and fairly unpredictable number of rows of data that is actually wanted. Also, because the records are random, there is no guarantee that they are evenly distributed through the data set. This might be fine if the data is being queried for statistical reasons, but it isn’t ideal when pulling data for graphs.</p>



<p>So while TABLESAMPLE can be a very fast way to select a random set of records over an entire table, it doesn’t work when we want a set of rows that is evenly distributed through the data set, but is only for a segment of the table’s total data, and for which we want to have some predictable control over the number of rows selected.</p>



<h2>Other Meanderings</h2>



<p>There are other solutions available when the problem to be solved is the random selection of table rows, but none of them are particularly useful for the selection of N or close-to N evenly distributed data points, and there is limited inspiration that can be found from them.</p>



<p>A…</p></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.joshsoftware.com/2020/10/14/efficient-evenly-distributed-sampling-of-time-series-records-in-postgresql/">https://blog.joshsoftware.com/2020/10/14/efficient-evenly-distributed-sampling-of-time-series-records-in-postgresql/</a></em></p>]]>
            </description>
            <link>https://blog.joshsoftware.com/2020/10/14/efficient-evenly-distributed-sampling-of-time-series-records-in-postgresql/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24781057</guid>
            <pubDate>Wed, 14 Oct 2020 20:17:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Visualize Starlink's current coverage with active TLEs]]>
            </title>
            <description>
<![CDATA[
Score 39 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24780065">thread link</a>) | @blach
<br/>
October 14, 2020 | http://orbitalindex.com/feature/starlink-coverage/ | <a href="https://web.archive.org/web/*/http://orbitalindex.com/feature/starlink-coverage/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="_main" role="main" data-color="#4fb1ba" data-theme-color="black" data-image="/assets/img/sidebar-bg.jpg" data-overlay=""><article class="page" role="article"><header></header>   <div id="starlink-coverage"> <canvas id="globe"></canvas><div><p>Degrees From Horizon For Connectivity <span onclick="display_help()">?</span> <span onclick="hide_help()">✕</span></p><p>25°</p><div><p>Degrees From Horizon is the amount you have to tilt your head to look at the satellite when standing in a flat field.</p><p>We believe the initial constellation will have connectivity if the satellite is 25° above the receiver's horizon, and that this requirement will later be eased to 40° to increase performance as satellite density increases. Note: This angle defines the maximum height above the horizon in all directions that can be occluded by any terrain, trees, or other structures.</p></div></div></div>  </article></div></div>]]>
            </description>
            <link>http://orbitalindex.com/feature/starlink-coverage/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24780065</guid>
            <pubDate>Wed, 14 Oct 2020 18:43:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Crafting Functions]]>
            </title>
            <description>
<![CDATA[
Score 56 | Comments 15 (<a href="https://news.ycombinator.com/item?id=24779624">thread link</a>) | @tosh
<br/>
October 14, 2020 | https://stopa.io/post/251 | <a href="https://web.archive.org/web/*/https://stopa.io/post/251">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p><span><p>We write so many functions in our programs that they become second nature before we know it. Like ants in a colony, they are numerous beyond imagination and they come together to form some surprisingly complex systems.</p><p>It begs the question: how do we write good functions? It can seem trivial: they’re just like ants after-all. But there is leverage in the answer: the right decisions multiply throughout your codebase and bubble up into great design.</p><p>I think there are about three key ideas you can employ to craft good functions. I wanted to share them with you.</p><p>Let’s start with an example. We have an app, and we want to export some data in a JSON format. Here’s what a function for that could look like:</p><pre><code><span>function</span><span> </span><span>exportFile</span><span>() { </span>
<span>  </span><span>setLoading</span><span>(</span><span>true</span><span>);</span>
<span>  </span><span>try</span><span> {</span>
<span>    </span><span>const</span><span> </span><span>data</span><span> </span><span>=</span><span> </span><span>getData</span><span>(); </span><span>// [Data, Data, Data]</span>
<span>    </span><span>const</span><span> </span><span>exportableData</span><span> </span><span>=</span><span> </span><span>toExportableData</span><span>(</span><span>data</span><span>); </span><span>// ExportableData</span>
<span>    </span><span>const</span><span> </span><span>jsonStr</span><span> </span><span>=</span><span> </span><span>JSON</span><span>.stringify</span><span>(</span><span>exportableData</span><span>); </span><span>// '{"data": {...</span>
<span>    </span><span>const</span><span> </span><span>fileURL</span><span> </span><span>=</span><span> </span><span>saveFile</span><span>(</span><span>"export.json"</span><span>, </span><span>jsonStr</span><span>); </span><span>// https://foo.com/export.json</span>
<span>    </span><span>setFileURL</span><span>(</span><span>fileURL</span><span>);</span>
<span>  } </span><span>finally</span><span> {</span>
<span>    </span><span>setLoading</span><span>(</span><span>false</span><span>)</span>
<span>  }</span>
<span>}</span></code></pre><p>Seems straight forward: To export as JSON, we first get our data. Now, this data may have some sensitive info, so we clean that up and transform into something exportable; ExportableData. Once we have that, we get a string representation, save the file, and badabing, badaboom, we’re done. </p><p>Okay, we’ve got something working well.</p><p>But life moves on and our program needs to evolve. Instead of just exporting JSON, we need to do more: <strong>we also need to export a CSV file</strong>. </p><p>How do we do that?</p><p>The first thing we notice, is that exporting a CSV is very similar to exporting JSON. Can we abstract <code>exportFile</code>?</p><p>One thing we can do, is to introduce a new flag: something like <code>exportFile(/*isCSV=*/ true)</code> </p><pre><code><span>function</span><span> </span><span>exportFile</span><span>(</span><span>isCSV</span><span>) { </span>
<span>  </span><span>...</span>
<span>  </span><span>let</span><span> </span><span>fileURL</span>
<span>  </span><span>if</span><span> (</span><span>isCSV</span><span>) { </span>
<span>    </span><span>const</span><span> </span><span>csvStr</span><span> </span><span>=</span><span> </span><span>toCSVStr</span><span>(</span><span>exportableData</span><span>)</span>
<span>    </span><span>fileURL</span><span> </span><span>=</span><span> </span><span>saveFile</span><span>(</span><span>"export.csv"</span><span>, </span><span>csvStr</span><span>);</span>
<span>  } </span><span>else</span><span> { </span>
<span>    </span><span>const</span><span> </span><span>jsonStr</span><span> </span><span>=</span><span> </span><span>JSON</span><span>.stringify</span><span>(</span><span>exportableData</span><span>);</span>
<span>    </span><span>fileURL</span><span> </span><span>=</span><span> </span><span>saveFile</span><span>(</span><span>"export.json"</span><span>, </span><span>jsonStr</span><span>);</span>
<span>  }</span>
<span>  </span><span>...</span></code></pre><p>By introducing this flag, we can conditionally produce a different <code>fileURL</code>: one for CSV and one for JSON. With that we see the first concept for abstraction: configuration. You pass some configuration, and you leave it to your function to figure what to do. </p><p>So, is it a good idea? </p><h2 id="the-key-advantage-is-that-our-logic-is-centralized">The key <em>advantage</em> is that our logic is centralized.</h2><p>With configuration, the caller is limited in what they can do: they can only provide flags. All the true logic stays inside <code>exportFile</code>. This means that callers of the function can’t go crazy and do something unsupported. And that could give us some peace of mind.</p><h2 id="the-key-disadvantage-is-thatour-logic-is-centralized">The key <em>disadvantage</em> is that…our logic is centralized.</h2><p>This will work, but let’s think about it. First, notice that in order to understand <code>exportFile</code> now, we need to understand both the CSV and JSON case. Imagine if someone opens up <code>exportFile</code> to figure out what it does:  if they <em>only</em> cared about JSON, they now have to understand more logic than they needed. Anyone who changes the logic for CSV, may also end up breaking JSON. <strong><code>exportFile</code></strong> <strong>has become</strong> <a href="https://www.infoq.com/presentations/Simple-Made-Easy/" target="_blank"><strong>complected</strong></a><strong>.</strong></p><p>Notice also, that because the caller of this function can <em>only</em> provide flags, their hands are tied for use-cases that you didn’t support. This was supposed to give you peace of mind, but it certainly can frustrate callers. imagine if they wanted to support XML, what could they do? They’d have to edit <code>exportFile</code> to support this case. (God forbid they edit it to be something like <code>exportFile(isCSV, isXML)</code> — now you have invariant conditions on your hands). By being so specific, you’ve chosen to make your function less abstract — this of course means that it is less powerful.  <strong><code>exportFile</code></strong> <strong>has become hard to extend</strong></p><h2 id="for-better-or-worse-configuration-gives-the-caller-the-least-amount-of-power">For better or worse, configuration gives the caller the least amount of power</h2><p>If you imagine a sort power spectrum, where the caller has the least power on the left, and most power on the right, configuration would be on the left. You control what the caller does so tightly that it gives your certainty, but makes your function more complex and less useful. </p><p>Say you wanted to address the problems, and move to the right of this spectrum, what could you do? </p><p>Well, if you look at what we wrote, we can notice that the only part that is <em>really</em> different, is the bit about taking <code>exportData</code>, and creating a <code>fileURL</code>. </p><pre><code><span>...</span>
<span>const</span><span> </span><span>exportableData</span><span> </span><span>=</span><span> </span><span>toExportableData</span><span>(</span><span>data</span><span>); </span><span>// ExportableData</span>
<span>...</span><span> </span><span>// *This can be different! Somehow we need to get a fileURL* </span>
<span>setFileURL</span><span>(</span><span>fileURL</span><span>);</span>
<span>...</span></code></pre><p>So one thing we can do is this: instead of providing a flag, we can provide a function: </p><pre><code><span>function</span><span> </span><span>exportFile</span><span>(</span><span>exportableDataToFileURL</span><span>) { </span>
<span>  </span><span>setLoading</span><span>(</span><span>true</span><span>);</span>
<span>  </span><span>try</span><span> {</span>
<span>    </span><span>const</span><span> </span><span>data</span><span> </span><span>=</span><span> </span><span>getData</span><span>(); </span><span>// [Data, Data, Data]</span>
<span>    </span><span>const</span><span> </span><span>exportableData</span><span> </span><span>=</span><span> </span><span>toExportableData</span><span>(</span><span>data</span><span>); </span><span>// ExportableData</span>
<span>    </span><span>const</span><span> </span><span>fileURL</span><span> </span><span>=</span><span> </span><span>exportableDataToFileURL</span><span>(</span><span>exportableData</span><span>)</span>
<span>    </span><span>setFileURL</span><span>(</span><span>fileURL</span><span>);</span>
<span>  } </span><span>finally</span><span> {</span>
<span>    </span><span>setLoading</span><span>(</span><span>false</span><span>)</span>
<span>  }</span>
<span>}</span></code></pre><p>Now, for JSON, we can write </p><pre><code><span>exportFile</span><span>((</span><span>exportableData</span><span>) </span><span>=&gt;</span><span> { </span>
<span>  </span><span>return</span><span> </span><span>saveFile</span><span>(</span><span>"export.json"</span><span>, </span><span>JSON</span><span>.stringify</span><span>(</span><span>exportableData</span><span>));</span>
<span>})</span></code></pre><p>and for CSV we can write: </p><pre><code><span>exportFile</span><span>((</span><span>exportableData</span><span>) </span><span>=&gt;</span><span> { </span>
<span>  </span><span>return</span><span> </span><span>saveFile</span><span>(</span><span>"export.csv"</span><span>, </span><span>toCSVStr</span><span>(</span><span>exportableData</span><span>));</span>
<span>})</span></code></pre><p>Oky doke, this is cool. </p><h2 id="the-key-advantage-is-that-you-give-the-caller-more-power">The key <em>advantage</em> is that you give the caller more power</h2><p>With this we solve both of the problems we had with configuration. Now if someone looks under the hood at <code>exportFile</code>, they won’t see unrelated code about csv. If they wanted to extend to XML, they can simply provide a different function. We’ve given the caller much more power</p><h2 id="the-key-disadvantage-is-that-it-can-be-either-too-powerful-or-not-powerful-enough">The key <em>disadvantage</em> is that it can be either too powerful or not powerful enough</h2><p>We’ve abstracted further, but there is a price there. The first is, that we <em>think</em> we know that what we <em>really</em> need to pass outwards is <code>exportableData</code>, and what we need to return is a <code>fileURL</code>. What if we were wrong? For example, some may need a slightly different data format — instead of <code>exportableData</code> they need <code>someOtherKindOfExportableData</code>. By the time we figured that out, it’s possible that there are numerous new usages of <code>exportFile</code>, which we’ll have to support as we evolve this function.</p><p>One way we could have prevented this, is to have stuck with configuration. This way, anyone who wanted to support something would have to funnel through this function, which would give us time to think about what the best abstraction was. </p><p>Another way, would have been if this function was abstracted even further, so callers could have easily supported <code>someOtherKindOfExportableData</code>.</p><h2 id="inversion-lies-in-the-middle-of-the-power-spectrum">Inversion lies in the middle of the power spectrum</h2><p>Inversion is more powerful than configuration, but it’s not the most powerful method. This can be a great choice, but you risk either being too powerful and exposing errors, or not being powerful enough and restricting callers. </p><p>We know the less powerful option: configuration. What would the most powerful one look like?</p><p>The next thing we may notice, is that our <code>exportFile</code> function is actually built up some building blocks that could be useful for a bunch of different things. For example, many functions may want a loading state, or just need to get <code>exportableData</code>, etc. We could create those building blocks:</p><pre><code><span>function</span><span> </span><span>exportJSONFile</span><span>() { </span>
<span>  </span><span>withLoading</span><span>(() </span><span>=&gt;</span><span> </span><span>saveJSONFile</span><span>(</span><span>getExportableData</span><span>()))</span>
<span>}</span>
<!-- -->
<!-- -->
<span>function</span><span> </span><span>exportCSVFile</span><span>() { </span>
<span>  </span><span>withLoading</span><span>(() </span><span>=&gt;</span><span> </span><span>saveCSVFile</span><span>(</span><span>getExportableData</span><span>()))</span>
<span>}</span></code></pre><h2 id="the-key-advantage-is-that-the-user-gets-the-most-power">The key advantage is that the user gets the most power</h2><p>The building blocks that we just built, can be used in a myriad of ways. The user can support CSV, XML, can use <code>isLoading</code> with some other function, and choose to provide a different kind of <code>exportableData</code>.  We’ve provided a lot of power for the user.</p><h2 id="the-key-disadvantage-is-that-you-are-the-most-vulnerable-to-mistakes">The key disadvantage is that you are the most vulnerable to mistakes</h2><p>The disadvantage though, like in the case of inversion, is that we open ourselves up to a lot of mistakes. What if <code>isLoading</code> was really meant for files, and other things should have been using a different flag? What if people start using <code>saveJSONFile</code>, and pass data that wasn’t really an export? These are all cases that we have implicitly allowed with our abstractions. </p><p>There’s a further problem: notice that with our first example of <code>exportFile</code>, you the code was more concrete: you could see what was actually happening. When code is more abstract, it’s a bit harder to reason about what is <em>actually</em> happening. Now, it can be worth it for the power gains, but if you optimized prematurely, you’re just paying this price for nothing. An example of this unnecessary price is <code>saveJSONFile</code> and <code>saveCSVFile</code> — if we had <a href="http://number-none.com/blow/john_carmack_on_inlined_code.html" target="_blank">inlined</a> those, the overall composition would still be abstract but more understandable. These are the kind of things to watch out for as you abstract at this level.</p><h2 id="composition-is-at-the-end-of-the-spectrum">Composition is at the end of the spectrum</h2><p>And with that, we see that composition gives us the most power, but gives us the most opportunities to shoot ourselves in the foot. Boy can it be worth it though. </p><p>It’s funny to notice that with each option, the pro <em>is</em> the con. So how do we pick? I think one heuristic you can use is this: pick the most powerful option you can limited by your confidence. For example, if you have a light understanding of the problem, stay on the lower side of the abstraction spectrum. As you understand more (say, time to introduce XML) you can evolve to the powerful side of the spectrum. When you’re <em>very</em> confident, and you can see good use-cases for your building blocks, lean to the most powerful side of the spectrum. </p><p><em>Thanks to Daniel Woelfel, Alex Reichert, Julien Odent for reviewing drafts of this essay</em></p></span></p></div></div></div>]]>
            </description>
            <link>https://stopa.io/post/251</link>
            <guid isPermaLink="false">hacker-news-small-sites-24779624</guid>
            <pubDate>Wed, 14 Oct 2020 18:08:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Read-Only Mode for Better Rails Downtime]]>
            </title>
            <description>
<![CDATA[
Score 75 | Comments 11 (<a href="https://news.ycombinator.com/item?id=24778920">thread link</a>) | @christoomey
<br/>
October 14, 2020 | https://ctoomey.com/writing/read-only-mode-for-better-rails-downtime/ | <a href="https://web.archive.org/web/*/https://ctoomey.com/writing/read-only-mode-for-better-rails-downtime/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        
  <p>Recently I was looking to upgrade the Postgres version on an application I’ve
been working on. This would require a small amount of downtime, likely about 10
minutes.</p>

<p>The default solution I’d reach for in these cases would be to go into Heroku’s
maintenance mode, which serves an HTML maintenance page with a <code>503 Service
Unavailable</code> status code. This works but makes the application entirely
unusable during the upgrade, and I was hoping to find a better solution. In this
particular case, I also wanted to be able to provide JSON responses as the
application mainly provides an API for a mobile app.</p>

<p>After <a href="https://www.bikeshed.fm/262">exploring a handful of half-baked options</a>, I settled on using a
read-only connection to the database to still allow reads but prevent any
writes from occurring. While using the read-only connection, the Postgres adapter
will raise an error any time we attempt to change data in the database, but we
can easily rescue this specific error and convert it to a user-facing notice. I
felt a bit odd using exceptions as the core of this workflow, but in the end, it
worked out really well, so I wanted to share the specifics.</p>

<p>It’s worth noting that this solution is particularly well suited to this
specific application, which only provides an API and has very read-heavy usage,
but I imagine it could be extended to work with other styles of app as well.</p>

<h2 id="configuring-rails-to-use-the-read-only-connection">Configuring Rails to Use the Read-Only Connection</h2>

<p>If present, Rails will use the connection string in a <code>DATABASE_URL</code> env var to
connect to the database. Following the <a href="https://guides.rubyonrails.org/configuring.html#connection-preference">Connection Preference</a> notes in the
Rails guides, I realized that I could make this <code>DATABASE_URL</code> usage explicit
and allow for a temporary override. To do this, I added an explicit <code>url</code>
property for the production environment with desired connection preference:</p>

<div><pre><code><span># config/database.yml</span>

<span>production</span><span>:</span>
  <span>&lt;&lt;</span><span>:</span> <span>*default</span>
  <span>url</span><span>:</span> <span>&lt;%= ENV["DATABASE_URL_READ_ONLY"] || ENV["DATABASE_URL"] %&gt;</span>
</code></pre></div>
<p>With this in place, I can enable the read-only mode simply by setting the
<code>DATABASE_URL_READ_ONLY</code> env var:</p>

<div><pre><code>heroku config:set <span>\</span>
  <span>DATABASE_URL_READ_ONLY</span><span>=</span><span>'postgres://read_only_user:abc123...'</span> <span>\</span>
  <span>--remote</span> production
</code></pre></div>
<p>Likewise, to disable the read-only mode, I can use:</p>

<div><pre><code>heroku config:unset DATABASE_URL_READ_ONLY <span>--remote</span> production
</code></pre></div>
<p><em>Note</em>: I was able to use <a href="https://devcenter.heroku.com/articles/heroku-postgresql-credentials#managing-permissions">Heroku’s Postgres Credentials</a> interface to create
the read-only user, but if you’re not working with Heroku you should be able to
use <a href="https://dba.stackexchange.com/a/160817">these instructions</a> to create your read-only user.</p>

<h2 id="error-handling">Error Handling</h2>

<p>With other approaches I considered I found that I had to close off multiple
different potential ways to issue writes to the database, but the read-only
connection worked well to cut everything off in one change. That said, it
was only half the solution, as I certainly didn’t want the errors making it to
users.</p>

<p>Thankfully it was relatively straightforward to provide a centralized <code>rescue</code>
that would allow me to handle all the errors. First, I created a module using
Rails’s <code>ActiveSupport::Concern</code> functionality:</p>

<div><pre><code><span># app/controllers/concerns/read_only_controller_support.rb</span>
<span>module</span> <span>ReadOnlyControllerSupport</span>
  <span>extend</span> <span>ActiveSupport</span><span>::</span><span>Concern</span>

  <span>included</span> <span>do</span>
    <span>if</span> <span>ENV</span><span>[</span><span>"DATABASE_URL_READ_ONLY"</span><span>].</span><span>present?</span>
      <span>rescue_from</span> <span>ActiveRecord</span><span>::</span><span>StatementInvalid</span> <span>do</span> <span>|</span><span>error</span><span>|</span>
        <span>if</span> <span>error</span><span>.</span><span>message</span><span>.</span><span>match?</span><span>(</span><span>/PG::InsufficientPrivilege/i</span><span>)</span>
          <span>render</span><span>(</span>
            <span>status: :service_unavailable</span><span>,</span>
            <span>json: </span><span>{</span>
              <span>info: </span><span>"The app is currently in read-only maintenance mode. Please try again later."</span><span>,</span>
            <span>},</span>
          <span>)</span>
        <span>else</span>
          <span>raise</span> <span>error</span>
        <span>end</span>
      <span>end</span>
    <span>end</span>
  <span>end</span>
<span>end</span>
</code></pre></div>
<p>When included, this module will use Rails’s <a href="https://api.rubyonrails.org/classes/ActiveSupport/Rescuable/ClassMethods.html#method-i-rescue_from"><code>rescue_from</code></a> method to capture
potentially relevant errors, and then we do a quick check within that block
to make sure we’re only capturing the relevant errors.</p>

<p>Note, the <code>rescue_from</code> logic is only enabled when the <code>DATABASE_URL_READ_ONLY</code>
is set, so we’re able to reuse the existence of that variable as a way to scope
this behavior.</p>

<p>I was then able to include that module in any relevant base controller:</p>

<div><pre><code><span># app/controllers/application_controller.rb</span>
<span>class</span> <span>ApplicationController</span> <span>&lt;</span> <span>ActionController</span><span>::</span><span>Base</span>
  <span>include</span> <span>ReadOnlyControllerSupport</span>
<span>end</span>

<span># app/controllers/api/base_controller.rb</span>
<span>class</span> <span>Api</span><span>::</span><span>BaseController</span> <span>&lt;</span> <span>ActionController</span><span>::</span><span>Base</span>
  <span>include</span> <span>ReadOnlyControllerSupport</span>
<span>end</span>
</code></pre></div>
<h2 id="non-api-error-handling">Non-API Error Handling</h2>

<p>My initial use case for this read-only mode only needed to support API requests,
but I could imagine extending it to HTML and form-based interfaces.</p>

<p>The first thing I would consider would be adding a sitewide banner that stated
that we were in a read-only maintenance mode to alert users to the current
status.</p>

<p>With that in place, I think we could extend the error handling in the
<code>ReadOnlyControllerSupport</code> module to redirect the user back and display a
relevant message:</p>

<div><pre><code><span>rescue_from</span> <span>ActiveRecord</span><span>::</span><span>StatementInvalid</span> <span>do</span> <span>|</span><span>error</span><span>|</span>
  <span>if</span> <span>error</span><span>.</span><span>message</span><span>.</span><span>match?</span><span>(</span><span>/PG::InsufficientPrivilege/i</span><span>)</span>
    <span>respond_to</span> <span>do</span> <span>|</span><span>format</span><span>|</span>
      <span>format</span><span>.</span><span>json</span> <span>do</span>
        <span># JSON erorr message as shown above</span>
      <span>end</span>

      <span>format</span><span>.</span><span>html</span> <span>do</span>
        <span>redirect_back</span><span>(</span>
          <span>fallback_location: </span><span>root_path</span><span>,</span>
          <span>alert: </span><span>"The app is currently in read-only maintenance mode. Please try again later."</span><span>,</span>
        <span>)</span>
      <span>end</span>
    <span>end</span>
  <span>else</span>
    <span>raise</span> <span>error</span>
  <span>end</span>
<span>end</span>
</code></pre></div>
<h2 id="scheduler-and-background-jobs">Scheduler and Background Jobs</h2>

<p>One additional consideration here would be around background jobs and scheduler
processes. For background jobs things are relatively straightforward – we just
need to scale our worker pool down to zero for the read-only period.</p>

<p>Scheduler processes are a little trickier as I didn’t have a mechanism for
globally enabling or disabling them. With that in mind, I think the ideal
solution would be to only ever have scheduler processes enqueue jobs but not
actually do any work beyond that.</p>

<h2 id="migrations">Migrations</h2>

<p>The final sticking point we ran into was migrations. We have a <code>release</code> command
defined in our <code>Procfile</code> that was configured to run <code>rake db:migrate</code>.
Unfortunately, it turns out that even if no migrations run, Rails will still
attempt to write to the <code>ar_internal_metadata</code> table as part of the <code>db:migrate</code>
command, and Heroku will run the release command any time we change an env. In
my initial attempt, Heroku failed when I attempted to set the
<code>DATABASE_URL_READ_ONLY</code> as the associated release command hit the read-only
error when running <code>rake db:migrate</code>.</p>

<p>To work around this I wrote a small script that first checks if there
are any migrations that need to be run, and only if there are, then runs <code>rake
db:migrate</code>:</p>

<div><pre><code><span>#!/bin/bash</span>

<span>set</span> <span>-e</span>

<span>if </span>bin/rails db:migrate:status | <span>grep</span> <span>'^\s\+down\s'</span><span>;</span> <span>then
  </span>bin/rails db:migrate
<span>fi</span>
</code></pre></div>
<p>This script was added to the repo as <code>bin/migrate-if-needed</code>, and then we
replaced our call to <code>rake db:migrate</code> with <code>bin/migrate-if-needed</code></p>

<h2 id="update-oct-14-2020">Update (Oct 14, 2020)</h2>

<p>After sharing this post, <a href="https://news.ycombinator.com/item?id=24780033">a commenter on Hacker News</a> pointed out <a href="https://github.com/discourse/rails_failover">the
rails_failover gem</a> that their team at Discourse maintains. It seems to offer
similar functionality, but in a more robust and fully thought out way. Looks
like a great option to implement this sort of system.</p>



    </div></div>]]>
            </description>
            <link>https://ctoomey.com/writing/read-only-mode-for-better-rails-downtime/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24778920</guid>
            <pubDate>Wed, 14 Oct 2020 17:03:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Zoom Rolling Out End-to-End Encryption Offering]]>
            </title>
            <description>
<![CDATA[
Score 232 | Comments 149 (<a href="https://news.ycombinator.com/item?id=24778490">thread link</a>) | @giuliomagnifico
<br/>
October 14, 2020 | https://blog.zoom.us/zoom-rolling-out-end-to-end-encryption-offering/ | <a href="https://web.archive.org/web/*/https://blog.zoom.us/zoom-rolling-out-end-to-end-encryption-offering/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
              
              
              <div>
                <p><a href="https://blog.zoom.us/author/mkrohn/" title="Max Krohn">
                                            <img src="https://blog.zoom.us/wp-content/uploads/2020/10/Max-Krohn-124x124.jpeg" data-src="https://blog.zoom.us/wp-content/uploads/2020/10/Max-Krohn-124x124.jpeg" alt="Max Krohn" title="Max Krohn">
                                      </a>
                </p>
                
            </div>
                          <p><img src="https://blog.zoom.us/wp-content/uploads/2020/10/Zoom-End-to-End.png" data-src="https://blog.zoom.us/wp-content/uploads/2020/10/Zoom-End-to-End.png" alt="Zoom Rolling Out End-to-End Encryption Offering">
                                      </p>
                <!--?xml encoding="UTF-8" ?--><p>We’re excited to announce that starting next week, Zoom’s end-to-end encryption (E2EE) offering will be available as a technical preview, which means we’re proactively soliciting feedback from users for the first 30 days. Zoom users – free and paid – around the world can host up to 200 participants in an E2EE meeting on Zoom, providing increased privacy and security for your Zoom sessions.</p>



<p>We <a href="https://blog.zoom.us/zoom-acquires-keybase-and-announces-goal-of-developing-the-most-broadly-used-enterprise-end-to-end-encryption-offering/" target="_blank" rel="noreferrer noopener">announced in May</a> our plans to build an end-to-end-encrypted meeting option into our platform, on top of Zoom’s already strong encryption and advanced security features. We’re pleased to roll out Phase 1 of 4 of our E2EE offering, which provides robust protections to help prevent the interception of decryption keys that could be used to monitor meeting content.</p>



<h2>About E2EE</h2>



<p>To be clear, Zoom’s E2EE uses the same powerful GCM encryption you get now in a Zoom meeting. The only difference is where those encryption keys live.</p>



<p>In typical meetings, Zoom’s cloud generates encryption keys and distributes them to meeting participants using Zoom apps as they join. With Zoom’s E2EE, the meeting’s host generates encryption keys and uses public key cryptography to distribute these keys to the other meeting participants. Zoom’s servers become oblivious relays and never see the encryption keys required to decrypt the meeting contents.&nbsp;&nbsp;</p>



<p>“End-to-end encryption is another stride toward making Zoom the most secure communications platform in the world,” said Zoom CEO Eric S. Yuan. “This phase of our E2EE offering provides the same security as existing end-to-end-encrypted messaging platforms, but with the video quality and scale that has made Zoom the communications solution of choice for hundreds of millions of people and the world’s largest enterprises.”</p>



<p>Zoom’s E2EE will be available as a technical preview next week. To use it, customers must enable E2EE meetings at the account level and opt-in to E2EE on a per-meeting basis.</p>



<figure><img alt="" data-src="https://lh6.googleusercontent.com/t2TiiQUVghal7h8dVHrvTZL-14BVFCJELb7TtGg81kjh3EDA62hSNF-_vDucMMyjmLeyYhgGTQwBd214jVKbj4gfjq9o3wwshEo35R9XiijNxcbwl-I6kZzcrcshTDQ4XSo4UcDs"></figure><h2>FAQs</h2>



<p><strong>How does Zoom provide end-to-end encryption?</strong></p>



<p>Zoom’s E2EE offering uses public key cryptography. In short, the keys for each Zoom meeting are generated by participants’ machines, not by Zoom’s servers. Encrypted data relayed through Zoom’s servers is indecipherable by Zoom, since Zoom’s servers do not have the necessary decryption key. This key management strategy is similar to that used by most end-to-end encrypted messaging platforms today.</p>



<p><strong>How do I turn on E2EE?</strong></p>



<p>Hosts can enable the setting for E2EE at the account, group, and user level and can be locked at the account or group level. All participants must have the setting enabled to join an E2EE meeting. In Phase 1, all meeting participants must join from the Zoom desktop client, mobile app, or Zoom Rooms.</p>



<p><strong>When would I use E2EE?</strong></p>



<p>E2EE is best for when you want enhanced privacy and data protection for your meetings, and is an extra layer to mitigate risk and protect sensitive meeting content. While E2EE provides added security, some Zoom functionality is limited in this first E2EE version (more on that below). Individual Zoom users should determine whether they need these features before enabling this version of E2EE in their meetings.</p>



<p><strong>Do I have access to all the features of a regular Zoom meeting?</strong></p>



<p>Not right now. Enabling this version of Zoom’s E2EE in your meetings disables certain features, including join before host, cloud recording, streaming, live transcription, Breakout Rooms, polling, 1:1 private chat, and meeting reactions.</p>



<p><strong>Do free Zoom users have access to end-to-end encryption?</strong></p>



<p>Yes. Free and paid Zoom accounts joining from Zoom’s desktop client or mobile app, or from a Zoom Room, can host or join an E2EE meeting.</p>



<p><strong>How is this different from Zoom’s enhanced GCM encryption?</strong></p>



<p>Zoom meetings and webinars by default use AES 256-bit GCM encryption for audio, video, and application sharing (i.e., screen sharing, whiteboarding) in transit between Zoom applications, clients, and connectors. In a meeting without E2EE enabled, audio and video content flowing between users’ Zoom apps is not decrypted until it reaches the recipients’ devices. However, the encryption keys for each meeting are generated and managed by Zoom’s servers. In a meeting with E2EE enabled, nobody except each participant – not even Zoom’s servers – has access to the encryption keys being used to encrypt the meeting.</p>



<p><strong>How do I verify that my meeting is using end-to-end-encryption?</strong></p>



<p>Participants can look for a green shield logo in the upper left corner of their meeting screen with a padlock in the middle to indicate their meeting is using E2EE. It looks similar to our GCM encryption symbol, but the checkmark is replaced with a lock.</p>



<figure><img loading="lazy" alt="" width="325" height="324" data-src="https://lh3.googleusercontent.com/z-Qf8a0hn5w7dX4q7GAQjGc4iNM_b45r45Um6g7iai7jV9xtmHmcl8WI26vkdAtGfLZrzZTdrszHO6kpgAKspf8rGJ7XcSYrM6asib4EgPyEwFwQkOWmPQuwYI-WplnUflaStT3T"></figure><p>Participants will also see the meeting leader’s security code that they can use to verify the secure connection. The host can read this code out loud, and all participants can check that their clients display the same code.</p>



<figure><img alt="" data-src="https://lh6.googleusercontent.com/Mox0nHn2hmBZqje0OSqXI46iBlhD0YmFzqG0Cv04IIDhUgN76uvL2WCP9NPhZNtKcBV0QMGugkdsUxaeVjgTjnhMrF_DGZBxW7slPIPDYGDUrqYVEiSHFgu-pLAtyYJYgAJ0fJJQ"></figure><p><strong>How will you continue to provide a safe and secure platform?</strong></p>



<p>Zoom’s top priority is the trust and safety of our users, and our implementation of E2EE will allow us to continue to enhance safety on our platform. Free/Basic users seeking access to E2EE will participate in a one-time verification process that will prompt the user for additional pieces of information, such as verifying a phone number via text message. Many leading companies perform similar steps to reduce the mass creation of abusive accounts. We are confident that by implementing risk-based authentication, in combination with our current mix of tools — including our work with human rights and children’s safety organizations and our users’ ability to lock down a meeting, report abuse, and a myriad of other features made available as part of our security icon — we can continue to enhance the safety of our users.</p>



<p><strong>What is the rest of the timeline for E2EE?</strong></p>



<p>We plan to roll out better identity management and E2EE SSO integration as part of Phase 2, which is tentatively roadmapped for 2021.&nbsp;</p>



<p>To learn more about using end-to-end encryption and other security features for your Zoom meetings, visit <a href="https://zoom.us/security" target="_blank" rel="noreferrer noopener">Zoom’s security webpage</a>.</p>
                              
            </div></div>]]>
            </description>
            <link>https://blog.zoom.us/zoom-rolling-out-end-to-end-encryption-offering/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24778490</guid>
            <pubDate>Wed, 14 Oct 2020 16:29:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Dockerfile Security Best Practices]]>
            </title>
            <description>
<![CDATA[
Score 374 | Comments 171 (<a href="https://news.ycombinator.com/item?id=24776771">thread link</a>) | @gbrindisi
<br/>
October 14, 2020 | https://cloudberry.engineering/article/dockerfile-security-best-practices/ | <a href="https://web.archive.org/web/*/https://cloudberry.engineering/article/dockerfile-security-best-practices/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <div>
            <p>Container security is a broad problem space and there are many low hanging fruits one can harvest to mitigate risks. A good starting point is to follow some rules when writing Dockerfiles.</p>

<p>I’ve compiled a list of common security issues and how to avoid them. For every issue I’ve also written an <a href="https://www.openpolicyagent.org/">Open Policy Agent</a> (OPA) rule ready to be used to statically analyze your Dockerfiles with <a href="https://conftest.dev/">conftest</a>. You can’t shift more left than this!</p>

<p>You can find the <code>.rego</code> rule set in <a href="https://github.com/gbrindisi/dockerfile-security">this repository</a>. I appreciate feedback and contributions.</p>

<h2 id="do-not-store-secrets-in-environment-variables">Do not store secrets in environment variables</h2>

<p>Secrets distribution is a hairy problem and it’s easy to do it wrong. For containerized  applications one can surface them either from the filesystem by mounting volumes or more handily through  environment variables.</p>

<p>Using <code>ENV</code> to store secrets is bad practice because Dockerfiles are usually distributed with the application, so there is no difference from hard coding secrets in code.</p>

<p>How to detect it:</p>

<pre><code>secrets_env = [
    "passwd",
    "password",
    "pass",
 #  "pwd", can't use this one   
    "secret",
    "key",
    "access",
    "api_key",
    "apikey",
    "token",
    "tkn"
]

deny[msg] {    
    input[i].Cmd == "env"
    val := input[i].Value
    contains(lower(val[_]), secrets_env[_])
    msg = sprintf("Line %d: Potential secret in ENV key found: %s", [i, val])
}
</code></pre>

<h2 id="only-use-trusted-base-images">Only use trusted base images</h2>

<p>Supply chain attacks for containerized application will also come from the hierarchy of layers used to build the container itself.</p>

<p>The main culprit is obviously the base image used. Untrusted base images are a high risk and whenever possible should be avoided.</p>

<p>Docker provides a <a href="https://docs.docker.com/docker-hub/official_images/">set of official base images</a> for most used operating systems and apps. By using them, we minimize risk of compromise by leveraging some sort of shared responsibility with Docker itself.</p>

<p>How to detect it:</p>

<pre><code>deny[msg] {
    input[i].Cmd == "from"
    val := split(input[i].Value[0], "/")
    count(val) &gt; 1
    msg = sprintf("Line %d: use a trusted base image", [i])
}
</code></pre>

<p>This rule is tuned towards DockerHub’s official images. It’s very dumb since I’m only detecting the absence of a namespace.</p>

<p>The definition of trust depends on your context: change this rule accordingly.</p>

<h2 id="do-not-use-latest-tag-for-base-image">Do not use ‘latest’ tag for base image</h2>

<p>Pinning the version of your base images will give you some peace of mind with regards to the predictability of the containers you are building.</p>

<p>If you rely on latest you might silently inherit updated packages that in the best worst case might impact your application reliability, in the worst worst case might introduce a vulnerability.</p>

<p>How to detect it:</p>

<pre><code>deny[msg] {
    input[i].Cmd == "from"
    val := split(input[i].Value[0], ":")
    contains(lower(val[1]), "latest"])
    msg = sprintf("Line %d: do not use 'latest' tag for base images", [i])
}
</code></pre>

<h2 id="avoid-curl-bashing">Avoid curl bashing</h2>

<p>Pulling stuff from internet and piping it into a shell is as bad as it could be. Unfortunately it’s a widespread solution to streamline installations of software.</p>

<pre><code>wget https://cloudberry.engineering/absolutely-trustworthy.sh | sh
</code></pre>

<p>The risk is the same framed for supply chain attacks and it <strong>boils down to trust</strong>. If you really have to curl bash, do it right:</p>

<ul>
<li>use a trusted source</li>
<li>use a secure connection</li>
<li>verify the authenticity and integrity of what you download</li>
</ul>

<p>How to detect it:</p>

<pre><code>deny[msg] {
    input[i].Cmd == "run"
    val := concat(" ", input[i].Value)
    matches := regex.find_n("(curl|wget)[^|^&gt;]*[|&gt;]", lower(val), -1)
    count(matches) &gt; 0
    msg = sprintf("Line %d: Avoid curl bashing", [i])
}
</code></pre>

<h2 id="do-not-upgrade-your-system-packages">Do not upgrade your system packages</h2>

<p>This might be a bit of a stretch but the reasoning is the following: you want to pin the version of your software dependencies, if you do <code>apt-get upgrade</code> you will effectively upgrade them all to the latest version.</p>

<p>If you do upgrade <strong>and</strong> you are using the <code>latest</code> tag for the base image, you amplify the unpredictability of your dependencies tree.</p>

<p>What you want to do is to pin the base image version and just <code>apt/apk update</code>.</p>

<p>How to detect it:</p>

<pre><code>upgrade_commands = [
    "apk upgrade",
    "apt-get upgrade",
    "dist-upgrade",
]

deny[msg] {
    input[i].Cmd == "run"
    val := concat(" ", input[i].Value)
    contains(val, upgrade_commands[_])
    msg = sprintf(“Line: %d: Do not upgrade your system packages", [i])
}
</code></pre>

<h2 id="do-not-use-add-if-possible">Do not use ADD if possible</h2>

<p>One little feature of the <code>ADD</code> command is that you can point it to a remote url and it will fetch the content at building time:</p>

<pre><code>ADD https://cloudberry.engineering/absolutely-trust-me.tar.gz
</code></pre>

<p>Ironically the official docs suggest to use curl bashing instead.</p>

<p>From a security perspective the same advice applies: don’t.
Get whatever content you need before, verify it and then <code>COPY</code>. But if you really have to, <strong>use trusted sources over secure connections</strong>.</p>

<p>Note: if you have a fancy build system that dynamically generate Dockerfiles, then <code>ADD</code> is effectively a sink asking to be exploited.</p>

<p>How to detect it:</p>

<pre><code>deny[msg] {
    input[i].Cmd == "add"
    msg = sprintf("Line %d: Use COPY instead of ADD", [i])
}
</code></pre>

<h2 id="do-not-root">Do not root</h2>

<p>Root in a container is the same root as on the host machine, but restricted by the docker daemon configuration. No matter the limitations, if an actor breaks out of the container he will still be able to find a way to get full access to the host.</p>

<p>Of course this is not ideal and your threat model can’t ignore the risk posed by running as root.</p>

<p>As such is best to always specify a user:</p>

<pre><code>USER hopefullynotroot
</code></pre>

<p>Note that explicitly setting a user in the Dockerfile is just one layer of defence and won’t solve the whole <a href="https://www.redhat.com/en/blog/understanding-root-inside-and-outside-container">running as root problem</a>.</p>

<p>Instead one can — and <em>should</em> — adopt a defence in depth approach and mitigate further across the whole stack: strictly configure the docker daemon or use a rootless container solution, restrict the runtime configuration (prohibit <code>--privileged</code> if possible, etc), and so on.</p>

<p>How to detect it:</p>

<pre><code>any_user {
    input[i].Cmd == "user"
 }

deny[msg] {
    not any_user
    msg = "Do not run as root, use USER instead"
}
</code></pre>

<h2 id="do-not-sudo">Do not sudo</h2>

<p>As a corollary to <code>do not root</code>, you shall not sudo either.</p>

<p>Even if you run as a user make sure the user is not in the <code>sudoers</code> club.</p>

<pre><code>deny[msg] {
    input[i].Cmd == "run"
    val := concat(" ", input[i].Value)
    contains(lower(val), "sudo")
    msg = sprintf("Line %d: Do not use 'sudo' command", [i])
}
</code></pre>

<h2 id="acknowledgements">Acknowledgements</h2>

<p>This work has been inspired and is an iteration on <a href="https://blog.madhuakula.com/dockerfile-security-checks-using-opa-rego-policies-with-conftest-32ab2316172f">prior art</a> from <a href="https://blog.madhuakula.com/@madhuakula">Madhu Akula</a>.</p>
        </div>
        
    </div></div>]]>
            </description>
            <link>https://cloudberry.engineering/article/dockerfile-security-best-practices/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24776771</guid>
            <pubDate>Wed, 14 Oct 2020 14:17:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Unspoken Hard Bits of Bootstrapping a SaaS Product to Life]]>
            </title>
            <description>
<![CDATA[
Score 105 | Comments 24 (<a href="https://news.ycombinator.com/item?id=24776605">thread link</a>) | @geoffroberts
<br/>
October 14, 2020 | https://www.outseta.com/posts/the-unspoken-hard-bits-of-bootstrapping | <a href="https://web.archive.org/web/*/https://www.outseta.com/posts/the-unspoken-hard-bits-of-bootstrapping">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-block-type="2" id="block-ec2306edd8f63db4e902"><div><p>The challenges that I’ve faced as a bootstrapped founder simply aren’t the ones that are commonly talked about</p><p>By <a href="https://twitter.com/GeoffTRoberts">Geoff Roberts</a> · 17 min read</p><p>The internet is littered with horror stories detailing the many challenges of entrepreneurship. We’ve all read the tales of founders wrestling for years to find <a href="https://www.outseta.com/posts/product-market-appetite">product market fit</a>, of co-founders squabbling over equity, of the CEO riddled by anxiety as he drains his infant daughter’s college fund to keep his start-up afloat for another month.</p><p>Cautionary tales? Sure. But while these circumstances may be relatively common, ultimately they gain notoriety in the tech media simply because they are alarmist and clickbait.&nbsp;</p><p>As I approach year four as a founder of a bootstrapped SaaS start-up, I can’t help but reflect on the hardships that I’ve encountered myself. As I have, I’ve had an overwhelming feeling—the majority of challenges that I’ve faced are by no means unique to me, but <em>nobody is talking about them</em>. This article is about surfacing those common entrepreneurial challenges that are gasping for some air.&nbsp;&nbsp;</p></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1602180654131_6032"><div><p>I’d go so far as to say most entrepreneurial challenges that we hear being bemoaned are a direct result of your chosen path being incompatible with your business idea or life circumstances. When these items are in harmony, entrepreneurship becomes vastly easier.</p><p>If you’re building SpaceX, your idea dictates that you go the VC route—it’s too big, too ambitious, and too capital intensive to bootstrap such a company into existence. This is an extreme example, but this is the lens through which we should be assessing our start-up ideas as we decide how to fund them.</p><p>Generally speaking, “smaller” products are better suited to bootstrapping. Building a slack notification tool? Great! You can probably launch something like this in less than a month, give the project the opportunity to gain some traction, then make the decision to proceed or not from there. You’d be crazy <em>not</em> to bootstrap such a company.&nbsp;&nbsp;&nbsp;</p><p>But if you’re building a bigger and more ambitious piece of software you need to look closely at the reality that it could take years to bring something of value to fruition. Can you afford a year without a paycheck? How about three years, or five?&nbsp;</p><p>It’s worth noting that this isn’t solely a financial decision or one of product scope, but also one that will impact your day-to-day life potentially for years to come. Did you recently sign a mortgage? Do you plan on having kids? The stresses that come with entrepreneurship and how you choose to fund your business will have trickle down effects on all aspects of your life.</p><p>The question is not do you prefer bootstrapping or venture capital. The question is which path is most compatible with the product you’re building… and your life.&nbsp;</p><p>Bringing this full circle to Outseta, in many ways Outseta is not an idea compatible with the idea of bootstrapping. Outseta is a very large and ambitious project that we’re executing on with a small team—it’s really three or four different software products rather than one. We knew this going in and openly talked about how it would take years for us to truly be able to deliver on our value proposition and start to grow revenue in a meaningful way. It took us two years to deliver a sellable product, and four years in now we’re just starting to scale.&nbsp;</p><p>But we had one major advantage—the idea that we chose to build was not one that needed “validating”—the categories of software that we offer (CRM, billing, email marketing, etc) have staying power and have been validated long ago. This gave us confidence that we could play the long game and allowed us to design all aspects of our business and lives so that we could survive long enough to see Outseta blossom into what it’s become today.&nbsp;</p><p>We didn’t choose an easy route, but we’re now finding that Outseta is massively defensible because very few teams would commit 4+ years just to bring an idea to life. You could do it much more quickly with venture capital, sure, but you’d never be able to serve the audience that we do at our price point.&nbsp;</p><h2>The “Doldrums” of SaaS</h2><p>One of the most common and least talked about hardships of bootstrapping a SaaS start-up is what I’ve started describing as “the doldrums of SaaS.” This occurs when your start-up hits an inflection point in sign-ups and support requests scale up dramatically to the extent that they all but take over your ability to focus on other aspects of your business, from marketing to building new features.</p><p>Ironically enough, this stage in a bootstrapped start-up’s growth initially became apparent to me because of one of our competitors. We started getting dozens of sign-ups from founders all singing the same tune.&nbsp;</p><p><em>“I was using CompetitorX—I loved their product initially, but they’re unresponsive and haven’t released any new features in months.”</em></p><p>Then earlier this spring, we went through a similar stage. On the back of a new partnership with <a href="https://www.outseta.com/webflow">Webflow</a>, all of a sudden the number of sign-ups for Outseta scaled up dramatically—and in tandem with that growth came an influx of support tickets from new users learning the platform.</p><p>My summer was spent focused almost entirely on technical support, while my time spent marketing Outseta fell off a cliff. Likewise, my Co-founders were pushing fixes and helping out with new Outseta implementations cutting into their ability to roll out new features.</p><p>Ultimately this is a stage in a bootstrapped start-up’s growth that doesn’t get much lip service because there’s little benefit to speaking about increased support levels and decreased capacity for building new features. But that’s unfortunate because this is a “good problem” that nearly every scaling company will encounter—yet there’s very little advice out there on how to best handle this stage of the entrepreneurial journey.</p><p>If you’re a VC backed company, it’s an easy problem to fix—throw some money at hiring additional support capacity, because you have the ability to run your company at a loss. But for a bootstrapper this stage can feel like your legs are stuck in quicksand.</p><p>I don’t have a solution here, aside from taking some degree of solace in the thought that time spent helping customers is the most single important thing that you can do to build your business. And rather than hiring support capacity, using your engineering resources to solve underlying issues that result in increased support requests will always pay off in the long run.</p><h2>The psychological toll of not feeling like you’re “all-in”</h2><p>It’s well documented that many entrepreneurs feel extreme levels of stress, anxiety, worry, and even depression—which most often is tied to financial instability and the regular peaks and valleys of building a company. But for me personally—and I suspect many others—one of the strongest psychological tolls I’ve felt is stress that comes from feeling like I’m not yet able to be “all-in” on my start-up.</p><p>Make no mistake about it—since the day we started Outseta, I’ve undoubtedly been “all-in.” I’ve rearranged almost all aspects of my life over four years in support of bringing this company into existence. But as part of our strategy to <a href="https://www.outseta.com/posts/marketing-strategies-for-bootstrappers">bootstrap the business</a>, our entire team began working on Outseta in a part-time capacity while consulting or working on other projects to pay the bills. We’ve gradually ramped up the time we’ve each invested in the business as our growth has permitted, as most bootstrappers do.</p><p>For me personally, this meant that for years, literally, there was always this nagging feeling that I could be doing more. I could be doing more or doing better for Outseta, and I could be doing more in terms of the other projects I was working on as well. For me, that feeling has been tough. It feels really good to be able to say that you unequivocally, without question, are giving something your all. But most bootstrappers have to wait quite a long period of time until their business can truly support every last scrap of their attention at work. That’s a long period of time to wait to shed that nagging feeling!</p><h2>SaaS <em>is</em> a torture chamber</h2><p>The wonders of SaaS as a business model are well known—the stability and predictability of recurring revenue, products that can scale to thousands of users, high valuations—the whole nine yards. But the fact of the matter is that for bootstrapped founders, SaaS <em>is</em> a torture chamber and a game of delayed gratification.</p><p>Don’t misunderstand me and immediately suppose that there’s some sort of self-inflicted pain behind this comment—I’m the biggest proponent of work/life balance and generally the principles outlined in Jason Fried and DHH’s <a href="https://www.amazon.com/Doesnt-Have-Be-Crazy-Work/dp/0062874780"><em>It Doesn’t Have To Be Crazy At Work</em></a> that you’ll ever find. This is solely a matter of the business model.</p><p>When you’re bootstrapping, you’re going to start off without a paycheck. Most of us work towards a point where the revenue of the business can eventually start to pay us something, then we scale up our own compensation until it reaches some semblance of a normal salary. The problem with SaaS and bootstrapping is you are hugely incentivized not to pay yourself—every dollar that you pay yourself is money that isn’t being reinvested in the growth of your business, so you’re intentionally slowing down your own growth.</p><p>Of course there are human, real world circumstances to consider and your own financial and emotional needs directly correlate to your ability to work on your business successfully. But the hard reality is the longer you can delay your own gratification, the greater your advantage.&nbsp;</p><p>I asked my Co-founder, Dimitris, to speak to his experience of the long, slow ramp of death that’s so prevalent in SaaS. Dimitris Co-founded <a href="https://www.buildium.com/">Buildium</a> back in 2004.</p><p>“It took us 2.5 years to get to 50 customers,” says Dimitris. “Then it took us another year to get to 400 customers, and a year after that we reached 1,000 customers. When we had 400 customers we made a conscious decision to defer paying ourselves more than a token $1,000 per month salary and instead hired our first two full-time …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.outseta.com/posts/the-unspoken-hard-bits-of-bootstrapping">https://www.outseta.com/posts/the-unspoken-hard-bits-of-bootstrapping</a></em></p>]]>
            </description>
            <link>https://www.outseta.com/posts/the-unspoken-hard-bits-of-bootstrapping</link>
            <guid isPermaLink="false">hacker-news-small-sites-24776605</guid>
            <pubDate>Wed, 14 Oct 2020 14:01:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Z80 CPU User Manual (2016)]]>
            </title>
            <description>
<![CDATA[
Score 106 | Comments 54 (<a href="https://news.ycombinator.com/item?id=24776115">thread link</a>) | @tosh
<br/>
October 14, 2020 | https://zany80.github.io/documentation/Z80/UserManual.html | <a href="https://web.archive.org/web/*/https://zany80.github.io/documentation/Z80/UserManual.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://zany80.github.io/documentation/Z80/UserManual.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24776115</guid>
            <pubDate>Wed, 14 Oct 2020 13:13:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Elon Musk Shows the Germans How to Move Quickly]]>
            </title>
            <description>
<![CDATA[
Score 69 | Comments 122 (<a href="https://news.ycombinator.com/item?id=24775556">thread link</a>) | @Tomte
<br/>
October 14, 2020 | https://www.spiegel.de/international/business/the-tesla-factory-near-berlin-elon-musk-shows-the-germans-how-to-move-quickly-a-a14a3415-a4ed-4d85-80c1-ec53b66ac0cb | <a href="https://web.archive.org/web/*/https://www.spiegel.de/international/business/the-tesla-factory-near-berlin-elon-musk-shows-the-germans-how-to-move-quickly-a-a14a3415-a4ed-4d85-80c1-ec53b66ac0cb">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-article-el="body">
<section data-app-hidden="true">


</section>
<section>
<div>
<figure data-component="Image" data-settings="{&quot;id&quot;:&quot;4f34f3e1-6c6f-4065-9ec6-3301690ac70f&quot;, &quot;zoomable&quot;:true,&quot;zoomId&quot;:&quot;011a50b0-5eca-4b9c-a93b-b9a3ce8c66a3&quot;}">
<p><span>
<span data-image-el="aspect">
<span>
<img data-image-el="img" src="https://cdn.prod.www.spiegel.de/images/4f34f3e1-6c6f-4065-9ec6-3301690ac70f_w948_r1.77_fpx76_fpy24.jpg" srcset="https://cdn.prod.www.spiegel.de/images/4f34f3e1-6c6f-4065-9ec6-3301690ac70f_w520_r1.77_fpx76_fpy24.jpg 520w, https://cdn.prod.www.spiegel.de/images/4f34f3e1-6c6f-4065-9ec6-3301690ac70f_w948_r1.77_fpx76_fpy24.jpg 948w" width="948" height="536" sizes="948px" title="Tesla founder Elon Musk: &quot;A ton of fun!&quot;" alt="Tesla founder Elon Musk: &quot;A ton of fun!&quot;">
</span>
</span>
</span>

</p>
<figcaption>
<p><strong>Tesla founder Elon Musk:</strong> "A ton of fun!"</p>
<span>
Foto: <p>Julian Stähle / dpa</p>
</span>
</figcaption>
</figure>
</div><div>
<p>A large property map hangs in the mayor's office, right next to a display cabinet full of memorabilia accumulated over a long term in office. The coat of arms of the town of Grünheide on the map has faded, as has the writing: "Net settlement area of 300 hectares," it reads, if you look hard enough.</p>


<div>
<p>Arne Christiani's predecessor hung up the poster 20 years ago, back when BMW wanted to build a car manufacturing plant on the site, but then chose the city of Leipzig instead. "When I was first elected mayor in 2003, I left the map up," says Christiani. The pine forest on the edge of the town has remained his field of dreams for almost 17 years.</p><p>During that time, Grünheide has grown steadily, but its population has also aged. It's a place that's beautiful for people who appreciate peace and quiet, but not one that’s particularly tempting for the younger generation. Each year, Christiani has apologized to locals on International Volunteer Day for the fact that it had once again not been possible to attract high-quality industrial jobs to the area.</p>
</div>

<div>
<p>For some time now, though, two new maps have been hanging above the old one, with the parcel of land colored red. Christiani's dream could finally be coming true, with Tesla hoping to build electric cars on the site.</p><h3><strong>Dreams Threatened, Dreams Come True</strong></h3><p>If you leave Town Hall and walk a good 800 meters through a pine forest to the edge of the village, you reach a lake called Peetzsee. Christiani had been in office for two years when Johannes Curth and his family came to fulfil their dream here, swapping a rental apartment in Berlin’s Prenzlauer Berg neighborhood for a home of their own, surrounded by forests and lakes.</p>
</div>

<p>The Curths bought a plot of land just a few meters from the shore of the lake back when prices were still reasonable. They built a house with large windows and surrounded by a good-sized yard, in which stand two magnificent old trees in it.</p>

<section data-area="contentbox">
<div>
<p><span>DER SPIEGEL 39/2020</span></p><figure data-component="Image" data-settings="{&quot;id&quot;:&quot;996d8f55-bef6-471b-ad10-5c788bf27a9e&quot;, &quot;zoomable&quot;:false,&quot;zoomId&quot;:&quot;640c6d43-536f-4a18-abc5-735accbca6fa&quot;}">
<span>
<span data-image-el="aspect">
<span>

<img data-image-el="img" src="https://cdn.prod.www.spiegel.de/images/996d8f55-bef6-471b-ad10-5c788bf27a9e_w568_r0.7571817357121258_fpx50.98_fpy47.69.jpg" srcset="https://cdn.prod.www.spiegel.de/images/996d8f55-bef6-471b-ad10-5c788bf27a9e_w284_r0.7571817357121258_fpx50.98_fpy47.69.jpg 284w, https://cdn.prod.www.spiegel.de/images/996d8f55-bef6-471b-ad10-5c788bf27a9e_w335_r0.7571817357121258_fpx50.98_fpy47.69.jpg 335w, https://cdn.prod.www.spiegel.de/images/996d8f55-bef6-471b-ad10-5c788bf27a9e_w568_r0.7571817357121258_fpx50.98_fpy47.69.jpg 568w" width="568" height="750" sizes="568px" loading="lazy" data-srcset="https://cdn.prod.www.spiegel.de/images/996d8f55-bef6-471b-ad10-5c788bf27a9e_w284_r0.7571817357121258_fpx50.98_fpy47.69.jpg 284w, https://cdn.prod.www.spiegel.de/images/996d8f55-bef6-471b-ad10-5c788bf27a9e_w335_r0.7571817357121258_fpx50.98_fpy47.69.jpg 335w, https://cdn.prod.www.spiegel.de/images/996d8f55-bef6-471b-ad10-5c788bf27a9e_w568_r0.7571817357121258_fpx50.98_fpy47.69.jpg 568w">
</span>
</span>
</span>
</figure>

</div>
</section>
<p>But now that Mayor Christiani's dream is coming true, Curth sees his own dream threatened. "We moved here because of the peace and quiet and the nature," he says. "What will happen if Tesla starts building cars here?" He fears for the quality of the water and air. And he worries about the extra traffic and what will happen to this sleepy community of 8,755 people when Tesla moves in.</p>

<div>
<p>Elon Musk, the entrepreneur behind the carmaker, is an uncompromising man whose ideas jump back and forth between California, Mars and Grünheide. The head of the world's largest electric car manufacturer builds rockets that ferry people into space and dreams of building a hyperloop tunnel for passenger transport. He is adored by his followers because, as an entrepreneur, he refuses to accept any limits.</p><h3><strong>Breathtaking Speed</strong></h3><p>Almost as a byproduct, Musk is now also changing not only the provincial state of Brandenburg, where he’s setting up his factory, but also Germany. The project just outside of Berlin is becoming symbolic for industrial policy in times of climate change. Whereas German companies tend to moan and dig in their heels when the government sets overly ambitious climate targets, as they did last week when the new European Union climate goals were announced, Tesla brings both together: sustainable manufacturing and speed. Breathtaking speed.</p>
</div>
<figure>
<div data-component="Image" data-settings="{&quot;id&quot;:&quot;7bfd7c90-7763-4bb3-ad45-ab17ec97c569&quot;, &quot;zoomable&quot;:true,&quot;zoomId&quot;:&quot;2ce6ae6b-8cd6-4df5-a9fe-c32f7c47f756&quot;}">
<div>
<div>
<p><span>
<span data-image-el="aspect">
<span>

<img data-image-el="img" src="https://cdn.prod.www.spiegel.de/images/7bfd7c90-7763-4bb3-ad45-ab17ec97c569_w718_r1.5_fpx33.34_fpy50.jpg" srcset="https://cdn.prod.www.spiegel.de/images/7bfd7c90-7763-4bb3-ad45-ab17ec97c569_w488_r1.5_fpx33.34_fpy50.jpg 488w, https://cdn.prod.www.spiegel.de/images/7bfd7c90-7763-4bb3-ad45-ab17ec97c569_w616_r1.5_fpx33.34_fpy50.jpg 616w, https://cdn.prod.www.spiegel.de/images/7bfd7c90-7763-4bb3-ad45-ab17ec97c569_w718_r1.5_fpx33.34_fpy50.jpg 718w" width="718" height="479" sizes="718px" loading="lazy" data-srcset="https://cdn.prod.www.spiegel.de/images/7bfd7c90-7763-4bb3-ad45-ab17ec97c569_w488_r1.5_fpx33.34_fpy50.jpg 488w, https://cdn.prod.www.spiegel.de/images/7bfd7c90-7763-4bb3-ad45-ab17ec97c569_w616_r1.5_fpx33.34_fpy50.jpg 616w, https://cdn.prod.www.spiegel.de/images/7bfd7c90-7763-4bb3-ad45-ab17ec97c569_w718_r1.5_fpx33.34_fpy50.jpg 718w" title="Tesla Gigafactory in Grünheide: Are the Germans fast enough?" alt="Tesla Gigafactory in Grünheide: Are the Germans fast enough?">
</span>
</span>
</span>
</p><figcaption>
<p><strong>Tesla Gigafactory in Grünheide:</strong> Are the Germans fast enough?</p>
<span>
Foto: Robert Grahn&nbsp;/ euroluftbild.de / ullstein bild
</span>
</figcaption>
</div>
</div>
</div>
</figure><div>
<p>Musk's Gigafactory will be built in a region where most structures tend to be single-family homes, if there are any at all. In the first stage of development, 12,000 people will work around the clock in three shifts. Once the factory is complete, more than 40,000 people could produce a good 2 million Tesla vehicles here. "Please work at Tesla Giga Berlin! It's going to be a ton of fun," Musk recently tweeted in German.</p><p>For quite some time, German car executives and politicians tended to make fun of Musk, notorious as he was for his outrageous personality on Twitter. When he outlined his visions at a 2014 lunch with Peter Altmaier - who was chief of staff of Angela Merkel's Chancellery at the time but is now economics minister – and raved about the advantages of electric propulsion, saying it could be used in all means of transportation except for rockets flying into space, Altmaier still thought he sounded a bit unhinged. "At the time," says Altmaier, "nobody thought this technology would be so successful." At least the German competition didn't.</p><p>As recently as 2018, when the California-based company was having troubles with the serial production of its Model 3, Volkswagen considered becoming a strategic investor in Tesla to teach Musk how to do mass production. But reality has long since overtaken that idea: Tesla is now worth five times as much as Volkswagen on the stock exchange.</p><p>The days when the billionaire had to ask politicians for an appointment are over. When he came to Germany in early September to visit his construction site, the reception he received was that of a pop star. Fans shared the latest movement data of his private jet and puzzled where he might pop up next. Leading politicians cleared their calendars at short notice.</p><p>This week, the Musk party is set to continue, and his name will once again appear in newspapers around the world. He has slated this Tuesday as "Battery Day,” when he plans to announce the progress Tesla has made in battery technology in addition to identifying the site of at least one new battery plant. There are many indications, including interviews with Musk, that Grünheide may be chosen as the site. If it is, giant tree-felling machines would again show up to wait for authorization to clear another 60 hectares (nearly 150 acres) of forest.</p><p>It would send an unmistakable message. Because one day later, on Wednesday, hearings are set to begin in the nearby town of Erkner on the 406 complaints against the factory that have been filed by environmental associations and residents. Construction, though, has already been underway for months, with Tesla deciding to move ahead at its own risk with preliminary permits.</p><h3><strong>Faster and Better</strong></h3><p>A recent visit to the construction site in Grünheide provided a glimpse of the degree to which Tesla's mantra has been internalized at Tesla, a mantra by which speed counts most. Evan Horetsky, who heads the roughly 100-member Tesla team in Grünheide, showed a number of interested journalists around the construction site.</p><p>The slim man in his mid-30s with a shaved head and carefully trimmed beard is one of the troubleshooters on Musk's team. He helped out with the Tesla factory in California before going to Reno, Nevada, to lead the creation of the company's first Gigafactory. That had hardly been finished by the time construction in Shanghai began. He says that he and his people have gotten "faster and better" each time. Now, Horetsky is moving things along in Brandenburg.</p><p>Just last fall, the site was covered with tall pine trees. Now, though, they have been replaced by dozens of white concrete pillars protruding from the levelled ground. In the rear section, the shell of the paint shop has been erected. "We gained experience during the construction of the first buildings that we could directly apply in the further development of the design," the American says. "It enabled us to save a couple of days."</p>
</div>
<figure>
<div data-component="Image" data-settings="{&quot;id&quot;:&quot;557ddc99-4b15-46b4-871e-c4391a0edffd&quot;, &quot;zoomable&quot;:true,&quot;zoomId&quot;:&quot;c472a109-402d-4560-bace-2978897f5ba0&quot;}">
<div>
<div>
<p><span>
<span data-image-el="aspect">
<span>

<img data-image-el="img" src="https://cdn.prod.www.spiegel.de/images/557ddc99-4b15-46b4-871e-c4391a0edffd_w718_r1.4951856946354882_fpx40.02_fpy49.94.jpg" srcset="https://cdn.prod.www.spiegel.de/images/557ddc99-4b15-46b4-871e-c4391a0edffd_w488_r1.4951856946354882_fpx40.02_fpy49.94.jpg 488w, https://cdn.prod.www.spiegel.de/images/557ddc99-4b15-46b4-871e-c4391a0edffd_w616_r1.4951856946354882_fpx40.02_fpy49.94.jpg 616w, https://cdn.prod.www.spiegel.de/images/557ddc99-4b15-46b4-871e-c4391a0edffd_w718_r1.4951856946354882_fpx40.02_fpy49.94.jpg 718w" width="718" height="480" sizes="718px" loading="lazy" data-srcset="https://cdn.prod.www.spiegel.de/images/557ddc99-4b15-46b4-871e-c4391a0edffd_w488_r1.4951856946354882_fpx40.02_fpy49.94.jpg 488w, https://cdn.prod.www.spiegel.de/images/557ddc99-4b15-46b4-871e-c4391a0edffd_w616_r1.4951856946354882_fpx40.02_fpy49.94.jpg 616w, https://cdn.prod.www.spiegel.de/images/557ddc99-4b15-46b4-871e-c4391a0edffd_w718_r1.4951856946354882_fpx40.02_fpy49.94.jpg 718w" title="Mayor Arne Christiani: A field of dreams." alt="Mayor Arne Christiani: A field of dreams.">
</span>
</span>
</span>
</p><figcaption>
<p><strong>Mayor Arne Christiani: </strong>A field of dreams.</p>
<span>
Foto: HC Plambeck / DER SPIEGEL
</span>
</figcaption>
</div>
</div>
</div>
</figure><div>
<p>The fact that final permission to build the factory has not yet been granted and that skeptical citizens must first be heard doesn't bother Horetsky. He says he takes their fears seriously. He notes that similarly complicated requirements had to be fulfilled when building the factory in Shanghai. "The difference to Germany is that here, the people who are directly affected can have their say," says Horetsky. "And who has more of a right to air their views than they do?"</p><p>It is, essentially, the concrete realization of what had been an abstract discussion. What price is society prepared to pay for the future? And are Germans capable of keeping up with the necessary pace?</p><p>The Gigafactory is set to be built in record time, with the first Y model electric SUVs slated for shipping as early as summer 2021. Plans call for 500,000 electric cars to be produced annually by the end of the first construction stage, a pace the <em>Wall Street Journal</em> has described as "breakneck."</p><p>And all this is taking place in Germany, a country where the length of approval procedures has almost doubled in the last 10 years. And in the state of Brandenburg, where construction of the Berlin-Brandenburg Airport (BER) has been marred by endless construction problems and is finally set to open its doors, fully nine years behind schedule.</p><h3><strong>Not Even Corona Has Slowed the Project</strong></h3><p>It sounded almost like a joke initially: An American high-tech car company with a volatile boss meets German environmental law, citizen participation and German bureaucracy. Now, though, it looks as though electric cars could start rolling off the assembly line in Grünheide even faster than they did in centrally steered China. And not even the coronavirus has thus far managed to slow down the project.</p><p>Somehow, the clichés didn't hold true. Tesla may be a tenacious, demanding company, but it also takes criticism seriously and tries to address it. In contrast to German companies, Musk uses every possibility that planning law avails him to accelerate construction, but he does so at his own risk. At the same time, the Brandenburg government has shown itself to be a skilful negotiator in the fight for the project. Since the contract was awarded, a task force of employees from the participating authorities has met weekly with Tesla representatives to discuss progress on the project.</p><p>Axel Vogel was one of the founding members of the Green Party in 1980. He worked …</p></div></div></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.spiegel.de/international/business/the-tesla-factory-near-berlin-elon-musk-shows-the-germans-how-to-move-quickly-a-a14a3415-a4ed-4d85-80c1-ec53b66ac0cb">https://www.spiegel.de/international/business/the-tesla-factory-near-berlin-elon-musk-shows-the-germans-how-to-move-quickly-a-a14a3415-a4ed-4d85-80c1-ec53b66ac0cb</a></em></p>]]>
            </description>
            <link>https://www.spiegel.de/international/business/the-tesla-factory-near-berlin-elon-musk-shows-the-germans-how-to-move-quickly-a-a14a3415-a4ed-4d85-80c1-ec53b66ac0cb</link>
            <guid isPermaLink="false">hacker-news-small-sites-24775556</guid>
            <pubDate>Wed, 14 Oct 2020 11:59:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Sega Master System Architecture: A Practical Analysis]]>
            </title>
            <description>
<![CDATA[
Score 260 | Comments 74 (<a href="https://news.ycombinator.com/item?id=24775305">thread link</a>) | @Parseus
<br/>
October 14, 2020 | https://www.copetti.org/projects/consoles/master-system/ | <a href="https://web.archive.org/web/*/https://www.copetti.org/projects/consoles/master-system/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div class="page"><nav id="navbar"></nav><h2>A Practical Analysis</h2><hr><hr><h2 id="a-quick-introduction">A quick introduction</h2><p>The Master System comes from a long line of succession. What started as a collection of off-the-shelf components, has now gained a new identity thanks to Sega’s engineering.</p><hr><h2 id="models-and-variants">Models and variants</h2><p>I was a bit confused at first while reading about the different models that Sega ended up shipping, so here is a summary of the main models discussed to avoid further confusions:</p><ul><li><strong>Sega Mark III</strong>: The first console featuring this architecture, only released in Japan.</li><li><strong>Sega Master System</strong> (Europe and America): A rebranded Mark III with a new case, a BIOS ROM chip and a different cartridge slot.</li><li><strong>Sega Master System</strong> (Japan): An European/American Master system with the Mark III’s cartridge slot, a new FM chip and a jack port for ‘3D glasses’. However, it lacks the <code>RESET</code> button.</li></ul><p>From now one I’ll use the term ‘Master System’ or ‘SMS’ to refer to all of these, except when talking about exclusive features from a particular model.</p><hr><h2 id="cpu">CPU</h2><p>Sega decided on a fully-fledged <strong>Zilog Z80</strong> CPU running at <strong>~3.58 MHz</strong>. A popular choice by other machines like the ZX Spectrum and the Amstrad CPC. The Z80 has an instruction set compatible with the Intel 8080 but expanded with lots of more instructions.</p><p>The motherboard picture at the start of the article shows a NEC D780C-1 CPU, that’s just SEGA second-sourcing the chip to different manufacturers, other revisions even included the chip manufactured by Zilog. But for this article, it doesn’t matter who fabricated the CPU, as the internal features remain the same.</p><h4 id="memory-available">Memory available</h4><p>The Z80 has a 16-bit address bus, so the CPU can find up to 64 KB worth of memory. In the memory map you’ll find <strong>8 KB of RAM</strong> for general purpose use, this is mirrored in another 8 KB block. Finally, <strong>up to 48 KB of game ROM</strong> are mapped as well.</p><h4 id="accessing-the-rest-of-the-components">Accessing the rest of the components</h4><p>As you can read from the previous paragraph, only main RAM and some cartridge ROM is found on the address space, so how can the program access other components? Well, unlike Nintendo’s <a href="https://www.copetti.org/projects/consoles/nes/">Famicom/NES</a>, not all the hardware of the Master System is mapped using memory locations. Instead, some peripherals are found on the <strong>I/O space</strong>.</p><p>This is because the Z80 family contains an interesting feature called <strong>I/O ports</strong> which enables the CPU to communicate with other hardware without running out of memory addresses. For this, there’s a separate address space for ‘I/O devices’ called <strong>ports</strong> and both share the same data and address bus. The difference, however, is that ports are read and written using <code>IN</code> and <code>OUT</code> instructions, respectively - as opposed to the traditional load/store instruction (<code>LD</code>).</p><p>When an <code>IN</code> or <code>OUT</code> instruction is executed, the Z80 sets up the address lines pointing to the peripheral (which could be, for instance, a keyboard), flags its <code>IORQ</code> pin indicating that an I/O request has been initiated and also flags the <code>RD</code> pin or the <code>WR</code> pin whether it’s an <code>IN</code> or <code>OUT</code> instruction, respectively. The addressed peripheral must manually check for the address bus and the I/O pins and perform the required operation. In the case of an <code>IN</code> instruction, the CPU will store the received value on a pre-defined register.</p><div><a href="https://www.copetti.org/images/consoles/mastersystem/addressing.e186afc9821090e7011a73663fff377720381c6427d70dfc0cdfe0c03921953e.png"><picture>
<img name="image_cover" alt="Image" width="944" height="315" src="https://www.copetti.org/images/consoles/mastersystem/addressing.e186afc9821090e7011a73663fff377720381c6427d70dfc0cdfe0c03921953e.png" loading="auto"></picture></a><figcaption>SMS' Addressing layout</figcaption></div><p>The way SEGA interconnected the CPU with the rest of the components enables not only to access values, but also showing/hiding certain components from appearing in the memory map.</p><p>Curiously enough, the <a href="https://www.copetti.org/projects/consoles/game-boy/#cpu">Game Boy</a> had a Z80 ‘variant’ that completely omitted the I/O ports. Thus, it had to fit everything in the memory map.</p><h4 id="backwards-compatibility">Backwards compatibility</h4><p>The architecture of this console is very similar to its predecessor, the <strong>Sega SG-1000</strong>, so the Master System managed to gain backwards compatibility with the SG-1000. Although, this only applies to the Japanese variant since the others contain a different cartridge slot.</p><hr><h2 id="graphics">Graphics</h2><p>The drawings on the screen are produced by a proprietary chip called <strong>Video Display Processor</strong> or ‘VDP’. Internally, it has the same design of the Texas instrument TMS9918 (used in the SG-1000), but enhanced with more features which we will discuss in the following sections.</p><h4 id="organising-the-content">Organising the content</h4><div><a href="https://www.copetti.org/images/consoles/mastersystem/vdp.2930ab05e2b147c948d5134eeb66a701849c0a047bd649abd3cfd4b84d7cde21.png"><picture>
<img name="image_cover" alt="Image" width="1019" height="303" src="https://www.copetti.org/images/consoles/mastersystem/vdp.2930ab05e2b147c948d5134eeb66a701849c0a047bd649abd3cfd4b84d7cde21.png" loading="auto"></picture></a><figcaption>Memory architecture of the VDP</figcaption></div><p>Next to the VDP is connected <strong>16 KB of VRAM</strong> which only the VDP can access using a 16-bit data bus. If you look at the motherboard picture again, you’ll notice that both RAM and VRAM chips are roughly the same, except that VRAM uses the chip model ending in ‘20’ which has lower latency.</p><p>In the case of the Master System, VRAM houses everything the VDP will require for rendering (except Colour RAM). The CPU fills VRAM by writing on VDP’s registers, which will in turn forward the values to VRAM. Since the VDP is accessed using I/O ports, the CPU must use <code>IN</code> and <code>OUT</code> instructions.</p><h4 id="constructing-the-frame">Constructing the frame</h4><p>The VDP renders frames with a resolution of <strong>up to 256x192 pixels</strong>, further revision added support for 256x224 px and 256x240 px, however, to maintain compatibility with all models, developers held on to the standard resolution. This chip has the same <em>modus operandi</em> of Nintendo’s <a href="https://www.copetti.org/projects/consoles/nes/#constructing-the-frame">PPU</a>, in other words, graphics are rendered on-the-spot.</p><p>On the other side, the VDP has four different modes of operation which will alter the characteristics of the frame (colour depth and resolution):</p><ul><li><strong>Mode 0 to III</strong>: Inherited from the TMS9918 found on the SG-1000. Included for backwards compatibility, although any SMS game can use them.</li><li><strong>Mode IV</strong>: Native mode of the Master System, which enables access to all the state-of-the-art features of the VDP. For the analysis, we’ll focus on this one!</li></ul><p>Now let’s see how a frame is drawn step by step, for this, I’ll borrow <em>Sonic The Hedgehog</em>’s assets. Also, to make explanations easier, I’m going to focus on the standard memory layout that Sega suggest for organising the graphics content (just remember that the VDP is very flexible with this, so games are allowed to optimise it).</p><div><ul><li id="tab-2-1-tiles-link"><a href="#tab-2-1-tiles">Tiles</a></li><li id="tab-2-2-background-layer-link"><a href="#tab-2-2-background-layer">Background Layer</a></li><li id="tab-2-3-sprite-layer-link"><a href="#tab-2-3-sprite-layer">Sprite Layer</a></li><li id="tab-2-4-result-link"><a href="#tab-2-4-result">Result</a></li></ul><div><div id="tab-2-1-tiles"><h4>Tiles</h4><p>Mode IV is based on the <strong>tile system</strong>. To recall <a href="https://www.copetti.org/projects/consoles/nes/#tab-2-1-tiles">previous explanations</a> about tile engines, tiles are just <strong>8x8 pixel bitmaps</strong> which the renderer fetches to draw the game’s graphics. In the case of the VDP, the frame is composed of two planes, the background layer and the sprite layer.</p><p>Inside VRAM, there’s an area dedicated for tiles called <strong>Character generator</strong> (Sega calls ‘Characters’ to tiles) and it’s set to be <strong>14 KB long</strong>. Each tile occupies 32 bytes, so we can store up to 448 tiles.</p><p>There are 64 pixels defined on every tile, the VDP rules that each pixel must weight 4 bits, that means that up to <strong>16 colours can be chosen</strong>. Those bits reference a single entry on <strong>Colour RAM</strong> or ‘CRAM’. That area is found inside the VDP and stores the colour palettes. Colour palette systems help reduce the size of tiles in memory and allows programmers to alternate its colours without storing multiple copies.</p><p>Colour RAM stores <strong>two palettes of 16 colours each</strong>. Each entry is 6-bit wide and each 2-bit set defines one colour from the RGB model. This means that there are 64 colours available to choose from.</p></div><div id="tab-2-2-background-layer"><h4>Background Layer</h4><p>The background layer is a large plane where static tiles are drawn. To place something here, there’s another area on VRAM called <strong>Screen map</strong> that takes 1.75 KB.</p><p>This enables to build a layer of 896 tiles (32x28 tiles), but if we do the math we’ll see that this layer is larger than the display resolution of this console. The reality is, only 768 tiles (32x24 tiles) are visible, so the visible area is manually selected at the programmer’s will. Hence, by slowly alternating the X and Y coordinates of the selected area, a <strong>scrolling effect</strong> is accomplished.</p><p>Each entry of the map is 2 bytes wide (as wide as the VDP data-bus) and contains the address of the tile in the Character generator and the following attributes:</p><ul><li><strong>Horizontal and Vertical flip</strong>.</li><li>The <strong>priority bit</strong> (whether to draw some or all the tile in front of sprites).</li><li>The <strong>colour palette</strong> used.</li></ul><p>Curiously enough, there are 3 unused bits in the entry which the game can use for other purposes (i.e. extra flags to assist the game engine).</p></div><div id="tab-2-3-sprite-layer"><h4>Sprite Layer</h4><div><a href="https://www.copetti.org/images/consoles/mastersystem/sonic/sprites.707537651fd6e5ce0ebcca7c4192748e4389797ebbcff4c1ddb4939cb8271e44.png"><picture>
<img name="image_cover" alt="Image" width="256" height="192" src="https://www.copetti.org/images/consoles/mastersystem/sonic/sprites.707537651fd6e5ce0ebcca7c4192748e4389797ebbcff4c1ddb4939cb8271e44.png" loading="auto"></picture></a><figcaption>Rendered Sprite layer</figcaption></div><p>Sprites are just tiles that move freely. The VDP can raster <strong>up to 64 sprites</strong> using a single tile (8x8 px) or two tiles stacked vertically (8x16 px).</p><p>The <strong>Sprite Attribute Table</strong> is a 256-byte area in VRAM that contains an array of all the sprites defined, its entries are similar to the background layer, except each sprite contain two additional values representing the X/Y coordinates.</p><p>The VDP is limited to <strong>up to eight sprites per horizontal scan-line</strong>. Also, if two sprites overlap, the last one in the list will be the one displayed.</p></div><div id="tab-2-4-result"><h4>Result</h4><div><a href="https://www.copetti.org/images/consoles/mastersystem/sonic/result.f37a1b0bb0f463acd33bdd04cc53b65c0504e26615bbe9a20f29533217601437.png"><picture>
<img name="image_cover" alt="Image" width="256" height="192" src="https://www.copetti.org/images/consoles/mastersystem/sonic/result.f37a1b0bb0f463acd33bdd04cc53b65c0504e26615bbe9a20f29533217601437.png" loading="auto"></picture></a><figcaption>Tada!</figcaption></div><p>The VDP automatically blends the two layers to form the final frame. The rendering process is done scan-line by scan-line, so the VDP doesn’t really know how the frame is going too look, that’s only seen by the user when the picture is constructed on the TV.</p><p>If you look at the example image, you may notice the frame has a vertical column at the left side. This is because the screen map is only tall enough to provide vertical scrolling without producing artefacts, <strong>but not wide enough for horizontal scrolling</strong>. So, the VDP can <strong>mask</strong> the left-most side with an 8 px column to protect the image from showing intermediate tiles.</p><p>To update the graphics for the next frame without breaking the image currently being displayed, the VDP sends two types of <strong>interrupts</strong> to the CPU. One which notifies that the CRT TV has finished beaming a chosen number of scan-lines (called <strong>horizontal interrupt</strong>) and another when the CRT finished drawing the last scan-line (called <strong>vertical interrupt</strong>) indicating the frame is finished. During those events, the CRT’s beam is re-allocating to draw the next scan-line (<strong>blanking interval</strong>), so any alteration of the VDP’s state won’t tear the image down. Horizontal blanking has a shorter time-frame than vertical blanking, yet it still allows to change, let’s say, the colour palette. This still can achieve some effects.</p></div></div></div><h4 id="secrets-and-limitation">Secrets and limitation</h4><p>At first glance, the VDP may seem like another chip with minimal functionality that we now take for …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.copetti.org/projects/consoles/master-system/">https://www.copetti.org/projects/consoles/master-system/</a></em></p>]]>
            </description>
            <link>https://www.copetti.org/projects/consoles/master-system/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24775305</guid>
            <pubDate>Wed, 14 Oct 2020 11:14:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Visidata 2.0]]>
            </title>
            <description>
<![CDATA[
Score 186 | Comments 20 (<a href="https://news.ycombinator.com/item?id=24774947">thread link</a>) | @polm23
<br/>
October 14, 2020 | https://www.visidata.org/blog/2020/v2.0/ | <a href="https://web.archive.org/web/*/https://www.visidata.org/blog/2020/v2.0/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section id="body">
        
<p>This is a major milestone. After almost 2 years of development, version 2.0 of VisiData is finally released. It's got several major improvements, a bunch of new loaders, and tons of new features and quality of life improvements. And, most importantly, an API specification for plugins.</p>
<h2>1. Licensing Changes</h2>
<p>[tl;dr: no more MIT vdtui; GPL3 for everything]</p>
<p>Previously, there was a core vdtui single-file library that I licensed as MIT, as I thought it might be a platform for a variety of apps like VisiData. Approximately no one showed interest in that though, and it became unwieldy to maintain, so over the course of developing VisiData 2.0, the vdtui library was thoroughly dismantled. It's now just the visidata module as a whole, which I'm releasing under GPL3. The last released version of vdtui.py under MIT was 1.5.2 if anyone wants to use that.</p>
<h2>2. Plugin API</h2>
<p>[tl;dr: "2.0" has a stable documented API; expect a growing ecosystem of plugins for a wide variety of use cases.]</p>
<p>To be honest, this is what held off the 2.0 release for so long. I knew I wanted to go through every function and decide whether I wanted to include it in the 2.0 API to be supported for the rest of the 2.x lifecycle, which might be years. (We don't intend to strictly adhere to "semver", but it's still important to try to maintain backwards compatibility within a major version number.) So now, we have an API spec with over 200 functions, which will be of interest if you want to customize VisiData, or create a plugin for it, or just to know more about its internal components.</p>
<p>Take a look at the actual API, at <a href="https://visidata.org/docs/api">visidata.org/docs/api</a>. It still needs a bit more polish, but the meat and bones are there.</p>
<h2>3. Undo and Redo</h2>
<p>This is a "game changer" according to @jsvine.</p>
<p>Undo and redo, along with the new <code>guard-sheet</code> command, make it much easier to rely on VisiData for data cleaning and data entry.</p>
<p>If you upgrade to 2.0 and learn nothing else about it, your life will be better for knowing Shift+U (undo) and Shift+R (redo).</p>
<h2>4. Deferred modifications</h2>
<p>[tl;dr: if you add/edit/delete rows on a few specific sheets, the changes won't take place right away; you'll have to press z Ctrl+S]</p>
<p>Certain sheets which know how to incrementally update their source--notably, the DirSheet and SqliteSheet--<strong>defer</strong> changes made to them, requiring an explicit save/commit step with commit-sheet (z Ctrl+S).</p>
<p>These changes are colorized on the screen and can be saved as data (or not saved, in the case of deletes) with save-sheet (Ctrl+S), even if they haven't been committed back to the original source with commit-sheet.</p>
<p>This means vd can work quite naturally as an interactive file manager, or as a sqlite database editor. I've been using it to manage my mp3 collection and my personal contacts database, which was a tsv file until I wanted to add a multiline "notes" field, so I saved it as a .json file and used that for a few months, and now I've been using it in an sqlite database. Of course they all look the same in VisiData so I can go back and forth without any friction.</p>
<h2>5. Split Window</h2>
<p>Press Shift+Z to split the terminal window into a top panel and bottom panel.</p>
<p>One panel contains the current/top sheet, the other panel contains the sheet "under" the top sheet. Press Tab or Ctrl+^ to go between them.</p>
<p>The fancy chooser (now the default for choosing aggregators or jointypes) uses this split window, and I have many other ideas for it as well.</p>
<p>It may not seem like much now, but I predict that this becomes a sleeper hit.</p>
<p>[previously blogged at: <a href="https://visidata.org/blog/2020/splitwin">visidata.org/blog/2020/splitwin</a>)]</p>
<h2>6. So many other features</h2>
<p>Here's curated list of highlights, the ones that seemed like people would be interested to know about:</p>
<ul>
<li>more visibility for long values, with "v" to toggle multi-line rows and and z+hjkl to adjust cell offset</li>
<li>[iota] the "i" family of commands to add an increment column</li>
<li>[unfurl] zM, which does row-wise expansion of iterables in a column (very useful with nested data)</li>
<li>[join] add "merge" jointype</li>
<li>[numeric binning] ranged binning for numeric columns</li>
<li>[cli] custom options parsing allows for per-sheet options</li>
<li>[cli] pipe and redirect to stdout; use as an interactive chooser</li>
<li>[input] Ctrl+Y paste from cell clipboard and other improvements</li>
<li>Alt+ as new keyboard layer for user keybindings</li>
</ul>
<p>And, as with every release, there are a bunch of new loaders, including MIME, recutils, vcard, imap, mysql, pdf, npy/npz, and more! See the new <a href="https://visidata.org/formats">/formats</a> page for a full list of supported formats, in tidy tabular form.</p>
<p>Then if you still haven't seen enough, you can see the <a href="https://github.com/saulpw/visidata/blob/stable/CHANGELOG.md#v2.0">CHANGELOG</a> for the complete list of bugfixes and changes.</p>
<p>Okay, that about wraps it up for this release. If anything I've written about here sounds interesting and you'd like me to cover it first, or more in-depth, let me know! Send me <a href="https://www.visidata.org/blog/2020/v2.0/vd@saul.pw">an email</a>, or <a href="https://www.visidata.org/blog/2020/v2.0/twitter.com/VisiData">tweet @VisiData</a>, or <a href="https://www.visidata.org/blog/2020/v2.0/github.com/saulpw/visidata/issues">open a github issue</a>, or chat with us on Freenode #visidata; however you want to get in touch, we'd love to hear from you.</p>

     </section></div>]]>
            </description>
            <link>https://www.visidata.org/blog/2020/v2.0/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24774947</guid>
            <pubDate>Wed, 14 Oct 2020 10:02:37 GMT</pubDate>
        </item>
    </channel>
</rss>
