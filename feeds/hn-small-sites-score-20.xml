<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 20]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 20. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Tue, 01 Dec 2020 08:32:01 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-20.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Tue, 01 Dec 2020 08:32:01 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[A better Kubernetes from the ground up]]>
            </title>
            <description>
<![CDATA[
Score 22 | Comments 3 (<a href="https://news.ycombinator.com/item?id=25243159">thread link</a>) | @mr-karan
<br/>
November 28, 2020 | https://blog.dave.tf/post/new-kubernetes/ | <a href="https://web.archive.org/web/*/https://blog.dave.tf/post/new-kubernetes/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
	<div>
		<p><span>Written by</span>
        David Anderson
        <br>
        <span>on&nbsp;</span><time datetime="2020-11-28 00:00:00 +0000 UTC">November 28, 2020</time>
</p>
		


		

		<p>Recently I had a chat with the excellent <a href="https://timewitch.net/">Vallery Lancey</a>, about Kubernetes. Specifically, what we would do differently if we built something new, from the ground up, with no regard for compatibility with Kubernetes. I found that conversation so stimulating that I feel the need to write things down, so here we are.</p>

<p>Before we get started, I want to stress a few things.</p>

<ul>
<li>This is not a fully formed design. Some of these things may not work at all, or require significant redesign. Each section is one random piece of the entire puzzle.</li>
<li>These are not solely my ideas. Some I <em>think</em> are original, but like many things in the Kubernetes community it’s the product of collective thinking. I know at least <a href="https://timewitch.net/">Vallery</a> and <a href="https://twitter.com/maisem_ali">Maisem Ali</a> have influenced my thinking at one time or another, and I’m forgetting many more. If you like an idea, it was a group effort. If you hate it, it’s entirely mine.</li>
<li>Some of these things are polarizing. I’m designing something that makes <em>me</em> happy.</li>
</ul>

<h2 id="guiding-principles">Guiding principles</h2>

<p>My experience of Kubernetes comes from two very different places: authoring <a href="https://www.metallb.org/">MetalLB</a> for bare metal clusters, and operating a large fleet of clusters-as-a-service in <a href="https://cloud.google.com/kubernetes-engine">GKE SRE</a>. Both of these taught me that Kubernetes is extremely complex, and that most people who are trying to use it are not prepared for the sheer amount of work that lies between the marketing brochure and the system those brochures promise.</p>

<p>MetalLB taught me that it’s not possible to build robust software that integrates with Kubernetes. I think MetalLB makes a damn good go of it, but Kubernetes still makes it far too easy to construct broken configurations, and far too hard to debug them. GKE SRE taught me that even the foremost Kubernetes experts cannot safely operate Kubernetes at scale. (Although GKE SRE does a spectacular job with the tools they’re given.)</p>

<p>Kubernetes is the C++ of orchestration software. Immensely powerful, includes all the features, looks deceptively simple, and <em>will</em> hurt you repeatedly until you join its priesthood and devote your life to its mysteries. And even then, the matrix of possible ways to configure and deploy it is so large that you’re never on firm footing.</p>

<p>Continuing that analogy, my guide star is Go. If Kubernetes is C++, what would the Go of orchestration systems look like? Aggressively simple, opinionated, grown slowly and warily, and you can learn it in under a week and get on with what you were actually trying to accomplish.</p>

<p>With that, let’s get going. Starting with Kubernetes, and with a license to completely and utterly break compatibility, what would I do?</p>

<h2 id="mutable-pods">Mutable pods</h2>

<p>In Kubernetes, pods are mostly (but not entirely) immutable after creation. If you want to change a pod, you don’t. Make a new one and delete the old one. This is unlike most other things in Kubernetes, which are mostly mutable and gracefully reconcile towards the new spec.</p>

<p>So, I’m going to make pods be not special. Make them entirely read-write, and reconcile them like you would any other object.</p>

<p>The immediately useful thing I get from that is in-place restarts. If scheduling constraints and resource allocations haven’t changed, guess what? SIGTERM runc, restart runc with different parameters, and you’re done. Now pods look like regular old systemd services, that can move between machines <em>if necessary</em>.</p>

<p>Note that this doesn’t require doing mutability at the runtime layer. If you change a pod definition, it’s still mostly fine to terminate the container and restart it with a new configuration. The pod is still holding onto the resource reservation that got it scheduled onto this machine, so conceptually it’s equivalent to <code>systemctl restart blah.service</code>. You could try to be fancy and make some operations actually update in place at the runtime level as well, but don’t have to. The main benefit is decoupling scheduling, pod lifetime, and lifetime at the runtime layer.</p>

<h2 id="version-control-all-the-things">Version control all the things</h2>

<p>Sticking at the pod layer for a bit longer: now that they’re mutable, the next obvious thing I want is rollbacks. For that, let’s keep old versions of pod definitions around, and make it trivial to “go back to version N”.</p>

<p>Now, a pod update looks like: write an updated definition of the pod, and it updates to match. Update broken? Write back version N-1, and you’re done.</p>

<p>Bonus things you get from this: a diffable history of what happened to your cluster, without needing GitOps nonsense. By all means keep the GitOps nonsense if you want, it has benefits, but you can answer a basic “what changed?” question using only data in the cluster.</p>

<p>This needs a bit more design. In particular, I want to separate out external changes (human submits a new pod) from mechanical changes (some internals of k8s alter a pod definition). I haven’t thought through how to encode both those histories and make both accessible to operators and automation. Maybe it could also be completely generic, wherein a “changer” identifies itself when submitting a new version, and you can then query for changes by or excluding particular changers (think similar to how label queries work at the minute). Again, more design needed there, I just know that I want versioned objects with an accessible history.</p>

<p>We’ll need garbage collection eventually. That said, changes to single pods should delta-compress really well, so my default would be to just keep everything until it becomes a truly dumb amount of data, and figure something out at that point. Keeping everything also acts as a useful mild pressure to avoid “death by a thousand changes” in the rest of the system. Prefer to have fewer, more meaningful changes over a flurry of control loops each changing one field in pursuit of convergence.</p>

<p>Once we have this history, we can do some neat minor things too. For example, the node software could keep container images for the last N versions pinned to the machine, so that rollbacks are as fast as they can possibly be. With an accessible history, you can do this more precisely than “GC older than 30 days and hope”. Generalizing, all the orchestration software can use older versions as GC roots for various resources, to make rollbacks faster. Rollbacks being the primary way of ending outages, this is a very valuable thing to have.</p>

<h2 id="replace-deployment-with-pinneddeployment">Replace Deployment with PinnedDeployment</h2>

<p>This is a short section to basically say that <a href="https://timewitch.net/">Vallery</a> knocked it out of the park with her <a href="https://timewitch.net/post/2019-12-30-pinneddeployments/">PinnedDeployment</a> resource, which lets operators explicitly control a rollout by tracking 2 versions of the deployment state. It’s a deployment object designed by an SRE, with a crisp understanding of what SREs want in a deployment. I love it.</p>

<p>This combines super well with the versioned, in-place pod updates above, and I really don’t have anything to add. It’s clearly how multi-pod things should work. There’s probably some tweaking required to adapt from the Kubernetes-constrained world to this new wonderful unconstrained universe, but the general design is perfect.</p>

<h2 id="explicit-orchestration-workflows">Explicit orchestration workflows</h2>

<p>The biggest issue I have with the “API machinery” bits of Kubernetes is the idea of orchestration as a loose choreography of independent control loops. On the surface, this seems like a nice idea: you have dozens of little control loops, each focused on doing one small thing. When combined in a cluster, they indirectly cooperate with each other to push the state forward and converge on the desired end state. So, what’s the problem?</p>

<p>The problem is that it’s entirely impossible to debug when it goes wrong. A typical failure mode in Kubernetes is that you submit a change to the cluster, then repeatedly refresh waiting for stuff to converge. When it doesn’t… Well, you’re screwed. Kubernetes doesn’t know the difference between “the system has converged successfully” and “a control loop is wedged and is blocking everything else.” You can hope that the offending control loop posted some events to the object to help you, but by and large they don’t.</p>

<p>At which point your only option is to cat the logs of every control loop that might be involved, looking for the one that was wedged. You can make this a bit faster if you have intimate knowledge of all the control loops and what each one does, because that lets you infer from the object’s current state which loop might be trying to run right now.</p>

<p>The key thing to notice here is that the complexity has been shifted from the designer of the control loop to the cluster operator. It’s easy (though not trivial) to make a control loop that does a dinky little thing in isolation. But to operate a cluster with dozens of these control loops requires the operator to assimilate the behavior of all of them, their interactions with each other, and try to reason about an extremely loosely coupled system. This is a problem because you have to write and test the control loop once, but work with it and its bugs many more times. And yet, the bias is to simplify the thing you only do once.</p>

<p>To fix this, I would look to systemd. It solves for a similar lifecycle problem: given a current state and a target, how do you get from A to B? The difference is that in systemd, the steps and their dependencies are made explicit. You <em>tell</em> systemd that your unit is a required part of <code>multi-user.target</code> (aka “normally-booted happy system”), that it must run after filesystems have been mounted, but before networking it brought up, and so forth. You can also depend on other concrete parts of the system, for example to say that your thing needs to run whenever sshd is running (sounds like a sidecar, right?).</p>

<p>The net result of this is that systemd can tell you precisely what piece of the system malfunctioned, or is still working on its thing, or failed a precondition. It can also print you a graph of the system’s boot process, and analyze it for things like “what’s the long pole of bootup?”</p>

<p>I want to steal all this wholesale, and plop it into my cluster orchestration …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.dave.tf/post/new-kubernetes/">https://blog.dave.tf/post/new-kubernetes/</a></em></p>]]>
            </description>
            <link>https://blog.dave.tf/post/new-kubernetes/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25243159</guid>
            <pubDate>Sun, 29 Nov 2020 05:35:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Undeleting a file overwritten with mv]]>
            </title>
            <description>
<![CDATA[
Score 90 | Comments 30 (<a href="https://news.ycombinator.com/item?id=25242444">thread link</a>) | @todsacerdoti
<br/>
November 28, 2020 | https://behind.pretix.eu/2020/11/28/undelete-flv-file/ | <a href="https://web.archive.org/web/*/https://behind.pretix.eu/2020/11/28/undelete-flv-file/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="main">

    <article>

        

<!--         <header class="post-header">
            <a id="blog-logo" href="https://behind.pretix.eu">
                
                    <span class="blog-title">pretix – behind the scenes</span>
                
            </a>
        </header> -->

        <!-- <span class="post-meta">
            <time datetime="2020-11-28">28 Nov 2020</time>
            
                on Technology, Forensics, and Linux
            
        </span> -->

        <!-- <h1 class="post-title">Undeleting a file overwritten with mv</h1> -->

        <section>
            <p>It’s been a while since we shared the story of an incident with you, and that’s probably a good thing –
most operational incidents we had in the past year were “boring” enough in nature to fix them easily.
This time, we’ve got a story of a data loss, caused by pure and simple human error – and the story of
how we recovered the data.</p>

<p>Even though it is quite embarrassing how the data loss happened, we think it’s worth sharing the story
of its recovery, as it might allow you to learn a few useful things in case you ever end up in a
similar situation.</p>

<p>As you might have seen, over the last 7 months we’ve extended our offerings beyond ticketing to allow
our customers to transform their events into the digital space as long as the global pandemic makes
traditional event formats impossible. The result of our effort is a joint venture called 
<a href="https://venueless.org/">Venueless</a> that you should absolutely check out if you haven’t yet.</p>

<p>One component of the virtual events we run on venueless is <strong>live video streaming</strong>. In this process,
our customers use a tool like <a href="https://obsproject.com/">OBS</a> or <a href="https://streamyard.com/">StreamYard</a>
to create a live video stream. The stream is then sent to an <strong>encoding server</strong> of ours via RTMP.
On the encoding server, we re-encode the stream into different quality levels and then distribute
it to our very own tiny streaming CDN.</p>

<p>Venueless currently does <strong>not yet</strong> include a video-on-demand component and usually, our customers record
their content at the source, e.g. with OBS or StreamYard, and process or publish them on their own.
However, just to be safe, we keep a recording of the incoming stream as well. This isn’t currently
part of our promoted service offering, we rather see it as a free backup service to our clients in case they
lose their recording. Given that we already consider it to just be a backup, we currently don’t make any
further backups of this data.</p>

<h4 id="data-loss">Data loss</h4>

<p>Usually, we delete these recordings after a while, but in some cases, our customers ask us to get them, e.g.
because their own recording failed, or because StreamYard only records the first 8 hours of every
stream. Since this doesn’t happen a lot, it’s not yet an automated process in our system. Whenever a customer
requests a recording we SSH into the respective encoding server and move the recording file to a
directory that’s accessible through HTTP, like this:</p>

<pre><code>/var/recordings $ mv recording-12345.flv public/
</code></pre>

<p>That’s it, we share the link with the customer, and the process is done. One of the simplest steps possible
in all this. Yesterday, a customer asked us for the recordings of the two last streams of their event. Just
before finishing up for the week, I wanted to supply them with the required file, SSH’d into the server,
looked for the correct files and typed…</p>

<pre><code>/var/recordings $ mv recording-16678.flv recording-16679.flv
</code></pre>

<p><strong>Oops.</strong> I hit return before typing out <code>public/</code>, and therefore replaced the last stream with the
second-last, losing one of the videos.</p>

<h4 id="damage-control">Damage control</h4>

<p>Having a very naive understanding of how file systems work, I knew that the <code>mv</code> command has only
changed the directory listing of the file system, but hasn’t actually wiped the file from the disk,
so I knew there is likely still a chance to recover the file, if it’s not overwritten by something
else in the meantime.</p>

<p>Since I didn’t manage to re-mount the root partition as read-only to avoid further damage softly,
I used the <a href="https://www.kernel.org/doc/html/latest/admin-guide/sysrq.html">big hammer</a> to remount
everything read-only immediately:</p>

<pre><code># echo u &gt; /proc/sysrq-trigger
</code></pre>

<p>Uhm, okay, this worked, but how do I install any data recovery tools now? After some experiments,
I decided it would be easiest to reboot into the recovery system provided by our server provider
<a href="https://www.hetzner.com/">Hetzner</a>. So I configured the boot loader to boot their recovery system
from the network and forcefully rebooted the server.</p>

<p>To be able to perform disk dumps and have some operational flexibility without downloading a 2 TB
disk image to my local machine (which would take rougly a week), I also quickly purchased
a <a href="https://www.hetzner.com/storage/storage-box">Hetzner Storage Box</a> with 5 TB space.</p>

<h4 id="failed-attempts">Failed attempts</h4>

<p>Just before I executed my fatal <code>mv</code> command, I executed <code>ls -lisah</code> to get a directory listing
of the files:</p>

<pre><code>3146449 1.1G -rw-r--r-- 1 www-data www-data 1.1G Nov XX XX:XX recording-16678.flv
3146113 1.6G -rw-r--r-- 1 www-data www-data 1.6G Nov XX XX:XX recording-16679.flv
</code></pre>

<p>This meant I <strong>knew</strong> the inode number of the deleted file! As I mentioned before, my understanding
of file systems was (and is) rather naive, and I was pretty optimistic to be able to recover the
file using that information. Isn’t that sort of what a journaling file system is for?</p>

<p>Recovering the file this way hover appeared to be impossible. <a href="http://ext4magic.sourceforge.net/howto_en.html">ext4magic</a>
and <a href="http://extundelete.sourceforge.net/">extundelete</a> are powerful tools that did find some 
deleted files on my disk – but not the one I was looking for, even after trying different options
for over two hours.</p>

<p>I did not spend the time to really understand how ext4 works, but from what I gathered from various
blogs, I was pretty much out of luck since the inode did no longer contain the relevant information
and ext4magic also wasn’t able to <a href="http://ext4magic.sourceforge.net/howto_en.html#Recovery_process_5">recover the neccessary information from the journal</a>
either.</p>

<pre><code>debugfs:  inode_dump &lt;3146113&gt;
0000  a081 0000 8503 0000 e83a c15f e83a c15f  .........:._.:._
0020  e83a c15f 0000 0000 7200 0100 0800 0000  .:._....r.......
0040  0000 0800 0100 0000 0af3 0100 0400 0000  ................
0060  0000 0000 0000 0000 0100 0000 e6eb c000  ................
0100  0000 0000 0000 0000 0000 0000 0000 0000  ................
*
0140  0000 0000 92d0 2cf5 0000 0000 0000 0000  ......,.........
0160  0000 0000 0000 0000 0000 0000 6fb2 0000  ............o...
0200  2000 e3fb 208a 515b 7c65 5d5a 7c65 5d5a   ... .Q[|e]Z|e]Z
0220  e83a c15f 7c65 5d5a 0000 0000 0000 0000  .:._|e]Z........
0240  0000 0000 0000 0000 0000 0000 0000 0000  ................
*
</code></pre>

<p>However, if you’re in a similar situation – the ext4magic how-tos are really helpful and worth a try.</p>

<h4 id="successful-recovery">Successful recovery</h4>

<p>There is this one other approach to file recovery that is often recommended on the internet, usually
for “small text files”: Just <code>grep</code> your whole disk for known parts of its contents! So why wouldn’t
this work on larger non-text files as well?</p>

<p>The first problem is obviously what to grep for. The only thing I know about the missing file, apart
from its rough size, is that it’s a FLV video file. Luckily, <a href="https://en.wikipedia.org/wiki/Flash_Video#Flash_Video_Structure">all FLV files</a>
that contain video start with the byte sequence <code>FLV\x01\x05</code>. So let’s search our 2 TB disk for
that byte sequence and print out the byte offset of all occurences!</p>

<pre><code>cat /dev/md2 \
	| pv -s 1888127576000 \
	| grep -P --byte-offset --text 'FLV\x01\x05' \
	| tee -a /mnt/storagebox/grep-log.txt
</code></pre>

<p>This took roughly 7 hours. The <code>pv</code> command with the (rough) total size of the disk is optional, but gives you
a nice progress bar. Overall, this took a little over 6 hours on our server.</p>

<p><code>grep</code> works line-based, which in a binary file menas “any byte sequence between two ASCII line breaks”. The
log file therefore contained lots of lines like this:</p>

<pre><code>184473878409:&lt;some binary data&gt;FLV&lt;some binary data&gt;
</code></pre>

<p>In total, the search found 126 FLV file headers on our disk. This was pretty reassuring, since we had 122 FLV files
still known to the file system – so there are at least four FLV byte sequences without a filename!</p>

<pre><code># find /mnt/disk/var/recordings/ -name '*.flv' -not -empty -ls | wc -l
122
</code></pre>

<p>Now, I needed to find out which of the 126 byte sequences did not have a filename. Since I really didn’t want
to spend all weekend with a deep-dive into the ext4 disk layout, I went for an easier solution: For every file
still known in the file system, I computed a hash of the first 500 kilobytes of the file:</p>

<figure><pre><code data-lang="python"><span>#!/usr/bin/python3
</span><span>import</span> <span>glob</span>
<span>import</span> <span>hashlib</span>
<span>import</span> <span>os</span>

<span>hashsize</span> <span>=</span> <span>500</span> <span>*</span> <span>1024</span>
<span>known_hashes</span> <span>=</span> <span>{}</span>
<span>not_deleted_files</span> <span>=</span> <span>sorted</span><span>(</span>
    <span>glob</span><span>.</span><span>glob</span><span>(</span><span>'/mnt/disk/var/recordings/*.flv'</span><span>)</span> <span>+</span> 
    <span>glob</span><span>.</span><span>glob</span><span>(</span><span>'/mnt/disk/var/recordings/public/*.flv'</span><span>)</span>
<span>)</span>
<span># Ignore files shorter than our hash size
</span><span>not_deleted_files</span> <span>=</span> <span>[</span>
    <span>f</span> <span>for</span> <span>f</span> <span>in</span> <span>not_deleted_files</span>
    <span>if</span> <span>os</span><span>.</span><span>stat</span><span>(</span><span>f</span><span>).</span><span>st_size</span> <span>&gt;</span> <span>hashsize</span>
<span>]</span>

<span>for</span> <span>fname</span> <span>in</span> <span>not_deleted_files</span><span>:</span>
    <span>with</span> <span>open</span><span>(</span><span>fname</span><span>,</span> <span>'rb'</span><span>)</span> <span>as</span> <span>f</span><span>:</span>
        <span>h</span> <span>=</span> <span>hashlib</span><span>.</span><span>md5</span><span>(</span><span>f</span><span>.</span><span>read</span><span>(</span><span>hashsize</span><span>)).</span><span>hexdigest</span><span>()</span>
        <span>if</span> <span>h</span> <span>in</span> <span>known_hashes</span><span>:</span>
            <span>print</span><span>(</span><span>"duplicate hash found:"</span><span>)</span>
        <span>known_hashes</span><span>[</span><span>h</span><span>]</span> <span>=</span> <span>fname</span>
        <span>print</span><span>(</span><span>h</span><span>,</span> <span>fname</span><span>)</span>

<span>print</span><span>(</span>
    <span>len</span><span>(</span><span>not_deleted_files</span><span>),</span> <span>"files with"</span><span>,</span>
    <span>len</span><span>(</span><span>known_hashes</span><span>),</span> <span>"hashes"</span>
<span>)</span></code></pre></figure>

<p>Interestingly, two files from the completely different customers shared the same hash of the first 500 kilobytes.
I haven’t tested it yet, but my theory is that those were streams that just did not contain any audio or video
in their first minutes, but only empty frames. However, since I knew this isn’t the case for my missing file,
I felt confident in proceeding with this approach.</p>

<p>Next, I computed the same hash for every byte offest found by grep and compared it to the hashes found in the
previous step:</p>

<figure><pre><code data-lang="python"><span>grep_log</span> <span>=</span> <span>'/mnt/storagebox/grep-log.txt'</span>
<span>disk</span> <span>=</span> <span>'/dev/md2'</span>

<span>print</span><span>(</span><span>"Parsing grep log…"</span><span>)</span>
<span>positions</span> <span>=</span> <span>[]</span>
<span>with</span> <span>open</span><span>(</span><span>grep_log</span><span>,</span> <span>'rb'</span><span>)</span> <span>as</span> <span>f</span><span>:</span>
    <span>for</span> <span>line</span> <span>in</span> <span>f</span><span>.</span><span>read</span><span>().</span><span>split</span><span>(</span><span>b'</span><span>\n</span><span>'</span><span>):</span>
        <span>if</span> <span>not</span> <span>line</span><span>:</span>  <span># ignore empty line e.g. at end of file
</span>            <span>continue</span>
        <span>pos</span><span>,</span> <span>data</span> <span>=</span> <span>line</span><span>.</span><span>split</span><span>(</span><span>b':'</span><span>,</span> <span>1</span><span>)</span>
        <span>pos</span> <span>=</span> <span>int</span><span>(</span><span>pos</span><span>.</span><span>decode</span><span>())</span>
        <span># add offset of FLV within line
</span>        <span>binoffset</span> <span>=</span> <span>data</span><span>.</span><span>index</span><span>(</span><span>b"FLV</span><span>\x01</span><span>"</span><span>)</span>
        <span>pos</span> <span>+=</span> <span>binoffset</span> 
        <span>positions</span><span>.</span><span>append</span><span>(</span><span>pos</span><span>)</span>

<span>print</span><span>(</span><span>"Computing hashes of files on disk…"</span><span>)</span>
<span>found_hashes</span> <span>=</span> <span>{}</span>
<span>with</span> <span>open</span><span>(</span><span>disk</span><span>,</span> <span>'rb'</span><span>)</span> <span>as</span> <span>f</span><span>:</span>
    <span>for</span> <span>p</span> <span>in</span> <span>positions</span><span>:</span>
        <span>f</span><span>.</span><span>seek</span><span>(</span><span>p</span><span>)</span>
        <span>d</span> <span>=</span> <span>f</span><span>.</span><span>read</span><span>(</span><span>hashsize</span><span>)</span>
        <span>h</span> <span>=</span> <span>hashlib</span><span>.</span><span>md5</span><span>(</span><span>d</span><span>).</span><span>hexdigest</span><span>()</span>
        <span>if</span> <span>h</span> <span>in</span> <span>known_hashes</span><span>:</span>
            <span>print</span><span>(</span><span>"At offset"</span><span>,</span> <span>p</span><span>,</span> <span>"found known hash"</span><span>,</span> <span>h</span><span>,</span>
                  <span>"corresponding to"</span><span>,</span> <span>known_hashes</span><span>[</span><span>h</span><span>])</span>
        <span>else</span><span>:</span>
            <span>print</span><span>(</span><span>"At offset"</span><span>,</span> <span>p</span><span>,</span> <span>"found unknown hash"</span><span>,</span> <span>h</span><span>)</span>
        <span>found_hashes</span><span>[</span><span>h</span><span>]</span> <span>=</span> <span>p</span>

<span>unknown_hashes</span> <span>=</span> <span>{</span>
    <span>h</span><span>:</span> <span>p</span> <span>for</span> <span>h</span><span>,</span> <span>p</span> <span>in</span> <span>found_hashes</span><span>.</span><span>items</span><span>()</span>
    <span>if</span> <span>h</span> <span>not</span> <span>in</span> <span>known_hashes</span>
<span>}</span>
<span>files_not_found</span> <span>=</span> <span>[</span>
    <span>fname</span> <span>for</span> <span>h</span><span>,</span> <span>fname</span> <span>in</span> <span>known_hashes</span><span>.</span><span>items</span><span>()</span>
   …</code></pre></figure></section></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://behind.pretix.eu/2020/11/28/undelete-flv-file/">https://behind.pretix.eu/2020/11/28/undelete-flv-file/</a></em></p>]]>
            </description>
            <link>https://behind.pretix.eu/2020/11/28/undelete-flv-file/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25242444</guid>
            <pubDate>Sun, 29 Nov 2020 02:21:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Isetta: Writing a Game Engine from Scratch]]>
            </title>
            <description>
<![CDATA[
Score 99 | Comments 4 (<a href="https://news.ycombinator.com/item?id=25241361">thread link</a>) | @da_big_ghey
<br/>
November 28, 2020 | https://isetta.io/blogs/week-0/ | <a href="https://web.archive.org/web/*/https://isetta.io/blogs/week-0/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <div data-md-component="container">
          
            
              
            
            
              
            
          
          <div>
            <article>
              
                
                
                
<h2 id="introduction">Introduction<a href="#introduction" title="Permanent link">¶</a></h2>
<p>The Isetta Engine is a student-driven project about demystifying game engine development and providing a roadmap and relevant knowledge for novice developers. To do so, <a href="https://isetta.io/team/">our team</a> will make a game engine by ourselves starting from a collection of base frameworks, and document the process, pitfalls, and advice for our audience with periodic blogs. Besides that, we will conduct interviews with experienced professionals to augment our novice perspective. We believe the novice perspective from our blogs and expert perspective from the interviews will nicely come together and form a complete document to help people get started. </p>
<p>The reason we think more work needs to be done in this field is that too many game engine developers wait until the completion of the engine, typically years, to talk about their development. For studios, this is because they consider the final product to be the game, not the engine. For others, it may be because the engine is what they see as valuable, not the writing. As a result, these talks typically lose the minutiae of the actual daily struggles that took place in the development process. There are others who document their development which has been going on for years, which makes it a daunting task for newcomers to start following along. </p>
<p>Although the project is aimed at helping novice developers, this is not to be used as a sole source of learning engine development. Being new engine developers ourselves, we can't guarantee the way we develop the engine will be correct, which is why interviews will help the project remain grounded. This means others who are learning can use what we've done as a guide and not necessarily the ground truth. The blogs won't be a walkthrough/tutorial/step-by-step instructions on how to develop an engine. We are learning as we go and think our journey is what can be valuable to you. </p>
<h3 id="about-the-project">About the Project<a href="#about-the-project" title="Permanent link">¶</a></h3>
<p>This project is being done as a student-pitched project at the <a href="https://www.etc.cmu.edu/">Entertainment Technology Center</a> (ETC). The ETC is an interdisciplinary Master's degree program at Carnegie Mellon University where students' main focus is working on small teams on a project each semester during a 3-month time period. Throughout the semester, a team's work will be presented to faculty and peers with feedback and critique being presented to help aid in the project development. Our particular project idea has gone through multiple iterations to do the following:</p>
<ol>
<li>Simplify the engine to be feasible within 3 months and</li>
<li>Deliver content that would be useful, and hopefully enjoyable, to consume.</li>
</ol>
<p>As of writing this, we've learned that creating content that will satisfy both is difficult and time-consuming, so we will be focusing on writing these milestone-type blogs as well as posting various types of content to test which is the best form of presenting our work. The short project duration also forces us to think clearly about our scope and be lean on the features we include before starting. </p>
<h3 id="schedule">Schedule<a href="#schedule" title="Permanent link">¶</a></h3>
<p>During the course of this project <strong>(08/26 - 12/16, 2018</strong>), a blog post will be published every week to share our thoughts and process, and an interview will be published every 1-2 weeks. The interview schedule depends on our progress on the engine itself, as each interview's topic will be themed around our current work.</p>
<p>For latest schedule, see our <a href="https://isetta.io/schedule/">schedule</a> page.</p>
<h3 id="prerequisites">Prerequisites<a href="#prerequisites" title="Permanent link">¶</a></h3>
<p>Although we will cover some basic features of engine development, it will profoundly help if you have experience in C++ programming and developing software, especially games, as our project won't provide step-by-step instructions on how to do everything. For a list of resources on how to gain related knowledge, please go to the <a href="#Readings">Readings</a> section. Additional resources will be posted on our <a href="https://isetta.io/resources/">resource page</a>.</p>
<p>Another prerequisite is passion for learning game engine development. As you are still reading this, we assume you are as excited about this as we are. This will be a bumpy ride, but you will have us on your side.</p>
<h2 id="research">Research<a href="#research" title="Permanent link">¶</a></h2>
<p>Being a student-pitched ETC project means that the project needed to pass through a pitch process of consulting and convincing faculty in the program. This allowed us to receive feedback about what could be considered a reasonable/manageable scope and where we might hit challenges for a general project. For this project to be a valid ETC project as well as accomplish our mission statement, there needs to be a fine balance between documentation and development. </p>
<p>Before confronting the big monster of engine development and documentation, we thought it would be a good idea to gear up by getting input from people who have actually done this. During our pitch process, we reached out and got the chance to talk to numerous industry professionals and got extremely helpful advice from them. All of these suggestions helped us shape our project into what it is now and provided invaluable knowledge on how to start a game engine. Thus we encourage you, too, to approach professionals and get advice if possible. We've compiled our notes from our conversations with them into a write-up, which will be published soon.</p>
<h3 id="why-another-engine">Why another engine?<a href="#why-another-engine" title="Permanent link">¶</a></h3>
<p>Using an existing game engine like <a href="https://unity3d.com/">Unity</a>, <a href="https://www.unrealengine.com/en-US/what-is-unreal-engine-4">Unreal</a> or <a href="https://www.panda3d.org/">Panda3D</a> is always a handy option to make a game. These well-established engines have a strong collection of tools and APIs so that developers can focus on making the game, not the wheels. However, there is the limitation of not having full control over all systems in the engine as well as not knowing how the engine is processing the game logic and assets. These can obstruct the complex systems of an engine, so although you may have an understanding of how a physics or graphics engine works, each engine operates differently and optimizes for different constraints. </p>
<p>In terms of learning about game engines and how to develop one, these established engines aren't a good source. Panda3D, originally developed by Disney and expanded by past ETC projects, has an older codebase in 2018 with limited community involvement. It is also not using the current industry standard language (C++). Unity and Unreal are both too massive and too cutting-edge to be suitable engine learning material for novices. In addition, Unity's source code isn't publicly available so you technically can't learn from it. The huge codebase sets a high threshold for any beginner to get started.</p>
<h2 id="roadmap">Roadmap<a href="#roadmap" title="Permanent link">¶</a></h2>
<p>The Isetta Engine will support the most primitive form of networked multiplayer twin-stick shooter game. Networked multiplayer was selected to be a part of the engine because it offers significant design and development challenge on every level of the project, and will help differentiate this engine from others being developed. We decided to create the engine in 3D for two reasons: Most AAA engines are 3D, and 3D requires more math and problem solving for us as developers to learn and grow from.</p>
<p>While planning, and before we knew too much about game engines, we had a basic idea of what a game engine would consist of. The image below displays the second/third iteration of what the Isetta engine would look like. We were initially naive thinking we may be able to do both networking as well as physics, however quickly came to grips that would balloon the scope too much. The audio and graphics were and are still planned to be imported from external libraries, and more of the discussion of what is imported and why will be included in a future blog. This diagram of the engine will soon be replaced with more in-depth explanations.</p>
<p><img alt="alt_text" src="https://isetta.io/images/blogs/week-0/pitch_architecture.png" title="Engine Architecture During Pitch"></p>
<h3 id="genre">Genre<a href="#genre" title="Permanent link">¶</a></h3>
<p>As for our choice of the twin-stick shooter genre, we came to the decision after lengthy consideration of the components required to build other game types as well as how that genre would utilize multiplayer. Twin-stick shooters can effectively have little to no physics, which is different from collisions (this will be explained in <a href="https://isetta.io/blogs/week-1/">week 1 blog</a>). Likewise, the information passed between networked sessions is relatively minimal and not too strict on latency. What's more, a twin-stick shooter specializes in simplistic gameplay that doesn't need a world editor or too much design. </p>
<p>In a Skype meeting, <a href="https://waltdestler.com/">Walt Destler</a> explained to us that each game -and more particularly, each genre- requires vastly different netcode solutions. This is also one of the reasons why we prefer netcode over physics, as it can greatly narrow down the genre options. For example, multiplayer shooters, specifically PvP shooters, require small amounts of information to be passed (i.e. bullet and player locations) from server to client with relatively low latency. PvP shooters can also feature client-side prediction <sup id="fnref:0"><a href="#fn:0" rel="footnote">1</a></sup> as well as the additional requirement of lobby/matchmaking with usually more than 2 players. On the other hand, genres like turn-based strategy require large amounts of information to be passed (all units, decisions, resources, etc.) to all users without too much concern for latency or prediction.</p>
<h3 id="building-with-an-example-game">Building with an Example Game<a href="#building-with-an-example-game" title="Permanent link">¶</a></h3>
<p>The other piece of advice we frequently heard from professionals and our faculty alike was the benefit of developing a game in conjunction with the engine. Doing so, they explained, allows you to prove and demonstrate your engine works as expected. The game can also test features to show immediate edge cases of the engine. </p>
<p>Another nicety of developing an engine is that feature creep can be prevented when you keep expanding certain features that won't be utilized in the final product. What the game built from this engine <em>won't</em> be is something original or necessarily fun. However, that's not to say a fun, original game couldn't be created from this engine. The idea of our sample game is to intentionally be derivative so features of a basic twin-stick shooter will be already included in the engine, rather than only specific …</p></article></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://isetta.io/blogs/week-0/">https://isetta.io/blogs/week-0/</a></em></p>]]>
            </description>
            <link>https://isetta.io/blogs/week-0/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25241361</guid>
            <pubDate>Sat, 28 Nov 2020 23:09:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Growl in Retirement]]>
            </title>
            <description>
<![CDATA[
Score 366 | Comments 173 (<a href="https://news.ycombinator.com/item?id=25241030">thread link</a>) | @flyingyeti
<br/>
November 28, 2020 | http://336699.org/GrowlRetirement | <a href="https://web.archive.org/web/*/http://336699.org/GrowlRetirement">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section id="container">
  <article id="8GugXoUrk4po3a8J7EZnDS">
	<time datetime="2020-11-28">November 28, 2020</time>
  
	<p>Growl is being retired after surviving for 17 years. With the announcement of Apple’s new hardware platform, a general shift of developers to Apple’s notification system, and a lack of obvious ways to improve Growl beyond what it is and has been, we’re announcing the retirement of Growl as of today.</p>

<p>It’s been a long time coming. Growl is the project I worked on for the longest period of my open source career. However at WWDC in 2012 everyone on the team saw the writing on the wall. This was my only WWDC. This is the WWDC where Notification Center was announced. Ironically Growl was called Global Notifications Center, before I renamed it to Growl because I thought the name was too geeky. There’s even a sourceforge project for Global Notifications Center still out there if you want to go find it.</p>

<p>We’ve had a lot of support over the years; from our hosting providers at <a href="http://www.networkredux.com/">Network Redux</a>, <a href="http://www.cachefly.com/">CacheFly</a> and others, to all of the apps using our framework, bindings, or any other integration. Special thanks go to <a href="https://adium.im/">Adium</a> and <a href="https://colloquy.app/">Colloquy</a>. Without these two projects having developers who wanted different types notifications, Growl wouldn’t have existed. Without Growl I do not know that we would have any sort of decent notification system in OS X, iOS, Android or who knows what else. </p>

<p>Special thanks goes to <a href="https://www.transifex.com/">Transifex</a> who made localizing into 24 languages a lot easier than anything else we tried. It’s a fantastic product, if you make software please try it. Our localizers were fantastic people and should all be commended for their work. </p>

<p>For developers we recommend transitioning away from Growl at this point. The apps themselves are gone from the app store, however the code itself still lives. Everything from our rake build system to our code is available for use on our <a href="https://github.com/growl/growl/">GitHub page</a></p>

  <figure id="kudo_8GugXoUrk4po3a8J7EZnDS">
    <a href="#kudo">
      
    </a>
    <p>1,752</p>
    <p>Kudos</p>
  </figure>
  <figure id="kudo_side_8GugXoUrk4po3a8J7EZnDS">
    <a href="#kudo">
      
    </a>
    <p>1,752</p>
    <p>Kudos</p>
  </figure>
</article>

</section></div>]]>
            </description>
            <link>http://336699.org/GrowlRetirement</link>
            <guid isPermaLink="false">hacker-news-small-sites-25241030</guid>
            <pubDate>Sat, 28 Nov 2020 22:19:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Blogging vs. Blog Setups]]>
            </title>
            <description>
<![CDATA[
Score 229 | Comments 95 (<a href="https://news.ycombinator.com/item?id=25240939">thread link</a>) | @Kye
<br/>
November 28, 2020 | https://rakhim.org/honestly-undefined/19/ | <a href="https://web.archive.org/web/*/https://rakhim.org/honestly-undefined/19/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Hi, I'm Rakhim. I teach, program, make podcasts, comics and videos on computer science at <a href="https://codexpanse.com/">Codexpanse.com</a>. You can learn more about <a href="https://rakhim.org/about">my work</a> and even <a href="https://www.patreon.com/rakhim">support me</a> via Patreon.</p><p><form action="https://buttondown.email/api/emails/embed-subscribe/rakhim" method="post" target="popupwindow" onsubmit="window.open('https://buttondown.email/rakhim','popupwindow')"><label for="bd-email">Oh, and I have a monthly non-spammy personal newsletter:</label><br>

</form></p><nav><p><a href="https://rakhim.org/">Home</a>
<span>|</span>
<a href="https://blog.rakhim.org/">Blog</a>
<span>|</span>
<a href="https://rakhim.org/about">About</a>
<span>|</span>
<a href="https://codexpanse.com/">Courses</a>
<span>|</span>
<a href="https://rakhim.org/talks">Talks</a>
<span>|</span>
<a href="https://rakhim.org/honestly-undefined">Comics</a>
<span>|</span>
<a href="https://rakhim.org/bookshelf">Bookshelf</a>
<span>|</span>
<a href="https://www.youtube.com/c/codexpanse">YT</a>
<span>|</span>
<a href="https://twitter.com/freetonik">TW</a>
<span>|</span>
<a href="https://rakhim.org/index.xml">RSS</a></p></nav><p>© Rakhim Davletkaliyev, 2020<br>Powered by <a href="https://gohugo.io/">Hugo</a>, <a href="https://www.netlify.com/">Netlify and the Everett interpretation of QM.</a></p></div></div>]]>
            </description>
            <link>https://rakhim.org/honestly-undefined/19/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25240939</guid>
            <pubDate>Sat, 28 Nov 2020 22:03:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Second Swiss firm allegedly sold encrypted spying devices]]>
            </title>
            <description>
<![CDATA[
Score 193 | Comments 131 (<a href="https://news.ycombinator.com/item?id=25240179">thread link</a>) | @secfirstmd
<br/>
November 28, 2020 | https://www.swissinfo.ch/eng/second-swiss-firm-allegedly-sold-encrypted-spying-devices/46186432 | <a href="https://web.archive.org/web/*/https://www.swissinfo.ch/eng/second-swiss-firm-allegedly-sold-encrypted-spying-devices/46186432">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<section>
<div>
<div>
<figure>
<picture>
<source srcset="https://www.swissinfo.ch/resource/image/46186430/landscape_ratio3x2/880/587/a683e845a8c9bdb270a5b635dfc947ed/gO/omnisec.jpg" media="(min-width: 900px)">
<source srcset="https://www.swissinfo.ch/resource/image/46186430/landscape_ratio3x2/580/387/a683e845a8c9bdb270a5b635dfc947ed/Gx/omnisec.jpg" media="(min-width: 321px)">

</picture>
<figcaption>
Omnisec is the second Swiss company that allegedly sold manipulated encryption devices to US intelligence services. <span>Keystone / Walter Bieri</span>
</figcaption> </figure>
</div>
</div><p>Swiss public television, SRF, has found a second company besides Crypto AG&nbsp;was involved in manufacturing manipulated devices allegedly used for spying by foreign intelligence.</p>
<span>This content was published on November 26, 2020 - 11:34</span>
<time datetime="2020-11-26T11:34:28+01:00">

</time><p>According to <a rel="noopener" target="_blank" href="https://www.srf.ch/news/schweiz/verschluesselungsgeraete-geheimdienstaffaere-weitere-schweizer-firma-rueckt-in-den-fokus">SRF sources</a>, the Swiss company Omnisec AG had ties to US intelligence services. This follows revelations in February by SRF, German television ZDF and <em>The Washington Post</em> that Zug-based firm Crypto AG was at the heart of a huge international spying operation led by the CIA, and to a lesser extent by the German BND spy agency.&nbsp;Omnisec was one of the largest competitors of Crypto AG.</p><p>Swiss cryptologist and professor Ueli Maurer was a consultant for Omnisec for years and told SRF that in 1989 US intelligence services (National Security Agency) contacted Omnisec through him.</p><p>Of concern are the OC-500 series devices. Devices were sold to several Swiss federal agencies. However, Swiss&nbsp;authorities only noticed the devices weren't secure&nbsp;in the mid-2000s.</p><p>Several Swiss companies also received manipulated devices from Omnisec, including Switzerland’s largest bank, UBS. It is unclear whether the authorities informed UBS about the weak devices in the mid-2000s. UBS told SRF that it does not comment on security matters but that it had no indications that sensitive data were exposed at the time.</p>
<p>Omnisec, founded in 1987, manufactured voice, fax and data encryption equipment. It was dissolved a few years ago. The most recent head of the company, Clemens Kammer, told SRF that Omnisec customers “have and will continue to place great value on security, confidentiality, discretion and reliability in business relationships”.</p><p>Some politicians have called for further investigations into these latest allegations that may reveal who, if anyone, in the federal government knew of Omnisec’s business affairs with foreign intelligence.</p><h2>Crypto affair</h2><p>Earlier this month, a nine-month&nbsp;<a rel="noopener" target="_blank" href="https://web.archive.org/web/20201110183555/https:/www.parlament.ch/press-releases/Pages/mm-gpdel-2020-11-10.aspx">investigation</a>&nbsp;by the Swiss parliamentary audit committee (GPDel), found that the Swiss intelligence service knew that the US Central Intelligence Agency was behind the Swiss-based Crypto AG as far back as 1993. The report says that Swiss intelligence later collaborated with them to gather information from foreign sources.&nbsp;</p><p>More than 100 countries bought encryption devices from the Zug-based company, which did business under the guise of Swiss neutrality. In reality, the firm belonged to the CIA and Germany intelligence service, which could freely read what it encrypted. Information intercepted with the help of Crypto’s devices changed the course of events, including the Iran hostage crisis of 1979.</p> </section>
</div></div>]]>
            </description>
            <link>https://www.swissinfo.ch/eng/second-swiss-firm-allegedly-sold-encrypted-spying-devices/46186432</link>
            <guid isPermaLink="false">hacker-news-small-sites-25240179</guid>
            <pubDate>Sat, 28 Nov 2020 20:18:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[30 years later, QBasic is still the best]]>
            </title>
            <description>
<![CDATA[
Score 294 | Comments 122 (<a href="https://news.ycombinator.com/item?id=25239424">thread link</a>) | @ohjeez
<br/>
November 28, 2020 | http://www.nicolasbize.com/blog/30-years-later-qbasic-is-still-the-best/ | <a href="https://web.archive.org/web/*/http://www.nicolasbize.com/blog/30-years-later-qbasic-is-still-the-best/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		<p><span><em>(5 minutes read)</em></span></p>
<p><span>My oldest son Noah turned 7 three months ago. If he could trade his family for a 2 hour session of playing minecraft, he would do it in a heartbeat. The other love of his life is Super Mario Maker, and&nbsp;it’s been a thrill to see him play the same game and levels that I played when I was his age. About 5 months ago, I left my family for my yearly pilgrimage of <a href="http://ludumdare.com/compo/">ludum dare</a>: a game dev competition during which I lock myself away with friends, return to a&nbsp;state of primitive caveman, not sleep for 48h, and create&nbsp;a full game from scratch (play it at the end of this post!) As I proudly showed my revolutionary AAA title to my wife, Noah was naturally intrigued and I introduced him to the world of code, showing him how simple&nbsp;words&nbsp;(he had just learned how to read) produced an actual game. Since&nbsp;that very day, Noah&nbsp;has been asking me repeatedly to teach him how to make&nbsp;his own video games. And for the past 5 months, I have been looking for the holy grail of language/IDE for kids in the hope of turning that spark of interest into a memorable experience…</span></p>
<p><span>My quest has led me to&nbsp;endless forums, through which I have tried countless suggestions: SmallBasic, Pico-8, Smalltalk, Scratch, etc. I have even inquired of the Great&nbsp;Oracles of StackOverflow,&nbsp;to&nbsp;no avail. After 5 months,&nbsp;I&nbsp;ended up with a disappointing conclusion: nothing is even close to what I had back in another era. 30 years later, QBasic is still the best when it comes to&nbsp;discovering programming.&nbsp;</span></p>
<blockquote>
<p><span>“OMG please don’t teach him GOTOs!!”</span></p>
</blockquote>
<pre><code>10 PRINT “OH NO, WHAT ARE YOU DOING?!!!”
20 GOTO 10</code></pre>
<p><span>Yes, QBasic is a terrible procedural language. It introduces one to concepts widely considered harmful, uses awkward syntax for implicit declarations, is not case sensitive, is non-zero-based, etc. the list goes on… When developing a skill, it is much better to acquire the right reflexes from the start rather than have to correct years of bad practice. Following this advice, I should have probably started off with&nbsp;the basics of the ruby language which I love. Yet, while most of those QBasic concepts are today generally considered&nbsp;as red flags by our peers, they each served a very specific&nbsp;purpose at the time: to keep the language simple and accessible, a notion that every other language has left behind in favor of flexibility, complexity and logic.</span></p>
<p><span>I installed QBasic on my son’s 11” HP Stream today, having to hack a DOSBox manual installation. He double clicked the icon on his desktop and in a split second, we were in the IDE, greeted with the introduction screen which brought back so many memories to my mind:</span></p>
<p><img src="https://upload.wikimedia.org/wikipedia/en/0/01/QBasic_Opening_Screen.png" alt="" width="640" height="400"></p>
<p><span>I then told Noah that there was a very sacred ritual, mandatory&nbsp;for anyone who enters the secret&nbsp;inner&nbsp;circle of programmers, to start off with a program that greets every other programmer out there. As I dictated the formula, he slowly&nbsp;searched for each&nbsp;key, carefully&nbsp;typing with his right finger&nbsp;the magic words: <code>PRINT “hello world”</code></span></p>
<p><span>He pressed F5 and looked amazed as he saw his code being compiled into text rendered on his black screen. He smiled, gave me a high-five, and then scribbled down the code in his little notebook so that he could remember later.</span></p>
<p><img src="http://nicolasbize.com/blog/images/noah_1.jpg" alt="" width="800" height="600"></p>
<p>We went on to a couple more commands: CLS, COLOR, PLAY, INPUT, and IF. There was nothing to explain: no complexity, no awkward operator, no abstract concepts, no documentation that needed to be read, no notion of objects/class/methods, no framework to install, no overwhelming menu/buttons in the IDE, no special keyword or parenthesis. It was code in its purest simplicity and form.</p>
<p><span>After less than an hour, he wrote his first program on his own – an interactive and incredibly subtle application which lets you know the computer’s feelings towards&nbsp;you as an individual and sensible human being:</span></p>
<p><img src="http://nicolasbize.com/blog/images/noah_3.jpg" alt="" width="800" height="600"></p>
<p><span>…which he ran with utmost pride for his cousin and best friend Christian:</span></p>
<p><img src="http://nicolasbize.com/blog/images/noah_4.jpg" alt="" width="800" height="600"></p>
<p><span>…after which he proceeded to easily explain him&nbsp;</span><span><b>how</b></span><span>&nbsp;it worked and what the code was doing!</span></p>
<p><img src="http://nicolasbize.com/blog/images/noah_5.jpg" alt="" width="800" height="600"></p>
<p><span>And so it was that in a single hour, my 7 year old was able to not only write his first text game, but also to experience the fun and thrill that comes from creating, compiling and executing his own little program. Bonus points, it all fit on a single notebook page:</span></p>
<p><img src="http://nicolasbize.com/blog/images/noah_2.jpg" alt="" width="600" height="800"></p>
<p><span>I was so glad that he was able to understand why I keep saying that I have the best job in the world.&nbsp;</span><span>My only regret today was to realize that in more than 30 years, we have not been able to come up with something&nbsp;better for our kids: Qbasic has a limited set of simple keywords (the entire help fits on a single F1 screen and is packed with simple examples!), does not distract the coder with any visual artifacts, has a very confined and cosy dev environment, shows errors as early as possible, compiles and executes the code in a heartbeat with a single key, and is extremely straightforward. &nbsp;We have built more robust and more complex languages/frameworks/IDEs (which are of course necessary for any real-life application), but we have never really made a simpler or more direct access to the thrill of programming than QBasic. Even running QBasic today has become dreadful&nbsp;to the novice that uses&nbsp;a modern Mac/PC/Linux machine, whereas it used to simply require inserting a 3,5” floppy in the A:\ disk drive…</span></p>
<p><span>Enough rant, today is all about the celebration of yet another person who discovered the excitement and beauty of programming!</span></p>
<p><span>Cheers!</span></p>
<p><span>(as promised, <a href="http://nicolasbize.com/ld34/">my AAA title</a> for which I await&nbsp;EA’s call to purchase copyrights)</span></p>
			</div></div>]]>
            </description>
            <link>http://www.nicolasbize.com/blog/30-years-later-qbasic-is-still-the-best/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25239424</guid>
            <pubDate>Sat, 28 Nov 2020 18:32:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Machine Learning for Art with Google’s Emil Wallner]]>
            </title>
            <description>
<![CDATA[
Score 22 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25239217">thread link</a>) | @andreyk
<br/>
November 28, 2020 | https://www.letstalkai.show/e/mlart-interview/ | <a href="https://web.archive.org/web/*/https://www.letstalkai.show/e/mlart-interview/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
	<div>


		
			<div id="post-15958234">
				<p><a href="https://www.letstalkai.show/">
										<img src="https://pbcdn1.podbean.com/imglogo/image-logo/7703921/Lets_Talk_Logo.jpg"></a></p><div>
				<div>
					
					<p>Nov 27th, 2020 by <a title="Posts by Skynet Today">Skynet Today</a> </p>
				</div>

				<div>
					 <div>
<p>An interview with <span>Emil Wallner, the creator of mlart.co . Emil is an internet-educated, independent machine learning researcher, and resident at the Google Arts &amp; Culture Lab. As a resident at Google he is using machine learning to explore art and culture. Part-time, he applies machine learning to logical tasks such as programming and mathematics.</span></p>
<p>Subscribe: <a href="https://feed.podbean.com/aitalk/feed.xml">RSS</a> | <a href="https://podcasts.apple.com/us/podcast/lets-talk-ai/id1502782720">iTunes</a> | <a href="https://open.spotify.com/show/17HiNdxcoKJLLNibIAyUch">Spotify</a> | <a href="https://www.youtube.com/channel/UCKARTq-t5SPMzwtft8FWwnA">YouTube</a></p>
<div>
<p>Check out coverage of similar topics at <a href="http://www.skynettoday.com/">www.skynettoday.com</a></p>
<p>Theme: Deliberate Thought Kevin MacLeod (incompetech.com)</p>
</div>
</div>
									</div>

				

   <p><span id="postbar_15958234"> <span> | </span><a href="https://www.podbean.com/site/EpisodeDownload/PBF380DAKYNN9" target="_blank">Download</a> </span></p>			</div>

		


	</div>
</div>
</div></div>]]>
            </description>
            <link>https://www.letstalkai.show/e/mlart-interview/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25239217</guid>
            <pubDate>Sat, 28 Nov 2020 18:08:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Apple Silicon M1: A Developer's Perspective]]>
            </title>
            <description>
<![CDATA[
Score 361 | Comments 438 (<a href="https://news.ycombinator.com/item?id=25238608">thread link</a>) | @steipete
<br/>
November 28, 2020 | https://steipete.com/posts/apple-silicon-m1-a-developer-perspective/ | <a href="https://web.archive.org/web/*/https://steipete.com/posts/apple-silicon-m1-a-developer-perspective/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div> <p><img src="https://d33wubrfki0l68.cloudfront.net/7dbf04694dfeeec9985b2ebb27cc1faff153111b/75e93/assets/img/2020/m1/m1.jpg"></p><p>The excitement around Apple’s new M1 chip is <a href="https://www.singhkays.com/blog/apple-silicon-m1-black-magic/">everywhere</a>. I bought a MacBook Air 16GB M1 to see how viable it is as main development machine - here’s an early report after a week of testing.</p><h2 id="xcode">Xcode</h2><p>Xcode runs FAST on the M1. Compiling the <a href="https://pspdfkit.com/">PSPDFKit PDF SDK</a> (debug, arm64) can almost compete with the fastest Intel-based MacBook Pro Apple offers to date, with <a href="https://twitter.com/steipete/status/1332052251712614405?s=21">8:49 min vs 7:31 min</a>. For comparison, my Hackintosh builds the same in less than 5 minutes.</p><p>One can’t overstate how impressive this is for a fan-less machine. Apple’s last experiment with fan-less MacBooks was the 12-inch version from 2017, which builds the same project in 41 minutes.</p><p>Our tests mostly ran just fine, although I found <a href="https://github.com/Aloshi/dukglue/pull/27">a bug specific to arm64</a> that we missed before, as we don’t run our tests on actual hardware on CI. Moving the Simulator to the same architecture as shipping devices will be beneficial and will help find more bugs.</p><p>Testing iOS below 14 is problematic. It seems <a href="https://twitter.com/steipete/status/1332654247809257473?s=21">WebKit is crashing in a memory allocator</a>, throwing EXC_BAD_INSTRUCTION (code=EXC_I386_INVOP, subcode=0x0) (Apple folks: FB8920323). Performance also seems really bad, with Xcode periodically <a href="https://twitter.com/steipete/status/1332348616145563653?s=21">freezing</a> and the whole system becoming so <a href="https://twitter.com/steipete/status/1332648748158246922?s=21">slow</a> that the mouse cursor gets choppy. Some Simulators even make problems on iOS 14, <a href="https://twitter.com/steipete/status/1331628274783543297?s=21">such as the iPad Air (4th gen) which still emulates Intel</a>, so try to avoid that one.</p><p>We were extremely excited to be moving our CI to Mac Mini’s with M1 chip and are <a href="https://www.macstadium.com/m1-mini">waiting on MacStadium to release devices</a>, however it seems we will have to restrict tests to iOS 14 for that to work. With our current schedule, we plan to drop iOS 12 in Q3 2021 and iOS 13 in Q3 2022, so it will be a while until we can fully move to Apple Silicon.</p><p>There is a chance that Apple fixes these issues, however it’s not something to count on - given that this only affects older versions of iOS, the problem will at some point just “go away”.</p><p><strong>Update:</strong> We’re working around the WebKit crashes for now via detecting Rosetta2 translation at runtime and simply skipping the tests where WebKit is used. This isn’t great, but luckily we’re not using WebKit a lot in our current project. <a href="https://gist.github.com/steipete/e15b1fabffc7da7d49c92e3fbd06971a">See my Gist for details</a>. Performance seems acceptable if you restrict parallel testing to at most two instances - else the system simply runs out of RAM and swapping is just really slow.</p><h2 id="docker">Docker</h2><p>We use Docker to automate our Website and load environments for our <a href="https://pspdfkit.com/pdf-sdk/web/">Web and Server PDF SDKs</a>. Docker posted a <a href="https://www.docker.com/blog/apple-silicon-m1-chips-and-docker/">status update blog post</a> about the current state of things, admitting that it currently won’t work but that they’re <a href="https://github.com/docker/roadmap/issues/142">working on it</a>. There are more <a href="https://finestructure.co/blog/2020/11/27/running-docker-on-apple-silicon-m1-follow-up">hacky ways to use Apple’s Hypervisor to run Docker container manually</a>, however this needs arm-based containers.</p><p>I expect a solution in Q1 2021 that runs arm-based containers. We’ll have to do some work to add arm-support (something already on the roadmap) so this is only a transitional issue.</p><h2 id="virtualization-and-windows">Virtualization and Windows</h2><p>To test our <a href="https://pspdfkit.com/pdf-sdk/windows/">Windows PDF SDK</a>, most folks are using a VMware virtual machine with Windows 10 and Visual Studio. Currently none of the Mac virtualisation solutions support Apple Silicon, however both <a href="https://appleinsider.com/articles/20/11/11/parallels-confirms-apple-m1-support-amid-silence-from-other-virtualization-companies">VMware and Parallels</a> are working on it. I do not expect Virtualbox to be updated <a href="https://forums.virtualbox.org/viewtopic.php?f=8&amp;t=98742">anytime soon</a>.</p><p>I expect that eventually we’ll be able to run ARM-based Windows with commercial tooling. Various <a href="https://9to5mac.com/2020/11/27/arm-windows-virtualization-m1-mac/">proof-of-concepts</a> already exist, and performance seems <a href="https://twitter.com/imbushuo/status/1332772957609922561?s=21">extremely promising</a>. Microsoft currently doesn’t sell ARM-based Windows, so getting a license will be interesting.</p><p>ARM-Windows can emulate x86 applications, and Microsoft is working on <a href="https://www.neowin.net/news/it039s-official-x64-emulation-is-coming-to-windows-on-arm">x64 emulation</a>, which is already rolling out in Insider builds. In a few months, it should be possible to develop and test our Windows SDK with Visual Studio on M1 in reasonable performance.</p><p>Running older versions of macOS might be more problematic. We currently support macOS 10.14 with our <a href="https://pspdfkit.com/blog/2017/pspdfkit-for-macos/">AppKit PDF SDK</a> and macOS 10.15 with the <a href="https://pspdfkit.com/blog/2019/pspdfkit-for-mac-catalyst/">Catalyst PDF SDK</a>, both OS releases that require testing. It remains to be seen if VMWare or Parallels include a complete x64 emulation layer. This would likely be really slow, so I wouldn’t count on it.</p><p><img src="https://d33wubrfki0l68.cloudfront.net/bbf100981357e4bc26c49722d31253daf76d293d/5b456/assets/img/2020/m1/memory.png" alt=""></p><p>Lastly, 16 GB RAM just isn’t a lot. When running parallel tests, the machine starts to heavily swap and performance really goes down the drain. This will be even more problematic with virtual machines running. Future machines will offer 32 GB options to alleviate this issue.</p><p><strong>Update:</strong> <a href="https://gist.github.com/niw/e4313b9c14e968764a52375da41b4278#file-readme-md">How to run Windows 10 on ARM in Qemu with Hypervisor.framework patches on Apple Silicon Mac</a></p><h2 id="android-studio">Android Studio</h2><p>IntelliJ is working on porting the <a href="https://youtrack.jetbrains.com/issue/JBR-2526">JetBrains Runtime</a> to Apple Silicon. The apps currently work through Rosetta 2, however building via Gradle is <a href="https://www.reddit.com/r/androiddev/comments/jx4ntt/apple_macbook_air_m1_is_very_slow_in_gradle_builds/">extremely slow</a>. Gradle creates code at runtime, which seems a particular bad combination with the Rosetta 2 ahead-of-time translation logic.</p><p>I expect that most issues will be solved by Q1 2021, however it will likely be some more time until all Java versions run great on ARM. A lot of effort has been put into <a href="https://bell-sw.com/java/arm/performance/2019/01/15/the-status-of-java-on-arm/">loop unrolling and vectorisation</a>, not everything there is available on ARM just yet.</p><p><strong>Update:</strong> <a href="https://www.azul.com/press_release/azul-announces-support-of-java-builds-of-openjdk-for-apple-silicon/">Azul offers macOS JDKs for arm64</a>, including for <a href="https://www.azul.com/downloads/zulu-community/?os=macos&amp;architecture=arm-64-bit&amp;package=jdk">Java 8</a>.</p><h2 id="homebrew">Homebrew</h2><p><a href="https://brew.sh/">Homebrew</a> currently works via Rosetta 2. Just prefix everything with <code>arch -x86_64</code> and it’ll just work. It is possible to install an additional (arm-based) version of Homebrew <a href="https://soffes.blog/homebrew-on-apple-silicon">under <code>/opt/homebrew</code></a> and mix setup, as <a href="https://github.com/Homebrew/brew/issues/7857">more and more software</a> is adding support for arm.</p><p>This is not a problem currently (performance is good) and will eventually just work natively.</p><h2 id="applications">Applications</h2><p>Most applications just work, Rosetta is barely noticeable. Larger apps to take a longer initial performance hit (e.g. Microsoft Word takes <a href="https://www.zdnet.com/article/microsoft-office-will-be-about-20-second-slower-initially-on-apple-silicon-rosetta-2/">around 20 seconds</a> until everything is translated), but then these binaries are cached and subsequent runs are fast.</p><p>There’s the occasional app that can’t be translated and fails on startup (e.g. <a href="https://beamer-app.com/download">Beamer</a> or the <a href="https://www.google.com/intl/en_gh/drive/download/">Google Drive “Backup and Sync” client</a>), but this is rare. Some apps are confused about their place on disk and ask to be moved to the Applications directory, when really it’s just the translated binary that runs somewhere else. Most of these dialogs can be ignored. Some apps (e.g. Visual Studio Code) <a href="https://twitter.com/steipete/status/1331884524934995968?s=21">block auto-updating</a> as the translated app location is readonly. However, in case of VS Code, the Insider build is already updated to ARM and just works.</p><p>Electron-based apps are slow if they run on Rosetta. It seems the highly optimized V8 JavaScript compiler blocks ahead-of-time translation. The latest stable version of Electron (Version 11) already <a href="https://www.electronjs.org/blog/apple-silicon">fully supports Apple Silicon</a>, and companies like Slack already updated their beta version to run natively.</p><p>Google just shipped <a href="https://www.macworld.com/article/3597749/google-releases-chrome-87-with-support-for-apple-silicon-macs.html">Chrome that runs on ARM</a>, however there’s still quite a performance gap between it and Apple Safari, which just <em>flies</em> on Apple Silicon.</p><h2 id="conclusion">Conclusion</h2><p>The new M1 MacBooks are fast, beautiful and silent and the hype is absolutely justified. There’s still a lot to do on the software-front to catch up, and the bugs around older iOS Simulators are especially problematic.</p><p>All of that can be fixed in software and the whole industry is currently working on making the experience better, so by next year, when Apple updates the 16-inch MacBook Pro and releases the next generation of their M chip line, it should be absolutely possible to use a M1 Mac as main dev machine.</p><p>For the time being, the M1 will be my <del>travel</del> secondary laptop, and I’ll keep working on the 2,4 GHz 16-inch MacBook Pro with 32 GB RAM, which just is the faster machine. I’ll be much harder to accept the loud, always-on fans though, now that I know what soon will be possible.</p></div></div>]]>
            </description>
            <link>https://steipete.com/posts/apple-silicon-m1-a-developer-perspective/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25238608</guid>
            <pubDate>Sat, 28 Nov 2020 16:47:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[No Config for Old Men]]>
            </title>
            <description>
<![CDATA[
Score 261 | Comments 215 (<a href="https://news.ycombinator.com/item?id=25238523">thread link</a>) | @zdw
<br/>
November 28, 2020 | https://datagubbe.se/noconf/ | <a href="https://web.archive.org/web/*/https://datagubbe.se/noconf/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>


<p><b>...or anyone else, for that matter.</b></p>

<p><i>Autumn 2020</i></p>

<p>Ask anyone who's really into cooking and they'll tell you how important it is to have a kitchen that's arranged just right. To someone who rarely cooks, a kitchen is probably just a place to store a few pots and a toaster, and the placement of such stuff doesn't matter much: canned soup and microwave dinners are designed for ease of preparation.</p>


<p>For the enthusiastic home cook, however, a lot of things can go wrong. Often there's only a second's notice to fix something that might ruin a perfect meal or set you back hours of hard toil. Hollandaise starting to split? Better bring out that ice cold water post haste! Garlic burning? Better chop some more right this instant, or the pasta will be overcooked and there goes the Aglio e Oglio.</p>


<p>To achieve speed, you have to know where your knives, pots, pans, spoons, whisks and other utensils are and you want to be able to arrange them so that they're easy to reach. Seasonings, spices, herbs and condiments should be within reach from the stove. Then there's the mise en place before the actual cooking begins: chopping all the vegetables, cubing the meat, slicing the bacon and so on.</p>


<p>All of this is, thankfully, easy to achieve. Even the most cramped kitchen will, after having been battle tested through a few meals, be as optimal as possible according to the cook's personal preference. The same goes for painters, carpenters, car mechanics and even office dwellers. Hammer missing from the hammer hook? For shame! Stapler not to the immediate right of the stack of post-its? Well it should be!</p>


<h3>The regulated kitchen</h3>


<p>Now imagine if you couldn't organize your kitchen to your heart's content. Not because you're lacking the funds or skills, but because some federally appointed clerk is constantly coming to inspect it.</p>


<p>"Nah," he says, adjusting his clip-on tie, "you can't put your spices there. Against regulations. All spices must be kept more than two yards from the stove at all times." He then goes on to explain that you'll have to call him every time you want to use the stove, just to make sure the pots you're using are compliance tested. Plus, they have to be stored in the government approved pot storage cabinet below the sink, otherwise they're not fit for kitchen use.</p>


<p>Want to change the color of the counter top? Sorry, no can do. Want to switch from glass bowls to stainless? Alas, you used to be able a few years ago, but nobody wants stainless anymore anyway, right? The salt <i>can</i> be put next to the stove, but it's not recommended and might change in the near future. Knives are now to be honed every Tuesday afternoon by a designated craftsman. Sure, you can postpone a few times, but eventually, you just have to live with that. Plus, there's going to be some dudes coming to inventory your pantry on a regular basis, most likely when you're in the middle of cooking something really complicated. There's no use in protesting - this is all for your own good.</p>

<p>And yes.


</p><p>Of course this is a metaphor for computers.</p>


<h3>The curious disappearance of configuration</h3>


<p>For the casual user, some of this can <i>maybe</i> be convenient - or at least not annoying. If someone who rarely uses the kitchen has decided to whip up a home cooked feast, it doesn't matter that the spices are kept strangely far from the stove: they're just happy they found them. And <i>maybe</i> there is, for the casual user, some "security" in lock-in efforts such as MacOS calling home<sup><a href="#footnote1">[1]</a></sup> to check if a program is allowed to run and that web browsers automatically block certain URLs.</p>


<p>Likewise, maybe a handful of confused beginners are helped by the fact that certain system settings are extremely hard to find, or that you're supposed to put all your photos in a specific directory, or that you can't decide what partition you want to install a program on, or that some indexing service starts running when you least expect it, or that not a single application gives a crap about the few color settings you're allowed to make.</p>


<p>For the power user, such things range from nuisances to something that seriously hampers productivity and creativity.</p>


<p>It used to be that whenever I got a new computer, I spent a day or two setting it up. I selected the fonts I wanted to use, I picked the colors I liked for window decorations and GUI elements, I installed my preferred tools and utilities and I organized the desktop icons and program launchers to my liking. It took a bit of time, but it was a labor of love. In times of trouble I was, if nothing else, at least the boss of my own desktop environment.</p>


<p>I don't know of any proprietary OS where I can do that anymore. Linux is, considering what's going on with the major distributions, desktop environments and UI toolkits, seemingly heading the same way. Sure, pick your own window manager, see if we care - we've got client side decorations! Want to theme your GUI? Yeah, but not in our Snap packages you won't! Want to turn off cursor blinking? Mmmmyyeeaahhh, not too sure about that. Oh, you started a GUI file manager? Hey, enjoy the ten new folders we've littered your home directory with! They all start with capital letters: designed for typing convenience in a case sensitive file system.</p>


<p>Of course I still spend a fair amount of time setting up a Windows machine, but these days it's not the joyful experience of configuring the best fonts and nicest colors and arranging the icons on the start menu in the correct order for my muscle memory. Instead it's usually a week of swearing over removed settings and working hard to find the ones that actually remain, or trying various registry hacks to circumvent seemingly unchangeable defaults. I'm working against the system instead of with it, and someone else is trying to boss me around.</p>


<h3>A better example</h3>


<p>All of this could be different. It used to be. On my <a href="https://datagubbe.se/ltmag/">Amiga</a>, I could configure <i>everything</i>. Apart from things like fonts and colors I could draw my own mouse pointer, tiling desktop backgrounds and icons. (Yes, the system really shipped with separate little paint programs just for pointers, desktop tiles and icons.) I could customize double click speed and key repeat rates on millisecond levels. I could even control the exact position of individual icons and the size and position of every individual directory window opened.</p>


<p>Most casual users didn't care about all that, but they didn't have to. The system came with a reasonable set of defaults and when or if they grew more proficient and wanted to change something about their daily working environment, they had the option to do so.</p>


<p>This was a great approach to users. Instead of being treated like an incompetent moron and placed in a walled garden, you were entrusted and empowered. Something as simple as drawing my own mouse pointer on the Amiga was a profound and formative experience for me. As corny as it sounds, it was as if the guys who built this amazing machine put it in my hands and said, "Hey kid, you're in charge. This computer is yours. Learn how to use it and you can make it do anything." It was a call for exploration and creativity.</p>


<p>Today, I can't even change the system font in Windows. I can select an "accent color", but most applications completely ignore it. Every program defaults to downloading into a Downloads folder and I've lost count of how many times I've changed its folder view from grouped to not grouped, only to discover it's been magically changed back the next time I browse it. Lots of settings have been removed completely while others are buried deep in strange places where a user clearly isn't really supposed to venture.</p>


<p>The problem is that there's no toggle for enabling "advanced mode". I'm just supposed to accept that I can no longer change simple things I've been able to configure for the past thirty years. Someone, somewhere just decided that all users have the same basic skill level and that the defaults are always acceptable.</p>


<h3>General purpose Instagram cameras</h3>


<p>I suppose the lack of configurability is a metaphor for personal computing in general: we're not buying our machines, we're renting them by way of bizarrely complex EULA:s for everything from the firmware to the OS and we're not supposed to be curious or creative, we're supposed to sit back and passively consume advertisements. The base level of creative computer use is no longer exploring programming or graphics or music, but photographing a meal someone else has prepared and then applying a predefined sepia filter to said photo. The base level of configuring a system is no longer picking some personal favorites among fonts and colors, but - maybe - selecting between dark and light mode.</p>


<p>
On the flip side, more and more people also need to use computers 
for actually producing stuff - not least programming all those ad 
delivery platforms and the curiously unconfigurable operating systems 
they run on. But there are also armies of innocents; office workers,
administrators, hotel clerks, librarians, teachers - those people now often 
have no choice but to strain their eyes staring at black text on bright 
white backgrounds, unable to select a font they find easier to read.
</p>

<p>Too bad they can no longer store their spices close to the stove, but hey, who cares? Let them take one for the team. We're all swimming in ad revenue and if people learn to configure things, maybe they'll suddenly realize that the presence of those ads should be configurable as well.</p>

<br>

<hr>



<p id="footnote1">
<sup>1</sup> In case my sarcasm isn't coming through here: No, it's not secure. The privacy and security problems this entails are huge.
</p>

</div></div>]]>
            </description>
            <link>https://datagubbe.se/noconf/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25238523</guid>
            <pubDate>Sat, 28 Nov 2020 16:35:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Is Probability Real?]]>
            </title>
            <description>
<![CDATA[
Score 192 | Comments 168 (<a href="https://news.ycombinator.com/item?id=25237356">thread link</a>) | @EbTech
<br/>
November 28, 2020 | https://www.arameb.com/blog/2020/11/22/probability | <a href="https://web.archive.org/web/*/https://www.arameb.com/blog/2020/11/22/probability">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p>Today, I want to address an issue with statements involving chance. To demonstrate, let’s first consider a statement that doesn’t involve chance:</p>

<p>“<em>A cubic die tossed onto a flat surface will come to rest on one of its six sides.</em>”</p>

<p>This claim can be empirically tested, with various dice and surfaces. If any one of our experiments results in the die spinning endlessly on a corner, we will have disproven the claim. We may have to refine the claim’s conditions; for instance, by requiring the presence of gravity. Nonetheless, it’s fairly clear what it means for the statement to be true or false. Now let’s try to make a claim involving probability:</p>

<p>“<em>If a pair of standard dice are thrown, the probability of their face-up sides summing to nine will be one in nine (about 0.11 or 11%).</em>”</p>

<p>What does it mean for this statement to be true? Unlike the first statement, this one doesn’t specify which result we’ll actually see. How can we possibly hope to test it, or to make use of its information?</p>



<p>Within the realm of abstract mathematics, we’re free to model probability in a way that fits our intuitions. Imagine a multiverse containing an infinity of possible worlds, whose total <em>measure</em> is 100%. Define the probability of an <em>event</em>, such as that of rolling a nine, to be the measure assigned to the subset of worlds in which the event actually occurs.</p>

<p>In the abstract formalism, we’re allowed to assign the measure however we like, subject to Kolmogorov’s axioms: the measure must be non-negative, countably additive, and total to 100%. By respecting the symmetry of an idealized die,<sup id="fnref:1" role="doc-noteref"><a href="#fn:1">1</a></sup> we might argue that only one such assignment makes sense; from it, we can calculate the probability of any event involving dice rolls.</p>

<p>There are two shortcomings to this approach. Firstly, we won’t always deal with nicely symmetrical objects for which direct a priori arguments are possible. Thus, we still need a means of testing probabilistic claims using real-life observations. Secondly, such arguments can never be airtight: after all, how can we hope to infer the measure on a hypothetical multiverse, when we only ever experience <em>one</em> world? Indeed, a realist might question if it makes any sense to discuss the chances of an event happening: either it happens or it doesn’t!</p>



<p>You might be more trusting of someone who puts their money where their mouth is. To back up a definite claim, not involving chance, I can simply agree to pay a penalty if it turns out I’m wrong.</p>

<p>This idea can be extended to probabilistic claims in the following manner: consider a lottery that pays a $90 jackpot if the next roll of a pair of dice yields a nine. If the maximum that I’m willing to pay to play is $10, this indicates that I believe a not-nine roll is eight times more likely than a nine roll. This approach is appealing because, after all, the <em>raison d’être</em> of probability theory is to explain the decision-making of individuals facing uncertainty.</p>

<p>If another gambler’s view conflicts with mine, you may aggregate our beliefs by creating a market on which we buy and sell predictions. Consider a contract that pays $100 (plus interest) when a specified event occurs. Its price on the market can be interpreted as the percentage probability of that event. Thus, to say an event is twice as “likely” as another, simply means its market price is double.</p>

<p>Unlike your typical gambler, a frictionless market offers transparent near-identical buy and sell prices. As a result, any violations of Kolmogorov’s axioms become money-making arbitrage opportunities. Arbitrage activity acts as an enforcer of the axioms, creating what economists call the <em>risk-neutral probability measure</em>.</p>

<p>In real markets, however, this probability measure exhibits several inconsistenties. Firstly, it depends on which currency is used: as an extreme example, we wouldn’t buy a dollar-denominated wager that only pays out if the dollar collapses, no matter how likely we imagine the collapse to be. Secondly, this measure is sensitive to (non-diversifiable) risk: if a widely-believed prophecy held that rolling a nine would induce a catastrophic famine, the market would value this outcome a lot more, because everyone wants to buy insurance against such a catastrophe. Thirdly, markets can be misinformed: indeed, one motivation for participating in a market is to try to beat it! And finally, liquid markets are hard to set up.</p>

<p>For these reasons, we abandon this approach. We’ll seek to define probability in terms of actual outcomes instead of human bets. Nonetheless, human bets are what inspired the creation of probability theory: it’s hard to think of any other practical application! Therefore, we should remember to revisit the matter once we’ve found an appealing probability concept. Ultimately, we must be able to explain <em>how</em> individuals and markets behave with respect to our concept, and answer <em>why</em> they should care about it at all.</p>

<p>These questions are incredibly subtle: the theory of evolution by natural selection tells us that individuals are wired to use strategies that enabled their ancestors’ survival; however, the nature of probabilistic beliefs is that a wide range of outcomes are plausible. Indeed, while a coin will always land heads or tails, it’s considered unwise to bet your life savings on either heads or tails. Intuitively speaking, the rationale is that you’re almost certain to lose <em>eventually</em>, if you keep playing this way. This idea of repeated trials inspires our next interpretation, which happens to be the most popular among scientists.</p>



<p>According to the frequentist school of thought, a probabilistic statement is not to be taken literally. Although it refers to a single event, the statement should be taken as shorthand for a claim involving a very large collection of similar events. Imagine rolling the dice over and over. The probabilistic claim that we started with is converted into the following:</p>

<p>“<em>If a pair of standard dice are thrown repeatedly, then in the limit as the number of throws goes to infinity, the proportion of nines converges to one in nine (about 0.11 or 11%).</em>”</p>

<p>The short-run probability is replaced by a long-run proportion. Given an infinite sequence of rolls, this statement unambiguously reveals itself to be true or false. In light of the frequentist interpretation, we can even make more sense of our earlier interpretations. While we only experience one world, repeating an experiment under similar conditions is like observing the experiment in a parallel universe: whether we count trials or worlds, the math is virtually identical. In the limit of infinitely many bets, we can make some unambiguous conclusions about the quality of a gambler’s strategy, too: this is how casinos ensure that the house always wins!</p>

<p>Testing our claim is a simple matter: we roll the dice, over and over, and over and over… infinity times. Oops. Of course, there is no such thing as an experiment with infinity trials. Our arms will get tired, the dice will wear out, the Sun will explode, and all the free energy in the universe will be consumed. At best, we can do a very large number of trials. Let’s say we roll dice 9,000 times; one in nine of these would be 1,000. Perhaps we won’t roll exactly 1,000 nines, so let’s interpret our claim with a suitable margin of error, called a <em>confidence interval</em>:</p>

<p>“<em>If a pair of standard dice are thrown 9,000 times, then the face-up sides will sum to nine for between 920 and 1,080 of the throws.</em>”</p>

<p>The probability of obtaining between 920 and 1,080 nines can be calculated to be 99.3%.<sup id="fnref:2" role="doc-noteref"><a href="#fn:2">2</a></sup> Thus, we’ve turned a probabilitic statement into a much more certain but still probabilistic statement. If we observe 1,100 nines, we should be able to dismiss the probabilistic claim as false. And yet, if every household on Earth were to independently perform this 9,000-throw experiment, we should expect that a great many of their results would fall outside the confidence interval. They would disagree on the truth of our statement!</p>

<p>There’s no getting around it: despite its intuitive appeal, the frequentist definition of probability is circular, reducing probability claims to probability claims.<sup id="fnref:3" role="doc-noteref"><a href="#fn:3">3</a></sup> To end the cycle, the frequentist chooses a threshold (say, 99%) beyond which to treat events as objective truths. This grants the claim an empirically observable meaning. And yet, the frequentist must take care not to consider too many such events, for otherwise the probability of <em>at least one</em> of the events failing may ALSO exceed the threshold of certainty: a logical contradiction.</p>

<p>Things only work out nicely in the limit of infinite sample size. Statisticians mainly deal with experiments which can be repeated so many times that, for most practical purposes, their conclusions can be treated as definite. Non-philosophers are usually happy to ignore a sub-1% chance of error; and if that’s not good enough, make it 0.0001%! Confidence can be increased by gathering more data, i.e., increasing the sample size.</p>

<p>This approach turns out to be very powerful. By designing more complex hypotheses in which probabilities vary as a function of context variables, even some phenomena that aren’t easily repeatable can be statistically analyzed. For example, weather forecasts are based on well-tested models that use measurements of variables such as temperature, pressure, humidity, and wind.</p>

<p>On the other hand, statistical models of sports games, democratic elections, or company stocks tend to be less testable: the interactions are very complex and there are too few outcomes from which to extrapolate. Similarly, when you try to predict which colleges will admit you or which of your friends will start a business, you don’t make your case using repeatable tests. Clearly, the frequentist interpretation cannot apply. One may argue that no conclusions in these cases would hold up to a scientific standard; nonetheless, if we seek a theory of decision-making under uncertainty, there’s no …</p></div></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.arameb.com/blog/2020/11/22/probability">https://www.arameb.com/blog/2020/11/22/probability</a></em></p>]]>
            </description>
            <link>https://www.arameb.com/blog/2020/11/22/probability</link>
            <guid isPermaLink="false">hacker-news-small-sites-25237356</guid>
            <pubDate>Sat, 28 Nov 2020 13:23:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Always leave the code better than you found it]]>
            </title>
            <description>
<![CDATA[
Score 47 | Comments 70 (<a href="https://news.ycombinator.com/item?id=25237341">thread link</a>) | @hans1729
<br/>
November 28, 2020 | https://letterstoanewdeveloper.com/2020/11/23/always-leave-the-code-better-than-you-found-it/ | <a href="https://web.archive.org/web/*/https://letterstoanewdeveloper.com/2020/11/23/always-leave-the-code-better-than-you-found-it/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<p>Dear new developer,</p>



<p>I’ve spent a lot of my time maintaining working code. I think that is more typical of software developers than working in greenfield development. Yes, there are definitely jobs where you are writing more new code than maintaining, upgrading, bug fixing and improving old code (startups without product market fit being one, consulting being another) but in general code is expensive and folks want to run it for a long time. </p>



<p>Often you’ll jump into code to fix a bug, investigate an issue or answer a question.</p>



<p>When you do so, improve it. This doesn’t mean you rewrite it, or upgrade all the libraries it depends on, or rename all the variables. </p>



<p>You don’t need to transform it. </p>



<p>But you should make it better. Just clean it up a bit. Doing so makes everyone’s lives just a bit better, helps the codebase in a sustainable way, and assists the business by making its supporting infrastructure more flexible.</p>



<p>What are some ways to improve the code when you are in it?</p>



<p><strong>Document</strong></p>



<p>Whether that is a comment that explains something tricky, a larger piece of documentation external to the code which explains how to interact with it, or fixing a typo, trustworthy documentation is key to interacting with code. This is a good way to start improving a codebase because it has minimal impact on the actual code. Therefore it is low risk. But if you’ve ever had a great comment explain a confusing bit of code, you’ll appreciate the time this effort can save.</p>



<p>You can also help documentation by removing old, crufty docs. If you see a comment that doesn’t apply, remove it. If there’s cut and paste documentation which doesn’t apply, get rid of it. That cleans up the code for the next person to come along (who might be you).</p>



<p><strong>Write a test or improve a test</strong> </p>



<p>Tests help you write maintainable, extensible code that others can change fearlessly. If you run across code that isn’t tested and you have time and the supporting framework to write one, do so. </p>



<p>Even if it tests simple functionality such as “can I instantiate this object” or “how does this function react when I pass it two null values”, an additional test will help the robustness of the code. </p>



<p><strong>Refactor it</strong></p>



<p>This is one of the most flexible improvements. Refactoring code can range from renaming a variable to be more true to its nature to an overhaul of an entire module. Start small and don’t get wrapped up in perfection. Make the code clearer in intent. </p>



<p>It’s easy with refactoring to get wound around an axle and make too many changes and end up with broken things. Timeboxing is one technique I use to avoid, or at least minimize, my tendencies toward this when refactoring. If all I have is 30 minutes, I’ll make my changes smaller in scope.</p>



<p>A warning about refactoring. Don’t refactor what you don’t understand. Don’t drive by refactor. Discuss your plan with someone more familiar with the code; <code>git blame</code> is your friend. Especially if the code is not well tested, you want to make sure you don’t do more harm than good.</p>



<p><strong>Upgrade a dependency</strong></p>



<p>It’s sometimes a winding path, but upgrading your dependencies regularly is a good way to maintain the code. I remember working in a fork of struts. It was an important application for the company, but we didn’t spend the time upgrading the dependencies, because it was too painful. Eventually, parts of the code became harder to update. The entire application couldn’t benefit from newer technologies and paradigms because of the older dependencies holding it back. </p>



<p>It never feels good to spend time updating a dependency; to me this always feels like running in place. But if you don’t do so, eventually dependencies will end of life and you’ll be forced to update. That’ll be even less pleasant. </p>



<p><strong>How to do it</strong></p>



<p><em>Based on feedback (<a href="https://www.reddit.com/r/programming/comments/k2cbtb/always_leave_the_code_better_than_you_found_it/gdv0kg9/?utm_source=reddit&amp;utm_medium=web2x&amp;context=3">this comment</a>, among others), I added this section on Nov 28.</em></p>



<p>When you are making these changes to improve the code, you’ll help out code reviewers and your future self by making changes that are improving the code separate from changes that add functionality. Whether you do this in separate pull requests, tickets, or commits depends on your team culture. Ask about that. But such separation will make it easier for people who aren’t familiar with the changes to understand them and give feedback on them, whether that is a code review this week or someone reviewing this component two years from now.</p>



<p><strong>Why do it</strong></p>



<p>All of these actions not only help others because they improve the quality of the code, they also provide examples to other developers on how to do so. For example, it is far easier to write the second test in a suite than the first. You can cut and paste a lot of the setup code and tweak only what is different. The first bit of documentation will inspire more.</p>



<p>Code isn’t everything, but it is an important work output. Whenever you touch it, you should strive to leave it in a better place that it was before you did so.</p>



<p>Sincerely,</p>



<p>Dan</p>
	</div></div>]]>
            </description>
            <link>https://letterstoanewdeveloper.com/2020/11/23/always-leave-the-code-better-than-you-found-it/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25237341</guid>
            <pubDate>Sat, 28 Nov 2020 13:19:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What were these Roman objects used for?]]>
            </title>
            <description>
<![CDATA[
Score 52 | Comments 37 (<a href="https://news.ycombinator.com/item?id=25237271">thread link</a>) | @jd115
<br/>
November 28, 2020 | http://www.celticnz.co.nz/Dodecahedron/Decoding%20the%20Druidic%20Dodecahedron1.html | <a href="https://web.archive.org/web/*/http://www.celticnz.co.nz/Dodecahedron/Decoding%20the%20Druidic%20Dodecahedron1.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
<p><strong>DECODING THE DRUIDIC DODECAHEDRON </strong></p>

<p><img src="http://www.celticnz.co.nz/OrgImages/Dodecahedron/Dodecahedron%20Types.jpg" width="900" height="438"></p>
<p><strong>These bronze artefacts are so-called <em>Roman</em> dodecahedra (plural of dodecahedron)  of which about 120 have been found in the Celtic countries of Europe. Strangely, none of these have been found in Italy, home turf of the Romans.</strong> <strong>To the left is seen a dodecahedron from the Römermuseum Schwarzenacker, Homburg, Germany collection. To the right is seen another pristine example from the Hunt Museum in Limerick Ireland </strong></p>

<p><img src="http://www.celticnz.co.nz/OrgImages/Dodecahedron/Dodecahedron%20Types3.jpg" width="935" height="438"></p>
<p><strong>To the left is a dodecahedron from Archaeological  Service Canton Aargau, Brugg, Switzerland (Vindonissa Museum). To the right is a dodecahedron from the Gallo-Roman Museum, Tongeren, Belgium. </strong></p>
<p>The basic design of these artefacts remains relatively constant (12 pentagonal faces with knop-shaped legs), however, there can be a range of different  incised designs in the layout of the faces<strong>. </strong></p>
<p>The actual function of these artefacts cannot be explained by our historians or archaeologists, although many theories abound,  none of which seem particularly convincing. Also, there is no  mention of these items in old historical records of the Romans or those of anyone else for that matter. They are such an enigma that academics have pretty-much come to the defeatist conclusion that <em><strong>"we will never know what these dodecahedrons were used for". </strong></em></p>
<p>In reviewing the academic literature, one begins to see why the mystery will probably never be solved within that community. Here are some of the impediments and pitfalls our experts create for themselves:</p>
<p>All archaeological measurements are given in metric increments (centimetres or millimetres), which is a modern system that was created as much as 2000-years after some of these dodecahedra were cast in bronze. Earlier exemplars in stone or wood could predate the latter, more refined ones, by yet another thousand years or more. This  metric measurement preoccupation renders the  encoded numbers invisible or unrecognisable. Our academics know a large swathe of the ancient measurements that were in use two thousand years ago or before, so why not apply them to this study? </p>
<p>Most assuredly, the various sized holes in the 12-faces, the concentric circles that circumnavigate them, as well as the additional incised lines or dotted circles, etc, infer that there is something vividly measurable going on and it's evident that each hole or ring  has been very purposely fabricated to represent a known, precise and sought-after measurement.</p>
<p><img src="http://www.celticnz.co.nz/OrgImages/Dodecahedron/Calibrated.jpg" width="900" height="476"> </p>
<p><strong>A number of dodecahedra have calibration marks along their edges or around the holes in their faces. To the left is seen a calibrated dodecahedron from Hereford Museum, Kenchester and to the right is seen another from Goodrich Castle. Yet another one found in Wales shows etched calibration marks. </strong></p>
<p>In their reports,  archaeologists will often round out measurements of the holes in the dodecahedron faces to the nearest millimetre only, which is grossly insufficient. It's much appreciated by researchers when measurements can be supplied to 1/10th  of a millimetre, but  it is nigh on impossible  to acquire more refined measurements undertaken with electronic vernier callipers. Precise measurements and scaling must precede any serious analysis of these artefacts, but our experts don't seem to think there would be anything significant to find anyway, so don't subject the dodecahedra to rigorous measurement analysis.</p>
<p>Despite the fact that 25.4 millimetres (1 British Standard Inch) or fraction expressions of the same will recur repeatedly in the faces of dodecahedra, no-one seems to have arrived at the conclusion that the enigmatic<em><strong> "inch"</strong></em> recurrence is worthy of serious investigation. </p>
<p>Almost anything considered high-art, technically advanced or an engineering feat within ancient European civilisations seems to be automatically attributed to the Romans, which is certainly the case for these dodecahedra artefacts. This  is a hangover of biased, classicist-isolationist historical  interpretations of  European history where, first came the  Roman conquerors, who finally retreated after centuries of domination, only to be replaced by Rome's State church. With the pedigree of the church being Greco-Roman it was in their interests to push the concept that the Roman armies had found everything in the regions they invaded to be backwards, rudimentary or crude until Rome delivered the great-unwashed masses out of their depravity and into  enlightenment and high-civilisation. </p>
<p>This general process of misattribution further hobbles or seriously limits proper investigation into the purpose and function of dodecahedra artefacts, inasmuch as focus is  directed, almost exclusively, to what Roman armies might have used them for as range-finders or other battle related paraphernalia, including club-heads. The druids or others don't get  any serious consideration, despite the fact that they are historically recorded as having been  advanced mathematicians and astronomers.</p>
<p>Within controlled academia the ability to do open-ended, ground-breaking research can be severely curtailed by the requirements of <em><strong>"peer review"</strong></em> by colleagues.  This is largely a racket that ensures one doesn't move too far from the protected consensus opinion upon which academic reputations are built and anyone venturing too far out into left field is considered a maverick who threatens the insulated central body.</p>
<p>By the same token academia, these days, is lumbered with deep-set social responsibilities and crippling political agendas. When it comes to European history, especially, the requirement is to be self-effacing, while lauding and applauding the (often meager) accomplishments of other ethnicities. Under  guises of political correctness and racial sensitivity, the door is opened for antagonistic non-European, prejudiced individuals, to write and interpret  our history for us, while pushing their own  cultural-Marxist or similar wheel-barrows.  All one has to do is sit through lectures in our western universities to see just how far out of kilter the abysmal problem of  European history-misrepresentation has become.</p>
<p>But, with regards to the dodecahedra artefacts,what one person can build, another can generally duplicate or back-engineer, sufficient to make sense of what's going on. </p>
<p>So, let's cut to the chase, bypass all the  confusion of modern-day naysayers and source testimony directly from an observer who lived contemporary to the druids, before they fell under Roman domination </p>
<p>Julius Caesar, who was a very thorough historian, writes the       following regarding the late era druids of his time (circa 55 BC) and        practices within their many universities in Britain, where students from Gaul       and elsewhere, including Rome, went for training:</p>
<p><strong>'They hold aloof from war and do not pay war taxes; they       are excused from military service and exempt from all liabilities. Tempted       by these great advantages, many young men assemble of their own motion to       receive their training, many are sent by parents and relatives. Report says       that in the schools of the Druids they learn by heart a great number of verses,       and therefore some persons remain twenty years under training'. </strong></p>
<p><strong>'They do not think it proper to commit these utterances to       writing, although in all other matters and in their public and private accounts       they make use of Greek characters. I believe that they have adopted the practice       for two reasons- that they do not wish the rule to become common property,       nor those who learn the rule to rely on writing and so neglect the cultivation       of memory; and, in fact, it does usually happen that the assistance of writing       tends to relax the diligence of the student and the action of memory...They       also lecture on the stars in their motion, the magnitude       of the Earth and its divisions, on natural history, on the power and       government of God; and instruct the youth in these subjects' <em>(see De Ballo       Gallico, VII, 15, 16.).</em></strong></p>
<p>Historian, Isabel Hill Elder  writes, <strong>'The students at these       colleges numbered at times sixty thousand of the youth and young nobility       of Britain and Gaul. Caesar comments on the fact that the Gauls sent their       youth to Britain to be educated...It required twenty years to master the complete       circle of Druidic knowledge. Natural philosophy, astronomy,       mathematics, geometry, medicine, jurisprudence, poetry and oratory       were all proposed and taught-natural philosophy and       astronomy with severe exactitude' (Elder refers to <em>Strabo I IV,       page 197. Caesars Comm. Lib V. Sueotonius, V Calegula. E. Campion, Accounts       of Ireland, pg. 18.).</em></strong></p>
<p>Isabel Hill Elder further writes,<strong> 'The education system       adopted by the Druids is traced to about 1800 BC when Hu Gardarn Hysicion       (Isaacson), or Hu the Mighty, led the first colony of Cymri into Britain from       Defrobane, where Constantinople now stands'.</strong> </p>
<p>Further commenting on Hu       Gardarn Hysicion, Isabel Hill Elder writes that he, <strong>'is commemorated in       Welsh archaeology as having made poetry the vehicle of memory'.</strong> Elsewhere       she writes, he <strong>'is said to have mnemonically systematized the wisdom of       the ancients...'.</strong> She goes on to say,<strong> 'The published compositions of       the Druids and Bards form but a very small portion of the extant remains of       their works. The Myvyrian MSS. alone, now in the British Museum, amount to       47 volumes of poetry, in 1600 pages, besides about 2000 epigrammatic stanzas.       Also in the same collection are 53 volumes of prose, in about 15,300 pages,       containing many curious documents on various subjects...' <em>(see Celt, Druid       and Culdee, pages 54 &amp; 55).</em></strong></p>
<p>With the testimony of Julius Caesar ringing in our ears, lets see how the druids would have used the dodecahedron artefacts as <em><strong>"memory"</strong></em>devices for mathematically encoding astronomical cycles,<em><strong> ("the stars in their motion")</strong></em>, navigation systems <em><strong>("the …</strong></em></p></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://www.celticnz.co.nz/Dodecahedron/Decoding%20the%20Druidic%20Dodecahedron1.html">http://www.celticnz.co.nz/Dodecahedron/Decoding%20the%20Druidic%20Dodecahedron1.html</a></em></p>]]>
            </description>
            <link>http://www.celticnz.co.nz/Dodecahedron/Decoding%20the%20Druidic%20Dodecahedron1.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25237271</guid>
            <pubDate>Sat, 28 Nov 2020 13:03:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Bill Gates is wrong about education]]>
            </title>
            <description>
<![CDATA[
Score 31 | Comments 64 (<a href="https://news.ycombinator.com/item?id=25235672">thread link</a>) | @rajlego
<br/>
November 27, 2020 | https://supermemo.guru/wiki/Bill_Gates_is_wrong_about_education | <a href="https://web.archive.org/web/*/https://supermemo.guru/wiki/Bill_Gates_is_wrong_about_education">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="mw-content-text" lang="en" dir="ltr"><p><small>This text is part of: "<i><a href="https://supermemo.guru/wiki/Problem_of_Schooling" title="Problem of Schooling">I would never send my kids to school</a></i>" by <a href="https://supermemo.guru/wiki/Piotr_Wozniak" title="Piotr Wozniak">Piotr Wozniak</a> (2017)</small>
</p>


<h2><span id="Bill_Gates_is_my_hero">Bill Gates is my hero</span></h2>
<p>Bill Gates was an early guiding light and <a href="https://supermemo.guru/wiki/SuperMemo_World" title="SuperMemo World">our</a> inspiration. When <a href="https://supermemo.guru/wiki/Krzysztof_Biedalak" title="Krzysztof Biedalak">Krzysztof Biedalak</a> and I made our first $3 investment in a corporate rubber stamp, which was a post-communist obligation for all companies in Poland in 1991, Microsoft was a multibillion-dollar company. How could we not have been blinded by inspiration? We wanted to write a universally useful piece of software and the world would be ours - we thought. Bill Gates's software philosophy, based on respect for backward compatibility, sheltered <a href="https://supermemo.guru/wiki/SuperMemo" title="SuperMemo">SuperMemo</a> on its path to its painfully slow adoption. Software and database compatibility have been preserved for 30 years now. My first pieces of knowledge in medical sciences, typed in on Dec 13, 1987, are still there in my collection, well-memorized and useful. Without Gates and his stance on compatibility, I would have lost all that knowledge to some upgrade hiccup long ago. When Gates moved to philanthropy, he has secured his place on my list of the greatest people who ever walked this planet. Perhaps as many as <a href="https://supermemo.guru/wiki/Bill_Gates_saved_over_100_million_children" title="Bill Gates saved over 100 million children">30-120 million kids have been saved by Bill's foundation</a>. This begs a vital question: Why is Gates so awfully wrong about education? Why does he fall for the same old myth that <a href="https://supermemo.guru/wiki/Myth:_You_can_improve_education_by_throwing_more_money_in_it" title="Myth: You can improve education by throwing more money in it">investing in education will produce better outcomes</a>? The education system is wrong and it must be redesigned. <a href="https://supermemo.guru/wiki/Compulsory_schooling_must_end" title="Compulsory schooling must end">Compulsory schooling must end</a>. See: <a href="https://supermemo.guru/wiki/Grand_Education_Reform" title="Grand Education Reform">Grand Education Reform</a>
</p>
<h2><span id="Could_Bill.27s_great_mind_be_wrong.3F">Could Bill's great mind be wrong?</span></h2>
<p>Everyone who disagrees with a great mind needs to pause and re-examine. Gates got sensational credentials. He sports a genius mind. He has seen more places that I could possibly ever manage to visit in Google Maps. He has spoken to more great people than I have had a chance to read about. He has visited more schools that I have seen on pictures. He started his forays into education in 1999. In contrast, I started thinking about "the system" only in 2016 when getting ready to write this <a href="https://supermemo.guru/wiki/Problem_of_Schooling" title="Problem of Schooling">book</a>. This makes me into a fledgling with an immature point of view. Gates himself is a great example of a brisk student who has turned his skills and talents into a monumental achievement. His credentials are so much better than mine!
</p>
<h2><span id="Bill_Gates.27s_perspective">Bill Gates's perspective</span></h2>
<p>Could this just be that Gates's perspective is so much different than mine?
</p><p>He looks at the education system like at the operating system. Measure the performance, look for bottlenecks in the system, fix the parameter here and there, videotape a great teacher, and make others copy the method, and manufacture greatness.
</p><p>He looks at education like a philanthropic job. Like he treats health problems with mass vaccinations, he looks for a simple formula which could improve the education of the masses with some industrial move? He seems less focused on letting the brightest thrive, and more focused on preventing the weakest from dropping out. He wants to bring up the average using some <a href="https://supermemo.guru/wiki/Testing" title="Testing">standardized testing</a> approach.
</p><p>He looks at education like a big company that needs to be managed effectively with departments, and sub-departments. With a clear division of responsibility. <a href="https://supermemo.guru/wiki/Modern_schooling_is_like_Soviet_economy#Schooling_is_like_Soviet_Economy" title="Modern schooling is like Soviet economy">With an industrial goal in mind?</a>
</p><p>Could this be that this great capitalist shows more socialist thinking than a little well-indoctrinated ex-communist like myself?
</p><p>There is a different perspective of an employer and an employee, esp. in a creative position. Gates looks at the number of college graduates. I look for specific skills and creative powers. Actual degrees do not matter much if you take time to get into a particular brain.
</p><p>He looks at students like productive workers. The heretic idea of a longer school day must have come from the factory model thinking. Longer days, more production, more manufacturing.
</p><p>He looks at education from a societal point of view, while I look at the brain of an individual. He wants to move the masses to high achievement, while I want to produce more little Bill Gateses.
</p><p>Unlike myself, Bill Gates does not focus on having more Bill Gateses. He focuses on helping the poor, in boosting qualifications of the middle class, and adds "<i>you can't run a society on top 5%</i>". He is right, however, that top 5% can forge a path in education that would inspire all the rest. They cannot be run through a compulsory system set on pushing through the remaining 95%.
</p><p>Gates's approach would be great for some poorer countries (e.g. in Africa). Where there are no schools, industrial approach and good management could quickly improve health, eliminate poverty, and provide basic education.
</p><p>My approach is probably more suited to well-developed nations where the industrial approach makes people sick of schooling. With social awareness and education on the rise, we look for more little future Noble Prize winners and future Bill Gateses.
</p><p>His own kids get the best kind of learning. During his trips around the world, they get to visit places like the Large Hadron Collider at CERN. This could spark a life-long passion that could turn them into future particle physicists or another incarnation of <a href="https://supermemo.guru/wiki/Tim_Berners-Lee" title="Tim Berners-Lee">Tim Berners-Lee</a>.  
</p><p>Where Gates optimizes for improving the average, I am looking for the optimum of peak intellectual performance.
</p><p>Last but not least, could Gates's approach be an afterglow of his dropping out from Harvard. I see that over and over again, dropouts seem to suffer from this life-long hangover about what could have been? They tend to over-appreciate the power of schooling or the power of college. In the same way, I might be under-appreciating my own degrees. Gates is <a href="https://supermemo.guru/wiki/Thiel_on_competition_for_degrees" title="Thiel on competition for degrees">the opposite of Peter Thiel</a> who studiously climbed the educational ladder until he stumbled to see the light. Thiel is now one of the staunchest critics of college.
</p>
<h2><span id="Bill_Gates.27s_formula_for_success">Bill Gates's formula for success</span></h2>
<p>I see Gates's own life as a simple formula for success in science, engineering, or life in general:
</p>
<ul><li> healthy childhood of few concerns (preferably without the relegation to <a href="https://supermemo.guru/wiki/Daycare_misery" title="Daycare misery">daycare</a>)</li>
<li> healthy approach to schooling with pranks, rebellions, disobedience, and freedom </li>
<li> minor trajectory nudges within the <a href="https://supermemo.guru/wiki/Push_zone" title="Push zone">push zone</a> by inspirational tutors. If tutors are not parents, this might be the most expensive part of the formula</li>
<li> breakthrough passion, e.g. for tinkering with computers or software</li>
<li> healthy education, possibly interrupted by some breakthrough decision (e.g. <i>Let me drop out from Harvard to set up the greatest software company in the world</i>)</li>
<li> relentless lifelong pursuit of goals born from that <a href="https://supermemo.guru/wiki/Passion_and_memory" title="Passion and memory">youthful passion</a></li>
<li> voracious reading (see: <a href="https://supermemo.guru/wiki/Bill_Gates_and_his_non-incremental_reading" title="Bill Gates and his non-incremental reading">Bill Gates and his non-incremental reading</a>)</li></ul>
<p>Only Bill Gates truly knows it, but my understanding of his life story is that his future was determined by just one major factor: getting his hands on a computer. He was good at math and programming. So are dozens of kids in my neighborhood. My thinking comes from the fact that I was also strongly affected by my first contact with computers.
</p>

<p>When <a href="https://supermemo.guru/wiki/First_steps_of_SuperMemo" title="First steps of SuperMemo">I got my first computer in 1986</a>, ZX Spectrum, I was 24 and experienced wild elation with computer's obedience in executing my commands. I told the computer what to do, and it did it perfectly without asking questions. That was wonderful. I started writing my <a href="https://supermemo.guru/wiki/Plan" title="Plan">program for planning my day</a> on paper long before I got the computer on my desk. I was eager to see it work! As ZX Spectrum would load programs from a cassette tape, I could not easily dream of having <a href="https://supermemo.guru/wiki/SuperMemo" title="SuperMemo">SuperMemo</a>. It needed access to some disk drive. I got my first PC with a 360 KB <a href="https://en.wikipedia.org/wiki/Floppy_disk">floppy disk</a> drive only <a href="https://supermemo.guru/wiki/SuperMemo_1.0_for_DOS_(1987)" title="SuperMemo 1.0 for DOS (1987)">in 1987</a></p>
<p>The above hypothetical formula for educational success is simple and effective. Only a few might ever dream to replicate the scope of Bill's success. If that formula does not bring serial Nobel Prize winners, it should at least bring up a great deal of happy and fulfilled individuals. Freedom to explore the world is essential and it is denied to a great deal of kids in the modern world. When Peter Thiel pays kids to drop out from college, he looks for this type of free thinking experience that can change one life and then can change the world.
</p>
<h2><span id="My_attempt_at_employing_Gates.27s_formula">My attempt at employing Gates's formula</span></h2>

<p>I am happy with <a href="https://supermemo.guru/wiki/Exponential_adoption_of_spaced_repetition" title="Exponential adoption of spaced repetition">my achievements in life</a>. I have followed the formula employed by Gates. However, there were some exceptions. Perhaps I could use them as an excuse for not being as wildly successful as Bill? I was sent to <a href="https://supermemo.guru/wiki/Daycare_misery" title="Daycare misery">daycare</a>, and I am sure this slowed down my development. The time I spent with my brother was more intellectual and inspirational by two orders of magnitude. However, he was a student and could not babysit the little me for ever. In later years, I was forced into a degree of conformity by an ever-present threat of being enlisted by the army in service of the Warsaw Pact. In 1986, I was finally free of the army service, and could finally drop out, however, I was not ready. There was no market economics culture in Poland of the 1980s. I read about entrepreneurial science in Science in 1989 (Oct 31, 1989). This was the first time when it occurred to me that my research into memory might actually be a seed of a business. Initially, though, my passions led me in the direction of a PhD. Schooling told me that science done by entrepreneurs is inferior to science done in academia. I thought of <a href="https://supermemo.guru/wiki/SuperMemo" title="SuperMemo">SuperMemo</a> as an opportunity to earn money for a trip to America. It seems that while Gates was fast to mature as a little entrepreneur, I needed 28 long years to even start thinking of my <a href="https://supermemo.guru/wiki/SuperMemo_World" title="SuperMemo World">own business</a>.</p>
<h2><span id="Reconciling_Gates_and_Woz">Reconciling Gates and Woz</span></h2>
<p>Gates wants better teachers, better education, verification, <a href="https://supermemo.guru/wiki/Testing" title="Testing">testing</a>, measuring, carrot-and-stick for teachers, etc. In contrast, I stand with Steve Jobs. Jobs told the kids to <a href="https://supermemo.guru/wiki/Fundamental_law_of_learning" title="Fundamental law of learning">rebel</a>!
</p><p>Gates believes that the key to the <a href="https://supermemo.guru/wiki/Reform" title="Reform">great future education system</a> is the teacher. He is almost right. If we could populate present schools with great teachers, I wouldn't ever need to write <a href="https://supermemo.guru/wiki/Problem_of_Schooling" title="Problem of Schooling">this book</a>. The problem is that <a href="https://supermemo.guru/wiki/Progressive_education" title="Progressive education">a great teacher is simply a truly great man</a>. Great teaching requires a degree of genius. We need millions of those great people. How can we possibly hope to produce hundreds of thousands …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://supermemo.guru/wiki/Bill_Gates_is_wrong_about_education">https://supermemo.guru/wiki/Bill_Gates_is_wrong_about_education</a></em></p>]]>
            </description>
            <link>https://supermemo.guru/wiki/Bill_Gates_is_wrong_about_education</link>
            <guid isPermaLink="false">hacker-news-small-sites-25235672</guid>
            <pubDate>Sat, 28 Nov 2020 06:12:37 GMT</pubDate>
        </item>
    </channel>
</rss>
