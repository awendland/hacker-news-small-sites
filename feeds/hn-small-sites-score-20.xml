<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 20]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 20. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Thu, 27 Aug 2020 00:52:11 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-20.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Thu, 27 Aug 2020 00:52:11 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[DIY Single-Chip 2D Retro Game Console]]>
            </title>
            <description>
<![CDATA[
Score 50 | Comments 13 (<a href="https://news.ycombinator.com/item?id=24268585">thread link</a>) | @0xmarcin
<br/>
August 24, 2020 | http://www.voja.rs/PROJECTS/GAME_HTM/1_intro.htm | <a href="https://web.archive.org/web/*/http://www.voja.rs/PROJECTS/GAME_HTM/1_intro.htm">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <td rowspan="4">
      <div>
			<iframe width="420" height="315" src="//www.youtube.com/embed/VbTwWFwbsE4" frameborder="0" allowfullscreen=""></iframe>
			<p>
			<img height="420" src="http://www.voja.rs/PROJECTS/GAME_HTM/console.jpg" width="600"></p>
			<p>This 
			DIY project offers the
            simple stand-alone VGA game console which is based on <b> PIC24EP512GP202</b>  microcontroller.
            As the video signal and the corresponding sync signals are generated by software, 
			the console contains a
            minimum of hardware. There is also an audio signal output with five binary tone channels, mixed by 
			a 
			passive resistor network. Two of those channels are used for sound effects,  
			similar to ones used in video games of that time (early eighties) and 
			three for background music. This output is capable of driving line 
			output for PC speakers or headphones.</p>
			<p>
			It should be noted that there is no video processing unit, PGA or 
			any special purpose chips, and that PIC microcontrollers are not 
			designed for video signal generation. Everything is achieved by a 
			series of different design tricks and some compromises.</p>
			<p>
			This is an open hardware and open software project. Video 
			and audio generators, which are the vital parts of the firmware, are 
			the parts of the operating system, which will soon be documented, and can be used 
			for any other game or application. As the timings are critical, those parts 
			are written in assembly language, but all the other parts of the 
			program (scenario for some other games or any other application) may 
			also be written in some other programming language, preferably 
			Microchip's C. In this case all parts are written in Assembler, but 
			only as a result of author's preference.</p>
			<p>
			At the moment, only the game Jumping Jack is written for the 
			platform, well known to those who played with the Spectrum personal 
			computer back in the day. However, once a new game is created, it is 
			easy to download it from the computer, via 
			the serial port. The console has a USB connector, but it is used 
			only for 5V power supply. Unfortunately, microcontrollers which are 
			packed in DIP packages (with thru-hole soldering, convenient for DIY 
			projects and workshops) do not have USB interface but only serial ports, so 
			you have to use RS 232 to download the new game instead of Jumping 
			Jack, which is deafult in this project.</p>
			<p>
			If you want to build this console, you need the PCB and components 
			which are listed <span><strong>
			<a href="http://www.voja.rs/PROJECTS/GAME_HTM/2.%20Hardware.htm#BOM">here</a></strong></span>. 
			To program the microcontroller, you should need a PIC programmer (e.g. 
			<strong>PICKIT3</strong>, avaliable <span><strong>
			<a href="http://www.microchipdirect.com/ProductSearch.aspx?Keywords=PG164130">here</a></strong></span>) and
			<strong>MPLAB X IDE</strong> software, available <span><strong>
			<a href="http://www.microchip.com/pagehandler/en-us/family/mplabx/">here</a></strong></span>. 
			But if you want to know how PIC generates video and audio signals by 
			software in real time, or even if you feel ambitious enough to 
			create your own game for this platform, please visit the
			<span>
			<strong><a href="http://www.voja.rs/PROJECTS/GAME_HTM/2.%20Hardware.htm">next page</a></strong></span></p>
          </div>
    </td>
  </div></div>]]>
            </description>
            <link>http://www.voja.rs/PROJECTS/GAME_HTM/1_intro.htm</link>
            <guid isPermaLink="false">hacker-news-small-sites-24268585</guid>
            <pubDate>Tue, 25 Aug 2020 06:23:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Renaissance of the Shell?]]>
            </title>
            <description>
<![CDATA[
Score 35 | Comments 42 (<a href="https://news.ycombinator.com/item?id=24268533">thread link</a>) | @dwmkerr
<br/>
August 24, 2020 | https://effective-shell.com/docs/part-1-transitioning-to-the-shell/6-the-renaissance-of-the-shell/ | <a href="https://web.archive.org/web/*/https://effective-shell.com/docs/part-1-transitioning-to-the-shell/6-the-renaissance-of-the-shell/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><p>This is the first of the “interludes” which end each section of the book. They don't teach any specific skills but instead give a little flavour and background about the world of the shell, Linux and modern computing.</p><p>In this first interlude we'll look at just why the shell is experiencing something of a renaissance in the modern age of IT.</p><p>To be honest, it is hard to know whether there is an increase in popularity of the use of the shell and command-line tooling in general. There are data sources which indicate there is more widespread usage amongst the technical community - Stack Overflow tag popularity is one. LinkedIn data on desired skillsets is another. However, disassociating whether there is a general increase in the need for diverse technical skillsets and whether there is a <em>specific</em> increase in the popularity of keyboard and script operated systems is a challenge.</p><p>For the purposes of this chapter, we'll instead examine changes in the technology landscape over the last few decades and consider what those changes might mean for the shell, the command-line and similar tools.</p><p>We'll look at three specific developments in technology:</p><ul><li>Diversity of programming languages</li><li>Convergence of operating platforms</li><li>DevOps</li></ul><p>Each of these developments has a potentially profound impact on how we work with computers, and might hint at the long term need for shell skills.</p><p>So let's look at some of the key changes in the technology landscape over recent years and consider how they might affect the popularity and importance of the shell.</p><h2 id="the-diversity-of-programming-languages">The Diversity of Programming Languages</h2><p>There have been many programming languages and platforms over the years. But in recent years it is possible that the diversity has increased at a greater rate than ever before.</p><p>With the advent of the internet and the increase in the size of the online technical community, programming has in a sense become more democratised (which we will discuss a little more in the ‘citizen coder’ section). When in the past it was necessary to find physical books or teachers and tutors to learn a programming language, students can now find a wealth of resources online.</p><p>It is perhaps this democratisation which has led to a startlingly diverse world of programming languages. For many years, there were a small number of ‘general purpose’ languages, and a larger number of highly specialised languages (and associated platforms).</p><p>“C”, and later, “C++” were the go-to languages for systems programming (sometimes backed up by assembly language). This was the language which kernels and compilers were written in.</p><p>“Java” become the ‘general purpose’ language of choice for applications which had to run on many systems. “Basic” and later “C#” were the standards for Windows platform development. PHP was a staple for web development.</p><p>Alongside these giants were the workhorses for specific use cases. Erlang was (and is) a language which is highly popular in the telecommunications industry, where high availability and reliability were paramount. COBOL was the language for the financial industry, where mission critical systems ran on mainframes (and many still do).</p><p>Of course there were many other languages, but many of these other languages were highly specific, in a sense C, Java, PHP and later C# dominated the landscape.</p><p>Transition to the time of writing. In the Stack Overflow 2020 Technology Survey[^1], the top ten languages most wanted by employers are:</p><ul><li>Python</li><li>JavaScript</li><li>Go</li><li>TypeScript</li><li>Rust</li><li>Kotlin</li><li>Java</li><li>C++</li><li>SQL</li><li>C#</li></ul><p>Some of our old friends are there, but there are many new languages, languages which are evolving quickly. Later on in the list we will see Swift, Dart, Ruby, Haskell, Scala. There are many programming languages which are extremely popular today.</p><p>Why does this matter for the shell? The answer is that for <em>many</em> new languages, developer tooling is not as mature (some might say bloated) as it is for the ‘Workhorse’ languages. Java developers are likely very familiar with the Eclipse IDE, Microsoft shops will be familiar with Visual Studio. These are products which have been evolving for years (or decades) to support developers with rich integrated development environments.</p><p>For server-side JavaScript, Golang, Rust, Python and other languages, the development environment really is the shell. Modern editors like Visual Studio Code, Atom and so on provide a vast amount of support and tooling, encompassing the features of a full fledged IDE if the user wants. But for modern programming languages, users often have <em>had</em> to rely on the shell to compile, transpile, manage packages, bundle and so on. The average developer today is perhaps much more likely to have to use the shell - to manage Python virtual environments one day, to run Node.js another, to install packages for Golang another.</p><p>In time tooling will likely catch up and provide a ‘friendly’ interface on top of these operations, but many engineers have realised (or always known) that direct access to simple command line tools can be <em>extremely efficient</em> when working, and that overly featured IDEs can get in the way and hide complexity.</p><p>The modern programming is often polyglot - having to be at least familiar in a number of languages. The shell provides a common environment and interface for tooling, which is accessible by all, without installing many complex components, for both development and runtime environments.</p><h2 id="convergence-of-operating-platforms">Convergence of Operating Platforms</h2><p>Whilst the variety in programming languages and developer tooling may have increased, in many ways the <em>operating platforms</em> engineers use have become more homogeneous.</p><p>In the early days of computing, each operating environment was highly diverse. There were many systems which were used for production and many of them were highly proprietary. Even popular application servers were often closed source and highly specialised.</p><p>The modern execution environment however is often fairly uniform. A Linux-like system, with few customisations, which the developer or operator can tweak to suit their needs.</p><p>More and more enterprise users have moved away from proprietary Unix platforms to Linux platforms (whether commercial or non-commercial). The earliest cloud environments were using open-source Linux distributions as the available operating systems.</p><p>Even Windows has increasing support for Linux-like operation, in the form of the Windows Subsystem for Linux.</p><p>Perhaps the greatest movement in this area has been the rapid adoption of Docker as a common container technology. Containers, or container-like systems have been around for a long time, but Docker brought containers to the masses. With Docker, engineers expect operating environments to be even more uniform and Linux-like.</p><p>This has made knowledge of the shell extremely valuable. For any containerised workloads, Linux and shell skills are crucial. Kubernetes (as an execution environment) has standardised things even more.</p><p>Whilst there are still many workloads which run on proprietary systems, modern solutions are often built to run in containers on Linux. The shell has historically been the most common way to manage Linux systems, and the standardisation of operating environments around Linux, or Linux-like systems has made shell skills even more critical.</p><h2 id="devops">DevOps</h2><p>Love it or hate it, DevOps has exploded in popularity. DevOps engineers, site-reliability engineers, these kinds of roles may have been unheard of in companies not that long ago and are now becoming ubiquitous.</p><p>In attempting to unify the goals of development and operation of software, DevOps represents an organisational and cultural change. Rather than having one group focus on feature development and another group focus on reliable software operations, a single group is responsible for both. The theory is that this encourages software engineers to also consider security, reliability, maintainability etc, and operators to also consider speed of delivery.</p><p>Regardless of whether teams are genuinely combined, or specialised roles are added to teams, or even if teams are still separated, the lines between development and operations blur somewhat. Software developers are expected to build and plan with knowledge of the execution environment, operators are expected to work with developers to build features which support reliability.</p><p>The intersection of these two roles often is in the realm of automation. Automated deployments after testing, automated failover in case of errors, automated alerting when potential issues are discovered, automated provisioning of environments, automated scaling of systems when load increases.</p><p>The world of automation is intimately linked to the world of the shell and in particular shell scripting. Many tasks which require automation can be easily achieved using shell scripts. Many aspects of modern environments (such as cloud environments) support provisioning and management of services via scripting. In fact, services which <em>cannot</em> be managed via shell scripts or simple interfaces are increasingly becoming obsolete. If it cannot be scripted, it cannot be automated, and the increasingly complex systems we build <em>require</em> automation.</p><p>In practice, this means software engineers are far more likely to have to build shell scripts (or at least understand how to interface with systems via the shell) than they perhaps might have been. Similarly, operators are far more likely to have to <em>program</em> automated routines to manage high availability and so on. Again, the shell and shell scripts are a common way to manage this (even if they are simply entrypoints to more complex systems, such as scripts which execute programs).</p><p>The rise in popularity of DevOps as a set of practices and beliefs has perhaps made the shell more popular, and more important, than any other recent developments in software engineering.</p><p>And for these reasons and many more, learning how to use the shell effectively has never been more relevant or practical.</p></article></div>]]>
            </description>
            <link>https://effective-shell.com/docs/part-1-transitioning-to-the-shell/6-the-renaissance-of-the-shell/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24268533</guid>
            <pubDate>Tue, 25 Aug 2020 06:13:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[rc.d belongs in libexec, not etc]]>
            </title>
            <description>
<![CDATA[
Score 65 | Comments 56 (<a href="https://news.ycombinator.com/item?id=24267933">thread link</a>) | @Khaine
<br/>
August 24, 2020 | https://jmmv.dev/2020/08/rcd-libexec-etc.html | <a href="https://web.archive.org/web/*/https://jmmv.dev/2020/08/rcd-libexec-etc.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <div>
              
              <article>

<p>Let’s open with the controversy: the scripts that live under <code>/etc/rc.d/</code> in FreeBSD, NetBSD, and OpenBSD are in the wrong place. They all should live in <code>/libexec/rc.d/</code> because they are code, <em>not</em> configuration.</p>

<p>This misplacement is something that has bugged me for ages but I never had the energy to open this can of worms back when I was very involved in NetBSD. I suspect it would have been a draining discussion and a very difficult thing to change.</p>

<p>But… what am I talking about anyway?</p>

<p>If you have administered a BSD system, you have certainly encountered the <code>/etc/rc.d/</code> directory; and if you have administered pre-systemd Linux systems, you have dealt with <code>/etc/init.d/</code>. These directories contain startup scripts to configure the system at boot time and are immutable. Their code is parameterized to allow changing their behavior via configuration files, not via code edits. And that’s the base of my critique.</p>

<p>But before getting into why the current state is problematic and how things should look like, let’s first dig into how we got here. And, for that, we need to go back in history.</p>



<p>4.4BSD’s (1993) boot process was rather simple: the kernel started <code>init</code> which in turn ran the <code>/etc/rc</code> script before starting <code>getty</code> on each console. The <code>/etc/rc</code> monolith was in charge of configuring the machine’s file systems and processes, and delegated to two other scripts: <code>/etc/netstart</code> for network configuration and <code>/etc/rc.local</code> for locally-added services. Current BSD systems are more advanced in this area as we shall see later, but the core boot process remains the same: <code>/etc/rc</code> is the primary entry point and bootstraps a collection of shell scripts.</p>

<p>In the early days, package management and file provenance tracking, like we are used to having in popular Linux distributions, was not a thing. You were expected to tune the systems’ behavior by <em>editing</em> files which might or might not have been designed to support edits. If you had to edit <code>/etc/rc</code>, which was a script shipped by the system, that was alright.</p>

<p><code>/etc/rc.local</code>, on the other hard, was <em>not</em> shipped by the system, and it was up to you to create it if you wanted to add custom startup commands without modifying <code>/etc/rc</code>. And this is where things get interesting. <code>/etc/rc.local</code> didn’t need to be supported: if you were expected and able to edit <code>/etc/rc</code> anyway, why would you deal with a separate file? The reason is, most likely, to simplify system upgrades: during an upgrade, you want to benefit from any upstream changes made to <code>/etc/rc</code> (some of which might actually be <em>necessary</em> for proper system operation). Applying updates to a manually-modified file is tricky, so putting as many of your manual overrides into <code>/etc/rc.local</code> helped minimize this problem.</p>



<p>System V 4 (SVR4, 1988) also came with its own, and very different, boot process. The key difference was that System V had the concept of runlevels. As a result, configuring the boot process was a more convoluted endeavour because it was possible to select different services per runlevel.</p>

<p>To accomplish per-runlevel tuning, the system used <a href="https://jmmv.dev/2020/08/config-files-vs-directories.html">configuration directories rather than files</a>: there was a separate <code>/etc/rcX.d/</code> directory for each runlevel (where <code>X</code> was the number of the runlevel), and these directories contained one file per action to take at startup time. To avoid duplicates, these files were just symlinks to common files under <code>/etc/init.d/</code>—and the symlinks, not their targets, were named so that their lexicographical order determined startup execution order.</p>

<p>Once again, we can already observe issues here: the symlinks under <code>/etc/rcX.d/</code> <em>are</em> configuration because their presence indicates what to start and their names determine their startup order. But the files under <code>/etc/init.d/</code> are <em>not</em>: they are shell scripts shipped with the system and should not be manually modified.</p>



<p>NetBSD <a href="http://www.mewburn.net/luke/papers/rc.d.pdf">modernized the boot process</a> in its 1.5 release (2000), and it did so in two ways: first, it introduced <code>/etc/rc.d/</code> as a directory to contain separate scripts per action and service; and, second, it introduced <a href="https://netbsd.gw.com/cgi-bin/man-cgi?rcorder+8+NetBSD-9.0-STABLE">the <code>rcorder(8)</code> tool</a> to determine the order in which these services run. <code>rcorder(8)</code> uses dependency information encoded in the scripts as comments—not lexicographical ordering as System V did. FreeBSD <a href="https://www.freebsd.org/cgi/man.cgi?query=rc&amp;apropos=0&amp;sektion=8&amp;manpath=FreeBSD+12.1-RELEASE&amp;arch=default&amp;format=html">inherited this design</a> in its 5.0 release (2003) and OpenBSD reimplemented something similar in its 4.9 release (2011).</p>

<p>With these two pieces in place, the <code>/etc/rc</code> script in NetBSD and FreeBSD changed to execute all files from <code>/etc/rc.d/</code> based on the output of <code>rcorder(8)</code>. Among these scripts is <a href="https://github.com/NetBSD/src/blob/8f8c6d6b2a8778b653d9630f3f18e057b477a012/etc/rc.d/local"><code>/etc/rc.d/local</code></a>, whose purpose is to run <code>/etc/rc.local</code> if it exists. And that’s all, really. The <code>/etc/rc</code> script thus became <a href="https://github.com/NetBSD/src/blob/8f8c6d6b2a8778b653d9630f3f18e057b477a012/etc/rc">trivial</a>.</p>

<p>The key thing to notice here is that the scripts shipped in <code>/etc/rc.d/</code> are <em>highly configurable</em> via the user-controlled <a href="https://github.com/NetBSD/src/blob/8f8c6d6b2a8778b653d9630f3f18e057b477a012/etc/rc.conf"><code>/etc/rc.conf</code></a> file. This essentially makes the scripts read-only, as it shifts local customizations to the configuration file. <em>System administrators are not supposed to edit the scripts.</em> Instead, they are supposed to: modify <code>/etc/rc.conf</code> to customize what gets run and how; add new scripts under <code>/etc/rc.d/</code> if they so choose; and edit <code>/etc/rc.local</code> to easily run arbitrary commands.</p>



<p>My main gripe is that the files under <code>/etc/rc.d/</code> are immutable scripts. They do not belong in <code>/etc/</code> and their presence there makes system upgrades harder for no good reason.</p>

<p>You see: in NetBSD and FreeBSD, system upgrades happen by unpacking new distribution sets in the root directory and then running a script to incorporate configuration updates. This script is interactive and helps highlight how new system-provided updates to configuration files conflict with previous manual edits. (This process might seem rudimentary to you, but it’s actually pretty robust and easy to understand—and you can use tooling like <a href="https://github.com/jmmv/sysupgrade/">sysupgrade</a> to make it trivial.)</p>

<p>So why is that a problem? Because you will <em>always</em> face merges like this:</p>
<div><pre><code data-lang="diff"><span>--- /etc/rc.d/npf               2019-08-09 19:09:42.800758233 -0400
</span><span></span><span>+++ /tmp/temproot/etc/rc.d/npf  2019-11-16 10:39:27.000000000 -0500
</span><span></span><span>@@ -1,6 +1,6 @@
</span><span></span> #!/bin/sh
 #
<span>-# $NetBSD: npf,v 1.3 2012/11/01 06:06:14 mrg Exp $
</span><span></span><span>+# $NetBSD: npf,v 1.4 2019/04/19 18:36:25 leot Exp $
</span><span></span> #
 # Public Domain.
 #
<span>@@ -36,7 +36,11 @@
</span><span></span>        echo "Enabling NPF."
        npf_cfg_check
        /sbin/npfctl reload
<span>-       /sbin/npfctl start
</span><span></span><span>+
</span><span>+       # The npf_boot script has enabled npf already.
</span><span>+       if [ "$autoboot" != "yes" ]; then
</span><span>+               /sbin/npfctl start
</span><span>+       fi
</span><span></span> }
 
 npf_stop()

File: /etc/rc.d/npf (modified)

Please select one of the following operations:

  d  Don't install the new file (keep your old file)
  i  Install the new file (overwrites your local modifications!)
  m  Merge the currently installed and new files
  s  Show the differences between the currently installed and new files
  su  Show differences in unified format ("diff -u")
  sc  Show differences in context format ("diff -c")
  ss  Show differences side by side ("sdiff -w187")
  scommand Show differences using the specified diff-like command
  v  Show the new file

What do you want to do? [Leave it for later]
</code></pre></div>
<p>And, really, who cares? Why are you being distracted to review a <em>code</em> change when what you are trying to do is assess <em>configuration</em> conflicts? How many times have you actually objected to these merges?</p>

<p>You might say: well, I want to know <em>exactly</em> how the boot process of my machine changes during an upgrade. Sure, that’s a fine goal, but then this procedure is flawed and completely insufficient to achieve such goal. In the example above, whatever <code>/etc/rc.d/npf</code> does can also be done from within the <code>/sbin/npfctl</code> binary it invokes… and you were never asked to review changes to the latter during an upgrade, were you? And <em>of course</em> you could review the binary’s code as part of your own system build, but if you did that, then you could have reviewed the startup script as well, right?</p>



<p>Startup scripts provided by the system need to live in a location that can contain executables—but we don’t want those executables to show up in the <code>PATH</code>. These requirements discard <code>bin</code> and <code>sbin</code>, and points us towards <code>libexec</code> on BSD systems and somewhere under <code>lib</code> on Linux.</p>

<p>Therefore, the read-only startup scripts should move from <code>/etc/rc.d/</code> to <code>/libexec/rc.d/</code> (which, by the way, also applies to <code>/etc/rc</code>, <code>/etc/rc.subr</code>, and <code>/etc/rc.shutdown</code>). And that’s it. <del><code>/etc/rc</code></del> <code>/libexec/rc</code> should continue to use <code>rcorder(8)</code> to check what’s needed to run, but it should read files from <code>/libexec/rc.d/</code>. You might even want to support a separate location for user-created services, which might still be <code>/etc/rc.d/</code> or, better yet, a more fitting location like <code>/usr/pkg/libexec/rc.d/</code> (though that quickly runs into problems if you have multiple file systems).</p>

<p>With this design, system upgrades would be much saner because the configuration merge process would focus, purely, on actual configuration changes and not on irrelevant code changes. All updates to <code>/libexec/rc.d/</code> would be applied by unpacking the new distribution sets (<code>base.txz</code> in this case) without disturbing you about how exactly they changed.</p>

<p>Does this relate to Linux distributions at all? I briefly mentioned <code>/etc/init.d/</code> at the beginning, and the problem there is similar. But it’s also an obsolete problem given that Linux distributions have moved onto systemd by now. That said, systemd still has to manage individual services and, like it or not, has gotten this right. If we look at the <a href="https://www.freedesktop.org/software/systemd/man/systemd.unit.html"><code>systemd.unit(5)</code></a> manual page, which describes where units are loaded from, the system first looks into various <code>/etc/</code> and <code>/run/</code> directories, but then also looks at <code>/usr/lib/systemd/system/</code> (a read-only location correctly controlled by the package manager)—and the vast majority of the scripts live inside the latter.</p>



<p>I currently don’t run BSD systems any more so my incentives to make this happen are low… but if this all makes sense and is something you’d like to pursue, by all means please do! I’m happy to help …</p></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://jmmv.dev/2020/08/rcd-libexec-etc.html">https://jmmv.dev/2020/08/rcd-libexec-etc.html</a></em></p>]]>
            </description>
            <link>https://jmmv.dev/2020/08/rcd-libexec-etc.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24267933</guid>
            <pubDate>Tue, 25 Aug 2020 03:35:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Jensen Huang’s vision for data center dominance may destroy the Arm ecosystem]]>
            </title>
            <description>
<![CDATA[
Score 128 | Comments 98 (<a href="https://news.ycombinator.com/item?id=24264288">thread link</a>) | @kasabali
<br/>
August 24, 2020 | https://semianalysis.com/jensen-huangs-vision-for-data-center-dominance-will-destroy-the-arm-ecosystem/ | <a href="https://web.archive.org/web/*/https://semianalysis.com/jensen-huangs-vision-for-data-center-dominance-will-destroy-the-arm-ecosystem/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-elementor-type="wp-post" data-elementor-id="552" data-elementor-settings="[]">
						<div>
							<div>
							<section data-id="680b3ce0" data-element_type="section">
						<div>
							<div>
					<div data-id="c620d2" data-element_type="column">
			<div>
							<div>
						<div data-id="6eb11d27" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<div><p>As the weeks pass by, the rumors keep spinning, the likelihood of an Nvidia Arm acquisition increases. On first glance, the two businesses look completely incompatible. A highly vertically integrated graphics and AI company with very high margins buying a low margin IP licensor doesn’t make sense. Nvidia can already build any product they wish as an Arm licensee. Purchasing the whole cow doesn’t yield additional milk or synergies from the current business model. Furthermore, given Nvidia’s reputation as a partner, it would likely even cause customers to start looking for contingencies and accelerate RISC-V adoption. Jensen Huang, in his quest for data center dominance, may destroy the Arm ecosystem for everyone else.</p><p><img loading="lazy" src="https://i0.wp.com/semianalysis.com/wp-content/uploads/2020/08/1.jpg?resize=1140%2C606&amp;ssl=1" alt="1" width="1140" height="606" data-recalc-dims="1"></p><p>The rational for purchasing Arm seems ridiculous to many, but Jensen’s vision is for the datacenter being a computer and Nvidia being the one to build it. They need to be to be completely vertically integrated and control every aspect of this computer. Currently they have the accelerator market on lock-down with their impressive hardware and vast software moat of CUDA/various SDKs which was built by thousands of Nvidia engineers over the last decade. With the acquisition of Mellanox, they bring the “Data Processing Unit (DPU)” of the data center in house as well. They have also continued to expand their vertically integrated software stack to networking with acquisitions of SwiftStack and Cumulus Networks.</p><p><img loading="lazy" src="https://i0.wp.com/semianalysis.com/wp-content/uploads/2020/08/2.jpg?resize=1140%2C575&amp;ssl=1" alt="2" width="1140" height="575" data-recalc-dims="1"></p><p>The datacenter is a 3 legged stool, and the remaining missing piece is a CPU. AMD, Intel, and various hyperscalers are also working to build out their own 3-legged stool. The largest threat to Nvidia is Intel/AMD finally having competent GPUs and software stacks to accompany them. With the US Department of Energy dumping money into SYCL and many in the industry congregating around it, the software front is accelerating rapidly. Furthermore, various hyperscalers are rapidly building out their own CPUs with Arm Neoverse IP to hook in with their accelerators such as the Google TPU and Amazon Inferentia for AI workloads. Lastly, these hyperscalers also already have their own custom network stacks. Nvidia is currently in very strong position, but it is very precarious as their moats may all be eroded simultaneously.</p><p>In any business, in order to maintain a high margin over a long period of time, one must create barriers of entry so high, that no one can break in and disrupt. Even though Intel has stopped executing for essentially 5 years, they are still raking in the dough with &gt;55% gross margins. Jensen Huang’s vision, if fully realized, would see Nvidia building a nearly impenetrable moat that commands high margins and locks customers in. This may sound nefarious, but Nvidia’s solution will be plug and play. The vast majority of companies do not have the resources required to build out the entire software stack to match specialized hardware. Nvidia would offer the best solution, which would eventually become an expensive deal imprisoning you in the Devil’s ecosystem.</p><p><img loading="lazy" src="https://i1.wp.com/semianalysis.com/wp-content/uploads/2020/08/3.png?resize=1140%2C587&amp;ssl=1" alt="3" width="1140" height="587" data-recalc-dims="1"></p><p>This is where acquiring Arm rather than licensing her technology comes into play. Nvidia needs to build the moat, and the only way to do this is to effectively hijack the entire open Arm ecosystem. Developing your own CPU ISA is far too large of an investment and there would be no adoption. Even the opening up of Power and MIPS have failed to stop their slow declines to irrelevancy. RISC-V is also still in its infancy and will take many years to move into any verticals besides embedded.</p><p>Jensen can only realize the of the vision of data center dominance by becoming the only company with the trifecta of CPU, GPU, and DPU. Nvidia can only achieve this by acquiring Arm at an unreasonable price. An independent Arm is simply not worth the $35B-$50B which SoftBank wants. Even a $20B valuation would be high valuation for Arm.</p><p><img loading="lazy" src="https://i1.wp.com/semianalysis.com/wp-content/uploads/2020/08/4.jpg?resize=1140%2C641&amp;ssl=1" alt="4" width="1140" height="641" data-recalc-dims="1"></p><p>Nvidia can justify this price if they are willing to flip the semiconductor IP world on its head. The ultimate path to ROI means upending the current Arm business model. Given Nvidia’s over $300B valuation, the deal wouldn’t have to be very dilutive to current shareholders. They would start by purchasing the business in a cash/stock deal and obtaining regulatory approval. Regulatory approval initially seems like a large hurdle, but we believe it will not be. The UK will gladly approve if Nvidia makes commitments for large investments. China would be willing to look the other way if the current Arm China JV drama is swept under the rug. The EU would likely need concessions, but because Nvidia does not compete in most of Arm’s verticals, it shouldn’t be too difficult to obtain approval here either. The US regulators would be foaming at the thought of US control of Arm.</p><p>The next step would involve assuring the clients that the businesses would operate separately. Jensen has already begun telegraphing this according to the <a href="https://www.ft.com/content/b4649576-9541-4857-b3a4-5b4ccb847642">Financial Times</a>.</p><blockquote><p>As the company extends its reach to supply a complete data centre computing platform, it would sell parts of the technology as separate “layers”, Mr Huang said. Other companies would also be able to license its intellectual property for use in their own chips, rather than needing to buy silicon from Nvidia, he added.</p></blockquote><p>As part of the integration of the two companies, Nvidia would cut or sell the Arm Mali GPU and Ethos NPU business. These would be redundant and can be supplemented with Nvidia’s own expertise. This would be quite the shock as Nvidia’s previous attempts to license their GPU architecture have completely failed. If Nvidia is successful in the renewed licensing efforts, we could live in a world where their CUDA architecture with accompanying software stack (read lock-in) is proliferated across phones, embedded, and the upcoming augmented reality segment. There would be some attrition as companies like Samsung have turned to licensing AMD’s RDNA graphics. In general, it would also accelerate the move out of the Arm ecosystem to RISC-V, but this will be a painful and slow move for most.</p><p><img loading="lazy" src="https://i1.wp.com/semianalysis.com/wp-content/uploads/2020/08/5.png?resize=1024%2C395&amp;ssl=1" alt="5" width="1024" height="395" data-recalc-dims="1"></p><p>The key for Nvidia here is creating captive, dependant customers by rocking the boat, but not too violently. If the NvidiArm solution is convenient and cheap, most of the ecosystem will not attempt to rush out. Nvidia likely does not increase prices for a while in order to give their licensees an illusion of a happy status quo. Eventually, these price increases will come. The attrition will be the worst in the embedded market where RISC-V is mostly already here and players like <a href="https://twitter.com/dylan522p/status/1295500585123188737?s=20">Alibaba</a> and Si-Five have the IP nearly ready to go.</p><p>The mobile SOC market is captive to Arm roadmaps for years to come, and this is one of the sectors Nvidia can start aggressively extracting ROI. Apple has a perpetual license and so they won’t be affected, but Qualcomm, Samsung, and Mediatek would start to sweat bullets as their licensing costs soar and they have no alternatives without their own custom core teams which have been disbanded. Mediatek specifically is highly dependent on not only ARM CPUs, but also GPUs and interconnects for many of their SOCs.</p><p><img loading="lazy" src="https://i0.wp.com/semianalysis.com/wp-content/uploads/2020/08/6.png?resize=1140%2C641&amp;ssl=1" alt="6" width="1140" height="641" data-recalc-dims="1"></p><p>Nvidia’s largest avenue for ROI comes the data center. x86 is long overdue for some disruption. Even with AMD innovating rapidly, the world wants more options. Arm server development is being done by multiple hyperscalers and independent fabless vendors. Arm is going to break the x86 monopoly with a combination of licensed Neoverse designs and in-house designs from the likes of Nuvia or Marvell. Once the x86 duopoly is broken, Nvidia can also raise prices rapidly here. &nbsp;The hyperscalers in-house Arm Neoverse designs will still have better TCO than any merchant silicon, but the savings will begin to wane.</p><p><img loading="lazy" src="https://i0.wp.com/semianalysis.com/wp-content/uploads/2020/08/7.png?resize=1140%2C641&amp;ssl=1" alt="7" width="1140" height="641" data-recalc-dims="1"></p><p>Another adjacent market where Nvidia can begin to pressure their competition is automotive. While Intel’s Mobileye currently uses MIPS and is transitioning to x86, Tesla and Qualcomm use Arm Cores. If licensing fees ratchet up here significantly, Nvidia can begin to extract margin out of their competitors’ sales. Ultimately, the CPU isn’t a competitive advantage in automotive, but just the cheapest and most convenient option.</p><p>As the Arm ecosystem matures, it will stop being the cheapest option, but only remain the convenient one. Embedded markets have already seen the light of RISC-V and the adoption can only accelerate from here. Other markets have been hooked to the drug of cheap, licensed, Arm IP. With aggressive Nvidia ownership, the junkies will have no choice but to pay up and give in to demands for the short run. They will search for alternative supplies, but this move will take a long time.</p><p><img loading="lazy" src="https://i1.wp.com/semianalysis.com/wp-content/uploads/2020/08/8.jpg?resize=1140%2C642&amp;ssl=1" alt="8" width="1140" height="642" data-recalc-dims="1"></p><p>Nvidia’s endgame isn’t more revenue from licensing costs. Their endgame is a fully vertically integrated data center provider. They will want to make and control every part of the three legged stool. This means they slowly destroy the idea of Neoverse. Whether through making that IP extremely costly, or having their own in house designs be a generation ahead, Nvidia will build a moat around Arm server CPUs. Over time, Jensen Huang will muscle out other Arm vendors supplementing them with Nvidia’s in-house designs. The open Arm ecosystem will be hijacked, and be replaced with a closed off ecosystem rivaling or exceeding that of Intel and AMD.</p><p><span>If Nvidia can quickly seize the worlds most important IP, the most commonly used CPU ISA and designs, they will control the destiny of mobile and data center. This is Jensen Huang’s “Trojan Horse” for a Machiavellian takeover of the future of computing.</span></p></div>
				</div>
				</div>
						</div>
					</div>
		</div>
								</div>
					</div>
		</section>
						</div>
						</div>
					</div></div>]]>
            </description>
            <link>https://semianalysis.com/jensen-huangs-vision-for-data-center-dominance-will-destroy-the-arm-ecosystem/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24264288</guid>
            <pubDate>Mon, 24 Aug 2020 19:14:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Writing a Test Case Generator for a Programming Language]]>
            </title>
            <description>
<![CDATA[
Score 30 | Comments 4 (<a href="https://news.ycombinator.com/item?id=24263117">thread link</a>) | @azhenley
<br/>
August 24, 2020 | http://fitzgeraldnick.com/2020/08/24/writing-a-test-case-generator.html | <a href="https://web.archive.org/web/*/http://fitzgeraldnick.com/2020/08/24/writing-a-test-case-generator.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p>Maxime Chevalier-Boisvert requested resources for learning about fuzzing
programming language implementations on Twitter:</p>

<blockquote>
  <p>I’d like to learn about fuzzing, specifically fuzzing programming language
implementations. Do you have reading materials you would recommend, blog
posts, papers, books or even recorded talks?</p>
</blockquote>

<p><cite><a href="https://twitter.com/Love2Code">@Love2Code</a> · <a href="https://twitter.com/Love2Code/status/1290363848885776385">August 3,
2020</a></cite></p>

<p>Maxime received many replies linking to informative papers, blog posts, and
lectures. <a href="https://twitter.com/johnregehr/status/1290368969199636480">John Regehr suggested writing a simple generative fuzzer for the
programming
language.</a></p>

<p>A generative fuzzer combines a test case generator with the system under test
(e.g. your compiler), generating new test cases and feeding them into the
system:</p>

<figure><pre><code data-lang="rust"><span>fn</span> <span>generative_fuzzer</span><span>()</span> <span>{</span>
    <span>loop</span> <span>{</span>
        <span>// Use the test case generator to create a new</span>
        <span>// input.</span>
        <span>let</span> <span>input</span> <span>=</span> <span>generate_test_case</span><span>();</span>

        <span>// Feed that input into the system under test.</span>
        <span>let</span> <span>result</span> <span>=</span> <span>run_system_under_test</span><span>(</span><span>input</span><span>);</span>

        <span>// Finally, if the system under test crashed,</span>
        <span>// failed an assertion, etc... then report</span>
        <span>// that!</span>
        <span>if</span> <span>result</span><span>.is_interesting</span><span>()</span> <span>{</span>
            <span>report</span><span>(</span><span>input</span><span>);</span>
        <span>}</span>
    <span>}</span>
<span>}</span></code></pre></figure>

<p>I realized that many people might not know what it takes to write their own
generative fuzzer, so this blog post shows one aspect of it: implementing a test
case generator.</p>

<p>Our test case generator will generate <a href="https://webassembly.org/">WebAssembly</a> programs. While
WebAssembly has its own quirks — it’s a binary format and is generally a
compilation target rather than a source language — it is a small and
simple language. The techniques we use when generating WebAssembly should
transfer to generating the programming language of your choice.</p>

<p>If you want to skip the exposition and jump head first into the code, <a href="https://github.com/fitzgen/wasm-smith">here is
the repository for our final test case generator</a>.</p>

<h2 id="table-of-contents">Table of Contents</h2>

<ul>
  <li><a href="#what-is-a-test-case-generator">What is a Test Case Generator?</a></li>
  <li><a href="#getting-set-up">Getting Set Up</a></li>
  <li><a href="#translating-grammars-into-generators">Translating Grammars into Generators</a></li>
  <li><a href="#generating-the-type-section">Generating the Type Section</a></li>
  <li><a href="#generating-the-import-section">Generating the Import Section</a></li>
  <li><a href="#generating-the-code-section">Generating the Code Section</a></li>
  <li><a href="#using-the-test-case-generator">Using the Test Case Generator</a></li>
  <li><a href="#conclusion">Conclusion</a></li>
</ul>

<h2 id="what-is-a-test-case-generator">What is a Test Case Generator?</h2>

<p>Test case generators generate test cases. These test cases are always within the
test domain: no cycles are wasted on invalid inputs, such as source text that
fails to parse. Compare this to <a href="https://www.fuzzingbook.org/beta/html/MutationFuzzer.html">mutation-based fuzzing</a>, where existing seed
inputs are mutated to produce new inputs. In general, nothing guarantees that
the new, mutated input is still within the test domain: the mutation may have
introduced a syntax error. This property, that generated inputs are always
within the test domain, is generative fuzzing’s main advantage and the test case
generator’s main responsibility.</p>

<p>A test case generator should, additionally, support every feature of its target
programming language. You won’t discover a bug in your compiler’s handling of
<code>switch</code> statements if the test case generator doesn’t support generating
<code>switch</code> statements. Pushing this idea even further, the test case generator
should <em>uniformly sample</em> from the test domain. If the test case generator can
technically generate <code>switch</code> statements but the probability of doing so is
nearly zero, then you likely still won’t find that bug. However, uniformly
sampling from the infinite set of all programs that can be written in a
particular programming language is
<a href="https://blog.regehr.org/archives/1700">nontrivial</a> and an area of
<a href="https://arxiv.org/pdf/0807.0992v1.pdf">active</a>
<a href="https://havrikov.github.io/publications/ase19-preprint.pdf">research</a>.</p>

<p>A test case generator should, finally, be fast. The faster we can generate test
cases, the faster we will discover bugs. If the generator is too slow, we can
blow our time budget, failing to find those bugs at all.</p>

<h2 id="getting-set-up">Getting Set Up</h2>

<p>First, we create a new crate with <code>cargo</code>. We’ll name this crate <code>wasm-smith</code>,
giving a little nod to <a href="https://embed.cs.utah.edu/csmith/">Csmith</a>, the popular C program generator.</p>

<figure><pre><code data-lang="shell"><span>$ </span>cargo new <span>--lib</span> wasm-smith</code></pre></figure>

<p>Second, we add <a href="https://github.com/rust-fuzz/arbitrary">the <code>arbitrary</code> crate</a> as a dependency:</p>

<figure><pre><code data-lang="toml"><span># wasm-smith/Cargo.toml</span>

<span>[dependencies]</span>
<span>arbitrary</span> <span>=</span> <span>{</span> <span>version</span> <span>=</span> <span>"0.4.6"</span><span>,</span> <span>features</span> <span>=</span> <span>["derive"]</span> <span>}</span></code></pre></figure>

<p>The <code>arbitrary</code> crate helps us generate structured data from arbitrary bytes. It
is typically used in combination with <a href="https://llvm.org/docs/LibFuzzer.html">libFuzzer</a> to translate the raw bytes
given to use by libFuzzer into something that the system you’re testing can
process. For example, a color conversion library might use <code>arbitrary</code> to turn
the raw fuzzer-provided bytes into <code>Rgb</code> or <code>Hsl</code> color types. We will use it in
a similar way for this project, translating raw bytes given to us by libFuzzer
into semantically valid WebAssembly modules.</p>

<p>The <code>arbitrary</code> crate’s main export is <a href="https://docs.rs/arbitrary/0.4.5/arbitrary/trait.Arbitrary.html">the <code>Arbitrary</code> trait</a>:</p>

<figure><pre><code data-lang="rust"><span>pub</span> <span>trait</span> <span>Arbitrary</span><span>:</span> <span>Sized</span> <span>+</span> <span>'static</span> <span>{</span>
    <span>fn</span> <span>arbitrary</span><span>(</span><span>u</span><span>:</span> <span>&amp;</span><span>mut</span> <span>Unstructured</span><span>)</span> <span>-&gt;</span> <span>Result</span><span>&lt;</span><span>Self</span><span>&gt;</span><span>;</span>

    <span>// Provided methods hidden...</span>
<span>}</span></code></pre></figure>

<p>It takes an <a href="https://docs.rs/arbitrary/0.4.5/arbitrary/struct.Unstructured.html"><code>Unstructured</code></a>, which is a helpful wrapper around a byte slice, and
returns an instance of the type for which it is implemented.</p>

<p>For our <code>wasm-smith</code> crate, we define a <code>Module</code> type that represents our
pseudo-random WebAssembly modules, and then we implement the <code>Arbitrary</code> trait
for it:</p>

<figure><pre><code data-lang="rust"><span>use</span> <span>arbitrary</span><span>::{</span><span>Arbitrary</span><span>,</span> <span>Result</span><span>,</span> <span>Unstructured</span><span>};</span>

<span>/// A pseudo-random WebAssembly module.</span>
<span>pub</span> <span>struct</span> <span>Module</span> <span>{</span>
    <span>// ...</span>
<span>}</span>

<span>impl</span> <span>Arbitrary</span> <span>for</span> <span>Module</span> <span>{</span>
    <span>fn</span> <span>arbitrary</span><span>(</span><span>u</span><span>:</span> <span>&amp;</span><span>mut</span> <span>Unstructured</span><span>)</span> <span>-&gt;</span> <span>Result</span><span>&lt;</span><span>Self</span><span>&gt;</span> <span>{</span>
        <span>todo!</span><span>()</span>
    <span>}</span>
<span>}</span></code></pre></figure>

<p>Before we fill in that <code>todo!()</code> lets take a moment to settle on a design for
what the implementation will look like.</p>

<h2 id="translating-grammars-into-generators">Translating Grammars into Generators</h2>

<p>Writing a generator is remarkably similar to hand-writing a <a href="https://en.wikipedia.org/wiki/Recursive_descent_parser">recursive descent
parser</a>, so if you’ve done that before, then you should feel right at home. For
example, given this grammar production (borrowed and lightly edited from <a href="https://itanium-cxx-abi.github.io/cxx-abi/abi.html#mangling">the
C++ name mangling</a> grammar):</p>

<pre><code>&lt;class-enum-type&gt; ::= Ts &lt;name&gt;
                    | Tu &lt;name&gt;
                    | Te &lt;name&gt;
</code></pre>

<p>A recursive descent parser will, almost mechanically, translate the production
into something like this:</p>

<figure><pre><code data-lang="rust"><span>impl</span> <span>Parse</span> <span>for</span> <span>ClassEnumType</span> <span>{</span>
    <span>fn</span> <span>parse</span><span>(</span><span>p</span><span>:</span> <span>&amp;</span><span>mut</span> <span>Parser</span><span>)</span> <span>-&gt;</span> <span>Result</span><span>&lt;</span><span>Self</span><span>&gt;</span> <span>{</span>
        <span>// Ts &lt;name&gt;</span>
        <span>if</span> <span>p</span><span>.peek</span><span>(</span><span>"Ts"</span><span>)</span> <span>{</span>
            <span>p</span><span>.consume</span><span>(</span><span>"Ts"</span><span>)</span><span>?</span><span>;</span>
            <span>let</span> <span>name</span> <span>=</span> <span>Name</span><span>::</span><span>parse</span><span>(</span><span>p</span><span>)</span><span>?</span><span>;</span>
            <span>return</span> <span>Ok</span><span>(</span><span>ClassEnumType</span><span>::</span><span>Ts</span><span>(</span><span>name</span><span>));</span>
        <span>}</span>

        <span>// Tu &lt;name&gt;</span>
        <span>if</span> <span>p</span><span>.peek</span><span>(</span><span>"Tu"</span><span>)</span> <span>{</span>
            <span>p</span><span>.consume</span><span>(</span><span>"Tu"</span><span>)</span><span>?</span><span>;</span>
            <span>let</span> <span>name</span> <span>=</span> <span>Name</span><span>::</span><span>parse</span><span>(</span><span>p</span><span>)</span><span>?</span><span>;</span>
            <span>return</span> <span>Ok</span><span>(</span><span>ClassEnumType</span><span>::</span><span>Tu</span><span>(</span><span>name</span><span>));</span>
        <span>}</span>

        <span>// Te &lt;name&gt;</span>
        <span>p</span><span>.consume</span><span>(</span><span>"Te"</span><span>)</span><span>?</span><span>;</span>
        <span>let</span> <span>name</span> <span>=</span> <span>Name</span><span>::</span><span>parse</span><span>(</span><span>p</span><span>)</span><span>?</span><span>;</span>
        <span>Ok</span><span>(</span><span>ClassEnumType</span><span>::</span><span>Te</span><span>(</span><span>name</span><span>))</span>
    <span>}</span>
<span>}</span></code></pre></figure>

<p>Our generator will do something similar, except instead of peeking at the input
string to decide which right-hand side of the production to parse, we will make
a pseudo-random choice to generate one of those potential right hand sides.</p>

<p>We could use a random number generator directly to make these choices, but this
has two problems:</p>

<ol>
  <li>
    <p>We give up determinism unless we are careful to control the RNG’s seed and
reuse the same RNG everywhere, threading it through all of our functions as a
parameter. Determinism is extremely important for reproducing test failures!
It’s definitely possible to do these things, but can occasionally be a little
annoying.</p>
  </li>
  <li>
    <p>More importantly, using an RNG precludes a mature fuzzing engine, like
libFuzzer, from guiding our test case generation based on code coverage and
other insights.</p>
  </li>
</ol>

<p>Instead, we use a raw input byte slice given to us by libFuzzer or AFL as a
sequence of predetermined choices.<sup id="back-dont-require-libfuzzer"><a href="#foot-dont-require-libfuzzer">0</a></sup> This <a href="https://arxiv.org/pdf/1812.00078v1.pdf">lets the fuzzer guide our
test case generation</a>, and <a href="https://drmaciver.github.io/papers/reduction-via-generation-preview.pdf">gives us test case reduction “for
free”</a> since we can ask the fuzzer to reduce the raw input
sequence, rather than write a domain-specific test case reducer. This comes as a
relief because writing a reducer that understands WebAssembly is easily as much
effort as writing the generator itself.</p>

<p>Here is the same C++ mangling example from above, but translated from a parser
into a generator, using <code>Unstructured</code>:</p>

<figure><pre><code data-lang="rust"><span>fn</span> <span>arbitrary_class_enum_type</span><span>(</span>
    <span>u</span><span>:</span> <span>&amp;</span><span>mut</span> <span>Unstructured</span><span>,</span>
    <span>output</span><span>:</span> <span>&amp;</span><span>mut</span> <span>String</span><span>,</span>
<span>)</span> <span>-&gt;</span> <span>Result</span><span>&lt;</span><span>()</span><span>&gt;</span> <span>{</span>
    <span>match</span> <span>u</span><span>.int_in_range</span><span>::</span><span>&lt;</span><span>u8</span><span>&gt;</span><span>(</span><span>0</span><span>..=</span><span>2</span><span>)</span> <span>{</span>
        <span>// Ts &lt;name&gt;</span>
        <span>0</span> <span>=&gt;</span> <span>{</span>
            <span>output</span><span>.push_str</span><span>(</span><span>"Ts"</span><span>);</span>
            <span>arbitrary_name</span><span>(</span><span>u</span><span>,</span> <span>output</span><span>)</span><span>?</span><span>;</span>
            <span>Ok</span><span>(())</span>
        <span>}</span>
        <span>// Tu &lt;name&gt;</span>
        <span>1</span> <span>=&gt;</span> <span>{</span>
            <span>output</span><span>.push_str</span><span>(</span><span>"Tu"</span><span>);</span>
            <span>arbitrary_name</span><span>(</span><span>u</span><span>,</span> <span>output</span><span>)</span><span>?</span><span>;</span>
            <span>Ok</span><span>(())</span>
        <span>}</span>
        <span>// Te &lt;name&gt;</span>
        <span>2</span> <span>=&gt;</span> <span>{</span>
            <span>output</span><span>.push_str</span><span>(</span><span>"Te"</span><span>);</span>
            <span>arbitrary_name</span><span>(</span><span>u</span><span>,</span> <span>output</span><span>)</span><span>?</span><span>;</span>
            <span>Ok</span><span>(())</span>
        <span>}</span>
        <span>_</span> <span>=&gt;</span> <span>unreachable!</span><span>(),</span>
    <span>}</span>
<span>}</span></code></pre></figure>

<p>Once again, this is mostly mechanical.</p>

<p>This pattern will generate <em>syntactically</em> correct test cases that can be parsed
successfully but which likely contain a plethora of type errors, calls to
undefined functions, etc. We’ve set out to generate <em>semantically</em> correct test
cases that pass type checking and will exercise more than just the language
implementation’s frontend.</p>

<p>Our final pattern maintains some extra information about the program we’ve
generated thus far, so that we can consult that information when generating new
forms. This extra information might include which names are in scope, the types
of each variable, etc. We consult that information while dynamically building up
thunks for every valid option we could generate. Once we have enumerated every
option, we ask the <code>Unstructured</code> to choose one of them, and finally we call the
chosen thunk to generate the form.</p>

<p>Here is an example of using this pattern for generating integer expressions,
where an integer expression is either a constant integer, an arithmetic
operation, a use of an integer variable, or a call of a function that returns an
integer:</p>

<figure><pre><code data-lang="rust"><span>fn</span> <span>arbitrary_int_expr</span><span>(</span>
    <span>u</span><span>:</span> <span>&amp;</span><span>mut</span> <span>Unstructured</span><span>,</span>
    <span>scope</span><span>:</span> <span>&amp;</span><span>mut</span> <span>Scope</span><span>,</span>
<span>)</span> <span>-&gt;</span> <span>Result</span><span>&lt;</span><span>Expr</span><span>&gt;</span> <span>{</span>
    <span>// We will dynamically build up all of the valid</span>
    <span>// options of what we can generate.</span>
    <span>let</span> <span>mut</span> <span>options</span><span>:</span> <span>Vec</span><span>&lt;</span><span>fn</span> <span>(</span>
        <span>&amp;</span><span>mut</span> <span>Unstructured</span><span>,</span>
        <span>&amp;</span><span>mut</span> <span>Scope</span><span>,</span>
    <span>)</span> <span>-&gt;</span> <span>Result</span><span>&lt;</span><span>Expr</span><span>&gt;&gt;</span> <span>=</span> <span>vec!</span><span>[];</span>

    <span>// It is always valid to generate a constant.</span>
    <span>options</span><span>.push</span><span>(|</span><span>u</span><span>,</span> <span>_</span><span>|</span> <span>{</span>
        <span>Ok</span><span>(</span><span>Expr</span><span>::</span><span>Constant</span><span>(</span><span>u</span><span>.arbitrary</span><span>::</span><span>&lt;</span><span>i32</span><span>&gt;</span><span>()</span><span>?</span><span>))</span>
    <span>});</span>

    <span>// It is always valid to generate an addition.</span>
    <span>options</span><span>.push</span><span>(|</span><span>u</span><span>,</span> <span>scope</span><span>|</span> <span>{</span>
        <span>let</span> <span>lhs</span> <span>=</span> <span>arbitrary_int_expr</span><span>(</span><span>u</span><span>,</span> …</code></pre></figure></div></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://fitzgeraldnick.com/2020/08/24/writing-a-test-case-generator.html">http://fitzgeraldnick.com/2020/08/24/writing-a-test-case-generator.html</a></em></p>]]>
            </description>
            <link>http://fitzgeraldnick.com/2020/08/24/writing-a-test-case-generator.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24263117</guid>
            <pubDate>Mon, 24 Aug 2020 17:36:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Applying tech frameworks to biotech: key differences]]>
            </title>
            <description>
<![CDATA[
Score 42 | Comments 16 (<a href="https://news.ycombinator.com/item?id=24262336">thread link</a>) | @apsec112
<br/>
August 24, 2020 | https://www.celinehh.com/tech-vs-biotech | <a href="https://web.archive.org/web/*/https://www.celinehh.com/tech-vs-biotech">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div data-block-type="2" id="block-yui_3_17_2_1_1590947194898_9413"><div><p>Many of the common startup frameworks for tech companies do not apply as well to biotech. I’ve gone through the most common frameworks below, and how they differ for biotech companies. </p><p>I’m defining a tech startup here as a company whose product is largely based off of code. I am not including in my arbitrary categorization ‘deep tech’ (e.g., autonomous trucks, satellite startups, etc), which often face similar challenges as biotech companies. </p><p>Biotech here is a startup developing a drug. </p><p><em>These are generalizations, and many exceptions exist. </em></p><h2><strong>Risks and Finding Product Market Fit</strong></h2><p><span><strong>TECH</strong></span><strong>: Significant market and execution risks<br></strong><span><strong>BIOTECH</strong></span><strong>: Minimal market risk, a lot of technical risk</strong></p></div></div><div><div><div data-block-type="2" id="block-yui_3_17_2_1_1594517769210_605840"><div><p>In tech, the company often uses a standard software stack and applies it in a novel way (a new product). The question is usually not ‘can this thing be built’, but ‘does anyone want this thing we made’?</p><p>In biotech, this is flipped. The market (a disease) is well established, but the ability to develop a product (a drug) that addresses this market is the core risk. </p></div></div></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1594517769210_607921"><p><span><strong>TECH</strong></span><strong>: Rolling derisking, early signs of product-market fit<br></strong><span><strong>BIOTECH</strong></span><strong>: Derisking comes in bursts over years (biological milestones), early signals less reliable</strong></p></div><div><div><div data-block-type="2" id="block-yui_3_17_2_1_1594517769210_617219"><div><p>In tech, you want the ‘up and to the right’ chart, showing exponential increase of some core metric of the company. Adoption, revenue, and other metrics derisk the company and give early signs of PMF. Early signs can be highly predictive of the company’s eventual success.</p><p>In biotech, derisking the company is predominantly tied to specific biological milestones. These come in bursts, with long periods of waiting in-between. Additionally, early milestones (such as the drug working in mice) aren’t 1-to-1 predictive of eventual success (the drug working in people).</p></div></div></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1594517769210_619233"><p><span><strong>TECH</strong></span><strong>: Iterate to product-market-fit<br></strong><span><strong>BIOTECH</strong></span><strong>: Product (drug) finalized years before on market</strong></p></div><div><div><div data-block-type="2" id="block-yui_3_17_2_1_1594517769210_631626"><div><p>In tech, the product is constant iterates and improves from customer feedback to find the exact product that people want. </p><p>In biotech, due to the extensive regulation, the final product (the drug) is finalized years before it first goes into people. If the drug doesn’t work in people, there is no iterating. If you want to modify the product, you need to restart the entire process over again. </p></div></div></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1594517769210_633705"><div><h2><strong>Founders &amp; Market</strong></h2><p><span><strong>TECH</strong></span><strong>: Founders often bring insight around a market<br></strong><span><strong>BIOTECH</strong></span><strong>: Founders often bring insight around key biology</strong></p></div></div><div><div><div data-block-type="2" id="block-yui_3_17_2_1_1594517769210_651094"><div><p>In tech, a prototypical founder often worked at the incumbent company or realized a market opportunity by being that market themself. The insight around the market opportunity itself is a core value of the company. </p><p>In biotech, the insight of the founder is around a new or better way to develop a drug for the disease, or a discovery that was made in the laboratory (and the relevant patents around it). </p></div></div></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1594517769210_665620"><p><span><strong>TECH</strong></span><strong>: Founders often younger, ‘youth wunderkinds’ widely accepted <br></strong><span><strong>BIOTECH</strong></span><strong>: Founders often older due to scientific training or are a professional CEO, rarer to have very young founders </strong></p></div><div><div><div data-block-type="2" id="block-yui_3_17_2_1_1594517769210_678110"><div><p>In tech, the 18-year-old drop-out is lauded and mystified. If anything, older founders may be subconsciously discriminated against in favor for younger founders. </p><p>In biotech, the prototypical founder is older, often a career CEO or exec coming out of a Big Pharma company. At minimum, the founders almost always have significant scientific training - a PhD can take 6-8 years, and post-docs 2-3 years each. It is less common to see founders in their 20s and you almost never see ‘youth wunderkinds’. This is in part due to the conservatism of the industry and in part because extensive scientific training is generally necessary to have enough biological insight to correctly identify an opportunity. </p></div></div></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1594517769210_420694"><p><span><strong>TECH</strong></span><strong>: Can create a new market<br></strong><span><strong>BIOTECH</strong></span><strong>: Markets are diseases and therefore public domain</strong></p></div><div><div><div data-block-type="2" id="block-yui_3_17_2_1_1594517769210_422265"><div><p>In tech, some of the most successful companies created or defined their market - a classic example being ride sharing. Once a new market is validated, other companies/copycats/fast-followers flow in. </p><p>In biotech, the market opportunities are diseases. New markets can somewhat be created (e.g., nootropics, elective medicines, Viagra) but generally speaking the markets are well known. </p></div></div></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1594517769210_423860"><p><span><strong>TECH</strong></span><strong>: Markets are winner-take-all<br></strong><span><strong>BIOTECH</strong></span><strong>: Many winners</strong></p></div><div><div><div data-block-type="2" id="block-yui_3_17_2_1_1594517769210_458802"><div><p>In tech, investors often bet on a specific horse with the hope that the horse will win the race (and all the earnings). Bifurcated markets can be especially dangerous as companies compete on pricing and ‘race to the bottom’.</p><p>In biotech, the markets are <em>so </em>large, and the unmet need so high, that there can and often are many winners in one market (disease). The classic example here are statins, which in 2020 had over $1 trillion in sales across seven market approved statins, with the best-selling Lipitor having peak sales of $12B in the mid-2000s. </p></div></div></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1594517769210_456236"><div><h2><strong>Product Strategy</strong></h2><p><span><strong>TECH</strong></span><strong>: Often develop one product at a time, focus is key <br></strong><span><strong>BIOTECH</strong></span><strong>: Portfolio approach is encouraged to de-risk company, exception is one-asset, repurposing plays</strong></p></div></div><div><div><div data-block-type="2" id="block-yui_3_17_2_1_1594517769210_482826"><div><p>Focus is crucial for any startup. However, in biotech the most successful and valuable companies often take a portfolio approach to product development - developing multiple products simultaneously. In tech, companies generally focus around one product or core offering, only differentiating once they have earned the right to do so by finding PMF with their first product.</p><p>A significant reason for this is to derisk the company against biological randomness. Instead, focus in a biotech company is usually around a core competency - e.g., a method of discovering drugs, or a way of delivering the drug - and then diversified within this core competency. For example, gene therapy company Spark Therapeutics had a core competency of AAV-based gene therapy (a virus loaded with DNA to treat a genetic disease) but leverages this competency simultaneously across multiple diseases. </p></div></div></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1594517769210_484564"><p><strong>﻿</strong><span><strong>TECH</strong></span><strong>: Outsourcing product development or engineering unadvisable<br></strong><span><strong>BIOTECH</strong></span><strong>: Common to use contractors for key experimental work</strong></p></div><div><div><div data-block-type="2" id="block-yui_3_17_2_1_1594517769210_497310"><div><p>In tech, not having someone technical on the founding team is a classic ‘no no’. You generally should have the ability to build (and therefore rapidly iterate on and improve) your core product within the team. </p><p>In biotech, it is common and often preferred to use contract research organizations (CROs) for much of your experimental work. Some experiments can only be done by specialized CROs, and they often have advantages from scale that a startup cannot hope to replicate. Building and staffing a laboratory, including the multiple six-figure machines necessary, is impracticable and unnecessary for most companies. </p><p>Virtual biotechs - companies with distributed leadership and all research outsourced to CROs - have been popular long before it became the tech zeitgeist.</p></div></div></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1594517769210_499137"><p><span><strong>TECH</strong></span><strong>: Fast-followers and copycats a significant risk<br></strong><span><strong>BIOTECH</strong></span><strong>: Strong patent protection </strong></p></div><div><div><div data-block-type="2" id="block-yui_3_17_2_1_1594517769210_570610"><div><p>In tech, being the first/best product to a new market is so important because once you validate a market’s need for a specific product, it is easy for others to copy and chip at your market share. This is especially common in traditional D2C brands, for example the many bed-in-a-box companies. </p><p>In biotech, patents are king. If you hold the key patent it is impossible for your drug to be copied. Once patents expire, however, there is a whole industry (generics) around copying drugs and selling them cheaper than the branded product. Because of the hundreds of millions it takes to develop a drug, it is almost impossible to commercialize a drug that is not able to be protected by patents, regardless of its efficacy. </p></div></div></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1594517769210_568710"><div><h2><strong>Raising, Spending, and Making Money</strong></h2><p><span><strong>TECH</strong></span><strong>: Primary burn usually people costs <br></strong><span><strong>BIOTECH</strong></span><strong>: Primary burn R&amp;D</strong></p></div></div><div><div><div data-block-type="2" id="block-yui_3_17_2_1_1594517769210_725052"><p>Biotech companies’ biggest line item is undoubtedly R&amp;D spend - funding to do research experiments necessary to find and develop their drug. This is despite the average salary in biotech also often being higher than tech’s.</p></div></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1594517769210_722809"><p><span><strong>TECH</strong></span><strong>: Series Seed and A smaller, with larger subsequent rounds to scale and win market share<br></strong><span><strong>BIOTECH</strong></span><strong>: Capital needs front-loaded, Seeds can be the size of tech Series A’s</strong></p></div><div><div><div data-block-type="2" id="block-yui_3_17_2_1_1594517769210_745080"><div><p>In tech, you can often show proof-of-concept or even begin selling your product with a small team and pre-seed capital. </p><p>Biotech Seeds can often look like tech Series As in magnitude. On the East Coast, the first rounds in biotech companies are more than often in the $10s of millions. This is because of the millions needed to hit biological milestones to push the company forward (and therefore qualify for the next stage of financing).</p></div></div></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1594517769210_742704"><p><span><strong>TECH</strong></span><strong>: Often command higher valuations early on <br></strong><span><strong>BIOTECH</strong></span><strong>: Often command lower valuations early on</strong></p></div><div><div><div data-block-type="2" id="block-yui_3_17_2_1_1594517769210_803591"><div><p>Tech valuations usually optimize for selling 10% - 25% of the company in any one financing. </p><p>In biotech, valuations are historically significantly lower, with many East Coast deals selling 50%+ of the company in one financing. Such huge dilution is less common in West Coast biotech financings, but it is more common sell 33%+ of the company in one financing. Biotech founders also often have less negotiating power here because they have to raise large amounts to bring the company to the next stage. </p></div></div></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1594517769210_805993"><p><span><strong>TECH</strong></span><strong>: Business usually has significant revenue at exit <br></strong><span><strong>BIOTECH</strong></span><strong>: Unlikely to have revenue at exit</strong></p></div><div><div><div data-block-type="2" id="block-yui_3_17_2_1_1594517769210_845025"><div><p>While the company may be far from profitable, tech companies almost always have significant revenue at exit (IPO or acquisition). </p><p>In biotech, companies almost never have revenue at exit. Instead, the value of the company is driven by the increasing probability that their drug will work (and therefore decreasing biological risk). The company is often sold or partnered years before the drug is commercialized.</p></div></div></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1594517769210_836878"><div><h2><strong>Team</strong></h2><p><span><strong>TECH</strong></span><strong>: Core team often younger, primed to take more equity over salary<br></strong><span><strong>BIOTECH</strong></span><strong>: Core team often older due to extensive scientific training, often more risk-adverse or otherwise unable to sacrifice heavily on salary </strong></p></div></div><div><div><div data-block-type="2" id="block-yui_3_17_2_1_1594517769210_824365"><div><p>In tech, there is a self-selecting group that aspire to work in or on a startup, and are primed to take the high equity with lower salary in the hope that they pick the company that will become a unicorn and make them rich, too. They are often younger …</p></div></div></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.celinehh.com/tech-vs-biotech">https://www.celinehh.com/tech-vs-biotech</a></em></p>]]>
            </description>
            <link>https://www.celinehh.com/tech-vs-biotech</link>
            <guid isPermaLink="false">hacker-news-small-sites-24262336</guid>
            <pubDate>Mon, 24 Aug 2020 16:37:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How I helped fix Canadaʼs Covid Alert app]]>
            </title>
            <description>
<![CDATA[
Score 240 | Comments 43 (<a href="https://news.ycombinator.com/item?id=24262236">thread link</a>) | @todsacerdoti
<br/>
August 24, 2020 | https://seancoates.com/blogs/how-i-helped-fix-canadas-covid-alert-app | <a href="https://web.archive.org/web/*/https://seancoates.com/blogs/how-i-helped-fix-canadas-covid-alert-app">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody text">
    <div>
<p><a href="https://pm.gc.ca/en/news/news-releases/2020/07/31/new-mobile-app-help-notify-canadians-potential-covid-19-exposure-now">On July 31st</a>, Canada's <a href="https://www.canada.ca/en/public-health/services/diseases/coronavirus-disease-covid-19/covid-alert.html">COVID Alert</a> app was made available for general use, though it does not have support for actually <em>reporting</em> a diagnosis in most provinces, yet.</p>
<p>In Quebec, we can run the tracing part of the app, and if diagnosis codes become available here, the app can retroactively report contact. It uses the tracing mechanism that <a href="https://covid19.apple.com/contacttracing">Google and Apple created together</a>, and in my opinion—at least for now—Canadians should be running this thing to help us all deal with COVID-19. I won't run it forever, but for now, it seems to me that the benefits outweigh the "government can track me" fear (it's not actually tracking you; it doesn't even know who you are), and it's enabled on my phone.</p>
<p>But, before I decided to take this position and offer up my own movement data, I wanted to be sure the app is doing what it says it's doing—at least to the extent of my abilities to be duly diligent. (Note: it's not purely <em>movement</em> data that's shared—at least without more context—but it's actual physical interactions with other people whose phones are available within the radio range of Bluetooth LE.)</p>
<p>Before installing the app on my real daily-carry phone, I decided to put it on an old phone I still have, and to do some analysis on the most basic level of communication: who is it contacting?</p>
<p>In 2015, I gave a <a href="https://prezi.com/iqwzy66rn3uo/inspect-https-with-your-own-man-in-the-middle-non-attacks/">talk</a> at <a href="https://confoo.ca/en">ConFoo</a> entitled "<em>Inspect HTTP(S) with Your Own Man-in-the-Middle Non-Attacks</em>", and this is exactly what I wanted to do here. The tooling has improved in the past 5 years, and firing up <em>mitmproxy</em>, even without ever having used it on this relatively new laptop, was a one-liner, thanks to <a href="https://nixos.org/learn.html">Nix</a>:</p>
<pre><span>nix-shell -p mitmproxy --run mitmproxy</span>
</pre>

<p>This gave me a terminal-based UI and proxy server that I pointed my old phone at (via the Wifi Network settings, under HTTP proxy, pointed to my laptop's local IP address). I needed to have mitmproxy create a Certificate Authority that it could use to generate and sign "trusted" certificates, and then have my phone trust that authority, by visiting <code>http://mitm.it/</code> in mobile Safari, and doing the certificate acceptance dance (this is even more complicated on the latest versions of iOS). Worth noting also, is that certain endpoints such as the Apple App Store appear to use <a href="https://en.wikipedia.org/wiki/HTTP_Public_Key_Pinning">Certificate Pinning</a>, so you'll want to do things like install the COVID Alert app from the App Store before turning on the proxy.</p>
<p>Once I was all set up to intercept my own traffic, I visited some <code>https://</code> URLs and saw the request flows in mitmproxy.</p>
<p>I fired up the COVID Alert app again, and noticed something strange… something disturbing:</p>
<p><img src="https://files.scoat.es/covid-tracker-traffic.png" title="COVID Alert app traffic in mitmproxy" alt="shows that the app is accessing clients.google.com"></p>
<p>In addition to the expected traffic to <code>canada.ca</code> (I noticed it's using <code>.alpha.canada.ca</code>, but I suspect that's due to the often-reported unbearably-long bureaucratic hassle in getting a <code>.canada.ca</code> TLS certificate, but that's another story), my phone, when running COVID Alert, was contacting Google.</p>
<pre><span>HEAD https://clients4.google.com/generate_204</span>
</pre>

<p>A little web searching helped me discover that this is a commonly-used endpoint that helps developers determine if the device is behind a "captive portal" (an interaction that requires log-in or payment, or at least acceptance of terms before granting wider access to the Web). I decided that this was <em>probably</em> unintended by the developers of COVID Alert, but it still bothered me that an app, designed for <em>tracking interactions between people['s devices]</em>, that the <em>government</em> wants us to run is telling Google that I'm running it, and disclosing my IP address in doing so:</p>
<p><img src="https://files.scoat.es/covid-alert-google.png" title="A request to clients.google.com, from the COVID Alert app" alt="shows that the User Agent header identifies the app as " covid="" alert="" version=""></p>
<p>(Note that the app clearly identifies itself in the <code>User-Agent</code> header.) </p>
<p>A bit more quick research turned up a <a href="https://www.priv.gc.ca/en/privacy-topics/privacy-laws-in-canada/the-personal-information-protection-and-electronic-documents-act-pipeda/pipeda-compliance-help/pipeda-interpretation-bulletins/interpretations_02/#fn50-rf">statement by Canada's Privacy Commissioner</a>:</p>
<blockquote><p>An Internet Protocol (IP) address can be considered personal information if it can be associated with an identifiable individual. For example, in one complaint finding, we determined that some of the IP addresses that an internet service provider (ISP) was collecting were personal information because the ISP had the ability to link the IP addresses to its customers through their subscriber IDs.</p></blockquote>

<p>It's not too difficult to imagine that Google <em>probably</em> has enough data on Canadians for this to be a real problem.</p>
<p>I discovered that this app is maintained by the <a href="https://digital.canada.ca/">Canadian Digital Service</a>, and that the <a href="https://github.com/cds-snc/covid-alert-app">source code is on GitHub</a>, but that the <a href="https://github.com/cds-snc/covid-alert-app/search?q=clients3.google.com&amp;unscoped_q=clients3.google.com&amp;type=Code">code itself didn't directly contain any references to <code>clients3.google.com</code></a>.</p>
<p>It's a <a href="https://reactnative.dev/">React Native</a> app, and I figured that the call out to Google must be in one of the <a href="https://github.com/cds-snc/covid-alert-app/blob/master/package.json">dependencies</a>, which—considering the norm with JavaScript apps—are pleasantly restrained mostly to React itself. I had no idea which of these libraries was calling out to Google.</p>
<p>Now, I could have run this app on the iOS Simulator (which did I end up doing to test my patches, below), but I thought "let's see what my <em>actual</em> phone is doing." I threw caution to the wind, and I ran <a href="https://checkra.in/">checkra1n</a> on my <em>old</em> phone, which gave me ssh access, which in turn allowed me to copy the app's application bundle to my laptop, where I could do a little more analysis (note the app is bundled as <em>CovidShield</em> because it was previously <a href="https://www.covidshield.app/">developed by volunteers at Shopify</a> and was then renamed by CDS (or so I gather, anyway)).</p>
<pre><span>~/De/C/iphone/CovidShield.app ▶ grep -r 'clients3.google.com' *</span>
<span>main.jsbundle:__d(function(g,r,i,a,m,e,d){Object.defineProperty(e,"__esModule",{value:!0}),</span>
<span>e.default=void 0;var t={reachabilityUrl:'https://clients3.google.com/generate_204',</span>
<span>reachabilityTest:function(t){return Promise.resolve(204===t.status)},reachabilityShortTimeout:5e3,</span>
<span>reachabilityLongTimeout:6e4,reachabilityRequestTimeout:15e3};e.default=t},708,[]);</span>
</pre>

<p>(Line breaks added for legibility.) Note <code>reachabilityUrl:'https://clients3.google.com/generate_204</code>. Found it! A bit more searching led me to a package called <code>react-native-netinfo</code> (which was directly in the above-linked <code>package.json</code>), and its <a href="https://github.com/react-native-community/react-native-netinfo/blob/4e3e9813fbae89013bbeee6470b005b6d923e022/src/internal/defaultConfiguration.ts#L2">default configuration</a> that sets the <code>reachabilityUrl</code> to Google.</p>
<p>Now that I knew where it was happening, I could fix it.</p>
<p>To make this work the same way, we needed a reliable <code>204</code> endpoint that the app could hit, and to keep with the expectation that this app should not "leak" data outside of <code>canada.ca</code>, I ended up <a href="https://github.com/cds-snc/covid-alert-server/pull/241">submitting a patch</a> for the <a href="https://github.com/cds-snc/covid-alert-server">server side code</a> that the app calls. (It turns out that this was not necessary after all, but I'm still glad I added this to my report.)</p>
<p>I also <a href="https://github.com/cds-snc/covid-alert-app/issues/1003">patched</a>, and tested the app code itself via the iOS Simulator.</p>
<p>I then submitted a write-up of what was going wrong and why it's bad, to the main app repository, as <a href="https://github.com/cds-snc/covid-alert-app/issues/1003">cds-snc/covid-alert-app issue 1003</a>, and felt pretty good about my COVID Civic Duty of the day.</p>
<p>The fine folks at the Canadian Digital Service seemed to recognize the problem and agree that it was something that needed to be addressed. A few very professional back-and-forths later (I'll be honest: I barely knew anything about the CDS and I expected some runaround from a government agency like this, and I was pleasantly surprised), we landed on a solution that simply didn't call the reachability URL at all, and they <a href="https://github.com/cds-snc/covid-alert-app/releases">released a version of the app</a> that fixed my issue!</p>
<p><img src="https://files.scoat.es/covid-alert-release.jpg" title="COVID Alert release notes showing my fix" alt=""></p>
<p>With the new version loaded, I once again checked the traffic and can confirm that the new version of the app does not reach out to anywhere but <code>.canada.ca</code>.</p>
<p><img src="https://files.scoat.es/covid-alert-no-google.png" alt="A mitmproxy flow showing traffic to canada.ca and not google.com"></p>
</div>
    </div></div>]]>
            </description>
            <link>https://seancoates.com/blogs/how-i-helped-fix-canadas-covid-alert-app</link>
            <guid isPermaLink="false">hacker-news-small-sites-24262236</guid>
            <pubDate>Mon, 24 Aug 2020 16:29:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Vitamin D, part 2: Shannon's story]]>
            </title>
            <description>
<![CDATA[
Score 384 | Comments 271 (<a href="https://news.ycombinator.com/item?id=24261948">thread link</a>) | @usefulcat
<br/>
August 24, 2020 | https://www.devaboone.com/post/vitamin-d-part-2-shannon-s-story?postId=5f39453f8d01fe00170023fe | <a href="https://web.archive.org/web/*/https://www.devaboone.com/post/vitamin-d-part-2-shannon-s-story?postId=5f39453f8d01fe00170023fe">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-hook="post-description"><article><div><div data-rce-version="7.16.2"><div dir="ltr"><div><div id="viewer-clbfl"><div><div data-hook="imageViewer" role="button" tabindex="0"><div role="img"><p><img data-pin-url="https://www.devaboone.com/post/vitamin-d-part-2-shannon-s-story?postId=5f39453f8d01fe00170023fe" data-pin-media="https://static.wixstatic.com/media/3e0600_cc86ea12bc4248faaa2a0e149d1a9ef4~mv2.jpg/v1/fit/w_900,h_450,al_c,q_80/file.png" src="https://static.wixstatic.com/media/3e0600_cc86ea12bc4248faaa2a0e149d1a9ef4~mv2.jpg/v1/fit/w_300,h_300,al_c,q_5/file.jpg"></p><svg viewBox="0 0 19 19" xmlns="http://www.w3.org/2000/svg"><path d="M15.071 8.371V4.585l-4.355 4.356a.2.2 0 0 1-.283 0l-.374-.374a.2.2 0 0 1 0-.283l4.356-4.355h-3.786a.2.2 0 0 1-.2-.2V3.2c0-.11.09-.2.2-.2H16v5.371a.2.2 0 0 1-.2.2h-.529a.2.2 0 0 1-.2-.2zm-6.5 6.9v.529a.2.2 0 0 1-.2.2H3v-5.371c0-.11.09-.2.2-.2h.529c.11 0 .2.09.2.2v3.786l4.355-4.356a.2.2 0 0 1 .283 0l.374.374a.2.2 0 0 1 0 .283L4.585 15.07h3.786c.11 0 .2.09.2.2z" fill="#000" fill-rule="nonzero"></path></svg></div></div></div></div><h3 id="viewer-7adfi">How much Vitamin D should I take? This is still the looming question, and it’s time to address it. </h3><p id="viewer-9k73p">First, though, imagine that someone in a public forum online asked me, “How much metoprolol (a common blood pressure medication) should I take?” It would be clear that I could not give a real answer. I could give a heavily qualified blanket statement that covered indications and common starting doses, and then recommended speaking with a doctor regarding a personalized dosage. I wouldn’t give a specific dose. But no one would expect me to.  Metoprolol is a medication, and medications are usually prescribed by a physician.</p><p id="viewer-7tpp4">We think of vitamins and supplements differently. A few readers have made comments like this: “I understand that the evidence for Vitamin D in healthy adults doesn’t really show a benefit, but I take Vitamin D because it probably won’t hurt me, and it might help.” This is a common sentiment regarding supplements, but not a statement that most people would make about metoprolol, or any prescribed medication.  Medications are generally understood to be substances taken in response to a specific disease or condition, and we hope that research has shown that they work. Supplements are given a pass; we take them if they might help, even though they may not be needed. </p><p id="viewer-2fbtq"><strong>But Vitamin D should be thought of as a medication</strong>, despite being sold over-the-counter in the supplements aisle. </p><p id="viewer-5549c">To illustrate this, let me introduce Shannon. </p><p id="viewer-518ch">In the fall of 2018, Shannon R. was the special education director for a large Arizona school district. Normally energetic and expressive, the otherwise healthy 38-year-old began having an odd and disturbing symptom: difficulty speaking. Her husband and two boys would ask her questions, and though understanding the question, she was unable to formulate the words to respond. </p><p id="viewer-e7f4v">Milder problems had started over the summer, when she felt more tired than usual. As the months passed, new symptoms appeared: palpitations, insomnia, anxiety, along with cognitive deficits – “like my brain wouldn’t function,” she recalled. Her heart rate, normally in the 60s, now often stayed in the 90s, even while in bed. She barely slept at night and lost nearly 50 pounds. By mid-semester, she was often unable to work. At around 1 AM one October morning, she was taken to the emergency room for a racing heart. When there, she had difficulty responding to the doctors’ and nurses’ questions. After a full workup, the doctors had no explanation, so they resorted to what doctors often reach for when confronted with mystery ailments: psychiatric illness. </p><p id="viewer-fu7id">Shannon would be hospitalized several times for “catatonia,” a general symptom describing difficulty with speaking or moving that is caused by certain psychiatric conditions like depression and schizophrenia. Though she had never exhibited mental illness before, doctors assumed that Shannon had developed a severe psychiatric disorder. </p><p id="viewer-4pb27">Shannon’s husband, as well as her new psychiatrist, doubted this diagnosis, and sought second and third opinions. By the time she contacted me four months later, they had consulted multiple specialists at three different hospitals around the state, but still did not have an explanation for her physical and mental decline. There was something that all of the doctors had noticed, though. Her blood calcium levels were often mildly to moderately elevated above normal, up to 11.1 mg/dl (normal for her age would be up to 10.2 mg/dl). The cause of this was unclear, but her doctors did not believe that this incidental finding was relevant to her current issues, and did not pursue it. <strong>Shannon was not taking calcium supplements at all throughout this time, but her levels were still high.</strong> When she emailed me in February 2019, she was desperate for answers and thought the calcium levels might be a clue. </p><p id="viewer-1miap">My specialty is parathyroid disease, which is the most common cause of high calcium. Based on her parathyroid hormone tests, it did not appear that Shannon had parathyroid disease. But she had high calcium levels, and the rise in those levels correlated with the onset of her symptoms. High calcium levels might initially appear to be a good thing, since we need calcium for our bones. But they are not. High blood calcium levels usually indicate a serious illness.</p><div id="viewer-ep36c"><div><div data-hook="imageViewer" role="button" tabindex="0"><div role="img"><p><img data-pin-url="https://www.devaboone.com/post/vitamin-d-part-2-shannon-s-story?postId=5f39453f8d01fe00170023fe" data-pin-media="https://static.wixstatic.com/media/3e0600_ab9b4f52fab24f4aaf3be163ee13d0ca~mv2.jpg/v1/fit/w_900,h_434,al_c,q_80/file.png" src="https://static.wixstatic.com/media/3e0600_ab9b4f52fab24f4aaf3be163ee13d0ca~mv2.jpg/v1/fit/w_300,h_300,al_c,q_5/file.jpg"></p><svg viewBox="0 0 19 19" xmlns="http://www.w3.org/2000/svg"><path d="M15.071 8.371V4.585l-4.355 4.356a.2.2 0 0 1-.283 0l-.374-.374a.2.2 0 0 1 0-.283l4.356-4.355h-3.786a.2.2 0 0 1-.2-.2V3.2c0-.11.09-.2.2-.2H16v5.371a.2.2 0 0 1-.2.2h-.529a.2.2 0 0 1-.2-.2zm-6.5 6.9v.529a.2.2 0 0 1-.2.2H3v-5.371c0-.11.09-.2.2-.2h.529c.11 0 .2.09.2.2v3.786l4.355-4.356a.2.2 0 0 1 .283 0l.374.374a.2.2 0 0 1 0 .283L4.585 15.07h3.786c.11 0 .2.09.2.2z" fill="#000" fill-rule="nonzero"></path></svg></div></div></div></div><p id="viewer-5d4om"><em>Calcium is known for its role in bone health, but its role in the brain and nervous system is just as important. Calcium levels need to be within a small range; anything too high or too low can cause problems.  Image by </em><a href="https://www.bigstockphoto.com/search/?contributor=madrock24" target="_blank" rel="noopener">madrock24</a> on <a href="http://bigstockphoto.com/" target="_blank" rel="noopener"><u>bigstockphoto.com</u></a></p><p id="viewer-115r5">Most patients with high calcium develop fatigue and body aches, and just generally feel bad. They may develop insomnia and palpitations, a feeling like the heart is racing. Some have more severe neurologic symptoms like muscle weakness and problems with balance, and some have psychiatric symptoms like depression and anxiety. Untreated high calcium can also lead to kidney stones, kidney failure, cardiac arrhythmias, headaches, and gastrointestinal problems. Shannon had some of the classic symptoms, as well as what appeared to be more severe “psychiatric” symptoms. I suspected they were all related to her calcium levels. </p><p id="viewer-bac7q">But why was her calcium high? The parathyroid glands exist to regulate calcium, and they do a very good job at it, keeping blood calcium within a tight range. Usually, a problem with calcium indicates a problem with the parathyroids. But over the last few years I have had more patients coming to me with high calcium related to something else: Vitamin D. </p><p id="viewer-6d1js"><strong>Vitamin D is a steroid hormone</strong>, in the same category as sex hormones like estrogen and testosterone, and glucocorticoids like the stress hormone cortisol. Steroid hormones are all made from cholesterol, and looking at their molecular structures, you can see the similarities. </p><div id="viewer-6s0p9"><div><div data-hook="imageViewer" role="button" tabindex="0"><div role="img"><p><img data-pin-url="https://www.devaboone.com/post/vitamin-d-part-2-shannon-s-story?postId=5f39453f8d01fe00170023fe" data-pin-media="https://static.wixstatic.com/media/3e0600_1ef7e9201aae4b54be7b21f6f218627e~mv2.png/v1/fit/w_1586,h_972,al_c,q_80/file.png" src="https://static.wixstatic.com/media/3e0600_1ef7e9201aae4b54be7b21f6f218627e~mv2.png/v1/fit/w_300,h_300,al_c,q_5/file.png"></p><svg viewBox="0 0 19 19" xmlns="http://www.w3.org/2000/svg"><path d="M15.071 8.371V4.585l-4.355 4.356a.2.2 0 0 1-.283 0l-.374-.374a.2.2 0 0 1 0-.283l4.356-4.355h-3.786a.2.2 0 0 1-.2-.2V3.2c0-.11.09-.2.2-.2H16v5.371a.2.2 0 0 1-.2.2h-.529a.2.2 0 0 1-.2-.2zm-6.5 6.9v.529a.2.2 0 0 1-.2.2H3v-5.371c0-.11.09-.2.2-.2h.529c.11 0 .2.09.2.2v3.786l4.355-4.356a.2.2 0 0 1 .283 0l.374.374a.2.2 0 0 1 0 .283L4.585 15.07h3.786c.11 0 .2.09.2.2z" fill="#000" fill-rule="nonzero"></path></svg></div></div></div></div><p id="viewer-3upia">Like the other steroid hormones, Vitamin D acts on multiple organs and only tiny amounts of the molecule are required to have substantial effects. Anyone who has gone through puberty understands the impressive physiologic changes brought about by relatively small shifts in hormone levels. Not surprisingly, most steroid hormones are considered medications that require a physician's order. Vitamin D is an exception. In the U.S., high dose Vitamin D can be purchased by anyone, without a prescription, in most drugstores and grocery stores. It is called a dietary supplement, which sounds safer than a medication, but this is misleading. Due to its role in calcium absorption, high dose Vitamin D can cause serious problems. </p><p id="viewer-21t00">Eventually we worked out what happened with Shannon: In 2013 she was diagnosed with mild osteopenia, a thinning of the bones that can be a precursor to osteoporosis. Her Vitamin D was low at the time, so her physician started her on over-the-counter Vitamin D supplementation at 5000 international units (IUs) daily. Five years later, she was still on this dose, and her blood Vitamin D level had risen to 79 ng/ml. This level is within what many labs call the normal range, between 30 and 100 ng/ml, but levels above 70 are almost always a result of high dose supplementation, and I have seen toxicity with levels between 70 and 100 ng/ml. (A better “normal range” based on what I have seen would probably be between 30 and 60.) Vitamin D builds up over time, so the longer someone is on a high dose, the more likely she is to develop toxicity. Shannon’s calcium levels began rising in the fall of 2018, when her severe symptoms developed. </p><p id="viewer-c0tav">Ironically, Shannon started to recover because she became too sick to worry about taking her vitamins, and stopped taking Vitamin D in October. It often takes many months for high Vitamin D levels to drop, and it took six months for Shannon’s level to fall into the 50s. As it fell, her calcium level gradually started to normalize, and her symptoms slowly resolved. By May, she was starting to feel like herself again. </p><p id="viewer-208hf">I spoke with Shannon recently. All of the symptoms that characterized her frightening and rapid decline in health had resolved completely. Listening to this animated woman, it was difficult to imagine her unable to talk. The only lingering effects appeared to be a wariness of physicians and distrust of vitamins, both understandable. Shannon agrees that Vitamin D should be treated like a medication. “It’s a hormone!” she exclaimed. “If I had to take ‘Hormone D’, I would have questioned my doctor about why I needed it.” Shannon is now committed to educating others about Vitamin D. </p><p id="viewer-16oc8">Of course, there is a selection bias in who comes to me. There are people out there doing just fine on 5000 units of Vitamin D daily. I only see the ones who develop high calcium levels. But I see enough of them to know that this is not an exceptionally rare occurrence. I have been to lectures in which physicians have claimed that Vitamin D toxicity almost never occurs. In my experience, this is false. I have seen many cases of Vitamin D toxicity in people who were taking the recommended dose from an over-the-counter bottle.</p><p id="viewer-8pgar">Unfortunately, none of those patients were warned about the potential for Vitamin D to cause high calcium. They all believed that they were taking a supplement to improve health and that there was very little risk. Supplements don’t require prescriptions, and most do not have the warning labels that accompany medications. For Vitamin D, a steroid hormone, that may need to change. </p><p id="viewer-4ie1g"><strong>So, how much Vitamin D should you take? </strong></p><p id="viewer-9iecb">Vitamin D should be approached like a medication that is used to treat low calcium levels and low levels of the hormone called Vitamin D. The dose depends on your calcium and current Vitamin D levels, and needs to be adjusted appropriately in response to those levels. For my patients, I can and do give very specific recommendations on Vitamin D doses. In future posts, I can go through how I decide that. I will not give any recommendation without first knowing Vitamin D and calcium levels. </p><p id="viewer-ecd8g"><strong>Edited to add: This post should not be taken as a …</strong></p></div></div></div></div></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.devaboone.com/post/vitamin-d-part-2-shannon-s-story?postId=5f39453f8d01fe00170023fe">https://www.devaboone.com/post/vitamin-d-part-2-shannon-s-story?postId=5f39453f8d01fe00170023fe</a></em></p>]]>
            </description>
            <link>https://www.devaboone.com/post/vitamin-d-part-2-shannon-s-story?postId=5f39453f8d01fe00170023fe</link>
            <guid isPermaLink="false">hacker-news-small-sites-24261948</guid>
            <pubDate>Mon, 24 Aug 2020 16:03:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Mechanist's Guide to the Coronavirus Genome]]>
            </title>
            <description>
<![CDATA[
Score 40 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24261853">thread link</a>) | @apsec112
<br/>
August 24, 2020 | https://csvoss.com/a-mechanists-guide-to-the-coronavirus-genome | <a href="https://web.archive.org/web/*/https://csvoss.com/a-mechanists-guide-to-the-coronavirus-genome">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
    <p>Hello and welcome to my Coronavirus Genome Walkthrough.</p>

<p>(Hoping someone comes out with that Vaccine Speedrun soon. This boss battle is really shaping up to be an intense one and we’ll need all the artifacts we can get.)</p>

<p>Here, I aim to provide a <em>mechanistic explanation</em> of the SARS-CoV-2 genome’s syntax and semantics. Let’s investigate what the SARS-CoV-2 viral genome actually does as if reading through code like a compiler, from nucleotides to amino acids all the way to proteins. From the four base pairs all the way up to the completed protein-coated virus, what is a virus like this is actually made of on the concrete, physical level?</p>

<h3 id="understanding-a-full-system">Understanding a Full System</h3>

<p>The underlying purpose of this essay is less about the coronavirus <em>per se</em> and more about how having a small—but functionally complete—piece of viral RNA to analyze gives me a unique opportunity to try to understand a complete self-replicating machine from scratch. This is not a feat that I would have the fortitude to manually replicate with the full human genome, for example—but the coronavirus genome, like the <a href="http://openworm.org/">nematode genome</a>, is small enough that we stand a chance at building a complete understanding. The task is perhaps akin to <a href="https://distill.pub/2018/building-blocks/">interpretability</a>, but for biological systems instead of artificial neural networks.</p>

<p>As a consequence, this essay is not intended to produce epidemiological conclusions; there are plenty of other sources for that! This essay is about fully understanding a biological system at the chemical and physical level.</p>

<h3 id="play-curiosity-and-mechanical-understanding">Play, Curiosity, and Mechanical Understanding</h3>

<p>Throughout this essay, I follow my curiosity in the style of <a href="https://en.wikipedia.org/wiki/Serious_play">serious play</a>: if I <a href="https://www.readthesequences.com/Noticing-Confusion-Sequence">notice I’m confused</a> about something, I look into it and explore it until I’m satisfied that I now understand, and that my understanding is <em>a <a href="https://plato.stanford.edu/entries/science-mechanisms/#ConMec">mechanical</a> understanding</em>. Things are made of stuff! It turns out that we can understand that stuff!</p>

<p>I may skip over some details that were not confusing to me during my own research, but your journey need not be the same as mine. If you’re confused about something while reading this essay, I encourage you to go and look it up! <a href="http://agentyduck.blogspot.com/2015/06/the-art-of-noticing.html">Notice</a> when your curiosity arises; that’s the meditation. It’s always possible to discover the <a href="http://samoburja.com/how-to-find-the-frontier-of-knowledge/">frontier of your own knowledge</a> and to expand it.</p>

<p>This all, at least, has been my intention as I set out to create this piece! As Ken Liu said of his philosophy while translating The Three-Body Problem, “I may not have succeeded, but these were the standards I had in mind as I set about my task.”</p>

<p>Part 1, here, covers just the genome and its translation to proteins. I hope to also write a Part 2 which would cover the structure and function of those proteins, their protein-protein interactions, and the full viral life cycle.</p>

<!--Finally, as you may already be able to tell, this essay also serves as a philosophical manifesto-by-example of how to think concretely about problems in biology. Along the way, I give some of my thoughts about the role of thermodynamics in molecular biology, legibility in complex systems, pedagogy, and the future of computational modeling.-->

<p>Let’s get started.</p>



<p>As a reminder, SARS-CoV-2 is a <em>positive-sense single-stranded RNA virus</em>.</p>



<p>What does this mean we can expect?</p>

<ol>
  <li><em>Single-stranded</em>: Its genome is a single strand of <a href="https://en.wikipedia.org/wiki/RNA">RNA</a> (ssRNA).</li>
  <li><em>Positive-sense</em>: That single strand of RNA can be immediately translated into protein by the ribosomes of the cell it infects.</li>
</ol>

<p>From this we can also infer that one of the proteins the virus encodes for must be <em>RNA-dependent RNA polymerase</em> (RdRP), a protein which synthesizes new RNA given an RNA template. That’s right: RNA → RNA. However, according to the <a href="https://en.wikipedia.org/wiki/Central_dogma_of_molecular_biology">central dogma of molecular biology</a>, isn’t RNA → RNA an unconscionable heresy? Correspondingly, RdRP is not naturally found in cells! All known positive-sense ssRNA viruses therefore <em>must encode</em> RdRP in order to successfully commit this heresy.</p>



<p>…Wait a minute, the phrase “positive-sense ssRNA virus” implies the existence of <em>negative-sense</em> viruses. If those don’t encode their proteins directly, how can they possibly work?</p>

<h2 id="positive-sense-and-negative-sense">Positive sense and negative sense</h2>

<p>Negative-sense ssRNA viruses also exist! Influenza, Ebola, and measles are examples.</p>



<p>The inner contents of <em>negative-sense</em> ssRNA viruses consist not of an RNA genome but of a <em>ribonucleoprotein</em>, which incorporates both an RNA genome as well as a cohort of viral proteins capable of replicating RNA. Unlike positive-sense ssRNA viruses, negative-sense ssRNA viruses must travel with a working copy of their RNA-replicating proteins. This ribonucleoprotein has enzymatic activity!</p>

<h2 id="rdrp-as-drug-target">RdRP as drug target</h2>

<p>Since RdRP has (as far as I know) no legitimate purpose in human cells and is not naturally coded by them, might it offer a potential target for novel antiviral drugs?</p>

<p><a href="https://pubmed.ncbi.nlm.nih.gov/24102407/">Velkov et al. 2014</a> explores RdRP as a drug target for antivirals against the <a href="https://en.wikipedia.org/wiki/Henipavirus">Hendra virus</a>, a negative-sense ssRNA virus, though I am unable to find the full text.</p>

<!-- <div class="unfurl-embed-info-media-default gallery-item-selectable"><img class="unfurl-embed-card-feature-image" src="https://cdn.ncbi.nlm.nih.gov/pubmed/persistent/pubmed-meta-image.png"><div class="unfurl-embed-card-title unfurl-embed-card-title-default notranslate"><a href="https://pubmed.ncbi.nlm.nih.gov/24102407/">The RNA-dependent-RNA Polymerase, an Emerging Antiviral Drug Target for the Hendra Virus - PubMed</a></div><div class="unfurl-embed-card-description unfurl-embed-card-description-default notranslate"><div style="overflow: hidden; text-overflow: ellipsis; -webkit-box-orient: vertical; display: -webkit-box; -webkit-line-clamp: 2;">Australia is facing a major national medical challenge with the emergence of the Hendra virus (HeV) as a medically and economically important pathogen of humans and animals. Clinical symptoms of human HeV infection can include fever, hypotension, dizziness, encephalitis, respiratory haemorrhage and …</div></div><div class="unfurl-embed-card-url notranslate">pubmed.ncbi.nlm.nih.gov</div></div> -->

<blockquote>
  <p>This review examines the current knowledge based on the multi-domain architecture of the Hendra RdRP and highlights which essential domain functions represent tangible targets for drug development against this deadly disease.</p>
</blockquote>

<p>There must be some reason that developing antivirals against this protein is technically (or socially) complicated, or I’d have expected us to do it by now – there are a lot of RNA viruses that this drug target could theoretically hit. Flagging this discrepancy for further research.<sup id="fnref:2" role="doc-noteref"><a href="#fn:2">1</a></sup></p>



<p>Back to SARS-CoV-2! First, let’s get us a genome. Obviously this virus has seen some mutations as it’s spread around, as you can explore at <a href="https://nextstrain.org/ncov/global">NextStrain</a>, so we’ve technically got choices as to which one to analyze. For this thread I’ll just stick to analyzing <em>one</em> version of the genome: Wuhan-Hu-1.</p>

<p>As a reminder, each <code>A</code>, <code>G</code>, <code>C</code>, and <code>T</code> in a genome is one of the four <a href="https://en.wikipedia.org/wiki/Nucleotide">nucleotides</a>: <a href="https://en.wikipedia.org/wiki/Adenine">adenine</a>, <a href="https://en.wikipedia.org/wiki/Guanine">guanine</a>, <a href="https://en.wikipedia.org/wiki/Cytosine">cytosine</a>, and <a href="https://en.wikipedia.org/wiki/Thymine">thymine</a>. There are actually <a href="https://www.scripps.edu/romesberg/publications.html">plenty of ways to engineer</a> different <a href="https://pubmed.ncbi.nlm.nih.gov/22850726/">unnatural base pair systems</a> by adding <a href="https://science.sciencemag.org/content/363/6429/884">artificial nucleotides</a>, and these can even be integrated into <a href="https://www.pnas.org/content/98/9/4922">transcription</a> and <a href="https://www.nature.com/articles/nature24659">translation</a>, but <a href="https://carlbrannen.wordpress.com/2007/06/13/why-does-dna-only-use-4-nucleotides/">for</a> <a href="https://dreamerbiologist.wordpress.com/2013/02/16/why-did-nature-settle-on-just-four-nucleotides/">whatever</a> <a href="https://www.pnas.org/content/114/32/E6476">reason</a>, these four <a href="https://www.nature.com/articles/s41467-018-07389-2">and not others</a> are <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3331698/">what life ultimately ended up with</a>.</p>

<p><img src="https://csvoss.com/images/nucleotides.png"></p>
<p><small>The four nucleotides in DNA.</small></p>

<p>The genome of Wuhan-Hu-1 is available from <a href="https://www.ncbi.nlm.nih.gov/nuccore/MN908947.3">NCBI GenBank</a>. Since SARS-CoV-2 is an RNA virus, each <code>T</code> in this string technically represents a <code>U</code>, for <a href="https://en.wikipedia.org/wiki/Uracil">uracil</a>, RNA’s information-equivalent of thymine. The genome sequence is therefore:</p>

<div><div><pre><code>1     AUUAAAGGUU UAUACCUUCC CAGGUAACAA ACCAACCAAC UUUCGAUCUC UUGUAGAUCU
61    GUUCUCUAAA CGAACUUUAA AAUCUGUGUG GCUGUCACUC GGCUGCAUGC UUAGUGCACU
121   CACGCAGUAU AAUUAAUAAC UAAUUACUGU CGUUGACAGG ACACGAGUAA CUCGUCUAUC

...

29761 ACAGUGAACA AUGCUAGGGA GAGCUGCCUA UAUGGAAGAG CCCUAAUGUG UAAAAUUAAU
29821 UUUAGUAGUG CUAUCCCCAU GUGAUUUUAA UAGCUUCUUA GGAGAAUGAC AAAAAAAAAA
29881 AAAAAAAAAA AAAAAAAAAA AAA
</code></pre></div></div>

<p><a target="blank" href="https://benchling.com/s/seq-28k9llmwnY475iv7ogwF/edit">Follow along with the genome »</a></p>

<p>That’s 29,903 nucleotides. Since there are only four possible nucleotides, we can estimate the information compression value of each nucleotide at approximately 2 bits; the virus’s genome therefore requires only 7.5 kilobytes to store. That’s roughly as much data, byte for byte, as there are characters in this essay up to this point!</p>

<!-- <img src="https://s3-us-west-2.amazonaws.com/courses-images/wp-content/uploads/sites/110/2016/05/02212445/Figure_03_05_03.png"> -->

<p>Lay out those 29,903 nucleobases along a ribose-phosphate backbone, reading them left to right <a href="https://en.wikipedia.org/wiki/Directionality_(molecular_biology)">from the 5’ end to the 3’ end</a>, and bam – if that single molecule* were teleported into a cell, that’s 100% chemically sufficient** to infect a person with the plague du jour.</p>

<p>*plus the 5’ cap, discussed below</p>

<p>**modulo viral load effects??</p>

<p><img src="https://csvoss.com/images/polynucleotide.png"></p>
<p><small>How to interpret the Wuhan-Hu-1 genome as a complete molecule.</small></p>

<h2 id="poly-a-tail">Poly-A tail</h2>

<p>First question, and perhaps the most obvious one to the naked eye – what’s with all the <code>AAAAA</code> at the end of the viral genome?</p>

<div><div><pre><code>29821 ...                                                ... AAAAAAAAAA
29881 AAAAAAAAAA AAAAAAAAAA AAA
</code></pre></div></div>
<p><a target="blank" href="https://benchling.com/s/seq-28k9llmwnY475iv7ogwF/edit">Follow along with the genome »</a></p>

<p>It’s… yelling at us? Is it… suffering? Should we <a href="https://reducing-suffering.org/is-there-suffering-in-fundamental-physics/">help</a>?</p>

<p>Simple: It’s a <a href="https://bioinformatics.stackexchange.com/questions/11227/why-does-the-sars-cov2-coronavirus-genome-end-in-aaaaaaaaaaaaaaaaaaaaaaaaaaaaaaa">3’ poly-A tail</a>! This <a href="https://en.wikipedia.org/wiki/Polyadenylation">long tail of adenosine monomers</a> is extremely common in both our own cells and in RNA viruses.</p>

<p>Our own messenger RNA (mRNA) has a poly-A tail when it’s freshly produced in the nucleus so as to slow its degradation by the cell, allowing it to last long enough to be transcribed into protein. Naturally, if you’re a positive-strand RNA virus, you’re also going to want to last long enough to be transcribed into protein – so, you need the same feature, yourself.</p>

<p>Genome 0.11% explained. So far so good!</p>

<h2 id="5-cap">5’ cap</h2>

<p>While we’re discussing chemical features of mRNA, note that the viral genome presumably must also have a <a href="https://en.wikipedia.org/wiki/Five-prime_cap">5’ cap</a> – an extra <a href="https://en.wikipedia.org/wiki/7-Methylguanosine">7-methylguanosine</a> at the 5’ end of its RNA strand – just like mRNAs do.</p>

<p><img src="https://csvoss.com/images/5primecap.png"></p>
<p><small>A 5' cap, consisting of a 7-methylguanosine as well as methylation of the first two ribose sugars.</small></p>

<p>The cap is not directly shown in the viral genome sequence or mentioned in NCBI GenBank, but it is referenced in multiple papers discussing coronaviral genomes:</p>

<blockquote>
  <p>Since 2003, the outbreak of severe acute respiratory syndrome coronavirus has drawn increased attention and stimulated numerous studies on the molecular virology of coronaviruses. Here, we review the current understanding of the mechanisms adopted by coronaviruses to produce the 5′-cap structure and methylation modification of viral genomic RNAs.</p>
</blockquote>



<blockquote>
  <p>Coronaviruses possess a cap structure at the 5′ ends of viral genomic RNA and subgenomic RNAs, which is generated through consecutive methylations by virally encoded guanine-N7-methyltransferase (N7-MTase) and 2′-O-methyltransferase (2′-O-MTase). The coronaviral N7-MTase is unique for its physical linkage with an exoribonuclease (ExoN) harbored in nonstructural protein 14 (nsp14) of coronaviruses.</p>
</blockquote>



<blockquote>
  <p>Here, we have reconstituted complete SARS-CoV mRNA cap methylation <em>in vitro</em>.</p>
</blockquote>



<p>Like the poly-A tail, the 5’ cap helps the genome to be recognized and translated by ribosomes rather than destroyed by the cell’s immune response.</p>

<p>How does the virus even ensure that it receives a 5’ cap and a poly-A tail, not to mention its outer coat? Hopefully these questions will be resolved by our review of its genes… let’s move on to look at those!</p>



<p>Per the “Features” section of the genome, again from <a href="https://www.ncbi.nlm.nih.gov/nuccore/MN908947.3">NCBI GenBank</a>, here are the identifiable genes in this genome, in order:</p>

<ol>
  <li><code>Orf1ab</code> (for <a href="https://www.ncbi.nlm.nih.gov/protein/1791269089">orf1ab polyprotein</a>)</li>
  <li><code>S</code> (for <a href="https://www.ncbi.nlm.nih.gov/protein/1791269090">surface glycoprotein</a>)</li>
  <li><code>Orf3…</code></li></ol></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://csvoss.com/a-mechanists-guide-to-the-coronavirus-genome">https://csvoss.com/a-mechanists-guide-to-the-coronavirus-genome</a></em></p>]]>
            </description>
            <link>https://csvoss.com/a-mechanists-guide-to-the-coronavirus-genome</link>
            <guid isPermaLink="false">hacker-news-small-sites-24261853</guid>
            <pubDate>Mon, 24 Aug 2020 15:55:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Being OK with not being extraordinary]]>
            </title>
            <description>
<![CDATA[
Score 709 | Comments 333 (<a href="https://news.ycombinator.com/item?id=24261826">thread link</a>) | @tmatthe
<br/>
August 24, 2020 | https://www.tiffanymatthe.com/not-extraordinary | <a href="https://web.archive.org/web/*/https://www.tiffanymatthe.com/not-extraordinary">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="skip-nav"><p><time>23.08.2020</time> — <a href="https://www.tiffanymatthe.com/tags/mindset">Mindset</a> — <span>2<!-- --> min read</span></p><section><img src="https://www.tiffanymatthe.com/static/c239dad4f9476bf8d02961e957aa71cf/a6c62/rock-climbing.jpg"><p>The internet always highlights the first place winners, the billionaires, the award-winning artists, the best-selling authors, the largest philanthropists, the extraordinary. Their stories are ones of success, of inspiration. They show us what is possible, and push us to achieve more.</p><p>But I don't feel inspired when I see extraordinary. I feel disappointed, jealous. My constant exposure to these amazing stories of success has normalized the extraordinary. I started comparing myself to these "normal" extraordinary people, and wondered why I was not them. This disappointment would incite me to take action, but after a few days of hard work, I would just quit. Quitting was easier; it helped me avoid thinking about the extraordinary and the negative dark clouds that I had shrouded it with.</p><p>This mentality was self-defeating. No one starts off as extraordinary, so that meant I quit a lot in the past. Over time, I came to realize two things:</p><ol><li>extraordinary as I perceived it was one-dimensional and unrealistic,</li><li>to improve, extraordinary could not be my end goal.</li></ol><p><strong>We need to redefine extraordinary.</strong> Extraordinary is often defined by the internet as a permanent trait someone has. They seemed to have been born with it, and extraordinary permeates their every pore. </p><p>But real extraordinary is nothing like this. Yes, it's exciting, but it also comes with sacrifices, limitations, and constraints. And it's not permanent. Extraordinary can disappear over time, just like you can achieve it over time.</p><p>Extraordinary also comes in many forms, and its value does not have to be measured in terms of money. You can be a tech giant who built their entire empire from scratch, just as you can be an amazing organizer who rallies entire communities together for a single cause. You can be a top-notch violinist player, or a inspiring storyteller. Extraordinary can be anything. Sometimes, when you realize what extraordinary really entails, you might not even want it. That's okay.</p><p><strong>Extraordinary should not be the end goal.</strong> I like to envision the extraordinary space in society as a small ledge at the top of a cliff. It gives you a beautiful view and a sense of accomplishment, but is also tight and oppressing. The sheer physical constraints means that not everyone will reach it. But that shouldn't stop you from putting a hand on the cliff and lifting yourself towards that ledge.</p><p>Why? Because the ledge is not the only thing that exists. There is a vast amount of space under it, other ledges, crooks, and crannies, that most people forget about. That space is just as valuable.</p><p>For example, someone starting out on Youtube might be disappointed that they don't have millions of subscribers. They don't think they have what it takes, so they quit. But most people don't only look at the channels with millions of subscribers. Smaller ones are as valuable for viewers, and the creators can get just as much value out of creating their original content and connecting with like-minded people.</p><p>So instead of searching for an extraordinary that is distorted and unrealistic, search to climb up to some space beneath the top ledge. You will be less disappointed and jealous, and you will still maintain some velocity in the right direction. Climbing to a higher vantage point can also unlock new forms of extraordinary that you might have never noticed before.</p><p>By consistently climbing and reassessing which direction to take, you might just reach your own extraordinary as a bonus.</p></section></div></div>]]>
            </description>
            <link>https://www.tiffanymatthe.com/not-extraordinary</link>
            <guid isPermaLink="false">hacker-news-small-sites-24261826</guid>
            <pubDate>Mon, 24 Aug 2020 15:53:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Remains of 17th century bishop support Neolithic emergence of tuberculosis]]>
            </title>
            <description>
<![CDATA[
Score 64 | Comments 12 (<a href="https://news.ycombinator.com/item?id=24261768">thread link</a>) | @benbreen
<br/>
August 24, 2020 | https://www.shh.mpg.de/1825450/neolithic-emergence-of-tuberculosis | <a href="https://web.archive.org/web/*/https://www.shh.mpg.de/1825450/neolithic-emergence-of-tuberculosis">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  
  
  <p>Bishop Peder Winstrup of Lund, Sweden passed away in the winter of 1679 at the age of 74 and was interred in a crypt at Lund Cathedral. Three centuries later, his astonishingly well-preserved remains provide insights to the origins of tuberculosis.</p>
  

  

  <p>In a recent study published in <em>Genome Biology</em>, researchers from the Max Planck Institute for the Science of Human History, Lund University and the Swedish Natural Historical Museum present analysis of the highest quality ancient Mycobacterium tuberculosis genome to date, suggesting the pathogen is much younger than previously believed.</p>
  
  
<figure data-description="Portrait of Bishop Peder Jensen Winstrup" data-picture="base64;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">
      
    

    
    <figcaption>
        <p>
          Portrait of Bishop Peder Jensen Winstrup
        </p>
        <p>
           © Orf3us / CC BY-SA (https://creativecommons.org/licenses/by-sa/3.0)
        </p>
    </figcaption>
</figure>


<p>When Anthropologist Caroline Arcini and her colleagues at the Swedish Natural Historical Museum discovered small calcifications in the extremely well preserved lungs of Bishop Peder Winstrup, they knew more investigation was needed. “We suspected these were remnants of a past lung infection,” says Arcini, “and tuberculosis was at the top of our list of candidates. DNA analysis was the best way to prove it.”</p>
<p>Up to one quarter of the world’s population is suspected to have been exposed to bacteria of the <i>Mycobacterium tuberculosis</i> complex, which cause tuberculosis (TB). Bishop Winstrup would have been one of many to fall ill during the onset of the so-called “White Plague” TB pandemic that ravaged post-medieval Europe. Today, TB is among the most prevalent diseases, accounting for the highest worldwide mortality from a bacterial infection.</p>
<p>The global distribution of TB has led to the prevailing assumption that the pathogen evolved early in human history and reached its global distribution via the hallmark Out of Africa human migrations tens of thousands of years ago, but recent work on ancient TB genomes has stirred up controversy over when this host-pathogen relationship began. In 2014, a team led by scientists from the University of Tübingen and Arizona State University reconstructed three ancient TB genomes from pre-contact South America – not only were the ancient strains unexpectedly related to those circulating in present-day seals, but comparison against a large number of human strains suggested that TB emerged within the last 6000 years. Understandably, skepticism surrounded this new estimate since it was based entirely on ancient genomes that are not representative of the TB strains associated with humans today.</p>
<p>“Discovery of the Bishop’s lung calcification gave us the opportunity to revisit the question of tuberculosis emergence with data from an ancient European,” comments Kirsten Bos, group leader for Molecular Paleopathology at the Max Planck Institute for the Science of Human History (MPI-SHH), who co-led the study. “If we could reconstruct a TB genome from Bishop Winstrup, where we know his date of death to the day, it would give a secure and independent calibration for our estimates of how old TB, as we know it, actually is.”</p>
<p><b>The highest quality ancient TB genome to date&nbsp; </b></p>
<p>In a new study published this week in Genome Biology, Susanna Sabin of MPI-SHH and colleagues reconstruct a tuberculosis genome from the calcified nodule discovered in Bishop Winstrup's remains.</p>
<p>“The genome is of incredible quality – preservation on this scale is extremely rare in ancient DNA,” comments Bos.</p>

<figure data-description="Scanning electron micrograph of <em>Mycobacterium tuberculosis</em> bacteria, which cause TB" data-picture="base64;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">
      
    

    
    <figcaption>
        <p>
          Scanning electron micrograph of <em>Mycobacterium tuberculosis</em> bacteria, which cause TB
        </p>
        <p>
           © NIAID
        </p>
    </figcaption>
</figure>


<p>Together with a handful of tuberculosis genomes from other work, the researchers revisit the question of the age of the Mycobacterium tuberculosis complex, with the year of the Bishop’s death as a fine-tuned calibration point. Using multiple molecular dating models, all angles indeed point to a relatively young age of the <i>Mycobacterium tuberculosis</i> complex.</p>
<p>“A more recent emergence of the tuberculosis pathogen complex is now supported by genetic evidence from multiple geographic regions and time periods,” comments Sabin, first author of the study. “It’s the strongest evidence available to date for this emergence having been a Neolithic phenomenon.”</p>
<p>This most recent shift in the narrative for when bacteria in the <i>Mycobacterium tuberculosis </i>complex became highly infectious to humans raises further questions about the context of its emergence, as it appears to have coincided with the rise of pastoralism and sedentary lifestyles.</p>
<p>“The Neolithic transition seems to have played an important role for the emergence of a number of human pathogens,” comments Denise Kühnert, group leader for disease transmission research at MPI-SHH who co-led the investigation.&nbsp;</p>
<p>“For TB in particular, stronger evidence could only come from an older genome, though these deeper time periods are unlikely to yield preservation on the scale of what we’ve seen for Bishop Winstrup,” adds Bos.</p>
<p>“Moving forward,” Sabin further comments, “the hope is we will find adequately preserved DNA from time periods close to the emergence of the complex, or perhaps from its ancestor.”</p>
  
</div></div>]]>
            </description>
            <link>https://www.shh.mpg.de/1825450/neolithic-emergence-of-tuberculosis</link>
            <guid isPermaLink="false">hacker-news-small-sites-24261768</guid>
            <pubDate>Mon, 24 Aug 2020 15:48:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Making money building Shopify micro-SaaS apps]]>
            </title>
            <description>
<![CDATA[
Score 214 | Comments 57 (<a href="https://news.ycombinator.com/item?id=24261192">thread link</a>) | @gk1
<br/>
August 24, 2020 | https://www.preetamnath.com/blog/building-your-first-micro-saas-app-on-shopify | <a href="https://web.archive.org/web/*/https://www.preetamnath.com/blog/building-your-first-micro-saas-app-on-shopify">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Starting your first business can be a daunting task. There’s so many variables involved - which ones to solve for, which ones to figure out?</p><p>Typically as software engineers and product people, building the product and writing code is not where we falter. </p><p>Where we get stuck is with existential questions like:</p><ul role="list"><li>Does anybody want this app?</li><li>How will I get users?</li></ul><p>And from my little experience in entrepreneurship, I find these questions to be more important than actually designing and building the app. Trust me when I say this.</p><p>Since I’ve been answering questions on email and Twitter DMs around these topics already, writing a guide came as the natural next step.</p><h3>Who this guide is for</h3><ul role="list"><li>You are starting your first micro-SaaS business</li><li>You want to earn extra outside your job, or you want to eventually replace your job income with a business</li><li>You can design apps with a baseline level of UX, and you can write code. Or, you have a business partner who can do these</li><li>You have 10+ hours to allocate every week (initially, more is better) and are in it for the long haul (say 3-6 months before you start seeing significant income from the business)</li><li>You want to serve customer’s needs</li></ul><h3>Who this guide is NOT for</h3><ul role="list"><li>You want to become a millionaire quickly</li><li>You are in it for the short term gain but you don’t see building businesses as your long-term path</li><li>You don’t know the A of design or coding, and neither have a business partner who does</li><li>You don’t have the patience to struggle for 3-6 months when the results might be 0, before things suddenly start to work in your favour</li></ul><p>If this guide is for you, read on. I’ve laid out the index of topics covered in the post. </p><p>Depending on the stage of your journey, feel free to skip to the sections that are most relevant to you.<br></p><h3><strong>Topics covered in this post</strong></h3><ol role="list"><li>Make money building Shopify apps</li><li>Discover problems, niches, and Shopify app ideas</li><li>Standing out from competition</li><li>Shopify App Store optimisation basics</li><li>Find your #1 keyword</li><li>How to build a Shopify app</li><li>Getting customers to review your Shopify app (by delivering great customer support)</li><li>Getting the first customers for your Shopify app</li><li>Finding early users and beta testers for your Shopify app outside the App Store</li><li>Getting listed under the right categories &amp; collections, and getting featured on the Shopify App Store</li><li>The right pricing model for your Shopify app</li><li>Optimising for trials</li><li>Long term game plan in the Shopify App Store</li></ol><p>‍<br></p><h2><strong>Make money building Shopify apps</strong></h2><p>Shopify isn’t the only choice when it comes to picking an apps marketplace. There’s </p><ul role="list"><li><a href="https://slack.com/apps" target="_blank">Slack</a></li><li><a href="https://marketplace.atlassian.com/" target="_blank">Atlassian</a></li><li><a href="https://appexchange.salesforce.com/" target="_blank">Salesforce</a></li><li><a href="https://gsuite.google.com/marketplace" target="_blank">GSuite Marketplace</a></li><li><a href="https://chrome.google.com/webstore/category/extensions" target="_blank">Chrome Web Store</a></li><li><a href="https://play.google.com/store/apps" target="_blank">Google Play Store</a></li><li><a href="https://www.apple.com/in/ios/app-store/" target="_blank">Apple iOS App Store</a></li><li><a href="https://apps.apple.com/us/genre/mac/id39?mt=12" target="_blank">Mac App Store</a></li></ul><p>All these marketplaces are valid options for you to start. I would lean on a marketplace where there’s a combination of 2 factors</p><ol role="list"><li><strong>Familiarity with problems</strong> - You know what the core product is about, you understand or can empathise with its users maybe from using the tool at your previous workplace, you have an idea on the different kind of problems that exist in the ecosystem and don’t find it too boring to solve them</li><li><strong>Skillset to execute</strong> - If you don’t know how to build Android, iOS, or Mac apps, perhaps steer clear of it. Your goal is not to take on a hard challenge, it’s to take on a challenge where you have some advantage from skill and insight. The goal is to win.<br></li></ol><h3>Why you should pick the Shopify app marketplace:</h3><ul role="list"><li><strong>Huge distribution:</strong> Marketing is often a big reason for a business’s failure, the App Store takes care of it. Shopify has 1mn+ merchants and tons of new signups every month who go to the app store browsing for solutions. <br>Shopify promotes apps within its product and has made it an integral part of its user journey. A new app is able to gain traction fairly easily in the app marketplace, which makes it friendly to newcomers. <br>Marketing is often a big reason for a business’s failure, the App Store takes care of it.</li><li><strong>Tons of app opportunities:</strong> E-commerce store owners have 101+ problems to be taken care of, and you can address any one and do a great job at it to build a sustainable business. It’s not hard (relative standards) to gain 200 paying customers paying you $10/mo to earn $2000/mo ($1600 after Shopify’s 20%)</li><li><strong>Ease of development:</strong> Shopify’s documentation and APIs are first-class, they get out of the way allowing you to build fast. Additionally, Shopify’s <a href="https://polaris.shopify.com/" target="_blank">Polaris UI framework</a> makes building app interfaces a piece of cake. It’s based on React and comes with a Sketch/Figma file to help you design and prototype solutions fast.</li><li><strong>Billing taken care of:</strong> Heads up, Shopify takes a 20% commission on all earnings. So if your app’s monthly subscription fees is $10, you get $8. In return, Shopify takes care of billing end to end.<br>You can charge monthly, annually, charge per activity, provide app credit, and issue refunds with very little effort. You don’t need to worry about failed payments, Shopify takes care of it. You don’t even need to generate an invoice, app bills are included in the merchant’s monthly Shopify invoice.</li><li><strong>Familiarity with ecommerce:</strong> If you’re someone who can jump into an industry and learn all about it, great. If not, you would want some familiarity with how an ecommerce store works, what are the typical problems faced by a merchant.<br>You can do this by creating a Shopify store and trying to sell your own products. Or you could have conversations with 10 different store owners and absorb from their experience. You could also find someone who works at an e-commerce agency for valuable insights. It’s not that hard.<br></li></ul><h3>Why you shouldn’t pick the Shopify app marketplace:</h3><ul role="list"><li><strong>Copycat galore:</strong> You’re likely to copy an existing app and make a slight improvement in terms of product, pricing, or both. Guess what, the next smart person with the same idea can do the same to you. If you’re dependent on getting all or majority of your customers from the app store, be ready for stiff competition from copycats. <br>This doesn’t mean you cannot grow your app to $1k or $10k MRR. SaaS is not a winner take all market. It just means that it gets harder to grow as you grow. If this is something you are not mentally prepared for, steer clear. <br>There’s ways you can grow out of this by taking a long term strategy, either by taking a brand-centric approach (brand is not your name, but the experience that customers remember you by for which they’ll choose you over a copycat). <br>Or you can go upmarket and target large volume and Plus merchants, where ticket sizes are $200/mo or higher and switching does not happen often. </li><li><strong>Low-end, high-maintenance customers:</strong> Majority of Shopify merchants are people who don’t want to pay beyond $10-$15/mo and yet they expect world-class customer service. Some will ask for phone support or to jump on a video call. <br>You can tackle this by solving problems where the ticket sizes are higher, in the range of $50-$100/mo, but also expect it to be significantly harder to rank and fight existing competitors in such problem spaces. Example - <a href="https://apps.shopify.com/search?q=page+builder" target="_blank">page builders</a>, <a href="https://apps.shopify.com/search?q=product+reviews" target="_blank">product review</a> apps. <br>You can mitigate this by going in with the mindset that you’ll be serving $15/mo customers, so your app better be self-serve ready, have a dead simple UX and sufficient documentation or walkthrough videos. You can also aim to be the cost-leader of a segment, example - <a href="https://apps.shopify.com/judgeme" target="_blank">Judge.me</a> </li></ul><p>‍<br></p><h2><strong>Discover problems, niches, and Shopify app ideas</strong></h2><p>I’ve previously written about <a href="https://www.preetamnath.com/blog/shopify-micro-saas-growth" target="_blank">uncovering opportunities on Shopify</a> and I also shared all my research in my big <a href="https://docs.google.com/spreadsheets/d/1Hnpcl1VAlPC9MuFvvsl2UsU0yu1iM6aKR-iK30VtbwA/edit?usp=sharing" target="_blank">Shopify app ideas spreadsheet</a>. Let me reiterate on the advice shared there in a more structured manner that will hopefully better answer questions like:</p><ul role="list"><li>“How do you find niches in the app store in the first place?”</li><li>“How to find a problem worth solving within shopify? (worth solving=stressful enough for merchants &amp; competition not too tough)”<br></li></ul><p>There have been people who have asked me what kind of problems to solve, or what are the underserved niches. The thing is - if there's an obviously underserved niche and people have taken the time to research about it, they are probably busy solving it. If it's being posted in any blog post, know that it's no longer an underserved or hidden niche, because clearly anyone could find it.</p><p>Ultimately, only you can find an idea that you find worthy enough to pursue, whose various pros and cons are justified in your mind. And therefore, I can only provide a directional framework towards evaluating ideas. I can't list out ideas.</p><p>The best use of a directional framework is to</p><ol start="" role="list"><li><strong>First</strong> - cast a wide net, get to know what's out there</li><li><strong>Second</strong> - narrow down your search based on parameters you have decided</li></ol><p>This first section of the article will help you with casting a wide net. </p><p>As you go further along the article, I've shared ideas and techniques which you can use to narrow down your search.<br></p><h3>1- Browse the entire App Store</h3><p>I recommend this as the starting point for anyone new to the Shopify ecosystem. Start by browsing all the categories &amp; sub-categories of apps on the app store. You can do the same on <a href="https://sasi.unionworks.co.uk/categories" target="_blank">SASI</a>. </p><p>The purpose of browsing this way is to familiarise yourself with the different types of problems faced by merchants and being solved by apps. Ideally, you want to note down some interesting apps that you come across during your browsing adventure to investigate later on.</p><figure id="w-node-892fc283544a-2f0d8df6"><p><img src="https://uploads-ssl.webflow.com/5e085291ed2a2769a872e587/5f1c114edd643e073591f8cc_browse%20categories%20shopify%20app%20store.png" alt=""></p></figure><h3>2- Go through every letter in search autocomplete</h3><p>Okay, this is a step I took when&nbsp;I was browsing the app store. I would type in "aa", "ab", "ac"... ... ... "zz" on the search bar, note the autocomplete terms and check the results of ones I found to be interesting.</p><p>Turns out, Shopify has since updated their algorithm. Autocomplete suggestions only show up after you type 3 letters now. So you can't recreate what I did with autocomplete and go through every letter. It's not feasible anymore.</p><p>Not to worry, it's still useful.</p><h4>Plug in keywords of shortlisted apps into the search bar</h4><p>From step 1, all the apps (hopefully at least a dozen) that you shortlisted for being interesting, extract the keywords used in the app's title or description. </p><p>Now, enter those keywords in search to find whether they …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.preetamnath.com/blog/building-your-first-micro-saas-app-on-shopify">https://www.preetamnath.com/blog/building-your-first-micro-saas-app-on-shopify</a></em></p>]]>
            </description>
            <link>https://www.preetamnath.com/blog/building-your-first-micro-saas-app-on-shopify</link>
            <guid isPermaLink="false">hacker-news-small-sites-24261192</guid>
            <pubDate>Mon, 24 Aug 2020 14:47:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[One Year of Nushell]]>
            </title>
            <description>
<![CDATA[
Score 188 | Comments 31 (<a href="https://news.ycombinator.com/item?id=24259914">thread link</a>) | @rainworld
<br/>
August 24, 2020 | https://www.nushell.sh/blog/2020/08/23/year_of_nushell.html | <a href="https://web.archive.org/web/*/https://www.nushell.sh/blog/2020/08/23/year_of_nushell.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <section>
      

      <p>Hard to imagine that it’s already been a year since Nu first went public. At the time, it was largely a demo of what could be possible, but still needed quite a bit of work to make it ready for everyday use. A year later and we’ve learned a lot, and made a few mistakes along the way. In this post, we look back over the year and see how we did and where we might be going in the future.</p>



<p>When Nu first started, it started with a simple idea: the output of <code>ls</code>, <code>ps</code>, and <code>sysinfo</code> should all output the same thing. Taking a page from PowerShell, we explored outputting structured data and quickly settled on a table design that would support the output of each of the three commands, with the added ability of streaming the output as it became available.</p>

<p>Around this idea, we then built a set of “filters”, like the <code>where</code> clause, borrowed from SQL, and a growing set of data types we would support natively.  Soon, we were able to write more complex statements like <code>ls | where size &gt; 10kb</code>. This became the crux of the idea - commands that output values from a core set of data types into a stream, composed together with the traditional UNIX pipe (<code>|</code>), so that you could build up a complex set of commands that work over the data as it streams through.</p>



<h2 id="contributors">Contributors</h2>

<p>Before we got started talking about Nushell today, we wanted to give a <em>big</em> “thank you!” to everyone who has contributed to Nu to get us to this point. Nu is what it is because of your help.</p>

<p>1ntEgr8, AaronC81, AdminXVII, aeosynth, aeshirey, aidanharris, almindor, Aloso, Amanita-muscaria, amousa11, andrasio, Andrew-Webb, arashout, arnaldo2792, avandesa, avranju, bailey-layzer, BatmanAoD, bndbsh, Bocom, boisgera, Borimino, BradyBromley, BurNiinTRee, Byron, candostdagdeviren, casidiablo, charlespierce, chhetripradeep, cjpearce, coolshaurya, cristicismas, DangerFunPants, daschl, daveremy, davidrobertmason, Delapouite, dependabot[bot], Detegr, devnought, Dimagog, djc, drmason13, DrSensor, elichai, eltonlaw, EmNudge, eoinkelly, equal-l2, est31, fdncred, filalex77, Flare576, gilesv, gorogoroumaru, GuillaumeGomez, hdhoang, he4d, hilias, HiranmayaGundu, hirschenberger, homburg, iamcodemaker, incrop, ineol, Jacobious52, jankoprowski, JCavallo, jdvr, jerodsanto, JesterOrNot, johnae, johnterickson, jonathandturner, JonnyWalker81, jonstodle, JosephTLyons, jzaefferer, k-brk, Kelli314, klnusbaum, kloun, kornelski, kubouch, kvrhdn, landaire, lesichkovm, LhKipp, lightclient, lincis, lord, luccasmmg, marcelocg, matsuu, mattclarke, mattyhall, max-sixty, mfarberbrodsky, mhmdanas, mike-morr, miller-time, mistydemeo, mlbright, mlh758, morrme, nalshihabi, naufraghi, nespera, neuronull, nickgerace, nmandery, notryanb, oknozor, orf, orientnab, oskarskog, oylenshpeegul, pag4k, Paradiesstaub, philip-peterson, piotrek-szczygiel, pizzafox, pka, pmeredit, pontaoski, Porges, pulpdrew, q-b, quebin31, rabisg0, ramonsnir, rimathia, ritobanrc, rnxpyke, romanlevin, routrohan, rrichardson, rtlechow, rutrum, ryuichi1208, Samboy218, samhedin, sandorex, sdfnz, sebastian-xyz, shaaraddalvi, shiena, siedentop, Sosthene-Guedon, Southclaws, svartalf, taiki-e, Tauheed-Elahee, tchak, thegedge, tim77, Tiwalun, twe4ked, twitu, u5surf, UltraWelfare, uma0317, utam0k, vsoch, vthriller, waldyrious, warrenseine, wycats, yaahc, yahsinhuangtw, yanganto, ymgyt, zombie110year</p>



<p>Nushell is an interactive programming language for working with your files, your system, and your data as a shell, a notebook, and more.</p>

<h2 id="nu-is-more-than-a-shell">Nu is more than a shell</h2>

<p>It’s easy to think of Nushell as just a shell. It’s even got ‘shell’ in the name. It’s the first and probably main way you’ll interact with it. So why say it’s “more than a shell”?</p>

<p>In truth, Nushell is actually two things at once: Nu and Nushell. Nu is an interactive language for processing streams of structured data, data that you’re probably getting from files, your system, a web address, etc.</p>

<p>So what’s Nushell?</p>

<p>Nushell is taking the Nu language and putting it into a shell, and building around it a set of shell features to make it feel comfortable to use as a login shell. Completions, pretty error messages, and the like.</p>

<p>When we say that “Nu is more than a shell”, does that imply that Nu can be used in other places, too? Absolutely. We’ve got two more hosts that let you run Nu, a <a href="https://github.com/nushell/nu_jupyter">jupyter-based</a> host that lets you run Nu in jupyter notebooks, and a <a href="https://github.com/nushell/demo">WebAssembly-based</a> host that we use to create the <a href="https://www.nushell.sh/demo/">Nu playground</a></p>

<p>The idea of Nu runs deeper than just the shell, to being a language that’s relatively easy to learn, yet powerful enough to do real work with your system, to process large amounts of data, to interactively let you iterate quickly on an idea, to invite exploration by building up a pipeline one piece at a time. There’s really no shortage of ambition for where we hope to go.</p>



<p>Nu’s original design has proven surprisingly robust thus far. Some of its core ideas are continuing to pay dividends a year later. Let’s look at the designs that still feel right.</p>

<h2 id="pipelines-are-infinite">Pipelines are infinite</h2>

<p>When we first started writing Nu, we took a few shortcuts that had us processing all the data in a pipeline at once. Very quickly, we realize this wasn’t going to work. External commands (think <code>cat /dev/random</code>) can output an infinite stream of data, and the system needs to be able to handle it. Understanding this, we transitioned to a different model: data flows between command as infinite streams of structured data. As the data is processed, we avoid collecting the data whenever possible to allow this streaming to happen.</p>

<p>Because the streams can be infinite, even the printing out of tables is done a batch at a time.</p>

<h2 id="separating-viewing-data-from-the-data-itself">Separating viewing data from the data itself</h2>

<p>Coming from other shells, the idea of running <code>echo</code> or <code>ls</code> goes hand-in-hand with printing something to the terminal. It’s difficult to see that there two steps going on behind the scenes: creating the information and then displaying it to the screen.</p>

<p>In Nu, these two steps are distinct. The <code>echo</code> command gets data ready to output into stream, but doesn’t do any work to print it to the screen. Likewise, <code>ls</code> gets ready to output a stream of file and directory entries, but doesn’t actually display this information.</p>

<p>That’s because both <code>echo</code> and <code>ls</code> are lazy commands. They’ll only do the work if the data is pulled from the stream. As a result, the step of viewing the data is separate from the step of creating it.</p>

<p>Behind the scenes, Nu converts a standalone <code>ls</code> to be the pipeline <code>ls | autoview</code>. The work of viewing comes from <code>autoview</code> and it handles working with the data and calling the proper viewer. In this way, we’re able to keep things as structured data for as long as possible, and only convert it to be displayed as the final step before being shown to the user. (note: the wasm-based demo and jupyter do a similar step, but instead of adding <code>autoview</code>, they add <code>to html</code>)</p>

<h2 id="rich-data-types">Rich data types</h2>

<p>In a similar way to working with structured data, rather than only plain text, Nu takes a different approach to data types as well. Nu takes the traditional set of basic types, like strings and numbers, and extends them into a richer set of basic data primitives.</p>

<p>Numbers are represented internally as big numbers and big decimals, rather than integers and floating point machine-based representations. This gives us more flexibility to do math more accurately, and generally removes the worry of whether the number you want to work with will fit in the integer or float size you have available.</p>

<p>We carry this further, by also representing values common in modern computer usage: URLs, file paths, file sizes, durations, and dates are all examples of built-in data types. By building them in, Nu can have better syntax and type checking with their use.</p>

<p>For example, in Nu it’s possible to write <code>= 1min + 1sec</code> to create a duration that is one minute one second long.  You can also use the file sizes, like being able to filter a directory list by the size of the file <code>ls | where size &gt; 10kb</code>.</p>

<p>Nu also can help if you try to mix types that shouldn’t. For example, if you had written: <code>= 1min + 1kb</code> it seems you didn’t mean to add time and file sizes together, and Nu gives you an error if you do:</p>

<div><div><pre><code>error: Coercion error
  ┌─ shell:1:3
  │
1 │ = 1min + 1kb
  │   ^^^^   --- filesize(in bytes)
  │   │       
  │   duration
</code></pre></div></div>

<p><em>note: we’ll be making this error better in the future</em></p>

<p>Data in Nu also isn’t just the value, but it’s also a set of metadata that comes with the value. For example, if you load data from a file using the <code>open</code> command, we track the place that it’s loaded along with the data that’s loaded. We can see this metadata using the <code>tags</code> command:</p>

<div><div><pre><code>open package.json | tags
───┬─────────────────┬──────────────────────────────────────────────────────────────────────────────
 # │      span       │                                    anchor                                    
───┼─────────────────┼──────────────────────────────────────────────────────────────────────────────
 0 │ [row end start] │ /home/jonathan/Source/servo/tests/wpt/web-platform-tests/webrtc/tools/packag 
   │                 │ e.json                                                                       
───┴─────────────────┴──────────────────────────────────────────────────────────────────────────────
</code></pre></div></div>

<p>This extra information allows us to know how to view the contents, and even save you time when you use the <code>save</code> command, as it will use the original location by default.</p>

<h2 id="keeping-it-fun">Keeping it fun</h2>

<p>Something we attached to early on was the idea that Nu should be fun. It should be fun to work on, it should be fun to contribute to, and it should be fun to use.</p>

<p>Nu is really about play. You play with your data, you play with the structures that make up your files and filesystem, you play with what web services give back to you. Everything about Nu is made to invite you to explore how things work and how data is put together. As you play, you learn more about Nu works and how to better use it. We firmly believe …</p></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.nushell.sh/blog/2020/08/23/year_of_nushell.html">https://www.nushell.sh/blog/2020/08/23/year_of_nushell.html</a></em></p>]]>
            </description>
            <link>https://www.nushell.sh/blog/2020/08/23/year_of_nushell.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24259914</guid>
            <pubDate>Mon, 24 Aug 2020 12:25:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[JavaScript Generators, Meet XPath]]>
            </title>
            <description>
<![CDATA[
Score 96 | Comments 17 (<a href="https://news.ycombinator.com/item?id=24259688">thread link</a>) | @fanf2
<br/>
August 24, 2020 | https://jack.wrenn.fyi/blog/xpath-for-2020/ | <a href="https://web.archive.org/web/*/https://jack.wrenn.fyi/blog/xpath-for-2020/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
          
<article>
    <header>
      
      <span>2020-08-22&nbsp;</span>
    </header>

    <p>Using Generators to Modernize a Geriatric Javascript API for <code>$CURRENT_YEAR</code></p>
<span id="continue-reading"></span>
<hr>
<p>How do you find-and-replace text on an HTML page?</p>
<pre><code><span>&lt;div&gt;</span><span>Hello, </span><span>&lt;span&gt;</span><span>human</span><span>&lt;/span&gt;</span><span>!</span><span>&lt;/div&gt;
</span></code></pre>
<p>If the text is neatly neatly isolated inside an HTML element, it's easy; this will do:</p>
<pre><code><span>document</span><span>.</span><span>querySelector</span><span>(</span><span>"span"</span><span>)</span><span>.textContent </span><span>= </span><span>"evolved ape"</span><span>;
</span></code></pre>
<p><strong>But here's a puzzle</strong>: how do you you change text that <em>isn't</em> neatly isolated in an HTML element?</p>
<p>You <em>could</em> use <code>innerHTML</code>:</p>
<pre><code><span>let </span><span>elt </span><span>= </span><span>document</span><span>.</span><span>querySelector</span><span>(</span><span>"div"</span><span>)</span><span>;
</span><span>elt</span><span>.innerHTML </span><span>= </span><span>elt</span><span>.innerHTML.</span><span>replace</span><span>(</span><span>"Hello"</span><span>, </span><span>"Greetings"</span><span>)</span><span>;
</span></code></pre>
<p>...but this will hose any event listeners registered on <code>elt</code>'s children.</p>
<p>You <em>could</em> grapple onto the nearest selectable element:</p>
<pre><code><span>let </span><span>node </span><span>= </span><span>document</span><span>.</span><span>querySelector</span><span>(</span><span>"div"</span><span>)</span><span>.childNodes[</span><span>0</span><span>];
</span><span>node</span><span>.textContent </span><span>= </span><span>node</span><span>.textContent.</span><span>replace</span><span>(</span><span>"Hello"</span><span>, </span><span>"Greetings"</span><span>)</span><span>;
</span></code></pre>
<p>Yuck; this sort of child-node indexing feels <em>really</em> brittle.</p>
<p><strong>Why can't we just <em>directly</em> select the text nodes containing <code>Hello</code>?</strong></p>
<h2 id="xpath">XPath</h2>
<p><strong>We can!</strong> Enter: <a href="https://en.wikipedia.org/wiki/XPath">XPath</a>, the <em>excessively</em> powerful language for querying XML documents. It's usable in web-browsers with the, uh, <em>descriptively</em>-named method <a href="https://developer.mozilla.org/en-US/docs/Web/API/Document/evaluate"><code>document.evaluate</code></a>.</p>
<p>It's a <em>bit</em> of a production to use:</p>
<pre><code><span>let </span><span>xpath </span><span>= </span><span>"//text()[contains(., 'Hello')]"</span><span>; </span><span>// find text nodes containing 'Hello'
</span><span>let </span><span>context </span><span>= </span><span>document</span><span>.body; </span><span>// look in the body element
</span><span>let </span><span>namespace_resolver </span><span>= </span><span>null</span><span>; </span><span>// some sorta xml voodoo
</span><span>let </span><span>result_type </span><span>= </span><span>XPathResult</span><span>.ORDERED_NODE_SNAPSHOT_TYPE; </span><span>// DEFINITELY MAKE SURE YOU USE THIS

</span><span>let </span><span>results </span><span>= </span><span>document</span><span>.</span><span>evaluate</span><span>(</span><span>xpath</span><span>, </span><span>context</span><span>, </span><span>null</span><span>, </span><span>result_type</span><span>)</span><span>;

</span><span>for </span><span>(</span><span>let </span><span>i </span><span>= </span><span>0</span><span>; </span><span>i </span><span>&lt; </span><span>results</span><span>.snapshotLength; </span><span>i</span><span>++</span><span>) {
  </span><span>let </span><span>node </span><span>= </span><span>results</span><span>.</span><span>snapshotItem</span><span>(</span><span>i</span><span>)</span><span>;
  </span><span>node</span><span>.textContent </span><span>= </span><span>node</span><span>.textContent.</span><span>replace</span><span>(</span><span>"Hello"</span><span>, </span><span>"Greetings"</span><span>)</span><span>;
}
</span></code></pre>
<p>Yes, you really need to write <em>all</em> of that. The <code>result_type</code> argument is technically optional, but omit it at your own peril: without it, you must instead stream results via <code>iterateNext</code>, and this will crash with an exception if you dare <em>modify</em> the queried elements!</p>
<p>It's no wonder <code>document.evaluate</code> is seldom used. <strong>Can we improve on it?</strong></p>
<h2 id="iterizing-xpath-queries">Iterizing XPath Queries</h2>
<p>Yes, with <a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Guide/Iterators_and_Generators"><strong>generators</strong></a>! We can exploit the implicit iterability of generators to modernize this unwieldy API:</p>
<pre><code><span>Document</span><span>.</span><span>prototype</span><span>.xpath </span><span>= </span><span>Element</span><span>.</span><span>prototype</span><span>.</span><span>xpath </span><span>=
  </span><span>function* </span><span>xpath</span><span>(</span><span>xpath</span><span>) {
    </span><span>let </span><span>context </span><span>= </span><span>this </span><span>instanceof </span><span>Document </span><span>? </span><span>document</span><span>.documentElement </span><span>: </span><span>this</span><span>;
    </span><span>let </span><span>namespace_resolver </span><span>= </span><span>null</span><span>;
    </span><span>let </span><span>result_type </span><span>= </span><span>XPathResult</span><span>.ORDERED_NODE_SNAPSHOT_TYPE;
    </span><span>let </span><span>results </span><span>= </span><span>document</span><span>.</span><span>evaluate</span><span>(</span><span>xpath</span><span>, </span><span>context</span><span>, </span><span>null</span><span>, </span><span>result_type</span><span>)</span><span>;

    </span><span>for </span><span>(</span><span>let </span><span>i </span><span>= </span><span>0</span><span>; </span><span>i </span><span>&lt; </span><span>results</span><span>.snapshotLength; </span><span>i</span><span>++</span><span>)
      </span><span>yield </span><span>results</span><span>.</span><span>snapshotItem</span><span>(</span><span>i</span><span>)</span><span>;
  };
</span></code></pre>
<p>And because the result of this function is iterable, we can use it with <a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Operators/Spread_syntax">spread syntax</a>:</p>
<pre><code><span>[</span><span>...</span><span>document</span><span>.</span><span>xpath</span><span>(</span><span>"//text()[contains(., 'Hello')]"</span><span>)</span><span>].
  </span><span>forEach</span><span>(</span><span>node </span><span>=&gt; </span><span>node</span><span>.textContent </span><span>= </span><span>node</span><span>.textContent.</span><span>replace</span><span>(</span><span>"Hello"</span><span>, </span><span>"Greetings"</span><span>))</span><span>;
</span></code></pre>
</article>

        </div></div>]]>
            </description>
            <link>https://jack.wrenn.fyi/blog/xpath-for-2020/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24259688</guid>
            <pubDate>Mon, 24 Aug 2020 11:43:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Origins of Venmo (2014)]]>
            </title>
            <description>
<![CDATA[
Score 23 | Comments 4 (<a href="https://news.ycombinator.com/item?id=24259509">thread link</a>) | @saadalem
<br/>
August 24, 2020 | https://kortina.nyc/essays/origins-of-venmo/ | <a href="https://web.archive.org/web/*/https://kortina.nyc/essays/origins-of-venmo/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
  <p>I often speak about the origins of Venmo in person and finally wrote down the story here to share with our latest intern class that started this week. (You can also watch an excellent video of Iqram speaking about even more of the history of Venmo <a href="https://www.youtube.com/watch?v=aX7JCCCmLJw">here</a>. It’s a good place to pickup the story where this post leaves off.)</p>

<p>My friend Iqram and I started Venmo to solve a very simple problem for ourselves and for our friends: we noticed that we were still using cash and checks to pay each other back and thought this was silly. Everyone should be using PayPal to pay each other back, but no one we knew was. We thought something must be not quite right about the PayPal experience for casual use, and we decided to design something that felt “right,” something that felt consistent with all of the other mobile tools we used to interact with our friends, like SMS, Gmail, Facebook, etc. This is the story of how we got to Venmo.</p>

<h2 id="penn">Penn</h2>

<p>Iqram and I met as randomly paired freshman year roommates at the University of Pennsylvania in 2001. We’ve been great friends ever since.</p>

<figure>
<img src="https://kortina.s3.amazonaws.com/_/git/origins-of-venmo/iqram-kortina-college.png">
<figcaption>Oldest pic I could find of me and Iqram.</figcaption>
</figure>

<p>Iqram studied computer science at Penn. I started in computer science, but found that much of the learning I was doing happened while I was doing homework exercises, and I was getting no additional value out of the University. I couldn’t justify tuition costs when I was only learning by spending time doing programming exercises, and I developed a hypothesis that I would maximize the value of tuition costs by studying the least practical subjects possible, the things I would not get to do after graduation / outside of University, like reading and discussing great books with a group of incredibly smart students and professors (this backfired, btw–liberal arts is very practical stuff!). I eschewed big lectures and things like On Campus Recruiting, and tried to spend as much time possible in seminars and writing workshops. I ended up with majors in Philosophy and Creative Writing and minors in Computer Science and Logic.</p>

<p>I remained interested in building things during this time, however, and always took the opportunity to build websites for various clubs I was in or for friends with bands, etc.</p>

<p>During our senior year, Iqram and I built our first real project together, a college classifieds site called My Campus Post. It was our first taste of all night coding sessions to get a product to market, and we learned a bunch about grassroots marketing and retention challenges that arise from products with seasonal usage.</p>

<figure>
<img src="https://kortina.s3.amazonaws.com/_/git/origins-of-venmo/mycampuspost.png">
<figcaption>My Campus Post marketing paraphernalia.</figcaption>
</figure>

<p>I loved spending all of my time reading philosophy, working on fun side projects, and actively ignoring practical things like interviewing for jobs, but I clearly remember the day when my Mom was in town for graduation and she asked, “What are you doing after you graduate?” I was sitting on the floor of my dorm room, and I remember being very scared about the question, thinking, “I have no idea what I want to do with my life,” but also feeling OK about the short term, eventually answering, “I don’t have to move out of my dorm until 2 weeks after graduation. I’ll figure something out.”</p>

<h2 id="post-grad-door-to-door-sales">Post Grad Door to Door Sales</h2>

<p>Iqram ended up finding a cheap sublet in West Philly, and we spent the summer building websites for restaurants, salons, bars, etc. We went door to door selling, “Hey, you need a website. We’ll build it for $500…. $100? OK, deal.” We learned a lot as we tried to abstract the sites we were building into something modular, and we got a lot of experience pitching and hearing “no.” One “no” that I still regret more than most of the others I have subsequently heard (for much bigger deals) was for this amazing Pakistani restaurant, Kabobeesh, that served a chicken kabob sandwich on fresh naan bread for $3.50: we tried to sell them a site for 100 chicken rolls, but failed to close them.</p>

<figure>
<img src="https://kortina.s3.amazonaws.com/_/git/origins-of-venmo/kabobeesh.png">
<figcaption>Kabobeesh: I recommend the chicken rolls and chicken karahi.</figcaption>
</figure>

<p>Once, we were chatting at a bar about how we might pad our sporadic income with some part time jobs. We noticed the bar was hiring, got two applications, and started filling them out. We spent a few minutes getting through all the basic background stuff, education, personal info, and got to the references section. We didn’t really have past employers to list at the time, so I put Iqram as a reference, and he put me. We were still rooming together at the time, so we had the same street address. We did not get a call back.</p>

<h2 id="swooge-and-philafunk">Swooge and Philafunk</h2>

<p>During this period, we were always also working on startup-y things, like a realtime website analytics tool called Swooge (which now reminds me of Chartbeat + Google Analytics) and a web based music selling platform, Philafunk (it was like iTunes + MySpace).</p>

<figure>
<img src="https://kortina.s3.amazonaws.com/_/git/origins-of-venmo/philafunk.jpg">
<figcaption>Philafunk site and flyer.</figcaption>
</figure>

<p>After working on a few of these, we realized we had a lot to learn about building a successful startup, so we decided to go find one and work there. Many of these projects we worked on were still in my opinion great ideas and solid evidence that execution matters much more than the idea.</p>

<h2 id="iminlikewithyou">iminlikewithyou</h2>

<p>So we found this NYC company, iminlikewithyou.com, that was just getting started out of Y Combinator, and we joined as 2 of the first 3 employees, all engineers starting together the day we moved to NYC. We had a talented team, built a really innovative, immersive web experience, and learned a bunch about doing startups for real. Eventually, the company pivoted from the original flirting-site idea into a casual games company (OMGPOP), and we both left because we weren’t interested in building games.</p>

<figure>
<img src="https://kortina.s3.amazonaws.com/_/git/origins-of-venmo/iminlikewithyou.png">
<figcaption>iminlikewithyou site.</figcaption>
</figure>

<h2 id="ticketleap-and-bitly">Ticketleap and Bit.ly</h2>

<p>Iqram worked at Ticketleap as the VP of Engineering for a few years, and I bounced around and ended up spending a bunch of time working at Betaworks, on Bit.ly.</p>

<p>We both learned a lot during this period, but I looked forward to the time when we would work on a new project together, with more knowledge and experience this time. Over the years, I often brought up this idea, but the timing was never quite right.</p>

<h2 id="exploring-new-product-ideas">Exploring New Product Ideas</h2>

<p>In early 2009, Iqram chatted me mentioning that he was feeling ready to move on from Ticketleap, and I remember thinking, “Great let’s do this.” We began getting together on weekends (he was in Philly and I was in NYC) to hack on different ideas.</p>

<h2 id="yogorino">Yogorino</h2>

<p>We had a friend in Philadelphia who was opening a yogurt shop, and while helping her get up and running technically, we realized how horrible traditional point of sales software was. We prototyped a web based point of sales software that would turn any laptop into a cash register with a $50 USB magtek swiper. As we thought about it more, it seemed like this would present a really challenging distribution problem (we remembered our days of door to door restaurant sales…). Plus, although this was designed to solve a problem for one of our friends, it wasn’t software that we would be using ourselves daily.</p>

<figure>
<img src="https://kortina.s3.amazonaws.com/_/git/origins-of-venmo/cardswiper.png">
<figcaption>Web POS prototype.</figcaption>
</figure>

<h2 id="back-to-music">Back to Music</h2>

<p>Another idea we explored came to us at a local jazz show: we thought, “It would be awesome to be able to download this show by sending a text message to this band right now, and then have an mp3 show up in our email.” This was getting closer to the Venmo concept we ultimately arrived at, and the detailed wireframes we constructed for this definitely informed a lot of the original Venmo service.</p>

<figure>
<img src="https://kortina.s3.amazonaws.com/_/git/origins-of-venmo/rootsbuy.png">
<figcaption>Wireframe for selling music downloads via SMS.</figcaption>
</figure>

<p>This concept even bore the Venmo name. Lots of people ask about the origin of the name. The brainstorming process was one of many we tried and was not important as the requirements. We were exploring the Latin root vendere “sell” and mo for mobile, but purely as a means to get to a name that (1) was short, 5-6 letters, (2) could be a verb, (3) didn’t have a unintuitive spelling, and (4) was cheap. Venmo was available on GoDaddy and met the important criteria, so we grabbed it.</p>

<figure>
<img src="https://kortina.s3.amazonaws.com/_/git/origins-of-venmo/visionslide.png">
<figcaption>A slide from our deck for an SMS music service.</figcaption>
</figure>

<h2 id="discovering-venmo">Discovering Venmo</h2>

<p>One of the weekends we were getting together to work on this idea, Iqram was visiting me in NYC and left his wallet in Philly. I covered him for the whole weekend, and he ended up writing me a check to pay me back. It was annoying for him to have to find a checkbook to do this, and annoying for me to have to go to the bank if I wanted to cash it (I never did). We thought, “Why are we still doing this? We do everything else with our phones. We should definitely be using PayPal to pay each other back. But we don’t, and none of our friends do.”</p>

<p>So we decided, let’s just try to solve this problem, and build a way to pay each other back that feels consistent with all of the other experiences we have in apps we use with our friends.</p>

<p>We got pretty excited about this idea, and thought, “Surely someone else must be doing this.” We found a laptop and started googling, and soon came across Obopay: a way to send money to anyone directly from your cell phone. They had recently raised $70M from Nokia, and we thought, “Uh-oh.” But then we poked around the website and the product and found that there was no feel and it seemed a little clunky and not like something anyone we knew would ever use.</p>

<h2 id="evolution-of-the-note">Evolution of the Note</h2>

<p>We got a prototype working pretty quickly. It worked over SMS, and was dead simple. To send iqram $20, text “iqram 20” to our number (a hacked Google Voice account, because the alternative, Textmarks, required that you prefix every text message with a keyword–this was back in the days before Twilio…). The recipient saw “kortina paid you $20.”</p>

<figure>
<img src="https://kortina.s3.amazonaws.com/_/git/origins-of-venmo/gvhack.png">
<figcaption>Google Voice SMS hack.</figcaption>
</figure>

<p>Right after we got this working we decided we needed to have a note with each payment so we could keep track of what all of these random amounts were for: “iqram 20 for thai lunch at Nooch.”</p>

<p>The interface was SMS, so we immediately thought, of course it would only be natural for the person on the other end to see the message, so we updated …</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://kortina.nyc/essays/origins-of-venmo/">https://kortina.nyc/essays/origins-of-venmo/</a></em></p>]]>
            </description>
            <link>https://kortina.nyc/essays/origins-of-venmo/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24259509</guid>
            <pubDate>Mon, 24 Aug 2020 11:11:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[BPF Portability and CO-Re (Compile Once Run Everywhere)]]>
            </title>
            <description>
<![CDATA[
Score 24 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24259499">thread link</a>) | @nyellin
<br/>
August 24, 2020 | https://facebookmicrosites.github.io/bpf/blog/2020/02/19/bpf-portability-and-co-re.html | <a href="https://web.archive.org/web/*/https://facebookmicrosites.github.io/bpf/blog/2020/02/19/bpf-portability-and-co-re.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p><span><p>What does portability mean in BPF context? What are the challenges of writing portable BPF programs that developers need to deal with? This post will describe BPF portability problem and how BPF CO-RE (Compile Once – Run Everywhere) is helping to address this problem.</p>
<!--truncate-->

<h2>BPF: state of the art</h2>
<p>Since the inception of (e)BPF, it’s been a constant priority for the BPF community to simplify BPF application development as much as possible, make it as straightforward and familiar of an experience as it would be for a user-space application. And with the steady progress around BPF programmability, writing BPF programs has never been easier.</p>
<p>Despite these usability improvements, though, one aspect of BPF application development has been neglected (mostly for technical reasons): portability. What does "BPF portability" mean, though? We define <strong>BPF portability</strong> as the ability to write a BPF program that will successfully compile and pass kernel verification, and will work <strong>correctly</strong> across <em>different kernel versions</em> without the need to recompile it for each particular kernel.</p>
<p>This note describes the BPF portability problem and our solution to it: BPF CO-RE (Compile Once – Run Everywhere). First, we’ll look at the BPF portability problem itself, describing why it is a problem and why it’s important to solve it. Then, we will outline high-level components of our solution, BPF CO-RE, and will give a glimpse into the pieces of the puzzle that needed to be put together to make it happen. We’ll conclude with a tutorial of sorts, describing the user-visible API of the BPF CO-RE approach and demonstrating its application with examples.</p>
<h2>The problem of BPF portability</h2>
<p>A BPF program is a piece of user-provided code which is injected straight into a kernel. Once loaded and verified, BPF programs execute in kernel context. These programs operate inside kernel memory space with access to all the internal kernel state available to it. This is extremely powerful and is one of the reasons why BPF technology is successfully used in so many varied applications. However, this powerful capability also creates the BPF portability pains we have today: BPF programs do not control memory layout of a surrounding kernel environment. They have to work with what they get from independently developed, compiled, and deployed kernels.</p>
<p>Additionally, kernel types and data structures are in constant flux. Different kernel versions will have struct fields shuffled around inside a struct, or even moved into a new inner struct. Fields can be renamed or removed, their types changed, either into some trivially-compatible ones or completely different ones. Structs and other types can get renamed, or they can be conditionally compiled out (depending on kernel configuration), or just plain removed between kernel versions.</p>
<p>In other words, things change all the time between kernel releases and yet BPF application developers are expected to cope with this problem somehow. How is it even possible to do anything useful with BPF today considering this ever-changing kernel environment? There are a few reasons for this.</p>
<p>First, not all BPF programs need to look into internal kernel data structures. One example is <code>opensnoop</code> tool, which relies on kprobes/tracepoints to track which processes open which files, and just needs to capture a few syscall arguments to work. As syscall parameters offer a stable ABI, these don’t change between kernel versions and as such portability is not a concern to begin with. Unfortunately, applications like this are quite rare. These types of applications are also typically quite limited in what they can do.</p>
<p>So, additionally, BPF machinery inside kernel provides a limited set of "stable interfaces" that BPF programs can rely on to be stable between kernels. In reality, underlying structures and mechanisms do change, but these BPF-provided stable interfaces abstract such details from user programs.</p>
<p>As one example, for networking applications it is usually enough to look at a limited set of <code>sk_buff</code>'s attributes (and packet data, of course) to be extremely useful and versatile. To that end, BPF verifier provides a stable <strong><code>__sk_buff</code></strong> "view" (notice underscores in front), which shields BPF programs from changing <code>struct sk_buff</code> layout. All the <code>__sk_buff</code> field accesses are transparently rewritten into an actual <code>sk_buff</code> accesses (sometimes quite elaborate ones – doing a bunch of internal pointer chasing before finally fetching requested field). Similar mechanisms are available to a bunch of different BPF program types. They are done as program type-specific BPF contexts understood by BPF verifier. So, if you are developing a BPF program with such context, consider yourself lucky, you can blissfully live in a nice illusion of stability.</p>
<p>But as soon as you need to get a glimpse at any raw internal kernel data (e.g., very commonly a <code>struct task_struct</code> which represents a process/thread and contains a treasure trove of process information), you are on your own. It is commonly the case for tracing, monitoring, and profiling applications, which are a huge class of extremely useful BPF programs.</p>
<p>In such cases, how do you make sure you are not reading garbage data when some kernel added an extra field before the field you thought is, say, at offset 16 from the start of <code>struct task_struct</code>? Suddenly, for that kernel, you'll need to read data from, e.g., offset 24. And the problems don't end there: what if a field got renamed, as was the case with <code>thread_struct</code>'s <code>fs</code> field (useful for accessing thread-local storage), which got renamed to <code>fsbase</code> between 4.6 and 4.7 kernels. Or what if you have to run on two different configurations of a kernel, one of which disabled some specific feature and completely compiled out parts of the struct (a common case for additional accounting fields, which are optional, but extremely useful if present)? All this means that you can no longer compile your BPF program locally using kernel headers of your dev server and distribute it in compiled form to other systems, while expecting it to work and produce correct results. This is because kernel headers for different kernel versions will specify a different memory layout of data your program relies on.</p>
<p>So far, people have been dealing with this problem by relying on <a href="https://github.com/iovisor/bcc/">BCC</a> (BPF Compiler Collection). With BCC, you embed your BPF program C source code into your user-space program (control application) <em>as a plain string</em>. When control application is eventually deployed and executed on target host, BCC invokes its embedded Clang/LLVM, pulls in local kernel headers (which you have to make sure are installed on the system from correct <code>kernel-devel</code> package), and performs compilation on the fly. This will make sure that memory layout that BPF program expects is exactly the same as in the target host's running kernel. If you have to deal with some optional and potentially compiled-out stuff in kernel, you'll just do <code>#ifdef</code>/<code>#else</code> guarding in your source code to accommodate such hazards as renamed fields, different semantics of values, or any optional stuff not available on current configuration. Embedded Clang will happily remove irrelevant parts of your code and will tailor BPF program code to specific kernel.</p>
<p>This sounds great, doesn't it? Not quite so, unfortunately. While this workflow works, it's not without major drawbacks.</p>
<ul>
<li><p>Clang/LLVM combo is a big library, resulting in big fat binaries that need to be distributed with your application.</p></li>
<li><p>Clang/LLVM combo is resource-heavy, so when you are compiling BPF code at start up, you'll use a significant amount of resources, potentially tipping over a carefully balanced production workfload. And vice versa, on a busy host, compiling a small BPF program might take minutes in some cases.</p></li>
<li><p>You are making a big bet that the target system will have kernel headers present, which most of the time is not a problem, but sometimes can cause a lot of headaches. This is also an especially annoying requirement for kernel developers, because they often have to build and deploy custom one-off kernels as part of their development process. And without a custom-built kernel header package, no BCC-based application will work on such kernels, stripping developers of a useful set of tools for debugging and monitoring.</p></li>
<li><p>BPF program testing and development iteration is quite painful as well, as you are going to get even most trivial compilation errors only in runtime, once you recompile and restart your user-space control application. This certainly increases friction and is not helping to iterate fast.</p></li>
</ul>
<p>Overall, while BCC is a great tool, especially for quick prototyping, experimentation, and small tools, it certainly has lots of disadvantages when used for widely deployed production BPF applications.</p>
<p>We are stepping up the game of BPF portability with BPF CO-RE and believe this is a future of BPF program development, especially for complex real-world BPF applications.</p>
<h2>High-level BPF CO-RE mechanics</h2>
<p>BPF CO-RE brings together necessary pieces of functionality and data at all levels of the software stack: kernel, user-space BPF loader library (libbpf), and compiler (Clang) – to make it possible and easy to write BPF programs in a portable manner, handling discrepancies between different kernels within the same pre-compiled BPF program. BPF CO-RE requires a careful integration and cooperation of the following components:</p>
<ul>
<li><p>BTF type information, which allows to capture crucial pieces of information about kernel and BPF program types and code, enabling all the other parts of BPF CO-RE puzzle;</p></li>
<li><p>compiler (Clang) provides means for BPF program C code to express the intent and record relocation information;</p></li>
<li><p>BPF loader (<a href="https://github.com/libbpf/libbpf">libbpf</a>) ties BTFs from kernel and BPF program together to adjust compiled BPF code to specific kernel on target hosts;</p></li>
<li><p>kernel, while staying completely BPF CO-RE-agnostic, provides advanced BPF features to enable some of the more advanced scenarios.</p></li>
</ul>
<p>Working in ensemble, these components …</p></span></p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://facebookmicrosites.github.io/bpf/blog/2020/02/19/bpf-portability-and-co-re.html">https://facebookmicrosites.github.io/bpf/blog/2020/02/19/bpf-portability-and-co-re.html</a></em></p>]]>
            </description>
            <link>https://facebookmicrosites.github.io/bpf/blog/2020/02/19/bpf-portability-and-co-re.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24259499</guid>
            <pubDate>Mon, 24 Aug 2020 11:10:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Pieter Levels Makes $600k a Year from Nomad List and Remote OK]]>
            </title>
            <description>
<![CDATA[
Score 280 | Comments 137 (<a href="https://news.ycombinator.com/item?id=24259201">thread link</a>) | @Pete-Codes
<br/>
August 24, 2020 | https://www.nocsdegree.com/pieter-levels-learn-coding/ | <a href="https://web.archive.org/web/*/https://www.nocsdegree.com/pieter-levels-learn-coding/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
                    <div>
                        <p><a href="https://twitter.com/levelsio">Pieter Levels </a>makes about $600,000 a year. He taught himself to code and has an unconventional philosophy. This is not an interview but an analysis piece. Pieter defied the critics and built Nomad List and Remote OK into successful businesses without cutting edge tools like React or other modern frameworks. I send articles like this twice a week - <a href="https://nocsdegree.carrd.co/">join 2,000 developers that get the newsletter</a>.</p><h2 id="who-is-pieter-levels">Who is Pieter Levels</h2><p>Pieter is a self-taught developer from The Netherlands. He has an MBA but no coding qualifications. As we will see in today's article he has a rough and ready approach to coding but it pays off handsomely. </p><p>His <a href="https://www.nomadlist.com/">Nomad List</a> directory and community for digital nomads draws in over $300k a year and that's despite a recent fall in revenue due to people not travelling during the Corona virus crisis. </p><figure><img src="https://www.nocsdegree.com/content/images/2020/05/Screenshot-2020-05-14-at-23.30.06.png" alt=""></figure><p>His Remote Ok job board for remote workers made <a href="https://remoteok.io/open">$300,000 over the last 12 months</a></p><figure><img src="https://www.nocsdegree.com/content/images/2020/05/Screenshot-2020-05-14-at-23.23.51.png" alt="Revenue chart for Remote OK job board"></figure><p>So that's a total of $600,00 from the last 12 months! Not bad for a self-taught developer! Pieter is active on Twitter and has a very stong following there. </p><p>As he works for himself he is able to travel extensively and live where he choses. Although, rather than the common misconception of digital nomads being constantly on the move, Pieter recommends spending a few months in each place. This way you avoid travel burnout. </p><h2 id="how-did-pieter-levels-learn-to-code">How did Pieter Levels learn to code?</h2><p>Not a lot is known about his very earlies forays into coding apart from the fact that as a teenager he played around programming. His first attempt at a web business was an analytics service for Youtube which would let you see how all your videos/channels were performing in one place. Unfortunately, he worked on it for a year without making any money from it. </p><p>From that point Pieter adopted his now familar approach to coding and business - build websites quickly and monetize from the beginning. He only adds more features if there is money coming in and the idea is validated by the market.</p><p>Pieter takes the "search on Google" approach to Google. So when he wanted to connect a database to a website or make a button do something on his website he would just search the terms on Google and find solutions in places like Stackoverflow. Pieter is a strong critic of the approach of doing courses as he believes people learn best by doing and building. </p><p>One analogy would be different approaches to learning Spanish. One person might study a course, learn the correct grammar and then go to Spain. Whereas Pieter would go to Spain, ask for the words he needs to use and go from there. </p><p>When asked in the past why he didn't use modern frameworks like React he made the point that as he was a solo founder he couldn't afford to spend time re-building his websites as this would mean his project would stall. </p><!--kg-card-begin: markdown--><p><a href="https://gum.co/GGofo"><img src="https://www.nocsdegree.com/content/images/2020/08/monetize.png" alt="monetize"></a></p>
<!--kg-card-end: markdown--><h2 id="what-technologies-does-pieter-levels-use">What technologies does Pieter Levels use?</h2><p>Pieter is famous (or infamous) for having a rather eccentric choice of stack by modern standards. It's essentially the easiest, least glamorous tools you could imagine. But that's ok because Pieter makes $600k a year! </p><p>Here is his stack:</p><ul><li>HTML (hand coded so no template to make life easier)</li><li>CSS (He has used pre-processors like LESS and SASS in the past)</li><li>Javascript (No frameworks - this is sometimes referred to jokingly as Vanilla Javascript. There is no such thing as Vanilla JS though. It's just plain-old Javascript without a framework such as React, Vue or Angular) </li><li>jQuery (An unfashionable choice nowadays but it does the job)</li><li>PHP (He doesn't use any frameworks like Laravel)</li><li>SQLite - Pieter says it's super quick and swears by it. SQLite is a database written in a single file so Pieter doesn't need to set up a server for it. &nbsp;</li><li>his sites are hosted on a single VPS running Ubuntu with NGINX.</li></ul><p>Here are some modern options Pieter doesn't use </p><ul><li>React - he jokes a lot about how he never wants to learn it due to it's (perceived) complexity. </li><li>Node - for a time he considered using it but he's never used it in production</li><li>Angular/ Vue - he doesn't use any Javascript frameworks </li><li>SQL/ Postgres - he doesn't use any of the conventional databases </li></ul><h2 id="get-a-job-without-a-cs-degree-">Get a job without a CS degree 👇</h2><!--kg-card-begin: markdown--><p><a href="http://nocsok.com/"><img src="https://www.nocsdegree.com/content/images/2020/08/Screenshot-2020-08-07-at-17.35.28-2.png" alt="No-CS-OK-screenshot-1"></a></p>
<!--kg-card-end: markdown--><h2 id="what-results-has-pieter-had-with-this-approach-to-coding">What results has Pieter had with this approach to coding?</h2><p>Despite the technical critics, Pieter has been consistently making six figures since 2014. He currently makes approximately $600,000 a year which is far more than most developers. He has been able to live in countries with a low cost of living so he will likely be able to have financial independence and not need to work relatively soon. </p><figure><blockquote data-width="550"><p lang="en" dir="ltr">📈 Record sales yesterday of $2,342.04 on <a href="https://t.co/S9Qv34rpbP">https://t.co/S9Qv34rpbP</a> for no apparent reason (maybe companies are spending their EOY HR budgets?). Normal sales is like $299 or 1 post per day. <a href="https://t.co/8HukglDuiv">pic.twitter.com/8HukglDuiv</a></p>— ؜ (@levelsio) <a href="https://twitter.com/levelsio/status/938699122445451265?ref_src=twsrc%5Etfw">December 7, 2017</a></blockquote>

</figure><figure><blockquote data-width="550"><p lang="en" dir="ltr"><a href="https://t.co/rORz8xdCQp">https://t.co/rORz8xdCQp</a> is a single PHP file called "index.php" generating $2,342.04 in a day. No frameworks. No libraries. 💖</p>— ؜ (@levelsio) <a href="https://twitter.com/levelsio/status/938707166508154880?ref_src=twsrc%5Etfw">December 7, 2017</a></blockquote>

</figure><h2 id="what-is-pieter-levels-working-on-now">What is Pieter Levels working on now?</h2><p>He just released a new project, <a href="https://remoteworkers.dev/">Remote Workers</a>, where people can post their resumé. He "built in public" - that is to say he gave daily updates of his code on Twitter. This is also a great way for developers to build an audience! You can check out what people are saying about Remote Workers on <a href="https://www.producthunt.com/posts/remote-workers">Product Hunt</a>. </p><h2 id="conclusion">Conclusion</h2><p>Pieter is like a bare knuckle boxer so don't compare him to a Judo practioner going to the Olympics. One is going to win no matter what and one is going to follow the rules they have trained under and have finer technique. Neither is better or worse. It depends on the situation. </p><p>Pieter's approach would not be good if you were trying to get a job in a lot of companies. But Pieter isn't looking for a job and the proof for him is in his bank balance. So Pieter's scrappy technique is better suited if you are attracted to coding for entrepreneurship and being a solo founder who doesn't have to share their code with others to work on. He doesn't use Github to save his code, for instance and this is an industry standard that most employers expect. If you want to be an indie hacker/entrepreneur though then Pieter is a fine act to follow. </p><h3 id="if-you-enjoyed-this-article-please-send-it-to-a-friend">If you enjoyed this article please send it to a friend </h3><!--kg-card-begin: html--><!--kg-card-end: html--><h3 id="and-you-should-totally-sign-up-for-the-newsletter">And you should totally <a href="https://nocsdegree.carrd.co/">sign up for the newsletter</a> </h3>
                    </div>
                </section></div>]]>
            </description>
            <link>https://www.nocsdegree.com/pieter-levels-learn-coding/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24259201</guid>
            <pubDate>Mon, 24 Aug 2020 10:21:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A tale of webpage speed, or throwing away React]]>
            </title>
            <description>
<![CDATA[
Score 343 | Comments 286 (<a href="https://news.ycombinator.com/item?id=24258855">thread link</a>) | @todsacerdoti
<br/>
August 24, 2020 | https://solovyov.net/blog/2020/a-tale-of-webpage-speed-or-throwing-away-react/ | <a href="https://web.archive.org/web/*/https://solovyov.net/blog/2020/a-tale-of-webpage-speed-or-throwing-away-react/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section itemprop="articleBody">
  <p>Back in 2011, I happened to get a job writing <a href="https://backbonejs.org/">Backbone.js</a> app. If you never did that, don’t. I was complaining about difficulties with composition left and right to whoever would listen. As I started digging into alternatives for the front-end, I discovered <a href="https://en.wikipedia.org/wiki/Functional_reactive_programming">FRP</a> and <a href="https://www.flapjax-lang.org/">Flapjax</a>, and <a href="https://clojurescript.org/">ClojureScript</a>. The last one got me hooked on <a href="https://clojure.org/">Clojure</a>. I even did a <a href="https://fwdays.com/event/js-frameworks-day-2013/review/Functional-Reactive-Programming-&amp;-ClojureScript">successful talk</a> on FRP and ClojureScript (and precursor to <a href="https://hoplon.io/">Hoplon</a>, called hlisp).</p>
<h2 id="react">React</h2>
<p>Then in May 2013 React was released. I championed it on my new job and discovered during Clojure-themed hackaton (<a href="https://solovyov.net/blog/2013/clojurecup/">Clojure Cup 2013</a>) that CLJS and React are a great match. What’s so good about React though? To me, the main selling point is that it composes well.</p>
<p>When you use predecessors like jQuery or Backbone or Angular or whatever after just a year of development your code is a mess of event listeners and triggers. Don’t get me started on unobtrusive JS, code locality is non-existent with jQuery. Which handler is bound where and what it does? It’s too hard to discover to be a good base for a good codebase!</p>
<p>Then I started working at <a href="https://kasta.ua/">Kasta</a>, where web frontend was exactly that jQuery-ish mess. Nobody ever wanted to touch checkout, since you could spend hours, if not days, making the smallest change. Then QA would find more invalid states than you can dream of. And then users would report more bugs to our call center. It was just as awful as you can imagine.</p>
<p>So after some experiments, tests, and checks, I decided that we’re going React + ClojureScript way with server-side rendering done in Clojure.</p>
<h2 id="demise">Demise</h2>
<p>And for a while, things were looking good. We had this <a href="https://solovyov.net/blog/2017/server-side-rendering/">architecture</a> where our components are executed as Clojure on the backend, so no Node.js on the server, hurray! And developer UX is through the roof with the excellent live reload (thanks CLJS), ability to connect from your editor to browser REPL, and experiment there. It is just great!</p>
<p>To make a long story short, our frontend grew bigger and bigger. Incremental compilation started to become slower — it now routinely takes more than a second or two. And while there were few attempts on keeping the whole app performant, ultimately we failed. It’s a death by a thousand cuts. The application became too big and its boot time became too long. Server side rendering helps partially, but then hydration freezes the browser. On the older hardware or Androids it became unacceptable!</p>
<p>One of the main reasonings back in 2016 was that we take a hit on startup time, but in turn, get no page loads and have a rich web application with a lot of interactions. And for a while that worked! But startup time became longer and longer, leading to a shameful rating of 5/100 from Google’s PageSpeed (okay, it was sometimes up to ~25/100, whatever).</p>
<p>More than that, while doing what is described below, we’ve discovered that React also leads to some questionable practices. Like hovers in JS (rather than in CSS), drop-down menus in JS, not rendering hidden (under a hover) text (Google won’t be happy), weird complex logic (since it’s possible!), etc. You can have a React app without those problems, but apparently, you have to have better self-control than we had (nobody’s perfect!).</p>
<p>Also since then, the vast majority of our users switched to mobile apps. This made the web app the main entry point for new users. This means its main goal is rendering fast for a newcomer, because old-timers, which want more functionality, are on mobile app now. And <a href="https://web.dev/tti/">TTI</a> (time to interactive) is so much more important here.</p>
<h2 id="time-for-a-change">Time For A Change</h2>
<p>So given that circumstances have changed, what do we do? I read articles “how I survive on vanilla JS” since before React appeared and they usually don’t make sense — it’s either a pink-glassed rant about how great it is, disregarding all the problems (separation of concerns, cohesion, composability, code locality) or a project by one (or few) persons, who just keep everything in their head.</p>
<p>Somewhere back in February I stumbled upon <a href="https://intercoolerjs.org/">Intercooler.js</a>. I’m not sure if I ever saw it before — maybe I did but skimmed over — it does not matter. This time it captured my attention.</p>
<p>The idea is that all HTML is rendered on the server. And client updates parts of HTML, controlled by element’s attributes. Basically like HTML+XHR on steroids. You can’t do anything you want, but that’s partially the point: some limits are good so you won’t do crazy stuff. And you need some support from the server, so you can render partial results — just an optimization, but quite an important one.</p>
<p>There is an alternative library — <a href="https://unpoly.com/">Unpoly</a>. It has more features around layout and styling but has a little bit less thought out XHR stuff (hard to do a POST request with parameters without having a form, for example). And the library size is much bigger. And it’s written in CoffeeScript with lots of classes, <a href="https://solovyov.net/blog/2020/inheritance/">ugh</a>.</p>
<p>So I made a proof-of-concept implementation of our catalogue page in Intercooler and it worked! Except there was a dependency on jQuery and some other irritating stuff… As I was struggling to make a batch request for HTML fragments I understood one thing: when I wrote down a roadmap for catalogue the last point was “small intercooler-like thing for analytics”.</p>
<p>So why wait?</p>
<h2 id="twinspark">TwinSpark</h2>
<p>I liked Intercooler’s coherent approach to working around AJAX, so I decided to name the library after some automotive stuff as well, and TwinSpark seems like an appropriate name. So what’s the deal?</p>
<p><a href="https://github.com/kasta-ua/twinspark-js">TwinSpark</a> is a framework for declarative HTML enhancement: you put additional attributes on your element and TwinSpark does something with them. Like makes an AJAX call and replaces target with a response, or adds a class, or… well, see <a href="https://kasta-ua.github.io/twinspark-js/">examples</a>, shall you?</p>
<p>There are some differences with Intercooler, of course, because why would it exist? The most noticeable one is that there is no dependency on jQuery. It supports only modern browsers (not IE or Opera Mini) but drops that 88kb monster.</p>
<p>It also has:</p>
<ul>
<li>no inheritance — can’t stress that enough!</li>
<li>clear extension points for your directives</li>
<li>support for batching requests to a server</li>
<li>tighter attribute name convention (my own opinion, but <code>ic-get</code> and <code>ic-post</code> irritate me: do not make me change keys!)</li>
<li>much smaller payload (thanks to no jQuery!)</li>
<li>should be faster (thanks to no jQuery again)</li>
</ul>
<p>Honestly speaking, the main reasons are <a href="https://kasta-ua.github.io/twinspark-js/#batch">batching</a> and <a href="https://solovyov.net/blog/2020/inheritance/">no inheritance</a>. Inheritance is particularly painful here. In Intercooler, if you declared <code>ic-target</code> on the body, all tags inside will think it’s their target too. So you include a component somewhere in HTML tree and an attribute higher on tree changes this component behavior. I mean this is a freaking dynamic scope, I want none of that! :)</p>
<p>Funnily enough, after about a month of dabbling with TwinSpark, Intercooler’s author announced that he’s doing a jQuery-less modern version: <a href="https://htmx.org/">htmx</a>. :) It has really good extensions points, so maybe it’s possible to add batching… but inheritance is still there. :-(</p>
<h2 id="why-is-that-a-good-idea">Why is that a good idea</h2>
<p>We need to look at it from two sides: if it’s good for developers and if it’s good for users. React was great at former and terrible at later.</p>
<p>TwinSpark approach is much better in most cases for the user: less JavaScript, less jitter, more common HTML-like behavior. In the worst case, we would serve you 2.5MB of minified (non-gzipped) JS and 700KB of HTML (half of it were initial data for React) for catalogue. JS bundle is not that big because of embedded images or css or some other obscure stuff, it’s big because it’s the whole app, with a lot of views and logic.</p>
<p>Now it’s 40KB of minified non-gzipped JS (TwinSpark, analytics, some behavior, IntersectionObserver polyfill) and 350KB of HTML. Two orders of magnitude difference and even HTML is smaller! This is just like Christmas in childhood!</p>
<p>On the developer side, I think React is better still, but code locality is great, composability is much better (since you are forced in a limited world of working in a simplistic model) than with jQuery. Plus there are a lot of ways to improve it.</p>
<p>The good news is that the development process did not change that much! We’re still writing components that query necessary data from site-wide memory store (and make a call to API when needed), but they are executed only on the server. We effectively piggy-backend on our previous architecture, and this gives us the perfect ability to render “partial” HTML - since components do not wait for some “controller” to give them all necessary data. This is what allowed us to have both React and non-React versions to co-exist and make an A/B test without writing the markup twice.</p>
<h2 id="results">Results</h2>
<p>It took us four months since the first experiments to release. Not exactly the amount of time I imagined when we started (“should take two to three weeks at most!"), heh, but we were not exclusively doing that. It still took a lot of time and energy to remove React-isms from the code and wrangle our app to be a server-side citizen. It still could use some polishing, but we decided to release it despite that just to cut it short. And A/B test showed that we were right — especially for Android phones.</p>
<p>Google gives our catalogue 75/100 now instead of 5/100. Hurray, I guess? :)</p>

  </section></div>]]>
            </description>
            <link>https://solovyov.net/blog/2020/a-tale-of-webpage-speed-or-throwing-away-react/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24258855</guid>
            <pubDate>Mon, 24 Aug 2020 09:25:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Apparatus with Magnets]]>
            </title>
            <description>
<![CDATA[
Score 39 | Comments 6 (<a href="https://news.ycombinator.com/item?id=24258396">thread link</a>) | @jiriro
<br/>
August 24, 2020 | https://www.notion.so/Apparatus-with-Magnets-Intro-2e32af5b59b64a45b3b203408374a56e | <a href="https://web.archive.org/web/*/https://www.notion.so/Apparatus-with-Magnets-Intro-2e32af5b59b64a45b3b203408374a56e">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.notion.so/Apparatus-with-Magnets-Intro-2e32af5b59b64a45b3b203408374a56e</link>
            <guid isPermaLink="false">hacker-news-small-sites-24258396</guid>
            <pubDate>Mon, 24 Aug 2020 07:59:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[IBM 5160]]>
            </title>
            <description>
<![CDATA[
Score 24 | Comments 21 (<a href="https://news.ycombinator.com/item?id=24258010">thread link</a>) | @hwdegroot
<br/>
August 23, 2020 | https://www.forsure.dev/-/2020/05/19/640-kilobytes-of-ram-and-why-i-bought-an-ibm-5160/ | <a href="https://web.archive.org/web/*/https://www.forsure.dev/-/2020/05/19/640-kilobytes-of-ram-and-why-i-bought-an-ibm-5160/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
        
        <div>
            <blockquote>
<p>640 Kilobytes!!!!1!!1 I shit you not. That is like 10 times the size of Donald Trump’s brain.</p>
</blockquote>
<p>Recently I was trying to get my son enthousiastic for programming. He is currently 7 years old and getting interested in all kinds of electronics,
so I thought that getting acquainted with programming would not hurt him. And I like to think of myself as a parent that stimulates his kids, so I used that
as an excuse to look into older computers, because <em>nostalgics</em>.</p>
<p><a href="#show-me-the-pics">Show me them footage</a></p>
<p>My kids grew up with LED monitors and TV’s and never really saw a real cathode tube, except on the episodes of <a href="https://en.wikipedia.org/wiki/Pat_%26_Mat">Pat &amp; Mat</a>.
I still remember the soft fading sound of of the tv turning off and the graphics vanishing into this thin line.</p>



<figure id="6fe72747c83aa07dbdebd9927f00a3d7">
    <p>
        
        <video controls="">
            <source src="https://www.forsure.dev/-/2020/05/19/640-kilobytes-of-ram-and-why-i-bought-an-ibm-5160/videos/mesmerizing-shutdown.mp4" type="video/mp4">
            Your browser does not support the video tag.
        </video>

    
    
    <figcaption>
        <small>
            
Mesmerizing shutdown. The terminal vanishes into a line.

        </small>
    </figcaption>
    
    </p>
</figure>


<p>Besides that, I am a fan of clicky keyboards. I have a <a href="https://www.daskeyboard.com/daskeyboard-4C-ultimate/">DasKeyboard 4C ultimate</a> tenkeyless with Cherry Blue switches and a <a href="https://www.daskeyboard.com/daskeyboard-4C-tenkeyless-professional/">4C Profressional</a> with brown switches. Sitting at home during the
corona period, made me google old skool stuff a lot.</p>
<p>So first I laid my eyes on a <a href="https://clickykeyboards.com/product/ibm-model-m2-1395300-made-by-ibm-06-30-1993/">IBM Model M2</a> and got this pretty cheap on
the dutch eBay. Getting this to work on my modern laptop was not rocket science, but not straight forward either. I warned my collegues
that the quiet days at the office were over. But this also opened up a window into vintage computers and computing. What if I could get a vintage computer, I thought. How awesome would that be?</p>
<p>How cool would it be to program a vintage computer with my collegues, or my kids. With all the speed we get nowadays, who still thinks about the limits of computing power. This will be totally different if you have just a fraction of the memory and chip available.</p>
<h2 id="ibm-5160">IBM 5160</h2>
<p>I am from 1983. So I was looking for a computer from that year. IBM was <em>the company</em> in those days for personal computing and when it came to makeing PC’s (I am NOT an apple fan). So I found that IBM produced the <a href="https://en.wikipedia.org/wiki/IBM_Personal_Computer_XT"><strong>IBM PC XT</strong></a> in that year. I also found out that you could still get them online for a reasonable price.
Luckliy I was able to lay my hands on one, in a pretty good state. It came with an <a href="https://clickykeyboards.com/product-category/1986-1989-ibm-model-m-silver-label/">IBM Model M</a> keyboard with the silver label (the PC is from 1986). The sound of that is even better than than the <code>Model M2</code>.</p>


<figure id="c1eacc927bc26694d18237b77c9b6c5e">
    <p><audio controls="">
            <source src="https://www.forsure.dev/-/2020/05/19/640-kilobytes-of-ram-and-why-i-bought-an-ibm-5160/audio/IBM-model-m-oh-that-clicky-sound.mp3" type="audio/mpeg">
            Your browser does not support the audio tag.
        </audio>
    </p>
    
    <figcaption>
        <small>
            
Need I say more...

        </small>
    </figcaption>
    
</figure>


<p>After introducing my kids to th <code>DIR</code> command (it was the only one I was pretty sure about it would work), they wanted to type “words” on the old computer (first success).</p>
<h2 id="exiting-vim-is-hard">Exiting Vim is hard?</h2>
<p>So, I know the <code>DIR</code> command. But now what. Let’s see what commands are available.</p>
<ul>
<li>No tab completion. <code>TAB</code> just places the cursor somewhere down the line</li>
<li>No <code>HISTORY</code>. You can repeat the last command by pressing the right-arrow.</li>
</ul>
<p><strong>FEEDBACK</strong></p>
<blockquote>
<p>This is incorrect. You say that you have IBM PC DOS 5. If so, this includes the DOSKEY command. This will give you a command-line history with editing. Just type <code>dos\doskey</code> to load it.</p>
</blockquote>
<p>For a starters, on <code>IBM DOS</code> (version 5.0) there is no <code>$PATH</code>. The executables are located in <code>C:\DOS</code> (or <code>c:\dos</code>, because <code>DOS</code> don’t care about casing). the most executables are located. After a day or two I figured this out, so I finally managed to open my first <code>BASIC</code> program. All fine, until I wanted to quit the program. It’s not that easy as <a href="https://stackoverflow.com/questions/11828270/how-do-i-exit-the-vim-editor">exiting <code>Vim</code></a>. It took me quite some time googling, until I finally found this <a href="https://stackoverflow.com/questions/44253055/how-can-i-exit-microsoft-gw-basic-ibm-basica-or-other-similar-old-dialects-of">lifesaver</a>.</p>
<p><strong>FEEDBACK</strong></p>
<blockquote>
<p>There certainly should be! DOS has 2 configuration files, which live in the root directory of the boot drive (A: or C:). They are called [1] CONFIG.SYS and [2] AUTOEXEC.BAT. In the 2nd, there should be a line:
<code>PATH=C:\DOS; C:\</code></p>
</blockquote>








<figure id="1fadd62c83243e573af5941d4eb32c02">
    <div>
        <p><img src="https://www.forsure.dev/-/2020/05/19/640-kilobytes-of-ram-and-why-i-bought-an-ibm-5160/images/basic-startup-screen_hu03af1e9e4264eec2575cd1ba06f1e20e_255454_600x600_fit_q75_box.jpg" width="600" height="450"></p><figcaption>
            <small>
                
                
Entering BASIC is peanuts

                
            </small>
        </figcaption>
    </div>
</figure>
<div data-target="1fadd62c83243e573af5941d4eb32c02">
    <div>
        <p><span id="close-1fadd62c83243e573af5941d4eb32c02">×</span></p><p><img src="https://www.forsure.dev/-/2020/05/19/640-kilobytes-of-ram-and-why-i-bought-an-ibm-5160/images/basic-startup-screen.jpg" width="4032" height="3024"></p>
    </div>
</div>










<figure id="0e171f24d2705fcfc1f3dddef5ea66e3">
    <div>
        <p><img src="https://www.forsure.dev/-/2020/05/19/640-kilobytes-of-ram-and-why-i-bought-an-ibm-5160/images/cannot-exit-basic_hu7173749eb1353b22f37803cfee1222d6_251610_600x600_fit_q75_box.jpg" width="600" height="450"></p><figcaption>
            <small>
                
                
Stuck in BASIC

                
            </small>
        </figcaption>
    </div>
</figure>
<div data-target="0e171f24d2705fcfc1f3dddef5ea66e3">
    <div>
        <p><span id="close-0e171f24d2705fcfc1f3dddef5ea66e3">×</span></p><p><img src="https://www.forsure.dev/-/2020/05/19/640-kilobytes-of-ram-and-why-i-bought-an-ibm-5160/images/cannot-exit-basic.jpg" width="4032" height="3024"></p>
    </div>
</div>





<figure id="34bf581ec5de30d29fb4a52465d157a0">
    <p>
        
        <video controls="">
            <source src="https://www.forsure.dev/-/2020/05/19/640-kilobytes-of-ram-and-why-i-bought-an-ibm-5160/videos/trying-stuff-in-qbasic.mp4" type="video/mp4">
            Your browser does not support the video tag.
        </video>
    
    
    <figcaption>
        <small>
            
Trying to exit QBASIC. Epic fail

        </small>
    </figcaption>
    
    </p>
</figure>


<p><strong>FEEDBACK</strong></p>
<blockquote>
<p>That is <em>not</em> <code>QBASIC</code>; <code>QBASIC</code> has a GUI. You were in either <code>BASICA</code> or <code>GWBASIC</code>. The command to quit is <code>syst em</code>, if I remember correctly after 30 years.</p>
</blockquote>
<p>So, now I can start a few commands, but getting all available commands is not that straight forward. There is a lot in the <code>DOS</code> directory, but there is no scrolling, and the monitor only is 25 lines.</p>
<p><strong>FEEDBACK</strong></p>
<blockquote>
<p>Yes there is [scrolling]. Type <code>dir /p</code> for page-by-page. <code>dir /w</code> gives a wide listing. You can combine these: <code>dir /w /p</code>. You can also do <code>dir | more</code></p>
</blockquote>
<blockquote>
<p>[the monitor is only 25 lines] This depends on the graphics card. If you have an MDA card, no, 25 lines is all. Try <code>mode con: lines=43</code> or <code>mode con: lines=50</code>. This will only work on a VGA-compatible card, though, and you will need ANSI.SYS installed, I think.</p>
</blockquote>
<p>So figuring out the available commands is using a lot of <code>DIR *.EXE</code>'s and <code>DIR *.COM</code>'s.</p>
<p>First class fun.</p>
<h2 id="show-me-the-pics">Show me the pics</h2>
<p>Not so long ago I was explaining my collegue (who is using a screensaver), <a href="https://en.wikipedia.org/wiki/Screensaver">where a screensaver got its name from</a>. Back in the days, when we were all running the <a href="https://www.youtube.com/watch?v=Uzx9ArZ7MUU">pipes</a> so the screen would not <span>fuck up</span>
.</p>
<p>But now, sit back and relax…</p>



<figure id="f3b027a374567777bfd8178001360334">
    <p>
        
        <video controls="">
            <source src="https://www.forsure.dev/-/2020/05/19/640-kilobytes-of-ram-and-why-i-bought-an-ibm-5160/videos/insane-refresh-rate-oldskool-monitor.mp4" type="video/mp4">
            Your browser does not support the video tag.
        </video>

    
    
    <figcaption>
        <small>
            
Check this insane refresh rate of the cathode tube. The color of the terminal is magnificent! 😍

        </small>
    </figcaption>
    
    </p>
</figure>





<figure id="4cdf95e55b8fbd6e1c5e3ea1f0bd43bf">
    <p>
        
        <video controls="">
            <source src="https://www.forsure.dev/-/2020/05/19/640-kilobytes-of-ram-and-why-i-bought-an-ibm-5160/videos/more-refresh-rate.mp4" type="video/mp4">
            Your browser does not support the video tag.
        </video>

    
    
    <figcaption>
        <small>
            
And more refresh rate. The mesmerizing fading away of the fonts into the background. Beautiful, just beautiful

        </small>
    </figcaption>
    
    </p>
</figure>





<figure id="6f82255ebe285b0963065fc046514bcf">
    <p>
        
        <video controls="">
            <source src="https://www.forsure.dev/-/2020/05/19/640-kilobytes-of-ram-and-why-i-bought-an-ibm-5160/videos/booting-into-dos.mp4" type="video/mp4">
            Your browser does not support the video tag.
        </video>

    
    
    <figcaption>
        <small>
            
🔈 The startup is amazing as well. The sound of the fan, and the nostalgic beep.

        </small>
    </figcaption>
    
    </p>
</figure>





<figure id="43c3937b62bdb5325a2b1a8a57bc530d">
    <p>
        
        <video controls="">
            <source src="https://www.forsure.dev/-/2020/05/19/640-kilobytes-of-ram-and-why-i-bought-an-ibm-5160/videos/booting-into-dos-again.mp4" type="video/mp4">
            Your browser does not support the video tag.
        </video>

    
    
    <figcaption>
        <small>
            
🔈 One more time. I could loop this forever.

        </small>
    </figcaption>
    
    </p>
</figure>










<figure id="01da5907dc0ec7a58dc42ca82d974286">
    <div>
        <p><img src="https://www.forsure.dev/-/2020/05/19/640-kilobytes-of-ram-and-why-i-bought-an-ibm-5160/images/ibm-dos-edit-dutch_hu3a6de3285dc77b6df0e675474f4c7576_447189_600x600_fit_q75_box.jpg" width="600" height="450"></p><figcaption>
            <small>
                
                
un DOS tres. The fluorescence is soooo pretty.

                
            </small>
        </figcaption>
    </div>
</figure>
<div data-target="01da5907dc0ec7a58dc42ca82d974286">
    <div>
        <p><span id="close-01da5907dc0ec7a58dc42ca82d974286">×</span></p><p><img src="https://www.forsure.dev/-/2020/05/19/640-kilobytes-of-ram-and-why-i-bought-an-ibm-5160/images/ibm-dos-edit-dutch.jpg" width="4032" height="3024"></p>
    </div>
</div>










<figure id="69f512f8bcce7a3b38b62b31e321231a">
    <div>
        <p><img src="https://www.forsure.dev/-/2020/05/19/640-kilobytes-of-ram-and-why-i-bought-an-ibm-5160/images/wpview-printer-driver-bat-file_hu5af41f7c240e39ab901ff694320d0a39_288464_600x600_fit_q75_box.jpg" width="600" height="450"></p><figcaption>
            <small>
                
                
wppreview, I totally miss the point of this program. But, hey, it's there.

                
            </small>
        </figcaption>
    </div>
</figure>
<div data-target="69f512f8bcce7a3b38b62b31e321231a">
    <div>
        <p><span id="close-69f512f8bcce7a3b38b62b31e321231a">×</span></p><p><img src="https://www.forsure.dev/-/2020/05/19/640-kilobytes-of-ram-and-why-i-bought-an-ibm-5160/images/wpview-printer-driver-bat-file.jpg" width="4032" height="3024"></p>
    </div>
</div>


<p><strong>FEEDBACK</strong></p>
<blockquote>
<p>It [wppreview] is not part of DOS. Sounds like a WordPerfect preview program for use with mailmerge.</p>
</blockquote>
<h2 id="what-next">What next?</h2>
<p>So far I had to explain to my son what a <code>file(name)</code> and a <code>command</code> is (when they were typing “words” the IBM kept returning</p>
<p>So the experience is already educational :)</p>
<p>To be honest, I do not have a clear idea what I am going to do with it next. I will be playing with it for a while like an 8 year old with his trains.
After the <a href="https://twitter.com/hashtag/stayathome"><code>#stayathome</code></a> is over, hopefully I can take it to the office, so we can start doing real cool things with it.</p>
<p>I will definitely have to up my <a href="https://www.qb64.org/wiki/GOTO"><code>GOTO</code></a> skills :)</p>
<p>I will start using my Model M2 for work (sorry collegues), for sure. I will have to remap my function key in <a href="https://i3wm.org/"><code>i3</code></a>, because I am currently using the
windows key for this. But the Model M2 does not have one. But I will overcome.</p>
<p><strong>FEEDBACK</strong></p>
<blockquote>
<p>It is easy to remap CapsLock to be a “Windows” (Super) key. This is how I use my IBM Model M in Linux. I suggest <code>xmodmap</code>.</p>
</blockquote>
<p>Besides that, I found this great archive with <a href="ihttps://archive.org/search.php?query=dos%20ibm">manuals</a> and <a href="http://www.retroarchive.org/dos/disks/">bootdisks</a> and even <a href="https://winworldpc.com/download/40c2a543-4218-c39a-11c3-a4e284a2c3a5">PC DOS 5.02</a>. Currently I am trying to get a VM up running PC DOS 5.0 (yes, that is possible in <a href="https://www.youtube.com/watch?v=xfjUkJMe_kw">virtualbox</a>)</p>
<p><strong>FEEDBACK</strong></p>
<blockquote>
<p>If you are willing to change the DOS version, I suggest DR DOS 3.41. The reason is this: MS/PC DOS 5, 6 &amp; later are designed for 386 memory management. This is impossible on an 8088 chip, and as a result, you will have very little free memory. Many DOS programs won’t work.</p>
</blockquote>
<blockquote>
<p>DR-DOS is a better 3rd party clone of DOS, by the company that wrote the original OS (CP/M) that MS-DOS was ripped-off from. The first version is 3.41 (before that it had different names) and it is far more memory-efficient. <a href="https://winworldpc.com/product/dr-dos/3x">https://winworldpc.com/product/dr-dos/3x</a></p>
</blockquote>
<blockquote>
<p>But if you want to stay with an IBM original DOS, then IBM developed PC DOS all the way to version 7.1, which supports EIDE hard disks over 8GB, FAT32 and some other nice features. It is a free download.</p>
</blockquote>
<blockquote>
<p>I have described how to get it here: <a href="https://liam-on-linux.livejournal.com/59703.html">https://liam-on-linux.livejournal.com/59703.html</a></p>
</blockquote>
<blockquote>
<p>PC DOS 7 is a bit strange; IBM removed Microsoft’s GUI editor and replaced it with an OS/2-derived one called E, which has a weird UI. IBM also removed GWBASIC and replaced it with the Rexx scripting language.</p>
</blockquote>
<blockquote>
<p>Personally, I combine bits of PC-DOS 7.1 with Microsoft’s editor, Microsoft’s diagnostics, Scandisk disk-repair tool and some other bits, but that is more than I can cover in a comment!</p>
</blockquote>
<blockquote>
<p>There is a lot you can do to upgrade a 5160 if you wish. Here is a crazy example: <a href="https://sites.google.com/site/misterzeropage/">https://sites.google.com/site/misterzeropage/</a></p>
</blockquote>
<blockquote>
<p>I would not go that far, but a VGA card, VGA CRT, a serial mouse and an XTIDE card with a CF card in it, and it would be a lot easier to use…</p>
</blockquote>
<p>The downside, my Cherry MX blue switches feel like second class now.</p>
<h2 id="update">UPDATE</h2>
<p>When I was installing my VM with <code>PC DOS</code>, at the end of the installation I was aske if I wanted to start in <code>shell</code> mode. It turns out there is a command <code>DOSSHELL</code> (needs to be executed fron <code>C:\DOS</code>) which gives you a very fancy
gui.</p>








<figure id="8a76cf6b5c012a99a1bf166c516671c4">
    <div>
        <p><img src="https://www.forsure.dev/-/2020/05/19/640-kilobytes-of-ram-and-why-i-bought-an-ibm-5160/images/dosshell_hu8b1374a2b83ba8d4970af29e66446ddf_361223_600x600_fit_q75_box.jpg" width="600" height="450"></p><figcaption>
            <small>
                
                
😱 It …</small></figcaption></div></figure></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.forsure.dev/-/2020/05/19/640-kilobytes-of-ram-and-why-i-bought-an-ibm-5160/">https://www.forsure.dev/-/2020/05/19/640-kilobytes-of-ram-and-why-i-bought-an-ibm-5160/</a></em></p>]]>
            </description>
            <link>https://www.forsure.dev/-/2020/05/19/640-kilobytes-of-ram-and-why-i-bought-an-ibm-5160/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24258010</guid>
            <pubDate>Mon, 24 Aug 2020 06:30:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[GCD and the magic of subtraction]]>
            </title>
            <description>
<![CDATA[
Score 42 | Comments 23 (<a href="https://news.ycombinator.com/item?id=24257871">thread link</a>) | @plumsempy
<br/>
August 23, 2020 | https://plumsempy.com/2020/08/24/gcd-and-the-magic-of-subtraction/ | <a href="https://web.archive.org/web/*/https://plumsempy.com/2020/08/24/gcd-and-the-magic-of-subtraction/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">

	<section id="primary">
		<main id="main">

			
<article id="post-1295">

	

	
			<figure>
				<img width="1229" height="727" src="https://plumsempy.files.wordpress.com/2020/08/illustration-4-e1598245496422.png?w=1229" alt="" loading="lazy" srcset="https://plumsempy.files.wordpress.com/2020/08/illustration-4-e1598245496422.png 1229w, https://plumsempy.files.wordpress.com/2020/08/illustration-4-e1598245496422.png?w=150 150w, https://plumsempy.files.wordpress.com/2020/08/illustration-4-e1598245496422.png?w=300 300w, https://plumsempy.files.wordpress.com/2020/08/illustration-4-e1598245496422.png?w=768 768w, https://plumsempy.files.wordpress.com/2020/08/illustration-4-e1598245496422.png?w=1024 1024w" sizes="(max-width: 1229px) 100vw, 1229px" data-attachment-id="1315" data-permalink="https://plumsempy.com/2020/08/24/gcd-and-the-magic-of-subtraction/illustration-4/" data-orig-file="https://plumsempy.files.wordpress.com/2020/08/illustration-4-e1598245496422.png" data-orig-size="1229,727" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Illustration – 4" data-image-description="" data-medium-file="https://plumsempy.files.wordpress.com/2020/08/illustration-4-e1598245496422.png?w=300" data-large-file="https://plumsempy.files.wordpress.com/2020/08/illustration-4-e1598245496422.png?w=750">			</figure><!-- .post-thumbnail -->

		
	<div>
		
<p>The greatest common divisor is something I learned in school but it was one of those “so what?” subjects. But recently I revisited it and it is very interesting.</p>



<p><strong>Why is gcd cool?</strong></p>



<p>Every number, can be expressed as the product of prime numbers. This product for every number is unique; sort of like saying, every number has a fingerprint. This is called the <a href="https://en.wikipedia.org/wiki/Fundamental_theorem_of_arithmetic">fundamental theorem of arithmetic</a>. 36 is <code>4x9</code>, and 45 is <code>5x9</code>. This means that some numbers will have common parts with each other.</p>



<p>These common parts can divide both numbers, and thus they are common divisors. In the example above, 36 is <code>4x9</code> or <code>2x2x3x3</code>, while 45 is <code>5x3x3</code>; 3 is a common divisor of both, so is <code>3x3</code>, which is 9; but 9 is the greatest divisor of both 36 and 45.</p>



<p>One question I had when I was younger, was why we are talking about the “greatest” and not the smallest common divisor. We could, but soon, this gets boring: there is 1, the smallest common divisor of every number, then there are some common divisors in between 1 and the gcd. But what the gcd does so uniquely, is that it takes two numbers and gives us <em>all</em> the common parts of two numbers. </p>



<figure><img data-attachment-id="1328" data-permalink="https://plumsempy.com/2020/08/24/gcd-and-the-magic-of-subtraction/illustration-1-3/" data-orig-file="https://plumsempy.files.wordpress.com/2020/08/illustration-1-2-e1598337364870.png" data-orig-size="1150,844" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Illustration – 1" data-image-description="" data-medium-file="https://plumsempy.files.wordpress.com/2020/08/illustration-1-2-e1598337364870.png?w=300" data-large-file="https://plumsempy.files.wordpress.com/2020/08/illustration-1-2-e1598337364870.png?w=750" src="https://plumsempy.files.wordpress.com/2020/08/illustration-1-2-e1598337364870.png?w=1024" alt="" srcset="https://plumsempy.files.wordpress.com/2020/08/illustration-1-2-e1598337364870.png?w=1024 1024w, https://plumsempy.files.wordpress.com/2020/08/illustration-1-2-e1598337364870.png?w=150 150w, https://plumsempy.files.wordpress.com/2020/08/illustration-1-2-e1598337364870.png?w=300 300w, https://plumsempy.files.wordpress.com/2020/08/illustration-1-2-e1598337364870.png?w=768 768w, https://plumsempy.files.wordpress.com/2020/08/illustration-1-2-e1598337364870.png 1150w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>common and uncommon parts of 36(4×9) and 45(5×9). The gcd of 36 and 45 is 9.</figcaption></figure>



<p>This is cool! The uncommon parts are relatively prime! — meaning, they have nothing in common but the number 1. </p>



<p>So to find the gcd, then, we need to find all the common parts of the two numbers when written in terms of their prime factors. </p>



<p><code>36=3x3x2x2</code> and <code>45=3x3x5</code>, thus the gcd of 36 and 45 is <code>3x3</code>, which is 9. So 36 is 9(4) and 45 is 9(5). It is very interesting to look at numbers as multiples of gcds. Moreover, notice that these multipliers, 4 and 5 in the example above, are relatively prime. </p>



<p><strong>The magic of subtraction</strong></p>



<p>Subtracting two relatively prime numbers, will produce another number that, while not necessarily prime itself, will be relatively prime to both the previous numbers. As an example, <code>13-7=6</code>. 6 is not prime, but it is relatively prime to both 7 and 13. If we subtract 6 from 13 we will get 7 again which is not very interesting. But if we subtract 6 from 7, the smaller one, since 6 and 7 are relatively prime we should get another number that is relatively prime to them both; <code>7-6=1</code>, which is relatively prime to every other number, if keep doing this:</p>


<pre title="">13 -  7 = 6
7  -  6 = 1
6  -  1 = 5
5  -  1 = 4
4  -  1 = 3
3  -  1 = 2
2  -  1 = 1
1  -  1 = 0

(1, 0)
</pre>


<p>The final two numbers are 0 and 1. So whenever we start with two relatively prime numbers and do this on them, it will always end with 0 and 1. This is pretty strange and magical. I am still perplexed by it, but the way I convinced myself, is to think about it bottom up: if we start with the number 1, and try to build our way to any other number by addition, there are finite number of ways. So when we start subtracting, what we are doing is walking that path backwards towards 1. </p>



<figure><img data-attachment-id="1319" data-permalink="https://plumsempy.com/2020/08/24/gcd-and-the-magic-of-subtraction/illustration-3/" data-orig-file="https://plumsempy.files.wordpress.com/2020/08/illustration-3-e1598245714605.png" data-orig-size="1226,634" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="Illustration – 3" data-image-description="" data-medium-file="https://plumsempy.files.wordpress.com/2020/08/illustration-3-e1598245714605.png?w=300" data-large-file="https://plumsempy.files.wordpress.com/2020/08/illustration-3-e1598245714605.png?w=750" src="https://plumsempy.files.wordpress.com/2020/08/illustration-3-e1598245714605.png?w=1024" alt="" srcset="https://plumsempy.files.wordpress.com/2020/08/illustration-3-e1598245714605.png?w=1024 1024w, https://plumsempy.files.wordpress.com/2020/08/illustration-3-e1598245714605.png?w=150 150w, https://plumsempy.files.wordpress.com/2020/08/illustration-3-e1598245714605.png?w=300 300w, https://plumsempy.files.wordpress.com/2020/08/illustration-3-e1598245714605.png?w=768 768w, https://plumsempy.files.wordpress.com/2020/08/illustration-3-e1598245714605.png 1226w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>There is a limited set of paths from any two numbers back to 1 by successive subtractions.</figcaption></figure>



<p>Now why do these two numbers need to be relatively prime? because if they are not relatively prime, that means that they have some parts in common, like 36 and 45 above, remember? they are 9(4) and 9(5). If we do the subtracting trick on them:</p>


<pre title="">9(5) - 9(4) = 9(1)
9(4) - 9(1) = 9(3)
9(3) - 9(1) = 9(2)
9(2) - 9(1) = 9(1)
9(1) - 9(1) = 9(0)

(9(1), 0)
</pre>


<p>So you see, the common part survives the subtractions, while the uncommon parts converge to 1. But 9 is <em>all</em> the common parts of 36 and 45, in other words the gcd of 36 and 45! </p>



<p>Can we keep subtracting any two numbers until we reach (X, 0) and then proclaim X is the greatest common divisor? yes, we can, and it is called the <em><a href="https://en.wikipedia.org/wiki/Euclidean_algorithm">Euclidean Algorithm</a></em>.</p>



<p>Here is a silly experiment, what if we subtract the partially common parts? for 36 and 45, what if we wrote them as 3(12) and 3(15)?</p>


<pre title="">3(15) -  3(12) = 3(3)
3(12) -  3(3)  = 3(9)
3(9)  -  3(3)  = 3(6)
3(6)  -  3(3)  = 3(3)
3(3)  -  3(3)  = 3(0)

(3(3), 0)
</pre>


<p>This is really funny. The algorithm basically told us that the gcd of 12 and 15 is 3. Now if we choose to multiply the other 3 that we have factored out before we started our subtraction, it will yield the same result: the gcd of 36 and 45 is 9.</p>



<p><strong>What just happened?</strong></p>



<p>We started by finding the gcd of two numbers, then subtracting the uncommon, relatively prime parts to realize we always reach 1, so if we always subtract any two numbers from each other repeatedly, since the gcd is a common factor of both, it will remain constant until the end, when the uncommon parts have reduced down to 1 and 0; and then what we are left with is the gcd. </p>



<p>Here is a recursive implementation of it in Python:</p>


<pre title="">def gcd(a,b):
    if a == 0: return b
    if b == 0: return a

    return gcd(abs(a-b), min(a,b))
</pre>


<p>If someone has a better explanation of why subtracting relatively prime numbers repeatedly will always result in one, please leave a comment or reach out and help me understand better.</p>
	</div><!-- .entry-content -->

	<!-- .entry-footer -->

				
</article><!-- #post-${ID} -->

	<nav role="navigation" aria-label="Posts">
		<h2>Post navigation</h2>
		
	</nav>
<!-- #comments -->

		</main><!-- #main -->
	</section><!-- #primary -->


	</div></div>]]>
            </description>
            <link>https://plumsempy.com/2020/08/24/gcd-and-the-magic-of-subtraction/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24257871</guid>
            <pubDate>Mon, 24 Aug 2020 05:57:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Principal Component Analysis]]>
            </title>
            <description>
<![CDATA[
Score 43 | Comments 5 (<a href="https://news.ycombinator.com/item?id=24257468">thread link</a>) | @keyboardman
<br/>
August 23, 2020 | https://leimao.github.io/article/Principal-Component-Analysis/ | <a href="https://web.archive.org/web/*/https://leimao.github.io/article/Principal-Component-Analysis/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <h3 id="introduction">Introduction</h3>

<p>Principal components analysis (PCA) is one of a family of techniques for taking high-dimensional data, and using the dependencies between the variables to represent it in a more tractable, lower-dimensional form, without losing too much information. It has been widely used for data compression and de-noising. However, its entire mathematical process is sometimes ambiguous to the user.</p>



<p>In this article, I would like to discuss the entire process of PCA mathematically, including PCA projection and reconstruction, with most of the derivations and proofs provided. At the end of the article, I implemented PCA projection and reconstruction from scratch. After reading this article, there should be no more black box in PCA anymore.</p>

<h3 id="prerequisites">Prerequisites</h3>

<h4 id="orthogonal-matrix">Orthogonal Matrix</h4>

<p>In linear algebra, an orthogonal matrix is a real square matrix whose columns and rows are orthogonal unit vectors (orthonormal vectors).</p>



<p>Equivalently, the mathematical expression is</p><p>

\[\begin{align}
A^{\top}A = AA^{\top} = I
\end{align}\]

</p><p>By <a href="https://en.wikipedia.org/wiki/Invertible_matrix">the definition of invertible matrix</a>, this means matrix $A$ is invertible and $A^{-1} = A^{\top}$.</p>



<p>We could also view this from the perspective of determinant.</p>



<p>Because $A$ and $A^{\top}$ are square matrices and using <a href="https://en.wikipedia.org/wiki/Determinant#Properties_of_the_determinant">the properties of determinant</a></p><p>

\[\begin{align}
\det(I) &amp;= \det(A^{\top}A) \\
&amp;= \det(AA^{\top}) \\
&amp;= \det(A) \det(A^{\top}) \\
&amp;= \det(A) \det(A) \\
&amp;= \det(A)^2 \\
&amp;= \det(A^{\top})^2 \\
&amp;= 1 \\
\end{align}\]

</p><p>Since $\det(A) \neq 0$, matrix $A$ is invertible. We multiply $A^{-1}$ on both side of the orthogonal matrix definition.</p><p>

\[\begin{align}
A^{\top}A A^{-1} &amp;= I A^{-1}\\
A^{\top} I &amp;= A^{-1} \\
A^{\top} &amp;= A^{-1} \\
\end{align}\]

</p><p>We have also derived the conclusion that $A^{-1} = A^{\top}$.</p>



<p>Similarly, a complex square matrix $A$ is unitary if its transpose conjugate $A^{\dagger}$ is also its inverse.</p>



<p>Equivalently, the mathematical expression is</p><p>

\[\begin{align}
A^{\dagger}A = AA^{\dagger} = I
\end{align}\]

</p><h4 id="symmetric-matrix">Symmetric Matrix</h4>

<p>Real symmetric matrix has the following useful properties:</p>



<p>If $A$ is a real symmetric matrix, all of its eigenvalues are real numbers.</p>



<p>Because of <a href="https://en.wikipedia.org/wiki/Complex_conjugate#Generalizations">the conjugate properties</a> and $\overline{A} = A$ since $A$ is a real value matrix,</p><p>

\[\begin{align}
\overline{Av} &amp;= \overline{\lambda v} \\
&amp;= \overline{A} \overline{v} \\
&amp;= A \overline{v} \\
&amp;= \overline{\lambda} \overline{v} \\
\end{align}\]

</p><p>We got $A \overline{v} = \overline{\lambda} \overline{v}$.</p>



<p>Let $\lambda \in \mathbb{C}$ be an eigenvalue of the symmetric matrix $A$. $Av = \lambda v$ and $v \neq 0$. We multiply $v^{\dagger}$ ($v^{\dagger} = \overline{v}^{\top}$) to the both sides, and because of $A^{\top} = A$ and the property we have just derived $A \overline{v} = \overline{\lambda} \overline{v}$,</p><p>

\[\begin{align}
v^{\dagger} A v &amp;= \lambda v^{\dagger} v \\
&amp;= v^{\dagger} A^{\top} v \\
&amp;= \overline{v}^{\top} A^{\top} v \\
&amp;= (A\overline{v})^{\top} v \\
&amp;= (\overline{\lambda} \overline{v})^{\top} v \\
&amp;= \overline{\lambda}^{\top} \overline{v}^{\top} v \\
&amp;= \overline{\lambda} v^{\dagger} v \\
\end{align}\]

</p><p>We have $\lambda v^{\dagger} v = \overline{\lambda} v^{\dagger} v$, thus $\lambda$ is real.</p>



<p>This concludes the proof.</p>

<h4 id="positive-semi-definite-matrix">Positive Semi-Definite Matrix</h4>

<p>The $n \times n$ symmetric matrix $A$ is defined to be positive semi-definite, if $x^{\dagger} A x \geq 0$ for $x \in \mathbb{C}^n$.</p>



<p>The positive semi-definite matrix has the following important property:</p>



<p>The eigenvalues of positive semi-definite matrix are non-negative.</p>



<p>Because $x^{\dagger} A x \geq$ for $x \in \mathbb{C}^n$, suppose $x$ is an eigenvector of $A$ and $Ax = \lambda x$ where $x \neq 0$,</p><p>

\[\begin{align}
x^{\dagger} A x &amp;= x^{\dagger} \lambda x \\
&amp;= \lambda x^{\dagger} x \\
&amp;\geq 0 \\
\end{align}\]

</p><p>Because $x^{\dagger} x$ must be real number and $x^{\dagger} x &gt; 0$, we have $\lambda \geq 0$.</p>



<p>This concludes the proof.</p>

<h4 id="covariance-matrix">Covariance Matrix</h4>

<p>The covariance matrix has the following important property:</p>



<p>Covariance matrix is positive semi-definite. This means that the eigenvalues of covariance matrix is non-negative.</p>



<p>The proof of that covariance must be positive semi-definite could be found in my previous post on <a href="https://leimao.github.io/blog/Multivariate-Gaussian-Covariance-Matrix/">Multivariate Gaussian and Covariance Matrix</a>.</p>

<h4 id="singular-values">Singular Values</h4>

<p>The singular values, $\sigma_1$, $\sigma_2$, $\cdots$, $\sigma_r$, of an $m \times n$ matrix $A$ are the square roots, $\sigma_i = \sqrt{\lambda_i}$, of non-negative eigenvalues of the associated Gram matrix $K = A^{\dagger}A$. The corresponding eigenvectors of $K$ are known as singular vectors of $A$.</p>



<p>Note that the associated Gram matrix $K = A^{\dagger}A$ is real and symmetric, so the eigenvalues of $K$ are all real.</p>



<p>$K = A^{\dagger}A$ is also positive semi-definite.</p>



<p>For any vector $x$</p><p>

\[x^{\dagger} (A^{\dagger} A) x = (Ax)^{\dagger} Ax\]

</p><p>Because $Ax$ is also a vector,</p><p>

\[\begin{align}
x^{\dagger} (A^{\dagger} A) x \geq 0
\end{align}\]

</p><p>Therefore, all the eigenvalues of $K = A^{\dagger}A$ are non-negative and they all have a corresponded singular value of $A$.</p>

<h4 id="singular-value-decomposition">Singular Value Decomposition</h4>

<p>In linear algebra, the singular value decomposition (SVD) is a factorization of a real or complex matrix that generalizes the eigendecomposition of a square normal matrix to any $ m\times n$ matrix via an extension of the polar decomposition.</p>



<p>Specifically, the singular value decomposition of an $m \times n$ real or complex matrix $M$ is a factorization of the form $U \Sigma V^{\dagger}$, where $U$ is an $m \times m$ real or complex unitary matrix, $\Sigma$ is a $m \times n$ rectangular diagonal matrix with non-negative real numbers on the diagonal, and $V$ is an $n \times n$ real or complex unitary matrix.</p>



<p>The diagonal entries $\sigma_{i}=\Sigma_{ii}$ of $\Sigma$ are known as the singular values of $M$. The number of non-zero singular values is equal to the rank of $M$.</p>



<p>In particular, for any matrix $A \in \mathbb{C}$,</p><p>

\[A_{m \times n} = U_{m\times m} \Sigma_{m \times n} V_{n \times n}^{\dagger}\]

</p><p>We will skip the proof for why every matrix has SVD and the algorithm for SVD.</p>

<h4 id="singular-value-decomposition-for-norm-matrix">Singular Value Decomposition for Norm Matrix</h4>

<p>For any matrix $A \in \mathbb{C}$, $A^{\dagger} A$ could be expressed as</p><p>

\[\begin{align}
A^{\dagger} A &amp;= (U \Sigma V^{\dagger})^{\dagger} U \Sigma V^{\dagger} \\
&amp;= V \Sigma^{\dagger} U^{\dagger}  U \Sigma V^{\dagger} \\
&amp;= V \Sigma^{\dagger} I \Sigma V^{\dagger} \\
&amp;= V \Sigma^{\dagger} \Sigma V^{\dagger}
\end{align}\]

</p><p>We multiply $V$ at both side of the equation.</p><p>

\[\begin{align}
A^{\dagger} A V &amp;= V \Sigma^{\dagger} \Sigma V^{\dagger} V \\
&amp;=  V \Sigma^{\dagger} \Sigma I \\
&amp;=  V \Sigma^{\dagger} \Sigma \\
&amp;= \Sigma^{\dagger} \Sigma V \\
\end{align}\]

</p><p>Note that $\Sigma^{\dagger} \Sigma$ is a square diagonal matrix. Based on the definition of eigenvalue and eigenvectors, the diagonal values of $\Sigma^{\dagger} \Sigma$, including the zeros, are the eigenvalues of $A^{\dagger} A$. All the columns of $V$ are the corresponding eigenvectors of $A^{\dagger} A$.</p>



<p>Similarly, $A A^{\dagger}$ could be expressed as</p><p>

\[\begin{align}
A A^{\dagger} U &amp;= \Sigma \Sigma^{\dagger} U \\
\end{align}\]

</p><p>Note that $\Sigma \Sigma^{\dagger}$ is a square diagonal matrix. Based on the definition of eigenvalue and eigenvectors, the diagonal values of $\Sigma \Sigma^{\dagger}$, including the zeros, are the eigenvalues of $A A^{\dagger}$. All the columns of $U$ are the corresponding eigenvectors of $A A^{\dagger}$.</p>

<h3 id="mathematics-of-principal-components-analysis">Mathematics of Principal Components Analysis</h3>

<p>We start with $p$-dimensional vectors, and want to summarize them by projecting down into a $q$-dimensional subspace, where $q \leq p$. Our summary will be the projection of the original vectors on to $q$ directions, the principal axes, which span the subspace.</p>

<h4 id="minimizing-projection-residuals">Minimizing Projection Residuals</h4>

<p>Given a dataset $X \in \mathbb{R}^{n \times p}$ whose row is the centered data vectors $x_i \in \mathbb{R}^p$ for $0 \leq i \leq n-1$ ($\sum_{i=0}^{n-1} x_{i} = 0$), if we have a unit vector $w \in \mathbb{R}^p$ ($|w| = 1$) and we project the all the data vectors to this unit vector $w$.</p>



<p>The length of projection for data vector $x_i$ on $w$, by definition, is</p><p>

\[\begin{align}
|x_i| \cos \theta &amp;= \frac{\langle x_i, w \rangle}{|w|} \\
&amp;= \langle x_i, w \rangle \\
\end{align}\]

</p><p>where $\langle x_i, w \rangle$ is the inner product of $x_i$ and $w$.</p>



<p>The projection vector for data vector $x_i$ on $w$ is $\langle x_i, w \rangle w$.</p>



<p>The residual, which is the distance from data vector $x_i$ to $w$, is the length of vector $x_i - \langle x_i, w \rangle w$.</p>



<p>Let’s check what the residual square $| x_i - \langle x_i, w \rangle w | ^2$ is.</p><p>

\[\begin{align}
| x_i - \langle x_i, w \rangle w |^2 &amp;= \langle x_i - \langle x_i, w \rangle w, x_i - \langle x_i, w \rangle w \rangle \\
&amp;= \langle x_i, x_i \rangle - \langle x_i, \langle x_i, w \rangle w \rangle - \langle \langle x_i, w \rangle w, x_i \rangle + \langle \langle x_i, w \rangle w, \langle x_i, w \rangle w \rangle \\
&amp;= \langle x_i, x_i \rangle - \langle x_i, w \rangle \langle x_i, w \rangle - \langle x_i, w \rangle \langle w, x_i \rangle + \langle x_i, w \rangle ^2 \langle w,  w \rangle \\
&amp;= \langle x_i, x_i \rangle - 2 \langle x_i, w \rangle ^2 + \langle x_i, w \rangle ^2 |w| ^2 \\
&amp;= \langle x_i, x_i \rangle - 2 \langle x_i, w \rangle ^2 + \langle x_i, w \rangle ^2 \\
&amp;= \langle x_i, x_i \rangle -  \langle x_i, w \rangle ^2 \\
\end{align}\]

</p><p>The optimization goal of projection is to minimize mean squared error $\text{MSE}(w)$, which is the mean of the residual sum of squares.</p><p>

\[\begin{align}
\text{MSE}(w) &amp;= \frac{1}{n} \sum_{i=0}^{n-1} | x_i - \langle x_i, w \rangle w |^2 \\
&amp;= \frac{1}{n} \sum_{i=0}^{n-1} \big( \langle x_i, x_i \rangle -  \langle x_i, w \rangle ^2 \big)\\
&amp;= \frac{1}{n} \sum_{i=0}^{n-1} \langle x_i, x_i \rangle - \frac{1}{n} \sum_{i=0}^{n-1}  \langle x_i, w \rangle ^2\\
\end{align}\]

</p><p>Remember the relationship between variance and expected value, $\mathbb{V}(X) = \mathbb{E}(X^2) - \mathbb{E}(X)^2$, …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://leimao.github.io/article/Principal-Component-Analysis/">https://leimao.github.io/article/Principal-Component-Analysis/</a></em></p>]]>
            </description>
            <link>https://leimao.github.io/article/Principal-Component-Analysis/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24257468</guid>
            <pubDate>Mon, 24 Aug 2020 04:12:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Writing an SSDP Directory in Elixir]]>
            </title>
            <description>
<![CDATA[
Score 84 | Comments 11 (<a href="https://news.ycombinator.com/item?id=24256984">thread link</a>) | @luu
<br/>
August 23, 2020 | https://quinnwilton.com/blog/writing-an-ssdp-directory-in-elixir | <a href="https://web.archive.org/web/*/https://quinnwilton.com/blog/writing-an-ssdp-directory-in-elixir">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
    <header>
      <a href="https://netscape-browser.en.softonic.com/" target="_blank">
        <img src="https://quinnwilton.com/images/netscape_now.gif">
      </a>
    </header>
<a href="https://quinnwilton.com/blog"><img src="https://quinnwilton.com/images/back.png"></a>

<section>
  
  <h2>2020-02-26</h2>

<p>I used to spend all of my free time programming random toy projects. Over time, likely after spending a few years in industry, I started to spend so much time thinking about how to write maintainable code that I think I started to lose out on what makes programming fun: exploring new ideas and learning how to do things I’ve never done before. I’d like to rediscover that joy, and to do that, I need to stop being so much of a perfectionist.</p>
<p>I think that in an office setting, deadlines force me to move on and call things done, but in my personal life, lack of that kind of pressure means that I can spend literally forever architecting and rearchitecting the same piece of code until it’s perfect (it never is).</p>
<p>To fix this, I’m going to try blogging! If I can make myself excited to share my code with other people, imperfect and unfinished as it is, then maybe I can start to unlearn the paralysis that’s been plaguing me for the past few years.</p>
<p>To start, I just want to walk through a small program I wrote a few months ago. I wanted to learn how <a href="https://en.wikipedia.org/wiki/Simple_Service_Discovery_Protocol">SSDP</a> works, so I implemented an SSDP Directory! For those of you who aren’t aware, SSDP is a fairly simple protocol from the 90s that’s used to facilitate the discovery of network services. Nowadays, it’s also used by everything from smart TVs to Hue lights.</p>
<p>My implementation can be found <a href="https://github.com/QuinnWilton/ssdp_directory">here</a>, and the (very readable!) RFC is <a href="https://tools.ietf.org/html/draft-cai-ssdp-v1-03">here</a>.</p>
<p>If I run the application, it discovers all of the devices on my network:</p>
<pre><code>iex(1)&gt; SSDPDirectory.list_services
%{
  "uuid:b236f169-9c9d-db64-ffff-ffffcff91970::upnp:rootdevice" =&gt; %SSDPDirectory.Service{
    location: "http://192.168.0.150:60000/upnp/dev/b236f169-9c9d-db64-ffff-ffffcff91970/desc",
    type: "upnp:rootdevice",
    usn: "uuid:b236f169-9c9d-db64-ffff-ffffcff91970::upnp:rootdevice"
  },
  ...
}</code></pre>
<p>The key to SSDP is what’s called <a href="https://en.wikipedia.org/wiki/Multicast">multicast addressing</a>. Essentially, services broadcast their presence to a specially designated multicast address, and then anyone else on the network is able to listen for those presence notifications in order to track the appearance and disappearance of new services.</p>
<p>Fortunately, Elixir, my language of choice, makes subscribing to these notifications <a href="https://github.com/QuinnWilton/ssdp_directory/blob/master/lib/ssdp_directory/multicast_channel.ex">easy</a>!</p>
<pre><code>defmodule SSDPDirectory.MulticastChannel do
  use GenServer

  alias __MODULE__

  alias SSDPDirectory.{
    Discovery,
    Presence
  }

  @multicast_group {239, 255, 255, 250}
  @multicast_port 1900

  def start_link(opts \\ []) do
    GenServer.start_link(__MODULE__, :ok, opts)
  end

  @spec broadcast(GenServer.name(), iodata) :: :ok
  def broadcast(channel \\ MulticastChannel, packet) do
    GenServer.cast(channel, {:broadcast, packet})
  end

  @spec init(:ok) :: {:ok, %{socket: port}}
  def init(:ok) do
    udp_options = [
      :binary,
      active: true,
      add_membership: {@multicast_group, {0, 0, 0, 0}},
      multicast_if: {0, 0, 0, 0},
      multicast_loop: false,
      reuseaddr: true
    ]

    {:ok, socket} = :gen_udp.open(@multicast_port, udp_options)

    {:ok, %{socket: socket}}
  end

  def handle_cast({:broadcast, packet}, state) do
    :ok = :gen_udp.send(state.socket, @multicast_group, @multicast_port, packet)

    {:noreply, state}
  end

  def handle_info({:udp, _socket, _ip, _port, data}, state) do
    Task.Supervisor.start_child(SSDPDirectory.DecodingSupervisor, fn -&gt;
      with {:ok, packet, rest} &lt;- :erlang.decode_packet(:http_bin, data, []),
           {:ok, handler} &lt;- packet_handler(packet),
           {:ok, decoded} &lt;- handler.decode(rest) do
        :ok = handler.handle(decoded)
      end
    end)

    {:noreply, state}
  end

  defp packet_handler({:http_request, "NOTIFY", _target, _version}),
    do: {:ok, Presence}

  defp packet_handler({:http_response, _version, 200, "OK"}),
    do: {:ok, Discovery.Response}

  defp packet_handler(_packet), do: :error
end</code></pre>
<p>Most of the magic happens in the <code>init/1</code> function. By opening a UDP socket and joining it to the protocol’s multicast group, our process is now able to receive packets that are broadcast to that group. That receiving logic is located in the <code>handle_info/2</code> function within the same file.</p>
<p>When receiving a packet, we spawn another process that is responsible for handling that packet. This process runs under a <code>Task.Supervisor</code> in order to isolate crashes of that process from the <code>MulticastChannel</code>. Also interesting, is that we’re able to decode the incoming packets using <a href="http://erlang.org/doc/man/erlang.html#decode_packet-3">:erlang.decode_packet/3</a>. This is a builtin function that allows us to decode a variety of packet formats, piece-by-piece. In this case, we’re using it to parse the packet as an HTTP packet. This is the same way that Elixir’s <a href="https://github.com/elixir-mint/mint/blob/master/lib/mint/http1/response.ex#L7">Mint</a> decodes HTTP responses too!</p>
<p>Based on the type of packet decoded, <code>packet_handler/1</code> then delegates the handling of that packet to another module. Either we’ve received an HTTP NOTIFY request, and we’re dealing with a <a href="https://github.com/QuinnWilton/ssdp_directory/blob/master/lib/ssdp_directory/presence.ex">presence notification</a>, or we’ve received a <a href="https://github.com/QuinnWilton/ssdp_directory/blob/master/lib/ssdp_directory/discovery/response.ex">response to a discovery request</a>.</p>
<p>Let’s take a look at the presence case. In case you’re curious, here’s an example presence notification:</p>
<pre><code>NOTIFY * HTTP/1.1
Host: 239.255.255.250:reservedSSDPport
NT: blenderassociation:blender
NTS: ssdp:alive
USN: someunique:idscheme3
AL: &lt;blender:ixl&gt;&lt;http://foo/bar&gt;
Cache-Control: max-age = 7393</code></pre>
<p>And here’s where we handle it:</p>
<pre><code>defmodule SSDPDirectory.Presence do
  require Logger

  alias __MODULE__
  alias SSDPDirectory.HTTP

  @type command :: Presence.Alive.t() | Presence.ByeBye.t()

  @spec decode(binary) ::
          :error
          | {:ok, command}
  def decode(data) do
    case HTTP.decode_headers(data, []) do
      {:ok, headers, _rest} -&gt;
        process_headers(headers)

      :error -&gt;
        _ = Logger.debug(fn -&gt; "Failed to decode NOTIFY request: " &lt;&gt; inspect(data) end)

        :error
    end
  end

  @spec handle(command) :: :ok
  def handle(%Presence.Alive{} = command) do
    Presence.Alive.handle(command)
  end

  def handle(%Presence.ByeBye{} = command) do
    Presence.ByeBye.handle(command)
  end

  defp process_headers(headers) do
    do_process_headers(headers, %{})
  end

  defp do_process_headers([], args) do
    case args do
      %{command: "ssdp:alive", usn: usn, type: type}
      when not is_nil(usn) and not is_nil(type) -&gt;
        {:ok,
         %Presence.Alive{
           usn: usn,
           type: type,
           location: Map.get(args, :location)
         }}

      %{command: "ssdp:byebye", usn: usn, type: type}
      when not is_nil(usn) and not is_nil(type) -&gt;
        {:ok,
         %Presence.ByeBye{
           usn: usn,
           type: type
         }}

      _ -&gt;
        :error
    end
  end

  defp do_process_headers([{"nts", command} | rest], args) do
    args = Map.put(args, :command, command)

    do_process_headers(rest, args)
  end

  defp do_process_headers([{"nt", type} | rest], args) do
    args = Map.put(args, :type, type)

    do_process_headers(rest, args)
  end

  defp do_process_headers([{"usn", usn} | rest], args) do
    args = Map.put(args, :usn, usn)

    do_process_headers(rest, args)
  end

  defp do_process_headers([{"al", location} | rest], args) do
    args = Map.put(args, :location, location)

    do_process_headers(rest, args)
  end

  defp do_process_headers([{"location", location} | rest], args) do
    args = Map.put(args, :location, location)

    do_process_headers(rest, args)
  end

  defp do_process_headers([_ | rest], args) do
    do_process_headers(rest, args)
  end
end</code></pre>
<p>It looks like there’s a lot going on here, but it’s actually pretty simple. Starting in <code>decode/1</code>, we continue decoding the packet from <code>MulticastChannel</code>. This time it’s the headers we’re interested in, so we decode those, and then process them in order to determine what kind of command we’re dealing with.</p>
<p>The processing step simply involves recursing over the list of headers, and accumulating the relevant ones in a map . Once we’ve done that, we just construct the corresponding command!</p>
<p>Lastly, the command handler delegates to a third module based on the type of command being processed. For example, in the case of an <a href="https://github.com/QuinnWilton/ssdp_directory/blob/master/lib/ssdp_directory/presence/alive.ex">ssdp:alive</a> command:</p>
<pre><code>defmodule SSDPDirectory.Presence.Alive do
  require Logger

  alias __MODULE__

  alias SSDPDirectory.{
    Cache,
    Service
  }

  @enforce_keys [:usn, :type]
  defstruct [:location] ++ @enforce_keys

  @type t :: %Alive{}

  @spec handle(Alive.t()) :: :ok
  def handle(%Alive{} = command) do
    _ = Logger.debug(fn -&gt; "Handling ssdp:alive request: " &lt;&gt; inspect(command) end)

    service = %Service{
      usn: command.usn,
      type: command.type,
      location: command.location
    }

    :ok = Cache.insert(service)
  end
end</code></pre>
<p>Here we just construct a service using the parameters in the command, and then store it in our <a href="https://github.com/QuinnWilton/ssdp_directory/blob/master/lib/ssdp_directory/cache.ex">cache</a>:</p>
<pre><code>defmodule SSDPDirectory.Cache do
  use GenServer

  require Logger

  alias __MODULE__
  alias SSDPDirectory.Service

  def start_link(opts \\ []) do
    GenServer.start_link(Cache, :ok, opts)
  end

  def contents(cache \\ Cache) do
    :ets.tab2list(cache)
    |&gt; Enum.into(%{})
  end

  def insert(cache \\ Cache, %Service{} = service) do
    GenServer.call(cache, {:insert, service})
  end

  def delete(cache \\ Cache, %Service{} = service) do
    GenServer.call(cache, {:delete, service})
  end

  def flush(cache \\ Cache) do
    GenServer.call(cache, :flush)
  end

  def init(:ok) do
    table = :ets.new(Cache, [:named_table, read_concurrency: true])

    {:ok, %{table: table}}
  end

  def handle_call({:insert, %Service{usn: usn} = service}, _from, data) when not is_nil(usn) do
    :ets.insert(data.table, {usn, service})

    _ = Logger.debug(fn -&gt; "Cached service: " &lt;&gt; inspect(usn) end)

    {:reply, :ok, data}
  end

  def handle_call({:delete, %Service{usn: usn}}, _from, data) when not is_nil(usn) do
    :ets.delete(data.table, usn)

    _ = Logger.debug(fn -&gt; "Evicted service: " &lt;&gt; inspect(usn) end)

    {:reply, :ok, data}
  end

  def handle_call(:flush, _from, data) do
    :ets.delete_all_objects(data.table)

    _ = Logger.debug(fn -&gt; …</code></pre></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://quinnwilton.com/blog/writing-an-ssdp-directory-in-elixir">https://quinnwilton.com/blog/writing-an-ssdp-directory-in-elixir</a></em></p>]]>
            </description>
            <link>https://quinnwilton.com/blog/writing-an-ssdp-directory-in-elixir</link>
            <guid isPermaLink="false">hacker-news-small-sites-24256984</guid>
            <pubDate>Mon, 24 Aug 2020 02:09:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Clean Start for the Web]]>
            </title>
            <description>
<![CDATA[
Score 111 | Comments 86 (<a href="https://news.ycombinator.com/item?id=24255541">thread link</a>) | @tannhaeuser
<br/>
August 23, 2020 | https://macwright.com/2020/08/22/clean-starts-for-the-web.html | <a href="https://web.archive.org/web/*/https://macwright.com/2020/08/22/clean-starts-for-the-web.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>The web is in need of some reinvention right now.</p><p>The web’s evolution over the last decade has mirrored the American economy. All of the essential indicators are going “up and to the right,” a steady stream of fundamental advances reassure use that there “is progress,” but the actual experience and effects for individuals stagnates or regresses.</p><p>The crisis affects platforms, creators, and consumers alike.</p><p><em>I’m going to try and dissect and diagnose this situation, a bit. You can skip forward if you just want to read my casual, unprofessional pitch for a reboot of the web. The idea is that we could choose a new lightweight markdown format to replace HTML &amp; CSS, split the web into documents and applications, and find performance, accessibility, and fun again.</em></p><details><summary>This post uses the pedantic definition of "the web"</summary>I've discussed attempts to reinvent the "Internet" a few times. Things like dat, IPFS, and arweave are all projects to reinvent an Internet, or a transport and data-sharing layer. The web is what lies on top of that, the HTML, CSS, URLs, JavaScript, browsing experience.</details><h3 id="the-platform-collapse">The platform collapse</h3><p>The platform side is what changed last week, when <a href="https://arstechnica.com/information-technology/2020/08/firefox-maker-mozilla-lays-off-250-workers-says-covid-19-lowered-revenue/">Mozilla laid off 250 employees</a> and indicated that it would affect Firefox development. Firefox wasn’t the #2 browser - that’s Safari, mainly because of the captive audience of iPhone and iPad users. But it was the most popular browser that people <em>chose</em> to use.</p><p><img alt="Chart of browser market share, with Chrome becoming the monopoly" src="https://macwright.com/images/2020-08-22-clean-starts-for-the-web-chart-of-browser-market-share-with-chrome-becoming-the-monopoly.png"></p><p><em>Chart from <a href="https://gs.statcounter.com/browser-market-share#monthly-200901-202007">statcounter</a></em></p><p>The real winner is not just Chrome, but Chrome’s engine. One codebase, <a href="https://en.wikipedia.org/wiki/KHTML">KHTML</a>, split into <a href="https://en.wikipedia.org/wiki/WebKit">WebKit</a> (Safari), and <a href="https://en.wikipedia.org/wiki/Blink_(browser_engine)">Blink</a> (Chrome, Microsoft Edge, Opera, etc.)</p><p>This a textbook monoculture. In one sense, it’s a victory for collaboration because nobody’s ‘wasting time’ on competing implementations and web developers can expect the same features and bugs across different browsers. But in a deeper way, it threatens one of the basic principles of how the web has evolved.</p><h3 id="specs--implementations">Specs &amp; implementations</h3><p><picture><source srcset="https://macwright.com/images/2020-08-22-clean-starts-for-the-web-decline.webp" type="image/webp"><img alt="Decline" src="https://macwright.com/images/2020-08-22-clean-starts-for-the-web-decline.jpg"></picture></p><p>The web has evolved through a combination of <em>specifications</em> and <em>implementations</em>. Organizations like the <a href="https://whatwg.org/">WHATWG</a>, <a href="https://www.w3.org/">W3C</a>, and <a href="https://www.ietf.org/">IETF</a> have been collaboration spaces for independent developers, corporations, and academics to discuss potential new features of the web. Then, browsers would test those ideas out in a variety of implementations.</p><p>This was an interesting structural piece: it reassured us all that it was <em>possible</em> to follow along, and that a multi-participant web was one of our goals. It was frustrating to pull up <a href="https://caniuse.com/">caniuse</a> and see blank spots, but the idea was that different browsers may take the lead in some areas, but everyone catches up eventually. Chrome was not always the first to jump on features, or the first to optimize.</p><p>It’s slower to collaborate than to work alone, but it was beneficial in some ways that we’ve lost now. Chrome has been moving extremely fast, adding new specifications and ideas at a startling rate, and it’s becoming one of the hardest pieces of software to replicate.</p><p>Mike Healy I think <a href="https://twitter.com/mike_hasarms/status/1296575224599556097">said it best</a>:</p><blockquote><p>Do you think the web has almost ‘priced itself out of the market’ in terms of complexity if only 1-2 organisations are capable of building rendering engines for it?</p></blockquote><p>Not only is it nearly impossible to build a new browser from scratch, once you have one the ongoing cost of keeping up with standards requires a full team of experts. Read Drew DeVault’s <a href="https://drewdevault.com/2020/08/13/Web-browsers-need-to-stop.html">Web browsers need to stop</a> for that point, and keep reading all of Drew’s stuff.</p><details><summary>What about Flow?</summary>Yep, there’s a <a href="https://www.ekioh.com/flow-browser/">browser called Flow</a>, which may exist and may support a full range of web standards. If it does exist, I’ll be very excited about it, but it has been teased for almost a year now without any concrete evidence, so it could equally be vaporware.</details><h3 id="the-problem-for-creators">The problem for creators</h3><p>The web has gotten much harder to develop for.</p><p>The web has had about 25 years to grow, few opportunities to shrink, and is now surrounded by an extremely short-sighted culture that is an outgrowth of economic and career short-termism. There are lots of <a href="https://frankchimero.com/blog/2018/everything-easy/">ways to do anything</a>, and some of the most popular ways of building applications on the web are - in my opinion - <a href="https://macwright.com/2020/05/10/spa-fatigue.html">usually ghoulish overkill</a>.</p><p>The best way for folks to enter <em>web development</em> in 2020 is to choose a niche, like <a href="https://vuejs.org/">Vue.js</a> or <a href="https://reactjs.org/">React</a>, and hope that there’s a CSS and accessibility expert on their team.</p><p>For folks who just want to create a web page, who don’t want to enter an industry, there’s a baffling array of techniques, but all the simplest, probably-best ones are stigmatized. It’s easier to stumble into building your resume in React with GraphQL than it is to type some HTML in Notepad.</p><h3 id="the-problem-for-consumers">The problem for consumers</h3><p>We hope that all this innovation is <em>for the user</em>, but often it isn’t. Modern websites seem to be as large, slow, and buggy as they’ve ever been. Our computers are <a href="https://macwright.com/2019/11/15/something-is-wrong-with-computers.html">barely getting faster</a> and our internet connection speeds are stagnating (don’t even <em>try</em> to mention 5G). Webpage <a href="https://www.pingdom.com/blog/webpages-are-getting-larger-every-year-and-heres-why-it-matters/">size growth</a> is outpacing it all.</p><p>The end result is that I no longer expect pages to be fast, even with <a href="https://github.com/gorhill/uBlock">uBlock</a> installed in Firefox and a good local <a href="https://sonic.net/">fiber internet provider</a>.</p><p>I don’t want to lay all of the blame at <em>those web developers</em>, though. Here’s a story from an old job that I find kind of funny. We were collecting some data from user interactions to answer simple questions like “do people click to upload or do they drag &amp; drop?” So we enabled <a href="https://segment.com/">Segment</a>, a tool that lets you add data-collection pipelines by including a single script. The problem, though, is that Segment offered a big page of on/off switches with hundreds of data providers &amp; ad-tech companies on it. And, sure, enough, some folks closer to the business side started <em>clicking all those buttons</em>.</p><p>See, the problem with ads and data tracking is that <em>you can</em>, and who is going to say no? (In that instance, I said no, and added a <a href="https://developer.mozilla.org/en-US/docs/Web/HTTP/CSP">CSP</a> that would block new advertiser access at the page level.)</p><h2 id="recreating-simplicity">Recreating simplicity</h2><blockquote><p>You cannot get a simple system by adding simplicity to a complex system. - <a href="http://erlang.org/pipermail/erlang-questions/2012-March/065087.html">Richard O’Keefe</a></p></blockquote><p>Where do we go from here? Some of the smartest folks out there have been <a href="https://twitter.com/_developit/status/1296628134406692865">advocating for a major version revision</a> of the web.</p><p><em>I am in no way qualified to speculate on a whole new web from scratch, but the <a href="https://www.nytimes.com/2020/08/21/us/california-wildfires.html">air quality</a> is scary so I’m skipping my run and it’s Saturday morning so here we are.</em></p><p>How do we make the web fun, participatory, and good?</p><p>My first thought is that there are two webs:</p><h3 id="the-document-web">The document web</h3><p><picture><source srcset="https://macwright.com/images/2020-08-22-clean-starts-for-the-web-illustration-of-web-pages.webp" type="image/webp"><img alt="Illustration of web pages" src="https://macwright.com/images/2020-08-22-clean-starts-for-the-web-illustration-of-web-pages.jpg"></picture></p><p>There is the “document web”, like blogs, news, Wikipedia, Twitter, Facebook. This is basically the original vision of the web, as far as I can understand it (I was 2). Basically CSS, which we now think of as a way for designers to add brand identity and tweak pixel-perfect details, was instead mostly a way of making plain documents readable and letting the <em>readers</em> of those documents customize how they looked. This attribute actually <a href="https://twitter.com/autiomaa/status/1296755641164468224">survived for a while in Chrome, in the form of user stylesheets</a>, and <a href="https://davidwalsh.name/firefox-user-stylesheet">still works in Firefox</a>. Though it’s going to be a rough ride in the current web which has basically thrown away <a href="https://en.wikipedia.org/wiki/Semantic_HTML">semantic HTML</a> as an idea.</p><h3 id="the-application-web">The “application” web</h3><p><picture><source srcset="https://macwright.com/images/2020-08-22-clean-starts-for-the-web-illustration-of-machines.webp" type="image/webp"><img alt="Illustration of machines" src="https://macwright.com/images/2020-08-22-clean-starts-for-the-web-illustration-of-machines.jpg"></picture></p><p>Then there’s the “application web”. This started as <em>server</em> applications, built with things like <a href="https://www.djangoproject.com/">Django</a> and <a href="https://rubyonrails.org/">Ruby on Rails</a> and before them a variety of technologies that will live forever in corporations, like <a href="https://en.wikipedia.org/wiki/Jakarta_Servlet">Java Servlets</a>.</p><p><a href="https://backbonejs.org/">Backbone.js</a> demonstrated that a lot of these applications could be moved into the browser, and then <a href="https://reactjs.org/">React</a> and its many SPA-style competitors established a new order for the web – highly-interactive, quite complex, client-side applications.</p><h3 id="the-war-between-the-parts-of-the-web">The war between the parts of the web</h3><p>I posit that this dual-nature is part of what gives the web its magic. But it’s also a destructive force.</p><p>The magic is that a simple blog can be creative expression, can be beautifully interactive. This one isn’t, but I’m just saying - <a href="https://www.typewolf.com/site-of-the-day">it’s possible</a>.</p><p>The problem is that the “document web” is often plagued by application characteristics - it’s the JavaScript and animations and complexity that makes your average newspaper website an unmitigated disaster. Where document websites adopt application patterns they often accidentally sacrifice <a href="https://www.a11yproject.com/">accessibility</a>, performance, and <a href="https://en.wikipedia.org/wiki/Web_scraping">machine readability</a>.</p><p>And the “application web” is plagued by the document characteristics - interactive applications are going to great lengths to avoid most of the essential characteristics of HTML &amp; CSS and just use them as raw materials - avoiding writing any HTML directly at all, avoiding <a href="https://mxstbr.com/thoughts/css-in-js">writing any CSS directly at all</a>, avoiding <a href="https://www.react-spring.io/">default animation features</a>, replacing <a href="https://reactrouter.com/">page-based navigation with something that looks like it but works completely differently</a>. The application web uses <a href="https://reactjs.org/docs/introducing-jsx.html">JSX</a>, not HTML, and would like that in the browser itself, or <a href="https://svelte.dev/">Svelte</a>, instead of JavaScript, and would like that too.</p><p>When I read blog posts from ‘traditional web developers’ who are mad that HTML &amp; CSS aren’t enough anymore and that everything is complicated –&nbsp;I think this is largely that the application stack for building websites has replaced the document stack in a lot of places. Where we would use Jekyll or server-side rendering, we now use React or Vue.js. There are advantages to that, but for a lot of minimally-interactive websites, it’s throwing away decades worth of knowledge in exchange for certain performance perks that might not even matter.</p><p>The appeal of social networks is partly because they let us create <em>documents</em> without thinking about web technology, and they provide guarantees around performance, accessibility, and polish that otherwise would take up our time. You don’t have to think about whether your last Facebook post will load quickly on your friend’s phone or whether your Instagram post will be correctly cropped and resized in the timeline - those things are taken care of.</p><p>To some extent, this doesn’t <em>need</em> to be something that only social networks provide, though: standards like <a href="https://en.wikipedia.org/wiki/RSS">RSS</a> and services like <a href="https://www.instapaper.com/">Instapaper</a> show that pleasing formatting and distribution can be done at the <em>platform level</em> and be provided on top of existing vanilla websites.</p><details><summary>These are not absolutes.</summary>Yeah, I can hear it now: but these categories are not …</details></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://macwright.com/2020/08/22/clean-starts-for-the-web.html">https://macwright.com/2020/08/22/clean-starts-for-the-web.html</a></em></p>]]>
            </description>
            <link>https://macwright.com/2020/08/22/clean-starts-for-the-web.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24255541</guid>
            <pubDate>Sun, 23 Aug 2020 21:47:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Loot boxes in online games and their effect on consumers [pdf]]]>
            </title>
            <description>
<![CDATA[
Score 33 | Comments 9 (<a href="https://news.ycombinator.com/item?id=24254712">thread link</a>) | @infodocket
<br/>
August 23, 2020 | https://www.europarl.europa.eu/RegData/etudes/ATAG/2020/652732/IPOL_ATA(2020)652732_EN.pdf | <a href="https://web.archive.org/web/*/https://www.europarl.europa.eu/RegData/etudes/ATAG/2020/652732/IPOL_ATA(2020)652732_EN.pdf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.europarl.europa.eu/RegData/etudes/ATAG/2020/652732/IPOL_ATA(2020)652732_EN.pdf</link>
            <guid isPermaLink="false">hacker-news-small-sites-24254712</guid>
            <pubDate>Sun, 23 Aug 2020 19:47:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Bare Metal Rust Generics]]>
            </title>
            <description>
<![CDATA[
Score 200 | Comments 48 (<a href="https://news.ycombinator.com/item?id=24254048">thread link</a>) | @cube00
<br/>
August 23, 2020 | https://www.ecorax.net/as-above-so-below-1/ | <a href="https://web.archive.org/web/*/https://www.ecorax.net/as-above-so-below-1/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <p>I've had the pleasure to work with very experienced firmware developers; the
kind of people who know the size of their <a href="https://en.wikipedia.org/wiki/Red_zone_(computing)">red
zones</a> and routinely
transform coffee into linker scripts and pointer dereferences. In other words,
the <a href="http://www.catb.org/%7Eesr/jargon/html/story-of-mel.html">Mels</a> and <a href="https://www.usenix.org/system/files/1311_05-08_mickens.pdf">Zeus
Hammers</a> of the
world.</p>
<p>When it comes to the tools of our trade, many of them are curious and
experimental. Some of them—very much myself included—explore far enough to leave
pragmatism behind and veer into idealism, stubbornly forcing beautiful round
pegs into industrial square holes. Hey, maybe they're square for a reason, but
it doesn't hurt to try.</p>
<p>The majority of them aren't like that. Your average battle-tested firmware
developer has accrued a healthy distrust of the abstract, probably born of
watching shiny platonic constructs crash and burn with painfully <em>real</em> and
<em>concrete</em> error traces. It is sobering, having to chase a hardfault on a tiny
MCU across enough vtables and templated code to make Herb Sutter puke angle
brackets. No wonder modern approaches are met with some resistance unless the
LOADs and the STOREs are in clear view.</p>
<p>I felt this way too when someone suggested to me, back in 2014, that an
up-and-coming language called <a href="https://www.rust-lang.org/">Rust</a> showed promise
in the embedded field. <em>Surely not</em>, I thought, <em>too high level.</em> Even though I
had been playing with it already, my profoundly ingrained bit-twiddling
instincts told me not to trust a language that supported functional programming,
or one that dared to have an <em>opinion</em> on how I managed my memory. Bah! That's
how you get philosophers to run out of forks, and your forks to turn into
SIGSEGVs.</p>
<p>I was wrong.</p>
<p>Through the past five years of experimentation, I've gone from intrigued, to
optimistic, to <em>convinced</em> that Rust is an ideal language to build industrial
grade, bulletproof bare metal software. Beyond that, I've come to realize that
even the highest level constructs that the base language offers are applicable
to firmware development, very much unlike other languages that span a wide range
of paradigms (I'm looking at you, C++). There are a few reasons I felt this way:</p>
<ul>
<li>Rust's safety guarantees and general strictness bring the debug time down
significantly, so there's less need to spend time developing mental maps of
how high level constructs correspond to hardware primitives.</li>
<li>The type system is <em>great</em> at enforcing local reasoning and preventing leaky
abstractions. Building decoupled systems with no runtime cost is easy.</li>
<li>The compiler error messages are worthy of an AI assistant with <em>concerning</em>
mind-reading abilities.</li>
</ul>
<p>Lately, I've had the chance to work on a Rust
<a href="https://www.st.com/en/microcontrollers-microprocessors/stm32f412.html">STM32F412</a>
project in a professional setting, with one of the goals being to foster a Rust
knowledge pool at my company. The project, <code>Loadstone</code>, is a 32kb secure
bootloader targeting bare metal devices for the medical industry.</p>
<p>While it would've been easier—and much less of a headache to my colleagues—to
stick to a subset of Rust more familiar to C developers, with your <code>for</code>s, your
<code>*mut u8</code>s and your <code>unsafe</code>s, I instead decided not to pull any punches and
make liberal use of generics, iterator adapters, typestate programming and other
stuff that would've made 2010's cuervo cry blood and hug the closest copy of
Kernighan and Ritchie.</p>
<p>The pressures of a real collaborative project have taught me a lot, and many
assumptions have been refined thanks to the criticism of several skilled
outsiders who, as outsiders often do, had a privileged view on things I took for
granted.</p>
<p>A topic that came up frequently in code review is
<a href="https://thume.ca/2019/07/14/a-tour-of-metaprogramming-models-for-generics/">generics</a>.
Perhaps still recovering from a SFINAE nightmare, some colleagues were
unsure about the use of generics to group behaviour that we'd normally write
separate implementations for. The concerns tended to fall in one of three
categories:</p>
<ul>
<li>Runtime performance.</li>
<li>Binary size bloat.</li>
<li>Habitability and readability.</li>
</ul>
<p>The first is easy to dispel, as it often comes from unfamiliarity with static
dispatch. No vtables or heap allocations in anything we're doing, promise! The
second concern is valid but I've found it to be negligible in practice; I have
plans for another blog post giving some concrete benchmarks.</p>
<p>The last concern is the most subjective and thus the hardest to argue, so I
decided to focus on it in this blog series. I'll go over the design process of
two similar flash memory drivers, and hopefully show how generic programming can
make the job easier and the result more habitable, even in the barren, heapless,
rugged world of bare metal firmware.</p>
<blockquote>
<p>Compile times are another common—and very valid—argument against liberal use
of generics. However, it is not a big problem for low footprint embedded
projects like this one.</p>
</blockquote>

<p><a href="https://en.wikipedia.org/wiki/Flash_memory">Flash memory</a> is electronic
non-volatile storage. It's ubiquitous in consumer electronics; any time you
switch a small device off and it <em>remembers something</em>—whether it's settings,
songs, documents, even its own program—chances are you have flash memory to
thank. We'll be looking at two different <em>NOR</em> flash chips, since the first demo
port of <code>Loadstone</code> requires us to operate both:</p>
<ul>
<li>The embedded
<a href="https://www.st.com/en/microcontrollers-microprocessors/stm32f412.html">STM32F412</a>
1MB MCU flash.</li>
<li>The external 128MB <a href="https://www.micron.com/-/media/client/global/documents/products/data-sheet/nor-flash/serial-nor/n25q/n25q_128mb_1_8v_65nm.pdf">Micron
N25Q128</a>
flash chip present in the <a href="https://www.st.com/en/evaluation-tools/32f412gdiscovery.html">STM32F412ZGT6 Discovery
Kit</a></li>
</ul>
<p>You probably knew what flash memory is used for already, but what non-firmware
developers may not know is that flash memory is <em>quirky</em>. You cannot simply
write a byte to a NOR flash address, sir, that would be rude. While a blob of
flash memory will happily turn a <code>1</code> into a <code>0</code>, the opposite operation will
fail silently.</p>
<p>You can think of every <code>1</code> bit (NOR flash's <em>erased</em> state) as a lit candle you
can blow out. However, in this metaphor you don't get a lighter
to light them back up; you get a flamethrower. Without getting into the hardware
principles involved, the design of NOR flash memory requires that you erase
(i.e. set to <code>1</code>) memory <em>in bulk</em>, in chunks often orders of magnitude bigger
than the minimum addressable memory. On most chips you even have a three way
mismatch: your read, write and erase sizes aren't equal. Ugh.</p>
<p>As you can imagine, this makes writing flash drivers a bit of a pain,
particularly because even the smallest write operations turn into <em>read/write
cycles</em>. Writing a single byte requires reading the minimum erasable block
surrounding the targeted address (which may itself require multiple reads),
potentially erasing the entire block, then writing back the original data merged
with the desired byte.</p>
<p>As you can also imagine, nobody but the person writing this driver <em>wants to
care about this</em>. Even in the minimalistic world of bare metal software,
productive collaboration depends on developers filing away these sharp edges,
presenting interfaces that uniformize or hide any aspects of hardware irrelevant
to the bigger design. As such, a first stab at a flash memory interface should
simply offer a way to read and write ranges of memory.</p>
<p>Let's look at some code:</p>
<pre><code><span>pub trait </span><span>ReadWrite {
   </span><span>type </span><span>Error;
   </span><span>type </span><span>Address;
   </span><span>fn </span><span>read</span><span>(</span><span>&amp;</span><span>mut </span><span>self</span><span>, </span><span>address</span><span>: </span><span>Self::</span><span>Address, </span><span>bytes</span><span>: </span><span>&amp;</span><span>mut</span><span> [</span><span>u8</span><span>]) -&gt; </span><span>Result</span><span>&lt;(), </span><span>Self::</span><span>Error&gt;;
   </span><span>fn </span><span>write</span><span>(</span><span>&amp;</span><span>mut </span><span>self</span><span>, </span><span>address</span><span>: </span><span>Self::</span><span>Address, </span><span>bytes</span><span>: </span><span>&amp;</span><span>[</span><span>u8</span><span>]) -&gt; </span><span>Result</span><span>&lt;(), </span><span>Self::</span><span>Error&gt;;
   </span><span>fn </span><span>range</span><span>(</span><span>&amp;</span><span>self</span><span>) -&gt; (</span><span>Self::</span><span>Address, </span><span>Self::</span><span>Address);
   </span><span>fn </span><span>erase</span><span>(</span><span>&amp;</span><span>mut </span><span>self</span><span>) -&gt; </span><span>Result</span><span>&lt;(), </span><span>Self::</span><span>Error&gt;;
}
</span></code></pre>
<p>The above is what I converged on as a generic interface to a flash
driver. If you're unfamiliar with Rust generics, the above isn't a type, or a
parent class to inherit from. It's more like a Haskell typeclass; a set of
requirements for a concrete type to implement, described in this case in the
form of associated types (<code>Error</code> and <code>Address</code>) and method signatures (<code>read</code>,
<code>write</code>, <code>range</code> and <code>erase</code>).</p>
<p>Even at this early step, some tradeoffs have to be made. The keen,
hardfault-traumatized reader will notice that this interface doesn't lend itself
well to timing sensitive problems. All methods are blocking, and abstracting the
read/write cycle away will naturally lead to non-deterministic write times; a
write may take very little if it only requires toggling bits off, or it might
take very long if it straddles two big sectors requiring erase operations. The
<code>bytes</code> output parameter in <code>read</code> might also strike you as not too rusty, where
returning a <code>Vec&lt;u8&gt;</code> is often idiomatic. Unfortunately we have no heap to work
with, so if you want to take your bytes home you'll have to bring your own bag.</p>
<p>Indeed, it's hard to write the universal interface. This one made sense for the
problems we're solving, but make sure to keep in mind the requirements of your
project!</p>
<h3 id="why-not-simply-write-a-concrete-type">Why not simply write a concrete type?<a href="#why-not-simply-write-a-concrete-type" aria-label="Anchor link for: why-not-simply-write-a-concrete-type">🔗</a></h3>
<p>Ah, the word "simply" is tricky. Datasheet in hand, it may have been easier to
write. It might even save us a few bytes down the line. But altogether I think
the benefits of starting here are well worth the drawbacks:</p>
<ul>
<li>Makes it easy to write test doubles and leverage static dispatch for unit
testing. This kind of approach is what I miss the most when writing C, where
I'm forced to resort to link time substitution or to do things with the
preprocessor too vile to even mention here.</li>
<li>Decouples your design from the get go and makes collaboration easy. Another
developer can immediately start working against this interface, and it's
abstract enough to give you confidence it won't need to be changed as more
knowledge of the hardware emerges.</li>
<li>Going abstract first forces you to think long and hard about what behaviour is
common to each implementation and what behaviour isn't, which helps to <a href="https://en.wikipedia.org/wiki/Don%27t_repeat_yourself">not
repeat yourself</a>.</li>
</ul>
<p>But the biggest reason, and one where C++ and Rust diverge, is the fact that
<em>you can reason about this interface locally</em>. This stems from a non-obvious
difference between the C++ template system and Rust traits. Where C++ templates
type check at the point of instantiation, Rust traits type check at the point of
definition.</p>
<p>What does this mean? It means that the inscrutable, seven-feet-deep-in-a-library
C++ template errors are impossible in Rust, because the compiler doesn't need to
go beyond the interface to prove it is used correctly.</p>
<p>A similar interface using C++ …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.ecorax.net/as-above-so-below-1/">https://www.ecorax.net/as-above-so-below-1/</a></em></p>]]>
            </description>
            <link>https://www.ecorax.net/as-above-so-below-1/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24254048</guid>
            <pubDate>Sun, 23 Aug 2020 18:26:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Finding vulnerable Twitter accounts with expired domains]]>
            </title>
            <description>
<![CDATA[
Score 189 | Comments 121 (<a href="https://news.ycombinator.com/item?id=24252524">thread link</a>) | @zainamro
<br/>
August 23, 2020 | https://zainamro.com/hacks/finding-vulnerable-twitter-accounts | <a href="https://web.archive.org/web/*/https://zainamro.com/hacks/finding-vulnerable-twitter-accounts">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
    <p><a href="https://zainamro.com/hacks">← hacks</a></p>
    <h3>Finding vulnerable Twitter accounts with expired domains</h3>
    <p>August 23, 2020</p>
    <p>Recently, I discovered a simple yet suprisingly effective attack vector against Twitter accounts (and which likely applies to other platforms as well). This attack vector makes it easy to find and hack vulnerable accounts with login emails that are using expired domains. If a user creates a Twitter account with an email on their own domain, then forgets to renew their domain at some point, that account can be hijacked by registering the domain, forwarding all emails to your email, then submitting a password reset on that account. By itself, this is hardly an attack vector since finding such vulnerable accounts is the more important part, and we already know that owning someone's email is essentially a "game over" situation. This attack becomes more dangerous when you can combine it with an efficient method to find these vulnerable accounts quickly and at scale. As it turns out, this is trivial on Twitter for several reasons attributable to their platform design.</p>
    <p>If you're familiar with Twitter, you know that users are given the option to add a public website url. With a simple script and proxy, an attacker can quickly iterate over millions of accounts and check if the domain in that url is not registered; this usually indicates some likelihood that the Twitter account was created with an email address on a now-expired domain. To verify this, they can submit a password reset which will show them a censored version of the account email address for confirmation; however, even though it's censored, it still provides enough information to check if the email domain matches the expired domain listed on their account profile. If it does, the attacker now knows this is an account that can be hacked. Once this entire process is automated, it makes finding these accounts very easy. This method of account hijacking is very likely being used right now by malicious hackers, and I believe it accounts for a large portion of stolen accounts/handles on the platform.</p>
    <img src="https://zainamro.com/assets/img/twitter-emails.png">
    <p>This attack can potentially be executed on other platforms besides Twitter, assuming one can find a similar discovery method. In Twitter's case, they could make it harder to discover these accounts by not showing any email confirmation upon requesting a password reset. This would make the process more costly for attackers who would no longer be able to verify whether an account can be hacked prior to registering the domain. Or perhaps, Twitter should monitor and unlist domains that are no longer registered and notify users when this happens so that they're aware. As for most users, in addition to turning on 2FA, it's important to be very cautious when using an email on your own domain to create accounts; it makes it much easier to lose access if you forget to renew or can't under certain extreme circumstances like incarceration or death.</p>
    <p><a href="https://news.ycombinator.com/item?id=24252524">Comments</a></p>
    <!-- Global site tag (gtag.js) - Google Analytics -->
    
    
  

</div>]]>
            </description>
            <link>https://zainamro.com/hacks/finding-vulnerable-twitter-accounts</link>
            <guid isPermaLink="false">hacker-news-small-sites-24252524</guid>
            <pubDate>Sun, 23 Aug 2020 15:25:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Writing a simple Python to C compiler: hello, fibonacci]]>
            </title>
            <description>
<![CDATA[
Score 41 | Comments 4 (<a href="https://news.ycombinator.com/item?id=24252233">thread link</a>) | @pcr910303
<br/>
August 23, 2020 | https://notes.eatonphil.com/writing-a-simple-python-compiler.html | <a href="https://web.archive.org/web/*/https://notes.eatonphil.com/writing-a-simple-python-compiler.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <div>
        <p>In this post we'll write a Python to C compiler in Python. This is
especially easy to do since Python has a <a href="https://docs.python.org/3/library/ast.html">builtin parser
library</a> and because a
number of <a href="https://docs.python.org/3/c-api/">CPython internals are exposed for extension
writers</a>.</p>
<p>By the end of this post, in a few hundred lines of Python, we'll be able to
compile and run the following program:</p>
<pre><code>$ cat tests/recursive_fib.py
def fib(n):
    if n == 0 or n == 1:
        return n

    return fib(n - 1) + fib(n - 2)


def main():
    print(fib(40))
$ python3 pyc tests/recursive_fib.py
$ ./bin/a.out
102334155
</code></pre>
<p>This post implements an extremely small subset of Python and
<strong>completely gives up on even trying to manage memory</strong> because I
cannot fathom manual reference counting. Maybe some day I'll find a
way to swap in an easy GC like Boehm.</p>
<p><a href="https://github.com/eatonphil/pyc">Source code for this project is available on Github.</a></p>
<h3 id="dependencies">Dependencies</h3><p>We'll need Python3, GCC, libpython3, and clang-format.</p>
<p>On Fedora-based systems:</p>
<pre><code>$ sudo dnf install gcc python3-devel clang-format python3
</code></pre>
<p>And on Debian-based systems:</p>
<pre><code>$ sudo apt install gcc python3-dev clang-format python3
</code></pre>
<p>
  This program will likely work as well on Windows, Mac, FreeBSD,
  etc. but I haven't gone through the trouble of testing this (or
  providing custom compiler directives). Pull requests welcome!
</p><h3 id="a-hand-written-first-pass">A hand-written first-pass</h3><p>Before we get into the compiler, let's write the fibonacci program by
hand in C using libpython.</p>
<p>As described in the <a href="https://docs.python.org/3/extending/embedding.html#very-high-level-embedding">Python embedding
guide</a>
we'll need to include libpython and initialize it in
our <code>main.c</code>:</p>
<pre><code>#define PY_SSIZE_T_CLEAN
#include &lt;Python.h&gt;

int main(int argc, char *argv[]) {
  Py_Initialize();

  return 0;
}
</code></pre>
<p>To compile against libpython, we'll use
<a href="https://helpmanual.io/man1/python3-config/">python3-config</a> installed
as part of <code>python3-devel</code> to tell us what should be linked
at each step during compilation.</p>
<pre><code>$ gcc -c -o main.o $(python3-config --cflags) main.c
$ gcc $(python3-config --ldflags) main.o
$ ./a.out; echo $?
0
</code></pre>
<p>Cool! Now as we think about translating the fibonacci implementation,
we want to keep everything as Python objects for as long as
possible. This means passing and receiving
<a href="https://docs.python.org/3/c-api/object.html">PyObject*</a> to and from
all functions, and converting all C integers to
<a href="https://docs.python.org/3/c-api/long.html">PyLong*</a>, a "subtype" of
<code>PyObject*</code>. You can imagine that everything in Python is
an <code>object</code> until you operate on it.</p>
<p>
  For more information on objects in Python, check out
  the <a href="https://docs.python.org/3/reference/datamodel.html">Data
  model</a> page in Python docs.
</p><p>To map a C integer to a <code>PyLong*</code> we use
<a href="https://docs.python.org/3/c-api/long.html#c.PyLong_FromLong">PyLong_FromLong</a>. To
map in reverse, we use
<a href="https://docs.python.org/3/c-api/long.html#c.PyLong_AsLong">PyLong_AsLong</a>.</p>
<p>To compare two <code>PyObject*</code>s we can use
<a href="https://docs.python.org/3/c-api/object.html#c.PyObject_RichCompareBool">PyObject_RichCompareBool</a>
which will handle the comparison regardless of the type of the two
parameters. Without this helper we'd have to write complex checks to
make sure that the two sides are the same and if they are, unwrap them
into their underlying C value and compare the C value.</p>
<p>We can use
<a href="https://docs.python.org/3/c-api/number.html#c.PyNumber_Add">PyNumber_Add</a>
and
<a href="https://docs.python.org/3/c-api/number.html#c.PyNumber_Subtract">PyNumber_Subtract</a>
for basic arithmetic, and there are many similar helpers available to
us for operations down the line.</p>
<p>Now we can write a translation:</p>
<pre><code>#define PY_SSIZE_T_CLEAN
#include &lt;Python.h&gt;

PyObject* fib(PyObject* n) {
  PyObject* zero = PyLong_FromLong(0);
  PyObject* one = PyLong_FromLong(1);
  if (PyObject_RichCompareBool(n, zero, Py_EQ) || PyObject_RichCompareBool(n, one, Py_EQ)) {
    return n;
  }

  PyObject* left = fib(PyNumber_Subtract(n, one));

  PyObject* two = PyLong_FromLong(2);
  PyObject* right = fib(PyNumber_Subtract(n, two));

  return PyNumber_Add(left, right);
}

int main(int argc, char *argv[]) {
  Py_Initialize();

  PyObject* res = fib(PyLong_FromLong(7)); // Should be 13

  return PyLong_AsLong(res);
}
</code></pre>
<p>Compile and run it:</p>
<pre><code>$ gcc -c -o main.o $(python3-config --cflags) main.c
$ gcc $(python3-config --ldflags) main.o
$ ./a.out; echo $?
13
</code></pre>
<p>That's great! But we cheated in one place. We assumed that the input
to the <code>fib</code> function was an integer, and we propagated
that assumption everywhere we wrote <code>PyNumber_*</code>
operations. When we write the compiler, we'll need to check that both
arguments are an integer before we call a numeric helper, otherwise we
may need to call a string concatenation helper or something else
entirely.</p>
<h3 id="compiler-architecture">Compiler Architecture</h3><p>We'll break the code into four major parts:</p>
<ol>
<li><code>libpyc.c</code>: helper functions for generated code</li>
<li><code>pyc/context.py</code>: utilities for scope and writing code in memory</li>
<li><code>pyc/codegen.py</code>: for generating C code from a Python AST</li>
<li><code>pyc/__main__.py</code>: the entrypoint</li>
</ol>
<p>
  When I'm writing a new compiler using an existing parser I almost
  always start with the entrypoint and code generator so I can explore
  the AST. However, it's easiest to explain the code if we start with
  the utilities first.
</p><p>We'll also want an empty <code>pyc/__init__.py</code>.</p>
<h3 id="libpyc.c">libpyc.c</h3><p>This C file will contain three helper functions for safely adding,
subtracting, and printing. It will be concatenated to the top of the
generated C file. We'll only support integers for now but this
structure sets us up for supporting more types later on.</p>
<p>We'll use
<a href="https://docs.python.org/3/c-api/long.html#c.PyLong_Check">PyLong_Check</a>
before calling number-specific methods.</p>
<pre><code>#define PY_SSIZE_T_CLEAN
#include &lt;Python.h&gt;

inline PyObject* PYC_Add(PyObject* l, PyObject* r) {
  // TODO: allow __add__ override

  // Includes ints and bools
  if (PyLong_Check(l) &amp;&amp; PyLong_Check(r)) {
    return PyNumber_Add(l, r);
  }

  // TODO: handle str, etc.

  // TODO: throw exception
  return NULL;
}

inline PyObject* PYC_Sub(PyObject* l, PyObject* r) {
  // TODO: allow __add__ override

  // Includes ints and bools
  if (PyLong_Check(l) &amp;&amp; PyLong_Check(r)) {
    return PyNumber_Subtract(l, r);
  }

  // TODO: handle str, etc.

  // TODO: throw exception
  return NULL;
}

inline PyObject* PYC_Print(PyObject* o) {
  PyObject_Print(o, stdout, Py_PRINT_RAW);
  printf("\n");
  return Py_None;
}
</code></pre>
<p>That's it! We could generate these as strings in Python but it gets
hairy to do so. By using a dedicated C file, we can take advantage of
syntax highlighting since this file is only C code. And since we've
marked all functions as <code>inline</code>, there's no runtime cost
to using not embedding these as strings in Python.</p>
<h3 id="pyc/context.py">pyc/context.py</h3><p>This file will contain a <code>Context</code> class for managing
identifiers in scope and for proxying to a <code>Writer</code> class
that contains helpers for writing lines of C code.</p>
<p>We'll have two instances of the <code>Writer</code> class in
<code>Context</code> so that we can write to a body (or
current/primary) region and an initialization region.</p>
<p>The initialization region is necessary in case there are any variables
declared at the top-level. We can't initialize these variables in C
outside of a function since every <code>PyObject*</code> must be
created after calling <code>Py_Initialize</code>. This section will be
written into our C <code>main</code> function before we enter a
compiled Python <code>main</code> function.</p>
<pre><code>import copy


class Writer():
    content = ""

    def write(self, exp: str, indent: int = 0):
        self.content += ("  " * indent) + exp

    def writeln(self, stmt: str, indent: int = 0):
        self.write(stmt + "\n", indent)

    def write_statement(self, stmt: str, indent: int = 0):
        self.writeln(stmt + ";", indent)


class Context():
    initializations = Writer()
    body = Writer()
    indentation = 0

    scope = 0
    ret = None
    namings = {}
    counter = -1

    def __getattr__(self, name: str) -&gt; object:
        # Helpers to avoid passing in self.indentation every time
        outputs = [initializations", "body"]
        for output in outputs:
            if name.startswith(output):
                return lambda s, i=None: getattr(getattr(self, output), name[len(output)+1:])(s, i if i is not None else self.indentation)

        return object.__getattr__(self, name)

    def get_local(self, source_name: str) -&gt; dict:
        return self.namings[source_name]

    def register_global(self, name: str, loc: str):
        self.namings[name] = {
            "name": loc,
            "scope": 0,
        }

    def register_local(self, local: str = "tmp") -&gt; str:
        self.counter += 1
        self.namings[local] = {
            "name": f"{local}_{self.counter}",
            # naming dictionary is copied, so we need to capture scope
            # at declaration
            "scope": self.scope,
        }
        return self.namings[local]["name"]

    def copy(self):
        new = copy.copy(self)
        # For some reason copy.deepcopy doesn't do this
        new.namings = dict(new.namings)
        return new

    def at_toplevel(self):
        return self.scope == 0
</code></pre>
<p>This is all pretty boring boilerplate. Let's move on.</p>
<h3 id="pyc/<strong>main</strong>.py">pyc/<strong>main</strong>.py</h3><p>The entrypoint is responsible for reading source code, parsing it,
calling the code generator, writing the source code to a C file, and
compiling it.</p>
<p>First, we read and parse the source code:</p>
<pre><code>import ast
import os
import subprocess
import shutil
import sys

from context import Context
from codegen import generate

BUILTINS = {
    "print": "PYC_Print",
}


def main():
    target = sys.argv[1]
    with open(target) as f:
        source = f.read()
    tree = ast.parse(source, target)
</code></pre>
<p>Then we write <code>libpyc.c</code> into the body, register builtins,
and run code generation:</p>
<pre><code>
...

def main()
    ...

    ctx = Context()
    with open("libpyc.c") as f:
        ctx.body_write(f.read() + "\n")

    for builtin, fn in BUILTINS.items():
        ctx.register_global(builtin, fn)

    generate(ctx, tree)
</code></pre>
<p>Next, we create a clean output directory and write
<code>main.c</code> with the generated code and a <code>main</code>
function to initialization Python and any global variables:</p>
<pre><code>...

def main():
   ...

    # Create and move to working directory
    outdir = "bin"
    shutil.rmtree(outdir, ignore_errors=True)
    os.mkdir(outdir)
    os.chdir(outdir)

    with open("main.c", "w") as f:
        f.write(ctx.body.content)

        main = ctx.namings.get("main")["name"]
        f.write(f"""int main(int argc, char *argv[]) {{
  Py_Initialize();

  // Initialize globals, if any.
{ctx.initializations.content}
  PyObject* r = {main}();
  return PyLong_AsLong(r);
}}""")
</code></pre>
<p>Finally, we run <code>clang-format</code> and <code>gcc</code> against
the generated C code:</p>
<pre><code>...

def main():
    ...

    subprocess.run(["clang-format", "-i", "main.c"])

    cflags_raw = …</code></pre></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://notes.eatonphil.com/writing-a-simple-python-compiler.html">https://notes.eatonphil.com/writing-a-simple-python-compiler.html</a></em></p>]]>
            </description>
            <link>https://notes.eatonphil.com/writing-a-simple-python-compiler.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24252233</guid>
            <pubDate>Sun, 23 Aug 2020 14:35:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Microsoft .NET SDK is violating the GDPR, object now]]>
            </title>
            <description>
<![CDATA[
Score 35 | Comments 10 (<a href="https://news.ycombinator.com/item?id=24251579">thread link</a>) | @dgl
<br/>
August 23, 2020 | https://dgl.cx/2020/08/dotnet-sdk-gdpr | <a href="https://web.archive.org/web/*/https://dgl.cx/2020/08/dotnet-sdk-gdpr">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>


<p><b>Skip to the end if you just want a template for a "Right to object"
letter.</b></p>

<p>The .NET Core software development kit (SDK) is a set of command line tools
that allow development against Microsoft's .NET. When the command line tool is
run it sends some telemetry back to Microsoft.</p>

<p>This telemetry is <a href="https://aka.ms/dotnet-cli-telemetry">documented</a>, however the way it is implemented appears
against the <a href="https://gdpr-info.eu/">GDPR</a> in multiple ways.</p>

<h3>Collection by default</h3>

<p>Running <code>dotnet help</code> on a clean install, will print a message about telemetry,
but will send the details on that run.</p>

<p><a href="https://dgl.cx/2020/08/dotnet-help.png"><img src="https://dgl.cx/2020/08/dotnet-help.png"></a></p>

<p>Therefore the GDPR requriements under <a href="https://gdpr-info.eu/recitals/no-42/">"Burden of proof and requirements for
consent"</a> cannot be met -- even if we
give Microsoft the benefit of doubt and consider a command line application
somewhat special, it does not give us a chance to opt-out, yet alone opt-in.</p>

<p><a href="https://dgl.cx/2020/08/dotnet-installer.png"><img src="https://dgl.cx/2020/08/dotnet-installer.png"></a></p>

<p>During the installation process, there is a link to Microsoft's <a href="https://privacy.microsoft.com/en-gb/privacystatement">Privacy
statement</a>, however this
does not mention the environment variable needed to opt-out, so there is no way
to opt out before the first piece of data is sent.</p>

<h3>Collecting personal data</h3>

<p>The linked information page, as well as the text printed  in the CLI both say "The data is
anonymous.", it clearly isn't. They collect MAC addresses and the current
working directory, which are sent to their servers hashed.</p>

<p>A key thing to understand: <b>Hashing without a salt does not make the data
anonymous or even pseudonymous.</b></p>

<p>See for example <a href="https://medium.com/@alexewerlof/gdpr-pseudonymization-techniques-62f7b3b46a56">GDPR pseudonymisation
techniques</a>.
Given this, it is a clear violation as <a href="https://gdpr-info.eu/art-6-gdpr/">Article
6</a> requires specific purposes for processing,
but the data was claimed to be anonymous, which it isn't.</p>

<p>A common place to run "dotnet help" might be a home directory, which can often
include a username, e.g. <code>/home/dgl</code>. So while it's hashed it is easily
possible to find the hash that relates to a particular user:</p>

<pre><code>$ pwd
/home/dgl
$ echo -n $PWD | sha256sum
67acfe0ddd44867e1e5da5ddaf25a5b90e928f523cecf614e201c683b7533cf6  -
</code>
</pre>

<p>This matches the relevant part of the JSON sent:</p>

<pre><code>  "Current Path Hash": "67acfe0ddd44867e1e5da5ddaf25a5b90e928f523cecf614e201c683b7533cf6",
</code></pre>

<p>There are some discussions about the collection of MAC addresses in
<a href="https://github.com/dotnet/sdk/issues/6145">issue #6145</a> but no
particular reply from Microsoft; people suspect it's a GDPR violation. Note
that under the GDPR there are time limits for replying, so that's another
potential GDPR issue.</p>

<p>The <a href="https://dgl.cx/2020/08/ms-report.txt">report</a> I sent to Microsoft detailed how a
MAC address is likely not even 48-bits of search space, as we know what ones
are assigned, so brute-forcing is quite possible, particularly when combined
with the fact the search space can be reduced by filtering on the path
hash.</p>

<p>One principle of the GDPR is you need to explain why you're collecting
information, Microsoft do in a round about way, rather than on the link
printed by the command (<a href="https://aka.ms/dotnet-cli-telemetry">https://aka.ms/dotnet-cli-telemetry</a>) which explains what they are collecting, the "why" is hidden on a <a href="https://devblogs.microsoft.com/dotnet/what-weve-learned-from-net-core-sdk-telemetry/">blog post</a>.</p><p>

It says:
</p><blockquote>
Hashed MAC address â€” Determine a cryptographically (SHA256) anonymous and unique ID for a machine. Useful to determine the aggregate number of machines that use .NET Core. This data will not be shared in the public data releases.
<p>

Hashed current working directory â€” Determine build machines from dev machines using the heuristic of a large number of working directories. This distinction helps explain large #s of builds from a machine.
</p></blockquote>


<p>This shows a clear intention to join the data, for some purposes. The "Hashed
MAC address" is obviously understood to be somewhat sensitive as it mentions
they won't share it. Interestingly the same is not said for the current working
directory, which is also sensitive.</p>

<h3>Privacy policy</h3>

<p>As mentioned Microsoft has a <a href="https://privacy.microsoft.com/en-gb/privacystatement">general privacy policy</a>.</p>

<p>This could allow some collection, however:</p>

<blockquote>
You have choices when it comes to the technology you use and the data you
share. When we ask you to provide personal data, you can decline.
</blockquote>

<p>This behaviour would be GDPR compliant, but the key point is due to the first
collection behaviour of e.g. running <code>dotnet help</code> there is no chance to
decline. So the behaviour of the dotnet tool is inconsistent with their own
privacy policy.</p>

<h3>How to respond?</h3>

<p>I sent a report to Microsoft's security team, because arguably incorrect use of
a cryptographic hashing function (SHA256 of the items, without a salt) is a
"Security Design Flaw" which qualifies under the <a href="https://www.microsoft.com/en-us/msrc/bounty-dot-net-core">dotnet 
bug bounty</a>. This was
obviously fishing a bit, and Microsoft denied me. More surpsingly they don't
seem to consider this a problem at all, their final reply was:</p>

<blockquote>
We have updates scheduled for the first run experience and related documentation to make it more accurate. Personal data is handled consistently with GDPR requirements.
</blockquote>

<p>You'll notice that they don't talk about any actual collection changes. Also
interestingly if the data is anonymous as they claim, what "Personal data" are
they referring to in this reply?</p>

<h4>What's the route the GDPR gives us here?</h4>

<p>This is an interesting one, partly <a href="https://gdpr-info.eu/art-11-gdpr/">Article 11 Processing which does not
  require identification</a> could apply, in that they can exclude themselves
from right of access, etc. With the exception of "Right to object".</p>

<p>There are two routes, either we give enough information for Microsoft to be
happy we identify ourselves (and use the right to erasure), or we use the right
to object, which while it doesn't require Microsoft to delete the data
entirely does require them to limit their use of it.</p>

<p>So I can object to any processing of my data, and as I've proved we can use
the MAC address to find my machine in their data. I believe given this has gone
on for several years that even if they make the data collection GDPR compliant,
there is a huge historical collection of data that may need clearing as it has
been collected unlawfully.</p>

<p>In my original <a href="https://dgl.cx/2020/08/ms-report.txt">report</a> to Microsoft I made some recommendations:</p>

<pre><code>
Recommendations:
<ul><li>Remove the telemetry, it avoids any potential GDPR issues;</li>
<li>Delete the historical data (I am not a lawyer, but I suspect this has GDPR
implications);
</li></ul></code></pre>

<p>It appears they do not intend to follow these so I suggest that any user of
.NET Core SDK in the European Union takes matters into their own hands and use
their right to object:</p>

<div>
<p>
[Your full address]
[The date]</p>

<p>To Data Controller, Microsoft Corporation</p>

<p>I am exercising my right to object under the General Data Protection
Regulation (Article 21).</p>

<p>It has come to my attention that Microsoft .NET Core SDK collects telemetry,
and the opt-out process for this data is flawed.</p>

<p>In particular setting the <code>DOTNET_CLI_TELEMETRY_OPTOUT</code> variable
is only suggested the first time the tool is run, so some data may have been
collected against my will.</p>

<p>In light of Microsoft not deleting this telemetry data for everyone (per the
report of David Leadbeater on 3 August 2020). I wish that my telemetry data is
restricted from further processing, as I have set the opt-out environment
variable, but I cannot be sure that some data has not reached Microsoft
already.</p>

<p>The MAC addresses of my machine(s) is/are:</p>

<p>XX:XX:XX:XX:XX:XX</p>

<p>I believe this is enough to identify my records, as they are stored as a
SHA256 hash of this MAC address.</p>

<p>Please send a full response within one calendar month confirming if you will
comply with my request. If you cannot respond within that timescale, please
tell me when you will be able to respond.</p>

<p>If there is anything you would like to discuss, please contact me.</p>

<p>Thank you,
</p></div>

<p>Obviously the somewhat strange thing about this is you reveal your MAC
address to Microsoft in the process, but I'm fairly sure the data protection
around GDPR requests is something that is well scrutinized.</p>

<p>If you do want to send this to Microsoft go to
<a href="https://www.microsoft.com/en-GB/concern/privacy">https://www.microsoft.com/en-GB/concern/privacy</a> and select "I want to contact
Microsoftâ€™s Data Protection Officer".</p>

<p>It's strange this is still an issue as this was previously discussed over
two years ago (see this <a href="https://news.ycombinator.com/item?id=17177241">Hacker News
thread</a>). Let's use our right to object!</p>

</div></div>]]>
            </description>
            <link>https://dgl.cx/2020/08/dotnet-sdk-gdpr</link>
            <guid isPermaLink="false">hacker-news-small-sites-24251579</guid>
            <pubDate>Sun, 23 Aug 2020 12:57:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Persisting as a solo founder]]>
            </title>
            <description>
<![CDATA[
Score 671 | Comments 244 (<a href="https://news.ycombinator.com/item?id=24251403">thread link</a>) | @vishnumohandas
<br/>
August 23, 2020 | https://vishnu.tech/posts/persistence/ | <a href="https://web.archive.org/web/*/https://vishnu.tech/posts/persistence/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><img src="https://sa.vishnu.tech/noscript.gif" alt="">




    



  



    
    <p><time itemprop="datePublished">August 19, 2020</time>
    </p>
    

<p>I quit my job in January 2020 to build a privacy friendly photo organizer.</p>

<p>As a 30 year old whose friends are either getting married or planning
off-springs, what I had underestimated was the difficulty involved in finding a co-founder and how that would compound the difficulty involved in
finding an investor.</p>

<p>Once I accepted the loneliness and the lack of a financial cushion I had to figure out a way to keep building without burning myself out.</p>

<p>It took me a while, but I have found a rhythm that works, and with it, a steady
source of endorphins. Here are some changes that helped me to keep things
moving.</p>

<h2 id="being-patient">Being patient</h2>

<p>Life is no longer as comfortable as it used to be and things are not always
going the way I want them to. Preseverance has been key and indirectly patience
too. Naval’s <a href="https://twitter.com/naval/status/1261481752448524289" target="_blank">take on
meditation</a> (60 minutes x
60 days), was an eye opener. I’ve stuck with it since, and I now have an easier
time identifying negative thought patterns and sitting out situations that would
otherwise overwhelm me.</p>

<p>On some level, spending the last few months locked indoors with my parents, who
are not the most rational people in the world has also helped. But I wouldn’t
recommend it.</p>

<h2 id="reducing-procrastination">Reducing procrastination</h2>

<p>Over time I’ve realized that action precedes motivation and procrastination precedes guilt.</p>

<p>Breaking down tasks into chunks that seem trivial to accomplish has helped reduce the friction in getting started on unexciting grunt work.</p>

<p>Then there are tasks which I loathe from my core, like writing out applications
to VCs explaining why what I’m doing will matter. To those I attach reinforcing
personal reasons, like, “I need the $50k to hire that college junior who I love
working with, and that will give me spare bandwidth to focus on traction channels”.</p>

<h2 id="thinking-clearer">Thinking clearer</h2>

<p>It is sub-optimal to not have a coworker to bounce ideas off and rant about problems to. A lot of times it’s these conversations that help you gain clarity.</p>

<p>It’s a luxury I do not have so every time I feel stuck, I type/scribble my thoughts out, and then question everything that was written, and then document my realizations.</p>

<p>Task tracking has also helped in clearing the path. I write down unstructured
thoughts into a diary, and once I’ve clarity, I promote them to a Notion board
(that’s divided into <em>Thinking</em>, <em>Building</em>, <em>Reading</em>, <em>Writing</em> and
<em>Adulting</em>) and every Monday within an Excel sheet I track what was done, and
what is left to be done.</p>

<h2 id="reducing-distractions">Reducing distractions</h2>

<p>I’ve reduced my information consumption to free up brain cycles. I’ve disabled all notifications on my phone barring a few contacts, and I’ve more or less stopped browsing on it. As an added bonus, this has reduced the negativity with which I perceived the world.</p>

<p>To minimize the overhead of context switches, I split tasks into a tree of checkpoints. Before taking a break I note down the next simplest checkpoint so that when I get back to work there’s little friction to resume.</p>

<p>To help me zone out I keep <a href="https://www.youtube.com/watch?v=5qap5aO4i9A" target="_blank">lofi
beats</a> or
<a href="http://github.audio/" target="_blank">github.audio</a> playing in the background. Listening to the
latter gives me a strange sense of motivation and makes me feel less alone.</p>

<h2 id="staying-grounded">Staying grounded</h2>

<p>I’m lucky to have some friends who call/text every other week. I look at them as my accountability partners and I talk to them about what I’m doing on a high level. While not all of them genuinely care, some do, and these conversations force me to reflect on how well I’m doing what I’m doing.</p>

<p>While Silicon Valley wisdom suggests that if I’m not sleeping I should be
working, failing because of a burn out would be stupid. An advantage of not
having a VC onboard so far has been the freedom to dictate my pace. So I spend
days thinking, reading, fiddling with my violin or just doing nothing when I
feel like writing code is not what I want to do.</p>

<hr>

<p>It’s been 7 months of building alone, and while this is not how I pictured things to be on my last day at work, this is the happiest I have ever been. There’s a long way to go, and the grind seems inviting.</p>

<p>This list is by no means exhaustive, for I’m still learning. If you’ve
anything to share, please join <a href="https://news.ycombinator.com/item?id=24251403" target="_blank">the discussion on HackerNews</a>.</p>

<hr>

<p>If you are curious about what I’ve been building, check out
<a href="https://ente.io/" target="_blank">ente.io</a>.</p>

    <br>
    


</div>]]>
            </description>
            <link>https://vishnu.tech/posts/persistence/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24251403</guid>
            <pubDate>Sun, 23 Aug 2020 12:27:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Remembering what you Read: Zettelkasten vs. P.A.R.A]]>
            </title>
            <description>
<![CDATA[
Score 113 | Comments 58 (<a href="https://news.ycombinator.com/item?id=24251068">thread link</a>) | @stanulilic
<br/>
August 23, 2020 | https://www.zainrizvi.io/blog/remembering-what-you-read-zettelkasten-vs-para/ | <a href="https://web.archive.org/web/*/https://www.zainrizvi.io/blog/remembering-what-you-read-zettelkasten-vs-para/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
			<!-- .cover -->


				<div>
					<p>I love reading. But retaining what I read tends to be a challenge. I usually walk away from a book feeling good but with only a faint idea of what was in there. Heck, if I spend a couple hours online I’ll barely remember what articles I read! And it’s not just me, studies show that <a href="https://learningsolutionsmag.com/articles/1379/brain-science-the-forgetting-curvethe-dirty-secret-of-corporate-training">you only retain a tiny percentage of what you read</a>.</p><p>I hated the idea of wasting all that time I spent reading, so a year ago I started looking into ways to retain what I learned.</p><p>My first attempt led me to Farnam Street’s tips on <a href="https://fs.blog/2014/05/remembering-what-you-read/">remembering what you read</a>. Their concept of writing your notes on the book itself was liberating (it’s okay to WRITE in my book?!?). Actively writing down notes helped me get more insights out of the text, but those thoughts would then be trapped in the analogue world, locked away until I happened to peruse the book some time in the future.</p><figure><img src="https://www.zainrizvi.io/content/images/2020/07/2020-05-08-Remember-20what-20you-20read-20-1--1-.png" alt="" srcset="https://www.zainrizvi.io/content/images/size/w600/2020/07/2020-05-08-Remember-20what-20you-20read-20-1--1-.png 600w, https://www.zainrizvi.io/content/images/2020/07/2020-05-08-Remember-20what-20you-20read-20-1--1-.png 769w" sizes="(min-width: 720px) 720px"></figure><p>FS also suggested writing down the book’s core ideas from memory right after you finish the book, but this is a process that requires discipline (unless you like testing yourself?) and things requiring discipline have a distressing tendency to not happen.</p><p>Those tips were exciting, but I couldn’t stick with it. I needed something different.</p><p>Next I came across the <a href="https://writingcooperative.com/zettelkasten-how-one-german-scholar-was-so-freakishly-productive-997e4e0ca125">Zettelkasten note taking method</a>. Its core idea is to create atomic notes, where each note is about exactly one topic (not more than a few paragraphs tops) and nothing more. Then you file the away in your system by linking that note to other notes which seem most relevant to it. All the notes are written in your own words, so you’re really writing down your own thoughts here.</p><figure><img src="https://www.zainrizvi.io/content/images/2020/07/2020-05-08-Remember-20what-20you-20read-20-2--1-.png" alt="" srcset="https://www.zainrizvi.io/content/images/size/w600/2020/07/2020-05-08-Remember-20what-20you-20read-20-2--1-.png 600w, https://www.zainrizvi.io/content/images/2020/07/2020-05-08-Remember-20what-20you-20read-20-2--1-.png 616w"></figure><p>The key here is that the linking process <strong><strong>groups relevant notes together</strong></strong>. Now when you’re interested in browsing your notes on a given topic, you’ll easily find them. You get to see how your ideas relate to each other as well as discover interesting ways they may play off against or even contradict one another.</p><p>But this technique is time intensive. You have to:</p><ul><li>Save the initial note, paraphrasing what you learned</li><li>Search for relevant notes to link it to</li><li>Potentially update your table of contents to find that note more easily later on</li></ul><p>If you take a lot of notes, the stream of incoming notes can quickly leave you overwhelmed. This technique requires time and dedication.</p><p>I couldn’t stick with it.</p><p>Finally I discovered Building a Second Brain and it’s <a href="https://fortelabs.co/blog/para/">P.A.R.A</a> technique. It offers an easier option for busy people.</p><p>With P.A.R.A. you organize all your notes by purpose, not by category. Let’s say you’re trying to build an app. You’ll have a folder called ‘app’ for all notes about it. Now if you study databases in order to build it, you’ll file any notes you take inside the ‘app’ folder, not in a separate ‘databases’ folder.</p><figure><img src="https://www.zainrizvi.io/content/images/2020/07/2020-05-08-Remember-20what-20you-20read-20-3--1-.png" alt="" srcset="https://www.zainrizvi.io/content/images/size/w600/2020/07/2020-05-08-Remember-20what-20you-20read-20-3--1-.png 600w, https://www.zainrizvi.io/content/images/size/w1000/2020/07/2020-05-08-Remember-20what-20you-20read-20-3--1-.png 1000w, https://www.zainrizvi.io/content/images/2020/07/2020-05-08-Remember-20what-20you-20read-20-3--1-.png 1500w" sizes="(min-width: 720px) 720px"></figure><p>What does this do? By creating purpose-based folders and putting all notes related to that <em>purpose</em> inside it, we’ve created a new way to group relevant notes together. All your notes related to that purpose are available front and center when you open the folder. This lets you avoid the time consuming process of sorting, organizing, and linking your notes in order to make them useful. Just drop the note in the right folder and BAM, that’s it.</p><p>How do you reference old notes? When you start working on a new project (like a writing assignment) you search the relevant folders and pull out notes that seem relevant to your task. All those notes will go into the new project’s folder. You’re effectively discovering related notes on the fly. You’ve avoided the work of double linking and cross referencing your notes. This solution gets you 80% of the way there with 20% of the effort. Just in Time linking.</p><p>When you finish a project, you file away the notes from that project in which ever folder you think they’ll be most useful in, and then archive the project folder. Now you’ve reset the notes to be discoverable the next time you need them.</p><p>And it’s not just good for retention. I’m finding that this purpose-based organization is helping me work much more productively on all my projects!</p><p>Even the step of summarizing what you read is optimized for efficiency. It’s called <a href="https://fortelabs.co/blog/progressive-summarization-a-practical-technique-for-designing-discoverable-notes/">Progressive Summarization</a></p><p>With progressive summarization you don’t bother summarizing what you’re learning, at least not at first. Instead you take the passages you found most interesting and copy them into your notes. If you ever reread those notes in the future then you can start highlighting the phrases that really spoke to you and if you reread them again, only then will you do the work to summarize the ideas in your own words.</p><p>It’s not that summarizing your notes from the beginning is bad, but if you procrastinate on it while still expecting yourself to do it then you’re setting yourself up for failure. Progressive summarization offers you a way to delay summarization while still retaining value.</p><p>Note what’s happened here: Instead of forcing myself to be disciplined about organizing my notes, P.A.R.A. + Progressive Summarization takes advantage of the times when I’m <strong><strong>already excited to work on them</strong></strong>. Each time I touch the notes, I have to take a small amount of effort which is proportionate to my level of interest in the task. <strong><strong>We’ve replaced forced discipline with leveraged excitement.</strong></strong></p><p>There is one other critical aspect of PARA that’s required to keep the system from being overwhelming. Successful followers of the Zettelkasten method seem to follow this instinctively, but <a href="https://zettelkasten.de/posts/collectors-fallacy/">it’s rarely mentioned</a>:</p><p>You’re highly encouraged to <strong><strong>limit</strong></strong> the kind of things you save in your second brain to the following:</p><ul><li>Things related to projects you’re <em>actively</em> working on. Don’t store trivia</li><li>Store things that surprise you: Don’t store stuff you already know</li><li>A 12 select problems that you love to think about</li></ul><p>Tiago recommends thinking about <a href="https://fortelabs.co/blog/how-to-use-evernote-for-your-creative-workflow/">the 12 problems you care most about</a> and <em>only</em> store things related to those problems in your notebook (so skip the articles about ancient mummies…unless you’re an archaeologist).</p><p>By limiting which topics you put in your second brain you free up more cognitive space to notice what you do store. By storing less you’ll remember more 🤯</p><p>Not making your second brain cognitively overwhelming is an under-emphasized part of the PARA system. There shouldn’t be anything in your project’s section unless you are actively working on it. Even the other sections are also meant to be pruned on a regular basis so that they only represent your primary interests. A good rule of thumb: if any folder gains more notes than you can easily skim (~50-100 notes), it might be time to split that folder into two or maybe even delete some notes.</p><p>This is by no means a complete comparison of Zettlekasten and P.A.R.A. (that would be a much longer essay) but it captures the major points.</p><p>Zettelkasten has its benefits: If you want to be able to casually browse through your notes, looking for ideas to spark your imagination, Zettelkasten will most likely have superior results since the ideas are already summarized right there for you. Zettelkasten makes it easy to compose essays and put together speeches, but that’s because you’ve already done the hard work of writing down your thoughts ahead of time.</p><p>It’s requirement to link all notes ahead of time is a HUGE barrier to entry, so Zettlekasten may be best suited to people with a strong research oriented disposition who’re already used to similar practices. The fact that there’s no good software available to help with this makes the process even harder. (Check out <a href="https://notes.andymatuschak.org/zUw5PuD8op9oq8kHvni6sug6eRTNtR9Wqma">Andy Matuschak’s notes</a> for a gorgeous Zettlekasten example)</p><p>P.A.R.A. is great for those who don’t have the time (or willpower) to force themselves to write down notes they may never use. Instead it’s Just-in-Time philosophy saves many hours and lets you be more productive. Tiago has designed P.A.R.A. to work with most productivity apps, but the process is optimized for his app of choice: Evernote.</p><p>All in all, I’m finding P.A.R.A. pretty useful so far. It has yet to pass the ultimate test of any knowledge management system: Will I still be using it three months from now? (ask me after July). I’m already noticing productivity boosts by using the PARA method to store notes for all my projects, so prospects are looking good 😁</p>
				</div><!-- .post-content -->
				<!-- .post-footer -->
				<!-- .comments-area -->


		</article></div>]]>
            </description>
            <link>https://www.zainrizvi.io/blog/remembering-what-you-read-zettelkasten-vs-para/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24251068</guid>
            <pubDate>Sun, 23 Aug 2020 11:03:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[2020: An Isolation Odyssey]]>
            </title>
            <description>
<![CDATA[
Score 21 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24250068">thread link</a>) | @unhammer
<br/>
August 22, 2020 | http://lydiacambron.com/index.php/project/2020-an-isolation-odyssey/ | <a href="https://web.archive.org/web/*/http://lydiacambron.com/index.php/project/2020-an-isolation-odyssey/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><em>2020: an isolation odyssey</em> is a reenactment of the iconic finale of <em>2001: A Space Odyssey</em> (Stanley Kubrick, 1968). Restaged in the context of home quarantine, the journey through time adapts to the mundane dramas of self-isolation–poking fun at the navel-gazing saga of life alone and indoors.</p>

<p>This project began in late March and was completed in late May, spanning the height of the pandemic in New York City. Staged in a one bedroom Brooklyn apartment, <em>2020</em> presents an obvious similarity to the domestic setting of <em>2001</em>. The stacked videos and synced movements also reveal parallels in emotion. The narrowness of daily life in a single space, transitioning from confusion to acceptance, a distorted sense of time, and ‘returning’ after a transformational event–all experiences analogous to quarantine. </p>

<p>The adapted version delineates the passing of time through wardrobe rather than age, identifying each phase of the character’s journey with a product of self care or PPE. Tools of private entertainment or self betterment are also used as props, questioning our confidence in products and productivity as anchors during times of uncertainty. Multitasking while #wfh, conjuring guilt or longing with unused exercise equipment, your entire being reduced to a measure of time–these scenes all illustrate the absurd comedy of trying to maintain control during this unprecedented and unpredictable time.<br>
</p></div></div>]]>
            </description>
            <link>http://lydiacambron.com/index.php/project/2020-an-isolation-odyssey/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24250068</guid>
            <pubDate>Sun, 23 Aug 2020 06:37:59 GMT</pubDate>
        </item>
    </channel>
</rss>
