<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 20]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 20. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Sun, 21 Feb 2021 04:35:44 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-20.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Sun, 21 Feb 2021 04:35:44 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[Where Everything Went Wrong: Error Handling and Error Messages in Rust]]>
            </title>
            <description>
<![CDATA[
Score 37 | Comments 10 (<a href="https://news.ycombinator.com/item?id=26191006">thread link</a>) | @lukastyrychtr
<br/>
February 19, 2021 | https://msirringhaus.github.io/Where-everything-went-wrong/ | <a href="https://web.archive.org/web/*/https://msirringhaus.github.io/Where-everything-went-wrong/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p><strong>Today you are frustrated.</strong></p>

<p>This is so annoying. You√¢‚Ç¨‚Ñ¢ve written a Rust crate and now that you want to test it for the very first time, <em>it doesn√¢‚Ç¨‚Ñ¢t work!</em></p>

<p>Come on, Rust! How dare you? You promised that once one gets past the compiler, it.<br>
<em>Just.<br>
<strong>Works!</strong></em><br>
And now this!</p>

<p>Ok, ok. You calm yourself down. Lets start from the beginning. You want to create so called <a href="https://docs.sentry.io/platforms/native/guides/minidumps/">minidumps</a>. This is a file that contains information about a crashed program (like stacks of all threads, CPU registers, system info, etc.).
The minidump consists of various sections, such as the minidump header (including time of day, versions and basically a table of contents), a thread section (including all threads of the process and their stacks), memory mappings and libraries, etc. [Just to give some context, as all of this is actually not really important.]</p>

<p>For this, you created a <a href="https://github.com/msirringhaus/minidump_writer_linux">crate</a>. One section gets written after the other, while information about the targeted process is retrieved from the system. You even created a nice, simple API. You hand in a process ID and an open file, where the minidump should be written to. like this:</p>

<div><div><pre><code>    <span>MinidumpWriter</span><span>::</span><span>new</span><span>(</span><span>pid</span><span>,</span> <span>blamed_thread</span><span>)</span>
        <span>.dump</span><span>(</span><span>&amp;</span><span>mut</span> <span>dump_file</span><span>)</span>
        <span>.expect</span><span>(</span><span>"Dumping failed!"</span><span>)</span>
</code></pre></div></div>

<p>You can also hand in user specified memory regions that should be included in the dump, like so:</p>

<div><div><pre><code>    <span>let</span> <span>app_memory</span> <span>=</span> <span>AppMemory</span> <span>{</span>
        <span>ptr</span><span>:</span> <span>some_address</span><span>,</span>
        <span>length</span><span>:</span> <span>memory_size</span><span>,</span>
    <span>};</span>

    <span>MinidumpWriter</span><span>::</span><span>new</span><span>(</span><span>pid</span><span>,</span> <span>pid</span><span>)</span>
        <span>.set_app_memory</span><span>(</span><span>vec!</span><span>[</span><span>app_memory</span><span>])</span>
        <span>.dump</span><span>(</span><span>&amp;</span><span>mut</span> <span>tmpfile</span><span>)</span>
        <span>.expect</span><span>(</span><span>"Dumping failed"</span><span>);</span>
</code></pre></div></div>



<p>But when you run your nice library code in an application, you get <code>'Dumping failed: "Failed in ptrace::read: Sys(EIO)"'</code>.</p>

<p><em>How useless is that?!</em></p>

<p>Okay, maybe you could enhance your library error handling, a little. And by enhance, you mean √¢‚Ç¨≈ìimplement one in the first place√¢‚Ç¨ÔøΩ.</p>

<h2 id="state-of-the-dart">State of the dart</h2>

<p>Your current approach is to define</p>

<div><div><pre><code><span>type</span> <span>Error</span> <span>=</span> <span>Box</span><span>&lt;</span><span>dyn</span> <span>error</span><span>::</span><span>Error</span> <span>+</span> <span>std</span><span>::</span><span>marker</span><span>::</span><span>Send</span> <span>+</span> <span>std</span><span>::</span><span>marker</span><span>::</span><span>Sync</span><span>&gt;</span><span>;</span>
<span>pub</span> <span>type</span> <span>Result</span><span>&lt;</span><span>T</span><span>&gt;</span> <span>=</span> <span>result</span><span>::</span><span>Result</span><span>&lt;</span><span>T</span><span>,</span> <span>Error</span><span>&gt;</span><span>;</span>
</code></pre></div></div>

<p>and using <code>Result&lt;T&gt;</code> in all of your functions as the return value and handing all of them to the parent function using <code>?</code>. Thus the original error pierces through your callstack like a dart through√¢‚Ç¨¬¶.jelly (Yes, you are good with words and you know it.).</p>

<div><div><pre><code>    <span>pub</span> <span>fn</span> <span>init</span><span>(</span><span>&amp;</span><span>mut</span> <span>self</span><span>)</span> <span>-&gt;</span> <span>Result</span><span>&lt;</span><span>()</span><span>&gt;</span> <span>{</span>
        <span>self</span><span>.read_auxv</span><span>()</span><span>?</span><span>;</span>
        <span>self</span><span>.enumerate_threads</span><span>()</span><span>?</span><span>;</span>
        <span>self</span><span>.enumerate_mappings</span><span>()</span><span>?</span><span>;</span>
        <span>Ok</span><span>(())</span>
    <span>}</span>
</code></pre></div></div>

<p>In Rust parlance, this is also called bubbling up errors.</p>

<p>Usually, you just bubble up errors from libraries you use, but for the rare errors you have to define yourself, you currently just do</p>
<div><div><pre><code><span>Err</span><span>(</span><span>"Found no auxv entry"</span><span>.into</span><span>())</span>
</code></pre></div></div>

<p>Well, now you know there is an error, at least. And that it has <em>something</em> to do with your usage of <code>ptrace</code>. But you have no idea where that happens. You use that functionality in various places. Is it during the init-phase? During one of the sections? And if so, which one? What are you trying to read? And from where? Or in short: <strong>What is going on?!</strong></p>

<h2 id="shoes-off-get-some-tea-research-time">Shoes off, get some tea: Research time!</h2>

<p>Well, Rust has been around for quite some time now and they always boast about how error handling is a first class citizen and all that. So error handling should be a done deal, right? With a canonical way of dealing with errors, officially documented and all that should be right there, correct?</p>

<p>Oh boy, were you wrong.</p>

<p>Turns out, this is a very active field of√¢‚Ç¨¬¶mh√¢‚Ç¨¬¶experimentation, lets say. There has been <a href="https://blog.yoshuawuyts.com/error-handling-survey/">a survey</a> recently, listing and quickly describing most the different libraries and ways for error handling that emerged, fallen out of favor, got forked, died anyways, got superseded, fallen out of favor again, etc.
And the opinions seem to change frequently, if you should use <code>error-chain</code> or <code>failure</code> or <code>fehler</code> or <code>snafu</code> or <code>thiserror</code> or <code>anyhow</code> or <code>eyre</code> or√¢‚Ç¨¬¶</p>

<p>You opened a can of hornets there, or whatever that saying is.</p>

<p>Then you find <a href="https://blog.rust-lang.org/inside-rust/2020/11/23/What-the-error-handling-project-group-is-working-on.html">this gem</a> and don√¢‚Ç¨‚Ñ¢t know if you should laugh or cry. Almost six years after Rust hit 1.0 an error handling project group is formed. Six. Years. <em>(heavy breathing)</em></p>

<p>Well, okay. At least they are sorting it out now. Problem is, you need√¢‚Ç¨¬¶.<em>SIX YEARS? Are you serious?</em>√¢‚Ç¨¬¶ahem, sorry√¢‚Ç¨¬¶Problem is, you need helpful error messages now.</p>

<p>After reading a few decent blogs on the topic (like <a href="http://www.sheshbabu.com/posts/rust-error-handling/">this</a> or <a href="https://nick.groenen.me/posts/rust-error-handling/">that</a>), there seems to emerge a consensus, at least for libraries: Return something that derives from <code>std::error::Error</code>. Either implement them by hand, or use a crate that does it for you, using macro magic. like <code>thiserror</code>. Which method you use depends on your level of laziness plus your patience regarding compile times.</p>

<h2 id="examples-vs-reality">Examples vs. Reality</h2>

<p>Another post highlighted <a href="https://doc.rust-lang.org/rust-by-example/error/multiple_error_types/wrap_error.html">error wrapping</a>, a particularly intriguing idea to you.</p>

<p>Unfortunately, all the articles have the understandable, but rather annoying tendency to use very simple example code for illustration purposes. Unrealistically simple, you might even say. They have callstacks of depth 1, return only three kinds of error in total in their API, and their errors are obvious and easily describable (e.g. √¢‚Ç¨≈ìInput file XY not found in your √¢‚Ç¨Àúcounting words√¢‚Ç¨‚Ñ¢ program√¢‚Ç¨ÔøΩ).</p>

<p>You have a more complicated callstack, with tons of different errors and code reuse in different places. For example, the function you think is to blame for the above error is <code>copy_from_process()</code>, which calls <code>ptrace::read()</code>, which probably returns something like <code>Failed in ptrace::read: Sys(EIO)</code>.
This function is used in multiple places in your code, e.g.:</p>

<div><div><pre><code>√¢‚Äù≈ì√¢‚Äù‚Ç¨ init()
√¢‚Äù‚Äö   √¢‚Äù≈ì√¢‚Äù‚Ç¨ read_auxv()
√¢‚Äù‚Äö   √¢‚Äù‚Äö  √¢‚Äù≈ì√¢‚Äù‚Ç¨ open(format!("/proc/{}/auxv", self.pid))
√¢‚Äù‚Äö   √¢‚Äù‚Äö  √¢‚Äù‚Äù√¢‚Äù‚Ç¨ some_parsing()
√¢‚Äù‚Äö   √¢‚Äù≈ì√¢‚Äù‚Ç¨ ...
√¢‚Äù‚Äö   √¢‚Äù≈ì√¢‚Äù‚Ç¨ enumerate_mappings()
√¢‚Äù‚Äö   √¢‚Äù‚Äö  √¢‚Äù≈ì√¢‚Äù‚Ç¨ open(format!("/proc/{}/maps", self.pid))
√¢‚Äù‚Äö   √¢‚Äù‚Äö  √¢‚Äù‚Äù√¢‚Äù‚Ç¨ some_parsing()
√¢‚Äù‚Äö   √¢‚Äù‚Äö
√¢‚Äù‚Äö   √¢‚Äù‚Äù√¢‚Äù‚Ç¨ some_more_checks()
√¢‚Äù‚Äö      √¢‚Äù‚Äù√¢‚Äù‚Ç¨ copy_from_process()
√¢‚Äù‚Äö
√¢‚Äù‚Äù√¢‚Äù‚Ç¨ dump()
   √¢‚Äù‚Äö
   √¢‚Äù≈ì√¢‚Äù‚Ç¨ sections::header::write()
   √¢‚Äù‚Äö
   √¢‚Äù≈ì√¢‚Äù‚Ç¨ sections::thread_list_stream::write()
   √¢‚Äù‚Äö  √¢‚Äù‚Äù√¢‚Äù‚Ç¨ copy_from_process()
   √¢‚Äù‚Äö
   √¢‚Äù≈ì√¢‚Äù‚Ç¨ sections::mappings::write()
   √¢‚Äù‚Äö  √¢‚Äù‚Äù√¢‚Äù‚Ç¨ elf_identifier_for_mapping()
   √¢‚Äù‚Äö     √¢‚Äù‚Äù√¢‚Äù‚Ç¨ copy_from_process()
   √¢‚Äù‚Äö
   √¢‚Äù≈ì√¢‚Äù‚Ç¨ sections::app_memory::write()
   √¢‚Äù‚Äö  √¢‚Äù‚Äù√¢‚Äù‚Ç¨ copy_from_process()
   √¢‚Äù‚Äö
   √¢‚Äù‚Äù√¢‚Äù‚Ç¨ ...
</code></pre></div></div>

<p>Same goes for opening files, which happens in multiple places (two examples of which are shown in <code>init()</code>), so getting <code>FileNotFound</code> without context is going to be equally fun, and so on.</p>



<p>Wrapping errors still sounds like a nice idea, but one layer alone is not going to <del>wrap it</del> cut it.
Going with <code>copy_from_process()</code> as an example, you see a few possibilities:</p>
<ol>
  <li>Wrapping the <code>ptrace</code> error into an <code>CopyFromProcessError</code>, but that gives you nothing (except maybe some context, if you add some)</li>
  <li>With <code>InitError</code>s and <code>DumpingError</code>s that wrap the <code>ptrace</code> errors, you will still not know which section failed and why, but know if it was during <code>init()</code> or not.</li>
</ol>

<p>You might add context to option 2 as well (see below on how), but each section has a variety of reasons why it could fail. Some unique to the section, some shared among a few, some among all of them.</p>

<p>Complex problems sometimes require complex solutions, maybe?</p>

<h2 id="inc-err-ption">Inc <em>Err()</em> ption</h2>

<p>Using <code>thiserror</code> and the fabulous <code>#[from]</code> macro, you quickly define a plethora of errors and wrappers, starting from the deepest, darkest places in your callstack, wrapping your way up:</p>

<div><div><pre><code><span>#[derive(Debug,</span> <span>Error)]</span>
<span>pub</span> <span>enum</span> <span>PtraceDumperError</span> <span>{</span>
    <span>#[error(</span><span>"nix::ptrace() error"</span><span>)]</span>
    <span>PtraceError</span><span>(</span><span>#[from]</span> <span>nix</span><span>::</span><span>Error</span><span>),</span>
    <span>...</span>
<span>}</span>

<span>#[derive(Debug,</span> <span>Error)]</span>
<span>pub</span> <span>enum</span> <span>SectionAppMemoryError</span> <span>{</span>
    <span>#[error(</span><span>"Failed to copy memory from process"</span><span>)]</span>
    <span>CopyFromProcessError</span><span>(</span><span>#[from]</span> <span>PtraceDumperError</span><span>),</span>
    <span>...</span>
<span>}</span>

<span>#[derive(Debug,</span> <span>Error)]</span>
<span>pub</span> <span>enum</span> <span>DumpError</span> <span>{</span>
    <span>#[error(</span><span>"Error during init phase"</span><span>)]</span>
    <span>InitError</span><span>(</span><span>#[from]</span> <span>InitError</span><span>),</span>
    <span>#[error(transparent)]</span>
    <span>PtraceDumperError</span><span>(</span><span>#[from]</span> <span>PtraceDumperError</span><span>),</span>
    <span>#[error(</span><span>"Failed when writing section AppMemory"</span><span>)]</span>
    <span>SectionAppMemoryError</span><span>(</span><span>#[from]</span> <span>SectionAppMemoryError</span><span>),</span>
    <span>...</span>
</code></pre></div></div>

<p>The fun part is: You have to touch very little of your existing code, thanks to the automatic conversion from one error to the other, conveniently provided by <code>#[from]</code>:</p>
<div><div><pre><code><span>- pub fn init(&amp;mut self) -&gt; Result&lt;()&gt; {
</span><span>+ pub fn init(&amp;mut self) -&gt; Result&lt;(), InitError&gt; {
</span>     self.read_auxv()?;
     self.enumerate_threads()?;
     self.enumerate_mappings()?;
     Ok(())
 }
</code></pre></div></div>

<p>or</p>

<div><div><pre><code><span>- pub fn get_stack_info(&amp;self, int_stack_pointer: usize) -&gt; Result&lt;(usize, usize)&gt; {
</span><span>+ pub fn get_stack_info(&amp;self, int_stack_pointer: usize) -&gt; Result&lt;(usize, usize), DumperError&gt; {
</span> // snip

    let mapping = self
        .find_mapping(stack_pointer)
<span>-        .ok_or("No mapping for stack pointer found")?;
</span><span>+        .ok_or(DumperError::NoStackPointerMapping)?;
</span>    let offset = stack_pointer - mapping.start_address;
    let distance_to_end = mapping.size - offset;
  // snip
</code></pre></div></div>

<p>If you run your test binary again, you now get</p>
<div><div><pre><code>Failed when writing section AppMemory
</code></pre></div></div>
<p>which is√¢‚Ç¨¬¶.<em>(Throws a stack of papers from the desk)</em>√¢‚Ç¨¬¶short. Too short, and not that much more helpful, actually. Well, you know which section is failing. Thats good. But where are all the nice error messages you specified in your errors?</p>

<p>Hm, you do only use <code>println!("{}", error);</code>. Maybe <code>{:?}</code> is better?</p>
<div><div><pre><code>SectionAppMemoryError(CopyFromProcessError(PtraceError(Sys(EIO))))
</code></pre></div></div>

<p>Aha! Now you are getting somewhere! Tiny, tiny, painfully <strong>tiny</strong> steps, but you are getting somewhere! No error texts, but at least a chain!</p>

<p>Normal printing doesn√¢‚Ç¨‚Ñ¢t seem to recursively go through all the wrapped errors, but stop at the top most. For this, you need to either go through all the errors yourself by hand, or use a crate that does this for you. There are a number of them that provide this, but <code>anyhow</code> will do (its by the same author as <code>thiserror</code>, so interoperability shouldn√¢‚Ç¨‚Ñ¢t be an issue).</p>

<div><div><pre><code>    <span>println!</span><span>(</span><span>"{:#}"</span><span>,</span> <span>anyhow</span><span>::</span><span>Error</span><span>::</span><span>new</span><span>(</span><span>error</span><span>));</span>
</code></pre></div></div>

<p>aaaaand:</p>

<div><div><pre><code>Failed when writing section AppMemory: Failed to copy memory from process: nix::ptrace() error: EIO: I/O error
</code></pre></div></div>

<p><em>Collects papers from the ‚Ä¶</em></p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://msirringhaus.github.io/Where-everything-went-wrong/">https://msirringhaus.github.io/Where-everything-went-wrong/</a></em></p>]]>
            </description>
            <link>https://msirringhaus.github.io/Where-everything-went-wrong/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26191006</guid>
            <pubDate>Fri, 19 Feb 2021 08:57:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[12 requests per second: A realistic look at Python web frameworks]]>
            </title>
            <description>
<![CDATA[
Score 267 | Comments 105 (<a href="https://news.ycombinator.com/item?id=26188765">thread link</a>) | @gilad
<br/>
February 18, 2021 | https://suade.org/dev/12-requests-per-second-with-python/ | <a href="https://web.archive.org/web/*/https://suade.org/dev/12-requests-per-second-with-python/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

<article>

<figure>
<img src="https://suade.org/content/images/2021/01/The_Tortoise_and_the_Hare_-_Project_Gutenberg_etext_19993-1.jpeg" alt="12 requests per second">
</figure>
<section>
<div>
<blockquote>
<p>A realistic look at Python web frameworks</p>
</blockquote>
<p>If you take a look around the blogosphere at various benchmarks for Python web frameworks, you might start to feel pretty bad about your own setup. Or, alternatively, super-hyped about the possibilities.</p><p>Consider, for instance, the incredible work of the guys at <a href="https://magic.io/blog/uvloop-blazing-fast-python-networking/">magic stack</a>, getting <strong>100,000 requests per second</strong> from <a href="https://github.com/MagicStack/uvloop">uvloop</a> in a single thread. This is on par with compiled language like Go's performance.</p><p>But that benchmark doesn't really cover a fully fleshed out web framework, right? We need a lot more functionality and structure from our frameworks than reading and writing bytes. What about fully fleshed-out web-frameworks in python?</p><p>One such framework is <a href="https://github.com/sanic-org/sanic">Sanic</a>, which again has been shown to have similar performance: <strong>100,000</strong> requests per-second. Or there's <a href="https://vibora.io/">Vibora</a>. Not only does this claim to be a drop-in replacement for <a href="https://github.com/pallets/flask">Flask</a>, but it also has its own templating engine. And it handles <strong>350,000 requests per second</strong>!</p><p>Even more mind-blowing is <a href="https://github.com/squeaky-pl/japronto">Japronto</a> which claims an insane <strong>1.2 million requests per-second</strong> in a single thread ü§Ø trouncing the performance of other languages and frameworks:</p><p><img src="https://raw.githubusercontent.com/squeaky-pl/japronto/master/benchmarks/results.png" alt="https://github.com/squeaky-pl/japronto"></p><p>Recently we've been doing a lot of work improving the performance of our Python APIs. Currently we're running <a href="https://github.com/pallets/flask">Flask</a>, and we initially had a single question: <em>how can we serve more requests from a single worker thread? </em>But looking at these benchmarks had us asking more:</p><ol><li>Can we meaningfully compare them to our setup?</li><li>How realistic are they for a full production application?</li><li>Would we be better using one of these frameworks over Flask?</li></ol><p>In other words, how much should we trust these benchmarks? And to what extent should they influence our choice of technology?</p><p>In order to answer these questions, in this post, I benchmark a realistic Flask application along with it's <a href="https://github.com/sanic-org/sanic">Sanic</a> equivalent. I'm going to guess that most readers come from a background with one of the more "traditional" Python frameworks (<a href="https://github.com/pallets/flask">Flask</a> or <a href="https://www.djangoproject.com/">Django</a>), and it's certainly more relevant to devs here at Suade Labs. For this reason, I run the Flask app in a number of different ways, to see what the best bang for our buck is: how performant can we make our application with (almost) zero changes to the code? Along the way we'll pick up some tips for the original question: <em>how can we serve more requests from a single worker thread?</em></p><p><strong>Sidenote: </strong>if you're new to Python's web frameworks, or its asynchronous libraries, take a look at [1] from the addenda at the bottom of this post for a quick explainer. This post mostly assumes you know these things.</p><h2 id="the-baseline">The baseline</h2><p>First let's run some simple "Hello, World!" benchmarks on our system to get a meaningful baseline for comparison. For reference, the Flask benchmarks on <a href="https://www.techempower.com/benchmarks/#section=data-r18&amp;hw=ph&amp;test=fortune&amp;l=zijzen-f">techempower</a> give 25,000 requests per second.</p><p>Here's our Flask app:</p><pre><code>app = Flask(__name__)

@app.route("/", methods=["GET", "POST"])
def hello():
    if request.method == "GET":
        return "Hello, World!"

    data = request.get_json(force=True)
    try:
        return "Hello, {id}".format(**data)
    except KeyError:
        return "Missing required parameter 'id'", 400</code></pre><p>I ran it under a variety of conditions. First "raw" via <code>python app.py</code>, and then under <a href="https://gunicorn.org/">Gunicorn</a> with a single <code>sync</code> worker via <code>gunicorn -k sync app:app</code> and finally Gunicorn with a single <a href="https://github.com/gevent/gevent">gevent</a> worker via <code>gunicorn -k gevent app:app</code>. In theory Gunicorn should handle concurrency and dropped connections much better than the raw python, and using the gevent worker should allow us to do asynchronous IO without changing our code [2a]. We also ran these benchmarks under <a href="https://www.pypy.org/">PyPy</a>, which in theory should speed up any CPU-bound code without making any changes (if you haven't heard of PyPy see [2b] in the addenda below for a quick explanation and some terminology).</p><p>And what about Sanic? Well, here's the "rewrite" of our app:</p><pre><code>app = Sanic(__name__)

@app.route("/", methods=["GET", "POST"])
async def hello(request):
    if request.method == "GET":
        return text("Hello, World!")

    data = request.json
    try:
        return text("Hello, {id}".format(**data))
    except KeyError:
        raise InvalidUsage("Missing required parameter 'id'")</code></pre><p>And here are the results:</p><figure><img src="https://suade.org/content/images/2021/01/hello_world-3.png" alt="" srcset="https://suade.org/content/images/size/w600/2021/01/hello_world-3.png 600w, https://suade.org/content/images/size/w1000/2021/01/hello_world-3.png 1000w, https://suade.org/content/images/2021/01/hello_world-3.png 1161w" sizes="(min-width: 720px) 720px"></figure><div><p>Some technical details: I used Python 3.7 with the regular CPython interpreter and Python 3.6 with PyPy 7.3.3. At the time of writing, running 3.6 is the latest PyPy interpreter, and their Python 2.7 interpreter is faster in some edge cases, but as Python 2 is <a href="https://www.python.org/doc/sunset-python-2/">officially dead</a>, I don't believe it productive to benchmark. My system details are available in the addenda [3]. I used <a href="https://github.com/wg/wrk">wrk</a> to actually execute the benchmarks.</p><p>I'll break the results down in two parts. First: Sanic dominates, with 23,000 requests a second, although running our Flask app under Guncorn + gevent and PyPy does a pretty good job at keeping up. Second: what's going on with the performance range for our Flask app?</p></div><p>Under CPython, we see that using Gunicorn quadruples the number of Flask requests per second from 1,000 to 4,000 and using a gevent worker adds a mild (sub 10%) speed boost to this. The PyPy results are more impressive. In the raw test, it is churning through 3,000 requests a second; it received the same 4x speed boost from Gunicorn, getting us to 12,000 requests a second; finally with the addition of gevent, it cranks up to 17,000 requests a second, 17x more than the raw CPython version without changing a single line of code.</p><p>I was quite struck by the fact that gevent had such little effect on the CPython process - probably this is because the CPU is maxed out at this point. On the other hand, it seems that PyPy's better speed means it is still spending time waiting on system calls / IO, even under Gunicorn. Adding gevent to the mix means that it switches between concurrent connections, processing them as fast as the CPU will let it.</p><p>To get a real sense of this, I ran the benchmark whilst monitoring CPU usage. Here's a short test against the raw app under PyPy:</p><figure><img src="https://suade.org/content/images/2021/01/sync_cpu_usage.png" alt="" srcset="https://suade.org/content/images/size/w600/2021/01/sync_cpu_usage.png 600w, https://suade.org/content/images/2021/01/sync_cpu_usage.png 919w" sizes="(min-width: 720px) 720px"></figure><p>You can see that the program hops between CPU cores and rarely utilises 100% of a given core. On the other hand, here's part of a much longer test against the Gunicorn gevent worker under PyPy:</p><figure><img src="https://suade.org/content/images/2021/01/gevent_cpu_usage.png" alt="" srcset="https://suade.org/content/images/size/w600/2021/01/gevent_cpu_usage.png 600w, https://suade.org/content/images/2021/01/gevent_cpu_usage.png 900w" sizes="(min-width: 720px) 720px"></figure><p>Now it's evident that there is no switching between CPU cores (the process has become "sticky") and the individual core is being utilised to a far higher degree.</p><p><strong>Key takeaways</strong>: Sanic wins. PyPy is fast. Run your "traditional" app under Gunicorn.</p><h2 id="realistic-benchmarks">Realistic benchmarks</h2><div><p>The benchmark above, while fun, is pretty meaningless for real-world applications. Let's add some more functionality to our app!</p><p>First, we'll allow users to actually store data in a database, which we'll retrieve via an ORM (in our case <a href="https://www.sqlalchemy.org/">SQLAlchemy</a>, the de-facto stand-alone ORM in python). Second, we'll add input-validation to make sure our users get meaningful error messages, and that we're not accepting junk that crashes our app. Finally we'll add a response marshaller to automate the process of converting our database object to JSON.</p></div><p>We'll write a simple book store app, for a publishing house. We have a number of authors each writing zero or more books in several genres. For simplicity, each book has only a single author, but can have multiple genres - for example we could have a book which is in both the "Existential Fiction" and "Beatnik Poetry" categories. We're going to add 1 million authors to our database and roughly 10 million books. [4]</p><p>Our SQLAlchemy models look a little like this:</p>
<pre><code>class Author(db.Model):
    id = db.Column(UUIDType, primary_key=True)
    name = db.Column(db.String, nullable=False)
    ... # snip!

class Book(db.Model):
    author_id = db.Column(
        UUIDType, db.ForeignKey("author.id"), nullable=False, index=True
    )
    author = db.relationship("Author", backref="books")
    ... # snip!
</code></pre>
<p>To marshal these, we use <a href="https://marshmallow.readthedocs.io/en/stable/">Marshmallow</a>, which is a popular Python marshalling library. Here's an example of the Marshmallow model for the Author overview:</p>
<pre><code>class Author(Schema):
    id = fields.Str(dump_only=True)
    name = fields.Str(required=True)
    country_code = EnumField(CountryCodes, required=True)
    email = fields.Str(required=True)
    phone = fields.Str(required=True)
    contact_address = fields.Str(required=True)
    contract_started = fields.DateTime(format="iso")
    contract_finished = fields.DateTime(format="iso")
    contract_value = fields.Integer()
</code></pre>
<p>In our endpoints these are used for validating input and returning results like so:</p>
<pre><code>@bp.route("/author", methods=["GET", "POST"])
def author():
    """View all authors, or create a new one."""

    if request.method == "GET":
        args = validate_get(marshallers.LimitOffsetSchema())
        limit = args["limit"]
        offset = args["offset"]

        authors = Author.query.limit(limit).offset(offset).all()
        return jsonify(marshallers.authors.dump(authors))

    if request.method == "POST":
        author = Author(**validate_post(marshallers.author))

        db.session.add(author)
        db.session.commit()

        return jsonify({"id": author.id})
</code></pre>
<p>The full source code can be viewed in the <a href="https://github.com/olliemath/async_python">GitHub repo</a>. Here, the thing to note is that <code>marshallers.foo</code> is an instance of a <a href="https://marshmallow.readthedocs.io/en/stable/">Marshmallow</a> schema, which can be used both to validate a Foo input, for instance in a POST request, as well as to marshal Foo instances ready for returning as JSON.</p>
<p>In order to actually perform asynchronous database requests, some fancy footwork is required with patching libraries, which depends on which postgres connector you use. SQLAlchemy does not support this out of the box, and in fact its primary developer has a great post arguing that <a href="https://techspot.zzzeek.org/2015/02/15/asynchronous-python-and-databases/">an async ORM is not always a great idea</a>. Juicy technical details in addenda [5], but beware that just using a Gunicorn gevent worker will not necessarily get you what you want.</p><p>PyPy tends to suffer a performance hit when using C-extensions and libraries instead of pure python, conversely CPython should get a performance boost from the C-based libs. To take account of this I tested two different underlying database connectors: both <a href="https://github.com/psycopg/psycopg2">psycopg2</a> and a ‚Ä¶</p></div></section></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://suade.org/dev/12-requests-per-second-with-python/">https://suade.org/dev/12-requests-per-second-with-python/</a></em></p>]]>
            </description>
            <link>https://suade.org/dev/12-requests-per-second-with-python/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26188765</guid>
            <pubDate>Fri, 19 Feb 2021 02:21:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Texas power outage is a nation-wide problem]]>
            </title>
            <description>
<![CDATA[
Score 241 | Comments 395 (<a href="https://news.ycombinator.com/item?id=26186645">thread link</a>) | @gwoplock
<br/>
February 18, 2021 | https://garrettbattaglia.com/post/texas-power/ | <a href="https://web.archive.org/web/*/https://garrettbattaglia.com/post/texas-power/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div>
        <p>Let me preface this with an explanation. Over the last few days I read online people saying that Texas' power outages had been caused by Texas being on its own grid‚Ä¶ deregulation‚Ä¶ Not following national standards‚Ä¶  had Texas been connected to the Eastern Interconnection or the Western Interconnection none of this would have happened. But not one post shows any evidence or requirements that backed up these claims. So, I went looking for proof and instead of finding requirements, I found a nationwide problem with winterization. As an aside I am not an expert in the grid or electricity, I am a software developer, and this is my best interpretation of the requirements I could find.</p>
<p>Let‚Äôs start off with how the electrical grid works in the US. The grid is made up of 3 interconnections: the Eastern Interconnection, the Western Interconnection, and the Texas Interconnect. Each of these interconnections operate in (near) isolation with their own frequency, voltage, and phase. There are several high voltage DC interconnects (HVDC or DC-DC) between them. In each of these interconnections there is at least one grid operators, for example ERCOT in Texas. These grid operators manage the generation and load of their interconnection, acting as almost as an electric clearing house. They are also responsible for keeping voltage and frequency within range and directing distributors (like ONCOR in north Texas) to shed load during Electrical Emergency Alerts (EEA). An important thing to note for later, from the best I can tell the different grid operators in the Eastern Interconnect share power in a ‚Äúnon-firm, as-available basis‚Äù.</p>
<p>What happened in Texas, starting 12:30 AM February 15. The long and short of it is an estimated 34GW of generation went offline in about 2 hours[1]. Looking at ERCOT‚Äôs tweets [2,3,4], generation was starting to have an issue at 00:17:45 and some load needed to be shed so ERCOT issued the first EEA (EEA1). In the February EEA tools document[5] EEA1 can open up around 1.6GW of ‚Äúpeeker‚Äù generation and importation from the Eastern and Western Interconnections. But by 1:12:06 that wasn‚Äôt enough and additional load had to be shed.  A second EEA was issued (EEA2) shedding another 1.6GW. But just a few minutes later the house came crashing down and at 1:25:40 the third EEA (EEA3) was issued. In addition to starting rolling blackouts to shed most of the load it also allowed for other actions to free .1-.2GW of load.</p>
<p>The 34GW of generation lost was from every fuel source used. Most of it was frozen-off natural gas (gas) wells, some of it was frozen wind turbines, solar panels that had snow on them and even a nuclear plant had to go offline due to issues with feedwater pressure sensing issues related to the cold.
What do the North American Electric Reliability Corporation (NERC) standards say about protecting any of these sources? Not much.</p>
<p>Let‚Äôs start by looking at the least complex, wind turbines. On September 12, 2012 NERC published a Lesson Learned document in regards to Texas‚Äôs issues with some of the wind farms freezing in extreme winter weather[6]. According to the document the event that was predicted over a week beforehand brought 4 days of low temperature, high winds and wind chills, ice and snow that limited the generation facility to just 25% of capacity. The facility did have a SOP for icing conditions that was implemented. However, the facility never defined it‚Äôs minimum operating temperature. When lightning knocked out some of the sensing equipment, the turbines had to be stop for safety. The repair crews couldn‚Äôt immediately get to the turbines and they had to sit, this gave the oil a chance to cool and partly freeze. When the turbines were returned to service, they tripped back off due to high oil pressure. Eventually after working with the manufacturer they were able to safely heat the oil and restart the turbines. One of the big lessons from this was to install cold weather packs for wind turbines and watch the oil temperature. You‚Äôd think that would solve future outage, but no, in 2019 in the midwestwind turbines failed due to exceptionally low temperatures, around -21. Again the cold weather package hadn‚Äôt been installed and was one of the root causes of the failure[7].</p>
<p>The nuclear plant‚Äôs sensing problems had happened before too. Although it wasn‚Äôt a nuclear plant, there are several documented cases on NERC‚Äôs website citing cold weather and sensor issues [8,9]. This repeated in Texas (2011) and in the south east (2018)[10].</p>
<p>Let‚Äôs discuss natural gas next. It appears that most of the issues in the problematic natural gas fired facilities was due to low gas supplies. In 2012 NERC warned of the interconnectivity of natural gas and electric[11]. Natural gas coming out of the ground has a naturally high water content. This water can freeze the extraction equipment during sub-freezing weather in improperly winterized wells creating what is know as a freeze-off. businesses, residential customers, and powerplants all run off the same supply, once wells start freezing off the supply dwindles for all. Natural gas companies prioritize residential customers as needed and will cut businesses and powerplants. This obviously creates issues in electrical generation.</p>
<p>In this latest case, much of the gas generation loss was due to under pressure conditions at the generation site. When generation sites detect this kind of fault, they are taken offline for safety. Not only is this what happened this year, but it has happened many, many times before</p>
<p>The most resent case I could find was 2018 in the south east[10]. Starting on January 18, 2018 a large area in the south east US experienced unusually cold weather. This caused 183 generation facilities to go offline or operate with greatly reduced output. At the peak there was nearly 30GW of production lost. This caused several grid operators to issue EEAs and begin rolling blackouts. In the ‚Äúevent area‚Äù 14% of the failures could be directly attributed to the cold weather. And another 30% could be indirectly linked to weather, including mechanical failures know to happen in cold weather and gas supply issues. NERC found that more than 33% of the failed powerplants didn‚Äôt have a winterization plan.</p>
<p>Why didn‚Äôt these plants have a winterization plan? Because it wasn‚Äôt required[10,12].</p>
<p>This wouldn‚Äôt be so bad if this wqs the first time it happened, it wasn‚Äôt even the second time it happened. In 2014 a polar vortex hit the US. bringing temperatures well below normal. During this event 55% of the outages were at gas power plants and in all 90GW of generation was lost[13].</p>
<p>The earliest report I could find was from the 2011 winter event in Texas[14]. A very strong cold front hit Texas (and other parts of the south central US) bringing temperatures below freezing for over 4 days and winds over 30 MPH. Leading up to the event, ERCOT and other grid operators in surrounding areas felt that there wouldn‚Äôt be a need for rolling blackouts. At the beginning of the event ERCOT had 3.1GW of reserve, nearly 1GW over the minimum required. However, over the next 2 days ERCOT lost nearly 30GW of production in 193 generation facilities. ERCOT was able to stabilize the grid with rolling blackouts and the other EEA methods[5]. Other grids suffered problems as well, EPE (El Paso) and SRP (Arizona) lost nearly 1.4GW due to cold weather. Another issue in ERCOT‚Äôs region was nearly 50% of the ‚Äúblack start‚Äù facilities were either down for scheduled maintenance or failed on startup. One of the main causes again was the loss of gas during this blackout period. 14.8 Bcf of natural gas production was lost due to freeze-offs, electrical outages (ironically) and customer curtailments. following the previous equivalent storm in 1989, the PUCT (Public Utility Commission of Texas) issued several recommendations and guidelines for winterization of power plants and gas wells. However, due to the infrequency of these storms the implementation lacked. With many of the same facilities that failed in 1989 also failed in 2011.  My guess is these same sites failed again in 2021. Interestingly the NERC found that it is quite possible that gas production in these unusually cold conditions may be impossible.</p>
<p>What has been done since 2011? Not a whole lot. A request for a new standard was issued to NERC in late 2012, however a few months later it was denied.[15] Also in 2012 NERC put out a set of guidelines for developing a plan for winter weather[16]. In 2017 NERC put out a special reliability report on the relationship between gas and electricity[17]. Finally, after the 2018 event NERC received another standard request that was approved[23], however it won‚Äôt be finalized until late 2021[18,19,20].</p>
<p>From what I can see, ERCOT has more restrictive rules in their Generator Winter Weatherization Workshop than NERC[21]. All generation stations must have plans for emergencies, address abnormal weather, critical failure points, weather design limits, alternative fuels and testing[21,22]. ERCOT reports that there were 80 spot checks done in the 2019/2020 season with 71 being gas plants and 6 being black start gas plants. 23 had to improve and would be reinspected in early 2021 the rest passed.</p>
<p>The issue of extreme cold weather and electrical outages is a national issue that needs to be addressed. However, after repeated failings it hasn‚Äôt really been addressed. Hopefully with the new NERC requirements and the Texas legislature in session progress can be made.</p>
<hr>
<p>[1] <a href="http://www.ercot.com/news/releases/show/225244">http://www.ercot.com/news/releases/show/225244</a><br>
[2] <a href="https://twitter.com/ERCOT_ISO/status/1361197991659503618">https://twitter.com/ERCOT_ISO/status/1361197991659503618</a><br>
[3] <a href="https://twitter.com/ERCOT_ISO/status/1361211669788176384">https://twitter.com/ERCOT_ISO/status/1361211669788176384</a><br>
[4] <a href="https://twitter.com/ERCOT_ISO/status/1361215084010352644">https://twitter.com/ERCOT_ISO/status/1361215084010352644</a><br>
[5] <a href="http://www.ercot.com/content/wcm/lists/219692/EEA_Tools_One_Pager_Winter_2021_2-13-2021.pdf">http://www.ercot.com/content/wcm/lists/219692/EEA_Tools_One_Pager_Winter_2021_2-13-2021.pdf</a><br>
[6] <a href="https://www.nerc.com/pa/rrm/ea/Lessons%20Learned%20Document%20Library/LL20120901_Wind_Farm_Winter_Storm_Issues.pdf">https://www.nerc.com/pa/rrm/ea/Lessons%20Learned%20Document%20Library/LL20120901_Wind_Farm_Winter_Storm_Issues.pdf</a><br>
[7] <a href="https://www.nerc.com/pa/rrm/ea/Lessons%20Learned%20Document%20Library/LL20200601_Unanticipated_Wind_Generation_Cutoffs_during_a_Cold_Weather_Event.pdf">https://w‚Ä¶</a></p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://garrettbattaglia.com/post/texas-power/">https://garrettbattaglia.com/post/texas-power/</a></em></p>]]>
            </description>
            <link>https://garrettbattaglia.com/post/texas-power/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26186645</guid>
            <pubDate>Thu, 18 Feb 2021 22:26:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Gleam 0.14 ‚Äì type-safe language for the Erlang VM]]>
            </title>
            <description>
<![CDATA[
Score 244 | Comments 38 (<a href="https://news.ycombinator.com/item?id=26185690">thread link</a>) | @lpil
<br/>
February 18, 2021 | https://gleam.run/news/gleam-v0.14-released/ | <a href="https://web.archive.org/web/*/https://gleam.run/news/gleam-v0.14-released/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
  <div>
<p>Hot on the heels of Gleam v0.13 comes another release, <a href="https://github.com/gleam-lang/gleam/releases/tag/v0.14.0">Gleam v0.14</a>!
As always, let‚Äôs take a look at some of the highlights.</p>

<h2 id="dialyzer--erlang-typespecs">Dialyzer &amp; Erlang typespecs</h2>

<p>Many dynamically typed BEAM languages support Erlang‚Äôs typespecs, type
annotations that can be analysed with the <a href="https://erlang.org/doc/man/dialyzer.html">Dialyzer</a> tool. While
not as powerful or reliable as Gleam‚Äôs type system it can be a useful tool
for finding problems with your Erlang or Elixir code. Dialyzer doesn‚Äôt
require typespecs but it can work better if they are added to the code.</p>

<p>Starting with this release Gleam will generate typespecs for all functions
and Erlang type definitions for all declared types within a Gleam program,
giving you one extra tool to help you write robust and reliable code when
using Gleam alongside Elixir or Erlang.</p>

<p>For a quick example, here‚Äôs some code in Gleam:</p>

<div><div><pre><code><span>pub</span> <span>type</span> <span>LinkedList</span><span>(</span><span>element</span><span>)</span> <span>{</span>
  <span>Empty</span>
  <span>Node</span><span>(</span><span>element</span><span>,</span> <span>LinkedList</span><span>(</span><span>element</span><span>))</span>
<span>}</span>

<span>pub</span> <span>fn</span> <span>is_empty</span><span>(</span><span>list</span><span>)</span> <span>{</span>
  <span>list</span> <span>==</span> <span>Empty</span>
<span>}</span>

<span>pub</span> <span>fn</span> <span>map</span><span>(</span><span>list</span><span>,</span> <span>fun</span><span>)</span> <span>{</span>
  <span>case</span> <span>list</span> <span>{</span>
    <span>Empty</span> <span>-&gt;</span> <span>Empty</span>
    <span>Node</span><span>(</span><span>i</span><span>,</span> <span>list</span><span>)</span> <span>-&gt;</span> <span>Node</span><span>(</span><span>fun</span><span>(</span><span>i</span><span>),</span> <span>map</span><span>(</span><span>list</span><span>,</span> <span>fun</span><span>))</span>
  <span>}</span>
<span>}</span>
</code></pre></div></div>

<p>And here‚Äôs the Erlang code and typespecs it compiles to:</p>

<div><div><pre><code><span>-</span><span>module</span><span>(</span><span>linked_list</span><span>).</span>
<span>-</span><span>compile</span><span>(</span><span>no_auto_import</span><span>).</span>

<span>-</span><span>export</span><span>([</span><span>is_empty</span><span>/</span><span>1</span><span>,</span> <span>map</span><span>/</span><span>2</span><span>]).</span>
<span>-</span><span>export_type</span><span>([</span><span>linked_list</span><span>/</span><span>1</span><span>]).</span>

<span>-</span><span>type</span> <span>linked_list</span><span>(</span><span>H</span><span>)</span> <span>::</span> <span>empty</span> <span>|</span> <span>{</span><span>node</span><span>,</span> <span>H</span><span>,</span> <span>linked_list</span><span>(</span><span>H</span><span>)}.</span>

<span>-</span><span>spec</span> <span>is_empty</span><span>(</span><span>linked_list</span><span>(</span><span>any</span><span>()))</span> <span>-&gt;</span> <span>boolean</span><span>().</span>
<span>is_empty</span><span>(</span><span>List</span><span>)</span> <span>-&gt;</span>
    <span>List</span> <span>=:=</span> <span>empty</span><span>.</span>

<span>-</span><span>spec</span> <span>map</span><span>(</span><span>linked_list</span><span>(</span><span>R</span><span>),</span> <span>fun</span><span>((</span><span>R</span><span>)</span> <span>-&gt;</span> <span>U</span><span>))</span> <span>-&gt;</span> <span>linked_list</span><span>(</span><span>U</span><span>).</span>
<span>map</span><span>(</span><span>List</span><span>,</span> <span>Fun</span><span>)</span> <span>-&gt;</span>
    <span>case</span> <span>List</span> <span>of</span>
        <span>empty</span> <span>-&gt;</span>
            <span>empty</span><span>;</span>

        <span>{</span><span>node</span><span>,</span> <span>I</span><span>,</span> <span>List</span><span>@</span><span>1</span><span>}</span> <span>-&gt;</span>
            <span>{</span><span>node</span><span>,</span> <span>Fun</span><span>(</span><span>I</span><span>),</span> <span>map</span><span>(</span><span>List</span><span>@</span><span>1</span><span>,</span> <span>Fun</span><span>)}</span>
    <span>end</span><span>.</span>
</code></pre></div></div>

<p>No annotations are required at all in your Gleam code to get full typespec
coverage, Gleam‚Äôs compiler reuses the type information from its powerful type
inference algorithm to determine the correct typespecs.</p>

<p>Thank you <a href="https://gitlab.com/greggreg">Greg</a> for this brilliant new feature!</p>

<h2 id="erlang-escripts">Erlang escripts</h2>

<p>Erlang projects are unusual in that typically instead of having a <code>main</code>
function as the entrypoint of your application you define a tree of actors to
come online and process items of work while your program is running.</p>

<p>This can be a powerful way to write long-lived services that make use of the
runtime‚Äôs fault tolerance features, but it does not lend itself well to
short-lived programs such as command line scripts. It can be confusing to
newcomers from other languages too.</p>

<p>For these short lived programs Erlang <a href="https://erlang.org/doc/man/escript.html">escripts</a> are typically used.
These are lightweight Erlang programs that have a <code>main</code> function as an entrypoint.</p>

<p>To make it easier to use these from Gleam the <code>gleam new</code> command now has an
escript template that can be used to create an escript project without any
further configuration required.</p>

<div><div><pre><code>gleam new my_script <span>--template</span> escript
</code></pre></div></div>

<p>A world class developer experience is a key goal of the Gleam project.
Further tooling improvements are right around the corner!</p>

<h2 id="night-mode">Night mode</h2>

<p>Gleam has the ability to render <a href="https://hexdocs.pm/gleam_stdlib/">HTML documentation</a> 
for your code, ready to upload to Hexdocs.</p>

<p>Thanks to <a href="https://github.com/tynanbe">Tynan Beatty</a> the documentation is
looking better than ever! There‚Äôs too many improvements to list but the big
one is they now have a night mode! If you‚Äôre a night owl like me I‚Äôm sure you
will enjoy the lower contrast dark tones when doing some late evening coding.</p>

<p><img src="https://gleam.run/images/news/gleam-v0.14-released/night-mode.png" alt="A screenshot of Gleam's rendered docs showing a beautiful dark theme"></p>

<h2 id="better-errors-again">Better errors, again</h2>

<p>At the risk of sounding like a broken record Gleam‚Äôs error messages have been
improved yet again. Here‚Äôs an example of one of the improvements:</p>

<p>Before:</p>

<div><div><pre><code>error: Syntax error
    ‚îå‚îÄ /src/thing.gleam:115:18
    ‚îÇ
115 ‚îÇ pub fn overlappedBy(compare, a, b) -&gt; Bool {
    ‚îÇ                  ^^ I was not expecting this.

Expected one of: "("
</code></pre></div></div>

<p>Now:</p>

<div><div><pre><code>error: Syntax error
    ‚îå‚îÄ /src/thing.gleam:115:18
    ‚îÇ
115 ‚îÇ pub fn overlappedBy(compare, a, b) -&gt; Bool {
    ‚îÇ                  ^^ This is not a valid name.

Hint: Names start with a lowercase letter and contain a-z, 0-9, or _.
Try: overlapped_by
</code></pre></div></div>

<p>Thank you to <a href="https://github.com/samontea">Samuel Mercier</a> and <a href="https://github.com/pd-andy">Andy
Thompson</a> for these.</p>

<h2 id="static-bit-string-validation">Static bit string validation</h2>

<p>Bit string syntax is a feature that Gleam inherits from Erlang. It provides a
way to declartively and concisely construct and manipulate raw bits of data
through literals and pattern matching.</p>

<p>With this Gleam release we apply further static analysis to bit string
literals and patterns used in Gleam programs to catch invalid or incorrect
code.</p>

<p>Here‚Äôs an example of one of the errors that may be reported:</p>

<div><div><pre><code>error: Syntax error
  ‚îå‚îÄ /Users/a/parser_test/src/a.gleam:2:20
  ‚îÇ
2 ‚îÇ   &lt;&lt;1:size(1)-unit(0)&gt;&gt;
  ‚îÇ                    ^ This is not a valid BitString unit value.

Hint: unit must be an integer literal &gt;= 1 and &lt;= 256
See: https://gleam.run/book/tour/bit-strings
</code></pre></div></div>

<p>Thank you <a href="https://gitlab.com/greggreg">Greg</a> for this bit string safety net.</p>

<h2 id="docker-images">Docker images</h2>

<p>Up until now <a href="https://github.com/CrowdHailer">Peter Saxton</a> has been very kindly
building Gleam docker images for use in <a href="https://sendmemo.app/">Memo</a> and the
wider community.</p>

<p>With this release he has ported his build automation over to the Gleam repo
so we have automation creation of OCI/Docker images built and published
automatically with each release.</p>

<p>We are building these variants:</p>

<ul>
  <li><code>gleam-erlang</code>: Gleam and the Erlang tooling on Ubuntu Linux</li>
  <li><code>gleam-erlang-slim</code>: Gleam and the Erlang tooling on slim Debian Linux</li>
  <li><code>gleam-erlang-alpine</code>: Gleam and the Erlang tooling on Alpine Linux</li>
  <li><code>gleam-elixir</code>: Gleam and the Elixir tooling on Ubuntu Linux</li>
  <li><code>gleam-elixir-slim</code>: Gleam and the Elixir tooling on slim Debian Linux</li>
  <li><code>gleam-elixir-alpine</code>: Gleam and the Elixir tooling on Alpine Linux</li>
</ul>

<p>For all the images see the <a href="https://github.com/orgs/gleam-lang/packages/container/package/gleam">Gleam image registry</a>. Thanks Peter!</p>

<h2 id="other-stuff">Other stuff</h2>

<p>These are just some of the highlights, but there‚Äôs plenty more improvements
made to the compiler and the standard library since the last release. For all
the details check out the changelog files:</p>

<ul>
  <li><a href="https://github.com/gleam-lang/gleam/blob/main/CHANGELOG.md">Gleam‚Äôs changelog</a></li>
  <li><a href="https://github.com/gleam-lang/stdlib/blob/main/CHANGELOG.md">Gleam stdlib‚Äôs changelog</a></li>
</ul>

<h2 id="discord-chat">Discord chat</h2>

<p>It‚Äôs time to plug the Gleam Discord server again! The community continues to
grow and it would be great to have you there too, so please click on the
button below.</p>

<center>
  <a href="https://discord.gg/Fm8Pwmy"><img src="https://img.shields.io/discord/768594524158427167?color=blue" alt="Discord chat"></a>
</center>

<h2 id="try-it-out">Try it out</h2>

<p>If you want to try out the new version of Gleam head over to the <a href="https://gleam.run/getting-started/">getting started
page</a>. I‚Äôd love to hear how you find it and get your feedback so
Gleam can continue to improve.</p>

<p>Want to view some existing Gleam projects? Head on over to the
<a href="https://github.com/gleam-lang/awesome-gleam">awesome-gleam</a> list. Looking for something to build in
Gleam? Check out <a href="https://github.com/gleam-lang/suggestions/issues">the suggestions tracker</a>.</p>

<h2 id="supporting-gleam">Supporting Gleam</h2>

<p>If you would like to help make strongly typed programming on the Erlang
virtual machine a production-ready reality please consider <strong><a href="https://github.com/sponsors/lpil">sponsoring
Gleam</a></strong> via the GitHub Sponsors program.</p>

<p>‚≠ê Or alternatively give us a star on <a href="https://github.com/gleam-lang/gleam">GitHub</a>! ‚≠ê</p>

<p>This release would not have been possible without the support of all the
people who have <a href="https://github.com/sponsors/lpil">sponsored</a> and contributed
to it, so a huge thank you to them.</p>

<ul>
  <li><a href="https://github.com/adamnbowen">Adam Bowen</a></li>
  <li><a href="https://github.com/amokan">Adam Mokan</a></li>
  <li><a href="https://github.com/aditya7iyengar">Adi Iyengar</a></li>
  <li><a href="https://github.com/scripttease">Al Dee</a></li>
  <li><a href="https://github.com/mudriyjo">Alexander Babin</a></li>
  <li><a href="https://github.com/farhadi">Ali Farhadi</a></li>
  <li><a href="https://github.com/pd-andy">Andy Thompson</a></li>
  <li><a href="https://github.com/bees">Arian Daneshvar</a></li>
  <li><a href="https://github.com/arnodirlam">Arno Dirlam</a></li>
  <li><a href="https://github.com/benmyles">Ben Myles</a></li>
  <li><a href="https://github.com/nono">Bruno Michel</a></li>
  <li><a href="https://github.com/brightly-salty">Caden Haustein</a></li>
  <li><a href="https://github.com/choonkeat">Chew Choon Keat</a></li>
  <li><a href="https://github.com/chrislloyd">Chris Lloyd</a></li>
  <li><a href="https://github.com/worldofchris">Chris Young</a></li>
  <li><a href="https://github.com/tlvenn">Christian Meunier</a></li>
  <li><a href="https://github.com/clangley">clangley</a></li>
  <li><a href="https://github.com/cleverbunny">Clever Bunny LTD</a></li>
  <li><a href="https://github.com/codec-abc">codec-abc</a></li>
  <li><a href="https://github.com/colelawrence">Cole Lawrence</a></li>
  <li><a href="https://github.com/connorlay">Connor Lay (Clay)</a></li>
  <li><a href="https://github.com/cschembor3">Connor Schembor</a></li>
  <li><a href="https://github.com/unthought">Dan Mueller</a></li>
  <li><a href="https://github.com/davydog187">Dave Lucia</a></li>
  <li><a href="https://github.com/rawkode">David McKay</a></li>
  <li><a href="https://github.com/davidpdrsn">David Pedersen</a></li>
  <li><a href="https://github.com/dangdennis">Dennis Dang</a></li>
  <li><a href="https://github.com/lostbean">Edgar Gomes</a></li>
  <li><a href="https://github.com/ericmj">Eric Meadows-J√∂nsson</a></li>
  <li><a href="https://github.com/eterps">Erik Terpstra</a></li>
  <li><a href="https://github.com/floriank">Florian Kraft</a></li>
  <li><a href="https://github.com/itsgreggreg">greggreg</a></li>
  <li><a href="https://github.com/ggpasqualino">Guilherme Pasqualino</a></li>
  <li><a href="https://github.com/hendi">Hendrik Richter</a></li>
  <li><a href="https://github.com/hhandoko">Herdy Handoko</a></li>
  <li><a href="https://github.com/human154">human154</a></li>
  <li><a href="https://github.com/Ian-GL">Ian Gonz√°lez</a></li>
  <li><a href="https://github.com/igagen">Ingmar Gagen</a></li>
  <li><a href="https://github.com/ivarvong">Ivar Vong</a></li>
  <li><a href="https://github.com/gampleman">Jakub Hampl</a></li>
  <li><a href="https://github.com/jamesmacaulay">James MacAulay</a></li>
  <li><a href="https://github.com/janpieper">Jan Pieper</a></li>
  <li><a href="https://github.com/jechol">Jechol Lee</a></li>
  <li><a href="https://github.com/jeffkreeftmeijer">Jeff Kreeftmeijer</a></li>
  <li><a href="https://github.com/jiangplus">jiangplus</a></li>
  <li><a href="https://github.com/joecorkerton">Joe Corkerton</a></li>
  <li><a href="https://github.com/Jwsonic">John Palgut</a></li>
  <li><a href="https://github.com/josevalim">Jos√© Valim</a></li>
  <li><a href="https://github.com/jveiga">Jo√£o Veiga</a></li>
  <li><a href="https://github.com/jmn">Jussi Norlund</a></li>
  <li><a href="https://github.com/kapp-technology">Kapp Technology</a></li>
  <li><a href="https://github.com/kodeFant">Lars Lillo Ulvestad</a></li>
  <li><a href="https://github.com/lawik">Lars Wikman</a></li>
  <li><a href="https://github.com/leandrocp">Leandro Cesquini Pereira</a></li>
  <li><a href="https://github.com/malcolmseyd">Malcolm Seyd</a></li>
  <li><a href="https://github.com/mario-mazo">mario</a></li>
  <li><a href="https://github.com/mvellandi">Mario Vellandi</a></li>
  <li><a href="https://github.com/markmark206">Mark Markaryan</a></li>
  <li><a href="https://github.com/markusfeyh">Markus</a></li>
  <li><a href="https://github.com/derhechi">Markus Hechenberger</a></li>
  <li><a href="https://github.com/MattCheely">Matthew Cheely</a></li>
  <li><a href="https://github.com/bausano">Michael Bausano</a></li>
  <li><a href="https://github.com/michaeljones">Michael Jones</a></li>
  <li><a href="https://github.com/michallepicki">Micha≈Ç ≈Åƒôpicki</a></li>
  <li><a href="https://github.com/mroach">Mike Roach</a></li>
  <li><a href="https://github.com/slashmili">Milad</a></li>
  <li><a href="https://github.com/ndreynolds">Nick Reynolds</a></li>
  <li><a href="http://www.ninefx.com/">NineFX</a></li>
  <li><a href="https://github.com/jraregris">Oddmund Str√∏mme</a></li>
  <li><a href="https://github.com/sorentwo">Parker Selbert</a></li>
  <li><a href="https://github.com/phiat">Patrick Ryan</a></li>
  <li><a href="https://github.com/PeteJodo">Pete Jodo</a></li>
  <li><a href="https://github.com/CrowdHailer">Peter Saxton</a></li>
  <li><a href="https://github.com/praveenperera">Praveen Perera</a></li>
  <li><a href="https://github.com/qingliangcn">qingliangcn</a></li>
  <li><a href="https://github.com/happysalada">Raphael Megzari</a></li>
  <li><a href="https://github.com/chouzar">Ra√∫l  Humberto Chouza Delgado</a></li>
  <li><a href="https://github.com/redmar">Redmar Kerkhoff</a></li>
  <li><a href="https://github.com/reneklacan">Ren√© Klaƒçan</a></li>
  <li><a href="https://github.com/romatthe">Robin Mattheussen</a></li>
  <li><a href="https://github.com/rvcas">rvcas</a></li>
  <li><a href="https://github.com/samaaron">Sam Aaron</a></li>
  <li><a href="https://github.com/samontea">samontea</a></li>
  <li><a href="https://github.com/mrgleam">Santi</a></li>
  <li><a href="https://github.com/sascha-wolf">Sascha Wolf</a></li>
  <li><a href="https://github.com/sasa1977">Sa≈°a Juriƒá√ß</a></li>
  <li><a href="https://github.com/scottwey">Scott Wey</a></li>
  <li><a href="https://github.com/seanjensengrey">Sean Jensen-Grey</a></li>
  <li><a href="https://github.com/sporto">Sebastian</a></li>
  <li><a href="https://github.com/shanesveller">Shane Sveller</a></li>
  <li><a href="https://github.com/shritesh">Shritesh Bhattarai</a></li>
  <li><a href="https://github.com/simonewebdesign">Simone Vittori</a></li>
  <li><a href="https://github.com/syukronrm">Syukron Rifail M</a></li>
  <li><a href="https://github.com/terkiterje">Terje Bakken</a></li>
  <li><a href="https://github.com/timbuchwaldt">Tim Buchwaldt</a></li>
  <li><a href="https://github.com/tomekowal">Tomasz Kowal</a></li>
  <li><a href="https://github.com/thara">Tomochika Hara</a></li>
  <li><a href="https://github.com/topherhunt">Topher Hunt</a></li>
  <li><a href="https://github.com/tsloughter">Tristan Sloughter</a></li>
  <li><a href="https://github.com/twilco">Tyler Wilcock</a></li>
  <li><a href="https://github.com/tynanbe">tynanbe</a></li>
  <li><a href="https://github.com/wojtekmach">Wojtek Mach</a></li>
</ul>

<p>Thanks for reading! Have fun! üíú</p>

</div>

</article></div>]]>
            </description>
            <link>https://gleam.run/news/gleam-v0.14-released/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26185690</guid>
            <pubDate>Thu, 18 Feb 2021 21:16:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Series A to Revolutionize Computing]]>
            </title>
            <description>
<![CDATA[
Score 22 | Comments 5 (<a href="https://news.ycombinator.com/item?id=26184594">thread link</a>) | @tosh
<br/>
February 18, 2021 | https://blog.repl.it/seriesa | <a href="https://web.archive.org/web/*/https://blog.repl.it/seriesa">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		<p>Our mission is to give everyone in the world <strong>computer superpowers</strong>. We build powerful yet approachable tools &amp; platforms for developers, students, and educators.</p>
<p>We see a new generation of hackers and entrepreneurs rising to seize the power of computers and the internet to create software that empowers them and their communities. They refuse to be programmed by the software priesthood that wants them to endlessly consume ads. Instead, they build a more free society where computers work for and under human users, not the other way around. The world we're describing is coming, and we exist to accelerate the shift.</p>
<p><img src="https://repl.art/replit.png" alt="art"></p>
<p>Replit is a multiplayer computing environment that makes it <a href="https://blog.replit.com/internet-of-fun">fun</a> to learn how to code, build, and <a href="https://repl.it/talk/share">share apps</a> with other people. You can create a cloud-powered computer in milliseconds -- we call them "repls" -- and you can create as many of them as you'd like, all for free. Repls come with storage for your code and files, a <a href="https://blog.repl.it/database">database</a> for your data, and a <a href="https://repl.it/site/multiplayer">multiplayer editor</a> &amp; console to code with your friends. For <a href="https://repl.it/pricing">$7/month</a>, you'll get more powerful machines and, with one-click, make them <a href="https://blog.repl.it/alwayson">run forever</a>.</p>
<p><img src="https://blog.repl.it/images/database/database1.gif" alt="db"></p>
<p>When you invite a friend to your repl, you can see them in your editor and talk to them <a href="https://blog.repl.it/annotations-for-education">right in your code</a>. You can make <a href="https://docs.repl.it/repls/http-servers">web</a>, <a href="https://blog.repl.it/native-graphics-love">desktop</a>, and even command-line apps. Replit takes care of the entire process of <a href="https://docs.repl.it/repls/web-hosting">publishing and hosting apps</a> so you can focus on your ideas.</p>
<p><img src="https://venturebeat.com/wp-content/uploads/2021/02/Live-Code-Editing.gif?resize=800%2C450&amp;strip=all" alt="multiplayer"></p>
<p>When you've built something you want to share, you can share the <a href="https://blog.replit.com/spotlight">repl URL</a>, and your users can play with your app, react to it, comment on it, and even fork and remix it. Replit gives you a profile to keep and showcase all your apps and repls. You can make <a href="https://repl.it/site/teams">shared team profiles</a> for your class, friends, or company to collaborate on repls.</p>
<p><img src="https://blog.repl.it/images/spotlight/ios-demo.gif" alt="share"></p>
<p>Because you can make a repl in milliseconds, Replit makes it fun and safe to experiment with ideas. Learning comes naturally as a side effect of playing in the Replit ecosystem.</p>
<p>Millions of people have learned how to code with Replit and built great apps with thousands of happy users. Some have even built businesses and become rich &amp; famous.</p>
<p>Replit's design principles:</p>
<ul>
<li><p><strong>Learnable yet scalable interfaces</strong>: Interfaces today present the same UI to vastly different users, from children to adults, from novices to experts. Our mission demands that we make computing environments more accessible to novices while making it possible to transition to more powerful interfaces. Replit starts with a simple editor and console, which gets learners very far. The UI, however, is adaptable and presents different faces to different users and use-cases.</p>
</li>
<li><p><strong>Infrastructure as legos</strong>: A core part of commanding computer power is to be able to build for the modern internet-connected world. Despite progress in cloud computing, infrastructure remains inaccessible to novices, hobbyists, and educators. We change this by designing simple and scalable components, like cloud-hosted servers accessible right from the repl, storage, databases, etc., that require little configuration and maintenance by the programmer. Coders can then mix and match components to create endless possibilities.</p>
</li>
<li><p><strong>People-centric technology</strong>: It's more exciting and fun to create and learn with other people. The future demands that computers and the internet have human interconnectedness as a core primitive. From our multiplayer computing protocol to our community spaces for sharing software, we build support for human beings, and we put collaboration right at the heart of our technology.</p>
</li>
</ul>
<h2 id="series-a">Series A</h2>
<p>As a team, we've always thought about the long-term, and we've grown Replit responsibly. We have so much conviction in our mission and our plan that we're willing to take our time. </p>
<p>Last year, with rapid growth in all aspects of our business, we felt it was a good time to raise a sizeable round to make faster progress our mission. We raised <a href="https://venturebeat.com/2021/02/18/replit-raises-20-million-for-collaborative-browser-based-coding/">$20M in Series A</a> financing led by <a href="https://acapital.com/">A.Capital</a> with strong participation from our seed investors: Andreessen Horowitz, Bloomberg Beta, Y Combinator, and Reach Capital. </p>
<p>Since then, thanks to the new capital and to <a href="https://amasad.me/moad">Engelbartian Bootstrapping</a>, we've accelerated feature development, and there's so much more on the horizon: extra resources for more complex projects, support for any language or package, further dev ops simplifications for novices and pros, business collaboration features, improvements to <a href="https://repl.it/teams-for-education">teacher workflows</a>, high quality content, a game development library, and more breakthroughs in collaborative coding. We're excited to see all the amazing things you build with the tools we provide!</p>
<p>Finally, we're hiring for multiple roles and want to bring on people who share our vision and passion. If you're interested in making computing more accessible while working with a creative and hardworking team building fantastic technology, <a href="https://repl.it/careers">join us</a>!</p>

	</div></div>]]>
            </description>
            <link>https://blog.repl.it/seriesa</link>
            <guid isPermaLink="false">hacker-news-small-sites-26184594</guid>
            <pubDate>Thu, 18 Feb 2021 19:53:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Scala 3.0.0-RC1 ‚Äì first release candidate is here]]>
            </title>
            <description>
<![CDATA[
Score 21 | Comments 4 (<a href="https://news.ycombinator.com/item?id=26184110">thread link</a>) | @tmfi
<br/>
February 18, 2021 | https://dotty.epfl.ch/blog/2021/02/17/scala3-rc1.html | <a href="https://web.archive.org/web/*/https://dotty.epfl.ch/blog/2021/02/17/scala3-rc1.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content-wrapper"> 
   <main> 
    <header> 
      
      
    </header> 
    <p>Greetings from the Scala 3 team! We are delighted to announce the first release candidate of the stable version of Scala 3 ‚Äì Scala 3.0.0-RC1.</p> 
    <p>This release brings some last-minute polishings, clean-ups and changes before the big release. There were a few language changes to improve the user experience, as well as the polishings of the metaprogramming framework. We have also worked on the issues that had to be fixed before the stable release.</p> 
    <p>Overall, more than <a href="https://github.com/lampepfl/dotty/pulls?q=is%3Apr+is%3Aclosed+closed%3A%3E2020-12-02+sort%3Acomments-desc">400 PRs</a> were merged after the M3 release and until today! Read more below!</p> <!--more--> 
     
    <p>Type parameters on extensions can now be combined with type parameters on the methods themselves. E.g.:</p> 
    <pre><code>List(1, 2, 3).second[Int]
extension [A](xs: List[A])
   def sumBy[B](f: A =&gt; B)(using Numeric[B]): B = ...
</code></pre> 
    <p>Type arguments matching method type parameters are passed as usual:</p> 
    <pre><code>List("a", "bb", "ccc").sumBy[Int](_.length)
</code></pre> 
    <p>By contrast, type arguments matching type parameters following <code>extension</code> can be passed only if the method is referenced as a non-extension method:</p> 
    <pre><code>sumBy[String](List("a", "bb", "ccc"))(_.length)
</code></pre> 
    <p>Or, when passing both type arguments:</p> 
    <pre><code>sumBy[String](List("a", "bb", "ccc"))[Int](_.length)
</code></pre> 
    <p>For discussion, see <a href="https://github.com/lampepfl/dotty/pull/10940">PR #10940</a>. For more information about the extension methods, see <a href="https://dotty.epfl.ch/docs/reference/contextual/extension-methods.html">documentation</a>.</p> 
     
    <p>The following are the changes to the <code>import</code> syntax made in this release.</p> 
    <p>Wildcard import <code>_</code> is replaced by <code>*</code>. The motivation is that the majority of other languages use <code>*</code>. For example:</p> 
    <pre><code>import scala.annotation.*  // imports everything in the annotation package
</code></pre> 
    <p>Renaming operator <code>=&gt;</code> is replaced by a soft keyword <code>as</code>. <code>as</code> is also allowed outside braces. For example:</p> 
    <pre><code>import scala.collection.mutable as mut
import NumPy as np
</code></pre> 
    <p>For the details and discussion, see <a href="https://github.com/lampepfl/dotty/pull/11244">PR #11244</a>. Read more about this change in the <a href="https://dotty.epfl.ch/docs/reference/changed-features/imports.html">documentation</a>.</p> 
     
    <p><a href="https://github.com/lampepfl/dotty/pull/11240">PR #11240</a> changed the syntax of vararg splices in patterns and function arguments. The new syntax uses a postfix <code>*</code>, instead of <code>: _*</code>, analogously to how a vararg parameter is declared.</p> 
     
    <p>An obscure use of <code>_</code> occurs in var definitions:</p> 
    <pre><code>var x: T = _
</code></pre> 
    <p>It defines a concrete variable x without an initial value, or rather the default initial value that the JVM assigns to object fields. It can only be used in a class or object, not to initialize a local variable.</p> 
    <p>We came up with an arguably better way to express this idiom: the special <code>uninitialized</code> value in the <code>scala.compiletime</code> object. To get an uninitialized field, you now write:</p> 
    <pre><code>import scala.compiletime.uninitialized

var x: A = uninitialized
</code></pre> 
    <p>This way expresses the intent of the idiom in a more verbose and easy to read way than simply writing an underscore.</p> 
    <p>For discussion, see <a href="https://github.com/lampepfl/dotty/pull/11231">PR #11231</a>, and the <a href="https://dotty.epfl.ch/docs/reference/dropped-features/wildcard-init.html">documentation</a> is available on our website.</p> 
     
    <p>Starting from RC1, we no longer generate a function parent for companions of case classes. Which means, for example, that given <code>case class Foo(x: Int)</code>, you won't be able to use <code>Foo</code> in a position where a function is expected:</p> 
    <pre><code>case class Foo(x: Int)
def f(g: Int =&gt; Foo) = g(10)

f(Foo)
</code></pre> 
    <p>Results in:</p> 
    <pre><code>1 |f(Foo)
  |  ^^^
  |The method `apply` is inserted. The auto insertion will be deprecated, please write `Foo.apply` explicitly.
</code></pre> 
    <p>As the warning suggests, now you should write <code>Foo.apply</code> instead of <code>Foo</code>. See <a href="https://github.com/lampepfl/dotty/issues/6190">Issue #6190</a> and <a href="https://github.com/lampepfl/dotty/pull/7207">PR #7207</a> for discussion.</p> 
     
    <p>We have settled on using the well-known <code>scaladoc</code> as a name for the documentation tool for Scala 3 (known previously as <code>scala3doc</code>).. The obsolete <code>dotty-doc</code> (or <code>scala3-doc</code>) is removed in RC1. We have also removed all the Kotlin dependencies (Dokka, etc.) from scaladoc. For details, see <a href="https://github.com/lampepfl/dotty/pull/11349">PR #11349</a>. To read more about <code>scaladoc</code>, see <a href="https://dotty.epfl.ch/docs/usage/scaladoc/index.html">documentation</a></p> 
     
    <p><a href="https://github.com/lampepfl/dotty/pull/11355">PR #11355</a> changes the <code>-source</code> specifier for the Scala version(s) after 3.0 from <code>3.1</code> to <code>future</code>. I.e. it is now <code>-source future</code> and <code>-source future-migration</code> instead of <code>-source 3.1</code> and <code>-source 3.1-migration</code>. Language imports are changed analogously. The reason for the change is that we want to keep the possibility open to ship a <code>3.1</code> version that does not yet contain all the changes enabled under <code>-source future</code>.</p> 
     
    <ul> 
     <li>Warn when matching against an opaque type <a href="https://github.com/lampepfl/dotty/pull/10664">#10664</a></li> 
     <li>Fix <a href="https://github.com/lampepfl/dotty/issues/8634">#8634</a>: Support -release option <a href="https://github.com/lampepfl/dotty/pull/10746">#10746</a> ‚Äì the same way Scala 2 does. This setting allows you to specify a version of the Java platform (8, 9 etc) and compile the code with classes specific to the that Java platform, and emit the bytecode for that version.</li> 
    </ul> 
     
    <p>A lot of work has been done on the metaprogramming side of things. Mostly we are cleaning up and polishing the API to prepare it for the stable release. The following are the important metaprogramming changes that took place:</p> 
    <ul> 
     <li>Add <code>scala.quoted.Expr.unapply</code> as dual of <code>Expr.apply</code> <a href="https://github.com/lampepfl/dotty/pull/10580">#10580</a></li> 
     <li>Remove <code>Expr.StringContext.unapply</code> <a href="https://github.com/lampepfl/dotty/pull/10675">#10675</a></li> 
     <li>Add reflect <code>MatchCase</code> <code>TypeRepr</code> <a href="https://github.com/lampepfl/dotty/pull/10735">#10735</a></li> 
     <li>Rename <code>scala.quoted.staging.{Toolbox =&gt; Compiler}</code> <a href="https://github.com/lampepfl/dotty/pull/11129">#11129</a></li> 
     <li>Fix <a href="https://github.com/lampepfl/dotty/issues/10863">#10863</a>: Make show <code>AnyKind</code>ed <a href="https://github.com/lampepfl/dotty/pull/10988">#10988</a></li> 
     <li>Add ParamClause to allow multiple type param clauses <a href="https://github.com/lampepfl/dotty/pull/11074">#11074</a></li> 
     <li>Rework reflect Symbol fields API <a href="https://github.com/lampepfl/dotty/pull/10705">#10705</a></li> 
     <li>Rename <code>Liftable</code> to <code>ToExpr</code> and <code>Unliftable</code> to <code>FromExpr</code> <a href="https://github.com/lampepfl/dotty/pull/10618">#10618</a></li> 
     <li>Expand non-transparent macros after Typer <a href="https://github.com/lampepfl/dotty/pull/9984">#9984</a></li> 
     <li>Rework TastyInspector API to allow inspection of all files <a href="https://github.com/lampepfl/dotty/pull/10792">#10792</a></li> 
     <li>Allow leading context parameters in extension methods <a href="https://github.com/lampepfl/dotty/pull/10940">#10940</a></li> 
     <li>Rename <code>Not</code> to <code>NotGiven</code> to make its purpose clearer <a href="https://github.com/lampepfl/dotty/pull/10720">#10720</a></li> 
     <li>Fix <a href="https://github.com/lampepfl/dotty/issues/10709">#10709</a>: Add missing level check before inlining <a href="https://github.com/lampepfl/dotty/pull/10781">#10781</a></li> 
    </ul> 
     
    <p>If you have questions or any sort of feedback, feel free to send us a message on our <a href="https://gitter.im/lampepfl/dotty">Gitter channel</a>. If you encounter a bug, please <a href="https://github.com/lampepfl/dotty/issues/new">open an issue on GitHub</a>.</p> 
    <h2><a href="#contributors" id="contributors"></a>Contributors</h2> 
    <p>Thank you to all the contributors who made this release possible üéâ</p> 
    <p>According to <code>git shortlog -sn --no-merges 3.0.0-M3..3.0.0-RC1</code> these are:</p> 
    <pre><code>   183  Martin Odersky
   138  Nicolas Stucki
    36  Krzysztof Romanowski
    25  Filip Zyba≈Ça
    25  Liu Fengyun
    24  Lan, Jian
    22  Jamie Thompson
    19  Tom Grigg
    17  Andrzej Ratajczak
    16  St√©phane Micheloud
    15  Guillaume Martres
    11  Pawe≈Ç Marks
     9  Phil
     6  Aleksander Boruch-Gruszecki
     6  Jonathan Brachth√§user
     6  Natsu Kagami
     6  odersky
     4  Jasper Moeys
     4  Adrien Piquerez
     3  S√©bastien Doeraene
     3  Micha≈Ç Pa≈Çka
     3  Albert Chen
     2  Alexandre Archambault
     2  Som Snytt
     2  kenji yoshida
     2  Luc Henninger
     2  Ayush
     2  Raphael Jolly
     2  Anatolii Kmetiuk
     2  Olivier Blanvillain
     2  changvvb
     1  ysthakur
     1  Ang Hao Yang
     1  Ang9876
     1  AngAng
     1  August Nagro
     1  Ciara O'Brien
     1  Dale Wijnand
     1  Florian Cassayre
     1  Florian Schmaus
     1  Iltotore
     1  Jason Zaugg
     1  Julien Richard-Foy
     1  Katrix
     1  Master-Killer
     1  Michael Pilquist
     1  Mikael Blomstrand
     1  Mike Samuel
     1  Philippus
     1  Philippus Baalman
     1  Rick M
     1  Stephane MICHELOUD
     1  Timur Abishev
     1  Tomas
     1  ansvonwa
     1  ayush
     1  costa100
     1  iroha168
     1  noti0na1
     1  riiswa
     1  tanishiking
</code></pre> 
    <p>If you want to get your hands dirty and contribute to Scala 3, now is a good time to get involved! Head to our <a href="https://dotty.epfl.ch/docs/contributing/getting-started.html">Getting Started page for new contributors</a>, and have a look at some of the <a href="https://github.com/lampepfl/dotty/issues?q=is%3Aissue+is%3Aopen+label%3Aexp%3Anovice">good first issues</a>. They make perfect entry points into hacking on the compiler.</p> 
    <p>We are looking forward to having you join the team of contributors.</p> 
    <hr> 
    <p><img id="author-img" src="https://dotty.epfl.ch/images/anatolii.png"> <span id="author-signature"> Anatolii Kmetiuk </span> 
    </p> 
   </main> 
  </div></div>]]>
            </description>
            <link>https://dotty.epfl.ch/blog/2021/02/17/scala3-rc1.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26184110</guid>
            <pubDate>Thu, 18 Feb 2021 19:09:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[GPT-3, Esq? Evaluating AI Legal Summaries [pdf]]]>
            </title>
            <description>
<![CDATA[
Score 49 | Comments 37 (<a href="https://news.ycombinator.com/item?id=26183114">thread link</a>) | @gavelin
<br/>
February 18, 2021 | http://www.davidvictorrodriguez.com/uploads/2/6/4/2/26420847/gpt-3_esq_-_evaluating_ai_legal_summaries.pdf | <a href="https://web.archive.org/web/*/http://www.davidvictorrodriguez.com/uploads/2/6/4/2/26420847/gpt-3_esq_-_evaluating_ai_legal_summaries.pdf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>http://www.davidvictorrodriguez.com/uploads/2/6/4/2/26420847/gpt-3_esq_-_evaluating_ai_legal_summaries.pdf</link>
            <guid isPermaLink="false">hacker-news-small-sites-26183114</guid>
            <pubDate>Thu, 18 Feb 2021 17:53:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Ruby Garbage Collection Deep Dive: Tri-Color Mark and Sweep]]>
            </title>
            <description>
<![CDATA[
Score 132 | Comments 15 (<a href="https://news.ycombinator.com/item?id=26182796">thread link</a>) | @mooreds
<br/>
February 18, 2021 | https://jemma.dev/blog/gc-mark-and-sweep | <a href="https://web.archive.org/web/*/https://jemma.dev/blog/gc-mark-and-sweep">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p>In the <a href="https://jemma.dev/blog/gc-internal">first post</a> in the Ruby Garbage Collection Deep Dive series, we went through a few definitions to give us a picture of how Ruby stores values in memory. If you haven‚Äôt read it yet, <a href="https://jemma.dev/blog/gc-internal">read it first</a>! We‚Äôll build on those definitions in this post. Particularly, we‚Äôll talk more about the Ruby Heap, Pages, Slots and RVALUES.</p>

<p>Okay, now that we have those baseline definitions out of the way, this post is going to explain the algorithm Ruby‚Äôs garbage collector uses to determine which objects it can collect: the Tri-Color Mark and Sweep algorithm. There are two phases to this algorithm. You guessed it: marking and sweeping. In the marking phase, the garbage collector marks all slots which contain accessible RVALUES. In the sweeping phase, the garbage collector clears the RVALUES out of all slots which are not marked. Let‚Äôs dig in!</p>

<h2 id="tri-color-mark-and-sweep">Tri-Color Mark and Sweep</h2>

<h3 id="marking">Marking</h3>

<p>We‚Äôll start off by discussing the marking phase. This is most straightforward to understand if we imagine the <a href="https://ruby-doc.org/core-3.0.0/ObjectSpace.html">Ruby ObjectSpace</a> to be a directed graph with root nodes. All of the nodes in the graphs are RVALUES. All of the edges in the graph are references from one RVALUE to another.</p>

<p>Ruby‚Äôs garbage collector starts at the root nodes and traces every edge it can access from these root nodes, marking every RVALUE it sees through this process. At the end, any RVALUE which was not traced, and therefore not accessible from a root RVALUE will be garbage collected.</p>

<h4 id="tri-color">Tri-Color</h4>

<p>Okay, but the algorithm Ruby uses for garbage collection is called a Tri-Color Mark and Sweep algorithm, so what‚Äôs the Tri-Color part all about? The Tri-Color algorithm is a model we can use to understand what Ruby‚Äôs garbage collector is doing, and how tracks its progress. The three colors in the Tri-Color algorithm (three shades, really) are white, black and grey.</p>

<p>At the beginning of garbage collection, every slot in the Ruby Heap is white. Then, as part of the initial setup, all slots which contain root RVALUEs are marked as grey.</p>

<p>Root RVALUES are all of the RVALUES that a Ruby program knows it will need to run. Examples of these are RVALUES that exist on the stack of instructions that the program is following, or protected global variables.</p>

<p>With all root slots grey, and all other slots white, we then get to the crux of the algorithm:</p>

<div><div><pre><code><span>while</span> <span>(</span><span>!</span><span>grey_slots</span><span>.</span><span>empty?</span><span>)</span>
  <span>current_slot</span> <span>=</span> <span>grey_slots</span><span>.</span><span>pop</span>
  <span>grey_slots</span> <span>+=</span> <span>current_slot</span><span>.</span><span>referenced_slots</span>
  <span>black_slots</span> <span>&lt;&lt;</span> <span>current_slot</span>
<span>end</span>
</code></pre></div></div>

<p>We iterate over all grey slots, coloring the slots that their RVALUES reference grey, and coloring themselves black. The algorithm continues until there are no grey slots left. At this point, any black slots contain RVALUES which were reachable by the RVALUEs in the root slots, and any white slots do not contain RVALUES which were reachable so can be swept away!</p>

<p>For the visual learners, here‚Äôs a gif of what the algorithm is doing:</p>

<p><img src="https://jemma.dev/assets/mark.gif" alt="mark-gif"></p>

<h4 id="references">References</h4>

<p>There is one detail which needs further explanation here: how does an RVALUE know which other RVALUES it references?</p>

<p>It depends on the type of object. For Ruby builtins, tracing the references are just baked into the garbage collector code itself. For example, to find all references from an array RVALUE, the collector iterates each element in the array and finds its references. For a hash, it will do this for both the keys and the values. This all happens in the garbage collector‚Äôs <a href="https://github.com/ruby/ruby/blob/296a2cab07ce530809ee74dee61180fbb3ca6f91/gc.c#L6269"><code>mark_children</code></a> method.</p>

<p>But, when objects are defined by C extensions, the C extensions must mark all child objects on their own. We‚Äôll dive more into this in a future C extensions post (which I‚Äôll backlink here).</p>

<p>Okay, so now that we understand how we find all accessbile objects, we need to learn how to dispose of all unaccessible objects.</p>

<h3 id="sweeping">Sweeping</h3>

<p>At this point, we have two sets: black slots and white slots. Internally, these are represented as a <code>marked</code> bitmap. Every Page on the Ruby Heap has its own <code>marked</code> bitmap with one bit per slot. A <code>1</code> bit means the slot is accessible, or Black in our Tri-Color scheme. A <code>0</code> bit means that the slot is no longer accessible, or White in our Tri-Color scheme.</p>

<p>In addition to holding this <code>marked</code> bitmap, each page also has a <code>freelist</code> which represents slots on that page which do not have live objects. The garbage collector iterates over all pages, finding all slots which are not marked. Where applicable, the garbage collector then adds the unmarked slots to each page‚Äôs freelist. If the RVALUES which were occupying these slots are also taking up space in the operating system heap, it also frees this memory.</p>

<p>Once pages have been swept, there might be pages which are now completely unallocated; they have no slots which contain RVALUES. These pages are referred to as ‚ÄúTomb Pages.‚Äù Tomb pages have their memory completely returned to the operating system‚Äôs heap. This is really helpful for memory management. It means that sweeping can result in freeing memory, or diminishing the overall size of the Ruby Heap.</p>

<p>Any pages with at least one occupied slot are called ‚ÄúEden Pages‚Äù. The sweeping phase might reduce the number of occupied slots in an Eden Page. The garbage collector will use the freelists from Eden Pages for future object allocations. That is to say, if you instantiate an object, the garbage collector will look for one of these free slots in an Eden Page and place the RVALUE representing your object in there.</p>

<p><img src="https://jemma.dev/assets/eden-and-tomb.png" alt="eden-and-tomb"></p>

<p>There is one more nuance here. As of Ruby 3.0, if auto-compaction is enabled, compaction will actually happen as part of the sweeping phase. A more in depth explanation of how and why this happens will follow in a later post about compaction in this Garbage Collection Deep Dive Series.</p>

<h3 id="tldr">TL;DR</h3>

<p>The Tri-Color mark and sweep algorithm is what Ruby‚Äôs garbage collector uses to determine which slots hold objects which no longer have accessible references. It marks all of the slots it has references to by following the Tri-Color algorithm in which it follows all references from root RVALUES. Once the garbage collector knows which objects are accessible from the roots, it can begin the sweep phase, where it will add the unoccupied slots to each page‚Äôs freelist, and release any operating system memory those RVALUES held. This enables the slots to be reused for new object allocation.</p>

<p>Here are a few new definitions we learned:</p>

<ul>
  <li><strong>Eden page</strong>: A page which contains slots with RVALUES, might also have empty slots</li>
  <li><strong>Tomb page</strong>: A page which contains only empty slots</li>
  <li><strong>Free list</strong>: A linked list per Heap Page of empty slots</li>
</ul>

<p>And that‚Äôs it for this post! I‚Äôm going to continue writing blog posts in this series, and am also writing a book about managed garbage collection, with a focus on Ruby. If this interests you, join the newsletter below or follow me <a href="https://twitter.com/jemmaissroff">on twitter</a> for updates!</p>


  </div>
</article>

      </div>
    </div></div>]]>
            </description>
            <link>https://jemma.dev/blog/gc-mark-and-sweep</link>
            <guid isPermaLink="false">hacker-news-small-sites-26182796</guid>
            <pubDate>Thu, 18 Feb 2021 17:32:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Coq 8.13]]>
            </title>
            <description>
<![CDATA[
Score 113 | Comments 38 (<a href="https://news.ycombinator.com/item?id=26180078">thread link</a>) | @infruset
<br/>
February 18, 2021 | https://coq.inria.fr/news/coq-8-13-0-is-out.html | <a href="https://web.archive.org/web/*/https://coq.inria.fr/news/coq-8-13-0-is-out.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>





<p>
The Coq development team is proud to announce the immediate availability of
<a href="https://github.com/coq/coq/releases/tag/V8.13.0">Coq 8.13.0</a>
</p>

<p>
Highlights:
</p><ul>
<li>Introduction of primitive persistent arrays in the core language, implemented using imperative persistent arrays. </li>
<li>Introduction of definitional proof irrelevance for the equality type defined in the SProp sort. </li>
<li>Many improvements to the handling of notations, including number notations, recursive notations and notations with bindings. A new algorithm chooses the most precise notation available to print an expression, which might introduce changes in printing behavior.</li>
</ul>



<p>Please see <a href="https://coq.github.io/doc/v8.13/refman/changes.html#version-8-13" rel="nofollow">the changelog</a> to learn more about this release.</p>




</div></div>]]>
            </description>
            <link>https://coq.inria.fr/news/coq-8-13-0-is-out.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26180078</guid>
            <pubDate>Thu, 18 Feb 2021 14:23:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Browsers eating RAM]]>
            </title>
            <description>
<![CDATA[
Score 131 | Comments 134 (<a href="https://news.ycombinator.com/item?id=26179817">thread link</a>) | @todsacerdoti
<br/>
February 18, 2021 | https://www.flotato.com/post/memory-chrome-safari-flotato | <a href="https://web.archive.org/web/*/https://www.flotato.com/post/memory-chrome-safari-flotato">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>I reached a point where I could barely hear the podcast I was trying to listen to. That's how loud the fan was. Then I&nbsp;closed down all open Chrome windows, and a few minutes after, the fan went silent. So I decided to see if it was just me.</p><div href=""><h3>How I&nbsp;measured</h3><p>I&nbsp;ran the 2-tab test in a completely fresh macOS install on a virtual machine. Then I ran the 54-tabs test on my own Big Sur installation, but with all extensions disabled. To record a usage snapshot ~250 times per second, I&nbsp;used <a href="https://github.com/astrofrog/psrecord">psrecord.</a></p></div><div><h2>2&nbsp;tabs:&nbsp;Twitter, then Gmail</h2><p>To simulate a realistic environment, I&nbsp;did the same steps on Safari, then Chrome:&nbsp;Go to twitter.com, scroll around, then open a new tab with Gmail and open an email. A dot means I interacted with the system. You can hover a dot to see what I&nbsp;did. </p></div><div><h3>Putting Flotato to the test</h3><p>To be light-weight, Flotato doesn't just run a stripped down, Safari-backed web view, it also defaults to the mobile version if one is available. Here's Flotato compared to a regular session in Safari. Note the slightly lower CPU usage. It's kind of hard to put a finger on what exactly the mobile version isn't calculating that the desktop version is; the two versions are almost identical when you use them.</p></div><div><h2>54 tabs:&nbsp;the stress test</h2><p>I&nbsp;bet you have more than 2 tabs open right now, I&nbsp;sure have more. So here's a stress test where I&nbsp;open 54 tabs while measuring the impact on my Mac's RAM and CPU. A dot means I&nbsp;opened a new tab. Hover the dot to see which site I&nbsp;opened.</p></div><div><h2>Is it bad?</h2><p>When I saw the results I got suspicious. Chrome was using way more memory than I thought it would. Maybe it was the virtual machine blocking Chrome's direct access to my Macbook's* GPU?&nbsp;I&nbsp;decided to run the next test, the one with 54 tabs directly on my own Big Sur installation. The results were, well, slightly worse.</p><h3>The graphs don't tell the full story</h3><p>But it's probably not as bad as it looks. It's not a terrible thing that an app actually <em>uses</em> your computer. And you've got to hand it to Chrome:&nbsp;it is fast! </p><p>I'm sure Chrome is going out of its way to manage its memory usage across tabs, keeping the current tab fast and responsive. That's great if you're not running any other macOS apps than Chrome, effectively using Chrome as your operating system, and macOS&nbsp;as a kind of bootloader. </p><p>But when you're using Sketch, Final Cut, Photoshop next to Chrome, that seems to be a problem. MacOS&nbsp;likely tries to tell Chrome to take it easy, and Chrome likely <em>does</em> take it easy. These graphs don't tell that story. </p><p>So no, it's most likely not as bad as it looks, but that doesn't change the fact since switching to Safari, I almost forgot what my fan sounds like.</p><p>And then there's <em>this</em> chart. As we can see, the two browsers heat up the computer almost to the exact same level - Safari even getting slightly warmer. This probably points to psutil not being able to see all Safari's child processes, but only the main ones ‚Äî despite the fact that Activity Monitor is able to group them. That's a little confusing. </p><figure><p><img src="https://uploads-ssl.webflow.com/5e78c687e58e25134b3fb751/602feb36d1388bb94f881998_EumcL7jXYAEBG_4.png" alt="Image"></p></figure><p>‚Äç</p><p>‚Äç</p><p><em>*&nbsp;Macbook 16" from 2019 with2.4 GHz, 8-Core Intel Core i9 with 32&nbsp;GB&nbsp;2667 MHz DDR4 RAM and an AMD&nbsp;Radeon Pro 5500M 8GB GPU</em></p></div></div>]]>
            </description>
            <link>https://www.flotato.com/post/memory-chrome-safari-flotato</link>
            <guid isPermaLink="false">hacker-news-small-sites-26179817</guid>
            <pubDate>Thu, 18 Feb 2021 13:56:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Curl is C (2017)]]>
            </title>
            <description>
<![CDATA[
Score 81 | Comments 65 (<a href="https://news.ycombinator.com/item?id=26179601">thread link</a>) | @taf2
<br/>
February 18, 2021 | https://daniel.haxx.se/blog/2017/03/27/curl-is-c/ | <a href="https://web.archive.org/web/*/https://daniel.haxx.se/blog/2017/03/27/curl-is-c/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<p>For some reason, this post got picked up again and is <a href="https://news.ycombinator.com/item?id=26179601">debated today</a> in 2021, almost 4 years since I wrote it. Some things have changed in the mean time and I might‚Äôve phrased a few things differently if I had written this today. But still, what‚Äôs here below is what I wrote back then. Enjoy!</p>



<div><figure><a href="https://daniel.haxx.se/blog/wp-content/uploads/2017/01/The_C_Programming_Language_cover.svg_.png"><img loading="lazy" width="348" height="450" src="https://daniel.haxx.se/blog/wp-content/uploads/2017/01/The_C_Programming_Language_cover.svg_-348x450.png" alt="" srcset="https://daniel.haxx.se/blog/wp-content/uploads/2017/01/The_C_Programming_Language_cover.svg_-348x450.png 348w, https://daniel.haxx.se/blog/wp-content/uploads/2017/01/The_C_Programming_Language_cover.svg_-155x200.png 155w, https://daniel.haxx.se/blog/wp-content/uploads/2017/01/The_C_Programming_Language_cover.svg_-768x992.png 768w, https://daniel.haxx.se/blog/wp-content/uploads/2017/01/The_C_Programming_Language_cover.svg_.png 792w" sizes="(max-width: 348px) 100vw, 348px"></a></figure></div>



<p>Every once in a while someone suggests to me that curl and libcurl would do better if rewritten in a ‚Äúsafe language‚Äù. Rust is one such alternative language commonly suggested. This happens especially often when we publish new security vulnerabilities. (Update: I think Rust is a fine language! This post and my stance here has nothing to do with what I think about Rust or other languages, safe or not.)</p>



<h2>curl is written in C</h2>



<p>The curl code guidelines mandate that we stick to using C89 for any code to be accepted into the repository. C89 (sometimes also called C90) ‚Äì the oldest possible ANSI C standard. Ancient and conservative.</p>



<h2>C is everywhere</h2>



<p>This fact has made it possible for projects, companies and people to adopt curl into things using basically any known operating system and whatever CPU architecture you can think of (at least if it was 32bit or larger). No other programming language is as widespread and easily available for <em>everything</em>. This has made curl one of the most portable projects out there and is part of the explanation for curl‚Äôs success.</p>



<p>The curl project was also started in the 90s, even long before most of these alternative languages you‚Äôd suggest, existed. Heck, for a truly stable project it wouldn‚Äôt be responsible to go with a language that isn‚Äôt even old enough to start school yet.</p>



<h2>Everyone knows C</h2>



<p>Perhaps not necessarily true anymore, but at least the knowledge of C is very widespread, where as the current existing alternative languages for sure have more narrow audiences or amount of people that master them.</p>



<h2>C is not a safe language</h2>



<p>Does writing safe code in C require more carefulness and more ‚Äútricks‚Äù than writing the same code in a more modern language better designed to be ‚Äúsafe‚Äù ? Yes it does. But we‚Äôve done most of that job already and maintaining that level isn‚Äôt as hard or troublesome.</p>



<p>We keep scanning the curl code regularly with static code analyzers (we maintain a <em>zero <a href="https://scan.coverity.com/projects/curl">Coverity</a> problems</em> policy) and we run the test suite with <a href="http://valgrind.org/">valgrind</a> and <a href="https://en.wikipedia.org/wiki/AddressSanitizer">address sanitizers</a>.</p>



<h2>C is not the primary reason for our past vulnerabilities</h2>



<p>There. The simple fact is that most of our past vulnerabilities happened because of logical mistakes in the code. Logical mistakes that aren‚Äôt really language bound and they would not be fixed simply by changing language.</p>



<p>Of course that leaves a share of problems that could‚Äôve been avoided if we used another language. Buffer overflows, double frees and out of boundary reads etc, but the bulk of our security problems has not happened due to curl being written in C.</p>



<h2>C is not a new dependency</h2>



<p>It is easy for projects to add a dependency on a library that is written in C since that‚Äôs what operating systems and system libraries are written in, still today in 2017. That‚Äôs the default. Everyone can build and install such libraries and they‚Äôre used and people know how they work.</p>



<p>A library in another language will add that language (and compiler, and debugger and whatever dependencies a libcurl written in that language would need) as a new dependency to a large amount of projects that are themselves written in C or C++ today. Those projects would in many cases downright ignore and reject projects written in ‚Äúan alternative language‚Äù.</p>



<h2>curl sits in the boat</h2>



<p>In the curl project we‚Äôre deliberately conservative and we stick to old standards, to remain a viable and reliable library for everyone. Right now and for the foreseeable future. Things that worked in curl 15 years ago still work like that today. The same way. Users can rely on curl. We stick around. We don‚Äôt knee-jerk react to modern trends. We sit still in the boat. We don‚Äôt rock it.</p>



<h2>Rewriting means adding heaps of bugs</h2>



<p>The plain fact, that also isn‚Äôt really about languages but is about plain old software engineering: translating or rewriting curl into a new language will introduce a lot of bugs. Bugs that we don‚Äôt have today.</p>



<p>Not to mention how rewriting would take a huge effort and a lot of time. That energy can instead today be spent on improving curl further.</p>



<h2>What if</h2>



<p><em>If I would start the project today, would I‚Äôve picked another language?</em> Maybe. Maybe not. If memory safety and related issues was the primary concern I had, then sure. But as I‚Äôve mentioned above there are several others concerns too so it would really depend on my priorities.</p>



<h2>Finally</h2>



<p>At the end of the day the question that remains is: would we gain more than we would pay, and over which time frame? Who would gain and who would lose?</p>



<p>I‚Äôm sure that there will be or it may even already exist, curl and libcurl competitors and potent alternatives written in most of these new alternative languages. Some of them are absolutely really good and will get used and reach fame and glory. Some of them will be crap. Just like software always work. Let a thousand curl competitors bloom!</p>



<p>Will curl be rewritten at some point in the future? I won‚Äôt rule it out, but I find it unlikely. I find it even more unlikely that it will happen in the short term or within the next few years.</p>



<p>Discuss this post on <a href="https://news.ycombinator.com/item?id=13966241">Hacker news</a> or <a href="https://www.reddit.com/r/programming/comments/61rh9j/curl_is_c/">Reddit</a>!</p>



<p><strong>Followup-post: </strong><a href="https://daniel.haxx.se/blog/2017/03/30/yes-c-is-unsafe-but/">Yes, C is unsafe, but‚Ä¶</a></p>
	</div></div>]]>
            </description>
            <link>https://daniel.haxx.se/blog/2017/03/27/curl-is-c/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26179601</guid>
            <pubDate>Thu, 18 Feb 2021 13:34:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[OpenZFS ‚Äì dRAID, Finally]]>
            </title>
            <description>
<![CDATA[
Score 161 | Comments 46 (<a href="https://news.ycombinator.com/item?id=26179566">thread link</a>) | @throw0101a
<br/>
February 18, 2021 | https://klarasystems.com/articles/openzfs-draid-finally/ | <a href="https://web.archive.org/web/*/https://klarasystems.com/articles/openzfs-draid-finally/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>




<div>
<h3><em>This is part of our article series published as ‚ÄúOpenZFS in Depth‚Äù. <a href="https://klarasystems.com/articles/"><strong><span>Subscribe to our article series</span></strong> </a>to find out more about the secrets of OpenZFS</em></h3>



<hr>



<p><strong><em>Isaac Huang‚Äôs <a href="https://www.youtube.com/watch?v=xPU3rIHyCTs">talk at the OpenZFS 2017 developers summit</a> witnessed the expansion of the ZFS storage endurance envelope for large installations.&nbsp; dRAID or distributed RAID is a new vdev type that complements existing ZFS data protection capabilities for very large storage arrays.&nbsp; Starting with the RAID-Z-like underpinnings, dRAID permutes, or mixes, disk blocks together in a way where accesses are evenly spread across all the drives. Fast spindle replacement is accomplished by using all members of the pool, using pre-allocated virtual spares, spread evenly over all the spindles. Contributors include Intel, Lawrence Livermore Labs, and HP Enterprise, which have material interest in storage at datacenter scale and high reliability. The OpenZFS user community are the benefactors of this enhancement if we apply it well.</em></strong></p>



<h3><strong>Avoiding the Death Spiral</strong></h3>



<p>Admins will often use wide RAID stripes to maximize usable storage given a number of spindles. RAID-Z deployments with large stripe widths, ten or larger, are subject to poor resilver performance for a number of reasons. Resilvering a full vdev means reading from every healthy disk and continuously writing to the new spare. This will saturate the replacement disk with writes while scattering seeks over the rest of the vdev. For 14 wide RAID-Z2 vdevs using 12TB spindles, rebuilds can take weeks. Resilver I/O activity is deprioritized when the system has not been idle for a minimum period. Full zpools get fragmented and require additional I/O‚Äôs to recalculate data during reslivering. A pool can degenerate into a never ending cycle of rebuilds or loss of the pool Aka: the Death Spiral.</p>



<p>As spindles age together, disks may fail in groups as defect counts and mechanical failure are not independent random processes with respect to age. SSD‚Äôs further complicate this math as the wear leveling endurance will be very closely matched and clusters of devices under identical load may fail together.&nbsp; Manufacturer provided mean time to failure is a forward-looking statement and is not suitable for replenishment planning. One manufacturer claims 1.2 Million hour MTBF: a dubious 137 year commitment to quality. It‚Äôs poor planning to assume any drive isn‚Äôt going to pick today to dramatically fail.&nbsp;</p>



<p>dRAID is an option providing rapid parity rebuild that can mitigate the death spiral behaviour of wide RAIDZ stripes, but as reflected in its default width setting of eight, it does not encourage wide stripes. Dedicating sufficient parity increases the durability of the ZFS pool and the investment in parity should be informed by the risk of losing the pool.</p>



<h3><strong>Distributed Spares?</strong></h3>



<p>Spare disks are a way of keeping a disk warm and ready to replace a failed member. Usually, a spare‚Äôs life is leisurely idle until they are scrammed into action during a rebuild. That idleness is a wasted opportunity to do useful work. There are no specific spare disks in a dRAID. Rather, enough blocks are allocated throughout out the vdev to act as spares. The distributed spare is a clever redistribution of work so that all disks are always in use. A disk failure precipitates a rebuild into that dedicated space. After replacement disks are available, the vdev can be re-balanced to return the spare block and put the replacement disk in to use.</p>



<h3><strong><strong><strong>Fixed Stripe Width</strong></strong></strong></h3>



<p>Unlike RAID-Z, an entire stripe in dRAID is allocated at once, no matter how many disk blocks are needed to store the object. The stripe width is determined by the disk sector size multiplied by the number of data drives in the RAID group.</p>



<div data-columns="3" data-layout="50-25-25"><div>




<div><div>
<p>Did you know?</p>



<h2>You can maximize the <strong>power of your FreeBSD</strong> infrastructure with our <strong>Support Subscription!</strong></h2>




</div></div>




</div></div>



<p>RAID-Z has a method of optimizing block layout to minimize block allocations for small files. dRAID however priorities the speed of rebuilding parity and does not make the same space preserving attempt. If your files are a small fraction of the stripe size, dRAID will not be able to use all the disk blocks fully. For example, a default dRAID vdev has a stripe with of 32k (4k per disk, 8 disks); any allocation will require at least 32k. Internal padding is allocated to fill out the stripe width after the request object is stored. Using a smaller stripe width or providing a special mirror vdev will suit smaller allocations and improve drive utilization.</p>



<h3><strong>A Tale of Two Resilvers</strong></h3>



<p>After a failure, the real or distributed spare is written to in sequence, following only the parity layout in the space map to rebuild the drive according to parity data. Sequential reconstruction can be accomplished rapidly by issuing large I/O blocks, reducing seeks, and avoiding tree indirection overhead. The rebuilt disk‚Äôs contents are not necessarily consistent with the Merkle tree that proves the zpools data is intact.&nbsp; It‚Äôs important to reconstruct this bitwise copy of the disk first, allowing the system to return to mostly intact state and return to service. That is to say, the sequential reconstruction process restores the redundancy level of the pool, but without being able to verify the checksums of the data. The advantage to this is that it can be completed much more quickly, reducing the window during which additional disk failures might put the pool at risk.</p>



<p>A healing resilver is triggered automatically after a sequential resilver, it is a final operation that verifies that all the contents of the drives match their initial checksums via block pointer traversal. The healing resilver has a number of optimizations to quickly find and reconstruct writes to the failed disk. When a replacement drive can be added to the pool, the rebalance operation is another sequential resilver followed by a healing resilver.</p>



<p>A scrub is the gold standard for a pool health; however, a scrub might be a prohibitive amount of work, visiting every block allocated in the pool. The healing resilver allows a practical return to operation in an environment where failures must be repaired routinely.</p>



<h3><strong><em>‚ÄúAre We There Yet? When Can I Play With it?‚Äù</em></strong></h3>



<p>According to a report from the January OpenZFS leadership meeting, OpenZFS 2.1 will support dRAID in early 2021. If you must have it now; the head branch of the OpenZFS build against recently supported operating systems: FreeBSD 12.1+, Linux 5.10+, Illumos, NetBSD et al. The OpenZFS regression test suite ztest is a good indication that dRAID satisfies the ZFS commitment to data protection. Corporate customers at IBM and Panasas have been flogging other distributed RAID systems for more than ten years. It‚Äôs a mature concept that complements the ZFS tool set.</p>



<h4><strong>Quick Start</strong></h4>



<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; There is no better way to learn software than to run headlong into mistakes.&nbsp;</p>



<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; We‚Äôll install ZFS head from source and gin up some ‚Äòmd‚Äô file backed disks.</p>



<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; ‚Äòzpool create r2dRAID dRAID2:3d:1s:14c /dev/md1 /dev/md2 ‚Ä¶.&nbsp; /dev/md13 /dev/md14‚Äô</p>



<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; There it is, a zpool with a dRAID vdev, ready to go to work.</p>



<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; The OpenZFS wiki has a good description of <a href="https://openzfs.github.io/openzfs-docs/Basic%20Concepts/dRAID%20Howto.html">dRAID care, resilvering and rebalancing</a></p>



<p>Following the life cycle of failure and replacement in the documentation is recommended before those skills are tested in production.</p>



<h4><strong>dRAID Nomenclature</strong></h4>



<p>Let‚Äôs decode the nomenclature that describes the geometry of a dRAID vdev. A string such as ‚ÄúdRAID2:3d:14c:1s‚Äù encodes the following about a dRAID vdev.</p>



<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; -dRAID[&lt;parity&gt;][:&lt;data&gt;d][:&lt;children&gt;c][:&lt;spares&gt;s]</p>



<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; -parity: Required, the number of spindles to use to store parity information. Eg: A dRAID3 can survive until a fourth disk failure without losing data. Parity may be 1,2 or 3.</p>



<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; -[d] data: (spindles per RAID group): Determines the width of the data stripe, 8 is the default. Larger values will increase the stripe width and reduce total parity.</p>



<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; -[c] children: This parameter should match the number of device entries that you feed to the vdev. A helpful check will warn you if you don‚Äôt get the right number of disks named correctly: ‚Äúinvalid number of dRAID children; 14 required but 13 provided‚Äù</p>



<p>&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; -[s] spares: The number of disk areas to mix in as distributed spares. No spares are created by default, a maximum of four are welcome. Each spare will remove a fraction of space from every disk.</p>



<h2><strong>Parting Short</strong></h2>



<p>The dRAID offers a solution for large arrays, vdevs with fewer than 20 spindles will have limited benefits from the new option. The performance and resilver result will be similar to RAIDZ for small numbers of spindles. Installations with many spindles will see the best results with regards to performance, fast spare activation and replacement. The benefits come with the associated cost of whole stripe at a time allocation for small objects in the pool. This overhead should be calculated in the design of the pool before it‚Äôs an operational surprise.</p>



<p>There is no free lunch with dRAID for in saving parity or spare drives, they are your defense against data loss. As drives increase in size, their time to resilver increases and the amount of data they can destroy increases.</p>



<h2><strong>Like this article? Share it!</strong></h2>


</div>




</div></div>]]>
            </description>
            <link>https://klarasystems.com/articles/openzfs-draid-finally/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26179566</guid>
            <pubDate>Thu, 18 Feb 2021 13:31:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I am a heroin user. I do not have a drug problem]]>
            </title>
            <description>
<![CDATA[
Score 261 | Comments 625 (<a href="https://news.ycombinator.com/item?id=26179003">thread link</a>) | @CapitalistCartr
<br/>
February 18, 2021 | http://m.nautil.us/issue/96/rewired/i-am-a-heroin-user-i-do-not-have-a-drug-problem | <a href="https://web.archive.org/web/*/http://m.nautil.us/issue/96/rewired/i-am-a-heroin-user-i-do-not-have-a-drug-problem">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
			<p><span>C</span>arl Hart is a neuroscientist and Ziff Professor of Psychology at Columbia University‚Äîhe was the first tenured African-American professor of sciences at Columbia. His research focuses on the ‚Äúbehavioral and neuropharmacological effects of psychoactive drugs in humans.‚Äù Hart‚Äôs new book, <i>Drug Use For Grown-Ups</i>, is a bold and engaging effort to counter what he sees as generations of misinformation and moral grandstanding about drug use. Today‚Äôs ‚Äúsensationalistic media coverage of the opioid crisis continues a long, awful tradition of exploiting ignorance and fear to vilify certain members of our society,‚Äù Hart writes. The media is not the only problem. Scientists, he states, ‚Äúhave frequently overinterpreted and distorted‚Äù drugs‚Äô effects on the brain.</p><p>Hart reports that more than 70 percent of drug users‚Äîwhether they use alcohol, cocaine, prescription medications, or heroin‚Äîdo not meet the health criteria for drug addiction. In <i>Drug Use for Grown-Ups</i>, Hart strives to ‚Äúpresent a more realistic image of the typical drug user: a responsible professional who happens to use drugs in his pursuit of happiness.‚Äù With genial candor, Hart presents himself as a model drug user. ‚ÄúI am now entering my fifth year as a regular heroin user,‚Äù he writes. ‚ÄúI do not have a drug-use problem. Never have. Each day, I meet my parental, personal, and professional responsibilities. I pay my taxes, serve as a volunteer in my community on a regular basis, and contribute to the global community as an informed and engaged citizen. I am better for my drug use.‚Äù</p><p><i>Nautilus</i> caught up with Hart to discuss his drug use and his sharp points about science and society. He was as casually bold in conversation as he is in <i>Drug Use for Grown-Ups</i>.</p><figure data-alt="MacNamara_BREAKER"><img src="http://static.nautil.us/18174_0f004440ba0c8f1ccc5c355f3d77207f.png" width="733" alt=""><figcaption><span><strong>HABIT OF A HIGHLY EFFECTIVE PERSON:</strong> ‚ÄúMy heroin use is as rational as my alcohol use,‚Äù Carl Hart writes. ‚ÄúLike vacation, sex, and the arts, heroin is one of the tools that I use to maintain my work-life balance.‚Äù</span><span>Courtesy of Carl Hart</span></figcaption></figure><p><b>You say ‚Äúmost drug-use scenarios cause little or no harm and that some responsible drug-use scenarios are actually beneficial for human health and functioning.‚Äù How so?</b></p><p>Let‚Äôs just talk about alcohol first. When you‚Äôre at a wedding reception, alcohol serves as a social lubricant. People are more gregarious. They talk, they interact. The same is true with cocaine at parties, heroin among friends, or opium among friends, NDMA among lovers. It enhances empathy, openness, and forgiveness, all of these pro-social attributes.</p><p><b>Drug research, you write, is full of bad science. If you had to name one example, what would it be?</b></p><p>The notion that drug addiction is a brain disease. That encapsulates all that‚Äôs wrong with today‚Äôs science in this area. There is absolutely no data in humans to show that drug addiction is a brain disease. Yet the narrative, the dogma, the dominant perspective is that it does. Even though nobody will dispute that, there‚Äôs absolutely no data in humans to support that statement.</p><p><b>Yet opioids do change the brain biologically, do they not?</b></p><p>Yes, opioids bind to a class of receptors called endogenous opioids, which you find in endorphins, for example. Opioids bind to these receptors‚Äîjust like natural chemicals do‚Äîwhich results in a response. In some cases, because of decreased sensitivities and certain types of pain, they may enhance a sense of euphoria. So it‚Äôs really just facilitating what‚Äôs already in the body naturally, a system that helps in our survival. Think of fructose or glucose. We add sugar to our tea, our coffee, whatever we have, we add more and more because we like it, it tastes good, and it enhances pleasure. It can give you energy. It can make life more interesting. Humans do not live on logic alone. And so sometimes we do these things, and that‚Äôs OK.</p><blockquote><p>People become addicted because they once had a middle-class-paying job that made them someone in their community.</p> </blockquote><p><b>How have scientists ‚Äúoverinterpreted and distorted‚Äù the effects of drugs on the brain?</b><br></p><p>Take brain imaging. People often show one image of someone‚Äôs brain. Let‚Äôs say this person is addicted to methamphetamine, according to DSM criteria, versus the brain of someone who‚Äôs not addicted. If you see some difference, some researchers have a propensity to make more out of the differences than are there. There‚Äôs a wide range of brain structural sizes, such that when we think about one person‚Äôs size of their nucleus accumbens, it may be smaller or larger than somebody else‚Äôs nucleus accumbens. But both of the nucleus accumbens, despite their sizes, are within the normal range of human variability. It‚Äôs like height. One guy might be 5‚Äô10‚Äù, another guy might be 6‚Äô2‚Äù. But we don‚Äôt say the guy who‚Äôs 5‚Äô10‚Äù is height deficient. We just say that he‚Äôs in a normal range, and he‚Äôs not as tall as the other guy. We wouldn‚Äôt say one is deficient versus the other. In neuroscience, one of the things that has happened, particularly when it comes to drugs, people have over-interpreted the differences to mean pathology, when, in fact, both of the brain structures are within the normal range of human variability. The overinterpretation is to interpret it as being pathological.</p><p><b>You say the opioid crisis has been sensationalized, and write, ‚ÄúPeople are not dying because of opioids; they are dying because of ignorance.‚Äù What do you mean?</b></p><p>Some people don‚Äôt know not to mix specific sedatives with opioids. For example, they don‚Äôt know not to mix large amounts of alcohol or large amounts of antihistamines. Specific combinations can lead to respiratory depression, which can lead to death. Another point of ignorance involves people who buy street drugs and don‚Äôt necessarily know if the drugs contain contaminants. That‚Äôs the kind of ignorance I‚Äôm talking about.</p><div>
<article>
<p><a href="http://m.nautil.us/issue/15/Turbulence/ingenious-robert-sapolsky" data-trval="ingenious-robert-sapolsky" data-trlbl="foc_rec" data-tract="internal_art">
<img src="http://static.nautil.us/3786_34306d99c63613fad5b2a140398c0420.png" alt="Sapolsky_TH-F1" width="314" height="177">
</a>
</p>
<div>
<p><span>
<span>

<span><a href="http://m.nautil.us/term/f/Neuroscience">Also in Neuroscience</a></span>&nbsp;&nbsp;</span>
</span></p><h4><a href="http://m.nautil.us/issue/15/Turbulence/ingenious-robert-sapolsky" data-trval="ingenious-robert-sapolsky" data-trlbl="foc_rec" data-tract="internal_art">Ingenious: Robert Sapolsky</a></h4>
<p>By Kevin Berger</p>
<p>
When we asked Robert Sapolsky what he might like to write about for the Nautilus Turbulence issue, he responded, ‚Äúadolescence.‚Äù We had to laugh because the idea just seemed so perfect. Is there a more turbulent time in our lives?...<strong><a href="http://m.nautil.us/issue/15/Turbulence/ingenious-robert-sapolsky" data-trval="ingenious-robert-sapolsky" data-trlbl="foc_rec" data-tract="internal_art">READ MORE</a></strong>
</p>

</div>

</article>
</div><p><b>So it‚Äôs the mix of drugs that is the problem, not opioids like heroin themselves?&nbsp;</b></p><p>Yes, the majority of opioid deaths occur as a result of combining opioids with multiple sedatives. But there are certain opioids that do concern us if taken alone and the person isn‚Äôt aware that they have this particular opioid. Those are fentanyl and the fentanyl analogs. These drugs are a lot more potent than something like heroin, meaning they require less of it to produce the effect. Most of the public aren‚Äôt seeking fentanyl or its analogs, but people are tainting things like heroin and oxycodone pills with fentanyl or an analog.</p><p>One way to deal with this tainting, this contamination, is to have free drug-checking facilities, where people can submit samples of their drug and get a chemical readout of what is contained in the substance. That way they‚Äôll know whether to take the substance or how much of it to take. The public also needs to know that most people who use these drugs are not addicts. If you understand that, then you know that for the people who do become addicted, we have to look beyond the drug and look at the person‚Äôs environment, their life. Do they have co-occurring psychiatric illnesses? Do they have pain that is not treated? All of these kinds of issues become important.</p><p><b>At what point does biological change in the brain lead to physical addiction?</b></p><p>Physical addiction occurs as a result of opioids‚Äîor any other drug, alcohol too‚Äîbeing in the body for consecutive weeks or periods, in particularly high doses. And then the body tries to compensate. For example, with opioids, one of the things that happens is that your gut, your gastrointestinal system, slows down the receptors. Your body is trying to compensate by speeding up the gastrointestinal tract. So when the drug abruptly leaves after several weeks of constant administration of the opioid, now the body is unprepared for the drug not being there and it overcompensates. It really ramps up the motility of the gastrointestinal tract, which causes diarrhea, among other things.</p><blockquote><p>It can give you energy. It can make life more interesting. Humans do not live on logic alone.</p> </blockquote><p><b>Why do some people get addicted and not others?</b><br></p><p>The amount of drugs they take, the period at which they take it. Some people can take opioids for extended periods of time. As long as they keep the doses fairly low and they don‚Äôt take multiple doses a day, they probably won‚Äôt experience physical dependence. It‚Äôs just like with alcohol. Most people drink alcohol on a regular basis, but they don‚Äôt become physically dependent. Whereas others drink every day in large amounts, and they will become physically dependent.</p><p><b>Why can‚Äôt people overcome addiction?</b></p><p>One of the major reasons people can‚Äôt overcome it is because we‚Äôre not very good at treating addiction in this country. Just think about why people become addicted. A large number become addicted because of co-occurring psychiatric illnesses, because of pain issues, because they once had a middle-class-paying job that made them someone in their home, someone in their community. Those jobs are gone. Then there‚Äôs no healthcare or there‚Äôs poor education. If your treatment is not addressing these issues, people are not going to overcome it. But if we have treatments that are holistic, and they‚Äôre looking at the individual, and not so much the drug, then we‚Äôre good. But if we‚Äôre just talking about the drug, then we‚Äôre already behind the eight ball, then we will lose that battle.</p><p><b>Your definition of addiction follows the DSM-5, which refers to a ‚Äúsubstance use disorder‚Äù and values functioning over regular ingestion of a substance. How do you define ‚Äúfunctioning‚Äù?</b></p><p>Functioning is determined by whether a user is happy in meeting their obligations, whatever they may be, whether they‚Äôre work-related, whether they‚Äôre family-related, or other social sorts of things. The person is not stressed out about their substance use. In fact, ‚Ä¶</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://m.nautil.us/issue/96/rewired/i-am-a-heroin-user-i-do-not-have-a-drug-problem">http://m.nautil.us/issue/96/rewired/i-am-a-heroin-user-i-do-not-have-a-drug-problem</a></em></p>]]>
            </description>
            <link>http://m.nautil.us/issue/96/rewired/i-am-a-heroin-user-i-do-not-have-a-drug-problem</link>
            <guid isPermaLink="false">hacker-news-small-sites-26179003</guid>
            <pubDate>Thu, 18 Feb 2021 12:23:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The frame rate of the universe (2009)]]>
            </title>
            <description>
<![CDATA[
Score 69 | Comments 55 (<a href="https://news.ycombinator.com/item?id=26178259">thread link</a>) | @codesections
<br/>
February 18, 2021 | https://www.librador.com/2009/01/16/The-frame-rate-of-the-universe/ | <a href="https://web.archive.org/web/*/https://www.librador.com/2009/01/16/The-frame-rate-of-the-universe/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">
      
<div id="page-2009-2009-01-16-The-frame-rate-of-the-universe-">
  
  <p><abbr title="2009-01-16T01:04:00+01:00">16 Jan 2009</abbr></p><div>
    <p>

    I stumbled upon <a href="http://www.newscientist.com/article/mg20126911.300-our-world-may-be-a-giant-hologram.html?full=true">this
article</a> which presents the hypothesis that the universe is a 3D projection of a 2D
surface, like a giant hologram. I like to read about modern physics. It is so weird and I can't say
I really understand very much of it. But the descriptions provoke strange and fascinating images
and thoughts in my head. Like this one:</p><p>The article mentions the <a href="http://en.wikipedia.org/wiki/Planck_length">Planck length</a>, which as I understand it is
the smallest distance there is. It's extremely small: 1.6 √ó 10<sup>-35</sup> meters, which makes
it billions and billions of times smaller than an atom (or even a proton). I'm used to thinking
about computer graphics, so I imagine the Planck length as the size of one "pixel" of the universe.
Nothing can be smaller than a pixel. (The pixels of the universe are small, I calculate the
resolution to correspond to 2.19 √ó 10<sup>33</sup> DPI.) The radius of the observable universe is
4.4 √ó 10<sup>26</sup> meters. If we want to fit the universe into a box, its sides would have to
be twice that size. That is 5.4 √ó 10<sup>61</sup> Planck lengths. So that's the width, height and
depth of the universe in pixels. Quite a good resolution. (Actually since they are 3D cubes instead
of 2D squares, I should call them voxels instead of pixels. All 1.61 √ó 10<sup>185</sup> of
them.)</p><p>There is also the <a href="http://en.wikipedia.org/wiki/Planck_time">Planck time</a>
which is the time it takes for light to travel one Planck length. As light is fast and the Planck
length is tiny (tiniest there is!), you can image that it's a very short period of time. Certainly.
The Planck time is 5.39 √ó 10<sup>-44</sup> seconds. No measurable time can be shorter than that
according to quantum physics. Thinking about graphics again, this is like a limit on the frame rate
of the universe. Inverting the Planck time, I get 1.855 √ó 10<sup>43</sup>. So by my surely
incorrect logic, we get the value of the universe's frame rate:</p><p>One thousand eight hundred
and fifty-five billion billion billion billion frames per second.</p><p>I'll say that
again:</p><p>18.55 septillion FPS!</p><p>Video cameras won't be perfect until they can record at
that speed.</p><p>I hope I got the calculations right, but I'm pretty sure my interpretation of the
quantum physics behind this are way off. It's still fascinating to think of the universe as a
computer simulation. Modern physics make it seem more like a video game than ever.<br>


</p>
  </div>
  
  
  <p><a href="http://disqus.com/">blog comments powered by </a>
</p></div>

    </div></div>]]>
            </description>
            <link>https://www.librador.com/2009/01/16/The-frame-rate-of-the-universe/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26178259</guid>
            <pubDate>Thu, 18 Feb 2021 10:37:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Lithuania plans to hold drills in case of accident at the Belarus nuclear plant]]>
            </title>
            <description>
<![CDATA[
Score 156 | Comments 132 (<a href="https://news.ycombinator.com/item?id=26178235">thread link</a>) | @maury91
<br/>
February 18, 2021 | https://www.lrt.lt/en/news-in-english/19/1346034/lithuania-plans-to-hold-evacuation-drills-after-belarus-launches-nuclear-plant | <a href="https://web.archive.org/web/*/https://www.lrt.lt/en/news-in-english/19/1346034/lithuania-plans-to-hold-evacuation-drills-after-belarus-launches-nuclear-plant">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<article id="article1346034">    

    
    
    <div>

        <div id="article_text1346034">
            <p>Lithuania‚Äôs Interior Ministry plans to hold drills and assess the need to evacuate Vilnius‚Äô residents in case of an accident at the Astravyets nuclear plant in Belarus, located some 50 kilometres from the Lithuanian capital.</p>
            
            <p>"That will be one of the key questions during the drafting of the exercises schedule and probably going back to the scenarios: do we or do we not need to evacuate Vilnius residents,‚Äù Vitalij Dmitrijev, vice minister of the interior, told LRT RADIO.</p>
            <p>The so-called Astravyets drill was held in October 2019 in Vilnius and Svenƒçionys districts, which are located close to the Belarusian border. During the exercises, authorities prepared to evacuate people from radiation-affected territories, distribute iodine pills, as well as simulated a resident cleanup and monitoring operation.</p>
            <p>The exercise involved around 300 officers, troops and civil servants from six municipalities and 24 institutions. Due to a dispute over the exercise scenario with the Vilnius authorities, officers from the capital did not take part in the drills.</p>
                

            <p><em>Read more: <a href="https://www.lrt.lt/en/news-in-english/19/1103053/lithuanians-stage-mock-evacuations-to-train-for-nuclear-accident-photos">Lithuanians stage mock evacuations to train for nuclear accident ‚Äì photos</a></em></p>
            <!--googleoff: all--><!--googleon: all-->            <p>Previously, the Vilnius authorities cancelled another exercise, planned in early September, to simulate an accident at the nuclear power plant in Belarus.</p>
            <p>Based on the information available to BNS, Vilnius Municipality faced resistance from the government at the time.</p>
            <p>Lithuanian officials say that the nuclear power plant built by the Russian state atomic corporation Rosatom and funded by a loan from the Kremlin was built in breach of international safety standards. Minsk denies all accusations.</p>
            <p>Estonia, Latvia, and Lithuania are also due to unplug from the Moscow-controlled energy grid that links them with Belarus. Vilnius says that the Kremlin may use the plant to derail the move.</p>
<!--googleoff: all--><div>
            
<div id="mlb2-1612938">
    <div>
        <div>
            <div>
                <div>
                    <p><img src="https://bucket.mlcdn.com/a/1239/1239192/templates/39/39540/5dcc95ea35753170c2955994a6fea7c948ffb283.png"></p><p>LRT English Newsletter<span><span><br></span><span><span>Every Friday morning.</span></span></span></p>
                    
                </div>
            </div>
            
        </div>
    </div>
</div>

<p><img src="https://track.mailerlite.com/webforms/o/1612938/i0s8k2?v4a60e9ef938a7fa0240ac9ba567062cb" width="1" height="1">
</p></div><!--googleon: all-->        </div>
    </div>
    <!--googleoff: all-->
        <!--googleon: all-->
        

<div data-id="gallery1346034"><div>
            <div>
                <div>
                    <div>
<p><img data-src="/img/2019/10/02/522637-581058-1287x836.jpg" alt="‚ÄòAstravyets drill‚Äô in Lithuania" title="‚ÄòAstravyets drill‚Äô in Lithuania" src="https://www.lrt.lt/img/2019/10/02/522637-581058-1287x836.jpg"></p>
<div>
    <div>
        <div>
<p>‚ÄòAstravyets drill‚Äô in Lithuania</p>            <p><span>1 / 5</span><span>D. Umbrasas / LRT</span></p>
        </div></div>
</div>
                    </div>
                    <div>
<p><img data-src="/img/2019/12/23/573047-835055-1287x836.jpg" alt="Lithuania has staged 'Astravyets drills' to prepare for nuclear emergencies" title="Lithuania has staged 'Astravyets drills' to prepare for nuclear emergencies" src="https://www.lrt.lt/img/2019/12/23/573047-835055-1287x836.jpg"></p>
<div>
    <div>
        <div>
<p>Lithuania has staged 'Astravyets drills' to prepare for nuclear emergencies</p>            <p><span>2 / 5</span><span>D. Umbrasas/LRT</span></p>
        </div></div>
</div>
                    </div>
                    <div>
<p><img data-src="/img/2019/10/02/522627-981621-1287x836.jpg" alt="‚ÄòAstravyets drill‚Äô in Lithuania" title="‚ÄòAstravyets drill‚Äô in Lithuania" src="https://www.lrt.lt/img/2019/10/02/522627-981621-1287x836.jpg"></p>
<div>
    <div>
        <div>
<p>‚ÄòAstravyets drill‚Äô in Lithuania</p>            <p><span>3 / 5</span><span>D. Umbrasas / LRT</span></p>
        </div></div>
</div>
                    </div>
                    <div>
<p><img data-src="/img/2019/10/02/522623-306261-1287x836.jpg" alt="‚ÄòAstravyets drill‚Äô in Lithuania" title="‚ÄòAstravyets drill‚Äô in Lithuania" src="https://www.lrt.lt/img/2019/10/02/522623-306261-1287x836.jpg"></p>
<div>
    <div>
        <div>
<p>‚ÄòAstravyets drill‚Äô in Lithuania</p>            <p><span>4 / 5</span><span>D. Umbrasas / LRT</span></p>
        </div></div>
</div>
                    </div>
                    <div>
<p><img data-src="/img/2019/10/02/522612-821132-1287x836.jpg" alt="‚ÄòAstravyets drill‚Äô in Lithuania" title="‚ÄòAstravyets drill‚Äô in Lithuania" src="https://www.lrt.lt/img/2019/10/02/522612-821132-1287x836.jpg"></p>
<div>
    <div>
        <div>
<p>‚ÄòAstravyets drill‚Äô in Lithuania</p>            <p><span>5 / 5</span><span>D. Umbrasas / LRT</span></p>
        </div></div>
</div>
                    </div>
                </div>
                
            </div>
        </div>
        
    </div>
 

    
    
</article>

        
    </div></div>]]>
            </description>
            <link>https://www.lrt.lt/en/news-in-english/19/1346034/lithuania-plans-to-hold-evacuation-drills-after-belarus-launches-nuclear-plant</link>
            <guid isPermaLink="false">hacker-news-small-sites-26178235</guid>
            <pubDate>Thu, 18 Feb 2021 10:34:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Reflections on Using Haskell for My Startup]]>
            </title>
            <description>
<![CDATA[
Score 41 | Comments 16 (<a href="https://news.ycombinator.com/item?id=26176940">thread link</a>) | @_query
<br/>
February 17, 2021 | https://alistairb.dev/reflections-on-haskell-for-startup/ | <a href="https://web.archive.org/web/*/https://alistairb.dev/reflections-on-haskell-for-startup/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p>Almost exactly one year ago I quit my job to create a Haskell startup as a solo developer. I had about 20 ideas, but eventually settled on the idea of dependency project health tracking with <a href="https://deadpendency.com/" target="_blank" rel="noopener">Deadpendency</a>.</p>

<p>This post describes the experience and evaluates Haskell and its ecosystem.</p>

<p><small>Disclaimer: This blog post contains a bunch of memes. They are trying to be humorous, not accurate or fair üòâ.</small></p>

<h2 id="why-haskell">Why Haskell?</h2>

<p>Since about 2016 I have had a strong <del>obsession</del> love of Haskell. Prior to learning Haskell, I was an experienced OO style developer but I didn‚Äôt really know how to keep improving my raw programming ability. Haskell introduced me to the world of functional programming (FP) which has an almost infinite depth of concepts to learn, which do actually help improve code quality and application architecture.</p>

<p><img width="400" src="https://i.imgflip.com/4x9eeq.jpg" alt="I should learn functional programming meme"></p>

<p>Haskell is challenging to learn, but extremely fun to write. For my own learning and pleasure, if my startup succeeds, I want to be doing Haskell.</p>

<p>Additionally, I think Haskell is the best general purpose programming language (that you can use in production). In particular, Haskell excels at writing ‚Äòboring‚Äô business applications which is typically what I work on. <a href="https://www.foxhound.systems/blog/why-haskell-for-production/" target="_blank" rel="noopener">‚ÄòWhy Haskell For Production‚Äô</a> goes into more detail on the benefits Haskell offers.</p>

<p><img width="400" src="https://i.imgflip.com/4x9fwz.jpg" alt="Haskell is the best change my mind meme"></p>

<h2 id="the-setup-phase">The Setup Phase</h2>

<p>Probably the most challenging part was building out a skeleton architecture to hang my business logic on. I decided to go with, even within Haskell, fairly advanced libraries of <a href="https://docs.servant.dev/en/stable/" target="_blank" rel="noopener"><code>servant</code></a> and <a href="https://hackage.haskell.org/package/fused-effects" target="_blank" rel="noopener"><code>fused-effects</code></a>.</p>

<p>I spent a fair amount of time banging my head against a wall trying to get these libraries to work nicely together. This was primarily from a lack of Haskell ability on my part. I had prepared as best I could, but Haskell is deep and I needed to learn more to work day to day with it. I was lucky enough to eventually find <a href="https://github.com/mitchellwrosen/hspolls" target="_blank" rel="noopener">an example</a> that marries these two libraries together, which was a life saver. I‚Äôm sure I would have gotten there eventually, but I was in a bit over my head at that point.</p>

<p><img width="400" src="https://i.imgflip.com/4x9j14.jpg" alt="Haskell with servant fused-effects is hard meme"></p>

<p>Haskell is awesome, but like most languages there is cruft and legacy to be avoided. Haskell has a standard library known as <a href="https://hackage.haskell.org/package/base" target="_blank" rel="noopener"><code>base</code></a> which unfortunately has a fair amount of unsafe or unperformant functions included. As such I went with an alternative standard library <a href="https://hackage.haskell.org/package/relude" target="_blank" rel="noopener"><code>relude</code></a> that builds on and improves <code>base</code>. On top of this, there are many core libraries that are not part of the standard library I wanted to use and have nice patterns around.</p>

<p>Additionally, I was <a href="https://alistairb.dev/haskell-on-google-cloud-is-great">deploying to google cloud</a> and so needed to figure out good patterns for that integration from Haskell.</p>

<p>This setup effort was quite challenging. I spent most of it squinting at compiler errors. Yet it only took about 2 weeks to have a good foundation of code to start building my business logic upon.</p>

<h2 id="building-it-out">Building it Out</h2>

<p>This is when it started to get really fun. I had my core patterns set out and I could focus on building a pipeline. The day in day out of writing out my logic as small pure functions that I composed together was very nice.</p>

<p>Haskell has such impressive auto-magic code generation techniques that you spend much more time focused on the interesting logic of your application rather than boilerplate.</p>

<div><div><pre><code><span>data</span> <span>HappinessLevel</span> <span>=</span>
    <span>Miserable</span>
  <span>|</span> <span>Sad</span>
  <span>|</span> <span>Average</span>
  <span>|</span> <span>Happy</span>
  <span>|</span> <span>HaskellDeveloper</span>
  <span>deriving</span> <span>(</span><span>Show</span><span>,</span> <span>Eq</span><span>,</span> <span>Ord</span><span>,</span> <span>Bounded</span><span>,</span> <span>Enum</span><span>,</span> <span>ToJSON</span><span>,</span> <span>FromJSON</span><span>)</span> <span>-- magic code generation</span>

<span>-- ok not really magic, think 'convention over configuration'</span>
<span>-- where you can have generated sane defaults, or customise if you like</span>
</code></pre></div></div>

<p>And personally I think Haskell is quite beautiful to read and write. #notbiased</p>

<h3 id="parsing-libraries">Parsing Libraries</h3>

<p>A lot of the logic of Deadpendency is parsing. Either parsing dependency files or parsing various API responses. Haskell has many excellent parsing libraries, most notably <a href="https://hackage.haskell.org/package/aeson" target="_blank" rel="noopener"><code>aeson</code></a> for JSON.</p>

<p>Why is this nice in Haskell? The ‚Äòmonad‚Äô abstraction is excellent for dealing with code with a lot of failure conditions (ie. parsing) and avoids ‚Äòpyramid of doom‚Äô type code. Haskell worked out really well in this key area.</p>

<p><img width="400" src="https://alistairb.dev/images/hadouken.jpeg" alt="Pyramid of doom meme"></p>

<h3 id="testing">Testing</h3>

<p>Another strong positive for writing Deadpendency was testing. Haskell has a lesser-known style of testing libraries that do ‚Äòproperty based testing‚Äô (PBT).</p>

<p>PBT allows you to write value generators for your data types, which you use to generate 100s or 1000s of test cases. Then, you run these generated values against some function and check that certain properties hold.</p>

<p>For example, part of the Deadpendency logic is generating an HTML report at the end. I had some <code>toHtml :: Report -&gt; HTML</code> function that I wanted to test. So I wrote a <code>fromHtml :: HTML -&gt; Report</code> function where it goes the other way (ok writing that was pretty painful). Then my PBT test will generate 100s of <code>Report</code> values and check that <code>report == fromHtml (toHtml report)</code> (this is known as ‚Äòroundtrip testing‚Äô). With this single test I was able to find many edge case bugs with my HTML report generation logic.</p>

<p><img width="400" src="https://i.imgflip.com/4x9tqj.jpg" alt="Haskell with servant fused-effects is hard meme"></p>

<p>PBT exists in some other languages, but it originated (I believe?) in Haskell so the libraries are excellent.</p>

<h3 id="not-actively-maintained-libraries">Not Actively Maintained Libraries</h3>

<p>A big challenge of working with Haskell was the lack of well-maintained libraries. Ironically, of the 75 (!) packages I depend upon 19 are flagged by Deadpendency as unhealthy (deprecated or inactive). This means I often don‚Äôt have the luxury of asking library maintainers to fix bugs. Even if I PR a fix, sometimes that PR will be ignored for months.</p>

<p>This I think is the reality of using a niche language like Haskell. To be clear, I do not think library developers owe me anything, but it is nonetheless a downside when compared to more popular languages.</p>

<p><img width="400" src="https://i.imgflip.com/4x9xjq.jpg" alt="Haskell not actively maintained meme"></p>

<p>Thankfully Haskell build tools have good support for loading a package from git. This means you can PR some bug fix or feature and immediately use your fork to work around the problem.</p>

<h3 id="compile-times-were-fine">Compile Times.. Were Fine</h3>

<p>I thought I‚Äôd call this out as it is a common complaint I see around Haskell. I followed some <a href="https://www.parsonsmatt.org/2019/11/27/keeping_compilation_fast.html" target="_blank" rel="noopener">good advice</a> which kept compilation fast (aside from <a href="https://twitter.com/AlistairBuzz/status/1253507016242294784" target="_blank" rel="noopener">one interesting edge case I resolved</a>).</p>

<ul>
  <li>Number of modules (Haskell source files) - 509</li>
  <li>Number of lines of Haskell - 20090</li>
  <li>Number of dependencies - 75</li>
  <li>Dell 9570 XPS Laptop - (Hex core - 8th-gen Intel Core i7-8750H CPU), 32GB memory</li>
</ul>

<p>So what are the numbers?</p>

<h4 id="compile-dependencies-from-scratch">Compile dependencies from scratch</h4>

<p>Time: 17m44s</p>

<p>This is compiling all application dependencies, which needs to be done before you can compile your application code. Rebuilding all from scratch rarely happens as both my dev machines and CI will cache and only rebuild what has changed.</p>

<p>You do sometimes update a very core package which triggers a lot of dependent packages to recompile which can take a while. Although, I usually do dependency updates at the start of the day while I‚Äôm sipping my coffee, so usually don‚Äôt notice.</p>

<h4 id="compile-app-including-tests-in-development">Compile app (including tests) in development</h4>

<p>Time: 1m1s</p>

<p>Likewise, due to caching a full recompilation rarely happens. As such, most code edits do not trigger many modules to be recompiled and it is fast.</p>

<p>Additionally, Haskell has nice ‚Äòcontinuous compilation‚Äô tools that fire on save. Usually by the time I actually look at my terminal compilation is already done.</p>

<h4 id="compile-app-for-deployment">Compile app for deployment</h4>

<p>with <a href="https://downloads.haskell.org/~ghc/latest/docs/html/users_guide/using-optimisation.html" target="_blank" rel="noopener">full optimisations</a> (-02).</p>

<p>Time: 2m53s</p>

<p>This typically runs in CI. It runs in parallel with a host of other checks such as running my tests, which also take a few minutes. Due to this, the time doesn‚Äôt really impact the build + deploy time too much.</p>

<p><img width="400" src="https://i.imgflip.com/4xp4zu.jpg" alt="Compile times meme"></p>

<h3 id="refactoring-pain">Refactoring Pain</h3>

<p>Deadpendency is relatively simple in what it does, but there is a lot of hidden complexity to the problem. Which is to say, it is like 99% of applications üòâ. When developing it I was constantly realising I had modelled things a bit too simplistically and would need to refactor.</p>

<p>Haskell is very safe to refactor thanks to the type safety the compiler brings, which is probably the most important thing. However, Haskell does not have great tools to help with refactoring, at least in terms of the restructuring changes I kept making. The <a href="https://hackage.haskell.org/package/apply-refact" target="_blank" rel="noopener">existing</a> <a href="https://hackage.haskell.org/package/retrie" target="_blank" rel="noopener">tools</a> seem more geared towards complex rewriting of common code, not restructuring modules or renaming identifiers.</p>

<p>As such I did it all manually with text search replace, or just change something and fix all the new compiler errors. This was a bit of a grind and it caused me to delay needed refactoring sometimes.</p>

<p>It‚Äôs a pity Haskell doesn‚Äôt have the refactoring tools to help in this situation. The dream would be these tools integrated into an IDE.</p>

<p><img width="400" src="https://i.redd.it/dbdshzzflgd31.jpg" alt="Haskell had an IDE meme"></p>

<p>(Stolen from <a href="https://www.reddit.com/r/ProgrammerHumor/comments/cjtbfj/society_if_haskell_has_ide/" target="_blank" rel="noopener">reddit</a>)</p>

<p>Having said that, it should be noted that Haskell does have an excellent IDE now in the form of <a href="https://github.com/haskell/haskell-language-server" target="_blank" rel="noopener">Haskell Language Server</a> (HLS). The momentum around the project is insane and I applaud the developers. One fixed pain point from HLS is it does auto imports now, which used to greatly contribute to the friction of working with Haskell. I‚Äôm sure Haskell will get there eventually.</p>

<h3 id="waiting-for-new-ghc-versions-to-be-usable">Waiting for New GHC Versions to be Usable</h3>

<p>This is mostly me complaining for the sake of it, but as someone pretty obsessed with both new shiny versions of things and Haskell, waiting for new GHC (GHC is the Haskell compiler) versions to be usable has been painful. There is a long tail of libraries and platforms that need to be updated before I can use a new GHC version. Sometimes these updates can drag a lot.</p>

<p>For example GHC 9 was just released, but I still haven‚Äôt been able to upgrade to GHC 8.10 yet which was first released in March 2020.</p>

<p><img width="500" src="https://i.imgflip.com/4xebid.jpg" alt="GHC releases meme"></p>

<h2 id="launching">Launching</h2>

<p>So after about 8 months of work I was ready to start getting users. I slowly soft launched, promoting it in a few small channels. How did my Haskell fair in prod?</p>

<h3 id="very-few-logic-bugs">Very Few Logic Bugs</h3>

<p>My core Haskell had very few logic bugs. This is because Haskell is very safe by default and I had opted into strict types that help catch edge cases.</p>

<p>For example, I was using a lot of <a href="https://hackage.haskell.org/package/base-4.14.1.0/docs/Data-List-NonEmpty.html" target="_blank" rel="noopener"><code>NonEmpty</code></a> lists which the compiler will guarantee is not empty. To use them you must specify how to handle the empty case. ie. what do I do if Deadpendency can‚Äôt find any dependencies to check?</p>

<p>And of course, I had ‚Ä¶</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://alistairb.dev/reflections-on-haskell-for-startup/">https://alistairb.dev/reflections-on-haskell-for-startup/</a></em></p>]]>
            </description>
            <link>https://alistairb.dev/reflections-on-haskell-for-startup/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26176940</guid>
            <pubDate>Thu, 18 Feb 2021 07:17:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[TLS certificates specifying hosts via the CommonName field is more or less gone]]>
            </title>
            <description>
<![CDATA[
Score 62 | Comments 21 (<a href="https://news.ycombinator.com/item?id=26176448">thread link</a>) | @zdw
<br/>
February 17, 2021 | https://utcc.utoronto.ca/~cks/space/blog/tech/TLSCertificateCNMostlyGone | <a href="https://web.archive.org/web/*/https://utcc.utoronto.ca/~cks/space/blog/tech/TLSCertificateCNMostlyGone">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><h2>TLS certificates specifying hosts via their CommonName field is more or less gone</h2>

	<p><small>February 17, 2021</small></p>
</div><div><p><a href="https://en.wikipedia.org/wiki/Transport_Layer_Security">TLS</a>
certificates for hosts and domains must somehow identify what
hostname (or names) they're for. Historically <a href="https://utcc.utoronto.ca/~cks/space/blog/tech/TLSCertificatesNamingHosts">there have been two
ways to do this</a>. The first way was a
specific sub-field, the <em>CN</em> or CommonName, of the certificate's
overall <em>Subject Name</em>. This had the problem that it could only
have one name. When people started wanting to have TLS certificates
that covered more than one name, they invented another mechanism,
the <em>Subject Alternative Name</em> (SAN) extension.</p>

<p>As a practical matter, all vaguely modern software that wants to
properly validate TLS certificates has supported (and often preferred)
Subject Alternative Names for some time. A great many TLS certificates
in the wild are for multiple hosts and it's generally unlikely that the
host you're connecting to is the one name that the system chose to put
in the CN field; software that only supports CN cannot validate those
TLS certificates. As a matter of timing, SANs have been theoretically
mandatory since 2002 and checking only SANs has been theoretically
required since 2011 (which means that since 2011 or earlier, the CN was
supposed to always be one of the SANs).</p>

<p>These days, any remaining support for looking at TLS certificate
CommonName to validate TLS certificates is getting more and more
extinct (and more so than I expected when I started writing this
entry). In the browser realm, <a href="https://www.chromestatus.com/feature/4981025180483584">Chrome apparently turned it off in
58, released in 2017</a>, and then
threw out the option to check it again in Chrome 65 (from the comment
on <a href="https://utcc.utoronto.ca/~cks/space/blog/tech/TLSCertificatesNamingHosts">my old entry</a>, which was ironically
written shortly before Chrome did this). Firefox is said to have
removed support in version 48, from August of 2016. <a href="https://support.apple.com/en-ca/HT210176">Safari
apparently stopped looking at CommonName in iOS 13 and macOS 10.15</a>, which I believe date
from late 2019. <a href="https://go-review.googlesource.com/c/go/+/231379">This Go change</a> also talks about
how browsers removed it in 2019 ('last year' for a mid 2020 change).</p>

<p>In non-browser TLS code, Go started ignoring CN by default in
Go 1.15 (released in August of 2020) and this will be the only
option starting in Go 1.17 (to be released in August of 2021),
per <a href="https://golang.org/doc/go1.16#crypto/x509">here</a>. Since
Firefox doesn't support CN any more, I assume that <a href="https://en.wikipedia.org/wiki/Network_Security_Services">NSS</a> doesn't
either, since NSS is basically Firefox's underlying TLS implementation.
I have no idea what other TLS libraries are doing, but I would expect
that many of them will support CommonName for some time to come; TLS
libraries are historically behind browser practices.  Hopefully they
are all following the 2011 requirement to check only SANs when SANs are
present (which they should always be in public certificates).</p>

<p>Probably TLS certificates will continue to contain CommonName fields
for a long time to come. Having a <em>Subject Name</em> in general is
common (although apparently not actually required) and the CN is a
standard (although not required) part of the Subject Name, so you
might as well throw it in. Even Mozilla and Let's Encrypt (still)
have TLS certificates with CNs. However, since I checked this now,
the current <a href="https://cabforum.org/">CA/Browser Forum</a> <a href="https://cabforum.org/baseline-requirements-documents/">baseline
requirements</a>
(version 1.7.3) allow but don't require CommonName (section 7.1.4.2.2,
which says that it's 'discouraged, but not prohibited'). Given how
conservative most Certificate Authorities are, I expect them to be
issuing TLS certificates with CommonName fields until they're
required to stop.</p>

<p>(An interested party could scan Certificate Transparency logs to see if
there were very many issued certificates without CNs. Probably there are
some; someone must have tried it out at some point through an official
CA.)</p>

<p>PS: <a href="https://no-common-name.badssl.com/">no-common-name.badssl.com</a>
has a TLS certificate without a CN, or at least it's supposed to
(<a href="https://community.letsencrypt.org/t/how-to-obtain-a-cert-without-a-common-name/72807/6">via</a>),
but the TLS certificate is expired right now as I write this entry
so it's hard to test how client software behaves. <a href="https://community.letsencrypt.org/t/compatibility-testing-of-no-common-name/72863">See also</a>,
which pointed me to <a href="https://no-subject.labs.vu.nl/">no-subject.labs.vu.nl</a>,
which has a currently valid TLS certificate with no <em>Subject Name</em> at all.</p>
</div></div>]]>
            </description>
            <link>https://utcc.utoronto.ca/~cks/space/blog/tech/TLSCertificateCNMostlyGone</link>
            <guid isPermaLink="false">hacker-news-small-sites-26176448</guid>
            <pubDate>Thu, 18 Feb 2021 05:54:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[40 Year History of Opposition to Nuclear Power in California]]>
            </title>
            <description>
<![CDATA[
Score 47 | Comments 39 (<a href="https://news.ycombinator.com/item?id=26175253">thread link</a>) | @Lammy
<br/>
February 17, 2021 | https://www.energy-net.org/01NUKE/CALIF.HTM | <a href="https://web.archive.org/web/*/https://www.energy-net.org/01NUKE/CALIF.HTM">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div width="49%"> 
	  <p><span face="Verdana, Arial, Helvetica, sans-serif" size="2" color="#CC6600"><b><span size="3" color="#000000">40 
		Year History of Opposition to Nuclear Power in California </span></b></span> 
		<br>
	  </p>
	  <p><span face="Verdana, Arial, Helvetica, sans-serif" size="2">California 
		citizens have made a unique stand concerning the attempts by Nuclear proponents 
		to make the state a premiere model for commercial nuclear energy. California's major 
		utilities, in particular Pacific Gas and Electric (PG&amp;E) has spent an
		enormous amount of money and political muscle in attempts to build reactors 
		across California but have mostly failed. PG&amp;E was supposedly involved in 
		the Atoms for Peace proposal made in 1953 and was 
		part of a coalition of american utilities that investigated the technical 
		potentials for building nuclear reactors as a source of electricity.</span></p>
	  <p><span face="Verdana, Arial, Helvetica, sans-serif" size="2">The following 
		is a brief summary of the battles against nuclear power that started here 
		in California in 1958.</span></p>
	  <p><span face="Verdana, Arial, Helvetica, sans-serif" size="2">Northern 
		California is the home of the first successful opposition to the promotion 
		and development of commercial nuclear reactors in the U.S. In the 1950's 
		northern and central California's privately Owned utility company, PG&amp;E 
		was planning to be one of the giants in the new field of nuclear energy. 
		It had helped design and build the Dresden I reactor in Illinois with 
		a consortium of 5 major companies, including General Electric(GE).</span></p>
	  <p><span face="Verdana, Arial, Helvetica, sans-serif" size="2">In conjunction 
		with GE, it built the vallecitos nuclear complex south of San Francisco 
		and then went it alone with their Humboldt reactor near Arcata. But their 
		luck took a turn for the worse when they tried to build the world's largest 
		nuclear facility 1000 feet from the fault that caused the 1906 earthquake.</span></p>
	  <p><span face="Verdana, Arial, Helvetica, sans-serif" size="2">Yes, PG&amp;E 
		even said they could build a reactor in downtown San Francisco! In 
		fact they were planning the construction of 63 reactors in California 
		during the early 1960's, one every 25 miles along the coast They even 
		 planned to build a floating reactor!!</span></p>
	  <h2><span face="Verdana, Arial, Helvetica, sans-serif" size="2"><b>The 
		Bodega Bay Duck Pond</b><br>
		</span></h2>
	  <p><span face="Verdana, Arial, Helvetica, sans-serif" size="2">When PG&amp;E 
		started pushing plans to build the reactors at Bodega Pay in 1958 a literal 
		groundswell of opposition erupted during the next 6 years to stop them 
		dead cold. The site they had chosen near the San Andreas Fault Zone was 
		just a few miles from the epicenter of the Great San Francisco Quake where 
		ground shifts of over 20 feet had occurred in 1906.</span></p>
	  <p><span face="Verdana, Arial, Helvetica, sans-serif" size="2">PG&amp;E's 
		unethical plans to build the reactor is not new for this company, as they 
		have a history of unfair tactics that goes back to the company's birth. 
		Upon deciding that the Bodega Headlands would be an excellent site for the largest nuclear 
		facility in the world, PG&amp;E simply beat the state out in its plans 
		to make the area a state park. </span></p>
	  <p><span face="Verdana, Arial, Helvetica, sans-serif" size="2">The battle 
		started in 1958 when the Santa Rosa Press Democrat published the first 
		story on PG&amp;E's plans. The company's ignored their own geologist, who had warned 
		that the area was likely to be effected by strong shaking during a quake. 
		Concerned citizens started getting involved as PG&amp;E refused to acknowledge 
		publicly that they were actually going to build nuclear reactors at the 
		proposed site.</span></p>
	  <p><span face="Verdana, Arial, Helvetica, sans-serif" size="2">The 1957 
		windscale accident in England, where a small reactor had burned out of 
		control for more than a day, helped focus concerns about safety on this 
		new idea of nuclear power.</span></p>
	  <p><span face="Verdana, Arial, Helvetica, sans-serif" size="2">In 1961, 
		after nearly 3 years of pushing their plan behind the scenes, PG&amp;E 
		announced plans to build the Atomic Park at the Bodega site. The ensuing battle 
		and PG&amp;E's nasty style started to backfire though as public concerns 
		grew.</span></p>
	  <p><span face="Verdana, Arial, Helvetica, sans-serif" size="2">Major opposition 
		came from within the ranks of the Sierra Club, but the board refused to 
		allow its active members the right to oppose the reactors on the issue 
		of earthquakes. When it came out that PG&amp;E had doctored fault maps 
		of the site, all hell broke loose.</span></p>
	  <p><span face="Verdana, Arial, Helvetica, sans-serif" size="2">One of PG&amp;E's 
		major claims at the time was that they could build reactors that would 
		survive a great Earthguake. At one point they said that the reactors could 
		survive a quake 50 per cent bigger than the O6' quake by floating the 
		reactors on 3 feet of compressable material but when the public and the 
		Atomic Energy Commission (AEC) got a close-up view of the devastation 
		from the air of the quake in Alaska during the spring of 1964, support 
		for the reactor complex dried up.</span></p>
	  <p><span face="Verdana, Arial, Helvetica, sans-serif" size="2">Opponents 
		had "infiltrated" the federal government and were pushing 
		for closure. With the disclosure of the AEC's WASH 740 report, which documented 
		potential dangers to the bay area residents in case of an accident, opposition 
		finally reached all government levels.</span></p>
	  <p><span face="Verdana, Arial, Helvetica, sans-serif" size="2">California 
		governor Pat Brown asked that PG&amp;E abandon the reactors. Two days 
		later PG&amp;E caved in and called the project off. The battle ended in 
		1964 with a $7 million duck pond as a living monunent to the future. (It 
		is still there today)</span></p>
	  <p><span face="Verdana, Arial, Helvetica, sans-serif" size="2">This experience 
		gave PG&amp;E a deadly lesson on how to overcome public concerns at their 
		next reactor site--Diablo Canyon.</span></p>
	  <h2><span face="Verdana, Arial, Helvetica, sans-serif" size="2"><b>The 
		Diablo Canyon Nightmare:</b><br>
		</span></h2>
	  <p><span face="Verdana, Arial, Helvetica, sans-serif" size="2">The 25 year 
		battle over Diablo Canyon is a classic case of courage in the face of 
		the political power this utility unleashed in its drive to build a major 
		nuclear facility in California.</span></p>
	  <p><span face="Verdana, Arial, Helvetica, sans-serif" size="2">PG&amp;E's 
		plans to build a mega facility shifted south to the less populated coastal 
		area near San Luis Obispo. The company purchased the Nipomo Dunes and 
		told environmental leaders that unless an acceptable site was chosen that 
		they would go ahead and build a facility at the popular beach area. The 
		wife of the Sierra Club president was selected to come up with an acceptable 
		site in secrecy with the company. </span></p>
	  <p><span face="Verdana, Arial, Helvetica, sans-serif" size="2">The site 
		chosen, Diablo Canyon, was California's second to last coastal wilderness 
		area, an area that had been proposed as a National Park due to its beauty. 
		Besides being a sacred Chumash burial ground, it was the home of one of 
		a kind 1,000 year old Oak trees (the largest in the world). It was also 
		the home of one of the state's largest populations of abalone and sea 
		otters.</span></p>
	  <p><span face="Verdana, Arial, Helvetica, sans-serif" size="2">In the process 
		of getting permission to go ahead with Diablo, PG&amp;E suceeded in selling 
		the site to key members of the Sierra Club's board of directors. The Utility 
		had sympathetic board members flown over the Diablo site in Frank Sinatra's 
		Lear jet, with entertainment by Danny Kaye (Danny later came out against 
		the reactors).</span></p>
	  <p><span face="Verdana, Arial, Helvetica, sans-serif" size="2">The first 
		slam-dunk by PG&amp;E came against the local farmer who had the right 
		of way access rights over the Diablo property. The company went to court 
		and had his rights removed. The beligerant act made the man a life-long 
		opponent of PG&amp;E's plan.</span></p>
	  <h2><span face="Verdana, Arial, Helvetica, sans-serif" size="2"><b>PG&amp;E 
		gets Cozy with Sierra Club Board Members</b><br>
		</span></h2>
	  <p><span face="Verdana, Arial, Helvetica, sans-serif" size="2">The biggest 
		tactical plan was to focus on the Sierra Club. The company and the electric 
		industry already had the board's ear with their claims that nuclear power 
		could reduce air pollution that was caused by coal power plants. The utility, 
		with inside help then sought official support for Diablo Canyon when club's 
		only board member who knew about the site's natural value was in Europe. 
		The board went along with PG&amp;E, and in fact voted to block any Club 
		members or chapters opposition to the facility. This move enraged David 
		Brower, eventually resulting in the split up of the club and the creation 
		of Friends of the Earth by embittered Sierra Club members who were angered 
		by the actions of key Sierra Club Board members.</span></p>
	  <p><span face="Verdana, Arial, Helvetica, sans-serif" size="2">PG&amp;E's 
		success within the Sierra Club was the culmination of 2 years of behind 
		the scenes work by Doris Leonard. She was the wife of the president of 
		the club. Her role in exchanging the Nipomo Dunes site for Diablo Canyon 
		was rewarded later when she was elected to PG&amp;E's board of directors. 
		</span></p>
	  <p><span face="Verdana, Arial, Helvetica, sans-serif" size="2">The Sierra 
		Club refused to allow its local chapter near Diablo to use the club nane 
		in opposing the five proposed reactors at the site. The group was forced 
		to take on another name in 1966, the Shoreline Preservation Conference.</span></p>
	  <p><span face="Verdana, Arial, Helvetica, sans-serif" size="2">The group 
		was concerned about earthquake faults along the coast as locals were fully 
		aware of the 1927 quake that completely destroyed a nearby city. They 
		called for a full investigation into potential fault areas. Their efforts 
		were ignored by the government and the media.</span></p>
	  <p><span face="Verdana, Arial, Helvetica, sans-serif" size="2">News of the 
		reactor siting was poorly covered by the Bay area's conservative media, 
		a tactic that made the issue invisible to bay area residents who had stopped 
		PG&amp;E's Bodega reactor plans.</span></p>
	  <p><span face="Verdana, Arial, Helvetica, sans-serif" size="2">Oil companies 
		chart the Hosgri Fault The Hosgri fault had been mapped by Shell oil geologists 
		during the 1960's, but not published until 1970. PG&amp;E claims to have 
		not found out about the fault until late 1972. The information was finally 
		publicized in November 1973 by an investigative reporter in Los Angeles. 
		In a suspicious turn of events, the lawyer who had been fighting the case 
		since 1965 was found dead in his car just after the announcement. Authorities 
		claimed it was suicide, with no other investigation to follow up.</span></p>
	  <p><span face="Verdana, Arial, Helvetica, sans-serif" size="2">P&amp;GE's 
		bad memories of Bodega Bay helped fuel their push to ignore earthquake 
		concerns at Diabl Canyon. The same Seismic experts who had been involved 
		with the Bodega Bay facility were brought in to review the site for seismicity. 
		They pointed out major flaws in PG&amp;E's own $2,000 seismic study. A 
		state of the art study at the time would have cost $100,000)</span></p>
	  <h2><span face="Verdana, Arial, Helvetica, sans-serif" size="2"><b>The 
		Hosgri Fault Forces PG&amp;E to Rebuild Diablo Again</b><br>
		</span></h2>
	  <p><span face="Verdana, Arial, Helvetica, sans-serif" size="2">A storm of 
		controversy erupted around the facility as one of the units was reaching 
		completion. Even with the help of the Nuclear Regulatory Commission's 
		(NRC) predecessor, the AEC, PG&amp;E was finally forced after 3 years 
		of federal in-fighting to rebuild seismic bracing in 1976.</span></p>
	  <p><span face="Verdana, Arial, Helvetica, sans-serif" size="2">In attempts 
		to stop a seismic retrofit, PG&amp;E even coined the Tao Effect which 
		said that the bigger the structure, the less damage a quake would have.</span></p>
	  <p><span face="Verdana, Arial, Helvetica, sans-serif" size="2">Seismic experts 
		for the concerned activists remained uninpressed, ‚Ä¶</span></p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.energy-net.org/01NUKE/CALIF.HTM">https://www.energy-net.org/01NUKE/CALIF.HTM</a></em></p>]]>
            </description>
            <link>https://www.energy-net.org/01NUKE/CALIF.HTM</link>
            <guid isPermaLink="false">hacker-news-small-sites-26175253</guid>
            <pubDate>Thu, 18 Feb 2021 03:28:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Decoding Mars 2020]]>
            </title>
            <description>
<![CDATA[
Score 34 | Comments 1 (<a href="https://news.ycombinator.com/item?id=26172593">thread link</a>) | @followben
<br/>
February 17, 2021 | https://destevez.net/2020/08/decoding-mars-2020/ | <a href="https://web.archive.org/web/*/https://destevez.net/2020/08/decoding-mars-2020/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-8920">

	

	<div>
		
<p><a href="https://en.wikipedia.org/wiki/Mars_2020">Mars 2020</a>, NASA‚Äôs latest mission to Mars, was launched a couple weeks ago. However, with all the Tianwen-1 work down the pipeline, until now I haven‚Äôt had time to dedicate an appropriate post to this mission (though I showed some <a href="https://twitter.com/ea4gpz/status/1289322621360730113">sneak peek on Twitter</a>). This mission consists of a <a href="https://en.wikipedia.org/wiki/Perseverance_(rover)">rover</a> and <a href="https://en.wikipedia.org/wiki/Mars_Helicopter_Ingenuity">helicopter</a> (a real novelty in space exploration). Both were launched with the cruise stage and the entry, descent and landing system on July 30 from <a href="https://en.wikipedia.org/wiki/Cape_Canaveral_Space_Launch_Complex_41">Cape Canaveral</a>, an are currently on their transfer orbit to Mars, as Tianwen-1 and Emirates Mars Mission.</p>



<p>In this post I will be working with some recordings made by <a href="https://amsat-dl.org/">AMSAT-DL</a> using the <a href="https://amsat-dl.org/en/20-meter-antenna/">20m radio telescope at Bochum‚Äôs observatory</a>. These feature the low rate safe mode telemetry, which was very strong and caused some anecdotes as it <a href="https://twitter.com/nascom1/status/1288828268552916992">saturated some NASA DSN receivers</a>, and the nominal 10kbps telemetry signal that was switched on later. Here I will describe the modulation and coding, giving <a href="https://www.gnuradio.org/">GNU Radio</a> decoders, and also take a look at the data. <a href="http://www.r00t.cz/?action=home">r00t.cz</a> has also written a <a href="http://www.r00t.cz/Sats/Mars2020">post</a> where he shows similar information.</p>



<h4>Safe mode modulation and coding</h4>



<p>Mars 2020‚Äôs X-band downlink is at approximately 8414.9 MHz. When in safe mode, a baudrate of only 80 baud is transmitted using PCM/PSK/PM (see <a href="https://deepspace.jpl.nasa.gov/files/phase1.pdf">this document</a> for the terminology). This means that the telemetry is a PSK signal modulated onto a subcarrier which is then phase modulated onto a residual carrier. The subcarrier in this case is a 25kHz square wave.</p>



<p>The figure below shows the spectrum of the signal, as recorded in Bochum on 2020-07-30 20:25 UTC. We see the central residual carrier at a slight offset from 0Hz, and then the data sidebands and their odd harmonics. We have only odd harmonics because of the square wave subcarrier. A sine wave subcarrier produces both even and odd harmonics when phase modulated.</p>



<figure><a href="https://destevez.net/wp-content/uploads/2020/08/mars2020_safe_mode_spec.png"><img width="644" height="382" src="https://destevez.net/wp-content/uploads/2020/08/mars2020_safe_mode_spec-644x382.png" alt="" srcset="https://destevez.net/wp-content/uploads/2020/08/mars2020_safe_mode_spec-644x382.png 644w, https://destevez.net/wp-content/uploads/2020/08/mars2020_safe_mode_spec-300x178.png 300w, https://destevez.net/wp-content/uploads/2020/08/mars2020_safe_mode_spec-768x455.png 768w, https://destevez.net/wp-content/uploads/2020/08/mars2020_safe_mode_spec.png 837w" sizes="(max-width: 644px) 100vw, 644px"></a></figure>



<p>If we zoom in to the centre of the modulation, we see that the data sidebands are very narrow, owing to the low baudrate.</p>



<figure><a href="https://destevez.net/wp-content/uploads/2020/08/mars2020_safe_mode_spec_zoom.png"><img width="644" height="385" src="https://destevez.net/wp-content/uploads/2020/08/mars2020_safe_mode_spec_zoom-644x385.png" alt="" srcset="https://destevez.net/wp-content/uploads/2020/08/mars2020_safe_mode_spec_zoom-644x385.png 644w, https://destevez.net/wp-content/uploads/2020/08/mars2020_safe_mode_spec_zoom-300x179.png 300w, https://destevez.net/wp-content/uploads/2020/08/mars2020_safe_mode_spec_zoom-768x460.png 768w, https://destevez.net/wp-content/uploads/2020/08/mars2020_safe_mode_spec_zoom.png 829w" sizes="(max-width: 644px) 100vw, 644px"></a></figure>



<p>The coding is CCSDS Turbo frames as described in the <a href="https://public.ccsds.org/Pubs/131x0b3e1.pdf">TM Synchronization and Channel Coding blue book</a>. A rate of 1/2 and frame size of 223 bytes is used. Note that each frame takes 45.5 seconds to transmit, due to the low baudrate.</p>



<p>The GNU Radio decoder flowgraph is shown in the figure below (click on it to view in full size). Its structure is very similar to other PCM/PSK/PM demodulators I‚Äôve shown in previous posts, such as <a href="https://destevez.net/2020/07/tianwen-1-telemetry-modulation-and-coding/" data-type="post" data-id="8747">the one for Tianwen-1</a>. The residual carrier is locked with a PLL (here using a bandwidth of 200Hz), the imaginary part of the signal is taken to extract the data sideband, the subcarrier is moved down to baseband, and then clock recovery and subcarrier recovery using a Costas loop are done. Finally, Turbo decoding is done with the blocks from <a href="https://github.com/daniestevez/gr-dslwp/tree/maint38">gr-dslwp</a>. The flowgraph can be found <a href="https://github.com/daniestevez/jupyter_notebooks/blob/master/Mars2020/mars2020_safemode.grc">here</a>.</p>



<figure><a href="https://destevez.net/wp-content/uploads/2020/08/mars2020_safemode.png"><img width="644" height="592" src="https://destevez.net/wp-content/uploads/2020/08/mars2020_safemode-644x592.png" alt="" srcset="https://destevez.net/wp-content/uploads/2020/08/mars2020_safemode-644x592.png 644w, https://destevez.net/wp-content/uploads/2020/08/mars2020_safemode-300x276.png 300w, https://destevez.net/wp-content/uploads/2020/08/mars2020_safemode-768x706.png 768w, https://destevez.net/wp-content/uploads/2020/08/mars2020_safemode.png 1232w" sizes="(max-width: 644px) 100vw, 644px"></a><figcaption>Mars 2020 safe mode GNU Radio decoder flowgraph</figcaption></figure>



<p>The figure below shows the decoder running. The signal is very strong, so the constellation is quite clean. We can see in the spectrum of the BPSK subcarrier that the data symbols are not filtered, since some sidelobes are visible.</p>



<figure><a href="https://destevez.net/wp-content/uploads/2020/08/mars2020_safemode_running.png"><img width="644" height="355" src="https://destevez.net/wp-content/uploads/2020/08/mars2020_safemode_running-644x355.png" alt="" srcset="https://destevez.net/wp-content/uploads/2020/08/mars2020_safemode_running-644x355.png 644w, https://destevez.net/wp-content/uploads/2020/08/mars2020_safemode_running-300x166.png 300w, https://destevez.net/wp-content/uploads/2020/08/mars2020_safemode_running-768x424.png 768w, https://destevez.net/wp-content/uploads/2020/08/mars2020_safemode_running-1536x848.png 1536w, https://destevez.net/wp-content/uploads/2020/08/mars2020_safemode_running.png 1600w" sizes="(max-width: 644px) 100vw, 644px"></a><figcaption>Mars 2020 safe mode decoder running</figcaption></figure>



<h4>10kbps modulation and coding</h4>



<p>The nominal 10kbps signal replaces the safe mode modulation during normal spacecraft operations. The modulation is 60kbaud PCM/PM/NRZ. This means that the data is directly phase-modulated onto the residual carrier.</p>



<p>The figure below shows the spectrum of the signal as recorded by Bochum on 2020-07-31 20:04 UTC. We can see the residual carrier and the data modulation, which can be approximated by a BPSK modulation in quadrature with the carrier.</p>



<figure><a href="https://destevez.net/wp-content/uploads/2020/08/mars2020_10kbps_spec.png"><img width="644" height="382" src="https://destevez.net/wp-content/uploads/2020/08/mars2020_10kbps_spec-644x382.png" alt="" srcset="https://destevez.net/wp-content/uploads/2020/08/mars2020_10kbps_spec-644x382.png 644w, https://destevez.net/wp-content/uploads/2020/08/mars2020_10kbps_spec-300x178.png 300w, https://destevez.net/wp-content/uploads/2020/08/mars2020_10kbps_spec-768x455.png 768w, https://destevez.net/wp-content/uploads/2020/08/mars2020_10kbps_spec.png 837w" sizes="(max-width: 644px) 100vw, 644px"></a></figure>



<p>The coding is CCSDS Turbo frames as in the safe mode signal, but here a rate of 1/6 and frame size of 1115 bytes are used to improve the low Eb/N0 performance. As such, frames take around 0.9 seconds to transmit.</p>



<p>The figure below shows the GNU Radio decoder flowgraph for the 10kbps signal. A slightly different approach from the <a href="https://destevez.net/2020/07/decoding-emirates-mars-mission-hope/" data-type="post" data-id="8670">Emirates Mars Mission decoder</a> (which is also PCM/PM/NRZ) is used here. The residual carrier is locked with a PLL (with 50Hz bandwidth) and then the imaginary part of the signal is taken to obtain the BPSK modulation. Clock recovery is made with an ML TED and polyphase root-raised cosine filter. Turbo decoding is done with the gr-dslwp blocks, as for the safe mode signal. The decoder can be found <a href="https://github.com/daniestevez/jupyter_notebooks/blob/master/Mars2020/mars2020.grc">here</a>.</p>



<figure><a href="https://destevez.net/wp-content/uploads/2020/08/mars2020_10kbps.png"><img src="https://destevez.net/wp-content/uploads/2020/08/mars2020_10kbps-644x592.png" alt="" width="644" height="592" srcset="https://destevez.net/wp-content/uploads/2020/08/mars2020_10kbps-644x592.png 644w, https://destevez.net/wp-content/uploads/2020/08/mars2020_10kbps-300x276.png 300w, https://destevez.net/wp-content/uploads/2020/08/mars2020_10kbps-768x706.png 768w, https://destevez.net/wp-content/uploads/2020/08/mars2020_10kbps.png 1232w" sizes="(max-width: 644px) 100vw, 644px"></a><figcaption>Mars 2020 10kbps mode GNU Radio decoder flowgraph</figcaption></figure>



<p>The decoder is shown below running. The signal is not very strong, and there are many bit errors, but the Turbo decoder is still able to correct most of them, so the frame error rate is low.</p>



<figure><img width="644" height="355" src="https://destevez.net/wp-content/uploads/2020/08/mars2020_10kbps_running-644x355.png" alt="" srcset="https://destevez.net/wp-content/uploads/2020/08/mars2020_10kbps_running-644x355.png 644w, https://destevez.net/wp-content/uploads/2020/08/mars2020_10kbps_running-300x166.png 300w, https://destevez.net/wp-content/uploads/2020/08/mars2020_10kbps_running-768x424.png 768w, https://destevez.net/wp-content/uploads/2020/08/mars2020_10kbps_running-1536x848.png 1536w, https://destevez.net/wp-content/uploads/2020/08/mars2020_10kbps_running.png 1600w" sizes="(max-width: 644px) 100vw, 644px"><figcaption>Mars 2020 safe mode GNU Radio decoder flowgraph</figcaption></figure>



<h4>Framing</h4>



<p>The framing is the same for the safe mode and 10kbps signals, so it is described here for both. The frames are AOS Space Data Link frames as described in the CCSDS <a href="https://public.ccsds.org/Pubs/732x0b3e1.pdf">AOS Space Data Link Protocol blue book</a>. The frames contain a CRC-16 used to discard frames with uncorrected errors.</p>






<p>In the recordings I have examined, only spacecraft ID 168 and virtual channel 0 are used in the AOS frames. The payload of the frames contains Space Packets (see the CCSDS <a href="https://public.ccsds.org/Pubs/133x0b2.pdf">Space Packet protocol blue book</a>) using the M_PDU protocol.</p>



<p>The Space Packets contain a secondary header which is a 6 byte timestamp using the CUC format (see the <a href="https://public.ccsds.org/Pubs/301x0b4e1.pdf">Time Code Formats blue book</a>). This means that the timestamp is a 48 bit counter, which in this case uses units of \(2^{-16}\) seconds. The epoch for the counter is the J2000 epoch, which is 2000-01-01 12:00:00. I am not sure about the timescale used (UTC, TAI, etc.), since the timestamps are somewhat off with respect to the timestamp in the recording filename.</p>



<h4>Safe mode frames</h4>



<p>Since safe mode frames take so long to transmit, I have only 4 frames extracted from the short recording. The last of them is partly corrupted, due to the signal fading out, so it has incorrect CRC. The frames are shown below, with one frame per row. As we will see later, the blue bands correspond to ASCII text.</p>



<figure><a href="https://destevez.net/wp-content/uploads/2020/08/safe_mode_frames.png"><img width="644" height="130" src="https://destevez.net/wp-content/uploads/2020/08/safe_mode_frames-644x130.png" alt="" srcset="https://destevez.net/wp-content/uploads/2020/08/safe_mode_frames-644x130.png 644w, https://destevez.net/wp-content/uploads/2020/08/safe_mode_frames-300x61.png 300w, https://destevez.net/wp-content/uploads/2020/08/safe_mode_frames-768x155.png 768w, https://destevez.net/wp-content/uploads/2020/08/safe_mode_frames.png 1161w" sizes="(max-width: 644px) 100vw, 644px"></a><figcaption>Mars 2020 safe mode frames</figcaption></figure>



<p>There are 7 space packets in these frames. The first four belong to APID 8, and the remaining three to the idle APID 2047. The packet timestamps, shown below, are quite interesting. We see that the first four packets (which are those in APID 8 having useful data) were generated almost simultaneously and are sent when possible, due to the low data rate. According to the filename, the recording starts on 20:25:19 UTC. The last three packets are idle and presumable have real-time timestamps. The timestamp spacing for these is 45.5 seconds, which is precisely the duration of the frames.</p>



<pre>2020-07-30T20:17:01.899688704
2020-07-30T20:17:01.899719296
2020-07-30T20:17:01.900863616
2020-07-30T20:17:02.899047808
2020-07-30T20:25:58.403961216
2020-07-30T20:26:43.904830976
2020-07-30T20:27:29.405853312</pre>



<p>The APID 2047 idle packets are filled in with an ASCII text as an Easter egg. However, the safe mode frames are too short to contain the full text, so it will be shown later in the 10kbps frames.</p>



<p>The packets in APID 8 contain the following ASCII strings, as well as some binary data</p>



<pre>seqengv
tsfp_15000
seqbg
cbm</pre>



<h4>10kbps mode frames</h4>



<p>A total of 950 frames were extracted from the recording. From these, only 4 have incorrect CRC. The frames can be seen in the figure below. Most of the frames have an idle packet with the Easter egg ASCII text, as shown by the blue bars (the deep blue blocks are ASCII spaces). The more irregular block near the top is a transmission of old telemetry data.</p>



<figure><a href="https://destevez.net/wp-content/uploads/2020/08/10kbps_frames.png"><img width="644" height="549" src="https://destevez.net/wp-content/uploads/2020/08/10kbps_frames-644x549.png" alt="" srcset="https://destevez.net/wp-content/uploads/2020/08/10kbps_frames-644x549.png 644w, https://destevez.net/wp-content/uploads/2020/08/10kbps_frames-300x256.png 300w, https://destevez.net/wp-content/uploads/2020/08/10kbps_frames-768x654.png 768w, https://destevez.net/wp-content/uploads/2020/08/10kbps_frames.png 1156w" sizes="(max-width: 644px) 100vw, 644px"></a></figure>



<p>Below we show the number of frames lost according to the virtual channel frame count.</p>



<figure><a href="https://destevez.net/wp-content/uploads/2020/08/mars2020_frame_loss.png"><img width="644" height="348" src="https://destevez.net/wp-content/uploads/2020/08/mars2020_frame_loss-644x348.png" alt="" srcset="https://destevez.net/wp-content/uploads/2020/08/mars2020_frame_loss-644x348.png 644w, https://destevez.net/wp-content/uploads/2020/08/mars2020_frame_loss-300x162.png 300w, https://destevez.net/wp-content/uploads/2020/08/mars2020_frame_loss.png 717w" sizes="(max-width: 644px) 100vw, 644px"></a></figure>



<p>There are three APIDs active in this recording: APID 2047, which contains idle packets and has 741 packets, APID 9, which contains some real time telemetry and has 58 packets, and APID 247, which contains old telemetry and has 14 packets. The distribution of the packets can be seen well in the figure below, which shows the timestamps classified by APID. We see that most of the time an idle packet is transmitted, with occasional real-time telemetry in APID 9. For some time, old data is transmitted in APID 247, while the real-time APID 9 data continues.</p>



<figure><img width="644" height="333" src="https://destevez.net/wp-content/uploads/2020/08/mars2020_timestamps-644x333.png" alt="" srcset="https://destevez.net/wp-content/uploads/2020/08/mars2020_timestamps-644x333.png 644w, https://destevez.net/wp-content/uploads/2020/08/mars2020_timestamps-300x155.png 300w, https://destevez.net/wp-content/uploads/2020/08/mars2020_timestamps.png 749w" sizes="(max-width: 644px) 100vw, 644px"></figure>



<p>The packets in APID 9 contain data in a format which is difficult to parse. It is a tag-value format in which there is a 2 byte tag describing the type of field and then the field itself. The problem is that the field length is implicit. This can be seen in the block below, which shows the first 64 bytes of the payload of some APID 9 packets in hex. Most of them start by the tag <code>0x027a</code>, then there is a <code>float64</code> value, then the tag <code>0x027d</code> followed by a 32 bit field, the the tag <code>0x027e</code>, etc.</p>



<pre>027a3fc4b0a55e22a0db027d00000000027e00000000027f00007724028000000000028100000000028200000000028300007724
027a3fd487d0f660cd9b027d00000000027e00000000027f00007724028000000000028100000000028200000000028300007724
027a3fd0d90f1448995f027d00000000027e00000000027f00007724028000000000028100000000028200000000028300007724
01f50000000101f60000000001f70000000101f80000000001f90000000101fa0000000001fb0000000101fc0000000001fd0000
027a3fce8f20f40f8c44027d00000000027e00000000027f00007724028000000000028100000000028200000000028300007724
027a3fe1b4b7d417ae74027d00000000027e00000000027f00007724028000000000028100000000028200000000028300007724
027a3fde55f7e8aff142027d00000000027e00000000027f00007724028000000000028100000000028200000000028300007724
027a3fc8294de5246b73027d00000000027e00000000027f00007724028000000000028100000000028200000000028300007724
027a3fd0a779c031d70c027d00000000027e00000000027f00007724028000000000028100000000028200000000028300007724
027a3fd9871585b5416d027d00000000027e00000000027f00007724028000000000028100000000028200000000028300007724</pre>



<p>The problem with parsing this kind of data is guessing the length of each field. However, I have made a heuristic algorithm that doesn‚Äôt do such a bad job. It is based on the fact that often one tag and the next one are related: the second tag ‚Ä¶</p></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://destevez.net/2020/08/decoding-mars-2020/">https://destevez.net/2020/08/decoding-mars-2020/</a></em></p>]]>
            </description>
            <link>https://destevez.net/2020/08/decoding-mars-2020/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26172593</guid>
            <pubDate>Wed, 17 Feb 2021 22:20:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[68% of the top links on Facebook since September are in support of Donald Trump]]>
            </title>
            <description>
<![CDATA[
Score 49 | Comments 76 (<a href="https://news.ycombinator.com/item?id=26172471">thread link</a>) | @smalera
<br/>
February 17, 2021 | https://www.businessofbusiness.com/articles/alt-right-media-thrives-on-facebook-dan-bongino-ben-shapiro/ | <a href="https://web.archive.org/web/*/https://www.businessofbusiness.com/articles/alt-right-media-thrives-on-facebook-dan-bongino-ben-shapiro/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main-section">
    <!-- .sidebar -->

    <section>
      
      

      <p><span>Dan Bongino is, in many ways, the perfect conservative strongman. Muscular and imposing, his mere existence as a voice on the right scores culture war points against the perceived droves of left-wing soyboys. His profiles boast that he is a New York Times bestselling author and former Secret Service agent, a former proximity to the presidency which affords him an air of credibility when talking politics.&nbsp;</span></p>
<p><span>He is also a rampant purveyor of misinformation. His bestselling book, </span><i><span>Spygate: The Attempted Sabotage of Donald Trump</span></i><span> proliferates the disproven conspiracy theory that Barack Obama and Hillary Clinton used spies to attempt to sabotage Trump‚Äôs 2016 campaign. He cast doubt over the effectiveness of masks at the start of the COVID-19 pandemic. His page was a hub of 2020 election conspiracy theories. As recently as February 10, Bongino posted on his Facebook page claiming that Democrats used doctored footage in Trump‚Äôs impeachment trial, a claim which was </span><a href="https://www.politifact.com/factchecks/2021/feb/11/blog-posting/no-house-democrats-impeachment-video-did-not-viola/"><span>quickly disproved</span></a><span>.&nbsp;</span></p>
<p>Despite, or&nbsp;more likely because of all these things, Bongino is one of the most popular figures on Facebook. His page has over 2 million likes and over 3.4 million followers, and its posts, which link to his live show and website, consistently rank among the top-performing links on the site. But Bongino is not the only conservative figure posting misinformation and thriving on Facebook.&nbsp;</p>
<p><span>Kevin Roose, a columnist at the New York Times </span><a href="https://www.nytimes.com/2020/10/29/technology/dan-bongino-has-no-idea-why-facebook-loves-him.html"><span>who has covered Bongino</span></a><span>, has been using the Facebook-owned analytics service Crowdtangle to share the top 10 highest-performing links on Facebook since July 22, 2020 </span><a href="https://twitter.com/FacebooksTop10"><span>on Twitter</span></a><span>. Using Roose‚Äôs data, the Business of Business tracked the top-performing link since September 28 ‚Äî the day before the first televised debate between Donald Trump and Joe Biden took place. The data revealed that throughout the election season and as recently as last week, posts from conservative media figures with histories of spreading misinformation have consistently ranked among the best performing links on the site.</span></p>
<p>In fact, posts from conservative media pages ‚Äî including&nbsp;figures like Bongino and Ben Shapiro, news outlets such as Fox News and Newsmax, and pages in support of Donald Trump such as USA Patriots for Donald Trump ‚Äî made up for 68% of the 880 top performing links on Facebook during the recorded period.</p>
<p>Not every single day since September 28 has been tracked; of the last 137 days since our count began, the list of top-performing links was only provided for 88. The race chart below shows which pages had top-performing links on every recorded day, as well as how many posts from that page were in the top 10.</p>

<p><a href="https://public.flourish.studio/visualisation/4637294/?utm_source=embed&amp;utm_campaign=visualisation/4637294" target="_top"><img alt="Made with Flourish" src="https://public.flourish.studio/resources/made_with_flourish.svg"> </a></p>
<p>Conservative pages performed well throughout the entire recorded period ‚Äî most notably on the days of or after major political events took place.</p>
<p>On September 29, the day of the first Presidential debate, nine of the top 10 performing links came from conservative pages including Fox News, Dan Bongino, Ben Shapiro, Donald Trump and USA Patriots for Donald Trump ‚Äî a trend which continued for the following two debates. On the day of the Vice Presidential Debate, posts from Bongino made up half of the top-performing links on Facebook. By the second Presidential debate, Bongino had eight of the top performing links with the other two belonging to Fox News and CNN.</p>
<p>On election day, posts from Bongino, Trump, Dr. Ben &amp; Candy Carson, and Fox News had seven of the top performing links, with the other three belonging to CNN and Alexandria Ocasio-Cortez. On November 7 ‚Äî the day the Associated Press and several other media outlets began calling the election for Joe Biden ‚Äî Donald Trump was the lone conservative figure with a link in the top 10, with the others belonging to news outlets like CNN, NPR, The New York Times and liberal pundit Rachel Maddow.&nbsp;</p>
<p>However, it only took one day for conservative media to reclaim its spot with the majority of the top-performing posts. By November 9, Donald Trump dominated the top 10 with five posts, with others belonging to Dan Bongino, religious conservative and Trump supporter Franklin Graham, and Newsmax ‚Äî the only odd one out was a single post from then Vice President-Elect Kamala Harris. Twitter and Facebook's suspensions of Donald Trump's accounts and other conservative accounts on January 8&nbsp;only added fuel to&nbsp;the fire ‚Äî just one day later on January 9, Bongino, Shapiro, Fox News, Brietbart and Brigitte Gabriel had seven of the top 10 performing links.</p>
<div><table>
<tbody>
<tr>
<td><b>Facebook Page</b></td>
<td><b>Links in the top 10</b></td>
</tr>
<tr>
<td><strong></strong>Dan Bongino</td>
<td>197</td>
</tr>
<tr>
<td>Fox News</td>
<td>116</td>
</tr>
<tr>
<td>Ben Shapiro</td>
<td>70</td>
</tr>
<tr>
<td>CNN</td>
<td>67</td>
</tr>
<tr>
<td>Donald J. Trump</td>
<td>56</td>
</tr>
<tr>
<td>Franklin Graham</td>
<td>46</td>
</tr>
<tr>
<td>NPR</td>
<td>33</td>
</tr>
<tr>
<td>The New York Times</td>
<td>20</td>
</tr>
<tr>
<td>Newsmax</td>
<td>17</td>
</tr>
<tr>
<td>Occupy Democrats</td>
<td>17</td>
</tr>
<tr>
<td>The Dodo</td>
<td>16</td>
</tr>
<tr>
<td>USA Patriots for Donald Trump</td>
<td>14</td>
</tr>
<tr>
<td>Donald Trump for President</td>
<td>12</td>
</tr>
<tr>
<td>Breitbart</td>
<td>11</td>
</tr>
<tr>
<td>Robert Reich</td>
<td>10</td>
</tr>
<tr>
<td>ForAmerica</td>
<td>9</td>
</tr>
<tr>
<td>Joe Biden</td>
<td>8</td>
</tr>
<tr>
<td>Dios Es Bueno</td>
<td>8</td>
</tr>
<tr>
<td>Dinesh D'Souza</td>
<td>7</td>
</tr>
</tbody>
</table></div>

<p>Though 103 pages had links in the top 10 during the recorded period, a table of the&nbsp;20 pages with the highest volume of top-performing links&nbsp;on Facebook shows the chokehold conservative media has on the platform. Bongino dominates the&nbsp;list not just among conservative figures but across all of Facebook. Links from Bongino‚Äôs page appeared in 84 of the 88 recorded days, with a total count of 197 links. The page with the next-highest volume of links in the top 10 was Fox News with 117, followed by Ben Shapiro with 70.&nbsp;Of the 103 pages with top-performing links, 67 of them only had one or two links appear in a daily top 10.</p>
<p><span>The majority&nbsp;of the top-performing conservative media links came from pundits like Bongino and Shapiro as well as from politicians like Ted Cruz, with slightly less</span><span>&nbsp;coming from conservative media outlets and pages in explicit support of Donald Trump. CNN, NPR and The New York Times are the only non-conservative media outlets to be among the top 10 performing pages during the recorded period with </span>67, 33 and 20<span>&nbsp;of the top-performing links respectively.&nbsp;</span><span>Robert Reich was the top-performing Democratic pundit with only </span>10<span> top-performing posts during the 88 recorded days.</span></p>
<p><span>Ben Shapiro, former editor-at-large of Brietbart and creator of conservative media site The Daily Wire, is well-known across social media for his controversial beliefs, books and show, </span><i><span>The Ben Shapiro Show</span></i><span>. In the past, Shapiro has made several dubious claims, such as when he </span><a href="https://www.politifact.com/factchecks/2014/nov/05/ben-shapiro/shapiro-says-majority-muslims-are-radicals/"><span>falsely argued</span></a><span> that over half of the world‚Äôs Muslim population was radicalized. Shapiro is one of many creators including Steven Crowder, Dave Rubin and others&nbsp;who make up what was once referred to as the "intellectual dark web," a group of right-wing pundits who challenged liberal and democratic beliefs. Many of these creators including Shapiro himself have disavowed the alt-right movement and white supremacist movements, yet <a href="https://arxiv.org/pdf/1908.08313.pdf">studies show</a>&nbsp;their content is often a direct pipeline to online alt-right communities.&nbsp;</span>Conservative media outlet Newsmax also recently received warning that it could face a defamation lawsuit from Dominion Voting Systems for false claims that the company helped rig the election against Donald Trump.</p>
<p>Facebook has made repeated attempts to curb misinformation on the platform, from implementing machine learning to identify false stories to investigating the accuracy of viral stories like the Hunter Biden laptop scandal itself, but to little avail. Misinformation and extreme content is as prevalent on the platform under the new Biden administration as it was during election season last year, and Facebook is <a href="https://about.fb.com/news/2021/02/reducing-political-content-in-news-feed/">only now beginning to restrict</a> the presence of political content in users' newsfeeds overall.</p>
<p>On Wednesday, Facebook announced that it would <a href="https://about.fb.com/news/2021/02/changes-to-sharing-and-viewing-news-on-facebook-in-australia/">remove all news content</a> from the platform in Australia in response to a proposed law which would require the company to pay publishers for every article posted on Facebook. In it, Facebook stated that the company's business gain is minimal, and that news makes up less than 4% of what appears in users' news feeds. However, Facebook did not provide a definition of what it considers to be "news" content. Posts from Bongino, Shapiro and others may not be considered strictly "news" by Facebook, but they often dress themselves up as&nbsp;such, looking nearly indistinguishable visually from average news articles. To their followers, Bongino's and Shapiro's posts are viewed as more credible than if they came from a mainstream media outlet ‚Äî A 2020 survey from Pew Research Center found that one in five U.S. adults get their news primarily through social media, and that these adults are typically less informed or more susceptible&nbsp;to misinformation.&nbsp;</p>
<p>Regardless of whether the 4% figure is correct, Facebook pages that post political or news content made up for 17 of the top 20 performing pages during the recorded period. Fox News, which can be considered a&nbsp;news source by most standards, is the second-most popular page on Facebook in terms of link performance. Regardless of whether Facebook has a significant business benefit from news content or not, the prevalence and success of it on the platform is enough to support entire businesses and ecosystems, like Bongino's and other "intellectual dark web" figures.</p>
<p>Bongino himself isn‚Äôt sure why he‚Äôs so popular on Facebook. ‚ÄúWe don‚Äôt use bots. We don‚Äôt even advertise much on Facebook,‚Äù Bongino told Roose in an October interview. ‚ÄúIf I told you I spent 10 minutes on analytics over the past year, I‚Äôd be lying.‚Äù</p>
<p>Much of Bongino‚Äôs content plays into the narrative that conservatives are being silenced by politicians and tech platforms. When Twitter banned Donald Trump‚Äôs account on January 8, Bongino was wrapped up in the crossfire. His account was suspended for 12 hours, which prompted him to leave the platform entirely in an act of protest. Bongino told Roose that he is preparing to be removed from Facebook for ideological reasons as well, and Facebook's recent decision to curb the amount of political content in newsfeeds may end up denting Bongino's empire. But in the meantime, he and his fellow pundits are thriving and have a near-complete control over which links get the ‚Ä¶</p></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.businessofbusiness.com/articles/alt-right-media-thrives-on-facebook-dan-bongino-ben-shapiro/">https://www.businessofbusiness.com/articles/alt-right-media-thrives-on-facebook-dan-bongino-ben-shapiro/</a></em></p>]]>
            </description>
            <link>https://www.businessofbusiness.com/articles/alt-right-media-thrives-on-facebook-dan-bongino-ben-shapiro/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26172471</guid>
            <pubDate>Wed, 17 Feb 2021 22:08:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Visualization of 40M Cell Towers]]>
            </title>
            <description>
<![CDATA[
Score 481 | Comments 135 (<a href="https://news.ycombinator.com/item?id=26169747">thread link</a>) | @alprc
<br/>
February 17, 2021 | https://alpercinar.com/open-cell-id/ | <a href="https://web.archive.org/web/*/https://alpercinar.com/open-cell-id/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

<!-- <hr> -->

<p>
	
	<a href="https://www.opencellid.org/">OpenCelliD</a> is the world's largest 
	open database of cell towers with a license
	<a href="https://creativecommons.org/licenses/by-sa/4.0/">CC BY-SA 4.0</a>
</p>

<p>
	Data has full world coverage and freely available for
	<a href="https://www.opencellid.org/">download.</a>
</p>

<p>
	This tabular data[1] has ~40 million rows and 6 columns in it but only 3
	columns (latitude, longitude, and type) are used in this visualization.
</p>

<p><a href="https://alpercinar.com/open-cell-id/csv.png" target="_blank">
	<img src="https://alpercinar.com/open-cell-id/csv.png" alt="">
</a>

<em>[1] Structure of input data.</em></p><p>
	Above table data is read line by line and grouped by their location info.
	Grouping is done as if they were <a href="https://developers.planet.com/planetschool/xyz-tiles-and-slippy-maps/">XYZ Tiles.</a></p>


<p>
	First, empty 2d integer arrays for each tile are created and its elements are 
	initialized with value = 0. 
	Those values hold a counter that shows the number of rows that 
	geographically contained in that pixel.
	Every row increases the relevant counter by one[2]. 
	After iterating all rows with this method, we end up with a bunch of
	integer values (in different 2d arrays) that represent row counts per region.
</p>

<p><a href="https://alpercinar.com/open-cell-id/step2.png" target="_blank">
	<img src="https://alpercinar.com/open-cell-id/step2.png" alt="">
</a>
<em>[2] Each row increases relevant counter.</em></p><p>
	In order to achieve city-level resolution for visualization, tiles up to
	zoom level 9 should be generated. 
	<a href="https://www.maptiler.com/google-maps-coordinates-tile-bounds-projection/">
	For XYZ tiles, the number of tiles per zoom level is 4^zoom.</a>
	Therefore, for zoom levels between 0 to 9, the number of tiles that should be generated 
	becomes 4^0 + 4^1 + 4^2 + .. + 4^9 which equals to 349525.
	Every tile has 256x256 integer values.
	Even with using 32 bit-sized integer values, 
	one tile occupies 256 * 256 * 32 bit = 256 kilobytes of storage,
	and <b>349525 tiles</b> occupies <b>87 gigabytes of storage</b> which is 
	definitely not acceptable.
</p>

<p>
	To solve this size problem every tile blob is compressed independently
	with a modern compression algorithm 
	<a href="https://github.com/google/brotli">brotli</a>.
	Despite being slow to encode, brotli has a fast decoding speed and high compression ratio
	compared to older compression methods like gzip. Additionally, 
	brotli-compressed-data is <a href="https://caniuse.com/#search=brotli">
	natively decodable with all modern browsers</a>.
	Since there are no cell towers in oceans or uninhabitable areas, tiles for those regions 
	are full of zero values or very sparse. Due to this high redundancy,
	compression performed extremely well for those regions (256kb compressed to 20~100bytes).
</p>

<p>
    In order to simplify the algorithm, it is described as if there was only one 
    counter value in each pixel, but there are 4 counter values per pixel each
    holding number of row counts for different cell tower types[3]
</p>


<p><a href="https://alpercinar.com/open-cell-id/step3.png" target="_blank">
	<img src="https://alpercinar.com/open-cell-id/step3.png" alt="">
</a>
<em>[3] Every pixel stores more than one channels (counter)</em></p><p>
    Even though these tiles are stored like XYZ tiles, they are not 
    valid XYZ tiles.Since these blobs are just brotli-compressed-integer-arrays.
    Visualization requires a blob to image conversion. This conversion is
    done by client side javascript and HTML5 Canvas API.
</p>

<p>
    Underlying map displaying library in this visualization is
    <a href="https://leafletjs.com/" target="_blank">leaflet</a>.
    Kudos to leaflet author(s) for writing such a well documented and extendable
    map library, I was able to write a custom tile layer for leaflet that 
    intercepts the image tile requests made by leaflet and redirects those
    image tile requests to an image generating (client-side) web worker that 
    works like a tile server. Web worker follows a simple algorithm for image generation.

    It reads the row count values pixel by pixel and generates a color for that
    pixel (higher the row count lighter and more opaque the pixel color).
</p>
<p>
    To summarize, this was a fun project for me to work on and I learned a lot 
    about data compression and multi-threading while working on this. 
    By off-loading compute-intensive tasks to web-workers, very impressive visualizations
    can be made even without sacrificing a single FPS drop on UI thread. 
</p>


</div></div>]]>
            </description>
            <link>https://alpercinar.com/open-cell-id/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26169747</guid>
            <pubDate>Wed, 17 Feb 2021 18:29:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Passwordless Logins with Yubikey]]>
            </title>
            <description>
<![CDATA[
Score 98 | Comments 64 (<a href="https://news.ycombinator.com/item?id=26169369">thread link</a>) | @adl1995
<br/>
February 17, 2021 | https://adl1995.github.io/passwordless-logins-with-yubikey.html | <a href="https://web.archive.org/web/*/https://adl1995.github.io/passwordless-logins-with-yubikey.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Yubikey is currently the de facto device for <span>U2F</span> authentication. It enables adding an extra layer of security on top of <span>SSH</span>, system login, signing <span>GPG</span> keys, and so on. It is also compatible with several other authentication methods, such as WebAuthn and <span>PAM</span>.</p>
<p>This post will show how to leverage your Yubikey for unlocking the system lock-screen, both with and without using a password. It will then delve into how to automatically lock the screen when the Yubikey is&nbsp;unplugged.</p>
<p>To achieve logins with Yubikeys we require a <span>PAM</span> configuration. <span>PAM</span> or Pluggable Authentication Modules define the authentication flow for common Linux utilities, such as <code>sudo</code>, <code>su</code>, and <code>passwd</code>. We will override the default authentication flow for the <a href="https://linux.die.net/man/1/xlock">xlock</a> lock manager to allow logins with&nbsp;Yubikey.</p>
<blockquote>
<p>Note: The above process should be similar across most lock managers, such as <code>i3lock</code> or <code>xscreensaver</code>.</p>
</blockquote>
<h2>Creating a <span>PAM</span>&nbsp;configuration</h2>
<p>We shall first replicate the default authentication provided with xlock using <span>PAM</span>. With this configuration the user should only be able to log in with their&nbsp;password.</p>
<p>All <span>PAM</span> configuration files lie under the <code>/etc/pam.d/</code> directory. We create a file named <code>xlock</code> which replicates the default&nbsp;authentication:</p>
<div><pre><span></span><code>$ cat /etc/pam.d/xlock
<span>#%PAM-1.0</span>
auth            include         system-auth
</code></pre></div>
<blockquote>
<p>Note: For the above configuration file to take effect the tool (<code>xlock</code>) must be <span>PAM</span> compatible. We can confirm that <code>xlock</code> is <span>PAM</span> compatible by inspecting the output of <code>ldd /usr/bin/xlock | grep libpam.so</code>.</p>
</blockquote>
<p>The first comment line indicates the <span>PAM</span> version. The lines that follow define the authentication&nbsp;flow:</p>
<ul>
<li><code>auth</code> is the module interface responsible for verifying the user‚Äôs&nbsp;password.</li>
<li><code>include</code> is the <span>PAM</span> control flag which <em>includes</em> the <code>system-auth</code> configuration file (this file defines the default authentication flow). This flag can also be used to load modules, as we shall see&nbsp;later.</li>
</ul>
<blockquote>
<p>Note: There is an excellent <a href="https://access.redhat.com/documentation/en-us/red_hat_enterprise_linux/6/html/managing_smart_cards/pam_configuration_files">documentation</a> provided by RedHat on <span>PAM</span> configuration&nbsp;files.</p>
</blockquote>
<h3>Supporting Yubikey&nbsp;logins</h3>
<p>We shall now add Yubikey login functionality to our <span>PAM</span> configuration, but we first need to install the Yubico module for <span>PAM</span> and set it&nbsp;up.</p>
<p>Yubico, the company behind Yubikeys, exposes the <a href="https://developers.yubico.com/yubico-pam/">pam_yubico.so</a> module which can be used for Yubikey&nbsp;authentication.</p>
<p>It provides two authentication mechanisms, the <code>client</code> mode and the <code>challenge-response</code> mode. The <code>client</code> mode sends a request to the Yubico server for verifying the user‚Äôs <span>OTP</span>, and requires an active Internet connection for the user to login. As this is inconvenient we shall only explore the <code>challenge-response</code> mode in this&nbsp;post.</p>
<p>Before proceeding with the configuration the <code>pam_yubico</code> package must be installed manually. This package is easily available across most Linux distributions. On Arch Linux it can be installed&nbsp;with:</p>

<p>We next add Yubikey mappings before setting the challenge-response&nbsp;credential.</p>
<blockquote>
<p>Warning: It is recommended that you use a secondary account to perform the next steps as there is a risk of permanently locking your account (in case of <span>PAM</span>&nbsp;misconfiguration).</p>
</blockquote>
<h4>Adding&nbsp;mappings</h4>
<p>Each Yubikey must be paired with a unique public <span>ID</span> which the <code>pam_yubico</code> module uses to uniquely identify the user. The public <span>ID</span> consists of the first 12 characters extracted from the <span>OTP</span>&nbsp;token.</p>
<p>To obtain your Yubikey‚Äôs public <span>ID</span> open up your shell and press the Yubikey button. You will see a similar output as&nbsp;below:</p>
<div><pre><span></span><code><span>vvctffbvkhdnliklfhbbfiecudthfvrvuhnhtirehidr</span>
</code></pre></div>
<p>Now copy take the first 12 characters (<code>vvctffbvkhdn</code>) and add them to a file named <code>yubikey_mappings</code> in the <code>/etc/</code> directory, along with your username. In our case this will&nbsp;be:</p>
<div><pre><span></span><code>$ cat /etc/yubikey_mappings
adeel:vvctffbvkhdn
</code></pre></div>
<blockquote>
<p>Note: This file also allows specifying multiple Yubikey mappings, each separated by a new&nbsp;line.</p>
</blockquote>
<h4>Setting the challenge response&nbsp;credential</h4>
<p>Yubikey needs to somehow verify the generated <span>OTP</span> (One Time Password) when it tries to authenticate the user. It does so by using the <code>challenge-response</code> mode.</p>
<p>To set up the <code>challenge-response</code> mode, we first need to install the Yubikey manager tool called <code>ykman</code>. On Arch Linux it can be installed&nbsp;with:</p>
<div><pre><span></span><code>$ pacman -S yubikey-manger
</code></pre></div>
<p>The <code>ykman</code> tool will generate a secret credential and store it in a local file. Whenever the user tries to login with <code>xlock</code>, the <code>pam_yubico</code> module will verify the generated <span>OTP</span> against the stored&nbsp;credential.</p>
<p>The challenge response credential can be set on slot 2 of the Yubikey&nbsp;with:</p>
<div><pre><span></span><code>$ ykman otp chalresp --generate <span>2</span>
Using a randomly generated key: 29eb38b6f50b246c46f954af9710a77c78792114
Program a challenge-response credential in slot <span>2</span>? <span>[</span>y/N<span>]</span>: y
</code></pre></div>
<blockquote>
<p>Warning: Ensure that the slot you‚Äôre writing the data to doesn‚Äôt already contain any credential, as it might not be&nbsp;recoverable!</p>
</blockquote>
<p>After the <code>challenge-response</code> credential is set it needs to be written to a local file which will be later read by <code>pam_yubico</code>.</p>
<p>Yubico provides another tool called <code>ykpamcfg</code> (which should be bundled with the <code>yubikey-manger</code> package) to write this file to disk. It takes the Yubikey slot number as its parameter and writes the secret to a&nbsp;file:</p>
<div><pre><span></span><code>$ ykpamcfg -2
Stored initial challenge and expected response in <span>'/home/adeel/.yubico/challenge-&lt;Serial ID&gt;'</span>.
</code></pre></div>
<h3>Updating the Linux <span>PAM</span>&nbsp;configuration</h3>
<p>We shall now update the <code>/etc/pam.d/xlock</code> file and add the Yubico <span>PAM</span> at the very&nbsp;beginning.</p>
<div><pre><span></span><code>$ cat /etc/pam.d/xlock
<span>#%PAM-1.0</span>

auth  sufficient  pam_yubico.so debug <span>mode</span><span>=</span>challenge-response <span>authfile</span><span>=</span>/etc/yubikey_mappings
auth  include     system-auth
</code></pre></div>
<p>We pass three parameters to the <code>pam_yubico.so</code> module:</p>
<ul>
<li><code>debug</code> prints all the authentication steps to the console when the ‚ÄòEnter‚Äô key is&nbsp;pressed.</li>
<li><code>mode</code> specifies which mode the module will use for authentication (<code>challenge-response</code> or <code>client</code>).</li>
<li><code>authfile</code> points to the credential file written by the <code>ykpamcfg</code> tool. </li>
</ul>
<p>Setting the module type to <code>sufficient</code> means that if Yubikey authentication succeeds, no further steps will be processed and the user will get logged in. This is the key point which enables passwordless logins. However, in the event of authentication failure, remaining authentication steps will still be applied, i.e. the user can still log in with their password if the Yubikey is not plugged&nbsp;in.</p>
<p>If the module type is set to <code>required</code> instead of <code>sufficient</code> it will enable Two-Factor Authentication (<span>2FA</span>) which will require the user to plug in their Yubikey <em>and</em> enter their password to&nbsp;login.</p>
<blockquote>
<p>Note: For passwordless logins the user will need to press the <code>Enter</code> with their Yubikey plugged in to unlock their&nbsp;screen.</p>
</blockquote>
<p>At this stage you should be able unlock your screen with they&nbsp;Yubikey.</p>
<blockquote>
<p>Note: You may need to replug your Yubikey for the changes to take&nbsp;effect.</p>
</blockquote>
<h2>Automatically locking the screen when Yubikey is&nbsp;unplugged</h2>
<p>Up till locking the screen still requires manually invoking the <code>xlock</code> command. It would be nice if we can somehow automatically lock the screen whenever our Yubikey is unplugged. We can achieve this with&nbsp;Udev.</p>
<p>Udev is the device manager used in Linux which can be used for a myriad of tasks. It tracks the state changes for all external devices, for example, it can be used to identify when a <span>USB</span> device is plugged or unplugged. Each device outputs a series of attributes which can be used to uniquely identify&nbsp;it.</p>
<p>We shall use these attributes to create a Udev rule which triggers an <code>xlock.service</code> Systemd service when the Yubikey is&nbsp;unplugged.</p>
<blockquote>
<p>Note: We can also achieve this with a Shell script instead of Systemd, but Udev discourages executing long-running programs using scripts as it terminates them after a certain time&nbsp;period.</p>
</blockquote>
<h3>Creating the Systemd&nbsp;service</h3>
<p>Systemd is the Linux service manager which can be used to launch user processes. We create a file named <code>xlock.service</code> in the <code>/etc/systemd/system/</code> directory:</p>
<div><pre><span></span><code>$ cat /etc/systemd/system/xlock.service
<span>[</span>Unit<span>]</span>
<span>Description</span><span>=</span>xlock

<span>[</span>Service<span>]</span>
<span>User</span><span>=</span>adeel
<span>Type</span><span>=</span>simple
<span>Environment</span><span>=</span><span>DISPLAY</span><span>=</span>:0
<span>ExecStart</span><span>=</span>/usr/bin/xlock 

<span>[</span>Install<span>]</span>
<span>WantedBy</span><span>=</span>multi-user.target
</code></pre></div>
<ul>
<li>The <code>Type=simple</code> implies that this service does not exit after&nbsp;execution.</li>
<li>The <code>Environment</code> tag specifies which display should be locked (<code>0</code> is the default&nbsp;display).</li>
<li>The <code>ExecStart</code> tag takes a path of the binary or script it will&nbsp;execute.</li>
</ul>
<blockquote>
<p>Note: Consult the <a href="https://www.freedesktop.org/software/systemd/man/systemd.service.html">official docs</a> to explore Systemd in&nbsp;detail.</p>
</blockquote>
<h3>Creating the Udev&nbsp;rule</h3>
<p>We first need to identify a set of unique attributes for our device (Yubikey). The <code>udevadm</code> tool allows monitoring Udev output whenever a device state changes. We shall invoke the following command and then remove our&nbsp;Yubikey:</p>
<div><pre><span></span><code>$ udevadm monitor --environment --udev 
monitor will print the received events <span>for</span>:
UDEV - the event which udev sends out after rule processing

UDEV  <span>[</span><span>461872</span>.738673<span>]</span> remove   /devices/pci0000:00/0000:00:14.0/usb1/1-2/1-2.1/1-2.1:1.0/0003:1050:0407.0157/input/input294/event18 <span>(</span>input<span>)</span>
<span>ACTION</span><span>=</span>remove
<span>ID_VENDOR</span><span>=</span>Yubico
<span>SUBSYSTEM</span><span>=</span>input
<span>DEVNAME</span><span>=</span>/dev/input/event18
<span>ID_INPUT_KEY</span><span>=</span><span>1</span>
...
</code></pre></div>
<p>We only show a truncated output above, but once you have identified the attributes you would like to use, create a file named <code>yubikey-actions.rules</code> in the <code>/etc/udev/rules.d/</code> directory:</p>
<div><pre><span></span><code>$ cat /etc/udev/rules.d/yubikey-actions.rules 
<span>ACTION</span><span>==</span><span>"remove"</span>, ENV<span>{</span>ID_MODEL_ID<span>}==</span><span>"0407"</span>, ENV<span>{</span>ID_VENDOR_ID<span>}==</span><span>"1050"</span>, <span>RUN</span><span>+=</span><span>"/usr/bin/systemctl start xlock.service"</span>
</code></pre></div>
<p>It might be worthwhile to reload the configuration for both Systemd and&nbsp;Udev:</p>
<div><pre><span></span><code>$ systemctl daemon-reload
$ udevadm control --reload
</code></pre></div>
<p>If everything worked out fine your screen should now get locked whenever you remove your&nbsp;Yubikey.</p>
<h2>References:</h2>
<ul>
<li><a href="https://fedoraproject.org/wiki/Using_Yubikeys_with_Fedora#Using_a_Yubikey_to_authenticate_to_a_machine_running_Fedora">Using a Yubikey to authenticate to a machine running&nbsp;Fedora</a></li>
<li><a href="https://ocramius.github.io/blog/yubikey-for-ssh-gpg-git-and-local-login/">YubiKey for <span>SSH</span>, Login, <span>2FA</span>, <span>GPG</span> and Git&nbsp;Signing</a></li>
<li><a href="http://blog.fraggod.net/2015/01/12/starting-systemd-service-instance-for-device-from-udev.html">Starting systemd service instance for device from&nbsp;udev</a></li>
</ul></div></div>]]>
            </description>
            <link>https://adl1995.github.io/passwordless-logins-with-yubikey.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26169369</guid>
            <pubDate>Wed, 17 Feb 2021 17:59:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[RetroForth 2021.1]]>
            </title>
            <description>
<![CDATA[
Score 130 | Comments 52 (<a href="https://news.ycombinator.com/item?id=26168640">thread link</a>) | @mindcrime
<br/>
February 17, 2021 | http://forthworks.com/retro | <a href="https://web.archive.org/web/*/http://forthworks.com/retro">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>[DIR] <a href="http://forthworks.com/">Forthworks</a>
______________________________________________________________________

RETRO is a clean, elegant, and pragmatic dialect of Forth. It provides
a simple alternative for those willing to make a break from legacy
systems.

The language draws influences from many sources including traditional 
Forth systems, cmForth, colorForth, Factor, and Parable. It was
designed to be easy to grasp and adapt to specific uses.

The basic language is very portable. It runs on a tiny virtual
machine (Nga), which is written in C. There are multiple interface
options, the main one (rre) is buildable with just the standard C
compiler and libraries on most systems.
______________________________________________________________________

Source Code

These include source code, documentation, and examples.

 BIN  <a href="http://forthworks.com/retro/r/latest.tar.gz">Nightly Snapshot (.tar.gz)</a>

 BIN  <a href="http://forthworks.com/retro/r/RETRO12-2021.2.tar.gz">Latest Release (2021.2, .tar.gz)</a>
 TXT  <a href="http://forthworks.com/retro/r/RETRO12-2021.2.tar.gz.sig">Signature for Latest Release</a>
 TXT  <a href="http://forthworks.com/retro/r/RETRO12-2021.2.tar.gz.pub">Public Key for Latest Release</a>

[DIR] <a href="http://forthworks.com/retro/r">Prior Versions</a>
______________________________________________________________________

Documentation

 TXT  <a href="http://forthworks.com/retro/r/RETRO12-2021.2.epub">RETRO Handbook (epub)</a>

You can view the glossary via Gopher or HTTP. This is served off the
latest documentation in the repository by a server written in RETRO.

[DIR] <a href="http://forthworks.com/">Glossary Browser (gopher)</a>
 HTM  <a href="http://forthworks.com:9999/">Glossary Browser (http)</a>
 TXT  <a href="http://forthworks.com/retro/s/doc/Glossary.txt">Glossary (text)</a>
______________________________________________________________________

Repository

Development is tracked using a Fossil repository.

Clone the repo:

  fossil clone http://forthworks.com:8000 retro.fossil

And open it:

  mkdir retro
  cd retro
  fossil open /path/to/retro.fossil

Mirrors of the repo are available via git.

 HTM  <a href="https://git.sr.ht/~crc_/retroforth">https://git.sr.ht/~crc_/retroforth</a>
 HTM  <a href="https://github.com/crcx/retroforth">https://github.com/crcx/retroforth</a>

I generate nightly snapshots of the development version.

 BIN  <a href="http://forthworks.com/retro/r/latest.tar.gz">Nightly Snapshot</a>
 TXT  <a href="http://forthworks.com/retro/changes.txt">Latest Changes (updates hourly)</a>
______________________________________________________________________

Packages &amp; Ports

NetBSD pkgsrc: lang/forth-retro
LiteBSD: lang/retro12
FreeBSD: lang/retro12
Milis Linux: "mps kur retro12" (or build-install "mps derle retro12")
______________________________________________________________________

Commercial Versions

I develop and maintain versions for iOS and macOS. These run the same
image and virtual machine as all of the other systems, but add a
custom editor-centric interface and some additional words to make
them more useful on their respective platforms.

 HTM  <a href="https://itunes.apple.com/us/app/retro-forth/id1317494014?ls=1&amp;mt=12">RETRO for macOS</a>
 HTM  <a href="https://itunes.apple.com/us/app/retro-forth-12/id1170943580?ls=1&amp;mt=8">RETRO for iOS</a>
______________________________________________________________________

Patreon

I have a Patreon at https://www.patreon.com/_crc for those that want
to financially support development. All funds raised are put into
development related expenses (server expenses, app store fees,
hardware, etc).

Thanks go out to my current and past patrons:

- Kiyoshi YONEDA
- Krinkleneck
- Rick Carlino
- Scott McCallum
______________________________________________________________________

Discussion

I can be reached:

- @crcx on Twitter
- @crc@mastodon.social on Mastodon
- /r/forth on reddit (/u/_crc)
- /u/crc_ on lobste.rs
- #retro on irc.freenode.net (look for crc)

The IRC channel is logged at http://tunes.org/~nef/logs/retro and a
mirror is provided via gopher:

[DIR] <a href="http://forthworks.com/retro/irc-logs">IRC Channel Logs</a>
</p></div>]]>
            </description>
            <link>http://forthworks.com/retro</link>
            <guid isPermaLink="false">hacker-news-small-sites-26168640</guid>
            <pubDate>Wed, 17 Feb 2021 17:06:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[QCovid: Personal Covid-19 risk calculator developed by Oxford University]]>
            </title>
            <description>
<![CDATA[
Score 29 | Comments 13 (<a href="https://news.ycombinator.com/item?id=26168403">thread link</a>) | @bananapear
<br/>
February 17, 2021 | https://qcovid.org/Calculation | <a href="https://web.archive.org/web/*/https://qcovid.org/Calculation">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <header>
            <nav>
                <div>
                    <div>
                        <p><a href="https://qcovid.org/">
                            <img src="https://qcovid.org/img/oxweb-logo-rect.svg" alt="University of Oxford">
                            <img src="https://qcovid.org/img/Logo_qcovid.svg" alt="QCovid">
                        </a>
                        </p>
                    </div>
                </div>
            </nav>
        </header>
        <div>
            <main role="main">
                
<h2>Please scroll to accept licence</h2>



<p>
    These licence terms apply to all licences granted by THE CHANCELLOR, MASTERS
    AND SCHOLARS OF THE UNIVERSITY OF OXFORD whose administrative offices are at
    University Offices, Wellington Square, Oxford OX1 2JD, United Kingdom ("the
    University") for use of or access to the QCovid Algorithm ("the Algorithm") through this website.
</p>

<p>
    By requesting access to the Algorithm through this Website
    <a href="https://qcovid.org/">https://qcovid.org/</a>
    ("the Website"), you ("the User") agree that
    your use of the Algorithm is subject to these licence terms and that you will
    use the Algorithm only in accordance with these licence terms.

</p>

<div>

    <p>
        Please read these licence terms carefully before using the algorithm.  If
        you do not agree to these licence terms you must not request access and
        you must not use the algorithm.
    </p>

    <p>
        The algorithm may be used only for academic research or for the purpose of
        peer review. The algorithm must not be used for any of the following:
    </p>

    <ul>
        <li>carrying out any clinical trial;</li>
        <li>
            carrying out any research with a view to commercialising or exploiting
            the algorithm or any derivative work, variation or adaptation of
            the algorithm;
        </li>
        <li>any other commercial purpose; or</li>
        <li>creating any derivative work, variation or adaptation of the algorithm.</li>
    </ul>

    <p>
        You must not distribute or share the use of the algorithm or any derivative
        work, variation or adaptation of the algorithm with any other person
    </p>

</div>

<ol>
    <li><b>ACADEMIC USE LICENCE</b>
        <ol>
            <li>The User is granted a non-exclusive, non-transferable, royalty 
                free licence to access and use the Algorithm provided that the User:
                <ol>
                    <li>uses the Algorithm only for academic research or for 
                        the purpose of peer review;</li>
                    <li>does not use the Algorithm for carrying out any clinical trial;</li>
                    <li>does not use the Algorithm for carrying out any 
                        research with a view to commercialising or exploiting
                        the Algorithm or any derivative work, variation or 
                        adaptation of the Algorithm;</li>
                    <li>does not use the Algorithm for any other commercial purpose;</li>
                    <li>does not, and does not attempt to, use the Algorithm to 
                        create any derivative work, variation, modification or 
                        adaptation of the Algorithm;</li>
                    <li>does not distribute or share the use of the Algorithm or 
                        any derivative work, variation or adaptation of the Algorithm 
                        with any other person.</li>
                    <li>does not use the Algorithm for or on behalf of any third party
                        or to provide any service;</li>
                    <li>does not integrate all or part of the Algorithm into any product;</li>
                    <li>uses the Algorithm only in accordance with any instructions 
                        and guidance for use of the Algorithm given on the Website;</li>
                    <li>complies with the procedures on the Website in relation to 
                        user identification, authentication and access to the 
                        Algorithm or the Website;</li>
                    <li>complies with all applicable laws and regulations relating 
                        to the use of the Algorithm and the Website (or either of them);</li>
                    <li>does not, and does not attempt to, create any derivative work 
                        from, or any variation, modification or of adaptation of, or frame,
                        mirror, republish, download, display, transmit, or distribute all
                        or any part of the Website in any form or media or by any means; 
                        and</li>
                    <li>ensures that, whenever the Algorithm is referred to in any peer 
                        review, research publication or other document or other material,
                        the Copyright Notice "Copyright ¬© 2020, University of Oxford" 
                        appears prominently.</li>
                </ol>
            </li>
            <li>The University reserves the right, at any time and without liability 
                and without giving notice to the User, to: cease publishing the Algorithm;
                to revise, modify or replace the Algorithm; to change the operation of 
                the Website; and to deny or suspend access to the Algorithm and the 
                Website (or either of them).
            </li>
            <li>The University reserves the right, at any time and without liability, 
                to change these licence terms.
            </li>
            <li>The User acknowledges and agrees that the University owns any and all
                intellectual property rights in the Algorithm and in any and all results
                or other output from the use of the Algorithm (except any peer review or
                research publication).
            </li>
            <li>The licence granted in clause 1.1 above will terminate automatically and
                immediately, and the User will no longer have any right to use the Algorithm,
                on any breach of the licence terms.
            </li>
        </ol>
    </li>
    <li><b>INDEMNITY AND LIABILITY</b>
        <ol>
            <li>The User shall defend, indemnify and hold harmless the University against
                any and all claims, actions, proceedings, losses, damages, expenses and 
                costs (including, without limitation, court costs and reasonable legal fees)
                arising out of or in connection with the User's possession or use of the 
                Algorithm, or any breach of these licence terms by the User.
            </li>
            <li>The Algorithm and the Website are provided on an √¢‚Ç¨Àúas is√¢‚Ç¨‚Ñ¢ basis and the
                User uses the Algorithm at their at their own risk. No representations, 
                conditions, warranties or other terms of any kind are given in respect of
                the Algorithm and all statutory warranties and conditions are excluded to
                the fullest extent permitted by law. Without affecting the generality of 
                the previous sentences, the University gives no implied or express warranty
                and makes no representation that the Algorithm: (a) will enable specific results
                to be obtained; or (b) meets a particular specification or is comprehensive 
                within its field or that it is error free or will operate without 
                interruption; or (c) is suitable for any particular, or the User's 
                specific, purpose.
            </li>
            <li>Except in relation to fraud, and death or personal injury caused by 
                negligence, the University will not be liable to the User in 
                connection with the Algorithm or the Website, in negligence or 
                arising in any other way, for: (a) any indirect or consequential 
                damage or loss; or (b) for any loss of profits, loss of revenue, 
                loss of data, loss of contracts or loss of opportunity, in each case 
                whether direct or indirect.
            </li>
            <li>The User irrevocably undertakes to the University not to bring any 
                claim against any employee, student, researcher or other individual 
                engaged by the University, that seeks to enforce against any of them 
                any liability whatsoever in connection with the Algorithm or the Website.
            </li>
        </ol>
    </li>
    <li><b>GENERAL</b>
        <ol>
            <li>Severability - If any provision (or part of a provision) of these licence 
                terms is found by any court or other body of competent jurisdiction to be
                invalid, unenforceable or illegal, the other provisions (or the other 
                parts of that provision) shall remain in full force and effect.
            </li>
            <li>Entire Agreement - These licence terms constitute the entire agreement 
                between the University and the User and supersede all previous arrangements,
                understandings and agreements between them relating to the Algorithm. The
                User acknowledges that it has not been induced to agree to these licence 
                terms or to use the Algorithm or the Website by any representation, statement
                or warranty (whether oral, or in writing) made by or on behalf of the 
                University and waives all claims for breach of any warranty and all
                claims for any misrepresentation, (negligent or of any other kind, 
                unless made by the University fraudulently).
            </li>
            <li>Law and Jurisdiction - These licence terms and their validity and any
                dispute or claim arising out of or in connection with them or the 
                Algorithm or the Website (including any non-contractual dispute or 
                claim) shall be governed by, and shall be construed in accordance 
                with, the laws of England and Wales. The User irrevocably submits 
                to the exclusive jurisdiction of the English courts in respect of 
                any dispute or claim that arises out of or in connection with these
                licence terms or the Algorithm or the Website.
            </li>
        </ol>
    </li>
</ol>

<p>
    If you are interested in using the Algorithm in a way not permitted by these licence terms,
    please contact Oxford University Innovation Limited to discuss obtaining an appropriate licence.
    Contact details are 
    <a href="mailto:enquiries@innovation.ox.ac.uk">enquiries@innovation.ox.ac.uk</a> 
    quoting reference [17939].
</p>


            </main>
        </div>

        
    </div></div>]]>
            </description>
            <link>https://qcovid.org/Calculation</link>
            <guid isPermaLink="false">hacker-news-small-sites-26168403</guid>
            <pubDate>Wed, 17 Feb 2021 16:45:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: An Event Sourced Minesweeper]]>
            </title>
            <description>
<![CDATA[
Score 83 | Comments 24 (<a href="https://news.ycombinator.com/item?id=26166595">thread link</a>) | @david-farr
<br/>
February 17, 2021 | https://dfarr.github.io/minesweeper | <a href="https://web.archive.org/web/*/https://dfarr.github.io/minesweeper">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://dfarr.github.io/minesweeper</link>
            <guid isPermaLink="false">hacker-news-small-sites-26166595</guid>
            <pubDate>Wed, 17 Feb 2021 14:28:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Coronavirus human challenge study gets green light in UK]]>
            </title>
            <description>
<![CDATA[
Score 113 | Comments 184 (<a href="https://news.ycombinator.com/item?id=26166556">thread link</a>) | @timthorn
<br/>
February 17, 2021 | https://www.politico.eu/article/worlds-first-coronavirus-human-challenge-study-gets-green-light-in-uk/ | <a href="https://web.archive.org/web/*/https://www.politico.eu/article/worlds-first-coronavirus-human-challenge-study-gets-green-light-in-uk/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
									<p>The U.K. is set to begin the world‚Äôs first trial of healthy volunteers being intentionally infected with coronavirus, after the study received ethics approval.&nbsp;</p>
<p>The so-called human challenge study will begin within a month, said the U.K. Department for Business, Energy and Industrial Strategy in a statement Wednesday, with up to 90 people being exposed to a very small amount of coronavirus in a safe and controlled environment. These kinds of trials are controversial as they expose healthy volunteers to diseases that may be deadly.&nbsp;</p>
<p>The next stage of the study, which has not yet been approved, will involve giving a coronavirus vaccine to different volunteers and then exposing them to coronavirus. Only vaccines that ‚Äúhave proven to be safe in clinical trials‚Äù will be used. However, researchers are still a ‚Äúlong way‚Äù from this stage of the study, according to Terence Stephenson, chair of the Health Research Authority, which gave ethics approval.</p>

<p>Proponents say these studies provide the fastest way to evaluate new vaccines, especially when the world emerges from an active pandemic, said Robert Read, head of clinical and experimental sciences within medicine at the University of Southampton, who belongs to this camp and is part of the team involved in the study.</p>
<p>This initial part of the study will help doctors understand how the immune system reacts to the virus and identify what affects transmission. The drug&nbsp;Remdesivir will be used as soon as volunteers start developing symptoms. </p>
<p>The volunteers, who are being encouraged to come forward for the study, will be between 18 and 30 and will be exposed to the variant circulating in the U.K. since March 2020. </p>
<p><em>This article is part of </em><span>POLITICO</span><em>‚Äôs premium policy service: Pro Health Care. From drug pricing, EMA, vaccines, pharma and more, our specialized journalists keep you on top of the topics driving the health care policy agenda. Email <a href="https://www.politico.eu/article/worlds-first-coronavirus-human-challenge-study-gets-green-light-in-uk/%E2%80%9Cmailto:pro@politico.eu%E2%80%9D" target="_blank"><span data-cfemail="90e0e2ffd0e0fffcf9e4f9f3ffbef5e5">[email&nbsp;protected]</span></a> for a complimentary trial.</em></p>
								</div></div>]]>
            </description>
            <link>https://www.politico.eu/article/worlds-first-coronavirus-human-challenge-study-gets-green-light-in-uk/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26166556</guid>
            <pubDate>Wed, 17 Feb 2021 14:24:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Python Concurrency: The Tricky Bits]]>
            </title>
            <description>
<![CDATA[
Score 39 | Comments 15 (<a href="https://news.ycombinator.com/item?id=26166232">thread link</a>) | @rbanffy
<br/>
February 17, 2021 | https://python.hamel.dev/concurrency/ | <a href="https://web.archive.org/web/*/https://python.hamel.dev/concurrency/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <p><strong>An exploration of threads, processes, and coroutines in Python, with interesting examples that illuminate the differences between each.</strong></p>
<p><img src="https://python.hamel.dev/cpu.jpg" alt=""> Credit:<sup id="fnref:1"><a href="#fn:1" role="doc-noteref">1</a></sup></p>

<p>As <a href="https://hamel.dev/">a data scientist who is spending more time on software engineering</a>, I was recently forced to confront an ugly gap in my knowledge of Python: concurrency.  To be honest, I never completely understood how the terms async, threads, pools and coroutines were different and how these mechanisms could work together.  Every time I tried to learn about the subject, the examples were a bit too abstract for me, and I hard time internalizing how everything worked.</p>
<p>This changed when a friend of mine<sup id="fnref:2"><a href="#fn:2" role="doc-noteref">2</a></sup> recommended <a href="https://youtu.be/MCs5OvhV9S4">a live coding talk</a> by <a href="https://www.dabeaz.com/">David Beazley</a>, an accomplished Python educator.</p>
<p><em>Because of restrictions with this YouTube video, I couldn‚Äôt embed <a href="https://youtu.be/MCs5OvhV9S4">the video</a> in this article, so you will have to open it in a different window</em>.</p>
<p>This talk is incredibly intimidating at first.  Not only is it coded live from scratch, but it also jumps immediately into socket programming, something that I had never encountered as a data scientist.  However, if you go through it slowly and understand all the components (as we do in this blog post) it turns out to be the best educational material on Python concurrency I have ever encountered.  This blog post documents what I learned along the way so others can benefit, too.</p>

<p>Before getting started, David sets up the following infrastructure that is used to demonstrate concurrency.</p>
<h2 id="a-cpu-bound-task-fibonacci">A cpu-bound task: Fibonacci</h2>
<p>To demonstrate concurrency, it is useful to create a task that can saturate your CPU (such as mathematical operations) for a noticeable period of time.  David uses a function that computes a <a href="https://en.wikipedia.org/wiki/Fibonacci_number">Fibonacci number</a>.</p>
<div><div>
<table><tbody><tr><td>
<pre><code><span>1
</span><span>2
</span><span>3
</span><span>4
</span></code></pre></td>
<td>
<pre><code data-lang="py3"><span>#fib.py</span>
<span>def</span> <span>fib</span><span>(</span><span>n</span><span>):</span>
    <span>if</span> <span>n</span> <span>&lt;=</span> <span>2</span><span>:</span> <span>return</span> <span>1</span>
    <span>else</span><span>:</span> <span>return</span> <span>fib</span><span>(</span><span>n</span><span>-</span><span>1</span><span>)</span> <span>+</span> <span>fib</span><span>(</span><span>n</span><span>-</span><span>2</span><span>)</span>
</code></pre></td></tr></tbody></table>
</div>
</div><p>This function takes much longer for large inputs versus smaller inputs<sup id="fnref:3"><a href="#fn:3" role="doc-noteref">3</a></sup>, which allows us to profile different workloads.</p>
<h2 id="a-simple-web-server">A Simple Web Server</h2>
<p>A web server is one of the best ways to illustrate different types of concurrency.  However, to really demonstrate how things work it is useful to use something that is sufficiently low level enough to see how all the pieces work.  For this, David sets up a web server using socket programming.  If you aren‚Äôt familiar with socket programming, I‚Äôll explain the important bits below, but feel free to dive deeper <a href="https://ruslanspivak.com/lsbaws-part1/">with this tutorial</a> later if you like.</p>
<p>To begin with, David starts with the below code (I‚Äôve highlighted the most interesting bits):</p>
<div><div>
<table><tbody><tr><td>
<pre><code><span> 1
</span><span> 2
</span><span> 3
</span><span> 4
</span><span> 5
</span><span> 6
</span><span> 7
</span><span> 8
</span><span> 9
</span><span>10
</span><span><span>11
</span></span><span>12
</span><span><span>13
</span></span><span>14
</span><span>15
</span><span>16
</span><span><span>17
</span></span><span>18
</span><span>19
</span><span>20
</span><span><span>21
</span></span><span>22
</span><span>23
</span><span>24
</span></code></pre></td>
<td>
<pre><code data-lang="python3"><span># server-1.py</span>
<span>from</span> <span>socket</span> <span>import</span> <span>*</span>
<span>from</span> <span>fib</span> <span>import</span> <span>fib</span> 

<span>def</span> <span>fib_server</span><span>(</span><span>address</span><span>):</span>
    <span>sock</span> <span>=</span> <span>socket</span><span>(</span><span>AF_INET</span><span>,</span> <span>SOCK_STREAM</span><span>)</span>
    <span>sock</span><span>.</span><span>setsockopt</span><span>(</span><span>SOL_SOCKET</span><span>,</span> <span>SO_REUSEADDR</span><span>,</span><span>1</span><span>)</span>
    <span>sock</span><span>.</span><span>bind</span><span>(</span><span>address</span><span>)</span>
    <span>sock</span><span>.</span><span>listen</span><span>(</span><span>5</span><span>)</span>
    <span>while</span> <span>True</span><span>:</span>
<span>        <span>client</span><span>,</span><span>addr</span> <span>=</span> <span>sock</span><span>.</span><span>accept</span><span>()</span>  <span># waits for a connection to be established</span>
</span>        <span>print</span><span>(</span><span>"Connection"</span><span>,</span> <span>addr</span><span>)</span>
<span>        <span>fib_handler</span><span>(</span><span>client</span><span>)</span> <span># passes the client to a handler which will listen for input data.</span>
</span>        
<span>def</span> <span>fib_handler</span><span>(</span><span>client</span><span>):</span>
    <span>while</span> <span>True</span><span>:</span>
<span>        <span>req</span> <span>=</span> <span>client</span><span>.</span><span>recv</span><span>(</span><span>100</span><span>)</span>  <span># waits for data that sent by the client.</span>
</span>        <span>if</span> <span>not</span> <span>req</span><span>:</span> <span>break</span>
        <span>result</span> <span>=</span> <span>fib</span><span>(</span><span>int</span><span>(</span><span>req</span><span>))</span>
        <span>resp</span> <span>=</span> <span>str</span><span>(</span><span>result</span><span>)</span><span>.</span><span>encode</span><span>(</span><span>'ascii'</span><span>)</span> <span>+</span> <span>b</span><span>'</span><span>\n</span><span>'</span>
<span>        <span>client</span><span>.</span><span>send</span><span>(</span><span>resp</span><span>)</span> <span># sends data back to the client.</span>
</span>    <span>print</span><span>(</span><span>"Closed"</span><span>)</span>
    
<span>fib_server</span><span>((</span><span>''</span><span>,</span> <span>25000</span><span>))</span>
</code></pre></td></tr></tbody></table>
</div>
</div><p>Here is an explanation of this code:</p>
<ul>
<li>Lines 6-9 are socket programming boilerplate.  It‚Äôs ok to just take this for granted as a reasonable way to set up a socket server.  This also matches the <a href="https://ruslanspivak.com/lsbaws-part1/">the tutorial</a> I linked to above.</li>
<li>Line 11 waits for an incoming connection from a client.  Once a connection is made, the server can begin receiving data from a client.  The code will stop execution on this line until a connection is made.</li>
<li>Line 13: Once a connection is established, the client object is passed to a function which can handle data sent by the client.</li>
<li>Line 17: waits for data to be sent by the client.  The code will stop execution on this line until data is received from the client.</li>
<li>Line 21: The server sends a response back to the client.  The code <em>could</em> stop execution on this line if the send buffers are full, but unlikely in this toy example.</li>
</ul>

<p>In the above example, the server will only be able to accept a connection from a single client, because the call to <code>fib_handler</code> will never return (because it will run in an infinite loop unless a kill signal is received).  This means that <code>sock.accept()</code> can only be called once.</p>
<p>You can test this out by first running the server:</p>
<p>Then establish a client:</p>
<p>You can type numbers in <a href="https://youtu.be/MCs5OvhV9S4?t=293">as David does in his video</a> and verifies that fibonacci numbers are returned.  However, if you try to connect with another client at the same time from a different terminal session:</p>
<p>You will notice that the second client just hangs and doesn‚Äôt return anything from the server.  This is because the server is only able to accept a single connection.  Next, we explore how to tackle this issue.</p>

<p>We can solve this issue with threads.  You can add threads to the handler so that more connections can be accepted with the following code highlighted in yellow:</p>
<div><div>
<table><tbody><tr><td>
<pre><code><span> 1
</span><span> 2
</span><span><span> 3
</span></span><span> 4
</span><span> 5
</span><span> 6
</span><span> 7
</span><span> 8
</span><span> 9
</span><span>10
</span><span>11
</span><span>12
</span><span><span>13
</span></span><span>14
</span><span>15
</span><span>16
</span><span>17
</span><span>18
</span><span>19
</span><span>20
</span><span>21
</span><span>22
</span><span>23
</span><span>24
</span></code></pre></td>
<td>
<pre><code data-lang="py3"><span>from</span> <span>socket</span> <span>import</span> <span>*</span>
<span>from</span> <span>fib</span> <span>import</span> <span>fib</span>
<span><span>from</span> <span>threading</span> <span>import</span> <span>Thread</span>
</span>
<span>def</span> <span>fib_server</span><span>(</span><span>address</span><span>):</span>
    <span>sock</span> <span>=</span> <span>socket</span><span>(</span><span>AF_INET</span><span>,</span> <span>SOCK_STREAM</span><span>)</span>
    <span>sock</span><span>.</span><span>setsockopt</span><span>(</span><span>SOL_SOCKET</span><span>,</span> <span>SO_REUSEADDR</span><span>,</span><span>1</span><span>)</span>
    <span>sock</span><span>.</span><span>bind</span><span>(</span><span>address</span><span>)</span>
    <span>sock</span><span>.</span><span>listen</span><span>(</span><span>5</span><span>)</span>
    <span>while</span> <span>True</span><span>:</span>
        <span>client</span><span>,</span><span>addr</span> <span>=</span> <span>sock</span><span>.</span><span>accept</span><span>()</span>
        <span>print</span><span>(</span><span>"Connection"</span><span>,</span> <span>addr</span><span>)</span>
<span>        <span>Thread</span><span>(</span><span>target</span><span>=</span><span>fib_handler</span><span>,</span> <span>args</span><span>=</span><span>(</span><span>client</span><span>,))</span><span>.</span><span>start</span><span>()</span>
</span>        
<span>def</span> <span>fib_handler</span><span>(</span><span>client</span><span>):</span>
    <span>while</span> <span>True</span><span>:</span>
        <span>req</span> <span>=</span> <span>client</span><span>.</span><span>recv</span><span>(</span><span>100</span><span>)</span> 
        <span>if</span> <span>not</span> <span>req</span><span>:</span> <span>break</span>
        <span>result</span> <span>=</span> <span>fib</span><span>(</span><span>int</span><span>(</span><span>req</span><span>))</span>
        <span>resp</span> <span>=</span> <span>str</span><span>(</span><span>result</span><span>)</span><span>.</span><span>encode</span><span>(</span><span>'ascii'</span><span>)</span> <span>+</span> <span>b</span><span>'</span><span>\n</span><span>'</span>
        <span>client</span><span>.</span><span>send</span><span>(</span><span>resp</span><span>)</span>
    <span>print</span><span>(</span><span>"Closed"</span><span>)</span>
    
<span>fib_server</span><span>((</span><span>''</span><span>,</span> <span>25000</span><span>))</span>
</code></pre></td></tr></tbody></table>
</div>
</div><p>You can verify that this works by connecting two separate clients to the server by running the following command in two separate terminal windows:</p>
<p>By executing the <code>fib_handler</code> in a thread, the main while loop in <code>fib_server</code> will continue, allowing <code>sock.accept()</code> to receive additional clients.  If you haven‚Äôt encountered threads before <a href="https://realpython.com/intro-to-python-threading/">this tutorial</a> provides a good introduction to the topic.</p>
<h2 id="thread-performance--the-gil">Thread performance &amp; the GIL</h2>
<p>When code stops execution and waits for an external event to occur (like a connection to be made, or data to be sent), this is often referred to as <a href="https://stackoverflow.com/questions/2407589/what-does-the-term-blocking-mean-in-programming">blocking</a>.</p>
<p>One important utility of threads is that it allows blocking tasks to release control of the CPU when the CPU is not being used.  However, the Python interpreter can only run on one thread at a time due to the <a href="https://wiki.python.org/moin/GlobalInterpreterLock">Global Interpreter Lock</a>.  Because Python can only run a single thread at any given time, any CPU-bound work in threads must take turn running one after the other.</p>
<p>Therefore, you have to think carefully about what kind of tasks you execute in threads with Python.  If you try to execute CPU bound tasks, these tasks will slow each other down.  David demonstrates this with the below script that sends requests to our threaded server:</p>
<div><div>
<table><tbody><tr><td>
<pre><code><span> 1
</span><span> 2
</span><span> 3
</span><span> 4
</span><span> 5
</span><span> 6
</span><span> 7
</span><span> 8
</span><span> 9
</span><span>10
</span><span>11
</span><span>12
</span><span>13
</span></code></pre></td>
<td>
<pre><code data-lang="py"><span>#perf1.py</span>
<span>from</span> <span>socket</span> <span>import</span> <span>*</span>
<span>import</span> <span>time</span>

<span>sock</span> <span>=</span> <span>socket</span><span>(</span><span>AF_INET</span><span>,</span> <span>SOCK_STREAM</span><span>)</span>
<span>sock</span><span>.</span><span>connect</span><span>((</span><span>'localhost'</span><span>,</span> <span>25000</span><span>))</span>

<span>while</span> <span>True</span><span>:</span>
    <span>start</span> <span>=</span> <span>time</span><span>.</span><span>time</span><span>()</span>
    <span>sock</span><span>.</span><span>send</span><span>(</span><span>b</span><span>'30'</span><span>)</span>
    <span>resp</span> <span>=</span> <span>sock</span><span>.</span><span>recv</span><span>(</span><span>100</span><span>)</span>
    <span>end</span> <span>=</span> <span>time</span><span>.</span><span>time</span><span>()</span>
    <span>print</span><span>(</span><span>end</span><span>-</span><span>start</span><span>)</span>
</code></pre></td></tr></tbody></table>
</div>
</div><p>If you run several instances of this script (after starting the server first):</p>
<p>You will see the execution times for each script linearly increase as you increase the number of these scripts running in parallel.  <strong>For this particular task, adding threads does not make anything faster.  But why?</strong>  This is because the fibonacci task is CPU bound so threads will compete with each other for resources.</p>
<p>Python threads work by interleaving the execution of different tasks on your CPU.<sup id="fnref:4"><a href="#fn:4" role="doc-noteref">4</a></sup>  Only one thread runs at a time, and have the ability to take turns executing in small bits until all threads are done.  The details of how thread processing is interleaved is carried out by the GIL and your operating system, so you need not worry about this detail (with one exception mentioned below).  Interleaving a bunch of CPU bound tasks will not speed up the total runtime of those tasks.  However, if your tasks involve lots of non-CPU time, such as waiting for network connections, or disk I/O, threading tasks may result in a considerable speedup.  A canonical way of simulating a non-cpu bound task in python is to use the built-in function <code>time.sleep()</code>.</p>
<p>To check my understanding about threads and performance, I ran the below experiment<sup id="fnref:5"><a href="#fn:5" role="doc-noteref">5</a></sup> and changed <code>time.sleep(2)</code> to <code>fib(20)</code> and back again:</p>
<div><div>
<table><tbody><tr><td>
<pre><code><span> 1
</span><span> 2
</span><span> 3
</span><span><span> 4
</span></span><span> 5
</span><span> 6
</span><span> 7
</span><span><span> 8
</span></span><span> 9
</span><span>10
</span><span>11
</span><span>12
</span><span>13
</span><span>14
</span><span>15
</span><span>16
</span><span>17
</span><span>18
</span><span>19
</span><span>20
</span><span>21
</span><span>22
</span><span>23
</span><span>24
</span><span>25
</span><span>26
</span><span>27
</span><span>28
</span><span>29
</span></code></pre></td>
<td>
<pre><code data-lang="py"><span>import</span> <span>logging</span>
<span>import</span> <span>threading</span>
<span>import</span> <span>time</span>
<span><span>import</span> <span>fib</span>
</span>
<span>def</span> <span>thread_function</span><span>(</span><span>name</span><span>):</span>
    <span>logging</span><span>.</span><span>info</span><span>(</span><span>"Thread </span><span>%s</span><span>: starting"</span><span>,</span> <span>name</span><span>)</span>
<span>    <span>time</span><span>.</span><span>sleep</span><span>(</span><span>2</span><span>)</span>  <span>## Change this line of code to fib(20)</span>
</span>    <span>logging</span><span>.</span><span>info</span><span>(</span><span>"Thread </span><span>%s</span><span>: finishing"</span><span>,</span> <span>name</span><span>)</span>

<span>if</span> <span>__name__</span> <span>==</span> <span>"__main__"</span><span>:</span>
    <span>format</span> <span>=</span> <span>"</span><span>%(asctime)s</span><span>: </span><span>%(message)s</span><span>"</span>
    <span>start</span> <span>=</span> <span>time</span><span>.</span><span>time</span><span>()</span>
    <span>logging</span><span>.</span><span>basicConfig</span><span>(</span><span>format</span><span>=</span><span>format</span><span>,</span> <span>level</span><span>=</span><span>logging</span><span>.</span><span>INFO</span><span>,</span>
                        <span>datefmt</span><span>=</span><span>"%H:%M:%S"</span><span>)</span>

    <span>threads</span> <span>=</span> <span>list</span><span>()</span>
    <span>for</span> <span>index</span> <span>in</span> <span>range</span><span>(</span><span>3</span><span>):</span>
        <span>logging</span><span>.</span><span>info</span><span>(</span><span>"Main    : create and start thread </span><span>%d</span><span>."</span><span>,</span> <span>index</span><span>)</span>
        <span>x</span> <span>=</span> <span>threading</span><span>.</span><span>Thread</span><span>(</span><span>target</span><span>=</span><span>thread_function</span><span>,</span> <span>args</span><span>=</span><span>(</span><span>index</span><span>,))</span>
        <span>threads</span><span>.</span><span>append</span><span>(</span><span>x</span><span>)</span>
        <span>x</span><span>.</span><span>start</span><span>()</span>

    <span>for</span> <span>index</span><span>,</span> <span>thread</span> <span>in</span> <span>enumerate</span><span>(</span><span>threads</span><span>):</span>
        <span>logging</span><span>.</span><span>info</span><span>(</span><span>"Main    : before joining thread </span><span>%d</span><span>."</span><span>,</span> <span>index</span><span>)</span>
        <span>thread</span><span>.</span><span>join</span><span>()</span>
        <span>logging</span><span>.</span><span>info</span><span>(</span><span>"Main    : thread </span><span>%d</span><span> done"</span><span>,</span> <span>index</span><span>)</span>
    <span>end</span> <span>=</span> <span>time</span><span>.</span><span>time</span><span>()</span>
    <span>print</span><span>(</span><span>f</span><span>'total time: {end-start}'</span><span>)</span>
</code></pre></td></tr></tbody></table>
</div>
</div><p>As expected, increasing the number of threads while running <code>time.sleep(2)</code> did not increase the program‚Äôs overall execution time (the program runs in roughly 2 seconds).  On the other hand, replacing <code>time.sleep(2)</code> with <code>fib(20)</code> causes this program‚Äôs running time to increase as more threads are added. This is because <code>fib(20)</code> is a cpu bound task so interleaving the ‚Ä¶</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://python.hamel.dev/concurrency/">https://python.hamel.dev/concurrency/</a></em></p>]]>
            </description>
            <link>https://python.hamel.dev/concurrency/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26166232</guid>
            <pubDate>Wed, 17 Feb 2021 13:51:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Declassified spacecrafts and orbital weapons of the USSR (2018)]]>
            </title>
            <description>
<![CDATA[
Score 306 | Comments 96 (<a href="https://news.ycombinator.com/item?id=26166204">thread link</a>) | @eternalban
<br/>
February 17, 2021 | https://www.xissufotoday.space/2018/04/declassified-spacecrafts-and-orbital.html | <a href="https://web.archive.org/web/*/https://www.xissufotoday.space/2018/04/declassified-spacecrafts-and-orbital.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="post-body-8701437466444498891" itemprop="description articleBody">
<p><a href="https://1.bp.blogspot.com/-hR9EPgdNTO0/V6igmMBuAsI/AAAAAAAABPs/RyK0eKmYbkor6nNer0HytjJN5OsSST14QCLcB/s1600/skif-20.jpg"><img alt="" height="296" src="https://1.bp.blogspot.com/-hR9EPgdNTO0/V6igmMBuAsI/AAAAAAAABPs/RyK0eKmYbkor6nNer0HytjJN5OsSST14QCLcB/s640/skif-20.jpg" width="640"></a></p><br>

<p>Fighting orbital laser station ‚ÄúPolyus‚Äù / ‚ÄúSkif‚Äù</p>
<p>(THE USSR)</p>
<p><a href="https://3.bp.blogspot.com/-vRb_iAi4sj8/V6igjYWZOKI/AAAAAAAABPo/6LaxidVk0dI_X7swTaVcqIBXuXhq_xqAACLcB/s1600/pole%2B16.gif"><img alt="Space program of Star Wars, and the technology that you have not seen before." src="https://3.bp.blogspot.com/-vRb_iAi4sj8/V6igjYWZOKI/AAAAAAAABPo/6LaxidVk0dI_X7swTaVcqIBXuXhq_xqAACLcB/s1600/pole%2B16.gif" title="Space program of Star Wars"></a></p>
<p>Specifications</p>
<p>Length: 37.00 m (121.39 ft)</p>
<p>Maximum Diameter: 4.10 m (13.5 ft)</p>
<p>Mass: 80,000 kg (180,000 lb)</p>
<p>Associated Launch Vehicle: Energia.</p>
<p>Intended orbit: altitude 280 km (170 mi), inclination 64¬∞</p>
<p>Targeting system: optical, radar, with low-yield laser for final targeting</p>
<p>Armament: 1-megawatt carbon-dioxide laser</p>
<p><a href="https://2.bp.blogspot.com/-ITAhROrlH5w/V6igsIb3bjI/AAAAAAAABPw/EEm94HDTt7sCoOJYU8ClpAGYHgefGZqsQCLcB/s1600/skif-11.jpg"><img alt="" height="296" src="https://2.bp.blogspot.com/-ITAhROrlH5w/V6igsIb3bjI/AAAAAAAABPw/EEm94HDTt7sCoOJYU8ClpAGYHgefGZqsQCLcB/s640/skif-11.jpg" title="Armament: 1-megawatt carbon-dioxide laser" width="640"></a></p><br>

<p>The&nbsp;Polyus&nbsp;spacecraft (<a title="Russian language" href="https://en.wikipedia.org/wiki/Russian_language">Russian</a>:&nbsp;<span lang="ru" xml:lang="ru">–ü–æ–ª—é—Å</span>,&nbsp;<a title="Geographical pole" href="https://en.wikipedia.org/wiki/Geographical_pole">pole</a>), also known as&nbsp;Polus,&nbsp;Skif-DM,&nbsp;<a title="GRAU" href="https://en.wikipedia.org/wiki/GRAU">GRAU</a>&nbsp;index&nbsp;17F19DM, was a prototype<a title="Space weapon" href="https://en.wikipedia.org/wiki/Space_weapon">orbital weapons platform</a>&nbsp;designed to destroy&nbsp;<a title="Strategic Defense Initiative" href="https://en.wikipedia.org/wiki/Strategic_Defense_Initiative">SDI satellites</a>&nbsp;with a megawatt&nbsp;<a title="Carbon dioxide laser" href="https://en.wikipedia.org/wiki/Carbon_dioxide_laser">carbon-dioxide laser</a>.<a href="https://en.wikipedia.org/wiki/Polyus_(spacecraft)#cite_note-starwars-1">[1]</a>&nbsp;It had a Functional Cargo Block derived from a&nbsp;<a title="TKS spacecraft" href="https://en.wikipedia.org/wiki/TKS_spacecraft">TKS spacecraft</a>&nbsp;to control its orbit and it could fire test targets to demonstrate the fire control system.</p>
<p>The Polyus spacecraft was launched 15 May 1987 from&nbsp;<a title="Baikonur Cosmodrome" href="https://en.wikipedia.org/wiki/Baikonur_Cosmodrome">Baikonur Cosmodrome</a>&nbsp;<a title="Baikonur Cosmodrome Site 250" href="https://en.wikipedia.org/wiki/Baikonur_Cosmodrome_Site_250">Site 250</a>&nbsp;as part of the first flight of the&nbsp;<a title="Energia" href="https://en.wikipedia.org/wiki/Energia">Energia</a>system,<a href="https://en.wikipedia.org/wiki/Polyus_(spacecraft)#cite_note-2">[2]</a>&nbsp;but failed to reach orbit.</p>
<p>According to&nbsp;<a title="Yuri Kornilov (page does not exist)" href="https://en.wikipedia.org/w/index.php?title=Yuri_Kornilov&amp;action=edit&amp;redlink=1">Yuri Kornilov</a>, Chief Designer of the Salyut Design Bureau, shortly before Polyus‚Äô launch,&nbsp;<a title="Mikhail Gorbachev" href="https://en.wikipedia.org/wiki/Mikhail_Gorbachev">Mikhail Gorbachev</a>&nbsp;visited the Baikonur Cosmodrome and expressly forbade the in-orbit testing of its capabilities. Kornilov claims that Gorbachev was worried that it would be possible for Western governments to view this activity as an attempt to create a weapon in space and that such an attempt would contradict the country‚Äôs previous statements on the USSR‚Äôs peaceful intent.<a href="https://en.wikipedia.org/wiki/Polyus_(spacecraft)#cite_note-kornilov-3">[3]</a></p>
<p>For technical reasons, the payload was launched upside down. It was designed to separate from the Energia, rotate 180 degrees in yaw, then 90 degrees in roll and then fire its engine to complete its boost to orbit. The Energia functioned perfectly. However, after disconnecting from Energia, the Polyus spun a full 360 degrees instead of the planned 180 degrees. When the rocket fired, it slowed and burned up in the atmosphere over the south Pacific ocean. This failure was attributed to a faulty<a title="Inertial guidance system" href="https://en.wikipedia.org/wiki/Inertial_guidance_system">inertial guidance system</a>&nbsp;that had not been rigorously tested due to the rushed production schedule.<a href="https://en.wikipedia.org/wiki/Polyus_(spacecraft)#cite_note-grondine-4">[4]</a></p><br>
<br>
<br>

<p><a href="https://3.bp.blogspot.com/-teiFsqZWb7A/V6ihr9TtXaI/AAAAAAAABP8/HzSWNCrGZZQnx6BbBREK4OTHhQYh6skAACLcB/s1600/pole12.jpg"><img alt="Space program of Star Wars, and the technology that you have not seen before." height="348" src="https://3.bp.blogspot.com/-teiFsqZWb7A/V6ihr9TtXaI/AAAAAAAABP8/HzSWNCrGZZQnx6BbBREK4OTHhQYh6skAACLcB/s640/pole12.jpg" title="Space program of Star Wars, and the technology that you have not seen before." width="640"></a></p>
<p>NPO&nbsp;Energia&nbsp;received orders from the&nbsp;<a title="Government of the Soviet Union" href="https://en.wikipedia.org/wiki/Government_of_the_Soviet_Union">Soviet government</a>&nbsp;to begin research on space-based strike weapons in the mid-70s. Even before, the USSR had been developing maneuverable satellites for the purpose of satellite interception. By the beginning of the 1980s,&nbsp;Energia&nbsp;had proposed two programs: laser-equipped&nbsp;Skif&nbsp;and guided missiles platform&nbsp;Kaskad&nbsp;(where&nbsp;Skif&nbsp;would cover the low-orbit targets,&nbsp;Kaskad&nbsp;engaged targets in high and geosynchronous orbits). Together with NPO&nbsp;Astrofizika&nbsp;and KBSalyut, they began developing their orbital weapons platform based on the&nbsp;<a title="Salyut program" href="https://en.wikipedia.org/wiki/Salyut_program">Salyut</a>&nbsp;DOS-17K frame.</p>
<p>Later, when the objective of ICBM interception proved too difficult, the aims of the project were shifted towards anti-satellite weapons. The 1983 announcement by the US of their SDI program prompted further political and financial support for the satellite interceptor program. In the nuclear exchange scenario, the interceptors would destroy the SDI satellites, followed by a so-called ‚Äúpre-emptive retaliation‚Äù large-scale Soviet ICBM launch.</p>
<p><a href="https://4.bp.blogspot.com/-Hi0M3Kqk2yU/V6ih91L_cxI/AAAAAAAABQA/hQqNjrWW5-syquXFC5bw8VN7v7Wz33VVgCLcB/s1600/pole13.jpg"><img alt="Skif spacecraft was the 1-megawatt carbon-dioxide laser, developed for the Beriev A-60 aircraft (an Il-76 flying laboratory with a combat laser)" height="332" src="https://4.bp.blogspot.com/-Hi0M3Kqk2yU/V6ih91L_cxI/AAAAAAAABQA/hQqNjrWW5-syquXFC5bw8VN7v7Wz33VVgCLcB/s640/pole13.jpg" title="Skif a combat laser)" width="640"></a></p><br>

<p>The laser chosen for the&nbsp;Skif&nbsp;spacecraft was the 1-megawatt carbon-dioxide laser, developed for the&nbsp;<a title="Beriev A-60" href="https://en.wikipedia.org/wiki/Beriev_A-60">Beriev A-60</a>&nbsp;aircraft (an Il-76 flying laboratory with a combat laser). The introduction of the&nbsp;Energia, capable of launching about 95 tonnes into orbit, finally allowed the spacecraft to accommodate the massive laser. The massive exhaust of the carbon-dioxide laser precipitated the objective of making the laser ‚Äúrecoil-less‚Äù. The&nbsp;zero-torque exhaust system&nbsp;(SBM) was developed to that end. Its testing in orbit meant the release of a large cloud of carbon dioxide, which would hint at the satellite‚Äôs purpose. Instead, the xenon-krypton mix would be used to simultaneously test the SBM and perform an innocent experiment on Earth‚Äôs&nbsp;<a title="Ionosphere" href="https://en.wikipedia.org/wiki/Ionosphere">ionosphere</a>.</p>
<p>In 1985, the decision was made to test-launch the new&nbsp;Energia&nbsp;launch vehicle, which was still in the&nbsp;<a title="Testbed" href="https://en.wikipedia.org/wiki/Testbed">testbed</a>&nbsp;phase. A 100-ton dummy payload was initially considered for the launch, but in a series of last-minute changes, it was decided that the almost-completed&nbsp;Skif&nbsp;spacecraft would be launched instead for a 30-day mission.</p>
<p>The launch May 15, 1987, shot by 24 cameras from different angles.</p>
<p>Prelaunch installation&nbsp;04.02.1987</p>
<p>The development of the real&nbsp;Skif&nbsp;was completed in just one year, from September 1985 to September 1986. Testing and tweaking the&nbsp;Energia&nbsp;launch vehicle, the launch pad and the&nbsp;Skif&nbsp;itself moved the launch to February, and later to May 1987. According to Boris Gubanov, the head designer of the&nbsp;Energia&nbsp;launch vehicle, the work schedule of the preceding years was exhausting, and at the point of Mikhail Gorbachev‚Äôs visit on 11 May, he asked the Soviet premier to clear the launch now, because ‚Äúthere will be heart attacks‚Äù.</p>
<p><a href="https://4.bp.blogspot.com/-CwxOEC0MP1o/V6ij0CpjnyI/AAAAAAAABQQ/EkKtncbH2OM8cwUp419gnVtycH86sGcZACLcB/s1600/gud_anim.gif"><img alt="Prelaunch installation 04.02.1987" src="https://4.bp.blogspot.com/-CwxOEC0MP1o/V6ij0CpjnyI/AAAAAAAABQQ/EkKtncbH2OM8cwUp419gnVtycH86sGcZACLcB/s1600/gud_anim.gif" title="Prelaunch installation 04.02.1987"></a></p>
<p>The catastrophic malfunction that led to&nbsp;Skif&nbsp;entering the atmosphere in the same area as&nbsp;Energia‚Äôs&nbsp;second stage was successfully investigated. It was found that 568 seconds after launch, the timing control device gave the logical block a command to discard the side modules‚Äô covers and laser exhaust covers. Unknowingly, the same command was earlier used to open the solar panels and disengage the maneuvering thrusters. This wasn‚Äôt discovered because of the logistics of the testing process and overall haste. Main thrusters engaged while the&nbsp;Skif&nbsp;kept turning, overshooting the intended 180-degree turn. The spacecraft lost speed and reverted to the&nbsp;<a title="Ballistic trajectory" href="https://en.wikipedia.org/wiki/Ballistic_trajectory">ballistic trajectory</a>.</p><br>

<p>Air-orbital plane ‚ÄúSpiral‚Äù</p>
<p><a href="https://1.bp.blogspot.com/-STY5S6KFa5A/V6imrd6R8MI/AAAAAAAABQc/0vSgs5_ceE03HJFT6TPu2zTt2tC1GwG_ACLcB/s1600/spiral7.gif"><img alt="Air-orbital plane &quot;Spiral&quot;" src="https://1.bp.blogspot.com/-STY5S6KFa5A/V6imrd6R8MI/AAAAAAAABQc/0vSgs5_ceE03HJFT6TPu2zTt2tC1GwG_ACLcB/s1600/spiral7.gif" title="Air-orbital plane &quot;Spiral&quot;"></a></p>
<p><a href="https://1.bp.blogspot.com/-awSlGVXU2MM/V6inOZK9REI/AAAAAAAABQk/4CO-uHtBTngwWFReSMGI1ihvVKlMaSK0ACLcB/s1600/bor4_13.gif"><img alt="Air-orbital plane &quot;Spiral&quot;" height="400" src="https://1.bp.blogspot.com/-awSlGVXU2MM/V6inOZK9REI/AAAAAAAABQk/4CO-uHtBTngwWFReSMGI1ihvVKlMaSK0ACLcB/s640/bor4_13.gif" title="Air-orbital plane &quot;Spiral&quot;" width="640"></a></p><br>
<br>
<div>
<p>Aerospace System ‚ÄúSpiral‚Äù ‚Äì space application system consisting of the orbital plane, which is the start of the air technology was displayed in hypersonic space plane, overclockers, and then stage rocket into orbit.</p>
<p><a href="https://4.bp.blogspot.com/-Sdl49qj8rKg/V6inZw8e77I/AAAAAAAABQo/WSA3ZjZaT1w9wuc6Zq-uBKZAXLDqErORwCLcB/s1600/MiG-105-11a.jpg"><img alt="Aerospace System &quot;Spiral&quot; - space application system consisting of the orbital plane" height="426" src="https://4.bp.blogspot.com/-Sdl49qj8rKg/V6inZw8e77I/AAAAAAAABQo/WSA3ZjZaT1w9wuc6Zq-uBKZAXLDqErORwCLcB/s640/MiG-105-11a.jpg" title="Aerospace System &quot;Spiral&quot; - space application system consisting of the orbital plane" width="640"></a></p>
<p>Source of image WIKIPEDIA</p>
<p>The ‚ÄúSpiral‚Äù, launched in 1960, was a response to the creation of the US space program interceptor reconnaissance-bomber, the X-20, ‚Äúthe Dyna Soar‚Äù</p><br>
<br>
<div>
<p>Plane-overclockers</p>
<p>Powerful airship overclockers (weight 52 tons, length 38 meters, wingspan of 16.5 m) was dispersed to six times the speed of sound (6M), then with his ‚Äúback‚Äù at an altitude of 28-30 km was supposed to start a 10-ton manned orbital plane 8 m long and 7.4 m span.</p>
<p><a href="https://2.bp.blogspot.com/-oSes4d9bcsg/V6inJIfNtfI/AAAAAAAABQg/lqy4GYfzDyk1Pp_vJyG_SIqnIVVrvhkzgCLcB/s1600/spiral1.gif"><img alt="Plane-overclockers" height="262" src="https://2.bp.blogspot.com/-oSes4d9bcsg/V6inJIfNtfI/AAAAAAAABQg/lqy4GYfzDyk1Pp_vJyG_SIqnIVVrvhkzgCLcB/s640/spiral1.gif" title="Plane-overclockers" width="640"></a></p><br>

<p>‚ÄúThe plane-overclockers to 6 Mach suggests the possibility of use as a passenger plane, airliner, which, of course, was rational: its high speed characteristics would allow to raise the rate of civil aviation.‚Äù</p>
<p>Plane-overclockers was the first technologically revolutionary detailed design of hypersonic aircraft with jet engines. At the 40th Congress of the International Aeronautical Federation (the FAI), which took place in 1989 in Malaga (Spain), representatives of the US National Aeronautics and Space Administration (NASA‚Äôs) gave the plane-overclockers high praise, noting that he ‚Äúwas designed in accordance with the modern requirements. ‚Äú</p><br>

<p>In view of the requirements of a lot of money for brand new motor, aerodynamic and material science technologies for the creation of such a hypersonic-overclockers aircraft in the latest versions of the project was considered less costly and more quickly achievable possibility of creating not a hypersonic and supersonic overclockers, as is considered modified shock-reconnaissance aircraft T-4 ( ‚Äú100‚Äù), however it was not realized.</p><br>
</div>
<p><a href="https://4.bp.blogspot.com/-f56Ka-Kmgx4/V6ing6SrPHI/AAAAAAAABQw/wSvcahmzZrUuhoyTc6KunO_st0HMdJsRwCLcB/s1600/spiral%2B1.gif"><img alt="hypersonic-overclockers aircraft" height="168" src="https://4.bp.blogspot.com/-f56Ka-Kmgx4/V6ing6SrPHI/AAAAAAAABQw/wSvcahmzZrUuhoyTc6KunO_st0HMdJsRwCLcB/s640/spiral%2B1.gif" title="hypersonic-overclockers aircraft" width="640"></a></p>
<p><a href="https://4.bp.blogspot.com/-ntrWcYZ1jMY/V6ing_kTtCI/AAAAAAAABQs/vzqLBGTn4AEoWQ_7w-FnT3bYQFDpNslWACLcB/s1600/spiral%2B2%2B%25281%2529.gif"><img alt="hypersonic-overclockers aircraft" height="458" src="https://4.bp.blogspot.com/-ntrWcYZ1jMY/V6ing_kTtCI/AAAAAAAABQs/vzqLBGTn4AEoWQ_7w-FnT3bYQFDpNslWACLcB/s640/spiral%2B2%2B%25281%2529.gif" title="hypersonic-overclockers aircraft" width="640"></a></p><br>
<br>

<p>BOR&nbsp;space drone</p>
<p><a href="https://3.bp.blogspot.com/-vYoT5DevGH4/V6ipam0sBYI/AAAAAAAABRo/V6aXqq5FKt8-46cakc0zzbqGkH3Hr-yiwCLcB/s1600/i1053rp.jpg"><img height="194" src="https://3.bp.blogspot.com/-vYoT5DevGH4/V6ipam0sBYI/AAAAAAAABRo/V6aXqq5FKt8-46cakc0zzbqGkH3Hr-yiwCLcB/s640/i1053rp.jpg" width="640"></a></p><br>

<p><a href="https://4.bp.blogspot.com/-wLcFH5YIyno/V6ipKJ5PMVI/AAAAAAAABRM/Lut7B63tcT08_Kqvl82jsFVW-H4-p1x8ACLcB/s1600/bor4-15.gif"><img alt="Unpiloted Orbital Rocketplane 4" height="412" src="https://4.bp.blogspot.com/-wLcFH5YIyno/V6ipKJ5PMVI/AAAAAAAABRM/Lut7B63tcT08_Kqvl82jsFVW-H4-p1x8ACLcB/s640/bor4-15.gif" title="Unpiloted Orbital Rocketplane 4" width="640"></a></p><br>
<br>
<div>
<p>The&nbsp;BOR-4&nbsp;(<span lang="ru" xml:lang="ru">Bespilotnyi Orbital‚Äônyi Raketoplan 4</span>, ‚ÄúUnpiloted Orbital Rocketplane 4‚Äù) flight vehicle is a scaled (1:2) prototype of the Soviet&nbsp;<a title="Spiral spaceplane" href="https://en.wikipedia.org/wiki/Spiral_spaceplane">Spiral</a>&nbsp;<a title="VTHL" href="https://en.wikipedia.org/wiki/VTHL">VTHL</a>&nbsp;(vertical takeoff, horizontal landing)<a title="Spaceplane" href="https://en.wikipedia.org/wiki/Spaceplane">spaceplane</a>. An unmanned, subscale&nbsp;<a title="Spacecraft" href="https://en.wikipedia.org/wiki/Spacecraft">spacecraft</a>, its purpose was to test the heatshield tiles and reinforced carbon-carbon for the&nbsp;<a title="Buran (spacecraft)" href="https://en.wikipedia.org/wiki/Buran_(spacecraft)">Buran space shuttle</a>, then under development.<a href="https://en.wikipedia.org/wiki/BOR-4#cite_note-1">[1]</a></p>
<p>Several of them were built and flown between 1982 and 1984 from the&nbsp;<a title="Kapustin Yar" href="https://en.wikipedia.org/wiki/Kapustin_Yar">Kapustin Yar</a>&nbsp;launch site at speeds of up to Mach 25. After reentry, they were designed to parachute to an ocean splashdown for recovery by the&nbsp;<a title="Soviet Navy" href="https://en.wikipedia.org/wiki/Soviet_Navy">Soviet Navy</a>. The testing was nearly identical to that carried out by the&nbsp;<a title="US Air Force" href="https://en.wikipedia.org/wiki/US_Air_Force">US Air Force</a>&nbsp;<a title="ASSET (spaceplane)" href="https://en.wikipedia.org/wiki/ASSET_(spaceplane)">ASSET program</a>&nbsp;in the 1960s, which tested the heatshield design for the&nbsp;<a title="X-20 Dyna-Soar" href="https://en.wikipedia.org/wiki/X-20_Dyna-Soar">X-20 Dyna-Soar</a>. On June 3, 1982 a&nbsp;<a title="Royal Australian Air Force" href="https://en.wikipedia.org/wiki/Royal_Australian_Air_Force">Royal Australian Air Force</a>&nbsp;<a title="P-3 Orion" href="https://en.wikipedia.org/wiki/P-3_Orion">P-3 Orion</a>&nbsp;reconnaissance aircraft captured the first Western images of the craft as it was recovered by a Soviet ship near the&nbsp;<a title="Cocos Islands" href="https://en.wikipedia.org/wiki/Cocos_Islands">Cocos Islands</a>.<a href="https://en.wikipedia.org/wiki/BOR-4#cite_note-2">[2]</a></p>
<p><a href="https://1.bp.blogspot.com/-HAbZbRnqeZ4/V6ipQtSw7HI/AAAAAAAABRQ/ZzElR0QP8iQPgvjpcaG761a29F3tTdFVQCLcB/s1600/bor4-7.gif"><img height="640" src="https://1.bp.blogspot.com/-HAbZbRnqeZ4/V6ipQtSw7HI/AAAAAAAABRQ/ZzElR0QP8iQPgvjpcaG761a29F3tTdFVQCLcB/s640/bor4-7.gif" width="96"></a></p>
<p><a href="https://3.bp.blogspot.com/-EfUE1OWo-q8/V6ipQ5Jsr9I/AAAAAAAABRY/lf6Bx_Idsg8PG1gu2i0r46PFAZ-imiQ0QCLcB/s1600/bor4-81.gif"><img src="https://3.bp.blogspot.com/-EfUE1OWo-q8/V6ipQ5Jsr9I/AAAAAAAABRY/lf6Bx_Idsg8PG1gu2i0r46PFAZ-imiQ0QCLcB/s1600/bor4-81.gif"></a></p>
<p><a href="https://2.bp.blogspot.com/-pQX430XulG0/V6ipQitpQII/AAAAAAAABRU/SEG93Sg14nwtZBsQci-UTdqaWowXrCDHACLcB/s1600/i0865rp.jpg"><img height="304" src="https://2.bp.blogspot.com/-pQX430XulG0/V6ipQitpQII/AAAAAAAABRU/SEG93Sg14nwtZBsQci-UTdqaWowXrCDHACLcB/s640/i0865rp.jpg" width="640"></a></p>
<p><a href="https://3.bp.blogspot.com/-vCQ4NhAyzF4/V6ipQ9YS97I/AAAAAAAABRc/VucBuBk__mgOtRDAI3ayI70kg1vaQ-aAwCLcB/s1600/i0937rp.jpg"><img height="300" src="https://3.bp.blogspot.com/-vCQ4NhAyzF4/V6ipQ9YS97I/AAAAAAAABRc/VucBuBk__mgOtRDAI3ayI70kg1vaQ-aAwCLcB/s400/i0937rp.jpg" width="400"></a></p>
<p><a href="https://4.bp.blogspot.com/-4ecLgpjXV38/V6ipRJYXmZI/AAAAAAAABRg/08wrJ-l3LY0f6aG_xaaSOv3vrUwTeGw8ACLcB/s1600/i1040rp.jpg"><img height="640" src="https://4.bp.blogspot.com/-4ecLgpjXV38/V6ipRJYXmZI/AAAAAAAABRg/08wrJ-l3LY0f6aG_xaaSOv3vrUwTeGw8ACLcB/s640/i1040rp.jpg" width="478"></a></p>
<p><a href="https://1.bp.blogspot.com/-z39-2F9dR44/V6ipRQ0HF0I/AAAAAAAABRk/1J2wISGkfnIwKtECHQX7SODuAfjmsMO-gCLcB/s1600/i1043rp.jpg"><img height="640" src="https://1.bp.blogspot.com/-z39-2F9dR44/V6ipRQ0HF0I/AAAAAAAABRk/1J2wISGkfnIwKtECHQX7SODuAfjmsMO-gCLcB/s640/i1043rp.jpg" width="478"></a></p><br>
<br>
<br>
<br>

<p><a href="https://2.bp.blogspot.com/-329Ztj6nwh0/V6io8aeDcfI/AAAAAAAABRE/RAwaJyioMJ8V0dxgtXEHAZVAc0YhZDpBACLcB/s1600/bor13_11.gif"><img height="300" src="https://2.bp.blogspot.com/-329Ztj6nwh0/V6io8aeDcfI/AAAAAAAABRE/RAwaJyioMJ8V0dxgtXEHAZVAc0YhZDpBACLcB/s400/bor13_11.gif" width="400"></a></p>
<p><a href="https://3.bp.blogspot.com/-eS6bZ2WgV4E/V6io8grD54I/AAAAAAAABRI/4vMejPNeBKQODrUBQ7B15-7uR3t1nlJbQCLcB/s1600/bor13_10.gif"><img height="300" src="https://3.bp.blogspot.com/-eS6bZ2WgV4E/V6io8grD54I/AAAAAAAABRI/4vMejPNeBKQODrUBQ7B15-7uR3t1nlJbQCLcB/s400/bor13_10.gif" width="400"></a></p><br>

<p>Russian Aerospace Plane</p><br>
</div>
<p><a href="https://1.bp.blogspot.com/-qBYyz-vcWwc/V6irQnxpysI/AAAAAAAABR0/Y9E9GfdOROAy0Pz-s4v6yvZCV2iJnPVbACLcB/s1600/6803551.jpg"><img alt="Russian Aerospace Plane" height="427" src="https://1.bp.blogspot.com/-qBYyz-vcWwc/V6irQnxpysI/AAAAAAAABR0/Y9E9GfdOROAy0Pz-s4v6yvZCV2iJnPVbACLcB/s640/6803551.jpg" title="Russian Aerospace Plane RAKS" width="640"></a></p><br>
<br>
<div>
<p>Possible Features</p>
<p>&nbsp; &nbsp;Length 7900 mm</p>
<p>&nbsp; &nbsp;Wingspan mm 3600</p>
<p>&nbsp; &nbsp;Starting weight, kg 2200</p>
<p>&nbsp; &nbsp;The stock of liquid oxygen, 18 kg</p>
<p>&nbsp; &nbsp;Speed range, Max 6 ‚Ä¶ 14</p><br>
</div>
<p><a href="https://1.bp.blogspot.com/-Id1G8Ai3FHk/V6irWH6acmI/AAAAAAAABSA/7Tq_By2nMfQp4R_0el1V0uAB6SkEsJjpgCLcB/s1600/3587219.jpg"><img alt="Russian Aerospace Plane (RAKS) is created as part of the research work &quot;Eagle&quot; by order of the Russian Aerospace Agency in 1993." height="318" src="https://1.bp.blogspot.com/-Id1G8Ai3FHk/V6irWH6acmI/AAAAAAAABSA/7Tq_By2nMfQp4R_0el1V0uAB6SkEsJjpgCLcB/s640/3587219.jpg" title="Russian Aerospace Plane" width="640"></a></p>
<p>Russian Aerospace Plane (RAKS) is created as part of the research work ‚ÄúEagle‚Äù by order of the Russian Aerospace Agency in 1993.</p>
<p><a href="https://2.bp.blogspot.com/-ls7d5uPaNL8/V6irV7m1QEI/AAAAAAAABR8/eeGSYmibxNAM7JsA05O0p5SwrodovDUrwCLcB/s1600/8450700.jpg"><img height="244" src="https://2.bp.blogspot.com/-ls7d5uPaNL8/V6irV7m1QEI/AAAAAAAABR8/eeGSYmibxNAM7JsA05O0p5SwrodovDUrwCLcB/s640/8450700.jpg" width="640"></a></p>
<p><a href="https://1.bp.blogspot.com/-DXSuq544CWo/V6irWQKDKiI/AAAAAAAABSE/hVzjAmz0vLoXJyiHuddT5r3rSp2BiwEJgCLcB/s1600/vks-4.jpg"><img height="305" src="https://1.bp.blogspot.com/-DXSuq544CWo/V6irWQKDKiI/AAAAAAAABSE/hVzjAmz0vLoXJyiHuddT5r3rSp2BiwEJgCLcB/s400/vks-4.jpg" width="400"></a></p>
<p><a href="https://2.bp.blogspot.com/-Wx9dP_DpcJk/V6irWTOUtYI/AAAAAAAABSI/Tm0kUSc5vFgPXRYnwiN3TLgxtOqMOqI9ACLcB/s1600/vks-7.jpg"><img height="320" src="https://2.bp.blogspot.com/-Wx9dP_DpcJk/V6irWTOUtYI/AAAAAAAABSI/Tm0kUSc5vFgPXRYnwiN3TLgxtOqMOqI9ACLcB/s320/vks-7.jpg" width="316"></a></p>
<p><a href="https://4.bp.blogspot.com/--w6856Ho57Y/V6irWvdAPII/AAAAAAAABSM/1gAUY-GV0voWH-WJ5jf4BNGfJ2Eo_7fzgCLcB/s1600/vks-8.jpg"><img height="176" src="https://4.bp.blogspot.com/--w6856Ho57Y/V6irWvdAPII/AAAAAAAABSM/1gAUY-GV0voWH-WJ5jf4BNGfJ2Eo_7fzgCLcB/s400/vks-8.jpg" width="400"></a></p><br>
<div>
<p>Main targets:</p>
<p>‚Äì The integration of scramjet and airframe;</p>
<p>‚Äì Study questions work ramjet engine in real hypersonic flight at cruising speed up to M = 14;</p>
<p>‚Äì The study of the thermal problems associated with operating ramjet engine and aerodynamic heating of the airframe;</p>
<p>‚Äì Dynamic throttling in a hypersonic scramjet flight;</p>
<p>‚Äì Check ground flight test experiments</p><br>
</div><br>
<br>

<p>Kliper</p>
<p><a href="https://1.bp.blogspot.com/-nM6wVrsBtIw/V6itl14uJtI/AAAAAAAABSc/M5lmXznMma4YD02HQ6vUv2moH-Xw_wO-ACLcB/s1600/%25D0%259A%25D0%25BB%25D0%25B8%25D0%25BF%25D0%25B5%25D1%2580_Infografia.jpg"><img alt="Kliper (–ö–ª–∏–ø–µ—Ä, English: Clipper) was a proposed partly reusable manned spacecraft by RSC Energia. Due to lack of funding from the ESA and RSA, the project has been indefinitely postponed as of 2006." height="398" src="https://1.bp.blogspot.com/-nM6wVrsBtIw/V6itl14uJtI/AAAAAAAABSc/M5lmXznMma4YD02HQ6vUv2moH-Xw_wO-ACLcB/s640/%25D0%259A%25D0%25BB%25D0%25B8%25D0%25BF%25D0%25B5%25D1%2580_Infografia.jpg" title="spacecraft by RSC Energia." width="640"></a></p><br>
<br>
<div>
<p>Kliper&nbsp;was a proposed partly&nbsp;<a title="Reusable launch system" href="https://en.wikipedia.org/wiki/Reusable_launch_system">reusable</a>&nbsp;manned&nbsp;<a title="Spacecraft" href="https://en.wikipedia.org/wiki/Spacecraft">spacecraft</a>&nbsp;by&nbsp;<a title="S.P. Korolev Rocket and Space Corporation Energia" href="https://en.wikipedia.org/wiki/S.P._Korolev_Rocket_and_Space_Corporation_Energia">RSC Energia</a>. Due to lack of funding from the ESA and RSA, the project has been indefinitely postponed as of 2006. <a href="https://en.wikipedia.org/wiki/Kliper" target="_blank" rel="nofollow">Source</a></p>
<p>Designed primarily to replace the&nbsp;<a title="Soyuz spacecraft" href="https://en.wikipedia.org/wiki/Soyuz_spacecraft">Soyuz spacecraft</a>, Kliper was proposed in two versions: as a pure&nbsp;<a title="Lifting body" href="https://en.wikipedia.org/wiki/Lifting_body">lifting body</a>&nbsp;design and as<a title="Spaceplane" href="https://en.wikipedia.org/wiki/Spaceplane">spaceplane</a>&nbsp;with small&nbsp;<a title="Wing" href="https://en.wikipedia.org/wiki/Wing">wings</a>. In either case, the craft would have been able to glide into the atmosphere at an angle that produces much less stress on the human occupants than the current Soyuz. Kliper was intended to be designed to be able to carry up to six people and to perform ferry services between Earth and the&nbsp;<a title="International Space Station" href="https://en.wikipedia.org/wiki/International_Space_Station">International Space Station</a>.</p>
<p><a href="https://2.bp.blogspot.com/-YBFudwoXK3Q/V6iuRRYYdOI/AAAAAAAABS0/C6Me6merYrY-ciSKCcGxOkMx-CabSkeQQCLcB/s1600/cliperan2.gif"><img alt="Kliper (–ö–ª–∏–ø–µ—Ä, English: Clipper) was a proposed partly reusable manned spacecraft by RSC Energia." height="173" src="https://2.bp.blogspot.com/-YBFudwoXK3Q/V6iuRRYYdOI/AAAAAAAABS0/C6Me6merYrY-ciSKCcGxOkMx-CabSkeQQCLcB/s400/cliperan2.gif" title="Kliper (–ö–ª–∏–ø–µ—Ä, English: Clipper) was a proposed partly reusable manned spacecraft by RSC Energia." width="400"></a></p>
<p><a href="https://3.bp.blogspot.com/-aalzuaqor_8/V6iuIEwP4xI/AAAAAAAABSg/7J4fzKwYq-8xHUTn7PBkoZmN3oygLP8LgCLcB/s1600/cliper05.gif"><img height="227" src="https://3.bp.blogspot.com/-aalzuaqor_8/V6iuIEwP4xI/AAAAAAAABSg/7J4fzKwYq-8xHUTn7PBkoZmN3oygLP8LgCLcB/s400/cliper05.gif" width="400"></a></p>
<p><a href="https://2.bp.blogspot.com/-2fm-a4DRCOg/V6iuIOu-FgI/AAAAAAAABSk/iBERytjejZAx0SR_pVzGyPovDNhCquSuACLcB/s1600/cliper07.gif"><img height="162" src="https://2.bp.blogspot.com/-2fm-a4DRCOg/V6iuIOu-FgI/AAAAAAAABSk/iBERytjejZAx0SR_pVzGyPovDNhCquSuACLcB/s640/cliper07.gif" width="640"></a></p>
<p><a href="https://3.bp.blogspot.com/-71vQS8q3AtQ/V6iuKHoZdoI/AAAAAAAABSo/8ssaVZSXKwAQimgqlWlfVn3nVePBVrxGwCLcB/s1600/cliper09.gif"><img alt="Kliper (–ö–ª–∏–ø–µ—Ä, English: Clipper) was a proposed partly reusable manned spacecraft by RSC Energia." height="417" src="https://3.bp.blogspot.com/-71vQS8q3AtQ/V6iuKHoZdoI/AAAAAAAABSo/8ssaVZSXKwAQimgqlWlfVn3nVePBVrxGwCLcB/s640/cliper09.gif" title="Kliper RSC Energia." width="640"></a></p>
<p><a href="https://2.bp.blogspot.com/-4RaU28U7s8Y/V6iuOuvWlHI/AAAAAAAABSs/SepEgtWvjVEdsvrOGsAalTmO6W3R3MHVQCLcB/s1600/clipeani.gif"><img height="180" src="https://2.bp.blogspot.com/-4RaU28U7s8Y/V6iuOuvWlHI/AAAAAAAABSs/SepEgtWvjVEdsvrOGsAalTmO6W3R3MHVQCLcB/s400/clipeani.gif" width="400"></a></p><br>
<br>
</div><br>
</div><br>

</div></div>]]>
            </description>
            <link>https://www.xissufotoday.space/2018/04/declassified-spacecrafts-and-orbital.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26166204</guid>
            <pubDate>Wed, 17 Feb 2021 13:48:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why did I leave Google or, why did I stay so long?]]>
            </title>
            <description>
<![CDATA[
Score 789 | Comments 794 (<a href="https://news.ycombinator.com/item?id=26165809">thread link</a>) | @mrowland
<br/>
February 17, 2021 | https://paygo.media/p/25171 | <a href="https://web.archive.org/web/*/https://paygo.media/p/25171">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://paygo.media/p/25171</link>
            <guid isPermaLink="false">hacker-news-small-sites-26165809</guid>
            <pubDate>Wed, 17 Feb 2021 12:59:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How I started believing in Cycle Time over Estimation]]>
            </title>
            <description>
<![CDATA[
Score 50 | Comments 20 (<a href="https://news.ycombinator.com/item?id=26165779">thread link</a>) | @snorberhuis
<br/>
February 17, 2021 | https://www.norberhuis.nl/how-i-started-believing-in-cycle-time-over-estimation/ | <a href="https://web.archive.org/web/*/https://www.norberhuis.nl/how-i-started-believing-in-cycle-time-over-estimation/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
                <div>
                    <p>Cycle time is the time it takes to produce value. In software engineering, this is the time between a team starting to develop a feature and delivering this to the customer. Most backlog tools track this data and show it in control charts. You can use cycle time data to predict how long an individual item will take. You can find more explanation <a href="https://www.youtube.com/watch?v=QVBlnCTu9Ms">here</a>.</p><p>I keep telling the following story over and over when I see teams trying to do Estimation while everyone knows that Estimation is a charade. So I thought I could write it down and share it. I believe a story like this will explain the theory how Cycle Time works better than Estimation in a much more lively way.</p><h2 id="background"><strong>Background</strong></h2><p>At the time of the story, I worked with a team that had a hard time planning. I joined after a Lift &amp; Shift to AWS and the company asked me to help get into control. The platform consisted of multiple legacy systems, all working together in complex ways. Before the migration, the hosting of the platform was outsourced resulting in &nbsp;developers not spending any time on pipelines and maintainability in the decade before.</p><p>We had trouble supporting other development teams consuming our platform due to the many operational incidents. Most of the work on new features stalled. We could never estimate when we would finish new features because work could be disrupted by sudden firefighting in production. After some time and by applying engineering to increase reliability, we started to build features again and people began requesting expected dates again. We estimated those dates, but we did not make those dates time and time again due to unforeseen complexity.</p><figure><img src="https://www.norberhuis.nl/content/images/2021/01/andrew-gaines-s76S64umXpo-unsplash.jpg" alt="" srcset="https://www.norberhuis.nl/content/images/size/w600/2021/01/andrew-gaines-s76S64umXpo-unsplash.jpg 600w, https://www.norberhuis.nl/content/images/size/w1000/2021/01/andrew-gaines-s76S64umXpo-unsplash.jpg 1000w, https://www.norberhuis.nl/content/images/size/w1600/2021/01/andrew-gaines-s76S64umXpo-unsplash.jpg 1600w, https://www.norberhuis.nl/content/images/size/w2400/2021/01/andrew-gaines-s76S64umXpo-unsplash.jpg 2400w" sizes="(min-width: 720px) 720px"><figcaption>Fire Fighting can happen in DevOps teams.</figcaption></figure><p>That we had a major problem became apparent to me when the team started to talk about a new project. I asked what it was about, and the team said they were already refining it for over a year but never came to it. The company expected the team to deliver this big project that would be strategical to the future. But it was unthinkable that we would make any headway in this in the coming time.</p><p>So I proposed we push out this project and have a new team work on it. The new team started delivering after some ramp-up time, but this new team still needed some support from us for some small features on our platform.</p><h2 id="predicting-a-feature-toggle">Predicting a Feature Toggle</h2><p>This new team requested a significant feature in our platform's critical component. We already built this feature and were running it on Acceptance for months. It was turned off in production by a feature flag. Producing this feature would be a simple change in our Configuration as Code and push it to production.</p><p>At the end of a Friday afternoon, the project manager asked our team when we would deliver this feature. The weeks before, he already gave some estimations that we didn't make. So he was reluctant to provide an estimate. At the time, I was telling the team that we should stop with estimation and do more in-depth data-driven planning. So he asked me over: "Hey, what would you say?"</p><figure><img src="https://www.norberhuis.nl/content/images/2021/01/viva-luna-studios-y3qrbAgm7q8-unsplash.jpg" alt="" srcset="https://www.norberhuis.nl/content/images/size/w600/2021/01/viva-luna-studios-y3qrbAgm7q8-unsplash.jpg 600w, https://www.norberhuis.nl/content/images/size/w1000/2021/01/viva-luna-studios-y3qrbAgm7q8-unsplash.jpg 1000w, https://www.norberhuis.nl/content/images/size/w1600/2021/01/viva-luna-studios-y3qrbAgm7q8-unsplash.jpg 1600w, https://www.norberhuis.nl/content/images/size/w2400/2021/01/viva-luna-studios-y3qrbAgm7q8-unsplash.jpg 2400w" sizes="(min-width: 720px) 720px"><figcaption>Estimation can feel like drawing Tarot cards.</figcaption></figure><p>I answered: "Let's pull up the Control Chart to see our Cycle Time.". There we are leaned over the display: the project manager, the team lead, and me. I moved the mouse over the control chart. A pop-up showed our rolling average: '5d 6hr. I stood up straight and said: "Our average is five days 6 hours with a standard deviation of up to two weeks.".</p><p>I could tell confusion from the look of my team lead. How could I say it would take over five days for a change that we estimate to take 10 minutes! I didn't really have the answer, but I just said that it takes us that time to deliver on average. But somehow, it did feel right. We agreed that it would be the first thing picked up on Monday. Satisfied that we at least would work on it, the project manager accepted the answer. Probably this was his goal anyway, not expecting any real date from us seeing our previous performance.</p><h2 id="delivering-a-feature-toggle">Delivering a feature toggle</h2><p>On Monday, we started with the stand-up and discussed picking up this task. Another engineer proposed fixing a bug on another component first before turning on the flag. We would generate a lot of extra load by turning on the feature flag. We could not test this in our acceptance environment. This bug was related to load. The component would make it more likely to handle it by fixing it. We decided to do this because if that component fails, the whole platform will go down. So that is already a day delay.</p><p>At the end of the day, I looked at the board and didn't see the bug moving to the release column. I gathered the team and asked if the bug fix is ready to be deployed after hours. The bug fix was reviewed and tested, ready to be deployed. But as it is such a crucial component for the whole platform, someone reminded us that we had to ask the release manager.</p><p>So we asked the release manager if we could deploy this. He exploded: "No way we can deploy this! We need to request all teams to test this change! I have to notify management if we deploy any changes to that component! That takes a full day." So we planned to release it the next day.</p><p>Tuesday, we notified all teams of our change and asked them to test it. They tested it on Acceptance during the day. They found no problem, so the bug fix was ready to be released in the combined release. Little did we know that a feature by another team was also in the combined changeset. This feature would break on production. After the release, customers started calling, so the release engineer reverted the release. The other team had to fix this bug the next day.</p><p>On Wednesday, the other team saw that the release failed due to their new bug and started to fix it. That evening a new release was scheduled with their and our bug fix. So our bug fix was finally in production.</p><p>So our bug fix was finally in production on Thursday. We turned on the feature flag. The feature started to be available on production and it worked.</p><figure><img src="https://www.norberhuis.nl/content/images/2021/01/spacex--p-KCm6xB9I-unsplash.jpg" alt="" srcset="https://www.norberhuis.nl/content/images/size/w600/2021/01/spacex--p-KCm6xB9I-unsplash.jpg 600w, https://www.norberhuis.nl/content/images/size/w1000/2021/01/spacex--p-KCm6xB9I-unsplash.jpg 1000w, https://www.norberhuis.nl/content/images/size/w1600/2021/01/spacex--p-KCm6xB9I-unsplash.jpg 1600w, https://www.norberhuis.nl/content/images/size/w2400/2021/01/spacex--p-KCm6xB9I-unsplash.jpg 2400w" sizes="(min-width: 720px) 720px"></figure><h2 id="capturing-complexity-in-data">Capturing Complexity in Data</h2><p>Our estimation of 10 minutes resulted in a Cycle Time of 4 days and 5 hours. The combination of the level of practices, the complexity of systems, and collaboration between teams caused this delay and are present in any sociotechnical system. These can all be improved, but that is not the point of this story. That takes time and work, while some features need to be delivered in the meantime. As humans, it is impossible to consider all the potential complexity. That is why we cannot estimate correctly. But Cycle Time data can and does.</p><p>We did not consider a legacy system with bugs and scaling problems. But we have run into this before while delivering other tasks. That complexity is captured in the data.</p><p>We did not consider a combined release process with a Release Manager. But previous releases failed before due to bugs introduced by other teams. But the tracking tools do measure these delays in previous task completion times.</p><p>This story is how I turned into a firm believer in using Cycle Time as a planning tool. Afterward, I have seen the same story play out time and time again but due to different complexities: the maturity of third parties, CISO, and so much more. I now never give any estimations anymore. Not using estimation require training. But planning is so important that using a charade like estimation is harmful.</p><p>If you liked this story, I would recommend to follow me on twitter: <a href="https://twitter.com/SNorberhuis">@snorberhuis</a>. I regularly tweet about Software Development. If you need any help to get into control in Agile or DevOps, feel free to contact me!</p><p>A major thank you goes out to <a href="https://twitter.com/pogrebnyak">Stanislav Pogrebnyak</a> to introduce me to <a href="https://www.youtube.com/watch?v=QVBlnCTu9Ms">#NoEstimates</a>. All photos are from <a href="https://unsplash.com/">unsplash</a>.</p>
                </div>
            </section></div>]]>
            </description>
            <link>https://www.norberhuis.nl/how-i-started-believing-in-cycle-time-over-estimation/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26165779</guid>
            <pubDate>Wed, 17 Feb 2021 12:53:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Designing a RISC-V CPU, Part 1: Learning hardware design as a software engineer]]>
            </title>
            <description>
<![CDATA[
Score 35 | Comments 3 (<a href="https://news.ycombinator.com/item?id=26164574">thread link</a>) | @lochsh
<br/>
February 17, 2021 | https://mcla.ug/blog/risc-v-cpu-part-1.html | <a href="https://web.archive.org/web/*/https://mcla.ug/blog/risc-v-cpu-part-1.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<div>
	
	<p><span>Tue 16 February 2021</span></p><p>I have no experience in digital logic design. That is, I didn't until I
recently decided that I would like to try designing my own CPU and running it
on an FPGA! If you too are a software engineer with a vague interest in
hardware design, I hope this series of posts about what I've learnt will be
helpful and interesting. In this first installment, I hope to answer these
questions:</p>
<ul>
<li>
<p>What is digital logic design?</p>
</li>
<li>
<p>How do I get started, and what tools might I use?</p>
</li>
</ul>
<p>In future installments, I will go into more detail about my CPU design and the
RISC-V architecture, as well as hopefully answering these questions:</p>
<ul>
<li>
<p>What about digital logic design is fundamentally different from software
  design?</p>
</li>
<li>
<p>What about digital logic design is similar to software design?</p>
</li>
</ul>
<p>You can see the code for my CPU at the time of writing
<a href="https://github.com/lochsh/riscy-boi/tree/47e94dc6e9665f73c871add002c34d1516fd5106">here</a>
or an up to date version <a href="https://github.com/lochsh/riscy-boi">here</a>.</p>
<h2>What is digital logic design?</h2>
<p>Digital logic design is designing logic circuits that operate on binary values.
The elementary components are logic gates: an AND gate, for example, has two
inputs and one output. The output is 1 iff<sup id="fnref:1"><a href="#fn:1">1</a></sup> both inputs are 1.</p>
<p>Typically, we design synchronous circuits which use flip-flops to store state,
and thereby synchronise the operation of the circuit to a common clock.
Flip-flops are composed of logic gates.</p>
<p>Analogue circuit design is concerned with the electronic components that make
up logic gates, like transistors and diodes. This level of abstraction is often
needed for applications dealing directly with signals derived from analogue
sensors, like radio receivers. When designing a CPU, this level of abstraction
would not be feasible: modern CPUs can have billions of transistors!</p>
<p>Instead, we use tools that can translate our digital logic design into
different useful formats: the configuration of an FPGA (see below); a
simulation; silicon layout.</p>
<h2>What is an FPGA and why are they used?</h2>
<p>We noted above that the same digital logic design tools can be used whether we
are creating a custom ASIC to be made into silicon, or configuring an FPGA. A
Field-Programmable Gate Array is an integrated circuit containing an array of
programmable logic blocks. You could imagine it is as a big array of logic
gates that can be connected together in various ways.</p>
<p>Making a custom chip generally costs millions, and of course once your chip is
manufactured it cannot be changed. Thus, generally FPGAs are used when:</p>
<ul>
<li>
<p>You cannot afford to create a custom ASIC due to lack of capital (e.g. if
  you're just some hacker like me and not ARM or Intel)</p>
</li>
<li>
<p>You cannot afford to create a custom ASIC because your volume is too low to
  make it worth the high one-off costs (e.g. if you are making a small quantity
  of MRI machines with custom data acquisition hardware)</p>
</li>
<li>
<p>You need the flexibility</p>
</li>
</ul>
<p>The downsides? FPGAs have a much higher per-chip cost, and they are generally
much slower as a consequence of being able to connect logic blocks together in
very flexible ways. In contrast, a custom design can be reduced to the minimum
number of transistors, with no concern for flexibility.</p>
<p>I think it's helpful context to compare the custom ASIC design process against
that of an FPGA design:</p>
<ul>
<li>
<p><span>Logic design</span>: just like we'd do for an FPGA, the logic design of an ASIC is
  done in a hardware description language.</p>
</li>
<li>
<p><span>Verification</span>: FPGA designs may well be verified, but you might expect the
  process for an ASIC design to be more rigorous ‚Äì after all, the design
  can't be changed once manufactured! Often verification will involve formally
  verifying<sup id="fnref:2"><a href="#fn:2">2</a></sup> parts of the design.</p>
</li>
<li>
<p><span>Synthesis</span>: This creates a <em>netlist</em>: a list of logic blocks and their
  connections. The connections are called <em>nets</em>, and the blocks are called
  <em>cells</em>. For both FPGAs and ASICs, the cells are vendor-specific.</p>
</li>
<li>
<p><span>Placement and routing</span> (P&amp;R): for an FPGA, this involves mapping the logic
  blocks described in the netlist to actual blocks in the FPGA. The resulting
  binary is often called a <em>bitstream</em>.  For an ASIC, this involves deciding
  where to place the cells on the silicon, and how to connect them up. Both
  applications generally use automated optimisation tools for this.</p>
</li>
</ul>
<h2>What tools do I need?</h2>
<h3>A hardware description language: I am using <a href="https://github.com/nmigen/nmigen">nMigen</a><sup id="fnref:3"><a href="#fn:3">3</a></sup></h3>
<p>You may have heard of Verilog or VHDL: both popular hardware description
languages (HDLs). I use "popular" here to mean widely used, not widely loved.</p>
<p>I won't pretend to know much about these tools: I only know that smarter people
than me with vast logic design experience have a lot of hate for them.
Due to the problems with Verilog and other similar tools, there have been
various attempts at making more useful and friendlier alternatives.  nMigen is
one such project, which creates a domain-specific language in Python. In their
own words:</p>
<blockquote>
<p>Despite being faster than schematics entry, hardware design with Verilog and
VHDL remains tedious and inefficient for several reasons. The event-driven
model introduces issues and manual coding that are unnecessary for
synchronous circuits, which represent the lion's share of today's logic
designs. Counterintuitive arithmetic rules result in steeper learning curves
and provide a fertile ground for subtle bugs in designs. Finally, support for
procedural generation of logic (metaprogramming) through "generate"
statements is very limited and restricts the ways code can be made generic,
reused and organized.</p>
<p>To address those issues, we have developed the nMigen FHDL, a library that
replaces the event-driven paradigm with the notions of combinatorial and
synchronous statements, has arithmetic rules that make integers always behave
like mathematical integers, and most importantly allows the design's logic to
be constructed by a Python program. This last point enables hardware
designers to take advantage of the richness of the Python language‚Äîobject
oriented programming, function parameters, generators, operator overloading,
libraries, etc.‚Äîto build well organized, reusable and elegant designs.</p>
</blockquote>
<p>If, like me, you've never used Verilog, then not all of this will have more
than abstract meaning to you. But it certainly sounds promising,
and I can attest that it has been very straightforward to get started with
logic design without the reportedly large barrier of grappling with Verilog. I
would recommend it, particularly if you are already familiar with Python!</p>
<p>The only downside I can think of is that nMigen is still in development, and
in particular the documentation is not complete. There is a helpful community
at #nmigen on <a href="https://mcla.ug/blog/chat.freenode.net">chat.freenode.net</a>.</p>
<h3>A wave viewer for inspecting simulations: I am using <a href="http://gtkwave.sourceforge.net/">GTKWave</a></h3>
<p>nMigen provides simulation tooling: I use it in my tests, written using
<code>pytest</code>. I record the signals during these tests and view them in a wave
viewer to help debug.</p>
<p><img alt="gtkwave" src="https://mcla.ug/blog/images/gtkwave.png" title="A screenshot of GTKWave"></p>
<h3>Optional: An FPGA dev board. I am using a myStorm BlackIce II</h3>
<p>You don't need an FPGA dev board to create your own CPU. You could do
everything in simulation! The fun of having a board to work with, for me, is
being able to flash LEDs and see my design in action.</p>
<p>Of course, if you were creating something more useful than my very basic CPU,
then you would probably want some hardware to run it on, and this would be less
"optional"!</p>
<h2>Getting started with nMigen</h2>
<p>Rather than immediately trying to design a CPU, I started by making an
Arithmetic Logic Unit (ALU) in nMigen. The ALU is a key piece of any CPU design
that I have seen: it performs arithmetic operations.</p>
<p>Why start with this? I knew I would need an ALU for my CPU; I knew I could make
a simple one; I knew that the feeling of making something is an important
motivator when starting a new project!</p>
<p>My design looked something like this:</p>

<div>
<pre id="vimCodeElement"><span id="L1"> 1 </span><span>"""</span><span>Arithmetic Logic Unit</span><span>"""</span>
<span id="L2"> 2 </span><span>import</span> enum
<span id="L3"> 3 </span>
<span id="L4"> 4 </span><span>import</span> nmigen <span>as</span> nm
<span id="L5"> 5 </span>
<span id="L6"> 6 </span>
<span id="L7"> 7 </span><span>class</span> <span>ALUOp</span><span>(</span>enum<span>.</span>IntEnum<span>)</span><span>:</span>
<span id="L8"> 8 </span>    <span>"""</span><span>Operations for the ALU</span><span>"""</span>
<span id="L9"> 9 </span>    ADD <span>=</span> <span>0</span>
<span id="L10">10 </span>    SUB <span>=</span> <span>1</span>
<span id="L11">11 </span>
<span id="L12">12 </span>
<span id="L13">13 </span><span>class</span> <span>ALU</span><span>(</span>nm<span>.</span>Elaboratable<span>)</span><span>:</span>
<span id="L14">14 </span>    <span>"""</span>
<span id="L15">15 </span><span>    Arithmetic Logic Unit</span>
<span id="L16">16 </span>
<span id="L17">17 </span><span>    * op (in): the opcode</span>
<span id="L18">18 </span><span>    * a (in): the first operand</span>
<span id="L19">19 </span><span>    * b (in): the second operand</span>
<span id="L20">20 </span>
<span id="L21">21 </span><span>    * o (out): the output</span>
<span id="L22">22 </span><span>    </span><span>"""</span>
<span id="L23">23 </span>
<span id="L24">24 </span>    <span>def</span> <span>__init__</span><span>(</span>self<span>,</span> width<span>)</span><span>:</span>
<span id="L25">25 </span>        <span>"""</span>
<span id="L26">26 </span><span>        Initialiser</span>
<span id="L27">27 </span>
<span id="L28">28 </span><span>        Args:</span>
<span id="L29">29 </span><span>            width (int): data width</span>
<span id="L30">30 </span><span>        </span><span>"""</span>
<span id="L31">31 </span>        self<span>.</span>op <span>=</span> nm<span>.</span>Signal<span>()</span>
<span id="L32">32 </span>        self<span>.</span>a <span>=</span> nm<span>.</span>Signal<span>(</span>width<span>)</span>
<span id="L33">33 </span>        self<span>.</span>b <span>=</span> nm<span>.</span>Signal<span>(</span>width<span>)</span>
<span id="L34">34 </span>        self<span>.</span>o <span>=</span> nm<span>.</span>Signal<span>(</span>width<span>)</span>
<span id="L35">35 </span>
<span id="L36">36 </span>    <span>def</span> <span>elaborate</span><span>(</span>self<span>,</span> _<span>)</span><span>:</span>
<span id="L37">37 </span>        m <span>=</span> nm<span>.</span>Module<span>()</span>
<span id="L38">38 </span>
<span id="L39">39 </span>        <span>with</span> m<span>.</span>Switch<span>(</span>self<span>.</span>op<span>)</span><span>:</span>
<span id="L40">40 </span>            <span>with</span> m<span>.</span>Case<span>(</span>ALUOp<span>.</span>ADD<span>)</span><span>:</span>
<span id="L41">41 </span>                m<span>.</span>d<span>.</span>comb <span>+=</span> self<span>.</span>o<span>.</span>eq<span>(</span>self<span>.</span>a <span>+</span> self<span>.</span>b<span>)</span>
<span id="L42">42 </span>            <span>with</span> m<span>.</span>Case<span>(</span>ALUOp<span>.</span>SUB<span>)</span><span>:</span>
<span id="L43">43 </span>                m<span>.</span>d<span>.</span>comb <span>+=</span> self<span>.</span>o<span>.</span>eq<span>(</span>self<span>.</span>a <span>-</span> self<span>.</span>b<span>)</span>
<span id="L44">44 </span>        <span>return</span> m
</pre>
</div>

<p>As you can see, we've created a lot of nMigen <code>Signal</code> instances to represent
well...the signals that define the interface to our ALU! But what is this
<code>elaborate</code> method? My understanding is that "elaboration" is the name for the
first step in synthesising the netlist (see above). The idea in the nMigen code
above is that we've created some <em>elaboratable</em> structure (by inheriting from
<code>nm.Elaboratable</code>), i.e. something that describes digital logic we want to
synthesise. The <code>elaborate</code> method describes that digital logic. It has to
return an nMigen <code>Module</code>.</p>
<p>Let's have a closer look at the contents of the <code>elaborate</code> method. The
<code>Switch</code> will create some kind of decision logic in the synthesised design.
But what is <code>m.d.comb</code>? nMigen has the concept of synchronous (<code>m.d.sync</code>)
and combinatorial<sup id="fnref:4"><a href="#fn:4">4</a></sup> (<code>m.d.comb</code>) control domains. From the nMigen
<a href="https://nmigen.info/nmigen/latest/lang.html#lang-domains">docs</a>:</p>
<blockquote>
<p>A control domain is a named group of signals that change their value in
identical conditions.</p>
<p>All designs have a single predefined <em>combinatorial domain</em>, containing all
signals that change immediately when any value used to compute them changes.
The name comb is reserved for the combinatorial domain.</p>
<p>A design can also have any amount of user-defined <em>synchronous domains</em>, also
called clock domains, containing signals that change when a specific edge
occurs on the domain‚Äôs ‚Ä¶</p></blockquote></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://mcla.ug/blog/risc-v-cpu-part-1.html">https://mcla.ug/blog/risc-v-cpu-part-1.html</a></em></p>]]>
            </description>
            <link>https://mcla.ug/blog/risc-v-cpu-part-1.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26164574</guid>
            <pubDate>Wed, 17 Feb 2021 09:45:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Dear Email Industry, We've Got a GDPR Problem]]>
            </title>
            <description>
<![CDATA[
Score 58 | Comments 88 (<a href="https://news.ycombinator.com/item?id=26164553">thread link</a>) | @iamacyborg
<br/>
February 17, 2021 | https://www.jacquescorbytuech.com/writing/gdpr-email-tracking | <a href="https://web.archive.org/web/*/https://www.jacquescorbytuech.com/writing/gdpr-email-tracking">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section id="content">
<article>
<header>

</header>
<p><small><time datetime="2019-06-10T13:37:00+01:00">
      Mon 10 June 2019
    </time></small>
</p>
<div>
<p><strong>The email industry's got a GDPR problem.</strong></p>
<p>Some of you reading this might have seen me talk about this problem in the very excellent <a href="https://email.geeks.chat/">Email Geeks Community</a>, but if you're new, let me break it down for you.</p>
<p>Last year, the GDPR came into effect, which put in place some rigorous laws around data processing and how personally identifiable information (PII) has to be handled. This stressed out a lot of email marketers, who quite rightly realised that the new regulations would have a significant effect on their ability to acquire and market to customers via their email address (which counts as PII). </p>
<p>Now if you're reading this, you're probably familiar with how that's gone, so I won't bore you with the details.</p>

<h2>So What's the Problem?</h2>
<p>The overwhelming majority of commercial email sent today contains tracking pixels and tracking links, these are used to uniquely identify individuals so that opens and clicks can be correctly attributed to them. This isn't strictly a problem, the GDPR does not ban processing of personal data for tracking purposes, however email tracking frequently fails to meet a number of criteria necessary to be legal under the GDPR.</p>
<p><strong>We're not collection consent to track user behaviour</strong> - That means we're probably relying on good old Legitimate Interest and that's frought with a number of risks.</p>
<p>Firstly, most brands aren't disclosing in their privacy policies or at moment of signup that they're tracking user behaviour in marketing emails. That's a problem. <a href="https://gdpr-info.eu/art-5-gdpr/">Article 5</a> clearly states that to be legally compliant, personal data should be processed in the following manner:</p>
<blockquote>
<p>processed lawfully, fairly and in a transparent manner in relation to the data subject (‚Äòlawfulness, fairness and transparency‚Äô);</p>
</blockquote>
<p>This is further expanded upon in <a href="https://gdpr-info.eu/recitals/no-39/">Recital 39</a>:</p>
<blockquote>
<p>It should be transparent to natural persons that personal data concerning them are collected, used, consulted or otherwise processed and to what extent the personal data are or will be processed.</p>
</blockquote>
<p>Failure to adequately disclose email tracking within your brand's privacy policy is a clear breach of the regulation.</p>
<p>Secondly, when Legitimate Interest is used as the legal basis for processing of personal data, the data subject has the <a href="https://gdpr-info.eu/art-21-gdpr/">Right to Object</a>.</p>
<blockquote>
<p>The data subject shall have the right to object, on grounds relating to his or her particular situation, at any time to processing of personal data concerning him or her which is based on point (e) or (f) of Article 6(1), including profiling based on those provisions.</p>
</blockquote>
<p>This means that when processing data under a Legitimate Interest basis, the data subject has the right to object to your tracking, this brings us round to our second problem.</p>

<h2>Email Marketing Platforms Are Not GDPR Compliant‚Ä†</h2>
<p>Take a look at your ESP, does it allow you to, on a per individual basis, opt-out of email tracking?</p>
<p>If the answer to that is no, and in most cases the answer will be no, you're in breach of the GDPR as soon as a customer objects to your data processing. That is assuming you disclose the tracking in your privacy policy, if you don't you're already in breach.</p>
<p>This becomes even more of a legal quagmire as soon as we start looking at tracking in emails sent on a legal basis other than Consent or Legitimate Interest.</p>
<p>So what can you do about it?</p>
<p><strong>Complain to your ESP!</strong> Complain frequently and loudly. Make them do something about it. Ultimately the GDPR is here to stay, and ESP's must put in the work to allow marketers to comply with the law.</p>

<h2>Where Does That Leave Email Marketing?</h2>
<p>Email marketing isn't going anywhere, email remains one of the most valuable channels for reaching your customers and losing the ability to track behavioural data isn't going to change that fundamental fact. What is going to change is our ability to act upon vast swathes of personal data.</p>
<p>You know what?</p>
<p>That's not a problem, personal data is not a crucial part of gauging the success of a campaign and anonymised data is more than good enough for us to achieve our objectives.</p>
<p>I'll leave you with a parting note; as marketers, we've become entirely too comfortable handling vast swathes of personal data, it's time we get used to a world where that option isn't always going to be available to us. </p>
<hr>
<p>Usual caveats apply. I am not a lawyer.</p>
<p>‚Ä† <em>Yes, I know a small minority are, but they're a small minority. This might be one of the very few instances in which I'd recommend SFMC</em></p>
<p>Cheers,</p>
<p><img alt="signature" src="https://www.jacquescorbytuech.com/images/jacques.png">
</p></div>
<div>
<h4>Subscribe for updates</h4>

<p>Updates, whenever I've got something valuable to say.</p>
</div>
</article>
</section></div>]]>
            </description>
            <link>https://www.jacquescorbytuech.com/writing/gdpr-email-tracking</link>
            <guid isPermaLink="false">hacker-news-small-sites-26164553</guid>
            <pubDate>Wed, 17 Feb 2021 09:42:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Easy Forth: Learn forth with REPL in the browser]]>
            </title>
            <description>
<![CDATA[
Score 100 | Comments 30 (<a href="https://news.ycombinator.com/item?id=26164275">thread link</a>) | @guerrilla
<br/>
February 17, 2021 | https://skilldrick.github.io/easyforth | <a href="https://web.archive.org/web/*/https://skilldrick.github.io/easyforth">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>

        

<h2 id="introduction">Introduction</h2>

<p>This small ebook is here to teach you a programming language called Forth. Forth is a
language unlike most others. It‚Äôs not functional <em>or</em> object oriented, it doesn‚Äôt
have type-checking, and it basically has zero syntax. It was written in the 70s, but
is still used today for
<a href="http://www.forth.com/resources/apps/more-applications.html">certain applications</a>.</p>

<p>Why would you want to learn such an odd language? Every new programming
language you learn helps you think about problems in new ways. Forth is very
easy to learn, but it requires you to think in a different way than you‚Äôre used
to. That makes it a perfect language to broaden your coding horizons.</p>

<p>This book includes a simple implementation of Forth I wrote in JavaScript. It‚Äôs by
no means perfect, and is missing a lot of the functionality you‚Äôd expect in a real
Forth system. It‚Äôs just here to give you an easy way to try out the examples. (If
you‚Äôre a Forth expert, please
<a href="https://github.com/skilldrick/easyforth">contribute here</a> and make it better!)</p>

<p>I‚Äôm going to assume that you know at least one other programming language, and have
a basic idea of how stacks work as a data structure.</p>

<h2 id="adding-some-numbers">Adding Some Numbers</h2>

<p>The thing that separates Forth from most other languages is its use of the
stack. In Forth, everything revolves around the stack. Any time you type a
number, it gets pushed onto the stack. If you want to add two numbers together,
typing <code>+</code> takes the top two numbers off the stack, adds them, and puts
the result back on the stack.</p>

<p>Let‚Äôs take a look at an example. Type (don‚Äôt copy-paste) the following into the
interpreter, typing <code>Enter</code> after each line.</p>

<pre><code>1
2
3
</code></pre>



<p>Every time you type a line followed by the <code>Enter</code> key, the Forth interpreter
executes that line, and appends the string <code>ok</code> to let you know there were no
errors. You should also notice that as you execute each line, the area at the
top fills up with numbers. That area is our visualization of the stack. It
should look like this:</p>

<p>1 2 3 &lt;- Top</p>

<p>Now, into the same interpreter, type a single <code>+</code> followed by the <code>Enter</code> key. The top two
elements on the stack, <code>2</code> and <code>3</code>, have been replaced by <code>5</code>.</p>

<p>1 5 &lt;- Top</p>

<p>At this point, your editor window should look like this:</p>

<p>1  <span>ok</span>
2  <span>ok</span>
3  <span>ok</span>
+  <span>ok</span>
</p>

<p>Type <code>+</code> again and press <code>Enter</code>, and the top two elements will be replaced by 6. If
you type <code>+</code> one more time, Forth will try to pop the top two elements off the
stack, even though there‚Äôs only <em>one</em> element on the stack! This results in a
<code>Stack underflow</code> error:</p>

<p>1  <span>ok</span>
2  <span>ok</span>
3  <span>ok</span>
+  <span>ok</span>
+  <span>ok</span>
+  <span>Stack underflow</span>
</p>

<p>Forth doesn‚Äôt force you to type every token as a separate line. Type the
following into the next editor, followed by the <code>Enter</code> key:</p>

<pre><code>123 456 +
</code></pre>



<p>The stack should now look like this:</p>

<p>579 &lt;- Top</p>

<p>This style, where the operator appears after the operands, is known as
<a href="https://en.wikipedia.org/wiki/Reverse_Polish_notation">Reverse-Polish
notation</a>. Let‚Äôs try
something a bit more complicated, and calculate <code>10 * (5 + 2)</code>. Type the
following into the interpreter:</p>

<pre><code>5 2 + 10 *
</code></pre>



<p>One of the nice things about Forth is that the order of operations is
completely based on their order in the program. For example, when executing <code>5
2 + 10 *</code>, the interpreter pushes 5 to the stack, then 2, then adds them and
pushes the resulting 7, then pushes 10 to the stack, then multiplies 7 and 10.
Because of this, there‚Äôs no need for parentheses to group operators with lower
precedence.</p>

<h3 id="stack-effects">Stack Effects</h3>

<p>Most Forth words affect the stack in some way. Some take values off the stack,
some leave new values on the stack, and some do a mixture of both. These ‚Äústack
effects‚Äù are commonly represented using comments of the form <code>( before -- after
)</code>. For example, <code>+</code> is <code>( n1 n2 -- sum )</code> - <code>n1</code> and <code>n2</code> are the top two numbers
on the stack, and <code>sum</code> is the value left on the stack.</p>

<h2 id="defining-words">Defining Words</h2>

<p>The syntax of Forth is extremely straightforward. Forth code is interpreted as
a series of space-delimited words. Almost all non-whitespace characters are valid
in words. When the Forth interpreter reads a word, it checks to see if a
definition exists in an internal structure known as the Dictionary. If it is
found, that definition is executed. Otherwise, the word is assumed to be a
number, and it is pushed onto the stack. If the word cannot be converted to a
number, an error occurs.</p>

<p>You can try that out yourself below. Type <code>foo</code> (an unrecognized word)
and press enter.</p>



<p>You should see something like this:</p>

<p>foo  <span>foo ?</span></p>

<p><code>foo ?</code> means that Forth was unable to find a definition for <code>foo</code>, and it
wasn‚Äôt a valid number.</p>

<p>We can create our own definition of <code>foo</code> using two special words called <code>:</code>
(colon) and <code>;</code> (semicolon).  <code>:</code> is our way of telling Forth we want to create
a definition. The first word after the <code>:</code> becomes the definition name, and the
rest of the words (until the <code>;</code>) make up the body of the definition. It‚Äôs
conventional to include two spaces between the name and the body of the
definition. Try entering the following:</p>

<pre><code>: foo  100 + ;
1000 foo
foo foo foo
</code></pre>

<p><strong>Warning:</strong> A common mistake is to miss out the space before the <code>;</code> word. Because Forth
words are space delimited and can contain most characters, <code>+;</code> is a perfectly
valid word and is not parsed as two separate words.</p>



<p>As you‚Äôve hopefully figured out, our <code>foo</code> word simply adds 100 to the value on
top of the stack. It‚Äôs not very interesting, but it should give you an idea of
how simple definitions work.</p>

<h2 id="stack-manipulation">Stack Manipulation</h2>

<p>Now we can start taking a look at some of Forth‚Äôs predefined words. First,
let‚Äôs look at some words for manipulating the elements at the top of the stack.</p>

<h3 id="dup--n----n-n-"><code>dup ( n -- n n )</code></h3>

<p><code>dup</code> is short for ‚Äúduplicate‚Äù ‚Äì it duplicates the top element of the stack. For example,
try this out:</p>

<pre><code>1 2 3 dup
</code></pre>



<p>You should end up with the following stack:</p>

<p>1 2 3 3 &lt;- Top</p>

<h3 id="drop--n----"><code>drop ( n -- )</code></h3>

<p><code>drop</code> simply drops the top element of the stack. Running:</p>

<pre><code>1 2 3 drop
</code></pre>

<p>gives you a stack of:</p>

<p>1 2 &lt;- Top</p>



<h3 id="swap--n1-n2----n2-n1-"><code>swap ( n1 n2 -- n2 n1 )</code></h3>

<p><code>swap</code>, as you may have guessed, swaps the top two elements of the stack. For example:</p>

<pre><code>1 2 3 4 swap
</code></pre>

<p>will give you:</p>

<p>1 2 4 3 &lt;- Top</p>



<h3 id="over--n1-n2----n1-n2-n1-"><code>over ( n1 n2 -- n1 n2 n1 )</code></h3>

<p><code>over</code> is a bit less obvious: it takes the second element from the top of the
stack and duplicates it to the top of the stack. Running this:</p>

<pre><code>1 2 3 over
</code></pre>

<p>will result in this:</p>

<p>1 2 3 2 &lt;- Top</p>



<h3 id="rot--n1-n2-n3----n2-n3-n1-"><code>rot ( n1 n2 n3 -- n2 n3 n1 )</code></h3>

<p>Finally, <code>rot</code> ‚Äúrotates‚Äù the top <em>three</em> elements of the stack. The third
element from the top of the stack gets moved to the top of the stack, pushing
the other two elements down.</p>

<pre><code>1 2 3 rot
</code></pre>

<p>gives you:</p>

<p>2 3 1 &lt;- Top</p>



<h2 id="generating-output">Generating Output</h2>

<p>Next, let‚Äôs look at some words for outputting text to the console.</p>

<h3 id="n-----period"><code>. ( n -- )</code> (period)</h3>

<p>The simplest output word in Forth is <code>.</code>. You can use <code>.</code> to output the top of
the stack in the output of the current line. For example, try running this
(make sure to include all the spaces!):</p>

<pre><code>1 . 2 . 3 . 4 5 6 . . .
</code></pre>



<p>You should see this:</p>

<p>1 . 2 . 3 . 4 5 6 . . . <span>1 2 3 6 5 4  ok</span></p>

<p>Going through this in order, we push <code>1</code>, then pop it off and output it. Then
we do the same with <code>2</code> and <code>3</code>. Next we push <code>4</code>, <code>5</code>, and <code>6</code> onto the stack.
We then pop them off and output them one-by-one. That‚Äôs why the last three
numbers in the output are reversed: the stack is last in, first out.</p>

<h3 id="emit--c----"><code>emit ( c -- )</code></h3>

<p><code>emit</code> can be used to output numbers as ascii characters. Just like <code>.</code> outputs
the number at the top of the stack, <code>emit</code> outputs that number as an ascii
character. For example:</p>

<pre><code> 33 119 111 87 emit emit emit emit
</code></pre>



<p>I won‚Äôt give the output here so as to not ruin the surprise. This could also be
written as:</p>

<pre><code>87 emit 111 emit 119 emit 33 emit
</code></pre>

<p>Unlike <code>.</code>, <code>emit</code> doesn‚Äôt output any space after each character, enabling you
to build up arbitrary strings of output.</p>

<h3 id="cr-----"><code>cr ( -- )</code></h3>

<p><code>cr</code> is short for carriage return ‚Äì it simply outputs a newline:</p>

<pre><code>cr 100 . cr 200 . cr 300 .
</code></pre>



<p>This will output:</p>

<p>cr 100 . cr 200 . cr 300 .<span>
100
200
300  ok</span></p>

<h3 id="section"><code>." ( -- )</code></h3>

<p>Finally we have <code>."</code> ‚Äì a special word for outputting strings. The <code>."</code> word works
differently inside definitions to interactive mode. <code>."</code> marks the beginning of
a string to output, and the end of the string is marked by <code>"</code>. The closing <code>"</code>
isn‚Äôt a word, and so doesn‚Äôt need to be space-delimited. Here‚Äôs an example:</p>

<pre><code>: say-hello  ." Hello there!" ;
say-hello
</code></pre>



<p>You should see the following output</p>

<p>say-hello <span>Hello there! ok</span></p>

<p>We can combine <code>."</code>, <code>.</code>, <code>cr</code>, and <code>emit</code> to build up more complex output:</p>

<pre><code>: print-stack-top  cr dup ." The top of the stack is " .
  cr ." which looks like '" dup emit ." ' in ascii  " ;
48 print-stack-top
</code></pre>



<p>Running this should give you the following output:</p>

<p>48 print-stack-top <span>
The top of the stack is 48
which looks like '0' in ascii   ok</span></p>

<h2 id="conditionals-and-loops">Conditionals and Loops</h2>

<p>Now onto the fun stuff! Forth, like most other languages, has conditionals and
loops for controlling the flow of your program. To understand how they work,
however, first we need to understand booleans in Forth.</p>

<h3 id="booleans">Booleans</h3>

<p>There‚Äôs actually no boolean type in Forth. The number <code>0</code> is treated as false,
and any other number is true, although the canonical true value is <code>-1</code> (all
boolean operators return <code>0</code> or <code>-1</code>).</p>

<p>To test if two numbers are equal, you can use <code>=</code>:</p>

<pre><code>3 4 = .
5 5 = .
</code></pre>

<p>This should output:</p>

<p>3 4 = . <span>0  ok</span>
5 5 = . <span>-1  ok</span></p>



<p>You can use <code>&lt;</code> and <code>&gt;</code> for less than and greater than. <code>&lt;</code> checks to see if the
second item from the top of the stack is less than the top item of the stack, and
vice versa for <code>&gt;</code>:</p>

<pre><code>3 4 &lt; .
3 4 &gt; .
</code></pre>

<p>3 4 &lt; . <span>-1  ok</span>
3 4 &gt; . <span>0  ok</span></p>



<p>The boolean operators And, Or, and Not are available as <code>and</code>, <code>or</code>, and <code>invert</code>:</p>

<pre><code>3 4 &lt; 20 30 &lt; and .
3 4 &lt; 20 30 &gt; or .
3 4 &lt; invert .
</code></pre>

<p>The first line is the equivalent of <code>3 &lt; 4 &amp; 20 &lt; 30</code> in a C-based language.
The second line is the equivalent of <code>3 &lt; 4 | 20 &gt; 30</code>. The third line is the
equivalent of <code>!(3 &lt; 4)</code>.</p>

<p><code>and</code>, <code>or</code>, and <code>invert</code> are all bitwise operations. For well-formed flags
(<code>0</code> and <code>-1</code>) they‚Äôll work as expected, but they‚Äôll give incorrect results for
arbitrary numbers.</p>



<h3 id="if-then"><code>if then</code></h3>

<p>Now we can finally get onto conditionals. Conditionals in Forth can only be
used inside definitions. The simplest conditional statement in Forth is <code>if
then</code>, which is equivalent to a standard <code>if</code> statement in most languages.
Here‚Äôs an example of a definition using ‚Ä¶</p></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://skilldrick.github.io/easyforth">https://skilldrick.github.io/easyforth</a></em></p>]]>
            </description>
            <link>https://skilldrick.github.io/easyforth</link>
            <guid isPermaLink="false">hacker-news-small-sites-26164275</guid>
            <pubDate>Wed, 17 Feb 2021 09:03:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[CTO Headaches: Top cloud-to-cloud migration woes (and how to solve them)]]>
            </title>
            <description>
<![CDATA[
Score 66 | Comments 30 (<a href="https://news.ycombinator.com/item?id=26163970">thread link</a>) | @llarsson
<br/>
February 17, 2021 | https://www.cncf.io/blog/2021/02/15/cto-headaches-top-5-cloud-to-cloud-migration-woes-and-how-to-solve-them/ | <a href="https://web.archive.org/web/*/https://www.cncf.io/blog/2021/02/15/cto-headaches-top-5-cloud-to-cloud-migration-woes-and-how-to-solve-them/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
			
<p><em>Guest post originally published on <a href="https://elastisys.com/top-5-cloud-to-cloud-migration-woes-and-how-to-solve-them/">Elastisys‚Äôs blog</a> by Lars Larsson, Senior Cloud Architect and Branch Manager</em> at <em>Elastisys</em></p>



<p>All companies that use cloud services do so for a reason. But those reasons may change. Whether motivated by the need for a multi-cloud strategy, expenditure minimization, legislative or regulatory demands, or simply to get closer to end users, many organizations find themselves migrating from one cloud to another. Cloud-to-cloud migration for a non-trivial application contains a lot of unknown unknowns. This causes stress and uncertainty for a CTO. To help shed some light based on years of experience in the field, we have asked senior cloud architect Lars Larsson at Elastisys, to list some of these issues.</p>



<h2>Executive summary</h2>



<ul><li>Cloud providers offer a wide range of services, each with their own associated costs. Make sure to fully understand the situation as you make your calculations.</li><li>Providers tend to lock in customers via well-integrated services. These may make migration more difficult.</li><li>Make clear inventory of features and functionality your application requires of a managed service. These may or may not match what other cloud providers offer.</li><li>Also make an inventory of the tools and services supporting your organizational processes.</li><li>Take all these inventories into account to calculate your total cost of ownership for any cloud-to-cloud migration.</li><li>Use cloud native technologies to decouple your application and organization from the services offered by a particular cloud provider. This makes migration easier in the future.</li></ul>



<h2>1. Pricing models vary wildly</h2>



<p>Most companies have been hit by that one cloud bill that surprised them. Some services or features wound up costing far more than originally anticipated.&nbsp;</p>



<p>Are you considering a cloud-to-cloud migration to reduce operational costs? If so, please take a long and hard look at the various costs in each of the clouds. Because each service has a different cost model, making it very difficult to compare accurately. You really need to get to the bottom of it.</p>



<p>Compute and storage costs are often easy enough to compare, because those are the most obvious two. But what about other services? How much are you spending on, e.g., log handling or monitoring? Good services such as AWS CloudWatch come at a cost, especially if you use it for log handling too (AWS CloudWatch Logs). Are you heavily using a managed database service? A queueing or pub/sub service?</p>



<p>Avoid feeling like that one time the surprise cloud bill hit you in the face by doing your homework this time. You are wiser from the experience, after all.</p>



<p>Network transfers in and out of the cloud can also vary by quite a large amount. The three major providers will give you incoming network traffic for free, but charge you for the outgoing traffic. Smaller, regional, cloud providers will often have higher compute and storage costs, but not charge you for network traffic. Or include a much larger amount of it in a free tier offering.</p>



<p>Overwhelming? I get it. It sure looks that way at first glance! But it doesn‚Äôt have to be. My trick is to look at your past few detailed billing statements, and map those costs to your new cloud provider options.</p>



<ul><li><em>Key takeaway: Deeply take all aspects of your current cloud billing into account. Find the differences between offerings, and make a more informed decision.</em></li></ul>



<h2>2. Cloud vendor-specific integrations</h2>



<p>Tell me, did you adopt Kubernetes to make yourself less dependent on cloud providers? Reduce vendor lock-in? Are you now surprised at finding out that you are still locked in, but on a different level?</p>



<p>What I‚Äôve seen is that most organizations will make sure they have highly portable application definitions. By relying on Kubernetes, the application definitions work across cloud providers.&nbsp;</p>



<p>But what I‚Äôve also seen is that if you are using a managed Kubernetes service, your users and permissions handling is perhaps tied not to Kubernetes role-based access control (RBAC) features, but rather, to cloud-specific offerings. Like AWS Identity and Access Management (IAM). Great service, but ties you to the AWS platform.</p>



<p>Fully-managed Kubernetes services, if offered by cloud vendors themselves, serve to offer a highly integrated experience. The cost of that integration is that migration to another cloud provider becomes just that certain amount more difficult.</p>



<p>As a community, we‚Äôve tried to fix this. But as a community of engineers, those fixes are technical. Kubernetes dictates standards for certain components or aspects. Networking has to work according to the Container Network Interface (CNI) standard. Storage according to Container Storage Interface (CSI). And so on. Great. But the business people have put in much more clever ways of locking you to the platform. This means that other less obvious aspects are more difficult to freely migrate from one cloud to another.</p>



<p>So what is the option? Do you have to manage Kubernetes yourself? No. Of course not. But it may make sense to investigate managed Kubernetes offerings that are not tied to a particular cloud provider to reduce the risk of vendor lock-in. Without having to take on the task of day-to-day operations on your own, of course.</p>



<ul><li><em>Key takeaway: Investigate the ways in which cloud providers make migration more difficult due to incompatible integrations. Choose third-party vendors that are not tied to any particular cloud provider, and can offer their services on top of other cloud providers if need be.</em></li></ul>



<h2>3. The devil is in the (technical) details</h2>



<p>Almost all organizations I‚Äôve talked to say the same thing. They went to the cloud because they wanted to get infrastructure or platform functionality on an as-a-Service basis. That is the whole point of the cloud, is it not?</p>



<p>So, of course, all cloud providers will offer certain services. It used to be just infrastructure as a service (virtual machines, network, and storage) but we are starting to also take, e.g., object storage and queuing services for granted. Many such services will claim to offer an ‚ÄúS3 compatible API‚Äù or similar. And that is a great starting point! But beware, because what does such a compatibility claim really mean?&nbsp;</p>



<p>AWS S3, for example, was, until December 2020, merely eventually consistent. Since&nbsp;<a href="https://www.infoq.com/news/2020/12/aws-s3-strong-consistency/">their announcement</a>, it is read-after-write consistent (strong consistency). Which level of consistency would a service that is ‚ÄúS3 compatible‚Äù have? The old one? Or the new one? And do you have aspects of your applications that depend on that answer being one or the other? Would you know off-hand?</p>



<p>If you don‚Äôt, by the way, you‚Äôre in excellent company. Most people‚Äôs eyes gloss over when consistency guarantees are discussed. But then again, you don‚Äôt want to get bitten by a bug caused by wrongful assumptions, so somebody has to stay awake to figure this stuff out. Hopefully not past midnight!</p>



<p>Ready for another unexciting example? Queuing services, such as AWS SQS, offer certain delivery guarantees. SQS standard queues offer ‚Äúat least once‚Äù guarantees. That means that a message can be delivered to your application more than once, and must have logic in place for dealing with duplicates. An application that is not prepared for this will start showing strange behavior. Especially under heavy load, because that is when the risk for multiple deliveries is higher. This is because high load means there is less time to do housekeeping for the queuing service. (Note that while SQS offers FIFO queues that have ‚Äúexactly once‚Äù&nbsp;<strong>processing</strong>&nbsp;guarantees, however, that&nbsp;<a href="https://www.ably.io/blog/sqs-fifo-queues-message-ordering-and-exactly-once-processing-guaranteed">does not imply exactly once delivery</a>.) So confusing for an application that was coded with assumptions of RabbitMQ‚Äôs ‚Äúat most once‚Äù delivery guarantees!</p>



<figure><div>
<blockquote data-width="500" data-dnt="true"><div lang="en" dir="ltr"><p>Most people's eyes gloss over when consistency guarantees are discussed</p><p>Read the whole article "CTO Headaches: Top 5 cloud-to-cloud migration woes" for more<a href="https://t.co/exLGZu5SZG">https://t.co/exLGZu5SZG</a></p></div>‚Äî elastisys (@elastisys) <a href="https://twitter.com/elastisys/status/1358795732132769794?ref_src=twsrc%5Etfw">February 8, 2021</a></blockquote>
</div></figure>



<p>The point I am making here is that you must make an inventory of all the cloud services you use, and what features in these are key to your applications working the way they are intended. Because&nbsp;<strong>your</strong>&nbsp;use case is the one that matters.</p>



<p>Cloud providers offer services that make certain trade-offs to ensure the scalability and availability&nbsp;<em>of their service</em>. From the perspective of individual customers and applications, the ideal trade-off choice might have been different. If you use a software such as RabbitMQ, you can configure it perfectly for your use case and requirements. Not the ones of the cloud providers. There are companies that offer managed services in a cloud-agnostic way. Especially on top of Kubernetes, which deserve your consideration.</p>



<ul><li><em>Key takeaway: Make a clear inventory of all cloud services you use, along with the required features of each for your use case. To make a cloud-to-cloud migration easier, start depending on software not tied to any particular provider.</em></li></ul>



<h2>4. Tools supporting your processes (may) change</h2>



<p>Industry wisdom and rule of thumb says that&nbsp;<a href="https://www.econnectivity.se/app-maintenance-cost-can-be-three-times-higher-than-development-cost/">about 70% of software costs</a>&nbsp;are in maintenance. Not development. Just keeping the thing running as intended. How do you address that? My take on it is to rely on smart tools and automation as much as possible. The less your staff has to work on rote menial tasks, the better. Everything they do is a process. So let‚Äôs talk about those processes.</p>



<p>Operating your mission-critical cloud application? A bunch of processes. And most, if not all, of these are supported by tools. Continuous integration and deployment, monitoring, notifications and alerting. These are the tools your operations staff is using to analyze and optimize your application deployment.</p>



<p>Great tools like AWS CloudWatch offer insight into monitoring, logging (CloudWatch Logs), and containerized workloads (CloudWatch Container Insights). Your team probably depends on them. But they are specific to a particular cloud vendor.</p>



<p>If you ‚Ä¶</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.cncf.io/blog/2021/02/15/cto-headaches-top-5-cloud-to-cloud-migration-woes-and-how-to-solve-them/">https://www.cncf.io/blog/2021/02/15/cto-headaches-top-5-cloud-to-cloud-migration-woes-and-how-to-solve-them/</a></em></p>]]>
            </description>
            <link>https://www.cncf.io/blog/2021/02/15/cto-headaches-top-5-cloud-to-cloud-migration-woes-and-how-to-solve-them/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26163970</guid>
            <pubDate>Wed, 17 Feb 2021 08:20:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Kill the Alarm Clock (2017)]]>
            </title>
            <description>
<![CDATA[
Score 110 | Comments 168 (<a href="https://news.ycombinator.com/item?id=26163691">thread link</a>) | @aminozuur
<br/>
February 16, 2021 | https://supermemo.guru/wiki/Kill_the_alarm_clock | <a href="https://web.archive.org/web/*/https://supermemo.guru/wiki/Kill_the_alarm_clock">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="mw-content-text" lang="en" dir="ltr"><p><small>This text is part of: "<i><a href="https://supermemo.guru/wiki/Science_of_sleep" title="Science of sleep">Science of sleep</a></i>" by <a href="https://supermemo.guru/wiki/Piotr_Wozniak" title="Piotr Wozniak">Piotr Wozniak</a> (2017)</small>
</p>


<h2><span id="Kill_the_alarm_clock.21">Kill the alarm clock!</span></h2>
<h3><span id="Alarm_clock_epidemic">Alarm clock epidemic</span></h3>
<p>Few upwardly mobile people in the modern rat-race society can live without an alarm clock. With a shot of strong coffee and round-the-clock stress, most people learn to live and survive with an alarm clock. Half of the population wakes up with an alarm, 9% are woken by a partner, 4% by pets, 3% by children, etc. That leaves a minority that wake up naturally. Increasingly, time becomes the most precious commodity in society where achievement is often associated with speed and perfect time-management. However, alarm clocks introduce harmful side effects: stress, sleep debt, and worst of all, disruption of the natural physiological sleep function. At worst, those factors will result in physical damage to the brain (e.g. such sensitive structures as the hippocampus, your memory switchboard, may literally <a href="https://supermemo.guru/wiki/If_you_do_not_sleep,_you_die!" title="If you do not sleep, you die!">lose neurons as a result of disrupted sleep</a>).
</p><p>The art of time-management makes it possible to live at a high speed with an alarm clock at your side, and still be free from <a href="https://supermemo.guru/wiki/Factors_that_affect_sleep#Stress" title="Factors that affect sleep">stress</a>. However, the societal damage inflicted by alarm clocks and <a href="https://supermemo.guru/wiki/Sleep_deprivation" title="Sleep deprivation">sleep deprivation</a> is unforgivable. An alarm clock that interrupts your sleep damages your memories, your ability to learn, your creativity, your mood and temper, your relationships with other people, your ability to focus, and your overall intellectual performance!
</p><p>Dr Robert Stickgold has shown that people who learn a skill during the day do not show significant improvement until they get 7-8 hours of good sleep<sup id="cite_ref-stickgold-2005_1-0"><a href="#cite_note-stickgold-2005-1">[1]</a></sup>. There was a noticeable correlation between the degree of improvement and the quality of sleep received. My own work with <a href="https://supermemo.guru/wiki/Sleep_habits#SleepChart_in_SuperMemo" title="Sleep habits">SleepChart</a> also shows that the <a href="https://supermemo.guru/wiki/Sleep_and_learning#Alarm_clock_vs._learning" title="Sleep and learning">use of alarm clocks can dramatically reduce memory recall and consolidation</a>. Forgetting is so painless that we rarely notice its effects. In a natural way, forgetting will proceed even if you get as much sleep as you need, and it is difficult to point to specific memories lost as a result of not sleeping enough. Moreover, <a href="https://supermemo.guru/wiki/Memory_optimization_in_sleep#Neural_optimization_in_sleep" title="Memory optimization in sleep">sleep deprivation may leave your memories intact while their storage will be sub-optimum</a>. The difference may be impossible to spot without measurement. We are more likely to notice sleepiness, reduced mental agility, or bad mood.
</p><p>Disrespect for sleep has reached biblical proportions. This is most noticeable in the US and other highly industrialized nations. <i>Men's Health's</i> Dan Vergano writing for <i>ABC News</i> in <i>"No More Rude Awakenings"</i> suggests a seven-day system for fighting sleepiness: <i>"The secret is to fuel that arousal system so it can <b>beat the pants off the sleep system</b>. By creating the kind of feel-good expectations that trigger hormones to wake the brain, you‚Äôll override the need to sleep and be able to jump out of bed like a man on fire"</i>. The article suggests a "fresh" mind method that capitalizes on the fact that stress hormones help keep you alert. However, the only rational remedy for <i>"rude awakenings"</i> is simple: get enough sleep! Jumping <i>like a man on fire</i> is not likely to have a positive effect on your creative potential!
</p><p>You may often notice that waking up with an alarm clock gives you a jumpstart for the day. You may then come to believe that using the alarm clock might help you stay alert later in the day. This is not the case. The alarm signal simply scares your brain into wakefulness, disrupting the carefully planned process of <a href="https://supermemo.guru/wiki/Memory_optimization_in_sleep#Neural_optimization_in_sleep" title="Memory optimization in sleep">neural optimization</a> that occurs in sleep. As a result, you get an immediate injection of <a href="http://en.wikipedia.org/wiki/Adrenaline">adrenaline</a> and your levels of <a href="http://en.wikipedia.org/wiki/ACTH">ACTH</a> and <a href="http://en.wikipedia.org/wiki/Cortisol">cortisol</a> also increase. This is cortisol that peaks at awakening in natural sleeping rhythm that provides you with the fresh-mind impression. With passing time, this cheaply gained alertness will wear thin unless you continue abusing your physiology with more "remedies". You may use more scare tactics for keeping yourself alert, abuse caffeine, or even get a more profound effect with <a href="http://en.wikipedia.org/wiki/Modafinil">modafinil</a>, <a href="http://en.wikipedia.org/wiki/Cocaine">cocaine</a>, or <a href="http://en.wikipedia.org/wiki/Amphetamines">amphetamines</a>. Alertness should be achieved with the help of sufficient sleep, not despite the lack of sleep! Apart from your reduced ability to learn new things, all unnatural anti-drowsiness methods will produce a great deal of side effects that can be pretty damaging to your health in the long run.
</p><p>All efforts to overcome sleepiness by means other than sleep itself can be likened to a chase of the first high in the use of psychoactive substances. If you drink buckets of coffee, do pushups, pour cold water over your head, or slap your face, you only dip into the last reserves of your alertness hormones that only worsen the effects of deprivation after the effects of the stimulation wear off, which is usually a matter of minutes. Rarely can you get a boost lasting more than an hour, and the more you perk up, the lower you fall in the aftermath.
</p>
<h3><span id="Insomnia_trap">Insomnia trap</span></h3>
<p>If your life without an alarm clock may seem like an impossibility, you will probably need to use all methods in the book to be sure you get enough sleep and minimize the damage. If you need to wake up early at the cost of your brain, avoid the <b><a href="https://supermemo.guru/wiki/Insomnia" title="Insomnia">insomnia trap</a></b>! Insomnia trap is a vicious circle of:
</p>
<ol><li> going to sleep too early to get more sleep,</li>
<li> failing to fall asleep in time (or worse, waking up prematurely),</li>
<li> feeling even more tired on the next day, and</li>
<li> going to sleep even earlier on the next day to catch up with the lost sleep.</li></ol>
<p>It is better to go to sleep at a natural hour (i.e. a bit later), wake up early, suffer a degree of sleep deprivation, and hope for a phase reset that will make it possible to continue on the <a href="http://www.stevepavlina.com/blog/2005/05/how-to-become-an-early-riser/">designer schedule</a>. For a solution to the insomnia trap see: <a href="https://supermemo.guru/wiki/Curing_DSPS_and_insomnia" title="Curing DSPS and insomnia">Curing DSPS and insomnia</a>.
</p><p>If you cannot reset your phase and still feel tired when getting up early on a regular basis, consider choosing a job that is acceptable for your body, not the other way around. Your long-term health and well-being is at stake. If you absolutely cannot live without an alarm clock, you can at least start from changing your mindset about the importance of sleep and ensure you do not impose wrong habits on your children. Perhaps the young ones will be lucky enough to work in a flex-time system that will make it possible to get sufficient amount of undisturbed sleep. At least, do not set a bad example!
</p>
<h3><span id="Wake_up_the_President">Wake up the President</span></h3>
<p>President Bill Clinton was woken up twice by telephone during the night of April 22, 2000 before the infamous I.N.S. raid on the home of Miami relatives of the young Cuban exile Elian Gonzales. He was probably the most often disrupted and sleep deprived president in history. Only after a heart surgery did Clinton take diet, sleep and (real) exercise seriously. Those interrupted nights would definitely influence his performance and the quality of his decisions! Has anybody thought of a rule: <i>Do not wake up the president?</i> A rule that could only be revoked in a true national emergency? President G. W. Bush (b. 1946) was woken up when an American spy plane landed in China in 2001. He was also woken up after a suicide bombing in Jerusalem in 2002. George H. W. Bush (b. 1924) and Hilary Clinton made "waking up in the middle of the night" part of their presidential campaign and prowess. It seems that only Ronald Reagan had pretty strong rules for protecting his own sleep. He also famously napped during some cabinet meetings. He slept through a couple of international events without an apparent negative impact on his somewhat delayed decision-making. Critics would say he slept through the entire <a href="http://en.wikipedia.org/wiki/Iran%E2%80%93Contra_affair">Iran-Contra affair</a>. Was Reagan so protective of sleep because he understood the role of sleep better, or perhaps he was just a bit lazier than other presidents? I don't know. However, he sure set a good example.
</p>
<h3><span id="Alarm_clock_monsters">Alarm clock monsters</span></h3>
<p>Andrea K. wrote to me with skepticism: 
</p>
<blockquote><p><i>"Take the alarm clock away from a typical person and they won't just wake up on their own at their desired time and they will miss work, school, or whatever. An alarm clock can't be that bad for you because of the simple fact that most people use it and I never noticed any problem with them&nbsp;:) Everyone in my family has been using one since they were children, and no one suddenly went crazy or began to mutate into a monster (yet)!"</i></p></blockquote> 
<p>When you use an alarm early in the morning in order to get to work or to school, you cut off the later stages of sleep. If the intrusion into natural sleep is not large (e.g. from minutes to an hour), the damage may be limited and hard to notice. Alarm clock will do far more damage if it cuts deep into the middle of the night sleep. You can compare the use of alarm clocks to smoking or eating hot dogs. The harm is not great enough to be instantly noticeable. It took the public many years to largely accept that "smoking is bad" or "fast food is bad". It is hard to quantify the degree of damage. However, as we move to knowledge society where our intellectual performance becomes increasingly important, the effects of <a href="https://supermemo.guru/wiki/Sleep_deprivation" title="Sleep deprivation">sleep deprivation</a> will come under closer scrutiny and alarm clocks are bound to gradually fall out of favor. Unlike hot dogs, they are already universally hated by their users. Most people are able to somewhat adapt their sleep to their schedules if their routines are regular enough. When those people need to resort to the use of the alarm clock, they cut less of their sleep and the damage is proportionally smaller. Nevertheless, we should always strive at eliminating alarm clocks altogether. Most of all, we should protect our kids from suffering interrupted sleep!
</p>
<h2><span id="References">References</span></h2>
<ol>
<li id="cite_note-stickgold-2005-1"><span><a href="#cite_ref-stickgold-2005_1-0">‚Üë</a></span> <span>Stickgold R., "<a href="http://www.nature.com/nature/journal/v437/n7063/full/nature04286.html">Sleep-dependent memory consolidation</a>," Nature / Volume 437 (October 27, 2005): 1272-1278</span>
</li>
</ol>

<!-- 
NewPP limit report
Cached time: 20210220073322
Cache expiry: 86400
Dynamic content: false
CPU time usage: 0.032 seconds
Real time usage: 0.058 seconds
Preprocessor visited node count: 56/1000000
Preprocessor generated node count: 158/1000000
Post‚Äêexpand include size: 1541/2097152 bytes
Template argument size: 438/2097152 bytes
Highest expansion depth: 4/40
Expensive parser function count: 0/100
-->

<!-- 
Transclusion expansion time report (%,ms,calls,template)
100.00%   40.352      1 - -total
 62.60%   25.261      1 - ArticleSleep
 17.15%    6.921      1 - Template:Excerpt
-->

<!-- Saved in parser cache with key supermem_kool_kids:pcache:idhash:1062-0!*!0!!en!*!* and timestamp 20210220073322 and revision id 14432
 -->
</div></div>]]>
            </description>
            <link>https://supermemo.guru/wiki/Kill_the_alarm_clock</link>
            <guid isPermaLink="false">hacker-news-small-sites-26163691</guid>
            <pubDate>Wed, 17 Feb 2021 07:28:17 GMT</pubDate>
        </item>
    </channel>
</rss>
