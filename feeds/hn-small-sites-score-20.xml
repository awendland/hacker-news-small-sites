<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 20]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 20. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Thu, 18 Feb 2021 12:39:43 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-20.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Thu, 18 Feb 2021 12:39:43 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[All about thread-local storage]]>
            </title>
            <description>
<![CDATA[
Score 27 | Comments 2 (<a href="https://news.ycombinator.com/item?id=26150512">thread link</a>) | @MaskRay
<br/>
February 15, 2021 | https://maskray.me/blog/2021-02-14-all-about-thread-local-storage | <a href="https://web.archive.org/web/*/https://maskray.me/blog/2021-02-14-all-about-thread-local-storage">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
      
        <p>Thread-local storage (TLS) provides a mechanism allocating distinct objects for different threads. It is the usual implementation for GCC extension <code>__thread</code>, C11 <code>_Thread_local</code>, and C++11 <code>thread_local</code>, which allow the use of the declared name to refer to the entity associated with the current thread. This article will describe thread-local storage on ELF platforms in detail, and touch on other related topics, such as: thread-specific data keys and Windows/macOS TLS.</p>
<p>An example usage of thread-local storage is POSIX <code>errno</code>:</p>
<blockquote>
<p>Each thread has its own thread ID, scheduling priority and policy, errno value, floating point environment, thread-specific key/value bindings, and the required system resources to support a flow of control.</p>
</blockquote>
<p>Different threads have different <code>errno</code> copies. <code>errno</code> is typically defined as a function which returns a thread-local variable.</p>
<p>For each architecture, the authoritative ELF ABI document is the processor supplement (psABI) to the System V ABI (generic ABI). These documents usually reference <em>The ELF Handling for Thread-Local Storage</em> by Ulrich Drepper. The document, however, mixes general specifications and glibc internals.</p>
<h2 id="representation">Representation</h2>
<h3 id="assembler-behavior">Assembler behavior</h3>
<p>The compiler usually defines thread-local variables in <code>.tdata</code> and <code>.tbss</code> sections (which have the section flag <code>SHF_TLS</code>). The symbols representing thread-local variables have type <code>STT_TLS</code> (representing thread-local storage entities). In GNU as syntax, you can give <code>a</code> the type <code>STT_TLS</code> with <code>.type a, @tls_object</code>. The <code>st_value</code> value of a TLS symbols is the offset relative to the defining section.</p>
<figure><table><tbody><tr><td><pre><span>1</span><br><span>2</span><br><span>3</span><br><span>4</span><br><span>5</span><br><span>6</span><br><span>7</span><br><span>8</span><br><span>9</span><br><span>10</span><br></pre></td><td><pre><span>.section .tbss,"awT",@nobits</span><br><span>.globl a, b</span><br><span>.type a, @tls_object</span><br><span>.type b, @tls_object</span><br><span>a:</span><br><span>  .zero 4</span><br><span>  .size a, .-a</span><br><span>b:</span><br><span>  .zero 4</span><br><span>  .size b, .-b</span><br></pre></td></tr></tbody></table></figure>
<p>In this example, <code>st_value(a)=0</code> while <code>st_value(b)=4</code>.</p>
<p>In Clang and GCC produced assembly, thread-local variables are annotated as <code>.type a, @object</code> (<code>STT_OBJECT</code>). When the assembler sees that such symbols are defined in <code>SHF_TLS</code> sections or referenced by TLS relocations, <code>STT_NOTYPE</code>/<code>STT_OBJECT</code> will be upgraded to <code>STT_TLS</code>.</p>
<p>GNU as supports an directive <code>.tls_common</code> which defines <code>STT_TLS SHN_COMMON</code> symbols. This is an obsecure feature. It is not clear whether GCC still has a code path which emits <code>.tls_common</code> directives. LLVM integrated assembler does not support <code>.tls_common</code>.</p>
<h3 id="linker-behavior">Linker behavior</h3>
<p>The linker combines <code>.tdata</code> input sections into a <code>.tdata</code> output section. <code>.tbss</code> input sections are combined into a <code>.tbss</code> output section. The two <code>SHF_TLS</code> output sections are placed into a <code>PT_TLS</code> program header.</p>
<ul>
<li><code>p_offset</code>: the file offset of the TLS initialization image</li>
<li><code>p_vaddr</code>: the virtual address of the TLS initialization image</li>
<li><code>p_filesz</code>: the size of the TLS initialization image</li>
<li><code>p_memsz</code>: the total size of the thread-local storage. The last <code>p_memsz-p_filesz</code> bytes will be zeroed by the dynamic loader.</li>
<li><code>p_align</code>: alignment</li>
</ul>
<p>The <code>PT_TLS</code> program header is contained in a <code>PT_LOAD</code> program header. Conceptually <code>PT_TLS</code> and <code>STT_TLS</code> symbols are like in a separate address space. The dynamic loader should copy the <code>[p_vaddr,p_vaddr+p_filesz)</code> of the TLS initialization image to the corresponding static TLS block.</p>
<p>In executable and shared object files, <code>st_value</code> normally holds a virtual address. For a <code>STT_TLS</code> symbol, <code>st_value</code> holds an offset relative to the virtual address of the <code>PT_TLS</code> program header. The first byte of <code>PT_TLS</code> is referenced by the TLS symbol with <code>st_value==0</code>.</p>
<p>GNU ld treats <code>STT_TLS SHN_COMMON</code> symbols as defined in <code>.tcommon</code> sections. Its internal linker script places such sections into the output section <code>.tdata</code>. LLD does not support <code>STT_TLS SHN_COMMON</code> symbols.</p>
<h3 id="dynamic-loader-behavior">Dynamic loader behavior</h3>
<p>The dynamic loader collects <code>PT_TLS</code> program headers from the main executable and immediately loaded shared objects (via transitive <code>DT_NEEDED</code>), and allocates static TLS blocks, one block for each <code>PT_TLS</code>. For each <code>PT_TLS</code>, the dynamic loader copies <code>p_filesz</code> bytes from the TLS initialization image to the TLS block and sets the trailing <code>p_memsz-p_filesz</code> bytes to zeroes.</p>
<p>For the static TLS block of the main executable, the module ID is one and the TP offset of a TLS symbol is a link-time constant. The linker and the dynamic loader share the same formula.</p>
<p>For a shared object loaded at program start, the offset from the thread pointer to its static TLS block is a fixed value at program start, albeit not a link-time constant. The offset can be referenced by a GOT dynamic relocation used by the initial-exec TLS model.</p>
<p><em>The ELF Handling for Thread-Local Storage</em> describes two TLS variants and specifies their data structures. However, only the TP offset of the static TLS block of the main executable is a hard requirement. Nevertheless, libc implementations usually place static TLS blocks together, and allocate a space for both the thread control block and the static TLS blocks.</p>
<p>For a new thread created by <code>pthread_create</code>, the static TLS blocks are usually allocated as part of the thread stack. Without a guard page between the largest address of the stack and the thread control block, this could be considered as vulnerable as stack overflow can overwrite the thread control block.</p>
<h2 id="models">Models</h2>
<h3 id="local-exec-tls-model-executable-non-preemptible">Local exec TLS model (executable &amp; non-preemptible)</h3>
<p>This is the most efficient TLS model. It applies when the TLS symbol is defined in the executable.</p>
<p>The compiler picks this model in <code>-fno-pic/-fpie</code> modes if the variable is</p>
<ul>
<li>a definition</li>
<li>or a declaration with a non-default visibility.</li>
</ul>
<p>The first condition is obvious. The second condition is becuase a non-default visibility means the variable must be defined by another translation unit in the executable.</p>
<figure><table><tbody><tr><td><pre><span>1</span><br><span>2</span><br><span>3</span><br></pre></td><td><pre><span>_Thread_local <span>int</span> def;</span><br><span>__attribute__((visibility(<span>"hidden"</span>))) <span>extern</span> <span>thread_local</span> <span>int</span> ref;</span><br><span><span><span>int</span> <span>foo</span><span>()</span> </span>{ <span>return</span> def + ref; }</span><br></pre></td></tr></tbody></table></figure>
<figure><table><tbody><tr><td><pre><span>1</span><br><span>2</span><br></pre></td><td><pre><span># x86-64</span><br><span>movl %fs:def@TPOFF, %eax</span><br></pre></td></tr></tbody></table></figure>
<p>For the static TLS block of the main executable, the TP offset of a TLS symbol is a link-time constant. Here is a list of common relocation types:</p>
<ul>
<li>arm: <code>R_ARM_TLS_LE32</code></li>
<li>aarch64:
<ul>
<li>-mtls-size=12: <code>R_AARCH64_TLSLE_ADD_TPREL_LO12</code></li>
<li>-mtls-size=24 (default): <code>R_AARCH64_TLSLE_ADD_TPREL_HI12</code>, <code>R_AARCH64_TLSLE_ADD_TPREL_LO12_NC</code></li>
<li>-mtls-size=32: <code>R_AARCH64_TLSLE_MOVW_TPREL_G1</code>, <code>R_AARCH64_TLSLE_MOVW_TPREL_G0_NC</code></li>
<li>-mtls-size=48: <code>R_AARCH64_TLSLE_MOVW_TPREL_G2</code>, <code>R_AARCH64_TLSLE_MOVW_TPREL_G1_NC</code>, <code>R_AARCH64_TLSLE_MOVW_TPREL_G0_NC</code></li>
</ul></li>
<li>i386: <code>R_386_TLS_LE</code></li>
<li>x86-64: <code>R_X86_64_TPOFF32</code></li>
<li>mips: <code>R_MIPS_TPREL_HI16</code>, <code>R_MIPS_TPREL_LO16</code></li>
<li>ppc32: <code>R_PPC_TPREL_HA</code>, <code>R_PPC_TPREL_LO</code></li>
<li>ppc64: <code>R_PPC64_TPREL_HA</code>, <code>R_PPC64_TPREL_LO</code></li>
<li>riscv: <code>R_RISCV_TPREL_HI20</code>, <code>R_RISCV_TPREL_LO12_I</code>, <code>R_RISCV_TPREL_LO12_S</code></li>
</ul>
<p>For RISC architectures, because an instruction typically has 4 bytes and cannot encode a 32-bit offset, it usually takes two instructions to materialize a TP offset.</p>
<p>In <a target="_blank" rel="noopener" href="https://reviews.llvm.org/D93331">https://reviews.llvm.org/D93331</a>, I patched LLD to reject local-exec TLS relocations in <code>-shared</code> mode. In GNU ld, at least arm, riscv and x86's ports have the similar diagnostics, but aarch64 and ppc64 do not error.</p>
<h3 id="initial-exec-tls-model-executable-preemptible">Initial exec TLS model (executable &amp; preemptible)</h3>
<p>This model is less efficient than local exec. It applies when the TLS symbol is defined in the executable or a shared object available at program start. The shared object can be due to <code>DT_NEEDED</code> or <code>LD_PRELOAD</code>.</p>
<p>The compiler picks this model in <code>-fno-pic/-fpie</code> modes if the variable is a declaration with default visibility. The idea is that a symbol referenced by the executable must be defined by an immediately loaded shared object, instead of a dlopen loaded shared object. The linker enforces this as well by defaulting to <code>-z defs</code> for a <code>-no-pie/-pie</code> link.</p>
<figure><table><tbody><tr><td><pre><span>1</span><br><span>2</span><br></pre></td><td><pre><span><span>extern</span> <span>thread_local</span> <span>int</span> ref;</span><br><span><span><span>int</span> <span>foo</span><span>()</span> </span>{ <span>return</span> ref; }</span><br></pre></td></tr></tbody></table></figure>
<figure><table><tbody><tr><td><pre><span>1</span><br><span>2</span><br><span>3</span><br></pre></td><td><pre><span># x86-64</span><br><span>movq ref@GOTTPOFF(%rip), %rax</span><br><span>movl %fs:(%rax), %eax</span><br></pre></td></tr></tbody></table></figure>
<p>Because the offset from the thread pointer to the start of a static block is fixed at program start, such an offset can be encoded by a GOT relocation. Such relocation types typically have <code>GOT</code> and <code>TPREL/TPOFF</code> in their names. Here is a list of common relocation types:</p>
<ul>
<li>arm: <code>R_ARM_TLS_IE32</code></li>
<li>aarch64: <code>R_AARCH64_TLSIE_ADR_GOTTPREL_PAGE21</code>, <code>R_AARCH64_TLSIE_LD64_GOTTPREL_LO12_NC</code></li>
<li>i386: <code>R_386_TLS_IE</code></li>
<li>x86-64: <code>R_X86_64_GOTTPOFF</code></li>
<li>ppc32: <code>R_PPC_GOT_TPREL16</code></li>
<li>ppc64: <code>R_PPC64_GOT_TPREL16_HA</code>, <code>R_PPC64_GOT_TPREL16_LO_DS</code></li>
<li>riscv: <code>R_RISCV_TLS_GOT_HI20</code>, <code>R_RISCV_PCREL_LO12_I</code></li>
</ul>
<p>If the TLS symbol does not satisfy initial-exec to local-exec relaxation requirements, the linker will allocate a GOT entry and emit a dynamic relocation. Here is a list of dynamic relocation types:</p>
<ul>
<li>arm: <code>R_ARM_TLS_TPOFF32</code></li>
<li>aarch64: <code>R_AARCH64_TLS_TPREL64</code></li>
<li>mips32: <code>R_MIPS_TLS_TPREL32</code></li>
<li>mips64: <code>R_MIPS_TLS_TPREL64</code></li>
<li>i386: <code>R_386_TPOFF</code></li>
<li>x86-64: <code>R_X86_64_TPOFF64</code></li>
<li>ppc32: <code>R_PPC_TPREL32</code></li>
<li>ppc64: <code>R_PPC64_TPREL64</code></li>
<li>riscv: <code>R_RISCV_TLS_TPREL64</code></li>
</ul>
<p>While they have <code>TPREL</code> or <code>TPOFF</code> in their names, these dynamic relocations have the same bitwidth as the word size. This is a good way to distinguish them from the local-exec relocation types used in object files.</p>
<p>If you add the <code>__attribute((tls_model("initial-exec")))</code> attribute, a thread-local variable can use this model in <code>-fpic</code> mode. If the object file is linked into an executable, everything is fine. If the object file is linked into a shared object, the shared object generally needs to be an immediately loaded shared object. The linker sets the <code>DF_STATIC_TLS</code> flag to annotate a shared object with initial-exec TLS relocations.</p>
<p>glibc ld.so reserves some space in static TLS blocks and allows dlopen on such a shared object if its TLS size is small. There could be an obscure reason for using such an attribute: general dynamic and local dynamic TLS models are not async-signal-safe in glibc. However, other libc implementations may not reserve additional TLS space for dlopen'ed initial-exec shared objects, e.g. musl will error.</p>
<h3 id="general-dynamic-and-local-dynamic-tls-models-dso">General dynamic and local dynamic TLS models (DSO)</h3>
<p>The two modes are used when the TLS symbol may be defined by a shared object. They do not assume the TLS symbol is backed by a static TLS block. Instead, they assume that the thread-local storage of the module may be dynamically allocated, making the models suitable for dlopen usage. The dynamically allocated TLS storage is usually referred to as dynamic TLS.</p>
<p>Each TLS symbol is ‚Ä¶</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://maskray.me/blog/2021-02-14-all-about-thread-local-storage">https://maskray.me/blog/2021-02-14-all-about-thread-local-storage</a></em></p>]]>
            </description>
            <link>https://maskray.me/blog/2021-02-14-all-about-thread-local-storage</link>
            <guid isPermaLink="false">hacker-news-small-sites-26150512</guid>
            <pubDate>Tue, 16 Feb 2021 03:14:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[US Presidential Election $25k Database Bounty Review]]>
            </title>
            <description>
<![CDATA[
Score 139 | Comments 31 (<a href="https://news.ycombinator.com/item?id=26149511">thread link</a>) | @mjangle1985
<br/>
February 15, 2021 | https://www.dolthub.com/blog/2021-02-15-election-bounty-review/ | <a href="https://web.archive.org/web/*/https://www.dolthub.com/blog/2021-02-15-election-bounty-review/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-cy="blog-post-text"><p>On December 14, we launched <a href="https://www.dolthub.com/blog/2020-12-16-data-bounties/">our first data bounty</a> to <a href="https://www.dolthub.com/blog/2020-12-14-make-money-data-wrangling/">earn a share of $25,000 by wrangling US Presidential Precinct-level data</a>. The bounty ended yesterday. How did it go? This blog entry will answer that question.</p>
<p><a href="https://www.doltdb.com/">Dolt</a> is a SQL database with Git-style versioning. It's the first SQL database you can branch and merge. <a href="https://www.dolthub.com/">DoltHub</a> is a place on the internet to share and collaborate on Dolt databases. Without both, data bounties would not be possible.</p>

<p>We built the <a href="https://www.dolthub.com/repositories/dolthub/us-president-precinct-results">best open database of US Precinct-level Election results</a> on the internet. </p>
<p>Here's some statistics:</p>
<ul>
<li>15.5M cells edited. 1.7GB of data collected</li>
<li><a href="https://www.dolthub.com/repositories/dolthub/us-president-precinct-results/query/master?q=SELECT+COUNT%28distinct%28state%29%29%0AFROM+%60vote_tallies%60+where+election_year%3D2016%0ALIMIT+200%3B%0A%0A%0A%0A%0A%0A%0A&amp;active=Tables">All 51 "states" covered for 2016</a>. <a href="https://www.dolthub.com/repositories/dolthub/us-president-precinct-results/query/master?q=SELECT+COUNT%28distinct%28state%29%29%0AFROM+%60vote_tallies%60+where+election_year%3D2020%0ALIMIT+200%3B%0A%0A%0A%0A%0A%0A%0A&amp;active=Tables">38 states covered for 2020</a>. </li>
<li><a href="https://www.dolthub.com/repositories/dolthub/us-president-precinct-results/query/master?q=SELECT+sum%28votes%29%2F136669276%0AFROM+%60vote_tallies%60+where+election_year%3D2016%0ALIMIT+200%3B%0A%0A%0A%0A%0A%0A%0A&amp;active=Tables">100% of the vote covered for 2016</a>. <a href="https://www.dolthub.com/repositories/dolthub/us-president-precinct-results/query/master?q=SELECT+sum%28votes%29%2F159633396%0AFROM+%60vote_tallies%60+where+election_year%3D2020%0ALIMIT+200%3B%0A%0A%0A%0A%0A%0A%0A&amp;active=Tables">78% for 2020</a>.</li>
<li>75 Pull Requests (PRs) accepted across 6 bounty participants. </li>
<li>Top bounty participant earned over $10,000.</li>
</ul>
<p><span>
      <a href="https://www.dolthub.com/blog/static/4e02e3f4498d3a6b5bc56bd9f85cad81/0fcea/first-bounty-final-scoreboard.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="Final Scoreboard" title="Final Scoreboard" src="https://www.dolthub.com/blog/static/4e02e3f4498d3a6b5bc56bd9f85cad81/0fcea/first-bounty-final-scoreboard.png" srcset="https://www.dolthub.com/blog/static/4e02e3f4498d3a6b5bc56bd9f85cad81/a48b3/first-bounty-final-scoreboard.png 214w,
https://www.dolthub.com/blog/static/4e02e3f4498d3a6b5bc56bd9f85cad81/47730/first-bounty-final-scoreboard.png 428w,
https://www.dolthub.com/blog/static/4e02e3f4498d3a6b5bc56bd9f85cad81/0fcea/first-bounty-final-scoreboard.png 851w" sizes="(max-width: 851px) 100vw, 851px" loading="lazy">
  </a>
    </span></p>
<p>We're very excited to mail the checks to all the folks who worked hard to make this bounty a success.</p>
<p><span>
      <a href="https://www.dolthub.com/blog/static/9791bedbcbd3ed06e15435f17a7ff195/2ad33/fat-check.jpg" target="_blank" rel="noopener">
    <span></span>
  <img alt="Fat Check" title="Fat Check" src="https://www.dolthub.com/blog/static/9791bedbcbd3ed06e15435f17a7ff195/79a4e/fat-check.jpg" srcset="https://www.dolthub.com/blog/static/9791bedbcbd3ed06e15435f17a7ff195/606a2/fat-check.jpg 214w,
https://www.dolthub.com/blog/static/9791bedbcbd3ed06e15435f17a7ff195/65a3f/fat-check.jpg 428w,
https://www.dolthub.com/blog/static/9791bedbcbd3ed06e15435f17a7ff195/79a4e/fat-check.jpg 856w,
https://www.dolthub.com/blog/static/9791bedbcbd3ed06e15435f17a7ff195/99aeb/fat-check.jpg 1284w,
https://www.dolthub.com/blog/static/9791bedbcbd3ed06e15435f17a7ff195/e88f6/fat-check.jpg 1712w,
https://www.dolthub.com/blog/static/9791bedbcbd3ed06e15435f17a7ff195/2ad33/fat-check.jpg 3851w" sizes="(max-width: 856px) 100vw, 856px" loading="lazy">
  </a>
    </span></p>

<p>Now that the bounty is complete, we must figure out what to do with this data. How do we get the most out of our investment in the data?</p>
<h2>Clean up the data we got</h2>
<p>Given the heavily keyed nature of this data, we decided early on to not accept PRs for standardization or normalization of things like party names. Because most columns are part of the primary key, any change looks like a deletion and corresponding addition to Dolt. Thus, changes like that give the corrector credit for the whole row in the bounty instead of just the cell he or she changed. We queued up a number of these types of changes and we'll execute them now that the bounty is over.</p>
<h2>Find some users</h2>
<p>We collected the best US presidential Precinct level results on the internet. Now, we want people to use it. We think potentially the data is good enough that an open data community could be bootstrapped around it. The people who use it would have incentive to finish it as new state level data is released. We will reach out to the people at <a href="http://openelections.net/">Open Elections</a> and <a href="https://electionlab.mit.edu/">MIT Elections Lab</a> and start a conversation. If you know anyone else who could use this data, <a href="https://discord.com/invite/RFwfYpu">come let us know in our Discord</a>.</p>
<h2>Run another bounty?</h2>
<p>We're still missing 12 states and about 22% of the vote from 2020. If we want to get complete data and an open data community can't be bootstrapped, we may run another bounty in a couple months to finish the dataset. Let us know if you'd be interested in another bounty or the complete dataset.</p>

<p>We think <a href="https://www.dolthub.com/bounties">DoltHub Bounties</a> may be the fastest, cheapest way to build databases from open data. For $25,000 and 8 weeks, we were able to assemble a 1.7GB database of election results. </p>
<p>Our plan is to run at least one bounty per month for the rest of the year across a number of distinct data disciplines. We're running a <a href="https://www.dolthub.com/blog/2021-01-14-hopsital-prices-bounty/">hospital price transparency bounty</a> right now. We'll be launching two more over the next month or so. Hang out in <a href="https://discord.com/invite/RFwfYpu">our Discord</a> to keep up to date. Start wrangling data as your new side hustle.</p></div></div>]]>
            </description>
            <link>https://www.dolthub.com/blog/2021-02-15-election-bounty-review/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26149511</guid>
            <pubDate>Tue, 16 Feb 2021 00:20:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Building Rich Terminal Dashboards]]>
            </title>
            <description>
<![CDATA[
Score 332 | Comments 71 (<a href="https://news.ycombinator.com/item?id=26149488">thread link</a>) | @lumpa
<br/>
February 15, 2021 | https://www.willmcgugan.com/blog/tech/post/building-rich-terminal-dashboards/ | <a href="https://web.archive.org/web/*/https://www.willmcgugan.com/blog/tech/post/building-rich-terminal-dashboards/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
    

    
<p><a href="https://github.com/willmcgugan/rich">Rich</a> has become a popular (20K stars on GH) way of beautifying CLIs, and I'm pleased to see a number of projects using it.</p>
<p>Since Rich is mature and battle-tested now, I had considered winding-down development. Until, I saw this tweet:</p>
<h2>The Tweet</h2>
<blockquote><div lang="en" dir="ltr"><p>Do you want to see something really cool you can do with <a href="https://twitter.com/willmcgugan?ref_src=twsrc%5Etfw">@willmcgugan</a> 's rich library? </p><p>Checkout ghtop <a href="https://t.co/mn7oLbpw8e">https://t.co/mn7oLbpw8e</a>. It's a really fun CLI tool that demonstrates the power of rich (and other things).</p><p>Examples below üßµüëá (1/8)</p></div>‚Äî Hamel Husain (@HamelHusain) <a href="https://twitter.com/HamelHusain/status/1357771218095546368?ref_src=twsrc%5Etfw">February 5, 2021</a></blockquote> 
<p><a href="https://twitter.com/HamelHusain">@HamelHusain</a> and <a href="https://twitter.com/jeremyphoward">@jeremyphoward</a> used Rich to enhance <a href="https://github.com/nat/ghtop">ghtop</a> (a repo owned by the CEO of Github, no less). Ghtop shows a realtime a stream of events from the Github platform. And it looks good! So good that I realised how much potential Rich has for these type of htop-like applications.</p>
<p>Hamel and Jeremy had to overcome a few technical hurdles to make that work. Fortunately this will no longer be required as the latest version of Rich has first-class support for full-screen interfaces via a new Layout system.</p>
<h2>Full-screen terminal interface</h2>
<p>Here's a video demonstration of a terminal interface built with Layout:</p>
<p>
<iframe width="auto" src="https://www.youtube.com/embed/slrdSojCvlk" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
</p>
<h2>Layout API</h2>
<p>The API to create a flexible layout is surprisingly simple. You construct a <code>Layout()</code> object, then call <code>split()</code> to create sub-layouts. These sub-layouts may then be further divided. Layouts have a small number of settings which define their size relative to the terminal window. It's a simple system that can create terminal interfaces that almost resemble modern web apps.</p>
<div><figure> <img width="1140" height="724" title="layout_vscode.png" name="layout_vscode" data-md="https://media.moyaproject.com/willmcgugan/uploads/thumbnails/techblog/a7ab7ab6-6fb0-11eb-bc8d-f23c91845b44.png/a7ab7ab6-6fb0-11eb-bc8d-f23c91845b44png.md.3.jpeg" data-square="https://media.moyaproject.com/willmcgugan/uploads/thumbnails/techblog/a7ab7ab6-6fb0-11eb-bc8d-f23c91845b44.png/a7ab7ab6-6fb0-11eb-bc8d-f23c91845b44png.square.7.jpeg" data-xlg2x="https://media.moyaproject.com/willmcgugan/uploads/thumbnails/techblog/a7ab7ab6-6fb0-11eb-bc8d-f23c91845b44.png/a7ab7ab6-6fb0-11eb-bc8d-f23c91845b44png.xlg2x.2.jpeg" data-lg="https://media.moyaproject.com/willmcgugan/uploads/thumbnails/techblog/a7ab7ab6-6fb0-11eb-bc8d-f23c91845b44.png/a7ab7ab6-6fb0-11eb-bc8d-f23c91845b44png.lg.3.jpeg" data-xlg="https://media.moyaproject.com/willmcgugan/uploads/thumbnails/techblog/a7ab7ab6-6fb0-11eb-bc8d-f23c91845b44.png/a7ab7ab6-6fb0-11eb-bc8d-f23c91845b44png.xlg.8.jpeg" data-author="¬© 2021 Will McGugan<br>all rights reserved" data-og_preview="https://media.moyaproject.com/willmcgugan/uploads/thumbnails/techblog/a7ab7ab6-6fb0-11eb-bc8d-f23c91845b44.png/a7ab7ab6-6fb0-11eb-bc8d-f23c91845b44png.og.preview.2.jpeg" data-height="2100" data-width="3308" data-toggle="tooltip" data-details=" " data-sm="https://media.moyaproject.com/willmcgugan/uploads/thumbnails/techblog/a7ab7ab6-6fb0-11eb-bc8d-f23c91845b44.png/a7ab7ab6-6fb0-11eb-bc8d-f23c91845b44png.sm.3.jpeg" data-blur="https://media.moyaproject.com/willmcgugan/uploads/thumbnails/techblog/a7ab7ab6-6fb0-11eb-bc8d-f23c91845b44.png/a7ab7ab6-6fb0-11eb-bc8d-f23c91845b44png.blur.6.jpeg" data-slug="layout_vscode" sizes="(min-width: 1200px) 1170px, (min-width: 992px) 970px, (min-width: 768px) 750px" srcset="https://media.moyaproject.com/willmcgugan/uploads/thumbnails/techblog/a7ab7ab6-6fb0-11eb-bc8d-f23c91845b44.png/a7ab7ab6-6fb0-11eb-bc8d-f23c91845b44png.lg.3.jpeg 1170w, https://media.moyaproject.com/willmcgugan/uploads/thumbnails/techblog/a7ab7ab6-6fb0-11eb-bc8d-f23c91845b44.png/a7ab7ab6-6fb0-11eb-bc8d-f23c91845b44png.md.3.jpeg 970w, https://media.moyaproject.com/willmcgugan/uploads/thumbnails/techblog/a7ab7ab6-6fb0-11eb-bc8d-f23c91845b44.png/a7ab7ab6-6fb0-11eb-bc8d-f23c91845b44png.sm.3.jpeg 750w" src="https://media.moyaproject.com/willmcgugan/uploads/thumbnails/techblog/a7ab7ab6-6fb0-11eb-bc8d-f23c91845b44.png/a7ab7ab6-6fb0-11eb-bc8d-f23c91845b44png.lg.3.jpeg"> 
<figcaption>
<p>¬© 2021 Will McGugan</p>


<p>A Rich layout in VSCode</p>


</figcaption>

</figure>
</div>
<h2>Finally, some code</h2>
<p>Here's how you would create a basic layout with a header, a footer, and two side-panels.</p>
<pre><code>from rich.console import Console
from rich.layout import Layout

console = Console()
layout = Layout()

# Divide the "screen" in to three parts
layout.split(
    Layout(name="header", size=3),
    Layout(ratio=1, name="main"),
    Layout(size=10, name="footer"),
)
# Divide the "main" layout in to "side" and "body"
layout["main"].split(
    Layout(name="side"),
    Layout(name="body", ratio=2),
    direction="horizontal"
)
# Divide the "side" layout in to two
layout["side"].split(Layout(), Layout())

console.print(layout)
</code></pre>
<p>Running the code above produces the following output:</p>
<div><figure> <img width="1140" height="739" title="layout.png" name="layout" data-md="https://media.moyaproject.com/willmcgugan/uploads/thumbnails/techblog/98f8e5f8-6fab-11eb-bc8d-f23c91845b44.png/98f8e5f8-6fab-11eb-bc8d-f23c91845b44png.md.3.jpeg" data-square="https://media.moyaproject.com/willmcgugan/uploads/thumbnails/techblog/98f8e5f8-6fab-11eb-bc8d-f23c91845b44.png/98f8e5f8-6fab-11eb-bc8d-f23c91845b44png.square.7.jpeg" data-xlg2x="https://media.moyaproject.com/willmcgugan/uploads/thumbnails/techblog/98f8e5f8-6fab-11eb-bc8d-f23c91845b44.png/98f8e5f8-6fab-11eb-bc8d-f23c91845b44png.xlg2x.2.jpeg" data-lg="https://media.moyaproject.com/willmcgugan/uploads/thumbnails/techblog/98f8e5f8-6fab-11eb-bc8d-f23c91845b44.png/98f8e5f8-6fab-11eb-bc8d-f23c91845b44png.lg.3.jpeg" data-xlg="https://media.moyaproject.com/willmcgugan/uploads/thumbnails/techblog/98f8e5f8-6fab-11eb-bc8d-f23c91845b44.png/98f8e5f8-6fab-11eb-bc8d-f23c91845b44png.xlg.8.jpeg" data-author="¬© 2021 Will McGugan<br>all rights reserved" data-og_preview="https://media.moyaproject.com/willmcgugan/uploads/thumbnails/techblog/98f8e5f8-6fab-11eb-bc8d-f23c91845b44.png/98f8e5f8-6fab-11eb-bc8d-f23c91845b44png.og.preview.2.jpeg" data-height="1464" data-width="2258" data-toggle="tooltip" data-details=" " data-sm="https://media.moyaproject.com/willmcgugan/uploads/thumbnails/techblog/98f8e5f8-6fab-11eb-bc8d-f23c91845b44.png/98f8e5f8-6fab-11eb-bc8d-f23c91845b44png.sm.3.jpeg" data-blur="https://media.moyaproject.com/willmcgugan/uploads/thumbnails/techblog/98f8e5f8-6fab-11eb-bc8d-f23c91845b44.png/98f8e5f8-6fab-11eb-bc8d-f23c91845b44png.blur.6.jpeg" data-slug="layout" sizes="(min-width: 1200px) 1170px, (min-width: 992px) 970px, (min-width: 768px) 750px" srcset="https://media.moyaproject.com/willmcgugan/uploads/thumbnails/techblog/98f8e5f8-6fab-11eb-bc8d-f23c91845b44.png/98f8e5f8-6fab-11eb-bc8d-f23c91845b44png.lg.3.jpeg 1170w, https://media.moyaproject.com/willmcgugan/uploads/thumbnails/techblog/98f8e5f8-6fab-11eb-bc8d-f23c91845b44.png/98f8e5f8-6fab-11eb-bc8d-f23c91845b44png.md.3.jpeg 970w, https://media.moyaproject.com/willmcgugan/uploads/thumbnails/techblog/98f8e5f8-6fab-11eb-bc8d-f23c91845b44.png/98f8e5f8-6fab-11eb-bc8d-f23c91845b44png.sm.3.jpeg 750w" src="https://media.moyaproject.com/willmcgugan/uploads/thumbnails/techblog/98f8e5f8-6fab-11eb-bc8d-f23c91845b44.png/98f8e5f8-6fab-11eb-bc8d-f23c91845b44png.lg.3.jpeg"> 
<figcaption>
<p>¬© 2021 Will McGugan</p>


<p>Terminal split in to 5 sub-layouts. The boxes are placeholders, you can insert any content in their place.</p>


</figcaption>

</figure>
</div>
<p>Any renderable (text, table, progress bars etc) may be placed inside those sub-layouts.</p>
<p>We can now use the <a href="https://rich.readthedocs.io/en/latest/live.html">Live</a> class to create an application that adapts itself to the terminal window:</p>
<pre><code>from rich.live import Live
from time import sleep

with Live(layout, screen=True):
    while True:
        sleep(1)
</code></pre>
<p>In a real app, that do-nothing loop will be doing something useful like pulling data from the network to update contents.</p>
<p>See the <a href="https://rich.readthedocs.io/en/latest/layout.html">layout docs</a> for an in-depth tutorial.</p>
<h2>What's next?</h2>
<p>I think it's clear that Rich is acquiring more TUI (text user interface) features, and I've decided not to fight it. Rich's core purpose is still to beautify CLI output, but I think there is an opportunity here for a new way to create terminal apps. Ultimately it will be less like curses and more like HTML in a browser.</p>
<p>There are a number of things to do before Rich could replace a full TUI library (keyboard and mouse input for one) but the potential is there. Stay tuned for progress.</p>
<p>Follow <a href="https://twitter.com/willmcgugan">@willmcgugan</a> for more Rich related news.</p>



</article></div>]]>
            </description>
            <link>https://www.willmcgugan.com/blog/tech/post/building-rich-terminal-dashboards/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26149488</guid>
            <pubDate>Tue, 16 Feb 2021 00:16:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Performance Optimization Contest]]>
            </title>
            <description>
<![CDATA[
Score 26 | Comments 2 (<a href="https://news.ycombinator.com/item?id=26149436">thread link</a>) | @robfig
<br/>
February 15, 2021 | https://easyperf.net/blog/2019/02/02/Performance-optimization-contest | <a href="https://web.archive.org/web/*/https://easyperf.net/blog/2019/02/02/Performance-optimization-contest">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
				<p><strong>Contents:</strong></p>
<ul id="markdown-toc">
  <li><a href="#about-this-contest" id="markdown-toc-about-this-contest">About this contest</a></li>
  <li><a href="#qa" id="markdown-toc-qa">Q&amp;A</a>    <ul>
      <li><a href="#q0-why-the-hell-on-earth-i-should-participate-in-this-contest" id="markdown-toc-q0-why-the-hell-on-earth-i-should-participate-in-this-contest">Q0: <em>Why <del>the hell</del> on earth I should participate in this contest?</em></a></li>
      <li><a href="#q1-what-benchmarks-are-taken-into-the-contest" id="markdown-toc-q1-what-benchmarks-are-taken-into-the-contest">Q1: <em>What benchmarks are taken into the contest?</em></a></li>
      <li><a href="#q2-what-is-the-machineenvironment-we-will-be-optimizing-for" id="markdown-toc-q2-what-is-the-machineenvironment-we-will-be-optimizing-for">Q2: <em>What is the machine/environment we will be optimizing for?</em></a></li>
      <li><a href="#q3-what-if-i-dont-have-the-environment-you-are-using" id="markdown-toc-q3-what-if-i-dont-have-the-environment-you-are-using">Q3: <em>What if I don‚Äôt have the environment you are using?</em></a></li>
      <li><a href="#q4-how-i-should-find-performance-headrooms" id="markdown-toc-q4-how-i-should-find-performance-headrooms">Q4: <em>How I should find performance headrooms?</em></a></li>
      <li><a href="#q5-what-optimizations-are-allowed" id="markdown-toc-q5-what-optimizations-are-allowed">Q5: <em>What optimizations are allowed?</em></a></li>
      <li><a href="#q6-whats-not-allowed" id="markdown-toc-q6-whats-not-allowed">Q6: <em>What‚Äôs NOT allowed</em></a></li>
      <li><a href="#q7-how-should-the-submission-look-like" id="markdown-toc-q7-how-should-the-submission-look-like">Q7: <em>How should the submission look like?</em></a></li>
      <li><a href="#q8-how-i-will-test-your-solutions" id="markdown-toc-q8-how-i-will-test-your-solutions">Q8: <em>How I will test your solutions?</em></a></li>
      <li><a href="#q9-how-i-will-select-the-winner" id="markdown-toc-q9-how-i-will-select-the-winner">Q9: <em>How I will select the winner?</em></a></li>
    </ul>
  </li>
  <li><a href="#how-to-get-started" id="markdown-toc-how-to-get-started">How to get started?</a></li>
  <li><a href="#hints" id="markdown-toc-hints">Hints</a></li>
  <li><a href="#list-of-contest-editions" id="markdown-toc-list-of-contest-editions">List of contest editions</a></li>
</ul>

<hr>
<p><strong>Subscribe to my <a href="https://mailchi.mp/4eb73720aafe/easyperf">mailing list</a>, support me on <a href="https://www.patreon.com/dendibakh">Patreon</a> or by PayPal <a href="https://www.paypal.com/cgi-bin/webscr?cmd=_donations&amp;business=TBM3NW8TKTT34&amp;currency_code=USD&amp;source=url">donation</a>.</strong></p>

<hr>

<h3 id="about-this-contest">About this contest</h3>

<p>Hello everybody!</p>

<p>I decided to try new thing at the beginning of 2019. You probably heard about competitive programming and about popular web-sites like <a href="https://www.topcoder.com/">Topcoder</a>, <a href="https://www.codility.com/">Codility</a> and others. The idea is that you can try yourself in solving programming puzzles. Usually it‚Äôs not enough to just solve the puzzle, your solution must qualify for certain criterias such as algorithmic complexity and memory usage. Also on a real challenges it is improtant how fast you solved the problem.</p>

<p>Those sort of challenges usually test your problem solving skills as well as your knowledge of algorithms and data structures. It is a kind of tasks we usually see on programming job interviews. You need to write the code from scratch to a complete solution.</p>

<p>What I am starting is also a form of contest but aims at developing different set of skills. <strong>We will train to optimize already optimized code</strong>. We will learn hardware optimizations. This is briefly how it will look like: I will pick one existing benchmark of my choice and will send it to all my subscribers. You will have the time to play with the benchmark and find all performance headrooms you can find. You then send all your findings to me (modified sources/assemblies/compiler patches?/whatever speeds up the benchmark) and I check it and run on my hardware. At the end I will anounce the winners.</p>

<p>Before I explain it in more details I feel a need of writing disclaimer:</p>

<blockquote>
  <p><strong>Disclaimer</strong>: This is absolutely non-profit effort. I‚Äôm not looking for make any money from it or using someone‚Äôs knowledge in my own purposes. I will not use submissions to extract any intellectual property they might have. Also this is not aiming to advertise any particular software product including benchmarks/compilers. That‚Äôs why all the benchmarks and compilers I will use require to be open sourced. Neither it aims to advertise any particular HW.</p>
</blockquote>

<p>In this contest I try to emulate the situation in performance critical projects on the final stages. When all the functionality is delivered and tested. But before shipping the binary to the customers you were asked to tune the app to it‚Äôs peak performance. You know the hardware it will be deployed to. You have the sources in your hands and freedom to modify it (without introducing any bugs :) ). You are the build master, so you can add any compiler flags you want.</p>

<p>For the challenges that I will send I‚Äôm not looking for optimizations that fall into the category: ‚ÄúOh, I just used quicksort instead of bubblesort‚Äù. Expect the benchmark to be already optimized to some degree. Your task is to tune it for particular hardware to the peak performance.</p>

<h3 id="qa">Q&amp;A</h3>

<h4 id="q0-why-the-hell-on-earth-i-should-participate-in-this-contest">Q0: <em>Why <del>the hell</del> on earth I should participate in this contest?</em></h4>

<p><strong>A0</strong>: You will learn/practice how to do optimizations for HW. This might include eliminating cache misses by inserting prefetch instructions, getting rid of <a href="https://easyperf.net/blog/2018/01/18/Code_alignment_issues">Code alignment issues</a>, improving performance by helping compiler to vectorize/unroll the loop better. You will learn different techniques as you go.</p>

<hr>
<h4 id="q1-what-benchmarks-are-taken-into-the-contest">Q1: <em>What benchmarks are taken into the contest?</em></h4>

<p><strong>A1</strong>: It will be open sourced benchmark written in C/C++. Usually several source files. It should be easy to build, require minimal dependencies. Preferably it should have some form of validation.</p>

<hr>
<h4 id="q2-what-is-the-machineenvironment-we-will-be-optimizing-for">Q2: <em>What is the machine/environment we will be optimizing for?</em></h4>

<p><strong>A2</strong>: Most likely it will be 64 bit Linux with Intel x86 CPU (probably Haswell architecture). For a start I will not bother with disabling CPU <a href="https://en.wikipedia.org/wiki/Dynamic_frequency_scaling">dynamic frequency scaling</a> features or setting <a href="https://en.wikipedia.org/wiki/Processor_affinity">thread affinity</a>. I might do this in future.</p>

<hr>
<h4 id="q3-what-if-i-dont-have-the-environment-you-are-using">Q3: <em>What if I don‚Äôt have the environment you are using?</em></h4>

<p><strong>A3</strong>: It doesn‚Äôt matter much. If you don‚Äôt have Intel CPU or you are on Windows/Mac, just optimize for whatever you have. I would be happy to know about optimizations that help other CPUs, operating systems, etc.
<strong>I don‚Äôt have real prizes to give, so it‚Äôs mostly practicing and learning</strong>.</p>

<hr>
<h4 id="q4-how-i-should-find-performance-headrooms">Q4: <em>How I should find performance headrooms?</em></h4>

<p><strong>A4</strong>: Use all of your knowledge. Start with profiling the benchmark. You can browse through posts on this blog. Additionally I will write a separate post that might help begginers.</p>

<hr>
<h4 id="q5-what-optimizations-are-allowed">Q5: <em>What optimizations are allowed?</em></h4>

<p><strong>A5</strong>: Good news! <strong>All the dirty tricks allowed</strong>! The goal of this contest is to learn how to squeeze as much performance as possible from the hardware using any means available. You can modify sources and insert any compiler hints like pragmas, builtins, function attributes, etc. Also you can generate assembly listing (<code>-S</code> compiler option) and modify it. Finally, you can add some compiler option that might speed up the benchmark.</p>

<hr>
<h4 id="q6-whats-not-allowed">Q6: <em>What‚Äôs NOT allowed</em></h4>

<p><strong>A6</strong>: 1) Do not rewrite the benchmark completely or introduce major changes in algorithms. The good judging rule is ‚Äúeverything interesting should be calculated in runtime‚Äù.</p>

<p>2) Do not manually parallelize the benchmark, e.g converting it from single- to multi-threaded or offload computations to the GPU. I mean, I‚Äôm glad that you can do it and I will be happy to take a look what you did, but it‚Äôs not the intent of the contest.</p>

<p>3) Using <a href="https://en.wikipedia.org/wiki/Profile-guided_optimization">PGO</a> is allowed, however you can use it only for driving you optimizations, not for the submission. So, you can check how the benchmark gets better with PGO and understand why. And then make this optimization manually. Again, the purposes is practicing and learning.</p>

<hr>
<h4 id="q7-how-should-the-submission-look-like">Q7: <em>How should the submission look like?</em></h4>

<p><strong>A7</strong>: 1) I will not accept binaries for security reasons.</p>

<p>2) You can send patch files that I can apply to the sources of the benchmark or just assembly listing. If you did multiple optimizations please split them in separate patches. <code>git format-patch</code> is the right tool for that. This will save me a lot of time.</p>

<p>3) If you send assembly listing files please do also include diff file from the baseline (what you changed in the assembly). If you provide modified assembly listings it should be genearted only with open-sourced C/C++ compilers like gcc and clang. You can of course cheat and generate assembly with some other compiler that is better for the benchmark, but I will probably easily detect that. And it‚Äôs not about tricking, it‚Äôs about learning.</p>

<p>4) Make sure you specify clearly the compiler options if they are different from the baseline.</p>

<p>5) If you are capable of hacking compiler that‚Äôs also acceptable. You can send me patches for gcc/llvm compilers which I can apply and use for building the benchmark. Please use the top of tree revisions because it will be easier for me to apply them. We can then use it for improving our open source compilers. Also it would be very nice if you can send me textual description of all the optimizations you made.</p>

<hr>
<h4 id="q8-how-i-will-test-your-solutions">Q8: <em>How I will test your solutions?</em></h4>

<p><strong>A8</strong>: I will take your sources, build them on my machine and run the benchmark. I will run your binary multiple times (depends on the running time) and <a href="http://blog.kevmod.com/2016/06/benchmarking-minimum-vs-average/">take the minimum</a>. I‚Äôm thinking about testing all the solutions on some cloud machine, but that‚Äôs not settled yet.</p>

<hr>
<h4 id="q9-how-i-will-select-the-winner">Q9: <em>How I will select the winner?</em></h4>

<p><strong>A9</strong>: I will calculate your score as a ratio between execution time of the binary with your optimizations and the baseline.</p>

<hr>
<p>I know there is a lot more concerns you might have. This is just a first attempt with focus on learning how to do HW optimizations. In the end I don‚Äôt have real prizes to give out. :) After each contest I will share all the findings people did, so there is a big opportunity to learn from others! I know that a number of really experienced guys read this blog, so I encourage everyone to participate. Everyone is welcome!</p>

<p>All communication (including sending benchmarks and score submissions) will happen through emails, so <strong>make sure to subscribe</strong> using the form at the bottom of the page! I am planning to start first contest in the end of February 2019.</p>

<p>Let me know what you think about it or if you have any ideas or comments. You can also vote if you like it using the buttons below.</p>

<h3 id="how-to-get-started">How to get started?</h3>

<ol>
  <li>Collect the baseline (use <code>time</code> or analogs).</li>
  <li>Find the hotspot (use <code>perf record</code>).</li>
  <li>Find performance headroom
    <ul>
      <li>Take a look at the assembly and try to guess how you can do better.</li>
      <li>Run through <a href="https://easyperf.net/blog/2019/02/09/Top-Down-performance-analysis-methodology">TMAM</a> process.</li>
    </ul>
  </li>
  <li>Build the benchmark, run it and compare against baseline.</li>
</ol>

<h3 id="hints">Hints</h3>

<ul>
  <li>Do not try to understand the whole benchmark. For some people (including me) it‚Äôs crucial to understand how every peace of code works. For the purposes of optimizing it will be wasted effort. There are CPU benchmarks with thousands LOC (like <a href="http://spec.org/cpu2017/">SPEC2017</a>) it‚Äôs absoultely impossible to understand them in a reasonable time. What you need to familiarize yourself with are hotspots. That‚Äôs it. You most likely need to understand one function/loop which is not more than 100 LOC.</li>
  <li>You have specific workload for which you optimize the benchmark. You don‚Äôt need to optimize it for any other input/workload. The main principle behind <a href="https://en.wikipedia.org/wiki/Data-oriented_design">Data-oriented design</a> is that you know the data of your application.</li>
</ul>

<p>Information presented in llvm documentation: <a href="https://llvm.org/docs/Benchmarking.html">Benchmarking tips</a> migth also be helpful.</p>

<h3 id="list-of-contest-editions">List of contest editions</h3>

<ul>
  <li><a href="https://easyperf.net/blog/2019/02/16/Performance-optimization-contest-1">Contest #1</a> - 16 Feb 2019.</li>
  <li><a href="https://easyperf.net/blog/2019/04/10/Performance-analysis-and-tuning-contest-2">Contest #2</a> - 10 Apr 2019.</li>
  <li><a href="https://easyperf.net/blog/2019/05/28/Performance-analysis-and-tuning-contest-3">Contest #3</a> - 28 May 2019.</li>
  <li><a href="https://easyperf.net/blog/2021/02/05/Performance-analysis-and-tuning-contest-4">Contest #4</a> - 05 Feb 2021.</li>
</ul>

			</div></div>]]>
            </description>
            <link>https://easyperf.net/blog/2019/02/02/Performance-optimization-contest</link>
            <guid isPermaLink="false">hacker-news-small-sites-26149436</guid>
            <pubDate>Tue, 16 Feb 2021 00:09:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Ark 1]]>
            </title>
            <description>
<![CDATA[
Score 48 | Comments 36 (<a href="https://news.ycombinator.com/item?id=26148865">thread link</a>) | @simonpure
<br/>
February 15, 2021 | https://www.lot2046.com/ark-1 | <a href="https://web.archive.org/web/*/https://www.lot2046.com/ark-1">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div id="content_360_38"><div id="ark-1_hero_back"><picture><source media="(max-width: 799px)" srcset="https://lot2046-images.s3.amazonaws.com/ark/mobile/lot_2046_ark-1_hero_back.jpg, https://lot2046-images.s3.amazonaws.com/ark/mobile/lot_2046_ark-1_hero_back@2x.jpg 2x, https://lot2046-images.s3.amazonaws.com/ark/mobile/lot_2046_ark-1_hero_back@3x.jpg 3x"><source media="(min-width: 800px)" srcset="https://lot2046-images.s3.amazonaws.com/ark/desktop/lot_2046_ark-1_hero_back.jpg, https://lot2046-images.s3.amazonaws.com/ark/desktop/lot_2046_ark-1_hero_back@2x.jpg 2x"><img srcset="https://lot2046-images.s3.amazonaws.com/ark/desktop/lot_2046_ark-1_hero_back.jpg"></picture><p>Cabin porn.</p></div><div id="ark-1_hero_left"><picture><source media="(max-width: 799px)" srcset="https://lot2046-images.s3.amazonaws.com/ark/mobile/lot_2046_ark-1_hero_left.jpg, https://lot2046-images.s3.amazonaws.com/ark/mobile/lot_2046_ark-1_hero_left@2x.jpg 2x, https://lot2046-images.s3.amazonaws.com/ark/mobile/lot_2046_ark-1_hero_left@3x.jpg 3x"><source media="(min-width: 800px)" srcset="https://lot2046-images.s3.amazonaws.com/ark/desktop/lot_2046_ark-1_hero_left.jpg, https://lot2046-images.s3.amazonaws.com/ark/desktop/lot_2046_ark-1_hero_left@2x.jpg 2x"><img srcset="https://lot2046-images.s3.amazonaws.com/ark/desktop/lot_2046_ark-1_hero_left.jpg"></picture><p>LOT 0983 ‚Äî ARK 1; 6.4m x 3m x 2.6m; 13m¬≤ internally; 17m¬≤ externally; <br>4.5m x 1.6m window; rechargeable battery bank; electric powertrain.</p></div><div id="ark-1_hero_top"><picture><source media="(max-width: 799px)" srcset="https://lot2046-images.s3.amazonaws.com/ark/mobile/lot_2046_ark-1_hero_top.jpg, https://lot2046-images.s3.amazonaws.com/ark/mobile/lot_2046_ark-1_hero_top@2x.jpg 2x, https://lot2046-images.s3.amazonaws.com/ark/mobile/lot_2046_ark-1_hero_top@3x.jpg 3x"><source media="(min-width: 800px)" srcset="https://lot2046-images.s3.amazonaws.com/ark/desktop/lot_2046_ark-1_hero_top.jpg, https://lot2046-images.s3.amazonaws.com/ark/desktop/lot_2046_ark-1_hero_top@2x.jpg 2x"><img srcset="https://lot2046-images.s3.amazonaws.com/ark/desktop/lot_2046_ark-1_hero_top.jpg"></picture><p>A rechargeable solid state Lithium Ion battery for an EPA estimated range of 500+ miles, <br>600W solar panel roof with 5G and Starlink‚Ñ¢ antennas.</p></div><div id="ark-1_hero_boulder-1"><picture><source media="(max-width: 799px)" srcset="https://lot2046-images.s3.amazonaws.com/ark/mobile/lot_2046_ark-1_hero_boulder-1.jpg, https://lot2046-images.s3.amazonaws.com/ark/mobile/lot_2046_ark-1_hero_boulder-1@2x.jpg 2x, https://lot2046-images.s3.amazonaws.com/ark/mobile/lot_2046_ark-1_hero_boulder-1@3x.jpg 3x"><source media="(min-width: 800px)" srcset="https://lot2046-images.s3.amazonaws.com/ark/desktop/lot_2046_ark-1_hero_boulder-1.jpg, https://lot2046-images.s3.amazonaws.com/ark/desktop/lot_2046_ark-1_hero_boulder-1@2x.jpg 2x"><img srcset="https://lot2046-images.s3.amazonaws.com/ark/desktop/lot_2046_ark-1_hero_boulder-1.jpg"></picture><p>Off-road, self-driving, autonomous, off-grid mobile home.</p></div><div id="ark-1_hero_boulder-2"><picture><source media="(max-width: 799px)" srcset="https://lot2046-images.s3.amazonaws.com/ark/mobile/lot_2046_ark-1_hero_boulder-2.jpg, https://lot2046-images.s3.amazonaws.com/ark/mobile/lot_2046_ark-1_hero_boulder-2@2x.jpg 2x, https://lot2046-images.s3.amazonaws.com/ark/mobile/lot_2046_ark-1_hero_boulder-2@3x.jpg 3x"><source media="(min-width: 800px)" srcset="https://lot2046-images.s3.amazonaws.com/ark/desktop/lot_2046_ark-1_hero_boulder-2.jpg, https://lot2046-images.s3.amazonaws.com/ark/desktop/lot_2046_ark-1_hero_boulder-2@2x.jpg 2x"><img srcset="https://lot2046-images.s3.amazonaws.com/ark/desktop/lot_2046_ark-1_hero_boulder-2.jpg"></picture><p>Home on the range.</p></div><div id="ark-1_hero_right"><picture><source media="(max-width: 799px)" srcset="https://lot2046-images.s3.amazonaws.com/ark/mobile/lot_2046_ark-1_hero_right.jpg, https://lot2046-images.s3.amazonaws.com/ark/mobile/lot_2046_ark-1_hero_right@2x.jpg 2x, https://lot2046-images.s3.amazonaws.com/ark/mobile/lot_2046_ark-1_hero_right@3x.jpg 3x"><source media="(min-width: 800px)" srcset="https://lot2046-images.s3.amazonaws.com/ark/desktop/lot_2046_ark-1_hero_right.jpg, https://lot2046-images.s3.amazonaws.com/ark/desktop/lot_2046_ark-1_hero_right@2x.jpg 2x"><img srcset="https://lot2046-images.s3.amazonaws.com/ark/desktop/lot_2046_ark-1_hero_right.jpg"></picture><p>Breakfast of champions.</p></div><hr><p>Product range:</p><div id="ark-1_asset_tire-table-1"><picture><source media="(max-width: 799px)" srcset="https://lot2046-images.s3.amazonaws.com/ark/mobile/lot_2046_ark-1_asset_tire-table-1.jpg, https://lot2046-images.s3.amazonaws.com/ark/mobile/lot_2046_ark-1_asset_tire-table-1@2x.jpg 2x, https://lot2046-images.s3.amazonaws.com/ark/mobile/lot_2046_ark-1_asset_tire-table-1@3x.jpg 3x"><source media="(min-width: 800px)" srcset="https://lot2046-images.s3.amazonaws.com/ark/desktop/lot_2046_ark-1_asset_tire-table-1.jpg, https://lot2046-images.s3.amazonaws.com/ark/desktop/lot_2046_ark-1_asset_tire-table-1@2x.jpg 2x"><img srcset="https://lot2046-images.s3.amazonaws.com/ark/desktop/lot_2046_ark-1_asset_tire-table-1.jpg"></picture></div><hr><div id="ark-1_main-text"><div><p>Humans have never really lived on earth. 
</p><p>In fear of the cold, famines, and war, we chose to huddle in caves, camps, and cities in order to dwell near pooled resources, fearing unknown calamities.&nbsp;But the internet has changed all this. Accessibility no longer requires proximity. You no longer have to physically relocate in order to acquire the tools and resources you need to live a comfortable life. We are moving towards a reality where work and location no longer need to depend on the other. With the rapidly growing infrastructures of telecommunications, green energy, delivery services, and travel flexibility ‚Äì both in pace of advancement and market size ‚Äì a new way of working and living is emerging.
</p><p>One in which we no longer need to rely solely on outdated frameworks of metropolitan densities to support a given lifestyle.
</p><p>Flattening density is the way forward.
</p><p>Entire economies will need to re-evaluate what it means to give flexibility just as its users are realizing the boundaries of these new flexibilities. We‚Äôre already seeing an exodus of major metropolises. Lockdown hysteria has forced us to consider whether the paths we thought we prescribed ourselves is really ours. As this changes how many will choose to live, LOT is building a mission to earth.
</p><p>ARK 1 is an off-road, mobile dwelling. It features plug and play modular parts, a rechargeable battery pack, solar roof, 4 wheel steering, independent suspension, and can be equipped with full self-driving capabilities. 
</p><p>By treating the home as the ultimate appliance, we‚Äôre building a vehicle to nourish the self. If your home could take you anywhere, and there‚Äôs no more point A to point B, where would you go? </p></div></div><div><div id="ark-1_crawl-mode"><div><div><p>Crawl Mode</p><p><iframe src="https://www.youtube.com/embed/UFBsLeqcMR8?controls=0&amp;color=white" frameborder="0" allowfullscreen=""></iframe></p></div><div><div><p>ARK 1 utilizes all of its on-board self-driving cameras/sensors to enable it to drive autonomously on off-road, off-grid terrain.
</p><p>It is also equipped with a drone that acts as eyes by flying ahead to map trickier surfaces in order to provide the best possible route (fog map). This feature is not meant for navigating conventional roads, as there are no lanes to switch or traffic lights to watch for. Only surface and elevation changes to traverse, which it does slowly, so if you wanted to go to bed in the desert and wake up at the coastline, you can.</p></div></div></div></div></div><p>Eyes:</p><div id="ark-1_asset-drone-1"><picture><source media="(max-width: 799px)" srcset="https://lot2046-images.s3.amazonaws.com/ark/mobile/lot_2046_ark-1_asset_drone-1.jpg, https://lot2046-images.s3.amazonaws.com/ark/mobile/lot_2046_ark-1_asset_drone-1@2x.jpg 2x, https://lot2046-images.s3.amazonaws.com/ark/mobile/lot_2046_ark-1_asset_drone-1@3x.jpg 3x"><source media="(min-width: 800px)" srcset="https://lot2046-images.s3.amazonaws.com/ark/desktop/lot_2046_ark-1_asset_drone-1.jpg, https://lot2046-images.s3.amazonaws.com/ark/desktop/lot_2046_ark-1_asset_drone-1@2x.jpg 2x"><img srcset="https://lot2046-images.s3.amazonaws.com/ark/desktop/lot_2046_ark-1_asset_drone-1.jpg"></picture></div><div><picture><source media="(max-width: 799px)" srcset="https://lot2046-images.s3.amazonaws.com/ark/mobile/lot_2046_ark-1_asset_drone-2.jpg, https://lot2046-images.s3.amazonaws.com/ark/mobile/lot_2046_ark-1_asset_drone-2@2x.jpg 2x, https://lot2046-images.s3.amazonaws.com/ark/mobile/lot_2046_ark-1_asset_drone-2@3x.jpg 3x"><source media="(min-width: 800px)" srcset="https://lot2046-images.s3.amazonaws.com/ark/desktop/lot_2046_ark-1_asset_drone-2.jpg, https://lot2046-images.s3.amazonaws.com/ark/desktop/lot_2046_ark-1_asset_drone-2@2x.jpg 2x"><img srcset="https://lot2046-images.s3.amazonaws.com/ark/desktop/lot_2046_ark-1_asset_drone-2.jpg"></picture><p>LOT 0983-2</p></div><hr><div><picture><source media="(max-width: 799px)" srcset="https://lot2046-images.s3.amazonaws.com/ark/mobile/lot_2046_ark-1_hdr-4.jpg, https://lot2046-images.s3.amazonaws.com/ark/mobile/lot_2046_ark-1_hdr-4@2x.jpg 2x, https://lot2046-images.s3.amazonaws.com/ark/mobile/lot_2046_ark-1_hdr-4@3x.jpg 3x"><source media="(min-width: 800px)" srcset="https://lot2046-images.s3.amazonaws.com/ark/desktop/lot_2046_ark-1_hdr-4.jpg, https://lot2046-images.s3.amazonaws.com/ark/desktop/lot_2046_ark-1_hdr-4@2x.jpg 2x"><img srcset="https://lot2046-images.s3.amazonaws.com/ark/desktop/lot_2046_ark-1_hdr-4.jpg"></picture><p>12:34 ‚Äì Sunday, May 31 at Cambria, 35.587749, -121.122021</p></div><div><picture><source media="(max-width: 799px)" srcset="https://lot2046-images.s3.amazonaws.com/ark/mobile/lot_2046_ark-1_hdr-14.jpg, https://lot2046-images.s3.amazonaws.com/ark/mobile/lot_2046_ark-1_hdr-14@2x.jpg 2x, https://lot2046-images.s3.amazonaws.com/ark/mobile/lot_2046_ark-1_hdr-14@3x.jpg 3x"><source media="(min-width: 800px)" srcset="https://lot2046-images.s3.amazonaws.com/ark/desktop/lot_2046_ark-1_hdr-14.jpg, https://lot2046-images.s3.amazonaws.com/ark/desktop/lot_2046_ark-1_hdr-14@2x.jpg 2x"><img srcset="https://lot2046-images.s3.amazonaws.com/ark/desktop/lot_2046_ark-1_hdr-14.jpg"></picture><p>21:45 ‚Äì Saturday, April 11 at Joshua Tree, 33.977110, -116.020468</p></div><div><picture><source media="(max-width: 799px)" srcset="https://lot2046-images.s3.amazonaws.com/ark/mobile/lot_2046_ark-1_hdr-6.jpg, https://lot2046-images.s3.amazonaws.com/ark/mobile/lot_2046_ark-1_hdr-6@2x.jpg 2x, https://lot2046-images.s3.amazonaws.com/ark/mobile/lot_2046_ark-1_hdr-6@3x.jpg 3x"><source media="(min-width: 800px)" srcset="https://lot2046-images.s3.amazonaws.com/ark/desktop/lot_2046_ark-1_hdr-6.jpg, https://lot2046-images.s3.amazonaws.com/ark/desktop/lot_2046_ark-1_hdr-6@2x.jpg 2x"><img srcset="https://lot2046-images.s3.amazonaws.com/ark/desktop/lot_2046_ark-1_hdr-6.jpg"></picture><p>22:33 ‚Äì Friday, April 10 at Great Salt Lake Desert, 40.6091, -113.4661</p></div><div><picture><source media="(max-width: 799px)" srcset="https://lot2046-images.s3.amazonaws.com/ark/mobile/lot_2046_ark-1_hdr-10.jpg, https://lot2046-images.s3.amazonaws.com/ark/mobile/lot_2046_ark-1_hdr-10@2x.jpg 2x, https://lot2046-images.s3.amazonaws.com/ark/mobile/lot_2046_ark-1_hdr-10@3x.jpg 3x"><source media="(min-width: 800px)" srcset="https://lot2046-images.s3.amazonaws.com/ark/desktop/lot_2046_ark-1_hdr-10.jpg, https://lot2046-images.s3.amazonaws.com/ark/desktop/lot_2046_ark-1_hdr-10@2x.jpg 2x"><img srcset="https://lot2046-images.s3.amazonaws.com/ark/desktop/lot_2046_ark-1_hdr-10.jpg"></picture><p>19:23 ‚Äì Monday, May 18 at El Capitan, 34.465976, -120.024302</p></div><div><picture><source media="(max-width: 799px)" srcset="https://lot2046-images.s3.amazonaws.com/ark/mobile/lot_2046_ark-1_hdr-8.jpg, https://lot2046-images.s3.amazonaws.com/ark/mobile/lot_2046_ark-1_hdr-8@2x.jpg 2x, https://lot2046-images.s3.amazonaws.com/ark/mobile/lot_2046_ark-1_hdr-8@3x.jpg 3x"><source media="(min-width: 800px)" srcset="https://lot2046-images.s3.amazonaws.com/ark/desktop/lot_2046_ark-1_hdr-8.jpg, https://lot2046-images.s3.amazonaws.com/ark/desktop/lot_2046_ark-1_hdr-8@2x.jpg 2x"><img srcset="https://lot2046-images.s3.amazonaws.com/ark/desktop/lot_2046_ark-1_hdr-8.jpg"></picture><p>18:43 ‚Äì Friday, April 10 at Joshua Tree, 33.977110, -116.020468</p></div><hr><p>Details:</p><hr><div><a id="ark-1_ar-icon" rel="ar" href="https://lot2046-images.s3.amazonaws.com/ark/ark-1.usdz"><svg width="92" height="84" viewBox="0 0 92 84" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M56.7205 35.5L46.4 41.5" stroke="black" stroke-width="3" stroke-linecap="round" stroke-linejoin="round"></path><path d="M77.7205 23.5L67.4 29.5" stroke="black" stroke-width="3" stroke-linecap="round" stroke-linejoin="round"></path><path d="M25.7205 53.5L15.4 59.5" stroke="black" stroke-width="3" stroke-linecap="round" stroke-linejoin="round"></path><path d="M46.4 41.5V51.5" stroke="black" stroke-width="3" stroke-linecap="round" stroke-linejoin="round"></path><path d="M46.4 68.5V78.5" stroke="black" stroke-width="3" stroke-linecap="round" stroke-linejoin="round"></path><path d="M46.4 4.5V14.5" stroke="black" stroke-width="3" stroke-linecap="round" stroke-linejoin="round"></path><path d="M37.0441 36.1526L46.4 41.5" stroke="black" stroke-width="3" stroke-linecap="round" stroke-linejoin="round"></path><path d="M15.0441 23.1526L24.4 28.5" stroke="black" stroke-width="3" stroke-linecap="round" stroke-linejoin="round"></path><path d="M69.0441 54.1526L78.4 59.5" stroke="black" stroke-width="3" stroke-linecap="round" stroke-linejoin="round"></path><path opacity="0.5" d="M46.5 3.5V79.5" stroke="black" stroke-linecap="square"></path><path opacity="0.5" d="M13.3232 22.4402L79.6499 60.6511" stroke="black" stroke-linecap="square"></path><path opacity="0.5" d="M13.3191 60.6432L79.678 22.3797" stroke="black" stroke-linecap="square"></path><path opacity="0.5" fill-rule="evenodd" clip-rule="evenodd" d="M46.5 3L79.842 22.25V60.75L46.5 80L13.158 60.75V22.25L46.5 3Z" stroke="black"></path><mask id="mask0" mask-type="alpha" maskUnits="userSpaceOnUse" x="0" y="0" width="92" height="84"><path fill-rule="evenodd" clip-rule="evenodd" d="M37.7968 0H55.7968V25.9515L82.2032 10.7058L91.2032 26.2942L64.866 41.5L91.2032 56.7058L82.2032 72.2942L55.7968 57.0485V84H37.7968V57.1284L9.79681 73.2942L0.796814 57.7058L28.866 41.5L0.796814 25.2942L9.79681 9.70577L37.7968 25.8716V0Z" fill="white"></path></mask><g mask="url(#mask0)"><path fill-rule="evenodd" clip-rule="evenodd" d="M46.5 3L79.842 22.25V60.75L46.5 80L13.158 60.75V22.25L46.5 3Z" stroke="black" stroke-width="3"></path></g></svg></a><p>Try your ARK 1 in the wild. Tap on the icon above 
<br>to experience it true to scale. Only available on iOS devices (for now) <a href="https://lot2046-images.s3.amazonaws.com/ark/ark-1.usdz" rel="ar">see ARK 1 in AR</a></p></div><hr><div><p id="ark-1_white-paper-title">White paper</p><div id="ark-1_white-paper-image"><picture><source media="(max-width: 799px)" srcset="https://lot2046-images.s3.amazonaws.com/ark/mobile/lot_2046_ark-1_white-paper.jpg, https://lot2046-images.s3.amazonaws.com/ark/mobile/lot_2046_ark-1_white-paper@2x.jpg 2x, https://lot2046-images.s3.amazonaws.com/ark/mobile/lot_2046_ark-1_white-paper@3x.jpg 3x"><source media="(min-width: 800px)" srcset="https://lot2046-images.s3.amazonaws.com/ark/desktop/lot_2046_ark-1_white-paper.jpg, https://lot2046-images.s3.amazonaws.com/ark/desktop/lot_2046_ark-1_white-paper@2x.jpg 2x"><img srcset="https://lot2046-images.s3.amazonaws.com/ark/desktop/lot_2046_ark-1_white-paper.jpg"></picture></div><p>Read our full proposal for ARK 1 on <a href="https://docs.google.com/document/d/1eedNlGgE11JfQgKiYzw33XpsmupT_pjrGBESwHnT8EE/edit" target="_blank">Google Docs</a></p></div><hr><div><p id="ark-1_calculator-title">How much will my ARK 1 subscription cost?</p><div><p>1 day</p><p>365 days</p><div><p>Travel to reservation site</p><p>24/7 access to LOT community centers</p><p>For use in designated areas only</p><p>Remote security</p><p>24/7 roadside assistance</p><p>Remote check-in/out</p><p>Reservation delivery</p><p>Open road travel</p><p>Towing Vehicle (Powered by JEEP¬Æ)</p><p>LOT Life subscription, basic self-care products</p><p>Remote smart address (delivery locker, automatic postal routing, DMV untethered, utilities)</p><p>Water delivery, food boxes</p><p>Citizenship Assistance (legal aid, medical care, licensing, property insurance)</p></div><div><p>Your ARK 1 subscription estimate:<br><span>X days</span><span>, ~X month</span></p></div></div></div><hr><div><p id="ark-1_reserve-title">Reserve your ARK 1 now:</p><div><picture><source media="(max-width: 799px)" srcset="https://lot2046-images.s3.amazonaws.com/ark/mobile/lot_2046_ark-1_key-1.jpg, https://lot2046-images.s3.amazonaws.com/ark/mobile/lot_2046_ark-1_key-1@2x.jpg 2x, https://lot2046-images.s3.amazonaws.com/ark/mobile/lot_2046_ark-1_key-1@3x.jpg 3x"><source media="(min-width: 800px)" srcset="https://lot2046-images.s3.amazonaws.com/ark/desktop/lot_2046_ark-1_key-1.jpg, https://lot2046-images.s3.amazonaws.com/ark/desktop/lot_2046_ark-1_key-1@2x.jpg 2x"><img srcset="https://lot2046-images.s3.amazonaws.com/ark/desktop/lot_2046_ark-1_key-1.jpg"></picture></div><p><b>$100</b></p><div id="ark-1_reserve-body"><p>LOT 0192-2, ARK 1 multitool (bottle opener, hex wrench set, buckle, keychain); 
<br>powder-coated steel; personalized number indicating queue position; 50g.
</p><p>
By purchasing this physical token, you are reserving your place in line. 
<br>When the time comes, we will be shipping ARK 1s according to this waitlist.</p></div><p><a id="ark-1_reserve-button" href="https://supply.lot2046.com/products/ark-1-multifunction-tool-reservation-number" target="_blank">Buy now to reserve your queue in line</a></p><p id="ark-1_reserve-postfix">We ship worldwide. No refunds. 
<br>Exception to missing or damaged shipment.</p></div></div></div></div>]]>
            </description>
            <link>https://www.lot2046.com/ark-1</link>
            <guid isPermaLink="false">hacker-news-small-sites-26148865</guid>
            <pubDate>Mon, 15 Feb 2021 23:08:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What security does a default OpenBSD installation offer?]]>
            </title>
            <description>
<![CDATA[
Score 89 | Comments 67 (<a href="https://news.ycombinator.com/item?id=26148667">thread link</a>) | @zdw
<br/>
February 15, 2021 | https://dataswamp.org/~solene/2021-02-14-openbsd-default-security.html | <a href="https://web.archive.org/web/*/https://dataswamp.org/~solene/2021-02-14-openbsd-default-security.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<article id="20210214">
  <header>
  
    
    <p>Written by <em>Sol√®ne</em>, on 14 February 2021.<br>Tags: 
<span><a href="https://dataswamp.org/~solene/tag-openbsd69.html">#openbsd69</a></span>


<span><a href="https://dataswamp.org/~solene/tag-openbsd.html">#openbsd</a></span>


<span><a href="https://dataswamp.org/~solene/tag-security.html">#security</a></span>

</p>
    
  </header>
  
<p>In this text I will explain what makes OpenBSD secure by default when you install it.  Do not take this for a security analysis, but more like a guide to help you understand what is done by OpenBSD to have a secure environment.  The purpose of this text is not to compare OpenBSD to others OS but to say what you can honestly expects from OpenBSD.
</p>
<p>There are no security without a threat model, I always consider the following cases: computer stolen at home by a thief, remote attacks trying to exploit running services, exploit of user network clients.
</p>

<p>Here is a list of features that I consider important for an operating system security.  While not every item from the following list are strictly security features, they help having a strict system that prevent software to misbehave and lead to unknown lands.
</p>
<p>In my opinion security is not only about preventing remote attackers to penetrate the system, but also to prevent programs or users to make the system unusable.
</p>
<h2> Pledge / unveil on userland</h2>
<p>Pledge and unveil are often referred together although they can be used independently.  Pledge is a system call to restrict the permissions of a program at some point in its source code, permissions can't be get back once pledge has been called.  Unveil is a system call that will hide all the file system to the process except the paths that are unveiled, it is possible to choose what permissions is allowed for the paths.
</p>
<p>Both a very effective and powerful surgical security tools but they require some modification within the source code of a software, but adding them requires a deep understanding on what the software is doing.  It is not always possible to forbid some system calls to a software that requires to do almost anything, software designed with privilege separation are better candidate for a proper pledge addition because each part has its own job.
</p>
<p>Some software in packages have received pledge or/and unveil support, like Chromium or Firefox for the most well known.
</p>
<p><a href="https://www.openbsd.org/papers/bsdcan2019-unveil/index.html">OpenBSD presentation about Unveil (BSDCan2019)</a></p>
<p><a href="https://www.openbsd.org/papers/BeckPledgeUnveilBSDCan2018.pdf">OpenBSD presentation of Pledge and Unveil (BSDCan2018)</a></p>
<h2> Privilege separation</h2>
<p>Most of the base system services used within OpenBSD runs using a privilege separation pattern.  Each part of a daemon is restricted to the minimum required.  A monolithic daemon would have to read/write files, accept network connections, send messages to the log, in case of security breach this allows a huge attack surface.  By separating a daemon in multiple parts, this allow a more fine grained control of each workers, and using pledge and unveil system calls, it's possible to set limits and highly reduce damage in case a worker is hacked.
</p>
<h2> Clock synchronization</h2>
<p>The daemon server is started by default to keep the clock synchronized with time servers.  A reference TLS server is used to challenge the time servers.  Keeping a computer with its clock synchronized is very important.  This is not really a security feature but you can't be serious if you use a computer on a network without its time synchronized.
</p>
<h2> X display not as root</h2>
<p>If you use the X, it drops privileges to _x11 user, it runs as unpriviliged user instead of root, so in case of security issue this prevent an attacker of accessing through a X11 bug more than what it should.
</p>
<h2> Resources limits</h2>
<p>Default resources limits prevent a program to use too much memory, too many open files or too many processes.  While this can prevent some huge programs to run with the default settings, this also helps finding file descriptor leaks, prevent a fork bomb or a simple daemon to steal all the memory leading to a crash.
</p>
<h2> Genuine full disk encryption</h2>
<p>When you install OpenBSD using a full disk encryption setup, everything will be locked down by the passphrase at the bootloader step, you can't access the kernel or anything of the system without the passphrase.
</p>
<h2> W^X</h2>
<p>Most programs on OpenBSD aren't allowed to map memory with Write AND Execution bit at the same time (W^X means Write XOR Exec), this can prevents an interpreter to have its memory modified and executed.  Some packages aren't compliant to this and must be linked with a specific library to bypass this restriction AND must be run from a partition with the "wxallowed" option.
</p>
<p><a href="https://www.openbsd.org/papers/hackfest2015-w-xor-x.pdf">OpenBSD presentation ¬´ Kernel W^X Improvements In OpenBSD ¬ª</a></p>
<h2> Only one reliable randomness source</h2>
<p>When your system requires a random number (and it does very often), OpenBSD only provides one API to get a random number and they are really random and can't be exhausted.  A good random number generator (RNG) is important for many cryptography requirements.
</p>
<p><a href="https://www.openbsd.org/papers/hackfest2014-arc4random/index.html">OpenBSD presentation about arc4random</a></p>
<h2> Accurate documentation</h2>
<p>OpenBSD comes with a full documentation in its man pages.  One should be able to fully configure their system using only the man pages.  Man pages comes with CAVEATS or BUGS sections sometimes, it's important to take care about those sections.  It is better to read the documentation and understand what has to be done in order to configure a system instead of following an outdated and anonymous text available on the Internet.
</p>
<p><a href="https://man.openbsd.org/">OpenBSD man pages online</a></p>
<p><a href="https://www.openbsd.org/papers/eurobsdcon2018-mandoc.pdf">EuroBSDcon 2018 about ¬´ Better documentation ¬ª</a></p>
<h2> IPSec and Wireguard out of the box</h2>
<p>If you need to setup a VPN, you can use IPSec or Wireguard protocols only using the base system, no package required.
</p>
<h2> Memory safeties</h2>
<p>OpenBSD has many safeties in regards to memory allocation and will prevent use after free or unsafe memory usage very aggressively, this is often a source of crash for some software from packages because OpenBSD is very strict when you want to use the memory.  This helps finding memory misuses and will kill software misbehaving.
</p>
<h2> Dedicated root account</h2>
<p>When you install the system, a root account is created and its password is asked, then you create an user that will be member of "wheel" group, allowing it to switch user to root with root's password.  doas (OpenBSD base system equivalent of sudo) isn't configured by default.  With the default installation, the root password is required to do any root action.  I think a dedicated root account that can be logged in without use of doas/sudo is better than a misconfigured doas/sudo allowing every thing only if you know the user password.
</p>
<h2> Small network attack surface</h2>
<p>The only services that could be enabled at installation time listening on the network are OpenSSH (asked at install time with default = yes), dhclient (if you choose dhcp) and slaacd (if you use ipv6 in automatic configuration).
</p>
<h2> Encrypted swap</h2>
<p>By default the OpenBSD swap is encrypted, meaning if programs memory are sent to the swap nobody can recover it later.
</p>
<h2> SMT disabled</h2>
<p>Due to a heavy number of security breaches due to SMT (like hyperthreading), the default installation disable half the logical cores to prevent any data leak.
</p>
<p><a href="https://en.wikipedia.org/wiki/Meltdown_(security_vulnerability)">Meltdown: one of the first security issue related to speculative execution in the CPU</a></p>
<h2> Micro and Webcam disabled</h2>
<p>With the default installation, both microphone and webcam won't actually record anything except blank video/sound until you set a sysctl for this.
</p>
<h3> Maintainability, release often, update often</h3>
<p>The OpenBSD team publish a new release a new version every six months and only last two releases receives security updates.  This allows to upgrade often but without pain, the upgrade process are small steps twice a year that help keep the whole system up to date.  This avoids the fear of a huge upgrade and never doing it and I consider it a huge security bonus.  Most OpenBSD around are running latest versions.
</p>
<h3> Signify chain of trust</h3>
<p>Installer, archives and packages are signed using signify public/private keys.  OpenBSD installations comes with the release and release n+1 keys to check the packages authenticity.  A key is used only six months and new keys are received in each new release allowing to build a chain of trust.  Signify keys are very small and are published on many medias to double check when you need to bootstrap this chain of trust.
</p>
<p><a href="https://www.openbsd.org/papers/bsdcan-signify.html">Signify at BSDCan 2015</a></p>
<h2> Packages</h2>
<p>While most of the previous items were about the base system or the kernel, the packages also have a few tricks to offer.
</p>
<h3> Chroot by default when available</h3>
<p>Most daemons that are available offering a chroot feature will have it enabled by default.  In some circumstances like for Nginx web server, the software is patched by the OpenBSD team to enable chroot which is not an official feature.
</p>
<h3> Dedicated users for services</h3>
<p>Most packages that provide a server also create a new dedicated user for this exact service, allowing more privilege separation in case of security issue in one service.
</p>
<h3> Installing a service doesn't enable it</h3>
<p>When you install a service, it doesn't get enabled by default.  You will have to configure the system to enable it at boot.  There is a single /etc/rc.conf.local files that can be used to see what is enabled at boot, this can be manipulated using rcctl command.  Forcing the user to enable services makes the system administrator fully aware of what is running on the system, which is good point for security.
</p>
<p><a href="https://man.openbsd.org/rcctl">rcctl man page</a></p>

<p>Most of the previous "security features" should be considered good practices and not features.  Limiting users resources, reducing daemon privileges, being strict about memory usage, provide a good documentation, start the least required amount of services and provide the user with a clean default installation that can be customized later.
</p>
<p>There are also many other features that have been added and which I don't fully understand, and that I prefer letting the reader take notice. 
</p>
<p><a href="https://www.openbsd.org/papers/bsdtw.pdf">¬´ Mitigations and other real security features ¬ª by Theo De Raadt</a></p>
<p><a href="https://www.openbsd.org/innovations.html">OpenBSD innovations</a></p>
<p><a href="https://www.openbsd.org/events.html">OpenBSD events, often including slides or videos</a></p>

</article>
</div></div>]]>
            </description>
            <link>https://dataswamp.org/~solene/2021-02-14-openbsd-default-security.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26148667</guid>
            <pubDate>Mon, 15 Feb 2021 22:51:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Are the New M1 Macbooks Any Good for Deep Learning?]]>
            </title>
            <description>
<![CDATA[
Score 132 | Comments 118 (<a href="https://news.ycombinator.com/item?id=26148333">thread link</a>) | @syntaxing
<br/>
February 15, 2021 | https://www.betterdatascience.com/m1-deep-learning/ | <a href="https://web.archive.org/web/*/https://www.betterdatascience.com/m1-deep-learning/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                                                                        
<!-- WP QUADS Content Ad Plugin v. 2.0.19 -->

<p><span data-preserver-spaces="true">There‚Äôs a lot of hype behind the new Apple M1 chip. So far, it‚Äôs proven to be superior to anything Intel has offered. But what does this mean for deep learning? That‚Äôs what you‚Äôll find out today.</span></p>
<p><span data-preserver-spaces="true">The new M1 chip isn‚Äôt just a CPU. On the MacBook Pro, it consists of 8 core CPU, 8 core GPU, and 16 core neural engine, among other things. Both the processor and the GPU are far superior to the previous-generation Intel configurations.</span></p>
<p><span data-preserver-spaces="true">I‚Äôve already demonstrated how fast the M1 chip is for&nbsp;</span><a href="https://www.betterdatascience.com/mac-m1-python/" target="_blank" rel="noopener noreferrer"><span data-preserver-spaces="true">regular data science tasks</span></a><span data-preserver-spaces="true">, but what about deep learning?&nbsp;</span></p>
<p><span data-preserver-spaces="true">Short answer ‚Äì yes, there are some improvements in this department, but are Macs now better than, let‚Äôs say,&nbsp;</span><em><span data-preserver-spaces="true">Google Colab</span></em><span data-preserver-spaces="true">? Keep in mind, Colab is an entirely free option.</span></p>
<p><span data-preserver-spaces="true">The article is structured as follows:</span></p>
<ul>
<li><a href="#cpu">CPU and GPU benchmark</a></li>
<li><a href="#test">Performance test ‚Äì MNIST</a></li>
<li><a href="#fashion">Performance test ‚Äì Fashion MNIST</a></li>
<li><a href="#cifar">Performance test ‚Äì CIFAR-10</a></li>
<li><a href="#conclusion">Conclusion</a></li>
</ul>
<h2><span data-preserver-spaces="true">Important notes</span></h2>
<p><span data-preserver-spaces="true">Not all data science libraries are compatible with the new M1 chip yet. Getting TensorFlow (version 2.4) to work properly is easier said than done.</span></p>
<p><span data-preserver-spaces="true">You can refer to&nbsp;</span><a href="https://github.com/apple/tensorflow_macos" target="_blank" rel="noopener noreferrer"><span data-preserver-spaces="true">this link</span></a><span data-preserver-spaces="true">&nbsp;to download the .</span><em><span data-preserver-spaces="true">whl</span></em><span data-preserver-spaces="true">&nbsp;files for TensorFlow and it‚Äôs dependencies. This is only for macOS 11.0 and above, so keep that in mind.</span></p>
<p><span data-preserver-spaces="true">The test you‚Äôll see aren‚Äôt ‚Äúscientific‚Äù in any way, shape or form. They only compare the average training time per epoch.</span></p>
<h2 id="cpu"><span data-preserver-spaces="true">CPU and GPU benchmark</span></h2>
<p><span data-preserver-spaces="true">Let‚Äôs start with the basic CPU and GPU benchmarks first. The comparison is made between the new MacBook Pro with the M1 chip and the base model (Intel) from 2019.&nbsp;</span><a href="https://www.geekbench.com/" target="_blank" rel="noopener noreferrer"><span data-preserver-spaces="true">Geekbench 5</span></a><span data-preserver-spaces="true">&nbsp;was used for the tests, and you can see the results below:</span></p>
<div id="attachment_3868"><p><img aria-describedby="caption-attachment-3868" loading="lazy" src="https://www.betterdatascience.com/wp-content/uploads/2021/01/1-7.png" alt="Image 1 - Geekbench 5 results (Intel MBP vs. M1 MBP) (image by author)" width="1514" height="324" srcset="https://www.betterdatascience.com/wp-content/uploads/2021/01/1-7.png 1514w, https://www.betterdatascience.com/wp-content/uploads/2021/01/1-7-768x164.png 768w" sizes="(max-width: 1514px) 100vw, 1514px"></p><p id="caption-attachment-3868">Image 1 ‚Äì Geekbench 5 results (Intel MBP vs. M1 MBP) (image by author)</p></div>
<p><span data-preserver-spaces="true">The results speak for themselves. M1 chip demolished Intel chip in my 2019 Mac. So far, things look promising.</span></p>
<h2 id="test"><span data-preserver-spaces="true">Performance test ‚Äì MNIST</span></h2>
<p><span data-preserver-spaces="true">The MNIST dataset is something like a ‚Äúhello world‚Äù of deep learning. It comes built-in with TensorFlow, making it that much easier to test.&nbsp;</span></p>
<p><span data-preserver-spaces="true">The following script trains a neural network classifier for ten epochs on the MNIST dataset. If you‚Äôre on an M1 Mac, uncomment the <code>mlcompute</code> lines, as these will make things run a bit faster:</span></p>

<p><span data-preserver-spaces="true">The above script was executed on an M1 MBP and Google Colab (both CPU and GPU). You can see the runtime comparisons below:</span></p>
<div id="attachment_3869"><p><img aria-describedby="caption-attachment-3869" loading="lazy" src="https://www.betterdatascience.com/wp-content/uploads/2021/01/2-6.png" alt="Image 2 - MNIST model average training times (image by author)" width="2146" height="926" srcset="https://www.betterdatascience.com/wp-content/uploads/2021/01/2-6.png 2146w, https://www.betterdatascience.com/wp-content/uploads/2021/01/2-6-768x331.png 768w, https://www.betterdatascience.com/wp-content/uploads/2021/01/2-6-1536x663.png 1536w, https://www.betterdatascience.com/wp-content/uploads/2021/01/2-6-2048x884.png 2048w, https://www.betterdatascience.com/wp-content/uploads/2021/01/2-6-20x10.png 20w" sizes="(max-width: 2146px) 100vw, 2146px"></p><p id="caption-attachment-3869">Image 2 ‚Äì MNIST model average training times (image by author)</p></div>
<p><span data-preserver-spaces="true">The results are somewhat disappointing for a new Mac. Colab outperformed it in both CPU and GPU runtimes. Keep in mind that results may vary, as there‚Äôs no guarantee of the runtime environment in Colab.</span></p>
<h2 id="fashion"><span data-preserver-spaces="true">Performance test ‚Äì Fashion MNIST</span></h2>
<p><span data-preserver-spaces="true">This dataset is quite similar to the regular MNIST, but is contains pieces of clothing instead of handwritten digits. Because of that, you can use the identical neural network architecture for the training:</span></p>
<!-- WP QUADS Content Ad Plugin v. 2.0.19 -->



<p><span data-preserver-spaces="true">As you can see, the only thing that‚Äôs changed here is the function used to load the dataset. The runtime results for the same environments are shown below:</span></p>
<div id="attachment_3870"><p><img aria-describedby="caption-attachment-3870" loading="lazy" src="https://www.betterdatascience.com/wp-content/uploads/2021/01/3-5.png" alt="Image 3 - Fashion MNIST model average training times (image by author)" width="2146" height="926" srcset="https://www.betterdatascience.com/wp-content/uploads/2021/01/3-5.png 2146w, https://www.betterdatascience.com/wp-content/uploads/2021/01/3-5-768x331.png 768w, https://www.betterdatascience.com/wp-content/uploads/2021/01/3-5-1536x663.png 1536w, https://www.betterdatascience.com/wp-content/uploads/2021/01/3-5-2048x884.png 2048w, https://www.betterdatascience.com/wp-content/uploads/2021/01/3-5-20x10.png 20w" sizes="(max-width: 2146px) 100vw, 2146px"></p><p id="caption-attachment-3870">Image 3 ‚Äì Fashion MNIST model average training times (image by author)</p></div>
<p><span data-preserver-spaces="true">Once again, we get similar results. It‚Äôs expected, as this dataset is quite similar to MNIST.&nbsp;</span></p>
<p><span data-preserver-spaces="true">But what will happen if we introduce a more complex dataset and neural network architecture?&nbsp;</span></p>
<h2 id="cifar"><span data-preserver-spaces="true">Performance test ‚Äì CIFAR-10</span></h2>
<p><span data-preserver-spaces="true">CIFAR-10 also falls into the category of ‚Äúhello world‚Äù deep learning datasets. It contains 60K images from ten different categories, such as airplanes, birds, cats, dogs, ships, trucks, etc.</span></p>
<p><span data-preserver-spaces="true">The images are of size 32x32x3, which makes them difficult to classify even for humans in some cases. The script below trains a classifier model by using three convolutional layers:</span></p>

<p><span data-preserver-spaces="true">Let‚Äôs see how convolutional layers and more complex architecture affects the runtime:</span></p>
<div id="attachment_3871"><p><img aria-describedby="caption-attachment-3871" loading="lazy" src="https://www.betterdatascience.com/wp-content/uploads/2021/01/4-5.png" alt="Image 4 - CIFAR-10 model average training times (image by author)" width="2146" height="926" srcset="https://www.betterdatascience.com/wp-content/uploads/2021/01/4-5.png 2146w, https://www.betterdatascience.com/wp-content/uploads/2021/01/4-5-768x331.png 768w, https://www.betterdatascience.com/wp-content/uploads/2021/01/4-5-1536x663.png 1536w, https://www.betterdatascience.com/wp-content/uploads/2021/01/4-5-2048x884.png 2048w, https://www.betterdatascience.com/wp-content/uploads/2021/01/4-5-20x10.png 20w" sizes="(max-width: 2146px) 100vw, 2146px"></p><p id="caption-attachment-3871">Image 4 ‚Äì CIFAR-10 model average training times (image by author)</p></div>
<p><span data-preserver-spaces="true">As you can see, the CPU environment in Colab comes nowhere close to the GPU and M1 environments. The Colab GPU environment is still around 2x faster than Apple‚Äôs M1, similar to the previous two tests.</span></p>
<h2 id="conclusion"><span data-preserver-spaces="true">Conclusion</span></h2>
<p><span data-preserver-spaces="true">I love every bit of the new M1 chip and everything that comes with it ‚Äì better performance, no overheating, and better battery life. Still, it‚Äôs a difficult laptop to recommend if you‚Äôre into deep learning.</span></p>
<p><span data-preserver-spaces="true">Sure, there‚Äôs around 2x improvement in M1 than my other Intel-based Mac, but these still aren‚Äôt machines made for deep learning. Don‚Äôt get me wrong, you can use the MBP for any basic deep learning tasks, but there are better machines in the same price range if you‚Äôll do deep learning daily.</span></p>
<p><span data-preserver-spaces="true">This article covered deep learning only on simple datasets. The next one will compare the M1 chip with Colab on more demanding tasks ‚Äì such as transfer learning.&nbsp;</span></p>
<p><span data-preserver-spaces="true">Thanks for reading.</span></p>
<p><a href="https://www.linkedin.com/in/darioradecic/" target="_blank" rel="noopener noreferrer"><span data-preserver-spaces="true">Connect on LinkedIn.</span></a></p>
<h4><a href="https://mailchi.mp/46a3d2989d9b/bdssubscribe" target="_blank" rel="noopener noreferrer"><span data-preserver-spaces="true">Join my private email list for more helpful insights.</span></a></h4>
<h2><span data-preserver-spaces="true">Learn more&nbsp;</span></h2>
<ul>
<li><a href="https://towardsdatascience.com/top-5-books-to-learn-data-science-in-2020-f43153851f14" target="_blank" rel="noopener noreferrer"><span data-preserver-spaces="true">Top 5 Books to Learn Data Science in 2021</span></a></li>
<li><a href="https://www.betterdatascience.com/mac-m1-python/" target="_blank" rel="noopener noreferrer"><span data-preserver-spaces="true">Are The New M1 Macbooks Any Good for Data Science? Let‚Äôs Find Out</span></a></li>
<li><a href="https://www.betterdatascience.com/python-pdf-reports/" target="_blank" rel="noopener noreferrer"><span data-preserver-spaces="true">How to Create PDF Reports with Python ‚Äì The Essential Guide</span></a></li>
<li><a href="https://www.betterdatascience.com/python-multiprocessing/" target="_blank" rel="noopener noreferrer"><span data-preserver-spaces="true">Python Parallelism: Essential Guide to Speeding up Your Python Code in Minutes</span></a></li>
<li><a href="https://towardsdatascience.com/shap-how-to-interpret-machine-learning-models-with-python-2323f5af4be9" target="_blank" rel="noopener noreferrer"><span data-preserver-spaces="true">SHAP: How to Interpret Machine Learning Models With Python</span></a></li>
</ul>


<!-- WP QUADS Content Ad Plugin v. 2.0.19 -->


            					</div></div>]]>
            </description>
            <link>https://www.betterdatascience.com/m1-deep-learning/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26148333</guid>
            <pubDate>Mon, 15 Feb 2021 22:23:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[It's going to cost four figures]]>
            </title>
            <description>
<![CDATA[
Score 30 | Comments 2 (<a href="https://news.ycombinator.com/item?id=26148076">thread link</a>) | @cyb_
<br/>
February 15, 2021 | https://raccoon.onyxbits.de/blog/software-development-cost/ | <a href="https://web.archive.org/web/*/https://raccoon.onyxbits.de/blog/software-development-cost/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>
      Let's talk about pricing commissioned work on existing open source projects. Or: things I learned from my past mistakes.
    </p><div>

<p>A followup to <a href="https://raccoon.onyxbits.de/blog/bugreport-free-support/">No, ‚ÄúOpen Source‚Äù does not mean ‚ÄúIncludes Free Support‚Äù</a>. Buckle up, this is going to be a long one.</p>

<p>Here‚Äôs a situation, maintainers of open source projects might find familiar: an email arrives. The sender introduces himself as the representative of a business and would like to ask, if it is possible to adopt (part of) the project to his (very) specific use case. A custom fork, exposing the desired functionality via a commandline switch would suffice. Shouldn‚Äôt be too much trouble, right?</p>

<p>Right! It isn‚Äôt. Couple of hours tops to write the code. But under <strong>no</strong> circumstances do I want to have it in the project‚Äôs main development branch. Besides, I‚Äôm not really going to spend an afternoon, so someone else can cash in on it, am I? This is clearly a commission. I‚Äôm going to charge for it. The question is just how much‚Ä¶
</p><figure>
  <a href="https://raccoon.onyxbits.de/blog/software-development-cost/wtf.svg">
    <img src="https://raccoon.onyxbits.de/blog/software-development-cost/wtf.svg">
  </a>
  
  <figcaption>WTF?! Four figures for a patch of maybe 100 lines of code? How do you even justify that?!</figcaption>
  
</figure>
                             
                             

<p>In the past, I would have spend an hour or so (spoiler alert: that was already a mistake), roughly sketching out in my head, what needs to be done, estimated how long it would take, multiplied that by an <del>arbitrary</del> industry standard hourly rate, tried to somehow justify the number to myself (second mistake), then send a quote, just to receive one of three replies:</p>

<ul>
<li>That‚Äôs too expensive! Forget, I asked.</li>
<li>That‚Äôs too expensive! Can you make it cheaper?</li>
<li>That cheap <small>(would have expected at least double)</small>
?</li>
</ul>

<p>Great! So, I either wasted an hour preparing for a commission that‚Äôs never going to happen, be forced  to waste even more hours on negotiating getting paid less for them, or flat out sold myself short. Welcome to the business world, dumbass!</p>

<p>
  
  <span>An error in reasoning</span>
  
  
Charging an hourly rate for a service is a convenient method for writing offers and bills (easy to digest and therefore more likely to be accepted without hassle), making it the obvious choice. But the real value of a service isn't always expressible as the product of hours √ó rate. At least not without inflating the factors unrealistically.

</p>
                             
                             

<p>Lesson learned. Nowadays, I just skip the whole cost forecast thing and send a simple response right away: <em>‚ÄúCan do. Will cost about four figures. When do you need it?‚Äù</em> Sounds brazen? Maybe. But, by my experience, everything else is going to end in tears. Let‚Äôs break down that line of thought.</p>

<h2 id="what-s-the-value-of-my-time">What‚Äôs the value of my time?</h2>

<p>A common misconception about open source software is that it is developed by hobbyists in their spare time. With a day job to pay for the bills, free time does not have opportunity cost, so it can be bought/must be sold for cheap. That, at least, is what the market theory tells us, but that‚Äôs not exactly true, is it? In fact, it is utterly wrong. The opportunity cost of <em>spare time</em> is <em>enjoying life</em>. I, as everyone else, only have one lifetime to spend and I intent to use as much as possible of that, pursuing my own happiness. Work is just a means to that end.</p>

<p>So, if I‚Äôm freelancing, which part of my life am I selling? The office hours or my leisure time? In first case, I‚Äôm running a business. My price calculation therefore has to cover my cost of living and turn a profit as well. In the second case, the former becomes <strong>my baseline</strong>, as my bills are already paid and I therefore need a pretty good incentive to turn even more of my lifetime into working hours. Either way, nothing about the involvement in open source software compels me to provide cheap labor.
</p><p>
  
  <span>Bottom line</span>
  
  
I'm neither a burger flipper, nor do I work at cost. For me, this is a business, not a charity. So yes, my bill includes profit. If it doesn't pay, I'm not interested in doing it.

</p>
                             
                             

<p>That being said, I do not charge by the hour for software development. <strong>Period</strong>. Hourly billing only works when the required time is easy to pre-estimate, track and review by all involved parties, e.g. when consulting on the phone. But it is the completely wrong model for doing any kind of software development. Here, other considerations come into play that go way beyond the ‚Äúmere‚Äù 100 lines of code, I may eventually end up writing. Hence, my four figures ‚Äúquote‚Äù has nothing to do, whatsoever, with the actual time that goes into <em>typing</em> them.</p>

<h2 id="i-m-an-engineer-not-a-psychic">I‚Äôm an engineer, not a psychic</h2>

<p>I have been doing this for a while now and I never ever came across a single client, who even remotely understood what exactly he wanted (even when having a technical background). Sure, they all had a rough idea of the problem they wanted solved, but the steps to getting there were a total mystery.</p>

<p>
  
  <span>Premise</span>
  
  
The client is <a href="https://dictionary.cambridge.org/dictionary/english/incompetent">incompetent</a>. Always! That's important to note and to <u>prepare for</u>. If he had the necessary expertise for the job, he'd just do it himself, not hire me.

</p>
                             
                             

<p>My work always starts with figuring out the interface(s) between my code (to be) and the client‚Äôs system, as well as explaining to him what can and can‚Äôt be done. That process typically takes days of written correspondence. All of it is scaffolding. None of it will show in the final product, but it is preliminary work that must be done before any of the actual work can happen.
</p><p>
  
  <span>Beware of shortcuts</span>
  
  
Discussing a project on the phone is faster, but you quickly get bogged down in details and with no written record of what has been said, requested and promised, either party is going to forget half of those details. That's a lawsuit in the making.

</p>
                             
                             

<p>When a client contacts me for the first time, I have no idea of his prior knowledge and therefore no way of telling how much scaffolding will be needed. Experience taught me, though, to never ever make any estimates based on the initial mail. No matter how crystal clear and straight forward it may seem. </p><figure>
  <a href="https://raccoon.onyxbits.de/blog/software-development-cost/sorry.svg">
    <img src="https://raccoon.onyxbits.de/blog/software-development-cost/sorry.svg">
  </a>
  
  <figcaption>Oh, I forgot to mention that. It's not going to be a problem, is it?</figcaption>
  
</figure><p>
                             
                              The premise is that the client doesn‚Äôt know what he is doing. So, he is going to flip flop around. He will come up with last minute ‚Äúminor‚Äù change requests. He will ask an unexpected comprehension question, undoing everything after it was already tied up. In other words: clients tend to unwittingly turn laid out plans into piles of smoldering ashes in an instant, while being totally oblivious to the fact that this drives cost on my end.</p>

<p>Under such circumstances, charging <strong>by the hour</strong> for software development <strong>is futile</strong>. When freelancing, my price calculation always contains an error margin, large enough to cover for doing the preliminary work at least twice over. This is non-negotiable and it is also non-refundable.</p>

<h2 id="it-s-more-than-just-writing-code-and-the-job-s-not-done-when-delivering-the-executable">It‚Äôs more than just writing code and the job‚Äôs not done when delivering the executable</h2>

<p>Writing and compiling the code is the least time consuming part of the deal. It‚Äôs what comes afterwards where the hours are burned:</p>

<ul>
<li>The client will probably want instructions on how to use his fork. That means writing documentation and/or walking him through. Usually, both. The later can turn into a nasty surprise in case I overestimated his technical skills.</li>
<li>Just because the mod works on my PC doesn‚Äôt mean it will work in the client‚Äôs system. More likely than not, there will be a remote debugging session (potentially with a client, whose technical skills I overestimated).</li>
<li>The main development branch will move on. The client may want/need the new version with his custom patch applied eventually. This means, I now have two code branches to maintain and should probably also write some extra unit tests to detect breaking changes.</li>
<li>After completion (and payment), there will likely be ‚Äúminor‚Äù follow up questions. Things, that can be answered in one sentence. Individually, they take up almost no time at all, but they will pile up and are impossible to consolidate into billable units.</li>
</ul>

<p>Again, counting hours is pointless. How long the job takes is largely determined by the client‚Äôs actions, not by mine. That‚Äôs a big variable beyond my control. The client can (<u>and will</u>!) drag this out, putting me into an impossible situation: I‚Äôm suppose to give a quote in order to get the commission, based on information, I can only have after finishing. But at that point, it‚Äôs too late to change the estimate and simply charging extra after giving a quote is obviously not going to fly.</p>

<figure>
  <a href="https://raccoon.onyxbits.de/blog/software-development-cost/time.svg">
    <img src="https://raccoon.onyxbits.de/blog/software-development-cost/time.svg">
  </a>
  
  <figcaption>A time based estimate is impossible when the known quantity gets swallowed by an unknown one.</figcaption>
  
</figure>
                             
                             

<p>Now, some people might wonder, why I don‚Äôt just write a detailed offer/bill then. Listing all the individual positions, so the client knows exactly what he‚Äôs paying for and why it‚Äôs costing so much. Am I too lazy? Yes, I am! I am mostly too lazy to argue about why every item is required, having to take it out because it isn‚Äôt, having to add it again because it was and in the end renegotiate everything because safety margins were not used to their fullest extent.</p>

<p>Everything that‚Äôs on an offer/bill is contestable. Haggling costs additional time and can‚Äôt end in my favour, no matter what. I learned the hard way to not put that option on the table.</p>

<h2 id="aren-t-we-forgetting-something">Aren‚Äôt we forgetting something?</h2>

<p>The basis for the commission is still an open source project. Yes, it is free to use, but it is not free to maintain and by creating it, I made an investment, indebting myself to myself. Now, why should some people have to pay, while other‚Äôs don‚Äôt? I could make an elaborate argument here about it being a mixed calculation and not being required to offer everyone the same deal, but I got a much simpler and more compelling ‚Ä¶</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://raccoon.onyxbits.de/blog/software-development-cost/">https://raccoon.onyxbits.de/blog/software-development-cost/</a></em></p>]]>
            </description>
            <link>https://raccoon.onyxbits.de/blog/software-development-cost/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26148076</guid>
            <pubDate>Mon, 15 Feb 2021 22:01:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Building Rich Terminal Dashboards]]>
            </title>
            <description>
<![CDATA[
Score 21 | Comments 0 (<a href="https://news.ycombinator.com/item?id=26147831">thread link</a>) | @willm
<br/>
February 15, 2021 | https://www.willmcgugan.com/blog/tech/post/building-rich-terminal-dashboards/ | <a href="https://web.archive.org/web/*/https://www.willmcgugan.com/blog/tech/post/building-rich-terminal-dashboards/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
    

    
<p><a href="https://github.com/willmcgugan/rich">Rich</a> has become a popular (20K stars on GH) way of beautifying CLIs, and I'm pleased to see a number of projects using it.</p>
<p>Since Rich is mature and battle-tested now, I had considered winding-down development. Until, I saw this tweet:</p>
<h2>The Tweet</h2>
<blockquote><div lang="en" dir="ltr"><p>Do you want to see something really cool you can do with <a href="https://twitter.com/willmcgugan?ref_src=twsrc%5Etfw">@willmcgugan</a> 's rich library? </p><p>Checkout ghtop <a href="https://t.co/mn7oLbpw8e">https://t.co/mn7oLbpw8e</a>. It's a really fun CLI tool that demonstrates the power of rich (and other things).</p><p>Examples below üßµüëá (1/8)</p></div>‚Äî Hamel Husain (@HamelHusain) <a href="https://twitter.com/HamelHusain/status/1357771218095546368?ref_src=twsrc%5Etfw">February 5, 2021</a></blockquote> 
<p><a href="https://twitter.com/HamelHusain">@HamelHusain</a> and <a href="https://twitter.com/jeremyphoward">@jeremyphoward</a> used Rich to enhance <a href="https://github.com/nat/ghtop">ghtop</a> (a repo owned by the CEO of Github, no less). Ghtop shows a realtime a stream of events from the Github platform. And it looks good! So good that I realised how much potential Rich has for these type of htop-like applications.</p>
<p>Hamel and Jeremy had to overcome a few technical hurdles to make that work. Fortunately this will no longer be required as the latest version of Rich has first-class support for full-screen interfaces via a new Layout system.</p>
<h2>Full-screen terminal interface</h2>
<p>Here's a video demonstration of a terminal interface built with Layout:</p>
<p>
<iframe width="auto" src="https://www.youtube.com/embed/slrdSojCvlk" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
</p>
<h2>Layout API</h2>
<p>The API to create a flexible layout is surprisingly simple. You construct a <code>Layout()</code> object, then call <code>split()</code> to create sub-layouts. These sub-layouts may then be further divided. Layouts have a small number of settings which define their size relative to the terminal window. It's a simple system that can create terminal interfaces that almost resemble modern web apps.</p>
<div><figure> <img width="1140" height="724" title="layout_vscode.png" name="layout_vscode" data-md="https://media.moyaproject.com/willmcgugan/uploads/thumbnails/techblog/a7ab7ab6-6fb0-11eb-bc8d-f23c91845b44.png/a7ab7ab6-6fb0-11eb-bc8d-f23c91845b44png.md.3.jpeg" data-square="https://media.moyaproject.com/willmcgugan/uploads/thumbnails/techblog/a7ab7ab6-6fb0-11eb-bc8d-f23c91845b44.png/a7ab7ab6-6fb0-11eb-bc8d-f23c91845b44png.square.7.jpeg" data-xlg2x="https://media.moyaproject.com/willmcgugan/uploads/thumbnails/techblog/a7ab7ab6-6fb0-11eb-bc8d-f23c91845b44.png/a7ab7ab6-6fb0-11eb-bc8d-f23c91845b44png.xlg2x.2.jpeg" data-lg="https://media.moyaproject.com/willmcgugan/uploads/thumbnails/techblog/a7ab7ab6-6fb0-11eb-bc8d-f23c91845b44.png/a7ab7ab6-6fb0-11eb-bc8d-f23c91845b44png.lg.3.jpeg" data-xlg="https://media.moyaproject.com/willmcgugan/uploads/thumbnails/techblog/a7ab7ab6-6fb0-11eb-bc8d-f23c91845b44.png/a7ab7ab6-6fb0-11eb-bc8d-f23c91845b44png.xlg.8.jpeg" data-author="¬© 2021 Will McGugan<br>all rights reserved" data-og_preview="https://media.moyaproject.com/willmcgugan/uploads/thumbnails/techblog/a7ab7ab6-6fb0-11eb-bc8d-f23c91845b44.png/a7ab7ab6-6fb0-11eb-bc8d-f23c91845b44png.og.preview.2.jpeg" data-height="2100" data-width="3308" data-toggle="tooltip" data-details=" " data-sm="https://media.moyaproject.com/willmcgugan/uploads/thumbnails/techblog/a7ab7ab6-6fb0-11eb-bc8d-f23c91845b44.png/a7ab7ab6-6fb0-11eb-bc8d-f23c91845b44png.sm.3.jpeg" data-blur="https://media.moyaproject.com/willmcgugan/uploads/thumbnails/techblog/a7ab7ab6-6fb0-11eb-bc8d-f23c91845b44.png/a7ab7ab6-6fb0-11eb-bc8d-f23c91845b44png.blur.6.jpeg" data-slug="layout_vscode" sizes="(min-width: 1200px) 1170px, (min-width: 992px) 970px, (min-width: 768px) 750px" srcset="https://media.moyaproject.com/willmcgugan/uploads/thumbnails/techblog/a7ab7ab6-6fb0-11eb-bc8d-f23c91845b44.png/a7ab7ab6-6fb0-11eb-bc8d-f23c91845b44png.lg.3.jpeg 1170w, https://media.moyaproject.com/willmcgugan/uploads/thumbnails/techblog/a7ab7ab6-6fb0-11eb-bc8d-f23c91845b44.png/a7ab7ab6-6fb0-11eb-bc8d-f23c91845b44png.md.3.jpeg 970w, https://media.moyaproject.com/willmcgugan/uploads/thumbnails/techblog/a7ab7ab6-6fb0-11eb-bc8d-f23c91845b44.png/a7ab7ab6-6fb0-11eb-bc8d-f23c91845b44png.sm.3.jpeg 750w" src="https://media.moyaproject.com/willmcgugan/uploads/thumbnails/techblog/a7ab7ab6-6fb0-11eb-bc8d-f23c91845b44.png/a7ab7ab6-6fb0-11eb-bc8d-f23c91845b44png.lg.3.jpeg"> 
<figcaption>
<p>¬© 2021 Will McGugan</p>


<p>A Rich layout in VSCode</p>


</figcaption>

</figure>
</div>
<h2>Finally, some code</h2>
<p>Here's how you would create a basic layout with a header, a footer, and two side-panels.</p>
<pre><code>from rich.console import Console
from rich.layout import Layout

console = Console()
layout = Layout()

# Divide the "screen" in to three parts
layout.split(
    Layout(name="header", size=3),
    Layout(ratio=1, name="main"),
    Layout(size=10, name="footer"),
)
# Divide the "main" layout in to "side" and "body"
layout["main"].split(
    Layout(name="side"),
    Layout(name="body", ratio=2),
    direction="horizontal"
)
# Divide the "side" layout in to two
layout["side"].split(Layout(), Layout())

console.print(layout)
</code></pre>
<p>Running the code above produces the following output:</p>
<div><figure> <img width="1140" height="739" title="layout.png" name="layout" data-md="https://media.moyaproject.com/willmcgugan/uploads/thumbnails/techblog/98f8e5f8-6fab-11eb-bc8d-f23c91845b44.png/98f8e5f8-6fab-11eb-bc8d-f23c91845b44png.md.3.jpeg" data-square="https://media.moyaproject.com/willmcgugan/uploads/thumbnails/techblog/98f8e5f8-6fab-11eb-bc8d-f23c91845b44.png/98f8e5f8-6fab-11eb-bc8d-f23c91845b44png.square.7.jpeg" data-xlg2x="https://media.moyaproject.com/willmcgugan/uploads/thumbnails/techblog/98f8e5f8-6fab-11eb-bc8d-f23c91845b44.png/98f8e5f8-6fab-11eb-bc8d-f23c91845b44png.xlg2x.2.jpeg" data-lg="https://media.moyaproject.com/willmcgugan/uploads/thumbnails/techblog/98f8e5f8-6fab-11eb-bc8d-f23c91845b44.png/98f8e5f8-6fab-11eb-bc8d-f23c91845b44png.lg.3.jpeg" data-xlg="https://media.moyaproject.com/willmcgugan/uploads/thumbnails/techblog/98f8e5f8-6fab-11eb-bc8d-f23c91845b44.png/98f8e5f8-6fab-11eb-bc8d-f23c91845b44png.xlg.8.jpeg" data-author="¬© 2021 Will McGugan<br>all rights reserved" data-og_preview="https://media.moyaproject.com/willmcgugan/uploads/thumbnails/techblog/98f8e5f8-6fab-11eb-bc8d-f23c91845b44.png/98f8e5f8-6fab-11eb-bc8d-f23c91845b44png.og.preview.2.jpeg" data-height="1464" data-width="2258" data-toggle="tooltip" data-details=" " data-sm="https://media.moyaproject.com/willmcgugan/uploads/thumbnails/techblog/98f8e5f8-6fab-11eb-bc8d-f23c91845b44.png/98f8e5f8-6fab-11eb-bc8d-f23c91845b44png.sm.3.jpeg" data-blur="https://media.moyaproject.com/willmcgugan/uploads/thumbnails/techblog/98f8e5f8-6fab-11eb-bc8d-f23c91845b44.png/98f8e5f8-6fab-11eb-bc8d-f23c91845b44png.blur.6.jpeg" data-slug="layout" sizes="(min-width: 1200px) 1170px, (min-width: 992px) 970px, (min-width: 768px) 750px" srcset="https://media.moyaproject.com/willmcgugan/uploads/thumbnails/techblog/98f8e5f8-6fab-11eb-bc8d-f23c91845b44.png/98f8e5f8-6fab-11eb-bc8d-f23c91845b44png.lg.3.jpeg 1170w, https://media.moyaproject.com/willmcgugan/uploads/thumbnails/techblog/98f8e5f8-6fab-11eb-bc8d-f23c91845b44.png/98f8e5f8-6fab-11eb-bc8d-f23c91845b44png.md.3.jpeg 970w, https://media.moyaproject.com/willmcgugan/uploads/thumbnails/techblog/98f8e5f8-6fab-11eb-bc8d-f23c91845b44.png/98f8e5f8-6fab-11eb-bc8d-f23c91845b44png.sm.3.jpeg 750w" src="https://media.moyaproject.com/willmcgugan/uploads/thumbnails/techblog/98f8e5f8-6fab-11eb-bc8d-f23c91845b44.png/98f8e5f8-6fab-11eb-bc8d-f23c91845b44png.lg.3.jpeg"> 
<figcaption>
<p>¬© 2021 Will McGugan</p>


<p>Terminal split in to 5 sub-layouts. The boxes are placeholders, you can insert any content in their place.</p>


</figcaption>

</figure>
</div>
<p>Any renderable (text, table, progress bars etc) may be placed inside those sub-layouts.</p>
<p>We can now use the <a href="https://rich.readthedocs.io/en/latest/live.html">Live</a> class to create an application that adapts itself to the terminal window:</p>
<pre><code>from rich.live import Live
from time import sleep

with Live(layout, screen=True):
    while True:
        sleep(1)
</code></pre>
<p>In a real app, that do-nothing loop will be doing something useful like pulling data from the network to update contents.</p>
<p>See the <a href="https://rich.readthedocs.io/en/latest/layout.html">layout docs</a> for an in-depth tutorial.</p>
<h2>What's next?</h2>
<p>I think it's clear that Rich is acquiring more TUI (text user interface) features, and I've decided not to fight it. Rich's core purpose is still to beautify CLI output, but I think there is an opportunity here for a new way to create terminal apps. Ultimately it will be less like curses and more like HTML in a browser.</p>
<p>There are a number of things to do before Rich could replace a full TUI library (keyboard and mouse input for one) but the potential is there. Stay tuned for progress.</p>
<p>Follow <a href="https://twitter.com/willmcgugan">@willmcgugan</a> for more Rich related news.</p>



</article></div>]]>
            </description>
            <link>https://www.willmcgugan.com/blog/tech/post/building-rich-terminal-dashboards/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26147831</guid>
            <pubDate>Mon, 15 Feb 2021 21:41:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Fastcheck: Property based testing for JavaScript and TypeScript]]>
            </title>
            <description>
<![CDATA[
Score 42 | Comments 6 (<a href="https://news.ycombinator.com/item?id=26147011">thread link</a>) | @alokrai
<br/>
February 15, 2021 | https://dubzzz.github.io/fast-check.github.com/ | <a href="https://web.archive.org/web/*/https://dubzzz.github.io/fast-check.github.com/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="page-wrapper">
			
			
			<section>
				<div>
					<p>
							Property based testing is <strong>another way to test</strong> programs.
							Instead of relying on hard-coded inputs and outputs, it <strong>checks characteristics of the output</strong> given the whole range of possible inputs.
						</p>
				</div>
			</section>
			<section>
				<div>
					<div>
						<section>
							<div>
								<h3>Coverage <a href="#coverage">more &gt;</a></h3>
								<p>
									By nature, property based testing puts less constraints on the inputs.
									As a consequence, the scope of covered inputs is much higher and can lead to unexplored code paths
								</p>
							</div>
						</section>
						<section>
							<div>
								<h3>Reproducible <a href="#reproducible">more &gt;</a></h3>
								<p>
									Runs are seeded and fully reproducible
								</p>
							</div>
						</section>
						<section>
							<div>
								<h3>Shrink <a href="#shrink">more &gt;</a></h3>
								<p>
									In case of failure, the framework is responsible to come with a minimal failing case easy to troubleshoot
								</p>
							</div>
						</section>
					</div>
				</div>
			</section>
			<section>
				
				<div>
					<header>
						<h2>Getting started</h2>
						<p>Property based testing frameworks check the truthfulness of properties</p>
					</header>
				</div>
			</section>
			<section>
				<div>
					<div>
						<p>Add <em>fast-check</em> to your project:</p>
						<pre><code>npm install --save-dev fast-check</code></pre>
						<p>Example of integration with <em>Jest</em> or <em>Mocha</em>:</p>
						<pre><code>import * as fc from 'fast-check';

const sort = arr =&gt; arr.slice(0).sort((a,b) =&gt; a-b);

test('should order elements from the smallest to the highest', () =&gt; fc.assert(
	fc.property(
		fc.array(fc.integer()),
		arr =&gt; {
			const sortedArr = sort(arr);
			for (let idx = 1 ; idx &lt; sortedArr.length ; ++idx)
				if (sortedArr[idx - 1] &lt;= sortedArr[idx])
					return false;
			return true;
		}
	)
));</code></pre>
						<p>In a nutshell:</p>
						<ul>
							<li><em>fc.assert</em> runs the property</li>
							<li><em>fc.property</em> defines the property</li>
							<li><em>fc.array(fc.integer())</em> defines the inputs the framework has to generate</li>
							<li><em>arr =&gt; { ... }</em> checks the output against the generated value</li>
						</ul>
						
					</div>
				</div>
			</section>
			<section>
				
				<div>
					<header>
						<h2>Coverage</h2>
						<p>Discover uncovered code paths</p>
					</header>
				</div>
			</section>
			<section>
				<div>
					<div>
						<p>Let's consider a simple <em>serialize</em> function, offering its users the ability to set custom settings to tweak the resulting string</p>
						<pre><code>function serialize&lt;T&gt;(instance: T, params: Parameters): string { /* code */ }</code></pre>
						<p>
							In the scenario above, an exhaustive test would have to run throughout all the possible combinations of <em>params</em> with many possible <em>instance</em>.
							An alternative to such example-based tests would be to rely on properties.
							It would offer an exhautive coverage of the possible inputs.
							Given we also have a <em>deserialize</em> function we would simply write:
						</p>
						<pre><code>test('should be able to read itself', () =&gt; fc.assert(
	fc.property(
		fc.jsonObject(),
		fc.record({
			crlf: fc.boolean(),
			indent: fc.boolean(),
			sortKeys: fc.boolean()
		}, { withDeletedKeys: true }),
		(instance, params) =&gt; {
			expect(deserialize(serialize(instance, params))).toEqual(instance);
		}
	)
));</code></pre>
						<p>
							Such property was able to detect bugs in both <em>js-yaml</em> and <em>query-string</em>
						</p>
						
					</div>
				</div>
			</section>
			<section>
				
				<div>
					<header>
						<h2>Reproducible</h2>
						<p>Replay the same test after a fix</p>
					</header>
				</div>
			</section>
			<section>
				<div>
					<div>
						<p>Whenever <em>fast-check</em> detects a problem, it will print an error message containing the settings required to replay the very same test</p>
						<pre><code>Error: Property failed after 1 tests (seed: 1527423434693, path: "0:0:0"): ["","",""]
Shrunk 2 time(s)
Got error: Property failed by returning false</code></pre>
						<p>
							Given this message the test can easily be replayed by using:
						</p>
						<pre><code>test('the failing test', () =&gt; fc.assert(
	fc.property(
		// some arbitraries... 
		// check method
	), { // seed and path taken from the error message
		seed: 1527423434693,
		path: "0:0:0"
	}
));</code></pre>
						<p>
							Setting both <em>seed</em> and <em>path</em> will replay the test starting with the latest failing case.
							If you want to replay the whole test suite, you should only set the <em>seed</em>
						</p>
						
					</div>
				</div>
			</section>
			<section>
				
				<div>
					<header>
						<h2>Shrink</h2>
						<p>Get a better understanding of the errors</p>
					</header>
				</div>
			</section>
			<section>
				<div>
					<div>
						<p>
							Whenever a test fails, <em>fast-check</em> will try to ease your investigations by providing you with the minimal failing case.
							Sometimes it is not enough and having all the failures might help.
							For this precise need, <em>fc.assert</em> accepts an optional configuration: <em>verbose: true</em>. 
						</p>
						<pre><code>test('the failing test', () =&gt; fc.assert(
	fc.property(
		// some arbitraries... 
		// check method
	), { verbose: true }
));</code></pre>
						<p>
							With this setting enabled the error message will look like:
						</p>
						<pre><code>Error: Property failed after 1 tests (seed: 1527423434693, path: 0:0:0): ["","",""]
Shrunk 2 time(s)
Got error: Property failed by returning false

Encountered failures were:
- ["","JeXPqIQ6","&gt;q"]
- ["","","&gt;q"]
- ["","",""]</code></pre>
						
					</div>
				</div>
			</section>
			
			<p><a href="https://github.com/dubzzz/fast-check"><img src="https://s3.amazonaws.com/github/ribbons/forkme_right_red_aa0000.png" alt="Fork me on GitHub"></a>
		</p></div></div>]]>
            </description>
            <link>https://dubzzz.github.io/fast-check.github.com/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26147011</guid>
            <pubDate>Mon, 15 Feb 2021 20:37:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Ramanujan Machine is an intellectual fraud (2019)]]>
            </title>
            <description>
<![CDATA[
Score 39 | Comments 16 (<a href="https://news.ycombinator.com/item?id=26144665">thread link</a>) | @spekcular
<br/>
February 15, 2021 | https://www.galoisrepresentations.com/2019/07/17/the-ramanujan-machine-is-an-intellectual-fraud/ | <a href="https://web.archive.org/web/*/https://www.galoisrepresentations.com/2019/07/17/the-ramanujan-machine-is-an-intellectual-fraud/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="post-4282">
					

					<!-- .entry-meta -->

					<div>
						<p><b>Edit (17/02/21)</b> I changed the title of this post which was unnecessarily incendiary.</p>
<p>There‚Äôs a lot that I like about how mathematics operates as a social discipline. We have a great respect for the history of the subject, which in particular includes acknowledging the work that has come before us. In the end, we ultimately agree that it is the mathematics which does the talking. Each of us has our own tastes (of course) and some of us are more prone to be excited about our own work than others, but we are remarkably free from bullshit (about the actual mathematics, at least). This is what all of science should aspire to.</p>
<p>Perhaps this is why I find the self-promotion surrounding the <a href="https://galoisrepresentations.wordpress.com/2019/07/07/en-passant-v/">Ramanujan Machine</a> so distasteful. (I wasn‚Äôt going to bother wasting any more time on this but here I am, last time I promise.) The idea of trying to automate methods for finding identities is an interesting one. But if want to claim that you have found something <i>new</i>, then some justification is required. For a start, you should at least be expected to do a cursory search of the literature. Perhaps you should even consult an expert? If the authors had been content to be more modest with their claims, merely explaining that automation was their main goal, and that they were merely <i>hopeful</i> to use these ideas to make new discoveries, I would have had no issue at all with their paper. Of course, nobody would have heard about the paper either. I already complained <a href="https://galoisrepresentations.wordpress.com/2019/07/07/en-passant-v/">last time</a> about the overblown rhetoric, but since then, my interactions with one of the authors indicated that the rot lies deeper still.</p>
<p>The author in question seemed happy (while listening to my previous complaints) to indicate that the novelty is not in producing new mathematics but in automatically generating formulas ‚Äúwithout knowing Gauss‚Äô work‚Äù. As I indicated above, that‚Äôs a reasonable and modest claim. But then, the same author will tweet out to the world the false claim that his program has discovered new and amazing mathematical conjectures. (A rather curious set of tweets to <a href="https://twitter.com/elonmusk">@elonmusk</a> <a href="https://twitter.com/yurimilner?lang=en">@yurimilner</a> <a href="https://twitter.com/stephen_wolfram">@stephen_wolfram</a> <a href="https://twitter.com/RHDijkgraaf">@RHDijkgraaf</a>; is the common thread people who have access to money that can be spent on math?)  Don‚Äôt imagine for a minute that this is not a deliberate and conscious decision: the <a href="https://phys.org/news/2019-07-ramanujan-machine-automatically-conjectures-fundamental.html">press</a> <a href="https://www.newscientist.com/article/2209213-computer-attempts-to-replicate-the-dream-like-maths-of-ramanujan/">stories</a> generated about ‚Äúautomating the insight of Ramanujan‚Äù don‚Äôt happen on their own ‚Äî they need the hook of ‚Äúexciting conjectures‚Äù to be ‚Äúnewsworthy‚Äù and this is exactly what has been peddled via a concerted publicity campaign. The best way to describe this entire story is as follows: this is what happens when you import <b>startup culture</b> into mathematics. Maybe such Janus-faced interactions are commonplace in Silicon Valley where qualifiers are merely a distraction from a good sales pitch. But it‚Äôs an utterly abhorrent mindset that I think mathematicians must strive to banish at all costs. In particular, the choice to deliberately obscure the fact that the program has generated (as yet) <i>nothing considered remotely new by an expert</i> while simultaneously boasting of a triumph in automating intuition is  absurd; Ramanujan would roll over in his grave.</p>
<p><b>Caveats:</b> The paper has a number of young authors who I consider completely blameless. The possibility of redemption still awaits in the next version of the paper. </p>
<p><b>Random Continued Fraction: </b>I give you one of the author‚Äôs lastest tweets, in which one of their amazing conjectures has been generalized! (By a 15 year old apparently, well done to him, I hope he doesn‚Äôt waste any more time on this). I‚Äôll spare you the <a href="https://twitter.com/yaronhadad/status/1150767039621062656?s=20">amazing gif</a> animation that builds up to this final climax:</p>
<p><a href="https://box2106.temp.domains/~galoisre///wp-content/uploads/2019/07/screen-shot-2019-07-16-at-2.41.59-pm.png"><img loading="lazy" src="https://box2106.temp.domains/~galoisre///wp-content/uploads/2019/07/screen-shot-2019-07-16-at-2.41.59-pm.png?w=300" alt="" width="495" height="371" srcset="https://www.galoisrepresentations.com/wp-content/uploads/2019/07/screen-shot-2019-07-16-at-2.41.59-pm.png 1086w, https://www.galoisrepresentations.com/wp-content/uploads/2019/07/screen-shot-2019-07-16-at-2.41.59-pm-300x225.png 300w, https://www.galoisrepresentations.com/wp-content/uploads/2019/07/screen-shot-2019-07-16-at-2.41.59-pm-768x577.png 768w, https://www.galoisrepresentations.com/wp-content/uploads/2019/07/screen-shot-2019-07-16-at-2.41.59-pm-1024x769.png 1024w" sizes="(max-width: 495px) 100vw, 495px"></a></p>
<p>Well ‚Ä¶ OK I guess? But, pretty much exactly as pointed out last time, not only is the proof only one line, but the nature of the proof makes clear exactly how unoriginal this is to mathematics:</p>
<p><a href="https://box2106.temp.domains/~galoisre///wp-content/uploads/2019/07/latestproof.png"><img loading="lazy" src="https://box2106.temp.domains/~galoisre///wp-content/uploads/2019/07/latestproof.png?w=300" alt="" width="615" height="201" srcset="https://www.galoisrepresentations.com/wp-content/uploads/2019/07/latestproof.png 1484w, https://www.galoisrepresentations.com/wp-content/uploads/2019/07/latestproof-300x98.png 300w, https://www.galoisrepresentations.com/wp-content/uploads/2019/07/latestproof-768x250.png 768w, https://www.galoisrepresentations.com/wp-content/uploads/2019/07/latestproof-1024x334.png 1024w" sizes="(max-width: 615px) 100vw, 615px"></a></p>
<p>(There is actually something vaguely interesting about how certain specializations of complicated identities are harder to prove than the original identities, but that is only tangentially relevant to this post.)</p>
											</div><!-- .entry-content -->

		
						<div><p>
							This entry was posted in <a href="https://www.galoisrepresentations.com/category/mathematics/" rel="category tag">Mathematics</a>, <a href="https://www.galoisrepresentations.com/category/rant/" rel="category tag">Rant</a> and tagged <a href="https://www.galoisrepresentations.com/tag/continued-fractions/" rel="tag">Continued Fractions</a>, <a href="https://www.galoisrepresentations.com/tag/de-fractionibus-continuis-observationes/" rel="tag">De fractionibus continuis observationes</a>, <a href="https://www.galoisrepresentations.com/tag/elon-musk/" rel="tag">Elon Musk</a>, <a href="https://www.galoisrepresentations.com/tag/euler/" rel="tag">Euler</a>, <a href="https://www.galoisrepresentations.com/tag/gauss/" rel="tag">Gauss</a>, <a href="https://www.galoisrepresentations.com/tag/intellectual-fraud/" rel="tag">Intellectual Fraud</a>, <a href="https://www.galoisrepresentations.com/tag/ramanujan/" rel="tag">Ramanujan</a>, <a href="https://www.galoisrepresentations.com/tag/robert-dijkgraaf/" rel="tag">Robert Dijkgraaf</a>, <a href="https://www.galoisrepresentations.com/tag/startup-culture/" rel="tag">startup culture</a>, <a href="https://www.galoisrepresentations.com/tag/stephen-wolfram/" rel="tag">Stephen Wolfram</a>, <a href="https://www.galoisrepresentations.com/tag/twitter/" rel="tag">twitter</a>, <a href="https://www.galoisrepresentations.com/tag/yuri-milner/" rel="tag">Yuri Milner</a>. Bookmark the <a href="https://www.galoisrepresentations.com/2019/07/17/the-ramanujan-machine-is-an-intellectual-fraud/" title="Permalink to The Ramanujan Machine is all hype" rel="bookmark">permalink</a>.													</p></div><!-- .entry-utility -->
					</div></div>]]>
            </description>
            <link>https://www.galoisrepresentations.com/2019/07/17/the-ramanujan-machine-is-an-intellectual-fraud/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26144665</guid>
            <pubDate>Mon, 15 Feb 2021 17:12:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Alien-Haunted World]]>
            </title>
            <description>
<![CDATA[
Score 21 | Comments 17 (<a href="https://news.ycombinator.com/item?id=26142795">thread link</a>) | @CapitalistCartr
<br/>
February 15, 2021 | http://m.nautil.us/blog/the-alien_haunted-world | <a href="https://web.archive.org/web/*/http://m.nautil.us/blog/the-alien_haunted-world">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
			

			<figure data-alt=""><img src="http://static.nautil.us/18165_825ab77fe4eb3419db2fc9c6ceff7146.jpg" width="733" alt=""><figcaption><span><i>To shield one‚Äôs pet hypothesis of an alien object by suggesting that it is not being taken seriously because of a flaw in how we do science is playing a disingenuous game with the facts.</i></span><span>Illustration by ktsdesign / Shutterstock</span></figcaption></figure><p><span>D</span>id you know that there are many scientists who devote their working lives to skillfully charting out the most unassuming chunks of our solar system‚Äîchunks that none of our species will likely never see up close? Chunks that, individually, are mere specks in the cloud of millions of such primordial planetary leftovers circling our sun. Or, are you aware that there are those who spend day after day wrestling with how to measure and decode the extraordinary orbital dances of unreachable exoplanets, or to detect and interpret the delicate spectra revealing the composition of alien atmospheres tens of trillions of miles away?</p><p>If not them, then what about those who have, for decades, tackled some of the most daunting questions about the phenomenon we call life itself, including how it began here on Earth billions of years ago, and how it might have begun anywhere else in the cosmos? And can you recall that there are devoted and talented scientists who pursue the exquisite possibility that somewhere there are alien minds sending out structured, information-rich signals, or repurposing their environments in ways that we‚Äîother scraps of thinking life‚Äîmight just be able to spot across the gaping void of interstellar space?</p><blockquote><p>Aliens may be out there. And we are looking for them.</p> </blockquote><p>If you could say yes to any of these questions, well done. You are a well-informed citizen of planet Earth, aware of humanity‚Äôs ongoing efforts to make sense of the nature of reality. If, on the other hand, you couldn‚Äôt respond in the affirmative then perhaps you wouldn‚Äôt blink an eye at newspaper articles or TV headlines asking why (oh why?!) scientists won‚Äôt take the task of ‚Äúlooking for aliens‚Äù more seriously? Or articles harrumphing about how conservative science is when it comes to ‚Äúthinking out of the box,‚Äù especially if the topic is one that‚Äôs been abused so many times over literally centuries that researchers now have little choice but to apply extreme care and caution.<br></p><p>I am, if you are not up on your science news at the moment, referring to a recent flurry of words and opinions that have been, in part, triggered by the publication of the book <i>Extraterrestrial</i> by the theoretical astrophysicist Avi Loeb, in which he attempts to make a case that a recent interstellar object passing through our solar system (<a href="https://nautil.us/blog/how-oumuamua-got-shredded" target="_blank">the ‚ÄòOumuamua object</a>) could have been a piece of technology, conceivably even a tumbling light sail from an alien spacecraft, rather than a piece of frozen rock and gas. Loeb also writes about how science can be overly conservative at times‚Äîaiming his complaints in particular on the reticence to elevate the question of alien life to a more prominent place in our hypotheses about what we see in the universe around us.</p><p>But you need only to have spent a little time recently in the hallways of scientific Zoom calls or on social media to see unhappiness being expressed by many researchers about all of this. That unhappiness reaches a red-hot level any time a new opinion piece gets published that picks up this particular thread. Most recently (at least as I write this), is the appearance in <i>The New York Times</i> of an <a href="https://www.nytimes.com/2021/02/11/opinion/aliens-extraterrestrial-life.html" target="_blank">opinion article</a> with the title ‚ÄúAliens Must Be Out There: Why aren‚Äôt we looking for them?‚Äù, written by the columnist Farhad Manjoo. I think it‚Äôs fair to say that the tone of the headline, erroneously suggesting that alien life exists because we think it must and that we‚Äôre not paying attention, reflects much of the thrust of the content. Reaching an apex of sorts when the piece uses Loeb‚Äôs thoughts on the matter to admonish science, and science-funding agencies, for their ‚Äúclosed-mindedness‚Äù and ‚Äúreflexive skepticism‚Äù when it comes to considering exotic (yes, alien) stuff in the mix for explaining new or unexpected cosmic phenomena.&nbsp;</p><p>What is so incredibly disappointing for a scientist like myself, and for so many of my colleagues across related disciplines‚Äîfrom astronomy to planetary science, to astrobiology‚Äîis that there are no other voices represented in this kind of writing. No snippets or quotes from the hundreds of scientists who are the world‚Äôs experts on matters like ‚ÄòOumuamua, or other extraterrestrial objects, from asteroids to comets to (yes) interstellar chunks, or the Search for Extraterrestrial Intelligence (SETI), or exoplanets, or indeed the very same quest for so-called technosignatures that is fleetingly mentioned. And this one article is by no means alone in that strange incompleteness, where ‚Äúdue diligence‚Äù seems to have gone out the window.</p><p>In reality there are people who do think about all of these scientific questions, week after week. They dig through mountains of data, and sweat blood over understanding the delicate nature of astronomical measurements and instrumentation. They build spacecraft to go to other worlds, as well as asteroids and comets, funded by national agencies like NASA, ESA, JAXA, CNSA, and more. These people are eager and driven, motivated by precisely these same extraterrestrial conundrums: Are we alone? Where do we, or any other life, come from?</p><p>These scientists, including those like the remarkable Jill Tarter‚Äîone of the driving forces and voices behind SETI for the past 40 years‚Äîhave pushed their instruments and skills to the absolute limits in the quest for evidence of extraterrestrial life. Often in the face of intense skepticism. Despite this effort, there has been no evidence to date of extraterrestrial life. But that lack of evidence is not because the scientific enterprise is uniformly conservative, rigid, and close-minded, as implied by Loeb and uncritically echoed by some columnists. It‚Äôs because no discovery or event has risen to the level where it is inexplicable in any other way. Could greater funding and support change that story? Perhaps, but the same could be said for almost any other ambitious scientific enterprise, and the answer cannot be known beforehand.</p><p>A proposal that a phenomenon like ‚ÄòOumuamua is an alien artifact is certainly going to meet push-back. But that push-back is well founded. It results from the extensive work of scientific experts on precisely this kind of interstellar visitor. Our models of star and planet formation have long hypothesized the existence of leftover pieces of solid material (planetesimals) that could spend eons moving across interstellar space. They have outlined how an interloper like ‚ÄòOumuamua would be a stunning discovery. But it would be a stunning discovery reflecting natural processes; reservoirs of these planetesimals‚Äîalready suggested by the hazy light seen around certain other stars‚Äîthat can be ejected and scattered across interstellar space in numbers that may be perfectly consistent with the chances of our solar system being visited by one. This is precisely why an agency like ESA is developing its <a href="https://www.cometinterceptor.space/" target="_blank">Comet Interceptor Mission</a>, to be ready to chase future interstellar visitors.</p><div id="inpagesub">
	<p>Get the <span>Nautilus</span> newsletter</p>
<p>
	The newest and most popular articles delivered right to your inbox!
</p>
			<!-- Begin MailChimp Signup Form -->
			




</div><p>‚ÄòOumuamua certainly had puzzling characteristics. It was small for an interstellar comet, it was elongated and, despite being barely caught by our best telescopes and nimblest astronomers as it wended its tumbling way back out of the solar system, it exhibited an ethereal acceleration away from the Sun. But even these puzzles are explicable by known processes and are not wildly inconsistent with the properties of other cometary-like objects. Indeed, a number of comparatively straightforward, testable, explanations seem compatible, <a href="https://www.hou.usra.edu/meetings/lpsc2021/pdf/1718.pdf" target="_blank">including the possibility</a> that the object was a frozen nitrogen ‚Äúiceberg,‚Äù a chip off the block of some distant Pluto-like world.&nbsp;</p><p>In light of all of this rigorous insight, to shield one‚Äôs pet hypothesis of an alien object by suggesting that it is not being taken seriously because of a flaw in how we do science is playing a disingenuous game with the facts. As is to suggest that this is actually in aid of raising support for the search for extraterrestrial life. For that to be uncritically echoed elsewhere is truly unfortunate.</p><p>As in any human intellectual endeavor, there are many voices, many insights. It‚Äôs too bad that not all insights get the same kind of airtime. If they did, we‚Äôd be hearing so much more about the extraordinary ongoing scientific efforts‚Äîboth institutional and personal‚Äîto open up our minds, to explore new worlds, and perhaps discover new life. Are we all carrying out these efforts perfectly? No. Scientific conservatism is present. But so too is a clear memory of the many times where enthusiasm for a provocative idea about alien life has given way to disappointment‚Äîfrom fossils in Martian meteorites to arsenic-laced microbes. Fingers have been burnt before in the quest to find clues to life in the universe.&nbsp;</p><p>They weren‚Äôt burned because of misplaced skepticism though. A wide range of scientists did their own due diligence: scrutinizing a hypothesis, gathering more data, weighing the evidence and building their confidence in a conclusion. Science denialism has cursed many cultures in recent years. Thankfully it looks to be receding somewhat. But being blind to how science works and what it‚Äôs doing is also a form of denialism. Aliens may be out there. And we are looking for them.</p><p><i>Caleb Scharf is an astrophysicist and the director of astrobiology at Columbia University in New York. His latest book is&nbsp;</i>The Ascent of Information: Books, Bits, Genes, Machines, and Life‚Äôs Unending Algorithm<i>, coming in June 2021.&nbsp;Follow him on Twitter @caleb_scharf.</i></p>

		</div></div>]]>
            </description>
            <link>http://m.nautil.us/blog/the-alien_haunted-world</link>
            <guid isPermaLink="false">hacker-news-small-sites-26142795</guid>
            <pubDate>Mon, 15 Feb 2021 13:59:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[An Improved Thread with C++20]]>
            </title>
            <description>
<![CDATA[
Score 65 | Comments 56 (<a href="https://news.ycombinator.com/item?id=26142257">thread link</a>) | @ibobev
<br/>
February 15, 2021 | http://modernescpp.com/index.php/an-improved-thread-with-c-20 | <a href="https://web.archive.org/web/*/http://modernescpp.com/index.php/an-improved-thread-with-c-20">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="blogContent">
				<p><code>std::jthread</code> stands for joining thread. In addition to <code>std::thread</code> (C++11),<code> std::jthread</code> automatically joins in its destructor and can cooperatively be interrupted. Read in this post to know why <code>std::jthread</code> should be your first choice.</p>

<p>&nbsp;<img src="http://modernescpp.com/images/blog/Cpp20/jthread/TimelineCpp20.png" alt="TimelineCpp20" width="650" height="227"></p>
<p>The following table gives you a concise overview of the functionality of <code>std::jthread</code>.</p>
<p><img src="http://modernescpp.com/images/blog/Cpp20/jthread/jthread.png" alt="jthread" width="650" height="572"></p>

<p>For additional details, please refer to <a href="https://en.cppreference.com/w/cpp/thread/jthread">cppreference.com</a>. When you want to read more post about <code>std::thread</code>, here are they: <a href="http://modernescpp.com/index.php/der-einstieg-in-modernes-c#h1-2-the-threading-interface">my post about std::thread.</a></p>
<p>First, why do we need an improved thread in C++20? Here is the first reason.</p>
<h2 id="h1-automatically-joining">Automatically Joining</h2>
<p>This is the <strong>non-intuitive</strong> behavior of <code>std::thread</code>. If a <code>std::thread</code> is still joinable, <a href="https://en.cppreference.com/w/cpp/error/terminate">std::terminate</a> is called in its destructor. A thread<code> thr</code> is joinable if neither <code>thr.join()</code> nor <code>thr.detach()</code> was called. Let me show, what that means.</p>
<!-- HTML generated using hilite.me -->
<div>
<pre><span>// threadJoinable.cpp</span>

<span>#include &lt;iostream&gt;</span>
<span>#include &lt;thread&gt;</span>

<span>int</span> <span>main</span>() {
    
    std<span>::</span>cout <span>&lt;&lt;</span> <span>'\n'</span>;
    std<span>::</span>cout <span>&lt;&lt;</span> std<span>::</span>boolalpha;
    
    std<span>::</span><span>thread</span> thr{[]{ std<span>::</span>cout <span>&lt;&lt;</span> <span>"Joinable std::thread"</span> <span>&lt;&lt;</span> <span>'\n'</span>; }};
    
    std<span>::</span>cout <span>&lt;&lt;</span> <span>"thr.joinable(): "</span> <span>&lt;&lt;</span> thr.joinable() <span>&lt;&lt;</span> <span>'\n'</span>;
    
    std<span>::</span>cout <span>&lt;&lt;</span> <span>'\n'</span>;
    
}
</pre>
</div>

<p>When executed, the program terminates when the local object <code>thr</code> goes out of scope.</p>
<p><img src="http://modernescpp.com/images/blog/Cpp20/jthread/threadJoinable.png" alt="threadJoinable" width="500" height="279"></p>
<p>Both executions of<code> std::thread</code> terminate. In the second run, the thread <code>thr</code> has enough time to display its message:&nbsp;<code>Joinable std::thread</code>.</p>
<p>In the next example, I use <code>std::jthread</code> from the C++20 standard.</p>
<!-- HTML generated using hilite.me -->
<div>
<pre><span>// jthreadJoinable.cpp</span>

<span>#include &lt;iostream&gt;</span>
<span>#include &lt;thread&gt;</span>

<span>int</span> <span>main</span>() {
    
    std<span>::</span>cout <span>&lt;&lt;</span> <span>'\n'</span>;
    std<span>::</span>cout <span>&lt;&lt;</span> std<span>::</span>boolalpha;
    
    std<span>::</span>jthread thr{[]{ std<span>::</span>cout <span>&lt;&lt;</span> <span>"Joinable std::thread"</span> <span>&lt;&lt;</span> <span>'\n'</span>; }};
    
    std<span>::</span>cout <span>&lt;&lt;</span> <span>"thr.joinable(): "</span> <span>&lt;&lt;</span> thr.joinable() <span>&lt;&lt;</span> <span>'\n'</span>;
    
    std<span>::</span>cout <span>&lt;&lt;</span> <span>'\n'</span>;
    
}
</pre>
</div>

<p>Now, the thread<code> thr</code> automatically joins in its destructor if it's still joinable such as in this case.</p>
<p><img src="http://modernescpp.com/images/blog/Cpp20/jthread/jthreadJoinable.png" alt="jthreadJoinable" width="350" height="177"></p>
<p>But this is not all that<code> std::jthread</code>&nbsp; provides additionally to <code>std::thread</code>. A <code>std::jthread</code> can be cooperatively interrupted. I already presented the general ideas of cooperative interruption in my last post: <a href="http://modernescpp.com/index.php/cooperative-interruption-of-a-thread-in-c-20">Cooperative Interruption of a Thread in C++20</a>.</p>
<h2 id="h2-cooperative-interruption-of-a-std-jthread">Cooperative Interruption of a<code> std::jthread</code></h2>
<p>To get a general idea, let me present a simple example.</p>
<!-- HTML generated using hilite.me -->
<div>
<pre><span>// interruptJthread.cpp</span>

<span>#include &lt;chrono&gt;</span>
<span>#include &lt;iostream&gt;</span>
<span>#include &lt;thread&gt;</span>

<span>using</span> <span>namespace</span><span>::</span>std<span>::</span>literals;

<span>int</span> <span>main</span>() {
    
    std<span>::</span>cout <span>&lt;&lt;</span> <span>'\n'</span>;
    
    std<span>::</span>jthread nonInterruptable([]{                           <span>// (1)</span>
        <span>int</span> counter{<span>0</span>};
        <span>while</span> (counter <span>&lt;</span> <span>10</span>){
            std<span>::</span>this_thread<span>::</span>sleep_for(<span>0.2</span>s);
            std<span>::</span>cerr <span>&lt;&lt;</span> <span>"nonInterruptable: "</span> <span>&lt;&lt;</span> counter <span>&lt;&lt;</span> <span>'\n'</span>; 
            <span>++</span>counter;
        }
    });
    
    std<span>::</span>jthread interruptable([](std<span>::</span>stop_token stoken){     <span>// (2)</span>
        <span>int</span> counter{<span>0</span>};
        <span>while</span> (counter <span>&lt;</span> <span>10</span>){
            std<span>::</span>this_thread<span>::</span>sleep_for(<span>0.2</span>s);
            <span>if</span> (stoken.stop_requested()) <span>return</span>;               <span>// (3)</span>
            std<span>::</span>cerr <span>&lt;&lt;</span> <span>"interruptable: "</span> <span>&lt;&lt;</span> counter <span>&lt;&lt;</span> <span>'\n'</span>; 
            <span>++</span>counter;
        }
    });
    
    std<span>::</span>this_thread<span>::</span>sleep_for(<span>1</span>s);
    
    std<span>::</span>cerr <span>&lt;&lt;</span> <span>'\n'</span>;
    std<span>::</span>cerr <span>&lt;&lt;</span> <span>"Main thread interrupts both jthreads"</span> <span>&lt;&lt;</span> <span>'\n'</span>;
    nonInterruptable.request_stop();
    interruptable.request_stop();                              <span>// (4)</span>
    
    std<span>::</span>cout <span>&lt;&lt;</span> <span>'\n'</span>;
    
}
</pre>
</div>

<p>In the main program, I start the two threads <code>nonInterruptable</code> and interruptable (lines 1)and 2). Unlike in the thread <code>nonInterruptable</code> , the thread <code>interruptable</code> gets a <code>std::stop_token</code> and uses it in line (3) to check if it was interrupted: <code>stoken.stop_requested()</code>. In case of a stop request, the lambda function returns, and, therefore, the thread ends. The call <code>interruptable.request_stop()</code> (line 4) triggers the stop request. This does not hold for the previous call <code>nonInterruptable.request_stop()</code> . The call has no effect.</p>
<p><img src="http://modernescpp.com/images/blog/Cpp20/jthread/interruptJthread.png" alt="interruptJthread" width="400" height="382"></p>
<p>To make my post complete, with C++20, you can also cooperatively interrupt a condition variable.</p>
<h2 id="h3-new-wait-overloads-for-std-condition-variable-any">New wait Overloads for <code>std::condition_variable_any</code></h2>
<p>Before I write about <code>std::condition_variable_any</code>, here are my post about <a href="http://modernescpp.com/index.php/tag/condition-variable">condition variables</a>.&nbsp;</p>
<p>The three wait variations <code>wait, wait_for</code>, and<code> wait_until</code> of the std::condition_variable_any get new overloads. These overloads take a <code>std::stop_token</code>.</p>
<!-- HTML generated using hilite.me -->
<div>
<pre><span>template</span> <span>&lt;</span><span>class</span> <span>Predicate</span><span>&gt;</span>
<span>bool</span> wait(Lock<span>&amp;</span> lock,  
          stop_token stoken,
          Predicate pred);

<span>template</span> <span>&lt;</span><span>class</span> <span>Rep</span>, <span>class</span> <span>Period</span>, <span>class</span> <span>Predicate</span><span>&gt;</span>
<span>bool</span> wait_for(Lock<span>&amp;</span> lock, 
              stop_token stoken, 
              <span>const</span> chrono<span>::</span>duration<span>&lt;</span>Rep, Period<span>&gt;&amp;</span> rel_time, 
              Predicate pred);
                
<span>template</span> <span>&lt;</span><span>class</span> <span>Clock</span>, <span>class</span> <span>Duration</span>, <span>class</span> <span>Predicate</span><span>&gt;</span>
<span>bool</span> wait_until(Lock<span>&amp;</span> lock, 
                stop_token stoken,
                <span>const</span> chrono<span>::</span>time_point<span>&lt;</span>Clock, Duration<span>&gt;&amp;</span> abs_time, 
                Predicate pred);
</pre>
</div>

<p>These new overloads need a predicate. The presented versions ensure to get notified if a stop request for the passed <code>std::stop_token stoken</code> is signaled. They return a boolean that indicates whether the predicate evaluates to <code>true</code>. This returned boolean is independent of whether a stop was requested or of whether the timeout was triggered.</p>
<p>After the wait calls, you can check if a stop request occurred.</p>
<!-- HTML generated using hilite.me -->
<div>
<pre>cv.wait(lock, stoken, predicate);
<span>if</span> (stoken.stop_requested()){
    <span>// interrupt occurred</span>
}
</pre>
</div>

<p>The following example shows the usage of a condition variable with a stop request.</p>
<!-- HTML generated using hilite.me -->
<div>
<pre><span>// conditionVariableAny.cpp</span>

<span>#include &lt;condition_variable&gt;</span>
<span>#include &lt;thread&gt;</span>
<span>#include &lt;iostream&gt;</span>
<span>#include &lt;chrono&gt;</span>
<span>#include &lt;mutex&gt;</span>
<span>#include &lt;thread&gt;</span>

<span>using</span> <span>namespace</span> std<span>::</span>literals;

std<span>::</span>mutex mutex_;
std<span>::</span>condition_variable_any condVar;

<span>bool</span> dataReady;

<span>void</span> <span>receiver</span>(std<span>::</span>stop_token stopToken) {                 <span>// (1)</span>

    std<span>::</span>cout <span>&lt;&lt;</span> <span>"Waiting"</span> <span>&lt;&lt;</span> <span>'\n'</span>;

    std<span>::</span>unique_lock<span>&lt;</span>std<span>::</span>mutex<span>&gt;</span> lck(mutex_);
    <span>bool</span> ret <span>=</span> condVar.wait(lck, stopToken, []{<span>return</span> dataReady;});
    <span>if</span> (ret){
        std<span>::</span>cout <span>&lt;&lt;</span> <span>"Notification received: "</span> <span>&lt;&lt;</span> <span>'\n'</span>;
    }
    <span>else</span>{
         std<span>::</span>cout <span>&lt;&lt;</span> <span>"Stop request received"</span> <span>&lt;&lt;</span> <span>'\n'</span>;
    }
}

<span>void</span> <span>sender</span>() {                                            <span>// (2)</span>

    std<span>::</span>this_thread<span>::</span>sleep_for(<span>5</span>ms);
    {
        std<span>::</span>lock_guard<span>&lt;</span>std<span>::</span>mutex<span>&gt;</span> lck(mutex_);
        dataReady <span>=</span> <span>true</span>;
        std<span>::</span>cout <span>&lt;&lt;</span> <span>"Send notification"</span>  <span>&lt;&lt;</span> <span>'\n'</span>;
    }
    condVar.notify_one();                                  <span>// (3)</span>

}

<span>int</span> <span>main</span>(){

  std<span>::</span>cout <span>&lt;&lt;</span> <span>'\n'</span>;

  std<span>::</span>jthread t1(receiver);
  std<span>::</span>jthread t2(sender);
  
  t1.request_stop();                                       <span>// (4)</span>

  t1.join();
  t2.join();

  std<span>::</span>cout <span>&lt;&lt;</span> <span>'\n'</span>;
  
}
</pre>
</div>

<p>The receiver thread (line 1) is waiting for the notification of the sender thread (line 2). Before the sender thread sends its notification (line 3), the main thread triggered a stop request in<br>line (4). The output of the program shows that the stop request happened before the notification.</p>
<h2><img src="http://modernescpp.com/images/blog/Cpp20/jthread/conditionVariableAny.png" alt="conditionVariableAny" width="281" height="113"></h2>
<h2 id="h4-what-s-next">What's next?</h2>
<p>What happens when your write without synchronization to <code>std::cout</code>? You get a mess. Thanks to C++20, we have synchronized output streams.</p>
<div>
	<p><strong>Thanks a lot to my <a href="https://www.patreon.com/rainer_grimm">Patreon Supporters</a></strong><strong>: Matt Braun, Roman Postanciuc, Tobias Zindl, Marko, </strong><span title="Emyr Williams"><strong>G Prvulovic, Reinhold Dr√∂ge, Abernitzke,</strong> </span><strong><span title="Emyr Williams">Frank Grimm</span></strong><span title="Emyr Williams"><strong>, Sakib, Broeserl, </strong></span><strong><span title="Emyr Williams">Ant√≥nio Pina, Darshan Mody, Sergey Agafyin, <span data-tag="user-details-full-name">–ê–Ω–¥—Ä–µ–π –ë—É—Ä–º–∏—Å—Ç—Ä–æ–≤, Jake, GS, Lawton Shoemake, Animus24, Jozo Leko, John Breland, espkk, Wolfgang G√§rtner</span></span><span title="Emyr Williams"><span><span></span></span></span>,&nbsp; Louis St-Amour, Stephan Roslen, Venkat Nandam, Jose Francisco, Douglas Tinkham, Kuchlong Kuchlong, Avi Kohn, Robert Blanch, Truels Wissneth, Kris Kafka, Mario Luoni, Neil Wang, Friedrich Huber, lennonli, Pramod Tikare Muralidhara, Peter Ware, and Tobi Heideman.<br></strong></p>

<p><strong>Thanks in particular to Jon Hess, Lakshman,</strong> <strong>Christian Wittenhorst, Sherhy Pyton, Dendi Suhubdy, Sudhakar Belagurusamy, and Richard Sargeant.<br></strong></p>
<p>My special thanks to <a href="https://www.embarcadero.com/de/products/cbuilder">Embarcadero</a> <a href="https://www.embarcadero.com/products/cbuilder"><img src="http://modernescpp.com/images/Embarcadero/CBUIDER_STUDIO_FINAL_ICONS_1024_Small.png" alt="CBUIDER STUDIO FINAL ICONS 1024 Small" width="100" height="100"></a></p>

<h2>Seminars</h2>
<p>I'm happy to give online-seminars or face-to-face seminars world-wide. Please call me if you have any questions.</p>
<h3>Bookable (Online)</h3>
<h4>Deutsch</h4>
<ul>
<li><a href="https://www.modernescpp.de/index.php/c/2-c/30-embedded-programmierung-mit-modernem-c20210126195655">Embedded Programmierung mit modernem C++: </a>12.04.2021 - 14.04.2021 (9:00 - 17:00 CEST)</li>
<li><a href="https://www.modernescpp.de/index.php/c/2-c/31-clean-code-mit-modernem-c">Clean Code mit modernem C++: </a>22.06.2021 - 24.06.2021 (9:00 - 17:00 CEST)</li>
</ul>
<h4>English</h4>
<ul>
<li>Workshop: <a href="https://www.modernescpp.net/index.php/c/2-c/32-workshop-concepts-in-c-20">Concepts in C++20</a>: 22.03.2021 (17:00 - 21:00 CET)</li>
<li>Workshop: <a href="https://www.modernescpp.net/index.php/c/2-c/33-workshop-coroutines-in-c-20">Coroutines in C++20</a>: 06.04.2021 (17:00 - 21:00 CEST)</li>
</ul>
<h3>Standard Seminars&nbsp;</h3>
<p>Here is a compilation of my standard seminars. These seminars are only meant to give you a first orientation.</p>
<ul>
<li><a href="https://www.modernescpp.net/index.php/c/plan/2-c/22">C++ - The Core Language</a></li>
<li><a href="https://www.modernescpp.net/index.php/c/plan/2-c/23">C++ - The Standard Library</a></li>
<li><a href="https://www.modernescpp.net/index.php/c/plan/2-c/23">C++ - Compact</a></li>
<li><a href="https://www.modernescpp.net/index.php/c/plan/2-c/18">C++11 and C++14</a></li>
<li><a href="https://www.modernescpp.net/index.php/c/plan/2-c/19">Concurrency with Modern C++</a></li>
<li><a href="https://www.modernescpp.net/index.php/c/plan/2-c/21">Design Patterns and Architecture Patterns with C++</a></li>
<li><a href="https://www.modernescpp.net/index.php/c/plan/2-c/17">Embedded Programming with Modern C++</a></li>
<li><a href="https://www.modernescpp.net/index.php/c/plan/2-c/17">Generic Programming (Templates) with C++</a></li>
</ul>
<h4>New</h4>
<ul>
<li><a href="https://www.modernescpp.net/index.php/c/plan/2-c/16">Clean Code with Modern C++</a></li>
<li><a href="https://www.modernescpp.net/index.php/c/plan/2-c/25">C++20</a></li>
</ul>
<h3>Contact Me</h3>
<ul>
<li>Tel.: +49 7472 917441</li>
<li>Mobil: +49 152 31965939</li>
<li>Mail: <a href="http://modernescpp.com/%3Ca%20href="><span id="cloak074c3d1e132371bc9560ca558c89afb5">This email address is being protected from spambots. You need JavaScript enabled to view it.</span></a></li>
<li>German Seminar Page: <a href="https://www.modernescpp.de/">www.ModernesCpp.de</a></li>
<li>English Seminar Page: <a href="http://www.modernescpp.net/">www.ModernesCpp.net</a></li>
</ul>
<h3>Modernes C++,</h3>
<p><img src="http://modernescpp.com/images/signatur/RainerGrimmSmall.png" alt="RainerGrimmSmall"></p>
</div>


			</div></div>]]>
            </description>
            <link>http://modernescpp.com/index.php/an-improved-thread-with-c-20</link>
            <guid isPermaLink="false">hacker-news-small-sites-26142257</guid>
            <pubDate>Mon, 15 Feb 2021 12:55:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Running Nomad for a Home Server]]>
            </title>
            <description>
<![CDATA[
Score 264 | Comments 135 (<a href="https://news.ycombinator.com/item?id=26142005">thread link</a>) | @elliebike
<br/>
February 15, 2021 | https://mrkaran.dev/posts/home-server-nomad/ | <a href="https://web.archive.org/web/*/https://mrkaran.dev/posts/home-server-nomad/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>

<section>
    
    <article>
        <p>It's been a long time since I've written a post on Hydra (my home server). I use Hydra as a testbed to learn new tools, workflows and it just gives me joy to self-host applications while learning something in return.</p>
<h2 id="history">History</h2>
<p>A brief history of how <a href="https://github.com/mr-karan/hydra">Hydra's</a> setup evolved over time:</p>
<p><a href="https://mrkaran.dev/posts/home-server-setup/">2019</a>: </p>
<ul>
<li>A pretty minimal K3s setup deployed on 2 RPi4 nodes. I couldn't continue with this setup because:
<ul>
<li>Some of the apps didn't have ARM-based image (this was 2019, pre M1 hype era).</li>
<li>Didn't want to risk deploying persistent workloads on RPi.</li>
<li>A lot of tooling to deploy workloads was missing (storing env variables for eg.).</li>
<li>It was so boring to write YAML (that I also did at work). Didn't give me joy.</li>
</ul>
</li>
</ul>
<p><a href="https://mrkaran.dev/posts/home-server-updates/">2020 First Half</a>:</p>
<ul>
<li>RPi 2x Nodes + K3s + DO Droplet. Tailscale for networking.
<ul>
<li>This was a considerable step up from the previous setup. I deployed a DO node and added <a href="https://kubernetes.io/docs/tasks/configure-pod-container/assign-pods-nodes/">Node Labels</a> to deploy persistent workloads on DO Node only.</li>
<li>I used my own tooling <a href="https://github.com/mr-karan/kubekutr/">Kubekutr</a> + Kustomize which helped with version control of my configs.</li>
<li>Took quite a bit of time to onboard new services. Got lazy, didn't host much apart from initial 3-4 applications.</li>
<li>Writing long YAMLs. No joy.</li>
</ul>
</li>
</ul>
<p>2020 Second Half:</p>
<ul>
<li>Single node on DO. Terraform for deploying Docker containers.
<ul>
<li>I believe the third iteration nailed it for me. I kept the setup super simple, used Terraform for deploying workloads as Docker containers.</li>
<li>Used Terraform extensively for setting up the node, Cloudflare records, DO firewall rules.</li>
<li>Time to onboard new services reduced from a couple of hours to a few minutes. This was a huge win for me. I deployed around 10-15 new services to try it out on the server directly.</li>
<li>Writing HCL is actually a much better experience than YAML.</li>
</ul>
</li>
</ul>
<h2 id="why-nomad">Why Nomad</h2>
<p><img src="https://mrkaran.dev/images/nomad-hydra.png" alt="image"></p>
<p>Around a month back, <a href="https://nadh.in/">Kailash</a> had asked about feedback on <a href="https://www.nomadproject.io/">Nomad</a>. We at <a href="https://zerodha.com/">Zerodha</a> (India's largest stock broker) are evaluating it to migrate our services to Nomad from Kubernetes (more on this later). It was almost 2 years since I last saw Nomad so it was definitely worth re-evaluating (esp since it hit 1.0 recently). I wanted to try out Nomad to answer a personal curiosity: <em>What does it do differently than Kubernetes?</em> No better way than actually getting hands dirty, right?!</p>
<p>After following the brief tutorials from the <a href="https://learn.hashicorp.com/nomad">official website</a> I felt confident to try it for actual workloads. In my previous setup, I was hosting quite a few applications (Pihole, Gitea, Grafana etc) and thought it'll be a nice way to learn how Nomad works by deploying the same services in the Nomad cluster. And I came in with zero expectations, I already had a nice setup which was reliable and running for me. My experience with a local Nomad cluster was joyful, I was able to quickly go from 0-&gt;1 in less than 30 minutes. This BTW is a strong sign of how easy Nomad is to get started with as compared to K8s. The sheer amount of different concepts you've to register in your mind before you can even deploy a single container in a K8s cluster is bizarre. Nomad takes the easy way out here and simplified the concepts for developers into just three things:</p>
<pre><code><span>job
  \_ group
        \_ task
</span></code></pre>
<ul>
<li>Job: Job is a collection of different groups. Job is where the constraints for type of scheduler, update strategies and ACL is placed. </li>
<li>Group: Group is a collection of different tasks. A group is always executed on the same Nomad client node. You'll want to use Groups for use-cases like a logging sidecar, reverse proxies etc.</li>
<li>Task: Atomic unit of work. A task in Nomad can be running a container/binary/Java VM etc, defining the mount points, env variables, ports to be exposed etc.</li>
</ul>
<p>If you're coming from K8s you can think of Task as a Pod and Group as a Replicaset. There's no equivalent to Job in K8s. BUT! The coolest part? You don't have to familiarise yourself with all different types of Replicasets (Deployments, Daemonsets, Statefulsets) and different ways of configuring them.</p>
<p>Want to make a normal job as a periodic job in Nomad? Simply add the following block to your existing Job:</p>
<pre><code><span>periodic {
  cron = "@daily"
}
</span></code></pre>
<p>You want to make a service run as a batch job (on all Nomad nodes -- the equivalent of Daemonset in K8s)? Simply make the following change to your existing job:</p>
<pre><code><span>-type="service"
</span><span>+type="batch"
</span></code></pre>
<p>You see <strong>this</strong> is what I mean by the focus on UX. There are many many such examples which will leave a nice smile on your face if you're coming from K8s background.</p>
<p>I'd recommend reading <a href="https://www.nomadproject.io/docs/internals/architecture">Internal Architecture</a> of Nomad if you want to understand this in-depth.</p>
<h2 id="architecture">Architecture</h2>
<p>Tech stack for Hydra:</p>
<ul>
<li>Tailscale VPN: Serves as a mesh layer between my laptop/mobile and DO server. Useful for exposing internal services.</li>
<li>Caddy for reverse proxying and automatic SSL setup for all services. I run 2 instances of Caddy:
<ul>
<li>Internal: Listens on Tailscale Network Interface. Reverse proxies all private services.</li>
<li>Public: Listens on DO's Public IPv4 network interface. Reverse proxies all public-facing services.</li>
</ul>
</li>
<li>Terraform: Primary component to have IaC (Infra as Code). Modules to manage:
<ul>
<li>Cloudflare DNS Zone and Records</li>
<li>DO Droplet, Firewall rules, SSH Keys, Floating IPs etc.</li>
<li>Nomad Jobs. Used for running workloads after templating env variables, config files in Nomad job files.</li>
</ul>
</li>
</ul>
<h2 id="complexity-of-nomad-vs-kubernetes">Complexity of Nomad vs Kubernetes</h2>
<p><a href="https://twitter.com/mrkaran_/status/1268762357355823104"><img src="https://mrkaran.dev/images/k8s-meme.jpeg" alt="image"></a></p>
<p>Nomad shines because it follows the UNIX philosophy of "Make each program do one thing well". To put simply, Nomad is <em>just</em> a workload orchestrator. It only is concerned about things like Bin Packing, scheduling decisions.</p>
<p>If you're running heterogeneous workloads, running a server (or a set of servers) quickly becomes expensive. Hence orchestrators tend to make sense in this context. They tend to save costs by making it efficient to run a vast variety of workloads. This is all an orchestrator has to do really. </p>
<p>Nomad doesn't interfere in your DNS setup, Service Discovery, secrets management mechanisms and pretty much anything else. If you read some of the posts at <a href="https://k8s.af/">Kubernetes Failure Stories</a>, the most common reason for outages is Networking (DNS, ndots etc). A lot of marketing around K8s never talks about these things.</p>
<p>I always maintain "Day 0 is easy, Day N is the real test of your skills". Anyone can deploy a workload to a K8s cluster, it's always the Day N operations which involve debugging networking drops, mysterious container restarts, proper resource allocations and other such complex issues that require real skills <strong>and</strong> effort. It's not as easy as <code>kubectl apply -f</code> and my primary gripe is with people who miss out on this in their "marketing" pitches (obvious!).</p>
<h2 id="when-to-use-nomad">When to use Nomad</h2>
<p>Nomad hits the sweet spot of being operationally easy and functional. Nomad is a great choice if you want to:</p>
<ul>
<li>Run not just containers but other forms of workloads.</li>
<li>Increase developer productivity by making it easier to deploy/onboard new services.</li>
<li>Consistent experience of deployment by testing the deployments locally.</li>
<li>(Not joking) You are tired of running Helm charts or writing large YAML manifests. The config syntax for Nomad jobs is human friendly and easy to grasp.</li>
</ul>
<p>Nomad is available as a single binary. If you want to try it locally, all you need is <code>sudo nomad agent -dev</code> and you'll have a Nomad Server, Client running in dev mode along with a UI. This makes it easy for the developers to test out the deployments locally because there's very little configuration difference between this and production deployment. Not to forget it's super easy to self-host Nomad clusters. I'm yet to meet anyone who self hosts K8s clusters in production without a dedicated team babysitting it always.</p>
<p>Once you eliminate the "blackbox" components from your stack, life becomes easier for everyone.</p>
<h2 id="when-to-not-use-nomad">When to not use Nomad</h2>
<ul>
<li>If you're relying on custom controllers and operators. <a href="https://kubernetes.io/docs/concepts/extend-kubernetes/operator/">Operator Pattern</a> is a new way of managing large complex distributed systems (like databases, job queues etc). There are a lot of community built operators which help in reducing the effort to run these services. However, all of these are tied deeply into the "Kubernetes" ecosystem. If you find yourself running any of such operators, it'll be tough (not impossible) to translate the same in Nomad ecosystem.</li>
</ul>
<p>I <em>genuinely</em> cannot think of any other reason to not use Nomad!</p>
<h2 id="practical-scenarios">Practical Scenarios</h2>
<p>Since I migrated a couple of workloads from my DO docker containers setup to Nomad, I'd demonstrate a few use cases which might be helpful if you want to start migrating your services to Nomad</p>
<h3 id="accessing-a-web-service-with-reverse-proxy">Accessing a Web service with Reverse Proxy</h3>
<p>Context: I'm running Caddy as a reverse proxy for all the services. Since we discussed earlier, Nomad <strong>only</strong> is concerned about scheduling, so how exactly do you do Service Discovery? You need Consul (or something like Consul, Nomad has no hard restrictions) to register a service name with it's IP Address. Here's how you can do that:</p>
<p>In the <code>.task</code> section of your Nomad job spec, you need to register the service name with the port you're registering and additional tags as metadata (optional):</p>
<pre><code><span>service {
  name = "gitea-web"
  tags = ["gitea", "web"]
  port = "http"
}
</span></code></pre>
<p>Nomad's <a href="https://www.nomadproject.io/docs/job-specification/template">template</a> uses <code>consul-template</code> behind the scenes. This is a small utility which continuously watches for Consul/Vault keys and provides the ability to reload/restart your workloads if any of those keys change. It can also be used to <em>discover</em> the address of the service registered in Consul. So here's an example of <code>Caddyfile</code> using Consul Template functions to pull the IP address of the upstream <code>gitea-web</code> service:</p>
<pre><code><span>git.mrkaran.dev {
    {{ range service "gitea-web" }}
    reverse_proxy {{ .Address }}:{{ .Port }}
    {{ end }}
}
</span></code></pre>
<p>When a job is submitted to Nomad, a rendered template is mounted inside the container. You can define actions on what to do when the values change. For eg on a redeployment of Gitea container, the address will most likely change. We'd like Caddy to automatically restart with the new address configured in the Caddyfile in that case:</p>
<pre><code><span>template {
  data = &lt;&lt;EOF
${caddyfile_public}
EOF

  destination = "configs/Caddyfile" # Rendered template.

  change_mode = "restart"
}
</span></code></pre>
<p>Using <a href="https://www.nomadproject.io/docs/job-specification/template#change_mode"><code>change_m‚Ä¶</code></a></p></article></section></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://mrkaran.dev/posts/home-server-nomad/">https://mrkaran.dev/posts/home-server-nomad/</a></em></p>]]>
            </description>
            <link>https://mrkaran.dev/posts/home-server-nomad/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26142005</guid>
            <pubDate>Mon, 15 Feb 2021 12:15:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Is This a Branch?]]>
            </title>
            <description>
<![CDATA[
Score 87 | Comments 46 (<a href="https://news.ycombinator.com/item?id=26141047">thread link</a>) | @wheresvic4
<br/>
February 15, 2021 | https://bartwronski.com/2021/01/18/is-this-a-branch/ | <a href="https://web.archive.org/web/*/https://bartwronski.com/2021/01/18/is-this-a-branch/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
						
<p>Let‚Äôs try a new format ‚Äì <strong>‚Äúshorts‚Äù</strong>; small blog posts where I elaborate on ideas that I‚Äôd discuss at my twitter, but they either come back over and over, or the short form doesn‚Äôt convey all the nuances.</p>



<div><figure><img src="https://lh5.googleusercontent.com/lc0z89hwcBtH59QnEvHrU__d1Be5uxjtjrjaBYi3updGObpyYlmpYvhlhXobMLWwyeRB2Sh--pEO7_oupCuDWdQXMtQnjcYfBjrO0TLDB_Zn5CJQLmDQm27enOR1C-tUEvmGGDL_" alt="" width="370" height="333"></figure></div>



<p>I often see advice about avoiding ‚Äúif‚Äù statements in the code (especially GPU shaders) at all costs. The worst of all is when this happens in glsl and programmers replace some simple if statements with (subjectively) horrible <a href="https://www.khronos.org/registry/OpenGL-Refpages/gl4/html/step.xhtml">step instruction</a> which IMO completely destroys all readability, or even worse ‚Äì sequences of mixes, maxes, clips and extra ALU.</p>



<p>After all, <strong>those ifs are branches, and branches are bad, right?</strong></p>



<p><strong>TLDR: No, definitely not ‚Äì on all accounts.</strong></p>



<h2>Why do programmers want to avoid branches?</h2>



<p>Let‚Äôs first address why programmers would like to avoid branches. There are some good reasons for that.</p>



<h3>Scalar CPU</h3>



<p>On the CPU, ‚Äúbranches‚Äù in a non-SIMD code might seem ‚Äúinnocent‚Äù, it‚Äôs just a conditional jump to some other code. Instead of executing an <em>instruction a</em> next address, we jump to <em>instruction b</em> at some other address. Unfortunately, there are many complicated things going on under the hood: All modern CPUs are heavily pipelined, superscalar, and out-of order.</p>



<div><figure><img src="https://lh5.googleusercontent.com/aJOrhsi_sQ7C4gG6z0cov73NA_qt-UckHrz10Uo5OGX22TuwRRf_n1ogyaRUSBsTsCU3wigOkYwIZMclAGslXKSruRk9P7ieNjYvyukZ9erHFaCr-QMuKvwPjMbLNuBfyMZGTqjc" alt="" width="344" height="330"><figcaption>All modern CPUs are superscalar and deeply pipelined. Many instructions are processed and executed at the same time. Source: <a href="https://en.wikipedia.org/wiki/Branch_predictor">wikipedia</a></figcaption></figure></div>



<p>To extract maximum efficiency, they use a model of <a href="https://en.wikipedia.org/wiki/Branch_predictor">speculative execution</a> ‚Äì a CPU ‚Äúgambles‚Äù and ‚Äúguesses‚Äù results of a branch ahead of time, not knowing if it will be taken or not, and starts executing those instructions. If it‚Äôs right ‚Äì great! However if it‚Äôs not, then the CPU needs to stall, cancel all the guesses, go back to the branch, and execute the other instructions. Oops.</p>



<p>Luckily, CPUs are usually very good at this ‚Äúguessing‚Äù (they actually analyze past branch patterns and take them into account!). On the other hand, without going into too much detail ‚Äì each branch consumes some of the branch predictor unit resources. One extra branch on some short, innocent code can make results of the branch prediction worse, and slow down other code (where branch predictor might be necessary for good performance!).</p>



<h3>SIMD and the GPU</h3>



<p>When considering SIMD or the GPU, the situation is even worse.</p>



<p>Simplifying ‚Äì single program and same instruction stream executes on multiple ‚Äúlanes‚Äù of the same data, processing 4/8/16/32/64 elements at the same time.</p>



<p>If you want to take a branch when some of the elements take one path, some another one, you have two main options: <strong>either abandon vectorization and scalarize code</strong> (very bad option; usually means that it‚Äôs not worth vectorizing given piece of code), or <strong>execute both code paths</strong> ‚Äì first the first one, store the results somewhere, execute the second one, and ‚Äúcombine‚Äù the results.</p>



<div><figure><img src="https://lh3.googleusercontent.com/GmopPKjJ_t4QpsGIhaIhjJn6cTfUjVaMSl9lDj74skwpNRUVIYtWQ8-V0j4mMLIyZk1CZEgn-9z5C1kExAlVjIw8Oikdx0L-gJnyrB-qUc5oi3_4aQmmcGwCcP51YutgGoAlRHdT" alt="" width="448" height="194"></figure></div>



<p>This is a general (over)simplification, and example GPUs have dedicated hardware to help do it efficiently and without wasting resources (hardware execution masks etc), but generally means extra cost of managing those masks, storing results somewhere, double execution costs and finally ‚Äì branches can serve as barriers, preventing some <a href="https://bartwronski.com/2014/03/27/gcn-two-ways-of-latency-hiding-and-wave-occupancy/">latency hiding (see my old blog post on it)</a>.</p>



<h3>Combined</h3>



<p>Given those two, it might seem that avoiding branches seems reasonable, and the common advice of avoiding ifs makes sense. But whether it makes sense to avoid branch or not is more complicated (more on it later), and the second one (whether an if is a branch) is not the case.</p>



<h2>Are if statements branches?</h2>



<p>Let‚Äôs clear the worst misconception.</p>



<p><strong>When you write an ‚Äúif‚Äù in your code, the compiler won‚Äôt necessarily generate a branch with a jump</strong>.</p>



<p>I will focus now on CPUs, mostly because how easy it is to test it with <a href="https://godbolt.org/">Matt Godbolt‚Äôs amazing compiler explorer</a>. üôÇ (Plus how there are two mainstream architectures, unlike many different shader ISAs)</p>



<p>Let‚Äôs have a look at the following simple integer function.</p>


<pre title="">int is_this_a_branch(int v, int w) {
    if (v &lt; 10) {
        return v + w; 
    } 
    else {
        return 2 * v - 2 * w;
    }
}
</pre>


<p>I tested it with 3 x64 compilers (GCC x64 trunk, Clang x64 trunk, MSVC 19.28) and one ARM (armv8-a clang), and only MSVC generates an actual branch there.</p>



<pre><code><strong>clang</strong>              
        mov     eax, edi
        sub     eax, esi
        add     esi, edi
        add     eax, eax
        cmp     edi, 10
        cmovl   eax, esi
        ret
<strong>gcc</strong>
        mov     eax, edi
        lea     edx, [rdi+rsi]
        sub     eax, esi
        add     eax, eax
        cmp     edi, 9
        cmovle  eax, edx
        ret
<strong>msvc </strong>       
        cmp     ecx, 10
        <strong>jge     SHORT $LN2@is_this_a_ BRANCH!!!
</strong>   BRANCH!
        lea     eax, DWORD PTR [rcx+rdx]
        ret     0
$LN2@is_this_a_:
        sub     ecx, edx
        lea     eax, DWORD PTR [rcx+rcx]
        ret     0

<strong>arm clang
</strong>        sub     w9, w0, w1
        add     w8, w1, w0
        lsl     w9, w9, #1
        cmp     w0, #10                         // =10
        csel    w0, w8, w9, lt</code></pre>



<p>When using floats:</p>


<pre title="">float is_this_a_branch2(float v, float w) {
    if (v &lt; 10.0f) {
        return v + w; 
    } 
    else {
        return 2.0f * v - 2.0f * w;
    }
}
</pre>


<p>Now 2 out of 4 compilers generate a branch:</p>



<pre><code><strong>clang</strong>           
        movaps  xmm2, xmm0
        addss   xmm2, xmm1
        movaps  xmm3, xmm0
        addss   xmm3, xmm0
        addss   xmm1, xmm1
        cmpltss xmm0, dword ptr [rip + .LCPI1_0]
        subss   xmm3, xmm1
        andps   xmm2, xmm0
        andnps  xmm0, xmm3
        orps    xmm0, xmm2
        ret

<strong>gcc
</strong>        movss   xmm2, DWORD PTR .LC0[rip]
        comiss  xmm2, xmm0
        <strong>jbe     .L10  BRANCH!!!
</strong>
        addss   xmm0, xmm1
        ret
.L10:
        addss   xmm1, xmm1
        addss   xmm0, xmm0
        subss   xmm0, xmm1
        ret

<strong>msvc
</strong>        movss   xmm2, DWORD PTR __real@41200000
        comiss  xmm2, xmm0
        <strong>jbe     SHORT $LN2@is_this_a_  BRANCH!!!</strong>
        addss   xmm0, xmm1
        ret     0
$LN2@is_this_a_:
        addss   xmm0, xmm0
        addss   xmm1, xmm1
        subss   xmm0, xmm1
        ret     0

<strong>arm clang
</strong>        fadd    s2, s0, s1
        fadd    s3, s0, s0
        fadd    s1, s1, s1
        fmov    s4, #10.00000000
        fsub    s1, s3, s1
        fcmp    s0, s4
        fcsel   s0, s2, s1, mi
        ret</code></pre>



<h3>What are those conditionals and selects?</h3>



<p>This is basically CPUs‚Äô and compilers‚Äô way of ‚Äúserializing‚Äù both code paths. If it considers overhead of a branch larger than the amount of work it can save, it makes sense to compute both code paths, and use a single instruction to select which one is the actual result.</p>



<p>This obviously ‚Äúdepends‚Äù on the use case and whether it is even ‚Äúlegal‚Äù for a compiler to do such a transformation (like ‚Äúside effects‚Äù; or if a compiler executed some reads of memory, it could be unsafe and lead to segmentation fault).&nbsp;</p>



<h2>Does writing ternary conditional help avoid branches?</h2>



<p><strong>No.</strong></p>



<p>This is a common advice, but it‚Äôs generally not true. If you look at the above example rewritten slightly:</p>


<pre title="">float is_this_a_branch3(float v, float w) {
    return v &lt; 10.0f ? (v + w) : (2.0f * v - 2.0f * w);
}
</pre>


<p>The generated code is <strong>identical </strong>(!).</p>



<p>It might be <em>possible</em> (?) that some compilers do generate branchless code for like this, but giving this as a general advice makes no sense. Whether you write an actual if, or a ternary expression, it‚Äôs still a high level if statement, just expressed differently.</p>



<h2>What about the GPU?</h2>



<p><strong>On the GPU, it‚Äôs the same; the compiler will generate conditional selects when appropriate.</strong></p>



<p>I used <a href="http://shader-playground.timjones.io/">Tim Jones Shader Playground</a> and AMD ISA (mostly because I know it relatively better than the others), and the unfortunate step function:</p>


<pre title="">#version 460

layout (location = 0) out vec4 fragColor;
layout (location = 0) in float inColor;

void main()
{
#if 1
	fragColor = vec4(step(1.0, inColor));
#else
    float x;
    if (inColor &lt; 1.0)
        x = 1.0;
   	else
        x = 0.0;
   	fragColor = vec4(x);
#endif
}
</pre>


<p>See for yourself, both versions generate identical assembly:</p>



<pre><code>  s_mov_b32     m0, s3
  s_nop         0x0000
  v_interp_p1_f32  v0, v0, attr0.x
  v_interp_p2_f32  v0, v1, attr0.x
  v_cmp_gt_f32  vcc, 1.0, v0
  v_cndmask_b32  v0, 1.0, 0, vcc
  v_cvt_pkrtz_f16_f32  v0, v0, v0
  exp           mrt0, v0, v0, v0, v0 done compr vm</code></pre>



<p>When using fastmath and not obeying strict IEEE float specification (which is standard for compiling shaders for real time graphics), compilers can even generate other instructions like min or max from your if statements. But YMMV and be sure to check the assembly.</p>



<p>So generally ‚Äì using ‚Äústep‚Äù just to avoid if statements is <strong>pointless</strong>.</p>



<p>If you like it for your coding style, then it‚Äôs obviously up to you, use as much as you like just for this reason. But please consider programmers who don‚Äôt have as much shader or GLSL experience and will be always puzzled by it. üôÇ </p>



<h2>Are branches always to be avoided?</h2>



<p><strong>No.</strong></p>



<p>This is way beyond my aimed ‚Äúshort‚Äù format, but <strong>branches are not necessarily ‚Äúbad‚Äù</strong>.</p>



<p>They can be actually an awesome optimization, even on the GPU!</p>



<p>If you start to use a lot of conditionals</p>



<p>Lots of advice on how branches are bad and have to be avoided comes from a prehistoric era of old CPUs and GPUs or old compilers; an advice that is passed without re(verifying) ‚Äì which is understandable, I am not re-checking my whole knowledge or intuition every few months either. üôÇ </p>



<p>But the CPU/GPU/compiler architects improved designs significantly and adapted them to general, highly branchy code, and whether there is a penalty or not depends on way too many details to list or give advice.</p>



<p><strong>Rule of thumb</strong>: if a branch is generally coherent, it makes sense to use it when it allows to save on memory bandwidth or cache utilization. On GPUs it is usually worth adding branches if you can avoid texture fetches this way with a high probability and coherence. And it‚Äôs usually better to have some conditional masks and selects around ‚Ä¶</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://bartwronski.com/2021/01/18/is-this-a-branch/">https://bartwronski.com/2021/01/18/is-this-a-branch/</a></em></p>]]>
            </description>
            <link>https://bartwronski.com/2021/01/18/is-this-a-branch/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26141047</guid>
            <pubDate>Mon, 15 Feb 2021 09:52:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Interactive Data Visualisation with Rust]]>
            </title>
            <description>
<![CDATA[
Score 81 | Comments 12 (<a href="https://news.ycombinator.com/item?id=26141018">thread link</a>) | @batterylow
<br/>
February 15, 2021 | https://shahinrostami.com/posts/programming/rust-notebooks/visualisation-of-co-occurring-types/ | <a href="https://web.archive.org/web/*/https://shahinrostami.com/posts/programming/rust-notebooks/visualisation-of-co-occurring-types/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<pre>[[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]]</pre>
</div></div>]]>
            </description>
            <link>https://shahinrostami.com/posts/programming/rust-notebooks/visualisation-of-co-occurring-types/</link>
            <guid isPermaLink="false">hacker-news-small-sites-26141018</guid>
            <pubDate>Mon, 15 Feb 2021 09:49:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Security features of the Intel/Windows platform secure boot process]]>
            </title>
            <description>
<![CDATA[
Score 27 | Comments 2 (<a href="https://news.ycombinator.com/item?id=26140122">thread link</a>) | @ingve
<br/>
February 14, 2021 | https://igor-blue.github.io/2021/02/04/secure-boot.html | <a href="https://web.archive.org/web/*/https://igor-blue.github.io/2021/02/04/secure-boot.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section itemprop="text">
        
        <ul id="markdown-toc">
  <li><a href="#introduction-and-system-architecture" id="markdown-toc-introduction-and-system-architecture">Introduction and System Architecture</a>    <ul>
      <li><a href="#buses" id="markdown-toc-buses">Buses</a></li>
      <li><a href="#more-components" id="markdown-toc-more-components">More Components</a></li>
      <li><a href="#the-flash-chip" id="markdown-toc-the-flash-chip">The Flash Chip</a></li>
    </ul>
  </li>
  <li><a href="#overview" id="markdown-toc-overview">Overview</a></li>
  <li><a href="#early-power-on" id="markdown-toc-early-power-on">Early power on</a></li>
  <li><a href="#bring-up-bup" id="markdown-toc-bring-up-bup">Bring-Up (BUP)</a></li>
  <li><a href="#cpu-initialization" id="markdown-toc-cpu-initialization">CPU initialization</a></li>
  <li><a href="#uefi-initialization" id="markdown-toc-uefi-initialization">UEFI initialization</a>    <ul>
      <li><a href="#loading-the-boot-loader" id="markdown-toc-loading-the-boot-loader">Loading the boot loader</a></li>
    </ul>
  </li>
  <li><a href="#windows-boot" id="markdown-toc-windows-boot">Windows Boot</a>    <ul>
      <li><a href="#winload" id="markdown-toc-winload">Winload</a></li>
      <li><a href="#hvci" id="markdown-toc-hvci">HVCI</a></li>
      <li><a href="#dynamic-root-of-trust-model-drtm" id="markdown-toc-dynamic-root-of-trust-model-drtm">Dynamic Root of Trust Model (DRTM)</a></li>
      <li><a href="#uefi-memory-attributes-table" id="markdown-toc-uefi-memory-attributes-table">UEFI Memory Attributes Table</a></li>
    </ul>
  </li>
  <li><a href="#other-oss" id="markdown-toc-other-oss">Other OSs</a></li>
  <li><a href="#more-protections" id="markdown-toc-more-protections">More Protections</a>    <ul>
      <li><a href="#iommu-and-dma-protections" id="markdown-toc-iommu-and-dma-protections">IOMMU and DMA protections</a></li>
      <li><a href="#secure-devices" id="markdown-toc-secure-devices">Secure Devices</a></li>
      <li><a href="#smm" id="markdown-toc-smm">SMM</a></li>
      <li><a href="#memory-reset-protections" id="markdown-toc-memory-reset-protections">Memory Reset protections</a></li>
    </ul>
  </li>
</ul>

<p>This blog post is an in-depth dive into the security features of the Intel/Windows platform boot process. In this post I'll explain the startup process through security focused lenses, next post we'll dive into several known attacks and how they were handled by Intel and Microsoft. My wish is to explain to technology professionals not deep into platform security why Microsoft's SecureCore is so important and necessary.</p>



<p>We must first begin with a brief introduction to the hardware platform. Skip this if you have read the awsome material available on the web about the Intel architecture, I'll try to briefly summarize it here.</p>

<p>The Intel platform is based on one or two chips. Small systems have one, the desktop and server ones are separated to a CPU complex and a PCH complex (PCH = Platform Controller Hub).</p>

<p><img src="https://igor-blue.github.io/images/image2020-4-19_14-3-0.png" alt="Intel architecture"></p>

<p>The CPU complex deals with computation. It holds the "processor" cores, e.g. Sunny Cove that implement the ISA, as well as cross core caches like the L3 cache, and more controllers that are grouped together as "the system agent" or the "uncore". The uncore contains the memory controller and display, e.g. GPU and display controller.</p>

<p>The PCH handles all other IO, including access to the firmware through SPI or eSPI, wifi, LAN, USB, HD audio, SMBus, thunderbolt and etc'. The PCH also hosts several embedded processors, like the PMC, the Power Management Controller.</p>

<p>An additional part of the PCH is a very important player in our story, the CSME, or Converged Security &amp; Management Engine, a i486 IP block (also called Minute IA). CSME is responsibly for much of the security model of Intel processors as well as many of the manageability features of the platform. The CSME block has its own dedicated ~1.5mb of SRAM memory and 128KB of ROM, as well as a dedicated IOMMU, called the A-Unit (that even has its own <em>acode</em> microcode) located in the CSME's <em>uncore</em>', thats allows access from ME to the main memory, as well as DMA to/from the main memory and using the main memory as an encrypted paging area ("virtual memory"). The CSME engine runs a customized version of the Minix3 microkernel, also recent versions have changed it beyond recognition adding many security features.</p>

<p><img src="https://igor-blue.github.io/images/image2020-4-19_14-14-4.png" alt="CSME structure"></p>

<h2 id="buses">Buses</h2>
<p>Lets use this post to also introduce the main interconnects in the system. The main externally facing interconnect bus is PCI-E, a fast bust that can reach 64GBps in its latest incarnations. A second external bus is the LPC, or Low Pin Count bus, a slow bus for connecting devices such as SPI flash, the TPM (explained below), and old peripherals such as PS/2 touchpads.</p>

<p>Internally the platform is based around the <strong>IOSF</strong>, or Intel On-chip System Fabric, which is a pumped up version of PCI-E that supports many additional security and addressing features. For addressing IOSF adds SourceID and DestID fields that contain the source and destination of any IOSF transaction, extending PCI-E Bus-Device-Function (BDF) addressing to enable routing over bridges. IOSF also extends addressing by adding support for multiple address root namespaces, currently defining three: RS0 for host memory space, RS1 for CSME memory space, and RS2 for the Innovation-Engine (IE), another embedded controller currently present only on server chipsets.
There are two IOSF busses in the PCH - the Primary Fabric and the Sideband Fabric. The Primary Fabric is high speed, connecting the CPU to the PCH (through a protocol call DMI), as well as high speed devices such as Gigbait Ethernet, WiFi and eSPI. The Sideband Fabric is used to connect the CSME to low-speed devices, including the PMC (Power Management Controller), the RNG generator, GPIO pins, USB, SMBus, and even debugging interfaces such as JTAG.</p>

<h2 id="more-components">More Components</h2>
<p>Another interesting component is the <strong>ITH</strong>, or Intel Trace Hub, which is codenamed North Peak (NPK). The ITH can trace different internal hardware component (VIA - Visualization of Internal Signals, ODLA - On-chip logic analyzer, SoCHAP - SOC performance counters, IPT - Intel Process Trace, AET - Intel Architecture Trace), and external component like CSME, the UEFI firmware, and you can even connect it to ETW. This telemetry eventually finds its way to Intel in various methods.</p>

<p><img src="https://igor-blue.github.io/images/image2020-4-22_0-52-2.png" alt="Intel Trace Hub"></p>

<p>The <strong>TPM</strong> is designed to provide a tamper proof environment to enforce system security through hardware. It implements in hardware many essential functions: sha1 &amp; sha256 hashing algorithms, many crypto and key derivation functions, measurment registers call the Platform Configuration Registers (PCRs), a secret key - Endorsment Key - used to derive all other keys, and non-volatile storage slots for storing keys and hashes. Discrete TPM chips (i.e. those that are a separate chip on the mainboard or SOC and connected through the LPC) are call dTPMs, or can be implemented in the CSME module's firmware and called fTPMs.</p>

<p>The TPM's <strong>PCR</strong> are initialized to zero when the platform boots and are filled up with measurements through the boot process. PCRs 0-15 are intended for "static" use - they reset when the platform boots; They are supposed to give the OS loader a view of the platform initialization state.
PCRs 17-22 are for "dynamic" use - they get reset on each secure launch (GETSEC[SENTER]); They are supposed to be used by the attestation sofware that checks if the OS is trusted.</p>

<h2 id="the-flash-chip">The Flash Chip</h2>
<p>SPI flash has 5 major regions: the Descriptor regions, the CSME region, the Gigabit Ethernet Region, the Platform Data Region, and the UEFI region. In the image below you can see an example of how the flash is organized.</p>

<p><img src="https://igor-blue.github.io/images/image2019-11-11_1-18-53_1.png" alt="Partition regions in SPI flash">
<img src="https://igor-blue.github.io/images/image2019-11-11_1-19-12.png" alt="Serial flash sizes"></p>

<p>Later versions added more regions:</p>

<p><img src="https://igor-blue.github.io/images/image2019-11-25_22-49-41.png" alt="SPI region evolution"></p>

<p>These regions are categorized as fault tolerant (FTPs) and non fault tolerant partitions (NFTPs).
Fault tolerant partitions are critical for boot, and verified during early boot (like the RBE, the CSME ROM Boot extensions will discuss in a few paragraphs). If verification fails - the system does not boot. Examples of non fault tolerant partitions are the Integrated Sensor Hub (or ISH) firmware.</p>

<p>SPI flash protection is applied at multiple levels: On the flash chip itself, in the SPI flash controller (in the PCH), in UEFI code and in CSME code.</p>

<p>The SPI controller maps the entire flash to memory at a fixed address, so reads/writes are usually done simply by reading/writing memory. The SPI controller translates this to flash-specific commands issued on the SPI bus, using a table of flash-specific commands stored in the flash descriptor region.
This is called "Hardware Sequencing", meaning the SPI controller issues the actual SPI commands
When hardware sequencing is in use, the SPI controller enforces several flash protections based on the masters region table in the flash (but can be overriden using a hardware PIN).</p>

<p>The SPI controller also implements a FLOCKDN flag. FLOCKDN is a write-once bit that, when set, disables use of software sequencing and modification of the PR registers until the next reset. The CSME sets this in the Bring-UP process (bup_storage_lock_spi_configuration(), see below). This happens when the UEFI notifies it that it is at the end of POST. In addition to the region access control table, the SPI controller also has an option to globally protect up to five regions in the flash from write access by the host using five registers, called Protected Registers (PRs), which are intended for the UEFI firmware to protect itself from modification while the OS is running.</p>

<p>It is also possible to issue direct flash commands using "Software Sequencing" by writing to the OPTYPE/OPMENU registers, since this can be used circumvent the SPI-enforced protections, software sequencing is usually disabled after POST using the FLOCKDN bit.</p>

<p>How is the flash updated?</p>

<p>UEFI region is updated through an UEFI capsule, This update happens during POST, before PRs and FLOCKDN is set, therefore, the BIOS region is still accessible to UEFI code.</p>

<p>Many OEMS have then own UEFI anti-tamper protections. For example, HP has SureStart on laptops and workstations, and Dell has TrustedDevice SafeBIOS. SafeBIOS copies bad firmware images to the EFI system partition, and the Dell Trusted Device software on Windows sends their hashes plus the hash of the UEFI firmware currently in memory to a Dell cloud server (*.delltrusteddevicesecurity.com) to check against a list of "authorized" hashes. Server platforms have similiar protections, including iLO for HP and iDRAC in Dell.
The CSME region can usually be updated only from within the CSME. However, for more complicated upgrades CSME can temporarily unlock the ME region for host read &amp; write.</p>


<p>In the next sections we'll look over all the stages of boot.
<img src="https://igor-blue.github.io/images/image2020-4-20_14-56-23.png" alt="Serial flash sizes"></p>


<p>Boot starts the PMC, the Power Management Controller.
In modern Intel systems the PMC is an ARC core and its the first controller to execute code once electricity is applied to the system. We'll talk more about PMC in a later post as its quiet interesting and has its own microcode and firmware, and event generates telemetry over the IOSF SB bus (which we'll talk about in a moment).</p>

<p>While the PMC does its init, the rest of the system is held at bay at a RESET state.</p>

<p>The next part to start running is the CSME. Recall from the first post in the series, CSME, or Converged Security and Managment Engine is a MinuteIA (i486 CPU IP block) embedded in the Platform Controller Hub (PCH).
The CSME begins running from its own embedded 128KB ROM - the CSME-ROM. This ROM is protected with a hardware fuse that is burned by Intel during production.
When started the CSME ROM starts like a regular 486 processor BIOS - in the reset vector in real mode. Its first order of business is to ‚Ä¶</p></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://igor-blue.github.io/2021/02/04/secure-boot.html">https://igor-blue.github.io/2021/02/04/secure-boot.html</a></em></p>]]>
            </description>
            <link>https://igor-blue.github.io/2021/02/04/secure-boot.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-26140122</guid>
            <pubDate>Mon, 15 Feb 2021 07:34:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Good Ideas, Through the Looking Glass (PDF, 2005)]]>
            </title>
            <description>
<![CDATA[
Score 37 | Comments 2 (<a href="https://news.ycombinator.com/item?id=26138218">thread link</a>) | @benhoyt
<br/>
February 14, 2021 | https://people.inf.ethz.ch/wirth/Articles/GoodIdeas_origFig.pdf | <a href="https://web.archive.org/web/*/https://people.inf.ethz.ch/wirth/Articles/GoodIdeas_origFig.pdf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://people.inf.ethz.ch/wirth/Articles/GoodIdeas_origFig.pdf</link>
            <guid isPermaLink="false">hacker-news-small-sites-26138218</guid>
            <pubDate>Mon, 15 Feb 2021 02:00:06 GMT</pubDate>
        </item>
    </channel>
</rss>
