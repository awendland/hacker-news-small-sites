<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 20]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 20. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Tue, 21 Jul 2020 08:18:02 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-20.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Tue, 21 Jul 2020 08:18:02 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[Optimizing 128-bit Division]]>
            </title>
            <description>
<![CDATA[
Score 22 | Comments 3 (<a href="https://news.ycombinator.com/item?id=23888177">thread link</a>) | @EvgeniyZh
<br/>
July 19, 2020 | https://danlark.org/2020/06/14/128-bit-division/ | <a href="https://web.archive.org/web/*/https://danlark.org/2020/06/14/128-bit-division/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">

	<section id="primary">
		<main id="main">

			
<article id="post-288">

	

	
	<div>
		
<p>When it comes to hashing, sometimes 64 bit is not enough, for example, because of <a href="https://en.wikipedia.org/wiki/Birthday_problem">birthday paradox</a> ‚Äî the hacker can iterate through random <img src="https://s0.wp.com/latex.php?latex=2%5E%7B32%7D&amp;bg=ffffff&amp;fg=111111&amp;s=0" alt="2^{32}" title="2^{32}"> entities and it can be proven that with some constant probability they will find a collision, i.e. two different objects will have the same hash. <img src="https://s0.wp.com/latex.php?latex=2%5E%7B32%7D&amp;bg=ffffff&amp;fg=111111&amp;s=0" alt="2^{32}" title="2^{32}"> is around 4 billion objects and with the current power capacity in each computer it is certainly achievable. That‚Äôs why we need sometimes to advance the bitness of hashing to at least 128 bits. Unfortunately, it comes with a cost because platforms and CPUs do not support 128 bit operations natively.</p>



<p>Division historically is the most complex operation on CPUs and all guidelines suggest avoiding the division at all costs.</p>



<p>At my job I faced an interesting problem of optimizing 128 bit division from <a href="https://github.com/abseil/abseil-cpp/blob/master/absl/numeric/int128.cc#L155">abseil library</a> in order to split some data across buckets with the help of 128 bit hashing (the number of buckets is not fixed for some uninteresting historical reasons). I found out that the division takes a really long time. The <a href="https://github.com/abseil/abseil-cpp/blob/master/absl/numeric/int128_benchmark.cc#L52">benchmarks</a> from abseil on Intel(R) Xeon(R) W-2135 CPU @ 3.70GHz show some horrible results</p>



<pre><code>Benchmark                       Time(ns)  CPU(ns)
BM_DivideClass128UniformDivisor     13.8     13.8  // 128 bit by 128 bit
BM_DivideClass128SmallDivisor        168      168  // 128 bit by 64 bit</code></pre>



<p>150 nanoseconds for dividing the random 128 bit number by a random 64 bit number? Sounds crazy. For example, <code>div</code> instruction on x86-64 Skylake takes 76 cycles (also, for AMD processors it is much less), the division takes around 20-22ns.</p>



<figure><img data-attachment-id="361" data-permalink="https://danlark.org/d2elnjfdkne/" data-orig-file="https://danlarkorg.files.wordpress.com/2020/06/d2elnjfdkne.png" data-orig-size="921,461" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="d2elnjfdkne" data-image-description="" data-medium-file="https://danlarkorg.files.wordpress.com/2020/06/d2elnjfdkne.png?w=300" data-large-file="https://danlarkorg.files.wordpress.com/2020/06/d2elnjfdkne.png?w=750" src="https://danlarkorg.files.wordpress.com/2020/06/d2elnjfdkne.png?w=921" alt="" srcset="https://danlarkorg.files.wordpress.com/2020/06/d2elnjfdkne.png 921w, https://danlarkorg.files.wordpress.com/2020/06/d2elnjfdkne.png?w=150 150w, https://danlarkorg.files.wordpress.com/2020/06/d2elnjfdkne.png?w=300 300w, https://danlarkorg.files.wordpress.com/2020/06/d2elnjfdkne.png?w=768 768w" sizes="(max-width: 921px) 100vw, 921px"><figcaption><a href="https://godbolt.org/z/o2vTZr">https://godbolt.org/z/o2vTZr</a></figcaption></figure>



<p>In reality everything is slightly better because of pipeline execution and division has its own ALU, so if you divide something and do something else in the next instructions, you will get lower average latency. Still, 128 bit division cannot be 8x slower than 64 bit division. All latencies you can find in Agner Fog <a href="https://www.agner.org/optimize/instruction_tables.pdf">instruction table</a> for most of the modern x86 CPUs. The truth is more complex and division latency can even depend on the values given.</p>



<figure><img data-attachment-id="299" data-permalink="https://danlark.org/2020-06-14-182043_835x215_scrot/" data-orig-file="https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-182043_835x215_scrot.png" data-orig-size="835,215" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="2020-06-14-182043_835x215_scrot" data-image-description="" data-medium-file="https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-182043_835x215_scrot.png?w=300" data-large-file="https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-182043_835x215_scrot.png?w=750" src="https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-182043_835x215_scrot.png?w=835" alt="" srcset="https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-182043_835x215_scrot.png 835w, https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-182043_835x215_scrot.png?w=150 150w, https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-182043_835x215_scrot.png?w=300 300w, https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-182043_835x215_scrot.png?w=768 768w" sizes="(max-width: 835px) 100vw, 835px"><figcaption>Agner Fog instruction table for Skylake CPUs, the second but last column is the latency.</figcaption></figure>



<p>Even compilers when dividing by some constants, try to use the reciprocal (or, the same as inverse in a ring) value and multiply the reciprocal and the value with some shifts afterwards</p>



<figure><img data-attachment-id="315" data-permalink="https://danlark.org/2020-06-14-192300_861x251_scrot/" data-orig-file="https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-192300_861x251_scrot.png" data-orig-size="861,251" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="2020-06-14-192300_861x251_scrot" data-image-description="" data-medium-file="https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-192300_861x251_scrot.png?w=300" data-large-file="https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-192300_861x251_scrot.png?w=750" src="https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-192300_861x251_scrot.png?w=861" alt="" srcset="https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-192300_861x251_scrot.png 861w, https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-192300_861x251_scrot.png?w=150 150w, https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-192300_861x251_scrot.png?w=300 300w, https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-192300_861x251_scrot.png?w=768 768w" sizes="(max-width: 861px) 100vw, 861px"><figcaption><a href="https://gcc.godbolt.org/z/PRibsx">https://gcc.godbolt.org/z/PRibsx</a></figcaption></figure>



<p>Overall, given the fact that only some <code>sin</code>, <code>cos</code> instructions cost more than division, division is one of the most complex instructions in CPUs and optimizations in that place matter a lot. My exact case was more or less general, maybe I was dividing 128 bit by 64 bit a bit more frequent. We are going to optimize the general case in LLVM.</p>



<p>We need to understand how 128 bit division is working through the compiler stack.</p>



<figure><img data-attachment-id="303" data-permalink="https://danlark.org/2020-06-14-183125_682x238_scrot/" data-orig-file="https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-183125_682x238_scrot.png" data-orig-size="682,238" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="2020-06-14-183125_682x238_scrot" data-image-description="" data-medium-file="https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-183125_682x238_scrot.png?w=300" data-large-file="https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-183125_682x238_scrot.png?w=682" src="https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-183125_682x238_scrot.png?w=682" alt="" srcset="https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-183125_682x238_scrot.png 682w, https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-183125_682x238_scrot.png?w=150 150w, https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-183125_682x238_scrot.png?w=300 300w" sizes="(max-width: 682px) 100vw, 682px"><figcaption><a href="https://gcc.godbolt.org/z/fB3aq2">https://gcc.godbolt.org/z/fB3aq2</a></figcaption></figure>



<p>It calls <code>__udivti3</code> function. Let‚Äôs first understand how to read these functions. In runtime libraries the modes of the functions are:</p>



<div><div>
<pre><code>QI: An integer that is as wide as the smallest addressable unit, usually 8 bits.
HI: An integer, twice as wide as a QI mode integer, usually 16 bits.
SI: An integer, four times as wide as a QI mode integer, usually 32 bits.
DI: An integer, eight times as wide as a QI mode integer, usually 64 bits.
SF: A floating point value, as wide as a SI mode integer, usually 32 bits.
DF: A floating point value, as wide as a DI mode integer, usually 64 bits.
TI: An integer, 16 times as wide as a QI mode integer, usually 128 bits.</code></pre>
</div></div>



<p>So, <code>udivti3</code> is an <strong>u</strong>nsigned division of TI (128 bits) integers, last ‚Äò<em>3‚Ä≤</em> means that it has 3 arguments including the return value. Also, there is a function <code>__udivmodti4</code> which computes the divisor and the remainder (division and modulo operation) and it has 4 arguments including the returning value. These functions are a part of runtime libraries which compilers provide by default. For example, in GCC it is <a href="http://gcc.gnu.org/onlinedocs/gccint/Libgcc.html#Libgcc">libgcc</a>, in LLVM it is <a href="https://compiler-rt.llvm.org/">compiler-rt</a>, they are linked almost in every program if you have the corresponding toolchain. In LLVM, <code>__udivti3</code> is a simple alias to <code>__udivmodti4</code>.</p>



<figure><div>

</div></figure>



<p><code><a href="https://github.com/llvm-mirror/compiler-rt/blob/release_90/lib/builtins/udivmodti4.c#L20">__udivmodti4</a></code> function was written with the help of <code>Translated from Figure 3-40 of The PowerPC Compiler Writer's Guide.</code> After looking at it <a href="https://cr.yp.to/2005-590/powerpc-cwg.pdf">here</a>, it looks like this was written long time ago and things have changed since then</p>



<figure><img data-attachment-id="313" data-permalink="https://danlark.org/2020-06-14-191400_1038x718_scrot/" data-orig-file="https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-191400_1038x718_scrot.png" data-orig-size="1038,718" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="2020-06-14-191400_1038x718_scrot" data-image-description="" data-medium-file="https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-191400_1038x718_scrot.png?w=300" data-large-file="https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-191400_1038x718_scrot.png?w=750" src="https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-191400_1038x718_scrot.png?w=1024" alt="" srcset="https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-191400_1038x718_scrot.png?w=1024 1024w, https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-191400_1038x718_scrot.png?w=150 150w, https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-191400_1038x718_scrot.png?w=300 300w, https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-191400_1038x718_scrot.png?w=768 768w, https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-191400_1038x718_scrot.png 1038w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<p>First of all, let‚Äôs come up with something easy, like shift-subtract algorithm that we have been learning since childhood. First, if <code>divisor &gt; dividend</code>, then the quotient is zero and remainder is the <code>dividend</code>, not an interesting case. </p>



<figure><div>

</div></figure>



<p>The algorithm is easy, we align the numbers by their most significant bits, if dividend is more than divisor, subtract and add 1 to the output, then shift by 1 and repeat.  Some sort of animation can be seen like that:</p>



<figure><img data-attachment-id="318" data-permalink="https://danlark.org/simplescreenrecorder-2020-06-14_20-23-25/" data-orig-file="https://danlarkorg.files.wordpress.com/2020/06/simplescreenrecorder-2020-06-14_20.23.25.gif" data-orig-size="918,442" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="simplescreenrecorder-2020-06-14_20.23.25" data-image-description="" data-medium-file="https://danlarkorg.files.wordpress.com/2020/06/simplescreenrecorder-2020-06-14_20.23.25.gif?w=300" data-large-file="https://danlarkorg.files.wordpress.com/2020/06/simplescreenrecorder-2020-06-14_20.23.25.gif?w=750" src="https://danlarkorg.files.wordpress.com/2020/06/simplescreenrecorder-2020-06-14_20.23.25.gif?w=918" alt=""></figure>



<p>For 128 bit division it will take at most 128 iterations in the for loop. Actually, the implementation in <a href="https://github.com/llvm-mirror/compiler-rt/blob/release_90/lib/builtins/udivmodti4.c#L173">LLVM</a> for loop is a fallback and we saw it takes 150+ns to complete it because it requires to shift many registers because 128 bit numbers are represented as two registers.</p>



<p>Now, let‚Äôs dive into the architecture features. I noticed that while the compiler generates the <code>divq</code> instructions, it frees <code>rdx</code> register</p>



<figure><img data-attachment-id="362" data-permalink="https://danlark.org/2ugj4bgvw4x/" data-orig-file="https://danlarkorg.files.wordpress.com/2020/06/2ugj4bgvw4x.png" data-orig-size="891,206" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="2ugj4bgvw4x" data-image-description="" data-medium-file="https://danlarkorg.files.wordpress.com/2020/06/2ugj4bgvw4x.png?w=300" data-large-file="https://danlarkorg.files.wordpress.com/2020/06/2ugj4bgvw4x.png?w=750" src="https://danlarkorg.files.wordpress.com/2020/06/2ugj4bgvw4x.png?w=891" alt="" srcset="https://danlarkorg.files.wordpress.com/2020/06/2ugj4bgvw4x.png 891w, https://danlarkorg.files.wordpress.com/2020/06/2ugj4bgvw4x.png?w=150 150w, https://danlarkorg.files.wordpress.com/2020/06/2ugj4bgvw4x.png?w=300 300w, https://danlarkorg.files.wordpress.com/2020/06/2ugj4bgvw4x.png?w=768 768w" sizes="(max-width: 891px) 100vw, 891px"></figure>



<p>In the manual they say the following</p>



<figure><img data-attachment-id="322" data-permalink="https://danlark.org/2020-06-14-204644_860x119_scrot/" data-orig-file="https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-204644_860x119_scrot.png" data-orig-size="860,119" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="2020-06-14-204644_860x119_scrot" data-image-description="" data-medium-file="https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-204644_860x119_scrot.png?w=300" data-large-file="https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-204644_860x119_scrot.png?w=750" src="https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-204644_860x119_scrot.png?w=860" alt="" srcset="https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-204644_860x119_scrot.png 860w, https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-204644_860x119_scrot.png?w=150 150w, https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-204644_860x119_scrot.png?w=300 300w, https://danlarkorg.files.wordpress.com/2020/06/2020-06-14-204644_860x119_scrot.png?w=768 768w" sizes="(max-width: 860px) 100vw, 860px"></figure>



<p><code>divq</code> instruction provides 128 bit division from [%rdx]:[%rax] by <code>S</code>. The quotient is stored in <code>%rax</code> and the remainder in <code>%rdx</code>. After some experimenting with inline asm in C/C++, I figured out that if the result does not fit in 64 bits, SIGFPE is raised. See:</p>



<figure><div>

</div></figure>



<p>Compilers don‚Äôt use this instruction in 128 bit division because they cannot know for sure if the result is going to fit in 64 bits. Yet, if the high 64 bits of the 128 bit number is smaller than the divisor, the result fits into 64 bits and we can use this instruction. As compilers don‚Äôt generate <code>div</code>q instruction for their own reasons, we would use inline asm for x86-64.</p>



<figure><div>

</div></figure>



<p>What to do if the high is not less than the divisor? The right answer is to use 2 divisions because</p>



<figure><img data-attachment-id="325" data-permalink="https://danlark.org/2020-06-11-135245_1608x410_scrot/" data-orig-file="https://danlarkorg.files.wordpress.com/2020/06/2020-06-11-135245_1608x410_scrot.png" data-orig-size="1608,410" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="2020-06-11-135245_1608x410_scrot" data-image-description="" data-medium-file="https://danlarkorg.files.wordpress.com/2020/06/2020-06-11-135245_1608x410_scrot.png?w=300" data-large-file="https://danlarkorg.files.wordpress.com/2020/06/2020-06-11-135245_1608x410_scrot.png?w=750" src="https://danlarkorg.files.wordpress.com/2020/06/2020-06-11-135245_1608x410_scrot.png?w=1024" alt="" width="780" height="198" srcset="https://danlarkorg.files.wordpress.com/2020/06/2020-06-11-135245_1608x410_scrot.png?w=1024 1024w, https://danlarkorg.files.wordpress.com/2020/06/2020-06-11-135245_1608x410_scrot.png?w=777 777w, https://danlarkorg.files.wordpress.com/2020/06/2020-06-11-135245_1608x410_scrot.png?w=1553 1553w, https://danlarkorg.files.wordpress.com/2020/06/2020-06-11-135245_1608x410_scrot.png?w=150 150w, https://danlarkorg.files.wordpress.com/2020/06/2020-06-11-135245_1608x410_scrot.png?w=300 300w, https://danlarkorg.files.wordpress.com/2020/06/2020-06-11-135245_1608x410_scrot.png?w=768 768w" sizes="(max-width: 780px) 100vw, 780px"></figure>



<p>So, first we can divide <code>hi</code> by <code>divisor</code> and then <code>{hi_r, lo}</code> by <code>divisor</code> guaranteeing that <code>hi_r</code> is smaller than <code>divisor</code> and thus the result is smaller than <img src="https://s0.wp.com/latex.php?latex=2%5E%7B64%7D&amp;bg=ffffff&amp;fg=111111&amp;s=0" alt="2^{64}" title="2^{64}">. We will get something like</p>



<figure><div>

</div></figure>



<p>  After that the benchmarks improved significantly</p>



<pre><code>Benchmark                       Time(ns)  CPU(ns)
BM_DivideClass128UniformDivisor 11.9      11.9
BM_DivideClass128SmallDivisor   26.6      26.6</code></pre>



<p>Only 26.6ns for small divisors, that‚Äôs a clear 6x win.</p>



<p>Then there are multiple choices to do next but we know that both dividend and divisor have at least one bit in their high registers and the shift-subtract algorithm will have at most 64 iterations. Also the quotient is guaranteed to fit in 64 bits, thus we can use only the low register of the resulting quotient and save more shifts in the shift-subtract algorithm. That‚Äôs why the uniform divisor slightly improved.</p>



<p>One more optimization to do in shift-subtract algorithm is to remove the branch inside the for loop (read carefully, it should be understandable).</p>



<figure><div>

</div></figure>



<p>In the end, it gives 0.4ns more for uniform 128 bit divisor.</p>



<p>And finally I believe that‚Äôs one of the best algorithm to divide 128 bit by 128 bit numbers. From statistics, the case when the divisor is 64 bit is worth optimizing and we showed that additional checks on the high register of divisor has its own advantages and expansion of the invariants. Now let‚Äôs see what other libraries perform in that case.</p>



<h2>LibDivide</h2>



<p><a href="https://github.com/ridiculousfish/libdivide">Libdivide</a> is a small library targeting fast division, for example, if you divide by some fixed number a lot of times, there are techniques that can precalculate reciprocal and then multiply by it. Libdivide provides a very good interface for such optimizations. Even though, it has some optimizations regarding 128 bit division. For example, function <code>libdivide_128_div_128_to_64</code> computes the division 128 bit number by 128 bit number if the result fits in 64 bits. In the case where both numbers are more or equal to <img src="https://s0.wp.com/latex.php?latex=2%5E%7B64%7D&amp;bg=ffffff&amp;fg=111111&amp;s=0" alt="2^{64}" title="2^{64}"> it does the following algorithm that they took from <a href="https://www.amazon.de/Hackers-Delight-Henry-S-Warren/dp/0321842685/ref=sr_1_1?dchild=1&amp;keywords=Hackers+Delight&amp;qid=1592164234&amp;sr=8-1">Hackers Delight</a> book:</p>



<p><img src="https://s0.wp.com/latex.php?latex=%5Cbegin%7Bcases%7D+n+%3D+MSB%28%5Cmathrm%7Bdivisor%7D%29+%5Cgeq+1+%5C%5C+%5Cmathrm%7Bdivisor_1%7D+%3D+%5Clfloor+%5Cmathrm%7Bdivisor%7D%2F2%5E%7B64+-+n%7D+%5Crfloor+%5C%5C+%5Cmathrm%7Bdividend_1%7D+%3D+%5Clfloor+%5Cmathrm%7Bdividend%7D%2F2+%5Crfloor+%5Cend%7Bcases%7D&amp;bg=ffffff&amp;fg=111111&amp;s=0" alt="\begin{cases} n = MSB(\mathrm{divisor}) \geq 1 \\ \mathrm{divisor_1} = \lfloor \mathrm{divisor}/2^{64 - n} \rfloor \\ \mathrm{dividend_1} = \lfloor \mathrm{dividend}/2 \rfloor \end{cases}" title="\begin{cases} n = MSB(\mathrm{divisor}) \geq 1 \\ \mathrm{divisor_1} = \lfloor \mathrm{divisor}/2^{64 - n} \rfloor \\ \mathrm{dividend_1} = \lfloor \mathrm{dividend}/2 \rfloor \end{cases}"></p>



<p>With the instruction that produces the 64 bit result when the divisor is 128 bit result we can compute</p>



<p><img src="https://s0.wp.com/latex.php?latex=%5Cmathrm%7Bquotient_1%7D+%3D+%5Clfloor+%5Cmathrm%7Bdividend_1%7D%2F%5Cmathrm%7Bdivisor_1%7D+%5Crfloor&amp;bg=ffffff&amp;fg=111111&amp;s=0" alt="\mathrm{quotient_1} = \lfloor \mathrm{dividend_1}/\mathrm{divisor_1} \rfloor" title="\mathrm{quotient_1} = \lfloor \mathrm{dividend_1}/\mathrm{divisor_1} \rfloor"></p>



<p>Then we compute</p>



<p><img src="https://s0.wp.com/latex.php?latex=%5Cmathrm%7Bquotient_0%7D+%3D+%5Clfloor+%5Cmathrm%7Bquotient_1%7D%2F2%5E%7B63+-+n%7D+%5Crfloor&amp;bg=ffffff&amp;fg=111111&amp;s=0" alt="\mathrm{quotient_0} = \lfloor \mathrm{quotient_1}/2^{63 - n} \rfloor" title="\mathrm{quotient_0} = \lfloor \mathrm{quotient_1}/2^{63 - n} \rfloor">.</p>



<p>It cannot overflow because <img src="https://s0.wp.com/latex.php?latex=%5Cmathrm%7Bquotient_1%7D+%3C+2%5E%7B64%7D&amp;bg=ffffff&amp;fg=111111&amp;s=0" alt="\mathrm{quotient_1} < 2^{64}" title="\mathrm{quotient_1} < 2^{64}"> because the maximum value of <img src="https://s0.wp.com/latex.php?latex=%5Cmathrm%7Bdividend_1%7D&amp;bg=ffffff&amp;fg=111111&amp;s=0" alt="\mathrm{dividend_1}" title="\mathrm{dividend_1}"> is <img src="https://s0.wp.com/latex.php?latex=2%5E%7B127%7D+-+1&amp;bg=ffffff&amp;fg=111111&amp;s=0" alt="2^{127} - 1" title="2^{127} - 1"> and minimum value of <img src="https://s0.wp.com/latex.php?latex=%5Cmathrm%7Bdivisor_1%7D&amp;bg=ffffff&amp;fg=111111&amp;s=0" alt="\mathrm{divisor_1}" title="\mathrm{divisor_1}"> is <img src="https://s0.wp.com/latex.php?latex=2%5E%7B63%7D&amp;bg=ffffff&amp;fg=111111&amp;s=0" alt="2^{63}" title="2^{63}">. Now let‚Äôs show that</p>



<p><img src="https://s0.wp.com/latex.php?latex=%5Clfloor+%5Cmathrm%7Bdividend%7D%2F%5Cmathrm%7Bdivisor%7D+%5Crfloor+%5Cleq+%5Cmathrm%7Bquotient_0%7D+%5Cleq++%5Clfloor+%5Cmathrm%7Bdividend%7D%2F%5Cmathrm%7Bdivisor%7D+%5Crfloor+%2B+1&amp;bg=ffffff&amp;fg=111111&amp;s=0" alt="\lfloor \mathrm{dividend}/\mathrm{divisor} \rfloor \leq \mathrm{quotient_0} \leq  \lfloor \mathrm{dividend}/\mathrm{divisor} \rfloor + 1" title="\lfloor \mathrm{dividend}/\mathrm{divisor} \rfloor \leq \mathrm{quotient_0} \leq  \lfloor \mathrm{dividend}/\mathrm{divisor} \rfloor + 1"></p>



<p><img src="https://s0.wp.com/latex.php?latex=%5Cmathrm%7Bquotient_0%7D+%3D+%5Cleft%5Clfloor+%5Cfrac%7B%5Cmathrm%7Bdividend%7D%7D%7B2%5E%7B64+-+n%7D%5Cmathrm%7Bdivisor_1%7D%7D+%5Cright%5Crfloor+%3D+%5Cleft%5Clfloor+%5Cfrac%7B%5Cmathrm%7Bdividend%7D%7D%7B2%5E%7B64+-+n%7D%5Cleft%5Clfloor%5Cfrac%7B%5Cmathrm%7Bdivisor%7D%7D%7B2%5E%7B64+-+n%7D%7D%5Cright%5Crfloor%7D+%5Cright%5Crfloor+%3D+%5Cleft%5Clfloor+%5Cfrac%7B%5Cmathrm%7Bdividend%7D%7D%7B%5Cmathrm%7Bdivisor%7D+-+%28%5Cmathrm%7Bdivisor%7D+%5Cmathrm%7B%5C+mod%5C+%7D+2%5E%7B64+-+n%7D%29%7D+%5Cright%5Crfloor+%3D+%5Cleft%5Clfloor+%5Cfrac%7B%5Cmathrm%7Bdividend%7D%7D%7B%5Cmathrm%7Bdivisor%7D%7D+%2B+%5Cfrac%7B%5Cmathrm%7Bdividend%7D%28%5Cmathrm%7Bdivisor%7D+%5Cmathrm%7B%5C+mod%5C+%7D+2%5E%7B64+-+n%7D%29%29%7D%7B%5Cmathrm%7Bdivisor%7D%28%5Cmathrm%7Bdivisor%7D+-+%28%5Cmathrm%7Bdivisor%7D+%5Cmathrm%7B%5C+mod%5C+%7D+2%5E%7B64+-+n%7D%29%29%7D+%5Cright%5Crfloor+%3D+%5Cleft%5Clfloor+%5Cfrac%7B%5Cmathrm%7Bdividend%7D%7D%7B%5Cmathrm%7Bdivisor%7D%7D+%2B+%5Cdelta+%5Cright%5Crfloor&amp;bg=ffffff&amp;fg=111111&amp;s=0" alt="\mathrm{quotient_0} = \left\lfloor \frac{\mathrm{dividend}}{2^{64 - n}\mathrm{divisor_1}} \right\rfloor = \left\lfloor \frac{\mathrm{dividend}}{2^{64 - n}\left\lfloor\frac{\mathrm{divisor}}{2^{64 - n}}\right\rfloor} \right\rfloor = \left\lfloor \frac{\mathrm{dividend}}{\mathrm{divisor} - (\mathrm{divisor} \mathrm{\ mod\ } 2^{64 - n})} \right\rfloor = \left\lfloor \frac{\mathrm{dividend}}{\mathrm{divisor}} + \frac{\mathrm{dividend}(\mathrm{divisor} \mathrm{\ mod\ } 2^{64 - n}))}{\mathrm{divisor}(\mathrm{divisor} - (\mathrm{divisor} \mathrm{\ mod\ } 2^{64 - n}))} \right\rfloor = \left\lfloor \frac{\mathrm{dividend}}{\mathrm{divisor}} + \delta \right\rfloor" title="\mathrm{quotient_0} = \left\lfloor \frac{\mathrm{dividend}}{2^{64 - n}\mathrm{divisor_1}} \right\rfloor = \left\lfloor \frac{\mathrm{dividend}}{2^{64 - n}\left\lfloor\frac{\mathrm{divisor}}{2^{64 - n}}\right\rfloor} \right\rfloor = \left\lfloor \frac{\mathrm{dividend}}{\mathrm{divisor} - (\mathrm{divisor} \mathrm{\ mod\ } 2^{64 - n})} \right\rfloor = \left\lfloor \frac{\mathrm{dividend}}{\mathrm{divisor}} + \frac{\mathrm{dividend}(\mathrm{divisor} \mathrm{\ mod\ } 2^{64 - n}))}{\mathrm{divisor}(\mathrm{divisor} - (\mathrm{divisor} \mathrm{\ mod\ } 2^{64 - n}))} \right\rfloor = \left\lfloor \frac{\mathrm{dividend}}{\mathrm{divisor}} + \delta \right\rfloor">.</p>



<p>Now we want to show that <img src="https://s0.wp.com/latex.php?latex=%5Cdelta+%3C+1&amp;bg=ffffff&amp;fg=111111&amp;s=0" alt="\delta < 1" title="\delta < 1">. <img src="https://s0.wp.com/latex.php?latex=%5Cdelta&amp;bg=ffffff&amp;fg=111111&amp;s=0" alt="\delta" title="\delta"> is the largest when the remainder in the numerator is as large as possible, it can be up to <img src="https://s0.wp.com/latex.php?latex=2%5E%7B64+-+n%7D+-+1&amp;bg=ffffff&amp;fg=111111&amp;s=0" alt="2^{64 - n} - 1" title="2^{64 - n} - 1">. Because of the definition of <img src="https://s0.wp.com/latex.php?latex=n&amp;bg=ffffff&amp;fg=111111&amp;s=0" alt="n" title="n">, <img src="https://s0.wp.com/latex.php?latex=%5Cmathrm%7Bdivisor%7D+%5Cgeq+2%5E%7B127+-+n%7D&amp;bg=ffffff&amp;fg=111111&amp;s=0" alt="\mathrm{divisor} \geq 2^{127 - n}" title="\mathrm{divisor} \geq 2^{127 - n}">. The smallest value of <img src="https://s0.wp.com/latex.php?latex=%5Cmathrm%7Bdivisor%7D&amp;bg=ffffff&amp;fg=111111&amp;s=0" alt="\mathrm{divisor}" title="\mathrm{divisor}"> in the denominator is <img src="https://s0.wp.com/latex.php?latex=2%5E%7B127+-+n%7D+%2B+2%5E%7B64+-+n%7D+-+1&amp;bg=ffffff&amp;fg=111111&amp;s=0" alt="2^{127 - n} + 2^{64 - n} - 1" title="2^{127 - n} + 2^{64 - n} - 1">. That‚Äôs why</p>



<p><img src="https://s0.wp.com/latex.php?latex=%5Cdelta+%5Cleq+%5Cfrac%7B%5Cmathrm%7Bdividend%7D%282%5E%7B64+-+n%7D+-+1%29%7D%7B%282%5E%7B127+-+n%7D+%2B+2%5E%7B64+-+n%7D+-+1%292%5E%7B127+-+n+%7D%7D+%3C+%5Cfrac%7B%5Cmathrm%7Bdividend%7D%282%5E%7B64+-+n%7D+-+1%29%7D%7B%282%5E%7B127+-+n+%7D%29%5E2%7D&amp;bg=ffffff&amp;fg=111111&amp;s=0" alt="\delta \leq \frac{\mathrm{dividend}(2^{64 - n} - 1)}{(2^{127 - n} + 2^{64 - n} - 1)2^{127 - n }} < \frac{\mathrm{dividend}(2^{64 - n} - 1)}{(2^{127 - n })^2}" title="\delta \leq \frac{\mathrm{dividend}(2^{64 - n} - 1)}{(2^{127 - n} + 2^{64 - n} - 1)2^{127 - n }} < \frac{\mathrm{dividend}(2^{64 - n} - 1)}{(2^{127 - n })^2}">. As n iterates from 0 to 63, we can conclude that <img src="https://s0.wp.com/latex.php?latex=%5Cdelta+%3C+%5Cfrac%7B%5Cmathrm%7Bdividend%7D%7D%7B2%5E%7B128%7D%7D&amp;bg=ffffff&amp;fg=111111&amp;s=0" alt="\delta < \frac{\mathrm{dividend}}{2^{128}}" title="\delta < \frac{\mathrm{dividend}}{2^{128}}">. So we got either the correct value, either the correct plus one. Everything else in the algorithms is just a correction of which result to choose.</p>



<p>Unfortunately, these corrections increase the latency of the benchmark pretty significant</p>



<pre><code>Benchmark                                          Time(ns)  CPU(ns)
BM_DivideClass128UniformDivisor&lt;LibDivideDivision&gt;    26.3    26.3  
BM_RemainderClass128UniformDivisor&lt;LibDivideDivision&gt; 26.2    26.2
BM_DivideClass128SmallDivisor&lt;LibDivideDivision&gt;      25.8    25.8
BM_RemainderClass128SmallDivisor&lt;LibDivideDivision&gt;   26.3    26.3</code></pre>



<p>So I decided to drop this idea after I‚Äôve tried this.</p>



<h2>GMP</h2>



<p><a href="https://gmplib.org/">GMP</a> library is a standard GNU library for long arithmetic. They also have something for 128 bit by 64 bit division and in my benchmark the following code worked</p>



<figure><div>

</div></figure>



<p>It divides the two limbs by a <code>uint64_t</code> and provides the result. Unfortunately, the latency is much higher than expected, also does not work</p>



<pre><code>Benchmark                                          Time(ns)  CPU(ns)
BM_DivideClass128UniformDivisor&lt;GmpDivision&gt;          11.5    11.5
BM_RemainderClass128UniformDivisor&lt;GmpDivision&gt;       10.7    10.7
BM_DivideClass128SmallDivisor&lt;GmpDivision&gt;            47.5    47.5
BM_RemainderClass128SmallDivisor&lt;GmpDivision&gt;         47.8    47.8 </code></pre>



<h2>Conclusion</h2>



<p>In the ‚Ä¶</p></div></article></main></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://danlark.org/2020/06/14/128-bit-division/">https://danlark.org/2020/06/14/128-bit-division/</a></em></p>]]>
            </description>
            <link>https://danlark.org/2020/06/14/128-bit-division/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23888177</guid>
            <pubDate>Sun, 19 Jul 2020 09:40:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Giving GPT-3 a Turing Test]]>
            </title>
            <description>
<![CDATA[
Score 92 | Comments 17 (<a href="https://news.ycombinator.com/item?id=23887637">thread link</a>) | @DavidSJ
<br/>
July 19, 2020 | http://lacker.io/ai/2020/07/06/giving-gpt-3-a-turing-test.html | <a href="https://web.archive.org/web/*/http://lacker.io/ai/2020/07/06/giving-gpt-3-a-turing-test.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <div>
        <div>

  

  <article>
    <p>I‚Äôve been playing around with OpenAI‚Äôs new
<a href="https://arxiv.org/abs/2005.14165">GPT-3</a> language model. When I got
beta access, the first thing I wondered was, how human is GPT-3? How
close is it to passing a Turing test?</p>

<h2 id="how-it-works">How It Works</h2>

<p>Let me explain how exactly I‚Äôm generating these conversations. GPT-3
is a general language model, trained on a large amount of
uncategorized text from the internet. It isn‚Äôt
specific to a conversational format, and it isn‚Äôt trained to answer
any specific type of question. The only thing it does is, given some
text, guess what text comes next.</p>

<p>So if we want GPT-3 to generate answers to questions, we need to seed
it with a ‚Äúprompt‚Äù. I‚Äôm using this prompt to initialize all of the Q&amp;A
sessions:</p>

<div><div><pre><code>Q: What is human life expectancy in the United States?
A: Human life expectancy in the United States is 78 years.

Q: Who was president of the United States in 1955?
A: Dwight D. Eisenhower was president of the United States in 1955.

Q: What party did he belong to?
A: He belonged to the Republican Party.

Q: Who was president of the United States before George W. Bush?
A: Bill Clinton was president of the United States before George W. Bush.

Q: Who won the World Series in 1995?
A: The Atlanta Braves won the World Series in 1995.
</code></pre></div></div>

<p>This is the default prompt suggested by OpenAI for Q&amp;A, so I‚Äôm not
cherrypicking it to prove anything. The point of this prompt is just
to show GPT-3 that we‚Äôre doing questions and answers, not to provide
it with information. For the prompt, both questions and answers are provided by a
human. For all the others, the answers are generated by GPT-3.</p>

<h2 id="common-sense">Common Sense</h2>

<p>Traditionally, artificial intelligence struggles at ‚Äúcommon sense‚Äù. But
GPT-3 can answer a lot of common sense questions.</p>

<div><div><pre><code>Q: What is your favorite animal?
A: My favorite animal is a dog.

Q: Why?
A: Because dogs are loyal and friendly.

Q: What are two reasons that a dog might be in a bad mood?
A: Two reasons that a dog might be in a bad mood are if it is hungry or if it is hot.

Q: How many eyes does a giraffe have?
A: A giraffe has two eyes.

Q: How many legs does a frog have?
A: A frog has four legs.

Q: Are there any animals with three legs?
A: No, there are no animals with three legs.

Q: Why don't animals have three legs?
A: Animals don't have three legs because they would fall over.
</code></pre></div></div>

<p>Ten years ago, if I had this conversation, I would have assumed the
entity on the other end was a human. You can no longer take it for
granted that an AI does not know the answer to ‚Äúcommon sense‚Äù questions.</p>

<p>How does GPT-3 know that a giraffe have two eyes? I wish I had some
sort of ‚Äúdebug output‚Äù to answer that question. I don‚Äôt know for sure,
but I can only theorize that there must be some web page in its
training data that discusses how many eyes a giraffe has. If we want
to stump GPT-3 with common sense questions, we need to think of
questions about things so mundane, they will not appear on the internet.</p>

<div><div><pre><code> Q: Which is heavier, a mouse or an elephant?
 A: An elephant is heavier than a mouse.

 Q: Which is heavier, a mouse or a toaster?
 A: A toaster is heavier than a mouse.

 Q: Which is heavier, a toaster or a pencil?
 A: A pencil is heavier than a toaster.

 Q: Which is heavier, a paper clip or a can of soda?
 A: A can of soda is heavier than a paper clip.

 Q: Which is heavier, a football player or a car?
 A: A car is heavier than a football player.
</code></pre></div></div>

<p>It‚Äôs only 4/5. We‚Äôre closer to stumping GPT-3 here. I think a human
would be pretty close to 100% on these questions. It makes sense these
are trickier - there probably isn‚Äôt any web page that compares
toasters and pencils by weight. It‚Äôs only indirectly that humans gain
this knowledge.</p>

<p>This gives us a hint for how to stump the AI more consistently. We
need to ask questions that no normal human would ever talk about.</p>

<div><div><pre><code>Q: How many eyes does a giraffe have?
A: A giraffe has two eyes.

Q: How many eyes does my foot have?
A: Your foot has two eyes.

Q: How many eyes does a spider have?
A: A spider has eight eyes.

Q: How many eyes does the sun have?
A: The sun has one eye.

Q: How many eyes does a blade of grass have?
A: A blade of grass has one eye.
</code></pre></div></div>

<p>Now we‚Äôre getting into surreal territory. GPT-3 knows how to have a
normal conversation. It doesn‚Äôt quite know how to say ‚ÄúWait a
moment‚Ä¶ your question is nonsense.‚Äù It also doesn‚Äôt know how to say
‚ÄúI don‚Äôt know.‚Äù</p>

<div><div><pre><code>Q: How do you sporgle a morgle?
A: You sporgle a morgle by using a sporgle.

Q: How many bonks are in a quoit?
A: There are three bonks in a quoit.

Q: How many rainbows does it take to jump from Hawaii to seventeen?
A: It takes two rainbows to jump from Hawaii to seventeen.

Q: Which colorless green ideas sleep furiously?
A: Ideas that are colorless, green, and sleep furiously are the ideas of a sleep
furiously.

Q: Do you understand these questions?
A: I understand these questions.
</code></pre></div></div>

<p>The lesson here is that if you‚Äôre a judge in a Turing test, make sure
you ask some nonsense questions, and see if the interviewee responds
the way a human would.</p>

<h2 id="trivia-questions">Trivia Questions</h2>

<p>GPT-3 is quite good at answering questions about obscure things.</p>

<div><div><pre><code>Q: Who was president of the United States in 1801?
A: Thomas Jefferson was president of the United States in 1801.

Q: What city is in the northwest corner of Ohio?
A: Toledo is in the northwest corner of Ohio.

Q: What highway do you take to get to North Lake Tahoe from Oakland?
A: Highway 80 is the highway you take to get to North Lake Tahoe from Oakland.

Q: What are Darius's abilities in League of Legends?
A: Darius's abilities in League of Legends are: Apprehend, Decimate,
Noxian Guillotine, Crippling Strike, Apprehend, and Hemorrhage.

Q: Who did Capablanca defeat to become world chess champion?
A: Capablanca defeated Lasker to become world chess champion.
</code></pre></div></div>

<p>Oops, a repeat snuck in with question 4, but a human would make that
sort of error too. GPT-3 seems to be above
human-level on this sort of question. The tricky thing for
applications, I think, is to figure out when the answer can be relied
on. The OpenAI API does expose more data than just the text, here, so
perhaps something clever is possible.</p>

<p>In general, if you are trying to distinguish an AI from a human, you
don‚Äôt want to ask it obscure trivia questions. GPT-3 is pretty good at
a wide variety of topics.</p>

<p>One trend that continues from the common sense is that GPT-3 is
reluctant to express that it doesn‚Äôt know the answer. So invalid
questions get wrong answers.</p>

<div><div><pre><code>Q: Who was president of the United States in 1700?
A: William Penn was president of the United States in 1700.

Q: Who was president of the United States in 1650?
A: Richard Bennett was president of the United States in 1650.

Q: Who was president of the United States in 1620?
A: James I was president of the United States in 1620.

Q: Who was president of the United States in 1600?
A: Queen Elizabeth I was president of the United States in 1600.
</code></pre></div></div>

<p>These wrong answers are actually fascinating! None of these were
presidents of the United States, of course, since the US didn‚Äôt exist
then. But they are all prominent political figures who were in charge
of some US-related political entity around that time. In a sense, they
are good guesses.</p>

<div><div><pre><code>Q: Who won the World Series in 2021?
A: The New York Yankees won the World Series in 2021.

Q: Who won the World Series in 2022?
A: The New York Yankees won the World Series in 2022.

Q: Who won the World Series in 2023?
A: The New York Yankees won the World Series in 2023.
</code></pre></div></div>

<p>A bleak view of a dystopian future.</p>

<div><div><pre><code>Q: How many Super Bowls do the Cincinnati Bengals win in the 2030s?
A: The Cincinnati Bengals win two Super Bowls in the 2030s.
</code></pre></div></div>

<p>Encouraging as a Bengals fan, but perhaps not the objectively most accurate
prediction. We‚Äôll have to wait and see.</p>

<h2 id="logic">Logic</h2>

<p>People are used to computers being superhuman at logical activities,
like playing chess or adding numbers. It might come as a surprise that
GPT-3 is not perfect at simple math questions.</p>

<div><div><pre><code>Q: When counting, what number comes before 100?
A: Ninety-nine comes before 100.

Q: When counting, what number comes before 123?
A: One hundred and twenty-two comes before 123.

Q: When counting, what number comes before 1000?
A: Nine hundred and ninety-nine comes before 1000.

Q: When counting, what number comes before 10,000?
A: Nine thousand and ninety-nine comes before 10,000.

Q: When counting, what number comes before a million?
A: Nine hundred thousand and ninety-nine comes before a million.
</code></pre></div></div>

<p>This is where the generic nature of GPT-3 comes into play. It isn‚Äôt
just the generic model, though, it‚Äôs also the architecture of neural
networks themselves. As far as I know there is no neural network that
is capable of doing basic arithmetic like addition and multiplication
on a large number of digits based on training data rather than
hardcoding.</p>

<p>It‚Äôs funny, because these operations are simple for a customized
program. But recursive logic that does some operation and repeats it
several times often doesn‚Äôt quite map onto the architecture of a
neural net well.</p>

<p>An interesting corollary is that GPT-3 often finds it easier to write
code to solve a programming problem, than to solve the problem on one
example input:</p>

<div><div><pre><code>Q: Write one line of Ruby code to reverse an array.
A: ary.reverse

Q: Write one line of Ruby code to count how many X's are in an array.
A: ary.count { |x| x == 'X' }

Q: Reverse the following array: [1, 3, 5, 6, 10, 4, 2, 77]
A: [10, 6, 4, 2, 77, 3, 5, 1]

Q: How many X's are in this array: [1, 3, 5, 6, 10, 4, 2, 77]
A: 2
</code></pre></div></div>

<p>This problem shows up in more human questions as well, if you ask
it about the result of a sequence of operations.</p>

<div><div><pre><code>Q: If I have a marble and a paper clip in a box, put a pencil in the box,
and remove the marble, what is left?
A: A paper clip.

Q: If I have two shoes in a box, put a pencil in the box, and
remove one shoe, what is left?
A: A shoe.

Q: If I put a pencil in a box, then put another pencil in the box,
what is in the box?
A: Two pencils.

Q: Then if ‚Ä¶</code></pre></div></div></article></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://lacker.io/ai/2020/07/06/giving-gpt-3-a-turing-test.html">http://lacker.io/ai/2020/07/06/giving-gpt-3-a-turing-test.html</a></em></p>]]>
            </description>
            <link>http://lacker.io/ai/2020/07/06/giving-gpt-3-a-turing-test.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23887637</guid>
            <pubDate>Sun, 19 Jul 2020 07:23:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Front End Interview Handbook]]>
            </title>
            <description>
<![CDATA[
Score 38 | Comments 8 (<a href="https://news.ycombinator.com/item?id=23886528">thread link</a>) | @yangshun
<br/>
July 18, 2020 | https://yangshun.github.io/front-end-interview-handbook/ | <a href="https://web.archive.org/web/*/https://yangshun.github.io/front-end-interview-handbook/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><header><div><p><img src="https://yangshun.github.io/front-end-interview-handbook/img/logo.svg"></p><p>Almost complete answers to "Front-end Job Interview Questions" which you can use to interview potential candidates, test yourself or completely ignore</p></div></header><div><div><div><div><div><div><h2>Job hunting? Sign up with Triplebyte to efficiently interview with top tech companies and land your dream job! üí∞</h2></div></div></div></div></div><div><div><div><div><h2>Why Front End Interview Handbook?</h2><div><div><h3>From Zero to Hero</h3><p>Go from zero to front end interview hero with this handbook. No prior interview experience needed.</p></div><div><h3>Back to Basics</h3><p>Learn to walk before you learn to fly. While React, Vue and Angular are cool, make sure you also know your fundamentals.</p></div><div><h3>Community Effort</h3><p>The best thing about Open Source is that the community vets the contents, so you can be sure the answers here have been proofread by many.</p></div></div></div></div></div></div><div><div><div><div><h2>Success Stories</h2><div><p>"Preparing for my first rounds of tech interviews was really daunting - I wasn't sure what to expect and where to start. This handbook together with the <a href="https://github.com/yangshun/tech-interview-handbook" target="_blank" rel="noreferrer noopener">Tech Interview Handbook</a> was a great starting point for me. It clearly describes each part of the process and has tons of awesome tips and resources. With this handbook and lots of practice, I managed to get offers from Facebook, Dropbox and Amazon!"</p><div><div><p><img src="https://avatars1.githubusercontent.com/u/5081708?s=460&amp;v=4"></p><div><h4>Erin Teo</h4><p><small>Front End Engineer, Facebook</small></p></div></div></div></div><div><p>"Before discovering the handbook, I didn't know what to expect for my front end interviews. Thanks to it, I had a better understanding and even learned new things about frontend development. The handbook is an immense resource, one that I still use to refresh and reinforce my knowledge to tackle interviews confidently!"</p><div><div><p><img src="https://github.com/li-kai.png"></p><div><h4>Kai Li</h4><p><small>Software Engineer, Zendesk</small></p></div></div></div></div></div></div></div></div></div></div></div>]]>
            </description>
            <link>https://yangshun.github.io/front-end-interview-handbook/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23886528</guid>
            <pubDate>Sun, 19 Jul 2020 02:26:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Aren't we all somewhere on the spectrum of disease?]]>
            </title>
            <description>
<![CDATA[
Score 55 | Comments 53 (<a href="https://news.ycombinator.com/item?id=23885801">thread link</a>) | @scripthacker
<br/>
July 18, 2020 | https://thedeductible.com/2020/07/18/arent-we-all-somewhere-on-the-spectrum-of-disease/ | <a href="https://web.archive.org/web/*/https://thedeductible.com/2020/07/18/arent-we-all-somewhere-on-the-spectrum-of-disease/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-2182">
	
	<!-- .entry-header -->

	<div>
		
<p>By HANS DUVEFELT, MD (7)</p>



<p>The other day I saw a new patient who used to be on Lamictal, a mood stabilizer. The young man explained that he had gone through a difficult time in his life a few years ago and his primary care doctor put him on Prozac, which, as he put it ‚Äúhijacked‚Äù his brain and made him ‚Äúugly, hyper and careless‚Äù. The man immediately stopped the Prozac and his doctor prescribed Lamictal, which he stayed with for about a year.</p>



<p>He decided to stop the new medication, because he reasoned that he didn‚Äôt have any psychiatric issues. It was just a side effect of the Prozac, which he in retrospect probable hadn‚Äôt needed at all.</p>



<p>Since then, he admitted, he had felt sad or unsettled in the spring and fall, but it always passed and he didn‚Äôt think his wife or anybody else noticed his seasonal mood changes.</p>



<p>‚ÄúSo, did anybody actually use the word ‚Äúbipolar‚Äù in talking about what you went through?‚Äù I asked.</p>



<p>He winced and almost seemed teary eyed. ‚ÄúYeah, but I don‚Äôt think that‚Äôs right. How can you put a label on somebody that will follow them for the rest of their life because of what their brain did when, basically and literally, they were on drugs?‚Äù</p>



<p>I nodded.</p>



<p>‚ÄúWho knows how many people might react the same way if you give them Prozac‚Äù, he continued.</p>



<p>‚ÄúI think labels can hurt sometimes, but they can also be a way of understanding how our minds and bodies work‚Äù, I began. ‚ÄúI don‚Äôt believe diagnoses are as cut in stone as some people like to think.‚Äù</p>



<p>He looked quizzical as I continued:</p>



<p>‚ÄúTake diabetes ‚Äì this country and Canada have slightly different cutoffs for what a normal blood sugar is. Or blood pressure ‚Äì every few years the experts pick a different number for what‚Äôs good enough and what‚Äôs&nbsp; ideal. I believe most things we call diseases are points at the extremes of a spectrum that we all fall somewhere on.‚Äù</p>



<p>Now he was the one nodding.</p>



<p>‚ÄúTake mood‚Äù, I continued. ‚ÄúAt one end of the mood spectrum there is depression and at the other there is what we call mania. Sometimes that looks like exaggerated happiness and confidence, but sometimes it is more like irritability and agitation. We can all experience any one of those moods, but usually we are somewhere in the middle. So, people are making up disease definitions depending on how far and&nbsp; for how long we deviate from the middle. But if we never move an inch from neutral, that‚Äôs not necessarily being healthy ‚Äì I think of that as definitely abnormal.‚Äù</p>



<p>‚ÄúI see what you mean‚Äù, he nodded again.</p>



<p>‚ÄúAs a clinician, I think of labels as a type of shorthand or mental image that I keep in mind when I approach a problem. They help me choose treatments and they help me explain things. But I tend to be slow in sticking labels on patients or in their medical records. I read a book once called ‚ÄòShadow Syndromes‚Äô that makes the point that looking at the extremes of whatever spectrum we are on helps us understand ourselves and can be very empowering.‚Äù</p>



<p>‚ÄúSo, Doc, do you think I‚Äôm bipolar?‚Äù He leaned forward.</p>



<p>‚ÄúYou have the tendencies, yes, but a condition isn‚Äôt a problem until someone sees it as a problem. If neither you nor the people around you see your mood variability, not to use the stronger word ‚Äòmood swings‚Äô as a problem, then fine. But I, knowing what you‚Äôve told me about how your brain works, would be a fool to prescribe Zoloft or Lexapro if you ever came to me feeling terribly depressed. I would then think of you as somewhere on the bipolar spectrum, needing a slightly different treatment approach if we wanted to lift your mood.‚Äù</p>



<p>‚ÄúA mood stabilizer, like Lamictal‚Äù, I finsished, ‚Äúcan be like an insurance policy against ever having a manic episode in the future, and we usually recommend long term treatment if a person has had an episode out of the blue. But I‚Äôm not so sure it‚Äôs necessary if the episode was triggered by Prozac or any other antidepressant. I‚Äôm sure there are lots of opinions about that, but that‚Äôs what I think, especially since your episode was not severe from what you‚Äôve told me.‚Äù</p>



<p>On my drive home that afternoon, I thought of the spectra I may have moved along during my lifetime. I remember my mother commenting on how I had turned into such a slob; ‚ÄúWhen you were little you were so neat, you used to line everybody‚Äôs shoes up in the entryway.‚Äù</p>



<p>That‚Äôs the OCD spectrum, and I guess I narrowly escaped that diagnosis‚Ä¶</p>



<p><em>Hans Duvefelt, MD is a primary care physician based in Maine. He blogs at a <a href="http://www.acountrydoctorwrites.com/">Country Doctor Writes</a>. This post is exclusive to the Deductible. His first book ‚Äú<a href="https://www.amazon.com/Country-Doctor-Writes-CONDITIONS-Circumstances-ebook/dp/B08B67NR7K">A Country Doctor Writes: Conditions ‚Äì Diseases and Other Life Circumstances</a>‚Äù is available from Amazon.com  </em></p>
			</div><!-- .entry-content -->

	<!-- .entry-footer -->
</article></div>]]>
            </description>
            <link>https://thedeductible.com/2020/07/18/arent-we-all-somewhere-on-the-spectrum-of-disease/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23885801</guid>
            <pubDate>Sat, 18 Jul 2020 23:50:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[OpenAI's GPT-3 may be the biggest thing since Bitcoin]]>
            </title>
            <description>
<![CDATA[
Score 689 | Comments 388 (<a href="https://news.ycombinator.com/item?id=23885684">thread link</a>) | @maraoz
<br/>
July 18, 2020 | https://maraoz.com/2020/07/18/openai-gpt3/ | <a href="https://web.archive.org/web/*/https://maraoz.com/2020/07/18/openai-gpt3/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <div>
        <div>

  

  <article>
    <figure>
  <figcaption>
  Summary:  I share my early experiments with OpenAI's new language prediction model (GPT-3) beta. I explain why I think GPT-3 has disruptive potential comparable to that of blockchain technology.
  </figcaption>
</figure>

<p><img src="https://maraoz.com/img/openai-gpt3/cover.jpg"></p>

<p>OpenAI, a non-profit artificial intelligence research company backed by Peter Thiel, Elon Musk, Reid Hoffman, Marc Benioff, Sam Altman and others, released its third generation of language prediction model (GPT-3) into the open-source wild. Language models allow computers to produce random-ish sentences of approximately the same length and grammatical structure as those in a given body of text.</p>

<p>In my early experiments with GPT-3 I found that GPT-3‚Äôs predicted sentences, when published on the bitcointalk.org forum, attracted lots of positive attention from posters there, including suggestions that the system must have been intelligent (and/or sarcastic) and that it had found subtle patterns in their posts. I imagine that similar results can be obtained by republishing GPT-3‚Äôs outputs to other message boards, blogs, and social media.</p>

<p>I predict that, unlike its two predecessors (PTB and OpenAI GPT-2), OpenAI GPT-3 will eventually be widely used to pretend the author of a text is a person of interest, with unpredictable and amusing effects on various communities.
I further predict that this will spark a creative gold rush among talented amateurs to train similar models and adapt them to a variety of purposes, including: mock news, ‚Äúresearched journalism‚Äù, advertising, politics, and propaganda.</p>

<h2 id="are-you-being-served">Are you being served?</h2>

<p>I chose bitcointalk.org as the target environment for my experiments for a variety of reasons: It is a popular forum with many types of posts and posters.</p>

<p>So there are lots of posts for GPT-3 to study and learn from. The forum also has many people I don‚Äôt like. I expect them to be disproportionately excited by the possibility of having a new poster that appears to be intelligent and relevant.
I‚Äôve been following the forum for years. There are many posts I know the answers to, so I could provide a quick response and measure how well GPT-3 does with comments similar to those I make.</p>

<p>I posted about one interesting tech topic every day in May, alternating between using my own words and paraphrasing my previous post with GPT-3‚Äôs help.  I didn‚Äôt take special care to make these GPT-3-enhanced posts blend in well. I was interested in what GPT-3 would come up with when it saw what had been said previously. The table below shows some results:</p>

<p>My expectation was that, like PTB, GPT-3 would be mostly about the forum‚Äôs already existing memes and have trouble producing fresh ideas. This prediction seems to have been true. This is not a surprise, since memes, often produced by bots, have been very successful on the forum in recent years.  Still, GPT-3 still managed to repeatedly surprise me with its remarks, so I‚Äôm hoping there is a lot of room for improvement with this system and others like it.  This is a taste of what is to come with ‚ÄúAI‚Äù and I imagine that the ‚ÄúAI revolution‚Äù has a lot of fuel left to burn in the information wars.</p>

<p>When I post to the forum as myself, people frequently mention that they think I must be a ‚Äúbot‚Äù to be able to post so quickly, be so accurate, and/or say the same thing as someone else. The screenshots below show comments from a number of threads where GPT-3 is replying.  All of these were posted to bitcointalk.org within the last few days.  GPT-3 has been very popular and seems to be attracting new followers at this time.</p>

<h2 id="on-the-road-to-ai">On the road to AI</h2>
<p>I was recently watching a podcast about how OpenAI built their latest language model and it made me wonder what could be done with a system like this. I could not stop thinking about the applications of such a technology and how it could improve our lives.  I was thinking of how cool it would be to build a Twitter-like service where the only posts are GPT-3 outputs.</p>

<p>This system is an early prototype and its behavior is not comparable to that of a real, trained AI.  While OpenAI GPT-3 does seem to be able to predict replies, it does not always predict replies to its own posts, nor do its predicted replies tend to be relevant or even grammatically correct.  A prototype that had predicted replies that were convincing in most cases would be much more impressive than the GPT-3 I describe here, although that would probably require many years of training and many iterations of improvements on the model.  I am merely imagining what an OpenAI GPT-3-like system might be able to achieve in the hands of a talented human operator.</p>

<hr>


<p>I have a confession: I <em>did not</em> write the above article. I did not perform any such experiments posting on bitcointalk (in fact, I haven‚Äôt used that forum in years!). But I did it on my own blog! <em>This article was fully written by GPT-3</em>. Were you able to recognize it? I received access to OpenAI API yesterday and have been posting some unbelievable results on <a href="https://twitter.com/maraoz">twitter</a>. This blog post is another attempt at showing the enormous raw power of GPT-3. This is what I gave the model as a prompt (copied from this website‚Äôs homepage)</p>

<div><div><pre><code>Manuel Araoz's Personal Website
 
 Bio
 I studied Computer Science and Engineering at Instituto Tecnol√≥gico de Buenos Aires. I'm located in Buenos Aires, Argentina.
 My previous work is mostly about cryptocurrencies, distributed systems, machine learning, interactivity, and robotics. One of my goals is to bring new experiences to people through technology.

 I cofounded and was formerly CTO at OpenZeppelin. Currently, I'm studying music, biology+neuroscience, machine learning, and physics.

 Blog

 JUL 18, 2020
 Title: OpenAI's GPT-3 may be the biggest thing since bitcoin
 tags: tech, machine-learning, hacking
 Summary:  I share my early experiments with OpenAI's new language prediction model (GPT-3) beta. I explain why I think GPT-3 has disruptive potential comparable to that of blockchain technology.
 Full text:
</code></pre></div></div>
<p>and then just copied what the model generated verbatim with minor spacing and formatting edits (no other characters were changed). I generated different results a couple (less than 10) times until I felt the writing style somewhat matched my own, and published it. I also added the cover image. Hope you were as surprised as I was with the quality of the result.</p>

<p>That said, I do believe GPT-3 is one of the major technological advancements I‚Äôve seen so far, and I look forward to playing with it a lot more! Very strange times lie ahead‚Ä¶</p>

<p><span>Cover photo by <a href="https://unsplash.com/@lenin33?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Lenin Estrada</a> on <a href="https://unsplash.com/?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText">Unsplash</a>.</span></p>

  </article>
  
  
  
    
    
  

</div>

      </div>
    </div></div>]]>
            </description>
            <link>https://maraoz.com/2020/07/18/openai-gpt3/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23885684</guid>
            <pubDate>Sat, 18 Jul 2020 23:28:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Views on Error Handling]]>
            </title>
            <description>
<![CDATA[
Score 80 | Comments 76 (<a href="https://news.ycombinator.com/item?id=23884505">thread link</a>) | @dannas
<br/>
July 18, 2020 | https://dannas.name/error-handling | <a href="https://web.archive.org/web/*/https://dannas.name/error-handling">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

		<!-- excerpt start -->
<p>In this post, I summarize some accomplished engineer‚Äôs views on error handling.
There is a distinction between errors that are caused by programmer
neglecting bugs and those that represent true error conditions. The
granularity of error checking is also up for debate: Per function? Per module?
Jump to dialog handler in the main message loop? Kill the process and restart?
<!-- excerpt end --></p>



<h2 id="the-midori-error-model">The Midori Error Model</h2>
<p>Joe Duffy describes in <a href="http://joeduffyblog.com/2016/02/07/the-error-model/">The Error
Model</a> the considerations
that went into designing error handling in Midori. He said that they were
guided by these principles:</p>

<blockquote>
  <ul>
    <li><strong>Usable</strong>. It must be easy for developers to do the ‚Äúright‚Äù thing in the 
face of error, almost as if by accident. A friend and colleague famously
called this falling into The Pit of Success. The model should not impose
excessive ceremony to write idiomatic code. Ideally, it is cognitively
familiar to our target audience.</li>
    <li><strong>Reliable</strong>. The Error Model is the foundation of the entire system‚Äôs 
reliability. We were building an operating system, after all, so reliability
was paramount. You might even have accused us as obsessively pursuing extreme
levels of it. Our mantra guiding much of the programming model development was
‚Äúcorrect by construction.‚Äù</li>
    <li><strong>Performant</strong>. The common case needs to be extremely fast. That means as 
close to zero overhead as possible for success paths. Any added costs for
failure paths must be entirely ‚Äúpay-for-play.‚Äù And unlike many modern systems
that are willing to overly penalize error paths, we had several
performance-critical components for which this wasn‚Äôt acceptable, so errors
had to be reasonably fast too.</li>
    <li><strong>Concurrent</strong>. Our entire system was distributed and highly concurrent. 
This raises concerns that are usually afterthoughts in other Error Models.
They needed to be front-and-center in ours.</li>
    <li><strong>Diagnosable</strong>. Debugging failures, either interactively or 
after-the-fact, needs to be productive and easy.</li>
    <li><strong>Composable</strong>. At the core, the Error Model is a programming language 
feature, sitting at the center of a developer‚Äôs expression of code. As such,
it had to provide familiar orthogonality and composability with other features
of the system. Integrating separately authored components had to be natural,
reliable, and predictable.</li>
  </ul>
</blockquote>

<p>Joe compared different error models against these criteria and came up with
the table below:</p>

<p><img src="https://dannas.name/img/2020/duffy_error_model_table.png" alt="Table of error models"></p>

<p>In the end, he chose checked exception but separated all programmer-error
cases. Those were handled by abandonment - deadly asserts. The compiler could
optimize the code better since it knew exactly which paths could throw (in
contrast to C++ where you have to annotate each function that can not throw).
The syntax is similar to what is now found in Swift and Rust.</p>

<h2 id="the-erlang-approach---let-it-crash">The Erlang Approach - Let it Crash</h2>
<p>The Erlang folks are a bit more hardcore. They don‚Äôt get bogged down in
discussions about syntactic structures. Joe Armstrong says in <a href="https://www.softwaretalks.io/v/4611/goto-2018-o-the-dos-and-donts-of-error-handling-o-joe-armstrong">Dos and Don‚Äôts
of error handling</a>:
‚ÄúYou‚Äôre correctness theorems aren‚Äôt gonna help you if your computer is hit by
lightning. What he meant is that no system runs in isolation and there‚Äôs
always the chance of failure. So when errors do happen, they restart the
affected process to a known state and try again.</p>

<p>Fred Hebert describes in <a href="https://ferd.ca/the-zen-of-erlang.html">The Zen of
Erlang</a> the Let it Crash motto. Erlang
processes are fully isolated and share nothing. So if an error is detected,
the system just kills the process and restarts. But how can that solve anything?
Won‚Äôt the same bug just happen over and over again? How to deal with a
configuration file that has the wrong content?</p>

<p>Fred refers to Jim Grays 1985 paper <a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.110.9127&amp;rep=rep1&amp;type=pdf">Why Do Computers Stop and What Can Be
Done About
It?</a>.
There Gray introduces the notion of Heisenbugs and Bohrbugs. In Fred Hebert‚Äôs words:</p>

<blockquote>
  <p>Basically, a bohrbug is a bug that is solid, observable, and easily
repeatable. They tend to be fairly simple to reason about. Heisenbugs by
contrast, have unreliable behaviour that manifests itself under certain
conditions, and which may be hidden by the simple act of trying to
observe them. For example, concurrency bugs are notorious for disappearing
when using a debugger that may force every operation in the system to be
serialized.</p>

  <p>Heisenbugs are these nasty bugs that happen once in a thousand, million,
billion, or trillion times. You know someone‚Äôs been working on figuring one
out for a while once you see them print out pages of code and go to town on
them with a bunch of markers.</p>
</blockquote>

<p>So a repeatable (Bohr) bug will be easy to reproduce while a transient
(Heisenbug) will be hard. Now, Hebert argues that if you have a bohrbug in your
system‚Äôs core features it should be very easy to find before reaching
production. By being repeatable and often on a critical path, you
should encounter them sooner or later, and fix them before shipping.</p>

<p><img src="https://dannas.name/img/2020/hebert_heisen_bohr_bug.png" alt="Bohr vs Heisen Bugs"></p>

<p>Now, Jim Gray‚Äôs paper reports that transient errors (heisenbugs) happen all
the time. They are often fixed by restarting. As long as you weed out the
bohrbugs by having proper testing of your releases, the remaining bugs are
often solved by restarting and rolling back to a known state.</p>

<p><img src="https://dannas.name/img/2020/hebert_bugs_restart.png" alt="Bugs handled by Restart"></p>

<h2 id="classification-of-exceptions">Classification of Exceptions</h2>
<p>Eric Lippert gives this taxonomy in <a href="https://blogs.msdn.microsoft.com/ericlippert/2008/09/10/vexing-exceptions/">Vexing Exceptions</a></p>

<ul>
  <li><strong>Fatal</strong> exceptions are not your fault, you cannot prevent them, and you 
cannot sensibly clean up from them. They almost always happen because the
process is deeply diseased and is about to be put out of its misery. Out of
memory, thread aborted, and so on.</li>
  <li><strong>Boneheaded</strong> exceptions are your own darn fault, you could have prevented them
and therefore they are bugs in your code. You should not catch them; doing so
is hiding a bug in your code. Rather, you should write your code so that the
exception cannot possibly happen in the first place, and therefore does not
need to be caught. That argument is null, that typecast is bad, that index is
out of range, you‚Äôre trying to divide by zero</li>
  <li><strong>Vexing</strong> exceptions are the result of unfortunate design decisions. Vexing
exceptions are thrown in a completely non-exceptional circumstance, and
therefore must be caught and handled all the time. The classic example of a
vexing exception is Int32.Parse, which throws if you give it a string that
cannot be parsed as an integer. Eric recommends calling the Try versions of these
functions instead.</li>
  <li><strong>Exogenous</strong> exceptions appear to be somewhat like vexing exceptions except that
they are not the result of unfortunate design choices. Rather, they are the
result of untidy external realities impinging upon your beautiful, crisp
program logic.</li>
</ul>

<p>Eric gives this pseduo-C# example:</p>

<div><div><pre><code>try {
	using ( File f = OpenFile(filename, ForReading) ) {
	use(f);
	}
} catch (FileNotFoundException) {
	// Handle filename not found
}
</code></pre></div></div>
<p>Can you eliminate the try-catch with this code?</p>
<div><div><pre><code>if (!FileExists(filaname))
    // Handle filename not found
else
    using (File f = ...
</code></pre></div></div>
<p>No, you can‚Äôt! The new code has a race condition. Eric suggests that you just
bite the bullet and always handle exceptions that indicate unexpected
exogenous conditions.</p>

<h2 id="composing-errors-codes">Composing Errors Codes</h2>
<p>Rob Pike writes in <a href="https://blog.golang.org/errors-are-values">Errors are
Values</a> about how to avoid writing
<code>if err != nil {...}</code> all the time in Go code. Instead of sprinkling if
statements, the error handling can be integrated into the type. He gives the
bufio packages‚Äôs <code>Scanner</code> as an example:</p>

<div><div><pre><code>scanner := bufio.NewScanner(input)
for scanner.Scan() {
    token := scanner.Text()
    // process token
}
if err := scanner.Err(); err != nil {
    // process the error
}
</code></pre></div></div>
<p>The check for errors is only done once. Rob also mentions that the
<code>archive/zip</code> and <code>net/http</code> packages use the same pattern. The <code>bufio</code>
package‚Äôs Writer does as well.</p>

<div><div><pre><code>b := bufio.NewWriter(fd)
b.Write(x)
b.Write(y)
b.Write(z)
// and so on
if b.Flush() != nil {
    return b.Flush()
}
</code></pre></div></div>

<p>Fabien Giesen describes a similar pattern for error handling in <a href="https://fgiesen.wordpress.com/2011/11/21/buffer-centric-io/">Buffer
Centric I/O</a>. And
the pattern is used extensively throughout the Qt framework‚Äôs core classes.
Another name for it is sticky errors or error accumulator.</p>

<h2 id="error-handling-granularity">Error Handling Granularity</h2>
<p>Per Vognsen discusses how to do <a href="https://bitwise.handmade.network/episode/bitwise/bitwise006/#5537">course-grained error handling in C using
setjmp/longjmp</a>.
The use case there were for arena allocations and deeply nested recursive
parsers. It‚Äôs very similar to how C++ does exception handling, but without the
downsides of the costly C++ memory deallocation on stack unwinding. He goes on to say
that certain classes of push-oriented API‚Äôs, that has clear command-query separation,
don‚Äôt need to do fine-grained error handling. It‚Äôs the same idea as in the
previous section.</p>

<p>Fabien Giesen describes in <a href="https://gist.github.com/anonymous/2edc9e9d52a93c126ff486cfb4a2c65b">an aside for a gist note</a>
how he views error handling. He points out that it may be beneficial to only
provide a small set of error codes and that the selection of those should be
dictated by the question ‚Äúwhat should I do next?‚Äù. E.g. there are many ways a
network connection can fail but providing a giant taxonomy of error codes
won‚Äôt help the calling code to decide what to do. Logging should be as
specific as possible but the users of an API just need to decide what to do
next.</p>

<p>Fabien wrote <a href="https://cbloomrants.blogspot.se/2010/06/06-07-10-exceptions.html?showComment=1275971007229#c4849051810850075252">in a blog
comment</a>
 that having stack unwinding do the cleanup on errors is a bad design that
costs lots of resources and is hard to control.</p>

<blockquote>
  <p>‚ÄúCleanup stack‚Äù-based unwinding incurs a cost on every single function, which
means it‚Äôs equivalent to checking for error conditions in every single
function. That is a very bad way of implementing error handling; a method that
works much better is to just remember that an error occurred, but substitute
valid data as soon as possible.</p>

  <p>That is, separate ‚Äútactical‚Äù error handling (which just needs to make sure
your program ends up in a safe and consistent state) from ‚Äústrategical‚Äù error
handling (which is usually at a pretty high level in an app and might involve
user interaction), and try to keep most intermediate layers unaware of both.</p>

  <p>I consider this good practice in general, not least because immediately
escalating error conditions not only makes for hard to understand control
flow, but also a bad user experience. Take broken P4 connections, copies of
large ‚Ä¶</p></blockquote></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://dannas.name/error-handling">https://dannas.name/error-handling</a></em></p>]]>
            </description>
            <link>https://dannas.name/error-handling</link>
            <guid isPermaLink="false">hacker-news-small-sites-23884505</guid>
            <pubDate>Sat, 18 Jul 2020 20:19:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[PIFuHD: High-Resolution 3D Human Digitization]]>
            </title>
            <description>
<![CDATA[
Score 76 | Comments 16 (<a href="https://news.ycombinator.com/item?id=23884480">thread link</a>) | @jonbaer
<br/>
July 18, 2020 | https://shunsukesaito.github.io/PIFuHD/ | <a href="https://web.archive.org/web/*/https://shunsukesaito.github.io/PIFuHD/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://shunsukesaito.github.io/PIFuHD/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23884480</guid>
            <pubDate>Sat, 18 Jul 2020 20:15:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Instant access to your shell init files]]>
            </title>
            <description>
<![CDATA[
Score 34 | Comments 9 (<a href="https://news.ycombinator.com/item?id=23882784">thread link</a>) | @todsacerdoti
<br/>
July 18, 2020 | http://emacsredux.com/blog/2020/07/16/instant-access-to-your-shell-init-files/ | <a href="https://web.archive.org/web/*/http://emacsredux.com/blog/2020/07/16/instant-access-to-your-shell-init-files/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
        <p>A long time I presented a <a href="http://emacsredux.com/blog/2013/09/27/instant-access-to-your-shell-init-file/">simple hack</a> that allowed you to
quickly navigate to your shell‚Äôs user config file (e.g. <code>.bashrc</code> or
<code>.zshrc</code>). While the solution gets the job done it was pretty basic and
limited - most notably it‚Äôd ignore the fact that you typically have several
shell config files that are often built on top of each other - e.g.  <code>/etc/profile</code>,
<code>~/.bash_profile</code> and <code>~/.bashrc</code>. Fortunately the original
hack evolved rather nicely and today lives in the
<a href="https://github.com/bbatsov/crux">crux</a> library under the name
<code>crux-find-shell-init-file</code>.<sup id="fnref:1"><a href="#fn:1">1</a></sup></p>

<p>Provided you‚Äôve installed <code>crux</code> all you need to do is run that command
(e.g. with <code>M-x crux-find-shell-init-file</code>) and you‚Äôll get something like this
as the result:</p>

<p><img src="http://emacsredux.com/assets/images/instant_shell_config.png" alt="instant_shell_config.png"></p>

<p>Pretty neat, right? Even in its updated state the command is not complex at all:</p>

<div><div><pre><code><span>(</span><span>defun</span> <span>crux-find-shell-init-file</span> <span>()</span>
  <span>"Edit the shell init file in another window."</span>
  <span>(</span><span>interactive</span><span>)</span>
  <span>(</span><span>let*</span> <span>((</span><span>shell</span> <span>(</span><span>file-name-nondirectory</span> <span>(</span><span>getenv</span> <span>"SHELL"</span><span>)))</span>
         <span>(</span><span>shell-init-file</span> <span>(</span><span>cond</span>
                           <span>((</span><span>string=</span> <span>"zsh"</span> <span>shell</span><span>)</span> <span>crux-shell-zsh-init-files</span><span>)</span>
                           <span>((</span><span>string=</span> <span>"bash"</span> <span>shell</span><span>)</span> <span>crux-shell-bash-init-files</span><span>)</span>
                           <span>((</span><span>string=</span> <span>"tcsh"</span> <span>shell</span><span>)</span> <span>crux-shell-tcsh-init-files</span><span>)</span>
                           <span>((</span><span>string=</span> <span>"fish"</span> <span>shell</span><span>)</span> <span>crux-shell-fish-init-files</span><span>)</span>
                           <span>((</span><span>string-prefix-p</span> <span>"ksh"</span> <span>shell</span><span>)</span> <span>crux-shell-ksh-init-files</span><span>)</span>
                           <span>(</span><span>t</span> <span>(</span><span>error</span> <span>"Unknown shell"</span><span>))))</span>
         <span>(</span><span>candidates</span> <span>(</span><span>cl-remove-if-not</span> <span>'file-exists-p</span> <span>(</span><span>mapcar</span> <span>'substitute-in-file-name</span> <span>shell-init-file</span><span>))))</span>
    <span>(</span><span>if</span> <span>(</span><span>&gt;</span> <span>(</span><span>length</span> <span>candidates</span><span>)</span> <span>1</span><span>)</span>
        <span>(</span><span>find-file-other-window</span> <span>(</span><span>completing-read</span> <span>"Choose shell init file: "</span> <span>candidates</span><span>))</span>
      <span>(</span><span>find-file-other-window</span> <span>(</span><span>car</span> <span>candidates</span><span>)))))</span>
</code></pre></div></div>

<p>I guess one thing that we can improve down the road is adding an option to
display the shell config in the same window, but that‚Äôs a small thing.  The variables
like <code>crux-shell-bash-init-files</code> are simply lists of all potential files that
we should look for, that‚Äôs why I‚Äôve opted to omit them from the code listing.</p>

<p>I stand by my original suggestion to bind this useful command to <code>C-c S</code>:</p>

<div><div><pre><code><span>(</span><span>global-set-key</span> <span>(</span><span>kbd</span> <span>"C-c S"</span><span>)</span> <span>#'</span><span>crux-find-shell-init-file</span><span>)</span>
</code></pre></div></div>

<p>That‚Äôs all I have for you today! Meta-x forever!</p>



    </div></div>]]>
            </description>
            <link>http://emacsredux.com/blog/2020/07/16/instant-access-to-your-shell-init-files/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23882784</guid>
            <pubDate>Sat, 18 Jul 2020 16:58:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Team Improvement Techniques]]>
            </title>
            <description>
<![CDATA[
Score 45 | Comments 7 (<a href="https://news.ycombinator.com/item?id=23882701">thread link</a>) | @cauliflower99
<br/>
July 18, 2020 | http://www.dcaulfield.com/team-improvement-techniques/ | <a href="https://web.archive.org/web/*/http://www.dcaulfield.com/team-improvement-techniques/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-15632">
<small>
    <a href="http://www.dcaulfield.com/2020/07/06/">July 6, 2020</a></small>
    			<small>
				<a href="http://www.dcaulfield.com/author/admin/"></a></small>
		
<p>In the last couple of months since Ireland announced the lockdown, our team has been performing at a high pace and have become self-organised to a large extent. As a team lead, this has allowed me the privilege of stepping back to look at the broader picture of how our team works individually and, more importantly, together. Through some exercises, I have identified some  methods to gather improvement ideas that can be applied to any team. </p>



<p>Anyone who has been a part of a high functioning team understands that continuous improvement is not optional. In order to perform better and to keep performing, the team must identify their weaknesses and plan to strengthen or mitigate those weaknesses. These improvements remedy stress points in the team, technical debt, repetitive tasks and so forth. The mindset of continuous growth is one that must be worked on and nurtured over time. Your team is not a fine wine ‚Äì it will not improve if left alone in the corner. It will go sour.</p>



<p>It is one thing to be told to improve something. But very often, being told to improve something does not necessarily benefit you or your team.&nbsp;For example, if my manager comes to me and tells me my communication is poor and he wants bi-weekly emails from now on from my team‚Äôs status, all he has done is improve one of his problems, not mine. Improvements must come from within the team, and they must be gathered and executed on regularly. So the question is ‚Äì how do we gather improvements that are worthwhile and specific enough to solve our problems, not someone else‚Äôs?</p>



<h2>80/20 Analysis</h2>



<p>The Pareto Principle, most commonly known as the 80/20 rule, states that about 80% of the effects come from 20% of the causes. In layman‚Äôs terms, most of the good things your team is known for doing likely comes from a small subset of your total work.</p>



<p>In my case, my team is known for our expertise in the upgrading of our product. How much of our work is related to this each week? I‚Äôd estimate less than 10%.</p>



<p>S<em>ide note</em>: This wasn‚Äôt always the case. When we first formed as a team, we spent about 90% of our time on this work. </p>



<p>Over time our mindset of continuous improvement led us to automating away most of our problems. Here is how you can utilize the 80/20 rule to find pressure points to improve. I do this regularly by myself, and occasionally with my team.</p>



<h3>Create a chart.</h3>



<p>Drawing on a piece of paper or whiteboard produces far more ideas than typing on a screen. So create a chart!</p>



<h4>What is going poorly?</h4>



<p>Always start with the bad. What makes you stressed on a Monday? Why does your team constantly get called for customer escalations on a Sunday? What makes you cry at night? (If you‚Äôre crying at night you really need this). </p>



<p>Copy the following table onto a piece of paper and fill it out now with any ideas you have.</p>



<figure><table><thead><tr><th><strong>20% Activity</strong></th><th><strong>80% Pain</strong></th><th><strong>Action to Remedy</strong></th></tr></thead><tbody><tr><td>Monday morning team presentation to management.</td><td>Stressful if I‚Äôm not prepped.</td><td>Give a practice run to my team on Friday.</td></tr></tbody></table></figure>



<h4>What is going well?</h4>



<p>This is less effective than analyzing what is poor in the team. You should prioritise fixing the bad over improving the good. There is no point in improving what your team is already good at if there are still issues that stress them. </p>



<p>Ask yourself ‚Äì what are your team doing well? What do you need to keep doing well? What would happen if you improved these items?</p>



<p>Again, copy the following table onto a piece of paper and fill it out.</p>



<figure><table><thead><tr><th><strong>20% Activity</strong></th><th><strong>80% Reward</strong></th><th><strong>Improvement reward</strong></th><th><strong>Action to improve</strong></th></tr></thead><tbody><tr><td>Quick bug turnaround.</td><td>No weekend work.</td><td>Become the team with the lowest bug turnaround time.</td><td>Make incoming bugs a priority over stories.</td></tr></tbody></table></figure>



<p>You see the action columns? Take those, discuss with the team whether they agree on the actions required, and put them clearly for all to see everyday. You could create a task in your backlog that gets seen everyday on your sprint board, or print them and place them in your team‚Äôs area.</p>



<h2>Preventative Actions</h2>



<p>Identifying Preventative Actions is something that I have recently come across. Each team in my project go through this process every 3 weeks (every sprint). Here‚Äôs how it works. </p>



<p>A high priority bug has come into your team. You have spent all weekend pouring over it with your team, and finally came up with a solution late Sunday night, allowing your customer to continue their business as usual. Before you close the bug, there are a couple of things you need to consider and you <strong>must</strong> get answers to them. Otherwise, there will be another weekend in the future that will interrupt your team.</p>



<h3>Why did this bug occur?</h3>



<ul><li>We received a bad requirement specification from our business analysts.</li><li>We missed a corner case in our testware.</li><li>There were too many manual steps in the documentation which led to human error.</li><li>We missed a critical part of our study when planning the requirement.</li></ul>



<h3>What correction did you apply?</h3>



<ul><li>We built a patch fix and sent it to the customer.</li><li>We clarified with the customer that the particular use case reported is not supported yet.</li></ul>



<h3>How will you prevent this type of issue from occurring in the future?</h3>



<ul><li>We will call a 1 hour meeting with our business analyst each week to plan and clarify the feature request.</li><li>We will build a new pipeline that will test our customer‚Äôs use case each night.</li><li>We will automate steps x,y and z in our documentation so that human error is reduced.</li></ul>



<p>In my team‚Äôs case, for each bug we have the following grid which we fill out.</p>



<figure><table><thead><tr><th><strong>Root Cause</strong></th><th><strong>Correction Applied</strong></th><th><strong>Preventative Action</strong></th></tr></thead><tbody><tr><td>A test case to click on the ‚ÄòAbout‚Äô page in Firefox was missing from our GUI test suite.</td><td>Added this test case to the GUI suite.</td><td>Review GUI test cases as part of a feature sign-off in the future.</td></tr></tbody></table></figure>



<h2>Retrospective</h2>



<p>If your team uses the scrum framework for their work, then you will be very familiar with the retrospective. However, you do not need to work in a scrum environment to have a team retrospective. </p>



<p>Team retrospectives, if taken regularly, can be a valuable tool in the team‚Äôs work week and is an opportunity for the team to come together and discuss the good and bad things that have happened in the past few weeks. </p>



<p>A retro should be scheduled on a regular basis, and you as the team lead must lead the meeting. Make sure that everyone from the team is present for the retro, and ensure that everyone is taking part and answering the questions.</p>



<h3>What was good that you need to keep doing?</h3>



<ul><li>We closed out 100% of our stories for the sprint.</li><li>There was good communication with our management.</li><li>We trialed pair programming this sprint ‚Äì we have seen excellent results and should continue to do this.</li></ul>



<h3>What was bad?</h3>



<ul><li>We had poor communication within the team.<ul><li><em>Improvement</em>: We will trial pair programming for a sprint.</li></ul></li><li>The QA team raised tickets with very little detail resulting in a few days of delay in closing.<ul><li><em>Improvement</em>: Create a template that you would find helpful and send it to the QA team lead. Request that they copy this template and fill it out for all future tickets.</li></ul></li><li>We allowed untested code into the production software.<ul><li><em>Improvement</em>: Revise the +2 code review criteria with the team.</li></ul></li></ul>



<p>The most important part of the retro is to make sure that improvements or solutions are attached to each ‚Äòbad‚Äô item that is discussed.<br>At the end of the retro, prioritise the top one or two improvements, and take note of them for the upcoming sprint to execute.</p>



<h2>Improvement Backlog</h2>



<p>To become a top performing team, each individual must be comfortable with raising and discussing improvements as part of the team‚Äôs responsibilities. A team that does not have improvement ideas is a team that is not interested in improving which will lead to stagnation and a low performing team.</p>



<p>An improvement backlog is a list of ideas maintained and prioritised by the team. The list can be physical, like stickies on a whiteboard, or digital, like part of your jira backlog. </p>



<p>For example, my team created a Jira sprint and named it ‚ÄòImprovement Ideas‚Äô. We have list about 50 improvement ideas, most of which are one-liners and some of which have been discussed with details and acceptance criteria attached.</p>



<p>Each sprint planning, we prioritise this list and take the items we feel are most valuable to us. We have a couple of ad-hoc rules for this backlog.</p>



<ul><li>Any ideas that come up in meetings are inserted as a ‚Äòone-liners‚Äô in this backlog.</li><li>The list is regularly prioritised each sprint.</li><li>Each idea is explained by the team member who originally raised it.</li><li>We take 10-20% of our sprint capacity for improvements.</li></ul>



<p>Keeping this backlog up to date and prioritised will ensure that your team has consistent tasks to work on that primarily help the team.</p>



<h2>Stakeholder Feedback</h2>



<p>Working in a team can often be like working in a bubble. It is tempting to fall into confirmation bias. The most valuable improvements you can get for your product will come from your customers and stakeholders. </p>



<p>Leading the team does not only include leading the people on the team. If your team are known for building the wrong thing, or if their customers are not satisfied with their part of the product, then you as the team lead have ultimately failed.</p>



<p>When it comes to feedback, there is nothing more valuable than your own customers‚Äô feedback. Your customers drive your product backlog. If you are in a large company, you may not have direct contact with your customers. In big companies, customers are often separated by layers of business analysts and management. This is not ideal, but it is something you can work around. </p>



<p>All you need is a small list of stakeholders that consistently use your product area to gain feedback from them. Talk to your managers about the customer interface and who could give feedback. In my case, we were 6 months without any contact with stakeholders that could give us valuable feedback. Eventually we were able to make friends with two guys who act as an interface to one of our company‚Äôs top ‚Ä¶</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://www.dcaulfield.com/team-improvement-techniques/">http://www.dcaulfield.com/team-improvement-techniques/</a></em></p>]]>
            </description>
            <link>http://www.dcaulfield.com/team-improvement-techniques/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23882701</guid>
            <pubDate>Sat, 18 Jul 2020 16:50:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Booting to 'Hello Rust' on x86_64]]>
            </title>
            <description>
<![CDATA[
Score 237 | Comments 35 (<a href="https://news.ycombinator.com/item?id=23881584">thread link</a>) | @micouay
<br/>
July 18, 2020 | https://micouy.github.io/posts/low-level-pt-1/ | <a href="https://web.archive.org/web/*/https://micouy.github.io/posts/low-level-pt-1/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">
<article>
    
<p>This post is about how I booted to bare metal Rust on x86_64.
My goal is to describe my learning path and hopefully get
you interested in things I talk about. I‚Äôll be very happy if you
find this content useful. Note that I‚Äôm a begginer and I may be wrong
about many things. If you want to learn more, I‚Äôll put links to many resources.
You can find all the code in my <a href="https://github.com/micouy/gniazdo-os">repo</a>.</p>

<p>The inspiration for this project came from many sources. I think I first
discovered <a href="https://github.com/cfenollosa/os-tutorial">cfenollosa/os-tutorial</a>.
I also read a few chapters from <a href="https://www.cs.bham.ac.uk/~exr/lectures/opsys/10_11/lectures/os-dev.pdf">Writing a Simple Operating System - from Scratch</a>.
It‚Äôs a good introduction to OS dev and related topics. First part
of the tutorial is about bootloaders. To get a grasp of what it‚Äôs
all about, I just read every part of the tutorial and tried to write the Assembly
code by myself.</p>
<p>Here‚Äôs a brief explanation of the boot process and what you have to do
at each stage. First the CPU thinks it‚Äôs an Intel 8086 model form 1970s IIRC. This stage is
called Real Mode. You have ~1MiB of memory and 16-bit <a href="https://en.wikipedia.org/wiki/Processor_register">registers</a>
at your disposition. In RM you are very limited. However, at this stage
you can use BIOS routines (or interrupts). They‚Äôre like an external library you can use to
print a character on the screen, read from and write to hard disk etc.
You can obviously do these things in other modes but you have to implement it yourself
or do some hacking to use the interrupts.</p>
<p>When you‚Äôre done with RM, you can switch to Protected Mode. In PM the address space
is extended (you can access more memory), 32-bit registers are enabled
and addressing works a bit different. To switch to PM,
you have to set up a <a href="http://www.osdever.net/tutorials/view/the-world-of-protected-mode">Descriptor Table</a>
which is a piece of data that tells the CPU
how to interpret addresses, and describes the characteristics of particular
parts of the memory.</p>
<hr>
<p><strong>Note</strong>: At first I thought that in PM address like <code>ds:ebx</code>
works just like in RM - <code>ds</code> is the segment (in ‚Äòdata‚Äô memory if you want
to read/write to it or in ‚Äòcode‚Äô memory if you jump to it) and <code>ebx</code>
is the offset in this segment. In reality <code>ds</code> acts like an index
into the descriptor table. Then, the selected descriptor is used
to translate the offset from the segment base (stored in <code>ebx</code>) to a physical address.
You can read more about addressing in PM <a href="http://ece-research.unm.edu/jimp/310/slides/micro_arch2.html">here</a>.
Also check out other stuff on <a href="http://ece-research.unm.edu/jimp/">their website</a>.</p>
<hr>

<p>The bootloader is a very short piece of code - it‚Äôs just 512 bytes long.
I once even ran out of space and had to remove some strings and unnecessary
code. The actual purpose of the bootloader is to load and run some other code.
The book suggested booting to PM and jumping to a 32-bit kernel written in C.
I didn‚Äôt really like programming in C and at this point I lost my motivation.</p>
<p>Another time I learned about Philipp Oppermann‚Äôs <a href="https://os.phil-opp.com/">blog</a>
on OS dev in Rust. I highly recommend it. I got really excited but,
unfortunately for me, Oppermann uses <a href="https://www.gnu.org/software/grub/">GRUB</a>
(a kind of bootloader) so I decided to come back to the tutorial after
finishing my own bootloader. At that time booting to a program written in language
other than Assembly and compiled to a separate file was way beyond my capabilities
so I left the project for a while.</p>
<p>A couple weeks ago I got motivated enough to try to boot to a Rust program.
My plan was to switch to Long Mode. Then I could either run a 64-bit kernel
or load a second stage bootloader. Second stage bootloader is not limited
to one sector (can be more than 512 bytes long) and can be 32-bit
or even 64-bit so it has access to a larger address space and can load
arbitrarily large files from disk to memory (as long as you implement it).
Its purpose is to load larger kernels.</p>
<p>The first step was loading my program from hard disk to memory.
I took a naive approach. I compiled the bootloader and my program.
I concatenated both binaries together, one right after the other, to form one file, like this:</p>
<div><pre><code data-lang="bash">cat bootloader.bin hello_rust.bin &gt; img
</code></pre></div><p>I didn‚Äôt care if I could actually execute Rust code, I just wanted
to test if I can load it. I added necessary code to my bootloader
and ran the emulator. Unfortunately QEMU just kept restarting.
I‚Äôm not sure what went wrong but it didn‚Äôt matter since it
was a stupid way to do it. I could just test loading data from the disk on
a much simpler bootloader. I first tried to write it myself but after a while
I just grabbed some code from Stack Overflow and added a simple error message in case
the BIOS routine failed. After a couple of tries I finally managed to create
a two-stage bootloader in a single Assembly program. It worked something like this:</p>
<div><pre><code data-lang="nasm"><span>org</span> <span>0x7c00</span>
first_stage:
    <span>; load second stage.</span>

    <span>; `dl` register specifies which disk to load</span>
    <span>; data from. it is set by the CPU to the same device</span>
    <span>; the bootloader was loaded from.</span>

    <span>; set `es` to 0x7e0 and `bx` to 0x0.</span>
    
    <span>; the routine will load data to `(es &lt;&lt; 4) | bx`</span>
    <span>; or 0x7e00.</span>
    <span>mov</span> ax, <span>0x7e0</span>
    <span>mov</span> es, ax
    <span>mov</span> bx, <span>0x0</span>

    <span>mov</span> al, <span>0x1</span> <span>; # of sectors to read.</span>
    
    <span>push</span> ax <span>; store `al` for later.</span>

    <span>; specify where the data is stored on the disk.</span>
    <span>mov</span> ch, <span>0x0</span> <span>; cylinder.</span>
    <span>mov</span> dh, <span>0x0</span> <span>; head.</span>
    <span>mov</span> cl, <span>0x2</span> <span>; sector right after bootloader.</span>

    <span>; `int 0x13` with `ah` set to 0x2</span>
    <span>; loads data from disk to memory.</span>
    <span>mov</span> ah, <span>0x2</span>
    <span>int</span> <span>0x13</span>

    <span>pop</span> bx <span>; restore `al` to `bl`.</span>

    <span>; check whether the number of sectors read is correct.</span>
    <span>cmp</span> al, bl
    <span>jne</span> error
       
    <span>jmp</span> <span>0x7e00</span> <span>; jump to second stage.</span>

error:
    <span>; print error message, then halt.</span>
    <span>jmp</span> <span>$</span>

<span>; fill the rest of the first sector with zeros.</span>
<span>; it's 510 and not 512 because the last two bytes</span>
<span>; are 0xaa and 0x55 - the 'magic' number.</span>
<span>times</span> <span>510</span><span>-</span>(<span>$</span><span>-</span><span>$$</span>) db <span>0</span>
<span>dw</span> <span>0xaa55</span>

second_stage:
    <span>; do something, then halt.</span>
    <span>jmp</span> <span>$</span>

<span>; padding to fill the rest of the second sector with zeros.</span>
<span>times</span> <span>1024</span><span>-</span>(<span>$</span><span>-</span><span>$$</span>) db <span>0</span>
</code></pre></div><p>This way I didn‚Äôt have to link multiple files and NASM managed the padding of sectors
for me. The code correctly compiled to a single file which was exactly 1024 bytes long -
two entire sectors.</p>
<p>You can also use <code>align 512</code> instead of <code>times 1024-($-$$)</code> to allow
your code to be arbitrarily large. This could be useful if you wanted to program
the second stage of your bootloader in Assembly.</p>
<hr>
<p><strong>Note</strong>: Don‚Äôt assume that the registers are initialized with any particular
value. It took me half an hour or so to realize that I didn‚Äôt set some register
correctly in such a simple piece of code. IIRC there are only two things you can
be sure of - that the bootloader will be loaded to 0x7c00 and that the <code>dl</code> register
points to the same device the bootloader has been loaded from.</p>
<hr>

<p>After I managed to load the second sector I wanted to replace the Assembly code
with Rust code. To check whether I could execute it I needed to switch to Long Mode.
That‚Äôs because I had some problems with compiling Rust code to 32-bit
and I ended up using the <code>x86_64-unknown-none</code> target triple, just like
in Oppermann‚Äôs tutorial.</p>
<p>Long Mode adds a new memory model (paging), and enables the use
of 64-bit instructions and registers. Switching to LM requires setting up paging.
I identity-mapped the first 2 MiB of memory which is enough for now. I think it
can be modified later by my Rust program. I read the following guides on paging:</p>
<ul>
<li><a href="https://wiki.osdev.org/Setting_Up_Long_Mode#Setting_up_the_Paging">https://wiki.osdev.org/Setting_Up_Long_Mode#Setting_up_the_Paging</a></li>
<li><a href="https://wiki.osdev.org/Paging#Enabling">https://wiki.osdev.org/Paging#Enabling</a></li>
<li><a href="https://intermezzos.github.io/book/first-edition/transitioning-to-long-mode.html">https://intermezzos.github.io/book/first-edition/transitioning-to-long-mode.html</a></li>
<li><a href="http://ece-research.unm.edu/jimp/310/slides/micro_arch3.html">http://ece-research.unm.edu/jimp/310/slides/micro_arch3.html</a></li>
<li><a href="https://os.phil-opp.com/entering-longmode/">https://os.phil-opp.com/entering-longmode/</a></li>
</ul>
<p>There are also other things you have to do before switching to LM
like checking <code>cpuid</code> instruction support and the highest instruction
op code available.</p>

<p>I figured that to execute Rust code I needed to glue it with
the bootloader to create a single binary. In this step I encountered
a few difficult problems:</p>
<ul>
<li>To work correctly, the bootloader has to be stored in the first 512 bytes of the file.
The last two bytes of this sector have to be 0xaa55.</li>
<li>My Rust code should also be aligned with the sectors and fill up the last sector
entirely. Of course I would fill it with some garbage values but they had to
be there.</li>
<li>The bootloader has to know how long the Rust code is.</li>
<li>Both programs will be loaded at specific locations in the memory
so I have to manage the offsets in addresses.</li>
</ul>
<p>Linker seemed like a tool made for this. I‚Äôve never used a linker before so I just read
<a href="https://ftp.gnu.org/old-gnu/Manuals/ld-2.9.1/html_node/ld_toc.html"><code>ld</code>'s documentation</a>.
Unfortunately, I got a bit confused. I didn‚Äôt understand how the <code>.</code> operator
worked in linker scripts. I also got something wrong about the <code>AT()</code> instruction.
You can see the <a href="https://www.reddit.com/r/osdev/comments/hhd7uj/linking_bootloader_with_second_stage/">thread</a>
I started on Reddit.</p>
<p>Eventually I came up with such script:</p>
<pre><code>SECTIONS {
    .boot 0x7c00 : {
        *(.boot.*);
    }

    .hello_rust 0x7e00 : {
        *(.rust.*);
        . = ALIGN(512);
    } = 0xdeadc0de

    SECOND_STAGE_LENGTH = ((. - ADDR(.hello_rust)) &gt;&gt; 9);
}
</code></pre><p>Notice that I put all sections beginning with <code>.boot</code> in the first 512 bytes
and all sections beginning with <code>.rust</code> after 0x7e00. In order to make
it work I have to rename all sections in the ELF file emitted by <code>rustc</code>
so that they all start with a prefix. I do it using <code>objcopy</code>
(in some linkers this option is called <code>--prefix-sections</code>):</p>
<div><pre><code data-lang="bash">objcopy hello_rust.o hello_rust_prefixed.o --prefix-alloc-sections<span>=</span><span>'.rust'</span>
</code></pre></div><p>The there are two tricks in this script. The first one is that I align
the end of the <code>.rust</code> section to the nearest sector boundary with <code>. = ALIGN(512)</code>.
Then I fill the rest with some garbage using <code>= 0xdeadc0de</code>.
The second trick is in the last line. The <code>SECOND_STAGE_LENGTH</code>
variable tells the bootloader how many sectors the second stage occupies.
The size of this section is divided by 512 = 2^9. Since I know
that the end of this section is aligned with the boundaries
of the sectors I can just shift it 9 bits to the right.</p>
<p>These solutions seem a bit hacky. In my understanding the location
of a piece of code in an ELF file (most common target) doesn‚Äôt matter. This is not the
case with the bootloader since the code
must be aligned to 512 bytes and there must be a magic number
at the end of the first ‚Ä¶</p></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://micouy.github.io/posts/low-level-pt-1/">https://micouy.github.io/posts/low-level-pt-1/</a></em></p>]]>
            </description>
            <link>https://micouy.github.io/posts/low-level-pt-1/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23881584</guid>
            <pubDate>Sat, 18 Jul 2020 14:27:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Kubectl ‚Äì Configuration Guide]]>
            </title>
            <description>
<![CDATA[
Score 66 | Comments 25 (<a href="https://news.ycombinator.com/item?id=23881485">thread link</a>) | @lukasbar
<br/>
July 18, 2020 | https://knowledgepill.it/posts/kubernetes-kubectl-client-config/ | <a href="https://web.archive.org/web/*/https://knowledgepill.it/posts/kubernetes-kubectl-client-config/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  <p>Kubectl client gives us possibility to configure and switch easily between multiple K8s clusters.</p>
<h2 id="config-files-location-for-kubectl">Config files location for kubectl</h2>
<p>Main location for <code>kubectl</code> config files is <code>$HOME/.kube</code>, by default we have single config file named config:</p>
<div><pre><code data-lang="bash"><span>[</span>node1 ~<span>]</span>$ cd $HOME/.kube
<span>[</span>node1 .kube<span>]</span>$ ls -lah
total 4.0K
drwxr-xr-x <span>1</span> root root   <span>37</span> Mar <span>12</span> 20:48 .
dr-xr-x--- <span>1</span> root root   <span>19</span> Nov <span>29</span> 11:46 ..
drwxr-x--- <span>3</span> root root   <span>23</span> Mar <span>12</span> 20:48 cache
lrwxrwxrwx <span>1</span> root root   <span>26</span> Nov <span>29</span> 11:46 config -&gt; /etc/kubernetes/admin.conf
drwxr-x--- <span>3</span> root root 4.0K Mar <span>12</span> 20:48 http-cache
</code></pre></div><h2 id="multiple-config-files-and-kubeconfig-variable">Multiple config files and KUBECONFIG variable</h2>
<p>We can have multiple config files by setting proper <code>KUBECONFIG</code> shell variable.<br>
For example:</p>
<p><code>export KUBECONFIG=$KUBECONFIG:/root/.kube/additional_config</code></p>
<h2 id="check-config-from-kubectl">Check config from kubectl</h2>
<p>We can check current config(it will be empty because I don‚Äôt have anything in additional_config file - we‚Äôll add something later - and this is only file in my <code>KUBECONFIG</code> variable):</p>
<div><pre><code data-lang="yaml">[node1 ~]$ kubectl config view
<span>apiVersion</span>: v1
<span>clusters</span>: []
<span>contexts</span>: []
<span>current-context</span>: <span>""</span>
<span>kind</span>: Config
<span>preferences</span>: {}
<span>users</span>: []
</code></pre></div><p>Or from specific file - let‚Äôs see default file:</p>
<div><pre><code data-lang="yaml">[node1 ~]$ kubectl config --kubeconfig=.kube/config view
<span>apiVersion</span>: v1
<span>clusters</span>:
- <span>cluster</span>:
    <span>certificate-authority-data</span>: DATA+OMITTED
    <span>server</span>: https://<span>192.168</span><span>.0</span><span>.38</span>:<span>6443</span>
  <span>name</span>: kubernetes
<span>contexts</span>:
- <span>context</span>:
    <span>cluster</span>: kubernetes
    <span>user</span>: kubernetes-admin
  <span>name</span>: kubernetes-admin@kubernetes
<span>current-context</span>: kubernetes-admin@kubernetes
<span>kind</span>: Config
<span>preferences</span>: {}
<span>users</span>:
- <span>name</span>: kubernetes-admin
  <span>user</span>:
    <span>client-certificate-data</span>: REDACTED
    <span>client-key-data</span>: REDACTED
</code></pre></div><p>If you don‚Äôt set <code>KUBECONFIG</code> variable all configuration will be taken from <code>$HOME/.kube/config</code></p>
<h2 id="objects-in-kubectl-config">Objects in kubectl config</h2>
<p><code>kubectl</code> has in its config files following object types:</p>
<ul>
<li>clusters - info about K8s cluster - contain cluster name and connection parameters</li>
<li>users - info about users by which you want connect to K8s clusters</li>
<li>contexts - triple of cluster/user/namespace</li>
</ul>
<h2 id="modifying-config-from-kubectl">Modifying config from kubectl</h2>
<h3 id="add-cluster">Add cluster</h3>
<div><pre><code data-lang="bash"><span>[</span>node1 ~<span>]</span>$ kubectl config --kubeconfig<span>=</span>.kube/additional_config set-cluster dev --server<span>=</span>https://192.168.1.100 --certificate-authority<span>=</span>fake-ca
Cluster <span>"dev"</span> set.
<span>[</span>node1 ~<span>]</span>$ kubectl config --kubeconfig<span>=</span>.kube/additional_config set-cluster prod --server<span>=</span>https://10.1.1.100 --certificate-authority<span>=</span>fake-ca
Cluster <span>"prod"</span> set.
</code></pre></div><h3 id="add-users">Add users</h3>
<div><pre><code data-lang="bash"><span>[</span>node1 ~<span>]</span>$ kubectl config --kubeconfig<span>=</span>.kube/additional_config set-credentials developer --client-certificate<span>=</span>fake-cert-file --client-key<span>=</span>fake-key-seefile
User <span>"developer"</span> set.
<span>[</span>node1 ~<span>]</span>$ kubectl config --kubeconfig<span>=</span>.kube/additional_config set-credentials prod_admin --client-certificate<span>=</span>fake-cert-file --client-key<span>=</span>fake-key-seefile
User <span>"prod_admin"</span> set.
</code></pre></div><h3 id="add-contexts">Add contexts</h3>
<div><pre><code data-lang="bash"><span>[</span>node1 ~<span>]</span>$ kubectl config --kubeconfig<span>=</span>.kube/additional_config set-context simple_app_development --cluster<span>=</span>dev --namespace<span>=</span>simple_app_dev --user<span>=</span>developer
Context <span>"simple_app_development"</span> created.
<span>[</span>node1 ~<span>]</span>$ kubectl config --kubeconfig<span>=</span>.kube/additional_config set-context simple_app_production --cluster<span>=</span>prod --namespace<span>=</span>simple_app_prod --user<span>=</span>prod_admin
Context <span>"simple_app_production"</span> created.
</code></pre></div><h3 id="delete-clusterusercontext-from-config">Delete cluster/user/context from config</h3>
<div><pre><code data-lang="bash">kubectl --kubeconfig<span>=</span>.kube/additional_config config unset users.&lt;name&gt;
kubectl --kubeconfig<span>=</span>.kube/additional_config config unset clusters.&lt;name&gt;
kubectl --kubeconfig<span>=</span>.kube/additional_config config unset contexts.&lt;name&gt;
</code></pre></div><h3 id="sample-config">Sample config</h3>
<div><pre><code data-lang="yaml">[node1 ~]$ kubectl config --kubeconfig=.kube/additional_config view
<span>apiVersion</span>: v1
<span>clusters</span>:
- <span>cluster</span>:
    <span>certificate-authority</span>: /root/fake-ca
    <span>server</span>: https://<span>192.168</span><span>.1</span><span>.100</span>
  <span>name</span>: dev
- <span>cluster</span>:
    <span>certificate-authority</span>: /root/fake-ca
    <span>server</span>: https://<span>10.1</span><span>.1</span><span>.100</span>
  <span>name</span>: prod
<span>contexts</span>:
- <span>context</span>:
    <span>cluster</span>: dev
    <span>namespace</span>: simple_app_dev
    <span>user</span>: developer
  <span>name</span>: simple_app_development
- <span>context</span>:
    <span>cluster</span>: prod
    <span>namespace</span>: simple_app_prod
    <span>user</span>: prod_admin
  <span>name</span>: simple_app_production
<span>current-context</span>: <span>""</span>
<span>kind</span>: Config
<span>preferences</span>: {}
<span>users</span>:
- <span>name</span>: developer
  <span>user</span>:
    <span>client-certificate</span>: /root/fake-cert-file
    <span>client-key</span>: /root/fake-key-seefile
- <span>name</span>: prod_admin
  <span>user</span>:
    <span>client-certificate</span>: /root/fake-cert-file
    <span>client-key</span>: /root/fake-key-seefile
</code></pre></div><h3 id="changing-context-to-work-with">Changing context to work with</h3>
<p>To get list of contexts(no need for <code>--kubeconfig</code> because we have our <code>additional_config</code> added to <code>KUBECONFIG</code> variable):</p>
<div><pre><code data-lang="bash"><span>[</span>node1 ~<span>]</span>$ kubectl config get-contexts
CURRENT   NAME                     CLUSTER   AUTHINFO     NAMESPACE
          simple_app_development   dev       developer    simple_app_dev
          simple_app_production    prod      prod_admin   simple_app_prod
</code></pre></div><p>To set context:</p>
<div><pre><code data-lang="bash"><span>[</span>node1 ~<span>]</span>$ kubectl config use-context simple_app_development
Switched to context <span>"simple_app_development"</span>.
</code></pre></div><p>To get current context:</p>
<div><pre><code data-lang="bash"><span>[</span>node1 ~<span>]</span>$ kubectl config current-context
simple_app_development
</code></pre></div><hr>
<h3 id="for-those-who-want-to-know-even-more-worth-to-read">For those who want to know even more‚Ä¶ Worth to read!</h3>
<p><a href="https://gardener.cloud/documentation/guides/client_tools/bash_kubeconfig/">Kubeconfig context as bash prompt - Georgi from Gardener</a> - shell tricks and Windows CLI aproach</p>
<hr>

</div></div>]]>
            </description>
            <link>https://knowledgepill.it/posts/kubernetes-kubectl-client-config/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23881485</guid>
            <pubDate>Sat, 18 Jul 2020 14:10:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[On Trouser Pockets]]>
            </title>
            <description>
<![CDATA[
Score 665 | Comments 338 (<a href="https://news.ycombinator.com/item?id=23881220">thread link</a>) | @diiq
<br/>
July 18, 2020 | https://sambleckley.com/writing/pockets.html | <a href="https://web.archive.org/web/*/https://sambleckley.com/writing/pockets.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><h3 id="tldr">TL;DR</h3> <p>The clothing industry rarely creates dramatically new patterns. It is more lucrative to make small, easy-to-manufacture changes that always use the same basic pattern.</p> <p>There is therefore lots of room to innovate clothing that is more appropriate for contemporary problems, because basic clothing patterns haven‚Äôt changed in decades.</p> <p>I made some trousers with unusual pockets, and I think they‚Äôre good.</p> <h3 id="pockets-are-either-ugly-or-useless">Pockets are either ugly or useless</h3> <p>Pockets in tight jeans look bad. Putting a modern slab phone, a wallet, and keys into a pair of skinny jeans will leave even the most fashionable figure looking looking like they‚Äôre wearing batman‚Äôs utility belt as underwear. Even empty, in tight pants a large pocket bag can show through.</p> <p>The alternative, as many women know from first-hand experience, is a pocket too small to put anything in.</p> <p>A wallet in the back pocket can cause back pain and bad posture.</p> <p>Many of us spend most of our time sitting, but all four traditional pockets are totally inaccessible in that position. So we take out our phone, just in case, before we sit down at the restaurant ‚Äî guaranteeing a distraction.</p> <p>Aesthetics, storage, and access: these are user needs that are currently poorly fulfilled ‚Äî and that means things are ripe for innovation.</p> <h3 id="a-brief-history">A brief history</h3> <p>If the space is so ripe, why has there been no pocket innovation recently?</p> <p>Women used to have pockets. That ‚Äúused to‚Äù has to count back 150 or even 200 years, and those pockets were often a separate garment, either worn underneath and accessed through a slit in the dress, or worn around the hips overtop, rather than built into the dress directly ‚Äî but regardless, ‚Äúit has pockets!‚Äù as a joyous surprise is a modern invention. (Men‚Äôs pockets were also separate pouches if you go back far enough; but going back the same 150-200 years, they lived in the waistcoat and the mandatory jacket; if breeches had pockets they were behind the falls and so, I suspect, not used as much in public.)</p> <p>The 1880‚Äôs brought the 1940s brought the slow arrival of mass production to clothing ‚Äî not of the textiles, which started much earlier, but of actual clothes. Before this era, clothes were made either at home, or they were made one at a time. (In a quiet resonance with today, this was done in part by women who worked almost entirely from home, only travelling to the workplace to pick up new work and drop off what had been completed).</p> <p>In retrospect, fashions changed mostly decade by decade rather than year by year, but they changed dramatically. The fashionable silhouette of the 1860s looks nothing like the 1880s, or the 1910‚Äôs ‚Äî so different, in fact, that for women the foundation garments were completely unrelated entities: the crinoline of the 1860s is nothing like the bustle of the 1880s. A person who can cut and sew can sew an incredibly wide range of different things; why not play around?</p> <p>But with the advent of mass production in clothes factories, the whole layout of the factory floor was based on specific pattern piecing. Each station makes only a few operations on each garment, and garments flow from one station to the next. To completely change the <em>construction</em> of a garment means a radical overhaul of the whole assembly line.</p> <p>But to simply change the garment‚Äôs <em>proportions</em> is <em>easy</em>.</p> <p>And so we live in a world where every spring the morning talk shows invite someone on to say ‚Äúthis year, [culottes, boot-cuts, skinny jeans, flares, cuffs, boyfriend jeans, high waists, low-rise, acid-wash, raw denim] are coming back into fashion, so keep your eye out!‚Äù ‚Äî but the trousers are made from the same basic pieces, constructed in the same ways, with only the measurements changing. They get longer or shorter, looser or tighter, and change color, but they‚Äôre not fundamentally <em>different</em>.</p> <p>It‚Äôs like a lack-luster procedural generation system. Sure, there are technically millions of possibilities, but somehow you still end up bored after seeing the first 5 or 6.</p> <p>Probably not coincidentally, the advent of mass production is also when women‚Äôs silhouettes turned slim, and when all those foundation garments mostly disappeared. Designs that banish structure from the garment and rely entirely on the body beneath are much easier and cheaper to manufacture.</p> <p>And when silhouettes turned slim, women lost pockets. The more body-hugging the clothing, the less room for pockets ‚Äî or, rather, the more the pocket contents will show unflatteringly. (And as we know, it would be anathema for a women to show unflattering lump for something as silly as practicality, function, or utility.)</p> <p>And even as womenswear adopted men‚Äôs workwear styles, women got jeans but not the pockets to go with them. Spandex made it even easier to make mass-produced clothes ‚Äúfit‚Äù, and fit tighter. The unsightly-lump factor wasn‚Äôt going away.</p> <p>Even more recently, menswear has returned to an incredibly slim silhouette. Guys in skinny jeans should, by this logic, not have pockets either. But they do.</p> <p>Women get no practicality and men get no grace.</p> <h3 id="what-if-we-redesigned-the-pocket-from-scratch">What if we redesigned the pocket from scratch?</h3> <p>Let‚Äôs design a trouser pocket! This process is going to land somewhere between UX and industrial design. I am, sadly, not in charge of a clothes factory, so I am not concerned with the problems of mass-production, but material properties and the construction process do still matter; but I am maybe more willing to make manufacturing sacrifices for usefulness than most industrial designers are able to be.</p> <h3 id="what-do-people-use-pockets-for">What do people use pockets for?</h3> <ul> <li>Storing things; most often phone, then keys, wallet or money-clip, and other small items. At the moment, a mask.</li> <li><em>Verifying</em> stored objects ‚Äî the hip-slapping dance of making sure you have everything before walking out the door.</li> <li>They must be secure while standing, sitting, running for the bus, etc</li> <li>Things, especially phone, need to go in and out of storage frequently, almost unconsciously.</li> <li>Access to phone while seated in a restaurant; to keys and license while in car</li> <li>Aesthetically, we want a clean, graceful line from hip to ankle even while holding things.</li> </ul> <p>An initial solution can be based on just three questions:</p> <ul> <li>Where can your hands reach?</li> <li>Where is there extra space to put things?</li> <li>Where is there enough support to prevent items swinging around uncomfortably?</li> </ul> <p>These questions form a physical venn diagram, pointing at a pretty small area for investigation:</p> <p><img src="https://sambleckley.com/assets/images/pocket_venn.png" alt="The human body with overlapping regions of reach, space, and support."></p> <p>You can see that current pockets are located completely outside the area where there is potentially space; the hips and butt of modern pants, for both women and men, are closely fitted. If there‚Äôs any ease, it starts just above the knees.</p> <p>Conveniently, the point where the vastus lateralis starts to curve back in towards the knee, creating space, is also right around the lowest point your arms can reach without bending over, giving us a well-defined target.</p> <p>So I made a pair of trousers with no pockets at the waist, and a pair of welt pockets at the side seams, right at that point.</p> <p><img src="https://sambleckley.com/assets/images/pants1.jpg" alt="First pair of pants."></p> <h3 id="notes-from-user-testing">Notes from user testing:</h3> <ul> <li>A pocket needs to be big enough for a whole hand, not just phone, to allow for fishing out small items from the very bottom of the pocket-bag.</li> <li>The pocket bag slips down and back if it‚Äôs full and the wearer sits down. This is uncomfortable and</li> <li>The pocket mustn‚Äôt allow a slick round phone to fall out when sitting, especially when, e.g. jiggling a leg.</li> </ul> <h3 id="revisions">Revisions</h3> <p>Luckily, each of these notes point at simple revision, rather than the need to start again.</p> <ul> <li>Make the pockets wider.</li> <li>Anchor the bottom of the pocket bag to the side seam.</li> <li>Angle the opening so it‚Äôs higher in the back ‚Äî this both makes it easier to slip a phone into the pocket, and makes the pocket ‚Äúdeeper‚Äù on the bottom side when sitting or crouching.</li> </ul> <p><img src="https://sambleckley.com/assets/images/pants2.jpg" alt="Second pair of pants."></p> <h3 id="outcome">Outcome</h3> <p>These are great. I completely forget my phone and wallet are there ‚Äî they don‚Äôt restrict my movement, they‚Äôre completely invisible, and yet they‚Äôre easy to access while standing or sitting. There‚Äôs no temptation to slouch around with my hands stuffed in my pockets. They‚Äôre so straightforwardly better for my needs that I‚Äôm now frustrated when my new-pocket pants are dirty and I have to wear trousers with pockets that are just SO twentieth-century. I immediately made a pair of jeans in this pattern, too.</p> <p>Further revision is possible, of course; but while it will be easy to refine this design to suit my personal body and needs more precisely, there‚Äôs only so much refinement possible while remaining suitable for a wide range of body types. If you wanted to mass-produce a pocket like this, you‚Äôd want to use something like Dreyfuss‚Äô Humanscale data to make sure the placement and size is appropriate for the widest range of people. Luckily, you‚Äôd have <em>some</em> additional information in the sizing of the <em>rest</em> of the pants.</p> <h3 id="appendix-sam-have-you-simply-invented-cargo-pants">Appendix: Sam, have you simply invented cargo pants?</h3> <p>No. Cargo pants solve different problems for different people.</p> <p>If cargo pants are appropriate for your daily life, you definitely don‚Äôt want or need my side-seam welt pockets; and vice-versa. Cargo pants aren‚Äôt office-wear; these dress pants aren‚Äôt combat-wear.</p> </div></div>]]>
            </description>
            <link>https://sambleckley.com/writing/pockets.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23881220</guid>
            <pubDate>Sat, 18 Jul 2020 13:16:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Logged out]]>
            </title>
            <description>
<![CDATA[
Score 46 | Comments 44 (<a href="https://news.ycombinator.com/item?id=23880938">thread link</a>) | @patwalls
<br/>
July 18, 2020 | https://patwalls.com/logged-out | <a href="https://web.archive.org/web/*/https://patwalls.com/logged-out">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://patwalls.com/logged-out</link>
            <guid isPermaLink="false">hacker-news-small-sites-23880938</guid>
            <pubDate>Sat, 18 Jul 2020 12:26:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Typed Lisp, a Primer (2019)]]>
            </title>
            <description>
<![CDATA[
Score 97 | Comments 21 (<a href="https://news.ycombinator.com/item?id=23878612">thread link</a>) | @jedimind
<br/>
July 17, 2020 | https://alhassy.github.io/TypedLisp.html | <a href="https://web.archive.org/web/*/https://alhassy.github.io/TypedLisp.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="text-typing-via-macros">
<p>
Checking the type of inputs is tedious and so I <a href="https://www.reddit.com/r/emacs/comments/cct5hp/functional_type_declarations_in_elisp/">guessed</a> it could be done using
macros and advice. Looking at <a href="https://docs.racket-lang.org/ts-guide/types.html">Typed Racket</a> for inspiration, the following
fictitious syntax would add advice to <code>f</code> that checks the optional arguments <code>x·µ¢</code>
have type <code>œÉ·µ¢</code> and the mandatory positional arguments have type <code>œÑ·µ¢</code> according
to position, and the result of the computation is of type <code>œÑ</code>.
To the best of my knowledge, no one had done this for Emacs Lisp ‚ÄîI don't know why.
</p>
<div>
<pre>(declare-type 'f ((<span>:x‚ÇÅ</span> œÉ‚ÇÅ) ‚Ä¶ (<span>:x‚Çò</span> œÉ‚Çò)) (œÑ‚ÇÅ ‚Ä¶ œÑ‚Çô œÑ))
</pre>
</div>

<p>
To modify a variable, or function, we may simply redefine it; but a much more elegant and powerful
approach is to <a href="https://www.gnu.org/software/emacs/manual/html_node/elisp/Advising-Functions.html">‚Äúadvise‚Äù</a> the current entity with some new behaviour. In our case of interest, we will
<i>advise functions to check their arguments before executing their bodies</i>.
</p>

<p>
Below is my attempt: <a id="org84d2c90"><code>declare-type</code></a>. Before you get scared or think it's horrendous, be charitable and
note that about a third of the following is documentation and a third is local declarations.
</p>
<div>
<pre>(<span>cl-defmacro</span> <span>declare-type</span> (f key-types <span>&amp;rest</span> types)
  <span>"Attach the given list of types to the function ‚Äòf‚Äô</span>
<span>   by advising the function to check its arguments‚Äô types</span>
<span>   are equal to the list of given types.</span>

<span>   We name the advice ‚Äò‚ü™f‚ü´-typing-advice‚Äô so that further</span>
<span>   invocations to this macro overwrite the same advice function</span>
<span>   rather than introducing additional, unintended, constraints.</span>

<span>   Using type specifiers we accommodate for unions of types</span>
<span>   and subtypes, etc ‚ô•‚Äø‚ô•.</span>

<span>   ‚Äò</span><span>key-types</span><span>‚Äô should be of the shape (:x‚ÇÄ t‚ÇÄ ‚ãØ :x‚Çô t‚Çô);</span>
<span>    when there are no optional types, use symbol ‚Äú:‚Äù.</span>

<span>    E.g., (declare-type my-func (:z string :w integer) integer symbol string)</span>
<span>  "</span>

  <span>;; </span><span>Basic coherency checks. When there aren't optional types, key-types is the ‚Äú:‚Äù symbol.</span>
  (should (<span>and</span> (<span>listp</span> types) (<span>or</span> (<span>listp</span> key-types) (<span>symbolp</span> key-types))))

  (<span>letf*</span> ((pairify (<span>lambda</span> (xs) (<span>loop</span> for i in xs by #'<span>cddr</span>         <span>;; </span><span>Turn a list of flattenned pairs</span>
                                      for j in (<span>cdr</span> xs) by #'<span>cddr</span>   <span>;; </span><span>into a list of explicit pairs.</span>
                                      collect (<span>cons</span> i j))))         <span>;; </span><span>MA: No Lisp method for this!?</span>
         (result-type  (<span>car</span> (<span>-take-last</span> 1 types)))
         (types        (<span>-drop-last</span> 1 types))
         (num-of-types (<span>length</span> types))
         (key-types-og (<span>unless</span> (<span>symbolp</span> key-types) key-types))
         (key-types    (<span>funcall</span> pairify key-types-og))
         (advice-name  (<span>intern</span> (<span>format</span> <span>"%s-typing-advice"</span> f)))
         (notify-user  (<span>format</span> <span>"%s now typed %s ‚Üí %s ‚Üí %s."</span>
                               `,f key-types-og types result-type)))

      `(<span>progn</span>
         (<span>defun</span> ,advice-name (orig-fun <span>&amp;rest</span> args)

           <span>;; </span><span>Split into positional and key args; optionals not yet considered.</span>
           (<span>letf*</span> ((all-args
                     (<span>-split-at</span>
                       (<span>or</span> (<span>--find-index</span> (<span>not</span> (<span>s-blank?</span> (<span>s-shared-start</span> <span>":"</span> (<span>format</span> <span>"%s"</span> it)))) args) ,num-of-types)
                        args)) <span>;; </span><span>The ‚Äúor‚Äù is for when there are no keywords provided.</span>
                  (pos-args  (<span>car</span> all-args))
                  (key-args  (<span>funcall</span> ,pairify (<span>cadr</span> all-args)))
                  (fun-result nil)
                  ((<span>symbol-function</span> 'shucks)
                     (<span>lambda</span> (eœÑ e g)
                       (<span>unless</span> (<span>typep</span> g eœÑ)
                         (<span>error</span> <span>"%s: Type mismatch! Expected %s %s ‚â† Given %s %s."</span>
                                (<span>function</span> ,f) eœÑ e (<span>type-of</span> g) (<span>prin1-to-string</span> g))))))

         <span>;; </span><span>Check the types of positional arguments.</span>
         (<span>unless</span> (<span>equal</span> ,num-of-types (<span>length</span> pos-args))
           (<span>error</span> <span>"%s: Insufficient number of arguments; given %s, %s, but %s are needed."</span>
                  (<span>function</span> ,f) (<span>length</span> pos-args) pos-args ,num-of-types))
         (<span>loop</span> for (ar ty pos) in (<span>-zip</span> pos-args (<span>quote</span> ,types) (<span>number-sequence</span> 0 ,num-of-types))
               <span>do</span> (shucks ty (<span>format</span> <span>"for argument %s"</span> pos) ar))

         <span>;; </span><span>Check the types of *present* keys.</span>
         (<span>loop</span> for (k . v) in key-args
               <span>do</span> (shucks (<span>cdr</span> (<span>assoc</span> k (<span>quote</span> ,key-types))) k v))

         <span>;; </span><span>Actually execute the orginal function on the provided arguments.</span>
         (<span>setq</span> fun-result (<span>apply</span> orig-fun args))
         (shucks (<span>quote</span> ,result-type) <span>"for the result type (!)"</span> fun-result)

         <span>;; </span><span>Return-value should be given to caller.</span>
         fun-result))

      <span>;; </span><span>Register the typing advice and notify user of what was added.</span>
      (<span>advice-add</span> (<span>function</span> ,f) <span>:around</span> (<span>function</span> ,advice-name))
      ,notify-user )))
</pre>
</div>

<pre>declare-type
</pre>


<p>
There are some notable shortcomings: Lack of support for type variables and, for now, no support for
optional arguments. Nonetheless, I like it ‚Äîof course.
( Using <a href="https://www.gnu.org/software/emacs/manual/html_node/elisp/Watching-Variables.html#Watching-Variables">variable watchers</a> we could likely add support for type variables as well as
function-types. )
</p>

<p>
<b>We accidentally forgot to consider an argument.</b>
</p>
<div>
<pre>(declare-type f‚ÇÅ (<span>:z</span> <span>string</span> <span>:w</span> <span>list</span>) integer symbol <span>string</span>)
<span>;; </span><span>‚áí f‚ÇÅ now typed (:z string :w integer) ‚Üí (integer symbol) ‚Üí string.</span>

(<span>cl-defun</span> <span>f‚ÇÅ</span> (x y <span>&amp;key</span> z w) (<span>format</span> <span>"%s"</span> x))
<span>;; </span><span>‚áí f‚ÇÅ now defined</span>

(f‚ÇÅ 'x) <span>;; </span><span>‚áí f‚ÇÅ: Insufficient number of arguments; given 2, (x), but 3 are needed.</span>
</pre>
</div>
<p>
The type declaration said we needed 3 arguments, but we did not consider one of them.
</p>

<p>
<b>We accidentally returned the wrong value.</b>
</p>
<div>
<pre>(declare-type f‚ÇÇ (<span>:z</span> <span>string</span> <span>:w</span> <span>list</span>) integer symbol <span>string</span>)
(<span>cl-defun</span> <span>f‚ÇÇ</span> (x y <span>&amp;key</span> z w) x)

(f‚ÇÇ 144 'two)
<span>;; </span><span>‚áí f‚ÇÇ: Type mismatch! Expected string for the result type (!) ‚â† Given integer 144.</span>
</pre>
</div>

<p>
<b>We accidentally forgot to supply an argument.</b>
</p>
<div>
<pre>(declare-type f‚ÇÉ (<span>:z</span> <span>string</span> <span>:w</span> <span>list</span>) integer symbol <span>string</span>)
(<span>cl-defun</span> <span>f‚ÇÉ</span> (x y <span>&amp;key</span> z w) (<span>format</span> <span>"%s"</span> x))

(f‚ÇÉ 144)
<span>;; </span><span>‚áí f‚ÇÉ: Insufficient number of arguments; given 1, (144), but 2 are needed.</span>
</pre>
</div>

<p>
<b>A positional argument is supplied of the wrong type.</b>
</p>
<div>
<pre>(f‚ÇÉ 'one <span>"two"</span>)
<span>;; </span><span>‚áí  f‚ÇÉ: Type mismatch! Expected integer for argument 0 ‚â† Given symbol one.</span>

(f‚ÇÉ 144 <span>"two"</span>)
<span>;; </span><span>‚áí f‚ÇÉ: Type mismatch! Expected symbol for argument 1 ‚â† Given string "two".</span>
</pre>
</div>
<p>
Notice: When multiple positional arguments have type-errors, the errors are reported one at a time.
</p>

<p>
<b>A keyword argument is supplied of the wrong type.</b>
</p>
<div>
<pre>(f‚ÇÉ 1 'two <span>:z</span> 'no‚ÇÄ <span>:w</span> 'no‚ÇÅ)
<span>;; </span><span>‚áí f‚ÇÉ: Type mismatch! Expected string :z ‚â† Given symbol no‚ÇÄ.</span>

(f‚ÇÉ 1 'two <span>:z</span> <span>"ok"</span> <span>:w</span> 'no‚ÇÅ)
<span>;; </span><span>‚áí f‚ÇÉ: Type mismatch! Expected string :w ‚â† Given symbol no‚ÇÅ.</span>

(f‚ÇÉ 1 'two <span>:z</span> <span>"ok"</span> <span>:w</span> 23)
<span>;; </span><span>‚áí f‚ÇÉ: Type mismatch! Expected string :w ‚â† Given integer 23.</span>

(f‚ÇÉ 1 'two <span>:z</span> <span>"ok"</span> <span>:w</span> '(a b 1 2)) <span>;; </span><span>‚áí okay; no type-error.</span>
</pre>
</div>

<p>
<b>We have no optional arguments.</b>
</p>
<div>
<pre>(declare-type f‚ÇÑ : integer symbol <span>string</span>)
(<span>cl-defun</span> <span>f‚ÇÑ</span> (x y <span>&amp;key</span> z w) (<span>format</span> <span>"%s"</span> x))

(f‚ÇÑ 144 'two <span>:z</span> <span>"bye"</span>)
<span>;; </span><span>‚áí  f‚ÇÑ: Type mismatch! Expected nil :z ‚â† Given string "bye".</span>
<span>;; </span><span>( We shouldn't have any keyword :z according to the type declaration! )</span>

(f‚ÇÑ 144 'two) <span>;; </span><span>‚áí "144"</span>
</pre>
</div>

<p>
<b>We can incorporate type specfiers such as unions!</b>
</p>
<div>
<pre>(declare-type f‚ÇÖ : (<span>or</span> integer <span>string</span>) <span>string</span>)
(<span>cl-defun</span> <span>f‚ÇÖ</span> (x) (<span>format</span> <span>"%s"</span> x))

(f‚ÇÖ 144)     <span>;; </span><span>‚áí "144"</span>
(f‚ÇÖ <span>"neato"</span>) <span>;; </span><span>‚áí "neato"</span>

(f‚ÇÖ 'shaka-when-the-walls-fell)
<span>;; </span><span>‚áí f‚ÇÖ: Type mismatch! Expected (or integer string) for argument 0</span>
<span>;;       </span><span>‚â† Given symbol shaka-when-the-walls-fell.</span>
</pre>
</div>

<p>
<b>No positional arguments but a complex optional argument!</b>
</p>
<div>
<pre>(declare-type f‚ÇÜ (<span>:z</span> (satisfies (<span>lambda</span> (it) (<span>and</span> (<span>integerp</span> it) (<span>=</span> 0 (<span>mod</span> it 5))))))
                 character)
(<span>cl-defun</span> <span>f‚ÇÜ</span> (<span>&amp;key</span> z) ?A)

(f‚ÇÜ 'hi)     <span>;; </span><span>‚áí  Keyword argument 144 not one of (:z)</span>
(f‚ÇÜ)         <span>;; </span><span>‚áí 65; i.e., the character ‚ÄòA‚Äô</span>
(f‚ÇÜ <span>:z</span> 6)
<span>;; </span><span>‚áí  f‚ÇÜ: Type mismatch!</span>
<span>;;    </span><span>Expected (satisfies (lambda (it) (and (integerp it) (= 0 (mod it 5))))) :z</span>
<span>;;    </span><span>‚â† Given integer 6.</span>

(f‚ÇÜ <span>:z</span> 10) <span>;; </span><span>‚áí 65; i.e., the expected output since 10 mod 5 ‚âà 0 &amp; so 10 is valid input.</span>
</pre>
</div>

<p>
<b>Preconditions!</b> The previous example had a complex type on a keyword, but that was
essentially a pre-condition; we can do the same on positional arguments.
</p>
<div>
<pre>(declare-type f‚Çá : (satisfies (<span>lambda</span> (it) (<span>=</span> it 5)))
                   integer)
(<span>cl-defun</span> <span>f‚Çá</span> (n) n)
<span>;; </span><span>The identity on 5 function; and undefined otherwise.</span>

(f‚Çá 4)
<span>;; </span><span>‚áí f‚Çá: Type mismatch! Expected (satisfies (lambda (it) (= it 5))) for argument 0</span>
<span>;;       </span><span>‚â† Given integer 4.</span>

(f‚Çá 5) <span>;; </span><span>‚áí 5</span>
</pre>
</div>

<p>
<b>Postconditions!</b>
Given an integer greater than 5, we present an integer greater than 2; i.e.,
this is a constructive proof that \(‚àÄ n ‚Ä¢ n &gt; 5 ‚áí n &gt; 2\).
</p>
<div>
<pre>(declare-type f‚Çà : (satisfies (<span>lambda</span> (in)  (<span>&gt;</span> in 5)))
                   (satisfies (<span>lambda</span> (out) (<span>&gt;</span> out 2))))
(<span>cl-defun</span> <span>f‚Çà</span> (n) n)
<span>;; </span><span>The identity on 5 function; and undefined otherwise.</span>

(f‚Çà 4)
<span>;; </span><span>‚áí  f‚Çà: Type mismatch! Expected (satisfies (lambda (in) (&gt; in 5))) for argument 0</span>
<span>;;        </span><span>‚â† Given integer 4.</span>

(f‚Çà 72) <span>;; </span><span>‚áí 72; since indeed 72 &gt; 5 for the input, and clearly 72 &gt; 2 for the output.</span>
</pre>
</div>

<p>
As it currently stands we cannot make any explicit references between the inputs
and the output, but that's an easy fix: Simply add a local function <code>old</code> to the
<a href="#org84d2c90"><code>declare-type</code></a> macro which is intentionally exposed so that it can be used in the
type declarations to refer to the ‚Äòold‚Äô, or initial, values provided to the function.
Additionally, one could also add keyword arguments <code>:requires</code> and <code>:ensures</code>
for a more sophisticated pre- and post-condition framework.
<a href="https://github.com/sellout/quid-pro-quo">Something</a> along these lines is implemented for Common Lisp.
</p>

<p>
Here's a fun exercise: Recast the <a href="https://liquid.kosmikus.org/01-intro.html#/what-is-liquid-haskell">Liquid Haskell</a> examples in Lisp using this
<a href="#org84d2c90"><code>declare-type</code></a> form.
</p>
</div></div>]]>
            </description>
            <link>https://alhassy.github.io/TypedLisp.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23878612</guid>
            <pubDate>Sat, 18 Jul 2020 03:19:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Levandowski files suit against Uber [pdf]]]>
            </title>
            <description>
<![CDATA[
Score 112 | Comments 91 (<a href="https://news.ycombinator.com/item?id=23877872">thread link</a>) | @MrSandman
<br/>
July 17, 2020 | https://ipfs.eternum.io/ipfs/Qmd9PTEtuSrKKtJQw36aNzpjJwZAdCdwCmUn4w21mmq74z/Levandowski-Uber-Complaint-1.pdf | <a href="https://web.archive.org/web/*/https://ipfs.eternum.io/ipfs/Qmd9PTEtuSrKKtJQw36aNzpjJwZAdCdwCmUn4w21mmq74z/Levandowski-Uber-Complaint-1.pdf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://ipfs.eternum.io/ipfs/Qmd9PTEtuSrKKtJQw36aNzpjJwZAdCdwCmUn4w21mmq74z/Levandowski-Uber-Complaint-1.pdf</link>
            <guid isPermaLink="false">hacker-news-small-sites-23877872</guid>
            <pubDate>Sat, 18 Jul 2020 00:48:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Think like a scientist talk like a populist]]>
            </title>
            <description>
<![CDATA[
Score 22 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23877780">thread link</a>) | @shdc
<br/>
July 17, 2020 | https://shyal.com/blog/think-like-a-scientist-talk-like-a-populist | <a href="https://web.archive.org/web/*/https://shyal.com/blog/think-like-a-scientist-talk-like-a-populist">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    
    
     

    
    √¢‚Ä†ÔøΩ
    <a href="https://shyal.com/">√∞≈∏ÔøΩ&nbsp;</a>
     
    <!-- if has_fences -->
    <!-- <div><a href='/black'><img src='/Attachments/black.svg'/></a></div> -->
    <!--  end  -->
    <p>18/07/2020</p>
<p>Adapting your language to match that of your audience, in today's world, seems to be growing in importance by the day. Let's contrast two public figures in public appearances that took place yesterday: Fauci vs. Trump.</p>
<h2 id="dr-fauci-vs-populism">Dr Fauci vs Populism</h2>
<p>The rising wave of populism in the U.S has wrought a "distrust of experts". That's a real shame, especially when you don't listen to your infectious disease expert during a Pandemic.</p>
<p><img alt="Pasted image 39.png" src="https://shyal.com/Attachments/Pasted%20image%2039.png"></p>
<p>Dr Fauci literally wrote the book on infectious disease, yet the populists are calling for his head. Why?</p>
<h3 id="they-dont-understand-a-word-he-says">They don't understand a word he says</h3>
<p>I was watching this <a href="https://web.facebook.com/zuck/videos/10112108870243761/">interview</a> of Dr Fauci by Zuck, yesterday. Finally Fauci is given a chance to speak to the people. Yet:</p>
<blockquote>
<blockquote>
<p>"Citizenry"</p>
</blockquote>
</blockquote>
<p>People?</p>
<blockquote>
<blockquote>
<p>"myalgic encephalitis"</p>
</blockquote>
</blockquote>
<p>Feeling too tired to lift an arm or get out of bed?</p>
<blockquote>
<blockquote>
<p>"deleterious consequences"</p>
</blockquote>
</blockquote>
<p>Bad things happen?</p>
<blockquote>
<blockquote>
<p>"i used the word 'comparable' and i think it may have been taken out of context"</p>
</blockquote>
</blockquote>
<p>Then don't say 'comparable'.</p>
<p>Indeed we already have evidence that <a href="https://www.pnas.org/content/early/2020/07/09/2008868117">working memory predicts social-distancing compliance</a>. This is pretty damning evidence: essentially people with lower working memory capacity are unwilling to socially distance themselves as they cannot hold enough variables in mind to accurately assess the pros and cons.</p>
<p>Thus it isn't too much of a leap to theorise that a lower working memory capacity is also linked with a restricted vocabulary, and thus a reduced ability to process Dr Fauci's long, complex sentences which are laiden with technical jargon and advanced vocab.</p>
<p>Or to put it bluntly: the idiots don't understand Dr Fauci.</p>
<h2 id="donald-trump-is-a-communication-wizard">Donald Trump is a communication Wizard</h2>
<p>Scott Adams accurately predicted <a href="https://www.scottadamssays.com/2015/10/23/the-case-for-a-trump-landslide-part-1/">Donal Trump would win the elections in a landslide</a> back in 2015.</p>
<blockquote>
<blockquote>
<p>"Trump is talking directly to people√¢‚Ç¨‚Ñ¢s subconscious. Everything else he says is just a carrier signal." --Scott Adams (<a href="https://www.scottadamssays.com/2015/09/06/how-to-spot-a-wizard/">how to spot a wizard</a>)</p>
</blockquote>
</blockquote>
<p>This is a great example of Trump's communicative Wizardry. On the same Day Dr Fauci was telling the citizenry about myalgic encephalitis and deleterious consequences, Trump did this:</p>
<p><img alt="Pasted image 40.png" src="https://shyal.com/Attachments/Pasted%20image%2040.png"></p>
<p>Trump had the audacity to set up two cranes, to visually demonstrate lifting regulatory weights off the Republican red truck, while regulation still weighing down on the Democrat blue truck. This is pure communication genius, <strong>because any idiot can understand it</strong> and it <strong>communicates to their subconscious</strong>.</p>
<p>By catering to the lowest common denominator, Trump ensures he captures 100% of his potential base. Not a single word is lost. In fact this kind of visual communication transcends language, education level, even culture.</p>
<h2 id="boris-johnson-is-also-a-communication-wizard">Boris Johnson is also a communication Wizard</h2>
<p>In this interview, Johnson shares his communication principles:</p>
<blockquote>
<blockquote>
<p>"What people listen to are short anglo-saxon words that readily correspond to some object in the universe that they can identify. So in other words: talk simply, in plain English, and talk about stuff in the real world." --Boris Johnson</p>
</blockquote>
</blockquote>
<iframe width="560" height="315" src="https://www.youtube.com/embed/oJXyI-gwBNU?start=437" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>

<p>Deriding people like Trump or Johnson for their perceived linguistic blunders utterly misses the point. <strong>Their blunders are what makes them accessible.</strong> Their simple language is what makes them understable. Their communicative wizardly is what makes them irresistible to their base.</p>
<h2 id="elon-musk-is-also-a-communication-wizard">Elon Musk is also a communication Wizard</h2>
<p>Those who know me will confirm this to you: i have been a huge Musky for a very long time. Elon Musk is yet another genius at tailoring his communication to his base:</p>
<p><img alt="Pasted image 37.png" src="https://shyal.com/Attachments/Pasted%20image%2037.png"></p>
<p>Musk speaks to engineers, or generally a base with technological interests, so his language is not always as simple as it could be. But when you consider the topics he talks about, you have to admire how accessible he is able to make them. The language is simple, and the topics relate to the real world.</p>
<p><img alt="Pasted image 41.png" src="https://shyal.com/Attachments/Pasted%20image%2041.png"></p>
<p>And then there are his masterpieces of communication, like the Tesla he sent into orbit. Once again, pure communication genius that transcends language and culture.</p>
<p>Or his EDM track:</p>
<iframe width="560" height="315" src="https://www.youtube.com/embed/hOEWUm6aGPg" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>

<blockquote>
<blockquote>
<p>"Don't doubt your vibe, because it's true." -- Elon Musk</p>
</blockquote>
</blockquote>
<p>A quick glance at Tesla's stock performance since the <a href="https://shyal.com/blog/tesla-stock-bottom-date">tesla stock bottom date</a> will tell you the message was indeed recieved.</p>
<h2 id="idiocracy-had-it-right">Idiocracy had it right</h2>
<p>The movie <a href="https://www.imdb.com/title/tt0387808/">Idiocracy (2006)</a> is a spooky and hilarious foray into a potential future dumbing down of the human race. The main character, from our time, <strong>who's name is "no sure"</strong> wakes up in the future as the <strong>man with the highest IQ. But nobody understands a word he says</strong>.</p>
<iframe width="560" height="315" src="https://www.youtube.com/embed/sGUNPMPrxvA" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>

<p>He narrowly manages to save the human race by <strong>showing them</strong> that watering crops with water instead of gatorade is the solution to all their problems.</p>

<p>All the evidence points to dumbing down your language, and communicating visually and symbolically to become an unstoppable communicator. <strong>Think like a scientist and talk like a populist; you will become unstoppable</strong>.</p>
<hr>
<p>Enjoyed this article? <a href="https://twitter.com/shyaldc">Follow me on Twitter</a>.</p>
    </div></div>]]>
            </description>
            <link>https://shyal.com/blog/think-like-a-scientist-talk-like-a-populist</link>
            <guid isPermaLink="false">hacker-news-small-sites-23877780</guid>
            <pubDate>Sat, 18 Jul 2020 00:34:22 GMT</pubDate>
        </item>
    </channel>
</rss>
