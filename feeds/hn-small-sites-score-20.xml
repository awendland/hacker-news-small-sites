<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 20]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 20. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Mon, 28 Sep 2020 12:31:38 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-20.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Mon, 28 Sep 2020 12:31:38 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[Pac-Man Maze Generation]]>
            </title>
            <description>
<![CDATA[
Score 26 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24603618">thread link</a>) | @kanamekun
<br/>
September 26, 2020 | https://shaunlebron.github.io/pacman-mazegen/ | <a href="https://web.archive.org/web/*/https://shaunlebron.github.io/pacman-mazegen/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="container">

<p>
by <a href="http://twitter.com/shaunlebron">Shaun LeBron</a>.
(<a href="https://github.com/shaunlebron/pacman-mazegen">code on GitHub</a>)
</p>


<canvas id="canvas"></canvas>

<h2><span>Work in Progress</span></h2>
<p>
<i>
Generating random Pac-Man mazes is a deceptively difficult problem that I spent some months working on.  It is not easy to describe clearly.  I hope you are patient.  This page is an effort to begin communicating how the algorithm works.  It will slowly be refined (your feedback appreciated) until it is all stated as clearly as possible.
</i>
</p>

<h2>Contraints</h2>
<p>
The mazes are built carefully to closely match design patterns deduced from the original maps found in Pac-Man and Ms. Pac-Man:
</p>

<ul>
<li>Map is 28x31 tiles.</li>
<li>Paths are only 1 tile thick</li>
<li>No sharp turns (i.e. intersections are separated by atleast 2 tiles).</li>
<li>There are 1 or 2 tunnels</li>
<li>No dead-ends.</li>
<li>Only I, L, T, or + wall shapes are allowed, including the occasional rectangular wall.</li>
<li>Any non-rectangular wall pieces must only be 2 tiles thick.</li>
</ul>

<h2>It's like Tetris</h2>

<p>
We start by stacking tetris pieces on a 5x9 grid. Gravity pulls the pieces in the left direction rather than down.  The edges of the resulting tetris pieces correspond to walkable paths in the maze.  This grid is then mirrored across the left vertical axis to create a symmetric map, then scaled by 3 to form an original-size 28x31 map.
</p>

<h2>Definitions</h2>

<p>
For clarity, I call the squares in the initial 5x9 grid, <b>cells</b>, and the squares in the final 28x31 grid, <b>tiles</b>.  So, this algorithm first creates the <b>cells</b> and transforms them into <b>tiles</b>
</p>

<h2>Simple Model</h2>

<p>
Shown in the above diagram titled "Simple Model" is the 5x9 grid of tetris pieces.  The pieces are created one cell at a time using some algorithm to limit the type of pieces at certain locations (they are numbered to show the order of creation).
</p>

<p>
The ghost pen and the edge between rows 7 and 8 at column 1 are present in every map, since the starting location of Pac-Man and the ghost pen location are constant.
</p>

<h2>Height and Width Adjustments</h2>

<p>
Cells are directly transformed into a 3x3 group of tiles. Unfortunately, this creates a resulting map that is too short by 1 tile and too wide by 1 tile.  So, we increase the height of one cell for every column, and decrease the width of one cell for every row, allowing the generated map to fit in the exact dimensions of the original game.
</p>

<p>
Shown in the above diagrams titled "Height Adjustments" and "Width Adjustments", the highlighted cells are the candidate cells whose size can be changed without creating ugly walls (i.e. walls that have non-uniform thickness).
</p>

<p>
Arrows occupy cells which have been chosen for size adjustment.  Care is taken to prevent discontinuities in the edges as a result of the shifting of cells from the size change.
</p>

<h2>Border Cells and Tunnels</h2>

<p>
I won't explain too much about this right now.  But the above diagram titled "Border Cells and Tunnels" has arrows to indicate the tunnel candidates.  The highlighted cells show the type of tunnel candidates by color.  Some cell edges are erased to create some variation in how walls connect with the boundary of the map (shown in green).  The tunnel creation algorithm is sophisticated in how it chooses different types of tunnels.
</p>

<h2>Final Paths</h2>

<p>
When the cells are finally transformed into tiles, what you are left with is shown in the diagram above titled "Final Paths".  Here you can directly map a cell to a 3x3 group of tiles.  You can even pick out the cells whose height are width have been adjusted by 1 tile in this map.
</p>

<h2>Final Tiles</h2>

<p>
See how the above diagram titled "Final Tiles" differs from "Final Paths".  The paths are shifted from the tile <em>edges</em> toward the tile <em>centers</em>.  Each tile with a path going through its center is turned into a path tile.  Finally, any tile that touches a path tile becomes a wall tile.  The map structure is now complete.
</p>

<h2>Results</h2>

<p>
<a href="https://shaunlebron.github.io/pacman-mazegen/tetris/many.htm">Click here to see many generated Pac-Man mazes together.</a>
</p>

<h2>Appendix</h2>

<h3>Original Maps</h3>
<p><img src="https://shaunlebron.github.io/pacman-mazegen/img/origmaps_2x.png" width="100%"></p><h3>Original Maps (plain)</h3>
<p><img src="https://shaunlebron.github.io/pacman-mazegen/img/origmaps_2x_print.png" width="100%"></p><h3>Original Maps (paths)</h3>
<p><img src="https://shaunlebron.github.io/pacman-mazegen/img/origmaps_path.png" width="100%">

</p></div></div>]]>
            </description>
            <link>https://shaunlebron.github.io/pacman-mazegen/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24603618</guid>
            <pubDate>Sun, 27 Sep 2020 02:01:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[DM41x: a modern take on the HP-41CX]]>
            </title>
            <description>
<![CDATA[
Score 28 | Comments 9 (<a href="https://news.ycombinator.com/item?id=24602722">thread link</a>) | @jmspring
<br/>
September 26, 2020 | https://www.swissmicros.com/product/dm41x | <a href="https://web.archive.org/web/*/https://www.swissmicros.com/product/dm41x">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>The DM41X, another member of our flagship line-up of RPN calculators, is a faithful recreation of the software environment of the HP-41CX, one of the most versatile calculators ever created and the first alphanumerical calculator, in a modern hardware architecture. Easily share or back up your programs or your entire DM41X environment and use hundreds of existing, professionally developed software applications with this rugged calculator sporting a stainless steel case and a Gorilla Glass screen.</p><p>Like all SwissMicros calculators, the DM41X uses the efficient and time-tested RPN logic.</p></div></div>]]>
            </description>
            <link>https://www.swissmicros.com/product/dm41x</link>
            <guid isPermaLink="false">hacker-news-small-sites-24602722</guid>
            <pubDate>Sat, 26 Sep 2020 22:37:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[All you need is λ, part one: booleans]]>
            </title>
            <description>
<![CDATA[
Score 107 | Comments 23 (<a href="https://news.ycombinator.com/item?id=24601981">thread link</a>) | @azhenley
<br/>
September 26, 2020 | https://antitypical.com/posts/2020-03-29-all-you-need-is-lambda-1-booleans/ | <a href="https://web.archive.org/web/*/https://antitypical.com/posts/2020-03-29-all-you-need-is-lambda-1-booleans/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    


    <div role="main">
      <div>
        

<article>
  <p>Nearly a century ago, Alonzo Church invented the simple, elegant, and yet elusive lambda calculus. Along with Alan Turing, he then proved the Church-Turing thesis: that anything computable with a Turing machine can also be computed in the lambda calculus. However, nearly as soon as we had digital computers, we started inventing programming languages, and with them a vast treasure of features, beautiful and terrible, many of which seem very hard to relate to the fundamental nature of computability, let alone the lambda calculus specifically.</p>
<!--more-->
<p>While it’s true that anything which can be computed, period, can be computed in the lambda calculus, you might not want to: it’s austere, to say the least, and was not designed with modern sensibilities regarding readability in mind. We developed all those languages and features for a reason! Still, Church demonstrated not just that it was possible to compute anything computable with the lambda calculus, but also <em>how</em> one might do so.</p>
<p>In this series, we’ll examine some ways to express common programming language features using the minimalistic tools of the lambda calculus. We begin with perhaps the most ubiquitous type: booleans.</p>
<h2 id="λ-is-blind">λ is blind</h2>
<p>The lambda calculus’s austerity is extreme: you don’t even have booleans. All you have are:</p>
<ol type="1">
<li><p>Lambda abstractions;</p></li>
<li><p>Applications; and</p></li>
<li><p>Variables.</p></li>
</ol>
<p>We’ll now review these in some detail; feel free to skip this section if you’re already familiar with the lambda calculus.</p>
<h3 id="lambda-abstractions">Lambda abstractions</h3>
<p>Lambda abstractions (“lambdas,” “abstractions,” and “functions” will also be used interchangeably) introduce a function of a single variable.</p>
<p>Abstractions are written <code>λ x . y</code>, for variable <code>x</code> and expression <code>y</code>, where <code>x</code> is now available as a bound variable in the body, and any enclosing definition of <code>x</code> is shadowed (i.e.&nbsp;<code>λ x . λ x . x</code> = <code>λ x . λ y . y</code> ≠ <code>λ x . λ y . x</code>). (We shall assume strictly lexical scoping for the time being.)</p>
<p>In Haskell, we would write <code>\ x -&gt; y</code> instead; in JavaScript, <code>function (x) { return y }</code> or <code>(x) =&gt; y</code>.</p>
<h3 id="applications">Applications</h3>
<p>Applications (“function application” and “function call” will be used interchangeably) apply the result of the expression on the left to the expression on the right.</p>
<p>Applications are written as <code>x y</code>, for expressions x and y, and left-associated, i.e.&nbsp;<code>a b c</code> = <code>(a b) c</code> ≠ <code>a (b c)</code>. Function application binds tighter than lambda abstraction, i.e.&nbsp;<code>λ x . λ y . y x</code> = <code>λ x . λ y . (y x)</code> ≠ <code>λ x . (λ y . y) x</code>.</p>
<p>The syntax is the same in Haskell; in JavaScript, we would write <code>x(y)</code> or <code>a(b, c)</code>. Note however that since lambda calculus functions are all single-argument functions, a more direct (though less idiomatic) equivalent for the latter would be <code>a(b)(c)</code>.</p>
<h3 id="variables">Variables</h3>
<p>Variables introduced by enclosing lambdas.</p>
<p>Variable are written as more or less arbitrary names, typically alphanumeric (e.g.&nbsp;<code>x</code> or <code>y0</code> or <code>thing</code>); however, we will feel free to include non-alphanumeric characters in names as we see fit, since the paucity of syntax means there’s little risk of ambiguity.</p>
<p>Since the only available variables are those bound by enclosing lambdas, we can also infer that there are no <code>let</code> bindings for local variables, and no globals of any sort; the lambda calculus doesn’t come with a standard library.</p>
<h3 id="summary">Summary</h3>
<p>In quasi-BNF, the grammar for the lambda calculus is extremely minimal:</p>
<figure>
<p><em>e</em> <strong>:=</strong> <code>λ</code> <em>x</em> <code>.</code> <em>e</em> <strong>|</strong> <em>e</em> <em>e</em> <strong>|</strong> <em>x</em> <strong>|</strong> (<em>e</em>)</p>
</figure>
<p>And finally, this table gives a side-by-side comparison of the syntax of the lambda calculus with the corresponding syntax in Haskell &amp; JavaScript:</p>
<table>
<caption>
Syntax of the lambda calculus, Haskell, &amp; JavaScript
</caption>
<thead>
<tr>
<th scope="col">
</th>
<th scope="col">
Lambda calculus
</th>
<th scope="col">
Haskell
</th>
<th scope="col">
JavaScript
</th>
</tr>
</thead>
<tbody>
<tr>
<th scope="row">
Abstraction
</th>
<td>
<code>λ x . y</code>
</td>
<td>
<code>\ x -&gt; y</code>
</td>
<td>
<code>(x) =&gt; y</code>
</td>
</tr>
<tr>
<th scope="row">
Application
</th>
<td>
<code>f x</code>
</td>
<td>
<code>f x</code>
</td>
<td>
<code>f(x)</code>
</td>
</tr>
<tr>
<th scope="row">
Variable
</th>
<td>
<code>x</code>
</td>
<td>
<code>x</code>
</td>
<td>
<code>x</code>
</td>
</tr>
</tbody>
</table>

<h2 id="unconditional-λ">Unconditional λ</h2>
<p>Lambdas are the only way to introduce values—they’re the only “literal” syntax in the language. We can therefore infer that the only kinds of runtime values must be closures. In an interpreter for the lambda calculus, closures might consist of the name of the introduced variable, the body of the lambda, &amp; a map relating the names and values of any variables it closed over when constructed (again, we assume strict lexical scoping). There are no bits, bytes, words, pointers, or objects in the language’s semantics; only this runtime representation of lambdas.</p>
<p>Likewise, lambdas are also the only way to introduce variables—there’s no standard library, built-ins, primitives, prelude, or global environment to provide common definitions. We’re truly baking the apple pie from scratch.</p>
<p>All of this raises the question: how do you <em>do</em> anything when you don’t even have <code>true</code> and <code>false</code>? Lambdas and variables don’t <em>do</em>, they merely <em>are</em>, so that leaves application. When all you have is application, everything looks like a lambda abstraction, so we’ll represent booleans using lambdas.</p>
<p>Of course, it’s not <em>just</em> booleans we’re after; <code>true</code> and <code>false</code> aren’t much use without <code>and</code>, <code>or</code>, <code>not</code>, <code>if</code>, and all the rest. To be useful, our representation of booleans should therefore suffice to define these, as well. But how do you define <code>if</code> without using <code>if</code>? In a lazy language like Haskell, we might define <code>if</code> as a function something like so:</p>
<div id="cb1"><pre><code><span id="cb1-1"><span>if_ ::</span> <span>Bool</span> <span>-&gt;</span> a <span>-&gt;</span> a <span>-&gt;</span> a</span>
<span id="cb1-2">if_ cond then_ else_ <span>=</span> <span>if</span> cond <span>then</span> then_ <span>else</span> else_</span></code></pre></div>
<p>In a strict language like JavaScript, we’d instead take functions for the alternatives:</p>
<div id="cb2"><pre><code><span id="cb2-1"><span>function</span> <span>if_</span>(cond<span>,</span> then_<span>,</span> else_) {</span>
<span id="cb2-2">  <span>if</span> (cond) {</span>
<span id="cb2-3">    <span>then_</span>()<span>;</span></span>
<span id="cb2-4">  } <span>else</span> {</span>
<span id="cb2-5">    <span>else_</span>()<span>;</span></span>
<span id="cb2-6">  }</span>
<span id="cb2-7">}</span></code></pre></div>
<p>Both these definitions use the language’s native booleans and <code>if</code> syntax (a tactic for implementing embedded DSLs known as “meta-circularity”), and thus aren’t viable in the lambda calculus. However, they do give us a hint: in both cases we have a function taking a condition, consequence, and alternative, and using the first to select one of the latter two. In the lambda calculus, we might start by writing:</p>
<pre><code>if = λ cond then else . ?</code></pre>
<p>(Note: there aren’t any keywords in the lambda calculus, so there’s nothing stopping me from naming variables things like <code>if</code>, a fact which I will take free advantage of.)</p>
<p>We’ve introduced a definition for <code>if</code>, as a function of three parameters; now what do we do with them? The lambda calculus’s stark palette makes it easy to enumerate <em>all</em> the things we can do with some variable <code>a</code>:</p>
<ol type="1">
<li><p>Ignore it, whether by simply not mentioning it at all (as in <code>λ a . λ b . b</code>), or by shadowing it with another lambda which binds the same name (as in <code>λ a . λ a . a</code>).</p></li>
<li><p>Mention it, whether on its own in the body of a lambda (as in <code>λ a . a</code> or <code>λ a . λ b . a</code>), somewhere within either side of an application (as in <code>λ a . λ b . a b</code> or <code>λ a . λ b . b a</code>), or some combination of both (as in <code>λ a . (λ b . a) a</code>).</p></li>
</ol>
<p>We could for example simply return <code>then</code> or <code>else</code>:</p>
<pre><code>if = λ cond then else . then
if = λ cond then else . else</code></pre>
<p>But in that case the conditional isn’t conditional at all—the value in no way depends on <code>cond</code>. Clearly the body must make use of all three variables if we want it to behave like the <code>if</code>s we know and love from other languages.</p>
<p>Taking a step back for a moment, let’s examine the roles of <code>if</code>’s arguments. <code>then</code> and <code>else</code> are passive; we only want to use or evaluate one or the other depending on the value of <code>cond</code>. <code>cond</code>, then, is the key: it takes the active role.</p>
<p>Thus, in the same way that our <code>if_</code> functions in Haskell &amp; JavaScript employed those language’s features to implement, we’re going to define <code>if cond then else</code> as the application of the condition to the other two parameters:</p>
<pre><code>if = λ cond then else . cond then else</code></pre>

<p>This feels strangely like cheating: surely we’ve only moved the problem around. Now instead of <code>if</code> making the decision about which argument to return, we’ve deferred it to <code>cond</code>. But <code>if</code> and <code>cond</code> aren’t the same, semantically; <code>if</code> takes a boolean and two other arguments and returns one of the latter, while <code>cond</code> <em>is</em> a boolean—albeit evidently a boolean represented as a function. Let’s make that precise by writing down <code>if</code>’s type:</p>
<pre><code>if : Bool -&gt; a -&gt; a -&gt; a</code></pre>
<p>Notwithstanding our use of the yet-to-be-defined name <code>Bool</code> for the type of the condition, this is the same type as we gave <code>if_</code> in Haskell; that’s a good sign that we’re on the right track! It takes a <code>Bool</code> and two arguments of type <code>a</code>, and it must return one of those because that’s the only way for it to come up with the <code>a</code> that it returns. But what <em>is</em> <code>Bool</code>?</p>
<p>Working backwards from the type and definition of <code>if</code>, we see that <code>cond</code> is applied to two arguments, and therefore must be a function of two parameters. Further, these are both of type <code>a</code>, and the value it returns must also be of type <code>a</code> for <code>if</code>’s type to hold. Thus, we can define the type <code>Bool</code> like so:</p>
<pre><code>Bool = ∀ a . a -&gt; a -&gt; a</code></pre>

<p>If a given <code>Bool</code> is a function of two arguments of arbitrary type, returning the same type, it must therefore select one of its arguments to return. There are only two distinguishable inhabitants of <code>Bool</code>, <code>true</code> and <code>false</code>, so we can therefore deduce that since <code>if</code> defers the selection of the result to the <code>Bool</code>, for <code>true</code> and <code>false</code> to actually differ they must make opposite selections. In other words, <code>true</code> must return the <code>then</code> parameter, while <code>false</code> must return the <code>else</code> one:</p>
<pre><code>true, false : Bool
true  = λ then else . then
false = λ then else . else</code></pre>
<p>We didn’t move the problem around after all; we solved it. What we noticed was a deeper insight: this encoding of booleans makes <code>if</code> redundant, since if we can apply <code>if</code> to a <code>Bool</code> and two arguments, we could equally apply the <code>Bool</code> to those arguments directly.</p>

<p>It’s frequently convenient to conflate booleans with bits, their minimal representation, but in truth they’re not the same at all. Practically, some programming languages define booleans as a byte in memory, perhaps clamping its values to 0 and 1; others define them as instances of some boolean class, or constructors of an algebraic datatype. Some provide no formal relationship between <code>true</code> and <code>false</code> at all, save for a common interface—duck typing.</p>
<p>Mathematically, booleans are the values in propositional logic; the upper and lower bounds of a lattice; the zero and one of a semiring; the members of the set with cardinality 2; …</p></article></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://antitypical.com/posts/2020-03-29-all-you-need-is-lambda-1-booleans/">https://antitypical.com/posts/2020-03-29-all-you-need-is-lambda-1-booleans/</a></em></p>]]>
            </description>
            <link>https://antitypical.com/posts/2020-03-29-all-you-need-is-lambda-1-booleans/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24601981</guid>
            <pubDate>Sat, 26 Sep 2020 20:46:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Pikchr – PIC-like markup language for diagrams in technical documentation]]>
            </title>
            <description>
<![CDATA[
Score 62 | Comments 8 (<a href="https://news.ycombinator.com/item?id=24601971">thread link</a>) | @smartmic
<br/>
September 26, 2020 | https://pikchr.org/home/doc/trunk/homepage.md | <a href="https://web.archive.org/web/*/https://pikchr.org/home/doc/trunk/homepage.md">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div>

<p>Pikchr (pronounced "picture") is a <a href="https://en.wikipedia.org/wiki/Pic_language">PIC</a>-like markup
language for diagrams in technical documentation.  Pikchr is
designed to be embedded in <a href="https://spec.commonmark.org/0.29/#fenced-code-blocks">fenced code blocks</a> of
Markdown or similar mechanisms of other documentation markup languages.</p>

<p>For example, the diagram:</p>
<!--0E0963AB574FA9FBD5D3D2FD226DC36650B428D37F17ABA05833DA2BBA324DBB-->
<div><p>
<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 423.821 195.84">
<polygon points="146,37 134,41 134,33" style="fill:rgb(0,0,0)"></polygon>
<path d="M2,37L140,37" style="fill:none;stroke-width:2.16;stroke:rgb(0,0,0);"></path>
<text x="74" y="25" text-anchor="middle" fill="rgb(0,0,0)" dominant-baseline="central">Markdown</text>
<text x="74" y="49" text-anchor="middle" fill="rgb(0,0,0)" dominant-baseline="central">Source</text>
<path d="M161,72L258,72A15 15 0 0 0 273 57L273,17A15 15 0 0 0 258 2L161,2A15 15 0 0 0 146 17L146,57A15 15 0 0 0 161 72Z" style="fill:none;stroke-width:2.16;stroke:rgb(0,0,0);"></path>
<text x="209" y="17" text-anchor="middle" fill="rgb(0,0,0)" dominant-baseline="central">Markdown</text>
<text x="209" y="37" text-anchor="middle" fill="rgb(0,0,0)" dominant-baseline="central">Formatter</text>
<text x="209" y="57" text-anchor="middle" fill="rgb(0,0,0)" dominant-baseline="central">(markdown.c)</text>
<polygon points="417,37 405,41 405,33" style="fill:rgb(0,0,0)"></polygon>
<path d="M273,37L411,37" style="fill:none;stroke-width:2.16;stroke:rgb(0,0,0);"></path>
<text x="345" y="25" text-anchor="middle" fill="rgb(0,0,0)" dominant-baseline="central">HTML+SVG</text>
<text x="345" y="49" text-anchor="middle" fill="rgb(0,0,0)" dominant-baseline="central">Output</text>
<polygon points="209,72 214,84 205,84" style="fill:rgb(0,0,0)"></polygon>
<polygon points="209,123 205,111 214,111" style="fill:rgb(0,0,0)"></polygon>
<path d="M209,78L209,117" style="fill:none;stroke-width:2.16;stroke:rgb(0,0,0);"></path>
<path d="M176,193L243,193A15 15 0 0 0 258 178L258,138A15 15 0 0 0 243 123L176,123A15 15 0 0 0 161 138L161,178A15 15 0 0 0 176 193Z" style="fill:none;stroke-width:2.16;stroke:rgb(0,0,0);"></path>
<text x="209" y="138" text-anchor="middle" fill="rgb(0,0,0)" dominant-baseline="central">Pikchr</text>
<text x="209" y="158" text-anchor="middle" fill="rgb(0,0,0)" dominant-baseline="central">Formatter</text>
<text x="209" y="178" text-anchor="middle" fill="rgb(0,0,0)" dominant-baseline="central">(pikchr.c)</text>
</svg>
</p>
<pre>arrow right 200% "Markdown" "Source"
box rad 10px "Markdown" "Formatter" "(markdown.c)" fit
arrow right 200% "HTML+SVG" "Output"
arrow &lt;-&gt; down 70% from last box.s
box same "Pikchr" "Formatter" "(pikchr.c)" fit
</pre>
</div>
<!--0E0963AB574FA9FBD5D3D2FD226DC36650B428D37F17ABA05833DA2BBA324DBB-->

<p>Is generated by 7 lines of Markdown:</p>
<pre><code>   ``` pikchr
   arrow right 200% "Markdown" "Source"
   box rad 10px "Markdown" "Formatter" "(markdown.c)" fit
   arrow right 200% "HTML+SVG" "Output"
   arrow &lt;-&gt; down 70% from last box.s
   box same "Pikchr" "Formatter" "(pikchr.c)" fit
   ```
</code></pre>
<p>Pikchr diagrams can appear in:</p>

<ul>
<li>Documentation</li>
<li>Wiki pages</li>
<li>Tickets and bug reports</li>
<li>Forum posts</li>
<li>Check-in comments</li>
<li>Anywhere else that Markdown or similar markup languages are used</li>
</ul>

<p>Pikchr diagrams are easy to generate.  The language is simple.
There is lots of documentation and examples on-line (links below).
Anyone who is comfortable using Markdown should be able to pick up Pikchr
with minimal extra effort.</p>

<p>Pikchr is safe for use in internet-facing applications.  Hostile
Pikchr scripts cause no harm (apart from generating ugly diagrams).</p>

<h2>Demos</h2>
<ul>
<li><a href="https://pikchr.org/home/doc/trunk/doc/examples.md">Example Pikchr Scripts</a></li>
<li><a href="https://pikchr.org/home/pikchrshow">/pikchrshow</a> ← Enter Pikchr text and see the result on-line</li>
</ul>

<h2>Documentation Is A Work In Progress</h2>
<p>As of 2020-09-16, the Pikchr code is stable and is in active use.
However, documentation is still under development.
We are using Pikchr to write the Pikchr documentation (in Markdown),
hence it was necessary to deploy Pikchr into a working content
management system (<a href="https://fossil-scm.org/fossil">Fossil</a> in this case) prior to having
complete documentation available.  Volunteer assistance is welcomed!</p>

<h2>Pikchr Documentation (<em>still under development</em>)</h2>
<ul>
<li><a href="https://pikchr.org/home/doc/trunk/doc/userman.md">Pikchr User Manual</a></li>
<li><a href="https://pikchr.org/home/doc/trunk/doc/teardown01.md">An Example Of How A Pikchr Script Is Written</a></li>
<li><a href="https://pikchr.org/home/doc/trunk/doc/grammar.md">Pikchr Language Grammar</a></li>
<li><a href="https://pikchr.org/home/doc/trunk/doc/differences.md">Differences From PIC</a></li>
<li><a href="https://pikchr.org/home/doc/trunk/doc/usepikchr.md">Invoking Pikchr From Markdown</a></li>
<li><a href="https://pikchr.org/home/doc/trunk/doc/build.md">How To Build Pikchr From Source</a></li>
</ul>

<h2>Copies Of Historical PIC Documentation</h2>
<ul>
<li><a href="https://pikchr.org/home/uv/pic.pdf">BWK paper on the original PIC</a></li>
<li><a href="https://pikchr.org/home/uv/dpic-doc.pdf">DPIC Documentation</a></li>
<li><a href="https://pikchr.org/home/uv/gpic.pdf">ESR GnuPIC Docs</a></li>
</ul>

<h2>Source-Code License: 0-clause BSD</h2>
<p>The Pikchr source code is a self-contained original work.  It has no
external dependencies apart from the standard C library and does not
use code taken from the internet or other external sources.  All of the Pikchr
source code is released under a <a href="https://spdx.org/licenses/0BSD.html">zero-clause BSD license</a>.  After being
processed using <a href="https://www.sqlite.org/lemon.html">Lemon</a>, the Pikchr source code is a single
file of C89 named "<code>pikchr.c</code>".  These features
are designed to make Pikchr <a href="https://pikchr.org/home/doc/trunk/doc/integrate.md">easy to integrate into other systems</a>.</p>

</div>


</div></div>]]>
            </description>
            <link>https://pikchr.org/home/doc/trunk/homepage.md</link>
            <guid isPermaLink="false">hacker-news-small-sites-24601971</guid>
            <pubDate>Sat, 26 Sep 2020 20:45:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Send Audio Messages in Gmail]]>
            </title>
            <description>
<![CDATA[
Score 25 | Comments 14 (<a href="https://news.ycombinator.com/item?id=24600928">thread link</a>) | @nathanganser
<br/>
September 26, 2020 | https://nat.app/gmail-record-audio | <a href="https://web.archive.org/web/*/https://nat.app/gmail-record-audio">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="grid"><div><h2>Why should you send audio emails?</h2><p>A few powerful use cases...</p><div><div><h3>Explain complex ideas</h3><p>Some things are hard to explain per text. Send an audio message instead.</p></div><div><h3>Communicate better</h3><p>Text can be understood in many ways. Your voice and tone says a lot, use it. </p></div><div><h3>Build trust</h3><p>Working remote or dealing with distant partners? Send an audio message to build trust and strengthen the relationship.</p></div></div></div></div></div>]]>
            </description>
            <link>https://nat.app/gmail-record-audio</link>
            <guid isPermaLink="false">hacker-news-small-sites-24600928</guid>
            <pubDate>Sat, 26 Sep 2020 18:19:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to properly manage SSH keys for server access]]>
            </title>
            <description>
<![CDATA[
Score 284 | Comments 142 (<a href="https://news.ycombinator.com/item?id=24599837">thread link</a>) | @mpaepper
<br/>
September 26, 2020 | https://www.paepper.com/blog/posts/how-to-properly-manage-ssh-keys-for-server-access/ | <a href="https://web.archive.org/web/*/https://www.paepper.com/blog/posts/how-to-properly-manage-ssh-keys-for-server-access/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <p>Every developer needs access to some servers for example to check the application logs.</p>
<p>Usually, this is done using public-private key encryption where each developer generates their own public-private key pair.
The public keys of each developer are added to the <code>authorized_keys</code> file on each server they should have access to.</p>
<h2 id="painful-manual-changes">Painful manual changes</h2>
<p>So far so good. However, what happens when one developer leaves the company?</p>
<p>In that case, the public keys of that developer should be removed from all servers. This could be quite a bit of work depending on how many servers they had access to.
And even worse, if it’s done manually, there is quite some risk that the key is still forgotten on some server, so the access remains open.</p>
<h2 id="alternative-solutions">Alternative solutions</h2>
<p>There are some commercial and open source solutions out there which want to help out with this problem. The basic idea is that you add and maintain the keys and the access lists on that service and when you remove a key, they will remove it from all your servers.</p>
<p>Sounds good, but it has one very big disadvantage: it’s a potential single source of failure. If someone captures access to that service, they can gain access to all your servers. And if you lose access to that service, you also lose access to all your servers in the worst case.</p>
<h2 id="the-solution-signing-keys">The solution: signing keys</h2>
<p>When I was facing this problem, I asked on <a href="https://news.ycombinator.com/item?id=24157180">HackerNews</a> how others are tackling this problem.</p>
<p>There were some great suggestions and insights from the community and the best solution to the problem seems to be the signing of keys which I will present to you here in detail.</p>
<h3 id="the-rough-idea">The rough idea</h3>
<p>The rough idea is this: You still generate a public-private key pair for each developer. However, you don’t upload the public keys to your servers.</p>
<p>Instead, you sign the public keys with a so-called certificate authority (CA) key which you generate before. This signing simply generates a third certificate file which you give back to the developer and they put it inside of their <code>.ssh/</code> folder next to the private and public key.</p>
<p>On the servers, you simply tell the server the public key of your CA and the server can detect if a user has a properly signed certificate and only allows access to the developers who have such a signed certificate.</p>
<h3 id="the-advantages">The advantages</h3>
<p>When you sign a certificate, you can determine how long that signing is valid. So if you sign it with a validity of 3 months and the developer leaves the company, then after 3 months they won’t have access to any of the servers for sure.</p>
<p>Now you say: well, but I don’t want to sign keys of everyone every 3 months which is a fair point.</p>
<p>One possibility is to automate the process for example by building a service where a user can automatically get a signed certificate when they authorize with their company e-mail and password, but that is beyond the scope of this article.</p>
<p>The simple alternative is that you issue certificates that are valid longer and then if someone leaves the company, you can revoke the certificate, i.e. invalidate it. You can put a list of invalid certificates on your servers and they will not accept the user any more.
This could for example be done by having this list on AWS S3 or some other storage and a cronjob on each server that regularly pulls this.</p>
<h3 id="show-me-how-to-do-this">Show me how to do this</h3>
<p>Glad that you asked!</p>
<p>It’s actually super simple once you know the drill.</p>
<p>First, you generate a certificate authority public-private key pair of which you should keep the private key very secure:</p>
<div><pre><code data-lang="bash">umask <span>77</span>                        <span># you want it to be private</span>
mkdir ~/my-ca <span>&amp;&amp;</span> cd ~/my-ca
ssh-keygen -C CA -f ca -b <span>4096</span>  <span># be sure to use a passphrase and store it securely</span>
</code></pre></div><p>Then on your server you specify that all users signed by your CA are allowed to access the server:</p>
<ol>
<li>Upload the public key of your CA on your server, e.g. at <code>/etc/ssh/ca.pub</code></li>
<li>Tell the server to allow access to users signed by it by adding a line to <code>/etc/ssh/sshd_config</code>:</li>
</ol>
<div><pre><code data-lang="bash">TrustedUserCAKeys /etc/ssh/ca.pub <span># Trust all with a certificate signed by ca.pub</span>
</code></pre></div><p>To make the changes effective, you should reload the ssh service: <code>sudo service ssh reload</code>.</p>
<p>Now if a developer generated their public-private key pair (e.g. <code>ssh-keygen -t ecdsa -b 521</code>), they simply send you their public key (note that you never need to send any private keys around!).
Then you sign their public key to generate their certificate:</p>
<div><pre><code data-lang="bash"><span># Inside your ~/my-ca folder, sign their public key (here: id_ecdsa.pub)</span>
ssh-keygen -s ca -I USER_ID -V +12w -z <span>1</span> id_ecdsa.pub
</code></pre></div><p>Quick explanation for the different parts:</p>
<ul>
<li><code>-s ca</code> - you want to use your CA to sign</li>
<li><code>-I USER_ID</code> - the id of your user / the username</li>
<li><code>-V +12w</code> - how long before the certificate expires - here valid for 12 weeks</li>
<li><code>-z 1</code> - the serial number of this certificate - can be used to make this particular certificate invalid later, should be unique</li>
<li><code>id_ecdsa.pub</code>: the public key of the developer which you want to sign</li>
</ul>
<p>It will generate the certificate <code>id_ecdsa-cert.pub</code> which you can send to the developer and they put it into their <code>~/.ssh</code> folder next to their public-private key pair.</p>
<h3 id="it-gets-even-better">It gets even better</h3>
<p>Sounds cool, right? But you can do even better!</p>
<p>You probably have developers with different experience and different teams and roles and not everyone accessing the same servers.</p>
<p>So let’s add roles into the signing process!</p>
<p>That way, on the server you specify which roles are allowed to access the server and during the signing process you specify the roles of the developer you are signing.</p>
<p>Then, that developer can access all servers matching to their roles.</p>
<p>When you on board a new developer, you only need to generate that one certificate and boom they have access to all relevant servers without adding anything on those servers.</p>
<p>Here is how this looks like schematically:</p>

  <figure>
    <img src="https://www.paepper.com/blog/posts/how-to-properly-manage-ssh-keys-for-server-access/ssh-keys-with-roles.png" alt="ssh certificate signing with roles">
    
      <figcaption>ssh certificate signing with roles</figcaption>
    
  </figure>


<p>This is how you configure roles on a server:</p>
<p>First, create the folder to configure access: <code>sudo mkdir /etc/ssh/auth_principals</code>
Inside that folder, you can create files with the name of the server user that someone could login as. For example to grant root access to some roles, add the file <code>/etc/ssh/auth_principals/root</code>.</p>
<p>Inside <code>/etc/ssh/auth_principals/root</code> you simply list all roles which should be able to login as root with one role per line:</p>
<p>Finally, configure on the server to use roles by again adding a line to <code>/etc/ssh/sshd_config</code>:</p>
<div><pre><code data-lang="bash">AuthorizedPrincipalsFile /etc/ssh/auth_principals/%u
</code></pre></div><p>To make the changes effective, you should reload the ssh service: <code>sudo service ssh reload</code>.</p>
<p>This is how you sign a key with roles (they are added to the certificate):</p>
<div><pre><code data-lang="bash">ssh-keygen -s ca -I USER_ID -n ROLE1,ROLE2 -V +12w -z <span>2</span> id_ecdsa.pub
</code></pre></div><p>It’s the same as before, but with the <code>-n ROLE1,ROLE2</code> flag. Important: there can’t be spaces between the comma for different roles!</p>
<p>Now, that developer could log onto any server where <code>ROLE1</code> or <code>ROLE2</code> are in an auth_principals file for a user name they try to login as.</p>
<h3 id="revoking-keys">Revoking keys</h3>
<p>Finally, if you want to invalidate a certificate, you can do that by the user name or the serial number of the certicate (<code>-z</code> flag). It’s recommended to make a list of generated certificates in an Excel spreadsheet or have a database depending on the number of your peeps.</p>
<div><pre><code data-lang="bash">ssh-keygen -k -f revoked-keys -u -s ca list-to-revoke
</code></pre></div><p>This is when you already have a <code>revoked-keys</code> list and want to update it (<code>-u</code> flag). For the initial generation, use it without the update flag.</p>
<p>The <code>list-to-revoke</code> needs to consist of usernames (ids) or serial numbers (<code>-z</code> flag during generation) like this:</p>
<pre><code>serial: 1
id: test.user
</code></pre><p>This would revoke access to the certificate with serial 1 and all certificates with id <code>test.user</code>.</p>
<p>To make the server respect revoked keys, you need to add the generated / updated <code>revoked keys</code> file to <code>/etc/ssh/revoked-keys</code> and configure it again in <code>/etc/ssh/sshd_config</code>:</p>
<p>Warning: make sure that the <code>revoked-keys</code> file is accessable and readable, otherwise you might lose access to your server</p>
<div><pre><code data-lang="bash">RevokedKeys /etc/ssh/revoked-keys
</code></pre></div><h2 id="summary-good-ssh-key-management">Summary: good ssh key management</h2>
<p>In my opinion, this solution is as good as it gets. You have the option to manage the access to your servers via ssh based on roles. You only need to configure your servers once (which roles are allowed to access it). For each new developer, you only need to generate a signed certificate and they immediately have access to all relevant machines matching their role / experience.
And when they leave the company, you can revoke their access also in a simple way.</p>
<p>And even if a mishap occurs and a developer leaves without having their access revoked, their certificate will expire after some time, so they also lose access automatically.</p>
<p>For small teams, you can do these steps manually as they are very fast to do; then as you grow, you can automate the certificate signing with a login service based on company authentication details.</p>
<p>Happy ssh-ing!</p>

    </div></div>]]>
            </description>
            <link>https://www.paepper.com/blog/posts/how-to-properly-manage-ssh-keys-for-server-access/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24599837</guid>
            <pubDate>Sat, 26 Sep 2020 16:13:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Fun with cell phone webcam and WebGL shaders]]>
            </title>
            <description>
<![CDATA[
Score 34 | Comments 14 (<a href="https://news.ycombinator.com/item?id=24599739">thread link</a>) | @jgeduldig
<br/>
September 26, 2020 | https://acidicworks.github.io/AcidFilters/ | <a href="https://web.archive.org/web/*/https://acidicworks.github.io/AcidFilters/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>         
            <p>Real-time webcam filters for laptop and mobile device cameras (front and back)</p>
          </div></div>]]>
            </description>
            <link>https://acidicworks.github.io/AcidFilters/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24599739</guid>
            <pubDate>Sat, 26 Sep 2020 15:58:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Stop Asking Me to “Sign Up” (2014)]]>
            </title>
            <description>
<![CDATA[
Score 372 | Comments 235 (<a href="https://news.ycombinator.com/item?id=24599642">thread link</a>) | @jeremylevy
<br/>
September 26, 2020 | https://www.gkogan.co/blog/stop-asking-me-to-sign-up/ | <a href="https://web.archive.org/web/*/https://www.gkogan.co/blog/stop-asking-me-to-sign-up/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p><img src="https://d33wubrfki0l68.cloudfront.net/6682ce0e9be9292fb093d16e4b89a6cbec481554/1fe8d/images/uploads/sign-up-buttons.png" alt="SaaS Startups Using Sign Up Buttons"></p>

<p>The fate of many&nbsp;startups depends almost entirely on one&nbsp;conversion point: When a visitor becomes a user.</p>

<p>All too often, this pivotal role&nbsp;falls on the shoulders of a pitifully generic “sign up” button that’s lucky to get even a minute of consideration during development.</p>

<p>If you take a moment to consider the wording of your signup button, you can drastically increase how many of your visitors turn into users.</p>

<p><em>(What happens after the conversion is important, too, but things get significantly easier once you have someone’s email and opt-in.)</em></p>
<h2>Why "Sign Up" buttons don't work.</h2>
<ul>
  <li><strong>They're&nbsp;ignored.&nbsp;</strong>When visitors see common elements repeated on many sites, they begin unconsciously ignoring those elements (aka "habituation").&nbsp;Doesn't matter if they're blue or green or hell-fire-orange.</li>
  <li><strong>You're asking for blind commitment.</strong>&nbsp;Don't&nbsp;assume visitors&nbsp;know what you're asking them to sign up for. People don't read pages, they skim. They could've easily missed the part where you mention a&nbsp;free trial or key benefits.</li>
  <li><strong>You're not offering any value.</strong> Asking someone to "sign up" offers no help in changing the visitor's thinking from "Why should I?" to "I want this!"</li>
</ul>
<h2>How to get more signups&nbsp;from your signup button:</h2>
<ul>
  <li><strong>Tie it to your product.</strong> If you have a SaaS for trading bitcoins: "Start Trading Bitcoins." If&nbsp;you have a marketplace for artists: "Start Selling Art." This helps prevent the button from being overlooked.</li>
  <li><strong>Give, don't take.</strong> "Get Access" and "Sign Up" both lead to the same thing, but one makes the visitor feel they're getting something, while the other doesn't.</li>
  <li><strong>Compel people to act.</strong> Use action verbs such as <em>get</em>, <em>start</em>, and <em>try</em>.</li>
</ul>
<p>Examples from startups that get it right:</p>

<p><img src="https://d33wubrfki0l68.cloudfront.net/a5e786dc725cdf0d2cc7d265cf2130fd5e785f5e/09f83/images/uploads/sign-up-buttons-2.png" alt="Startups with Good Signup Buttons"></p>

<p>(I especially like gliffy’s “Start Drawing,” which implies how quickly you can get started, and directly relates to&nbsp;their product: <a href="http://www.gliffy.com/">an app for easily drawing diagrams</a>.)</p>
<h2>Case study: Getting 3x more clicks by changing two words.</h2>
<p>Take this example from one of my clients. Like many software companies, Scalyr—a <a href="https://www.scalyr.com/">log aggregation and monitoring tool</a>—asked its visitors to “sign up.” I suggested that we test a version of the button that <em>gives</em> and <em>compels</em>: “Try it Free”. Here’s what happened:</p>

<p><strong>Asking visitors to <em>Try it Free</em> <span>increased clicks by 212%</span>.</strong></p>

<p>Complete obliteration of the old “Sign Up” button, and a&nbsp;huge win for a test that took two minutes to set up.</p>

<p><img src="https://d33wubrfki0l68.cloudfront.net/7562f9ce9e08b024e6c838126e1d6f54e24e07ed/7465d/images/uploads/scalyr-test-result.png" alt="A/B test on Scalyr resulted in 212% increase in clicks."></p>
<h2>Now try it yourself...</h2>
<p>Test a variation of your “sign up” button with something that <em>gives</em>,&nbsp;<em>compels</em>, and is <em>tied to your product</em>. It’s one of the easiest things to test, and could have a huge effect on your conversion rates. If you follow my advice then you’re almost certain to do better than asking visitors to “sign up.”</p>


    <p>◼</p>

    <p>PS - Liked this article? I write one every month or so, covering lessons learned on B2B startup growth. Don't miss the next one:</p>

    <!-- Begin MailChimp Signup Form -->
    

    <!--End mc_embed_signup-->
    
    <p>If you need help with marketing and revenue growth, <a href="https://www.gkogan.co/contact/">get in touch</a>.</p>

  </div>

  

  
  
  



</article>

<!-- Begin MailChimp popup signup form -->



<!-- End MailChimp popup signup form -->
      </div>
    </div></div>]]>
            </description>
            <link>https://www.gkogan.co/blog/stop-asking-me-to-sign-up/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24599642</guid>
            <pubDate>Sat, 26 Sep 2020 15:47:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Towards Principled Reactive UI]]>
            </title>
            <description>
<![CDATA[
Score 205 | Comments 79 (<a href="https://news.ycombinator.com/item?id=24599560">thread link</a>) | @raphlinus
<br/>
September 26, 2020 | https://raphlinus.github.io/rust/druid/2020/09/25/principled-reactive-ui.html | <a href="https://web.archive.org/web/*/https://raphlinus.github.io/rust/druid/2020/09/25/principled-reactive-ui.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p>This is a followup to my post about a year ago, <a href="https://raphlinus.github.io/ui/druid/2019/11/22/reactive-ui.html">Towards a unified theory of reactive UI</a>. It is a deeper exploration of the question: “what is the best way to express reactive UI in Rust?”</p>

<h2 id="introduction">Introduction</h2>

<p>There is an astonishing diversity of “literature” on reactive UI systems. I put “literature” in quotes here, because, with some exceptions, the best primary sources are the code of open source projects. Some of the diversity comes from differences in goals, but some of it is accidental. In many cases, it’s simply because the designers didn’t have insight at the time about better solutions. My post last year attempted to put some order to this diversity, by discovering common patterns.</p>

<p>I believe it’s likely that the answer to “the best way to express reactive UI in Rust” is to be found in the existing literature, at least by combining major themes, if not in a single existing system to copy. It seems unlikely we’ll have to invent something completely new. But sorting through it is not easy. It is not the intent of this post to provide a comprehensive review of the literature (though I think such a thing would be interesting), it is to guide inquiry into the most promising avenues. I want to do mining, not stamp collecting. Where is the richest vein of ore?</p>

<p>To focus the inquiry, I will start by listing some goals. While in general these goals all seem like good things, it’s important to understand them as tradeoffs. Prioritizing different goals will lead you to different places, and not everyone has the same needs. Take overall system complexity, for example. If you’re a trillion dollar corporation, then a complex system is merely a question of allocating resources, and may even be strategically useful as a moat to discourage competition. But if you’re an indie game developer trying to integrate basic UI, you have a very different perspective.</p>

<p>Each goal will be presented primarily as a way to introduce design decisions made by existing reactive systems, and filter the ones that seem most promising as sources and inspiration.</p>

<p>Then I will go into deeper into three principles, which I feel are critically important in any reactive UI framework: whether to use “observable objects,” how to express the mutation of the render object tree (or trees in general), and the notion of stable identity of nodes in that tree.</p>

<p>Finally, I will introduce <a href="https://github.com/raphlinus/crochet">Crochet</a>, a research prototype built for the purpose of exploring these ideas.</p>

<h2 id="goals">Goals</h2>

<h3 id="concise-expression-of-application-logic">Concise expression of application logic</h3>

<p>The main point of a reactive UI architecture is so that the app can express its logic clearly and concisely, and the results can drive the rest of the UI stack in a reasonable way.</p>

<p>A central feature of reactive UI is for the app to declaratively express the current state of the view tree. In traditional object-oriented UI, it’s more common to specify the initial state (often as a static document, not even code), plus additional logic for state changes. I think the debate is now essentially over, the reactive approach is winning.</p>

<p>SwiftUI has gained considerable attention due to its excellent ergonomics in this regard. But other approaches are also worth studying. In particular, immediate mode GUI (<a href="https://github.com/ocornut/imgui">imgui</a>) is nearly as declarative, it just achieves it in a very different way (about which more below). And React and its many derivatives are also “good enough.” <a href="https://svelte.dev/">Svelte</a> is another example from the JS world that deserves praise, though considerably more difficult to adapt to Rust because of its reliance on a sophisticated compiler.</p>

<p>It’s very popular in Rust GUI land to adapt <a href="https://guide.elm-lang.org/architecture/">Elm</a> patterns; we see clear influence in <a href="https://github.com/antoyo/relm">relm</a>, <a href="https://github.com/hecrj/iced">Iced</a>, <a href="https://github.com/bodil/vgtk">vgtk</a>, and others. But I think much of the conciseness and friendliness of Elm comes from the language itself, particularly its facility with higher-order composition. When adapting to a more pragmatic language such as Rust, I consider each subtask of view building and dispatching messages to components as each a half-lens, requiring the writing out of two pieces of logic to integrate a component. For this reason, I find Rust UI code adapted from Elm to be not as clear and concise as possible.</p>

<p>A great resource for comparing the concision of different toolkits is <a href="https://eugenkiss.github.io/7guis/">7GUIs</a>. We don’t have these ported to Crochet yet, except for counter, but plan to. For reference, here’s the <code>run</code> method for that:</p>

<div><div><pre><code>    <span>fn</span> <span>run</span><span>(</span><span>&amp;</span><span>mut</span> <span>self</span><span>,</span> <span>cx</span><span>:</span> <span>&amp;</span><span>mut</span> <span>Cx</span><span>)</span> <span>{</span>
        <span>Label</span><span>::</span><span>new</span><span>(</span><span>format!</span><span>(</span><span>"current count: {}"</span><span>,</span> <span>self</span><span>.count</span><span>))</span><span>.build</span><span>(</span><span>cx</span><span>);</span>
        <span>if</span> <span>Button</span><span>::</span><span>new</span><span>(</span><span>"Increment"</span><span>)</span><span>.build</span><span>(</span><span>cx</span><span>)</span> <span>{</span>
            <span>self</span><span>.count</span> <span>+=</span> <span>1</span><span>;</span>
        <span>}</span>
    <span>}</span>
</code></pre></div></div>

<h3 id="actually-being-incremental">Actually being incremental</h3>

<p>While imgui can express UI concisely, it cheats somewhat by not being incremental. Generally, it makes up for this by being able to repaint the world very quickly (using GPU acceleration), but there are downsides, including power consumption. In the context of a game which is actively using the GPU anyway, it’s fine, but is a good reason not to choose imgui outside that context.</p>

<p>The documentation of <a href="https://github.com/PistonDevelopers/conrod">Conrod</a> expresses a goal fairly well: “Conrod aims to adopt the best of both worlds by providing an immediate mode API over a hidden, retained widget state graph.” And once you have that, doing efficient incremental updates in the retained widget graph is a solved problem, though the details can be intricate. Unfortunately, I do not believe Conrod delivers on this promise, because app logic does an awful lot of explicit graph construction and juggling of node id’s, neither of which you would find in an actual immediate mode API.</p>

<p>On the other side, <a href="https://github.com/hecrj/iced">Iced</a>, while having many desirable properties, does not satisfy the “actually incremental” goal: while there is caching in the renderer, it builds a full view tree every 16ms (actually twice when there are incoming events). This is fine when the view tree is relatively small, but is a serious problem at scale.</p>

<p>The popularity of “virtual DOM” approaches requires a discussion of diffing, which I feel is (modulo escape hatches for lower level direct tree mutation) a form of half-incrementality. The idea is that it should be cheap to produce a full view tree, then a reconciliation engine computes a minimal diff between that and the old tree, which is then be applied, through DOM mutation or some other means. Because DOM is slow, it’s certainly faster than ham-handed direct DOM mutation (which is difficult to make truly minimal), but still creates performance problems as the view tree grows. React programmers should be well familiar with this issue.</p>

<p>When escape hatches are provided, are they a reasonably principled way to achieve lower level access to tree mutation, simply shifting some tracking of state to the component (often a list view or similar collection), or are they a dirty hack to work around fundamental architectural decisions that limit performance? Both are represented in the literature.</p>

<h3 id="tab-focusing">Tab focusing</h3>

<p>It seems like a relatively simple feature, but proper implementation of tab focusing requires fairly deep architectural support (or, in the case of Web-based UI, it is punted to the browser). Basically, it requires the toolkit to maintain state of which widget is focused, and to query enough of the entire view tree to determine which is the next in tab focus order. Proponents of imgui have suggested a very hacky partial solution (see <a href="http://www.johno.se/book/imgui.html">johno on IMGUI</a>), but I find such things unsatisfying.</p>

<p>Again, Iced is an example of an existing Rust GUI toolkit that is lacking this feature, and I think would require nontrivial architectural work to address, at least in a systematic way that would satisfy similar future needs. Down the line, those needs include accessibility, a serious Achilles heel for imgui-flavored designs in particular.</p>

<p>I believe a proper approach to this problem involves stable identity of widgets, about which much more below.</p>

<h3 id="simple-types">Simple types</h3>

<p>Now we get into more controversial goals. One that I personally am finding increasingly important is expressing the interface between app logic and UI toolkit using simple types.</p>

<p>Rust in particular invites the use of complex types, largely because it has a rich type system that is capable of expressing many concepts as types. By contrast, it’s traditional in object oriented UI to have very loosely coupled dynamic typing; a lot of the values being passed around have a type which is some variant of “any.”</p>

<p>A great example of complex types is SwiftUI, in which a component returns a statically-known type implementing the <a href="https://developer.apple.com/documentation/swiftui/view"><code>View</code></a> protocol. As a consequence, the concrete return type of a component generally encodes its entire view hierarchy, including special conditional and looping combinators; this is explained well in the <a href="https://www.objc.io/blog/2019/11/05/static-types-in-swiftui/">Static Types in SwiftUI</a> blog.</p>

<p>There are advantages to such a scheme, but also serious downsides. Error messages from the compiler get… interesting. And it also has a serious impact on compile times, as (at least in Rust) the compiler has to monomorphize the types before even starting to generate code.</p>

<p>To me, one of the most serious drawbacks to the complex type approach is that scripting languages can’t easily play, as the types must be known at compile time.</p>

<p>Again, imgui is an example of an architecture that avoids complex types, by drawing the UI directly rather than constructing an intermediate tree of view objects. But imgui is not the only such; another compelling example to learn from is <a href="https://medium.com/androiddevelopers/under-the-hood-of-jetpack-compose-part-2-of-2-37b2c20c6cdd">Jetpack Compose</a>.</p>

<h3 id="simple-control-flow">Simple control flow</h3>

<p>It is very tempting to use complex control flow patterns: putting significant logic in callbacks, using higher order composition techniques, or using a compiler to significantly transform the code. Yet, such techniques have downsides.</p>

<p>The first is simply that this complexity leaks out into the app. In current Druid, we use some higher order composition techniques such as lenses. While fairly simple by Haskell standards, and our users with Haskell background tend to like them, a lot of people coming to Druid find them confusing.</p>

<p>The simplest mechanism for …</p></div></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://raphlinus.github.io/rust/druid/2020/09/25/principled-reactive-ui.html">https://raphlinus.github.io/rust/druid/2020/09/25/principled-reactive-ui.html</a></em></p>]]>
            </description>
            <link>https://raphlinus.github.io/rust/druid/2020/09/25/principled-reactive-ui.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24599560</guid>
            <pubDate>Sat, 26 Sep 2020 15:36:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Randomized Living]]>
            </title>
            <description>
<![CDATA[
Score 42 | Comments 28 (<a href="https://news.ycombinator.com/item?id=24599440">thread link</a>) | @joubert
<br/>
September 26, 2020 | https://maxhawkins.me/work/randomized_living | <a href="https://web.archive.org/web/*/https://maxhawkins.me/work/randomized_living">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
    

    <section id="intro">
        <div>
            <p>For the past two years I’ve been letting randomized computer programs decide what I do.</p>
            <p>I believe giving in to chance is a way to liberate yourself from personal and social programming that traps you in a narrow sense of self.</p>
        </div>

        <p><img src="https://d33wubrfki0l68.cloudfront.net/fc964a042abbadff5604d8c26c2815855cf65889/e21fa/images/sip-point.jpg" alt="photo of me pointing at a random place">
        </p>
    </section>

	<section id="newsletter">
		<h2>Subscribe here for stories from my random path:</h2>
		
	</section>

    <section id="trip">
        <div>
            <h2>My Trip</h2>
            <p>Starting in 2015 I let a computer decide where I lived and what I did for over two years. It sent me all over the world—everywhere from <a href="https://www.google.com/maps/place/Noonans+North/@42.601437,-90.9984737,17z/data=!3m1!4b1!4m5!3m4!1s0x87fcb393f67baf4b:0x54d13227bb28cc1e!8m2!3d42.601437!4d-90.996285?q=noonans+north&amp;um=1&amp;ie=UTF-8&amp;sa=X&amp;ved=0ahUKEwjunKjD1qzUAhUQzmMKHTLqD1MQ_AUICigB" target="_blank">small town bars</a> in rural Iowa to cat cafes in Taipei, Taiwan.</p>
            <p>When the computer chose a location I would live there for roughly a month. Once there, the computer chose places to go, people to meet, and things to do within the selected city.</p>
        </div>
        <div>
            <p><img src="https://d33wubrfki0l68.cloudfront.net/de76d0afe885d62e73407c947f00d6c14d57e465/6e325/images/bot-map.jpg" alt="map of Ljubljana created by the bot"></p><figcaption>Random path through Ljubljana</figcaption>
        </div>
    </section>

    <section id="videos">
        <h2>Videos</h2>
        <iframe width="560" height="315" src="https://www.youtube.com/embed/3ecDsJrkKn4" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
        <iframe width="560" height="315" src="https://www.youtube.com/embed/anwk8b7c_s0" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
    </section>

    <section id="tools">
		<h2>Tools for Living Randomly</h2>

        

        

        

        

    </section>

    <section id="tools">
		<h2>Exhibitions</h2>

        
    </section>


	

	
	
	
	
	
	

</div>]]>
            </description>
            <link>https://maxhawkins.me/work/randomized_living</link>
            <guid isPermaLink="false">hacker-news-small-sites-24599440</guid>
            <pubDate>Sat, 26 Sep 2020 15:18:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The fresh smell of ransomed coffee]]>
            </title>
            <description>
<![CDATA[
Score 130 | Comments 178 (<a href="https://news.ycombinator.com/item?id=24599434">thread link</a>) | @zdw
<br/>
September 26, 2020 | https://decoded.avast.io/martinhron/the-fresh-smell-of-ransomed-coffee/ | <a href="https://web.archive.org/web/*/https://decoded.avast.io/martinhron/the-fresh-smell-of-ransomed-coffee/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-720">

                    
                    
                    
                    <div>
                        
<div><figure><img src="https://lh3.googleusercontent.com/edWAE16W2o2XYc5tH2XhF49IdvtCSlgypcNVCDiuoLXHmq-1Cs3oN4fbZMwIhrnyKmx4HCDBi4u8oIA8FalwMddd_dHQ9emWYzmv6EWZTAqccf4_OFsrb2trEqiK-K7I3m8y4Si_" alt=""></figure></div>



<p>We turned a coffee maker into a dangerous machine asking for ransom by modifying the maker’s firmware. While we could, could someone else do it too? As you might expect, the answer is: Yes. Follow us on a journey where we show you that firmware is the new software.&nbsp;</p>







<p>Some research is so fun that it confirms why I do this work. I was asked to prove a myth, call it a suspicion, that the threat to IoT devices is not just to access them via a weak router or exposure to the internet, but that an IoT device itself is vulnerable and can be easily owned without owning the network or the router. I also bet that I could make that threat persist and present a true danger to any user. We often say that your home network, thought of as a chain of trust, is only as strong as its weakest link, but what if the same were true at the device level? What would that mean?&nbsp;</p>



<p>Let’s say you have an IoT device that is well protected with functions that can be accessed through a well-defined API; even if you can control the device through the API, you probably can’t do too much harm. Firmware, the programming inside the device has logical constraints that don’t allow you, for example, to close garage doors while someone is in the way of them or overheat a device so that it combusts.&nbsp;</p>



<p>We used to trust that hardware, such as a common kitchen appliance, could be trusted and could not be easily altered without physically dismounting the device. But with today’s “smart” appliances, this is no longer the case.</p>



<p>My colleagues often hear me say that&nbsp; “firmware is a new software.” And that software is very often flawed. We see it everywhere. CPU flaws, and cryptographic chips generating weak keys that can be easily broken. The weakened state of IoT security is due in large part to the fact that, nowadays, it is more convenient and cheap to place a processor inside a device which controls and orchestrates all hardware parts, motors, sensors, heating elements, etc. based on a short program called firmware. This solution is not only cheap, but has also one important property – it can be updated</p>



<p><br>Back in the day, if there was a so-called design flaw in a piece of hardware, the rigid design (often hardwired) meant the vendor would need to replace the whole component or logic board or even replace the entire device. Manufacturers would have to change the manufacturing process and at potentially great financial losses. In the era of firmware, this can be easily mitigated just by issuing a firmware update.&nbsp;</p>



<p>The process of updating firmware can vary greatly, from connecting to the special device using a special tool (which still requires the vendor’s physical interaction) to the more and more popular way of OTA (over the air) updates. In this case, a vendor doesn’t have to be physically present and the whole process is done either automatically over the internet or semi-automatically after a user’s notification and approval of the update.&nbsp;</p>







<p>So let’s see what we have. We have a coffee maker that allows you to make coffee the old fashioned way by pressing a few buttons or via a mobile phone or tablet using an app. The maker operates with Wi-Fi and when unboxed you have to connect it to your network through a companion app on your mobile phone. When turned on for the first time, the coffee maker works in a local mode and it creates its own Wi-Fi network that the hopeful coffee drinker first connects to in order to set up the device.&nbsp;</p>



<p>When we downloaded the companion app, we saw that it allows you to create a network of any&nbsp; devices of this particular vendor and connects these devices to the&nbsp; home network and then allows you to control all the functions of your coffee maker or smart kettle. It also allows you to check the firmware version of the device and update it if needed.&nbsp;</p>



<p>The protocol that this device speaks has already been documented on the internet by <a href="#references">several other researchers</a>. As expected, it’s a simple binary protocol with hardly any encryption, authorization or authentication. Communication with machines takes place on <code>TCP</code> port <code>2081</code>. The format of the command is very simple:</p>



<div><figure><img loading="lazy" width="593" height="111" src="https://decoded.avast.io/wp-content/uploads/sites/2/2020/09/image-6.png" alt="" srcset="https://decoded.avast.io/wp-content/uploads/sites/2/2020/09/image-6.png 593w, https://decoded.avast.io/wp-content/uploads/sites/2/2020/09/image-6-300x56.png 300w" sizes="(max-width: 593px) 100vw, 593px"></figure></div>







<p>In response (if there is a response) the coffee maker sends back:</p>



<div><figure><img loading="lazy" width="593" height="111" src="https://decoded.avast.io/wp-content/uploads/sites/2/2020/09/image-10.png" alt="" srcset="https://decoded.avast.io/wp-content/uploads/sites/2/2020/09/image-10.png 593w, https://decoded.avast.io/wp-content/uploads/sites/2/2020/09/image-10-300x56.png 300w" sizes="(max-width: 593px) 100vw, 593px"></figure></div>



<p><code>response_type</code> differs based on the command, but the general rule is: If the response contains data <code>response_type = command + 1</code>, if it’s just a status then <code>response_type=3</code> and then there is only one <code>data</code> byte which contains resulting status, where <code>1</code> means success. The complete list of commands is in the  <a href="https://github.com/avast/ioc/tree/master/SmarterCoffee" target="_blank" rel="noreferrer noopener">GitHub repository</a>.<br></p>



<p>&nbsp;So just for illustration, by issuing this command:</p>



<div><figure><img loading="lazy" width="396" height="78" src="https://decoded.avast.io/wp-content/uploads/sites/2/2020/09/image-8.png" alt="" srcset="https://decoded.avast.io/wp-content/uploads/sites/2/2020/09/image-8.png 396w, https://decoded.avast.io/wp-content/uploads/sites/2/2020/09/image-8-300x59.png 300w" sizes="(max-width: 396px) 100vw, 396px"><figcaption><em>making a nice cup of coffee with “default” settings</em></figcaption></figure></div>







<p>You’ll make yourself a nice cup/cups of coffee based on the default settings of the coffee maker. As you can see, there is no security, so anyone who has access to the network and is able to reach the IP address of the coffee maker can control it. What is more interesting, is that all these commands are also available through that default opened Wi-Fi network when the device is not joined to a home network yet.&nbsp;</p>







<p>Let’s return to our main goal of hijacking the coffee maker for nefarious purposes. How secure is the updating process? Can we break into it? Can we even change the firmware to do something else than was originally intended? Can we turn the device into a physically dangerous device? Can we do it remotely? As I said in the beginning, the weakest link always compromises the whole system. Either it’s a network or a device. The goal is answering all the above questions and prove that IoT devices could be also compromised at the firmware level.</p>



<p>To start, we wanted to learn how the update process works. We have several options to do this, but we already have a recipe for this based on similar past research we have done. The general rule is to make it as simple as possible; here is our to-do list when trying to reverse the update process of a piece of firmware.</p>



<ol><li>Get it (the file with the firmware)</li><li>Unpack it (if it is packed/encrypted)</li><li>Reverse engineer it (translate those zeroes and ones into meaningful code)</li><li>Modify it (add the malicious content)</li><li>Upload it (and push it back to the device)</li></ol>



<p>It’s simple right?</p>







<p>First, we need to get the firmware somehow, and again there are several options. Let’s stick to the rule, the simplest option first:</p>



<ol><li>Google it – as obvious as it seems,&nbsp; sometimes security researchers omit this step which could save them a lot of work. Firmware is often available on the internet to be downloaded.</li><li>Capture and analyze network traffic – if the protocol is unencrypted the easiest way is to just capture the network traffic, in that case, we have three more options where to look<ul><li>traffic between the device and the internet</li><li>traffic between device and companion app, if there is any</li><li>traffic between the companion app and the internet</li></ul></li><li>Analyze and reverse engineer the companion app. Before we dive deeply into the device, it’s advisable to first peek into the device’s companion app, it’s usually the easiest solution for grabbing the communication protocol and commands. No luck with any of the above? It’s time to dismount the device, trace the board to identify all the components, get datasheets to find debugging ports, and possibly dump the firmware directly from the chip. This is really an adventure in hardware and not for everyone.</li></ol>



<p>Life is not so simple, and neither is reverse engineering IoT devices. It turned out that we had to use a combination of all the aforementioned techniques. First, we googled it, and as the commands have already been documented, we found a command that says <code>“update the firmware.”</code> But the command itself (its parameters and format) had not been documented. So by issuing:</p>







<div><figure><img loading="lazy" src="https://decoded.avast.io/wp-content/uploads/sites/2/2020/09/image-9.png" alt="" width="396" height="78" srcset="https://decoded.avast.io/wp-content/uploads/sites/2/2020/09/image-9.png 396w, https://decoded.avast.io/wp-content/uploads/sites/2/2020/09/image-9-300x59.png 300w" sizes="(max-width: 396px) 100vw, 396px"><figcaption>t<em>his simple (two bytes) command switches coffee maker into update mode</em></figcaption></figure></div>







<p>the coffee maker goes into an update mode (on the newer firmware you have to push a button to actually start the update, but this is not the case with older versions !)</p>



<div><figure><img src="https://lh4.googleusercontent.com/zt-eEhReRyN8xe20y_NoBwNR_TCZ02Y87hyXVZDDiU6WtGGW2s4bmTBy37tdaIS9TBm5hLoBKwqcc1iE0tHjhC4HzVqqhSX_DB1bRUvGy9QTeuwGiYuSRVXTuoWxnkGFwOn57tVX" alt=""></figure></div>







<p>Hmm nice, but nothing happens. By analyzing network traffic, we concluded that there is nothing to analyze, as there is no traffic coming out of the coffee maker at this stage. So we tried the Android companion app.&nbsp;</p>



<div><figure><img src="https://decoded.avast.io/wp-content/uploads/sites/2/2019/08/Screen-Shot-2019-08-02-at-9.30.47-AM.png" alt="This image has an empty alt attribute; its file name is Screen-Shot-2019-08-02-at-9.30.47-AM.png"><figcaption><em>Android application for smart coffee maker, right picture shows an update screen</em></figcaption></figure></div>







<p>You can see the update button is grayed out, so obviously, the firmware is up-to-date and there is no easy option to push the firmware update to be able to see what’s in the network traffic. What’s interesting here is what’s missing. There was no communication to the internet neither from the coffee maker nor from the app. So how is it possible that the app knows that the coffee maker has the latest firmware? The only packets of data that went through were those between the machine and app when the app had been asking the machine for the version of the firmware.</p>



<div><figure><img loading="lazy" width="677" height="177" src="https://decoded.avast.io/wp-content/uploads/sites/2/2020/09/image-4.png" alt="" srcset="https://decoded.avast.io/wp-content/uploads/sites/2/2020/09/image-4.png 677w, https://decoded.avast.io/wp-content/uploads/sites/2/2020/09/image-4-300x78.png 300w" sizes="(max-width: 677px) 100vw, 677px"><figcaption>Typical traffic analysis of IoT with companion app: we are interested in traffic between app and internet and app and device.</figcaption></figure></div>







<p>This is strange, and it seemed to tell us that the firmware is probably not on the internet and must be part of the app. So we opened the .apk file as easy as a .zip file. What we found there, proved our assumption.&nbsp;</p>



<div><figure><img src="https://lh5.googleusercontent.com/reUvllV7KNcZW0e9A4E_XljR0jknTZL-CLUbS3vJx0uiyArpgKdEVSpK1vEUUG0Q6Tu00I0wUlZMdQ8nG1w_Mdxz611TUCxA2DozEy0wftaC0qynZhhx8_pKNc6VeST1djzBgVti" alt=""><figcaption><em>Files inside the apk: You can see firmware for both products are contained in the two files with suffix .bin&nbsp;</em></figcaption></figure></div>







<p>The firmware is part of the Android app and it also means that new versions of the firmware always come with new versions of the app. This makes perfect sense if you think about it for a second. The new firmware usually adds new functionality, which has to be reflected somehow inside the user interface of the app, and it allows us to find a file containing the firmware without even touching the device. That’s nice and not very common.</p>







<p>In the next step of my research we try to figure out …</p></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://decoded.avast.io/martinhron/the-fresh-smell-of-ransomed-coffee/">https://decoded.avast.io/martinhron/the-fresh-smell-of-ransomed-coffee/</a></em></p>]]>
            </description>
            <link>https://decoded.avast.io/martinhron/the-fresh-smell-of-ransomed-coffee/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24599434</guid>
            <pubDate>Sat, 26 Sep 2020 15:17:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Endless Frontier Act]]>
            </title>
            <description>
<![CDATA[
Score 36 | Comments 13 (<a href="https://news.ycombinator.com/item?id=24598904">thread link</a>) | @rfreytag
<br/>
September 26, 2020 | https://benjaminreinhardt.com/the-endless-frontier-act/ | <a href="https://web.archive.org/web/*/https://benjaminreinhardt.com/the-endless-frontier-act/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  <div>
    <div>

      

      <article role="main">
        <p>This is going to be a painfully cliched, but imagine that the American science and technology system is an engine. It’s just not performing as well as it used to. It’s making a lot of noise and when we push the accelerator it’s sluggish. This bill assumes the solution is STEP ON THE ACCELERATOR HARDER. That is, it wants to slam more money through a system shot through with friction and bad incentives. Slamming on the accelerator when your engine has problems doesn’t often fix the problem. I’ve tried it, and it ended up with my car ‘<a href="https://www.cartalk.com/content/what-does-it-mean-throw-rod#:~:text=The%20motion%20of%20that%20piston,one%20of%20two%20things%20occurs.">throwing a rod</a>.’</p>

<p>Senator Todd Young (R-Ind.), Senate Democratic Leader Chuck Schumer (D-N.Y.), Congressman Ro Khanna (D-Calif.), and Congressman Mike Gallagher (R-Wis.) introduced “The Endless Frontier Act” a bipartisan bill to spend $100B to super-charge the National Science Foundation at the end of May. You can read an official announcement <a href="https://www.young.senate.gov/newsroom/press-releases/young-schumer-unveil-endless-frontier-act-to-bolster-us-tech-leadership-and-combat-china">here</a> and Noah Smith’s summary on Bloomberg <a href="https://www.bloomberg.com/opinion/articles/2020-06-01/the-u-s-gets-serious-about-catching-up-to-china-in-r-d">here</a>.</p>

<p>Some thoughts after reading through the actual text of the bill. (My eyes will bleed so yours don’t need to.)</p>

<p>This bill is proposing to give money with risk-averse restrictions to a risk-averse organization (the NSF) to be dispersed among other risk-averse organizations (Universities) into a system with increasingly risk-averse incentives.  Note that I’m not saying “it’s all fubar’d lets burn it to the ground!” but I am suggesting that instead of slamming on the accelerator, we should be asking “what would a tune-up and an oil change look like instead? “</p>

<h3 id="the-bill">The Bill</h3>
<p>The bill comes back to its  <code>Key Technology Focus Areas</code> throughout the document:</p>

<p>(i) artificial intelligence and machine learning;
(ii) high performance computing, semiconductors, and advanced computer hardware
(iii) quantum computing and information systems
(iv) robotics, automation, and advanced manufacturing
(v) natural or anthropogenic disaster prevention
(vi) advanced communications technology
(vii) biotechnology, genomics, and synthetic biology
(viii) cybersecurity, data storage, and data management technologies;
(ix) advanced energy
(x) materials science, engineering, and exploration relevant to the other key technology focus areas described in this subparagraph.</p>

<p>That list is pretty uncontroversial.<sup id="fnref:1" role="doc-noteref"><a href="#fn:1">1</a></sup> And that should raise a flag. In other words, this is a list of “what are the top 10 hot technologies right now?” What if there is suddenly a huge opportunity in airship technology? Or underground construction? Or wormholes? It wouldn’t be too much of a problem but this list can only be changed <em>every four years</em>.  You could make the argument that these definitions are so broad that anything could fit in them - ok, then what’s the point of having the list in the first place?</p>

<p>The bill is heavy on bureaucratic requirements and light on science or organizational structure (“we’ll figure that out later.”)  Which reports need to be given to whom and when, how money can and can’t be spent, etc. I agree that this is the job of lawmakers, but it doesn’t feel like opening up an endless frontier, it feels like “here are the walls of your sandbox.”</p>

<p>We are very clear that the grant awards are going to happen on a competitive basis. The bill is shot through with the term <code>award grants, on a competitive basis</code> . This is code for “to get this money, amazing scientist, are going to need to spend a good chunk of your life writing grants” and interacting with websites that look like <a href="https://www.research.gov/research-web/">this.</a> or <a href="https://www.grants.gov/">this</a>.  Competition is good <em>when the output is valuable no matter who wins.</em> Failed grants are basically worthless except as the basis for other grant applications. Economist <a href="https://www.youtube.com/watch?feature=player_embedded&amp;v=XwBP_pqkGJA">Mike Munger does a great job explaining how grants can often end up burning more value than they create</a>.  Months of grant writing is one of the things that makes people think twice about academia.</p>

<p>The bill specifies exactly what the money can be used for <code>may be used for the purchase of equipment, the support of graduate students and postdoctoral researchers, and the salaries of staff. </code> Like the key areas, this sounds eminently reasonable. However, it means that grant money, unlike normal money, is not fully fungible. You need to track all of it and where it goes in case you are audited. It also means that if the project runs into an expense that doesn’t fall into one of these buckets - say you need a specialized service from a company to do an experiment - you’re stuck. Chilling effects are hard to measure, but my research experience has been shot through with being forced to pay more for an inferior product through a web portal that made your eyes bleed because we had to prioritize “approved vendors” for accounting reasons tied to restrictions like these.</p>

<p>I don’t think it matters for this discussion but <code>$20B/year</code> is misleading - the actual bill specifies that the $100B will be backloaded: $2B in 2021, $8B in 2022, $20B in 2023, and $35B in 2024 and 2025.</p>

<h3 id="nstf">NS(T?)F</h3>
<p><code>“I share your feeling about this point,” I said with the fervor of conviction, “but then why not do something about the retardation of scientific progress?”</code></p>

<p><code>“That I would very much like to do,” Mark Gable said, “but how do I go about it?”</code></p>

<p><code>“Well,” I said, “I think that shouldn’t be very difficult. As a matter of fact, I think it would be quite easy. You could set up a foundation, with an annual endowment of thirty million dollars. Research workers in need of funds could apply for grants, if they could make out a convincing case. Have ten committees, each composed of twelve scientists, appointed to pass on these applications. Take the most active scientists out of the laboratory and make them members of these committees. And the very best men in the field should be appointed as chairmen at salaries of fifty thousand dollars each. Also have about twenty prizes of one hundred thousand dollars each for the best scientific papers of the year. This is just about all you would have to do. Your lawyers could easily prepare a charter for the foundation. As a matter of fact, any of the National Science Foundation bills which were introduced in the Seventy-ninth and Eightieth Congresses could perfectly well serve as a model.”</code></p>

<p><code>“I think you had better explain to Mr. Gable why this foundation would in fact retard the progress of science,” said a bespectacled young man sitting at the far end of the table, whose name I didn’t get at the time of introduction. It should be obvious,” I said. “First of all, the best scientists would be removed from their laboratories and kept busy on committees passing on applications for funds. Secondly, the scientific workers in need of funds would concentrate on problems which were considered promising and were pretty certain to lead to publishable results. For a few years there might be a great increase in scientific output; but by going after the obvious, pretty soon science would dry out. Science would become something like a parlor game. Some things would be considered interesting, others not. There would be fashions. Those who followed the fashion would get grants. Those who wouldn’t would not, and pretty soon they would learn to follow the fashion, too.”</code>
From <a href="https://judgestarling.tumblr.com/post/619829573132107776/a-short-story-by-martian-physicist-le%C3%B3-szil%C3%A1rd">The Marla Gable Foundation</a> by Nobel Prize winning Physicist Leo Szilard, published in 1948.</p>

<p>The core idea of the bill is to increase the National Science Foundation’s funding and expand its mandate to include technology development as well as science.</p>

<p>Roughly, the National Science Foundation - NSF (and the NIH) decide what to work on by getting some of the ‘top people’ in a field together in a room and asking them “what programs should we pursue?” This process depends first on being able to identify the top people in a field and convincing them to stay in a shitty hotel in Washington. So the agenda is being set by ‘the top people in a field who are willing to come to Washington and stay in a shitty hotel.’ Additionally, who entails the ‘top people’ is up to the program officers and since professors have long term relationships with their NSF program officers, chances are that the professors who have put the work into those relationships are going to be the most salient.</p>

<p>All the incentives are set up so people probably push for their lines of research. Even if they are being completely intellectually honest, researchers probably think that their area of research is the most important thing to fund. If they are slightly less intellectually honest, they realize that they’re more likely to be funded if their priorities line up with the NSF’s.</p>

<p>The process is inherently conservative because if you’re consulting the top people in a field on what to fund, the chances they’ll suggest the weird new thing are low.</p>

<h4 id="but-will-be-like-darpa">But will be like DARPA!</h4>

<p>DARPA has a great track record of enabling paradigm shifting technology - it had its fingers in the creation of personal computing, the internet, modern robotics, gps, and autonomous cars, to name a few. Riffing on DARPA’s model to emulate its success is a worthy goal. However, there is only one section in the entire bill that gives a head nod to the DARPA model:</p>

<p><code>The Director shall have the authority to carry out a program of personnel management authority for the Directorate in the same manner, and subject to the same requirements, as the program of personnel management authority authorized for the Director of the Defense Advanced Research Projects Agency under section 1599h of title 10, United States Code, for the Defense Advanced Research Projects Agency.</code>
<code>(B) PROGRAM MANAGERS.—The employees of the Directorate may include program managers for the key technology focus areas, who shall perform a role similar to programs managers employed by the Defense Advanced Research Projects Agency for the oversight and selection of programs supported by the Directorate. </code></p>

<p>DARPA’s program managers work because they are embedded in an organizational structure and culture that is tuned to empower them to explore high-risk opportunities. DARPA has ~125 staff and three layers of hierarchy while the NSF …</p></article></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://benjaminreinhardt.com/the-endless-frontier-act/">https://benjaminreinhardt.com/the-endless-frontier-act/</a></em></p>]]>
            </description>
            <link>https://benjaminreinhardt.com/the-endless-frontier-act/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24598904</guid>
            <pubDate>Sat, 26 Sep 2020 13:59:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Facebook Says It Will Stop Operating in Europe If Regulators Don’t Back Down]]>
            </title>
            <description>
<![CDATA[
Score 37 | Comments 23 (<a href="https://news.ycombinator.com/item?id=24597347">thread link</a>) | @notRobot
<br/>
September 26, 2020 | https://www.vice.com./en_us/article/889pk3/facebook-threatens-to-pull-out-of-europe-if-it-doesnt-get-its-way | <a href="https://web.archive.org/web/*/https://www.vice.com./en_us/article/889pk3/facebook-threatens-to-pull-out-of-europe-if-it-doesnt-get-its-way">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Soumyabrata Roy/NurPhoto via AP</p></div><div data-component="BodyComponentRenderer"><p><span data-component="TextBlock"></span><span data-component="TextBlock"><p>CORK, Ireland â€” Facebook has threatened to pack up its toys and go home if European regulators donâ€™t back down and let the social network get its own way.</p>
</span><span data-component="TextBlock"><p>In a court filing in Dublin, Facebook said that a decision by Irelandâ€™s Data Protection Commission (DPC) would force the company to pull up stakes and leave the 410 million people who use Facebook and photo-sharing service Instagram in the lurch.</p>
</span></p><p><span data-component="TextBlock"><p>If the decision is upheld, â€œit is not clear to [Facebook] how, in those circumstances, it could continue to provide the Facebook and Instagram services in the EU,â€� Yvonne Cunnane, who is Facebook Irelandâ€™s head of data protection and associate general counsel, <a href="https://www.dropbox.com/s/yngcdv99irbm5sr/Facebook%20DPC%20filing%20Sept%202020-rotated.pdf?dl=0">wrote in a sworn affidavit</a>.</p>
</span><span data-component="TextBlock"><p>The decision Facebookâ€™s referring to is <a href="https://www.vice.com/en_ca/article/v7gkgy/europe-ordered-facebook-to-stop-sending-user-data-to-the-united-states">a preliminary order handed down last month</a> to stop the transfer of data about European customers to servers in the U.S., over concerns about U.S. government surveillance of the data.</p>
</span><span data-component="TextBlock"><p>Facebook hit back by filing a lawsuit challenging the Irish DPCâ€™s ban, and in a sworn affidavit filed this week, the company leveled some very serious accusations about the Irish data-protection commissioner, including a lack of fairness and apparent bias in singling out Facebook.</p>
</span><span data-component="TextBlock"><p>Cunnane points out that Facebook was given only three weeks to respond to the decision, a period that is â€œmanifestly inadequate,â€� adding that Facebook wasnâ€™t contacted about the inquiry prior to judgment being handed down.</p>
</span><span data-component="TextBlock"><p>She also raises concerns about the decision being made â€œsolelyâ€� by Helen Dixon, Irelandâ€™s data protection commissioner.</p>
</span><span data-component="TextBlock"><p>â€œThe fact one person is responsible for the entire process is relevant to [Facebookâ€™s] concerns, in respect of the inadequacy of the investigative process engaged in and independence of the ultimate decision-making process,â€� Cunnane wrote.</p>
</span><span data-component="TextBlock"><p>Cunnane also complains that Facebook is being singled out, noting no other big tech company using similar methods to transfer data to the U.S. from the EU is under the same scrutiny.</p>
</span></p><p><span data-component="TextBlock"><p>â€œThis gives rise to an apprehension that [Facebook] is not being treated equally,â€� Cullinane wrote. â€œIf [Facebook] alone is being investigated and subject to a suspension of data transfers to the U.S., this would be liable to create a serious distortion of competition.â€�</p>
</span><span data-component="TextBlock"><p>The Irish DPC declined to comment to VICE News. Facebook denies that it is trying to force the regulator to change its decision with a threat with withdraw its services.</p>
</span><span data-component="TextBlock"><p>â€œFacebook is not threatening to withdraw from Europe,â€� a Facebook spokesperson said, adding that the court filing simply lays out how â€œFacebook, and many other businesses, organisations and services, rely on data transfers between the EU and the US in order to operate their services.â€�</p>
</span><span data-component="TextBlock"><p>A judge last week allowed Facebookâ€™s challenge to go ahead and put a stay on the DPCâ€™s ban on data transfers â€” though the DPC can challenge that decision.</p>
</span><span data-component="TextBlock"><p>Besides threatening to close down Facebook and Instagram completely, Cunnane also points out that Facebook is an important tool for the freedom of expression of its 410 million EU users â€” it also reportedly generated â‚¬208 billion in sales for companies who use the platforms.</p>
</span><span data-component="TextBlock"><p>What she failed to mention, though, is that the service has also been weaponized to sow disinformation and conspiracy theories, as well as being used to influence the results of votes across the region, <a href="https://www.politico.eu/article/cambridge-analytica-leave-eu-ukip-brexit-facebook/">including the U.K.â€™s decision to leave the EU</a>.</p>
</span><span data-component="TextBlock"><p>Facebookâ€™s entire business model relies on being able to easily and quickly transfer data across the globe so that it can better target users with ads. By disrupting that flow of data, the EU is threatening Facebookâ€™s revenue potential, and as this lawsuit shows, that is something the company takes very seriously indeed.</p>
</span><span data-component="TextBlock"><p>But Facebookâ€™s ultimatum is little more than an empty threat, according to privacy experts.</p>
</span><span data-component="TextBlock"><p>â€œThe idea that Facebook would withdraw from the European market is absurd brinksmanship that I donâ€™t think anyone truly believes,â€� Michael Veale, a technology policy researcher at University College London, told VICE News.</p>
</span><span data-component="TextBlock"><p><em>Cover: In this illustration photo, the logo of Facebook is displayed on a smartphone in Tehatta, Nadia, West Bengal; India on June 4, 2020. (Photo Illustrattion by Soumyabrata Roy/NurPhoto via AP)</em></p>
</span></p></div><div><div><div><p><h3>Get a personalized roundup of VICE's best stories in your inbox.</h3></p><p>By signing up to the VICE newsletter you agree to receive electronic communications from VICE that may sometimes include advertisements or sponsored content.</p></div></div></div></div>]]>
            </description>
            <link>https://www.vice.com./en_us/article/889pk3/facebook-threatens-to-pull-out-of-europe-if-it-doesnt-get-its-way</link>
            <guid isPermaLink="false">hacker-news-small-sites-24597347</guid>
            <pubDate>Sat, 26 Sep 2020 08:47:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[On not choosing WordPress for the W3C redesign project]]>
            </title>
            <description>
<![CDATA[
Score 196 | Comments 192 (<a href="https://news.ycombinator.com/item?id=24596769">thread link</a>) | @ziodave
<br/>
September 25, 2020 | https://w3c.studio24.net/updates/on-not-choosing-wordpress/ | <a href="https://web.archive.org/web/*/https://w3c.studio24.net/updates/on-not-choosing-wordpress/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div tabindex="0"> <div>  <div class="page"> <div id="main-content" role="main">  <p> <span>Updates</span> <span>CMS</span> </p>  <hr> <p>The W3C redesign project is an incredibly exciting one for us at Studio 24, it’s an honour to be working with an organisation we have looked up to for our whole career. But it’s also challenging, with many aspects coming under more scrutiny than we’re normally used to. It’s also made harder in this time of pandemic, with increased anxiety and challenges working effectively during this “new normal” we’re all living in.</p> <p>We’re happy to rise to this challenge. Yesterday a well written article was published by WordPress Tavern on <a href="https://wptavern.com/w3c-drops-wordpress-from-consideration-for-redesign-narrows-cms-shortlist-to-statamic-and-craft">W3C dropping WordPress from consideration</a> which I’d like to respond to.</p> <h2 id="in-context-of-the-project"> <a href="#in-context-of-the-project"></a> In context of the project </h2> <p>We’ve tackled a huge variety of work so far from initial Discovery, User Research, Information Architecture, Content Design and UX Design that has helped move the project forward.</p> <p>The CMS platform decision is just part of this and for the end website is one of the less visible aspects. As you can read from <a href="https://w3c.studio24.net/docs/cms-selection-report/">Marie’s report on the work we did to choose Craft CMS</a> you can see the steps we went through to help shortlist and choose a CMS.</p> <p>For us, and the requirements from W3C, the delivery of accessible HTML/CSS pages that meet user needs is the most important part of this project - and where we are focussing our time. All in, we spent around 15 days on the CMS platform choice. Enough to help evaluate a limited number of options, but not enough to do a thorough review of the state of accessibility in a wide range of CMSs.</p> <p>We were surprised by the accessibility issues that cropped up in CMS platforms after our <a href="https://w3c.studio24.net/docs/w3c-cms-selection-process-update/">initial CMS review</a>. This prompted us to prioritise accessibility above other requirements due to the <a href="https://www.w3.org/Consortium/mission#principles">principles and values of W3C</a>.</p> <h2 id="challenges-of-gutenberg-for-now"> <a href="#challenges-of-gutenberg-for-now"></a> Challenges of Gutenberg (for now) </h2> <p><a href="https://www.studio24.net/">Studio 24</a> is a firm supporter of open source software and we use <a href="https://www.wordpress.org/">WordPress</a> extensively for our client work. For this project we had committed to not selecting a CMS until we’d had the chance to better understand client requirements.</p> <p>An important consideration for WordPress was accessibility concerns with the new Gutenberg editor. Many have written about the <a href="https://www.marcozehe.de/my-thoughts-on-gutenberg-accessibility/">accessibility issues</a> the project has had as well as the positive <a href="https://www.marcozehe.de/whats-new-for-accessibility-in-gutenberg-7-2/">steps to improve accessibility in Gutenberg</a>.</p> <p>Gutenberg is an exciting and really interesting development. Many CMS vendors are looking at ways to allow editors to create more flexible content from compontents or blocks. However, this comes with huge challenges on how to make innovative user interfaces accessible. WordPress decided to use the JavaScript framework <a href="https://reactjs.org/">React</a> to meet these needs.</p> <p>We <a href="https://medium.com/studio24/we-tried-converting-a-bespoke-website-design-in-wordpress-with-gutenberg-42e11986b05a">tested Gutenberg</a> six months before it was released in WordPress 5. Recently we worked on a project for the University of Cambridge creating a site for their <a href="https://magazine.alumni.cam.ac.uk/">Alumni magazine</a>. This launched in April 2020 and uses Gutenberg to manage content. This gave us a good idea of how Gutenberg works. In June, we reviewed the current accessibility issue backlog (<a href="https://github.com/WordPress/gutenberg/labels/Accessibility%20%28a11y%29">issues</a>, <a href="https://github.com/WordPress/gutenberg/projects/25">a11y project</a>) and had some feedback from users with accessibility needs who had difficulties using the current user interface. This was a contributing factor in our decision that WordPress was not a good fit for this project.</p> <p>Given the importance the WordPress project has put on Gutenberg as the future of WordPress we did not feel it was reasonable to recommend using the Classic Editor if there is a good chance this will not be supported in the future. At present <a href="https://make.wordpress.org/core/2018/11/07/classic-editor-plugin-support-window/">Classic Editor is slated for end of life in Dec 2021</a>.</p> <p>We look forward to the continued development of Gutenberg and applaud efforts to make it more accessible. We appreciate improvements have been made since our review and we’re very glad to see the <a href="https://wpaccessibilityday.org/">WordPress Accessibility Day</a> on 2nd October.</p> <h2 id="front-end-complexity"> <a href="#front-end-complexity"></a> Front-end complexity </h2> <p>From a business perspective I also believe Gutenberg creates a complexity issue that makes it challenging for use by many agencies who create custom websites for clients; where we have a need to create lots of bespoke blocks and page elements for individual client projects.</p> <p>The use of React complicates front-end build. We have very talented front-end developers, however, they are not React experts - nor should they need to be. I believe front-end should be built as standards-compliant HTML/CSS with JavaScript used to enrich functionality where necessary and appropriate.</p> <p>As of yet, we have not found a satisfactory (and profitable) way to build custom Gutenberg blocks for commercial projects. We won’t stop trying though and plan to do more R&amp;D with Gutenberg in the future. The W3C project, however, did not feel like the right place to do this. On a project as wide-ranging as this one, development time does become a factor.</p> <p>Drupal also has this complexity issue which makes developing sites harder than it needs to be, and is why we didn’t consider that platform either. I’ve talked to <a href="https://torchbox.com/blog/torchbox-has-dropped-drupal/">other agencies who have decided to drop Drupal</a> due to its complexity.</p> <h2 id="the-question-of-open-source"> <a href="#the-question-of-open-source"></a> The question of open source </h2> <p>The W3C embraces and supports the open web. However, as an agency we also have to be practical when it comes to the tools we use to build sites. From our review, which was focussed on PHP-based CMSs, Craft and Statamic came out as meeting all the key requirements and are both very developer-friendly platforms. An important consideration for a tool that we need to hand over to W3C to maintain in the future.</p> <p>While their <a href="https://github.com/craftcms/cms">source code</a> is open, they do have commercial licenses and cost money (though a modest sum). Charging money enables small teams to develop good software, so we’re not ideologically against this business model. Both platforms are well respected in the community and well-used by professionals, running sites such as <a href="https://media.netflix.com/en/">Netflix</a> and <a href="https://www.bigcommerce.com/">Big Commerce</a> in Craft, <a href="https://www.spiegel.de/plus/">Spiegel Plus</a> and <a href="https://www.freshbooks.com/">FreshBooks</a> in Statamic.</p> <p>We are using open source technology in the majority of this project (HTML/CSS, JavaScript, PHP, Symfony). While Craft is a proprietary CMS, this has given us the advantage of direct access to the team developing the CMS which has helped improve accessibility in these CMSs. We hope this helps move accessibility forward in the CMS industry.</p> <p>Open tools will continue to be used to publish the standards of the web. The <a href="https://www.w3.org/TR/">Technical Reports</a> page is powered by <a href="https://symfony.com/">Symfony</a> and specifications will continue to be published to <a href="https://github.com/w3c">GitHub</a> to facilitate open discussion. Nothing’s changing with how the W3C work in the open.</p> <h2 id="a-note-on-front-end-delivery"> <a href="#a-note-on-front-end-delivery"></a> A note on front-end delivery </h2> <p>One final note. We are currently considering a <a href="https://www.studio24.net/blog/what-is-a-headless-cms/">Headless CMS</a> option for front-end page delivery. This means using the CMS in a decoupled way to manage content but use a separate system to deliver front-end pages. Please note this solution would not be reliant on JavaScript (e.g. a single page app which is common with headless). Under this option we’d use Symfony to deliver front-end pages which is an established technology W3C already use across a lot of the site.</p> <p>This may give W3C better flexibility for the future, though comes at a cost of added complexity. The W3C site is already made up of a lot of different systems, the CMS is just one part of the what makes up the varied content on <a href="https://www.w3.org/">w3.org</a>.</p> <p>I hope this helps explain the thought process behind our decision a little more and addresses some of the valid concerns highlighted in the WordPress Tavern post.</p> <hr>  </div> </div> </div> </div></div>]]>
            </description>
            <link>https://w3c.studio24.net/updates/on-not-choosing-wordpress/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24596769</guid>
            <pubDate>Sat, 26 Sep 2020 06:05:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Is the C runtime and library a legitimate part of the Unix API? (2017)]]>
            </title>
            <description>
<![CDATA[
Score 49 | Comments 33 (<a href="https://news.ycombinator.com/item?id=24596680">thread link</a>) | @ingve
<br/>
September 25, 2020 | https://utcc.utoronto.ca/~cks/space/blog/unix/UnixAPIAndCRuntime | <a href="https://web.archive.org/web/*/https://utcc.utoronto.ca/~cks/space/blog/unix/UnixAPIAndCRuntime">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><h2>Is the C runtime and library a legitimate part of the Unix API?</h2>

	<p><small>December 31, 2017</small></p>
</div><div><p>One of the knocks against Go is, to quote from <a href="https://marcan.st/2017/12/debugging-an-evil-go-runtime-bug/">Debugging an evil
Go runtime bug</a> (partly
<a href="https://zaitcev.livejournal.com/240821.html">via</a>):</p>

<blockquote><p>Go also happens to have a (rather insane, in my opinion) policy of
reinventing its own standard library, so it does not use any of the
standard Linux glibc code to call vDSO, but rather rolls its own calls
(and syscalls too).</p>
</blockquote>

<p>Ordinary non-C languages on Unixes generally implement a great many
low level operations by calling into the standard C library. This
starts with things like making system calls, but also includes
operations such as <code>getaddrinfo(3)</code>. Go doesn't do this; it implements
as much as possible itself, going straight down to direct system
calls in assembly language. Occasionally there are problems that
ensue.</p>

<p>A few Unixes explicitly say that the standard C library is the
stable API and point of interface with the system; one example is
Solaris (and now Illumos). Although they don't casually change the
low level system call implementation, as far as I know Illumos
officially reserves the right to change all of their actual system
calls around, breaking any user space code that isn't dynamically
linked to <code>libc</code>. If your code breaks, it's your fault; Illumos
told you that dynamic linking to <code>libc</code> is the official API.</p>

<p>Other Unixes simply do this tacitly and by accretion. For example,
on any Unix using <code>nsswitch.conf</code>, it's very difficult to always
get the same results for operations like <code>getaddrinfo()</code> without
going through the standard C library, because these may use arbitrary
and <a href="https://utcc.utoronto.ca/~cks/space/blog/linux/SystemdResolvedNotes">strange</a> dynamically loaded
modules that are accessed through <code>libc</code> and require various random
<code>libc</code> APIs to work. This points out one of the problems here; once
you start (indirectly) calling random bits of the <code>libc</code> API, they
may quite reasonably make assumptions about the runtime environment
that they're operating in. How to set up a limited standard C library
runtime environment is generally not documented; instead the official
view is generally 'let the standard C library runtime code start
your <code>main()</code> function'.</p>

<p>I'm not at all sure that all of this requirement and entanglement
with the standard C library and its implicit runtime environment
is a good thing. The standard C library's runtime environment is
designed for C, and it generally contains a tangled skein of
assumptions about how things work. Forcing all other languages to
fit themselves into these undocumented constraints is clearly
confining, and the standard C library generally isn't designed to
be a transparent API; in fact, at least GNU libc deliberately
manipulates what it does under the hood to be more useful to C
programs. Whether these manipulations are useful or desired for
your non-C language is an open question, but the GNU libc people
aren't necessarily going to even document them.</p>

<p>(<a href="https://marcan.st/2017/12/debugging-an-evil-go-runtime-bug/">Marcan's story</a> shows
that the standard C library behavior would have been a problem for
any language environment that attempted to use minimal stacks while
calling into 'libc', here in the form of a kernel vDSO that's
designed to be called through libc. This also shows another aspect
of the problem, in that as far as I know how much stack space you
must provide when calling the standard C library is generally not
documented. It's just assumed that you will have 'enough', whatever
that is. C code will; people who are trying to roll their own
coroutines and thread environment, maybe not.)</p>

<p>This implicit assumption has a long history in Unix. Many Unixes
have only really documented their system calls in the form of the
standard C library interface to them, quietly eliding the distinction
between the kernel API to user space and the standard C library API
to C programs. If you're lucky, you can dig up some documentation
on how to make raw system calls and what things those raw system
calls return in unusual cases like <a href="https://utcc.utoronto.ca/~cks/space/blog/unix/SocketReturnAPIDesign"><code>pipe(2)</code></a>.
I don't think very many Unixes have ever tried to explicitly and
fully document the kernel API separately from the standard C library
API, especially once you get into cases like <code>ioctl()</code> (where there
are often C macros and <code>#define</code>s that are used to form some of the
arguments, which are of course only 'documented' in the C header
files).</p>
</div></div>]]>
            </description>
            <link>https://utcc.utoronto.ca/~cks/space/blog/unix/UnixAPIAndCRuntime</link>
            <guid isPermaLink="false">hacker-news-small-sites-24596680</guid>
            <pubDate>Sat, 26 Sep 2020 05:33:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Let's talk about safety of Pinephone]]>
            </title>
            <description>
<![CDATA[
Score 164 | Comments 65 (<a href="https://news.ycombinator.com/item?id=24596248">thread link</a>) | @lostmsu
<br/>
September 25, 2020 | https://xnux.eu/log/#017 | <a href="https://web.archive.org/web/*/https://xnux.eu/log/#017">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">

<ul>
	<li><a href="#019">2020–09–20: Downsizing the multi-boot image</a></li>
	<li><a href="#018">2020–09–20: Some ways to improve Pinephone safety</a></li>
	<li><a href="#017">2020–09–18: Let's talk about safety of Pinephone</a></li>
	<li><a href="#016">2020–09–17: Video acceleration experiments with PinePhone</a></li>
	<li><a href="#015">2020–09–16: PineBook Pro and Levinboot again</a></li>
	<li><a href="#014">2020–09–14: Putting 13 PinePhone distributions on a 8GiB uSD card</a></li>
	<li><a href="#013">2020–09–11: Adding postmarket OS to multi-distro image</a></li>
	<li><a href="#012">2020–09–11: Ways to help improve Pinephone kernel</a></li>
	<li><a href="#011">2020–09–11: PinePhone multi-boot image deduplication tool complete</a></li>
	<li><a href="#010">2020–09–10: PinePhone multi-boot image deduplication</a></li>
	<li><a href="#009">2020–09–08: PinePhone multi-boot finishing touches / modem improvements</a></li>
	<li><a href="#008">2020–09–08: PinePhone multi-boot image optimizations</a></li>
	<li><a href="#007">2020–09–07: PinePhone multi-boot image boot testing</a></li>
	<li><a href="#006">2020–09–05: PinePhone multi-boot image</a></li>
	<li><a href="#005">2020–09–04: Pinebook Pro and Levinboot</a></li>
	<li><a href="#004">2020–09–02: Progress on the multi-boot image</a></li>
	<li><a href="#003">2020–09–01: More p-boot cleanups and an example configuration</a></li>
	<li><a href="#002">2020–08–31: Releasing p-boot GUI bootloader</a></li>
	<li><a href="#001">2020–08–31: Getting started</a></li>
</ul>

<article id="019">
<h2 id="toc-2020-09-20-downsizing-the-multi-boot-image">2020–09–20:
Downsizing the multi-boot image</h2>

<p>If the multi-boot image doesn't fit your 8GiB uSD card, because it's&nbsp;a tad
too big, you can downsize it a bit by using this script:</p>

<pre><span>#!/bin/bash</span>

<span>set -e -x</span>

<span>mkdir</span> <span>-p</span> m
L<span>=</span><span>`losetup -P --show -f multi.img`</span>
mount <span>-o</span> <span>compress</span><span>-force</span><span>=</span>zstd <span>${L}</span>p2 m
btrfs filesystem resize <span>7000</span>M m
<span>echo</span> <span>",7000M"</span> <span>|</span> sfdisk <span>-N</span> <span>2</span> <span>${L}</span>
umount m
losetup <span>-d</span> <span>"</span><span>$L</span><span>"</span>

truncate <span>-s</span> <span>$((128+7000)</span><span>)</span>M multi.img
</pre>

<p>If something fails in the middle, you may need to recover by calling
<code>umount</code> and <code>losetup -d</code> yourself.
<code>losetup -l</code> can tell you if the image is still exported as a loop
device, and which&nbsp;one.</p>

<p>The image will have the size of 7128&nbsp;MiB after resize and this should fit
more „8“ giga something uSD cards, as there are obviously some other giga
units than gigabyte and gigibyte used by some manufacturers.</p>
</article>

<article id="018">
<h2 id="toc-2020-09-20-some-ways-to-improve-pinephone-safety">2020–09–20:
Some ways to improve Pinephone safety</h2>

<p>This is a follow up on some issues from the previous article. On surface,
solutions to some of the previously presented issues can seem simple. Toggle a
few registers in PMIC, and we're mostly done. Trouble is that safety mechanisms
are barely ever triggered, by definition. Safety events occur rarely. That means
that the mechanisms are not regularly tested, and it is not known that
they&nbsp;work.</p>

<p>Also it's&nbsp;not clear which code's&nbsp;responsibility fixing the issues should
be. Bootloader, or kernel, or userspace? Finally, there are a bunch of devils in
the details, that complicate the upstreamability of any solution. And having
fixes upstream is necessary to make sure they reach the most&nbsp;users.</p>

<h3 id="toc-necessary-minimum">Necessary minimum</h3>

<p>Nevertheless, at least enabling some pre-existing PMIC functionality blindly
is better than nothing, so that's&nbsp;precisely what I&nbsp;decided to do <a href="https://megous.com/git/p-boot/commit/?id=db73ff85c60944207b7f7368e554003494148a05">in
p-boot</a>. It's&nbsp;the easiest place to start resolving these issues for me
personally, and for other p-boot&nbsp;users.</p>

<p>I&nbsp;fixed two issues:</p>

<ul>
	<li>I&nbsp;enabled the battery temperature monitoring and charging regulation based
	on temperature thresholds defined in the Pinephone battery specification.</li>

	<li>I&nbsp;enabled emergency shutdown when crossing the critical temperature
	of&nbsp;PMIC.</li>
</ul>

<p>I&nbsp;didn't measure the 3kOhm NTC used in Pinephone battery and third party
batteries I&nbsp;bought. I&nbsp;just used a table from some random 3kOhm NTC spec on The
Internet, that seemed like it could match. Hopefully it's&nbsp;close enough.</p>

<p>Trouble with the second fix is that it's&nbsp;a hard power cut-off, so data loss
may occur when PMIC overheats. There are three fixed temperature levels in
AXP803. On level 1&nbsp;the charging is limited, on level 2&nbsp;the interrupt is sent
to SoC, on level 3&nbsp;the PMIC shuts down if configured to do so (by default it
keeps running, and this is what my p-boot fix changes). Ideally, the crossing of
level 2&nbsp;would be handled by Linux to make it safely shut down the system, and
level 3&nbsp;forced power cut-off would never happen. Arguably, if charging was
source of the heating, crossing level 1&nbsp;will lead to resolving the issue, so
the next level will not be reached.</p>

<h3 id="toc-suggested-fixes-elsewhere">Suggested fixes elsewhere</h3>

<p>These fixes will reach a very limited audience. It would be nice to have
these fixes in U-Boot too, but that's&nbsp;not possible at the moment, because
U-Boot doesn't have access to&nbsp;PMIC.</p>

<p>Other places to put the fix is to ATF or Linux kernel. That can reach more
people faster, but there would have to be some generic mechanism to make the fix
upstreamable, otherwise it will not reach people using the mainline Linux kernel
or mainline&nbsp;ATF.</p>

<p>There are some ways to approach this:</p>

<ul>
	<li>Use battery description in DT from <a href="https://github.com/ARM-software/arm-trusted-firmware">ATF</a> to set up
	thresholds in PMIC (ATF has access to&nbsp;PMIC).</li>

	<li>Use battery description in DT from Linux's&nbsp;battery charger driver for
	AXP803 to set up thresholds in PMIC and stop disabling temperature
	monitoring.</li>

	<li>Use <a href="https://elixir.bootlin.com/linux/latest/source/Documentation/devicetree/bindings/power/supply/charger-manager.txt">charger
	manager</a> in Linux, but that looks like it's&nbsp;a completely software solution,
	that will be inferior to PMIC handling the regulation. And it seems it would not
	work in system suspend, anyway, because Linux is not running&nbsp;then.</li>

	<li>Detect Pinephone compatible string in either ATF or Linux and set up the
	thresholds to ad-hoc values for 3kOhm NTC. (easiest, unlikely to be acceptable
	upstream)</li>
</ul>

<p>First, the most generic solution would be to have a description of the
battery in DT describing the Pinephone. Sadly, the <a href="https://elixir.bootlin.com/linux/v5.9-rc5/source/Documentation/devicetree/bindings/power/supply/battery.yaml">current
bindings</a> don't include battery temperature limits.</p>

<p>Also converting from temperature to NTC resistance (which is necessary to
determine the code word from ADC for the limits used by the temperature monitor
logic in PMIC) is not straightforward. It is usually defined in NTC datasheet as
a table. Do I&nbsp;have NTC datasheet? No. I&nbsp;bought the batteries online from some
mobile phone service&nbsp;shop.</p>

<p>There are also equations that approximate the temperature&nbsp;– resistance
relationship for the NTC, which could be used instead of a fixed table, if one
knows the relevant coefficients. These can be calculated after measuring the
NTC's&nbsp;resistance at a few temperature points when we lack the datasheet.</p>

<p>So generic solution may look like this:</p>

<ul>
	<li>DT contains battery temperature limits from the battery&nbsp;spec</li>

	<li>DT contains NTC coefficients (perhaps also on the battery&nbsp;node)</li>

	<li>some routine would use all this info from DT to calculate code words used by
	AXP803 ADC and program them to PMIC (either in ATF, or&nbsp;Linux)</li>
</ul>

<p>Kernel also has support for NTC devices, so maybe NTC can be described
outside of the battery node (even though it's&nbsp;part of the battery).</p>

<p>This may all fail to be upstreamed on one thing: the battery is user
swappable, so it's&nbsp;arguably not part of the Pinephone, and describing it inside
the pinephone DT will not be appropriate.</p>

<p>I&nbsp;don't have any plans implementing any of the above, atm. Maybe with the
exception of adding a 4th approach to the fix to my Linux kernel (the easiest
one ;)). I'd like to work on my multi-boot image. So these are mostly pointers
for somebody else who'd like to tackle&nbsp;this.</p>

<h3 id="toc-other-issues">Other issues</h3>

<p>Fast charging is not necesary in many situations, so having it as a default
is not great. User should be able to decide if he wants to trade off slower,
safer charging and battery longetivity over speed. This tradeoff can be realized
in many&nbsp;ways.</p>

<p>All this is already controllable from userspace via sysfs. Ideally there
would be some charging monitoring daemon that would take into account
users's&nbsp;wishes and select proper strategy for charging, based on preference for
battery longetivity or&nbsp;speed.</p>

<p>There are several trade offs the deamon would be able to handle:</p>

<ul>
	<li>0.2C charging all the way (slow, but safer)</li>

	<li>0.5C charging to 40% and 0.2C charging to 100% (middle ground)</li>

	<li>0.5C charging all the way to 100%</li>
</ul>

<p>All this is decision making that doesn't belong to the kernel.</p>

<p>Similar daemon could monitor power usage of the phone and try to limit it to
safer levels, or warn the user if that's&nbsp;not possible.</p>
</article>

<article id="017">
<h2 id="toc-2020-09-18-let-s-talk-about-safety-of-pinephone">2020–09–18:
Let's&nbsp;talk about safety of Pinephone</h2>

<p>My gf read me some articles about exploding phones today. :) I&nbsp;think there
needs to be some serious conversation about Pinephone safety. Safety needs to
become an important concern now, when more and more people are getting their
Pinephones every month. It's&nbsp;just a matter of time before the first major
safety incident hits this community, and it may be more than just a hacked
store. It's&nbsp;just a numbers&nbsp;game.</p>

<p>Pinephone is an interesting device in one way. You can run whatever software
you like on it (and you do!), and this software comes almost universally with
<strong>zero</strong> guarantees. Read the license to any of the program you run
on your Pinephone and it will almost certainly tell&nbsp;you:</p>

<blockquote>
	<p>THIS SOFTWARE IS PROVIDED ``AS IS'' AND WITHOUT ANY EXPRESS OR IMPLIED
	WARRANTIES, INCLUDING, WITHOUT LIMITATION, THE IMPLIED WARRANTIES OF
	MERCHANTABILITY AND FITNESS FOR A&nbsp;PARTICULAR PURPOSE.</p>
</blockquote>

<p>or</p>

<blockquote>
	<p>THIS SOFTWARE IS PROVIDED BY &lt;COPYRIGHT HOLDER&gt; AS IS AND ANY EXPRESS
	OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF
	MERCHANTABILITY AND FITNESS FOR A&nbsp;PARTICULAR PURPOSE ARE DISCLAIMED. IN NO
	EVENT SHALL &lt;COPYRIGHT HOLDER&gt; BE LIABLE FOR ANY DIRECT, INDIRECT,
	INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES</p>
</blockquote>

<p>or</p>

<blockquote>
	<p>This program is distributed in the hope that it will be useful, but WITHOUT
	ANY WARRANTY; without even the implied warranty of MERCHANTABILITY or FITNESS
	FOR A&nbsp;PARTICULAR PURPOSE. See the GNU General Public License for more
	details.</p>
</blockquote>

<p>etc.</p>

<p>In case of Pinephone you have to take these warnings <strong>very
seriously</strong>, because this software is not provided by the manufacturer
(Pine64), and as far as I&nbsp;know, there's&nbsp;no software related safety testing
going on at&nbsp;all.</p>

<h3 id="toc-some-skeletons-hiding-at-the-lower-levels">Some skeletons, hiding at
the lower levels…</h3>

<p>I'll give you a few reasons why things may not be so rosy, when it comes to
safety.</p>

<p>There's&nbsp;no unchangeable well tested guardian angel management engine that
safely manages battery, power supplies, thermal behavior, that is provided by
the manufacturer, and that is independent of the operating system.</p>

<p>Pinephone's&nbsp;SoC is quite bare when it comes to software/firmware
(that's&nbsp;why FOSS enthusiasts like it, no blobs, you know!). This has a dark</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://xnux.eu/log/#017">https://xnux.eu/log/#017</a></em></p>]]>
            </description>
            <link>https://xnux.eu/log/#017</link>
            <guid isPermaLink="false">hacker-news-small-sites-24596248</guid>
            <pubDate>Sat, 26 Sep 2020 03:45:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Calculus in SaaS]]>
            </title>
            <description>
<![CDATA[
Score 55 | Comments 21 (<a href="https://news.ycombinator.com/item?id=24594833">thread link</a>) | @Lukas1994
<br/>
September 25, 2020 | https://www.causal.app/blog/calculus-in-saas | <a href="https://web.archive.org/web/*/https://www.causal.app/blog/calculus-in-saas">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><em>Note:&nbsp;this was originally published at </em><a href="https://alexoppenheimer.substack.com/" target="_blank"><em>https://alexoppenheimer.substack.com/</em></a>‍</p><p>I have been studying the SaaS model in depth for almost 7 years now. Since the day <a href="https://alexoppenheimer.substack.com/p/harry-2d5d1af6bf">Harry Weller</a> walked into my office with a stack of materials and told me to study it and then SaaS build models and bring them to portfolio companies, I don't think a day has gone by where I have not thought about the conceptual and operational nuances of the recurring revenue business model.</p><p>Somewhere around mid 2015 I had my "aha" moment in my research when I tied my academic training in mechanical engineering to the startup business models I was building: it's all calculus. The integral-derivative relationship applies incredibly well to the ARR and Recognized Revenue relationship. Making this connection between engineering math and financial math gave me a feeling that only a true nerd could appreciate: the joy of putting integral symbols and accounting terms on the same slide.</p><p>The simplest way to illustrate this mathematical parallel is with a car:</p><figure id="w-node-2abd43418357-51d2da99"><p><img src="https://uploads-ssl.webflow.com/5e8a043bfbc2c035b4d8e5b5/5f649b33c9e3271323643b3d_https%253A%252F%252Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%252Fpublic%252Fimages%252F42d5ef92-52d9-49fe-8be7-16028bee1ff4_884x306.png" alt=""></p></figure><p>If a car is moving at 60mph, then in one hour it will travel 60 miles (assuming its speed does not change). That is the definition of "miles per hour." ARR is very similar: if a company is "moving" at $10M ARR, then in one year it will recognize $10M of revenue (assuming everything stays consistent). Recognized revenue is the distance, ARR is the speed. It's critical to recognize that ARR is a rate at a specific point in time used to imply something (here, expected recognized revenue in the future period).</p><p>For the more accounting oriented, another analogy can be made to the balance sheet:</p><figure id="w-node-9fc87f218c80-51d2da99"><p><img src="https://uploads-ssl.webflow.com/5e8a043bfbc2c035b4d8e5b5/5f649b3392b0138c4e64006b_https%253A%252F%252Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%252Fpublic%252Fimages%252F6c06ddcc-de3e-4d96-960a-22b4b39e334e_842x455.png" alt=""></p></figure><p>While revenue is the top line metric on the income statement, ARR works more like a balance sheet metric: it is taken at a single point in time rather than over a period of time. This can make income statements confusing and misaligned - another example of the divergence of accounting in economics in subscription businesses.</p><p>Now back to calculus... if the ARR function was actually a mathematical equation, you could integrate it. If y = 10x where y = ARR and x = time in months, then after two months ARR = $20. After 12 months, ARR = $120 (assuming we start from $0 of ARR). So at the end of a year, the business has grown from $0 to $120 in ARR. But what is the recognized revenue? The complex answer is that it's the integral of 10x from 0 to 12 months. (Apologies in advance if this triggers a high school calculus flashback.)</p><figure><p><img src="https://uploads-ssl.webflow.com/5e8a043bfbc2c035b4d8e5b5/5f649b337d3c7911d7362b81_https%253A%252F%252Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%252Fpublic%252Fimages%252Ff7fcb57f-644b-490c-bfa8-6d0c986d2fda_305x80.png" alt=""></p></figure><p>You could also chart this out and see that it is a right triangle with the area of 1/2*base*height. Where the base is 12 months and the height is $120: $1,440/2 = $720).</p><p>Pretty cool relationship and calculation conceptually, but in real businesses ARR growth doesn't fit a simple equation (or any equation at all), so it's not inherently practical to start breaking out the power rule and your old textbooks to predict ARR growth.</p><p>If we switch back to the car analogy, it takes on a little more of a nuanced meaning. Just like a business doesn't grow on a smooth curve, car speeds do not either. Just like the gas pedal makes the car go faster and the brake pedal &amp; friction make it go slower, so too in a SaaS company, <a href="https://alexoppenheimer.substack.com/p/thin-slicing-arr">the new sales are making the speed/ARR increase and the churned customers are making the speed/ARR decrease</a>. I will dive into more details in later posts, but the goal in a car is to go as far and fast as you can while burning the least amount of fuel. So too in a SaaS company, the goal is to have the highest ARR you can, recognize the most revenue and burn the least cash. You can think about SaaS Magic Number like the fuel efficiency of a SaaS business - looking forward to diving into why this is actually helpful in building a company.</p></div></div>]]>
            </description>
            <link>https://www.causal.app/blog/calculus-in-saas</link>
            <guid isPermaLink="false">hacker-news-small-sites-24594833</guid>
            <pubDate>Fri, 25 Sep 2020 22:40:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Lawyers for Assange Open Letter to the UK Prime Minister et al.]]>
            </title>
            <description>
<![CDATA[
Score 70 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24594374">thread link</a>) | @jstanley
<br/>
September 25, 2020 | https://www.lawyersforassange.org/en/open-letter.html | <a href="https://web.archive.org/web/*/https://www.lawyersforassange.org/en/open-letter.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                <p><strong>14 August 2020</strong></p>



<p><strong>Dear Prime Minister, </strong></p>

<p><strong>Dear Lord Chancellor and Secretary of State for Justice,</strong></p>

<p><strong>Dear Secretary of State for Foreign Affairs,</strong></p>

<p><strong>Dear Home Secretary,</strong></p>





<p>We write to you as legal practitioners and legal academics to express our collective concerns about the violations of Mr. Julian Assange’s fundamental human, civil and political rights and the precedent his persecution is setting.</p>



<p>We call on you to act in accordance with national and international law, human rights and the rule of law by bringing an end to the ongoing extradition proceedings and granting Mr. Assange his long overdue freedom – freedom from torture, arbitrary detention and deprivation of liberty, and political persecution.</p>



<ol>
	<li><strong>ILLEGALITY OF POTENTIAL EXTRADITION TO THE UNITED STATES</strong></li>
</ol>



<p><strong>Extradition of Mr. Assange from the UK to the US would be illegal on the following grounds: </strong></p>



<ol>
	<li><strong>Risk of being subjected to an unfair trial in the US</strong></li>
</ol>



<p>Extradition would be unlawful owing to failure to ensure the protection of Mr. Assange’s fundamental trial rights in the US. Mr. Assange faces show trial at the infamous “Espionage court” of the Eastern District of Virginia, before which no national security defendant has ever succeeded. Here, he faces secret proceedings before a jury picked from a population in which most of the individuals eligible for jury selection work for, or are connected to, the CIA, NSA, DOD or DOS.<a href="#_edn1" name="_ednref1" title=""><sup><sup>[i]</sup></sup></a></p>



<p>Furthermore, Mr. Assange’s<strong> </strong>legal privilege, a right enshrined in Art. 8 European Convention on Human Rights (ECHR) and long recognised under English common law, was grossly violated through<strong> </strong>constant and criminal video and audio surveillance at the Ecuadorian embassy carried out by the Spanish security firm, UC Global. This surveillance was, according to witness testimony, ordered by the CIA and has triggered an investigation into the owner of UC Global, David Morales, by Spain’s High Court, the Audiencia Nacional.<a href="#_edn2" name="_ednref2" title="">[ii]</a> The surveillance resulted in all of Mr. Assange’s meetings and conversations being recorded, including those with his lawyers. The Council of Bar and Law Societies of Europe, which represents more than a million European lawyers, has expressed its concerns that these illegal recordings may be used – openly or secretly – in proceedings against Mr. Assange in the event of successful extradition to the US. The Council states that if the information merely became known to the prosecutors, this would present an irremediable breach of Mr. Assange’s fundamental rights to a fair trial under Art. 6 of the ECHR and due process under the US Constitution.<a href="#_edn3" name="_ednref3" title=""><sup><sup>[iii]</sup></sup></a> Furthermore, the prosecuting state obtained the totality of Mr. Assange’s legal papers after their unlawful seizure in the Embassy. Upon hearing that the Government of Ecuador was planning to seize and hand over personal belongings of Mr. Assange, including documents, telephones, electronic devices, memory drives, etc. to the US, the UN Special Rapporteur on Privacy, Joseph Cannataci, expressed his serious concern to the Ecuadorian government and twice formally requested it to return Mr. Assange's personal effects to his lawyers, to no avail.<a href="#_edn4" name="_ednref4" title=""><sup><sup>[iv]</sup></sup></a> <strong>The UN Model Treaty on Extradition prohibits extradition if the person has not received, or would not receive, the minimum guarantees in criminal proceedings, as enshrined in Art. 14 of the International Covenant on Civil and Political Rights (ICCPR).</strong><a href="#_edn5" name="_ednref5" title=""><sup><sup>[v]</sup></sup></a></p>



<ol start="2">
	<li><strong>The political nature of the offence prohibits extradition</strong></li>
</ol>



<p>The US superseding indictment issued against Mr. Assange on the 24 June 2020 charges him with 18 counts all related solely to the 2010 publications of US government documents. The publications, comprising information about the wars in Iraq and Afghanistan, US diplomatic cables and Guantanamo Bay, revealed evidence of war crimes, corruption and governmental malfeasance.<a href="#_edn6" name="_ednref6" title=""><sup><sup>[vi]</sup></sup></a></p>



<p>Charges 1-17 are brought under the Espionage Act 1917, which, in name alone, reveals the political and antiquated nature of the charges.<a href="#_edn7" name="_ednref7" title=""><sup><sup>[vii]</sup></sup></a><strong> </strong>Furthermore, the essence of the 18 charges concerns Mr. Assange’s alleged intention to obtain or disclose US state “secrets” in a manner that was damaging to the strategic and national security interests of the US state, to the capability of its armed forces, the work of the security and intelligence services of the US, and to the interests of the US abroad. Thus, the conduct, motivation and purpose attributed to Mr. Assange confirm the political character of the 17 charges brought under the Espionage Act (‘pure political’ offences) and of the hacking charge (a ‘relative political’ offence). In addition, several US government officials have at various times ascribed motives “hostile” to the US to Mr. Assange, an Australian citizen.<a href="#_edn8" name="_ednref8" title=""><sup><sup>[viii]</sup></sup></a> <strong>The UK-US Extradition Treaty, which provides the very basis of the extradition request, specifically prohibits extradition for political offences in Art. 4(1). </strong>Yet the presiding judge and prosecution wish to simply disregard this article by referring to the Extradition Act 2003 (“EA”) instead, which does not include the political offence exception. This blatantly ignores the fact that the EA is merely an enabling act that creates the minimum statutory safeguards, but it does not preclude stronger protections from extradition as expressly provided in subsequently ratified treaties such as the UK-US Extradition Treaty. <strong>Furthermore, there is broad international consensus that political offences should not be the basis of extradition.<a href="#_edn9" name="_ednref9" title=""><sup><strong><sup>[ix]</sup></strong></sup></a> This is reflected in Art. 3 of the 1957 European Convention on Extradition, Art. 3 ECHR, Art. 3(a) of the UN Model Treaty on Extradition, the Interpol Constitution and every bilateral treaty ratified by the US for over a century.</strong></p>



<ol start="3">
	<li><strong>Risk of torture or other cruel, inhuman or degrading treatment or punishment in the US</strong></li>
</ol>



<p>The United Nations Special Rapporteur on Torture and Other Cruel, Inhuman or Degrading Treatment or Punishment (“the UN Rapporteur on Torture”), Professor Nils Melzer, has expressed with certainty that, if extradited to the US, Mr. Assange will be exposed to torture or other cruel, inhuman or degrading treatment or punishment. Similar concerns have also been raised by the UN Working Group on Arbitrary Detention, and Amnesty International has recently restated its concerns in relation to the unacceptable risk of mistreatment.<a href="#_edn10" name="_ednref10" title=""><sup><sup>[x]</sup></sup></a></p>



<p>The detention conditions, and the draconian punishment of 175 years, in a maximum security prison, which Mr. Assange faces under the US indictment, would constitute torture or other cruel, inhuman or degrading treatment or punishment, according to the current UN Rapporteur on Torture and according to the<strong> </strong>consistently expressed opinion of his predecessor, as well as of NGOs and legal authorities.<a href="#_edn11" name="_ednref11" title=""><sup><sup>[xi]</sup></sup></a></p>



<p>If extradited, Mr. Assange would, by the US government’s own admission, likely be placed under Special Administrative Measures. These measures prohibit prisoners from contact or communication with all but a few approved individuals, and any approved individuals would not be permitted to report information concerning the prisoner’s treatment to the public, thereby shielding potential torture from public scrutiny and government from accountability.<a href="#_edn12" name="_ednref12" title=""><sup><sup>[xii]</sup></sup></a></p>



<p><strong>Under the principle of non-refoulement, it is not permissible to extradite a person to a country in which there are substantial grounds for</strong> <strong>believing that they would be subjected to torture. This principle is enshrined in the 1951 UN Convention Relating to the Status of Refugees, specifically Art. 33(1) from which no derogations are permitted. Also relevant are Art. 3(1) UN Declaration on Territorial Asylum 1967, Art. 3 of the Convention against Torture and Other Cruel, Inhuman or Degrading Treatment or Punishment (CAT)</strong>,<strong> and Art. 2 of the Resolution on Asylum to Persons in Danger of Persecution, adopted by the Committee of Ministers of the Council of Europe in 1967. As an obligation arising from the prohibition of torture, the principle of non-refoulement in this area is absolute and also takes on the character of a peremptory norm of customary international law, i.e. jus cogens.<a href="#_edn13" name="_ednref13" title=""><sup><strong><sup>[xiii]</sup></strong></sup></a></strong></p>



<p><strong>Mr. Assange, who was accepted as a political asylee by the Ecuadorian government owing to what have proved to have been wholly legitimate fears of political persecution and torture in the US, should clearly have been accorded protection of this principle, firstly by Ecuador and secondly by the UK. Ecuador violated its human rights obligations by summarily rescinding Mr. Assange’s asylum in direct contradiction of the ‘Latin American tradition of asylum’<a href="#_edn14" name="_ednref14" title=""><sup><strong><sup>[xiv]</sup></strong></sup></a> and the Advisory Opinion </strong><strong>OC-25/18 of 30 May 2018 of the Inter-American Court of Human Rights affirming the principle of non-refoulement in cases of persons who have entered an embassy for protection.<a href="#_edn15" name="_ednref15" title=""><sup><strong><sup>[xv]</sup></strong></sup></a> The entry of the Ecuadorian Embassy by UK police and the arrest of Mr. Assange were thus based on an illegal revocation of his nationality and asylum, which can only be rectified by the UK upholding its own duty to protect the principle of non-refoulement by denying extradition to the US.</strong></p>



<p><strong>B) VIOLATIONS OF THE FREEDOM OF THE PRESS AND THE RIGHT TO KNOW</strong></p>



<p>Counts 1-17 of the indictment under the Espionage Act violate the right to freedom of expression, the right to freedom of the press and the right to know. These counts present standard and necessary investigative journalistic practices as criminal.<a href="#_edn16" name="_ednref16" title=""><sup><sup>[xvi]</sup></sup></a> Such practices include indicating availability to receive information, indicating what information is of interest, encouraging the provision of information, receipt of information for the purpose of publication, and publication of information in the public interest.</p>



<p>Under the charge of conspiracy to commit computer intrusion, the initial indictment criminalised also Mr. Assange’s alleged attempt at helping his source to maintain their anonymity while providing the documents in question, which falls squarely under the standard journalistic practice and duty of protecting the …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.lawyersforassange.org/en/open-letter.html">https://www.lawyersforassange.org/en/open-letter.html</a></em></p>]]>
            </description>
            <link>https://www.lawyersforassange.org/en/open-letter.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24594374</guid>
            <pubDate>Fri, 25 Sep 2020 21:37:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Deafening Silence of the Royal Society Open Science Journal]]>
            </title>
            <description>
<![CDATA[
Score 84 | Comments 16 (<a href="https://news.ycombinator.com/item?id=24593465">thread link</a>) | @mathgenius
<br/>
September 25, 2020 | https://www.iqoqi-vienna.at/blog/article/dishonesty-in-academia-the-deafening-silence-of-the-royal-society-open-science-journal-on-an-accept/ | <a href="https://web.archive.org/web/*/https://www.iqoqi-vienna.at/blog/article/dishonesty-in-academia-the-deafening-silence-of-the-royal-society-open-science-journal-on-an-accept/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Florin Moldoveanu researches the foundation of quantum mechanics with emphasis on quantum mechanics reconstruction and solving the measurement problem. After getting his PhD in theoretical physics at the University of Maryland at College Park in 1999, he pursued a career in industry. Three years ago he started the transition back from industry to academia and became an adjunct professor at George Mason University. His earlier graduate student research papers in theoretical physics received 267 citations to date.</p><hr><p>More than two years ago, on February 26<sup>th</sup> 2018, I was contacted by the <strong>Royal Society Open Science Journal</strong> to referee a submitted manuscript. Two prior referees had accepted the paper and two had rejected it, and I was the tiebreaker. The manuscript, <em>Quantum Correlations are Weaved by the Spinors of the Euclidean Primitives</em> by Joy Christian, basically claims that Bell’s theorem is incorrect. If true, this would be a game changer in the foundation of quantum mechanics. Bell’s theorem shows that it is impossible to construct a local realistic model of the theory.</p><p>Bell’s result is an impossibility proof; it attracts such passion as the impossibility of perpetual motion machines that were so popular some 100 years ago. A manuscript claiming the invention of a working perpetual motion device, proof that Earth is flat (yes, there is such a thing as an annual conference of Flat-Earth-ers), or that the sun circles Earth would be rejected by any respectable journal right away.</p><p>So, what if someone managed to “disprove” Bell’s theorem and, better yet, to publish that “discovery”? This would create lots of debates and excitement – certainly, notoriety and free publicity for the journal who published your claim. In other words, good business.</p><p>But who is claiming to have “disproven” Bell theorem? Enter Joy Christian, who has been asserting this claim for 13 years. It was debunked by many scientists and scientific panels over the years, yet Christian is not having any of it. Basically, he alleges to have found a method for obtaining the quantum correlation of a Bell pair of particles, by using a Bell “loophole”. In the no-mans-land at the intersection of physics, mathematics, and philosophy, experts in all three fields are scarce. Christian’s ‘method’ is based on a mathematical error, which is ultimately adding apples and oranges, but the error is hard to spot if you are not a genuine expert in geometric algebra. Add to this the language and structure of a well-written physics paper and you might convince an unsuspecting referee to approve your manuscript.</p><p>I had found Christian’s mistake again in the manuscript and I recommended to reject the paper. Certain that it would never be published, I went about my daily business. Imagine my surprise when I heard Christian had somehow managed to publish his nonsense. I thought this impossible; the vote had been 3 to 2 for rejection. I checked and found that indeed, the paper had gotten accepted after submitting a revision. <strong>However,</strong><strong>I was not contacted by the journal to review the revision. </strong>I started contacting colleagues who had to deal with Joy’s claims before, and together with Philippe Grangier, Richard Gill, Howard Wiseman, Brukner Časlav, Gregor Weihs, and Scott Aaronson, in a letter to the journal on July 28<sup>th</sup> 2018, we asked that the article be withdrawn:</p><p><em>Dear Editor-in-Chief,</em></p><p><em>We are writing to you about the publication of the paper “Quantum Correlations are weaved by the spinors of the Euclidean primitives” by Joy Christian in your journal on May 30 2018&nbsp;</em><a href="http://rsos.royalsocietypublishing.org/content/5/5/180526" target="_blank"><em>http://rsos.royalsocietypublishing.org/content/5/5/180526</em></a></p><p><em>The result of this paper conflicts with an established scientific fact (Bell’s theorem) well known in the foundations of quantum physics and a basis of modern quantum information science; moreover, the subject of recent high-profile experiments (“loophole free tests of Bell’s theorem”). The paper contains numerous errors in elementary algebra, calculus, and logic. The manuscript was rejected by three of the five reviewers,&nbsp;but the editorial process as stated to the reviewers by your journal was not followed:&nbsp;the manuscript was accepted without informing the reviewers&nbsp;and giving them a chance to rebut the misleading statements made by the author (see review history on the link above).</em></p><p><em>The claims made by the author are well known from 2007 and they were disproven in the past (</em><a href="https://fqxi.org/community/forum/topic/1577" target="_blank"><em>https://fqxi.org/community/forum/topic/1577</em></a><em>&nbsp;). From time to time Joy Christian attempts to publish his faulty claims and recently a similar paper was withdrawn by Annals of Physics&nbsp;</em><a href="https://www.sciencedirect.com/science/article/pii/S0003491616300975" target="_blank"><em>https://www.sciencedirect.com/science/article/pii/S0003491616300975</em></a></p><p><em>The journal did extend an invitation to write a rebuttal paper but stated that Joy Christian would be a reviewer to the rebuttal. This is not an acceptable course of action from an ethical point of view because it legitimizes scientific dishonesty on behalf of Joy Christian who is well aware of the issues with his arguments for more than 10 years and yet continues to obfuscate the truth.</em></p><p><em>Considering this, we are respectfully asking your journal to withdraw the paper.</em></p><p><em>Sincerely,</em></p><p><em>Florin Moldoveanu&nbsp;- George Mason University (reviewer 5)</em></p><p><em>Richard Gill – Leiden University</em></p><p><em>Howard Wiseman – Griffith University (reviewer 3)</em></p><p><em>Scott Aaronson - University of Texas</em></p><p><em>Philippe Grangier - Institute of Optics, Charles Fabry Laboratory</em></p><p><em>Brukner Caslav - IQOQI - Institute for Quantum Optics and Quantum Information Vienna</em></p><p><em>Gregor Weihs – Innsbruck University</em></p><p>This was about two years ago. We kept asking for updates, and when not stonewalling us, the journal kept pushing one roadblock after another.</p><p>The <strong>Royal Society Open Science Journal had more than two years to get their act together. By now, their silence speaks louder than words.</strong></p><p>It is unconscionable that instead of putting extra checks in place for authors with a history of inaccurate publications, the journal violated their own peer review policy and chose to maintain a faulty paper instead of withdrawing it.</p><p>We gave the journal the benefit of the doubt for two years. The passing of time made it clear that the decision to maintain the faulty paper is no accident and no mistake.</p><p>Perhaps this is a symptom of a larger systemic problem with open journals who are paid by the authors to get their papers (usually rejected elsewhere) published. When your salary and livelihood depend on the people you are supposed to enforce rules upon, the temptation to bend those rules is high.</p><p>I grew up in a former communist country of the eastern bloc. At the time of communism, a rule supposed to be enforced by the traffic police was that if you pay for a traffic ticket on the spot, you will be charged with half the fine. You might guess that most officers pocketed that money. The rule only solidified endemic corruption.</p><p>In our case, the author is well known for making the same incorrect argument over and over again. However, <strong>the root of the problem seems to be with the journal</strong>. After all, had they followed their own policy, the problem would not have arisen in the first place. And in case the mistake was genuine (as sometimes mistakes do happen), is two years enough time to get the record straight? It makes me wonder: just how often did the editors turn a blind eye to publication issues to secure revenue? <strong>Is it really a good idea that those in charge of rule enforcement are financially dependent on the rule violators? </strong></p></div></div>]]>
            </description>
            <link>https://www.iqoqi-vienna.at/blog/article/dishonesty-in-academia-the-deafening-silence-of-the-royal-society-open-science-journal-on-an-accept/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24593465</guid>
            <pubDate>Fri, 25 Sep 2020 19:51:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Anecdotes from Donald Knuth and Robert Tarjan]]>
            </title>
            <description>
<![CDATA[
Score 99 | Comments 12 (<a href="https://news.ycombinator.com/item?id=24591454">thread link</a>) | @furcyd
<br/>
September 25, 2020 | https://scilogs.spektrum.de/hlf/applying-mathematics-and-computer-science-to-everyday-life-anecdotes-from-donald-knuth-and-robert-tarjan/ | <a href="https://web.archive.org/web/*/https://scilogs.spektrum.de/hlf/applying-mathematics-and-computer-science-to-everyday-life-anecdotes-from-donald-knuth-and-robert-tarjan/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="text"> <figure id="attachment_7848" aria-describedby="caption-attachment-7848"><a href="https://scilogs.spektrum.de/hlf/files/Screen-Shot-2020-09-22-at-12.06.55-PM.png"> <img alt="" width="342" height="114" srcset="https://scilogs.spektrum.de/hlf/files/Screen-Shot-2020-09-22-at-12.06.55-PM-300x100.png 300w, https://scilogs.spektrum.de/hlf/files/Screen-Shot-2020-09-22-at-12.06.55-PM-1024x341.png 1024w, https://scilogs.spektrum.de/hlf/files/Screen-Shot-2020-09-22-at-12.06.55-PM-768x256.png 768w, https://scilogs.spektrum.de/hlf/files/Screen-Shot-2020-09-22-at-12.06.55-PM.png 1291w" sizes="(max-width: 342px) 100vw, 342px" data-srcset="https://scilogs.spektrum.de/hlf/files/Screen-Shot-2020-09-22-at-12.06.55-PM-300x100.png 300w, https://scilogs.spektrum.de/hlf/files/Screen-Shot-2020-09-22-at-12.06.55-PM-1024x341.png 1024w, https://scilogs.spektrum.de/hlf/files/Screen-Shot-2020-09-22-at-12.06.55-PM-768x256.png 768w, https://scilogs.spektrum.de/hlf/files/Screen-Shot-2020-09-22-at-12.06.55-PM.png 1291w" data-src="https://scilogs.spektrum.de/hlf/files/Screen-Shot-2020-09-22-at-12.06.55-PM-300x100.png" src="https://scilogs.spektrum.de/hlf/files/Screen-Shot-2020-09-22-at-12.06.55-PM-300x100.png"></a><figcaption id="caption-attachment-7848">Donald Knuth and Robert Tarjan chat during the virtual HLF</figcaption></figure> <p><span>On day two of the Virtual </span><a href="https://www.heidelberg-laureate-forum.org/"><span>Heidelberg Laureate Forum</span></a><span> (HLF) 2020, Robert Endre Tarjan and Donald Ervin Knuth engaged in a freewheeling conversation about mathematics, computer science, and art.&nbsp;</span></p> <p><a href="https://www.heidelberg-laureate-forum.org/laureate/donald-ervin-knuth.html"><span>Donald Knuth</span></a><span> was the 1974 </span><a href="https://amturing.acm.org/"><span>ACM A.M. Turing Award</span></a><span> winner for “for his major contributions to the analysis of algorithms and the design of programming languages, and in particular for his contributions to the “art of computer programming” through his well-known books in a continuous series by this title,” while </span><a href="https://www.heidelberg-laureate-forum.org/laureate/robert-endre-tarjan.html"><span>Robert Tarjan</span></a><span>, won the </span><a href="https://www.mathunion.org/imu-awards/rolf-nevanlinna-prize"><span>Nevanlinna Prize</span></a><span> in 1982 “for devising near-optimal algorithms for many graph-theoretic and geometric problems for the development and exploitation of data structures supporting efficient algorithms, and for contributing several algorithmic analyses of striking profundity and elegance” and the Turing Award in 1986 “with </span><a href="https://en.wikipedia.org/wiki/John_Hopcroft"><span>John E. Hopcroft</span></a><span>, for fundamental achievements in the design and analysis of algorithms and data structures.”</span></p> <p><span>Tarjan was a student of Knuth’s at Stanford, and their history together was on display in their dynamic banter. The conversation produced a number of entertaining anecdotes, such as Knuth’s concern for Tarjan’s health when he was an assistant professor. Knuth said of Tarjan, “as I sort of remember…I was very worried about you because you were proving theorems in your head as you were driving the freeways and I was afraid you would get into a wreck.” Remember kids, don’t do math and drive.&nbsp;</span></p> <p><span>Knuth also discussed his time as the manager of the </span><a href="https://ohiohistorycentral.org/w/Case_Institute_of_Technology"><span>Case Institute of Technology</span></a><span> basketball team while he was an undergraduate. During his junior year he created a process to keep better statistics on each basketball player during practices and games. Then, using punch cards, he fed this data into an </span><a href="https://en.wikipedia.org/wiki/IBM_650"><span>IBM 650</span></a><span> to generate strategic recommendations for the coach of the team. This system seems to have been a success — Case won more games the year they began to use Knuth’s system than they did the year before. IBM even recorded a short film about Knuth’s system called </span><i><span>The Electronic Coach</span></i><span>, which you can watch on Youtube </span><a href="https://www.youtube.com/watch?v=dhh8Ao4yweQ"><span>here</span></a><span>.&nbsp;</span></p> <p><span>Knuth was ahead of his time — modern NBA teams rely on detailed data analytics to better understand their players and the competition; in fact during the 2013-2014 season the NBA </span><a href="https://www.engadget.com/2013-09-07-nba-stats-llc-motion-tracking-sportvu.html"><span>installed SportVu motion tracking cameras</span></a><span> in every NBA stadium. These SportVu cameras monitor the movements of every player and the basketball at 25 frames per second, generating data about everything that happens in every basketball game. NBA teams, </span><a href="https://digital.hbs.edu/platform-digit/submission/moreyball-the-houston-rockets-and-analytics/"><span>most famously the Houston Rockets</span></a><span>, have used these analytics to redefine how the game is played. While three point shots are the toughest shot to make, they have a higher expected value than a long two point shot (because the difference in shooting percentage between the two is marginal), increase the spacing between players (which makes it harder to play defense), and increases the likelihood of getting an offensive rebound (because missed three point shots tend to bounce further away from the basket). Realizing this, NBA teams consistently shoot more and more threes every season. In the 1979-1980 season, the first year the three point line was introduced to the NBA, the San Diego Clippers </span><a href="https://www.basketball-reference.com/leagues/NBA_1980.html"><span>led the league</span></a><span> with 6.6 three point attempts (3PA) per game. Last year the Houston Rockets smashed that number, attempting the most threes in NBA history with </span><a href="https://www.basketball-reference.com/leagues/NBA_2019.html"><span>45.4 attempts per game</span></a><span>.&nbsp;</span></p> <p><span>This is all to say that Knuth was really onto something when he had the novel idea of using a computer to better understand a basketball game. You can learn more about the work of a NBA modern data scientist in this video from </span><a href="https://www.youtube.com/watch?v=MpLHMKTolVw"><span>Bloomberg</span></a><span> that profiles </span><a href="https://www.linkedin.com/in/ivana-seric-503b4731/"><span>Ivana Seric</span></a><span>, a senior researcher with the Philadelphia 76ers.&nbsp;</span></p> <figure id="attachment_7851" aria-describedby="caption-attachment-7851"><a href="https://scilogs.spektrum.de/hlf/files/Screen-Shot-2020-09-24-at-1.08.50-PM.png"> <img alt="" width="300" height="154" srcset="https://scilogs.spektrum.de/hlf/files/Screen-Shot-2020-09-24-at-1.08.50-PM-300x154.png 300w, https://scilogs.spektrum.de/hlf/files/Screen-Shot-2020-09-24-at-1.08.50-PM-1024x524.png 1024w, https://scilogs.spektrum.de/hlf/files/Screen-Shot-2020-09-24-at-1.08.50-PM-768x393.png 768w, https://scilogs.spektrum.de/hlf/files/Screen-Shot-2020-09-24-at-1.08.50-PM-1536x786.png 1536w, https://scilogs.spektrum.de/hlf/files/Screen-Shot-2020-09-24-at-1.08.50-PM-2048x1048.png 2048w" sizes="(max-width: 300px) 100vw, 300px" data-srcset="https://scilogs.spektrum.de/hlf/files/Screen-Shot-2020-09-24-at-1.08.50-PM-300x154.png 300w, https://scilogs.spektrum.de/hlf/files/Screen-Shot-2020-09-24-at-1.08.50-PM-1024x524.png 1024w, https://scilogs.spektrum.de/hlf/files/Screen-Shot-2020-09-24-at-1.08.50-PM-768x393.png 768w, https://scilogs.spektrum.de/hlf/files/Screen-Shot-2020-09-24-at-1.08.50-PM-1536x786.png 1536w, https://scilogs.spektrum.de/hlf/files/Screen-Shot-2020-09-24-at-1.08.50-PM-2048x1048.png 2048w" data-src="https://scilogs.spektrum.de/hlf/files/Screen-Shot-2020-09-24-at-1.08.50-PM-300x154.png" src="https://scilogs.spektrum.de/hlf/files/Screen-Shot-2020-09-24-at-1.08.50-PM-300x154.png"></a><figcaption id="caption-attachment-7851">Typeset score from Chapter 1 of Fantasia Apocalyptica</figcaption></figure> <p><span>Knuth’s application of math and computer science to other fields doesn’t stop there. Knuth is also an accomplished pipe organ player and a few years ago he composed, </span><a href="https://www-cs-faculty.stanford.edu/~knuth/fant.html"><i><span>Fantasia Apocalyptica</span></i></a><span>, a multimedia work for pipe organ. In </span><i><span>Apocalyptica </span></i><span>Knuth used a few mathematical and algorithmic methods to generate melodies. </span><a href="https://www-cs-faculty.stanford.edu/~knuth/fant.html"><span>On his webpage</span></a><span> Knuth says:</span></p> <p><span>“At one point I thought I might have time to understand music theory well enough that I could try to teach that theory to a computer. But eventually I concluded that it would be better to create this piece almost entirely by hand, using my desktop machine only to help organize the work. Thus it’s definitely </span><i><span>not</span></i><span> “computer music”, although I do profess to be a computer scientist.</span></p> <p><span>On the other hand, I did apply some algorithms manually in a few places. For example, a haunting melody, taken from one of the earliest surviving instances of ancient Greek music, occurs ten times. I harmonized it differently each time, using the algorithm of David Kraehenbuehl that’s described in Chapter 22 of </span><a href="https://www-cs-faculty.stanford.edu/~knuth/fg.html"><span>Selected Papers on Fun &amp; Games</span></a><span>. (See </span><a href="https://www-cs-faculty.stanford.edu/~knuth/papers/randomness.ps.gz"><span>“Randomness in Music”</span></a><span>.)</span></p> <p><span>Mathematical methods were also used to generate the changeringing patterns that appear briefly, as well as certain melodies used for the twelve tribes of Israel and for the twelve precious jewels below the “pearly gates” of the New Jerusalem. If those methods hadn’t been successful, I would have changed the results by hand. Fortunately, I didn’t have to do that; the algorithmic approach did give a pleasing result in those cases.”</span></p> <p><span>Knuth’s diverse interests led Tarjan to ask a compelling question: “It’s been said that any field that has science in its name is not a science, so I might ask you is computer science a science, a branch of engineering, a branch of mathematics, an art — but let me ask it in a more personal way….do you see yourself as an artist, a scientist, a mathematician, an engineer, a philosopher, some combination?”&nbsp;</span></p> <p><span>Knuth replied that he realized art stands not only for fine art but also for things that are artificial or made by human beings (as opposed to nature). He defined science as “what we understand well enough to explain to a computer” while “art is everything else.” He went on to say that as we learn more science about something our brains “keep a few jumps ahead, and that’s the art.”&nbsp;</span></p> <p><span>Finally, Knuth was asked if he had advice for students. Knuth’s response was to echo the </span><a href="https://scilogs.spektrum.de/hlf/have-fun-life-and-career-advice-from-sir-c-antony-r-hoare-and-leslie-lamport/"><span>advice of Leslie Lamport</span></a><span> from earlier in HLF, which was to write often. However, Knuth cautioned to not be “too influenced by trendy stuff. Don’t write a paper because you have to write a paper or because you think you have to impress people about something that you aren’t personally really interested in…that’s the worst reason to write a paper.”&nbsp;</span></p> <p><span>Tarjan added to this and said, “You have to figure out what your own path is and follow it. The best students I’ve had came in with or ended up with their own idea that they developed.” Clearly both men have had success finding and following their own path. </span><b>Watch the full conversation between Tarjan and Knuth on Youtube </b><a href="https://www.youtube.com/watch?v=O5g4Zl8ppQA"><b>here</b></a><b>. </b></p>  </div></div>]]>
            </description>
            <link>https://scilogs.spektrum.de/hlf/applying-mathematics-and-computer-science-to-everyday-life-anecdotes-from-donald-knuth-and-robert-tarjan/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24591454</guid>
            <pubDate>Fri, 25 Sep 2020 16:24:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Iron, How Did They Make It? Part II]]>
            </title>
            <description>
<![CDATA[
Score 253 | Comments 72 (<a href="https://news.ycombinator.com/item?id=24591216">thread link</a>) | @parsecs
<br/>
September 25, 2020 | https://acoup.blog/2020/09/25/collections-iron-how-did-they-make-it-part-ii-trees-for-blooms/ | <a href="https://web.archive.org/web/*/https://acoup.blog/2020/09/25/collections-iron-how-did-they-make-it-part-ii-trees-for-blooms/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<p>This week we continue our four-part (<a href="https://acoup.blog/2020/09/18/collections-iron-how-did-they-make-it-part-i-mining/">I</a>, II, III, IV) look at pre-modern iron and steel production.  Last week we prospected our iron ore and extracted it from the ground and did some initial mechanical processing (washing, sorting, crushing).  This week, we’re going to make our way from just rocks to an actual mass of <em>metal</em> rather than just some metal-bearing ore.  As we’ll see, we are going to do this by applying <em>heat</em> and (more importantly) <em><strong>chemistry</strong></em>:</p>



<figure><img data-attachment-id="4618" data-permalink="https://acoup.blog/fuel-use-in-iron-production-1/" data-orig-file="https://acoupdotblog.files.wordpress.com/2020/09/fuel-use-in-iron-production-1.png" data-orig-size="1024,372" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="fuel-use-in-iron-production-1" data-image-description="" data-medium-file="https://acoupdotblog.files.wordpress.com/2020/09/fuel-use-in-iron-production-1.png?w=300" data-large-file="https://acoupdotblog.files.wordpress.com/2020/09/fuel-use-in-iron-production-1.png?w=1024" src="https://acoupdotblog.files.wordpress.com/2020/09/fuel-use-in-iron-production-1.png?w=1024" alt="" srcset="https://acoupdotblog.files.wordpress.com/2020/09/fuel-use-in-iron-production-1.png 1024w, https://acoupdotblog.files.wordpress.com/2020/09/fuel-use-in-iron-production-1.png?w=150 150w, https://acoupdotblog.files.wordpress.com/2020/09/fuel-use-in-iron-production-1.png?w=300 300w, https://acoupdotblog.files.wordpress.com/2020/09/fuel-use-in-iron-production-1.png?w=768 768w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>Note that this week is going to be spent <strong>just</strong> getting our iron ore into being an <strong>iron bloom</strong>, the first two steps.</figcaption></figure>



<p>Warning: Many, <em><strong>many</strong></em> trees were harmed in the making of this iron.</p>



<p>As always, if you like what you are reading here, please share it; if you really like it, you can support me on <a href="https://www.patreon.com/user?u=20122096">Patreon</a>. And if you want updates whenever a new post appears, you can click below for email updates or follow me on twitter (@BretDevereaux) for updates as to new posts as well as my occasional ancient history, foreign policy or military history musings.</p>





<p>But let’s start with the <strong>single largest input</strong> for our entire process, measured in either mass or volume – quite literally the largest input resource <em>by an order of magnitude</em>.  That’s right, it’s…</p>



<h2>Trees</h2>



<figure><img data-attachment-id="4597" data-permalink="https://acoup.blog/a_route_through_pine_forest/" data-orig-file="https://acoupdotblog.files.wordpress.com/2020/09/a_route_through_pine_forest.jpg" data-orig-size="5184,3456" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;3.5&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;Canon EOS 60D&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1402052182&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;18&quot;,&quot;iso&quot;:&quot;200&quot;,&quot;shutter_speed&quot;:&quot;0.033333333333333&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="a_route_through_pine_forest" data-image-description="" data-medium-file="https://acoupdotblog.files.wordpress.com/2020/09/a_route_through_pine_forest.jpg?w=300" data-large-file="https://acoupdotblog.files.wordpress.com/2020/09/a_route_through_pine_forest.jpg?w=1024" src="https://acoupdotblog.files.wordpress.com/2020/09/a_route_through_pine_forest.jpg?w=1024" alt="" srcset="https://acoupdotblog.files.wordpress.com/2020/09/a_route_through_pine_forest.jpg?w=1024 1024w, https://acoupdotblog.files.wordpress.com/2020/09/a_route_through_pine_forest.jpg?w=2048 2048w, https://acoupdotblog.files.wordpress.com/2020/09/a_route_through_pine_forest.jpg?w=150 150w, https://acoupdotblog.files.wordpress.com/2020/09/a_route_through_pine_forest.jpg?w=300 300w, https://acoupdotblog.files.wordpress.com/2020/09/a_route_through_pine_forest.jpg?w=768 768w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<p>The reader may be pardoned for having gotten to this point expecting to begin with exciting furnaces, bellowing roaring flames and melting all and sundry.  <strong>The thing is, all of that energy has to come from somewhere and that somewhere is, by and large, wood</strong>.  Now it is absolutely true that there are other common fuels which were probably frequently experimented with and sometimes used, but don’t seem to have been used widely.  Manure, used as cooking and heating fuel in many areas of the world where trees were scarce, doesn’t – to my understanding – reach sufficient temperatures for use in iron-working.  Peat seems to have similar problems, although my understanding is it can be reduced to charcoal like wood; I haven’t seen any clear evidence this was often done, although one assumes it must have been tried.</p>



<p>Instead, the fuel I gather most people <em>assume</em> was used (to the point that it is what many video-game crafting systems set for) was coal.  The problem with coal is that it has to go through a process of <em>coking</em> in order to create a pure mass of carbon (called ‘coke’) which is suitable for use.  Without that conversion, the coal itself both does not burn hot enough, but also is apt to contain lots of sulfur, which will ruin the metal being made with it, as the iron will absorb the sulfur and produce an inferior alloy (sulfur makes the metal brittle, causing it to break rather than bend, and makes it harder to weld too).  Indeed, the reason we <em>know</em> that the Romans in Britain experimented with using local coal this way is that analysis of iron produced at Wilderspool, Cheshire during the Roman period revealed the presence of sulfur in the metal which was likely from the coal on the site.</p>



<p>We have records of early experiments with methods of coking coal in Europe beginning in the late 1500s, but the first truly successful effort was that of Abraham Darby in 1709.  Prior to that, it seems that the use of coal in iron-production in Europe was minimal (though coal might be used as a fuel for other things like cooking and home heating).  In China, development was more rapid and there is evidence that iron-working was being done with coke as early as the eleventh century.  But apart from that, by and large the fuel to create all of the heat we’re going to need is going to come from <strong>trees</strong>.</p>



<p><strong>And, as we’ll see, really quite a lot of trees.  Indeed, a <em>staggering</em> number of trees, if iron production is to be done on a major scale</strong>.  The good news is we needn’t be <em>too </em>picky about what trees we use;  ancient writers go on at length about the very specific best woods for ships, spears, shields, or pikes (fir, cornel, poplar or willow, and ash respectively, for the curious), but are far less picky about fuel-woods.  Pinewood seems to have been a consistent preference, both Pliny (<em>NH</em> 33.30) and Theophrastus (<em>HP</em> 5.9.1-3) note it as the easiest to use and Buckwald (<em>op cit</em>.) notes its use in medieval Scandinavia as well.  But we are also told that chestnut and fir also work well, and we see a fair bit of birch in the archaeological record.  So we have our trees, more or less.</p>



<h2>Forests and Fellers</h2>



<p>The bad news is that while ancient sources are often <em>very</em> interested in trees (entire books about them, in fact), they are generally interested in trees used to make things like ships, buildings, furniture and weapons; essentially, elite products.  They are <em>not</em> interested in trees used as fuel.  Indeed, Latin marks this distinction, where wood for building was <em>materia</em> whereas wood for burning (but also, it seems, bulk wood being transported overseas) was <em>lignum</em>; our sources care greatly about the former and only minimally about the latter.  And so as soon as we get very far into the question of the harvesting and preparation of fuel woods, our evidence just about drops away entirely, save for a few poor mentions of this or that tree being good for charcoaling (a crucial process we’ll get to in a moment).</p>



<figure><img data-attachment-id="4598" data-permalink="https://acoup.blog/1024px-transport_cedar_dur_sharrukin_louvre_ao19891/" data-orig-file="https://acoupdotblog.files.wordpress.com/2020/09/1024px-transport_cedar_dur_sharrukin_louvre_ao19891.jpg" data-orig-size="1024,833" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="1024px-transport_cedar_dur_sharrukin_louvre_ao19891" data-image-description="" data-medium-file="https://acoupdotblog.files.wordpress.com/2020/09/1024px-transport_cedar_dur_sharrukin_louvre_ao19891.jpg?w=300" data-large-file="https://acoupdotblog.files.wordpress.com/2020/09/1024px-transport_cedar_dur_sharrukin_louvre_ao19891.jpg?w=1024" src="https://acoupdotblog.files.wordpress.com/2020/09/1024px-transport_cedar_dur_sharrukin_louvre_ao19891.jpg?w=1024" alt="" srcset="https://acoupdotblog.files.wordpress.com/2020/09/1024px-transport_cedar_dur_sharrukin_louvre_ao19891.jpg 1024w, https://acoupdotblog.files.wordpress.com/2020/09/1024px-transport_cedar_dur_sharrukin_louvre_ao19891.jpg?w=150 150w, https://acoupdotblog.files.wordpress.com/2020/09/1024px-transport_cedar_dur_sharrukin_louvre_ao19891.jpg?w=300 300w, https://acoupdotblog.files.wordpress.com/2020/09/1024px-transport_cedar_dur_sharrukin_louvre_ao19891.jpg?w=768 768w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption><a href="https://commons.wikimedia.org/wiki/Dur_Sharrukin#/media/File:Transport_cedar_Dur_Sharrukin_Louvre_AO19891.jpg">Via Wikipedia</a>, a detail of an Assyrian relief from the palace of Sargon II (r. 722-705) at Dur-Sharrukin, now in the Louvre, Paris, showing the transport of Lebanese cedars; in this case, clearly building timber.</figcaption></figure>



<p>Consequently, our ability to see the fellows felling the forests (say <em>that</em> five times fast) is limited.  Medieval ‘foresters’ are often more visible, but much like we noted last time that when Georgius Agricola says ‘miner’ he means ‘mine owner,’ my understanding is that foresters in the Middle Ages were something closer to <em>administrators</em> of the forest (responsible for letting out contracts, catching poachers, etc.; essentially a sheriff but in the woods) rather than simple tree-fellers.</p>



<p>So who did the actual tree-cutting?  I must confess, I have found relatively little evidence for the social standing of ancient tree-fellers. <strong> In quite a lot of cases, they must not have been meaningfully distinct from the local peasantry or other sources of unskilled rural labor.</strong>  Clearly a lot of woodcutting was done by the rural population that bordered the forests to clear spaces for fields, gather fuel and firewood and so on, and consequently it seems like the basic skills of tree-felling may have been relatively common. The Latin word for a wood-cutter was a <em>lignator</em> (or sometimes a <em>caesor</em>, which meant ‘cutter’ but could mean of wood (<em>lignorum caesores</em>) or of stone), but that word most often appears in military contexts to mean soldiers tasked with cutting wood for fuel, not full-time lumberjacks.  Evidence for the medieval period is somewhat better and also generally suggests that the local peasantry was employed in the wood-cutting itself (for this, note J. Birrell, “Peasant Craftsmen in the Medieval Forest” <em>Agricultural History Review</em> 17.2 (1969): 91-107).  <strong>As we will see below, often wood cut for charcoaling was cut by the colliers themselves</strong>, who we will discuss below.  It seems hard to imagine that there wasn’t some division of labor in larger operations (like on Elba or at Populonia), but how that might have been structured is not clear from the limited evidence.</p>



<p>Not all timber works were so easily acquired, of course.  While ancient wood-cutters are hard to see in the evidence, ancient sawyers and carpenters are more visible; records from building programs in Athens and Delphi suggest that skilled sawyers (seemingly always assisted by at least one unskilled worker) were paid at least as well as citizen oarsmen in the Athenian navy and in some cases rather better.  The presence of English surnames like Carpenter, Cooper, Fletcher, Bowyer, Turner, Sawyer and Wheeler speak to the fact that these were specialized crafts in medieval England; the absence of wood-<em>cutting</em> surnames further suggests that the bulk labor of felling was mostly done by the local rural workforce.  <strong>Consequently, the social status of the average timber-cutter seems to have been about the same as that of a local peasant, serf or small-farmer, because by and large these seem to have been the same people</strong>; while the work done once the tree was down and barked might be done by specialists (but is far less important for trees that are going to be charcoaled).  There were also clearly specialist timber merchants, even in the ancient world, and the degree of their visibility, especially in timber-rich regions suggests that they could do quite well for themselves (although, <a href="https://acoup.blog/2020/08/21/collections-bread-how-did-they-make-it-part-iv-markets-and-non-farmers/">like most merchants</a>, we effectively never see them penetrate into the ruling class), but again, these merchants were likely working with building timbers because, as we’ll see, charcoal wood doesn’t tend to travel very far.</p>



<figure><img data-attachment-id="4600" data-permalink="https://acoup.blog/800px-transport_cedar_dur_sharrukin_louvre_ao19890/" data-orig-file="https://acoupdotblog.files.wordpress.com/2020/09/800px-transport_cedar_dur_sharrukin_louvre_ao19890.jpg" data-orig-size="800,1008" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="800px-transport_cedar_dur_sharrukin_louvre_ao19890" data-image-description="" data-medium-file="https://acoupdotblog.files.wordpress.com/2020/09/800px-transport_cedar_dur_sharrukin_louvre_ao19890.jpg?w=238" data-large-file="https://acoupdotblog.files.wordpress.com/2020/09/800px-transport_cedar_dur_sharrukin_louvre_ao19890.jpg?w=800" src="https://acoupdotblog.files.wordpress.com/2020/09/800px-transport_cedar_dur_sharrukin_louvre_ao19890.jpg?w=800" alt="" srcset="https://acoupdotblog.files.wordpress.com/2020/09/800px-transport_cedar_dur_sharrukin_louvre_ao19890.jpg 800w, https://acoupdotblog.files.wordpress.com/2020/09/800px-transport_cedar_dur_sharrukin_louvre_ao19890.jpg?w=119 119w, https://acoupdotblog.files.wordpress.com/2020/09/800px-transport_cedar_dur_sharrukin_louvre_ao19890.jpg?w=238 238w, https://acoupdotblog.files.wordpress.com/2020/09/800px-transport_cedar_dur_sharrukin_louvre_ao19890.jpg?w=768 768w" sizes="(max-width: 800px) 100vw, 800px"><figcaption><a href="https://commons.wikimedia.org/wiki/Dur_Sharrukin#/media/File:Transport_cedar_Dur_Sharrukin_Louvre_AO19890.jpg">Via Wikipedia</a>, a detail of an Assyrian relief from the palace of Sargon II (r. 722-705) at Dur-Sharrukin, now in the Louvre, Paris, showing the shipment of timber, in this case likely down the Tigris to the Assyrian heartland.  High quality building timbers or ship timbers do seem to have been valuable enough to be worth shipping long distances (Athens famously imported its ship-timber from Macedon), but fuel timbers tended to come from closer to hand.  But I <strong>had</strong> this picture and I wanted to use it.</figcaption></figure>



<p><strong>The largest stock of forest-land was typically owned by the state, but private landholders owning their own forests also played a role, albeit generally a small one</strong>.  In Macedon, the king owned the forests and controlled the supply of lumber, granting or revoking the authority for communities within his territory to take advantage of woodland resources; the practice seems to have been the same, Meiggs (<em>op cit</em>.) notes, in the Near East.  In Roman Italy, a large amount of the forest-land was held by the state and contracted out for timber-cutting;<em> </em>Meiggs supposes that figures called <em>saltuarii</em> may have been responsible for making sure that …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://acoup.blog/2020/09/25/collections-iron-how-did-they-make-it-part-ii-trees-for-blooms/">https://acoup.blog/2020/09/25/collections-iron-how-did-they-make-it-part-ii-trees-for-blooms/</a></em></p>]]>
            </description>
            <link>https://acoup.blog/2020/09/25/collections-iron-how-did-they-make-it-part-ii-trees-for-blooms/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24591216</guid>
            <pubDate>Fri, 25 Sep 2020 16:02:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[YouTube Channels to Level Up Your Programming Skills]]>
            </title>
            <description>
<![CDATA[
Score 260 | Comments 119 (<a href="https://news.ycombinator.com/item?id=24589474">thread link</a>) | @spiderjako22
<br/>
September 25, 2020 | https://blog.codegiant.io/programming-skills-d77d4abdf255 | <a href="https://web.archive.org/web/*/https://blog.codegiant.io/programming-skills-d77d4abdf255">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><section><div><div><div><div><div><div><p><a href="https://blog.codegiant.io/@codegiant?source=post_page-----d77d4abdf255--------------------------------" rel="noopener"><img alt="Team Codegiant" src="https://miro.medium.com/fit/c/96/96/2*iU0oAI5CSMp5LPuEKOqNuQ.png" width="48" height="48"></a></p></div></div></div></div><figure><div><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/2740/1*Xx2YxTWIGNI3ExVLq1meoA.png" width="1370" height="992" srcset="https://miro.medium.com/max/552/1*Xx2YxTWIGNI3ExVLq1meoA.png 276w, https://miro.medium.com/max/1104/1*Xx2YxTWIGNI3ExVLq1meoA.png 552w, https://miro.medium.com/max/1280/1*Xx2YxTWIGNI3ExVLq1meoA.png 640w, https://miro.medium.com/max/1400/1*Xx2YxTWIGNI3ExVLq1meoA.png 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*Xx2YxTWIGNI3ExVLq1meoA.png?q=20"></p></div></div></div></figure><p id="d6a2"><strong>From the desk of a brilliant weirdo #1:</strong></p><p id="e270"><em>Thank you for taking the time to check out this article. It doesn’t matter where you’re coming from (Codegiant, Hacker News, Reddit, or some other place), I always appreciate every reader who lands on my articles.</em></p><p id="0d0f">Now that I’ve coaxed you into reading this article, let’s get down to brass tacks.</p><p id="fb09">Whenever you’re just starting out with <a rel="noopener" href="https://blog.codegiant.io/software-development-life-cycle-the-ultimate-guide-2020-153d17bb20fb">software development</a> or simply want to uplevel your programming skills, you’ll need the right info resources to achieve your goals.</p><p id="3284">In this article, I’ve listed 22 of the best YouTube channels for improving your programming skills. Some are geared towards beginners while others focus on advanced topics.</p><p id="993e">So, if you consider yourself an experienced programmer, you can jump over to the last section where you’ll find all the 22 YouTube channels.</p><p id="2c67">If you are a beginner developer, however, I recommend that you go through each section of this article as we’ll talk about coding in general, programming skills, your computer programming resume, job opportunities, and some of the most in-demand programming languages.</p><p id="65e3">Without further ado:</p><p id="359c">Coding is the end result of a specific set of actions triggered to create a tangible result, whether it is a web page, an app, a video, or just an image on your screen.</p><p id="c92e">The great thing about computer coding (or programming) is that you can have a big idea and actually code it out into reality. And it doesn’t cost much, barring some time and effort on your side.</p><p id="3e5a">Many non-tech people consider the definition of a computer programmer to be someone who just makes programs. Although that’s partly true, partly not, it’s a mistake. Managers believe that the more lines of code a programmer can produce a month, the more creative he will be — another mistake. You can’t put a <a rel="noopener" href="https://blog.codegiant.io/software-developer-vs-software-engineer-31e873e787bc">developer</a> into a cubicle, set a deadline, ask him to work for 8–9 hours straight, and expect a top-notch quality software at the end.</p><p id="9e66">Instead of thinking about the programs a developer composes, one should consider the possible computations evoked by the developed program. “Designing a set of computations” is a more accurate description of what programmers actually do.</p><p id="5647">One can also imagine programmers as writers that have to think and write carefully, because the readers (the computers) take what the programmers write literally.</p><figure><div><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/2330/0*al-_-Anr6m8BIIIi" width="1165" height="805" srcset="https://miro.medium.com/max/552/0*al-_-Anr6m8BIIIi 276w, https://miro.medium.com/max/1104/0*al-_-Anr6m8BIIIi 552w, https://miro.medium.com/max/1280/0*al-_-Anr6m8BIIIi 640w, https://miro.medium.com/max/1400/0*al-_-Anr6m8BIIIi 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/0*al-_-Anr6m8BIIIi?q=20"></p></div></div></div></figure><p id="f506">Many non-tech folks believe that programming is all about acquiring technical skills. I believe that being a developer requires more than just knowing how to code. To make it in the software development world, you’ll need to dig up some creativity and inject it into your coding skills. The ability to think analytically is highly valued among developers as well.</p><p id="1779">One of the most essential skills a developer can have isn’t actually technical, it’s social, and that is empathy. Lack of empathy inevitably leads to poor communication (barring you are a narcissist, sociopath, or psychopath and therefore can be charming as hell). On the other hand, being able to put empathy into practice will, without doubt, boost your career opportunities.</p><p id="9732">When it comes to <strong>planning software</strong>, developers should know how to use models and flowcharts to convey instructions clearly.</p><p id="c39f"><strong>Designing and creating applications</strong>. Depending on the project, this can take from a couple of weeks to months and sometimes even years to complete.</p><p id="9b77"><strong>Writing programs</strong>. As simple as that.</p><p id="9220"><strong>Update and expand existing programs</strong>. Most times, you’ll need to modify and update existing programs with extra features.</p><p id="e7df"><strong>Debugging code</strong>. Yup.</p><p id="5ef0"><strong>Simplify programming</strong>. Developers may also use software tools to automate a part of their development process in order to simplify and speed up the workflow.</p><figure><div><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/2564/0*tJ40Go85DKYBw5cS" width="1282" height="869" srcset="https://miro.medium.com/max/552/0*tJ40Go85DKYBw5cS 276w, https://miro.medium.com/max/1104/0*tJ40Go85DKYBw5cS 552w, https://miro.medium.com/max/1280/0*tJ40Go85DKYBw5cS 640w, https://miro.medium.com/max/1400/0*tJ40Go85DKYBw5cS 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/0*tJ40Go85DKYBw5cS?q=20"></p></div></div></div></figure><p id="8ced">Showing up and practicing your programming skills seem to be the main ingredients to getting better at programming and coding. You gotta be programming in your spare time; you gotta be obsessed with it. Load yourself with patience because becoming a skilled coder takes years. And anyone who is telling you that you can learn and become good at coding in a month is probably trying to sell you something.</p><p id="8e25">Senior developers have all adopted common traits and basic coding skills that have helped them to rise in the hierarchy during their programming careers. Here are some valuable skills needed for you to be a senior developer:</p><p id="3a2c">One, being able to easily explain tech stuff to non-technical people.</p><p id="b60e">Two, being able to come up with accurate estimates.</p><p id="8cdb">Three, willingness to roll up their sleeves and do some grunt work.</p><p id="49a8">Four, knowing when to raise an issue to upper management.</p><p id="ff3f">Five, the ability to mentor junior developers.</p><p id="eb41">Six, vast knowledge of the technicalities for their domain.</p><h2 id="5ec1">Understand how the language works</h2><p id="e035">Focus on one language while learning. Having your focus split between two or three languages will discombobulate you.</p><p id="c797">It becomes obvious when a programmer doesn’t have a good understanding of the programming language he’s using. He’ll try to solve problems by following the logic of other languages and thus litter the code with unnecessary statements that can otherwise be reduced to fewer lines.</p><p id="094c">Also, you must know how to organize code into a system that makes sense. Creating rigid classes, schemas, and hierarchies require you to first think them through. Design can be a broad topic so I won’t cover much, but if you wish to read more, head over <a href="https://en.wikipedia.org/wiki/Fred_Brooks" rel="noopener">here</a>.</p><p id="e256">Poorly designed software lacks well-defined concepts, and its responsibilities are vague. Good software, on the other hand, comes with clear concepts and responsibilities. Take a look at mathematicians and physicists. They spend a huge amount of time trying to develop a clear definition of something because that will allow them to understand the truth about it. Developers should take a similar approach and spend a considerable amount of time brainstorming before writing code. Yes, this might be controversial to Agile but you gotta do what you gotta do.</p><p id="8ecf">It’s better to sit down with the dev team initially and outline all the required tasks than to go through 10 rounds of code reviews later.</p><p id="ea9f">Perhaps the best way to learn about design is to write and study many programs written by experienced programmers. As you gain more coding experience, you’ll, without doubt, enhance your design skills and expand your knowledge.</p><p id="0729">Good programmers ask questions like:</p><ul><li id="ff87">What’s the goal of this function?</li><li id="ee63">How can I explain this data structure to my teammates?</li><li id="771f">Can this function represent two standalone tasks?</li><li id="0e31">What’s the responsibility of this snippet of code?</li><li id="0f32">What should I include in the public interface?</li></ul><figure><div><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/2648/0*uR00-riTaFDc4QFt" width="1324" height="919" srcset="https://miro.medium.com/max/552/0*uR00-riTaFDc4QFt 276w, https://miro.medium.com/max/1104/0*uR00-riTaFDc4QFt 552w, https://miro.medium.com/max/1280/0*uR00-riTaFDc4QFt 640w, https://miro.medium.com/max/1400/0*uR00-riTaFDc4QFt 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/0*uR00-riTaFDc4QFt?q=20"></p></div></div></div></figure><p id="d2d4">Most people think that you need a diploma from Harvard or universities alike to be considered for a job in big tech companies. Although that may be partially true (<a href="https://www.cnbc.com/2018/08/16/15-companies-that-no-longer-require-employees-to-have-a-college-degree.html" rel="noopener">not always though, it seems Apple and Google no longer require you to have a college degree</a>), some companies prefer the opposite, or at least don’t want you to be coming for Harvard, Oxford, Stanford, etc.</p><p id="3c6c">There are CEOs out there looking for developers that are qualified but not overly qualified… hard workers, being on time, but also leaving at the stroke of 5. Such CEOs consider Ivy League schools to be a red flag. Big resumes are also a red flag. That’s because developers coming from such schools can’t get off their high horse, question whether every decision is optimal, and are always hungry for praise, recognition, and “interesting work.”</p><p id="c97a">Instead, these CEOs are looking for loyal people who know how to take orders without questioning, and are ready to do the work, day in and day out, because they need the paycheck at the end of the month.</p><p id="6749">At a glance, this might seem quite controversial. Yet, there are developers out there who don’t want to become millionaire CTOs at the age of 30. Instead, they are satisfied with what they have on their plate: a steady job, fair pay, and that’s about it. Some companies with that kind of culture say that they have produced a 100% employee retention rate which means developers are happy with their work environment.</p><h2 id="11a4">Let’s talk about your resume now.</h2><figure><div><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/1964/0*P0TDzRLC7SaDQKzK" width="982" height="911" srcset="https://miro.medium.com/max/552/0*P0TDzRLC7SaDQKzK 276w, https://miro.medium.com/max/1104/0*P0TDzRLC7SaDQKzK 552w, https://miro.medium.com/max/1280/0*P0TDzRLC7SaDQKzK 640w, https://miro.medium.com/max/1400/0*P0TDzRLC7SaDQKzK 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/0*P0TDzRLC7SaDQKzK?q=20"></p></div></div></div></figure><p id="2aa7">So, what should you list on your resume?</p><p id="8bab">Proficiency in programming languages is, ostensibly, a vital thing to include. Always remember that companies are getting tens, hundreds, even thousands of applications a month. All of which say “I can do X.” The thing is skill level varies between each applicant. You should describe your coding experience and give examples of successful projects you’ve completed.</p><p id="dbb6">When listing your most valuable programming skills, there are a couple of things you need to know in order to have a fully optimized programming resume.</p><ol><li id="72b7">Before sending your resume, always go through the job description a couple of times and try to understand what is relevant to the job you are applying for. Then make yourself relevant to the job.</li><li id="dd11">Always be honest with yourself. Don’t list programming languages you don’t know because they are mentioned in the job description. Don’t tell them you have 5 years of experience when you only have 4 years and 1 month.</li><li id="1642">Place your programming skills (languages) right at the top, below the header.</li><li id="a384">List your most advanced coding skills first, then in the middle list the ones you are least experienced with, and at the end, list the programming skills you have a decent experience with.</li><li id="44ae">Create horizontal categories instead of vertical ones. This eliminates the blank space on your resume while remaining aesthetically pleasing.</li></ol><p id="1230">In your resume, except for talking about what you bring to the table, you can also mention what you’re looking for in an employer. You’ll thus earn the respect you are looking for if you get the job.</p><p id="48b7">Also, avoid using phrases that everybody else is using. Don’t be afraid to infuse your CV with some personality. You’ll thus stand out. Not everybody will like your personality, but those that do will adore you. Try to be specific in your writing. Instead of “extensive experience,” say “5 years and 6 months of experience.” Instead of saying “Y number of successful projects,” say “Y amount of successful projects that helped us achieve A, …</p></div></div></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.codegiant.io/programming-skills-d77d4abdf255">https://blog.codegiant.io/programming-skills-d77d4abdf255</a></em></p>]]>
            </description>
            <link>https://blog.codegiant.io/programming-skills-d77d4abdf255</link>
            <guid isPermaLink="false">hacker-news-small-sites-24589474</guid>
            <pubDate>Fri, 25 Sep 2020 13:30:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[MacOS-like Fonts on Manjaro/Arch Linux]]>
            </title>
            <description>
<![CDATA[
Score 167 | Comments 156 (<a href="https://news.ycombinator.com/item?id=24588947">thread link</a>) | @aswinmohanme
<br/>
September 25, 2020 | https://aswinmohan.me/posts/better-fonts-on-linux/ | <a href="https://web.archive.org/web/*/https://aswinmohan.me/posts/better-fonts-on-linux/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
				<p>Either you love gorgeous typography or just don’t care. If you are the former read ahead on how to make the font rendering on your Linux look just as awesome as that on macOS, else read on to find out what beauty you have been missing.</p>
<p>I switched to a hackintosh for a while and fell in love with how beautiful the typography was. After returning to Linux and some fiddiling around I came across a not so ugly setup that looked close enough to macOS. So if you want to make your Linux Distro a tad bit typographically better, follow along.</p>
<h3 id="results">Results</h3>
<p>This is how the fonts look on the default installation of Manjaro Linux.
</p><figure>
    <img src="https://aswinmohan.me/images/before_macosfont.png"> <figcaption>
            <h4>Search before font change</h4>
        </figcaption>
</figure>

<figure>
    <img src="https://aswinmohan.me/images/wikipedia_beforefonts.png"> <figcaption>
            <h4>Wikipedia before font change</h4>
        </figcaption>
</figure>

<p>This is how they would look after we are done.
</p><figure>
    <img src="https://aswinmohan.me/images/after_macos.png"> <figcaption>
            <h4>Search after font change</h4>
        </figcaption>
</figure>

<figure>
    <img src="https://aswinmohan.me/images/wikipedia_afterfonts.png"> <figcaption>
            <h4>Wikipedia after font change</h4>
        </figcaption>
</figure>

<h3 id="some-pointers">Some Pointers</h3>
<p>Rather than copy pasting everything on here, let’s try to understand why the fonts on macOS looks better than the ones we have on Linux.</p>
<p>Fonts belong to certain types.</p>
<ul>
<li><code>sans-serif</code> : Well the sans fonts on your computer. The regular plain fonts.</li>
<li><code>serif</code> : The fonts that look like they came out of a 14th century Bible. You know with the curves and they look like showoffs.</li>
<li><code>monospace</code> : The typical code font. The ones where every character is the same width.</li>
</ul>
<p>The reason fonts look way better on macOS is because Steve Jobs loved typography, and he went the extra mile and licensed some great typefaces for each font type, and recently Apple put in the extra effort to make their custom fonts even better. Well fret not Linux has some free fonts that are metric compatible(means they look awfully similar), and better that we can substitute for fonts.</p>
<h3 id="installation">Installation</h3>
<p>Step one is installing the fonts that look similar or better than the ones on macOS.
All the fonts that are used here can be found on the Arch Repositories, and on Google Fonts. You are free to replace everything with the ones you find great.</p>
<ul>
<li><code>sans-serif</code> : tex-gyre-fonts, free alternative to Helvetica and Arial and looks really really similar</li>
<li><code>serif</code> : Libertinus Serif, suprisingly looks really great</li>
<li><code>monospace</code> : DM Mono from Google Fonts, for monospace fonts that look great</li>
<li><code>emoji</code> : noto-fonts-emoji, get some colorful emojis</li>
</ul>
<p>If you are using Manjaro or Arch here is the command to get all fonts in one go.</p>
<div><pre><code data-lang="fallback">yay -S tex-gyre-fonts otf-libertinus noto-fonts-emoji
</code></pre></div><h3 id="font-setup">Font Setup</h3>
<p>Everything about fonts can be configured from a single file located at <code>/etc/fonts/local.conf</code> if the file doesn’t exist create it. You do require <code>sudo</code> for it.</p>
<div><pre><code data-lang="fallback">sudo nvim /et/fonts/local.conf
</code></pre></div><p>After you are editing the file copy paste everything here.</p>
<div><pre><code data-lang="fallback">&lt;?xml version='1.0'?&gt;
&lt;!DOCTYPE fontconfig SYSTEM 'fonts.dtd'&gt;
&lt;fontconfig&gt;

&lt;match target="font"&gt;
  &lt;edit name="autohint" mode="assign"&gt;
    &lt;bool&gt;true&lt;/bool&gt;
  &lt;/edit&gt;
  &lt;edit name="hinting" mode="assign"&gt;
    &lt;bool&gt;true&lt;/bool&gt;
  &lt;/edit&gt;
  &lt;edit mode="assign" name="hintstyle"&gt;
    &lt;const&gt;hintslight&lt;/const&gt;
  &lt;/edit&gt;
  &lt;edit mode="assign" name="lcdfilter"&gt;
   &lt;const&gt;lcddefault&lt;/const&gt;
 &lt;/edit&gt;
&lt;/match&gt;


&lt;!-- Default sans-serif font --&gt;
 &lt;match target="pattern"&gt;
   &lt;test qual="any" name="family"&gt;&lt;string&gt;-apple-system&lt;/string&gt;&lt;/test&gt;
   &lt;!--&lt;test qual="any" name="lang"&gt;&lt;string&gt;ja&lt;/string&gt;&lt;/test&gt;--&gt;
   &lt;edit name="family" mode="prepend" binding="same"&gt;&lt;string&gt;Tex Gyre Heros&lt;/string&gt;  &lt;/edit&gt;
 &lt;/match&gt;

 &lt;match target="pattern"&gt;
   &lt;test qual="any" name="family"&gt;&lt;string&gt;Helvetica Neue&lt;/string&gt;&lt;/test&gt;
   &lt;!--&lt;test qual="any" name="lang"&gt;&lt;string&gt;ja&lt;/string&gt;&lt;/test&gt;--&gt;
   &lt;edit name="family" mode="prepend" binding="same"&gt;&lt;string&gt;Tex Gyre Heros&lt;/string&gt;  &lt;/edit&gt;
 &lt;/match&gt;

 &lt;match target="pattern"&gt;
   &lt;test qual="any" name="family"&gt;&lt;string&gt;Helvetica&lt;/string&gt;&lt;/test&gt;
   &lt;!--&lt;test qual="any" name="lang"&gt;&lt;string&gt;ja&lt;/string&gt;&lt;/test&gt;--&gt;
   &lt;edit name="family" mode="prepend" binding="same"&gt;&lt;string&gt;Tex Gyre Heros&lt;/string&gt;  &lt;/edit&gt;
 &lt;/match&gt;

 &lt;match target="pattern"&gt;
   &lt;test qual="any" name="family"&gt;&lt;string&gt;arial&lt;/string&gt;&lt;/test&gt;
   &lt;!--&lt;test qual="any" name="lang"&gt;&lt;string&gt;ja&lt;/string&gt;&lt;/test&gt;--&gt;
   &lt;edit name="family" mode="prepend" binding="same"&gt;&lt;string&gt;Tex Gyre Heros&lt;/string&gt;  &lt;/edit&gt;
 &lt;/match&gt;

 &lt;match target="pattern"&gt;
   &lt;test qual="any" name="family"&gt;&lt;string&gt;sans-serif&lt;/string&gt;&lt;/test&gt;
   &lt;!--&lt;test qual="any" name="lang"&gt;&lt;string&gt;ja&lt;/string&gt;&lt;/test&gt;--&gt;
   &lt;edit name="family" mode="prepend" binding="same"&gt;&lt;string&gt;Tex Gyre Heros&lt;/string&gt;  &lt;/edit&gt;
 &lt;/match&gt;
 
&lt;!-- Default serif fonts --&gt;
 &lt;match target="pattern"&gt;
   &lt;test qual="any" name="family"&gt;&lt;string&gt;serif&lt;/string&gt;&lt;/test&gt;
   &lt;edit name="family" mode="prepend" binding="same"&gt;&lt;string&gt;Libertinus Serif&lt;/string&gt;  &lt;/edit&gt;
   &lt;edit name="family" mode="prepend" binding="same"&gt;&lt;string&gt;Noto Serif&lt;/string&gt;  &lt;/edit&gt;
   &lt;edit name="family" mode="prepend" binding="same"&gt;&lt;string&gt;Noto Color Emoji&lt;/string&gt;  &lt;/edit&gt;
   &lt;edit name="family" mode="append" binding="same"&gt;&lt;string&gt;IPAPMincho&lt;/string&gt;  &lt;/edit&gt;
   &lt;edit name="family" mode="append" binding="same"&gt;&lt;string&gt;HanaMinA&lt;/string&gt;  &lt;/edit&gt;
 &lt;/match&gt;

&lt;!-- Default monospace fonts --&gt;
 &lt;match target="pattern"&gt;
   &lt;test qual="any" name="family"&gt;&lt;string&gt;SFMono-Regular&lt;/string&gt;&lt;/test&gt;
   &lt;edit name="family" mode="prepend" binding="same"&gt;&lt;string&gt;DM Mono&lt;/string&gt;&lt;/edit&gt;
   &lt;edit name="family" mode="prepend" binding="same"&gt;&lt;string&gt;Space Mono&lt;/string&gt;&lt;/edit&gt;
   &lt;edit name="family" mode="append" binding="same"&gt;&lt;string&gt;Inconsolatazi4&lt;/string&gt;&lt;/edit&gt;
   &lt;edit name="family" mode="append" binding="same"&gt;&lt;string&gt;IPAGothic&lt;/string&gt;&lt;/edit&gt;
 &lt;/match&gt;

 &lt;match target="pattern"&gt;
   &lt;test qual="any" name="family"&gt;&lt;string&gt;Menlo&lt;/string&gt;&lt;/test&gt;
   &lt;edit name="family" mode="prepend" binding="same"&gt;&lt;string&gt;DM Mono&lt;/string&gt;&lt;/edit&gt;
   &lt;edit name="family" mode="prepend" binding="same"&gt;&lt;string&gt;Space Mono&lt;/string&gt;&lt;/edit&gt;
   &lt;edit name="family" mode="append" binding="same"&gt;&lt;string&gt;Inconsolatazi4&lt;/string&gt;&lt;/edit&gt;
   &lt;edit name="family" mode="append" binding="same"&gt;&lt;string&gt;IPAGothic&lt;/string&gt;&lt;/edit&gt;
 &lt;/match&gt;

 &lt;match target="pattern"&gt;
   &lt;test qual="any" name="family"&gt;&lt;string&gt;monospace&lt;/string&gt;&lt;/test&gt;
   &lt;edit name="family" mode="prepend" binding="same"&gt;&lt;string&gt;DM Mono&lt;/string&gt;&lt;/edit&gt;
   &lt;edit name="family" mode="prepend" binding="same"&gt;&lt;string&gt;Space Mono&lt;/string&gt;&lt;/edit&gt;
   &lt;edit name="family" mode="append" binding="same"&gt;&lt;string&gt;Inconsolatazi4&lt;/string&gt;&lt;/edit&gt;
   &lt;edit name="family" mode="append" binding="same"&gt;&lt;string&gt;IPAGothic&lt;/string&gt;&lt;/edit&gt;
 &lt;/match&gt;

&lt;!-- Fallback fonts preference order --&gt;
 &lt;alias&gt;
  &lt;family&gt;sans-serif&lt;/family&gt;
  &lt;prefer&gt;
   &lt;family&gt;Noto Sans&lt;/family&gt;
   &lt;family&gt;Noto Color Emoji&lt;/family&gt;
   &lt;family&gt;Noto Emoji&lt;/family&gt;
   &lt;family&gt;Open Sans&lt;/family&gt;
   &lt;family&gt;Droid Sans&lt;/family&gt;
   &lt;family&gt;Ubuntu&lt;/family&gt;
   &lt;family&gt;Roboto&lt;/family&gt;
   &lt;family&gt;NotoSansCJK&lt;/family&gt;
   &lt;family&gt;Source Han Sans JP&lt;/family&gt;
   &lt;family&gt;IPAPGothic&lt;/family&gt;
   &lt;family&gt;VL PGothic&lt;/family&gt;
   &lt;family&gt;Koruri&lt;/family&gt;
  &lt;/prefer&gt;
 &lt;/alias&gt;
 &lt;alias&gt;
  &lt;family&gt;serif&lt;/family&gt;
  &lt;prefer&gt;
   &lt;family&gt;Noto Serif&lt;/family&gt;
   &lt;family&gt;Noto Color Emoji&lt;/family&gt;
   &lt;family&gt;Noto Emoji&lt;/family&gt;
   &lt;family&gt;Droid Serif&lt;/family&gt;
   &lt;family&gt;Roboto Slab&lt;/family&gt;
   &lt;family&gt;IPAPMincho&lt;/family&gt;
  &lt;/prefer&gt;
 &lt;/alias&gt;
 &lt;alias&gt;
  &lt;family&gt;monospace&lt;/family&gt;
  &lt;prefer&gt;
   &lt;family&gt;Noto Sans Mono&lt;/family&gt;
   &lt;family&gt;Noto Color Emoji&lt;/family&gt;
   &lt;family&gt;Noto Emoji&lt;/family&gt;
   &lt;family&gt;Inconsolatazi4&lt;/family&gt;
   &lt;family&gt;Ubuntu Mono&lt;/family&gt;
   &lt;family&gt;Droid Sans Mono&lt;/family&gt;
   &lt;family&gt;Roboto Mono&lt;/family&gt;
   &lt;family&gt;IPAGothic&lt;/family&gt;
  &lt;/prefer&gt;
 &lt;/alias&gt;

&lt;/fontconfig&gt;
</code></pre></div><p>What this file does that is it creates aliases for the common fonts used on the web and uses the metric compatible fonts that we have. That way we have way better looking fonts.</p>
<p>After you have done all this, restart your computer to see the changes.</p>
<h3 id="chrome">Chrome</h3>
<p>If you are using chrome, you can do something more too.</p>
<ul>
<li>Goto Settings</li>
<li>Select Customize Fonts under Appearences</li>
<li>Set Standard to <code>Libertinus Serif</code></li>
<li>Set Serif to <code>Libertinus Serif</code></li>
<li>Set Sans-serif to <code>TeX Gyre Heros</code></li>
<li>Set Fixed-width to <code>Monospace</code></li>
</ul>
<h3 id="interface-text">Interface Text</h3>
<p>For Desktop Environments like Gnome and KDE, you could use Tex-Gyre-Heros for the overall Helvetica look. I use Gnome 3.36 and use <code>TeX Gyre Heros Regular 10</code> as my interface text.</p>
<p>That’s all set, and keep in mind this guide will be improved.</p>

			</div></div>]]>
            </description>
            <link>https://aswinmohan.me/posts/better-fonts-on-linux/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24588947</guid>
            <pubDate>Fri, 25 Sep 2020 12:22:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What makes a good REPL? (2017)]]>
            </title>
            <description>
<![CDATA[
Score 62 | Comments 27 (<a href="https://news.ycombinator.com/item?id=24588453">thread link</a>) | @diggan
<br/>
September 25, 2020 | https://vvvvalvalval.github.io/posts/what-makes-a-good-repl.html | <a href="https://web.archive.org/web/*/https://vvvvalvalval.github.io/posts/what-makes-a-good-repl.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <ol><li><a href="#what_does_a_good_repl_give_you?">What does a good REPL give you?</a></li><ol><li><a href="#a_smooth_transition_from_manual_to_automated">A smooth transition from manual to automated</a></li><li><a href="#a_repl_lets_you_improvise">A REPL lets you improvise</a></li><li><a href="#a_repl_lets_you_write_fewer_tests,_faster">A REPL lets you write fewer tests, faster</a></li><li><a href="#a_repl_makes_you_write_accessible_code">A REPL makes you write accessible code</a></li></ol><li><a href="#what_makes_a_good_repl?">What makes a good REPL?</a></li><li><a href="#what_makes_a_programming_language_repl-friendly?">What makes a programming language REPL-friendly?</a></li><li><a href="#conclusion">Conclusion</a></li></ol>
    <p> <i>Dear Reader: although this post mentions Clojure as an example, it is not specifically about Clojure; please do not make it part of a language war. If you know other configurations which allow for a productive REPL experience, please describe them in the comments!</i></p><p> <img src="https://vvvvalvalval.github.io/img/repl.gif" width="100%"></p><p>Most comparisons I see of Clojure to other programming languages are in terms of its programming language <em>semantics</em>:  immutability, homoiconicity, data-orientation, dynamic typing, first-class functions, polymorphism 'à la carte'...  All of these are interesting and valuable features, but what actually gets me to <em>choose</em> Clojure for projects is its interactive  development story, enabled by <em>the REPL</em> (Read-Eval-Print Loop), which lets you evaluate Clojure expressions in an interactive  shell (including expressions which let you modify the state or behaviour of a running program).  </p><p>If you're not familiar with Clojure, you may be surprised that I describe the REPL as Clojure's most differentiating feature:   after all, most industrial programming languages come with REPLs or 'shells' these days (including Python, Ruby, Javascript, PHP, Scala,  Haskell, ...). However, I've never managed to reproduced the productive REPL workflow I had in Clojure with those languages;  the truth is that <strong>not all REPLs are created equal</strong>.</p><p>In this post, I'll try to describe what a 'good' REPL gives you, then list some technical characteristics which make some REPLs   qualify as 'good'. Finally, I'll try to reflect on what programming language features give REPLs the most leverage.</p><h2 id="what_does_a_good_repl_give_you?">What does a good REPL give you?</h2><p>The short answer is: by providing a <i>tight feedback loop</i>, and making your programs <i>tangible</i>,  a REPL helps you deliver programs with significantly higher productivity and quality.  If you're wondering why a tight feedback loop is important for creative activities such as programming, I recommend you watch  <a href="https://www.vimeo.com/36579366">this talk by Bret Victor</a>.</p><p>If you have no idea what REPL-based development looks like, I suggest you watch a few minutes of  <a href="https://vimeo.com/230220635" target="_blank">the following video</a>:</p><p><iframe src="https://player.vimeo.com/video/230220635" width="640" height="359" frameborder="0" webkitallowfullscreen="" mozallowfullscreen="" allowfullscreen=""></iframe></p><p>Now, here's the long answer: <i>A good REPL gives you...</i></p><h3 id="a_smooth_transition_from_manual_to_automated">A smooth transition from manual to automated</h3><p>The vast majority of the programs we write essentially automate tasks that humans can do themselves.  Ideally, to automate a complex task, we should be able to break it down into smaller sub-tasks, then gradually automate each of the subtasks until reaching a fully-automated solution.  If you were to build a sophisticated machine like a computer from scratch, you would want to make sure you understand how the individual components work before putting them together, right?  Unfortunately, this is not what we get with the typical write/(compile)/run/watch-stdout workflow, in which we essentially put all the pieces together blindly and pray it works the first time we hit 'run'.  The story is different with a REPL: you will have played with each piece of code in isolation before running the whole program,  which makes you quite confident that each of the sub-tasks is well implemented.</p><p>This is also true in the other direction: when a fully-automated program breaks, in order to debug it,  you will want to re-play some of the sub-tasks manually.</p><p>Finally, not all programs need be fully automated - sometimes the middle ground between manual and automated is exactly what you want.  For instance, a REPL is a great environment to run ad hoc queries to your database, or perform ad hoc data analysis, while leveraging  all of the automated code you have already written for your project - much better than working with database clients, especially when  you need to query several data stores or reproduce advanced business logic to access the data.</p><p>How's life without a REPL? Here's a list of things that we do to cope with these issues when we don't have a REPL:</p><ul><li>Experiment with interactive tools such as cURL or database clients, then reproduce what we did in code.  Problem: you can't connect these in any way with your existing codebase. These tools are good at experimenting manually,  but then you have to code all the way to bridge the gap between making it work with these tools and having it work in your project.</li><li>Run scripts which call our codebase to print to standard output our files. Problem: you need to know exactly what to output before writing the script; you can't hold on to program state and <em>improvise</em> from there, as we'll discuss in the next section.</li><li>Use unit tests (possibly with auto-reloading), which have a number of limitations in this regard, as we'll see later in this post.</li></ul><h3 id="a_repl_lets_you_improvise">A REPL lets you improvise</h3><p>Software programming is primarily and <i>exploratory</i> activity.  If we had a precise idea of how our programs should work before writing them, we'd be <i>using</i> code, not writing it.</p><p>Therefore, we should be able to write our programs incrementally, one expression at a time, figuring out what to do next at each step,  <i>walking the machine through</i> our current thinking. This is simply not what the  compile/run-the-whole-thing/look-at-the-logs workflow gives you.</p><p>In particular, one situation where this ability is critical is fixing bugs in an emergency.  When you have to reproduce the problem, isolate the cause, simulate the fix and finally apply it, a REPL is often the  difference between minutes and hours.</p><p>Fun fact: maybe the most spectacular occurrence of this situation was the fixing of a bug  of the <a href="https://www.youtube.com/watch?v=_gZK0tW8EhQ">Deep Space 1</a> probe in 1999,  which fortunately happened to run a Common Lisp REPL while drifting off course several light-minutes away from Earth.</p><h3 id="a_repl_lets_you_write_fewer_tests,_faster">A REPL lets you write fewer tests, faster</h3><p>Automated tests are very useful for expressing what your code is supposed to do,  and giving you confidence that it works and keeps working correctly.</p><p>However, when I see some TDD codebases, it seems to me that a lot of unit tests are mostly here to make the code more tangible while developing, which is the same value proposition as using a REPL. However, using unit tests for this purpose comes with its lot of issues:</p><ol><li>Having too many unit tests makes your codebase harder to evolve. You ideally want to have as few tests as possible capture as many properties of your domain as possible.</li><li>Tests can only ever answer close-ended questions: "does this work?", but not "how does this work?", "what does this look like?" etc.</li><li>Tests typically won't run in real-world conditions: they'll use simple, artificial data and mocks of services such as databases or API clients. As a result, they don't typically help you understand a problem that only happens on real-life data, nor do they give you confidence that the real-life implementations of the services they emulate do work.</li></ol><p>So it seems to me a lot of unit tests get written for lack of a better solution for interactivity,  even though they don't really pull their weight as unit tests.  When you have a REPL, you can make the choice to only write the tests that matter.</p><p>What's more, the REPL <i>helps you</i> write these tests. Once you have explored from the REPL, you can just copy and paste  some of the REPL history to get both example data and expected output. You can even use the REPL to assist you in writing  the fixture data for your tests by generating it programmatically (everyone who has written comprehensive fixture datasets  by hand knows how tedious this can get). Finally, when writing the tests require implementing some non-trivial logic  (as is the case when doing Property-Based Testing), the productivity benefits of the REPL for writing code applies to writing tests as well.</p><p>Again, do <i>not</i> take from this that a REPL is a replacements for tests. Please do write tests, and let the REPL help you  write the right tests effectively.</p><h3 id="a_repl_makes_you_write_accessible_code">A REPL makes you write accessible code</h3><p>A REPL-based workflow encourages you to write programs which manipulate values that are <strong><i>easy to fabricate.</i></strong>  If you need to set up a complex graph of objects before you can make a single method call, you won't be very inclined to use the REPL.  </p><p>As a result, you'll tend to write <strong><i>accessible code</i></strong> - with few dependencies, little environmental coupling, high modularity,   and tangible inputs and outputs.  This is likely to make your code more clear, easy to test, and easy to debug.  </p><p>To be clear, this <i>is</i> an additional constraint on your code (it requires some upfront thinking to make your code REPL-friendly,  just likes it requires some upfront thinking to make your code easy to test) - but I believe it's a very beneficial constraint.  When my car engine breaks, I'm glad I can just lift the hood and access all the parts - and making this possible  has certainly put more work on the plate of car designers.</p><p>Another way a REPL makes code more accessible is that it makes it easier to learn, by providing a rich playground for beginners to experiment.  This applies to both learning languages and onboarding existing projects.</p><h2 id="what_makes_a_good_repl?">What makes a good REPL?</h2><p>As I said above, not all REPLs give you the same power.  Having experimented with REPLs in various configurations of language and tooling,  this is the list of the main things I believe a REPL should enable you to do to give you the most leverage:</p><ol><li><strong>Defining new behaviour / modify existing behaviour.</strong> For instance, in a procedural language, this means defining new functions, and modify the implementation of existing functions.</li><li><strong>Saving state in-memory.</strong> If you can't hold on to the data you manipulate, you will waster a ton of effort re-obtaining it - it's like doing your paperwork without a desk.</li><li><strong>Outputting values which can easily be translated to code.</strong> This means that the textual representation the REPL outputs is suitable for being embedded in code.</li><li><strong>Giving you access to your whole project code.</strong> You should be able to call any piece of code written in your project of its dependencies. As an execution …</li></ol></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://vvvvalvalval.github.io/posts/what-makes-a-good-repl.html">https://vvvvalvalval.github.io/posts/what-makes-a-good-repl.html</a></em></p>]]>
            </description>
            <link>https://vvvvalvalval.github.io/posts/what-makes-a-good-repl.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24588453</guid>
            <pubDate>Fri, 25 Sep 2020 10:38:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Throw away code]]>
            </title>
            <description>
<![CDATA[
Score 98 | Comments 77 (<a href="https://news.ycombinator.com/item?id=24587934">thread link</a>) | @lukastyrychtr
<br/>
September 25, 2020 | https://vorner.github.io/2020/09/20/throw-away-code.html | <a href="https://web.archive.org/web/*/https://vorner.github.io/2020/09/20/throw-away-code.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main_content_wrap">
      <section id="main_content">
        

<p>There’s an ongoing discussion about what makes Python better prototyping
language than Rust (with Python being probably just the archetype of some
scripted weakly-typed language). The thing is, I prefer doing my prototypes in
Rust over Python. Apparently, I’m not the only one. So I wanted to share few
things about what makes Rust viable for these kinds of throw-away coding
sprints, at least for me.</p>

<h2 id="our-goals">Our goals</h2>

<p>Sometimes, our goal isn’t really to write perfect code that is performant,
correct, handles all kinds of errors sanely, has great UX and is maintainable.
These projects are what we are proud of, sure. We pin them on github profiles.
We write blog posts about them. We write whole handbooks of best practices how
to do them.</p>

<p>But sometimes we just need to throw something together really fast and don’t
care about the quality as much. That kind of bit of cardboard and huge amount of
duck tape thing. These include:</p>

<ul>
  <li>Single-use debugging tools („I need to throw 10k of these weird requests at
the server to see if it triggers the bug. It didn’t? Ok, let’s try something
else…“)</li>
  <li>Searching for a counter-example to a claim in a scientific paper („I can prove
it’s a counter example once I have it, so I won’t need the code any more“)</li>
  <li>Processing bunch of data just once („I wonder how many of these <code>.txt</code> files
have broken unicode in them“)</li>
  <li>Figuring if something has any chance to fly at all, before committing to it
(„Could I distribute the changes as compressed binary diffs, or would that be
too large?“)</li>
  <li>Demonstration purposes („We would like to build something in lines of this,
but, you know, actually working“)</li>
</ul>

<p>Of course, there’s a lot more. I’m not even sure if there’s more of the „proper“
coding or of this „throw away“ coding. Except that we don’t really brag about
our throw-away code („Look what terrible monster I’ve stitched together during
the lunch break“), we don’t write tutorials how to write them much, etc. So this
is exactly the kind of blog post we don’t write 😈.</p>

<p>Instead of writing something proper this time, we are going to talk about
how to write terrible code, but fast. We have decided to make an explicitly
sloppy job of this one and admit it to ourselves not to feel ashamed of it
later:</p>

<ul>
  <li>We want to spend as little time on it as possible. Just do it, throw the code
away after it had its use and move on. This one is going to be over by lunch
time.</li>
  <li>We don’t care about performance that much (as long as it finishes running
before the lunch too).</li>
  <li>We don’t care about handling all corner cases, only the ones we actually
encounter in the data.</li>
  <li>We don’t care about documentation or readability.</li>
  <li>We don’t care about tests, provided we are confident enough the answers are
accurate enough.</li>
  <li>Actually, we don’t really care at all…</li>
</ul>

<p><em>Note: make sure not to let anyone put this into production 😇. If you don’t
delete it, make sure there’s a comment on a prominent place warning people not
to use it.</em></p>

<h2 id="why-do-people-think-python-fits-here-better-than-rust">Why do people think Python fits here better than Rust</h2>

<p>The thing is, Rust <em>makes us</em> care. That’s one of the points of Rust. It’ll
complain that our code is not production quality and that we need to do better
to save on the pain down the line. Its type system can be a real prick in
insisting on little details, like that ints and strings are not really the same
thing and that there’s a difference between owned and borrowed thing and… Well,
you know, all that stuff. Rust wants you to make good, proper, maintainable
code.</p>

<p>On the other hand, Python doesn’t really insist on anything. Therefore, it is
easier to not care in Python.</p>

<h2 id="my-own-experience">My own experience</h2>

<p>I know a bunch of programming languages and reach for the one that I hope would
suit me best in the given time. So, for some really simple things I simply put
together few lines of shell (and some slightly less simple ones ‒ I’m ashamed to
admit that some 1000 lines long shell monster kept running in real production
for years ‒ but it <em>did run</em>). If it can be done by 2 or 3 ugly pipelines, it’s
fine.</p>

<p>Over the years, I’ve used Perl a lot (that one doesn’t care if it’s int or
string… no, correction, in Perl everything is a string, ints just don’t exist.
Well, kind of). It’s probably <em>the</em> language designed for throw away coding.
I’ve done some Python too (that’s like Perl, but with proper objects in it, and
everything is a dictionary there).</p>

<p>But recently I’ve noticed that if I try to do a similar thing, I do it faster in
Rust. Not that it runs faster (well, that usually too, but that’s not the
point), but that I’m done with the task at hand sooner and with slightly smaller
amount of cursing.</p>

<p>This certainly is in part because I’m more proficient in Rust than in Python.
It’s also because the Rust mental model is closer to how my brain works than the
Python one. <strong>Your mileage will vary</strong> ‒ if you’re a Python matador who’s been
coding in it for decades and are just learning Rust, you’ll certainly do it
faster in Python.</p>

<p>But also, there are some tricks you might employ to do these things in Rust
faster (that is, faster than you do now, not necessarily faster than in
<code>$OTHER_LANGUAGE</code>).</p>

<h2 id="tricks-for-faster-coding">Tricks for faster coding</h2>

<h3 id="compile-times">Compile times</h3>

<p>Rust is known for its slow compile times. Python has <em>no</em> compile times. If you
have to wait every time for the compilation just to have a bunch of errors
thrown into your face, it’s going to slow you down. Especially because Rust
<em>likes to</em> throw bunch of errors at you every time you try to compile it. Rust
is known for its great error messages, so it wants to brag how good they are by
using them <em>a lot</em>.</p>

<p>You can, however, notice that you don’t really need to <em>build and run</em> every
time. That you often just want to check everything is on the right path. For
Python, you do need to actually run the thing (because Python doesn’t really
have much of a compile time so it likes to throw the bunch of errors into your
face at <em>run time</em>), but Rust is the language that „if
it compiles, it’s correct“. And by complies, I actually mean mostly type-checks.</p>

<p>What does this all mean? You can check out:</p>

<ul>
  <li>The <code>rust-analyzer</code> language server. You’ll be getting red squiggles in the
editor instead of having to compile. It’s not perfect (sometimes the list of
errors is different, sometimes it just gives up on that particular project),
but it’s getting better and it points out most of the errors without any
compilation at all.</li>
  <li><code>cargo check</code> performs just the first stages of compilation and will stop
before codegen. It means it doesn’t produce anything that could be run, but
it is so much faster and provides the bunch of errors we so much want to have.</li>
  <li>You can let <code>cargo watch</code> keep recompiling the code asynchronously in another
terminal. I just glance at it to check if there are any errors around, but I
don’t wait for it ‒ at worst, the list of errors is one iteration outdated. It
can be used for other things, like keeping the documentation of the current
crate up to date, or having a head start at compiling the executable, or even
having all the tests being re-run on each save (I’m getting off topic here; we
are being sloppy here on purpose, so what tests are we talking about?)</li>
</ul>

<p>These don’t make the compile times shorter, but it eliminates the <em>waiting</em> for
them from the hot coding path. It still takes some time to compile (especially
if you have a lot of dependencies and do a clean release build), but that
doesn’t mean it has to slow you down.</p>

<h3 id="embrace-the-type-system-and-borrow-checker-and-all-of-these-things">Embrace the type system (and borrow checker and all of these things)</h3>

<p>After some time working with Rust, one learns to lean onto them instead of
fighting them.</p>

<p>This is where most of my own speed up comes from and what I miss about Python.
When I want to know if my code is working, I actually have to run the Python
thing and feed it with data. Which means I either need to set up a smaller input
or wait for the whole thing to get crunched, only to have it explode on some
typo or switched order of parameters after 5 minutes of running. After 10
iterations of running the Python code (each crashing later and later in the
code), it finally finishes. By that time, I’m no longer confident it does what
it should, after all these retries, so I go back and have to figure a way to
double-check it.</p>

<p>In Rust not only I don’t have to run the code until it is almost finished and
even when I feed it the whole input (which I usually do), it’s usually faster
and it runs to completion the first time. I also can move through the code much
faster. With Python, I stop to check the documentation, think about what type
goes where, etc, exactly because it’s so painful to find out only at runtime. I
need to be careful while writing the code.
With Rust, I just type the code, get the red squiggly, fix it and move on. I
outsource that effort of checking if these things click together in any
meaningful way to the compiler.</p>

<p>This is kind of in the theme of „hurry slowly“ approach. By making sure
everything has the right types and aligns well, it makes each iteration slower.
But it also makes it possible to have much fewer iterations before the whole
thing works well enough.</p>

<p>Also, don’t fall for the impression that throwing <code>unsafe</code> in there to bypass
some of the checking will save you time. It won’t. It’s a trap. If you don’t
know for sure that you need it, then you probably don’t and doing <code>unsafe</code> right
is a lot of work. Doing it wrong is easy, maybe easier than doing it safely, but
you’ll pay for it later on, when trying to figure out why the thing does
something arcanely weird. If you put any non-trivial <code>unsafe</code> in the code,
you’re risking spending days and nights in front of a debugger. The checks are
there for a reason.</p>

<h3 id="take-the-easy-way-out">Take the easy way out</h3>

<p>I don’t say to clone everything. Even in prototyping code, I often take <code>&amp;str</code>
as parameter if it’s just „looking at it“. But I do so in the obvious, trivial
cases. The ones I don’t really need to think about any more.</p>

<p>But if you ever find yourself thinking about writing any kind of
<code>-&gt; impl Iterator&lt;Item = &amp;impl Display&gt; + '_</code>, just stop and throw a
<code>Vec&lt;String…</code></p></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://vorner.github.io/2020/09/20/throw-away-code.html">https://vorner.github.io/2020/09/20/throw-away-code.html</a></em></p>]]>
            </description>
            <link>https://vorner.github.io/2020/09/20/throw-away-code.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24587934</guid>
            <pubDate>Fri, 25 Sep 2020 08:55:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Time Zone Bugs I Ran Into]]>
            </title>
            <description>
<![CDATA[
Score 54 | Comments 66 (<a href="https://news.ycombinator.com/item?id=24586991">thread link</a>) | @Sandeepg33k
<br/>
September 24, 2020 | https://blog.davidojeda.dev/4-time-zone-bugs-i-ran-into | <a href="https://web.archive.org/web/*/https://blog.davidojeda.dev/4-time-zone-bugs-i-ran-into">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><section itemprop="articleBody mainEntityOfPage"><meta itemprop="thumbnailUrl image" content="https://cdn.hashnode.com/res/hashnode/image/upload/v1600871234687/et6yX6Wlb.png?w=1600&amp;h=840&amp;fit=crop&amp;crop=entropy&amp;auto=format&amp;q=60"><div><div itemprop="text"><p>Software development is hard. Time zones are hard. Dealing with time zones in software development?  Yeah, <strong>harder</strong>.</p>
<p>Here are <strong>4</strong> places where time zones might differ; and 4 personal bug stories for each case. I'll be referring to the same app for each story, the one I work with and maintain in my day-to-day job. This app works with Mexico's City time zone.</p>

<h2 id="time-zone-of-your-app">Time zone of your app</h2>
<p>Your app runs with a default time zone. It's usually the time zone of the server it runs on, but it can be different.</p>
<p>In Java, you can define the time zone of the whole application when it boots. If for some reason you don't want to work with your server's timezone, this is the place to change it.</p>
<h3 id="the-bug-time-in-chile-off-by-one-hour">The bug - Time in Chile off by one hour</h3>
<p>The app shows the date of creation of an object in many places. Three of these places were showing different times; <strong>two incorrect and one correct</strong>.</p>
<p>One error was because I forgot to pass the user's timezone to the date formatter. Quick fix.</p>
<p>The second error was weird. I couldn't identify why, so I compared it with the correct one.</p>
<p>But the third case was only right because the date had been double parsed! Once on the server and a second time on the client (browser).</p>
<p>So none of the three dates were actually correct. <strong>WTF?</strong></p>
<p>After some headaches, I learned that each version of Java comes with a time zone data file. This file includes the latest information on the world's time zones, and the <a target="_blank" href="https://www.iana.org/time-zones">Internet Assigned Numbers Authority (IANA)</a> manages it. </p>
<p>Time zone changes happen when governments decide to apply or not to apply daylight saving times (DST). </p>
<p>In 2015, Chile decided to move from seasonal DST to permanent DST, and some JRE releases included this change. But then, in 2016 Chile decided to revert to how it was before; seasonal DST instead of permanent. <strong>What was the issue?</strong> The app was using one of these JRE releases with an outdated time zone data file.</p>
<p>You can read more about these <a target="_blank" href="https://hi.service-now.com/kb_view.do?sysparm_article=KB0622033">DST issues with Java here</a>.</p>

<h2 id="time-zone-of-your-server">Time zone of your server</h2>
<p>The operative system defines your server's time zone. I've always used Linux for production servers, and they come with UTC as the default time zone.</p>
<p>If you need to change this time zone, make sure to do it before your application starts or it won't reflect the change.</p>
<h3 id="the-bug-app-using-the-wrong-default-time-zone-from-the-server">The bug - App using the wrong default time zone from the server</h3>
<p>I was migrating some processes in our build and deployment pipeline. From configuring the app with every deploy to a pre-built AWS Amazon Machine Image (AMI) with HashiCorp's Packer.</p>
<p>One step of the initial configuration was to change the server's time zone to America/Mexico_City, and I was aware of it. So I created a bash script that changed the time zone on the AMI we were going to use. The script worked well when I tested it on a Linux instance. No problem there.</p>
<p>I proceeded to use this AMI in our staging environment and neither I nor my teammates noticed something off. So, to production!</p>
<p>Customer's questions and complaints about dates behaving weird arrived minutes later 😥</p>
<p><strong>The issue?</strong> The script that updated the server's time zone was failing silently and I missed double-checking it in the staging environment. The app wasn't using an explicit time zone, so it took the server's. And the server's time zone was UTC by default, and we needed America/Mexico_City. I fixed the script and, to make sure, updated the app's default time zone to the expected one.</p>

<h2 id="time-zone-of-your-database">Time zone of your database</h2>
<p>You can also change your database's time zone. I use AWS Relational Database Service (RDS) and the default time zone is UTC. You can update it from the parameter group of your cluster or individual instance.</p>
<h3 id="the-bug-wrong-database-time-zone">The bug - Wrong database time zone</h3>
<p>Now I was doing a migration of our database. I anticipated myself by changing the database's time zone to America/Mexico_City because the app and server had it. Every part of the system should be in the same page, right? <strong>Wrong!</strong></p>
<p>The database was perfectly okay being in UTC while the app and server were in America/Mexico_City. That's how it worked. </p>
<p>This bug was not as critical as the previous ones because I caught it in our staging environment. </p>

<h2 id="time-zone-of-your-users">Time zone of your users</h2>
<p>If it wasn't enough, each one of your users can have a different time zone, and you have to take that into consideration when showing time sensitive-data.</p>
<h3 id="the-bug-many-of-them">The bug - Many of them!</h3>
<p>I've encountered many bugs related to user's time zones:</p>
<ul>
<li>Missing time zone in date formatter.</li>
<li>Incorrect time zone selection from the user.</li>
<li>Missing DST time zone options for users to select.</li>
<li>Storing dates with time zone modifications that get parsed again when retrieved.</li>
</ul>
<hr>
<p>Time zones are one of the most complicated topics you'll find while developing software. They're complex by themselves, and even more when you throw some code into the mix.</p>
<p>I hope these short stories can help you avoid my mistakes in the future 🙌🏼</p>
<p><strong>Thanks for reading me! 💙</strong></p>
</div></div></section></div></div>]]>
            </description>
            <link>https://blog.davidojeda.dev/4-time-zone-bugs-i-ran-into</link>
            <guid isPermaLink="false">hacker-news-small-sites-24586991</guid>
            <pubDate>Fri, 25 Sep 2020 06:01:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How Iranian diaspora is using old-school tech to fight internet shutdown at home]]>
            </title>
            <description>
<![CDATA[
Score 111 | Comments 42 (<a href="https://news.ycombinator.com/item?id=24585986">thread link</a>) | @rfreytag
<br/>
September 24, 2020 | https://restofworld.org/2020/cat-and-mouse-censorship/ | <a href="https://web.archive.org/web/*/https://restofworld.org/2020/cat-and-mouse-censorship/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
			
<p>One November morning last year, Mehdi Yahyanejad listened to a voicemail in his Los Angeles office: “I’m contacting you from the city of Tehran,” said the voice. “This was the first time I’ve experienced an internet shutdown. … It feels like I’m in a prison.”</p>



<p>A few weeks earlier, Iran’s largest mobile networks and internet providers went offline. Amid weeks of growing anti-regime protests, Iranian authorities imposed <a href="https://edition.cnn.com/2019/11/18/middleeast/iran-protests-explained-intl/index.html">the longest internet shutdown</a> in the country’s history, effectively cutting off external communication for over 80 million Iranians. In an unprecedented crackdown, regime forces <a href="https://www.amnesty.org/en/latest/news/2020/05/iran-details-released-of-304-deaths-during-protests-six-months-after-security-forces-killing-spree/">killed more than 300 protesters</a> and arrested <a href="https://www.amnesty.org/en/latest/news/2019/12/iran-thousands-arbitrarily-detained-and-at-risk-of-torture-in-chilling-post-protest-crackdown/">over 7,000 people</a>. When access was finally restored on November 23, nearly half the country was still unable to come online.</p>



<p>Nine months after the November blackout, Iranians still live in fear of another all-out shutdown. As authorities tighten their hold on internet access, diaspora-led companies are filling the gap for Iranians who are seeking a way to bypass censors. The circumvention tools, created largely by diaspora entrepreneurs, are becoming increasingly critical as they face a crackdown at home and the bite of American-led sanctions online.</p>



<p>On November 15, as Iranian authorities first moved to induce the digital blackout, 44-year-old Yahyanejad raced against the clock in Los Angeles to make sure that people back home had downloaded his satellite file-casting application <a href="https://www.toosheh.org/">Toosheh</a>.<em> </em>“It was a very small window,” says Yahyanejad. “Once they were fully disconnected, I wasn’t sure they’d be able to download the software.”&nbsp;</p>



<p>Launched by Yahyanejad in 2016, the technology aggregates uncensored content, like news articles, YouTube videos, and podcasts, and sends it to Iranian homes directly via satellite TV. When Yahyanejad first began developing Toosheh in 2013, an estimated 70% of Iranian households owned a satellite dish, while around 20% had access to the internet. Even as internet access has grown, state censorship means Toosheh’s satellite technology is a much more reliable source for uncensored content. Iranians can install Toosheh’s satellite channel and receive a daily dispatch in the form of a file package of up to 8 gigabytes. Once a user downloads the app, the satellite transfers circumvent the internet entirely.&nbsp;</p>



<p>Yahyanejad says Toosheh gained nearly 100,000 new Iranian users in November 2019. In the absence of an internet connection, it became the only way for many users to access news from the outside world. The voice on Toosheh’s voicemail belonged to one such user, a 34-year-old high school principal in Tehran who downloaded emergency VPN and proxy tools delivered to him through the satellite service.&nbsp;</p>



<p>Having navigated extensive cyber censorship for over a decade, Iranians are tech savvy and <a href="https://www.bbc.com/news/blogs-trending-42612546">adept at nimbly crossing firewalls</a>, using proxies and foreign circumvention tools. “It’s a constant cat-and-mouse game,” says Fereidoon Bashar, executive director of ASL19, a Canadian organization working to help Iranians bypass internet censorship. The group often works in tandem with Yahyanejad to distribute proxy tools.&nbsp;</p>



<p>Bashar says Iranians adapt quickly to ever-changing institutionalized control online. But the last five years of Iranian president Hassan Rouhani’s rule have seen <a href="https://www.cnet.com/news/irans-president-plans-to-cut-countrys-internet-off-from-the-rest-of-the-world/">a tighter grip on internet connections</a>. Site blocking and calculated internet outages have become easier to enforce: the regime has reduced Iran’s dependence on global networks by pushing a local intranet, with the <a href="https://www.wired.com/2016/09/how-iran-is-building-its-censorship-friendly-domestic-internet/">aim to keep online traffic</a> inside the country. With strict American sanctions that threaten hefty fines for companies interfacing with Iran, foreign tech companies limit ordinary Iranians’ ability to purchase reliable proxies <a href="https://www.wired.com/2016/09/how-iran-is-building-its-censorship-friendly-domestic-internet/">out of an abundance of caution</a>. Riddled with insecurity, the local VPN black market is not a reliable option for those trying to avoid government attention.</p>



<p>But even as internet access grew incrementally difficult over the years, no one saw the November blackout coming. “An internet shutdown was previously viewed as a kind of dystopian political campaign,” says Kaveh Azarhoosh, an internet policy researcher. In November, the worst-case scenario for Iran’s censorship suddenly became a reality.&nbsp;&nbsp;</p>



<p>In the early days of the protest, Toosheh created a special “Protest News Package.” Every night, after aggregating content from over 200 publications, Toosheh delivered digital bundles containing clips of protests occuring in different cities: Tabriz, Qom, Shiraz, Mashhad, and others. It also contained slides about how to stay safe during a protest; crucial news coverage from banned sites, like the <em>New York Times</em>, Voice of America Persian, and Deutsche Welle; and a curated compilation of tweets from Iranian politicians. These packages weren’t just bringing news of the outside world to Iran: they kept Iranians informed about what was happening inside their own country too.</p>



<p>Yahyanejad, a physicist by training, left Iran in 1997 to pursue a Ph.D. from the Massachusetts Institute of Technology. “I’ve lived in Iran, and I’ve gone to school and college there,” he explains. “I know that this repressive government exists because they are able to control the flow of information.” He says he’s always had an interest in limiting their control. “I want,” he says, “to see democracy in Iran in my lifetime.”&nbsp;</p>



<p>In 2006, Yahyanejad launched a Reddit-like forum called <a href="https://www.balatarin.com/">Balatarin</a>. “Its popularity surprised me,” he says. The site posted a translated rumor about the supreme leader’s death, after he hadn’t been seen in public for two months, and was swiftly blocked by Iran shortly after. The moment was a turning point for Yahyanejad, who says, “I made a conscious decision to keep the platform open at a personal cost.”&nbsp;</p>



<p>The Iranian blocks on Balatarin inspired Yahyanejad to explore censorship circumvention. He launched the satellite app Toosheh in 2016. “I <a href="https://www.youtube.com/watch?v=FWfwF8Gx6VA">went on BBC Persian’s ‘Newshour</a>,’ and as soon as I talked about it, people started downloading and testing it immediately,” he says.&nbsp;</p>



<p>Yahyanjad finds himself among a cohort of diaspora Iranians working to fight the regime’s censors. ASL19, the Canadian technology group, collaborated with him to deliver proxy tools to over half a million Iranians during November’s shutdown. ASL19’s Bashar, who left Iran in the early 2000s before <a href="https://opennet.net/blog/2013/02/after-green-movement-internet-controls-iran-2009-2012">the tumultuous Green Movement</a>, says diaspora Iranians are stepping into the field because Iranians “risk harsh conditions, imprisonment, and long sentences” if they’re caught creating circumvention tools inside the country.&nbsp;&nbsp;</p>



<p>But even outside of Iran, outspoken diaspora activists like Bashar and Yahyanejad face immense risks. In June, it was reported that an Iranian activist named Ruhollah Zam was <a href="https://www.bbc.com/news/world-middle-east-53238000">sentenced to death </a>in Iran after creating a popular anti-government Telegram news channel that he operated while living in exile in France. The channel, with 1.4 million followers, was shut down shortly after. For Yahyanejad, who knew of Ruhollah through the diaspora community, the ordeal was a shot across the bow. “I can never go back to Iran,” Yahyanejad admits. “But I see myself as part of the movement.”&nbsp;</p>



<p>Yahyanejad’s work has become crucial for Iranians, even after November’s shutdown. On July 14, following news that Iran’s Supreme Court had upheld the death sentences of three young anti-regime protesters, Iranians took to banned social media sites in an unprecedented protest, with over 6 million posts under the hashtag #DontExecute. Hours after #DontExecute began trending online, digital rights organization NetBlocks <a href="https://twitter.com/netblocks/status/1283106806332620801?s=20">monitored disruptions in the network</a>. Panicked users, still reeling from November’s shutdown, speculated another block was imminent. Luckily, an all-out ban didn’t occur, but the renewed threat of one was enough to increase Toosheh’s usage by more than 50% in the days that followed.&nbsp;</p>



<p>For Yahyanejad, who has been actively fighting the Iranian regime’s censorship for over a decade, the past year is proof that his work is even more necessary. “Internet shutdowns are psychological tools designed to terrify populations, to convince them that they are voiceless,” he says. “Fighting shutdowns is important so that you can show people that they are not alone and that there are others.”</p>
		</div></div>]]>
            </description>
            <link>https://restofworld.org/2020/cat-and-mouse-censorship/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24585986</guid>
            <pubDate>Fri, 25 Sep 2020 02:26:43 GMT</pubDate>
        </item>
    </channel>
</rss>
