<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 20]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 20. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Fri, 16 Oct 2020 16:34:21 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-20.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Fri, 16 Oct 2020 16:34:21 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[LDM: My Favorite ARM Instruction]]>
            </title>
            <description>
<![CDATA[
Score 84 | Comments 74 (<a href="https://news.ycombinator.com/item?id=24785357">thread link</a>) | @one_and_only
<br/>
October 14, 2020 | https://keleshev.com/ldm-my-favorite-arm-instruction/ | <a href="https://web.archive.org/web/*/https://keleshev.com/ldm-my-favorite-arm-instruction/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
  


  

<center>Vladimir Keleshev • 2020-10-13</center>


<p>LDM—or <em>load multiple</em>—is my favorite assembly instruction of the ARM instruction set. Here’s why.</p>
<p>First, let’s discuss what LDM does. An example:</p>
<pre><code>ldm r4, {r0, r1, r2, r3}</code></pre>
<p>Here, it takes a <em>base register</em> (in this case, <code>r4</code>) and a <em>register set</em> (in this case, <code>{r0, r1, r2, r3}</code>). It loads consecutive words from the address in the base register into the registers in the set. In this example, the effect could be described using the following C-like pseudo-code:</p>
<pre><code>r0 = r4[0];
r1 = r4[1];
r2 = r4[2];
r3 = r4[3];</code></pre>
<p>That’s quite a few assignments for a single instruction! And that’s why it’s called <em>load multiple</em>.</p>
<p>The set notation also allows for ranges. We can rewrite the previous example as follows:</p>
<pre><code>ldm r4, {r0-r3}</code></pre>
<p>Any and all of the 16 ARM registers are allowed in the set. So, the following is legal:</p>
<pre><code>ldm r0, {r0, r1, r2, r3, r4, r5, r6, r7, r8, r9, r10, r11, r12, r13, r14, r15}</code></pre>
<p>The register set is encoded as a 16-bit mask in a 32-bit instruction. Here’s a simplified encoding of the original example:</p>
<figure>
<img src="https://keleshev.com/ldm-my-favorite-arm-instruction/ldm-encoding-arm.svg" alt=""><figcaption>Simplified encoding of the LDM instruction</figcaption>
</figure>
<p>Such instruction is a perfect fit for a <a href="https://en.wikipedia.org/wiki/Load%E2%80%93store_architecture">load-store architecture</a> like ARM, where the primary workflow is:</p>
<ul>
<li>load many values from memory into registers,</li>
<li>perform operations exclusively on registers,</li>
<li>store results back from registers into memory.</li>
</ul>
<p>The opposite of LDM is STM—<em>store multiple</em>.</p>
<!---Since both of them operate on *sets* of registers (which are implemented as bit masks), you can't directly select the order in which the values are loaded or stored.
The set `{r0, r1, r2}` is the same as `{r2, r1, r0}`.
That's why-->
<h2 id="block-copy">Block copy</h2>
<p>With these two, you can copy large blocks of memory fast. You can copy eight words (or 32 bytes!) of memory in just two instructions:</p>
<pre><code>ldm r0, {r4-r11}
stm r1, {r4-r11}</code></pre>
<p>LDM and STM also have auto-increment variants (denoted with “!”) where the base register is incremented by the number of words loaded/stored so that you can do the copying in a fast loop:</p>
<pre><code>ldm r0!, {r4-r11}
stm r1!, {r4-r11}</code></pre>
<h2 id="implementing-stacks">Implementing stacks</h2>
<p>ARM’s POP instruction is simply an alias for LDM with a stack pointer (and auto-increment). The following two are exactly the same:</p>
<pre><code>ldm sp!, {r0-r3}
pop {r0-r3}</code></pre>
<p>And the PUSH instruction is an alias for an STM variant (STMDB).</p>
<p>You can push and pop large quantities to and from the stack in one go. And if you replace SP by another register you can implement efficient stacks in other regions of memory. For example, you can implement a <a href="https://en.wikipedia.org/wiki/Shadow_stack">shadow stack</a> in the heap.</p>
<h2 id="saving-registers">Saving registers</h2>
<p>Are you hesitating to use the call-preserved registers because you need to save them, and you might as well use a stack slot anyway? Not any more, because you can save all call-preserved registers you want to use in one go:</p>
<pre><code>push {r4-r11}</code></pre>
<h2 id="prologue-and-epilogue">Prologue and epilogue</h2>
<p>On ARM, the first four arguments, the return address (LR) and the frame pointer (FP) are all passed in registers. That’s why it’s especially important to have efficient prologues and epilogues. Fortunately, you can save FP and LR in one go, using a fairly standard ARM prologue:</p>
<pre><code>push {fp, lr}</code></pre>
<p>And then restore both and return (for the epilogue):</p>
<pre><code>pop {fp, lr}
bx lr</code></pre>
<p>Even better, you can restore both and return in one go!</p>
<pre><code>pop {fp, pc}</code></pre>
<p>This works by popping the return address value (LR) into the program counter register (PC), so you don’t need an explicit return!</p>
<p>This is good enough in itself, but you can—<em>at the same time</em>—spill some arguments onto the stack (for example, if their address is taken):</p>
<pre><code>push {r0-r3, fp, lr}</code></pre>
<p>Or, you can save FP and LR and—<em>at the same time</em>—allocate some space on the stack:</p>
<pre><code>push {r0-r3, fp, lr}</code></pre>
<p>In this case, we push <code>r0-r3</code> not for their value but to advance the stack pointer by four words.</p>
<h2 id="arm64">ARM64</h2>
<p>I suspect it was a difficult trade-off, but when it was time to design the 64-bit version of the ARM instruction set, the decision was made to double the number of registers to 32. I remember reading a paper saying that this change improves the performance by about 6% across the board. With 32 registers it is no longer possible to encode a bitmask of all registers into a 32-bit long instruction. So, instead, ARM64 has LDP and STP: load pair and store pair, which are the spiritual successors of LDM and STM.</p>
<hr>
<p>This blog post started out originally as a <a href="https://twitter.com/keleshev/status/1285654345988673536">Twitter thread</a>. <a href="https://keleshev.com/" title="Home">■</a></p>
<hr>
<p><em>Did you like this blog post? If so, check out my new book:</em> Compiling to Assembly from Scratch. <em>It teaches you enough assembly programming and compiler fundamentals to implement a compiler for a small programming language. </em></p>


      
  <p><a href="https://keleshev.com/compiling-to-assembly-from-scratch">
       <img alt="Compiling to Assembly from Scratch, the book by Vladimir Keleshev" src="https://keleshev.com/compiling-to-assembly-from-scratch.jpg" width="200" height="300">
      </a>
  </p>
  <hr>


</div>]]>
            </description>
            <link>https://keleshev.com/ldm-my-favorite-arm-instruction/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24785357</guid>
            <pubDate>Thu, 15 Oct 2020 06:04:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Eric Yuan's Visa Application Was Rejected 8 Times]]>
            </title>
            <description>
<![CDATA[
Score 60 | Comments 64 (<a href="https://news.ycombinator.com/item?id=24783979">thread link</a>) | @shsachdev
<br/>
October 14, 2020 | https://www.careerfair.io/reviews/eric-yuan-effect | <a href="https://web.archive.org/web/*/https://www.careerfair.io/reviews/eric-yuan-effect">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <p>
I’ve been reading about Eric Yuan, founder of Zoom.
</p>
<p>
Yuan migrated to the USA from China in the 80s. He had heard Bill Gates speak about the internet and he wanted to be a part of the digital revolution. 
</p>
<p>
So he applied for his visa. He was rejected. He applied again. Rejected again.
</p>
<p>
9 tries. It took Eric Yuan 9 tries to finally get his visa for the USA.
</p>
<p>
Once in the USA, he started working at the video conferencing software company WebEx. 
</p>
<p>
He worked there for a decade and rose up the ranks to become the VP of Engineering. 
</p>
<p>
Under Yuan’s leadership, WebEx grew to more than 750 engineers and had an annual revenue of around $1B (and was later acquired by Cisco). Safe to say the company was doing well. 
</p>
<p>
But there was a problem. 
</p>
<p>
The video conferencing software <em>sucked</em>. 
</p>
<p>
Yuan would meet with customers and they would be unhappy. They’d complain about video and audio lag. Connectivity issues. All sorts of stuff. 
</p>
<p>
In Yuan’s own words:
</p>

<blockquote>
  Before I left Cisco I spent a lot of time talking to WebEx customers and every time I talked to them I felt very embarrassed because I did not see a single happy customer, and I tried to understand why that was.
    <span>Eric Yuan</span>
</blockquote>

<p>
So in 2011, Yuan left. He decided to start his own company with the mission of building the best video conferencing software in the world. 
</p>
<p>
After he left, 40 of the 800 engineers he worked with immediately joined him at Zoom. 
</p>
<p>
And according to <a href="https://twitter.com/dscheinm/status/1300544031458553859">this tweet</a>, almost all of the others sent in resumes to work with him. He had something like 1000 job inquiries within a week of announcing his leaving.
</p>
<p>
Talk about engineering loyalty. 
</p>
<p>
Today Zoom is valued at more than $40 billion. The pandemic may have accelerated the company’s growth but make no mistake: this was an overnight success 9 years in the making. 
</p>
<h2>Takeaway</h2>
<p>
I think the part that stands out the most to me is that Yuan actually had the courage to leave Cisco and go on to start Zoom. 
</p>
<p>
There is often great inertia that prevents us from leaving jobs we’re unhappy with. 
</p>
<p>
In Yuan’s case, he had by all measures a very successful career ever since he immigrated to the US. Most people in his shoes wouldn’t even bother resigning from a comfortable VP of Engineering position. 
</p>
<p>
So he could have settled and just resigned himself to the fact that maybe video conferencing software was supposed to be like this. After all, there was very little competition in the market. 
</p>
<p>
But he didn’t. He chose discomfort and hundreds of other engineers believed in him. 
</p>
<p>
Keep moving forward and don’t settle. You might be surprised at how many people follow you. 
</p>
          </div></div>]]>
            </description>
            <link>https://www.careerfair.io/reviews/eric-yuan-effect</link>
            <guid isPermaLink="false">hacker-news-small-sites-24783979</guid>
            <pubDate>Thu, 15 Oct 2020 01:59:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why software engineering processes and tools don’t work for machine learning]]>
            </title>
            <description>
<![CDATA[
Score 79 | Comments 70 (<a href="https://news.ycombinator.com/item?id=24781490">thread link</a>) | @ChefboyOG
<br/>
October 14, 2020 | https://www.comet.ml/site/why-software-engineering-processes-and-tools-dont-work-for-machine-learning/ | <a href="https://web.archive.org/web/*/https://www.comet.ml/site/why-software-engineering-processes-and-tools-dont-work-for-machine-learning/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		    <div>
			
<p>“AI is the new electricity.” At least, that’s what <a href="https://www.coursera.org/instructor/andrewng">Andrew Ng</a> suggested at this year’s <a href="https://remars.amazon.com/">Amazon re:MARS</a> conference. In his <a href="https://www.youtube.com/watch?v=j2nGxw8sKYU">keynote address</a>, Ng discussed the rapid growth of artificial intelligence (AI) — its steady march into industry after industry; the unrelenting presence of AI breakthroughs, technologies, or fears in the headlines each day; the tremendous amount of investment, both from established enterprises seeking to modernize (see: <a href="https://www.engadget.com/2019/11/19/sony-ai/">Sony</a>, a couple of weeks ago) as well as from venture investors parachuting into the market riding a wave of AI-focused founders.&nbsp;</p>



<p>“AI is the next big transformation,” Ng insists, and we’re watching the transformation unfold.</p>



<p>While AI may be the new electricity (and as a Data Scientist at <a href="http://comet.ml/">Comet</a>, I don’t need much convincing), significant challenges remain for the field to realize this potential.<strong> In this blog post, I’m going to talk about why data scientists and teams can’t rely on the tools and processes that software engineering teams have been using for the last 20 years for machine learning</strong> <strong>(ML).&nbsp;</strong></p>



<p>The reliance on the tools and processes of software engineering makes sense – data science and software engineering are both disciplines whose principal tool is<em> code</em>. Yet <em>what is being done</em> in data science teams is radically different from what is being done in software engineering teams. An inspection of the core differences between the two disciplines is a helpful exercise in clarifying how we should think about structuring our tools and processes for doing AI.&nbsp;</p>



<p>At Comet, we believe the adoption of tools and processes designed specifically for AI will help practitioners unlock and enable the type of revolutionary transformation Ng is speaking about.</p>



<h2>Different Disciplines, Different Processes</h2>



<p>Software engineering is a discipline whose aim is, considered broadly, the design and implementation of programs that a computer can execute to perform a defined function. Assuming the input to a software program is within the expected (or constrained) range of inputs, its behavior is knowable. In a <a href="https://leon.bottou.org/talks/2challenges">talk</a> at ICML in 2015, Leon Bottou formulated this well: in software engineering an algorithm or program can be proven <em>correct</em>, in the sense that given particular assumptions about the input, certain properties will be true when the algorithm or program terminates.</p>
<figure id="attachment_2550" aria-describedby="caption-attachment-2550"><img src="https://www.comet.ml/site/app/uploads/2019/12/Screen-Shot-2020-03-27-at-9.56.18-AM-1024x863.png" alt="ml vs software eng" width="500" height="422" srcset="https://www.comet.ml/site/app/uploads/2019/12/Screen-Shot-2020-03-27-at-9.56.18-AM-1024x863.png 1024w, https://www.comet.ml/site/app/uploads/2019/12/Screen-Shot-2020-03-27-at-9.56.18-AM-300x253.png 300w, https://www.comet.ml/site/app/uploads/2019/12/Screen-Shot-2020-03-27-at-9.56.18-AM-768x648.png 768w, https://www.comet.ml/site/app/uploads/2019/12/Screen-Shot-2020-03-27-at-9.56.18-AM.png 1110w" sizes="(max-width: 500px) 100vw, 500px" data-old-src="https://www.comet.ml/site/app/ewww/lazy/placeholder-1024x863.png" data-src="https://www.comet.ml/site/app/uploads/2019/12/Screen-Shot-2020-03-27-at-9.56.18-AM-1024x863.png" data-srcset="https://www.comet.ml/site/app/uploads/2019/12/Screen-Shot-2020-03-27-at-9.56.18-AM-1024x863.png 1024w, https://www.comet.ml/site/app/uploads/2019/12/Screen-Shot-2020-03-27-at-9.56.18-AM-300x253.png 300w, https://www.comet.ml/site/app/uploads/2019/12/Screen-Shot-2020-03-27-at-9.56.18-AM-768x648.png 768w, https://www.comet.ml/site/app/uploads/2019/12/Screen-Shot-2020-03-27-at-9.56.18-AM.png 1110w"><figcaption id="caption-attachment-2550">Source: Futurice</figcaption></figure>
<p>

The provable correctness of software programs has shaped the tools and processes we have built for doing software engineering. Consider one corollary characteristic of software programming that follows from provable correctness: if a program is provably correct for some input values, then the program contains sub-programs that are also provably correct for those input values. This is why engineering processes like <a href="https://en.wikipedia.org/wiki/Scaled_agile_framework">Agile</a> are, broadly speaking, successful and productive for software teams. Breaking apart these projects into sub-tasks works. Most <a href="https://en.wikipedia.org/wiki/Waterfall_model">waterfall</a> and <a href="https://en.wikipedia.org/wiki/Scrum_(software_development)">scrum</a> implementations also include sub-tasking as well.</p>


<figure>
<figure id="attachment_2552" aria-describedby="caption-attachment-2552"><img src="https://www.comet.ml/site/app/uploads/2019/12/Screen-Shot-2020-03-27-at-9.57.24-AM-1024x550.png" alt="" width="700" height="376" srcset="https://www.comet.ml/site/app/uploads/2019/12/Screen-Shot-2020-03-27-at-9.57.24-AM-1024x550.png 1024w, https://www.comet.ml/site/app/uploads/2019/12/Screen-Shot-2020-03-27-at-9.57.24-AM-300x161.png 300w, https://www.comet.ml/site/app/uploads/2019/12/Screen-Shot-2020-03-27-at-9.57.24-AM-768x413.png 768w, https://www.comet.ml/site/app/uploads/2019/12/Screen-Shot-2020-03-27-at-9.57.24-AM-1536x825.png 1536w, https://www.comet.ml/site/app/uploads/2019/12/Screen-Shot-2020-03-27-at-9.57.24-AM.png 1694w" sizes="(max-width: 700px) 100vw, 700px" data-old-src="https://www.comet.ml/site/app/ewww/lazy/placeholder-1024x550.png" data-src="https://www.comet.ml/site/app/uploads/2019/12/Screen-Shot-2020-03-27-at-9.57.24-AM-1024x550.png" data-srcset="https://www.comet.ml/site/app/uploads/2019/12/Screen-Shot-2020-03-27-at-9.57.24-AM-1024x550.png 1024w, https://www.comet.ml/site/app/uploads/2019/12/Screen-Shot-2020-03-27-at-9.57.24-AM-300x161.png 300w, https://www.comet.ml/site/app/uploads/2019/12/Screen-Shot-2020-03-27-at-9.57.24-AM-768x413.png 768w, https://www.comet.ml/site/app/uploads/2019/12/Screen-Shot-2020-03-27-at-9.57.24-AM-1536x825.png 1536w, https://www.comet.ml/site/app/uploads/2019/12/Screen-Shot-2020-03-27-at-9.57.24-AM.png 1694w"><figcaption id="caption-attachment-2552">Software Engineering vs. Machine Learning Lifecycle</figcaption></figure>
</figure>

<p>We see a lot of data science teams using workflow processes that are identical or broadly similar to these software methodologies. Unfortunately, they don’t work very well. The reason? The provable correctness of software engineering does not extend to AI and machine learning. In (supervised) machine learning, the only guarantee we have about a model we’ve built is that if the training set is an <a href="https://en.wikipedia.org/wiki/Independent_and_identically_distributed_random_variables">iid</a> (independent and identically distributed) sample from some distribution, then performance on another iid sample from the same distribution will be <em>close</em> to the performance on the training set. Because uncertainty is an intrinsic property of machine learning, sub-tasking can lead to unforeseeable downstream effects.&nbsp;</p>

<h2><strong>Why is uncertainty intrinsic to machine learning?</strong>&nbsp;</h2>

<p>Part of the answer lies in the fact that the problems that are both (a) interesting to us and (b) amenable to machine learning solutions (self-driving cars, object recognition, labeling images, and generative language models, to name a few) do not have a clear reproducible mathematical or programmatic specification. In place of specifications, machine learning systems feed in lots of data in order to detect patterns and generate predictions. Put another way, the <em>purpose of machine learning is to create a statistical proxy that can serve as a specification for one of these tasks</em>. We hope our collected data is a representative subsample of the real-world distribution, but in practice we cannot know exactly how well this condition is met. Finally, the algorithms and model architectures we use are complex, sufficiently complex that we cannot always break them apart into sub-models to understand precisely what is happening.&nbsp;</p>

<p>From this description, obstacles to the <em>knowability</em> of machine learning systems should be somewhat obvious. Inherent to the types of problems amenable to machine learning is a lack of a clear mathematical specification. The statistical proxy we use in the absence of a specification is accumulating lots of environmental data we <em>hope</em> is iid and representative. And the models we use to extract patterns from this collected data are sufficiently complex that we cannot reliably break them apart and understand precisely how they work. My colleague at Comet, Dhruv Nair, has written a three-part series on uncertainty in machine learning (here’s a link to <a href="https://www.comet.ml/blog/?p=662">Part I</a>) if you’d like to dig deeper into this topic.&nbsp;</p>

<p>Consider, then, the implications for something like the Agile methodology used on a machine learning project. We cannot possibly hope to break machine learning tasks into <em>sub-tasks</em>, tackled as part of some larger sprint and then pieced together like legos into a whole product, platform, or feature, because we cannot reliably predict how the sub-models, or the model itself, will function.&nbsp;</p>

<figure>
<figure id="attachment_2553" aria-describedby="caption-attachment-2553"><img src="https://www.comet.ml/site/app/uploads/2019/12/Screen-Shot-2020-03-27-at-9.58.40-AM-1024x738.png" alt="" width="700" height="504" srcset="https://www.comet.ml/site/app/uploads/2019/12/Screen-Shot-2020-03-27-at-9.58.40-AM-1024x738.png 1024w, https://www.comet.ml/site/app/uploads/2019/12/Screen-Shot-2020-03-27-at-9.58.40-AM-300x216.png 300w, https://www.comet.ml/site/app/uploads/2019/12/Screen-Shot-2020-03-27-at-9.58.40-AM-768x553.png 768w, https://www.comet.ml/site/app/uploads/2019/12/Screen-Shot-2020-03-27-at-9.58.40-AM.png 1252w" sizes="(max-width: 700px) 100vw, 700px" data-old-src="https://www.comet.ml/site/app/ewww/lazy/placeholder-1024x738.png" data-src="https://www.comet.ml/site/app/uploads/2019/12/Screen-Shot-2020-03-27-at-9.58.40-AM-1024x738.png" data-srcset="https://www.comet.ml/site/app/uploads/2019/12/Screen-Shot-2020-03-27-at-9.58.40-AM-1024x738.png 1024w, https://www.comet.ml/site/app/uploads/2019/12/Screen-Shot-2020-03-27-at-9.58.40-AM-300x216.png 300w, https://www.comet.ml/site/app/uploads/2019/12/Screen-Shot-2020-03-27-at-9.58.40-AM-768x553.png 768w, https://www.comet.ml/site/app/uploads/2019/12/Screen-Shot-2020-03-27-at-9.58.40-AM.png 1252w"><figcaption id="caption-attachment-2553">Source: Youtube</figcaption></figure>
<figcaption></figcaption>
</figure>

<p>Ng discussed this topic at re:MARS as well. He revealed how his team adopted a workflow system designed specifically for ML: <strong>1 day sprints</strong>, structured as follows:</p>

<ol>
<li>Build models and write code each day</li>
<li>Set up training and run experiments overnight</li>
<li>Analyze results in the morning and…</li>
<li>Repeat</li>
</ol>

<p>Ng’s 1 day sprints methodology reflects something crucial to understanding and designing teams that practice machine learning: it is an inherently <strong>experimental science</strong>. Because the systems being built lack a clear specification, because data collection is an imperfect science, and because machine learning models are incredibly complex, <em>experimentation is necessary</em>. Rather than structuring team processes around a multi-week sprint, it is usually more fruitful to test out many different architectures, feature engineering choices, and optimization methods rapidly until a rough image of what is working and what isn’t starts to emerge. 1 day sprints allow teams to move quickly, test many hypotheses in a short amount of time, and begin building intuition and knowledge around a modeling task.&nbsp;</p>

<h2><strong>Tools for ML: Experiment Management&nbsp;</strong></h2>

<p>Let’s say you adopt Andrew Ng’s 1 day sprints methodology or something similar (<em>and you should</em>). You’re setting new hyperparameters, tweaking your feature selections, and running experiments each night. What tool are you using to keep track of these decisions for each model training? How are you comparing experiments to see how different configurations are working? How are you sharing experiments with co-workers? Can your manager or co-worker reliably reproduce an experiment you ran yesterday?</p>

<p>In addition to processes, the tools you use to do machine learning matter as well. At Comet, our mission is to help companies extract business value from machine learning by providing a tool that does this for you. Most of the data science teams we speak to are stuck using a combination of git, emails, and (believe it or not) spreadsheets to record all of the artifacts around each experiment.&nbsp;</p>
<figure id="attachment_1994" aria-describedby="caption-attachment-1994"><img src="https://www.comet.ml/site/app/uploads/2020/01/Screen-Shot-2020-01-30-at-11.45.53-AM-1024x459.jpg" alt="" width="700" height="314" srcset="https://www.comet.ml/site/app/uploads/2020/01/Screen-Shot-2020-01-30-at-11.45.53-AM-1024x459.jpg 1024w, https://www.comet.ml/site/app/uploads/2020/01/Screen-Shot-2020-01-30-at-11.45.53-AM-300x134.jpg 300w, https://www.comet.ml/site/app/uploads/2020/01/Screen-Shot-2020-01-30-at-11.45.53-AM-768x344.jpg 768w, https://www.comet.ml/site/app/uploads/2020/01/Screen-Shot-2020-01-30-at-11.45.53-AM.jpg 1794w" sizes="(max-width: 700px) 100vw, 700px" data-old-src="https://www.comet.ml/site/app/ewww/lazy/placeholder-1024x459.png" data-src="https://www.comet.ml/site/app/uploads/2020/01/Screen-Shot-2020-01-30-at-11.45.53-AM-1024x459.jpg" data-srcset="https://www.comet.ml/site/app/uploads/2020/01/Screen-Shot-2020-01-30-at-11.45.53-AM-1024x459.jpg 1024w, https://www.comet.ml/site/app/uploads/2020/01/Screen-Shot-2020-01-30-at-11.45.53-AM-300x134.jpg 300w, https://www.comet.ml/site/app/uploads/2020/01/Screen-Shot-2020-01-30-at-11.45.53-AM-768x344.jpg 768w, https://www.comet.ml/site/app/uploads/2020/01/Screen-Shot-2020-01-30-at-11.45.53-AM.jpg 1794w"><figcaption id="caption-attachment-1994">Comet: Hyperparameter space visualization for 20+ experiments.</figcaption></figure>
<p>

Consider a modeling task where you’re keeping track of 20 hyperparameters, 10 metrics, dozens of architectures and feature engineering techniques, all while iterating quickly and running dozens of models a day. It can become incredibly tedious to manually track all of these artifacts. Building a good ML model can oftentimes resemble tuning a radio with 50 knobs. If you don’t keep track of all of the configurations you’ve tried, the combinatorial complexity of finding the signal in your modeling space can become cumbersome.</p>
<figure id="attachment_2554" aria-describedby="caption-attachment-2554"><img src="https://www.comet.ml/site/app/uploads/2019/12/Screen-Shot-2020-03-27-at-10.01.14-AM-1024x544.png" alt="comet exp UI" width="700" height="372" srcset="https://www.comet.ml/site/app/uploads/2019/12/Screen-Shot-2020-03-27-at-10.01.14-AM-1024x544.png 1024w, https://www.comet.ml/site/app/uploads/2019/12/Screen-Shot-2020-03-27-at-10.01.14-AM-300x160.png 300w, https://www.comet.ml/site/app/uploads/2019/12/Screen-Shot-2020-03-27-at-10.01.14-AM-768x408.png 768w, https://www.comet.ml/site/app/uploads/2019/12/Screen-Shot-2020-03-27-at-10.01.14-AM-1536x817.png 1536w, https://www.comet.ml/site/app/uploads/2019/12/Screen-Shot-2020-03-27-at-10.01.14-AM.png 1862w" sizes="(max-width: 700px) 100vw, 700px" data-old-src="https://www.comet.ml/site/app/ewww/lazy/placeholder-1024x544.png" data-src="https://www.comet.ml/site/app/uploads/2019/12/Screen-Shot-2020-03-27-at-10.01.14-AM-1024x544.png" data-srcset="https://www.comet.ml/site/app/uploads/2019/12/Screen-Shot-2020-03-27-at-10.01.14-AM-1024x544.png 1024w, https://www.comet.ml/site/app/uploads/2019/12/Screen-Shot-2020-03-27-at-10.01.14-AM-300x160.png 300w, https://www.comet.ml/site/app/uploads/2019/12/Screen-Shot-2020-03-27-at-10.01.14-AM-768x408.png 768w, https://www.comet.ml/site/app/uploads/2019/12/Screen-Shot-2020-03-27-at-10.01.14-AM-1536x817.png 1536w, https://www.comet.ml/site/app/uploads/2019/12/Screen-Shot-2020-03-27-at-10.01.14-AM.png 1862w"><figcaption id="caption-attachment-2554">Comet: Single experiment live metric tracking and dashboard</figcaption></figure>
<p><span>We’ve built Comet based on these needs (and what we wanted when we were working on data science and machine learning ourselves, at Google, IBM, and as part of research groups at Columbia University and Yale University). Every time you train a model, there should be </span><em>something</em><span> to capture all of the artifacts of your experiment and save them in some central ledger where you can look up, compare, and filter through all of your (or your team’s) work. Comet was built to provide this function to practitioners of machine learning.&nbsp;</span></p>

<p>Measuring workflow efficiency is a <a href="https://gravityflow.io/articles/measure-workflow-automations-roi/">notoriously difficult</a> thing to do, but on average our users report&nbsp;<em>20-30% time savings by using Comet</em> (note: Comet is free for individuals and researchers – <a href="https://www.comet.ml/pricing?opensignup=true&amp;utm_source=Software%20Eng%20vs%20ML&amp;utm_medium=Blog&amp;utm_campaign=Software%20Eng%20vs%20ML%20Blog%20Post">you can sign-up here</a>). This doesn’t take into account unique insights and knowledge that arise from having access to a visual understanding of your hyperparameter space, real-time metric tracking, team-wide collaboration and experiment comparison. Access to this knowledge enables time savings as well as, and perhaps more importantly, the ability to <em>build better models</em>.</p>

<h2><strong>Looking Ahead</strong></h2>

<p>It is tempting to ignore questions about ML tools and processes altogether. In a field responsible for self-driving cars, voice assistants, facial recognition, and many more groundbreaking technologies, one may be forgiven for leaping into the fray of building these tools themselves and not considering how best to build them.&nbsp;</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.comet.ml/site/why-software-engineering-processes-and-tools-dont-work-for-machine-learning/">https://www.comet.ml/site/why-software-engineering-processes-and-tools-dont-work-for-machine-learning/</a></em></p>]]>
            </description>
            <link>https://www.comet.ml/site/why-software-engineering-processes-and-tools-dont-work-for-machine-learning/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24781490</guid>
            <pubDate>Wed, 14 Oct 2020 20:55:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Efficient Evenly Distributed Sampling of Time Series Records in PostgreSQL]]>
            </title>
            <description>
<![CDATA[
Score 22 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24781057">thread link</a>) | @mooreds
<br/>
October 14, 2020 | https://blog.joshsoftware.com/2020/10/14/efficient-evenly-distributed-sampling-of-time-series-records-in-postgresql/ | <a href="https://web.archive.org/web/*/https://blog.joshsoftware.com/2020/10/14/efficient-evenly-distributed-sampling-of-time-series-records-in-postgresql/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-6304">
	
	
	<div>
		
<h2>The Problem</h2>



<p>I have been working on an application that, at it’s heart, stores a large amount of data that is organized primarily through the use of a foreign key and a timestamp field. The table’s own primary key is UUID based, combining the foreign key with a UUID for the individual record itself, and it has a single primary data field that utilizes a JSONB type since it can receive arbitrary data. The table sees frequent, regular inserts, and periodic deletions, with old data being thinned out over time, but for each foreign key, there may be tens of thousands of records distributed amongst hundreds of thousands, or millions of other records for other foreign keys.</p>



<figure><table><thead><tr><th>Column</th><th data-align="center">Type</th></tr></thead><tbody><tr><td>id</td><td data-align="center">uuid</td></tr><tr><td>server_id</td><td data-align="center">uuid</td></tr><tr><td>data</td><td data-align="center">jsonb</td></tr><tr><td>created_at</td><td data-align="center">timestamp(6) without time zone</td></tr></tbody></table><figcaption>Basic Table Schema</figcaption></figure>



<p>This was all very simple, but when the time came to start writing the code that generates data graphs from this table, I encountered a puzzle.</p>



<p>How does one ensure that the API doesn’t return too much data? Too many data points just means sending more data than the user probably needs, and it results in the graphing tool having to work with more data than it wants for quick, responsive performance, as well.</p>



<p>And how does one, efficiently, find that data without running a query take takes a burdensome amount of time? In our case, the data is being returned to a React based front end by an API, and snappy application performance hinges on snappy API performance.</p>



<h2>THe first solution</h2>



<p>Early in the history of the application, I arrived at a solution. If I had a maximum cap on the number of data points to query, such as 500, I could query the total count of records which matched my query, and then a little integer division would give me an interval to use when querying.</p>



<p>Counting the data points is simple. It looks something like this:</p>


<pre title="">sql = &lt;&lt;-ESQL
SELECT
  COUNT(*)
FROM
  telemetries
WHERE
  server_id = $1
  AND created_at BETWEEN $2 AND $3
  AND data ? 'load_avg'
ESQL

count = 0_64
DBH.using_connection do |conn|
  count = conn.query_one(sql, uuid, start_date, end_date, as: {Int64})
end
</pre>


<p>Once the count of records is determined, an interval can be calculated which will be used to query the sample of records.</p>



<p>i.e. if there are 5000 data points, and I want to sample 500 of them, then I need to query every 10th record. It looks something like this to find that interval:</p>


<pre title="">row_modulo = count // limit
row_modulo = 1 if row_modulo == 0
</pre>


<p>Once one has an interval, there is a technique that can be used with Postgresql to select records on that interval. The <code><a rel="noreferrer noopener" href="https://www.postgresql.org/docs/12/functions-window.html" target="_blank">row_number()</a></code> is a <a rel="noreferrer noopener" href="https://www.postgresql.org/docs/12/tutorial-window.html" target="_blank">window function</a> that assigns a sequential number to each row in a result set. Once each record has a monotonically increasing sequential number assigned to it, that number can be used in a <code>WHERE</code> clause.</p>


<pre title="">SELECT
  stuff,
  ROW_NUMBER()
    OVER (ORDER BY created_at ASC)
    AS row
FROM
  mytable
WHERE
  row % 10 = 0
</pre>


<p>This example would <code>select</code>, for every 10th record from <code>mytable</code>, the <code>stuff</code> field. </p>



<p>In the context of full, working code, assembling that query looked like this:</p>


<pre title="">sql = &lt;&lt;-ESQL
SELECT
  t.*
FROM (
  SELECT
    data,
    created_at,
    row_number()
      OVER (ORDER BY created_at ASC)
      AS row
  FROM
    telemetries
  WHERE
    server_id = $1
    AND created_at BETWEEN $2 AND $3
    AND data ? 'load_avg'
) 
AS t
WHERE
  t.row %#{row_modulo} = 0
ESQL
</pre>


<p>This worked! It’s a viable general technique when you want to select every nth record from some result set, and you want to make the database do the work instead of your application. It’s also almost always faster and less resource intensive to do data management like this inside the database than it is to pull all of the data into your application and make it responsible for sorting through the data and pruning unneeded rows.</p>



<h2>A Wrinkle: Counting Isn’t Cheap!</h2>



<p>There are a couple of performance problems with this approach that become apparent when the table starts significantly growing.</p>



<p>First, pulling a <code>count</code> is not cheap. MySQL maintains a global record count for tables as part of it’s MyISAM data format. PostgreSQL, however, uses something called a multi-version concurrency control strategy with its tables, which essentially means that different views of a database may see different sets of rows. Thus there is no one single, simple count of records for it to fall back on. Thus, when you count records in a table in PostgreSQL, the database is required to actually walk through the data and count all of the visible records.</p>



<p>This is a relatively intense, and thus slow process.</p>



<p>If you simply want an estimate of the number of total rows in a  table, there is a way to get that very cheaply:</p>


<pre title="">SELECT
  reltuples::bigint
    AS estimated_count
FROM
  pg_class
WHERE
  relname = 'mytable'
</pre>


<div><p>This doesn’t work when you want to count only a subset of records, though, and this value is only an estimate. It is the estimate that the query planner uses, so it should generally always be within about 10% of the real value, but it is unlikely to ever match exactly unless the table size changes only rarely.</p><p>There are other counting strategies, but they all have tradeoffs or inherent inaccuracies, so for this use case, there is no getting around paying that up-front time and resource cost just to get a count of records to use when calculating the query interval that is needed.</p></div>



<p>The second expensive part of this technique is the use of <code>row_number()</code> in combination with a modulo (%) in the <code>WHERE</code> clause. This means that the database must traverse every possible record when running the query in order to figure out which ones satisfy the <code>WHERE</code> clause. So if there are 150000 records, but one only wants 500 of them, all 150000 will still be scanned.</p>



<p>These factors combine to make this approach brutally, unusably slow for queries that are intended to be ran ad hoc, and quickly, as part of an API driving a UI.</p>


<pre title="">                                                                      QUERY PLAN                                                                      
------------------------------------------------------------------------------------------------------------------------------------------------------
 Subquery Scan on t  (cost=105.19..2583.85 rows=1 width=387) (actual time=418.318..26002.490 rows=545 loops=1)
   Filter: ((t."row" % '49'::bigint) = 0)
   Rows Removed by Filter: 26198
   -&gt;  WindowAgg  (cost=105.19..2582.55 rows=87 width=387) (actual time=210.259..25995.686 rows=26743 loops=1)
         -&gt;  Bitmap Heap Scan on telemetries  (cost=105.19..2581.46 rows=87 width=379) (actual time=210.248..25959.166 rows=26743 loops=1)
               Recheck Cond: (data ? 'load_avg'::text)
               Filter: (server_id = 'a0dcc312-0623-af60-4dc0-238301cc9bf8'::uuid)
               Rows Removed by Filter: 178886
               Heap Blocks: exact=39489
               -&gt;  Bitmap Index Scan on telemetries_data_idx  (cost=0.00..105.17 rows=689 width=0) (actual time=101.188..101.188 rows=205629 loops=1)
                     Index Cond: (data ? 'load_avg'::text)
 Planning Time: 1.860 ms
 Execution Time: 26006.389 ms

</pre>


<p>This is a real example of a query on a real database using the prior technique, and this example had the advantage that the index that it uses (a <code>BTREE</code> index across the data field, since in production we are limiting results to fields that have one specific type of data) was already warm and cached in the database’s working set when I ran this example, so this result was a best case for this technique, on this database. If that index were not available, or were not used, it would have been even slower given that this index filter rejected almost 180,000 rows. That’s too slow to be triggered directly via an API request, as the user will be waiting a half-minute for data to even begin to show up in their browser.</p>



<h2>There has to be a better way</h2>



<p>It turns out that Postgresql offers a high performance option to sample a random set of data in a table. There is a <code><a href="https://www.postgresql.org/docs/9.6/sql-select.html#SQL-FROM" target="_blank" rel="noreferrer noopener">TABLESAMPLE</a></code> clause that can be placed in the <code>FROM</code> section of a query that will sample a subset of a table.</p>


<pre title="">SELECT
  data
FROM
  mytable
  TABLESAMPLE SYSTEM(5)
</pre>


<p>This would return a roughly random set of about 5% of <code>mytable</code>‘s rows. If one wants a specific number of rows, there is an extension that can provide that, <code><a rel="noreferrer noopener" href="https://www.postgresql.org/docs/9.6/tsm-system-rows.html" target="_blank">tsm_system_rows</a></code>.</p>


<pre title="">SELECT
  data
FROM
  mytable
  TABLESAMPLE SYSTEM_ROWS(500)
</pre>


<p>This would return a random-ish set of 500 rows from the table. A <code>WHERE</code> clause can be used in a query that uses <code>TABLESAMPLE</code> in order to select only the rows of interest, but the <code>TABLESAMPLE</code> is applied before the <code>WHERE</code> clause, which makes this method unsuitable for my use case. As an example:</p>


<pre title="">SELECT
  data,
  created_at
FROM
  telemetries
  TABLESAMPLE SYSTEM_ROWS(500)
WHERE
  server_id = $1
</pre>


<p>This would first select 500 random rows from the entire data set, and would then try to find records from that set which matched the <code>WHERE</code> clause. This would probably result in the query only returning a very small, and fairly unpredictable number of rows of data that is actually wanted. Also, because the records are random, there is no guarantee that they are evenly distributed through the data set. This might be fine if the data is being queried for statistical reasons, but it isn’t ideal when pulling data for graphs.</p>



<p>So while TABLESAMPLE can be a very fast way to select a random set of records over an entire table, it doesn’t work when we want a set of rows that is evenly distributed through the data set, but is only for a segment of the table’s total data, and for which we want to have some predictable control over the number of rows selected.</p>



<h2>Other Meanderings</h2>



<p>There are other solutions available when the problem to be solved is the random selection of table rows, but none of them are particularly useful for the selection of N or close-to N evenly distributed data points, and there is limited inspiration that can be found from them.</p>



<p>A…</p></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.joshsoftware.com/2020/10/14/efficient-evenly-distributed-sampling-of-time-series-records-in-postgresql/">https://blog.joshsoftware.com/2020/10/14/efficient-evenly-distributed-sampling-of-time-series-records-in-postgresql/</a></em></p>]]>
            </description>
            <link>https://blog.joshsoftware.com/2020/10/14/efficient-evenly-distributed-sampling-of-time-series-records-in-postgresql/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24781057</guid>
            <pubDate>Wed, 14 Oct 2020 20:17:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Visualize Starlink's current coverage with active TLEs]]>
            </title>
            <description>
<![CDATA[
Score 39 | Comments 1 (<a href="https://news.ycombinator.com/item?id=24780065">thread link</a>) | @blach
<br/>
October 14, 2020 | http://orbitalindex.com/feature/starlink-coverage/ | <a href="https://web.archive.org/web/*/http://orbitalindex.com/feature/starlink-coverage/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="_main" role="main" data-color="#4fb1ba" data-theme-color="black" data-image="/assets/img/sidebar-bg.jpg" data-overlay=""><article class="page" role="article"><header></header>   <div id="starlink-coverage"> <canvas id="globe"></canvas><div><p>Degrees From Horizon For Connectivity <span onclick="display_help()">?</span> <span onclick="hide_help()">✕</span></p><p>25°</p><div><p>Degrees From Horizon is the amount you have to tilt your head to look at the satellite when standing in a flat field.</p><p>We believe the initial constellation will have connectivity if the satellite is 25° above the receiver's horizon, and that this requirement will later be eased to 40° to increase performance as satellite density increases. Note: This angle defines the maximum height above the horizon in all directions that can be occluded by any terrain, trees, or other structures.</p></div></div></div>  </article></div></div>]]>
            </description>
            <link>http://orbitalindex.com/feature/starlink-coverage/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24780065</guid>
            <pubDate>Wed, 14 Oct 2020 18:43:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Crafting Functions]]>
            </title>
            <description>
<![CDATA[
Score 56 | Comments 15 (<a href="https://news.ycombinator.com/item?id=24779624">thread link</a>) | @tosh
<br/>
October 14, 2020 | https://stopa.io/post/251 | <a href="https://web.archive.org/web/*/https://stopa.io/post/251">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p><span><p>We write so many functions in our programs that they become second nature before we know it. Like ants in a colony, they are numerous beyond imagination and they come together to form some surprisingly complex systems.</p><p>It begs the question: how do we write good functions? It can seem trivial: they’re just like ants after-all. But there is leverage in the answer: the right decisions multiply throughout your codebase and bubble up into great design.</p><p>I think there are about three key ideas you can employ to craft good functions. I wanted to share them with you.</p><p>Let’s start with an example. We have an app, and we want to export some data in a JSON format. Here’s what a function for that could look like:</p><pre><code><span>function</span><span> </span><span>exportFile</span><span>() { </span>
<span>  </span><span>setLoading</span><span>(</span><span>true</span><span>);</span>
<span>  </span><span>try</span><span> {</span>
<span>    </span><span>const</span><span> </span><span>data</span><span> </span><span>=</span><span> </span><span>getData</span><span>(); </span><span>// [Data, Data, Data]</span>
<span>    </span><span>const</span><span> </span><span>exportableData</span><span> </span><span>=</span><span> </span><span>toExportableData</span><span>(</span><span>data</span><span>); </span><span>// ExportableData</span>
<span>    </span><span>const</span><span> </span><span>jsonStr</span><span> </span><span>=</span><span> </span><span>JSON</span><span>.stringify</span><span>(</span><span>exportableData</span><span>); </span><span>// '{"data": {...</span>
<span>    </span><span>const</span><span> </span><span>fileURL</span><span> </span><span>=</span><span> </span><span>saveFile</span><span>(</span><span>"export.json"</span><span>, </span><span>jsonStr</span><span>); </span><span>// https://foo.com/export.json</span>
<span>    </span><span>setFileURL</span><span>(</span><span>fileURL</span><span>);</span>
<span>  } </span><span>finally</span><span> {</span>
<span>    </span><span>setLoading</span><span>(</span><span>false</span><span>)</span>
<span>  }</span>
<span>}</span></code></pre><p>Seems straight forward: To export as JSON, we first get our data. Now, this data may have some sensitive info, so we clean that up and transform into something exportable; ExportableData. Once we have that, we get a string representation, save the file, and badabing, badaboom, we’re done. </p><p>Okay, we’ve got something working well.</p><p>But life moves on and our program needs to evolve. Instead of just exporting JSON, we need to do more: <strong>we also need to export a CSV file</strong>. </p><p>How do we do that?</p><p>The first thing we notice, is that exporting a CSV is very similar to exporting JSON. Can we abstract <code>exportFile</code>?</p><p>One thing we can do, is to introduce a new flag: something like <code>exportFile(/*isCSV=*/ true)</code> </p><pre><code><span>function</span><span> </span><span>exportFile</span><span>(</span><span>isCSV</span><span>) { </span>
<span>  </span><span>...</span>
<span>  </span><span>let</span><span> </span><span>fileURL</span>
<span>  </span><span>if</span><span> (</span><span>isCSV</span><span>) { </span>
<span>    </span><span>const</span><span> </span><span>csvStr</span><span> </span><span>=</span><span> </span><span>toCSVStr</span><span>(</span><span>exportableData</span><span>)</span>
<span>    </span><span>fileURL</span><span> </span><span>=</span><span> </span><span>saveFile</span><span>(</span><span>"export.csv"</span><span>, </span><span>csvStr</span><span>);</span>
<span>  } </span><span>else</span><span> { </span>
<span>    </span><span>const</span><span> </span><span>jsonStr</span><span> </span><span>=</span><span> </span><span>JSON</span><span>.stringify</span><span>(</span><span>exportableData</span><span>);</span>
<span>    </span><span>fileURL</span><span> </span><span>=</span><span> </span><span>saveFile</span><span>(</span><span>"export.json"</span><span>, </span><span>jsonStr</span><span>);</span>
<span>  }</span>
<span>  </span><span>...</span></code></pre><p>By introducing this flag, we can conditionally produce a different <code>fileURL</code>: one for CSV and one for JSON. With that we see the first concept for abstraction: configuration. You pass some configuration, and you leave it to your function to figure what to do. </p><p>So, is it a good idea? </p><h2 id="the-key-advantage-is-that-our-logic-is-centralized">The key <em>advantage</em> is that our logic is centralized.</h2><p>With configuration, the caller is limited in what they can do: they can only provide flags. All the true logic stays inside <code>exportFile</code>. This means that callers of the function can’t go crazy and do something unsupported. And that could give us some peace of mind.</p><h2 id="the-key-disadvantage-is-thatour-logic-is-centralized">The key <em>disadvantage</em> is that…our logic is centralized.</h2><p>This will work, but let’s think about it. First, notice that in order to understand <code>exportFile</code> now, we need to understand both the CSV and JSON case. Imagine if someone opens up <code>exportFile</code> to figure out what it does:  if they <em>only</em> cared about JSON, they now have to understand more logic than they needed. Anyone who changes the logic for CSV, may also end up breaking JSON. <strong><code>exportFile</code></strong> <strong>has become</strong> <a href="https://www.infoq.com/presentations/Simple-Made-Easy/" target="_blank"><strong>complected</strong></a><strong>.</strong></p><p>Notice also, that because the caller of this function can <em>only</em> provide flags, their hands are tied for use-cases that you didn’t support. This was supposed to give you peace of mind, but it certainly can frustrate callers. imagine if they wanted to support XML, what could they do? They’d have to edit <code>exportFile</code> to support this case. (God forbid they edit it to be something like <code>exportFile(isCSV, isXML)</code> — now you have invariant conditions on your hands). By being so specific, you’ve chosen to make your function less abstract — this of course means that it is less powerful.  <strong><code>exportFile</code></strong> <strong>has become hard to extend</strong></p><h2 id="for-better-or-worse-configuration-gives-the-caller-the-least-amount-of-power">For better or worse, configuration gives the caller the least amount of power</h2><p>If you imagine a sort power spectrum, where the caller has the least power on the left, and most power on the right, configuration would be on the left. You control what the caller does so tightly that it gives your certainty, but makes your function more complex and less useful. </p><p>Say you wanted to address the problems, and move to the right of this spectrum, what could you do? </p><p>Well, if you look at what we wrote, we can notice that the only part that is <em>really</em> different, is the bit about taking <code>exportData</code>, and creating a <code>fileURL</code>. </p><pre><code><span>...</span>
<span>const</span><span> </span><span>exportableData</span><span> </span><span>=</span><span> </span><span>toExportableData</span><span>(</span><span>data</span><span>); </span><span>// ExportableData</span>
<span>...</span><span> </span><span>// *This can be different! Somehow we need to get a fileURL* </span>
<span>setFileURL</span><span>(</span><span>fileURL</span><span>);</span>
<span>...</span></code></pre><p>So one thing we can do is this: instead of providing a flag, we can provide a function: </p><pre><code><span>function</span><span> </span><span>exportFile</span><span>(</span><span>exportableDataToFileURL</span><span>) { </span>
<span>  </span><span>setLoading</span><span>(</span><span>true</span><span>);</span>
<span>  </span><span>try</span><span> {</span>
<span>    </span><span>const</span><span> </span><span>data</span><span> </span><span>=</span><span> </span><span>getData</span><span>(); </span><span>// [Data, Data, Data]</span>
<span>    </span><span>const</span><span> </span><span>exportableData</span><span> </span><span>=</span><span> </span><span>toExportableData</span><span>(</span><span>data</span><span>); </span><span>// ExportableData</span>
<span>    </span><span>const</span><span> </span><span>fileURL</span><span> </span><span>=</span><span> </span><span>exportableDataToFileURL</span><span>(</span><span>exportableData</span><span>)</span>
<span>    </span><span>setFileURL</span><span>(</span><span>fileURL</span><span>);</span>
<span>  } </span><span>finally</span><span> {</span>
<span>    </span><span>setLoading</span><span>(</span><span>false</span><span>)</span>
<span>  }</span>
<span>}</span></code></pre><p>Now, for JSON, we can write </p><pre><code><span>exportFile</span><span>((</span><span>exportableData</span><span>) </span><span>=&gt;</span><span> { </span>
<span>  </span><span>return</span><span> </span><span>saveFile</span><span>(</span><span>"export.json"</span><span>, </span><span>JSON</span><span>.stringify</span><span>(</span><span>exportableData</span><span>));</span>
<span>})</span></code></pre><p>and for CSV we can write: </p><pre><code><span>exportFile</span><span>((</span><span>exportableData</span><span>) </span><span>=&gt;</span><span> { </span>
<span>  </span><span>return</span><span> </span><span>saveFile</span><span>(</span><span>"export.csv"</span><span>, </span><span>toCSVStr</span><span>(</span><span>exportableData</span><span>));</span>
<span>})</span></code></pre><p>Oky doke, this is cool. </p><h2 id="the-key-advantage-is-that-you-give-the-caller-more-power">The key <em>advantage</em> is that you give the caller more power</h2><p>With this we solve both of the problems we had with configuration. Now if someone looks under the hood at <code>exportFile</code>, they won’t see unrelated code about csv. If they wanted to extend to XML, they can simply provide a different function. We’ve given the caller much more power</p><h2 id="the-key-disadvantage-is-that-it-can-be-either-too-powerful-or-not-powerful-enough">The key <em>disadvantage</em> is that it can be either too powerful or not powerful enough</h2><p>We’ve abstracted further, but there is a price there. The first is, that we <em>think</em> we know that what we <em>really</em> need to pass outwards is <code>exportableData</code>, and what we need to return is a <code>fileURL</code>. What if we were wrong? For example, some may need a slightly different data format — instead of <code>exportableData</code> they need <code>someOtherKindOfExportableData</code>. By the time we figured that out, it’s possible that there are numerous new usages of <code>exportFile</code>, which we’ll have to support as we evolve this function.</p><p>One way we could have prevented this, is to have stuck with configuration. This way, anyone who wanted to support something would have to funnel through this function, which would give us time to think about what the best abstraction was. </p><p>Another way, would have been if this function was abstracted even further, so callers could have easily supported <code>someOtherKindOfExportableData</code>.</p><h2 id="inversion-lies-in-the-middle-of-the-power-spectrum">Inversion lies in the middle of the power spectrum</h2><p>Inversion is more powerful than configuration, but it’s not the most powerful method. This can be a great choice, but you risk either being too powerful and exposing errors, or not being powerful enough and restricting callers. </p><p>We know the less powerful option: configuration. What would the most powerful one look like?</p><p>The next thing we may notice, is that our <code>exportFile</code> function is actually built up some building blocks that could be useful for a bunch of different things. For example, many functions may want a loading state, or just need to get <code>exportableData</code>, etc. We could create those building blocks:</p><pre><code><span>function</span><span> </span><span>exportJSONFile</span><span>() { </span>
<span>  </span><span>withLoading</span><span>(() </span><span>=&gt;</span><span> </span><span>saveJSONFile</span><span>(</span><span>getExportableData</span><span>()))</span>
<span>}</span>
<!-- -->
<!-- -->
<span>function</span><span> </span><span>exportCSVFile</span><span>() { </span>
<span>  </span><span>withLoading</span><span>(() </span><span>=&gt;</span><span> </span><span>saveCSVFile</span><span>(</span><span>getExportableData</span><span>()))</span>
<span>}</span></code></pre><h2 id="the-key-advantage-is-that-the-user-gets-the-most-power">The key advantage is that the user gets the most power</h2><p>The building blocks that we just built, can be used in a myriad of ways. The user can support CSV, XML, can use <code>isLoading</code> with some other function, and choose to provide a different kind of <code>exportableData</code>.  We’ve provided a lot of power for the user.</p><h2 id="the-key-disadvantage-is-that-you-are-the-most-vulnerable-to-mistakes">The key disadvantage is that you are the most vulnerable to mistakes</h2><p>The disadvantage though, like in the case of inversion, is that we open ourselves up to a lot of mistakes. What if <code>isLoading</code> was really meant for files, and other things should have been using a different flag? What if people start using <code>saveJSONFile</code>, and pass data that wasn’t really an export? These are all cases that we have implicitly allowed with our abstractions. </p><p>There’s a further problem: notice that with our first example of <code>exportFile</code>, you the code was more concrete: you could see what was actually happening. When code is more abstract, it’s a bit harder to reason about what is <em>actually</em> happening. Now, it can be worth it for the power gains, but if you optimized prematurely, you’re just paying this price for nothing. An example of this unnecessary price is <code>saveJSONFile</code> and <code>saveCSVFile</code> — if we had <a href="http://number-none.com/blow/john_carmack_on_inlined_code.html" target="_blank">inlined</a> those, the overall composition would still be abstract but more understandable. These are the kind of things to watch out for as you abstract at this level.</p><h2 id="composition-is-at-the-end-of-the-spectrum">Composition is at the end of the spectrum</h2><p>And with that, we see that composition gives us the most power, but gives us the most opportunities to shoot ourselves in the foot. Boy can it be worth it though. </p><p>It’s funny to notice that with each option, the pro <em>is</em> the con. So how do we pick? I think one heuristic you can use is this: pick the most powerful option you can limited by your confidence. For example, if you have a light understanding of the problem, stay on the lower side of the abstraction spectrum. As you understand more (say, time to introduce XML) you can evolve to the powerful side of the spectrum. When you’re <em>very</em> confident, and you can see good use-cases for your building blocks, lean to the most powerful side of the spectrum. </p><p><em>Thanks to Daniel Woelfel, Alex Reichert, Julien Odent for reviewing drafts of this essay</em></p></span></p></div></div></div>]]>
            </description>
            <link>https://stopa.io/post/251</link>
            <guid isPermaLink="false">hacker-news-small-sites-24779624</guid>
            <pubDate>Wed, 14 Oct 2020 18:08:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Read-Only Mode for Better Rails Downtime]]>
            </title>
            <description>
<![CDATA[
Score 75 | Comments 11 (<a href="https://news.ycombinator.com/item?id=24778920">thread link</a>) | @christoomey
<br/>
October 14, 2020 | https://ctoomey.com/writing/read-only-mode-for-better-rails-downtime/ | <a href="https://web.archive.org/web/*/https://ctoomey.com/writing/read-only-mode-for-better-rails-downtime/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        
  <p>Recently I was looking to upgrade the Postgres version on an application I’ve
been working on. This would require a small amount of downtime, likely about 10
minutes.</p>

<p>The default solution I’d reach for in these cases would be to go into Heroku’s
maintenance mode, which serves an HTML maintenance page with a <code>503 Service
Unavailable</code> status code. This works but makes the application entirely
unusable during the upgrade, and I was hoping to find a better solution. In this
particular case, I also wanted to be able to provide JSON responses as the
application mainly provides an API for a mobile app.</p>

<p>After <a href="https://www.bikeshed.fm/262">exploring a handful of half-baked options</a>, I settled on using a
read-only connection to the database to still allow reads but prevent any
writes from occurring. While using the read-only connection, the Postgres adapter
will raise an error any time we attempt to change data in the database, but we
can easily rescue this specific error and convert it to a user-facing notice. I
felt a bit odd using exceptions as the core of this workflow, but in the end, it
worked out really well, so I wanted to share the specifics.</p>

<p>It’s worth noting that this solution is particularly well suited to this
specific application, which only provides an API and has very read-heavy usage,
but I imagine it could be extended to work with other styles of app as well.</p>

<h2 id="configuring-rails-to-use-the-read-only-connection">Configuring Rails to Use the Read-Only Connection</h2>

<p>If present, Rails will use the connection string in a <code>DATABASE_URL</code> env var to
connect to the database. Following the <a href="https://guides.rubyonrails.org/configuring.html#connection-preference">Connection Preference</a> notes in the
Rails guides, I realized that I could make this <code>DATABASE_URL</code> usage explicit
and allow for a temporary override. To do this, I added an explicit <code>url</code>
property for the production environment with desired connection preference:</p>

<div><pre><code><span># config/database.yml</span>

<span>production</span><span>:</span>
  <span>&lt;&lt;</span><span>:</span> <span>*default</span>
  <span>url</span><span>:</span> <span>&lt;%= ENV["DATABASE_URL_READ_ONLY"] || ENV["DATABASE_URL"] %&gt;</span>
</code></pre></div>
<p>With this in place, I can enable the read-only mode simply by setting the
<code>DATABASE_URL_READ_ONLY</code> env var:</p>

<div><pre><code>heroku config:set <span>\</span>
  <span>DATABASE_URL_READ_ONLY</span><span>=</span><span>'postgres://read_only_user:abc123...'</span> <span>\</span>
  <span>--remote</span> production
</code></pre></div>
<p>Likewise, to disable the read-only mode, I can use:</p>

<div><pre><code>heroku config:unset DATABASE_URL_READ_ONLY <span>--remote</span> production
</code></pre></div>
<p><em>Note</em>: I was able to use <a href="https://devcenter.heroku.com/articles/heroku-postgresql-credentials#managing-permissions">Heroku’s Postgres Credentials</a> interface to create
the read-only user, but if you’re not working with Heroku you should be able to
use <a href="https://dba.stackexchange.com/a/160817">these instructions</a> to create your read-only user.</p>

<h2 id="error-handling">Error Handling</h2>

<p>With other approaches I considered I found that I had to close off multiple
different potential ways to issue writes to the database, but the read-only
connection worked well to cut everything off in one change. That said, it
was only half the solution, as I certainly didn’t want the errors making it to
users.</p>

<p>Thankfully it was relatively straightforward to provide a centralized <code>rescue</code>
that would allow me to handle all the errors. First, I created a module using
Rails’s <code>ActiveSupport::Concern</code> functionality:</p>

<div><pre><code><span># app/controllers/concerns/read_only_controller_support.rb</span>
<span>module</span> <span>ReadOnlyControllerSupport</span>
  <span>extend</span> <span>ActiveSupport</span><span>::</span><span>Concern</span>

  <span>included</span> <span>do</span>
    <span>if</span> <span>ENV</span><span>[</span><span>"DATABASE_URL_READ_ONLY"</span><span>].</span><span>present?</span>
      <span>rescue_from</span> <span>ActiveRecord</span><span>::</span><span>StatementInvalid</span> <span>do</span> <span>|</span><span>error</span><span>|</span>
        <span>if</span> <span>error</span><span>.</span><span>message</span><span>.</span><span>match?</span><span>(</span><span>/PG::InsufficientPrivilege/i</span><span>)</span>
          <span>render</span><span>(</span>
            <span>status: :service_unavailable</span><span>,</span>
            <span>json: </span><span>{</span>
              <span>info: </span><span>"The app is currently in read-only maintenance mode. Please try again later."</span><span>,</span>
            <span>},</span>
          <span>)</span>
        <span>else</span>
          <span>raise</span> <span>error</span>
        <span>end</span>
      <span>end</span>
    <span>end</span>
  <span>end</span>
<span>end</span>
</code></pre></div>
<p>When included, this module will use Rails’s <a href="https://api.rubyonrails.org/classes/ActiveSupport/Rescuable/ClassMethods.html#method-i-rescue_from"><code>rescue_from</code></a> method to capture
potentially relevant errors, and then we do a quick check within that block
to make sure we’re only capturing the relevant errors.</p>

<p>Note, the <code>rescue_from</code> logic is only enabled when the <code>DATABASE_URL_READ_ONLY</code>
is set, so we’re able to reuse the existence of that variable as a way to scope
this behavior.</p>

<p>I was then able to include that module in any relevant base controller:</p>

<div><pre><code><span># app/controllers/application_controller.rb</span>
<span>class</span> <span>ApplicationController</span> <span>&lt;</span> <span>ActionController</span><span>::</span><span>Base</span>
  <span>include</span> <span>ReadOnlyControllerSupport</span>
<span>end</span>

<span># app/controllers/api/base_controller.rb</span>
<span>class</span> <span>Api</span><span>::</span><span>BaseController</span> <span>&lt;</span> <span>ActionController</span><span>::</span><span>Base</span>
  <span>include</span> <span>ReadOnlyControllerSupport</span>
<span>end</span>
</code></pre></div>
<h2 id="non-api-error-handling">Non-API Error Handling</h2>

<p>My initial use case for this read-only mode only needed to support API requests,
but I could imagine extending it to HTML and form-based interfaces.</p>

<p>The first thing I would consider would be adding a sitewide banner that stated
that we were in a read-only maintenance mode to alert users to the current
status.</p>

<p>With that in place, I think we could extend the error handling in the
<code>ReadOnlyControllerSupport</code> module to redirect the user back and display a
relevant message:</p>

<div><pre><code><span>rescue_from</span> <span>ActiveRecord</span><span>::</span><span>StatementInvalid</span> <span>do</span> <span>|</span><span>error</span><span>|</span>
  <span>if</span> <span>error</span><span>.</span><span>message</span><span>.</span><span>match?</span><span>(</span><span>/PG::InsufficientPrivilege/i</span><span>)</span>
    <span>respond_to</span> <span>do</span> <span>|</span><span>format</span><span>|</span>
      <span>format</span><span>.</span><span>json</span> <span>do</span>
        <span># JSON erorr message as shown above</span>
      <span>end</span>

      <span>format</span><span>.</span><span>html</span> <span>do</span>
        <span>redirect_back</span><span>(</span>
          <span>fallback_location: </span><span>root_path</span><span>,</span>
          <span>alert: </span><span>"The app is currently in read-only maintenance mode. Please try again later."</span><span>,</span>
        <span>)</span>
      <span>end</span>
    <span>end</span>
  <span>else</span>
    <span>raise</span> <span>error</span>
  <span>end</span>
<span>end</span>
</code></pre></div>
<h2 id="scheduler-and-background-jobs">Scheduler and Background Jobs</h2>

<p>One additional consideration here would be around background jobs and scheduler
processes. For background jobs things are relatively straightforward – we just
need to scale our worker pool down to zero for the read-only period.</p>

<p>Scheduler processes are a little trickier as I didn’t have a mechanism for
globally enabling or disabling them. With that in mind, I think the ideal
solution would be to only ever have scheduler processes enqueue jobs but not
actually do any work beyond that.</p>

<h2 id="migrations">Migrations</h2>

<p>The final sticking point we ran into was migrations. We have a <code>release</code> command
defined in our <code>Procfile</code> that was configured to run <code>rake db:migrate</code>.
Unfortunately, it turns out that even if no migrations run, Rails will still
attempt to write to the <code>ar_internal_metadata</code> table as part of the <code>db:migrate</code>
command, and Heroku will run the release command any time we change an env. In
my initial attempt, Heroku failed when I attempted to set the
<code>DATABASE_URL_READ_ONLY</code> as the associated release command hit the read-only
error when running <code>rake db:migrate</code>.</p>

<p>To work around this I wrote a small script that first checks if there
are any migrations that need to be run, and only if there are, then runs <code>rake
db:migrate</code>:</p>

<div><pre><code><span>#!/bin/bash</span>

<span>set</span> <span>-e</span>

<span>if </span>bin/rails db:migrate:status | <span>grep</span> <span>'^\s\+down\s'</span><span>;</span> <span>then
  </span>bin/rails db:migrate
<span>fi</span>
</code></pre></div>
<p>This script was added to the repo as <code>bin/migrate-if-needed</code>, and then we
replaced our call to <code>rake db:migrate</code> with <code>bin/migrate-if-needed</code></p>

<h2 id="update-oct-14-2020">Update (Oct 14, 2020)</h2>

<p>After sharing this post, <a href="https://news.ycombinator.com/item?id=24780033">a commenter on Hacker News</a> pointed out <a href="https://github.com/discourse/rails_failover">the
rails_failover gem</a> that their team at Discourse maintains. It seems to offer
similar functionality, but in a more robust and fully thought out way. Looks
like a great option to implement this sort of system.</p>



    </div></div>]]>
            </description>
            <link>https://ctoomey.com/writing/read-only-mode-for-better-rails-downtime/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24778920</guid>
            <pubDate>Wed, 14 Oct 2020 17:03:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Zoom Rolling Out End-to-End Encryption Offering]]>
            </title>
            <description>
<![CDATA[
Score 232 | Comments 149 (<a href="https://news.ycombinator.com/item?id=24778490">thread link</a>) | @giuliomagnifico
<br/>
October 14, 2020 | https://blog.zoom.us/zoom-rolling-out-end-to-end-encryption-offering/ | <a href="https://web.archive.org/web/*/https://blog.zoom.us/zoom-rolling-out-end-to-end-encryption-offering/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
              
              
              <div>
                <p><a href="https://blog.zoom.us/author/mkrohn/" title="Max Krohn">
                                            <img src="https://blog.zoom.us/wp-content/uploads/2020/10/Max-Krohn-124x124.jpeg" data-src="https://blog.zoom.us/wp-content/uploads/2020/10/Max-Krohn-124x124.jpeg" alt="Max Krohn" title="Max Krohn">
                                      </a>
                </p>
                
            </div>
                          <p><img src="https://blog.zoom.us/wp-content/uploads/2020/10/Zoom-End-to-End.png" data-src="https://blog.zoom.us/wp-content/uploads/2020/10/Zoom-End-to-End.png" alt="Zoom Rolling Out End-to-End Encryption Offering">
                                      </p>
                <!--?xml encoding="UTF-8" ?--><p>We’re excited to announce that starting next week, Zoom’s end-to-end encryption (E2EE) offering will be available as a technical preview, which means we’re proactively soliciting feedback from users for the first 30 days. Zoom users – free and paid – around the world can host up to 200 participants in an E2EE meeting on Zoom, providing increased privacy and security for your Zoom sessions.</p>



<p>We <a href="https://blog.zoom.us/zoom-acquires-keybase-and-announces-goal-of-developing-the-most-broadly-used-enterprise-end-to-end-encryption-offering/" target="_blank" rel="noreferrer noopener">announced in May</a> our plans to build an end-to-end-encrypted meeting option into our platform, on top of Zoom’s already strong encryption and advanced security features. We’re pleased to roll out Phase 1 of 4 of our E2EE offering, which provides robust protections to help prevent the interception of decryption keys that could be used to monitor meeting content.</p>



<h2>About E2EE</h2>



<p>To be clear, Zoom’s E2EE uses the same powerful GCM encryption you get now in a Zoom meeting. The only difference is where those encryption keys live.</p>



<p>In typical meetings, Zoom’s cloud generates encryption keys and distributes them to meeting participants using Zoom apps as they join. With Zoom’s E2EE, the meeting’s host generates encryption keys and uses public key cryptography to distribute these keys to the other meeting participants. Zoom’s servers become oblivious relays and never see the encryption keys required to decrypt the meeting contents.&nbsp;&nbsp;</p>



<p>“End-to-end encryption is another stride toward making Zoom the most secure communications platform in the world,” said Zoom CEO Eric S. Yuan. “This phase of our E2EE offering provides the same security as existing end-to-end-encrypted messaging platforms, but with the video quality and scale that has made Zoom the communications solution of choice for hundreds of millions of people and the world’s largest enterprises.”</p>



<p>Zoom’s E2EE will be available as a technical preview next week. To use it, customers must enable E2EE meetings at the account level and opt-in to E2EE on a per-meeting basis.</p>



<figure><img alt="" data-src="https://lh6.googleusercontent.com/t2TiiQUVghal7h8dVHrvTZL-14BVFCJELb7TtGg81kjh3EDA62hSNF-_vDucMMyjmLeyYhgGTQwBd214jVKbj4gfjq9o3wwshEo35R9XiijNxcbwl-I6kZzcrcshTDQ4XSo4UcDs"></figure><h2>FAQs</h2>



<p><strong>How does Zoom provide end-to-end encryption?</strong></p>



<p>Zoom’s E2EE offering uses public key cryptography. In short, the keys for each Zoom meeting are generated by participants’ machines, not by Zoom’s servers. Encrypted data relayed through Zoom’s servers is indecipherable by Zoom, since Zoom’s servers do not have the necessary decryption key. This key management strategy is similar to that used by most end-to-end encrypted messaging platforms today.</p>



<p><strong>How do I turn on E2EE?</strong></p>



<p>Hosts can enable the setting for E2EE at the account, group, and user level and can be locked at the account or group level. All participants must have the setting enabled to join an E2EE meeting. In Phase 1, all meeting participants must join from the Zoom desktop client, mobile app, or Zoom Rooms.</p>



<p><strong>When would I use E2EE?</strong></p>



<p>E2EE is best for when you want enhanced privacy and data protection for your meetings, and is an extra layer to mitigate risk and protect sensitive meeting content. While E2EE provides added security, some Zoom functionality is limited in this first E2EE version (more on that below). Individual Zoom users should determine whether they need these features before enabling this version of E2EE in their meetings.</p>



<p><strong>Do I have access to all the features of a regular Zoom meeting?</strong></p>



<p>Not right now. Enabling this version of Zoom’s E2EE in your meetings disables certain features, including join before host, cloud recording, streaming, live transcription, Breakout Rooms, polling, 1:1 private chat, and meeting reactions.</p>



<p><strong>Do free Zoom users have access to end-to-end encryption?</strong></p>



<p>Yes. Free and paid Zoom accounts joining from Zoom’s desktop client or mobile app, or from a Zoom Room, can host or join an E2EE meeting.</p>



<p><strong>How is this different from Zoom’s enhanced GCM encryption?</strong></p>



<p>Zoom meetings and webinars by default use AES 256-bit GCM encryption for audio, video, and application sharing (i.e., screen sharing, whiteboarding) in transit between Zoom applications, clients, and connectors. In a meeting without E2EE enabled, audio and video content flowing between users’ Zoom apps is not decrypted until it reaches the recipients’ devices. However, the encryption keys for each meeting are generated and managed by Zoom’s servers. In a meeting with E2EE enabled, nobody except each participant – not even Zoom’s servers – has access to the encryption keys being used to encrypt the meeting.</p>



<p><strong>How do I verify that my meeting is using end-to-end-encryption?</strong></p>



<p>Participants can look for a green shield logo in the upper left corner of their meeting screen with a padlock in the middle to indicate their meeting is using E2EE. It looks similar to our GCM encryption symbol, but the checkmark is replaced with a lock.</p>



<figure><img loading="lazy" alt="" width="325" height="324" data-src="https://lh3.googleusercontent.com/z-Qf8a0hn5w7dX4q7GAQjGc4iNM_b45r45Um6g7iai7jV9xtmHmcl8WI26vkdAtGfLZrzZTdrszHO6kpgAKspf8rGJ7XcSYrM6asib4EgPyEwFwQkOWmPQuwYI-WplnUflaStT3T"></figure><p>Participants will also see the meeting leader’s security code that they can use to verify the secure connection. The host can read this code out loud, and all participants can check that their clients display the same code.</p>



<figure><img alt="" data-src="https://lh6.googleusercontent.com/Mox0nHn2hmBZqje0OSqXI46iBlhD0YmFzqG0Cv04IIDhUgN76uvL2WCP9NPhZNtKcBV0QMGugkdsUxaeVjgTjnhMrF_DGZBxW7slPIPDYGDUrqYVEiSHFgu-pLAtyYJYgAJ0fJJQ"></figure><p><strong>How will you continue to provide a safe and secure platform?</strong></p>



<p>Zoom’s top priority is the trust and safety of our users, and our implementation of E2EE will allow us to continue to enhance safety on our platform. Free/Basic users seeking access to E2EE will participate in a one-time verification process that will prompt the user for additional pieces of information, such as verifying a phone number via text message. Many leading companies perform similar steps to reduce the mass creation of abusive accounts. We are confident that by implementing risk-based authentication, in combination with our current mix of tools — including our work with human rights and children’s safety organizations and our users’ ability to lock down a meeting, report abuse, and a myriad of other features made available as part of our security icon — we can continue to enhance the safety of our users.</p>



<p><strong>What is the rest of the timeline for E2EE?</strong></p>



<p>We plan to roll out better identity management and E2EE SSO integration as part of Phase 2, which is tentatively roadmapped for 2021.&nbsp;</p>



<p>To learn more about using end-to-end encryption and other security features for your Zoom meetings, visit <a href="https://zoom.us/security" target="_blank" rel="noreferrer noopener">Zoom’s security webpage</a>.</p>
                              
            </div></div>]]>
            </description>
            <link>https://blog.zoom.us/zoom-rolling-out-end-to-end-encryption-offering/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24778490</guid>
            <pubDate>Wed, 14 Oct 2020 16:29:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Dockerfile Security Best Practices]]>
            </title>
            <description>
<![CDATA[
Score 374 | Comments 171 (<a href="https://news.ycombinator.com/item?id=24776771">thread link</a>) | @gbrindisi
<br/>
October 14, 2020 | https://cloudberry.engineering/article/dockerfile-security-best-practices/ | <a href="https://web.archive.org/web/*/https://cloudberry.engineering/article/dockerfile-security-best-practices/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <div>
            <p>Container security is a broad problem space and there are many low hanging fruits one can harvest to mitigate risks. A good starting point is to follow some rules when writing Dockerfiles.</p>

<p>I’ve compiled a list of common security issues and how to avoid them. For every issue I’ve also written an <a href="https://www.openpolicyagent.org/">Open Policy Agent</a> (OPA) rule ready to be used to statically analyze your Dockerfiles with <a href="https://conftest.dev/">conftest</a>. You can’t shift more left than this!</p>

<p>You can find the <code>.rego</code> rule set in <a href="https://github.com/gbrindisi/dockerfile-security">this repository</a>. I appreciate feedback and contributions.</p>

<h2 id="do-not-store-secrets-in-environment-variables">Do not store secrets in environment variables</h2>

<p>Secrets distribution is a hairy problem and it’s easy to do it wrong. For containerized  applications one can surface them either from the filesystem by mounting volumes or more handily through  environment variables.</p>

<p>Using <code>ENV</code> to store secrets is bad practice because Dockerfiles are usually distributed with the application, so there is no difference from hard coding secrets in code.</p>

<p>How to detect it:</p>

<pre><code>secrets_env = [
    "passwd",
    "password",
    "pass",
 #  "pwd", can't use this one   
    "secret",
    "key",
    "access",
    "api_key",
    "apikey",
    "token",
    "tkn"
]

deny[msg] {    
    input[i].Cmd == "env"
    val := input[i].Value
    contains(lower(val[_]), secrets_env[_])
    msg = sprintf("Line %d: Potential secret in ENV key found: %s", [i, val])
}
</code></pre>

<h2 id="only-use-trusted-base-images">Only use trusted base images</h2>

<p>Supply chain attacks for containerized application will also come from the hierarchy of layers used to build the container itself.</p>

<p>The main culprit is obviously the base image used. Untrusted base images are a high risk and whenever possible should be avoided.</p>

<p>Docker provides a <a href="https://docs.docker.com/docker-hub/official_images/">set of official base images</a> for most used operating systems and apps. By using them, we minimize risk of compromise by leveraging some sort of shared responsibility with Docker itself.</p>

<p>How to detect it:</p>

<pre><code>deny[msg] {
    input[i].Cmd == "from"
    val := split(input[i].Value[0], "/")
    count(val) &gt; 1
    msg = sprintf("Line %d: use a trusted base image", [i])
}
</code></pre>

<p>This rule is tuned towards DockerHub’s official images. It’s very dumb since I’m only detecting the absence of a namespace.</p>

<p>The definition of trust depends on your context: change this rule accordingly.</p>

<h2 id="do-not-use-latest-tag-for-base-image">Do not use ‘latest’ tag for base image</h2>

<p>Pinning the version of your base images will give you some peace of mind with regards to the predictability of the containers you are building.</p>

<p>If you rely on latest you might silently inherit updated packages that in the best worst case might impact your application reliability, in the worst worst case might introduce a vulnerability.</p>

<p>How to detect it:</p>

<pre><code>deny[msg] {
    input[i].Cmd == "from"
    val := split(input[i].Value[0], ":")
    contains(lower(val[1]), "latest"])
    msg = sprintf("Line %d: do not use 'latest' tag for base images", [i])
}
</code></pre>

<h2 id="avoid-curl-bashing">Avoid curl bashing</h2>

<p>Pulling stuff from internet and piping it into a shell is as bad as it could be. Unfortunately it’s a widespread solution to streamline installations of software.</p>

<pre><code>wget https://cloudberry.engineering/absolutely-trustworthy.sh | sh
</code></pre>

<p>The risk is the same framed for supply chain attacks and it <strong>boils down to trust</strong>. If you really have to curl bash, do it right:</p>

<ul>
<li>use a trusted source</li>
<li>use a secure connection</li>
<li>verify the authenticity and integrity of what you download</li>
</ul>

<p>How to detect it:</p>

<pre><code>deny[msg] {
    input[i].Cmd == "run"
    val := concat(" ", input[i].Value)
    matches := regex.find_n("(curl|wget)[^|^&gt;]*[|&gt;]", lower(val), -1)
    count(matches) &gt; 0
    msg = sprintf("Line %d: Avoid curl bashing", [i])
}
</code></pre>

<h2 id="do-not-upgrade-your-system-packages">Do not upgrade your system packages</h2>

<p>This might be a bit of a stretch but the reasoning is the following: you want to pin the version of your software dependencies, if you do <code>apt-get upgrade</code> you will effectively upgrade them all to the latest version.</p>

<p>If you do upgrade <strong>and</strong> you are using the <code>latest</code> tag for the base image, you amplify the unpredictability of your dependencies tree.</p>

<p>What you want to do is to pin the base image version and just <code>apt/apk update</code>.</p>

<p>How to detect it:</p>

<pre><code>upgrade_commands = [
    "apk upgrade",
    "apt-get upgrade",
    "dist-upgrade",
]

deny[msg] {
    input[i].Cmd == "run"
    val := concat(" ", input[i].Value)
    contains(val, upgrade_commands[_])
    msg = sprintf(“Line: %d: Do not upgrade your system packages", [i])
}
</code></pre>

<h2 id="do-not-use-add-if-possible">Do not use ADD if possible</h2>

<p>One little feature of the <code>ADD</code> command is that you can point it to a remote url and it will fetch the content at building time:</p>

<pre><code>ADD https://cloudberry.engineering/absolutely-trust-me.tar.gz
</code></pre>

<p>Ironically the official docs suggest to use curl bashing instead.</p>

<p>From a security perspective the same advice applies: don’t.
Get whatever content you need before, verify it and then <code>COPY</code>. But if you really have to, <strong>use trusted sources over secure connections</strong>.</p>

<p>Note: if you have a fancy build system that dynamically generate Dockerfiles, then <code>ADD</code> is effectively a sink asking to be exploited.</p>

<p>How to detect it:</p>

<pre><code>deny[msg] {
    input[i].Cmd == "add"
    msg = sprintf("Line %d: Use COPY instead of ADD", [i])
}
</code></pre>

<h2 id="do-not-root">Do not root</h2>

<p>Root in a container is the same root as on the host machine, but restricted by the docker daemon configuration. No matter the limitations, if an actor breaks out of the container he will still be able to find a way to get full access to the host.</p>

<p>Of course this is not ideal and your threat model can’t ignore the risk posed by running as root.</p>

<p>As such is best to always specify a user:</p>

<pre><code>USER hopefullynotroot
</code></pre>

<p>Note that explicitly setting a user in the Dockerfile is just one layer of defence and won’t solve the whole <a href="https://www.redhat.com/en/blog/understanding-root-inside-and-outside-container">running as root problem</a>.</p>

<p>Instead one can — and <em>should</em> — adopt a defence in depth approach and mitigate further across the whole stack: strictly configure the docker daemon or use a rootless container solution, restrict the runtime configuration (prohibit <code>--privileged</code> if possible, etc), and so on.</p>

<p>How to detect it:</p>

<pre><code>any_user {
    input[i].Cmd == "user"
 }

deny[msg] {
    not any_user
    msg = "Do not run as root, use USER instead"
}
</code></pre>

<h2 id="do-not-sudo">Do not sudo</h2>

<p>As a corollary to <code>do not root</code>, you shall not sudo either.</p>

<p>Even if you run as a user make sure the user is not in the <code>sudoers</code> club.</p>

<pre><code>deny[msg] {
    input[i].Cmd == "run"
    val := concat(" ", input[i].Value)
    contains(lower(val), "sudo")
    msg = sprintf("Line %d: Do not use 'sudo' command", [i])
}
</code></pre>

<h2 id="acknowledgements">Acknowledgements</h2>

<p>This work has been inspired and is an iteration on <a href="https://blog.madhuakula.com/dockerfile-security-checks-using-opa-rego-policies-with-conftest-32ab2316172f">prior art</a> from <a href="https://blog.madhuakula.com/@madhuakula">Madhu Akula</a>.</p>
        </div>
        
    </div></div>]]>
            </description>
            <link>https://cloudberry.engineering/article/dockerfile-security-best-practices/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24776771</guid>
            <pubDate>Wed, 14 Oct 2020 14:17:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Unspoken Hard Bits of Bootstrapping a SaaS Product to Life]]>
            </title>
            <description>
<![CDATA[
Score 105 | Comments 24 (<a href="https://news.ycombinator.com/item?id=24776605">thread link</a>) | @geoffroberts
<br/>
October 14, 2020 | https://www.outseta.com/posts/the-unspoken-hard-bits-of-bootstrapping | <a href="https://web.archive.org/web/*/https://www.outseta.com/posts/the-unspoken-hard-bits-of-bootstrapping">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-block-type="2" id="block-ec2306edd8f63db4e902"><div><p>The challenges that I’ve faced as a bootstrapped founder simply aren’t the ones that are commonly talked about</p><p>By <a href="https://twitter.com/GeoffTRoberts">Geoff Roberts</a> · 17 min read</p><p>The internet is littered with horror stories detailing the many challenges of entrepreneurship. We’ve all read the tales of founders wrestling for years to find <a href="https://www.outseta.com/posts/product-market-appetite">product market fit</a>, of co-founders squabbling over equity, of the CEO riddled by anxiety as he drains his infant daughter’s college fund to keep his start-up afloat for another month.</p><p>Cautionary tales? Sure. But while these circumstances may be relatively common, ultimately they gain notoriety in the tech media simply because they are alarmist and clickbait.&nbsp;</p><p>As I approach year four as a founder of a bootstrapped SaaS start-up, I can’t help but reflect on the hardships that I’ve encountered myself. As I have, I’ve had an overwhelming feeling—the majority of challenges that I’ve faced are by no means unique to me, but <em>nobody is talking about them</em>. This article is about surfacing those common entrepreneurial challenges that are gasping for some air.&nbsp;&nbsp;</p></div></div><div data-block-type="2" id="block-yui_3_17_2_1_1602180654131_6032"><div><p>I’d go so far as to say most entrepreneurial challenges that we hear being bemoaned are a direct result of your chosen path being incompatible with your business idea or life circumstances. When these items are in harmony, entrepreneurship becomes vastly easier.</p><p>If you’re building SpaceX, your idea dictates that you go the VC route—it’s too big, too ambitious, and too capital intensive to bootstrap such a company into existence. This is an extreme example, but this is the lens through which we should be assessing our start-up ideas as we decide how to fund them.</p><p>Generally speaking, “smaller” products are better suited to bootstrapping. Building a slack notification tool? Great! You can probably launch something like this in less than a month, give the project the opportunity to gain some traction, then make the decision to proceed or not from there. You’d be crazy <em>not</em> to bootstrap such a company.&nbsp;&nbsp;&nbsp;</p><p>But if you’re building a bigger and more ambitious piece of software you need to look closely at the reality that it could take years to bring something of value to fruition. Can you afford a year without a paycheck? How about three years, or five?&nbsp;</p><p>It’s worth noting that this isn’t solely a financial decision or one of product scope, but also one that will impact your day-to-day life potentially for years to come. Did you recently sign a mortgage? Do you plan on having kids? The stresses that come with entrepreneurship and how you choose to fund your business will have trickle down effects on all aspects of your life.</p><p>The question is not do you prefer bootstrapping or venture capital. The question is which path is most compatible with the product you’re building… and your life.&nbsp;</p><p>Bringing this full circle to Outseta, in many ways Outseta is not an idea compatible with the idea of bootstrapping. Outseta is a very large and ambitious project that we’re executing on with a small team—it’s really three or four different software products rather than one. We knew this going in and openly talked about how it would take years for us to truly be able to deliver on our value proposition and start to grow revenue in a meaningful way. It took us two years to deliver a sellable product, and four years in now we’re just starting to scale.&nbsp;</p><p>But we had one major advantage—the idea that we chose to build was not one that needed “validating”—the categories of software that we offer (CRM, billing, email marketing, etc) have staying power and have been validated long ago. This gave us confidence that we could play the long game and allowed us to design all aspects of our business and lives so that we could survive long enough to see Outseta blossom into what it’s become today.&nbsp;</p><p>We didn’t choose an easy route, but we’re now finding that Outseta is massively defensible because very few teams would commit 4+ years just to bring an idea to life. You could do it much more quickly with venture capital, sure, but you’d never be able to serve the audience that we do at our price point.&nbsp;</p><h2>The “Doldrums” of SaaS</h2><p>One of the most common and least talked about hardships of bootstrapping a SaaS start-up is what I’ve started describing as “the doldrums of SaaS.” This occurs when your start-up hits an inflection point in sign-ups and support requests scale up dramatically to the extent that they all but take over your ability to focus on other aspects of your business, from marketing to building new features.</p><p>Ironically enough, this stage in a bootstrapped start-up’s growth initially became apparent to me because of one of our competitors. We started getting dozens of sign-ups from founders all singing the same tune.&nbsp;</p><p><em>“I was using CompetitorX—I loved their product initially, but they’re unresponsive and haven’t released any new features in months.”</em></p><p>Then earlier this spring, we went through a similar stage. On the back of a new partnership with <a href="https://www.outseta.com/webflow">Webflow</a>, all of a sudden the number of sign-ups for Outseta scaled up dramatically—and in tandem with that growth came an influx of support tickets from new users learning the platform.</p><p>My summer was spent focused almost entirely on technical support, while my time spent marketing Outseta fell off a cliff. Likewise, my Co-founders were pushing fixes and helping out with new Outseta implementations cutting into their ability to roll out new features.</p><p>Ultimately this is a stage in a bootstrapped start-up’s growth that doesn’t get much lip service because there’s little benefit to speaking about increased support levels and decreased capacity for building new features. But that’s unfortunate because this is a “good problem” that nearly every scaling company will encounter—yet there’s very little advice out there on how to best handle this stage of the entrepreneurial journey.</p><p>If you’re a VC backed company, it’s an easy problem to fix—throw some money at hiring additional support capacity, because you have the ability to run your company at a loss. But for a bootstrapper this stage can feel like your legs are stuck in quicksand.</p><p>I don’t have a solution here, aside from taking some degree of solace in the thought that time spent helping customers is the most single important thing that you can do to build your business. And rather than hiring support capacity, using your engineering resources to solve underlying issues that result in increased support requests will always pay off in the long run.</p><h2>The psychological toll of not feeling like you’re “all-in”</h2><p>It’s well documented that many entrepreneurs feel extreme levels of stress, anxiety, worry, and even depression—which most often is tied to financial instability and the regular peaks and valleys of building a company. But for me personally—and I suspect many others—one of the strongest psychological tolls I’ve felt is stress that comes from feeling like I’m not yet able to be “all-in” on my start-up.</p><p>Make no mistake about it—since the day we started Outseta, I’ve undoubtedly been “all-in.” I’ve rearranged almost all aspects of my life over four years in support of bringing this company into existence. But as part of our strategy to <a href="https://www.outseta.com/posts/marketing-strategies-for-bootstrappers">bootstrap the business</a>, our entire team began working on Outseta in a part-time capacity while consulting or working on other projects to pay the bills. We’ve gradually ramped up the time we’ve each invested in the business as our growth has permitted, as most bootstrappers do.</p><p>For me personally, this meant that for years, literally, there was always this nagging feeling that I could be doing more. I could be doing more or doing better for Outseta, and I could be doing more in terms of the other projects I was working on as well. For me, that feeling has been tough. It feels really good to be able to say that you unequivocally, without question, are giving something your all. But most bootstrappers have to wait quite a long period of time until their business can truly support every last scrap of their attention at work. That’s a long period of time to wait to shed that nagging feeling!</p><h2>SaaS <em>is</em> a torture chamber</h2><p>The wonders of SaaS as a business model are well known—the stability and predictability of recurring revenue, products that can scale to thousands of users, high valuations—the whole nine yards. But the fact of the matter is that for bootstrapped founders, SaaS <em>is</em> a torture chamber and a game of delayed gratification.</p><p>Don’t misunderstand me and immediately suppose that there’s some sort of self-inflicted pain behind this comment—I’m the biggest proponent of work/life balance and generally the principles outlined in Jason Fried and DHH’s <a href="https://www.amazon.com/Doesnt-Have-Be-Crazy-Work/dp/0062874780"><em>It Doesn’t Have To Be Crazy At Work</em></a> that you’ll ever find. This is solely a matter of the business model.</p><p>When you’re bootstrapping, you’re going to start off without a paycheck. Most of us work towards a point where the revenue of the business can eventually start to pay us something, then we scale up our own compensation until it reaches some semblance of a normal salary. The problem with SaaS and bootstrapping is you are hugely incentivized not to pay yourself—every dollar that you pay yourself is money that isn’t being reinvested in the growth of your business, so you’re intentionally slowing down your own growth.</p><p>Of course there are human, real world circumstances to consider and your own financial and emotional needs directly correlate to your ability to work on your business successfully. But the hard reality is the longer you can delay your own gratification, the greater your advantage.&nbsp;</p><p>I asked my Co-founder, Dimitris, to speak to his experience of the long, slow ramp of death that’s so prevalent in SaaS. Dimitris Co-founded <a href="https://www.buildium.com/">Buildium</a> back in 2004.</p><p>“It took us 2.5 years to get to 50 customers,” says Dimitris. “Then it took us another year to get to 400 customers, and a year after that we reached 1,000 customers. When we had 400 customers we made a conscious decision to defer paying ourselves more than a token $1,000 per month salary and instead hired our first two full-time …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.outseta.com/posts/the-unspoken-hard-bits-of-bootstrapping">https://www.outseta.com/posts/the-unspoken-hard-bits-of-bootstrapping</a></em></p>]]>
            </description>
            <link>https://www.outseta.com/posts/the-unspoken-hard-bits-of-bootstrapping</link>
            <guid isPermaLink="false">hacker-news-small-sites-24776605</guid>
            <pubDate>Wed, 14 Oct 2020 14:01:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Z80 CPU User Manual (2016)]]>
            </title>
            <description>
<![CDATA[
Score 106 | Comments 54 (<a href="https://news.ycombinator.com/item?id=24776115">thread link</a>) | @tosh
<br/>
October 14, 2020 | https://zany80.github.io/documentation/Z80/UserManual.html | <a href="https://web.archive.org/web/*/https://zany80.github.io/documentation/Z80/UserManual.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://zany80.github.io/documentation/Z80/UserManual.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24776115</guid>
            <pubDate>Wed, 14 Oct 2020 13:13:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Elon Musk Shows the Germans How to Move Quickly]]>
            </title>
            <description>
<![CDATA[
Score 69 | Comments 122 (<a href="https://news.ycombinator.com/item?id=24775556">thread link</a>) | @Tomte
<br/>
October 14, 2020 | https://www.spiegel.de/international/business/the-tesla-factory-near-berlin-elon-musk-shows-the-germans-how-to-move-quickly-a-a14a3415-a4ed-4d85-80c1-ec53b66ac0cb | <a href="https://web.archive.org/web/*/https://www.spiegel.de/international/business/the-tesla-factory-near-berlin-elon-musk-shows-the-germans-how-to-move-quickly-a-a14a3415-a4ed-4d85-80c1-ec53b66ac0cb">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-article-el="body">
<section data-app-hidden="true">


</section>
<section>
<div>
<figure data-component="Image" data-settings="{&quot;id&quot;:&quot;4f34f3e1-6c6f-4065-9ec6-3301690ac70f&quot;, &quot;zoomable&quot;:true,&quot;zoomId&quot;:&quot;b2f85209-1496-4ddf-80ce-1b0219228930&quot;}">
<p><span>
<span data-image-el="aspect">
<span>
<img data-image-el="img" src="https://cdn.prod.www.spiegel.de/images/4f34f3e1-6c6f-4065-9ec6-3301690ac70f_w948_r1.77_fpx76_fpy24.jpg" srcset="https://cdn.prod.www.spiegel.de/images/4f34f3e1-6c6f-4065-9ec6-3301690ac70f_w520_r1.77_fpx76_fpy24.jpg 520w, https://cdn.prod.www.spiegel.de/images/4f34f3e1-6c6f-4065-9ec6-3301690ac70f_w948_r1.77_fpx76_fpy24.jpg 948w" width="948" height="536" sizes="948px" title="Tesla founder Elon Musk: &quot;A ton of fun!&quot;" alt="Tesla founder Elon Musk: &quot;A ton of fun!&quot;">
</span>
</span>
</span>

</p>
<figcaption>
<p><strong>Tesla founder Elon Musk:</strong> "A ton of fun!"</p>
<span>
Foto: <p>Julian Stähle / dpa</p>
</span>
</figcaption>
</figure>
</div><div>
<p>A large property map hangs in the mayor's office, right next to a display cabinet full of memorabilia accumulated over a long term in office. The coat of arms of the town of Grünheide on the map has faded, as has the writing: "Net settlement area of 300 hectares," it reads, if you look hard enough.</p>


<div>
<p>Arne Christiani's predecessor hung up the poster 20 years ago, back when BMW wanted to build a car manufacturing plant on the site, but then chose the city of Leipzig instead. "When I was first elected mayor in 2003, I left the map up," says Christiani. The pine forest on the edge of the town has remained his field of dreams for almost 17 years.</p><p>During that time, Grünheide has grown steadily, but its population has also aged. It's a place that's beautiful for people who appreciate peace and quiet, but not one that’s particularly tempting for the younger generation. Each year, Christiani has apologized to locals on International Volunteer Day for the fact that it had once again not been possible to attract high-quality industrial jobs to the area.</p>
</div>

<div>
<p>For some time now, though, two new maps have been hanging above the old one, with the parcel of land colored red. Christiani's dream could finally be coming true, with Tesla hoping to build electric cars on the site.</p><h3><strong>Dreams Threatened, Dreams Come True</strong></h3><p>If you leave Town Hall and walk a good 800 meters through a pine forest to the edge of the village, you reach a lake called Peetzsee. Christiani had been in office for two years when Johannes Curth and his family came to fulfil their dream here, swapping a rental apartment in Berlin’s Prenzlauer Berg neighborhood for a home of their own, surrounded by forests and lakes.</p>
</div>

<p>The Curths bought a plot of land just a few meters from the shore of the lake back when prices were still reasonable. They built a house with large windows and surrounded by a good-sized yard, in which stand two magnificent old trees in it.</p>

<section data-area="contentbox">
<div>
<p><span>DER SPIEGEL 39/2020</span></p><figure data-component="Image" data-settings="{&quot;id&quot;:&quot;996d8f55-bef6-471b-ad10-5c788bf27a9e&quot;, &quot;zoomable&quot;:false,&quot;zoomId&quot;:&quot;36cf9ec6-d1c7-4020-bca9-38c54e1e2d12&quot;}">
<span>
<span data-image-el="aspect">
<span>

<img data-image-el="img" src="https://cdn.prod.www.spiegel.de/images/996d8f55-bef6-471b-ad10-5c788bf27a9e_w568_r0.7571817357121258_fpx50.98_fpy47.69.jpg" srcset="https://cdn.prod.www.spiegel.de/images/996d8f55-bef6-471b-ad10-5c788bf27a9e_w284_r0.7571817357121258_fpx50.98_fpy47.69.jpg 284w, https://cdn.prod.www.spiegel.de/images/996d8f55-bef6-471b-ad10-5c788bf27a9e_w335_r0.7571817357121258_fpx50.98_fpy47.69.jpg 335w, https://cdn.prod.www.spiegel.de/images/996d8f55-bef6-471b-ad10-5c788bf27a9e_w568_r0.7571817357121258_fpx50.98_fpy47.69.jpg 568w" width="568" height="750" sizes="568px" loading="lazy" data-srcset="https://cdn.prod.www.spiegel.de/images/996d8f55-bef6-471b-ad10-5c788bf27a9e_w284_r0.7571817357121258_fpx50.98_fpy47.69.jpg 284w, https://cdn.prod.www.spiegel.de/images/996d8f55-bef6-471b-ad10-5c788bf27a9e_w335_r0.7571817357121258_fpx50.98_fpy47.69.jpg 335w, https://cdn.prod.www.spiegel.de/images/996d8f55-bef6-471b-ad10-5c788bf27a9e_w568_r0.7571817357121258_fpx50.98_fpy47.69.jpg 568w">
</span>
</span>
</span>
</figure>

</div>
</section>
<p>But now that Mayor Christiani's dream is coming true, Curth sees his own dream threatened. "We moved here because of the peace and quiet and the nature," he says. "What will happen if Tesla starts building cars here?" He fears for the quality of the water and air. And he worries about the extra traffic and what will happen to this sleepy community of 8,755 people when Tesla moves in.</p>

<div>
<p>Elon Musk, the entrepreneur behind the carmaker, is an uncompromising man whose ideas jump back and forth between California, Mars and Grünheide. The head of the world's largest electric car manufacturer builds rockets that ferry people into space and dreams of building a hyperloop tunnel for passenger transport. He is adored by his followers because, as an entrepreneur, he refuses to accept any limits.</p><h3><strong>Breathtaking Speed</strong></h3><p>Almost as a byproduct, Musk is now also changing not only the provincial state of Brandenburg, where he’s setting up his factory, but also Germany. The project just outside of Berlin is becoming symbolic for industrial policy in times of climate change. Whereas German companies tend to moan and dig in their heels when the government sets overly ambitious climate targets, as they did last week when the new European Union climate goals were announced, Tesla brings both together: sustainable manufacturing and speed. Breathtaking speed.</p>
</div>
<figure>
<div data-component="Image" data-settings="{&quot;id&quot;:&quot;7bfd7c90-7763-4bb3-ad45-ab17ec97c569&quot;, &quot;zoomable&quot;:true,&quot;zoomId&quot;:&quot;c2d53115-b299-404a-be48-9fb8e38219c1&quot;}">
<div>
<div>
<p><span>
<span data-image-el="aspect">
<span>

<img data-image-el="img" src="https://cdn.prod.www.spiegel.de/images/7bfd7c90-7763-4bb3-ad45-ab17ec97c569_w718_r1.5_fpx33.34_fpy50.jpg" srcset="https://cdn.prod.www.spiegel.de/images/7bfd7c90-7763-4bb3-ad45-ab17ec97c569_w488_r1.5_fpx33.34_fpy50.jpg 488w, https://cdn.prod.www.spiegel.de/images/7bfd7c90-7763-4bb3-ad45-ab17ec97c569_w616_r1.5_fpx33.34_fpy50.jpg 616w, https://cdn.prod.www.spiegel.de/images/7bfd7c90-7763-4bb3-ad45-ab17ec97c569_w718_r1.5_fpx33.34_fpy50.jpg 718w" width="718" height="479" sizes="718px" loading="lazy" data-srcset="https://cdn.prod.www.spiegel.de/images/7bfd7c90-7763-4bb3-ad45-ab17ec97c569_w488_r1.5_fpx33.34_fpy50.jpg 488w, https://cdn.prod.www.spiegel.de/images/7bfd7c90-7763-4bb3-ad45-ab17ec97c569_w616_r1.5_fpx33.34_fpy50.jpg 616w, https://cdn.prod.www.spiegel.de/images/7bfd7c90-7763-4bb3-ad45-ab17ec97c569_w718_r1.5_fpx33.34_fpy50.jpg 718w" title="Tesla Gigafactory in Grünheide: Are the Germans fast enough?" alt="Tesla Gigafactory in Grünheide: Are the Germans fast enough?">
</span>
</span>
</span>
</p><figcaption>
<p><strong>Tesla Gigafactory in Grünheide:</strong> Are the Germans fast enough?</p>
<span>
Foto: Robert Grahn&nbsp;/ euroluftbild.de / ullstein bild
</span>
</figcaption>
</div>
</div>
</div>
</figure><div>
<p>Musk's Gigafactory will be built in a region where most structures tend to be single-family homes, if there are any at all. In the first stage of development, 12,000 people will work around the clock in three shifts. Once the factory is complete, more than 40,000 people could produce a good 2 million Tesla vehicles here. "Please work at Tesla Giga Berlin! It's going to be a ton of fun," Musk recently tweeted in German.</p><p>For quite some time, German car executives and politicians tended to make fun of Musk, notorious as he was for his outrageous personality on Twitter. When he outlined his visions at a 2014 lunch with Peter Altmaier - who was chief of staff of Angela Merkel's Chancellery at the time but is now economics minister – and raved about the advantages of electric propulsion, saying it could be used in all means of transportation except for rockets flying into space, Altmaier still thought he sounded a bit unhinged. "At the time," says Altmaier, "nobody thought this technology would be so successful." At least the German competition didn't.</p><p>As recently as 2018, when the California-based company was having troubles with the serial production of its Model 3, Volkswagen considered becoming a strategic investor in Tesla to teach Musk how to do mass production. But reality has long since overtaken that idea: Tesla is now worth five times as much as Volkswagen on the stock exchange.</p><p>The days when the billionaire had to ask politicians for an appointment are over. When he came to Germany in early September to visit his construction site, the reception he received was that of a pop star. Fans shared the latest movement data of his private jet and puzzled where he might pop up next. Leading politicians cleared their calendars at short notice.</p><p>This week, the Musk party is set to continue, and his name will once again appear in newspapers around the world. He has slated this Tuesday as "Battery Day,” when he plans to announce the progress Tesla has made in battery technology in addition to identifying the site of at least one new battery plant. There are many indications, including interviews with Musk, that Grünheide may be chosen as the site. If it is, giant tree-felling machines would again show up to wait for authorization to clear another 60 hectares (nearly 150 acres) of forest.</p><p>It would send an unmistakable message. Because one day later, on Wednesday, hearings are set to begin in the nearby town of Erkner on the 406 complaints against the factory that have been filed by environmental associations and residents. Construction, though, has already been underway for months, with Tesla deciding to move ahead at its own risk with preliminary permits.</p><h3><strong>Faster and Better</strong></h3><p>A recent visit to the construction site in Grünheide provided a glimpse of the degree to which Tesla's mantra has been internalized at Tesla, a mantra by which speed counts most. Evan Horetsky, who heads the roughly 100-member Tesla team in Grünheide, showed a number of interested journalists around the construction site.</p><p>The slim man in his mid-30s with a shaved head and carefully trimmed beard is one of the troubleshooters on Musk's team. He helped out with the Tesla factory in California before going to Reno, Nevada, to lead the creation of the company's first Gigafactory. That had hardly been finished by the time construction in Shanghai began. He says that he and his people have gotten "faster and better" each time. Now, Horetsky is moving things along in Brandenburg.</p><p>Just last fall, the site was covered with tall pine trees. Now, though, they have been replaced by dozens of white concrete pillars protruding from the levelled ground. In the rear section, the shell of the paint shop has been erected. "We gained experience during the construction of the first buildings that we could directly apply in the further development of the design," the American says. "It enabled us to save a couple of days."</p>
</div>
<figure>
<div data-component="Image" data-settings="{&quot;id&quot;:&quot;557ddc99-4b15-46b4-871e-c4391a0edffd&quot;, &quot;zoomable&quot;:true,&quot;zoomId&quot;:&quot;363f9d81-9d93-4b99-8ba7-3982c091ef87&quot;}">
<div>
<div>
<p><span>
<span data-image-el="aspect">
<span>

<img data-image-el="img" src="https://cdn.prod.www.spiegel.de/images/557ddc99-4b15-46b4-871e-c4391a0edffd_w718_r1.4951856946354882_fpx40.02_fpy49.94.jpg" srcset="https://cdn.prod.www.spiegel.de/images/557ddc99-4b15-46b4-871e-c4391a0edffd_w488_r1.4951856946354882_fpx40.02_fpy49.94.jpg 488w, https://cdn.prod.www.spiegel.de/images/557ddc99-4b15-46b4-871e-c4391a0edffd_w616_r1.4951856946354882_fpx40.02_fpy49.94.jpg 616w, https://cdn.prod.www.spiegel.de/images/557ddc99-4b15-46b4-871e-c4391a0edffd_w718_r1.4951856946354882_fpx40.02_fpy49.94.jpg 718w" width="718" height="480" sizes="718px" loading="lazy" data-srcset="https://cdn.prod.www.spiegel.de/images/557ddc99-4b15-46b4-871e-c4391a0edffd_w488_r1.4951856946354882_fpx40.02_fpy49.94.jpg 488w, https://cdn.prod.www.spiegel.de/images/557ddc99-4b15-46b4-871e-c4391a0edffd_w616_r1.4951856946354882_fpx40.02_fpy49.94.jpg 616w, https://cdn.prod.www.spiegel.de/images/557ddc99-4b15-46b4-871e-c4391a0edffd_w718_r1.4951856946354882_fpx40.02_fpy49.94.jpg 718w" title="Mayor Arne Christiani: A field of dreams." alt="Mayor Arne Christiani: A field of dreams.">
</span>
</span>
</span>
</p><figcaption>
<p><strong>Mayor Arne Christiani: </strong>A field of dreams.</p>
<span>
Foto: HC Plambeck / DER SPIEGEL
</span>
</figcaption>
</div>
</div>
</div>
</figure><div>
<p>The fact that final permission to build the factory has not yet been granted and that skeptical citizens must first be heard doesn't bother Horetsky. He says he takes their fears seriously. He notes that similarly complicated requirements had to be fulfilled when building the factory in Shanghai. "The difference to Germany is that here, the people who are directly affected can have their say," says Horetsky. "And who has more of a right to air their views than they do?"</p><p>It is, essentially, the concrete realization of what had been an abstract discussion. What price is society prepared to pay for the future? And are Germans capable of keeping up with the necessary pace?</p><p>The Gigafactory is set to be built in record time, with the first Y model electric SUVs slated for shipping as early as summer 2021. Plans call for 500,000 electric cars to be produced annually by the end of the first construction stage, a pace the <em>Wall Street Journal</em> has described as "breakneck."</p><p>And all this is taking place in Germany, a country where the length of approval procedures has almost doubled in the last 10 years. And in the state of Brandenburg, where construction of the Berlin-Brandenburg Airport (BER) has been marred by endless construction problems and is finally set to open its doors, fully nine years behind schedule.</p><h3><strong>Not Even Corona Has Slowed the Project</strong></h3><p>It sounded almost like a joke initially: An American high-tech car company with a volatile boss meets German environmental law, citizen participation and German bureaucracy. Now, though, it looks as though electric cars could start rolling off the assembly line in Grünheide even faster than they did in centrally steered China. And not even the coronavirus has thus far managed to slow down the project.</p><p>Somehow, the clichés didn't hold true. Tesla may be a tenacious, demanding company, but it also takes criticism seriously and tries to address it. In contrast to German companies, Musk uses every possibility that planning law avails him to accelerate construction, but he does so at his own risk. At the same time, the Brandenburg government has shown itself to be a skilful negotiator in the fight for the project. Since the contract was awarded, a task force of employees from the participating authorities has met weekly with Tesla representatives to discuss progress on the project.</p><p>Axel Vogel was one of the founding members of the Green Party in 1980. He worked …</p></div></div></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.spiegel.de/international/business/the-tesla-factory-near-berlin-elon-musk-shows-the-germans-how-to-move-quickly-a-a14a3415-a4ed-4d85-80c1-ec53b66ac0cb">https://www.spiegel.de/international/business/the-tesla-factory-near-berlin-elon-musk-shows-the-germans-how-to-move-quickly-a-a14a3415-a4ed-4d85-80c1-ec53b66ac0cb</a></em></p>]]>
            </description>
            <link>https://www.spiegel.de/international/business/the-tesla-factory-near-berlin-elon-musk-shows-the-germans-how-to-move-quickly-a-a14a3415-a4ed-4d85-80c1-ec53b66ac0cb</link>
            <guid isPermaLink="false">hacker-news-small-sites-24775556</guid>
            <pubDate>Wed, 14 Oct 2020 11:59:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Sega Master System Architecture: A Practical Analysis]]>
            </title>
            <description>
<![CDATA[
Score 260 | Comments 74 (<a href="https://news.ycombinator.com/item?id=24775305">thread link</a>) | @Parseus
<br/>
October 14, 2020 | https://www.copetti.org/projects/consoles/master-system/ | <a href="https://web.archive.org/web/*/https://www.copetti.org/projects/consoles/master-system/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div class="page"><nav id="navbar"></nav><h2>A Practical Analysis</h2><hr><hr><h2 id="a-quick-introduction">A quick introduction</h2><p>The Master System comes from a long line of succession. What started as a collection of off-the-shelf components, has now gained a new identity thanks to Sega’s engineering.</p><hr><h2 id="models-and-variants">Models and variants</h2><p>I was a bit confused at first while reading about the different models that Sega ended up shipping, so here is a summary of the main models discussed to avoid further confusions:</p><ul><li><strong>Sega Mark III</strong>: The first console featuring this architecture, only released in Japan.</li><li><strong>Sega Master System</strong> (Europe and America): A rebranded Mark III with a new case, a BIOS ROM chip and a different cartridge slot.</li><li><strong>Sega Master System</strong> (Japan): An European/American Master system with the Mark III’s cartridge slot, a new FM chip and a jack port for ‘3D glasses’. However, it lacks the <code>RESET</code> button.</li></ul><p>From now one I’ll use the term ‘Master System’ or ‘SMS’ to refer to all of these, except when talking about exclusive features from a particular model.</p><hr><h2 id="cpu">CPU</h2><p>Sega decided on a fully-fledged <strong>Zilog Z80</strong> CPU running at <strong>~3.58 MHz</strong>. A popular choice by other machines like the ZX Spectrum and the Amstrad CPC. The Z80 has an instruction set compatible with the Intel 8080 but expanded with lots of more instructions.</p><p>The motherboard picture at the start of the article shows a NEC D780C-1 CPU, that’s just SEGA second-sourcing the chip to different manufacturers, other revisions even included the chip manufactured by Zilog. But for this article, it doesn’t matter who fabricated the CPU, as the internal features remain the same.</p><h4 id="memory-available">Memory available</h4><p>The Z80 has a 16-bit address bus, so the CPU can find up to 64 KB worth of memory. In the memory map you’ll find <strong>8 KB of RAM</strong> for general purpose use, this is mirrored in another 8 KB block. Finally, <strong>up to 48 KB of game ROM</strong> are mapped as well.</p><h4 id="accessing-the-rest-of-the-components">Accessing the rest of the components</h4><p>As you can read from the previous paragraph, only main RAM and some cartridge ROM is found on the address space, so how can the program access other components? Well, unlike Nintendo’s <a href="https://www.copetti.org/projects/consoles/nes/">Famicom/NES</a>, not all the hardware of the Master System is mapped using memory locations. Instead, some peripherals are found on the <strong>I/O space</strong>.</p><p>This is because the Z80 family contains an interesting feature called <strong>I/O ports</strong> which enables the CPU to communicate with other hardware without running out of memory addresses. For this, there’s a separate address space for ‘I/O devices’ called <strong>ports</strong> and both share the same data and address bus. The difference, however, is that ports are read and written using <code>IN</code> and <code>OUT</code> instructions, respectively - as opposed to the traditional load/store instruction (<code>LD</code>).</p><p>When an <code>IN</code> or <code>OUT</code> instruction is executed, the Z80 sets up the address lines pointing to the peripheral (which could be, for instance, a keyboard), flags its <code>IORQ</code> pin indicating that an I/O request has been initiated and also flags the <code>RD</code> pin or the <code>WR</code> pin whether it’s an <code>IN</code> or <code>OUT</code> instruction, respectively. The addressed peripheral must manually check for the address bus and the I/O pins and perform the required operation. In the case of an <code>IN</code> instruction, the CPU will store the received value on a pre-defined register.</p><div><a href="https://www.copetti.org/images/consoles/mastersystem/addressing.e186afc9821090e7011a73663fff377720381c6427d70dfc0cdfe0c03921953e.png"><picture>
<img name="image_cover" alt="Image" width="944" height="315" src="https://www.copetti.org/images/consoles/mastersystem/addressing.e186afc9821090e7011a73663fff377720381c6427d70dfc0cdfe0c03921953e.png" loading="auto"></picture></a><figcaption>SMS' Addressing layout</figcaption></div><p>The way SEGA interconnected the CPU with the rest of the components enables not only to access values, but also showing/hiding certain components from appearing in the memory map.</p><p>Curiously enough, the <a href="https://www.copetti.org/projects/consoles/game-boy/#cpu">Game Boy</a> had a Z80 ‘variant’ that completely omitted the I/O ports. Thus, it had to fit everything in the memory map.</p><h4 id="backwards-compatibility">Backwards compatibility</h4><p>The architecture of this console is very similar to its predecessor, the <strong>Sega SG-1000</strong>, so the Master System managed to gain backwards compatibility with the SG-1000. Although, this only applies to the Japanese variant since the others contain a different cartridge slot.</p><hr><h2 id="graphics">Graphics</h2><p>The drawings on the screen are produced by a proprietary chip called <strong>Video Display Processor</strong> or ‘VDP’. Internally, it has the same design of the Texas instrument TMS9918 (used in the SG-1000), but enhanced with more features which we will discuss in the following sections.</p><h4 id="organising-the-content">Organising the content</h4><div><a href="https://www.copetti.org/images/consoles/mastersystem/vdp.2930ab05e2b147c948d5134eeb66a701849c0a047bd649abd3cfd4b84d7cde21.png"><picture>
<img name="image_cover" alt="Image" width="1019" height="303" src="https://www.copetti.org/images/consoles/mastersystem/vdp.2930ab05e2b147c948d5134eeb66a701849c0a047bd649abd3cfd4b84d7cde21.png" loading="auto"></picture></a><figcaption>Memory architecture of the VDP</figcaption></div><p>Next to the VDP is connected <strong>16 KB of VRAM</strong> which only the VDP can access using a 16-bit data bus. If you look at the motherboard picture again, you’ll notice that both RAM and VRAM chips are roughly the same, except that VRAM uses the chip model ending in ‘20’ which has lower latency.</p><p>In the case of the Master System, VRAM houses everything the VDP will require for rendering (except Colour RAM). The CPU fills VRAM by writing on VDP’s registers, which will in turn forward the values to VRAM. Since the VDP is accessed using I/O ports, the CPU must use <code>IN</code> and <code>OUT</code> instructions.</p><h4 id="constructing-the-frame">Constructing the frame</h4><p>The VDP renders frames with a resolution of <strong>up to 256x192 pixels</strong>, further revision added support for 256x224 px and 256x240 px, however, to maintain compatibility with all models, developers held on to the standard resolution. This chip has the same <em>modus operandi</em> of Nintendo’s <a href="https://www.copetti.org/projects/consoles/nes/#constructing-the-frame">PPU</a>, in other words, graphics are rendered on-the-spot.</p><p>On the other side, the VDP has four different modes of operation which will alter the characteristics of the frame (colour depth and resolution):</p><ul><li><strong>Mode 0 to III</strong>: Inherited from the TMS9918 found on the SG-1000. Included for backwards compatibility, although any SMS game can use them.</li><li><strong>Mode IV</strong>: Native mode of the Master System, which enables access to all the state-of-the-art features of the VDP. For the analysis, we’ll focus on this one!</li></ul><p>Now let’s see how a frame is drawn step by step, for this, I’ll borrow <em>Sonic The Hedgehog</em>’s assets. Also, to make explanations easier, I’m going to focus on the standard memory layout that Sega suggest for organising the graphics content (just remember that the VDP is very flexible with this, so games are allowed to optimise it).</p><div><ul><li id="tab-2-1-tiles-link"><a href="#tab-2-1-tiles">Tiles</a></li><li id="tab-2-2-background-layer-link"><a href="#tab-2-2-background-layer">Background Layer</a></li><li id="tab-2-3-sprite-layer-link"><a href="#tab-2-3-sprite-layer">Sprite Layer</a></li><li id="tab-2-4-result-link"><a href="#tab-2-4-result">Result</a></li></ul><div><div id="tab-2-1-tiles"><h4>Tiles</h4><p>Mode IV is based on the <strong>tile system</strong>. To recall <a href="https://www.copetti.org/projects/consoles/nes/#tab-2-1-tiles">previous explanations</a> about tile engines, tiles are just <strong>8x8 pixel bitmaps</strong> which the renderer fetches to draw the game’s graphics. In the case of the VDP, the frame is composed of two planes, the background layer and the sprite layer.</p><p>Inside VRAM, there’s an area dedicated for tiles called <strong>Character generator</strong> (Sega calls ‘Characters’ to tiles) and it’s set to be <strong>14 KB long</strong>. Each tile occupies 32 bytes, so we can store up to 448 tiles.</p><p>There are 64 pixels defined on every tile, the VDP rules that each pixel must weight 4 bits, that means that up to <strong>16 colours can be chosen</strong>. Those bits reference a single entry on <strong>Colour RAM</strong> or ‘CRAM’. That area is found inside the VDP and stores the colour palettes. Colour palette systems help reduce the size of tiles in memory and allows programmers to alternate its colours without storing multiple copies.</p><p>Colour RAM stores <strong>two palettes of 16 colours each</strong>. Each entry is 6-bit wide and each 2-bit set defines one colour from the RGB model. This means that there are 64 colours available to choose from.</p></div><div id="tab-2-2-background-layer"><h4>Background Layer</h4><p>The background layer is a large plane where static tiles are drawn. To place something here, there’s another area on VRAM called <strong>Screen map</strong> that takes 1.75 KB.</p><p>This enables to build a layer of 896 tiles (32x28 tiles), but if we do the math we’ll see that this layer is larger than the display resolution of this console. The reality is, only 768 tiles (32x24 tiles) are visible, so the visible area is manually selected at the programmer’s will. Hence, by slowly alternating the X and Y coordinates of the selected area, a <strong>scrolling effect</strong> is accomplished.</p><p>Each entry of the map is 2 bytes wide (as wide as the VDP data-bus) and contains the address of the tile in the Character generator and the following attributes:</p><ul><li><strong>Horizontal and Vertical flip</strong>.</li><li>The <strong>priority bit</strong> (whether to draw some or all the tile in front of sprites).</li><li>The <strong>colour palette</strong> used.</li></ul><p>Curiously enough, there are 3 unused bits in the entry which the game can use for other purposes (i.e. extra flags to assist the game engine).</p></div><div id="tab-2-3-sprite-layer"><h4>Sprite Layer</h4><div><a href="https://www.copetti.org/images/consoles/mastersystem/sonic/sprites.707537651fd6e5ce0ebcca7c4192748e4389797ebbcff4c1ddb4939cb8271e44.png"><picture>
<img name="image_cover" alt="Image" width="256" height="192" src="https://www.copetti.org/images/consoles/mastersystem/sonic/sprites.707537651fd6e5ce0ebcca7c4192748e4389797ebbcff4c1ddb4939cb8271e44.png" loading="auto"></picture></a><figcaption>Rendered Sprite layer</figcaption></div><p>Sprites are just tiles that move freely. The VDP can raster <strong>up to 64 sprites</strong> using a single tile (8x8 px) or two tiles stacked vertically (8x16 px).</p><p>The <strong>Sprite Attribute Table</strong> is a 256-byte area in VRAM that contains an array of all the sprites defined, its entries are similar to the background layer, except each sprite contain two additional values representing the X/Y coordinates.</p><p>The VDP is limited to <strong>up to eight sprites per horizontal scan-line</strong>. Also, if two sprites overlap, the last one in the list will be the one displayed.</p></div><div id="tab-2-4-result"><h4>Result</h4><div><a href="https://www.copetti.org/images/consoles/mastersystem/sonic/result.f37a1b0bb0f463acd33bdd04cc53b65c0504e26615bbe9a20f29533217601437.png"><picture>
<img name="image_cover" alt="Image" width="256" height="192" src="https://www.copetti.org/images/consoles/mastersystem/sonic/result.f37a1b0bb0f463acd33bdd04cc53b65c0504e26615bbe9a20f29533217601437.png" loading="auto"></picture></a><figcaption>Tada!</figcaption></div><p>The VDP automatically blends the two layers to form the final frame. The rendering process is done scan-line by scan-line, so the VDP doesn’t really know how the frame is going too look, that’s only seen by the user when the picture is constructed on the TV.</p><p>If you look at the example image, you may notice the frame has a vertical column at the left side. This is because the screen map is only tall enough to provide vertical scrolling without producing artefacts, <strong>but not wide enough for horizontal scrolling</strong>. So, the VDP can <strong>mask</strong> the left-most side with an 8 px column to protect the image from showing intermediate tiles.</p><p>To update the graphics for the next frame without breaking the image currently being displayed, the VDP sends two types of <strong>interrupts</strong> to the CPU. One which notifies that the CRT TV has finished beaming a chosen number of scan-lines (called <strong>horizontal interrupt</strong>) and another when the CRT finished drawing the last scan-line (called <strong>vertical interrupt</strong>) indicating the frame is finished. During those events, the CRT’s beam is re-allocating to draw the next scan-line (<strong>blanking interval</strong>), so any alteration of the VDP’s state won’t tear the image down. Horizontal blanking has a shorter time-frame than vertical blanking, yet it still allows to change, let’s say, the colour palette. This still can achieve some effects.</p></div></div></div><h4 id="secrets-and-limitation">Secrets and limitation</h4><p>At first glance, the VDP may seem like another chip with minimal functionality that we now take for …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.copetti.org/projects/consoles/master-system/">https://www.copetti.org/projects/consoles/master-system/</a></em></p>]]>
            </description>
            <link>https://www.copetti.org/projects/consoles/master-system/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24775305</guid>
            <pubDate>Wed, 14 Oct 2020 11:14:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Visidata 2.0]]>
            </title>
            <description>
<![CDATA[
Score 186 | Comments 20 (<a href="https://news.ycombinator.com/item?id=24774947">thread link</a>) | @polm23
<br/>
October 14, 2020 | https://www.visidata.org/blog/2020/v2.0/ | <a href="https://web.archive.org/web/*/https://www.visidata.org/blog/2020/v2.0/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section id="body">
        
<p>This is a major milestone. After almost 2 years of development, version 2.0 of VisiData is finally released. It's got several major improvements, a bunch of new loaders, and tons of new features and quality of life improvements. And, most importantly, an API specification for plugins.</p>
<h2>1. Licensing Changes</h2>
<p>[tl;dr: no more MIT vdtui; GPL3 for everything]</p>
<p>Previously, there was a core vdtui single-file library that I licensed as MIT, as I thought it might be a platform for a variety of apps like VisiData. Approximately no one showed interest in that though, and it became unwieldy to maintain, so over the course of developing VisiData 2.0, the vdtui library was thoroughly dismantled. It's now just the visidata module as a whole, which I'm releasing under GPL3. The last released version of vdtui.py under MIT was 1.5.2 if anyone wants to use that.</p>
<h2>2. Plugin API</h2>
<p>[tl;dr: "2.0" has a stable documented API; expect a growing ecosystem of plugins for a wide variety of use cases.]</p>
<p>To be honest, this is what held off the 2.0 release for so long. I knew I wanted to go through every function and decide whether I wanted to include it in the 2.0 API to be supported for the rest of the 2.x lifecycle, which might be years. (We don't intend to strictly adhere to "semver", but it's still important to try to maintain backwards compatibility within a major version number.) So now, we have an API spec with over 200 functions, which will be of interest if you want to customize VisiData, or create a plugin for it, or just to know more about its internal components.</p>
<p>Take a look at the actual API, at <a href="https://visidata.org/docs/api">visidata.org/docs/api</a>. It still needs a bit more polish, but the meat and bones are there.</p>
<h2>3. Undo and Redo</h2>
<p>This is a "game changer" according to @jsvine.</p>
<p>Undo and redo, along with the new <code>guard-sheet</code> command, make it much easier to rely on VisiData for data cleaning and data entry.</p>
<p>If you upgrade to 2.0 and learn nothing else about it, your life will be better for knowing Shift+U (undo) and Shift+R (redo).</p>
<h2>4. Deferred modifications</h2>
<p>[tl;dr: if you add/edit/delete rows on a few specific sheets, the changes won't take place right away; you'll have to press z Ctrl+S]</p>
<p>Certain sheets which know how to incrementally update their source--notably, the DirSheet and SqliteSheet--<strong>defer</strong> changes made to them, requiring an explicit save/commit step with commit-sheet (z Ctrl+S).</p>
<p>These changes are colorized on the screen and can be saved as data (or not saved, in the case of deletes) with save-sheet (Ctrl+S), even if they haven't been committed back to the original source with commit-sheet.</p>
<p>This means vd can work quite naturally as an interactive file manager, or as a sqlite database editor. I've been using it to manage my mp3 collection and my personal contacts database, which was a tsv file until I wanted to add a multiline "notes" field, so I saved it as a .json file and used that for a few months, and now I've been using it in an sqlite database. Of course they all look the same in VisiData so I can go back and forth without any friction.</p>
<h2>5. Split Window</h2>
<p>Press Shift+Z to split the terminal window into a top panel and bottom panel.</p>
<p>One panel contains the current/top sheet, the other panel contains the sheet "under" the top sheet. Press Tab or Ctrl+^ to go between them.</p>
<p>The fancy chooser (now the default for choosing aggregators or jointypes) uses this split window, and I have many other ideas for it as well.</p>
<p>It may not seem like much now, but I predict that this becomes a sleeper hit.</p>
<p>[previously blogged at: <a href="https://visidata.org/blog/2020/splitwin">visidata.org/blog/2020/splitwin</a>)]</p>
<h2>6. So many other features</h2>
<p>Here's curated list of highlights, the ones that seemed like people would be interested to know about:</p>
<ul>
<li>more visibility for long values, with "v" to toggle multi-line rows and and z+hjkl to adjust cell offset</li>
<li>[iota] the "i" family of commands to add an increment column</li>
<li>[unfurl] zM, which does row-wise expansion of iterables in a column (very useful with nested data)</li>
<li>[join] add "merge" jointype</li>
<li>[numeric binning] ranged binning for numeric columns</li>
<li>[cli] custom options parsing allows for per-sheet options</li>
<li>[cli] pipe and redirect to stdout; use as an interactive chooser</li>
<li>[input] Ctrl+Y paste from cell clipboard and other improvements</li>
<li>Alt+ as new keyboard layer for user keybindings</li>
</ul>
<p>And, as with every release, there are a bunch of new loaders, including MIME, recutils, vcard, imap, mysql, pdf, npy/npz, and more! See the new <a href="https://visidata.org/formats">/formats</a> page for a full list of supported formats, in tidy tabular form.</p>
<p>Then if you still haven't seen enough, you can see the <a href="https://github.com/saulpw/visidata/blob/stable/CHANGELOG.md#v2.0">CHANGELOG</a> for the complete list of bugfixes and changes.</p>
<p>Okay, that about wraps it up for this release. If anything I've written about here sounds interesting and you'd like me to cover it first, or more in-depth, let me know! Send me <a href="https://www.visidata.org/blog/2020/v2.0/vd@saul.pw">an email</a>, or <a href="https://www.visidata.org/blog/2020/v2.0/twitter.com/VisiData">tweet @VisiData</a>, or <a href="https://www.visidata.org/blog/2020/v2.0/github.com/saulpw/visidata/issues">open a github issue</a>, or chat with us on Freenode #visidata; however you want to get in touch, we'd love to hear from you.</p>

     </section></div>]]>
            </description>
            <link>https://www.visidata.org/blog/2020/v2.0/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24774947</guid>
            <pubDate>Wed, 14 Oct 2020 10:02:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Prefer Fakes over Mocks]]>
            </title>
            <description>
<![CDATA[
Score 96 | Comments 113 (<a href="https://news.ycombinator.com/item?id=24770954">thread link</a>) | @oftenwrong
<br/>
October 13, 2020 | https://tyrrrz.me/blog/fakes-over-mocks | <a href="https://web.archive.org/web/*/https://tyrrrz.me/blog/fakes-over-mocks">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><p>The primary purpose of software testing is to detect any potential defects in a program before it reaches its intended consumers. This is typically achieved by establishing functional requirements which define supported user interactions as well as expected outcomes, and then validating them using (automated) tests.</p>
<p>Consequentially, the value provided by such tests is directly dependent on how well the scenarios they simulate resemble the way the software is actually used. Any deviation therein diminishes that value, as it becomes harder to reason about the state of the would-be production system based on the result of a test run.</p>
<p>In an ideal world, our test scenarios, including the environment they execute in, should perfectly match real-life conditions. This is always desirable, but might not always be practical, as the system can rely on components that are difficult to test with, either because they are not available or because their behavior is inconsistent or slow.</p>
<p>A common practice in cases like this is to replace such dependencies with lightweight substitutes that act as <em>test doubles</em>. Although doing so does lead to lower confidence, it’s often an unavoidable trade-off when it comes to designing a robust and consistent test suite.</p>
<p>That said, while test doubles can be implemented in different ways, most of the time developers tend to resort to <em>mocking</em> as the default choice. This is unfortunate, as it leads to overuse of mocks where other forms of substitutes are typically more suitable, making tests <a href="https://en.wikipedia.org/wiki/Mock_object#Limitations">implementation-aware and fragile</a> as a result.</p>
<p>When writing tests, I prefer to avoid mocks as much as possible and rely on <em>fake</em> implementations instead. They require a bit of additional upfront investment, but provide many practical advantages which are important to consider.</p>
<p>In this article we will look at the differences between these two variants of test doubles, identify how using one over the other impacts test design, and why using fakes often results in more manageable test suites.</p>
<h2>Drawbacks of mocking</h2>
<p>As we enter the realm of software terminology, words slowly start to lose their meaning. Testing jargon is exceptionally notorious in this regard, as it always seems to create a lot of uncertainty among developers.</p>
<p>Unsurprisingly, the concept of “mock” or how it’s fundamentally different from other types of substitutes is also one of those cases. Despite its highly ubiquitous usage, this term <a href="https://stackoverflow.com/questions/346372/whats-the-difference-between-faking-mocking-and-stubbing">doesn’t have a single universally accepted interpretation</a>.</p>
<p>According to the <a href="https://martinfowler.com/bliki/TestDouble.html">original definitions introduced by Gerard Meszaros</a>, a mock is a very specific type of substitutes which is used to verify interactions between the system under test and its dependencies. Nowadays, however, the distinction has become a bit blurry, as this term is commonly used to refer to a broader class of objects created with frameworks such as <a href="https://github.com/moq/moq4">Moq</a>, <a href="https://github.com/mockito/mockito">Mockito</a>, <a href="https://github.com/facebook/jest">Jest</a>, and others.</p>
<p>Such substitutes may not necessarily be mocks under the original definition, but there’s very little benefit in acknowledging these technicalities. So to make matters simpler, we will stick to this more colloquial understanding of the term throughout the article.</p>
<p>Generally speaking, a <strong>mock is a substitute, that pretends to function like its real counterpart, but returns predefined responses instead</strong>. From a structural standpoint, it does implement the same external interface as the actual component, however that <strong>implementation is entirely superficial</strong>.</p>
<p>In fact, <strong>a mock is not intended to have valid functionality at all</strong>. Its purpose is rather to mimic the outcomes of various operations, so that the system under test exercises the behavior required by a given scenario.</p>
<p>Besides that, <strong>mocks can also be used to verify side-effects</strong> that take place within the system. This is achieved by recording method calls and checking if the number of times they appear and their parameters match the expectations.</p>
<p>Let’s take a look at how all of this works in practice. As an example, imagine that we’re building a system that relies on some binary file storage represented by the following interface:</p>
<div data-language="csharp"><pre><code><span>public</span> <span>interface</span> <span>IBlobStorage</span>
<span>{</span>
    <span>Task<span>&lt;</span>Stream<span>&gt;</span></span> <span>ReadFileAsync</span><span>(</span><span><span>string</span></span> fileName<span>)</span><span>;</span>

    <span>Task</span> <span>DownloadFileAsync</span><span>(</span><span><span>string</span></span> fileName<span>,</span> <span><span>string</span></span> outputFilePath<span>)</span><span>;</span>

    <span>Task</span> <span>UploadFileAsync</span><span>(</span><span><span>string</span></span> fileName<span>,</span> <span>Stream</span> stream<span>)</span><span>;</span>

    <span>Task</span> <span>UploadManyFilesAsync</span><span>(</span><span>IReadOnlyDictionary<span>&lt;</span><span>string</span><span>,</span> Stream<span>&gt;</span></span> fileNameStreamMap<span>)</span><span>;</span>
<span>}</span></code></pre></div>
<p>As we can see, it provides basic operations to read and upload files, as well as a few more specialized methods. The actual implementation of the above abstraction does not concern us, but for the sake of complexity we can pretend that it relies on some expensive cloud vendor and doesn’t lend itself well for testing.</p>
<p>Built on top of it, we also have another component which is responsible for loading and saving text documents:</p>
<div data-language="csharp"><pre><code><span>public</span> <span>class</span> <span>DocumentManager</span>
<span>{</span>
    <span>private</span> <span>readonly</span> <span>IBlobStorage</span> _storage<span>;</span>

    <span>public</span> <span>DocumentManager</span><span>(</span><span>IBlobStorage</span> storage<span>)</span> <span>=&gt;</span>
        _storage <span>=</span> storage<span>;</span>

    <span>private</span> <span>static</span> <span><span>string</span></span> <span>GetFileName</span><span>(</span><span><span>string</span></span> documentName<span>)</span> <span>=&gt;</span>
        <span><span>$"docs/</span><span><span>{</span><span>documentName</span><span>}</span></span><span>"</span></span><span>;</span>

    <span>public</span> <span>async</span> <span>Task<span>&lt;</span><span>string</span><span>&gt;</span></span> <span>GetDocumentAsync</span><span>(</span><span><span>string</span></span> documentName<span>)</span>
    <span>{</span>
        <span><span>var</span></span> fileName <span>=</span> <span>GetFileName</span><span>(</span>documentName<span>)</span><span>;</span>

        <span>await</span> <span>using</span> <span><span>var</span></span> stream <span>=</span> <span>await</span> _storage<span>.</span><span>ReadFileAsync</span><span>(</span>fileName<span>)</span><span>;</span>
        <span>using</span> <span><span>var</span></span> streamReader <span>=</span> <span>new</span> <span>StreamReader</span><span>(</span>stream<span>)</span><span>;</span>

        <span>return</span> <span>await</span> streamReader<span>.</span><span>ReadToEndAsync</span><span>(</span><span>)</span><span>;</span>
    <span>}</span>

    <span>public</span> <span>async</span> <span>Task</span> <span>SaveDocumentAsync</span><span>(</span><span><span>string</span></span> documentName<span>,</span> <span><span>string</span></span> content<span>)</span>
    <span>{</span>
        <span><span>var</span></span> fileName <span>=</span> <span>GetFileName</span><span>(</span>documentName<span>)</span><span>;</span>

        <span><span>var</span></span> data <span>=</span> Encoding<span>.</span>UTF8<span>.</span><span>GetBytes</span><span>(</span>content<span>)</span><span>;</span>
        <span>await</span> <span>using</span> <span><span>var</span></span> stream <span>=</span> <span>new</span> <span>MemoryStream</span><span>(</span>data<span>)</span><span>;</span>

        <span>await</span> _storage<span>.</span><span>UploadFileAsync</span><span>(</span>fileName<span>,</span> stream<span>)</span><span>;</span>
    <span>}</span>
<span>}</span></code></pre></div>
<p>This class gives us an abstraction over raw file access and exposes methods that work with text content directly. Its implementation is not particularly complex, but let’s imagine we want to test it anyway.</p>
<p>As we’ve identified earlier, using the real implementation of <code>IBlobStorage</code> in our tests would be troublesome, so we have to resort to test doubles. One of the simpler ways to approach this is, of course, by creating mock implementations:</p>
<div data-language="csharp"><pre><code><span>[</span><span><span>Fact</span></span><span>]</span>
<span>public</span> <span>async</span> <span>Task</span> <span>I_can_get_the_content_of_an_existing_document</span><span>(</span><span>)</span>
<span>{</span>
    
    <span>await</span> <span>using</span> <span><span>var</span></span> documentStream <span>=</span> <span>new</span> <span>MemoryStream</span><span>(</span>
        <span>new</span> <span><span>byte</span><span>[</span><span>]</span></span> <span>{</span><span>0x68</span><span>,</span> <span>0x65</span><span>,</span> <span>0x6c</span><span>,</span> <span>0x6c</span><span>,</span> <span>0x6f</span><span>}</span>
    <span>)</span><span>;</span>

    <span><span>var</span></span> blobStorage <span>=</span> Mock<span>.</span><span><span>Of</span><span><span>&lt;</span>IBlobStorage<span>&gt;</span></span></span><span>(</span><span>)</span><span>;</span>

    Mock<span>.</span><span>Get</span><span>(</span>blobStorage<span>)</span>
        <span>.</span><span>Setup</span><span>(</span>bs <span>=&gt;</span> bs<span>.</span><span>ReadFileAsync</span><span>(</span><span>"docs/test.txt"</span><span>)</span><span>)</span>
        <span>.</span><span>ReturnsAsync</span><span>(</span>documentStream<span>)</span><span>;</span>

    <span><span>var</span></span> documentManager <span>=</span> <span>new</span> <span>DocumentManager</span><span>(</span>blobStorage<span>)</span><span>;</span>

    
    <span><span>var</span></span> content <span>=</span> <span>await</span> documentManager<span>.</span><span>GetDocumentAsync</span><span>(</span><span>"test.txt"</span><span>)</span><span>;</span>

    
    content<span>.</span><span>Should</span><span>(</span><span>)</span><span>.</span><span>Be</span><span>(</span><span>"hello"</span><span>)</span><span>;</span>
<span>}</span>

<span>[</span><span><span>Fact</span></span><span>]</span>
<span>public</span> <span>async</span> <span>Task</span> <span>I_can_update_the_content_of_a_document</span><span>(</span><span>)</span>
<span>{</span>
    
    <span><span>var</span></span> blobStorage <span>=</span> Mock<span>.</span><span><span>Of</span><span><span>&lt;</span>IBlobStorage<span>&gt;</span></span></span><span>(</span><span>)</span><span>;</span>
    <span><span>var</span></span> documentManager <span>=</span> <span>new</span> <span>DocumentManager</span><span>(</span>blobStorage<span>)</span><span>;</span>

    
    <span>await</span> documentManager<span>.</span><span>SaveDocumentAsync</span><span>(</span><span>"test.txt"</span><span>,</span> <span>"hello"</span><span>)</span><span>;</span>

    
    Mock<span>.</span><span>Get</span><span>(</span>blobStorage<span>)</span><span>.</span><span>Verify</span><span>(</span>bs <span>=&gt;</span> bs<span>.</span><span>UploadFileAsync</span><span>(</span>
        <span>"docs/test.txt"</span><span>,</span>
        It<span>.</span><span><span>Is</span><span><span>&lt;</span>Stream<span>&gt;</span></span></span><span>(</span>s <span>=&gt;</span> <span>)</span>
    <span>)</span><span>)</span><span>;</span>
<span>}</span></code></pre></div>
<p>In the above code snippet, the first test attempts to verify that the consumer can retrieve a document, given it already exists in the storage. To facilitate this precondition, we configure the mock in such way that it returns a hardcoded byte stream when <code>ReadFileAsync()</code> is called with the expected file name.</p>
<p>However, in doing so, we are inadvertently making a few very strong assumptions about how <code>DocumentManager</code> works under the hood. Namely, we assume that:</p>
<ul>
<li>Calling <code>GetDocumentAsync()</code> in turn calls <code>ReadFileAsync()</code></li>
<li>File name is formed by prepending <code>docs/</code> to the name of the document</li>
</ul>
<p>These specifics may be true now, but they can easily change in the future. For example, it’s not a stretch to imagine that we may decide to store files under a different path or replace the call to <code>ReadFileAsync()</code> with <code>DownloadFileAsync()</code>, as a means to preemptively cache files locally.</p>
<p>In both cases, the changes in the implementation won’t be observable from the user perspective as the surface-level behavior will remain the same. However, because the test we wrote relies on internal details of the system, it will start failing, indicating that there’s an error in our code, when in reality there isn’t.</p>
<p>The second scenario works a bit differently, but also suffers from the same issue. To verify that a document is correctly persisted in the storage when it gets saved, it checks that a call to <code>UploadFileAsync()</code> takes place in the process.</p>
<p>Again, it’s not hard to imagine a situation where the underlying implementation can change in way that breaks this test. For example, we may decide to optimize the behavior slightly by not uploading the documents straight away, but instead keeping them in memory and sending in batches using <code>UploadManyFilesAsync()</code>.</p>
<p>An experienced mocking practitioner might argue that some of these shortcomings can be mitigated if we configure our mocks to be less strict. In this instance, we can modify the test so it expects a call to any of the upload methods rather than a specific one, while also not checking the parameters at all:</p>
<div data-language="csharp"><pre><code><span>[</span><span><span>Fact</span></span><span>]</span>
<span>public</span> <span>async</span> <span>Task</span> <span>I_can_update_the_content_of_a_document</span><span>(</span><span>)</span>
<span>{</span>
    
    <span><span>var</span></span> eitherUploadMethodCalled <span>=</span> <span>false</span><span>;</span>

    <span><span>var</span></span> blobStorage <span>=</span> Mock<span>.</span><span><span>Of</span><span><span>&lt;</span>IBlobStorage<span>&gt;</span></span></span><span>(</span><span>)</span><span>;</span>

    Mock<span>.</span><span>Get</span><span>(</span>blobStorage<span>)</span><span>.</span><span>Setup</span><span>(</span>bs <span>=&gt;</span> bs<span>.</span><span>UploadFileAsync</span><span>(</span>
        It<span>.</span><span><span>IsAny</span><span><span>&lt;</span><span>string</span><span>&gt;</span></span></span><span>(</span><span>)</span><span>,</span> 
        It<span>.</span><span><span>IsAny</span><span><span>&lt;</span>Stream<span>&gt;</span></span></span><span>(</span><span>)</span>  
    <span>)</span><span>)</span><span>.</span><span>Callback</span><span>(</span><span>(</span><span>)</span> <span>=&gt;</span> eitherUploadMethodCalled <span>=</span> <span>true</span><span>)</span><span>;</span>

    Mock<span>.</span><span>Get</span><span>(</span>blobStorage<span>)</span><span>.</span><span>Setup</span><span>(</span>bs <span>=&gt;</span> bs<span>.</span><span>UploadManyFilesAsync</span><span>(</span>
        
        It<span>.</span><span><span>IsAny</span><span><span>&lt;</span>IReadOnlyDictionary<span>&lt;</span><span>string</span><span>,</span> Stream<span>&gt;</span><span>&gt;</span></span></span><span>(</span><span>)</span>
    <span>)</span><span>)</span><span>.</span><span>Callback</span><span>(</span><span>(</span><span>)</span> <span>=&gt;</span> eitherUploadMethodCalled <span>=</span> <span>true</span><span>)</span><span>;</span>

    <span><span>var</span></span> documentManager <span>=</span> <span>new</span> <span>DocumentManager</span><span>(</span>blobStorage<span>)</span><span>;</span>

    
    <span>await</span> documentManager<span>.</span><span>SaveDocumentAsync</span><span>(</span><span>"test.txt"</span><span>,</span> <span>"hello"</span><span>)</span><span>;</span>

    
    eitherUploadMethodCalled<span>.</span><span>Should</span><span>(</span><span>)</span><span>.</span><span>BeTrue</span><span>(</span><span>)</span><span>;</span>
<span>}</span></code></pre></div>
<p>The mocking framework we’re using (<a href="https://github.com/Moq/moq4">Moq</a>) doesn’t allow us to directly verify that either one of the given methods was called, so we need a workaround. To do this, …</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://tyrrrz.me/blog/fakes-over-mocks">https://tyrrrz.me/blog/fakes-over-mocks</a></em></p>]]>
            </description>
            <link>https://tyrrrz.me/blog/fakes-over-mocks</link>
            <guid isPermaLink="false">hacker-news-small-sites-24770954</guid>
            <pubDate>Tue, 13 Oct 2020 22:16:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Review of Consensus Protocols]]>
            </title>
            <description>
<![CDATA[
Score 118 | Comments 43 (<a href="https://news.ycombinator.com/item?id=24768971">thread link</a>) | @tcgv
<br/>
October 13, 2020 | https://thomasvilhena.com/2020/10/a-review-of-consensus-protocols | <a href="https://web.archive.org/web/*/https://thomasvilhena.com/2020/10/a-review-of-consensus-protocols">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <p>The consensus problem is a fundamental problem in multi-agent systems which requires a group of processes (or agents) to reliably and timely agree on a single data value. Although extensively discussed in the context of distributed computing it’s not exclusive to this field, also being present in our society in a variety of situations such as in democratic elections, the legislative process, jury trial proceedings, and so forth.</p>

<p>It’s solved through the employment of a consensus protocol governing how processes (agents) interact with one another. It may seem redundant but, to solve the consensus problem, first all processes agree to follow the same consensus protocol.</p>

<p>Some of these processes may fail or be unreliable in other ways (such as in a conflict of interest situation) so consensus protocols must be fault tolerant or resilient. The processes must somehow propose their candidate values, communicate with one another, and decide on a single consensus value.</p>

<p>In this post I review four major consensus protocols for solving the consensus problem based on my implementation of them, namely:</p>

<ol>
  <li>Chandra–Toueg</li>
  <li>Ben-Or</li>
  <li>Basic Paxos</li>
  <li>Nakamoto Consensus</li>
</ol>

<p>You can find supporting code for this analysis in this GitHub repository: <a href="https://github.com/TCGV/ConsensusKit">ConsensusKit</a></p>

<p>Before getting started let’s recap the three key properties of consensus protocols and take a quick look at relevant terminology for this discussion.</p>



<p>Formally a consensus protocol must satisfy the following three properties:</p>

<p><b>Termination</b></p>

<ul>
  <li>Eventually, every correct process decides some value.</li>
</ul>

<p><b>Integrity</b></p>

<ul>
  <li>If all the correct processes proposed the same value “v”, then any correct process must decide “v”.</li>
</ul>

<p><b>Agreement</b></p>

<ul>
  <li>Every correct process must agree on the same value.</li>
</ul>

<p>These requirements are rather straight forward. “Termination” certifies the protocol is resilient to halting failures. “Agreement” deters any two correct processes from deciding on different values which would break consensus. Lastly “Integrity”, which is in fact flexible and may vary depending on application requirements, assures the protocol behaves in an expected and unbiased way.</p>



<p>These terms are used throughout this post as well within the provided support source code.</p>

<h4>Protocol</h4>

<p>The official set of rules (“algorithm”) governing the behavior of processes for solving the consensus problem.</p>

<h4>Process</h4>

<p>An individual agent belonging to a larger group of agents collectively interested in reaching consensus. Processes can be “correct”, meaning they strictly adhere to the protocol and are not subject to failures, or “faulty”, meaning we cannot rely on them following the protocol at all times.</p>

<h4>Instance</h4>

<p>A well-defined round of interactions among processes under a consensus protocol. Depending on the underlying protocol one or multiple intances are required for reaching consensus.</p>

<h4>Proposer</h4>

<p>A process role. Processes under this role are entitled for proposing values. Any value agreed upon by all correct processes must have originated in a proposer.</p>

<h4>Decider</h4>

<p>A process role. Processes under this role are entitled for deciding on a value. Any value agreed upon by all correct processes must have been voted by at least one decider.</p>

<h4>Archiver</h4>

<p>An application or a subsystem that is responsible for persisting decided values and implementing a protocol’s specific data constraints.</p>

<h4>Failure detector</h4>

<p>An application or a subsystem that is responsible for the detection of node failures or crashes.</p>

<h4>Majority</h4>

<p>A protocol’s specific threshold requiring at least half of available votes, more when faulty processes are taken into account.</p>

<h4>Quorum</h4>

<p>A protocol’s specific threshold which ensures that a minimum number of participants (or votes) is met for taking an action.</p>

<p>With these definitions in place let’s move on to the implementation and review of each consensus protocol.</p>



<p>My main goal has been to implement these four protocols in code to be able to run and evaluate them in a controlled environment. I was also interested in trying to spot structural similarities among them that could be extracted into a common base structure, promoting code reuse.</p>

<p>The result of my first coding iteration is displayed in the simplified class diagram below:</p>

<p>
  <img src="https://thomasvilhena.com/images/p22/main-classes.PNG" alt="Main Clasees">
</p>

<p>Three main classes are depicted in the diagram:</p>

<ul>
  <li>The <b>Procotol</b> class has a collection of processes that will interact among each other according to the protocol rules for reaching consensus. Each execution of the protocol, through the <code>Execute</code> method, creates a new Instance (not to be confused with the conventional meaning of “instance” in object oriented programming).</li>
  <li>The <b>Instance</b> class represents one round of interactions among processes potentially resulting in a consensus, as indicated by the <code>Consensus</code> and <code>Value</code> properties. It’s responsible for managing the interaction between processes exercicing proposer and/or decider roles, providing methods for message delivery (<code>Send</code>) and retrieval (<code>WaitMessage</code> and <code>WaitQuorum</code>).</li>
  <li>The <b>Process</b> class is responsible for implementing proposer and/or decider roles. Behavior is defined in the <code>Bind</code> method just before the instance starts since, as well see, some protocols require processes to play different roles according the the current instance.</li>
</ul>

<p>The <code>Process.Propose</code> virtual method is called at the start of an instance execution for all proposer processes in that instance to kick off communication and has the following default implementation:</p>

<div><div><pre><code>
<span>protected</span> <span>virtual</span> <span>void</span> <span>Propose</span><span>(</span><span>Instance</span> <span>r</span><span>)</span>
<span>{</span>
    <span>var</span> <span>v</span> <span>=</span> <span>Proposer</span><span>.</span><span>GetProposal</span><span>();</span>
    <span>if</span> <span>(</span><span>Archiver</span><span>.</span><span>CanCommit</span><span>(</span><span>v</span><span>))</span>
        <span>Broadcast</span><span>(</span><span>r</span><span>,</span> <span>MessageType</span><span>.</span><span>Propose</span><span>,</span> <span>v</span><span>);</span>
<span>}</span>

</code></pre></div></div>

<p>It first generates a proposal based on the underlying proposer logic (ex: random boolean proposer), then verifies against an archiver if the generated value passes custom application requirements and finally broadcasts it to all sibling processes.</p>

<p>Processes that bind to the <code>Instance.WaitQuorum</code> event will wait for the protocol specific amount of messages (for each message type) required for taking an action. The specific amounts are defined in each protocol implementation when deriving the Instance class.</p>

<p>All four consensus protocols were implemented using this base structure, as presented in the following sections. Rather than performing an extensive code analysis I will focus on presenting each theoretical algorithm and key points of my implementation.</p>



<p>The Chandra–Toueg consensus algorithm was first published by Tushar Deepak Chandra and Sam Toueg in 1996 and introduced the concept of failure detectors as means for solving the consensus problem. The algorithm assumes a number of faulty processes denoted by <b>f</b> that’s less than <b>n/2</b> (i.e. less than simple majority).</p>

<p>In each instance one process acts as the decider (rotating coordinator) and all other processes act as proposers. The actions carried out in each instance are<sup>1</sup>:</p>

<ol>
  <li>All processes send (r, preference, timestamp) to the coordinator.</li>
  <li>The coordinator waits to receive messages from at least half of the processes (including itself).
    <ol>
      <li>It then chooses as its preference a value with the most recent timestamp among those sent.</li>
    </ol>
  </li>
  <li>The coordinator sends (r, preference) to all processes.</li>
  <li>Each process waits (1) to receive (r, preference) from the coordinator, or (2) for its failure detector to identify the coordinator as crashed.
    <ol>
      <li>In the first case, it sets its own preference to the coordinator’s preference and responds with ack(r).</li>
      <li>In the second case, it sends nack(r) to the coordinator.</li>
    </ol>
  </li>
  <li>The coordinator waits to receive ack(r) or nack(r) from a majority of processes.
    <ol>
      <li>If it receives ack(r) from a majority, it sends decide(preference) to all processes.</li>
    </ol>
  </li>
  <li>Any process that receives decide(preference) for the first time relays decide(preference) to all processes, then decides preference and terminates.</li>
</ol>

<p>Let’s take a look at the code. The following code snippet defines the proposer process behavior:</p>

<div><div><pre><code>
<span>private</span> <span>void</span> <span>BindAsProposer</span><span>(</span><span>Instance</span> <span>r</span><span>)</span>
<span>{</span>
    <span>WaitQuorum</span><span>(</span><span>r</span><span>,</span> <span>MessageType</span><span>.</span><span>Select</span><span>,</span> <span>msgs</span> <span>=&gt;</span>
    <span>{</span>
        <span>var</span> <span>m</span> <span>=</span> <span>msgs</span><span>.</span><span>Single</span><span>();</span>
        <span>SendTo</span><span>(</span><span>m</span><span>.</span><span>Source</span><span>,</span> <span>r</span><span>,</span> <span>MessageType</span><span>.</span><span>Ack</span><span>,</span> <span>m</span><span>.</span><span>Value</span><span>);</span>
    <span>});</span>

    <span>WaitQuorum</span><span>(</span><span>r</span><span>,</span> <span>MessageType</span><span>.</span><span>Decide</span><span>,</span> <span>msgs</span> <span>=&gt;</span>
    <span>{</span>
        <span>var</span> <span>v</span> <span>=</span> <span>msgs</span><span>.</span><span>Single</span><span>().</span><span>Value</span><span>;</span>
        <span>Terminate</span><span>(</span><span>r</span><span>,</span> <span>v</span><span>);</span>
    <span>});</span>
<span>}</span>

</code></pre></div></div>

<p>On instance start proposers broadcast their values. Then they wait for a quorum to select a value from the pool of proposals. Since the protocol defines only a single decider per round this quorum is met when the decider process broadcasts his selection. Upon receiving this selection the proposer node will acknowledge it and wait for the decider’s decision, and then decide on the same value and terminate execution.</p>

<p>Now let’s see the code defining the complementary decider processes behavior:</p>

<div><div><pre><code>
<span>private</span> <span>void</span> <span>BindAsCoordinator</span><span>(</span><span>Instance</span> <span>r</span><span>)</span>
<span>{</span>
    <span>WaitQuorum</span><span>(</span><span>r</span><span>,</span> <span>MessageType</span><span>.</span><span>Propose</span><span>,</span> <span>msgs</span> <span>=&gt;</span>
    <span>{</span>
        <span>var</span> <span>v</span> <span>=</span> <span>PickMostRecentValue</span><span>(</span>
            <span>msgs</span><span>.</span><span>Where</span><span>(</span><span>m</span> <span>=&gt;</span> <span>Archiver</span><span>.</span><span>CanCommit</span><span>(</span><span>m</span><span>.</span><span>Value</span><span>))</span>
        <span>);</span>

        <span>Broadcast</span><span>(</span><span>r</span><span>,</span> <span>MessageType</span><span>.</span><span>Select</span><span>,</span> <span>v</span><span>);</span>
    <span>});</span>

    <span>WaitQuorum</span><span>(</span><span>r</span><span>,</span> <span>MessageType</span><span>.</span><span>Ack</span><span>,</span> <span>msgs</span> <span>=&gt;</span>
    <span>{</span>
        <span>var</span> <span>v</span> <span>=</span> <span>PickMostRecentValue</span><span>(</span><span>msgs</span><span>);</span>
        <span>Broadcast</span><span>(</span><span>r</span><span>,</span> <span>MessageType</span><span>.</span><span>Decide</span><span>,</span> <span>v</span><span>);</span>
        <span>Terminate</span><span>(</span><span>r</span><span>,</span> <span>v</span><span>);</span>
    <span>});</span>
<span>}</span>

</code></pre></div></div>

<p>It first waits for a quorum of proposals, i.e, for a simple majority of proposers to submit their values. Then the decider picks the most recent message value, possibly validating the value with the archiver, and broadcasts the selected value back to all processes.</p>

<p>After broadcasting the selected value the decider waits for a quorum of proposers to acknowledge it, in which case it decides on that value and broadcasts its decision to all processes before terminating.</p>

<p>Notice that this simplified implementation doesn’t take failures into account, even though the Chandra–Toueg protocol is fault-resilient.</p>



<p>Ben-Or is a decentralized consensus protocol, i.e., it doesn’t assign the decider role to any specific process. Curiously the algorithm correctness proof was only provided in a paper 15 years after its original publication<sup>2</sup>.</p>

<p>Because it lacks a decider for solving tie-break …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://thomasvilhena.com/2020/10/a-review-of-consensus-protocols">https://thomasvilhena.com/2020/10/a-review-of-consensus-protocols</a></em></p>]]>
            </description>
            <link>https://thomasvilhena.com/2020/10/a-review-of-consensus-protocols</link>
            <guid isPermaLink="false">hacker-news-small-sites-24768971</guid>
            <pubDate>Tue, 13 Oct 2020 19:03:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Norway officially accuses Russia for cyberattacks on parliament]]>
            </title>
            <description>
<![CDATA[
Score 193 | Comments 110 (<a href="https://news.ycombinator.com/item?id=24768344">thread link</a>) | @lknik
<br/>
October 13, 2020 | https://www.regjeringen.no/en/aktuelt/datainnbruddet-i-stortinget/id2770135/ | <a href="https://web.archive.org/web/*/https://www.regjeringen.no/en/aktuelt/datainnbruddet-i-stortinget/id2770135/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

        <header>
            

            

            



 
        </header>


<div>
    <p>
            <span>Press release |</span>
                    <span>Date: 13/10/2020</span>
            <span>
        | <a href="https://www.regjeringen.no/en/dep/ud/id833/">Ministry of Foreign Affairs</a>
    </span>

    </p>
    
    


</div>
        


            <p>
                    On 24 August, the Storting (Norwegian parliament) disclosed that its email systems had been hacked. ‘This is a very serious incident, affecting our most important democratic institution. The security and intelligence services are cooperating closely to deal with this matter at the national level. Based on the information the Government has, it is our view that Russia is responsible for these activities,’ said Minister of Foreign Affairs Ine Eriksen Søreide.
                </p>

        <div>

            



            
<p>The incident management is coordinated through the Norwegian Joint Cyber Coordination Centre.</p>
<p>This incident demonstrates the importance of good security measures. The increasing use of digital solutions means that the threats against us have also shifted to the digital arena. The Government will continue its efforts to strengthen national cyber security and expand international cooperation in this field.</p>
<p>Businesses, organisations, and private individuals must all participate in preventive security efforts if we are to prevent breaches of digital security. All types of organisations are advised to follow the recommendations of the Norwegian National Security Authority (NSM) regarding passwords and the basic guidelines for ICT security.</p>
<ul>
<li><a href="https://nsm.no/home/">Read more about the NSM here.</a>&nbsp;</li>
</ul>





                        
            
        </div>


    </div></div>]]>
            </description>
            <link>https://www.regjeringen.no/en/aktuelt/datainnbruddet-i-stortinget/id2770135/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24768344</guid>
            <pubDate>Tue, 13 Oct 2020 18:21:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[SEO mistakes I've made and how I fixed them]]>
            </title>
            <description>
<![CDATA[
Score 299 | Comments 123 (<a href="https://news.ycombinator.com/item?id=24766682">thread link</a>) | @MaximeHeckel
<br/>
October 13, 2020 | https://blog.maximeheckel.com/posts/seo-mistakes-i-have-made-and-how-i-fixed-them/ | <a href="https://web.archive.org/web/*/https://blog.maximeheckel.com/posts/seo-mistakes-i-have-made-and-how-i-fixed-them/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>From 0 to 90k impressions in about a year, following <strong>S</strong>earch <strong>E</strong>ngine <strong>O</strong>ptimization good practices was key to help to grow my blog and my audience. However, when I started it, <strong>I made terrible mistakes</strong> that some SEO literate people could almost qualify as self-sabotage.</p><p>Thus, I want to dedicate this blog post <strong>to look back at 3 issues</strong> that caused me, and many others, countless headaches when dealing with SEO and Gatsby and <strong>the steps I took to fix them</strong>. I hope that this will help to fix some issues you might currently have on your awesome blog or portfolio without even being aware of them, kick-off your audience growth, and get discovered online 🚀.</p><section id="why-seo-is-so-important-section"><h2 id="why-seo-is-so-important"><a href="#why-seo-is-so-important" aria-label="why seo is so important permalink"><svg style="width:0px;height:0px"></svg></a>Why SEO is so important?</h2><p>You might know very little about what SEO does behind the scenes. To me, at least, it looked like an obscure, inconsistent, pseudo-science that only marketing people could understand (spoiler alert, it still kind of is).
However, after getting <a href="https://twitter.com/monicalent">@monicalent</a>'s awesome course <a href="https://bloggingfordevs.com/">bloggingfordevs</a>, it made the inner workings and good practices related to SEO a bit clearer to me. To quote her from her first newsletter</p><blockquote><p>SEO is a way of making sure that search engines can understand what your page is about, that it contains quality up-to-date information from an authoritative source, and will answer the question that the searcher had in mind.</p></blockquote><p>With good SEO, search engines can know what your content is about, discover all the blog posts you've written and, if you're lucky, catapult you to the top search result for a given set of keywords. Moreover, where <strong>sharing my newest articles on Twitter and Reddit would just cause a spike in traffic for a few days</strong>, <strong>SEO helps you get a more consistent traffic</strong> on your website, and for a longer time. The latter is what I was lacking for the longest time, despite having set up my Gatsby website and SEO component properly (or at least I thought so).</p><p>Gatsby's documentation has an incredibly well-written section on <a href="https://www.gatsbyjs.com/tutorial/seo-and-social-sharing-cards-tutorial/">how to build an SEO component</a> to help you get started. However, that alone wasn't enough to make my blog discoverable early on, as you can see in the chart below representing the number of daily impressions I got since starting this blog:</p><figcaption>Chart representing the number of impressions per day of this blog on Google Search from August 2019 to the October 2020 (hover to see the data)</figcaption><p>For most of its first year, my blog was getting less than 50 daily impressions. <strong>Today</strong>, after fixing the issues I'm about to talk about, <strong>I get over 1000 daily impressions and it's still growing!</strong>
Of course, SEO is not the only component here, I also created more content this year and choose a better way to promote them, but it is still a significant driver to the growth you can see above.</p></section><section id="trailing-slashes-chaos-section"><h2 id="trailing-slashes-chaos"><a href="#trailing-slashes-chaos" aria-label="trailing slashes chaos permalink"><svg style="width:0px;height:0px"></svg></a>Trailing slashes chaos</h2><p>The blog you're reading this article on is built with Gatsby and hosted on Netlify. Sadly, using these two tools together without taking care of inconsistent trailing slash <code>/</code> at the end of your URLs can result in some undesirable outcomes.</p><p>One of these outcomes was that I was seeing a lot of <code>301</code> redirects logged in my analytics as readers were navigating to my articles. On my blog, a link to one of my blog posts would typically look like this: <code>/posts/learning-in-public</code> but when a reader clicked on it Netlify would append a trailing slash at the end of it thus redirecting the user.</p><p>That, my friends, is extremely bad for SEO. It impacted several unrelated areas of my website, such as:</p><ul><li><strong>Opengraph images or Twitter cards not being rendered consistently</strong>: readers would share a link sometimes with or without the trailing slash which would make it hard for some services to get the proper metadata and thus render a simple link instead of a proper preview card.</li><li><strong>Invalid URLs in sitemap</strong>: my sitemap is generated automatically at build time with a Gatsby plugin based on the URLs and pages of my website. Since I did not have trailing slashes at the end of my URLs it would generate my sitemap without them which once uploaded to Google Search Console would result in tons of warnings about invalid URLs since Google referenced the ones with the trailing slashes.</li></ul><section><h3 id="how-i-fixed-this"><a href="#how-i-fixed-this" aria-label="how i fixed this permalink"><svg style="width:0px;height:0px"></svg></a>How I fixed this</h3><p>I could have fixed this in two different ways:</p><ol><li>Disable the "Pretty URLs" option in Netlify's asset optimization settings. (see screenshot below)</li><li>Add a trailing slash to all my URLs on my blog.</li></ol><figure>
    <span>
      <a href="https://blog.maximeheckel.com/static/5e9051d4443b042704a15079eaac2993/cf0be/netlify-settings.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="Image showcasing the asset optimizations options available in the Netlify project settings. Here you can see that I have the pretty URL option turned on which will add a trailing slash at the end of my URLs on this project." title="Image showcasing the asset optimizations options available in the Netlify project settings. Here you can see that I have the pretty URL option turned on which will add a trailing slash at the end of my URLs on this project." src="https://d33wubrfki0l68.cloudfront.net/a49ac35b34bbcb6cdb4c6c7231100040bfff6131/0ac3c/static/5e9051d4443b042704a15079eaac2993/1cfc2/netlify-settings.png" srcset="https://d33wubrfki0l68.cloudfront.net/6ecc8f818785e47dae754d6941f54b35e54483a0/2278b/static/5e9051d4443b042704a15079eaac2993/3684f/netlify-settings.png 225w,https://d33wubrfki0l68.cloudfront.net/dfb54cd67b3f94f8b56b8cf33e5f62a5b5034aae/12f10/static/5e9051d4443b042704a15079eaac2993/fc2a6/netlify-settings.png 450w,https://d33wubrfki0l68.cloudfront.net/a49ac35b34bbcb6cdb4c6c7231100040bfff6131/0ac3c/static/5e9051d4443b042704a15079eaac2993/1cfc2/netlify-settings.png 900w,https://d33wubrfki0l68.cloudfront.net/f385f4210359f67c56540de380449c638338b608/b31c7/static/5e9051d4443b042704a15079eaac2993/21482/netlify-settings.png 1350w,https://d33wubrfki0l68.cloudfront.net/d5b9f2320b291280ba1e429d1a0bb154e3b69bc5/ca35e/static/5e9051d4443b042704a15079eaac2993/d61c2/netlify-settings.png 1800w,https://d33wubrfki0l68.cloudfront.net/2b7014b28c0153cfa30292e719454682f084965c/f77ac/static/5e9051d4443b042704a15079eaac2993/cf0be/netlify-settings.png 1994w" sizes="(max-width: 900px) 100vw, 900px" loading="lazy">
  </a>
    </span>
    <figcaption>Image showcasing the asset optimizations options available in the Netlify project settings. Here you can see that I have the pretty URL option turned on which will add a trailing slash at the end of my URLs on this project.</figcaption>
  </figure><p>As Google already referenced my blog posts with a trailing slash, I decided to go with option number 2.</p><p>That change might look insignificant, but it resulted in a lot of weird issues suddenly disappearing. Additionally, it was essential for me to fix this before addressing the issue I'm just about to start talking about 😄!</p></section></section><section id="canonical-links-section"><h2 id="canonical-links"><a href="#canonical-links" aria-label="canonical links permalink"><svg style="width:0px;height:0px"></svg></a>Canonical links</h2><p>If you've been following me for a while, you might have started reading my content on <a href="https://medium.com/@MaximeHeckel">Medium</a>. I started blog.maximeheckel.com just about a year ago as of the time I'm writing these words. All the content on this site that dates back to before August 2019, was originally published on Medium.</p><p>On top of that, I did not edit the articles when migrating them to this website, nor did I delete the Medium ones. This resulted in <a href="https://moz.com/learn/seo/duplicate-content">duplicated content</a>, which meant that my newly deployed blog was in competition with Medium on the same keyword, the same content, from the same author when it comes to ranking on Google.</p><p>Thankfully there's a way to avoid this: <strong>setting canonical URLs</strong>. These URLs are placed in the <code>&lt;head&gt;</code> of your blog posts source code and designate that this post is the "original" post with that given content.</p><p>There are 2 steps to add valid canonical URLs to your website:</p><ol><li>You need to add them to the <code>&lt;head&gt;</code> of your post. For example: <code>&lt;link rel="canonical" href="https://blog.maximeheckel.com/posts/learning-in-public/" /&gt;</code></li><li>Head over to any third party platform you used in the past that has the content and add this canonical URL into the setting page of your post. I followed <a href="https://help.medium.com/hc/en-us/articles/360033930293-Set-a-canonical-link">this guide</a> on Medium to update my old blog post.</li></ol><p>Of course, you cannot do the first step until you've fixed any potential trailing slashes issues you may have like the ones I shared just above.</p><div><p>If like me you're a Gatsby user, you might be tempted to use <a href="https://www.gatsbyjs.com/plugins/gatsby-plugin-canonical-urls/">gatsby-plugin-canonical-urls</a> which adds canonical URLs to your site's HTML pages at build time. </p><p><strong>I do not recommend this plugin</strong> for complex setups.</p><p>I tried it and it would consistently fail to put the proper URL, especially since my website as offline support it would sometimes write the offline fallback url in the <code>&lt;head/&gt;</code> of my HTML pages.
You'll be safer to add your canonical links programmatically in your own SEO component. See the code snippet below for an example. </p></div><div><div><p data-testid="codesnippet-title">Simplied version of the SEO component I built with support for canonical URLs</p></div><pre title="Simplied version of the SEO component I built with support for canonical URLs"><div data-testid="line"><p>1</p><p><span><span data-testid="content-line">import</span><span data-testid="content-line"> </span><span data-testid="content-line">{</span><span data-testid="content-line"> graphql</span><span data-testid="content-line">,</span><span data-testid="content-line"> </span><span data-testid="content-line">StaticQuery</span><span data-testid="content-line"> </span><span data-testid="content-line">}</span><span data-testid="content-line"> </span><span data-testid="content-line">from</span><span data-testid="content-line"> </span><span data-testid="content-line">'gatsby'</span><span data-testid="content-line">;</span><span data-testid="content-line"></span></span></p></div><div data-testid="line"><p>2</p><p><span><span data-testid="content-line"></span><span data-testid="content-line">import</span><span data-testid="content-line"> </span><span data-testid="content-line">React</span><span data-testid="content-line"> </span><span data-testid="content-line">from</span><span data-testid="content-line"> </span><span data-testid="content-line">'react'</span><span data-testid="content-line">;</span><span data-testid="content-line"></span></span></p></div><div data-testid="line"><p>3</p><p><span><span data-testid="content-line"></span><span data-testid="content-line">import</span><span data-testid="content-line"> </span><span data-testid="content-line">Helmet</span><span data-testid="content-line"> </span><span data-testid="content-line">from</span><span data-testid="content-line"> </span><span data-testid="content-line">'react-helmet'</span><span data-testid="content-line">;</span><span data-testid="content-line"></span></span></p></div><div data-testid="line"><p>13</p><p><span><span data-testid="content-line">        defaultDescription: description</span></span></p></div><div data-testid="line"><p>20</p><p><span><span data-testid="content-line"></span><span data-testid="content-line">const</span><span data-testid="content-line"> </span><span data-testid="content-line">SEO</span><span data-testid="content-line"> </span><span data-testid="content-line">=</span><span data-testid="content-line"> </span><span data-testid="content-line">(</span><span data-testid="content-line">{</span><span data-testid="content-line"> title</span><span data-testid="content-line">,</span><span data-testid="content-line"> desc</span><span data-testid="content-line">,</span><span data-testid="content-line"> image</span><span data-testid="content-line">,</span><span data-testid="content-line"> pathname</span><span data-testid="content-line">,</span><span data-testid="content-line"> date </span><span data-testid="content-line">}</span><span data-testid="content-line">)</span><span data-testid="content-line"> </span><span data-testid="content-line">=&gt;</span><span data-testid="content-line"> </span><span data-testid="content-line">(</span><span data-testid="content-line"></span></span></p></div><div data-testid="line"><p>36</p><p><span><span data-testid="content-line">        description</span><span data-testid="content-line">:</span><span data-testid="content-line"> desc </span><span data-testid="content-line">||</span><span data-testid="content-line"> defaultDescription</span><span data-testid="content-line">,</span><span data-testid="content-line"></span></span></p></div><div data-testid="line"><p>37</p><p><span><span data-testid="content-line">        image</span><span data-testid="content-line">:</span><span data-testid="content-line"> </span><span data-testid="content-line">`</span><span data-testid="content-line">${</span><span data-testid="content-line">siteUrl</span><span data-testid="content-line">}</span><span data-testid="content-line">${</span><span data-testid="content-line">image</span><span data-testid="content-line">}</span><span data-testid="content-line">`</span><span data-testid="content-line">,</span><span data-testid="content-line"></span></span></p></div><div data-testid="line"><p>38</p><p><span><span data-testid="content-line">        date</span><span data-testid="content-line">:</span><span data-testid="content-line"> date </span><span data-testid="content-line">?</span><span data-testid="content-line"> date </span><span data-testid="content-line">:</span><span data-testid="content-line"> </span><span data-testid="content-line">''</span><span data-testid="content-line">,</span><span data-testid="content-line"></span></span></p></div><div data-testid="line"><p>39</p><p><span><span data-testid="content-line">        title</span><span data-testid="content-line">:</span><span data-testid="content-line"> title </span><span data-testid="content-line">||</span><span data-testid="content-line"> defaultTitle</span><span data-testid="content-line">,</span><span data-testid="content-line"></span></span></p></div><div data-testid="line"><p>40</p><p><span><span data-testid="content-line">        url</span><span data-testid="content-line">:</span><span data-testid="content-line"> </span><span data-testid="content-line">`</span><span data-testid="content-line">${</span><span data-testid="content-line">siteUrl</span><span data-testid="content-line">}</span><span data-testid="content-line">/</span><span data-testid="content-line">${</span><span data-testid="content-line">pathname </span><span data-testid="content-line">?</span><span data-testid="content-line"> `posts</span><span data-testid="content-line">/</span><span data-testid="content-line">$</span><span data-testid="content-line">{</span><span data-testid="content-line">pathname</span><span data-testid="content-line">}</span><span data-testid="content-line">` </span><span data-testid="content-line">:</span><span data-testid="content-line"> </span><span data-testid="content-line">''</span><span data-testid="content-line">}</span><span data-testid="content-line">`</span><span data-testid="content-line">,</span><span data-testid="content-line"></span></span></p></div><div data-testid="line"><p>44</p><p><span><span data-testid="content-line">        </span><span data-testid="content-line">&lt;</span><span data-testid="content-line">Helmet</span><span data-testid="content-line"> title</span><span data-testid="content-line">=</span><span data-testid="content-line">{</span><span data-testid="content-line">seo</span><span data-testid="content-line">.</span><span data-testid="content-line">title</span><span data-testid="content-line">}</span><span data-testid="content-line"> defer</span><span data-testid="content-line">=</span><span data-testid="content-line">{</span><span data-testid="content-line">false</span><span data-testid="content-line">}</span><span data-testid="content-line">&gt;</span><span data-testid="content-line"></span></span></p></div><div data-testid="line"><p>46</p><p><span><span data-testid="content-line">          </span><span data-testid="content-line">&lt;</span><span data-testid="content-line">meta name</span><span data-testid="content-line">=</span><span data-testid="content-line">"description"</span><span data-testid="content-line"> content</span><span data-testid="content-line">=</span><span data-testid="content-line">{</span><span data-testid="content-line">seo</span><span data-testid="content-line">.</span><span data-testid="content-line">description</span><span data-testid="content-line">}</span><span data-testid="content-line"> </span><span data-testid="content-line">/</span><span data-testid="content-line">&gt;</span><span data-testid="content-line"></span></span></p></div><div data-testid="line"><p>47</p><p><span><span data-testid="content-line">          </span><span data-testid="content-line">&lt;</span><span data-testid="content-line">meta name</span><span data-testid="content-line">=</span><span data-testid="content-line">"image"</span><span data-testid="content-line"> content</span><span data-testid="content-line">=</span><span data-testid="content-line">{</span><span data-testid="content-line">seo</span><span data-testid="content-line">.</span><span data-testid="content-line">image</span><span data-testid="content-line">}</span><span data-testid="content-line"> </span><span data-testid="content-line">/</span><span data-testid="content-line">&gt;</span><span data-testid="content-line"></span></span></p></div><div data-testid="highlight-line"><p>48</p><p><span><span data-testid="content-line">          </span><span data-testid="content-line">&lt;</span><span data-testid="content-line">link rel</span><span data-testid="content-line">=</span><span data-testid="content-line">"canonical"</span><span data-testid="content-line"> href</span><span data-testid="content-line">=</span><span data-testid="content-line">{</span><span data-testid="content-line">seo</span><span data-testid="content-line">.</span><span data-testid="content-line">url</span><span data-testid="content-line">}</span><span data-testid="content-line"> </span><span data-testid="content-line">/</span><span data-testid="content-line">&gt;</span><span data-testid="content-line"></span></span></p></div><div data-testid="line"><p>49</p><p><span><span data-testid="content-line">          </span><span data-testid="content-line">&lt;</span><span data-testid="content-line">meta property</span><span data-testid="content-line">=</span><span data-testid="content-line">"og:url"</span><span data-testid="content-line"> content</span><span data-testid="content-line">=</span><span data-testid="content-line">{</span><span data-testid="content-line">seo</span><span data-testid="content-line">.</span><span data-testid="content-line">url</span><span data-testid="content-line">}</span><span data-testid="content-line"> </span><span data-testid="content-line">/</span><span data-testid="content-line">&gt;</span><span data-testid="content-line"></span></span></p></div><div data-testid="line"><p>50</p><p><span><span data-testid="content-line">          </span><span data-testid="content-line">&lt;</span><span data-testid="content-line">meta property</span><span data-testid="content-line">=</span><span data-testid="content-line">"og:type"</span><span data-testid="content-line"> content</span><span data-testid="content-line">=</span><span data-testid="content-line">"article"</span><span data-testid="content-line"> </span><span data-testid="content-line">/</span><span data-testid="content-line">&gt;</span><span data-testid="content-line"></span></span></p></div><div data-testid="line"><p>53</p><p><span><span data-testid="content-line">            content</span><span data-testid="content-line">=</span><span data-testid="content-line">{</span><span data-testid="content-line">keywords </span><span data-testid="content-line">&amp;&amp;</span><span data-testid="content-line"> keywords</span><span data-testid="content-line">.</span><span data-testid="content-line">length</span><span data-testid="content-line"> </span><span data-testid="content-line">&gt;</span><span data-testid="content-line"> </span><span data-testid="content-line">0</span><span data-testid="content-line"> </span><span data-testid="content-line">?</span><span data-testid="content-line"> keywords</span><span data-testid="content-line">.</span><span data-testid="content-line">join</span><span data-testid="content-line">(</span><span data-testid="content-line">`</span><span data-testid="content-line">, </span><span data-testid="content-line">`</span><span data-testid="content-line">)</span><span data-testid="content-line"> </span><span data-testid="content-line">:</span><span data-testid="content-line"> </span><span data-testid="content-line">''</span><span data-testid="content-line">}</span><span data-testid="content-line"></span></span></p></div><div data-testid="line"><p>55</p><p><span><span data-testid="content-line">          </span><span data-testid="content-line">&lt;</span><span data-testid="content-line">meta property</span><span data-testid="content-line">=</span><span data-testid="content-line">"og:title"</span><span data-testid="content-line"> content</span><span data-testid="content-line">=</span><span data-testid="content-line">{</span><span data-testid="content-line">seo</span><span data-testid="content-line">.</span><span data-testid="content-line">title</span><span data-testid="content-line">}</span><span data-testid="content-line"> </span><span data-testid="content-line">/</span><span data-testid="content-line">&gt;</span><span data-testid="content-line"></span></span></p></div><div data-testid="line"><p>56</p><p><span><span data-testid="content-line">          </span><span data-testid="content-line">&lt;</span><span data-testid="content-line">meta property</span><span data-testid="content-line">=</span><span data-testid="content-line">"og:description"</span><span data-testid="content-line"> content</span><span data-testid="content-line">=</span><span data-testid="content-line">{</span><span data-testid="content-line">seo</span><span data-testid="content-line">.</span><span data-testid="content-line">description</span><span data-testid="content-line">}</span><span data-testid="content-line"> </span><span data-testid="content-line">/</span><span data-testid="content-line">&gt;</span><span data-testid="content-line"></span></span></p></div><div data-testid="line"><p>57</p><p><span><span data-testid="content-line">          </span><span data-testid="content-line">&lt;</span><span data-testid="content-line">meta property</span><span data-testid="content-line">=</span><span data-testid="content-line">"og:image"</span><span data-testid="content-line"> content</span><span data-testid="content-line">=</span><span data-testid="content-line">{</span><span data-testid="content-line">seo</span><span data-testid="content-line">.</span><span data-testid="content-line">image</span><span data-testid="content-line">}</span><span data-testid="content-line"> </span><span data-testid="content-line">/</span><span data-testid="content-line">&gt;</span><span data-testid="content-line"></span></span></p></div><div data-testid="line"><p>58</p><p><span><span data-testid="content-line">          </span><span data-testid="content-line">&lt;</span><span data-testid="content-line">meta name</span><span data-testid="content-line">=</span><span data-testid="content-line">"twitter:card"</span><span data-testid="content-line"> content</span><span data-testid="content-line">=</span><span data-testid="content-line">"summary_large_image"</span><span data-testid="content-line"> </span><span data-testid="content-line">/</span><span data-testid="content-line">&gt;</span><span data-testid="content-line"></span></span></p></div><div data-testid="line"><p>59</p><p><span><span data-testid="content-line">          </span><span data-testid="content-line">&lt;</span><span data-testid="content-line">meta name</span><span data-testid="content-line">=</span><span data-testid="content-line">"twitter:creator"</span><span data-testid="content-line"> content</span><span data-testid="content-line">=</span><span data-testid="content-line">{</span><span data-testid="content-line">twitter</span><span data-testid="content-line">}</span><span data-testid="content-line"> </span><span data-testid="content-line">/</span><span data-testid="content-line">&gt;</span><span data-testid="content-line"></span></span></p></div><div data-testid="line"><p>60</p><p><span><span data-testid="content-line">          </span><span data-testid="content-line">&lt;</span><span data-testid="content-line">meta name</span><span data-testid="content-line">=</span><span data-testid="content-line">"twitter:site"</span><span data-testid="content-line"> content</span><span data-testid="content-line">=</span><span data-testid="content-line">{</span><span data-testid="content-line">twitter</span><span data-testid="content-line">}</span><span data-testid="content-line"> </span><span data-testid="content-line">/</span><span data-testid="content-line">&gt;</span><span data-testid="content-line"></span></span></p></div><div data-testid="line"><p>61</p><p><span><span data-testid="content-line">          </span><span data-testid="content-line">&lt;</span><span data-testid="content-line">meta name</span><span data-testid="content-line">=</span><span data-testid="content-line">"twitter:title"</span><span data-testid="content-line"> content</span><span data-testid="content-line">=</span><span data-testid="content-line">{</span><span data-testid="content-line">seo</span><span data-testid="content-line">.</span><span data-testid="content-line">title</span><span data-testid="content-line">}</span><span data-testid="content-line"> </span><span data-testid="content-line">/</span><span data-testid="content-line">&gt;</span><span data-testid="content-line"></span></span></p></div><div data-testid="line"><p>62</p><p><span><span data-testid="content-line">          </span><span data-testid="content-line">&lt;</span><span data-testid="content-line">meta name</span><span data-testid="content-line">=</span><span data-testid="content-line">"twitter:description"</span><span data-testid="content-line"> content</span><span data-testid="content-line">=</span><span data-testid="content-line">{</span><span data-testid="content-line">seo</span><span data-testid="content-line">.</span><span data-testid="content-line">description</span><span data-testid="content-line">}</span><span data-testid="content-line"> </span><span data-testid="content-line">/</span><span data-testid="content-line">&gt;</span><span data-testid="content-line"></span></span></p></div><div data-testid="line"><p>63</p><p><span><span data-testid="content-line">          </span><span data-testid="content-line">&lt;</span><span data-testid="content-line">meta name</span><span data-testid="content-line">=</span><span data-testid="content-line">"twitter:image"</span><span data-testid="content-line"> content</span><span data-testid="content-line">=</span><span data-testid="content-line">{</span><span data-testid="content-line">seo</span><span data-testid="content-line">.</span><span data-testid="content-line">image</span><span data-testid="content-line">}</span><span data-testid="content-line"> </span><span data-testid="content-line">/</span><span data-testid="content-line">&gt;</span><span data-testid="content-line"></span></span></p></div></pre></div></section><section id="server-side-rendering-and-missing-meta-tags-section"><p>In this part, we'll look at the one instance where Gatsby's server-side rendering mixed with my carelessness completely broke my SEO. By completely I mean all my custom SEO meta tags that I carefully put in my SEO component were gone from the server-side rendered version of the website making it almost invisible to any search engine.</p><section><h3 id="how-it-happened"><a href="#how-it-happened" aria-label="how it happened permalink"><svg style="width:0px;height:0px"></svg></a>How it happened</h3><p>This issue stemmed from what I would qualify as an <strong>interrupted static HTML build</strong>. </p><p>When building your Gatsby site the last steps of the build process involve building your production JS files and also generating the HTML for each page. If you're looking for more details you can check out <a href="https://www.gatsbyjs.com/docs/overview-of-the-gatsby-build-process/">this section of the Gatsby documentation about the build process</a>.</p><p>However, I wrote a <code>ThemeProvider</code> that wrapped the whole application. Thus any component or page can know which theme (dark or light) is currently enabled and the colors to use. This component was added to the <code>gatsby-ssr</code> and <code>gatsby-browser</code> files.</p><p>Under the hood, this <code>ThemeProvider</code> worked as follow:</p><ul><li>the state of the theme (dark or light) was injected via a React Provider to the whole app, that's how I can allow users to toggle between each theme.</li><li>that same state was also saved in the local storage to make sure revisiting the website would keep the previous theme enabled. When a reader loads this blog, the ThemeProvider will check for the presence of a specific variable in <code>localStorage</code> before setting the theme accordingly.</li></ul><p>I dedicated a blog post for this: <a href="https://blog.maximeheckel.com/posts/switching-off-the-lights-adding-dark-mode-to-your-react-app-with-context-and-hooks-f41da6e07269/">Switching off the lights - Adding dark mode to your React app</a>
and it actually contains the mistake that triggered the missing meta tags:</p><ul><li>Getting the variable set to the current theme from local storage was done in a React <code>useEffect</code>. Thus, …</li></ul></section></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.maximeheckel.com/posts/seo-mistakes-i-have-made-and-how-i-fixed-them/">https://blog.maximeheckel.com/posts/seo-mistakes-i-have-made-and-how-i-fixed-them/</a></em></p>]]>
            </description>
            <link>https://blog.maximeheckel.com/posts/seo-mistakes-i-have-made-and-how-i-fixed-them/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24766682</guid>
            <pubDate>Tue, 13 Oct 2020 15:45:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Virginia voter registration down on last day to register before election]]>
            </title>
            <description>
<![CDATA[
Score 61 | Comments 81 (<a href="https://news.ycombinator.com/item?id=24766452">thread link</a>) | @gkop
<br/>
October 13, 2020 | https://www.wusa9.com/article/news/local/virginia/virginia-voter-registration-site-down-on-last-day-to-register-to-vote-officials-say/65-3e5b390b-3e47-4a22-a440-6afddf770f3a | <a href="https://web.archive.org/web/*/https://www.wusa9.com/article/news/local/virginia/virginia-voter-registration-site-down-on-last-day-to-register-to-vote-officials-say/65-3e5b390b-3e47-4a22-a440-6afddf770f3a">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>Officials say that a cut cable is to blame for the "temporary" system shutdown.</p><div>
                            <p>RICHMOND, Va. — A Virginia judge has granted a request to extend voter registration for 48 hours following technical issues that caused the commonwealth's voter registration portal to shut down for hours on Tuesday.</p>
                    <p>U.S. District Judge John A. Gibney, Jr. in Richmond gave the order Wednesday. The shutdown of the state’s website caused “a tremendous harm” to the people who want to register to vote, Gibney said.&nbsp;</p>
                        
                    <p>The deadline to register to vote is now 11:59 p.m. on Thursday Oct. 15. It includes both online and in-person registration.</p>
                    <p>“Today’s agreement to extend the voter registration deadline is a big win for democracy. Any eligible Virginian who was not able to register to vote yesterday can now do so,” said Attorney General Herring<strong>.&nbsp;</strong>“I have made it a top priority over the last several months to protect Virginians’ right to vote by making it as easy, safe and secure as possible, and this agreement is no different. I will continue to fight to make sure that every eligible Virginian can vote in this crucial election and that their vote will count.”</p>
                                <div>
                                    <blockquote><p lang="en" dir="ltr">🚨BREAKING🚨 Judge says he will GRANT our request to extend voter registration deadline until 11:59pm on Thursday, October 15. Register to vote now!!</p>— Mark Herring (@MarkHerringVA) <a href="https://twitter.com/MarkHerringVA/status/1316369056019218432?ref_src=twsrc%5Etfw">October 14, 2020</a></blockquote>

                                </div>
                    <p>An accidentally cut cable caused the entire Virginia voter registration system to go down for hours on the last day to register to vote before election day, according to the Virginia Information Technology Agency (VITA). Just before 3:30 p.m., the Virginia Department of Elections tweeted out that the <a href="https://vote.elections.virginia.gov/VoterInformation" rel="noopener noreferrer" target="_blank">registration portal</a> was back up and functioning properly.&nbsp;</p>
                    <p>Virginians are once again able to register to vote online with identification, or in-person at their voter registrar's offices.</p>
                    <p>VITA &nbsp;<a href="https://twitter.com/vaELECT/status/1316012911031017482?s=20" rel="noopener noreferrer" target="_blank">tweeted that a fiber cut</a> near Route 10 in Chester, Virginia was to blame for Tuesday's outage.&nbsp;</p>
                    <p>"Technicians learned that a Verizon fiber had been inadvertently struck as part of activities related to a Chesterfield County roadside utilities project, located off of Route 10 in Chester, Virginia," VITA said in a statement.&nbsp;</p>
                    <p>There was no time estimate given on when the problem would be fixed.</p>
                    <p>"Due to a network outage, the Citizen Portal is temporarily unavailable," the Virginia Department of Elections posted on their registration website Tuesday morning. "We are working with our network providers to restore service as quickly as possible."&nbsp;</p>
                                
                                <div>
                                    <blockquote><p lang="en" dir="ltr">Thank you everyone for your patience! The citizen portal is back up, you can go to <a href="https://t.co/8vK06RBLHl">https://t.co/8vK06RBLHl</a> to register to vote, update information or check your registration status.</p>— VA Dept of Elections (@vaELECT) <a href="https://twitter.com/vaELECT/status/1316097971721773056?ref_src=twsrc%5Etfw">October 13, 2020</a></blockquote>

                                </div>
                    <p>Tuesday is the deadline to register to vote across Virginia, D.C. and Maryland.</p>
                    <div>
<p>You can check if you're already registered at <a href="https://vote.elections.virginia.gov/VoterInformation" rel="noopener noreferrer" target="_blank">vote.elections.virginia.gov</a>. You may register to vote at your local Division of Motor Vehicles (DMV) office or request an application <a href="https://vote.elections.virginia.gov/VoterInformation/PublicContactLookup" rel="noopener noreferrer" target="_blank">from your local general registrar</a>.</p>                                            </div>
                    <p>Additional information about registering to vote in Virginia <a href="https://www.elections.virginia.gov/registration/" rel="noopener noreferrer" target="_blank">can be found here</a> or at your local registrar's website.</p>
                                <div>
                                    <blockquote><div lang="en" dir="ltr"><p>Virginia election officials say *this* accidentally cut wire in Chesterfield County is likely why Virginia’s entire voter registration system is down...</p><p>On the final day to register to vote.<a href="https://twitter.com/wusa9?ref_src=twsrc%5Etfw">@WUSA9</a> <a href="https://twitter.com/CBSNews?ref_src=twsrc%5Etfw">@CBSNews</a> <a href="https://twitter.com/hashtag/VOTE?src=hash&amp;ref_src=twsrc%5Etfw">#VOTE</a> <a href="https://t.co/J7axn996jQ">https://t.co/J7axn996jQ</a></p></div>— Mike Valerio (@MikevWUSA) <a href="https://twitter.com/MikevWUSA/status/1316015529228865536?ref_src=twsrc%5Etfw">October 13, 2020</a></blockquote>

                                </div>
                    <p>Northam said during his Tuesday afternoon coronavirus briefing how he does not appear to have the authority to extend the voter registration deadline, according to state code, and this would come from the courts. However, the governor expressed support for a court order to extend the deadline.</p>
                    <p>“I look forward to [the courts] assisting us and making sure we can extend the deadline,” Northam said.</p>
                                <div>
    <div data-module="video" data-stream="https://video.tegna-media.com/assets/WUSA/videos/c7a72fcc-3073-46d1-8e02-bcef97b72970/c7a72fcc-3073-46d1-8e02-bcef97b72970.m3u8" data-float="false" data-thumbnail="https://media.wusa9.com/assets/WUSA/images/157ee226-8fa6-4eab-bf92-e2e453f6631e/157ee226-8fa6-4eab-bf92-e2e453f6631e_1920x1080.jpg" data-title="Gov. Northam speaks about voter registration deadline in Virginia" data-description="Northam said during his Tuesday briefing how he does not appear to have the authority to extend the voter registration deadline, according to state code." data-site="65" data-id="c7a72fcc-3073-46d1-8e02-bcef97b72970" data-dfpposition="" data-mute="false" data-autoplay="false" data-link="https://www.wusa9.com/video/news/local/virginia/virginia-voter-registration-deadline/65-c7a72fcc-3073-46d1-8e02-bcef97b72970" data-origin="clipping" data-section="news" data-subsection="local" data-topic="virginia" data-subtopic="" data-captions="" data-related-playlist-id="tSIkxFyA" data-related-media-id="RRI79RaE" data-use-trending="true" data-ugc-preroll-disabled="false" data-duration="46" data-disable-preroll-at-duration="0">
        <div>
            <div>
                <div>
                    <div>
                        <p><img data-asset-fallback="default" src="https://media.wusa9.com/assets/WUSA/images/157ee226-8fa6-4eab-bf92-e2e453f6631e/157ee226-8fa6-4eab-bf92-e2e453f6631e_1920x1080.jpg"></p>
                        
                    </div>
                    
                </div>
            </div>
        </div>
                            
        </div>
                                </div>
                    <p>Virginia Secretary of Administration Keyanna Conner mentioned during Tuesday's coronavirus briefing that she hopes services will be re-instated this afternoon.</p>
                    <p>“We hope to have a temporary solution in place by 4 p.m. that will bring our services back online," Conner said.</p>
                                <div>
                                    <blockquote><div lang="en" dir="ltr"><p>NEW &gt;&gt; Virginia voter registration system is DOWN for the entire state... on the final day to register.</p><p>Officials feared this would happen.</p><p>They told us over the system, called VERIS, is still “insufficiently reliable”<br>STORY:<a href="https://twitter.com/wusa9?ref_src=twsrc%5Etfw">@WUSA9</a> <a href="https://twitter.com/hashtag/EarlyVoting?src=hash&amp;ref_src=twsrc%5Etfw">#EarlyVoting</a> <a href="https://twitter.com/CBSNews?ref_src=twsrc%5Etfw">@CBSNews</a><a href="https://t.co/kCop0GhmQG">https://t.co/kCop0GhmQG</a></p></div>— Mike Valerio (@MikevWUSA) <a href="https://twitter.com/MikevWUSA/status/1316009339463835648?ref_src=twsrc%5Etfw">October 13, 2020</a></blockquote>

                                </div>
                    <p>Lt. Governor Justin Fairfax wrote on Twitter calling for Virginia's voter registration deadline to be extended given the statewide outage.</p>
                    <p>"I am officially calling for Virginia's Registration Deadline to be extended beyond today due to the service outages impacting voters' ability to register statewide," Fairfax said. "We will work with the Administration to resolve this issue and ensure all voters have access to vote."</p>
                                <div>
                                    <blockquote><p lang="en" dir="ltr">VA <a href="https://twitter.com/LGJustinFairfax?ref_src=twsrc%5Etfw">@LGJustinFairfax</a> calls for Virginia's voter registration deadline to be extended after the statewide system is down <a href="https://t.co/roHCtgZteh">https://t.co/roHCtgZteh</a></p>— Laura Geller TV (@LauraGellerTV) <a href="https://twitter.com/LauraGellerTV/status/1316025155999551489?ref_src=twsrc%5Etfw">October 13, 2020</a></blockquote>

                                </div>
                    <p>If you've already received your mail-in ballot, your ballot must be postmarked by Nov. 3 and must be received to the Virginia Board of Elections by Nov. 6 at noon.</p>
                    <p>Before mailing your ballot in, make sure that you've signed everywhere that needs to be signed. If not, your ballot could be thrown out. This includes the voter's oath or your return envelope, and anything pertaining to your witness requirements. &nbsp;</p>
                    
                                
                    
                    
                    
                                <div>
    <div data-module="video" data-stream="https://video.tegna-media.com/assets/WUSA/videos/6b5dcfb4-3870-4615-acc9-74ab309bf1f9/6b5dcfb4-3870-4615-acc9-74ab309bf1f9.m3u8" data-float="false" data-thumbnail="https://media.wusa9.com/assets/WUSA/images/5803acd9-ce44-4112-8a65-1e23bde50b15/5803acd9-ce44-4112-8a65-1e23bde50b15_1920x1080.jpg" data-title="Officials fear parts of Virginia election system labeled 'unreliable' in 2018 may slow or crash on Election Day" data-description="Virginia’s election commissioner expressed full confidence in the critical computer system, known as VERIS. It is slated to be replaced in July 2022, documents show." data-site="65" data-id="6b5dcfb4-3870-4615-acc9-74ab309bf1f9" data-dfpposition="" data-mute="false" data-autoplay="false" data-link="https://www.wusa9.com/video/news/local/virginia/virginia-election-system-labeled-unreliable-in-2018-election-day/65-6b5dcfb4-3870-4615-acc9-74ab309bf1f9" data-origin="clipping" data-section="news" data-subsection="local" data-topic="virginia" data-subtopic="" data-captions="" data-related-playlist-id="tSIkxFyA" data-related-media-id="rHOsaz7J" data-use-trending="true" data-ugc-preroll-disabled="false" data-duration="236" data-disable-preroll-at-duration="0">
        <div>
            <div>
                <div>
                    <div>
                        <p><img data-asset-fallback="default" src="https://media.wusa9.com/assets/WUSA/images/5803acd9-ce44-4112-8a65-1e23bde50b15/5803acd9-ce44-4112-8a65-1e23bde50b15_1920x1080.jpg"></p>
                        
                    </div>
                    
                </div>
            </div>
        </div>
                            
        </div>
                                </div>
                    
                    
    </div></div>]]>
            </description>
            <link>https://www.wusa9.com/article/news/local/virginia/virginia-voter-registration-site-down-on-last-day-to-register-to-vote-officials-say/65-3e5b390b-3e47-4a22-a440-6afddf770f3a</link>
            <guid isPermaLink="false">hacker-news-small-sites-24766452</guid>
            <pubDate>Tue, 13 Oct 2020 15:22:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Collection of low fidelity website wireframe templates]]>
            </title>
            <description>
<![CDATA[
Score 25 | Comments 13 (<a href="https://news.ycombinator.com/item?id=24765941">thread link</a>) | @losteden1
<br/>
October 13, 2020 | https://octopus.do/sitemap/resource/low-fidelity-wireframes | <a href="https://web.archive.org/web/*/https://octopus.do/sitemap/resource/low-fidelity-wireframes">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section id="content" vocab="http://schema.org/" typeof="Content">
            <!-- Include navbar -->
<nav data-nav="">
    

    
</nav>





<section>
    <div>
        <div>
                                                                                                                            

<div id="">
    <h4>PROTOTYPE FASTER</h4>

    <div>
        <p><strong>A&nbsp;collection of wireframes</strong> for almost any occasion.&nbsp;You can very quickly and easily <span>show the future visual placement of information</span> on web pages, <span>plan website content</span> or <span>estimate the development</span>.</p>
    </div>

    
        </div>

                            
<div id="">
            <h3>
            Low fidelity website wireframe templates
        </h3>
    
    <ul>
                    
                            
                <li>
                    <p>
                        Header
                    </p>

                    <img src="https://static.octopus.do/media/09/header.png" alt="wireframe header | octopus.do">
                </li>
                            
                <li>
                    <p>
                        Footer
                    </p>

                    <img src="https://static.octopus.do/media/01/footer.png" alt="wireframe footer 1 | octopus.do">
                </li>
                            
                <li>
                    <p>
                        Text
                    </p>

                    <img src="https://static.octopus.do/media/05/text.png" alt="wireframe text 1 | octopus.do">
                </li>
                            
                <li>
                    <p>
                        Text
                    </p>

                    <img src="https://static.octopus.do/media/01/texts-three-columns.png" alt="wireframe text 2 | octopus.do">
                </li>
                            
                <li>
                    <p>
                        Text
                    </p>

                    <img src="https://static.octopus.do/media/03/texts-two-columns.png" alt="wireframe text 3 | octopus.do">
                </li>
                            
                <li>
                    <p>
                        Features
                    </p>

                    <img src="https://static.octopus.do/media/07/features3.png" alt="wireframe features 1 | octopus.do">
                </li>
                            
                <li>
                    <p>
                        Text &amp; Image
                    </p>

                    <img src="https://static.octopus.do/media/05/text-image-2.png" alt="wireframe text and image 1 | octopus.do">
                </li>
                            
                <li>
                    <p>
                        Images
                    </p>

                    <img src="https://static.octopus.do/media/10/images2.png" alt="wireframe images 1 | octopus.do">
                </li>
                            
                <li>
                    <p>
                        Images
                    </p>

                    <img src="https://static.octopus.do/media/06/image.png" alt="wireframe images 2 | octopus.do">
                </li>
                            
                <li>
                    <p>
                        Video
                    </p>

                    <img src="https://static.octopus.do/media/08/video.png" alt="wireframe video | octopus.do">
                </li>
                            
                <li>
                    <p>
                        Download
                    </p>

                    <img src="https://static.octopus.do/media/04/download.png" alt="wireframe download | octopus.do">
                </li>
                            
                <li>
                    <p>
                        Action
                    </p>

                    <img src="https://static.octopus.do/media/01/action.png" alt="wireframe action | octopus.do">
                </li>
                            
                <li>
                    <p>
                        Image &amp; Action
                    </p>

                    <img src="https://static.octopus.do/media/05/image-action2.png" alt="wireframe image and action | octopus.do">
                </li>
                            
                <li>
                    <p>
                        Features
                    </p>

                    <img src="https://static.octopus.do/media/09/features2.png" alt="wireframe features 2 | octopus.do">
                </li>
                            
                <li>
                    <p>
                        Text &amp; Image
                    </p>

                    <img src="https://static.octopus.do/media/04/text-image.png" alt="wireframe text and image 2 | octopus.do">
                </li>
                            
                <li>
                    <p>
                        Sign Up
                    </p>

                    <img src="https://static.octopus.do/media/06/sign-up.png" alt="wireframe sign up | octopus.do">
                </li>
                            
                <li>
                    <p>
                        Slider
                    </p>

                    <img src="https://static.octopus.do/media/01/sloder.png" alt="wireframe slider | octopus.do">
                </li>
                            
                <li>
                    <p>
                        Features
                    </p>

                    <img src="https://static.octopus.do/media/04/features.png" alt="wireframe features 3 | octopus.do">
                </li>
                            
                <li>
                    <p>
                        Images
                    </p>

                    <img src="https://static.octopus.do/media/01/images3.png" alt="wireframe images 3 | octopus.do">
                </li>
                            
                <li>
                    <p>
                        Table
                    </p>

                    <img src="https://static.octopus.do/media/08/table.png" alt="wireframe table | octopus.do">
                </li>
                            
                <li>
                    <p>
                        Footer
                    </p>

                    <img src="https://static.octopus.do/media/01/footer.png" alt="wireframe footer 2 | octopus.do">
                </li>
                        </ul>
</div>

                            
<div id="">
    
            <h2>FAQ</h2>
    
    
    <ul>
        
                                    <li data-dropdown="">
                <h3>
                    
                </h3>

                <p>A visual diagram of a web page (screen) showing the future elements and content. The main goal is to plan and display the informational and logical content of the screen before the development phase begins. There are low fidelity wireframes with low presentational accuracy and, in contrast, high fidelity wireframes with higher content detail.</p>
            </li>
        
                                    <li data-dropdown="">
                <h3>
                    
                </h3>

                <p>The simplest and fastest visual representation of a future web page or interface. Remotely represents how and what information will be located on the screen. It can be compared to a paper sketch.</p>
            </li>
        
                                    <li data-dropdown="">
                <h3>
                    
                </h3>

                <p>In order to quickly show the client or the development team how the information should be presented on the future web page (screen). This, in turn, helps to assess the development of the project and remotely imagine what the website will be like.</p>
            </li>
        
                                    <li data-dropdown="">
                <h3>
                    
                </h3>

                <p>A detailed (sometimes clickable) layout of a web page or application that is as close to the final design as possible. It also serves to test the user experience scenario at an early stage.</p>
            </li>
        
                                    <li data-dropdown="">
                <h3>
                    
                </h3>

                <p>For creating and testing layouts for more or less complex interfaces or websites where it is important to convey the accuracy and nuances of visual architecture and UX, therefore reducing the risks of misunderstanding when the project moves from the prototyping stage to the development stage.</p>
            </li>
        
                                    <li data-dropdown="">
                <h3>
                    
                </h3>

                <div>
                    <p>With the help of <strong>Low fidelity</strong> wireframes, you can very quickly and without having in-depth knowledge of web development show the future visual placement of information on web pages. Great for initial design and content planning for standard websites, interfaces, and applications.</p>

<p>Creating <strong>High fidelity</strong> wireframes requires a lot of time and expertise, but they are indispensable for creating complex interfaces where you need to see user interaction and test different UX scenarios before starting to work on the design.</p>


                                    </div>
            </li>
            </ul>
</div>

                            <div id="">
                    <p><a href="https://www.octopus.do/">
        Go to app now
    </a></p><p>No sign up required</p>
    </div>

                    </div>
    </div>
</section>

<!-- Include footer -->



        </section></div>]]>
            </description>
            <link>https://octopus.do/sitemap/resource/low-fidelity-wireframes</link>
            <guid isPermaLink="false">hacker-news-small-sites-24765941</guid>
            <pubDate>Tue, 13 Oct 2020 14:36:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Plug’nPwn – Connect to Jailbreak]]>
            </title>
            <description>
<![CDATA[
Score 167 | Comments 62 (<a href="https://news.ycombinator.com/item?id=24765461">thread link</a>) | @clashmeifyoucan
<br/>
October 13, 2020 | https://blog.t8012.dev/plug-n-pwn/ | <a href="https://web.archive.org/web/*/https://blog.t8012.dev/plug-n-pwn/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
<div>
<article>

<figure>
<img srcset="https://blog.t8012.dev/content/images/size/w300/2020/10/T2-PortOpen.jpeg 300w,
                            https://blog.t8012.dev/content/images/size/w600/2020/10/T2-PortOpen.jpeg 600w,
                            https://blog.t8012.dev/content/images/size/w1000/2020/10/T2-PortOpen.jpeg 1000w,
                            https://blog.t8012.dev/content/images/size/w2000/2020/10/T2-PortOpen.jpeg 2000w" sizes="(max-width: 800px) 400px,
                        (max-width: 1170px) 1170px,
                            2000px" src="https://blog.t8012.dev/content/images/size/w2000/2020/10/T2-PortOpen.jpeg" alt="Plug'nPwn - Connect to Jailbreak">
</figure>
<section>
<div>
<p>For those just joining us, news broke last week about the jailbreaking of <a href="https://www.apple.com/euro/mac/shared/docs/Apple_T2_Security_Chip_Overview.pdf" rel="noreferrer nofollow noopener">Apple’s T2 security processor in recent Macs</a>. If you haven't read it yet, <a href="https://blog.t8012.dev/on-bridgeos-t2-research/" rel="noreferrer nofollow noopener">you can catch up on the story here</a>, and try this out yourself at home <a href="https://checkra.in/" rel="noreferrer nofollow noopener">using the latest build of checkra1n</a>. So far we’ve stated that you must put the computer into DFU before you can run checkra1n to jailbreak the T2 and that remains true, however today we are introducing a demo of replacing a target Mac's EFI and releasing details on the T2 debug interface.</p><p>In order to build their products unlike app developers Apple has to debug the core operating system. This is how firmware, the kernel and the debugger itself are built and debugged. From the earliest days of the iPod, Apple has built specialized debug probes for building their products. <a href="https://bgr.com/2019/03/08/iphone-hack-what-dev-fused-iphones-are-and-why-theyre-important/" rel="noreferrer nofollow noopener">These devices are leaked</a> from Apple headquarters and their factories and have traditionally had monkey related names such as the “<a href="https://www.theiphonewiki.com/wiki/Kong_Cable" rel="noreferrer nofollow noopener">Kong</a>”, “<a href="https://www.theiphonewiki.com/wiki/Kanzi_Cable" rel="noreferrer nofollow noopener">Kanzi</a>” and “<a href="https://www.theiphonewiki.com/wiki/Chimp_Cable" rel="noreferrer nofollow noopener">Chimp</a>”. They work by allowing access to special debug pins of the CPU, (which for <a href="https://developer.arm.com/architectures/cpu-architecture/debug-visibility-and-trace/coresight-architecture/serial-wire-debug" rel="noreferrer nofollow noopener">ARM devices is called Serial Wire Debug</a> or SWD), as well as other chips via JTAG and UART. <a href="https://blog.senr.io/blog/jtag-explained" rel="noreferrer nofollow noopener">JTAG is a powerful protocol</a> allowing direct access to the components of a device and access generally provides the ability to circumvent most security measures. Apple has even spoken about their debug capabilities <a href="https://www.blackhat.com/docs/us-16/materials/us-16-Krstic.pdf" rel="noreferrer nofollow noopener">in a BlackHat talk</a> describing the security measures in effect. Apple has <a href="https://www.macrumors.com/2020/05/31/internal-usb-c-diagnostic-tool/" rel="noreferrer nofollow noopener">even deployed versions of these</a> to their retail locations allowing for repair of their iPads and Macs.</p><h2 id="the-bonobo-in-the-myst">The Bonobo in the Myst</h2><p>Another hardware hacker and security researcher <a href="http://ramtin-amin.fr/#tristar" rel="noreferrer nofollow noopener">Ramtin Amin did work last year</a> to create an effective <a href="https://shop.lambdaconcept.com/home/37-bonobo-debug-cable.html" rel="noreferrer nofollow noopener">clone of the Kanzi cable</a>. This combined with the checkm8 vulnerability from <a href="https://twitter.com/axi0mX" rel="noreferrer nofollow noopener">axi0mX</a> allows iPhones 5s - X to be debugged. </p><p>One of the interesting questions is how does the Macs <a href="https://support.apple.com/guide/apple-configurator-2/revive-or-restore-mac-firmware-apdebea5be51/mac" rel="noreferrer nofollow noopener">share a USB port </a>with both the Intel CPU (macOS) and the T2 (bridgeOS) for DFU. &nbsp;These are essentially separate computers inside of the case sharing the same pins. &nbsp;Schematics of the MacBook leaked from Apple’s vendors (a quick search with a part number and “schematic”), and analysis of the USB-C firmware update payload show that there is a component on each port which is tasked with both multiplexing (allowing the port to be shared) as well as terminating <a href="https://en.wikipedia.org/wiki/USB_hardware#PD" rel="noreferrer nofollow noopener">USB power delivery (USB-PD)</a> for the charging of the MacBook or connected devices. &nbsp;Further analysis shows that this port is shared between the following:<br></p><ul><li>The Thunderbolt controller which allows the port to be used by macOS as Thunderbolt, USB3 or DisplayPort</li><li>The T2 USB host for DFU recovery</li><li>Various UART serial lines</li><li>The debug pins of the T2</li><li>The debug pins of the Intel CPU for debugging EFI and the kernel of macOS</li></ul><p><br>Like the above documentation related to the iPhone, the debug lanes of a Mac are only available if enabled via the T2. &nbsp;Prior to the checkm8 bug this required a specially signed payload from Apple, meaning that Apple has a <a href="https://www.vox.com/2016/2/17/11031902/apple-encryption-fbi-san-bernardino-backdoor" rel="noreferrer nofollow noopener">skeleton key to debug any device</a> including production machines. &nbsp;Thanks to checkm8, any T2 can be demoted, and the debug functionality can be enabled. &nbsp;Unfortunately Intel has placed large amounts of <a href="https://thunderbolttechnology.net/developer-application">information about the Thunderbolt controllers</a> and <strong>protocol under NDA</strong>, meaning that it has not been properly researched leading to a <a href="https://www.kaspersky.com/blog/thunderstrike-mac-osx-bootkit/7164/" rel="noreferrer nofollow noopener">string</a> of <a href="https://www.trendmicro.com/vinfo/tr/security/news/vulnerabilities-and-exploits/thunderstrike-2-rootkit-can-now-infect-macs-remotely" rel="noreferrer nofollow noopener">vulnerabilities</a> over the years.</p><figure><img src="https://blog.t8012.dev/content/images/2020/10/USB_Type-C_Receptacle_Pinout.png" alt="" srcset="https://blog.t8012.dev/content/images/size/w600/2020/10/USB_Type-C_Receptacle_Pinout.png 600w, https://blog.t8012.dev/content/images/size/w1000/2020/10/USB_Type-C_Receptacle_Pinout.png 1000w, https://blog.t8012.dev/content/images/size/w1600/2020/10/USB_Type-C_Receptacle_Pinout.png 1600w, https://blog.t8012.dev/content/images/2020/10/USB_Type-C_Receptacle_Pinout.png 2292w" sizes="(min-width: 720px) 720px"></figure><p>Given that the USB-C port on the Mac does many things, it is necessary to indicate to the multiplexer what device inside the Mac you’d like to connect too. &nbsp;The USB-C port specification provides pins for this exact purpose (CC1/CC2) as well as detecting the orientation of the cable allowing for it to be reversible. &nbsp;On top of the CC pins runs another low speed protocol called USB-PD or USB power delivery. &nbsp;It is primarily used to negotiate power requirements between chargers(sources) and devices (sinks). &nbsp;USB-PD also allows for arbitrary packets of information in what are called “Vendor Defined Messages” or VDMs.</p><h2 id="apple-s-usb-pd-extensions">Apple’s USB-PD Extensions</h2><p>The VDM allows Apple to trigger actions and specify the target of a USB-C connection. &nbsp;We have discovered USB-PD payloads that <strong>cause the T2 to be rebooted and for the T2 to be held into a DFU state</strong>. &nbsp;Putting these two actions together, we can cause the T2 to restart ready to be jailbroken by checkra1n without any user interaction. &nbsp;While we haven’t tested a Apple Serial Number Reader, we suspect it works in a similar fashion, allowing the devices ECID and Serial Number to be read from the T2’s DFU reliably. &nbsp;The Mac also speaks USB-PD to other devices, such as when an iPad Pro is connected in DFU mode. &nbsp;<br><strong>Apple needs to document the entire set of VDM messages</strong> used in their products so that consumers can understand the security risks. &nbsp;The set of commands we issue are unauthenticated, and even if they were they were undocumented and thus un-reviewed. &nbsp;<strong>Apple could have prevented this scenario</strong> by requiring that some physical attestation occurs during these VDMs such as holding down the power button at the same time.</p><p>Taking all this information into account, we can string it together to reflect a real world attack. &nbsp;By creating a specialized device <strong>about the size of a power charger</strong>, we can place a T2 into DFU mode, run checkra1n, replace the EFI and upload a key logger to capture all keys. &nbsp;This is possible even though macOS is un-altered (the logo at boot is for effect but need not be done). &nbsp;This is because in Mac portables <strong>the keyboard is directly connected to the T2</strong> and passed through to macOS.</p><p>PlugNPwn is the entry into DFU directly from connecting a cable to the DFU port (if it doesn't show, it may be your AdBlock: <a href="https://youtu.be/LRoTr0HQP1U">https://youtu.be/LRoTr0HQP1U</a>)</p><figure><iframe width="612" height="344" src="https://www.youtube.com/embed/LRoTr0HQP1U?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><figcaption>PlugN'Pwn Automatic Jailbreak</figcaption></figure><p>In the next video we use <code>checkra1n</code> to modify the <code>MacEFI</code> payload for the Intel processor (again, AdBlock may cause it not to show <a href="https://youtu.be/uDSPlpEP-T0">https://youtu.be/uDSPlpEP-T0</a>)</p><figure><iframe width="612" height="344" src="https://www.youtube.com/embed/uDSPlpEP-T0?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe><figcaption>Replacing the T2 MacEFI with SecureBoot on</figcaption></figure><p>In order to facilitate further research on the topic of USB-PD security, and to allow users at home to perform similar experiments we are pleased to announce pre-ordereing of our USB-PD screamer. &nbsp;It allows a computer to directly "speak" USB-PD to a target device. &nbsp;Get more info here:</p><figure>


</figure>
</div>
</section>
</article>
</div>
</div></div>]]>
            </description>
            <link>https://blog.t8012.dev/plug-n-pwn/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24765461</guid>
            <pubDate>Tue, 13 Oct 2020 13:41:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[14,000x Speedup (2015)]]>
            </title>
            <description>
<![CDATA[
Score 416 | Comments 226 (<a href="https://news.ycombinator.com/item?id=24764605">thread link</a>) | @signa11
<br/>
October 13, 2020 | http://james.hiebert.name/blog/work/2015/09/14/CS-FTW.html | <a href="https://web.archive.org/web/*/http://james.hiebert.name/blog/work/2015/09/14/CS-FTW.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p>In my job as a scientific software developer, I tend to write a lot of code. And most people who haven’t been through a Computer Science degree tend to think that CS is “just” about slinging code at the screen and then running it. I have a good working relationship with many of my colleagues and co-workers with other backgrounds… Physics, Climate Science, Biology, etc. But when it comes to developing software, I get the distinct impression that people think, “Hey, how hard could this be?! We just write down a few instructions about what we want the computer to do, hit the execute button and the, ‘Blamo!’, we get our answer!”</p>

<p>The problem with that line of thinking is that it’s incredibly easy to write instructions that don’t mean what you think they mean. For example, your program could be completely uninterpretable by the computer. Furthermore, there is literally <a href="https://en.wikipedia.org/wiki/Halting_problem">no way to tell whether your program will ever actually terminate</a> without actually executing it. And there are many, many, <em>many</em>, ways to write a program which make it “slow” to execute. “Slow” being… like <em>really</em> slow. Like it would take your entire lifetime or more to actually execute it. This final problem is one that I see most often when reading software written by people without a CS education. And fixing that is my job.</p>

<p>The thing about CS that people don’t realize is that it teaches you about the theory of computation, computability (i.e. can we actually compute something? We often take for granted that we can!), algorithm complexity, and all of the knowledge, logic and analysis techniques and help you compose a program that will run in the minimum amount of time or using the minimum amount of space.</p>

<p>Allow me to show you an example of a huge optimization that I made to a simple script written by a colleague.</p>

<p>In climate science we do a lot of downscaling. We take temperature and precipitation readings from a coarse scale Global Climate Model grid and map them to a fine scale local grid. Let’s say the global grid is 50x25 and the local grid is 1000x500. For each grid cell in the local grid, we want to know to which grid cell in the global grid it corresponds.</p>

<p>A simple way to think about this is that we want to minimize the distance between L[n] and G[n]. So a simple way to do the search would be:</p>

<pre><code>for each Local cell L[i]:
  for each Global cell G[j]:
     compute distance between L[i] and G[j]
  find the minimum distance in the set L[i] * G
  return the index of the minimum
</code></pre>

<p>It seems simple enough. However, if you look closely, you’ll notice that you have to do a <em>lot</em> of extra work. Look at the algorithm in terms of the size of the input.</p>

<pre><code>for each Local cell L[i]:                        # Do this L times
  for each Global cell G[j]:                     # Do this L x G times
     compute distance (d) between L[i] and G[j]  # Do this L x G times
  find the minimum distance in the set d[i*j]    # Read G cells L times (cost L x G)
  find the index whose cell matches the minimum  # Read G cells L times (cost L x G)
</code></pre>

<p>The code for this looked something like this:</p>

<pre><code>obs.lon &lt;- ncvar_get(nc.obs, 'lon')
obs.lat &lt;- ncvar_get(nc.obs, 'lat')
n.lon &lt;- length(obs.lon)
n.lat &lt;- length(obs.lat)

obs.lats &lt;- matrix(obs.lat, nrow=n.lon, ncol=n.lat, byrow=TRUE)
obs.lons &lt;- matrix(obs.lon, nrow=n.lon, ncol=n.lat)
obs.time &lt;- netcdf.calendar(nc.obs)

gcm.lon &lt;- ncvar_get(nc.gcm, 'lon')-360
gcm.lat &lt;- ncvar_get(nc.gcm, 'lat')
gcm.lats &lt;- matrix(gcm.lat, ncol=length(gcm.lat), nrow=length(gcm.lon),
                   byrow=TRUE)
gcm.lons &lt;- matrix(gcm.lon, ncol=length(gcm.lat), nrow=length(gcm.lon))
gcm.lons.lats &lt;- cbind(c(gcm.lons), c(gcm.lats))

# Figure out which GCM grid boxes are associated with each fine-scale grid point
# Confine search to 10 deg. x 10 deg. neighbourhood

dxy &lt;- 10
mdist &lt;- function(x, y)
    apply(abs(sweep(data.matrix(y), 2, data.matrix(x), '-')), 1, sum)
nn &lt;- list()
for (i in seq_along(obs.lons)) {
    if((i %% 500)==0) cat(i, '')
    gcm.lims &lt;- ((gcm.lons.lats[,1] &gt;= (obs.lons[i]-dxy)) &amp;
                 (gcm.lons.lats[,1] &lt;= (obs.lons[i]+dxy))) &amp;
                ((gcm.lons.lats[,2] &gt;= (obs.lats[i]-dxy)) &amp;
                 (gcm.lons.lats[,2] &lt;= (obs.lats[i]+dxy)))
    gcm.lims &lt;- which(gcm.lims)
    nn.min &lt;- which.min(mdist(c(obs.lons[i], obs.lats[i]),
                        gcm.lons.lats[gcm.lims,]))
    nn[[i]] &lt;- gcm.lims[nn.min]
}
nn &lt;- unlist(nn)
</code></pre>

<p>So, it seems like a simple algorithm. “Just” compute the distances and then find the minimum. But the way it was written, as the size of the number of local cells grows, our cost of computation grows by its product with the number of global grid cells. For Canadian ANUSPLIN data, there are 1068 x 510 cells (for a total of 544,680) and let’s say that our GCM has 50 x 25 cells (for a total of 1,250 cells). So the cost of the inner loop in “some computational unit” is:</p>



<p>where the  terms are constants that correspond to the cost of computing a distance between two points, finding the minimum point, and finding an array index. Really, we don’t care (much) about the constant terms, because they are not affected by the size of the input. So we can just clump them together and call the cost;</p>



<p>So for this set of input, our cost is </p>

<p>680 million.</p>

<p>That <em>seems</em> like a lot, but is it? Computers are fast, right? If we run the naive implementation that’s something like this:</p>

<p>it ends up taking 1668 seconds which is a little less than half an hour.</p>

<pre><code>&gt; source('BCCA/naive.implementation.R')
500 1000 1500 2000 2500 3000 ... 543000 543500 544000 544500 [1] "Elapsed Time"
    user   system  elapsed 
1668.868    8.926 1681.728 
</code></pre>

<p>But do we <em>need</em> for it to take 30 minutes? Here’s the thing. We’re comparing two grids together, both of which have tons of structure that we haven’t taken advantage of. For example the latitudes and longitudes in both the coarse and the fine grid are in sorted order. So if you want to search for a number, you don’t have to look at every single number. You can use a bisect algorithm where you look at the point in the middle and then decide which half of the array you want to search. Then searching the full space only costs you the log (base 2) of the search space.</p>

<p>The other major structure that we haven’t taken advantage of is the fact that the latitudes repeat themselves in the  dimension and the longitudes repeat themselves in the  dimension. So instead of doing an operation  times, we can do it  times. That’s a <em>huge</em> optimization.</p>

<p>What does that look like in pseudo-code?</p>

<pre><code>For each local[x]:
    bisect_search(local[x], Global[x])

For each local[y]:
    bisect_search(local[y], Global[y])

return a 2d grid of the search results for each dimension
</code></pre>

<p>In code:</p>

<pre><code>## Perform a binary search on the *sorted* vector v
## Return the array index of the element closest to x
find.nearest &lt;- function(x, v) {
    if (length(v) == 1) {
        return(1)
    }
    if (length(v) == 2) {
        return(which.min(abs(v - x)))
    }
    mid &lt;- ceiling(length(v) / 2)
    if (x == v[mid]) {
        return(mid)
    } else if (x &lt; v[mid]) {
        return(find.nearest(x, v[1:mid]))
    }
    else {
        return((mid - 1) + find.nearest(x, v[mid:length(v)]))
    }
}

regrid.one.dim &lt;- function(coarse.points, fine.points) {
    return(sapply(fine.points, find.nearest, coarse.points))
}

## Take a fine scale (e.g. ANUSPLINE) grid of latitudes and longitudes
## and find the indicies that correspond to a coarse scale (e.g. a GCM) grid
## Since the search is essentially a minimizing distance in 2 dimensions
## We can actually search independently in each dimensions separately (which
## is a huge optimization, making the run time x + y instead of x * y) and
## then reconstruct the indices to create a full grid
regrid.coarse.to.fine &lt;- function(coarse.lats, coarse.lons, fine.lats, fine.lons) {
    xi &lt;- regrid.one.dim(gcm.lon, obs.lon)
    yi &lt;- regrid.one.dim(gcm.lat, obs.lat)
    ## Two dimensional grid of indices
    xi &lt;- matrix(xi, ncol=length(fine.lats), nrow=length(fine.lons), byrow=F)
    yi &lt;- matrix(yi, ncol=length(fine.lats), nrow=length(fine.lons), byrow=T)
    return(list(xi=xi, yi=yi))
}

</code></pre>

<p>The cost for every bisection search is the log of the input size. Our input size is divided into X and Y space this time, so we’ll use , and  for Global, Local, X and Y.</p>



<p>Plugging in our numbers this gives us a cost estimate of 553,076. 553 thousand sounds a lot better than 680 million. Do we see that in the run time?</p>

<pre><code>&gt; ptm &lt;- proc.time(); rv &lt;- regrid.coarse.to.fine(gcm.lat, gcm.lon, obs.lat, obs.lon); print('Elapsed Time'); print(proc.time() - ptm)[1] "Elapsed Time"
   user  system elapsed 
  0.117   0.000   0.117 
&gt; str(rv)
List of 2
 $ xi: num [1:1068, 1:510] 15 15 15 15 15 15 15 15 15 15 ...
 $ yi: num [1:1068, 1:510] 13 13 13 13 13 13 13 13 13 13 ...
&gt; 
</code></pre>

<p>0.117 seconds. What took us almost half an hour before, now takes us a little over  of a second.</p>

<pre><code>&gt; 1668.868 / .117
[1] 14263.83
</code></pre>

<p>Soooooo… I know that I’m trained to do this kind of work and it’s my job to know how to do these types of things. But even <em>I’m</em> surprised and self-impressed at how significant that speedup is. That’s a <em>14 thousand times</em> speedup.</p>

<p>This script used to take so long that it had to save its output to disk and be manually checked by a scientist before proceeding. Now you can compute it in the blink of an eye. This is a computation that we have to do hundreds of times, and this saves us days to weeks of computation time. And it increases the ability to interact with the system, helping us to get more value out of our scientists’ time… they’re not sitting around waiting for a computation to finish. It just does it.</p>

<p>I should emphasize that these epic performance improvements come without buying any larger computer systems, no parallelization or increase in complexity… in fact the code for the faster algorithm is actually simpler and more reusable! It’s pretty much an all around win, just by reading the code and having …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://james.hiebert.name/blog/work/2015/09/14/CS-FTW.html">http://james.hiebert.name/blog/work/2015/09/14/CS-FTW.html</a></em></p>]]>
            </description>
            <link>http://james.hiebert.name/blog/work/2015/09/14/CS-FTW.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24764605</guid>
            <pubDate>Tue, 13 Oct 2020 11:49:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Low-Level Academy, an explorable systems programming course]]>
            </title>
            <description>
<![CDATA[
Score 393 | Comments 33 (<a href="https://news.ycombinator.com/item?id=24764589">thread link</a>) | @nbaksalyar
<br/>
October 13, 2020 | https://lowlvl.org/tcp-ip-fundamentals/exchanging-messages | <a href="https://web.archive.org/web/*/https://lowlvl.org/tcp-ip-fundamentals/exchanging-messages">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="__next"><div><div id="content-container"><div id="headbar"><div id="logo-block"><a href="https://lowlvl.org/"><img id="sign" src="https://lowlvl.org/images/animation_1.svg" alt="Low-Level Academy"></a></div></div><div><div><p>When you opened this page in your web browser, your computer exchanged data with quite a few servers on the internet,
almost unnoticeably to you. In this lesson, we’ll build a network client application, which does something similar to
your browser in this situation.</p><p>It all starts with an <em>address</em>: you want to send a message to your friend Alice, but your computer needs to know
<em>where</em> these messages should be sent for the message to be delivered to the right computer—just like you need to
provide a recipient address when you send an email.</p><p>We are used to one kind of address system: <em>domain names</em>, like <code>lowlvl.org</code> or <code>duckduckgo.com</code>. However, these
addresses are intended to be used by human beings; machines use another addressing system.
Internet protocol (or <em>IP</em>) addresses look like <code>192.168.0.1</code>. In order to find out which IP address we should use
for a domain name like <code>lowlvl.org</code>, we ask a <em>name server</em>, a computer with a well-known IP address like
<code>1.2.3.4</code>. A name server understands DNS, or the domain name service <em>protocol</em>. Protocols are languages in
which computers can talk to each other.</p><p>So why don't we give it a try? Let's translate a domain name into an IP address:</p><p>Below you see a code example written in Rust (if you are not familiar with the Rust syntax, you can refer to
<a href="https://doc.rust-lang.org/book/">The Rust Book</a> and learn by example).</p><p>This should give you a taste of what it's like to work with computer networks. Now let's start looking into
what makes this code tick!</p></div></div><div><div><p>We have now seen how IP addresses are used in a small, imaginary network of two computers.
But just knowing an address isn’t enough to do something useful: machines need to follow a well-known
protocol to make sure they can communicate with each other in a predictable way. This is what the
Internet protocol suite, also known as <a href="https://en.wikipedia.org/wiki/Internet_protocol_suite">TCP/IP</a>,
is about: it's a standard collection of protocols used on the Internet.</p><p>The protocol suite consists of several protocols, of which we are interested in two: IP and UDP (later
we will also cover TCP and other protocols).</p><p>​<abbr title="Internet Protocol">IP</abbr> is the bread and butter of networking.
It serves as a foundation for high-level protocols. When computers exchange
messages, they encode them into IP <em>packets</em>, which you can view as individual
message units of up to 65 kilobytes in size. Usually, the operating system takes
care of the encoding for us and we don't need to do it manually, but it's still
good to know how it works under the hood, so let's see what a typical IP packet
looks like:</p><p>When you run this code, you see the destructured IP packet in a table. Each table cell contains an
individial field of the packet header. The header fields we set in code are highlighted in green—we
can skip the rest of them, for now.</p><p>On the right side, you can see the exact same packet represented in the
<em>hexadecimal</em> numerical system which is often used
to represent bytes because of its compactness (each single byte can be encoded by a hexadecimal
number ranging from <code>0x00</code> to <code>0xFF</code>, which <a href="https://duckduckgo.com/?q=0xFF+in+decimal&amp;t=hk&amp;ia=answer">corresponds to decimal</a>
<code>0</code> to <code>255</code>). This demonstrates that the IP header is just a sequence of numbers that we can interpret
and represent in different ways. If you are not comfortable with hexadecimal numbers, you can refer to
the <a href="https://lowlvl.org/prerequisites/binary-and-hexadecimal-numbers">prerequisite lesson on number encoding</a>.</p><h2>User Datagram Protocol</h2><p>​<abbr title="User Datagram Protocol">UDP</abbr>, or User Datagram Protocol, is a
thin layer above IP which adds some more contextual information for a message. A
UDP <abbr title="a word combination of data + telegram">datagram</abbr>
is also divided into a header and a payload. The fun thing about it is that an
entire UDP datagram is the <em>payload</em> of an IP packet! This is called
<em>encapsulation</em> and it's one of the core ideas in networking. A single layer of
the network stack like IP doesn’t know and doesn’t care about its payload, which
can be a protocol from the Internet protocol suite like TCP and UDP or even a
protocol defined by you.</p><p>UDP headers are only 8 bytes long. They contain source and destination <em>port numbers</em> which help to identify
different services running on the same computer—it's very common for a server to have many functions. Usually,
we designate a specific port number for a given service by convention. For example, name servers commonly use
the port number 53.</p><p>A UDP header also includes the total size of a datagram in bytes and a <em>checksum</em> which is used to verify
that the original network packet is not corrupted during transmission. And that's all it adds to the IP header!</p><p>Let's construct a UDP datagram header and add it to the previous example:</p><p>Now we are ready to move onto sending messages we have constructed
over the network!</p></div></div><div><div><p>Now we know how UDP datagrams and IP packets are constructed, but we
don't have to do this ourselves all the time. Instead, we can use
tools and functions provided by the operating system and the
standard library of our programming language. In Rust, these
functions are part of the <a href="https://doc.rust-lang.org/stable/std/net/index.html"><code>std::net</code></a>
module.</p><p>We can use the <a href="https://doc.rust-lang.org/stable/std/net/struct.UdpSocket.html#method.bind"><code>UdpSocket::bind</code></a>
function to construct <em>sockets</em>, which are virtual files that associate your program with a given port number.
All UDP datagrams incoming to this port will be redirected to your program by the operating system.</p><p><a href="https://doc.rust-lang.org/stable/std/net/struct.UdpSocket.html#method.send_to"><code>UdpSocket::send_to</code></a> can be used
to construct UDP datagrams from a given payload and send them over the network. We can wait for a response by using
the <a href="https://doc.rust-lang.org/stable/std/net/struct.UdpSocket.html#method.recv_from"><code>UdpSocket::recv_from</code></a>
function, which returns an IP address and a port number of a sender along with the message payload. In the case of
the name server request, we can interpret the payload as an IP address. If we send a request for Alice’s address to
the name server, we should get it back in this response!</p><p>Let's give it a try:</p><p>When you run this code, you can find a list of all IP packets you send and receive on the right. You can browse the
contents of IP packet headers and UDP datagrams. You can also find contents of an original message represented in
hexadecimal format below the packet browser.</p><p>With everything we have learned, you should be ready for a final test. In this test, you need to send a message to
your friend Alice. You know that she uses the port number <code>1000</code>—but you don't know her IP address yet! Maybe the
name server can help?</p><p>Congratulations, you have finished this lesson!</p><p>In the next one, we will cover the topic of fragmentation. So far we have been dealing with small messages only,
but what if you want to send a larger file, like a photo to share with your friend? We will learn how to break
large messages into small parts and how to reconstruct original files in the next lesson.</p><p><span>If you would like to follow updates, you can<!-- --> <a href="https://eepurl.com/haHQUn">subscribe to our mailing list</a>.</span></p></div></div><div><div id="lesson-navigation"><ol><li data-step="1">Exchanging Messages</li><li data-step="2">Sockets and Datagrams</li><li data-step="3">Sockets API</li></ol></div></div></div></div></div></div>]]>
            </description>
            <link>https://lowlvl.org/tcp-ip-fundamentals/exchanging-messages</link>
            <guid isPermaLink="false">hacker-news-small-sites-24764589</guid>
            <pubDate>Tue, 13 Oct 2020 11:47:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Grand Unified Theory of Product Ideation]]>
            </title>
            <description>
<![CDATA[
Score 79 | Comments 15 (<a href="https://news.ycombinator.com/item?id=24764467">thread link</a>) | @jakobgreenfeld
<br/>
October 13, 2020 | https://jakobgreenfeld.com/gut | <a href="https://web.archive.org/web/*/https://jakobgreenfeld.com/gut">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p>In short, effective methods to come up with product ideas can be categorized along two dimensions:</p>

<ul>
  <li><a href="http://www.paulgraham.com/startupideas.html">Organic ↔ Inorganic</a>. While organic ideas are solutions to problems you noticed in your own life, inorganic ideas are related to other people’s problems. Formulated differently, organic ideas grow out of the founders’ own experiences, while inorganic ideas don’t.</li>
  <li><a href="https://mobile.twitter.com/eriktorenberg/status/1243820706116198403">Bottom-up ↔ Top-down</a>. When you start only with a category in mind, you’re following a top-down approach, while if your ideation efforts start at some smaller scale you’re doing bottom-up ideation.</li>
</ul>

<p>We’ll discuss these distinctions in much more tangible terms in a moment. But first, just one more high-level observation. With the two dimensions at hand, we’re left with four distinct categories:</p>

<ul>
  <li>Organic, Bottom-Up Ideation. (“Scratch your own itch”)</li>
  <li>Organic, Top-Down Ideation. (“Live in the future, then build what’s missing”)</li>
  <li>Inorganic, Bottom-Up Ideation. (“Idea extraction”)</li>
  <li>Inorganic, Top-Up Ideation. (“Idea safaris”)</li>
</ul>

<p>Different entrepreneurs swear by different ideation methods. But what they all have in common is that they focus on finding problems over ideas.</p>

<blockquote>
  <p>“Customers don’t pay for ideas; they pay for their problems to be solved.” - Nathan Barry</p>
</blockquote>

<p>Focusing on ideas is dangerous because it often leads to clever products that no one wants.</p>

<p><img src="https://jakobgreenfeld.com/images/gut.svg" alt=""></p>

<p>My humble opinion is that you should try all ideation methods at least once. Doing this will equip you with a broad arsenal of ideas that you can later put through the metaphorical <a href="https://tylertringas.com/business-ideas-meat-grinder/">“meat grinder”</a> (i.e. <a href="https://productideas.co/evaluation">evaluate</a> and <a href="https://productideas.co/validation">validate</a>).</p>

<p>In this essay I will not judge the different approaches (they’re all amazing!). My goal is merely to organize them within a common framework.</p>

<p>With that out of the way, let’s dive in. (I discuss the different ideation methods in the order recommended by <a href="https://training.kalzumeus.com/newsletters/archive/validating_product_ideas">Patrick McKenzie</a>. However, feel free to approach them in any order you like.)</p>

<h2 id="organic-bottom-up-ideation">Organic, Bottom-Up Ideation</h2>

<p>Organic, bottom-up ideation is all about solving problems that you currently have yourself or had in the past. It’s a great method because the best ideas are often things that you notice rather than things that you purposefully come up with during a brainstorming session.</p>

<p>While “<a href="https://tylertringas.com/finding-micro-saas-business-ideas/">scratching your own itch</a>” might sound easy, it requires a lot of effort if you want to do it right. We all develop a certain blindness to our routines and daily processes. Hence, we need to actively turn the spotlight on and scrutinize all areas of our lives.</p>

<p>This includes your current job, your hobbies and all jobs you had in the past. For each of them ask yourself:</p>

<ul>
  <li>What frictions did you encounter?</li>
  <li>What suboptimal processes did you notice?</li>
  <li>Did you found yourself wondering: “Why doesn’t someone make x?”</li>
  <li>What did you find frustrating? What made you think: “I shouldn’t have to x.”</li>
  <li>What would you spend money on without thinking if it existed?</li>
</ul>

<p>It makes a lot of sense to make it a habit to ask yourself this kind of questions regularly. With ideas, it’s like with radio frequency. You have to tune in to receive them and questions like the ones listed above will help you do that.</p>

<p>The biggest advantage of organic, bottom up ideation is that <a href="https://levels.io/startups/">you’re an expert on your own problems</a> and hence in an ideal position to navigate the corresponding <a href="https://cdixon.org/2013/08/04/the-idea-maze">idea maze</a>.</p>

<p>However, the usefulness of organic, bottom-up ideation depends heavily on the kind of life you’re living. If you’re living an interesting life, full of intellectual adventures, you’ll have no problem spotting opportunities.</p>

<p>But if your life is more mundane, the ideas you’ll be able to come up with organically will be less promising.</p>

<p>For example, most college students will only be able to usual problems:</p>

<ul>
  <li>I don’t know what I should do next Friday.</li>
  <li>It’s difficult to find a sexual partner.</li>
</ul>

<p>Only if you’re doing things that others don’t, you’ll be able to see what everyone else is missing.</p>

<p>An obvious solution to the “boring life”-problem is to start living a more interesting life and being more curious. This is what organic, top-down ideation is all about.</p>

<h2 id="organic-top-down-ideation">Organic, Top-Down Ideation</h2>

<p>A very poetic way to describe organic, top-down ideation was coined by Paul Graham: “Live in the future, then build what’s missing.” Formulated differently, if no promising ideas grow out of your own experiences, it’s time to become the kind of person who has more interesting product ideas.</p>

<p>This means that you purposefully pick a field (ideally one that will have a large impact in the future) and then immerse yourself in it. Hence, instead of starting with a specific problem you pick a new field and then try to get to the edge of it.</p>

<p>The most common way to do this is to get a job at a company in the space. Alternatively, you can, of course, also spend your free time dabbling in the field. For example, if you’re convinced that soon everyone will use <a href="https://en.wikipedia.org/wiki/Internet_of_things">IoT devices</a>, you could start by <a href="https://github.com/HannahMitt/HomeMirror">building a smart mirror</a> to get your feet wet and then move on to more ambitious projects.</p>

<p>If you pick a promising field, the organic, top-down approach will allow you to spot many new problems worth solving. Ideally, you pick a field that is on the verge of becoming the next big thing. After all, <a href="http://jakobgreenfeld.com/trends">everything is easier when you’re riding a wave</a>. Then the problems you want to be solved, a few years later, millions of other people will want to be solved.</p>

<blockquote>
  <p>“[S]ince the most successful startups generally ride some wave bigger than themselves, it could be a good trick to look for waves and ask how one could benefit from them. Looking for waves is essentially a way to simulate the organic method. If you’re at the leading edge of some rapidly changing field, you don’t have to look for waves; you are the wave.” - <a href="http://www.paulgraham.com/startupideas.html">Paul Graham</a></p>
</blockquote>

<p>An interesting method to find industries and professions you could start to immerse yourself in is <a href="https://escapefromcubiclenation.libsyn.com/how-do-i-choose-which-business-to-start-">Pamela Slim’s month-long ideation exercise</a>. Each day you write down in a notebook how you respond to different things that occur in your life. After a while this will allow you to observe yourself like a scientist would observe an ant. Ideally, you’ll then be able to find patterns in the things that excite you. These are the things you should spend more time on.</p>

<p>A related useful method is to apply the principles of “curiosity overload” (h/t Daniel Priestley). Attend every event, listen to every sales pitch and subscribe to as much marketing material as you can find. If you bombard your brain this way, you’ll eventually notice interesting themes. As with Pamela Slim’s exercise, curiosity overload allows you to find out what kind of ideas get you excited. Moreover, it’s very likely that you stumble upon interesting inefficiencies and suboptimal processes. After all, if you fill your cup for a while it will eventually start pouring over.</p>

<p>Alternatively or supplementary, follow <a href="http://www.paulgraham.com/hs.html">Paul Graham’s advice:</a> “Look for smart people and hard problems. Smart people tend to clump together, and if you can find such a clump, it’s probably worthwhile to join it.”</p>

<p>The biggest downside of organic, top-down ideation is that it takes a lot of time. You can’t expect to get to the edge of a new field in just a few weeks. More realistically, we’re talking about years. This may only be viable if you’re young. Hence, inorganic ideation methods can be invaluable.</p>

<h2 id="inorganic-bottom-up-ideation">Inorganic, Bottom-Up Ideation</h2>

<p>Rather than focusing on problems that you know from your own experiences, you can also focus on other people’s problems.</p>

<p>If you talk to people to find their specific pains, we call this inorganic, bottom-up ideation since we’re again starting with specific problems of a single person. It’s just that this person is no longer you. As with organic, bottom-up ideation, the goal is to discover the most painful problems (processes) that you can then put through the “<a href="https://productideas.co/validation">meat grinder</a>”.</p>

<p>However, while it is already difficult to become aware of suboptimal processes and problems in your own life, it’s even harder to do this for other people. Everyone becomes to some extent numb to the pain they experience in their daily lives.</p>

<p>In theory, you make a list of all the people you could talk to, reach out, and then just ask them questions like:  “What’s tedious or annoying about your work?”</p>

<p>However, in practice it’s usually a lot more difficult than that. Proper <a href="https://nathanbarry.com/finding-ideas-project/">idea extraction</a> is a skill and an art. <a href="http://momtestbook.com/">Whole books</a> have been written about how to do it right. The main problem is that if you ask the wrong kind of questions, the answers you’re getting will either be not very helpful or even lead you astray.</p>

<p>For example, when someone tells you about a problem it’s essential to ask them: “What have you already tried to solve it?” If the answer is: “Nothing.” the problem is not painful enough. Your solution would merely be “nice to have”. A hallmark of good product ideas is that the problem is currently solved through awkward workarounds.</p>

<p>A cautionary tale that exemplifies how difficult it is to learn something by talking to people is what happened to anthropologist <a href="https://en.wikipedia.org/wiki/Margaret_Mead">Margaret Mead</a>. She lived with the villagers in Samoa, and tried to learn everything she could about the life of teenagers there by talking to them. Years later other scientists discovered that most of her findings were based on stories that were completely made up by her teenage subjects. The teenagers admitted that they had made up stories just for fun.</p>

<p>Hence, instead of talking to individual people it can make a lot of sense to observe what happens within a whole industry. In that case, we’re talking again about top-down ideation.</p>

<h2 id="inorganic-top-down-ideation">Inorganic, top-down ideation</h2>

<p>The key idea is, as with, organic, top-down ideation, to start with a specific industry in mind. But instead of immersing yourself in it, you observe it from the outside like a scientist.</p>

<p>The first task is to find out where the people in your industry hang out (“<a href="https://stackingthebricks.com/cant-find-audience/">watering holes</a>”). This could be, for example, online forums, Slack channels, Subreddit, or Facebook groups. Once you’ve discovered these places, you go there and start observing what is happening. You’ll have to learn the …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://jakobgreenfeld.com/gut">https://jakobgreenfeld.com/gut</a></em></p>]]>
            </description>
            <link>https://jakobgreenfeld.com/gut</link>
            <guid isPermaLink="false">hacker-news-small-sites-24764467</guid>
            <pubDate>Tue, 13 Oct 2020 11:28:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[State-Transition Tables]]>
            </title>
            <description>
<![CDATA[
Score 42 | Comments 9 (<a href="https://news.ycombinator.com/item?id=24764303">thread link</a>) | @todsacerdoti
<br/>
October 13, 2020 | https://bytes.zone/posts/state-transition-tables | <a href="https://web.archive.org/web/*/https://bytes.zone/posts/state-transition-tables">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>October 12, 2020</p><section><p>I was reading Wikipedia the other day (as you do) and found out about <a href="https://en.wikipedia.org/wiki/State-transition_table" title="">state-transition tables</a>.</p><p>Basically, state transition tables show how a state machine transitions between different states.
It's an alternative to drawing a <a href="https://en.wikipedia.org/wiki/State_diagram" title="">state diagram</a> that helps you find holes in your logic.</p><p>Wikipedia shows some pretty abstract tables, so I'm going to model a vending machine instead.
To simplify things, we'll serve a single drink for a single quarter.
The idealized version of the interaction with this machine (the "happy path") is:</p><ol><li>Put a quarter in</li><li>Press the button for the drink you want</li><li>Get the drink</li></ol><p>To implement this, we have to manage two independent pieces of state: whether you've put money in the machine and whether it has at least one drink left to vend.</p><p>Let's model the interaction above with a one-dimensional state-transition table.
Using only one dimension keeps the modeling as simple as possible while still capturing enough detail to be useful: we have a column each for <strong>input</strong>, <strong>current state</strong>, <strong>next state</strong>, and <strong>side effects</strong>.
To find out what happens after an event you just find the <strong>input</strong> and <strong>current state</strong> rows you care about and look at the matching <strong>next state</strong> and <strong>side effect</strong>.
For our vending machine, it might look like this:</p><table><thead><tr><th>Input</th><th>Current State</th><th>Next State</th><th>Side Effect</th></tr></thead><tbody><tr><td>Insert Quarter</td><td>No Money, Some Drinks</td><td>Some Money, Some Drinks</td><td>-</td></tr><tr><td>Hit Button</td><td>Some Money, Some Drinks</td><td>No Money, Some Drinks</td><td>Vend Drink</td></tr></tbody></table><p>But, of course, we have to model what happens when we do things that are not on the happy path.
Unfortunately, the one-dimensional version of the table doesn't give us a great view of that!</p><p>To figure out where we have holes, we need to add more dimensions.
Let's reorganize our states along the vertical axis and inputs along the horizontal axis to get a two-dimentional state-transition table.</p><p>To read this table, match the <strong>current state</strong> along the vertical axis with the <strong>input</strong> along the horizontal.
Our <strong>next state</strong> and <strong>side effects</strong> live in the intersections (I've separated them with a <code>/</code>):</p><table><thead><tr><th>↓ Current State / Input →</th><th>Insert Quarter</th><th>Hit Button</th></tr></thead><tbody><tr><td>No Money, Some Drinks</td><td>Some Money, Some Drinks / Nothing</td><td></td></tr><tr><td>Some Money, Some Drinks</td><td></td><td>No Money, Some Drinks / Vend Drink</td></tr><tr><td>No Money, No Drinks</td><td></td><td></td></tr><tr><td>Some Money, No Drinks</td><td></td><td></td></tr></tbody></table><p>And we see, uh... problems.
When we look at things this way, it's clear that we've only defined two of the possible 8 outcomes!
Writing things down in an orderly way revealed that we haven't specified all of the possibilities implied by our modeling.</p><p>Let's fill the rest out.
To make things easier, when the state stays the same or there's no side effect I've marked <code>-</code>:</p><table><thead><tr><th>↓ Current State / Input →</th><th>Insert Quarter</th><th>Hit Button</th></tr></thead><tbody><tr><td>No Money, Some Drinks</td><td>Some Money, Some Drinks / -</td><td>- / Beep</td></tr><tr><td>Some Money, Some Drinks</td><td>- / Refund Quarter</td><td>No Money, Some Drinks / Vend Drink</td></tr><tr><td>No Money, No Drinks</td><td>- / Refund Quarter</td><td>- / Beep</td></tr><tr><td>Some Money, No Drinks</td><td><strong>???</strong></td><td><strong>???</strong></td></tr></tbody></table><p>But when we fill things out, we can see that we have a potentially weird situation: what if we somehow have some money, but no drinks?
The state machine should prevent that, since there's no new state field that could create this situation.
But it's feasible to get there either via programming (for example, by modeling the state as two independent fields) or hardware issues (for example, someone prying open the machine to leave quarters in an atypical act of vandalism.)</p><p>Our modeling has revealed this undefined behavior way before we got to the code parts of our application, and the hardest part was making a table and looking for empty cells.
Now I can take this same table to a stakeholder or domain expert and have a productive conversation about what they think should happen.</p><p>I'd call that a win for just a little time spent modeling!</p><p>(oh, and bonus: if you're using Elm, the one-dimensional form here is probably pretty familiar.
"Input, Current State, Next State, Output" does the same job as <code>update : msg -&gt; model -&gt; ( model, Cmd msg )</code>!)</p><hr><p>Thanks to Charlie Koster and Richard Feldman for reviewing drafts of this post.</p></section></div></div>]]>
            </description>
            <link>https://bytes.zone/posts/state-transition-tables</link>
            <guid isPermaLink="false">hacker-news-small-sites-24764303</guid>
            <pubDate>Tue, 13 Oct 2020 11:05:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[CSS Layout – Grid vs. Flexbox]]>
            </title>
            <description>
<![CDATA[
Score 94 | Comments 65 (<a href="https://news.ycombinator.com/item?id=24763958">thread link</a>) | @xxlcloudinc
<br/>
October 13, 2020 | https://codecoda.com/en/blog/entry/css-layout-grid-vs-flexbox | <a href="https://web.archive.org/web/*/https://codecoda.com/en/blog/entry/css-layout-grid-vs-flexbox">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="description">
<p>A good layout makes users stay on a site because it makes important stuff easily accessible and intuitive to find. A lousy layout frustrates users, who leave because they can’t find what they are looking for.</p>
<div><p>In web design, <em>a layout</em> is a term that explains how a website is displayed on the screen. HTML 5 has quite a few elements that define parts of a web page: <em>header, nav, section, aside, article</em>, and <em>footer</em> are the significant distinctions in creating a layout. They constitute the four major sections of a webpage - <em>header/banner, navigation, content</em>, and <em>footer</em>.</p><p>Programming languages make websites feel alive, but at the core of every web page stands the good old HTML. When we discuss layouts, we must consider factors that make <em>a good</em> layout: responsiveness, viewing ports, display devices, browsers, and users’ screen sizes. A great layout not only looks great but can preserve the original intent by fitting in every possible display ratio. This correction is produced through CSS. In this article, we will examine two powerful properties: <em>CSS Flexbox and CSS Grid</em>.</p></div>
<figure><img src="https://cdn.codecoda.com/img/pixel.gif" data-plugin-lazyload="" data-plugin-options="{'effect' : 'fadeIn', 'speed' : 'fast'}" data-original="https://cdn.codecoda.com/themes/user/site/default/asset/img/blog/CSS-layout-1.png" alt="Generic Web Layout">
<figcaption><small>Generic Web Layout</small></figcaption>
</figure>
<h2>WHAT IS CSS FLEXBOX LAYOUT?</h2>
<div><p>The Flexible Box Module, commonly shortened to ‘flexbox,’ is a one-dimensional layout model. This means it deals with either row or column at a time but never both together. Flexbox is efficient when in aligning, distributing, and directing elements in a page.</p><p>Two key terminologies in Flexbox are the <strong>main axis</strong> and the <strong>cross axis</strong>. A flex container's main axis is the primary axis along which these flex items are laid out, and the cross-axis is perpendicular to it.</p><p>To start, we will wrap our HTML <em>divs</em> in a <em>flex-wrapper</em>.&nbsp;</p></div>
<pre><code>&lt;div class="flex-wrapper"&gt;
  &lt;div id="one"&gt;Header&lt;/div&gt;
  &lt;div id="two"&gt;Nav&lt;/div&gt;
  &lt;div id="three"&gt;Content&lt;/div&gt;  
  &lt;div id="four"&gt;Footer&lt;/div&gt;
&lt;/div&gt;
</code></pre>
<p>In CSS, our parent container, "flex-wrapper" will be converted to a flexbox with a simple line of code. </p>
<pre><code>.flex-wrapper { 
  display: flex; 
} 
</code></pre>
<p>I'll be adding a few elements and properties with bright colors and margins to make our <i>containers</i> and <i>divs</i> stand out.</p>
<pre><code>.flex-wrapper{ 
  display: flex; 
  background-color: beige; 
} 
.flex-wrapper &gt; div { 
  background-color: green; 
  height: 100px; 
  width: 100px; 
  margin: 10px; 
} 
</code></pre>
<p>You can see how nicely the div elements position itself horizontally. But if you notice, it doesn’t entirely take up all the space within the container. There’s a gap at the end. We can change this by adding <b>flex-grow</b>.</p>
<pre><code>.flex-wrapper &gt; div { 
  flex-grow: 1; 
}</code></pre>
<p>The flex-grow element distributes each item in a flex container. The default is 0, and by assigning a unit number to any of the <em>divs</em>, you can make it grow more massive than the rest. The opposite of this is <b>flex-shrink</b>.</p>
<pre><code>#one{ 
  flex-grow: 10;
} 
/* this gives the first div ten more units than the others */
</code></pre>
<h3>Flex-direction</h3>
<p>Flex-direction controls the direction in which items in a flex container should face. You can make the <em>divs</em> go up, down, left, and right. You can also have them in reverse order. By default, items in a flex-container are ordered from left to right, horizontally, within the main axis.</p>
<pre><code>.flex-wrapper{ 
  display: flex; 
  flex-direction: row; /* default direction */ 
}
.flex-wrapper{ 
  display: flex; 
  flex-direction: row-reverse;  
}</code></pre>
<p>Here, the items are displayed from left to right, but in reverse order. The fourth <em>div</em> now becomes the first and the first — the last.</p>
<pre><code>.flex-wrapper{ 
  display: flex; 
  flex-direction: column; 
} 
</code></pre>
<p>The <em>divs</em> are ordered from in a vertical manner - from up to down.</p>
<pre><code>.flex-wrapper{ 
  display: flex; 
  flex-direction: column-reverse; 
}</code></pre>
<p>The <em>divs</em> are ordered vertically, but in reverse, where the fourth <em>div</em> is at the top, and the first one is at the bottom.</p>
<h3>Flex Basis</h3>
<p>Flex basis defines the size of an item or a div inside the flex-container. This size value can be in <em>em, px,</em> or <em>percentage</em>. Flex-basis is different from flex-grow because it doesn’t equally share the space between items in a container.</p>
<pre><code>#three { 
  flex-basis: 200px; 
}</code></pre>
<h3>Flex</h3>
<p>Flex is a shorthand property that combines flex-shrink, flex-grow and flex-basis. It is recommended that you use this property instead of writing each individual property and its value. The order to set the values for the property is this: flex-grow, flex-shrink, flex-basis.</p>
<pre><code>.flex-wrapper { 
  display: flex; 
  flex: 0 0 200px; 
} 
</code></pre>
<h3>Justify-content and align-self</h3>
<p>Justify-content and align-self is the perfect solution to centralize a <em>div</em> or a container on a browser using flexbox.</p>
<pre><code>.flex-wrapper { 
  display: flex; 
  flex: 0 0 200px; 
  justify-content: center; 
  align-items: center; 
} 
</code></pre>
<h2>CSS Layout GRID</h2>
<p>CSS grid is a powerful 2-dimensional layout. This means <b>it can handle both the rows and columns of the layout</b>. CSS grid works with a 12-grid arrangement, where the screen is (invisibly) divided into 12 parts, and items must fit into this arrangement.<br <br=""><b>CSS grid's advantage over flexbox and other layout models is its two-dimensional quality</b>. It also makes positioning more straightforward, and the container’s elements can be set to overlap and overlap each other.</p>
<h3>Defining a grid in CSS grid</h3>
<p>A simple CSS line will transform an HTML structure to a CSS grid.</p>
<pre><code>&lt;div class="container"&gt; 
  &lt;div id="one"&gt;Header&lt;/div&gt; 
  &lt;div id="two"&gt;Nav&lt;/div&gt; 
  &lt;div id="three"&gt;Content&lt;/div&gt;  
  &lt;div id="four"&gt;Aside&lt;/div&gt;   
  &lt;div id="five"&gt;Section&lt;/div&gt;  
  &lt;div id="six"&gt;Footer&lt;/div&gt; 
&lt;/div&gt; 
</code></pre>
<pre><code>.container { 
  display: grid; 
} 
</code></pre>
<h3>Grid template-columns and grid-template-rows</h3>
<p>The grid-template-columns and grid-template-row define the size of a column or row. It assigns a <i>div</i> a size depending on what is assigned. When you set the size of a template-column and template-grid size, you use <i>px, fr, percentage, or em</i>.</p>
<pre><code>.container { 
  display: grid; 
  grid-template-columns:  40px 1fr 20%;  
  grid-template-rows: 200px; 
  background-color: beige;   
}
.container &gt; div { 
  background-color: green; 
  margin: 10px; 
} 
</code></pre>
<div><p><b>grid-template-columns:</b> 40px 1fr 20%; - this line of code tells the browser to assign the first div a width of 40px. The second takes one fraction of the assigned space and the third 20%. Automatically, <em>divs</em> 4 to 6 move below the first 3, and takes on the values assigned in the same order. This means <em>div</em> 4 is assigned 40px, <em>div</em> 5 one fraction and <em>div</em> 6, 20%.</p><p>To place all six <em>divs</em> on one line, we must assign six values to the grid-template-column. We do not have to give different measurements to the grid-columns. We could use only <em>percentages, fr,</em> or <em>px</em>.</p><p>
<b>grid-template-rows:</b> 200px; - this assigns all the divs a height of 200px;</p></div>
<h3>FR</h3>
<pre><code>.container { 
  display: grid; 
  grid-template-columns: 16.7% 16.7% 16.7% 16.7% 16.7% 16.7%;  
} 
</code></pre>
<div><p>By assigning 16.7% in 6 places, I have successfully divided the six divs in the container into six equal parts on the screen. I used 16.7 because 16.7 times 6 gives 100% of the screen width.</p><p>Using percentage and px works perfectly, but it lacks adequate flexibility and belies the most useful resource - <b>a fraction of the CSS grid</b>.</p><p><b>Fr</b> is a fractional unit. It assigns each item one fraction of available space. The fractional space can be increased to accommodate each div according to how much space they need.</p><p>Our grid-template-columns now becomes</p></div>
<pre><code>grid-template-columns: 1fr 1fr 1fr 1fr 1fr 1fr; 
</code></pre>
<p>This divides each div equally on the screen.</p>
<pre><code>grid-template-columns: 1fr 2fr 1fr 2fr 1fr 1fr; 
</code></pre>
<p>This new value makes the second and fourth div twice the size of the rest. Most importantly, it is still distributed evenly on the browser and very much responsive.</p>
<h3>Repeat Function</h3>
<p>Rather than write down the values repeatedly, we can take advantage of the repeat function to assign values once.</p>
<pre><code>.container { 
  display: grid; 
  grid-template-columns: repeat(6, 1fr);
}</code></pre>
<p>The syntax is relatively straightforward. We need to use the word ‘repeat’ and then assign how many times we want the size repeated, which is 6, and then give the measurement value. This repeat function works with <em>fr, em, px</em> as well as <em>percentage</em>. This works for template-row as well.</p>
<h3>Gap</h3>
<p>Gap, also called <em>gutter</em> is a CSS grid property that allows you to specify the gap-space between <em>divs</em> in a CSS grid container. It works just like the margin property and is calculated mainly in <em>px</em>.</p>
<pre><code>gap: 10px;</code></pre>
<h3>Grid-column-start/grid-column-end and grid-row-start/grid-row-end</h3>
<p>The grid-column-start and grid-column-end place a grid item in a particular location within the column by referring to specific grid lines. The grid-row-start and grid-row-end also do the same to the row. By assigning a value to this property, grid items can be conveniently manipulated to start and end within the specified areas.</p>
<pre><code>.container { 
  display: grid; 
  grid-template-columns: repeat (3, 1fr); 
  grid-template-rows: repeat(4, 200px); 
}
#one { 
  grid-column-start: 1; 
  grid-column-end: 3; 
  grid-row-start: 1; 
  grid-row-end: 4; 
}</code></pre>
<div><p>When you assign these values to the first div, you’ll notice it pushes the second div one unit away, and it occupies the first two positions, pushing div 3 below. Row-wise, it now occupies three positions giving it a longer height.</p><p>There is a rule when indexing in programming because we generally count from 0, which applies here. The last value is usually mentioned, but not put into effect. For example, the grid-column-end is 3, but it stops at 2 just like the grid-row-end, which ends at 3 and not 4.</p></div>
<h3>Grid-columns and grid-row</h3>
<p>Gap, also called <em>gutter</em> is a CSS grid property that allows you to specify the gap-space between <em>divs</em> in a CSS grid container. It works just like the margin property and is calculated mainly in <em>px</em>.</p>
<pre><code>#one { 
  grid-column: 1/3; 
  grid-row: 1/4; 
}</code></pre>
<h3>Creating galleries using CSS grid</h3>
<p>CSS grid is the perfect model to create galleries. With little code and manipulation, you could make perfect, responsive gallery layouts.</p>
<h4>A Mosaic Gallery Layout</h4>
<p>A mosaic gallery layout creates even tiles of images distributed evenly over a page/container.</p>
<pre><code>&lt;div class="container"&gt; 
  &lt;div id="one"&gt;Image One&lt;/div&gt; 
  &lt;div id="two"&gt;Image Two&lt;/div&gt; 
  &lt;div…</code></pre></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://codecoda.com/en/blog/entry/css-layout-grid-vs-flexbox">https://codecoda.com/en/blog/entry/css-layout-grid-vs-flexbox</a></em></p>]]>
            </description>
            <link>https://codecoda.com/en/blog/entry/css-layout-grid-vs-flexbox</link>
            <guid isPermaLink="false">hacker-news-small-sites-24763958</guid>
            <pubDate>Tue, 13 Oct 2020 09:58:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Cockney Rhyming Slang History]]>
            </title>
            <description>
<![CDATA[
Score 92 | Comments 72 (<a href="https://news.ycombinator.com/item?id=24763872">thread link</a>) | @BerislavLopac
<br/>
October 13, 2020 | https://romanroadlondon.com/cockney-rhyming-slang-history/ | <a href="https://web.archive.org/web/*/https://romanroadlondon.com/cockney-rhyming-slang-history/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
			
<div><p>Ever fallen down the ‘apples and pears’? Have you had your ‘barnet’ chopped recently? Called a mate on the old ‘dog and bone’? Or, ‘aven’t you a scooby’ about what all of that means?</p><p>Sit back, grab a nice cuppa ‘Rosy Lee’, and all will be explained.&nbsp;</p></div>



<p>These phrases belong to the vernacular of Cockney rhyming slang, a code-like way of speaking that originated in mid-19th century East London. You may remember your grandparents speaking it growing up, or perhaps you’ve heard a phrase or two being thrown about as you walk down <a href="https://romanroadlondon.com/roman-road-market-history/">Roman Road Market</a>, hunting for a bargain.</p>



<div><p>Leanne, who works in <a href="https://romanroadlondon.com/g-kelly-pie-mash-shop-working-class-food/">G Kelly</a>, said that hearing rhyming slang in the East End ‘isn’t as common these days’. ‘Pie and liquor is the Cockney rhyming slang for vicar’, she smilingly told us as she ladled the legendary parsley sauce. </p><p>Despite being less popular today, its old prevalence can still be heard, or seen, on our local streets. ‘<a href="https://romanroadlondon.com/bottlejob-craft-off-licence-shop-opens-globe-road/">BottleJob</a>‘, the bottle shop and craft off-licence in Globe Town, takes its name from a Cockney rhyming slang expression used to mean ‘coward’, which owner Alex Dehayen recalls as his grandfather’s affectionate nickname for him.&nbsp;</p></div>



<p>Due to its largely spoken nature, there are very few written records of its roots, but it was supposedly the language of stallholders and criminals. Thieves and vagabonds could use this type of ‘cryptolect’, a secretive language, to keep their liaisons well kept from eavesdropping authorities. A type of ‘in-the-know’ jargon, aiming to exclude or mislead anyone from outside of the Cockney bubble.&nbsp;</p>



<p>A sense of pride and nostalgia transpired from our Facebook call out about Cockney rhyming slang memories, particularly from the children that can remember their parents and grandparents using it. Mary Demmel remembers her aunt Mag leaving her house to get the bus saying “let me get me ole grey mare out”, meaning ‘fare’. Carol Legg’s nan ‘used to talk of the Artful that lived up the road’, referring to the lodger (Artful Dodger).&nbsp;</p>



<p>Pete Bailey, who comes from Hackney, recalled, ‘Growing up on the market, I used to hear everyone speaking it. Now it’s just a rare thing. I was at a football match last season and was standing with our captain’s girlfriend. She was shivering so I handed her my scarf and said, “Get that round your Gregory”. She looked at me funny and said, “What are you talking about?”. I’m trying to keep the Cockney language alive by teaching my godchildren.’</p>



<p>More commonly used today to describe a working class London accent, the term ‘Cockney’ actually has a specific geographical radius. It is officially defined as someone born within earshot of the chiming bells of Cheapside’s St Mary-le-Bow Church.</p>



<div><p>So, how exactly does this old-school lingo work? And, how on earth does a word like ‘plates’ come to mean ‘feet’? In its simplest form, a common word (feet) is typically replaced by a rhyming phrase of two or three words (plates of meat). The most proficient Cockney would usually shorten this back down to one word (plates). And, there you have it. Suddenly the expression ‘me plates are killing me’ translates as ‘my feet hurt’.</p><p>Don’t be fooled by the off-the-tongue ease at which it is most authentically delivered. These sayings can get confusingly cryptic. ‘Double slang’ is even harder to unscramble; this is how the name of a Greek philosopher came to mean one’s derrière. Aris is short for Aristotle. Aristotle rhymes with bottle. Bottle and glass rhymes with…you might want to have a go at working that one out yourself.</p></div>



<p>Marian Peck commented on our Facebook call out explaining her recollections of ‘backslang’. She said, ‘<strong>I</strong> think there were a couple of versions, but the one Cyril used was to take off the first letter of the word and put an ‘a’ on the end. So cat would be ‘ata’, television would be ‘elevisiona’.He came from Poplar, but worked as a bell boy in a London Hotel in the 1920s. Apparently a lot of staff could speak it and so the guests would not know what they were saying if they wanted to have a private conversation. My sister had go at it and tried to teach me, but I never had the patience!’</p>



<p>Some terms were born out of the summers that Cockneys spent hop picking. Whole families from the poorer parts of London would migrate ‘down to Kent’ to work on the fields, providing the surge of manual labour needed at harvest time. ‘Cherry’ is slang for ‘dog’, relating to the ‘cherry hog’ container that was used to collect crops. East Ender, Kim West, recalls, ‘I remember as a child in the hop fields, the adults would use slang and us kids would pick it up. The farmer would not understand a word’.&nbsp;</p>



<p>Other older examples relate to London locations. ‘Peckham Rye’ meaning ‘tie’, ‘Hampstead Heath’ meaning ‘teeth’ and ‘Tilbury Docks’ meaning ‘socks’. An all time favourite, first recorded in the 1850s, has to be ‘Barnet (fair)’, relating to one’s hair.&nbsp;&nbsp;</p>



<p>In the 20th century, celebrity names began to influence these linguistic inventions. Musician Hank Marvin’ came to mean ‘starving’, singer Ruby Murray morphed into a synonym for ‘curry’, and racing driver Ayrton Senna was the new way of saying ‘tenner’.&nbsp;</p>



<p>During the 2012 Olympics, an ATM on Commercial Street gave customers the language option of ‘Cockney rhyming slang’. To withdraw a bit of ’sausage and mash’ (cash), you were first asked to enter your ‘Huckleberry Finn’ (pin). This led to monetary prompts such as ‘Lady Godiva’ (£5) and ‘Horn of Plenty’ (£20).&nbsp;</p>



<div><p>In 1987, Mile End born record producer Paul Oakenfold coined the slang phrase ‘It’s all gone Pete Tong’, meaning ‘a bit wrong’. He wrote it in an article about acid house called ‘Bermondsey Goes Balearic’ for ‘Boy’s Own’ fanzine. Radio 1 DJ Pete Tong adopted it as the name for his Ibiza club night set and his nightly radio programme in the United States.&nbsp;</p><p>Whether from Del Boy or Danny Dyer, you have probably heard a bit of Cockney rhyming slang when watching the custard (telly – from ‘custard and jelly’). Some phrases even made it to DisneyLand via the lamplighters and chimney sweepers of ‘Mary Poppins’.</p></div>



<p>From <a href="https://romanroadlondon.com/knees-up-mother-brown-song-history/">old cockney classics</a>, like ‘My Old Man’s a Dustman’, to the lyrics of The Kinks and The Streets, you may have heard some rhyming slang sing from your record player or through your speakers.</p>



<p>Although it comes from the East End, the use of Cockney rhyming slang spreads far beyond the Bow Bells. The East Midlands accent has substituted ‘Derby Road’ for ‘cold’ and, down under, the name of Australian businessman Reg Grundy created ‘grundies’ (an Aussie word for ‘undies’).&nbsp;</p>



<p>Despite their travels, these phrases are undoubtedly heard most satisfyingly from the buoyant vocal box of a true, old-school, Cockney. In fact, some terms won’t make sense in any other accent. ‘Joanna’ means piano, relying on the ‘piannah’ pronunciation.&nbsp; Bawdy, bolshy and cheeky, the organically East End intonations perfectly capture the lingo’s playful charm.&nbsp;</p>



<p>Is the tradition dying out? A study carried out by the Museum of London in 2012 surveyed 2000 people, half of them Londoners, about their understanding and use of Cockney rhyming slang. It emerged that just 8% used the terms in everyday speech. The changing face of society, with new multi-cultural influences and the rise of virtual communication, is more aptly reflected in the contemporary slang of today’s youth.</p>



<p>However, that’s not to say that Cockney rhyming slang is a distant memory. New references to popular culture have been updating the canon since Victoria sat on the throne.&nbsp; The famous cartoon dog ‘Scooby Doo’ even managed to make the cut when ‘not a scooby’ came to mean ‘not a clue’.</p>



<div><p>Some phrases have become obsolete, but some are here to stay. Just as Shakespeare’s plays gave us terms like ‘a laughing stock’ and ‘a pound of flesh’, the old rhymes of East End folk have seeped right into the heart of the English Language. So, despite change and time, maybe it’ll never really be ‘brown bread’.</p><p>To find out more about Cockney rhyming slang, you can watch this <a href="https://www.facebook.com/watch/?v=299871854075637" target="_blank" rel="noreferrer noopener">archive footage</a> about how it was used.</p></div>








<div><div>			<div>
<hr>
<h3>Can you help us?</h3>
<p>As a not-for-profit media organisation using journalism to strengthen communities, we have not put our digital content behind a paywall or membership scheme as we think the benefits of an independent, local publication should be available to everyone living in our area.</p>

<p>If a fraction of the local 40,000 residents donated two pounds a month to <em>Roman Road LDN</em> it would be enough for our editorial team to serve the area full time and be beholden only to the community. A pound at a time, we believe we can get there.</p>
<h5>Support <em>Roman Road LDN</em> from as little as £2 and enjoy the benefits of being a Patron.</h5>

<h4><a href="https://romanroadlondon.com/support-us/" target="_blank" rel="noopener noreferrer">Become a Patron from as little as £2 per month ⇒</a></h4>
</div>
		</div></div><!-- AddThis Advanced Settings above via filter on the_content --><!-- AddThis Advanced Settings below via filter on the_content --><!-- AddThis Advanced Settings generic via filter on the_content --><!-- AddThis Share Buttons above via filter on the_content --><!-- AddThis Share Buttons below via filter on the_content --><!-- AddThis Share Buttons generic via filter on the_content -->		</div></div>]]>
            </description>
            <link>https://romanroadlondon.com/cockney-rhyming-slang-history/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24763872</guid>
            <pubDate>Tue, 13 Oct 2020 09:43:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Improve Bluetooth Audio Quality on Linux]]>
            </title>
            <description>
<![CDATA[
Score 166 | Comments 67 (<a href="https://news.ycombinator.com/item?id=24763593">thread link</a>) | @kn100
<br/>
October 13, 2020 | https://kn100.me/improving-bluetooth-audio-linux/ | <a href="https://web.archive.org/web/*/https://kn100.me/improving-bluetooth-audio-linux/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div> <p><a href="https://news.ycombinator.com/item?id=24763593">Hacker News Discussion</a> | <a href="https://www.reddit.com/r/Ubuntu/duplicates/ja9kch/improving_bluetooth_audio_quality_on_ubuntu_linux/">Reddit Discussion</a></p>
<p>Bluetooth Audio is generally considered convenient, but not ‘audiophile’. Any self respecting audiophile is probably connecting their fancy headphones to some Digital to Analog Converter/Amp combo which might be connected to their computer using some fancy gold plated USB Cable. More power to them, I am not self respecting. I made a decision a few months ago to switch entirely to Bluetooth Audio as the convenience and tidiness of having a wireless headset just appealed to me so much.</p>
<p>I purchased the M-Pow H21s - which are a fairly budget noise cancelling pair of Bluetooth headphones. They appealed to me because they weren’t enormously expensive, and other M-Pow stuff I’d purchased in the past was of good enough quality for me to trust these would be too. I wasn’t wrong. The noise cancelling is reasonably good, and the sound profile, while not ‘neutral’ - is totally fine for me to use while working.</p>
<p>One thing that really did annoy me about these headphones (and I’m not sure if the fault lies with Bluetooth Audio on Linux or with the headphones themselves) is that if I walked away from my desk and then returned, the audio quality would perceptibly drop, but never quite recover. It seemed to get ‘stuck’ at a lower quality, until the headset was rebooted. One day, I got tired of this, so decided to research what was going on.</p>

<p>In the beginning, there was A2DP - or the Advanced Audio Distribution Profile. This is a Bluetooth profile - which describes a method by which audio can be transmitted between a sender and a receiver. The profile mandates that all Bluetooth devices support a codec called SBC - or Low Complexity Subband Codec. A codec defines exactly how the device that is sending the audio should compress it. SBC is what’s known as a Low Complexity codec. Low Complexity codecs have the design goal of being easy to encode for the sender and being easy to decode for the receiver. It’s a fairly old codec, being the precursor to MP2 - itself the precursor of MP3. When consumers started demanding better quality audio out of their Bluetooth hardware, various other codecs were added to hardware. Some hardware added MP3 encoding and decoding - which was a small improvement in two ways. Firstly, if the source material was already MP3, and the encoder was smart enough, the MP3 data could directly be sent to the receiver, meaning that no encoding step was necessary. Secondly, MP3 is generally considered to be a better codec in terms of the resulting audio quality, so even if there was an encoding step, the results were generally better. Apple added AAC support to their hardware - which itself is a far superior codec to MP3 lends much the same benefits. The freshest codec which seems to be available is from a company that Qualcomm gobbled up - aptX. This codec is interesting in the sense that it only offers the second advantage talked about above. Nobody has music in aptX format, which meant that all source material must be re-encoded on the device sending the audio.</p>

<p>The first step to identifying if improvements can be made to your own Bluetooth Audio is to figure out which codecs your Bluetooth Headset supports. You can generally find this out by finding the manufacturers information. My particular headset, the h21 - is dumb as rocks, and only supports SBC. If your headset supports a better codec, especially if it supports a codec called LDAC - you should very much consider trying that before trying to do what we’ll be doing in this article, which is improving the quality available to us using the SBC codec. <a href="https://www.nextpit.com/bluetooth-audio-codecs">This article does a reasonably good job of covering all the codecs.</a></p>
<p>No matter what your headphones support, the next thing you’re going to want to do is install a custom PulseAudio module which both enables support for a bunch of more fancy codecs, and also allows you to configure the codecs. Go grab <a href="https://github.com/EHfive/pulseaudio-modules-bt/wiki/Packages">EHfive/pulseaudio-modules-bt</a> and restart PulseAudio. You should already see in your systems sound settings you can now actually select between AAC, APTX, APTX HD, and LDAC - if your headset supports it. You can probably stop here if you’re able to switch to APTX or LDAC. If not, it’s time to configure SBC to be less sucky.</p>
<figure>
<img src="https://kn100.me/bt-audio-cli.png"> <figcaption>
<h4>default.pa, with the changes</h4>
</figcaption>
</figure>
<p>So, a quick review of the options the SBC encoder has that we likely care about. Firstly, the Stereo mode. Generally in audio the two stereo modes we have are.. well Stereo and Joint Stereo. Stereo transmits two distinct channels of audio in the same stream, but completely distinct from one another. Joint stereo makes the assumption that the left and right channels are probably similar enough that just encoding how the right channel differs from the left will result in a more efficient packing of data. Your headset is likely already using one of these two modes. SBC actually supports a third mode, called dual - which essentially sends two audio streams to your headset, completely independently of one another. This effectively doubles the bit-rate your headset can operate at, since you now will have two separate streams of audio being encoded, rather than just one. If your headset supports this dual mode, and it most likely does, you definitely want it. In fact, this unofficial feature has been added to a popular custom Android OS - called LineageOS, <a href="https://www.lineageos.org/engineering/Bluetooth-SBC-XQ/">and they describe the benefit of this very well here</a>.</p>
<p>The next option we likely care about is the bitpool. The bitpool effectively determines the bitrate the audio will be encoded at. The higher, the better. <a href="https://btcodecs.valdikss.org.ru/sbc-bitrate-calculator/">A calculator is available here</a> but what is shows is that at the default highest available Bitpool value (53) in Joint Stereo mode - the maximum available bitrate is 328kbps. If we do nothing else, and just switch to Dual Channel mode - the bitrate predictably roughly doubles to 617.4kbps. Some headsets, like my H21s, actually seem to do fine at higher bitpool values. Through experimentation, I found that around 70 was as much as my headset could manage without hearing the audio equivalent of a buffer overflow. At a bitpool value of 70, in dual channel mode, the bitrate now gets to 804.8kbps!</p>
<p>If you are experimenting with a different headset, I suggest starting with a bitpool value of 53 and dual stereo enabled. You can then experiment with increasing the bitpool value, as described below.</p>
<p>To modify these values, you’ll need to edit <code>/etc/pulse/default.pa</code>. Firstly, find the lind that begins <code>load-module module-bluetooth-discover</code>. Modify it to add these flags, like so:</p>
<p><code>load-module module-bluetooth-discover a2dp_config="sbc_cmode=dual sbc_min_bp=53 sbc_min_bp=53 sbc_freq=44k"</code></p>
<p>This will lock your SBC encoder to work at a bitpool size of 53 - in dual stereo mode. Restart PulseAudio by doing <code>pulseaudio -k</code> - and reconnect your Bluetooth headset. Hopefully, you’ll perceive a large improvement in quality, as I did. You can now experiment by changing that value of 53 for a higher value. <a href="https://btcodecs.valdikss.org.ru/codec-compatibility/">There’s a list of known compatibility available here</a>.</p>
<p>The one downside of this approach of locking the encoder to work at a particular bitpool is that you lose graceful degredation of quality as the link quality reduces. You could experiment with having a lower value for the <code>sbc_min_bp</code> so that the encoder can reduce quality.</p>
<p>Let me know if this helps you!</p>
<p><a href="https://news.ycombinator.com/item?id=24763593">Hacker News Discussion</a> | <a href="https://www.reddit.com/r/Ubuntu/duplicates/ja9kch/improving_bluetooth_audio_quality_on_ubuntu_linux/">Reddit Discussion</a></p>
</div></div>]]>
            </description>
            <link>https://kn100.me/improving-bluetooth-audio-linux/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24763593</guid>
            <pubDate>Tue, 13 Oct 2020 08:51:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Automatically sending Webmentions from a static website]]>
            </title>
            <description>
<![CDATA[
Score 75 | Comments 29 (<a href="https://news.ycombinator.com/item?id=24763587">thread link</a>) | @chrislo
<br/>
October 13, 2020 | https://jamesmead.org/blog/2020-10-13-sending-webmentions-from-a-static-website | <a href="https://web.archive.org/web/*/https://jamesmead.org/blog/2020-10-13-sending-webmentions-from-a-static-website">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
      <p>A few months back I wrote about <a href="https://jamesmead.org/blog/2020-06-27-indieweb-ifying-my-personal-website">indieweb-ifying this website</a>. I attempted to follow the excellent <a href="https://indiewebify.me/">indiewebify.me guide</a>, but I skipped step 2 of Level 2, i.e. <a href="https://indiewebify.me/#send-webmentions">adding the ability to send Webmentions to other IndieWeb sites</a>. My <a href="https://jamesmead.org/blog/2020-06-27-indieweb-ifying-my-personal-website#publishing-on-the-indieweb">excuse</a> at the time was:</p>

<blockquote>
  <p>I decided to skip this step for now given that it's relatively easy to <a href="https://indieweb.org/webmention-implementation-guide#One-liner_webmentions">send a Webmention manually using <code>curl</code></a> and it's not as if I currently blog that frequently!</p>
</blockquote>

<p>Anyway a couple of recent discoveries led me to fix this omission…</p>

<h3 id="webmentionapp">webmention.app</h3>

<p>This lovely little <a href="https://webmention.app/">service</a> built by <a href="https://remysharp.com/">Remy Sharp</a>, not to be confused with <a href="https://webmention.io/">webmention.io</a> which is used for <em>receiving</em> incoming <a href="https://indieweb.org/Webmention">Webmentions</a>, makes it easy to <em>send</em> outgoing webmentions for all the links on a given page:</p>

<blockquote>
  <p>This is a platform agnostic service that will check a given URL for links to other sites, discover if they support webmentions, then send a webmention to the target.</p>
</blockquote>

<p>Fortunately I still have an <a href="http://feeds.jamesmead.org/floehopper-blog">RSS feed</a> for my blog and in this case the documentation <a href="https://webmention.app/docs#using-ifttt-to-trigger-checks">suggests using IFTTT</a> to automate doing this each time you publish an article.</p>

<h3 id="actionsflow">Actionsflow</h3>

<p>Somewhat serendipitously I recently came across <a href="https://actionsflow.github.io/docs/">Actionsflow</a> which is a free Zapier/IFTTT alternative for developers to automate workflows based on GitHub Actions.</p>

<p>I have to admit that I was initially quite confused by the Actionsflow documentation and I tried to add my Webmention-sending workflow to <a href="https://github.com/floehopper/jamesmead.org">the repo for this website</a>. However, once I realised the idea was to <a href="https://github.com/actionsflow/actionsflow-workflow-default/generate">create a new repo</a> based on a template, things became a little clearer.</p>

<h3 id="workflow-to-send-webmentions">Workflow to send Webmentions</h3>

<p>I created <a href="https://github.com/floehopper/send-webmentions">this repo</a> and added <a href="https://github.com/floehopper/send-webmentions/blob/main/workflows/send-webmentions.yml">this workflow</a> to poll my RSS feed and send an HTTP POST request to the webmention.app API for every new item. I was pleasantly surprised by how simple this was:</p>

<pre><code>name: Send webmentions for new blog posts
on:
  rss:
    url: http://feeds.jamesmead.org/floehopper-blog
    config:
      logLevel: debug
      limit: 1
jobs:
  send_webmentions:
    name: Send webmentions
    runs-on: ubuntu-latest
    steps:
      - name: 'Send webmentions for RSS item link'
        uses: actionsflow/axios@v1
        with:
          url: https://webmention.app/check/
          method: 'POST'
          params: '{ "url": "${{on.rss.outputs.link}}", "token": "${{ secrets.WM_TOKEN }}" }'
          is_debug: true
</code></pre>

<p>It took me a while to realise that the underlying Actionsflow GitHub Action was running every 5 minutes and <em>polling</em> my RSS feed. It seems to use the GitHub Action cache to "remember" which items it has seen before. Since I don't publish blog posts very often, polling every 5 minutes seemed a bit excessive and so I decided to <a href="https://github.com/floehopper/send-webmentions/commit/eb5a9cb573b1c532c92143b7fb2aed260c5fa552">reduce the frequency to hourly</a>.</p>

<h3 id="observations">Observations</h3>

<ul>
  <li>
    <p>I'm not sure I like the design of Actionsflow which means creating a new repo, but perhaps this would make more sense to me if I had more than one workflow. I suppose this repo is roughly equivalent to a single IFTTT account.</p>
  </li>
  <li>
    <p>Over the course of the last year I've automated some backup jobs for <a href="https://gofreerange.com/">Go Free Range</a> using the <a href="https://docs.aws.amazon.com/cdk/api/latest/typescript/api/aws-ecs-patterns/scheduledfargatetask.html#aws_ecs_patterns_ScheduledFargateTask"><code>ScheduledFargateTask</code> class</a> in the <a href="https://aws.amazon.com/cdk/">AWS CDK</a> to fire up a container and run a script on a cron schedule. This has worked really well, but it's quite tempting to port these over to Actionsflow so we don't have to maintain anything other than the <code>Dockerfile</code> and associated shell scripts.</p>
  </li>
  <li>
    <p>webmention.app is really nicely implemented with good documentation; it's a classic example of an elegant solution to a tightly scoped problem. Since I'll be making use of the API on a regular basis, I decided to <a href="https://jamesmead.org/blog/paypal.me/rem">buy Remy a drink</a> to say thank you!</p>
  </li>
  <li>
    <p>I'd also like to find a way to say thank you to <a href="https://aaronparecki.com/">Aaron Parecki</a> who built webmention.io and <a href="https://snarfed.org/">Ryan Barrett</a>, <a href="https://kylewm.com/">Kyle Mahan</a>, et al who built <a href="https://brid.gy/">brid.gy</a>. However, I can't see a way to do either and, indeed, the latter <a href="https://brid.gy/about#cost">explicitly say</a> "We don't need donations, promise."</p>
  </li>
</ul>


    </section></div>]]>
            </description>
            <link>https://jamesmead.org/blog/2020-10-13-sending-webmentions-from-a-static-website</link>
            <guid isPermaLink="false">hacker-news-small-sites-24763587</guid>
            <pubDate>Tue, 13 Oct 2020 08:50:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Niche I am Looking to Fill]]>
            </title>
            <description>
<![CDATA[
Score 82 | Comments 36 (<a href="https://news.ycombinator.com/item?id=24763209">thread link</a>) | @DoreenMichele
<br/>
October 13, 2020 | http://www.eclogiselle.com/2020/10/the-niche-i-am-looking-to-fill.html | <a href="https://web.archive.org/web/*/http://www.eclogiselle.com/2020/10/the-niche-i-am-looking-to-fill.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<div id="post-body-206541096419142738"><p>
Eclogiselle is intended to be a compendium of free resources for small communities with paid services available below $5000. In fact, I hope to be able to offer some services for well under a thousand dollars.

</p><p>


I am looking to serve small communities that would have trouble hiring someone at all to do planning and economic development work for them. I am hoping to find creative ways to provide useful resources for communities who often either cannot afford paid staff or cannot find someone willing to work for them for what they can afford to pay.

</p><hr><p>
The small town I live in made an offer to a candidate for their city manager position and the candidate turned them down and took a higher paying job elsewhere. That seems to be par for the course.

</p><p>

Years ago when I was looking to become a professional planner, I haunted the online job listings. A lot of small communities kept the same job openings available for months at a time because of the challenges they face in filling such positions at all.

</p><p>
I have first-hand experience with my local <a href="https://www.reddit.com/r/CitizenPlanners/comments/duf6ae/main_street_america/">Main Street America</a> program. This is the leading voice for preservation-based economic development and community revitalization across the US. 
</p><p>
It is aimed at revitalizing small towns. In order to be an accredited Main Street program, you need to have an executive director: 

</p><ul><li>0-2500 people = half time volunteer Executive Director</li>

  <li>2500-5000 = half time paid Executive Director</li>

  <li>5000+ = full time paid Executive Director</li></ul><p>

So this well-established program doesn't expect a town of less than 2500 people to be able to pay their economic development director <i>at all</i>. It's a part-time, volunteer position for such communities. It's basically a labor of love. 
</p><p>
For towns between 2500 and 5000 people, they only expect them to be able to pay for a part-time director. It's only for communities above 5000 that they expect you to have a full-time paid executive director for this non-profit economic development entity.

</p><p>
Please note that if they have a full-time executive director, this is probably their only paid employee. There will also be a board running the non-profit and those are all unpaid positions.

</p><p>
So all the evidence suggests that small communities have trouble hiring planning and economic development staff <i>at all</i>, whether it is a city job or a job at a local non-profit trying to fill in the gaps in their small town. And when <a href="https://www.reddit.com/r/urbanplanning/comments/j5a0vr/dark_side_question_typical_services_and_prices_at/">I asked around</a>, the answers I got suggest small communities face additional challenges when they look to contract out services instead of hiring paid staff to serve them.
</p><p>
In one reply to my query, I was given a link to <a href="https://patch.com/new-jersey/triboro/kinnelon-council-members-fear-environmental-resource-e348f325fc">an article</a> from 2012 where The Land Conservancy of New Jersey was offering to do an Environmental Resources Inventory (ERI) for Kinnelon, a burrough in New Jersey. They were offering it at a discount and the price was expected to be $10,000 (back in 2012 -- no doubt, prices have gone up since then).
</p><p>
<a href="https://tlc-nj.org/">The Land Conservancy of New Jersey</a> is apparently a <i>non-profit</i> land trust that has a goal of protecting open space. The person who left the link implied that this is probably a typical fee for non-profits and universities serving this space for small communities.

</p><p>

Non-profits and universities are supposed to be the good guys, the affordable option, the folks doing it out of idealism and not to make a quick buck. But it doesn't take much digging to be suspicious of this $10,000 ERI and why it is being pushed.
</p><p>
In the article, one person objecting to paying for the ERI said, in part, <i>All we do is keep spending money and no ones giving us money.</i> so I pulled up the <a href="https://en.wikipedia.org/wiki/Kinnelon,_New_Jersey">Wikipedia page for Kinnelon</a>, New Jersey and, unsurprisingly, this is a wealthy suburb.
</p><p>
According to Wikipedia, in 2012 they were among the top 500 most expensive zip codes in the US. It lists them as at number 462.
</p><p>
A quick search tells me there are nearly 42,000 zip codes in the US. If you pull out a calculator and divide 462 by 42,000, the result is 0.011. So we are talking about people who are just outside of the One Percent. 
</p><p>
I read this article and I see vague, hand-wavy claims that this ERI is "useful for planning efforts" and I also see people complaining about a pattern of being bled for money over the years without getting results. I can readily believe they are being taken advantage of. 

</p><p>
I can believe that people keep going to Kinnelon burrough, selling them services "at a discount" (because "we are the good guys") for thousands of dollars -- because these people can come up with the money -- and the services aren't actually useful for development.
</p><p>
The other thing I was told was that most for-profit, private planning firms do not actively seek out projects that are below about $5k. If you approach them, they might do a small project for you, but chasing it down isn't worth it. It doesn't pay well enough.

</p><p>

Before life got in the way, I wanted to be a professional planner. I've spent years around online planning forums and attending local meetings and what not and I think I would have trouble finding a private planning firm. 
</p><p>
They seem to me to not be very visible. I'm not exactly an insider because I never got the career I wanted, but you would think this would be less opaque to me.
</p><p>

So my impression is that planning firms are hard to identify by small communities, aren't actively seeking business from small communities because it doesn't pay well enough and may not even take a bid from you even if you approach them. If it's only a few thousand dollars, they seem to feel like they are doing you some kind of favor if they are willing to work with you.

</p><p>

I am in Aberdeen, Washington. It is in a region I have dubbed The Pacific Coastal Region of Washington State or <a href="https://www.reddit.com/r/CoastalWA/">CoastalWA</a>. 

</p><p><a href="https://1.bp.blogspot.com/-bGDP0jo2muo/X4Tk73UfcOI/AAAAAAAAGyU/ng7YAFlb8jEcNG137qzgwJx-WcKRulB5QCLcBGAsYHQ/s0/CoastalWA256sq.png"><img alt="" data-original-height="256" data-original-width="256" src="https://1.bp.blogspot.com/-bGDP0jo2muo/X4Tk73UfcOI/AAAAAAAAGyU/ng7YAFlb8jEcNG137qzgwJx-WcKRulB5QCLcBGAsYHQ/s0/CoastalWA256sq.png"></a></p><p>



This is a region with a sparse number of small towns and a large number of unincorporated communities. There is at least a half million people, two or three dozen incorporated small towns and probably upwards of 200 unincorporated communities.

</p><p>
And most likely an influx of people will be coming here in the next few years because it is a relative safe haven from things like climate change. So I think the many small communities in this region need to begin preparing for growth if they don't want a bunch of well-heeled outsiders to come in and run rough-shod over the people who are already here.

</p><ul><li><a href="https://www.reddit.com/r/CoastalWA/comments/j4u0by/welcome/">
  Welcome to CoastalWA</a></li><li>
<a href="https://www.reddit.com/r/CoastalWA/comments/izecag/counties_of_coastal_wa/">Counties of CoastalWA</a></li><li>
<a href="https://www.reddit.com/r/CoastalWA/comments/iztsji/coastal_wa_is_a_relative_safe_haven_in_2020/">CoastalWA is A Relative Safehaven</a></li></ul><p>

So I think there is tremendous need for free and low cost economic development and planning resources and services that would work well for small communities. The only question in my mind is if I can figure out how to package up offerings that make sense for both me and them and find a way to connect with the people who need it.





</p><blockquote>The
  Map on this page is by <a href="http://stamen.com/">Stamen Design</a> and is being used under <a href="http://creativecommons.org/licenses/by/3.0">CC BY 3.0</a>. Map Data by <a href="http://openstreetmap.org/">OpenStreetMap</a>, under <a href="http://www.openstreetmap.org/copyright">ODbL</a>. It has been edited by <a href="https://doreenmichele.blogspot.com/">Doreen Traylor</a>.</blockquote>


<p>
<a href="https://news.ycombinator.com/item?id=24763209">Hacker News Discussion</a></p></div>
</div></div>]]>
            </description>
            <link>http://www.eclogiselle.com/2020/10/the-niche-i-am-looking-to-fill.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24763209</guid>
            <pubDate>Tue, 13 Oct 2020 07:40:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Custom Allocators Demystified]]>
            </title>
            <description>
<![CDATA[
Score 94 | Comments 66 (<a href="https://news.ycombinator.com/item?id=24762840">thread link</a>) | @deafcalculus
<br/>
October 12, 2020 | https://slembcke.github.io/2020/10/12/CustomAllocators.html | <a href="https://web.archive.org/web/*/https://slembcke.github.io/2020/10/12/CustomAllocators.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p>Have you ever wondered why people write their own memory allocators? Are they masochists? Do they think they can write a better memory allocator than the OS? Shouldn’t they just use a garbage collected language instead?</p>

<h2 id="why-bother-with-custom-allocators">Why bother with custom allocators?</h2>

<p>Around 2010 or so when Chipmunk2D was new(ish), it didn’t use any custom allocators. Even temporary data was allocated when needed, tracked, and freed when I was done with it. At the time I was developing it, I was using OS X, and this was more or less fine. I even have some old stress test videos on YouTube with tens of thousands of colliding objects in real time on an old Core 2 Duo laptop. Running the same code on Windows XP wasn’t so great however. Had somebody suggested using a custom allocator, I probably would have turned my nose up at the idea and said something like “That’s dumb, I can do something simpler.” Besides, looking at sampling profiler data on OS X was telling me that memory functions weren’t even 1% of the CPU time after all. Why bother trying to make the allocator more efficient? On the other hand I knew what I had really wanted to do was to try and pack all of my collision data together to make it cache friendly. So what I did was to keep pools of various types of structs. If I needed a collision pair struct, I could just grab one from the pool. If the pool was empty, I’d allocate a few more kilobytes of them in a big block first. I did something similar for contact data, but since it only needed to be kept for a single frame I could release entire blocks of it back to the pools all at once. This solved my Windows performance problem, and the locality made for a very nice performance bump on other platforms too!</p>

<p>The astute reader is probably performing a face palm right now as I’ve just described a slab allocator and a zone allocator. :)</p>

<h3 id="no-need-for-a-better-malloc">No need for a better <code>malloc()</code></h3>

<p>So what does <code>malloc()</code> give us anyway?</p>

<ul>
  <li>Access to nearly unlimited amounts of virtual memory</li>
  <li>Create or free individual allocations of any size</li>
  <li>Safe, transparent access to allocations from any thread</li>
</ul>

<p>These are all great features, and it would be difficult to implement a reasonably generic replacement. On the other hand, many programs and systems within them have unique memory requirements. For Chipmunk2D’s collision system what I needed was completely different:</p>

<ul>
  <li>Memory locality</li>
  <li>Predictable performance</li>
  <li>Simplified memory ownership</li>
</ul>

<p>So while I didn’t know it at the time, I had several reasons to want a custom allocator, and I accidentally implemented several! The last item in particular is interesting to me because it’s completely antithetical to what I used to think custom allocators were all about. I had a model in my head where custom allocators were about performance, and garbage collection to be about simplifying ownership, but it turns out the two are not so mutually exclusive. Using some custom allocator techniques in a garbage collected language can improve performance, and using them in a traditional language can give many of the same benefits as if you had garbage collection.</p>

<h3 id="more-reasons-to-bother-with-custom-allocators">More reasons to bother with custom allocators</h3>

<p>Over the years, I’ve wasted <em>many</em> hours debugging memory issues. With just a hash table and a set of linked lists, you can track the history of all your allocations. That makes it pretty easy to track down use after free errors, double free errors, and memory leaks. Using guard pages around your allocations, you can detect overflows. Techniques like this can be a nice complement to external tools like Valgrind or AddressSanitizer. Between the simplified memory ownership, having tools to help detect errors, and tools to debug issues when they do occur, I can happily say I haven’t spent a lot of time debugging memory issues for years. :)</p>

<h2 id="common-allocators">Common Allocators</h2>

<p>Several of the common allocators you hear people talk about are so simple, you can describe them in a paragraph! (Though I’m going to cheat and use diagrams too.)</p>

<h3 id="1-slab-allocator">1) Slab Allocator</h3>

<p><img src="https://slembcke.github.io/images/SlabAllocator.svg" alt="Slab Allocator Diagram"></p>

<p>The collision pair example from Chipmunk2D is basically a slab allocator. The idea is that your allocator just needs to keep a list of large blocks of memory (slabs) that you have allocated, and break those into little fixed sized blocks of memory for your objects that you store in a linked list of free allocations. The trick is to use the allocations themselves as linked list nodes so you don’t have to waste any extra memory for tracking. Allocating memory becomes as fast as pushing or popping nodes onto a linked list, and you only have to talk to the OS when you run out of space in your existing slabs. Additionally, all of the memory is packed together which helps play nice with the CPU cache. As a bonus, you know for sure that you are packing small, short lived allocations together and minimizing fragmentation of your main memory space.</p>

<p><strong>When to use it:</strong> When you need to keep a pool of short lived allocations that are all the same size.</p>

<h3 id="2-linear-allocator">2) Linear Allocator</h3>

<p><img src="https://slembcke.github.io/images/LinearAllocator.svg" alt="Linear Allocator Diagram"></p>

<p>Linear allocators (sometimes called bump allocators) are one of the simplest and most useful custom allocators. The short version: Given a block of memory, start at the beginning and make allocations one after another. When you are done with all the allocations, free or reuse the block. Generally speaking you also need to deal with alignment, overflow, and out of memory issues, but none of that is particularly complicated. Linear allocators are great when you need scratch memory to build a temporary data structure, or otherwise know that all the data you are allocating has a finite lifespan. This works well when processing a user input event in a GUI, or a frame in a game. Not only does your data end up well packed for the CPU cache, but the actual cost of the allocation is just a tiny bit of arithmetic, and deallocation is basically free! The biggest downside of linear allocators is that you need to know the worst case memory usage up front.</p>

<p><strong>When to use it:</strong> When you need fast temporary memory with a finite lifespan.</p>

<h3 id="3-zone-allocator">3) Zone Allocator</h3>

<p><img src="https://slembcke.github.io/images/ZoneAllocator.svg" alt="Zone Allocator Diagram"></p>

<p>Zone allocators (sometimes called arena allocators) make linear allocators more flexible by relaxing the upfront memory allocation. Instead of a single block of memory, you make a series of linear allocators. Whenever one runs out of space, allocate another block and switch to it. Then all you need to do is keep a list of the blocks you allocate so they can be freed (or returned to a pool) when you are done with the zone.</p>

<p>Zone allocators are pretty simple to extend to be thread safe as well. Instead of a single linear allocator you can make one per thread as needed. Only the list of blocks shared by the zone’s linear allocators needs to be protected by a mutex.</p>

<p><strong>When to use it:</strong> When you need fast temporary memory with a finite lifespan, but don’t know how much you’ll need.</p>

<h3 id="4-buddy-block-allocator">4) Buddy Block Allocator</h3>

<p>The buddy block allocator is the fanciest allocator I’ve personally implemented. It’s pretty generic, and is exactly the sort of thing I thought would be a waste of time all those years ago. On the other hand it’s not particularly complicated, and my own implementation is barely 200 sloc. The basic idea is that you start with a large block of memory that you want to split up, and when you make allocations you recursively break the block into halves until you have the size you need. Since sub-blocks are always broken into pairs (buddies), it’s easy to figure out the location of any given block’s buddy with a little math. When freeing a block, you can easily check if the buddy is free and join them back together into a larger block.</p>

<p>While I can’t succinctly describe the whole algorithm in a paragraph, there are plenty of articles on the internet if you want a clearer picture. Also, keep in mind that while this is a pretty generic algorithm that you really <em>could</em> replace malloc() with, you might want to have a pretty good idea of why you’d want to. Maybe you have some strong latency constraints (audio, graphics, etc), or maybe you are allocating something that isn’t regular memory (ex: Vulkan memory). I’ve only used my implementation in a real-time audio synthesizer, but it would have been fine without it too. It was for a hobby project, and it was fun. :)</p>

<p><strong>When to use it:</strong> When you need a general purpose allocator with predictable performance.</p>

<h2 id="why-not-bother-with-custom-allocators">Why not bother with custom allocators!</h2>

<p>Hopefully I’ve convinced somebody that custom allocators aren’t a terrible idea after all, and given them some terms to search for more information.</p>

<p>Happy allocating! :)</p>

  </div>
</article>

      </div>
    </div></div>]]>
            </description>
            <link>https://slembcke.github.io/2020/10/12/CustomAllocators.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24762840</guid>
            <pubDate>Tue, 13 Oct 2020 06:28:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Predict a Reddit user's Myers-Briggs type from their profile]]>
            </title>
            <description>
<![CDATA[
Score 108 | Comments 122 (<a href="https://news.ycombinator.com/item?id=24762449">thread link</a>) | @ragnarkar
<br/>
October 12, 2020 | https://gimmeserendipity.com/mbtimodel/reddit/ | <a href="https://web.archive.org/web/*/https://gimmeserendipity.com/mbtimodel/reddit/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  

<title>Predict a Reddit User's MBTI Personality</title>

<form method="POST" action="/mbtimodel/reddit/" enctype="multipart/form-data">



<br>
<label for="message"><h4>Enter username here: </h4></label>


</form>
<p>Please be patient, this could take up to a minute to process.</p>


</div></div>]]>
            </description>
            <link>https://gimmeserendipity.com/mbtimodel/reddit/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24762449</guid>
            <pubDate>Tue, 13 Oct 2020 05:05:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[At Home Covid-19 Testing for Pirates – Hello Virology]]>
            </title>
            <description>
<![CDATA[
Score 37 | Comments 7 (<a href="https://news.ycombinator.com/item?id=24761208">thread link</a>) | @nikoftime
<br/>
October 12, 2020 | https://www.hellovirology.com/2020/10/at-home-covid-testing-for-pirates.html?hn | <a href="https://web.archive.org/web/*/https://www.hellovirology.com/2020/10/at-home-covid-testing-for-pirates.html?hn">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<div id="post-body-6021876468798783801">

<p>
In the age of COVID, we are all worried all the time. Am I sick? Did he just breathe on me? Will I kill my parents? I’m not even worried for myself, I say, but am I going to be the asshole that infects everyone? Every decision feels so heavy<sup id="fnref1"><a href="#fn1" rel="footnote">1</a></sup> all of the time. It’s exhausting.
</p>
<p>
A friend told me one day: a group of friends planned a get-together, and everyone got tested in the morning at a nearby center with a turnaround of a couple hours.
</p>
<p>
Brilliant. Testing. How obvious a salve! If I could know with reasonable confidence before and after an event that I was safe, I wouldn’t have to worry so much about killing my friends and parents, and I could do more things and see more humans. 
</p>
<p>
But, of course, in my area, I couldn’t find a testing center that would even test me without symptoms, much less give a sub-day turnaround. And, given the timeline of infection, I would really want frequent access to testing to make sure I wasn’t missing the onset of an infection. Alas.
</p>
<p>
I admit I raged against the machine a little— how can we not have better testing infrastructure at this point<sup id="fnref2"><a href="#fn2" rel="footnote">2</a></sup>? Why isn’t every PCR in the country running around the clock? Heck, I ran tests like that all the time in the lab— how hard could it be?
</p>
<p>
“How hard could it be?” — famous last words in tech. But I decided to find out, and it turns out that the answer is… not that hard. It’s actually surprisingly easy to set up, and I now have an at-home COVID testing rig that I have been using to test myself and my family. There are many caveats to that statement, and I will get to those, but, first— let me tell you a little bit more about how I set everything up.
</p>
<h3>What is a PCR, anyway?</h3>


<p>
There are a number of new technologies being developed to make testing for COVID easier, faster, and cheaper<sup id="fnref3"><a target="_blank" href="#fn3" rel="footnote">3</a></sup>, but the gold-standard is still a PCR-based test that looks for fragments of RNA from the virus. PCR stands for “polymerase chain reaction,” and it refers to the well-established process by which scientists can make copies of a given piece of DNA: a sample containing the target DNA, special DNA fragments called “primers,” and special enzymes are run through a temperature cycling program that replicates the target DNA sequence, doubling the number of target fragments with each pass through the program.
</p>

<table><tbody><tr><td><img height="413" src="https://lh4.googleusercontent.com/uBntKNqjM4N2JygvtofhLXkS0i1bDYqRg0rqiuUj9cE8y3IDyYQHK8j5RtLcGasq2-Bd54U16PK0vuiLbyi4apbmnHQmSrf10tt0uOsVPweazD5yc9sgdFFjsKqnLxMs85P1FAfQ=w640-h413" width="640"></td></tr><tr><td>Through a thermal cycling program, DNA is replicated. The magic of science.&nbsp;<br></td></tr></tbody></table><p>
PCR is run on a PCR machine. The simplest versions of these are thermal cyclers: there are little holes to put lab-sized plastic tubes in, and the machine runs programmed temperature patterns. These machines are used extensively in labs and clinics to create libraries of DNA fragments being studied for any number of reasons. 
</p>
<p>
A variation on the PCR theme is what’s called a “real-time PCR machine”<sup id="fnref4"><a target="_blank" href="#fn4" rel="footnote">4</a></sup>: a thermal cycler with the ability to measure fluorescence. Instead of just replicating the DNA fragment, a real-time PCR replicates the fragment via its thermal program while also measuring the amount of fluorescent signal created by the process of replicating each fragment in the presence of special fluorescent molecules<sup id="fnref5"><a target="_blank" href="#fn5" rel="footnote">5</a></sup>. A real-time PCR machine thus enables scientists to run a process called quantitative PCR, or qPCR, which answers the critical question, “How much of a given DNA fragment exists in this sample?” 
</p>
<p>
<a target="_blank" href="https://www.fda.gov/media/134922/download">The CDC protocol for COVID testing</a> relies on qPCR: collect a sample from the patient, extract the DNA and RNA from the sample, add special DNA fragments called “primers” that match the genetic sequence of SARS-CoV-2, and run qPCR to measure the amount of DNA in the sample that matched the SARS-CoV-2 primers. 
</p>
<p>
So, clearly, the first thing I needed to run an at-home COVID test was a real-time PCR. There are a number of major manufacturers, including <a target="_blank" href="https://lifescience.roche.com/en_us/brands/realtime-pcr-overview.html#qpcr-instruments">Roche</a> and <a target="_blank" href="https://www.bio-rad.com/en-us/category/real-time-pcr-systems?ID=059db09c-88a4-44ad-99f8-78635d8d54db">Bio-Rad</a>, but new top-of-the-line real-time PCR machines cost upwards of $20,000, which is more than I am willing to commit. There are also <a target="_blank" href="https://www.alibaba.com/trade/search?fsb=y&amp;IndexArea=product_en&amp;CatId=&amp;SearchText=real-time+pcr+system">manufacturers in China that sell on Alibaba</a>, but I couldn’t tell which machines would actually be real-time PCRs with software sufficiently in English for me to operate. Plus, after contacting several companies, it seemed they were reticent to ship to the US given regulations anyhow.
</p>
<p>
Which left the resale market. I was skeptical I could find anything given what I assumed would be a worldwide shortfall of PCRs, but I was happy to discover that the market for used real-time PCRs is robust: in addition to dedicated <a target="_blank" href="https://www.biosurplus.com/">used lab supply retailers</a>, there are a <a target="_blank" href="https://www.ebay.com/sch/i.html?_from=R40&amp;_trksid=p2380057.m570.l1311&amp;_nkw=real+time+pcr&amp;_sacat=0">wide range of systems available on eBay</a>. I watched the inventory cycle for a while, and soon enough found a good deal on the machine I wanted, the Applied Biosystems StepOne<sup id="fnref6"><a href="#fn6" rel="footnote">6</a></sup>. That was the machine I had used in the lab when getting my PhD, so I knew that it had the capabilities I needed and that the software would be ye olde and Windows-only, but usable. 
</p>



<h3>A lab to call my own</h3>


<p>
And so, for $5,000, I became the happy owner of a <strong>real</strong> real-time PCR. COVID-testing aside, real-time PCRs are workhorses of genomics labs, useful for any number of experiments, so I figured if nothing else, I was one step closer to having my own private lab space. But, reading through the CDC protocol, I realized how much standard equipment is assumed in a lab or clinic: freezer, centrifuge, eppies, tube racks, pipettes, ethanol, distilled water, and much more, even before you get to actual reagents (that is, the consumable chemicals).
</p>
<p>
Luckily, <a target="_blank" href="https://www.ebay.com/">eBay</a> and <a target="_blank" href="https://www.amazon.com/">Amazon</a> are here to help. I was quite impressed by how easy it was to quickly stock my lab with everything from pipette tips to saline. The centrifuge and pipettes I bought used; I first tried cheap new pipettes from Alibaba, but they were clearly inaccurate and inconsistent. That left the reagents and consumables. Most, including the expensive enzymes required for qPCR, came from <a target="_blank" href="https://www.thermofisher.com/">ThermoFisher</a>, and the rest came from any number of lab supply companies that turn up in Google searches.
</p>
<p>
All in all, I got everything I needed for less than $8,000 (the final supply list is <a target="_blank" href="https://docs.google.com/spreadsheets/d/1-3OBo0eH2512aYwh1O4uRNhoznlhtOHyqC2SRx1Mx1c/edit?usp=sharing">here</a>). Finding a place to put it all was tricky, especially while we’re all in our apartment all the time, but I had one dresser’s worth of space to spare. And so, in our guest bedroom above our linens and next to our assortment of exercise equipment, I now have my very own COVID-testing facility.
</p><table><tbody><tr><td><img height="480" src="https://lh6.googleusercontent.com/aYjbyGzxesocl7eDklxE_ScwNnLrlc3Bl4sMe7-yWzVCpWNmZo2X96efzQgEnj8D9atBv-qdqrgnns7JnBPhzZUh8YZohFdgiGORXWWOh_jifkzJE1Co8PMwtTVWMilDiYslbvam=w640-h480" width="640"></td></tr><tr><td>Don’t mind the hand towels I’m using to line the dresser.<br></td></tr></tbody></table>

<h3>Running an at-home COVID test</h3>


<p>
It takes me about two hours of hands-on time to collect and prep samples, plus an hour to run the PCR and analyze results. I’m intentionally not going to go through the details of the testing protocol itself; I used the <a target="_blank" href="https://www.fda.gov/media/134922/download">published CDC protocol</a>, and if you are not familiar enough with RNA extraction and qPCR to follow that protocol, then I can’t be held responsible for what you do. But, at a high level:
</p>
<ol>

<li>Nasal swabbing seems gross, so I collect a <a target="_blank" href="https://www.cdc.gov/flu/pdf/professionals/flu-specimen-collection-poster.pdf">throat swab</a>. This is the most dangerous part of the process for me as the “clinician”; reaching into the mouth of a potentially infected person is foolhardy. So, I only run the test for people who I am willing to die for<sup id="fnref7"><a href="#fn7" rel="footnote">7</a></sup>, and I have people self-swab for good measure.

</li><li>I use an <a target="_blank" href="https://www.thermofisher.com/order/catalog/product/12280050#/12280050">Invitrogen viral extraction kit</a> to lyse cells and collect RNA and DNA.

</li><li>Starting at the cell lysis step, I introduce a SARS-CoV-2 positive control (a fragment of the SARS-CoV-2 genome as a DNA plasmid) alongside the real human samples.

</li><li>I run reverse transcription (the process of turning RNA, either from the patient or the virus, into DNA) and qPCR in one go with a <a target="_blank" href="https://www.thermofisher.com/order/catalog/product/4444432#/4444432">TaqMan 1-step master mix</a> and each of three primers: two for SARS-CoV-2 genome targets and one negative control (a common human gene, RnaseP). I typically run two replicates per primer per sample to guard against my own imprecision.

</li>
  <li>In theory, qPCR would allow me to run comparative analyses, to determine how much SARS-CoV-2 is detectable in samples relative to the internal controls. However, all I really care about is the binary result, as ANY positive signal for the SARS-CoV-2 would warrant an official clinical test.

</li>
</ol>

<table><tbody><tr><td><img height="640" src="https://lh6.googleusercontent.com/URxJhR4w9LRMYyTacShsf_FDxIZtGt1WvBb3rrKG_4yi1rEdy8BiHXnfiHvyk6Mx6OhFVTrYfE-ySW0HczAawHITkE1zjDMCh7jxE_aTOwhIdVdwXsF2Im7uSs3D3fQ-NXRPZQtZ=w480-h640" width="480"></td></tr><tr><td>We have a lax shoe policy in our lab.<br></td></tr></tbody></table>

<table><tbody><tr><td><img height="366" src="https://lh4.googleusercontent.com/fzWQtnZX3bZ5CYpw4lo25PbQGaP67MhjKOnYf2JW-18GCmaFd8b07KAyH5CAL4gTOvv94dWd6uFGZWm8ItwCkRGuHbhfDTyyj8J00dn_msxjlA0Enmu4TVumDSmuTzVGTdidPtSn=w640-h366" width="640"></td></tr><tr><td>The software runs in Parallels on my Mac laptop, so that I can watch the happy rainbows of successful qPCR form as the program runs.</td></tr></tbody></table>

<table><tbody><tr><td><img height="410" src="https://lh6.googleusercontent.com/gmRHZ8UWYylh9Jj9X5eHqRYKMqAW3RucinRhLGhzBPbl2uTBtpqJARgZ32Xr9_G3_G7yIu2z1ZhDAr7A55klsomI0VPrzegxoXyOoxYIC62wtGj3AFvrK33h7jW56YYo1u3BiRcy=w640-h410" width="640"></td></tr><tr><td>The first two sets of bars represent signal from SARS-CoV-2 genes, while the third set is a common human gene used as a control. The y-axis represents the number of cycles of the thermal program required to detect signal for the target sequence, with bars at zeroish for no signal detected. The hardest part was getting Google Sheets to draw error bars, which proved impossible. Luckily, I only need the binary answer.<br></td></tr></tbody></table>

<h3>How reliable is testing?</h3>
<p>
I have now run a number of tests for myself and my family. Notably, I have not tested a COVID-positive person so far as I know, so I am not sure yet if any of this works at all. But the internal controls give me some confidence; I figure if I can successfully scrape human RNA off the inside of your throat, but not any viral RNA, chances are you’re not shedding a ton of viral particles in any case.
</p>
<p>
That said— I’m doing this in my house. Barefoot. Even if it were 100% accurate, there would still be a fourish day incubation window to contend with, during which someone could test negative but still be a threat. And I am of course not 100% accurate; even the official clinical tests have an error rate, and can return false positives (that is, return a positive result when the patient is uninfected) or false negatives (that is, return a negative result when the patient is infected). 
</p>
<p>
My lower-bound estimate is that my test is 90% accurate, so I use the 10% chance I am wrong to scale the base risk percentage. For example:
</p>
<ul>

<li>Marla is very conservative about her COVID risk, and for the two weeks prior to testing, she goes to the market twice, with a mask. She has not experienced any symptoms of COVID in relevant memory. We can ball-park Marla’s risk as 0.1% chance she has COVID. If we additionally test her and she comes back negative, there is 10% …</li></ul></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.hellovirology.com/2020/10/at-home-covid-testing-for-pirates.html?hn">https://www.hellovirology.com/2020/10/at-home-covid-testing-for-pirates.html?hn</a></em></p>]]>
            </description>
            <link>https://www.hellovirology.com/2020/10/at-home-covid-testing-for-pirates.html?hn</link>
            <guid isPermaLink="false">hacker-news-small-sites-24761208</guid>
            <pubDate>Tue, 13 Oct 2020 00:50:39 GMT</pubDate>
        </item>
    </channel>
</rss>
