<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 20]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 20. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Sun, 09 Aug 2020 08:19:39 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-20.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Sun, 09 Aug 2020 08:19:39 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[Terminating a Frozen SSH Session]]>
            </title>
            <description>
<![CDATA[
Score 37 | Comments 31 (<a href="https://news.ycombinator.com/item?id=24076656">thread link</a>) | @erredois
<br/>
August 6, 2020 | https://www.remembertheusers.com/2020/07/0668-terminating-a-frozen-ssh-session.html | <a href="https://web.archive.org/web/*/https://www.remembertheusers.com/2020/07/0668-terminating-a-frozen-ssh-session.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  <div>
   <div>
    

    <p>One of my observations about computer software is no matter how much I know there is something new to learn every day.</p>

    <p>I have been using SSH for many years. I use a local <code>config</code> file and multiple key pairs to connect to remote systems.</p>

    <p>Occasionally an SSH session times out or somehow freezes. Often this leaves the terminal window in a frozen state, requiring a forced closure.</p>

    <p>Except a forced closure might not be needed. There is a built-in SSH escape trigger.</p>

    <p>Press the <code>~</code> (tilde) key. Notice that the <code>~</code> won’t appear on screen when the character is the very first character typed. The character prints on screen normally when not the first character.</p>

    <p>To view a list of available options with this escape trigger type <code>~?</code>.</p>

    <p>To force terminate a frozen SSH session, press <code>~.</code>. The result is much the same as <code>Ctrl+C</code> or <code>Ctrl+D</code> to terminate a process.</p>

    <p>The escape character can be changed using the <code>-e</code> option.</p>

    <p>Posted: <span>July 19, 2020</span> Category: <span><a href="https://www.remembertheusers.com/categories/usability.html">Usability</a></span> Tagged: <span><a href="https://www.remembertheusers.com/tags/general.html">General</a></span></p>

    <p>Next: <span><a href="https://www.remembertheusers.com/2020/07/0669-resolving-problems.html">Resolving Problems</a></span></p>

    <p>Previous: <span><a href="https://www.remembertheusers.com/2020/07/0667-google-captchas.html">Google Captchas</a></span></p>
   </div>
  </div>
 </div></div>]]>
            </description>
            <link>https://www.remembertheusers.com/2020/07/0668-terminating-a-frozen-ssh-session.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24076656</guid>
            <pubDate>Thu, 06 Aug 2020 23:58:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[First Impressions of Rust]]>
            </title>
            <description>
<![CDATA[
Score 181 | Comments 113 (<a href="https://news.ycombinator.com/item?id=24076083">thread link</a>) | @jmillikin
<br/>
August 6, 2020 | https://john-millikin.com/first-impressions-of-rust | <a href="https://web.archive.org/web/*/https://john-millikin.com/first-impressions-of-rust">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><blog-article posted="2020-08-06T22:23:05Z"><p><img src="https://john-millikin.com/first-impressions-of-rust/crab.jpg"></p><p>I've been wanting to write a big project in <a href="https://www.rust-lang.org/">Rust</a> for a while as a learning exercise, and actually started one in late 2018 (a FUSE server implementation). But then life happened and I got busy and never went anywhere with it. Due to certain world circumstances I'm currently spending a lot of time indoors so <a href="https://github.com/jmillikin/rust-fuse">rust-fuse</a> (<a href="https://jmillikin.github.io/rust-fuse/fuse-v0.0.1-a6ad16d1127d36f80e6d02f36e48da56920ca693/fuse/">docs</a>) now exists and is good enough to write basic hello-world filesystems. I plan to polish it up a bit more with the goal of releasing a v1.0 that supports the same use cases as <a href="https://github.com/libfuse/libfuse">libfuse</a>.</p><p>I took some notes along the way about things that struck me as especially good or bad. Overall I quite like Rust the language, have mixed feelings about the quality of ancillary tooling, and have strong objections to some decisions made by the packaging system (Cargo + crates.io).</p><blog-section><h2 slot="title">Background</h2><p>I've been programming professionally for 15 years, primarily network servers and GUIs on Linux. Between roughly 2009 and 2015 I experimented with using Haskell for systems programming, writing several projects in pure Haskell (<a href="https://john-millikin.com/software/haskell-dbus">haskell-dbus</a>, <a href="https://john-millikin.com/software/anansi">Anansi</a>) and as bindings (<a href="https://john-millikin.com/software/haskell-ncurses">haskell-ncurses</a>, <a href="https://john-millikin.com/software/haskell-cpython">haskell-cpython</a>). However, I couldn't achieve the sorts of reliability improvements over bread-and-butter C++ that I had hoped for:</p><ul><li>Haskell has a lot of tools for reasoning about the structure of computation, notably monads for declarative I/O, but it doesn't do much to help the programmer with non-algorithmic concerns such as memory lifetimes. I spent a lot of time debugging dangling pointers and race conditions.</li><li>I found it very difficult to write Haskell code that could run as fast as C. Avoiding allocation, auto-boxing, etc felt like it required a deep knowledge of undocumented or unspecified GHC behavior.</li></ul><p>In late 2015 I started rough sketches for a new language, Funk, that would combine the type-safety of Haskell with the low-level precision of C/C++. Funk was strongly influenced by Google's internal dialect of C++, which uses smart pointers and sum types (e.g. <tt>StatusOr&lt;T&gt;</tt>) to improve memory safety – many of its features later became part of the C++11 and C++14 standards. To this foundation I bolted on Haskell-style typeclasses and modules, then started writing a Funk-to-C translator based on <a href="https://wiki.gnome.org/Projects/Vala/Documentation">Vala</a>.</p><p>At some point I was looking around for inspiration on how to handle memory allocation (I planned to use scoped arenas as the fundamental dynamic memory system) and I discovered Rust. Here was a language that was solving the same problems as Funk but (1) better designed (2) already implemented and (3) supported by an entire team of compiler experts. So that was that, Funk went to <tt>/dev/null</tt> and I logged a TODO to learn Rust.</p></blog-section><blog-section><h2 slot="title">The Rust language</h2><p>It shouldn't come as a surprise that someone looking for a cross between C++ and Haskell would like Rust, but I want to be clear: I really <i>really</i> enjoy using Rust. It is nearly everything I want in a systems programming language, and the few parts it's missing are due to legitimate technical difficulty. The amount of careful thought I've seen put into its design – crafting <tt>async/await</tt> to work in <tt>no_std</tt> environments, or the <a href="https://blog.rust-lang.org/inside-rust/2020/06/08/new-inline-asm.html">new inline assembly syntax</a> – has produced a language that is not only better than what I could have designed, it's better among axes I was not even aware existed prior to reading the Rust RFCs.</p><p>The "nightly" release channel is an excellent idea that I wish more infrastructure software made use of. Stabilizing individual features on their own schedules lets the compiler maintain a blistering release cadence (stable releases every <i>six weeks</i>!). Users are empowered to choose their own preferred point on the maintenance/velocity curve, opting in to higher upgrade costs in exchange for early access to new features. The "editions" system goes a bit further, derisking backwards-incompatible syntax changes that would have stymied C++ for decades (see: trigraphs).</p><blog-section><h3 slot="title">Type system</h3><p>Rust has a reasonable amount of Haskell-style type programming, though I wouldn't mind a <i>bit</i> more. Some parts of its type system are limited in non-intuitive ways – for example only lifetime-kinded type parameters can be universally quantified in a trait bound. I hit a lot of compiler errors that recognized exactly what I wanted to do but wouldn't let me do it.</p><p>I wish Rust's type system supported:</p><ul><li>Closed-world ("sealed") traits. Rust's rules against private types in the public API are good civilization but they make it difficult to define pseudo-private traits like <tt>Mount</tt> that I want users to name but not implement or call into.</li><li>Associated types in structs. Rust lets traits have associated types, and structs can have associated <i>values</i>, but there's no equivalent to the nested type names found in C++ or Java.</li><li>Very basic dependent typing, or maybe something like Eiffel's contracts, for the purpose of eliminating array bounds checks. I'd like to be able to say "this function accepts a <tt>&amp;[u8]</tt> of at least <tt>size_of&lt;SomeType&gt;</tt>" so I can do safe unchecked byte poking.</li></ul></blog-section><blog-section><h3 slot="title">Standard library</h3><p>There's a lot of standard UNIX functionality that's missing from the Rust standard library. Some of it is more-or-less available from separate packages like <a href="https://crates.io/crates/nix">nix</a>, but I shouldn't have to depend on four crates plus a C compiler to get access to <tt>getuid()</tt>. I shouldn't have to depend on <i>anything</i> to get the definition of <tt>ENOSYS</tt> or the size of <tt>c_ulong</tt>. Go is the gold standard here – it can cross-compile to a Linux target from macOS using its own copies of the Linux syscall table – and even Haskell has <a href="http://hackage.haskell.org/package/base-4.14.0.0/docs/Foreign-C-Types.html"><tt>Foreign.C.Types</tt></a>.</p><p>A <tt>std::os::unix</tt> without <tt>getuid()</tt> is incomplete but can be worked around with a small <tt>extern "C"</tt> block. Much worse is the lack of macro-dependent functions like <tt>recvmsg()</tt>, which is not a great API to begin with, or functions with OS-dependent arity like <tt>mount()</tt>. Rust is not averse to providing clean wrappers around the OS library – the <tt>std::fs</tt> and <tt>std::process</tt> modules contain little else – so it's frustrating to see these very basic functions left out.</p></blog-section></blog-section><blog-section><h2 slot="title">Tooling</h2><blog-section><h3 slot="title">rustdoc</h3><p>I categorize documentation generators into two basic groups:</p><ul><li>First is the <a href="https://www.sphinx-doc.org/">Sphinx</a> group, which consumes prose and uses embedded pragmas to reference symbols of the library being documented. The output layout tends to be textbook-like, containing long "chapters" that might cover entire modules in one HTML file. Sphinx-style docs are popular among Python programmers.</li><li>Second is the <a href="https://www.doxygen.nl/">Doxygen</a> group, which consumes source code and generates a rigidly-structured catalog of symbols with optional attached prose. The output feels more like an encyclopedia or reference manual.</li></ul><p><tt>rustdoc</tt> is obviously in the second category. It is designed to consume doc comments, which are special-cased by the Rust compiler, and produces output closely matching the structure of the exported API. At this task <tt>rustdoc</tt> does a reasonable job: the page layout is navigable, the markup format (<tt>rustdoc</tt> uses Markdown) isn't great but it could be worse, and it doesn't hardcode absolute file paths into the output like Haddock.</p><p>Some of its annotations, like whether a symbol is OS-specific (<a href="https://github.com/rust-lang/rust/issues/43781">rust-lang/rust#43781</a>), are gated to the Nightly toolchain. It's not obvious to me why they do this – it's a documentation generator, why does it care what version of the Rust compiler I'm using? What's more, some of its functionality is reserved for the standard library only. I can't mark fields as unstable (subject to change in future library versions) because that annotation is based on the <tt>#[unstable]</tt> attribute, which the compiler reserves for its own use. Ditto for annotations about which version a symbol was added in. If I'm going to use a Doxygen-group tool then I don't want it to get too fussy about what libraries it's documenting.</p></blog-section><blog-section><h3 slot="title">rustfmt</h3><p>Something like a cross between <tt>gofmt</tt>, <tt>clang-format</tt>, and GNU indent. It has a lot of configuration options but all the interesting ones are gated to Nightly, and most of those are much less useful than you might expect.</p><p>As a representative sample, consider <tt>rustfmt</tt>'s handling of hard tabs. Given the following input there are two basic ways you might use hard tabs to indent it, depending on whether struct value alignment should apply to nested structs:</p><blog-code><pre>MyStruct{
  field_with_long_name: (some_big_complex_variable_name + another_big_complex_variable_name),
  another_field: 123,
  nested_struct: &amp;NestedStruct{
    nested_struct_field: 456,
  },
  final_field: 123,
}
</pre></blog-code><p>The first is to treat the nested struct as a "break" in the alignment (<tt>gofmt</tt> does this). I've drawn the tabs as <span>████</span> for clarity:</p><blog-code><pre><code>MyStruct{
<span>████</span>field_with_long_name: (some_big_complex_variable_name
<span>████</span>                       + another_big_complex_variable_name),
<span>████</span>another_field:        123,
<span>████</span>nested_struct: &amp;NestedStruct{
<span>████████</span>nested_struct_field: 456,
<span>████</span>},
<span>████</span>final_field: 123,
}
</code></pre></blog-code><p>The second is to align all the values, including the nested struct, and introduce a nested layer of tabs:</p><blog-code><pre><code>MyStruct{
<span>████</span>field_with_long_name: (some_big_complex_variable_name
<span>████</span>                       + another_big_complex_variable_name),
<span>████</span>another_field:        123,
<span>████</span>nested_struct:        &amp;NestedStruct{
<span>████</span>                      <span>████</span>nested_struct_field: 456,
<span>████</span>                      },
<span>████</span>final_field:          123,
}
</code></pre></blog-code><p>But what <tt>rustfmt</tt> produces is an indecisive and poorly formatted combo of the two – it doesn't even properly align the parenthesized expression after line-breaking it:</p><blog-code><pre><code>MyStruct {
<span>████</span>field_with_long_name: (some_big_complex_variable_name
<span>████████</span>+ another_big_complex_variable_name),
<span>████</span>another_field:        123,
<span>████</span>nested_struct:        &amp;NestedStruct {
<span>████████</span>nested_struct_field: 456,
<span>████</span>},
<span>████</span>final_field:          123,
}
</code></pre></blog-code><p>I eventually gave up on trying to make the formatted rust-fuse code look pretty, and settled for "consistent".</p></blog-section></blog-section><blog-section><h2 slot="title">Cargo and crates.io</h2><p>While the Rust language feels carefully designed to combine the best parts of multiple popular and interesting languages, Rust's default build system (Cargo) and package repository (crates.io) are the opposite. They combine the worst parts of Cabal/Hackage and NPM, resulting in a user experience that is somehow inferior to both.</p><blog-section><h3 slot="title">Pa…</h3></blog-section></blog-section></blog-article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://john-millikin.com/first-impressions-of-rust">https://john-millikin.com/first-impressions-of-rust</a></em></p>]]>
            </description>
            <link>https://john-millikin.com/first-impressions-of-rust</link>
            <guid isPermaLink="false">hacker-news-small-sites-24076083</guid>
            <pubDate>Thu, 06 Aug 2020 22:26:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Surviving Django, if you care about databases]]>
            </title>
            <description>
<![CDATA[
Score 139 | Comments 155 (<a href="https://news.ycombinator.com/item?id=24074520">thread link</a>) | @pauloxnet
<br/>
August 6, 2020 | https://www.varrazzo.com/blog/2020/07/25/surviving-django/ | <a href="https://web.archive.org/web/*/https://www.varrazzo.com/blog/2020/07/25/surviving-django/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  <div>
    <div id="content"><p>Django is currently the most commonly used full-stack web framework for Python. It has
been around for a good 15 years, emerging as a winner from a period in which
Python was already mature, but its web development tools were comparatively
much more immature and fragmented.</p>
<p>Django allows the definition of objects in your program as "models" using the
<tt>Model</tt> base class. They behave largely like normal Python classes, with
added support to save into, and retrieve from, the relational database backing
your application. If you don't need such database support, you didn't
need a full-stack web framework in first place.</p>
<p>Django tries to be independent from the database you choose. It sounds like
a good idea, but only on paper. After working several years
with Django systems, both written from scratch or inherited and maintained, I
feel the "blessed" way of working with databases and
Django leads you to using your database in a sub-optimal way, and unnecessarily complicates
the development and maintenance cycle of your project.</p>
<p>I think the divergence between wishful thinking and reality starts from a
fundamental misunderstanding between you and Django, which is not written in
the contract you haven't signed with them anyway:</p>
<blockquote>
"independence from the relational database" is a feature needed by Django
as a framework, <em>not by the program you are writing</em>.</blockquote>
<p>Django needs it because a web framework not tied to a single database vendor
is more valuable than one tied to a specific one - and that's fair enough. <em>But you
don't:</em> your web program, most likely than not, will not have to switch from
one database to another. So, <a href="https://www.martinfowler.com/bliki/Yagni.html">You Ain't Gonna Need It™</a>. Portability at all costs
leads to at least two problems:</p>
<p>1) You will not able to use all the features offered by your relational
database.</p>
<p>2) Every change to your models, or to your database schema, will be more
complicated than it should be.</p>
<div id="you-ain-t-gonna-need-it">
<h3>You Ain't Gonna Need It</h3>
<p>How many times have you worked on a project and, after 1-2 years of
development, you have changed to a different database?</p>
<p>I can tell you how many times it happened to me, I counted them: exactly
never.</p>
<p>Replacing your database vendor is a major, traumatic occurrence, almost as
much as rewriting your program in a different language. If you replace your
database, more likely than not, it is because you are interested in the
features of the new databas. You need to use them so using the common
functionalities between the old and the new one will not solve any of your
problems.</p>
<p>Did you maybe start your project with SQLite and now your project grew enough
to need a bigger database? If so then you are still at the phase in
which your project is a toy: you haven't done anything yet that requires
thinking in terms of concurrency. Even if you have to rewrite a few things,
it's not going to be a lot.</p>
<p>Do you have a large MySQL project and now you have to migrate to PostgreSQL?
That's not gonna happen: you have probably tweaked MySQL, have expertise in
MySQL. Maybe PostgreSQL might be a better database in some aspects, but not so much
that you want to migrate all your data and start from scratch without
<a href="http://www.catb.org/jargon/html/F/frobnicate.html">frobbing, twiddling, tweaking</a> the database configuration. Did you say
you have High Availability and Disaster Recovery configured? That's to be
converted too of course.</p>
<p>In the above paragraph, replace the database vendor with all the permutations
of MySQL, PostgreSQL, MS SQL, Oracle. <em>That's not gonna happen</em>. Except maybe
if an Oracle salesman gets hold of someone in your project with a modicum of
decision making and talks them into buying some sort of expensive license, but
that's not a technical problem, it's a political one, and it's up to you to
decide if you are comfortable with it.</p>
<p>Have you got PostgreSQL in production, but you want to test with SQLite because
it's easier to set up? If so, your tests are just a tick-box exercise: you
are not testing anything remotely plausible and resembling your live system.</p>
<p>Choosing a database happens in the first days of your projects, it will not
happen when the project is mature. You may as well use all the features
available with your database, not only the ones common enough that Django
created a Python wrapper for it.</p>
</div>
<div id="use-all-the-features">
<h3>Use all the features</h3>
<p>Scanning the schema of a Django program I've written and maintained for a few
years I see:</p>
<ul>
<li>Schemas (as in the "directory of the tables", not all the other meanings)</li>
<li>Custom domains</li>
<li>Collations</li>
<li>Triggers</li>
<li>Permissions</li>
<li>Partial indexes</li>
<li>Constraint exclusions</li>
<li>Views</li>
<li>Stored procedures</li>
<li>Partitioned tables</li>
</ul>
<p>If these features were used, it's because they allowed to implement
certain features needed for the program in a simpler way than what possible in
the language (if even would have been possible there). Audit for
instance: Django doesn't have an audit feature except for the changes made in
the admin. Even if you added some form of manual auditing to each <tt>save()</tt>
method, it will not capture changes made outside Django. It wouldn't be very
secure either: Django uses a single user to access the database so if someone
manages to hijack that user, they would be able to change the data in the database
and alter the audit tables to hide their traces.</p>
<p>In PostgreSQL you can:</p>
<ul>
<li>Create an "audit" user: it will have different permissions than the user of
the Django application.</li>
<li>Create an "audit" schema: revoking write permission to all the objects it
will contain from the Django user.</li>
<li>Create a function to append a record to an audit table owned by the "audit"
user, but callable by the Django user.</li>
<li>Add a trigger to the tables to audit.</li>
</ul>
<p>This setup requires Postgres-specific knowledge, which is fair for a feature
that has to watch over the database data whichever the origin of the change
is. But being PostgreSQL extensible as it is, you can <a href="https://github.com/dvarrazzo/pgaudit">use an extension</a> to automate the creation and
maintenance of the audit triggers and functions.</p>
</div>
<div id="so-where-do-i-put-the-schema">
<h3>So where do I put the schema?</h3>
<p>Into an SQL file!</p>
<p>With its tiny <tt>.sql</tt> extension!</p>
<p>And with comments! Explaining why a certain index or constraint exist!</p>
<p>With constraints named meaningfully, available for manipulation, not
<tt>auth_group_permissions_group_id_b120cbf9_fk_auth_group_id</tt>.</p>
<p>Sounds civilised to me.</p>
<p>The nice thing of doing this is that, if you do things carefully enough, Django
will not notice anything at all.</p>
<p>Take the above audit examples: Django is not meant to interact with it:
everything will just happen under its nose. You can use views instead of
tables for read-only models, you can use domains instead of more basic data
types for your fields: Django won't see your triggers triggering, your
constraints constraining, your permissions permitting - except when things go
wrong, which will result in an error 500 and a Python traceback. This is at least
better than bad data in the database. Also it won't see your procedures
proceeding, your domains dominating...you get the idea.</p>
<p>Using psql to import the schema into an empty database means you can modularise the
code and use <tt>\i</tt> to import "submodules". A typical pattern for me is to have
a <tt>database.sql</tt> to create global objects (users, extensions, schemas),
set the basic permissions and import the details into target schemas.</p>
<pre><span>\</span><span>i</span> <span>users</span><span>.</span><span>sql</span>
<span>revoke</span> <span>create</span> <span>on</span> <span>schema</span> <span>public</span> <span>from</span> <span>public</span><span>;</span>     <span>-- safety
</span>
<span>--- create a schema for the django app tables
</span><span>create</span> <span>schema</span> <span>myapp</span><span>;</span>
<span>grant</span> <span>usage</span> <span>on</span> <span>schema</span> <span>myapp</span> <span>to</span> <span>myapp</span><span>,</span> <span>backup</span><span>;</span>

<span>--- set the default permissions for all the object that will be created there
</span><span>alter</span> <span>default</span> <span>privileges</span> <span>in</span> <span>schema</span> <span>myapp</span>
    <span>grant</span> <span>select</span><span>,</span> <span>insert</span><span>,</span> <span>update</span><span>,</span> <span>delete</span> <span>on</span> <span>tables</span> <span>to</span> <span>myapp</span><span>;</span>
<span>alter</span> <span>default</span> <span>privileges</span> <span>in</span> <span>schema</span> <span>myapp</span>
    <span>grant</span> <span>select</span> <span>on</span> <span>tables</span> <span>to</span> <span>view</span><span>,</span> <span>backup</span><span>;</span>
<span>alter</span> <span>default</span> <span>privileges</span> <span>in</span> <span>schema</span> <span>myapp</span> <span>grant</span> <span>all</span> <span>on</span> <span>sequences</span> <span>to</span> <span>myapp</span><span>;</span>
<span>alter</span> <span>default</span> <span>privileges</span> <span>in</span> <span>schema</span> <span>myapp</span> <span>grant</span> <span>select</span> <span>on</span> <span>sequences</span> <span>to</span> <span>backup</span><span>;</span>

<span>--- import the tables into the schema
</span><span>set</span> <span>search_path</span> <span>to</span> <span>myapp</span><span>,</span> <span>public</span><span>;</span>
<span>\</span><span>i</span> <span>django</span><span>.</span><span>sql</span>   <span>-- django objects - users, groups, permissions tables
</span><span>\</span><span>i</span> <span>myapp</span><span>.</span><span>sql</span>    <span>-- your app models
</span><span>reset</span> <span>search_path</span><span>;</span>
</pre>
<p>The <tt>database.sql</tt> doesn't create the database itself so you can create an
empty one anywhere it's needed, then you can use <tt>psql <span>-f</span> database.sql
<span>"postgres://connection/url"</span></tt> to populate it. The <tt>myapp.sql</tt> file
shouldn't contain any reference to the schema <tt>myapp</tt> where the objects are
created so the schama can be easily changed. Postgres doesn't have a statement like
<tt>CREATE USER ... IF NOT EXIST</tt>: in <tt>users.sql</tt> you can simulate it with:</p>
<pre><span>do</span> <span>$</span><span></span><span>$</span>
<span>begin</span>
    <span>perform</span> <span>1</span> <span>from</span> <span>pg_user</span> <span>where</span> <span>usename</span> <span>=</span> <span>'myapp'</span><span>;</span>
    <span>if</span> <span>not</span> <span>found</span> <span>then</span>
        <span>create</span> <span>user</span> <span>myapp</span><span>;</span>
    <span>end</span> <span>if</span><span>;</span>
<span>end</span>
<span>$</span><span></span><span>$</span> <span>language</span> <span>plpgsql</span><span>;</span>
</pre>
</div>
<div id="migrations">
<h3>Migrations</h3>
<p>Django has an amazingly complex system to <a href="https://docs.djangoproject.com/en/3.0/topics/migrations/">perform model migrations</a>. It is
complex amongst other reasons because:</p>
<ul>
<li><p>It actually migrates <em>Python models</em> not <em>database schemas</em>. Even if you change a field's help
text, it generates a migration.</p>
<pre><span>class</span> <span>Migration</span><span>(</span><span>migrations</span><span>.</span><span>Migration</span><span>):</span>

    <span>operations</span> <span>=</span> <span>[</span>
        <span>migrations</span><span>.</span><span>AlterField</span><span>(</span>
            <span>model_name</span><span>=</span><span>'foo'</span><span>,</span>
            <span>name</span><span>=</span><span>'bar'</span><span>,</span>
            <span>field</span><span>=</span><span>models</span><span>.</span><span>BooleanField</span><span>(</span><span>help_text</span><span>=</span><span>'I only changed this'</span><span>),</span>
        <span>),</span>
</pre>
<p>That's not useful at all for the database, but Django will create it for you
and if you remove it, it will add it back. Similarly, changing a <a href="https://docs.djangoproject.com/en/3.0/ref/models/fields/#choices">choices
list</a>, a display label, results in migrations with no database operation,
only a Python operation, and practically no SQL purpose.</p>
</li>
<li><p>It allows access to the state of the model at times intermediate between
migrations, using <a href="https://docs.djangoproject.com/en/3.0/ref/applications/#django.apps.AppConfig.get_models">get_model</a><tt>(appname, modelname)</tt> and with some
Python code in the returned model. But if that code also happens to use
any code inside your application, importing models with a normal Python
<tt>import</tt>, things will crash because of a mismatch between model
definitions and schema in the database. But they won't crash immediately: only
later when you will apply some unrelated migration. And not when that
migration is needed: only after it has already been applied and it doesn't
have anything more to do in its lifetime: it is implemented as a model that
Django will keep on importing over and over. In a …</p></li></ul></div></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.varrazzo.com/blog/2020/07/25/surviving-django/">https://www.varrazzo.com/blog/2020/07/25/surviving-django/</a></em></p>]]>
            </description>
            <link>https://www.varrazzo.com/blog/2020/07/25/surviving-django/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24074520</guid>
            <pubDate>Thu, 06 Aug 2020 19:28:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Busted retailers use bankruptcy to break leases by the thousands]]>
            </title>
            <description>
<![CDATA[
Score 199 | Comments 249 (<a href="https://news.ycombinator.com/item?id=24074311">thread link</a>) | @finphil
<br/>
August 6, 2020 | https://www.bnnbloomberg.ca/busted-retailers-use-bankruptcy-to-break-leases-by-the-thousands-1.1476347 | <a href="https://web.archive.org/web/*/https://www.bnnbloomberg.ca/busted-retailers-use-bankruptcy-to-break-leases-by-the-thousands-1.1476347">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>With the pandemic intensifying the plight of U.S. retailers, companies from J. Crew Group Inc. to the owner of Ann Taylor are using Chapter 11 bankruptcy filings to quickly get out of costly, long-term leases and shutter thousands of stores.</p>

<p>By seeking court protection, firms like Neiman Marcus Group Inc. and the parent company of Menâ€™s Wearhouse avoid the headache of protracted negotiations with individual landlords. But the moves threaten to upend huge swaths of the real estate market and the half-trillion dollar market for commercial mortgage-backed securities.</p>

<p>â€œThis is now black-letter law -- a debtor can cram down a landlord,â€� said Melanie Cyganowski, a former bankruptcy judge whoâ€™s now a partner at law firm Otterbourg PC. â€œIf this becomes a tsunami of retailers rejecting their leases, itâ€™s going to trigger another part of the sea change -- the mortgages held by the landlords.â€�</p>

<p>As bankrupt firms like J.C. Penney Co. and Brooks Brothers Group Inc. look to jettison leases, landlords are already feeling the consequences. CBL &amp; Associates Properties Inc., owner of more than 100 shopping centers in the U.S., is preparing its own bankruptcy&nbsp;filing&nbsp;after rent collections cratered. And 16 per cent&nbsp;of retail property loans bundled into CMBS were delinquent in July, according to research firm Trepp.</p>

<p><strong>Filing Surge</strong></p>

<p>At least 25 major retailers have filed for bankruptcy this year, according to data compiled by Bloomberg. The most recent additions include Tailored Brands Inc., owner of Menâ€™s Wearhouse and Jos. A. Bank, which is seeking to&nbsp;close&nbsp;about a third of its more than 1,200 stores, and Lord &amp; Taylor parent company&nbsp;Le Tote, which said it could shut down all of the department storeâ€™s remaining locations.</p>

<p>â€œItâ€™s economical, itâ€™s efficient and it allows retailers to rationalize their footprint quickly,â€� said Fred Ringel, co-chair of the business finance and restructuring practice at the law firm Robinson Brog Leinwand Greene Genovese &amp; Gluck P.C. Ringel, who works for landlords, said heâ€™s busier than ever renegotiating leases and in some cases persuading tenants to forgo cancellations and stay under modified terms.</p>

<p><img alt="Embedded Image" height="750" src="https://www.bnnbloomberg.ca/polopoly_fs/1.1476348!/fileimage/httpImage/image.png_gen/derivatives/default/a-pedestrian-wearing-a-protective-mask-walks-past-a-boarded-up-j-crew-group-inc-store-on-14th-street-in-washington-d-c-u-s-on-thursday-april-16-2020-on-wednesday-mayor-muriel-bowser-announced-an-extension-of-the-shutdown-of-nonessential-businesses-until-may-15-after-the-original-date-of-april-24.png" width="1296"></p>

<p>Take vitamin retailer GNC Holdings Inc. It operates hundreds of stores across the country, mostly in strip malls. Since filing for bankruptcy in June, GNC has asked to reject at least 500 leases, along with more than 50 franchise agreements and subleases, according to court records.</p>

<p>Meanwhile, CEC Entertainment Inc., the parent company of Chuck E. Cheese, is negotiating with its landlords after its June bankruptcy filing. It won court approval this week to defer rent payments as it evaluates which locations it wants to keep open.</p>

<p>And the U.S. unit of Spanish retailer Desigual said it was forced to file after struggling to get rent abatements from its landlords. â€œUnfortunately, DUSA had little success in getting landlords to realize the new reality that most tenants -- especially those in retail -- cannot afford to pay pre-COVID-19 rent,â€� a representative for the firm said in court papers.</p>

<p>Landlords, in turn, have their own mortgages to worry about, which were also underwritten with pre-pandemic assumptions about rent collections. Amid the stress, Barry Sternlichtâ€™s Starwood Capital Group&nbsp;missed&nbsp;payments on securitized debt linked to five shopping malls, and Saks owner Hudsonâ€™s Bay Co. also&nbsp;skipped&nbsp;interest due on certain CMBS. Delinquencies on retail mortgages bundled into bonds climbed to 16 per cent&nbsp;in July, from 3.8 per cent&nbsp;in January, according to Trepp.</p>

<p><strong>Tenant Power</strong></p>

<p>Some retailers can work out rent abatements and other lease modifications including terminations without filing for bankruptcy. However, negotiating hundreds of deals outside of a court process can be challenging, especially for big retail chains that may have hundreds of landlords to deal with, said Navin Nagrani, an executive vice president at Hilco Real Estate.</p>

<p>Bankruptcy flips the power from landlords to tenants. Retailers can legally reject a swath of leases in court, sometimes leaving building owners to collect just pennies on the dollar. Firms can also sell off favorable contracts to other parties to help repay creditors.</p>

<p>â€œSometimes a bankruptcy is the most advantageous way to get out of those leases,â€� Nagrani said.</p>

<p>As many as 25,000 stores are expected to close in the U.S. in 2020, mostly in shopping malls, according to Coresight Research. Department stores and fashion boutiques are seen as the most endangered.</p>

<p><img alt="Embedded Image" height="675" src="https://www.bnnbloomberg.ca/polopoly_fs/1.1476623!/fileimage/httpImage/image.png_gen/derivatives/default/mall-landlords-get-mauled.png" width="1200"></p>

<p>More than half of mall department stores could close for good by the end of 2021, according to an April report from real estate research firm Green Street&nbsp;Advisors. J.C. Penney said last month that it would&nbsp;shutter&nbsp;more than 150 locations, while Neiman Marcus plans to pull out of New Yorkâ€™s Hudson Yards development and&nbsp;close&nbsp;three other U.S. locations.</p>

<p>The closures so far are â€œjust the tip of the iceberg,â€� said&nbsp;Garrick Brown, head of Americas retail research for Cushman &amp; Wakefield. Over the next two years, at least 1.2 billion of square feet -- 10% of already-occupied store real estate -- will go vacant, he said. â€œWorst-case scenario, that could double.â€�</p>
</div></div>]]>
            </description>
            <link>https://www.bnnbloomberg.ca/busted-retailers-use-bankruptcy-to-break-leases-by-the-thousands-1.1476347</link>
            <guid isPermaLink="false">hacker-news-small-sites-24074311</guid>
            <pubDate>Thu, 06 Aug 2020 19:04:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What’s New in Apache Kafka 2.6]]>
            </title>
            <description>
<![CDATA[
Score 42 | Comments 0 (<a href="https://news.ycombinator.com/item?id=24073023">thread link</a>) | @drojas
<br/>
August 6, 2020 | https://www.confluent.io/blog/apache-kafka-2-6-updates | <a href="https://web.archive.org/web/*/https://www.confluent.io/blog/apache-kafka-2-6-updates">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p>On behalf of the Apache Kafka<sup>®</sup> community, it is my pleasure to announce the release of <a href="https://kafka.apache.org/downloads" target="_blank" rel="noopener noreferrer">Apache Kafka 2.6.0</a>. This another exciting release with many new features and improvements. We’ll highlight some of the more prominent features in this blog post, but see the <a href="https://dist.apache.org/repos/dist/release/kafka/2.6.0/RELEASE_NOTES.html" target="_blank" rel="noopener noreferrer">release notes</a> for the full list of changes.</p>
<p>We’ve made quite a few significant performance improvements in this release, particularly when the broker has larger partition counts. Broker shutdown performance is <a href="https://issues.apache.org/jira/browse/KAFKA-9373" target="_blank" rel="noopener noreferrer">significantly improved</a>, and performance is dramatically improved when producers use compression. Various aspects of ACL usage are faster and require less memory. And we’ve reduced memory allocations in several other places within the broker.</p>
<p>This release also adds support for Java 14. And over the past few releases, the community has switched to using Scala 2.13 by default and now recommends using Scala 2.13 for production.</p>
<p>Finally, these accomplishments are only one part of a larger active roadmap in the run up to Apache Kafka 3.0, which may be one of the most significant releases in the project’s history. The work to <a href="https://cwiki.apache.org/confluence/display/KAFKA/KIP-500%3A+Replace+ZooKeeper+with+a+Self-Managed+Metadata+Quorum" target="_blank" rel="noopener noreferrer">replace ZooKeeper</a> with built-in Raft-based consensus is well underway with eight KIPs in active development. Kafka’s new Raft protocol for the metadata quorum is already <a href="https://github.com/apache/kafka/pull/9130" target="_blank" rel="noopener noreferrer">available for review</a>. Tiered Storage unlocks infinite scaling and faster rebalance times via <a href="https://cwiki.apache.org/confluence/display/KAFKA/KIP-405%3A+Kafka+Tiered+Storage" target="_blank" rel="noopener noreferrer">KIP-405</a> and is up and running in internal clusters at Uber.</p>
<h2 id="kafka-broker-producer-and-consumer"><a id="kafka-broker-producer-and-consumer"></a>Kafka broker, producer, and consumer</h2>
<h3 id="kip-546"><a id="kip-546"></a>KIP-546: Add Client Quota APIs to the Admin Client</h3>
<p>Managing quotas today in Kafka can be challenging because they can map to any combination of user and client. This feature adds a native API for managing quotas, making the process more intuitive and less error prone. A new <code>kafka-client-quotas.sh</code> command line tool lets users describe existing quotas, resolve the effective quotas for an entity with contextual information about how those quotas were derived, and modify a quota configuration entry by specifying which entries to add, update, and/or remove. For example:</p>
<pre>$ /bin/kafka-client-quotas.sh --bootstrap-server localhost:9092 \
						 --alter --names=client-id=my-client \
						 --defaults=user \
                              --add=consumer_byte_rate=2000000 \
                              --delete=producer_byte_rate</pre>
<p>See <a href="https://cwiki.apache.org/confluence/display/KAFKA/KIP-546%3A+Add+Client+Quota+APIs+to+the+Admin+Client" target="_blank" rel="noopener noreferrer">KIP-546</a> for more details.</p>
<h3 id="KIP-551"><a id="KIP-551"></a>KIP-551: Expose disk read and write metrics</h3>
<p>Disk access on the Kafka broker machines may impact latency and throughput. This change adds metrics that track how many bytes Kafka is reading and writing from the disk.</p>
<p>See <a href="https://cwiki.apache.org/confluence/display/KAFKA/KIP-551%3A+Expose+disk+read+and+write+metrics" target="_blank" rel="noopener noreferrer">KIP-551</a> for more details.</p>
<h3 id="KIP-568"><a id="KIP-568"></a>KIP-568: Explicit rebalance triggering on the Consumer</h3>
<p>The Kafka consumer coordinates which topic partitions are assigned to each client in the same consumer group. This feature allows applications using the consumer to explicitly trigger a rebalance, such as if an application uses some system condition to determine whether it is ready to receive partitions.</p>
<p>See <a href="https://cwiki.apache.org/confluence/display/KAFKA/KIP-568%3A+Explicit+rebalance+triggering+on+the+Consumer" target="_blank" rel="noopener noreferrer">KIP-568</a> for more details.</p>
<h3 id="KIP-573"><a id="KIP-573"></a>KIP-573: Enable TLSv1.3 by default</h3>
<p>TLS 1.3 is now the default TLS protocol when using Java 11 or higher, and TLS 1.2 remains the default for earlier Java versions. As with Apache Kafka 2.5.0, TLS 1.0 and 1.1 are disabled by default due to known security vulnerabilities, though users can still enable them if required.</p>
<p>See <a href="https://cwiki.apache.org/confluence/display/KAFKA/KIP-573%3A+Enable+TLSv1.3+by+default" target="_blank" rel="noopener noreferrer">KIP-573</a> for more details.</p>
<h3 id="KIP-574"><a id="KIP-574"></a>KIP-574: CLI Dynamic Configuration with file input</h3>
<p>Kafka configs for the most part are defined by a single value that maps to a config name. Before this change, it was hard to set configs that are better defined by more complex structures such as nested lists or JSON. Kafka now supports using the<code> kafka-configs.sh</code> command line tool to set configs defined in a file. For example:</p>
<pre>$ bin/kafka-configs.sh --bootstrap-server localhost:9092 \
                       --entity-type brokers --entity-default \
                       --alter --add-config-file new.properties</pre>
<p>See <a href="https://cwiki.apache.org/confluence/display/KAFKA/KIP-574%3A+CLI+Dynamic+Configuration+with+file+input" target="_blank" rel="noopener noreferrer">KIP-574</a> for more details.</p>
<h3 id="KIP-602"><a id="KIP-602"></a>KIP-602: Change default value for <code>client.dns.lookup</code></h3>
<p>Apache Kafka 2.1.0 and <a href="https://cwiki.apache.org/confluence/display/KAFKA/KIP-302+-+Enable+Kafka+clients+to+use+all+DNS+resolved+IP+addresses" target="_blank" rel="noopener noreferrer">KIP-302</a> introduced the <code>use_all_dns_ips</code> option for the <code>client.dns.lookup</code> client property. With this change, the <code>use_all_dns_ips</code> option is now the default so that it will attempt to connect to the broker using all of the possible IP addresses of a hostname. The new default will reduce connection failure rates and is more important in cloud and containerized environments where a single hostname may resolve to multiple IP addresses.</p>
<p>See <a href="https://cwiki.apache.org/confluence/display/KAFKA/KIP-602%3A+Change+default+value+for+client.dns.lookup" target="_blank" rel="noopener noreferrer">KIP-602</a> for more details.</p>
<h2 id="kafka-connect"><a id="kafka-connect"></a>Kafka Connect</h2>
<h3 id="kip-158"><a id="kip-158"></a>KIP-158: Kafka Connect should allow source connectors to set topic-specific settings for new topics</h3>
<p>This widely requested feature allows Kafka Connect to automatically create Kafka topics for source connectors that write records, if those topics do not yet exist. This is enabled by default but does require connector configurations to define the rules used by Connect when creating these topics. For example, simply including the following will cause Connect to create any missing topics with <code>5</code> partitions and a replication factor of <code>3</code>:</p>
<pre>topic.creation.default.replication.factor=3
topic.creation.default.partitions=5</pre>
<p>Additional rules with topic matching expressions and topic-specific settings can be defined, making this a powerful and useful feature, especially when Kafka brokers have disabled topic auto creation.</p>
<p>See <a href="https://cwiki.apache.org/confluence/display/KAFKA/KIP-158%3A+Kafka+Connect+should+allow+source+connectors+to+set+topic-specific+settings+for+new+topics" target="_blank" rel="noopener noreferrer">KIP-158</a> for more details.</p>
<h3 id="KIP-605"><a id="KIP-605"></a>KIP-605: Expand Connect Worker Internal Topic Settings</h3>
<p>Speaking of creating topics, the Connect worker configuration can now specify additional topic settings, including using the Kafka broker defaults for partition count and replication factor, for the internal topics used for connector configurations, offsets, and status.</p>
<p>See <a href="https://cwiki.apache.org/confluence/display/KAFKA/KIP-605%3A+Expand+Connect+Worker+Internal+Topic+Settings" target="_blank" rel="noopener noreferrer">KIP-605</a> for more details.</p>
<h3 id="KIP-610"><a id="KIP-610"></a>KIP-610: Error Reporting in Sink Connectors</h3>
<p>Kafka Connect already had the ability to write records to a dead letter queue (DLQ) topic if those records could not be serialized or deserialized, or when a Single Message Transform (SMT) failed. Now Connect gives sink connectors the ability to send individual records to the DLQ if the connector deems the records to be invalid or problematic. Sink connectors need to explicitly make use of this feature, but doing so will allow sink connectors to continue operating even if some records in the consumed topics are somehow incompatible with the sink connector.</p>
<p>See <a href="https://cwiki.apache.org/confluence/display/KAFKA/KIP-610%3A+Error+Reporting+in+Sink+Connectors" target="_blank" rel="noopener noreferrer">KIP-610</a> for more details.</p>
<h3 id="KIP-585"><a id="KIP-585"></a>KIP-585: Filter and Conditional SMTs</h3>
<p>Defining SMTs for connectors that use multiple topics can be challenging, since not every SMT may apply for every record on every topic. With this feature, each SMT can define a predicate with the conditions when that SMT should be applied. It also defines a “filter” SMT that works with the predicates to drop records that match certain conditions.</p>
<p>See <a href="https://cwiki.apache.org/confluence/display/KAFKA/KIP-585%3A+Filter+and+Conditional+SMTs" target="_blank" rel="noopener noreferrer">KIP-585</a> for more details.</p>
<h3 id="KIP-577"><a id="KIP-577"></a>KIP-577: Allow HTTP Response Headers to be Configured for Kafka Connect</h3>
<p>It is now possible to add custom headers to all Kafka Connect REST API responses. This allows users to ensure REST API responses comply with corporate security policies.</p>
<p>See<a href="https://cwiki.apache.org/confluence/display/KAFKA/KIP+577%3A+Allow+HTTP+Response+Headers+to+be+Configured+for+Kafka+Connect" target="_blank" rel="noopener noreferrer"> KIP-577</a> for more details.</p>
<h2 id="kafka-streams"><a id="kafka-streams"></a>Kafka Streams</h2>
<h3 id="KIP-441"><a id="KIP-441"></a>KIP-441: Smooth Scaling Out of Kafka Streams</h3>
<p>Prior to this change, when Kafka Streams assigns a stateful task, Streams had to catch it up to the head of its changelog before beginning to process it. This feature avoids stop-the-world rebalances by allowing the prior owner of a stateful task to keep it even if the assignment is unbalanced, until the new owner gets caught up, then changing ownership after the catch-up phase.</p>
<p>See <a href="https://cwiki.apache.org/confluence/display/KAFKA/KIP-441%3A+Smooth+Scaling+Out+for+Kafka+Streams" target="_blank" rel="noopener noreferrer">KIP-441</a> for more details.</p>
<h3 id="KIP-444"><a id="KIP-444"></a>KIP-444: Augment metrics for Kafka Streams</h3>
<p>This feature adds more out-of-the-box metrics and removes some that are not useful. It also improves the APIs that Streams applications use to register custom metrics.</p>
<p>See <a href="https://cwiki.apache.org/confluence/display/KAFKA/KIP-444%3A+Augment+metrics+for+Kafka+Streams" target="_blank" rel="noopener noreferrer">KIP-444</a> for more details.</p>
<h3 id="KIP-447"><a id="KIP-447"></a>KIP-447: Producer scalability for exactly once semantics</h3>
<p>This release adds additional work on this KIP to simplify the API for applications that read from and write to Kafka transactionally. Previously, this use case typically required separate producer instances for each input partition, but now there is no special requirement. This makes it much easier to build exactly-once semantics (EOS) applications that consume large numbers of partitions. This is foundational for a similar improvement in Kafka Streams in the next release.</p>
<p>See <a href="https://cwiki.apache.org/confluence/display/KAFKA/KIP-447%3A+Producer+scalability+for+exactly+once+semantics" target="_blank" rel="noopener noreferrer">KIP-447</a> for more details.</p>
<h3 id="KIP-557"><a id="KIP-557"></a>KIP-557: Add emit on change support for Kafka Streams</h3>
<p>This change adds an emit-on-change processing option to Kafka Streams and complements the existing emit-on-update and emit-on-window-close options. This new option drops idempotent updates where the prior and updated record have identical byte arrays. This feature helps eliminate high numbers of identical operations that forward an enormous number of unnecessary results down the topology.</p>
<p>See <a href="https://cwiki.apache.org/confluence/display/KAFKA/KIP-557%3A+Add+emit+on+change+support+for+Kafka+Streams" target="_blank" rel="noopener noreferrer">KIP-557</a> for more details.</p>
<h2 id="conclusion"><a id="conclusion"></a>Conclusion</h2>
<p>To learn more about what’s new in Apache Kafka 2.6 and to see all the KIPs included in this release, be sure to check out the <a href="https://dist.apache.org/repos/dist/release/kafka/2.6.0/RELEASE_NOTES.html" target="_blank" rel="noopener noreferrer">release notes</a> and highlights in the <a href="https://youtu.be/WOiL5kym_Us" target="_blank" rel="noopener noreferrer">video</a> below.</p>
<center><iframe src="https://www.youtube.com/embed/WOiL5kym_Us" width="560" height="315" frameborder="0" allowfullscreen="allowfullscreen"></iframe></center>&nbsp;
<p>This was a huge community effort, so thank you to everyone who contributed to this release, including all of our users and the 127 people (according to git shortlog) that contributed code or documentation changes in this release:</p>
<p>17hao, A. Sophie Blee-Goldman, Aakash Shah, Adam Bellemare, Agam Brahma, Alaa Zbair, Alexandra Rodoni, Andras Katona, Andrew Olson, Andy Coates, Aneel Nazareth, Anna Povzner, Antony Stubbs, Arjun Satish, Auston, avalsa, Badai Aqrandista, belugabehr, Bill Bejeck, Bob Barrett, Boyang Chen, Brian Bushree, Brian Byrne, Bruno Cadonna, Charles Feduke, Chia-Ping Tsai, Chris Egerton, Colin Patrick McCabe, Daniel, Daniel Beskin, David Arthur, David Jacot, David Mao, dengziming, Dezhi “Andy” Fang, Dima Reznik, Dominic Evans, Ego, Eric Bolinger, Evelyn Bayes, Ewen Cheslack-Postava, fantayeneh, feyman2016, Florian Hussonnois, Gardner Vickers, Greg Harris, Gunnar Morling, Guozhang Wang, high.lee, Hossein Torabi, huxi, Ismael Juma, Jason Gustafson, Jeff Huang, jeff kim, Jeff Widman, Jeremy Custenborder, Jiamei Xie, jiameixie, jiao, Jim Galasyn, …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.confluent.io/blog/apache-kafka-2-6-updates">https://www.confluent.io/blog/apache-kafka-2-6-updates</a></em></p>]]>
            </description>
            <link>https://www.confluent.io/blog/apache-kafka-2-6-updates</link>
            <guid isPermaLink="false">hacker-news-small-sites-24073023</guid>
            <pubDate>Thu, 06 Aug 2020 17:11:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A crash course on hacking satellites]]>
            </title>
            <description>
<![CDATA[
Score 346 | Comments 56 (<a href="https://news.ycombinator.com/item?id=24072829">thread link</a>) | @PatrolX
<br/>
August 6, 2020 | https://nyan-sat.com/chapter0.html | <a href="https://web.archive.org/web/*/https://nyan-sat.com/chapter0.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
        <div>
            
            <p>We'll be guiding you through a crash course on satellites - their history, where in (well, around) the world they are, and how they send and receive data. Accompanying this guide (though not strictly required for it) is a set of equipment we've used ourselves to get everything going.</p>

            <p>If you have the means, we recommend buying the equipment yourself. If you don't, we've put together a kit that we'll send to you for a very reasonable price, though supplies are limited. The list of parts is below, or you can <a href="https://shoppe.redballoonsecurity.com/products/nyansat-kit">click here</a> to request a kit. We also have stickers and T-shirts <a href="https://shoppe.redballoonsecurity.com/collections/nyansat">here</a>. If you don't want a kit right now, you can continue on to the <a href="https://nyan-sat.com/chapter1.html">next section</a>.</p>

            <p><a href="https://nyan-sat.com/assets/pcbh_board.jpg"><img src="https://nyan-sat.com/assets/pcbh_board.jpg"></a>
            <span>Antenny v1</span></p>

            <p>For the kit, we custom-built a PCB in our kit that integrates multiple parts, allowing you to connect everything together on a single board with no wiring. This board is the hardware component of the RBS Antenny project. It combines the EPS32 (with Bluetooth and Wifi support), a 16 channel PWM driver, and a motor driver with a maximum output of maximum 27W at 6V. The RBS Antenny board can easily handle the movement control of NyanSat antenna gimbal, and you can load your own custom code to adjust it however you like. The onboard reserved I2C channel connectors allow you to extend the basic NyanSat setup with an RBS custom made IMU module, OLED screen and GPS module.</p>

            <p>The RBS Antenny board is designed using Altium Designer and Assembled by an in-house pick and place machine in Manhattan, New York. After DEF CON, you can even repurpose the board for your future projects requiring microcontrollers and motor drivers. You can read more about it <a href="https://github.com/RedBalloonShenanigans/antenny/">here</a>.</p>

            

            <p>After completing the Antenny v1 board, we found ways to enhance the board and designed the Antenny v2 which fixes bugs, improves functionality and reliability, and is now adaptable for future development on hardware.</p>

            <p><a href="https://nyan-sat.com/assets/pcbh_board2.jpg"><img src="https://nyan-sat.com/assets/pcbh_board2.jpg"></a>
            <span>Antenny v2</span></p><p>The main improvements to highlight from the Antenny v1 to the Antenny v2 are as follows.</p>

            <ol>
                <li>Reduced PCB size by 40%</li>
                <li>Breakout unused GPIO pins from ESP32 for future development</li>
                <li>Fixed I2C GPIO pull up bugs</li>
                <li>Enhanced power output of servo motor driver by 25%</li>
                <li>Added BeiDou/GPS (beitian bn-880) module connector pinout on PCB board</li>
            </ol>

            <p>For more information on Antenny v2 and general setup, please review <a href="https://github.com/RedBalloonShenanigans/antenny/blob/master/hardware/Antenny_board_hardware_setup_guide.pdf">this document</a> for pinouts and hardware requirements.</p>
            
            
            <p>These are covered in more detail in Chapter 4. Feel free to skip ahead. Not every part here is strictly required - feel free to only get the ones that interest you.</p>

            <h2>Pan/Tilt Gimbal</h2>
            <p><img src="https://nyan-sat.com/assets/gimbal.jpg"></p><p>This is a small gimbal we're using for pointing an antenna in a specific direction and track a satellite across the sky. They can be found multiple places. We have spare ones that we're selling at cost. Without one of these you can listen to geosynchronous satellites, but low orbit satellites will be whizzing across your antenna’s pickup area in seconds.</p>
            <p><a href="https://www.amazon.com/dp/B085HDYTCQ/">Product link</a></p>

            <h2>RTL-SDR</h2>
            <p><img src="https://nyan-sat.com/assets/rtl-sdr.jpg"></p><p>The cheapest and most flexible SDR available.</p>
            <p><a href="https://www.amazon.com/dp/B011HVUEME/">Product link</a></p>

            <h2>ESP32</h2>
            <p><img src="https://nyan-sat.com/assets/esp32.jpg"></p><p>Lots of features in a tiny package. This is the microcontroller that our software expects.</p>
            <p><a href="https://www.amazon.com/dp/B0718T232Z">Product link</a></p>

            <h2>IMU</h2>
            <p>This Inertial Measuring Unit tells the software which way the antenna is pointing, helping you to point it very precisely.</p>
            <p><a href="https://www.amazon.com/dp/B017PEIGIG/">Product link</a></p>

            <h2>Motor Driver</h2>
            <p><img src="https://nyan-sat.com/assets/driver.jpg"></p><p>The ESP32 isn't able to drive the motors directly, so an adapter board is needed.</p>
            <p><a href="https://www.amazon.com/dp/B01D9VNXEQ/">Product link</a></p>

            <h2>OLED Screen (optional)</h2>
            <p><img src="https://nyan-sat.com/assets/oled.jpg"></p><p>Super simple display for getting quick feedback from the device.</p>
            <p><a href="https://www.amazon.com/dp/B07X25T786/">Product link</a></p>

            <p><a href="https://nyan-sat.com/chapter1.html"><span>NEXT CHAPTER</span></a>
        </p></div>
    </article></div>]]>
            </description>
            <link>https://nyan-sat.com/chapter0.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24072829</guid>
            <pubDate>Thu, 06 Aug 2020 16:55:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: CheerpX – x86 virtualization in browser using WebAssembly – Python Demo]]>
            </title>
            <description>
<![CDATA[
Score 24 | Comments 10 (<a href="https://news.ycombinator.com/item?id=24072213">thread link</a>) | @apignotti
<br/>
August 6, 2020 | https://www.leaningtech.com/pages/pythondemo.html | <a href="https://web.archive.org/web/*/https://www.leaningtech.com/pages/pythondemo.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="failure">

<p id="cxFailure">

<h6>CheerpX uses WebAssembly tail calls. Not all browsers support them out of the box (yet).</h6>
<br>
<h6>You can follow our tutorials below, to run your browser with tail cals, or watch a video of the demo if you prefer not to.</h6>
</p>
<div id="SVGmockupBg">

<div>
<h2>Want to interact with the demo yourself?</h2>

<ul id="pills-tab" role="tablist">
<li>
<a id="pills-one-example1-tab" data-toggle="pill" href="#pills-one-example1" role="tab" aria-controls="pills-one-example1" aria-selected="false">
<p><i></i>
Linux
</p>
</a>
</li>
<li>
<a id="pills-two-example1-tab" data-toggle="pill" href="#pills-two-example1" role="tab" aria-controls="pills-two-example1" aria-selected="false">
<p><i></i>
Mac OS
</p>
</a>
</li>
<li>
<a id="pills-three-example1-tab" data-toggle="pill" href="#pills-three-example1" role="tab" aria-controls="pills-three-example1" aria-selected="false">
<p><i></i>
Windows
</p>
</a>
</li>
</ul>


<div id="pills-tabContent">
<div id="pills-one-example1" role="tabpanel" aria-labelledby="pills-two-example1-tab">

<div>
<div>
<ul>

<li>
<span>
</span>
<p>
<h5>Open a Terminal/Command Prompt
</h5>
</p>
</li>


<li>
<span>
</span>
<p>
<h5>Enter the following command:</h5>
<h6>chromium --incognito --js-flags="--experimental-wasm-return-call"
</h6>
</p>
</li>


<li>
<span>
</span>
<p>
<h5>Navigate back to this page. That's it!</h5>
</p>
</li>

</ul>
</div>
</div>

</div>
<div id="pills-two-example1" role="tabpanel" aria-labelledby="pills-three-example1-tab">

<div>
<div>
<ul>

<li>
<span>
</span>
<p>
<h5>Open a Terminal/Command Prompt</h5>
</p>
</li>


<li>
<span>
</span>
<div>
<h5>
Enter the following command:
</h5>
<pre>/Applications/Google\ Chrome.app/Contents/MacOS/Google\ Chrome --js-flags=“--experimental-wasm-return-call”</pre>
</div>
</li>


<li>
<span>
</span>
<p>
<h5>Navigate back to this page. That's it!</h5>
</p>
</li>

</ul>
</div>
</div>

</div>
<div id="pills-three-example1" role="tabpanel" aria-labelledby="pills-one-example1-tab">

<div>
<div>
<ul>

<li>
<span>
</span>

</li>


<li>
<span>
</span>
<p>
<h5> Go to the start menu,
and open 'Windows
PowerShell'
</h5>
</p>
</li>


<li>
<span>
</span>
<p>
<h5>Enter the following
command:
</h5><h6>Start-Process -FilePath
"$env:LOCALAPPDATA\Chromium\Application\chrome.exe"
-js-flags="--experimental-wasm-return-call"
</h6>

</p>
</li>


<li>
<span>
</span>
<p>
<h5>Navigate back to this page. That's it!</h5>
 </p>
</li>

</ul>
</div>
</div>

</div>

</div>
</div>

</div>
<h2>Want to see the demo in action?</h2>
<div id="pills-tabContent-1">
<div id="pills-result-1" role="tabpanel" aria-labelledby="pills-result-tab-1">
<div>

<div>

<div>
<p id="vimeoVideoIframeExample1" data-vimeo-initialized="true"><iframe src="https://player.vimeo.com/video/445194549" frameborder="0" allow="fullscreen;" allowfullscreen="" title="DESIGN DISRUPTORS Trailer #2 - A documentary from InVision" data-ready="true"></iframe></p>
</div>

</div>

</div>
</div>
</div>
</div></div>]]>
            </description>
            <link>https://www.leaningtech.com/pages/pythondemo.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24072213</guid>
            <pubDate>Thu, 06 Aug 2020 16:03:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Auth is now available in Supabase (YC S20)]]>
            </title>
            <description>
<![CDATA[
Score 166 | Comments 47 (<a href="https://news.ycombinator.com/item?id=24072051">thread link</a>) | @kiwicopple
<br/>
August 6, 2020 | https://supabase.io/blog/2020/08/05/supabase-auth | <a href="https://web.archive.org/web/*/https://supabase.io/blog/2020/08/05/supabase-auth">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><p>Supabase is an open source Firebase alternative. We are building the features of Firebase using scalable, open source products. </p><p>Two months ago a developer discovered Supabase and (unexpectedly) <a href="https://news.ycombinator.com/item?id=23319901" target="_blank" rel="noopener noreferrer">launched us on Hacker News</a>. Although we had completed only 3 months of development the community support was both incredible and humbling.</p><p><img src="https://supabase.io/img/supabase-hn-launch.png" alt="This image shows all of the top dev tool launches on Hacker news. The most popular is Stripe, with 1249 upvotes, the next popular is Supabase with 1120 upvotes, and third is Fly.io with 626 upvotes."></p><p>Developers were obviously excited about the prospect of an open source Firebase alternative, but the comments were dominated by one emphatic feature request: Auth.</p><blockquote><p>" <em>Just FYI, making a good auth solution in Supabase will instantly make me a customer.</em> "<br><small>@pdimitar</small></p></blockquote><blockquote><p>" <em>For me the MVP, before I could use it for my commercial projects, would be: DB+auth. At that point, I could switch - and probably would.</em> "<br><small>@julianeon</small></p></blockquote><blockquote><p>" <em>This looks great, however at first peek it doesn't mention anything about auth. Do you have any plans for that? For me this is the topic I most want to just delegate to the service.</em> "<br><small>@2mol</small></p></blockquote><p>So we got to work, and today we're ecstatic to launch Supabase Auth. Let's dig into some of the features of the Auth system.</p><p>Supabase Auth provides all the backend services you need to authenticate and authorize your users.</p><h3>User management</h3><p>Supabase makes it simple to onboard your users with our new <code>supabase.auth.signup()</code> and <code>supabase.auth.login()</code> <a href="https://supabase.io/docs/library/user-management">functions</a>.</p><video width="99%" autoplay="autoplay" loop="" muted="" controls=""><source src="https://supabase.io/videos/auth-zoom.mp4" type="video/mp4"></video><h3>Row Level Security</h3><p>Authentication only gets you so far. When you need granular authorization rules, nothing beats PostgreSQL's <a href="https://www.postgresql.org/docs/current/ddl-rowsecurity.html" target="_blank" rel="noopener noreferrer">Row Level Security</a>. Supabase makes it simple to turn RLS on and off.</p><video width="99%" autoplay="autoplay" loop="" muted="" controls=""><source src="https://supabase.io/videos/rls-zoom.mp4" type="video/mp4"></video><h3>Policies</h3><p><a href="https://www.postgresql.org/docs/current/sql-createpolicy.html" target="_blank" rel="noopener noreferrer">Policies</a> are PostgreSQL's rule engine. They are incredibly powerful and flexible, allowing you to write complex SQL rules which fit your unique business needs. </p><video width="99%" autoplay="autoplay" loop="" muted="" controls=""><source src="https://supabase.io/videos/policies-zoom.mp4" type="video/mp4"></video><p>With policies, your database becomes the rules engine. Instead of repetitively filtering your queries, like this ...</p><div><div><div tabindex="0"><div><p><span>const</span><span> loggedInUserId </span><span>=</span><span> </span><span>'d0714948'</span><span></span></p><p><span></span><span>let</span><span> user </span><span>=</span><span> </span><span>await</span><span> supabase</span></p><p><span>    </span><span>.</span><span>from</span><span>(</span><span>'users'</span><span>)</span><span></span></p><p><span>    </span><span>.</span><span>select</span><span>(</span><span>'user_id, name'</span><span>)</span><span></span></p><p><span>    </span><span>.</span><span>eq</span><span>(</span><span>'user_id'</span><span>,</span><span> loggedInUserId</span><span>)</span><span></span></p></div></div></div></div><p>... you can simply define a rule on your database table, <code>auth.uid() = user_id</code>, and your request will return the rows which pass the rule, even when you remove the filter from your middleware:</p><div><div><div tabindex="0"><div><p><span>let</span><span> user </span><span>=</span><span> </span><span>await</span><span> supabase</span></p><p><span>    </span><span>.</span><span>from</span><span>(</span><span>'users'</span><span>)</span><span></span></p><p><span>    </span><span>.</span><span>select</span><span>(</span><span>'user_id, name'</span><span>)</span><span></span></p></div></div></div></div><h3>Open source</h3><p>Building an open source Firebase alternative is difficult task, made possible by an amazing suite of OSS tools that have forged the way for Supabase. We spent many weeks building Auth POC's with existing OSS tools. Notable mentions go to RedHat's <a href="https://www.keycloak.org/" target="_blank" rel="noopener noreferrer">KeyCloak</a>, and Ory's <a href="https://github.com/ory/kratos" target="_blank" rel="noopener noreferrer">Kratos</a>. </p><p>Ultimately we landed on a system which utilises three amazing open source products: </p><ul><li>Authorization: <a href="https://www.postgresql.org/" target="_blank" rel="noopener noreferrer">PostgreSQL</a> and <a href="http://postgrest.org/en/v7.0.0/auth.html" target="_blank" rel="noopener noreferrer">PostgREST</a>.</li><li>Authentication: Netlify's <a href="https://github.com/netlify/gotrue" target="_blank" rel="noopener noreferrer">GoTrue</a> server, which we forked and will continue to contribute to.</li></ul><h3>Next steps</h3><p>Supabase has a culture of shipping early and often. Our Auth release is another example of this, and we still have a lot of work to do. Next month we have more Auth features planned, including custom email templates and 3rd-party OAuth providers. We also plan to simplify the Policy interface, enabling non-technical users to get started with one of PostgreSQL's best features.</p><h3>Get started</h3><p>Supabase Auth is ready for you to start using today, free of charge: <a href="https://app.supabase.io/" target="_blank" rel="noopener noreferrer">app.supabase.io</a></p><p>To see the full power of our auth system, watch <a href="https://youtu.be/2oqIZW5S-lQ" target="_blank" rel="noopener noreferrer">this demo</a> where I deploy a secure, real-time slack clone to Vercel in less than 3 minutes.</p></section></div>]]>
            </description>
            <link>https://supabase.io/blog/2020/08/05/supabase-auth</link>
            <guid isPermaLink="false">hacker-news-small-sites-24072051</guid>
            <pubDate>Thu, 06 Aug 2020 15:50:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Simon's Algorithm]]>
            </title>
            <description>
<![CDATA[
Score 26 | Comments 3 (<a href="https://news.ycombinator.com/item?id=24072037">thread link</a>) | @keyboardman
<br/>
August 6, 2020 | https://leimao.github.io/blog/Simon-Algorithm/ | <a href="https://web.archive.org/web/*/https://leimao.github.io/blog/Simon-Algorithm/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <h3 id="introduction">Introduction</h3>

<p>Simon’s algorithm is a quantum computing algorithm invented to solve a contrived problem which is called Simon’s problem. Compared to one of the other quantum computing algorithms, <a href="https://leimao.github.io/blog/Deutsch-Jozsa-Algorithm/">Deutsch-Jozsa algorithm</a>, which only requires to run once, Simon’s algorithm requires to run the algorithm multiple times, yet it is still able to solve Simon’s problem exponentially faster asymptotically running on quantum circuits than the best conventional probabilistic algorithm running on classical circuits.</p>



<p>In this blog post, I would like to discuss Simon’s problem and Simon’s algorithm in details.</p>

<h3 id="prerequisites">Prerequisites</h3>

<h4 id="xor-properties">XOR Properties</h4>

<ul>
  <li><em>Commutativity</em>: $A \oplus B = B \oplus A$</li>
  <li><em>Associativity</em>: $A \oplus (B \oplus C) = (A \oplus B) \oplus C$</li>
  <li><em>Identity element</em>: $A \oplus 0 = A$</li>
  <li><em>Self-invertible</em>:  $A \oplus A = 0$</li>
</ul>

<h4 id="reducing-sum-or-difference-to-boolean">Reducing Sum or Difference to Boolean</h4>

<p>If $x$ and $y$ are binary values, $x, y \in \{0, 1\}$, we have</p><p>

\[\begin{align}
(-1)^{x + y} &amp;= (-1)^{x \oplus y} \\
(-1)^{x - y} &amp;= (-1)^{x \oplus y} \\
\end{align}\]

</p><p>where $\oplus$ is $\text{XOR}$ (binary addition modulo 2). This could be easily verified using truth table.</p>

<h4 id="inner-product-and-inner-product-space-for-binary-vector-space">Inner Product and Inner Product Space for Binary Vector Space</h4>

<p>In the previous <a href="https://leimao.github.io/blog/Inner-Product/">blog post</a>, we have defined the inner product and inner product space for complex vector space. Similarly, we could also define the inner product and inner product space for binary vector space.</p><p>

\[\begin{align}
\langle -, - \rangle : \{0,1\}^n \times \{0,1\}^n \rightarrow \{0,1\}
\end{align}\]

</p><p>Given two binary vectors $\mathbf{x}, \mathbf{y} \in \{0,1\}^n$, $\mathbf{x} = \{x_0, x_1, \cdots, x_{n-1}\}$ and $\mathbf{y} = \{y_0, y_1, \cdots, y_{n-1}\}$, the inner product of $\mathbf{x}$ and $\mathbf{y}$ is defined as</p><p>

\[\begin{align}
\langle \mathbf{x}, \mathbf{y} \rangle &amp;= (x_0 \wedge y_0) \oplus (x_1 \wedge y_1) \oplus \cdots \oplus (x_{n-1} \wedge y_{n-1}) \\
&amp;= \bigoplus_{i=0}^{n-1} (x_i \wedge y_i )
\end{align}\]

</p><p>which is somewhat similar to the inner product definition for real vector space.</p>



<p>The bitwise exclusive-or operation $\oplus$ was also defined for binary vectors $\mathbf{x}$ and $\mathbf{y}$ of the same length. Given two binary vectors $\mathbf{x}, \mathbf{y} \in \{0,1\}^n$, $\mathbf{x} = \{x_0, x_1, \cdots, x_{n-1}\}$ and $\mathbf{y} = \{y_0, y_1, \cdots, y_{n-1}\}$,</p><p>

\[\begin{align}
\mathbf{x} \oplus \mathbf{y} = \{x_0 \oplus y_0, x_1 \oplus y_1, \cdots, x_{n-1} \oplus y_{n-1}\}
\end{align}\]

</p><p>The following inner product properties are satisfied based on the above inner product definition.</p>



<p>Given $\mathbf{x}, \mathbf{x}^{\prime}, \mathbf{y}, \mathbf{y}^{\prime} \in \{0,1\}^n$, using the $\text{XOR}$ distributivity property we derived above,</p><p>

\[\begin{align}
\langle \mathbf{x} \oplus \mathbf{x}^{\prime}, \mathbf{y} \rangle &amp;= \big((x_0 \oplus x_0^{\prime})\wedge y_0\big) \oplus \big((x_1 \oplus x_1^{\prime}) \wedge y_1\big) \oplus \cdots \oplus \big((x_{n-1} \oplus x_{n-1}^{\prime}) \wedge y_{n-1}\big) \\
&amp;= \big((x_0 \wedge y_0) \oplus (x_0^{\prime} \wedge y_0) \big) \oplus \big((x_1 \wedge y_1) \oplus (x_1^{\prime} \wedge y_1) \big) \oplus \cdots \oplus \big((x_{n-1} \wedge y_{n-1}) \oplus (x_{n-1}^{\prime} \wedge y_{n-1}) \big) \\
&amp;= (x_0 \wedge y_0) \oplus (x_0^{\prime} \wedge y_0)  \oplus (x_1 \wedge y_1) \oplus (x_1^{\prime} \wedge y_1)  \oplus \cdots \oplus (x_{n-1} \wedge y_{n-1}) \oplus (x_{n-1}^{\prime} \wedge y_{n-1}) \\
&amp;= \big( (x_0 \wedge y_0) \oplus (x_1 \wedge y_1)  \oplus \cdots \oplus (x_{n-1} \wedge y_{n-1}) \big) \oplus  \big( (x_0^{\prime} \wedge y_0) \oplus (x_1^{\prime} \wedge y_1)  \oplus \cdots \oplus (x_{n-1}^{\prime} \wedge y_{n-1}) \big) \\
&amp;= \langle \mathbf{x}, \mathbf{y} \rangle \oplus \langle \mathbf{x}^{\prime}, \mathbf{y} \rangle   \\
\end{align}\]

</p><p>Similarly,</p><p>

\[\begin{align}
\langle \mathbf{x}, \mathbf{y} \oplus \mathbf{y}^{\prime} \rangle = \langle \mathbf{x}, \mathbf{y} \rangle \oplus \langle \mathbf{x}, \mathbf{y}^{\prime} \rangle \\
\end{align}\]

</p><p>Let $\mathbf{0} = \{ \underbrace{0, 0, \cdots, 0}_{n} \} =  0^n$, we have</p><p>

\[\begin{align}
\langle \mathbf{0}, \mathbf{y} \rangle = 0 \\
\langle \mathbf{x}, \mathbf{0} \rangle = 0 \\
\end{align}\]

</p><h4 id="hadamard-operator">Hadamard Operator</h4>

<p>Most of the important properties of Hadamard operator have been derived in the prerequisites section of my previous blog post on <a href="https://leimao.github.io/blog/Deutsch-Jozsa-Algorithm/">Deutsch-Jozsa algorithm</a>. Unlike Deutsch-Jozsa algorithm, Simon’s algorithm is only going to use a small fraction of the Hadamard operator properties that Deutsch-Jozsa algorithm has used. I would just copy the properties useful for Simon’s algorithm algorithm. For the derivation, proof, and other properties of Hadamard operator, the reader should refer to my previous blog post.</p>



<p>To extract an arbitrary column $j$ from $H^{\otimes {n}}$, we prepared a one-hot quantum system basic state vector $| \mathbf{y} \rangle = [y_0, y_1, \cdots, y_{2^n-1}]^{\top}$, where $y_j = 1$ and $y_k = 0$ for $k \neq j$.</p><p>

\[\begin{align}
H^{\otimes {n}}_{:,j} &amp;= H^{\otimes {n}} | \mathbf{y} \rangle \\
&amp;= H^{\otimes n}[\mathbf{0}, \mathbf{j}] | \mathbf{x}_0 \rangle + H^{\otimes n}[\mathbf{1}, \mathbf{j}] | \mathbf{x}_1 \rangle + \cdots + H^{\otimes n}[\mathbf{2^n-1}, \mathbf{j}] | \mathbf{x}_{2^{n}-1} \rangle \\
&amp;= \frac{1}{\sqrt{2^n}} (-1)^{\langle \mathbf{0}, \mathbf{j} \rangle} | \mathbf{x}_0 \rangle + \frac{1}{\sqrt{2^n}} (-1)^{\langle \mathbf{1}, \mathbf{j} \rangle} | \mathbf{x}_1 \rangle + \cdots + \frac{1}{\sqrt{2^n}} (-1)^{\langle \mathbf{2^n-1}, \mathbf{j} \rangle} | \mathbf{x}_{2^{n}-1} \rangle \\
&amp;= \frac{1}{\sqrt{2^n}} \sum_{i=0}^{2^n-1} (-1)^{\langle \mathbf{i}, \mathbf{j} \rangle} | \mathbf{x}_i \rangle\\
&amp;= \frac{1}{\sqrt{2^n}} \sum_{ \mathbf{x} \in \{0,1\}^n } (-1)^{\langle \mathbf{x}, \mathbf{j} \rangle} | \mathbf{x} \rangle\\
&amp;= \frac{1}{\sqrt{2^n}} \sum_{ \mathbf{x} \in \{0,1\}^n } (-1)^{\langle \mathbf{x}, \mathbf{y} \rangle} | \mathbf{x} \rangle\\
\end{align}\]

</p><p>where $| \mathbf{x}_i \rangle$ is a quantum system one-hot basic state vector,  $|\mathbf{x}_i\rangle = [x_0, x_1, \cdots, x_{2^{n}-1}]^{\top}$, where $x_i = 1$ and $x_k = 0$ for $k \neq i$.</p>



<p>Specifically, if $j = 0$, $| \mathbf{y} \rangle = [\underbrace{1, 0, 0, \cdots, 0}_{2^n} ]^{\top} = | \mathbf{0} \rangle$,</p><p>

\[\begin{align}
H^{\otimes {n}} | \mathbf{0} \rangle 
&amp;= \frac{1}{\sqrt{2^n}} \sum_{i=0}^{2^n-1} (-1)^{\langle \mathbf{i}, \mathbf{0} \rangle} | \mathbf{x}_i \rangle \\
&amp;= \frac{1}{\sqrt{2^n}} \sum_{i=0}^{2^n-1} (-1)^{0} | \mathbf{x}_i \rangle \\
&amp;= \frac{1}{\sqrt{2^n}} \sum_{i=0}^{2^n-1} | \mathbf{x}_i \rangle \\
&amp;= \frac{1}{\sqrt{2^n}} \sum_{ \mathbf{x} \in \{0,1\}^n } | \mathbf{x} \rangle \\
\end{align}\]

</p><h3 id="simons-problem">Simon’s Problem</h3>

<p>Simon’s problem is defined as the follows. Given a black box function $f: \{0,1\}^n \rightarrow \{0,1\}^n$, we are further assured that there exists a hidden binary string $\mathbf{c} \in \{0,1\}^n$, such that, for all $\mathbf{x}, \mathbf{y} \in \{0,1\}^n$,</p><p>

\[f(\mathbf{x}) = f(\mathbf{y}) \Leftrightarrow \mathbf{y} = \mathbf{x} \oplus \mathbf{c}\]

</p><p>where $\oplus$ is (bit-wise) $\text{XOR}$ (binary addition modulo 2).</p>



<p>Our goal is to find out what $\mathbf{c}$ is.</p>

<h4 id="mapping-properties">Mapping Properties</h4>

<p>There are some properties of the mapping $f$. $f$ is either a one-to-one or two-to-one mapping.</p>



<p>$\mathbf{c} = \mathbf{0}$ $\Leftrightarrow$ $f$ is a one-to-one mapping</p>



<p><em>Proof</em></p>



<p>For $f$ is a one-to-one mapping $\Rightarrow$ $\mathbf{c} = \mathbf{0}$, it is too trivial to prove.</p>



<p>For $\mathbf{c} = \mathbf{0}$ $\Rightarrow$ $f$ is a one-to-one mapping, we would like to prove by contradiction.</p>



<p>If $\mathbf{c} = \mathbf{0}$ and $f$ is not a one-to-one mapping, there must exists $\mathbf{x}$ and $\mathbf{y}$, $\mathbf{x} \neq \mathbf{y}$, and $f(\mathbf{x}) = f(\mathbf{y})$. According to the assurance, $\mathbf{y} = \mathbf{x} \oplus \mathbf{c} = \mathbf{x} \oplus \mathbf{0} = \mathbf{x}$. This raises contradiction and therefore $f$ has to be a one-to-one mapping when $\mathbf{c} = \mathbf{0}$.</p>



<p>This concludes the proof.</p>



<p>$\mathbf{c} \neq \mathbf{0}$ $\Leftrightarrow$ $f$ is a two-to-one mapping.</p>



<p><em>Proof</em></p>



<p>For $f$ is a two-to-one mapping $\Rightarrow$ $\mathbf{c} \neq \mathbf{0}$, it is too trivial to prove.</p>



<p>For $\mathbf{c} \neq \mathbf{0}$ $\Rightarrow$ $f$ is a two-to-one mapping, we would like to prove by contradiction.</p>



<p>If $\mathbf{c} \neq \mathbf{0}$, for any $\mathbf{x}$, we must have $\mathbf{y}$, where $\mathbf{y} = \mathbf{x} \oplus \mathbf{c}$ and $\mathbf{x} \neq \mathbf{y}$, $f(\mathbf{x}) = f(\mathbf{y})$. So $f$ is at least a two-to-one mapping. Assuming there exists a tuple of $\mathbf{x}$, $\mathbf{y}$, and $\mathbf{z}$, where $\mathbf{y} = \mathbf{x} \oplus \mathbf{c}$, $\mathbf{z} \neq \mathbf{x}$, and $\mathbf{z} \neq \mathbf{y}$, and $f(\mathbf{x}) = f(\mathbf{y}) = f(\mathbf{z})$. According to the assurance, $\mathbf{z} = \mathbf{x} \oplus \mathbf{c}$. But $\mathbf{x} \oplus \mathbf{c} = \mathbf{y}$ so we have $\mathbf{z} = \mathbf{y}$. This raises contradiction and therefore $f$ has to be a two-to-one mapping when $\mathbf{c} \neq \mathbf{0}$.</p>



<p>This concludes the proof.</p>

<h4 id="trivial-solution">Trivial Solution</h4>

<p>Solving Simon’s problem could be trivial.</p>



<p>If we happen to know any $\mathbf{x}$ and $\mathbf{y}$, where $\mathbf{x} \neq \mathbf{y}$ and $f(\mathbf{x}) = f(\mathbf{y})$, we immediately know $\mathbf{c} \neq \mathbf{0}$ and $\mathbf{c} = \mathbf{x} \oplus \mathbf{y}$. This is because,</p><p>

\[\begin{align}
\mathbf{x} \oplus \mathbf{y} &amp;= \mathbf{x} \oplus ( \mathbf{x} \oplus \mathbf{c} ) \\
&amp;= ( \mathbf{x} \oplus \mathbf{x} ) \oplus \mathbf{c} \\
&amp;= \mathbf{0} \oplus \mathbf{c} \\
&amp;= \mathbf{c} \\
\end{align}\]

</p><p>If we have checked all $\mathbf{x}, \mathbf{y} \in \{0,1\}^n$ and found there are no $\mathbf{x}$ and $\mathbf{y}$, where $\mathbf{x} \neq \mathbf{y}$ and $f(\mathbf{x}) = f(\mathbf{y})$, we immediately know $\mathbf{c} = \mathbf{0}$.</p>



<p>So the trivial solution for solving Simon’s problem is to evaluate $f$ using the values in $\{0,1\}^n$ one by one, and check if the newly …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://leimao.github.io/blog/Simon-Algorithm/">https://leimao.github.io/blog/Simon-Algorithm/</a></em></p>]]>
            </description>
            <link>https://leimao.github.io/blog/Simon-Algorithm/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24072037</guid>
            <pubDate>Thu, 06 Aug 2020 15:49:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to use the next-gen open-sourced .Avif image format, 50% smaller than JPEG]]>
            </title>
            <description>
<![CDATA[
Score 63 | Comments 28 (<a href="https://news.ycombinator.com/item?id=24071431">thread link</a>) | @tomhanlon
<br/>
August 6, 2020 | https://reachlightspeed.com/blog/using-the-new-high-performance-avif-image-format-on-the-web-today/ | <a href="https://web.archive.org/web/*/https://reachlightspeed.com/blog/using-the-new-high-performance-avif-image-format-on-the-web-today/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><h2>A More Optimal Image Format</h2><p><a href="http://aomedia.org/" title="AV1 (.avif) File Format"><svg width="220" viewBox="0 0 240 330" fill="none" xmlns="http://www.w3.org/2000/svg"><title>AV1 (.avif) File Format</title><path d="M9 10v310h221V69l-58-59H9zm163 0v59h58" fill="#fff"></path><path d="M172 10l58 59h-58V10z" fill="#fff"></path><path d="M230 69v251H9V10h163m58 59l-58-59m58 59h-58V10" stroke="#3B5EE2" stroke-width="8" stroke-linecap="round" stroke-linejoin="round"></path><path d="M211 190l-42-74-43 74h85z" fill="#FBAC30"></path><path d="M211 190l-16-19h-53l-16 19h85z" fill="#12B17D"></path><path d="M169 218l26-47h-53l27 47z" fill="#BB255C"></path><path d="M67 183H47l-2 7H28l19-53h20l20 53H69l-2-7zm-16-13h12l-6-19-6 19zm25-33h18l12 36 11-36h18l-19 53H96l-20-53" fill="#000"></path><path d="M165 150l-5 6-6-6 13-13h9v32h-11v-19" fill="#F1F4D4"></path><path d="M172 10l58 59h-58V10z" fill="#3B5EE2" stroke="#3B5EE2" stroke-width="8" stroke-linecap="round" stroke-linejoin="round"></path></svg></a></p><p>One of the upcoming technologies we're really excited about is the <a href="https://aomediacodec.github.io/av1-avif/">AV1 (.avif)</a> image file format. It's basically a super-compressed image type. <a href="https://netflixtechblog.com/avif-for-next-generation-image-coding-b1d75675fe4" title="AVIF for Next-Generation Image Coding">Netflix</a> has already considered .avif superior to the JPEG, PNG, and even the newer WebP image formats for its image quality to compressed file size ratio.</p><p>The format was developed by the <a href="http://aomedia.org/">Alliance for Open Media</a> in collaboration with Google, Cisco, and Xiph.org (who worked with Mozilla, creators of the Firefox browser). This format was created to be an open-sourced and royalty-free image format (unlike JPEG XR, which is a file format that compresses down very small but requires expensive licensing to implement).</p><h2>AVIF Compared to JPEG and WebP</h2><p>AVIF offers significant file size reduction for images compared with JPEG or WebP; <strong>~50% savings compared to JPEG</strong>, and <strong>~20% savings compared to WebP</strong>. Daniel Aleksandersen of <a href="https://www.ctrl.blog/">CTRL.Blog</a> has a great breakdown and deep dive into <a href="https://www.ctrl.blog/entry/webp-avif-comparison.html">AVIF comparison to JPEG and WebP</a>.</p><p><svg width="768" viewBox="0 0 768 216" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M0 16h380a4 4 0 014 4v44a4 4 0 01-4 4H0V16zM0 82h533.6a4 4 0 014 4v44a4 4 0 01-4 4H0V82zM0 148h764a4 4 0 014 4v44a4 4 0 01-4 4H0v-52z" fill="#3B5EE2"></path><text fill="#fff" style="white-space:pre" font-size="28" letter-spacing="0em"><tspan x="317.08" y="50.95">.avif</tspan></text><text fill="#fff" style="white-space:pre" font-size="20" font-weight="300" letter-spacing="0em"><tspan x="12" y="49.11">50% smaller than .jpeg</tspan></text><text fill="#fff" style="white-space:pre" font-size="20" font-weight="300" letter-spacing="0em"><tspan x="12" y="116.11">30% smaller than .jpeg</tspan></text><text fill="#fff" style="white-space:pre" font-size="28" letter-spacing="0em"><tspan x="449.21" y="116.95">.webp</tspan></text><text fill="#fff" style="white-space:pre" font-size="28" letter-spacing="0em"><tspan x="692.03" y="182.95">.jpeg</tspan></text></svg></p><p>The format is very flexible in that it supports any image codec, can be lossy or lossless, has the ability to use an alpha channel (transparency for UI and design elements), and even has the ability to store a series of animated frames (think lightweight high-quality animated GIFs).</p><p>It is also one of the first image formats to support HDR color support; offering higher brightness, color bit depth, and color gamuts.</p><h2>Using AVIF in Web Development Today</h2><p>AVIF is supposed to land in <a href="https://www.chromestatus.com/feature/4905307790639104">Chrome 85</a> and <a href="https://www.mozilla.org/en-US/firefox/80.0beta/releasenotes/">Firefox 80</a> on August 25, 2020; so we should start developing for it today!</p><p><picture><source srcset="https://reachlightspeed.com/img/blog/post-using-avif-images-today-support.avif" type="image/avif"><source srcset="https://reachlightspeed.com/img/blog/post-using-avif-images-today-no_support.jpg" type="image/jpeg"><img src="https://reachlightspeed.com/img/blog/post-using-avif-images-today-no_support.jpg" width="768" loading="lazy" alt="Does your browser support AVIF?"></picture></p><p>The AVIF image above likely doesn't show in your browser, but it can by using <a href="https://www.google.com/chrome/canary/">Chrome Canary</a> or by enabling AVIF in the Firefox advanced configuration preferences. You can do this by entering <code>about:config</code> in the URL bar, searching <code>image.avif.enabled</code>, and flipping this parameter to <code>true</code>.</p><p><picture><source srcset="https://reachlightspeed.com/img/blog/post-using-avif-images-today-firefox-avif.webp" type="image/webp"><img src="https://reachlightspeed.com/img/blog/post-using-avif-images-today-firefox-avif.png" width="768" loading="lazy" alt="Enable AVIF within Firefox Advanced Configuration Preferences"></picture></p><h2>Create AVIF Files with Squoosh (AVIF Beta)</h2><p><a href="https://squoosh.app/">Squoosh</a> is an image compression web app that allows you to dive into the advanced options provided by various image compressors.</p><p>While Google Chrome Labs plans to add AVIF to the amazing Squoosh web app, <a href="https://squoosh-avif.netlify.app/">here is an early build with AVIF support</a> that is built from a more recent <a href="https://github.com/GoogleChromeLabs/squoosh/pull/722">Pull Request</a>. It might be a little buggy as expected, but definitely functions well. In my opinion, this is the best option right now for converting and creating .avif files.</p><p><a href="https://squoosh-avif.netlify.app/"><picture><source srcset="https://reachlightspeed.com/img/blog/post-using-avif-images-today-squoosh-avif.avif" type="image/avif"><source srcset="https://reachlightspeed.com/img/blog/post-using-avif-images-today-squoosh-avif.webp" type="image/webp"><img src="https://reachlightspeed.com/img/blog/post-using-avif-images-today-squoosh-avif.jpg" width="768" loading="lazy" alt="Use Squoosh to convert and encode AVIF files."></picture></a></p><p><a href="https://squoosh-avif.netlify.app/">Squoosh (AVIF Beta)</a></p><p>If you are comfortable in the command line, you can use the offical AOMedia library, <a href="https://github.com/AOMediaCodec/libavif">libavif</a>, to encode/decode AVIF files. Also, if you're a macOS user with <a href="https://brew.sh/">Homebrew</a>, you can quickly install a pre-built version using <code>brew install joedrago/repo/avifenc</code>, and <code>avifenc --help</code> for syntax and options.</p><h2>AVIF as Progressive Enhancement</h2><p>Even though AVIF isn't support everywhere yet, we can still use the format in native HTML with the <code>&lt;picture&gt;</code> element. The <code>&lt;picture&gt;</code> element allows for progressive support as we can list the image sources in the order in which we want loaded, and the browser will load the first that it supports. If browser doesn't support <code>&lt;picture&gt;</code> at all, it will fallback to using the default <code>&lt;img&gt;</code>.</p><pre><code><span><span><span>&lt;</span>picture</span><span>&gt;</span></span><br>	<span><span><span>&lt;</span>source</span> <span>srcset</span><span><span>=</span><span>"</span>img/photo.avif<span>"</span></span> <span>type</span><span><span>=</span><span>"</span>image/avif<span>"</span></span><span>&gt;</span></span><br>	<span><span><span>&lt;</span>source</span> <span>srcset</span><span><span>=</span><span>"</span>img/photo.webp<span>"</span></span> <span>type</span><span><span>=</span><span>"</span>image/webp<span>"</span></span><span>&gt;</span></span><br>	<span><span><span>&lt;</span>img</span> <span>src</span><span><span>=</span><span>"</span>img/photo.jpg<span>"</span></span> <span>alt</span><span><span>=</span><span>"</span>Description of Photo<span>"</span></span><span>&gt;</span></span><br><span><span><span>&lt;/</span>picture</span><span>&gt;</span></span></code></pre><h2>AVIF Content-Type Headers + Netlify</h2><p>An issue we noticed when using .avif files on <a href="https://www.netlify.com/">Netlify</a>, was that the image wasn't showing up in Firefox. It worked fine for Chrome, but not Firefox. We identified that the Response Headers were returning <code>Content-Type: application/octet-stream</code>, causing Firefox to display nothing. We fixed this by defining custom headers within the Netlify configuration file (<code>netlify.toml</code>).</p><pre><code><span>[</span><span>[</span>headers<span>]</span><span>]</span><br>  for = "<span>*.avif"</span><br>  <span>[</span>headers.values<span>]</span><br>    Content<span>-</span>Type = "image/avif"<br>    Content<span>-</span>Disposition = "inline"</code></pre><p>We also set the <code>Content-Disposition</code> to <code>inline</code> vs <code>attachment</code>, this way the browser will try to render the file within the browser rather than externally. A good example of this is when a PDF will open within the browser vs as a downloadable file. While <code>inline</code> should be default behavior, specifying won't hurt as this is a new filetype.</p><p>You can learn more about setting <a href="https://docs.netlify.com/routing/headers/">Custom Headers in Netlify</a> by checking out their docs.</p><h2>We're Excited</h2><p>We are super excited about what kind of awesome new experiences can be made with the flexibility and performance gains of this new format.</p></section></div>]]>
            </description>
            <link>https://reachlightspeed.com/blog/using-the-new-high-performance-avif-image-format-on-the-web-today/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24071431</guid>
            <pubDate>Thu, 06 Aug 2020 14:53:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Math of Card Shuffling (2018)]]>
            </title>
            <description>
<![CDATA[
Score 131 | Comments 58 (<a href="https://news.ycombinator.com/item?id=24069999">thread link</a>) | @benibraz
<br/>
August 6, 2020 | https://fredhohman.com/card-shuffling/ | <a href="https://web.archive.org/web/*/https://fredhohman.com/card-shuffling/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="idyll-mount"><div data-reactroot=""><div><div><div><h2>Riffling from factory order to complete randomness.</h2></div><p>You’ve probably seen a few ways to shuffle a deck of cards.
Sometimes the deck is split in half and the halves are switched.
Sometimes the deck is <em><a href="https://big.assets.huffingtonpost.com/smooshing.gif">smooshed</a></em> until it’s all mixed up.
But most of the time, a deck of cards is shuffled using a <em>riffle</em>.</p><p><img src="https://fredhohman.com/card-shuffling/static/images/riffle.gif" idyll="[object Object]"></p><p>Here’s a question: <em>how many times do you have to riffle a deck of cards before it is completely shuffled?</em>

It’s a tricky one, but math has us covered: <a href="https://en.wikipedia.org/wiki/Shuffling#Riffle">you need seven riffles</a>.</p><div><p>
We can calculate the number of orderings of a deck of cards using the notion of a <a href="https://en.wikipedia.org/wiki/Permutation">permutation</a>.
To find all arrangements of 52 cards in a deck, we compute <strong>5<!-- -->2<!-- -->!</strong>, which happens to be a <a href="https://www.wolframalpha.com/input/?i=52!">really big number</a>.</p></div><p>Riffle seven times and you’ll have a sufficiently random ordering of cards, an ordering that has likely <a href="http://www.murderousmaths.co.uk/cardperms.htm">never existed before</a>.
In other words, it’s unlikely you’ll ever shuffle two decks the same.</p><p>The card shuffling result appears in a <a href="https://www.youtube.com/watch?v=AxJubaijQbI">Numberphile video from 2015</a>, along with a number of other card shuffling facts.
Here’s another problem posed in that video: what if instead of a standard riffle using a deck roughly split in half, you were to only riffle <em>1<!-- --> card at a time</em>?</p><div><p><a href="https://projecteuclid.org/download/pdf_1/euclid.aoap/1177005705">This paper</a> shows a number of other interesting card shuffling results in all their gory details.</p></div><p>That is, using a standard deck of 52 cards, in one hand hold 51 cards and in the other hold the remaining single card.
Now riffle these together.
This is equivalent to taking one card and placing it at random inside of the deck.</p><p><strong>So here’s the question:</strong>
<br><em>How many single riffles do you have to do in order to have a completely shuffled deck?</em>

</p><h2>Theorem</h2><p>You could simulate this in a short program, which we will do towards the end, but first we can solve for the number of riffles explicitly.</p><p>Consider an ordered deck of cards. <a href="https://en.wikipedia.org/wiki/Without_loss_of_generality">Without loss of generality</a>, let’s say the suits are in the following order: <span suit="S">♠</span>, <span suit="C">♣</span>, <span suit="H">♥</span>, <span suit="D">♦</span>.
So our ordered deck looks like this.</p><p>The bottom suit is <span suit="D">♦</span>, which means the bottom card of our deck is the King of Diamonds (<span number="K" suit="D">K♦</span>).
Now perform the following iteration:</p><blockquote>Place the top card of the deck randomly inside the deck</blockquote><p>This means taking the <span number="A" suit="S">A♠</span> and placing it randomly somewhere in the deck.
The top card then becomes <span number="2" suit="S">2♠</span>.</p><p>If this procedure is repeated, eventually the top card will be placed at the very bottom of the deck, shifting the <span number="K" suit="D">K♦</span> to the penultimate position.
Since every riffled card has a <span><span> <span><span><math><semantics><mrow><mfrac><mrow><mn>1</mn></mrow><mrow><mn>5</mn><mn>2</mn></mrow></mfrac></mrow><annotation encoding="application/x-tex">\frac{1}{52}</annotation></semantics></math></span></span> </span></span> chance of moving to any new position in the deck, that means, on average, after about 52 top card riffles, the top card will become the new bottom card.</p><div><div><p><strong>Note:</strong> notice the <span number="K" suit="D">K♦</span> can only rise in the deck.
There are two cases:</p><ol><li>The top card is placed above the <span number="K" suit="D">K♦</span>, therefore its position does not change.</li><li>The top card is placed underneath the <span number="K" suit="D">K♦</span>, therefore it rises one position closer to the top.</li></ol></div></div><p>Once the <span number="K" suit="D">K♦</span> moves up one position, upon subsequent riffles there are now two spots for the new top card to be placed underneath it.
That means there is now a <span><span> <span><span><math><semantics><mrow><mfrac><mrow><mn>1</mn></mrow><mrow><mn>5</mn><mn>2</mn></mrow></mfrac><mo>+</mo><mfrac><mrow><mn>1</mn></mrow><mrow><mn>5</mn><mn>2</mn></mrow></mfrac><mo>=</mo><mfrac><mrow><mn>2</mn></mrow><mrow><mn>5</mn><mn>2</mn></mrow></mfrac></mrow><annotation encoding="application/x-tex">\frac{1}{52}+\frac{1}{52}=\frac{2}{52}</annotation></semantics></math></span></span> </span></span> chance of a riffled card going underneath the <span number="K" suit="D">K♦</span>.</p><p>Continuing this procedure, the original bottom card, the <span number="K" suit="D">K♦</span>, will eventually rise to the top of the deck and be riffled.
Once this happens, the deck is randomly shuffled: the order we’re left with is equally as likely as any other order.</p><p>So, how many single card riffles does this take?
Recall each time a card is placed underneath the <span number="K" suit="D">K♦</span>, our chances of placing another card increases by <span><span> <span><span><math><semantics><mrow><mfrac><mrow><mn>1</mn></mrow><mrow><mn>5</mn><mn>2</mn></mrow></mfrac></mrow><annotation encoding="application/x-tex">\frac{1}{52}</annotation></semantics></math></span></span> </span></span>.
We can calculate the number of riffles this would take.</p><p><span><span> <span><span><span><math><semantics><mrow><munderover><mo>∑</mo><mrow><mi>i</mi><mo>=</mo><mn>1</mn></mrow><mrow><mn>5</mn><mn>2</mn></mrow></munderover><mfrac><mrow><mn>5</mn><mn>2</mn></mrow><mrow><mi>i</mi></mrow></mfrac><mo>=</mo><mfrac><mrow><mn>5</mn><mn>2</mn></mrow><mrow><mn>1</mn></mrow></mfrac><mo>+</mo><mfrac><mrow><mn>5</mn><mn>2</mn></mrow><mrow><mn>2</mn></mrow></mfrac><mo>+</mo><mfrac><mrow><mn>5</mn><mn>2</mn></mrow><mrow><mn>3</mn></mrow></mfrac><mo>+</mo><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mi mathvariant="normal">.</mi><mo>+</mo><mfrac><mrow><mn>5</mn><mn>2</mn></mrow><mrow><mn>5</mn><mn>2</mn></mrow></mfrac><mo>≈</mo><mn>2</mn><mn>3</mn><mn>6</mn></mrow><annotation encoding="application/x-tex">\sum_{i=1}^{52} \frac{52}{i} = \frac{52}{1} + \frac{52}{2} + \frac{52}{3} + ... + \frac{52}{52} \approx 236</annotation></semantics></math></span></span></span> </span></span></p><p>On average, 236 single card riffles will randomly shuffle a deck of cards.</p><h2>Let’s Riffle</h2><p>Equations are great, but let’s visualize this!
Below is the same ordered deck of cards from before, except the <span number="K" suit="D">K♦</span> has been highlighted red so we can follow its journey to the top of the deck.</p><p>Click the <strong>Riffle</strong> button to move the top card somewhere else in the deck randomly.</p><p>Did you see where it went? Click again.</p><p>Click a bunch more really fast.</p><p>Now I could tell you to keep clicking until the highlighted <span number="K" suit="D">K♦</span> rises to the top, but as we have already shown, that would take about 236 clicks.
Instead, click the <strong>Riffle (x<!-- -->1<!-- -->0<!-- -->)</strong> button to riffle 10 times.
Keep riffling until the <span number="K" suit="D">K♦</span> moves to the top.</p><div><p>
You have riffled <strong><span>0</span></strong> times.<br></p></div><p>Here is a chart of the <span number="K" suit="D">K♦</span>’s position in the deck for each riffle.
Notice how it takes many riffles to move the <span number="K" suit="D">K♦</span> up just a few positions, but once the <span number="K" suit="D">K♦</span> starts rising towards the top of the deck, it accelerates.</p><div><p>
Once the <span number="K" suit="D">K♦</span> is the top card, click the <strong>Clear</strong> button to try again.</p></div><p>On average, the <span number="K" suit="D">K♦</span> will reach the top position somewhere around 236 riffles.
Since this is the <em>average</em> result, there is a chance your first shuffled deck of cards took less riffles (or many more!).
To try again, click the <strong>Clear</strong> button and get riffling.</p><h3>Acknowledgements</h3><ul><li>This article was created using <a href="https://idyll-lang.org/">Idyll</a>.</li><li>Shoutout to <a href="https://twitter.com/mathisonian">@mathisonian</a> <!-- -->for help and feedback.</li><li>The source code is available on <a href="https://github.com/fredhohman/card-shuffling/">Github</a>.</li></ul></div></div></div></div></div>]]>
            </description>
            <link>https://fredhohman.com/card-shuffling/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24069999</guid>
            <pubDate>Thu, 06 Aug 2020 11:27:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Programming with RISC-V Vector Instructions]]>
            </title>
            <description>
<![CDATA[
Score 105 | Comments 17 (<a href="https://news.ycombinator.com/item?id=24069793">thread link</a>) | @pantalaimon
<br/>
August 6, 2020 | https://gms.tf/riscv-vector.html | <a href="https://web.archive.org/web/*/https://gms.tf/riscv-vector.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
      <header>
        
      </header>
      
<!-- content -->
<p>Perhaps the most interesting part of the open <a href="https://en.wikipedia.org/wiki/RISC-V">RISC-V</a> <a href="https://en.wikipedia.org/wiki/Instruction_set_architecture">instruction set architecture (ISA)</a> is the vector extension (RISC-V "V").
In contrast to the average <a href="https://en.wikipedia.org/wiki/SIMD">single-instruction multipe-data (SIMD)</a> instruction set, RISC-V vector instructions are vector length agnostic (VLA).
Thus, a RISC-V "V" CPU is flexible in choosing a vector register size while RISC-V "V" binary code is portable between different CPU implementations.</p>
<p>This articles compares the two main different styles of vector ISAs, discusses a string processing  example that is implemented using <a href="https://github.com/riscv/riscv-v-spec/releases/tag/0.8">RISC-V "V" draft version 0.8</a> (current as of early 2020) vector instructions and details how to set up a RISC-V "V" development environment under Linux.</p>

<section id="simd-challenges">
<h2><a href="#id13">SIMD Challenges</a></h2>
<p>With a vector length specific (VLS) <a href="https://en.wikipedia.org/wiki/SIMD">SIMD</a> instruction set the main problem is to pick the right vector register size.
Of course there is a trade-off between the amount of data-level parallelism and hardware costs.
Due to <a href="https://en.wikipedia.org/wiki/Moore%27s_law">Moore's law</a>, vector register sizes can be increased over time without making the CPU chip more expensive.
Also, some users are interested in powerful CPUs with wider vector registers while the average user is fine with averagely sized register.
Thus, there is no one right vector register size.
This shows for example with x86, where the answer is to provide one VLS ISA after the other, such as <a href="https://en.wikipedia.org/wiki/MMX_(instruction_set)">MMX</a> (64 bit registers), <a href="https://en.wikipedia.org/wiki/Streaming_SIMD_Extensions">SSE</a> (128 bit), <a href="https://en.wikipedia.org/wiki/Advanced_Vector_Extensions">AVX</a> (256 bit) and <a href="https://en.wikipedia.org/wiki/AVX-512">AVX512</a> (512 bit).</p>
<p>Because of <a href="https://en.wikipedia.org/wiki/Backward_compatibility">backward compatibility</a>, each CPU that adds a new VLS ISA also has to support all existing ones.
This leads to a waste of <a href="https://en.wikipedia.org/wiki/Opcode">opcode</a> space and increases the complexity of the CPU's <a href="https://en.wikipedia.org/wiki/Instruction_cycle#Decode_stage">instruction decoder</a>.
Of course this also increases the complexity for the programmer who has then remember (or look up all the time) syntactic and functional differences between all the VLS ISAs.</p>
<p>That means that while VLS code written for smaller vector registers runs on newer CPUs, it can't make use of the wider vector registers.
Thus, existing code has to be reimplemented again and again to make use of new VLS ISAs.
Similarly, code written for high-end CPUs doesn't run on middle-end CPUs (because it requires the VLS-ISA with wider vector registers).
Thus one either has to target some older (hopefully widely available) VSL-ISA or has to provide multiple implementations for different VSL-ISAs.</p>
</section>
<section id="the-solution-agnosticism">
<h2><a href="#id14">The Solution: Agnosticism</a></h2>
<p>The solution to all this is to design a variable length vector instruction set.
In that way the instructions are then agnostic to the vector register size of a concrete CPU implementation.
Thus, the binary code is portable between low, middle and high-end CPUs, and automatically makes use of wider registers in newer CPUs.</p>
<p>The <a href="https://github.com/riscv/riscv-v-spec/releases/tag/0.8">RISC-V vector extension "V"</a> implements such vector instruction set.
As of early 2020, the <a href="https://github.com/riscv/riscv-v-spec/releases/tag/0.8">RISC-V "V" specification</a> is at version 0.8 and has draft status.</p>
<p>RISC-V "V" adds 32 vector registers, where the first register can be used as mask register and up to 8 registers can be grouped together.
The operands of a vector instruction such as <code>vadd.vv</code> are single vector registers or vector register groups.</p>
<p>Since vector registers are of variable length, RISC-V "V" code has to indicate the maximum vector length it wants to work with, e.g.:</p>
<pre><span>vsetvli</span> <span>t0</span><span>,</span> <span>a2</span><span>,</span> <span>e8</span></pre>
<p>Meaning that a vector length (vl) of up to <code>a2</code> 8 bit wide (<code>e8</code>) elements is requested while the instruction returns the resulting length in register <code>t0</code>.
Thus, if the <code>a2</code> register is set to - say - <code>4096</code>, on a CPU with a vector register length (VLEN) of 128 bits, the following vector instructions work on 16 element wide vectors and <code>t0</code> is thus set to <code>16</code>, while on a CPU with 512 bit registers the vectors are configured to be 64 elements wide and <code>t0</code> is set to <code>64</code>.</p>
<p>This approach also simplifies loops that iterate over an input array in vector length chunks.
For example (where <code>a1</code> contains the address of an array of <code>a2</code> times 4 bytes):</p>
<pre><span>.Loop:</span>                        <span># local symbol name because of .L prefix</span>
    <span>vsetvli</span> <span>t0</span><span>,</span> <span>a2</span><span>,</span> <span>e32</span>       <span># configure vectors of 32 bit elements</span>

    <span>vlw.v</span>   <span>v4</span><span>,</span> <span>(</span><span>a1</span><span>)</span>          <span># Load t0 elements into v4,</span>
                              <span># starting at the address stored in a1</span>

    <span>...</span>                       <span># work with that chunk</span>

    <span>slli</span>    <span>t1</span><span>,</span> <span>t0</span><span>,</span> <span>2</span>         <span># shift-left logical, i.e. times 4</span>
    <span>add</span>     <span>a1</span><span>,</span> <span>a1</span><span>,</span> <span>t1</span>        <span># increment src by read elements</span>
    <span>sub</span>     <span>a2</span><span>,</span> <span>a2</span><span>,</span> <span>t0</span>        <span># decrement n</span>
    <span>bnez</span>    <span>a2</span><span>,</span> <span>.Loop</span>         <span># branch to loop head if not equal to zero</span>

    <span>...</span>                       <span># continue</span></pre>
<p>In cases where <code>a2</code> isn't a multiple of the maximum vector length, the last iteration
sets the vector length to a smaller value and the following vector instructions ignore
the unused trailing elements.
This implicit masking mechanism is orthogonal to the optional mask operand that is supported by most RISC-V vector instructions.</p>
<p>In contrast to that, with a vector length specific ISA, the main loop usually has to be followed by some finalization code block to explicitly deal with the last elements that don't fill a complete register, e.g.:</p>
<pre><span>const</span> <span>unsigned</span> <span>char</span> <span>*</span><span>p</span> <span>=</span> <span>inp</span><span>;</span>
<span>size_t</span> <span>l</span> <span>=</span> <span>n</span> <span>/</span> <span>(</span><span>VECTOR_LENGTH</span> <span>*</span> <span>ELEMENT_BYTES</span><span>);</span>
<span>for</span> <span>(</span><span>size_t</span> <span>i</span> <span>=</span> <span>0</span><span>;</span> <span>i</span> <span>&lt;</span> <span>l</span><span>;</span> <span>++</span><span>i</span><span>,</span> <span>p</span> <span>+=</span> <span>VECTOR_LENGTH</span> <span>*</span> <span>ELEMENT_BYTES</span><span>)</span> <span>{</span>
    <span>...</span> <span>// load p into a vector register</span>
    <span>...</span> <span>// execute some vector instructions</span>
<span>}</span>
<span>// deal with some remaining bytes</span>
<span>// e.g. by setting up a mask or work on single elements</span>
<span>for</span> <span>(</span><span>size_t</span> <span>i</span> <span>=</span> <span>l</span><span>;</span> <span>i</span> <span>&lt;</span> <span>n</span><span>;</span> <span>++</span><span>i</span><span>,</span> <span>p</span> <span>+=</span> <span>ELEMENT_BYTES</span><span>)</span> <span>{</span>
    <span>...</span> <span>// work on the next element located at p</span>
<span>}</span></pre>
</section>
<section id="example">
<h2><a href="#id15">Example</a></h2>
<p>To illustrate RISC-V "V" with a real example, this section shows how to implement a vectorized function that converts a string of <a href="https://en.wikipedia.org/wiki/Binary-coded_decimal">binary coded decimals (BCD)</a> into an <a href="https://en.wikipedia.org/wiki/ASCII">ASCII</a> string.
Why BCD to ASCII conversion?
The task is complex enough such that most of the different vector instructions are used.
On the other hand, it's simple enough to fit into a small article and doesn't require domain specific knowledge.
It also demonstrates some perhaps not entirely obvious ways how vector instructions are used for string processing where those instruction could be assumed to only be useful for calculations.</p>
<p>With BCD, a byte (8 bits) is divided into two <a href="https://en.wikipedia.org/wiki/Nibble">nibbles</a> (4 bits) such that each nibble stores a (hexa-)decimal digit.
Note that 4 bits allow to exactly encode <span>2<sup>4</sup></span> values, thus when using it just for storing decimal digits it's not a very efficient encoding.</p>
<p>For the purpose of our example, the exercise is to write vector code that efficiently converts a BCD string such as <code>{ 0x12, 0x34, ..., 0xcd, 0xef }</code> to a corresponding ASCII string (e.g. <code>{ '1', '2', '3', '4', ..., 'c', 'd', 'e', 'f' }</code>). On a high-level, a solution involves separating the nibbles into single bytes and then converting each byte to the matching ASCII value.</p>
<p>The complete example source code is available in <a href="https://github.com/gsauthof/riscv">my github repository</a>.</p>
<section id="shuffling-nibbles">
<h3><a href="#id16">Shuffling Nibbles</a></h3>
<p>Our function has the following function signature:</p>
<pre><span>void</span> <span>bcd2ascii</span><span>(</span><span>void</span><span>*</span> <span>dst</span><span>,</span> <span>void</span> <span>const</span> <span>*</span> <span>src</span><span>,</span> <span>size_t</span> <span>n</span><span>);</span></pre>
<p>Meaning that <code>n</code> input bytes are read from <code>src</code> and the conversion writes <code>2*n</code> bytes into the <code>dst</code> output buffer.
Under the RISC-V calling conventions, <code>dst</code> is passed in register <code>a0</code>, <code>src</code> in register <code>a1</code> and <code>n</code> in register <code>a2</code>.</p>
<pre><span>.Loop:</span>                        <span># local symbol name because of .L prefix</span>
    <span>vsetvli</span> <span>a3</span><span>,</span> <span>a2</span><span>,</span> <span>e16</span><span>,</span> <span>m8</span>   <span># switch to 16 bit element size,</span>
                              <span># 4 groups of 8 registers</span>
    <span># --&gt; a3 = min(a2, 8*vlenb/2)</span>
    <span>vlbu.v</span> <span>v16</span><span>,</span> <span>(</span><span>a1</span><span>)</span>          <span># Load a3 unsigned bytes,</span>
                              <span># one byte per 16 bit element, zero-extend,</span>
                              <span># starting at addr stored in a1</span>
    <span># --&gt; v16 = | 0, a1[vlenb/2-1], ..., 0, a1[1], 0, a1[0] |, ...,</span>
    <span>#     v23 = | 0, a1[a3-1],       ...,  0, a1[7*vlenb/2] |</span>
    <span># --&gt; v16 = | ... 00mn 00kl 00ij 00gh |</span>

    <span>add</span> <span>a1</span><span>,</span> <span>a1</span><span>,</span> <span>a3</span>            <span># increment src by read elements</span>
    <span>sub</span> <span>a2</span><span>,</span> <span>a2</span><span>,</span> <span>a3</span>            <span># decrement n</span></pre>
<p>The main loop starts with configuring a vector element size of 16 bit (<code>e16</code>), grouping 8 registers together (<code>m8</code>) and requesting a vector length that equals the number of remaining source bytes or the CPU maximum.
With this grouping, each register group is accessed by using a vector register with a number that is dividable by 8.
That means <code>v0</code> identifies the group consisting of <code>v0, v1, ..., v7</code>, <code>v8</code> identifies <code>v8, ..., v15</code>, etc.</p>
<p>The <code>vl*.v</code> load instruction comes in different variants.
Here, the <code>vlbu.v</code> variant zero extends each input byte per 16 bit element which is useful in our example because this directly leaves room for shuffling the nibbles.
In other words, it's a widening load and thus saves a separate widening operation such as <code>vwaddu.vx</code>.</p>
<p>That means on CPUs with 256 bit vector registers, this code loads up to 128 input bytes into the <code>v16</code> register group.</p>
<p>Note that register content in the comments is enclosed in <code>| |</code> and written right to left, starting with the least significant element.
Arbitrary nibbles are denoted sometimes by placeholder variables such as <code>g, h, ...</code>.</p>
<p>The actual nibble shuffling:</p>
<pre><span>vsll.vi</span> <span>v24</span><span>,</span> <span>v16</span><span>,</span> <span>8</span>       <span># shift-left-logical each element by 8 bits</span>
<span># --&gt; v24 = | ... mn00 kl00 ij00 gh00 |</span>

<span>vsrl.vi</span> <span>v16</span><span>,</span> <span>v16</span><span>,</span> <span>4</span>       <span># shift-right-logical each element by 4 bits</span>
<span># --&gt; v16 = | ... 000m 000k 000i 000g |</span>

<span>slli</span> <span>a3</span><span>,</span> <span>a3</span><span>,</span> <span>1</span>            <span># shift left logical by immediate,</span>
                          <span># i.e. to double the number of vector elements</span>
<span>vsetvli</span> <span>t4</span><span>,</span> <span>a3</span><span>,</span> <span>e8</span><span>,</span> <span>m8</span>    <span># switch to 8 bit element size,</span>
                          <span># 4 groups of 8 registers</span>

<span>vand.vx</span> <span>v24</span><span>,</span> <span>v24</span><span>,</span> <span>t2</span>      <span># and each element with 0x0f,</span>
                          <span># i.e. zero-out the high nibbles</span>
<span># --&gt; v24 = | ... 0n 00 0l 00 0j 00 0h 00 |</span>
<span>vor.vv</span>  <span>v16</span><span>,</span> <span>v16</span><span>,</span> <span>v24</span>     <span># or each element</span>
<span># --&gt; v16 = | ... 0n 0m 0l 0k 0j 0i 0h 0g |</span></pre>
<p>So far the example shows most of the syntactic conventions of the "V" ISA.
Vector instructions start with <code>v</code> and a suffix such as <code>.vi</code>, <code>.vx</code> and <code>.vv</code> describe the source operand types, i.e. vector-immediate, vector-scalar and vector-vector.</p>
<p>The bit-shift instructions don't cross element boundaries.
Thus, just vector group <code>v24</code> has to be zero-masked and not <code>v16</code>.</p></section></section></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://gms.tf/riscv-vector.html">https://gms.tf/riscv-vector.html</a></em></p>]]>
            </description>
            <link>https://gms.tf/riscv-vector.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24069793</guid>
            <pubDate>Thu, 06 Aug 2020 10:52:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Two Features of JavaScript that you might not know]]>
            </title>
            <description>
<![CDATA[
Score 56 | Comments 59 (<a href="https://news.ycombinator.com/item?id=24069444">thread link</a>) | @illuminated
<br/>
August 6, 2020 | https://www.monkwhocode.com/2020/06/javascriptnodejs-2-features-that-you.html | <a href="https://web.archive.org/web/*/https://www.monkwhocode.com/2020/06/javascriptnodejs-2-features-that-you.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<div id="post-body-5960135948766008378">
<div dir="ltr" trbidi="on">
<p><a href="https://1.bp.blogspot.com/-eUGp0l2lGGI/Xu8IjGPaWoI/AAAAAAAAWPw/t1PSsuhsUMUErg6Pqodr1mFqR8_Y1pNQgCLcBGAsYHQ/s1600/LEARN%2BeXPLORE%2Bgrow%2B%25288%2529.png" imageanchor="1"><img data-original-height="500" data-original-width="500" height="320" src="https://1.bp.blogspot.com/-eUGp0l2lGGI/Xu8IjGPaWoI/AAAAAAAAWPw/t1PSsuhsUMUErg6Pqodr1mFqR8_Y1pNQgCLcBGAsYHQ/s320/LEARN%2BeXPLORE%2Bgrow%2B%25288%2529.png" width="320"></a></p>

<p>
This is a very short article where we will be discussing two Javascript features that you may not know.</p>


<p>
So let's start,</p>

<p><b>1)Exponentiation operator(**):</b></p>
<p>
This operator was added in ES6 and is supported by most of the browsers but excluding internet explorer.</p>
<p>
It is also called an Infix operator for Exponentiation.</p>
<p>
Before for exponentiation, we have to use Math.pow(x,y).</p>
<p>
But now you can use x**y.</p>

<p>
For example: 2**5 //returns 32</p>

<p><b>2)Numeric Separators:</b></p>
<p>
Large numeric literals are difficult for the human eye to parse quickly,</p>
<p>
especially when there are lots of repeating digits. To improve readability, you can use</p>
<p>
underscores as separators in numeric literals.</p>

<p>
For example:</p>
<p>
let value= 100_000_000_00 //Is same as 10000000000</p>

<p>
As of May 2020, It is supported by all major browsers (Chrome[75+], Firefox[70+], Edge, Safari[13+], Opera) (<a href="https://caniuse.com/#feat=mdn-javascript_grammar_numeric_separators">source 1</a>, <a href="https://v8.dev/features/numeric-separators">source 2</a> for more details about different browsers and versions supporting it)&nbsp;</p>

<p>
Interesting note: although supported by all browsers, this is not part of any ECMAScript version yet.</p>



<p>
I hope you like this article and if any doubts please let me know in the comment section.</p>
<p>
Subscribe&nbsp;this blog for more articles on&nbsp;Node.js&nbsp;and&nbsp;JavaScript.<br>
You can also follow me on&nbsp;<b><a href="https://twitter.com/joshiisaurabh">Twitter</a></b>&nbsp;or&nbsp;<b><a href="https://www.linkedin.com/in/saurabh-joshi-b16b05b4/">Linkedin</a>&nbsp;</b>for<b>&nbsp;</b>the<b>&nbsp;</b>latest updates.</p><p>

Written By:<br>
<b>Saurabh Joshi</b></p>




<br></div>
</div>
</div></div>]]>
            </description>
            <link>https://www.monkwhocode.com/2020/06/javascriptnodejs-2-features-that-you.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24069444</guid>
            <pubDate>Thu, 06 Aug 2020 09:37:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Epic Systems workers are organizing]]>
            </title>
            <description>
<![CDATA[
Score 161 | Comments 83 (<a href="https://news.ycombinator.com/item?id=24068201">thread link</a>) | @mgerdts
<br/>
August 5, 2020 | https://www.tonemadison.com/articles/epic-workers-arent-just-mad-theyre-organizing | <a href="https://web.archive.org/web/*/https://www.tonemadison.com/articles/epic-workers-arent-just-mad-theyre-organizing">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div data-layout-label="Post Body" data-type="item" data-updated-on="1596655167481" id="item-5f2b05c776829d20055ef8a0"><div><div><div data-block-type="2" id="block-b9ef3d0cb4832dbe6ac8"><div><p><strong><em>The Madison-area tech company's botched COVID-19 response has spurred some employees to pursue unionization.</em></strong></p><p><strong><em>John McCracken contributed additional reporting for this story.</em></strong></p><p><strong><em>Photo by </em></strong><a href="https://www.flickr.com/photos/gas_station_sushi/7261830974" target="_blank"><strong><em>E. Nekervis on Flickr</em></strong></a><strong><em>.</em></strong></p><p>Epic Systems is putting Madison back in the tech-industry spotlight, this time for its troubling public health and labor practices. As COVID-19 cases mount in Wisconsin, Dane County’s second-largest employer is set to send workers back to its sprawling Verona campus in stages, starting on August 10.&nbsp;</p><p>Employee fears and anger surrounding the return-to-work plan are, at this point, well-established: national and local reporters have <a href="https://twitter.com/lkwhite/status/1290677520078196736?s=20" target="_blank">noted</a> the dozens of messages, calls, and emails they received in response to requests for comment. But employee dissatisfaction has manifested in more than complaints. It has also cracked open an opportunity for collective action in the Madison area’s biggest, most ostentatiously anti-labor private employer.&nbsp;</p><p>Many of the Epic employees facing down the return-to-work date say they are scared about the health implications of heading back to share physical space with thousands of their co-workers.</p><p>“There’s a person in my household who is at high risk for serious complications from COVID-19 and I am very cognizant of the fact that my actions affect more than just myself,” says one employee, who also has two school-aged kids. Like many Epic workers speaking to the press this week, this employee asked to be cited anonymously, due to fears about retaliation or firing.</p><p>In an August 3 email, company executives addressed people who are parents or facing higher risks of coronavirus-related complications to offer an extended work-from-home period—but only until November 2, at which point employees are told to take a leave of absence without a guarantee of getting their jobs back. In an earlier message, sent on July 1, executives told employees: "If you’re a parent with young children, you will need to use the time between now and your return to campus to make arrangements for childcare so that you can be on campus full-time."</p><p>Of the Epic employees who spoke with <em>Tone Madison</em> this week, even those who are not at personally heightened risk for COVID-19&nbsp; expressed concern on behalf of the community at large.</p><p>“I’m a software developer at Epic, I’ve worked there for over 8 years...it’s disrespectful and risking the health of the entire community,” says another concerned employee, who remained anonymous for fear of reprisal. “We should all understand&nbsp; that personal risk is community risk. And so Epic, by forcing 10,000 people to increase their personal risk, it does risk the whole community.”</p><p>The scheduled plan will have workers populating the medical software company’s sprawling campus over the same period that University of Wisconsin-Madison students prepare to return to their dorms and downtown housing. To justify the rapid return to work, Epic CEO Judy Faulkner has cited the “culture” of the company: “It’s hard (actually, it’s impossible) to retain our culture when we’re working from our homes,” wrote Faulkner in an all-staff email on July 1.&nbsp;</p><p>Workers argue that given the projected course of the virus, there’s no way the company can provide for a safe return to work.</p><p>In Faulkner’s communications with Epic staff, she emphasized the role of individual employees in preventing the spread of COVID-19 on campus: “We ask you to do your part by avoiding bars, attending crowded gatherings, or other places where physical distancing can’t be easily observed.” By placing the responsibility of limiting exposure on individual workers, the company rhetorically absolves itself of the possibility of an outbreak: after all, Faulkner—Epic's <a href="https://www.nytimes.com/2018/12/20/business/epic-systems-campus-verona-wisconsin.html" target="_blank">eccentric billionaire</a> founder —claimed in the same&nbsp; email, “we’ve been told by many that our campus looks specifically designed to weather an epidemic.”&nbsp;</p><p>Epic is notorious for preventing employees from coming together to advocate for themselves as a group. In the 2018 ruling <em>&nbsp;</em><a href="https://www.oyez.org/cases/2017/16-285" target="_blank"><em>Epic Systems Corp. v. Lewis</em></a>, the United States Supreme Court enshrined the right of employers to force workers into individual arbitration. To work for Epic, employees sign away their rights to file class-action lawsuits against the company. It's now easier for other employers around the country to enforce those kinds of terms: In May 2018, <a href="https://www.jdsupra.com/legalnews/new-jersey-supreme-court-confirms-20004/" target="_blank">citing the </a><a href="https://www.jdsupra.com/legalnews/new-jersey-supreme-court-confirms-20004/"><em>Epic v. Lewis</em> SCOTUS ruling, </a>the New Jersey Supreme Court ruled that truck drivers attempting to file a collective suit against their employer could be prohibited from doing so.&nbsp;</p><p>In mid-July, a coalition of Epic workers, concerned about the company’s plan to reopen offices, circulated a survey to demonstrate collective disapproval of the plan. The poll yielded hundreds of responses condemning the company’s response to the coronavirus pandemic—but an Epic employee familiar with the survey, who prefers to remain anonymous for fear of reprisal, says that the company ignored the survey results. <a href="https://www.cbsnews.com/video/employees-raise-safety-concerns-with-return-to-work-plans/">In a </a><a href="https://www.cbsnews.com/video/employees-raise-safety-concerns-with-return-to-work-plans/" target="_blank"><em>CBS News</em></a><a href="https://www.cbsnews.com/video/employees-raise-safety-concerns-with-return-to-work-plans/"> segment that aired Tuesday morning</a>, Epic’s Chief Administrative Officer Sverre David Roang evaded questions about the survey, claiming that he was unaware of complaints surrounding the plan to reopen.&nbsp;</p><p>The pandemic, and Epic’s disregard for workers’ concerns, have occasioned a sudden flurry of labor activism at the company. Groups of workers have started organizing with the International Association of Sheet Metal, Air, Rail and Transportation Workers (SMART) Local 565. The local represents workers at several Madison-area companies, including Sub-Zero and Trachte Building Systems, and at a few companies in the Wausau area. IWW, a political affiliation group emphasizing direct action, has likewise supported workers in their fight for better conditions at Epic. The IWW's local activities of late have included <a href="http://captelunion.org/2020/03/18/captel-workers-union-calls-sickout/" target="_blank">working to organize employees at CapTel's call centers</a> in Madison and Milwaukee, and <a href="https://www.tonemadison.com/articles/the-grassroots-response-to-covid-19-in-madison-puts-our-institutions-to-shame" target="_blank">spearheading mutual-aid efforts during the pandemic</a>.</p><p>One first-time organizer among Epic's workers reached a boiling point after the usual channels available to Epic employees failed. “The reason that we reached out to the IWW,” says the worker, who requested anonymity, “is that we basically tried all of the internal avenues to have things change for the better, the work-from-home policies, the response to Black Lives Matter. Epic tells us that we’re supposed to be able to give feedback to whomever we want, and it doesn’t seem to have gone anywhere.”</p><p>“The only reason I am doing something is that it got to a point where my fear of getting fired was outweighed by 'I have to do something,'" this worker says.&nbsp;</p><p>This worker and organizer provided internal emails that outline the supposed benefits of coming back to work. One email that Faulkner sent to staff argues that employees who return to campus will have a better connection to Epic's software and internal employees. “Personally, I’m not willing to go back to work and possibly get sick for a better internet connection,” the worker says.&nbsp;</p><p>One employee in the company’s hosting sector, who has looked into the various union organizing drives, says that organizing at Epic will be a challenge, given the company’s hiring practices and labor structure.&nbsp;</p><p>“It is a little bit harder to organize than other places because there’s so many people that are young, straight out of college . . . without any frame of reference for their workplace conditions,” he says. “And there's a lot of&nbsp; anti-union or anti-collective sentiments that the company will work very hard to enforce.”</p><p>In addition to the 2018 SCOTUS ruling, Epic has, in the past several weeks, quashed workers’ attempts to act collectively. In an email obtained by <em>Tone Madison</em>, a company representative explained that an employee’s post questioning the return-to-work plan had been removed from an internal discussion board “per request by upper management.” <a href="https://madison.com/ct/news/local/health-med-fit/epic-employees-say-coronavirus-concerns-met-with-retaliation-demotions/article_7a7ce63e-4e56-5b57-a7f4-8c4dba286094.html#tracking-source=home-top-story" target="_blank">Employees also told </a><a href="https://madison.com/ct/news/local/health-med-fit/epic-employees-say-coronavirus-concerns-met-with-retaliation-demotions/article_7a7ce63e-4e56-5b57-a7f4-8c4dba286094.html#tracking-source=home-top-story"><em>The Capital Times </em>this week</a> that on multiple occasions, managers who had expressed concern about the company’s COVID-19 plan faced demotions.&nbsp;</p><p>The company has taken precautions to enable physical distancing on the premises, installing the same airflow systems used in hospitals, and rearranging the main cafeteria to preclude the daily mass gatherings characteristic of pre-pandemic lunchtime at the software company. But Epic's coronavirus response diverges significantly from those of other tech companies, including Alphabet, Google’s parent company, <a href="https://www.wsj.com/articles/google-to-keep-employees-home-until-summer-2021-amid-coronavirus-pandemic-11595854201" target="_blank">which will not require workers to return to its Mountain View, California offices until July of next year</a>.&nbsp;</p><p>Before the sudden spate of labor coverage at Epic, the medical software company had mostly <a href="https://madison.com/wsj/news/local/govt-and-politics/epic-systems-draws-on-literature-greats-for-its-next-expansion/article_4d1cf67c-2abf-5cfd-8ce1-2da60ed84194.html" target="_blank">drawn attention for its themed campus</a>—an oversized playground paying homage to storybook figures like Alice in Wonderland, Humpty Dumpty, and Harry Potter.&nbsp;</p><p>But with COVID-19 spreading quickly <a href="https://www.dhs.wisconsin.gov/covid-19/local.htm" target="_blank">in 61 of Wisconsin’s 72 counties</a>, the pandemic highlights the contradiction between Epic’s friendly workplace aesthetic and its disregard for worker safety. </p></div></div></div></div></div></div></div>]]>
            </description>
            <link>https://www.tonemadison.com/articles/epic-workers-arent-just-mad-theyre-organizing</link>
            <guid isPermaLink="false">hacker-news-small-sites-24068201</guid>
            <pubDate>Thu, 06 Aug 2020 04:48:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Node Modules at War: Why CommonJS and ES Modules Can’t Get Along]]>
            </title>
            <description>
<![CDATA[
Score 180 | Comments 138 (<a href="https://news.ycombinator.com/item?id=24067748">thread link</a>) | @dfabulich
<br/>
August 5, 2020 | https://redfin.engineering/node-modules-at-war-why-commonjs-and-es-modules-cant-get-along-9617135eeca1 | <a href="https://web.archive.org/web/*/https://redfin.engineering/node-modules-at-war-why-commonjs-and-es-modules-cant-get-along-9617135eeca1">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><section><div><div><h2 id="4131">Interop between them is possible, but it’s a hassle</h2><div><div><div><p><a href="https://redfin.engineering/@danfabulich?source=post_page-----9617135eeca1----------------------" rel="noopener"><img alt="Dan Fabulich" src="https://miro.medium.com/fit/c/96/96/0*3NuQy3oh1ckOGP-9." width="48" height="48"></a></p></div></div></div><p id="38db"><em>Dan Fabulich is a Principal Engineer at Redfin. (</em><a href="https://www.redfin.com/about/jobs?utm_source=engblog" target="_blank" rel="noopener"><em>We’re hiring</em></a><em>!)</em></p><p id="65d7">In Node 14, there are now two kinds of scripts: there are old-style CommonJS (CJS) scripts and new-style ESM scripts (aka MJS). CJS scripts use <code>require()</code> and <code>module.exports</code>; ESM scripts use <code>import</code> and <code>export</code>.</p><p id="4684"><strong>ESM and CJS are completely different animals.</strong> Superficially, ESM looks very similar to CJS, but their implementations couldn’t be more different. One of them is a honey bee, and the other is a murder hornet.</p><figure><div><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/3436/1*ljab8kLJtGC-o36VQ7vBZg.jpeg" width="1718" height="581" srcset="https://miro.medium.com/max/552/1*ljab8kLJtGC-o36VQ7vBZg.jpeg 276w, https://miro.medium.com/max/1104/1*ljab8kLJtGC-o36VQ7vBZg.jpeg 552w, https://miro.medium.com/max/1280/1*ljab8kLJtGC-o36VQ7vBZg.jpeg 640w, https://miro.medium.com/max/1400/1*ljab8kLJtGC-o36VQ7vBZg.jpeg 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*ljab8kLJtGC-o36VQ7vBZg.jpeg?q=20"></p></div></div></div><figcaption>A hornet and a honey bee. One of these is like ESM and the other is like CJS, but I can never remember which one is which. Credit: <a href="https://en.wikipedia.org/wiki/File:Hornet-vespa.jpg" target="_blank" rel="noopener">wikimedia</a>, <a href="https://commons.wikimedia.org/wiki/File:Honey_bee_(Apis_mellifera).jpg" target="_blank" rel="noopener">wikimedia</a></figcaption></figure><p id="c5d2"><strong>Calling CJS from ESM and vice versa is possible, but it’s a hassle.</strong></p><p id="4a03">Here are the rules, which I’ll explain in more detail below:</p><ol><li id="0fb2">You can’t <code>require()</code> ESM scripts; you can only <code>import</code> ESM scripts, like this: <code>import {foo} from 'foo'</code></li><li id="e91d">CJS scripts can’t use static <code>import</code> statements like the one above.</li><li id="ad90">CJS scripts <em>can</em> use asynchronous dynamic <code>import()</code> to use ESM, but that's a hassle, compared to synchronous <code>require</code>.</li><li id="d3b7">ESM scripts <em>can</em> <code>import</code> CJS scripts, but only by using the “default import” syntax <code>import _ from 'lodash'</code>, not the “named import” syntax <code>import {shuffle} from 'lodash'</code>, which is a hassle if the CJS script uses named exports.</li><li id="a767">ESM scripts <em>can</em> <code>require()</code> CJS scripts, even with named exports, but it’s typically not worth the trouble, because it requires even more boilerplate, and, worst of all, bundlers like Webpack and Rollup don’t/won’t know how to work with ESM scripts that use <code>require()</code>.</li><li id="3a5c">CJS is the default; you have to opt-in to ESM mode. You can opt-in to ESM mode by renaming your script from <code>.js</code> to <code>.mjs</code>. Alternately, you can set <code>"type": "module"</code> in <code>package.json</code>, and then you can opt-out of ESM by renaming scripts from <code>.js</code> to <code>.cjs</code>. (You can even tweak just an individual subdirectory by putting a one-line <code>{"type": "module"}</code> <code>package.json</code> file in there.)</li></ol><p id="1641">These rules are <em>painful</em>. Worse, for many users, especially newbies to Node, these rules are <em>incomprehensible</em>. (Fear not, I’ll explain them all here in this article.)</p><p id="5fb5">Many observers of the Node ecosystem have speculated that these rules are due to a failure of leadership, or even hostility toward ESM. But, as we’ll see, all of these rules are here for a good reason, which will make it very difficult to break these rules in the future.</p><p id="1121">I’ll conclude with three guidelines for library authors to follow:</p><ul><li id="fc38">Provide a CJS version of your library</li><li id="6dae">Provide a thin ESM wrapper for your CJS</li><li id="4ca9">Add an <code>exports</code> map to your <code>package.json</code></li></ul><p id="7269"><strong>It’s all gonna be OK.</strong></p><p id="2f7d"><a href="https://www.reddit.com/r/node/comments/i4jwb7/node_modules_at_war_why_commonjs_and_es_modules/" target="_blank" rel="noopener">Discuss on Reddit</a><br><a href="https://news.ycombinator.com/item?id=24067748" target="_blank" rel="noopener">Discuss on Hacker News</a></p><p id="8d2e">Since the dawn of Node, Node modules were written as CommonJS modules. We use <code>require()</code> to import them. When implementing a module for other people to use, we can define <code>exports</code>, either “named exports” by setting <code>module.exports.foo = 'bar'</code> or a “default export” by setting <code>module.exports = 'baz'</code>.</p><p id="a362">Here’s a CJS example using <strong>named exports</strong>, where <code>util.cjs</code> has an export named <code>sum</code>.</p><pre><span id="36d6">// @filename: util.cjs<br>module.exports.sum = (x, y) =&gt; x + y;</span><span id="b41b">// @filename: main.cjs<br>const {sum} = require('./util.cjs');<br>console.log(sum(2, 4));</span></pre><p id="d017">Here’s a CJS example where <code>util.cjs</code> sets a <strong>default export</strong>. The default export has no name; modules using <code>require()</code> define their own name.</p><pre><span id="6577">// @filename: util.cjs<br>module.exports = (x, y) =&gt; x + y;</span><span id="eeec">// @filename: main.cjs<br>const whateverWeWant = require('./util.cjs');<br>console.log(whateverWeWant(2, 4));</span></pre><p id="b405">In ESM scripts, <code>import</code> and <code>export</code> are part of the language; like CJS, they have two different syntaxes for named exports and the default export.</p><p id="e73c">Here’s an ESM example with <strong>named exports</strong>, where <code>util.mjs</code> has an export named <code>sum</code>.</p><pre><span id="4112">// @filename: util.mjs<br>export const sum = (x, y) =&gt; x + y;</span><span id="3c49">// @filename: main.mjs<br>import {sum} from './util.mjs'<br>console.log(sum(2, 4));</span></pre><p id="d0ee">Here’s an ESM example where <code>util.mjs</code> sets a <strong>default export</strong>. Just like in CJS, the default export has no name, but the module using <code>import</code> defines its own name.</p><pre><span id="ab2d">// @filename: util.mjs<br>export default (x, y) =&gt; x + y;</span><span id="0916">// @filename: main.mjs<br>import whateverWeWant from './util.mjs'<br>console.log(whateverWeWant(2, 4));</span></pre><p id="bfb3"><strong>In CommonJS, </strong><code><strong>require()</strong></code><strong> is synchronous</strong>; it doesn't return a promise or call a callback. <code>require()</code> reads from the disk (or perhaps even from the network), and then immediately runs the script, which may itself do I/O or other side effects, and then returns whatever values were set on <code>module.exports</code>.</p><p id="5eb2"><strong>In ESM, the module loader runs in asynchronous phases.</strong> In the first phase, it parses the script to detect calls to <code>import</code> and <code>export</code> without running the imported script. In the parsing phase, the ESM loader can immediately detect a typo in named imports and throw an exception without ever actually running the dependency code.</p><p id="d291">The ESM module loader then asynchronously downloads and parses any scripts that you imported, and then scripts that your scripts imported, building out a “module graph” of dependencies, until eventually it finds a script that doesn’t import anything. Finally, that script is allowed to execute, and then scripts that depend on that are allowed to run, and so on.</p><p id="8815">All of the “sibling” scripts in the ES module graph download in parallel, but they execute in order, guaranteed by the loader specification.</p><p id="6f7b">ESM changes a bunch of stuff in JavaScript. ESM scripts use Strict Mode by default (<code>use strict</code>), their <code>this</code> doesn't refer to the global object, scoping works differently, etc.</p><p id="8a61">This is why, even in browsers, <code>&lt;script&gt;</code> tags are non-ESM by default; you have to add a <code>type="module"</code> attribute to opt into ESM mode.</p><p id="e76a">Switching the default from CJS to ESM would be a big break in backwards compatibility. (<a href="https://deno.land/" target="_blank" rel="noopener">Deno</a>, the hot new alternative to Node, makes ESM the default, but as a result, its ecosystem is starting from scratch.)</p><p id="03c6">The simplest reason that CJS can’t <code>require()</code> ESM is that ESM can do top-level <code>await</code>, but CJS scripts can't.</p><p id="a892"><a href="https://v8.dev/features/top-level-await" target="_blank" rel="noopener">Top-level </a><code><a href="https://v8.dev/features/top-level-await" target="_blank" rel="noopener">await</a></code> lets us use the <code>await</code> keyword outside of an <code><a href="https://developer.mozilla.org/en-US/docs/Learn/JavaScript/Asynchronous/Async_await" target="_blank" rel="noopener">async</a></code><a href="https://developer.mozilla.org/en-US/docs/Learn/JavaScript/Asynchronous/Async_await" target="_blank" rel="noopener"> function</a>, at the “top level.”</p><p id="1b27">ESM’s multi-phase loader makes it possible for ESM to implement top-level await without making it a “footgun.” Quoting from the <a href="https://v8.dev/features/top-level-await" target="_blank" rel="noopener">V8 team’s blog post</a>:</p><blockquote><p id="368f">Perhaps you have seen the <a href="https://gist.github.com/Rich-Harris/0b6f317657f5167663b493c722647221" target="_blank" rel="noopener">infamous gist</a> by <a href="https://twitter.com/Rich_Harris" target="_blank" rel="noopener">Rich Harris</a> which initially outlined a number of concerns about top-level <code>await</code> and urged the JavaScript language not to implement the feature. Some specific concerns were:</p><p id="d5f0">• Top-level <code>await</code> could block execution.<br>• Top-level <code>await</code> could block fetching resources.<br>• There would be no clear interop story for CommonJS modules.</p><p id="9ad3">The stage 3 version of the proposal directly addresses these issues:</p><p id="81b7">• As siblings are able to execute, there is no definitive blocking.<br>• Top-level <code>await</code> occurs during the execution phase of the module graph. At this point all resources have already been fetched and linked. There is no risk of blocking fetching resources.<br>• Top-level <code>await</code> is limited to [ESM] modules. There is explicitly no support for scripts or for CommonJS modules.</p></blockquote><p id="a0c0">(Rich now approves of the current top-level <code>await</code> implementation.)</p><p id="8cd5">Since CJS doesn’t support top-level <code>await</code>, it’s not even possible to <em>transpile</em> ESM top-level <code>await</code> into CJS. How would you rewrite this code in CJS?</p><pre><span id="1969">export const foo = await fetch('./data.json');</span></pre><p id="1c9b">It’s frustrating, because the vast majority of ESM scripts don’t use top-level <code>await</code>, but, as one commenter wrote in that thread, “I don’t think designing a system with the blanket assumption that some feature just won’t get used is a viable path.”</p><p id="445d"><a href="https://github.com/nodejs/modules/issues/454" target="_blank" rel="noopener">There’s an active debate on how to </a><code><a href="https://github.com/nodejs/modules/issues/454" target="_blank" rel="noopener">require()</a></code><a href="https://github.com/nodejs/modules/issues/454" target="_blank" rel="noopener"> ESM in this thread.</a> (Please read the whole thread and the linked discussions before commenting. If you dive in, you’ll find that top-level <code>await</code> isn’t even the only problematic case… what do you think happens if you synchronously <code>require</code> ESM which can asynchronously <code>import</code> some CJS which can synchronously <code>require</code> some ESM? What you get is a sync/async zebra stripe of <em>death</em>, that’s what! Top-level <code>await</code> is just the last nail in the coffin, and the easiest to explain.)</p><p id="d83f">Reviewing that conversation, it doesn’t look like we’re going to be able to <code>require()</code> ESM any time soon!</p><h2 id="3acf">CJS Can import() ESM, but It’s Not Great</h2><p id="b19b">For now, if you’re writing CJS and you want to <code>import</code> an ESM script, you’ll have to use asynchronous dynamic <code>import()</code>.</p><pre><span id="69f7">(async () =&gt; {<br>    const {foo} = await import('./foo.mjs');<br>})();</span></pre><p id="dcae">It’s… fine, I guess, as long as you don’t have any <code>exports</code>. If you do need to do some <code>exports</code>, you’ll have to export a Promise instead, which may be <a href="https://journal.stuffwithstuff.com/2015/02/01/what-color-is-your-function/" target="_blank" rel="noopener">a huge inconvenience to your users</a>:</p><pre><span id="ad31">module.exports.foo = (async () =&gt; {<br>    const {foo} = await import('./foo.mjs');<br>    return foo;<br>})();</span></pre><p id="94bc">You can do this:</p><pre><span id="6859">import _ from './lodash.cjs'</span></pre><p id="3b2c">But you can’t do this:</p><pre><span id="c06a">import {shuffle} from './lodash.cjs'</span></pre><p id="7e7b">That’s because CJS scripts compute their named exports as they <em>execute</em>, whereas ESM’s named exports must be computed during the <em>parsing</em> phase.</p><p id="2899">Fortunately for us, there’s a workaround! The workaround is annoying, but totally doable. We just have to import CJS scripts like this:</p><pre><span id="bccb">import _ from './lodash.cjs';<br>const {shuffle} = _;</span></pre><p id="7e2f">There are no real downsides to this, and ESM-aware CJS libraries can even provide their own ESM wrappers that encapsulate this boilerplate for us.</p><p id="7fd3">This is totally fine! I just… wish it were better.</p><h2 id="6069">Out-of-order execution would work, but it might be even worse</h2><p id="6455">A number of people have proposed executing CJS imports before ESM imports, out of order. That way, the CJS named exports could be computed at the same time as ESM named exports.</p><p id="ab6c">But that would <a href="https://github.com/nodejs/modules/issues/81#issuecomment-391348241" target="_blank" rel="noopener">create a new problem</a>.</p><pre><span id="34c8">import {liquor} from 'liquor';<br>import {beer} from 'beer';</span></pre><p id="69a1">If <code>liquor</code> and <code>beer</code> are both initially CJS, changing <code>liquor</code> from CJS to ESM would change the ordering from <code>liquor, beer</code> to <code>beer, liquor</code> , which would be nauseatingly problematic if <code>beer</code> relied on something from <code>liquor</code> being executed first.</p><p id="b454"><a href="https://github.com/nodejs/modules/issues/509" target="_blank" rel="noopener">Out-of-order execution is still under debate</a>, though the conversation seems to have mostly fizzled out a few weeks ago.</p><h2 id="59b5">Dynamic Modules could save us, but their star is poisoned</h2><p id="79d1">There’s an alternative proposal that doesn’t require out-of-order execution or wrapper scripts, called <a href="https://github.com/nodejs/dynamic-modules" target="_blank" rel="noopener">D…</a></p></div></div></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://redfin.engineering/node-modules-at-war-why-commonjs-and-es-modules-cant-get-along-9617135eeca1">https://redfin.engineering/node-modules-at-war-why-commonjs-and-es-modules-cant-get-along-9617135eeca1</a></em></p>]]>
            </description>
            <link>https://redfin.engineering/node-modules-at-war-why-commonjs-and-es-modules-cant-get-along-9617135eeca1</link>
            <guid isPermaLink="false">hacker-news-small-sites-24067748</guid>
            <pubDate>Thu, 06 Aug 2020 03:01:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Is insurance more expensive in Black neighborhoods?]]>
            </title>
            <description>
<![CDATA[
Score 27 | Comments 45 (<a href="https://news.ycombinator.com/item?id=24067408">thread link</a>) | @ddispaltro
<br/>
August 5, 2020 | https://www.goodcover.com/blog/is-insurance-more-expensive-in-black-neighborhoods/ | <a href="https://web.archive.org/web/*/https://www.goodcover.com/blog/is-insurance-more-expensive-in-black-neighborhoods/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p><em>Black neighborhoods pay 20% more in renters insurance.</em></p><p>With the recent Black Lives Matter protests much of society has been re-examining explicit and implicit sources of discrimination against Blacks in America. What are the ways our society and economy has set up harmful policies towards Black citizens?</p><p>Housing and its associated cost has historically played a critical role in institutionalizing racism and segregation. Even insurance companies have historically discriminated against Blacks through processes like <a href="https://en.wikipedia.org/wiki/Redlining">redlining</a> where by they refused to write policies in certain neighborhoods, thus making housing more expensive or challenging to acquire.</p><p>As an insurance provider ourselves, we wanted to examine data to see how race impacts the price of insurance. We asked: is renters insurance more expensive if you live in a predominantly Black neighborhood than if you live in a predominantly white one?</p><p>We analyzed public data from the California Department of Insurance on how much companies charge for renters insurance in cities across the state. We also analyzed our own pricing for those locations.</p><p>We found the higher the percentage of Blacks living in a zip code or city, the higher the price of insurance on average. Across the industry renters insurance annual premiums were about 20% higher in predominantly Black neighborhoods than predominantly white ones. While we did not find such a correlation in our own prices, we recognize there is a lot of work left to do.</p><h3 id="the-data-and-methodology">The data and methodology</h3><p>Before diving into the results, it’s worth spending a moment on methodology. The <a href="http://www.insurance.ca.gov/">California Department of Insurance</a> requires all insurance companies operating in the state to publicly file the rates they would charge for a set coverage level in a given area. We analyzed this public data using defined coverage limits ($100k liability, $30k personal property, $500 deductible) for the top <a href="https://www.iii.org/table-archive/23446">10 most popular companies</a> in the state and analyzed how much they charged in different zip codes and cities for renters insurance. Using US census data, we’re able to calculate the percentage of the population in those areas that is Black, and see how that correlates with prices.</p><p>This analysis is focused on showing the difference in insurance prices for the same kind of housing that’s in a mostly Black neighborhood versus a mostly white one. Housing discrimination spans all races and ethnicities across our country, however for this research our primary focus is on Black communities in the state of California. </p><p>In this analysis we haven’t identified any causal factors; It’s meant more as a jumping off point for further analysis examining potential causal factors which can range from discriminatory practices based on the racial composition of a neighborhood (i.e. redlining), to other factors that impact pricing like proximity to a fire station.</p><p>So, there’s definitely more work to be done – but we thought it’s important to make a best effort with the messy data we have to start the discussion.</p><h3 id="cost-of-renters-insurance-in-california">Cost of renters insurance in California</h3><p>To begin, let’s look at the average price of renters insurance in California and how much it varies according to the percentage of the population in a zip code that is Black. For context, in California 5.9% of the population is Black, and across the state the average renters insurance policy costs $183 per year.</p><figure><img src="https://goodcover.ghost.io/content/images/2020/08/bar-chart.png" alt="" srcset="https://goodcover.ghost.io/content/images/size/w600/2020/08/bar-chart.png 600w, https://goodcover.ghost.io/content/images/size/w1000/2020/08/bar-chart.png 1000w, https://goodcover.ghost.io/content/images/2020/08/bar-chart.png 1200w" sizes="(min-width: 720px) 720px"></figure><p>As shown above, companies charge more for renters insurance in zip codes where there’s a higher percentage of Black residents. If your zip code has more than 20% Black population, the expected annual price for renters insurance would be $210, which is around 20% more expensive than in zip codes where less than one percent of the population is Black.</p><p>Next, let’s turn our attention to the average price of renters insurance across various cities in California and how it varies by the percentage of residents who are Black. The chart below ranks cities in California from most to least expensive annual policies and also shows the percentage of Black residents in that city. (One column represents the average price for the top 10 insurance providers, and next column are average Goodcover prices for those cities. Only cities with over 100k residents where the CA Department of Insurance publishes rates are included.)</p><figure><img src="https://goodcover.ghost.io/content/images/2020/08/table.png" alt="" srcset="https://goodcover.ghost.io/content/images/size/w600/2020/08/table.png 600w, https://goodcover.ghost.io/content/images/size/w1000/2020/08/table.png 1000w, https://goodcover.ghost.io/content/images/2020/08/table.png 1200w" sizes="(min-width: 720px) 720px"></figure><p>Across California, renters insurance is most expensive in Berkeley, followed by Oakland and Los Angeles. Each of the top five cities with most expensive renters insurance policies in California have a substantially higher percentage of Black residents than the state average of 5.9%.</p><p>Is there any correlation between the percentage of Black residents in a city and companies charging more for renters insurance?</p><p>Let’s see, the following chart plots renters insurance prices versus percent of population that is Black from the same list of cities as above.</p><figure><img src="https://goodcover.ghost.io/content/images/2020/08/scatterplot-wm-1.png" alt="" srcset="https://goodcover.ghost.io/content/images/size/w600/2020/08/scatterplot-wm-1.png 600w, https://goodcover.ghost.io/content/images/size/w1000/2020/08/scatterplot-wm-1.png 1000w, https://goodcover.ghost.io/content/images/2020/08/scatterplot-wm-1.png 1200w" sizes="(min-width: 720px) 720px"></figure><p>The chart above shows some correlation between higher prices for renters insurance and the percentage of Blacks living in the city. Virtually every city with a higher rate of Black residents have insurance policies that cost more than the state average.</p><h3 id="examining-our-own-rates">Examining our own rates</h3><p>Our analysis would not be complete if we didn’t also specifically analyze our own rates in the same way. So we looked at how Goodcover would rate for the same policy and location compared to the top 10 insurance companies in the state using the government pricing data. We found a far lower correlation as shown below.</p><figure><img src="https://goodcover.ghost.io/content/images/2020/08/scatterplot-with-gc-wm-1.png" alt="" srcset="https://goodcover.ghost.io/content/images/size/w600/2020/08/scatterplot-with-gc-wm-1.png 600w, https://goodcover.ghost.io/content/images/size/w1000/2020/08/scatterplot-with-gc-wm-1.png 1000w, https://goodcover.ghost.io/content/images/2020/08/scatterplot-with-gc-wm-1.png 1200w" sizes="(min-width: 720px) 720px"></figure><p>Furthermore, doing the same population segment analysis as earlier, our average annual pricing was $91, $91, $94, $92, for zip codes with percentage of Black population of &lt;1%, 1-5%, 5-20%, and 20%+ respectively – a different trend than the increase of price seen for the top 10 companies which resulted in a 20% higher price for areas with the largest Black population. </p><p>Goodcover’s rates were computed and filed with the State of California in 2019, so we were able to evaluate risk as we see it now, rather than inheriting old rating structures and any potential biases. This modern structure has also allowed us to offer significantly better pricing making financial security more accessible and affordable for more people. </p><p>We’re not sure of the causal factors that make renters insurance more expensive for Black neighborhoods. All we can be sure of is that in our own analysis of risk and causal factors of loss we don’t have an answer for why this correlation would exist.</p><h3 id="closing-thoughts">Closing thoughts</h3><p>In this analysis, we have shown that there’s a wide variation in how much renters insurance costs across California and that prices tend to be significantly higher in predominantly Black neighborhoods.</p><p>However we’ve also shown that from our own analysis of risk, which resulted in Goodcover’s rating, there is no readily evident reason why this correlation exists. Further study is warranted to understand why this is so.</p><p>At Goodcover, we believe it is our responsibility both as a company and as an industry to understand and address our systemic biases. This begins internally – Goodcover is committed to diversity, equity and inclusion in our hiring practices, service and pricing. And then there’s more to be done in our industry – we must further examine rating for bias, increase use of digital servicing to remove biases such as <a href="https://journals.sagepub.com/doi/10.1177/1078087405281064">linguistic profiling</a>, reduce or eliminate installment fees that penalize policyholders living paycheck to paycheck, and simply lower the cost of renters insurance to make it more accessible for the 56% of Californians who still don’t have it.</p><p>Eliminating pricing disparities because of the composition of a community is attainable, and a right. Our industry needs to keep vigilant in rexaming our processes so we banish discrimination from the ways we serve our policyholders and the public.</p></div></div></div>]]>
            </description>
            <link>https://www.goodcover.com/blog/is-insurance-more-expensive-in-black-neighborhoods/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24067408</guid>
            <pubDate>Thu, 06 Aug 2020 01:44:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[$250k books sold, to save lives]]>
            </title>
            <description>
<![CDATA[
Score 112 | Comments 52 (<a href="https://news.ycombinator.com/item?id=24067365">thread link</a>) | @gregalbritton
<br/>
August 5, 2020 | https://sive.rs/250k | <a href="https://web.archive.org/web/*/https://sive.rs/250k">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">

<article>
<header>


<small>2020-08-06</small>
</header>

<p>
	Six weeks ago I emailed my <a href="https://sive.rs/list">private email list</a> with a secret link to buy my new books.
</p><p>
	They’re not even officially released yet, but they’ve already sold over $250,000.
</p><p>
	I made 5000 limited edition hardcover copies of each, but those have sold out now.
</p><p>
<strong>
	I’ll admit, it made me ridiculously happy to make $250,000.
</strong>
	I was expecting way less than that, so it was a big surprise.
	I had a spring in my step for days.
</p><p>
	Then I thought about what to do with the money.
	There’s nothing I want to buy.
	Should I put it in an investment account?
	Eh.
	For what purpose?
	I <a href="https://sive.rs/full">don’t want more money</a>.
</p><p>
	So, I decided to donate it to charity.
	Which charity?
	I want to save the most lives.
	So I let <a href="https://www.givewell.org/">GiveWell</a> decide.
</p><p>
<strong>
	Yesterday I wired the entire $250,000 to the <a href="https://www.againstmalaria.com/">Against Malaria Foundation</a>.
</strong>
	That will buy 125,000 malaria nets, protecting ~225,000 people, averting ~65,000 cases of malaria, preventing ~125 deaths.
</p><p>
	Yeah.
	That’s <a href="https://sive.rs/n">worth doing</a>.
</p><p>
	Afterwards, a friend reminded me that I had just repeated my “<a href="https://sive.rs/232">232 sand dollars</a>” story, so <a href="https://sive.rs/232">go read that</a> if interested.
</p><p>
	You can buy the books now, directly from me.
	They won’t be available anywhere else for a couple more months.
</p>
<ul><li>
	“<strong><a href="https://sive.rs/m">Your Music and People</a></strong>” is a philosophy of getting your work to the world by being creative, considerate, resourceful, and connected.
</li><li>
	“<strong><a href="https://sive.rs/n">Hell Yeah or No</a></strong>” is a collection of thoughts around what’s worth doing, fixing faulty thinking, and making things happen.
</li></ul>
<img src="https://sive.rs/images/DerekSivers-cover-YourMusicAndPeople-400x492.png" alt="Your Music and People">
<br>
<img src="https://sive.rs/images/DerekSivers-cover-HellYeahOrNo-400x492.png" alt="Hell Yeah or No">


</article>



</div></div>]]>
            </description>
            <link>https://sive.rs/250k</link>
            <guid isPermaLink="false">hacker-news-small-sites-24067365</guid>
            <pubDate>Thu, 06 Aug 2020 01:33:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Do Not Trust Google]]>
            </title>
            <description>
<![CDATA[
Score 61 | Comments 38 (<a href="https://news.ycombinator.com/item?id=24067162">thread link</a>) | @DlSGUSTING
<br/>
August 5, 2020 | https://lukeboyle.com/blog-posts/2020/08/do-not-trust-google | <a href="https://web.archive.org/web/*/https://lukeboyle.com/blog-posts/2020/08/do-not-trust-google">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="___gatsby"><div tabindex="-1" id="gatsby-focus-wrapper"><div><main><div><article><div><p>Posted by <!-- -->Luke Boyle<!-- --> on the<!-- --> <time datetime="Sat Aug 01 2020 00:00:00 GMT+0000 (Coordinated Universal Time)">1st of August, 2020</time></p><p><img src="https://lukeboyle.com/static/google-fasc-6d23fd163ac10360abb4467ecdb9645a.jpg" alt="" data-identifier="google-fasc"></p><p>I realise that this is one of the most well-explored topics on the privacy-conscious edges of the internet, but seriously... Do not trust Google. Facebook seems to be our current punching bag of choice because of their supposed ability to manipulate political opinion, but in my opinion Google is a much more insidious company with far greater potential for abuse. Google is the <a href="https://www.investopedia.com/news/facebook-google-digital-ad-market-share-drops-amazon-climbs/" target="_blank" rel="noreferrer noopener">largest advertising platform</a> by a significant margin (accounting for 36.3% of advertising in the U.S. with Facebook trailing at 19.3%). At the end of the day, if you delete your Facebook account, what are you really missing out on?</p><p>Google (or more specifically Alphabet Inc.) owns the largest search engine (Google.com), the largest video streaming platform (Youtube), and the most-used smartphone operating system (Android). You might ask, "What's wrong with that? Sounds like they're just very successful at what they do". Well, let's break down those three markets (Search, Streaming, Mobile).</p><p><img src="https://lukeboyle.com/static/do-be-evil-6ba993531a7046106f481b038b7ed98b.jpg" alt="The classic Google slogan &quot;Don't be evil&quot;, except the end of the &quot;don't&quot; is crossed out so it says &quot;Do be evil&quot;" data-identifier="do-be-evil"></p><h2>Search</h2><p>Google's estimated market share for search traffic globally is 92.16% <a href="https://gs.statcounter.com/search-engine-market-share" target="_blank" rel="noreferrer noopener">source</a>. As people increasingly are using search to navigate the web (as opposed to typing a URL into the address bar), this traffic increases, those people see more ads, Google makes more money. Google then uses this money to purchase exclusivity agreements with the likes of Apple (just two years ago it was announce that Google would be paying $12 billion US to Apple to remain the default search engine on Safari in 2019 <a href="https://fortune.com/2018/09/29/google-apple-safari-search-engine/" target="_blank" rel="noreferrer noopener">source</a> at a cost of roughly $10 per user).</p><h3>How does Google abuse Search?</h3><p>If you ask the average user how Google search works, they'd probably say "it just searches for your search term across the web", but what they probably don't know is that is just the tip of the iceberg. Other dimensions of search include:</p><ul><li>what kind of users go to that websites (and does the user searching fit that profile)?</li><li>how much traffic does the website get?</li><li>how relevant the content is to the search term (SEO magic)?</li><li>and, most importantly, does this website fit an acceptable narrative?</li></ul><p>There's certainly an argument to be made for suppressing some search results, such as pro-authoritarian sites (e.g. communist or fascist), extremely fringe conspiracy, illegal pornography, or bomb-making instructions. Advertisers probably don't want their ads next to those results. Rightly or wrongly, Google is already suppressing content from such websites (though, they're probably still indexing them).</p><p>If Google can suppress fascist content from sites like Stormfront (prominent white-supremacy forum), then who is to say which content they can or cannot suppress? Breitbart is a well-known right wing news site that has had their content <a href="https://www.breitbart.com/tech/2020/07/28/election-interference-google-purges-breitbart-from-search-results/" target="_blank" rel="noreferrer noopener">almost entirely purged</a> from Google search results (as evidenced by the "search engine visibility" chart below).</p><p><img src="https://lukeboyle.com/static/breitbart-visibility-index-7479c89645b960fee2d841dfa4f1574d.jpg" alt="Search engine visibility index for Breitbart.com shows significant increase in visibility leading up to the 2016 presidential election with a sharp drop in mid 2017" data-identifier="breitbart-visibility-index"></p><p>You don't have to agree with them politically to see that Google is applying different standards to conservative content than to more liberal content. I don't visit Breitbart, I don't read their articles, and frankly I don't give a shit what they have to say, but I believe in a free and open internet. If you believe in a free and open internet then you have to agree this is wrong. During the cold war, anyone who didn't follow the extreme protectionist beliefs of the time <a href="https://www.history.com/topics/cold-war/red-scare" target="_blank" rel="noreferrer noopener">were shouted down as communists</a> (Even Martin Luther King Jr. was dismissed as a communist by J. Edgar Hoover). This same thing is happening now, but the buzz word is different. The new weaponised word is "Nazi". If time had elapsed differently, I have no doubt that it would be left-wing websites suppressed in search results, and that still wouldn't be okay.</p><p>There's plenty of evidence to suggest that Google is manually making these decisions to block conservative websites, however, Alphabet CEO Sundar Pichai denied that they manually censor websites at the recent <a href="https://www.theguardian.com/technology/2020/jul/29/tech-hearings-facebook-mark-zuckerberg-amazon-jeff-bezos-apple-tim-cook-google-sundar-pichai-congress" target="_blank" rel="noreferrer noopener">Congressional antitrust hearing</a> except for in cases where there are legal requirements or copyright issues. I don't buy that, personally.</p><h2>Streaming</h2><p>When YouTube was founded it was facing severe scaling problems (because video processing and streaming is extremely expensive). Fortunately for them, Google saw potential in the platform and purchased the company for $1.65bn in Google stock, and their money issues were over. Google was throwing money into scaling the platform, and it was experiencing great growth. This success turned out to be a major problem for the YouTube, because, from the time it was purchased it has been making a loss. In recent years, YouTube has become profitable, however, without the bottomless pockets of Google behind it, they never would have been able to accomplish this. What incentive could Google have to take losses year after year on YouTube? Well, it turns out user data is particularly delicious. Mastercard's CEO has infamously said <a href="https://www.cnbc.com/2017/10/24/mastercard-boss-just-said-data-is-the-new-oil.html" target="_blank" rel="noreferrer noopener">"data is the new oil"</a>. I personally can't wait for Facebook, Amazon, and Google to become para-military organisations in the up-coming data wars.</p><p>YouTube has essentially bullied their way into market dominance using Google's bottomless pit of money. This is problematic because it allows failing companies to cheat death. Just like a bottom-feeding fish,latching onto a whale shark and hitching a ride. As I mentioned before, video streaming is extremely expensive, so it makes sense that great cloud infrastructure is a prerequisite to success. Well, big surprise, Google offers world-class commercial cloud infrastructure with Google Cloud Platform (GCP)! Do you suppose YouTube is paying full price for their infra?</p><p><img src="https://lukeboyle.com/static/google-shark-ad4f1bd39e618a72413dc9456fb01ebc.jpg" alt="A whale shark with small fish adhered to the top of it. YouTube, Google Play, and Google Plus logos are superimposed on the small fish heads" data-identifier="google-shark"></p><p>So, when you see a headline that says "<a href="https://bgr.com/2020/07/30/google-one-free-phone-backup-ios-android/" target="_blank" rel="noreferrer noopener">Stop paying for iCloud – Google One will now back up your iPhone for free</a>". Before obeying the shill who wrote it, you should ask yourself, "How can a company afford to give away so much storage space for free?". Well, they can't. Google simply obscures their losses with the immense revenue from Google Ads in the profit/loss statement at the end of each quarter. For more reading about this topic, Tim Bray has a fantastic article called <a href="https://www.tbray.org/ongoing/When/202x/2020/06/25/Break-Up-Google" target="_blank" rel="noreferrer noopener">"Break up Google"</a>.</p><h2>Mobile</h2><p>This article is already becoming too long, so I'm just going to cover mobile quickly. As Tim Bray mentions in the article above, Android isn't really a business. The only real non-ad revenue they have is from the commission they get from app purchases and licensing fees from OEMs (e.g. Samsung, Huawei, LG). How, then, are they able to sustain hundreds of highly paid engineers and all the other non-technical staff required to support the system?</p><p><img src="https://lukeboyle.com/static/android-ios-market-share-aa0b256bae300e426ecb38c8ef842165.jpg" alt="A map of the world with Android vs iOS market share. iOS is most dominant in first-world countries, whereas Android dominates emerging nations" data-identifier="android-ios-market-share"></p><p>Above is a map of Android vs iOS market shares. You can see that iOS pretty much only has the dominant market share in first world countries (like USA, Canada, Australia, UK, Japan). Most of the emerging countries in the world are strongly in favour of Android because, unlike Apple, the OS is not restricted to a particular device. So, countries like India (where the number of smart-phone users has increased sharply from 199 million in 2015 to 401 million in 2020 <a href="https://www.statista.com/statistics/467163/forecast-of-smartphone-users-in-india/" target="_blank" rel="noreferrer noopener">source</a>) that mostly purchase low-cost phones (e.g. Huawei, Xiaomi, Oppo). Emerging markets are extremely important to companies like Google partly because these countries are easier to exploit because they don't have strong legislation to protect users from predatory advertising, anticompetitive tactics, or data privacy. This is why I speculate that Mastercard is scrambling to <a href="https://www.forbes.com/sites/tomgroenfeldt/2020/05/06/financial-inclusion-helps-refugees-move-from-aid-recipients-to-earners-and-tax-payers" target="_blank" rel="noreferrer noopener">connect refugees to the global payment network</a> (Remember that quote from the Mastercard CEO: "Data is the new oil") and, indeed, why Mastercard <a href="https://www.jihadwatch.org/2018/08/patreon-and-mastercard-ban-robert-spencer-without-explanation" target="_blank" rel="noreferrer noopener">forced Patreon to ban Robert Spencer for his anti-refugee sentiment</a>.</p><p>Again, regardless of whether you agree with someone's political leaning or rhetoric, I shouldn't have to explain why it's ludicrous for people to believe that faceless, soulless corporations such as MasterCard or Google give two fucks about moral righteousness when their only servant is a number ticker on the Nasdaq website.</p><h2>Closing thoughts</h2><p>So, after reading all of that, I have to ask:</p><p>Why don't you route all of your web traffic through Google Servers?</p><p><img src="data:image/jpeg;base64,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" alt="Google DNS logo" data-identifier="google-dns"></p><p>To be clear, I'm not accusing Google of storing DNS logs or associating that with specific users (they claim that they don't in their terms of service), however, I think it's unreasonable to think that they wouldn't be capable of that. I also wouldn't put it past them to lie in terms of service considering their recent run-ins with the law (<a href="https://www.cbsnews.com/news/google-eu-fines-google-1-7-billion-for-blocking-advertising-rivals/" target="_blank" rel="noreferrer noopener">$1.7bn fine for anti-competitive behaviour</a>, <a href="https://www.nytimes.com/2019/09/04/technology/google-youtube-fine-ftc.html" target="_blank" rel="noreferrer noopener">$170m for violating children's privacy on YouTube</a>, <a href="https://www.theverge.com/2019/1/21/18191591/google-gdpr-fine-50-million-euros-data-consent-cnil" target="_blank" rel="noreferrer noopener">50 million euro fine for GDPR violations</a>).</p><p>$2bn doesn't matter to Google. It's a drop in the bucket, especially considering they would probably be able to freely harvest user data for months or even years before they're caught and slapped on the wrist. If a single user's search data is worth upwards of $10 a year (see the Safari Google default search engine deal) for Google, then the complete logs of their browsing history would be quite juicy indeed.</p><p>Okay, so that's verging on conspiracy theory I suppose. Maybe Google DNS will remain clean. How about you get a Google® Nest™ WiFi mesh router and let them inspect all of your web traffic that way?</p><p><img src="https://lukeboyle.com/static/nest-c6cc34d5b4043b24d7c12a3223cc9ae4.jpg" alt="Google Nest Wifi Router product photo" data-identifier="nest"></p><p>Or perhaps you want to buy the new Pixel and give them advanced analytics about how you use your phone (<a href="https://www.searchenginejournal.com/google-privacy-lawsuit-android-apps/374952/" target="_blank" rel="noreferrer noopener">privacy class action lawsuit</a>), everywhere you go (Location History), how much physical activity you do (Google Fit), every article/video you engage with (Chrome), everything you buy (Google Pay - and incidentally, how much disposable income you have, so they can better target more relevant ads to you). All of these "services" are simply a ruse so that Google can build an extremely accurate profile about the type of consumer you are and target you with more advertising to turn you into a soulless consumer.</p><p>I don't want these people to also be the arbiters of what content I should or should not be able to see online.</p><h2>Actual closing thoughts</h2><p>Well that was pretty depressing. So, how can you reclaim a shred of your privacy?</p><h3>Search</h3><p>There's a swathe of …</p></div></article></div></main></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://lukeboyle.com/blog-posts/2020/08/do-not-trust-google">https://lukeboyle.com/blog-posts/2020/08/do-not-trust-google</a></em></p>]]>
            </description>
            <link>https://lukeboyle.com/blog-posts/2020/08/do-not-trust-google</link>
            <guid isPermaLink="false">hacker-news-small-sites-24067162</guid>
            <pubDate>Thu, 06 Aug 2020 00:49:46 GMT</pubDate>
        </item>
    </channel>
</rss>
