<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 20]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 20. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Tue, 08 Dec 2020 04:33:50 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-20.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Tue, 08 Dec 2020 04:33:50 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[An Airbnb Thanksgiving Burglary]]>
            </title>
            <description>
<![CDATA[
Score 26 | Comments 33 (<a href="https://news.ycombinator.com/item?id=25321770">thread link</a>) | @dsr12
<br/>
December 5, 2020 | https://ternaus.blog/incident/2020/12/01/Airbnb-Thanksgiving-Burglary.html | <a href="https://web.archive.org/web/*/https://ternaus.blog/incident/2020/12/01/Airbnb-Thanksgiving-Burglary.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section itemprop="text">
        
        <p><img src="https://habrastorage.org/webt/mm/dk/wp/mmdkwpapgwobqrzcauk213qoglk.png" alt=""></p>



<p>I used <a href="https://www.airbnb.com/">Airbnb</a> for years in Russia, Germany, and the United States. All the time, the experience was great. At some point, I read a <a href="https://amzn.to/3o9JywH">book about Airbnb</a> to understand the company better.</p>

<p>For Thanksgiving week (November 21-29), five of my friends and I rented a house in Las Vegas.</p>

<p>The total price for nine days: <strong>$2543</strong>.</p>

<p>Previously people went to Vegas to spend time in casinos or walk on The Strip. This year, <a href="https://www.worldometers.info/coronavirus/">the pandemic</a> made it impossible.</p>

<p>It was not a problem for us. We did not plan to socialize; we were going rock climbing.</p>

<p><a href="https://www.mountainproject.com/area/105731932/red-rock">Red Rocks</a>, located next to Vegas, is an excellent place for traditional, sport, bouldering, multi-pitch climbing.</p>

<p>The plan was for some people to take days off and climb every day, and for others to work three days remotely and join the gang during the rest.</p>

<h2 id="incident">Incident</h2>

<p>We moved in on Saturday night. The next morning, excited, we woke up at 6am, had breakfast, verified that we closed back and front doors and at 7am drove to the Red Rocks Park.</p>

<p>We had a fantastic day of climbing, but after the sunset, we went home to realize that the window in one of the rooms was open and some of our belongings had disappeared.</p>

<ul>
  <li>Three work Macbook Pro (I do not include the price, they are replaced by our employees for free)</li>
  <li>One personal <a href="https://amzn.to/33uWB3F">Macbook Pro</a> ($1550)</li>
  <li><a href="https://amzn.to/2JCZWqE">Oculus Quest 2</a>. I just bought it. Really cool. Wanted to share the experience. ($399)</li>
  <li><a href="https://amzn.to/2VnyrUt">GoPro Hero 6</a> ($194)</li>
  <li><a href="https://amzn.to/36oMMGz">Lenovo Tab 4, 10.1in Android Tablet</a> ($190)</li>
  <li><a href="https://amzn.to/3lms9is">Sony WH1000XM3 Noise Cancelling Headphones</a> ($348)</li>
  <li><a href="https://amzn.to/3qbPNSm">Bose Quietcontrol 30 Wireless Headphones</a> ($169)</li>
  <li><a href="https://amzn.to/3fVzzIh">Bose Noise Cancelling Wireless Bluetooth Headphones 700</a> ($339)</li>
  <li><a href="https://amzn.to/37qgsSN">BlueTooth ledger</a> ($118)</li>
  <li>Two backpacks. (2 x $100)</li>
</ul>

<p><img src="https://habrastorage.org/webt/kz/an/pd/kzanpdzeno_6rkrjjgbrhbscbbs.jpeg" alt=""></p>

<p>I called the host, told her about the situation. She shared a set of images from the cameras and the next day sent the whole video.</p>

<!-- Courtesy of embedresponsively.com //-->

<p>
    <iframe src="https://www.youtube-nocookie.com/embed/cg3Z9ZxtKGw" frameborder="0" webkitallowfullscreen="" mozallowfullscreen="" allowfullscreen=""></iframe>
  </p>

<p>We believe this is what happened:</p>

<p>At 8:55am, two hours after we left, someone</p>
<ol>
  <li>Openly came to the front door.</li>
  <li>Knocked in the door.</li>
  <li>Waved Lexus car keys at the camera. (We do not have Lexus.)</li>
  <li>Ringed the bell.</li>
  <li>Waited to verify that no one was at home.</li>
  <li>Got to the back of the house.</li>
  <li>Put gloves and balaclava on.</li>
  <li>Checked if the back door was open. It was not.</li>
  <li>Checked if he can open the window. And it was possible.
10 Moved the pool chair below the window.</li>
  <li>Got into the house.</li>
</ol>

<p>We called the police, and in two hours an officer came. He was polite and professional. He got the list of the stolen items, our version of the incident in the written form, and left.</p>

<p>I was curious, how did the burglar open the window? I checked, and the answer was simple: <strong>the lock on the window was not operational.</strong> No need to break anything, anyone can open the window from the outside!</p>

<p>If the weather was warmer, we would probably try to open windows the night we came. In that case we would discover the problem, but the night was cold and we did not touch the windows.</p>

<p>Till this moment, I was chill. Bad things happen. Burglars get into houses, and no one could be protected from it. We were safe in this incident, and from the money perspective, our loss was not huge.</p>

<p>But the fact that the lock on that window was not functioning is an issue (few more windows had the same problem). If the front door lock was broken it would be worse but even windows that could not be locked are sketchy.</p>

<p>In general, I prefer to blame myself for bad things that happen to me. This time I cannot figure out what was my fault. For sure, we could check all the locks in the house, but it is an overkill.</p>

<p>I am ok with making mistakes and paying for them. But this time, we paid for the host’s errors and Airbnb’s as a company.</p>

<ul>
  <li><strong>Host</strong>: the house was not ready for hosting the guests.</li>
  <li><strong>Airbnb</strong>: limitations of the onboarding policy. I believe there is a list of things that the house owner needs to mark to become a host, and either functioning window locks are not on the list, or it is not enforced.</li>
</ul>

<p>After we told the host about our discovery, she sent a person to lock all the windows completely. From now on, no one would be able to open them from inside or outside.</p>



<p>I wanted to reach out to Airbnb, tell them about the situation, and ask about the next steps.</p>

<p>Safety comes first. Hence I assumed that even if you are under stress and your brain is not functioning well, it is obvious how to contact the support team.</p>

<p>To my surprise, it is not the case.</p>

<p>I spent some time on the Airbnb website but could not figure out which phone number I should call.</p>

<p><strong>Message to AirBnb</strong>: It would be great if you simplify the design of the support page. When we talk about safety, it should be about efficiency and not about the visual appeal or cuteness level.</p>

<p>I would like it to be:</p>

<ul>
  <li>I open the Airbnb website =&gt; I see an obvious button/link to the support page.</li>
  <li>I open the support page =&gt; I see an obvious button/link to the hotline phone number.</li>
</ul>

<p>I posted the tweet about the incident and tagged Airbnb and Las Vegas police in it.</p>

<blockquote>— Vladimir Iglovikov (@viglovikov) <a href="https://twitter.com/viglovikov/status/1330741490759266304?ref_src=twsrc%5Etfw">November 23, 2020</a></blockquote>


<p>A miracle happened. Airbnb contacted me and asked for my email to identify the account and to get more details.</p>

<p>My guess is that the Marketing team at Airbnb has alarms that trigger when someone mentions the company on social media.</p>

<p>Finally, after two hours, we got into the conversation about the incident, but the path to get there was not obvious at all.</p>

<p>Imagine how many people got into trouble in similar situations and did not leverage this communication channel?</p>

<p>I got an email:</p>

<blockquote>
  <p>My name is XXX, from the Airbnb claims team.</p>

  <p>I am contacting you regarding the incident that occurred during your reservation with YYY.</p>

  <p>As my colleague informed you in the previous email, we are only able to offer up to $500 for any stolen property. In order to proceed with this refund, I will need the following:</p>

  <p>*Original purchase invoice for the stolen items.</p>

  <p>This is requested as “proof of ownership”, if you don’t have the original purchase invoice, a picture of you where the item can be seen will also be accepted as proof of ownership.</p>
</blockquote>

<p>All this story is not about money. But getting compensated for the host’s and Airbnb’s mistake with cash or AirBnB credits would be nice. It does not address the issue with window locks but sweetens the situation.</p>

<p>We interpreted the email as: “We will compensate up to $500 per stolen item”. Using the numbers from the invoices, it summed to $2600.</p>

<p>We collected invoices, sent them to Airbnb, and got the reply with words: “After additional review, I’m happy to report that we have just released a payout in the amount of $500 to your Airbnb account. You can confirm in your Airbnb Transaction History.”</p>

<p>The guess about up to $500 per item was overly optimistic.</p>

<p>After the end of the stay, I got a message from the host:</p>

<blockquote>
  <p>Hi Vladimir,</p>

  <p>Thank you again for choosing our home for your vacation stay.</p>

  <p>I hope the home met (and even surpassed) your expectations. It was a sincere pleasure hosting you, and I really hope to host you again in the near future. I would be truly grateful for a 5 star review of your stay when you have a spare moment and I would definitely do the same for you.</p>

  <p>Also, please in the private comments if there is something, the home or myself can approve of please let me know.</p>
</blockquote>

<p>I understand that this is a standard template, but under the circumstances, it sounds strange and
does not fit the story and overall experience.</p>

<p>I did not plan to share the actual address of the property. The harm to the renting business could be material. But after this text, I changed my mind. It does not look like the host plans to revise the house and look for things that can and should be fixed. For example, the front door lock is barely working. The door could be open with a good push.</p>



<p>We had a great vacation. The weather was good, and the red rocks are remarkable. We had a lot of fun and plan to come back sometime soon.</p>

<p>Work laptops were replaced. We accepted the loss of personal items.</p>

<p>The Airbnb experience was not as smooth as we expected. Our things got stolen, and even on the other days, we did not feel comfortable leaving belongings in the house.</p>

<p>The host was responsive, but it is not enough. Communicating with guests and collecting money should not be the only responsibility. It is worth inspecting the house and fixing things that do not work as expected proactively, without waiting till the universe gives you feedback.</p>

<p>Overall, I believe that staying at AirBnB is safe, and such incidents are the exception rather than the rule, but, for sure, Airbnb has some work to do to improve communication and increase the guests’ safety. The compensation of $500 for all the stolen items does not look fair either.</p>

<p>I would like to end the story with some action items like: “<strong>Next time, when I rent a place, I will do XXX</strong>.” Nothing reasonable comes to my mind.</p>

<p>When I sit in front of the computer in San Francisco, the only thing that comes to my mind is to build a Face Recognition system and check the burglar’s face in it. Something similar to Clearview. Machine Learning is my expertise; creating such a system is straightforward but will take some time. Tempting. Thinking about it.</p>

<p>What would be your action item after such an experience?</p>

        
      </section></div>]]>
            </description>
            <link>https://ternaus.blog/incident/2020/12/01/Airbnb-Thanksgiving-Burglary.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25321770</guid>
            <pubDate>Sun, 06 Dec 2020 07:14:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Lessons for Early Stage Founders]]>
            </title>
            <description>
<![CDATA[
Score 57 | Comments 5 (<a href="https://news.ycombinator.com/item?id=25321667">thread link</a>) | @sarathyweb
<br/>
December 5, 2020 | https://calv.info/early-stage-lessons | <a href="https://web.archive.org/web/*/https://calv.info/early-stage-lessons">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>In Segmentâ€™s early days, we hit countless problems as a founding team. And at the time, I thought those problems were unique to our own special snowflake of a founding journey. I chalked it up to us being new grads and first-time founders.</p><p>But as I've worked with more and more startups, I've realized just how wrong I was.</p><p>Over the past five years, I've made about 25 different seed-stage investments. In doing so, it's taught me a <em>LOT</em> about the common errors that startup founders make. Even across different industries and levels of experience, I see founders hitting the exact same set of problems we encountered in the early days of Segment!</p><p>This post shares a handful of the top lessons that benefit todayâ€™s early stage founders. Itâ€™s a list of the things I wish weâ€™d figured out earlier at Segment. [1]</p><p>This sounds incredibly boring... but the #1 mistake I see startups making is that they donâ€™t set goals. If you take one thing from this post, it's that you should set goals for where you want to be.</p><p>For the longest time at Segment, we didn't have goals. We moved ahead in various (often random) directions, and we would launch features consistently... but we never really set goals at all.</p><p>As we grew the company, we started to lose momentum. Teams were spending time on a bunch of stuff that frankly just didn't really matter to the overall business.</p><p>It wasn't until we hired our VP Eng, Tido, that we finally started setting focused and audacious product goals. Just by verbalizing where we wanted to go and then grading our results, our velocity improved by an order of magnitude.</p><p>I don't care if you call them OKRs, sprints, or something else entirely. Just set a deadline when you want to have something done and a metric you want to move or some other concrete result.</p><p>When early stage founders do attempt to set goals, I often see them agonize over what specific goals to choose. In practice, a "pretty good goal" is way better than "no goals at all". Perfect is the enemy of good.</p><p>If you don't yet have product-market fit, your goal should probably be getting your first 3-5 customers using the product. If you've hit the level where you now have dozens of users, your goal should be growing by an order of magnitude. It's better to get in the habit of setting and driving towards goals rather than being too worried about their exact semantics. Worst case, you just pick a better goal later.</p><p>A great set of goals answers the question: <em><strong>"what would have to be true in order for us to feel good about our progress at the end of the month?"</strong></em><em> [2]</em></p><p>If each teammate can independently answer "what are our goals for the month?" in the same way, you'll know you've succeeded. If youâ€™re looking for prior art, read <a href="https://www.amazon.com/Measure-What-Matters-Google-Foundation/dp/0525536221">Measure What Matters</a>. </p><p>If you strictly focus on making things true by a certain date, you are bound to make at least some progress towards your end result. </p><p>At the end of the day, every billion-dollar startup is really just the sum of many small deltas.</p><p>Let's get one thing straight: your investors won't know everything. But investors won't know <em>anything</em> if you don't keep them updated on how things are going.</p><p>For the longest time, we were fearful of our Segment investors, to the point that we wouldn't bother sending them emails unless they asked about us. I can say now with confidence that this was 100% the wrong approach.</p><p>We worried that investors would think that we were screwing up (true) and failing (true as well!). And while that might be the case, a founder-friendly investor won't think that way. Investors, especially angels, invested because they believe in <em>you</em>. If I didn't think a team would go somewhere, I wouldn't put money in.</p><p>With each investor, <strong>include the goals you're working towards, as well as the asks for them</strong>. I think monthly is about the right cadence for this in the early days, moving to quarterly around Series A/B time when you start partnering more with a few board members.</p><p>Simply writing the updates should clarify your own thinking tremendously. If it takes you more than 1-2h to put together an update on the most important things happening at the company, it's probably a sign that you should be doing more thinking about the big picture.</p><p>When asking for help, the things that our investors have been able to help us with evolved quite a bit over time. But here's a good rule of thumb for what to ask for:</p><ul><li><p><u>Seed/Pre-seed</u>: user-testing, intros to beta users, hiring</p></li><li><p><u>Series A</u>: hiring, early customers, go-to-market</p></li><li><p><u>Series B/C+</u>: comparables at other companies, senior/exec hires, specific expertise around things like management, infrastructure, systems, etc.</p></li></ul><p>Not all investors will be able to help with everything. But at the very least, sending them information will help you be top of mind. I've lost track of how many times a moment of serendipity where I'm catching up with an old friend has led to a meaningful conversation for a company I've invested in.</p><p>As an extra bonus, the strongest startups send these updates to everyone on their team. It's amazing how much putting the goals in writing helps everyone stay on the same page about what's most important.</p><p>One other note here: take pictures. I now wish we had far more pictures of Segment at every stage of the company. They help turn investor updates into cherished memories.</p><p>Okay, this lesson is taken directly from the YC playbook. And YET, I see so many founders (including YC founders) fail to launch their product. </p><p>If no one notices your launch... just ignore it and then launch again. If you're doing things right, you'll never run out of stuff to launch! [3]</p><p>Why is launching so important? Let me share a personal story...</p><p>We spent about 1.5 years building different iterations of analytics tools. For every iteration, we had a waitlist that users could sign up to use. We personally reached out to the users who we thought were the best fits, and then tried to set up time to use the product. </p><p>The result? Nobody cared. We had no users. We never launched. </p><p>When we finally launched Segment in it's current incarnation, we threw out that approach entirely. We put up a self-service flow, and let anyone who wanted to sign up for it.</p><p>That's when something strange happened... we attracted an entirely new set of developers who just were crawling out of the woodwork and excited to use the new product we'd built. They were coming from companies far outside of SV that we'd never heard of.</p><p>It floored me.</p><p><strong>Lesson learned: the people you happen to be talking to now are probably not the people who have the biggest problem in your space. Do everything you can to reach the folks with the biggest problem, and then, reduce any barriers they might encounter.</strong></p><p>I expect a bunch of you reading this post to ignore this advice, just like we did in the early days. It takes a certain confidence to launch something you've built and put it out there for the world to see. Ultimately though, the rewards are worth it. You'll see users coming from communities you've never even heard of.</p><p>Let me tell you a tale of two startups.</p><p><strong>Startup A</strong> is constantly putting up interesting content on their blog. Their founders are sharing product launches, engineering posts, and creatively brainstorming about what it takes to solve problems in their market.</p><p><strong>Startup B</strong> is operating in stealth. You can't find much about them online, but one of the founders reached out with a nice personalized email mentioning their funding by a top-tier VC. </p><p>Suppose you're looking for a job... do you pick Startup A or Startup B? In my experience, A almost always wins. Momentum is a compounding force.</p><p><strong>Unless you are working in a space that heavily depends on IP, you should probably be publishing more content about what you are doing.</strong> This could be open source, it could be a weekly newsletter, it could be a changelog. [4]</p><p>Whatever it is, it's going to help you both hire <em>and</em> attract customers. So much of the internet is merely about consuming, that just by putting ideas out there, youâ€™ll have a leg up on the competition.</p><p>In the early days of Segment, our <a href="https://segment.com/blog/show-hn-to-series-d/">user acquisition was powered by open source projects and blog posts</a>. But I've seen founders have success with Twitter, Substacks, Podcasts and a variety of different channels.</p><p>If you're looking for inspiration, the <a href="https://railway.app/changelog">Railway</a> and <a href="https://linear.app/changelog">Linear</a> changelogs are epic examples. Companies like <a href="https://baremetrics.com/blog/i-sold-baremetrics">Baremetrics</a> and <a href="https://buffer.com/resources/shareholder-update-q2-2020-and-july/">Buffer</a> differentiated themselves by just being open and honest. <a href="https://stripe.com/blog/globe">Stripe</a> and <a href="https://www.figma.com/blog/behind-the-feature-the-making-of-the-new-auto-layout/">Figma's blogs</a> not only share what they build, but how they built it.</p><p>There are three big inputs that all startups need to continue growing</p><ol><li><p>product capabilities</p></li><li><p>customers and users</p></li><li><p>hiring</p></li></ol><p>I've put them in roughly the order that most teams encounter them. </p><p>Startups begin with a small product that has a modicum of utility. It starts attracting a handful of customers organically. And as more and more customers start using the product, the founders realize that they need extra help to stay on top of all of those requests.</p><p>Remember though, the real goal here is #2. Itâ€™s not the size of your team, itâ€™s the value youâ€™re able to provide to the world. [5]</p><p>I see hiring a big team before you have product-market fit as a red flag. If the company doesn't yet have a set direction, it's going to be harder to pivot with 10 people than it is with 3.</p><p>But, I've worked with startups who have traction and runway... and just seem to be spinning their wheels under load from existing customers.</p><p>I get it. Hiring isn't the most fun, especially for an introvert. It's a lot of interviewing and feeling like there's a lot of rejection. Rejecting people sucks. Losing candidates sucks. For many of our roles at Segment, we've had to talk with 50-100 different people to make an eventual hire.</p><p><strong>If you have 24 months of runway, and a clear list of things youâ€™d do if you had more copies of yourself: you probably aren't spending time to hire the people you need.</strong></p><p>At Segment, my co-founder <a href="https://twitter.com/ivolo">Ilya</a> fulfilled this role. It was back in 2014, we were 12 people at the time, had raised a $10m Series A, and had $1m in revenue.</p><p>Thing…</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://calv.info/early-stage-lessons">https://calv.info/early-stage-lessons</a></em></p>]]>
            </description>
            <link>https://calv.info/early-stage-lessons</link>
            <guid isPermaLink="false">hacker-news-small-sites-25321667</guid>
            <pubDate>Sun, 06 Dec 2020 06:46:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How does Brown University know where you are?]]>
            </title>
            <description>
<![CDATA[
Score 180 | Comments 122 (<a href="https://news.ycombinator.com/item?id=25319392">thread link</a>) | @jswrenn
<br/>
December 5, 2020 | https://jack.wrenn.fyi/blog/brown-location-surveillance | <a href="https://web.archive.org/web/*/https://jack.wrenn.fyi/blog/brown-location-surveillance">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
    <p>In September 2020, Brown University <a href="https://www.browndailyherald.com/2020/09/28/remote-students-receive-emails-brown-accusing-violating-code-student-conduct">accused students</a> of lying about their location; e.g.:</p>
<p><img src="https://jack.wrenn.fyi/blog/brown-location-surveillance/notice.png" height="auto" width="100%" alt="The University has learned that between September 14, 2020 and September 21, 2020 you were allegedly in the Providence area during which time your location of study was listed as remote. This alleged behavior is a violation of the Student Code of Conduct and the COVID-19 Campus Safety Policy. A copy of the Student Commitment to COVID-19 Community Health and Safety Requirements is attached for your review, along with this link to the COVID-19 Campus Safety Policy. failure to abide by these requirements is a violation of the Code of Student Conduct. 
Based on the details of the incident and your student conduct history, the Office of Student Conduct &amp; Community Standards has decided to allow you the opportunity to accept responsibility for the following prohibited conduct without having a COVID-19 Dean's Review Meeting:
• D.8 Failure to Comply
• D.13 Misrepresentation
"></p>
<p><strong>What was Brown's basis for these accusations?</strong></p>
<p>In an <a href="https://www.browndailyherald.com/2020/09/28/remote-students-receive-emails-brown-accusing-violating-code-student-conduct">interview with The Brown Daily Herald</a>, University Spokesperson Brian Clark said the University evaluated a variety of indicators, including:</p>
<ol>
<li>indications of building access,</li>
<li>indications of accessing private electronic services,</li>
<li>indications of accessing secure networks, and</li>
<li>reports from community members.</li>
</ol>
<p>The mechanics of that last indicator are pretty self-explanatory, but what about the others? <a href="https://it.brown.edu/services/type/canvas-learning-management-system">Canvas</a> <em>doesn't</em> <a href="https://knowyourmeme.com/memes/google-wants-to-know-your-location">Want To Know Your Location</a>. <strong>In this post, I'm going to break down the technical mechanisms behind each of these indicators.</strong></p>
<p>For the most part, I do not have insider knowledge on how Brown reached its decisions. Rather, I'm going to consider each of the indicators Brian Clark named, and describe the technical mechanisms to which Brown <em>could</em> have availed itself to generating location data.</p>
<h2 id="indications-of-building-access">Indications of Building Access</h2>
<p>This is an easy one. Brown's buildings are located on Brown's campus. Brown's campus is in Providence. If you are in Brown's buildings, you are on Brown's campus, in Providence. QED.</p>
<p>At Brown, building access is primarily regulated with electronic control systems (namely Software House's <a href="https://www.swhouse.com/products/software_CCURE9000.aspx"><strong>C•CURE 9000</strong></a> system), not mechanical keys.</p>
<p>Encoded on <a href="https://en.wikipedia.org/wiki/Magnetic_stripe_card#Track_2">track 2</a> of the magnetic stripe on every University ID card is a sixteen digit number that uniquely identifies the card:</p>
<p><img src="https://jack.wrenn.fyi/blog/brown-location-surveillance/brown-id-card-back.jpg" height="auto" width="100%" alt="Image of back of Brown ID card. A tall magnetic stripe runs across the entire width of the card."></p>
<p>Well, that's underwhelming — of <em>course</em> you can't <em>see</em> it! However, up until 2017 or 2018, this number was also <em>printed</em> on the front of ID cards, just above the card-holder's name:</p>
<p><img src="https://jack.wrenn.fyi/blog/brown-location-surveillance/brown-id-card-front.jpg" height="auto" width="100%" alt="Image fo the front of a Brown ID card, displaying the building access code: 6009553660926201"></p>
<p>This pseudo-random identifier (well, its last ten digits) are what uniquely identify you whenever you swipe your Brown ID card <em>anywhere</em>. And, if you lose your Brown ID card, this is the <em>only</em> thing that's changed when you're issued a replacement. Convenient! In contrast, when you lose your dorm room's mechanical key, Brown must replace (or rather, <a href="https://en.wikipedia.org/wiki/Rekeying">rekey</a>) the locks.</p>
<p>But, <em>also</em> unlike a mechanical key, <em>every</em> swipe of a Brown ID card is logged in a central database. <strong>The C•CURE 9000 lets administrators view the complete historical building access history of a person.</strong> Last Spring, Brown used this mechanism to identify and prod students who were slow to evacuate Providence.</p>
<h2 id="indicators-from-electronic-services">Indicators from Electronic Services</h2>
<p>University web services like Canvas <em>don't</em> directly ask you for your location. Nonetheless, accessing these services leaves a location finger print: your IP address.</p>
<p>Your <a href="https://en.wikipedia.org/wiki/IP_address">IP address</a> is a number that identifies your device (computer, phone, etc.) for the purposes of network routing. In principle, nobody but you and your internet provider know the <em>exact</em> mapping of your IP address to your physical address.</p>
<p>In practice, IP addresses can be used to <em>roughly</em> geolocate a device. Batches of IP addresses are associated <em>loosely</em> with geographic areas. Since every web service access leaves an IP address as a trace, there are tremendous incentives for advertisers to be able accurately identify what city or town an IP address is probably associated with.</p>
<p>Brown probably <em>isn't</em> analyzing the access logs of its <em>individual</em> web services (like Canvas). Rather, they need only to audit the access logs of its three identity access management (IAM) systems:</p>
<ul>
<li>The <a href="https://workspace.google.com/">Google Workplace</a> IAM system is used to control access to your @brown.edu email, and to the various Google Drive services. <a href="https://support.google.com/a/answer/4580120?hl=en"><strong>Google Workplace</strong> provides administrators with login audit logs that include users' IP addresses.</a></li>
<li>The <a href="https://www.shibboleth.net/">Shibboleth</a> IAM system controls access to all <em>other</em> Brown web services, such as Canvas. It's what you think of as your "Brown account". Shibboleth is <em>very</em> flexible, and can be <a href="https://wiki.shibboleth.net/confluence/display/IDP30/AuditLoggingConfiguration#AuditLoggingConfiguration-GenericFields">configured to log IP addresses</a>.</li>
<li><a href="https://duo.com/">DUO</a> is used to provide two-factor authentication for Shibboleth logins. <a href="https://help.duo.com/s/article/1023?language=en_US#docs-internal-guid-0aa3b4ce-c686-7559-8814-1377592fce4a:%7E:text=Access%20Device">It too provides administrators with detailed access logs</a>.</li>
</ul>
<p>You can partly view your Google Workplace login history for yourself by opening your Brown email and clicking "Details" in the bottom right-hand corner of the page; e.g.:</p>
<p><img src="https://jack.wrenn.fyi/blog/brown-location-surveillance/gmail-account-activity.png" height="auto" width="100%"></p>
<p>With <em>either</em> of these access logs in hand, Brown could then turn to any number of geolocation services (<a href="https://tools.keycdn.com/geo">like this one</a>) to guess your physical location.</p>
<h2 id="indicators-from-secure-networks">Indicators from Secure Networks</h2>
<p>This is another easy one. Brown's WiFI network <a href="https://jack.wrenn.fyi/blog/blog/brown-location-surveillance/Campus_Wireless_Coverage_Map_24x36_1.pdf">blankets Brown's campus</a>. Brown's campus is in Providence. If you are on Brown's WiFi network, you are on Brown's campus. QED.</p>
<p>What might surprise you is the sheer depth of surveillance that's capable with WiFi alone. This section will <em>barely</em> scratch the surface.</p>
<h3 id="identification">Identification</h3>
<p>Brown's WiFi routers each broadcast three <a href="https://en.wikipedia.org/wiki/Service_set_(802.11_network)">service sets</a>:</p>
<ol>
<li><a href="https://it.brown.edu/services/type/wireless-network-brown">Brown</a></li>
<li><a href="https://it.brown.edu/services/type/wireless-network-eduroam">eduroam</a></li>
<li><a href="https://it.brown.edu/services/type/wireless-access-brown-guest">Brown Guest</a></li>
</ol>
<p>The Brown and eduroam networks require that you authenticate with your Brown account credentials. Brown University is thus able to identify the owner of any device connected to these networks.</p>
<p>While Brown Guest does <em>not</em> require authentication, it still provides mechanisms of identification. Your network devices broadcast a unique identifier called a <a href="https://en.wikipedia.org/wiki/MAC_address"><strong>MAC address</strong></a>.</p>
<p><a href="https://drawings.jvns.ca/mac-address/"><img type="image/svg+xml" src="https://drawings.jvns.ca/drawings/mac-address.svg" height="auto" width="100%" alt="Comic by Julia Evans. Text: Every computer on the internet has a network card. When you make HTTP requests with Ethernet/WiFi, every packet gets sent to a MAC address. (&quot;Wait, how do I know someone else on the same network isn't reading all my packets?&quot; &quot;You don't! That's one reason we use HTTPS &amp; secure WiFi networks.&quot;) Your router has a table that maps IP addresses to MAC addresses.  (Read about ARP for more.)
"></a></p>
<p>Brown <a href="https://it.brown.edu/computing-policies/network-connection-policy#32:%7E:text=CIS%20maintains%20a%20database%20of%20unique,a%20computer%20when%20it%20is%20necessary.">maintains databases of the MAC addresses of all connected devices</a>.</p>
<p>If you have ever connected to an authenticated network, Brown will be able to de-anonymize your connections to Brown Guest — <em>unless</em> your device implements <a href="https://en.wikipedia.org/wiki/MAC_address#Randomization">MAC address randomization</a>, which (as the name suggests) randomizes your device's MAC address on a per-network basis.</p>
<h3 id="localization">Localization</h3>
<p>Brown's access points log the MAC addresses of the devices that have connected to them. As of 2015, Brown retained these logs for at least several years — possibly indefinitely. Since there are so many access points on campus, which access point you are connected to can narrow your location down to a particular room. <strong>Combined, these logs paint a <em>very</em> accurate picture of your location on campus at any time.</strong></p>
<p>You do not need to be <em>actively</em> browsing the internet for Brown to know where you are via this mechanism. As you walk through campus, your phone likely <em>automatically</em> reconnects to the nearest available access point. If you are within a literal stone's throw of campus, you should assume that Brown can (roughly) identify your location.</p>
<p>Furthermore, if you are in range of three or more of Brown's ARUBA access points, Brown can, in principle, precisely triangulate your location. This functionality is <a href="https://www.arubanetworks.com/pdf/technology/whitepapers/wp_Hybrid_WIDS.pdf">common</a> in enterprise-grade WiFi infrastructure. (If you've ever tried to run a "rogue" WiFi router in your dorm room and receive an angry knock on your door — this is the mechanism by which you were located.)</p>
<h2 id="how-do-i-find-out-more">How do I find out more?</h2>
<p>The <a href="https://en.wikipedia.org/wiki/Family_Educational_Rights_and_Privacy_Act"><em>Family Educational Rights and Privacy Act</em></a> empowers students to request their education records from their University.</p>
<p><iframe src="https://www.youtube.com/embed/jWzBrC8dVnw" frameborder="0" allowfullscreen=""></iframe></p>
<p>If you are a current Brown student and would like to go beyond my blog post and learn <em>exactly</em> how Brown University knows your location, <a href="https://www.brown.edu/about/administration/registrar/student-information-rightsferpa">file a FERPA request</a>. Brown University is obligated to respond within 45 days. You'll need to be specific with your request. I suggest requesting:</p>
<ul>
<li>the timestamps, MAC addresses and BSSIDs associated with your devices' connections to Brown University's wireless access points</li>
<li>the timestamps and locations associated with all building accesses conducted with your ID card</li>
<li>the login audit data associated with all Google Workplace, Shibboleth, and DUO authentications conducted by your accounts</li>
</ul>
<p>Additionally, the <a href="https://en.wikipedia.org/wiki/General_Data_Protection_Regulation"><em>General Data Protection Regulation</em></a> gives EU citizens and residents expansive control over how their personally identifiable information (PII) is used, and the right to request a copy of or the destruction of collected data. I believe these requests should be directed to <a href="https://compliance.brown.edu/">Brown's compliance office</a>. You might be able to do this even if you're a Brown alumni.</p>
<p><strong>If you attempt either of these steps, <a href="mailto:jack@wrenn.fyi">please get in touch</a>!</strong> I'm very curious as to what Brown is <em>actually</em> doing.</p>
<h2 id="bonus-surveillance-cameras">Bonus: Surveillance Cameras</h2>
<p>As of February 2020, <a href="https://www.browndailyherald.com/2020/02/21/cameras-installed-hegeman-hall/#post-2838338:%7E:text=The%20University%20uses%20approximately%20800%20cameras,with%20high%20crime%20activity%2C%20Porter%20said."><em>eight hundred</em> surveillance cameras monitor campus 24/7</a>. Brown has as about as many surveillance cameras as it has full-time faculty! This map documents a <em>mere seven percent</em> of Brown University's total camera surveillance capacity:</p>

<p><small>This map displays data from <a href="https://www.openstreetmap.org/about">OpenStreetMap</a>. <a href="https://pietervdvn.github.io/Staging/surveillance.html?z=17&amp;lat=41.82681&amp;lon=-71.4016">Help improve its accuracy!</a></small></p><p>Brown University has a longstanding policy governing the appropriate uses of its surveillance cameras. <strong>Unfortunately, <a href="https://www.browndailyherald.com/2008/01/10/surveillance-cameras-on-campus-triple/#post-1679525:%7E:text=DPS%20would%20not%20release%20the%20University%E2%80%99s%20full%20policy%20on%20the%20surveillance%20camera%20system">this policy is secret</a>.</strong></p>
<p>While Brown probably does not <em>currently</em> have the capacity to both broadly and deeply inspect the firehose of data produced by these cameras, expect this to change in the near future. Axis Communications, Brown's primary supplier of surveillance cameras, <a href="https://www.axis.com/customer-story/3767">now touts cameras that can perform <em>on-board</em> facial recognition</a>. And Software House, the provider of the C•CURE 9000 access control system, has begun marketing the integration of facial recognition with its access control systems:</p>
<p><iframe src="https://www.youtube.com/embed/bk395D0tPRA" frameborder="0" allowfullscreen=""></iframe></p>

  </div></div>]]>
            </description>
            <link>https://jack.wrenn.fyi/blog/brown-location-surveillance</link>
            <guid isPermaLink="false">hacker-news-small-sites-25319392</guid>
            <pubDate>Sat, 05 Dec 2020 23:18:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Special Kind of Hell: intmax_t in C and C++]]>
            </title>
            <description>
<![CDATA[
Score 59 | Comments 93 (<a href="https://news.ycombinator.com/item?id=25316933">thread link</a>) | @ingve
<br/>
December 5, 2020 | https://thephd.github.io/intmax_t-hell-c++-c | <a href="https://web.archive.org/web/*/https://thephd.github.io/intmax_t-hell-c++-c">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
  
      <p>C and C++ as languages have a few things separating them from each other, mostly in their minute details and, occasionally, larger feature sets like designated initializers. But there is a disturbingly high amount of C++ that can simply do C’s job far better than C<!--more-->, including when it comes to solving some of the biggest problems facing the evolution of C and C++.</p>

<p>Let’s take a contemporary problem plaguing both C and C++, affecting everyone from standard library maintainers to project developers, that has been going on for the last 20 or so years: <code>intmax_t</code>.</p>



<p>The concept behind <code>intmax_t</code> is simple enough: it is the largest integer type that your implementation and its standard library support in conjunction. Here is a few things <code>intmax_t</code> controls inside the implementation:</p>

<ul>
  <li>numeric literals are preprocessed according to what <code>intmax_t</code> can handle (C and C++);</li>
  <li>it is the maximum number of bits that can be printed portably, e.g. with <code>printf("%j", (intmax_t)value)</code> (C and C++);</li>
  <li><code>intmax_t</code> is the largest type for which <code>std::numeric_limits</code> applies, including most types up to and including that type (C++ only);</li>
  <li><code>intmax_t</code> underpins <code>std::chrono</code>’s casts and similar (e.g. no information is lost during conversions out of and into the system) (C++ only);</li>
  <li>and, there are a set of integer operations provided by the standard library (like absolute value and quotient / remainder operations) that can be done with the maximum bit precision available to the implementation (C and C++).</li>
</ul>

<p>These properties forge the basis of <code>intmax_t</code>’s purpose. Lossless storage, pass-through operations, and more can all be achieved by relying on this implicit contract of the type. Since it is a type definition, the “real” integer type underneath it can be swapped out and people relying on it can be upgraded seamlessly!</p>



<p>We cannot upgrade seamlessly.</p>

<p>C has a much higher commitment to not breaking old code and keeping “developers close to the machine”. What this actually translates to for most Application Binary Interfaces is very simplistic “name mangling” schemes (i.e., none), <a href="https://twitter.com/__phantomderp/status/1329960075096694790">weak linkers</a>, and other shenanigans. The end result is that we expose C developers to platform details that become invisible dependencies for their code that must be preserved at all costs. For example, let’s take a C Standard function that uses <code>intmax_t</code>, <code>imaxabs</code>:</p>

<div><div><pre><code><span>intmax_t</span> <span>imaxabs</span><span>(</span><span>intmax_t</span> <span>j</span><span>);</span>
</code></pre></div></div>

<p>and, let’s try to figure out how we can upgrade someone off of this usage without breaking their code too badly. We will try fixing this in both C and C++.</p>



<p>Taking <code>intmax_t</code>, let’s do a no-brainer usage case: calling a function with <code>intmax_t</code> input and return types. The syntax and usage ends up looking like this:</p>

<div><div><pre><code><span>#include &lt;inttypes.h&gt;
</span>
<span>int</span> <span>main</span> <span>()</span> <span>{</span>
	<span>intmax_t</span> <span>original</span> <span>=</span> <span>(</span><span>intmax_t</span><span>)</span><span>-</span><span>2</span><span>;</span>
	<span>intmax_t</span> <span>val</span> <span>=</span> <span>imaxabs</span><span>(</span><span>original</span><span>);</span>
	<span>return</span> <span>(</span><span>int</span><span>)</span><span>val</span><span>;</span>
<span>}</span>
</code></pre></div></div>

<p>Easy enough! But, there’s also a hidden dependency here, based on how the code is compiled. While many people compile their C standard library as a static library and only generate final binary code for what they use as to have a “self-contained” binary, the vast majority of the shared ecosystem depends on shared libraries/dynamically linked libraries for the standard. This means that when a program is milled through an operating system at program startup, the “loader” runs off to find the symbol <code>imaxabs</code> inside some system library (e.g., <code>/lib/x86_64-linux-gnu/libc-2.27.so</code> for an “amd64” system). Harmless enough, right? Well, it turns out to be a bit of a problem in practice, because the name <code>imaxabs</code> is all that’s used in C to figure out what subroutine to talk with in some shared library,</p>

<p>and that name is completely inadequate.</p>

<p>Consider the following scenario:</p>

<ol>
  <li>The glibc maintainers decide they’re going to change from <code>long long</code> as their <code>intmax_t</code> and move to <code>__int256_t</code> for most platforms, because most platforms support it and they have a lot of customers asking for it.</li>
  <li>They upgrade the <code>libc</code> to its next version for various Linux distribution, and everyone links against it when they look for the default <code>libc</code>.</li>
  <li>You have an application. Your code was not changed or updated, so it was not recompiled. It calls <code>imaxabs</code>. The argument it passes is a <code>long long</code>, because that was the type at the time you last compiled and shipped your software.</li>
  <li>The <code>imaxabs</code> used to lookup the function to call finds the version that takes a <code>__int256_t</code> in the new <code>libc</code>.</li>
  <li>Different registers are used to pass and return the function value than expected by the <code>imaxabs</code> function call in the <code>libc</code> binary, because your application is in <code>long long</code> mode but glibc expects a <code>__int256_t</code>.</li>
  <li>All hell breaks loose.</li>
</ol>

<p>This is one of the manifestations of what is called an “Application Binary Interface (ABI) Break”. ABI Breaks are generally undetectable, silent breaks that occur within the runtime of a program that completely destroy any dependency your program has on that functionality for correctness. It typically happens when a subtle detail – the registers used to negotiate a large integral value between a shared library and its application, the amount of padding a structure might have on a certain build, the ordering and layout of class members, the interpretation of bits even if the layout or passing convention of a type never changes, and even more – changes.</p>

<h2 id="but-c-is-abi-stable">“But C Is ABI-Stable?!”</h2>

<p>Not necessarily. C is a simple language, and it both sells itself on and prides itself as such. So much so, that it’s even part of the <a href="http://www.open-std.org/jtc1/sc22/wg14/www/docs/n2021.htm">language’s rolling charter</a>. There’s barely any name mangling because there’s no overloading. If you want “virtual functions” you need to hand-craft your virtual table structure and initialize it yourself. There’s barely any lookup or entity negotiation: what you write – <a href="https://twitter.com/thingskatedid/status/1328918322507706368">however scary or cursed</a> – is what you get, in a general sense. (No, it’s not “portable assembly”. Compilers tear C code apart and make it far more efficient than the code people stuff into it. It’s not even a direct model of the machine anymore: just an abstract one.)</p>

<p>Still, sometimes even C can’t get away from it. The function <code>imaxabs</code> relates to exactly one entity that, for historical reasons, was pinned to a function taking and returning a <code>long long</code>. Upgrading it means dealing with this schism between what the user expects (<code>intmax_t</code> that got upgraded and can print <code>__int128_t</code>/<code>__int256_t</code>) with old, non-recompiled code that maintains the old invariant (<code>long long</code>, a 64-bit number).</p>



<p>Okay, so symbols can be repurposed between library versions that lead to ABI breaks. What are the ways to defend against such a world, in C?</p>

<h2 id="macros">Macros?</h2>

<p>Macros! Object-like macros are fun. You could do something like this…</p>

<div><div><pre><code><span>#define imaxabs __glibc228_imaxabs
</span></code></pre></div></div>

<p>… as a way to provide the <code>imaxabs</code> function. It is a bit like artisanal, hand-crafted, free-range, and organic ABI versioning (or, as I have affectionately come to call it: personal masochism to make up for language failures). This mostly works, until… it doesn’t!</p>

<h3 id="714">§7.1.4</h3>

<p>This is the “ABI Breaks Guaranteed” section in the C Standard. It’s real name is “§7.1.4 Use of library functions”. Reproduced below is the relevant piece that condemns us, emphasis mine:</p>

<blockquote>
  <p>Any function declared in a header may be additionally implemented as a function-like macro defined in the header, so if a library function is declared explicitly when its header is included, one of the techniques shown below can be used to ensure the declaration is not affected by such a macro. <strong>Any macro definition of a function can be suppressed locally by enclosing the name of the function in parentheses</strong>, because the name is then not followed by the left parenthesis that indicates expansion of a macro function name. For the same syntactic reason, it is permitted to take the address of a library function even if it is also defined as a macro. <strong>The use of <code>#undef</code> to remove any macro definition will also ensure that an actual function is referred to</strong>.</p>
</blockquote>

<p>Not only can a user suppress a function-like macro invocation by using the same trick used on <code>&lt;windows.h&gt;</code> like <code>(max)(value0, value1)</code>, but the C Standard Library permits them to also undefine function names:</p>

<div><div><pre><code><span>// implementer code: inttypes.h</span>
<span>#define imaxabs __glibc228_imaxabs
</span></code></pre></div></div>

<div><div><pre><code><span>// user code: main.c</span>
<span>#include &lt;inttypes.h&gt;
</span>
<span>#undef imaxabs // awh geez
</span>
<span>int</span> <span>main</span> <span>()</span> <span>{</span>
	<span>intmax_t</span> <span>val</span> <span>=</span> <span>-</span><span>1</span><span>;</span>
	<span>intmax_t</span> <span>absval</span> <span>=</span> <span>imaxabs</span><span>(</span><span>val</span><span>);</span> <span>// awH GEEZ</span>
	<span>return</span> <span>(</span><span>int</span><span>)</span><span>absval</span><span>;</span>
<span>}</span>
</code></pre></div></div>

<p>Mmm……</p>

<h3 id="implementation-specific-strategies">Implementation-specific strategies</h3>

<p>Alright, the C Standard basically loads a double barrel and brings our only standardized mitigation strategy out back behind the barn. What’s left? Well, implementation-specific insanity, that’s what:</p>

<div><div><pre><code><span>extern</span>
<span>intmax_t</span>
<span>__glibc228_imaxabs</span><span>(</span><span>intmax_t</span><span>);</span>

<span>__attribute</span><span>((</span><span>symbol</span><span>(</span><span>__MANGLE</span><span>(</span><span>__glibc228_imaxabs</span><span>))))</span>
<span>extern</span>
<span>intmax_t</span>
<span>imaxabs</span><span>(</span><span>intmax_t</span><span>);</span>
</code></pre></div></div>

<p>This is pseudo-code. But, wouldn’t you believe it, some implementations actually do things very similar to this to get around these problems! The things they do are far more involved, like actually dropping down to the level of the linker and creating symbol maps and other exceedingly painful workarounds. The sed scripts and the awk scripts and the bash starts coming out, people are doing lots of text processing to get symbol names and match them to versioned symbol names…</p>

<p>It’s a mess.</p>

<p>Still, given the mess, it does save us from the problem. In C code you get to use “the real name” <code>imaxabs</code> as Our Lord and Savior intended, the binary gets linked to <code>___glibc228_imaxabs</code>, and everyone’s happy. There’s only one problem with this kind of fix…</p>

<p>It’s Quality of Implementation (QoI).</p>

<p>QoI is great for the pure, theoretical standard. We get to write sexy narratives in the C standard and call them “Recommended Practice”, with little footnotes furtively implying a more wonderful world while waggling our eyebrows seductively at hot, young developers in our area. Just come along, it’s going to be so great, we’re going have soooooo much fun, just go with that lovely little implementation right over there, you’re making such fine progress, enjoy yourself and come back soon my …</p></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://thephd.github.io/intmax_t-hell-c++-c">https://thephd.github.io/intmax_t-hell-c++-c</a></em></p>]]>
            </description>
            <link>https://thephd.github.io/intmax_t-hell-c++-c</link>
            <guid isPermaLink="false">hacker-news-small-sites-25316933</guid>
            <pubDate>Sat, 05 Dec 2020 18:30:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Benefits of Walking]]>
            </title>
            <description>
<![CDATA[
Score 183 | Comments 81 (<a href="https://news.ycombinator.com/item?id=25316328">thread link</a>) | @KlimYadrintsev
<br/>
December 5, 2020 | https://klimy.co/blog/benefits-of-walking | <a href="https://web.archive.org/web/*/https://klimy.co/blog/benefits-of-walking">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="blog">
                    <h2>How long does it take to walk 1 mile?</h2>
<p>As both research and actual scientific measurements, an average adult will walk 1 mile in 15 to 18 minutes at moderate to a brisk pace. Or in other words, 3 to 4 miles per hour.</p>
<p>This is a general measure for a healthy adult between 20 and 50 years old, at dry weather, on relatively flat terrain, with no destruction from cars and other environments.</p>
<p>If you are either less healthy or subjected to any of the environmental distractions, your speed, of course, will be lower.</p>
<h2>Average walking speed by age group and gender</h2>
<p>There is little difference between male and female, with males walking on average 2% faster.</p>
<p>The table below shows the speed of walking based on age and gender:</p>
<pre><code>| Age      | Sex    | Meters per second | Miles per hour |
|----------|--------|-------------------|----------------|
| 20 to 29 | Male   | 1.36              | 3.04           |
|          | Female | 1.34              | 3.0            |
| 30 to 39 | Male   | 1.43              | 3.2            |
|          | Female | 1.34              | 3.0            |
| 40 to 49 | Male   | 1.43              | 3.2            |
|          | Female | 1.39              | 3.11           |
| 50 to 59 | Male   | 1.43              | 3.2            |
|          | Female | 1.31              | 2.93           |
| 60 to 69 | Male   | 1.34              | 3.0            |
|          | Female | 1.24              | 2.77           |
| 70 to 79 | Male   | 1.26              | 2.82           |
|          | Female | 1.13              | 2.53           |
| 80 to 89 | Male   | 0.97              | 2.17           |
|          | Female | 0.94              | 2.10           |
</code></pre>
<h2>Benefits of walking</h2>
<p>There has been a great deal of research that showed that walking brings a huge advantage to humans. To both <a href="https://journals.sagepub.com/doi/abs/10.1177/0013916518800798">physical, and mental well being.</a> The benefits are as follows:</p>
<p>Physical:</p>
<ul>
<li>Burning calories. A direct way to reduce and to control your weight.</li>
<li>Lower glucose level and blood sugar levels. <a href="https://care.diabetesjournals.org/content/early/2013/06/03/dc13-0084">Research</a> has focused on short walks, where it helped reduce glucose intolerance.</li>
<li><a href="https://bjsm.bmj.com/content/45/12/987?sid=fe62a8c5-430b-4506-b854-20b62e8a5e9e">Help deal with infection and possibly Covid.</a></li>
<li>Help boost immune function.</li>
<li>Give additional energy to do other tasks due to increased efficiency of nutrients absorption and conversion.</li>
<li>Prolonging life. There is a <a href="https://bjsm.bmj.com/content/52/12/761">research that showed</a> evidence of having a relationship between physical activity and overall life expectancy. </li>
<li>Strengthen the heart. Even 20 minutes of daily walking has shown to reduce the risk of stroke by at least 20%.</li>
</ul>
<p>Mental:</p>
<ul>
<li><a href="https://pubs.acs.org/doi/abs/10.1021/es903183r">Improving self esteem</a> by 45%.</li>
<li><a href="https://pubs.acs.org/doi/abs/10.1021/es903183r">Improving mood</a> by 54%.</li>
<li>Additional time on focusing on self-education with educational podcasts and books. <a href="https://digitalcommons.georgiasouthern.edu/nyar_savannah/2020/2020/90/">Research</a> has shown that it leads to better learning of the material, longer retention, better engagement in post-walk discussions, better behaviour and mood, AND improved health literacy.</li>
<li>Improving <a href="https://www.tandfonline.com/doi/abs/10.1080/10413200.2020.1815100">goal setting</a> in other areas by targeting non-specific goals which in consequence lead to better results.</li>
<li>Walking helps you get your thoughts in order. Whenever you are alone with yourself, and you are unable to really look at the phone, you are finally able to understand what is happening with yourself with no distractions.</li>
<li>Improve the creative part of the brain. While walking, <a href="https://psycnet.apa.org/record/2014-14435-001">research showed</a>, that it is easier to come up with great ideas.</li>
<li>Save money on medications. With the amount of food, we consume and with costly medicine, walking and doing exercises can help you save money and nerves.</li>
</ul>
<h2>Covid and sitting time</h2>
<p>In the world of pandemics and covid, it has been evident that humans are sitting more and more and do less and less exercises. There is a <a href="https://www.sciencedirect.com/science/article/pii/S221133552030214X">great research</a> that shows that 2020 has caused a sharp increase in average sitting time. The data is staggering.</p>
<p><code>Overall, 42.6% of participants reported sitting for &gt; 8 h/day (95% CI: 41.2%–44.0%) and 72.5% (71.2%–73.7%) reported being either sufficiently (150–300 MVPA minutes) or highly active (&gt;300 min).</code></p>
<p>If you want to boost your health and still to be able to keep up with a busy schedule walking or running can be the best idea for spending your free time. In the world where only entertainment inside your house is minimal. If being glued to the screen is no longer an option, than being outside can boost your health and your mental capabilities immensely.</p>
<p><img alt="walking in the park grass and women leg" src="https://i.gyazo.com/ecae9926d17ad69ded99b1a445482e9a.jpg"></p>
<h2>Tips on how to start walking</h2>
<h3>How to make walking a habit?</h3>
<p>The walk starts with the first step. It would be best if you did not put huge goals onto yourself. Start somewhere small, then later you can always adjust based on how you feel.</p>
<p>Start by putting on clothes(plus a mask) and go outside. Going back to your apartment would feel bad at that point.</p>
<p>Next, you should walk around your building or up and down the street.</p>
<p>Next, you walk around the block and later you can finally go for huge walks that can be a couple of hours long.</p>
<p>Don’t try to start at the last step that would only make you quit before you get the full benefit of the habit.</p>
<p>Peg your walking habit to something else. If you go for a coffee every morning, go to a coffee house that is further away. If you are usually riding a tube to work, start the journey at the stop further away from you</p>
<h3>Identify as a walker</h3>
<p>If you would like to start walking you need to think of <strong>how do you become a walker.</strong></p>
<p>You need to make sure you identify as someone who goes on walks, then keeping up with the habit will be much easier.</p>
<p>Next time someone asks you, whatever you do any exercises or what you love doing with your free time, you need to want to say that you love walking. At that point, you will be able to keep on walking and improving your health immensely.</p>
<h2>How much walking per week is enough?</h2>
<p>I think that it is tough to give a simple number for everyone, but if you are in the age range of 18-50, then:</p>
<ul>
<li>150 to 300 minutes per week is an ideal level if you are walking with moderate speed</li>
<li>75 to 150 minutes per week if you are walking with a brisk pace.</li>
</ul>
<p>Don’t think that doing extra physical exercise will be useless. In contrast, anything above that time limit will give even higher benefits to your health, so take the timing above as a general guideline. Do as much as you want.</p>
<h2>Personal tips on walking more</h2>
<h3>Wake up earlier</h3>
<p>Right now it is very easy to blame everything on covid and health, but not many people <a href="https://klimy.co/blog/how-to-wake-up-early">wake up very early in the morning</a>, that gives people that live in the city an ability to walk as much as they want, even in usually crowded spaces.</p>
<p>Also, your excuse of not having enough time can not be reinforced if you have an extra hour in the morning.</p>
<h3>Get a pet (dog)</h3>
<p>Even though it can seem like a lousy idea, multiple research papers show a relationship between owning a dog and the number of steps you do daily. If you are struggling to make time, your favourite pet will make you find time for walks.</p>
<p><img alt="man and dog walking in forest autumn" src="https://i.gyazo.com/5e16de8c0474f84f4285df88fab28c14.jpg"></p>
<h3>Podcasts and Audiobooks</h3>
<p>I love learning and listening to books. I do it all the time even when I am at home at my desk, so a change of pace for me is always going for an extended walk where I can do the same thing.</p>
<p>What I discovered is that I understand and remember information much better when I have consumed it while walking. That makes me spend twice as little time and getting twice the result. </p>
<p>Podcasts have been my go-to method of getting new relevant news and information in my field of expertise. Since I have started a habit of walking, I have been on top of my field and able to implement solutions that I would have never thought of otherwise.</p>
<h3>Music</h3>
<p>I also love discovering new music. Sometimes when I really need to get my head around something I go for a brisk walk with my favourite songs. This helps me to unwind and later really understand the problem.</p>
<p>Most of the time while on the walk, I solve the problem that I had, and in my experience would off taken me much more time to solve.</p>
<h3>Walking groups</h3>
<p><img alt="walking groups picture" src="https://i.gyazo.com/26609ccb0d7ae90e9f746389479a32b0.jpg"></p>
<p>Sometimes socialising can be hard and especially when all of your friends are on the lockdown and all of the socialising places, such as restaurants, are closed. </p>
<p>That is where walking groups can come into play! You can find someone who is staying healthy and being diligent with their health and walk together! That will allow you to catch up and have social interaction, that we humans require.</p>
<h5>So what this means?</h5>
<p>Now you have a social responsibility in your habit, and the whole activity can let you be more motivated to do it.</p>
<p>Also, walking groups normally allow you to meet new people and to bond better with existing relationships.</p>
<p>Also, walking groups is a great way to speed up your walking pace and improve your health.</p>
<h2>How do I get better at walking?</h2>
<p>If you would like to improve the speed at which you walk, there are multiple ways to do so:</p>
<ul>
<li>As mentioned above, walking groups are amazing for giving you a speedup of pace, just make sure to not overdo it.</li>
<li>Walking poles (tracking poles) are an easy way to speed up the pace. They are especially useful for those with back or leg injury, that immensely help reduce the stress on joints and back as well as speed up the pace. There is a lot of research behind use cases and benefits of using them.</li>
<li>Treadmills. If you are unable to properly walk in the wild or in the park, get yourself a treadmill. Although they can be expensive, some are very cheap and immensely powerful alternatives provide the same result. You don’t need something overly expensive. Treadmills are great for controlling your pace as well as letting you support yourself with the rails that are at either side of the treadmill.</li>
<li>Have an open goal. Whenever you are walking, the <a href="https://www.tandfonline.com/doi/abs/10.1080/10413200.2020.1815100">research has shown</a> that having an open goal to where you want to walk or for how long will extend the amount of walking that you will eventually do.</li>
<li>Keep track of your metrics. Understanding what your heart rate and your pace are, is vital for your well being and motivation. Seeing that you have improved over a period of time is the greatest motivator there is.</li>
<li>Strive towards a 13 minutes per mile goal. The 13 minutes per mile has been shown to be the meeting point between fast walkers and the joggers. As …</li></ul></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://klimy.co/blog/benefits-of-walking">https://klimy.co/blog/benefits-of-walking</a></em></p>]]>
            </description>
            <link>https://klimy.co/blog/benefits-of-walking</link>
            <guid isPermaLink="false">hacker-news-small-sites-25316328</guid>
            <pubDate>Sat, 05 Dec 2020 17:28:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Improbable Inspiration: Bayesian Networks (1996)]]>
            </title>
            <description>
<![CDATA[
Score 91 | Comments 19 (<a href="https://news.ycombinator.com/item?id=25315982">thread link</a>) | @1e
<br/>
December 5, 2020 | https://www.cs.ubc.ca/~murphyk/Bayes/la.times.html | <a href="https://web.archive.org/web/*/https://www.cs.ubc.ca/~murphyk/Bayes/la.times.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <td>

      <span face="Arial,Helvetica" color="#003366">

      <b>Improbable Inspiration</b><p>
      The future of software may lie in the obscure theories of an
      18th century cleric named Thomas Bayes.

      </p><p>

      By LESLIE HELM, Times Staff Writer

      </p><hr>
      <p>

      When Microsoft Senior Vice President Steve
      Ballmer first heard his company was planning to make a huge
      investment in an Internet service offering movie reviews and
      local entertainment information in major cities across the
      nation, he went to Chairman Bill Gates with his concerns.

      </p><p>

      &nbsp;&nbsp;&nbsp; After all, Ballmer has billions of dollars of
      his own money in Microsoft stock, and entertainment isn't
      exactly the company's strong point.

      </p><p>

      &nbsp;&nbsp;&nbsp; But Gates dismissed such
      reservations. Microsoft's competitive advantage, he responded,
      was its expertise in "Bayesian networks."

      </p><p>

      &nbsp;&nbsp;&nbsp; Asked recently when computers would finally
      begin to understand human speech, Gates began discussing the
      critical role of "Bayesian" systems.

      </p><p>

      &nbsp;&nbsp;&nbsp; Ask any other software executive about
      anything "Bayesian" and you're liable to get a blank
      stare.

      </p><p> 

      &nbsp;&nbsp;&nbsp; Is Gates onto something? Is this
      alien-sounding technology Microsoft's new secret weapon?

      </p><p>

      &nbsp;&nbsp;&nbsp; Quite possibly.
      
      </p><p>

      &nbsp;&nbsp;&nbsp; Bayesian networks are complex diagrams that
      organize the body of knowledge in any given area by mapping out
      cause-and-effect relationships among key variables and encoding
      them with numbers that represent the extent to which one
      variable is likely to affect another.

      </p><p>

      &nbsp;&nbsp;&nbsp; Programmed into computers, these systems can
      automatically generate optimal predictions or decisions even
      when key pieces of information are missing.

      </p><p>

      &nbsp;&nbsp;&nbsp; When Microsoft in 1993 hired Eric Horvitz,
      David Heckerman and Jack Breese, pioneers in the development of
      Bayesian systems, colleagues in the field were surprised. The
      field was still an obscure, largely academic enterprise.

      </p><p>
 
      &nbsp;&nbsp;&nbsp; Today the field is still obscure. But scratch
      the surface of a range of new Microsoft products and you're
      likely to find Bayesian networks embedded in the software. And
      Bayesian nets are being built into models that are used to
      predict oil and stock prices, control the space shuttle and
      diagnose disease.

      </p><p>

      &nbsp;&nbsp;&nbsp; Artificial intelligence (AI) experts, who saw
      their field discredited in the early 1980s after promising a
      wave of "thinking" computers that they ultimately
      couldn't produce, believe widening acceptance of the Bayesian
      approach could herald a renaissance in the field.

      </p><p>
      
      &nbsp;&nbsp;&nbsp; Bayesian networks provide "an
      overarching graphical framework" that brings together
      diverse elements of AI and increases the range of its likely
      application to the real world, says Michael Jordon, professor of
      brain and cognitive science at the Massachusetts Institute of
      Technology.

      </p><p>

      &nbsp;&nbsp;&nbsp; Microsoft is unquestionably the most
      aggressive in exploiting the new approach. The company offers a
      free Web service that helps customers diagnose printing problems
      with their computers and recommends the quickest way to resolve
      them. Another Web service helps parents diagnose their
      children's health problems.

      </p><p>

      &nbsp;&nbsp;&nbsp; The latest version of Microsoft Office
      software uses the technology to offer a user help based on past
      experience, how the mouse is being moved and what task is being
      done.

      </p><p>

      &nbsp;&nbsp;&nbsp; "If his actions show he is distracted,
      he is likely to need help," Horvitz says. "If he's
      been working on a chart, chances are he needs help formatting
      the chart."

      </p><p>

      &nbsp;&nbsp;&nbsp; "Gates likes to talk about how computers
      are now deaf, dumb, blind and clueless. The Bayesian stuff helps
      deal with the clueless part," says Daniel T.  Ling,
      director of Microsoft's research division and a former IBM
      scientist.

      </p><p>

      &nbsp;&nbsp;&nbsp; Bayesian networks get their name from the
      Rev. Thomas Bayes, who wrote an essay, posthumously published in
      1763, that offered a mathematical formula for calculating
      probabilities among several variables that are causally related
      but for which--unlike calculating the probability of a coin
      landing on heads or tails--the relationships can't easily be
      derived by experimentation.

      </p><p>

      &nbsp;&nbsp;&nbsp; Early students of probability applied the
      ideas to discussions about the existence of God or efforts to
      improve their odds in gambling. Much later, social scientists
      used it to help clarify the key factors influencing a particular
      event.

      </p><p>

      &nbsp;&nbsp;&nbsp; But it was the rapid progress in computer
      power and the development of key mathematical equations that
      made it possible for the first time, in the late 1980s, to
      compute Bayesian networks with enough variables that they were
      useful in practical applications.

      </p><p>

      &nbsp;&nbsp;&nbsp; The Bayesian approach filled a void in the
      decades-long effort to add intelligence to computers.

      </p><p>

      &nbsp;&nbsp;&nbsp; In the late 1970s and '80s, reacting to the
      "brute force" approach to problem solving by early
      users of computers, proponents of the emerging field of
      artificial intelligence began developing software programs using
      rule-based, if-then propositions. But the systems took time to
      put together and didn't work well if, as was frequently the
      case, you couldn't answer all the computer's questions clearly.

      </p><p>

      &nbsp;&nbsp;&nbsp; Later companies began using a technique
      called "neural nets" in which a computer would be
      presented with huge amounts of data on a particular problem and
      programmed to pull out patterns. A computer fed with a big stack
      of X-rays and told whether or not cancer was present in each
      case would pick out patterns that would then be used to
      interpret X-rays.

      </p><p>

      &nbsp;&nbsp;&nbsp; But the neural nets won't help predict the
      unforeseen. You can't train a neural net to identify an incoming
      missile or plane because you could never get sufficient data to
      train the system.

      </p><p>

      &nbsp;&nbsp;&nbsp; In part because of these limitations, a slew
      of companies that popped up in the early 1980s to sell
      artificial intelligence systems virtually all went bankrupt.

      </p><p>

      &nbsp;&nbsp;&nbsp; Many AI techniques continued to be
      used. Credit card companies, for example, began routinely using
      neural networks to pick out transactions that don't look right
      based on a consumer's past behavior. But increasingly, AI was
      regarded as a tool with limited use.

      </p><p>

      &nbsp;&nbsp;&nbsp; Then, in the late 1980s--spurred by the early
      work of Judea Pearl, a professor of computer science at UCLA,
      and breakthrough mathematical equations by <a href="http://www.hugin.dk/">Danish researchers</a>--AI
      researchers discovered that Bayesian networks offered an
      efficient way to deal with the lack or ambiguity of information
      that has hampered previous systems.

      </p><p>

      &nbsp;&nbsp;&nbsp; Horvitz and his two Microsoft colleagues, who
      were then classmates at Stanford University, began building
      Bayesian networks to help diagnose the condition of patients
      without turning to surgery.

      </p><p>

      &nbsp;&nbsp;&nbsp; The approach was efficient, says Horvitz,
      because you could combine historical data, which had been
      meticulously gathered, with the less precise but more intuitive
      knowledge of experts on how things work to get the optimal
      answer given the information available at a given time.

      </p><p>

      &nbsp;&nbsp;&nbsp; Horvitz, who with two colleagues founded
      Knowledge Industries to develop tools for developing Bayesian
      networks, says he and the others left the company to join
      Microsoft in part because they wanted to see their theoretical
      work more broadly applied.

      </p><p>

      &nbsp;&nbsp;&nbsp; Although the company did important work for
      the National Aeronautics and Space Administration and on medical
      diagnostics, Horvitz says, "It's not like your grandmother
      will use it."

      </p><p>

      &nbsp;&nbsp;&nbsp; Microsoft's activities in the field are now
      helping to build a groundswell of support for Bayesian ideas.

      </p><p>

      &nbsp;&nbsp;&nbsp; "People look up to Microsoft," says
      Pearl, who wrote one of the key early texts on Bayesian networks
      in 1988 and has become an unofficial spokesman for the
      field. "They've given a boost to the whole area."
                     
      </p><p>

      &nbsp;&nbsp;&nbsp; A researcher at German conglomerate Siemens
      says Microsoft's work has drawn the attention of his superiors,
      who are now looking seriously at applying Bayesian concepts to a
      range of industrial applications.

      </p><p>

      &nbsp;&nbsp;&nbsp; Scott Musman, a computer consultant in
      Arlington, Va., recently designed a Bayesian network for the
      Navy that can identify enemy missiles, aircraft or vessels and
      recommend which weapons could be used most advantageously
      against incoming targets.

      </p><p>

      &nbsp;&nbsp;&nbsp; Musman says previous attempts using
      traditional mathematical approaches on state-of-the-art
      computers would get the right answer but would take two to three
      minutes.

      </p><p>

      &nbsp;&nbsp;&nbsp; "But you only have 30 seconds before the
      missile has hit you," says Musman.

      </p><p>

      &nbsp;&nbsp;&nbsp; General Electric is using Bayesian techniques
      to develop a system that will take information from sensors
      attached to an engine and, based on expert opinion built into
      the system as well as vast amounts of data on past engine
      performance, pinpoint emerging problems.

      </p><p>

      &nbsp;&nbsp;&nbsp; Microsoft is working on techniques that will
      enable the Bayesian networks to "learn" or update
      themselves …</p></span></td></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.cs.ubc.ca/~murphyk/Bayes/la.times.html">https://www.cs.ubc.ca/~murphyk/Bayes/la.times.html</a></em></p>]]>
            </description>
            <link>https://www.cs.ubc.ca/~murphyk/Bayes/la.times.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25315982</guid>
            <pubDate>Sat, 05 Dec 2020 16:53:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Major Flaws of Human Thinking]]>
            </title>
            <description>
<![CDATA[
Score 181 | Comments 89 (<a href="https://news.ycombinator.com/item?id=25315667">thread link</a>) | @dandanua
<br/>
December 5, 2020 | https://dandanua.github.io/posts/major-flaws-of-human-thinking/ | <a href="https://web.archive.org/web/*/https://dandanua.github.io/posts/major-flaws-of-human-thinking/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>As in the lovely child’s quote found on the internet —</p><blockquote><p>I know everything. Except anything I don’t.</p></blockquote><p>— we think that we see everything around us. But we don’t. There are so many things that greatly affect our lives, yet we don’t aware of them. One type of such things is deep inside us — the flaws of our own thinking. Here is my top list of those flaws.</p><h2 id="1-wishful-thinking-conservatism-and-conformism"><strong>1. Wishful thinking, conservatism and conformism</strong></h2><p>By <em>wishful thinking</em> I don’t mean optimism, which is rather speculation about the future. Wishful thinking is when we put more weight on the present knowledge that is pleasant to us, and at the same time ignore the knowledge that is not so nice. For example, people like to ignore the knowledge that puts them in a bad light. This is clearly seen in toxic relationships, where an abuser justifies his actions by “the care” of its victim. A dictator probably thinks that he is doing the best for its nation, while completely ignoring his incapabilities and bad doings. The same is true for groups of people or even nations. An invasion is commonly portrayed as liberation.</p><p>On the other hand, anyone who had experienced an addiction probably knows how it can alter decision-making. “Vodka is an antiseptic, didn’t you know? Let’s drink those bottles so we’ll be healthier!” Gambler thinks that he is going to make money, so his family will be happy. An ordinary gamer thinks that other real affairs are not that important, so it’s ok to spend more time on the game.</p><p>This is just few examples, but such thinking is so common that I don’t think a single book will be enough to collect all different “use cases”.</p><hr><p>Another flaw of our thinking is <em>conservatism</em> — an insufficient ability to change our common views and beliefs with the new data, new evidence. This is understandable — changing basis views leads to a reconsideration of all related knowledge. An enormous amount of rebuilding is required. Our biological brains just can’t do that in a short time, also it’s much harder with age. Because of this, we give much more weight to old knowledge rather than new evidence, thus making a conservatism bias.</p><p>In our rapidly changing world, this problem will have even more impact.</p><hr><p><em>Conformism</em> is when we weigh our knowledge in accordance with our community. The effect of this is highly underrated. An ordinary human thinks that “her thoughts are her own”, without realizing to what extent they are shaped by a community. I think that we’re all conformists to some degree. And it’s hard to imagine what’s that means not to be. This is proved by numerous experiments with a group of actors and one unsuspicious testee, where actors trick the testee to make some ridiculous statements or to do some crazy actions, like the one described <a href="https://www.youtube.com/watch?v=vjP22DpYYh8">here</a>. We are social creatures.</p><p>An extreme version of conformist thinking is the one imposed by religion. I’m not against religions in general, they can be useful, but a blind belief, an unquestioning subordination to “sacred” authorities — that’s just a disaster for a clear mind. A clear mind should have the ability to stress any dogmas.</p><h2 id="2-binary-black-and-white-thinking-overgeneralization"><strong>2. Binary (black-and-white) thinking, overgeneralization</strong></h2><p>Good-evil, smart-stupid, beautiful-ugly, tall-short, fast-slow, and so on and on. We think in binary terms. Our language reflects that. And some people are stuck very hard in such thinking. The worst case of it is <em>all-or-nothing</em> thinking, when any result other than the best is considered as a failure. It causes stress and depression in people. They don’t realize anymore why the world is so mean to them. They stop seeing how many gradients are there, and also how colorful our world is.</p><p>A similar flaw is <em>overgeneralization</em>. We put into the same category very broad types of information. Prejudice, labeling, stereotypes are all related to overgeneralization.</p><h2 id="3-self-projecting-thinking"><strong>3. Self-projecting thinking</strong></h2><p>Mind reading is an ability that everyone would like to have. It would be so easier to communicate. Also, it’s an advantage if we could read the thoughts of our rivals. While we can’t do it in reality, we’re still trying to predict other people’s thoughts, both in collaboration and confrontation.</p><p>To make such predictions we use two main assumptions:</p><ol><li>Other people see the same things as we do.</li><li>Other people are like us, thus their way of thinking is similar to ours.</li></ol><p>Based on these assumptions we use our way of thinking to deduce the thoughts of others. And this is very natural since we have to model another person’s thinking somehow. But the only model that we have is ours. It’s the only model that we can use. So, we essentially project our mind into another person’s head.</p><p>This has a fatal flaw. Because both main assumptions are only half true. While we see the same bits of the world, perception is a way more complex process. From bits we see high-order patterns, but they can be very personal. People could see different patterns and focus on different things. Also, the same bits (e.g. colors) can cause different emotions. Associations are also personal. The way we do conclusions is also very different in people because every person has its own experience, principles, beliefs, preferences, etc. We do not understand how unique the mind of every human.</p><p>And this causes a lot of trouble. People are fighting because of misunderstandings. In most situations they don’t realize, that they are fighting against their own reflection (from a distorting mirror).</p><h2 id="4-human-centric-thinking"><strong>4. Human-centric thinking</strong></h2><p>Humans are extremely focused on their own businesses. Yes, we are successful as a whole, in comparison to other creatures. But we are still part of nature. We follow its laws. Despite this, we neglect nature and the life of other species at scale.</p><p>Moreover, we value leaders, rulers and heroes amongst us much more than others. Even in fiction secondary characters usually die (who cares), while all hail goes to the main performers. We think that leaders are responsible for like 99% of the job done. Thus, we are trying to analyze them, rather than abstract patterns, situations and laws of nature. For example, from the popular culture it may look like Hitler was solely responsible for WWII and the Holocaust. Yeah, sure. How about WWI? Or any other war, genocide, mass conflict in human history? It’s silly to think that all these things were mainly because of leaders. This is just how humans work. In every moment in history there is a mix of wishes, intentions, beliefs, possibilities, thoughts of a total population. It could be that nature just picks a random guy as a leader that represents the mass.</p><p>On the other hand, we think that human is a singular, indivisible unit. That’s also not true. We are a composition of attributes, that are selected by evolution. Any child has some attributes from its mother and some attributes from its father. Human is a composable organism, the same is true for its mind. I’m sure that everyone experienced competing thoughts in his head. There is a natural selection of thoughts ongoing in the mind of every human.</p><h2 id="5-false-associations-confusion-of-causation-and-correlation"><strong>5. False associations, confusion of causation and correlation</strong></h2><p>Our thinking is associative, and we can make connections very fast based on very small data. A typical example is superstition, which is clearly seen in <a href="https://www.psychologistworld.com/superstition">pigeon experiments</a>.</p><p>Survival bias and filtering are accompanying flaws that lead to false associations. In probability theory, this is related to the fact that independent events are not necessary conditionally independent.</p><p>Even when our associations are quite objective we can make false conclusions about the causes. In fact, in probability theory and statistics the notion of a <em>cause</em> is not even defined. Events can be either correlated or independent in this theory. To deduce <em>what causes what</em> we use other tools, like common sense, physics, etc. Typically, to deduce a causation from two correlated events, we check two main things:</p><ol><li>One event is earlier in time than another one.</li><li>There is no common cause that could explain the correlation.</li></ol><p>This is hard stuff even for scientists. Because you have to exclude any possible common cause. Earlier we could use physical locality of events to exclude a lot of possible common causes. But with the advance of quantum mechanics, even locality is not a reliable factor anymore.</p><h2 id="final-words"><strong>Final words</strong></h2><p>There are a lot of other flaws, if you want to learn more you can start <a href="https://en.wikipedia.org/wiki/Cognitive_bias">here</a> and <a href="https://en.wikipedia.org/wiki/Cognitive_distortion">here</a>. But those described above I find the most impactful. I feel them myself and meet them all the time.</p></div></div>]]>
            </description>
            <link>https://dandanua.github.io/posts/major-flaws-of-human-thinking/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25315667</guid>
            <pubDate>Sat, 05 Dec 2020 16:22:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: I Wrote a Book on Data Analysis with Rust Notebooks]]>
            </title>
            <description>
<![CDATA[
Score 97 | Comments 27 (<a href="https://news.ycombinator.com/item?id=25314170">thread link</a>) | @DataCrayon
<br/>
December 5, 2020 | https://datacrayon.com/shop/product/data-analysis-with-rust-notebooks/ | <a href="https://web.archive.org/web/*/https://datacrayon.com/shop/product/data-analysis-with-rust-notebooks/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main-content">
    <div id="et-boc">
			
		<!-- #end wrapper --><div>
			<div>
		<div>
				
				
				
				
					<div>
				<div>
				
				
				<div>
				
				
				
				
				<p>A practical book on Data Analysis with Rust Notebooks that teaches you the concepts and how they’re implemented in practice.</p>
			</div>
			</div> <!-- .et_pb_column --><div>
				
				
				<div>
				
				
				
				
				<div>
					<div data-columns="4">
	<figure>
		<p><a href="https://datacrayon.com/shop/wp-content/uploads/2020/02/cover_darn.jpg"><img width="480" height="679" src="https://datacrayon.com/shop/wp-content/uploads/2020/02/cover_darn.jpg" alt="" loading="lazy" title="cover_darn" data-caption="" data-src="https://datacrayon.com/shop/wp-content/uploads/2020/02/cover_darn.jpg" data-large_image="https://datacrayon.com/shop/wp-content/uploads/2020/02/cover_darn.jpg" data-large_image_width="480" data-large_image_height="679" srcset="https://datacrayon.com/shop/wp-content/uploads/2020/02/cover_darn.jpg 480w, https://datacrayon.com/shop/wp-content/uploads/2020/02/cover_darn-212x300.jpg 212w, https://datacrayon.com/shop/wp-content/uploads/2020/02/cover_darn-300x424.jpg 300w" sizes="(max-width: 480px) 100vw, 480px"></a></p>	</figure>
</div>

				</div>
			</div>
			</div> <!-- .et_pb_column -->
				
				
			</div> <!-- .et_pb_row -->
				
				
			</div> <!-- .et_pb_section --><div>
				
				
				
				<div>
					 <!-- .et_pb_column --><div>
				
				
				 <!-- .et_pb_row_inner --><div>
				<div>
				
				
				<div>
				
				
				<ul>
					<li><a href="#">Description</a></li>
				</ul>
				<div>
					<div>
					<div>
						<p>A practical book on Data Analysis with Rust Notebooks that teaches you the concepts and how they're implemented in practice.</p>
<ul>
<li><strong>Discounted</strong>&nbsp;<strong>Price</strong> that will grow as the book does,</li>
<li>All code examples in <strong>Rust</strong>,</li>
<li><strong>Rust (Jupyter) Notebooks</strong> for each Section,</li>
<li>Supplementary <strong>Video Tutorials</strong>,</li>
<li>Format: <strong>PDF download</strong>,</li>
<li><strong>Unlimited</strong> downloads and access to updates.</li>
</ul>
<p>Get it now to enhance your work in Rust, NDArray, Data Science, Data Analysis, and Machine Learning.</p>

					</div><!-- .et_pb_tab_content" -->
				</div>
				</div> <!-- .et_pb_all_tabs -->
			</div> <!-- .et_pb_tabs -->
			</div> <!-- .et_pb_column -->
				
				
			</div> <!-- .et_pb_row_inner -->
			</div> <!-- .et_pb_column -->
				</div> <!-- .et_pb_row -->
				
			</div> <!-- .et_pb_section --> <!-- .et_pb_section --><div>
				
				
				
				
					<div>
				<div>
				
				
				 <!-- .et_pb_text --><p><span><img src="https://store.shahinrostami.com/wp-content/uploads/2020/07/shahin_square.jpg" alt="" title="shahin_square" srcset="https://datacrayon.com/shop/wp-content/uploads/2020/07/shahin_square.jpg 288w, https://datacrayon.com/shop/wp-content/uploads/2020/07/shahin_square-150x150.jpg 150w, https://datacrayon.com/shop/wp-content/uploads/2020/07/shahin_square-100x100.jpg 100w" sizes="(max-width: 288px) 100vw, 288px"></span>
			</p>
			</div> <!-- .et_pb_column --><div>
				
				
				<div>
				
				
				<div><p>Dr. Shahin Rostami is a <a href="http://staffprofiles.bournemouth.ac.uk/display/srostami" target="_blank" rel="noopener noreferrer">Senior Academic (Associate Professor)</a> and <a href="https://www.linkedin.com/in/shahinrostami/" target="_blank" rel="noopener noreferrer">Consultant</a> in Data Science and Artificial Intelligence, with applications in the areas of Healthcare and Defence.</p>
<p>As a <a href="https://www.heacademy.ac.uk/system/files/downloads/UK%20Professional%20Standards%20Framework%20%28PSF%29_1.pdf">Senior Fellow</a> of the Higher Education Academy and <a href="https://shahinrostami.com/">Programme Leader</a> for many postgraduate programmes, he aims to contribute openly available learning resources through this website and his <a href="https://www.youtube.com/shahinrostami" target="_blank" rel="noopener noreferrer">YouTube channel</a>.</p></div>
			</div> <!-- .et_pb_text --><div>
				
				
				<p>Dr. Rostami writes and maintains the works published and offered through this website. You can expect ongoing updates and support through the communication channels listed below.</p>
			</div> <!-- .et_pb_text --> <!-- .et_pb_text --><ul>
				
				
				<li><a href="https://twitter.com/shahinrostami" title="Follow on Twitter" target="_blank"></a></li><li><a href="https://www.youtube.com/ShahinRostami" title="Follow on Youtube" target="_blank"></a></li><li><a href="https://www.linkedin.com/in/shahinrostami/" title="Follow on LinkedIn" target="_blank"></a></li><li><a href="https://www.instagram.com/stamilabs/" title="Follow on Instagram" target="_blank"></a></li>
			</ul> <!-- .et_pb_counters -->
			</div> <!-- .et_pb_column -->
				
				
			</div> <!-- .et_pb_row -->
				
				
			</div> <!-- .et_pb_section --><div>
				
				
				
				
					<div>
				<div>
				
				
				<p><span><img src="https://store.shahinrostami.com/wp-content/uploads/2020/07/author-icon-03-2.png" alt="" title=""></span>
			</p><div>
				
				
				<div><p>The aim is to generate everything in this book through code! This means you’ll see the code for all the figures and tables, including things like flowcharts.</p>
<p>Every section is intended to be independent and <span jsslot=""><span data-dobid="hdw">reproducible</span></span>, so you’ll find some repetition as you progress from one section to another.</p></div>
			</div> <!-- .et_pb_text -->
			</div> <!-- .et_pb_column -->
				
				
			</div> <!-- .et_pb_row -->
				
				
			</div> <!-- .et_pb_section --><div>
				
				
				
				
					<div>
				<div>
				
				
				<div>
				
				
				<div><h2>10% discount on books.</h2>
<p>Join the newsletter to receive book and software updates, as well as discounts and occasional freebies! Your email will only used for this newsletter.</p></div>
			</div> <!-- .et_pb_text --> <!-- .et_pb_code --><ul>
				
				
				<li><a href="https://twitter.com/shahinrostami" title="Follow on Twitter" target="_blank"></a></li><li><a href="https://www.youtube.com/ShahinRostami" title="Follow on Youtube" target="_blank"></a></li><li><a href="https://www.linkedin.com/in/shahinrostami/" title="Follow on LinkedIn" target="_blank"></a></li><li><a href="https://www.instagram.com/stamilabs/" title="Follow on Instagram" target="_blank"></a></li>
			</ul> <!-- .et_pb_counters -->
			</div> <!-- .et_pb_column --> <!-- .et_pb_column -->
				
				
			</div> <!-- .et_pb_row -->
				
				
			</div> <!-- .et_pb_section -->		</div><!-- .et_builder_inner_content -->
	</div><!-- .et-l -->
	
			
		</div><!-- #et-boc -->
		    </div></div>]]>
            </description>
            <link>https://datacrayon.com/shop/product/data-analysis-with-rust-notebooks/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25314170</guid>
            <pubDate>Sat, 05 Dec 2020 12:52:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Std::visit is everything wrong with modern C++ (2017)]]>
            </title>
            <description>
<![CDATA[
Score 108 | Comments 206 (<a href="https://news.ycombinator.com/item?id=25314126">thread link</a>) | @xucheng
<br/>
December 5, 2020 | https://bitbashing.io/std-visit.html | <a href="https://web.archive.org/web/*/https://bitbashing.io/std-visit.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
    <!--
Sorry once again for the infrequent posts.
I've been busy.
Originally, because I was supposed to get married this summer.
Then because my fiancée cheated on me while I was watching my grandfather die
and moved in with the other guy the following week.
So that's been fun, but I'm trying to get back into some more productive habits.
Hopefully that includes blogging regularly.
-->

<h2 id="sum-types-and-you">Sum Types and You</h2>

<p>Let’s talk about a simple, yet powerful concept in programming: <em>sum types</em>.<sup id="fnref:1"><a href="#fn:1">1</a></sup></p>

<p>A sum type, also called a <em>discriminated union</em>,
can hold one (and only one) of several types of things.
For example, consider some settings in an
<a href="https://en.wikipedia.org/wiki/INI_file">INI</a>-like configuration file.
Let’s say that each setting must be a string, an integer, or a Boolean value.
If we wanted to roll our own solution in C++, we might write something resembling:</p>

<div><pre><code><span>struct</span> <span>Setting</span> <span>{</span>
    <span>union</span> <span>{</span>
        <span>string</span> <span>str</span><span>;</span>
        <span>int</span> <span>num</span><span>;</span>
        <span>bool</span> <span>b</span><span>;</span>
    <span>};</span>
    <span>enum</span> <span>Type</span> <span>{</span> <span>Str</span><span>,</span> <span>Int</span><span>,</span> <span>Bool</span> <span>};</span>
    <span>Type</span> <span>tag</span><span>;</span>
<span>};</span>

<span>// Map settings to their names.
</span><span>using</span> <span>Settings</span> <span>=</span> <span>unordered_map</span><span>&lt;</span><span>string</span><span>,</span> <span>Setting</span><span>&gt;</span><span>;</span>
</code></pre>
</div>

<p>Here be dragons, though, since we must always remember to:</p>

<ul>
  <li>
    <p>Update <code>tag</code> whenever assigning a new value.</p>
  </li>
  <li>
    <p>Only retrieve the correct type from the union (according to <code>tag</code>).</p>
  </li>
  <li>
    <p>Call constructors and destructors at appropriate times for all non-trivial types.
(<code>string</code> is the only one here, but you could imagine similar
scenarios with others.)</p>
  </li>
</ul>

<p>If a step is ever forgotten, the object falls into an
inconsistent state and there shall be wailing and gnashing of teeth.
You could encapsulate all this trickery and interact with the type
through a series of methods—e.g., <code>getType()</code>, <code>asBool()</code>,
<code>asString()</code>, and so on—but this is quite verbose.
It also just shifts the problem onto whoever implements these methods; they
still need to carefully maintain the invariants with no help from the language.</p>

<p>It would be much nicer if a general-purpose sum type was provided by the standard
library.
In C++17, we finally get one!
It’s called <a href="http://en.cppreference.com/w/cpp/utility/variant"><code>std::variant</code></a>.
Let’s take a look.</p>

<h2 id="using-stdvariant">Using <code>std::variant</code></h2>

<p><code>variant</code> is a class template that takes, as template parameters, the types
it could hold.
For the example above,
we could define a setting as a <code><span>variant</span><span>&lt;</span><span>string</span><span>,</span> <span>int</span><span>,</span> <span>bool</span><span>&gt;</span></code>.
Assigning a value to a <code>variant</code> works just like you might expect:</p>
<div><pre><code><span>variant</span><span>&lt;</span><span>string</span><span>,</span> <span>int</span><span>,</span> <span>bool</span><span>&gt;</span> <span>mySetting</span> <span>=</span> <span>string</span><span>(</span><span>"Hello!"</span><span>);</span> <span>// Or,
</span><span>mySetting</span> <span>=</span> <span>42</span><span>;</span> <span>// Or,
</span><span>mySetting</span> <span>=</span> <span>false</span><span>;</span>
</code></pre>
</div>

<p>Once we put a value into a <code>variant</code>, we’ll eventually want to look at what that
value is, and just as importantly, what the type of the value is.
This is where the fun begins.
Some languages offer dedicated <em>pattern matching</em> syntax for the task,
such as:</p>
<div><pre><code><span>match</span> <span>(</span><span>theSetting</span><span>)</span> <span>{</span>
    <span>Setting</span><span>::</span><span>Str</span><span>(</span><span>s</span><span>)</span> <span>=&gt;</span>
        <span>println!</span><span>(</span><span>"A string: {}"</span><span>,</span> <span>s</span><span>),</span>
    <span>Setting</span><span>::</span><span>Int</span><span>(</span><span>n</span><span>)</span> <span>=&gt;</span>
        <span>println!</span><span>(</span><span>"An integer: {}"</span><span>,</span> <span>n</span><span>),</span>
    <span>Setting</span><span>::</span><span>Bool</span><span>(</span><span>b</span><span>)</span> <span>=&gt;</span>
        <span>println!</span><span>(</span><span>"A boolean: {}"</span><span>,</span> <span>b</span><span>),</span>
<span>};</span>
</code></pre>
</div>
<p>but this didn’t make the cut for C++17.<sup id="fnref:2"><a href="#fn:2">2</a></sup>
Instead we’re given a companion function called <code>std::visit</code>.
It takes the <code>variant</code> you want to examine, along with
some <em>visitor</em> that is callable for each type in the variant.</p>

<p>How do we define such a visitor?
One way is to create an object that overloads the call operator
for relevant types:</p>
<div><pre><code><span>struct</span> <span>SettingVisitor</span> <span>{</span>
    <span>void</span> <span>operator</span><span>()(</span><span>const</span> <span>string</span><span>&amp;</span> <span>s</span><span>)</span> <span>const</span> <span>{</span>
        <span>printf</span><span>(</span><span>"A string: %s</span><span>\n</span><span>"</span><span>,</span> <span>s</span><span>.</span><span>c_str</span><span>());</span>
    <span>}</span>

    <span>void</span> <span>operator</span><span>()(</span><span>const</span> <span>int</span> <span>n</span><span>)</span> <span>const</span> <span>{</span>
        <span>printf</span><span>(</span><span>"An integer: %d</span><span>\n</span><span>"</span><span>,</span> <span>n</span><span>);</span>
    <span>}</span>

    <span>void</span> <span>operator</span><span>()(</span><span>const</span> <span>bool</span> <span>b</span><span>)</span> <span>const</span> <span>{</span>
        <span>printf</span><span>(</span><span>"A boolean: %d</span><span>\n</span><span>"</span><span>,</span> <span>b</span><span>);</span>
    <span>}</span>
<span>};</span>
</code></pre>
</div>

<p>This seems terribly verbose, and it gets even worse
if we want our visitor to capture or modify some other state.
Hmm—<a href="https://stackoverflow.com/a/7627218">lambdas</a> are perfect
for capturing state.
What if we could build a visitor from those?</p>
<div><pre><code><span>make_visitor</span><span>(</span>
    <span>[</span><span>&amp;</span><span>](</span><span>const</span> <span>string</span><span>&amp;</span> <span>s</span><span>)</span> <span>{</span>
        <span>printf</span><span>(</span><span>"string: %s</span><span>\n</span><span>"</span><span>,</span> <span>s</span><span>.</span><span>c_str</span><span>());</span>
        <span>// ...
</span>    <span>},</span>
    <span>[</span><span>&amp;</span><span>](</span><span>const</span> <span>int</span> <span>d</span><span>)</span> <span>{</span>
        <span>printf</span><span>(</span><span>"integer: %d</span><span>\n</span><span>"</span><span>,</span> <span>d</span><span>);</span>
        <span>// ...
</span>    <span>},</span>
    <span>[</span><span>&amp;</span><span>](</span><span>const</span> <span>bool</span> <span>b</span><span>)</span> <span>{</span>
        <span>printf</span><span>(</span><span>"bool: %d</span><span>\n</span><span>"</span><span>,</span> <span>b</span><span>);</span>
        <span>// ...
</span>    <span>}</span>
<span>)</span>
</code></pre>
</div>
<p>That’s a bit better, but the standard library doesn’t provide any sort of
<code>make_visitor</code> to combine the lambdas into a callable object for us.
We’ll need to define it ourselves.</p>

<div><pre><code><span>template</span> <span>&lt;</span><span>class</span><span>...</span> <span>Fs</span><span>&gt;</span>
<span>struct</span> <span>overload</span><span>;</span>

<span>template</span> <span>&lt;</span><span>class</span> <span>F0</span><span>,</span> <span>class</span><span>...</span> <span>Frest</span><span>&gt;</span>
<span>struct</span> <span>overload</span><span>&lt;</span><span>F0</span><span>,</span> <span>Frest</span><span>...</span><span>&gt;</span> <span>:</span> <span>F0</span><span>,</span> <span>overload</span><span>&lt;</span><span>Frest</span><span>...</span><span>&gt;</span>
<span>{</span>
    <span>overload</span><span>(</span><span>F0</span> <span>f0</span><span>,</span> <span>Frest</span><span>...</span> <span>rest</span><span>)</span> <span>:</span> <span>F0</span><span>(</span><span>f0</span><span>),</span> <span>overload</span><span>&lt;</span><span>Frest</span><span>...</span><span>&gt;</span><span>(</span><span>rest</span><span>...)</span> <span>{}</span>

    <span>using</span> <span>F0</span><span>::</span><span>operator</span><span>();</span>
    <span>using</span> <span>overload</span><span>&lt;</span><span>Frest</span><span>...</span><span>&gt;::</span><span>operator</span><span>();</span>
<span>};</span>

<span>template</span> <span>&lt;</span><span>class</span> <span>F0</span><span>&gt;</span>
<span>struct</span> <span>overload</span><span>&lt;</span><span>F0</span><span>&gt;</span> <span>:</span> <span>F0</span>
<span>{</span>
    <span>overload</span><span>(</span><span>F0</span> <span>f0</span><span>)</span> <span>:</span> <span>F0</span><span>(</span><span>f0</span><span>)</span> <span>{}</span>

    <span>using</span> <span>F0</span><span>::</span><span>operator</span><span>();</span>
<span>};</span>

<span>template</span> <span>&lt;</span><span>class</span><span>...</span> <span>Fs</span><span>&gt;</span>
<span>auto</span> <span>make_visitor</span><span>(</span><span>Fs</span><span>...</span> <span>fs</span><span>)</span>
<span>{</span>
    <span>return</span> <span>overload</span><span>&lt;</span><span>Fs</span><span>...</span><span>&gt;</span><span>(</span><span>fs</span><span>...);</span>
<span>}</span>
</code></pre>
</div>

<p>Here we use C++11’s <a href="http://en.cppreference.com/w/cpp/language/parameter_pack">variadic templates</a>.
They must be defined recursively, so we create some base case <code>F0</code>,
then use that to define a cascading set of constructors for <code>overload</code>,
each of which peels off a lambda argument and adds it to the type
as a call operator.</p>

<p>If this seems troublesome, fear not! C++17 will offer a new syntax
that reduces all of the above to:</p>
<div><pre><code><span>template</span><span>&lt;</span><span>class</span><span>...</span> <span>Ts</span><span>&gt;</span> <span>struct</span> <span>overloaded</span> <span>:</span> <span>Ts</span><span>...</span> <span>{</span> <span>using</span> <span>Ts</span><span>::</span><span>operator</span><span>()...;</span> <span>};</span>
<span>template</span><span>&lt;</span><span>class</span><span>...</span> <span>Ts</span><span>&gt;</span> <span>overloaded</span><span>(</span><span>Ts</span><span>...)</span> <span>-&gt;</span> <span>overloaded</span><span>&lt;</span><span>Ts</span><span>...</span><span>&gt;</span><span>;</span>
</code></pre>
</div>
<p>Easy, right? But if don’t like any of these options, you could
use C++17’s compile-time conditionals instead:</p>
<div><pre><code><span>[](</span><span>auto</span><span>&amp;</span> <span>arg</span><span>)</span> <span>{</span>
    <span>using</span> <span>T</span> <span>=</span> <span>std</span><span>::</span><span>decay_t</span><span>&lt;</span><span>decltype</span><span>(</span><span>arg</span><span>)</span><span>&gt;</span><span>;</span>

    <span>if</span> <span>constexpr</span> <span>(</span><span>std</span><span>::</span><span>is_same_v</span><span>&lt;</span><span>T</span><span>,</span> <span>string</span><span>&gt;</span><span>)</span> <span>{</span>
        <span>printf</span><span>(</span><span>"string: %s</span><span>\n</span><span>"</span><span>,</span> <span>arg</span><span>.</span><span>c_str</span><span>());</span>
        <span>// ...
</span>    <span>}</span>
    <span>else</span> <span>if</span> <span>constexpr</span> <span>(</span><span>std</span><span>::</span><span>is_same_v</span><span>&lt;</span><span>T</span><span>,</span> <span>int</span><span>&gt;</span><span>)</span> <span>{</span>
        <span>printf</span><span>(</span><span>"integer: %d</span><span>\n</span><span>"</span><span>,</span> <span>arg</span><span>);</span>
        <span>// ...
</span>    <span>}</span>
    <span>else</span> <span>if</span> <span>constexpr</span> <span>(</span><span>std</span><span>::</span><span>is_same_v</span><span>&lt;</span><span>T</span><span>,</span> <span>bool</span><span>&gt;</span><span>)</span> <span>{</span>
        <span>printf</span><span>(</span><span>"bool: %d</span><span>\n</span><span>"</span><span>,</span> <span>arg</span><span>);</span>
        <span>// ...
</span>    <span>}</span>
<span>}</span>
</code></pre>
</div>

<p>Much better, no?</p>

<h2 id="no">No.</h2>

<p>The rigmarole needed for <code>std::visit</code> is entirely insane.
We started with a simple goal: look at the contents of a sum type.
To accomplish this meager mission, we had to:</p>

<ol>
  <li>
    <p>Define a function object, which requires a lot of
boilerplate, <em>or</em></p>
  </li>
  <li>Define our behavior with lambdas, which required:
    <ul>
      <li>An understanding of variadic templates, in all their recursively-defined fun, <em>or</em></li>
      <li>A familiarity with variadic <code>using</code> declarations, fresh on the scene from C++17.</li>
    </ul>

    <p><em>or</em></p>
  </li>
  <li>Use compile-time conditionals, which require you to know
about—and grok—the new <code><span>constexpr</span> <span>if</span></code> syntax, along with
<code>type_traits</code> fun like
<code>std::decay</code>.</li>
</ol>

<p>None of these concepts are too enigmatic if you’re an experienced C++ developer,
but several are certainly “advanced” features of the language.
Things have really gone sideways if we need to know so much
to do something so simple.</p>

<h2 id="how-did-we-get-here">How did we get here?</h2>

<p>My goal isn’t to disparage the folks on the ISO C++ committee
who picked this approach.
I’ve had beers with some of them,
and they’re smart, kind, hardworking people.
I’m sure that I’m missing important context since I’ve never sat in on a
standards meeting or read all of the relevant
<a href="http://www.open-std.org/jtc1/sc22/wg21/docs/papers/">committee papers</a>.
But from an outsider’s perspective, the disparity in complexity between the
problem being solved (“What’s in here?”)
and the solutions is just nuts.
How do you teach this without overwhelming a beginner with all this other…
stuff?
Is it expected to be common knowledge for your everyday programmer?
(And if the goal of adding <code>variant</code> to the standard library <em>isn’t</em> to
make it a tool for the masses, shouldn’t it be?)
The very least C++17 could do—if the committee didn’t have the time or resources
to get pattern matching into the language—is provide something akin to <code>make_visitor</code>.
But that too is left as an exercise for the user.</p>

<p>If I had to guess how we ended up this way,
I’d assume it comes down to confirmation bias.
Maybe when a bunch of really smart people who know how
<a href="http://en.cppreference.com/w/cpp/language/sfinae">SFINAE</a> works offhand
and don’t flinch when they see the likes of</p>

<div><pre><code><span>template</span> <span>&lt;</span><span>typename</span> <span>F</span><span>&gt;</span>
<span>typename</span> <span>std</span><span>::</span><span>enable_if</span><span>&lt;!</span><span>std</span><span>::</span><span>is_reference</span><span>&lt;</span><span>F</span><span>&gt;::</span><span>value</span><span>,</span> <span>int</span><span>&gt;::</span><span>type</span>
<span>foo</span><span>(</span><span>F</span> <span>f</span><span>)</span>
<span>{</span>
    <span>// ...
</span><span>}</span>
</code></pre>
</div>

<p>get together, the result is something like <code>std::visit</code>.
Nobody proclaims that the emperor has no clothes, or that it’s completely
bonkers to expect the average user to build an overloaded callable
object with recursive templates just to see if the thing they’re looking at
holds an <code><span>int</span></code> or a <code><span>string</span></code>.</p>

<p>I’m also not here to claim that C++ is too complicated for its own good,
but it’s certainly more complicated than it has to be.
Scott Meyers, the guy who wrote <em>Effective&nbsp;C++</em> and <em>Effective Modern&nbsp;C++</em>,
has made similar noises in <a href="http://www.ustream.tv/recorded/47947981">recent</a>
<a href="https://youtu.be/RT46MpK39rQ?t=29m51s">talks</a>.
To paraphrase Meyers, I’m sure each member of the committee cares very much
about avoiding needless complexity and making the language easier to use.
But if you look at the results of their work, it’s hard to tell.
The accidental complexity just keeps stacking up.</p>

<h2 id="where-are-we-headed">Where are we headed?</h2>

<p>There’s a reason C++ is so widely used, especially in systems programming.<sup id="fnref:3"><a href="#fn:3">3</a></sup>
It can be incredibly expressive, yet gives you nearly full control of your hardware.
The tooling around it is some of the most mature of any programming language
out there, bar C.
It supports a ridiculous number of platforms.</p>

<p>But even if you set aside all the historical baggage, it has some serious shortcomings.
Spend any amount of time messing with D and you’ll quickly realize that
metaprogramming needn’t require self-flagellation and insane syntax.
Play with Rust and <!-- Hi, PCJ --> you’ll feel like <code>unique_ptr</code>
and <code>shared_ptr</code>—which themselves have been a breath of fresh air—are
a bad joke.
The fact that we still handle dependencies in 2017
by literally copy-pasting files into each other with <code><span>#include</span></code>
macros is <em>obscene</em>.</p>

<p>You get the impression, based on what ends up in the ISO standards and what
you hear in conference talks,
that those driving C++ are trying to eliminate some of these shortcomings by
glomming nice bits from other languages onto it.
That’s a great idea on its face,
but these features often seem to arrive half-baked.
While C++ isn’t going away any time soon,
it feels like the language is constantly playing a clumsy game of catchup.</p>

<hr>

<p>In spite of all of this,
I’ll be busy encouraging my coworkers to use <code>variant</code> if anybody needs me.
Sum types are such a useful concept that they’re worth the pain,
and <a href="https://www.youtube.com/watch?v=wvtFGa6XJDU">to quote Jon Kalb</a>,
“If you can’t program in a language with ugly warts, maybe C++ isn’t the language
you should be programming in.”</p>

<hr>



  </article></div>]]>
            </description>
            <link>https://bitbashing.io/std-visit.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25314126</guid>
            <pubDate>Sat, 05 Dec 2020 12:44:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Scaling Down Deep Learning]]>
            </title>
            <description>
<![CDATA[
Score 117 | Comments 28 (<a href="https://news.ycombinator.com/item?id=25314066">thread link</a>) | @lelf
<br/>
December 5, 2020 | https://greydanus.github.io/2020/12/01/scaling-down/ | <a href="https://web.archive.org/web/*/https://greydanus.github.io/2020/12/01/scaling-down/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <div>
      <div>

  

  <article>
  

<div>
    <div>
    <video id="demoDisplay">
    	<source src="https://greydanus.github.io/assets/scaling-down/construction.mp4" type="video/mp4">
    </video>
    <p>Constructing the MNIST-1D dataset. As with the original MNIST dataset, the task is to learn to classify the digits 0-9. Unlike the MNIST dataset, which consists of 28x28 images, each of these examples is a one-dimensional sequence of points. To generate an example, we begin with 10 digit templates and then randomly pad, translate, add noise, and transform them as shown above.</p>
  	</div>
</div>





<p>By any scientific standard, the Human Genome Project <a href="https://deepblue.lib.umich.edu/handle/2027.42/62798">was enormous</a>: it involved billions of dollars of funding, dozens of institutions, and over a decade of accelerated research. But that was only the tip of the iceberg. Long before the project began, scientists were hard at work assembling the intricate science of human genetics. And most of the time, they were not studying humans. The foundational discoveries in genetics centered on far simpler organisms such as peas, molds, fruit flies, and mice. To this day, biologists use these simpler organisms as genetic “minimal working examples” in order to save time, energy, and money. A well-designed experiment with Drosophilia, such as <a href="https://pubmed.ncbi.nlm.nih.gov/10746727/">Feany and Bender (2000)</a>, can teach us an astonishing amount about humans.</p>

<p>The deep learning analogue of Drosophilia is the MNIST dataset. A large number of deep learning innovations including <a href="https://jmlr.org/papers/v15/srivastava14a.html">dropout</a>, <a href="https://arxiv.org/abs/1412.6980">Adam</a>, <a href="http://yann.lecun.com/exdb/publis/pdf/lecun-89e.pdf">convolutional networks</a>, <a href="https://arxiv.org/abs/1406.2661">generative adversarial networks</a>, and <a href="https://arxiv.org/abs/1312.6114">variational autoencoders</a> began life as MNIST experiments. Once these innovations proved themselves on small-scale experiments, scientists found ways to scale them to larger and more impactful applications.</p>

<p>They key advantage of Drosophilia and MNIST is that they dramatically accelerate the iteration cycle of exploratory research. In the case of Drosophilia, the fly’s life cycle is just a few days long and its nutritional needs are negligible. This makes it much easier to work with than mammals, especially humans. In the case of MNIST, training a strong classifier takes a few dozen lines of code, less than a minute of walltime, and negligible amounts of electricity. This is a stark contrast to state-of-the-art vision, text, and game-playing models which can take months and <a href="https://arxiv.org/abs/2004.08900">hundreds of thousands of dollars</a> of electricity to train.</p>

<p>Yet in spite of its historical significance, MNIST has three notable shortcomings. First, it does a poor job of differentiating between linear, nonlinear, and translation-invariant models. For example, logistic, MLP, and CNN benchmarks obtain 94, 99+, and 99+% accuracy on it. This makes it hard to measure the contribution of a CNN’s spatial priors or to judge the relative effectiveness of different regularization schemes. Second, it is somewhat large for a toy dataset. Each input example is a 784-dimensional vector and thus it takes a non-trivial amount of computation to perform hyperparameter searches or debug a metalearning loop. Third, MNIST is hard to hack. The ideal toy dataset should be procedurally generated so that researchers can smoothly vary parameters such as background noise, translation, and resolution.</p>

<p>In order to address these shortcomings, we propose the MNIST-1D dataset. It is a minimalist, low-memory, and low-compute alternative to MNIST, designed for exploratory deep learning research where rapid iteration is a priority. Training examples are 20 times smaller but they are still better at measuring the difference between 1) linear and nonlinear classifiers and 2) models with and without spatial inductive biases (eg. translation invariance). The dataset is procedurally generated but still permits analogies to real-world digit classification.</p>

<div>
  <div>
    <p><img src="https://greydanus.github.io/assets/scaling-down/overview_a.png"></p><p>Constructing the MNIST-1D dataset. Like MNIST, the classifier's objective is to determine which digit is present in the input. Unlike MNIST, each example is a one-dimensional sequence of points. To generate an example, we begin with a digit template and then randomly pad, translate, and transform it.</p>
  </div>
  <div>
    <p><img src="https://greydanus.github.io/assets/scaling-down/overview_b.png"></p><p>Visualizing the performance of common models on the MNIST-1D dataset. This dataset separates them cleanly according to whether they use nonlinear features (logistic regression vs. MLP) or whether they have spatial inductive biases (MLP vs. CNN). Humans do best of all. Best viewed with zoom.</p>
  </div>
</div>

<div>
  <p><img src="https://greydanus.github.io/assets/scaling-down/tsne.png">
  </p>
  <p>Visualizing the MNIST and MNIST-1D datasets with tSNE. The well-defined clusters in the MNIST plot indicate that the majority of the examples are separable via a kNN classifier in pixel space. The MNIST-1D plot, meanwhile, reveals a lack of well-defined clusters which suggests that learning a nonlinear representation of the data is much more important to achieve successful classification. Thanks to <a href="https://twitter.com/hippopedoid">Dmitry Kobak</a> for making this plot.</p>
</div>

<h2 id="example-use-cases">Example use cases</h2>

<p>In this section we will explore several examples of how MNIST-1D can be used to study core “science of deep learning” phenomena.</p>

<p><strong>Finding lottery tickets.</strong> It is not unusual for deep learning models to have ten or even a hundred times more parameters than necessary. This overparameterization helps training but increases computational overhead. One solution is to progressively prune weights from a model during training so that the final network is just a fraction of its original size. Although this approach works, conventional wisdom holds that sparse networks do not train well from scratch. Recent work by <a href="https://arxiv.org/abs/1803.03635">Frankle &amp; Carbin (2019)</a> challenges this conventional wisdom. The authors report finding sparse subnetworks inside of larger networks that train to equivalent or even higher accuracies. These “lottery ticket” subnetworks can be found through a simple iterative procedure: train a network, prune the smallest weights, and then rewind the remaining weights to their original initializations and retrain.</p>

<p>Since the original paper was published, a multitude of works have sought to explain this phenomenon and then harness it on larger datasets and models. However, very few works have attempted to isolate a “minimal working example” of this effect so as to investigate it more carefully. The figure below shows that the MNIST-1D dataset not only makes this possible, but also enables us to elucidate, via carefully-controlled experiments, some of the reasons for a lottery ticket’s success. Unlike many follow-up experiments on the lottery ticket, this one took just two days of researcher time to produce. The curious reader can also <a href="https://bit.ly/3nCEIaL">reproduce these results</a> in their browser in a few minutes.</p>

<div>
  <p><img src="https://greydanus.github.io/assets/scaling-down/lottery_a1.png">
  </p>
  <p><img src="https://greydanus.github.io/assets/scaling-down/lottery_a2.png">
  </p>
  <p>Finding and analyzing lottery tickets. In <b>a-b)</b>, we isolate a "minimum viable example" of the effect. Recent work by <a href="https://arxiv.org/abs/1906.02773">Morcos et al (2019)</a> shows that lottery tickets can transfer between datasets. We wanted to determine whether spatial inductive biases played a role. So we performed a series of experiments: in <b>c)</b> we plot the asymptotic performance of a 92% sparse ticket. In <b>d)</b> we reverse all the 1D signals in the dataset, effectively preserving spatial structure but changing the location of individual datapoints. This is analogous to flipping an image upside down. Under this ablation, the lottery ticket continues to win.</p>
</div>

<div>
  <p><img src="https://greydanus.github.io/assets/scaling-down/lottery_b1.png">
  </p>
  <p><img src="https://greydanus.github.io/assets/scaling-down/lottery_b2.png">
  </p>
    <p>Next, in <b>e)</b> we permute the indices of the 1D signal, effectively removing spatial structure from the dataset. This ablation hurts lottery ticket performance significantly more, suggesting that part of the lottery ticket's performance can be attributed to a spatial inductive bias. Finally, in <b>f)</b> we keep the lottery ticket sparsity structure but initialize its weights with a different random seed. Contrary to results reported in <a href="https://arxiv.org/abs/1803.03635">Frankle &amp; Carbin (2019)</a>, we see that our lottery ticket continues to outperform a dense baseline, aligning well with our hypothesis that the lottery ticket mask has a spatial inductive bias. In <b>g)</b>, we verify our hypothesis by measuring how often unmasked weights are adjacent to one another in the first layer of our model. The lottery ticket has many more adjacent weights than chance would predict, implying a local connectivity structure which helps gives rise to spatial biases.</p>
</div>

<p>You can also visualize the actual masks selected via random and lottery pruning:
<br></p>





<p><strong>Observing deep double descent.</strong> Another intriguing property of neural networks is the “double descent” phenomenon. This phrase refers to a training regime where more data, model parameters, or gradient steps can actually <em>reduce</em> a model’s test accuracy<sup id="fnref:fn1" role="doc-noteref"><a href="#fn:fn1">1</a></sup> <sup id="fnref:fn2" role="doc-noteref"><a href="#fn:fn2">2</a></sup> <sup id="fnref:fn3" role="doc-noteref"><a href="#fn:fn3">3</a></sup> <sup id="fnref:fn4" role="doc-noteref"><a href="#fn:fn4">4</a></sup>. The intuition is that during supervised learning there is an interpolation threshold where the learning procedure, consisting of a model and an optimization algorithm, is just barely able to fit the entire training set. At this threshold there is effectively just one model that can fit the data and this model is very sensitive to label noise and model mis-specification.</p>

<p>Several properties of this effect, such as what factors affect its width and location, are not well understood in the context of deep models. We see the MNIST-1D dataset as a good tool for exploring these properties. In fact, we were able to reproduce the double descent pattern after a few hours of researcher effort. The figure below shows our results for a fully-connected network and a convolutional model. We also observed a nuance that we had not seen mentioned in previous works: when using a mean square error loss, the interpolation threshold lies at \(n * K\) model parameters where \(n\) is the number of training examples and \(K\) is the number of model outputs. But when using a negative log likelihood loss, the interpolation threshold lies at \(n\) model parameters – it does not depend on the number of model outputs. This is an interesting empirical observation that may explain some of the advantage in using a log likelihood loss over a MSE loss on this type of task. You can reproduce these results <a href="https://bit.ly/2UBWWNu">here</a>.</p>

<div>
  <p><img src="https://greydanus.github.io/assets/scaling-down/ddd_a.png">
  </p>
  <p><img src="https://greydanus.github.io/assets/scaling-down/ddd_b.png">
  </p>
  <p>Observing deep double descent. MNIST-1D is a good environment for determining how to locate the interpolation threshold of deep models. This threshold is fairly easy to predict in fully-connected models but less easy to …</p></div></article></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://greydanus.github.io/2020/12/01/scaling-down/">https://greydanus.github.io/2020/12/01/scaling-down/</a></em></p>]]>
            </description>
            <link>https://greydanus.github.io/2020/12/01/scaling-down/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25314066</guid>
            <pubDate>Sat, 05 Dec 2020 12:30:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Your Smart TV is probably ignoring your PiHole]]>
            </title>
            <description>
<![CDATA[
Score 400 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25313776">thread link</a>) | @giuliomagnifico
<br/>
December 5, 2020 | https://labzilla.io/blog/force-dns-pihole | <a href="https://web.archive.org/web/*/https://labzilla.io/blog/force-dns-pihole">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody"><p><span><i></i></span> <strong>Welcome Hacker News readers!</strong><br>
<strong>•</strong> Thank you to <a href="https://homepage.cs.uiowa.edu/~mmazhar/">M. Hammad Mazhar</a> for his <a href="https://arxiv.org/pdf/2001.08288.pdf">research</a> that inspired this guide.<br>
<strong>•</strong> <a href="https://twitter.com/healeyio">@healyio</a> made some great additional suggestions in this Twitter <a href="https://twitter.com/healeyio/status/1335347122649006080">thread</a> which I’ll be incorporating into a future update.<br>
<strong>•</strong> The HN <a href="https://news.ycombinator.com/item?id=25313480">comment thread</a> is full of insightful comments from individuals who work on IoT hardware and other embedded devices, and is well worth a read.<br>
<strong>•</strong> Finally, you can subscribe to the <a href="https://labzilla.io/feed.xml">RSS feed</a> or follow on <a href="https://twitter.com/labzilla">Twitter</a> for updates.</p>
<p>If you’re using PiHole on your network to block ads and prevent your various smart devices from sending tracking information to their manufacturers, <strong>you might be surprised to find out that some of these devices are using a sneaky tactic to bypass your PiHole entirely.</strong></p>
<p>Smart devices manufacturers often “hard-code” in a public DNS server, like Google’s 8.8.8.8, and their devices ignore whatever DNS server is assigned by your router - such as your PiHole.</p>
<p><a href="https://arxiv.org/pdf/2001.08288.pdf">Nearly 70% of smart TVs and 46% of game consoles</a> were found to contain hardcoded DNS settings - allowing them to simply ignore your local network’s DNS server entirely. On average, Smart TVs generate an average of 60 megabytes of outgoing Internet traffic <em>per day</em>, all the while bypassing tools like PiHole.</p>
<h2 id="force-all-dns-queries-through-pihole">Force all DNS queries through PiHole</h2>
<p>Fortunately, with a few simple firewall rules, you can intercept these hardcoded DNS queries and redirect them to your PiHole. These instructions are for pfSense, however you should be able to adapt them for Sophos XG, Ubiquiti EdgeRouter, etc.</p>
<h3 id="create-nat-rules">Create NAT Rules</h3>
<p>Log in to your pfSense admin interface, and navigate to <em>Firewall</em> &gt; <em>NAT</em> &gt; <em>Port Forward</em>.</p>
<p>We’re going to create two Port Forward NAT rules - one to redirect any DNS queries originating from devices on the LAN to PiHole, and another to allow PiHole to commmunicate with external DNS servers. We will also create an additional outbound NAT rule that will make this process invisible to any clients on the network with hardcoded DNS.</p>
<p><strong>NAT Rule 1: Redirect DNS queries to PiHole</strong></p>
<p>Click the <em>Add</em> button to create your first new NAT Port Forward rule.</p>
<ul>
<li><strong>Interface:</strong> LAN</li>
<li><strong>Protcol:</strong> TCP/UDP</li>
<li><strong>Source:</strong> LAN net (you may need to click the blue show advanced button to see this option)</li>
<li><strong>Destination - Invert match:</strong> Checked</li>
<li><strong>Destination - Type:</strong> Single host or alias</li>
<li><strong>Destination - Address/mask:</strong> Your PiHole’s IP address</li>
<li><strong>Destination Port Range - From:</strong> DNS</li>
<li><strong>Destination Port Range - To:</strong> DNS</li>
<li><strong>Redirect Target IP:</strong> Your PiHole’s IP address</li>
<li><strong>Redirect Target Port:</strong> DNS</li>
<li><strong>Description:</strong> Intercept any outgoing DNS queries and redirect them to PiHole.</li>
</ul>
<p><strong>NAT Rule 2: Exempt PiHole from DNS query redirects</strong></p>
<p>Click the <em>Add</em> button to create your second new NAT Port Forward rule.</p>
<ul>
<li><strong>No RDR (NOT):</strong> Checked</li>
<li><strong>Interface:</strong> LAN</li>
<li><strong>Protcol:</strong> TCP/UDP</li>
<li><strong>Source - Type:</strong> Single host or alias</li>
<li><strong>Source - Address/Mask:</strong> Your PiHole’s IP address</li>
<li><strong>Destination:</strong> Any</li>
<li><strong>Destination Port Range - From:</strong> DNS</li>
<li><strong>Destination Port Range - From:</strong> DNS</li>
<li><strong>Description:</strong> Allow PiHole to reach external DNS servers</li>
</ul>
<p><strong>Note:</strong> pfSense (and most other firewalls) process rules from top to bottom. Make sure you drag the second rule exempting PiHole from DNS query redirects <em>above</em> the first rule we created - otherwise PiHole will not be able to contact external DNS servers.</p>
<p><strong>NAT Rule 3: Prevent clients from giving unexpected source errors</strong></p>
<p>Finally, we need to create an outbound NAT rule. Navigate to <em>Firewall</em> &gt; <em>NAT</em> &gt; <em>Outbound</em>.</p>
<ul>
<li><strong>Interface:</strong> LAN</li>
<li><strong>Address Family:</strong> IPv4+IPv6</li>
<li><strong>Protocol:</strong> any</li>
<li><strong>Source - Type:</strong> Network</li>
<li><strong>Source - Network for the outbound NAT mapping:</strong> Your internal LAN network</li>
<li><strong>Destination - Type:</strong> Network</li>
<li><strong>Destination - Network for the outbound NAT Mappings:</strong> Your PiHole’s IP Address</li>
<li><strong>Destination Port Range:</strong> 53</li>
<li><strong>Translation:</strong> Interface Address</li>
<li><strong>Description:</strong> Prevents hardcoded DNS clients from giving unexpected source error after DNS redirected to PiHole.</li>
</ul>
<h3 id="test-it-out">Test it out</h3>
<p>You can easily test to make sure your DNS redirection is working properly.</p>
<ol>
<li>Create a new, temporary internal DNS entry on your network (“piholetest.example.com”), and point it to 10.0.1.1. You can do this right from PiHole under <em>Local DNS Records</em>.</li>
<li>Manually set your computer’s DNS server to <em>1.1.1.1</em>.</li>
<li>Open a terminal window (or command promt on Windows), and run <code>nslookup piholetest.example.com</code></li>
<li>
<p>If you set this up correctly, <code>nslookup</code> should return 10.0.1.1. Your computer <em>thinks</em> it’s receiving DNS records from 1.1.1.1, while in reality they are coming from your PiHole.</p>
<div><div><pre><code> macbookpro:~ labzilla$ nslookup piholetest.example.com
 Server:		1.1.1.1
 Address:	1.1.1.1#53
	
 Name:	piholetest.example.com
 Address: 10.0.1.1
</code></pre></div> </div>
</li>
<li>
<p>You can further demonstate this by temporarily disabling the first NAT rule we created, and running the same <code>nslookup piholetest.example.com</code> command:</p>
<div><div><pre><code> macbookpro:~ labzilla$ nslookup piholetest.example.com
 Server:		1.1.1.1
 Address:	1.1.1.1#53
	
 ** server can't find piholetest.example.com: NXDOMAIN 
</code></pre></div> </div>
<p>As “piholetest.example.com” doesn’t exist on the public Internet, the real 1.1.1.1 server has no record to provide - resulting in your <code>nslookup</code> request returning a NXDOMAIN error.</p>
</li>
</ol>
<p><strong>Don’t forget to revert your computer’s DNS settings back to their original value, and reenable any firewall rules you temporary disabled while testing.</strong></p>
<h2 id="hacker-news">Hacker News</h2>
<p>This post hit the front page of Hacker News <span><i></i></span> on Saturday December 5th, 2020. Thank you <a href="https://boramalper.org/">@boramalper</a> for submitting it, and I hope you found the information useful!</p>
<ul>
<li>If you’re curious about what the Hacker News bump looks like - this blog normally sees about 100 hits per day. Between December 5th-6th, this post had over 70,000 views.</li>
<li>The <a href="https://news.ycombinator.com/item?id=25313480">original comment thread</a> is full of insightful comments from individuals who work on IoT hardware and other embedded devices, and is well worth a read.</li>
<li>A follow up article incorporating some of the suggestion that <a href="https://twitter.com/healeyio">@healyio</a> made in this Twitter <a href="https://twitter.com/healeyio/status/1335347122649006080">thread</a> is coming soon.</li>
</ul>
</div></div>]]>
            </description>
            <link>https://labzilla.io/blog/force-dns-pihole</link>
            <guid isPermaLink="false">hacker-news-small-sites-25313776</guid>
            <pubDate>Sat, 05 Dec 2020 11:38:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[72% of smart TVs and 46% of game consoles hardcode DNS settings]]>
            </title>
            <description>
<![CDATA[
Score 459 | Comments 596 (<a href="https://news.ycombinator.com/item?id=25313480">thread link</a>) | @boramalper
<br/>
December 5, 2020 | https://labzilla.io/blog/force-dns-pihole | <a href="https://web.archive.org/web/*/https://labzilla.io/blog/force-dns-pihole">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody"><p><span><i></i></span> <strong>Welcome Hacker News readers!</strong><br>
<strong>•</strong> Thank you to <a href="https://homepage.cs.uiowa.edu/~mmazhar/">M. Hammad Mazhar</a> for his <a href="https://arxiv.org/pdf/2001.08288.pdf">research</a> that inspired this guide.<br>
<strong>•</strong> <a href="https://twitter.com/healeyio">@healyio</a> made some great additional suggestions in this Twitter <a href="https://twitter.com/healeyio/status/1335347122649006080">thread</a> which I’ll be incorporating into a future update.<br>
<strong>•</strong> The HN <a href="https://news.ycombinator.com/item?id=25313480">comment thread</a> is full of insightful comments from individuals who work on IoT hardware and other embedded devices, and is well worth a read.<br>
<strong>•</strong> Finally, you can subscribe to the <a href="https://labzilla.io/feed.xml">RSS feed</a> or follow on <a href="https://twitter.com/labzilla">Twitter</a> for updates.</p>
<p>If you’re using PiHole on your network to block ads and prevent your various smart devices from sending tracking information to their manufacturers, <strong>you might be surprised to find out that some of these devices are using a sneaky tactic to bypass your PiHole entirely.</strong></p>
<p>Smart devices manufacturers often “hard-code” in a public DNS server, like Google’s 8.8.8.8, and their devices ignore whatever DNS server is assigned by your router - such as your PiHole.</p>
<p><a href="https://arxiv.org/pdf/2001.08288.pdf">Nearly 70% of smart TVs and 46% of game consoles</a> were found to contain hardcoded DNS settings - allowing them to simply ignore your local network’s DNS server entirely. On average, Smart TVs generate an average of 60 megabytes of outgoing Internet traffic <em>per day</em>, all the while bypassing tools like PiHole.</p>
<h2 id="force-all-dns-queries-through-pihole">Force all DNS queries through PiHole</h2>
<p>Fortunately, with a few simple firewall rules, you can intercept these hardcoded DNS queries and redirect them to your PiHole. These instructions are for pfSense, however you should be able to adapt them for Sophos XG, Ubiquiti EdgeRouter, etc.</p>
<h3 id="create-nat-rules">Create NAT Rules</h3>
<p>Log in to your pfSense admin interface, and navigate to <em>Firewall</em> &gt; <em>NAT</em> &gt; <em>Port Forward</em>.</p>
<p>We’re going to create two Port Forward NAT rules - one to redirect any DNS queries originating from devices on the LAN to PiHole, and another to allow PiHole to commmunicate with external DNS servers. We will also create an additional outbound NAT rule that will make this process invisible to any clients on the network with hardcoded DNS.</p>
<p><strong>NAT Rule 1: Redirect DNS queries to PiHole</strong></p>
<p>Click the <em>Add</em> button to create your first new NAT Port Forward rule.</p>
<ul>
<li><strong>Interface:</strong> LAN</li>
<li><strong>Protcol:</strong> TCP/UDP</li>
<li><strong>Source:</strong> LAN net (you may need to click the blue show advanced button to see this option)</li>
<li><strong>Destination - Invert match:</strong> Checked</li>
<li><strong>Destination - Type:</strong> Single host or alias</li>
<li><strong>Destination - Address/mask:</strong> Your PiHole’s IP address</li>
<li><strong>Destination Port Range - From:</strong> DNS</li>
<li><strong>Destination Port Range - To:</strong> DNS</li>
<li><strong>Redirect Target IP:</strong> Your PiHole’s IP address</li>
<li><strong>Redirect Target Port:</strong> DNS</li>
<li><strong>Description:</strong> Intercept any outgoing DNS queries and redirect them to PiHole.</li>
</ul>
<p><strong>NAT Rule 2: Exempt PiHole from DNS query redirects</strong></p>
<p>Click the <em>Add</em> button to create your second new NAT Port Forward rule.</p>
<ul>
<li><strong>No RDR (NOT):</strong> Checked</li>
<li><strong>Interface:</strong> LAN</li>
<li><strong>Protcol:</strong> TCP/UDP</li>
<li><strong>Source - Type:</strong> Single host or alias</li>
<li><strong>Source - Address/Mask:</strong> Your PiHole’s IP address</li>
<li><strong>Destination:</strong> Any</li>
<li><strong>Destination Port Range - From:</strong> DNS</li>
<li><strong>Destination Port Range - From:</strong> DNS</li>
<li><strong>Description:</strong> Allow PiHole to reach external DNS servers</li>
</ul>
<p><strong>Note:</strong> pfSense (and most other firewalls) process rules from top to bottom. Make sure you drag the second rule exempting PiHole from DNS query redirects <em>above</em> the first rule we created - otherwise PiHole will not be able to contact external DNS servers.</p>
<p><strong>NAT Rule 3: Prevent clients from giving unexpected source errors</strong></p>
<p>Finally, we need to create an outbound NAT rule. Navigate to <em>Firewall</em> &gt; <em>NAT</em> &gt; <em>Outbound</em>.</p>
<ul>
<li><strong>Interface:</strong> LAN</li>
<li><strong>Address Family:</strong> IPv4+IPv6</li>
<li><strong>Protocol:</strong> any</li>
<li><strong>Source - Type:</strong> Network</li>
<li><strong>Source - Network for the outbound NAT mapping:</strong> Your internal LAN network</li>
<li><strong>Destination - Type:</strong> Network</li>
<li><strong>Destination - Network for the outbound NAT Mappings:</strong> Your PiHole’s IP Address</li>
<li><strong>Destination Port Range:</strong> 53</li>
<li><strong>Translation:</strong> Interface Address</li>
<li><strong>Description:</strong> Prevents hardcoded DNS clients from giving unexpected source error after DNS redirected to PiHole.</li>
</ul>
<h3 id="test-it-out">Test it out</h3>
<p>You can easily test to make sure your DNS redirection is working properly.</p>
<ol>
<li>Create a new, temporary internal DNS entry on your network (“piholetest.example.com”), and point it to 10.0.1.1. You can do this right from PiHole under <em>Local DNS Records</em>.</li>
<li>Manually set your computer’s DNS server to <em>1.1.1.1</em>.</li>
<li>Open a terminal window (or command promt on Windows), and run <code>nslookup piholetest.example.com</code></li>
<li>
<p>If you set this up correctly, <code>nslookup</code> should return 10.0.1.1. Your computer <em>thinks</em> it’s receiving DNS records from 1.1.1.1, while in reality they are coming from your PiHole.</p>
<div><div><pre><code> macbookpro:~ labzilla$ nslookup piholetest.example.com
 Server:		1.1.1.1
 Address:	1.1.1.1#53
	
 Name:	piholetest.example.com
 Address: 10.0.1.1
</code></pre></div> </div>
</li>
<li>
<p>You can further demonstate this by temporarily disabling the first NAT rule we created, and running the same <code>nslookup piholetest.example.com</code> command:</p>
<div><div><pre><code> macbookpro:~ labzilla$ nslookup piholetest.example.com
 Server:		1.1.1.1
 Address:	1.1.1.1#53
	
 ** server can't find piholetest.example.com: NXDOMAIN 
</code></pre></div> </div>
<p>As “piholetest.example.com” doesn’t exist on the public Internet, the real 1.1.1.1 server has no record to provide - resulting in your <code>nslookup</code> request returning a NXDOMAIN error.</p>
</li>
</ol>
<p><strong>Don’t forget to revert your computer’s DNS settings back to their original value, and reenable any firewall rules you temporary disabled while testing.</strong></p>
<h2 id="hacker-news">Hacker News</h2>
<p>This post hit the front page of Hacker News <span><i></i></span> on Saturday December 5th, 2020. Thank you <a href="https://boramalper.org/">@boramalper</a> for submitting it, and I hope you found the information useful!</p>
<ul>
<li>If you’re curious about what the Hacker News bump looks like - this blog normally sees about 100 hits per day. Between December 5th-6th, this post had over 70,000 views.</li>
<li>The <a href="https://news.ycombinator.com/item?id=25313480">original comment thread</a> is full of insightful comments from individuals who work on IoT hardware and other embedded devices, and is well worth a read.</li>
<li>A follow up article incorporating some of the suggestion that <a href="https://twitter.com/healeyio">@healyio</a> made in this Twitter <a href="https://twitter.com/healeyio/status/1335347122649006080">thread</a> is coming soon.</li>
</ul>
</div></div>]]>
            </description>
            <link>https://labzilla.io/blog/force-dns-pihole</link>
            <guid isPermaLink="false">hacker-news-small-sites-25313480</guid>
            <pubDate>Sat, 05 Dec 2020 10:46:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Make slides with text, markdown, YAML, JSON or JavaScript, your call]]>
            </title>
            <description>
<![CDATA[
Score 127 | Comments 25 (<a href="https://news.ycombinator.com/item?id=25313347">thread link</a>) | @abusedmedia
<br/>
December 5, 2020 | https://play.presenta.cc/v2 | <a href="https://web.archive.org/web/*/https://play.presenta.cc/v2">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://play.presenta.cc/v2</link>
            <guid isPermaLink="false">hacker-news-small-sites-25313347</guid>
            <pubDate>Sat, 05 Dec 2020 10:21:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Between two Lisps]]>
            </title>
            <description>
<![CDATA[
Score 117 | Comments 58 (<a href="https://news.ycombinator.com/item?id=25313311">thread link</a>) | @galfarragem
<br/>
December 5, 2020 | https://ane.github.io/2020/10/05/between-two-lisps.html | <a href="https://web.archive.org/web/*/https://ane.github.io/2020/10/05/between-two-lisps.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p>Out of all Lisps the ones I’ve come to appreciate the most are <a href="https://en.wikipedia.org/wiki/Scheme_(programming_language)">Scheme</a> and <a href="https://common-lisp.net/">Common
Lisp</a>. <!--break-->These two languages are fundamentally very different: Scheme
is a minimalist language built on the foundations of <a href="https://en.wikipedia.org/wiki/Lambda_calculus">lambda calculus</a>, while
Common Lisp is a multi-paradigm synthesis of many Lisps before it. Common Lisp
is a large standard with many implementations, Scheme is a collection of an
evolving but minimalistic standard with many implementations. The core of Scheme
is quite small compared to Common Lisp. The latest standard <a href="http://www.r6rs.org/final/r6rs-lib.pdf">R6RS</a> is about 65
pages, while the ANSI Common Lisp standard from 1994 is about 1100 pages. The
<a href="https://srfi.schemers.org/">Scheme Requests for Implementation</a> process aims to standardize additional
features (like <a href="https://srfi.schemers.org/srfi-64/srfi-64.html">test suites</a>) that implementations may implement.</p>

<p>Common Lisp has some wonderful features, <a href="http://www.gigamonkeys.com/book/beyond-exception-handling-conditions-and-restarts.html">conditions and restarts</a>, the <a href="https://lispcookbook.github.io/cl-cookbook/clos.html">Common
Lisp Object System (CLOS)</a>, <a href="http://www.paulgraham.com/onlisp.html">the macro system</a>, among many other things. The <a href="http://joaotavora.github.io/sly/">SLY
IDE for Emacs</a> is <em>amazing</em>, and the <a href="http://www.sbcl.org/">Steel Bank Common Lisp</a> compiler is really
great. It has <a href="https://www.quicklisp.org/index.html">Quicklisp</a> and <a href="https://common-lisp.net/project/asdf/">ASDF</a> for package and build management,
respectively. I find the developer experience of Common Lisp to be superior to
almost anything imaginable, and this is not an empty statement: having used all
sorts of IDEs and editors for over 25 years, I have seen <em>many</em>.</p>

<h3 id="tastes-differ">Tastes differ</h3>

<p>That said, Common Lisp is <em>weird</em>. What I find particularly jarring is that
functions and variables live in different namespaces: if you put a function into
a variable, you can’t just use it like a function, you have to <code>funcall</code> it.
Having programmed in lots of languages of the ML family this is just, well, odd;
but this is due to historical reasons and there are <a href="http://www.nhplace.com/kent/Papers/Technical-Issues.html">sound technical reasons for
it</a>.  There are other
oddities, some strange things like <code>(cdr '())</code> is not an error (in Scheme it
is), <code>()</code> and <code>nil</code> are equal (in Scheme <code>#f</code> and <code>()</code> are separate things), and
so on.</p>

<p>This isn’t really a fault in Common Lisp: other languages have impacted my taste
and preferences to bias me in the direction of Scheme, but that is not to say I
cannot work with Common Lisp’s idiosyncracies. Actually, I don’t mind them, I
just <em>notice</em> them.</p>

<p>I like the naming styles of Scheme more, as well. It has <code>string?</code> vs <code>string-p</code>
for predicate functions, <code>set!</code>  for state modifying functions, <code>foo-&gt;bar</code> for
conversions, these make code quite easier to read. Scheme has hygienic macros,
Guile has the traditional <code>defmacro</code> as well.</p>

<p>Many nice Scheme features are available in Common Lisp libraries. Pattern match
is available in the <a href="https://github.com/guicho271828/trivia">trivia</a> library. Named lets are easy to implement with a macro.</p>

<p>Common Lisp aficionados are quick to point out things Scheme <em>doesn’t</em> have:
keyword arguments, docstrings, rest arguments, but my Scheme implementation of
choice Guile has these built into the language.</p>

<h3 id="productivity-matters">Productivity matters</h3>

<p>Guile is in a strange niche is that its primary <em>raison d’être</em> is to be an
extension language for the GNU project. Like Emacs Lisp is for extending Emacs,
Guile is the <em>de facto</em> language for GNU programs for extension and scripting.</p>

<p>Guile doesn’t have Quicklisp and its package manager and build system is
basically nonexistent for the first and <a href="https://www.gnu.org/software/autoconf/">Autoconf</a> for the second. There is
<a href="https://lists.gnu.org/archive/html/guile-user/2017-03/msg00168.html">sentiment</a> in the Guile community to have <a href="https://guix.gnu.org/">Guix</a> as the package manager for
Guile. This might sound a bit onerous, since Guix is also a complete package
management for many other things than Guile, but consider this: as Andy Wingo
points out in his message that Guile libraries often come with C extensions,
Guile packages need some sort of managed build system for building the C
extensions. Since it doesn’t have one, to solve the problem of building a
package manager you’d also have to build a build system that can manage C code
and packages needed by the C code bits. To do this elegantly is a gargantuan
task, for instance, <a href="https://wiki.call-cc.org/man/5/Extensions#installing-eggs-that-use-libraries">chicken-install just asks you to put compiler/linker flags
on the command line before calling it</a>, so it obviously is a hard problem.</p>

<p>Now, Guix solves all that, and more, in a manner that is quite elegant and
interesting. But it’s not as lightweight as something like Quicklisp or
<a href="https://wiki.call-cc.org/man/5/Extensions"><code>chicken-install</code></a> from <a href="http://call-cc.org/">CHICKEN Scheme</a>. What is more, Guix works only on GNU/Linux
systems really, so macOS and Windows users won’t be able to do use your library
if you plan on distributing it via Guix. Duh, it’s the GNU project, but
portability is always nice.</p>

<p>But in Common Lisp I can write <code>(ql:quickload :alexandria)</code> and voilà, it will
automatically install the <a href="http://quickdocs.org/alexandria/">Alexandria</a> library that I can use. Then again, in
Common Lisp it’s somewhat rarer to have C extensions, so I don’t know how ASDF
handles that.</p>

<p>It is unfair to compare <a href="http://joaotavora.github.io/sly/">SLY</a> to <a href="https://www.nongnu.org/geiser/">Geiser</a>, the best Emacs Scheme integration
package.  SLY is based on <a href="https://common-lisp.net/project/slime/">SLIME</a> which has <em>decades</em> of man-years of work behind
it. Geiser is able to support multiple Scheme implementations and it is quite
impressive in this regard. But SLY obviously has much more (e.g. an interactive
debugger). That said, Geiser has nice Guile support, and Guile is in general the
most Common Lisp-y of all Schemes, in fact, it has</p>

<ul>
  <li>an imitation of CLOS in the form of <a href="https://www.gnu.org/software/goops/">GOOPS</a></li>
  <li>docstrings and keyword, rest, and optional arguments for function
definitions</li>
  <li>an interactive REPL and a mutable top-level (unlike many Schemes)</li>
  <li>a nice module system</li>
  <li><a href="https://www.gnu.org/software/guile/manual/html_node/Defmacros.html"><code>defmacro</code></a> and exceptions somewhat <a href="https://www.gnu.org/software/guile/manual/html_node/Raising-and-Handling-Exceptions.html">similar to Common Lisp restarts </a></li>
</ul>

<p>and some nice things Common Lisp doesn’t have like first-class
continuations. But then again I would use those rarely.</p>

<h3 id="when-would-i-pick-one-over-the-other">When would I pick one over the other?</h3>

<p>If I were to write an extensible C/C++/Rust program that I <em>know</em> will need to use
a low-level language, I might do the low level bits using a low level language
and then write the rest in Guile. Guile makes it very easy to spin up a REPL
socket to do something like <code>myprogram --repl=12345</code> that you can connect to, and
the interop between C and Guile is fantastic, it has to be, as it’s primarily an
extension language.</p>

<p>On the other hand, if were to build a wholly standalone application, the choice is
not as obvious. I could do the whole thing in either language. Common Lisp can
build native executables, although their size will be large (who cares?) since
the binary will include the whole Lisp implementation. Guile cannot compile to
native code so you’ll have to write a script executable, but that doesn’t really
matter.</p>

<p>Scenarios where I would pick Guile:</p>

<ul>
  <li>when I’m making an extensible program that has to have some C/C++ bits but I
want to make it scriptable by users</li>
  <li>when I want to write a native binary but not write too much C/C++ code</li>
  <li>I just want to write Scheme, because Scheme is a bit more elegant</li>
  <li>the project has something to do with the <a href="https://www.gnu.org/software/autoconf/">GNU project</a></li>
</ul>

<p>On the other hand, Common Lisp makes the most sense if I just want to enjoy a
seriously rapid development experience, a large standard library and language,
and I don’t mind having 50MB binaries (again, who cares?) if I were to write
standalone programs. Guile can’t do that, but it’s easy to either write Guile
scripts or a C program that essentially bootstraps a binary to load a Scheme
runtime. This is how <a href="http://lilypond.org/">LilyPond</a> is written, for example.</p>

<p>So the answer to which one is decidedly <strong>both</strong>! Both languages are really fun to
write. At the moment I don’t do Lisp at my day job so it’s all for fun
anyway. If this were for professional purposes, I don’t know. Very often a
strict requirement for professional work is to be able to be productive. In that
regard I think Common Lisp has a significant edge, not only due to its superior
development experience, but its history as a real production language. There are
actual companies doing stuff in Common Lisp. I have not heard of any
professional (in the industrial sense) uses of Guile, notwithstanding that many
projects powered by Guile (Guix, etc.)  are <em>extremely</em> professional in the way
they are written and maintained. But Common Lisp has <em>more</em> libraries and
companies behind it.</p>

<h3 id="what-about-clojure">What about Clojure?</h3>

<p>I’ve actually had the pleasure to use Clojure for personal fun, and a little bit
of professional use. I wrote a couple of libraries (<a href="https://github.com/ane/vigil">vigil</a> and <a href="https://github.com/ane/task">task</a>) and my
experience with has always been positive and its development experience is
excellent. Clojure isn’t a true Lisp, or well, it is part of the <em>Lisp
family</em>. Its ability to interface with the JVM makes it easy to leverage the
thousands of JVM libraries out there.</p>

<p>I’d gladly do it again, though I feel that Common Lisp with CLOS and its module
system makes it somewhat easier to practice <a href="https://en.wikipedia.org/wiki/Programming_in_the_large_and_programming_in_the_small"><em>programming in the large</em></a>. Clojure
explores interesting territories with <a href="https://clojure.org/guides/spec">spec</a>, so it is interesting to see what
direction the language will take in the future.</p>

<h3 id="final-words-emacs-lisp">Final words: Emacs Lisp</h3>

<p>There’s also a parenthetical elephant in the room here: Emacs Lisp! An old
descendant of <a href="https://en.wikipedia.org/wiki/Maclisp">MacLisp</a>, it’s actually quite fun to write, and the fact that Emacs
itself is the interpreter, you have superb introspectability for any Elisp
code. Most of the Lisp I write these days is probably Emacs Lisp. It’s very
close to Common Lisp. <a href="https://www.gnu.org/software/emacs/manual/html_mono/cl.html#Overview">cl-lib</a> adds a sufficient amount of convenience from
Common Lisp to make Elisp writing quite enjoyable. <a href="https://www.gnu.org/software/emacs/manual/html_mono/eieio.html#Top">EIEIO</a> adds a subset of CLOS
that can be used seamlessly with cl-lib. The condition system is missing.</p>

<p>I’ve also done a fair bit of <a href="https://fennel-lang.org/">Fennel</a>, a Lisp that compiles to Lua. I used it to
write a <a href="https://github.com/ane/mudrally">small game</a> and it was fun to write since you could develop the game in a
REPL.</p>

<p>All in all, Lisp in all its variants is the most fun I’ve ever had while
programming a computer. Guile and Common Lisp are definitely the most fun I’ve
had programming in <em>Lisp</em>.</p>

  </div></div>]]>
            </description>
            <link>https://ane.github.io/2020/10/05/between-two-lisps.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25313311</guid>
            <pubDate>Sat, 05 Dec 2020 10:16:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Maybe we shouldn't want a fully decentralized web]]>
            </title>
            <description>
<![CDATA[
Score 160 | Comments 415 (<a href="https://news.ycombinator.com/item?id=25312854">thread link</a>) | @talhah
<br/>
December 5, 2020 | https://withblue.ink/2020/11/12/maybe-we-shouldnt-want-a-fully-decentralized-web.html | <a href="https://web.archive.org/web/*/https://withblue.ink/2020/11/12/maybe-we-shouldnt-want-a-fully-decentralized-web.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><p>I spent a large part of 2019 working with the distributed and decentralized web, especially IPFS, also known as the “Inter-Planetary File System”. I’ve written a few articles on the topic, on how you can host a web app on IPFS, one of which even ended up on the front page of HackerNews.</p><p>For about a year, I hosted my blog and other apps through an IPFS cluster. I wrote a utility for making pinning files easier on Pinata, a third-party cloud service for IPFS. I made some small contributions to the IPFS core projects. I built some projects with it, including one that I never released–nor fully completed–that used both IPFS and Ethereum. And I even gave a talk about hosting static web apps on IPFS at Node+JS Interactive last December in Montreal.</p><p>That all changed in the Spring of 2020. I called myself out of the distributed web.</p><p>My blog and other apps I built aren’t hosted on IPFS anymore. I don’t participate in those online communities anymore. I’ve stopped writing about the distributed and researching about it. I’ve shelved all my projects that were using those technologies.</p><p>I also updated my blog posts about IPFS adding a note that my blog isn’t hosted that way anymore. More than a few people asked me why, and I always gave the same answer: a mix of technical issues and mostly personal reasons. So, I think it’s time I explain the personal reasons.</p><p>First, I need to explain why I got involved with IPFS in the first place.</p><p>When I first read about IPFS, my mind immediately saw it as an exciting new platform I could build my apps for. The premise of a fully-decentralized platform included unlimited scalability, ultra-high availability and resiliency, no single points of failure, and resistance against attacks like DDoS.</p><p>Coming from a background in which I am always thinking about SLAs, number of nines of uptime, disaster recovery, etc, IPFS sounded like a dream platform that would magically solve all my concerns. And, aside from some performance issues at times, it did. Plus, the small engineer inside me was really excited about being able to play with a new, shiny toy, that had lots of hype around it!</p><p>What happened next for me was a reckoning with the reality of what many people behind the IPFS core project and the community around it saw: the dream of a radically open, unfiltered, and by-design un-censorable platform.</p><p>I have recently opened up about my experience, over a decade ago, with building an app with good intentions but that was then misused (<a href="https://withblue.ink/2020/09/24/that-time-i-accidentally-built-a-spying-app.html"><em>That time I accidentally built a spying app</em></a>). I learned early on in my life and (pre-)professional career about the importance of ethics in software development, and I am now a proponent of the idea that just because something <em>can</em> be built, it doesn’t mean it <em>should</em> be built.</p><p>And that brings me back to why, after spending some time in the world of the decentralized web, I have called myself out, and why I think that should things like IPFS actually become mainstream, they might cause more harm than good in the world.</p><p><strong>I have seen, and I am seeing every day, the dangers of completely unrestricted speech, and I don’t want to be the one enabling that.</strong></p><p>I know that last sentence is a strong ideological statement; some might call it a <em>political</em> statement, but for me it’s more than just political, which is often used to describe extemporary beliefs.</p><p>Many of you reading this will not agree with me, and that’s fine. I’m not going to try and change your beliefs with this blog post. Rather, I’m looking to explain why, while I respect that others might have differing opinions, I stopped doing anything that would actively advance a technology whose ethics I question. To put it in other terms: your freedom of speech isn’t my obligation to enable you and give you a platform.</p><p>In short, I think that while the Internet has helped the world in countless of ways, it has also brought out the worst in people.</p><p>I do believe we need some filters on the Internet. It’s not just about stopping criminal activities, terrorism and child pornography: while I am obviously unsupportive of all them, I also think they’re not the biggest dangers coming from the Internet (yet they’re a very convenient pretext for politicians).</p><p>Instead, I think that regular people’s writings on the Internet is hurting the world on a bigger scale. And the collective sentiment is often manipulated by some “agitators” that are exploiting anonymous online speech for their own agendas: that includes online militias–for example sponsored by foreign governments–whose goal is to destabilize a society.</p><p>In the last few years, completely unregulated online speech has given rise to fake news and conspiracy theories that have actually killed people. It’s offered a megaphone to those promoting dangerous ideas like white supremacy, Islamophobia, anti-Semitism, homophobia and other anti-LGBTQ positions, and sometimes outright Nazism. It has tilted many democracies towards right-wing populism and fascism.</p><p>All these extreme ideas have divided societies and increased social tensions. And they’re responsible for a number of acts of terrorism which caused the death of too many people.</p><p>Given our experiences so far, there’s no sign that indicates that a fully decentralized and unrestrained web would be anything but a dangerous wild west.</p><p>In fact, despite being tightly centralized and controlled, social media companies are facing significant challenges regulating what people write on their platforms, and in fact they are usually at the center of every scandal of these years. Decentralization and less control won’t be the solution to this issue, but rather the opposite.</p><p>If you believe that I’m overthinking this, and that it’s not going to be bad <em>this time</em>, I urge you to think twice.</p><p>First, there’s no indication that a new Web would be better than the previous one just on virtue of being decentralized. The same actors that are using today’s Internet to wreak havoc around the world would not disappear in the new Internet, and actually, they could be even more unrestrained.</p><p>Second, while almost everyone in the communities supporting a distributed web are good people, with good intentions, seeing some names in there is concerning to me. Regarding IPFS, advocates (at least for a while) included people like Nick Lim of BitMitigate and VanwaNet, companies responsible for rescuing, among others, <a href="https://www.geekwire.com/2017/seattles-bitmitigate-now-protecting-pro-nazi-site-daily-stormer-web-attacks/">pro-nazi website</a> The Daily Stormer <a href="https://arstechnica.com/information-technology/2019/11/breaking-the-law-how-8chan-or-8kun-got-briefly-back-online/">and the platform</a> 8chan, a cesspool full of Nazi propaganda, child pornography, and other hate speech. Gatherings on 8chan have been <a href="https://en.wikipedia.org/wiki/8chan#2019_shootings">blamed</a> for at least three mass shootings in 2019 alone, including the one in the <a href="https://time.com/5648479/8chan-ban-new-zealand/">mosque in Christchurch</a>, all of them motivated by racial hatred.</p><p>The first real examples of the distributed web aren’t particularly encouraging either. Among some of the most popular apps (“popular” in relative terms, of course) for the distributed web is DTube, a sort of YouTube that is built on top of IPFS. As you can expect, the website is full of questionable content, including conspiracy theories, cryptocurrency scams, weapons, RT&nbsp;International’s <a href="https://www.theguardian.com/commentisfree/2019/jul/26/russia-disinformation-rt-nuanced-online-ofcom-fine">Russian propaganda</a>… and of course, porn.</p><p>In essence, if it’s true that <em>a good beginning makes a good ending</em>… with such a mixed beginning, the outlook isn’t too rosy.</p><p>I understand that my opinion is somehow a minority one, and people will continue to build IPFS and other technologies part of the distributed web. There’s also a chance they might become successful and potentially get mainstream adoption–although at this stage the barrier to entry is too high for the average user.</p><p>However, I feel that it’s my responsibility to not be helping to advance this technology and the beliefs of at least some advocates in the world of the distributed web hold. If the advancement occurs, it won’t be because of my help.</p><hr><p><em>PS: The idea that freedom of speech is an absolute right that should have (almost) no limitations is not a universal one. While that right is granted to people living in all democratic countries, outside of North America it’s accepted that such right comes <a href="https://www.nytimes.com/2019/08/06/world/europe/el-paso-shooting-freedom-of-speech.html">with limitations</a>, and usually that has roots in the history of those places.</em></p><p><em>For example, in Italy where I grew up, the same constitution that grants freedom of expression (speech, press, etc) also criminalizes “apology of fascism”, or propagating the ideas of fascism; it also sets other limits on speech that is hateful or discriminatory. Other European countries have similar laws, such as the outlawing of Nazi rhetoric and symbology in Germany.</em></p></article></div>]]>
            </description>
            <link>https://withblue.ink/2020/11/12/maybe-we-shouldnt-want-a-fully-decentralized-web.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25312854</guid>
            <pubDate>Sat, 05 Dec 2020 08:31:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Modern Tire-pressure monitoring system Sensors: Let's try a DoS attack]]>
            </title>
            <description>
<![CDATA[
Score 60 | Comments 33 (<a href="https://news.ycombinator.com/item?id=25312714">thread link</a>) | @pabs3
<br/>
December 4, 2020 | http://www.mirider.com/weblog/2020/12/04#20201204_Modern_TPMS_Sensors_Lets_try_a_DoS_attack | <a href="https://web.archive.org/web/*/http://www.mirider.com/weblog/2020/12/04#20201204_Modern_TPMS_Sensors_Lets_try_a_DoS_attack">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  <td>&nbsp; &nbsp;</td>

  <!-- left column -->
  <td>

<!--
   <p>
   <br />
   <b>About</b> <br />
   Dieter Spaar's blog, Dieter Spaar's personal Blosxom blog.<br /><br />
   Dieter Spaar<br />
   <a href="mailto:spaar@mirider.com">spaar@mirider.com</a> <br />
   </p>
-->

   <p>
   <a href="http://www.mirider.com/weblog/index.rss">RSS</a>
   </p>

   <p>
     <b>Dieter's Web</b> <br>
     <a href="http://www.mirider.com/">mirider.com</a><br>
   </p>

   <p>
   <b>Projects I am participating</b> <br>
    <a href="http://bb.osmocom.org/" target="_blank">OsmocomBB</a><br>
    <a href="http://openbsc.osmocom.org/" target="_blank">OpenBSC</a><br>
    
   </p>

   <p>
   <b>Categories</b> <br>
   </p>
   <ul>
<li><a href="http://www.mirider.com/weblog/index.html">Root</a> (24)
<ul>
<li><a href="http://www.mirider.com/weblog/automotive/index.html">automotive</a> (3)
</li>
<li><a href="http://www.mirider.com/weblog/gsm/index.html">gsm</a> (17)
</li>
<li><a href="http://www.mirider.com/weblog/misc/index.html">misc</a> (1)
</li>
<li><a href="http://www.mirider.com/weblog/sdr/index.html">sdr</a> (2)
</li>
</ul>
</li>
</ul>


   <p>
   <b>Archives</b> <br>
   </p>
   <ul>
	<li><a href="http://www.mirider.com/weblog/2020/">2020</a> (1)
		<ul>
			<li><a href="http://www.mirider.com/weblog/2020/12/index.html">December</a> (1)</li>
		</ul>
	</li>
	<li><a href="http://www.mirider.com/weblog/2018/">2018</a> (5)
		<ul>
			<li><a href="http://www.mirider.com/weblog/2018/09/index.html">September</a> (1)</li>
			<li><a href="http://www.mirider.com/weblog/2018/05/index.html">May</a> (1)</li>
			<li><a href="http://www.mirider.com/weblog/2018/03/index.html">March</a> (1)</li>
			<li><a href="http://www.mirider.com/weblog/2018/01/index.html">January</a> (2)</li>
		</ul>
	</li>
	<li><a href="http://www.mirider.com/weblog/2013/">2013</a> (3)
	</li>
	<li><a href="http://www.mirider.com/weblog/2012/">2012</a> (4)
	</li>
	<li><a href="http://www.mirider.com/weblog/2011/">2011</a> (3)
	</li>
	<li><a href="http://www.mirider.com/weblog/2010/">2010</a> (8)
	</li>
</ul>


<!--
   <p>
   <b>Flavours</b> <br />
   There's more than one way to view this weblog; try these flavours on
   for size.
    <li><a href="http://www.mirider.com/weblog/index.index">index</a></li>
    <li><a href="http://www.mirider.com/weblog/index.1993">circa 1993</a></li>
    <li><a href="http://www.mirider.com/weblog/index.rss">RSS</a></li>
   </p>
-->
   <p>
   <b>Other Bloggers</b> <br>
    <a href="http://laforge.gnumonks.org/weblog/" target="_blank">Harald Welte</a><br>
    <a href="http://openbts.blogspot.com/" target="_blank">David Burgess</a><br>
   </p>

<!--
   <p>
   
   </p>
-->

   <p>
    <br>
    <a href="http://www.blosxom.com/"><img src="http://mirider.com/weblog/pb_blosxom.gif" alt="blosxom"></a>
   </p>

   <p>
    <br>
    <a href="http://www.mirider.com/#Site%20Contact">Contact/Impressum</a>
   </p>

  </td>

  <td>&nbsp; &nbsp;</td>

  <td>&nbsp; &nbsp;</td> 

  <!-- main blog entry column -->
  <td> 

   <br>

<span>Fri, 04 Dec 2020</span>
<div>
<p><a name="20201204_Modern_TPMS_Sensors_Lets_try_a_DoS_attack"><b>Modern TPMS Sensors: Let's try a DoS attack</b></a></p><p>
TPMS (Tire-pressure monitoring system) sensors have been researched extensively
many years ago, they periodically transmit the tire pressure, temperature
and a unique ID which can be misused for tracking a vehicle. But there is
another aspect: modern TMPS sensors also have a receiver which is typically
used to trigger the data transmission when a new TPMS sensor is presented to
the vehicle ("learning procedure").
</p>

<p>
Here in Europe TPMS sensors usually transmit on the 433 MHz ISM band. The
receiver operates on 125 kHz, very similar to LF RFID. A simple way to make
use of the receiver is just to look for the presence of the 125 kHz carrier
and then trigger data transmission. Current sensors are usually more evolved
and use a modulated carrier which contains command packets and only if the
correct command is received data transmission is triggered.
</p>

<p>
If you already have a receiver you can do of course more than just trigger
data transmission: For example there might be support for different
commands, some sensors even allow firmware updates this way.
</p>

<p>
One such command which is typically supported is switching the sensor into
"Shipping" mode. Why would you need that? When the sensor is operating
normally it waits for motion (there is an acceleration/shock sensor inside)
and only starts periodic data transmission when the wheel is rotating. This
is used to safe battery life. When the TPMS sensor is not yet mounted in the
tire it should not react on motion, that’s why there is this "Shipping" mode.
In this mode the sensor only wakes up every few seconds and looks if there
is a 125 kHz signal, if yes it checks for a valid command, for example the
command to trigger data transmission which usually also leaves "Shipping"
mode and switches the sensor into normal operation.
</p>

<p>
This "Shipping" mode can be misused: If you can switch a TPMS sensor of a
vehicle’s wheel into "Shipping" mode the sensor will no longer transmit data
and the vehicle's tire pressure control light will go on after a while.
Just to make it clear: This warning light is annoying to the driver, it
does not affect safety of the car because the deactivated TMPS sensor has
not affected the actual tire pressure.
</p>

<p>
I have looked at a few TPMS sensors for different cars if this really works,
I choose sensors for BMW and Ford cars. Please note that most certainly
other car manufactures are affected too, mainly because there are only a
few manufactures of TPMS sensors which deliver their sensors to various
car manufactures. My choice for BMW and Ford came from the fact that I
found lots of cheap, used sensor for those cars.
</p>

<p>
Also I only looked at "OEM" sensors for BMW and Ford, which means that those
sensors are mounted by the car manufacturer. There are also so called
"Universal" sensors which are typically mounted by tire dealers, there
are some notes about them at the end of this text.
</p>

<p>
It is quite easy to build a tool for transmitting data on 125 kHz: There
is this cheap EL-50448 TMPS sensor activation tool which only transmits a
carrier without modulation. However the hardware can easily be modified
to modulate the carrier: Most of the time OOK (On-Off Keying) is used
for communication, which means that the carrier is just turned on and off.
The EL-50448 uses a power driver with an unused "enable" pin to generate
the carrier, you can use this "enable" pin to modulate the carrier. The
data rate is slow, a frequently used rate is 3900 baud.  Most of the time
Manchester encoding of the data bits is used, which means that the carrier
changes twice as much (7800 changes per second). This is nothing special
and can be done with probably any microcontroller you prefer to use. The
hardware costs for such a setup are below EUR 20, the transmission range
is about 20 centimeters.
</p>

<p>
How can you find the command to switch to Shipping" mode? Brute force by
trying all possible commands is only an option if the command is short.
The reason is that the sensor only looks for the LF 125 kHz signal every
few seconds. If the command is not longer than two bytes brute force is
possible (it takes a few days), for longer commands it is impractical.
Please note that you also have to find a way to detect if the command you
send causes a reaction of the TPMS sensor, e.g. by monitoring the power
consumption of the sensor or receiving the 433 MHz data signal (which of
course only works if the command you send causes a data transmission).
</p>

<p>
Another option is looking at those TPMS tools which tire dealers and
car repair workshops use to check TPMS sensors. Some of those tools
might support switching a TPMS sensor into "Shipping" mode.
</p>

<p>
Those are the results I found (I won't go into the details to avoid misuse):
</p>

<ul>
<li><b>BMW:</b>

  A certain sensor used in several car models from TPMS Sensor manufacturer
  "A" can be switched into "Shipping" mode. The deactivated TPMS sensor can
  be activated again with a different command. Also if the sensor detects a
  fast pressure change (e.g. by inflating the tire) the sensor leaves
  "Shipping" mode. The command length is four bytes so brute force is no option. 

</li>

<li><b>Ford:</b>

  A certain sensor used in several car models from TPMS Sensor manufacturer
  "A" (the same manufacture as above for the BMW sensor) can be switched
  into "Shipping" mode, it is the same command as used by the BMW sensor
  from above. The deactivated TPMS sensor can be activated again with a
  different command.
  
  A certain sensor used in several car models from TPMS Sensor manufacturer
  "B" can be switched into "Shipping" mode. The deactivated TPMS sensor can
  be activated again with a different command. The command in this case is
  only two bytes and I tried all combinations which resulted in several more
  "interesting" commands, a few examples:


    <ul>
<li>
      It is possible to completely turn off the TPMS sensor. In this case it
      will no longer react on anything, you have to break open the sensor
      case and apply a hardware reset or disconnect the battery to reactivate
      it again.
</li>

<li>
      It is possible to switch the sensor into continuous "carrier transmit"
      mode on 433 MHz. In this mode the sensor will continuously transmit
      the 433 MHz carrier until the battery is empty or you apply a hardware
      reset (see above), it will not react on anything else. There are two
      other similar commands which transmit on the upper and lower shifted
      frequency (the sensor uses FSK modulation, Frequency Shift Keying, when
      transmitting data).
</li>
</ul>      

  Those examples show that it is basically possible to destroy this specific
  sensor by transmitting the appropriate command. Also if the sensor is in
  "carrier transmit" mode it probably disturbs the remote control car
  key fob which usually uses the same frequency as the TPMS sensor.
</li>
</ul>

<p>
You have to be close to the sensor to send those LF 125 kHz signals but it
only takes a few seconds to send the signal. Using a larger antenna (which is
basically a coil) for the transmitter, e.g. large enough to fit in a suitcase,
might extend the transmission range to more than a meter. 
</p>

<p>
How can those problems be avoided? This is actually quite easy, the command
to switch into "Shipping" mode should not be allowed if the measured tire
pressure is above a certain limit, which means that the sensor is mounted in
the tire of a vehicle. This also applies to those other commands of the sensor
from manufacturer "B" which are probably some kind of factory test or developer
commands. Please note that during my tests the commands I described were
possible even when the measured tire pressure was in the range of a typical
vehicle wheel.
</p>

<p>
I contacted the car manufactures (BMW and Ford) before I published this
article, this is the experience I made:
</p>

<ul>
<li>
  <b>BMW:</b>
  The contact information for reporting security issues can be found on
  the BMW website. I had a phone call with the responsible person within
  a few days after reporting the issue. BMW already knew the problem, they
  found it during an internal review. Their latest TPMS sensors have fixed
  the issue by blocking certain commands if the tire pressure is above a
  certain limit.
</li>

<li>
  <b>Ford:</b>
  I wasn't able to find a security contact on the website of Ford Germany
  so I contacted the person responsible for "Public Relation". He promised
  to look for someone who takes care of the issue I reported, after several
  days I got a reply that it is possible to disturb the TPMS system due to
  the nature of radio transmission and that this is a known problem. I wasn't
  able to communicate directly with the responsible person and I then replied
  that the reported issue is not about disturbance but a "Denial of Service"
  and that it is even possible to destroy a certain TPMS sensor used in Ford
  cars. I didn't receive any further information about the security issue, I
  notified them again after several weeks that I am now going to publish
  the issue which was acknowledged.
</li>
</ul>

<p>
Some notes about those "Universal" sensors tire dealers normally use: Those
sensors are "Universal" because they can be programmed for different car
models. The main benefit for the tire dealer is that only a few different
kind of "Universal" sensors have to be on stock, it’s not necessary to have
lots of different "OEM" TPMS sensors for every possible car model lying
around. The programming of those …</p></div></td></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://www.mirider.com/weblog/2020/12/04#20201204_Modern_TPMS_Sensors_Lets_try_a_DoS_attack">http://www.mirider.com/weblog/2020/12/04#20201204_Modern_TPMS_Sensors_Lets_try_a_DoS_attack</a></em></p>]]>
            </description>
            <link>http://www.mirider.com/weblog/2020/12/04#20201204_Modern_TPMS_Sensors_Lets_try_a_DoS_attack</link>
            <guid isPermaLink="false">hacker-news-small-sites-25312714</guid>
            <pubDate>Sat, 05 Dec 2020 07:53:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Reading Manpages Like a Pro (2018)]]>
            </title>
            <description>
<![CDATA[
Score 54 | Comments 31 (<a href="https://news.ycombinator.com/item?id=25311867">thread link</a>) | @woodruffw
<br/>
December 4, 2020 | https://blog.yossarian.net/2018/01/22/Reading-Manpages-Like-a-Pro | <a href="https://web.archive.org/web/*/https://blog.yossarian.net/2018/01/22/Reading-Manpages-Like-a-Pro">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">


<h2><em>Programming, philosophy, pedaling.</em></h2>

<ul>
    <li><a href="https://blog.yossarian.net/">Home</a></li>
    <li><a href="https://blog.yossarian.net/tags">Tags</a></li>
    <li><a href="https://blog.yossarian.net/favorites">Favorites</a></li>
    <li><a href="https://blog.yossarian.net/archive">Archive</a></li>
    
      <li><a href="https://yossarian.net/">Main Site</a></li>
    
</ul>

<hr>



<h2>
  <em>Jan 22, 2018</em>
</h2>

  <p>Tags:
  
    
    <a href="https://blog.yossarian.net/tags#programming">programming</a>,
    
  
    
    <a href="https://blog.yossarian.net/tags#workflow">workflow</a>
    
  
  </p>


<h3 id="preword">Preword</h3>

<p>I often reference the <a href="https://en.wikipedia.org/wiki/Man_page">manpages</a> when giving a development
presentation or talk, but I’ve only recently come to realize how few people are both <em>comfortable</em>
with the <code>man</code> interface and adept at discovering information through it.</p>

<p>This post is my attempt to share some of the tricks and techniques I’ve picked up over years of
reading manpages.</p>

<h2 id="a-quick-recap">A Quick Recap</h2>

<p>The manpages (short for “manual pages”) are the oldest and longest-running documentation collection
on *nix, stemming back to the
<a href="https://www.bell-labs.com/usr/dmr/www/1stEdman.html">first edition of the Unix Programmer’s Manual</a>
in 1971.</p>

<p>On a modern system, the <code>man</code> command is the most common way to access the manpages:</p>

<div><div><pre><code><span># access the first manpage named "time", which happens to be time(1)</span>
man <span>time</span>

<span># access a specific section's "time", in this case the C time function</span>
man 2 <span>time</span>

<span># attempt to access a nonexistent "time" in section 5</span>
man 5 <span>time</span>
</code></pre></div></div>

<p>Because the manpages were originally published on paper, they were (and continue to be) typeset with
<a href="https://en.wikipedia.org/wiki/Troff"><code>troff</code></a> on most systems. Today, the <code>man</code> command (and other
manpage readers) invoke <code>troff</code> internally and pipe the output to the user’s
<a href="https://en.wikipedia.org/wiki/Terminal_pager">pager</a> (like <code>more</code> or <code>less</code>).</p>

<p>In fact, a very simple manpage reader (which only works with section 1) can be implemented with
just three commands pipelined together:</p>

<div><div><pre><code><span>function </span>myman <span>{</span>
    <span># `-t` and `-e`: run `tbl` and `eqn` on the input, for tables and equations</span>
    <span># `-mandoc`: use a set of troff macros specifically for manpages</span>
    <span># `-Tutf8`: output UTF-8 text rather than PostScript</span>
    <span>gunzip</span> &lt; /usr/share/man/man1/<span>"</span><span>${</span><span>1</span><span>}</span><span>.1.gz"</span> | groff <span>-t</span> <span>-e</span> <span>-mandoc</span> <span>-Tutf8</span> | less
<span>}</span>

myman gcc
myman <span>ls</span>
</code></pre></div></div>

<p>Apart from their simplicity and adherence to the UNIX philosophy, <code>man</code> and the manpages serve a
number of important roles:</p>

<ul>
  <li>
    <p>They provide a categorization: section 1 is for system commands, 2 for system calls, 3 for library
functions, and so forth. This categorization is followed both by the system itself (which populates
several of the sections) and by programs installed by the user or package manager.</p>
  </li>
  <li>
    <p>They provide offline documentation: <code>man</code> doesn’t require an internet connection, and can provide
much of the documentation that an internet search would yield.</p>
  </li>
  <li>
    <p>They offer <em>canonical</em> information: searching for a command or function online might tell you
whether it exists, but won’t tell you the flags, arguments, or behavior specific to your system.
For example, <code>man ls</code> will tell you whether your system’s <code>ls</code> is BSD or GNU (and the differences
therebetween). The manpages (on Linux) will also tell you which feature macros you’ll need to define
in a C program in order to use a function (or a variant of a function).</p>
  </li>
</ul>

<p>So, let’s move on to some techniques.</p>

<h2 id="colorized-manpages">Colorized manpages</h2>

<p>One of the simplest things you can do to enhance the readability of manpages within <code>man</code> is to
colorize the pager’s output:</p>

<p><img src="https://blog.yossarian.net/assets/gcc_man.png" alt="A colorized version of `man gcc`"></p>

<p>In <code>less</code>, this is accomplished by setting the <code>LESS_TERMCAP_*</code> environment variables to your
preferred ANSI color codes. Here are the variables you can set:</p>

<div><div><pre><code>LESS_TERMCAP_mb <span># blinking mode (not common in manpages)</span>
LESS_TERMCAP_md <span># double-bright mode (used for boldface)</span>
LESS_TERMCAP_me <span># exit/reset all modes</span>
LESS_TERMCAP_so <span># enter standout mode (used by the less statusbar and search results)</span>
LESS_TERMCAP_se <span># exit standout mode</span>
LESS_TERMCAP_us <span># enter underline mode (used for underlined text)</span>
LESS_TERMCAP_ue <span># exit underline mode</span>
</code></pre></div></div>

<p>You may be able to set others corresponding to the
<a href="https://www.gnu.org/software/termutils/manual/termcap-1.3/html_chapter/termcap_5.html">termcap capability names</a>,
but the variables above should cover all of your manpage needs.</p>

<p>By way of example, here is the <code>bash</code> function I use to colorize my manpages:</p>

<div><div><pre><code>man<span>()</span> <span>{</span>
    <span>env</span> <span>\</span>
    <span>LESS_TERMCAP_mb</span><span>=</span><span>"</span><span>$(</span><span>printf</span> <span>"</span><span>\e</span><span>[1;31m"</span><span>)</span><span>"</span> <span>\</span>
    <span>LESS_TERMCAP_md</span><span>=</span><span>"</span><span>$(</span><span>printf</span> <span>"</span><span>\e</span><span>[1;31m"</span><span>)</span><span>"</span> <span>\</span>
    <span>LESS_TERMCAP_me</span><span>=</span><span>"</span><span>$(</span><span>printf</span> <span>"</span><span>\e</span><span>[0m"</span><span>)</span><span>"</span> <span>\</span>
    <span>LESS_TERMCAP_se</span><span>=</span><span>"</span><span>$(</span><span>printf</span> <span>"</span><span>\e</span><span>[0m"</span><span>)</span><span>"</span> <span>\</span>
    <span>LESS_TERMCAP_so</span><span>=</span><span>"</span><span>$(</span><span>printf</span> <span>"</span><span>\e</span><span>[1;44;33m"</span><span>)</span><span>"</span> <span>\</span>
    <span>LESS_TERMCAP_ue</span><span>=</span><span>"</span><span>$(</span><span>printf</span> <span>"</span><span>\e</span><span>[0m"</span><span>)</span><span>"</span> <span>\</span>
    <span>LESS_TERMCAP_us</span><span>=</span><span>"</span><span>$(</span><span>printf</span> <span>"</span><span>\e</span><span>[1;32m"</span><span>)</span><span>"</span> <span>\</span>
    man <span>"</span><span>${</span><span>@</span><span>}</span><span>"</span>
<span>}</span>
</code></pre></div></div>

<p>Note that you don’t need to use escape sequences as above — <code>tput</code> will work just fine.</p>

<h2 id="other-sections">Other sections</h2>

<p>I mentioned some of the big sections above: 1 for system commands, 2 for system calls, and so on.</p>

<p>90% of <code>man</code> lookups will be in those three, but there are a few lesser-known sections that can also
be useful:</p>

<ul>
  <li>
    <p><code>man 4</code> - Special files and devices</p>

    <p>On Linux, section 4 is used to document special files, usually representing some aspect of
  the machine or its peripherals. For example, <code>man 4 mem</code> will tell you how to use the
  <code>/dev/mem</code>, <code>/dev/kmem</code>, and <code>/dev/port</code> files to read from and write to the system’s main
  memory.</p>
  </li>
  <li>
    <p><code>man 5</code> - Configuration files and formats</p>

    <p>You probably know the <code>/etc/shadow</code> file, but do you know how its format is specified?
  <code>man 5 shadow</code> will tell you that. Similarly, <code>man 5 deb</code> describes the <code>.deb</code> package format,
  and <code>man 5 ppm</code> lists the spec for <a href="https://en.wikipedia.org/wiki/Netpbm_format">PPM images</a>.</p>
  </li>
  <li>
    <p><code>man Np</code> - POSIX pages</p>

    <p>These pages come in handy for contrasting POSIX behavior with the system’s behavior.</p>

    <p>Some examples:</p>

    <div><div><pre><code>  <span># compare the system ls (on Linux, GNU) to the POSIX ls behavior</span>
  man 1 <span>ls
  </span>man 1p <span>ls</span>

  <span># compare the read syscall to the POSIX read function</span>
  <span># note the categorization: POSIX read is a function, not a syscall!</span>
  man 2 <span>read
  </span>man 3p <span>read</span>
</code></pre></div>    </div>
  </li>
</ul>

<h2 id="searching-and-navigating">Searching and navigating</h2>

<p>Like colorization, searching is more of a general <code>less</code> feature than one specific to <code>man</code>. That
being said, <code>less</code>’s searching and navigating features can make browsing the manpages a much faster
and more pleasant experience.</p>

<p>Searches in <code>less</code> can be forwards or backwards, using the <code>/</code> and <code>?</code> commands respectively. The
search syntax is mostly POSIX ERE, but with some additions (<code>man less</code> has the details!).</p>

<p>For example, to find the first instance of “x86” in <code>man gcc</code> (watch the bottom of the screen for
the search prompt):</p>

<p><a href="https://asciinema.org/a/Wc0OiKVTrTDiP4tG9bPRWtDwM" target="_blank" rel="noopener noreferrer">
  <img src="https://blog.yossarian.net/assets/asc_Wc0OiKVTrTDiP4tG9bPRWtDwM.png">
</a></p>

<p>Observe that instances of the search term are highlighted with the standout colors from before.</p>

<p>Once a search term is entered, its results can be navigated via the <code>n</code> and <code>N</code> commands, which
move forwards and backwards in the results list respectively. For example, going through all
of the results for “Windows”:</p>

<p><a href="https://asciinema.org/a/n3S3wteHmbdPrtmyTSkCSVMiX" target="_blank" rel="noopener noreferrer">
  <img src="https://blog.yossarian.net/assets/asc_n3S3wteHmbdPrtmyTSkCSVMiX.png">
</a></p>

<p>When the last result has been jumped to, the statusbar changes to “Pattern not found”. Once that
happens, as in the video above, previous results can be returned to by hitting <code>N</code>.</p>

<p>Even this can be simplified: the <code>&amp;</code> command can be used to display only lines that match the given
pattern. For example, retrieving every line that contains either “ARM” or “ABI”:</p>

<p><a href="https://asciinema.org/a/Wh8QZ4eideLNmCMBmAkYExgEm" target="_blank" rel="noopener noreferrer">
  <img src="https://blog.yossarian.net/assets/asc_Wh8QZ4eideLNmCMBmAkYExgEm.png">
</a></p>

<p>The effect is more dramatic when searching for the definition of a flag (in this case <code>-D</code>):</p>

<p><a href="https://asciinema.org/a/17Kcnb8PBNIz8JdogOFKVeDQn" target="_blank" rel="noopener noreferrer">
  <img src="https://blog.yossarian.net/assets/asc_17Kcnb8PBNIz8JdogOFKVeDQn.png">
</a></p>

<p>These commands are just the tip of the iceberg — <code>less</code> supports searching multiple files at
once, jumping around scopes (opening and closing parentheses, braces, brackets), and marking the
current location for later return. Each of these is documented on the help screen, which you can
get to in any <code>less</code> session via the <code>h</code> command:</p>

<p><a href="https://asciinema.org/a/8i6kyFTbFttVTgDNbgnzyJvGB" target="_blank" rel="noopener noreferrer">
  <img src="https://blog.yossarian.net/assets/asc_8i6kyFTbFttVTgDNbgnzyJvGB.png">
</a></p>

<h2 id="wrapup">Wrapup</h2>

<p>Before picking up these tricks (especially searching), the manpages were an item of last resort
for me: I would search the internet or ask a friend, with mixed results. I had no real idea how to
use <code>less</code>, and would just clumsily page around until I found what I was looking for. More often
than not, I would give up entirely.</p>

<p>At the end of the day, the manpages (and the <code>man</code> interface) are not perfect — there’s no
hyperlinking or real cross-referencing, and the entire corpus is written in a 45+ year old
typesetting language designed for <em>physical</em> output, not display in a virtual terminal.</p>

<p>That being said, they’re a <em>fantastic</em> initial resource for pretty much anything concerning your
system — they remain up-to-date (unlike blogs and articles), they’re accurate and concise, and
they’re <em>very</em> UNIX-y (text files and pipelines!).</p>

<hr>

<h3 id="addendum">Addendum</h3>

<p>This post was discussed on <a href="https://news.ycombinator.com/item?id=25311867">HN</a>; a response
by <a href="https://news.ycombinator.com/item?id=25313405">‘djeiasbsbo</a> includes some additionally
useful tricks and advice.</p>


<hr>




  


  





</div>]]>
            </description>
            <link>https://blog.yossarian.net/2018/01/22/Reading-Manpages-Like-a-Pro</link>
            <guid isPermaLink="false">hacker-news-small-sites-25311867</guid>
            <pubDate>Sat, 05 Dec 2020 04:53:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Visualizing Poker Hands Geometrically]]>
            </title>
            <description>
<![CDATA[
Score 26 | Comments 7 (<a href="https://news.ycombinator.com/item?id=25311545">thread link</a>) | @chairmanwow1
<br/>
December 4, 2020 | https://evermontbills.com/blogs/prop-money-musings/a-new-way-to-look-at-poker-hands | <a href="https://web.archive.org/web/*/https://evermontbills.com/blogs/prop-money-musings/a-new-way-to-look-at-poker-hands">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article aria-labelledby="title-0">
  <div>
    <div>
      <div id="shopify-section-article-template">

<div>
  
<p>An interesting way for getting an intuitive sense for why <a href="https://en.wikipedia.org/wiki/Poker_probability" title="Poker hand probabilities">certain hands</a> are rare in poker, I've laid out all the cards in a standard deck in a grid:&nbsp;</p>
<p><img src="https://cdn.shopify.com/s/files/1/0502/8370/8606/files/blank_1024x1024.png?v=1607133617" alt="Array of Playing Cards" width="1024x1024" height="1024x1024">
</p>


<p>When I first learned to play poker, it took a while before I could get an intuitive understanding of the relationships between the various poker hands. Calculating their likelihood definitely helped get a handle on how many ways for a specific hand to actually occur there were.</p>

<p>Nonetheless, I think laying the hands out in a grid like this would have given me an intuitive understanding of the game much more quickly.&nbsp;</p>
<h2>Poker Hands shown geometrically</h2>
<p>So the lowest poker hand, high card, is the most common happening 50% of the time, but will rarely be the winning hand:</p>
<p><img src="https://cdn.shopify.com/s/files/1/0502/8370/8606/files/High_Card_1024x1024.png?v=1607134813" alt="High Card" width="1023" height="1023"></p>

<p>The next highest hand is a single pair which has a geometric interpretation of one column with two dots in it:&nbsp;</p>
<p><img src="https://cdn.shopify.com/s/files/1/0502/8370/8606/files/Pair_1024x1024.png?v=1607134853" alt="Pair" width="1024x1024" height="1024x1024"></p>

<p>Two pair has a similar flair to it, except this one has 2 vertical lines:</p>
<p><img src="https://cdn.shopify.com/s/files/1/0502/8370/8606/files/Two_Pair_1024x1024.png?v=1607134962" width="1024x1024" height="1024x1024"></p>

<p>Three of a kind is similar in spirit, but is much rarer than the two preceding hands happening once every 50 hands:&nbsp;</p>
<p><img src="https://cdn.shopify.com/s/files/1/0502/8370/8606/files/three_of_a_kind_1024x1024.png?v=1607135086" alt="3 of a kind" width="1024x1024" height="1024x1024"></p>

<p>For a straight, we need 5 cards that are in order without any gaps and can look kind of like a nice scatter plot:&nbsp;</p>
<p><img src="https://cdn.shopify.com/s/files/1/0502/8370/8606/files/straight_1024x1024.png?v=1607135179" alt="Straight" width="1024x1024" height="1024x1024"></p>

<p>A flush requires all 5 cards in the hand to be in a single horizontal row, but there can gaps between them:</p>
<p><img src="https://cdn.shopify.com/s/files/1/0502/8370/8606/files/flush_84512f1f-428d-4ed7-b703-9372fc3575d6_1024x1024.png?v=1607135233" alt="Flush" width="1024x1024" height="1024x1024"></p>

<p>A full house requires that all points be split into two lines of 3 and 2 points each:</p>

<p><img src="https://cdn.shopify.com/s/files/1/0502/8370/8606/files/full_house_1024x1024.png?v=1607135454" alt="Full House" width="1024x1024" height="1024x1024"></p>

<p>Four of a Kind requires a vertical line that spans the entire grid with an extra point tucked away somewhere:&nbsp;</p>
<p><img src="https://cdn.shopify.com/s/files/1/0502/8370/8606/files/4_of_a_kind_1024x1024.png?v=1607135655" alt="4 of a kind" width="1024x1024" height="1024x1024"></p>

<p>A straight flush is one of the tidiest hands as it requires all cards to be colinear on the same row and be immediately adjacent to each other:</p>
<p><img src="https://cdn.shopify.com/s/files/1/0502/8370/8606/files/straight_flush_1024x1024.png?v=1607135809" alt="Straight Flush" width="1024x1024" height="1024x1024"></p>

<p>The best hand that you can get is a subset of all the straight flushes that you can get. It's just a straight flush all the way against the right side of the grid with the 5 highest cards:&nbsp;</p>
<p><img src="https://cdn.shopify.com/s/files/1/0502/8370/8606/files/Royal_Flush_1024x1024.png?v=1607135877" alt="Royal Flush" width="1024x1024" height="1024x1024"></p>


<p>Looking at poker this way made me realize that there are some interesting hands that we could add to the game.&nbsp;</p>
<h2>Rectangle</h2>
<p>This hand is formed when you have 4 points that are <a href="https://mathworld.wolfram.com/Collinear.html" title="Mathematical Definition of colinearity">colinear</a> in both orthogonal axes (form a rectangle):&nbsp;</p>
<p><img src="https://cdn.shopify.com/s/files/1/0502/8370/8606/files/Rectangle_1024x1024.png?v=1607136065" alt="Rectangle Hand" width="1024x1024" height="1024x1024"></p>

<h2>Flower</h2>
<p>This one seems like it would be complicated to spot in the wild, but in reality it's a lot like a full house. You need a Three of a Kind and the other two cards need to be the same suit as one of your 3oK cards, and just before and after it. So, maybe it is a little complicated to spot, but it certainly is an interesting idea.&nbsp;</p>
<p><img src="https://cdn.shopify.com/s/files/1/0502/8370/8606/files/Screen_Shot_2020-12-04_at_18.42.56_1024x1024.png?v=1607136337" alt="Flower Hand" width="1024x1024" height="1024x1024"></p>

<h2>Want More?</h2>
<p>If you found this interesting, you'll probably love the 3D reconstruction we did of <a href="https://evermontbills.com/pages/walter-white-did-not-have-80m" title="Walter White's Cash Pile Counting">Walter White's cash pile</a> in order to count it.&nbsp;</p>
</div>


  <!-- /snippets/social-sharing.liquid -->







</div>
    </div>
  </div>
</article></div>]]>
            </description>
            <link>https://evermontbills.com/blogs/prop-money-musings/a-new-way-to-look-at-poker-hands</link>
            <guid isPermaLink="false">hacker-news-small-sites-25311545</guid>
            <pubDate>Sat, 05 Dec 2020 03:48:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[No One Ever Got Fired for Choosing React]]>
            </title>
            <description>
<![CDATA[
Score 60 | Comments 85 (<a href="https://news.ycombinator.com/item?id=25310462">thread link</a>) | @petercooper
<br/>
December 4, 2020 | https://jake.nyc/words/no-one-ever-got-fired-for-choosing-react/ | <a href="https://web.archive.org/web/*/https://jake.nyc/words/no-one-ever-got-fired-for-choosing-react/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>If you spend a lot of time on Hacker News, it’s easy to get taken by the allure of building a web app without a framework. There are a bunch of potential advantages (no bloat! bespoke to your project!) and being able to say you built something with minimal dependencies gets you Engineer Points.</p>
<p>That is, if you can pull it off.</p>
<p>I started a new side project recently. It’s a web-based graphics editor, so it needs to be a single page app. My time spent profiling <a href="https://songrender.com/">SongRender</a> for performance issues has made me a little wary of React for building interfaces that update at 60 frames per second, so I decided to avoid it. I’d go (mostly) vanilla and see how far that took me.</p>
<p>I installed <a href="https://lit-html.polymer-project.org/">lit-html</a> and got to work. “Components” were simply functions that returned lit-html template results. A big singleton at the top of the tree held onto all the application state, stored as a global variable within that module.</p>
<p>The first hurdle came when a component needed local state. I could have lifted it to the singleton, but that would have broken the component’s encapsulation. I noticed that lit-html directives can keep state, so I decided to use them to build a tiny component library — ignoring a warning from the lit-html developers that this wasn’t a supported use case.</p>
<p>My home-brewed library worked great… until I needed to run some code when a component appeared on the screen. I started digging through lit-html documentation and issues looking for a way to detect a directive’s lifecycle, but it became clear to me that going down that path would be painful.</p>
<p>At that point, I recalled <a href="https://tomdale.net/2015/11/javascript-frameworks-and-mobile-performance/">this quote by Tom Dale</a>:</p>
<blockquote>
<p>I have heard from many developers who have told me that they accepted the argument that vanilla JavaScript or microlibraries would let them write leaner, meaner, faster apps. After a year or two, however, what they found themselves with was a slower, bigger, less documented and unmaintained in-house framework with no community. As apps grow, you tend to need the abstractions that a framework offers. Either you or the community write the code.</p>
</blockquote>
<p>Fair enough. Let’s avoid that trap. What about a small framework? I’d heard a lot of good things about Svelte, and although I was slightly worried about the size of the Svelte community I figured it would be fine.</p>
<p>My migration attempt quickly ground to a halt when I wanted a parent component to apply some styles to a child component. In React, I’d pass a class name in from the parent as a <code>className</code> prop. In Svelte, that’s considered a workaround, and the actual feature is the subject of an <a href="https://github.com/sveltejs/rfcs/blob/master/text/0000-style-properties.md">RFC</a>.<sup id="fnref:1"><a href="#fn:1" role="doc-noteref">1</a></sup></p>
<p>Maybe this is an example of <a href="https://prog21.dadgum.com/160.html">dangling by a trivial feature</a>. But it’s so basic a capability that I’m surprised Svelte is on version three without an officially blessed way to do it. I ran into this limitation when I created my <strong>second component</strong>. Way before I got to try out any of the cool reactivity that earns Svelte all that buzz.</p>
<p>So I changed my mind and went with React. After an hour or so, I’d finished moving everything over — and my anxiety had vanished. I stopped worrying about having most efficient component system, and picked up work on the thing I wanted to build in the first place.</p>
<p>No, React isn’t perfect. It’s optimized for apps that make network requests and then display lists of things (i.e. most apps) which isn’t really what I’m doing here<sup id="fnref:2"><a href="#fn:2" role="doc-noteref">2</a></sup>. The performance is fine now, although I expect I’ll have to optimize as my project gets more complex.</p>
<p>But React lets me stop thinking about the framework. React gets out of my way. React is <a href="https://mcfunley.com/choose-boring-technology">boring</a>. React is actively developed. React has a giant ecosystem and a giant community. React is battle-tested on some of the most visited websites in the world.</p>
<p>I’m sure there are technically better ways to build a highly interactive interface on the web, but life is too short for me to spend hours trying to figure them out. There are things I want to create, and the only way I can actually create them is to stop spending so much time on tooling.</p>
<p>For now, I’m choosing React.</p>
<section role="doc-endnotes">
<hr>
<ol>
<li id="fn:1" role="doc-endnote">
<p>The solution they seem to have landed on — letting the child expose CSS custom properties as props — is actually pretty cool, though I don’t like that Svelte will silently wrap your component with an extra <code>div</code>. <a href="#fnref:1" role="doc-backlink">↩︎</a></p>
</li>
<li id="fn:2" role="doc-endnote">
<p>Although Dan, if you read this, the <a href="https://twitter.com/dan_abramov/status/1133341485133438982">“animation pass” mode</a> you’ve mentioned offhandedly sounds very relevant! <a href="#fnref:2" role="doc-backlink">↩︎</a></p>
</li>
</ol>
</section></div></div>]]>
            </description>
            <link>https://jake.nyc/words/no-one-ever-got-fired-for-choosing-react/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25310462</guid>
            <pubDate>Sat, 05 Dec 2020 00:52:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I accidentally built a spying app]]>
            </title>
            <description>
<![CDATA[
Score 172 | Comments 59 (<a href="https://news.ycombinator.com/item?id=25310316">thread link</a>) | @akeck
<br/>
December 4, 2020 | https://withblue.ink/2020/09/24/that-time-i-accidentally-built-a-spying-app.html | <a href="https://web.archive.org/web/*/https://withblue.ink/2020/09/24/that-time-i-accidentally-built-a-spying-app.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><p>In the fall of 2007, my parents gave me an unforgettable gift for my sixteenth birthday: a first-generation iPhone.</p><p>I still clearly remember watching the keynote in which Steve Jobs announced the first Apple-branded phone a few months earlier. As a teenager attending high school in my hometown of Vicenza, Italy, I tuned into the livestream just before dinner, carefully listening to every word he said. That evening, Jobs started announcing a “widescreen iPod with touch controls”, a “revolutionary mobile phone” and a “breakthrough Internet communications device”–theatrically pausing before confessing that he was actually talking about one single device: the iPhone. Thousands of miles away from me, you could hear attendees exploding cheerfully through the live feed. Jobs went on demoing this amazing invention that, a decade later, would end up changing much more than the mobile phones market: it directly or indirectly impacted our society through mobile web, app stores, changing work-life balance, and social media.</p><p>October came, and so did the day I finally got my iPhone. I was really excited as I was the first one in my social circle with one. Every other teenager (and adult!) that saw my phone reacted in awe and with lots of curiosity. More than a few were also secretly envious, something I secretly did not mind. To add to the novelty, at the time the iPhone was only available for sale in the US.</p><p>To get an iPhone for me, my father had to ask a friend traveling to New York on a business trip to bring one back on the plane with her. That was not the end of it, however, as all phones were locked to the AT&amp;T network. In order for me to be able to use my iPhone in Italy, I had to unlock it.</p><p>That process required learning a variety of tools and techniques developed by hackers in the community, then documented in various blogs and forums. The first step was to <em>jailbreak</em> the phone, which gave you full access to the system and allowed you to run third-party apps. Then you’d have add one of those “hacking” apps to your phone, which patched the bootloader to remove the lock the US carrier had put on it. Despite sounding like a mouthful, the iPhone hacking community had worked hard on the User Experience (UX), making this entire process relatively easy for most people with basic tech skills.</p><hr><p>I really loved my shiny, new iPhone, and I was so excited about it that I was willing to accept many of its original limitations. It only supported slow 2G networks, didn’t have copy/paste, couldn’t transfer files via Bluetooth to my friends, and <a href="https://www.apple.com/hotnews/thoughts-on-flash/">famously</a> didn’t support Adobe Flash, which was ubiquitous on the web at the time.</p><p>However, there was one thing I really couldn’t stand: the Messages application could only store 1,000 texts (SMS).</p><p>That was 2007 — before the days of WhatsApp, Facebook Messenger, Telegram, etc. Instant messaging was something people did on their PCs only, with things like Windows Live Messenger (née MSN Messenger) or AIM.</p><p>For a high schooler like me, text messaging was the main way I kept in touch with my friends daily (<em>what was I supposed to do, call them?</em>). With my carrier giving me a whopping 100 free texts per day (seriously, we had to pay for them), between sent and received texts it would take less than a week to reach the storage limit of 1,000.</p><p>That’s when it all started.</p><p>Because my iPhone was already “hacked” (jailbroken), as a requirement for unlocking it and use it in Italy, I had full system access already. That allowed me to c extract any document I wanted, including my phone’s text message database.</p><p>It wasn’t even a month since I got my iPhone that I had already built a small “app” running on my laptop to archive my text messages forever. I would manually extract the SMS database from my iPhone, copy it to my laptop, then use a set of scripts written in PHP (the only programming language I knew at the time) to store the messages in a local database, and finally display them using a web-based interface.</p><p>This thing I put together worked just fine for me, but I immediately realized the “business potential” of what I had just created. Just like myself, I assumed many others had the same annoyance. I could have used what I learned to help them too, and maybe make some pocket change in the process. As a matter of fact, I did consider myself an enterprising teenager.</p><p>The idea had potential, and the “app” I built for myself already provided solid foundations, so I just needed to do a bit more work to turn it into a commercially-viable project.</p><p>The biggest challenge was making the solution more accessible to others, including those who were not particularly tech-savvy. That’s when I started learning about app development for iPhone.</p><p>Famously, Apple did not want the iPhone to support third-party apps at the beginning, saying developers should build web apps instead. That policy didn’t last long, and with the iPhone OS 2 update, launched in mid-2008, the official App Store came to life: the rest, as they say, is history.</p><p>However, the hacking community had already found a way to sideload apps and had even developed an “app store” called Cydia where you could find games, apps, and even mods to enhance the capabilities of the operating system itself. Cydia came preinstalled on every <em>jailbroken</em> iPhone, which meant potentially hundreds of thousands of people had access to it.</p><p>Everyone could build apps that would be published on Cydia, as long as you knew how to–something that was not remotely as easy to do as it is with today’s tools. As an enterprising teenager with quite a bit of free time on my hand during those winter afternoons and evenings, I took on that challenge.</p><hr><p>The first version of YouArchive.It came out in January 2008.</p><p>Today, you would describe YouArchive.It as a cloud service to store iPhone text messages. You could store all your messages in there, then read and search them using a web-based application.</p><p>There’s still a video left on YouTube showing the application in action (this was the third, and last, version):</p><p><iframe src="https://www.youtube-nocookie.com/embed/ps5ohEhO3S4" allowfullscreen="" title="YouTube Video"></iframe></p><p>With YouArchive.It came an iPhone application too. Published on the Cydia app store, it allowed importing messages into the “cloud service” directly from the phone.</p><p>YouArchive.It was free to use with a limit of 80,000 text messages. Because personal communications can be sensitive, all messages were stored encrypted. With a one-time payment of just €5 (about $6), you could become a VIP, remove any limit and enjoy unlimited storage.</p><p><img src="https://cdn-images-1.medium.com/max/2000/1*vTxYRljXFl3IBXGRsXOVag.png" alt="A screenshot of iTextUploader running on a first-generation iPhone"></p><figcaption>A screenshot of iTextUploader running on a first-generation iPhone</figcaption><p>For the next year and a half, YouArchive.It continued to grow organically. A few blogs and websites dedicated to iPhone “hacking” and to the underground app stores wrote about the app. Even a small radio program in the US featured it</p><p>I continued developing the app as a side project while in high school. I was also providing tech support and maintaining the infrastructure.</p><p>Listening to users' feedback, I would periodically add new features. YouArchive.It started displaying emojis as soon as the iPhone supported that (outside of Japan, it required downloading an app to enable them). Users asked for and got the ability to restore texts in another iPhone, before iCloud was available. I also implemented other privacy features such as requiring a password to open the mobile app.</p><blockquote><h3 id="what-i-didnt-realize-at-the-time-however-is-that-i-had-unknowingly-and-unwillingly-built-a-spying-tool-and-a-really-convenient-and-efficient-one">What I didn’t realize at the time, however, is that I had, unknowingly and unwillingly, built a spying tool, and a really convenient and efficient one.</h3></blockquote><p>Enough users were paying the fee to become VIP that I could cover the costs of running the service–this was before everyone was using Amazon Web Services or Microsoft Azure, so I was renting a co-located physical server which wasn’t cheap–and keep some pocket cash. Not much, but enough to pay for some hobbies and outings with friends.</p><p>Most importantly, building YouArchive.It gave me a lot of satisfaction and the opportunity to learn a lot of things about software development, business, dealing with customers and listening to their feedback.</p><hr><p>When I finally shut the service down, in June 2010, YouArchive.It had about 32,000 registered users who stored over 76 million messages.</p><p>The first, and stated, reason for the deprecation was a technical one: YouArchive.It’s iPhone app required using private APIs, which meant it could not be published on the App Store (and it still couldn’t to this day), limiting it to <em>jailbroken</em> phones only.</p><p>The second reason however was the most important to me, even though I have not revealed it until now.</p><p>About a year before the app closed, in April 2009 I implemented a new feature that was requested by many users: the ability to upload texts automatically, in background, without user intervention. For paying “VIP” users only, the mobile app could automatically send all new text messages to YouArchive.It, as often as every 15 minutes.</p><p>Automatic upload was an incredible convenience for many users that wanted to hoard their texts like me, to keep them forever, search within them, print or export them, or just liked having a backup.</p><p>What I didn’t realize at the time, however, is that I had, unknowingly and unwillingly, built a spying tool, and a really convenient and efficient one.</p><p>Thanks to background uploads, people could install the YouArchive.It app on another person’s iPhone, set it up, maybe even hide it (something possible on a <em>jailbroken</em> iPhone), and then watch as the text messages come in, almost real-time. Jealous partners, stalkers and the likes could install this tool on an unknowing victim’s phone with relative ease.</p><p>I can’t remember how I discovered that — it might have been a support request from a user or a post in a bulletin board. I also can’t know how many people were using YouArchive.It for their own archiving rather than to spy on others. Realizing what my users were doing, however, made me feel really uncomfortable and I did not want any part of that anymore.</p><p>As a senior in high school, barely eighteen years-old, I realized for the first time how technology can have a …</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://withblue.ink/2020/09/24/that-time-i-accidentally-built-a-spying-app.html">https://withblue.ink/2020/09/24/that-time-i-accidentally-built-a-spying-app.html</a></em></p>]]>
            </description>
            <link>https://withblue.ink/2020/09/24/that-time-i-accidentally-built-a-spying-app.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25310316</guid>
            <pubDate>Sat, 05 Dec 2020 00:32:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Down Here, They Sometimes Call It 'Boy']]>
            </title>
            <description>
<![CDATA[
Score 65 | Comments 55 (<a href="https://news.ycombinator.com/item?id=25308101">thread link</a>) | @pelt
<br/>
December 4, 2020 | https://www.realclearbooks.com/articles/2020/11/17/down_here_they_sometimes_call_it_boy_585675.html | <a href="https://web.archive.org/web/*/https://www.realclearbooks.com/articles/2020/11/17/down_here_they_sometimes_call_it_boy_585675.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

                            

                                                        <!-- sphereit start -->
                            <!-- startprint -->

                            <!-- end article source sponsored -->

                                                                                                                                                                                                                                                                                                    
                                                                                        
                            
                            
                            
                            
                                
                                
                                                                                        
                                                            <div>
<p><a href="https://www.amazon.com/stores/page/60E52DB6-B5F7-48D8-8FC5-73A5CE8F8AF4"> <img src="https://assets.realclear.com/images/52/527328_5_.jpg"> </a></p>

<p>Regnery Publishing</p>


</div>
<p><em>The following is an excerpt from "<a href="https://www.amazon.com/stores/page/60E52DB6-B5F7-48D8-8FC5-73A5CE8F8AF4">Big White Ghetto: Dead Broke, Stone-Cold Stupid, and High on Rage in the Dank Woolly Wilds of the "Real America"</a>" by Kevin D. Williamson.</em></p>
<p>"Dogfood—yeah, <em>d</em><em>o</em><em>g</em><em>f</em><em>o</em><em>o</em><em>d</em>—because it looks like ground-up dog food.” He’s embarrassed to be talking about this. “Or sand, because it’s brown. Or diesel. Or killa or 9-1-1. That’s the influence of rap culture down here.” He is a young, clean-cut, Eagle Scout–ish white kid, hesitant about using the words “rap culture,” like he’s not sure if he’s allowed to say that. But he goes on, matter-of-factly. He’s been off heroin for only a few months, so the details are fresh in his mind, even if he remains a little hazy on parts of his autobiographical timeline. “The 9-1-1, they call it that because they want you to know it’s potent, that you’ll have to go to the emergency room.”</p>
<p>That’s a weird and perverse and nasty kind of advertising, but then dope-buying psychology isn’t very much like Volvo-buying psychology: Crashing is just another part of the ride. One spiteful dealer boasts about spiking his product with excessive amounts of fentanyl—a pharmaceutical analgesic used for burn victims and cancer patients—his plan being to intentionally send overdosed users to the hospital or the morgue . . . for <em>m</em><em>a</em><em>r</em><em>k</em><em>e</em><em>t</em><em>i</em><em>n</em><em>g</em> <em>p</em><em>u</em><em>r</em><em>p</em><em>os</em><em>e</em><em>s</em>. Once the word got out about the hideous strength of his product, that killa went right out the door ricky-tick.</p>
<p>The young man explaining the current vocabulary of opiate addiction in Birmingham is barely old enough to buy a beer, and his face and voice are soft. He describes the past several years of his life: “dope-sick and stealing,” going from job to job—eight jobs in six months—robbing his employers of everything not physically nailed to the floor, alienating his family, descending. He was an addict on a mission: “You’re always chasing that first shot of dope, that first high—and the first one for me almost killed me. I was seventeen or eighteen years old, and I met a guy who had just got out of prison, doing a thirteen-year sentence for heroin possession and distribution. He was staying at the Oak Mountain Lodge, which is a nice little classic place.” (In 2013, four police officers and a drug dog had to be treated for exposure to dangerous chemicals after raiding a suspected meth lab in that hotel; the customer reviews online are decidedly mixed.) “I was <em>snorting </em>heroin when I met up with him, and set him up with my connect. He offered to shoot me up, and I wanted to do it. And I remember him looking me in the eyes and telling me, ‘If you do this, you’ll never stop, and you’ll never go back.’ And I said, ‘Let’s do it.’”</p>
<p>He doesn’t know what happened for the next several hours. When he regained consciousness, his junkie buddy’s girlfriend was worriedly ministering to him.</p>
<p>“That was first thing in the morning,” he says. “That night, I did another one.”</p>
<p>Same results. “I’d nodded out from snorting it, but there’s nothing like shooting it.”</p>
<p>He was, he says, a “pretty good junkie” for a time.</p>
<p>This particular opiate odyssey starts off in a Walgreens, something that turns out to be absolutely appropriate. I’m headed up the south coast and then inland on the heroin highway up to Atlanta, starting from the Port of Houston, which connects that city with 1,053 ports in nearly 200 countries and which in December alone welcomed the equivalent of 63,658 20-foot cargo containers of goods into the United States. There was, the feds are pretty sure, some dope squirreled away in there. In fact, all sorts of interesting stuff comes in and out of Houston. In May, U.S. Customs seized a Fast Attack Vehicle with gun mounts headed to the Netherlands. It hadn’t been ordered by the Dutch military. (Organized crime in the Netherlands is bananas: A raid in the summer of 2020 found Dutch police opening up a shipping container expecting to find it loaded with narcotics or stolen goods, but what they found instead was a dentist’s chair bolted to the floor and handcuffs hanging overhead—it was set up as a mobile torture chamber, God knows why.) I’m at Walgreens because I’ve got a long drive ahead and I’m going to be out of pocket for a bit, and I have a prescription to fill: an honest-to-goodness Schedule II Controlled Substance, in the official nomenclature, a term that covers some pretty interesting stuff, including the oxycodone and fentanyl I’ll be hearing so much about in the next few days. Some of us are going to heaven, some of us are going to hell, but all of us have to stop at Walgreens first.</p>
<p>The clerk is on the phone with a doctor’s office: “What’s your DEA number?”</p>
<p>For working-class white guys who haven’t found their way into the good jobs in the energy economy or the related manufacturing and construction booms that have reverberated throughout the oil patch, who aren’t college-bound or in possession of the skills to pay the bills, things aren’t looking so great: While much of the rest of the world gets healthier and longer-lived, the average life expectancy for white American men without college educations is declining. Angus Deaton, the Princeton economist who won the Nobel Prize in 2015, ran the numbers and found (in a study co-authored by his Princeton colleague Anne Case) that what’s killing what used to be the white working class isn’t diabetes or heart disease or the consumption of fatty foods and Big Gulps that so terrifies Michael Bloomberg, but alcohol-induced liver failure, along with overdoses of opioid prescription painkillers and heroin: Wild Turkey and hillbilly heroin, and regular old heroin, too, the use of which has increased dramatically in recent years as medical and law-enforcement authorities crack down on the wanton overprescription of oxy and related painkillers.</p>
<p>Which is to say: While we were <em>ignoring </em>criminally negligent painkiller prescriptions, we helped create a gigantic population of opioid addicts, and then, when we started paying attention, the first thing we did was take away the legal (and quasi-legal) stuff produced to exacting clinical standards by Purdue Pharma (maker of OxyContin) and others. So: lots of opiate addicts, fewer prescription opiates.</p>
<p>What was left was diesel, sand—<em>d</em><em>o</em><em>g</em><em>f</em><em>o</em><em>o</em><em>d</em>.</p>
<p>The clerks at this Walgreens are super friendly, but the place is set up security-wise like a bank, and that’s to be expected. This particular location was knocked over by a young white man with a gun the summer before last, an addict who had been seen earlier lurking around the CVS down the road. This is how you know you’re a pretty good junkie: The robber walked in and pointed his automatic at the clerk and demanded oxy first, then a bottle of Tusinex cough syrup, and then, almost as an afterthought, the $90 in the till. Walgreens gets robbed a lot: In January, armed men stormed the Walgreens in Edina, Minnesota, and stole $8,000 worth of drugs, mainly oxy. In October, a sneaky young white kid in an Iowa State sweatshirt made off with more than $100,000 worth of drugs—again, mainly oxy and related opioid painkillers, from a Walgreens in St. Petersburg, Florida. Other Walgreens locations—in Liberty, Kansas; East Bradford, Pennsylvania; Elk Grove, California; Kaysville, Utah; Virginia Beach; New Orleans—all have been hit by armed robbers or sneak thieves over the past year or so, and there have been many more oxy thefts.</p>
<p>It won’t make the terrified clerks feel any better, but there’s poetic justice in that: In 2013, Walgreens paid the second-largest fine ever imposed under the Controlled Substances Act for being so loosey-goosey in handling oxy at its distribution center in Jupiter, Florida, that it enabled untold quantities of the stuff to reach the black market. The typical pharmacy sells 73,000 oxycodone pills a year; six Walgreens in Florida were going through more than 1 million pills a year—each. A few years before that, Purdue was fined $634.5 million for misleading the public about the addictiveness of oxycodone. Kentucky, which has been absolutely ravaged by opiate addiction, is still pursuing litigation against Purdue, and it has threatened to take its case all the way to the Supreme Court, if it comes to that.</p>
<p>Ground Zero in the opiate epidemic isn’t some exotic Taliban-managed poppy field or some cartel boss’s fortified compound: It’s right there at Walgreens, in the middle of every city and town in the country.</p>
<p>I pick up my prescription and get on my way.</p>
<p>The next afternoon, having driven past billboards advertising boudin and strip joints with early-bird lunch specials and casino after casino after sad little casino; help-wanted signs for drilling-fluid businesses and the Tiger Truck Stop (which has a twenty-four-hour Cajun café and an actual no-kidding <em>live tiger </em>in a cage out front); past Whiskey Bay and Contraband Bayou, where the pirate Jean Lafitte once stashed his booty; around the Port of New Orleans, another <em>entrepôt </em>for heroin and cocaine—it is almost as close to Cartagena as it is to New York—I arrive at a reasonably infamous New Orleans drug corner, where I inquire as discreetly as I can about the availability of prescription …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.realclearbooks.com/articles/2020/11/17/down_here_they_sometimes_call_it_boy_585675.html">https://www.realclearbooks.com/articles/2020/11/17/down_here_they_sometimes_call_it_boy_585675.html</a></em></p>]]>
            </description>
            <link>https://www.realclearbooks.com/articles/2020/11/17/down_here_they_sometimes_call_it_boy_585675.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25308101</guid>
            <pubDate>Fri, 04 Dec 2020 21:15:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A Continuous Integration Mystery]]>
            </title>
            <description>
<![CDATA[
Score 26 | Comments 25 (<a href="https://news.ycombinator.com/item?id=25306898">thread link</a>) | @basicallydan
<br/>
December 4, 2020 | https://danhough.com/blog/ci/ | <a href="https://web.archive.org/web/*/https://danhough.com/blog/ci/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		<header>
			
			<p>
				<span>Published 03 December 2020 in Vancouver, BC, Canada</span>
				
				<span title="It took me about 5 minutes to read this blog post back to myself.">(~5min read)</span>
				
			</p>
		</header>
		<p>Yesterday I faced a version control situation I rarely face.</p>

<p>It showed me that I may rely a little too much on the green light from CI tools like CircleCI and GitHub Actions when deciding whether it’s safe to merge a branch.</p>

<p>Here’s what happened:</p>

<ol>
  <li>My colleague added new <code>expect</code> clauses to a test, plus the code to <strong>pass it</strong>.</li>
  <li>They merged this into the main branch via a PR.</li>
  <li>Later, I forked off of the main branch.</li>
  <li>I added <strong>more new clauses</strong> to the test my colleague had earlier modified.<br>I worked on it for the rest of the day.</li>
  <li>I made a <strong>pull request</strong>.</li>
  <li>Next, two colleagues reviewed my work and approved it on GitHub.<br>All the pre-merge checks on CircleCI were passing, including tests and style checks.<br>I rebased and decided to save the merge for the morning.</li>
  <li>Soon after, an error was found related to the code the first colleague had deployed.<br>They <strong>reverted</strong> the PR they had merged on Day 1.</li>
  <li>Not long after, I checked my PR again - there were no merge conflicts.<br><strong>I merged my code</strong>.</li>
</ol>

<p>An hour or so later, another colleague tells me that, according to CircleCI, a test I wrote was failing on the main branch. How could this be, they said? It appears to have been passing on the branch it came from!</p>

<p>What is the cause of this mysterious failure?</p>

<p>I’d recently touched that test, so I looked at the error and quickly worked out what it was: The test I’d added to was failing because one of it’s <code>expect</code> clauses relied on code which had been been reverted - it was no longer a valid expectation. GitHub didn’t run a new diff on my PR after the removal of the clause in question from the main branch; the reverted test code simply looks ‘unchanged’ in the diff, as if it had been and was still there.</p>

<p>I didn’t remove it, I didn’t rebase, and my PR ended up re-adding the recently-removed <code>expect</code> clause even though it didn’t appear to.</p>

<p>Is there a lesson to be learned here?</p>

<p>On one hand, the process is working. There was a merge error caused by the <code>git</code> equivalent of a race condition, we were told about it, and we were able to resolve it. Why bother running tests on the main branch before you deploy unless you are concerned that there is a chance they’ll fail?</p>

<p>Maybe the lesson is to keep on doing what we’re doing.</p>

<p>On the other hand, the process felt like it was disrupting the order of things. Something like this is often said: “if you have a reliable QA and CI process, then if something is on the main branch it should be deployable.” And yet here was an anomalous case which suggested otherwise.</p>

<p>Perhaps, then, the lesson is that our QA and CI process isn’t robust enough. Should CI create a merged branch behind-the-scenes and run tests on <em>that</em> before allowing the branch to be merged?</p>

<p>I’m not sure. In the meantime, while I try to decide what the lesson is, I think I’ll just rebase my branches more often.</p>

<p>A <a href="https://news.ycombinator.com/item?id=25306898">discussion has begun on Hacker News</a>, please share your thoughts if you have any.</p>

		<p>Heckle me on Twitter <a href="http://twitter.com/basicallydan">@basicallydan</a>.</p>
	</div></div>]]>
            </description>
            <link>https://danhough.com/blog/ci/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25306898</guid>
            <pubDate>Fri, 04 Dec 2020 19:53:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Myth of Code Coverage]]>
            </title>
            <description>
<![CDATA[
Score 83 | Comments 103 (<a href="https://news.ycombinator.com/item?id=25306071">thread link</a>) | @ingve
<br/>
December 4, 2020 | https://preslav.me/2020/12/03/the-myth-of-code-coverage/ | <a href="https://web.archive.org/web/*/https://preslav.me/2020/12/03/the-myth-of-code-coverage/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<div id="post-body"><p>One question I often ask potential software engineering candidates is to pinpoint the percentage of code coverage in an ideal project. Interestingly enough, many of them jump to the sky with numbers beyond 90%. They would start preaching how well-tested code is more reliable and brings more value to all stakeholders. When I ask about the current projects they work on, the reality looks a bit more down to earth.</p><p>Want to know my answer? I'd say it's <strong>around 66.7%</strong>.</p><p>The reasons for that vary, but allow me to be blunt and say that <strong>1/3 of the code every software project is irrelevant, buggy, overly complicated, or simply sucks.</strong> It has a reason to be where it is, but chances are, one year down the road, it will become a liability. Being dogmatic about tests and covering every line will only make it more difficult to get rid of it.</p><p>See, no two lines of code are equal in value and importance. Adding a new feature to an existing application affects its capabilities only marginally. However, it takes a proportionally large amount of time to develop and integrate due to the existing complexity. The bigger the complexity, the longer it takes to introduce new functionality. By the time the feature finds itself in production, it may as well be already irrelevant.</p><blockquote>The only sure-fire way to improve code coverage (and by that keep software relevant) is to identify and remove the unnecessary code.</blockquote><p>How do you identify irrelevant code? Don't search for it. Instead, let it reveal itself to you. One dimension of software that few teams make good use of, is its history. Git is a great analysis tool. Start using it not only to prevent future problems but also, to understand where and how often certain parts of the code change over time.</p><p>Chances are, you will find pieces of code that have undergone fewer changes than the rest in long periods. Those are the pillars of your application - the 2/3s that <strong>must be well-tested</strong>.</p><p>You will also find others where changes occur more or less every week. Ask yourselves whether those are still relevant, both from a technical and business perspective. Adding tests for the sake of coverage would have the opposite effect of increasing the code quality. In a perfectly-design software project, the part that is allowed to change most often is the configuration. A simple analysis of the code change frequency would show whether that is the case. If it isn't, try separating the moving parts from the core logic. If this is not feasible either, most probably those portions of the code don't belong to the codebase anyway. Turning them into interchangeable scripts (even stored in a separate repository) is one way of tackling them in their own right.</p><p>Let's not get too much into technical details. I have already alluded to the work of <a href="https://twitter.com/AdamTornhill">Adam Tornhill</a> on code analysis in a previous post of mine:</p><figure><a href="https://preslav.me/2020/03/01/use-the-git-history/"><div><p>Use the Git History to Identify Pain Points in Any Project</p><p>Have you heard of Adam Tornhill [https://twitter.com/AdamTornhill]’s work? If
not, I highly recommend that you set some time aside and check out Your Code as
a Crime Scene [https://amzn.to/32DM1G9] or Software DEsign X-Rays
[https://amzn.to/2vtbjdR…</p><p><img src="https://preslav.me/favicon.png"><span>Preslav Rachev</span></p></div><p><img src="https://www.gravatar.com/avatar/fd47e6bba1f42ecacf2e7af9e4c5fb52?s=250&amp;d=mm&amp;r=x"></p></a></figure><p>In a future post, I will discuss some of the new ideas I applied to the simple git one-liner I presented there.</p></div>
</div></div>]]>
            </description>
            <link>https://preslav.me/2020/12/03/the-myth-of-code-coverage/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25306071</guid>
            <pubDate>Fri, 04 Dec 2020 18:46:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Fable 3: F# to JavaScript compiler]]>
            </title>
            <description>
<![CDATA[
Score 239 | Comments 123 (<a href="https://news.ycombinator.com/item?id=25305650">thread link</a>) | @adamnemecek
<br/>
December 4, 2020 | https://fable.io/blog/Announcing-Nagareyama-4.html | <a href="https://web.archive.org/web/*/https://fable.io/blog/Announcing-Nagareyama-4.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Today is the day, Fable 3 Nagareyama is officially released! Does this mean the latest version is bug-free? Probably not, but at least the install command is shorter. We have also tested the release candidates in many projects and managed to fix all the outstanding issues so if you find a problem when upgrading your Fable 2 project you may even consider yourself lucky (also, please report).</p>
<p>First things first, I have to acknowledge all the people that have contributed to this release: from Don Syme himself to ncave, our mysterious contributor, and all the early-users that have helped polish this release. Very importantly, the teachers too that take care of my children in difficult times so I can focus on programming. The fact that so many people can collaborate together to put a project like Fable forward still feels like magic to me and I can only say a big THANK YOU to you all. I'm also very happy this is coincidental with the release of F# 5, as incredibly smart people are putting a lot of effort to make the development experience with the language really pleasant. Quoting Krzysztof Cieślak, what a great time to be an F# developer!</p>
<p>How can you try Fable 3, you say? This is it:</p>
<pre><code>dotnet tool install fable
dotnet fable src</code></pre><p>(Change "src" with the path to your project.) It's that easy, type <code>dotnet fable --help</code> to see more options. Of course you still need extra tooling to bundle the JS code, spin off a development server, etc. If you're upgrading an app using Webpack, please <a href="https://github.com/MangelMaxime/fulma-demo/pull/43">check this PR for reference</a>.</p>
<p>Let's quickly go through the highlights of Nagareyama:</p>
<ul>
<li>It's Fable v3. Three is bigger than two, that's already a win.</li>
<li>There are no breaking changes, your Fable 2 project should compile as is with Nagareyama (you may need to update some libraries).</li>
<li>It's a dotnet tool, following suit with most F# project. Remember when Fable, Paket and Fake had each their own way to be downloaded and version-managed? Those days are happily gone!</li>
<li>It removes the inter-process communication with JS, greatly simplifying Fable usage and development.</li>
<li>The previous point together with other fixes have improved the compilation speed by a big deal. Expect it to be at least cut in half in most cases!</li>
<li>Fable is not tightly coupled with a specific bundler anymore like Webpack so you can use any tool you like! (Webpack is still a great choice.)</li>
<li>A lot of effort has been also put to prettify the generated code, making it more readable and easier to debug if needed.</li>
<li>Nagareyama can accept plugins by library authors. Zaid is already using this feature to make it much simpler to <a href="https://youtu.be/a6Ct3CM_lj4?t=860">write React components compatible with JS tooling</a>.</li>
</ul>
<p>You can check the <a href="https://fable.io/blog/Announcing-Nagareyama-3.html">previous posts</a> for more details.</p>


<p>So what are you waiting for? Give Nagareyama a try and let the world know if it goes well... and let us know (privately) if it doesn't 😅 Have fun!</p>
</div></div>]]>
            </description>
            <link>https://fable.io/blog/Announcing-Nagareyama-4.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25305650</guid>
            <pubDate>Fri, 04 Dec 2020 18:08:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Porting a 100% local app to the web]]>
            </title>
            <description>
<![CDATA[
Score 159 | Comments 79 (<a href="https://news.ycombinator.com/item?id=25304100">thread link</a>) | @jlongster
<br/>
December 4, 2020 | https://actualbudget.com/blog/porting-local-app-web | <a href="https://web.archive.org/web/*/https://actualbudget.com/blog/porting-local-app-web">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p>While researching <a href="https://actualbudget.com/blog/cursed-caching-curious">a curious caching bug</a>, I got inspired to take another look at how Actual stores data locally on the web. There's some history I need to explain. Years ago, Actual was only going to be a desktop app. That means <em>all</em> of your data is stored locally. No server.</p><p>Then I realized how important mobile is, and that most people don't want to worry about losing their data if they drop their computer in the ocean. A syncing engine was born, and desktop and mobile apps have happily synced their data ever since. A copy is kept on a server so users can login and easily view their data, and if they worry about privacy they can enable <a href="https://actualbudget.com/docs/overview/syncing-across-devices/#end-to-end-encryption">end-to-end encryption</a>.</p><p>In the last year I grew jealous of web apps. Look at how easily they can deploy… how quickly they can drop users right into the app. No install required. Here I am asking users to download an 80MB file just to run the app. That download absolutely kills conversion rates, and makes the login flow, support, a/b testing and <em>everything</em> much harder.</p><p>I love desktop apps because you have access to much better tech (like native sqlite3), the app is super fast (no network calls), and the user owns their data. However, I can't ignore that the benefits of the web <a href="https://www.kalzumeus.com/2009/09/05/desktop-aps-versus-web-apps/">dwarfs these advantages</a>.</p><p>I started thinking about a web version of Actual. After some hacking, <a href="https://app.actualbudget.com/">I got it working</a> without changing the architecture. That means all your data is still stored locally in the browser, and there are no network calls. It's a completely 100% "local" app in the browser [0].</p><p>I haven't marketed the web version much because it hasn't been tested enough, and it needs improvements like lazy loading code to make it load faster. The biggest thing I'm worried about is the data storage layer. Since <strong>all your data is local</strong>, if something goes wrong there you could potentially lose data. And we're really stressing the browser's persistant db by storing everything in it.</p><p>To be clear: <strong>we are not deprecating the desktop version</strong>. However in the future the web version will be the primary platform, with the choice to download the desktop version if desired.</p><p>The way it works a bit unusual. Here's a high-level overview:</p><ul><li>Actual uses <a href="https://www.sqlite.org/index.html">sqlite3</a>. This is a hard requirement. The app runs tons of complex SQL queries to aggregate financial data and it's so good at doing it. Queries are easy to express and run super fast.</li><li>On desktop and mobile, native sqlite3 is used. The web does not support sqlite3, however. To get around this, Actual uses a <a href="https://github.com/sql-js/sql.js">wasm version</a> of sqlite3 and creates an in-memory db.</li><li>The obvious problem is persistence. When you make changes, we need to persist them somewhere so when the user reloads they don't lose their data. Luckily we are using <a href="https://en.wikipedia.org/wiki/Conflict-free_replicated_data_type#State-based_CRDTs">state-based CRDT's</a> and all updates come through as a list of "messages". If you are online, these messages get synced to our server so when you reload, all your data should sync up.</li><li>It's not ideal to require a big sync every time you open the app though. Also, if you are offline there shouldn't be any chance of losing data. To solve this, Actual persists each message into IndexedDB. When the app opens, it applies all messages from the local IndexedDB to get up-to-date.</li><li>It's <em>still</em> not ideal to require applying any messages on load. It won't scale - if you use the app for months you'll accumulate tens of thousands of messages. IndexedDB would grow indefinitely and loading the app would get slower. To solve this, when the stored messages crosses a threshold it flushes the entire sqlite3 db to IndexedDB and clears all the messages.</li><li>That means both a binary representation of the sqlite3 db and a list of messages is persisted in IndexedDB. On load, the app creates the in-memory sqlite3 db from the snapshot and applies any remaining messages from IDB.</li></ul><p>Turns out this is similar to how a <a href="https://sqlite.org/wal.html">write-ahead log</a> works.</p><p>I was worried about the reliability of IndexedDB. Reading the docs it seems like browsers might delete databases as needed, but in practice this doesn't seem to happen [1]. It's probably a much bigger problem on mobile where memory is scarce, but I don't mess with the mobile web (use a native app instead). I was also worried about hitting the limit of IDB storage, but as explained next that hasn't been a problem.</p><p>This technique started as an experiment, but it has worked surprisingly well. I have 5 years worth of data in Actual, and the size of the sqlite3 db is 9.7MB. The threshold of the messages table is around 50KB, so in total I'm storing ~10MB in IndexedDB for a user who's been around for 5 years. It's not even close to hitting the IndexedDB max storage limit, which these days is at least 500MB.</p><p>While it has worked so far, I want to be 100% confident in this approach. I've been digging deep into how each browser stores IndexedDB data on disk and discovered a couple improvements I can make. I was going to write about them in this post, but I ended up writing more about the overall approach. In the next post I'll dig deep into how IndexedDB works across browsers.</p><p>[0] While I didn't talk about it in this post, this also means that the entire app runs in the browser. The "backend" runs in a background worker thread and everything happens locally.</p><p>[1] If the local data does somehow get corrupted or deleted, it's not a <em>huge</em> deal. All changes are still sent off and stored on a server (which is how all other devices get synced). If something goes wrong, the app can re-download your data from the server. The only case where you'd lose data is if you were offline and lost your local data, which is to be expected.</p></div></div></div>]]>
            </description>
            <link>https://actualbudget.com/blog/porting-local-app-web</link>
            <guid isPermaLink="false">hacker-news-small-sites-25304100</guid>
            <pubDate>Fri, 04 Dec 2020 16:23:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Mannequin.js: An Articulated Mannequin Figure Library]]>
            </title>
            <description>
<![CDATA[
Score 149 | Comments 16 (<a href="https://news.ycombinator.com/item?id=25302602">thread link</a>) | @petercooper
<br/>
December 4, 2020 | https://boytchev.github.io/mannequin.js/ | <a href="https://web.archive.org/web/*/https://boytchev.github.io/mannequin.js/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      
      
      

      

<ul>
  <li><a href="#About">About</a></li>
  <li><a href="#Initialization">Initialization</a>
    <ul>
      <li><a href="#Minimal-program">Minimal program</a></li>
      <li><a href="#Figure-types">Figure types</a></li>
    </ul>
  </li>
  <li><a href="#Body-parts">Body parts</a>
    <ul>
      <li><a href="#Central-body-parts">Central body parts</a></li>
      <li><a href="#Upper-limbs">Upper limbs</a></li>
      <li><a href="#Lower-limbs">Lower limbs</a></li>
    </ul>
  </li>
  <li><a href="#Body-posture">Body posture</a>
    <ul>
      <li><a href="#Static-posture">Static posture</a></li>
      <li><a href="#Dynamic-posture">Dynamic posture</a></li>
    </ul>
  </li>
  <li><a href="#Other-functions">Other functions</a>
    <ul>
      <li><a href="#Custom-colors">Custom colors</a></li>
      <li><a href="#Hiding-body-parts">Hiding body parts</a></li>
      <li><a href="#Custom-body-parts">Custom body parts</a></li>
      <li><a href="#Global-position">Global position</a></li>
    </ul>
  </li>
  <li><a href="#Future-plans">Future plans</a></li>
</ul>


<p><strong>Mannequin.js</strong> is a simple library of an articulated mannequin figure. The shape of the figure
and its movements are done purely in JavaScript. The graphics is implemented in
<a href="https://threejs.org/">Three.js</a>. Click on an image to open a live demo.</p>

<p><a href="https://boytchev.github.io/mannequin.js/examples/example-posture.html"><img src="https://boytchev.github.io/mannequin.js/examples/snapshots/example-posture.jpg" width="150"></a>
<a href="https://boytchev.github.io/mannequin.js/examples/example-figure-types.html"><img src="https://boytchev.github.io/mannequin.js/examples/snapshots/example-figure-types.jpg" width="150"></a>
<a href="https://boytchev.github.io/mannequin.js/examples/example-custom-body-parts.html"><img src="https://boytchev.github.io/mannequin.js/examples/snapshots/example-custom-body-parts.jpg" width="150"></a>
<a href="https://boytchev.github.io/mannequin.js/examples/example-point.html"><img src="https://boytchev.github.io/mannequin.js/examples/snapshots/example-point.jpg" width="150"></a>
<a href="https://boytchev.github.io/mannequin.js/examples/example-scene.html"><img src="https://boytchev.github.io/mannequin.js/examples/snapshots/example-scene.jpg" width="150"></a></p>

<p>This is the fourth incarnation of the mannequin figure. The first one was implemented
in Elica. The second one was implemented in C/C++ and OpenGL. The third one
was implemented in JS/Three.js and is a direct predecessor of the current mannequin.js.
Since its first incarnation, mannequin.js is used in the course <em>Fundamentals of Computer Graphics</em> for Computer Sciences undergraduate students from the
<a href="https://www.fmi.uni-sofia.bg/en">Faculty of Mathematics and Informatics</a>
at <a href="https://www.uni-sofia.bg/index.php/eng">Sofia University</a>.</p>

<p>Mannequin.js is licensed under <strong>GPL-3.0</strong>.</p>

<p>Three.js is included in this repository to safeguard against incompatibilities with future versions. Three.js is not a part of mannequin.js.</p>



<p>The <strong>mannequin.js</strong> library is provided as a JavaScript file that has to
be include along with three.js.</p>

<h3 id="minimal-program">Minimal program</h3>

<p>Here is a minimal program that creates a male figure in the browser (<a href="https://boytchev.github.io/mannequin.js/examples/example-minimal.html">live example</a>):</p>

<div><div><pre><code><span>&lt;!DOCTYPE html&gt;</span>
<span>&lt;html&gt;</span>
  <span>&lt;head&gt;</span>
    <span>&lt;script</span> <span>src=</span><span>"three.min.js"</span><span>&gt;&lt;/script&gt;</span>
    <span>&lt;script</span> <span>src=</span><span>"mannequin.min.js"</span><span>&gt;&lt;/script&gt;</span>
  <span>&lt;/head&gt;</span>
  <span>&lt;body&gt;</span>
    <span>&lt;script&gt;</span>
      createScene();
      var man = new Male();
    <span>&lt;/script&gt;</span>
  <span>&lt;/body&gt;</span>
<span>&lt;/html&gt;</span>
</code></pre></div></div>

<p>The helper function <code>createScene()</code> provides a default set-up of the scene and its elements, like lighting, camera, ground, etc. Another helper function, <code>animate(t)</code> is responsible for defining figures’ postures at moment <em>t</em>. If the set-up is done with a custom function, then it should also manage the animation loop by itself.</p>

<h3 id="figure-types">Figure types</h3>

<p>Mannequin figures are created as instances of classes <code>Male()</code>, <code>Female()</code> or <code>Child()</code> (<a href="https://boytchev.github.io/mannequin.js/examples/example-figure-types.html">live example</a>):</p>

<p><a href="https://boytchev.github.io/mannequin.js/examples/example-figure-types.html"><img src="https://boytchev.github.io/mannequin.js/examples/snapshots/example-figure-types.jpg"></a></p>

<div><div><pre><code><span>var</span> <span>man</span> <span>=</span> <span>new</span> <span>Male</span><span>();</span>
    <span>man</span><span>.</span><span>position</span><span>.</span><span>set</span><span>(</span><span>20</span><span>,</span><span>3.5</span><span>,</span><span>0</span><span>);</span>
    <span>man</span><span>.</span><span>turn</span><span>(</span><span>-</span><span>120</span><span>);</span>
    <span>:</span>
<span>var</span> <span>woman</span> <span>=</span> <span>new</span> <span>Female</span><span>();</span>
    <span>woman</span><span>.</span><span>position</span><span>.</span><span>set</span><span>(</span><span>-</span><span>20</span><span>,</span><span>2</span><span>,</span><span>0</span><span>);</span>
    <span>woman</span><span>.</span><span>turn</span><span>(</span><span>-</span><span>60</span><span>);</span>
    <span>:</span>
<span>var</span> <span>kid</span> <span>=</span> <span>new</span> <span>Child</span><span>();</span>
    <span>kid</span><span>.</span><span>position</span><span>.</span><span>y</span> <span>=</span> <span>-</span><span>8</span><span>;</span>
    <span>kid</span><span>.</span><span>turn</span><span>(</span><span>-</span><span>90</span><span>);</span>
    <span>:</span>
</code></pre></div></div>

<p>These three classes have a common predecessor – the class <code>Mannequin(feminine,height)</code>, where <em>feminine</em> is boolean and defines whether the shape is feminine or masculine, and the second parameter is a number for relative height (adults have height 1).</p>



<p>All types of figures have the same structure of joints. For example, the right arm of a figure is accessed by <code>r_arm</code>. Left and right body parts are in respect to the figure, not to the viewer (<a href="https://boytchev.github.io/mannequin.js/examples/example-body-parts.html">live example</a>):</p>

<p><a href="https://boytchev.github.io/mannequin.js/examples/example-body-parts.html"><img src="https://boytchev.github.io/mannequin.js/examples/snapshots/example-body-parts.jpg"></a></p>

<p>Each body part has rotation methods that turn it around a pivot point.
The first parameter <em>angle</em> of the methods is the angle of rotation in degrees,
so 180 is half turn and 360 is full turn. Negative angles are allowed and
they represent turning in the opposite direction. Some methods have an optional
second parameter for <em>direction</em> of motion, which could be the constant <code>LEFT</code> or
<code>RIGHT</code>.</p>

<h3 id="central-body-parts">Central body parts</h3>

<p>The central body parts are the ones which have single instances - <em>head</em>, <em>neck</em>, <em>torso</em>, <em>pelvis</em> and the body as a whole. To move the whole <strong>body</strong> use methods <em>bend</em>, <em>turn</em> and <em>tilt</em> of the figure (<a href="https://boytchev.github.io/mannequin.js/examples/example-body.html">live example</a>):</p>

<ul>
  <li><code>figure.bend ( angle )</code></li>
  <li><code>figure.turn ( angle )</code></li>
  <li><code>figure.turn ( angle, direction )</code></li>
  <li><code>figure.tilt ( angle )</code></li>
  <li><code>figure.tilt ( angle, direction )</code></li>
</ul>

<p>The <strong>head</strong> supports similar methods: <em>nod</em>, <em>turn</em> and <em>tilt</em> (<a href="https://boytchev.github.io/mannequin.js/examples/example-head.html">live example</a>):</p>

<ul>
  <li><code>figure.head.nod ( angle )</code></li>
  <li><code>figure.head.turn ( angle )</code></li>
  <li><code>figure.head.turn ( angle, dir )</code></li>
  <li><code>figure.head.tilt ( angle )</code></li>
  <li><code>figure.head.tilt ( angle, dir )</code></li>
</ul>

<p>The <strong>torso</strong> has the same methods as the whole body: <em>bend</em>, <em>turn</em> and <em>tilt</em> (<a href="https://boytchev.github.io/mannequin.js/examples/example-torso.html">live example</a>):</p>

<ul>
  <li><code>figure.torso.bend ( angle )</code></li>
  <li><code>figure.torso.turn ( angle )</code></li>
  <li><code>figure.torso.turn ( angle, direction )</code></li>
  <li><code>figure.torso.tilt ( angle )</code></li>
  <li><code>figure.torso.tilt ( angle, direction )</code></li>
</ul>

<p>Although the <strong>neck</strong> is a separate part of the body, it is not controlled individually. Instead, a part of the head motion is distributed over the neck. Similarly, the <strong>pelvis</strong> is not controlled individually. Instead, the whole body is controlled by bending, turning and tilting.</p>

<h3 id="upper-limbs">Upper limbs</h3>

<p>The upper limbs are symmetrical body parts: <em>arm</em>, <em>elbow</em>, <em>wrist</em> and <em>fingers</em>.</p>

<p>Both <strong>arms</strong> support methods <em>raise</em>, <em>straddle</em> and <em>turn</em> (<a href="https://boytchev.github.io/mannequin.js/examples/example-arm1.html">live example</a>). The following list refers to the right arm, however, the same methods are available for the right hand:</p>

<ul>
  <li><code>figure.r_arm.raise ( angle )</code></li>
  <li><code>figure.r_arm.straddle ( angle )</code></li>
  <li><code>figure.r_arm.straddle ( angle, direction )</code></li>
  <li><code>figure.r_arm.turn ( angle )</code></li>
  <li><code>figure.r_arm.turn ( angle, direction )</code></li>
</ul>

<p>If the <em>direction</em> parameter is omitted, then the default motions of <em>straddle</em> and <em>turn</em> are symmetrical. For example, the left arm is straddled to the left, while the right arm is straddled to the right (<a href="https://boytchev.github.io/mannequin.js/examples/example-arm2.html">live example</a>).</p>

<p>The motion of the <strong>elbow</strong> is only <em>bend</em> (<a href="https://boytchev.github.io/mannequin.js/examples/example-elbow.html">live example</a>). Negative values for <em>angle</em> result in unnatural elbow position.</p>

<ul>
  <li><code>figure.r_elbow.bend ( angle )</code></li>
</ul>

<p>The <strong>wrists</strong> have the same methods as the torso: <em>bend</em>, <em>turn</em> and <em>tilt</em> (<a href="https://boytchev.github.io/mannequin.js/examples/example-wrist.html">live example</a>), but similar to the arms, the directions are symmetrical, if <em>direction</em> is not set:</p>

<ul>
  <li><code>figure.r_wrist.bend ( angle )</code></li>
  <li><code>figure.r_wrist.turn ( angle )</code></li>
  <li><code>figure.r_wrist.turn ( angle, direction )</code></li>
  <li><code>figure.r_wrist.tilt ( angle )</code></li>
  <li><code>figure.r_wrist.tilt ( angle, direction )</code></li>
</ul>

<p>The last body parts of the upper limbs are the <strong>fingers</strong>. They can only <em>bend</em> (<a href="https://boytchev.github.io/mannequin.js/examples/example-fingers.html">live example</a>), however, they are composed of two segments and the bending angle is distributed over both of them.</p>

<ul>
  <li><code>figure.r_fingers.bend ( angle )</code></li>
</ul>

<h3 id="lower-limbs">Lower limbs</h3>

<p>The lower limbs are symmetrical body parts: <em>leg</em>, <em>knee</em> and <em>ankle</em>.</p>

<p>Both <strong>legs</strong> support methods <em>raise</em>, <em>straddle</em> and <em>turn</em> (<a href="https://boytchev.github.io/mannequin.js/examples/example-leg.html">live example</a>). Straddling and turning are symmetrical if <em>direction</em> is not set.</p>

<ul>
  <li><code>figure.r_leg.raise ( angle )</code></li>
  <li><code>figure.r_leg.straddle ( angle )</code></li>
  <li><code>figure.r_leg.straddle ( angle, direction )</code></li>
  <li><code>figure.r_leg.turn ( angle )</code></li>
  <li><code>figure.r_leg.turn ( angle, direction )</code></li>
</ul>

<p>The motion of the <strong>knee</strong> is only <em>bend</em> (<a href="https://boytchev.github.io/mannequin.js/examples/example-knee.html">live example</a>). Negative values for <em>angle</em> result in unnatural knee position.</p>

<ul>
  <li><code>figure.r_knee.bend ( angle )</code></li>
</ul>

<p>The <strong>ankles</strong> have the same methods as the wrists: <em>bend</em>, <em>turn</em> and <em>tilt</em> (<a href="https://boytchev.github.io/mannequin.js/examples/example-ankle.html">live example</a>), but similar to the legs, the directions are symmetrical, if <em>direction</em> is not set:</p>

<ul>
  <li><code>figure.r_ankle.bend ( angle )</code></li>
  <li><code>figure.r_ankle.turn ( angle )</code></li>
  <li><code>figure.r_ankle.turn ( angle, direction )</code></li>
  <li><code>figure.r_ankle.tilt ( angle )</code></li>
  <li><code>figure.r_ankle.tilt ( angle, direction )</code></li>
</ul>



<p>The posture of a figure is defined by a setting the rotations of body parts. The order of rotations is fixed independent on the order of rotations in the user program (<a href="https://boytchev.github.io/mannequin.js/examples/example-order.html">live example</a>). For example:</p>

<div><div><pre><code><span>figure</span><span>.</span><span>head</span><span>.</span><span>nod</span><span>(</span><span>30</span><span>);</span>
<span>figure</span><span>.</span><span>head</span><span>.</span><span>turn</span><span>(</span><span>45</span><span>);</span>
<span>figure</span><span>.</span><span>head</span><span>.</span><span>tilt</span><span>(</span><span>20</span><span>,</span><span>RIGHT</span><span>);</span>
</code></pre></div></div>

<p>produces the same posture as:</p>

<div><div><pre><code><span>figure</span><span>.</span><span>head</span><span>.</span><span>tilt</span><span>(</span><span>20</span><span>,</span><span>RIGHT</span><span>);</span>
<span>figure</span><span>.</span><span>head</span><span>.</span><span>turn</span><span>(</span><span>45</span><span>);</span>
<span>figure</span><span>.</span><span>head</span><span>.</span><span>nod</span><span>(</span><span>30</span><span>);</span>
</code></pre></div></div>

<p>Sometimes this might lead to unexpected results, especially if the user assumes an order of rotations that is different from what mannequin.js uses. This might happen when a body part is rotated around 3 or 2 axes.</p>

<h3 id="static-posture">Static posture</h3>

<p>The static posture defines the position of body part that do not change. By default, when a figure is created, its body parts are set to the default posture. This version of mannequin.js does not provide posture editor, so all rotations has to be defined programmatically.</p>

<p><a href="https://boytchev.github.io/mannequin.js/examples/example-posture.html"><img src="https://boytchev.github.io/mannequin.js/examples/snapshots/example-posture.jpg"></a></p>

<p>Sometimes it is better to define the figure step by step. Tai Chi Chuan posture (<a href="https://boytchev.github.io/mannequin.js/examples/example-posture.html">live example</a>) could start by defining the whole body position:</p>

<div><div><pre><code><span>// overall body position</span>
<span>man</span><span>.</span><span>position</span><span>.</span><span>y</span> <span>=</span> <span>-</span><span>7.7</span><span>;</span>
<span>man</span><span>.</span><span>tilt</span><span>(</span><span>5</span><span>,</span><span>LEFT</span><span>);</span>
<span>man</span><span>.</span><span>bend</span><span>(</span><span>15</span><span>);</span>

<span>// torso and head</span>
<span>man</span><span>.</span><span>torso</span><span>.</span><span>turn</span><span>(</span><span>30</span><span>,</span><span>RIGHT</span><span>);</span>
<span>man</span><span>.</span><span>torso</span><span>.</span><span>tilt</span><span>(</span><span>15</span><span>,</span><span>RIGHT</span><span>);</span>
<span>man</span><span>.</span><span>torso</span><span>.</span><span>bend</span><span>(</span><span>-</span><span>15</span><span>);</span>
<span>man</span><span>.</span><span>head</span><span>.</span><span>turn</span><span>(</span><span>70</span><span>,</span><span>RIGHT</span><span>);</span>
</code></pre></div></div>

<p>Then the orientation of the legs can be set:</p>

<div><div><pre><code><span>// right leg</span>
<span>man</span><span>.</span><span>r_leg</span><span>.</span><span>raise</span><span>(</span><span>85</span><span>);</span>
<span>man</span><span>.</span><span>r_leg</span><span>.</span><span>turn</span><span>(</span><span>20</span><span>);</span>
<span>man</span><span>.</span><span>r_leg</span><span>.</span><span>straddle</span><span>(</span><span>40</span><span>,</span><span>LEFT</span><span>);</span>
<span>man</span><span>.</span><span>r_knee</span><span>.</span><span>bend</span><span>(</span><span>90</span><span>);</span>
<span>man</span><span>.</span><span>r_ankle</span><span>.</span><span>bend</span><span>(</span><span>35</span><span>);</span>
<span>man</span><span>.</span><span>r_ankle</span><span>.</span><span>turn</span><span>(</span><span>20</span><span>,</span><span>RIGHT</span><span>);</span>
<span>man</span><span>.</span><span>r_ankle</span><span>.</span><span>tilt</span><span>(</span><span>-</span><span>15</span><span>);</span>

<span>// left leg</span>
<span>man</span><span>.</span><span>l_leg</span><span>.</span><span>raise</span><span>(</span><span>-</span><span>30</span><span>);</span>
<span>man</span><span>.</span><span>l_knee</span><span>.</span><span>bend</span><span>(</span><span>25</span><span>);</span>
<span>man</span><span>.</span><span>l_ankle</span><span>.</span><span>bend</span><span>(</span><span>42</span><span>);</span>
</code></pre></div></div>

<p>Finally, the arms are fixed:</p>

<div><div><pre><code><span>// left arm</span>
<span>man</span><span>.</span><span>l_arm</span><span>.</span><span>raise</span><span>(</span><span>10</span><span>);</span>
<span>man</span><span>.</span><span>l_arm</span><span>.</span><span>turn</span><span>(</span><span>-</span><span>40</span><span>);</span>
<span>man</span><span>.</span><span>l_arm</span><span>.</span><span>tilt</span><span>(</span><span>-</span><span>60</span><span>);</span>
<span>man</span><span>.</span><span>l_elbow</span><span>.</span><span>bend</span><span>(</span><span>155</span><span>);</span>
<span>man</span><span>.</span><span>l_wrist</span><span>.</span><span>turn</span><span>(</span><span>50</span><span>);</span>
<span>man</span><span>.</span><span>l_fingers</span><span>.</span><span>bend</span><span>(</span><span>-</span><span>10</span><span>);</span>

<span>// right arm</span>
<span>man</span><span>.</span><span>r_arm</span><span>.</span><span>raise</span><span>(</span><span>-</span><span>10</span><span>);</span>
<span>man</span><span>.</span><span>r_arm</span><span>.</span><span>tilt</span><span>(</span><span>70</span><span>);</span>
<span>man</span><span>.</span><span>r_arm</span><span>.</span><span>turn</span><span>(</span><span>20</span><span>);</span>
<span>man</span><span>.</span><span>r_elbow</span><span>.</span><span>bend</span><span>(</span><span>40</span><span>);</span>
<span>man</span><span>.</span><span>r_wrist</span><span>.</span><span>turn</span><span>(</span><span>30</span><span>);</span>
<span>man</span><span>.</span><span>r_fingers</span><span>.</span><span>bend</span><span>(</span><span>90</span><span>);</span>
</code></pre></div></div>

<h3 id="dynamic-posture">Dynamic posture</h3>

<p>The dynamic posture – i.e. a posture that changes over time – is set with the same methods that are used for static posture. Mannequin.js defines an empty function <code>animate(t)</code>, which is called in the animation loop once for each frame. All changes of a posture should be defined inside this function (<a href="https://boytchev.github.io/mannequin.js/examples/example-dynamic.html">live example</a>). The parameter <em>t</em> is the time, measured in tenths of seconds. This function is set up in <code>createScene()</code>. If <em>createScene</em> and <em>animate</em> are not used, then the animation loop should be managed manually.</p>

<p><a href="https://boytchev.github.io/mannequin.js/examples/example-dynamic.html"><img src="https://boytchev.github.io/mannequin.js/examples/snapshots/example-dynamic.jpg"></a></p>

<div><div><pre><code><span>function</span> <span>animate</span><span>(</span><span>t</span><span>)</span>
<span>{</span>
    <span>var</span> <span>time1</span> <span>=</span> <span>(</span><span>sin</span><span>(</span><span>2</span><span>*</span><span>t</span><span>)</span><span>+</span><span>cos</span><span>(</span><span>3</span><span>*</span><span>t</span><span>)</span><span>+</span><span>cos</span><span>(</span><span>5</span><span>*</span><span>t</span><span>))</span><span>/</span><span>3</span><span>,</span>
        <span>time2</span> <span>=</span> <span>(</span><span>sin</span><span>(</span><span>2</span><span>*</span><span>t</span><span>-</span><span>60</span><span>)</span><span>+</span><span>cos</span><span>(</span><span>3</span><span>*</span><span>t</span><span>-</span><span>90</span><span>)</span><span>+</span><span>cos</span><span>(</span><span>5</span><span>*</span><span>t</span><span>-</span><span>120</span><span>))</span><span>/</span><span>3</span><span>;</span>

    <span>ball</span><span>.</span><span>position</span><span>.</span><span>x</span> <span>=</span> <span>-</span><span>3</span><span>*</span><span>time1</span><span>;</span>

    <span>child</span><span>.</span><span>position</span><span>.</span><span>x</span> <span>=</span> <span>-</span><span>3</span><span>*</span><span>time1</span><span>;</span>
    <span>child</span><span>.</span><span>position</span><span>.</span><span>y</span> <span>=</span> <span>4</span><span>+</span><span>cos</span><span>(</span><span>90</span><span>*</span><span>time1</span><span>);</span>

    <span>child</span><span>.</span><span>turn</span><span>(</span><span>-</span><span>90</span><span>-</span><span>20</span><span>*</span><span>time1</span><span>+</span><span>20</span><span>*</span><span>time2</span><span>);</span>
    <span>child</span><span>.</span><span>tilt</span><span>(</span><span>10</span><span>*</span><span>time1</span><span>);</span>
    <span>:</span>
	
    <span>scene</span><span>.</span><span>rotation</span><span>.</span><span>y</span> <span>=</span> <span>rad</span><span>(</span><span>30</span><span>*</span><span>time1</span><span>);</span>
<span>}</span>
</code></pre></div></div>

<p>To make the animation loop faster, all constant rotations should be defined outside <em>animate</em>. Also, if a rotation changing in the loop, there is no need to set it up outside the loop.</p>



<p>Apart for moving body parts, the current version of mannequin.js provides basic functionality for additional modification or accessing the figure.</p>

<h3 id="custom-colors">Custom colors</h3>

<p>By default, all figures use a predefined set of global colors for body parts. Global colors are stored in <code>Mannequin.colors</code> array as six <a href="https://threejs.org/docs/#api/en/math/Color">Three.js colors</a> or lowercase <a href="https://www.w3schools.com/colors/colors_names.asp">HTML/CSS color names</a> in specific order – head, shoes, pelvis, joints, limbs and torso:</p>

<div><div><pre><code><span>Mannequin</span><span>.</span><span>colors</span> <span>=</span> <span>[</span>
    <span>'</span><span>antiquewhite</span><span>'</span><span>,</span>	<span>// head</span>
    <span>'</span><span>gray</span><span>'</span><span>,</span>		<span>// shoes</span>
    <span>'</span><span>antiquewhite</span><span>'</span><span>,</span>	<span>// pelvis</span>
    <span>'</span><span>burlywood</span><span>'</span><span>,</span>	<span>// joints</span>
    <span>'</span><span>antiquewhite</span><span>'</span><span>,</span>	<span>// limbs</span>
    <span>'</span><span>bisque</span><span>'</span>		<span>// torso</span>
<span>];</span>
</code></pre></div></div>

<p>The global color of …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://boytchev.github.io/mannequin.js/">https://boytchev.github.io/mannequin.js/</a></em></p>]]>
            </description>
            <link>https://boytchev.github.io/mannequin.js/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25302602</guid>
            <pubDate>Fri, 04 Dec 2020 14:35:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Has AI 'solved' protein folding?]]>
            </title>
            <description>
<![CDATA[
Score 29 | Comments 21 (<a href="https://news.ycombinator.com/item?id=25302487">thread link</a>) | @stuartbman
<br/>
December 4, 2020 | https://explainthispaper.com/ai-solving-protein-folding/ | <a href="https://web.archive.org/web/*/https://explainthispaper.com/ai-solving-protein-folding/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<div>
<h2><b>Has AI 'solved' protein folding? 📎</b></h2>
<div>
<p><i>article</i></p>
<div>
<p>Improved protein structure prediction using potentials from deep learning</p>
<p>Andrew W. Senior, Richard Evans, John Jumper, James Kirkpatrick, Laurent Sifre, Tim Green, Chongli Qin, Augustin Žídek, Alexander W. R. Nelson, Alex Bridgland, Hugo Penedones, Stig Petersen, Karen Simonyan, Steve Crossan...</p>
<p><a href="https://www.nature.com/articles/s41586-019-1923-7.epdf?author_access_token=Z_KaZKDqtKzbE7Wd5HtwI9RgN0jAjWel9jnR3ZoTv0MCcgAwHMgRx9mvLjNQdB2TlQQaa7l420UCtGo8vYQ39gg8lFWR9mAZtvsN_1PrccXfIbc6e-tGSgazNL_Xd">Nature</a>
</p></div>
</div>
<div>
<h3>TL;DR</h3>
<p><span><p>Predicting protein folding is a massive problem with huge potential to help us understand disease. It’s been stuck in a rut for the past 50 years, but one team of researchers has come out of nowhere and claims to have solved the problem. But have they?</p></span>
</p></div>
<h3 grey-text="" text-darken-4="">Clinical Need</h3>
<section>
<div>
<p><span>
<div><p>Proteins are made up of amino acids. Getting the amino acid sequence for a protein is pretty easy these days. But going from this sequence to the 3-dimensional shape of the protein is really hard.</p><p>For decades, researchers have worked out protein structures using slow and expensive techniques such as <sample>x-ray crystallography</sample>. So far we’ve only solved about 170,000 proteins using these approaches. Yet more than 200 million proteins have been discovered across all forms of life 😳</p><p>Being able to predict a protein’s shape based on its amino acid sequence would be a game changer. We could design drugs faster by targeting proteins more effectively. But computer-based predictions haven’t been accurate enough to be useful. Until now…</p></div>
</span>
</p>
<div>

<p>X-ray crystallography uses the diffraction of x-rays to work out the shape of a protein. The pictures are murky and there's a lot of guesswork involved!</p>
<p><img alt="stu.jpg" height="200" src="https://explainthispaper.s3.amazonaws.com/images/stu.2e16d0ba.fill-200x200.jpg" width="200">
</p>

</div>
</div>
</section>
<h3 grey-text="" text-darken-4="">What did they do?</h3>
<div><p>The team created a deep learning pipeline for predicting protein shape from its amino acid sequence.</p><p>They entered this neural network into the “Critical Assessment of Protein Structure Prediction” (CASP) competition. Teams are given amino acids sequences for ~100 proteins with unknown structures and asked to predict protein shape. The predictions are given a score from 0-100. Slow techniques (like x-ray crystallography) score above 90.</p></div>
<h3 grey-text="" text-darken-4="">How did the model work?</h3>
<section>
<div>
<p><span>
<div><p>The first version of their model (AlphaFold) performs the following stages:</p><p>First, it looks for similar sequence fragments to the protein of interest from a large protein sequence database. This helps identify features of the protein at interest. An <sample>autoencoder</sample> predicts which protein shape the sequence fragment most likely represents.</p><p>These features are then fed into a convolutional neural network which predicts the distances between different parts of the protein sequence. Predicting distances enables it to also predict contact points.</p><p>Then, using the predicted distances and contact points, the model considers all the possible shapes of the protein and identifies the most likely one.</p></div>
</span>
</p>
<div>

<p>This is a type of neural network that compresses data into a bottleneck of it's most important features, and measures it's performance by reconstructing that bottleneck back up to size. It's an in depth topic worth <a href="https://www.jeremyjordan.me/autoencoders/#:~:text=Autoencoders%20are%20an%20unsupervised%20learning,representation%20of%20the%20original%20input.">reading more on</a></p>
<p><img alt="stu.jpg" height="200" src="https://explainthispaper.s3.amazonaws.com/images/stu.2e16d0ba.fill-200x200.jpg" width="200">
</p>
<p><span><b>
Stu Maitland</b>
</span><br>
<span>NIHR Doctoral Fellow</span>
</p>
</div>
</div>
</section>
<section>
<div>
<p><span>
<p>With the updated model (AlphaFold-2) they made some changes. They haven't released a paper yet (only an abstract), but from what we can tell they used an <sample>attention-based deep learning</sample> to fit over the whole shape of the protein, not just the fragments.</p>
</span>
</p>
<div>

<p>Instead of working over the whole sequence at once, this method allows the learning to 'attend' to subsections individually. This is a bit like trying to translate a long german word- instead of trying to decode the whole word, you break it into sub-words and see how they match, then put it all together.</p>
<p><img alt="chris.jpg" height="200" src="https://explainthispaper.s3.amazonaws.com/images/chris.2e16d0ba.fill-200x200.jpg" width="200">
</p>
<p><span><b>
Chris Lovejoy</b>
</span><br>
<span>Doctor, Data Scientist</span>
</p>
</div>
</div>
</section>
<h3 grey-text="" text-darken-4="">How did the model perform?</h3>
<div><p><img alt="Animated Protein" height="450" src="https://explainthispaper.s3.amazonaws.com/images/protein.width-800.png" width="800"></p><p>From the start of the competition in 1994 up to 2016, CASP scores had been around 40. The first time DeepMind entered, they scored up to 60. This year- AlphaFold scored an average of 92.4, smashing the threshold of 90/100!</p><p>In fact, the organisers of the competition thought that DeepMind had been cheating, so they set them a special challenge- a membrane protein from an ancient species of <i>archaea</i>. For 10 years with no success, research teams tried every trick in the book to get an x-ray crystal structure of the protein.</p><p>AlphaFold had no problem, returning an image of a three part protein with two helical arms. In hindsight, this structure fit the x-ray crystallography data perfectly, effectively going beyond the limitations of current human research.</p></div>
<h3 grey-text="" text-darken-4="">So what?</h3>
<section>
<div>
<p><span>
<div><p>This is a thorny problem that researchers and pharmaceutical companies have been working on for 50+ years. This model could predict the shape of proteins without unreliable experimental measurements. This would mean faster development of a wide range of drugs, from cancer drugs that better target proteins for cell replication, to antibiotics that target surface receptors of microbes.</p><p>What’s more, this model was cheap to train- just weeks on quite a <sample>small cluster of servers</sample></p><p>It's worth saying that this isn't the whole picture of protein folding- this still doesn't inform how proteins change shape in the presence of other molecules (like oxygen near haemoglobin). These are also the crystallised protein forms rather than the true 'in vivo' structures, so there may be some errors in translation, but that remains to be seen.</p></div>
</span>
</p>
<div>

<p>Using Google's <a href="https://cloud.google.com/tpu/pricing#pricing_calculator">pricing calculator</a> and the details from the blog post, this could be trained for around $21,000. In the grand scheme of biology and pharmaceuticals, this is pennies!<br></p>
<p><img alt="stu.jpg" height="200" src="https://explainthispaper.s3.amazonaws.com/images/stu.2e16d0ba.fill-200x200.jpg" width="200">
</p>
<p><span><b>
Stu Maitland</b>
</span><br>
<span>NIHR Doctoral Fellow</span>
</p>
</div>
</div>
</section>

</div>
</div><div>
<h2>The latest papers in your inbox</h2>
<p>Keep up to date with the latest research, summarised concisely and clearly.</p>



</div></div>]]>
            </description>
            <link>https://explainthispaper.com/ai-solving-protein-folding/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25302487</guid>
            <pubDate>Fri, 04 Dec 2020 14:25:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Guide to Effective Reading]]>
            </title>
            <description>
<![CDATA[
Score 196 | Comments 20 (<a href="https://news.ycombinator.com/item?id=25302132">thread link</a>) | @accountLost
<br/>
December 4, 2020 | https://maartenvandoorn.nl/reading-guide/ | <a href="https://web.archive.org/web/*/https://maartenvandoorn.nl/reading-guide/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-1454">

	<!-- .entry-header -->



	<div>

		
<figure><img src="https://cdn-images-1.medium.com/max/2600/1*0tmBPKA1YGo82VNeMS3KhA.jpeg" alt=""><figcaption> <a rel="noreferrer noopener" href="https://unsplash.com/photos/9pw4TKvT3po?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" target="_blank">Let’s make that magic&nbsp;happen</a> </figcaption></figure>



<p>Learning is a heavily misunderstood&nbsp;concept.</p>



<p>As a&nbsp;paradigm&nbsp;example of&nbsp;deep work,&nbsp;we understand that, when reading, directing your full attention to the material at hand is essential.&nbsp;Graspingcomplex information is hard.</p>



<p>But this is only half the battle.</p>



<p>After some string of words hits your retina and has made its way to your brain, you’re&nbsp;not done.</p>



<p>In a&nbsp;cruel&nbsp;irony,&nbsp;these hours of&nbsp;deep work&nbsp;often cause&nbsp;flow&nbsp;states&nbsp;and the feeling that ‘you’ve had a good day’ and learned a&nbsp;shitload&nbsp;of new stuff.</p>



<p>But for many reading&nbsp;episodes&nbsp;this feeling is&nbsp;deceptive.&nbsp;There is anineliminable&nbsp;aspect to learning that takes place&nbsp;<em>after&nbsp;</em>the&nbsp;glorious&nbsp;flow state.</p>



<p>The&nbsp;other half of the battle is&nbsp;to&nbsp;transfer the newly acquired intelligence from your working memory to your&nbsp;long-term&nbsp;understanding and&nbsp;integrate&nbsp;it into your standing stack of mental models.</p>



<p>If you don’t&nbsp;facilitate&nbsp;this, your learning&nbsp;gains&nbsp;are only a&nbsp;fraction&nbsp;of what they could have been.</p>



<p>In this article,&nbsp;I’m going to breakdown how to win the battle and the war — how to&nbsp;avoid&nbsp;these traps and organize your reading habit for a maximalReturn On Investment (ROI)&nbsp;on reading hours.</p>



<p>This is what we’ll cover:</p>



<pre><strong>Table of Contents</strong></pre>



<pre>1. <a href="https://medium.com/@maartenvandoorn/the-complete-guide-to-effective-reading-fc1835937757/#1b1d">Meta-Learning</a><br>2. <a href="https://medium.com/@maartenvandoorn/the-complete-guide-to-effective-reading-fc1835937757/#1d70">Learning is a two-step process</a><br>3. <a href="https://medium.com/@maartenvandoorn/the-complete-guide-to-effective-reading-fc1835937757/#9181">Remembering the right things</a><br>4. <a href="https://medium.com/@maartenvandoorn/the-complete-guide-to-effective-reading-fc1835937757/#7b89">Enter: Mental models</a><br>5. <a href="https://medium.com/@maartenvandoorn/the-complete-guide-to-effective-reading-fc1835937757/#a837">Learning = upgrading your mental models</a></pre>



<pre>6. <a href="https://medium.com/@maartenvandoorn/the-complete-guide-to-effective-reading-fc1835937757/#f0d0">How to ‘get it in there’ (macro-level)</a><br>7. <a href="https://medium.com/@maartenvandoorn/the-complete-guide-to-effective-reading-fc1835937757/#8823">How to ‘get it in there’ (micro level)</a><br>7.1 <a href="https://medium.com/@maartenvandoorn/the-complete-guide-to-effective-reading-fc1835937757/#19fe">Know your why</a></pre>



<pre>8. <a href="https://medium.com/@maartenvandoorn/the-complete-guide-to-effective-reading-fc1835937757/#d988">Active reading</a><br>8.1 <a href="https://medium.com/@maartenvandoorn/the-complete-guide-to-effective-reading-fc1835937757/#414f">How to make a mind map</a><br>8.2 <a href="https://medium.com/@maartenvandoorn/the-complete-guide-to-effective-reading-fc1835937757/#ad79">Which Returns are you aiming for?</a><br>8.3 <a href="https://medium.com/@maartenvandoorn/the-complete-guide-to-effective-reading-fc1835937757/#d61e">Written active recall with bullet points</a><br>8.4 <a href="https://medium.com/@maartenvandoorn/the-complete-guide-to-effective-reading-fc1835937757/#a187">How to actively read a book</a><br>8.5 <a href="https://medium.com/@maartenvandoorn/the-complete-guide-to-effective-reading-fc1835937757/#8ead">Remember your why (yes, again)</a></pre>



<pre>9. <a href="https://medium.com/@maartenvandoorn/the-complete-guide-to-effective-reading-fc1835937757/#4e04">Advanced active reading</a><br>9.1 <a href="https://medium.com/@maartenvandoorn/the-complete-guide-to-effective-reading-fc1835937757/#9782">The QEC method</a><br>9.2 <a href="https://medium.com/@maartenvandoorn/the-complete-guide-to-effective-reading-fc1835937757/#8dac">Keep a running tally</a><br>9.3 <a href="https://medium.com/@maartenvandoorn/the-complete-guide-to-effective-reading-fc1835937757/#dc6b">Put your unconsciousness to work</a><br>9.4 <a href="https://medium.com/@maartenvandoorn/the-complete-guide-to-effective-reading-fc1835937757/#7a10">Pulling it all together</a><br>9.5 <a href="https://medium.com/@maartenvandoorn/the-complete-guide-to-effective-reading-fc1835937757/#6b84">How to actively read a book (advanced)</a></pre>



<pre>10. <a href="https://medium.com/@maartenvandoorn/the-complete-guide-to-effective-reading-fc1835937757/#926b">Organizing repetition and reflection</a><br>10.1 <a href="https://medium.com/@maartenvandoorn/the-complete-guide-to-effective-reading-fc1835937757/#f934">Setting up and using your review cycle</a><br>10.2 <a href="https://medium.com/@maartenvandoorn/the-complete-guide-to-effective-reading-fc1835937757/#5182">Improved learning: engage in active recall</a></pre>



<pre><a href="https://medium.com/@maartenvandoorn/the-complete-guide-to-effective-reading-fc1835937757/#fc24">Conclusion: The cycle of learning</a></pre>



<p>Warning: this is a very&nbsp;nerdy&nbsp;post.</p>



<h3 id="1b1d">Meta-Learning</h3>



<p>Meta-learning&nbsp;is knowing how to learn.&nbsp;It is one of the most important skills to learn, yet few people know how to do to it.</p>



<p>Reading and writing is what I do for a living, and, interestingly, a lot of non-imaginary&nbsp;friends have been asking me how I learn.&nbsp;This is special, becausemost of the times when people don’t know how to do something, they go&nbsp;togreat&nbsp;lengths&nbsp;<em>not&nbsp;</em>to notice their&nbsp;deficiency.</p>



<p>Could it be that many students turned ‘knowledge workers’ have the&nbsp;naggingfeeling that something is missing in their skillset because they were never taught&nbsp;meta-learning?</p>



<p>This is not their fault, but a&nbsp;<a href="https://medium.com/the-understanding-project/schools-dont-support-personal-development-they-distort-it-7e1c227eb01d" target="_blank" rel="noreferrer noopener">lack in our education system</a>.</p>



<p>As Adam Robinson observed on the&nbsp;<a href="https://fs.blog/adam-robinson-pt2/" rel="noreferrer noopener" target="_blank"><em>Farnam Street&nbsp;</em>podcast</a>:</p>



<blockquote><p>“<strong>No one ever shows us how to learn, ever</strong>.&nbsp;Nowhere in school.&nbsp;For example, imagine, Shane, [Shane is the host of the FS podcast] in French class, French 101, your first French class, your teacher said,&nbsp;“Everyone, you’re going to have to learn a lot of vocabulary in this class so before I teach you any words I’m going to teach you a way to remember vocabulary.”&nbsp;They never do that.&nbsp;They just go, “We’re going to have a quiz on these 30 words on Monday.&nbsp;Good luck.”&nbsp;But they don’t teach us how to learn actually, or remember things.”</p></blockquote>



<p>This is&nbsp;weird, because,&nbsp;in today’s high-information world,&nbsp;people need the ability to&nbsp;<em>make sense of</em>&nbsp;complexity and to&nbsp;<em>combine</em>&nbsp;many bits of data into a broad picture of the world.</p>



<p>Merely&nbsp;<em>acquiring</em>information is&nbsp;<em>not&nbsp;</em>(yet) learning.</p>



<p>Learning itself is a skill, and knowing how to do it well is an incredibly valuable advantage.</p>



<p>We take this is for granted, but how to do this is&nbsp;far from&nbsp;obvious&nbsp;and doesn’t get taught in the curriculum.</p>



<hr>



<h3 id="1d70">Learning is a&nbsp;two-step&nbsp;process</h3>



<p>So, how do we learn?</p>



<p>Before we attempt to answer the question,&nbsp;let’s get clear&nbsp;on what a&nbsp;satisfactoryanswer needs to get us.&nbsp;What does it&nbsp;<em>mean&nbsp;</em>to learn?&nbsp;When have you learned something?</p>



<p>In the introduction, I stated that&nbsp;just studying the information isn’t enough(no matter how intense your focus was).&nbsp;Learning has&nbsp;two phases — not one.</p>



<ol><li>Read/listen&nbsp;the damn thing</li><li>Process and&nbsp;recall&nbsp;what you’ve just ‘learned’</li></ol>



<p>A lot has been said about the first phase — about deep work, concentration, blocking out&nbsp;distractions, and so&nbsp;forth.&nbsp;This makes sense:&nbsp;if you’re checking Facebook all the time,&nbsp;your mind is not ‘there’, and you might as well not have spent your afternoon ’reading’ this book.</p>



<p>This is all great and I‘m a big fan, but in the&nbsp;meantime, we’re ignoring step two.</p>



<p>If you don’t spend time revisiting and grappling with the book either,&nbsp;<em>the same applies</em> — you might as well not have read it.&nbsp;In the long run, there is no difference between skipping the first or the second stage (except whether you passed that French test in high school back in 2019…).</p>



<p>After you’ve killed Cersei, you’ve still got the&nbsp;White Walkers to deal with.&nbsp;If you don’t, you lose either way.</p>



<p>That is why students who&nbsp;binge-study&nbsp;the night before the exam quite literally forget everything two days later:&nbsp;while all these&nbsp;lame&nbsp;French words were still in their short-term memory,&nbsp;allowing them to pass the test,&nbsp;the information never&nbsp;transitioned&nbsp;to their long-term understanding — and so, sooner or later, it&nbsp;evaporated.</p>



<p>To learn,&nbsp;you need to transfer the newly acquired intelligence from&nbsp;your working memory to your long-term understanding.</p>



<p><strong>The jump from short-term memory to long-term understanding doesn’t happen automatically.</strong><strong>The default mode, after you close your books for the day, is not&nbsp;</strong><strong>retainment</strong><strong>&nbsp;but&nbsp;<em>forgetting</em></strong><strong>.</strong></p>



<p>This learning guide&nbsp;is not about&nbsp;<a href="https://medium.com/the-understanding-project/why-you-dont-need-to-read-those-productivity-guides-347fe02cc196" target="_blank" rel="noreferrer noopener">how to do generic deep work</a>.&nbsp;It explains how to maximize the ROI on hours spent reading,&nbsp;<em>assuming</em>&nbsp;you did them ‘deep work style’.</p>



<h3 id="9181">Remembering the right&nbsp;things</h3>



<p>First, I need to discuss a common&nbsp;objection&nbsp;that denies phase two of learning matters.&nbsp;If you have no&nbsp;quibble&nbsp;with memorization, and doing the required effort, you can skip this section.</p>



<p>“But Mr. Maarten,” the protest goes, “you mention ‘processing’ and ‘remembering’ into my ‘long-term understanding’, but isn’t memorizing pointless?&nbsp;My Google Assistant can look everything up and also is smarter than me, says my Google Assistant.”</p>



<p>Indeed,&nbsp;Albert Einstein is&nbsp;<a href="https://medium.com/the-polymath-project/studying-history-is-more-important-than-ever-in-todays-economy-c99fde4be7d0" target="_blank" rel="noreferrer noopener">supposed</a>&nbsp;to have said:&nbsp;“Never&nbsp;memorize&nbsp;what you can look up in a book”.&nbsp;In Einstein’s days, books were&nbsp;unequaled&nbsp;as a source of information.&nbsp;We, on the other hand, live in an age where nearly everything can be accessed through the magic vehicle of internet.&nbsp;Following Einstein’s logic, then,&nbsp;<em>nothing&nbsp;</em>is worth memorizing anymore, because&nbsp;<em>everything</em>&nbsp;can be looked up.</p>



<p>But, of course, that is probably not what old Albert was getting at.</p>



<p>Most likely,&nbsp;the advice he wanted to&nbsp;dispense&nbsp;was that&nbsp;you should not waste your time by committing unimportant details to memory.&nbsp;Rather,&nbsp;your&nbsp;focus should be on understanding the bigger picture — on&nbsp;how things relate to each other.</p>



<p>This reminds me of Elon Musk’s&nbsp;approach to learning.&nbsp;He&nbsp;<a href="https://www.reddit.com/r/IAmA/comments/2rgsan/i_am_elon_musk_ceocto_of_a_rocket_company_ama/" rel="noreferrer noopener" target="_blank">recommends</a>viewing knowledge as a tree:</p>



<blockquote><p>Make sure you understand the fundamental principles, the trunk and big branches, before you get into the leaves/details or there is nothing for them to hang on to.</p></blockquote>



<p>To ‘learn’, we need to do more than merely feeding ourselves new information.&nbsp;Expanding our intelligence requires&nbsp;<em>connecting</em>&nbsp;new materials to what we already knew&nbsp;(the second phase of learning).&nbsp;That, in turn, requires something to connect&nbsp;<em>to.</em></p>



<p>There’s no adding branches without a solid trunk.</p>



<p>The very possibility of genuine insight requires a memorized base.&nbsp;Without it, data you consume will not be added to your tree of knowledge.&nbsp;Instead, they will float in the air for a couple of weeks or so, before being taken away by the wind.</p>



<p>Knowledge, gone.&nbsp;Time, wasted.</p>



<p>What I’m saying is&nbsp;<em>not&nbsp;</em>that we should&nbsp;devise&nbsp;techniques which enable us torecite&nbsp;everything we’ve learned.&nbsp;That’s why we’re not talking about, for example,&nbsp;retaining&nbsp;the date of the French revolution.</p>



<p>However,&nbsp;you&nbsp;<em>should&nbsp;</em>learn by heart the lessons it tells you about how the world works&nbsp;and update your representation of reality&nbsp;accordingly.</p>



<p>In&nbsp;other words,&nbsp;you should use it to&nbsp;inform&nbsp;your&nbsp;unconscious — the&nbsp;sum&nbsp;of your mental models.</p>



<h3 id="7b89">Enter: Mental&nbsp;models</h3>



<p>I’ve long been skeptical about mental models since (1) they’re all the rage now and (2) no one seems to be able to explain in concrete terms what they are. A dangerous combination.</p>



<p>It turned out my doubt was due to ignorance on my part.</p>



<p>A mental model,&nbsp;as&nbsp;<a href="https://en.wikipedia.org/wiki/Mental_model" rel="noreferrer noopener" target="_blank">Wikipedia</a>&nbsp;tells us, is</p>



<blockquote><p>An explanation of someone’s thought process about how something works in the real world.&nbsp;<strong>It is a representation of the surrounding world</strong>, the relationships between its various parts and a person’s intuitive perception about his or her own acts and their consequences.</p></blockquote>



<p>Every problem and situation is just another ‘one of those’ — another one of a certain type.&nbsp;Figuring out what type it is and reflecting on principles for handling that type of issue will help you do a better job.</p>



<p>On the conscious level, mental models allow us to ‘fit’ different possible interpretations onto reality to see if it is ‘one of those’.</p>



<p>For example,&nbsp;according to&nbsp;<a href="https://en.wikipedia.org/wiki/Hanlon%27s_razor" rel="noreferrer noopener" target="_blank">Hanlon’s Razor</a>&nbsp;one should&nbsp;“never attribute tomalice&nbsp;that which is adequately explained by carelessness”.&nbsp;When your coworker hands you crappy slides for the presentation you have to give in five minutes — what’s going on here?</p>



<p>Which ‘one of those’ do we have here?</p>



<p>You can see&nbsp;how different mental models in our heads will cause us to reach different conclusions about the correct interpretation of the situation.</p>



<p>A mental model is a mental, simplified&nbsp;depiction&nbsp;of how something works.They are how we order complexity, why we consider some things more relevant than others, and how we reason.&nbsp;They help us filter, organize and understand.</p>



<p>For instance, according to&nbsp;<a href="https://en.wikipedia.org/wiki/Pareto_distribution" rel="noreferrer noopener" target="_blank">Pareto distribution</a>,&nbsp;“for many events,&nbsp;roughly 80% of the …</p></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://maartenvandoorn.nl/reading-guide/">https://maartenvandoorn.nl/reading-guide/</a></em></p>]]>
            </description>
            <link>https://maartenvandoorn.nl/reading-guide/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25302132</guid>
            <pubDate>Fri, 04 Dec 2020 13:45:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Using Google Analytics without GDPR consent]]>
            </title>
            <description>
<![CDATA[
Score 53 | Comments 108 (<a href="https://news.ycombinator.com/item?id=25301500">thread link</a>) | @evrimfeyyaz
<br/>
December 4, 2020 | https://evrim.io/using-google-analytics-without-gdpr-consent/ | <a href="https://web.archive.org/web/*/https://evrim.io/using-google-analytics-without-gdpr-consent/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://evrim.io/using-google-analytics-without-gdpr-consent/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25301500</guid>
            <pubDate>Fri, 04 Dec 2020 12:23:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Wikipedia's in Trouble (2019)]]>
            </title>
            <description>
<![CDATA[
Score 102 | Comments 86 (<a href="https://news.ycombinator.com/item?id=25300942">thread link</a>) | @sanqui
<br/>
December 4, 2020 | http://blog.spencermounta.in/2019/wikipedias-in-trouble/index.html | <a href="https://web.archive.org/web/*/http://blog.spencermounta.in/2019/wikipedias-in-trouble/index.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>
I got involved in wikipedia <a href="https://en.wikipedia.org/w/index.php?title=User%3ASpencerk&amp;action=history&amp;year=2006&amp;month=-1&amp;tagfilter=">very early</a>.

It was one of the most revealing things in my life, watching it being laughed at, to become the center of, and authority of, human knowledge.

It was obvious that it was working. The lag of this was 5 years or more.

Wikipedia was an experiment that proved itself, when every graph was going up and to the right.

Some of the graphs are now going down.

</p><p>Wikipedia's Markup language:</p><p>
One of the central design decisions in wikipedia is that <span>all information</span> is stored in an editable document.
This poses a huge amount of challenges for caching and scaling wikipedia. It's not a database, that you can run a script on.

Worse though, is that all of it's content is buried in this ad-hoc, impenetrable, opaque, and mostly <i>un-parsable</i> format.

If wikipedia had used <i>markdown</i>, <i>html</i>, or some <i>standardised format</i>, any parser would flip-it into other future formats.

Wikipedia's custom language is just <a href="https://github.com/spencermountain/wtf_wikipedia/blob/master/README.md">clearly insane</a>, undocumented, hopeless.
There's a team <span>(of great people!)</span> at wikimedia <a href="https://phabricator.wikimedia.org/tag/parsoid/">constantly working on it</a>, and unable to make any backwards-incompatible changes. I imagine their lives are hard.
People are creating weird new syntax concepts all the time.

Here's the markup for the <b>first sentence</b> of the Albert Einstein wikipedia article:
<img src="http://blog.spencermounta.in/2019/wikipedias-in-trouble/assets/albert-einstein.jpg">

The first wikimedia parser was called <a href="https://github.com/earwig/mwparserfromhell/">mwparserfromhell</a>. DBPedia, <a href="https://upload.wikimedia.org/wikipedia/commons/a/a9/LOD_Cloud_2014-08.svg">the center of the semantic web</a>, after years of work, has only ever offered limited parsing from categories and infoboxes.
Much of the early-years at <b>Freebase</b> were spent trying, with limited-success, at parsing wikipedia.
I've spent <a href="https://github.com/spencermountain/wtf_wikipedia/graphs/commit-activity">years</a> trying to parse it myself.
I'm a shitty programmer. <i>WolframAlpha</i>, and many other serious companies are using my parser,
       which is <span>down right hilarious</span>.

<img id="rtl" src="http://blog.spencermounta.in/2019/wikipedias-in-trouble/assets/rtl.jpg"></p><p>yes, arabic editors must write it in right-to-left, <a href="https://youtu.be/OCQd02hORJQ">somehow</a>.</p><p>

It's hard to describe how much of a serious problem this is.
Wikipedia's content is never going to go anywhere, or be used by anything.

Wikipedia may slowly die-off - like myspace, or geocities - but it's information will not go on.

Play-around in the official wikipedia android app. Many pages are unreadable.
There is a good-deal of <i>clearfix</i>, and <span>table-span</span> logic, mushed right into the syntax.
Most developers will not touch this kind of stuff.

There will be no move to a wikipedia 2.

</p><p>Static copies of dynamic content</p><p>
The contents of the english wikipedia dump are as follows, (as of Jan 2019):
</p><p>
of the <b>14m</b> records in the wikipedia dump, only <b>5.5m</b> (40%) are public-facing articles.

   <span>Yup.</span>
This does not include deleted pages, or old versions, either.


<b>Redirects:</b>
A computer-science 101 problem is to implement a fuzzy string matching. There's usually a section in the textbook about it:
</p><div>
<p><img src="http://blog.spencermounta.in/2019/wikipedias-in-trouble/assets/clr.jpg"></p><p>oh yes, right here in chapter 34.</p><p>
there are <b>8,550,441</b> redirects in wikipedia.
They are mostly typos, or case-changes, and are mostly created by hand, every day.

<span>and what happens to a redirect when a page gets deleted, or merged, or spli - <a href="https://en.wikipedia.org/wiki/Wikipedia:Link_rot">Yup</a>.</span>
</p></div>

<p><b>Talk pages:</b>
Wikipedia has 35m registered users. When a user joins, a bot will often send them a <a href="https://en.wikipedia.org/wiki/Template:Welcome">{{welcome}}</a> template.
Sometimes nice users will do it themselves. It looks <a href="https://en.wikipedia.org/wiki/User_talk:Kj_aviator">like this</a>.

   - when this happens, this creates a new user page, with <b>a copy of this text</b> each time.

There are millions of examples of this in the dump. The same text, verbatim over and over.

The same process happens with <b>'Wikiprojects'</b>. Bots go around adding templates, by creating a talk page, and adding a template to it.

The same process happens with <i>deleted pages, fair-use warnings, and some bot edits</i>. Each time an edit happens, a new page is created, and boilerplate text gets thrown into it.
Resulting in <a href="https://en.wikipedia.org/wiki/Talk:XTC_discography">this</a>:
<img src="http://blog.spencermounta.in/2019/wikipedias-in-trouble/assets/boilerplate.png"></p><hr><p>
So let's get things straight:
in <b>1993</b>, a small japanese game company created <a href="https://en.wikipedia.org/wiki/A-Rank_Thunder_Tanjouhen">this videogame</a>:
</p><p><img src="http://blog.spencermounta.in/2019/wikipedias-in-trouble/assets/thunder.jpg">
</p><p>
• In <b>2008</b>, a wikipedia user created the article with <a href="https://en.wikipedia.org/w/index.php?title=A-Rank_Thunder_Tanjouhen&amp;oldid=205879125">two sentences and a link</a>.

• In the past 10 years since, the page has been edited <a href="https://en.wikipedia.org/w/index.php?title=A-Rank_Thunder_Tanjouhen&amp;oldid=205879125">26 times by bots</a>.

• this created a Talk page filled with <a href="https://en.wikipedia.org/wiki/Talk:A-Rank_Thunder_Tanjouhen">11 automated sentences</a>.

A huge bulk of the wikipedia database is this boilerplate text. See <a href="https://en.wikipedia.org/wiki/Talk:764_Gedania">this asteroid</a>, <a href="https://en.wikipedia.org/wiki/Talk:NS3_(HCV)">this virus</a>, or this <a href="https://en.wikipedia.org/wiki/Talk:Oceania_Judo_Union">judo club</a>.

... and remember, if we wanted to change this text, we'd have to go and edit each of these pages - and because this syntax is so nuts, <b>bots have a hard time</b> making even simple stylistic changes, without ruining a whole page.

oh, so what happens to these auto-generated talk pages when a page is deleted, merged, or spli- <a href="https://en.wikipedia.org/wiki/Talk:578_Happelia">yup</a>

<b id="automation">Automated articles:</b>
There is a lot of disagreement about how much of wikipedia is generated by bots, and if this matters.
There's no way of knowing. Any boring-themed article with a few sentences, a reference, and an infobox probably won't get deleted.
So nothing's stopping you from spitting-out articles from a <b>database of enzymes</b>, or <b>college rugby players</b>, or season statistics for defunct sports teams.
</p><p><img src="http://blog.spencermounta.in/2019/wikipedias-in-trouble/assets/enzymes.jpg">
  <img src="http://blog.spencermounta.in/2019/wikipedias-in-trouble/assets/subgiants.png">
</p><p>
I have nothing against bots, I have nothing against the long-tail, but I think automated article-creation is responsible for a good amount of the wikipedia's claimed growth, over the past few years.
We need to be up-front about this, if we're talking about the health of the project.

Here's the distribution of words in english wikipedia, by the size of articles:
</p>

<div>
<p><span>ok hey,</span> I don't mind that the wm developers didn't develop a fancy search index, in 2001.
That's fine.
Nobody could have predicted the success and scale of wikipedia early on.
</p><p>
What angers me though
         - <i>and it should anger you</i> -
is that these problems has not been fixed in the <b>18 years</b> since.

God damn them.

Well-meaning people are wasting their time on this <span>everyday</span>.

Any <i>startup job-interview</i> asks questions about implementing a system like this.
Any CS grad can create a lucene index, to handle typos.
Some of it is complicated. Some of it is basic competence.

<span>It's annoying to whine</span>,
     but at some point, we're right to be angry at wikipedia.

            that it cannot find 2nd gear,
     when the rest of the world is zipping-along.
</p>
</div>

<p>Wikidata</p><p>
In 2007 Danny Hillis raised $57 million dollars,<a href="https://www.crunchbase.com/organization/metawebtechnologies#section-overview">[1]</a> bought-out the <b>entire</b> MIT semantic-web group,
hired 50~ employees, (including <a href="https://www.apple.com/leadership/john-giannandrea/">this person</a>, <a href="https://www.amazon.com/Toby-Segaran/e/B001I9RQVS">this person</a>, <a href="http://davidhuynh.net/">this person</a>) and got an office in the mission.

They reconciled all of wikipedia, the entire musicbrainz database, the entire open-library database, the tvdb database, and all of wordnet.
They signed a (massive) deal to import <b>all collections of the stanford library</b>.<a href="https://www.clir.org/pubs/reports/pub152/stanford-linked-data-workshop/">[2]</a>

They hit <b>high-90%</b> classification of all <a href="https://research.google.com/pubs/archive/44818.pdf"><b>50 million</b></a> entities (wikipedia has 5m)
They were evaluated at very-high 90's accuracy by several third-parties.

Facebook, Bing, Amazon, and Google all began using its data in nearly real-time in their search products.

This was one of the largest and most ambitious software projects in history.

In 2010 freebase was bought for a whack of money, and then killed-off by google.
When google announced they would be shutting down the API, they offered to import all of this data to a new wikimedia project called <span>wikidata</span>.

Wikidata was 4-or-5 Lua developers, in Germany, on a few research grants.

</p><p>and they said no. 😐</p><p>

so they said this data didn't meet it's guidelines regarding sourced data.

    <i>... aren't you pulling information <b>from wikipedia</b> blindly?</i>

    <i>... what about your (~60%) unreferenced facts?</i>

    <i>... aren't you <b>multiplying vandalism</b> from multi-lingual wikipedias?</i>

    <i>... how do you use, or verify references?</i>

They built a tool to <b>hand-transfer each freebase fact</b>, which if you have a calculator, may seem funny.
<span>(at 10 people clicking full-time, would have taken 10 million years)</span>

8 years later, <a href="https://www.wikidata.org/wiki/Wikidata:Main_Page">Wikidata</a> remains tiny, buggy, unused, and worse - <i>majority unreferenced</i>.
I mean, they're pulling their data from wikipedia, which gets vandalized almost every minute!

It's accomplished very-little from its 5-year plan. They write academic papers.
They still don't really offer a rest api.
       ...creating new types or properties is I think, possible? or it's supposed to be...

It's got few of the safeguards, momentum, features, and ambition that Freebase had a full decade ago.
If wikidata was a company, it would not exist anymore, and you wouldn't have heard of it.

But Wikimedia places <b>banner-ads</b> on <span>hours of eye-blistering user-created content</span>,
begging children, students, and poor-people for money.
and they choose to be this petty, pithy and behind-the-times.

</p><p>Category-system</p><p>
It's a beautiful idea, to classify information with category-scheme, <a href="https://humane.computer/review-the-science-of-managing-our-digital-stuff/">until it falls-apart</a>.

<a href="http://www.shirky.com/writings/ontology_overrated.html"><img src="http://blog.spencermounta.in/2019/wikipedias-in-trouble/assets/shirky-category.jpg"></a>
Wikipedia has many-thousands of categories. They <a href="https://en.wikipedia.org/wiki/Wikipedia:Dump_reports/Category_cycles">loop-around</a> all-over the place.

</p><p>
People:
    → Musicians
        → Singers
              → American_Idol
                  → Books_about_American_Idol
</p><p>
or worse:
</p><p><span>Albanian language</span>:
    → Albanian-speaking countries and territories
      → Kosovo (region)
        → Kosovo
          → Kosovar society
            → Languages of Kosovo
              → <span>Albanian language</span>
</p><p>
if you're ever too-cheerful, and wanting to feel depressed, have a visit <a href="https://en.wikipedia.org/wiki/Wikipedia:Categories_for_discussion/Log/Today">Categories for deletion/Today</a>,
where you'll see precious human-life spent debating whether <b>'Category:Goth'</b> should exist, if it is a genre of music, if it's is a fashion-style, etc.

Work is being ravenously deleted all the time. You'll get sad thinking about it.

</p><p>Templates</p>
<div>
  <p>what about all this stuff →</p>
  <p><img src="http://blog.spencermounta.in/2019/wikipedias-in-trouble/assets/infobox.png">
</p></div><p>
You're right.

Wikipedia has good structured-data in <b>infoboxes, lists, tables, citations, etc</b>.

The issue is, as of Feb 2019, Wikipedia has <b>634,755 different kinds of templates</b> (see this <a href="https://s3-us-west-1.amazonaws.com/spencer-scratch/allTemplates-2018-10-26.tsv">21mb download</a>).

Yes, there are all different.

Yes, there are <span>templates-within-templates-with-escaping-with-escaping</span>.

Even if you parse them perfectly, how do you know that for <a href="https://en.wikipedia.org/wiki/Template:HorseDeathYear">Template:HorseDeathYear</a>, the third parameter is the <b>birth date of the horse</b>, and the fourth is the birth-month?

see, for example:

• <a href="https://en.wikipedia.org/wiki/Category:16-Team_bracket_templates">Tennis Brackets vs Table Tennis Brackets</a>

• '<a href="https://en.wikipedia.org/wiki/Template:Birth_date_and_age">Birth_date_and_age</a>' vs '<a href="https://en.wikipedia.org/wiki/Template:Birth-date_and_age">Birth-date_and_age</a>'.

• <a href="https://en.wikipedia.org/wiki/Template:Trapezoidnotation">a template for a Trapezoid unicode symbol</a>
It's just a straight-up mess.

If you're thinking, <i>gee wikipedia editors must feel exhausted and stupid</i> - you're right.

<a href="https://en.wikipedia.org/w/index.php?title=Special:WhatLinksHere/Template:Retired&amp;limit=500">Many</a>…</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://blog.spencermounta.in/2019/wikipedias-in-trouble/index.html">http://blog.spencermounta.in/2019/wikipedias-in-trouble/index.html</a></em></p>]]>
            </description>
            <link>http://blog.spencermounta.in/2019/wikipedias-in-trouble/index.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25300942</guid>
            <pubDate>Fri, 04 Dec 2020 10:41:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I made 24 high-quality Covid illustrations. Free for commercial and personal use]]>
            </title>
            <description>
<![CDATA[
Score 317 | Comments 116 (<a href="https://news.ycombinator.com/item?id=25300594">thread link</a>) | @andyydao
<br/>
December 4, 2020 | https://www.pixeltrue.com/frontliner-heroes | <a href="https://web.archive.org/web/*/https://www.pixeltrue.com/frontliner-heroes">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
  
<div data-collapse="small" data-animation="default" data-duration="400" role="banner"><div data-w-id="829bd4f8-a52c-9bed-f351-1f1c429ebfb2"><p><a href="#" id="w-node-1f1c429ebfb3-a3ea6df0"><img src="https://uploads-ssl.webflow.com/5dd3495558fd7f3d1fcb52bc/5fc50a7fc8b859794cc27d27_COVID%20Logo.svg" loading="lazy" alt=""></a></p><div id="w-node-1f1c429ebfb6-a3ea6df0"><p><img src="https://uploads-ssl.webflow.com/5dd3495558fd7f3d1fcb52bc/5fc50a7fc8b859446ec27d28_Logo%20no%20background.png" loading="lazy" sizes="(max-width: 767px) 100vw, (max-width: 1439px) 20px, (max-width: 1919px) 25px, 30px" srcset="https://uploads-ssl.webflow.com/5dd3495558fd7f3d1fcb52bc/5fc50a7fc8b859446ec27d28_Logo%2520no%2520background-p-500.png 500w, https://uploads-ssl.webflow.com/5dd3495558fd7f3d1fcb52bc/5fc50a7fc8b859446ec27d28_Logo%2520no%2520background-p-800.png 800w, https://uploads-ssl.webflow.com/5dd3495558fd7f3d1fcb52bc/5fc50a7fc8b859446ec27d28_Logo%2520no%2520background-p-1080.png 1080w, https://uploads-ssl.webflow.com/5dd3495558fd7f3d1fcb52bc/5fc50a7fc8b859446ec27d28_Logo%20no%20background.png 1214w" alt=""></p></div></div></div><div><div data-w-id="f1207815-d48c-2550-8aa6-2af2cd0d2c1b"><p data-w-id="f1207815-d48c-2550-8aa6-2af2cd0d2c1c">Frontliner Heroes</p><p>24 high-quality Covid illustrations. Free for commercial and personal use.</p></div><p><img src="https://uploads-ssl.webflow.com/5dd3495558fd7f3d1fcb52bc/5fc50b2c6728188179a7570d_Hero%20Illustration.svg" loading="eager" width="462" data-w-id="f1207815-d48c-2550-8aa6-2af2cd0d2c20" alt=""><img src="https://uploads-ssl.webflow.com/5dd3495558fd7f3d1fcb52bc/5fc50b2c672818d125a7570c_Background.svg" loading="lazy" data-w-id="f1207815-d48c-2550-8aa6-2af2cd0d2c21" alt=""></p></div><div><div><div><div><p>Frontliner Heroes comes with exciting scenes that are commonly used to stop the spread of COVID. In addition, we'll be continually adding new illustration to this pack!</p></div></div></div></div><div><p><h2>24 Illustrations to fight against COVID!</h2></p></div><div><div><h2>Sample Applications</h2><p>These illustrations are perfect for any type of project. Simply Drag and drop them in and you're ready to go!</p></div><p><img src="https://uploads-ssl.webflow.com/5dd3495558fd7f3d1fcb52bc/5fc50b4456b3fd49b0f42063_Sample%20Applications.svg" loading="eager" alt=""></p></div><div><p><h2>Awesome Features</h2></p><div id="benefits"><div><div><p><img src="https://uploads-ssl.webflow.com/5dd3495558fd7f3d1fcb52bc/5fc50b54fe9410cacea1ebe4_Group%2084.png" alt=""></p><div><h3>Fully Vector<br></h3><p>All illustrations are fully vector meaning you can enlarge illustrations without quality loss<br></p></div></div><div><p><img src="https://uploads-ssl.webflow.com/5dd3495558fd7f3d1fcb52bc/5fc50b54fe94105ee6a1ebe8_Group%20174.svg" alt=""></p><div><h3>Customizable<br></h3><p>Easily change illustration scenes to match your brand using common programs like Sketch and Figma.<br></p></div></div><div><p><img src="https://uploads-ssl.webflow.com/5dd3495558fd7f3d1fcb52bc/5fc50b54fe9410876ca1ebe6_Group%20148.png" alt=""></p><div><h3>Different File Formats<br></h3><p>With our Frontliners pack you'll get access to all source files - this includes SVG, PNG&nbsp;and AI&nbsp;files.<br></p></div></div></div></div></div><!--[if lte IE 9]><script src="//cdnjs.cloudflare.com/ajax/libs/placeholders/3.0.2/placeholders.min.js"></script><![endif]-->


<!-- Hotjar Tracking Code for www.pixeltrue.com -->






<!-- Memberstack --> 
 








<meta name="p:domain_verify" content="efd5329f8b1be336c6381d60a312999c">



<!-- Facebook Pixel Code -->


<!-- End Facebook Pixel Code -->


<!-- Global site tag (gtag.js) - Google Analytics -->














</div>]]>
            </description>
            <link>https://www.pixeltrue.com/frontliner-heroes</link>
            <guid isPermaLink="false">hacker-news-small-sites-25300594</guid>
            <pubDate>Fri, 04 Dec 2020 09:40:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Self-host your fonts for better performance]]>
            </title>
            <description>
<![CDATA[
Score 592 | Comments 398 (<a href="https://news.ycombinator.com/item?id=25300396">thread link</a>) | @zwacky
<br/>
December 4, 2020 | https://wicki.io/posts/2020-11-goodbye-google-fonts/ | <a href="https://web.archive.org/web/*/https://wicki.io/posts/2020-11-goodbye-google-fonts/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">

<div>
  <div>
    <div>
      
      <p>
        
          November 30, 2020
        
      </p>

      <figure>
    <img src="https://wicki.io/posts/2020-11-goodbye-google-fonts/goodbye-google-fonts.jpg" alt="Google Fonts"> 
</figure>

<p>I’ve used Google Fonts in prototypes and in 10M+ MAU products. It’s incredibly easy to get started with and provides an amazing font discovery. That’s also why it’s currently still used on over <a href="https://trends.builtwith.com/websitelist/Google-Font-API">42M websites</a>!</p>
<p>This convenience has its price: Performance. Many <a href="https://blog.cloudflare.com/fast-google-fonts-with-cloudflare-workers/">have</a> <a href="https://medium.com/clio-calliope/making-google-fonts-faster-aadf3c02a36d">already</a> <a href="https://www.keycdn.com/blog/web-font-performance#disadvantages-of-web-fonts">pointed</a> <a href="https://blog.logrocket.com/self-hosted-fonts-vs-google-fonts-api/">out</a> the cost of multiple requests. If you want the remaining speed boost, then you’re best off downloading your used Google Fonts and self-host them.</p>
<p>This is nothing new. In fact it’s been advocated already for years. Even Google themselves <a href="https://www.youtube.com/watch?v=Mv-l3-tJgGk&amp;feature=youtu.be&amp;t=24m58s">advised others to self-host fonts</a> in their Google I/O ‘18 talk about web performance.</p>
<h2 id="self-hosting-fonts-vs-google-fonts">Self-hosting fonts vs Google Fonts</h2>
<p>By nature Google Fonts, even with all its font and CSS optimisations, can’t be faster than self-hosted fonts.</p>
<p>Sia wrote <a href="https://medium.com/clio-calliope/making-google-fonts-faster-aadf3c02a36d">a great post</a> where she compared the performance between Google Fonts and self-hosted fonts without the impact of a CDN.</p>
<figure>
    <img src="https://wicki.io/posts/2020-11-goodbye-google-fonts/with-google-fonts.png" alt="Network flow with Google Fonts"> <figcaption>
            <p>Optimised Google Fonts loading with preconnect</p>
        </figcaption>
</figure>

<figure>
    <img src="https://wicki.io/posts/2020-11-goodbye-google-fonts/without-google-fonts.png" alt="Network flow with self-hosting fonts"> <figcaption>
            <p>Optimised self-hosting fonts with preload</p>
        </figcaption>
</figure>

<hr>
<h2 id="the-old-performance-argument">The old performance argument</h2>
<p>So if the bottom-line performance is in self-hosting fonts’ favour: What was the argument that convinced us developers that Google Fonts is at least as performing as the self-host approach?</p>
<p>Google Fonts was designed to be distributed on a global CDN and reap the caching benefits from it. Users request fonts via said CDN. Chances are that they have downloaded the font resources at an earlier point already from a different site.</p>
<blockquote>
<p>“[…] Our cross-site caching is designed so that you only need to load a font once, with any website, and we’ll use that same cached font on any other website that uses Google Fonts.”</p>
<p>— <a href="https://fonts.google.com/about">https://fonts.google.com/about</a></p>
</blockquote>
<h2 id="invalidating-the-old-performance-argument">Invalidating the old performance argument</h2>
<p>Since Chrome v86, released October 2020, cross-site resources like fonts can’t be shared on the same CDN anymore. This is due to the partitioned browser cache (Safari has had this for years already).</p>
<p>In <a href="https://developers.google.com/web/updates/2020/10/http-cache-partitioning">this Google post</a> they explain what the partitioned browser cache is. It got only introduced to prevent a possible cross-site tracking mechanism.</p>
<h2 id="cache-partitioning-in-other-browsers">Cache partitioning in other browsers</h2>
<p>Safari really cares about privacy. It circumvented this very cross-site tracking attack for years already. Then finally comes Chrome. Other browsers that are based off Chromium, still need to signal or implement the feature.</p>
<ul>
<li>✅ <strong>Chrome</strong>: since v86 (October 2020)</li>
<li>✅ <strong>Safari</strong>: since 2013</li>
<li>🚫 <strong>Firefox</strong>: planning to implement</li>
<li>🚫 <strong>Edge</strong>: most likely soon</li>
<li>🚫 <strong>Opera</strong>: most likely soon</li>
<li>🚫 <strong>Brave</strong>: most likely soon</li>
<li>🚫 <strong>Vivaldi</strong>: most likely soon</li>
</ul>
<h2 id="conclusion">Conclusion</h2>
<p>Google Fonts resources will be redownloaded for every website, regardless it being cached on the CDN. Self-host your fonts for better performance. The old performance argument is not valid anymore.</p>
<p>Thanks for checking this post out!</p>


      
      <hr><div>
  <p><img src="https://wicki.io/images/me_huc890d15b6e9f2ce8978e9aa27127dd5e_67203_350x0_resize_q75_box.jpg" alt="Simon Wicki">
    
  </p>

  <div>
    <div>
      <p>
        <strong>Simon Wicki</strong> is a Freelance Frontend Developer in
				Berlin. Passionate and fluent in Vue, Angular, React and Ionic. Interested in 
				Tech, frontend &amp; non-fiction books
      </p>
      <p>
        <a href="https://twitter.com/zwacky" onclick="ga('send', 'event', 'clickout', 'bottom_cta', '\/posts\/2020-11-goodbye-google-fonts\/')" target="_blank">
          <img src="https://wicki.io/images/svg/twitter.svg" alt="Twitter" title="Twitter">
          Follow @zwacky
        </a>
      </p>
    </div>
  </div>
</div>

    </div>
  </div>
</div>


        </div></div>]]>
            </description>
            <link>https://wicki.io/posts/2020-11-goodbye-google-fonts/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25300396</guid>
            <pubDate>Fri, 04 Dec 2020 09:01:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Project Loom and Structured Concurrency]]>
            </title>
            <description>
<![CDATA[
Score 167 | Comments 105 (<a href="https://news.ycombinator.com/item?id=25300233">thread link</a>) | @ingve
<br/>
December 4, 2020 | https://www.javaadvent.com/2020/12/project-loom-and-structured-concurrency.html | <a href="https://web.archive.org/web/*/https://www.javaadvent.com/2020/12/project-loom-and-structured-concurrency.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
							
<h2>Why Loom?</h2>
<p>In 1998, it was amazing that the Sun Java Web Server (the precursor of Tomcat) ran each request in a separate thread, and not an OS process. It was able to serve thousands of concurrent requests this way! Nowadays, that’s not so amazing. Each thread takes up a significant amount of memory, and you can’t have millions of threads on a typical server.</p>
<p>That’s why the modern mantra of server-side programming is: “Never block!” Instead, you specify what should happen once the data is available.</p>
<p>This asynchronous programming style is great for servers, allowing them to handily support millions of concurrent requests. It isn’t so great for programmers.</p>
<p>Here is an asynchronous request with the <code>HttpClient</code> API:</p>
<pre>HttpClient.newBuilder()
   .build()
   .sendAsync(request, HttpResponse.BodyHandlers.ofString())
   .thenAccept(response -&gt; . . .);
   .thenApply(. . .);
   .exceptionally(. . .);
</pre>
<p>What we would normally achieve with statements is now encoded as method calls. If we loved this style of programming, we would not have statements in our programming language and merrily code in Lisp.</p>
<p>In JavaScript, code tagged as “async” is rewritten into method calls like the ones that you’ve just seen. But that means you can only call async methods from other async methods, and your API splits into a sync and an async part, forcing you to duplicate functionality.</p>

<p>Project Loom takes its guidance from languages such as Erlang and Go, attacking the root of the problem by making blocking very cheap. You run tasks in “virtual threads”, a nearly unlimited resource that is mapped into actual “carrier” threads. When a virtual thread blocks, it is “parked” and another virtual thread runs on the carrier thread. The name is supposed to remind you of virtual memory that is mapped to actual RAM.</p>
<p>Before you complain about the name, remember that naming is hard. The Loom team previously tried “fiber”, but it is already used elsewhere with a slightly different meaning. And “lightweight” or “new” thread might look foolish when something lighter-weight or newer comes along.</p>
<p>After experimenting with separate classes for OS threads and virtual threads, they ended up deciding to use a single class for both—the familiar <code>java.lang.Thread</code>—in order to ease migration.</p>
<p>Of course, good old <code>java.lang.Thread</code>, which has been around for 25 years, ever since Java 1.0, has its share of cruft. Awkward cancellation, thread groups, priorities, depreceated methods <code>stop</code>,<code>suspend</code>, <code>resume</code>. The Loom team felt that these liabilities were minor since most programmers never explicitly use the <code>Thread</code> API but launch tasks with an <code>ExecutorService</code>. (Of course, the same argument would support coming up with a cleaner virtual thread API instead.)</p>
<p>If you have been around for a very long time, you may remember that early versions of Java had “green threads” that were mapped to an OS thread. However, there is a crucial difference. When a green thread blocked, its carrier thread was also blocked, preventing all other green threads from making progress.</p>

<p>You can download binaries of Project Loom at <a href="http://jdk.java.net/loom/">http://jdk.java.net/loom/</a>. They are updated regularly.</p>
<p>As already mentioned, a virtual thread is an object of the <code>Thread</code> class. Here are three ways of producing fibers. First, there is a new factory method that constructs and starts a virtual thread:</p>
<pre>Thread thread = Thread.startVirtualThread(runnable);
  // <cite>Note that the thread is already started</cite></pre>
<p>This is good for demos, tutorials or quick-and-dirty experiments in JShell.</p>
<p>For more customization, there is a builder API:</p>
<pre>Thread thread = Thread.builder()
   .virtual()
   .name(taskname)
   .task(runnable)
   .build();</pre>
<p>However, as you have been told for many years now, it is better to use an executor service than to manually construct <code>Thread</code> instances. The static method <code>Executors.newVirtualThreadExecutor()</code> provides one. (The existing executor services are not useful for virtual threads. It would be counterproductive to pool them!)</p>
<p>For example,</p>
<pre>ExecutorService exec = Executors.newVirtualThreadExecutor();
exec.submit(runnable1);
exec.submit(runnable2);
</pre>
<p>As with the other factory methods in the <code>Executors</code> class, you can optionally supply a <code>ThreadFactory</code>. And the new <code>Thread.Builder</code> class has an easy way to provide a factory, instead of a single instance:</p>
<pre>ThreadFactory factory = Thread.builder()
   .virtual()
   .name(taskname)
   .task(runnable)
   .<b>factory()</b>;

ExecutorService exec = Executors.newThreadExecutor(factory);
</pre>
<p>Let’s try this out. As a first test, we just sleep in each task.</p>
<pre>import java.util.concurrent.*;

public class Test {
   public static int DELAY = 10_000;
   public static int NTASKS = 1_000_000;

   public static void run(Object obj) {
      try {
         Thread.sleep((int) (DELAY * Math.random()));
      } catch (InterruptedException ex) {
         ex.printStackTrace();
      }
      System.out.println(obj);
   }

   public static void main(String[] args) {
      ExecutorService exec = Executors.newVirtualThreadExecutor();
      for (int i = 1; i &lt;= NTASKS; i++) {
         String taskname = "task-" + i;
         exec.submit(() -&gt; run(taskname));
      }
      exec.close();
   }
}
</pre>
<p>Run the program and it just works. Then try using OS threads—change to <code>Executors.newCachedThreadPool()</code> or <code>Executors.newFixedThreadPool(NTASKS)</code>. The program will run out of memory; on my laptop, after about 25,000 threads.</p>
<p>Ok, but in practice, you don’t want to sleep, but do useful work. Consider a program adapted from one of <a href="https://www.javaspecialists.eu/about/heinz/">Heinz Kabutz</a>‘ puzzlers, The program fetches a daily image, from Dilbert or Wikimedia. It consists of classes <a href="http://horstmann.com/unblog/2019-07-27/dailyImages/ImageProcessor.java"><code>ImageProcessor</code></a> and <a href="http://horstmann.com/unblog/2019-07-27/dailyImages/ImageInfo.java"><code>ImageInfo</code></a>. The code is an impenetrable maze of twisty passages, all alike (i.e. helper functions yielding completable futures).</p>
<p>With virtual threads, simply read web contents synchronously. It blocks, but we don’t care. All the complexity goes away. The control flow is simple and comprehensible.</p>
<pre>exec.submit(() -&gt; {
    String pageURL = info.getUrlForDate(date);
    String page = getSync(pageURL, HttpResponse.BodyHandlers.ofString());
    String imageURL = info.findImage(page).getImagePath();
    byte[] image = getSync(imageURL, HttpResponse.BodyHandlers.ofByteArray());
    info.setImageData(image);
    process(info);
    return null;
});</pre>
<p>Here is the simplified <a href="http://horstmann.com/unblog/2020-12-05/dailyImages/ImageProcessor.java"><code>ImageProcessor</code></a> code.</p>
<p><b>Pro tip: </b>The statement <code>return null;</code> makes the lambda into a <code>Callable</code> instead of a <code>Runnable</code>, so that you don’t have to catch checked exceptions 😜</p>
<p>Try this out with something you care about. Call web services and make database connections, without worrying about callbacks. When blocking is cheap, a whole lot of accidental complexity goes away. Of course, to use this in a web app framework, you’ll have to wait for your framework provider to run your code in virtual threads.</p>
<h2>Structured Concurrency</h2>
<p>In <a href="https://vorpus.org/blog/notes-on-structured-concurrency-or-go-statement-considered-harmful/">this highly recommended article</a> (from which the images below are taken), Nathaniel Smith proposes structured forms of concurrency. Here is his central argument. Launching a task in a new thread is really no better than programming with GOTO, i.e. harmful:</p>
<pre>new Thread(runnable).start();</pre>
<p><img src="http://horstmann.com/unblog/2019-12-05/sequential-and-go-to-schematic.svg" alt=".svg" width="38%"></p>
<p>When multiple threads run without coordination, it’s spaghetti code all over again. In the 1960s, structured programming replaced <code>goto</code> with branches, loops, and functions:</p>
<p><img src="http://horstmann.com/unblog/2019-12-05/control-schematics.svg" alt=".svg" width="42%"></p>
<p>When you look at a line of code, you know how the program got there.</p>
<p>Structured concurrency does the same for concurrent tasks. We should know, from reading the program text, when they all finish.</p>
<p><img src="http://horstmann.com/unblog/2019-12-05/nursery-schematic-unlabeled.svg" alt=".svg" width="30%"></p>
<p>That way we can control the resources that the tasks use, and we know when it is time to move on.</p>
<p>In Loom, the <code>ExecutorService</code> implements this basic construct. <code>ExecutorService</code> has a <code>close</code> method that blocks until all of its virtual threads have completed. (I used this method in the first sample program to keep <code>main</code> alive until all virtual threads are done. In the past, you had to call the <code>awaitTermination</code> method instead.)</p>
<p>Conveniently, <code>ExecutorService</code> implements the <code>AutoCloseable</code> interface, so that you can just use a <code>try</code>-with-resources statement:</p>
<pre>try (ExecutorService exec = Executor.newVirtualThreadExecutor()) {
   for (int i = 0; i &lt; NTASKS; i++) {
      exec.schedule(() -&gt; run(i));
   }
} // <cite>Blocks until all threads completed</cite>
</pre>
<p>I wrote a simple web crawler as a demonstration of virtual threads—here is the <a href="http://horstmann.com/unblog/2020-12-05/Crawler.java"><code>Crawler</code></a> class. In my first attempt, I fired off a new virtual thread for each URL in a page. If I had wanted to become Google, I could have let my crawler run forever. But I wanted to go no more than 3 hops from the starting point. With “fire and forget”, there is no way of knowing when the recursion is done.</p>
<p>Instead, for each page, I make a new executor service and wait for completion. That way, the whole program completes when all pages have been crawled.</p>
<p>This seems a lot of blocking. But in Loom, blocking is cheap, so we shouldn’t worry about that.</p>
<p>We are used to having one executor service as thread pool for all our tasks. But in Loom, you are encouraged to use a separate executor service for each task set.</p>
<h2>Deadlines</h2>
<p>When crawling the web, you are likely to encounter dead links. Reading from one should time out eventually, but it can take surprisingly long.</p>
<p>The standard remedy is, of course, to provide a timeout. Loom prefers deadlines to timeouts, so you specify</p>
<pre>ExecutorService exec = Executors.newVirtualThreadExecutor().withDeadline(
   Instant.now().plus(30, ChronoUnit.SECONDS))
</pre>
<p>Why deadlines? In general, timeouts compose poorly. Suppose you have to accomplish two sequential tasks with an overall timeout of 10 seconds. You don’t want to give each of the tasks a timeout of 5 seconds. After all, if one takes 6 seconds and the other 3 seconds, you still come in under the finish line. To get the timeout of the second task, you’d have to measure the duration of the first task and subtract that from the overall timeout. With deadlines, it is much simpler. Each task gets the same deadline.</p>
<p>The call <code>exec.close()</code> blocks until all virtual threads have completed or the …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.javaadvent.com/2020/12/project-loom-and-structured-concurrency.html">https://www.javaadvent.com/2020/12/project-loom-and-structured-concurrency.html</a></em></p>]]>
            </description>
            <link>https://www.javaadvent.com/2020/12/project-loom-and-structured-concurrency.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25300233</guid>
            <pubDate>Fri, 04 Dec 2020 08:24:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Monoliths as a Service]]>
            </title>
            <description>
<![CDATA[
Score 112 | Comments 57 (<a href="https://news.ycombinator.com/item?id=25299598">thread link</a>) | @gdeglin
<br/>
December 3, 2020 | https://www.themostfamousartist.com/maas | <a href="https://web.archive.org/web/*/https://www.themostfamousartist.com/maas">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-block-type="2" id="block-a13f76d094074a98b8e4"><p><h3>PO BOX 4115</h3><h3>SANTA FE, NM 87502</h3><h3><strong>© 2020 THE MOST FAMOUS ARTIST, LLC</strong></h3></p></div></div>]]>
            </description>
            <link>https://www.themostfamousartist.com/maas</link>
            <guid isPermaLink="false">hacker-news-small-sites-25299598</guid>
            <pubDate>Fri, 04 Dec 2020 06:22:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Faroe Island roundabout under the Atlantic Ocean]]>
            </title>
            <description>
<![CDATA[
Score 94 | Comments 60 (<a href="https://news.ycombinator.com/item?id=25299574">thread link</a>) | @sohkamyung
<br/>
December 3, 2020 | https://nordfra.dk/faroe-island-first-roundabout-in-the-world-under-the-atlantic-ocean/ | <a href="https://web.archive.org/web/*/https://nordfra.dk/faroe-island-first-roundabout-in-the-world-under-the-atlantic-ocean/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://nordfra.dk/faroe-island-first-roundabout-in-the-world-under-the-atlantic-ocean/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25299574</guid>
            <pubDate>Fri, 04 Dec 2020 06:18:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How I Manage My Random Daily Notes]]>
            </title>
            <description>
<![CDATA[
Score 210 | Comments 180 (<a href="https://news.ycombinator.com/item?id=25299442">thread link</a>) | @hachibu
<br/>
December 3, 2020 | https://hachibu.net/posts/2020/how-i-manage-my-random-daily-notes/ | <a href="https://web.archive.org/web/*/https://hachibu.net/posts/2020/how-i-manage-my-random-daily-notes/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><figure><img src="https://hachibu.net/posts/2020/how-i-manage-my-random-daily-notes/images/featured.png"><figcaption><p>Illustration: Hachibu</p></figcaption></figure><p>For years, I kept track of random notes by creating a text or Markdown
file on my desktop. And at the end of the day, I would delete that file and
start over again the next day. Inspired by the minimalism of <a href="https://github.com/todotxt/todo.txt-cli">todo-txt-cli</a>,
I created a similar system to manage my own notes.</p><p>Keep reading for more details or skip to the code: <a href="https://github.com/hachibu/note.sh">github.com/hachibu/note.sh</a>.</p><h4 id="introduction">Introduction</h4><p>As I mentioned before, I used to keep a single notes file on my desktop, and I
would delete it everyday. I would use this notes file to keep track of random
thoughts and details related to my work and personal life. My notes file might
contain code snippets from work, inspirational quotes, or it might have my
latest and greatest open-source software idea, or maybe even the beginning of a
new blog post. Anyway, I loved the simplicity of it, and I didn’t want any more
apps, databases or logins in my life.</p><p>But it wasn’t until I started using <a href="https://github.com/todotxt/todo.txt-cli">todo-txt-cli</a>
that I considered writing a script to manage my own notes. The brilliant part
about <code>todo-txt-cli</code> is that it’s just text files stored in my Dropbox and a
small shell script to interface with those files.</p><p>Inspired by the minimalism of <code>todo-txt-cli</code>, I built <a href="https://github.com/hachibu/note.sh">note.sh</a>.
In total, the entire project consists of 1 Bash script, 1 environment variable
to configure the notes directory and 1 symlink to install it to your
<code>/usr/local/bin</code> directory.</p><h4 id="how-it-works">How It Works</h4><p>The way it works is that every time I run the script, it opens the note for that
day in my editor of choice. For example, if today was December 2, 2020 then the
script would open a file named <code>2020-12-02.md</code> in the notes directory.</p><p>I use Vim as my editor, and I have my notes stored on Dropbox so I can access
them on all of my computers. So, my shell RC file looks like this.</p><div><pre><code data-lang="shell"><span>export</span> <span>EDITOR</span><span>=</span><span>"vim"</span>
<span>export</span> <span>NOTE_DIR</span><span>=</span><span>"</span><span>$HOME</span><span>/Dropbox/Notes"</span>
</code></pre></div><p>And my Dropbox directory looks like this.</p><p><img src="https://hachibu.net/posts/2020/how-i-manage-my-random-daily-notes/images/dropbox-screenshot.png" alt="Dropbox Screenshot"></p><p>For searching, the script accepts a pattern and runs a recursive grep over the
notes directory. I chose grep because I use this script on both Mac and Linux,
and I wanted the script to be as portable as possible.</p><h4 id="conclusion">Conclusion</h4><p>I’ve been using this script for several months across several computers, and I
still love it. I don’t search as often as I thought I would, but it’s comforting
to know it’s all there if I need it. I also ended up creating an alias for my
script so all I need to type is the letter <code>n</code> to run the script.</p><p>In the future, I’d like to add a test suite to the code base, figure out how
to create a Homebrew formula, and add archiving for older notes.</p></div></div>]]>
            </description>
            <link>https://hachibu.net/posts/2020/how-i-manage-my-random-daily-notes/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25299442</guid>
            <pubDate>Fri, 04 Dec 2020 05:51:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[That Dothraki Horde, Part I: Barbarian Couture]]>
            </title>
            <description>
<![CDATA[
Score 119 | Comments 103 (<a href="https://news.ycombinator.com/item?id=25299176">thread link</a>) | @parsecs
<br/>
December 3, 2020 | https://acoup.blog/2020/12/04/collections-that-dothraki-horde-part-i-barbarian-couture/ | <a href="https://web.archive.org/web/*/https://acoup.blog/2020/12/04/collections-that-dothraki-horde-part-i-barbarian-couture/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<p>This is the first part of a three part (II, III) look at the Dothraki, the fictional horse-borne nomads of the <em>Game of Thrones</em> / <em>A Song of Ice and Fire</em> series and the degree to which George R.R. Martin’s claim that they are “an amalgam of a number of steppe and plains cultures” holds up to scrutiny.  This is something that I have been suggesting I would get to since (checks notes),<a href="https://acoup.blog/2019/05/04/new-acquisitions-that-dothraki-charge/"> May.  Of Last Year.</a>  So it is about time we actually get to it.</p>



<p>The plan is for this series to run in three parts.  Part I (this part) will discuss how the Dothraki <em>look</em> in the setting.  Part II will look at broader questions of social organization and culture (I am nearly certain this is one of those cases where there will be a IIa and a IIb, but my hope for brevity springs eternal).  Part III will look at military culture.  In all three parts I am going to use both the books and the show – noting where they diverge – in part because the heaviest characterization the Dothraki got in the show was when Martin was still significantly involved with it (meaning that large parts of it likely still reflect his vision), but also because the show is how the vast majority of people experience this particular fiction.  Both the original text and the show derived from it deserve to have their vision discussed.</p>



<p>As always, if you like what you are reading here, please share it; if you really like it, you can support me on <a href="https://www.patreon.com/user?u=20122096">Patreon</a>. And if you want updates whenever a new post appears, you can click below for email updates or follow me on twitter (@BretDevereaux) for updates as to new posts as well as my occasional ancient history, foreign policy or military history musings.</p>






<p>First, a <strong>content warning for this series</strong>: this is discussing <em>A Song of Ice and Fire</em> and <em>Game of Thrones</em> which features a lot of content which is not G-rated.  More to the point, it is a discussion of what – I will argue – Martin presents as one of, if not the most brutal and sexually violent society in that setting.  And that means those themes are going to come up here (less in this essay, but more in the other parts); we are going to remain serious and adult about those things of course, but they will be a part of this analysis nonetheless.  If that is not for you, by all means feel free to check out for a few weeks.</p>



<p>Before we get into the main point, <strong>I want to note that I am going to reference my series on the <a href="https://acoup.blog/2020/01/17/collections-the-fremen-mirage-part-i-war-at-the-dawn-of-civilization/">Fremen Mirage</a> <em>a lot</em> here</strong>, because there is a lot of Fremen stuff going on with how Dothraki society is depicted.  As a result, it may be useful to go back and read those, but just to recap, we may define the Fremen Mirage this way:</p>



<p><a href="https://acoup.blog/2020/02/21/collections-the-fremen-mirage-interlude-ways-of-the-fremen/"><strong>The Fremen Mirage is a literary trope, <em>unconnected to historical reality</em>, which presents societies as a contrast between unsophisticated, but morally pure, hyper-masculine and militarily effective ‘strong men’ societies honed by ‘hard times’ (that is, the Fremen of the term) and a sophisticated but effeminate and decadent ‘weak men’ societies weakened by ‘good times,’ frequently with an implicit assertion of the superior worth of the former.</strong></a></p>



<p>Next, a note on citation here from the books.  My understanding is that different printings of the books have different pagination, which seems to be why the Wiki of Ice and Fire cites by chapter numbers (except that the chapters of the books, as printed, <em>aren’t numbered</em> in the print editions I’ve seen, making this classical-style citation extremely cumbersome and inexact).  I am going to cite by the page numbers of my edition, which is the 2011 Bantam Books Trade Paperback Edition (the box set).  Hopefully that will be enough.</p>



<p>Finally, a note on my expertise here.  <strong>I am not a scholar of either the peoples of the Eurasian Steppe or the American Great Plains</strong>.  The former group does intrude into my period and study, as steppe nomads, in the form of Scythians, Sarmatians and Huns did interact (sometimes peacefully, sometimes violently) with the broader Mediterranean world.  Consequently, my knowledge of steppe peoples tend to be better that my knowledge of the Native American peoples of the Great Plains, but I have tried, within the limits of time and availability, to do my research. <strong> I actually think, in a strange sense, this is useful, because my own initial unfamiliarity with the topic has demonstrated to me just how <em>basic</em> the level of research and reading necessary to avoid the failures of this depiction are</strong>.  You do not, in turns out, need to be an experienced scholar on the topic; just a few books and a couple of emails is enough to already radically improve on what we see and read in <em>A Song of Ice and Fire</em>, much less the absolute <em>mess </em>of what we see in <em>A Game of Thrones</em>.</p>



<p>Writing this has been tricky.  I am well aware that both of these broad cultural groups (that is, Steppe peoples and Plains Native Americans) are often represented in popular culture only in the form of inaccurate and demeaning stereotypes.  I do not want to be just another link in that chain of poor understanding.  I have thus tried to root my argument here, wherever possible, in either the writings of specialist scholars (there will be more of that next week as we get into subsistence patterns, warfare, etc.) or primary evidence, particularly in terms of <em>period photographs</em>, when it comes to clothing and dress.  With luck I have not erred overmuch.</p>



<figure><img data-attachment-id="5355" data-permalink="https://acoup.blog/1024px-skythian_archer_plate_bm_e135_by_epiktetos/" data-orig-file="https://acoupdotblog.files.wordpress.com/2020/12/1024px-skythian_archer_plate_bm_e135_by_epiktetos.jpg" data-orig-size="1024,991" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="1024px-skythian_archer_plate_bm_e135_by_epiktetos" data-image-description="" data-medium-file="https://acoupdotblog.files.wordpress.com/2020/12/1024px-skythian_archer_plate_bm_e135_by_epiktetos.jpg?w=300" data-large-file="https://acoupdotblog.files.wordpress.com/2020/12/1024px-skythian_archer_plate_bm_e135_by_epiktetos.jpg?w=1024" src="https://acoupdotblog.files.wordpress.com/2020/12/1024px-skythian_archer_plate_bm_e135_by_epiktetos.jpg?w=1024" alt="" srcset="https://acoupdotblog.files.wordpress.com/2020/12/1024px-skythian_archer_plate_bm_e135_by_epiktetos.jpg 1024w, https://acoupdotblog.files.wordpress.com/2020/12/1024px-skythian_archer_plate_bm_e135_by_epiktetos.jpg?w=150 150w, https://acoupdotblog.files.wordpress.com/2020/12/1024px-skythian_archer_plate_bm_e135_by_epiktetos.jpg?w=300 300w, https://acoupdotblog.files.wordpress.com/2020/12/1024px-skythian_archer_plate_bm_e135_by_epiktetos.jpg?w=768 768w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption><a href="https://en.wikipedia.org/wiki/Scythians#/media/File:Skythian_archer_plate_BM_E135_by_Epiktetos.jpg">Via Wikipedia</a>, an Attic vase-painting of a Scythian archer (c. 500 BCE).  The Scythians, like the Huns and Mongols, were a Eurasian Steppe people, many of them horse-borne nomads of the same sort.  Far from being drab, their clothing was colorful and distinctive, including their particular hats, which show up not only in Greek but also in Persian artwork.</figcaption></figure>



<h2>…But, Why?</h2>



<p>But before we get into the issue proper, it is important to clear away the standard objections, both why subject <em>A Song of Ice and Fire</em> (and its spin-off properties) to critical analysis at all and also why, if we are going to do that, we are going to focus squarely in on the Dothraki.  The answer to the first is something that we’ve rehearsed a number of times, but bears restating: for most of its readers (and the watchers of <em>A Game of Thrones</em>), <em>A Song of Ice and Fire</em> will be their primary exposure to the idea of the Middle Ages.  This is particularly true because of the reputation that the series has for being ‘<a href="https://acoup.blog/2019/05/28/new-acquisitions-not-how-it-was-game-of-thrones-and-the-middle-ages-part-i/">how it really was</a>,’ a reputation that George R.R. Martin has consciously cultivated (as with his classic complaint of <a href="https://youtu.be/p-VxvKoDFIw">‘what was Aragorn’s tax policy’</a> – there is a rich irony that, had Martin understood rulership in the Middle Ages better, he would have understood why Aragorn’s tax policy was less important).  Martin has been quite open that he “<a href="https://www.westeros.org/Citadel/SSM/Entry/6040/">draw[s] inspiration from history</a>” and that fact has long been a selling point of the series over more obviously fantastical kinds of medieval-themed high fantasy as well as a <a href="https://ew.com/article/2015/06/03/george-rr-martin-thrones-violence-women/">response to some of the series’ more controversial moments</a>.</p>



<p><strong>Naturally, that cloak of verisimilitude has tended to intensify the degree to which elements of <em>A Song of Ice and Fire</em> is taken by its readers and viewers as representative of the Middle Ages more generally.</strong>  And of course as I have noted in the (quite recent) past,<strong> <a href="https://acoup.blog/2020/11/20/miscellanea-my-thoughts-on-assassins-creed-valhalla/">fiction is often how the public conceptualizes the past and that concept of the past shapes the decisions we make in the present</a></strong>.  In the case of <em>A Song of Ice and Fire</em> in particular, this vision of the past is <a href="https://acoup.blog/2019/06/12/new-acquisitions-how-it-wasnt-game-of-thrones-and-the-middle-ages-part-iii/">particularly worth interrogating</a> because it serves as the basis for a<a href="https://youtu.be/ek2O6bVAIQQ"> parable on power and violence</a>.</p>



<p>But <em>even if it didn’t</em>, it would still be worth discussing these aspects of the universe of <em>A Song of Ice and Fire</em>, because that is what we are supposed to do with cultural products, with <em>literature</em>.  <strong>I am sometimes baffled that the very fans who insist that their particular loves be treated seriously, as <em>art</em> are the same fans who react with frustration if one then sets out to interrogate those same genres the way one would interrogate serious art or literature</strong>.  This is it, after all!  This is what you (we, really) wanted!  A (quite unimpressive, I’ll grant you) ivory tower academic is taking this genre seriously and subjecting it to serious criticism!  Isn’t that what emerging genres often hope for, to be taken seriously as ‘high’ literature?</p>



<p><strong>And of course we should take it seriously.</strong>  And here I want to speak briefly to the purpose of these sorts of endeavors, <strong>because the goal here is not to force anyone to dislike <em>A Song of Ice and Fire</em></strong>.   We’re not here to ‘cancel’ <em>ASOIF</em> any more than we were going to ‘cancel’ <a href="https://acoup.blog/2020/11/20/miscellanea-my-thoughts-on-assassins-creed-valhalla/"><em>AC:Valhalla</em> two weeks ago</a> (a game I continue to play, I might add).  Instead, discussing cultural products like this is a form of inoculation against their potentially negative aspects, because once a reader knows that, for instance, the depiction of a given culture in a work of fiction has relatively little to do with any real world culture, they can compartmentalize that to the fiction itself; <strong>it loses its power to mislead</strong> <strong>and so may be enjoyed in safety, as it were</strong>.  And there are good things in <em>A Song of Ice and Fire</em> and in the first six or so seasons of <em>Game of Thrones</em>; but we also need to be honest about the failings.</p>



<p>(Of course, more broadly, doing this as a practice exercise is a key part of building up that skill – what we may term ‘critical reading’ – more generally, rendering the alert reader more resistant to this sort of thing, both in its unintended form (as, I suspect, in this case) or  in its more dangerous<em> intended form</em>.  Put another way, developing critical reading skills is one important way to make one’s self a harder target for misinformation, including historical misinformation.)</p>



<h2>A Dash of Pure Fantasy</h2>



<p>Alright, so <em>A Song of Ice and Fire</em> is worth looking at closely.  So why <em>this</em> part of the fiction?  It comes down to something <a href="https://www.westeros.org/Citadel/SSM/Entry/6040/">George R.R. Martin wrote</a>:</p>



<blockquote><p>The Dothraki were actually fashioned as an amalgam of a number of steppe and plains cultures… Mongols and Huns, certainly, but also …</p></blockquote></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://acoup.blog/2020/12/04/collections-that-dothraki-horde-part-i-barbarian-couture/">https://acoup.blog/2020/12/04/collections-that-dothraki-horde-part-i-barbarian-couture/</a></em></p>]]>
            </description>
            <link>https://acoup.blog/2020/12/04/collections-that-dothraki-horde-part-i-barbarian-couture/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25299176</guid>
            <pubDate>Fri, 04 Dec 2020 05:05:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[PixelNeRF Neural Radiance Fields from One or Few Images]]>
            </title>
            <description>
<![CDATA[
Score 210 | Comments 55 (<a href="https://news.ycombinator.com/item?id=25298426">thread link</a>) | @choppaface
<br/>
December 3, 2020 | https://alexyu.net/pixelnerf/ | <a href="https://web.archive.org/web/*/https://alexyu.net/pixelnerf/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <p id="paper-title">
            
            <h3>
                Neural Radiance Fields from One or Few Images
            </h3>
            <h3>
                <small title="Note: This is a joke">IEEE International Conference on Neural Radiance Fields (ICNeRF)</small>
            </h3>
        </p>

        
        
        <div>
            <div>
                <div id="dynamic-teaser">
                     <!-- row -->

                     <!-- row -->
                    <div id="teaser-dtu">
                        <div>
                            <p>3 Input Views</p>
                            
                            <p><strong>pixelNeRF</strong></p>
                            <p>3-view NeRF</p>
                        </div>
                        <div>
                            <p><img src="https://alexyu.net/pixelnerf/img/teaser/dtu_inputs.jpg">
                            </p>
                            
                            <p><img src="https://alexyu.net/pixelnerf/img/teaser/dtu_outputs_sm.gif">
                            </p>
                        </div> <!-- row -->
                    </div>
                </div> <!-- dynamic-teaser -->
                <!-- <img id="teaser" src="img/teaser.png" class="img-responsive" alt="teaser figure"> -->
                <p>
                    We propose pixelNeRF, a learning framework that predicts a continuous neural scene representation conditioned on
                    one or few input images.
                    The existing approach for
                    constructing neural radiance fields&nbsp;<a href="https://www.matthewtancik.com/nerf">[Mildenhall et al. 2020]</a>
                    involves optimizing the representation to every scene independently, requiring many calibrated views and significant compute time.
                    We take a step towards resolving these shortcomings
                    by introducing an architecture that conditions a NeRF on image inputs in a fully convolutional manner. This allows the network to be trained across multiple scenes to learn a scene prior, enabling it to perform novel view synthesis in a feed-forward manner from a sparse set of views (as few as one).
                </p>

            </div>
        </div>
        <div id="overview-video">
            <div>
                <h4>Narrated Overview</h4>
                <p>
                    <iframe src="https://www.youtube.com/embed/voebZx7f32g" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
                </p>
            </div>
        </div>
        <div>
            <div>
                <p>
                    Leveraging the volume rendering approach of NeRF, our model can be trained directly from images with no explicit 3D supervision.
                    We conduct extensive experiments on ShapeNet benchmarks for single image novel view synthesis tasks with held-out objects as well as entire unseen categories.
                    We further demonstrate the flexibility of pixelNeRF by demonstrating it on multi-object ShapeNet scenes and real scenes from the DTU dataset. In all cases, pixelNeRF outperforms current state-of-the-art baselines for novel view synthesis and single image 3D reconstruction.
                </p>
                <p><img src="https://alexyu.net/pixelnerf/img/pipeline.png" alt="pipeline">
            </p></div>
        </div>
        <div>
            <div>
                <h4>Feed-forward NeRF from One View</h4>
                <p>
                    Using multiview image supervision, we train a single pixelNeRF to 13 largest object categories
                    in ShapeNet in order to perform novel-view synthesis on unseen objects.
                    Our approach operates in <strong>view-space</strong>—as opposed to canonical—and requires <strong>no test-time optimization</strong>.
                    Nevertheless, in terms of image metrics, we significantly outperform existing methods quantitatively, as shown in the paper.
                </p>
                <div>
                    <div>
                        <div>
                            <p>Input</p>
                            <p>SoftRas</p>
                            <p>DVR</p>
                            <p>SRN</p>
                            <p><strong>pixelNeRF</strong></p>
                            <p>GT</p>
                        </div>
                        <p><img src="https://alexyu.net/pixelnerf/img/gif/shapenet_000.gif" alt="shapenet results animated">
                    </p></div>
                    <div>
                        <div>
                            <p>Input</p>
                            <p>SoftRas</p>
                            <p>DVR</p>
                            <p>SRN</p>
                            <p><strong>pixelNeRF</strong></p>
                            <p>GT</p>
                        </div>
                        <p><img src="https://alexyu.net/pixelnerf/img/gif/shapenet_001.gif" alt="shapenet results animated">
                    </p></div>
                </div>
            </div>
        </div>
        <div>
            <div>
                <h4>Scene-level Representation</h4>
                <p>
                    Since our method requires <strong>neither canonical space nor object-level information such as masks</strong>,
                    it can represent scenes with multiple objects, where a canonical space is unavailable,
                    without modification.
                    Our method can also <strong>seemlessly integrate multiple views</strong> at test-time to obtain better results.
                    SRN performs extremely poorly here due to the lack of a consistent canonical space.
                </p>
                <div>
                    <div>
                        <div>
                            <p>2 Input Views</p>
                            <p>SRN</p>
                            <p><strong>pixelNeRF</strong></p>
                        </div>
                        <div>
                            <p><img src="https://alexyu.net/pixelnerf/img/gif/two_000_input.jpg" alt="two object input">
                            </p>
                            <p><img src="https://alexyu.net/pixelnerf/img/gif/two_000_sm.gif" alt="two object results animated">
                            </p>
                        </div>
                    </div>
                    <div>
                        <div>
                            
                            <p>1 Input View</p>
                            <p>SRN</p>
                            <p><strong>pixelNeRF</strong></p>
                        </div>
                        <div>
                            <p><img src="https://alexyu.net/pixelnerf/img/gif/two_001_input.jpg" alt="two object input">
                            </p>
                            <p><img src="https://alexyu.net/pixelnerf/img/gif/two_001_sm.gif" alt="two object results animated">
                            </p>
                        </div>
                    </div>
                </div>
            </div>
        </div>
        <div>
            <div>
                <h4>Real-world Scenes</h4>
                <p>
                    We show that our method can also conduct wide-baseline view synthesis on more complex real scenes from the <a href="http://roboimagedata.compute.dtu.dk/?page_id=36">DTU MVS</a> dataset,
                    producing reasonable results when given only 1-3 views at inference time.
                    Moreover, it is feed-forward without requiring test-time optimization for each scene.
                </p>
                <div>
                    
                    <div>
                        <p><img src="https://alexyu.net/pixelnerf/img/gif/dtu_inputs.jpg" alt="DTU 3 input images">
                        </p>
                        <p><img src="https://alexyu.net/pixelnerf/img/gif/dtu.gif" alt="DTU results animated">
                        </p>
                    </div>
                </div>
            </div>
        </div>
        <div>
            <div>
                <h4>Generalization</h4>
                <p>
                    To demonstrate generalization capabilities,
                    we apply a model trained on ShapeNet planes, cars, and chairs to unseen ShapeNet categories.
                </p>
                <div>
                    <div>
                        <div>
                            <p>Input</p>
                            <p>DVR</p>
                            <p>SRN</p>
                            <p><strong>pixelNeRF</strong></p>
                            <p>GT</p>
                        </div>
                        <p><img src="https://alexyu.net/pixelnerf/img/gif/gen_000.gif" alt="shapenet unseen category results animated">
                    </p></div>
                    <div>
                        <div>
                            <p>Input</p>
                            <p>DVR</p>
                            <p>SRN</p>
                            <p><strong>pixelNeRF</strong></p>
                            <p>GT</p>
                        </div>
                        <p><img src="https://alexyu.net/pixelnerf/img/gif/gen_001.gif" alt="shapenet unseen category results animated">
                    </p></div>
                </div>
                <p>
                    Separately, we apply a pretrained model on real car images after background removal.
                </p>
                
                
            </div>
        </div>
        <div>
            <div>
                <h4>Related Links</h4>
                <ul>
                    <li>
                        NeRF was introduced in <a href="https://www.matthewtancik.com/nerf">Mildenhall et al. (2020)</a>
                    </li><li>
                        Local image features were used in the related regime of implicit surfaces in
                        <a href="https://shunsukesaito.github.io/PIFu/">Saito et al. (2019)</a>
                        and
                        <a href="https://arxiv.org/abs/1905.10711">Xu et al. (2019)</a>
                    </li><li>
                        Our MLP architecture is
                        inspired by
                        <a href="https://avg.is.tuebingen.mpg.de/publications/niemeyer2020cvpr">DVR</a>
                    </li><li>
                        Parts of our
                        PyTorch NeRF implementation are taken from
                        <a href="https://github.com/kwea123/nerf_pl">kwea123</a>
                    </li><li>
                        Also see the concurrent work
                        <a href="https://arxiv.org/abs/2010.04595">GRF</a>
                        which also introduces image features for NeRF, showing image features can even improve NeRF when a large number of views are available.
                </li></ul>
            </div>
        </div>
        
        <div>
            <div>
                <h4>Acknowledgements</h4>
                <p>
                    We thank Shubham Goel and Hang Gao for comments on the text. We also thank
                    Emilien Dupont and Vincent Sitzmann for helpful discussions.
                    This website is inspired by the template of <a href="http://mgharbi.com/">Michaël Gharbi</a>.
                </p>
                <p>
                    Please send any questions or comments to <a href="https://alexyu.net/">Alex Yu</a>.
                </p>
            </div>
        </div>
    </div></div>]]>
            </description>
            <link>https://alexyu.net/pixelnerf/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25298426</guid>
            <pubDate>Fri, 04 Dec 2020 03:01:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A terminal-based workflow for research, writing, and programming]]>
            </title>
            <description>
<![CDATA[
Score 271 | Comments 121 (<a href="https://news.ycombinator.com/item?id=25297268">thread link</a>) | @jerodsanto
<br/>
December 3, 2020 | http://jacobzelko.com/workflow/ | <a href="https://web.archive.org/web/*/http://jacobzelko.com/workflow/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
          <p><em>My personal workflow for terminal-based coding, writing, research, and more!</em></p>

<p>Hello everyone!
It has been quite sometime since I last posted!
Suffice it to say, I have been immensely busy the past year but I am happy to say I am able to resurrect this blog! <img title=":tada:" alt=":tada:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f389.png" height="20" width="20"></p>

<p>I have thoroughly grown into my own workflow for programming, research, and writing.
Today, I am happy to be able to share it with you!</p>

<p>If you prefer to watch a video describing most of this entire process, here is an overview of my workflow from one of my <a href="https://www.twitch.tv/thecedarprince">live streams</a>.
It does not go as in-depth as this document but should serve as a strong complement to this post. <img title=":smile:" alt=":smile:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f604.png" height="20" width="20"></p>

<p><a href="https://youtu.be/2SLZQQfMF8E"><img src="http://jacobzelko.com/assets/workflow_youtube_vid.jpg" alt=""></a></p>



<p>I use <a href="https://github.com/alacritty/alacritty">Alacritty</a> as my terminal, <a href="https://www.zsh.org/">zsh</a> and <a href="https://ohmyz.sh/">oh-my-zsh</a> as my shell and plugin manager respectively, <a href="https://github.com/tmux/tmux">tmux</a> as my multiplexer, <a href="https://github.com/Peltoche/lsd">lsd</a> as my list command with fun icons, <a href="https://github.com/belluzj/fantasque-sans">Fantasque Sans Mono</a> as my typeface font, <a href="https://github.com/neovim/neovim">neovim</a> for my editor, <a href="https://github.com/junegunn/fzf">fzf</a> paired with <a href="https://github.com/BurntSushi/ripgrep">ripgrep</a> for speedy and interactive file finding, <a href="https://github.com/sharkdp/bat">bat</a> an enhanced <code>cat</code> with a git diff gutter, <a href="https://github.com/jgm/pandoc">pandoc</a> for writing in markdown and LaTeX and outputting the piece to whatever file type I want, <a href="http://jacobzelko.com/setting-up-zotero/">Zotero</a> for managing my collection on scientific literature, <a href="https://github.com/ranger/ranger">ranger</a> as a terminal-based file explorer, and <a href="https://github.com/morhetz/gruvbox-contrib">gruvbox-dark</a> as my general color palette.</p>

<p>Here are gists to the relevant config files I use to modify my interface and user experience:</p>

<ul>
  <li>
<strong>neovim</strong>: <a href="https://gist.github.com/TheCedarPrince/7b9b51af4c146880f17c39407815b594">init.vim</a>
</li>
  <li>
<strong>Alacritty</strong>: <a href="https://gist.github.com/TheCedarPrince/7743091bd8743a7568b718f30bf707c2">.alacritty.yml</a>
</li>
  <li>
<strong>tmux</strong>: <a href="https://gist.github.com/TheCedarPrince/07f6f8f79b1451ec436ff8dee236ccdd">.tmux.conf</a>
</li>
  <li>
<strong>zsh</strong>: <a href="https://gist.github.com/TheCedarPrince/77afe2674803d965a0f5abd108337040">.zshrc</a>
</li>
</ul>

<p>Here is a picture of what that looks like altogether:</p>

<p><img src="http://jacobzelko.com/assets/workflow_layout.png" alt=""></p>

<h2 id="my-workflow-in-action-boom">My Workflow in Action <img title=":boom:" alt=":boom:" src="https://github.githubassets.com/images/icons/emoji/unicode/1f4a5.png" height="20" width="20">
</h2>

<p>The following sections describe in broad strokes my workflow.
I mention some plugins that I use and are provided in my config files.
If you want to learn more about them, I encourage you to read through my config files or search for them.</p>

<h3 id="floating-terminals">Floating Terminals</h3>

<p><img src="http://jacobzelko.com/assets/float_term.gif" alt=""></p>

<p>Floating terminals are immensely powerful and I love them!
This enables me to quickly pull up a terminal and do some changes without having to split tmux panes or get out of vim.
Furthermore, what is awesome is that you can use it as a sort of <code>vim-slime</code> tool to send lines of code to the floating terminal.
This is a great feature as it uses your last used floating terminal for its target - therefore, if you switch between projects a lot, just switch your floating terminal accordingly.
No need to keep opening and closing REPL sessions and such!</p>

<h3 id="persistent-working-sessions-via-tmux">Persistent Working Sessions via tmux</h3>

<p><img src="http://jacobzelko.com/assets/tmux_restore.gif" alt=""></p>

<p>Though it is a little hard to see, I closed my terminal completely.
Oh no!
All my paneling and windows have disappeared! 
I’ll have to spend valuable time getting my workflow set back up… Or do I?</p>

<p>tmux can actually remember all these layouts with the plugins, <code>resurrect</code> and <code>continuum</code>. 
This is great for when your computer unexpectedly dies or crashes as everything is backed up at regular intervals you define!
Furthermore, pairing the (neo)vim plugin, <code>obsession</code>, allows tmux to also automatically recover vim layouts and sessions as well.
You will never have to worry about losing your terminal workflow again!</p>

<h3 id="mouse-mode">Mouse Mode</h3>

<p><img src="http://jacobzelko.com/assets/mouse_mode.gif" alt=""></p>

<p>tmux and (neo)vim also support mouse mode and interactivity!
I can quickly jump all over the place with my mouse or easily resize any opened pane.</p>

<h3 id="interactive-file-finding">Interactive File Finding</h3>

<p><img src="http://jacobzelko.com/assets/vim_fzf.gif" alt=""></p>

<p>I integrated the powerful file finding tool, <code>fzf</code>, with <code>ripgrep</code> to quickly find files I am looking to use. 
Then, in my (neo)vim configuration file, I merged these two together into one function that I can easily call while editing files in (neo)vim. 
find files I search for and pandoc to enable citations in pandoc, markdown, or TeX files.</p>

<h3 id="terminal-based-file-explorer">Terminal-Based File Explorer</h3>

<p><img src="http://jacobzelko.com/assets/ranger_mode.gif" alt=""></p>

<p>Furthermore, I also use the great tool, <code>ranger</code>, which allows me to have a terminal based file explorer.
It’s nice as it pops up in its own window and does not actually directly interfere with any of the background files being edited. 
It even has image preview capabilities!</p>

<h3 id="citation-engine--live-preview">Citation Engine &amp; Live Preview</h3>

<p><img src="http://jacobzelko.com/assets/citation_mode.gif" alt=""></p>

<p>As a researcher, this part gets me immensely excited!
While I am writing, I can actively insert citation keys into whatever I am working on via <code>vim-pandoc</code>.
With my config file, you will have to specify where your own .bib file exists.
Furthermore, <code>markdown-preview</code> allows me to preview my markdown in a web browser and <code>vim-latex-live-preview</code> allows me to view my current TeX files in a pdf viewer – works for subfiles too! 
This works for whenever I write TeX files or markdown files which makes writing a breeze!</p>

<p>If any of this section is confusing, I strongly encourage you to read my article on <a href="http://jacobzelko.com/personal-research-management/">Knowledge Management</a>.</p>



<p>These are parts of my workflow that I used to use.
They have been retired for a variety of reasons but all in an effort to improve my workflow.
I have kept these around in case anyone finds it useful!</p>

<h3 id="vim-slime-for-rapid-evaluation">Vim-Slime for Rapid Evaluation</h3>

<p><strong>Rationale for deprecation:</strong> I used to use <code>vim-slime</code> but deprecated it from my workflow because of the flexibility of floating terminals.
Not only could I use floating terminals to send code, I could also quickly flip through terminals in one button press.</p>

<p><img src="http://jacobzelko.com/assets/vim_slime.gif" alt=""></p>

<p>Here, I target my Julia REPL in a tmux panel and use the <code>vim-slime</code> plugin to send code from my Julia script opened in neovim to the Julia REPL for rapid evaluation. 
This config works for any time you want to target a window.
This also works for code chunks such as functions or loops!</p>

<h2 id="conclusion">Conclusion</h2>

<p>I hope you found my workflow and toolchain interesting!
My dream would be for this workflow to serve as inspiration for your own workflow.
Make it your own and all the best!</p>

<p><em>If you spot any errors or have any questions, feel free to <a href="http://jacobzelko.com/contact/">contact me</a> about them!</em></p>

<hr>

        </div></div>]]>
            </description>
            <link>http://jacobzelko.com/workflow/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25297268</guid>
            <pubDate>Fri, 04 Dec 2020 00:05:02 GMT</pubDate>
        </item>
    </channel>
</rss>
