<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 20]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 20. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Tue, 22 Dec 2020 17:02:47 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-20.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Tue, 22 Dec 2020 17:02:47 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[Show HN: A TO-DO app that fits inside a single tweet]]>
            </title>
            <description>
<![CDATA[
Score 31 | Comments 30 (<a href="https://news.ycombinator.com/item?id=25492302">thread link</a>) | @rukshn
<br/>
December 20, 2020 | https://ruky.me/2020/12/21/a-to-do-app-that-fits-in-a-single-tweet/ | <a href="https://web.archive.org/web/*/https://ruky.me/2020/12/21/a-to-do-app-that-fits-in-a-single-tweet/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-59">

<div>
<p>Sunday morning while I was scrolling through my Twitter feed one tweet caught my eye,</p>
<blockquote data-width="550" data-dnt="true"><div lang="en" dir="ltr"><p><a href="https://twitter.com/hashtag/JavaScript?src=hash&amp;ref_src=twsrc%5Etfw">#JavaScript</a> Challenge:</p><p>Can you make a TO-DO app within a single Tweet? (280 chars)</p><p>The app should be able to add tasks, strike-through finished tasks &amp; clear all tasks.</p><p>Any general-purpose library is allowed.<br>Starting HTML body should be empty except the &lt;script&gt;.<a href="https://twitter.com/hashtag/JS?src=hash&amp;ref_src=twsrc%5Etfw">#JS</a> <a href="https://twitter.com/hashtag/code?src=hash&amp;ref_src=twsrc%5Etfw">#code</a></p></div>‚Äî Dumi (@dumindaxsb) <a href="https://twitter.com/dumindaxsb/status/1340539549890404354?ref_src=twsrc%5Etfw">December 20, 2020</a></blockquote>
<p>The challenge was to make a todo app that fits in a single tweet, just like any other todo app, you should be able to add or remove tasks and clear the task list. I thought how hard this can get, I thought to myself this is doable just by using plain JavaScript.</p>
<p>So since I don‚Äôt have a laptop, what resulted was a whole day of torture having to code though my iPad on codepen.</p>
<h2><strong>Plain JavaScript</strong> </h2>
<p>Soon after I started using plain JavaScript it became obvious that I was not able to make it within one tweet, the DOM manipulation was taking too much characters<em>, document.createElements, document.getElements. </em></p>
<p>It was obvious that was not the right approach.</p>
<h2>Using vue</h2>
<p>Vue framework won‚Äôt require any build tools, so I don‚Äôt have to go through setting up Webpack,</p>
<p>Also I can easily create the DOM within the script tag using simple HTML. So that will save some characters for me in DOM manipulation.</p>
<p>The first version I made use the <em>method</em> option in Vue app to handle button clicks, the button click event will call the function in methods to add new tasks and clear the task list.</p>
<p>However, I was unable to reduce it to one tweet. Then I went back to in-line functions, the same methods were added to button click events inline and not within the <em>methods</em> section.</p>
<p>Also I had to change buttons to anchor tags, in order to save some characters, and I had to use emojis instead of button text to save some more characters.</p>
<p>I also had to drop few buttons like a button to add a task, and instead I had to go with pressing enter key to add a task instead.</p>
<p>So I made the final version, the JavaScript code looked like this, </p>
<p data-height="300" data-theme-id="dark" data-default-tab="js" data-user="rukshn" data-slug-hash="qBaXmpE" data-pen-title="qBaXmpE">
<span>See the Pen <a href="https://codepen.io/rukshn/pen/qBaXmpE">
qBaXmpE</a> by Rukshan Ranatunge (<a href="https://codepen.io/rukshn">@rukshn</a>)
on <a href="https://codepen.io/">CodePen</a>.</span>
</p>

<p>Then I ran the code through an online JavaScript minifier and then the whole HTML though an HTML minifier, and ended up with this piece of code,</p>
<pre><code>&lt;body&gt;&lt;script src=https://unpkg.com/<a href="https://ruky.me/cdn-cgi/l/email-protection" data-cfemail="a6d0d3c3e6c8c3ded2">[email&nbsp;protected]</a>&gt;&lt;/script&gt;&lt;script&gt;var x={data:()=&gt;({t:[],k:""}),template:'&lt;input @keyup.enter="t.push(k)" v-model="k"&gt;&lt;a @click="t=[]"&gt;‚ùé&lt;/a&gt;&lt;p v-for="(v,i) in t"&gt;&lt;a @click="t.splice(i,1)"&gt;üÖæÔ∏è&lt;/a&gt;{{v}}&lt;/p&gt;'};Vue.createApp(x).mount("body")&lt;/script&gt;</code></pre>
<p>With my fingers crossed, I copied the code on to Twitter, and guess what it fits perfectly inside a single Tweet.</p>
<blockquote data-width="550" data-dnt="true"><p lang="en" dir="ltr">&lt;body&gt;&lt;script src=<a href="https://t.co/FY9eWOxLgZ">https://t.co/FY9eWOxLgZ</a>&gt;&lt;/script&gt;&lt;script&gt;var x={data:()=&gt;({t:[],k:""}),template:'&lt;input <a href="https://twitter.com/keyup?ref_src=twsrc%5Etfw">@keyup</a>.enter="t.push(k)" v-model="k"&gt;&lt;a <a href="https://twitter.com/Click?ref_src=twsrc%5Etfw">@click</a>="t=[]"&gt;‚ùé&lt;/a&gt;&lt;p v-for="(v,i) in t"&gt;&lt;a <a href="https://twitter.com/Click?ref_src=twsrc%5Etfw">@click</a>="t.splice(i,1)"&gt;üÖæÔ∏è&lt;/a&gt;{{v}}&lt;/p&gt;'};Vue.createApp(x).mount("body")&lt;/script&gt;</p>‚Äî Rukshan (@JustRuky) <a href="https://twitter.com/JustRuky/status/1340862545322762240?ref_src=twsrc%5Etfw">December 21, 2020</a></blockquote>
<p>And here is the code in action, <a href="https://jsbin.com/venihiliha/1/edit?html,output">link</a> </p>
<p data-height="265" data-theme-id="dark" data-default-tab="result" data-user="rukshn" data-slug-hash="qBaXmpE" data-pen-title="qBaXmpE">
<span>See the Pen <a href="https://codepen.io/rukshn/pen/qBaXmpE">
qBaXmpE</a> by Rukshan Ranatunge (<a href="https://codepen.io/rukshn">@rukshn</a>)
on <a href="https://codepen.io/">CodePen</a>.</span>
</p>

<h2>What I failed to achieve </h2>
<p>The original Tweet says, that the completed tasks should have a strike through.</p>
<p>But because css was costing me too much characters I had to fall back to remove completed tasks instead, but I‚Äôm sure someone will figure a solution for that as well.</p>
<p>At the same time, I think you can save even more characters by using <a href="https://mithril.js.org/">mithril</a>, because you have short-codes for DOM elements as well, but I haven‚Äôt tried mithril in awhile.</p>
<h4>One last thing</h4>
<p>No I didn‚Äôt waste my whole Sunday on this problem, but I had to spend few hours, thinking and trying different versions. </p>
<p>I would have cut back some more time if I had a laptop. Somerimes I feel like buying an old laptop and refurbishing it and installing Ubuntu on it.</p>
<p>Sunday well spent? Absolutely yes.</p>
<h2>Best answer?</h2>
<p>One thing I love about HN is the fact that there are lot of bright minds out there. Since I posted this on HN I knew it was just a matter of time since someone figures this out.</p>
<p>I guess this is the best answer and also ticks all the boxes, well done.</p>
<pre><code> &lt;script&gt;document.write(`&lt;style&gt;:checked+*{text-decoration:line-through}#t{display:none}&lt;/style&gt;&lt;p id="t"&gt;&lt;input type="checkbox"&gt;&lt;input&gt;&lt;div id="f"&gt;&lt;/div&gt;&lt;p&gt;&lt;button onclick="f.appendChild(t.cloneNode(true)).id=''"&gt;+&lt;/button&gt;&lt;button onclick="f.innerHTML=''"&gt;√ó&lt;/button&gt;`)&lt;/script&gt;</code></pre>
<p><strong>HN link to this answer</strong>: https://news.ycombinator.com/item?id=25493533</p>
<p><strong>Original thread on HN</strong>: https://news.ycombinator.com/item?id=25492302</p>
</div>

</article></div>]]>
            </description>
            <link>https://ruky.me/2020/12/21/a-to-do-app-that-fits-in-a-single-tweet/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25492302</guid>
            <pubDate>Mon, 21 Dec 2020 05:12:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Unix Recovery Legend (1986)]]>
            </title>
            <description>
<![CDATA[
Score 117 | Comments 46 (<a href="https://news.ycombinator.com/item?id=25491790">thread link</a>) | @signa11
<br/>
December 20, 2020 | https://www.ee.ryerson.ca/~elf/hack/recovery.html | <a href="https://web.archive.org/web/*/https://www.ee.ryerson.ca/~elf/hack/recovery.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">

<h4>This classic article from Mario Wolczko first
appeared on Usenet in 1986.  </h4>

Have you ever left your terminal logged in, only to find when you
came back to it that a (supposed) friend had typed "<kbd>rm -rf
~/*</kbd>" and was hovering over the keyboard with threats along the
lines of "<em>lend me a fiver 'til Thursday, or I hit return</em>"?
Undoubtedly the person in question would not have had the nerve to
inflict such a trauma upon you, and was doing it in jest.  So you've
probably never experienced the worst of such disasters....<p>


It was a quiet Wednesday afternoon.  Wednesday, 1st October, 15:15
BST, to be precise, when Peter, an office-mate of mine, leaned away
from his terminal and said to me, "<em>Mario, I'm having a little
trouble sending mail.</em>" Knowing that msg was capable of confusing
even the most capable of people, I sauntered over to his terminal to
see what was wrong.  A strange error message of the form (I forget
the exact details) "<kbd>cannot access /foo/bar for userid 147</kbd>"
had been issued by msg.  My first thought was "<em>Who's userid 147?;
the sender of the message, the destination, or what?</em>" So I leant
over to another terminal, already logged in, and typed</p><blockquote>        <kbd>grep 147 /etc/passwd</kbd></blockquote>

<p>only to receive the response</p><blockquote>        <kbd>/etc/passwd: No such file or directory.</kbd></blockquote>

Instantly, I guessed that something was amiss.  This was confirmed
when in response to<blockquote>        <kbd>ls /etc</kbd></blockquote>

<p>I got</p><blockquote>        <kbd>ls: not found.</kbd></blockquote>

I suggested to Peter that it would be a good idea not to try anything
for a while, and went off to find our system manager.<p>

When I arrived at his office, his door was ajar, and within ten
seconds I realised what the problem was.  James, our manager, was
sat down, head in hands, hands between knees, as one whose world has
just come to an end.  Our newly-appointed system programmer, Neil, was
beside him, gazing listlessly at the screen of his terminal.  And at
the top of the screen I spied the following lines:</p><blockquote>
        <kbd># cd <br>
        # rm -rf *</kbd>
</blockquote>

<p>Oh, shit, I thought.  That would just about explain it.</p><p>


I can't remember what happened in the succeeding minutes; my memory
is just a blur.  I do remember trying <kbd>ls</kbd> (again),
<kbd>ps</kbd>, <kbd>who</kbd> and maybe a few other commands beside,
all to no avail.  The next thing I remember was being at my terminal
again (a multi-window graphics terminal), and typing</p><blockquote>
        <kbd>cd /<br>
        echo *</kbd>
</blockquote>
<p>I owe a debt of thanks to David Korn for making <kbd>echo</kbd> a
built-in of his shell; needless to say, <kbd>/bin</kbd>, together
with <kbd>/bin/echo</kbd>, had been deleted.  What transpired in the
next few minutes was that <kbd>/dev</kbd>, <kbd>/etc</kbd> and
<kbd>/lib</kbd> had also gone in their entirety; fortunately Neil had
interrupted <kbd>rm</kbd> while it was somewhere down below
<kbd>/news</kbd>, and <kbd>/tmp</kbd>, <kbd>/usr</kbd> and
<kbd>/users</kbd> were all untouched.</p><p>


Meanwhile James had made for our tape cupboard and had retrieved what
claimed to be a dump tape of the root filesystem, taken four weeks
earlier.  The pressing question was, "<em>How do we recover the
contents of the tape?</em>".  Not only had we lost
<kbd>/etc/restore</kbd>, but all of the device entries for the tape
deck had vanished.  And where does <kbd>mknod</kbd> live?  You
guessed it, <kbd>/etc</kbd>.  How about recovery across Ethernet of
any of this from another VAX?  Well, <kbd>/bin/tar</kbd> had gone,
and thoughtfully the Berkeley people had put <kbd>rcp</kbd> in
<kbd>/bin</kbd> in the 4.3 distribution.  What's more, none of the
Ether stuff wanted to know without <kbd>/etc/hosts</kbd> at least.
We found a version of <kbd>cpio</kbd> in <kbd>/usr/local</kbd>, but
that was unlikely to do us any good without a tape deck.</p><p>


Alternatively, we could get the boot tape out and rebuild the root
filesystem, but neither James nor Neil had done that before, and we
weren't sure that the first thing to happen would be that the whole
disk would be re-formatted, losing all our user files.  (We take dumps
of the user files every Thursday; by Murphy's Law this had to happen
on a Wednesday).  Another solution might be to borrow a disk from
another VAX, boot off that, and tidy up later, but that would have
entailed calling the DEC engineer out, at the very least.  We had a
number of users in the final throes of writing up PhD theses and the
loss of a maybe a weeks' work (not to mention the machine down time)
was unthinkable.</p><p>


So, what to do?  The next idea was to write a program to make a
device descriptor for the tape deck, but we all know where
<kbd>cc</kbd>, <kbd>as</kbd> and <kbd>ld</kbd> live.  Or maybe make
skeletal entries for <kbd>/etc/passwd</kbd>, <kbd>/etc/hosts</kbd>
and so on, so that <kbd>/usr/bin/ftp</kbd> would work.  By sheer
luck, I had a <kbd>gnuemacs</kbd> still running in one of my windows,
which we could use to create <kbd>passwd</kbd>, etc., but the first
step was to create a directory to put them in.  Of course
<kbd>/bin/mkdir</kbd> had gone, and so had <kbd>/bin/mv</kbd>, so we
couldn't rename <kbd>/tmp</kbd> to <kbd>/etc</kbd>.  However, this
looked like a reasonable line of attack.</p><p>


By now we had been joined by Alasdair, our resident UNIX guru, and as
luck would have it, someone who knows VAX assembler.  So our plan
became this: write a program in assembler which would either rename
<kbd>/tmp</kbd> to <kbd>/etc</kbd>, or make <kbd>/etc</kbd>, assemble
it on another VAX, <kbd>uuencode</kbd> it, type in the uuencoded file
using my gnu, <kbd>uudecode</kbd> it (some bright spark had thought
to put <kbd>uudecode</kbd> in <kbd>/usr/bin</kbd>), run it, and hey
presto, it would all be plain sailing from there.  By yet another
miracle of good fortune, the terminal from which the damage had been
done was still <kbd>su</kbd>'d to root (<kbd>su</kbd> is in
<kbd>/bin</kbd>, remember?), so at least we stood a chance of all
this working.</p><p>


Off we set on our merry way, and within only an hour we had managed
to concoct the dozen or so lines of assembler to create
<kbd>/etc</kbd>.  The stripped binary was only 76 bytes long, so we
converted it to hex (slightly more readable than the output of
<kbd>uuencode</kbd>), and typed it in using my editor.  If any of you
ever have the same problem, here's the hex for future reference:</p><blockquote>
   <kbd>070100002c000000000000000000000000000000000000000000000000000000<br>
        0000dd8fff010000dd8f27000000fb02ef07000000fb01ef070000000000bc8f<br>
		8800040000bc012f65746300</kbd>
</blockquote>

<p>

I had a handy program around (doesn't everybody?) for converting
ASCII hex to binary, and the output of <kbd>/usr/bin/sum</kbd>
tallied with our original binary.  But hang on---how do you set
execute permission without <kbd>/bin/chmod</kbd>?  A few seconds
thought (which as usual, lasted a couple of minutes) suggested that
we write the binary on top of an already existing binary, owned by
me...problem solved.

So along we trotted to the terminal with the root login, carefully
remembered to set the umask to 0 (so that I could create files in it
using my gnu), and ran the binary.  So now we had a <kbd>/etc</kbd>,
writable by all.  From there it was but a few easy steps to creating
<kbd>passwd</kbd>, <kbd>hosts</kbd>, <kbd>services</kbd>,
<kbd>protocols</kbd>, (etc), and then <kbd>ftp</kbd> was willing to
play ball.  Then we recovered the contents of <kbd>/bin</kbd> across
the ether (it's amazing how much you come to miss <kbd>ls</kbd> after
just a few, short hours), and selected files from <kbd>/etc</kbd>.
The key file was <kbd>/etc/rrestore</kbd>, with which we recovered
<kbd>/dev</kbd> from the dump tape, and the rest is history.</p><p>


Now, you're asking yourself (as I am), what's the moral of this
story?  Well, for one thing, you must always remember the immortal
words, <strong>DON'T PANIC</strong>.  Our initial reaction was to
reboot the machine and try everything as single user, but it's
unlikely it would have come up without <kbd>/etc/init</kbd> and
<kbd>/bin/sh</kbd>.  Rational thought saved us from this one.</p><p>


The next thing to remember is that UNIX tools really can be put to
unusual purposes.  Even without my <kbd>gnuemacs</kbd>, we could have
survived by using, say, <kbd>/usr/bin/grep</kbd> as a substitute for
<kbd>/bin/cat</kbd>.</p><p>


And the final thing is, it's amazing how much of the system you can
delete without it falling apart completely.  Apart from the fact that
nobody could login (<kbd>/bin/login</kbd>?), and most of the useful
commands had gone, everything else seemed normal.  Of course, some
things can't stand life without say <kbd>/etc/termcap</kbd>, or
<kbd>/dev/kmem</kbd>, or <kbd>/etc/utmp</kbd>, but by and large it
all hangs together.</p><p>


I shall leave you with this question: if you were placed in the same
situation, and had the presence of mind that always comes with
hindsight, could you have got out of it in a simpler or easier way?
Answers on a postage stamp to:</p><pre>Mario Wolczko
------------------------------------------------------------------------
Dept. of Computer Science       ARPA:   miw%uk.ac.man.cs.ux@cs.ucl.ac.uk
The University                  USENET: mcvax!ukc!man.cs.ux!miw
Manchester M13 9PL              JANET:  miw@uk.ac.man.cs.ux
U.K.                            061-273 7121 x 5699
------------------------------------------------------------------------
</pre>

<hr>

<address><a href="https://www.ee.ryerson.ca/~elf/hack/index.html">Hacker's Wisdom</a>: Unix Recovery
Legend</address>

<!-- hhmts start -->
Last modified: Thu Mar  7 13:47:40 EST 1996
<!-- hhmts end --></div>]]>
            </description>
            <link>https://www.ee.ryerson.ca/~elf/hack/recovery.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25491790</guid>
            <pubDate>Mon, 21 Dec 2020 03:11:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Russian Covid vaccine scientist dead w stab wounds after falling from 14th floor]]>
            </title>
            <description>
<![CDATA[
Score 30 | Comments 4 (<a href="https://news.ycombinator.com/item?id=25491576">thread link</a>) | @bookofjoe
<br/>
December 20, 2020 | https://www.thesun.ie/news/6309990/russian-scientist-covid-vaccine-dead-stab-wounds/ | <a href="https://web.archive.org/web/*/https://www.thesun.ie/news/6309990/russian-scientist-covid-vaccine-dead-stab-wounds/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://www.thesun.ie/news/6309990/russian-scientist-covid-vaccine-dead-stab-wounds/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25491576</guid>
            <pubDate>Mon, 21 Dec 2020 02:30:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Cakelisp: A Programming Language for Games]]>
            </title>
            <description>
<![CDATA[
Score 119 | Comments 33 (<a href="https://news.ycombinator.com/item?id=25491568">thread link</a>) | @makuto
<br/>
December 20, 2020 | https://macoy.me/blog/programming/CakelispIntro | <a href="https://web.archive.org/web/*/https://macoy.me/blog/programming/CakelispIntro">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
<p><em>Update:</em> See the <a href="https://news.ycombinator.com/item?id=25491568">Hacker News thread</a>, <a href="https://www.reddit.com/r/programming/comments/kh6ox0/cakelisp_a_programming_language_for_games/">/r/programming</a>, <a href="https://www.reddit.com/r/ProgrammingLanguages/comments/kh6gh2/cakelisp_a_programming_language_for_games/">/r/ProgrammingLanguages</a>, and <a href="https://www.reddit.com/r/gamedev/comments/kh1p0a/cakelisp_a_programming_language_for_games/">/r/gamedev</a> posts for discussions on this article and Cakelisp.</p>
<p>I have been working on a new programming language since the end of August 2020. It is hosted on <a href="https://github.com/makuto/cakelisp/">Github</a>, and mirrored on <a href="https://macoy.me/code/macoy/cakelisp/">my site</a>.</p>
<p>If you want to see a working example first, <a href="https://macoy.me/code/macoy/gamelib/src/branch/master/test/src/VocalGame.cake">VocalGame.cake</a> is a simple audio looper with Ogre 3D graphics and SDL for windowing, input, and audio. This demo supports code hot-reloading and doesn't require an external build system, only Cakelisp. You can also check <a href="https://macoy.me/code/macoy/cakelisp/src/branch/master/runtime/Macros.cake">Macros.cake</a>, which demonstrates some use-cases for compile-time code.</p>
<p>I figured showing non-trivial examples would be much more interesting. It also proves that Cakelisp is working.</p>

<p>Cakelisp is built for me first, but it should appeal to fellow programmers who know what they're doing and want to try a more powerful language.</p>
<p>Cakelisp might be for you if you want‚Ä¶</p>
<ul>
<li><strong>Uncompromised performance</strong></li>
<li><strong>Trust in you, the programmer</strong></li>
<li><strong>Powerful code generation</strong></li>
</ul>
<p>If any of the things in that list don't make sense to you, or you think you're already getting them in language <em>X</em>, then Cakelisp isn't for you, and that's okay! We have different domains and different problems, so it makes some sense to use different languages and methodologies.</p>
<p>While many languages have these features, few have the combination of all three. Lisp has extremely powerful code generation, but makes serious performance compromises. C is great for performance but can require extremely repetitive code writing to accomplish tasks a simple code generator could handle. Rust is fast (well, apart from compilation, which is very important for iterative development to be productive), but doesn't trust the programmer.</p>

<p>My goal is to "have my cake and eat it too", meaning all three of these features in one coherent package. Importantly, there isn't one dominating principle in Cakelisp (no <a href="https://www.youtube.com/watch?v=TH9VCN6UkyQ">Big Idea</a>). I've found that the small things like removing the need for header files, no longer dealing with external build systems, or being able to run Cakelisp files like scripts, end up making a big difference when combined in one package.</p>
<p>It is useful to go over the goals in detail so you can understand my decisions.</p>
<h2 id="uncompromised-performance">Uncompromised performance</h2>
<p>This means no garbage collection, no type boxing/unboxing, etc. Fewer abstractions (besides the ones you create) between you and what the computer is actually doing. Idiomatic usage of the language should result in performance comparable with C (in most cases, it should be identical, because it's only a thin layer on C).</p>
<h2 id="trust-in-you-the-programmer">Trust in you, the programmer</h2>
<p>While languages like Rust offer benefits in terms of security and stability, they cost programmers in terms of productivity. It makes sense to value safety so highly if your code is safety-critical (operating systems, aerospace, automotive, etc.), but it's much less valuable when safety isn't as important (e.g. in games).</p>
<p>In a perfect world all programs would be as robust as space flight software, but in reality, that level of robustness is unnecessary for most programs. It's important to realize that the safety focus is just one way of doing things, not the <em>One True Way</em> or anything.</p>
<h2 id="powerful-code-generation">Powerful code generation</h2>
<p>In my opinion, most languages offer far too little opportunity for the programmer to automate the actual writing of code. This power also relates to trusting in the programmer, because gone wild, the code can become incomprehensible.</p>
<p>The company I work for has what I consider to be a state-of-the-art code generator built for the company's use-case: multi-platform MMOs. It's used very effectively on serialization, RPC, automatic commands, monitoring, automatic documentation, and more.</p>
<p>To give more credence to the use of code generation in games, <a href="https://docs.unrealengine.com/en-US/ProgrammingAndScripting/GameplayArchitecture/index.html">Unreal</a> and <a href="https://www.youtube.com/watch?v=wiJqUWfR90I">Naughty Dog</a> also rely on code generation.</p>
<h2 id="simplify-project-setup-and-management">Simplify project setup and management</h2>
<p>I want to dramatically reduce time wasted on C++ project set-up and "code logistics". This includes setting up build systems, creating header files, adding and managing new C/C++ 3rd party libraries, and other things of that ilk.</p>
<h2 id="gain-more-power">Gain more power!</h2>
<p>Every language has limitations. The lack of straightforward, all-powerful code generation was my primary gripe with C++.</p>
<p>For example, automatically creating function and structure bindings using C++ template metaprogramming is very complex. These are two very useful tools in game development: function bindings for commands, scripting languages, and RPC; structure bindings for serialization or game monitors.</p>
<p>I also wanted features like hot-reloading (being able to load new versions of the code without restarting the program/losing runtime state). Cakelisp made it possible to implement hot-reloading entirely in "user-space", thanks to code modification.</p>
<h2 id="have-my-cake-and-eat-it-too.">"Have my cake and eat it too."</h2>
<p>By this I mean lose little-to-nothing on metrics I care about, which include build time, runtime performance, overall complexity, and various other things. I looked into several languages in my <a href="https://macoy.me/code/macoy/LanguageTests">LanguageTests</a> experiment and found they all had major drawbacks I couldn't accept.</p>
<h2 id="unexpected-freedom">Unexpected freedom</h2>
<p>I did not realize when I started Cakelisp how freeing it felt. All of the sudden, I got to decide what made sense to <em>me</em>, not what made sense to previous language designers.</p>
<h3 id="freedom-in-syntax">Freedom in syntax</h3>
<p>A simple example is type declarations. In C:</p>

<p>The same variable, in Cakelisp:</p>

<p>In my opinion C type declarations are much harder to parse than my explicit type declarations. You need to work backwards from the name to properly interpret the type. The parentheses do add more typing, but they're more clear, machine-parseable, and can be read naturally (e.g. read left to right "pointer to constant character" vs. C's "constant character pointer", which seems worse in my mind).</p>
<p>My form also handles arrays as part of the type: <code>(var my-array ([] 5 int))</code> rather than <code>int myArray[5];</code>, another way it is more consistent, readable, and parsable.</p>
<p>I chose to swap the order of name and type because it places more emphasis on the name. A well-written program will convey more useful information in the name than in the type, so it makes sense to me to have it come first for the reader.</p>
<h3 id="freedom-in-process">Freedom in process</h3>
<p>I also found that having an executable which preprocesses my code exactly how I want it opens the door to a huge amount of awesome features:</p>
<ul>
<li>Compile-time code execution. "Macros" and "Generators" are defined in-line with the rest of your code, making them feel like a natural part of your code. Defining them in-line makes it acceptable to add one-off macros, whereas adding such a thing to an external code generator would quickly become unmaintainable</li>
<li>Build optimization. A recent idea I discovered is automatically creating precompiled headers for large batches of 3rd-party headers. This would be a complex task that would need to be integrated in whatever build system you use, whereas Cakelisp can have it built-in</li>
<li>Other data processing. Compile-time code execution means you can do things like prepare assets, download 3rd-party code, run tests, etc. without having to set up all these additional tools</li>
</ul>

<p>I was inspired by Naughty Dog's use of <a href="https://en.wikipedia.org/wiki/Game_Oriented_Assembly_Lisp">Game Oriented Assembly Lisp</a>, GOOL, and <a href="https://www.youtube.com/watch?v=oSmqbnhHp1c">Racket/Scheme</a> (on their modern titles). I've also taken several ideas from Jonathan Blow's <a href="https://www.youtube.com/user/jblow888">talks on Jai</a>.</p>
<p>I'm a software engineer in the game industry. I've been working since July 2015 at a studio that makes cross-platform MMOs. The company has a custom engine written in C (with some C++).</p>
<p>I <a href="https://macoy.me/code/macoy/LanguageTests">experimented</a> with other languages before deciding I needed to write my own.</p>

<p>Now that my goals are clear, I will show you how I approached achieving them.</p>
<h2 id="notation">Notation</h2>
<p>Cakelisp uses an <a href="https://en.wikipedia.org/wiki/S-expression">S-expression</a>-style notation. Here is some Cakelisp code from <a href="https://macoy.me/code/macoy/gamelib/src/branch/master/test/src/VocalGame.cake">VocalGame</a>:</p>

<p>There are a few things you can notice from reading this code:</p>
<ul>
<li>Types. Cakelisp is strongly- and explicitly-typed. I prefer reading code with explicit types because I can better imagine what the computer is actually doing, and what possibilities I have with each variable</li>
<li>Name-type order. I talked about this in a previous section. I wanted to emphasize the name of a variable for conveying meaning, especially when you may have many variables of the same type</li>
<li>Explicit <code>return</code>. I find I prefer code where return points are made explicit. Lisp will implicitly return the result of the last evaluation</li>
<li>Lisp-y style. The parentheses, plus keywords like <code>unless</code>, <code>defun</code>, <code>var</code>, <code>at</code>, and <code>incr</code>. I matched Lisp only when I didn't have strong opinions for a better notation. I am not trying to create something which is compatible with existing Lisps</li>
<li>C types and function calls. Cakelisp has seamless C interop, which means Cakelisp's "standard library" <em>is</em> C's standard library. No bindings had to be written to use the C types or make the function calls</li>
</ul>
<p>You can read more Cakelisp code in <a href="https://macoy.me/code/macoy/gamelib/src/branch/master/src">Gamelib</a>.</p>
<p>You should think of Cakelisp more as "C in S-expressions" rather than "Lisp with C performance". If you know C, you'll have a relatively smooth transition to Cakelisp. If you only know Lisp, you're going to have a rougher time.</p>
<h3 id="why-s-expressions">Why S-expressions?</h3>
<p>When I set out to make Cakelisp, I decided on S-expressions syntax for several reasons:</p>
<ul>
<li>Parsability. S-expressions shift the burden of creating a syntax tree onto the programmer. This does result on more work for the human, but I value its extremely explicit nature. It also facilitates simpler tokenization, domain-specific-language implementation, and external tool support</li>
<li>Consistency. There are only four types of tokens in Cakelisp: open and close parenthesis, symbol, and string. The consistency is admittedly limiting, so things like paths (<code>myThing-&gt;member.member</code>) become much more verbose to type, unfortunately. However, this limitation keeps Cakelisp code parsable, and has an elegant feel that I appreciate</li>
</ul>
<p>I don't believe there is one notation to rule them all, especially after I've encountered the disadvantages of using S-exprs. I'm still happy with the decision though, and it does give Cakelisp a novel and distinguishing characteristic from the many ‚Ä¶</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://macoy.me/blog/programming/CakelispIntro">https://macoy.me/blog/programming/CakelispIntro</a></em></p>]]>
            </description>
            <link>https://macoy.me/blog/programming/CakelispIntro</link>
            <guid isPermaLink="false">hacker-news-small-sites-25491568</guid>
            <pubDate>Mon, 21 Dec 2020 02:28:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[eBPF Is Awesome]]>
            </title>
            <description>
<![CDATA[
Score 195 | Comments 29 (<a href="https://news.ycombinator.com/item?id=25490138">thread link</a>) | @filipn
<br/>
December 20, 2020 | https://filipnikolovski.com/posts/ebpf/ | <a href="https://web.archive.org/web/*/https://filipnikolovski.com/posts/ebpf/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>I was doing some research at work for tracing and observability for microservices, when I came across <a href="https://pixielabs.ai/">Pixielabs</a>. This tool advertises that you can instantly troubleshoot applications without any instrumentation or special code inside the apps, which sounded ‚ú®magical‚ú® to me. So naturally I wanted to know a little more about what enables this technology to work, and after scrolling through the site, under the ‚ÄúNo Instrumentation‚Äù section was this acronym <strong>eBPF</strong>.</p><p>After some further digging on the internet, reading the <a href="https://www.tcpdump.org/papers/bpf-usenix93.pdf">design papers</a> and watching several videos, it was safe to say this technology caught my attention, so I wanted to write some notes on it and I hope this post will spark some further interest in you as well.</p><h2 id="so-what-is-ebpf-exactly">So what is eBPF exactly?</h2><p>The TL;DR version is that this technology enables sandboxed user space applications to run in the Linux kernel itself. In a way it makes the kernel <em>programmable</em> which unlocks tremendous possibilities.</p><p>You can pick <strong>any function</strong> from the kernel and execute the program every time that function runs. Running a program that ‚Äúattaches‚Äù to network sockets, tracepoints and perf events can be extremely useful. Developers can debug the kernel without having to re-compile it. There are plenty of use cases such as:</p><ul><li>Application performance &amp; troubleshooting</li><li>Networking &amp; security</li><li>Runtime security</li><li>Application tracing</li><li>Observability</li></ul><p>That‚Äôs what enables tools like Pixie to do blackbox analysis, without requiring any tinkering inside the applications that we‚Äôre trying to debug.</p><p>Originally BPF was <a href="https://www.tcpdump.org/papers/bpf-usenix93.pdf">designed</a> for capturing and filtering network packets that matched specific rules, discarding any unwanted packets. That‚Äôs why it was called the ‚ÄúBerkeley Packet Filter‚Äù. If you‚Äôve ever used <strong>tcpdump</strong> you‚Äôve probably already used it. Nowadays eBPF can be used for many different things and not just packet filtering but the name stuck for some reason.</p><p>This architecture of network monitoring was vastly superior to the current existing packet capture technologies in terms of performance, mainly because the filtering was done in the kernel instead of copying all of the packets in user space and doing
the calculations there. But with the advancement of processors it didn‚Äôt hold up so well with it‚Äôs initial design. That‚Äôs why the <strong>extended BPF</strong> (eBPF) design was introduced, to take advantage of the modern processing power.</p><p>Initially eBPF was to be also used as a network packet filtering solution, but the ability to run user-space programs inside the kernel proved to be very powerful. The new design extended what the BPF virtual machine could do, which was to allow it to run on all kinds of events, not just packets, and also do certain actions instead of just the ability to filter things.</p><h2 id="how-does-it-work">How does it work?</h2><p>An eBPF program is just a sequence of 64-bit instructions. The virtual machine‚Äôs instruction set is fairly limited and it has two goals in mind:</p><ol><li>The code needs to be executed as fast as possible.</li><li>All BPF instructions must be verifiable at load time to ensure the safety of the kernel.</li></ol><p>Okay so, eBPF code is run in a safe virtual machine inside the kernel. Writing these programs is done with the help of some frameworks (like <a href="https://github.com/iovisor/bcc">bcc</a> and <a href="https://github.com/iovisor/bpftrace">bpftrace</a>) and the program bytecode is then loaded via the <a href="https://man7.org/linux/man-pages/man2/bpf.2.html"><code>bpf</code></a> system call.</p><p>To nullify the security and stability risks when running a user space program inside the kernel, several checks are performed
to ensure that the code we run is safe and that it terminates so our computer won‚Äôt freeze up.</p><p>Firstly, to even be able to run a user program which loads eBPF code, it needs root privileges to do so, unless unprivileged eBPF is enabled, in which case the process can load a program with a reduced functionality. Secondly, there‚Äôs the eBPF verifier which all eBPF programs must go through before they can be executed.</p><p>The verifier runs several checks on the code that safeguards the kernel. The first check ensures that any unbounded
loops which could freeze up the kernel are prohibited. The second check, which is more extensive, simulates the execution of the code making sure that all paths of the code run to completion, no out of bounds memory is accessed and overall the state of the virtual machine is valid.</p><p>The last step of the verification process involves restricting the eBPF program abilities, which kernel functions are callable and which data it can access. The verifier knows how to apply those restrictions because of the <strong>program type</strong>. The program type is determined when we associate the program with a certain event.</p><p>After the verification process is done, the BPF bytecode is then interpreted, or compiled by a JIT compiler, into native instructions that run efficiently whenever an event happens in the kernel.</p><h2 id="kprobes--uprobes">kprobes &amp; uprobes</h2><p>We can create and insert kernel probes or kprobes for short to virtually any function in the kernel, and attach an eBPF program so that it executes each time that function is invoked.</p><p>Here‚Äôs a simple hello world example from the <a href="https://github.com/iovisor/bcc/tree/master/examples">bcc</a> repository:</p><div><pre><code data-lang="python"><span>from</span> bcc <span>import</span> BPF
<span>from</span> bcc.utils <span>import</span> printb
<span># define BPF program</span>
prog <span>=</span> <span>"""
</span><span>int hello(void *ctx) {
</span><span>    bpf_trace_printk("Hello, World!</span><span>\\</span><span>n");
</span><span>    return 0;
</span><span>}
</span><span>"""</span>
<span># load BPF program</span>
b <span>=</span> BPF(text<span>=</span>prog)
b<span>.</span>attach_kprobe(event<span>=</span>b<span>.</span>get_syscall_fnname(<span>"clone"</span>), fn_name<span>=</span><span>"hello"</span>)
<span># header</span>
<span>print</span>(<span>"</span><span>%-18s</span><span> </span><span>%-16s</span><span> </span><span>%-6s</span><span> </span><span>%s</span><span>"</span> <span>%</span> (<span>"TIME(s)"</span>, <span>"COMM"</span>, <span>"PID"</span>, <span>"MESSAGE"</span>))
<span># format output</span>
<span>while</span> <span>1</span>:
    <span>try</span>:
        (task, pid, cpu, flags, ts, msg) <span>=</span> b<span>.</span>trace_fields()
    <span>except</span> <span>ValueError</span>:
        <span>continue</span>
    <span>except</span> <span>KeyboardInterrupt</span>:
        exit()
    printb(<span>b</span><span>"</span><span>%-18.9f</span><span> </span><span>%-16s</span><span> </span><span>%-6d</span><span> </span><span>%s</span><span>"</span> <span>%</span> (ts, task, pid, msg))
</code></pre></div><p>The eBPF program is written in a pseudo-C code and it‚Äôs placed in the variable <code>prog</code> as a string. The bcc framework does all the heavy lifting of generating the bytecode, loading the programs and all that stuff, which makes writing these programs a bit easier.</p><p>In this example, the hello function invokes a bpf helper function called <code>bpf_trace_printk</code> which outputs a ‚ÄúHello, World!‚Äù trace. Then we load the program and we attach a kernel probe for the <a href="https://man7.org/linux/man-pages/man2/clone.2.html"><code>clone</code></a> event, basically saying that we want to call the <code>hello</code> program each time <code>clone</code> is called.</p><p>After that the script waits for new traces to arrive, fetches the fields and prints the values to the screen.</p><p>Let‚Äôs try running it:</p><pre><code>$ sudo python3 hello-ebpf.py
TIME(s)            COMM             PID    MESSAGE
</code></pre><p>The script has successfully loaded the program and now we wait for the traces to arrive. The next thing to do is to try and invoke the <code>clone</code> syscall. We can run any command on the terminal, such as <code>ls</code> and a child process will be created. Since I had firefox running, it created some child processes in the meantime and traces started to show up:</p><pre><code>611.247475000      firefox          5378   Hello, World!
</code></pre><p>As we can see, the message ‚ÄúHello, World!‚Äù is printed on the screen along with the other trace fields. Super cool!</p><p>Besides attaching to kernel functions, we could also observe functions invoked in user space, such as <strong>malloc</strong> or <strong>strlen</strong>. This is possible via another Linux kernel feature - <strong>uprobes</strong>.</p><p>Here‚Äôs an interesting script that counts frequencies of strings by tracing strlen() and using a hash map to store the strings along with the count of their recurrence: <a href="https://github.com/iovisor/bcc/blob/master/examples/tracing/strlen_count.py">https://github.com/iovisor/bcc/blob/master/examples/tracing/strlen_count.py</a></p><h2 id="helper-functions">helper functions</h2><p>Since arbitrary kernel functions are prohibited to be called by ebpf programs, there are several helper functions which the kernel provides for us, such as the <code>bpf_trace_printk</code> function. We can use them to:</p><ul><li>Get the current time</li><li>Interact with eBPF maps</li><li>Manipulate network packets</li><li>Print debugging messages</li></ul><p>Note that each program can only use a subset of these helpers because of the different contexts the programs can run in. Here‚Äôs the extensive <a href="https://man7.org/linux/man-pages/man7/bpf-helpers.7.html">list</a> of bpf helpers.</p><h2 id="map-storage">map storage</h2><p>To write more complicated programs you‚Äôll need some type of data store, and that is where <strong>maps</strong> come in. They are an important part of the BPF internal system, which allows programs to store information that can be accessed from userspace.</p><p>BPF supports different <a href="https://github.com/iovisor/bcc/blob/master/docs/reference_guide.md#maps">types</a> of data stores - you can use a hash map, an array, or even a stack or a queue, depending on the use case of course.</p><h2 id="conclusion">conclusion</h2><p>eBPF opens up all kinds of possibilities for observability. You can treat a system as a blackbox, without really knowing anything about it, and run all kinds of interesting analysis: count the most frequently called functions, trace network packets, do performance tracing and debugging, etc.</p><p>There are a myriad of tools that you can use to observe every component of the system: the CPU, memory, file system, networking, containers, applications‚Ä¶</p><figure><img src="https://d33wubrfki0l68.cloudfront.net/b19abde4b1ccfe4ce140969c8bf44f39d1c2fe70/f9ed3/images/ebpf/bcc_tracing_tools_early2019.png" alt="ebpf-tracing-tools"><figcaption>BCC performance tools (courtesy of Brendan Gregg)</figcaption></figure><p>I‚Äôve only scratched the surface on this subject and I can‚Äôt wait to learn more about it, as well as Linux performance in general. There‚Äôs tons of great posts and videos on this exciting technology, and I‚Äôve left some links below for you. Cheers!</p><h2 id="references">References</h2><ul><li><a href="https://www.tcpdump.org/papers/bpf-usenix93.pdf">https://www.tcpdump.org/papers/bpf-usenix93.pdf</a> ‚Äì BPF paper</li><li><a href="https://lwn.net/Articles/740157/">https://lwn.net/Articles/740157/</a> ‚Äì A thorough introduction to eBPF</li><li><a href="https://www.youtube.com/watch?v=16slh29iN1g">https://www.youtube.com/watch?v=16slh29iN1g</a> ‚Äì interesting talk by Brendan Gregg on BPF performance analysis at Netflix</li><li><a href="http://www.brendangregg.com/ebpf.html">http://www.brendangregg.com/ebpf.html</a> ‚Äì eBPF trace tools</li><li><a href="https://github.com/iovisor/bcc/blob/master/docs/reference_guide.md">https://github.com/iovisor/bcc/blob/master/docs/reference_guide.md</a> ‚Äì BCC reference guide</li></ul></div></div>]]>
            </description>
            <link>https://filipnikolovski.com/posts/ebpf/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25490138</guid>
            <pubDate>Sun, 20 Dec 2020 22:24:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The U.S. Army Is Creating Robots with Synthetically Grown Muscle]]>
            </title>
            <description>
<![CDATA[
Score 46 | Comments 13 (<a href="https://news.ycombinator.com/item?id=25489005">thread link</a>) | @bookofjoe
<br/>
December 20, 2020 | https://smosa.com/army-building-robots-with-synthetic-muscle/ | <a href="https://web.archive.org/web/*/https://smosa.com/army-building-robots-with-synthetic-muscle/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>

					<!-- .post-header -->


					<div>
						<p>According to <a href="https://www.eurekalert.org/pub_releases/2020-12/uarl-asf121720.php">an announcement in EurekAlert</a>!, The U.S. Army has been researching with Duke University a technological approach that uses robotics and "biohybrid" muscle elements.</p><p>Army researchers claim that robotic systems filled with muscle tissue will deliver a new level of agility and flexibility. In order to maximize efficiency, biohybrid robotics incorporates living organisms into mechanical systems. The team's first applications are legged platforms similar to the LLAMA and Marine Corps Legged Squad Support System (LS3), the legged locomotive and movement adaptation device of the Army.</p><p>"Though impressive in their own right, today's robots are deployed to serve a limited purpose then are retrieved some minutes later," said research scientist Dr. Dean Culver, "ARL wants robots to be versatile teammates capable of going anywhere soldiers can and more, adapting to the needs of any given situation." Culver added, "Organisms outperform engineered robots in so many ways. Why not use biological components to achieve those remarkable capabilities?"</p><figure><img src="https://images.unsplash.com/photo-1580835239846-5bb9ce03c8c3?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=MXwxMTc3M3wwfDF8c2VhcmNofDl8fHJvYm90fGVufDB8fHw&amp;ixlib=rb-1.2.1&amp;q=80&amp;w=2000" alt="Humanoid robot Robotis Bioloid with the hands in the air, cheering." srcset="https://images.unsplash.com/photo-1580835239846-5bb9ce03c8c3?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=MXwxMTc3M3wwfDF8c2VhcmNofDl8fHJvYm90fGVufDB8fHw&amp;ixlib=rb-1.2.1&amp;q=80&amp;w=600 600w, https://images.unsplash.com/photo-1580835239846-5bb9ce03c8c3?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=MXwxMTc3M3wwfDF8c2VhcmNofDl8fHJvYm90fGVufDB8fHw&amp;ixlib=rb-1.2.1&amp;q=80&amp;w=1000 1000w, https://images.unsplash.com/photo-1580835239846-5bb9ce03c8c3?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=MXwxMTc3M3wwfDF8c2VhcmNofDl8fHJvYm90fGVufDB8fHw&amp;ixlib=rb-1.2.1&amp;q=80&amp;w=1600 1600w, https://images.unsplash.com/photo-1580835239846-5bb9ce03c8c3?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=MXwxMTc3M3wwfDF8c2VhcmNofDl8fHJvYm90fGVufDB8fHw&amp;ixlib=rb-1.2.1&amp;q=80&amp;w=2400 2400w" sizes="(min-width: 720px) 720px"><figcaption>Photo by <a href="https://unsplash.com/@anilinverse?utm_source=ghost&amp;utm_medium=referral&amp;utm_campaign=api-credit">Adam Lukomski</a> / <a href="https://unsplash.com/?utm_source=ghost&amp;utm_medium=referral&amp;utm_campaign=api-credit">Unsplash</a></figcaption></figure><p>In addition, a separate team from Duke University will focus on the characteristics of macroscopic performance of muscles, tendons and ligaments in skiping animals using legged robots.</p><p>The muscle tissue is excellent for generating a certain mechanical strength, and its flexibility is unrivaled in today's robotic service. The research could show the bio-hybrid engineering community how to grow strong muscular tissue instead of extracting it from a trained organism in addition to providing insight into the mesomechanics that control motor protein movement.</p><p>"Muscle tissue is outstanding at producing a specific amount of mechanical power at a given moment," says Culver, "and its versatility is unrivaled in robotic actuation today."</p>
					</div><!-- .post-content -->

					<!-- .post-footer -->


				</article></div>]]>
            </description>
            <link>https://smosa.com/army-building-robots-with-synthetic-muscle/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25489005</guid>
            <pubDate>Sun, 20 Dec 2020 19:51:57 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[On the Graying of Gnome]]>
            </title>
            <description>
<![CDATA[
Score 123 | Comments 197 (<a href="https://news.ycombinator.com/item?id=25488887">thread link</a>) | @yankcrime
<br/>
December 20, 2020 | https://hpjansson.org/blag/2020/12/16/on-the-graying-of-gnome/ | <a href="https://web.archive.org/web/*/https://hpjansson.org/blag/2020/12/16/on-the-graying-of-gnome/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="page"><div id="content"><section id="primary"><main id="main" role="main"><article id="post-622"><div><p><a href="https://gnome.org/">The GNOME project</a> turned 23 this year, and despite equally persistent rumors to the contrary, it‚Äôs still alive and kicking.</p><p>Just how alive, though? All I know is this: Where the topic of GNOME‚Äôs health goes, accurate data rarely follows. Of course, there <em>is</em> data ‚Äî lots of it in fact, in public source code repositories. Though flawed in many ways, it allows us to make comparisons to the past ‚Äî and maybe predictions for the future: Are a few organizations carrying most of the workload, making them critical points of failure? Are new contributors able to pick up the slack from those who leave? Is the project graying (i.e. increasingly dominated by veterans)?</p><p>In one of my occasional fits of hubris, I set out to process this data to see if I could shake out anything meaningful. I‚Äôm usually fine with just satisfying my own curiosity and leaving it at that, but it‚Äôs one of those times where the results seem interesting enough for a blog post. So here we are.</p><p>I‚Äôm going to lead with the nice graphs and follow on with a <a href="https://hpjansson.org/blag/2020/12/16/on-the-graying-of-gnome/#methodology">section on methodology</a>. The latter is long, boring, and mandatory reading.</p><h2 id="contributors">Active contributors</h2><h3>By generation</h3><figure><a href="https://hpjansson.org/blag/wp-content/uploads/2020/12/gnome-authors-firstyear-year-2020.png"><img loading="lazy" width="1920" height="900" src="https://hpjansson.org/blag/wp-content/uploads/2020/12/gnome-authors-firstyear-year-2020-1920x900.png" alt="Active GNOME authors per year, first-year cohorts" srcset="https://hpjansson.org/blag/wp-content/uploads/2020/12/gnome-authors-firstyear-year-2020-1920x900.png 1920w, https://hpjansson.org/blag/wp-content/uploads/2020/12/gnome-authors-firstyear-year-2020-300x141.png 300w, https://hpjansson.org/blag/wp-content/uploads/2020/12/gnome-authors-firstyear-year-2020-768x360.png 768w, https://hpjansson.org/blag/wp-content/uploads/2020/12/gnome-authors-firstyear-year-2020-1536x720.png 1536w, https://hpjansson.org/blag/wp-content/uploads/2020/12/gnome-authors-firstyear-year-2020-2048x960.png 2048w" sizes="(max-width: 1920px) 100vw, 1920px"></a></figure><p>The stacked histogram above shows the number of contributors who touched the project on a yearly basis. Each contributor is assigned to a generational cohort based on the year of their first contribution. The cohorts tend to shrink over time as people leave.</p><p>There‚Äôs a special ‚Äúdrive-by‚Äù cohort (in a fetching shade of off-white) for contributors who were only briefly involved, meaning all their activity fits in a three-month window. It‚Äôs a big group. In a typical year, it numbers 200-400 persons who were not seen before or since. Most of them contribute a single commit.</p><p>According to this, GNOME peaked at slightly above 1,400 contributors in 2010 and went into decline with the GNOME 3.0 release the following year. However, 2020 saw the most contributors in a long time, even with preliminary data ‚Äî there‚Äôs still two weeks to go. Who knows if it‚Äôs an anomaly or not. It‚Äôs been an atypical year across the board.</p><figure><a href="https://hpjansson.org/blag/wp-content/uploads/2020/12/gnome-authors-firstyear-month-2020.png"><img loading="lazy" width="1920" height="900" src="https://hpjansson.org/blag/wp-content/uploads/2020/12/gnome-authors-firstyear-month-2020-1920x900.png" alt="Active GNOME authors per month, first-year cohorts" srcset="https://hpjansson.org/blag/wp-content/uploads/2020/12/gnome-authors-firstyear-month-2020-1920x900.png 1920w, https://hpjansson.org/blag/wp-content/uploads/2020/12/gnome-authors-firstyear-month-2020-300x141.png 300w, https://hpjansson.org/blag/wp-content/uploads/2020/12/gnome-authors-firstyear-month-2020-768x360.png 768w, https://hpjansson.org/blag/wp-content/uploads/2020/12/gnome-authors-firstyear-month-2020-1536x720.png 1536w, https://hpjansson.org/blag/wp-content/uploads/2020/12/gnome-authors-firstyear-month-2020-2048x960.png 2048w" sizes="(max-width: 1920px) 100vw, 1920px"></a></figure><p>This is the same histogram, but with per-month bins. There‚Äôs a clear periodicity caused by the semiannual release cycle. The peak month was March 2011, right before the <a href="https://www.gnome.org/press/2011/04/gnome-3-0-released-better-for-users-developers-3/">GNOME 3.0 release</a>. About 450 contributors got involved that month.</p><p>The drive-by cohort is relatively smaller on a monthly basis. This makes sense, as it has little overlap from month to month, and the per-year bins tend to add them all up.</p><h3>By affiliation</h3><figure><a href="https://hpjansson.org/blag/wp-content/uploads/2020/12/gnome-authors-domain-year-2020.png"><img loading="lazy" width="1920" height="900" src="https://hpjansson.org/blag/wp-content/uploads/2020/12/gnome-authors-domain-year-2020-1920x900.png" alt="Active GNOME authors per year, top-15 domain cohorts" srcset="https://hpjansson.org/blag/wp-content/uploads/2020/12/gnome-authors-domain-year-2020-1920x900.png 1920w, https://hpjansson.org/blag/wp-content/uploads/2020/12/gnome-authors-domain-year-2020-300x141.png 300w, https://hpjansson.org/blag/wp-content/uploads/2020/12/gnome-authors-domain-year-2020-768x360.png 768w, https://hpjansson.org/blag/wp-content/uploads/2020/12/gnome-authors-domain-year-2020-1536x720.png 1536w, https://hpjansson.org/blag/wp-content/uploads/2020/12/gnome-authors-domain-year-2020-2048x960.png 2048w" sizes="(max-width: 1920px) 100vw, 1920px"></a></figure><p>Above, the top 15 affiliations of active contributors. I‚Äôve excluded personal accounts. This is pretty flawed (details below), but interesting nonetheless. For what it‚Äôs worth, it mostly lines up with my memory of things.</p><p>The pattern tracks well with the total despite only capturing a minority portion of it. I think this means that paid and unpaid contributions are driven by the same underlying trends, or that there‚Äôs a lot of the former hiding in the latter.</p><h2 id="commitcount">Commit count</h2><h3>By generation</h3><figure><a href="https://hpjansson.org/blag/wp-content/uploads/2020/12/gnome-commits-firstyear-year-2020.png"><img loading="lazy" width="1920" height="900" src="https://hpjansson.org/blag/wp-content/uploads/2020/12/gnome-commits-firstyear-year-2020-1920x900.png" alt="Number of GNOME commits per year, first-year cohorts" srcset="https://hpjansson.org/blag/wp-content/uploads/2020/12/gnome-commits-firstyear-year-2020-1920x900.png 1920w, https://hpjansson.org/blag/wp-content/uploads/2020/12/gnome-commits-firstyear-year-2020-300x141.png 300w, https://hpjansson.org/blag/wp-content/uploads/2020/12/gnome-commits-firstyear-year-2020-768x360.png 768w, https://hpjansson.org/blag/wp-content/uploads/2020/12/gnome-commits-firstyear-year-2020-1536x720.png 1536w, https://hpjansson.org/blag/wp-content/uploads/2020/12/gnome-commits-firstyear-year-2020-2048x960.png 2048w" sizes="(max-width: 1920px) 100vw, 1920px"></a></figure><p>Here I‚Äôm counting the number of commits per year in the various cohorts.</p><p>At first glance, this looks much less dire. However, note how newcomers are having a smaller impact, especially from 2014 on. And the 2018-2020 bounce is entirely due to a handful of veterans making a comeback.</p><p>Half the commits in 2020 were made by contributors who‚Äôve been with the project for ten years or more. Also noteworthy, drive-by commits are a vanishingly small portion of the total.</p><h3>By affiliation</h3><figure><a href="https://hpjansson.org/blag/wp-content/uploads/2020/12/gnome-commits-domain-year-2020.png"><img loading="lazy" width="1920" height="900" src="https://hpjansson.org/blag/wp-content/uploads/2020/12/gnome-commits-domain-year-2020-1920x900.png" alt="Number of GNOME commits per year, top-15 domain cohorts" srcset="https://hpjansson.org/blag/wp-content/uploads/2020/12/gnome-commits-domain-year-2020-1920x900.png 1920w, https://hpjansson.org/blag/wp-content/uploads/2020/12/gnome-commits-domain-year-2020-300x141.png 300w, https://hpjansson.org/blag/wp-content/uploads/2020/12/gnome-commits-domain-year-2020-768x360.png 768w, https://hpjansson.org/blag/wp-content/uploads/2020/12/gnome-commits-domain-year-2020-1536x720.png 1536w, https://hpjansson.org/blag/wp-content/uploads/2020/12/gnome-commits-domain-year-2020-2048x960.png 2048w" sizes="(max-width: 1920px) 100vw, 1920px"></a></figure><p>Top 15 affiliations again, but now ordered by commit counts. It‚Äôs safe to say that GNOME is dependent on paid developers in a big way. Specifically, and to no one‚Äôs surprise, it leans heavily on Red Hat.</p><h2 id="observations">General observations</h2><p>A few observations can be made with confidence:</p><ul><li>By F/OSS standards, the project is not <em>un</em>healthy. It has hundreds of experienced and first-time contributors every year. It is well-organized and arguably well-funded compared to its peers. But:</li><li>Every metric has the project peaking around 2010.</li><li>A diminishing number of veterans is doing an increasing share of the work.</li><li>Although recruitment is stable, newcomers don‚Äôt seem to be hitting their stride in terms of commits.</li><li>Corporate sponsorship is probably necessary to keep the project going, but the field of sponsors has kept thinning.</li></ul><p>I think GNOME is addressing the risk factors competently by modernizing infrastructure (<a href="https://gitlab.gnome.org/">GitLab</a>, <a href="https://discourse.gnome.org/">Discourse</a>). This has obvious value even in the absence of quantifiable results, but it‚Äôll be interesting to see if the effect can be measured over the next couple of years.</p><p>Diminished enthusiasm may also be due to there being fewer ways for a new contributor to make their mark or assume a role of responsibility. GNOME has become more conservative, certainly much more so than it was a decade ago in the run-up to GNOME 3. The rationale and phrasing in <a href="https://discourse.gnome.org/t/new-gnome-versioning-scheme/4235">the announcement of the new versioning scheme</a> (e.g. <em>‚ÄúRadical technological and design changes are too disruptive for maintainers, users, and developers‚Äù</em>) seems indicative of this trend<sup>1</sup>.</p><h2 id="methodology">Notes on methodology</h2><p>So what‚Äôs wrong with this analysis? If you‚Äôre so inclined, you can find the details under the next couple of subheadings and pass harsh, harsh judgement.</p><p>I‚Äôve set the unscientific rigor bar high enough to hopefully yield something useful, but low enough that I could do it in my spare time and not get stuck in the dreaded state commonly known as ‚Äú90% done‚Äù.</p><h3>Module selection</h3><p>I aggregated data from <a href="https://github.com/hpjansson/fornalder/blob/45d4e9703dfa1fed1f9396b2cfc6f8425fae9389/projects/gnome-repos">189 Git repositories</a>. The vast majority of these are hosted on <code>gnome.org</code>, with a handful from <code>freedesktop.org</code> and <code>github.com</code>. Commits are uniquely identified by their commit hash, meaning trivial duplicates are counted only once.</p><p>GNOME has always been a decentralized, big-tent project, so it‚Äôs not obvious how to delineate it. I‚Äôve tried to be fair by including most of the repositories from a full meta-gnome-desktop jhbuild, including fairly low-level dependencies like Cairo, Pango, and Pipewire, as well as past, present and would-be flagship applications under the GNOME umbrella. Documentation and infrastructure is represented, as are many archived projects (e.g. ORBit2, Bonobo, Sabayon, GAL).</p><p>I was a little uncertain about what to do with X.Org and Wayland. In the end I decided to include the latter, but not the former, since Wayland has close ties to GNOME (it even references GTK+ in its TODO file), while X.Org has its roots in the much older XFree86.</p><p>Mono is another project I resisted including; its development was tangential to GNOME proper, diverging completely in the most recent decade. However, I did include GtkSharp and several GNOME-hosted C# applications common on desktops in the 2005-2010 time frame.</p><p>Since I haven‚Äôt established hard criteria for module selection, it‚Äôs subject to various biases. Older code is probably underrepresented, since providers of important functionality were more loosely attached to the project early on (e.g. GNOME Online Accounts and Telepathy got pulled in, should I have included Gaim or Pidgin too? How about XChat?).</p><p>Anyway, the list isn‚Äôt terrible, but there‚Äôs room for improvement.</p><h3>Contributor identities</h3><p>Similar studies often identify contributors by their e-mail addresses. I used full author names instead, since there‚Äôs good reason to think they‚Äôre more stable over a 20-year time span. We‚Äôre fairly consistent in spelling our own names, and we change them rarely (often never). On the other hand, e-mail addresses come and go with different hosting arrangements, employers, etc.</p><p>An added challenge with this approach is that sometimes different people have the exact same name. In practice, I‚Äôm not aware of any instances of this happening in GNOME. It seems to be rare enough that I doubt it‚Äôd introduce significant error in most projects.</p><p>I should add here that the drive-by cohort depends on a fair amount of hindsight (you never know when someone might come back with more contributions, but the likelihood drops off quickly as time passes). This means the cohorts for 2020 are preliminary. They‚Äôll be a lot more accurate with another run late next year.</p><h3>Domain names</h3><p>I‚Äôm using e-mail domain names as a proxy for organizations in some of the graphs. This is a notoriously unreliable approach for at least three reasons:</p><ol><li>Contributors often use personal e-mail addresses for paid work, leading to significant undercounting in general.</li><li>Specific companies may require their employees (or ask them nicely) to use company e-mail for collaboration. Out of the listed companies, I know of at least one that definitely did this. However, there are many that don‚Äôt, and these will be comparatively less well represented.</li><li>The mapping between DNS and organizations isn‚Äôt one-to-one. A company may operate under multiple names or TLDs (e.g. <code>.co.uk</code> and <code>.com</code>).</li></ol><p>Despite these weaknesses, it‚Äôs common to slice the data this way. It‚Äôs difficult to do better without access to semi-closed data troves, and depending on your views on privacy and ability to handle <a href="https://en.wikipedia.org/wiki/Personal_data">PII</a> safely, it might not be something you‚Äôd want to get into anyway. But I bet you‚Äôd be well-positioned for it if you were, say, the corporate owner of both LinkedIn and GitHub.</p><p>When grouping by organization, the goal is to get an idea of which outside entities are sponsoring contributions. Therefore, I‚Äôve filtered out addresses from the biggest mass e-mail providers like <code>@gmail.com</code> and project-centric providers of personal accounts (e.g. <code>@gnome.org</code>, <code>@gtk.org</code>).</p><p>I took the liberty of reassigning the personal domains of a few extra prolific authors who would‚Äôve otherwise showed up as individual organizations. Since there‚Äôs no way I‚Äôm doing it for everyone, this introduces some bias. The full details are in <a href="https://github.com/hpjansson/fornalder/blob/45d4e9703dfa1fed1f9396b2cfc6f8425fae9389/projects/gnome-meta.json">the project‚Äôs metadata file</a> (see: <a href="https://hpjansson.org/blag/2020/12/16/on-the-graying-of-gnome/#code">code</a>).</p><h3>Version control systems</h3><p>Changeovers in version control systems divide GNOME‚Äôs VCS history into three eras with noticeable discontinuities between them.</p><h4>Before 1998: Dark ages</h4><p>In the Bad Old Days, Free Software would often use plain <a href="https://en.wikipedia.org/wiki/Revision_Control_System">RCS</a> or no version control at all. I have basically no data for this era: The GIMP, being the ur-project from which ‚Ä¶</p></div></article></main></section></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://hpjansson.org/blag/2020/12/16/on-the-graying-of-gnome/">https://hpjansson.org/blag/2020/12/16/on-the-graying-of-gnome/</a></em></p>]]>
            </description>
            <link>https://hpjansson.org/blag/2020/12/16/on-the-graying-of-gnome/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25488887</guid>
            <pubDate>Sun, 20 Dec 2020 19:33:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Posenet Fruit Ninja in the Browser (Tensorflow.js and Posenet)]]>
            </title>
            <description>
<![CDATA[
Score 44 | Comments 16 (<a href="https://news.ycombinator.com/item?id=25486322">thread link</a>) | @liuxiaopai
<br/>
December 20, 2020 | https://huhai463127310.github.io/posenet_fruit_ninja/ | <a href="https://web.archive.org/web/*/https://huhai463127310.github.io/posenet_fruit_ninja/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <p>‰øùËØÅÊëÑÂÉèÂ§¥Â§Ñ‰∫éÊú™Á¶ÅÁî®Áä∂ÊÄÅÔºåÊ≠£ÂØπÊëÑÂÉèÂ§¥Á´ôÁ´ãÔºå‰øùËØÅÂ∑¶‰∏äËßíÊëÑÂÉèÂ§¥Á™óÂè£ÂèØÁúãËßÅ‰Ω†ÁöÑ‰∏äÂçäË∫´ÔºåÊå•ËàûÊâãËáÇÔºåÂàíÊéâNew Game„ÄÇ</p>
        <p>Êå•Ëàû‰Ω†ÁöÑÊâãÔºÅÊå•Ëàû‰Ω†ÁöÑÊâãÔºÅÊå•Ëàû‰Ω†ÁöÑÊâãÔºÅ</p>
    </div></div>]]>
            </description>
            <link>https://huhai463127310.github.io/posenet_fruit_ninja/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25486322</guid>
            <pubDate>Sun, 20 Dec 2020 14:17:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Understanding how AES encryption works]]>
            </title>
            <description>
<![CDATA[
Score 68 | Comments 17 (<a href="https://news.ycombinator.com/item?id=25486017">thread link</a>) | @nakabonne
<br/>
December 20, 2020 | https://nakabonne.dev/posts/understanding-how-aes-encryption-works/ | <a href="https://web.archive.org/web/*/https://nakabonne.dev/posts/understanding-how-aes-encryption-works/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <p>I recently had the opportunity to encrypt/decrypt stuff using AES, but I didn‚Äôt know it inside out well. I couldn‚Äôt help but be curious about how it is working, and I realized my mind could only be satisfied by digging deeper into its implementation.
This post walks you through how AES encryption works by reading core implementation written in Go.</p>
<h2 id="what-is-aes-encryption">What is AES encryption?</h2>
<p>The Advanced Encryption Standard (AES) is a symmetric block cipher, an alternative to the DES. Cryptographers from around the world proposed algorithms, from which the Rijndael algorithm was selected in 2000. Hence we‚Äôll take a look the implementation of this Rijndael.</p>
<h2 id="rijndael">Rijndael</h2>
<p>Rijndael is a block cipher algorithm. A block cipher is a cryptographic algorithm that processes a specific number of bits at a time.
The number of bits (called block length) to be processed at a time depends on the algorithm, AES is 128-bits (16-bytes). Most plaintext we encrypt is longer than this block length, so we typically use this block cipher algorithm repeatedly.
Keep in mind this post goes into some details on only on one block‚Äôs process to focus more on the core algorithm.</p>
<h2 id="digging-deeper-into-the-implementation">Digging deeper into the implementation</h2>
<p>The Go language officially provides the <a href="https://golang.org/pkg/crypto/aes/">crypto/aes</a> package, which makes use of Go Assembly to leverage Intel‚Äôs hardware support for AES if it‚Äôs built for amd64.
It otherwise uses the implementation written in pure Go. Let‚Äôs take a look at the pure Go implementation that the human mind relatively can work in.</p>
<p>The public method <code>aesCipher.Encrypt</code> defined in <a href="https://github.com/golang/go/blob/55b58018f41e6de63bdaa8f3d9a284077d4e88c1/src/crypto/aes/cipher.go#L54-L65">aes/cipher.go</a> looks to implement a block cipher:</p>
<div><pre><code data-lang="go"><span>// The AES block size in bytes.
</span><span></span><span>const</span> <span>BlockSize</span> = <span>16</span>

<span>func</span> (<span>c</span> <span>*</span><span>aesCipher</span>) <span>Encrypt</span>(<span>dst</span>, <span>src</span> []<span>byte</span>) {
	<span>if</span> len(<span>src</span>) &lt; <span>BlockSize</span> {
		panic(<span>"crypto/aes: input not full block"</span>)
	}
	<span>if</span> len(<span>dst</span>) &lt; <span>BlockSize</span> {
		panic(<span>"crypto/aes: output not full block"</span>)
	}
	<span>if</span> <span>subtle</span>.<span>InexactOverlap</span>(<span>dst</span>[:<span>BlockSize</span>], <span>src</span>[:<span>BlockSize</span>]) {
		panic(<span>"crypto/aes: invalid buffer overlap"</span>)
	}
	<span>encryptBlockGo</span>(<span>c</span>.<span>enc</span>, <span>dst</span>, <span>src</span>)
}
</code></pre></div><p>This method does the two validations that check if:</p>
<ul>
<li>the given plaintext is equal to 16-bytes, the block length of AES</li>
<li><code>dst</code> and <code>src</code> share memory at any index</li>
</ul>
<p>It seems to leave the core implementation to <code>encryptBlockGo</code> defined in <a href="https://github.com/golang/go/blob/55b58018f41e6de63bdaa8f3d9a284077d4e88c1/src/crypto/aes/block.go#L43-L87">aes/block.go</a>:</p>
<div><pre><code data-lang="go"><span>// Encrypt one block from src into dst, using the expanded key xk.
</span><span></span><span>func</span> <span>encryptBlockGo</span>(<span>xk</span> []<span>uint32</span>, <span>dst</span>, <span>src</span> []<span>byte</span>) {
	<span>_</span> = <span>src</span>[<span>15</span>] <span>// early bounds check
</span><span></span>	<span>s0</span> <span>:=</span> <span>binary</span>.<span>BigEndian</span>.<span>Uint32</span>(<span>src</span>[<span>0</span>:<span>4</span>])
	<span>s1</span> <span>:=</span> <span>binary</span>.<span>BigEndian</span>.<span>Uint32</span>(<span>src</span>[<span>4</span>:<span>8</span>])
	<span>s2</span> <span>:=</span> <span>binary</span>.<span>BigEndian</span>.<span>Uint32</span>(<span>src</span>[<span>8</span>:<span>12</span>])
	<span>s3</span> <span>:=</span> <span>binary</span>.<span>BigEndian</span>.<span>Uint32</span>(<span>src</span>[<span>12</span>:<span>16</span>])

	<span>// First round just XORs input with key.
</span><span></span>	<span>s0</span> ^= <span>xk</span>[<span>0</span>]
	<span>s1</span> ^= <span>xk</span>[<span>1</span>]
	<span>s2</span> ^= <span>xk</span>[<span>2</span>]
	<span>s3</span> ^= <span>xk</span>[<span>3</span>]

	<span>// Middle rounds shuffle using tables.
</span><span></span>	<span>// Number of rounds is set by length of expanded key.
</span><span></span>	<span>nr</span> <span>:=</span> len(<span>xk</span>)<span>/</span><span>4</span> <span>-</span> <span>2</span> <span>// - 2: one above, one more below
</span><span></span>	<span>k</span> <span>:=</span> <span>4</span>
	<span>var</span> <span>t0</span>, <span>t1</span>, <span>t2</span>, <span>t3</span> <span>uint32</span>
	<span>for</span> <span>r</span> <span>:=</span> <span>0</span>; <span>r</span> &lt; <span>nr</span>; <span>r</span><span>++</span> {
		<span>t0</span> = <span>xk</span>[<span>k</span><span>+</span><span>0</span>] ^ <span>te0</span>[uint8(<span>s0</span><span>&gt;&gt;</span><span>24</span>)] ^ <span>te1</span>[uint8(<span>s1</span><span>&gt;&gt;</span><span>16</span>)] ^ <span>te2</span>[uint8(<span>s2</span><span>&gt;&gt;</span><span>8</span>)] ^ <span>te3</span>[uint8(<span>s3</span>)]
		<span>t1</span> = <span>xk</span>[<span>k</span><span>+</span><span>1</span>] ^ <span>te0</span>[uint8(<span>s1</span><span>&gt;&gt;</span><span>24</span>)] ^ <span>te1</span>[uint8(<span>s2</span><span>&gt;&gt;</span><span>16</span>)] ^ <span>te2</span>[uint8(<span>s3</span><span>&gt;&gt;</span><span>8</span>)] ^ <span>te3</span>[uint8(<span>s0</span>)]
		<span>t2</span> = <span>xk</span>[<span>k</span><span>+</span><span>2</span>] ^ <span>te0</span>[uint8(<span>s2</span><span>&gt;&gt;</span><span>24</span>)] ^ <span>te1</span>[uint8(<span>s3</span><span>&gt;&gt;</span><span>16</span>)] ^ <span>te2</span>[uint8(<span>s0</span><span>&gt;&gt;</span><span>8</span>)] ^ <span>te3</span>[uint8(<span>s1</span>)]
		<span>t3</span> = <span>xk</span>[<span>k</span><span>+</span><span>3</span>] ^ <span>te0</span>[uint8(<span>s3</span><span>&gt;&gt;</span><span>24</span>)] ^ <span>te1</span>[uint8(<span>s0</span><span>&gt;&gt;</span><span>16</span>)] ^ <span>te2</span>[uint8(<span>s1</span><span>&gt;&gt;</span><span>8</span>)] ^ <span>te3</span>[uint8(<span>s2</span>)]
		<span>k</span> <span>+=</span> <span>4</span>
		<span>s0</span>, <span>s1</span>, <span>s2</span>, <span>s3</span> = <span>t0</span>, <span>t1</span>, <span>t2</span>, <span>t3</span>
	}

	<span>// Last round uses s-box directly and XORs to produce output.
</span><span></span>	<span>s0</span> = uint32(<span>sbox0</span>[<span>t0</span><span>&gt;&gt;</span><span>24</span>])<span>&lt;&lt;</span><span>24</span> | uint32(<span>sbox0</span>[<span>t1</span><span>&gt;&gt;</span><span>16</span><span>&amp;</span><span>0xff</span>])<span>&lt;&lt;</span><span>16</span> | uint32(<span>sbox0</span>[<span>t2</span><span>&gt;&gt;</span><span>8</span><span>&amp;</span><span>0xff</span>])<span>&lt;&lt;</span><span>8</span> | uint32(<span>sbox0</span>[<span>t3</span><span>&amp;</span><span>0xff</span>])
	<span>s1</span> = uint32(<span>sbox0</span>[<span>t1</span><span>&gt;&gt;</span><span>24</span>])<span>&lt;&lt;</span><span>24</span> | uint32(<span>sbox0</span>[<span>t2</span><span>&gt;&gt;</span><span>16</span><span>&amp;</span><span>0xff</span>])<span>&lt;&lt;</span><span>16</span> | uint32(<span>sbox0</span>[<span>t3</span><span>&gt;&gt;</span><span>8</span><span>&amp;</span><span>0xff</span>])<span>&lt;&lt;</span><span>8</span> | uint32(<span>sbox0</span>[<span>t0</span><span>&amp;</span><span>0xff</span>])
	<span>s2</span> = uint32(<span>sbox0</span>[<span>t2</span><span>&gt;&gt;</span><span>24</span>])<span>&lt;&lt;</span><span>24</span> | uint32(<span>sbox0</span>[<span>t3</span><span>&gt;&gt;</span><span>16</span><span>&amp;</span><span>0xff</span>])<span>&lt;&lt;</span><span>16</span> | uint32(<span>sbox0</span>[<span>t0</span><span>&gt;&gt;</span><span>8</span><span>&amp;</span><span>0xff</span>])<span>&lt;&lt;</span><span>8</span> | uint32(<span>sbox0</span>[<span>t1</span><span>&amp;</span><span>0xff</span>])
	<span>s3</span> = uint32(<span>sbox0</span>[<span>t3</span><span>&gt;&gt;</span><span>24</span>])<span>&lt;&lt;</span><span>24</span> | uint32(<span>sbox0</span>[<span>t0</span><span>&gt;&gt;</span><span>16</span><span>&amp;</span><span>0xff</span>])<span>&lt;&lt;</span><span>16</span> | uint32(<span>sbox0</span>[<span>t1</span><span>&gt;&gt;</span><span>8</span><span>&amp;</span><span>0xff</span>])<span>&lt;&lt;</span><span>8</span> | uint32(<span>sbox0</span>[<span>t2</span><span>&amp;</span><span>0xff</span>])

	<span>s0</span> ^= <span>xk</span>[<span>k</span><span>+</span><span>0</span>]
	<span>s1</span> ^= <span>xk</span>[<span>k</span><span>+</span><span>1</span>]
	<span>s2</span> ^= <span>xk</span>[<span>k</span><span>+</span><span>2</span>]
	<span>s3</span> ^= <span>xk</span>[<span>k</span><span>+</span><span>3</span>]

	<span>_</span> = <span>dst</span>[<span>15</span>] <span>// early bounds check
</span><span></span>	<span>binary</span>.<span>BigEndian</span>.<span>PutUint32</span>(<span>dst</span>[<span>0</span>:<span>4</span>], <span>s0</span>)
	<span>binary</span>.<span>BigEndian</span>.<span>PutUint32</span>(<span>dst</span>[<span>4</span>:<span>8</span>], <span>s1</span>)
	<span>binary</span>.<span>BigEndian</span>.<span>PutUint32</span>(<span>dst</span>[<span>8</span>:<span>12</span>], <span>s2</span>)
	<span>binary</span>.<span>BigEndian</span>.<span>PutUint32</span>(<span>dst</span>[<span>12</span>:<span>16</span>], <span>s3</span>)
}
</code></pre></div><p>Don‚Äôt be afraid of it. We‚Äôll focus on the significant parts.</p>
<p>The input (means plaintext) to a single block is 16-bytes as we can see above. The input is first divided into four lines, separated by four bytes.</p>
<div><pre><code data-lang="go"><span>s0</span> <span>:=</span> <span>binary</span>.<span>BigEndian</span>.<span>Uint32</span>(<span>src</span>[<span>0</span>:<span>4</span>])
<span>s1</span> <span>:=</span> <span>binary</span>.<span>BigEndian</span>.<span>Uint32</span>(<span>src</span>[<span>4</span>:<span>8</span>])
<span>s2</span> <span>:=</span> <span>binary</span>.<span>BigEndian</span>.<span>Uint32</span>(<span>src</span>[<span>8</span>:<span>12</span>])
<span>s3</span> <span>:=</span> <span>binary</span>.<span>BigEndian</span>.<span>Uint32</span>(<span>src</span>[<span>12</span>:<span>16</span>])
</code></pre></div><p>This illustrates how the input is handled in the AES encryption process. It is definitely the key to understand to keep this format in mind.</p>
<figure>
    <img src="https://nakabonne.dev/img/aes-divided-input.jpg" width="100%" height="auto"> 
</figure>

<p>And the next part which is something iterating, is the most core implementation.</p>
<div><pre><code data-lang="go"><span>// Middle rounds shuffle using tables.
</span><span>// Number of rounds is set by length of expanded key.
</span><span></span><span>nr</span> <span>:=</span> len(<span>xk</span>)<span>/</span><span>4</span> <span>-</span> <span>2</span> <span>// - 2: one above, one more below
</span><span></span><span>k</span> <span>:=</span> <span>4</span>
<span>var</span> <span>t0</span>, <span>t1</span>, <span>t2</span>, <span>t3</span> <span>uint32</span>
<span>for</span> <span>r</span> <span>:=</span> <span>0</span>; <span>r</span> &lt; <span>nr</span>; <span>r</span><span>++</span> {
	<span>t0</span> = <span>xk</span>[<span>k</span><span>+</span><span>0</span>] ^ <span>te0</span>[uint8(<span>s0</span><span>&gt;&gt;</span><span>24</span>)] ^ <span>te1</span>[uint8(<span>s1</span><span>&gt;&gt;</span><span>16</span>)] ^ <span>te2</span>[uint8(<span>s2</span><span>&gt;&gt;</span><span>8</span>)] ^ <span>te3</span>[uint8(<span>s3</span>)]
	<span>t1</span> = <span>xk</span>[<span>k</span><span>+</span><span>1</span>] ^ <span>te0</span>[uint8(<span>s1</span><span>&gt;&gt;</span><span>24</span>)] ^ <span>te1</span>[uint8(<span>s2</span><span>&gt;&gt;</span><span>16</span>)] ^ <span>te2</span>[uint8(<span>s3</span><span>&gt;&gt;</span><span>8</span>)] ^ <span>te3</span>[uint8(<span>s0</span>)]
	<span>t2</span> = <span>xk</span>[<span>k</span><span>+</span><span>2</span>] ^ <span>te0</span>[uint8(<span>s2</span><span>&gt;&gt;</span><span>24</span>)] ^ <span>te1</span>[uint8(<span>s3</span><span>&gt;&gt;</span><span>16</span>)] ^ <span>te2</span>[uint8(<span>s0</span><span>&gt;&gt;</span><span>8</span>)] ^ <span>te3</span>[uint8(<span>s1</span>)]
	<span>t3</span> = <span>xk</span>[<span>k</span><span>+</span><span>3</span>] ^ <span>te0</span>[uint8(<span>s3</span><span>&gt;&gt;</span><span>24</span>)] ^ <span>te1</span>[uint8(<span>s0</span><span>&gt;&gt;</span><span>16</span>)] ^ <span>te2</span>[uint8(<span>s1</span><span>&gt;&gt;</span><span>8</span>)] ^ <span>te3</span>[uint8(<span>s2</span>)]
	<span>k</span> <span>+=</span> <span>4</span>
	<span>s0</span>, <span>s1</span>, <span>s2</span>, <span>s3</span> = <span>t0</span>, <span>t1</span>, <span>t2</span>, <span>t3</span>
}
</code></pre></div><p>Rijndael encrypts a block by repeating a process called a round.
In a round, there are four processes: SubBytes, ShiftRows, MixColumns, and AddRoundKey. As commented out in the snippet, the number of rounds depends on the key length.</p>
<h3 id="subbytes">SubBytes</h3>
<p>The conversion is done 1-byte at a time based on a conversion table called S-box which has 256 values.
Below illustrates to perform <code>sbox[s0[1]]</code> well:</p>
<figure>
    <img src="https://nakabonne.dev/img/aes-sbox.jpg" width="100%" height="auto"> 
</figure>

<p>Unlike DES, we can see that all bytes have been converted at this point.
This post doesn‚Äôt cover AES‚Äôs S-Box as it is mentioned in many places and much better than I could do.</p>
<h3 id="shiftrows">ShiftRows</h3>
<p>The next step is to process the rows that are grouped into 4-byte units and shifted regularly to the left.
The number of bytes to be shifted depends on the line, as shown below:</p>
<figure>
    <img src="https://nakabonne.dev/img/aes-shift-rows.jpg" width="100%" height="auto"> 
</figure>

<h3 id="mixcolumns">MixColumns</h3>
<p>In the previous step, it dealt with rows, but the next is to process the bytes in columns.</p>
<figure>
    <img src="https://nakabonne.dev/img/aes-mix-columns.jpg" width="100%" height="auto"> 
</figure>

<p>It involves multiplication operations in a finite field, hence this step is a bit tough to describe. See <a href="https://en.wikipedia.org/wiki/Rijndael_MixColumns">Wikipedia</a> for more details.</p>
<h3 id="addroundkey">AddRoundKey</h3>
<p>Finally, it XORs the output of MixColumns with the round key. The following figure shows the execution of <code>s0[1] ^ xk[4]</code> (the <code>^</code> denotes an XOR operation in Go).</p>
<figure>
    <img src="https://nakabonne.dev/img/aes-add-round-key.jpg" width="100%" height="auto"> 
</figure>

<h2 id="bottom-line">Bottom Line</h2>
<p>While this post has only shown you the encryption process, these processes are fully reversible with an Inverse MixColumns, ShiftRows, SubBytes. How beautiful!
I‚Äôll keep reading the implementation to deepen my understanding of cryptography.</p>

        
    </div></div>]]>
            </description>
            <link>https://nakabonne.dev/posts/understanding-how-aes-encryption-works/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25486017</guid>
            <pubDate>Sun, 20 Dec 2020 13:17:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How we made the PJON network protocol from scratch]]>
            </title>
            <description>
<![CDATA[
Score 121 | Comments 27 (<a href="https://news.ycombinator.com/item?id=25485943">thread link</a>) | @gioscarab
<br/>
December 20, 2020 | https://www.pjon.org/how.php | <a href="https://web.archive.org/web/*/https://www.pjon.org/how.php">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      
      <section>
        <div>
          
          <p>
            <a href="https://github.com/gioblu/PJON" target="_blank" rel="noopener noreferrer">PJON (Padded Jittering Operative Network)</a> is a lightweight, efficient and completely open network protocol. It has revolutionary features such as single wire communication with a range of up to 2 kms, wireless LED-to-LED communication and long range laser communication.
          </p>
        </div>
      </section>
      <section>
        <div>
          <article>
            <h2>2009 - Communication</h2>
            <p>
              Far back in 2009, while following Digital Communication, Advertising and Art Direction at NABA (New Academy of Fine Arts of Milan), I became interested in Professor Massimo Banzi's classes and managed to get an Arduino Diecimila. In just one day my vision of the world had changed and I slowly started to better understand computers and electronics while sharing results with the Arduino community both on my website and on Arduino's forum. I started to build robots and after few years of experiments I launched my first start¬≠up: a webshop of arduino-compatible, CNC machined robot kits, boards and sensors.
            </p>
          </article>
          <br>
          <article>
            <h2>2010 - Let's transmit data</h2>
            <p>
              At the time in my projects I had to connect many microcontrollers on a common bus and I found myself not satisfied by the solutions available, for this reason I started to develop my own data link. I perfectly remember that night back in 2010 when I started bit-banging bits using an Arduino and trying to sample them with another. The first problem I hit were bugs in the implementation that were quickly resolved. Then I unsterstood I did not have any synchronization, depending on when the receiver was powered on bits were shifted. That night, with no experience in electronics or engineering I instinctively defined the synchronization pulse that is still present as the core of <a href="https://github.com/gioblu/PJON/blob/13.0/src/strategies/SoftwareBitBang/specification/PJDL-specification-v5.0.md" target="_blank" rel="noopener noreferrer">PJDL (Padded Jittering Data Link) v5.0</a>. To make sure to synchronize with the start of each byte I have added a 1 longer than data bits followed by a 0 and instructed the receiver to find it and only then start sampling 8 bits. Data was coming in perfectly. That was <a href="https://github.com/gioblu/PJON/blob/master/src/strategies/SoftwareBitBang/specification/obsolete/padded-jittering-protocol-specification-v0.1.md" target="_blank" rel="noopener noreferrer">PJDL (Padded jittering data link) v0.1</a> which was basic and working by mere chance. Then, after debugging it further, experiments proved it was working well not only through wires and the human body, but also wirelessly through radio and infrared light, yet it showed to be robust operating bidirectionally in spite of interference. After I noticed that it was possible to connect more than 2 devices to the same wire, I started to experiment with an initial collision avoidance phase, an 8 bits device id and a synchronous acknowledgement at the end of the packet. It was shocking to see that many devices were able to send and receive data through the same wire. Soon after I released <a href="https://github.com/gioblu/PJON/blob/master/specification/obsolete/PJON-protocol-specification-v0.1.md" target="_blank" rel="noopener noreferrer">PJON v0.1</a> on the Arduino forum, receiving plenty of "don't ¬≠reinvent ¬≠the ¬≠wheel" and few active contributors.
            </p>
          </article>
        </div>
      </section>
      <section>
        
      </section>
      <section>
        <div>
          <article>
            <h2>2014 - Let's network</h2>
            <p>
              In those days I became aware of how quickly the cloud was eating the world and how difficult was to connect stuff directly without relying on a third-party. It seemed like noone could connect computers together anymore without an ever present observing big brother. To be honest, I did not like it: that was the point when I understood how <a href="https://github.com/gioblu/PJON" target="_blank" rel="noopener noreferrer">PJON</a> could have changed the game and what I personally could have done to influence the outcome. I decided to double my efforts on the protocol and try my best to provide humanity with a free and more efficient way to make networks. With a working protocol layer and support from the community, I went further in the address space development adding an optional 32 bits bus id used to identify a group of up to 255 devices, supporting up to 4.294.967.295 buses and a total of 1.090.921.692.930 devices. This addition released in <a href="https://github.com/gioblu/PJON/blob/master/specification/obsolete/PJON-protocol-specification-v0.2.md" target="_blank" rel="noopener noreferrer">PJON v0.2</a> enabled coexistence and networking for groups of devices. Thanks to Micheal Teeuw's post on his blog, PJON received contributions, testing, debugging and feature requests. Then many talented contributors added support for devices like ESP8266, Teensy 3.2 and Node MCU.
            </p>
          </article>
          <br>
          <article>
            <h2>2015 - Abstracting the data link</h2>
            <p>
              The community wanted to use PJON over different existing protocols and physical layers, to obtain that without making the implementation complex and more difficult to use I have defined the <a href="https://github.com/gioblu/PJON/tree/master/src/strategies" target="_blank" rel="noopener noreferrer">strategy</a> abstraction. The curiously recurring template pattern or CRTP was adopted to abstract the physical layer in separate classes called strategies. Thanks to this change from then it was possible to instantiate a PJON object passing the selected data link. Initially, I developed three strategies, a bit-banged implementation of <a href="https://github.com/gioblu/PJON/blob/13.0/src/strategies/SoftwareBitBang/specification/PJDL-specification-v5.0.md">PJDL</a> called <a href="https://github.com/gioblu/PJON/tree/master/src/strategies/SoftwareBitBang">SoftwareBitBang</a>, <a href="https://github.com/gioblu/PJON/tree/master/src/strategies/OverSampling">OverSampling</a> for radio communication and <a href="https://github.com/gioblu/PJON/tree/master/src/strategies/AnalogSampling">AnalogSampling</a> able to communicate wirelessly or with optical fiber using off-the-shelf LEDs. Later on, I developed together with Fred Larsen <a href="https://github.com/gioblu/PJON/tree/master/src/strategies/ThroughSerial">ThroughSerial</a> able to operate through a serial port.
            </p>
          </article>
        </div>
      </section>
      <section>
        
      </section>
      <section>
        <div>
          <article>
            <h2>2016 - It's mainstream</h2>
            <p>
               <a href="http://hackaday.com/2016/03/31/pjon-fancy-one-wire-arduino-communications-protocol-for-home-automation/" target="_blank" rel="noopener noreferrer">Hackaday</a> and the <a href="http://blog.atmel.com/2016/04/09/pjon-is-a-pretty-cool-one-wire-protocol/" target="_blank" rel="noopener noreferrer">Atmel blog</a> wrote about the PJON protocol and from that day an ongoing earthquake began. The initial response, especially in the Hackaday's comments, was quite negative - trolls were raging. Only when I joined the discussion and answered openly and sincerely to all the complaints and questions asked, the tone changed dramatically. Well, so dramatically, that in the next comments I got the most praiseworthy compliments I have ever received, those people for sure helped me not to desist. Since then, the PJON protocol specification has been used in academic researches and PhDs in different parts of the world, and the official PJON implementation has already been applied globally in a wide range of different systems.
            </p>
          </article>
          <br>
          <article>
            <h2>2016 - Let's add a header</h2>
            <p>
              The release of the <a href="https://github.com/gioblu/PJON/blob/master/specification/obsolete/PJON-protocol-specification-v0.3.md" target="_blank" rel="noopener noreferrer">PJON v0.3</a> was the result of the most interesting proposal I have received so far, by Fred Larsen, who is a great friend already even if we never met personally. He proposed the addition of a 8 bits header containing a map of the fields contained in the packet and the configuration requested by the sender. At this point we left a fixed configuration scenario, where interoperability was impossible, heading towards a dynamic network architecture. An entire new set of possibilities opened up and users started to make use of this new field.
            </p>
          </article>
        </div>
      </section>
      <section>
        
      </section>
      <section>
        <div>
          <article>
            <h2>2016 - PJON over the internet</h2>
            <p>
              <a href="https://github.com/gioblu/PJON/tree/master/src/strategies/EthernetTCP">EthernetTCP</a> and <a href="https://github.com/gioblu/PJON/tree/master/src/strategies/LocalUDP">LocalUDP</a> made by Fred Larsen enabled multiple devices with Ethernet ports use PJON to communicate with each other on a LAN, WAN or across the Internet. It became possible to create a PJON network of devices using also an Internet connection. Our constantly growing community has already provided PJON implementations in other programming languages like <a href="https://github.com/Girgitt/PJON-python">PJON-python</a> by Zbigniew Zasieczny and <a href="https://github.com/Matheus-Garbelini/PJON-C">PJON-c</a> by Matheus Garbelini. Thanks to their work, it was for the first time possible to run PJON on a wider range of devices. At the same time the protocol reached its first stable version with the release of the <a href="https://github.com/gioblu/PJON/blob/master/specification/obsolete/PJON-protocol-specification-v1.0.md" target="_blank" rel="noopener noreferrer">PJON v1.0</a> which added a lot of new features.
            </p>
          </article>
          <br>
          <article>
            <h2>2017 - Let's make it universal</h2>
            <p>
              New features brought new objectives: the community wanted to have <a href="https://github.com/gioblu/PJON">PJON</a> working on many different MCUs and real time operative systems although I wanted to avoid code duplication and maintain only one unified implementation. For this reason I defined the <a href="https://github.com/gioblu/PJON/tree/master/src/interfaces">interface</a> abstraction. With interfaces it was for the first time possible to run and cross-compile the same implementation on all supported targets. I developed the <a href="https://github.com/gioblu/PJON/tree/master/src/interfaces/RPI">RPI</a> interface to support Raspberry Pi, after few weeks Zbigniew Zasieczny developed the <a href="https://github.com/gioblu/PJON/tree/master/src/interfaces/WINX86">WINX86</a> interface enabling PJON communication on Windows computers, and soon after, Fred Larsen developed the <a href="https://github.com/gioblu/PJON/tree/master/src/interfaces/LINUX">LINUX</a> interface. In late 2017 I discovered that frame inizialization was missing from both the specification and the implementation and that arbitrary data could have been mistaken for a valid frame. I vividly remember how shocked I was, that was a serious hole, so I quickly found a way to safely identify frames in each strategy. After that was fixed and all seemed perfect I discovered the <a href="https://betterembsw.blogspot.com/2012/02/can-protocol-vulnerabilities.html">length corruption vulnerability</a> that affected PJON and still affects CAN (Controlled Area Network). To close that hole I added an additional CRC8 to protect the header and soon after I released <a href="https://github.com/gioblu/PJON/blob/9.0/specification/PJON-protocol-specification-v2.0.md">PJON v2.0</a>.
            </p>
          </article>
        </div>
      </section>
      <section>
        
      </section>
      <section>
        <div>
          <article>
            <h2>2018 - Distributed field test</h2>
            <p>
              Although PJON is licensed "AS IS", the more it was applied in the real world, the more I was feeling the responsibility for possible failures. When in 2018 Fred Larsen used PJON and <a href="https://github.com/fredilarsen/ModuleInterface">ModuleInterface</a> to handle the life support systems of his hens' house in Norway I started to be preoccupied for those animals and be finally aware of the potential consequencies and the risks involved in PJON real world applications, specially if dealing with living beings. If for whatever reason the temperature value transmitted was corrupted by interference or because of a bug, the hens could have ended up frozen or roasted. The conception of this possibility pushed me to study deeper the implementation and make better software.
            </p>
          </article>
          <br>
          <article>
            <h2>2019 - PJON in the top ten</h2>
            <p>
              After the release of <a href="https://github.com/gioblu/PJON/releases/tag/12.0">PJON 12.0</a>, in November 2019, unexpectedly, we experienced a 25% growth of the community in few days. The right <a href="https://news.ycombinator.com/item?id=21427013">HN post</a> and few reddit discussions ‚Ä¶</p></article></div></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.pjon.org/how.php">https://www.pjon.org/how.php</a></em></p>]]>
            </description>
            <link>https://www.pjon.org/how.php</link>
            <guid isPermaLink="false">hacker-news-small-sites-25485943</guid>
            <pubDate>Sun, 20 Dec 2020 13:02:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Python Print() and Beyond]]>
            </title>
            <description>
<![CDATA[
Score 44 | Comments 17 (<a href="https://news.ycombinator.com/item?id=25485916">thread link</a>) | @josiasaurel
<br/>
December 20, 2020 | https://josiasdev.best/python-print-and-beyond | <a href="https://web.archive.org/web/*/https://josiasdev.best/python-print-and-beyond">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><section itemprop="articleBody mainEntityOfPage"><div><div><div><div><p>Subscribe to <!-- -->my<!-- --> newsletter and never miss <!-- -->my<!-- --> upcoming articles</p></div></div></div><div itemprop="text"><h2 id="beyond-the-print-function-in-python">Beyond the <code>print()</code> function in <em>Python</em></h2>
<p>Hey guys, today I am going to talk about some features of the <code>print()</code> function in python. You will probably have come across some of these functions while others could seem new.</p>
<p>Let's start by understanding the basics of the print function. 
In python, the built-in print function is used to print all kinds of stuff - text, numbers, objects, dictionaries etc.
But how does this function handle that ?! You might think; it just can do it, it was made for that. But in reality, the print function in python can only handle strings.</p>
<p>Under the hood, anything you pass to the <code>print()</code> function gets converted to a string before being printed to your screen. That mean it will make use of the <code>str()</code> type casting and convert all other data types to strings before displaying them to your console/terminal.
Now that you know how the <code>print()</code> work, let's dive into its features.</p>
<p>Furthermore, print doesn't know how to print text to the screen. I won't go detail into that for now. Later in this post, you will know what happens under it.</p>
<p>Basically, you can print whatever you want . The simplest example you have come across is <code>print("Hello World!")</code>
It take a string enclosed in double quotes or single quotes and prints it.
You can also print multiple stuff by simply separating them with comas as such :</p>
<pre><code>name = <span>"Mike"</span>
age = <span>24</span>
print(<span>"Hello"</span>, name, <span>"Your age is"</span>, age)

</code></pre>
<p>You can as well print text that takes more than a line. In this case, you will be using the newline escape character <code>\n</code>
Example :</p>
<pre><code>print(<span>"Hello \nWorld"</span>)



</code></pre>
<p>You can also format text with it. Making use of <code>f-strings</code></p>
<pre><code>name = <span>"Samson"</span>
print(<span>f"Hello <span>{name}</span>"</span>)

</code></pre>
<p>The example above showcase the basics of the print function. It can take a variable number of values to print. Other than that, there are also some keyword arguments.
Let's dive into them</p>
<h2 id="1-separator">1. Separator</h2>
<p><code>print()</code> allows you to decide what separates text we print with it. By default, all the values you pass to it are separated by empty strings. But we change that. It suffices to include <code>sep=</code> followed by whatever you want to separate your text.
Let's make use of the previous example.</p>
<pre><code>name = <span>"Mike"</span>
age = <span>24</span>
print(<span>"Hello"</span>, name, <span>"Your age is"</span>, age, sep=<span>"-"</span>)

</code></pre>
<p>You notice that all what we passed into it separately are separated by a <code>-</code>. You can modify that however you want. You just need to make sure the separator is a valid string.</p>
<h2 id="2-ending">2. Ending</h2>
<p>You can specify by whatever you want your output to end with. By default, what you print end with a newline escape character <code>\n</code>. Let's change that and see what happens</p>
<pre><code>
print(<span>"Hello James"</span>)
print(<span>"How are you doing"</span>)





print(<span>"Hello James"</span>, end=<span>""</span>)
print(<span>"How are you doing"</span>, end=<span>""</span>)


</code></pre>
<p>If we execute that, we notice the text is no more separated by a new line. Let's try that again! But this time, we want it to end by <code>y</code> and move to a new line.</p>
<pre><code>print(<span>"Hello James"</span>, end=<span>"y\n"</span>)
print(<span>"How are you doing"</span>, end=<span>"\n"</span>)
</code></pre>
<p>We get the following output</p>
<pre><code><span>Hello</span> Jamesy
How are you doingy
</code></pre><p>Yay it worked !</p>
<h2 id="3-writing-to-a-file">3. Writing to a file</h2>
<p>At the beginning of this post, I said python doesn't know how to print stuff to the screen by itself. It rather uses <code>sys.stdout</code> and writes your text to that file. 
Wait what ! Print will write text to a file object which I sent to your screen via <code>sys.stdout</code>. Therefore, you can modify this behaviour too in order to have this printed elsewhere.
Let's give it a try.
Write the following code:</p>
<pre><code><span>with</span> open(<span>"hello.txt"</span>, <span>"w"</span>) <span>as</span> file_object:
        print(<span>"This message is for you"</span>, file=file_object)
</code></pre>
<p>Executing the above will end in a file name <code>hello.text</code> in the same directory with the text <em>This message is for you</em> in it. 
Therefore, we can direct where we want our text to be printed. In this case, we created a file name <code>hello.txt</code> and use the <code>file</code> keyword argument to direct the result to be written to that file rather than our terminal. You can use this to direct any result to wherever you want, even through a socket connection.</p>
<h2 id="4-flushing">4. Flushing</h2>
<p>This one requires an example. Let's have one!</p>
<pre><code><span>import</span> time

names = [<span>"John"</span>, <span>"Sylvia"</span>, <span>"Smith"</span>]

<span>for</span> name <span>in</span> names:
    print(name, end=<span>" "</span>)
    time.sleep(<span>1</span>)
</code></pre>
<p>What this code should do is; print a name after a second. Try and run it and see what happens. 
You notice it unexpectedly waits and print all at once.  This is because since it's on a single line, it is all buffered (packed) before we get it. 
<a target="_blank" href="https://en.m.wikipedia.org/wiki/Data_buffer#:~:text=In%20computer%20science%2C%20a%20data,from%20one%20place%20to%20another.&amp;text=However%2C%20a%20buffer%20may%20be,comparable%20to%20buffers%20in%20telecommunication.">Read more about buffers here</a>
But we could go around that by simply adding the <code>flush=</code> keyword argument to the print function. By default it it set to <code>False</code>. Setting it to true will ensure every print statement is executed and freed from buffer before the next one.
The following code will make it :</p>
<pre><code><span>import</span> time

names = [<span>"John"</span>, <span>"Sylvia"</span>, <span>"Smith"</span>]

<span>for</span> name <span>in</span> names:
    print(name, end=<span>", "</span>, flush=<span>True</span>)
    time.sleep(<span>1</span>)
</code></pre>
<p>If you run it. It will print a name, sleep for a second and print another, all on the same line. 
Yay we did it !</p>
<p>You have reached the end of this post. 
<a target="_blank" href="https://ko-fi.com/S6S01ULOV"><img src="https://www.ko-fi.com/img/githubbutton_sm.svg" alt="ko-fi"></a></p>
</div></div></section></div></div>]]>
            </description>
            <link>https://josiasdev.best/python-print-and-beyond</link>
            <guid isPermaLink="false">hacker-news-small-sites-25485916</guid>
            <pubDate>Sun, 20 Dec 2020 12:53:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Building a simple neural net in Java]]>
            </title>
            <description>
<![CDATA[
Score 131 | Comments 51 (<a href="https://news.ycombinator.com/item?id=25485841">thread link</a>) | @wheresvic4
<br/>
December 20, 2020 | https://smalldata.tech/blog/2016/05/03/building-a-simple-neural-net-in-java | <a href="https://web.archive.org/web/*/https://smalldata.tech/blog/2016/05/03/building-a-simple-neural-net-in-java">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            

            <p>
            In this post we will tackle Artificial Intelligence with baby steps and try to build a very simple neural net in Java.
            </p>

            <h5 id="what-is-a-neural-net">What is a Neural net?</h5>

            <p>
            A neural net is a software representation of how the brain works. Unfortunately, we do not know as of yet how exactly does the brain really work but we do know a little bit of the biology behind this process: the human brain consists of 100 billion cells called neurons, connected together by synapses. If sufficient synapses connected to a neuron fire, then that neuron will also fire. This process is known as "thinking".
            </p>

            <p>
            We thus try and model the above process using a very simple example that has 3 inputs (synapses) and results in a single output (1 neuron firing).

            <img alt="Neural net example" src="https://smalldata.tech/img/blog/nn-1-simple-problem.png" width="400">
            </p>



            <h5 id="a-simple-problem">A simple problem</h5>

            <p>
            We will train our above neural net to solve the following problem. Can you figure out the pattern and guess what the value of the new input should be? 0 or 1?
            </p>

            <div>
              <table>
              <tbody><tr>
                <th>Examples</th>
                <th colspan="3">Input</th>
                <th>Output</th>
              </tr>
              <tr>
                <td>Example 1</td>
                <td>0</td>
                <td>0</td>
                <td>1</td>
                <td>0</td>
              </tr>

              <tr>
                <td>Example 2</td>
                <td>1</td>
                <td>1</td>
                <td>1</td>
                <td>1</td>
              </tr>

              <tr>
                <td>Example 3</td>
                <td>1</td>
                <td>0</td>
                <td>1</td>
                <td>1</td>
              </tr>

              <tr>
                <td>Example 4</td>
                <td>0</td>
                <td>1</td>
                <td>1</td>
                <td>0</td>
              </tr>

              <tr>
                <td colspan="5">&nbsp;</td>
              </tr>

              <tr>
                <td>New situation</td>
                <td>1</td>
                <td>1</td>
                <td>0</td>
                <td>?</td>
              </tr>

              </tbody></table>
            </div>

            <p>
            The answer is actually very simply the value of the left-most column, i.e. 1!
            </p>


            <h5 id="training-process">The training process</h5>

            <p>
            So now that we have the model of a human brain, we will try and get our neural net to learn what the pattern is given the training set. We will first assign each input a random number to produce an output.
            </p>

            <p><img alt="Neural net example" src="https://smalldata.tech/img/blog/nn-1-simple-problem-neuron-weights.png" width="400"></p><p>
            The formula for calculating the output is given as follows:
            $$\sum weight_i . input_i = weight1 . input1 + weight2 . input2 + weight3 . input3$$
            </p>

            <p>
            As it turns out we would like to normalize this output value to something between 0 and 1 so that the prediction makes sense. After normalization we compare the output with the expected output of our inputs. This gives us the error, or how far off is our prediction. We can then use this error to slightly adjust the weights of our neural net and try our luck on the same input again. This can be summarized in the following image:
            </p>

            <!--
            <div>
                <a class="image-popup-no-margins" href="/img/blog/nn-1-training-process.png">
                    <img class="img-responsive centered img-border" alt="Neural net training process" src="/img/blog/nn-1-training-process.png" />
                </a>
                <div class="img-desc">
                </div>
            </div>
            -->

            <p><img alt="Neural net training process" src="https://smalldata.tech/img/blog/nn-1-training-process.png" width="450"></p><p>
            We repeat this training process for all the inputs <i><b>10,000 times</b></i> to reach a satisfactorily trained neural net. We can then use this neural net to make predictions on new inputs!
            </p>

            <p>
            Before we jump into the implementation however, we still need to clarify how we achieved the normalization and the weight adjustment based on the error (also known as back-propagation).
            </p>

            <h5 id="normalization">Normalization</h5>

            <p>
            In a biologically inspired neural network, the output of a neuron is usually an abstraction representing the rate of action potential firing in the cell. In its simplest form, this is binary value, i.e., either the neuron is firing or not. Hence, the need for normalization of this output value.
            </p>

            <p>
            To achieve this normalization we apply what is known as an activation function to the output of the neuron. If we take the example of a really simple Heaviside step function which assigns a 0 to any negative value and a 1 to any positive value, then a large number of neurons would be required to achieve the required granularity of slowly adjusting the weights to reach an acceptable consensus of the training set.
            </p>

            <p>
            As we will see in the next section on back-propagation, this concept of slowly adjusting the weights can be represented mathematically as the slope of the activation function. In biological terms, it can be thought of as the increase in firing rate that occurs as input current increases. If we were to use a linear function instead of the Heaviside function, then we would find that the resulting network would have an unstable convergence because neuron inputs along favored paths would tend to increase without bound, as a linear function is not normalizable.
            </p>

            <p>
            All problems mentioned above can be handled by using a normalizable sigmoid activation function. One realistic model stays at zero until input current is received, at which point the firing frequency increases quickly at first, but gradually approaches an asymptote at 100% firing rate. Mathematically, this looks like:
            $$ \frac{1}{1 + e^{-x}} $$
            </p>

            <p>
            If plotted on a graph, the Sigmoid function draws an S shaped curve:
            </p>

            <p><img alt="sigmoid plot" src="https://smalldata.tech/img/blog/nn-1-sigmoid-plot.png" width="450"></p><p>
            Thus, the final formula for the output of a neuron now becomes
            $$ Output = \frac{1}{1 + e^{-(\sum weight_i . input_i)}} $$
            </p>

            <p>
            There are other normalization functions that we can use but the sigmoid has the advantage of being fairly simple and also having a simple derivative which will be useful when we look at the back propagation below.
            </p>

            <h5 id="back-propagation">Back-propagation</h5>

            <p>
            During the training cycle, we adjusted the weights depending on the error. To do this, we can use the "Error weighted derivative" formula
            $$ Adjustment = error . input . SigmoidCurveGradient(output) $$
            </p>

            <p>
            The reason we use this formula is that firstly, we want to make the adjustment proportional to the size of the error. Secondly, we multiply by the input, which is either a 0 or a 1. If the input is 0, the weight isn‚Äôt adjusted. Finally, we multiply by the gradient of the Sigmoid curve (or the derivative).
            </p>

            <p>
            The reason that we use the gradient is because we are trying to minimize the loss. Specifically, we do this by a <a href="https://en.wikipedia.org/wiki/Gradient_descent">gradient descent method</a>. It basically means that from our current point in the parameter space (determined by the complete set of current weights), we want to go in a direction which will decrease the loss function. Visualize standing on a hillside and walking down the direction where the slope is steepest. The gradient descent method as applied to our neural net is illustrated as follows:
            </p><ol>
                <li>If the output of the neuron is a large positive or negative number, it signifies the neuron was quite confident one way or another.</li>
                <li>From the sigmoid plot, we can see that at large numbers the Sigmoid curve has a shallow gradient.</li>
                <li>Thus, if the neuron is confident that the existing weight is correct, it doesn‚Äôt want to adjust it very much and multiplying by the gradient of the sigmoid curve achieves this.</li>
            </ol>
            

            <p>
            The derivative of the sigmoid function is given by the following formula
            $$ SigmoidCurveGradient(output) = output . (1 - output) $$
            Substituting this back into the adjustment formula gives us
            $$ Adjustment = error . input . output . (1 - output) $$
            </p>

            <h5 id="code">Code</h5>

            <p>
            An important but subtle point that was missed out when explaining the mathematics above was that for each training iteration, the mathematical operations are done on the entire training set at the same time. Thus, we will make use of matrices to store the set of input vectors, the weights and the expected outputs.
            </p>

            <p>
            You can grab the entire project source here: <a href="https://github.com/wheresvic/neuralnet">https://github.com/wheresvic/neuralnet</a>. For the sake of learning, we implemented all the math ourselves using only the standard java Math functions :)
            </p>

            <p>
            We will begin with the <code>NeuronLayer</code> class which is just a placeholder for the weights in our neural net implementation. We provide it with the number of inputs per neuron and the number of neurons which it can use to build a table of the weights. In our current example, this is very simply the last output neuron which has the 3 input neurons.
            </p>

<pre>public class NeuronLayer {

    public final Function<double, double=""> activationFunction, activationFunctionDerivative;

    double[][] weights;

    public NeuronLayer(int numberOfNeurons, int numberOfInputsPerNeuron) {
        weights = new double[numberOfInputsPerNeuron][numberOfNeurons];

        for (int i = 0; i &lt; numberOfInputsPerNeuron; ++i) {
            for (int j = 0; j &lt; numberOfNeurons; ++j) {
                weights[i][j] = (2 * Math.random()) - 1; // shift the range from 0-1 to -1 to 1
            }
        }

        activationFunction = NNMath::sigmoid;
        activationFunctionDerivative = NNMath::sigmoidDerivative;
    }

    public void adjustWeights(double[][] adjustment) {
        this.weights = NNMath.matrixAdd(weights, adjustment);
    }
}
</double,></pre>

            <p>
            Our neural net class is where all the action happens. It takes as a constructor the <code>NeuronLayer</code> and has 2 main functions:
            </p><ul>
                <li><code>think</code>: calculates the outputs of a given input set</li>
                <li><code>train</code>: runs the training loop <code>numberOfTrainingIterations</code> times (usually a high number like 10,000). Note that the training itself involves calculating the output and then adjusting the weights accordingly</li>
            </ul>
            

<pre>public class NeuralNetSimple {

    private final NeuronLayer layer1;
    private double[][] outputLayer1;

    public NeuralNetSimple(NeuronLayer layer1) {
        this.layer1 = layer1;
    }

    public void think(double[][] inputs) {
        outputLayer1 = apply(matrixMultiply(inputs, layer1.weights), layer1.activationFunction);
    }

    public void train(double[][] inputs, double[][] outputs, int numberOfTrainingIterations) {
        for (int i = 0; i &lt; numberOfTrainingIterations; ++i) {

            // pass the training set through the network
            think(inputs);

            // adjust weights by error * input * output * (1 - output)

            double[][] errorLayer1 = matrixSubtract(outputs, outputLayer1);
            double[][] deltaLayer1 = ‚Ä¶</pre></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://smalldata.tech/blog/2016/05/03/building-a-simple-neural-net-in-java">https://smalldata.tech/blog/2016/05/03/building-a-simple-neural-net-in-java</a></em></p>]]>
            </description>
            <link>https://smalldata.tech/blog/2016/05/03/building-a-simple-neural-net-in-java</link>
            <guid isPermaLink="false">hacker-news-small-sites-25485841</guid>
            <pubDate>Sun, 20 Dec 2020 12:37:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Meritocracies Are Unfair ‚Äì and That's the Point]]>
            </title>
            <description>
<![CDATA[
Score 57 | Comments 98 (<a href="https://news.ycombinator.com/item?id=25485766">thread link</a>) | @whack
<br/>
December 20, 2020 | https://outlookzen.com/2020/12/20/meritocracies-are-unfair-and-thats-the-point/ | <a href="https://web.archive.org/web/*/https://outlookzen.com/2020/12/20/meritocracies-are-unfair-and-thats-the-point/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<figure><a href="https://en.as.com/en/2020/04/13/other_sports/1586800170_771249.html" target="_blank"><img data-attachment-id="1212" data-permalink="https://outlookzen.com/bolt/" data-orig-file="https://outlookzen.files.wordpress.com/2020/12/bolt.jpeg" data-orig-size="1242,1114" data-comments-opened="0" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="bolt" data-image-description="" data-medium-file="https://outlookzen.files.wordpress.com/2020/12/bolt.jpeg?w=300" data-large-file="https://outlookzen.files.wordpress.com/2020/12/bolt.jpeg?w=1024" src="https://outlookzen.files.wordpress.com/2020/12/bolt.jpeg?w=1024" alt="" srcset="https://outlookzen.files.wordpress.com/2020/12/bolt.jpeg?w=1024 1024w, https://outlookzen.files.wordpress.com/2020/12/bolt.jpeg?w=150 150w, https://outlookzen.files.wordpress.com/2020/12/bolt.jpeg?w=300 300w, https://outlookzen.files.wordpress.com/2020/12/bolt.jpeg?w=768 768w, https://outlookzen.files.wordpress.com/2020/12/bolt.jpeg 1242w" sizes="(max-width: 1024px) 100vw, 1024px"></a></figure>



<p>When your father suffers a heart attack and needs emergency surgery, who would you rather have operating on him?</p>



<p>An inspiring doctor who lost an arm in a tragic car accident, and still heroically manages to attain an average level of success as a surgeon?<br>Or the son of a multimillionaire who has breezed through life with minimal setbacks, and boasts one of the best surgical track records?</p>



<hr>



<p>There is a common perception that a meritocracy is the most fair way to run society. That because we are avoiding bias and favoritism and picking candidates purely based on their capabilities and achievements, a meritocratic system is the most fair of all.&nbsp;</p>



<p>Such a belief is hogwash. There‚Äôs nothing ‚Äúfair‚Äù about not selecting the surgeon who lost his arm in a car accident, and is now trying desperately to hold on to his career. There‚Äôs nothing fair about the fact that some people are born into good circumstances which confer a tremendous headstart in life. There‚Äôs nothing fair about the fact that so many of society‚Äôs most accomplished individuals grew up in upper-middle-class families that nurtured them, raised them well, and gave them access to highly regarded schools and teachers.</p>



<p>A meritocracy never was, and never will be, ‚Äúfair‚Äù. <strong>And that‚Äôs the whole point.</strong></p>



<p>The reason meritocracies work so well, is not because they are fair, but because they produce peak performance.</p>



<p>NFL teams draft the ‚Äúbest‚Äù players they can find, because they know that‚Äôs how they can win the most games. Universities grant tenure to the most productive professors, because that will best enhance the University‚Äôs reputation, and further the frontiers of knowledge. Hospitals hire the best doctors, because they can save the most lives.&nbsp;</p>



<p>Hiring people who are ‚Äúgood enough‚Äù is simply not good enough. There has never been, and never will be, a team that won the world cup by selecting players who are ‚Äúgood enough.‚Äù And what‚Äôs true for a kid‚Äôs game, is doubly true for our society. A society should delegate its jobs to those who are smartest, most capable, and most accomplished in that field. Because they are the ones who can best lead society through the worldly challenges we face everyday. Corrupting this process by discriminating on the basis of family ties, personal friendships, wealth, race, or gender, is simply cutting your nose to spite your face.</p>



<p>Which is not to say that ‚Äúfairness‚Äù and Social Justice isn‚Äôt important. It is vital. But you don‚Äôt get to it by hiring less qualified candidates. By turning down the best possible candidate in favor of someone who is more sympathetic and ‚Äúgood enough‚Äù. A meritocracy excels at producing wealth and economic prosperity. Universal basic income, universal healthcare, unemployment insurance, better public schooling and free job trainings‚Ä¶ these are the kind of Social Justice programs that can share the resulting prosperity among everyone.</p>



<p>Social justice teaches us how to distribute the pie fairly, so that no one is left behind. This is absolutely essential, and something we should always keep in mind. But social justice doesn‚Äôt have all the answers on how to grow the pie in the first place. And unless we harness the power of a meritocracy to keep the pie growing, we will all soon be fighting over scraps.</p>



<hr>



<p><a rel="noreferrer noopener" href="https://news.ycombinator.com/item?id=25485766" target="_blank"><em>Discussion thread on HackerNews</em></a></p>



<p><em><strong>Addendum</strong>: This article‚Äôs thesis is that we should select/hire candidates who will perform best in the role, regardless of their personal circumstances. Many have mentioned that traditional methods of assessment may be flawed, incomplete, or biased. In accordance with the thesis, we should certainly strive to refine our assessment methods, and continually make them more accurate. This article is certainly not stating that current methods of assessment are perfect.</em></p>



<p><em>Many have also brought up the point that personal circumstances often do impact job performance. For example, <a rel="noreferrer noopener" href="https://www.gsb.stanford.edu/insights/diversity-work-group-performance" target="_blank">some studies have suggested that diverse teams perform better than homogenous teams</a>, especially in certain job roles. If you are an ardent believer in improving team performance, this would mean taking into account any demographic info that would help the organization perform better. This is also a double-edged sword for a couple reasons:<br>1. By legalizing the use of race or gender as a factor in hiring decisions, you would also be enabling prejudiced employers who discriminate against women or minorities, for purely bigoted reasons<br>2. <a rel="noreferrer noopener" href="https://archive.boston.com/news/globe/ideas/articles/2007/08/05/the_downside_of_diversity/" target="_blank">Studies have also found that communities operate better in some ways, when they are more homogenous</a>. If more such studies are unearthed in future, the same reasoning above could be used to justify discriminating against all women and people of color. Something most of us, including myself, would consider to be dystopian.</em></p>
	</div><div>
				<p><strong>Published</strong>
			<time datetime="2020-12-20T07:05:42-05:00">December 20, 2020</time><time datetime="2020-12-21T08:16:07-05:00">December 21, 2020</time>		</p><!-- .site-posted-on -->
	</div></div>]]>
            </description>
            <link>https://outlookzen.com/2020/12/20/meritocracies-are-unfair-and-thats-the-point/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25485766</guid>
            <pubDate>Sun, 20 Dec 2020 12:19:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Raspberry Pi Server Mark III]]>
            </title>
            <description>
<![CDATA[
Score 311 | Comments 155 (<a href="https://news.ycombinator.com/item?id=25485428">thread link</a>) | @homarp
<br/>
December 20, 2020 | https://uplab.pro/2020/12/raspberry-pi-server-mark-iii/ | <a href="https://web.archive.org/web/*/https://uplab.pro/2020/12/raspberry-pi-server-mark-iii/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-597">
								
				<div>
					
<figure><img loading="lazy" width="1024" height="681" src="https://uplab.pro/wp-content/uploads/2020/12/UPTIME-Raspberry-Pi-Platform-pi18nossd-v1.0-1024x681.jpg" alt="" srcset="https://uplab.pro/wp-content/uploads/2020/12/UPTIME-Raspberry-Pi-Platform-pi18nossd-v1.0-1024x681.jpg 1024w, https://uplab.pro/wp-content/uploads/2020/12/UPTIME-Raspberry-Pi-Platform-pi18nossd-v1.0-300x200.jpg 300w, https://uplab.pro/wp-content/uploads/2020/12/UPTIME-Raspberry-Pi-Platform-pi18nossd-v1.0-768x511.jpg 768w, https://uplab.pro/wp-content/uploads/2020/12/UPTIME-Raspberry-Pi-Platform-pi18nossd-v1.0-1536x1022.jpg 1536w, https://uplab.pro/wp-content/uploads/2020/12/UPTIME-Raspberry-Pi-Platform-pi18nossd-v1.0.jpg 1669w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<p>Raspberry Pi Rack Server Mark I –∏ Mark II have been working pretty nice for 6 month already. Both of them are based on a model which I found on <a href="https://thingiverse.com/" data-type="URL" data-id="https://thingiverse.com">thingiverse.com</a> and inherited the basic design idea.</p>



<p>With Mark III, I completely rethought the design, which allowed to:</p>



<ul><li>increase the number of raspberries in 2 rack units</li><li>significantly reduce printing time and plastic consumption</li><li>significantly reduce the time required for assembling and disassembling the server</li><li>reduce the number of parts</li><li>implement a modular design, which means that MARK III will be available in various modifications</li></ul>



<p>I‚Äôm glad to present the first basic model, designed for 14x of Raspberry Pi and 14x of a standard 2.5‚Ä≥ SSD.</p>



<p>BTW I will be glad if you subscribe to my instagram <a rel="noreferrer noopener" href="https://www.instagram.com/uptime.lab/" target="_blank">instagram.com/uptime.lab</a> your feedback and likes are very important for me!</p>










<figure><a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" target="_blank" rel="noopener noreferrer"><img loading="lazy" width="179" height="82" src="https://uplab.pro/wp-content/uploads/2020/10/image-1.png" alt=""></a></figure>



<p>Printing recommendations:</p>



<ul><li>layer height 0.15mm</li><li>wall thickness &nbsp;0.6mm</li><li>no supports</li><li>horizontal expansion &nbsp;-0.1mm</li><li>without a skirt&nbsp;&nbsp;</li></ul>



<p>Please print one Tray and one Body part first and have a look at how they fit each other, as well as how it works with Raspberry Pi and your SSD.</p>



<p>Screws and other parts:</p>



<ul id="block-9f0674bd-8795-4e10-ada2-1c682dcbc328"><li>Set of 5 fans <a rel="noreferrer noopener" href="https://www.amazon.de/gp/product/B00NTUJZ36" target="_blank">Arctic F8 Value Pack, ACFAN0 0061 A</a>&nbsp;‚Äì&nbsp;<strong>‚Ç¨17.60 incl. VAT</strong></li><li>Power supply for fans&nbsp;<a rel="noreferrer noopener" href="https://www.amazon.de/gp/product/B07MJQ8K4P" target="_blank">12V2A 7Tipps</a>&nbsp;‚Äì&nbsp;<strong>EUR 13.99 incl. VAT</strong></li><li>Adapter with 1 to 6 fans. Cutting off the extra one turns out perfect for my purposes&nbsp;<a rel="noreferrer noopener" href="https://www.amazon.de/gp/product/B003UU6EQQ" target="_blank">L√ºfter Adapterkabel 3Pin auf 6x 3Pin Molex (6x15cm)</a>&nbsp;‚Äì&nbsp;<strong>‚Ç¨4.40 incl. VAT</strong></li><li>Screws for fans M4 12mm 10 pcs. with nuts</li><li>Threaded rod M5 ~452mm &nbsp;2 pcs. and 4pcs nuts M5</li><li>20 screws for fans for plastic (usually come with fans) Like that <a rel="noreferrer noopener" href="https://www.amazon.de/-/en/StarTech-com-Case-Fan-Screws-Pack/dp/B0002AFTD6" target="_blank">StarTech.com PC Case Fan Screws (Pack of 50)</a></li><li>In case you don‚Äôt use original PoE hat you additionally need 2x M2.5 with M2.5 nut for each Raspberry</li><li>2pcs. M3 ~5mm for each SSD. Like <a rel="noreferrer noopener" href="https://www.amazon.de/-/en/Poppstar-Hard-Drive-Screws-Drives/dp/B01HBRG3W8/ref=sr_1_7?__mk_de_DE=%C3%85M%C3%85%C5%BD%C3%95%C3%91&amp;dchild=1&amp;keywords=m3+ssd+schraube&amp;qid=1608385770&amp;sr=8-7" target="_blank">Poppstar Hard Drive Screws for 3.5 Inch or 2.5 Inch Hard Drives Set of 50</a></li><li>SATA Cable Adapter, USB 3.0 to SSD&nbsp;(you don‚Äôt need model faster). Like <a href="https://www.amazon.de/-/en/Sabrent-2-5-inch-Optimized-Supports-EC-SSHD/dp/B011M8YACM/" target="_blank" rel="noreferrer noopener">Sabrent SATA Cable Adapter, USB 3.0 to SSD / 2.5-inch SATA Hard Drive Adapter</a></li></ul>




			
				</div><!-- end .entry-content -->
							</article></div>]]>
            </description>
            <link>https://uplab.pro/2020/12/raspberry-pi-server-mark-iii/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25485428</guid>
            <pubDate>Sun, 20 Dec 2020 11:08:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Writing a custom iterator in modern C++]]>
            </title>
            <description>
<![CDATA[
Score 42 | Comments 51 (<a href="https://news.ycombinator.com/item?id=25484444">thread link</a>) | @signa11
<br/>
December 19, 2020 | https://www.internalpointers.com/post/writing-custom-iterators-modern-cpp | <a href="https://web.archive.org/web/*/https://www.internalpointers.com/post/writing-custom-iterators-modern-cpp">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>‚Äî Written by Triangles on December 13, 2020 
								‚Ä¢ updated on December 19, 2020  
								‚Ä¢ ID 86 ‚Äî</p><p>An experimental Forward Iterator written from scratch to boost up hand-made containers.</p><div>
				
<!-- internalpointers responsive -->
<p>An iterator is an object that points to an element inside a container. Like a pointer, an iterator can be used to access the element it points to and can be moved through the content of the container. Each container in the C++ Standard Library provides its own iterator, as well as some methods to retrieve it. Using iterators is quite easy: obtain an instance from a container, move it around where needed and then get the pointed element.</p>
<p>Concretely, an iterator is a simple class that provides a bunch of operators: increment <code>++</code>, dereference <code>*</code> and few others which make it very similar to a pointer and the arithmetic operations you can perform on it. In fact, iterators are a generalization of pointers, which are often used as a foundation when writing the iterator itself.</p>
<p>Iterators are one of the building blocks of the Standard Library containers, but they are also useful when you want to provide the ability to iterate over elements of a custom container that you wrote yourself: this is what I want to investigate in the present article. Adding iterators to your containers will make them compatible with the <a href="https://en.cppreference.com/w/cpp/language/range-for">range-based for loops</a> and the <a href="https://en.cppreference.com/w/cpp/algorithm">C++ Algorithms library</a>: a collection of functions for searching, sorting, counting and manipulating containers, based on iterators.</p>
<h2>A dummy container for our experiments</h2>
<p>Before digging deeper, let's define a silly custom container that we want to spice up with iterators:</p>
<pre><code>class Integers
{
private:
    int m_data[200];
};
</code></pre>
<p>The <code>Integers</code> class is a wrapper around a raw array of <code>int</code>s: we want to be able to access elements of that private array through an iterator, as well as to loop over it or pass it to any of the Standard Library algorithms. Let's start by making some design decisions.</p>
<h2>Choose the nature of our iterator</h2>
<p>The first step is to choose the type of iterator we want to implement. Modern C++ defines six types:</p>
<table>
<thead><tr>
<th>#</th>
<th>Name</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td><strong><a href="https://en.cppreference.com/w/cpp/named_req/InputIterator">Input Iterator</a></strong></td>
<td>Can scan the container forward only once, can't change the value it points to (read-only);</td>
</tr>
<tr>
<td>2</td>
<td><strong><a href="https://en.cppreference.com/w/cpp/named_req/OutputIterator">Output Iterator</a></strong></td>
<td>Can scan the container forward only once, can't read the value it points to (write-only);</td>
</tr>
<tr>
<td>3</td>
<td><strong><a href="https://en.cppreference.com/w/cpp/named_req/ForwardIterator">Forward Iterator</a></strong></td>
<td>Can scan the container forward multiple times, can read and write the value it points to;</td>
</tr>
<tr>
<td>4</td>
<td><strong><a href="https://en.cppreference.com/w/cpp/named_req/BidirectionalIterator">Bidirectional Iterator</a></strong></td>
<td>Same as previous one but can scan the container back and forth;</td>
</tr>
<tr>
<td>5</td>
<td><strong><a href="https://en.cppreference.com/w/cpp/named_req/RandomAccessIterator">Random Access Iterator</a></strong></td>
<td>Same as previous one but can access the container also non-sequentially (i.e. by jumping around);</td>
</tr>
<tr>
<td>6</td>
<td><strong><a href="https://en.cppreference.com/w/cpp/named_req/ContiguousIterator">Contiguous Iterator</a></strong></td>
<td>Same as previous one, with the addition that logically adjacent elements are also physically adjacent in memory.</td>
</tr>
</tbody>
</table>
<p>The six categories are hierarchical: a Bidirectional Iterator is also a Forward Iterator and a Random Access Iterator is both a Bidirectional and a Forward Iterator and so on. Normally, all iterators are Input Iterators (1) which makes them read-only, also known as <strong>constant iterators</strong>. Iterators that both support read and write operations are also Output Iterators (2) and are called <strong>mutable iterators</strong>.</p>
<div>
<p><img src="https://raw.githubusercontent.com/monocasual/internalpointers-files/master/2020/12/iterators/iterator-hierarchy.png" alt="Iterators hierarchy"></p><p>1. Iterators hierarchy in C++. All iterators are Input Iterators, Output Iterators or both.</p>
</div><p>Input and Output iterators are often used for low-level components such as input and output streams (the so-called <strong>single-pass algorithms</strong>) and thus have limitations. We want to do more with our custom container, so we will skip those two and jump straight to the mutable Forward Iterator.</p>
<h2>Prepare the custom iterator</h2>
<p>An iterator is usually declared inside the class it belongs to, for example:</p>
<pre><code>class Integers
{
public:
    struct Iterator { /* ... */ };

    // ...
};
</code></pre>
<p>The first thing to do is to assign the iterator some properties. Until C++17 this is done by <em>tagging</em> it with the <a href="https://www.fluentcpp.com/2018/04/27/tag-dispatching/"><strong>tag dispatch</strong></a> mechanism, while C++20 uses <strong>concepts</strong>: in this article I will follow the traditional approach.</p>
<p>C++ expects some properties from an iterator:</p>
<ul>
<li><code>iterator_category</code> ‚Äî one of the six iterator categories we have seen above. The full list is available <a href="https://en.cppreference.com/w/cpp/iterator/iterator_tags">here</a>. The <code>std::forward_iterator_tag</code> tag is what we need;</li>
<li><code>difference_type</code> ‚Äî a signed integer type that can be used to identify distance between iterator steps. Our iterator is basically a wrapper around a pointer and leverages pointer arithmetic, so the default <a href="https://en.cppreference.com/w/cpp/types/ptrdiff_t"><code>std::ptrdiff_t</code></a> is a good choice;</li>
<li><code>value_type</code> ‚Äî the type the iterator iterates over. <code>int</code> in our case;</li>
<li><code>pointer</code> ‚Äî defines a pointer to the type iterated over. <code>int*</code> in our case;</li>
<li><code>reference</code> ‚Äî defines a reference to the type iterated over. <code>int&amp;</code> in our case;</li>
</ul>
<p>Translated into code:</p>
<pre><code>#include &lt;iterator&gt; // For std::forward_iterator_tag
#include &lt;cstddef&gt;  // For std::ptrdiff_t

struct Iterator 
{
    using iterator_category = std::forward_iterator_tag;
    using difference_type   = std::ptrdiff_t;
    using value_type        = int;
    using pointer           = int*;  // or also value_type*
    using reference         = int&amp;;  // or also value_type&amp;
};
</code></pre>
<h3>Why are tags useful?</h3>
<p>Some of the tags above might seem useless at first. In fact, you will notice how they will never get mentioned during the definition of our iterator. Tags are used to select the most efficient algorithm if your container is passed to one of the Standard Library functions from the <code>&lt;algorithm&gt;</code> library. Wrong tags mean sub-optimal performance! The iterator category is also used to set algorithm requirements, for example: <a href="https://en.cppreference.com/w/cpp/algorithm/fill"><code>std::fill</code></a> wants a Forward Iterator, while <a href="https://en.cppreference.com/w/cpp/algorithm/reverse"><code>std::reverse</code></a> wants a Bidirectional Iterator. Passing the wrong iterator will result in a compilation error.</p>
<h2>Define the iterator constructors</h2>
<p>All iterators must be <em>constructible</em>, <em>copy-constructible</em>, <em>copy-assignable</em>, <em>destructible</em> and <em>swappable</em>. Let's translate those requirements into code for our iterator:</p>
<pre><code>struct Iterator 
{
    // Iterator tags here...

    Iterator(pointer ptr) : m_ptr(ptr) {}

private:

    pointer m_ptr;
};
</code></pre>
<p>Easy! We just need a custom constructor to initialize the private member variable <code>m_ptr</code>, which points to an element of the <code>Integers</code> container. The custom constructor satisfies the <em>constructible</em> requirement, while all others are covered by the implicitly-declared constructors and operators kindly provided by the compiler.</p>
<h2>Implement operators</h2>
<p>We are building a mutable Forward Iterator, which inherits properties from both Input and Output Iterators. The resulting iterator must support the following operations:</p>
<ul>
<li><code>*iterator</code> and <code>iterator-&gt;x</code> ‚Äî dereferenceable, to get the value it points to;</li>
<li><code>++iterator</code> and <code>iterator++</code> ‚Äî incrementable, to move it one step forward, both prefix and postfix versions. The latter must return something dereferenceable;</li>
<li><code>iterator_a == iterator_b</code> and <code>iterator_a != iterator_b</code> ‚Äî comparable with another iterator;</li>
</ul>
<p>This is done by implementing some custom operators in the <code>Iterator</code> class, like this:</p>
<pre><code>struct Iterator 
{
    // Iterator tags here...

    // Iterator constructors here...

    reference operator*() const { return *m_ptr; }
    pointer operator-&gt;() { return m_ptr; }

    // Prefix increment
    Iterator&amp; operator++() { m_ptr++; return *this; }  

    // Postfix increment
    Iterator operator++(int) { Iterator tmp = *this; ++(*this); return tmp; }

    friend bool operator== (const Iterator&amp; a, const Iterator&amp; b) { return a.m_ptr == b.m_ptr; };
    friend bool operator!= (const Iterator&amp; a, const Iterator&amp; b) { return a.m_ptr != b.m_ptr; };     

private:

    pointer m_ptr;
};
</code></pre>
<p>As you can see every operator involves the usage of the private pointer <code>m_ptr</code>. Also, notice the <code>friend</code> declaration for the two comparison operators: this is handy way to define the operators as non-member functions, yet being able to access private parts of the <code>Iterator</code> class (rationale  <a href="https://stackoverflow.com/questions/4421706/what-are-the-basic-rules-and-idioms-for-operator-overloading/4421729#4421729">here</a>).</p>
<h2>Prepare the container</h2>
<p>Our iterator is good to go. The last step is to give our custom container the ability to create <code>Iterator</code> objects. This is done by adding two public methods <code>begin()</code> and <code>end()</code> that return instances of the <code>Iterator</code> class, representing the first and the last element respectively:</p>
<pre><code>class Integers
{
public:

    // Iterator definition here ...

    Iterator begin() { return Iterator(&amp;m_data[0]); }
    Iterator end()   { return Iterator(&amp;m_data[200]); } // 200 is out of bounds
};
</code></pre>
<p>The <code>end()</code> method returns an iterator that refers to an <em>invalid</em> memory address, past the end of our raw array. Such iterator is just a placeholder used to determine when the boundary has been reached: it should never be accessed directly.</p>

<!-- internalpointers responsive -->
<h2>Time to test our iterator</h2>
<p>Both the custom container and its iterator are now ready. Let's test them with the range-based for loop:</p>
<pre><code>Integers integers;
for (auto i : integers)
    std::cout &lt;&lt; i &lt;&lt; "\n";
</code></pre>
<p>This code will magically print the value of each integer in the container. It works because the range-based for loop is just syntactic sugar created by the compiler for the following:</p>
<pre><code>for (auto it = integers.begin(), end = integers.end(); it != end; ++it) { 
    const auto i = *it; 
    std::cout &lt;&lt; i &lt;&lt; "\n";
}
</code></pre>
<p>In words: two iterators <code>it</code> and <code>end</code> are created. The first one points to the beginning of the container, the other one points to the end. Then, on each loop, the <code>it</code> iterator is incremented until it's equal to <code>end</code>, that is until the end of the container has been reached. The actual value is obtained by dereferencing <code>it</code> in a local variable before being printed.</p>
<p>Notice how the compiler makes use of all the operators and functions we have previously implemented: the <code>begin()</code> and <code>end()</code> methods in the custom container, the ability to compare the two iterators with the <code>!=</code> operator, the ability to increment <code>it</code> with the prefix syntax and finally the ability to dereference it to grab the actual value it points to.</p>
<p>Let's now try a function from the Algorithm library, <a href="https://en.cppreference.com/w/cpp/algorithm/fill"><code>std::fill</code></a> for example:</p>
<pre><code>Integers integers;

std::fill(integers.begin(), integers.end(), 3);
</code></pre>
<p>The function assigns all elements in the container the value <code>3</code>. It works because <code>std::fill</code> is usually implemented like this:</p>
<pre><code>template &lt;typename ForwardIterator, ‚Ä¶</code></pre></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.internalpointers.com/post/writing-custom-iterators-modern-cpp">https://www.internalpointers.com/post/writing-custom-iterators-modern-cpp</a></em></p>]]>
            </description>
            <link>https://www.internalpointers.com/post/writing-custom-iterators-modern-cpp</link>
            <guid isPermaLink="false">hacker-news-small-sites-25484444</guid>
            <pubDate>Sun, 20 Dec 2020 06:46:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Knotwork Designer]]>
            </title>
            <description>
<![CDATA[
Score 45 | Comments 9 (<a href="https://news.ycombinator.com/item?id=25484101">thread link</a>) | @blewboarwastake
<br/>
December 19, 2020 | http://birrell.org/andrew/knotwork/ | <a href="https://web.archive.org/web/*/http://birrell.org/andrew/knotwork/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>http://birrell.org/andrew/knotwork/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25484101</guid>
            <pubDate>Sun, 20 Dec 2020 05:33:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Rebooting a 15 year-old game written in D ‚Äì Part 1 Compiling]]>
            </title>
            <description>
<![CDATA[
Score 103 | Comments 49 (<a href="https://news.ycombinator.com/item?id=25483693">thread link</a>) | @arunc
<br/>
December 19, 2020 | https://speps.fr/articles/torus-trooper-part1/ | <a href="https://web.archive.org/web/*/https://speps.fr/articles/torus-trooper-part1/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main-container">
        <div id="main">
            
<div id="content">
	<div id="page">
		
		
		
		
		<p>See also</p>
<ul>
<li><a href="https://speps.fr/articles/torus-trooper-part1">Part 1 - Compiling a new executable</a></li>
<li><a href="https://speps.fr/articles/torus-trooper-part2">Part 2 - Running the game for the first time</a></li>
<li><a href="https://speps.fr/articles/torus-trooper-part3">Part 3 - Porting to WebAssembly</a></li>
<li><a href="https://speps.fr/articles/torus-trooper-part4">Part 4 - Final steps</a></li>
</ul>
<p>While exploring D recently, I remembered a game I played while at university 15 years ago. For a long time, I couldn‚Äôt remember the name at all, only that it was from a Japanese developer. After some search wrangling, I finally managed to find the name of the game: <strong>Torus Trooper!</strong></p>
<p>You can find it there: <a href="http://www.asahi-net.or.jp/~cs8k-cyu/windows/tt_e.html">http://www.asahi-net.or.jp/~cs8k-cyu/windows/tt_e.html</a></p>
<p><img src="https://speps.fr/media/articles/tt1.png" alt=""></p>
<p>Here is a copy of the tt0_22.zip file archived: <a href="https://github.com/speps/tt/archive/legacy.zip">https://github.com/speps/tt/archive/legacy.zip</a></p>
<p>What made me remember this game is that :</p>
<ul>
<li>It came with <a href="https://github.com/speps/tt/tree/legacy/src/abagames">source code</a>, quite unusual at the time for me</li>
<li>Written in D, a language I didn‚Äôt know at all while I was busy studying C++</li>
<li>It‚Äôs awfully addictive!</li>
</ul>
<p>What better project than try to compile a <strong>D v0.110</strong> project in a modern version of D and possibly porting the game to WebAssembly+WebGL! So here we are‚Ä¶</p>
<h2 id="switching-from-ant-to-dub">Switching from Ant to DUB</h2>
<p>The game used Ant and its <code>build.xml</code> file to generate the executable, resources, etc. Since then, D added DUB as a build system / package manager so let‚Äôs use that!</p>
<div><div>
<table><tbody><tr><td>
<pre><code><span> 1
</span><span> 2
</span><span> 3
</span><span> 4
</span><span> 5
</span><span> 6
</span><span> 7
</span><span> 8
</span><span> 9
</span><span>10
</span><span>11
</span><span>12
</span><span>13
</span><span>14
</span></code></pre></td>
<td>
<pre><code data-lang="json"><span>{</span>
	<span>"authors"</span><span>:</span> <span>[</span>
		<span>"Kenta Cho"</span><span>,</span>
		<span>"Remi Gillig"</span>
	<span>],</span>
	<span>"copyright"</span><span>:</span> <span>"Copyright ¬© 2004 - Kenta Cho, 2020 - Remi Gillig"</span><span>,</span>
	<span>"description"</span><span>:</span> <span>"Torus Trooper (Reboot)"</span><span>,</span>
	<span>"license"</span><span>:</span> <span>"BSD 2-clause"</span><span>,</span>
	<span>"name"</span><span>:</span> <span>"tt"</span><span>,</span>
	<span>"targetType"</span><span>:</span> <span>"executable"</span><span>,</span>
	<span>"sourcePaths"</span><span>:</span> <span>[</span>
		<span>"src"</span>
	<span>]</span>
<span>}</span>
</code></pre></td></tr></tbody></table>
</div>
</div><p>With this initial <code>dub.json</code> file, I was set to run the <code>dub</code> command‚Ä¶</p>
<div><pre><code data-lang="plaintext">Performing "debug" build using C:\D\dmd2\windows\bin64\dmd.exe for x86.
tt ~master: building configuration "application"...
src\abagames\tt\barrage.d(95,33): Error: instead of C-style syntax, use D-style BulletMLParserTinyXML*[char[]][char[]] parser
src\abagames\tt\barrage.d(122,28): Error: instead of C-style syntax, use D-style BulletMLParserTinyXML*[] pl
src\abagames\tt\barrage.d(130,14): Error: instead of C-style syntax, use D-style BulletMLParserTinyXML*[char[]] pa
src\abagames\tt\boot.d(51,12): Error: instead of C-style syntax, use D-style char[4096] exe
src\abagames\tt\tunnel.d(300,14): Error: template argument expected following !
src\abagames\tt\tunnel.d(322,14): Error: template argument expected following !
src\abagames\util\rand.d(115,6): Error: instead of C-style syntax, use D-style uint[N] state
src\abagames\util\rand.d(140,20): Error: instead of C-style syntax, use D-style uint[] init_key
src\abagames\util\sdl\luminous.d(21,10): Error: instead of C-style syntax, use D-style GLuint[LUMINOUS_TEXTURE_WIDTH_MAX * LUMINOUS_TEXTURE_HEIGHT_MAX * 4 * (uint).sizeof] td
src\abagames\util\sdl\luminous.d(83,17): Error: instead of C-style syntax, use D-style float[2][2] lmOfs
C:\D\dmd2\windows\bin64\dmd.exe failed with exit code 1.
</code></pre></div><p>Alright let‚Äôs start and get this to compile!</p>
<h2 id="c-style-syntax-errors">C-style syntax errors</h2>
<p>This is one is easy to fix, the suggestion from the compiler works, I just replaced every instance of this error with the suggestion.</p>
<p>Here is an example:</p>
<div><div>
<table><tbody><tr><td>
<pre><code><span>1
</span><span>2
</span><span>3
</span><span>4
</span><span>5
</span><span>6
</span><span>7
</span><span>8
</span></code></pre></td>
<td>
<pre><code data-lang="diff"><span>@@ -42,7 +43,7 @@ struct SDL_AudioSpec {
</span><span></span>     Once the callback returns, the buffer will no longer be valid.
     Stereo samples are stored in a LRLRLR ordering.
  */
<span>- void (*callback)(void *userdata, Uint8 *stream, int len);
</span><span></span><span>+ void function(void *userdata, Uint8 *stream, int len) callback;
</span><span></span>  void  *userdata;
 }
</code></pre></td></tr></tbody></table>
</div>
</div><h2 id="error-template-argument-expected-following-">Error: template argument expected following !</h2>
<p>This is an interesting one, here is one of the files where this error triggers:</p>
<div><div>
<table><tbody><tr><td>
<pre><code><span> 1
</span><span> 2
</span><span> 3
</span><span> 4
</span><span> 5
</span><span> 6
</span><span> 7
</span><span> 8
</span><span> 9
</span><span>10
</span><span>11
</span><span>12
</span><span>13
</span><span>14
</span><span>15
</span><span>16
</span><span><span>17
</span></span><span>18
</span><span>19
</span><span>20
</span><span>21
</span></code></pre></td>
<td>
<pre><code data-lang="d">  <span>private</span> <span>void</span> <span>calcIndex</span><span>(</span><span>in</span> <span>float</span> <span>z</span><span>,</span> <span>out</span> <span>int</span> <span>idx</span><span>,</span> <span>out</span> <span>float</span> <span>ofs</span><span>)</span> <span>{</span>
    <span>idx</span> <span>=</span> <span>slice</span><span>.</span><span>length</span> <span>+</span> <span>99999</span><span>;</span>
    <span>for</span> <span>(</span><span>int</span> <span>i</span> <span>=</span> <span>1</span><span>;</span> <span>i</span> <span>&lt;</span> <span>slice</span><span>.</span><span>length</span><span>;</span> <span>i</span><span>++)</span> <span>{</span>
      <span>if</span> <span>(</span><span>z</span> <span>&lt;</span> <span>slice</span><span>[</span><span>i</span><span>].</span><span>depth</span><span>)</span> <span>{</span>
        <span>idx</span> <span>=</span> <span>i</span> <span>-</span> <span>1</span><span>;</span>
        <span>ofs</span> <span>=</span> <span>(</span><span>z</span> <span>-</span> <span>slice</span><span>[</span><span>idx</span><span>].</span><span>depth</span><span>)</span> <span>/</span> <span>(</span><span>slice</span><span>[</span><span>idx</span> <span>+</span> <span>1</span><span>].</span><span>depth</span> <span>-</span> <span>slice</span><span>[</span><span>idx</span><span>].</span><span>depth</span><span>);</span>
        <span>break</span><span>;</span>
      <span>}</span>
    <span>}</span>
    <span>if</span> <span>(</span><span>idx</span> <span>&lt;</span> <span>0</span><span>)</span> <span>{</span>
      <span>idx</span> <span>=</span> <span>0</span><span>;</span>
      <span>ofs</span> <span>=</span> <span>0</span><span>;</span>
    <span>}</span> <span>else</span> <span>if</span> <span>(</span><span>idx</span> <span>&gt;=</span> <span>slice</span><span>.</span><span>length</span> <span>-</span> <span>1</span><span>)</span> <span>{</span>
      <span>idx</span> <span>=</span> <span>slice</span><span>.</span><span>length</span> <span>-</span> <span>2</span><span>;</span>
      <span>ofs</span> <span>=</span> <span>0.99</span><span>;</span>
    <span>}</span>
<span>    <span>if</span> <span>(</span><span>ofs</span> <span>!&gt;=</span> <span>0</span><span>)</span> <span>// ERROR HERE
</span></span><span></span>      <span>ofs</span> <span>=</span> <span>0</span><span>;</span>
    <span>else</span> <span>if</span> <span>(</span><span>ofs</span> <span>&gt;=</span> <span>1</span><span>)</span>
      <span>ofs</span> <span>=</span> <span>0.99</span><span>;</span>
  <span>}</span>
</code></pre></td></tr></tbody></table>
</div>
</div><p>I did try a few searches without success so I asked on the D community forums and a few people guessed right, it‚Äôs of course a <code>not &gt;=</code>, equivalent to <code>&lt;</code>. However, <a href="https://forum.dlang.org/post/rec3d1$toc$1@digitalmars.com">thanks to Walter Bright</a>, I got a link to the <a href="https://www.digitalmars.com/ctg/ctgNumerics.html#comparisons">original documentation from Digital Mars</a>. The subtle difference with <code>!&gt;=</code> is that it will also return <code>true</code> if any operands are <code>NaN</code>. Suggested fix seems to have worked:</p>
<div><div>
<table><tbody><tr><td>
<pre><code><span>17
</span><span>18
</span></code></pre></td>
<td>
<pre><code data-lang="d">    <span>if</span> <span>(</span><span>std</span><span>.</span><span>math</span><span>.</span><span>isNaN</span><span>(</span><span>ofs</span><span>)</span> <span>||</span> <span>ofs</span> <span>&lt;</span> <span>0</span><span>)</span>
      <span>ofs</span> <span>=</span> <span>0</span><span>;</span>
</code></pre></td></tr></tbody></table>
</div>
</div><h2 id="replacing-char-with-string">Replacing <code>char[]</code> with <code>string</code></h2>
<p>D1 used to have <code>char[]</code> as the string type, and functions in <code>std.string</code> in Phobos to manipulate this type. D2 replaced this with an <code>alias string = immutable(char)[]</code>. As a result, a lot of the code needs updating to deal with this. That includes the code in the custom bindings.</p>
<p>Most of the changes here are similar to this</p>
<div><div>
<table><tbody><tr><td>
<pre><code><span> 1
</span><span> 2
</span><span> 3
</span><span> 4
</span><span> 5
</span><span> 6
</span><span> 7
</span><span> 8
</span><span> 9
</span><span>10
</span><span>11
</span><span>12
</span><span>13
</span><span>14
</span><span>15
</span><span>16
</span><span>17
</span><span>18
</span><span>19
</span><span>20
</span><span>21
</span><span>22
</span><span>23
</span><span>24
</span><span>25
</span></code></pre></td>
<td>
<pre><code data-lang="diff"><span>@@ -92,24 +91,24 @@ public class Barrage {
</span><span></span>  */
 public class BarrageManager {
  private:
<span>-  static BulletMLParserTinyXML *parser[char[]][char[]];
</span><span>-  static const char[] BARRAGE_DIR_NAME = "barrage";
</span><span></span><span>+  static BulletMLParserTinyXML*[string][string] parser;
</span><span>+  static const string BARRAGE_DIR_NAME = "barrage";
</span><span></span> 
   public static void load() {
<span>-    char[][] dirs = listdir(BARRAGE_DIR_NAME);
</span><span>-    foreach (char[] dirName; dirs) {
</span><span>-      char[][] files = listdir(BARRAGE_DIR_NAME ~ "/" ~ dirName);
</span><span>-      foreach (char[] fileName; files) {
</span><span>-        if (getExt(fileName) != "xml")
</span><span></span><span>+    string[] dirs = listdir(BARRAGE_DIR_NAME);
</span><span>+    foreach (string dirName; dirs) {
</span><span>+      string[] files = listdir(BARRAGE_DIR_NAME ~ "/" ~ dirName);
</span><span>+      foreach (string fileName; files) {
</span><span>+        if (fileName.extension != ".xml")
</span><span></span>           continue;
         parser[dirName][fileName] = getInstance(dirName, fileName);
       }
     }
   }
</code></pre></td></tr></tbody></table>
</div>
</div><h2 id="converting-value-to-string">Converting value to string</h2>
<p>D1 used to have <code>std.string.toString</code> to convert a value to a <code>char[]</code> value. This functionality was replaced by <code>std.conv.to!string</code>.</p>
<div><div>
<table><tbody><tr><td>
<pre><code><span> 1
</span><span> 2
</span><span> 3
</span><span> 4
</span><span> 5
</span><span> 6
</span><span> 7
</span><span> 8
</span><span> 9
</span><span>10
</span><span>11
</span><span>12
</span><span>13
</span><span>14
</span><span>15
</span><span>16
</span><span>17
</span></code></pre></td>
<td>
<pre><code data-lang="diff"><span>@@ -5,6 +5,7 @@
</span><span></span>  */
 module abagames.tt.shot;
 
<span>+private import std.conv;
</span><span></span> private import std.math;
 private import std.string;
 private import opengl;
<span>@@ -179,7 +180,7 @@ public class Shot: Actor {
</span><span></span>       else if (sc &gt;= 2000)
         size = 0.7;
       size *= (1 + multiplier * 0.01f);
<span>-      fl.set("X" ~ std.string.toString(multiplier), pos, size * pos.y,
</span><span></span><span>+      fl.set("X" ~ to!string(multiplier), pos, size * pos.y,
</span><span></span>              cast(int) (30 + multiplier * 0.3f));
     }
     if (chargeShot) {
</code></pre></td></tr></tbody></table>
</div>
</div><h2 id="passing-strings-to-c">Passing strings to C</h2>
<p>The usual way to pass strings to C seems to have been to just to use <code>std.string.toStringz</code>. However, back in D1 it used to return char* :</p>
<pre><code>char* toStringz(char[] s);
</code></pre><p>This worked well for the C bindings but with D2, it now returns:</p>
<pre><code>immutable(char)* toStringz(scope return string s) pure nothrow @trusted;
</code></pre><p>Again, the fix is quite straightforward. For example, the bindings weren‚Äôt written with this in mind so they need fixing:</p>
<div><div>
<table><tbody><tr><td>
<pre><code><span>1
</span><span>2
</span><span>3
</span><span>4
</span><span>5
</span><span>6
</span></code></pre></td>
<td>
<pre><code data-lang="diff"><span>@@ -81,7 +81,7 @@ struct SDL_RWops {
</span><span></span> 
 /* Functions to create SDL_RWops structures from various data sources */
 
<span>-SDL_RWops * SDL_RWFromFile(char *file, char *mode);
</span><span></span><span>+SDL_RWops * SDL_RWFromFile(const char *file, const char *mode);
</span></code></pre></td></tr></tbody></table>
</div>
</div><h2 id="simple-substitution">Simple substitution</h2>
<ul>
<li><code>typedef</code> ‚Üí <code>alias</code></li>
</ul>
<div><div>
<table><tbody><tr><td>
<pre><code><span> 1
</span><span> 2
</span><span> 3
</span><span> 4
</span><span> 5
</span><span> 6
</span><span> 7
</span><span> 8
</span><span> 9
</span><span>10
</span><span>11
</span><span>12
</span></code></pre></td>
<td>
<pre><code data-lang="diff"><span>@@ -28,10 +28,10 @@ import SDL_types;
</span><span></span> 
 extern(C):
 
<span>-typedef int (*_seek_func_t)(SDL_RWops *context, int offset, int whence);
</span><span>-typedef int (*_read_func_t)(SDL_RWops *context, void *ptr, int size, int maxnum);
</span><span>-typedef int (*_write_func_t)(SDL_RWops *context, void *ptr, int size, int num);
</span><span>-typedef int (*_close_func_t)(SDL_RWops *context);
</span><span></span><span>+alias int function(SDL_RWops *context, int offset, int whence) _seek_func_t;
</span><span>+alias int function(SDL_RWops *context, void *ptr, int size, int maxnum) _read_func_t;
</span><span>+alias int function(SDL_RWops *context, void *ptr, int size, int num) _write_func_t;
</span><span>+alias int function(SDL_RWops *context) _close_func_t;
</span></code></pre></td></tr></tbody></table>
</div>
</div><ul>
<li><code>inout</code> ‚Üí <code>ref</code>: this made sense for all instances where <code>inout</code> was used</li>
</ul>
<div><div>
<table><tbody><tr><td>
<pre><code><span>1
</span><span>2
</span><span>3
</span><span>4
</span><span>5
</span><span>6
</span><span>7
</span><span>8
</span></code></pre></td>
<td>
<pre><code data-lang="diff"><span>@@ -59,7 +59,7 @@ public class PrefData {
</span><span></span> 
   public this() {
     gradeData = new GradeData[Ship.GRADE_NUM];
<span>-    foreach (inout GradeData gd; gradeData)
</span><span></span><span>+    foreach (ref GradeData gd; gradeData)
</span><span></span>       gd = new GradeData;
   }
</code></pre></td></tr></tbody></table>
</div>
</div><ul>
<li><code>auto T</code> ‚Üí <code>auto</code>: it seems the original author specified auto along with the type which isn‚Äôt allowed anymore</li>
</ul>
<div><div>
<table><tbody><tr><td>
<pre><code><span> 1
</span><span> 2
</span><span> 3
</span><span> 4
</span><span> 5
</span><span> 6
</span><span> 7
</span><span> 8
</span><span> 9
</span><span>10
</span><span>11
</span><span>12
</span><span>13
</span><span>14
</span><span>15
</span><span>16
</span><span>17
</span><span>18
</span><span>19
</span><span>20
</span><span>21
</span><span>22
</span><span>23
</span><span>24
</span><span>25
</span></code></pre></td>
<td>
<pre><code data-lang="diff"><span>@@ -631,9 +631,9 @@ public class BulletShape: Drawable {
</span><span></span>   }
 
   private void createSquareShape(bool wireShape) {
<span>-    auto Vector3 cp = new Vector3;
</span><span>-    auto Vector3[] p = new Vector3[4];
</span><span>-    auto Vector3[] np = new Vector3[4];
</span><span></span><span>+    auto cp = new Vector3;
</span><span>+    auto p = new Vector3[4];
</span><span>+    auto np = new Vector3[4];
</span><span></span>     static const float[][][] POINT_DAT = [
       [[-1, -1, 1], [1, -1, 1], [1, 1, 1], [-1, 1, 1], ],
       [[-1, -1, -1], [1, -1, -1], [1, 1, -1], [-1, 1, -1], ],
<span>@@ -642,9 +642,9 @@ public class BulletShape: Drawable {
</span><span></span>       [[1, -1, -1], [1, -1, 1], [1, 1, 1], [1, 1, -1], ],
       [[-1, -1, -1], [-1, -1, 1], [-1, 1, 1], [-1, 1, -1], ],
     ];
<span>-    foreach (inout Vector3 ip; p)
</span><span></span><span>+    foreach (ref Vector3 ip; p)
</span><span></span>       ip = new Vector3;
<span>-    foreach (inout Vector3 inp; np)
</span><span></span><span>+    foreach (ref Vector3 inp; np)
</span><span></span>       inp = new Vector3;
     for (int i = 0; i &lt; 6; i++) {
       cp.x = cp.y = cp.z = 0;
</code></pre></td></tr></tbody></table>
</div>
</div><ul>
<li><code>getExt</code> ‚Üí <code>.extension</code>: behaviour is different but it‚Äôs easy enough to fix, it now includes the dot</li>
</ul>
<div><div>
<table><tbody><tr><td>
<pre><code><span> 1
</span><span> 2
</span><span> 3
</span><span> 4
</span><span> 5
</span><span> 6
</span><span> 7
</span><span> 8
</span><span> 9
</span><span>10
</span><span>11
</span><span>12
</span><span>13
</span><span>14
</span><span>15
</span></code></pre></td>
<td>
<pre><code data-lang="diff"><span>@@ -44,10 +45,10 @@ public class SoundManager: abagames.util.sdl.sound.SoundManager {
</span><span></span> 
   private static Music[] loadMusics() {
     Music[] musics;
<span>-    char[][] files = listdir(Music.dir);
</span><span>-    foreach (char[] fileName; files) {
</span><span>-      char[] ext = getExt(fileName);
</span><span>-      if (ext != "ogg" &amp;&amp; ext != "wav")
</span><span></span><span>+    string[] files = listdir(Music.dir);
</span><span>+    foreach (string ‚Ä¶</span></code></pre></td></tr></tbody></table></div></div></div></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://speps.fr/articles/torus-trooper-part1/">https://speps.fr/articles/torus-trooper-part1/</a></em></p>]]>
            </description>
            <link>https://speps.fr/articles/torus-trooper-part1/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25483693</guid>
            <pubDate>Sun, 20 Dec 2020 03:42:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Back to the '70s with Serverless]]>
            </title>
            <description>
<![CDATA[
Score 492 | Comments 290 (<a href="https://news.ycombinator.com/item?id=25482410">thread link</a>) | @pjmlp
<br/>
December 19, 2020 | http://evrl.com/devops/cloud/2020/12/18/serverless.html | <a href="https://web.archive.org/web/*/http://evrl.com/devops/cloud/2020/12/18/serverless.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <div>
        <div>

  

  <article>
    <p>I‚Äôve now worked with ‚ÄúThe Cloud‚Äù for long enough to see that there‚Äôs still a long way to
go before it becomes materially better than, say, the oldschool method of renting a
couple of servers with a co-location company and running your software there. The
latest fad is Serverless, which makes me feel a lot like we‚Äôve arrived in 1970.</p>

<p>A long, long time ago, I was pretending to study business administration
while teaching myself to code in C. The university was in two worlds:
we had a lab with ‚Äúpersonal computers‚Äù but also terminals to the mini
computer and assignments had to be made on either one depending on the
professors‚Äô preferences. But both systems were at least ‚Äúon-line‚Äù systems‚Äìinteractive, with immediate feedback. A friend of mine was not so lucky:
he had an assignment for one of his courses in civil engineering that
had to be completed in Pascal and had to be handed in as a print-out
from the university‚Äôs mainframe.</p>

<p>He called me in for help, because he never wrote a line of code before. So I hopped
over to his place, a Turbo Pascal floppy disk in hand, and assumed that we would
make short work of the assignment. And we did, even though I never coded in Pascal
before: the IDE, even back then, was marvellous and a quick succession of trial-and-error
got us the results we wanted (they were some simple engineering calculations, much
quicker done on even the most primitive of calculators, but such are course assignments. At
least it was easy for us to verify the program was correct).</p>

<p>We hopped into the car and drove over the the university‚Äôs computer center, a ‚Äô70s brutalist
concrete bunker. We sat behind a terminal, typed in the code, surrounded it with the required
IBM Job Control Language that the teaching assistant helpfully added to the assignment, and
hit ‚ÄúEnter‚Äù (not ‚ÄúReturn‚Äù, actually ‚ÄúEnter‚Äù - Enter The Job). A couple of minutes later, the
printer started and spit out a couple of pages. Between gibberish in all caps, there it was: a
compiler error. Back to square one - Turbo Pascal and IBM Mainframe Pascal clearly had some
differences. A couple of hours and reams of wasted paper later, we had what my friend wanted:
the results of a good run. The numbers matched our notes, and we could retreat to the nearest
bar for a well-earned beer.</p>

<p>Ever since that experience, I have stressed the value of feedback and especially of quick
feedback. Even in this minimal example, we spent more time tweaking the code for the dialect
than we spent on writing it in the first place. Slow feedback loops kill performance, and if
you don‚Äôt believe me, find an online version of <a href="https://en.wikipedia.org/wiki/Beer_distribution_game">The Beer Distribution Game</a> and play it. You‚Äôll be surprised.</p>

<p>The pinnacle of interactivity was, and still is, Smalltalk. I worked in that language for a
couple of years and having your system compile and run most of your tests in less than a second
is addictive. It is incredible how much your performance increases on a fully interactive
programming system but it takes first-hand experience to fully appreciate it. It‚Äôs a strange
system, a strange language, a tough sell; therefore Smalltalk is still in a very undeserved
state of limbo.</p>

<p>After my Smalltalk years, I met a lot of large Java systems. They started out as horrible
hairballs, but when the idea of ‚Äúdependency injection‚Äù got a foothold, things started to get
better. Except for the return of the Job Control Language, this time disguised in XML and
carrying friendlier names like ‚ÄúSpring‚Äù. Internally, the code was reasonably clean and modular,
but telling the computer how to run it took pretty much the same amount of typing, this time
not in a programming language but in a structured markup language. That language lacked all
the facilities that apply to writing good code, so principles like ‚ÄúDon‚Äôt Repeat Yourself‚Äù went
overboard and copy/paste programming ensued. New business logic? New controller, twenty lines of
Java boilerplate, 10 lines of Java business logic, 50 lines of XML to wire it to the rest of
the system.</p>

<p>At least, in hindsight, XML was a blessing: your editor would tell you whether your ‚Äúthis is
how the code is wired up‚Äù description had the right structure, and later on even whether you
used names that existed in your Java codebase.</p>

<p>These systems took ages to compile, hours to run all the unit tests, and clearly interactivity
went down the drain. So ‚Äúsplit it all up‚Äù was not a bad idea. It was an unnecessary idea, mostly
driven by the shortfalls of mainstream programming languages, but necessity is the mother of
invention - even though your average Java business app was much simpler than the Smalltalk
IDE before you added a single line of code to write your app, it was already too complex to
maintain and ‚Äúdivide and conquer‚Äù was the answer. Service Oriented Architecture, and later
microservices, was born. Split your codebase, split your teams, create a lot of opportunities
for mediocre coders to grow into mediocre engineering managers, everybody was happy. Including
your hardware vendor, because suddenly you needed much more hardware to run the same workloads. Because
networks are slow, and whereas it can be argued whether a three tier system is actually a distributed
computing system, a microservices system certainly qualifies for that label.</p>

<p>The return of the Job Control Language this time was in the form of,
again, configuration data on how to run your microservice. Microservices
were somewhat fatter than the very fine-grained objects of the old days,
so there was less of it, but still - it was there. The feedback cycle
became worse as well: in the monolith-with-XML days, your XML editor
would get you mostly there and a quick local compile and run would
leave you all but certain that your configuration was working.
XML, however, was universally rejected in favour of things like JSON, Yaml, HCL,
Toml - all free of structure, with zero indication whether a computer
would find your prose gibberish or the next Shakespeare play until
you actually pushed your code to some test cluster. It suddenly felt
a lot like being back at that university interacting with a mainframe,
but at least you still owned the hardware and could introspect all the
way down, especially if you were doing ‚ÄúDevOps‚Äù meaning mostly that you
had administrative access to your hardware.</p>

<p>Microservices have trouble scaling, and they are very complex. Most companies that employ them
have no need for them, but the systems and programming languages they employ are sufficiently
lacking that this stacking of complexity on top of complexity becomes a necessity. It seems that,
contrary to what everybody is saying, software developers are in plentiful and cheap supply so
wasting a lot of their talent makes economic sense over the perceived cost of adapting more
powerful programming systems. C‚Äôest la vie. The feedback cycle is truly broken - testing a
microservice is merely testing a cog in a machine and no guarantee that the cog will fit the
machine - but we just throw more bodies at the problem because Gartner tells us this is the future.</p>

<p>So, we‚Äôre now at the next phase of this game: maintaining these very complex systems is
hard and not your core business, so outsource it (simplifying it would cost too many managers‚Äô
jobs, so that is not an option). The Cloud was born, first as a marketing label for an old
business model (offering ‚Äúvirtual private servers‚Äù to the public), but more and more as a marketing
label for an even older business model (the mainframe - we run it, we own it, you lease capacity).</p>

<p>Apparently, <a href="https://www.dreamsongs.com/WorseIsBetter.html">Worse Is Better</a> and you can do worse than Virtual Private Servers, so through a short-lived detour through
containerizing microservices and deploying them on a distributed scheduler like Mesos, Nomad,
or Kubernetes, we have arrived at ‚ÄúServerless‚Äù. You deploy individual stateless functions. But
not inside a Java monolith, that is old, but on top of a distributed system. You would have been
laughed out of the door if you had proposed that in 2000, and you should be laughed out of the
door right now, but such is the power of marketing. So what have we now? A ‚Äúmono repo‚Äù codebase,
because clearly a Git repository per function in your system would be too much, a large deployment
descriptor per fine-grained component, which Spring maybe called ‚ÄúController‚Äù but is now called
‚ÄúFunction‚Äù, and instead
of combining them all on your desktop, you send them off to someone else‚Äôs mega-mainframe. You
deploy, get an error message, and login to CloudWatch to see what actually happened - it‚Äôs all
batch-driven, just like the bad old days, so progress is slow. At least we‚Äôre not having to
walk to the printer on every try, but that pretty much sums up the progress of the last half
century. Oh, and a ‚ÄúFunction‚Äù
will be able to handle a single request concurrently, so here‚Äôs your AWS hosting bill, we needed
a lot of instances, I hope you won‚Äôt have a heart attack. Yes, we run workloads that your nephew
can run on his Raspberry Pi 4, but this is the future of enterprise.</p>

<p>History will repeat itself, of course. Conceptually, hiding a lot of the scaling and coordination
machinery is not a bad idea; programming systems like Erlang and OTP have shown for decades how
well that can work and Elixir is giving the platform a well-deserved surge in popularity. But there‚Äôs
a big difference here: a platform like OTP handles pretty much everything that a platform like
AWS Lambda handles, but it does it in a single programming language. Tools of the trade are
available: you can refactor Erlang code, you can write Elixir macros, all to keep the system
clean, malleable, and free of <a href="https://en.wikipedia.org/wiki/No_Silver_Bullet">accidental complexity</a>.</p>

<p>It is called ‚ÄúConfiguration as Code‚Äù, and it truly is a great idea (but hardly a new one). But XML
is not code, and neither is JSON, nor YAML, nor HCL. There is an essential quality lacking in all
of these markup languages, and that causes all the copy/paste programming I am currently seeing
everywhere, whether a ‚Ä¶</p></article></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://evrl.com/devops/cloud/2020/12/18/serverless.html">http://evrl.com/devops/cloud/2020/12/18/serverless.html</a></em></p>]]>
            </description>
            <link>http://evrl.com/devops/cloud/2020/12/18/serverless.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25482410</guid>
            <pubDate>Sat, 19 Dec 2020 23:44:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[VisUAL ‚Äì A highly visual ARM emulator]]>
            </title>
            <description>
<![CDATA[
Score 87 | Comments 7 (<a href="https://news.ycombinator.com/item?id=25481614">thread link</a>) | @pjmlp
<br/>
December 19, 2020 | https://salmanarif.bitbucket.io/visual/index.html | <a href="https://web.archive.org/web/*/https://salmanarif.bitbucket.io/visual/index.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
<ul>
  <li><a href="https://salmanarif.bitbucket.io/visual/index.html">Home</a></li>
  <li><a href="https://salmanarif.bitbucket.io/visual/user_guide/index.html">User Guide</a></li>
  <li><a href="https://salmanarif.bitbucket.io/visual/downloads.html">Downloads</a></li>
  <li><a href="https://salmanarif.bitbucket.io/visual/about.html">About</a></li>
</ul>

<p>

<img src="https://salmanarif.bitbucket.io/visual/images/full_screenshot.png" alt="full screenshot"></p><p>


VisUAL has been developed as a cross-platform tool to make learning ARM Assembly language easier. In addition to emulating <a href="https://salmanarif.bitbucket.io/visual/supported_instructions.html">a subset of the ARM UAL instruction set</a>, it provides visualisations of key concepts unique to assembly language programming and therefore helps make programming ARM assembly more accessible.

</p><p>It has been designed specifically to use as a teaching tool for the <a href="http://www3.imperial.ac.uk/electricalengineering/internal/curriculumee2">Introduction to Computer Architecture course</a> taught at the Department of Electrical and Electronic Engineering of Imperial College London.
<br></p>

<p><a href="#navproghist"><img src="https://salmanarif.bitbucket.io/visual/images/nav_hist_button.png" alt="navigate program history"></a>
<a href="#pointervis"><img src="https://salmanarif.bitbucket.io/visual/images/ptr_vis_button.png" alt="pointer visualisation"></a>
<a href="#shiftvis"><img src="https://salmanarif.bitbucket.io/visual/images/shift_vis_button.png" alt="shift visualisation"></a>
<a href="#memvis"><img src="https://salmanarif.bitbucket.io/visual/images/mem_access_button.png" alt="memory access visualisation"></a>
<a href="#stackvis"><img src="https://salmanarif.bitbucket.io/visual/images/stack_vis_button.png" alt="stack visualisation"></a>
<a href="#branchvis"><img src="https://salmanarif.bitbucket.io/visual/images/branch_vis_button.png" alt="branch visualisation"></a>
<a href="#subvis"><img src="https://salmanarif.bitbucket.io/visual/images/subroutine_vis_button.png" alt="subroutine visualisation"></a>
<a href="#errorsugg"><img src="https://salmanarif.bitbucket.io/visual/images/error_sug_button.png" alt="error correction suggestions"></a>
<a href="#loopdetect"><img src="https://salmanarif.bitbucket.io/visual/images/loop_detect_button.png" alt="infinite loop detection"></a>
<a href="#headless"><img src="https://salmanarif.bitbucket.io/visual/images/headless_emu_button.png" alt="headless emulation mode"></a>
</p>




<h2>Key Features</h2>



<h4>Navigate Program History</h4>

<p>In addition to stepping through code, users can navigate program history by browsing past register values. This feature can help debugging and understanding complex code easier.</p>

<p><img src="https://salmanarif.bitbucket.io/visual/images/history_browsing.png" alt="history browsing"></p>



<h4>Pointer Visualisation</h4>

<p>Pointers in ARM assembly can be quite difficult to understand, especially since ARM assembly has 9 different variations of pointer behaviour when it comes to load/store instructions. VisUAL provides an information pane that displays useful pointer information when needed.</p>

<p><img src="https://salmanarif.bitbucket.io/visual/images/pointer_visualisation.png" alt="pointer visualisation"></p>



<h4>Shift Operation Visualisation</h4>

<p>VisUAL can demonstrate shift operations by playing them as animations. The animations use actual data values from the shift instruction being demonstrated.</p>

<p><video width="100%" autoplay="" loop="">
  <source src="https://salmanarif.bitbucket.io/visual/images/shift_visualisation.mp4" type="video/mp4">
  Your browser does not support HTML5 video.
</video></p>



<h4>Memory Access Visualisation</h4>

<p>All memory access operations, word-aligned or byte-aligned,  can be visualised. Base and offset addresses are shown, and any values that have been changed are highlighted.</p>

<p><img src="https://salmanarif.bitbucket.io/visual/images/memory_visualisation.png" alt="memory visualisation"></p>



<h4>Stack Visualisation</h4>

<p>Instructions to load/store multiple instructions in the form of a stack can be visualised. Stack behaviour is described, and the stack as well as stack pointer at the start and end of the stack are displayed.</p>

<p><img src="https://salmanarif.bitbucket.io/visual/images/stack_visualisation.png" alt="stack visualisation"></p>



<h4>Branch Visualisation</h4>

<p>Colour coded line highlights are used to indicate when a branch is being taken. For conditional instructions, status bits involved in condition checking are highlighted. An arrow points to the branch destination, acting as a visual cue to indicate a branch to another line of code is about to take place.</p>

<p><img src="https://salmanarif.bitbucket.io/visual/images/branch_visualisation.png" alt="branch visualisation"></p>



<h4>Subroutine Visualisation</h4>

<p>Whenever the link register is set to enter a subroutine, the linked subroutine return point will be highlighted and will remain highlighted until the subroutine exits.</p>

<p><img src="https://salmanarif.bitbucket.io/visual/images/subroutine_visualisation.png" alt="subroutine visualisation"></p>



<h4>Error Correction Suggestions</h4>

<p>As opposed to providing cryptic compiler error messages, VisUAL provides context-specific error messages with explanations of exactly what is expected. In addition, whenever a runtime error occurs, the user is informed of the problematic instruction and what operation in the instruction resulted in the error.</p>

<p><img src="https://salmanarif.bitbucket.io/visual/images/syntax_error.png" alt="syntax error"> <img src="https://salmanarif.bitbucket.io/visual/images/runtime_error.png" alt="runtime error"></p>



<h4>Infinite Loop Detection</h4>

<p>Inadvertently typed code that may result in an infinite loop can cause code to malfunction. VisUAL detects possible infinte loops and prompts the user to select the appropriate response.</p>

<p><img src="https://salmanarif.bitbucket.io/visual/images/infinite_loop_warning.png" alt="branch visualisation"></p>

<h4>View Memory Contents</h4>

<p>By using the view memory contents window, data defined in memory can be monitored in real-time as it changes. This allows fast debugging of memory access instructions from a static viewpoint in addition to the dynamic viewpoint provided by the pointer and memory access visualisations.</p>

<p><img src="https://salmanarif.bitbucket.io/visual/images/memory_window.png" alt="memory contents window"></p>
    
<h4>View Symbols</h4>
    
<p>The symbols window provides a list of all code and data symbols that have been defined. This provides an easy method of lookup up symbols during execution.</p>

<p><img src="https://salmanarif.bitbucket.io/visual/images/symbols_window.png" alt="view symbols window"></p>
    


<h4>Headless Emulation Mode</h4>

<p>VisUAL allows assembly code to be executed via the command line and logs the program state to an XML file. This is useful for power users for testing large batches of code. See the <a href="https://salmanarif.bitbucket.io/visual/logging_guide.html">logging guide</a> for details on how to use this.</p>

</div>]]>
            </description>
            <link>https://salmanarif.bitbucket.io/visual/index.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25481614</guid>
            <pubDate>Sat, 19 Dec 2020 21:57:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Setting up your own Nextcloud instance to get off of Google]]>
            </title>
            <description>
<![CDATA[
Score 274 | Comments 164 (<a href="https://news.ycombinator.com/item?id=25481465">thread link</a>) | @kmclean
<br/>
December 19, 2020 | https://kiramclean.com/blog/how-to-set-up-your-own-nextcloud-server/ | <a href="https://web.archive.org/web/*/https://kiramclean.com/blog/how-to-set-up-your-own-nextcloud-server/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

<p>One of my goals for 2020 was to stop using Google's products. There are a lot of reasons why, but that's not the point of this post. I found out about Nextcloud last month and it turns out it's a great replacement for a lot of Google. I don't actually use all of its features, but I've migrated my calendar, reminders, contacts, bookmarks, video calls, photos, and news feeds and I'm really happy with it so far.</p>
<p>There are a lot of companies that will host Nextcloud for you where you just sign up for an account like anything else, but in case you're interested in hosting Nextcloud for yourself this post is basically a brain dump of how I did that. It took me a while to cobble together all the pieces I needed to get everything working from end to end, so I'm hoping this might save someone else from having to do the same. If you know your way around servers and Nextcloud already you can just skim the headings like a checklist to make sure you don't forget an important step. But if you want a succinct overview of the actual steps I did and commands I ran, each section contains those details. By the end you'll see how I installed Nextcloud on my own server, secured it, set up backups, and set up external storage for my photos.</p>
<p>Some parts are pieced together from other partial guides or longer blog posts, so where relevant the references lead to those sources. This post is more of a quick start with just the essential steps. Anything in <code>&lt;pointy-brackets&gt;</code> is meant to be replaced. So the actual command I ran was e.g. <code>adduser kira</code>, not <code>adduser &lt;name&gt;</code>.</p>
<h2>What this list assumes you already have</h2>
<ul>
<li>A domain name. I got mine from <a href="https://namecheap.com/">Namecheap</a>.</li>
<li>An account with a cloud server provider. I use <a href="https://www.linode.com/choosing-linode/">Linode</a>.</li>
<li>An account with <a href="https://www.backblaze.com/b2/cloud-storage.html">Backblaze</a></li>
<li>An account with <a href="https://healthchecks.io/">Healthchecks.io</a></li>
<li>Your ssh key</li>
<li>$75/year. I pay $5/month for the server I use, $5/year for the domain name ($5.16 actually), and CAD$10/year for carbon offsets.</li>
</ul>
<h2>1. Set up a server running Ubuntu and set up ssh access for yourself</h2>
<ul>
<li>Spin up a new server with your cloud provider. I use a "nanode", the smallest server available from Linode, with 1GB of RAM and 25GB of storage, which is plenty more than <a href="https://docs.nextcloud.com/server/16/admin_manual/installation/system_requirements.html#server">Nextcloud's minimum specs</a>.</li>
<li>Select an operating system that can install <a href="https://snapcraft.io/docs/installing-snapd">snap packages</a>. I'm using Ubuntu 20.04 (LTS). Nextcloud recommends at least either Ubuntu 18.04 LTS or Red Hat Enterprise Linux 7.</li>
<li>Add your ssh key to the server. There should be a way to do this through the UI where you manage your new server.</li>
<li>Copy the IP address of your new server</li>
</ul>
<h3>1.1. ssh into your server as the root user and make yourself a new sudo user that can also ssh into the machine <sup><a href="https://www.digitalocean.com/community/tutorials/initial-server-setup-with-ubuntu-20-04">1</a></sup></h3>
<ul>
<li><code>ssh <a href="https://kiramclean.com/cdn-cgi/l/email-protection" data-cfemail="e89a87879ca8">[email&nbsp;protected]</a>&lt;server-ip-address&gt;</code></li>
<li><code>adduser &lt;name&gt;</code></li>
<li><code>usermod -aG sudo &lt;name&gt;</code></li>
<li><code>rsync --archive --chown=&lt;name&gt;:&lt;name&gt; ~/.ssh /home/&lt;name&gt;</code></li>
</ul>
<p>Close this ssh session and log in as your new user to make sure it works:</p>
<ul>
<li><code>logout</code></li>
<li><code>ssh &lt;name&gt;@&lt;server-ip-address&gt;</code></li>
</ul>
<p>Leave this ssh session open. The rest of the commands below are meant to be run on your server, unless otherwise stated.</p>
<h2>2. Point your new server to your custom domain</h2>
<p>There should be a way to do this in the admin section for your server. On Linode's there's a "Domains" section in the left admin menu. From there I clicked "Add a Domain" in the top right, then filled in the domain name, my email address, and selected "Insert default records from one of my Linodes" from the "Insert Defaults Records" dropdown, then I selected my new Nextcloud server from the list of Linodes. The steps might be slightly different depending what cloud server provider you're using. By the end you need DNS records pointing your domain name to your Nextcloud server. If you did this through Linode (or whatever you're using), you'll also need to update the nameservers with your domain registar.</p>
<h2>3. Set up a basic firewall</h2>
<ul>
<li><code>sudo ufw allow OpenSSH</code></li>
<li><code>sudo ufw allow https</code></li>
<li><code>sudo ufw allow http</code></li>
<li><code>sudo ufw enable</code></li>
</ul>
<h2>4. Install Nextcloud</h2>
<ul>
<li><code>sudo snap install nextcloud</code></li>
<li><code>sudo nextcloud.manual-install &lt;username&gt; &lt;password&gt;</code></li>
</ul>
<h2>5. Set up your domain, enable https, and install an auto-updating certificate from Let's Encrypt</h2>
<ul>
<li><code>sudo nextcloud.occ config:system:set trusted_domains 1 --value=&lt;your-domain.name&gt;</code></li>
<li><code>sudo nextcloud.enable-https lets-encrypt</code></li>
</ul>
<h2>6. Enable 2FA on your Nextcloud account <sup>*</sup></h2>
<ul>
<li>Log in to your new personal cloud at the domain you configured using the username and password you chose above and install the 2FA app
<ul>
<li>Click on your initial in the top right corner of the Nextcloud dashboard and select "Apps"</li>
<li>In the left side bar click on "Security", then search for the "Two-Factor TOTP Provider" app</li>
<li>Click "Download and enable"</li>
</ul>
</li>
<li>Set up 2FA with this newly installed app
<ul>
<li>Click on your initial in the top right corner and select "Settings"</li>
<li>In the left sidebar, click on "Security" (in the "Personal" section) then check the "Enable TOTP" box and follow the instructions to set up 2FA</li>
</ul>
</li>
</ul>
<p>I managed to forget my password in the time between installing Nextcloud and trying to log in for the first time. If that happens to you, you can reset it by running <code>sudo nextcloud.occ user:resetpassword &lt;username&gt;</code>.</p>
<hr>
<p><small>* Doing this means you will be required to generate "app passwords" in order to log in to your Nextcloud account in third party apps or other devices (to use Nextcloud to sync your calendar or reminders to your phone, for example.) There's a tiny box with a button that says "Create new app password" at the bottom of the "Security" admin section (under "Personal", not "Administration") where you can do that.</small></p>
<h2>7. Set up backups</h2>
<h3>7.1. Turn on "local" backups</h3>
<ul>
<li>Enable backups for your whole server for a first layer of backups. I did this when I was setting up my Linode (there was a checkbox in the "Optional Add-ons" section for it). Otherwise there's a "Backups" tab in the admin section where you can turn them on. Linode charges $2/months for this.</li>
</ul>
<h3>7.2. Set up "offsite" backups</h3>
<ul>
<li>
<p>Install and set up Backblaze</p>
<ul>
<li>Make a bucket in Backblaze for your backups</li>
<li>Make an app key with access to your backup bucket</li>
<li>Get the Backblaze cli and configure it
<ul>
<li><code>sudo apt install python3-pip</code></li>
<li><code>sudo pip3 install b2</code></li>
<li><code>sudo b2 authorize_account &lt;keyID&gt;</code></li>
<li>Copy the key secret from the app key you just made to authorize the Backblaze cli</li>
</ul>
</li>
</ul>
</li>
<li>
<p>Create a new user to run the backups and disable password access for it, for security <sup><a href="https://kevq.uk/how-to-backup-nextcloud/">2</a></sup></p>
<ul>
<li><code>sudo adduser ncbackup</code></li>
<li><code>sudo usermod -s /sbin/nologin ncbackup</code> <sup>*</sup></li>
</ul>
</li>
<li>
<p>Create directories for the backups and logs</p>
<ul>
<li><code>sudo mkdir -p /home/ncbackup/backups/logs</code></li>
</ul>
</li>
<li>
<p>Create the backup script and make it runnable <sup>**</sup></p>
<ul>
<li><code>sudo touch /usr/sbin/ncbackup.sh</code></li>
<li><code>sudo chmod +x /usr/sbin/ncbackup.sh</code></li>
<li><code>sudo vim /usr/sbin/ncbackup.sh</code> and copy the contents of the backup script below into your new file, or write your own that accomplishes the same things: <sup>***</sup></li>
</ul>
</li>
</ul>
<pre><code>#!/bin/bash
set -e

DATE=$(date '+%Y-%m-%d')

# Output to a logfile
exec &amp;&gt; /home/ncbackup/backups/logs/${DATE}.txt

# Export all your config and data from Nextcloud
echo "Starting Nextcloud export..."
nextcloud.export
echo "Export complete"

# Compress backed up folder
echo "Compressing backup..."
tar -zcf /home/ncbackup/backups/${DATE}.tar.gz -C /var/snap/nextcloud/common/backups/ .
echo "Nextcloud backup successfully compressed to /home/ncbackup/backups"

# Remove uncompressed backup data
rm -rf /var/snap/nextcloud/common/backups/*

# Remove backups and logs older than 5 days
echo "Removing backups older than 5 days..."
find /home/ncbackup/backups -type f -mtime +5 -delete
find /home/ncbackup/backups/logs -type f -mtime +5 -delete

# Keep 14 days of backups in Backblaze
echo "Uploading to Backblaze..."
b2 sync --keepDays 14 --replaceNewer /home/ncbackup/backups b2://&lt;your-bucket-name&gt;
echo "Nextcloud backup completed successfully"
</code></pre>
<ul>
<li>Let the <code>ncbackup</code> user run the backup script as the root user
<ul>
<li><code>sudo visudo</code></li>
<li>Copy this to the end of the file that opens:</li>
</ul>
</li>
</ul>
<pre><code># Allow ncbackup to run script as sudo
ncbackup ALL=(ALL) NOPASSWD: /usr/sbin/ncbackup.sh
</code></pre>
<hr>
<p>
<small>
* If you want to undo this for some reason you can run <code>sudo usermod -s /bin/bash ncbackup</code>
</small>
</p>
<p>
<small>
** Note this means you will have 6 copies of all your data on your server all the time -- 5 backups and the live versions. The backups are compressed, but it can still add up to a lot of space. Keep an eye on how much storage your server is using. Running it out of space will probably be one of the first issues you run into. I explain how to get notified when that's close to happening at the end.
</small>
</p>
<p>
<small>
*** You don't have to use vim here. Your server probably has nano installed or you can install the editor of your choice. To change the default editor on your server, run <code>sudo update-alternatives --config editor</code>, and choose the one you want.
</small>
</p>
<h2>8. Schedule and monitor your backups</h2>
<ul>
<li>Make yourself a healthcheck at <a href="https://healthchecks.io/">healthchecks.io</a> and copy the ping url</li>
<li><code>sudo crontab -u ncbackup -e</code></li>
<li>Copy this to the bottom of the file: <code>0 2 * * * sudo /usr/sbin/ncbackup.sh &amp;&amp; curl -fsS -m 10 --retry 5 -o /dev/null &lt;your-ping-url&gt;</code></li>
</ul>
<p>This will run your backups once per day at 2am (in your server's timezone, probably UTC), but you can set whatever time and frequency you want, just remember to update your healthcheck to match.</p>
<h2>9. Test your backups</h2>
<p>Backups are only useful if you can use them to restore your data. Make sure yours work before you need them.</p>
<p>To test your entire server backups you can just try restoring the whole server using Linode's (or whoever's) UI. Testing the archived backups we uploaded to Backblaze is a little more involved but you'll be glad you know how to do it when you need it.</p>
<ul>
<li>Repeat steps 1-5, except you can just update the records for your domain that's already set up to point to your new server's IP address(es).</li>
<li>Download one of your backups</li>
<li>Copy the backup onto your new server. Run this in a terminal on your machine (not in an ssh session with a remote server):
<ul>
<li><code>scp /local/path/to/your/backup/ &lt;user&gt;@&lt;new-server-ip-address&gt;:~</code></li>
</ul>
</li>
</ul>
<p><em>ssh into your new server for the rest of these commands</em></p>
<ul>
<li>Unzip, rename, and move the backup to a place where the Nextcloud snap installation will be able to access it, then make the root user the owner
<ul>
<li><code>tar -xvzf &lt;backup-name&gt;.tar.gz</code></li>
<li><code>sudo mv &lt;backup-data-dir&gt;/ ‚Ä¶</code></li></ul></li></ul></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://kiramclean.com/blog/how-to-set-up-your-own-nextcloud-server/">https://kiramclean.com/blog/how-to-set-up-your-own-nextcloud-server/</a></em></p>]]>
            </description>
            <link>https://kiramclean.com/blog/how-to-set-up-your-own-nextcloud-server/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25481465</guid>
            <pubDate>Sat, 19 Dec 2020 21:39:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The original "Spacewar!" running on a virtual DEC PDP-1]]>
            </title>
            <description>
<![CDATA[
Score 108 | Comments 23 (<a href="https://news.ycombinator.com/item?id=25481278">thread link</a>) | @CharlesW
<br/>
December 19, 2020 | https://www.masswerk.at/spacewar/ | <a href="https://web.archive.org/web/*/https://www.masswerk.at/spacewar/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="description">
	<h2>Notes &amp; Descriptions</h2>
	<h3>Program Versions &amp; Sources</h3>
	<p>The emulation is running various versions of the original game, both from binaries copies of the original paper tapes and newly assembled from authentic code listings. The programs are loaded as virtual paper tapes (RIM-mode: Read In Memory) into the memory of the emulated DEC PDP-1.</p>
	<p><img src="https://www.masswerk.at/spacewar/images/hingham-space-warfare-2.png" alt="Spaceships (stylized) according to the Hingham Institute Study Group on Space Warfare" title="Spaceships according to the Hingham Institute Study Group on Space Warfare" width="81" height="94"></p><p><strong onclick="selectSpacewarModule('spacewar3.1');" data-title="Click to play Spacewar! 3.1"><span></span>Spacewar! 3.1</strong>, the final version of Spacewar! as left by the original programmers (Steve Russell and the other members of the <em>Hingham Institute Study Group on Space Warfare</em>), is presented here once in its original form and in a modified version showing scaled up graphics and effects for the benefit of small screen sizes. Further, there are both earlier and later versions, as <strong onclick="selectSpacewarModule('spacewar2b');" data-title="Click to play Spacewar! 2B"><span></span>Spacewar! 2B</strong> (the program described in <a href="https://www.masswerk.at/spacewar/SpacewarOrigin.html" target="SpacewarOrigin">"The Origin of Spacewar"</a> by J. M. Graetz) and some examples of <strong onclick="selectSpacewarModule('spacewar4.1f');" data-title="Click to play Spacewar! 4.1f"><span></span>version 4</strong> (adding minor features and compatibility to an upgraded hardware). Finally, there is a special version of Spacewar 3.1, demonstrating the "Winds of Space" effect.</p>
	<p><em>(Please mind that the title screens are generated by the emulator and are not part of the original games.)</em></p>
	<p>There are two display resolutions to select from:</p>
	<ul>
		<li><strong>Low resolution</strong>, plotting at 512 x 512 px, 50% of the original display.<br>Special subpixel rendering is employed in order to boost the visible resolution beyond the physical resolution provided by the display element in the browser.<br>The result corresponds closely (if not being even a bit better) to the visual resolution of the original display: While the display featured a resolution of 1024 x 1024 plotting locations, only approximately 512 points on each axis were "resolvable to the unaided eye" <cite>(DP-35-2 / PDP-1 Instruction Manual / Part 3; DEC 1971; p. 5)</cite>.<br>Compare these contemporary photos: <a href="https://www.masswerk.at/spacewar/SpacewarOrigin.html#figure-1" target="SpacewarOrigin" title="Illustrative image in &quot;The Origin of Spacewar&quot; by J. M. Graetz" onclick="if (window.showEmbeddedImage) {return showEmbeddedImage('spacewar_origins/spacewar-fig1.jpeg', 421, 418);} else {return true;}">[1]</a> <a href="https://www.masswerk.at/spacewar/SpacewarOrigin.html#figure-a3-7" target="SpacewarOrigin" title="A black and white screenshot of Spacewar!, 1963 ca." onclick="if (window.showEmbeddedImage) {return showEmbeddedImage('spacewar_origins/chm-spacewar_screenshot.jpg', 500, 391);} else {return true;}">[2]</a> <a href="https://www.masswerk.at/spacewar/SpacewarOrigin.html#figure-a3-6" target="SpacewarOrigin" title="Dan Edwards and Peter Samson playing Spacewar! (DEC material)" onclick="if (window.showEmbeddedImage) {return showEmbeddedImage('spacewar_origins/playing-spacewar-1962.jpg', 500, 340);} else {return true;}">[3]</a>.</li>
		<li><strong>High resolution</strong>, plotting at the <a href="https://www.masswerk.at/spacewar/fullscreen.html" data-title="Compare the full-scale version‚Ä¶"><span></span>original 1024 x 1024 px</a>, with the display element scaled to 50%.</li>
	</ul>
	<p>Versions available (by the <i>"versions menu"</i> at the top left of the emulated display):</p>
	<ul>

		<li id="spacewar3.1"><strong onclick="selectSpacewarModule('spacewar3.1');" data-title="Click to select this program."><span></span>Spacewar! 3.1</strong> <span>(24 Sep 1962)</span><br>This could be regarded as the "standard version" of Spacewar!. The program is dated <em>"24 sep 62"</em> and is loaded from an authentic binary paper-tape image (<a href="http://textfiles.com/bitsavers/bits/DEC/pdp1/papertapeImages/20031202/SteveRussell_box1/" target="_blank" title="Archive of Steve Russell's box #1 at textfiles.com">spacewar3.1_24-sep-62.bin</a>) provided by Steve Russell via <a href="http://bitsavers.org/" target="_blank">bitsavers.org</a>.</li>

		<li><strong onclick="selectSpacewarModule('spacewar3.1bigships');" data-title="Click to select this program."><span></span>Spacewar! 3.1, scaled ships</strong> <span>(low resolution only)</span><br>Scaled up graphics and effects to show the game in greater detail on a small display. (Colission radii and turning pivots of the ships have been adjusted accordingly.) This is quite similar to the presentation seen in other emulations. Please mind that the changes have minor effects on the gameplay.<br>
		The code is based on the original PDP-1 <a href="http://textfiles.com/bitsavers/bits/DEC/pdp1/papertapeImages/20031202/SteveRussell_box1/_text/" target="_blank" title="Text-files in the archive of Steve Russell's box #1 at textfiles.com">assembler sources</a> by Steve Russell as available at <a href="http://bitsavers.org/" target="_blank">bitsavers.org</a> and was modified and newly assembled in 2014. (N. Landsteiner, 2014; this is not an authentic version!)</li>

		<li id="spacewar2b"><strong onclick="selectSpacewarModule('spacewar2b');" data-title="Click to select this program."><span></span>Spacewar! 2B</strong> <span>(2 Apr 1962)</span><br>This is the first complete version version of the game as presented at MIT's annual <em>Science Open House</em> in May 1962. Notably this is also the very version the background starfield (Peter Samson's <em>Expensive Planetarium</em>) was designed for, as this is annotated in the source code by <em>"stars by prs for s/w 2b"</em> and dated <em>"3/13/62, prs".</em> The program features the pre-particle-system "Crock Explosion" <a href="https://www.masswerk.at/spacewar/SpacewarOrigin.html#figure-5" target="SpacewarOrigin" title="Illustrative image in &quot;The Origin of Spacewar&quot; by J. M. Graetz" onclick="if (window.showEmbeddedImage) {return showEmbeddedImage('spacewar_origins/spacewar-fig5.jpeg', 417, 422);} else { return true;}">[4]</a> and optionally a faster movement of the starfield (sense switch 4), torpedoes are single shot only (no salvoes). Some of the differences are more cosmetical: The ships' exhaust flames are half the size of later versions, also the display of the starfield hasn't found its final form yet (starting at an other position as compared to later versions). Moreover, the original starfield routine, found here, is modulating the varying brightnesses of the stars by how often the individual stars are drawn, whereas later versions are using the built-in intensity levels of the <em>Type 30 CRT</em> display instead.<br>For more on the making-of of Spacewar! see <a href="https://www.masswerk.at/spacewar/SpacewarOrigin.html" target="SpacewarOrigin">"The Origin of Spacewar" by J. M. Graetz</a>.<br>
		<span></span>The code is run from a binary paper tape image (RIM) labeled "<a href="http://textfiles.com/bitsavers/bits/DEC/pdp1/papertapeImages/20031202/InsidePDP1_80s_box3/" target="_blank" title="&quot;spaceWar_SA-5.bin&quot; in &quot;InsidePDP1_80s_box3&quot; at textfiles.com">spaceWar_SA-5.bin</a>". This has been proven to be identical to loading the two paper tapes "<a href="http://textfiles.com/bitsavers/bits/DEC/pdp1/papertapeImages/20050823/" target="_blank" title="'spacewar2B_2apr62.bin' at textfiles.com">spacewar2B_2apr62.bin</a>" and "<a href="http://textfiles.com/bitsavers/bits/DEC/pdp1/papertapeImages/20031202/SteveRussell_box1/" target="_blank" title="'stars.bin' at textfiles.com">stars.bin</a>", both to be found at bitsavers.org.<br>
		(<em>"SA-5"</em> is not a version string, but indicates the program's start address being 5, which would start the program in a setup for reading the input from the console test switches rather than from MIT's special control boxes, as would be the case with the default start address. The label suggests that this was a tape sent from MIT to an other facility.)<br>
		Spacewar! 2B is known with a date as early as 25 March 1962. This earlier version shows minor differences regarding the polarity of the sense switch settings.<br>
		<img src="https://www.masswerk.at/spacewar/images/spacewar-minskytron-hyperspace.png" alt="Spacewar! ‚Äî The Hyperspace Minskytron signature" title="The Minskytron signature effected by &quot;warp-induced photonic stress emission&quot;" width="75" height="105">
		<span></span>The program is presented here with two patches applied, namely the hyperspace-patch to include Martin Graetz's original hyperspace routine, the "<strong><a href="https://www.masswerk.at/spacewar/inside/insidespacewar-minskytron-hyperspace.html" target="_blank">Minskytron hyperspace</a></strong>" <a href="https://www.masswerk.at/spacewar/SpacewarOrigin.html#figure-4" target="_blank" title="Illustrative image in &quot;The Origin of Spacewar&quot; by J. M. Graetz" onclick="if (window.showEmbeddedImage) {return showEmbeddedImage('spacewar_origins/spacewar-fig4.jpeg', 419, 416);} else {return true;}">[5]</a> and its <em>"warp-induced photonic stress emission",</em> and the auto-restart patch for seemless playing. (There are exactly three jumps to hyperspace per player.)<br>
		This represents the the game as described and depicted in J.M. Graetz's seminal article <a href="https://www.masswerk.at/spacewar/SpacewarOrigin.html" target="SpacewarOrigin">"The Origin of Spacewar"</a> and as presented at the <em>MIT Science Open House</em> in May 1962. (It still lacks a scorer-patch, which seems to be lost.)
		The patches are provided by the paper tape images "<a href="http://textfiles.com/bitsavers/bits/DEC/pdp1/papertapeImages/20031202/InsidePDP1_80s_box3/" target="_blank">hyperspace85.bin</a>" <em>(Hyperspace VIci, 2 May 1962)</em> and  "<a href="http://textfiles.com/bitsavers/bits/DEC/pdp1/papertapeImages/20030408/" target="_blank">spaceWarRstrt.bin</a>" ‚Äî an other tape provides the same patch as "<a href="http://textfiles.com/bitsavers/bits/DEC/pdp1/papertapeImages/20031202/InsidePDP1_80s_box3/" target="_blank">spacewAutoRestartPatch.bin</a>". (The auto-restart patch was to be applied to the hyperspace-patch and is by this officially a patch to a patch. Thus, loading the full program had become a fairly complex affair then, involving up to 6 tapes.)<br>
		<span></span>Listings of Spacewar! 2B and the patches may be found <a href="https://www.masswerk.at/spacewar/sources/" target="_blank">here</a>.<br>
		<span></span>Please mind that this is still the game early in development. The restart-patch is missing an edge case (pun in¬≠tend¬≠ed), where the ships would collide at the "antipode" in the corners of the display. The game requires a manual restart in this situation.</li>

		<li id="spacewar4.1f"><strong onclick="selectSpacewarModule('spacewar4.1f');" data-title="Click to select this program."><span></span>Spacewar! 4.1f</strong> <span>(20 Feb 1963; mod. for CHM 2005 ‚Äì 2008)</span><br>This is the version apparently running at the <a href="http://www.computerhistory.org/" target="_blank">Computer History Museum</a> (CHM).<br>This is Spacewar! 4.1 modified by <strong>Peter Samson</strong> in 2005‚Äì2008 to include the <strong>scorer routine of Spacewar! 4.8</strong>. Moreover, version 4.1f features modified brightness settings for the background starfield (for use at the CHM), which are here remapped to usual values by the emulator. (Otherwise most of the stars would remain invisible.) Like other version of Spacewar! 4.x it requires the hardware multiply/divide option and features the single shot switch for torpedoes. The source code is dated <em>"spacewar 4.1  2/20/63 dfw"</em> and annotated <em>"mod for CHM, 2005-06-01 - 2005-11-28  --prs",</em> and <em>"changed delay in score display, 2008-08-22  --prs.".</em> The code is run from a binary paper tape image (<a href="http://textfiles.com/bitsavers/bits/DEC/pdp1/from_peter_samson/" target="_blank" title="Archive PDP-1 codes provided by Peter Samson at textfiles.com">sw41f.rim</a>) provided by Peter Samson via <a href="http://bitsavers.org/" target="_blank">bitsavers.org</a>.</li>

		<li id="spacewar4.2"><strong onclick="selectSpacewarModule('spacewar4.2a');" data-title="Click to select this program."><span></span>Spacewar! 4.2a (4.1/4.2 dfw)</strong> <span>(22 Feb 1963 ?)</span><br>This is an authentic representative of the 4.x-generation of Spacewar! (probably by "dfw", like version 4.1 above), requiring the hardware multiply/divide option of the PDP-1. Additionaly to some internal modifications it features, like all versions 4, a working single shot mode for torpedoes (sense switch 3). The code is run from a binary paper tape image (<a href="http://textfiles.com/bitsavers/bits/DEC/pdp1/papertapeImages/20040106/russell2/" target="_blank" title="Archive of Steve Russell's box #2 at textfiles.com">spacewar4.2a_sa4.bin</a>) provided by Steve Russell via <a href="http://bitsavers.org/" target="_blank">bitsavers.org</a>.<br>A visually distinctive detail of versions 4.x (4.1 and later) is the <em>"Sun"</em> (heavy star), now drawn by a dashed line like the rocket blasts, thus separating it visually a bit more from the starships (see the <a href="https://www.masswerk.at/spacewar/fullscreen.html#version=4.2a" title="Full-scale version of Spacewar! 4.2 emulated in HTML5/Javascript">high-res/full-scale version</a> for a close-up view.) Also, two ships colliding in free fall in the center will explode at the <em>"antipode"</em> rather than at the center as with earlier versions of the game.</li>

		<li id="spacewar4.3"><strong onclick="selectSpacewarModule('spacewar4.3');" data-title="Click to select this program."><span></span>Spacewar! 4.3</strong> <span>(17 May 1963)</span><br>This is a version by Monty Preonas (signing <em>"ddp"</em>), who also provided the adaptations for the automatic hardware multiply/divide option and the new gravity computations used by all flavors of Spacewar! 4 in his version 4.0 <em>(2 Feb 1962)</em> earlier.<br>
		Spacewar! 4.3 features, like Monty Preonas' flavor of version 4.2 and version 4.4 (also signed <em>"ddp",</em> but presumably by Joe Morris), a special <strong>on-screen score display</strong>, very much like the one of the 4.8-scorer-patch (see the note on scores below). Like all versions by Monty Preonas, it usues an implementation of the background starfield alike the one of Spacewar! 2B.<br>
		The game features a special <strong>Twin Star mode</strong> to be engaged by sense-switch 2 (accessible by the <em>options menu</em> <img src="https://www.masswerk.at/spacewar/images/menubutton_small.png" width="20" height="16" alt="options menu icon" title="options menu icon"> at the top right corner of the screen). This visually distorted mode puts the <em>Needle</em> in the center of the screen in between a doubled sun and draws any other objects relatively to this ship. Moreover, some items are drawn at a double offset and torpedoes are displaced for real, resulting in a quite vexing game play. This mode was probably initially intended as an <em>ego view</em> from the <em>Needle's</em> perspective and left <em>as-is</em> as an amazing novelty. (Compare "Spacewar! 2015" below.)<br>
		<span></span>The program, dated <em>"5/17/63",</em> was newly assembled from source code provided in the assorted listings available at <a href="http://www.computerhistory.org/collections/catalog/102664173" target="_blank" title="'Stars by prs for s/w 2b', CHM, catalog no. 102664173">CHM catalog no. 102664173</a> (which apparently came from Joe Morris, compare <cite><a href="https://groups.google.com/d/msg/alt.sys.pdp10/cNG89mmlbK0/V0JPyn3Mg7sJ" target="_blank">Joe Morris, alt.sys.pdp10, Jannuary 6, 2005</a></cite>).</li>

		<li id="spacewar4.8"><strong onclick="selectSpacewarModule('spacewar4.8');" data-title="Click to select this program."><span></span>Spacewar! 4.8</strong> <span>(24 Jul 1963)</span><br>Apparently the final version of MIT-Spacewar!, dated <em>"7/24/63"</em> and signed <em>"dfw"</em>. A patch for a special <strong>on-screen scorer</strong> is available for this version (see the note on scoring below).<br>
		The game was newly assembled including the dedicated scorer patch. Sources <em>("spacewar4.8part1_engl.txt", "spacewar4.8part2_engl.txt", and "spacewar4.8_scorer.txt")</em> are available at <a href="http://textfiles.com/bitsavers/bits/DEC/pdp1/papertapeImages/20040817/" target="_blank" title="Spacewar 4.8! sources and sorer-patch at textfiles.com">textfiles.com</a> and <a href="http://bitsavers.org/" target="_blank">bitsavers.org</a>.</li>

		<li id="spacewar4.1hafb"><strong onclick="selectSpacewarModule('spacewar4.1hafb');" data-title="Click to select this program."><span></span>Spacewar! 4.1 Holloman Air Force Base Version</strong><br>This is a reconstruction of a version of PDP-1 Spacewar! as seen at the Holloman Air Force Base (New Mexico) and described by John W. Andrews in December 1966 for "The Gamesman" (<a href="https://archive.org/details/The_Gamesman_4-1967-12/page/n31" target="_blank" title="Archived copy of The Gamesman, issue 4, Dec. 1967 (archive.org)">The Gamesman, Issue 4, Dec 1967, pp 30-32</a>). Altered starting positions are probably the most interesting feature of this version. (Controls have been swapped accordingly to accommodate for this.)<br>
		<span></span><img src="https://www.masswerk.at/spacewar/images/holloman-afb-spacewar.png" alt="Starting positions in Holloman Air Force Base Spacewar." width="338" height="339" onclick="showEmbeddedImage('images/holloman-afb-spacewar_solid.png', 338, 339);return false;">These are the changes as applied ‚Ä¶</li></ul></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.masswerk.at/spacewar/">https://www.masswerk.at/spacewar/</a></em></p>]]>
            </description>
            <link>https://www.masswerk.at/spacewar/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25481278</guid>
            <pubDate>Sat, 19 Dec 2020 21:16:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Bevy 0.4: data oriented game engine built in Rust]]>
            </title>
            <description>
<![CDATA[
Score 112 | Comments 23 (<a href="https://news.ycombinator.com/item?id=25480321">thread link</a>) | @_cart
<br/>
December 19, 2020 | https://bevyengine.org/news/bevy-0-4/ | <a href="https://web.archive.org/web/*/https://bevyengine.org/news/bevy-0-4/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p><img src="https://bevyengine.org/news/bevy-0-4/colonize.png"></p>
      
    
  </div><div><p>A little over a month after releasing Bevy 0.3, and thanks to <strong>66</strong> contributors, <strong>178</strong> pull requests, and our <a href="https://github.com/sponsors/cart"><strong>generous sponsors</strong></a>, I'm happy to announce the <strong>Bevy 0.4</strong> release on <a href="https://crates.io/crates/bevy">crates.io</a>!</p>
<p>For those who don't know, Bevy is a refreshingly simple data-driven game engine built in Rust. You can check out <a href="https://bevyengine.org/learn/book/getting-started/">Quick Start Guide</a> to get started. Bevy is also free and open source forever! You can grab the full <a href="https://github.com/bevyengine/bevy">source code</a> on GitHub.</p>
<p>Here are some of the highlights from this release:</p>
<h2 id="wasm-webgl2">WASM + WebGL2</h2>

<p>Bevy now has a WebGL2 render backend! @mrk-its has been hard at work building the <a href="https://github.com/mrk-its/bevy_webgl2">Bevy WebGL2 Plugin</a> and expanding <code>bevy_render</code> to meet the needs of the web. He also put together a nice website showcasing various Bevy examples and games running on the web. </p>
<p>I think the results speak for themselves:</p>
<h3 id="bevy-webgl2-showcase"><a href="https://mrk.sed.pl/bevy-showcase/">Bevy WebGL2 Showcase</a></h3>
<p><a href="https://mrk.sed.pl/bevy-showcase/"><img src="https://bevyengine.org/news/bevy-0-4/webgl_showcase.png" alt="webgl2 showcase"></a></p>
<h2 id="cross-platform-main-function">Cross Platform Main Function</h2>
<p>authors: @cart</p>
<p>On most supported Bevy platforms you can just use normal main functions (ex: Windows, MacOS, Linux, and Web). Here is the smallest possible Bevy app that runs on those platforms:</p>
<pre><code><span>use </span><span>bevy</span><span>::</span><span>prelude</span><span>::*;

</span><span>fn </span><span>main</span><span>() {
    </span><span>App</span><span>::</span><span>build</span><span>().</span><span>run</span><span>();
}
</span></code></pre>
<p>However some platforms (currently Android and iOS) require additional boilerplate. This arcane magic is error prone, takes up space, and isn't particularly nice to look at. Up until this point, Bevy users had to supply their own boilerplate ... but no more! <strong>Bevy 0.4</strong> adds a new <code>#[bevy_main]</code> proc-macro, which inserts the relevant boilerplate for you. This is a big step toward our "write once run anywhere" goal.</p>
<p>This Bevy App has all the code required to run on Windows, MacOS, Linux, Android, iOS, and Web:</p>
<pre><code><span>use </span><span>bevy</span><span>::</span><span>prelude</span><span>::*;

#[</span><span>bevy_main</span><span>]
</span><span>fn </span><span>main</span><span>() {
    </span><span>App</span><span>::</span><span>build</span><span>().</span><span>run</span><span>();
}
</span></code></pre><h2 id="live-shader-reloading">Live Shader Reloading</h2>
<p>authors: @yrns</p>
<p>Bevy can now update changes to shaders at runtime, giving you instant feedback without restarting your app. This video isn't sped up!</p>

<h2 id="ecs-improvements">ECS Improvements</h2>
<p>authors: @cart</p>
<p>It wouldn't be a Bevy update without another round of ECS improvements!</p>
<h3 id="flexible-ecs-parameters">Flexible ECS Parameters</h3>
<p>Prior versions of Bevy forced you to provide system parameters in a specific order:</p>
<pre><code><span>/// This system followed the [Commands][Resources][Queries] order and compiled as expected
</span><span>fn </span><span>valid_system</span><span>(</span><span>mut </span><span>commands</span><span>:</span><span> Commands, </span><span>time</span><span>: </span><span>Res</span><span>&lt;</span><span>Time</span><span>&gt;</span><span>, </span><span>query</span><span>: </span><span>Query</span><span>&lt;&amp;</span><span>Transform</span><span>&gt;) {
}

</span><span>/// This system did not follow the required ordering, which caused compilation to fail
</span><span>fn </span><span>invalid_system</span><span>(</span><span>query</span><span>: </span><span>Query</span><span>&lt;&amp;</span><span>Transform</span><span>&gt;</span><span>, </span><span>mut </span><span>commands</span><span>:</span><span> Commands, </span><span>time</span><span>: </span><span>Res</span><span>&lt;</span><span>Time</span><span>&gt;) {
}
</span></code></pre>
<p>Newbies would fall prey to this constantly. These completely arbitrary constraints were a quirk of the internal implementation. The <code>IntoSystem</code> trait was only implemented for specific orders. Supporting every order would have exponentially affected compile times. The internal implementation was also constructed with a <a href="https://github.com/bevyengine/bevy/blob/9afe196f1690a6a6e47bf67ac740b4edeffd97bd/crates/bevy_ecs/src/system/into_system.rs#L158">famously complicated macro</a>.</p>
<p>To resolve this, I completely rewrote how we generate systems. We now use a <code>SystemParam</code> trait, which we implement for each parameter type. This has a number of benefits:</p>
<ul>
<li><strong>Significantly Faster Compile Times</strong>: We're seeing a <b>~25%</b> decrease in clean compile times</li>
<li><strong>Use Any Parameter Order You Want</strong>: No more arbitrary order restrictions!</li>
<li><strong>Easily Add New Parameters</strong>: It is now easy for us (and for users) to create new parameters. Just implement the <code>SystemParam</code> trait!</li>
<li><strong>Simpler Implementation</strong>: The new implementation is much smaller and also way easier to maintain and understand.</li>
</ul>
<pre><code><span>// In Bevy 0.4 this system is now perfectly valid. Cool!
</span><span>fn </span><span>system</span><span>(</span><span>query</span><span>: </span><span>Query</span><span>&lt;&amp;</span><span>Transform</span><span>&gt;</span><span>, </span><span>commands</span><span>: &amp;</span><span>mut</span><span> Commands, </span><span>time</span><span>: </span><span>Res</span><span>&lt;</span><span>Time</span><span>&gt;) {
}
</span></code></pre>
<p>Notice that in <strong>Bevy 0.4</strong>, commands now look like <code>commands: &amp;mut Commands</code> instead of <code>mut commands: Commands</code>. </p>
<h3 id="simplified-query-filters">Simplified Query Filters</h3>
<p>Up until now, Bevy's Query filters were intermingled with components:</p>
<pre><code><span>fn </span><span>system</span><span>(</span><span>query</span><span>: </span><span>Query</span><span>&lt;</span><span>With</span><span>&lt;</span><span>A, Without</span><span>&lt;</span><span>B, </span><span>(&amp;</span><span>Transform, Changed</span><span>&lt;</span><span>Velocity</span><span>&gt;)&gt;&gt;&gt;) {
}
</span></code></pre>
<p>Confused? You wouldn't be the first! You can interpret the query above as "give me immutable references to the <code>Transform</code> and <code>Velocity</code> components of all entities that have the <code>A</code> component, <em>do not</em> have the <code>B</code> component, and have a changed Velocity component".</p>
<p>First, the nesting of types via With / Without makes it very unclear whats going on. Additionally, it's hard to tell what the <code>Changed&lt;Velocity&gt;</code> parameter does. Is it just a filter? Does it also return a Velocity component? If so, is it immutable or mutable?</p>
<p>It made sense to break up these concepts. In <strong>Bevy 0.4</strong>, Query filters are separate from Query components. The query above looks like this:</p>
<pre><code><span>// Query with filters
</span><span>fn </span><span>system</span><span>(</span><span>query</span><span>: </span><span>Query</span><span>&lt;(&amp;</span><span>Transform, </span><span>&amp;</span><span>Velocity</span><span>)</span><span>, </span><span>(</span><span>With</span><span>&lt;</span><span>A</span><span>&gt;</span><span>, Without</span><span>&lt;</span><span>B</span><span>&gt;</span><span>, Changed</span><span>&lt;</span><span>Velocity</span><span>&gt;)&gt;) {
}

</span><span>// Query without filters
</span><span>fn </span><span>system</span><span>(</span><span>query</span><span>: </span><span>Query</span><span>&lt;(&amp;</span><span>Transform, </span><span>&amp;</span><span>Velocity</span><span>)&gt;) {
}
</span></code></pre>
<p>This makes it much easier to tell what a Query is doing at a glance. It also makes for more composable behaviors. For example, you can now filter on <code>Changed&lt;Velocity&gt;</code> without actually retrieving the <code>Velocity</code> component.</p>
<p>And now that filters are a separate type, you can create type aliases for filters that you want to re-use:</p>
<pre><code><span>type </span><span>ChangedVelocity </span><span>= (</span><span>With</span><span>&lt;</span><span>A</span><span>&gt;, </span><span>Without</span><span>&lt;</span><span>B</span><span>&gt;, </span><span>Changed</span><span>&lt;</span><span>Velocity</span><span>&gt;);

</span><span>fn </span><span>system</span><span>(</span><span>query</span><span>: </span><span>Query</span><span>&lt;(&amp;</span><span>Transform, </span><span>&amp;</span><span>Velocity</span><span>)</span><span>, ChangedVelocity</span><span>&gt;) {
}
</span></code></pre><h3 id="system-inputs-outputs-and-chaining">System Inputs, Outputs, and Chaining</h3>
<p>Systems can now have inputs and outputs. This opens up a variety of interesting behaviors, such as system error handling:</p>
<pre><code><span>fn </span><span>main</span><span>() {
  </span><span>App</span><span>::</span><span>build</span><span>()
    .</span><span>add_system</span><span>(</span><span>result_system</span><span>.</span><span>system</span><span>().</span><span>chain</span><span>(</span><span>error_handler</span><span>.</span><span>system</span><span>()))
    .</span><span>run</span><span>();
}

</span><span>fn </span><span>result_system</span><span>(</span><span>query</span><span>: </span><span>Query</span><span>&lt;&amp;</span><span>Transform</span><span>&gt;) -&gt; </span><span>Result</span><span>&lt;()&gt; {
  </span><span>let</span><span> transform </span><span>=</span><span> query</span><span>.</span><span>get</span><span>(</span><span>SOME_ENTITY</span><span>)?;
  </span><span>println!</span><span>("</span><span>found entity transform: {:?}</span><span>",</span><span> transform</span><span>);
  </span><span>Ok</span><span>(())
}

</span><span>fn </span><span>error_handler_system</span><span>(</span><span>In</span><span>(</span><span>result</span><span>)</span><span>: In</span><span>&lt;</span><span>Result</span><span>&lt;()&gt;&gt;</span><span>, </span><span>error_handler</span><span>: </span><span>Res</span><span>&lt;</span><span>MyErrorHandler</span><span>&gt;) {
  </span><span>if let </span><span>Err</span><span>(</span><span>err</span><span>) =</span><span> result </span><span>{
</span><span>      error_handler</span><span>.</span><span>handle_error</span><span>(</span><span>err</span><span>);
  }
}
</span></code></pre>
<p>The <a href="https://docs.rs/bevy_ecs/latest/bevy_ecs/trait.System.html"><code>System</code>
</a> trait now looks like this:</p>
<pre><code><span>// Has no inputs and no outputs
</span><span>System</span><span>&lt;</span><span>In = </span><span>()</span><span>, Out = </span><span>()&gt;

</span><span>// Takes a usize as input and return a f32
</span><span>System</span><span>&lt;</span><span>In = </span><span>usize</span><span>, Out = </span><span>f32</span><span>&gt;
</span></code></pre>
<p>We use this feature in our new Schedule implementation.</p>
<h3 id="schedule-v2">Schedule V2</h3>
<p>Bevy's old Schedule was nice. System registrations were easy to read and easy to compose. But it also had significant limitations:</p>
<ul>
<li>Only one Schedule allowed</li>
<li>Very static: you were limited to using the tools we gave you:
<ul>
<li>stages are just lists of systems</li>
<li>stages are added to schedules</li>
<li>stages use hard-coded system runners</li>
</ul>
</li>
<li>Couldn't switch between schedules at runtime</li>
<li>Couldn't easily support "fixed timestep" scenarios</li>
</ul>
<p>To solve these problems, I wrote a new Schedule system from scratch. Before you get worried, these are largely <em>non-breaking</em> changes. The high level "app builder" syntax you know and love is still available:</p>
<pre><code><span>app</span><span>.</span><span>add_system</span><span>(</span><span>my_system</span><span>.</span><span>system</span><span>())
</span></code></pre><h4 id="stage-trait">Stage Trait</h4>
<p>Stages are now a trait. You can now implement your own <a href="https://docs.rs/bevy_ecs/latest/bevy_ecs/trait.Stage.html"><code>Stage</code>
</a> types!</p>
<pre><code><span>struct </span><span>MyStage</span><span>;

</span><span>impl </span><span>Stage </span><span>for </span><span>MyStage </span><span>{
    </span><span>fn </span><span>run</span><span>(&amp;</span><span>mut </span><span>self</span><span>, </span><span>world</span><span>: &amp;</span><span>mut</span><span> World, </span><span>resources</span><span>: &amp;</span><span>mut</span><span> Resources</span><span>) {
        </span><span>// Do stage stuff here.
        // You have unique access to the World and Resources, so you are free to do anything
    </span><span>}
}
</span></code></pre><h4 id="stage-type-systemstage">Stage Type: <a href="https://docs.rs/bevy_ecs/latest/bevy_ecs/struct.SystemStage.html"><code>SystemStage</code></a></h4>
<p>This is basically a "normal" stage. You can add systems to it and you can decide how those systems will be executed (parallel, serial, or custom logic)</p>
<pre><code><span>// runs systems in parallel (using the default parallel executor)
</span><span>let</span><span> parallel_stage </span><span>=
    </span><span>SystemStage</span><span>::</span><span>parallel</span><span>()
        .</span><span>with_system</span><span>(</span><span>a</span><span>.</span><span>system</span><span>())
        .</span><span>with_system</span><span>(</span><span>b</span><span>.</span><span>system</span><span>());

</span><span>// runs systems serially (in registration order)
</span><span>let</span><span> serial_stage </span><span>=
    </span><span>SystemStage</span><span>::</span><span>serial</span><span>()
        .</span><span>with_system</span><span>(</span><span>a</span><span>.</span><span>system</span><span>())
        .</span><span>with_system</span><span>(</span><span>b</span><span>.</span><span>system</span><span>());

</span><span>// you can also write your own custom SystemStageExecutor
</span><span>let</span><span> custom_executor_stage </span><span>=
    </span><span>SystemStage</span><span>::</span><span>new</span><span>(</span><span>MyCustomExecutor</span><span>::</span><span>new</span><span>())
        .</span><span>with_system</span><span>(</span><span>a</span><span>.</span><span>system</span><span>())
        .</span><span>with_system</span><span>(</span><span>b</span><span>.</span><span>system</span><span>());
</span></code></pre><h4 id="stage-type-schedule">Stage Type: <a href="https://docs.rs/bevy_ecs/latest/bevy_ecs/struct.Schedule.html"><code>Schedule</code></a></h4>
<p>You read that right! <a href="https://docs.rs/bevy_ecs/latest/bevy_ecs/struct.Schedule.html"><code>Schedule</code>
</a> now implements the <a href="https://docs.rs/bevy_ecs/latest/bevy_ecs/trait.Stage.html"><code>Stage</code>
</a> trait, which means you can nest Schedules within other schedules: </p>
<pre><code><span>let</span><span> schedule </span><span>= </span><span>Schedule</span><span>::</span><span>default</span><span>()
    .</span><span>with_stage</span><span>("</span><span>update</span><span>", </span><span>SystemStage</span><span>::</span><span>parallel</span><span>()
        .</span><span>with_system</span><span>(</span><span>a</span><span>.</span><span>system</span><span>())
        .</span><span>with_system</span><span>(</span><span>b</span><span>.</span><span>system</span><span>())
    )
    .</span><span>with_stage</span><span>("</span><span>nested</span><span>", </span><span>Schedule</span><span>::</span><span>default</span><span>()
        .</span><span>with_stage</span><span>("</span><span>nested_stage</span><span>", </span><span>SystemStage</span><span>::</span><span>serial</span><span>()
            .</span><span>with_system</span><span>(</span><span>b</span><span>.</span><span>system</span><span>())
        )
    );
</span></code></pre><h4 id="run-criteria">Run Criteria</h4>
<p>You can add "run criteria" to any <a href="https://docs.rs/bevy_ecs/latest/bevy_ecs/struct.SystemStage.html"><code>SystemStage</code>
</a> or <a href="https://docs.rs/bevy_ecs/latest/bevy_ecs/struct.Schedule.html"><code>Schedule</code>
</a>.</p>
<pre><code><span>// A "run criteria" is just a system that returns a `ShouldRun` result
</span><span>fn </span><span>only_on_10_criteria</span><span>(</span><span>value</span><span>: </span><span>Res</span><span>&lt;</span><span>usize</span><span>&gt;) -&gt;</span><span> ShouldRun </span><span>{
    </span><span>if </span><span>*</span><span>value </span><span>== </span><span>10 </span><span>{ 
        </span><span>ShouldRun</span><span>::</span><span>Yes 
    </span><span>} </span><span>else </span><span>{ 
        </span><span>ShouldRun</span><span>::</span><span>No
    </span><span>}
}

</span><span>app
    </span><span>// this stage only runs when Res&lt;usize&gt; has a value of 10
    </span><span>.</span><span>add_stage_after</span><span>(</span><span>stage</span><span>::</span><span>UPDATE</span><span>, "</span><span>only_on_10_stage</span><span>", </span><span>SystemStage</span><span>::</span><span>parallel</span><span>()
        .</span><span>with_run_criteria</span><span>(</span><span>only_on_10_criteria</span><span>.</span><span>system</span><span>())
        .</span><span>with_system</span><span>(</span><span>my_system</span><span>.</span><span>system</span><span>())
    )
    </span><span>// this stage only runs once
    </span><span>.</span><span>add_stage_after</span><span>(</span><span>stage</span><span>::</span><span>RUN_ONCE</span><span>, "</span><span>one_and_done</span><span>", </span><span>Schedule</span><span>::</span><span>default</span><span>()
        .</span><span>with_run_criteria</span><span>(</span><span>RunOnce</span><span>::</span><span>default</span><span>())
        .</span><span>with_system</span><span>(</span><span>my_system</span><span>.</span><span>system</span><span>())
    )
</span></code></pre><h4 id="fixed-timestep">Fixed Timestep</h4>
<p>You can now run stages on a "fixed timestep".</p>
<pre><code><span>// this stage will run once every 0.4 seconds
</span><span>app</span><span>.</span><span>add_stage_after</span><span>(</span><span>stage</span><span>::</span><span>UPDATE</span><span>, "</span><span>fixed_update</span><span>", </span><span>SystemStage</span><span>::</span><span>parallel</span><span>()
    .</span><span>with_run_criteria</span><span>(</span><span>FixedTimestep</span><span>::</span><span>step</span><span>(</span><span>0.4</span><span>))
    .</span><span>with_system</span><span>(</span><span>my_system</span><span>.</span><span>system</span><span>())
)
</span></code></pre>
<p>This builds on top of <code>ShouldRun::YesAndLoop</code>, which ensures that the schedule continues to loop until it has consumed all accumulated time.</p>
<p>Check out the excellent <a href="https://gafferongames.com/post/fix_your_timestep/">"Fix Your Timestep!"</a> article if you want to learn more about fixed timesteps.</p>
<h4 id="typed-stage-builders">Typed Stage Builders</h4>
<p>Now that stages can be any type, we need a way for <a href="https://docs.rs/bevy_app/latest/bevy_app/trait.Plugin.html"><code>Plugins</code>
</a> to interact with arbitrary stage types:</p>
<pre><code><span>app
    </span><span>// this "high level" builder pattern still works (and assumes that the stage is a SystemStage)
    </span><span>.</span><span>add_system</span><span>(</span><span>some_system</span><span>.</span><span>system</span><span>())
    </span><span>// this "low level" builder is equivalent to add_system()
    </span><span>.</span><span>stage</span><span>(</span><span>stage</span><span>::</span><span>UPDATE</span><span>, |</span><span>stage</span><span>: &amp;</span><span>mut</span><span> SystemStage</span><span>|
        </span><span>stage</span><span>.</span><span>add_system</span><span>(</span><span>some_system</span><span>.</span><span>system</span><span>())
    )
    </span><span>// this works for custom stage types too
    </span><span>.</span><span>stage</span><span>(</span><span>MY_CUSTOM_STAGE</span><span>, |</span><span>stage</span><span>: &amp;</span><span>mut</span><span> MyCustomStage</span><span>|
        </span><span>stage</span><span>.</span><span>do_custom_thing</span><span>()
    )
</span></code></pre><h3 id="deprecated-for-each-systems">Deprecated For-Each Systems</h3>
<p>Prior versions of Bevy supported "for-each" systems, ‚Ä¶</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://bevyengine.org/news/bevy-0-4/">https://bevyengine.org/news/bevy-0-4/</a></em></p>]]>
            </description>
            <link>https://bevyengine.org/news/bevy-0-4/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25480321</guid>
            <pubDate>Sat, 19 Dec 2020 19:24:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[AWS Proton is Conway‚Äôs Law-as-a-Service]]>
            </title>
            <description>
<![CDATA[
Score 30 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25479967">thread link</a>) | @forrestbrazeal
<br/>
December 19, 2020 | https://acloudguru.com/blog/engineering/aws-proton-is-conways-law-as-a-service | <a href="https://web.archive.org/web/*/https://acloudguru.com/blog/engineering/aws-proton-is-conways-law-as-a-service">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-id="8a920a5" data-element_type="widget" data-widget_type="theme-post-content.default"><div><p><em>Is that a good thing? It‚Äôs ‚Ä¶ different, anyhow</em></p><p><a href="https://acloudguru.com/blog/engineering/what-you-need-to-know-about-the-new-aws-proton-service">AWS Proton</a> launched in preview last week to great fanfare and even greater confusion.</p><figure><div><blockquote data-width="500" data-dnt="true"><p lang="en" dir="ltr">If there is one thing that unites the AWS Hero Slack right now, it's that all of us are a little bit confused about what Proton is. We want to like it! But, like ‚Ä¶ what is it?</p>‚Äî Forrest Brazeal @re:Invent 2020 (@forrestbrazeal) <a href="https://twitter.com/forrestbrazeal/status/1333887600592121858?ref_src=twsrc%5Etfw">December 1, 2020</a></blockquote> </div></figure><p>‚ÄúAutomated management for container and serverless deployments,‚Äù <a href="https://aws.amazon.com/proton/">says AWS marketing</a>. So this is a tool specifically for deploying serverless apps, like <a href="https://stackery.io/">Stackery</a> or Amplify? Nope! I think the reason they‚Äôre advertising Proton as a solution for ‚Äúcontainers and serverless‚Äù is that the two provided sample template bundles are for a Lambda CRUD app and a load-balanced Fargate service. But while building your own templates appears to be <em>frustrating, </em>there‚Äôs no technical <em>limit</em> on the sorts of apps Proton could help you deploy.</p><p>Proton itself is ‚Äúserverless‚Äù only in the way CloudFormation is serverless: it‚Äôs a managed service. So is Proton a new and improved CloudFormation? No, it uses <a href="https://github.com/aws-samples/aws-proton-sample-templates">CloudFormation templates all marked up with Jinja</a>, but it operates at a higher level than that.</p><p>It took a while to click for me, but Proton is not just another half-baked AWS developer tool. It‚Äôs doing something I don‚Äôt believe AWS has ever attempted before.</p><p>Proton‚Äôs innovation is that it builds <em>explicit assumptions about your organization</em> into its technical design.</p><p>Proton is <a href="https://twitter.com/forrestbrazeal/status/1334321228694380544">Conway‚Äôs Law-as-a-Service</a>.</p><h2 id="h-proton-assumes-a-platform-team">Proton assumes a platform team</h2><p>I‚Äôve spoken a lot over the years about the phenomenon (and, increasingly, <a href="https://siliconangle.com/2020/08/07/cloud-bard-forrest-brazeal-pinpoints-failure-celebrates-success-cloud-native-evolution/">the pathologies</a>) of the central cloud team: the Terraform nerds at the center of a cloud-first org who create tools and standards for everybody else, particularly product developers. In your company, this team might be called the ‚Äúplatform team‚Äù, the ‚Äúinfrastructure team‚Äù, or just the ‚Äúcloud team‚Äù. It‚Äôs a remarkably consistent pattern across larger orgs, even if it‚Äôs <a href="https://acloudguru.com/blog/engineering/why-central-cloud-teams-fail-and-how-to-save-yours">ultimately sub-optimal</a>.</p><p>In fact, the ‚Äúone platform team supporting many product dev teams‚Äù pattern is so prevalent that AWS, in true customer-obsession mode, has now reasoned backwards from it to design Proton. Proton is a prescriptive way for platform teams to package up environments and infrastructure services, then toss them over the wall to development teams who will consume them. Proton draws the line between automation of infrastructure and development of application code exactly where your average enterprise does.</p><p>This means that if you do NOT have a central platform team and multiple dev teams ‚Äî say, if you are a 10-person startup ‚Äî <em>Proton is not for you, </em>at least not now, even if you have many Containers and Serverless Apps to deploy<em>. </em>Not for the reason many AWS services will not be for you ‚Äî because they solve a technical problem you don‚Äôt have at a cost you can‚Äôt afford ‚Äî but because Proton solves the app deployment problem in a way that is <em>incompatible with your organizational structure.</em></p><p>I really can‚Äôt think of another AWS service that is built this way. Even services like CodePipeline that ship AWS‚Äôs own organizational philosophy ‚Äî I‚Äôm thinking of its reluctance to support branch-based workflows ‚Äî do so implicitly and with workarounds. Proton is made for enterprise-shaped orgs. Period.</p><p>And that‚Äôs not a criticism! AWS absolutely should be releasing services designed with specific customer workflows in mind. Heck, I‚Äôve <a href="https://aws.amazon.com/quickstart/architecture/serverless-cicd-for-enterprise/">personally implemented</a> at least three bespoke versions of AWS Proton over the years, and so have many, many other people who‚Äôve worked on central cloud teams. The hard part was always the separation of duties between what the central team should do and what the development teams should do, and how to get buy-in on that line of separation, wherever you end up drawing it. I even wrote up a janky Service Catalog-y solution in <a href="https://www.trek10.com/blog/pragmatic-enterprise-cicd">this 2019 piece</a>, which reads in retrospect like a cry for help.</p><p>Proton is <em>prescriptive</em> in the sense that it gives you a pre-baked pattern for coordinating application delivery, but <em>descriptive </em>in the sense that this pattern wasn‚Äôt dreamed up as an arbitrary ‚Äúbest practice‚Äù ‚Äì it‚Äôs simply a canonization of what AWS sees customers already doing. In this way, it reminds me more of the reference architectures we often see open-sourced by AWS solutions architects and partners, rather than a typical top-level service.</p><h2 id="h-but-is-proton-a-good-idea">But is Proton a good idea?</h2><p>Proton‚Äôs been released in preview and is not fully baked yet, so I won‚Äôt offer specific technical nitpicks here, but I‚Äôd like to address a criticism that I‚Äôve already heard quite a bit from central cloud teams: ‚ÄúProton doesn‚Äôt simplify the process of creating deployment infrastructure nearly enough to be helpful!‚Äù</p><p>I justified my <a href="https://www.trek10.com/blog/pragmatic-enterprise-cicd">‚Äúpragmatic CI/CD design‚Äù</a> last year by pointing out that, while it involved complex templating, that complexity was distributed mostly where you‚Äôd want it: on the shoulders of the platform team. (Their job is YAML! They can deal with it!) Proton has made the same calculation, and drawn the lines of separation mostly in the same places. They are giving raw, somewhat labor-intensive controls to platform teams in order to present a streamlined deployment workflow to app dev teams, with all that nasty infrastructure abstracted away. (Maybe that‚Äôs a second reason Proton could be called ‚Äúserverless?‚Äù No server automation for dev teams?)</p><p>Far from being too complicated, I worry that Proton may in fact be oversimplified. Because at the enterprise level, it‚Äôs well-nigh impossible to create deployment templates that are really general enough to work out of the box for a diverse portfolio of app teams. Sure, you‚Äôll have a set of ‚Äúhappy path‚Äù teams that your templates support quite nicely. But then there are the edge cases, the teams that need services you don‚Äôt support or workflows you can‚Äôt accommodate. How do you keep them from dropping off into shadow IT ‚Ä¶ or worse, ballooning every template into an unusable mass of one million parameters?</p><p>These are teams who maybe <em>should </em>be building some of their own infrastructure, who should have less centralized dictation and more decentralized enablement. That‚Äôs the ‚ÄúUmbrella‚Äù pattern of org -&gt; CI/CD expression I called for earlier this year, <a href="https://acloudguru.com/blog/engineering/cd-pipeline">in a blog that reads like lost minutes from a Proton design session</a>. It‚Äôs the pattern I‚Äôm seeing more and more forward-thinking organizations adopt ‚Äì those who‚Äôve run with the central cloud team long enough to realize its limits.</p><p><a href="https://acloudguru.com/blog/engineering/why-central-cloud-teams-fail-and-how-to-save-yours">Central cloud teams are bottlenecks</a>, even if 80% of organizations haven‚Äôt matured enough to figure this out. And that leads to the most curious question of all: Will teams complex enough to <em>need </em>Proton eventually become too sophisticated to <em>use </em>Proton?</p><p>That remains to be seen, but I do hope that as Proton evolves, it will lead its customers toward sustainable best practices, instead of productizing the organizational mistakes of the past. Customer obsession is great, but as Andy Jassy said in last week‚Äôs keynote ‚Äî sometimes you have to give them not what they ask for, but what they need.</p></div></div></div>]]>
            </description>
            <link>https://acloudguru.com/blog/engineering/aws-proton-is-conways-law-as-a-service</link>
            <guid isPermaLink="false">hacker-news-small-sites-25479967</guid>
            <pubDate>Sat, 19 Dec 2020 18:48:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Chemicals in Plastic Waste Are Killing Us]]>
            </title>
            <description>
<![CDATA[
Score 67 | Comments 17 (<a href="https://news.ycombinator.com/item?id=25479833">thread link</a>) | @buddhacobbler
<br/>
December 19, 2020 | https://smosa.com/report-plastic-waste-not-just-bad-for-environment-the-chemicals-are-killing-us/ | <a href="https://web.archive.org/web/*/https://smosa.com/report-plastic-waste-not-just-bad-for-environment-the-chemicals-are-killing-us/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>

					<!-- .post-header -->


					<div>
						<p>According to a new study, 144 endocrine-disrupting chemicals can be found in ordinary plastic products. The study details plastic endocrine disrupting chemicals (EDCs) and the threats that these chemicals pose to human health during the plastic life cycle.</p><figure><img src="https://smosa.com/content/images/2020/12/Screen-Shot-2020-12-16-at-9.38.11-AM.png" alt="" srcset="https://smosa.com/content/images/size/w600/2020/12/Screen-Shot-2020-12-16-at-9.38.11-AM.png 600w, https://smosa.com/content/images/size/w1000/2020/12/Screen-Shot-2020-12-16-at-9.38.11-AM.png 1000w, https://smosa.com/content/images/size/w1600/2020/12/Screen-Shot-2020-12-16-at-9.38.11-AM.png 1600w, https://smosa.com/content/images/size/w2400/2020/12/Screen-Shot-2020-12-16-at-9.38.11-AM.png 2400w" sizes="(min-width: 720px) 720px"><figcaption>Source: <a href="https://www.endocrine.org/-/media/endocrine/files/topics/edc_guide_2020_v1_6bhqen.pdf">Endocrine Society</a></figcaption></figure><p>Most plastic additives are considered to interfere with the functioning of hormones and are endocrine disrupting substances, by definition. Many EDC exposures are the agent of tumors, diabetes, kidney, liver, and thyroid symptoms, metabolic disorders, neurological effects, inflammation. At the 4th International Chemicals Management Conference, more than 100 countries agreed to call for policy action on EDCs. AMA, largest U.S. medical professional group, called for increased regulatory oversight in 2009 and 2011. American Public Health Laboratories and American Chemical Society proposed increased education and research. International Conference on Children's Health and Environment released a 2013 Jerusalem Declaration on its "commitment to protect the health of children from environmental hazards."</p><p>EDCs include Bisphenol A (BPA), which is used in polycarbonate plastics. EDCs are linked to cancer, early puberty in young girls, obesity and diabetes, male and female reproductive disorders, and neurodevelopmental disorders</p><figure><img src="https://images.unsplash.com/photo-1597348989645-46b190ce4918?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=MXwxMTc3M3wwfDF8c2VhcmNofDI0fHxwbGFzdGljc3xlbnwwfHx8&amp;ixlib=rb-1.2.1&amp;q=80&amp;w=2000" alt="Grocery Store Bag" srcset="https://images.unsplash.com/photo-1597348989645-46b190ce4918?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=MXwxMTc3M3wwfDF8c2VhcmNofDI0fHxwbGFzdGljc3xlbnwwfHx8&amp;ixlib=rb-1.2.1&amp;q=80&amp;w=600 600w, https://images.unsplash.com/photo-1597348989645-46b190ce4918?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=MXwxMTc3M3wwfDF8c2VhcmNofDI0fHxwbGFzdGljc3xlbnwwfHx8&amp;ixlib=rb-1.2.1&amp;q=80&amp;w=1000 1000w, https://images.unsplash.com/photo-1597348989645-46b190ce4918?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=MXwxMTc3M3wwfDF8c2VhcmNofDI0fHxwbGFzdGljc3xlbnwwfHx8&amp;ixlib=rb-1.2.1&amp;q=80&amp;w=1600 1600w, https://images.unsplash.com/photo-1597348989645-46b190ce4918?crop=entropy&amp;cs=tinysrgb&amp;fit=max&amp;fm=jpg&amp;ixid=MXwxMTc3M3wwfDF8c2VhcmNofDI0fHxwbGFzdGljc3xlbnwwfHx8&amp;ixlib=rb-1.2.1&amp;q=80&amp;w=2400 2400w" sizes="(min-width: 720px) 720px"><figcaption>Photo by <a href="https://unsplash.com/@vegaguy?utm_source=ghost&amp;utm_medium=referral&amp;utm_campaign=api-credit">Christopher Vega</a> / <a href="https://unsplash.com/?utm_source=ghost&amp;utm_medium=referral&amp;utm_campaign=api-credit">Unsplash</a></figcaption></figure><p>Estimates of the health and other economic costs of EDC exposure are also coming to light. A number of international health organizations have taken up the call for improved EDC policies. The Policy Department for Citizen's rights and Constitutional Affairs within the European Parliament commissioned its own study of EDcs.</p><p>The endocrine system consists of a series of glands that are distributed throughout the body. Each gland produces one or more hormones that are released into the bloodstream. When they reach a target organ, they bind to specific receptors, triggering a response. Hormones are critical to reproductive function and are essential to normal development of the body and brain. The glands must be able to adjust hormone release in response to the changing environment to enable a healthy life.</p><h3 id="chart-production-of-selected-chemicals-and-plastics-in-the-united-states-in-2019-by-type">Chart: Production of selected chemicals and plastics in the United States in 2019, by type</h3><figure><img src="https://smosa.com/content/images/2020/12/Screen-Shot-2020-12-19-at-9.44.32-PM.png" alt="" srcset="https://smosa.com/content/images/size/w600/2020/12/Screen-Shot-2020-12-19-at-9.44.32-PM.png 600w, https://smosa.com/content/images/size/w1000/2020/12/Screen-Shot-2020-12-19-at-9.44.32-PM.png 1000w, https://smosa.com/content/images/2020/12/Screen-Shot-2020-12-19-at-9.44.32-PM.png 1056w" sizes="(min-width: 720px) 720px"><figcaption>Source: American Chemistry Council; US Census Bureau; US International Trade Commission; ICIS; Chemical Week; AFPM; TFI</figcaption></figure><p>The Endocrine Society described EDCs as an exogenous [non-natural] chemical, or mixture of chemicals, that interferes with any aspect of hormone action Today, a vast number of chemicals generated are in use. The report concentrated on plastic EDCs, "particularly bisphenols, phthalates, alkylphenol ethoxylates, nonylphenols, brominated flame retardants, perfluorinated substances, benzotriazole UV stabilizers, and toxic metals".</p><p>Chemicals enter the body primarily through the oral route, skin contact, and inhalation. Chemicals in a pregnant or lactating woman's body may also be transferred through placental transfer or via breast milk to a fetus or infant. EDCs in plastics are better studied for mimicking or interfering with estrogen- and androgen-regulated processes such as reproduction.</p>
					</div><!-- .post-content -->

					<!-- .post-footer -->


				</article></div>]]>
            </description>
            <link>https://smosa.com/report-plastic-waste-not-just-bad-for-environment-the-chemicals-are-killing-us/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25479833</guid>
            <pubDate>Sat, 19 Dec 2020 18:36:54 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Observer Effect ‚Äì Tobi L√ºtke]]>
            </title>
            <description>
<![CDATA[
Score 40 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25478070">thread link</a>) | @charlieirish
<br/>
December 19, 2020 | https://www.theobservereffect.org/tobi.html | <a href="https://web.archive.org/web/*/https://www.theobservereffect.org/tobi.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p><em>
									Welcome to the third interview on 'The Observer Effect'. We are lucky to have one
									of the most interesting founders in technology and commerce - Tobi L√ºtke, Founder
									and CEO of Shopify. This interview was published on December 16th, 2020.

							</em></p><p><em>Tobi is one of the most thoughtful and first principles oriented founders I've met and
								this was a fascinating conversation. Enjoy!
								</em>
							</p><p><b><a href="https://sriramk.com/">Sriram Krishnan</a></b><br>
								<em><strong>Let‚Äôs start with the basics. Walk me through a typical day in the life of
										Tobi L√ºtke.</strong></em>
							</p><p>
								Here‚Äôs the honest answer: obviously I have a schedule and people helping me manage my
								time, however, I think a lot about where to devote my attention. In this way, there is
								no typical day.

							</p><p>My attention is the most liquid and valuable resource that I have. Even back in the day
								when Shopify went public, I spent a good deal of time pre-selling the various investors.
								During meetings, I would say, ‚ÄúHey, I'm here, and we've been doing this roadshow, but I
								actually spend a lot of my time on the product.‚Äù This was to set expectations because I
								knew I wasn't going to attend very many investor conferences. Fundamentally, my
								attention belonged to the product, not to the sales and marketing of it. </p><p>A day in my life really depends on what's happening. That said, usually I have themes.
								For instance, I have a priority list, and I have decision logs that chronicle all the
								things I am trying to figure out. </p><p>
								These cover different questions. For example, if I had just taken the company over, how
								would I change it? How would I build a company to potentially disrupt Shopify? I try to
								make my calendar match these bigger topics and other urgent priorities. In a way, the
								calendar is nothing more than a strategy. Although it's incredibly easy‚Äîand it has
								happened to me quite a lot‚Äîto have circumstances dictate the calendar. Because of this,
								there‚Äôs this constant tug of war between the actual priorities of the company and the
								kind of things that have to be done.

							</p><p>So, I end up trying to insert themes into my days. Like today, for instance, I have a
								meeting with my small team to begin the week; I reserved my afternoon for product
								reviews‚Äîwhat we call ‚Äúgreenpathing exercises‚Äù‚Äîwhere, oddly, I'm trying to discern how
								everyone is thinking about the main things we're working on. I do this because
								oftentimes I feel as though I am the connective tissue combining operations, finance,
								and more formal business functions with the product itself. This connection helps me to
								make good decisions.</p><p>Lastly, on Wednesdays, Shopify doesn't do scheduled meetings. Usually, I have a list of
								memos to read or reactions to record to various mock-ups and so on. This is basically my
								very loosely defined schedule.</p><p>
								<b><i>How do you work with your so-called ‚Äúexpansion pack team‚Äù on reallocating your
										portfolio management on time? What does that loop look like?
									</i></b>
							</p><p>
								A lot of this is almost automatic by just having a good color coding system, which is
								really fun.
								<i>[laughs]</i>

							</p><p> At one point, I started complaining about blue weeks where every single time slot was
								taken. And someone said, ‚ÄúWell, if you don't like blue, I can make any color.‚Äù And I
								replied, ‚ÄúWell, how about we color based on leverage?‚Äù And that‚Äôs just what we did. </p><p>
								We ended up labeling my product-related things red, investor/Board of Director-related
								things some kind of teal color, et cetera. And the thing I‚Äôm looking for is a balanced
								week; a week where, ideally, I manage to devote about 30% of the time‚Äîat least‚Äîto the
								product and then as much as possible to things like recruiting, bigger picture projects,
								and one-on-ones.

							</p><p>
								And so, if my calendar becomes too external or too much of anything, it's the first
								thing we see when we sit down for our priorities meeting. This makes scheduling a lot
								easier.

							</p><p>
								<b><i>
										This is a very natural segue to my next question. One of the theories behind
										this whole set of interviews is diving into the atomic bits of how we spend our
										time in meetings. This time compounds over the long term and has a massive
										effect. What does a good meeting with Tobi look like? Alternatively, what does a
										bad meeting with you look like?
									</i>
							</b></p><div>
							<p>So actually, agendas are not terribly successful with me. I admire how other CEOs I‚Äôve
								spoken with always have a strict agenda where everyone has a speaking slot. I find that
								absolutely fascinating. Even if I really set myself to an agenda and say, ‚ÄúOkay, great,
								this is going to happen,‚Äù I can't get through half of a meeting like this. Partly
								because a good meeting is, for me personally, when I learn something.</p>
								<blockquote>
									<p>..when I have my own ideas, the first thing I tend to do is
										just try to falsify them, to figure out why what I'm thinking about is probably
										incorrect...<em>
									</em></p>
								</blockquote>
							<p>
								I started a company because I love learning. I went into programming because I found it
								fascinating. During meetings, I just love to hear the things that teams have discovered.
								When you're discussing an idea or a decision, I want to know what has been considered.
								To be honest, I find myself more interested in the inputs of an idea than the actual
								decision. I say this because when I have my own ideas, the first thing I tend to do is
								just try to falsify them, to figure out why what I'm thinking about is probably
								incorrect. This is actually something that I have to explain to people that I work with.
								If I like someone's idea, I tend to do the same thing: I try to poke holes in it.
							</p>

							<p>I usually say, ‚ÄúWell, the implication of this choice means you've made the following
								assumptions. What inputs did you use to make these foundational assumptions?‚Äù
								Effectively, I'm trying to figure out if an idea is built on solid fundamentals. I find
								that shaky fundamentals tend to be where things often go wrong. The decision being
								discussed could be the perfect decision according to the various assumptions that
								everyone came into the room with. But if those assumptions are faulty, the seemingly
								perfect decision is faulty too. Interestingly, assumptions are rarely mentioned in the
								briefing docs or in the slide deck. Usually, I'm trying to make sure those are rock
								solid. Through this process, I invariably end up learning something completely new about
								a field. That gives me great confidence and comfort both in the decision and the
								direction.</p>

							
							<h2 id="enneagrams"><b>On Enneagrams and Comprehensivists</b></h2>
							<p>


								<b><i>Two words have come up a lot in preparatory conversations: comprehensivist and
										enneagrams. Could you talk about both?

									</i></b>

							</p>

							<p>Interesting.</p>
							<p>
								<i>[Laughs]</i>
								I feel like I'm becoming known for pointing people towards the enneagram. I actually
								don't think it's that valuable on its own. The valuable thing about any of these
								personality-type constructs is that they do a really good job of teaching people that
								other people are very different. That realization is probably one of the biggest growth
								moments for people in general. It tells you that different people play different roles.
								On that note, I do think that, ideally, people should play their own roles really,
								really well.

							</p>
							<p>
								I play the role of challenger, personally. I find that the enneagram helps me remind
								myself that with different people I have to talk about the same things in different
								ways. I think it allows you to skip some time which would otherwise be touch and go at
								the beginning of a relationship and helps build trust better. In short, it enables us to
								have fruitful and effective conversations.
								And comprehensivist, I mean, that's a fancy word.
							</p>
							<p>

								<i>[Laughs]</i> I don't think I've ever used it outside of putting it into my Twitter
								bio when I was reading Buckminster Fuller. That said, I do like range. I find that the
								first 80% of every field is pretty quick to learn‚Äîit‚Äôs equivalent to the Pareto
								principle‚Äîand I think that creativity generally is people using lessons from one field
								in another field in different ways. Because of this, I find learning fascinating.

								</p><blockquote>
									<p>..creativity generally is people using lessons from one field
										in another field in different ways...<em>
									</em></p>
								</blockquote>
							
						


							<h2 id="decisionmaking"><b>On Time and Attention on Shopify<br></b></h2>
							<p>
								<b><i>
										You try and design how your company spends time and attention. One particular
										incident came up recently which I found really fascinating. You wrote a script
										to delete every recurring meeting at Shopify. Talk about why you did that, and
										what you ended up learning from it.


									</i></b>
							</p>


							<p>
								<i>[Laughs]</i>
								So, going back a little bit further there‚Äîyou know what, I should talk about books. One
								thing that is interesting is how people have accused Shopify of being a book club thinly
								veiled as a public company.

							</p>
							<p>We tend to read a lot and talk about a lot of books. We read Nassim Taleb‚Äôs books and one
								person on my team began talking about Antifragile and gave an outline. He said, ‚ÄúI think
								Nassim is putting a word to the thing that you keep talking about‚Ä¶‚Äù </p>

							<p>Now, I come from an engineering perspective. One of my biggest beefs with engineers, in
								general, is ‚Ä¶</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.theobservereffect.org/tobi.html">https://www.theobservereffect.org/tobi.html</a></em></p>]]>
            </description>
            <link>https://www.theobservereffect.org/tobi.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25478070</guid>
            <pubDate>Sat, 19 Dec 2020 15:44:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[When DevSecOps goes wrong: a short lesson from Huawei's source code]]>
            </title>
            <description>
<![CDATA[
Score 53 | Comments 22 (<a href="https://news.ycombinator.com/item?id=25477069">thread link</a>) | @DyslexicAtheist
<br/>
December 19, 2020 | https://r2c.dev/blog/2020/when-devsecops-goes-wrong-a-short-lesson-from-huaweis-source-code/ | <a href="https://web.archive.org/web/*/https://r2c.dev/blog/2020/when-devsecops-goes-wrong-a-short-lesson-from-huaweis-source-code/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><div><div><div><p>There‚Äôs a trend to unify security and developer flows that goes by various names like DevSecOps and ‚Äúshift left.‚Äù Generally security teams seem more enthusiastic about this than developer teams, who refer to security as a <a href="https://www.darkreading.com/application-security/open-source-developers-still-not-interested-in-secure-coding/d/d-id/1339654" target="_blank" rel="noopener">‚Äúsoul-withering chore‚Äù or ‚Äúinsufferably boring procedural hinderance.‚Äù</a> If developers don‚Äôt believe in code hardening ideas, things can go wrong in amusing ways.</p>
<p><span>
      <a href="https://r2c.dev/static/4df5e05b677b46135740d1f1852a05a6/50978/shiftleft.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="Semgrep pattern example" title="Semgrep pattern example" src="https://r2c.dev/static/4df5e05b677b46135740d1f1852a05a6/50978/shiftleft.png" srcset="https://r2c.dev/static/4df5e05b677b46135740d1f1852a05a6/5a46d/shiftleft.png 300w,
https://r2c.dev/static/4df5e05b677b46135740d1f1852a05a6/50978/shiftleft.png 478w" sizes="(max-width: 478px) 100vw, 478px" loading="lazy">
  </a>
    </span></p>
<p>I was recently reading the <a href="https://www.gov.uk/government/publications/huawei-cyber-security-evaluation-centre-oversight-board-annual-report-2019" target="_blank" rel="noopener">2019 UK government security evaluation of Huawei</a> which provides a humorous example: developers for one of the LTE base stations literally used a <code>#define</code> to redefine unsafe_functions like <code>strcpy</code> to safer varients like <code>strlcpy</code>. Specifically:</p>
<p><span>
      <a href="https://r2c.dev/static/aa680407147acdd651f9df0feda4aa94/3fe45/huaweiborder.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="Semgrep pattern example" title="Semgrep pattern example" src="https://r2c.dev/static/aa680407147acdd651f9df0feda4aa94/3fe45/huaweiborder.png" srcset="https://r2c.dev/static/aa680407147acdd651f9df0feda4aa94/5a46d/huaweiborder.png 300w,
https://r2c.dev/static/aa680407147acdd651f9df0feda4aa94/0a47e/huaweiborder.png 600w,
https://r2c.dev/static/aa680407147acdd651f9df0feda4aa94/3fe45/huaweiborder.png 699w" sizes="(max-width: 699px) 100vw, 699px" loading="lazy">
  </a>
    </span></p>
<p><em><a href="https://assets.publishing.service.gov.uk/government/uploads/system/uploads/attachment_data/file/790270/HCSEC_OversightBoardReport-2019.pdf" target="_blank" rel="noopener">Report from the Huawei Cyber Security Evaluation Centre Oversight Board</a>, page 29, March 2019</em></p>
<p>In net, the report found that about 11% of <code>memcpy</code>-like and 22% of <code>strcpy</code>-like function calls in the codebase were to the least safe variants. And assuming safety just from the function name is simplistic‚Äîeven the <em>safe</em> variants could still be dangerous.</p>
<p>In Huawei‚Äôs defense, while they have been subjected to an unusual level of public scrutiny they are definitely not an outlier in having trouble getting developers to adopt secure coding guidelines. In the <code>memcpy</code> case, it‚Äôs been <a href="https://web.archive.org/web/20090519182728/http://msdn.microsoft.com/en-us/library/bb288454.aspx" target="_blank" rel="noopener">banned at Microsoft</a> <a href="https://www.theregister.com/2009/05/15/microsoft_banishes_memcpy/" target="_blank" rel="noopener">since 2009</a>, but I haven‚Äôt personally seen any other companies outside the FAANG (Facebook/Apple/Amazon/Netflix/Google) that have done the same. You can actually tell who has banned the bad POSIX functions empirically, by looking at binaries‚Äîa non-profit named CITL did a great overview of this and more in the IoT space. As you‚Äôd probably guess, the <a href="https://cyber-itl.org/2019/08/26/iot-data-writeup.html" target="_blank" rel="noopener">results are dismal</a>.</p>
<p><a href="https://twitter.com/clintgibler" target="_blank" rel="noopener">Clint Gibler</a> and I <a href="https://r2c.dev/global-appsec-sf-2020" target="_blank" rel="noopener">recently presented</a> at Global AppSec SF 2020 about what we think are some of the core principles for successfully bridging the developer/security divide. If you‚Äôre looking for a quick takeaway, we suggest three principles:</p>
<ol>
<li>Be fast: scanning should run in parallel and be <em>faster than the slowest test</em>. Otherwise you‚Äôre blocking developer workflow.</li>
<li>Be early: if you‚Äôre going to complain, the editor is better than commit-time is better than CI.</li>
<li>Autofix: don‚Äôt just complain, offer a fix. Even an imperfect suggestion is better than nothing.</li>
</ol>
<hr>
<p>P.S. If you have a giant C codebase sitting around and you want to figure out how much <code>strcpy</code> is used, the two fastest ways are probably <a href="https://blog.burntsushi.net/ripgrep/" target="_blank" rel="noopener">ripgrep, a hyper-fast grep</a> (noisy, fastest) or <a href="https://semgrep.dev/" target="_blank" rel="noopener">Semgrep, a semantic grep-for-code</a> (precise, slower; full disclosure‚ÄîI work on Semgrep!). Here‚Äôs how you could do it in both:</p>
<div data-language="shell"><pre><code><span>(</span>webkit@aadf31<span>)</span> $ rg --quiet --stats strcpy -tc
<span>163</span> matches
<span>..</span>.</code></pre></div>
<p>But ripgrep includes some false positives, like commented code:</p>
<div data-language="shell"><pre><code><span>45</span>:// string.h is not guaranteed to provide strcpy on C++ Builder.</code></pre></div>
<p>We could obviously try to improve our regex to avoid <code>//</code> at the start of the line, but then we‚Äôd have to consider <code>/*</code> also, plus a lot more if we really want to do it right, so it might be nice to have a proper parser, which is what Semgrep provides. If you‚Äôre curious about the syntax, there‚Äôs an <a href="https://semgrep.dev/learn" target="_blank" rel="noopener">online tutorial</a> that takes a few minutes or you can <a href="https://semgrep.dev/docs" target="_blank" rel="noopener">read the docs</a>.</p>
<div data-language="shell"><pre><code><span>(</span>webkit@aadf31<span>)</span> $ semgrep -e <span>"memcpy(...)"</span> --lang<span>=</span>c <span>.</span>
<span>..</span>.
ran <span>1</span> rules on <span>1710</span> files: <span>80</span> findings</code></pre></div>
<p>(Note that Semgrep has some parse failures on Webkit; <a href="https://semgrep.dev/docs/status/" target="_blank" rel="noopener">C support is still in alpha</a>)</p></div></div></div></section></div>]]>
            </description>
            <link>https://r2c.dev/blog/2020/when-devsecops-goes-wrong-a-short-lesson-from-huaweis-source-code/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25477069</guid>
            <pubDate>Sat, 19 Dec 2020 12:41:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[PC Engine / TurboGrafx-16 Architecture ‚Äì A Practical Analysis]]>
            </title>
            <description>
<![CDATA[
Score 32 | Comments 5 (<a href="https://news.ycombinator.com/item?id=25476926">thread link</a>) | @Parseus
<br/>
December 19, 2020 | https://www.copetti.org/projects/consoles/pc-engine/ | <a href="https://web.archive.org/web/*/https://www.copetti.org/projects/consoles/pc-engine/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div class="page"><nav id="navbar"></nav><h2>A Practical Analysis</h2><hr><div><ul><li><a href="#cover-model">Model</a></li><li><a href="#cover-motherboard">Motherboard</a></li><li><a href="#cover-diagram">Diagram</a></li></ul><div><div id="cover-motherboard"><figcaption>Showing the TurboGrafx's motherboard<br>The PC Engine one was considerably smaller and stacked</figcaption></div><div id="cover-diagram"><a href="https://www.copetti.org/images/consoles/pcengine/diagram.png"><picture>
<img width="1286" height="614" alt="Diagram" loading="auto" src="https://www.copetti.org/images/consoles/pcengine/diagram.png"></picture></a><figcaption>Looks pretty simple, huh?</figcaption></div></div></div><hr><h2 id="a-quick-introduction">A quick introduction</h2><p>Hudson and NEC joined forces to kickstart the 4th generation of consoles. Unfortunately, their efforts will be eventually eclipsed once the competition arrives. Nonetheless, their console will stay on the top as one of the most compact designs in the market.</p><hr><h2 id="models-and-variants">Models and variants</h2><p>Just like the Master system, NEC shipped a lot of revisions and strange variations which can be a bit troubling to follow at first. So, for future reference, here are the most important models:</p><ul><li><strong>PC Engine</strong>: The first console featuring this architecture, but only released in Japan. It looks like a small white box with minimal ports.</li><li><strong>TurboGrafx-16</strong>: Redesigned PC Engine for the American market. It has the same features with a different external appearance. Reminds me of the <a href="https://www.copetti.org/projects/consoles/nes/">NES/Famicom adaptation</a>.</li><li><strong>Supergrafx</strong>: Enhanced version of the PC Engine with a completely different case and new hardware. Its exclusive features are out of the scope of this article.</li><li><strong>PC Engine Duo/TurboDuo</strong>: A combination of the PC Engine/TurboGrafx and the aftermarket CD-ROM¬≤ expansion.</li></ul><p>This article will focus on the PC Engine/TurboGrafx-16, but will also discuss the expansions that led to the release of the PC Engine Duo/TurboDuo.</p><hr><h2 id="cpu">CPU</h2><p>Inside this console, we find the <strong>HuC6280</strong>, a chip made by <strong>Hudson Soft</strong> that houses two components. One of them is the CPU, which can operate at two speeds: <strong>~1.79 MHz</strong> and <strong>~7.16 MHz</strong>.</p><p>The HuC6280 is not an off-the-shelf component, like the <a href="https://www.copetti.org/projects/consoles/master-system/#cpu">Z80</a>, but instead a proprietary CPU designed by NEC. After checking out the official docs, it does seem to replicate a lot of behaviour from the famous <strong>MOS 6502</strong> and <strong>WDC‚Äôs 65C02</strong>. That being said, what does all of this mean for the programmer?</p><p>Before we start, we‚Äôve already covered some parts of the MOS 6502 <a href="https://www.copetti.org/projects/consoles/nes/#cpu">here</a> and also described a 16-bit variant made by WDC and Ricoh <a href="https://www.copetti.org/projects/consoles/super-nintendo/#cpu">here</a>, in case you want to check them out first.</p><p>The 65C02 is another modified version of the MOS 6502 made by Western Design Center, it‚Äôs a lot more efficient due to its manufacturing approach (CMOS). From the software side, the 65C02 adds a couple of new instructions and modifies the behaviour of some existing ones.</p><p>We could a lot more about the 65C02, but I think it‚Äôs better to focus on the features added by Hudson (complementing the 65C02) because they are critical to efficiently operate this console. Compared to the 65C02, the HuC6280 has:</p><ul><li><strong>More opcodes</strong>, some targeting the components surrounding the CPU.</li><li>An <strong>8-bit I/O port</strong> used to interface external components.</li><li>An <strong>interrupt controller</strong> to receive interrupts from other devices.</li><li>A <strong>timer</strong>. It works by counting down from a specified value and when it finishes, it dispatches an interrupt to the CPU.</li></ul><p>Finally, there are <strong>8 KB of RAM</strong> available for general purpose.</p><h4 id="memory-access">Memory access</h4><p>One thing I didn‚Äôt mention <em>yet</em> is that NEC also added a <strong>Memory Management Unit</strong> or ‚ÄòMMU‚Äô next to the CPU, allowing to handle <strong>21-bit addresses</strong> (remember the original 6502 only has 16-bit addresses). Thus, the amount of memory that can be accessed raises from 64 KB to <strong>2 MB</strong>.</p><p>This MMU is very different from any modern-day MMU. The one found in the PC Engine is composed of <strong>eight 8-bit registers</strong> (called <strong>Mapping Register</strong> or ‚ÄòMPR‚Äô) which are combined with the CPU‚Äôs 16 address lines to form a 21-bit address bus.</p><div><a href="https://www.copetti.org/images/consoles/pcengine/mmu.7db09aefb948cf6a8a5dfb8bfabb5d1b1021970dec3dadcbebef1e688c5d7b06.png"><picture>
<img name="image_cover" alt="Image" width="975" height="323" src="https://www.copetti.org/images/consoles/pcengine/mmu.7db09aefb948cf6a8a5dfb8bfabb5d1b1021970dec3dadcbebef1e688c5d7b06.png" loading="auto"></picture></a><figcaption>Addressing approach of the MMU</figcaption></div><p>This works as follows:</p><ol><li>The CPU can read from and/or write to any MPR using the special <code>TAM</code> and <code>TMA</code> instructions, respectively.</li><li>When physical memory is accessed, the MMU reserves the address lines A13-A16 from the CPU to select one of the eight MPRs.</li><li>The MMU then combines the CPU lines A0-A12 with the 8-bit value of the selected MPR to set A13-A20. Resulting in a 21-bit address.</li></ol><p>Consequently, this MMU groups physical memory in 8 KB pages (12 CPU lines = 8 KB pages), which is the amount of memory the CPU can access without swapping out the MPR nor altering its value.</p><p>Anyway, don‚Äôt overwhelm yourself if you have trouble understanding it (it‚Äôs just an unconventional modus operandi some may find interesting).</p><hr><h2 id="graphics">Graphics</h2><p>This is taken care by the <strong>Hudson Soft HuC6270</strong>, a separate chip also referred to as the <strong>Video Display Controller</strong> or ‚ÄòVDC‚Äô. The HuC6270 will draw everything that the player will see on the screen and its functionality is very similar to <a href="https://www.copetti.org/projects/consoles/master-system/#gpu">Sega‚Äôs counterpart</a>, so please check out that article beforehand since I‚Äôll focus on what‚Äôs different with Hudson‚Äôs offering.</p><h4 id="organising-the-content">Organising the content</h4><p>First things first, the VDC is a <strong>tile engine</strong> (pretty much the standard until the 5th generation showed up) but notice how the PC Engine includes <strong>64 KB of VRAM</strong> which is a significant amount compared to the competition. This may lead to a new type of content, which we‚Äôll check later on.</p><div><a href="https://www.copetti.org/images/consoles/pcengine/graphics/vdc.e0bce70688354b7ea91f7f4b486327b8e8f3d6f3cc82580dfb80b51ec10fb88a.png"><picture>
<img name="image_cover" alt="Image" width="1005" height="482" src="https://www.copetti.org/images/consoles/pcengine/graphics/vdc.e0bce70688354b7ea91f7f4b486327b8e8f3d6f3cc82580dfb80b51ec10fb88a.png" loading="auto"></picture></a><figcaption>Memory architecture of the VDP</figcaption></div><p>The way graphics data is arranged is a bit confusing: Both CPU and VDC use 16-bit addresses, but while the CPU can only handle 8-bit words, the HuC6270 stores 16-bit words in VRAM. This means that a single address in RAM contains a byte while an address in VRAM stores two bytes, so developers had to watch out for that discrepancy when transferring data to VRAM.</p><p>The reason for this comes down to the way Hudson organised the circuitry: The VDC has a 16-bit address bus but <strong>only the first 15 lines are controlled</strong> (the last one is always set to ‚Äò0‚Äô), so odd addresses are fetched from the second byte. I don‚Äôt know why Hudson went down this path, but I do know that all of this would make better sense if the system had instead 128 KB of VRAM (since a 16-bit address bus can only access up to 64 KB, so by somehow doubling the data bus, up to 128 KB can be retrieved). Maybe that was the original plan for Hudson/NEC?</p><h4 id="constructing-the-frame">Constructing the frame</h4><p>Aside from the aforementioned granularity oddity, functionality-wise the VDP is very simple. The subsystem has three main components: The <strong>VDC</strong> and <strong>VRAM</strong>, which we already discussed - and the <strong>video encoder</strong> (also called ‚ÄòVEC‚Äô, we‚Äôll see more about it in due time).</p><p>The system can use multiple resolutions, this is because the game can alter a set of registers that act as parameters for controlling the display timings, which in turn alter when the CRT starts beaming the frame (as opposed to overscan). The minimum resolution is <strong>256 √ó 224 pixels</strong>, while some homebrew has proved this system can go as high as <strong>512 √ó 240 pixels</strong>.</p><p>Now let‚Äôs see how a frame is drawn step by step, for this, I‚Äôll borrow <em>Bonk‚Äôs Adventure</em>‚Äôs assets.</p><div><ul><li id="tab-2-1-tiles-link"><a href="#tab-2-1-tiles">Tiles</a></li><li id="tab-2-2-storing-tiles-link"><a href="#tab-2-2-storing-tiles">Storing tiles</a></li><li id="tab-2-3-background-layer-link"><a href="#tab-2-3-background-layer">Background Layer</a></li><li id="tab-2-4-sprite-layer-link"><a href="#tab-2-4-sprite-layer">Sprite Layer</a></li><li id="tab-2-5-result-link"><a href="#tab-2-5-result">Result</a></li></ul><div><div id="tab-2-1-tiles"><h4>Tiles</h4><p>As a quick reminder, tiles are just <strong>8x8 pixel bitmaps</strong> that the renderer fetches to draw portions of the screen. With the VDC, the frame is composed of two planes: The background layer and the sprite layer.</p><p>Inside VRAM there‚Äôs an area called <strong>Character generator</strong> where tiles exclusive to the background layer are defined. Each pixel of a tile occupies four bits, so it can use up to 16 colours. In theory, up to 4096 background tiles can be defined, but this is less in practice due to VRAM being much smaller.</p><p>Sprites, on the other hand, are drawn using tiles from a separate memory location in VRAM, this is called <strong>Sprite Generator</strong> and differs from the previous Character generator as tiles here are <strong>16x16 pixels</strong> wide.</p><p>The video encoder is a separate chip that stores <strong>32 colour palettes</strong> (16 for the background and 16 for sprites), each palette stores 16 colours and each colour is 9-bit wide (3 bits for Red + 3 bits for Green + 3 bits for Blue).</p></div><div id="tab-2-2-storing-tiles"><h4>Storing tiles</h4><p>(This section is written for those interested in how Hudson took advantage of 64 KB of VRAM with that 16-bit granularity, but you don‚Äôt have to understand it completely to be able to follow the rest of the article).</p><p>So far we‚Äôve discussed that each pixel of a tile is stored using 4 bits (or a half byte, also called a <strong>nibble</strong>). Now, Hudson dictates that <strong>tiles are composed of four 8x8 bitmaps</strong> (called ‚ÄòCH0‚Äô, ‚ÄòCH1‚Äô, ‚ÄòCH2‚Äô and ‚ÄòCH3‚Äô, respectively). Each map is 1-bit wide, but once the four are combined, they form the final tile with 4-bit pixels.</p><p>Also, remember the 16-bit alignment on VRAM? <strong>Each 16-bit word stores a single row of two 1-bit bitmaps</strong> (8 rows + 8 rows). So, after writing eight entries, two maps will be stored (instead of just one). Please have a look at the diagrams to help understand this better.</p><p>The same happens with Sprite tiles, but since they are 16x16 bitmaps, each bitmap occupies 16 words. To put it another way, to store a single sprite tile, 64 words are taken (equivalent to 8 bytes in VRAM).</p></div><div id="tab-2-3-background-layer"><h4>Background Layer</h4><div><a href="https://www.copetti.org/images/consoles/pcengine/graphics/background.08352a4808c29a6f3a808ab30c0e82af9dc2528ac88d7f6ec5816f2caa6af9d8.png"><picture>
<img name="image_cover" alt="Image" width="256" height="232" src="https://www.copetti.org/images/consoles/pcengine/graphics/background.08352a4808c29a6f3a808ab30c0e82af9dc2528ac88d7f6ec5816f2caa6af9d8.png" loading="auto"></picture></a><figcaption>Rendered background layer</figcaption></div><p>The background layer is constructed by filling the <strong>Background Attribute Table</strong> with entries in VRAM, the position of each entry defines X/Y coordinate of the tile in the screen. Each entry contains the tile index from the Character Generator and the colour palette.</p><p>The maximum dimension of this layer is <strong>1024 x 512 pixels</strong> (128 x 64 tiles), but programmers can set up a 256 x 256 pixels (32 x 32 tiles) layer as the minimum.</p><p>As always, this layer is scrollable by changing the value of some registers in the VDC.</p></div><div id="tab-2-4-sprite-layer"><h4>Sprite Layer</h4><div><a href="https://www.copetti.org/images/consoles/pcengine/graphics/sprites.e6213bbc42946458d3f72c2ba5c06210b7f03830671119a02189d229fd33c5a1.png"><picture>
<img name="image_cover" alt="Image" width="256" height="232" src="https://www.copetti.org/images/consoles/pcengine/graphics/sprites.e6213bbc42946458d3f72c2ba5c06210b7f03830671119a02189d229fd33c5a1.png" loading="auto"></picture></a><figcaption>Rendered Sprite layer</figcaption></div><p>The VDC contains an internal memory called <strong>Sprite Attribute Table Buffer</strong> where up to 64 sprites can be defined. Each entry of the table stores the independent X/Y position, colour palette, tile index and H/V flip. Furthermore, there‚Äôs an attribute allowing to combine a sprite with another one.</p><p>Each entry is 8 bytes long, although some space is wasted due to the 16-bit granularity.</p><p>To top it all off, <strong>the CPU can‚Äôt access this table</strong>, so it needs to be completed in VRAM and then activate a DMA channel to copy it to the VDC (so the latter can use it).</p><p>Regarding limitations, there can only be up to 16 sprites per scan-line. On the other side, interrupts can be set so the game can be notified when there‚Äôs been a case of sprite overflow or <a href="https://www.copetti.org/projects/consoles/master-system/#tab-4-1-collision-detection">collision</a>.</p></div><div id="tab-2-5-result"><h4>Result</h4><div><a href="https://www.copetti.org/images/consoles/pcengine/graphics/complete.df6eb72088e9f9cadfdad24e4de6cb63760d6adcf56fc3a9c7120ae14afa685e.png"><picture>
<img name="image_cover" alt="Image" width="256" height="232" src="https://www.copetti.org/images/consoles/pcengine/graphics/complete.df6eb72088e9f9cadfdad24e4de6cb63760d6adcf56fc3a9c7120ae14afa685e.png" loading="auto"></picture></a><figcaption>Tada!</figcaption></div><p>So far we‚Äôve seen how the VDC does all the heavy work, but the last task is actually delegated to the <strong>Video ‚Ä¶</strong></p></div></div></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.copetti.org/projects/consoles/pc-engine/">https://www.copetti.org/projects/consoles/pc-engine/</a></em></p>]]>
            </description>
            <link>https://www.copetti.org/projects/consoles/pc-engine/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25476926</guid>
            <pubDate>Sat, 19 Dec 2020 12:10:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How Shopify Uses WebAssembly Outside of the Browser]]>
            </title>
            <description>
<![CDATA[
Score 239 | Comments 127 (<a href="https://news.ycombinator.com/item?id=25476605">thread link</a>) | @oedmarap
<br/>
December 19, 2020 | https://shopify.engineering/shopify-webassembly | <a href="https://web.archive.org/web/*/https://shopify.engineering/shopify-webassembly">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
  <p>At Shopify we aim to make what most merchants need easy, and the rest possible. We make the rest possible by exposing interfaces to query, extend and alter our Platform. These interfaces empower a rich ecosystem of Partners to solve a variety of problems. The primary mechanism of this ecosystem is an ‚ÄúApp‚Äù, an independently hosted web service which communicates with Shopify over the network. This model is powerful, but comes with a host of technical issues. Partners are stretched beyond their available resources as they have to build a web service that can operate at Shopify‚Äôs scale. Even if Partners‚Äô resources were unlimited, the network latency incurred when communicating with Shopify precludes the use of Apps for time sensitive use cases.</p>
<p>We want Partners to focus on using their domain knowledge to solve problems, and not on managing scalable web services. To make this a reality we‚Äôre keeping the flexibility of untrusted Partner code, but executing it on our own infrastructure. We choose a universal format for that code that ensures it‚Äôs performant, secure, and flexible: WebAssembly.</p>

<p>What is WebAssembly? According to <a href="https://webassembly.org/" target="_blank" title="WebAssembly" rel="nofollow noopener noreferrer">WebAssembly.org</a>:&nbsp;</p>
<p>‚ÄúWebAssembly (abbreviated Wasm) is a binary instruction format for a stack-based virtual machine. Wasm is designed as a portable compilation target for programming languages, enabling deployment on the web for client and server applications.‚Äù</p>
<p>To learn more, see this series of <a href="https://hacks.mozilla.org/2017/02/a-cartoon-intro-to-webassembly/" target="_blank" title="A cartoon intro to WebAssembly" rel="nofollow noopener noreferrer">illustrated articles written by Lin Clark of Mozilla</a> with information on WebAssembly and its history.</p>
<p>Wasm is often presented as a performant language that runs alongside JavaScript from within the Browser. We, however, execute Wasm outside of the browser and with no Javascript involved. Wasm, far from being solely a Javascript replacement, is designed for <a href="https://webassembly.org/docs/non-web/" target="_blank" title="Non-Web Embeddings - WebAssembly" rel="nofollow noopener noreferrer">Web and Non-Web Embeddings alike</a>. It solves the more general problem of performant execution in untrusted environments, which exists in browsers and code execution engines alike. Wasm satisfies our three main technical requirements: security, performance, and flexibility.</p>
<h2>Security</h2>
<p>Executing untrusted code is a dangerous thing‚Äîit's exceptionally difficult to predict by nature, and it has potential to cause harm to Shopify‚Äôs platform at large. While no application is entirely secure, we need to both prevent security flaws and mitigate their impacts when they occur.</p>
<p>Wasm executes within a sandboxed stack-based environment, relying upon explicit imports to allow communication with the host. Because of this, you cannot <strong>express</strong> anything malicious in Wasm. You can only express manipulations of the virtual environment and use provided imports. This differs from bytecodes which have references to the computers or operating systems they expect to run on built right into the syntax.</p>
<p>Wasm also hosts a number of features which protect the user from buggy code, including protected call stacks and runtime type checking. <a href="https://webassembly.org/docs/security/" target="_blank" title="Security - WebAssembly" rel="nofollow noopener noreferrer">More details on the security model of Wasm can be found on WebAssembly.org</a>.</p>
<h2>Performance</h2>
<p>In ecommerce, speed is a competitive advantage that merchants need to drive sales. If a feature we deliver to merchants doesn‚Äôt come with the right tradeoff of load times to customization value, then we may as well not deliver it at all.</p>
<p>Wasm is designed to leverage common hardware capabilities that provide it near native performance on a wide variety of platforms. It‚Äôs used by a community of performance driven developers looking to optimize browser execution. As a result, Wasm and surrounding tooling was built, and continues to be built, with a performance focus.</p>
<h2>Flexible</h2>
<p>A code execution service is only as useful as the developers using it are productive. This means providing first class development experiences in multiple languages they‚Äôre familiar with. As a bytecode format, Wasm is targeted by a number of different compilers. This allows us to support multiple languages for developer use without altering the underlying execution model.</p>
<h2>Community Driven</h2>
<p>We have a fundamental alignment in goals and design, which provides our ‚Äúengineering reason‚Äù for using Wasm. But there‚Äôs more to it than that‚Äîit‚Äôs about the people as well as the technology. If nobody was working on the Wasm ecosystem, or even if it was just on life support in its current state, <strong>we wouldn‚Äôt use it</strong>. WebAssembly is an energized community that‚Äôs constantly building new things and has a lot of potential left to reach. By becoming a part of that community, Shopify stands to gain significantly from that enthusiasm.</p>
<p>We‚Äôre also contributing to that enthusiasm ourselves. We‚Äôre collecting user feedback, discussing feature gaps, and most importantly contributing to the open source tools we depend on. We think this is the start of a healthy reciprocal relationship between ourselves and the WebAssembly community, and we expect to expand these efforts in the future.</p>

<p>Now that we‚Äôve covered WebAssembly and why we‚Äôre using it, let‚Äôs move onto how we‚Äôre executing it.</p>
<p>We use an open source tool called <a href="https://www.fastly.com/blog/announcing-lucet-fastly-native-webassembly-compiler-runtime" target="_blank" title="Announcing Lucet: Fastly‚Äôs native WebAssembly compiler and runtime" rel="nofollow noopener noreferrer">Lucet</a> (originally written by Fastly). As a company, Fastly provides a programmable edge cloud platform. They‚Äôre trying to bring execution of high-volume, short-lived, and untrusted modules closer to where they‚Äôre being requested. This is the same as the problem we‚Äôre trying to solve with our Partner code, so it‚Äôs a natural fit to be using the same tools.</p>
<h3>Lucet</h3>
<p>Lucet is both a runtime and a compiler for Wasm. Modules are represented in Wasm for the safety that representation provides. Recall that you can‚Äôt <em>express</em> anything malicious in Wasm. Lucet takes advantage of this and uses a validation of the Wasm module as a security check. After the validation, the module is compiled to an executable artifact with near bare metal performance. It also supports ahead of time compilation, allowing us to have these artifacts ready to execute at runtime. Lucet containers boast an impressive startup time of <em>35&nbsp;</em><em><span>Œºs</span></em>. That‚Äôs because it‚Äôs a container that doesn‚Äôt need to do anything at all to start up.&nbsp; If you want the full picture, Tyler McMullan, the CTO of Fastly, did a great talk which <a href="https://www.youtube.com/watch?v=QdWaQOgvd-g" target="_blank" title="Lucet: Safe WebAssembly Outside the Browser by Tyler McMullen" rel="nofollow noopener noreferrer">gives an overview of Lucet and how it works</a>.</p>
<figure><img alt="A flow diagram showing how Shopify uses our Wasm engine: Lucet wrapped within a Rust web service which manages the I/O and storage of modules" data-src="https://cdn.shopify.com/s/files/1/0779/4361/files/flow-diagram-shopify-wasm-engine.jpg?v=1608224390" src="https://cdn.shopify.com/s/files/1/0779/4361/files/flow-diagram-shopify-wasm-engine.jpg?v=1608224390">
<figcaption>A flow diagram showing Shopify's Wasm engine</figcaption>
</figure>
<p>We wrap Lucet within a Rust web service which manages the I/O and storage of modules, which we call the Wasm Engine. This engine is called by Shopify during a runtime process, usually a web request, in order to satisfy some function. It then applies the output in context of the callsite. This application could involve the creation of a discount, the enforcement of a constraint, or any form of synchronous behaviour Merchants want to customize within the Platform.</p>
<h3>Execution Performance</h3>
<p>Here‚Äôs some metrics pulled from a recent performance test. During this test, 100k modules were executed per minute for approximately 5 min. These modules contained a trivial implementation of enforcing a limit on the number of items purchased in a cart.&nbsp;</p>
<figure><img alt="A line graph showcasing the time taken to execute a module. The x axis representing the time over the test was running and the y axis is the time represented in ms" data-src="https://cdn.shopify.com/s/files/1/0779/4361/files/Lucet-module-execution.jpg?v=1608225321" src="https://cdn.shopify.com/s/files/1/0779/4361/files/Lucet-module-execution.jpg?v=1608225321">
<figcaption>Time taken to execute a module</figcaption>
</figure>
<p>This chart demonstrates a breakdown of the time taken to execute a module, including I/O with the container and the execution of the module. The y-axis is time in ms, the x-axis is the time over which the test was running.</p>
<p>The light purple bar shows the time taken to execute the module in Lucet, the width of which hovers around 100 Œºs. The remaining bars deal with I/O and engine specifics, and the total time of execution is around 4 ms. All times are 99th percentiles (p99).To put these times in perspective, let‚Äôs compare these times to the request times of <a href="https://shopify.engineering/how-shopify-reduced-storefront-response-times-rewrite" target="_blank" title="How Shopify Reduced Storefront Response Times with a Rewrite" rel="nofollow noopener noreferrer">Storefront Renderer, our performant Online Store rendering service</a>:</p>
<figure><img alt="A line graph showing Storefront Renderer Response time" data-src="https://cdn.shopify.com/s/files/1/0779/4361/files/Storefront-Renderer-Response-Times.jpg?v=1608300459" src="https://cdn.shopify.com/s/files/1/0779/4361/files/Storefront-Renderer-Response-Times.jpg?v=1608300459">
<figcaption>Storefront Renderer response time</figcaption>
</figure>
<p>This chart demonstrates the request time to Storefront Renderer over time. The y-axis is request time in seconds. The x-axis is the time over which the values were retrieved. The light blue line representing the 99th percentile hovers around 700 ms.</p>
<p>Then if we consider the time taken by our module execution process to be generally under 5 ms, we can say that the performance impact of Lucet execution is negligible.</p>
<h2>Generating WebAssembly</h2>
<p>To get value out of our high performance execution engine, we‚Äôll need to empower developers to create compatible Wasm modules. Wasm is primarily intended as a compilation target, rather than something you write by hand (<a href="https://blog.scottlogic.com/2018/04/26/webassembly-by-hand.html" target="_blank" title="Writing WebAssembly By Hand" rel="nofollow noopener noreferrer">though you can write Wasm by hand</a>). This leaves us with the question of what languages we‚Äôll support and to what extent.</p>
<p>Theoretically any language with a Wasm target can be supported, but the effort developers spend to conform to our API is better focused on solving problems for merchants. That‚Äôs why we‚Äôve chosen to provide first class support to a single language that includes tools that get developers up and running quickly.At Shopify, our language of choice is Ruby. However, because Ruby is a dynamic language, we can‚Äôt compile it down to Wasm directly. We explored solutions involving compiling interpreters, but found that there was a steep performance penalty. Because of this, we decided to go with a statically compiled language and revisit the possibility of dynamic languages in the future.</p>
<p>Through our research we found that developers in our ecosystem were most familiar with Javascript. Unfortunately, Javascript was precluded as it‚Äôs a dynamic language like Ruby. Instead, we chose a language with familiar TypeScript-like syntax called <a href="https://www.assemblyscript.org/" target="_blank" title="AssemblyScript" rel="nofollow noopener noreferrer">AssemblyScript</a>.</p>
<h2>Using AssemblyScript</h2>
<p>At first glance, there are a huge number of languages that support a WebAssembly target. Unfortunately, there are two broad categories of WebAssembly compilers which we can‚Äôt use:</p>
<ul>
<li>Compilers that generate environment or language specific artifacts, namely node or the browser. (Examples: <a href="https://github.com/tweag/asterius" target="_blank" title="Asterius: A Haskell to WebAssembly compiler" rel="nofollow noopener noreferrer">Asterius</a>, <a href="https://dotnet.microsoft.com/apps/aspnet/web-apps/blazor" target="_blank" title="Blazor Build client web apps with C#" rel="nofollow noopener noreferrer">Blazor</a>)</li>
<li>Compilers that are designed to work only with a particular Runtime. The modules generated by these compilers rely upon special language specific imports. This is often done to support a language‚Äôs standard library, which expects certain system calls or runtime features to be available. Since we don‚Äôt want to be ‚Ä¶</li></ul></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://shopify.engineering/shopify-webassembly">https://shopify.engineering/shopify-webassembly</a></em></p>]]>
            </description>
            <link>https://shopify.engineering/shopify-webassembly</link>
            <guid isPermaLink="false">hacker-news-small-sites-25476605</guid>
            <pubDate>Sat, 19 Dec 2020 10:54:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Solving Algorithmic Problems in Python with Pytest (2019)]]>
            </title>
            <description>
<![CDATA[
Score 77 | Comments 42 (<a href="https://news.ycombinator.com/item?id=25476503">thread link</a>) | @BerislavLopac
<br/>
December 19, 2020 | https://adamj.eu/tech/2019/04/21/solving-algorithmic-problems-in-python-with-pytest/ | <a href="https://web.archive.org/web/*/https://adamj.eu/tech/2019/04/21/solving-algorithmic-problems-in-python-with-pytest/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
  

  <span>2019-04-21</span>

  

  <img src="https://adamj.eu/tech/assets/2019-04-21-flute.jpg" alt="Pytest Flute" title="Pytest Flute">

  <p>I occasionally enjoy solving algorithmic problems, for example <a href="https://projecteuler.net/">Project Euler</a> or <a href="https://adventofcode.com/">The Advent of Code</a>.
I‚Äôve been doing them since I was a pimply PHP-slinging teenager, competing with my peers across the UK in the British Informatics Olympiad.
It was terribly nerdy and terribly fun.</p>

<p>Algorithmic problems are often used in technical interviews, which I find less fun.
Strict deadlines stress me out.</p>

<p>In either case, using automated tests makes these problems way easier.
I wish I knew this earlier!</p>

<p>Online algorithmic platforms, such as <a href="https://codility.com/">Codility</a>, provide their own automated tests.
You use these for basic validation on some examples, but edge cases are sneakily reserved for final marking.
To ensure your solution covers all the bases, you need to write your own tests.</p>

<p>In Python, there‚Äôs no better test framework than <a href="https://pytest.org/">Pytest</a> - I use it on all my open source projects.
It makes it easy for you to add tests for any Python code.
And it‚Äôs much better than Python‚Äôs built-in <a href="https://docs.python.org/3/library/unittest.html"><code>unittest</code></a>.</p>

<p><code>unittest</code> is an old horse and cart, while <code>pytest</code> is the batmobile.</p>

<p><img src="https://adamj.eu/tech/assets/2019-04-21-pytest.png" alt="Pytest homepage"></p>

<h2 id="an-example">An Example</h2>

<p>Let‚Äôs look at a small problem together using Pytest.
Here‚Äôs the problem statement:</p>

<blockquote>
  <p>Write a function <code>solve(items)</code> that takes <code>items</code>, a list of integers, and returns the smallest integer greater than 0 that appears in the list, or 0 if there is none.</p>

  <p>For example <code>solution([1, 2])</code> should return 1, and <code>solution([-1])</code> should return 0.</p>

  <p>The list <code>items</code> will contain up to 1,000,000 integers.</p>
</blockquote>

<p>First, let‚Äôs write the most basic sketch of a <code>solve</code> function.
Since 0 is a default value to return, if we always return that we can score some easy points.
Create a file called <code>example.py</code> with the contents:</p>

<figure><pre><code data-lang="python"><span>def</span> <span>solve</span><span>(</span><span>items</span><span>):</span>
    <span>return</span> <span>0</span></code></pre></figure>

<p>Let‚Äôs test the function manually by running it in the Python 3 interpreter. Open the command line and run the examples:</p>

<figure><pre><code data-lang="text">$ python
Python 3.7.3 (default, Apr 14 2019, 21:08:36)
[Clang 10.0.1 (clang-1001.0.46.3)] on darwin
Type "help", "copyright", "credits" or "license" for more information.
&gt;&gt;&gt; from example import solve
&gt;&gt;&gt; solve([1, 2])
0
&gt;&gt;&gt; solve([-1])
0</code></pre></figure>

<p>So we failed on the first example, but succeeded with the second.</p>

<p>Doing this each time we modify the code would get tiresome quickly.
We have to restart the interpreter, rerun the import and tests, and manually compare the outputs.
Writing automated tests now, before we‚Äôve tried to solve the problem properly, makes the whole loop faster.
It also makes us think about all the cases up front.</p>

<p>Let‚Äôs write the tests and solve the problem with the <strong>Red, Green, Refactor</strong> pattern.</p>

<h3 id="red">Red</h3>

<p>First, let‚Äôs add tests that fail.</p>

<p>Pytest can work with tests in the same file as our code, as simple functions with names starting <code>test_</code>.
We use Python‚Äôs <code>assert</code> statement to compare the results of our code with our expectations.</p>

<p>Add tests for the two examples:</p>

<figure><pre><code data-lang="python"><span>def</span> <span>solve</span><span>(</span><span>items</span><span>):</span>
    <span>return</span> <span>0</span>


<span>def</span> <span>test_example_1</span><span>():</span>
    <span>assert</span> <span>solve</span><span>([</span><span>1</span><span>,</span> <span>2</span><span>])</span> <span>==</span> <span>1</span>


<span>def</span> <span>test_example_2</span><span>():</span>
    <span>assert</span> <span>solve</span><span>([</span><span>-</span><span>1</span><span>])</span> <span>==</span> <span>0</span></code></pre></figure>

<p>Then install Pytest and run the tests:</p>

<figure><pre><code data-lang="text">$ python -m pip install pytest
Collecting pytest
  Downloading
...
Successfully installed atomicwrites-1.3.0 attrs-19.1.0 more-itertools-7.0.0 pluggy-0.9.0 py-1.8.0 pytest-4.4.1 six-1.12.0
$ pytest example.py
============================= test session starts ==============================
platform darwin -- Python 3.7.3, pytest-4.4.1, py-1.8.0, pluggy-0.chainz.0
rootdir: /Users/chainz/tmp/pytest_algos
collected 2 items

example.py F.                                                            [100%]

=================================== FAILURES ===================================
________________________________ test_example_1 ________________________________

    def test_example_1():
&gt;       assert solve([1, 2]) == 1
E       assert 0 == 1
E        +  where 0 = solve([1, 2])

example.py:5: AssertionError
====================== 1 failed, 1 passed in 0.03 seconds ======================</code></pre></figure>

<p>In the middle of the output, we see the tests in <code>example.py</code> running.
Pytest outputs an <code>F</code> for the failing test, and a dot <code>.</code> for the passing one.</p>

<p>The <code>FAILURES</code> section expands on the failure with the line that failed.
It then shows that <code>solve([1, 2])</code> returned <code>0</code> which doesn‚Äôt compare equal to the expected value <code>1</code>.</p>

<p>The tests we have are a start but they don‚Äôt cover all the cases.
We don‚Äôt have any lists that contain <code>0</code>.
Also two extremes are missing: the empty list and a list of 1,000,000 items.
Long lists could also contain lots of negative or positive integers, so we should try both of these.</p>

<p>Let‚Äôs add more tests.
We can make a list of 1,000,000 items in Python by multiplying a short list.
Add these tests at the end of the file:</p>

<figure><pre><code data-lang="python"><span>def</span> <span>test_empty_list</span><span>():</span>
    <span>assert</span> <span>solve</span><span>([])</span> <span>==</span> <span>0</span>


<span>def</span> <span>test_list_with_zero</span><span>():</span>
    <span>assert</span> <span>solve</span><span>([</span><span>0</span><span>,</span> <span>2</span><span>])</span> <span>==</span> <span>2</span>


<span>def</span> <span>test_long_positive_list</span><span>():</span>
    <span>assert</span> <span>solve</span><span>([</span><span>1</span><span>,</span> <span>2</span><span>,</span> <span>3</span><span>,</span> <span>4</span><span>]</span> <span>*</span> <span>250_000</span><span>)</span> <span>==</span> <span>1</span>


<span>def</span> <span>test_long_negative_list</span><span>():</span>
    <span>assert</span> <span>solve</span><span>([</span><span>-</span><span>1</span><span>,</span> <span>-</span><span>2</span><span>,</span> <span>-</span><span>3</span><span>,</span> <span>-</span><span>4</span><span>]</span> <span>*</span> <span>250_000</span><span>)</span> <span>==</span> <span>0</span></code></pre></figure>

<p>Run them again:</p>

<figure><pre><code data-lang="text">============================= test session starts ==============================
platform darwin -- Python 3.7.3, pytest-4.4.1, py-1.8.0, pluggy-0.9.0
rootdir: /Users/chainz/tmp/pytest_algos
collected 6 items

example.py F..FF.                                                        [100%]

=================================== FAILURES ===================================
________________________________ test_example_1 ________________________________

    def test_example_1():
&gt;       assert solve([1, 2]) == 1
E       assert 0 == 1
E        +  where 0 = solve([1, 2])

example.py:6: AssertionError
_____________________________ test_list_with_zero ______________________________

    def test_list_with_zero():
&gt;       assert solve([0, 2]) == 2
E       assert 0 == 2
E        +  where 0 = solve([0, 2])

example.py:18: AssertionError
___________________________ test_long_positive_list ____________________________

    def test_long_positive_list():
&gt;       assert solve([1, 2, 3, 4] * 250_000) == 1
E       assert 0 == 1
E        +  where 0 = solve(([1, 2, 3, 4] * 250000))

example.py:22: AssertionError
====================== 3 failed, 3 passed in 0.08 seconds ======================</code></pre></figure>

<p>There are more failures - which is good!</p>

<h3 id="green">Green</h3>

<p>Now we can work to a solution that makes all the tests pass.
Replace <code>solve</code> with this first attempt:</p>

<figure><pre><code data-lang="python"><span>def</span> <span>solve</span><span>(</span><span>items</span><span>):</span>
    <span>minimum</span> <span>=</span> <span>0</span>
    <span>for</span> <span>i</span> <span>in</span> <span>items</span><span>:</span>
        <span>if</span> <span>minimum</span> <span>==</span> <span>0</span> <span>or</span> <span>i</span> <span>&lt;</span> <span>minimum</span><span>:</span>
            <span>minimum</span> <span>=</span> <span>i</span>
    <span>return</span> <span>minimum</span></code></pre></figure>

<p>Re-run the tests:</p>

<figure><pre><code data-lang="text">============================= test session starts ==============================
platform darwin -- Python 3.7.3, pytest-4.4.1, py-1.8.0, pluggy-0.9.0
rootdir: /Users/chainz/tmp/pytest_algos
collected 6 items

example.py .F...F                                                        [100%]

=================================== FAILURES ===================================
________________________________ test_example_2 ________________________________

    def test_example_2():
&gt;       assert solve([-1]) == 0
E       assert -1 == 0
E        +  where -1 = solve([-1])

example.py:14: AssertionError
___________________________ test_long_negative_list ____________________________

    def test_long_negative_list():
&gt;       assert solve([-1, -2, -3, -4] * 250_000) == 0
E       assert -4 == 0
E        +  where -4 = solve(([-1, -2, -3, -4] * 250000))

example.py:30: AssertionError
====================== 2 failed, 4 passed in 0.17 seconds ======================</code></pre></figure>

<p>We have two different failures now.
It seems we have yet to ignore negative numbers, woops!</p>

<p>Modify the solution to do so, by adding the <code>i &gt; 0</code> condition:</p>

<figure><pre><code data-lang="python"><span>def</span> <span>solve</span><span>(</span><span>items</span><span>):</span>
    <span>minimum</span> <span>=</span> <span>0</span>
    <span>for</span> <span>i</span> <span>in</span> <span>items</span><span>:</span>
        <span>if</span> <span>i</span> <span>&gt;</span> <span>0</span> <span>and</span> <span>(</span><span>minimum</span> <span>==</span> <span>0</span> <span>or</span> <span>i</span> <span>&lt;</span> <span>minimum</span><span>):</span>
            <span>minimum</span> <span>=</span> <span>i</span>
    <span>return</span> <span>minimum</span></code></pre></figure>

<p>Now re-run the tests:</p>

<figure><pre><code data-lang="collected">def solve(items):
    return min((i for i in items if i &gt; 0), default=0)</code></pre></figure>

<p>Re-running the tests produces the same, all-passing output as above.
Yay, we got the code down to one line!</p>

<h2 id="fin">Fin</h2>

<p>I hope this tutorial has been useful, and you use this technique to level up your algorithmic game,</p>

<p>‚ÄîAdam</p>

<p>Thanks to <a href="https://www.linkedin.com/in/mafaldammarques/">Mafalda Marques</a> for testing this tutorial.</p>


  
  <hr>

  <p>
    <strong>Working on a Django project?</strong>
    Check out my book <a href="https://gumroad.com/l/suydt">Speed Up Your Django Tests</a> which covers loads of best practices so you can write faster, more accurate tests.
  </p>

  

  

  <hr>

  
<p><small>One summary email a week, no spam, I pinky promise.</small></p>


  
    <p>
      <strong>Related posts:</strong>
    </p>
    <ul>
    
      
      
      <li><a href="https://adamj.eu/tech/2019/10/03/my-most-used-pytest-commandline-flags/">My Most Used Pytest Commandline Flags</a></li>
      
    
      
      
      <li><a href="https://adamj.eu/tech/2019/07/05/tuples-versus-lists-in-python/">Tuples versus Lists in Python</a></li>
      
    
    </ul>
  

  <p>
  <strong>Tags:</strong>
  
    <a href="https://adamj.eu/tech/tag/pytest/">pytest</a>, 
  
    <a href="https://adamj.eu/tech/tag/python/">python</a>
  
  </p>

  <p>¬© 2020 All rights reserved.</p>



  

</article></div>]]>
            </description>
            <link>https://adamj.eu/tech/2019/04/21/solving-algorithmic-problems-in-python-with-pytest/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25476503</guid>
            <pubDate>Sat, 19 Dec 2020 10:23:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Countries build 9 mile wide tree wall across Africa to prevent Sahara advancing (2014)]]>
            </title>
            <description>
<![CDATA[
Score 50 | Comments 13 (<a href="https://news.ycombinator.com/item?id=25474895">thread link</a>) | @Circumnavigate
<br/>
December 18, 2020 | http://www.alearned.com/green-wall-of-africa/ | <a href="https://web.archive.org/web/*/http://www.alearned.com/green-wall-of-africa/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		<p>12 <strong>African</strong> nations have come together pledging to build a 9 mile wide band of trees that will stretch all the way across Africa, 4750 miles, in order to stop the progressive advancement of the Sahara.</p><!-- START-WP-ADS-ID: 2 --><!-- END-WP-ADS-PRIO -->
<p>Senegal is leading a 12 African nations to build a living defense system appropriately named the Great Green Wall of Africa.</p>
<p>The Sahara is currently the 2nd largest desert in size, only smaller than Antarctica. However, unlike its frozen relative, the Sahara is actually expanding.</p>
<p>The United Nations estimates that, by 2025, 60 % of Africa‚Äôs arable land will be covered in Saharan sand, significantly expanding the current 9 million square km‚Äôs. Even if these estimations prove aggressive, the effects of farmland exploitation on a region already hard-pressed for food would be devastating on any level.<br>
With this danger in sight, the leaders of Senegal, Mauritania, Mali, Burkina Faso, Niger, Nigeria, Chad, Sudan, Eritrea, Ethiopia, and Djibouti have banded together on an remarkable effort to prevent approaching disaster.</p>
<p><a href="http://www.alearned.com/wp-content/uploads/2014/07/great-green-wall-full-300x239.jpg"><img src="http://www.alearned.com/wp-content/uploads/2014/07/great-green-wall-full-300x239.jpg" alt="Africa" width="300" height="239"></a></p>
<p>Once complete, Africa‚Äôs Green Wall will be a manmade forest of drought-resistant trees (principally acacia) extending across the entire region.<br>
9 miles wide and 4,750 miles long, the vision for the project is as committed as it is necessary. Thus far, only 330 miles of greenery stands guard in Northern Senegal, and has cost the Sengalese government over $6 million since the start of digging in 2008. International organizations have pledged over $3 billion to the enormous defense system.</p>
<p><iframe src="//www.youtube.com/embed/jI_nRHg-0l4" width="560" height="315" frameborder="0" allowfullscreen="allowfullscreen"></iframe></p>
<p>Leaders point out that the Great Green Wall is about more than just defense from windblown sand. The project will bring thousands of jobs to poor communities, and has already transformed usually useless land into gardens scattered with tree nurseries.</p>
<p>The increase of tourists, scientists, and medical professionals has also brought attention and resources to a neglected region in which aid is scarce and doctors are not readily available to needy people.</p>
<!-- START-WP-ADS-ID: 1 --><!-- END-WP-ADS-PRIO -->			</div></div>]]>
            </description>
            <link>http://www.alearned.com/green-wall-of-africa/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25474895</guid>
            <pubDate>Sat, 19 Dec 2020 03:59:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Virtual Machine Detection in the Browser (2019)]]>
            </title>
            <description>
<![CDATA[
Score 161 | Comments 93 (<a href="https://news.ycombinator.com/item?id=25474183">thread link</a>) | @blindm
<br/>
December 18, 2020 | https://bannedit.github.io/Virtual-Machine-Detection-In-The-Browser.html | <a href="https://web.archive.org/web/*/https://bannedit.github.io/Virtual-Machine-Detection-In-The-Browser.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <h3>Introduction</h3>
<p>Virtual Machine (VM) detection is nothing new. Malware has been doing it for over a decade now. Over time the techniques have advanced as defenders learned new ways of avoiding VM detection.</p>
<p>A while back a friend and I were working on a project related to exploit delivery via a web application for redteaming purposes. I wanted a way to fingerprint visitors of the site and hash the fingerprint data so I could look for potential repeat visitors. While investigating fingerprinting I stumbled upon something pretty interesting. I was looking at some code that collected information about WebGL capabilities. I quickly realized that some of the fingerprinting information could be useful for VM detection because vendor names were exposed. In this particular instance the string "VMWare" was contained within the WebGL information. After some more testing I also discovered that VirtualBox reported the same kind of information. </p>
<p>Once I realized it was potentially possible to detect VMs from the browser I started to dig deeper and began searching for other research related to this discovery. I found a pretty well researched academic paper <a href="http://yinzhicao.org/TrackingFree/crossbrowsertracking_NDSS17.pdf">[1]</a> related to tracking users across multiple browsers. This gave me some other potential techniques that could be applied to VM detection.</p>
<p>The end goal of this research is to have multiple techniques for VM detection. Multiple techniques lead to much more accurate detection. Since some techniques are more false-positive prone than others, a weighting system can be applied to the detection capabilities. This allows us to generate detection confidence scoring. This can help account for inaccuracies of certain detection methods. Given enough testing and data it would then be possible to come up with a reasonable threshold value. If a browser scores above the threshold then it would most likely be within a VM. Alternatively, if the browser scored below the threshold value it could be considered to be running on physical hardware.</p>
<h3>Techniques</h3>
<p>Now that I have covered some of the background information and history leading up to this blog post we can start to dig into the actual techniques.</p>
<p>As mentioned prior in the introduction, WebGL can provide a lot of information about the OpenGL implementation including vendor information. The WEBGL_debug_renderer_info extension <a href="https://developer.mozilla.org/en-US/docs/Web/API/WEBGL_debug_renderer_info">[2]</a> can be used to query for debug information such as the WebGL vendor and rendered.</p>
<div><pre><span></span><span>var</span> <span>canvas</span> <span>=</span> <span>document</span><span>.</span><span>createElement</span><span>(</span><span>'canvas'</span><span>);</span>
<span>var</span> <span>gl</span> <span>=</span> <span>canvas</span><span>.</span><span>getContext</span><span>(</span><span>'webgl'</span><span>);</span>

<span>var</span> <span>debugInfo</span> <span>=</span> <span>gl</span><span>.</span><span>getExtension</span><span>(</span><span>'WEBGL_debug_renderer_info'</span><span>);</span>
<span>var</span> <span>vendor</span> <span>=</span> <span>gl</span><span>.</span><span>getParameter</span><span>(</span><span>debugInfo</span><span>.</span><span>UNMASKED_VENDOR_WEBGL</span><span>);</span>
<span>var</span> <span>renderer</span> <span>=</span> <span>gl</span><span>.</span><span>getParameter</span><span>(</span><span>debugInfo</span><span>.</span><span>UNMASKED_RENDERER_WEBGL</span><span>);</span>

<span>console</span><span>.</span><span>log</span><span>(</span><span>vendor</span><span>);</span>
<span>console</span><span>.</span><span>log</span><span>(</span><span>renderer</span><span>);</span>
</pre></div>


<p>Additionally, extension availability can be queried using the <strong><em>getExtension</em></strong> method on a WebGL context. I have not fully explored this avenue but it might be possible to detect certain WebGL implementations provided by VMs based on the extensions available. Though this idea is likely very false-positive prone.</p>
<p>Below is a screenshot from <a href="https://webglreport.com/">[3]</a> WebGLReport a website dedicated to fingerprinting WebGL.</p>
<blockquote>
<p><img alt="alt-text" src="https://bannedit.github.io/resources/VirtualBox-VM-Win10-Chrome.png" title="VirtualBox Windows 10 x64 VM Google Chrome Visiting webglreport.com">
<strong><em>VirtualBox Windows 10 x64 VM Google Chrome Visiting webglreport.com</em></strong></p>
</blockquote>
<p>Now, it is important to note that this depends on how the VM is configured. In Virtual Box for example, setting the graphics controller setting under Display to VMSVGA will report cause WebGL to use CPU based implementations of OpenGL which is browser dependent. However, this could still be a useful indicator that the client machine is running in a VM because most modern hardware has integrated GPUs and can provide access to OpenGL natively. Just keep in mind that CPU based OpenGL implementations do not necessarily mean it is a VM outright.</p>
<blockquote>
<p><img alt="alt-text" src="https://bannedit.github.io/resources/VirtualBox-VM-Win10-Chrome-VMSVGA.png" title="VirtualBox Windows 10 x64 VM Google Chrome Using VMSVGA">
<strong><em>VirtualBox Windows 10 x64 VM Google Chrome Using VMSVGA Visiting webglreport.com</em></strong></p>
</blockquote>
<p>This screenshot depicts Google Chrome utilizing the CPU based OpenGL implementation renderer Google SwiftShader <a href="https://github.com/google/swiftshader">[4]</a>.</p>
<p>Another technique seen in normal malware is to determine the screen width and height. This can be achieved in Javascript as well. Additionally, color depth and bits per pixel are other potentially good indicators related to the display.</p>
<div><pre><span></span><span>var</span> <span>width</span> <span>=</span> <span>screen</span><span>.</span><span>width</span><span>;</span>
<span>var</span> <span>height</span> <span>=</span> <span>screen</span><span>.</span><span>height</span><span>;</span>
<span>var</span> <span>color_depth</span> <span>=</span> <span>screen</span><span>.</span><span>colorDepth</span><span>;</span>
<span>var</span> <span>bitspp</span> <span>=</span> <span>screen</span><span>.</span><span>pixelDepth</span><span>;</span>
</pre></div>


<p>More details on the screen object can be found at <a href="https://www.w3schools.com/jsref/obj_screen.asp">[5]</a>.</p>
<p>Can we detect the amount of RAM on the client? You bet. Again using Javascript we can determine roughly the amount of RAM available on the browser. One quirk to note here is that the browser will only report RAM values in gigabytes (gb). It also has a quirk where it will only report up to 8gb and as low as 256mb (0.25gb). These ranges of values however, are still enough to use as a VM detection method. Most physical workstations these days come with at least 8gb of RAM. Detecting smaller amounts of RAM such as 2gb or less would be a good indicator the client browser is in a VM. The specification for the Device Memory can be found at <a href="https://www.w3.org/TR/device-memory/">[6]</a></p>
<div><pre><span></span><span>var</span> <span>ram</span> <span>=</span> <span>navigator</span><span>.</span><span>deviceMemory</span><span>;</span>
</pre></div>


<p>Finally, the last technique I will be covering detects the number of CPU cores. This is done by performing timing attacks using multiple web workers running simultaneously. During my testing of this technique I found it to be very accurate. I tested this concept out using the <a href="https://oswg.oftn.org/projects/core-estimator/demo/">[7]</a> Core Estimator Demo site. A small number of CPU cores can be a decent VM indicator and has been used by malware in the past. Core Estimator also provides the Javascript libraries on github <a href="https://github.com/oftn-oswg/core-estimator">[8]</a>.</p>
<blockquote>
<p><img alt="alt-text" src="https://bannedit.github.io/resources/VirtualBox-VM-Win10-Chrome-2-Cores.png" title="VirtualBox Windows 10 x64 VM Chrome With 2 CPU Cores">
<strong><em>VirtualBox Windows 10 x64 VM Google Chrome 2 CPU Cores Tested with Core Estimator</em></strong></p>
</blockquote>
<h3>Conclusion</h3>
<p>This blog post covered four unique VM detection capabilities that can be performed from Javascript. When I first discovered these techniques my initial thought was to apply the concepts toward VM detection. Hopefully, both defenders and offensive security professions can find something useful to apply these techniques toward.</p>
<p>It is interesting to see that academics and various other researchers have applied some of the same concepts toward fingerprinting and privacy issues. </p>
<h3>References</h3>
<ol>
<li>
<p>(Cross-)Browser Fingerprinting via OS and
Hardware Level Features <a href="http://yinzhicao.org/TrackingFree/crossbrowsertracking_NDSS17.pdf">http://yinzhicao.org/TrackingFree/crossbrowsertracking_NDSS17.pdf</a></p>
</li>
<li>
<p>MDN web-docs WEBGL_debug_renderer_info <a href="https://developer.mozilla.org/en-US/docs/Web/API/WEBGL_debug_renderer_info">https://developer.mozilla.org/en-US/docs/Web/API/WEBGL_debug_renderer_info</a></p>
</li>
<li>
<p>WebGL Report <a href="https://webglreport.com/">https://webglreport.com</a></p>
</li>
<li>
<p>Google Swiftshader Github <a href="https://github.com/google/swiftshader">https://github.com/google/swiftshader</a>  </p>
</li>
<li>
<p>W3 Device Memory Specification <a href="https://www.w3.org/TR/device-memory/">https://www.w3.org/TR/device-memory/</a></p>
</li>
<li>
<p>W3 Schools - The Screen Object <a href="https://www.w3schools.com/jsref/obj_screen.asp">https://www.w3schools.com/jsref/obj_screen.asp</a></p>
</li>
<li>
<p>Core Estimator Demo <a href="https://oswg.oftn.org/projects/core-estimator/demo/">https://oswg.oftn.org/projects/core-estimator/demo/</a></p>
</li>
<li>
<p>Core Estimator Github <a href="https://github.com/oftn-oswg/core-estimator">https://github.com/oftn-oswg/core-estimator</a></p>
</li>
</ol>
  </div></div>]]>
            </description>
            <link>https://bannedit.github.io/Virtual-Machine-Detection-In-The-Browser.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25474183</guid>
            <pubDate>Sat, 19 Dec 2020 01:39:03 GMT</pubDate>
        </item>
    </channel>
</rss>
