<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 20]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 20. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Wed, 19 Aug 2020 12:25:39 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-20.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Wed, 19 Aug 2020 12:25:39 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[A-Levels: The Model is not the Student]]>
            </title>
            <description>
<![CDATA[
Score 41 | Comments 26 (<a href="https://news.ycombinator.com/item?id=24185621">thread link</a>) | @tosh
<br/>
August 17, 2020 | http://thaines.com/post/alevels2020 | <a href="https://web.archive.org/web/*/http://thaines.com/post/alevels2020">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>http://thaines.com/post/alevels2020</link>
            <guid isPermaLink="false">hacker-news-small-sites-24185621</guid>
            <pubDate>Mon, 17 Aug 2020 09:47:17 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[ACCC: Response to Google Open Letter]]>
            </title>
            <description>
<![CDATA[
Score 121 | Comments 81 (<a href="https://news.ycombinator.com/item?id=24185374">thread link</a>) | @ajdlinux
<br/>
August 17, 2020 | https://www.accc.gov.au/media-release/response-to-google-open-letter | <a href="https://web.archive.org/web/*/https://www.accc.gov.au/media-release/response-to-google-open-letter">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section id="content-column">
              
            <div id="readspeaker-process">
        <section>
                                
                            </section>
        <div>
          <section>
                                                                                                    <div>
    <section id="block-system-main">

      
  <div>
    <article id="node-87993" about="/media-release/response-to-google-open-letter" typeof="sioc:Item foaf:Document">
    <header>
            <span property="dc:title" content="Response to Google open letter"></span>      </header>
    <div><div><div property="content:encoded"><p>The open letter published by Google today contains misinformation about the draft news media bargaining code which the ACCC would like to address.&nbsp;</p>

<p>Google will not be required to charge Australians for the use of its free services such as Google Search and YouTube, unless it chooses to do so.</p>

<p>Google will not be required to share any additional user data with Australian news businesses unless it chooses to do so.</p>

<p>The draft code will allow Australian news businesses to negotiate for fair payment for their journalists’ work that is included on Google services.</p>

<p>This will address a significant bargaining power imbalance between Australian news media businesses and Google and Facebook.</p>

<p>A healthy news media sector is essential to a well-functioning democracy.</p>

<p>We will continue to consult on the draft code with interested parties, including Google.</p>

<p><a href="https://www.accc.gov.au/focus-areas/digital-platforms/news-media-bargaining-code/draft-legislation">Consultation</a> closes on 28 August 2020.</p>

<p>More information about the draft news media bargaining code can be found here:&nbsp;<a href="https://www.accc.gov.au/media-release/australian-news-media-to-negotiate-payment-with-major-digital-platforms">Australian news media to negotiate payment with major digital platforms</a></p>
</div></div></div>    </article>
  </div>

</section> <!-- /.block -->
<section id="block-service-links-service-links">

        <p>
      <h2>Share</h2>
    </p>
    
  

</section> <!-- /.block -->
  </div>
                                  </section>
                  </div>
      </div>
    </section></div>]]>
            </description>
            <link>https://www.accc.gov.au/media-release/response-to-google-open-letter</link>
            <guid isPermaLink="false">hacker-news-small-sites-24185374</guid>
            <pubDate>Mon, 17 Aug 2020 08:59:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Handmade: A Community for Self-Rolled Performant Software (2016)]]>
            </title>
            <description>
<![CDATA[
Score 61 | Comments 17 (<a href="https://news.ycombinator.com/item?id=24184688">thread link</a>) | @TheUndead96
<br/>
August 16, 2020 | https://handmade.network/manifesto | <a href="https://web.archive.org/web/*/https://handmade.network/manifesto">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <div>
        
            <div>
                
                
    <div>
        
        
            

<p> Modern computer hardware is amazing. Manufacturers have orchestrated billions of pieces of silicon into terrifyingly complex and efficient structures that sweep electrons through innumerable tangled paths, branchings, and reunions with the sole purpose of performing computations at more than a billion times per second. This awe-inspiring piece of computational wizardry has at its disposal multiple billions of uniquely addressible silicon plates where it can store the results of millions of computations in an array of several vanishingly small chips. All of this hardware, though each component often sits no further than 7 or 8 centimeters away from the others, cycles so fast that the speed of light, a physical law of the universe, limits the rate at which they communicate with each other.
</p><p><span>So why is software still slow?</span>
</p><p>Why does it take your operating system 10 seconds, 30 seconds, a minute to boot up? Why does your word processor freeze when you save a document on the cloud? Why does your web browser take 3, 4, 10 seconds to load a web page? Why does your phone struggle to keep more than a few apps open at a time? And why does each update somehow make the problem worse?
</p><p><span>We made it slow</span>.
</p><p>Not necessarily you, not necessarily me, not necessarily any single person in particular. But we, the software development community, made it slow by ignoring the fundamental reality of our occupation. We write code, code that runs on computers. Real computers, with central processing units and random access memory and hard disk drives and display buffers. Real computers, with integer and bitwise math and floating point units and L2 caches, with threads and cores and a tenuous little network connection to a million billion other computers. Real computers not built for ease of human understanding but for blindingly, incomprehensibly fast speed.
</p><p><span>A lot of us have forgotten that</span>.
</p><p>In our haste to get our products, our projects, the works of our hands and minds, to as many people as possible, we take shortcuts. We make assumptions. We generalize, and abstract, and assume that just because these problems have been solved before that they never need to be solved again. We build abstraction layers, then forget we built them and build more on top.
</p><p>And it's true that many of us think we do not have the time, the money, the mental bandwidth to always consider these things in detail. The deadline is approaching or the rent is due or we have taxes to fill out and a manager on our back and someone asking us why we always spend so much time at the office, and we just have to stick the library or virtual machine or garbage collector in there to cover up the places we can't think through right now.
</p><p>Others of us were never taught to think about the computer itself. We learned about objects and classes and templates and how to make our code clean and pretty. We learned how to write code to make the client or the manager or the teacher happy, but made the processor churn. And because we did, that amazing speed we'd been granted was wasted, by us, in a death by a thousand abstraction layers.
</p><p><span>But some of us aren't satisfied with that.</span>
</p><p>Some of us take a few extra steps into the covered territory, the wheels sitting, motionless, in a pile behind us, examine their designs and decide there is a better way. The more experienced among us remember how software used to be, the potential that we know exists for computer programs to be useful, general, <em>and</em> efficient. Others of us got fed up with the tools we were expected to use without complaint, but which failed us time and time again. Some of us are just curious and don't know what's good for us. Don't trust what we've been told is good for us.
</p><p>We sat down and looked at our hardware, and examined our data, and thought about how to use the one to transform the other. We tinkered, and measured, and read, and compared, and wrote, and refined, and modified, and measured again, over and over, until we found we had built the same thing, but 10 times faster and incomparably more useful to the people we designed it for. And we had built it by hand.
</p><p>That is what Handmade means. It's not a technique or a language or a management strategy, it isn't a formula or a library or an abstraction. It's an idea. The idea that we can build software that works with the computer, not against it. The idea that sometimes an individual programmer can be more productive than a large team, that a small group can do more than an army of software engineers and *do it better*. The idea that programming is about transforming data and we wield the code, the tool we use to bend that data to our will.
</p><p> It doesn't require a degree, or a dissertation, or a decade of experience. You don't need an
expensive computer or a certificate or even prior knowledge. All you need is an open mind and a sense of
curiosity. We'll help you with the rest.
</p><p><span>Will you join us?</span>
</p><p>Will you build your software by hand?</p>

        
        
        <p>
            
                Last updated by Andrew Chronister on April 23, 2016, 1:39 a.m.
            
        </p>
    </div>

                
            </div>
        
    </div>
    
</div></div>]]>
            </description>
            <link>https://handmade.network/manifesto</link>
            <guid isPermaLink="false">hacker-news-small-sites-24184688</guid>
            <pubDate>Mon, 17 Aug 2020 06:56:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How long since Google said a Google Drive Linux client is coming?]]>
            </title>
            <description>
<![CDATA[
Score 140 | Comments 94 (<a href="https://news.ycombinator.com/item?id=24183399">thread link</a>) | @zdw
<br/>
August 16, 2020 | https://abevoelker.github.io/how-long-since-google-said-a-google-drive-linux-client-is-coming/ | <a href="https://web.archive.org/web/*/https://abevoelker.github.io/how-long-since-google-said-a-google-drive-linux-client-is-coming/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">
        
        <p>
          have elapsed since <a href="https://productforums.google.com/forum/#!category-topic/drive/report-a-problem/KeC7Ax76dAA">Google said to "hang tight" about Linux support for Google Drive</a>.
        </p>
        <p>
          <strong><a href="https://tools.google.com/dlpage/drive">We're still waiting</a></strong>.
        </p>
        <p><a href="https://productforums.google.com/forum/#!category-topic/drive/report-a-problem/KeC7Ax76dAA">
          <img src="https://abevoelker.github.io/how-long-since-google-said-a-google-drive-linux-client-is-coming/img/waiting.gif">
        </a></p><hr>
        <p>
          Made with frustration by <a href="https://twitter.com/abevoelker">@abevoelker</a>
        </p>
      </div></div>]]>
            </description>
            <link>https://abevoelker.github.io/how-long-since-google-said-a-google-drive-linux-client-is-coming/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24183399</guid>
            <pubDate>Mon, 17 Aug 2020 02:47:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Factorio and Software Engineering]]>
            </title>
            <description>
<![CDATA[
Score 312 | Comments 128 (<a href="https://news.ycombinator.com/item?id=24181783">thread link</a>) | @nindalf
<br/>
August 16, 2020 | https://blog.nindalf.com/posts/factorio-and-software-engineering/ | <a href="https://web.archive.org/web/*/https://blog.nindalf.com/posts/factorio-and-software-engineering/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section id="wrapper">
            <article>
                <header>
                    
                    <h2>
                    Aug 16, 2020 00:15
                    · 1364 words
                    · 7 minute read
                      <span>
                      
                      
                          
                              <a href="https://blog.nindalf.com/tags/tech">tech</a>
                          
                      
                      
                      </span>
                    </h2>
                </header>
                
                <section id="post-body">
                    <p>I’ve been a software engineer a while now and I can say this with confidence - it is fun. It’s great and I wouldn’t trade it for anything else. It’s so much fun that some folks try to capture the most enjoyable elements and put them into games.</p>

<p>I’ve played two such games. The first is <strong><a href="https://store.steampowered.com/app/504210/SHENZHEN_IO/">Shenzhen.io</a></strong>. This one looks similar to what an engineer working on embedded devices would see. You solve puzzles by writing assembly code on low power devices. What makes this game great is that they remove the annoying parts of writing and shipping code.</p>

<ul>
<li>The requirements are clear, rarely true on the job.</li>
<li>The edit-debug-compile loop is lightning quick. That combined with a great test suite means you can try several potential solutions in a minute.</li>
<li>The platform your code depends on (the game itself) doesn’t have bugs. You don’t need to fix your dependencies before you start on your own code.</li>
</ul>

<p>Should a software engineer play Shenzhen.io? The gameplay isn’t for everyone. For some people it feels too much “like work”. At the end of the day you want to relax, not work at tasks that feel similar to what you did for 8 hours. Despite that, I think it’s worthwhile just to see how much more fun a task becomes when the requirements are clear and developer tools are fast. Everyone knows that investing in our direction and our tools will help, but having fun playing this game reinforces that feeling.</p>

<!-- There's a great article about Shenzhen.io that I couldn't quite work in - https://probablydance.com/2016/11/07/lessons-learned-from-shenzhen-io/ -->

<p>The second game is <strong><a href="https://factorio.com/">Factorio</a></strong> which released last Friday, though it has been available as an early access preview for about 4 years now. Those who’ve played it are probably scratching their heads right now - this is a game about building a factory, not coding. You work with conveyor belts, metals, oil products to craft products necessary to make a spacecraft.</p>

<iframe width="560" height="315" src="https://www.youtube.com/embed/BqaAjgpsoW8" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>

<p>And yet, this game reminds me of software engineering more than any other. Let me explain why.</p>

<ul>
<li><strong>Technical debt</strong>. Do we hack it for now or do we implement it right? The answer as always - it depends. Hacking it gets us closer to our goals right now but we have to pay off the debt eventually. Novice players (like me!) start out connecting various parts of our base by conveyor belts till our base resembles spaghetti, similar to poorly maintained codebases. Eventually we learn techniques to tame this complexity so our base/codebase becomes easier to reason about.</li>
<li><strong>Don’t Repeat Yourself (DRY)</strong>. One of those techniques is reducing duplication. If you have a component that’s needed in multiple places, do you make it once and use it everywhere or do you copy paste in each place it’s needed? The answer is “it depends”. As an engineer, sometimes you use a library while other times you copy paste. It depends on the complexity of the component - a couple of functions can be copy pasted while something complex probably shouldn’t. So it is in Factorio, a certain component (electronic circuits) was being produced in 4-5 places. I eventually replaced them all with one centralised production array to simplify the factory.</li>
<li><strong>Scaling</strong>. A repeated theme in this game is building a production array and later finding we need 3-5x the throughput. The first few times this happens, it requires redoing from scratch. After we wise up, we start design our arrays with space for scaling up. So it is with software - our systems need to scale to many more users, sometimes without much warning. We design our systems keeping that in mind.</li>
<li><strong>Rebuilding</strong>. When we’re rebuilding a component in a single player game or a personal software project we don’t usually care if the component or the whole system stops working briefly. I was playing multiplayer with friends though, so I tried to make sure components I was working on didn’t break anything else. I created a new oil refinery system, shifted existing customers to the new one before decommissioning the old one. Zero downtime.</li>
<li><strong>Debugging</strong> to find root causes. Our factory is far from perfect, so something is always breaking as we add stuff to it. Finding the root causes of these issues is tricky, especially when fixing those leads to other problems, like playing whack-a-mole. An example from yesterday - We don’t have enough electricity, so we add more boilers, but now the water pipes need fixing. Then the water is fine, but we don’t have enough coal. That mirrors real life</li>
<li><strong>Teamwork</strong>. Most things are possible solo given enough time. But it’s quicker and more fun working with a team you like. We were able to move fast by splitting responsibilities among the team. We have one oil guy (me), one trains guy, one secretary of defense, among other roles. The others don’t care about the internals of the refinery system, just the interface - they use the outputs and let me know if it’s broken. It’s the same on large software projects - everyone can’t learn the intricacies of the whole system. Instead everyone learns the APIs of all components while a few are responsible for the implementation.</li>
<li><strong>Researching</strong>. We spend most of our time exploiting our existing knowledge to keep us in our local maxima of output. However, a smart player dedicates some time to learning new techniques. In our game, coal power wasn’t working out for us and I had dismissed nuclear power as an option because we didn’t have enough uranium ore. I looked into it again when we were desperately short of power and producing too much pollution. Turns out even a little ore is enough to power the base for a 100 hours if we do it right. It’s the same with software - our existing stack probably works well, but it’s smart to see what’s out there and possibly learn from others. New team mates can help here too - everything is new to them so they’re spending more time than you on learning. They can come across stuff that we didn’t know about and use that knowledge to find a higher maxima. A fresh pair of eyes is always good.</li>
<li><strong>Automation</strong>. You can do most things manually, it just takes time. But if you’re doing something repeatedly, it should be automated. The game gently eases you towards this idea by requiring a few items be automated. It gets better later in the game you unlock construction robots. You can tell them the layout of the production array you’ve designed, give them the materials and they will construct it for you. This reminded me of AWS CloudFormation and similar tools - although it’s possible to set up servers by hand, it’s quicker and less error prone to specify the end state and let a tool do it for us. But if you’ve developed software, you know that automation isn’t just a means to an end - it’s an end in and of itself. We do it because it makes us happy, even if we do too much of it and <a href="https://xkcd.com/1319/">forget what we were doing in the first place</a>.</li>
<li><strong>Putting out fires</strong>. Sometimes it’s hard to implement new features because we’re being pulled away to deal with alerts - all too common on software engineering teams. The typical solution is to have one team member deal with alerts while the rest focus on adding features. That’s we did in the game too.</li>
</ul>

<p>But more than any one thing, the game is about managing complexity. Designing a specification and implementing systems that fulfill that specification. Maintaining and growing that system over time.</p>

<p>IMO, playing Factorio will not make you a better software engineer. But if you’re a software engineer, you’ll likely find the game fun. And conversely, if you’re good at the game you should give software engineering a shot.</p>

<p>You can get Factorio at on the <a href="https://factorio.com/">official website</a> or <a href="https://store.steampowered.com/app/427520/Factorio/">Steam</a>. There’s also a <a href="https://factorio.com/download">free demo</a>, in case you’d like to try before you buy. (Just one thing - don’t wait for a sale. This game has never gone on sale and possibly never will.)</p>

<hr>

<p>Thanks to Minesh Patel for reading drafts of this and suggesting improvements.</p>

<p>Check out the comments on <a href="https://news.ycombinator.com/item?id=24181783">Hacker News</a> and <a href="https://blog.nindalf.com/posts/factorio-and-software-engineering/">reddit</a>.</p>

                </section>
            </article>

            

            

            

            

        </section></div>]]>
            </description>
            <link>https://blog.nindalf.com/posts/factorio-and-software-engineering/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24181783</guid>
            <pubDate>Sun, 16 Aug 2020 22:08:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Pure Skill Minesweeper]]>
            </title>
            <description>
<![CDATA[
Score 227 | Comments 74 (<a href="https://news.ycombinator.com/item?id=24181772">thread link</a>) | @ColinWright
<br/>
August 16, 2020 | https://github.andrewt.net/mines/ | <a href="https://web.archive.org/web/*/https://github.andrewt.net/mines/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
	
	<p>
		If you're around my age, you'll remember Windows Minesweeper. It was one of several games included with Windows back in the day to try to train users in the use of the then-newfangled â€˜mouseâ€™. It doesnâ€™t come with Windows any more. You can get Minesweeper for Windows 10, but the developers haveâ€¦ made some choices.
	</p>
	<p>
		If you havenâ€™t played it, Minesweeper is a grid of squares, some of which have mines underneath, and your job is to click on all the others. If you click on a mine, you lose. You can also flag squares with the right mouse button to record that you think they are a mine. Your only clue as to where the mines are is that when you click on a square that isnâ€™t a mine, it tells you how many of the eight adjacent squares are mines. If that number is zero, the game automatically clicks on all the adjacent squares for you so you can get a little patch to start from. Hopefully that will include a 1 in a tight corner so thereâ€™s only one place its mine can go, and that will complete a nearby 1 so you can get some more numbers to work from, eventually leading you to complete the game.
	</p>
	<p>
		If youâ€™re not so lucky, you might not get a solvable board. A common situation is that you get down to the last two spaces and you know one of them is a mine but thereâ€™s no wat to predict which one. You have to guess. Heads you win, tails you just wasted 10 minutes carefully clearing the whole board only to be scuppered by a forced guess.
	</p>
	<p>
		<a href="https://www.chiark.greenend.org.uk/~sgtatham/puzzles/js/mines.html">Thereâ€™s a version of Minesweeper that guarantees you never have to guess</a>, which is very nice. It neatly solves the problem of unwinnable games, and while I find that always knowing you can make a deduction can be too big a clue, in regular Minesweeper you could even lose straight off the bat â€” you have to guess the first move and maybe itâ€™ll be a mine. In this case, Windows Minesweeper quietly chooses a different arrangement of mines and pretends like you got lucky after all â€” but it doesnâ€™t do that if youâ€™re stuck at the <em>end</em>.
	</p>
	<p>
		So what if we went further? Below is a version of Minesweeper where you will <em>never</em> be penalised when forced to guess. Any time there simply isnâ€™t enough information to deduce a safe move, weâ€™ll pull Windowsâ€™s trick and quietly rearrange the mines so you donâ€™t get penalised.
	</p>
	<p>
		But since that would on its own make the game too easy, the flip side of this coin is that if you <em>can</em> in theory deduce a safe move but guess anyway, the code will quietly rearrange the mines so that your unnecessary risk backfires and you lose.
	</p>
	<p><label>Width </label>
		<label>Height </label>
		<label>Mines </label>
		
	</p>
	
	<p>
		This game is also rigged to give you a zero on your first click rather than simply a non-mine space. To be honest this is mostly to avoid situations that are computationally difficult â€” this is not what I would call carefully optimised code. If I wanted to expand this I would (eg) make it precalculate things while youâ€™re staring at the screen instead of waiting for you to choose a square and then trying to work out what to do about it.
	</p>
	<p>
		More importantly, I would like to make the game recognise when thereâ€™s a forced guess _coming_ â€” currently if thereâ€™s a 50/50 chance in one corner of the grid that youâ€™re clearly going to have to take eventually, you have to wait until thatâ€™s <em>all</em> there is. If you take the chance when there was a safe space available elsewhere, youâ€™ll always lose.
	</p>
	<p>
		If I was feeling especially mean, I could insist that the player choose the square with the best odds of being safe, rather than simply judging whether or not each square is theoretically knowable. But I think that would be taking things too far.
	</p>
	

</div>]]>
            </description>
            <link>https://github.andrewt.net/mines/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24181772</guid>
            <pubDate>Sun, 16 Aug 2020 22:07:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I tried to use WordPress with GitHub Pages]]>
            </title>
            <description>
<![CDATA[
Score 67 | Comments 103 (<a href="https://news.ycombinator.com/item?id=24181153">thread link</a>) | @mdu96
<br/>
August 16, 2020 | https://www.melissadu.com/i-tried-to-use-wordpress-with-github-pages-and-it-was-a-nightmare/ | <a href="https://web.archive.org/web/*/https://www.melissadu.com/i-tried-to-use-wordpress-with-github-pages-and-it-was-a-nightmare/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><!-- .entry-header --><div><p>Recently I migrated this website over to WordPress.org. I tried to set it up so I could use my WordPress site with Github Pages. This post details the tribulations I faced while doing so. Here are the different sections; feel free to skip around however you like:&nbsp;</p><ol><li><a href="#backstory">The backstory: my previous setup and why I switched</a></li><li><a href="#requirements">Requirements for a new solution</a></li><li><a href="#mistakes">Two big initial mistakes</a></li><li><a href="#warning">A warning (because hindsight is 20/20)</a></li><li><a href="#run-locally">The treacherous journey to run WordPress locally</a></li><li><a href="#annoying-issues">More annoying issues I faced</a></li><li><a href="#is-it-working">Finally, it’s working?</a></li><li><a href="#conclusion">The Conclusion</a></li><li><a href="#postscript">Postscript: I’m never satisfied and here are a few more things about WordPress that I’m annoyed with</a></li></ol><h2 id="backstory"><strong>The backstory: my previous setup and why I switched</strong> to WordPress</h2><p>Prior to WordPress, I had a nice set up with <a href="https://jekyllrb.com/">Jekyll</a> (static site generator) and <a href="https://pages.github.com/">Github/Github Pages</a> (hosting &amp; serving). I liked this old setup because it was simple and free. I also liked Jekyll’s plain, minimal look. Jekyll’s visual style is very barebones and that’s exactly what I wanted.</p><p>My old workflow for editing and publishing posts was simple. I’d open a text editor, write a post in Markdown, and build and run my website locally to test the changes. Next, I’d push the new post to Github, where I’d re-deploy my website with the changes.</p><p>I first started to get annoyed with this setup when I had to re-remind myself how Jekyll glued together and rendered my site each time I wanted to publish a post. I got even more annoyed when I wanted to make changes to the layout. For example, I tried and failed multiple times to add a <code>&lt;meta&gt;</code> tag to the head of my <code>index.html</code> file. This theoretically should have been a very simple change.&nbsp;</p><p>If this happened once or twice, I’d be fine with it. The bigger problem is that the purpose of my website is to encourage me to write more. I started to procrastinate writing because there was always some small thing I wanted to fix with Jekyll first. Then, when I made time to tinker around with Jekyll, I was annoyed that I spent more time doing that than actually writing.</p><h2 id="requirements"><strong>Requirements for a new solution</strong></h2><p>So, I decided to make it was time to change my setup. My new setup had to fulfill just two requirements:</p><ol><li><strong>Easy content management. </strong>I really like the idea of just writing something, editing it, and then hitting a button to publish it once it’s ready. I didn’t like diving into Ruby files just to fix configuration issues, deploy issues, UI issues, etc. (what was happening with Jekyll).&nbsp;</li><li><strong>Be a writing first experience. </strong>I’ve never quite liked writing in text editors. Something about it just doesn’t <em>feel</em> right, though I can’t put my finger on exactly what.&nbsp;</li></ol><p>I decided to go with WordPress because it seemed like it fulfilled both of those requirements really well. Also <a href="https://wordpress.org/">WordPress.org</a> is free, unlike Webflow and Ghost, two alternatives I considered that are both quite pricey ($20/month for Webflow and $29/month for Ghost) and loaded with a bunch of features I don’t need yet.</p><h2 id="mistakes"><strong>Two big initial mistakes</strong></h2><p>As mentioned above, previously I used Github/Github Pages to host and serve my website. Github was free and worked great, so I wanted to rig up my WordPress setup to also use Github and Github Pages.&nbsp;</p><p>The only requirement to use Github Pages is that your site has to be static. Some light Googling showed me that there were a few plugins that converted WordPress site files to static pages. There were even <a href="https://www.hywel.me/static/site/wordpress/2016/07/17/fast-free-static-website-with-wordpress-and-github-pages.html">a few tutorials</a> describing how to do this, so I was confident this would be possible. That was my first big mistake.</p><p>Next, I began figuring out how to get WordPress to run locally. That was my second big mistake. My logic here was simple. Previously with Jekyll, I’d run my website locally, add my changes, and then push the new version of my website to Github to redeploy it. Thus, if I wanted to use WordPress with Github and Github Pages, then I should run my WordPress site locally, add my changes, and then push the new version of the site to Github.&nbsp;</p><p>While this logic wasn’t bad, I really should have tested the core assumption that it relied on first (the fact that the WordPress site <em>could</em> be converted into a static website). Or I should have done a bit more research than just some “light Googling” before venturing into a solution and stubbornly refusing to give up.&nbsp;</p><h2 id="warning"><strong>A warning (because hindsight is 20/20)</strong></h2><p>Here’s what I know now: running WordPress locally is a nightmare. Successfully figuring it out was way harder than it should have been. If you’re trying to do this yourself, don’t. You most likely don’t need to, and there’s probably another solution you can use to get to what you want.&nbsp;</p><p>(I should also caveat that I know almost nothing about Apache, MySQL, FTP, and PHP. If you’re familiar with them, then you might not have the same issues. However, I really don’t think I should have needed to learn about all of those technologies just to set up WordPress locally.)</p><h2 id="run-locally"><strong>The treacherous journey to run WordPress locally</strong></h2><p>First, I downloaded WordPress.org and installed it locally. The <a href="https://wordpress.org/support/article/installing-wordpress-on-your-own-computer/">official WordPress installation page</a> implied that I also needed some combination of Apache, MySQL, and PHP. A few of the links on that page were broken, a red flag that I promptly ignored.&nbsp;</p><p>I read a few other tutorials and subsequently downloaded and installed <a href="https://sourceforge.net/projects/xampp/files/">XAMPP</a>, making sure to include Apache, MySQL, PHP, and phpMyAdmin in the installation. I opened up XAMPP and pressed the “Start Application” button. That took me to an error page.</p><p>I clicked through some XAMPP tabs and pressed a few more buttons that started Apache, MySQL, and ProFTD. Now pressing “Start Application” took me to an XAMPP page. This seemed promising, but I still got an error page when trying to access my WordPress site which should have been running locally.</p><p>I bopped around a bit more and figured out that I had to enable local forwarding in XAMPP on an available port. I roll my eyes and question why XAMPP is so difficult to use.</p><p>Now that I could <em>see</em> my WordPress site locally, I still couldn’t do anything (e.g. create post). I learned that I needed to create a database locally via phpMyAdmin. Again, this is something that should have been easy, but the interface SUCKED. I had such difficulty performing such a simple action. I mean…just look at it:&nbsp;</p><figure><img width="1024" height="544" src="https://www.melissadu.com/wp-content/uploads/2020/08/Screen-Shot-2020-08-15-at-10.01.03-PM-1024x544.png" alt="phpMyAdmin home screen" srcset="https://www.melissadu.com/wp-content/uploads/2020/08/Screen-Shot-2020-08-15-at-10.01.03-PM-1024x544.png 1024w, https://www.melissadu.com/wp-content/uploads/2020/08/Screen-Shot-2020-08-15-at-10.01.03-PM-300x159.png 300w, https://www.melissadu.com/wp-content/uploads/2020/08/Screen-Shot-2020-08-15-at-10.01.03-PM-768x408.png 768w, https://www.melissadu.com/wp-content/uploads/2020/08/Screen-Shot-2020-08-15-at-10.01.03-PM-1536x817.png 1536w, https://www.melissadu.com/wp-content/uploads/2020/08/Screen-Shot-2020-08-15-at-10.01.03-PM-2048x1089.png 2048w, https://www.melissadu.com/wp-content/uploads/2020/08/Screen-Shot-2020-08-15-at-10.01.03-PM-600x319.png 600w" sizes="(max-width: 1024px) 100vw, 1024px" data-old-src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://www.melissadu.com/wp-content/uploads/2020/08/Screen-Shot-2020-08-15-at-10.01.03-PM-1024x544.png" data-srcset="https://www.melissadu.com/wp-content/uploads/2020/08/Screen-Shot-2020-08-15-at-10.01.03-PM-1024x544.png 1024w, https://www.melissadu.com/wp-content/uploads/2020/08/Screen-Shot-2020-08-15-at-10.01.03-PM-300x159.png 300w, https://www.melissadu.com/wp-content/uploads/2020/08/Screen-Shot-2020-08-15-at-10.01.03-PM-768x408.png 768w, https://www.melissadu.com/wp-content/uploads/2020/08/Screen-Shot-2020-08-15-at-10.01.03-PM-1536x817.png 1536w, https://www.melissadu.com/wp-content/uploads/2020/08/Screen-Shot-2020-08-15-at-10.01.03-PM-2048x1089.png 2048w, https://www.melissadu.com/wp-content/uploads/2020/08/Screen-Shot-2020-08-15-at-10.01.03-PM-600x319.png 600w"><figcaption><em>phpMyAdmin home screen</em></figcaption></figure><figure><img width="1022" height="486" src="https://www.melissadu.com/wp-content/uploads/2020/08/Screen-Shot-2020-08-15-at-10.02.19-PM.png" alt="bad database creation UI" srcset="https://www.melissadu.com/wp-content/uploads/2020/08/Screen-Shot-2020-08-15-at-10.02.19-PM.png 1022w, https://www.melissadu.com/wp-content/uploads/2020/08/Screen-Shot-2020-08-15-at-10.02.19-PM-300x143.png 300w, https://www.melissadu.com/wp-content/uploads/2020/08/Screen-Shot-2020-08-15-at-10.02.19-PM-768x365.png 768w, https://www.melissadu.com/wp-content/uploads/2020/08/Screen-Shot-2020-08-15-at-10.02.19-PM-600x285.png 600w" sizes="(max-width: 1022px) 100vw, 1022px" data-old-src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" data-src="https://www.melissadu.com/wp-content/uploads/2020/08/Screen-Shot-2020-08-15-at-10.02.19-PM.png" data-srcset="https://www.melissadu.com/wp-content/uploads/2020/08/Screen-Shot-2020-08-15-at-10.02.19-PM.png 1022w, https://www.melissadu.com/wp-content/uploads/2020/08/Screen-Shot-2020-08-15-at-10.02.19-PM-300x143.png 300w, https://www.melissadu.com/wp-content/uploads/2020/08/Screen-Shot-2020-08-15-at-10.02.19-PM-768x365.png 768w, https://www.melissadu.com/wp-content/uploads/2020/08/Screen-Shot-2020-08-15-at-10.02.19-PM-600x285.png 600w"><figcaption><em>phpMyAdmin “Create Database” page</em></figcaption></figure><p>Looking at these screenshots now makes me annoyed all over again.</p><h2 id="annoying-issues"><strong>More annoying issues I faced</strong></h2><p>I then ran into some issues that took me a long time to figure out. Surprisingly, there was not a lot of advice out there on good solutions. I spent more time than I’d like to admit on WordPress support forums and arcane blogs. I’ll include the two most annoying issues here for posterity and in the event that another poor soul is also sifting through Google searching for a solution.&nbsp;</p><p><strong><em>Annoying error #1: “to perform the requested action WordPress needs to access your web server”</em></strong></p><p>To fix this, add <code>define( 'FS_METHOD', 'direct' );</code> to your <code>wp-config.php</code> file.</p><p><strong><em>Annoying error #2: fix the file and folder permissions error in WordPress / “installation failed could not create directory”</em></strong></p><p>To fix this, you need to give XAMPP write access to the local directory you have WordPress set up in. I spent awhile messing around with quite a few config files (like .htaccess) and FTP permission codes to no avail. The solution was ultimately simple: right-click on your local WordPress directory, click “Get Info”, scroll to “Sharing &amp; Permissions”, and change the permissions on your directory to “Read and Write (anyone)”.</p><h2 id="is-it-working"><strong>Finally, it’s working?</strong></h2><p>At long last, all of this is finally working and I now have WordPress running locally.&nbsp;</p><p>Anyways, the next step is to install a plugin to convert my site into a bunch of static pages. I go with <a href="https://www.simplystatic.co/">SimplyStatic</a>, the most popular and highly recommended plugin to do this.</p><p>I immediately run into quite a few errors with SimplyStatic. After progressively resolving each one, I ultimately run into one I can’t fix. I search some more and realize that it’s because SimplyStatic was only compatible with an earlier version of WordPress than the one I was running. I dig further and realize that the plugin hasn’t been updated for over two years. And there don’t seem to be <em>any</em> currently updated plugins that do this conversion. Epic FAIL.&nbsp;</p><p>I didn’t want to sink in even more time to learn how to convert the WordPress PHP files into static pages. I decided to cut my losses right there and abandon ship.&nbsp;</p><h2 id="conclusion"><strong>The Conclusion</strong></h2><p><strong><span>TL;DR? Don’t try to run WordPress locally, and don’t try to use WordPress with Github Pages to host and serve it. It won’t work.</span></strong></p><p>I ultimately ended up going with <a href="http://siteground.com/">Siteground</a> for managed hosting. Siteground’s interface is awful, but after poking around a bit I got most of it set up. I had a few minor configuration issues when enabling HTTPS and spent ~30 minutes chatting with a customer support agent, who was actually quite helpful.&nbsp;</p><h2 id="postscript"><strong>Postscript: I’m never satisfied and here are a few more things about WordPress that I’m annoyed with</strong></h2><ol><li>Unless you want your WordPress site to look bad or just like everyone else’s, you’ll probably want to customize an existing theme to your own liking. <strong>To do this, you’ll still need to hack around with code<em> </em></strong><em>(in this case, a combination of HTML, CSS and PHP)</em>. Theoretically, you could probably install a plugin to help you do this, but that’d probably slow down your site and further obscure how things actually work.&nbsp;</li><li>Getting used to WordPress itself was a bit of a curve. The main dashboard, for instance, is completely useless to me. I’ve just been ignoring all parts of the interface I don’t need, which thus far has been working pretty well.&nbsp;</li></ol><hr><p>If you liked this post, add your email address below to stay updated whenever there’s a new one.  Or you can <a href="https://www.twitter.com/melissadooo">follow me on Twitter</a>. I like talking to people there.</p></div><!-- .entry-content --></article></div>]]>
            </description>
            <link>https://www.melissadu.com/i-tried-to-use-wordpress-with-github-pages-and-it-was-a-nightmare/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24181153</guid>
            <pubDate>Sun, 16 Aug 2020 20:45:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[WebAssembly without the browser]]>
            </title>
            <description>
<![CDATA[
Score 122 | Comments 51 (<a href="https://news.ycombinator.com/item?id=24180303">thread link</a>) | @pacificat0r
<br/>
August 16, 2020 | https://alexene.dev/2020/08/17/webassembly-without-the-browser-part-1.html | <a href="https://web.archive.org/web/*/https://alexene.dev/2020/08/17/webassembly-without-the-browser-part-1.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        

<article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p>Most WebAssembly tutorials and examples you will find online focus on using it inside the browser in order to accelerate various functionality of a website or web app.<br>
However, there is an area where WebAssembly is really powerful but not talked too much about: outside the browser usage scenarios. That is what we’ll focus on in this series of posts.</p>

<h2 id="what-is-webassembly">What is WebAssembly?</h2>
<p>Web people are on a roll of giving bad names to things (web-gpu is another example).<br>
WebAssembly is neither web or assembly, but a bytecode that can be targeted from languages like C++, C#, Rust and others. This means you can write some Rust code, compile it into WebAssembly and run that code in a WebAssembly virtual machine.</p>

<p>This is powerful because you won’t have to deal with garbage collected scripted languages anymore, and essentially use Rust or C++ as your <em>scripting language</em>.  WebAssembly enables predictable and stable performance because it doesn’t require garbage collection like the usual options (LUA/JavaScript).</p>

<p>It’s a relatively new product and there are a lot of rough edges, especially for out-of-browser scenarios. One of the roughest ones in my experience has been documentation for out-of-browser scenarios and this is the reason for my blog posts, to document my findings and hopefully help some people that may be interested in this subject.</p>

<h2 id="why-would-we-want-to-run-webassembly-outside-of-a-browser">Why would we want to run WebAssembly outside of a browser?</h2>
<p>For out of browser scenarios, one of its main advantage is that it provides system level access without compromising on security. This is done through WASI, the Web Assembly System Interface. <a href="https://wasi.dev/">WASI</a> is a collection of C-like functions that provide access to functionality such as <code>fd_read</code>, <code>rand</code>, <code>fd_write</code>, threads (WIP), in a safe way.</p>

<p>Here are a few scenarios where you would be able to use web-assembly outside of a browser:</p>
<ul>
  <li>A scripting language for a video game.</li>
  <li>To run some code with minimal overhead as Fastly/Cloudflare are doing with their compute-at-edge scenarios.</li>
  <li>To run some easy to update code on IoT devices safely and with minimal runtime overhead.</li>
  <li>Extreamly fast programs in environments where you can’t JIT for <em>reasons</em>.</li>
</ul>

<h2 id="prerequisites">Prerequisites</h2>
<p>For the best experience in this adventure, I suggest using <a href="https://code.visualstudio.com/">Visual Studio Code</a> as your IDE and install the following extensions:</p>
<ul>
  <li><code>rust-analyzer</code>: for autocomplete and other great features.</li>
  <li><code>Code-LLDB</code>: For debugging with LLDB (even works on Windows)</li>
  <li><code>WebAssembly by the WebAssembly foundation</code>: Allows you to disassemble and inspect <code>.wasm</code> binaries.</li>
</ul>


<p>First you need a Virtual Machine (VM) that can run your WebAssembly program. This VM needs to be embeddable, so you can add it in your game engine, or what we will call from now on <strong>host program</strong>. There are a few to pick from: <a href="https://github.com/wasm3/wasm3">WASM3</a>, <a href="https://github.com/bytecodealliance/wasmtime">Wasmtime</a>, <a href="https://github.com/bytecodealliance/wasm-micro-runtime">WAMR</a>, and many others. They have various characteristics, such as supporting JIT, using as little memory as possible and so on and you have to choose one one that fits your target platform and scenario.</p>

<p>It doesn’t matter too much what VM you’re choosing besides runtime properties, with the exception of debugging. The only VM that allows for a seamless debugging experience that I’ve found is Wasmtime (this is another one of those rough edges). So even if you don’t plan on deploying that anywhere due to other constraints, I suggest using it as the <strong>debug VM</strong>. Whenever you’d want to debug some WASM code you can launch it with Wasmtime.</p>



<p>First, we need to create a new <code>lib</code> project:</p>
<div><div><pre><code>cargo new <span>--lib</span> wasm_example
</code></pre></div></div>

<p>In <code>Cargo.toml</code> add the following:</p>

<div><div><pre><code>[lib]
crate-type = ["cdylib"]
</code></pre></div></div>

<p>Now we can edit <code>lib.rs</code> and export the following <code>C</code> FFI compatible function from it:</p>

<div><div><pre><code><span>#[no_mangle]</span>
<span>extern</span> <span>"C"</span> <span>fn</span> <span>sum</span><span>(</span><span>a</span><span>:</span> <span>i32</span><span>,</span> <span>b</span><span>:</span> <span>i32</span><span>)</span> <span>-&gt;</span> <span>i32</span> <span>{</span>
    <span>let</span> <span>s</span> <span>=</span> <span>a</span> <span>+</span> <span>b</span><span>;</span>
    <span>println!</span><span>(</span><span>"From WASM: Sum is: {:?}"</span><span>,</span> <span>s</span><span>);</span>
    <span>s</span>
<span>}</span>
</code></pre></div></div>

<p>This a function that takes two numbers, adds them, then prints the result before returning their sum.<br>
WebAssembly doesn’t define a default function that’s executed after a module is loaded, so in the host program you need to get a function by it’s signature, and run it (quite similar to how <code>dlopen</code>/<code>dlsym</code> works).</p>

<p>We expose this <code>sum</code> function (and any other functions we want to call from the host VM) as a function that’s callable from <code>C</code>, using <code>[#no_mangle]</code> and <code>pub extern "C"</code>. If you’re coming here from some WASM for the browser tutorials, you may notice we don’t need to use <code>wasm-bindgen</code> at all.</p>

<h2 id="how-do-we-compile-it">How do we compile it?</h2>
<p>Rust supports two targets for WebAssembly: <code>wasm32-unknown-unknown</code> and <code>wasm32-wasi</code>. The first one is bare-bones WebAssembly. Think of it like the <code>[#no-std]</code> of WebAssembly. It’s the kind you’d use for the browser that doesn’t assume any system functions are available.</p>

<p>At the other end, <code>wasm32-wasi</code> assumes that the VM exposes the <code>WASI</code> functionality, allowing a different implementation of the standard library to be used (the implementation that depends on the WASI functions to be available).</p>

<p>You can take a look at the available implementations for the Rust’s stdlib here: <a href="https://github.com/rust-lang/rust/tree/master/library/std/src/sys">https://github.com/rust-lang/rust/tree/master/library/std/src/sys</a>  <br>
This is the implementation that assumes WASI functions are available to the rust program when running in a WebAssembly VM: <a href="https://github.com/rust-lang/rust/tree/master/library/std/src/sys/wasi">https://github.com/rust-lang/rust/tree/master/library/std/src/sys/wasi</a>.</p>

<p>To comile for wasm32-wasi run:</p>
<div><div><pre><code><span># Run this just once</span>
rustup target add wasm32-wasi

<span># Compile for the wasm32-wasi target.</span>
cargo build <span>--target</span> wasm32-wasi
</code></pre></div></div>

<h2 id="but-how-does-println-work">But how does <code>println!()</code> work?</h2>
<p>You may have noticed that we’re calling <code>println!()</code> and expecting the program to work and print to the console, but how does a WebAssembly program knows how to do that?</p>

<p>This is why we’re using <code>wasm32-wasi</code>. This target selects for the rust stdlib the version that assumes some functionality to be there (the <code>WASI</code> functions). Printing to the console means just writing to a special file descriptor. Most VMs allow that by default so we don’t need to do any special settings, besides compiling the correct <code>wasm32-wasi</code> target.</p>

<p>If you have installed the required extensions for vscode, you can now right click on <code>target/wasm32-wasi/debug/wasm_example.wasm</code> and select <code>Show WebAssembly</code> and you should have a new file open in vscode that looks like this:</p>

<div><div><pre><code><span>(</span><span>module</span><span>
  </span><span>....</span><span>
  </span><span>(</span><span>type</span><span> </span><span>$</span><span>t15</span><span> </span><span>(</span><span>func</span><span> </span><span>(</span><span>param</span><span> </span><span>i64</span><span> </span><span>i32</span><span> </span><span>i32</span><span>)</span><span> </span><span>(</span><span>result</span><span> </span><span>i32</span><span>)))</span><span>
  </span><span>(</span><span>import</span><span> </span><span>"wasi_snapshot_preview1"</span><span> </span><span>"fd_write"</span><span> </span><span>(</span><span>func</span><span> </span><span>$</span><span>_</span><span>ZN4wasi13lib_generated22wasi_snapshot_preview18fd_write17h6ec13d25aa9fb6acE</span><span> </span><span>(</span><span>type</span><span> </span><span>$</span><span>t8</span><span>)))</span><span>
  </span><span>(</span><span>import</span><span> </span><span>"wasi_snapshot_preview1"</span><span> </span><span>"proc_exit"</span><span> </span><span>(</span><span>func</span><span> </span><span>$</span><span>__</span><span>wasi_proc_exit</span><span> </span><span>(</span><span>type</span><span> </span><span>$</span><span>t0</span><span>)))</span><span>
  </span><span>(</span><span>import</span><span> </span><span>"wasi_snapshot_preview1"</span><span> </span><span>"environ_sizes_get"</span><span> </span><span>(</span><span>func</span><span> </span><span>$</span><span>__</span><span>wasi_environ_sizes_get</span><span> </span><span>(</span><span>type</span><span> </span><span>$</span><span>t2</span><span>)))</span><span>
  </span><span>(</span><span>import</span><span> </span><span>"wasi_snapshot_preview1"</span><span> </span><span>"environ_get"</span><span> </span><span>(</span><span>func</span><span> </span><span>$</span><span>__</span><span>wasi_environ_get</span><span> </span><span>(</span><span>type</span><span> </span><span>$</span><span>t2</span><span>)))</span><span>
  </span><span>(</span><span>func</span><span> </span><span>$</span><span>_</span><span>ZN4core3fmt9Arguments6new_v117hb11611244be67330E</span><span> </span><span>(</span><span>type</span><span> </span><span>$</span><span>t9</span><span>)</span><span> </span><span>(</span><span>param</span><span> </span><span>$</span><span>p0</span><span> </span><span>i32</span><span>)</span><span> </span><span>(</span><span>param</span><span> </span><span>$</span><span>p1</span><span> </span><span>i32</span><span>)</span><span> </span><span>(</span><span>param</span><span> </span><span>$</span><span>p2</span><span> </span><span>i32</span><span>)</span><span> </span><span>(</span><span>param</span><span> </span><span>$</span><span>p3</span><span> </span><span>i32</span><span>)</span><span> </span><span>(</span><span>param</span><span> </span><span>$</span><span>p4</span><span> </span><span>i32</span><span>)</span><span>
    </span><span>(</span><span>local</span><span> </span><span>$</span><span>l5</span><span> </span><span>i32</span><span>)</span><span> </span><span>(</span><span>local</span><span> </span><span>$</span><span>l6</span><span> </span><span>i32</span><span>)</span><span> </span><span>(</span><span>local</span><span> </span><span>$</span><span>l7</span><span> </span><span>i32</span><span>)</span><span> </span><span>(</span><span>local</span><span> </span><span>$</span><span>l8</span><span> </span><span>i32</span><span>)</span><span> </span><span>(</span><span>local</span><span> </span><span>$</span><span>l9</span><span> </span><span>i32</span><span>)</span><span> </span><span>(</span><span>local</span><span> </span><span>$</span><span>l10</span><span> </span><span>i32</span><span>)</span><span>
    </span><span>global.get</span><span> </span><span>$</span><span>g0</span><span>
    </span><span>local.set</span><span> </span><span>$</span><span>l5</span><span>
  </span><span>...</span><span>
</span></code></pre></div></div>

<p>This is a <code>wat</code> file. <code>wat</code> stands for WebAssembly text format. It’s kind of like looking at x64/ARM ASM instructions when disassembling a binary, just uglier and harder to understand. I have read that this was because the creators of WebAssembly couldn’t decide on a text format so they just left it in this ugly s-expression form.</p>

<p>The import statements here tell us that the WASM program needs the following functions <code>proc_exit</code>, <code>fd_write</code>, <code>environ_get</code>, <code>environ_sizes_get</code> to exist in the <code>wasi_snapshot_preview1</code> namespace.<br>
All imported or exported functions from a WebAssembly module require a namespace. <code>wasi_snapshot_preview1</code> is the WASI namespace so you can think of it as a reserved namespace for these functions. <code>println!</code> needs <code>wasi_snapshot_preview1::fd_write</code> to write to stdout.</p>

<h2 id="the-host-program">The host program</h2>
<p>You can pick any VM that has WASI available. I will use Wasmtime because later on I want to show you how to debug WebAssembly and this VM is the only one where debugging works at the moment.</p>

<p>The program loads the wasm binary file from the path: <code>examples/wasm_example.wasm</code>.<br>
This is the file you have previously compiled that you can find in <code>wasm_example/target/wasm32-wasi/debug/wasm_example.wasm</code>. <strong>Make sure you move it in the right place before running the host program.</strong></p>

<p>Here is the full listing of the host VM rust program that initializes the Wasmtime VM, loads the module, links against WASI and loads and executes the exported <code>sum</code> function from the WASM module:</p>

<div><div><pre><code><span>use</span> <span>std</span><span>::</span><span>error</span><span>::</span><span>Error</span><span>;</span>
<span>use</span> <span>wasmtime</span><span>::</span><span>*</span><span>;</span>
<span>use</span> <span>wasmtime_wasi</span><span>::{</span><span>Wasi</span><span>,</span> <span>WasiCtx</span><span>};</span>

<span>fn</span> <span>main</span><span>()</span> <span>-&gt;</span> <span>Result</span><span>&lt;</span><span>(),</span> <span>Box</span><span>&lt;</span><span>dyn</span> <span>Error</span><span>&gt;&gt;</span> <span>{</span>
    <span>// A `Store` is a sort of "global object" in a sense, but for now it suffices</span>
    <span>// to say that it's generally passed to most constructors.</span>
    <span>// let store = Store::default();</span>
    <span>let</span> <span>engine</span> <span>=</span> <span>Engine</span><span>::</span><span>new</span><span>(</span><span>Config</span><span>::</span><span>new</span><span>()</span><span>.debug_info</span><span>(</span><span>true</span><span>));</span>
    <span>let</span> <span>store</span> <span>=</span> <span>Store</span><span>::</span><span>new</span><span>(</span><span>&amp;</span><span>engine</span><span>);</span>

    <span>// We start off by creating a `Module` which represents a compiled form</span>
    <span>// of our input wasm module. In this case it'll be JIT-compiled after</span>
    <span>// we parse the text format.</span>
    <span>let</span> <span>module</span> <span>=</span> <span>Module</span><span>::</span><span>from_file</span><span>(</span><span>&amp;</span><span>engine</span><span>,</span> <span>"examples/wasm_example.wasm"</span><span>)</span><span>?</span><span>;</span>

    <span>// Link the WASI module to our VM. Wasmtime allows us to decide if WASI is present.</span>
    <span>// So we need to load it here, as our module rquires certain functions to be present from the</span>
    <span>// wasi_snapshot_preview1 namespace as seen above.</span>
    <span>// This makes println!() from our WASM program to work. (it uses fd_write).</span>
    <span>let</span> <span>wasi</span> <span>=</span> <span>Wasi</span><span>::</span><span>new</span><span>(</span><span>&amp;</span><span>store</span><span>,</span> <span>WasiCtx</span><span>::</span><span>new</span><span>(</span><span>std</span><span>::</span><span>env</span><span>::</span><span>args</span><span>())</span><span>?</span><span>);</span>
    <span>let</span> <span>mut</span> <span>imports</span> <span>=</span> <span>Vec</span><span>::</span><span>new</span><span>();</span>
    <span>for</span> <span>import</span> <span>in</span> <span>module</span><span>.imports</span><span>()</span> <span>{</span>
        <span>if</span> <span>import</span><span>.module</span><span>()</span> <span>==</span> <span>"wasi_snapshot_preview1"</span> <span>{</span>
            <span>if</span> <span>let</span> <span>Some</span><span>(</span><span>export</span><span>)</span> <span>=</span> <span>wasi</span><span>.get_export</span><span>(</span><span>import</span><span>.name</span><span>())</span> <span>{</span>
                <span>imports</span><span>.push</span><span>(</span><span>Extern</span><span>::</span><span>from</span><span>(</span><span>export</span><span>.clone</span><span>()));</span>
                <span>continue</span><span>;</span>
            <span>}</span>
        <span>}</span>
        <span>panic!</span><span>(</span>
            <span>"couldn't find import for `{}::{}`"</span><span>,</span>
            <span>import</span><span>.module</span><span>(),</span>
            <span>import</span><span>.name</span><span>()</span>
        <span>);</span>
    <span>}</span>
    <span>// After we have a compiled `Module` we can then instantiate it, creating</span>
    <span>// an `Instance` …</span></code></pre></div></div></div></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://alexene.dev/2020/08/17/webassembly-without-the-browser-part-1.html">https://alexene.dev/2020/08/17/webassembly-without-the-browser-part-1.html</a></em></p>]]>
            </description>
            <link>https://alexene.dev/2020/08/17/webassembly-without-the-browser-part-1.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24180303</guid>
            <pubDate>Sun, 16 Aug 2020 19:08:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Matrix Calculus for Deep Learning]]>
            </title>
            <description>
<![CDATA[
Score 45 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24180065">thread link</a>) | @tosh
<br/>
August 16, 2020 | https://explained.ai/matrix-calculus/ | <a href="https://web.archive.org/web/*/https://explained.ai/matrix-calculus/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">




<p><a href="http://parrt.cs.usfca.edu/">Terence Parr</a> and <a href="http://www.fast.ai/about/#jeremy">Jeremy Howard</a></p>



<p>(We teach in University of San Francisco's <a href="https://www.usfca.edu/arts-sciences/graduate-programs/data-science">MS in Data Science program</a> and have other nefarious projects underway. You might know Terence as the creator of the <a href="http://www.antlr.org/">ANTLR parser generator</a>. For more material, see Jeremy's <a href="http://course.fast.ai/">fast.ai courses</a> and University of San Francisco's Data Institute <a href="https://www.usfca.edu/data-institute/certificates/deep-learning-part-one">in-person version of the deep learning course</a>.)</p>

<p><a href="https://arxiv.org/abs/1802.01528" onclick="gtag('event', 'download', {
  'video_title': 'PDF version',
  'non_interaction': true
});">Printable version</a> (This HTML was generated from markup using <a href="https://github.com/parrt/bookish" onclick="gtag('event', 'bookish', {
  'video_title': 'bookish',
  'non_interaction': true
});">bookish</a>)</p>



<p><b>Abstract</b></p>
<p>This paper is an attempt to explain all the matrix calculus you need in order to understand the training of deep neural networks. We assume no math knowledge beyond what you learned in calculus 1, and provide links to help you refresh the necessary math where needed. Note that you do <b>not</b> need to understand this material before you start learning to train and use deep learning in practice; rather, this material is for those who are already familiar with the basics of neural networks, and wish to deepen their understanding of the underlying math. Don't worry if you get stuck at some point along the way---just go back and reread the previous section, and try writing down and working through some examples. And if you're still stuck, we're happy to answer your questions in the <a href="http://forums.fast.ai/c/theory">Theory category at forums.fast.ai</a>. <b>Note</b>: There is a <a href="#reference">reference section</a> at the end of the paper summarizing all the key matrix calculus rules and terminology discussed here.</p>






<h2 id="intro">Introduction </h2>


<p>Most of us last saw calculus in school, but derivatives are a critical part of machine learning, particularly deep neural networks, which are trained by optimizing a loss function. Pick up a machine learning paper or the documentation of a library such as <a href="http://pytorch.org/">PyTorch</a> and calculus comes screeching back into your life like distant relatives around the holidays.  And it's not just any old scalar calculus that pops up---you need differential <i>matrix calculus</i>, the shotgun wedding of <a href="https://en.wikipedia.org/wiki/Linear_algebra">linear algebra</a> and <a href="https://en.wikipedia.org/wiki/Multivariable_calculus">multivariate calculus</a>. </p>

<p>Well... maybe <i>need</i> isn't the right word; Jeremy's courses show how to become a world-class deep learning practitioner with only a minimal level of scalar calculus, thanks to leveraging the automatic differentiation built in to modern deep learning libraries. But if you really want to really understand what's going on under the hood of these libraries, and grok academic papers discussing the latest advances in model training techniques, you'll need to understand certain bits of the field of matrix calculus.</p>

<p>For example, the activation of a single computation unit in a neural network is typically calculated using the dot product (from linear algebra) of an edge weight vector <span>w</span> with an input vector <span>x</span> plus a scalar bias (threshold): <img src="https://explained.ai/matrix-calculus/images/eqn-EEDCFA4252D0992243A283CE0EB777A6-depth003.31.svg">. Function <img src="https://explained.ai/matrix-calculus/images/eqn-C599D931407509E0FA08F8686B205B6D-depth003.25.svg"> is called the unit's <i>affine function</i> and is followed by a <a href="https://goo.gl/7BXceK">rectified linear unit</a>, which clips negative values to zero: <img src="https://explained.ai/matrix-calculus/images/eqn-66258AA93A4746DA10D306190271DE4B-depth003.25.svg">. Such a computational unit is sometimes referred to as an “artificial neuron” and looks like:</p>

<center>
<p><img src="https://explained.ai/matrix-calculus/images/neuron.png" alt="neuron.png" width="250"></p>
</center>

<p>Neural networks consist of many of these units, organized into multiple collections of neurons called <i>layers</i>. The activation of one layer's units become the input to the next layer's units. The activation of the unit or units in the final layer is called the network output.</p>

<p><i>Training</i> this neuron means choosing weights <span>w</span> and bias <span>b</span> so that we get the desired output for all <span>N</span> inputs <span>x</span>.  To do that, we minimize a <i>loss function</i> that compares the network's final <img src="https://explained.ai/matrix-calculus/images/eqn-7971D42A6C6C6A28D6443F0645E4A036-depth003.25.svg"> with the <img src="https://explained.ai/matrix-calculus/images/eqn-E146B831A1E53B95E4C63775285D62CF-depth003.25.svg"> (desired output of <span>x</span>) for all input <span>x</span> vectors. To minimize the loss, we use some variation on gradient descent, such as plain <a href="https://en.wikipedia.org/wiki/Stochastic_gradient_descent">stochastic gradient descent</a> (SGD), SGD with momentum, or <a href="https://en.wikipedia.org/wiki/Stochastic_gradient_descent#Adam">Adam</a>.   All of those require the partial derivative (the gradient) of <img src="https://explained.ai/matrix-calculus/images/eqn-7971D42A6C6C6A28D6443F0645E4A036-depth003.25.svg"> with respect to the model parameters <span>w</span> and <span>b</span>. Our goal is to gradually tweak <span>w</span> and <span>b</span> so that the overall loss function keeps getting smaller across all <span>x</span> inputs.</p>

<p>If we're careful, we can derive the gradient by differentiating the scalar version of a common loss function (mean squared error):</p>
<p><img src="https://explained.ai/matrix-calculus/images/blkeqn-A129949CD1EF7BE2CA8BD424D34F9930.svg" alt=""></p>

<p>But this is just one neuron, and neural networks must train the weights and biases of all neurons in all layers simultaneously.  Because there are multiple inputs and (potentially) multiple network outputs, we really need general rules for the derivative of a function with respect to a vector and even rules for the derivative of a vector-valued function with respect to a vector.</p>

<p>This article walks through the derivation of some important rules for computing partial derivatives with respect to vectors, particularly those useful for training neural networks. This field is known as <i>matrix calculus</i>, and the good news is, we only need a small subset of that field, which we introduce here.  While there is a lot of online material on multivariate calculus and linear algebra, they are typically taught as two separate undergraduate courses so most material treats them in isolation.  The pages that do discuss matrix calculus often are really just lists of rules with minimal explanation or are just pieces of the story. They also tend to be quite obscure to all but a narrow audience of mathematicians, thanks to their use of dense notation and minimal discussion of foundational concepts. (See the annotated list of resources at the end.)</p>

<p>In contrast, we're going to rederive and rediscover some key matrix calculus rules in an effort to explain them. It turns out that matrix calculus is really not that hard! There aren't dozens of new rules to learn; just a couple of key concepts.  Our hope is that this short paper will get you started quickly in the world of matrix calculus as it relates to training neural networks. We're assuming you're already familiar with the basics of neural network architecture and training. If you're not, head over to <a href="http://course.fast.ai/">Jeremy's course</a> and complete part 1 of that, then we'll see you back here when you're done. (Note that, unlike many more academic approaches, we strongly suggest <i>first</i> learning to train and use neural networks in practice and <i>then</i> study the underlying math. The math will be much more understandable with the context in place; besides, it's not necessary to grok all this calculus to become an effective practitioner.)</p>

<p><i>A note on notation</i>: Jeremy's course exclusively uses code, instead of math notation, to explain concepts since unfamiliar functions in code are easy to search for and experiment with. In this paper, we do the opposite: there is a lot of math notation because one of the goals of this paper is to help you understand the notation that you'll see in deep learning papers and books. At the <a href="#notation">end of the paper</a>, you'll find a brief table of the notation used, including a word or phrase you can use to search for more details.</p>


<h2 id="sec2">Review: Scalar derivative rules</h2>


<p>Hopefully you remember some of these main scalar derivative rules. If your memory is a bit fuzzy on this, have a look at <a href="https://www.khanacademy.org/math/ap-calculus-ab/ab-derivative-rules">Khan academy vid on scalar derivative rules</a>.</p>
<center>
<table>
<thead>
	<tr>
		<th>Rule</th><th><img src="https://explained.ai/matrix-calculus/images/eqn-50BBD36E1FD2333108437A2CA378BE62-depth003.25.svg"></th><th>Scalar derivative notation with respect to <span>x</span></th><th>Example</th>
	</tr>
</thead>
<tbody>
	<tr>
		<td><b>Constant</b></td><td><span>c</span></td><td><img src="https://explained.ai/matrix-calculus/images/eqn-CFCD208495D565EF66E7DFF9F98764DA-depth000.20.svg"></td><td><img src="https://explained.ai/matrix-calculus/images/eqn-64F478FC4F8CA7284B3A00A378371DD9-depth004.58.svg"></td>
	</tr>
	<tr>
		<td><b>Multiplication by constant</b></td><td><span>cf</span></td><td><img src="https://explained.ai/matrix-calculus/images/eqn-6F4437952F8A3645EDFDBA34800939C7-depth004.58.svg"></td><td><img src="https://explained.ai/matrix-calculus/images/eqn-E6BBA7095B8356839BB31CBAA81BEB2D-depth004.58.svg"></td>
	</tr>
	<tr>
		<td><b>Power Rule</b></td><td><img src="https://explained.ai/matrix-calculus/images/eqn-B41952E9DFED8E1ED562FDDAFECA7C70-depth000.14.svg"></td><td><img src="https://explained.ai/matrix-calculus/images/eqn-778B829130B1FD49AB222C57E43AA511-depth000.14.svg"></td><td><img src="https://explained.ai/matrix-calculus/images/eqn-0E35EE43AF43B99B9DEC113EF495C9B1-depth004.58.svg"></td>
	</tr>
	<tr>
		<td><b>Sum Rule</b></td><td><img src="https://explained.ai/matrix-calculus/images/eqn-F90CB0F11C73CF039948C790CB958167-depth002.72.svg"></td><td><img src="https://explained.ai/matrix-calculus/images/eqn-272CCFD170B42C2D5FC34B8F6B59B919-depth004.58.svg"></td><td><img src="https://explained.ai/matrix-calculus/images/eqn-30CBA4C53B1DA339D30A685E5F750181-depth004.58.svg"></td>
	</tr>
	<tr>
		<td><b>Difference Rule</b></td><td><img src="https://explained.ai/matrix-calculus/images/eqn-6BF1771953527A02849B0FD62C669A81-depth002.72.svg"></td><td><img src="https://explained.ai/matrix-calculus/images/eqn-94A32391D8AF942F5DD6DF56F3A6B9D7-depth004.58.svg"></td><td><img src="https://explained.ai/matrix-calculus/images/eqn-A5BC3AF74DAB50898B00534C3A67F8E7-depth004.58.svg"></td>
	</tr>
	<tr>
		<td><b>Product Rule</b></td><td><span>fg</span></td><td><img src="https://explained.ai/matrix-calculus/images/eqn-BEE9614EE8574DD7D3739CB7B896CF87-depth004.58.svg"></td><td><img src="https://explained.ai/matrix-calculus/images/eqn-80B75BFF0AE78CDC1377C9DA385E5733-depth004.58.svg"></td>
	</tr>
	<tr>
		<td><b>Chain Rule</b></td><td><img src="https://explained.ai/matrix-calculus/images/eqn-8BC3A7E80988236E8F017205F413461C-depth003.25.svg"></td><td><img src="https://explained.ai/matrix-calculus/images/eqn-8FF3736047AA480DA61894A92CA055ED-depth004.58.svg">,  let <img src="https://explained.ai/matrix-calculus/images/eqn-F1EA68A4A1E70E96ADA7592EF8752C30-depth003.25.svg"></td><td><img src="https://explained.ai/matrix-calculus/images/eqn-951A8B94D11F280E3A440D55B3D520D3-depth004.61.svg"></td>
	</tr>
</tbody>
</table>
</center>

<p>There are other rules for trigonometry, exponentials, etc., which you can find at <a href="https://www.khanacademy.org/math/differential-calculus">Khan Academy differential calculus course</a>.</p>

<p>When a function has a single parameter, <img src="https://explained.ai/matrix-calculus/images/eqn-50BBD36E1FD2333108437A2CA378BE62-depth003.25.svg">, you'll often see <img src="https://explained.ai/matrix-calculus/images/eqn-6BDA8AF54C40BC23ED858E9E9F5C11D2-depth002.72.svg"> and <img src="https://explained.ai/matrix-calculus/images/eqn-74CAF4D1EC90D3A36EA7C7BBFE65B516-depth003.25.svg"> used as shorthands for <img src="https://explained.ai/matrix-calculus/images/eqn-5BA9D16419154B1BDBECA39D99E8E809-depth004.58.svg">. We recommend against this notation as it does not make clear the variable we're taking the derivative with respect to. </p>

<p>You can think of <img src="https://explained.ai/matrix-calculus/images/eqn-624FEBB9A49A3FC96353C861D175C806-depth004.58.svg"> as an operator that maps a function of one parameter to another function.  That means that <img src="https://explained.ai/matrix-calculus/images/eqn-EC0CEC5F9488EC510F8D688E7003222D-depth004.58.svg"> maps <img src="https://explained.ai/matrix-calculus/images/eqn-50BBD36E1FD2333108437A2CA378BE62-depth003.25.svg"> to its derivative with respect to <span>x</span>, which is the same thing as <img src="https://explained.ai/matrix-calculus/images/eqn-07A5EA519C4CEA1A3539E3A7FC289163-depth004.58.svg">. Also, if <img src="https://explained.ai/matrix-calculus/images/eqn-FD91C508F91C2C84498680BD337C1D7A-depth003.25.svg">, then <img src="https://explained.ai/matrix-calculus/images/eqn-B1ED3CF9BA4D6F25A5A4F481C45EC658-depth004.58.svg">. Thinking of the derivative as an operator helps to simplify complicated derivatives because the operator is distributive and lets us pull out constants. For example, in the following equation, we can pull out the constant 9 and distribute the derivative operator across the elements within the parentheses.</p>
<p><img src="https://explained.ai/matrix-calculus/images/blkeqn-A1EC7F214318E08949CC8BFCED138D94.svg" alt=""></p>

<p>That procedure reduced the derivative of <img src="https://explained.ai/matrix-calculus/images/eqn-FDFD125C741CD062B2CA779DDE0524BE-depth003.25.svg"> to a bit of arithmetic and the derivatives of <span>x</span> and <img src="https://explained.ai/matrix-calculus/images/eqn-32F5240D0DBF2CCBE75EF7F8EF2015E0-depth000.14.svg">, which are much easier to solve than the original derivative.</p>


<h2 id="sec3">Introduction to vector calculus and partial derivatives</h2>


<p>Neural network layers are not single functions of a single parameter, <img src="https://explained.ai/matrix-calculus/images/eqn-50BBD36E1FD2333108437A2CA378BE62-depth003.25.svg">. So, let's move on to functions of multiple parameters such as <img src="https://explained.ai/matrix-calculus/images/eqn-3BAF1600AE50930A155F58AE172B51BD-depth003.25.svg">. For example, what is the derivative of <span>xy</span> (i.e., the multiplication of <span>x</span> and <span>y</span>)? In other words, how does the product <span>xy</span> change when we wiggle the variables? Well, it depends on whether we are changing <span>x</span> or <span>y</span>.  We compute derivatives with respect to one variable (parameter) at a time, giving us two different <i>partial derivatives</i> for this two-parameter function (one for <span>x</span> and one for <span>y</span>).  Instead of using operator <img src="https://explained.ai/matrix-calculus/images/eqn-624FEBB9A49A3FC96353C861D175C806-depth004.58.svg">, the partial derivative operator is  <img src="https://explained.ai/matrix-calculus/images/eqn-4D6C379F66675645B3FFE28A15306857-depth004.67.svg"> (a stylized <span>d</span> and not the Greek letter <img src="https://explained.ai/matrix-calculus/images/eqn-77A3B715842B45E440A5BEE15357AD29-depth000.22.svg">). So, <img src="https://explained.ai/matrix-calculus/images/eqn-08DCCFBE629A14FCCD9FB9A20F2E367C-depth004.67.svg"> and <img src="https://explained.ai/matrix-calculus/images/eqn-1FDCF7A9F137AE48FA25EE34A69F8201-depth006.34.svg"> are the partial derivatives of <span>xy</span>; often, these are just called the <i>partials</i>.  For functions of a single parameter, operator <img src="https://explained.ai/matrix-calculus/images/eqn-4D6C379F66675645B3FFE28A15306857-depth004.67.svg"> is equivalent to <img src="https://explained.ai/matrix-calculus/images/eqn-624FEBB9A49A3FC96353C861D175C806-depth004.58.svg"> (for sufficiently smooth functions). However, it's better to use <img src="https://explained.ai/matrix-calculus/images/eqn-624FEBB9A49A3FC96353C861D175C806-depth004.58.svg"> to make it clear you're referring to a scalar derivative.</p>

<p>The partial derivative with respect to <span>x</span> is just the usual scalar derivative, simply treating any other variable in the equation as a constant.  Consider function <img src="https://explained.ai/matrix-calculus/images/eqn-D6DEAE7E403381C2C425D4B40CCA936E-depth003.25.svg">. The partial derivative with respect to <span>x</span> is written <img src="https://explained.ai/matrix-calculus/images/eqn-F063B8EC812DF3D204F9327F5D094073-depth004.67.svg">. There are three constants from the perspective of <img src="https://explained.ai/matrix-calculus/images/eqn-4D6C379F66675645B3FFE28A15306857-depth004.67.svg">: 3, 2, and <span>y</span>. Therefore, <img src="https://explained.ai/matrix-calculus/images/eqn-D981BA4BD14AC44C43A4E4E0EC750B4A-depth004.67.svg">. The partial derivative with respect to <span>y</span> treats <span>x</span> like a constant: <img src="https://explained.ai/matrix-calculus/images/eqn-55A3A400FAD3326FEF1BB9DDD2658383-depth006.34.svg">.  It's a good idea to derive these yourself before continuing otherwise the rest of the article won't make sense.  Here's the <a href="https://www.khanacademy.org/math/multivariable-calculus/multivariable-derivatives/partial-derivative-and-gradient-articles/a/introduction-to-partial-derivatives">Khan Academy video on partials</a> if you need help.</p>

<p>To make it clear we are doing vector calculus and not just multivariate calculus, let's consider what we do with the partial derivatives <img src="https://explained.ai/matrix-calculus/images/eqn-84D799755A7F73945BD58B2E057121AB-depth004.67.svg"> and <img src="https://explained.ai/matrix-calculus/images/eqn-A2DE2EC029172B84A0A0E8A8D00F5A6F-depth006.34.svg"> (another way to say <img src="https://explained.ai/matrix-calculus/images/eqn-75645E70B6C95F7466C353E9C2306FE0-depth004.67.svg"> and <img src="https://explained.ai/matrix-calculus/images/eqn-B20FF70C037320C2D0B710F4B592927E-depth006.34.svg">) that we computed for <img src="https://explained.ai/matrix-calculus/images/eqn-D6DEAE7E403381C2C425D4B40CCA936E-depth003.25.svg">.  Instead of having them just floating around and not organized in any way, let's organize them into a horizontal vector. We call this vector the <i>gradient</i> of <img src="https://explained.ai/matrix-calculus/images/eqn-3BAF1600AE50930A155F58AE172B51BD-depth003.25.svg"> and …</p></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://explained.ai/matrix-calculus/">https://explained.ai/matrix-calculus/</a></em></p>]]>
            </description>
            <link>https://explained.ai/matrix-calculus/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24180065</guid>
            <pubDate>Sun, 16 Aug 2020 18:39:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Recent Advances in Natural Language Processing]]>
            </title>
            <description>
<![CDATA[
Score 253 | Comments 153 (<a href="https://news.ycombinator.com/item?id=24179795">thread link</a>) | @saadalem
<br/>
August 16, 2020 | https://deponysum.com/2020/01/16/recent-advances-in-natural-language-processing-some-woolly-speculations/ | <a href="https://web.archive.org/web/*/https://deponysum.com/2020/01/16/recent-advances-in-natural-language-processing-some-woolly-speculations/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-1118">
	<!-- .entry-header -->

	<div>
		<p><em>If you enjoy this article, please check out my free book by clicking <a href="https://deponysum.com/2020/03/30/something-to-read-in-quarantine-essays-2018-to-2020/">Here: “Something to Read in Quarantine: Essays 2018-2020.”</a></em></p>
<p id="b9a9">Natural Language Processing (NLP) per Wikipedia:</p>
<p id="34cf">“Is a subfield of linguistics, computer science, information engineering, and artificial intelligence concerned with the interactions between computers and human (natural) languages, in particular how to program computers to process and analyze large amounts of natural language data.”</p>
<p id="7dd8">The field has seen tremendous advances during the recent explosion of progress in machine learning techniques.</p>
<p id="b5f8">Here are some of its more impressive recent achievements:</p>
<p id="cb15"><strong>A)</strong>&nbsp;The Winograd Schema is a test of common sense reasoning- easy for humans, but historically almost impossible for computers- which requires the test taker to indicate which noun an ambiguous pronoun stands for. The correct answer hinges on a single word, which is different between two separate versions of the question. For example:</p>
<p id="512d"><em>The city councilmen refused the demonstrators a permit because they feared violence.</em></p>
<p id="ece3"><em>The city councilmen refused the demonstrators a permit because they advocated violence.</em></p>
<p id="0ddf">Who does the pronoun “They” refer to in each of the instances?</p>
<p id="d33c">The Winograd schema test was originally intended to be a more rigorous replacement for the Turing test, because it seems to require deep knowledge of how things fit together in the world, and the ability to reason about that knowledge in a linguistic context. Recent advances in NLP have allowed computers to achieve near human scores:(<a href="https://gluebenchmark.com/leaderboard/" target="_blank" rel="noopener nofollow">https://gluebenchmark.com/leaderboard/</a>).</p>
<p id="0a43"><strong>B)</strong>&nbsp;The New York Regent’s science exam is a test requiring both scientific knowledge and reasoning skills, covering an extremely broad range of topics. Some of the questions include:</p>
<p id="a36d"><em>1.Which equipment will best separate a mixture of iron filings and black pepper? (1) magnet (2) filter paper (3) triplebeam balance (4) voltmeter</em></p>
<p id="9797"><em>2. Which form of energy is produced when a rubber band vibrates? (1) chemical (2) light (3) electrical (4) sound</em></p>
<p id="966a"><em>3. Because copper is a metal, it is (1) liquid at room temperature (2) nonreactive with other substances (3) a poor conductor of electricity (4) a good conductor of heat</em></p>
<p id="6d70"><em>4. Which process in an apple tree primarily results from cell division? (1) growth (2) photosynthesis (3) gas exchange (4) waste removal</em></p>
<p id="3a8a">On the 8th grade, non-diagram based questions of the test, a program was recently able to score 90%. (&nbsp;<a href="https://arxiv.org/pdf/1909.01958.pdf" target="_blank" rel="noopener nofollow">https://arxiv.org/pdf/1909.01958.pdf</a>&nbsp;)</p>
<p id="2f49"><strong>C)</strong></p>
<p id="267a">It’s not just about answer selection either. Progress in text generation has been impressive. See, for example, some of the text samples created by Megatron:&nbsp;<a href="https://arxiv.org/pdf/1909.08053.pdf" target="_blank" rel="noopener nofollow">https://arxiv.org/pdf/1909.08053.pdf</a></p>
<p id="b8f7"><strong>2.</strong></p>
<p id="db13">Much of this progress has been rapid. Big progress on the Winograd schema, for example, still looked like it might be decades away back in (from memory) much of 2018. The computer science is advancing very fast, but it’s not clear our concepts have kept up.</p>
<p id="1a6c">I found this relatively sudden progress in NLP surprising. In my head- and maybe this was naive- I had thought that, in order to attempt these sorts of tasks with any facility, it wouldn’t be sufficient to simply feed a computer lots of text. Instead, any “proper” attempt to understand language would have to integrate different modalities of experience and understanding, like visual and auditory, in order to build up a full picture of how things relate to each other in the world. Only on the basis of this extra-linguistic grounding could it deal flexibly with problems involving rich meanings- we might call this the multi-modality thesis. Whether the multi-modality thesis is true for some kinds of problems or not, it’s certainly true for far fewer problems than I, and many others, had suspected.</p>
<p id="5a4d">I think science-fictiony speculations generally backed me up on this (false) hunch. Most people imagined that this kind of high-level language “understanding” would be the capstone of AI research, the thing that comes after the program already has a sophisticated extra-linguistic model of the world. This sort of just seemed obvious- a great example of how assumptions you didn’t even know you were making can ruin attempts to predict the future.</p>
<p id="f943">In hindsight it makes a certain sense that reams and reams of text alone can be used to build the capabilities needed to answer questions like these. A lot of people remind us that these programs are really just statistical analyses of the co-occurence of words, however complex and glorified. However we should not forget that the relationships between words are isomorphic to the relations between things- that isomorphism is why language works. This is to say the patterns in language use mirror the patterns of how things are(1). Models are transitive- if x models y, and y models z, then x models z. The upshot of these facts are that if you have a really good statistical model of how words relate to each other, that model is also implicitly a model of the world.</p>
<p id="12db">It might be instructive to think about what it would take to create a program which has a model of eighth grade science sufficient to understand and answer questions about hundreds of different things like “growth is driven by cell division”, and “What can magnets be used for” that wasn’t NLP led. It would be a nightmare of many different (probably handcrafted) models. Speaking somewhat loosely, language allows for intellectual capacities to be greatly compressed. From this point of view, it shouldn’t be surprising that some of the first signs of really broad capacity- common sense reasoning, wide ranging problem solving etc., have been found in language based programs- words and their relationships are just a vastly more efficient way of representing knowledge than the alternatives.</p>
<p id="1e8b">So I find myself wondering if language is not the crown of general intelligence, but a potential shortcut to it.</p>
<p id="beea"><strong>3.</strong></p>
<p id="0095">A couple of weeks ago I finished this essay, read through it, and decided it was not good enough to publish. The point about language being isomorphic to the world, and that therefore any sufficiently good model of language&nbsp;<em>is</em>&nbsp;a model of the world, is important, but it’s kind of abstract, and far from original.</p>
<p id="e0e2">Then today I read&nbsp;<a href="https://slatestarcodex.com/2020/01/06/a-very-unlikely-chess-game/" target="_blank" rel="noopener nofollow">this report</a>&nbsp;by Scott Alexander of having trained GPT-2 (a language program) to play chess. I realised this was the perfect example. GPT-2 has no (visual) understanding of things like the arrangement of a chess board. But if you feed it enough sequences of alphanumerically encoded games- 1.Kt-f3, d5 and so on- it begins to understand patterns in these strings of characters which are isomorphic to chess itself. Thus, for all intents and purposes, it develops a model of chess.</p>
<p id="1a14">Exactly how strong this approach is- whether GPT-2 is capable of some limited analysis, or can only overfit openings- remains to be seen. We might have a better idea as it is optimised — for example, once it is fed board states instead of sequences of moves. Either way though, it illustrates the point about isomorphism.</p>
<p id="a87a">Of course everyday language stands in a woolier relation to sheep, pine cones, desire and quarks than the formal language of chess moves stands in relation to chess moves, and the patterns are far more complex. Modality, uncertainty, vagueness and other complexities enter but the isomorphism between world and language is there, even if inexact.</p>
<p id="b6c0"><strong>Postscript- The Chinese Room Argument</strong></p>
<p id="f901">After similar arguments are made, someone usually mentions the Chinese room thought experiment. There are, I think, two useful things to say about it:</p>
<p id="3d7e">A) The thought experiment is an argument about understanding in itself, separate from capacity to handle tasks, a difficult thing to quantify or understand. It’s unclear that there is a practical upshot for what <em>AI can actually do.</em></p>
<p id="1f79">B) A lot of the power of the thought experiment hinges on the fact that the room solves questions using a lookup table, this stacks the deck. Perhaps we be more willing to say that the room as a whole understood language if it formed an (implicit) model of how things are, and of the current context, and used those models to answer questions? Even if this doesn’t deal with all the intuition that the room cannot understand Chinese, I think it takes a bite from it.</p>
<p id="96a9">— — — — — — — — — — — — — — — — — — — — — — — — — — — — — —</p>
<p id="4642">(1)- Strictly of course only the patterns in true sentences mirror, or are isomorphic to, the arrangement of the world, but most sentences people utter are at least approximately true.</p>
			</div><!-- .entry-content -->

	<!-- .entry-footer -->

		<!-- .entry-auhtor -->
</article></div>]]>
            </description>
            <link>https://deponysum.com/2020/01/16/recent-advances-in-natural-language-processing-some-woolly-speculations/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24179795</guid>
            <pubDate>Sun, 16 Aug 2020 18:03:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Error recovery with parser combinators, using Rust and nom]]>
            </title>
            <description>
<![CDATA[
Score 50 | Comments 7 (<a href="https://news.ycombinator.com/item?id=24178208">thread link</a>) | @fanf2
<br/>
August 16, 2020 | https://www.eyalkalderon.com/nom-error-recovery/ | <a href="https://web.archive.org/web/*/https://www.eyalkalderon.com/nom-error-recovery/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
<article>

<ul id="frontmatter">
<li>
<time datetime="2020-04-01">April 01, 2020</time>
</li>
<span></span>
<li> 3534 words </li>
<span></span>
<li> 18 min </li>
</ul>
<p>As the COVID-19 pandemic continues to ravage the globe, lots of people are stuck
at home, either working remotely or sitting around without much to do. The
previous afternoon, I had stumbled across an online announcement that the
<a href="https://www.acm.org/articles/bulletins/2020/march/dl-access-during-covid-19">ACM Digital Library has been made free to all to read and download</a> to
help foster research, discovery, and learning during this time of crisis.
Feeling curious, and having previously wanted to read certain research papers
from the ACM DL previously, I took the opportunity to peruse through its library
and read as much content as I could. As I was doing so, I stumbled across a very
useful paper called <a href="https://dl.acm.org/doi/10.1145/3167132.3167261"><strong>"Syntax error recovery in parsing expression
grammars"</strong></a> by (Medeiros, S. and Fabio Mascarenhas, 2018) that I would
like to share, and I'll be testing some of its concepts using a prototype parser
written in <a href="https://www.rust-lang.org/">Rust</a> with the help of the <a href="https://docs.rs/nom"><code>nom</code></a> crate.</p>
<h2 id="some-background">Some background</h2>
<p>Language parsing is a very broad and interesting topic, with a swathe of varying
approaches and tools to choose from depending on the requirements of the task at
hand, but the basic premise is simple: the goal of a parser is to consume some
data as input, break it down into its component parts according to some grammar,
and derive meaning or understanding from it (<a href="https://en.wikipedia.org/wiki/Parsing">wiki</a>). I personally happen to
enjoy working with <em>parsing expression grammars</em> (PEGs) and <em>parser combinators</em>
when writing my own projects.</p>
<p>In case you are not familiar, PEG is a kind of declarative formal language for
describing other languages in terms of string pattern matching. That is, PEG
allows the parser author to declare the grammar of the language they wish to
parse using sets of expressions like those shown below:</p>
<pre><span>expr    ← sum
sum     ← product (('+' / '-') product)*
product ← value (('*' / '/') value)*
value   ← [0-9]+ / '(' expr ')'
</span></pre>
<p>These PEG rules would then be able to describe the rules to a simple arithmetic
language that behaves like this:</p>
<table><thead><tr><th>Input</th><th>Parsed syntax tree</th></tr></thead><tbody>
<tr><td><code>123</code></td><td><code>Value(123)</code></td></tr>
<tr><td><code>1 + 2</code></td><td><code>Sum(Value(1), Value(2))</code></td></tr>
<tr><td><code>1 + 2 * 3</code></td><td><code>Sum(Value(1), Product(Value(2), Value(3)))</code></td></tr>
<tr><td><code>(1 + 2) * 3</code></td><td><code>Product(Sum(Value(1), Value(2)), Value(3))</code></td></tr>
</tbody></table>
<p>Any PEG expression can be converted directly into a <a href="https://en.wikipedia.org/wiki/Recursive_descent_parser">recursive descent parser</a>,
either automatically using a parser generator or crafted by hand in the
programming language of your choice.</p>
<p>I really enjoy using parser combinator frameworks like <a href="https://docs.rs/nom"><code>nom</code></a> as a nice middle
ground between the two options, since they grant you the freedom and flexibility
of writing your parser fully in the host language (in this example, Rust), but
the resulting code is succinct, fairly declarative, and looks somewhat PEG-ish,
if you tilt your head and squint hard enough.</p>
<pre><span>fn </span><span>expr</span><span>(</span><span>input</span><span>: &amp;</span><span>str</span><span>) -&gt; IResult&lt;&amp;</span><span>str</span><span>, &amp;</span><span>str</span><span>&gt; {
    </span><span>sum</span><span>(input)
}

</span><span>fn </span><span>sum</span><span>(</span><span>input</span><span>: &amp;</span><span>str</span><span>) -&gt; IResult&lt;&amp;</span><span>str</span><span>, &amp;</span><span>str</span><span>&gt; {
    </span><span>let</span><span> op = </span><span>alt</span><span>((</span><span>char</span><span>('</span><span>+</span><span>'), </span><span>char</span><span>('</span><span>-</span><span>')));
    </span><span>recognize</span><span>(</span><span>pair</span><span>(product, </span><span>many0</span><span>(</span><span>pair</span><span>(op, product))))(input)
}

</span><span>fn </span><span>product</span><span>(</span><span>input</span><span>: &amp;</span><span>str</span><span>) -&gt; IResult&lt;&amp;</span><span>str</span><span>, &amp;</span><span>str</span><span>&gt; {
    </span><span>let</span><span> op = </span><span>alt</span><span>((</span><span>char</span><span>('</span><span>*</span><span>'), </span><span>char</span><span>('</span><span>/</span><span>')));
    </span><span>recognize</span><span>(</span><span>pair</span><span>(value, </span><span>many0</span><span>(</span><span>pair</span><span>(op, value))))(input)
}

</span><span>fn </span><span>value</span><span>(</span><span>input</span><span>: &amp;</span><span>str</span><span>) -&gt; IResult&lt;&amp;</span><span>str</span><span>, &amp;</span><span>str</span><span>&gt; {
    </span><span>recognize</span><span>(</span><span>alt</span><span>((digit1, </span><span>delimited</span><span>(</span><span>char</span><span>('</span><span>(</span><span>'), expr, </span><span>char</span><span>('</span><span>)</span><span>')))))(input)
}
</span></pre>
<p>Each of the four parsers above corresponds to a PEG rule, and since each one is
represented as a pure function, they compose nicely in code and each one can
easily be tested in isolation from the others, e.g. with inline unit tests. All
in all, I enjoy working with PEG and parser combinators!</p>
<h2 id="motivation">Motivation</h2>
<p>I've been hacking on a parser and <a href="https://microsoft.github.io/language-server-protocol/">language server</a> for the <a href="https://nixos.org/nix/">Nix programming
language</a> as a side project (<a href="https://github.com/ebkalderon/nix-language-server">GitHub</a>) for some time now, and this extended
period of being stuck at home renewed my interest in working on it. This
language server aims to supply code analysis, and auto-completion for compatible
third-party text editors and IDEs. This project has been very challenging for me
to work on, in a good way, because language servers tend to have very strict
requirements of their underlying parsers.</p>
<p>Most compilers and static analysis tools are <a href="https://en.wikipedia.org/wiki/Batch_program">batch programs</a> which act like a
dumb pipe, consuming source code in one end and spitting an executable out the
other (yes, incremental compilation and artifact caching bends this analogy a
bit, but the basic premise still holds). This means that their parsers and
resulting <a href="https://en.wikipedia.org/wiki/Abstract_syntax_tree">abstract syntax trees</a> are optimized for very different things than
what an interactive IDE would want.</p>
<p>Since the user is continuously modifying the source text and entering keystrokes
into their editor, the parser providing syntax checking for their editor is very
frequently exposed to incomplete or downright invalid snippets of code more
often than not. This means that halting parsing and bailing with an error
message whenever the first error is encountered, like many traditional parsers
do, is <em>simply not an option</em>.</p>
<p><img src="https://user-images.githubusercontent.com/1711539/76758522-1ee9ad80-678a-11ea-84cd-111739ecd379.gif" alt="rust-analyzer in action">
<em>Source: <a href="https://rust-analyzer.github.io/thisweek/2020/03/16/changelog-16.html">rust-analyzer Changelog #16</a></em></p>
<p>Instead, the parser needs to be as fault-tolerant as possible, always producing
a syntax tree of some kind on every single parse and deriving as much syntactic
and semantic meaning as it can from user input, however malformed it might be.
Your editor should still be able to provide meaningful code completion, hover
documentation, go-to-definition, and symbol searching regardless of whether
there is a missing semicolon somewhere halfway down the page.</p>
<h2 id="a-naive-approach">A naive approach</h2>
<p>When I first started working on this project, I had chosen to implement my Nix
parser in Rust using <code>nom</code> 5.0, since that was the tool I was most comfortable
using for writing parsers at the time.</p>
<p>As I was writing up my parsers, I very quickly realized that bailing early from
parsing with an <code>Err(nom::Err::Error(_))</code> or <code>Err(nom::Error::Failure(_))</code>
wasn't a good idea for emitting errors. The former triggers a backtrack, which I
didn't always want, and the latter would halt parsing altogether with an error,
which I never wanted. <code>Err(nom::Error::Incomplete(_))</code> sounded promising due to
the name, but it too ended up being useless given the design constraints I had
in mind. I needed some way to log that a non-fatal parse error had been
encountered and resume parsing as though nothing had happened, but
unfortunately, there seemed to be nothing in the vast <code>nom</code> parser combinator
toolbox that could help me deal with this.</p>
<p>Given that <code>nom</code> parser combinators are pure functions whose signatures are
structured like this:</p>
<pre><span>impl </span><span>Fn(Input) -&gt; IResult&lt;Input, Output, Error&gt;
</span></pre>
<p>which maps to:</p>
<pre><span>impl </span><span>Fn(Input) -&gt; Result&lt;(Remaining, Output), Error&gt;
</span></pre>
<p>I decided to carry these non-fatal parse errors through the <code>Output</code> instead of
returning them through <code>Result::Err(nom::Error::Error(_))</code> using a custom data
structure which I had named <a href="https://github.com/ebkalderon/nix-language-server/blob/master/nix-parser/src/parser/partial.rs#L64-L68"><code>Partial</code></a>. This was a monadic data structure which
was essentially:</p>
<pre><span>pub struct </span><span>Partial&lt;T&gt; {
    </span><span>value</span><span>: Option&lt;T&gt;,
    </span><span>errors</span><span>: Vec&lt;Error&gt;,
}

</span><span>impl</span><span>&lt;T&gt; Partial&lt;T&gt; {
    </span><span>pub fn </span><span>map</span><span>&lt;U, F&gt;(</span><span>self</span><span>, </span><span>f</span><span>: F) -&gt; Partial&lt;U&gt;
    </span><span>where</span><span>
        F: FnOnce(T) -&gt; U
    { ... }

    </span><span>pub fn </span><span>flat_map</span><span>&lt;U, F&gt;(</span><span>mut </span><span>self</span><span>, </span><span>f</span><span>: F) -&gt; Partial&lt;U&gt;
    </span><span>where</span><span>
        F: FnOnce(T) -&gt; Partial&lt;U&gt;
    { ... }

    </span><span>pub fn </span><span>value</span><span>(&amp;</span><span>self</span><span>) -&gt; Option&lt;&amp;T&gt; {
        ...
    }

    </span><span>pub fn </span><span>errors</span><span>(&amp;</span><span>self</span><span>) -&gt; &amp;[Error] {
        ...
    }

    </span><span>pub fn </span><span>verify</span><span>(</span><span>self</span><span>) -&gt; Result&lt;T, Vec&lt;Error&gt;&gt; {
        ...
    }
}
</span></pre>
<p>This data structure was complemented with a bunch of custom <code>nom</code> combinators,
e.g. <code>map_partial()</code>, <code>expect_terminated()</code>, and <code>skip_if_err()</code>, which would
allow me to compose these fault-tolerant parsers together while accumulating
errors in the <code>errors</code> field.</p>
<p>The consumer of this data structure would then choose to either:</p>
<ol>
<li>Assert that they need a valid AST without errors by calling <code>expr.verify()</code>,
transforming the <code>Partial&lt;T&gt;</code> into a <code>Result&lt;T, Vec&lt;Error&gt;&gt;</code>. This option
would be useful for traditonal batch compiler authors, as well as for testing
and debugging.</li>
<li>Extract and examine the contents of the <code>value</code> and <code>errors</code> field
separately. This is what the language server would do: publish the
accumulated errors to the user's editor in the form of diagnostics and then
perform further analysis on the syntax tree contained in <code>value</code>.</li>
</ol>
<p>All the parser combinators would have this function signature instead:</p>
<pre><span>impl </span><span>Fn(Input) -&gt; IResult&lt;Input, Partial&lt;Output&gt;, Error&gt;
</span></pre>
<p>While this approach seemed to work well initially, it spiralled out of control
once the parser grew beyond a certain size. The number of <code>Partial</code> specific
combinators grew, the parser logic got hairier, more imperative, and trickier to
debug, and the performance implications of carrying around a heavy stack of
errors from function to function <a href="https://github.com/ebkalderon/nix-language-server/commit/4cd939a2917709a527bd1967f4a29bfd9f2767cc">were astonishingly awful</a>. It didn't
look and feel that much like PEG anymore.</p>
<p>I will admit I learned a lot about a breadth of topics during this time, from
benchmarking functions with <a href="https://github.com/bheisler/criterion.rs"><code>criterion</code></a> to generating flamegraphs with
<a href="https://github.com/ferrous-systems/flamegraph"><code>cargo-flamegraph</code></a>, and going to extreme lengths to avoid heap allocations to
make the parser as fast as possible. I used <a href="https://docs.rs/nom_locate"><code>nom_locate</code></a> to retain string span
information and be as zero-copy as possible when constructing the syntax tree.
But ultimately, I couldn't fix all the warts and fundamental flaws. I needed a
new approach.</p>
<h2 id="the-paper-s-solution">The paper's solution</h2>
<p>Finally, back to the paper that originally inspired this article! I shelved this
project some months ago due to work and personal life matters, but came back
to it last month with some fresh ideas and a better intuition of where to look.
Discouraged by the previous setbacks, I was questioning whether parser
combinators in general were flexible enough to express parsers which were both
permissive and fault-tolerant, while also emitting good hand-crafted
diagnostics. But then I stumbled upon the <a href="https://dl.acm.org/doi/10.1145/3167132.3167261">"Syntax error recovery in parsing
expression grammars" (2018)</a> paper while scouring the ACM DL search
engine for interesting articles last night.</p>
<p>The authors of this paper actually managed to get pretty great results parsing
the <a href="https://www.lua.org/">Lua programming language</a> using a set of extended PEGs, producing excellent
tailor-made diagnostics rivaling the automatic error recovering capabilities of
their control, a top-down <a href="https://en.wikipedia.org/wiki/LL_parser">LL parser</a>…</p></article></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.eyalkalderon.com/nom-error-recovery/">https://www.eyalkalderon.com/nom-error-recovery/</a></em></p>]]>
            </description>
            <link>https://www.eyalkalderon.com/nom-error-recovery/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24178208</guid>
            <pubDate>Sun, 16 Aug 2020 14:43:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Hiding messages in x86 binaries using semantic duals]]>
            </title>
            <description>
<![CDATA[
Score 165 | Comments 51 (<a href="https://news.ycombinator.com/item?id=24178188">thread link</a>) | @todsacerdoti
<br/>
August 16, 2020 | https://blog.yossarian.net/2020/08/16/Hiding-messages-in-x86-binaries-using-semantic-duals | <a href="https://web.archive.org/web/*/https://blog.yossarian.net/2020/08/16/Hiding-messages-in-x86-binaries-using-semantic-duals">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">


<h2><em>Programming, philosophy, pedaling.</em></h2>

<ul>
    <li><a href="https://blog.yossarian.net/">Home</a></li>
    <li><a href="https://blog.yossarian.net/tags">Tags</a></li>
    <li><a href="https://blog.yossarian.net/favorites">Favorites</a></li>
    <li><a href="https://blog.yossarian.net/archive">Archive</a></li>
    
      <li><a href="https://yossarian.net/">Main Site</a></li>
    
</ul>

<hr>



<h2>
  <em>Aug 16, 2020</em>
</h2>

  <p>Tags:
  
    
    <a href="https://blog.yossarian.net/tags#rust">rust</a>,
    
  
    
    <a href="https://blog.yossarian.net/tags#devblog">devblog</a>,
    
  
    
    <a href="https://blog.yossarian.net/tags#programming">programming</a>
    
  
  </p>


<p>This is a quick writeup of a <a href="https://en.wikipedia.org/wiki/Steganography">steganographic</a> tool
that I threw together: <a href="https://github.com/woodruffw/steg86"><em>steg86</em></a>. It uses a quirk of the
x86 instruction encoding format to hide messages in pre-existing binaries with no size or
performance overhead.</p>

<p>You can play with it yourself by fetching it with <code>cargo</code>:</p>

<div><div><pre><code><span>$ </span>cargo <span>install </span>steg86
<span>$ </span>steg86 <span>--help</span>
</code></pre></div></div>

<h2 id="a-quick-steganography-refresher">A quick steganography refresher</h2>

<p>Steganography is the practice of concealing data within other data. A variety of different
common formats open themselves up to steganographic channels:</p>

<ul>
  <li>Image formats: using the least significant bits of the color space</li>
  <li>Audio formats: hiding information in background noise, or hiding an image
in the <a href="https://en.wikipedia.org/wiki/Spectrogram">spectrogram</a></li>
  <li>Plain text: using <a href="https://en.wikipedia.org/wiki/IDN_homograph_attack">homographs</a> and
<a href="https://en.wikipedia.org/wiki/Zero-width_joiner">special spacing characters</a> to encode information</li>
</ul>

<p>On its own, steganography is <em>not</em> a replacement for cryptography: it’s strictly
obfuscatory, and does not provide any deniablity of the embedded message if revealed.</p>

<p>That being said, there exist a variety of use cases for steganographic schemes:</p>

<ul>
  <li>Coupled with strong cryptography, they <em>do</em> allow for deniability: depending on the format,
an extracted message can be made indistinguishable from random noise prior to decryption.</li>
  <li>Steganography can be used for fingerprinting and asset management.
<a href="https://en.wikipedia.org/wiki/Machine_Identification_Code">Commercial printers</a> are well-known for doing this;
video games have also used it to <a href="https://www.schneier.com/blog/archives/2012/09/steganography_i_1.html">track users and their machines</a>.</li>
</ul>

<h2 id="doing-steganography-on-computer-programs">Doing steganography on computer programs</h2>

<p>There are two obvious avenues for doing steganography on compiled programs. <em>steg86</em> does
<strong>neither</strong> of these, but for the sake of completeness:</p>

<h3 id="instrumenting-the-program-via-the-compiler">Instrumenting the program via the compiler</h3>

<p>Compilers perform instruction selection to lower their internal representations into machine code.
Instruction selection can be informed by any number of weights, including
<a href="https://en.wikipedia.org/wiki/Register_allocation">register pressure</a>, individual instruction
performance (clock cycles, use of shared units), and feature availability
(e.g., selecting an older version of <a href="https://en.wikipedia.org/wiki/Streaming_SIMD_Extensions">SSE</a>
to be compatible with more CPUs).</p>

<p>In this approach, the steganographer would control the compiler and its instruction selection
weights, encoding information in particular selections of instructions (or other parts of
code generation, like stack object order).</p>

<p>This affords a great deal of flexibility and control, but also makes it more difficult for the
compiler to perform optimal selections. It also requires the steganographer to maintain
their (forked) compiler. Not a bad idea, but requires a decent amount of effort.</p>

<h3 id="instrumenting-the-container-format">Instrumenting the container format</h3>

<p>Another approach is to ignore the compiled instructions themselves, and focus on the binary
container: <a href="https://en.wikipedia.org/wiki/Executable_and_Linkable_Format">ELF</a>,
<a href="https://en.wikipedia.org/wiki/Mach-O">Mach-O</a>, or
<a href="https://en.wikipedia.org/wiki/Portable_Executable">PE</a>, among others.</p>

<p>These formats afford many opportunities for embedding information: the order
(both file and virtual address) of segments and sections, the order and layout
of <a href="https://en.wikipedia.org/wiki/Relocation_(computing)">relocation tables</a> and the composition of
their internal rules, and so on.</p>

<p>Instrumenting the binary format rather than the executable code means not having
to muck with instruction selection, but is also less bountiful in terms of
information density. It’s also not portable, e.g. tricks for hiding information
in ELF relocation entries would have to be tweaked for PEs.</p>

<h2 id="how-steg86-works">How <em>steg86</em> works</h2>

<p>Instead of controlling instruction selection or tweaking the details of the containing binary
format, <em>steg86</em> takes a third route: it uses the presence of <em>semantic duals</em> in the x86 and AMD64
instruction formats to selectively rewrite a program <em>after</em> compilation.</p>

<h3 id="semantic-duals">Semantic duals</h3>

<p>Like every ISA, x86 (and AMD64) have multiple ways to encode the semantics of a particular
(higher level, conceptual) operation. For example, clearing a register:</p>

<div><div><pre><code><span>; xor'ing a register with itself clears all bits</span>
<span>xor</span> <span>eax</span><span>,</span> <span>eax</span>

<span>; and'ing a register with 0 also clears all bits</span>
<span>and</span> <span>eax</span><span>,</span> <span>0</span>

<span>; we could also set 0</span>
<span>mov</span> <span>eax</span><span>,</span> <span>0</span>

<span>; ...or subtract</span>
<span>sub</span> <span>eax</span><span>,</span> <span>eax</span>

<span>; ...or load a "computed" address that's always 0</span>
<span>lea</span> <span>eax</span><span>,</span> <span>[</span><span>0</span><span>]</span>
</code></pre></div></div>

<p>…among many others. Unfortunately, this doesn’t work exactly as we’d like:</p>

<ul>
  <li>Each of these alternatives may have a different length when encoded, e.g. 2 bytes for
<code>xor eax, eax</code> versus 6 for <code>lea eax, [0]</code>. Consequently, rewriting one in terms of another
might entail a length change and subsequent relocation and displacement fixups.</li>
  <li>Each of these alternatives has subtle microarchitectural differences: they set and clear
different arithmetic flags, have different implicit segmentation behavior, and so on.
We don’t know perfectly whether the original operations took advantage of those details,
so many of our potential alternatives run the risk of subtle breakage.</li>
</ul>

<p>Fortunately, this is <strong>not</strong> what <em>steg86</em> does.</p>

<p>Instead, <em>steg86</em> takes advantage of one of the quirks of the x86 instruction encoding: the ModR/M
byte:</p>

<p><img src="https://blog.yossarian.net/assets/modrm.png" alt="The ModR/M byte."></p>

<p>The ModR/M byte is normally used to encode one or more explicit register and/or memory operands
to an opcode<sup id="fnref:1" role="doc-noteref"><a href="#fn:1">1</a></sup>: it’s how x86 can supply the rich range of source-to-sink modes that it has
(register-to-memory, memory-to-register, register-to-register, immediate-to-register, &amp;c).</p>

<p>Because register-to-memory and memory-to-register are both valid source-sink combinations for
many opcodes, many have encoding forms like the following:</p>

<div><div><pre><code><span>; xor register with register/memory32 and store register/memory32</span>
<span>xor</span> <span>r</span><span>/</span><span>m32</span><span>,</span> <span>r32</span>

<span>; xor register/memory32 with register and store register</span>
<span>xor</span> <span>r32</span><span>,</span> <span>r</span><span>/</span><span>m32</span>
</code></pre></div></div>

<p>Consequently, there are actually <strong>two</strong> ways to encode <code>xor eax, eax</code>:</p>

<div><div><pre><code>; r/m32, r
31 C0

; r, r/m32
33 C0
</code></pre></div></div>

<p>These encodings are <em>semantic duals</em>: they have different opcodes, but belong to the same
instruction family, have the same length, and have the <em>exact same behavior and performance</em>.
We could replace every occurrence of <code>31 C0</code> with <code>33 C0</code> and our programs would happily chug along,
none the wiser.</p>

<p>As it turns out, there are actually quite a few of these duals on some of the most common
x86 instructions<sup id="fnref:2" role="doc-noteref"><a href="#fn:2">2</a></sup>:</p>

<div><div><pre><code>ADD r/m8, r8   &lt;=&gt; ADD r8, r/m8
ADD r/m16, r16 &lt;=&gt; ADD r16, r/m16
ADD r/m32, r32 &lt;=&gt; ADD r32, r/m32
ADD r/m64, r64 &lt;=&gt; ADD r64, r/m64

ADC r/m8, r8   &lt;=&gt; ADC r8, r/m8
ADC r/m16, r16 &lt;=&gt; ADC r16, r/m16
ADC r/m32, r32 &lt;=&gt; ADC r32, r/m32
ADC r/m64, r64 &lt;=&gt; ADC r64, r/m64

AND r/m8, r8   &lt;=&gt; AND r8, r/m8
AND r/m16, r16 &lt;=&gt; AND r16, r/m16
AND r/m32, r32 &lt;=&gt; AND r32, r/m32
AND r/m64, r64 &lt;=&gt; AND r64, r/m64

OR r/m8, r8    &lt;=&gt; OR r8, r/m8
OR r/m16, r16  &lt;=&gt; OR r16, r/m16
OR r/m32, r32  &lt;=&gt; OR r32, r/m32
OR r/m64, r64  &lt;=&gt; OR r64, r/m64

XOR r/m8, r8   &lt;=&gt; XOR r8, r/m8
XOR r/m16, r16 &lt;=&gt; XOR r16, r/m16
XOR r/m32, r32 &lt;=&gt; XOR r32, r/m32
XOR r/m64, r64 &lt;=&gt; XOR r64, r/m64

SUB r/m8, r8   &lt;=&gt; SUB r8, r/m8
SUB r/m16, r16 &lt;=&gt; SUB r16, r/m16
SUB r/m32, r32 &lt;=&gt; SUB r32, r/m32
SUB r/m64, r64 &lt;=&gt; SUB r64, r/m64

SBB r/m8, r8   &lt;=&gt; SBB r8, r/m8
SBB r/m16, r16 &lt;=&gt; SBB r16, r/m16
SBB r/m32, r32 &lt;=&gt; SBB r32, r/m32
SBB r/m64, r64 &lt;=&gt; SBB r64, r/m64

MOV r/m8, r8   &lt;=&gt; MOV r8, r/m8
MOV r/m16, r16 &lt;=&gt; MOV r16, r/m16
MOV r/m32, r32 &lt;=&gt; MOV r32, r/m32
MOV r/m64, r64 &lt;=&gt; MOV r64, r/m64

CMP r/m8, r8   &lt;=&gt; CMP r8, r/m8
CMP r/m16, r16 &lt;=&gt; CMP r16, r/m16
CMP r/m32, r32 &lt;=&gt; CMP r32, r/m32
CMP r/m64, r64 &lt;=&gt; CMP r64, r/m64
</code></pre></div></div>

<p>Each dual represents one bit of information: we can arbitrarily assign one form
to be <code>true</code> and its counterpart to be <code>false</code>. Given enough of them in a target
program, we can hide a message by translating between the forms. The result:
a binary that’s exactly the same size as the original and with the same performance
characteristics, but with a hidden message.</p>

<p>That’s all <em>steg86</em> does: it locates every semantic dual in its target program, maps
its input message to a bitstring, and translates each dual depending on its corresponding
message bit. Because it only uses duals, it’s completely agnostic to its containing format:
the <code>steg86</code> CLI currently supports ELF, Mach-O, and PE/PE32+ binaries.</p>

<p>Here’s what that actually looks like, with (some of the) differing bytes highlighted in red:</p>

<p><img src="https://blog.yossarian.net/assets/steg86_vbindiff.png" alt="vbindiff between bash and steg'd bash"></p>

<p>And, of course, try it for yourself:</p>

<div><div><pre><code><span>$ </span>steg86 profile /bin/bash
Summary <span>for</span> /bin/bash:
  175828 total instructions
  27957 potential semantic pairs
  27925 bits of information capacity <span>(</span>3490 bytes, approx. 3KB<span>)</span>

<span>$ </span>steg86 embed /bin/bash test.steg <span>&lt;&lt;&lt;</span> <span>"hello world!"</span>
<span>$ </span>file test.steg
test.steg: ELF 64-bit LSB shared object, x86-64, version 1 <span>(</span>SYSV<span>)</span>, dynamically linked, interpreter /lib64/ld-linux-x86-64.so.2, BuildID[sha1]<span>=</span>a6cb40078351e05121d46daa768e271846d5cc54, <span>for </span>GNU/Linux 3.2.0, stripped

<span>$ </span>steg86 extract test.steg
hello world!
</code></pre></div></div>

<p>See the <a href="https://github.com/woodruffw/steg86/blob/master/README.md">README</a> for prior work and
future refinements to <em>steg86</em>’s informational capacity.</p>

<p><strong>Edit</strong>: An important note: because compilers and assemblers tend to select just one of the forms
above, <em>steg86</em> <strong>cannot</strong> provide deniability, even with strong encryption. Its transformations
will always look abnormal compared to a compiler-produced binary.</p>

<hr>




<hr>




  






</div>]]>
            </description>
            <link>https://blog.yossarian.net/2020/08/16/Hiding-messages-in-x86-binaries-using-semantic-duals</link>
            <guid isPermaLink="false">hacker-news-small-sites-24178188</guid>
            <pubDate>Sun, 16 Aug 2020 14:40:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Patterns of Regional Cerebral Blood Flow as a Function of Obesity in Adults]]>
            </title>
            <description>
<![CDATA[
Score 84 | Comments 52 (<a href="https://news.ycombinator.com/item?id=24177679">thread link</a>) | @InInteraction
<br/>
August 16, 2020 | https://www.iospress.nl/ios_news/body-weight-has-surprising-alarming-impact-on-brain-function/ | <a href="https://web.archive.org/web/*/https://www.iospress.nl/ios_news/body-weight-has-surprising-alarming-impact-on-brain-function/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>
            <h3>Body Weight Has Surprising, Alarming Impact on Brain Function</h3> 
			<h4>Higher BMI is linked to decreased cerebral blood flow, which is associated with increased risk of Alzheimer's disease and mental illness, according to a new study in JAD</h4>		</p><div> 
						            		
						<p>
							<em>August 5, 2020</em><br>
							<strong>Amsterdam, NL and Costa Mesa, CA, USA – As a person's weight goes up, all regions of the brain go down in activity and blood flow, according to a <a href="https://content.iospress.com/articles/journal-of-alzheimers-disease/jad200655" target="_blank">new brain imaging study</a> in the <em><a href="http://j-alz.com/" target="_blank">Journal of Alzheimer's Disease</a></em>. One of the largest studies linking obesity with brain dysfunction, scientists analyzed over 35,000 functional neuroimaging scans using single-photon emission computerized tomography from more than 17,000 individuals to measure blood flow and brain activity. </strong>
						</p><p>Low cerebral blood flow is the #1 brain imaging predictor that a person will develop Alzheimer’s disease. It is also associated with depression, ADHD, bipolar disorder, schizophrenia, traumatic brain injury, addiction, suicide, and other conditions. “This study shows that being overweight or obese seriously impacts brain activity and increases the risk for Alzheimer’s disease as well as many other psychiatric and cognitive conditions,” explained Daniel G. Amen, MD, the study’s lead author and founder of Amen Clinics, one of the leading brain-centered mental health clinics in the United States</p>
<div id="attachment_48994"><p><img src="https://www.iospress.nl/wp-content/uploads/2020/08/JAD77-3_PR1_image1_crop.jpg" alt="" width="454" height="293" srcset="https://www.iospress.nl/wp-content/uploads/2020/08/JAD77-3_PR1_image1_crop.jpg 454w, https://www.iospress.nl/wp-content/uploads/2020/08/JAD77-3_PR1_image1_crop-300x194.jpg 300w, https://www.iospress.nl/wp-content/uploads/2020/08/JAD77-3_PR1_image1_crop-148x96.jpg 148w, https://www.iospress.nl/wp-content/uploads/2020/08/JAD77-3_PR1_image1_crop-333x215.jpg 333w, https://www.iospress.nl/wp-content/uploads/2020/08/JAD77-3_PR1_image1_crop-320x207.jpg 320w, https://www.iospress.nl/wp-content/uploads/2020/08/JAD77-3_PR1_image1_crop-310x200.jpg 310w" sizes="(max-width: 454px) 100vw, 454px"></p><p><em>Areas of obesity-related hypoperfusion in brain regions vulnerable to Alzheimer’s disease: Hippocampus</em></p></div>
<p>Striking patterns of progressively reduced blood flow were found in virtually all regions of the brain across categories of underweight, normal weight, overweight, obesity, and morbid obesity. These were noted while participants were in a resting state as well as while performing a concentration task. In particular, brain areas noted to be vulnerable to Alzheimer’s disease, the temporal and parietal lobes, hippocampus, posterior cingulate gyrus, and precuneus, were found to have reduced blood flow along the spectrum of weight classification from normal weight to overweight, obese, and morbidly obese.</p>
<div id="attachment_48995"><p><img src="https://www.iospress.nl/wp-content/uploads/2020/08/JAD77-3_PR1_image2_crop.jpg" alt="" width="500" height="333" srcset="https://www.iospress.nl/wp-content/uploads/2020/08/JAD77-3_PR1_image2_crop.jpg 500w, https://www.iospress.nl/wp-content/uploads/2020/08/JAD77-3_PR1_image2_crop-300x200.jpg 300w, https://www.iospress.nl/wp-content/uploads/2020/08/JAD77-3_PR1_image2_crop-148x99.jpg 148w, https://www.iospress.nl/wp-content/uploads/2020/08/JAD77-3_PR1_image2_crop-323x215.jpg 323w, https://www.iospress.nl/wp-content/uploads/2020/08/JAD77-3_PR1_image2_crop-320x213.jpg 320w, https://www.iospress.nl/wp-content/uploads/2020/08/JAD77-3_PR1_image2_crop-310x206.jpg 310w" sizes="(max-width: 500px) 100vw, 500px"></p><p><em>3D renderings of blood flow averaged across normal BMI (BMI = 23), overweight (BMI = 29), and obese (BMI = 37) men, each 40 years of age (credit: Amen Clinics)</em></p></div>
<p>Considering the latest statistics showing that 72% of Americans are overweight of whom 42% are obese, this is distressing news for America’s mental and cognitive health.</p>
<p>Commenting on this study, George Perry, PhD, Editor-in-Chief of the <em>Journal of Alzheimer’s Disease</em> and Semmes Foundation Distinguished University Chair in Neurobiology at The University of Texas at San Antonio, stated, “Acceptance that Alzheimer’s disease is a lifestyle disease, little different from other age-related diseases, that is the sum of a lifetime is the most important breakthrough of the decade. Dr. Amen and collaborators provide compelling evidence that obesity alters blood supply to the brain to shrink the brain and promote Alzheimer’s disease. This is a major advance because it directly demonstrates how the brain responds to our body.”</p>
<p>This study highlights the need to address obesity as a target for interventions designed to improve brain function, be they Alzheimer disease prevention initiatives or attempts to optimize cognition in younger populations. Such work will be crucial in improving outcomes across all age groups.</p>
<p>Although the results of this study are deeply concerning, there is hope. Dr. Amen added, “One of the most important lessons we have learned through 30 years of performing functional brain imaging studies is that brains can be improved when you put them in a healing environment by adopting brain-healthy habits, such as a healthy calorie-smart diet and regular exercise.”</p>
<p>###</p>
<p><strong>NOTES FOR EDITORS<br>
Full open access study</strong>:&nbsp;“<a href="https://content.iospress.com/articles/journal-of-alzheimers-disease/jad200655" target="_blank" rel="noopener">Patterns of Regional Cerebral Blood Flow as a Function of Obesity in Adults</a>” by Daniel G. Amen, Joseph Wu, Noble George, and Andrew Newberg (<a href="https://doi.org/10.3233/JAD-200655" target="_blank" rel="noopener">doi.org/10.3233/JAD-200655</a>). The article appears online in the <em>Journal of Alzheimer’s Disease</em> in advance of Volume 77, Issue 3 (September 2020) published by IOS Press. The study is openly available at: <a href="https://content.iospress.com/articles/journal-of-alzheimers-disease/jad200655" target="_blank" rel="noopener">content.iospress.com/articles/journal-of-alzheimers-disease/jad200655</a>.</p>
<p><strong>Contact</strong><br>
To request the full text of the article or further information please contact Diana Murray, IOS Press (+1 718-640-5678 or <a href="mailto:d.murray@iospress.com">d.murray@iospress.com</a>) To reach the authors for comment please contact. Natalie Buchoz, Amen Clinics (+1 714-421-3778 or <a href="mailto:nbuchoz@amenclinic.com">nbuchoz@amenclinic.com</a>) For questions about the <em>Journal of Alzheimer’s Disease</em>, please contact George Perry (+1 210-458-8660 or <a href="mailto:george.perry@utsa.edu">george.perry@utsa.edu</a>)</p>
<p><strong>About the Journal of Alzheimer’s Disease</strong><br>
Now in its 23d year of publication, the&nbsp;<a href="http://www.j-alz.com/" target="_blank" rel="noopener"><em>Journal of Alzheimer’s Disease</em></a>&nbsp;(JAD) is an international multidisciplinary journal to facilitate progress in understanding the etiology, pathogenesis, epidemiology, genetics, behavior, treatment, and psychology of Alzheimer’s disease. The journal publishes research reports, reviews, short communications, book reviews, and letters-to-the-editor. Groundbreaking research that has appeared in the journal includes novel therapeutic targets, mechanisms of disease, and clinical trial outcomes. JAD has a 2019 Journal Impact Factor of 3.909 according to Journal Citation Reports (Clarivate, 2020). It is&nbsp;published by IOS Press.<a href="http://j-alz.com/" target="_blank" rel="noopener">&nbsp;j-alz.com</a></p>
<p><strong>About&nbsp;IOS Press</strong><br>
IOS Press is headquartered in Amsterdam with satellite offices in the USA, Germany, India and China and serves the information needs of scientific and medical communities worldwide. IOS Press now publishes more than 80 international peer-reviewed journals and about 75 book titles each year on subjects ranging from computer science, artificial intelligence, and engineering to medicine, neuroscience, and cancer research.&nbsp;<a href="http://iospress.com/" target="_blank" rel="noopener">iospress.com</a></p>
  
					</div></div>]]>
            </description>
            <link>https://www.iospress.nl/ios_news/body-weight-has-surprising-alarming-impact-on-brain-function/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24177679</guid>
            <pubDate>Sun, 16 Aug 2020 13:39:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[AKAI MPC 3000 sampler/sequencer drum machine]]>
            </title>
            <description>
<![CDATA[
Score 108 | Comments 94 (<a href="https://news.ycombinator.com/item?id=24177626">thread link</a>) | @omnibrain
<br/>
August 16, 2020 | https://audiojive.com/akai-mpc-3000/ | <a href="https://web.archive.org/web/*/https://audiojive.com/akai-mpc-3000/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
<figure><img loading="lazy" width="1024" height="655" src="https://i0.wp.com/audiojive.com/wp-content/uploads/2020/08/akai-mpc-3000.jpg?resize=1024%2C655&amp;ssl=1" alt="akai-mpc-3000" srcset="https://i0.wp.com/audiojive.com/wp-content/uploads/2020/08/akai-mpc-3000.jpg?resize=1024%2C655&amp;ssl=1 1024w, https://i0.wp.com/audiojive.com/wp-content/uploads/2020/08/akai-mpc-3000.jpg?resize=300%2C192&amp;ssl=1 300w, https://i0.wp.com/audiojive.com/wp-content/uploads/2020/08/akai-mpc-3000.jpg?resize=768%2C491&amp;ssl=1 768w, https://i0.wp.com/audiojive.com/wp-content/uploads/2020/08/akai-mpc-3000.jpg?resize=1536%2C982&amp;ssl=1 1536w, https://i0.wp.com/audiojive.com/wp-content/uploads/2020/08/akai-mpc-3000.jpg?resize=360%2C230&amp;ssl=1 360w, https://i0.wp.com/audiojive.com/wp-content/uploads/2020/08/akai-mpc-3000.jpg?resize=545%2C349&amp;ssl=1 545w, https://i0.wp.com/audiojive.com/wp-content/uploads/2020/08/akai-mpc-3000.jpg?resize=1600%2C1023&amp;ssl=1 1600w, https://i0.wp.com/audiojive.com/wp-content/uploads/2020/08/akai-mpc-3000.jpg?w=1911&amp;ssl=1 1911w" sizes="(max-width: 1024px) 100vw, 1024px" data-recalc-dims="1"></figure>



<p>The AKAI MPC 3000 is a classic and legendary sampler/sequencer drum machine from the early 90’s. This music instrument has been associated with everything from Hip-Hop to R&amp;B and House music.</p>



<h2>AKAI MPC 3000 Classic</h2>



<figure><img loading="lazy" width="1024" height="655" src="https://i2.wp.com/audiojive.com/wp-content/uploads/2020/08/akai-mpc-3000-classic.jpg?resize=1024%2C655&amp;ssl=1" alt="" srcset="https://i2.wp.com/audiojive.com/wp-content/uploads/2020/08/akai-mpc-3000-classic.jpg?resize=1024%2C655&amp;ssl=1 1024w, https://i2.wp.com/audiojive.com/wp-content/uploads/2020/08/akai-mpc-3000-classic.jpg?resize=300%2C192&amp;ssl=1 300w, https://i2.wp.com/audiojive.com/wp-content/uploads/2020/08/akai-mpc-3000-classic.jpg?resize=768%2C491&amp;ssl=1 768w, https://i2.wp.com/audiojive.com/wp-content/uploads/2020/08/akai-mpc-3000-classic.jpg?resize=1536%2C982&amp;ssl=1 1536w, https://i2.wp.com/audiojive.com/wp-content/uploads/2020/08/akai-mpc-3000-classic.jpg?resize=360%2C230&amp;ssl=1 360w, https://i2.wp.com/audiojive.com/wp-content/uploads/2020/08/akai-mpc-3000-classic.jpg?resize=545%2C349&amp;ssl=1 545w, https://i2.wp.com/audiojive.com/wp-content/uploads/2020/08/akai-mpc-3000-classic.jpg?resize=1600%2C1023&amp;ssl=1 1600w, https://i2.wp.com/audiojive.com/wp-content/uploads/2020/08/akai-mpc-3000-classic.jpg?w=1911&amp;ssl=1 1911w" sizes="(max-width: 1024px) 100vw, 1024px" data-recalc-dims="1"></figure>



<p>The original AKAI MPC 3000 Classic released in 1994 as the step up from its predecessor, the MPC 60 (and the later MPC 60 mkII). MSRP was staggering, coming in at just under $4,000 in the early 90’s (a little over $7,000 in today’s money). It was clear that this machine was meant for professional studios and intended to be a tool for deliberate music applications.</p>



<h2>AKAI MPC 3000 LE</h2>



<figure><img loading="lazy" width="1024" height="655" src="https://i0.wp.com/audiojive.com/wp-content/uploads/2020/08/akai-mpc-3000-le-.jpg?resize=1024%2C655&amp;ssl=1" alt="akai-mpc-3000-le" srcset="https://i0.wp.com/audiojive.com/wp-content/uploads/2020/08/akai-mpc-3000-le-.jpg?resize=1024%2C655&amp;ssl=1 1024w, https://i0.wp.com/audiojive.com/wp-content/uploads/2020/08/akai-mpc-3000-le-.jpg?resize=300%2C192&amp;ssl=1 300w, https://i0.wp.com/audiojive.com/wp-content/uploads/2020/08/akai-mpc-3000-le-.jpg?resize=768%2C491&amp;ssl=1 768w, https://i0.wp.com/audiojive.com/wp-content/uploads/2020/08/akai-mpc-3000-le-.jpg?resize=1536%2C982&amp;ssl=1 1536w, https://i0.wp.com/audiojive.com/wp-content/uploads/2020/08/akai-mpc-3000-le-.jpg?resize=360%2C230&amp;ssl=1 360w, https://i0.wp.com/audiojive.com/wp-content/uploads/2020/08/akai-mpc-3000-le-.jpg?resize=545%2C349&amp;ssl=1 545w, https://i0.wp.com/audiojive.com/wp-content/uploads/2020/08/akai-mpc-3000-le-.jpg?resize=1600%2C1023&amp;ssl=1 1600w, https://i0.wp.com/audiojive.com/wp-content/uploads/2020/08/akai-mpc-3000-le-.jpg?w=1911&amp;ssl=1 1911w" sizes="(max-width: 1024px) 100vw, 1024px" data-recalc-dims="1"></figure>



<p>The black AKAI MPC 3000 LE is a limited edition release of only 2000 individually numbered units in the year 2000. </p>



<p>There is a rumor that only 1400 units have been released to the public because as far as we know, the public has not seen any units numbered 1400 through 2000. Let it be known if you have one of these rare units.</p>



<h2>AKAI MPC 3000 Specifications</h2>



<figure><img loading="lazy" width="1024" height="400" src="https://i1.wp.com/audiojive.com/wp-content/uploads/2020/08/akai-mpc-3000-specifications.jpg?resize=1024%2C400&amp;ssl=1" alt="akai-mpc-3000-specifications" srcset="https://i1.wp.com/audiojive.com/wp-content/uploads/2020/08/akai-mpc-3000-specifications.jpg?resize=1024%2C400&amp;ssl=1 1024w, https://i1.wp.com/audiojive.com/wp-content/uploads/2020/08/akai-mpc-3000-specifications.jpg?resize=300%2C117&amp;ssl=1 300w, https://i1.wp.com/audiojive.com/wp-content/uploads/2020/08/akai-mpc-3000-specifications.jpg?resize=768%2C300&amp;ssl=1 768w, https://i1.wp.com/audiojive.com/wp-content/uploads/2020/08/akai-mpc-3000-specifications.jpg?resize=1536%2C601&amp;ssl=1 1536w, https://i1.wp.com/audiojive.com/wp-content/uploads/2020/08/akai-mpc-3000-specifications.jpg?resize=2048%2C801&amp;ssl=1 2048w, https://i1.wp.com/audiojive.com/wp-content/uploads/2020/08/akai-mpc-3000-specifications.jpg?resize=360%2C141&amp;ssl=1 360w, https://i1.wp.com/audiojive.com/wp-content/uploads/2020/08/akai-mpc-3000-specifications.jpg?resize=545%2C213&amp;ssl=1 545w, https://i1.wp.com/audiojive.com/wp-content/uploads/2020/08/akai-mpc-3000-specifications.jpg?resize=1600%2C626&amp;ssl=1 1600w, https://i1.wp.com/audiojive.com/wp-content/uploads/2020/08/akai-mpc-3000-specifications.jpg?w=2320&amp;ssl=1 2320w" sizes="(max-width: 1024px) 100vw, 1024px" data-recalc-dims="1"></figure>



<p><strong>Polyphony: 32 notes<br>Sampler: 16 bit, 44.1KHz, Mono and Stereo<br>Memory: 2 MB RAM (22 seconds) to upgradable 32 MB<br>Filter: Lowpass filter with resonance and envelope</strong></p>



<p><strong>General</strong><br>• Display: 320 character (240 x 64 dot graphic) LCD<br>• Disk drive: 3.5 inch HD (1.44MB formatted)<br>• CPU: V53 @ 16MHz<br>• Dimensions: 440(W) x 121(H) x 405(D) mm<br>• Weight: 9 kg<br>• Power requirements: 120 VAC 60Hz 40W<br>220-240 VAC 50Hz</p>



<p><strong>Sound Generator</strong><br>• Sampling rate: 44.1kHz (frequency response: 20Hz-20kHz)<br>• Sampling capacity: 2MB standard (21.9 seconds mono or 10.9<br>seconds stereo), expandable to 16MB (188.3 seconds mono or 94.1<br>seconds stereo).<br>• Data format: 16-bit linear<br>• Dynamic filtering: 12 dB/Octave dynamic resonant lowpass filter<br>per voice<br>• Maximum sounds in memory: 128<br>• Number of sound programs: 24<br>• Sound assignments per program: 64<br>• Simultaneous voices: 32</p>



<p><strong>Sequencer</strong><br>• Maximum notes: 75,000<br>• Resolution: 96 parts per 1/4-note (ppq)<br>• Sequences: 99<br>• Tracks per sequence: 99<br>• MIDI output channels: 64 (16 channels x 4 output ports)<br>• Song mode: 20 songs, 250 steps per song<br>• Drum pads: 16 (velocity and pressure sensitive)<br>• Drum pad banks: 4<br>• Sync modes: MIDI Time Code, MIDI clock, FSK 24, 1/4-note clicks<br>and SMPTE (optional). SMPTE frame rates supported are 24, 25,<br>29.97 drop and 30.</p>



<p><strong>Rear Panel Inputs/Outputs</strong><br>• Record input sensitivity (both L and R): (HI gain) -58dBm, 45kΩ;<br>(MID gain) -38dBm, 45kΩ; (LO gain) -18dBm, 45kΩ<br>• Digital sampling input: S/PDIF<br>• Stereo output level: 6dBm, 600Ω<br>• Level of 8 individual outputs: 6dBm, 600Ω<br>• Sync/Trigger input level: 0.5V p-p level (with input control at<br>maximum)<br>• Sync output level: 2.5V p-p, impedance 600Ω<br>• MIDI inputs: 2 (mergeable)<br>• MIDI outputs: 4 (independent)<br>• SCSI port: 1 (Apple 25-pin D-type SCSI connector)<br>• Headphone output: 1<br>• Foot Switch inputs: 2 (independently assignable)</p>



<figure><img loading="lazy" width="1024" height="404" src="https://i0.wp.com/audiojive.com/wp-content/uploads/2020/08/akai-mpc-3000-io-rear-back.jpg?resize=1024%2C404&amp;ssl=1" alt="akai-mpc-3000-io-rear-back" srcset="https://i0.wp.com/audiojive.com/wp-content/uploads/2020/08/akai-mpc-3000-io-rear-back.jpg?resize=1024%2C404&amp;ssl=1 1024w, https://i0.wp.com/audiojive.com/wp-content/uploads/2020/08/akai-mpc-3000-io-rear-back.jpg?resize=300%2C118&amp;ssl=1 300w, https://i0.wp.com/audiojive.com/wp-content/uploads/2020/08/akai-mpc-3000-io-rear-back.jpg?resize=768%2C303&amp;ssl=1 768w, https://i0.wp.com/audiojive.com/wp-content/uploads/2020/08/akai-mpc-3000-io-rear-back.jpg?resize=1536%2C606&amp;ssl=1 1536w, https://i0.wp.com/audiojive.com/wp-content/uploads/2020/08/akai-mpc-3000-io-rear-back.jpg?resize=360%2C142&amp;ssl=1 360w, https://i0.wp.com/audiojive.com/wp-content/uploads/2020/08/akai-mpc-3000-io-rear-back.jpg?resize=545%2C215&amp;ssl=1 545w, https://i0.wp.com/audiojive.com/wp-content/uploads/2020/08/akai-mpc-3000-io-rear-back.jpg?resize=1600%2C631&amp;ssl=1 1600w, https://i0.wp.com/audiojive.com/wp-content/uploads/2020/08/akai-mpc-3000-io-rear-back.jpg?w=1800&amp;ssl=1 1800w" sizes="(max-width: 1024px) 100vw, 1024px" data-recalc-dims="1"></figure>



<h2>History of the AKAI MPC 3000</h2>



<h3>Roger Linn</h3>



<p>In 1980 Roger Linn designed and released the worlds first drum machine that uses samples called the LM-1, under his own company Linn Moffett Electronics with then partner Alex Moffett. Eventually Linn Electronics went out of business and the next chapter would be Roger Linn and Akai Professional linking up to create new products. The collaboration was a good fit because Akai needed a creative designer and Roger Linn wasn’t a fan of the manufacturing aspects of the business. In 1988 they would release the Akai MPC 60 and later followed by the updated MPC 60 MKII. In 1994 came the release of the MPC 3000, the celebrated upgrade from the MPC 60 line.</p>



<h3>MPC 60 vs MPC 3000</h3>



<ul><li>MPC 60: 12 bit audio – MPC 3000: 16 bit audio.</li><li>MPC 60 has 750KB of stock memory, expandable to 1.5 MB. The MPC 3000 has 2 MB of stock memory, expandable up to 32 MB.</li><li>The MPC 60 only has a single mono sampling input, while the MPC 3000 has dual stereo inputs.</li><li>MPC 60 has no filters whle the MPC 3000 comes equipped with a lowpass filter.</li><li>Both sound slightly different from eachother. Some prefer the 60, others prefer the 3000.</li></ul>



<p>Roger Linn’s vision for what a drum machine could be revolved around <em>grooves</em>. A drum machine had to have great groove to it. So he wanted it to be simple and be able to record exactly what you threw at it. This required the timing to be super tight in the MPC 3000. Linn made sure all the details were figured out for this on the backend and the result is a machine that grooves perfectly.</p>



<figure><div>
<p><span><iframe width="1160" height="653" src="https://www.youtube.com/embed/vubHg2379d0?version=3&amp;rel=1&amp;fs=1&amp;autohide=2&amp;showsearch=0&amp;showinfo=1&amp;iv_load_policy=1&amp;start=80&amp;wmode=transparent" allowfullscreen="true"></iframe></span></p>
</div><figcaption>Roger Linn talks about the AKAI MPC 3000.</figcaption></figure>



<p>Hip-hop took an immediate kinship to the machine. Early notable users were producers like DJ Quik, Battlecat, Dr. Dre and J DIlla. The creation of the drum machine sampler ushered in innovation to a musical artform that was previously based around two turntables. The innovation of the sampler elevated the artform to a new frontier. Roger Linn himself has said that he did not anticipate this.</p>



<blockquote><p><em><span><b>”The AKAI MPC simultaneously </b></span><strong>digitized beat-making, progressed the pastiche musical form, and freed Hip-Hop from the confines of earlier technology.”</strong></em></p><cite><a href="https://happymag.tv/in-praise-of-the-akai-mpc-a-hip-hop-time-machine/" target="_blank" rel="noreferrer noopener">HappyMag.Tv</a></cite></blockquote>



<h3>J Dilla</h3>



<p>J Dilla started to make a name for himself in the mid 90’s with classic records like Pharcyde’s “Runnin”, Janet Jackson’s “Got Til It’s Gone”, and Q-Tip’s “Breathe &amp; Stop”.</p>



<figure><img loading="lazy" width="1024" height="797" src="https://i2.wp.com/audiojive.com/wp-content/uploads/2020/08/akai-mpc-3000-j-dilla-making-a-beat.jpg?resize=1024%2C797&amp;ssl=1" alt="akai-mpc-3000-j-dilla-making-a-beat" srcset="https://i2.wp.com/audiojive.com/wp-content/uploads/2020/08/akai-mpc-3000-j-dilla-making-a-beat.jpg?resize=1024%2C797&amp;ssl=1 1024w, https://i2.wp.com/audiojive.com/wp-content/uploads/2020/08/akai-mpc-3000-j-dilla-making-a-beat.jpg?resize=300%2C233&amp;ssl=1 300w, https://i2.wp.com/audiojive.com/wp-content/uploads/2020/08/akai-mpc-3000-j-dilla-making-a-beat.jpg?resize=768%2C597&amp;ssl=1 768w, https://i2.wp.com/audiojive.com/wp-content/uploads/2020/08/akai-mpc-3000-j-dilla-making-a-beat.jpg?resize=1536%2C1195&amp;ssl=1 1536w, https://i2.wp.com/audiojive.com/wp-content/uploads/2020/08/akai-mpc-3000-j-dilla-making-a-beat.jpg?resize=2048%2C1593&amp;ssl=1 2048w, https://i2.wp.com/audiojive.com/wp-content/uploads/2020/08/akai-mpc-3000-j-dilla-making-a-beat.jpg?resize=360%2C280&amp;ssl=1 360w, https://i2.wp.com/audiojive.com/wp-content/uploads/2020/08/akai-mpc-3000-j-dilla-making-a-beat.jpg?resize=545%2C424&amp;ssl=1 545w, https://i2.wp.com/audiojive.com/wp-content/uploads/2020/08/akai-mpc-3000-j-dilla-making-a-beat.jpg?resize=1600%2C1245&amp;ssl=1 1600w" sizes="(max-width: 1024px) 100vw, 1024px" data-recalc-dims="1"><figcaption>J Dilla making music on the AKAI MPC 3000 LE.</figcaption></figure>



<p>Out of Dilla’s music also spawned the R&amp;B sub-genre Neo-soul. Also connected to the MPC 3000 through J Dilla’s work.</p>



<p>It’s safe to say that nobody else has displayed the MPC 3000’s groove capablities better than J Dilla. He was turning off the quantize setting during a time when literally everybody was relying on quantization for electronic music creation. He approached the MPC 3000 like a drummer would, and in turn he is regarded as one of the best drum programmers of all time.</p>



<figure><img loading="lazy" width="1024" height="832" src="https://i1.wp.com/audiojive.com/wp-content/uploads/2020/08/akai-mpc-3000-j-dilla-smithsonian.jpg?resize=1024%2C832&amp;ssl=1" alt="akai-mpc-3000-j-dilla-smithsonian" srcset="https://i2.wp.com/audiojive.com/wp-content/uploads/2020/08/akai-mpc-3000-j-dilla-smithsonian-scaled.jpg?resize=1024%2C832&amp;ssl=1 1024w, https://i2.wp.com/audiojive.com/wp-content/uploads/2020/08/akai-mpc-3000-j-dilla-smithsonian-scaled.jpg?resize=300%2C244&amp;ssl=1 300w, https://i2.wp.com/audiojive.com/wp-content/uploads/2020/08/akai-mpc-3000-j-dilla-smithsonian-scaled.jpg?resize=768%2C624&amp;ssl=1 768w, https://i2.wp.com/audiojive.com/wp-content/uploads/2020/08/akai-mpc-3000-j-dilla-smithsonian-scaled.jpg?resize=1536%2C1247&amp;ssl=1 1536w, https://i2.wp.com/audiojive.com/wp-content/uploads/2020/08/akai-mpc-3000-j-dilla-smithsonian-scaled.jpg?resize=2048%2C1663&amp;ssl=1 2048w, https://i2.wp.com/audiojive.com/wp-content/uploads/2020/08/akai-mpc-3000-j-dilla-smithsonian-scaled.jpg?resize=360%2C292&amp;ssl=1 360w, https://i2.wp.com/audiojive.com/wp-content/uploads/2020/08/akai-mpc-3000-j-dilla-smithsonian-scaled.jpg?resize=545%2C443&amp;ssl=1 545w, https://i2.wp.com/audiojive.com/wp-content/uploads/2020/08/akai-mpc-3000-j-dilla-smithsonian-scaled.jpg?resize=1600%2C1299&amp;ssl=1 1600w, https://i2.wp.com/audiojive.com/wp-content/uploads/2020/08/akai-mpc-3000-j-dilla-smithsonian-scaled.jpg?w=2320&amp;ssl=1 2320w" sizes="(max-width: 1024px) 100vw, 1024px" data-recalc-dims="1"><figcaption>J Dilla’s MPC 3000 LE displayed in the Smithsonian National Museum of African American History &amp; Culture.</figcaption></figure>



<h3>Dr. Dre</h3>



<p>After the release of the landscape-changing album <em>The Chronic 2001</em> in 1999 by Dr. Dre, more of the public started to take strong notice of the machine. Dr. Dre stated in an interview with Scratch Magazine that he used four or five different MPC 3000’s at one time for the creation of the album to avoid the drawbacks of using disks and memory. He shared that during this time his beats were layed down with the drums in the 3000 first, and everything else revolving around that.</p>



<figure><img loading="lazy" width="1024" height="614" src="https://i0.wp.com/audiojive.com/wp-content/uploads/2020/08/akai-mpc-3000-dr-dre.jpg?resize=1024%2C614&amp;ssl=1" alt="akai-mpc-3000-dr-dre" srcset="https://i0.wp.com/audiojive.com/wp-content/uploads/2020/08/akai-mpc-3000-dr-dre.jpg?resize=1024%2C614&amp;ssl=1 1024w, https://i0.wp.com/audiojive.com/wp-content/uploads/2020/08/akai-mpc-3000-dr-dre.jpg?resize=300%2C180&amp;ssl=1 300w, https://i0.wp.com/audiojive.com/wp-content/uploads/2020/08/akai-mpc-3000-dr-dre.jpg?resize=768%2C461&amp;ssl=1 768w, https://i0.wp.com/audiojive.com/wp-content/uploads/2020/08/akai-mpc-3000-dr-dre.jpg?resize=360%2C216&amp;ssl=1 360w, https://i0.wp.com/audiojive.com/wp-content/uploads/2020/08/akai-mpc-3000-dr-dre.jpg?resize=545%2C327&amp;ssl=1 545w, https://i0.wp.com/audiojive.com/wp-content/uploads/2020/08/akai-mpc-3000-dr-dre.jpg?w=1200&amp;ssl=1 1200w" sizes="(max-width: 1024px) 100vw, 1024px" data-recalc-dims="1"></figure>



<h2>Interesting Facts About the MPC 3000</h2>



<ul><li>There are no visual waveforms. You chop on the MPC 3000 with numbers, editing the start and end time of samples with numerical digits. Others would argue that you can chop by individually sampling each chop.</li><li>There is no EQ or FX in the MPC 3000. Only a lowpass filter and attack/decay, and delay.</li><li>You can only cutoff 2 other pads per pad. Compare this with modern drum machines where you can apply choke groups, etc. and cutoff any pad.</li></ul>



<h2>Why The MPC 3000 Is The Best Drum Machine of All Time</h2>



<p>To put it plainly, the simplicity.</p>



<p>Even though technically an MPC is a computer, the ushering in of personal computers as we know them today, and the fast innovation simply changed how music was being made. Workflow started to shift from unmanageably short sample times to hoards of collections of samples on hard drives. Modern workflow now allows freely auditioning any sized samples and endless decisions to be made with endless tools at your fingertips, effectively debilitating creativity very easily.</p>



<p>If Roger Linn had not been the first to incorporate sampling into drum machines, and then successfuly iterate on it leading into the release of the 3000, its safe to say that Hip-Hop and House music would not have taken it under their wing and catapulted the machine into the history books in the way that its heralded as a classic machine and musical instrument.</p>



<p>When you take a step back, its easy to realize that the 3000 was really where things peaked for drum machines. The MPC 3000 knocked it out of the park where it mattered most…. The sound, the timing, and the workflow. Drum machines that came after the MPC 3000 started to offer new abilities and functions, but traded them for things like the beefy analog sound and streamlined workflow.</p>



<p><strong>The Timing</strong></p>



<p>When you talk to fans of the MPC 3000, you hear them talk about “The Feel.” They will tell you that the feel of the 3000 is like no other drum machine or sampler that exists. This is due to the timing that Roger Linn built into the machine. The timing on the MPC 3000 is extremely tight and about as true as you can get. It will record exactly what you play. Essentially, it is the essense of what a “groovebox” is.<br>The sequencer on the MPC 3000 is second to none.</p>



<p><strong>The Sound</strong></p>



<p>Theres something about the sound of the MPC 3000. It’s the sampling engine, but it also seems to be more than that. For drums, while subtle… enthusiasts will tell you its unmatched. While the sampling engine will color sounds in its own way, the 3000 also seems to have a unique glue which provides subtle punch. Sounds will jump off of the track and manage to coexist beautifully on the 3000.</p>



<p><em>The low end on the MPC 3000 is amazing.</em></p>



<p>The MPC 3000 is very bottom heavy and thick in sound. Roger Linn has talked about how they tried to make it sound like a tape machine. And it clearly does. You can drive this machine extremely hot and loud without ever losing any bottom end.</p>



<p>You can’t really get a computer or any DAW to sound like an MPC 3000. Some claim its a matter of boosting the low end, and cutting some of the high end frequencies to match the sound of the 3000. This is simply false. There are much more nuances happening that have yet to be achieved on a computer… mostly the digitial to analog conversion. The DAC on the MPC 3000 is extremely unique. It’s a machine and it sounds like a machine, in a good way. In the best way possible.</p>



<p><strong>The Workflow</strong></p>



<p>The workflow is unmatched. It’s minimal, but it also gives you the proper buttons for only the functions and screens that you need. </p>



<p>The addition of a number pad is brilliant and is extremely useful allowing …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://audiojive.com/akai-mpc-3000/">https://audiojive.com/akai-mpc-3000/</a></em></p>]]>
            </description>
            <link>https://audiojive.com/akai-mpc-3000/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24177626</guid>
            <pubDate>Sun, 16 Aug 2020 13:33:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Do I Need Kubernetes?]]>
            </title>
            <description>
<![CDATA[
Score 191 | Comments 156 (<a href="https://news.ycombinator.com/item?id=24177469">thread link</a>) | @mocko
<br/>
August 16, 2020 | https://mbird.biz/writing/do-i-need-kubernetes.html | <a href="https://web.archive.org/web/*/https://mbird.biz/writing/do-i-need-kubernetes.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <p>A question I often hear from teams - both new and established - is “should we host our stack on <a href="https://kubernetes.io/">Kubernetes</a>?”.  Given all the buzz it gets in the tech world a lot of people assume&nbsp;so.</p>
<p>I’ve been working with k8s for several years - often with very powerful and complex platforms - and I think the truth is more&nbsp;nuanced.</p>
<p>Here’s my attempt at untangling that decision.  It’s geared toward startups and self-sufficient teams in wider organisations with responsibility for hosting their own products.  It might also have value to people in more traditional <span>IT</span> departments at larger&nbsp;organisations.</p>
<h3>How Can it Help&nbsp;Me?</h3>
<p>Kubernetes isn’t just a 2018-era buzzword.  It’s a robust, highly scalable system that allows you to construct application deployments out of well-considered primitives (<code>Pod</code>, <code>Service</code>, <code>Ingress</code> etc) then does its damnedest to make the reality match.  When applications crash it restarts them.  When whole swathes of underlying machines disappear it tries to replace them.  If you’re running numerous services (probably developed as a microservice architecture) and you’re looking for efficiency, resilience and a good story for deployment it can do a lot for&nbsp;you.</p>
<p>Want a basic degree of resilience in your service? (yes you do) - run <a href="https://kubernetes.io/docs/concepts/workloads/controllers/replicaset/">multiple replicas</a> in your deployment then balance traffic between&nbsp;them.</p>
<p>If your workload is ‘bursty’ (e.g. a lot of <span>API</span> traffic) you could build on this by rigging up <a href="https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/">autoscaling</a> to grow capacity when it’s needed.  This can save you a lot of money - instead of paying for peak capacity all of the time, provision a baseload amount to keep the platform ticking over and bring up more replicas when they’re needed.  And if you can <a href="https://cloud.google.com/kubernetes-engine/docs/concepts/custom-and-external-metrics">import the queue length</a> into your system autoscaling works for queue-based workloads&nbsp;too.</p>
<p>Worried about your code breaking?  Configure liveness/readiness <a href="https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/">probes</a> and Kubernetes will automatically restart your services when they fail.  Likewise for hardware failure - I’ve seen clusters who’ve lost half their nodes keep on trucking like nothing happened.  A well-configured and maintained Kubernetes cluster can be incredibly robust.  If you have the resources you might even try running a <a href="https://netflix.github.io/chaosmonkey/">chaos-monkey</a>-like <a href="https://www.gremlin.com/chaos-monkey/chaos-monkey-alternatives/kubernetes/">tool</a> to make certain your stack will tolerate regular&nbsp;failures.</p>
<p>Kubernetes has excellent features for integrating with your <span>CI</span> workflow.  The most common pattern I see for this is a build (ideally standardised across all your projects) that pushes an image to a Docker registry then kicks your k8s cluster to load it.  Depending on taste that can be done by modifying the deployment to pull a new tag, or pointing the tag to the new image and triggering k8s to reload all pods.  In most cases (migrations ruin everything) deployment can be fully automated: if you trust your tests and feature flags it can be 100% automatic (aka <a href="https://www.continuousdelivery.com/">Continuous Delivery</a>); for the less brave a manual approval step after the build eases the pain.  Either way your developers should be able to release most builds to the cluster without any help from Kubernetes&nbsp;specialists.</p>
<p>In a similar vein to <span>CI</span> it can help you standardise logging and monitoring for your applications.  Doing this is by no means unique to Kubernetes, but having a single cluster-wide system that gathers together data about all your services in the same place can greatly ease the pain of debugging.  I’ve seen particularly good results come from using <a href="https://github.com/fluent/fluentd-kubernetes-daemonset">fluentd</a> to pipe json-structured logging output from applications into <a href="https://aws.amazon.com/cloudwatch/"><span>AWS</span> CloudWatch</a> and query it through <a href="https://docs.aws.amazon.com/AmazonCloudWatch/latest/logs/AnalyzingLogData.html">Insights</a>.</p>
<p>Finally it can do a great deal to increase efficiency - both at the hosting layer (i.e. jamming as many applications onto those expensive <span>EC2</span> instances as possible) and also reducing the time your developers need to spend deploying software.  Humans cost more than computers so for most organisations the second of these will be the biggest win.  But Kubernetes isn’t magic - I’ve seen some beautiful, efficient clusters and some total gas guzzlers.  <em>You’ll only save money with Kubernetes if you invest in using it&nbsp;correctly.</em></p>
<h3>Where Does Kubernetes&nbsp;Shine?</h3>
<p>First of all think about your workload.  What kind of applications do you need to run?  How do they talk to each other and the outside world?  From experience I’d say the following attributes make your stack a good&nbsp;fit:</p>
<ul>
<li>Broadly speaking have you followed a microservice architecture?  There’s little value in Kubernetes if your world only has one application.  You’ll need to <a href="https://docs.docker.com/engine/examples/">Dockerize</a> your applications to deploy them to k8s; doing this from day 1 of any project is a good way to make yourself think about the boundaries between&nbsp;services.</li>
<li>Are your services exposed to each other and the outside world via <span>HTTP</span>(s) (probably yes, it’s 2020)?  This will fit k8s’ model nicely and you can use one of the normal <a href="https://github.com/kubernetes/ingress-nginx">ingress controllers</a> to front&nbsp;them.</li>
<li>Are your applications suitable to be load balanced?  No local state (use PostgreSQL / Redis / whatever for that), communication over known endpoints, fast startup/shutdown.  That isn’t to say you can’t keep shortlived state like a Redis cache in your cluster but for many cases you’d do better to use the boxed services a cloud provider&nbsp;offers.</li>
<li>Kubernetes is also well suited to headless applications like batch processing (through its <code>Job</code> <a href="https://kubernetes.io/docs/concepts/workloads/controllers/job/">controller</a>) and long-lived&nbsp;queue-consumers.</li>
<li>Is memory (and to a lesser extent <span>CPU</span>) usage predictable?  Kubernetes will try to host your applications on the same physical machines, so if one of them goes haywire and consumes all the <span>RAM</span> other workloads may be randomly killed.  In my experience this is the single biggest source of instability on Kubernetes clusters.  If you understand the resource usage of your applications you can declare a <code>resources.requests</code> and <code>resources.limits</code> to guarantee they’ll always get the memory they need and won’t be bad&nbsp;neighbours.</li>
</ul>
<p>Conversely here are a few kinds of workload I <em>don’t</em> think you should use it&nbsp;for:</p>
<ul>
<li>Static websites.  Typically you’d do this by baking your content into an <a href="https://hub.docker.com/_/nginx/">Nginx</a>-derived image and exposing it via your cluster’s ingress controller.  That’s a terrible way to host static content: all those little copies of Nginx need to be maintained, it’s inefficient and far less resilient / performant than it could be at the network level.  Sure you could stick it behind a <span>CDN</span> but if you’re doing that, why not have a cloud service host the content as&nbsp;well?</li>
<li>Hosting untrusted code.  That could mean applications supplied by your customers or third party code with a history of security problems, e.g. Wordpress or a dodgy library from <span>NPM</span>.  By default Kubernetes’ features for isolating workloads aren’t great.  You can add things like <a href="https://www.projectcalico.org/">Calico</a> to control network access but it’s easy to screw up and your security model is always going to be 100% dependent on the container runtime.  The default for this (Docker, based on <a href="https://en.wikipedia.org/wiki/Cgroups">Linux cgroups</a>) offers a huge attack surface to compromised applications: if a codebase your cluster is running gets hacked an attacker will not find it hard to escalate their access to the rest of the cluster.  Interesting work is being doing on alternatives to cgroups (e.g. <a href="https://katacontainers.io/">Kata Containers</a>) but it’s not yet mainstream enough to recommend to the average&nbsp;user.</li>
</ul>
<p>If your workload isn’t a good fit you may still have options for shoehorning it into Kubernetes (e.g. <a href="https://kubernetes.io/docs/concepts/storage/volumes/">volumes</a> can be used for long-lived state), but expect to spend a lot of engineering time working around the problems.  A lot of them are bad practices anyhow so your resources time might be better spent designing them out of the stack altogether - they’re only going to hurt you further down the&nbsp;line.</p>
<h3>No Magic&nbsp;Bullet</h3>
<p>Kubernetes isn’t a magic bullet.  It can help to move the complexities of hosting applications into a well-designed layer of their own but it won’t make them go away.  You’re always going to have to secure and maintain your&nbsp;platform.</p>
<p>To make a cluster useful for the average workload a menagerie of add-ons will be required.  Some of them almost everyone uses, others are somewhat niche.  Examples include (the Nginx <a href="https://github.com/kubernetes/ingress-nginx">ingress controller</a>, <a href="https://github.com/jetstack/cert-manager">cert-manager</a> and <a href="https://github.com/kubernetes/autoscaler/tree/master/cluster-autoscaler">cluster-autoscaler</a> to add extra nodes when you don’t have enough capacity.  Having a bespoke set of software operating key features of the environment makes your cluster a unique snowflake and it needs to be managed as such.  Also they need to be updated regularly and can sometimes be of questionable quality.  Configuration management tools like <a href="https://helm.sh/">Helm</a> or <a href="https://registry.terraform.io/providers/hashicorp/kubernetes/latest/docs">Terraform</a> are nigh-on mandatory: tinker with a cluster by hand at your peril, absent a declarative setup you’ll never be able to spin up another in exactly the same way.  I’ve seen this lead to no end of problems when operating or replacing more mature&nbsp;clusters.</p>
<p>When running any nontrivial stack on Kubernetes a degree of curation is always going to be required.  Letting anybody deploy whatever they like, however they like to your cluster can only lead to chaos.  You’ll end up with mess of inconsistently named applications scattered across dozens (or worse, one) namespaces with nobody knowing how they fit together.  Congratulations: you took your old spaghetti infrastructure and replaced it with a new flavour of spaghetti infrastructure, just served on a cooler kind of&nbsp;plate.</p>
<p>The most successful Kubernetes implementations I’ve seen are those where infrastructure specialist(s) work with developers to make sure workloads are well-configured, standardised, protected from one another and have defined patterns of communication.  They’ll handle the initial setup of an application on an infrastructure, hopefully wired up to a build/release system so dev teams can ship new versions of the code without help.  In a lot of ways this mirrors the wider culture of your organisation - if engineering is a chaotic free-for-all of bad communication and ill-defined responsibilities your hosting environment will mirror it.  At best this leads to unreliability; at worst an unreliable, unmaintainable, expensive&nbsp;mess.</p>
<h3>Cost of&nbsp;Ownership</h3>
<p>If you’re running applications on a large scale …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://mbird.biz/writing/do-i-need-kubernetes.html">https://mbird.biz/writing/do-i-need-kubernetes.html</a></em></p>]]>
            </description>
            <link>https://mbird.biz/writing/do-i-need-kubernetes.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24177469</guid>
            <pubDate>Sun, 16 Aug 2020 13:10:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A layman's guide to understanding the Cloud]]>
            </title>
            <description>
<![CDATA[
Score 46 | Comments 9 (<a href="https://news.ycombinator.com/item?id=24176918">thread link</a>) | @kislayverma
<br/>
August 16, 2020 | https://kislayverma.com/for-the-layman/for-the-layman-ep-2-what-is-the-cloud/ | <a href="https://web.archive.org/web/*/https://kislayverma.com/for-the-layman/for-the-layman-ep-2-what-is-the-cloud/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>

<div>
<p>Hello everyone!</p>
<p>In this episode of the “<a href="https://kislayverma.com/category/for-the-layman/">For the layman</a>” series, I am going to discuss what the “cloud” is. We’ve all heard of iCloud, AWS, cloud computing etc, and understand the power of their ubiquitous presence. Let’s understand the history and the mechanics of the Cloud a little more.</p>
<hr>
<p><span><strong>tl;dr –</strong> The Cloud is Uber for computers. It is made up of hundreds of thousands of computers (aka servers) that users can rent out to run their software in exchange for a regular fee – mostly based on usage. Cloud companies take care of running the hardware with all kinds of best practices so that software developers and software development companies don’t have to and can focus on their core work.</span></p>
<hr>
<p>Have you ever seen one of those high intensity surgery scenes in movies where the doctor keeps shouting at the nurses “Give me a clamp” or “Give me 5cc of &lt;insert medicine name&gt;”? For the longest time, software development used to be like (only less high stakes for the most part). Programmers would write awesome <a href="https://a16z.com/2011/08/20/why-software-is-eating-the-world/">applications that could eat the world</a>. But running these awesome apps required big computers. So while the programmer finished writing the last line of code or polishing the last bit of documentation (HAHAHAHA), she would start screaming, “Give me a big computer”.</p>
<div><figure><img loading="lazy" src="https://kislayverma.com/wp-content/uploads/2020/08/give-me-a-big-computer-1024x637.jpg" alt="" width="506" height="314" srcset="https://kislayverma.com/wp-content/uploads/2020/08/give-me-a-big-computer-1024x637.jpg 1024w, https://kislayverma.com/wp-content/uploads/2020/08/give-me-a-big-computer-300x187.jpg 300w, https://kislayverma.com/wp-content/uploads/2020/08/give-me-a-big-computer-768x478.jpg 768w, https://kislayverma.com/wp-content/uploads/2020/08/give-me-a-big-computer-1536x955.jpg 1536w, https://kislayverma.com/wp-content/uploads/2020/08/give-me-a-big-computer-1142x706.jpg 1142w, https://kislayverma.com/wp-content/uploads/2020/08/give-me-a-big-computer-1070x665.jpg 1070w, https://kislayverma.com/wp-content/uploads/2020/08/give-me-a-big-computer.jpg 1603w" sizes="(max-width: 506px) 100vw, 506px"></figure></div>
<p>For many years, this meant going out and buying the computer, plugging it in, installing a bazillion things on it, and forever making sure no one pulled out the plug by mistake. I’m not even getting into the bureaucracy of procuring said computer. As companies started churning out more and more software, this got to be a real problem. With the rise of the cloud, today the application developer could herself set up a new computer with no more than a few clicks of the mouse. No fuss at all. <strong>The cloud has commoditized hardware and the operations around it.</strong></p>
<p>To understand the rise of cloud computing, let’s look a little bit at the history of computers and their use.</p>
<hr>
<p>The first programmable computer was (arguably) the one developed by Alan Turing’s team in Bletchley Park as part of the allied effort at intelligence gathering in WW2. “<strong>Programmable Computer</strong>” means that this was a machine that could be arranged to do any calculation. Configured one way, it could crack the Nazi ENIGMA code. Set up another way, it could compute the <a href="https://www.wired.com/2016/03/six-things-probably-didnt-know-pi/">value of Pi</a> to the umpy-umpth decimal.&nbsp;</p>
<p>This is remarkable by itself because most machines now or since do only one thing. A screwdriver, a bulldozer, an airplane, all of them do exactly one thing. Even the “swiss knife” is a collection of many machines, each for one purpose. So this “programmable computer” was a breakthrough in its own right because you could get it to do anything by programming it in different ways.</p>
<p>Anyhow, with a dazzling array of innovations in hardware and computer science, it came to be that computers became commonplace. They could be found in people’s homes, and what we know today as Silicon Valley was beginning to take shape. However, access to computers at the scale at which this new computing revolution wanted it was still not easy. You could easily buy a computer for your home or office, but buying 50 computers was still a pain. Marc Randolph recounts the story from the launch day of Netflix in his book <a href="https://www.amazon.in/gp/product/B07QRVWBX2?ie=UTF8&amp;tag=kislayverma-21&amp;camp=3638&amp;linkCode=xm2&amp;creativeASIN=B07QRVWBX2">That will never work</a> about how his team were constantly rushing out to buy more computers from a neighbourhood shop because of the unexpectedly large number of people visiting the website.</p>
<p>Since this buy-on-demand model did not work very well, software companies started buying and keeping computers in their office (this is still done widely and is called <strong>on-premise/on-prem</strong>). IT teams would set up the computers, power system, air conditioning, cable layouts, failsafes etc in some designated area in the office. This meant that the company always had a buffer stock of computing power at hand. The cost of this was the capital tied up in all the servers whether being used or not.</p>
<div><figure><img loading="lazy" src="https://kislayverma.com/wp-content/uploads/2020/08/on-prem-deployments-1013x1024.jpg" alt="" width="514" height="519" srcset="https://kislayverma.com/wp-content/uploads/2020/08/on-prem-deployments-1013x1024.jpg 1013w, https://kislayverma.com/wp-content/uploads/2020/08/on-prem-deployments-297x300.jpg 297w, https://kislayverma.com/wp-content/uploads/2020/08/on-prem-deployments-150x150.jpg 150w, https://kislayverma.com/wp-content/uploads/2020/08/on-prem-deployments-768x776.jpg 768w, https://kislayverma.com/wp-content/uploads/2020/08/on-prem-deployments-1070x1081.jpg 1070w, https://kislayverma.com/wp-content/uploads/2020/08/on-prem-deployments.jpg 1233w" sizes="(max-width: 514px) 100vw, 514px"></figure></div>
<p>And you know what the sneaky software developers did (and have been doing since)? They found out that getting computers wouldn’t be so much of a pain anymore, so they started churning out even more software. Sooo much more of it. Easy supply further fuelled the hunger for computational resources.</p>
<div>
<div>
<h4>Support this blog on Patreon</h4>

</div>
<div>
<div><figure><a href="https://www.patreon.com/bePatron?u=29760145"><img loading="lazy" src="http://167.71.230.226/wp-content/uploads/2020/08/Digital-Patreon-Logo_FieryCoral-1024x1024.png" alt="" width="100" height="100" srcset="https://kislayverma.com/wp-content/uploads/2020/08/Digital-Patreon-Logo_FieryCoral-1024x1024.png 1024w, https://kislayverma.com/wp-content/uploads/2020/08/Digital-Patreon-Logo_FieryCoral-300x300.png 300w, https://kislayverma.com/wp-content/uploads/2020/08/Digital-Patreon-Logo_FieryCoral-150x150.png 150w, https://kislayverma.com/wp-content/uploads/2020/08/Digital-Patreon-Logo_FieryCoral-768x768.png 768w, https://kislayverma.com/wp-content/uploads/2020/08/Digital-Patreon-Logo_FieryCoral.png 1080w" sizes="(max-width: 100px) 100vw, 100px"></a></figure></div>
</div>
</div>

<p>The other problem for companies was that off-the-shelf computers came in certain specific sizes. Roughly speaking, <strong>a computer is made up of storage (Hard disk), computing power (CPU cores), memory (RAM) and the network (LAN/Internet)</strong>. But in the new digital age, all kinds of programs were being written which demanded each of these in different combinations. Some wanted a lot of network but didn’t do much computing (Netflix, Zoom), some stored a lot of data but didn’t have to be fast (data backup systems), and so on.</p>
<p>Most companies couldn’t afford to keep all combinations of such machines at hand. It was too expensive to buy and they would have had to keep a team of engineers for this alone. So some smart folks at IBM, the premier computing company of its time, came up with the idea of <strong>Virtualization</strong>. Virtualization allowed us to hide multiple computers and all their resources behind a curtain and think in terms of their aggregate resources. E.g. Ten 4 core computers with 8 GB RAM and 256 GB storage each became a collection of 40 cores, 80 GB RAM, and 2560GB of storage which could be parcelled out into “<strong>virtual machines</strong>” as per the programmer’s requirement. e.g. All of the above mentioned resources could be combined to make 2 huge virtual machines (aka VMs) of 20 cores, 40 GB RAM, and 1280GB storage. Wide adoption of virtualization has since hidden the actual computers (aka <strong>bare metal</strong>) from the programmers view.</p>
<div><figure><img loading="lazy" src="https://kislayverma.com/wp-content/uploads/2020/08/virtualization-1024x753.jpg" alt="" width="460" height="338" srcset="https://kislayverma.com/wp-content/uploads/2020/08/virtualization-1024x753.jpg 1024w, https://kislayverma.com/wp-content/uploads/2020/08/virtualization-300x220.jpg 300w, https://kislayverma.com/wp-content/uploads/2020/08/virtualization-768x564.jpg 768w, https://kislayverma.com/wp-content/uploads/2020/08/virtualization-1536x1129.jpg 1536w, https://kislayverma.com/wp-content/uploads/2020/08/virtualization-1070x786.jpg 1070w, https://kislayverma.com/wp-content/uploads/2020/08/virtualization.jpg 1664w" sizes="(max-width: 460px) 100vw, 460px"></figure></div>
<p>While virtualization gave organization’s huge leeway in terms of deploying computational resources efficiently, it also introduced a huge “<strong>Virtualization Layer</strong>” to the already complex stack of hundreds, sometimes thousands of computers they were running. Some companies were reaching the stage where they couldn’t house all their servers in their offices and had to open up <strong>data-centers</strong> (separate facilities for storing and operating all the servers). This was obviously a huge capital investment and distraction for these companies. They didn’t want to be in the business of running hardware, but they had no choice.</p>
<p>Around the dot com crash of the 90s, some companies (especially Amazon) had a lot of computers and expertise in operating them, and were looking to make some money. They realized that with the internet potentially connecting all computers of the world to each other, they could not only rent out their servers to people who needed to use them, but also sell their expertise in operating them reliably as a service with the hardware. This was the origin of the <strong>cloud</strong> (or <strong>cloud computing</strong> or <strong>cloud services</strong>) as we know it today.</p>
<p>The users of the cloud (the renters of the servers) essentially reach out into the Cloud to lay their hands on mostly Virtual Machines as per their computing needs without worrying about where they kept, which brand they are, and whether they are connected to the power supply or not. Cloud companies like AWS, Azure, GCP, Digital Ocean (where this blog is hosted) take care of all that so we can just focus on running the cool Facemash applications we have written. Users pay an hourly, or monthly, or some other sort of recurring charge based on their usage of these machines. No more scrambling around to buy computers, connect them etc etc. With heavy automation, today even individual developers can manage more computing power than entire teams not too long ago.</p>
<div><figure><img loading="lazy" src="https://kislayverma.com/wp-content/uploads/2020/08/cloud-providers-and-users-923x1024.jpg" alt="" width="434" height="481" srcset="https://kislayverma.com/wp-content/uploads/2020/08/cloud-providers-and-users-923x1024.jpg 923w, https://kislayverma.com/wp-content/uploads/2020/08/cloud-providers-and-users-271x300.jpg 271w, https://kislayverma.com/wp-content/uploads/2020/08/cloud-providers-and-users-768x852.jpg 768w, https://kislayverma.com/wp-content/uploads/2020/08/cloud-providers-and-users-1070x1187.jpg 1070w, https://kislayverma.com/wp-content/uploads/2020/08/cloud-providers-and-users.jpg 1359w" sizes="(max-width: 434px) 100vw, 434px"></figure></div>
<p>In the last decade, this process of cloudification has gone beyond hardware and even into the realm of software. Most cloud providers have “<strong>managed services</strong>” under which they provide well set up and maintained installations of the most commonly used software already running. We don’t even have to set up this software now – we just rent a running version of it for our own purposes -as if it was a physical thing. This is a huge blessing for startups since some of the most commonly used types of software like databases, firewalls, caches, message queues are available at only a few clicks notice and don’t have to be installed and operated. The barrier to entry in the software world has never been lower with more and more of the grunt work being moved off to the cloud.</p>
<p>Think of cloud hardware and software in terms of the “<a href="https://kislayverma.com/for-the-layman/for-the-layman-ep-1-what-is-a-distributed-system/">distributed car</a>” I had discussed in a previous article. The engine, the wheels, the fuel injection system etc are all in the cloud now, and you can have as many of them as you can pay for. As the car maker, you can now focus on your unique value addition – the branding, the interiors and leather seats, the new electric battery that only you hold the patent to, and so on.</p>
<p>Today, the cloud is part of the internet’s infrastructure like highways or schools for the real world. Most people want highways and schools as a means to an end. They don’t want to have to build them themselves. The cloud plays the same role for anyone that wants to build software. The result – omnipresent software and huge cloud provider bills 🙂</p>
<p><strong>Read Next</strong> – More articles on <a href="https://kislayverma.com/tag/distributed-systems/">distributed systems</a>.</p>

</div>
</article></div>]]>
            </description>
            <link>https://kislayverma.com/for-the-layman/for-the-layman-ep-2-what-is-the-cloud/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24176918</guid>
            <pubDate>Sun, 16 Aug 2020 11:27:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Web by Google (TM)]]>
            </title>
            <description>
<![CDATA[
Score 672 | Comments 461 (<a href="https://news.ycombinator.com/item?id=24176898">thread link</a>) | @alangibson
<br/>
August 16, 2020 | https://landshark.io/2020/08/16/web-by-google.html | <a href="https://web.archive.org/web/*/https://landshark.io/2020/08/16/web-by-google.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
	<p>Looking at Mozilla’s finances, it’s reasonable to conclude that Google is keeping them on life support to keep the anti-trust hounds at bay. Mozilla’s deal with Google will account for at least 70% of their revenues going forward. That’s over $400 million to be the default search provider in 4% of browsers. For 1 year. I’ll bet my next paycheck that Google reupped this rather generous agreement to avoid a repeat of Microsoft’s troubles over an Internet Explorer monopoly. My guess is that Google will decide it’s in their interest to pull the plug right around the time this latest wave of anti-trust talk blows over.</p>

<p>With the troubles at Mozilla, Google is one step closer to replicating the WeChat and Facebook walled-garden model on the Web. A quick survey a the field of play shows just how far Google has come in capturing the once open Web.</p>

<h2 id="browser-war-is-over">(Browser) War is over</h2>

<p>Chrome’s ability to dictate web standards will only get stronger over time. Safari and Firefox have been able to apply some shame to Chrome on things like disabling third-party cookies, but soon it’ll just be Apple left with a voice.</p>

<p>But Google doesn’t even need Chrome to dictate standards since it controls the Web’s front door. AMP, a technology no one asked for, is now on over 70% of all marketing websites for no other reason than Google said so.</p>

<p>And let’s not forget that most people now access the web via mobile devices, 75% of which run Google’s Android.</p>

<h2 id="original-sins">Original Sins</h2>

<p>Two deficiencies have determined the course the Web has taken: lack of native search and lack of native payments.</p>

<p>Lacking native distributed search allowed Google to grab a monopoly position as the entry point to the web. The Web’s orignal architects were off base on hyperlinks; it turns out people just want to skip right to the answer they’re looking for. There was once the beginnings of an alternative in public bookmarking sites, but social networks came and sucked all the air out of that space.</p>

<p>Lack of a safe and easy way of exchanging funds was a big factor in advertising becoming the dominant business model on the Web. No-charge services became the norm because, for a long time, there was no reasonable way to pay for them. Enter advertising to fill the void. I think it’s safe to say that Google’s AdWords is the dominant advertising platform on the open Web, which means it holds a commanding position in the Web’s finances.</p>

<p>I’m also going to throw in an honorable mention to poor native video support (it is hyper_text_ after all). It’s beating a dead horse to point out that Google also serves up the vast majority of videos streamed on the Web.</p>

<h2 id="so-then">So then…</h2>

<p>So Google controls the Web’s search and video infrastructure. It can and does dictate standards and media formats. It also controls a huge chunk of the revenues available when publishing and selling on the Web. It even controls the operating system and browser through which most people interact with it.</p>

<p>Google’s capture of the Web is a <em>fait accompli</em>. Only legislation will keep the World Wide Web from finally becoming Web by Google (TM).</p>


</div></div>]]>
            </description>
            <link>https://landshark.io/2020/08/16/web-by-google.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24176898</guid>
            <pubDate>Sun, 16 Aug 2020 11:23:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What I've learned about scaling OSPF in Datacenters]]>
            </title>
            <description>
<![CDATA[
Score 68 | Comments 14 (<a href="https://news.ycombinator.com/item?id=24176872">thread link</a>) | @signa11
<br/>
August 16, 2020 | https://elegantnetwork.github.io/posts/What-Ive-learned-about-OSPF/ | <a href="https://web.archive.org/web/*/https://elegantnetwork.github.io/posts/What-Ive-learned-about-OSPF/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <div>
	
	<h4>The wisdom is that BGP is the only Datacenter protocol, but is it? Do we know?</h4>
	<p>
		Published on Aug 14, 2020 by Justin Pietsch
	</p>
	<ul></ul>
</div>
</div><div>
    <div>
      <div>
          <p>I worked at Amazon for 17 years as a network engineer. Now I’m out of Amazon and looking at the industry, I’m learning new things. <strong>One of the things I’ve learned recently is that OSPF shouldn’t be used for Clos leaf-spine networks because of scale.</strong> I’ve heard that it can’t keep up with the size and scale of the modern datacenter networks. <a href="https://www.juniper.net/documentation/en_US/release-independent/solutions/topics/task/configuration/ip-fabric-underlay-cloud-dc-configuring.html">Juniper IP Fabric Underlay Network Design and Implementation</a> is an example of the recommendation.  <a href="https://tools.ietf.org/html/rfc7938">https://tools.ietf.org/html/rfc7938</a> is what as used as the reference for using eBGP to be the routing protocol inside of large Clos networks.</p>

<p><strong>This is a shock to me</strong> since we built large OSPF Clos networks a decade ago. We built networks this way with hundreds of routers (even thousands) speaking OSPF. I’m not saying it is easy or that we didn’t have to understand OSPF well; If you don’t design it well, you get a flooding disaster. But if you do set it up right, it works really well. It converges quickly and doesn’t collapse under failure. The key thing is to be sure you understand how flooding works and you focus on areas and summarization. There are different things you have to be aware of when you are designing a Clos network with BGP vs OSPF. With BGP you have to be figure out how to mitigate path hunting. With OSPF need to work on how to avoid congestion collapse.</p>

<p>There is also work on building new protocols for these large Clos or Clos-like networks, such as <a href="https://datatracker.ietf.org/wg/rift/documents/">https://datatracker.ietf.org/wg/rift/documents/</a>. I don’t understand why OSPF or ISIS isn’t good enough so I don’t understand why these are necessary. There <a href="https://pc.nanog.org/static/published/meetings/NANOG74/1763/20181003_Martin_Routing_In_Dense_v1.pdf">are some good ideas in RIFT</a>, I’m just haven’t seen a reason to use it.</p>

<p>When we did this we were using CPUs from 2003 and we were using a lesser known OSPF stack. It’s OSPF implementation was okay, but we were strongly warned away from using their BGP implementation by the developers. <strong>We had to understand and mitigate risk</strong>. We had to test it as well as we could and be very careful in our first deployments. The stack had never been battle tested like this before. We still ran into some scary performance issues but got to work with great software engineers on the protocol stack to work through problems and figure out our scale.</p>

<p>Others agree with me, <a href="https://www.youtube.com/watch?v=Qmvg2mnbcPg">https://www.youtube.com/watch?v=Qmvg2mnbcPg</a>, even though they are mostly focusing on smaller networks than I was working on. But either way, OSPF can be made to work just fine on very large (or small) Clos networks.</p>

<p>As an example of the scale, this is a generic 24 port 3-tier Clos. It is possible to make OSPF work on this. This is smaller than what we were working on in 2012.
<img src="https://elegantnetwork.github.io/assets/images/24port-3tier-clos-resize.png" alt="24 port 3-tier clos"></p>

<p>To understand and then mitigate the risks an unknown OSPF stack, at scale, is why I started building a configuration management system and started <a href="https://elegantnetwork.github.io/posts/Network-Validation-with-Vagrant/">simulating our network design</a>. We needed to understand how any OSPF protocol stack would work. Could we make the protocol scale at all? We needed to see what would actually happen with a real OSPF implementation. <strong>I cannot stress enough how important this simulation was.</strong> We did not understand the problem of flooding and we did not understand the solution until we had tried it out in simulation.</p>

<p>Before that, though, we spent a lot of time on white boards arguing about topology and OSPF. <strong>I think whiteboards are the most important tool for network design</strong> currently available, which makes me sad. I wish that wasn’t true, I want much better tools. I can’t even tell you the number of disasters averted by 2-3 great network engineers arguing over a whiteboard. This works really well, but there are important reasons it’s not good enough. One is that for many of these discussions, it’s extremely hard to get data to make the decisions. In this case, a comparison of convergence time and failure detection in a 3-tier Clos with eBGP, iBGP, and OSPF should be required, but we didn’t have that capability.</p>

<p>In a dense mesh-like network such as a Clos network, the concerns around OSPF swirled around four main issues: the effect of flooding, the size of the link state database, the speed of SPF calculations, and the ability for OSPF to carry a large number of prefixes. We were concerned about OSPF scaling w.r.t. its flooding and it’s the flooding that is expensive with a Link State Database protocol, not the Shortest Path First (SPF) calculations. Which means you have to be very careful about what is flooded, what are the areas, and how things are summarized. I didn’t understand this until I had a simulation and I could try things out with areas or without, and the effect was dramatic. I think it’s often true that there is a part of a design that you don’t understand, which is one of the big reasons to do simulation. We didn’t have the ability to lab up a network as big as we were going to be building, so the simulation was critical. I can’t even imagine what we would have done without it. Based on the simulation, we created targeted tests for real hardware to understand how it would deal with the scale.</p>

<p>The point of this article is not that OSPF is better than BGP, but that it does work in very large size Clos networks. I’m frustrated that so much of the industry went a direction without great data or analysis, just following one set of opinions and design choices. <strong>I wish there were easy ways for people to be able to design, simulate and test different designs</strong> like this so that they could decide for themselves the tradeoffs they’d like to make, rather than have to rely on some type of industry hype. There needs to be a better way to be able to describe topologies and designs so that it’s really easy to try out different ideas.</p>

<p>If you have other considerations, such as you want to run IPv6, or EVPN, a single instance of eBGP such as the one popularized by the open source routing suite, FRR, maybe the simplest or elegant. But with proper design, scale is not the reason to use BGP over OSPF. If you are running a small Clos network and don’t have IPv6 or EVPN, OSPF is more straightforward and generally faster, as was the common practice before the advent of BGP in the data center.</p>

<p>No matter what, you need to understand the choices that you are making and understand the tradeoffs. This is hard to do, and especially hard in networking because we lack design patterns and good tools to help us understand the implications of our choices.</p>

<p>If anybody knows about tools or design patterns or even somebody who’s actually compared OSPF vs BGP in Clos networks with data, I’d love to hear about it.</p>

      </div>

        <!-- Configure Disqus -->
        
        </div>
  </div></div>]]>
            </description>
            <link>https://elegantnetwork.github.io/posts/What-Ive-learned-about-OSPF/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24176872</guid>
            <pubDate>Sun, 16 Aug 2020 11:16:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Python 3.8 Makes me Sad Again]]>
            </title>
            <description>
<![CDATA[
Score 23 | Comments 41 (<a href="https://news.ycombinator.com/item?id=24176823">thread link</a>) | @ilyash
<br/>
August 16, 2020 | https://ilya-sher.org/2020/08/16/python-3-8-makes-me-sad-again/ | <a href="https://web.archive.org/web/*/https://ilya-sher.org/2020/08/16/python-3-8-makes-me-sad-again/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-7193">
		<!-- .entry-header -->

	<div>
					
<p>Looking at some “exciting” <a href="https://docs.python.org/3.8/whatsnew/3.8.html">features landing in Python 3.8</a>, I’m still disappointed and frustrated by the language… like by quite a few other languages.</p>



<div><figure><img data-attachment-id="7204" data-permalink="https://ilya-sher.org/chimpanzee-978809_640/" data-orig-file="https://ilyasherdotorg.files.wordpress.com/2020/08/chimpanzee-978809_640.jpg" data-orig-size="640,640" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;5.6&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;NIKON D7000&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;200&quot;,&quot;iso&quot;:&quot;400&quot;,&quot;shutter_speed&quot;:&quot;0.0015625&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="chimpanzee-978809_640" data-image-description="" data-medium-file="https://ilyasherdotorg.files.wordpress.com/2020/08/chimpanzee-978809_640.jpg?w=300" data-large-file="https://ilyasherdotorg.files.wordpress.com/2020/08/chimpanzee-978809_640.jpg?w=640" src="https://ilyasherdotorg.files.wordpress.com/2020/08/chimpanzee-978809_640.jpg?w=640" alt="" srcset="https://ilyasherdotorg.files.wordpress.com/2020/08/chimpanzee-978809_640.jpg 640w, https://ilyasherdotorg.files.wordpress.com/2020/08/chimpanzee-978809_640.jpg?w=150 150w, https://ilyasherdotorg.files.wordpress.com/2020/08/chimpanzee-978809_640.jpg?w=300 300w" sizes="(max-width: 640px) 100vw, 640px"></figure></div>



<p>As an author of another programming language, I can’t stop thinking about how things “should have been done” from my perspective. I want to be explicit here. My perspective is <strong>biased</strong> towards correctness and “WTF are you doing?”. Therefore, take everything here with a appropriate amount of salt.</p>



<p>Yes, not talking about any “positive” changes here.</p>



<h2>Assignment Expressions</h2>



<blockquote><p>There is new syntax <code>:=</code> that assigns values to variables as part of a larger expression.</p></blockquote>



<p>A fix which couldn’t be the best because of previous design decision.</p>



<p>“Somebody” ignored the wisdom of Lisp, which was “everything is an expression and evaluates to a value” (no statements vs expressions), and made assignment a statement in Python years ago. Now this can not be fixed in a straightforward manner. It must be another syntax. Two different syntaxes for almost the same thing which is <code>=</code> for assignment as a statement and <code>:=</code> for expression assignment.</p>



<h2>Positional-only Parameters</h2>



<blockquote><p>There is a new function parameter syntax <code>/</code> to indicate that some function parameters must be specified positionally and cannot be used as keyword arguments:</p></blockquote>



<pre><code>def f(a, b, /, c, d, *, e, f):
    print(a, b, c, d, e, f)</code></pre>



<p>Trying to clean up a mess created by mixing positional and named parameters. Unfortunately I did not give it enough thought at the time and copied parameters handling behaviour from Python. Now <a href="https://ngs-lang.org/">NGS</a> also has the same problem as Python had before 3.8. Hopefully, I will be able to fix it in some more elegant way than Python did.</p>



<h2>LRU cache</h2>



<blockquote><p><a href="https://docs.python.org/3.8/library/functools.html#functools.lru_cache"><code>functools.lru_cache()</code></a> can now be used as a straight decorator rather than as a function returning a decorator. So both of these are now supported</p></blockquote>



<p>OK. Bug fix. But … (functools.py)</p>



<pre><code>    if isinstance(maxsize, int):
        # Negative maxsize is treated as 0
        if maxsize &lt; 0:
            maxsize = 0</code></pre>



<p>If you are setting LRU cache size to a negative number, it’s 99% by mistake. In NGS that would be an exception. That’s the approach that causes <code>rm -rf $myfolder/</code> to remove <code>/</code> when <code>myfolder</code> is unset. Note that the <code>maxsize</code> code is not new but it’s still there in Python 3.8. I guess that is another mistake which can not be easily fixed now because that would break “working” code.</p>



<h2>Collections</h2>



<blockquote><p>The <a href="https://docs.python.org/3.8/library/collections.html#collections.somenamedtuple._asdict"><code>_asdict()</code></a> method for <a href="https://docs.python.org/3.8/library/collections.html#collections.namedtuple"><code>collections.namedtuple()</code></a> now returns a <a href="https://docs.python.org/3.8/library/stdtypes.html#dict"><code>dict</code></a> instead of a <a href="https://docs.python.org/3.8/library/collections.html#collections.OrderedDict"><code>collections.OrderedDict</code></a>. This works because regular dicts have guaranteed ordering since Python 3.7</p></blockquote>



<p>OK. Everybody had the mistake of making maps unordered: Perl, Ruby, Python.</p>



<ol><li>Ruby <a href="https://www.igvita.com/2009/02/04/ruby-19-internals-ordered-hash/">fixed that with the release of version 1.9</a> in 2008 (according to the post).</li><li>Python <a href="https://www.python.org/downloads/release/python-370/">fixed that with the release of version 3.7</a> in 2018 (which I take as 10 years of “f*ck you, the developer”).</li><li>Perl <a href="https://perldoc.perl.org/functions/keys.html">keeps using unordered maps according to documentation</a>.</li><li>Same for Raku, again according to <a href="https://docs.raku.org/language/hashmap">the documentation</a>.</li></ol>



<p>NGS had ordered maps from the start but that’s not a fair comparison because NGS project started in 2013, when the mistake was already understood.</p>



<hr>



<p>How all that helps you, the reader? I encourage deeper thinking about the choice of programming languages that you use. From my perspective, all languages suck, while NGS aims to suck less than the rest for the intended <a href="https://github.com/ngs-lang/ngs/wiki/Use-Cases">use cases</a> (tl;dr – for DevOps scripting).</p>



<hr>



<h2>Update 2020-08-16</h2>



<p>Discussions:</p>



<ol><li><a href="https://news.ycombinator.com/item?id=24176823">https://news.ycombinator.com/item?id=24176823</a></li><li><a href="https://lobste.rs/s/rgcgjz/python_3_8_makes_me_sad_again">https://lobste.rs/s/rgcgjz/python_3_8_makes_me_sad_again</a></li></ol>



<h2>Update 2020-08-17</h2>



<p>It looks like the article above needs some clarification about my perspective: background, what I am doing and why.</p>



<h3>TL;DR</h3>



<p>The main points of the article are:</p>



<ol><li>Everything still sucks, including Python. By sucks I mean does not fit well with the tasks I need to do neither aligned with how I think about these tasks.</li><li>I am trying to help the situation and the industry by developing my own programming language</li></ol>



<h3>Background about my Thinking</h3>



<p>In general, I’m amazed with how bad the overall state of programming is. That includes:</p>



<ol><li>All programming languages that I know including my own NGS. This is aggravated by inability to fix anything properly for any language with substantial amount of code written in it because you will be breaking existing code. And if you do break, you get the shitstorm like with Python 3 or Perl 6 (Raku).</li><li><a href="https://github.com/MohGovIL/hamagen-react-native/issues/115">Code quality</a> of the programs written in all languages. Most of the code that I have seen is bad. Sometimes even in <a href="https://github.com/MicrosoftDocs/cpp-docs/issues/1929">official examples</a>.</li><li>Quality of available materials, which are sometimes <a href="https://dev.to/ilya_sher_prog/comment/m9oe">plainly wrong</a>.</li><li>Many of existing “Infrastructure as code” solutions, which in most cases follow the same path:<ol><li>Invent  a DSL or use YAML.</li><li>“figure out” later that it’s not powerful enough (by the way there is an elegant solution – a programming language, forgot the name)</li><li>Create pretty ugly programming language on top of a DSL that was intended for data.</li></ol></li></ol>



<p>I am creating new programming language and a shell out of <strong>frustration with current situation, especially with bash and Python</strong>. Why these two? Because that’s what I was and still using to get my tasks done.</p>



<p>Are these languages bad? I don’t think it’s a question with any good answers. <a href="https://ilya-sher.org/2017/10/10/why-i-have-no-favorite-programming-language/">These languages don’t fit the tasks that I’m trying to do</a> nor are aligned with how I think while being apparently one of the best choices available.</p>



<h3>This Article Background</h3>



<ol><li>Seen some post on RSS about new features in Python 3.8.</li><li>Took a look.</li><li>Yep, everything is still f*cked up.</li><li>Wrote a post about it which was not meant to be “deep discussion about Python flaws”.</li></ol>



<p>I was not planning to invest more time in this but here I am trying to clarify.</p>



<h3>And your Language is Better? Really?</h3>



<p>Let’s clarify “better”.  For me, it’s to suck less than the rest for the intended use cases.</p>



<blockquote><p>author really does consider himself a superior language designer than the Python core-dev team</p></blockquote>



<p>( From <a href="https://www.reddit.com/r/Python/comments/iartgp/python_38_makes_me_sad_again/">https://www.reddit.com/r/Python/comments/iartgp/python_38_makes_me_sad_again/</a> )</p>



<p>I consider myself in much easier circumstances:</p>



<ol><li>No substantial amount of code is written in NGS yet.</li><li>I’m starting later and therefore have the advantage of looking at more languages, avoiding bad parts, copying (with adaptation) the good parts.</li><li>NGS targets a niche, it’s not intended to be general purpose language. Choices are clearer and easier when you target a niche.</li><li>The language that I’m creating is almost by definition is more aligned with how I think. Hoping that people out there will benefit from using NGS if it is more aligned with how they think too.</li><li>See also my <a href="https://ilya-sher.org/2016/10/28/creating-a-language-is-easier-now/">Creating a language is easier&nbsp;now</a> (2016) post.</li></ol>



<p>Will I be able to make a “better” language?</p>



<p><strong>From technical perspective</strong>, that’s probable: I am a skilled programmer in several languages and I have languages to look at more than everybody else had before. My disadvantage is not much experience in language design. I’m trying to offset that with thinking hard (<a href="https://github.com/ngs-lang/ngs/wiki#design-documents">about the language</a>, the essence of <a href="https://ilya-sher.org/2019/05/18/on-information-loss-in-software/">what is being expressed</a>, common patterns, etc), looking at other languages and experimenting.</p>



<p><strong>From marketing perspective</strong>, I need to learn a lot. I am aware that “technically better” doesn’t matter as much as I would like to. Without community and users that would be a failed project.</p>



<p>Also don’t forget luck which I might or might not have.</p>



<h3>What if NGS fails?</h3>



<p>I think that the situation today is unbearable. I’m trying to fix it. I feel like I have to, despite the odds. I hope that even if NGS fails to move the industry forward it would be useful to somebody who will attempt that later.</p>
					</div><!-- .entry-content -->

	<!-- .entry-footer -->
</article></div>]]>
            </description>
            <link>https://ilya-sher.org/2020/08/16/python-3-8-makes-me-sad-again/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24176823</guid>
            <pubDate>Sun, 16 Aug 2020 11:04:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Messy Mediterranean]]>
            </title>
            <description>
<![CDATA[
Score 29 | Comments 17 (<a href="https://news.ycombinator.com/item?id=24176329">thread link</a>) | @BerislavLopac
<br/>
August 16, 2020 | https://sovereignlimits.com/blog/the-messy-mediterranean | <a href="https://web.archive.org/web/*/https://sovereignlimits.com/blog/the-messy-mediterranean">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            
<h2>Or, Why is Mediterranean Maritime Sovereignty So Complicated?</h2>



<p>The Mediterranean Sea could almost be considered an inland body of water, except for a small connection to the Atlantic Ocean (only 16 km or 10 miles) between the coasts of Spain and Morocco at the Strait of Gibraltar. The waters of the Mediterranean can be further divided into the Alboran, Libyan, Levantine, Aegean, Ionian, Adriatic, Tyrrhenian, and Balearic Seas. Twenty-three separate States lay claim to the waters of the Mediterranean Sea, and many of these are overlapping or disputed leading to an incredibly complex picture of maritime sovereignty.</p>



<h2>The Established Boundaries</h2>



<p>There are, however, twenty-two established maritime boundaries between the various Mediterranean States. The oldest is between Cyprus and the UK on behalf of its Sovereign Base Areas (SBAs) of Akrotiri and Dhekelia located in the south of the island. Both the land and maritime boundaries between the SBAs and Cyprus were established by the same agreement from which Cyprus gained its independence from the UK on 16 August 1960. The <a href="https://sovereignlimits.com/boundaries/cyprus-united-kingdom-maritime" target="_blank" rel="noreferrer noopener">maritime boundary</a> extends in four separate parts from the various land boundary termini on the coast and delimits the UK’s claimed three nautical mile territorial sea and Cyprus’s 12. The UK ceded all exclusive economic zone (EEZ) claims to Cyprus.</p>



<div><figure><img loading="lazy" width="749" height="1024" src="https://sovereignlimits.com/wp-content/uploads/sites/2/2020/08/Cyprus_UK-Airbases-01-749x1024.png" alt="Map showing the maritime boundary between Cyprus and the UK Sovereign Base Areas of Akrotiri and Dhekelia. " srcset="https://sovereignlimits.com/wp-content/uploads/sites/2/2020/08/Cyprus_UK-Airbases-01-749x1024.png 749w, https://sovereignlimits.com/wp-content/uploads/sites/2/2020/08/Cyprus_UK-Airbases-01-219x300.png 219w, https://sovereignlimits.com/wp-content/uploads/sites/2/2020/08/Cyprus_UK-Airbases-01-44x60.png 44w, https://sovereignlimits.com/wp-content/uploads/sites/2/2020/08/Cyprus_UK-Airbases-01-768x1050.png 768w, https://sovereignlimits.com/wp-content/uploads/sites/2/2020/08/Cyprus_UK-Airbases-01-1123x1536.png 1123w, https://sovereignlimits.com/wp-content/uploads/sites/2/2020/08/Cyprus_UK-Airbases-01-600x821.png 600w, https://sovereignlimits.com/wp-content/uploads/sites/2/2020/08/Cyprus_UK-Airbases-01.png 1496w" sizes="(max-width: 749px) 100vw, 749px"><figcaption><em>The four-part Cyprus–UK maritime boundaries.</em></figcaption></figure></div>



<p>The most recent (as of late July 2020) Mediterranean maritime boundary is between Greece and Italy, signed on 9 June 2020. This new agreement updates a 24 May 1977 Treaty, transforming the already-established 16 point maritime boundary into WGS-84 and confirming its application for the EEZ, in addition to the continental shelf (CS). The 2020 update left the tripoints, with Albania in the north and Libya in the south, undefined. The Italy–Greece boundary is arguably less interesting than the second most recent Mediterranean maritime boundary between Turkey and Libya (signed 27 November 2019). That will be covered in greater depth below.</p>



<div><figure><img loading="lazy" width="749" height="1024" src="https://sovereignlimits.com/wp-content/uploads/sites/2/2019/04/Greece_Italy-01-749x1024.png" alt="A map depicting the maritime boundary between Greece and Italy." srcset="https://sovereignlimits.com/wp-content/uploads/sites/2/2019/04/Greece_Italy-01-749x1024.png 749w, https://sovereignlimits.com/wp-content/uploads/sites/2/2019/04/Greece_Italy-01-219x300.png 219w, https://sovereignlimits.com/wp-content/uploads/sites/2/2019/04/Greece_Italy-01-44x60.png 44w, https://sovereignlimits.com/wp-content/uploads/sites/2/2019/04/Greece_Italy-01-768x1050.png 768w, https://sovereignlimits.com/wp-content/uploads/sites/2/2019/04/Greece_Italy-01-600x821.png 600w, https://sovereignlimits.com/wp-content/uploads/sites/2/2019/04/Greece_Italy-01.png 1123w" sizes="(max-width: 749px) 100vw, 749px"><figcaption><em>Greece and Italy’s original 1977 maritime boundary was updated to WGS-84 in 2020.</em></figcaption></figure></div>



<p>If you’re interested in learning more about the maritime boundary between Greece and Italy, check out our <a href="https://sovereignlimits.com/boundaries/greece-italy" target="_blank" rel="noreferrer noopener">Boundaries</a> page.</p>



<p>Surprise! Greece and Egypt signed a new EEZ boundary Agreement on Thursday, August 6. The details have not yet been released to the public, but both Turkey and Libya have already protested the new boundary.</p>



<p>The shortest established Mediterranean maritime boundary is between <a href="https://sovereignlimits.com/boundaries/italy-slovenia" target="_blank" rel="noreferrer noopener">Italy and Slovenia</a> at 15 M and the longest is between <a href="https://sovereignlimits.com/boundaries/italy-tunisia" target="_blank" rel="noreferrer noopener">Italy and Tunisia</a>, which runs for 528 M.</p>



<p>That leaves about 30 maritime boundaries to be established, some of which are currently being negotiated (Greece and Albania) and some of which have 300 plus years of dispute that will need to be resolved before maritime boundary delimitation can begin (Spain and the UK on behalf of Gibraltar).</p>



<h2>Disputed Maritime Space</h2>



<p>When looking at disputed maritime areas in the Mediterranean, Turkey is the shadow over all of the eastern Sea. Its role in the Cyprus–Northern Cyprus conflict as well as the full extent of maritime disputes with Greece will be discussed in greater detail below. This section is to delve into Turkey’s full set of unilateral maritime claims which were updated in 2019.</p>



<div><figure><img loading="lazy" width="1024" height="576" src="https://sovereignlimits.com/wp-content/uploads/sites/2/2020/08/Turkey_Claims_v2-01-1-1024x576.png" alt="Map showing Turkey's unilateral maritime claim, overlaid with established maritime boundaries and provisional equidistance lines from Sovereign Limits." srcset="https://sovereignlimits.com/wp-content/uploads/sites/2/2020/08/Turkey_Claims_v2-01-1-1024x576.png 1024w, https://sovereignlimits.com/wp-content/uploads/sites/2/2020/08/Turkey_Claims_v2-01-1-300x169.png 300w, https://sovereignlimits.com/wp-content/uploads/sites/2/2020/08/Turkey_Claims_v2-01-1-60x34.png 60w, https://sovereignlimits.com/wp-content/uploads/sites/2/2020/08/Turkey_Claims_v2-01-1-768x432.png 768w, https://sovereignlimits.com/wp-content/uploads/sites/2/2020/08/Turkey_Claims_v2-01-1-1536x865.png 1536w, https://sovereignlimits.com/wp-content/uploads/sites/2/2020/08/Turkey_Claims_v2-01-1-2048x1153.png 2048w, https://sovereignlimits.com/wp-content/uploads/sites/2/2020/08/Turkey_Claims_v2-01-1-600x338.png 600w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption><em>This map depicting extensions of Turkey’s EEZ claims was released by a Turkish diplomat in December 2019 (the map source and more information is from this <a href="https://www.hurriyetdailynews.com/map-delineates-turkeys-maritime-frontiers-in-med-sea-149379" target="_blank" rel="noreferrer noopener">article</a>). To capture the complicated nature of all of the other claims and established maritime boundaries, we’ve overlaid Sovereign Limits maritime data over top.</em> Between points A and B is the established maritime boundary with Northern Cyprus and between points E and F the new line with Libya.</figcaption></figure></div>



<p>Additionally, on 27 November 2019, Turkey and the UN-backed government of Libya (Libya is in the midst of a civil war, so yes, there are two entirely separate governments) signed a short, two-point maritime boundary agreement that dangles in the middle of Greek-claimed sea. This new boundary enraged neighboring Greece and Egypt as well as the entire EU. Its location deviates from the equidistance default stipulated by UNCLOS. Turkey and Libya note that the bilaterally negotiated boundary has nothing to do with third states, but as Greece claims the waters surrounding this new delimitation, it has caused quite a stir. The new August 2020 Egypt–Greece maritime boundary likely overlaps with the Libya–Turkey boundary in some capacity.</p>



<p>The conflict between Cyprus and Northern Cyprus would not have reached its modern outcome without Turkish involvement. Disagreements between Turkish Cypriots and Greek Cypriots on the island of Cyprus have been ongoing since even before Ottoman control of the island, and the modern conflict began shortly after independence from the United Kingdom. Turkey moved to occupy northern Cyprus in 1974 and the Turkish Republic of Northern Cyprus declared independence in 1983. Today, Turkey is the only country who recognizes Northern Cyprus’s statehood.</p>



<p>The island of Cyprus is now divided by a UN mandated and monitored buffer zone that snakes its way through hilly territory and divides the capital city (for both Cypruses) of Nicosia. The southern Greek Republic of Cyprus is an EU member and is recognized by the UN as the sole sovereign power of the island.</p>



<p>Related to the Cyprus dispute, the maritime picture off the coast of the island is quite complicated. The Republic of Cyprus has established maritime boundaries with <a href="https://sovereignlimits.com/boundaries/cyprus-egypt" target="_blank" rel="noreferrer noopener">Egypt</a>, <a href="https://sovereignlimits.com/boundaries/cyprus-israel" target="_blank" rel="noreferrer noopener">Israel</a>, and <a href="https://sovereignlimits.com/boundaries/cyprus-lebanon" target="_blank" rel="noreferrer noopener">Lebanon</a>, in addition to the short UK boundaries already mentioned. Northern Cyprus agreed to a maritime boundary with Turkey, that the southern Republic of Cyprus disputes. Due to the nature of the dispute, the maritime boundaries between Cyprus and Northern Cyprus are also unresolved (and unlikely to become so in the foreseeable future).</p>



<p>Turning to the maritime disputes between Turkey and neighboring Greece offers an even more complicated picture (at least delimitation wise) due to the multitude of Greek Islands that lay just off the Turkish coast. Relations between Turkey and Greece have been historically complicated and often quite problematic, negativity driven by both the conflict in Cyprus and unresolved maritime issues in the Aegean Sea. Oil was discovered in the continental shelf in 1973, adding [literal] fuel to the fire.</p>



<figure><ul><li><figure><img loading="lazy" width="1024" height="576" src="https://sovereignlimits.com/wp-content/uploads/sites/2/2020/08/20190212_UN.001-1024x576.png" alt="" data-id="1366" data-full-url="https://sovereignlimits.com/wp-content/uploads/sites/2/2020/08/20190212_UN.001.png" data-link="https://sovereignlimits.com/?attachment_id=1366" srcset="https://sovereignlimits.com/wp-content/uploads/sites/2/2020/08/20190212_UN.001-1024x576.png 1024w, https://sovereignlimits.com/wp-content/uploads/sites/2/2020/08/20190212_UN.001-300x169.png 300w, https://sovereignlimits.com/wp-content/uploads/sites/2/2020/08/20190212_UN.001-60x34.png 60w, https://sovereignlimits.com/wp-content/uploads/sites/2/2020/08/20190212_UN.001-768x432.png 768w, https://sovereignlimits.com/wp-content/uploads/sites/2/2020/08/20190212_UN.001-1536x864.png 1536w, https://sovereignlimits.com/wp-content/uploads/sites/2/2020/08/20190212_UN.001-600x338.png 600w, https://sovereignlimits.com/wp-content/uploads/sites/2/2020/08/20190212_UN.001.png 1920w" sizes="(max-width: 1024px) 100vw, 1024px"></figure></li><li><figure><img loading="lazy" width="1024" height="576" src="https://sovereignlimits.com/wp-content/uploads/sites/2/2020/08/20190212_UN.002-1024x576.png" alt="" data-id="1367" data-full-url="https://sovereignlimits.com/wp-content/uploads/sites/2/2020/08/20190212_UN.002.png" data-link="https://sovereignlimits.com/?attachment_id=1367" srcset="https://sovereignlimits.com/wp-content/uploads/sites/2/2020/08/20190212_UN.002-1024x576.png 1024w, https://sovereignlimits.com/wp-content/uploads/sites/2/2020/08/20190212_UN.002-300x169.png 300w, https://sovereignlimits.com/wp-content/uploads/sites/2/2020/08/20190212_UN.002-60x34.png 60w, https://sovereignlimits.com/wp-content/uploads/sites/2/2020/08/20190212_UN.002-768x432.png 768w, https://sovereignlimits.com/wp-content/uploads/sites/2/2020/08/20190212_UN.002-1536x864.png 1536w, https://sovereignlimits.com/wp-content/uploads/sites/2/2020/08/20190212_UN.002-600x338.png 600w, https://sovereignlimits.com/wp-content/uploads/sites/2/2020/08/20190212_UN.002.png 1920w" sizes="(max-width: 1024px) 100vw, 1024px"></figure></li><li><figure><img loading="lazy" width="1024" height="576" src="https://sovereignlimits.com/wp-content/uploads/sites/2/2020/08/20190212_UN.003-1024x576.png" alt="" data-id="1368" data-full-url="https://sovereignlimits.com/wp-content/uploads/sites/2/2020/08/20190212_UN.003.png" data-link="https://sovereignlimits.com/?attachment_id=1368" srcset="https://sovereignlimits.com/wp-content/uploads/sites/2/2020/08/20190212_UN.003-1024x576.png 1024w, https://sovereignlimits.com/wp-content/uploads/sites/2/2020/08/20190212_UN.003-300x169.png 300w, https://sovereignlimits.com/wp-content/uploads/sites/2/2020/08/20190212_UN.003-60x34.png 60w, https://sovereignlimits.com/wp-content/uploads/sites/2/2020/08/20190212_UN.003-768x432.png 768w, https://sovereignlimits.com/wp-content/uploads/sites/2/2020/08/20190212_UN.003-1536x864.png 1536w, https://sovereignlimits.com/wp-content/uploads/sites/2/2020/08/20190212_UN.003-600x338.png 600w, https://sovereignlimits.com/wp-content/uploads/sites/2/2020/08/20190212_UN.003.png 1920w" sizes="(max-width: 1024px) 100vw, 1024px"></figure></li></ul><figcaption><em>This series depicts the intricacies of constructing a strict equidistance line between Greek Islands and the Turkish coast in the Aegean. Turkey’s proposed maritime boundary lies to the west of equidistance.</em></figcaption></figure>



<p>Greece and Turkey have two extremely different perspectives on the possible delimitations of the maritime boundary through the Aegean Sea. Turkey is not a signatory of UNCLOS and claims that Greece’s Aegean Islands are not entitled to full continental shelf claims and would seek to have a mainland coast equidistance boundary through the middle of the Aegean Sea, while enclaving the Greek islands on the Turkish side of the maritime boundary line. Greece, a signatory of UNCLOS, meanwhile proposes a strict equidistance-based maritime boundary utilizing all of its islands, pushing the maritime boundary far to the east, just off the Turkish coast. Turkey’s position on the Greek claim is that this would create a “Greek Lake” of the Aegean Sea and severely limit Turkey’s freedom of navigation from the Black Sea to the Mediterranean.</p>



<p>There is also at least one officially disputed island between Turkey and Greece known as Imia by the Greeks and Kardak by the Turks. Turkish claims to additional islands have been made and redacted over the years.</p>



<p>Conflict over Greek and Turkish maritime claims is common. During the summer of 2020, Turkey has been conducting seismic surveys in Greek-claimed waters. And Greece is working on increasing its military power in response to Turkish aggression. Meanwhile, diplomats from the two states also sat down for a round of negotiations. In August, Greece called for talks to continue or a referral of the dispute to the ICJ. To read more, check out this <a href="https://www.ekathimerini.com/255548/article/ekathimerini/news/pm-proposes-fresh-talks-with-turkey-on-maritime-zones-or-world-court" target="_blank" rel="noreferrer noopener">article</a>. </p>



<p>Looking beyond Turkey-centered disputes, there is a handful of interesting and impossible to resolve conflicts that speckle the entire Mediterranean Sea and neighboring bodies of water. Israel and Lebanon seem to be constantly in conflict over both their unresolved <a href="https://sovereignlimits.com/boundaries/israel-lebanon-land" target="_blank" rel="noreferrer noopener">land boundary</a> and maritime frontier. Natural gas reserves have been discovered in maritime space that both states claim, and in 2018 Lebanon auctioned off several disputed oil blocks. Israel is currently working on its own oil exploration in the disputed area.</p>



<p>The Palestinian territory of Gaza set forth maritime claims in 2015 and 2019 in which they proposed lateral boundaries with Egypt and Israel, creating a corridor of Palestinian maritime space before reaching the boundary with Cyprus. Both Israel and Egypt have submitted protests to the UN over Palestine’s unilateral maritime claims.</p>



<div><figure><img loading="lazy" width="1024" height="963" src="https://sovereignlimits.com/wp-content/uploads/sites/2/2020/08/PSE_Claims-1-1024x963.jpg" alt="A map showing Palestine's unilateral maritime claims (a corridor from Gaza Strip to the already established boundaries with Cyprus)." srcset="https://sovereignlimits.com/wp-content/uploads/sites/2/2020/08/PSE_Claims-1-1024x963.jpg 1024w, https://sovereignlimits.com/wp-content/uploads/sites/2/2020/08/PSE_Claims-1-300x282.jpg 300w, https://sovereignlimits.com/wp-content/uploads/sites/2/2020/08/PSE_Claims-1-60x56.jpg 60w, https://sovereignlimits.com/wp-content/uploads/sites/2/2020/08/PSE_Claims-1-768x722.jpg 768w, https://sovereignlimits.com/wp-content/uploads/sites/2/2020/08/PSE_Claims-1-600x564.jpg 600w, https://sovereignlimits.com/wp-content/uploads/sites/2/2020/08/PSE_Claims-1.jpg 1200w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption><em>Palestine’s unilateral maritime claims extend from the Gaza Strip out to the already established boundaries with Cyprus.</em></figcaption></figure></div>



<p>The former Yugoslav States of Croatia and Slovenia also have disputed maritime space in the northern Adriatic Sea despite a <a href="https://sovereignlimits.com/boundaries/croatia-slovenia" target="_blank" rel="noreferrer noopener">2017 Permanent Court of Arbitration Award</a> delimiting the boundary (Croatia had unilaterally withdrawn from the case in 2015 following a scandal). Slovenia accepts the Tribunal’s delimitation, but Croatia does not.</p>



<p>Some similarities can be drawn to the maritime boundary between Greece and Albania in the southern reaches of the Adriatic Sea. The two States signed a maritime boundary agreement in 2009, but this document was annulled shortly thereafter by Albania. Negotiations over the maritime boundary began again in 2018 and are ongoing. And with Greece’s current dedication to maritime boundary delimitation with its neighbors it is plausible that a new Greece–Albania maritime boundary Agreement …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://sovereignlimits.com/blog/the-messy-mediterranean">https://sovereignlimits.com/blog/the-messy-mediterranean</a></em></p>]]>
            </description>
            <link>https://sovereignlimits.com/blog/the-messy-mediterranean</link>
            <guid isPermaLink="false">hacker-news-small-sites-24176329</guid>
            <pubDate>Sun, 16 Aug 2020 09:01:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Hello “Hello World”]]>
            </title>
            <description>
<![CDATA[
Score 55 | Comments 9 (<a href="https://news.ycombinator.com/item?id=24175174">thread link</a>) | @hermanradtke
<br/>
August 15, 2020 | https://blog.jfo.click/hello-hello-world/ | <a href="https://web.archive.org/web/*/https://blog.jfo.click/hello-hello-world/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
          <p>Languages are often judged initially on their "<a href="https://en.wikipedia.org/wiki/%22Hello,_World!%22_program">Hello,
world!</a>" program.
How easy is it to write? To run? How easy is it to understand? It's a very
simple program, of course, one of the simplest, even... just produce a little
text, and display it, what could be simpler?</p>
<p>It's really not fair to judge a language by such a cursory impression, but it
<em>can</em> give you an idea of what a language <em>values</em> and how it works. What does
the syntax look like? Is it typed? Is it interpreted? You can usually tell a
lot at a glance.</p>
<p>For example, One of Ruby's (many) hello worlds is so simple, it's also Python!</p>
<pre><code>print(<span>'Hello world!'</span>)
</code></pre>
<p>Often, people coming from interpreted languages experience compiled, systems
languages to be more complicated right off the bat. There is the obvious added
complexity of compiling and running being separate steps, as opposed to simply
pointing an executable at some source code and seeing a result right away, but
there are often syntactical constructs to go along with that...</p>
<p>At first glance, Rust's hello world looks fairly inert, as well:</p>
<pre><code><span><span>fn</span> <span>main</span></span>() {
    <span>println!</span>(<span>"Hello World!"</span>);
}
</code></pre>
<p>But <code>println!</code> is actually a macro, what does it look like expanded?</p>
<pre><code><span>macro_rules!</span> println {
    () =&gt; ($crate::<span>print!</span>(<span>"\n"</span>));
    ($($arg:tt)*) =&gt; ({
        $crate::io::_print($crate::format_args_nl!($($arg)*));
    })
}
</code></pre>
<p>You'll notice that this <em>also</em> has a macro <em>inside of it.</em> This matches on the
second case (because there is an argument present) and calls into
<code>$crate::format_args_nl!</code> and passes the result of that to <code>$crate::io::_print</code></p>
<pre><code><span>pub</span> <span><span>fn</span> <span>_print</span></span>(args: fmt::Arguments&lt;<span>'_</span>&gt;) {
    print_to(args, &amp;LOCAL_STDOUT, stdout, <span>"stdout"</span>);
}
</code></pre>
<p>which calls into <code>print_to</code>, which looks like</p>
<pre><code><span><span>fn</span> <span>print_to</span></span>&lt;T&gt;(
    args: fmt::Arguments&lt;<span>'_</span>&gt;,
    local_s: &amp;<span>'static</span> LocalKey&lt;RefCell&lt;<span>Option</span>&lt;<span>Box</span>&lt;<span>dyn</span> Write + <span>Send</span>&gt;&gt;&gt;&gt;,
    global_s: <span><span>fn</span></span>() -&gt; T,
    label: &amp;<span>str</span>,
) <span>where</span>
    T: Write,
{
    <span>let</span> result = local_s
        .try_with(|s| {
            
            
            
            <span>let</span> prev = s.borrow_mut().take();
            <span>if</span> <span>let</span> <span>Some</span>(<span>mut</span> w) = prev {
                <span>let</span> result = w.write_fmt(args);
                *s.borrow_mut() = <span>Some</span>(w);
                <span>return</span> result;
            }
            global_s().write_fmt(args)
        })
        .unwrap_or_else(|_| global_s().write_fmt(args));

    <span>if</span> <span>let</span> <span>Err</span>(e) = result {
        <span>panic!</span>(<span>"failed printing to {}: {}"</span>, label, e);
    }
}

</code></pre>
<p>Which is, uh, well let's just say it's not exactly <em>simple</em> looking now? There
is a lot going on here!</p>
<p>To be clear, I'm not faulting Rust here at all, my point is exactly the
opposite actually, in that there is <em>always</em> necessarily more going on in a
"Hello world!" than <code>puts "la de da"</code> or similar would have you believe on its
face. Speaking of Ruby's <code>puts</code>, what <em>is</em> the code that runs <code>puts</code> in the
Ruby interpreter itself, which is written in C?</p>
<p>Well it looks like <a href="https://github.com/ruby/ruby/blob/7c2bbd1c7d40a30583844d649045824161772e36/io.c#L7727-L7758">this</a></p>
<pre><code><span>VALUE
<span>rb_io_puts</span><span>(<span>int</span> argc, <span>const</span> VALUE *argv, VALUE out)</span>
</span>{
    <span>int</span> i, n;
    VALUE <span>line</span>, args[<span>2</span>];

    
    <span>if</span> (argc == <span>0</span>) {
        rb_io_write(out, rb_default_rs);
        <span>return</span> Qnil;
    }
    <span>for</span> (i=<span>0</span>; i&lt;argc; i++) {
        <span>if</span> (RB_TYPE_P(argv[i], T_STRING)) {
            <span>line</span> = argv[i];
            <span>goto</span> <span>string</span>;
        }
        <span>if</span> (rb_exec_recursive(io_puts_ary, argv[i], out)) {
            <span>continue</span>;
        }
        <span>line</span> = rb_obj_as_string(argv[i]);
      <span>string</span>:
        n = <span>0</span>;
        args[n++] = <span>line</span>;
        <span>if</span> (RSTRING_LEN(<span>line</span>) == <span>0</span> ||
            !rb_str_end_with_asciichar(<span>line</span>, <span>'\n'</span>)) {
            args[n++] = rb_default_rs;
        }
        rb_io_writev(out, n, args);
    }

    <span>return</span> Qnil;
}
</code></pre>
<p>Hello world!</p>
<p>We all know that a languages like Ruby or Python are designed explicitly to
hide this sort of complexity from us and let us get on with the dirty business
of munging data blobs or serving web requests or solving sudokus or whatever,
and thank goodness for that, but wow that is <em>quite</em> a lot, isn't it?</p>
<hr>
<p>When people come from languages that were designed to be ergonomic to more
systems oriented languages, they're often jarred by what they perceive to be
code thatis inelegant, ugly, and verbose. To be sure, it sometimes <em>is</em> exactly
that... (although anyone who has worked with a "pretty" language in a production
codebase knows that those are not immune to these descriptors either).</p>
<p>Usually, the tradeoff is explicit: elegance and simplicity for
<em>control</em>...  specific and granular <em>control</em>, over the program that will
eventually be run.  It isn't always necessary, in fact it is almost always _un_necessary,
to have <em>that</em> much control over your program. Obviously, productivity matters,
and if your business is <em><em>insert viable business</em></em>, well it's likely that your
goals are not going to be optimally met by futzing with manual memory
management all day (<a href="https://danluu.com/sounds-easy/">at least from the macro level, in the general
sense</a>).</p>
<p>But what if you <em>do</em> need that control? Well then, <em>you need it</em>. When every
ounce of performance actually is necessary, or on embedded systems with hard
memory constraints, or when writing code for some bespoke or otherwise uncommon
processor.</p>
<p>I'm going to choose one language, Zig, and dive deep into its hello world, but
it is important to note here that my point is not primarily about Zig, it's
about how <em>all</em> languages have to contend with an enormous amount of complexity
in order to do <em>anything</em>, even the simplest of tasks like a hello world
program. Complexity that is, for the most part, hidden from us in our day to
day. So what in the hello world is <em>actually</em> going on then?</p>
<blockquote>
<p>I'll be using the most current minor release version of Zig: 0.6.0.</p>
</blockquote>
<h2>Let's take a walk</h2>
<p><a href="https://ziglang.org/">Zig</a>'s hello world looks like this, from the docs.:</p>
<pre><code><span>const</span> std = <span>@import</span>(<span>"std"</span>);

<span>pub</span> <span><span>fn</span> <span>main</span></span>() !<span>void</span> {
    <span>const</span> stdout = std.io.getStdOut().outStream();
    <span>try</span> stdout.print(<span>"Hello, {}!\n"</span>, .{<span>"world"</span>});
}
</code></pre>
<p>If you are new to zig, a quick word on this syntax before I get into the gritty
details.</p>
<pre><code><span>const</span> std = <span>@import</span>(<span>"std"</span>);
</code></pre>
<p><code>@import</code> is a <a href="https://ziglang.org/documentation/0.6.0/#Builtin-Functions"><em>compiler
builtin</em></a> function
that assigns the namespace of the file it is referencing to the <code>const</code>
variable on the left hand side.</p>
<pre><code><span>pub</span> <span><span>fn</span> <span>main</span></span>() !<span>void</span> {
  
}
</code></pre>
<p>Just like in C, <code>main</code> is a special function that marks the entry point to a
program after it has been compiled as an executable. Unlike in C, it accepts no
arguments (C's main function has a variety of vagaries that make it a bit
<a href="https://stackoverflow.com/a/4207223">unique</a>) and command line input is
available through utility functions to allow easier cross platform use.</p>
<p>It is marked <a href="https://ziglang.org/documentation/0.6.0/#Keyword-pub"><code>pub</code></a> so
that it is accessible from outside of the immediate module ('module' here
referring to nothing more than the top level scope of the current namespace...
i.e., the file), this is a necessary step since, as the program's entry point,
<code>main</code> would <em>have</em> to be accessible from outside the immediate scope.</p>
<p><code>fn</code> is the function keyword.</p>
<p><code>main()</code> is the name of the function (and where the argument list <em>would</em> be)
and <code>!void</code> is the return type. Looking a little closer at that return type:</p>
<p>In C, the return type of a function is declared <em>before</em> anything else. This
makes a certain amount of sense: it's congruent with how variables are
declared, after all, and scanning the file you can see clearly "calling this
will get you that."</p>
<p>In Zig, the return type comes after the function declaration but before the
function body. This also makes sense! It's the same in Rust and Go, and seems
to be generally a more modern approach. The reason is actually pretty simple:
doing it this way makes it possible to have a context-free grammar! C and C++
put the parser in a position where it <a href="https://stackoverflow.com/questions/14589346/is-c-context-free-or-context-sensitive">has to understand semantics to even just
<em>parse</em> the source
code.</a></p>
<p>In Zig, <code>main</code> returns <code>void</code> (well, actually, it can return a variety of
things, and if it returns void (which is just a way of saying it doesn't return
anything at all)), it's actually returning
<a href="https://github.com/jfo/zig/blob/7381aaf70e0cad92fc52b79f3aa2a0abb7c3ee04/lib/std/start.zig#L241-L244"><code>0</code></a>
as a success code, but) there is a wrinkle!  <code>void</code> is preceded by an
exclamation mark. This means: "This function is supposed to return <code>void</code>, but
it <em>could</em> fail and return an error." This is an <a href="https://ziglang.org/documentation/0.6.0/#Inferred-Error-Sets">inferred error
set</a>, and
whenever a function that <em>could</em> fail is called, the compiler will enforce that
you handle that error at the call site. More on Zig's error handling some other
time, for now it is enough to understand what the <code>!</code> in front of the return
type declaration means. I want to move on to the body of the function, let's go
line by line.</p>
<pre><code><span>const</span> stdout = std.io.getStdOut().outStream();
</code></pre>
<p>So, we can see that this is a call into a standard library function (<code>std</code>)
that returns something that we assign to <code>const stdout</code>. Standard out (stdout) and
standard error (stderr) may be familiar concepts from the shell, but what does it
mean to be referring to <code>stdout</code> here in this program? What exactly <em>is</em>
<code>stdout</code>? Whatever it is, it's being returned by the call to <code>outStream()</code>,
which is a method called on the return value of <code>std.io.getStdOut()</code>, so we
first need to know what <em>that</em> is.</p>
<p>To the source! In the Zig source tree, <code>std</code> lives in <code>lib/std/std.zig</code>, which
is a file that makes a wide variety of functionality available. It includes the line:</p>
<pre><code><span>pub</span> <span>const</span> io = <span>@import</span>(<span>"io.zig"</span>);
</code></pre>
<p>Which is referred to on the <code>std</code> variable as <code>std.io</code> (again, notice the <code>pub</code>
keyword, without which this declared constant would be inaccesible outside of
this immediate scope). Going deeper, into <code>lib/std/io.zig</code>...</p>
<pre><code><span>pub</span> <span><span>fn</span> <span>getStdOut</span></span>() File {
    <span>return</span> File{
        .handle = getStdOutHandle(),
        .capable_io_mode = .blocking,
        .intended_io_mode = default_mode,
    };
}
</code></pre>
<p>So, <code>stdout</code> is a <em>File</em> struct. Let's look at that. It is imported at the top
of <code>io.zig</code> as</p>
<pre><code><span>const</span> File = std.fs.File;
</code></pre>
<p>and lives in the source, perhaps unsurprisingly, at <code>lib/std/fs/File.zig</code>. This
struct definition is quite long, so I'll focus on what we want to look at, the
<code>outStream()</code> method.</p>
<h2>An aside: methods vs functions</h2>
<p>Zig doesn't <em>really</em> have methods, but it's useful to talk about a special
class of functions <em>as</em> methods, since the calling convention supports implicit
passing of <code>self</code> when called on a struct "instance" using dot syntax. Let me
show you what I mean.</p>
<pre><code><span>const</span> std = <span>@import</span>(<span>"std"</span>);

<span>con…</span></code></pre></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.jfo.click/hello-hello-world/">https://blog.jfo.click/hello-hello-world/</a></em></p>]]>
            </description>
            <link>https://blog.jfo.click/hello-hello-world/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24175174</guid>
            <pubDate>Sun, 16 Aug 2020 04:39:44 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A joke about the difference between mathematicians and physicists]]>
            </title>
            <description>
<![CDATA[
Score 29 | Comments 27 (<a href="https://news.ycombinator.com/item?id=24174155">thread link</a>) | @tazedsoul
<br/>
August 15, 2020 | http://www.thingspondered.xyz/2020/08/excerpt-man-who-loved-only-numbers.html | <a href="https://web.archive.org/web/*/http://www.thingspondered.xyz/2020/08/excerpt-man-who-loved-only-numbers.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="post-body-7665629433863837456" itemprop="description articleBody">
<p><a href="https://1.bp.blogspot.com/-c_LMUfBgElw/XziOsG57gNI/AAAAAAAACcA/0YyZSCdHztQIDOZjFZqzAF5HfIEsMGcmACLcBGAsYHQ/s620/f6efef949e3a9dab7e1625e09a282424.jpg"><img data-original-height="330" data-original-width="620" src="https://1.bp.blogspot.com/-c_LMUfBgElw/XziOsG57gNI/AAAAAAAACcA/0YyZSCdHztQIDOZjFZqzAF5HfIEsMGcmACLcBGAsYHQ/s0/f6efef949e3a9dab7e1625e09a282424.jpg"></a></p><p>"The Man Who Loved Only Numbers" by Paul Hoffman is a biography about the memorable personality that is Paul Erdős, the prolific mathematician, who published with over 500 collaborators. Erdős, who is well-known for his contributions to number theory, set theory, probability theory, graph theory, and more, as well as the invention of the Erdős Number, a measure of one's proximity to having collaborated with him, is of course a subject himself. That said, in Hoffman's biography of him, there is a bit about the behavior of mathematicians and a lone physicist that does well to embody the spiritual and cognitive differences between the two groups, both of which share a passion for mathematical thinking but nevertheless are separable beasts.&nbsp;</p><p><span></span>The excerpt of interest tells of a mathematics conference in which a group of mathematicians return to the coffee table after a talk only to find a puzzle.</p><p><a name="more"></a><i>The rest filed out and raced toward a folding table that supported two large brown plastic tanks, one labeled WITH CAFFEINE, the other WITHOUT CAFFEINE. The mathematicians had already tanked up once, before the graph theo- rist's talk, and now the labels on the tanks were curiously switched. The mathematicians were in a tizzy and stared, puzzled, at the tanks. Their collective brainpower, fine for discerning the latest wrinkles in infinite graph theory, was stalling out on the case of the true Joe.</i></p><p><i>Finally a lightbulb went off in the head of a jovial, beer-bellied fellow in a JOY OF SETS T-shirt. He stepped forward and filled his Styrofoam cup, half from one tank and half from the other.&nbsp;</i></p><p><i>"I see," laughed one of his compatriots, "the game-theoretic solution!"</i></p><p><i>"I have another solution," said a thin man whose hands trembled slightly, apparently from a caffeine high. He&nbsp;</i><i>filled his cup a quarter full from one of the tanks.&nbsp;</i><i>"This is the asymptotic solution," he announced. "I'm already so wired I only want a little bit more; whatever is in the cup, I win."</i></p><p><i>A bystander who was a physicist rather than a mathematician didn't understand the need for all this sophisticated thinking. He pointed out that one tank was bigger than the other, and that the bigger tank presumably held caffeinated coffee since more people drink it than drink decaf. &nbsp;The mathematicians were taken aback by the simplicity of the solution. "Our different approaches," said the physicist, "remind me of an old joke. A physicist and a mathematician are flying cross-country together. Each is keeping a diary of the trip. They fly over a white horse in Iowa. The physicist writes, 'There is a white horse in Iowa.' The mathematician writes, 'There exists, somewhere in the Midwest, a horse, white on top.'"</i></p><p>For all that has been written about the difference between physicists and mathematicians, especially with the goal of illuminating their inner minds, this passage provides both a reasonable illustration and a good laugh.</p><p><b><a href="http://twitter.com/philliplevin"> Did you enjoy this? Follow me on Twitter: @philliplevin to find out when I post next</a></b></p>
</div></div>]]>
            </description>
            <link>http://www.thingspondered.xyz/2020/08/excerpt-man-who-loved-only-numbers.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24174155</guid>
            <pubDate>Sun, 16 Aug 2020 01:53:09 GMT</pubDate>
        </item>
    </channel>
</rss>
