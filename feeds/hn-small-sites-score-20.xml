<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 20]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 20. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Sun, 10 Jan 2021 20:43:50 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-20.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Sun, 10 Jan 2021 20:43:50 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[Pfizer vaccine appears effective against mutation in new coronavirus variants]]>
            </title>
            <description>
<![CDATA[
Score 354 | Comments 122 (<a href="https://news.ycombinator.com/item?id=25696577">thread link</a>) | @awnird
<br/>
January 8, 2021 | https://www.cbc.ca/news/health/pfizer-biontech-vaccine-appears-effective-against-mutation-in-new-coronavirus-variants-study-suggests-1.5865885 | <a href="https://web.archive.org/web/*/https://www.cbc.ca/news/health/pfizer-biontech-vaccine-appears-effective-against-mutation-in-new-coronavirus-variants-study-suggests-1.5865885">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>Pfizer Inc. and BioNTech's COVID-19 vaccine appeared to work against a key mutation in the highly transmissible new variants of the coronavirus discovered in Britain and South Africa, according to a laboratory study conducted by the U.S. drugmaker.</p><div><figure><div><p><img loading="lazy" alt="" srcset="" sizes="" src="https://i.cbc.ca/1.5852149.1608672062!/cumulusImage/httpImage/image.jpg_gen/derivatives/16x9_780/covid-vaccinations-toronto.jpg"></p></div><figcaption>A nurse prepares a dose of the Pfizer-BioNTech COVID-19 vaccine for care home workers at St. Michael’s Hospital in Toronto on Dec. 22, 2020.<!-- --> <!-- -->(Evan Mitsui/CBC)</figcaption></figure><p><span><p>Pfizer Inc. and BioNTech's COVID-19 vaccine appeared to work against a key mutation in the highly transmissible new variants of the coronavirus discovered in Britain and South Africa, according to a laboratory study conducted by the U.S. drugmaker.</p>  <p>The study by Pfizer and scientists from the University of Texas Medical Branch, which has not yet been peer-reviewed, indicated the vaccine was effective in neutralizing virus with the so-called N501Y mutation of the spike protein.</p>  <p>The mutation could be responsible for greater transmissibility and there had been concern it could also make the virus escape antibody neutralization elicited by the vaccine, said Phil Dormitzer, one of Pfizer's top viral vaccine scientists.</p>  <p>The first results of tests on the variants offer a glimmer of hope while more studies are carried out as Britain and other countries try to tame the more infectious variants that&nbsp;authorities believe are driving a surge in infections that could overwhelm health-care systems.</p>  <p>The Pfizer-BioNTech study was conducted on blood taken from people who had been given the vaccine. Its findings are limited because it does not look at the full set of mutations found in either of the new variants of the rapidly spreading virus.</p>  <p>Dormitzer said it was encouraging that the vaccine appears effective against the mutation, as well as 15 other mutations the company has previously tested against.</p>  <p>"So we've now tested 16 different mutations, and none of them have really had any significant impact. That's the good news," he said. "That doesn't mean that the 17th won't."</p>  <p><em><strong>WATCH | What scientists know about the new coronavirus variant:</strong></em></p>  <p><span><span><div><div title="What scientists know about the new coronavirus variant" role="button" tabindex="0"><div><div aria-labelledby="1842141251676-metadata-" title="What scientists know about the new coronavirus variant"><div><p><img src="https://thumbnails.cbc.ca/maven_legacy/thumbnails/643/819/COVID-VARIANT-SCI-BIRAK-080121.jpg" alt="" loading="lazy"></p></div></div></div></div></div><span>The B1-17 coronavirus variant, first discovered in the U.K., is now in at least 40 countries, including Canada. It has 23 mutations, including one that attaches to healthy cells like a key going into a lock.<!-- --> <!-- -->1:56</span></span></span></p>  <p>Dormitzer said another mutation found in the South African variant, called the E484K mutation, was also concerning.</p>  <p>The researchers plan to run similar tests to establish whether the vaccine is effective against other mutations found in the British and South African variants and hope to have more data within weeks.</p>  <p>The variants are said by scientists to be more transmissible than previously dominant ones, but they are not thought to cause more serious illness.</p>  <p>The virus's spikes act as a key that must unlock our cells to cause the infection.&nbsp;The variant first identified in the U.K. has a mutation that appears to make it easier for the coronavirus to grab hold of the lock more tightly, scientists say.</p>    <p>Scientists said the results of the study would help calm concerns that people will not be protected by vaccines being given to millions of people around the world in the fight against the pandemic, which has killed more than 1.8 million people and roiled economies.</p>  <p>But they cautioned that more clinical tests and data are still needed to come to a definitive conclusion.</p>  <p>"This is good news, mainly because it is not bad news," said Stephen Evans, professor of pharmacoepidemiology at the&nbsp;London School of Hygiene &amp; Tropical Medicine.</p>  <p>"So, yes this is good news, but it does not yet give us total confidence that the Pfizer (or other) vaccines will definitely give protection."</p>  <h2>AstraZeneca, Moderna, CureVac testing against variants</h2>  <p>AstraZeneca, Moderna and CureVac are also testing whether their shots work against the fast-spreading variants. They have said they expect them to be effective, but the timing of those studies is not known.</p>  <p>A senior British lawmaker expressed concerns in an interview on Friday that COVID-19 vaccines might not work properly against the South African variant. He was not responding to questions about Friday's data.</p>  <p>The Pfizer-BioNTech vaccine and the one from Moderna Inc., which use synthetic messenger RNA technology, can be quickly tweaked to address new mutations of a virus if necessary. Scientists have suggested the changes could be made in as little as six weeks.</p>  <p><span><figure><div><p><img loading="lazy" alt="" srcset="https://i.cbc.ca/1.5866498.1610132224!/cpImage/httpImage/image.jpg_gen/derivatives/original_300/virus-outbreak-new-variants.jpg 300w,https://i.cbc.ca/1.5866498.1610132224!/cpImage/httpImage/image.jpg_gen/derivatives/original_460/virus-outbreak-new-variants.jpg 460w,https://i.cbc.ca/1.5866498.1610132224!/cpImage/httpImage/image.jpg_gen/derivatives/original_620/virus-outbreak-new-variants.jpg 620w,https://i.cbc.ca/1.5866498.1610132224!/cpImage/httpImage/image.jpg_gen/derivatives/original_780/virus-outbreak-new-variants.jpg 780w,https://i.cbc.ca/1.5866498.1610132224!/cpImage/httpImage/image.jpg_gen/derivatives/original_1180/virus-outbreak-new-variants.jpg 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.5866498.1610132224!/cpImage/httpImage/image.jpg_gen/derivatives/original_780/virus-outbreak-new-variants.jpg"></p></div><figcaption>Graphic shows a diagram of the COVID-19 virus.<!-- --> <!-- -->(AP)</figcaption></figure></span></p>  <p>Some other vaccines to protect against COVID-19 also use the spike protein to show our immune system what the enemy looks like.</p>  <p>Canadian microbiologist Benjamin tenOever, a professor at the&nbsp;Icahn School of Medicine at Mount Sinai in New York,&nbsp;said our immune system learns to recognize and attack the viral attachment protein at many different sites.</p>  <p>"It would require many many mutations to render our vaccines non-effective,"&nbsp;tenOever&nbsp;said.</p>  <p>The variant is also not the first of the pandemic to emerge and Eleanor Riley, professor of immunology and infectious disease at the University of Edinburgh, said these types of studies&nbsp;will be needed as they appear.</p>  <p>"It may be necessary to tweak the vaccine over time," she said.</p>  <p>Dr. Theresa Tam, Canada's chief public health officer, said Friday that 14 cases of the variant first reported in the U.K. have been reported in Canada.</p>  <p>Researchers in Ontario have developed a faster test to identify variants.</p></span></p></div></div>]]>
            </description>
            <link>https://www.cbc.ca/news/health/pfizer-biontech-vaccine-appears-effective-against-mutation-in-new-coronavirus-variants-study-suggests-1.5865885</link>
            <guid isPermaLink="false">hacker-news-small-sites-25696577</guid>
            <pubDate>Sat, 09 Jan 2021 03:48:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Writing an iRacing SDK Implementation in F#]]>
            </title>
            <description>
<![CDATA[
Score 35 | Comments 16 (<a href="https://news.ycombinator.com/item?id=25696493">thread link</a>) | @sanesmith
<br/>
January 8, 2021 | https://markjames.dev/2021-01-08-writing-an-iracing-sdk-implementation-fsharp/ | <a href="https://web.archive.org/web/*/https://markjames.dev/2021-01-08-writing-an-iracing-sdk-implementation-fsharp/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article role="main">
        <p>In my <a href="https://markjames.dev/2021-01-04-why-learning-fsharp-2021/">previous post</a>, I discussed how I’ve decided to learn F# in 2021 for a number of reasons. Around the same time, I also happened to setup my Sim Racing rig so that I could continue to play <a href="https://www.iracing.com/" target="_blank">iRacing</a> with my VR headset (HTC Vive). Its been several years since I’ve last played, but with COVID-related curfews being implemented here in Montreal tomorrow, I’ve been increasingly taking up home-based pursuits which I didn’t always have the time for pre-lockdown. Since the last time I played iRacing, I’m running a PC with a much better processor, motherboard, and only SSDs. The VR performance has been a huge leap forward since I used to play with my old machine and I was quite impressed. After spending a couple of hours setting up, here’s what my current humble racing setup looks like:</p>

<p><img src="https://markjames.dev/img/posts/irsdk-fsharp/racing-rig.jpg" width="650" height="488" alt="Photo of my current iRacing VR setup"></p>

<p>Having a dedicated table really helps, as in my old apartment it was fairly difficult to setup a station with limited space, but now I can fortunately just jump in. Despite the past limitations, I was able to get fairly competitive and still remember the thrill of my first win agaisnt a field of real racers in a Mazda MX-5:</p>

<p><img src="https://markjames.dev/img/posts/irsdk-fsharp/iracing-win.jpg" width="500" height="279" alt="Photo of my iRacing first win certificate"></p>

<p>Inspired by setting everything up and doing some laps to practice for an eventual return to comeptition, I started thinking about how I once experimented with using the <a href="https://github.com/kutu/pyirsdk" target="_blank">Python implementation</a> of the iRacing SDK to connect to an arduino and display a speedometer readout in realtime on a small screen. In reminiscing about the experience, I thought about how I could look into writing an F# implementation of the SDK as a learning project. In addition to learning through the project, it also has the benefit of being of use in a future project involving an iRacing stats tracker web app that I’ve been thinking about writing as a project for my upcoming <a href="https://markjames.dev/2020-12-09-back-to-school/">cloud computing courses</a>.</p>

<h2 id="getting-started">Getting Started</h2>

<p>I tend to learn best when projects are slightly outside of my comfort zone, and this would be both my first time writing a library, as well as writing one in a functional language! Having used an array of libraries at this point, I had some confidence in choosing an organizational structure, and the Python implementation is only <a href="https://github.com/kutu/pyirsdk/blob/master/irsdk.py" target="_blank">739 lines of code</a> which felt doable compared to some of the larger libraries out there.</p>

<p>Moreover, the python implementation of the SDK has the ability to:</p>

<ul>
  <li>Get session data (WeekendInfo, SessionInfo, etc…)</li>
  <li>Get live telemetry data (Speed, FuelLevel, etc…)</li>
  <li>Broadcast messages (camera, replay, chat, pit and telemetry commands)</li>
</ul>

<p>and I figured that this would be a good featureset to aim for in the final version of the F# SDK. Out of these features, the session data and live telemetry data would be the ones I plan to implement first.</p>

<h2 id="creating-the-library">Creating the Library</h2>

<p>After coming up with some desired features, the first step was to create a new FSharp solution called iRacingFSharp. Inside the solution, I created two projects. One was our actual library, called iRacingFSharp, and the other was a basic console app called SDKReader (located in the Examples Folder) to test the functionality of the library as I worked on it. Note, if you’d like to see the full codebase you can <a href="https://github.com/markjamesm/irsdk-fsharp" target="_blank">here on github</a>.</p>

<h2 id="the-first-function">The First Function</h2>

<p>Starting small, I decided that a good first function would be to find out the state of the simulator. Fortunately, the iRacing SDK allows you to check if the sim is running using the following URL which points to a localhost server:</p>

<div><div><pre><code>http://127.0.0.1:32034/get_sim_status?object=simStatus
</code></pre></div></div>
<p>Getting this URL in Postman returns a JSON object which looks like this:</p>

<div><div><pre><code>var simStatus={
   running:0 // 1 if the sim is running
};
</code></pre></div></div>

<p>I decided to make use of the <a href="https://fsharp.github.io/FSharp.Data/library/Http.html" target="_blank">F# Data HTTP library</a> in order to download the response and so I installed it from NuGet at this point.</p>

<p>Next, inside my iRacingFSharp project I created a file called Irsdk.fs and wrote the following code:</p>

<div><div><pre><code><span>namespace</span> <span>IrsdkFS</span>

<span>open</span> <span>FSharp</span><span>.</span><span>Data</span>

<span>///&lt;summary&gt;F# implementation of the iRacing SDK.&lt;/summary&gt;</span>
<span>module</span> <span>IrsdkFS</span> <span>=</span>

    <span>///&lt;summary&gt;Returns the simStatus in string format&lt;/summary&gt;</span>
    <span>let</span> <span>SimStatus</span><span>()</span> <span>=</span>
        <span>let</span> <span>simStatusURL</span> <span>=</span> <span>"http://127.0.0.1:32034/get_sim_status?object=simStatus"</span>
        <span>let</span> <span>simStatusObject</span> <span>=</span> <span>Http</span><span>.</span><span>RequestString</span><span>(</span><span>simStatusURL</span><span>)</span>
        <span>simStatusObject</span>
</code></pre></div></div>

<p>In the above code, I’ve created a module which contains a function called SimStatus that takes no parameters. It then binds the JSON response to simStatusURL and passes it to the HTTP library via Http.RequestString(). Finally, simStatusObject is returned in string format which can be parsed further by another function in a later step.</p>



<p>With this simple function in place, the next step was to create SDKReader.fs inside my SDKReader console app. This file contained code to call the SimStatus() function and print the output:</p>

<div><div><pre><code><span>[&lt;</span><span>EntryPoint</span><span>&gt;]</span>
<span>let</span> <span>main</span> <span>argv</span> <span>=</span>
    <span>let</span> <span>test</span> <span>=</span> <span>IrsdkFS</span><span>.</span><span>SimStatus</span><span>()</span>
    <span>printf</span> <span>"%s"</span> <span>test</span>
    <span>0</span> <span>// return an integer exit code</span>
</code></pre></div></div>

<p>Running dotnet build inside the SDKReader folder displayed the following output while iRacing was running:</p>

<div><div><pre><code><span>"var simStatus={
   running:1
};
"</span><span>
</span></code></pre></div></div>

<p>Success! With this method working, we now have the very beginnings of an F# implementation of the iRacing SDK! Although it is a small step, we were also able to create and structure the project. Lastly, I also setup a a basic .NET build through Github Actions for CI.</p>



<p>iRacing’s API telemetry comes in three variations; data written to a .ibt file 60 times a second, live data exposed to the telemetry API 60 times per second, and a session string in YAML format that contains more or less static information about the session. The YAML string is appended to the end of the .ibt file but only a small portion of that data is exposed. This means that going forward, I’ll need to look into parsing the YAML as well as mapping more of the API endpoints. The iRacing API appears to be nonstandard and so it may take a little more work than just a typical REST API.</p>

<p>Stay tuned for Part Two where I plan to implement some telemetry functions and look into parsing the aforementioned YAML. In addition, be sure to follow along with the <a href="https://github.com/markjamesm/irsdk-fsharp" target="_blank">Github Repo here</a> if you’re interested in seeing how to project progresses (or would like to contribute)!</p>

      </article></div>]]>
            </description>
            <link>https://markjames.dev/2021-01-08-writing-an-iracing-sdk-implementation-fsharp/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25696493</guid>
            <pubDate>Sat, 09 Jan 2021 03:42:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Archive of 43k+ Donald Trump Twitter Screenshots]]>
            </title>
            <description>
<![CDATA[
Score 89 | Comments 29 (<a href="https://news.ycombinator.com/item?id=25693054">thread link</a>) | @soheilpro
<br/>
January 8, 2021 | https://pikaso.me/blog/donald-trump-twitter-archive | <a href="https://web.archive.org/web/*/https://pikaso.me/blog/donald-trump-twitter-archive">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  
  <div>


    <section>
      <p>
        <h2>Donald Trump Twitter Screenshot Archive</h2>
      </p>
      
        
      

      <div><p>Donald Trump loves to tweet and everyone knows that.
Twitter is his favorite medium to express his ideas and to communicate with the world.
He has been an active Twitter user since 2009. Much longer than many other world leaders.</p>
<p>Last month (May 2020) he tweeted 845 times â€” that's 28 tweets per day on average!</p>
<center>
  <a href="https://twitter.com/realDonaldTrump/status/491324429184823296"><img src="https://pikaso.me/blog/files/pikaso.me-realDonaldTrump-20140721_205046-491324429184823296.png" alt="Trump Tweet" width="500" height="244"></a>
</center>
<p>A while ago we received a request from one of our users who was looking for a way to screenshot all Donald Trump tweets.
We realized that's a good opportunity to put <a href="https://pikaso.me/">Pikaso</a> into test and see if it can perform such a task without any problems.
It went smoothly and there was only an issue with one of his tweets which included a deleted image.</p>
<p>Today, we are releasing the resulting files to the public.
This archive contains screenshots of 43,475 Donald Trump tweets from May 2009 to May 2020.
Whether you are pro- or anti- Trump, this is an important part of Internet history that we believe should be preserved.</p>
<h3 id="download">Download</h3>
<p>The Donald Trump Twitter Screenshot Archive can be downloaded through the following links:</p>
<ul>
<li><a href="https://pikaso.me/go/trump-twitter-archive-v1.zip">trump_twitter_archive_v1.zip</a> (Direct download, 2.6 GB)</li>
<li><a href="https://pikaso.me/go/trump-twitter-archive-v1.torrent">trump_twitter_archive_v1.torrent</a> (Torrent download, 28.2 KB)</li>
</ul>
<h3 id="howthiswasmade">How This Was Made?</h3>
<p>To create this archive, we first extracted all tweet ids from the realDonaldTrump.csv file that was provided to us.
That file only contained Donald Trump tweets up to March 29, 2020. To get the later tweets, we used <a href="http://trumptwitterarchive.com/">trumptwitterarchive.com</a>.</p>
<p>We then used the <a href="https://pikaso.me/api">Pikaso API</a> to screenshot each individual tweet.</p>
<h3 id="updates">Updates</h3>
<p>We have no plans to keep this archive up to date after the initial release.
However, if you are interested in doing so, you can use <a href="https://pikaso.me/">Pikaso</a>.
You can even <a href="https://pikaso.me/automate">automate</a> it so that each time he tweets, an automatic screenshot is taken.</p>
<h3 id="credit">Credit</h3>
<p>All the tweets are copyright https://twitter.com/realdonaldtrump.<br>
All the media embedded in tweets are copyright their respective owners.<br>
Original tweets data provided by <a href="https://twitter.com/twentysox">@twentysox</a>.</p>
<h3 id="copyrightlicense">Copyright &amp; License</h3>
<p>Copyright © 2020 https://pikaso.me.<br>
This work by https://pikaso.me is licensed under <a href="https://creativecommons.org/licenses/by/4.0">CC BY 4.0</a>.</p>
<h3 id="contact">Contact</h3>
<p>If you have any feedback or questions regarding this work, please <a href="https://pikaso.me/contact">contact us</a>.</p></div>
    </section>

    

    
      <section>
        <h2>More from the Blog</h2>

        
      </section>
    

      </div>
  
</div></div>]]>
            </description>
            <link>https://pikaso.me/blog/donald-trump-twitter-archive</link>
            <guid isPermaLink="false">hacker-news-small-sites-25693054</guid>
            <pubDate>Sat, 09 Jan 2021 00:14:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Semantic Web, Syllogism, and Worldview (2003)]]>
            </title>
            <description>
<![CDATA[
Score 67 | Comments 6 (<a href="https://news.ycombinator.com/item?id=25691623">thread link</a>) | @cratermoon
<br/>
January 8, 2021 | https://www.karmak.org/archive/2004/06/semantic_syllogism.html | <a href="https://web.archive.org/web/*/https://www.karmak.org/archive/2004/06/semantic_syllogism.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://www.karmak.org/archive/2004/06/semantic_syllogism.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25691623</guid>
            <pubDate>Fri, 08 Jan 2021 22:58:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Ruby 3, Concurrency and the Ecosystem]]>
            </title>
            <description>
<![CDATA[
Score 197 | Comments 47 (<a href="https://news.ycombinator.com/item?id=25690212">thread link</a>) | @ksec
<br/>
January 8, 2021 | https://kirshatrov.com/2021/01/06/ruby-concurrency-and-ecosystem/ | <a href="https://web.archive.org/web/*/https://kirshatrov.com/2021/01/06/ruby-concurrency-and-ecosystem/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  
  <p><span>06 Jan 2021</span></p><p>With the <a href="http://www.ruby-lang.org/en/news/2020/12/25/ruby-3-0-0-released/" target="\_blank">Ruby 3.0 release</a>, there’s been a lot of chatter about concurrency, parallelism, and async IO.</p>

<p>For my own reflection, I wanted to write down what that means for performance and capacity/costs of apps, and what would be the impact on the Ruby ecosystem.</p>

<p>I will assume that the audience already knows the difference between <a href="https://en.wikipedia.org/wiki/Thread_(computing)#Threads_vs._processes_pros_and_cons" target="\_blank">threads vs processes model in UNIX</a> and the <a href="https://en.wikipedia.org/wiki/Little%27s_law" target="\_blank">Little’s law</a>.</p>

<p>
Updated on Jan 9, 2021: thanks to the feedback from <a href="https://github.com/ioquatix" target="_blank">Samuel Williams</a>, I’ve revised the post with findings from <a href="https://github.com/socketry/falcon" target="_blank">Falcon</a>, the async web server written in Ruby.</p>

<h2 id="learning-from-python">Learning from Python</h2>

<p>It’s always good to take learnings from other languages. There’s an excellent <a href="http://calpaterson.com/async-python-is-not-faster.html" target="\_blank">write-up “Async Python is not faster” by Cal Paterson</a>.</p>

<p>It argues that process-based (aka forking) web servers <strong>show better latencies for web requests</strong> when they are compared to async IO-powered servers.</p>

<p>But why? That’s because async IO brings co-operative scheduling, which means that the execution is only yielded upon language keywords like <code>await</code>.</p>

<p>Quoting the author, this means that execution time is not distributed “fairly” and one thread can inadvertently starve another of CPU time while it is working. This is why latency is more erratic.</p>

<blockquote>
  <p>In contrast, traditional sync webservers use the pre-emptive multi-processing of the kernel scheduler, which works to ensure fairness by periodically swapping processes out from execution. This means that time is divided more fairly and that latency variance is lower.</p>
</blockquote>

<h2 id="learning-from-falcon">Learning from Falcon</h2>

<p>
(added on Jan 9, 2021)
</p>

<p><a href="https://github.com/socketry/falcon">Falcon</a> is a multi-process, multi-fiber HTTP server written in Ruby that is already utilizing async IO.</p>

<p>It has a great <a href="https://github.com/socketry/falcon-benchmark">set of benchmarks</a> that let us compare Falcon’s async IO with other non-async web servers like Passenger, Puma and Unicorn. Those benchmarks have been showing that <strong>async IO-powered server like Falcon</strong> provides better latencies on web requests.</p>

<p>Interestingly, that’s a very different story than Python! Looking at Python, I’ve expected that the thread driven server should be more “balanced” but it turns out the opposite.</p>

<p>Falcon’s authors explain that the fiber scheduler naturally scales according to load much better than the worker pool implementation in Puma. When fibers are busy handling requests, they don’t call <code>accept</code> so the requests are naturally picked up by other workers who are less busy.</p>

<h3 id="what-does-that-mean-for-us-ruby-developers">What does that mean for us Ruby developers?</h3>

<p>Scheduling threads and fibers is nuanced, and you can see that similar approaches demonstrate different results on Python and Ruby/Falcon examples.</p>

<p>In the first revision of this post, I’ve argued that async IO may often increase the latency. Thanks to the data <a href="https://github.com/socketry/falcon-benchmark">shown</a> by Samuel Williams, we can see that’s not the case.</p>

<p>One of the benefits of async IO is that concurrency is archived by the <code>yield</code>/<code>await</code> instruction, not by the constant interrupt of threads. Every interrupt causes the context switch - and it’s nice to reduce context switching where we can because scheduler switching from one task to another always adds a little overhead. Since that happens thousands of times every second, <strong>less context switching would mean fewer CPU cycles wasted</strong>.</p>

<h2 id="where-does-ractor-fit-in">Where does Ractor fit in?</h2>

<p>The Ractor pattern allows parallel execution (which wasn’t possible in Ruby before) of more than one Ruby thread by limiting the shared state of a block of code that you want to execute in parallel. Those “blocks of code” (aka “actors”) can also talk to each other through messages. This is the <a href="https://en.wikipedia.org/wiki/Actor_model">Actor model</a> used in other languages.</p>

<p>There are two ways we could leverage Ractors for modern apps: from the top (wrap every worker into a Ractor) and from the bottom (selectively use Ractors within existing code to parallelize CPU-intensive work).</p>

<p>While I see more to be gained from the top way, it seems like there’s so much shared and mutable state in Ruby libraries that it’s going to be quite tricky, although not impossible. It will likely take some efforts and at least a year of work from the community to push libraries towards less shared state. For the next year, we’ll mostly see Ractor maturing and getting adopted in the “bottom” use cases.</p>

<h2 id="impact-on-the-ruby-ecosystem">Impact on the Ruby ecosystem</h2>

<p><strong>By itself, async IO will help to use CPU more efficiently by reducing context switching.</strong></p>

<p>Better support for async IO in Ruby 3.0 will increase community’s adoption of async web servers like Falcon, and will hopefully give birth to async background job systems.</p>

<p>Having Sidekiq execute jobs concurrently through the async IO and event loop instead of threads could increase the throughput and save CPU work, especially for IO-bound workloads like webhook delivery.</p>

<p><strong>We’ll need to push the Ruby ecosystem to have less shared state to fully leverage the Ractor pattern.</strong> That will take us some time.</p>

<p>If you’ve enjoyed reading this, I highly recommend to read <em><a href="http://wjwh.eu/posts/2020-12-28-ruby-fiber-scheduler-c-extension.html" target="\_blank">Ruby 3.0 and the new FiberScheduler interface</a></em> by Wander Hillen.</p>

<p>Thanks to Samiel Williams and to Julik Tarkhanov for providing early feedback on this post.</p>

<p>I’m looking forward to hearing your thoughts on this in the comments!</p>

</div></div>]]>
            </description>
            <link>https://kirshatrov.com/2021/01/06/ruby-concurrency-and-ecosystem/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25690212</guid>
            <pubDate>Fri, 08 Jan 2021 20:44:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Smooth Voxel Terrain, Part 2 (2012)]]>
            </title>
            <description>
<![CDATA[
Score 124 | Comments 16 (<a href="https://news.ycombinator.com/item?id=25690189">thread link</a>) | @fanf2
<br/>
January 8, 2021 | https://0fps.net/2012/07/12/smooth-voxel-terrain-part-2/ | <a href="https://web.archive.org/web/*/https://0fps.net/2012/07/12/smooth-voxel-terrain-part-2/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
						<p><a href="https://0fps.wordpress.com/2012/07/10/smooth-voxel-terrain-part-1/">Last time</a> we formulated the problem of isosurface extraction and discussed some general approaches at a high level.&nbsp; Today, we’re going to get very specific and look at meshing in particular.</p>
<p>For the sake of concreteness, let us suppose that we have approximated our potential field <img src="https://s0.wp.com/latex.php?latex=f&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" alt="f" title="f"> by sampling it onto a cubical grid at some fixed resolution.&nbsp; To get intermediate values, we’ll just interpolate between grid points using the standard <a href="http://paulbourke.net/miscellaneous/interpolation/">trilinear interpolation</a>.&nbsp; This is like a <img src="https://s0.wp.com/latex.php?latex=C%5E0&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" alt="C^0" title="C^0"> generalization of Minecraft-style voxel surfaces.&nbsp; Our goal in this article is to figure out how to extract a mesh of the implicit surface (or zero-crossings of <img src="https://s0.wp.com/latex.php?latex=f&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" alt="f" title="f">).&nbsp; In particular, we’re going to look at three different approaches to this problem:</p>
<h2>Marching Cubes</h2>
<p>By far the most famous method for extracting isosurfaces is the <a href="http://en.wikipedia.org/wiki/Marching_cubes">marching cubes</a> algorithm. &nbsp;In fact, it is so popular that the term `marching cubes’ is even more popular than the term `isosurface’ (at least according to Google)!&nbsp;&nbsp; It’s quite a feat when an algorithm becomes more popular than the problem which it solves!&nbsp; The history behind this method is very interesting.&nbsp; It was originally <a href="http://dl.acm.org/citation.cfm?id=37422">published back in SIGGRAPH 87</a>, and then summarily patented by the Lorensen and Cline. &nbsp;This fact has caused a lot of outrage, and is been widely cited as one of the classic examples of patents hampering innovation.&nbsp; Fortunately, the patent on marching cubes expired back in 2005 and so today you can freely use this algorithm in the US with no fear of litigation.</p>
<p>Much of the popularity of marching cubes today is due in no small part to a famous article written by <a href="http://paulbourke.net/">Paul Bourke</a>. &nbsp;Back in 1994 he made a webpage called <a href="http://paulbourke.net/geometry/polygonise/">“Polygonizing a Scalar Field”</a>, which presented a short, self-contained reference implementation of marching cubes (derived from some earlier work by Cory Gene Bloyd.)&nbsp; That tiny snippet of a C program is possibly <strong><em>the most copy-pasted code of&nbsp;<span>all time</span></em></strong>. &nbsp;I have seen some variation of Bloyd/Bourke’s code in <strong>every</strong> implementation of marching cubes that I’ve ever looked at, without exception.&nbsp; There are at least a couple of reasons for this:</p>
<ol>
<li>Paul Bourke’s exposition is really good. &nbsp;Even today, with many articles and tutorials written on the technique, none of them seem to explain it quite as well.&nbsp; (And I don’t have any delusions that I will do any better!)</li>
<li>Also their implementation is very small and fast. &nbsp;It uses some clever tricks like a precalculated edge table to speed up vertex generation.&nbsp; It is difficult to think of any non-trivial way to improve upon it.</li>
<li>Finally, marching cubes is incredibly difficult to code from scratch.</li>
</ol>
<p>This last point needs some explaining, &nbsp;Conceptually, marching cubes is rather simple. &nbsp;What it does is sample the implicit function along a grid, and then checks the sign of the potential function at each point (either +/-). &nbsp;Then, for every edge of the cube with a sign change, it finds the point where this edge intersects the volume and adds a vertex (this is just like ray casting a bunch of tiny little segments between each pair of grid points).&nbsp; The hard part is figuring out how to stitch some surface between these intersection points.&nbsp; Up to the position of the zero crossings, there are&nbsp;<img src="https://s0.wp.com/latex.php?latex=2%5E8+%3D+256&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" alt="2^8 = 256" title="2^8 = 256"> different possibilities, each of which is determined by the sign of the function at the 8 vertices of the cube:</p>
<p><a href="http://en.wikipedia.org/wiki/File:MarchingCubes.svg"><img loading="lazy" data-attachment-id="561" data-permalink="https://0fps.net/2012/07/12/smooth-voxel-terrain-part-2/marchingcubes/" data-orig-file="https://0fps.files.wordpress.com/2012/07/marchingcubes.png" data-orig-size="501,236" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;}" data-image-title="marchingcubes" data-image-description="<p>Some of the marching cubes special cases.  (c) WIkipedia, created by Jean-Marie Favreau.</p>
" data-medium-file="https://0fps.files.wordpress.com/2012/07/marchingcubes.png?w=300" data-large-file="https://0fps.files.wordpress.com/2012/07/marchingcubes.png?w=501" title="marchingcubes" alt="" src="https://0fps.files.wordpress.com/2012/07/marchingcubes.png?w=300&amp;h=141" height="141" width="300" srcset="https://0fps.files.wordpress.com/2012/07/marchingcubes.png?w=300&amp;h=141 300w, https://0fps.files.wordpress.com/2012/07/marchingcubes.png?w=150&amp;h=71 150w, https://0fps.files.wordpress.com/2012/07/marchingcubes.png 501w" sizes="(max-width: 300px) 100vw, 300px"></a></p>
<p>Some of the marching cubes special cases. &nbsp;(c) Wikipedia, created by Jean-Marie Favreau.</p>
<p>Even worse, some of these cases are ambiguous!&nbsp; The only way to resolve this is to somewhat arbitrarily break the symmetry of the table based on a case-by-case analysis. What a mess!&nbsp; Fortunately, if you just download Bloyd/Bourke’s code, then you don’t have to worry about any of this and everything will just work. &nbsp;No wonder it gets used so much!</p>
<h2>Marching Tetrahedra</h2>
<p>Both the importance of isosurface extraction and the perceived shortcomings of marching cubes motivated the search for alternatives. &nbsp;One of the most popular was the <a href="http://search.ieice.org/bin/summary.php?id=e74-d_1_214">marching tetrahedra</a>, introduced by Doi and Koide.&nbsp; Besides the historical advantage that marching tetrahedra was not patented, it does have a few technical benefits:</p>
<ol>
<li>Marching tetrahedra does not have ambiguous topology, unlike marching cubes.&nbsp; As a result, surfaces produced by marching tetrahedra are always manifold.</li>
<li>The amount of geometry generated per tetrahedra is much smaller, which might make it more suitable for use in say a geometry shader.</li>
<li>Finally, marching tetrahedra has only <img src="https://s0.wp.com/latex.php?latex=2%5E4+%3D+16&amp;bg=ffffff&amp;fg=333333&amp;s=0&amp;c=20201002" alt="2^4 = 16" title="2^4 = 16"> cases, a number which can be further reduced to just 3 special cases by symmetry considerations. &nbsp;This is enough that you can work them out by hand.</li>
</ol>
<p><strong>Exercise:&nbsp; </strong>Try working out the cases for marching tetrahedra yourself. &nbsp;(It is really not bad.)</p>
<p>The general idea behind marching tetrahedra is the same as marching cubes, only it uses a tetrahedral subdivision. &nbsp;Again, the standard reference for practical implementation is Paul Bourke (<a href="http://local.wasp.uwa.edu.au/~pbourke/geometry/polygonise/">same page as before</a>, just scroll down a bit.) &nbsp;While there is a lot to like about marching tetrahedra, it does have some draw backs. &nbsp;In particular, the meshes you get from marching tetrahedra are typically about 4x larger than marching cubes. &nbsp;This makes both the algorithm and rendering about 4x slower. &nbsp;If your main consideration is performance, you may be better off using a cubical method. &nbsp;On the other hand, if you really need a manifold mesh, then marching tetrahedra could be a good option. &nbsp;The other nice thing is that if you are obstinate and like to code everything yourself, then marching tetrahedra may be easier since there aren’t too many cases to check.</p>
<h2>The Primal/Dual Classification</h2>
<p>By now, both marching cubes and tetrahedra are quite old. &nbsp;However, research into isosurface extraction hardly stopped in the 1980s.&nbsp; In the intervening years, many new techniques have been developed. &nbsp;One general class of methods which has proven very effective are the so-called `dual’ schemes. &nbsp;The first dual method, surface nets, was proposed by Sarah Frisken Gibson in 1999:</p>
<p>S.F. Gibson, (1999) “<a href="http://www.merl.com/papers/docs/TR99-24.pdf" target="_blank">Constrained Elastic Surface Nets</a>”&nbsp; Mitsubishi Electric Research Labs, Technical Report.</p>
<p>The main distinction between dual and primal methods (like marching cubes) is the way they generate surface topology.&nbsp; In both algorithms, we start with the same input: a volumetric mesh determined by our samples, which I shall take the liberty of calling a&nbsp;<em>sample complex</em> for lack of a better term.&nbsp; If you’ve never heard of the word&nbsp;<a href="http://www.inperc.com/wiki/index.php?title=Cell_complex">cell complex</a>&nbsp;before, you can think of it as an n-dimensional generalization of a triangular mesh, where the `cells’ or facets don’t have to be simplices.</p>
<p>In the sample complex, vertices (or 0-cells) correspond to the sample points; edges (1-cells) correspond to pairs of nearby samples; faces (2-cells) bound edges and so on:</p>
<p><img loading="lazy" data-attachment-id="534" data-permalink="https://0fps.net/2012/07/12/smooth-voxel-terrain-part-2/samplecomplex/" data-orig-file="https://0fps.files.wordpress.com/2012/07/samplecomplex.png" data-orig-size="533,419" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;}" data-image-title="samplecomplex" data-image-description="" data-medium-file="https://0fps.files.wordpress.com/2012/07/samplecomplex.png?w=300" data-large-file="https://0fps.files.wordpress.com/2012/07/samplecomplex.png?w=533" title="samplecomplex" alt="" src="https://0fps.files.wordpress.com/2012/07/samplecomplex.png?w=300&amp;h=235" height="235" width="300" srcset="https://0fps.files.wordpress.com/2012/07/samplecomplex.png?w=300&amp;h=235 300w, https://0fps.files.wordpress.com/2012/07/samplecomplex.png?w=150&amp;h=118 150w, https://0fps.files.wordpress.com/2012/07/samplecomplex.png 533w" sizes="(max-width: 300px) 100vw, 300px"></p>
<p>Here is an illustration of such a complex. &nbsp;I’ve drawn the vertices where the potential function is negative black, and the ones where it is positive white.</p>
<p>Both primal and dual methods walk over the sample complex, looking for those cells which cross the 0-level of the potential function. &nbsp;In the above illustration, this would include the following faces:</p>
<p><img loading="lazy" data-attachment-id="535" data-permalink="https://0fps.net/2012/07/12/smooth-voxel-terrain-part-2/boundarycells/" data-orig-file="https://0fps.files.wordpress.com/2012/07/boundarycells.png" data-orig-size="533,419" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;}" data-image-title="boundarycells" data-image-description="" data-medium-file="https://0fps.files.wordpress.com/2012/07/boundarycells.png?w=300" data-large-file="https://0fps.files.wordpress.com/2012/07/boundarycells.png?w=533" title="boundarycells" alt="" src="https://0fps.files.wordpress.com/2012/07/boundarycells.png?w=300&amp;h=235" height="235" width="300" srcset="https://0fps.files.wordpress.com/2012/07/boundarycells.png?w=300&amp;h=235 300w, https://0fps.files.wordpress.com/2012/07/boundarycells.png?w=150&amp;h=118 150w, https://0fps.files.wordpress.com/2012/07/boundarycells.png 533w" sizes="(max-width: 300px) 100vw, 300px"></p>
<h3>Primal Methods</h3>
<p>Primal methods, like marching cubes, try to turn the cells crossing the bounary into an isosurface using the following recipe:</p>
<ul>
<li>Edges crossing the boundary become vertices in the isosurface mesh.</li>
<li>Faces crossing the boundary become edges in the isosurface mesh.</li>
<li>…</li>
<li>n-cells crossing the boundary become (n-1)-cells in the isosurface mesh.</li>
</ul>
<p>One way to construct a primal mesh for our sample complex would be the following:</p>
<p><img loading="lazy" data-attachment-id="536" data-permalink="https://0fps.net/2012/07/12/smooth-voxel-terrain-part-2/primalcomplex/" data-orig-file="https://0fps.files.wordpress.com/2012/07/primalcomplex.png" data-orig-size="533,424" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;}" data-image-title="primalcomplex" data-image-description="" data-medium-file="https://0fps.files.wordpress.com/2012/07/primalcomplex.png?w=300" data-large-file="https://0fps.files.wordpress.com/2012/07/primalcomplex.png?w=533" title="primalcomplex" alt="" src="https://0fps.files.wordpress.com/2012/07/primalcomplex.png?w=300&amp;h=238" height="238" width="300" srcset="https://0fps.files.wordpress.com/2012/07/primalcomplex.png?w=300&amp;h=238 300w, https://0fps.files.wordpress.com/2012/07/primalcomplex.png?w=150&amp;h=119 150w, https://0fps.files.wordpress.com/2012/07/primalcomplex.png 533w" sizes="(max-width: 300px) 100vw, 300px"></p>
<p>This is pretty nice because it is easy to find intersection points along edges. &nbsp;Of course, there is some topological ambiguity in this construction.&nbsp; For non-simplicial cells crossing the boundary it is not always clear how you would glue the cells together:</p>
<p><img loading="lazy" data-attachment-id="537" data-permalink="https://0fps.net/2012/07/12/smooth-voxel-terrain-part-2/primalcell/" data-orig-file="https://0fps.files.wordpress.com/2012/07/primalcell.png" data-orig-size="929,198" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;}" data-image-title="primalcell" data-image-description="" data-medium-file="https://0fps.files.wordpress.com/2012/07/primalcell.png?w=300" data-large-file="https://0fps.files.wordpress.com/2012/07/primalcell.png?w=640" title="primalcell" alt="" src="https://0fps.files.wordpress.com/2012/07/primalcell.png?w=300&amp;h=63" height="63" width="300" srcset="https://0fps.files.wordpress.com/2012/07/primalcell.png?w=296&amp;h=63 296w, https://0fps.files.wordpress.com/2012/07/primalcell.png?w=591&amp;h=126 591w, https://0fps.files.wordpress.com/2012/07/primalcell.png?w=150&amp;h=32 150w, https://0fps.files.wordpress.com/2012/07/primalcell.png?w=300&amp;h=64 300w" sizes="(max-width: 300px) 100vw, 300px"></p>
<p>As we have seen, these ambiguities lead to exponentially many special cases, and are generally a huge pain to deal with.</p>
<h3>Dual Methods</h3>
<p>Dual methods on the other hand use a very different topology for the surface mesh.&nbsp; Like primal methods, they only consider the cells which intersect the boundary, but the rule they use to construct surface cells is very different:</p>
<ul>
<li>For every edge crossing the boundary, create an (n-1) cell.&nbsp; (Face in 3D)</li>
<li>For every face crossing the boundary, create an (n-2) cell. (Edge in 3D)</li>
<li>…</li>
<li>For every d-dimensional cell, create an (n-d) cell.</li>
<li>…</li>
<li>For every n-cell, create a vertex.</li>
</ul>
<p>This creates a much simpler topological structure:</p>
<p><img loading="lazy" data-attachment-id="538" data-permalink="https://0fps.net/2012/07/12/smooth-voxel-terrain-part-2/dualcomplex/" data-orig-file="https://0fps.files.wordpress.com/2012/07/dualcomplex.png" data-orig-size="537,419" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;}" data-image-title="dualcomplex" data-image-description="" data-medium-file="https://0fps.files.wordpress.com/2012/07/dualcomplex.png?w=300" data-large-file="https://0fps.files.wordpress.com/2012/07/dualcomplex.png?w=537" title="dualcomplex" alt="" src="https://0fps.files.wordpress.com/2012/07/dualcomplex.png?w=300&amp;h=234" height="234" width="300" srcset="https://0fps.files.wordpress.com/2012/07/dualcomplex.png?w=300&amp;h=234 300w, https://0fps.files.wordpress.com/2012/07/dualcomplex.png?w=150&amp;h=117 150w, https://0fps.files.wordpress.com/2012/07/dualcomplex.png 537w" sizes="(max-width: 300px) 100vw, 300px"></p>
<p>The nice thing about this construction is that unlike primal methods, the topology of the dual isosurface mesh is completely determined by the sample complex (so there are no ambiguities).&nbsp; The disadvantage is that you may sometimes get non-manifold vertices:</p>
<p><img loading="lazy" data-attachment-id="465" data-permalink="https://0fps.net/2012/07/12/smooth-voxel-terrain-part-2/dualmesh/" data-orig-file="https://0fps.files.wordpress.com/2012/07/dualmesh.png" data-orig-size="589,245" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;}" data-image-title="dualmesh" data-image-description="" data-medium-file="https://0fps.files.wordpress.com/2012/07/dualmesh.png?w=300" data-large-file="https://0fps.files.wordpress.com/2012/07/dualmesh.png?w=589" title="dualmesh" alt="" src="https://0fps.files.wordpress.com/2012/07/dualmesh.png?w=300&amp;h=124" height="124" width="300" srcset="https://0fps.files.wordpress.com/2012/07/dualmesh.png?w=298&amp;h=124 298w, https://0fps.files.wordpress.com/2012/07/dualmesh.png?w=150&amp;h=62 150w, https://0fps.files.wordpress.com/2012/07/dualmesh.png 589w" sizes="(max-width: 300px) 100vw, 300px"></p>
<h2>Make Your Own Dual Scheme</h2>
<p>To create your own dual method, you just have to specify two things:</p>
<ol>
<li>A sample complex.</li>
<li>And a rule to assign vertices to every n-cell intersecting the boundary.</li>
</ol>
<p>The second item is the tricky part, and much of the research into dual methods has focused on exploring the possibilities. &nbsp;It is interesting to note that this is the opposite of primal methods, where finding vertices was pretty easy, but gluing them together consistently turned out to be quite hard.</p>
<h3>Surface Nets</h3>
<p>Here’s a neat puzzle: what happens if we apply the dual recipe to a regular, cubical grid&nbsp;(like we did in marching cubes)? &nbsp;Well, it turns out that you get the same boxy, cubical meshes that you’d make in a Minecraft game (topologically speaking)!</p>
<p><a href="https://0fps.files.wordpress.com/2012/07/exampledualmesh.png"><img title="exampledualmesh" alt="" src="https://0fps.files.wordpress.com/2012/07/exampledualmesh.png?w=150&amp;h=145" height="145" width="150"></a><a href="https://0fps.files.wordpress.com/2012/07/spheresmoothed.png"><img title="spheresmoothed" alt="" src="https://0fps.files.wordpress.com/2012/07/spheresmoothed.png?w=150&amp;h=138" height="138" width="150"></a></p>
<p>Left: A dual mesh with vertex positions snapped to integer coordinates.&nbsp; Right: A dual mesh with smoothed vertex positions.</p>
<p>So if you know how to <a href="https://0fps.wordpress.com/2012/06/30/meshing-in-a-minecraft-game/">generate Minecraft meshes</a>, then you already know how to make smooth shapes! &nbsp;All you have to do is squish your vertices down onto the isosurface somehow. &nbsp;How cool is that?</p>
<p>This technique is called “surface nets” (remember when we mentioned them before?) &nbsp;Of course the trick is to figure out where you place the vertices. &nbsp;In Gibson’s original paper, she formulated the process of vertex …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://0fps.net/2012/07/12/smooth-voxel-terrain-part-2/">https://0fps.net/2012/07/12/smooth-voxel-terrain-part-2/</a></em></p>]]>
            </description>
            <link>https://0fps.net/2012/07/12/smooth-voxel-terrain-part-2/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25690189</guid>
            <pubDate>Fri, 08 Jan 2021 20:43:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Baldur's Gate 2 reincarnated in the browser using WebAssembly]]>
            </title>
            <description>
<![CDATA[
Score 39 | Comments 19 (<a href="https://news.ycombinator.com/item?id=25687261">thread link</a>) | @yuri91
<br/>
January 8, 2021 | https://browser-games.itch.io/baldursgate2 | <a href="https://web.archive.org/web/*/https://browser-games.itch.io/baldursgate2">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="wrapper"><div id="inner_column"><div id="header"><p><img alt="Baldur's Gate 2 Demo (Web Edition)" src="https://img.itch.zone/aW1nLzMzOTMyMDYuanBn/original/ymT9Bf.jpg"></p></div><div id="view_html_game_page_41775"><div id="html_embed_widget_78833"><div data-height="800" data-width="1000"></div></div><div><div><div><p>Link to Discord community:&nbsp;<a href="https://discord.gg/zUSZ3T8" rel="nofollow noopener">https://discord.gg/zUSZ3T8</a></p></div><div><div><span>More information<svg height="6" width="12" role="img" aria-hidden="" viewBox="0 0 37 20" version="1.1"><path d="m2.0858 0c-1.1535 0-2.0858 0.86469-2.0858 1.9331 0 0.5139 0.21354 1.0183 0.38704 1.1881l18.113 16.879 18.112-16.879c0.174-0.1696 0.388-0.674 0.388-1.1879 0-1.0684-0.932-1.9331-2.086-1.9331-0.577 0-1.111 0.23008-1.49 0.57992l-14.924 13.894-14.925-13.893c-0.3777-0.34998-0.9134-0.581-1.4902-0.581z"></path></svg></span></div><div><div><table><tbody><tr><td>Updated</td><td><abbr title="08 January 2021 @ 18:16"><span></span> 2 days ago</abbr></td></tr><tr><td>Status</td><td><a href="https://itch.io/games/released">Released</a></td></tr><tr><td>Platforms</td><td><a href="https://itch.io/games/html5">HTML5</a></td></tr><tr><td>Author</td><td><a href="https://browser-games.itch.io/">browser games</a></td></tr><tr><td>Genre</td><td><a href="https://itch.io/games/genre-rpg">Role Playing</a></td></tr></tbody></table></div></div></div><div><h2 id="comments">Leave a comment</h2><p><a href="https://itch.io/login?return_to=https%3A%2F%2Fbrowser-games.itch.io%2Fbaldursgate2" data-register_action="comment">Log in with itch.io</a> to leave a comment.</p><div id="community_topic_posts_widget_54185"></div></div></div><div><p><a href="https://img.itch.zone/aW1nLzMzNTc4NzIuanBn/original/Eh%2FX49.jpg" target="_blank" data-image_lightbox="true"><img src="https://img.itch.zone/aW1nLzMzNTc4NzIuanBn/347x500/O3hTpf.jpg"></a></p></div></div></div><div id="view_game_footer"><a href="https://itch.io/"><svg height="17" width="20" role="img" aria-hidden="" viewBox="0 0 262.728 235.452" version="1.1"><path d="M31.99 1.365C21.287 7.72.2 31.945 0 38.298v10.516C0 62.144 12.46 73.86 23.773 73.86c13.584 0 24.902-11.258 24.903-24.62 0 13.362 10.93 24.62 24.515 24.62 13.586 0 24.165-11.258 24.165-24.62 0 13.362 11.622 24.62 25.207 24.62h.246c13.586 0 25.208-11.258 25.208-24.62 0 13.362 10.58 24.62 24.164 24.62 13.585 0 24.515-11.258 24.515-24.62 0 13.362 11.32 24.62 24.903 24.62 11.313 0 23.773-11.714 23.773-25.046V38.298c-.2-6.354-21.287-30.58-31.988-36.933C180.118.197 157.056-.005 122.685 0c-34.37.003-81.228.54-90.697 1.365zm65.194 66.217a28.025 28.025 0 0 1-4.78 6.155c-5.128 5.014-12.157 8.122-19.906 8.122a28.482 28.482 0 0 1-19.948-8.126c-1.858-1.82-3.27-3.766-4.563-6.032l-.006.004c-1.292 2.27-3.092 4.215-4.954 6.037a28.5 28.5 0 0 1-19.948 8.12c-.934 0-1.906-.258-2.692-.528-1.092 11.372-1.553 22.24-1.716 30.164l-.002.045c-.02 4.024-.04 7.333-.06 11.93.21 23.86-2.363 77.334 10.52 90.473 19.964 4.655 56.7 6.775 93.555 6.788h.006c36.854-.013 73.59-2.133 93.554-6.788 12.883-13.14 10.31-66.614 10.52-90.474-.022-4.596-.04-7.905-.06-11.93l-.003-.045c-.162-7.926-.623-18.793-1.715-30.165-.786.27-1.757.528-2.692.528a28.5 28.5 0 0 1-19.948-8.12c-1.862-1.822-3.662-3.766-4.955-6.037l-.006-.004c-1.294 2.266-2.705 4.213-4.563 6.032a28.48 28.48 0 0 1-19.947 8.125c-7.748 0-14.778-3.11-19.906-8.123a28.025 28.025 0 0 1-4.78-6.155 27.99 27.99 0 0 1-4.736 6.155 28.49 28.49 0 0 1-19.95 8.124c-.27 0-.54-.012-.81-.02h-.007c-.27.008-.54.02-.813.02a28.49 28.49 0 0 1-19.95-8.123 27.992 27.992 0 0 1-4.736-6.155zm-20.486 26.49l-.002.01h.015c8.113.017 15.32 0 24.25 9.746 7.028-.737 14.372-1.105 21.722-1.094h.006c7.35-.01 14.694.357 21.723 1.094 8.93-9.747 16.137-9.73 24.25-9.746h.014l-.002-.01c3.833 0 19.166 0 29.85 30.007L210 165.244c8.504 30.624-2.723 31.373-16.727 31.4-20.768-.773-32.267-15.855-32.267-30.935-11.496 1.884-24.907 2.826-38.318 2.827h-.006c-13.412 0-26.823-.943-38.318-2.827 0 15.08-11.5 30.162-32.267 30.935-14.004-.027-25.23-.775-16.726-31.4L46.85 124.08c10.684-30.007 26.017-30.007 29.85-30.007zm45.985 23.582v.006c-.02.02-21.863 20.08-25.79 27.215l14.304-.573v12.474c0 .584 5.74.346 11.486.08h.006c5.744.266 11.485.504 11.485-.08v-12.474l14.304.573c-3.928-7.135-25.79-27.215-25.79-27.215v-.006l-.003.002z"></path></svg></a><p><a href="https://itch.io/">itch.io</a><span>·</span><a href="https://browser-games.itch.io/">View all by browser games</a><span>·</span>Report<span>·</span>Embed<span>·</span></p><p>Updated <abbr title="08 January 2021 @ 18:16"> 2 days ago</abbr></p><div><p><a href="https://itch.io/games">Games</a> › <a href="https://itch.io/games/genre-rpg">Role Playing</a> › <a href="https://itch.io/games/free">Free</a></p></div></div></div></div></div>]]>
            </description>
            <link>https://browser-games.itch.io/baldursgate2</link>
            <guid isPermaLink="false">hacker-news-small-sites-25687261</guid>
            <pubDate>Fri, 08 Jan 2021 17:35:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Apache Beam for Search: Getting Started by Hacking Time]]>
            </title>
            <description>
<![CDATA[
Score 78 | Comments 8 (<a href="https://news.ycombinator.com/item?id=25686936">thread link</a>) | @clandry94
<br/>
January 8, 2021 | https://shopify.engineering/apache-beam-for-search-getting-started-by-hacking-time | <a href="https://web.archive.org/web/*/https://shopify.engineering/apache-beam-for-search-getting-started-by-hacking-time">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
  <p>To create relevant search, processing clickstream data is key: you frequently want to promote search results that are being clicked on and purchased, and demote those things users don’t love.</p>
<p>Typically search systems think of processing clickstream data as a batch job run over historical data, perhaps using a system like Spark. But on Shopify’s Discovery team, we ask the question: What if we could auto-tune relevance in real-time as users interact with search results—not having to wait days for a large batch job to run?</p>
<p>At Shopify—this is what we’re doing! We’re using streaming data processing systems that can process both real-time and historic data to enable real-time use cases ranging from simple auto boosting or down boosting of documents, to computing aggregate click popularity statistics, building <a href="https://elasticsearch-learning-to-rank.readthedocs.io/en/latest/core-concepts.html#judgments-expression-of-the-ideal-ordering" target="_blank" rel="nofollow noopener noreferrer">offline search evaluation sets</a>, and on to more complex reinforcement learning tasks.</p>
<p>But this article is introducing you to the streaming system themselves. In particular, to Apache Beam. And the most important thing to think about is <em>time</em> with those streaming systems. So let’s get started!</p>
<h2>What Exactly is Apache Beam?</h2>
<p><a href="https://beam.apache.org/" target="_blank" title="Apache Beam" rel="nofollow noopener noreferrer">Apache Beam</a> is a unified batch and stream processing system. This lets us potentially unify historic and real-time views of user search behaviors in one system. Instead of a batch system, like Spark, to churn over months of old data, and a separate streaming system, like Apache Storm, to process the live user traffic, Beam hopes to keep these workflows together.</p>
<p>For search, this is rather exciting. It means we can build search systems that both rely on historic search logs while perhaps being able to live-tune the system for our users’ needs in various ways.</p>
<p>Let’s walk through an early challenge everyone faces with Beam: that of <strong><em>time!</em></strong> Beam is a kind of time machine that has to reorder events in their right spot after getting annoyingly delayed by lots of intermediate processing and storage step. This is one of the core complications of a streaming system - how long do we wait? How do we deal with late or out of order data?</p>
<p>So to get started with Beam, the first thing you’ll need to do is Hack Time!</p>
<h2>The Beam Time Problem</h2>
<p>At the core of Apache Beam are <a href="https://beam.apache.org/documentation/programming-guide/#creating-a-pipeline" target="_blank" rel="nofollow noopener noreferrer">pipelines</a>. They connect a source through various processing steps to finally a sink.&nbsp;&nbsp;</p>
<p>Data flowing through a pipeline is timestamped. When you consider a streaming system, this makes sense. We have various delays as events flow from browsers, through APIs, and other data systems. Finally the events arrive at our Beam pipeline. They can easily be out-of-order or delayed. Beam source APIs, like the one for <a href="https://beam.apache.org/releases/javadoc/2.5.0/org/apache/beam/sdk/io/kafka/KafkaIO.html" target="_blank" rel="nofollow noopener noreferrer">Kafka</a>, maintain a moving view of the event data to emit well-ordered events known as a <a href="https://beam.apache.org/documentation/programming-guide/#watermarks-and-late-data" target="_blank" rel="nofollow noopener noreferrer">watermark</a>.</p>
<p>If we don’t give our Beam source good information on how to build a timestamp, we’ll drop events or receive them in the wrong order. But even more importantly for search, we likely must combine different streams of data to build a single view on a search session or query, like below:</p>
<figure><img alt="combine different streams of data to build a single view on a search session or query, like below" data-src="https://cdn.shopify.com/s/files/1/0779/4361/files/Beam_for_Search__Getting_started_with_the_Beam_time_machine.png?format=jpg&amp;quality=90&amp;v=1610128718" src="https://cdn.shopify.com/s/files/1/0779/4361/files/Beam_for_Search__Getting_started_with_the_Beam_time_machine.png?format=jpg&amp;quality=90&amp;v=1610128718"></figure>
<p>Joining (a Beam topic for another day!) needs to look back over each source’s watermark and ensure they’re aligned in time before deciding that sufficient time has elapsed before moving on. But before you get to the complexities of streaming joins, replaying with accurate timestamps is the first milestone on your Beam-for-clickstream journey.</p>
<h2>Configuring the Timestamp Right at the Source</h2>
<p>Let’s set up a simple Beam pipeline to explore Beam. Here we’ll use Kafka in Java as an example. You can see the full source code <a href="https://gist.github.com/geekigirl/738ead73033ae673483ab9690452f10f" target="_blank" title="Timestamp policy example with Kafka source with Apache BEAM" rel="nofollow noopener noreferrer">in this gist</a>.</p>
<p>Here we’ll set up a Kafka source, the start of a pipeline producing a custom SearchQueryEvent stored in a search_queries_topic.</p>

<p>You’ll notice we have information on the topic/servers to retrieve the data, along with how to deserialize the underlying binary data. We might add further processing steps to transform or process our SearchQueryEvents, eventually sending the final output to another system.</p>
<p>But nothing about <strong>time</strong> yet. By default, the produced SearchQueryEvents will use Kafka <em>processing</em> time. That is, when they’re read from Kafka. This is the least interesting for our purposes. We care about when users actually searched and clicked on results.</p>
<p>More interesting is when the event was created in a Kafka client. Which we can add here:</p>
<p><code>.withCreateTime(Duration.<em>standardMinutes</em>(5))</code></p>
<p>You’ll notice above, when we use create time below, we need to give the source’s Watermark a tip for how out of order event times might be. For example, below we instruct the Kafka source to use create time, but with a possible 5 minutes of discrepancy.&nbsp;</p>
<h2>Appreciating The Beam Time Machine</h2>
<p>Let’s reflect on what such a 5 minute possible delay actually means from the last snippet. Beam is kind of a time machine… How Beam bends space-time is where your mind can begin to hurt.</p>
<p>As you might be picking up, <em>event time </em>&nbsp;is quite different from <em>processing time</em>! So in the code snippet above, we’re *not* telling the computer to wait for 5 minutes of execution time for more data. No, the event time might be replayed from historical data, where 5 minutes of event time is replayed through our pipeline in mere milliseconds. Or it could be event time is really now, and we’re actively streaming live data for processing. So we DO indeed wait 5 real minutes!&nbsp;</p>
<p>Let’s take a step back and use a silly example to understand this. It’s really crucial to your Beam journey.&nbsp;</p>
<p>Imagine we’re super-robot androids that can watch a movie at 1000X speed. Maybe like Star Trek The Next Generation’s Lt Commander Data. If you’re unfamiliar, he could process input as fast as a screen could display! Data might say “Hey look, I want to watch the classic 80s movie, The Goonies, so I can be a cultural reference for the crew of the Enterprise.”&nbsp;</p>
<p>Beam is like watching a movie in super-fast forward mode with chunks of the video appearing possibly delayed or out of order relative to other chunks in movie time. In this context we have two senses of time:</p>
<ul>
<li>Event Time: the timestamp in the actual 1h 55 minute runtime of The Goonies aka movie time.</li>
<li>Processing Time: the time we actually experience The Goonies (perhaps just a few minutes if we’re super-robot androids like Data).</li>
</ul>
<p>So Data tells the Enterprise computer “Look, play me The Goonies as fast as you can recall it from your memory banks.” And the computer has various hiccups where certain frames of the movie aren’t quite getting to Data’s screen to keep the movie in order.&nbsp;</p>
<p>Commander Data can tolerate missing these frames. So Data says “Look, don’t wait more than 5 minutes in *movie time* (aka event time) before just showing me what you have so far of that part of the movie. This lets Data watch the full movie in a short amount of time, dropping a tolerable number of movie frames.</p>
<p>This is just what Beam is doing with our search query data. Sometimes it’s replaying days worth of historic search data in milliseconds, and other times we’re streaming live data where we truly must wait 5 minutes for reality to be processed. Of course, the right delay might not be 5 minutes, it might be something else appropriate to our needs.&nbsp;</p>
<p>Beam has other primitives such as <a href="https://beam.apache.org/releases/javadoc/2.0.0/org/apache/beam/sdk/transforms/windowing/Window.html" target="_blank" rel="nofollow noopener noreferrer">windows</a> which further inform, beyond the source, how data should be buffered or collected in units of time. Should we collect our search data in daily windows? Should we tolerate late data? What does subsequent processing expect to work over? Windows also work with the same time machine concepts that must be appreciated deeply to work with Beam.</p>
<h2>Incorporating A Timestamp Policy</h2>
<p>Beam might know a little about Kafka, but it really doesn’t know anything about <strong>our</strong> data model. Sometimes we need even more control over the definition of time in the Beam time machine.</p>
<p>For example, in our previous movie example, movie frames perhaps have some field informing us of how they should be arranged in movie time. If we examine our SearchQueryEvent, we also see a specific timestamp embedded in the data itself:</p>
<p><code>public class SearchQueryEvent {</code></p>
<p><code>&nbsp;&nbsp;&nbsp;public final String queryString;</code></p>
<p><code>&nbsp;&nbsp;&nbsp;public final Instant searchTimestamp;</code></p>
<p><code>…</code></p>
<p><code>}</code></p>
<p>Well Beam sources can often be configured to use a custom event time like our searchTimestamp. We just need to make a TimestampPolicy. We simply provide a simple function-class that takes in our record (A key-value of Long-&gt;SearchQueryEvent) and returns a timestamp:</p>

<p>We can use this to create our own timestamp policy:</p>

<p>Here, we’ve passed in our own function, and we’ve given the same allowed delay (5 minutes). This is all wrapped up in a factory class TimestampPolicyFactory SearchQueryTimestampPolicyFactory (now if that doesn’t sound like a Java class name, I don’t know what does ;) )</p>
<p>We can add our timestamp policy to the builder:</p>
<p><code>.withTimestampPolicyFactory(new SearchQueryTimestampPolicyFactory())</code></p>
<h2>Hacking Time!</h2>
<p>Beam is about hacking time, I hope you’ve appreciated this walkthrough of some of Beam’s capabilities. If you’re interested in joining me on building Shopify’s future in search and discovery, please check out these great job postings!</p>
<p>Doug Turnbull is a Sr. Staff Engineer in Search Relevance at Shopify. He is known for writing the book “Relevant Search”, contributing to “AI Powered Search”, and creating relevance tooling for Solr and Elasticsearch like Splainer, Quepid, and the Elasticsearch Learning to Rank plugin. Doug’s team at Shopify helps Merchants make their products and brands more discoverable. If you’d like to work with Doug, send him a Tweet at <a href="https://twitter.com/softwaredoug" target="_blank" title="Doug Turnbull on Twitter" rel="nofollow noopener noreferrer">@softwaredoug</a>!</p>
</div></div>]]>
            </description>
            <link>https://shopify.engineering/apache-beam-for-search-getting-started-by-hacking-time</link>
            <guid isPermaLink="false">hacker-news-small-sites-25686936</guid>
            <pubDate>Fri, 08 Jan 2021 17:13:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Yeti Foods is a Facebook-Free business]]>
            </title>
            <description>
<![CDATA[
Score 37 | Comments 26 (<a href="https://news.ycombinator.com/item?id=25686437">thread link</a>) | @shafyy
<br/>
January 8, 2021 | https://blog.yeticheese.com/yeti-is-a-facebook-free-business/ | <a href="https://web.archive.org/web/*/https://blog.yeticheese.com/yeti-is-a-facebook-free-business/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
				<p>Yeti will not use any of Facebook's products from today onwards.</p><p>Why?</p><p>Facebook controls some of the most used apps such as WhatsApp, Instagram, Messenger, and of course, Facebook. They have shown time over time that they don't care about their users' privacy and are willing to do anything to maximize their stronghold and power.</p><p>It's clear that consumers and society always lose when one company becomes too big. That's why there are monopoly and anti-trust laws that try to prevent and regulate such cases.</p><p>Tech companies such as Facebook and Google have new business models and therefore have managed to evade those laws. Luckily, this is changing, as governments are introducing more laws that aim at breaking up and regulating these companies to protect consumers.</p><p>But we can't only rely on our governments to take action. Every single consumer's decisions also matter. If enough people stop using Facebook's products, their power will diminish.</p><p>This is easier said than done, because these products have network effects. That means that the value of the product to the user increases exponentially for every additional user. For example, you wouldn't use WhatsApp if none of your friends were on it. At the same time, it's much harder for you to switch to a different messaging app like Signal because you need to convince all your friends to join, too.</p><p>It's hard but not impossible.</p><p>From today onwards, we pledge that Yeti will not use any products by Facebook. As stated in <a href="https://m.signalvnoise.com/become-a-facebook-free-business/">Basecamp's blog post</a>, which inspired our decision, this means:</p><ol><li>We do not buy advertisement on Facebook, Messenger, Instagram, or WhatsApp.</li><li>We do not use Facebook, Messenger, Instagram, or WhatsApp to promote or represent our business or to communicate with our customers.</li><li>We do not assist Facebook in its data collection regime through use of Facebook social Like buttons or by offering Facebook logins.</li></ol><p>This was not an easy decision. For example, Instagram and Facebook are important platform for us to stay in touch with current and prospective consumers. It's clear that by taking this decision, we will lose customers and money. However, it is the right thing to do and this is something that's more important than financial success.</p><p>As a customer, you can be assured that none of the money you spend with us goes to Facebook.</p><p>Now, go and <a href="https://yeticheese.com/product/yeti-no-1">buy our cheese</a> so we can make up for the lost revenue 😝</p>
			</section></div>]]>
            </description>
            <link>https://blog.yeticheese.com/yeti-is-a-facebook-free-business/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25686437</guid>
            <pubDate>Fri, 08 Jan 2021 16:38:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[India could get nasal vaccine against Covid-19 soon]]>
            </title>
            <description>
<![CDATA[
Score 55 | Comments 11 (<a href="https://news.ycombinator.com/item?id=25685187">thread link</a>) | @jangid
<br/>
January 8, 2021 | https://www.indiatoday.in/coronavirus-outbreak/story/india-nasal-coronavirus-vaccine-soon-trials-begin-nagpur-1756780-2021-01-07 | <a href="https://web.archive.org/web/*/https://www.indiatoday.in/coronavirus-outbreak/story/india-nasal-coronavirus-vaccine-soon-trials-begin-nagpur-1756780-2021-01-07">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody"><p>A nasal Covid-19 vaccine could be a reality in India soon with Bharat Biotech, the Indian vaccine maker, all set to start phase 1 and 2 trials of a nasal vaccine at Gillurkar Multi Speciality Hospital in Nagpur.</p><p>Bharat Biotech’s head Dr Krishna Ella said on Thursday, "We are working on a nasal vaccine and have partnered with the Washington University School of Medicine. We are working on a single dose vaccine compare to two-dose inactivated vaccine. Research has proven that the nasal vaccine is the best choice. Coronavirus also attacks through the nose."</p><p>"We are <a href="https://www.indiatoday.in/coronavirus-outbreak/vaccine-updates/story/bharat-biotech-founder-assures-safety-of-covaxin-nasal-vaccine-1755712-2021-01-04" target="_blank">all set to host the trials for the nasal Covaxin in the next two weeks</a>. Enough scientific evidence is available that vaccines given through nasal route are more effective than injected ones. Bharat Biotech is in the process to submit a proposal to the DCGI shortly," said Dr Chandrashekar Gillurkar.</p><p>The trials will be conducted on at least 30-45 healthy volunteers above the age of 18 till the age of 65 years at four trial sites in the country -- Bhuvneshwar, Pune, Nagpur and Hyderabad.</p><p>Presently, Bharat Biotech is working on two intranasal vaccines -- one with US-based vaccine maker FluGen and scientists from the University of Wisconsin Madison and the other with the University of Washington School of Medicine.</p><p>Experts say that the nasal variant of the Covid-19 vaccine, which is currently under trial in the US, could play a major role in stopping transmission of the virus.</p><p><em><strong>Read: <a href="https://www.indiatoday.in/coronavirus-outbreak/vaccine-updates/story/confused-about-covid-19-vaccines-this-is-for-you-1756786-2021-01-07" target="_blank" title="Confused about Covid-19 vaccines? This is for you">Confused about Covid-19 vaccines? This is for you</a></strong></em></p><h3><span><strong>WHAT IS NASAL VACCINE?</strong></span></h3><p>Unlike other Covid-19 vaccines that are administered intramuscularly (or through the muscles), this one is delivered via the nose, which is also an initial point of infection in humans.</p><p>A study done by the University of Washington School of Medicine in St Louis found that the nasal delivery route created a strong immune response throughout the body, but it was particularly effective in the nose and respiratory tract, preventing the infection from taking hold in the body.</p><p><em><strong>Read: <a href="https://www.indiatoday.in/coronavirus-outbreak/story/vaccination-doesn-t-guarantee-100-protection-wearing-mask-is-must-experts-1756766-2021-01-07" target="_blank" title="Vaccination doesn't guarantee 100% protection, wearing mask is must: Experts">Vaccination doesn't guarantee 100% protection, wearing mask is must: Experts</a></strong></em></p><h3><span><strong>ARE NASAL VACCINES BETTER THAN INJECTIONS?</strong></span></h3><p>Experts say the nasal Covid-19 vaccine has the potential to become a game-changer because injecting the vaccine intramuscularly only protects the lower lung. A nasal vaccine can protect both the upper and lower lung and can prevent transmission of the virus as well as an infection.</p><p>Dr Samiran Panda, senior epidemiologist at Indian Council of Medical Research said nasal vaccine provides benefits such as faster absorption, lesser volume and no use of syringes.</p><p> <img data-src="https://akm-img-a-in.tosshub.com/indiatoday/images/bodyeditor/202101/PHOTO-2021-01-07-23-05-59-x1280.jpg?CsWamucYQxVXvG9OqXSQo33RxTxirvDo" src="https://akm-img-a-in.tosshub.com/indiatoday/images/bodyeditor/202101/PHOTO-2021-01-07-23-05-59-x1280.jpg?CsWamucYQxVXvG9OqXSQo33RxTxirvDo" alt=""></p><p>"There are two arms of the immune system in the body - one is antibody or protein and one is cellular immunity. <a href="https://www.indiatoday.in/coronavirus-outbreak/story/mucosal-immunity-prevent-covid-outbreak-1745369-2020-11-30" target="_blank">The mucosal immunity is created</a> when administered a nasal vaccine against those infections that enter our body through the nose or respiratory tract. Coronavirus impacts the respiratory tract the most. Therefore, the nasal vaccine is much better. Antibodies will be secreted directly into the nasal mucous membrane, where you need more concentration of the antibody because it is where the infection begins from."</p><p><strong>Faster absorption:</strong></p><p>When administered orally or nasally, the antigen is presented to the mucous membrane, the absorption is much better and it quickly goes to the lymph nodes. There is an effective presentation of the viral antigen directed at the infection.</p><p><strong>Lesser volume:</strong></p><p>Earlier rabies vaccine used to be given in the subcutaneous fat and now is being given intra-dermal injection route (through the skin). A similar immune response can be generated with a much smaller dose.</p><h3><span><strong>INTERNATIONAL TRIALS</strong></span></h3><p>An influenza vaccine called FLUmist, delivered via the nose, uses the weakend form of live influenza virus but can’t be administered to certain groups including those whose immune systems are compromised by cancer, HIV and diabetes.</p><p>In contrast, the new coronavirus intranasal vaccine does not use a live virus capable of replication, presumably making it safer.</p><p>The United Kingdom's Medicines and Healthcare Products Regulatory Agency (MHRA), has approved Open Orphan and Codagenix to conduct a phase 1 study of its nasal Covid-19 vaccine in the country.</p><p><strong>Also Read | <a href="https://www.indiatoday.in/coronavirus-outbreak/vaccine-updates/story/bharat-biotech-founder-assures-safety-of-covaxin-nasal-vaccine-1755712-2021-01-04" target="_blank" title="Bharat Biotech founder assures safety of Covaxin, pins hopes on its new nasal vaccine">Bharat Biotech founder assures safety of Covaxin, pins hopes on its new nasal vaccine</a></strong></p><p><strong>Also Read | <a href="https://www.indiatoday.in/coronavirus-outbreak/video/covishield-covaxin-vaccines-will-be-available-in-india-soon-health-minister-harsh-vardhan-1756772-2021-01-07">Covishield, Covaxin vaccines will be available in India soon: Health minister Harsh Vardhan</a></strong></p><p><strong>Also Read | <a href="https://www.indiatoday.in/coronavirus-outbreak/story/vaccination-doesn-t-guarantee-100-protection-wearing-mask-is-must-experts-1756766-2021-01-07">Vaccination doesn't guarantee 100% protection, wearing mask is must: Experts</a></strong></p></div></div>]]>
            </description>
            <link>https://www.indiatoday.in/coronavirus-outbreak/story/india-nasal-coronavirus-vaccine-soon-trials-begin-nagpur-1756780-2021-01-07</link>
            <guid isPermaLink="false">hacker-news-small-sites-25685187</guid>
            <pubDate>Fri, 08 Jan 2021 14:45:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Collections: That Dothraki Horde, Part IV: Screamers and Howlers]]>
            </title>
            <description>
<![CDATA[
Score 47 | Comments 19 (<a href="https://news.ycombinator.com/item?id=25682359">thread link</a>) | @Illniyar
<br/>
January 7, 2021 | https://acoup.blog/2021/01/08/collections-that-dothraki-horde-part-iv-screamers-and-howlers/ | <a href="https://web.archive.org/web/*/https://acoup.blog/2021/01/08/collections-that-dothraki-horde-part-iv-screamers-and-howlers/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<p>This is the fourth part of a four part (<a href="https://acoup.blog/2020/12/04/collections-that-dothraki-horde-part-i-barbarian-couture/">I</a>, <a href="https://acoup.blog/2020/12/11/collections-that-dothraki-horde-part-ii-subsistence-on-the-hoof/">II</a>, <a href="https://acoup.blog/2020/12/18/collections-that-dothraki-horde-part-iii-horse-fiddles/">III</a>) look at the Dothraki from George R. R. Martin’s <em>A Song of Ice and Fire</em> and HBO’s <em>Game of Thrones</em>.  We’re looking at, in particular, if Martin’s claim that the Dothraki are “an amalgam of a number of steppe and plains cultures” can be sustained in the face of even basic knowledge about historical Steppe and Great Plains nomadic peoples.</p>



<p>Last week, we <a href="https://acoup.blog/2020/12/18/collections-that-dothraki-horde-part-iii-horse-fiddles/">concluded </a>that the vast majority of Dothraki culture, social organization, economic practices and family structure are effectively completely untethered from the historical realities of effectively any of the literally dozens of historical Great Plains Native Americans or Steppe nomads.  This week, we’re going to close out our look by discussing Dothraki warfare.  We’ll start with the visual – weapons and armor – and then move to the conceptual – strategy, operations and tactics.</p>



<p>And as always, if you like what you are reading here, please share it; if you really like it, you can support me on <a href="https://www.patreon.com/user?u=20122096">Patreon</a>. And if you want updates whenever a new post appears, you can click below for email updates or follow me on twitter (@BretDevereaux) for updates as to new posts as well as my occasional ancient history, foreign policy or military history musings.</p>






<p>Finally, as a reminder both of what we are investigating, <strong>the key statement we are really assessing here is <a href="https://www.westeros.org/Citadel/SSM/Entry/6040/">this one by George R.R. Martin</a>:</strong></p>



<blockquote><p>The Dothraki were actually fashioned as an amalgam of a number of steppe and plains cultures… Mongols and Huns, certainly, but also Alans, Sioux, Cheyenne, and various other Amerindian tribes… seasoned with a dash of pure fantasy.</p></blockquote>



<p>It is not the <em>existence</em> of a fantasy culture which draws our attention, but the explicit declaration that this fantasy culture is not merely inspired, but ‘fashioned as an amalgam’ of real cultures, which both existed in the past <em>and still exist today</em>, with only ‘a dash of pure fantasy.’  That line is important, to be clear, <strong>because it presents the fictional Dothraki as a statement on historical Native American and Eurasian nomads</strong> and – when combined with Martin’s statements that he relies on history to inform his work – that this statement is based in some sort of historical reality.</p>



<p>Which it isn’t.  But we’re getting ahead of ourselves.</p>



<h2>Where There’s a Whip…</h2>



<p>The Dothraki are described as having three main weapons: <strong>bows </strong>(<em>AGoT</em>, 86, 555, 558, 597, 669), <strong>whips </strong>(<em>AGoT</em>, 86, 194, 493, 555, 596, 669) and a <strong>curved sword called an <em>arakh</em></strong> (<em>AGoT</em> 85, 86, 327, 493, 555, 556, 559, 560, 596, 597, 669, 674); <strong>of these, the <em>arakh</em> is clearly the most prominent</strong> (I am sure I have missed a reference to a weapon here or there, but I hope the citations here give some sense of the relative weight each is given – the <em>arakh</em> is the most frequently mentioned by some distance).  When a Dothraki warrior enters <em>Vaes Dothrak</em>, each, “unbelted his <em>arakh</em> and handed it to a waiting slave, and any other weapons he carried as well” – after the <em>arakh</em>, the other weapons are seemingly afterthoughts (<em>AGoT</em>, 327).  The prominence of the <em>arakh</em> in the narrative is underscored by the fact that it is the only one of these weapons whose name we learn in Dothraki, or which is described in terms of its shape or special function (<em>AGoT</em>, 85), while the bows and whips remain just bows and whips (ironic, as it was Steppe <em>bows</em>, not Steppe swords, which were unusual).</p>



<p>We might dismiss this as simply an accident of Daenerys’ perspective – that, being Westerosi, she focuses on the weapon most meaningful to the Westerosi – but that’s clearly not true.  After all, the <strong>offering of an <em>arakh</em> is how Daenerys’ loyal followers demonstrate their fealty to her</strong>, in a ceremony that is clearly Dothraki, not Westerosi (<em>AGoT</em>, 674).  It is also, I should note,<a href="https://awoiaf.westeros.org/index.php/Arakh"> the only weapon we see <em>non</em>-Dothraki using that is clearly identified as being foreign and typical of the Dothraki</a>.  It remains special through the eyes of multiple point-of-view characters, including military men.</p>



<p>(And, as an aside, now that we are this far in, it seems obvious but worth saying that the fact that Martin has no Dothraki viewpoint characters in his narrative is hardly a saving grace; it merely intensifies the ‘view of a savage culture from outside’ effect.  As we’ll see, this makes perfect sense given what seem to be the actual inspirations for his depiction.)</p>



<p><strong>The prominence of a curved iron (or steel) sword lets us rule out a Great Plains Native American inspiration for this kit right out</strong>; the sword was never a significant part of Plains Native American armament (the lack of tool-metal production in the Americas prior to European contact means that there was no indigenous sword-making tradition, although the <a href="https://en.wikipedia.org/wiki/Macuahuitl"><em>maquahuitl</em> </a>represents a clever sort of ‘sharpened club’ design).  Even after contact, it’s hard to avoid the conclusion that the expense of trading for a sword wouldn’t have been justified by its utility over a steel axe which might also double as a tool (on axes, see W. Lee, “The Military Revolution of Native North America: Firearms, Forts and Politics” in <em>Empires and Indigenes</em> (2011), 62-3).  <strong>So we must turn to the Eurasian Steppe</strong>.</p>



<p><strong>And immediately we run into problems</strong>, not that any of these weapons are <em>wrong</em> per se, but <strong>that their proportion and prominence is all mixed up and that there are other, far more important weapons missing.</strong></p>



<p><strong>For a Steppe nomad, by far, above and away, the most important weapon was the bow.</strong>  The Armenians literally called the Mongols “the nation of archers” (May, <em>Mongol Art of War</em>, 43).  Nomads spent the most time learning the bow (May, <em>op. cit.</em> 42-49) and it was the one indispensable weapon.  Indeed, so indispensable that nomads were generally required to have several; the <em>Liao Shi</em> records that Khitan nomad warriors were required to possess four bows and 400 arrows, while John de Plano Carpini reports that the Mongols all needed to have 2-3 bows and three larger quivers (May, <em>op. cit. </em>49-50).  <strong>The Steppe bow itself would also have looked unusual in both shape and construction</strong> to a Westerosi observer either strung or unstrung – they were composite bows, made with a wood core, a backing of horn and a rigid end-piece (called a <em>siyah</em> in Arabic) and were generally drawn with the use of a thumb-ring to reduce strain on the thumb (May, <em>op. cit.</em>, 50-1).  This unique construction allowed these bows to reach draw weights and launch energies equivalent to the far larger yew longbows of England and Wales and still be compact enough to use from horseback.</p>



<div><figure><img data-attachment-id="5819" data-permalink="https://acoup.blog/ilkhanidhorsearcher-2/" data-orig-file="https://acoupdotblog.files.wordpress.com/2021/01/ilkhanidhorsearcher.jpg" data-orig-size="450,350" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="ilkhanidhorsearcher" data-image-description="" data-medium-file="https://acoupdotblog.files.wordpress.com/2021/01/ilkhanidhorsearcher.jpg?w=300" data-large-file="https://acoupdotblog.files.wordpress.com/2021/01/ilkhanidhorsearcher.jpg?w=450" src="https://acoupdotblog.files.wordpress.com/2021/01/ilkhanidhorsearcher.jpg?w=450" alt="" srcset="https://acoupdotblog.files.wordpress.com/2021/01/ilkhanidhorsearcher.jpg 450w, https://acoupdotblog.files.wordpress.com/2021/01/ilkhanidhorsearcher.jpg?w=150 150w, https://acoupdotblog.files.wordpress.com/2021/01/ilkhanidhorsearcher.jpg?w=300 300w" sizes="(max-width: 450px) 100vw, 450px"><figcaption><a href="https://en.wikipedia.org/wiki/Mongols#/media/File:IlkhanidHorseArcher.jpg">Via Wikipedia</a>, a 13th century Mongol horse archer.  Lightly armored, he carries a bow (and a fancy hat) but no sword.</figcaption></figure></div>



<p>(I should note that the bow was <em>also</em> the paramount weapon for the Native American horse-borne nomads of the Great Plains, at least until it came into competition with firearms, though my understanding is that Native American bows were not as powerful as Steppe bows).</p>



<div><figure><img loading="lazy" data-attachment-id="5821" data-permalink="https://acoup.blog/minolta-dsc/" data-orig-file="https://acoupdotblog.files.wordpress.com/2021/01/naadam_women_archery.jpg" data-orig-size="1920,2560" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;3.2&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;DiMAGE A1&quot;,&quot;caption&quot;:&quot;Minolta DSC&quot;,&quot;created_timestamp&quot;:&quot;1118415959&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;12.91796875&quot;,&quot;iso&quot;:&quot;100&quot;,&quot;shutter_speed&quot;:&quot;0.0003125&quot;,&quot;title&quot;:&quot;Minolta DSC&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="Minolta DSC" data-image-description="" data-medium-file="https://acoupdotblog.files.wordpress.com/2021/01/naadam_women_archery.jpg?w=225" data-large-file="https://acoupdotblog.files.wordpress.com/2021/01/naadam_women_archery.jpg?w=768" src="https://acoupdotblog.files.wordpress.com/2021/01/naadam_women_archery.jpg?w=768" alt="" width="596" height="795" srcset="https://acoupdotblog.files.wordpress.com/2021/01/naadam_women_archery.jpg?w=768 768w, https://acoupdotblog.files.wordpress.com/2021/01/naadam_women_archery.jpg?w=596 596w, https://acoupdotblog.files.wordpress.com/2021/01/naadam_women_archery.jpg?w=1192 1192w, https://acoupdotblog.files.wordpress.com/2021/01/naadam_women_archery.jpg?w=113 113w, https://acoupdotblog.files.wordpress.com/2021/01/naadam_women_archery.jpg?w=225 225w" sizes="(max-width: 596px) 100vw, 596px"><figcaption><a href="https://en.wikipedia.org/wiki/Mongols#/media/File:Naadam_women_archery.jpg">Via Wikipedia</a>, a modern Mongolian woman taking part in an archery contest.  You can see here the unique shape and multi-part construction of the Steppe bow (notice how the material on the tips, the belly and the spine of the bow are all different) which allows it so much power in such a small frame.<br>Also, notice the very nice and colorful traditional Mongolian clothing – not leather and rough furs!</figcaption></figure></div>



<p><strong>But even after the bow, the sword is not first.  Or even close to first.</strong>  Or, indeed, <em>even on the list</em>!  The Khitan regulations I mentioned included four bows, two spears (one ‘long’ and one ‘short’), a club, an axe and a halberd, but no sword.  John de Plano Carpini describes the full kit as two or three bows with quivers, an axe, ropes, and swords <em>only for the wealthy</em> (May. <em>op. cit.</em>, 50).  Speaking more broadly, May notes that spears (used as lances from horseback) seem universal in accounts of the Mongols, but “accounts are contradictory regarding whether these [swords] were universally used” (May, <em>op. cit.</em>, 52).  While May supposes that the <em>ughurgh-a</em>, the Mongolian lasso, might have been used in combat – and it may well have – we have no definitive evidence of it.  If it was ever a weapon, it doesn’t seem to have been an important one.</p>



<p><strong>In short, while the Dothraki’s weapons are an <em>arakh</em>-sword, a whip, and a bow in that order, the Mongol’s chief weapons were his bow, followed by his backup bow, followed by his <em>other </em>backup bow, followed by his spear, and then his axe and only then followed by a sword, should he have one, which he might well not</strong>.  The reason for preferring an axe or a spear for the humble nomad should not be too surprising – iron in quantity could be hard to get on the Steppe.  Spears and axes are not only weapons, but also useful hunting and survival tools; swords are generally weapons only.  <a href="https://acoup.blog/2020/09/18/collections-iron-how-did-they-make-it-part-i-mining/">Nomads generally cannot do their own metal working</a>, so swords would have to be imported.  Moreover, even in a melee, the first recourse would be to a spear, <a href="https://acoup.blog/2020/05/08/collections-the-battle-of-helms-deep-part-ii-total-warg/">whose reach on horseback was a huge advantage</a>,<strong> making a sword an expensive imported foreign luxury <em>backup</em> weapon with no additional utility</strong>.  Nevertheless, it’s clear that Steppe nomads, once successful and moving into agrarian areas, liked to acquire swords – swords are effective weapons! – but the sword was about the furthest thing from the core of Mongol culture the way the <em>arakh</em> is practically the <em>symbol</em> of Dothraki culture.</p>



<figure><img data-attachment-id="5816" data-permalink="https://acoup.blog/langshiming_mao/" data-orig-file="https://acoupdotblog.files.wordpress.com/2021/01/langshiming_mao.jpg" data-orig-size="1920,1118" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="langshiming_mao" data-image-description="" data-medium-file="https://acoupdotblog.files.wordpress.com/2021/01/langshiming_mao.jpg?w=300" data-large-file="https://acoupdotblog.files.wordpress.com/2021/01/langshiming_mao.jpg?w=1024" src="https://acoupdotblog.files.wordpress.com/2021/01/langshiming_mao.jpg?w=1024" alt="" srcset="https://acoupdotblog.files.wordpress.com/2021/01/langshiming_mao.jpg?w=1024 1024w, https://acoupdotblog.files.wordpress.com/2021/01/langshiming_mao.jpg?w=150 150w, https://acoupdotblog.files.wordpress.com/2021/01/langshiming_mao.jpg?w=300 300w, https://acoupdotblog.files.wordpress.com/2021/01/langshiming_mao.jpg?w=768 768w, https://acoupdotblog.files.wordpress.com/2021/01/langshiming_mao.jpg 1920w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption><a href="https://en.wikipedia.org/wiki/Mongols#/media/File:Langshiming_mao.JPG">Via Wikipedia</a>, a relatively late Mongol soldier (c. 1755) nevertheless shows nearly the full kit, including mail body defense, a long spear for use on horseback, arrows (the bow in its bow-case would have been on the other side) and, this being the 1700s, a musket.</figcaption></figure>



<p><strong>The other issue, of course, is the <em>arakh</em> itself.</strong>  Martin describes the weapons as “long razor-sharp blades, half sword and half scythe” (<em>AGoT</em>, 85) and goes back to that scythe analogy (e.g. <em>ASoS</em>, 245).  It seems generally asserted that what Martin means by this is something close to a scimitar (I have to confess, I haven’t found anywhere that Martin says …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://acoup.blog/2021/01/08/collections-that-dothraki-horde-part-iv-screamers-and-howlers/">https://acoup.blog/2021/01/08/collections-that-dothraki-horde-part-iv-screamers-and-howlers/</a></em></p>]]>
            </description>
            <link>https://acoup.blog/2021/01/08/collections-that-dothraki-horde-part-iv-screamers-and-howlers/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25682359</guid>
            <pubDate>Fri, 08 Jan 2021 07:10:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Over 100 Scientists and Doctors Call for Increased Vitamin D to Combat Covid-19]]>
            </title>
            <description>
<![CDATA[
Score 119 | Comments 107 (<a href="https://news.ycombinator.com/item?id=25680282">thread link</a>) | @kpfleger
<br/>
January 7, 2021 | https://vitamindforall.org/letter.html | <a href="https://web.archive.org/web/*/https://vitamindforall.org/letter.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p><span>#VitaminDforAll </span><span>(for questions or fact checking assistance, contact press@vitaminDforAll.org)</span></p><p id="h.mjz6soj7f435"><span>Over 100 </span><span>Scientists, Doctors, &amp; Leading Authorities</span><span>&nbsp;Call For </span><span>Increased</span><span>&nbsp;Vitamin D Use To Combat COVID-19</span></p><p><span>[Residents of the USA: Text “VitaminDforAll” to 50409 to send this to your state’s governor.]</span></p><p><span>Research shows low vitamin D levels almost certainly promote COVID-19 infections, hospitalizations, and deaths. Given its safety, </span><span>w</span><span>e call for immediate widespread increased vitamin D intakes</span><span>.</span></p><p><span>Vitamin D modulates thousands of genes and many aspects of immune function, both innate and adaptive. The scientific evidence</span><span>1</span><span>&nbsp;shows that:</span></p><p><span>Vitamin D is well known to be essential, but most people do not get enough. Two common definitions of inadequacy are deficiency &lt; 20ng/ml (50nmol/L), the target of most governmental organizations, and insufficiency &lt; 30ng/ml (75nmol/L), the target of several medical societies &amp; experts.</span><span>2</span><span>&nbsp;Too many people have levels below these targets. </span><span>Rates of vitamin D deficiency &lt;20ng/ml exceed 33% of the population in most of the world, and most estimates of insufficiency &lt;30ng/ml are well over 50% (but much higher in many countries).</span><span>3</span><span>&nbsp;Rates are even higher in winter, and several groups have notably worse deficiency: the overweight, those with dark skin (especially far from the equator), and care home residents. These same groups face increased COVID-19 risk.</span></p><p><span>It has been shown that 3875 IU (97mcg) daily is required for 97.5% of people to reach 20ng/ml, and 6200 IU (155mcg) for 30ng/ml,</span><span>4</span><span>&nbsp;intakes far above all national guidelines. Unfortunately, the report that set the US RDA included an admitted statistical error in which required intake was calculated to be ~10x too low.</span><span>4</span><span>&nbsp;Numerous calls in the academic literature to raise official recommended intakes had not yet resulted in increases by the time SARS-CoV-2 arrived. Now, many papers indicate that vitamin D affects COVID-19 more strongly than most other health conditions, with increased risk at levels &lt; 30ng/ml (75nmol/L) and severely greater risk &lt; 20ng/ml (50nmol/L).</span><span>1</span></p><p><span>Evidence to date </span><span>suggests </span><span>the possibility that the COVID-19 pandemic sustains itself in large part &nbsp;through infection of those with low vitamin D, and that deaths are concentrated largely in those with deficiency. The mere possibility that this is so should compel urgent gathering of more vitamin D data. </span><span>Even without more data</span><span>, </span><span>the </span><span>preponderance </span><span>of evidence indicates that </span><span>increased vitamin D would help reduce infections, hospitalizations, ICU admissions, &amp; deaths</span><span>.</span></p><p><span>Decades of safety data show that vitamin D has very low risk: </span><span>Toxicity would be extremely rare with the recommendations here. The risk of insufficient levels far outweighs any risk from levels that seem to provide most of the protection against COVID-19, and this is notably different from drugs. Vitamin D is much safer than steroids, such as dexamethasone, the most widely accepted treatment to have also demonstrated a large COVID-19 benefit. Vitamin D’s safety is more like that of face masks. </span><span>There is no need to wait for further clinical trials to increase use of something so safe, </span><span>especially when remedying high rates of deficiency/insufficiency should already be a priority</span><span>.</span></p><p><span>Therefore, we call on all governments, doctors, and healthcare workers worldwide to immediately recommend and implement efforts appropriate to their adult populations to increase vitamin D, at least until the end of the pandemic. Specifically to:</span></p><p><span>Many factors are known to predispose individuals to higher risk from exposure to SARS-CoV-2, such as age, being male, comorbidities, etc., but </span><span>inadequate</span><span>&nbsp;v</span><span>itamin D is by far the most easily and quickly </span><span>modifiable</span><span>&nbsp;risk factor with abundant evidence to support a large effect</span><span>. Vitamin D is inexpensive and has negligible risk compared to the considerable risk of COVID-19.</span></p><p><span>5</span><span>&nbsp;The following include 4000 IU within their tolerable intakes in official guidelines: NAM (US, Canada), SACN (UK), EFSA (Europe), Endocrine Society (international), Nordic countries, The Netherlands, Australia &amp; New Zealand, UAE, and the American Geriatrics Soc. (USA, elderly). No major agency specifies a lower tolerable intake limit. The US NAM said 4000 IU “is likely to pose no risk of adverse health effects to almost all individuals.” See also [</span><span><a href="https://pubmed.ncbi.nlm.nih.gov/32180081/">Giustina et al ‘20</a></span><span>].</span></p><p><span>The signatories below endorse this letter. Affiliations do not imply endorsement of the letter by the institutions themselves.</span></p><p><span>This letter takes no position on other public health measures besides vitamin D. Personal views of individual signatories on any other matter do not represent the group as a whole.</span></p><p><span>All signatories declare no conflicts of interest except as noted.</span></p><p><span>To emphasize: </span><span>The organizing signatories have no conflicts of interest in this area (financial or otherwise)</span><span>, nor have they done research in this area prior to 2020.</span></p><div><tbody><tr><td colspan="1" rowspan="1"><p><span>Signatories (185)</span></p></td><td colspan="1" rowspan="1"><p><span>recom- mended intake</span></p></td><td colspan="1" rowspan="1"><p><span>personal daily intake</span></p></td></tr><tr><td colspan="1" rowspan="1"><p><span>Dr. Karl Pfleger</span><span>, PhD AI &amp; Computer Science, Stanford. Former Google Data Scientist. Biotechnology Investor, AgingBiotech.info, San Francisco, CA, USA. (organizing signatory)</span></p></td><td colspan="1" rowspan="1"><p><span>4000 IU</span></p></td><td colspan="1" rowspan="1"><p><span>7000 IU</span></p></td></tr><tr><td colspan="1" rowspan="1"><p><span>Dr. Gareth Davies</span><span>, PhD Medical Physics, Imperial College, London, UK. Codex World’s Top 50 Innovator 2019. Independent Researcher. Lead author of “</span><span><a href="https://www.medrxiv.org/content/10.1101/2020.05.01.20087965v3">Evidence Supports a Causal Role for Vitamin D Status in COVID-19 Outcomes</a></span><span>.” (organizing signatory)</span></p></td><td colspan="1" rowspan="1"><p><span>4000 IU</span></p></td><td colspan="1" rowspan="1"><p><span>10,000 IU</span></p></td></tr><tr><td colspan="1" rowspan="1"><p><span>Dr. Bruce W Hollis</span><span>, PhD. Professor of Pediatrics, Medical University of South Carolina, USA.</span></p></td><td colspan="1" rowspan="1"><p><span>4000 IU</span></p></td><td colspan="1" rowspan="1"><p><span>6000 IU</span></p></td></tr><tr><td colspan="1" rowspan="1"><p><span>Dr. Barbara J Boucher</span><span>, MD, FRCP (London). </span><span>Honorary Professor (Medicine), Blizard Institute, Bart's &amp; The London School of Medicine and Dentistry, Queen Mary University of London, UK. </span><span>(significantly contributing signatory)</span></p></td><td colspan="1" rowspan="1"><p><span>4000 IU</span></p></td><td colspan="1" rowspan="1"><p><span>2000 IU</span></p></td></tr><tr><td colspan="1" rowspan="1"><p><span>Dr. Ashley Grossman</span><span>, MD FRCP FMedSci. Emeritus Professor of Endocrinology, University of Oxford, UK. Professor of Neuroendocrinology, Barts and the London School of Medicine. 2020 Endocrine Society Laureate Award.</span></p></td><td colspan="1" rowspan="1"><p><span>2000 IU</span></p></td><td colspan="1" rowspan="1"><p><span>2200 IU</span></p></td></tr><tr><td colspan="1" rowspan="1"><p><span>Dr. Gerry Schwalfenberg</span><span>, MD, CCFP, FCFP. Assistant Clinical Professor in Family Medicine, University of Alberta, Canada.</span></p></td><td colspan="1" rowspan="1"><p><span>4000 IU</span></p></td><td colspan="1" rowspan="1"><p><span>5000 IU</span></p></td></tr><tr><td colspan="1" rowspan="1"><p><span>Dr. Giovanna Muscogiuri</span><span>, MD PhD. Associate Editor, European Journal of Clinical Nutrition. </span><span>Department of Clinical Medicine and Surgery, Section of Endocrinology, University "Federico II" of Naples, Naples, Italy.</span><span>.</span></p></td><td colspan="1" rowspan="1"><p><span>4000 IU</span></p></td><td colspan="1" rowspan="1"><p><span>1000 IU</span></p></td></tr><tr><td colspan="1" rowspan="1"><p><span>Dr. Michael F. Holick</span><span>, PhD MD. Professor Medicine, Physiology and Biophysics and Molecular Medicine, Director Vitamin D, Skin and Bone Research Laboratory, Boston University Medical Center, USA. (6000 IU) </span><span>Disclosure: Consultant Biogena and speaker's Bureau Abbott Inc.</span></p></td><td colspan="1" rowspan="1"><p><span>4000 IU</span></p></td><td colspan="1" rowspan="1"><p><span>6000 IU</span></p></td></tr><tr><td colspan="1" rowspan="1"><p><span>Dr. John Umhau</span><span>, MD, MPH. CDR, USPHS (ret). </span><span>President, Academy of Medicine of Washington, DC, USA. Ex-NIH: c</span><span>o-author of the first peer-reviewed report linking vitamin D deficiency with acute respiratory infection.</span><span>&nbsp;</span><span>(significantly contributing signatory)</span></p></td><td colspan="1" rowspan="1"><p><span>4000 IU</span></p></td><td colspan="1" rowspan="1"><p><span>5000 IU</span></p></td></tr><tr><td colspan="1" rowspan="1"><p><span>Dr. </span><span>Pawel</span><span>&nbsp;</span><span>Pludowski</span><span>, MD, dr hab. Associate Professor, Biochemistry, Radioimmunology and Experimental Medicine, Children’s Memorial Health Institute, Warsaw, Poland. Chair, European Vitamin D Association (EVIDAS) [non-profit].</span></p></td><td colspan="1" rowspan="1"><p><span>4000 IU</span></p></td><td colspan="1" rowspan="1"><p><span>2000 IU</span></p></td></tr><tr><td colspan="1" rowspan="1"><p><span>Dr. Cedric F. Garland</span><span>, DrPH. Professor Emeritus, Department of Family Medicine and Public Health, University of California, San Diego, USA.</span></p></td><td colspan="1" rowspan="1"><p><span>4000 IU</span></p></td><td colspan="1" rowspan="1"><p><span>6000 IU</span></p></td></tr><tr><td colspan="1" rowspan="1"><p><span>Dr. Jose M. Benlloch</span><span>, Professor, Director of the Institute for Instrumentation on Molecular Imaging, CSIC-UPV, Valencia, Spain.</span></p></td><td colspan="1" rowspan="1"><p><span>2000 IU</span></p></td><td colspan="1" rowspan="1"><p><span>3000 IU</span></p></td></tr><tr><td colspan="1" rowspan="1"><p><span>Dr. Samantha Kimball</span><span>, PhD, MLT. Professor, St. Mary's University, Calgary, Alberta, Canada. Research Director, GrassrootsHealth Nutrient Research Institute [non-profit].</span><span>&nbsp;</span><span>(significantly contributing signatory)</span></p></td><td colspan="1" rowspan="1"><p><span>4000 IU</span></p></td><td colspan="1" rowspan="1"><p><span>6000 IU</span></p></td></tr><tr><td colspan="1" rowspan="1"><p><span>Dr. William B. Grant</span><span>, PhD Physics, U. of California, Berkeley. Director at Sunlight, Nutrition, and Health Research Center [non-profit], San Francisco, CA, USA. </span><span>Disclosure: Receives funding from Bio-Tech Pharmacal, Inc.</span></p></td><td colspan="1" rowspan="1"><p><span>4000 IU</span></p></td><td colspan="1" rowspan="1"><p><span>5300 IU</span></p></td></tr><tr><td colspan="1" rowspan="1"><p><span>Dr. Carol L. Wagner,</span><span>&nbsp;MD. Professor, Medical University of South Carolina, USA.</span></p></td><td colspan="1" rowspan="1"><p><span>4000 IU</span></p></td><td colspan="1" rowspan="1"><p><span>5000 IU</span></p></td></tr><tr><td colspan="1" rowspan="1"><p><span>Dr. Paul Marik</span><span>, MD, FCCP, FCCM. </span><span>Chief of Pulmonary and Critical Care Medicine and Professor of Medicine</span><span>, Eastern Virginia Medical School, Norfolk, VA, USA.</span></p></td><td colspan="1" rowspan="1"><p><span>2000 IU</span></p></td><td colspan="1" rowspan="1"><p><span>2000 IU</span></p></td></tr><tr><td colspan="1" rowspan="1"><p><span>Dr. Morry Silberstein</span><span>, MD. Associate Professor, Curtin University, Australia.</span></p></td><td colspan="1" rowspan="1"><p><span>4000 IU</span></p></td><td colspan="1" rowspan="1"></td></tr><tr><td colspan="1" rowspan="1"><p><span>Dr. Vatsal Thakkar</span><span>, MD. Founder, Reimbursify, NY, USA. &nbsp;Former faculty, NYU and Vanderbilt. &nbsp;Op-Ed writer on Vitamin D and COVID-19.</span><span>&nbsp;</span><span>(significantly contributing signatory)</span></p></td><td colspan="1" rowspan="1"><p><span>4000 IU</span></p></td><td colspan="1" rowspan="1"><p><span>10,000 IU</span></p></td></tr><tr><td colspan="1" rowspan="1"><p><span>Dr. Peter H Cobbold</span><span>, PhD. Emeritus Professor, Cell Biology, University of Liverpool, UK.</span></p></td><td colspan="1" rowspan="1"><p><span>4000 IU</span></p></td><td colspan="1" rowspan="1"><p><span>4000 IU</span></p></td></tr><tr><td colspan="1" rowspan="1"><p><span>Dr. Afrozul Haq</span><span>, PhD. Professor Dept of Food Technology, Jamia Hamdard University, New Delhi, India.</span></p></td><td colspan="1" rowspan="1"><p><span>4000 IU</span></p></td><td colspan="1" rowspan="1"><p><span>2000 IU</span></p></td></tr><tr><td colspan="1" rowspan="1"><p><span>Dr. Barry H. Thompson</span><span>, MD, FAAP, FACMG. Clinical Associate Professor (Pediatrics), Uniformed Services University of the Health Sciences, Bethesda, MD, USA.</span></p></td><td colspan="1" rowspan="1"><p><span>4000 IU</span></p></td><td colspan="1" rowspan="1"><p><span>5000 IU</span></p></td></tr><tr><td colspan="1" rowspan="1"><p><span>Dr. Reinhold Vieth</span><span>, PhD, FCACB. Professor, Departments of Nutritional Sciences and Laboratory Medicine &amp; Pathobiology, University of Toronto, Canada. Director (retired), Bone and Mineral Group Laboratory, Mt Sinai Hospital. </span><span>Disclosure: </span><span>Receives patent royalties from Ddrops (an infant vitamin D supplement).</span></p></td><td colspan="1" rowspan="1"><p><span>4000 IU</span></p></td><td colspan="1" rowspan="1"><p><span>4000 IU</span></p></td></tr><tr><td colspan="1" rowspan="1"><p><span>Dr. Linda Benskin</span><span>, PhD, RN, SRN(Ghana), CWCN, CWS, DAPWCA. Independent Researcher for Tropical Developing Countries and Ferris Mfg. Corp, Texas, USA. </span><span>(significantly contributing signatory)</span></p></td><td colspan="1" rowspan="1"><p><span>4000 IU</span></p></td><td colspan="1" rowspan="1"><p><span>4000 IU</span></p></td></tr><tr><td colspan="1" rowspan="1"><p><span>Jim O’Neill</span><span>, CEO, SENS Research Foundation. Former principal associate deputy secretary of Health and Human Services, USA.</span></p></td><td colspan="1" rowspan="1"><p><span>4000 IU</span></p></td><td colspan="1" rowspan="1"><p><span>6000 IU</span></p></td></tr><tr><td colspan="1" rowspan="1"><p><span>Dr. Eric Feigl-Ding</span><span>, PhD. Epidemiologist &amp; Health Economist. Senior Fellow, Federation of American Scientists. USA.</span></p></td><td colspan="1" rowspan="1"><p><span>4000 IU</span></p></td><td colspan="1" rowspan="1"><p><span>5000 IU</span></p></td></tr><tr><td colspan="1" rowspan="1"><p><span>Rt Hon David Davis MP</span><span>, Member of Parliament (Conservative Party). BSc, Joint Hons Molecular Science / Computer Science, Warwick University, UK.</span></p></td><td colspan="1" rowspan="1"><p><span>4000 IU</span></p></td><td colspan="1" rowspan="1"><p><span>6000 IU</span></p></td></tr><tr><td colspan="1" rowspan="1"><p><span>Dr. Rupa Huq MP,</span><span>&nbsp;Member of Parliament (Labour Party). PhD, Cultural Studies, University of East London, UK.</span></p></td><td colspan="1" rowspan="1"><p><span>4000 IU</span></p></td><td colspan="1" rowspan="1"></td></tr><tr><td colspan="1" rowspan="1"><p><span>Dr. Susan J Whiting</span><span>, PhD. Professor Emerita, University of Saskatchewan, Canada.</span></p></td><td colspan="1" rowspan="1"><p><span>4000 IU</span></p></td><td colspan="1" rowspan="1"><p><span>4000 IU</span></p></td></tr><tr><td colspan="1" rowspan="1"><p><span>Dr. Richard Mazess</span><span>. PhD. Emeritus Professor, University of Wisconsin, Madison, USA.</span></p></td><td colspan="1" rowspan="1"><p><span>4000 IU</span></p></td><td colspan="1" rowspan="1"><p><span>5000 IU</span></p></td></tr><tr><td colspan="1" rowspan="1"><p><span>Dr. Helga Rhein</span><span>, MD (retired). </span><span>Sighthill…</span></p></td></tr></tbody></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://vitamindforall.org/letter.html">https://vitamindforall.org/letter.html</a></em></p>]]>
            </description>
            <link>https://vitamindforall.org/letter.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25680282</guid>
            <pubDate>Fri, 08 Jan 2021 01:34:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Avoiding instruction cache misses (2019)]]>
            </title>
            <description>
<![CDATA[
Score 67 | Comments 17 (<a href="https://news.ycombinator.com/item?id=25680125">thread link</a>) | @nkurz
<br/>
January 7, 2021 | https://paweldziepak.dev/2019/06/21/avoiding-icache-misses/ | <a href="https://web.archive.org/web/*/https://paweldziepak.dev/2019/06/21/avoiding-icache-misses/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div role="main"><div><article><p>Modern processors are quite complex, with many parts having the potential to become a bottleneck. It is relatively easy to reason about the performance of short pieces of code, especially if memory effects are kept to a minimum. Both static analysis tools like LLVM MCA and microbenchmarks can provide a lot of information in such cases. However, the behaviour of the whole program is not just the sum of those small parts. As the code becomes larger and more complex other effects start appearing. One of such potential problems are excessive instruction cache misses.</p><p>Every program has different properties, and those large-scale effects will affect it differently. However, if its job is to execute complex logic on a small amount of data, the instruction cache is likely to become a problem at some point. The actual impact may vary significantly from codebase to codebase, which is why I won’t show any numbers in this article. Let’s consider this just a collection of ideas, but it is not easy to tell how much any of them will help for a given application.</p><p>First, let’s have a quick look at the processor front end. Below is a simplified diagram of how it is arranged in Skylake, the numbers between units are the maxima per cycle.</p><p><img loading="lazy" width="630" height="860" src="https://paweldziepak.dev/static/icache-front-end.min.2e73578fff.svg" alt="CPU front end"></p><p>Each cycle the processor fetches up to 16 bytes from the instruction cache using information from the Branch Prediction Unit to predict the control flow. The pre-decode unit determines instruction lengths and puts up to five of them in the Instruction Queue. From the Instruction Queue, up to 5 instructions (with macro-fusion) are brought each cycle to the decoders. There is one complex decoder that can handle instructions that translate to up to 4 µops and 3 simple decoders that can handle only single-µop instructions. In total, all decoders are limited to producing no more than 5 µops each cycle. Instructions that require more than 4 µops go through Microcode Sequence ROM, which emits 4 µops per cycle, and while it is active, the decoders are disabled. There is also Decoded ICache (<abbr title="Decoded Stream Buffer">DSB</abbr>) which caches decoded µops. It can emit up to 6 µops each cycle. All µops, regardless of their source, end up in the Instruction Decode Queue (IDQ). The Loop Stream Detector (LSD) detects small loops and keeps them in the queue, so that no fetched, decodes or reads from the DSB are needed during the duration of the loop. IDQ is the last part of the front end, and the queued µops continue to the back end.</p><p>From the instruction cache point of view, the front end has two weaknesses. Firstly, instructions are processed in-order which can severely limit the processor ability to hide latencies of cache misses. HyperThreading can make sure that this part of the processor still does some useful work, but it is also the source of the second problem – all resources, including the L1 instruction cache and µop cache are shared between the hardware threads.</p><p>Modern processors provide various metrics that help monitor their behaviour. However, the task of extracting the relevant data requires a proper approach if it is to be done efficiently. Top-down analysis is invaluable with helping to understand microarchitectural phenomena in large codebases. The idea is to monitor program behaviour with the <abbr title="Performance Monitoring Unit">PMU</abbr> counters and identify the bottleneck starting with the major functional parts of the CPU and then digging deeper narrowing down on the exact source of the problem. It can be done in an automated way by tools like VTune or toplev.</p><pre><code>FE    Frontend_Bound:                                      39.48 +-  0.00 % Slots
BE    Backend_Bound:                                       16.19 +-  0.00 % Slots
    This category represents fraction of slots where no uops are
    being delivered due to a lack of required resources for
    accepting new uops in the Backend...
FE    Frontend_Bound.Frontend_Latency:                     24.92 +-  0.00 % Slots
FE    Frontend_Bound.Frontend_Bandwidth:                   13.45 +-  0.00 % Slots
FE    Frontend_Bound.Frontend_Latency.ICache_Misses:       14.45 +-  0.00 % Clocks &lt;==
    This metric represents fraction of cycles the CPU was
    stalled due to instruction cache misses...
    Sampling events:  frontend_retired.l2_miss:pp frontend_retired.l1i_miss:pp
FE    Frontend_Bound.Frontend_Latency.ITLB_Misses:          8.71 +-  0.00 % Clocks
    This metric represents fraction of cycles the CPU was
    stalled due to instruction TLB misses...
    Sampling events:  frontend_retired.stlb_miss:pp frontend_retired.itlb_miss:pp
FE    Frontend_Bound.Frontend_Latency.Branch_Resteers:      8.42 +-  0.00 % Clocks_Est
    This metric represents fraction of cycles the CPU was
    stalled due to Branch Resteers...
    Sampling events:  br_misp_retired.all_branches:u
FE    Frontend_Bound.Frontend_Bandwidth.MITE:              31.93 +-  0.00 % CoreClocks
    This metric represents Core fraction of cycles in which CPU
	was likely limited due to the MITE pipeline (Legacy Decode
    Pipeline)...
</code></pre><p>Above is an example of a toplev result. We can see that the instruction cache misses were the dominating bottleneck. Unsurprisingly instruction TLB misses also show up. On the front end bandwidth side of things, toplev points to the legacy decode pipeline. That makes perfect sense if the instructions are supplied from DSB or LSD, then there are no instruction fetches, and no cache misses.</p><p>Sometimes, the final summary may not provide sufficient information if there are changes in the code behaviour during the test. When that’s the case, a graph is likely to be a much more helpful way of presenting the results.</p><p><img loading="lazy" width="950" height="950" src="https://paweldziepak.dev/static/icache-toplev.min.2b465fdb6f.svg" alt="toplev"></p><p>Tools like toplev are great for initial identification of the problem, but once that’s done what we need is a right way for comparing different solutions. Ultimately, the most important metric is the actual performance of the program in a real-life workload. toplev still can be helpful as it shows the balance between different performance-limiting factors. What also can be useful is <code>perf stat</code> which can show the performance counter statistics. The event most relevant for us is <code>L1-icache-load-misses</code>, though there are more model-specific registers that may be of interest.</p><p>Now, that we know how to diagnose excessive instruction cache misses, let’s see what can be done to deal with this problem.</p><h2 id="avoiding-work">Avoiding work</h2><p>If the number of executed instructions is the problem, the most obvious solution is to try to reduce that number. Obviously, that’s much easier said than done, but there are some common patterns for dealing with this issue. One example would be prepared statements in databases. The general idea is that if a client knows it will send requests that have some commonality, it can tell the database engine early that the requests are going to match specific templates. This information allows the server to do as much work as possible during the preparation stage, thus reducing the amount of logic that needs to be executed for each individual request.</p><p>Extracting common patterns doesn’t have to be explicit. A server or any other kind of an application which actions depend on the user input could attempt to look for repeating patterns and cache some common parts. This is a very vague idea and most likely won’t be easily implementable in a lot of applications, but in some cases may be quite a natural solution. It also shows the main problem with the “just do less” approach – it is very application specific. On the plus, side, if this can be done, it is likely to help with the overall performance, not just the instruction cache misses.</p><p>Another potential problem is making sure that the preparation phase can really do something to help during the execution phase. If that means pre-computing some values, then it’s simple. However, if the only thing that preparation gives us is the knowledge which code paths are going to be exercised and which branches taken during the execution, it is going to be harder to take benefit from it. One option is to have some specialised code for the most common paths, C++ templates may come in handy here. If it is not easy to determine what may be the most common paths, then a just-in-time compiler may be used to generate code in the preparation stage.<sup id="fnref:1"><a href="#fn:1" role="doc-noteref">1</a></sup></p><h2 id="batching-work">Batching work</h2><p>So far, we have been trying to reduce the number of executed instructions, by taking advantage of some earlier knowledge to avoiding repeating the same work. In other words, we have introduced two stages:</p><ul><li>preparation, which is performed rarely and, consequently, less performance critical</li><li>execution, which is done many times and is expected to dominate overall performance</li></ul><p>The way this can help with the instruction cache misses is that the execution stage, being smaller, is more likely to fit in the instruction cache. Whether this brings any measurable benefits depends highly on the type of the application and how much logic can be moved from execution to preparation stages.</p><p>We have already split our processing pipeline into preparation and execution stage. If the execution stage can fit in the instruction cache, we are done. However, often, that’s not the case. What we can do to improve the situation more is to split the execution into more stages. This time the goal is not to reuse work as it was with the preparation, but to group entities that need to have the same code executed for them. In other words, if the processing pipeline consists of steps A, B and C the idea is to separate them, add a queue in front of each of those stages, and then cycle through those stages each time handling multiple elements from the queue. Connections between the stages don’t have to be one-to-one, any directed graph is fine.</p><p><img loading="lazy" width="756" height="331" src="https://paweldziepak.dev/static/icache-seda.min.7259b25adc.svg" alt="SEDA diagram"></p><p>In the diagram above, there is one stage that feeds tasks to one of two stages. This could be, for example, a front-end of a database server. The first stage does some initial request processing and then, depending on whether it is a read or write, puts it in the appropriate queue. Each stage processes requests in batches, the first one warms up the instruction …</p></article></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://paweldziepak.dev/2019/06/21/avoiding-icache-misses/">https://paweldziepak.dev/2019/06/21/avoiding-icache-misses/</a></em></p>]]>
            </description>
            <link>https://paweldziepak.dev/2019/06/21/avoiding-icache-misses/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25680125</guid>
            <pubDate>Fri, 08 Jan 2021 01:15:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[CO2 already emitted will warm Earth beyond climate targets, study finds]]>
            </title>
            <description>
<![CDATA[
Score 332 | Comments 241 (<a href="https://news.ycombinator.com/item?id=25679618">thread link</a>) | @colinprince
<br/>
January 7, 2021 | https://www.cbc.ca/news/technology/climate-targets-1.5861537 | <a href="https://web.archive.org/web/*/https://www.cbc.ca/news/technology/climate-targets-1.5861537">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>The amount of baked-in global warming, from carbon pollution already in the air, is enough to blow past international agreed upon goals to limit climate change, a new study finds. But it can be delayed for centuries if governments takes action.</p><div><figure><div><p><img loading="lazy" alt="" srcset="" sizes="" src="https://i.cbc.ca/1.4922800.1543350548!/cpImage/httpImage/image.jpg_gen/derivatives/16x9_780/us-coal-s-decline.jpg"></p></div><figcaption>Smoke and steam rise from the smokestack of a coal-fired power plant near Ordos in northern China's Inner Mongolia Autonomous Region in 2015.  A new study estimates that 2.3 C of warming is inevitable, but can be delayed for centuries if the world quickly stops emitting extra greenhouse gases from the burning of coal, oil and natural gas, the study's authors say.<!-- --> <!-- -->(Mark Schiefelbein/Associated Press)</figcaption></figure><p><span><p>The amount of baked-in global warming, from carbon pollution already in the air, is enough to blow past international agreed upon goals to limit climate change, a new study finds.</p>  <p>But it's not game over because, while that amount of warming may be inevitable, it can be delayed for centuries if the world quickly stops emitting extra greenhouse gases from the burning of coal, oil and natural gas, the study's authors say.</p>  <p>For decades, scientists have talked about so-called "committed warming" or the increase in future temperature based on past carbon dioxide emissions that stay in the atmosphere for well over a century. It's like the distance a speeding car travels after the brakes are applied.</p>  <p>But Monday's <a href="https://www.nature.com/articles/s41558-020-00955-x">study in the journal Nature Climate Change</a> calculates that a bit differently and now figures the carbon pollution already put in the air will push global temperatures to about 2.3 degrees Celsius (4.1 degrees Fahrenheit) of warming since pre-industrial times.</p>  <p>Previous estimates, including those accepted by international science panels, were about a degree Celsius (1.8 degrees Fahrenheit) less than that amount of committed warming.</p>  <p>International climate agreements set goals of limiting warming to 2 C&nbsp;(3.6 F) since pre-industrial times, with the more ambitious goal of limiting it to 1.5 C&nbsp;(2.7 F) added in Paris in 2015. The world has already warmed about 1.1 C&nbsp;(2 F).</p>  <p>"You've got some ... global warming inertia that's going to cause the climate system to keep warming, and that's essentially what we're calculating," said study co-author Andrew Dessler, a climate scientist at Texas A&amp;M University. "Think about the climate system like the Titanic. It's hard to turn the ship when you see the icebergs."</p>  <p>Dessler and colleagues at the Lawrence Livermore National Lab and Nanjing University in China calculated committed warming to take into account that the world has warmed at different rates in different places and that places that haven't warmed as fast are destined to catch up.</p>    <p>Places such as the Southern Ocean, surrounding Antarctica are a bit cooler, and that difference creates low-lying clouds that reflect more sun away from earth, keeping these places cooler. But this situation can't keep going indefinitely because physics dictates that cooler locations will warm up more and when they do, the clouds will dwindle and more heating will occur, Dessler said.</p>  <p>Previous studies were based on the cooler spots staying that way, but Dessler and colleagues say that's not likely.</p>  <p><span><figure><div><p><img loading="lazy" alt="" srcset="https://i.cbc.ca/1.5693652.1597940952!/cpImage/httpImage/image.jpg_gen/derivatives/original_300/greenland-record-melt.jpg 300w,https://i.cbc.ca/1.5693652.1597940952!/cpImage/httpImage/image.jpg_gen/derivatives/original_460/greenland-record-melt.jpg 460w,https://i.cbc.ca/1.5693652.1597940952!/cpImage/httpImage/image.jpg_gen/derivatives/original_620/greenland-record-melt.jpg 620w,https://i.cbc.ca/1.5693652.1597940952!/cpImage/httpImage/image.jpg_gen/derivatives/original_780/greenland-record-melt.jpg 780w,https://i.cbc.ca/1.5693652.1597940952!/cpImage/httpImage/image.jpg_gen/derivatives/original_1180/greenland-record-melt.jpg 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.5693652.1597940952!/cpImage/httpImage/image.jpg_gen/derivatives/original_780/greenland-record-melt.jpg"></p></div><figcaption>In this Aug. 16, 2019 file photo, icebergs float away as the sun rises near Kulusuk, Greenland. Greenland lost a record amount of ice that year. The world has already warmed 1.1 C since pre-industrial times.<!-- --> <!-- -->(Felipe Dana/The Associated Press)</figcaption></figure></span></p>  <h2>More research needed, outside experts say</h2>  <p>Outside experts said the work is based on compelling reasoning, but want more research to show that it's true. Breakthrough Institute climate scientist Zeke Hausfather said the new work fits better with climate models than observational data.</p>  <p>Just because the world is bound to get more warming than international goals, that doesn't mean all is lost in the fight against global warming, said Dessler, who cautioned against what he called "climate doomers."</p>  <p>If the world gets to net zero carbon emissions soon, 2 degrees of global warming could be delayed enough so that it won't happen for centuries, giving society time to adapt or even come up with technological fixes, he said.</p>  <p>"If we don't, we're going to blow through (climate goals) in a few decades," Dessler said. "It's really the rate of warming that makes climate change so terrible. If we got a few degrees over 100,000 years, that would not be that big a deal. We can deal with that. But a few degrees over 100 years is really bad."</p></span></p></div></div>]]>
            </description>
            <link>https://www.cbc.ca/news/technology/climate-targets-1.5861537</link>
            <guid isPermaLink="false">hacker-news-small-sites-25679618</guid>
            <pubDate>Fri, 08 Jan 2021 00:23:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[iPhone 12 magnets deactivating implanted defibrillators in cardiac patients]]>
            </title>
            <description>
<![CDATA[
Score 34 | Comments 12 (<a href="https://news.ycombinator.com/item?id=25677717">thread link</a>) | @efunkem
<br/>
January 7, 2021 | http://www.medmalreviewer.com/does-the-iphone-12-deactivate-implantable-cardioverter-defibrillators/ | <a href="https://web.archive.org/web/*/http://www.medmalreviewer.com/does-the-iphone-12-deactivate-implantable-cardioverter-defibrillators/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
				<div data-elementor-type="wp-post" data-elementor-id="3642" data-elementor-settings="[]">
						<div>
							<div>
							<section data-id="d29a4f4" data-element_type="section">
						<div>
							<div>
					
				<div data-id="d4df9de" data-element_type="column">
			<div>
							<div>
						<div data-id="82f4b7d" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<div><p>An interesting article came out <a href="https://www.heartrhythmjournal.com/article/S1547-5271(20)31227-3/fulltext?fbclid=IwAR3DokV5V8f8G-LYlKwXFDjdIE5Jf9w4B5KAgpv0vRJ8P2--ZvOfyQO802k">a few days ago in Heart Rhythm</a>, raising concern that new hardware in the iPhone 12 may deactivate implanted cardioverter defibrillators (ICDs).&nbsp;</p>
<p>In short, the concern is that an array of magnets in the phone may turn off the life-saving function of these cardiac devices.</p>
<p>This “MagSafe” technology was already used elsewhere, but this is the first time it has been incorporated into an iPhone.</p>
<p>Nearly all ICDs will stop shocking a patient when placed near a sufficiently strong magnet.&nbsp;</p>
<p>Pacemakers exposed to a magnet are set to a pre-programmed mode that varies by manufacturer, usually with a rate of 65-80bpm.&nbsp;</p>
<p>Ask any Emergency Medicine physician and they will be able to point you to a blue circular magnet used for this exact purpose.&nbsp;</p></div>
				</div>
				</div>
						</div>
					</div>
		</div>
				
								</div>
					</div>
		</section>
				<section data-id="50b654d" data-element_type="section">
						<div>
							<div>
					
				<div data-id="7506540" data-element_type="column">
			<div>
							<div>
						<div data-id="074d5bd" data-element_type="widget" data-widget_type="image.default">
				<div>
					<p><img width="800" height="812" src="http://www.medmalreviewer.com/wp-content/uploads/2021/01/Magnet.jpg" alt="" loading="lazy" srcset="http://www.medmalreviewer.com/wp-content/uploads/2021/01/Magnet.jpg 819w, http://www.medmalreviewer.com/wp-content/uploads/2021/01/Magnet-296x300.jpg 296w, http://www.medmalreviewer.com/wp-content/uploads/2021/01/Magnet-768x779.jpg 768w, http://www.medmalreviewer.com/wp-content/uploads/2021/01/Magnet-500x507.jpg 500w, http://www.medmalreviewer.com/wp-content/uploads/2021/01/Magnet-800x812.jpg 800w" sizes="(max-width: 800px) 100vw, 800px">											</p>
				</div>
				</div>
						</div>
					</div>
		</div>
				
								</div>
					</div>
		</section>
				<section data-id="a778930" data-element_type="section">
						<div>
							<div>
					
				<div data-id="c5b38f5" data-element_type="column">
			<div>
							<div>
						<div data-id="7ba4163" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<div><p>A patient with a malfunctioning pacemaker or defibrillator may be suffering numerous inappropriate shocks. The magnet comes in very handy in these situations.</p>
<p>However, a patient that goes into ventricular tachycardia (among other life-threatening cardiac rhythms) will need their device to work appropriately, delivering a shock to save their life.</p>
<p>If this issue is reproduceable in other patients, an iPhone 12 carried in a front shirt pocket has the chance to inactivate the device and block life-saving electrical therapy.&nbsp;</p>
<p>The authors demonstrated this (<a href="https://www.heartrhythmjournal.com/article/S1547-5271(20)31227-3/fulltext?fbclid=IwAR3DokV5V8f8G-LYlKwXFDjdIE5Jf9w4B5KAgpv0vRJ8P2--ZvOfyQO802k">picture from their publication</a>) using an iPhone 12 on a real patient with an ICD:</p>
</div>
				</div>
				</div>
						</div>
					</div>
		</div>
				
								</div>
					</div>
		</section>
				<section data-id="c205503" data-element_type="section">
						<div>
							<div>
					
				<div data-id="253ec3d" data-element_type="column">
			<div>
							<div>
						<div data-id="e92e1ac" data-element_type="widget" data-widget_type="image.default">
				<div>
					<div>
							<figure>
										<img width="499" height="556" src="http://www.medmalreviewer.com/wp-content/uploads/2021/01/gr1_lrg-1.jpg" alt="" loading="lazy" srcset="http://www.medmalreviewer.com/wp-content/uploads/2021/01/gr1_lrg-1.jpg 499w, http://www.medmalreviewer.com/wp-content/uploads/2021/01/gr1_lrg-1-269x300.jpg 269w" sizes="(max-width: 499px) 100vw, 499px">											<figcaption></figcaption>
										</figure>
					</div>
				</div>
				</div>
						</div>
					</div>
		</div>
				
								</div>
					</div>
		</section>
				<section data-id="6a3c0ef" data-element_type="section">
						<div>
							<div>
					
				<div data-id="9263bf4" data-element_type="column">
			<div>
							<div>
						<div data-id="e311c1c" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<p>Green arrow: iPhone 12 placed over ICD<br>Red arrow: Interrogation device – “SUSPENDED: Magnet Present”<br>Yellow arrow: Magnetic ring in iPhone 12</p>
				</div>
				</div>
						</div>
					</div>
		</div>
				
								</div>
					</div>
		</section>
				<section data-id="5370fb2" data-element_type="section">
						
		</section>
				<section data-id="2bfc3bb" data-element_type="section">
						
		</section>
				<section data-id="7669176" data-element_type="section">
						<div>
							<div>
					
				<div data-id="58dae32" data-element_type="column">
			<div>
							<div>
						<div data-id="c785851" data-element_type="widget" data-widget_type="image.default">
				<div>
					<p><img width="800" height="666" src="http://www.medmalreviewer.com/wp-content/uploads/2021/01/Breakdown-Phone.jpg" alt="" loading="lazy" srcset="http://www.medmalreviewer.com/wp-content/uploads/2021/01/Breakdown-Phone.jpg 829w, http://www.medmalreviewer.com/wp-content/uploads/2021/01/Breakdown-Phone-300x250.jpg 300w, http://www.medmalreviewer.com/wp-content/uploads/2021/01/Breakdown-Phone-768x639.jpg 768w, http://www.medmalreviewer.com/wp-content/uploads/2021/01/Breakdown-Phone-500x416.jpg 500w, http://www.medmalreviewer.com/wp-content/uploads/2021/01/Breakdown-Phone-800x666.jpg 800w" sizes="(max-width: 800px) 100vw, 800px">											</p>
				</div>
				</div>
						</div>
					</div>
		</div>
				
								</div>
					</div>
		</section>
				<section data-id="a783810" data-element_type="section">
						<div>
							<div>
					
				<div data-id="5a8a0ce" data-element_type="column">
			<div>
							<div>
						<div data-id="f5d8fdd" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<div><p>Notice the similar circular layout between the iPhone and the standard blue medical magnet.</p>
<p>Physicians should be aware of this issue. While there is no active litigation related to this, it is a very high risk situation.&nbsp;<span>&nbsp;</span></p></div>
				</div>
				</div>
						</div>
					</div>
		</div>
				
								</div>
					</div>
		</section>
				<section data-id="fa63cd5" data-element_type="section">
						
		</section>
				<section data-id="a87a621" data-element_type="section">
						<div>
							<div>
					
				<div data-id="2b0d0b5" data-element_type="column">
			<div>
							<div>
						<div data-id="bff2ed2" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<div><p>MedMalReviewer Opinion:</p>
<p>1. This is unlikely to result in medical malpractice litigation against any individual physician. However, it does place the manufacturer at risk for product liability.&nbsp;</p>
<p>2. ED physicians should keep this in mind for patients with out-of-hospital cardiac arrest. These patients should be completely exposed during the code, removing all clothing and foreign objects.&nbsp;</p>
<p>3. For patients with pacemakers, consider that any unusual or unexplained symptoms could have been explained by a transient switch in pacemaker mode while their phone was nearby. Interrogating the pacemaker will help shed light on this.</p></div>
				</div>
				</div>
						</div>
					</div>
		</div>
				
								</div>
					</div>
		</section>
				<section data-id="3d300b0" data-element_type="section">
						
		</section>
				<section data-id="508993e" data-element_type="section">
						<div>
							<div>
					
				<div data-id="86adb72" data-element_type="column">
			<div>
							<div>
						<div data-id="63012ba" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<div><p>Check out these real-life medical malpractice cases:</p>
<p><a href="http://www.medmalreviewer.com/case-13-cervical-fusion/">Case 13: Cervical Fusion</a> – A patient suffers an unexpected cardiac arrest during a neck surgery.&nbsp;</p>
<p><a href="http://www.medmalreviewer.com/case-15-ski-accident/">Case 15: Ski Accident</a> – A patient on blood thinners crashes and hits her head while skiing.</p></div>
				</div>
				</div>
						</div>
					</div>
		</div>
				
								</div>
					</div>
		</section>
				<section data-id="207a1e5" data-element_type="section">
						
		</section>
				<section data-id="c177169" data-element_type="section">
						<div>
							<div>
					
				<div data-id="e09ce0e" data-element_type="column">
			<div>
							<div>
						<div data-id="5227a13" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<div><p>Read expert witness opinions from malpractice lawsuits:</p>
<p><a href="https://expertwitness.substack.com/p/expert-witness-case-34">Expert Witness Case #34</a>&nbsp;– Urologist accidentally ligates artery instead of vas deferens during vasectomy. Patient loses testicle.</p>
<p><a href="https://expertwitness.substack.com/p/expert-witness-case-32">Expert Witness Case #32</a>&nbsp;– Patient admitted with DKA develops severe leg pain. Long delays in care result in amputation.</p></div>
				</div>
				</div>
						</div>
					</div>
		</div>
				
								</div>
					</div>
		</section>
				<section data-id="5586f05" data-element_type="section">
						
		</section>
						</div>
						</div>
					</div>
				
			</div></div>]]>
            </description>
            <link>http://www.medmalreviewer.com/does-the-iphone-12-deactivate-implantable-cardioverter-defibrillators/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25677717</guid>
            <pubDate>Thu, 07 Jan 2021 21:24:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What React Gets Wrong]]>
            </title>
            <description>
<![CDATA[
Score 33 | Comments 74 (<a href="https://news.ycombinator.com/item?id=25677648">thread link</a>) | @jehna1
<br/>
January 7, 2021 | https://thejunkland.com/blog/what-react-gets-wrong.html | <a href="https://web.archive.org/web/*/https://thejunkland.com/blog/what-react-gets-wrong.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><article><p>React is the de-facto tool for frontend web development. It has a rich ecosystem and a well-known company to back it up. Despite all of this, I think they still get a ton of stuff wrong. This post is about my personal views and things I think React is already a too slow-moving giant to fix.</p><h2 id="the-syntax">The syntax</h2><p>React has such an awful API that they needed to create a whole new programming language syntax to overcome it: The <code>React.createElement</code> API. Most of the time it's hidden behind JSX that's transpiled onto <code>React.createElement</code> calls.</p><p>You either only ever write JSX when working with React, or you get frustrated with the amount of clutter that gets to your codebase from all that repetition that provides no value to the reader.</p><pre><code>Reat.createElement(<span>'html'</span>, <span>null</span>,
  React.createElement(<span>'body'</span>, <span>null</span>,
    React.createElement(<span>'div'</span>, <span>null</span>,
      React.createElement(...)
    )
  )
)
</code></pre><p>I think a much better way is to follow what SwiftUI and Flutter are doing: Move the element's name from argument to be the function's name:</p><pre><code>html(
  body(
    div(...)
  )
)
</code></pre><p>This does not only remove unnecessary clutter, but removes the need for any compilation step.</p><h2 id="create-react-app">create-react-app</h2><p>Next up us a monstrosity that's nowadays accepted by many to be a "best practice" for getting started with a React project. The problem being, that React ecosystem is such a complex beast that they created a bootstrap project so you can get anything done in a meaningful time. Just pray that you don't need to eject it any time soon.</p><p>Just to give you an idea of the absurdness of this situation: create-react-app creates a "hello world" project for you that downloads <strong>2.5 million lines of Javascript code</strong> to your machine. For a hello world app.</p><p>I have strong feelings about fighting complexity by adding more complexity, and this sure smells like something you should not be doing in 2021.</p><p>Instead we should be thinking about where our browsers and server ecosystems are nowadays and if we could make the bootstrapping <em>simpler</em>. Browsers <a href="https://caniuse.com/es6-module">know how to handle imports nowadays</a>, and the module format is <a href="https://nodejs.org/api/esm.html">also part of Node.js</a> without any preprocessing, so you don't necessarily need a build step to get those working.</p><p>Modern browsers are really good with on-the-fly compression like gzip <a href="https://caniuse.com/brotli">and even brotli</a>, so minification is not so much of an issue. Your CDN should anyways be optimizing compression of your static assets.</p><p>Another point being that React is over 100kb when minified (including React DOM because you can't do that much without it). Imagine how much unminified code you could fit in 100kb if you used something that doesn't need to be built at all.</p><h2 id="react-is-not-just-a-view-rendering-library-anymore">React is not just a view rendering library anymore</h2><p>React used to be only a good frontend rendering library with JSX. Nowadays you're signing up for a framework with its own plugin ecosystem, hooks, fibers, suspense, and other obscure future features like <a href="https://reactjs.org/blog/2020/12/21/data-fetching-with-react-server-components.html">server components</a>.</p><p>We've changed from doing <em>model-view-controller</em> to using all-consuming views that perform both business logic and create side effects. Views have become the top-level entity that controls everything else.</p><p>Remember the old saying "UI is a function of state"? React used to be a good implementation of this, but nowadays it's more of "UI that handles your state".</p><p>I think a good view rendering library should do just one thing well: Render the UI based on the app's state. It should not care where the state is, and most importantly it should not handle the state itself. Otherwise we'll end up with things like bloated class components or <em>"suddenly global state and black magic is fine"</em> type of hooks inside otherwise pure functions.</p><p>Instead you should be handling your business logic, side effects and data gathering some place else, and use proper separation of concerns to model your application's logic.</p><h2 id="imagine-a-better-world">Imagine a better world</h2><p>So how would a better React alternative look in 2021? I made a small prototype library called <a href="https://www.npmjs.com/package/longwood">Longwood</a> based on above principles, and a hello world looks like this:</p><pre><code><span>&lt;<span>html</span>&gt;</span>
  <span>&lt;<span>body</span>&gt;</span>
    <span>&lt;<span>div</span> <span>id</span>=<span>"app"</span>&gt;</span><span>&lt;/<span>div</span>&gt;</span>
    <span>&lt;<span>script</span> <span>type</span>=<span>"module"</span>&gt;</span><span>
      <span>import</span> { div, text } <span>from</span> <span>'https://cdn.skypack.dev/longwood'</span>

      <span>const</span> render = div(text(<span>'Hello world!'</span>))
      render(<span>document</span>.getElementById(<span>'app'</span>))
    </span><span>&lt;/<span>script</span>&gt;</span>
  <span>&lt;/<span>body</span>&gt;</span>
<span>&lt;/<span>html</span>&gt;</span>
</code></pre><p><a href="https://codesandbox.io/s/unruffled-star-xs16e?file=/index.html">▶️ Try it out at CodeSandbox.io</a></p><p>That's all the code you need. No precompilation, no build steps, no downloading of 2.5 million lines of code to get started. You can open a text editor, save the code as an <code>index.html</code> file, open it in a browser and it works.</p><p>You have the same power of Javascript to compose your views as with React, and there's a <a href="https://www.npmjs.com/package/longwood-usestate">separate state management library</a> to get started if you're coming from React. But moreover <em>it's okay to handle your state however you want</em>. It's just a rendering library. It can be used for just a small portion of your site if you want. It even supports server-side rendering out of the box (with jsdom).</p><p>Since you're going to ask, here are a couple of examples:</p><ul><li><a href="https://codesandbox.io/s/competent-swartz-beoub?file=/src/TodoComponent.ts">React style Todo app</a></li><li><a href="https://links.thejunkland.com/">Rendering 1000+ rows of data with Longwood</a><ul><li><a href="https://links.thejunkland.com/react/">Same example done with create-react-app</a></li></ul></li></ul><h2 id="to-wrap-up">To wrap up</h2><p>We’ve come a long way since the web 2.0 times. jQuery made the world a better place by making DOM manipulation easier. AngularJS made the world a better place by introducing data binding to the masses. But all great increments seem to fade at some point to welcome better alternatives.</p><p>Will the future be bright for Longwood? I have no idea, it’s a single-person project and at the moment has one production site running on it. But I hope it demonstrates a point that we can do things even better in the future if we keep innovating and cherry-picking the good stuff from others.</p><p>Happy hacking.</p><p><a href="https://twitter.com/intent/tweet?text=%22What%20React%20gets%20wrong%22%20by%20@luotojesse%20https://thejunkland.com/blog/what-react-gets-wrong.html" target="_blank" rel="noopener">Tweet</a></p></article></div></div>]]>
            </description>
            <link>https://thejunkland.com/blog/what-react-gets-wrong.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25677648</guid>
            <pubDate>Thu, 07 Jan 2021 21:19:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[CVE-2021-3011: Key recovery on Google Titan Key]]>
            </title>
            <description>
<![CDATA[
Score 233 | Comments 78 (<a href="https://news.ycombinator.com/item?id=25675556">thread link</a>) | @hexa-
<br/>
January 7, 2021 | https://ninjalab.io/a-side-journey-to-titan/ | <a href="https://web.archive.org/web/*/https://ninjalab.io/a-side-journey-to-titan/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
	<div>
					<div>
							<section id="blog">
				<article id="post-747" class="page">
		<div>
		
<center><h3> <a href="https://ninjalab.io/wp-content/uploads/2021/01/a_side_journey_to_titan.pdf" target="_blank" rel="noopener noreferrer">Download the Writeup<center><img src="https://ninjalab.io/wp-content/uploads/2021/01/Titan_Bluetooth_EM_probe.png"></center>
</a></h3></center><br>

<h3>Abstract</h3>
<p><span> The <a href="https://store.google.com/product/titan_security_key" target="_blank" rel="noopener noreferrer"><i>Google Titan Security Key</i></a> is a FIDO U2F hardware device proposed by Google (available since July 2018) as a two-factor authentication token to sign in to applications (e.g. your Google account). Our work describes a side-channel attack that targets the <i>Google Titan Security Key</i>’s secure element (the NXP A700X chip) by the observation of its local electromagnetic radiations during ECDSA signatures (the core cryptographic operation of the FIDO U2F protocol). In other words, an attacker can create a clone of a legitimate <i>Google Titan Security Key</i>.</span></p>

<p><span> To understand the NXP ECDSA implementation, find a vulnerability and design a key-recovery attack, we had to make a quick stop on <i>Rhea</i> (NXP J3D081 JavaCard smartcard). Freely available on the web, this product looks very much like the NXP A700X chip and uses the same cryptographic library. <i>Rhea</i>, as an open JavaCard platform, gives us more control to study the ECDSA engine.</span></p>

<p><span> We could then show that the electromagnetic side-channel signal bears partial information about the ECDSA ephemeral key. The sensitive information is recovered with a non-supervised machine learning method and plugged into a customized lattice-based attack scheme.</span></p>

<p><span> Finally, 4000 ECDSA observations were enough to recover the (known) secret key on <i>Rhea</i> and validate our attack process. It was then applied on the <i>Google Titan Security Key</i> with success (this time by using 6000 observations) as we were able to extract the long term ECDSA private key linked to a FIDO U2F account created for the experiment.</span></p>

<h3>Cautionary Note</h3>
<p><span> Two-factor authentication tokens (like FIDO U2F hardware devices) primary goal is to fight phishing attacks. Our attack requires physical access to the <i>Google Titan Security Key</i>, expensive equipment, custom software, and technical skills.</span></p>

<p><span> <b>Thus, as far as our study goes, it is still safer to use your <i>Google Titan Security Key</i> or other impacted products as FIDO U2F two-factor authentication token to sign in to applications rather than not using one.</b></span></p>

<p><span> Nevertheless, this work shows that the <i>Google Titan Security Key</i> (and other impacted products) would not avoid unnoticed security breach by attackers willing to put enough effort into it. Users that face such a threat should probably switch to other FIDO U2F hardware security keys, where no vulnerability has yet been discovered.</span></p>

<h3>Discovered By</h3>
<p><span> Victor lomné (NinjaLab) and Thomas Roche (NinjaLab).<br>
with the help of Camille Mutschler (NinjaLab) and Dr. Laurent Imbert (LIRMM, CNRS).</span></p>

<h3>List of Impacted Products</h3>
<ul>
<li> Google Titan Security Key (all versions) </li>
<li> Yubico Yubikey Neo </li>
<li> Feitian FIDO NFC USB-A / K9 </li>
<li> Feitian MultiPass FIDO / K13 </li>
<li> Feitian ePass FIDO USB-C / K21 </li>
<li> Feitian FIDO NFC USB-C / K40 </li>
<li> NXP J3D081_M59_DF and variants </li>
<li> NXP J3A081 and variants </li>
<li> NXP J2E081_M64 and variants </li>
<li> NXP J3D145_M59 and variants </li>
<li> NXP J3D081_M59 and variants </li>
<li> NXP J3E145_M64 and variants </li>
<li> NXP J3E081_M64_DF and variants </li>
</ul>


<h3>Further Notes</h3>
<p><span>
1. The impacted Yubico Yubikey Neo is an old product no more available for sale. All FIDO U2F Yubico Yubikeys currently available on their webstore are based on a newer secure element from Infineon, and are not impacted by our work to our knowledge.
</span></p>
<p><span>
2. The NXP P5 / SmartMX secure microcontroller family and its associated cryptographic library (up to v2.9) impacted by our work is quite old. Since, NXP has released two new generations of secure microcontroller families, the “NXP P60 / SmartMX2” family and now the “NXP P70 / SmartMX3” family. Both are Common Criteria certified (with recent certification process), and are not impacted by our work to our knowledge.
</span></p>

<h3>CVE</h3>
<p><span> 
We assigned <a href="https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-3011" target="_blank" rel="noopener noreferrer">CVE-2021-3011</a>
</span></p>
	</div><!--/.blog-post-entry.markup-format-->
</article><!--/#post-747.blog-post-->
			</section><!--/#blog-->
		</div><!--/.col-sm-7-->
			</div><!--/.row-->
</div></div>]]>
            </description>
            <link>https://ninjalab.io/a-side-journey-to-titan/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25675556</guid>
            <pubDate>Thu, 07 Jan 2021 19:00:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Dissecting the Apple M1 GPU, part I]]>
            </title>
            <description>
<![CDATA[
Score 536 | Comments 132 (<a href="https://news.ycombinator.com/item?id=25673631">thread link</a>) | @caution
<br/>
January 7, 2021 | https://rosenzweig.io/blog/asahi-gpu-part-1.html | <a href="https://web.archive.org/web/*/https://rosenzweig.io/blog/asahi-gpu-part-1.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
<header><p>7 Jan 2021</p></header><p>Apple’s latest line of Macs includes their in-house “M1” system-on-chip, featuring a custom GPU. This poses a problem for those of us in the <a href="https://asahilinux.org/">Asahi Linux</a> project who wish to run Linux on our devices, as this custom Apple GPU has neither public documentation nor open source drivers. Some speculate it might descend from PowerVR GPUs, as used in older iPhones, while others believe the GPU to be completely custom. But rumours and speculations are no fun when we can peek under the hood ourselves!</p>
<p>A few weeks ago, I purchased a Mac Mini with an M1 GPU as a development target to study the instruction set and command stream, to understand the GPU’s architecture at a level not previously publicly understood, and ultimately to accelerate the development of a Mesa driver for the hardware. Today I’ve reached my first milestone: I now understand enough of the instruction set to disassemble simple shaders with a free and open-source tool chain, <a href="https://github.com/AsahiLinux/gpu">released on GitHub here</a>.</p>
<p>The process for decoding the instruction set and command stream of the GPU parallels the same process I used for reverse-engineering Mali GPUs in the Panfrost project, originally pioneered by the Lima, Freedreno, and Nouveau free software driver projects. Typically, for Linux or Android driver reverse-engineering, a small wrap library will be written to inject into a test application via <code>LD_PRELOAD</code> that hooks key system calls like <code>ioctl</code> and <code>mmap</code> in order to analyze user-kernel interactions. Once the “submit command buffer” call is issued, the library can dump all (mapped) shared memory for offline analysis.</p>
<p>The same overall process will work for the M1, but there are some macOSisms that need to be translated. First, there is no <code>LD_PRELOAD</code> on macOS; the equivalent is <code>DYLD_INSERT_LIBRARIES</code>, which has some extra security features which are easy enough to turn off for our purposes. Second, while the standard Linux/BSD system calls do exist on macOS, they are not used for graphics drivers. Instead, Apple’s own <code>IOKit</code> framework is used for both kernel and userspace drivers, with the critical entry point of <code>IOConnectCallMethod</code>, an analogue of <code>ioctl</code>. These differences are easy enough to paper over, but they do add a layer of distance from the standard Linux tooling.</p>
<p>The bigger issue is orienting ourselves in the IOKit world. Since Linux is under a copyleft license, (legal) kernel drivers are open source, so the <code>ioctl</code> interface is public, albeit vendor-specific. macOS’s kernel (XNU) being under a permissive license brings no such obligations; the kernel interface is proprietary and undocumented. Even after wrapping <code>IOConnectCallMethod</code>, it took some elbow grease to identify the three critical calls: memory allocation, command buffer creation, and command buffer submission. Wrapping the allocation and creation calls is essential for tracking GPU visible memory (what we are interested in studying), and wrapping the submission call is essential for timing the memory dump.</p>
<p>With those obstacles cleared, we can finally get to the shader binaries, black boxes in themselves. However, the process from here on out is standard: start with the simplest fragment or compute shader possible, make a small change in the input source code, and compare the output binaries. Iterating on this process is tedious but will quickly reveal key structures, including opcode numbers.</p>
<p>The findings of the process documented in the free software disassembler confirm a number of traits of the GPU:</p>
<p>One, this is a scalar architecture. Unlike some GPUs that are scalar for 32-bits but vectorized for 16-bits, the M1’s GPU is scalar at all bit sizes. Yet Metal optimization resources imply 16-bit arithmetic should be significantly faster, in addition to a reduction of register usage leading to higher thread count (occupancy). This suggests the hardware is superscalar, with more 16-bit ALUs than 32-bit ALUs, allowing the part to benefit from low-precision graphics shaders much more than competing chips can, while removing a great deal of complexity from the compiler.</p>
<p>Two, this seems to handle scheduling in hardware, common among desktop GPUs but less so in the embedded space. This again makes the compiler simpler at the expense of more hardware. Instructions seem to have minimal encoding overhead, unlike other architectures which need to pad out instructions with <em>nop</em>’s to accommodate highly constrained instruction sets.</p>
<p>Three, various modifiers are supported. Floating point ALUs can do clamps (saturate), negates, and absolute value modifiers “for free”, a common shader architecture trait. Further, most (all?) instructions can type-convert between 16-bit and 32-bit “for free” on both the destination and the sources, which allows the compiler to be much more aggressive about using 16-bit operations without risking conversion overheads. On the integer side, various bitwise complements and shifts are allowed on certain instructions for free. None of this is unique to Apple’s design, but it’s worth noting all the same.</p>
<p>Finally, not all ALU instructions have the same timing. Instructions like <code>imad</code>, used to multiply two integers and add a third, are avoided in favour of repeated <code>iadd</code> integer addition instructions where possible. This also suggests a superscalar architecture; software-scheduled designs like those I work on for my day job cannot exploit differences in pipeline length, inadvertently slowing down simple instructions to match the speed of complex ones.</p>
<p>From my prior experience working with GPUs, I continue to expect to find some eldritch horror waiting in the instruction set, to balloon compiler complexity. Though the above work currently covers only a small surface area of the instruction set, so far everything seems sound. There are no convoluted optimization tricks, but doing away with the trickery is creating a streamlined, efficient design that does one thing and does it well. Maybe Apple’s hardware engineers discovered it’s hard to beat simplicity.</p>
<p>Alas, a shader tool chain isn’t much use without an open-source userspace driver. Next up: dissecting the command stream!</p>
<p><em>Disclaimer: This work is a hobby project, conducted based on public information. Opinions expressed may not reflect those of my employer.</em></p>
<p><a href="https://rosenzweig.io/">Back to home</a></p>
</div>]]>
            </description>
            <link>https://rosenzweig.io/blog/asahi-gpu-part-1.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25673631</guid>
            <pubDate>Thu, 07 Jan 2021 17:01:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[My stack is HTML+CSS]]>
            </title>
            <description>
<![CDATA[
Score 219 | Comments 175 (<a href="https://news.ycombinator.com/item?id=25673495">thread link</a>) | @zdw
<br/>
January 7, 2021 | https://blog.steren.fr/2020/my-stack-will-outlive-yours/ | <a href="https://web.archive.org/web/*/https://blog.steren.fr/2020/my-stack-will-outlive-yours/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="main">
  <article>
	<header>
		
		<time date="2020-12-22">December 2020</time>
	</header>

		<p>
		My stack requires no maintenance, has perfect Lighthouse scores, will never have any security vulnerability, is based on open standards, is portable, has an instant dev loop, has no build step and… will outlive any other stack.
		</p>
		<p>
		It’s not LAMP, Wordpress, Rails, MEAN, Jamstack... I don’t do CSR (Client-side rendering), SSR (Server Side Rendering), SSG (Static Site Generation)...
		</p>
		<p>
		My stack is <b>HTML+CSS</b>.
		</p>
		<p>
		And because my sources are in git, pushed to GitHub, <a href="https://pages.github.com/">GitHub Pages</a> is my host.
		</p>
		<p>
		Of course, I’m being a bit provocative here. I should rather say that, for some specific use cases, I concluded that to get top performances and to guatantee long term support, HTML+CSS was the best choice, instead on relying on technologies currently more popular. Because I’m done rewriting my site every couple of years.
		</p>

		<h3>Why HTML+CSS?</h3>
		<p>
		It all started with <a href="https://labs.steren.fr/">a blog</a>, that I was hosting on Wordpress.com (which is "Wordpress-as-a-Service", because the last thing I want to do is administer a Wordpress installation on my own server). I <strong>paid</strong> Wordpress.com to do one job: host my blog. And one day I looked at its sources and Lighthouse scores:
		</p>
		<figure>
			<img src="https://blog.steren.fr/2020/my-stack-will-outlive-yours/wordpress-sources.png" alt="Sources of my Wordpress.com blog, showing a lot of inlined unreadable scripts">
			<figcaption>Sources of my Wordpress.com blog, what is all this?</figcaption>
		</figure>
		<figure>
			<img src="https://blog.steren.fr/2020/my-stack-will-outlive-yours/wordpress-lighthouse.png" alt="Lighthouse scores of my Wordpress.com blog, showing 19/100 for Performance">
			<figcaption>Lighthouse score of my blog hosted on Wordpress.com</figcaption>
		</figure>
		<p>
		What have we done?
		</p>
		<p>
		Sure, these are the problems of one specific blogging platform. I’m pretty sure others are better, at least in terms of performance. But isn’t there something fundamentally wrong if displaying a short text with images takes seconds, loads countless render-blocking scripts, and has unreadable sources?
		</p>
		<p>
		My requirements were:
		</p>
		<ol>
			<li>performance</li>
			<li>simplicity</li>
			<li>long long term support</li>
		</ol>
		<p>
		It was time to say goodbye to Wordpress. I didn’t need 99% of its features anyway. Other blogging platforms didn’t meet expectations either (I seriously have no idea why so many people publish on Medium… behind a login wall). I looked at static site generators like Jekyll, Hugo, 11ty, but all of these require tooling installed, have a build step and will ultimately need some updates or be abandonned by their maintainer. What if we also get rid of these?
		</p>
		<p>
		The best tool is no tool, the best build step is no build step, the best update is no update. HTML gives us all that, and more.
		</p>

		<figure>
			<img src="https://blog.steren.fr/2020/my-stack-will-outlive-yours/lighthouse-score-pure-html-css.svg" alt="Lighthouse score of 100">
			<figcaption>Lighthouse score of this page</figcaption>
		</figure>

		<h3>What is the HTML+CSS stack good for?</h3>
		<p>
		Let’s first differentiate between what I call a web <em>page</em> and a web <em>app</em>: The goal of a web <em>page</em> is to serve content, on the other hand, the goal of a web <em>app</em> is to enable the user to perform interactive tasks. Of course, there are in-betweens, often in the form of content that might need customization depending on the logged in user and content that might allow some interactions.
		</p>
		<p>
		HTML+CSS fits the web <em>page</em> use case. Wow, what a revelation! It might seem obvious, but it seems we’ve all forgotten this these days. HTML+CSS does not fit the web <em>app </em>use case, or any in between.
		</p>
		<p>
		We said a web <em>page</em> serves content, but let’s dive into more concrete use cases:
		</p>
		<ul>
			<li>Product / Company / Business landing page and marketing sites</li>
			<li>Personal portfolio / bio</li>
			<li>Blog</li>
			<li>Documentation</li>
		</ul>

		<h3>How to develop for HTML+CSS?</h3>
		<p>
		Authoring a pure HTML+CSS site can be done in any text editor, in any environment (any desktop OS, any smartphone, or even directly using GitHub’s single file editor) and previewed by simply opening the file in any browser.
		</p>
		<p>
		Keep the HTML of every page minimal and semantic. First, because there is no need for countless of &lt;div&gt;, but then because it makes sources more readable and easier to edit. See for example the <a href="https://github.com/steren/blog/blob/master/2020/my-stack-will-outlive-yours/index.html">HTML sources of this page</a>: a total of 150 lines, 100 lines are for the content, the rest is metadata and page structure, nothing extra. 
		</p>
		<p>
		For consistency, all pages that need to share the same style can point to the same CSS file. This avoids  duplication when it comes to styling (but note that loading this file creates an extra HTTP request, which could be avoided if style was inlined).
		</p>
		<p>
		When not cluttered with unnecessary scripts, divs or classes, I have no issue writing HTML directly. Yes, the paragraph tags are a bit annoying and distracting, but proper indentation and syntax highlighting mitigate this.
		<br>
		Sometimes, for drafting long blog articles, I’m working in Google Docs, and when I’m happy, export the content to clean HTML using an add-on. Google Docs is awesome for collaboration, with powerful suggestions and commenting system. That’s ideal for the “draft” phase. 
		<br>
		Because all content is in git, final review and approval can be done via GitHub pull requests.
		</p>
		<p>
		When I publish a new page, I need to link to it manually from the index page. I’m OK with that. It’s done in one line. It also allows me to have more control over when I want the page to be “published”.
		</p>
		<p>
		I don't need to pay for custom themes, I have complete freedom in the style and layout of my site.
		I can embed anything I want without being restricted by the choice of the hosting platform: SVG images, 3D models, interactive JS experiences. 
		</p>
		<p>
		Creating a new page requires to clone an existing one.
		So... if I don’t use any templating system, how do I update my header, footer or nav? Well, simply by using the ”Replace in files” feature of any good text editor. They don’t need frequent updates anyway. The benefits of using a templating system is not worth the cost of introducing the tooling it requires.
		</p>
		
		<h3>In conclusion</h3>
		<p>
		You don’t need  Wordpress, or Hugo to put a blog online, or Angular, React or Next.js to put a web page online. Raw HTML and CSS do the job.
		</p>
		<p>
		That being said, you’ll need to pick up some tooling or framework if you want to build a web app or add more interactivity or customization to your web pages. And for that, I’m very glad to see that frameworks now seem to be prioritizing performance, notably by prioritizing serving the content first and leveraging caching whenever possible. The era of “download 5MB of JS first and then download content from a REST API” seems to be over for content web pages. (I personally think it’s still OK to do so for web apps, as the user’s intent and expectations are different).
		</p>
		<p>
		Is the “HTML+CSS only” approach a bit extreme? A bit, it’s basically saying “all software is terrible, how can I minimize my dependencies on software”. Web standards are a model of backward compatibility. I’m pretty confident that my web pages written in raw HTML+CSS will have no issue being accessed and authored 10 years from now, without me having to do anything.
		</p>  
	</article>
</div></div>]]>
            </description>
            <link>https://blog.steren.fr/2020/my-stack-will-outlive-yours/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25673495</guid>
            <pubDate>Thu, 07 Jan 2021 16:54:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[No meetings, no deadlines, no full-time employees]]>
            </title>
            <description>
<![CDATA[
Score 1278 | Comments 494 (<a href="https://news.ycombinator.com/item?id=25673275">thread link</a>) | @sahillavingia
<br/>
January 7, 2021 | https://sahillavingia.com/work | <a href="https://web.archive.org/web/*/https://sahillavingia.com/work">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><label>Jan 7, 2021 • 10 min read</label><h2>No Meetings, No Deadlines, No Full-Time Employees</h2><p>I started Gumroad in 2011. In 2015, we reached a peak of 23 full-time employees. In 2016, after <a href="https://sahillavingia.com/reflecting">failing</a> to raise more money, I ended up back where I began: a one-person company.</p><p>Today, when I’m asked how many people work at Gumroad, I respond with “ten or so.” That’s how I convert the number of people we have into what others expect. But the truth is more complicated:</p><p>If we include everyone who works on Gumroad, it’s 25.</p><p>If we include full-time employees, it’s none. Not even me.</p><p>We have no meetings, and no deadlines either.</p><p>And it’s working: our creators earn over $175 million a year, and we generate $11 million in annualized revenue, growing 85% year-over-year.</p><p><img src="https://sahillavingia.com/2020-earnings.png"></p><p>That said, I don’t expect anyone to copy our way of working wholesale. We got here on accident, not some grand plan.</p><p>However, I do think there are pieces of our story and the way we work that could benefit other companies, their people, and–most importantly–their customers.</p><h2>Freedom at all costs</h2><p>After the layoffs in 2015, even though the team shrunk, Gumroad itself continued to grow.</p><p><img src="https://sahillavingia.com/2018-earnings.png"></p><p>But hiring people full-time and leasing a new office in San Francisco to work out of was untenable. Instead, I found an Indian firm called <a href="https://bigbinary.com/">BigBinary</a> and hired a few engineers as contractors.</p><p>These contractors saved the company. They fixed bugs and maintained the site while I answered support tickets, designed features, and wrote about new initatives.</p><p>Eventually, I hired back the same customer support person we had from before the layoffs, this time via an hourly contracting agreement too.</p><p>Meanwhile, I <a href="https://sahillavingia.com/bubble">moved to Utah</a> and attempted to become a full-time creator.</p><p>While Gumroad was no longer on track to become a billion-dollar company, I acquired a new asset: time. I used that time to take classes on writing and painting.</p><p>Because I was burned out and didn’t want to think about working any more than I needed to, I instituted a no-meeting, no-deadline culture.</p><p>For me, it was no longer about growth at all costs, but “freedom at all costs.”</p><p>This way, Gumroad stayed profitable, I could take a much-needed break to explore my hobbies, and the product continued to improve over time.</p><p><img src="https://sahillavingia.com/operating.png"></p><h2>How we work</h2><p>Today, working at Gumroad resembles working on an open source project like Rails. Except it’s neither open source, nor unpaid.</p><p>Instead of having meetings, people “talk” to each other via GitHub, Notion, and (occasionally) Slack, expecting responses within 24 hours. Because there are no standups or “syncs” and some projects can involve expensive feedback loops to collaborate, working this way requires clear and thoughtful communication.</p><p>Everyone writes well, and writes <em>a lot</em>.</p><p>There are no deadlines either. We ship incrementally, and launch things whenever the stuff in development is better than what’s currently in production. The occasional exception does exist, such as a tax deadline, but as a rule, I try not to tell anyone what to do or how fast to do it. When someone new joins the company, they do what everyone else does: go into our Notion queue, pick a task, and get to work, asking for clarification when needed.</p><p>Instead of setting quarterly goals or using OKRs, we move towards a single north star: maximizing how much money creators earn. It’s simple and measurable, allowing anyone in the company to do the math on how much a feature or bug-fix might be worth.</p><p>But we don’t prioritize ruthlessly.</p><p>People can work on what’s fun or rely on their intuition, because as long as we remain profitable and keep shipping, we tend to get to the important stuff eventually. Our <a href="https://www.notion.so/gumroad/Roadmap-ce2ad07c483046e7941227ad7810730d">public roadmap</a> helps Gumroad's creators hold us accountable.</p><p>We ship big things this way too.</p><p>In November 2020, we shipped <a href="https://gumroad.com/gumroad/p/introducing-gumroad-memberships">Gumroad Memberships</a>, a year in the works and now used by hundreds of creators to earn over $1,500,000 per month.</p><p>This is a screenshot from our roadmap to show what it looks like in practice:</p><p><img src="https://sahillavingia.com/memberships-roadmap.png"></p><p>For more, I recorded <a href="https://www.youtube.com/watch?v=2PcIC1DKBU0">an hour-long video</a> about how we ship something as large as Gumroad Memberships.</p><p>Gumroad engineer Helen Hood, who shipped Memberships, says, “it’s one of the biggest product launches of my career, and we shipped it without a single meeting or video call. I've worked at your typical startup, with an open floor plan, lots of whiteboards, standups and sprint planning, beers after work. I’ve also worked on a remote team with little communication and engineers largely siloed on their own projects. The way we work at Gumroad is ideal for me. It lets me maximize my productive hours, and clock out when I've hit my limit.”</p><p>Those are the broad strokes, but we’ve published more specific documentation about the way we work:</p><ul><li><a href="https://www.notion.so/gumroad/How-do-we-decide-what-to-work-on-f2064b8ab16c4cbcac1077e16c8cf33b">How do we decide what to work on?</a><p>“At the end of the day there's a lot of emotion that goes into Gumroad, that's not dissimilar from an art project. We sometimes pick what's fun and feels good to work on! We love listening to creators! We don't do tons of data analysis to decide what's worth working on.”</p></li><li><a href="https://www.notion.so/gumroad/How-do-we-communicate-06f2032bfdae4552a38149c99c68e3df">How do we communicate?</a><p>“Turn off all notifications from your phone!”</p></li><li><a href="https://www.notion.so/gumroad/What-does-working-at-Gumroad-feel-like-7d9fd1c9548245a58afe5569d76a7960">What does working at Gumroad feel like?</a><p>“We ship incrementally, iteratively, and have one massive tentpole launch a year. Every month we see how much creators got paid, then we move on. The journey is the fun part, we're not waiting to arrive at some destination.”</p></li><li><a href="https://www.notion.so/gumroad/What-s-not-so-good-at-Gumroad-847e3c285b1f45ab955ebacf52867900">What’s not so good at Gumroad?</a><p>“There's not a lot of room for growth. We're staying profitable, and not planning to double the team every year. While there will likely be a few leadership roles, there aren't plenty of them and they aren't built into the career path of working at Gumroad.”</p></li></ul><p>Gumroad’s Chris Maximin says, “this way to work is responsible for the highest level of productivity I've ever experienced. The ability to focus on actual work creates a virtuous circle benefiting both the company and the workers: 1) the company does not have to pay expensive engineers to sit around in endless, useless meetings, and 2) the engineers get to do more and learn more, which benefits them in the long term.”</p><p>This isn’t just for engineers.</p><p>Justin Mikolay, a writer at Gumroad, ships each of our <a href="https://gumroad.com/l/BCMDz">Creator Spotlights</a> this way, even though each one requires at least three people–plus the creator.</p><p><em>Everything</em> is handled this way: support, risk, content, growth, product prioritization, board decks, design feedback, and more.</p><h2>Minimum viable culture</h2><p>This way of working isn’t for everyone.</p><p>There are no retreats planned, and no social channels in Slack. There are limited opportunities for growth. And we can’t compete with the comp packages that big tech companies can provide.</p><p>But we can compete–and win–on flexibility.</p><p><a href="https://twitter.com/sidyadav">Sid Yadav</a>, former VP of Product at Teachable, joined Gumroad in 2018.</p><p>In his words, “most entrepreneurs have two options: work a full-time job and hustle nights/weekends, or leave your job and risk everything to start the company. Gumroad provided a third way: I could contract 20-35 hours a week, and for a couple days a week, incubate ideas and work on my next thing.”</p><p>In 2020, Sid left Gumroad to start his own creator economy company, <a href="https://circle.so/">Circle</a>, together with former Gumroad coworker <a href="https://community.circle.so/u/45ef416b">Rudy Santino</a>:</p><blockquote><p lang="en" dir="ltr">I’m starting a new company: <a href="https://t.co/BW40WmGBlF">https://t.co/BW40WmGBlF</a>! I’ll be sharing more about it in the coming weeks, but today I wanted to show gratitude to the life situation that made this possible: contracting for a flexible remote startup — <a href="https://twitter.com/gumroad?ref_src=twsrc%5Etfw">@gumroad</a>. It wouldn’t have happened without it.</p>— Sid Yadav (@sidyadav) <a href="https://twitter.com/sidyadav/status/1216761573479473152?ref_src=twsrc%5Etfw">January 13, 2020</a></blockquote> <p>Working on Gumroad isn't a majority of anyone's identity.</p><p>People work at Gumroad as little as they need to sustain the other parts of their lives they prefer to spend their time and energy on: a creative side-hustle, their family, or anything else.</p><p>Gumroad engineer Nathan Chan says, “I produce more value for my time than at any other company in my career, and I’m able to fully participate in parenting and watching my kiddo grow up.”</p><p>That includes me.</p><p>From 2011 to 2016, building Gumroad was my singular focus in life. But today, it is just a part of my life, like a hobby might be. For example, I paint for fun, and every once in a while, I sell a painting.</p><h2>A company of creators</h2><p>One day, out of the blue, I received an email from <a href="https://twitter.com/dvassallo">Daniel Vassallo</a>. I knew Daniel; he was a creator who had made over $250,000 on Gumroad in less than a year.</p><p>He was already using the product–so he understood what problems Gumroad ought to solve next–and he had some ideas for how he could help out:</p><blockquote>I love Gumroad (and I’m living off it!), I enjoy product scoping and strategy, and I think I can take over your PM tasks. I would only be able to dedicate around 2hrs/day on average, but I’d be available daily. Don’t know if this is the type of commitment you had in mind, but I figured if there’s a place where this arrangement can work, it’s Gumroad :)</blockquote><p>It was a perfect fit. Daniel became our new Head of Product.</p><p>It can be a great deal for Gumroad too. Before Daniel quit his job at Amazon, he was making over $400,000 a year. We pay him $120,000 a year.</p><p>How? He works ten hours a week for us. In his words:</p><blockquote><p lang="en" dir="ltr">Almost nobody is seeing this trend as an opportunity to work less, rather than to earn more. <a href="https://t.co/U9YBqp1ebn">https://t.co/U9YBqp1ebn</a></p>— Daniel Vassallo (@dvassallo) <a href="https://twitter.com/dvassallo/status/1334288446697865216?ref_src=twsrc%5Etfw">December 3, 2020</a></blockquote> <h2>Getting paid</h2><p>In practice, we pay everyone hourly based on their role. The range varies from $50 (customer support) to $250 (Head of Product) an hour.</p><p>Recently I standardized our rates world-wide:</p><blockquote><p lang="en" dir="ltr">🌍🌎🌏 Excited to announce we've deprecated all location-based pay! Gumroad will now pay you the same salary, no matter if you live in San Francisco, Bangalore, Lagos, or anywhere else.</p>— Sahil (@shl) <a href="https://twitter.com/shl/status/1334201934702493697?ref_src=twsrc%5Etfw">December 2, 2020</a></blockquote> <p>This rate is agreed upon during our interview process:</p><ol><li>Apply via a form.</li><li>An unpaid, few-hour challenge, that resembles the high-level work we do at Gumroad. This may include breaking down a large shipment (like Gumroad Memberships) into its atomic parts, planning the schema associated with a new feature, or writing up a Help Center article.</li><li>A paid, few-week trial period, that resembles the day-to-day work we do at Gumroad. This may …</li></ol></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://sahillavingia.com/work">https://sahillavingia.com/work</a></em></p>]]>
            </description>
            <link>https://sahillavingia.com/work</link>
            <guid isPermaLink="false">hacker-news-small-sites-25673275</guid>
            <pubDate>Thu, 07 Jan 2021 16:41:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Elon Musk throws a jab at Facebook, suggests using Signal instead of WhatsApp]]>
            </title>
            <description>
<![CDATA[
Score 21 | Comments 5 (<a href="https://news.ycombinator.com/item?id=25672773">thread link</a>) | @CarCooler
<br/>
January 7, 2021 | https://www.teslaoracle.com/2021/01/07/elon-musk-suggests-signal-instead-whatsapp-jabs-facebook/ | <a href="https://web.archive.org/web/*/https://www.teslaoracle.com/2021/01/07/elon-musk-suggests-signal-instead-whatsapp-jabs-facebook/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        
			<figure data-amp-original-style="margin-bottom:30px;">
            <figcaption data-amp-original-style="border:1px dotted blue; margin:2px 0; text-align:center;">Advertisement</figcaption>
            <amp-ad width="100vw" height="320" type="adsense" data-ad-client="ca-pub-0923072950810999" data-ad-slot="4076643206" data-auto-format="rspv" data-full-width="" i-amphtml-layout="fixed">
              
            </amp-ad>
            </figure>
				<!-- .Adsense Ad -->

		
<p>At an early hour of the morning, Tesla &amp; SpaceX CEO Elon Musk tweeted “Use Signal” — the precursor for this tweet was an earlier reply to WhatsApp’s recent policy that forcefully asks to comply to data sharing with Facebook.</p>



<figure></figure>



<div><figure><a href="https://evannex.com/?ref=Iqtidar_TeslaOracle_EVANNEX_Banner" target="_blank" rel="sponsored noopener noreferrer"><amp-img src="https://www.teslaoracle.com/wp-content/uploads/2020/10/evannex_googlead_300x250.jpg" alt="" width="300" height="250" layout="intrinsic" i-amphtml-layout="intrinsic"><img src="https://www.teslaoracle.com/wp-content/uploads/2020/10/evannex_googlead_300x250.jpg" alt="" width="300" height="250" data-old-src="data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9JzI1MCcgd2lkdGg9JzMwMCcgeG1sbnM9J2h0dHA6Ly93d3cudzMub3JnLzIwMDAvc3ZnJyB2ZXJzaW9uPScxLjEnLz4="></amp-img></a><figcaption>– Sponsored –</figcaption></figure></div>



<figure><div>
<amp-twitter width="600" height="480" layout="responsive" data-tweetid="1347165930674012168" data-width="550" data-dnt="true" i-amphtml-layout="responsive"><i-amphtml-sizer></i-amphtml-sizer><blockquote data-width="550" data-dnt="true" placeholder=""><p lang="en" dir="ltr">Yes exactly. Time to switch to Signal, folks. Open-source and independent. E2E encrypted (WhatsApp's encryption is based on the Signal protocol). Supports groups and video call now.</p>— Pranay Pathole (@PPathole) <a href="https://twitter.com/PPathole/status/1347165930674012168?ref_src=twsrc%5Etfw">January 7, 2021</a></blockquote></amp-twitter>
</div></figure>



<p>WhatsApp is actually owned by Facebook Inc. (FB), now Facebook is apparently trying to widen its human data research to the next level. With the past scandals like Cambridge Analytica, the social media platform’s credibility has been shaken.</p>



<p>Interestingly, the Cambridge Analytica scandal surfaced within a few weeks after Elon Musk <a href="https://www.theverge.com/2018/3/23/17156402/elon-musk-deleted-tesla-and-spacex-facebook-pages-twitter-challenge" target="_blank" rel="noreferrer noopener">ordered</a> to remove <a href="https://www.teslaoracle.com/topic/spacex/">SpaceX</a>, <a href="https://www.teslaoracle.com/">Tesla</a>, and his official page from Facebook. Musk has been a staunch opposer of Facebook and regularly criticizes the social media platform for bad user experience and possible misuse of personal data.</p>



<div><figure><amp-img width="465" height="1024" src="https://www.teslaoracle.com/wp-content/uploads/2021/01/WhatsApp-2021-Agreement.jpg" alt="WhatsApp 2021 agreement screenshot." srcset="https://www.teslaoracle.com/wp-content/uploads/2021/01/WhatsApp-2021-Agreement.jpg 465w, https://www.teslaoracle.com/wp-content/uploads/2021/01/WhatsApp-2021-Agreement-136x300.jpg 136w" sizes="(max-width: 465px) 100vw, 465px" layout="intrinsic" disable-inline-width="" i-amphtml-layout="intrinsic"><img loading="lazy" width="465" height="1024" src="https://www.teslaoracle.com/wp-content/uploads/2021/01/WhatsApp-2021-Agreement.jpg" alt="WhatsApp 2021 agreement screenshot." srcset="https://www.teslaoracle.com/wp-content/uploads/2021/01/WhatsApp-2021-Agreement.jpg 465w, https://www.teslaoracle.com/wp-content/uploads/2021/01/WhatsApp-2021-Agreement-136x300.jpg 136w" sizes="(max-width: 465px) 100vw, 465px" data-old-src="data:image/svg+xml;base64,PHN2ZyBoZWlnaHQ9JzEwMjQnIHdpZHRoPSc0NjUnIHhtbG5zPSdodHRwOi8vd3d3LnczLm9yZy8yMDAwL3N2ZycgdmVyc2lvbj0nMS4xJy8+"></amp-img><figcaption>WhatsApp 2021 terms of use asking for mandatory data sharing compliance with Facebook. Source: <a href="https://www.xda-developers.com/whatsapp-updates-terms-privacy-policy-mandate-data-sharing-facebook/" target="_blank" rel="noreferrer noopener">XDA</a></figcaption></figure></div>



<figure>
<amp-ad width="100vw" height="320" type="adsense" data-ad-client="ca-pub-0923072950810999" data-ad-slot="7514654329" data-auto-format="rspv" data-full-width="" i-amphtml-layout="fixed">
  
</amp-ad>
</figure>



<p>In the new WhatsApp terms of use agreement (screenshot above), it’s clearly mentioned that if you do not agree with Facebook data sharing otherwise you will not be granted permission to use WhatsApp (a little rephrased I know but that’s what Facebook meant actually).</p>



<p>Now with WhatsApp’s mandatory data sharing with Facebook, <a href="https://www.teslaoracle.com/topic/elon-musk/">Elon Musk</a> decided to give a boost to Signal Private Messenger. As of this writing, Signal Messenger 570k+ users on Google Playstore vs. 127 million+ WhatsApp users. With Musk’s more than 41 million followers on Twitter, the number of Signal users is likely to hike in the coming hours, days, and weeks.</p>



<p>Another interesting bit is that Elon Musk has now <a href="https://www.bloomberg.com/news/articles/2021-01-06/musk-close-to-surpassing-bezos-as-world-s-richest-person" target="_blank" rel="noreferrer noopener">become</a> the world’s richest person with Tesla stock reaching an all-time high of $796.12 ($3,980.6 pre-split) at the time of this writing.</p>



<p>However, Signal offers real end-to-end encryption for enhanced security and privacy. <a href="https://signal.org/" target="_blank" rel="noreferrer noopener nofollow">Signal Messenger</a> has no social media partners to share data for profit and that’s even better.</p>



<p>The dilemma is, how we are going to convince our friends and family to migrate to Signal when they are addicted to WhatsApp, I don’t see that happening very soon.</p>



<p>For more interesting stories about Elon Musk, Tesla, and SpaceX, follow us on:<br><a rel="noreferrer noopener" href="https://news.google.com/publications/CAAqBwgKMOarmgswgLayAw" target="_blank">Google News</a>&nbsp;|&nbsp;<a rel="noreferrer noopener nofollow" href="https://flipboard.com/@TeslaOracle" target="_blank">Flipboard</a>&nbsp;|&nbsp;<a rel="noreferrer noopener nofollow" href="https://feedly.com/i/subscription/feed%2Fhttps%3A%2F%2Fwww.teslaoracle.com%2Ffeed%2F" target="_blank">RSS (Feedly)</a></p>
		<!-- Adsense Matched -->
        <figure>
        <amp-ad width="100vw" height="320" type="adsense" data-ad-client="ca-pub-0923072950810999" data-ad-slot="9763094783" data-auto-format="mcrspv" data-full-width="" i-amphtml-layout="fixed">
          
        </amp-ad>
        </figure><!-- Adsense Matched End -->
		</div></div>]]>
            </description>
            <link>https://www.teslaoracle.com/2021/01/07/elon-musk-suggests-signal-instead-whatsapp-jabs-facebook/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25672773</guid>
            <pubDate>Thu, 07 Jan 2021 16:15:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: I built an intercom for my 6 yo to keep us connected during quarantine]]>
            </title>
            <description>
<![CDATA[
Score 177 | Comments 122 (<a href="https://news.ycombinator.com/item?id=25671919">thread link</a>) | @daylankifky
<br/>
January 7, 2021 | https://chordata.cc/blog/open-source-intercom-for-kids/ | <a href="https://web.archive.org/web/*/https://chordata.cc/blog/open-source-intercom-for-kids/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
			<!-- .entry-container -->

			<div>
				
<pre><em>Today we’ll take a turn and showcase a personal project developed by our Tech Lead, Bruno, who took the multiple hours of lockdown we experienced last year and turned them into an initiative that allowed him to communicate with his 6 year old daughter. Below you’ll be able to review his experience and gather all of the details of his project (in case you want to replicate his system).</em></pre>



<p>In terms of social interactions, 2020 was an odd year, with cyclic lockdowns and openings. <strong>Keeping in touch with our close ones was one of the main challenges for all of us</strong>. The lockdowns are a bizarre experience in itself, but one of the strangest parts for me was when I topped it all up with a fever. It ended up being just a regular flu in the end, but for precaution my doctor ordered me to lock me down in a room for two weeks. Being there just a few meters away from my family and not being able to hug them or have a direct conversation was <strong>hard for all of us, but especially for my six-year-old daughter who wasn’t able to wrap her head around the reasons we couldn’t just see each other.</strong></p>



<p>So this time I decided to build something for her to keep us in touch in case something similar happens. The basic concept is a <strong>simplified interface for a Telegram voice chat with only a few (big) buttons: it should allow to easily and intuitively send and receive voice messages</strong>. Of course having a raspberry-pi as the core of this device was a no-brainer, since It has everything that’s needed for the project: WiFi connectivity, low level interface to control leds and buttons, and of course a complete OS where to run a Python interpreter to control everything.</p>



<div><figure><img src="https://chordata.cc/wp-content/uploads/2021/01/daddy_box_blueprint-300x217.jpg" alt="" width="538" height="389" srcset="https://chordata.cc/wp-content/uploads/2021/01/daddy_box_blueprint-300x217.jpg 300w, https://chordata.cc/wp-content/uploads/2021/01/daddy_box_blueprint-1024x739.jpg 1024w, https://chordata.cc/wp-content/uploads/2021/01/daddy_box_blueprint-768x555.jpg 768w, https://chordata.cc/wp-content/uploads/2021/01/daddy_box_blueprint-640x462.jpg 640w, https://chordata.cc/wp-content/uploads/2021/01/daddy_box_blueprint-100x72.jpg 100w, https://chordata.cc/wp-content/uploads/2021/01/daddy_box_blueprint.jpg 1108w" sizes="(max-width: 538px) 100vw, 538px"></figure></div>



<h3>TUI</h3>



<p>A good idea when dealing with electronic projects is to <strong>start small and have a proof of concept working before getting all the components</strong> and wire the whole thing together. In this case I started by creating the main program but replacing the physical button interface with a <em>TUI</em> (terminal user interface). The code can be found <a href="https://gitlab.com/daylanKifky/daddy-box-python-module" target="_blank" rel="noreferrer noopener">in this repository</a>, you should be able to test it by running it using the <code>--tui</code> flag like this:</p>



<pre>python -m daddy_box --tui</pre>



<div><figure><img src="https://chordata.cc/wp-content/uploads/2021/01/daddy_box_tui.jpg" alt="" srcset="https://chordata.cc/wp-content/uploads/2021/01/daddy_box_tui.jpg 575w, https://chordata.cc/wp-content/uploads/2021/01/daddy_box_tui-300x242.jpg 300w, https://chordata.cc/wp-content/uploads/2021/01/daddy_box_tui-100x81.jpg 100w" sizes="(max-width: 575px) 100vw, 575px"></figure></div>



<h3>Telegram bot setup</h3>



<p>The first time you run it you will need to give it a telegram bot key. Follow <a href="https://core.telegram.org/bots#3-how-do-i-create-a-bot" target="_blank" rel="noreferrer noopener">this steps</a> to create your instance of a Bot, and then run it with the <code>--setup-bot</code> flag and input the information the <em>BotFather</em> gave you.</p>



<p>You should now be able to search for the bot’s username in telegram and exchange some messages with it. You will first find that you get “not allowed” responses. The <strong>idea behind this bot is to exchange messages privately with just one user</strong>, so you have to tell the bot which is the allowed user id to interact with.</p>



<p>Take a look at the terminal where the bot is running, you will see some printed messages like this one:</p>



<div><figure><img src="https://chordata.cc/wp-content/uploads/2021/01/daddy_box_user_id.png" alt="" srcset="https://chordata.cc/wp-content/uploads/2021/01/daddy_box_user_id.png 571w, https://chordata.cc/wp-content/uploads/2021/01/daddy_box_user_id-300x66.png 300w, https://chordata.cc/wp-content/uploads/2021/01/daddy_box_user_id-100x22.png 100w" sizes="(max-width: 571px) 100vw, 571px"></figure></div>



<p>Copy your user-id from there and give it to the bot using the <code>--setup-user</code> flag.  You should now be able to send and receive voice messages, so we are ready to start with the physical part of the project.</p>







<h3>Raspberry pi HAT</h3>



<p>When doing a one-shot project like this I normally use breadboards or perfboards to assemble all the components. I used that approach a bunch of times in the past to handle a few backlitghted buttons, and the process was always frustrating: I ended up spending lots of time with the soldering and wiring of the components. So this time I decided to actually do what I promised myself each one of those times: design a <strong>breakout HAT for the raspberry with screw terminals where to easily connect everything.</strong></p>



<p>Since I was at it I added a darlington array and a number of selectable power sources in order to potentially handle bigger loads. I designed it in Kicad and then ordered a few PCBs. You can find the project files <a href="https://gitlab.com/daylanKifky/daddy-box-raspberry-pi-hat" target="_blank" rel="noreferrer noopener">here</a>.</p>



<div><figure><img src="https://chordata.cc/wp-content/uploads/2021/01/daddy_box_HAT-1024x681.jpg" alt="" width="583" height="388" srcset="https://chordata.cc/wp-content/uploads/2021/01/daddy_box_HAT-1024x681.jpg 1024w, https://chordata.cc/wp-content/uploads/2021/01/daddy_box_HAT-300x199.jpg 300w, https://chordata.cc/wp-content/uploads/2021/01/daddy_box_HAT-768x511.jpg 768w, https://chordata.cc/wp-content/uploads/2021/01/daddy_box_HAT-640x425.jpg 640w, https://chordata.cc/wp-content/uploads/2021/01/daddy_box_HAT-100x66.jpg 100w, https://chordata.cc/wp-content/uploads/2021/01/daddy_box_HAT.jpg 1053w" sizes="(max-width: 583px) 100vw, 583px"></figure></div>



<h3>Audio</h3>



<p>One little detail I wasn’t taking into consideration when I started the project was the fact that a <strong>raspberry pi doesn’t have an audio input</strong>.<strong> So I had to buy an USB microphone.</strong> A cheap one from a local store did the trick. I removed all the plastic parts and shortened the cable to avoid unnecessary EM interference.</p>



<div><figure><img src="https://chordata.cc/wp-content/uploads/2021/01/daddy_box_mic.jpg" alt="" width="322" height="443" srcset="https://chordata.cc/wp-content/uploads/2021/01/daddy_box_mic.jpg 581w, https://chordata.cc/wp-content/uploads/2021/01/daddy_box_mic-218x300.jpg 218w, https://chordata.cc/wp-content/uploads/2021/01/daddy_box_mic-349x480.jpg 349w, https://chordata.cc/wp-content/uploads/2021/01/daddy_box_mic-73x100.jpg 73w" sizes="(max-width: 322px) 100vw, 322px"></figure></div>



<p>Before using it I also tried a small USB audio card but I had a lot of conflicts being raised by <a rel="noreferrer noopener" href="http://people.csail.mit.edu/hubert/pyaudio/" target="_blank">pyaudio,</a> the library I used to handle the recording and playing of audio files in python.</p>



<p>For the audio output I connected a small speaker directly to the RPi audio output jack. The volume is a little low, but it gets the work done.</p>



<h3>Final assembly</h3>



<p>Once the PCBs and all the components arrived it was time to replace the <em>TUI</em> with a Button UI. I used the handy <a href="https://gpiozero.readthedocs.io/en/stable/" target="_blank" rel="noreferrer noopener">gpiozero</a> library to handle button press and leds. For the external case I used a shoe box to which I made holes for the buttons and speaker.</p>



<div>
<div>
<figure><img src="https://chordata.cc/wp-content/uploads/2021/01/daddy_box_assembly1-1024x576.jpg" alt="" srcset="https://chordata.cc/wp-content/uploads/2021/01/daddy_box_assembly1-1024x576.jpg 1024w, https://chordata.cc/wp-content/uploads/2021/01/daddy_box_assembly1-300x169.jpg 300w, https://chordata.cc/wp-content/uploads/2021/01/daddy_box_assembly1-768x432.jpg 768w, https://chordata.cc/wp-content/uploads/2021/01/daddy_box_assembly1-640x360.jpg 640w, https://chordata.cc/wp-content/uploads/2021/01/daddy_box_assembly1-100x56.jpg 100w, https://chordata.cc/wp-content/uploads/2021/01/daddy_box_assembly1.jpg 1422w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>




</div>



<div>
<figure><img src="https://chordata.cc/wp-content/uploads/2021/01/daddy_box_assembly2-1024x576.jpg" alt="" srcset="https://chordata.cc/wp-content/uploads/2021/01/daddy_box_assembly2-1024x576.jpg 1024w, https://chordata.cc/wp-content/uploads/2021/01/daddy_box_assembly2-300x169.jpg 300w, https://chordata.cc/wp-content/uploads/2021/01/daddy_box_assembly2-768x432.jpg 768w, https://chordata.cc/wp-content/uploads/2021/01/daddy_box_assembly2-640x360.jpg 640w, https://chordata.cc/wp-content/uploads/2021/01/daddy_box_assembly2-100x56.jpg 100w, https://chordata.cc/wp-content/uploads/2021/01/daddy_box_assembly2.jpg 1422w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>
</div>
</div>



<div><figure><img src="https://chordata.cc/wp-content/uploads/2021/01/daddy_box_assembly3-1024x576.jpg" alt="" width="493" height="277" srcset="https://chordata.cc/wp-content/uploads/2021/01/daddy_box_assembly3-1024x576.jpg 1024w, https://chordata.cc/wp-content/uploads/2021/01/daddy_box_assembly3-300x169.jpg 300w, https://chordata.cc/wp-content/uploads/2021/01/daddy_box_assembly3-768x432.jpg 768w, https://chordata.cc/wp-content/uploads/2021/01/daddy_box_assembly3-640x360.jpg 640w, https://chordata.cc/wp-content/uploads/2021/01/daddy_box_assembly3-100x56.jpg 100w, https://chordata.cc/wp-content/uploads/2021/01/daddy_box_assembly3.jpg 1422w" sizes="(max-width: 493px) 100vw, 493px"></figure></div>



<p>Once everything was set and tested I disassembled and packed all the components inside the box, wrapped the whole thing as a gift to prepare it for the best part.</p>



<h3>XMAS</h3>



<p>I gave the box as a present to my daughter to be opened on Christmas eve without telling her what the purpose of all those parts were. <strong>The next morning we spent a couple of hours putting it all together, so she discovered the purpose of the device, its final shape and got a glimpse of the internal functionality during the process.</strong></p>



<div><figure><img src="https://chordata.cc/wp-content/uploads/2021/01/daddy_box_assemblykid-1024x576.jpg" alt="" width="510" height="286" srcset="https://chordata.cc/wp-content/uploads/2021/01/daddy_box_assemblykid-1024x576.jpg 1024w, https://chordata.cc/wp-content/uploads/2021/01/daddy_box_assemblykid-300x169.jpg 300w, https://chordata.cc/wp-content/uploads/2021/01/daddy_box_assemblykid-768x432.jpg 768w, https://chordata.cc/wp-content/uploads/2021/01/daddy_box_assemblykid-640x360.jpg 640w, https://chordata.cc/wp-content/uploads/2021/01/daddy_box_assemblykid-100x56.jpg 100w, https://chordata.cc/wp-content/uploads/2021/01/daddy_box_assemblykid.jpg 1422w" sizes="(max-width: 510px) 100vw, 510px"></figure></div>



<p>When it was done my kid liked it way more than I could ever expect. What I conceived as an utilitary tool to keep us connected when I wasn’t close soon became a part of a game of exchanging messages about every little action in the everyday routine, even when we are just a few meters away 😅.&nbsp;</p>



<p>So I’m quite happy with the result. Not only did this object help strengthen our relationship, it ended up being a <strong>cool way to transmit the hacker-maker values and habits to a young mind.</strong></p>



<p>I hope some of you find this useful and if you try to build this at home I would love to know how it went for you, please share your experience in <a href="https://forum.chordata.cc/">our forum</a> using the <em>offtopic</em> tag.</p>



<p>And above all, have a great starting of the year!</p>



<figure><img src="https://chordata.cc/wp-content/uploads/2021/01/daddy_box_final-1024x576.jpg" alt="" srcset="https://chordata.cc/wp-content/uploads/2021/01/daddy_box_final-1024x576.jpg 1024w, https://chordata.cc/wp-content/uploads/2021/01/daddy_box_final-300x169.jpg 300w, https://chordata.cc/wp-content/uploads/2021/01/daddy_box_final-768x432.jpg 768w, https://chordata.cc/wp-content/uploads/2021/01/daddy_box_final-640x360.jpg 640w, https://chordata.cc/wp-content/uploads/2021/01/daddy_box_final-100x56.jpg 100w, https://chordata.cc/wp-content/uploads/2021/01/daddy_box_final.jpg 1422w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>
			</div><!-- .entry-content -->

			
		</div></div>]]>
            </description>
            <link>https://chordata.cc/blog/open-source-intercom-for-kids/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25671919</guid>
            <pubDate>Thu, 07 Jan 2021 15:11:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[German Foreign Minister: Those Who Incite Bear Responsibility]]>
            </title>
            <description>
<![CDATA[
Score 67 | Comments 8 (<a href="https://news.ycombinator.com/item?id=25671401">thread link</a>) | @dakna
<br/>
January 7, 2021 | https://www.spiegel.de/international/world/german-foreign-minister-heiko-maas-those-who-incite-bear-responsibility-a-9e808002-67ee-4175-93b0-a01bf8e6dde2 | <a href="https://web.archive.org/web/*/https://www.spiegel.de/international/world/german-foreign-minister-heiko-maas-those-who-incite-bear-responsibility-a-9e808002-67ee-4175-93b0-a01bf8e6dde2">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>The images of the storming of the Capitol Building in Washington, D.C., are painful to the soul of every friend of democracy. The democratic world is shocked and appalled. But that’s not enough. We need all democrats around the world to stand shoulder to shoulder. The struggle against narrow-minded delusion, against intolerance, against the division of our societies is our common struggle. Indeed, it would be self-righteous to point the finger solely at America right now. Here in Germany, too, in <a target="_blank" rel="noopener noreferrer" href="https://www.spiegel.de/international/germany/when-far-right-hatred-turns-into-terrorism-a-e58ac378-bc7c-442e-a024-c801296d2b9c" data-link-flag="english">Hanau</a>, <a target="_blank" rel="noopener noreferrer" href="https://www.spiegel.de/international/germany/far-right-terrorism-in-germany-shooting-exposes-lapses-in-security-apparatus-a-1291075.html" data-link-flag="english">Halle </a>and on the steps of Reichstag (in coronavirus protests last summer), we have seen how agitation and inflammatory words can spark hateful deeds.</p><div>
<p>This should be extremely clear: Those who, like Trump, have spent years using words to constantly inflame and incite their own supporters, ultimately bear responsibility for this attack on the heart of American democracy. We see all around the world what happens when radical populists come to power and systematically stir up resentment against democratic institutions. Yes, democracy thrives on contradiction, even disagreement. But it dies when brute force silences the other, when sheer hatred breaks all bounds of decency and respect.</p><p>The radical mob does not represent the majority in the United States. The vast majority of American voters stand firmly behind democracy and voted decisively against a right-wing populist. And it’s not just Donald Trump who needs to finally accept that. Every Republican with a modicum of responsibility needs to finally repudiate Trump once and for all. The American courts have ruled clearly that this was a lawful election. Those who disrespect that election result are disrespecting their own people.</p>
</div><div>
<p>America’s strength is its diversity. It is admired around the world for the freedom of its democracy. U.S. president-elect Joe Biden knows this. His call yesterday for mutual respect and reconciliation were the soothing words of a president. And the confirmation of the election of Joe Biden and Kamala Harris by the U.S. Congress was the best democratic response to those who sowed chaos and discord in Washington yesterday.</p><p>As friends of America and as friends of democracy, we wish Joe Biden and Kamala Harris great strength in the difficult task of overcoming America’s division. We stand together with them in the fight for democracy. In keeping with the quintessential American motto: "E pluribus unum" – out of many, one.</p>
<p><span><svg aria-labelledby="title-680377a9-380e-453a-bdaa-8af27c3b1302" width="10" height="20" viewBox="0 0 10 20" fill="none" xmlns="http://www.w3.org/2000/svg" role="img"><title id="title-680377a9-380e-453a-bdaa-8af27c3b1302">Icon: Der Spiegel</title><g id="l-s-flag-680377a9-380e-453a-bdaa-8af27c3b1302"><path id="vector-680377a9-380e-453a-bdaa-8af27c3b1302" d="M9.85 16.293v-8H3.212V4.667h3.533v2.24h3.212v-3.2C9.85 2.747 8.993 2 8.03 2H1.713C.749 2 0 2.747 0 3.707v7.253h6.638v4.373H3.105v-2.986H0v3.84c0 .96.75 1.706 1.713 1.706H8.03c.963.107 1.82-.64 1.82-1.6z" fill="#000"></path></g></svg>
</span>
</p></div></div>]]>
            </description>
            <link>https://www.spiegel.de/international/world/german-foreign-minister-heiko-maas-those-who-incite-bear-responsibility-a-9e808002-67ee-4175-93b0-a01bf8e6dde2</link>
            <guid isPermaLink="false">hacker-news-small-sites-25671401</guid>
            <pubDate>Thu, 07 Jan 2021 14:30:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[MakAir: Covid-19 ventilator with a Raspberry Pi]]>
            </title>
            <description>
<![CDATA[
Score 95 | Comments 63 (<a href="https://news.ycombinator.com/item?id=25670303">thread link</a>) | @mtmail
<br/>
January 7, 2021 | https://blog.senx.io/makair-covid-19-ventilator-with-a-raspberry-pi/ | <a href="https://web.archive.org/web/*/https://blog.senx.io/makair-covid-19-ventilator-with-a-raspberry-pi/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>During the COVID-19 crisis, The birth of the first open source data enabled ventilator. </p><article>
      
<p>Back to March 20, 2020. <a href="https://twitter.com/waxzce" target="_blank" rel="noreferrer noopener">Quentin Adam</a>, with some friends living in Nantes, is trying to build a ventilator prototype with 3D printing and Arduino, in response to a shortage of equipment. </p>



<p><strong>Project MakAir is started</strong>. </p>



<p>Quentin, a software expert and CEO of <a href="https://www.clever-cloud.com/" target="_blank" rel="noreferrer noopener">Clever Cloud</a>, is struggling with the electronics part and looking for electronics engineers. Among his friends is Mathias, SenX CTO. That is how Mathias asked me to review the electronics part of the project. My first call with Quentin was to help him connect an old pressure sensor to an Arduino, during the late evening of March 20.</p>



<p><strong>The goal was clear: to mass-produce an open-source medical ventilator</strong>. Crazy! Looking at the project that day, it looked like an "amateur" project. So I did the first real schematics, the first BOM, the first Radiospares, and Farnell reference list during the weekend, discussing with more and more people on the MakAir Slack. </p>



<figure></figure>



<h3>Amateur? Not really...</h3>



<p>Next Thursday, I understood that the small "amateur" project is quickly getting big. Two electronics companies detached people, and a whole regulatory team was up. In this team, there were some experts in medical devices. We also knew that we were on a shortlist of projects that the French government is looking at closely.</p>



<p>I soon realized that in Nantes, there is no one able to actually make the prototypes. <a href="https://blog.senx.io/connecting-a-beertender-to-warp-10-using-mqtt-on-lorawan-with-thethingsnetwork/" target="_blank" rel="noreferrer noopener">Engineers with prototyping knowledge</a> are scarce, I just know a few of them like me. So, on the 25th during the evening, in a few minutes, I convinced Cherine, a former Renault Sport colleague living near Paris who has the same knowledge of prototyping as me, to join the project as well.</p>



<p><strong>On the 26th, I joined the MakAir core team, choosing to confine myself with 17 other people to make project MakAir a reality</strong>. Cherine came from Paris the same day I came from Brest. At the same time in France, 100 people were already helping us remotely. </p>



<p>I brought with me all my personal tools, from soldering iron to oscilloscope, and tons of components. </p>



<figure><blockquote><p>If I had been told this would last 25 days, I would have brought more than 3 days of clothing!</p></blockquote></figure>



<div><figure><img loading="lazy" src="https://blog.senx.io/wp-content/uploads/2020/09/DSC_6328-1024x682.jpg" data-src="https://blog.senx.io/wp-content/uploads/2020/09/DSC_6328-1024x682.jpg" alt="working in the Palace, Nantes" width="509" height="339" data-srcset="https://blog.senx.io/wp-content/uploads/2020/09/DSC_6328-1024x682.jpg 1024w, https://blog.senx.io/wp-content/uploads/2020/09/DSC_6328-300x200.jpg 300w, https://blog.senx.io/wp-content/uploads/2020/09/DSC_6328-768x512.jpg 768w, https://blog.senx.io/wp-content/uploads/2020/09/DSC_6328-1536x1024.jpg 1536w, https://blog.senx.io/wp-content/uploads/2020/09/DSC_6328-600x400.jpg 600w, https://blog.senx.io/wp-content/uploads/2020/09/DSC_6328.jpg 2000w" data-sizes="(max-width: 509px) 100vw, 509px" srcset="https://blog.senx.io/wp-content/uploads/2020/09/DSC_6328-1024x682.jpg 1024w, https://blog.senx.io/wp-content/uploads/2020/09/DSC_6328-300x200.jpg 300w, https://blog.senx.io/wp-content/uploads/2020/09/DSC_6328-768x512.jpg 768w, https://blog.senx.io/wp-content/uploads/2020/09/DSC_6328-1536x1024.jpg 1536w, https://blog.senx.io/wp-content/uploads/2020/09/DSC_6328-600x400.jpg 600w, https://blog.senx.io/wp-content/uploads/2020/09/DSC_6328.jpg 2000w"><figcaption>One sleepless night later, the first functional prototype was up.</figcaption></figure></div>







<p>Three days later, <strong>the <a href="http://www.cea.fr/" target="_blank" rel="noreferrer noopener">CEA</a></strong> (french government agency for atomic energy) is now supporting us. On the 31<sup>st</sup> of March, we all moved from Nantes to Grenoble CEA facility, traveling on a nearly empty motorway.</p>



<p>The first prototype had basic electronics: STM32 Nucleo, a small 4 lines screen, a few buttons, a good precision pressure sensor, and several servo outputs. <strong>This first prototype allows us to make a pig breath for 4 hours</strong> on the 3rd of April, only 2 weeks after the project started.</p>



<figure><ul><li><figure><img loading="lazy" width="1024" height="682" src="https://blog.senx.io/wp-content/uploads/2020/09/DSC_6336-1024x682.jpg" data-src="https://blog.senx.io/wp-content/uploads/2020/09/DSC_6336-1024x682.jpg" alt="" data-id="11640" data-link="https://blog.senx.io/?attachment_id=11640" data-srcset="https://blog.senx.io/wp-content/uploads/2020/09/DSC_6336-1024x682.jpg 1024w, https://blog.senx.io/wp-content/uploads/2020/09/DSC_6336-300x200.jpg 300w, https://blog.senx.io/wp-content/uploads/2020/09/DSC_6336-768x512.jpg 768w, https://blog.senx.io/wp-content/uploads/2020/09/DSC_6336-1536x1024.jpg 1536w, https://blog.senx.io/wp-content/uploads/2020/09/DSC_6336-600x400.jpg 600w, https://blog.senx.io/wp-content/uploads/2020/09/DSC_6336.jpg 2000w" data-sizes="(max-width: 1024px) 100vw, 1024px" srcset="https://blog.senx.io/wp-content/uploads/2020/09/DSC_6336-1024x682.jpg 1024w, https://blog.senx.io/wp-content/uploads/2020/09/DSC_6336-300x200.jpg 300w, https://blog.senx.io/wp-content/uploads/2020/09/DSC_6336-768x512.jpg 768w, https://blog.senx.io/wp-content/uploads/2020/09/DSC_6336-1536x1024.jpg 1536w, https://blog.senx.io/wp-content/uploads/2020/09/DSC_6336-600x400.jpg 600w, https://blog.senx.io/wp-content/uploads/2020/09/DSC_6336.jpg 2000w"><figcaption>The first prototype board...</figcaption></figure></li><li><figure><img loading="lazy" width="1024" height="682" src="https://blog.senx.io/wp-content/uploads/2020/09/DSC_6337-1024x682.jpg" data-src="https://blog.senx.io/wp-content/uploads/2020/09/DSC_6337-1024x682.jpg" alt="" data-id="11641" data-link="https://blog.senx.io/?attachment_id=11641" data-srcset="https://blog.senx.io/wp-content/uploads/2020/09/DSC_6337-1024x682.jpg 1024w, https://blog.senx.io/wp-content/uploads/2020/09/DSC_6337-300x200.jpg 300w, https://blog.senx.io/wp-content/uploads/2020/09/DSC_6337-768x512.jpg 768w, https://blog.senx.io/wp-content/uploads/2020/09/DSC_6337-1536x1024.jpg 1536w, https://blog.senx.io/wp-content/uploads/2020/09/DSC_6337-600x400.jpg 600w, https://blog.senx.io/wp-content/uploads/2020/09/DSC_6337.jpg 2000w" data-sizes="(max-width: 1024px) 100vw, 1024px" srcset="https://blog.senx.io/wp-content/uploads/2020/09/DSC_6337-1024x682.jpg 1024w, https://blog.senx.io/wp-content/uploads/2020/09/DSC_6337-300x200.jpg 300w, https://blog.senx.io/wp-content/uploads/2020/09/DSC_6337-768x512.jpg 768w, https://blog.senx.io/wp-content/uploads/2020/09/DSC_6337-1536x1024.jpg 1536w, https://blog.senx.io/wp-content/uploads/2020/09/DSC_6337-600x400.jpg 600w, https://blog.senx.io/wp-content/uploads/2020/09/DSC_6337.jpg 2000w"><figcaption>Stacking a Nucleo F411 with pressure sensor, keyboard, screen.</figcaption></figure></li><li><figure><img loading="lazy" width="1024" height="768" src="https://blog.senx.io/wp-content/uploads/2020/09/4C103809-C6CC-423D-B054-48B8C853F29E_1_105_c.jpeg" data-src="https://blog.senx.io/wp-content/uploads/2020/09/4C103809-C6CC-423D-B054-48B8C853F29E_1_105_c.jpeg" alt="" data-id="11748" data-full-url="https://blog.senx.io/wp-content/uploads/2020/09/4C103809-C6CC-423D-B054-48B8C853F29E_1_105_c.jpeg" data-link="https://blog.senx.io/?attachment_id=11748" data-srcset="https://blog.senx.io/wp-content/uploads/2020/09/4C103809-C6CC-423D-B054-48B8C853F29E_1_105_c.jpeg 1024w, https://blog.senx.io/wp-content/uploads/2020/09/4C103809-C6CC-423D-B054-48B8C853F29E_1_105_c-300x225.jpeg 300w, https://blog.senx.io/wp-content/uploads/2020/09/4C103809-C6CC-423D-B054-48B8C853F29E_1_105_c-768x576.jpeg 768w" data-sizes="(max-width: 1024px) 100vw, 1024px" srcset="https://blog.senx.io/wp-content/uploads/2020/09/4C103809-C6CC-423D-B054-48B8C853F29E_1_105_c.jpeg 1024w, https://blog.senx.io/wp-content/uploads/2020/09/4C103809-C6CC-423D-B054-48B8C853F29E_1_105_c-300x225.jpeg 300w, https://blog.senx.io/wp-content/uploads/2020/09/4C103809-C6CC-423D-B054-48B8C853F29E_1_105_c-768x576.jpeg 768w"><figcaption>First wood prototype</figcaption></figure></li></ul></figure>



<h2>Enters the Raspberry Pi</h2>



<p>What we learned from the first test on a pig:</p>



<ul><li>The ventilator did the job. The pig was alive and woke up correctly.</li><li><strong>There is a huge UX problem.</strong></li><li>The airflow measurement is really helpful.</li></ul>



<p>The experts from the medical world are now used to high-tech screens displaying curves with not only pressure, but real-time air volume blown into the patient lungs. Even in crisis time, we understand that our product does not meet their minimum UI/UX needs.</p>



<figure><img loading="lazy" width="1024" height="418" src="https://blog.senx.io/wp-content/uploads/2020/09/image-4-1024x418.jpg" data-src="https://blog.senx.io/wp-content/uploads/2020/09/image-4-1024x418.jpg" alt="difference of UX between first MakAir screen and a recent ventilator" data-srcset="https://blog.senx.io/wp-content/uploads/2020/09/image-4-1024x418.jpg 1024w, https://blog.senx.io/wp-content/uploads/2020/09/image-4-300x123.jpg 300w, https://blog.senx.io/wp-content/uploads/2020/09/image-4-768x314.jpg 768w, https://blog.senx.io/wp-content/uploads/2020/09/image-4-1536x627.jpg 1536w, https://blog.senx.io/wp-content/uploads/2020/09/image-4.jpg 1660w" data-sizes="(max-width: 1024px) 100vw, 1024px" srcset="https://blog.senx.io/wp-content/uploads/2020/09/image-4-1024x418.jpg 1024w, https://blog.senx.io/wp-content/uploads/2020/09/image-4-300x123.jpg 300w, https://blog.senx.io/wp-content/uploads/2020/09/image-4-768x314.jpg 768w, https://blog.senx.io/wp-content/uploads/2020/09/image-4-1536x627.jpg 1536w, https://blog.senx.io/wp-content/uploads/2020/09/image-4.jpg 1660w"><figcaption>Makair prototype on the left, a recent ventilator on the right. <br>Both can save life, but UX gap is huge!</figcaption></figure>



<p>Always listen to the users. Even if we succeed in mass production of an open-source ventilator, if doctors want curves and measures of the number of air liters entering the lungs, we must do it. </p>



<p>Since the beginning, this project is time driven. We never consider the price, but we always look at worldwide stocks. In a time where lots of plants are closed in Europe, <strong>the supply chain is leading the project.</strong></p>



<div><figure><img loading="lazy" src="https://blog.senx.io/wp-content/uploads/2020/09/DSC_6374-edited.jpg" data-src="https://blog.senx.io/wp-content/uploads/2020/09/DSC_6374-edited.jpg" alt="inside the v1 of the MakAir" width="522" height="347" data-srcset="https://blog.senx.io/wp-content/uploads/2020/09/DSC_6374-edited.jpg 1378w, https://blog.senx.io/wp-content/uploads/2020/09/DSC_6374-edited-300x200.jpg 300w, https://blog.senx.io/wp-content/uploads/2020/09/DSC_6374-edited-1024x683.jpg 1024w, https://blog.senx.io/wp-content/uploads/2020/09/DSC_6374-edited-768x512.jpg 768w, https://blog.senx.io/wp-content/uploads/2020/09/DSC_6374-edited-600x400.jpg 600w" data-sizes="(max-width: 522px) 100vw, 522px" srcset="https://blog.senx.io/wp-content/uploads/2020/09/DSC_6374-edited.jpg 1378w, https://blog.senx.io/wp-content/uploads/2020/09/DSC_6374-edited-300x200.jpg 300w, https://blog.senx.io/wp-content/uploads/2020/09/DSC_6374-edited-1024x683.jpg 1024w, https://blog.senx.io/wp-content/uploads/2020/09/DSC_6374-edited-768x512.jpg 768w, https://blog.senx.io/wp-content/uploads/2020/09/DSC_6374-edited-600x400.jpg 600w"><figcaption>Scooter lead-acid batteries. Because these are the most available batteries in the word.</figcaption></figure></div>



<p>So, what is the world's most available touch screen? </p>



<div><figure><img loading="lazy" src="https://blog.senx.io/wp-content/uploads/2020/09/image-2.png" data-src="https://blog.senx.io/wp-content/uploads/2020/09/image-2.png" alt="farnell stocks" width="616" height="217" data-srcset="https://blog.senx.io/wp-content/uploads/2020/09/image-2.png 832w, https://blog.senx.io/wp-content/uploads/2020/09/image-2-300x106.png 300w, https://blog.senx.io/wp-content/uploads/2020/09/image-2-768x270.png 768w" data-sizes="(max-width: 616px) 100vw, 616px" srcset="https://blog.senx.io/wp-content/uploads/2020/09/image-2.png 832w, https://blog.senx.io/wp-content/uploads/2020/09/image-2-300x106.png 300w, https://blog.senx.io/wp-content/uploads/2020/09/image-2-768x270.png 768w"><figcaption>(and 18000 more at radiospares)</figcaption></figure></div>



<p>As I just said, the supply chain rules the project. MakAir will have a raspberry to display curves. Nice coincidence for an open-source project!</p>



<p>By the way, the mass flow meter sensor was a huge problem. Since the beginning, MakAir did not want to disturb the production of existing ventilators. But this component is on the airway, it should be approved for medical use. In April, it was impossible to source any Sensirion or Honeywell mass flow sensors... Anyway, the next test will be done with a raspberry connected to the STM32. </p>







<h2>Enter Warp&nbsp;10</h2>



<p>On the 17th of April, the first batch of ventilators built in the CEA clean-rooms was ready. This batch was used for the 1st clinical tests. </p>



<p><strong>The pressure switches from the technical team to the regulatory team, remotely working on the project since the beginning. </strong></p>



<p>To prepare the next batch, we came back to Nantes. After 25 days, we switched from commando mode (18h/day, 7 days a week) to a more standard week (14h/day, the weekends with the family).</p>



<div><figure><img loading="lazy" src="https://blog.senx.io/wp-content/uploads/2020/09/IMG_5752-1024x768.jpg" data-src="https://blog.senx.io/wp-content/uploads/2020/09/IMG_5752-1024x768.jpg" alt="MakAir team in the CEA cleanroom with prototypes" width="521" height="390" data-srcset="https://blog.senx.io/wp-content/uploads/2020/09/IMG_5752-1024x768.jpg 1024w, https://blog.senx.io/wp-content/uploads/2020/09/IMG_5752-300x225.jpg 300w, https://blog.senx.io/wp-content/uploads/2020/09/IMG_5752-768x576.jpg 768w, https://blog.senx.io/wp-content/uploads/2020/09/IMG_5752-1536x1152.jpg 1536w, https://blog.senx.io/wp-content/uploads/2020/09/IMG_5752.jpg 2016w" data-sizes="(max-width: 521px) 100vw, 521px" srcset="https://blog.senx.io/wp-content/uploads/2020/09/IMG_5752-1024x768.jpg 1024w, https://blog.senx.io/wp-content/uploads/2020/09/IMG_5752-300x225.jpg 300w, https://blog.senx.io/wp-content/uploads/2020/09/IMG_5752-768x576.jpg 768w, https://blog.senx.io/wp-content/uploads/2020/09/IMG_5752-1536x1152.jpg 1536w, https://blog.senx.io/wp-content/uploads/2020/09/IMG_5752.jpg 2016w"><figcaption>Tyvek sterile clothing in a cleanroom. Could not be better for medical device assembly. Thanks to the CEA.</figcaption></figure></div>



<p>On the 30<sup>th</sup> of April, the prototype with a Raspberry Pi is ready for the next animal test. Two people had to fly to Grenoble CEA with this prototype, but the rest of us, and all the people remotely working on the project wanted to follow the experience. </p>



<p>So, the night before the test, I quickly deployed Warp&nbsp;10 on the raspberry and wrote a small script to copy data every 10s to another Warp&nbsp;10 server.</p>


<span><span><a href="https://twitter.com/intent/tweet?url=https%3A%2F%2Fblog.senx.io%2F%3Fp%3D11630&amp;text=MakAir%3A%20the%20birth%20of%20the%20first%20open-source%20data-enabled%20ventilator.%20From%20the%20first%20prototype%20to%20more%20modern%20UX%2C%20thanks%20to%20Raspberry%20Pi.&amp;via=SenXHQ&amp;related=SenXHQ" target="_blank" rel="noopener noreferrer">MakAir: the birth of the first open-source data-enabled ventilator. From the first prototype to more modern UX, thanks to Raspberry Pi. </a></span><a href="https://twitter.com/intent/tweet?url=https%3A%2F%2Fblog.senx.io%2F%3Fp%3D11630&amp;text=MakAir%3A%20the%20birth%20of%20the%20first%20open-source%20data-enabled%20ventilator.%20From%20the%20first%20prototype%20to%20more%20modern%20UX%2C%20thanks%20to%20Raspberry%20Pi.&amp;via=SenXHQ&amp;related=SenXHQ" target="_blank" rel="noopener noreferrer">Click To Tweet</a></span>


<p>What is <a href="https://www.warp10.io/" target="_blank" rel="noreferrer noopener">Warp&nbsp;10</a>? It is a time series platform. But unlike other TSDB (Time Series Database), there is a full analysis environment behind, and even a task scheduler. Compress time series, replicate to another server while managing network outage is really easy. Same tooling on the server and the connected object, that what I call easy IoT. To stream data, you just need a few WarpScript functions among <a href="https://www.warp10.io/doc/functionList" target="_blank" rel="noreferrer noopener">the thousand available</a>.</p>



<p>Basically, the WarpScript pseudo code is:</p>



<pre><code>- Read the last value of makair.lastupload GTS
- take the last tick as start
- take now as end
- fetch locally all the makair GTS from start to end
- WRAP all the GTS
- build a script that UNWRAP and UPDATE the data
- do a remote execution of the script with REXEC 
- if the REXEC was a success, store end in makair.lastupload</code></pre>



<p>You can follow the <a href="https://www.warp10.io/content/04_Tutorials/01_WarpScript/30_Server_to_Server" target="_blank" rel="noreferrer noopener">server to server tutorial</a> to implement such a WarpScript, then save it as $WARP10HOME/warpscripts/makair/10000/upload_data.mc2 to schedule an execution every 10s.</p>



<p>To display data in real-time, <a href="http://studio.senx.io/" target="_blank" rel="noreferrer noopener">WarpStudio</a> did the job easily too. Autorefresh of the DataViz every 10s is a built-in function:</p>



<div><figure><img loading="lazy" src="https://blog.senx.io/wp-content/uploads/2020/09/image-3.png" data-src="https://blog.senx.io/wp-content/uploads/2020/09/image-3.png" alt="autorefresh settings of the MakAir test" width="522" height="385" data-srcset="https://blog.senx.io/wp-content/uploads/2020/09/image-3.png 575w, https://blog.senx.io/wp-content/uploads/2020/09/image-3-300x221.png 300w" data-sizes="(max-width: 522px) 100vw, 522px" srcset="https://blog.senx.io/wp-content/uploads/2020/09/image-3.png 575w, https://blog.senx.io/wp-content/uploads/2020/09/image-3-300x221.png 300w"><figcaption>In the dataviz tab of WarpStudio.</figcaption></figure></div>







<p>Around 30 lines of code to allow all the MakAir team to follow the pressure inside the pig lungs in real-time!</p>



<div><figure><img loading="lazy" src="https://blog.senx.io/wp-content/uploads/2020/09/DSC_6580-70pc-1024x683.jpg" data-src="https://blog.senx.io/wp-content/uploads/2020/09/DSC_6580-70pc-1024x683.jpg" alt="real time display" width="516" height="343" data-srcset="https://blog.senx.io/wp-content/uploads/2020/09/DSC_6580-70pc-1024x683.jpg 1024w, https://blog.senx.io/wp-content/uploads/2020/09/DSC_6580-70pc-300x200.jpg 300w, https://blog.senx.io/wp-content/uploads/2020/09/DSC_6580-70pc-768x512.jpg 768w, https://blog.senx.io/wp-content/uploads/2020/09/DSC_6580-70pc-1536x1024.jpg 1536w, https://blog.senx.io/wp-content/uploads/2020/09/DSC_6580-70pc-2048x1365.jpg 2048w, https://blog.senx.io/wp-content/uploads/2020/09/DSC_6580-70pc-600x400.jpg 600w" data-sizes="(max-width: 516px) 100vw, 516px" srcset="https://blog.senx.io/wp-content/uploads/2020/09/DSC_6580-70pc-1024x683.jpg 1024w, https://blog.senx.io/wp-content/uploads/2020/09/DSC_6580-70pc-300x200.jpg 300w, https://blog.senx.io/wp-content/uploads/2020/09/DSC_6580-70pc-768x512.jpg 768w, https://blog.senx.io/wp-content/uploads/2020/09/DSC_6580-70pc-1536x1024.jpg 1536w, https://blog.senx.io/wp-content/uploads/2020/09/DSC_6580-70pc-2048x1365.jpg 2048w, https://blog.senx.io/wp-content/uploads/2020/09/DSC_6580-70pc-600x400.jpg 600w"><figcaption>WarpStudio on a 60" 4k display, that's a nice dashboard.</figcaption></figure></div>







<h2>Next steps</h2>



<p>MakAir ventilators are designed to store everything in the <a href="https://warp10.io/" target="_blank" rel="noreferrer noopener">Warp&nbsp;10</a> time series database. They also have built-in WiFi and LoRa. All these features are not yet available, because the priority is still to make an open-source approved ventilator. </p>



<figure><ul><li><figure><img loading="lazy" width="225" height="300" src="https://blog.senx.io/wp-content/uploads/2020/09/IMG_20200519_171307-scaled.jpg" data-src="https://blog.senx.io/wp-content/uploads/2020/09/IMG_20200519_171307-225x300.jpg" alt="" data-id="11728" data-full-url="https://blog.senx.io/wp-content/uploads/2020/09/IMG_20200519_171307-scaled.jpg" data-link="https://blog.senx.io/?attachment_id=11728" data-srcset="https://blog.senx.io/wp-content/uploads/2020/09/IMG_20200519_171307-225x300.jpg 225w, https://blog.senx.io/wp-content/uploads/2020/09/IMG_20200519_171307-768x1024.jpg 768w, https://blog.senx.io/wp-content/uploads/2020/09/IMG_20200519_171307-1152x1536.jpg 1152w, https://blog.senx.io/wp-content/uploads/2020/09/IMG_20200519_171307-1536x2048.jpg 1536w, https://blog.senx.io/wp-content/uploads/2020/09/IMG_20200519_171307-scaled.jpg 1920w" data-sizes="(max-width: 225px) 100vw, 225px" srcset="https://blog.senx.io/wp-content/uploads/2020/09/IMG_20200519_171307-225x300.jpg 225w, https://blog.senx.io/wp-content/uploads/2020/09/IMG_20200519_171307-768x1024.jpg 768w, https://blog.senx.io/wp-content/uploads/2020/09/IMG_20200519_171307-1152x1536.jpg 1152w, https://blog.senx.io/wp-content/uploads/2020/09/IMG_20200519_171307-1536x2048.jpg 1536w, https://blog.senx.io/wp-content/uploads/2020/09/IMG_20200519_171307-scaled.jpg 1920w"><figcaption>Revision 3 has a Raspberry screen on top of the small screen.</figcaption></figure></li><li><figure><img loading="lazy" width="225" height="300" src="https://blog.senx.io/wp-content/uploads/2020/09/IMG_20200519_171259-scaled.jpg" data-src="https://blog.senx.io/wp-content/uploads/2020/09/IMG_20200519_171259-225x300.jpg" alt="" data-id="11727" data-full-url="https://blog.senx.io/wp-content/uploads/2020/09/IMG_20200519_171259-scaled.jpg" data-link="https://blog.senx.io/?attachment_id=11727" data-srcset="https://blog.senx.io/wp-content/uploads/2020/09/IMG_20200519_171259-225x300.jpg 225w, https://blog.senx.io/wp-content/uploads/2020/09/IMG_20200519_171259-768x1024.jpg 768w, https://blog.senx.io/wp-content/uploads/2020/09/IMG_20200519_171259-1152x1536.jpg 1152w, https://blog.senx.io/wp-content/uploads/2020/09/IMG_20200519_171259-1536x2048.jpg 1536w, https://blog.senx.io/wp-content/uploads/2020/09/IMG_20200519_171259-scaled.jpg 1920w" data-sizes="(max-width: 225px) 100vw, 225px" srcset="https://blog.senx.io/wp-content/uploads/2020/09/IMG_20200519_171259-225x300.jpg 225w, https://blog.senx.io/wp-content/uploads/2020/09/IMG_20200519_171259-768x1024.jpg 768w, https://blog.senx.io/wp-content/uploads/2020/09/IMG_20200519_171259-1152x1536.jpg 1152w, https://blog.senx.io/wp-content/uploads/2020/09/IMG_20200519_171259-1536x2048.jpg 1536w, https://blog.senx.io/wp-content/uploads/2020/09/IMG_20200519_171259-scaled.jpg 1920w"><figcaption>The Raspberry Pi connected to the mainboard</figcaption></figure></li></ul></figure>



<p>Connected features + open-source software is an enabler for doctors and researchers to perform extensive data collection and try new algorithms in the machine. Warp&nbsp;10 is the best open source time series database to <a href="https://blog.senx.io/warp-10-for-iot-gdpr-compliant-before-gdpr-even-existed/" target="_blank" rel="noreferrer noopener">securely</a> store medical data and analyze it. It's not a walled garden.</p>



<p>If you need to connect medical devices to a time series database, <a href="mailto:contact@senx.io" target="_blank" rel="noreferrer noopener">just ask us</a>.</p>



<p>MakAir is now entering the second phase of clinical tests. We can consider we are halfway to the goal. Keep in mind that among all the projects of ventilators announced by big companies, MakAir is the only one to reach the clinical tests step. <a href="https://makair.life/" target="_blank" rel="noreferrer noopener">200 people, backed up by CEA and a few french companies</a> are about to make a commercially available open source ventilator... </p>



<p>That's crazy when you think about it!</p>



<p>Learn more about the MakAir project on <a href="http://makair.life/" target="_blank" rel="noreferrer noopener">makair.life</a>.</p>
<!-- relpost-thumb-wrapper --><!-- close relpost-thumb-wrapper -->      
           
    </article></div>]]>
            </description>
            <link>https://blog.senx.io/makair-covid-19-ventilator-with-a-raspberry-pi/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25670303</guid>
            <pubDate>Thu, 07 Jan 2021 12:34:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Reed-Solomon error recovery in RAID-6]]>
            </title>
            <description>
<![CDATA[
Score 100 | Comments 37 (<a href="https://news.ycombinator.com/item?id=25666830">thread link</a>) | @signa11
<br/>
January 6, 2021 | http://anadoxin.org/blog/error-recovery-in-raid6.html/ | <a href="https://web.archive.org/web/*/http://anadoxin.org/blog/error-recovery-in-raid6.html/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        

        

        <p>
            <h3>Reed-Solomon error recovery in RAID-6</h3>
        </p>

        <p>
            https://anadoxin.org/blog/error-recovery-in-raid6.html
        </p>

        
        
        
        

        
        
        
        

        
        <p>There are lots of resources on the Internet about RAID-6 error recovery and how you can create your own implementation of it, but most of those resources require spending a lot of time fighting with mathematical equations and figuring out the real algorithm.</p>
<p>In this post I'll try to give you a simple example how you can create your own error recovery solution based on what is used in RAID-6. More specifically, if you need to provide rendundancy across your mediums so that a failure of 1 or 2 mediums will be tolerated, look no further! ;)</p>
<p>If you'll read this post, as a bonus you'll gain knowledge about how RAID-5 error recovery works, because RAID-6 is an improved version of RAID-5 error recovery system.</p>

<p>Let's assume you have 3 disk drives with some data. Let's name those drives as <code>D1</code>, <code>D2</code> and <code>D3</code>. In order to use the same error recovery technique as RAID-6 uses, you'll need two additional disk drives, the <code>PD</code> drive, and the <code>RS</code> drive. I'll describe what <code>PD</code> and <code>RS</code> means in few moments. So, you'll need a total of 5 disk drives: <code>D1</code>, <code>D2</code>, <code>D3</code>, <code>PD</code> and <code>RS</code>.</p>
<p><img src="https://anadoxin.org/blog/error-recovery-in-raid6.html/image1.svg" alt=""></p>
<p>So, here's the situation:</p>
<ul>
<li><code>D1</code>, <code>D2</code> and <code>D3</code> contain <em>arbitrary user data</em>, and it doesn't matter what their contents are. FWIW you can assume those drives are full of cat pictures.</li>
<li>The special <code>PD</code> drive (named after <code>Parity Drive</code>, sometimes called <code>P</code> in whitepapers) contains the XOR data, generated automatically from <code>D1</code>, <code>D2</code> and <code>D3</code>.</li>
<li>The second special <code>RS</code> drive (named after <code>Reed-Solomon Drive</code>, sometimes also called <code>Q</code>) contains the Reed-Solomon codes, calculated from the same data as <code>PD</code>, namely from drives <code>D1</code>, <code>D2</code> and <code>D3</code>.</li>
</ul>
<p>Let's see how we can perform some basic operations on such disk array.</p>

<p>If we have properly calculated <code>PD</code> and <code>RS</code> drives, we can lose up to 2 drives. How we recover from failures depends on which drives will fail. There are generally 7 cases that RAID-6 can handle. Next points will describe the scenarios, sorted from the easiest case, to the most complicated.</p>
<ol>
<li>
<p>Loss of the <code>PD</code> drive (failure of only one drive).</p>
<p><img src="https://anadoxin.org/blog/error-recovery-in-raid6.html/image-losspd.svg" alt=""></p>
<p>This case is very straightforward. The <code>PD</code> drive contains only autogenerated data, so in case we lose the <code>PD</code> drive, we can regenerate it by using only user data (stored on disks <code>D1</code>, <code>D2</code> and <code>D3</code>).</p>
</li>
<li>
<p>Loss of one of the data drives: either <code>D1</code>, <code>D2</code> or <code>D3</code> (failure of only one drive).</p>
<p><img src="https://anadoxin.org/blog/error-recovery-in-raid6.html/image-datadrive.svg" alt=""></p>
<p>In this case we're losing data, but since we only lose 1 disk, the recovery scenario is the same as in RAID-5 error recovery: we'll use <code>PD</code> drive <em>together with two non-missing data drives</em> to recover data from the missing data drive. It doesn't matter which data drive we lose, because if we have 2 data drives and the <code>PD</code> drive, we can always generate data for the third drive. The <code>RS</code> drive is not needed to regenerate the data drive in this case (and is not used at all in this failure case).</p>
</li>
<li>
<p>Loss of the <code>RS</code> drive (failure of only one drive).</p>
<p><img src="https://anadoxin.org/blog/error-recovery-in-raid6.html/image-lossrs.svg" alt=""></p>
<p>Similar to the situation from point 1: we have all the data drives, and we can simply regenerate the <code>RS</code> drive by calculating Reed-Solomon codes from drives that did not fail.</p>
</li>
<li>
<p>Loss of the <code>PD</code> drive and the <code>RS</code> drive (failure of two drives).</p>
<p><img src="https://anadoxin.org/blog/error-recovery-in-raid6.html/image-losspdrs.svg" alt=""></p>
<p>This case is very similar to points 1 or 3, we have all the data intact, so we can generate contents of <code>PD</code> drive and then <code>RS</code> drive very easily.</p>
</li>
<li>
<p>Loss of the <code>RS</code> drive and one data drive (failure of two drives).</p>
<p><img src="https://anadoxin.org/blog/error-recovery-in-raid6.html/image-lossdatars.svg" alt=""></p>
<p>In this case we're losing two disks, but only one lost disk is filled with data. Since we have <code>PD</code> drive intact, we can use it to regenerate data from missing data drive, so this case is not so different than case #2. After that, we will have all the data drives, so we can regenerate the <code>RS</code> drive easily.</p>
</li>
<li>
<p>Loss of the <code>PD</code> drive and one data drive (failure of two drives).</p>
<p><img src="https://anadoxin.org/blog/error-recovery-in-raid6.html/image-lossdatapd.svg" alt=""></p>
<p>This case is more complicated. We lose one user data drive (in this example <code>D3</code>), and we don't have the <code>PD</code> drive to aid with recovery, because we've lost it as well. We have to use the <code>RS</code> drive in conjunction with all user data drives that are still available (<code>D1</code> and <code>D2</code>) to regenerate the missing data drive <code>D3</code>. After we'll have all data drives regenerated, we can calculate the missing <code>PD</code> drive. This is the first case where recovery using Reed-Solomon codes comes into play.</p>
</li>
<li>
<p>Loss of two data drives (failure of two drives).</p>
<p><img src="https://anadoxin.org/blog/error-recovery-in-raid6.html/image-lossdatadata.svg" alt=""></p>
<p>This is the most complicated scenario. We need to use both <code>PD</code> and <code>RS</code> to regenerate both data drives. Reed-Solomon coding makes this case possible.</p>
</li>
</ol>
<p>In the following sections, I'll try to describe those cases above with more detail, and provide some source code (in Python :P) that will perform actual recovery of data.</p>
<p>Please keep in mind that real RAID-6 arrays don't really dedicate whole disk for <code>PD</code> or <code>RS</code>. Real arrays span this additional checksum data across all disks. There are multiple methods used by various controllers: left asynchronous, right synchronous, there can be an offset to the RAID data, there can be pattern delays, etc. Why it's done this way, and how exactly RAID-6 stripes looks like is beyond the scope of this blog post. So let's stick only to Reed-Solomon codes.</p>
<h2 id="test-data">Test data</h2>
<p>Let's define how our "user data" looks like. To keep things simple, let's pretend that our "disk drives" are 5 bytes big.</p>
<table><thead><tr><th>Disk</th><th>Data in ASCII</th><th>Data in HEX</th></tr></thead><tbody>
<tr><td><code>D1</code></td><td>f i r s t</td><td>0x66, 0x69, 0x72, 0x73, 0x74</td></tr>
<tr><td><code>D2</code></td><td>s e c n d</td><td>0x73, 0x65, 0x63, 0x6e, 0x64</td></tr>
<tr><td><code>D3</code></td><td>t h i r d</td><td>0x74, 0x68, 0x69, 0x72, 0x64</td></tr>
</tbody></table>
<p>Let's go into the scenarios mentioned above in more details.</p>

<p>In order to generate the <code>PD</code> data, we need only the user data drives. In our case it's <code>D1</code>, <code>D2</code> and <code>D3</code>. The <code>PD</code> drive consists of nothing more than <a href="https://en.wikipedia.org/wiki/Bitwise_operation#XOR">XOR</a> of all user data.</p>
<ul>
<li>To generate offset 0 of the <code>PD</code> drive, you need to XOR all bytes from offset 0 from all disk drives.</li>
<li>Then, to generate offset 1 of the <code>PD</code> drive, you need to XOR bytes from offset 1 from all disk drives. E.g.:</li>
</ul>
<pre><code><span>PD[0] = D1[0] xor D2[0] xor D3[0]
PD[1] = D1[1] xor D2[1] xor D3[1]
PD[2] = D1[2] xor D2[2] xor D3[2]
PD[3] = D1[3] xor D2[3] xor D3[3]
PD[4] = D1[4] xor D2[4] xor D3[4]
</span></code></pre>
<p>Example:</p>
<pre><code><span>PD[0] = 0x66 xor 0x73 xor 0x74  =&gt;  0x61
PD[1] = 0x69 xor 0x65 xor 0x63  =&gt;  0x64
PD[2] = 0x72 xor 0x63 xor 0x69  =&gt;  0x78
PD[3] = 0x73 xor 0x6e xor 0x72  =&gt;  0x6f
PD[4] = 0x74 xor 0x64 xor 0x64  =&gt;  0x74
</span></code></pre>
<p>Yes, it's that simple. Do it for the whole drives (in our case, 5 bytes), and you'll have the properly generated <code>PD</code> drive:</p>
<table><thead><tr><th>Disk</th><th>Data in HEX</th></tr></thead><tbody>
<tr><td><code>PD</code></td><td>0x61, 0x64, 0x78, 0x6f, 0x74</td></tr>
</tbody></table>
<p>So, in case when only your <code>PD</code> drive will fail, you can see it's trivial to regenerate it from the data drives <code>D1</code>, <code>D2</code> and <code>D3</code>.</p>

<p>By the way, this is how RAID-5 error recovery works. If only one drive with user data will fail, we can use the <code>PD</code> drive to recalculate missing user data.</p>
<p>Let's say we're losing <code>D2</code>, so the drives that are still working are: <code>D1</code>, <code>D3</code>, <code>PD</code> and <code>RS</code>. In this case, we don't even look at <code>RS</code>. All we need are the <code>D1</code>, <code>D3</code> and <code>PD</code> drives. To calculate missing data, you can use the XOR function again, like in the previous point.</p>
<p>To recover user data from offset 0, XOR the bytes from offsets 0 of disks with user data you haven't lost (<code>D1</code> and <code>D3</code>) together with the byte from offset 0 from the <code>PD</code> drive. Do the same thing for offset 1, like this:</p>
<pre><code><span>D2[0] = D1[0] xor D3[0] xor PD[0]
D2[1] = D1[1] xor D3[1] xor PD[1]
D2[2] = D1[2] xor D3[2] xor PD[2]
D2[3] = D1[3] xor D3[3] xor PD[3]
D2[4] = D1[4] xor D3[4] xor PD[4]
</span></code></pre>
<p>Example:</p>
<pre><code><span>D2[0] = 0x66 xor 0x74 xor 0x61  =&gt;  0x73 (s)
D2[1] = 0x69 xor 0x63 xor 0x64  =&gt;  0x65 (e)
D2[2] = 0x72 xor 0x69 xor 0x78  =&gt;  0x63 (c)
D2[3] = 0x73 xor 0x72 xor 0x6f  =&gt;  0x6e (n)
D2[4] = 0x74 xor 0x64 xor 0x74  =&gt;  0x64 (d)
</span></code></pre>
<p>As you can see, we can easily recover data from the missing drive. It doesn't matter which drive is missing; the <a href="https://en.wikipedia.org/wiki/Bitwise_operation#XOR">XOR function</a> will work anyway.</p>

<p>Now we enter the realm of the Reed-Solomon codes and Galois fields. But don't worry, you don't have to be a mathematician in order to <em>use</em> it.</p>
<p>When we lose only <code>RS</code> drive, or when we initialize a new RAID-6-like redundation system, we simply need to regenerate it. In order to do that, we need to use the <code>gflog</code> and <code>gfilog</code> tables, which are always constant, plus data from our existing data drives <code>D1</code>, <code>D2</code> and <code>D3</code>.</p>
<p>This is the <code>gflog</code> table, it always stays the same:</p>
<pre><code><span>    0x00, 0x00, 0x01, 0x19, 0x02, 0x32, 0x1a, 0xc6, 0x03, 0xdf, 0x33, 0xee, 0x1b, 0x68, 0xc7, 0x4b,
    0x04, 0x64, 0xe0, 0x0e, 0x34, 0x8d, 0xef, 0x81, 0x1c, 0xc1, 0x69, 0xf8, 0xc8, 0x08, 0x4c, 0x71,
    0x05, 0x8a, 0x65, 0x2f, 0xe1, 0x24, 0x0f, 0x21, 0x35, 0x93, 0x8e, 0xda, 0xf0, 0x12, 0x82, 0x45,
    0x1d, 0xb5, 0xc2, 0x7d, 0x6a, 0x27, 0xf9, 0xb9, 0xc9, 0x9a, 0x09, 0x78, 0x4d, 0xe4, 0x72, 0xa6,
    0x06, 0xbf, 0x8b, 0x62, 0x66, 0xdd, 0x30, 0xfd, 0xe2, 0x98, 0x25, 0xb3, 0x10, 0x91, 0x22, 0x88,
    0x36, 0xd0, 0x94, 0xce, 0x8f, 0x96, 0xdb, 0xbd, 0xf1, 0xd2, 0x13, 0x5c, 0x83, 0x38, 0x46, 0x40,
    0x1e, 0x42, 0xb6, 0xa3, 0xc3, 0x48, 0x7e, 0x6e, 0x6b, 0x3a, 0x28, 0x54, 0xfa, 0x85, 0xba, 0x3d,
    0xca, 0x5e, 0x9b, 0x9f, 0x0a, 0x15, 0x79, 0x2b, 0x4e, 0xd4, 0xe5, 0xac, 0x73, 0xf3, 0xa7, 0x57,
    0x07, 0x70, 0xc0, 0xf7, 0x8c, 0x80, 0x63, 0x0d, 0x67, 0x4a, 0xde, 0xed, 0x31, 0xc5, 0xfe, 0x18,
    0xe3, 0xa5, 0x99, 0x77, 0x26, 0xb8, 0xb4, 0x7c, 0x11, 0x44, 0x92, 0xd9, 0x23, 0x20, 0x89, 0x2e,
    0x37, 0x3f, 0xd1, 0x5b, 0x95, 0xbc, 0xcf, 0xcd, 0x90, 0x87, 0x97, 0xb2, 0xdc, 0xfc, 0xbe, 0x61,
    0xf2, 0x56, 0xd3, 0xab, 0x14, 0x2a, 0x5d, 0x9e, 0x84, 0x3c, 0x39, 0x53, 0x47, 0x6d, 0x41, 0xa2,
    0x1f, 0x2d, 0x43, 0xd8, 0xb7, 0x7b, 0xa4, 0x76, 0xc4, 0x17, 0x49, 0xec, 0x7f, 0x0c, 0x6f, 0xf6,
    0x6c, 0xa1, 0x3b, 0x52, 0x29, 0x9d, 0x55, 0xaa, 0xfb, 0x60, 0x86, 0xb1, 0xbb, 0xcc, 0x3e, 0x5a,
    0xcb, 0x59, 0x5f, 0xb0, 0x9c, 0xa9, 0xa0, 0x51, 0x0b, 0xf5, 0x16, 0xeb, 0x7a, 0x75, 0x2c, 0xd7,
    0x4f, 0xae, 0xd5, 0xe9, 0xe6, 0xe7, 0xad, 0xe8, 0x74, 0xd6, 0xf4, 0xea, 0xa8, 0x50, 0x58, 0xaf.
</span></code></pre>
<p>This is the <code>gfilog</code> table, it's also constant:</p>
<pre><code><span>    0x01, 0x02, 0x04, 0x08, 0x10, 0x20, 0x40, 0x80, 0x1d, 0x3a, 0x74, 0xe8, …</span></code></pre></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://anadoxin.org/blog/error-recovery-in-raid6.html/">http://anadoxin.org/blog/error-recovery-in-raid6.html/</a></em></p>]]>
            </description>
            <link>http://anadoxin.org/blog/error-recovery-in-raid6.html/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25666830</guid>
            <pubDate>Thu, 07 Jan 2021 03:13:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Shooting photos with an IMAX projector lens]]>
            </title>
            <description>
<![CDATA[
Score 168 | Comments 63 (<a href="https://news.ycombinator.com/item?id=25666217">thread link</a>) | @dmitrygr
<br/>
January 6, 2021 | https://theslantedlens.com/2021/crazy-huge-imax-lens-amazing-street-portraits/ | <a href="https://web.archive.org/web/*/https://theslantedlens.com/2021/crazy-huge-imax-lens-amazing-street-portraits/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><div><p>What the heck is that huge lens? That Crazy Huge Lens is an IMAX Lens. You will be surprised at the cool street portraits we got with this thing. Take a look at how Jay P rigged this with his <a href="https://bhpho.to/38bRbgL">Canon EOS R</a> camera and the amazing results.</p>
<p><iframe width="750" height="450" src="https://www.youtube.com/embed/D-ihZrP4C0A" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="allowfullscreen"></iframe></p>
<p>This is Jay P Morgan. Today on The Slanted Lens we are in Santa Monica at a skate park. <img loading="lazy" src="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_8.png" alt="" width="1092" height="611" srcset="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_8.png 1092w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_8-300x168.png 300w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_8-768x430.png 768w" sizes="(max-width: 1092px) 100vw, 1092px">This is a great skate park. I’ve been here before with my daughter who comes down to skate. <img loading="lazy" src="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_35.png" alt="" width="1070" height="600" srcset="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_35.png 1070w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_35-300x168.png 300w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_35-768x431.png 768w" sizes="(max-width: 1070px) 100vw, 1070px">This time I came with this huge IMAX lens. <img loading="lazy" src="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_1.png" alt="" width="1072" height="598" srcset="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_1.png 1072w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_1-300x167.png 300w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_1-768x428.png 768w" sizes="(max-width: 1072px) 100vw, 1072px">This thing is a beast. It’s an IMAX lens and it was made by Iwerks. I’ve had it in a huge hard case in my storage for a long, long time. I’ve always wanted to adapt this to a camera and take portraits with it. <img loading="lazy" src="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_2.png" alt="" width="1071" height="601" srcset="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_2.png 1071w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_2-300x168.png 300w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_2-768x431.png 768w" sizes="(max-width: 1071px) 100vw, 1071px">So I want to do street portraits with an IMAX Lens using my Canon EOS R Camera. So here’s the process I went through to get this lens adapted, so I’ll be able to focus it and work with it.</p>
<p><img loading="lazy" src="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_9.png" alt="" width="1090" height="611" srcset="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_9.png 1090w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_9-300x168.png 300w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_9-768x431.png 768w" sizes="(max-width: 1090px) 100vw, 1090px"> <img loading="lazy" src="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_10.png" alt="" width="1093" height="612" srcset="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_10.png 1093w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_10-300x168.png 300w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_10-768x430.png 768w" sizes="(max-width: 1093px) 100vw, 1093px"> <img loading="lazy" src="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_11.png" alt="" width="1092" height="612" srcset="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_11.png 1092w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_11-300x168.png 300w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_11-768x430.png 768w" sizes="(max-width: 1092px) 100vw, 1092px"> <img loading="lazy" src="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_12.png" alt="" width="1091" height="612" srcset="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_12.png 1091w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_12-300x168.png 300w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_12-768x431.png 768w" sizes="(max-width: 1091px) 100vw, 1091px"> <img loading="lazy" src="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_14.png" alt="" width="1091" height="611" srcset="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_14.png 1091w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_14-300x168.png 300w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_14-768x430.png 768w" sizes="(max-width: 1091px) 100vw, 1091px"> <img loading="lazy" src="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_15.png" alt="" width="1086" height="610" srcset="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_15.png 1086w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_15-300x169.png 300w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_15-768x431.png 768w" sizes="(max-width: 1086px) 100vw, 1086px"> <img loading="lazy" src="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_16.png" alt="" width="1094" height="610" srcset="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_16.png 1094w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_16-300x167.png 300w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_16-768x428.png 768w" sizes="(max-width: 1094px) 100vw, 1094px"> <img loading="lazy" src="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_17.png" alt="" width="1091" height="610" srcset="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_17.png 1091w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_17-300x168.png 300w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_17-768x429.png 768w" sizes="(max-width: 1091px) 100vw, 1091px"> <img loading="lazy" src="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_18.png" alt="" width="1088" height="610" srcset="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_18.png 1088w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_18-300x168.png 300w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_18-768x431.png 768w" sizes="(max-width: 1088px) 100vw, 1088px">Let’s take some pictures. The way I focus this thing is so silly. <img loading="lazy" src="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_20.png" alt="" width="1092" height="611" srcset="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_20.png 1092w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_20-300x168.png 300w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_20-768x430.png 768w" sizes="(max-width: 1092px) 100vw, 1092px">I have a track that I can release here and I can move my camera back and forth inside this tape I put around the lens. Then I find the point where it focuses. It’s pretty gorilla. Very, very gorilla, but it works.<img loading="lazy" src="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_25.png" alt="" width="1072" height="599" srcset="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_25.png 1072w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_25-300x168.png 300w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_25-768x429.png 768w" sizes="(max-width: 1072px) 100vw, 1072px"></p>
<p>So in this situation I don’t have a lens on the front of the camera. So if the camera is going to fire without a lens on it, you have to go to the menus and you’ve have to turn on the setting which will allow the camera to fire when there’s no lens attached. There’s no coupling here. <img loading="lazy" src="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_26.png" alt="" width="1071" height="600" srcset="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_26.png 1071w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_26-300x168.png 300w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_26-768x430.png 768w" sizes="(max-width: 1071px) 100vw, 1071px">This is just a space between the lens and the front of the camera. I did have to turn that feature on that will allow me to shoot without a lens in order to make this work.</p>
<p><img loading="lazy" src="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_28.png" alt="" width="1070" height="599" srcset="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_28.png 1070w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_28-300x168.png 300w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_28-768x430.png 768w" sizes="(max-width: 1070px) 100vw, 1070px"> <img loading="lazy" src="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_29.png" alt="" width="1070" height="597" srcset="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_29.png 1070w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_29-300x167.png 300w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_29-768x429.png 768w" sizes="(max-width: 1070px) 100vw, 1070px">This lens is so interesting because it has a 180 degree angle of view. So I can get right here close and to the side and I’m in the shot. And I am in the shot when I move all the way around to the other side.</p>
<p><img loading="lazy" src="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_30.png" alt="" width="1071" height="599" srcset="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_30.png 1071w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_30-300x168.png 300w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_30-768x430.png 768w" sizes="(max-width: 1071px) 100vw, 1071px">This lens has a really strange quality because my face is in focus, but the area around it is out of focus. It almost has a tilt shift kind of quality like it’s you’re focusing on one point. <img loading="lazy" src="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_31.png" alt="" width="1072" height="599" srcset="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_31.png 1072w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_31-300x168.png 300w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_31-768x429.png 768w" sizes="(max-width: 1072px) 100vw, 1072px">When you get somebody up front like this, it gives you a blur all the way around. It’s very cool looking.</p>
<p><img loading="lazy" src="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_37.png" alt="" width="1070" height="600" srcset="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_37.png 1070w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_37-300x168.png 300w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_37-768x431.png 768w" sizes="(max-width: 1070px) 100vw, 1070px"> <img loading="lazy" src="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_38.png" alt="" width="1071" height="600" srcset="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_38.png 1071w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_38-300x168.png 300w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_38-768x430.png 768w" sizes="(max-width: 1071px) 100vw, 1071px"></p>
<p>I’m learning as we go along here, it doesn’t have a flat plane of focus, but I think that’s because of the way I mounted the camera back there. It’s a little bit like a tilt shift. So I didn’t get them quite square, which is kind of cool because I get the face in focus, but the hands or the body go out of focus in the foreground. It’s just kind of cool looking.</p>
<p><img loading="lazy" src="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_39.png" alt="" width="1067" height="596" srcset="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_39.png 1067w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_39-300x168.png 300w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_39-768x429.png 768w" sizes="(max-width: 1067px) 100vw, 1067px"></p>
<p>One of the reasons I love to carry a light in my bag is anytime I’m doing a street portrait or something, a continuous light is so easy to flip up really fast. It gives us a little bit of light on the face and opens up the shadows. The <a href="https://bhpho.to/32nCIvK">LitraStudio</a> is perfect for that because it’s easy. <img loading="lazy" src="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_40.png" alt="" width="1074" height="601" srcset="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_40.png 1074w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_40-300x168.png 300w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_40-768x430.png 768w" sizes="(max-width: 1074px) 100vw, 1074px">Turn it on and it’s so powerful, it’s worth the weight. It’s not like one of the little tiny ones Litra makes. I like the bigger heavier light because it just gives me so much more power. Especially in a situation like this where you have the sun to deal with.</p>
<p><img loading="lazy" src="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_42.png" alt="" width="1072" height="601" srcset="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_42.png 1072w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_42-300x168.png 300w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_42-768x431.png 768w" sizes="(max-width: 1072px) 100vw, 1072px"></p>
<p>So there you have it. I’m going to do more of this. <img loading="lazy" src="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_44.png" alt="" width="1072" height="602" srcset="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_44.png 1072w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_44-300x168.png 300w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_44-768x431.png 768w" sizes="(max-width: 1072px) 100vw, 1072px">I want to adapt some other lenses to my EOS R and just try to get weird views and that kind of gritty look. This actually was way cleaner than I thought it was going to be. <img loading="lazy" src="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_46.png" alt="" width="1071" height="600" srcset="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_46.png 1071w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_46-300x168.png 300w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_46-768x430.png 768w" sizes="(max-width: 1071px) 100vw, 1071px">I don’t even have something blocking the light between the camera and the lens. I used just a little bit of tape in here. But it projects a great image on the sensor. It’s a little hard to focus but a lot of fun to shoot. <img loading="lazy" src="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_48.png" alt="" width="1071" height="600" srcset="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_48.png 1071w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_48-300x168.png 300w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_48-768x430.png 768w" sizes="(max-width: 1071px) 100vw, 1071px">So I hope you enjoyed this. Make sure you subscribe to the channel and ring that bell. Keep those cameras rollin’ and keep on clickin’.</p>
<p>Check out <a href="https://bhpho.to/32nCIvK">LitraStudio lights</a>:</p>
<p><img loading="lazy" src="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_50.png" alt="" width="1073" height="599" srcset="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_50.png 1073w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_50-300x167.png 300w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_50-768x429.png 768w" sizes="(max-width: 1073px) 100vw, 1073px"> <img loading="lazy" src="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_51.png" alt="" width="1070" height="600" srcset="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_51.png 1070w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_51-300x168.png 300w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_51-768x431.png 768w" sizes="(max-width: 1070px) 100vw, 1070px"> <img loading="lazy" src="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_52.png" alt="" width="1072" height="597" srcset="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_52.png 1072w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_52-300x167.png 300w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_52-768x428.png 768w" sizes="(max-width: 1072px) 100vw, 1072px"> <img loading="lazy" src="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_53.png" alt="" width="1071" height="598" srcset="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_53.png 1071w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_53-300x168.png 300w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_53-768x429.png 768w" sizes="(max-width: 1071px) 100vw, 1071px"></p>
<!-- AddThis Advanced Settings above via filter on the_content --><!-- AddThis Advanced Settings below via filter on the_content --><!-- AddThis Advanced Settings generic via filter on the_content --><!-- AddThis Share Buttons above via filter on the_content --><!-- AddThis Share Buttons below via filter on the_content --><!-- AddThis Share Buttons generic via filter on the_content --><!-- AddThis Related Posts below via filter on the_content --><!-- AddThis Related Posts generic via filter on the_content --><!--<rdf:RDF xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
			xmlns:dc="http://purl.org/dc/elements/1.1/"
			xmlns:trackback="http://madskills.com/public/xml/rss/module/trackback/">
		<rdf:Description rdf:about="https://theslantedlens.com/2021/crazy-huge-imax-lens-amazing-street-portraits/"
    dc:identifier="https://theslantedlens.com/2021/crazy-huge-imax-lens-amazing-street-portraits/"
    dc:title="Crazy Huge Imax Lens &#8211; Amazing Street Portraits"
    trackback:ping="https://theslantedlens.com/2021/crazy-huge-imax-lens-amazing-street-portraits/trackback/" />
</rdf:RDF>-->
</div></article></div>]]>
            </description>
            <link>https://theslantedlens.com/2021/crazy-huge-imax-lens-amazing-street-portraits/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25666217</guid>
            <pubDate>Thu, 07 Jan 2021 01:50:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A developer's perspective: the problem with screen reader testing]]>
            </title>
            <description>
<![CDATA[
Score 69 | Comments 52 (<a href="https://news.ycombinator.com/item?id=25665851">thread link</a>) | @jacobtracey
<br/>
January 6, 2021 | https://jaketracey.com/a-developers-perspective-the-problem-with-screen-reader-testing/ | <a href="https://web.archive.org/web/*/https://jaketracey.com/a-developers-perspective-the-problem-with-screen-reader-testing/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article itemscope="" itemtype="http://schema.org/Article"><header><p>January 06, 2021</p></header><section itemprop="articleBody"><p>Screen readers are an essential part of using the web for people who are vision impaired, illiterate or have a learning disability.</p>
<p>Today’s screen readers traverse web pages and applications and read out user interface elements, content and allow users to navigate and interact with the web.</p>
<p>There are many screen readers available for different devices and platforms, each with differing levels of functionality, interfaces and features. The most common are JAWS, NVDA, VoiceOver and TalkBack.</p>
<p>According to the latest <a href="https://webaim.org/projects/screenreadersurvey8/">WebAIM Screen Reader User Survey</a>, when it comes to desktop screen reader usage, JAWS and NVDA are practically equal in usage, with around 40% of respondents reporting that they use one or the other.</p>
<figure>
<img src="https://jaketracey.com/webaim-graph.png" alt="Line chart of primary screen reader usage since October 2009. JAWS has steady decline from 68% to 40%. NVDA has steady incline from 3% to 41%. VoiceOver has a slow incline from 10% to 13%.">
<figcaption>Source: WebAIM</figcaption>
</figure>
<p>Based on the graph above, there’s a clear pattern over the course of the last 10 years, with NVDA usage increasing as JAWS usage drops, culminating in an inflection point in 2019 when NVDA surpassed JAWS usage for the first time.</p>
<p>As a developer regularly faced with time constraints, I have often wondered: what should be the baseline in terms of testing for screen readers, and what browser and screen reader combinations are the most important to cover in order to achieve the greatest level of WCAG compliance?</p>
<h2>An issue of time</h2>
<p>Given that almost all web applications developed in 2021 are also used on mobile and therefore require testing on both iOS and Android devices, as well as Windows and macOS for desktop users, providing adequate support for such a broad range of scenarios becomes quite difficult to manage.</p>
<p>Let’s say in a best-case scenario, a given page or feature will be tested on the following combinations:</p>
<ul>
<li>iOS / VoiceOver</li>
<li>Android / TalkBack</li>
<li>macOS / Chrome / VoiceOver</li>
<li>macOS / Safari / VoiceOver</li>
<li>macOS / Firefox / VoiceOver</li>
<li>Windows / Microsoft Edge / NVDA</li>
<li>Windows / Chrome / NVDA</li>
<li>Windows / Firefox / NVDA</li>
<li>Windows / Microsoft Edge / JAWS</li>
<li>Windows / Chrome / JAWS</li>
<li>Windows / Firefox / JAWS</li>
</ul>
<p>I should clarify that by “best-case”, I am conveniently leaving out any versions of Internet Explorer, but as frustrating as it may be, including it would add at least another 2 rounds of testing.</p>
<p>It’s also worth noting that WebAIM also recommends using Microsoft Edge with Narrator, but given its low usage, we’ll leave it out (more on this later).</p>
<p>Hypothetically, depending on the size of the functionality or page implemented, let’s say each round of testing takes one hour to complete, assuming the developer has experience with each of these browsers and screen readers.</p>
<p>In this scenario, comprehensively testing screen reader support across all these combinations adds 11 hours of development work – and that’s just to test!</p>
<h2>An issue of fragmentation</h2>
<p>Web developers will be familiar with the issues surrounding browser version fragmentation, and this problem is compounded when testing with screen readers. Contending with not only varying levels of HTML, Javascript and CSS support in the browser can be tough, and to combat this, polyfills and tools like <a href="https://caniuse.com/">caniuse.com</a> have made life a lot easier.</p>
<p>When it comes to screen reader version fragmentation, there is very little in the way of either documentation or support for developers. Fixing issues often comes down to a case of trial and error, retesting and hoping for the best.</p>
<p>A piece of information that would be incredibly useful in this area would be <em>penetration of screen reader updates</em> from the vendors. If, for instance, developers knew that there was a high adoption rate of updates among screen reader users, they could be confident that if a screen reader update resolved an issue, patches for older versions could be sunsetted. This approach has worked exceptionally well for browsers such as Chrome and Firefox.</p>
<p>Sadly, there’s not currently any way for a developer to identify the type or version of a screen reader that is being used, so implementing targeted fixes isn’t an option anyway right now.</p>
<h2>A case for dedicated accessibility testers</h2>
<p>Given the scope and time it takes to properly test across so many devices, browsers and screen readers, having dedicated accessibility testers embedded into teams can significantly increase the quality and speed with which properly accessible applications can be produced.</p>
<p>Let’s face it: developers already have a hard time keeping up with the pace of change in their own domain, let alone the level of knowledge required for comprehensive accessibility auditing.</p>
<p>That is not to say that developers should ignore accessibility completely. However, expecting someone to know about a specific bug on a particular combination of code, browser and screen reader is too much, even for the most experienced accessibility-focused developer.</p>
<h2>Why automation isn’t enough</h2>
<p>The old saying "a good programmer is a lazy programmer" comes to mind when I think about testing here. Being lazy myself (although possibly not that great of a programmer), I rely on automated tools like <a href="https://www.deque.com/axe/">axe</a> to do most of my accessibility for me. While the current range of tooling is excellent, and picks up the most obvious issues, when it comes to screen readers there’s no way around it: you need to manually test.</p>
<p>Why? Well, the current state of both browsers and screen reader support is all over the place. To highlight this, the Powermapper website has a neat <a href="https://www.powermapper.com/tests/screen-readers/aria/">list of screen reader support for WAI-ARIA attributes</a>. Not throwing shade at any one – things are continuously improving with updates to browsers and screen readers – but the point stands. Current automated testing tools are not going to catch these problems because they essentially test the validity of code, in much the same way as a code linter does.</p>
<h2>A compromise, so we can all still get stuff done</h2>
<p>Not every team has the luxury of a dedicated accessibility tester, or even a dedicated tester for that matter. Sometimes, you just need to do the best you can, with the resources that you have available.</p>
<p>"When can we stop supporting this?" has been the desperate cry of developers for years when it comes to Internet Explorer 9/10 and most recently 11, and as their usage has dropped, so has the rate of developers losing their hair trying to get their code working.</p>
<p>Which brings me back to Microsoft Edge with Narrator, as mentioned earlier. With 1% of users in that survey, and possibly 0% of users for your application or site, is it worth testing on this combination at all? More specifically, what number of users justifies support, and the testing and development overhead that comes with it?</p>
<h3>Windows - Chrome (latest version), NVDA</h3>
<p>As of December 2020, Chrome is by far the most popular browser in the world, with 65.3% of users. Later versions of Microsoft Edge utilize the same rendering engine, so there is a high likelihood that if it works in Chrome, it will work similarly in Edge.</p>
<p>Based on the WebAIM stats, it is a safe bet that NVDA will begin to increase its lead over JAWS over the next few years. Given that it is also open-source and free, I can’t help but draw a comparison to the way Firefox overtook Internet Explorer in the 2000s browser wars.</p>
<h3>macOS - Safari (latest version), VoiceOver</h3>
<p>Safari is a fair distance behind Chrome in terms of users, with 16.7% share as of writing, but it has the benefit of being the default browser in macOS. It is also free, and the support for accessibility features with VoiceOver is second to none. In addition to this, because of the similarity with its mobile counterpart, most likely any issues that are identified in the desktop version will have similar fixes.</p>
<h3>iOS - Safari (latest version), VoiceOver</h3>
<p>Safari is by far the most popular browser on iOS and all other browsers on iOS use the WebKit rendering engine. VoiceOver is the gold standard for mobile screen readers (and the only option for iOS devices), and as such it makes sense to use this combination for testing iOS accessibility.</p>
<h3>Android - Chrome (latest version), TalkBack</h3>
<p>In a similar vein to iOS, being the default browser and screen reader combination for Android makes this a simple choice, as it will cover the vast majority of users on this platform. Although manufacturers do include their own browsers and there are quite a few other options on Android, the vast majority of the time they use the inbuilt rendering engine, so the expectation in terms of accessibility should be similar, if not identical, to the Chrome experience.</p>
<p>This is by no means a catch-all solution for everyone. Each circumstance will be different, and the best course of action would be to engage your users and ask rather than trying to make the decision for them.</p>
<p>The reality is that if your site or application’s design or functionality looks bad or works poorly for a large enough number of your users because it does not support the software that they use, it can have potential ramifications to your business, through sales or reputation. Similarly, poor accessibility will have a negative impact if your users are using older versions of screen readers and browser combinations.</p>
<h2>But what about JAWS, ZoomText, System Access, <em>insert screen reader here</em>?</h2>
<p>At the risk of being slightly incendiary, I dislike the idea of paying for something that I can get for free. NVDA is a project that has brought screen readers to everybody – including those without the financial means to pay for it – so I support it. Along with the clear trajectory of its usage uptake, it is not unreasonable to expect that the majority of users will adopt it in the next 5 to 10 years.</p>
<p>At the end of the day, however, your best bet when it comes to identifying where your testing efforts should be placed is to talk to your users to find out what their needs are and what software they use. If you don’t have access to this information, the proposed testing scope above will suffice for the vast majority of your site or application’s users, and most likely will continue to do so in the years to come.</p></section></article></div>]]>
            </description>
            <link>https://jaketracey.com/a-developers-perspective-the-problem-with-screen-reader-testing/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25665851</guid>
            <pubDate>Thu, 07 Jan 2021 01:12:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Love’s contradictions: Catullus on the agony of infatuation]]>
            </title>
            <description>
<![CDATA[
Score 91 | Comments 18 (<a href="https://news.ycombinator.com/item?id=25664867">thread link</a>) | @diodorus
<br/>
January 6, 2021 | https://psyche.co/ideas/loves-contradictions-catullus-on-the-agony-of-infatuation | <a href="https://web.archive.org/web/*/https://psyche.co/ideas/loves-contradictions-catullus-on-the-agony-of-infatuation">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><blockquote>I hate and love. If you ask me to explain<br>The contradiction,<br>I canâ€™t, but I can feel it, and the pain<br>Is crucifixion.</blockquote>
<blockquote> <em>Odi et amo: quare id faciam fortasse requiris.</em><br><em>Nescio, sed fieri sentio et excrucior.</em> </blockquote>
<p><strong>This simple but heartfelt</strong> couplet (translation above by James Michie in 1969) is the best-known Latin love epigram â€“ a short poem in elegiac metre â€“ that survives from Ancient Rome. Composed by the poet Catullus around <span>55 BCE,</span> <span>number 85</span> of his book of <span>116 poems,</span> it pithily encapsulates the searing conflict of emotions that he claims to be experiencing in the course of his affair with a younger married woman, who is addressed in other poems as his â€˜girlâ€™ (<em>puella</em>) and by the pseudonym â€˜Lesbiaâ€™. But for such a short poem â€“ just 14 words in Latin â€“ it has raised a whole host of questions, and hundreds of pages have been written about it. What is the point of the poem? How should it be translated from the Latin? How does it relate to the poetâ€™s life and feelings? Its psychology comes across as complex and strikingly modern, as does much of Catullusâ€™s poetry; to some, the questions it raises might seem more suited to a post-FreudÂ­ian examination of mental conflict than to the concerns of an ancient poet. We might recognise that the opposite emotions of love and hate can be simultaneously entertained; but how, after all, does that work?</p>
<p>In its original Latin, <span>Poem 85</span> is a so-called elegiac couplet, in which a longer line (hexameter) is followed by a shorter one (pentameter). The words of the poem have been placed with care. The couplet is composed in a criss-cross pattern, beginning and ending with two verbs of intense emotional connotation: <em>odi</em>, â€˜I hateâ€™; and <em>excrucior</em>, â€˜Iâ€™m rackedâ€™. The first line concludes with the questÂ­ioning <em>requiris</em>, â€˜you askâ€™; the second opens with the answer <em>nescio</em>, â€˜I donâ€™t knowâ€™. The middle of the first line has <em>faciam</em>, â€˜I doâ€™; the middle of the second has its passive counterÂ­part <em>fieri</em>, â€˜is being doneâ€™ (related to <em>fiat</em> â€“ literally, â€˜let it be doneâ€™).</p>
<p>The couplet thus mimics by its shape the image of the poet being pulled apart in opposite directions, an image made explicit by the verb <em>excrucior</em>. That word (the root of our â€˜excruciatingâ€™) will have evoked for Romans the noun <em>crux</em> (plural <em>cruces</em>). Although in the <span>1st millennium CE</span> <em>crux</em> came to be heard almost exclusively to mean â€˜crossâ€™ with reference to the crucifixion of Christ, in CatullÂ­usâ€™s time it was more commonly used to signify the â€˜rackâ€™. This was the standard instrument of torture in the Roman world, to which unfortÂ­unate victims were bound by their hands and legs so that their bodies might literally be pulled apart.</p>
<p>While Catullus remains utterly infatuated with Lesbia, she has proved to be <br>distressÂ­ingly fickle to him</p>
<p>No less cruel and visible as a method of executÂ­ion in the Roman world was crucifixion. Catullus was in his teens when in <span>71 BCE</span> the slave-revolt led by Spartacus was quelled, and he would probably have witnessed at first hand the gruesome sight of 6,000 captured slaves being nailed or strung up to die on wooden crosses along the Appian Way leading from Rome to Capua. WhatÂ­ever the precise image intended by Catullus as a parallel to his own feeling of torment, what is evident is that the combination of hate and love, pulling him in different directions, is making him feel as if he is being â€˜racked to deathâ€™: the <em>ex</em> of <em>excrucÂ­ior</em> connotes a process leading towards expiry and extinction, as well as extenÂ­sion â€“ both in time and across space. Moreover, Catullus claims, thereâ€™s nothing he can <em>do</em> about it: heâ€™s simply the object of this torturous and self-contradictory feeling. His response to someone who might wish to enquire (<em>requiÂ­ris</em>) about what heâ€™s â€˜doingâ€™ (<em>faciam</em>) is that heâ€™s not â€˜doingâ€™ anything, but that he senses (<em>sentio</em>) it â€˜being doneâ€™ (<em>fieri</em>) to him: the passive form of the verb corresÂ­ponds to his own passivÂ­ity in the process heâ€™s describing.</p>
<p>However, just before Catullus presents himself as the helpless victim of opposing emotÂ­ions, the answer he gives to the imagined question is unequivocal: â€˜I donâ€™t knowâ€™. The implication of <em>nescio</em> (the negative of <em>scio</em>, â€˜knowâ€™, whence comes our word â€˜scienceâ€™) has been overlooked by generations of translators from the Latin, who have rendered the word <em>quare</em> as â€˜whyâ€™ or â€˜the reason whyâ€™ rather than â€˜howâ€™ â€“ even though itâ€™s clear that Catullus does know, as do his readÂ­ers, why or for what reason heâ€™s prey to emotional conflict. For instance, one of the poemâ€™s earliest English transÂ­lators, the poet Richard Lovelace (1617-57), renders it as:</p>
<blockquote>I hate and love; wouldâ€™st thou the reason know?<br>I know not, but I burn, and feel it so.</blockquote>
<p>Similarly, the translator in the popular Loeb series, which prints classical texts with facing versions in straightforward English, in 1976 had it as:</p>
<blockquote>I hate and love. Why I do so, perhaps you ask? <br>I know not, but I feel it, and I am in torment.</blockquote>
<p>Such translations using â€˜whyâ€™ followed by â€˜I donâ€™t knowâ€™ ask us to suppÂ­ose that Catullus is claiming an inability to understand the reason for his painful emotional turmoil. Yet the poet has already made it abundantly clear, in several other poems describing his affair with Lesbia, that he knows the reason only too well: while he remains utterly infatuated with her, she has proved distressÂ­ingly fickle to him, willing to be unfaithful not only to her husband but to her adultÂ­erous liaison with the poet too. In <span>Poem 72</span> (my translation), Catullus analyses the effect on him of Lesbiaâ€™s infidelity:</p>
<blockquote>You used to say you had eyes for Catullus alone, <br>Lesbia, and would rather hold me in your arms than Jove. <br>My feelings for you then were not just vulgar lust,<br>but the kind of love a father feels for his children and their kin. <br>Now that I know your ways, my desire for you burns ever fiercer,<br>even though youâ€™re far shabbier in my eyes, and flightier. <br>How can this be, you say: itâ€™s because such hurtful treatment <br>is bound to make one desire oneâ€™s lover more, but like them less.</blockquote>
<p>How is it possible, in terms of logic or emotion, to feel both hate and love towards the same person at the same time?</p>
<p>In the final couplet here, Catullus explains to the reader, in terms very similar to those he uses in <span>Poem 85,</span> the paradox of his feelings. The enquirer doesnâ€™t need to ask the cause of the poetâ€™s pain, here described as <em>iniuria</em> (â€˜hurtful treatmentâ€™) because itâ€™s easy to understand: Catullus is wounded by Lesbiaâ€™s sexual intimacy with other lovers and hotly resents her behaviour; but his desire for her, perhaps intensified by the prospect of losing her to a love-rival, is even stronger.</p>
<p><strong>The reader might still </strong>ask how such divergent feelings as love and dislike can coexist in a lover and be directed towards the same object â€“ indeed, the final line above describes someÂ­thing that feels like such an emotional contradiction, the combinÂ­ation of desire with disliking. That divergence is, in <span>Poem 85,</span> yet more starkly expressed with â€˜I hate and loveâ€™ (rendered more emphatically in translations that repeat the â€˜Iâ€™: â€˜I hate and I loveâ€™). But, again, Catullus would expect the reader to ask not â€˜whyâ€™, but â€˜howâ€™; that is, how is it possible, whether in terms of logic or emotion, for someone to feel both hate and love towards the same person at the same time? Since Catullus knows, as do his readers, <em>why</em> heâ€™s prey to these contradictory feelings, only in answer to the question â€˜howâ€™ can it be reasonable for him to follow up, as he does, with â€˜I donâ€™t knowâ€™. Having declared his ignorance of how the perplexing phenomenon of simultaneous opposing emotions can arise, he then abandons analysis and simply testifies to his own torment.</p>
<p>The correctness of the translation of <em>quare</em> as â€˜howâ€™ is confirmed by lexical data. In Catullusâ€™s time and before (as found, for example, in passages written by Catullusâ€™s older contempÂ­orary, the orator Cicero) <em>quare</em> is used to mean â€˜howâ€™ or â€˜in what wayâ€™. It comes to mean â€˜whyâ€™ in the course of the languageâ€™s histÂ­Â­ory; but given the compelling contextual and linguistic arguments for the understanding of what Catullus is asking in <span>Poem 85,</span> what explanation can there be for the persistÂ­ent mistranslation of <em>quare</em> as â€˜whyâ€™ rather than as â€˜howâ€™ in English? (TransÂ­lations into other languages such as Italian, German and French also tend to fluctuate between rendering <em>quare</em> as â€˜whyâ€™ and â€˜howâ€™).</p>
<p>One answer must be that translators have been influenced by a later Latin couplet thatâ€™s as famous as Catullusâ€™s, and indeed alludes to it. A satirical squib <span>(number 32)</span> composed by the poet Martial in the late <span>1st century CE,</span> more than <span>100 years</span> after Catullusâ€™s death, uses the same couplet form:</p>
<blockquote>I donâ€™t like you, Sabidius, and Iâ€™m unable to say why:<br>All I can say is this: I donâ€™t like you.</blockquote>
<blockquote> <em>Non amo te, Sabidi, nec possum dicere quare: </em><br><em>Hoc tantum possum dicere: non amo te</em>.</blockquote>
<p>Nothing is known of the context of the epigram or of the implied feud between the poet and the otherwise unknown Sabidius. But the poem has won a firm, if anecdotal, place in the annals of Latin studies in England. The story (undoubÂ­tedly apocryphal) is told how, as a student at Christ Church College, Oxford, the writer Thomas Brown (1662-1704) committed a misdeÂ­meanour and was sent for punishment to the college dean, a <span>Dr Fell.</span> The dean required Brown to transÂ­late some Latin verse on the spot, and opened a book of epigrams at random to present him with Martialâ€™s couplet. After a momentâ€™s thought, Brown recited, allegedly to the deanâ€™s delight, his witty and memorable version of the poem:</p>
<blockquote>I do not like thee, Doctor Fell, <br>The reason why I cannot tell; <br>But this I know, and know full well, <br>I do not like thee, Doctor Fell.</blockquote>
<p>In the case of Martialâ€™s epigram, â€˜the reason whyâ€™ is a …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://psyche.co/ideas/loves-contradictions-catullus-on-the-agony-of-infatuation">https://psyche.co/ideas/loves-contradictions-catullus-on-the-agony-of-infatuation</a></em></p>]]>
            </description>
            <link>https://psyche.co/ideas/loves-contradictions-catullus-on-the-agony-of-infatuation</link>
            <guid isPermaLink="false">hacker-news-small-sites-25664867</guid>
            <pubDate>Thu, 07 Jan 2021 00:15:08 GMT</pubDate>
        </item>
    </channel>
</rss>
