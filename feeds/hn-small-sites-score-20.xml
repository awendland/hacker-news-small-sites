<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 20]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 20. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Sun, 10 Jan 2021 12:57:57 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-20.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Sun, 10 Jan 2021 12:57:57 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[Over 100 Scientists and Doctors Call for Increased Vitamin D to Combat Covid-19]]>
            </title>
            <description>
<![CDATA[
Score 109 | Comments 82 (<a href="https://news.ycombinator.com/item?id=25680282">thread link</a>) | @kpfleger
<br/>
January 7, 2021 | https://vitamindforall.org/letter.html | <a href="https://web.archive.org/web/*/https://vitamindforall.org/letter.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p><span>#VitaminDforAll </span><span>(for questions or fact checking assistance, contact press@vitaminDforAll.org)</span></p><p id="h.mjz6soj7f435"><span>Over 100 </span><span>Scientists, Doctors, &amp; Leading Authorities</span><span>&nbsp;Call For </span><span>Increased</span><span>&nbsp;Vitamin D Use To Combat COVID-19</span></p><p><span>[Residents of the USA: Text “VitaminDforAll” to 50409 to send this to your state’s governor.]</span></p><p><span>Research shows low vitamin D levels almost certainly promote COVID-19 infections, hospitalizations, and deaths. Given its safety, </span><span>w</span><span>e call for immediate widespread increased vitamin D intakes</span><span>.</span></p><p><span>Vitamin D modulates thousands of genes and many aspects of immune function, both innate and adaptive. The scientific evidence</span><span>1</span><span>&nbsp;shows that:</span></p><p><span>Vitamin D is well known to be essential, but most people do not get enough. Two common definitions of inadequacy are deficiency &lt; 20ng/ml (50nmol/L), the target of most governmental organizations, and insufficiency &lt; 30ng/ml (75nmol/L), the target of several medical societies &amp; experts.</span><span>2</span><span>&nbsp;Too many people have levels below these targets. </span><span>Rates of vitamin D deficiency &lt;20ng/ml exceed 33% of the population in most of the world, and most estimates of insufficiency &lt;30ng/ml are well over 50% (but much higher in many countries).</span><span>3</span><span>&nbsp;Rates are even higher in winter, and several groups have notably worse deficiency: the overweight, those with dark skin (especially far from the equator), and care home residents. These same groups face increased COVID-19 risk.</span></p><p><span>It has been shown that 3875 IU (97mcg) daily is required for 97.5% of people to reach 20ng/ml, and 6200 IU (155mcg) for 30ng/ml,</span><span>4</span><span>&nbsp;intakes far above all national guidelines. Unfortunately, the report that set the US RDA included an admitted statistical error in which required intake was calculated to be ~10x too low.</span><span>4</span><span>&nbsp;Numerous calls in the academic literature to raise official recommended intakes had not yet resulted in increases by the time SARS-CoV-2 arrived. Now, many papers indicate that vitamin D affects COVID-19 more strongly than most other health conditions, with increased risk at levels &lt; 30ng/ml (75nmol/L) and severely greater risk &lt; 20ng/ml (50nmol/L).</span><span>1</span></p><p><span>Evidence to date </span><span>suggests </span><span>the possibility that the COVID-19 pandemic sustains itself in large part &nbsp;through infection of those with low vitamin D, and that deaths are concentrated largely in those with deficiency. The mere possibility that this is so should compel urgent gathering of more vitamin D data. </span><span>Even without more data</span><span>, </span><span>the </span><span>preponderance </span><span>of evidence indicates that </span><span>increased vitamin D would help reduce infections, hospitalizations, ICU admissions, &amp; deaths</span><span>.</span></p><p><span>Decades of safety data show that vitamin D has very low risk: </span><span>Toxicity would be extremely rare with the recommendations here. The risk of insufficient levels far outweighs any risk from levels that seem to provide most of the protection against COVID-19, and this is notably different from drugs. Vitamin D is much safer than steroids, such as dexamethasone, the most widely accepted treatment to have also demonstrated a large COVID-19 benefit. Vitamin D’s safety is more like that of face masks. </span><span>There is no need to wait for further clinical trials to increase use of something so safe, </span><span>especially when remedying high rates of deficiency/insufficiency should already be a priority</span><span>.</span></p><p><span>Therefore, we call on all governments, doctors, and healthcare workers worldwide to immediately recommend and implement efforts appropriate to their adult populations to increase vitamin D, at least until the end of the pandemic. Specifically to:</span></p><p><span>Many factors are known to predispose individuals to higher risk from exposure to SARS-CoV-2, such as age, being male, comorbidities, etc., but </span><span>inadequate</span><span>&nbsp;v</span><span>itamin D is by far the most easily and quickly </span><span>modifiable</span><span>&nbsp;risk factor with abundant evidence to support a large effect</span><span>. Vitamin D is inexpensive and has negligible risk compared to the considerable risk of COVID-19.</span></p><p><span>5</span><span>&nbsp;The following include 4000 IU within their tolerable intakes in official guidelines: NAM (US, Canada), SACN (UK), EFSA (Europe), Endocrine Society (international), Nordic countries, The Netherlands, Australia &amp; New Zealand, UAE, and the American Geriatrics Soc. (USA, elderly). No major agency specifies a lower tolerable intake limit. The US NAM said 4000 IU “is likely to pose no risk of adverse health effects to almost all individuals.” See also [</span><span><a href="https://pubmed.ncbi.nlm.nih.gov/32180081/">Giustina et al ‘20</a></span><span>].</span></p><p><span>The signatories below endorse this letter. Affiliations do not imply endorsement of the letter by the institutions themselves.</span></p><p><span>This letter takes no position on other public health measures besides vitamin D. Personal views of individual signatories on any other matter do not represent the group as a whole.</span></p><p><span>All signatories declare no conflicts of interest except as noted.</span></p><p><span>To emphasize: </span><span>The organizing signatories have no conflicts of interest in this area (financial or otherwise)</span><span>, nor have they done research in this area prior to 2020.</span></p><div><tbody><tr><td colspan="1" rowspan="1"><p><span>Signatories (185)</span></p></td><td colspan="1" rowspan="1"><p><span>recom- mended intake</span></p></td><td colspan="1" rowspan="1"><p><span>personal daily intake</span></p></td></tr><tr><td colspan="1" rowspan="1"><p><span>Dr. Karl Pfleger</span><span>, PhD AI &amp; Computer Science, Stanford. Former Google Data Scientist. Biotechnology Investor, AgingBiotech.info, San Francisco, CA, USA. (organizing signatory)</span></p></td><td colspan="1" rowspan="1"><p><span>4000 IU</span></p></td><td colspan="1" rowspan="1"><p><span>7000 IU</span></p></td></tr><tr><td colspan="1" rowspan="1"><p><span>Dr. Gareth Davies</span><span>, PhD Medical Physics, Imperial College, London, UK. Codex World’s Top 50 Innovator 2019. Independent Researcher. Lead author of “</span><span><a href="https://www.medrxiv.org/content/10.1101/2020.05.01.20087965v3">Evidence Supports a Causal Role for Vitamin D Status in COVID-19 Outcomes</a></span><span>.” (organizing signatory)</span></p></td><td colspan="1" rowspan="1"><p><span>4000 IU</span></p></td><td colspan="1" rowspan="1"><p><span>10,000 IU</span></p></td></tr><tr><td colspan="1" rowspan="1"><p><span>Dr. Bruce W Hollis</span><span>, PhD. Professor of Pediatrics, Medical University of South Carolina, USA.</span></p></td><td colspan="1" rowspan="1"><p><span>4000 IU</span></p></td><td colspan="1" rowspan="1"><p><span>6000 IU</span></p></td></tr><tr><td colspan="1" rowspan="1"><p><span>Dr. Barbara J Boucher</span><span>, MD, FRCP (London). </span><span>Honorary Professor (Medicine), Blizard Institute, Bart's &amp; The London School of Medicine and Dentistry, Queen Mary University of London, UK. </span><span>(significantly contributing signatory)</span></p></td><td colspan="1" rowspan="1"><p><span>4000 IU</span></p></td><td colspan="1" rowspan="1"><p><span>2000 IU</span></p></td></tr><tr><td colspan="1" rowspan="1"><p><span>Dr. Ashley Grossman</span><span>, MD FRCP FMedSci. Emeritus Professor of Endocrinology, University of Oxford, UK. Professor of Neuroendocrinology, Barts and the London School of Medicine. 2020 Endocrine Society Laureate Award.</span></p></td><td colspan="1" rowspan="1"><p><span>2000 IU</span></p></td><td colspan="1" rowspan="1"><p><span>2200 IU</span></p></td></tr><tr><td colspan="1" rowspan="1"><p><span>Dr. Gerry Schwalfenberg</span><span>, MD, CCFP, FCFP. Assistant Clinical Professor in Family Medicine, University of Alberta, Canada.</span></p></td><td colspan="1" rowspan="1"><p><span>4000 IU</span></p></td><td colspan="1" rowspan="1"><p><span>5000 IU</span></p></td></tr><tr><td colspan="1" rowspan="1"><p><span>Dr. Giovanna Muscogiuri</span><span>, MD PhD. Associate Editor, European Journal of Clinical Nutrition. </span><span>Department of Clinical Medicine and Surgery, Section of Endocrinology, University "Federico II" of Naples, Naples, Italy.</span><span>.</span></p></td><td colspan="1" rowspan="1"><p><span>4000 IU</span></p></td><td colspan="1" rowspan="1"><p><span>1000 IU</span></p></td></tr><tr><td colspan="1" rowspan="1"><p><span>Dr. Michael F. Holick</span><span>, PhD MD. Professor Medicine, Physiology and Biophysics and Molecular Medicine, Director Vitamin D, Skin and Bone Research Laboratory, Boston University Medical Center, USA. (6000 IU) </span><span>Disclosure: Consultant Biogena and speaker's Bureau Abbott Inc.</span></p></td><td colspan="1" rowspan="1"><p><span>4000 IU</span></p></td><td colspan="1" rowspan="1"><p><span>6000 IU</span></p></td></tr><tr><td colspan="1" rowspan="1"><p><span>Dr. John Umhau</span><span>, MD, MPH. CDR, USPHS (ret). </span><span>President, Academy of Medicine of Washington, DC, USA. Ex-NIH: c</span><span>o-author of the first peer-reviewed report linking vitamin D deficiency with acute respiratory infection.</span><span>&nbsp;</span><span>(significantly contributing signatory)</span></p></td><td colspan="1" rowspan="1"><p><span>4000 IU</span></p></td><td colspan="1" rowspan="1"><p><span>5000 IU</span></p></td></tr><tr><td colspan="1" rowspan="1"><p><span>Dr. </span><span>Pawel</span><span>&nbsp;</span><span>Pludowski</span><span>, MD, dr hab. Associate Professor, Biochemistry, Radioimmunology and Experimental Medicine, Children’s Memorial Health Institute, Warsaw, Poland. Chair, European Vitamin D Association (EVIDAS) [non-profit].</span></p></td><td colspan="1" rowspan="1"><p><span>4000 IU</span></p></td><td colspan="1" rowspan="1"><p><span>2000 IU</span></p></td></tr><tr><td colspan="1" rowspan="1"><p><span>Dr. Cedric F. Garland</span><span>, DrPH. Professor Emeritus, Department of Family Medicine and Public Health, University of California, San Diego, USA.</span></p></td><td colspan="1" rowspan="1"><p><span>4000 IU</span></p></td><td colspan="1" rowspan="1"><p><span>6000 IU</span></p></td></tr><tr><td colspan="1" rowspan="1"><p><span>Dr. Jose M. Benlloch</span><span>, Professor, Director of the Institute for Instrumentation on Molecular Imaging, CSIC-UPV, Valencia, Spain.</span></p></td><td colspan="1" rowspan="1"><p><span>2000 IU</span></p></td><td colspan="1" rowspan="1"><p><span>3000 IU</span></p></td></tr><tr><td colspan="1" rowspan="1"><p><span>Dr. Samantha Kimball</span><span>, PhD, MLT. Professor, St. Mary's University, Calgary, Alberta, Canada. Research Director, GrassrootsHealth Nutrient Research Institute [non-profit].</span><span>&nbsp;</span><span>(significantly contributing signatory)</span></p></td><td colspan="1" rowspan="1"><p><span>4000 IU</span></p></td><td colspan="1" rowspan="1"><p><span>6000 IU</span></p></td></tr><tr><td colspan="1" rowspan="1"><p><span>Dr. William B. Grant</span><span>, PhD Physics, U. of California, Berkeley. Director at Sunlight, Nutrition, and Health Research Center [non-profit], San Francisco, CA, USA. </span><span>Disclosure: Receives funding from Bio-Tech Pharmacal, Inc.</span></p></td><td colspan="1" rowspan="1"><p><span>4000 IU</span></p></td><td colspan="1" rowspan="1"><p><span>5300 IU</span></p></td></tr><tr><td colspan="1" rowspan="1"><p><span>Dr. Carol L. Wagner,</span><span>&nbsp;MD. Professor, Medical University of South Carolina, USA.</span></p></td><td colspan="1" rowspan="1"><p><span>4000 IU</span></p></td><td colspan="1" rowspan="1"><p><span>5000 IU</span></p></td></tr><tr><td colspan="1" rowspan="1"><p><span>Dr. Paul Marik</span><span>, MD, FCCP, FCCM. </span><span>Chief of Pulmonary and Critical Care Medicine and Professor of Medicine</span><span>, Eastern Virginia Medical School, Norfolk, VA, USA.</span></p></td><td colspan="1" rowspan="1"><p><span>2000 IU</span></p></td><td colspan="1" rowspan="1"><p><span>2000 IU</span></p></td></tr><tr><td colspan="1" rowspan="1"><p><span>Dr. Morry Silberstein</span><span>, MD. Associate Professor, Curtin University, Australia.</span></p></td><td colspan="1" rowspan="1"><p><span>4000 IU</span></p></td><td colspan="1" rowspan="1"></td></tr><tr><td colspan="1" rowspan="1"><p><span>Dr. Vatsal Thakkar</span><span>, MD. Founder, Reimbursify, NY, USA. &nbsp;Former faculty, NYU and Vanderbilt. &nbsp;Op-Ed writer on Vitamin D and COVID-19.</span><span>&nbsp;</span><span>(significantly contributing signatory)</span></p></td><td colspan="1" rowspan="1"><p><span>4000 IU</span></p></td><td colspan="1" rowspan="1"><p><span>10,000 IU</span></p></td></tr><tr><td colspan="1" rowspan="1"><p><span>Dr. Peter H Cobbold</span><span>, PhD. Emeritus Professor, Cell Biology, University of Liverpool, UK.</span></p></td><td colspan="1" rowspan="1"><p><span>4000 IU</span></p></td><td colspan="1" rowspan="1"><p><span>4000 IU</span></p></td></tr><tr><td colspan="1" rowspan="1"><p><span>Dr. Afrozul Haq</span><span>, PhD. Professor Dept of Food Technology, Jamia Hamdard University, New Delhi, India.</span></p></td><td colspan="1" rowspan="1"><p><span>4000 IU</span></p></td><td colspan="1" rowspan="1"><p><span>2000 IU</span></p></td></tr><tr><td colspan="1" rowspan="1"><p><span>Dr. Barry H. Thompson</span><span>, MD, FAAP, FACMG. Clinical Associate Professor (Pediatrics), Uniformed Services University of the Health Sciences, Bethesda, MD, USA.</span></p></td><td colspan="1" rowspan="1"><p><span>4000 IU</span></p></td><td colspan="1" rowspan="1"><p><span>5000 IU</span></p></td></tr><tr><td colspan="1" rowspan="1"><p><span>Dr. Reinhold Vieth</span><span>, PhD, FCACB. Professor, Departments of Nutritional Sciences and Laboratory Medicine &amp; Pathobiology, University of Toronto, Canada. Director (retired), Bone and Mineral Group Laboratory, Mt Sinai Hospital. </span><span>Disclosure: </span><span>Receives patent royalties from Ddrops (an infant vitamin D supplement).</span></p></td><td colspan="1" rowspan="1"><p><span>4000 IU</span></p></td><td colspan="1" rowspan="1"><p><span>4000 IU</span></p></td></tr><tr><td colspan="1" rowspan="1"><p><span>Dr. Linda Benskin</span><span>, PhD, RN, SRN(Ghana), CWCN, CWS, DAPWCA. Independent Researcher for Tropical Developing Countries and Ferris Mfg. Corp, Texas, USA. </span><span>(significantly contributing signatory)</span></p></td><td colspan="1" rowspan="1"><p><span>4000 IU</span></p></td><td colspan="1" rowspan="1"><p><span>4000 IU</span></p></td></tr><tr><td colspan="1" rowspan="1"><p><span>Jim O’Neill</span><span>, CEO, SENS Research Foundation. Former principal associate deputy secretary of Health and Human Services, USA.</span></p></td><td colspan="1" rowspan="1"><p><span>4000 IU</span></p></td><td colspan="1" rowspan="1"><p><span>6000 IU</span></p></td></tr><tr><td colspan="1" rowspan="1"><p><span>Dr. Eric Feigl-Ding</span><span>, PhD. Epidemiologist &amp; Health Economist. Senior Fellow, Federation of American Scientists. USA.</span></p></td><td colspan="1" rowspan="1"><p><span>4000 IU</span></p></td><td colspan="1" rowspan="1"><p><span>5000 IU</span></p></td></tr><tr><td colspan="1" rowspan="1"><p><span>Rt Hon David Davis MP</span><span>, Member of Parliament (Conservative Party). BSc, Joint Hons Molecular Science / Computer Science, Warwick University, UK.</span></p></td><td colspan="1" rowspan="1"><p><span>4000 IU</span></p></td><td colspan="1" rowspan="1"><p><span>6000 IU</span></p></td></tr><tr><td colspan="1" rowspan="1"><p><span>Dr. Rupa Huq MP,</span><span>&nbsp;Member of Parliament (Labour Party). PhD, Cultural Studies, University of East London, UK.</span></p></td><td colspan="1" rowspan="1"><p><span>4000 IU</span></p></td><td colspan="1" rowspan="1"></td></tr><tr><td colspan="1" rowspan="1"><p><span>Dr. Susan J Whiting</span><span>, PhD. Professor Emerita, University of Saskatchewan, Canada.</span></p></td><td colspan="1" rowspan="1"><p><span>4000 IU</span></p></td><td colspan="1" rowspan="1"><p><span>4000 IU</span></p></td></tr><tr><td colspan="1" rowspan="1"><p><span>Dr. Richard Mazess</span><span>. PhD. Emeritus Professor, University of Wisconsin, Madison, USA.</span></p></td><td colspan="1" rowspan="1"><p><span>4000 IU</span></p></td><td colspan="1" rowspan="1"><p><span>5000 IU</span></p></td></tr><tr><td colspan="1" rowspan="1"><p><span>Dr. Helga Rhein</span><span>, MD (retired). </span><span>Sighthill…</span></p></td></tr></tbody></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://vitamindforall.org/letter.html">https://vitamindforall.org/letter.html</a></em></p>]]>
            </description>
            <link>https://vitamindforall.org/letter.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25680282</guid>
            <pubDate>Fri, 08 Jan 2021 01:34:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Avoiding instruction cache misses (2019)]]>
            </title>
            <description>
<![CDATA[
Score 49 | Comments 8 (<a href="https://news.ycombinator.com/item?id=25680125">thread link</a>) | @nkurz
<br/>
January 7, 2021 | https://paweldziepak.dev/2019/06/21/avoiding-icache-misses/ | <a href="https://web.archive.org/web/*/https://paweldziepak.dev/2019/06/21/avoiding-icache-misses/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div role="main"><div><article><p>Modern processors are quite complex, with many parts having the potential to become a bottleneck. It is relatively easy to reason about the performance of short pieces of code, especially if memory effects are kept to a minimum. Both static analysis tools like LLVM MCA and microbenchmarks can provide a lot of information in such cases. However, the behaviour of the whole program is not just the sum of those small parts. As the code becomes larger and more complex other effects start appearing. One of such potential problems are excessive instruction cache misses.</p><p>Every program has different properties, and those large-scale effects will affect it differently. However, if its job is to execute complex logic on a small amount of data, the instruction cache is likely to become a problem at some point. The actual impact may vary significantly from codebase to codebase, which is why I won’t show any numbers in this article. Let’s consider this just a collection of ideas, but it is not easy to tell how much any of them will help for a given application.</p><p>First, let’s have a quick look at the processor front end. Below is a simplified diagram of how it is arranged in Skylake, the numbers between units are the maxima per cycle.</p><p><img loading="lazy" width="630" height="860" src="https://paweldziepak.dev/static/icache-front-end.min.2e73578fff.svg" alt="CPU front end"></p><p>Each cycle the processor fetches up to 16 bytes from the instruction cache using information from the Branch Prediction Unit to predict the control flow. The pre-decode unit determines instruction lengths and puts up to five of them in the Instruction Queue. From the Instruction Queue, up to 5 instructions (with macro-fusion) are brought each cycle to the decoders. There is one complex decoder that can handle instructions that translate to up to 4 µops and 3 simple decoders that can handle only single-µop instructions. In total, all decoders are limited to producing no more than 5 µops each cycle. Instructions that require more than 4 µops go through Microcode Sequence ROM, which emits 4 µops per cycle, and while it is active, the decoders are disabled. There is also Decoded ICache (<abbr title="Decoded Stream Buffer">DSB</abbr>) which caches decoded µops. It can emit up to 6 µops each cycle. All µops, regardless of their source, end up in the Instruction Decode Queue (IDQ). The Loop Stream Detector (LSD) detects small loops and keeps them in the queue, so that no fetched, decodes or reads from the DSB are needed during the duration of the loop. IDQ is the last part of the front end, and the queued µops continue to the back end.</p><p>From the instruction cache point of view, the front end has two weaknesses. Firstly, instructions are processed in-order which can severely limit the processor ability to hide latencies of cache misses. HyperThreading can make sure that this part of the processor still does some useful work, but it is also the source of the second problem – all resources, including the L1 instruction cache and µop cache are shared between the hardware threads.</p><p>Modern processors provide various metrics that help monitor their behaviour. However, the task of extracting the relevant data requires a proper approach if it is to be done efficiently. Top-down analysis is invaluable with helping to understand microarchitectural phenomena in large codebases. The idea is to monitor program behaviour with the <abbr title="Performance Monitoring Unit">PMU</abbr> counters and identify the bottleneck starting with the major functional parts of the CPU and then digging deeper narrowing down on the exact source of the problem. It can be done in an automated way by tools like VTune or toplev.</p><pre><code>FE    Frontend_Bound:                                      39.48 +-  0.00 % Slots
BE    Backend_Bound:                                       16.19 +-  0.00 % Slots
    This category represents fraction of slots where no uops are
    being delivered due to a lack of required resources for
    accepting new uops in the Backend...
FE    Frontend_Bound.Frontend_Latency:                     24.92 +-  0.00 % Slots
FE    Frontend_Bound.Frontend_Bandwidth:                   13.45 +-  0.00 % Slots
FE    Frontend_Bound.Frontend_Latency.ICache_Misses:       14.45 +-  0.00 % Clocks &lt;==
    This metric represents fraction of cycles the CPU was
    stalled due to instruction cache misses...
    Sampling events:  frontend_retired.l2_miss:pp frontend_retired.l1i_miss:pp
FE    Frontend_Bound.Frontend_Latency.ITLB_Misses:          8.71 +-  0.00 % Clocks
    This metric represents fraction of cycles the CPU was
    stalled due to instruction TLB misses...
    Sampling events:  frontend_retired.stlb_miss:pp frontend_retired.itlb_miss:pp
FE    Frontend_Bound.Frontend_Latency.Branch_Resteers:      8.42 +-  0.00 % Clocks_Est
    This metric represents fraction of cycles the CPU was
    stalled due to Branch Resteers...
    Sampling events:  br_misp_retired.all_branches:u
FE    Frontend_Bound.Frontend_Bandwidth.MITE:              31.93 +-  0.00 % CoreClocks
    This metric represents Core fraction of cycles in which CPU
	was likely limited due to the MITE pipeline (Legacy Decode
    Pipeline)...
</code></pre><p>Above is an example of a toplev result. We can see that the instruction cache misses were the dominating bottleneck. Unsurprisingly instruction TLB misses also show up. On the front end bandwidth side of things, toplev points to the legacy decode pipeline. That makes perfect sense if the instructions are supplied from DSB or LSD, then there are no instruction fetches, and no cache misses.</p><p>Sometimes, the final summary may not provide sufficient information if there are changes in the code behaviour during the test. When that’s the case, a graph is likely to be a much more helpful way of presenting the results.</p><p><img loading="lazy" width="950" height="950" src="https://paweldziepak.dev/static/icache-toplev.min.2b465fdb6f.svg" alt="toplev"></p><p>Tools like toplev are great for initial identification of the problem, but once that’s done what we need is a right way for comparing different solutions. Ultimately, the most important metric is the actual performance of the program in a real-life workload. toplev still can be helpful as it shows the balance between different performance-limiting factors. What also can be useful is <code>perf stat</code> which can show the performance counter statistics. The event most relevant for us is <code>L1-icache-load-misses</code>, though there are more model-specific registers that may be of interest.</p><p>Now, that we know how to diagnose excessive instruction cache misses, let’s see what can be done to deal with this problem.</p><h2 id="avoiding-work">Avoiding work</h2><p>If the number of executed instructions is the problem, the most obvious solution is to try to reduce that number. Obviously, that’s much easier said than done, but there are some common patterns for dealing with this issue. One example would be prepared statements in databases. The general idea is that if a client knows it will send requests that have some commonality, it can tell the database engine early that the requests are going to match specific templates. This information allows the server to do as much work as possible during the preparation stage, thus reducing the amount of logic that needs to be executed for each individual request.</p><p>Extracting common patterns doesn’t have to be explicit. A server or any other kind of an application which actions depend on the user input could attempt to look for repeating patterns and cache some common parts. This is a very vague idea and most likely won’t be easily implementable in a lot of applications, but in some cases may be quite a natural solution. It also shows the main problem with the “just do less” approach – it is very application specific. On the plus, side, if this can be done, it is likely to help with the overall performance, not just the instruction cache misses.</p><p>Another potential problem is making sure that the preparation phase can really do something to help during the execution phase. If that means pre-computing some values, then it’s simple. However, if the only thing that preparation gives us is the knowledge which code paths are going to be exercised and which branches taken during the execution, it is going to be harder to take benefit from it. One option is to have some specialised code for the most common paths, C++ templates may come in handy here. If it is not easy to determine what may be the most common paths, then a just-in-time compiler may be used to generate code in the preparation stage.<sup id="fnref:1"><a href="#fn:1" role="doc-noteref">1</a></sup></p><h2 id="batching-work">Batching work</h2><p>So far, we have been trying to reduce the number of executed instructions, by taking advantage of some earlier knowledge to avoiding repeating the same work. In other words, we have introduced two stages:</p><ul><li>preparation, which is performed rarely and, consequently, less performance critical</li><li>execution, which is done many times and is expected to dominate overall performance</li></ul><p>The way this can help with the instruction cache misses is that the execution stage, being smaller, is more likely to fit in the instruction cache. Whether this brings any measurable benefits depends highly on the type of the application and how much logic can be moved from execution to preparation stages.</p><p>We have already split our processing pipeline into preparation and execution stage. If the execution stage can fit in the instruction cache, we are done. However, often, that’s not the case. What we can do to improve the situation more is to split the execution into more stages. This time the goal is not to reuse work as it was with the preparation, but to group entities that need to have the same code executed for them. In other words, if the processing pipeline consists of steps A, B and C the idea is to separate them, add a queue in front of each of those stages, and then cycle through those stages each time handling multiple elements from the queue. Connections between the stages don’t have to be one-to-one, any directed graph is fine.</p><p><img loading="lazy" width="756" height="331" src="https://paweldziepak.dev/static/icache-seda.min.7259b25adc.svg" alt="SEDA diagram"></p><p>In the diagram above, there is one stage that feeds tasks to one of two stages. This could be, for example, a front-end of a database server. The first stage does some initial request processing and then, depending on whether it is a read or write, puts it in the appropriate queue. Each stage processes requests in batches, the first one warms up the instruction …</p></article></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://paweldziepak.dev/2019/06/21/avoiding-icache-misses/">https://paweldziepak.dev/2019/06/21/avoiding-icache-misses/</a></em></p>]]>
            </description>
            <link>https://paweldziepak.dev/2019/06/21/avoiding-icache-misses/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25680125</guid>
            <pubDate>Fri, 08 Jan 2021 01:15:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[CO2 already emitted will warm Earth beyond climate targets, study finds]]>
            </title>
            <description>
<![CDATA[
Score 304 | Comments 187 (<a href="https://news.ycombinator.com/item?id=25679618">thread link</a>) | @colinprince
<br/>
January 7, 2021 | https://www.cbc.ca/news/technology/climate-targets-1.5861537 | <a href="https://web.archive.org/web/*/https://www.cbc.ca/news/technology/climate-targets-1.5861537">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>The amount of baked-in global warming, from carbon pollution already in the air, is enough to blow past international agreed upon goals to limit climate change, a new study finds. But it can be delayed for centuries if governments takes action.</p><div><figure><div><p><img loading="lazy" alt="" srcset="" sizes="" src="https://i.cbc.ca/1.4922800.1543350548!/cpImage/httpImage/image.jpg_gen/derivatives/16x9_780/us-coal-s-decline.jpg"></p></div><figcaption>Smoke and steam rise from the smokestack of a coal-fired power plant near Ordos in northern China's Inner Mongolia Autonomous Region in 2015.  A new study estimates that 2.3 C of warming is inevitable, but can be delayed for centuries if the world quickly stops emitting extra greenhouse gases from the burning of coal, oil and natural gas, the study's authors say.<!-- --> <!-- -->(Mark Schiefelbein/Associated Press)</figcaption></figure><p><span><p>The amount of baked-in global warming, from carbon pollution already in the air, is enough to blow past international agreed upon goals to limit climate change, a new study finds.</p>  <p>But it's not game over because, while that amount of warming may be inevitable, it can be delayed for centuries if the world quickly stops emitting extra greenhouse gases from the burning of coal, oil and natural gas, the study's authors say.</p>  <p>For decades, scientists have talked about so-called "committed warming" or the increase in future temperature based on past carbon dioxide emissions that stay in the atmosphere for well over a century. It's like the distance a speeding car travels after the brakes are applied.</p>  <p>But Monday's <a href="https://www.nature.com/articles/s41558-020-00955-x">study in the journal Nature Climate Change</a> calculates that a bit differently and now figures the carbon pollution already put in the air will push global temperatures to about 2.3 degrees Celsius (4.1 degrees Fahrenheit) of warming since pre-industrial times.</p>  <p>Previous estimates, including those accepted by international science panels, were about a degree Celsius (1.8 degrees Fahrenheit) less than that amount of committed warming.</p>  <p>International climate agreements set goals of limiting warming to 2 C&nbsp;(3.6 F) since pre-industrial times, with the more ambitious goal of limiting it to 1.5 C&nbsp;(2.7 F) added in Paris in 2015. The world has already warmed about 1.1 C&nbsp;(2 F).</p>  <p>"You've got some ... global warming inertia that's going to cause the climate system to keep warming, and that's essentially what we're calculating," said study co-author Andrew Dessler, a climate scientist at Texas A&amp;M University. "Think about the climate system like the Titanic. It's hard to turn the ship when you see the icebergs."</p>  <p>Dessler and colleagues at the Lawrence Livermore National Lab and Nanjing University in China calculated committed warming to take into account that the world has warmed at different rates in different places and that places that haven't warmed as fast are destined to catch up.</p>    <p>Places such as the Southern Ocean, surrounding Antarctica are a bit cooler, and that difference creates low-lying clouds that reflect more sun away from earth, keeping these places cooler. But this situation can't keep going indefinitely because physics dictates that cooler locations will warm up more and when they do, the clouds will dwindle and more heating will occur, Dessler said.</p>  <p>Previous studies were based on the cooler spots staying that way, but Dessler and colleagues say that's not likely.</p>  <p><span><figure><div><p><img loading="lazy" alt="" srcset="https://i.cbc.ca/1.5693652.1597940952!/cpImage/httpImage/image.jpg_gen/derivatives/original_300/greenland-record-melt.jpg 300w,https://i.cbc.ca/1.5693652.1597940952!/cpImage/httpImage/image.jpg_gen/derivatives/original_460/greenland-record-melt.jpg 460w,https://i.cbc.ca/1.5693652.1597940952!/cpImage/httpImage/image.jpg_gen/derivatives/original_620/greenland-record-melt.jpg 620w,https://i.cbc.ca/1.5693652.1597940952!/cpImage/httpImage/image.jpg_gen/derivatives/original_780/greenland-record-melt.jpg 780w,https://i.cbc.ca/1.5693652.1597940952!/cpImage/httpImage/image.jpg_gen/derivatives/original_1180/greenland-record-melt.jpg 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.5693652.1597940952!/cpImage/httpImage/image.jpg_gen/derivatives/original_780/greenland-record-melt.jpg"></p></div><figcaption>In this Aug. 16, 2019 file photo, icebergs float away as the sun rises near Kulusuk, Greenland. Greenland lost a record amount of ice that year. The world has already warmed 1.1 C since pre-industrial times.<!-- --> <!-- -->(Felipe Dana/The Associated Press)</figcaption></figure></span></p>  <h2>More research needed, outside experts say</h2>  <p>Outside experts said the work is based on compelling reasoning, but want more research to show that it's true. Breakthrough Institute climate scientist Zeke Hausfather said the new work fits better with climate models than observational data.</p>  <p>Just because the world is bound to get more warming than international goals, that doesn't mean all is lost in the fight against global warming, said Dessler, who cautioned against what he called "climate doomers."</p>  <p>If the world gets to net zero carbon emissions soon, 2 degrees of global warming could be delayed enough so that it won't happen for centuries, giving society time to adapt or even come up with technological fixes, he said.</p>  <p>"If we don't, we're going to blow through (climate goals) in a few decades," Dessler said. "It's really the rate of warming that makes climate change so terrible. If we got a few degrees over 100,000 years, that would not be that big a deal. We can deal with that. But a few degrees over 100 years is really bad."</p></span></p></div></div>]]>
            </description>
            <link>https://www.cbc.ca/news/technology/climate-targets-1.5861537</link>
            <guid isPermaLink="false">hacker-news-small-sites-25679618</guid>
            <pubDate>Fri, 08 Jan 2021 00:23:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What React Gets Wrong]]>
            </title>
            <description>
<![CDATA[
Score 31 | Comments 67 (<a href="https://news.ycombinator.com/item?id=25677648">thread link</a>) | @jehna1
<br/>
January 7, 2021 | https://thejunkland.com/blog/what-react-gets-wrong.html | <a href="https://web.archive.org/web/*/https://thejunkland.com/blog/what-react-gets-wrong.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><article><p>React is the de-facto tool for frontend web development. It has a rich ecosystem and a well-known company to back it up. Despite all of this, I think they still get a ton of stuff wrong. This post is about my personal views and things I think React is already a too slow-moving giant to fix.</p><h2 id="the-syntax">The syntax</h2><p>React has such an awful API that they needed to create a whole new programming language syntax to overcome it: The <code>React.createElement</code> API. Most of the time it's hidden behind JSX that's transpiled onto <code>React.createElement</code> calls.</p><p>You either only ever write JSX when working with React, or you get frustrated with the amount of clutter that gets to your codebase from all that repetition that provides no value to the reader.</p><pre><code>Reat.createElement(<span>'html'</span>, <span>null</span>,
  React.createElement(<span>'body'</span>, <span>null</span>,
    React.createElement(<span>'div'</span>, <span>null</span>,
      React.createElement(...)
    )
  )
)
</code></pre><p>I think a much better way is to follow what SwiftUI and Flutter are doing: Move the element's name from argument to be the function's name:</p><pre><code>html(
  body(
    div(...)
  )
)
</code></pre><p>This does not only remove unnecessary clutter, but removes the need for any compilation step.</p><h2 id="create-react-app">create-react-app</h2><p>Next up us a monstrosity that's nowadays accepted by many to be a "best practice" for getting started with a React project. The problem being, that React ecosystem is such a complex beast that they created a bootstrap project so you can get anything done in a meaningful time. Just pray that you don't need to eject it any time soon.</p><p>Just to give you an idea of the absurdness of this situation: create-react-app creates a "hello world" project for you that downloads <strong>2.5 million lines of Javascript code</strong> to your machine. For a hello world app.</p><p>I have strong feelings about fighting complexity by adding more complexity, and this sure smells like something you should not be doing in 2021.</p><p>Instead we should be thinking about where our browsers and server ecosystems are nowadays and if we could make the bootstrapping <em>simpler</em>. Browsers <a href="https://caniuse.com/es6-module">know how to handle imports nowadays</a>, and the module format is <a href="https://nodejs.org/api/esm.html">also part of Node.js</a> without any preprocessing, so you don't necessarily need a build step to get those working.</p><p>Modern browsers are really good with on-the-fly compression like gzip <a href="https://caniuse.com/brotli">and even brotli</a>, so minification is not so much of an issue. Your CDN should anyways be optimizing compression of your static assets.</p><p>Another point being that React is over 100kb when minified (including React DOM because you can't do that much without it). Imagine how much unminified code you could fit in 100kb if you used something that doesn't need to be built at all.</p><h2 id="react-is-not-just-a-view-rendering-library-anymore">React is not just a view rendering library anymore</h2><p>React used to be only a good frontend rendering library with JSX. Nowadays you're signing up for a framework with its own plugin ecosystem, hooks, fibers, suspense, and other obscure future features like <a href="https://reactjs.org/blog/2020/12/21/data-fetching-with-react-server-components.html">server components</a>.</p><p>We've changed from doing <em>model-view-controller</em> to using all-consuming views that perform both business logic and create side effects. Views have become the top-level entity that controls everything else.</p><p>Remember the old saying "UI is a function of state"? React used to be a good implementation of this, but nowadays it's more of "UI that handles your state".</p><p>I think a good view rendering library should do just one thing well: Render the UI based on the app's state. It should not care where the state is, and most importantly it should not handle the state itself. Otherwise we'll end up with things like bloated class components or <em>"suddenly global state and black magic is fine"</em> type of hooks inside otherwise pure functions.</p><p>Instead you should be handling your business logic, side effects and data gathering some place else, and use proper separation of concerns to model your application's logic.</p><h2 id="imagine-a-better-world">Imagine a better world</h2><p>So how would a better React alternative look in 2021? I made a small prototype library called <a href="https://www.npmjs.com/package/longwood">Longwood</a> based on above principles, and a hello world looks like this:</p><pre><code><span>&lt;<span>html</span>&gt;</span>
  <span>&lt;<span>body</span>&gt;</span>
    <span>&lt;<span>div</span> <span>id</span>=<span>"app"</span>&gt;</span><span>&lt;/<span>div</span>&gt;</span>
    <span>&lt;<span>script</span> <span>type</span>=<span>"module"</span>&gt;</span><span>
      <span>import</span> { div, text } <span>from</span> <span>'https://cdn.skypack.dev/longwood'</span>

      <span>const</span> render = div(text(<span>'Hello world!'</span>))
      render(<span>document</span>.getElementById(<span>'app'</span>))
    </span><span>&lt;/<span>script</span>&gt;</span>
  <span>&lt;/<span>body</span>&gt;</span>
<span>&lt;/<span>html</span>&gt;</span>
</code></pre><p><a href="https://codesandbox.io/s/unruffled-star-xs16e?file=/index.html">▶️ Try it out at CodeSandbox.io</a></p><p>That's all the code you need. No precompilation, no build steps, no downloading of 2.5 million lines of code to get started. You can open a text editor, save the code as an <code>index.html</code> file, open it in a browser and it works.</p><p>You have the same power of Javascript to compose your views as with React, and there's a <a href="https://www.npmjs.com/package/longwood-usestate">separate state management library</a> to get started if you're coming from React. But moreover <em>it's okay to handle your state however you want</em>. It's just a rendering library. It can be used for just a small portion of your site if you want. It even supports server-side rendering out of the box (with jsdom).</p><p>Since you're going to ask, here are a couple of examples:</p><ul><li><a href="https://codesandbox.io/s/competent-swartz-beoub?file=/src/TodoComponent.ts">React style Todo app</a></li><li><a href="https://links.thejunkland.com/">Rendering 1000+ rows of data with Longwood</a><ul><li><a href="https://links.thejunkland.com/react/">Same example done with create-react-app</a></li></ul></li></ul><h2 id="to-wrap-up">To wrap up</h2><p>We’ve come a long way since the web 2.0 times. jQuery made the world a better place by making DOM manipulation easier. AngularJS made the world a better place by introducing data binding to the masses. But all great increments seem to fade at some point to welcome better alternatives.</p><p>Will the future be bright for Longwood? I have no idea, it’s a single-person project and at the moment has one production site running on it. But I hope it demonstrates a point that we can do things even better in the future if we keep innovating and cherry-picking the good stuff from others.</p><p>Happy hacking.</p><p><a href="https://twitter.com/intent/tweet?text=%22What%20React%20gets%20wrong%22%20by%20@luotojesse%20https://thejunkland.com/blog/what-react-gets-wrong.html" target="_blank" rel="noopener">Tweet</a></p></article></div></div>]]>
            </description>
            <link>https://thejunkland.com/blog/what-react-gets-wrong.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25677648</guid>
            <pubDate>Thu, 07 Jan 2021 21:19:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[CVE-2021-3011: Key recovery on Google Titan Key]]>
            </title>
            <description>
<![CDATA[
Score 225 | Comments 71 (<a href="https://news.ycombinator.com/item?id=25675556">thread link</a>) | @hexa-
<br/>
January 7, 2021 | https://ninjalab.io/a-side-journey-to-titan/ | <a href="https://web.archive.org/web/*/https://ninjalab.io/a-side-journey-to-titan/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
	<div>
					<div>
							<section id="blog">
				<article id="post-747" class="page">
		<div>
		
<center><h3> <a href="https://ninjalab.io/wp-content/uploads/2021/01/a_side_journey_to_titan.pdf" target="_blank" rel="noopener noreferrer">Download the Writeup<center><img src="https://ninjalab.io/wp-content/uploads/2021/01/Titan_Bluetooth_EM_probe.png"></center>
</a></h3></center><br>

<h3>Abstract</h3>
<p><span> The <a href="https://store.google.com/product/titan_security_key" target="_blank" rel="noopener noreferrer"><i>Google Titan Security Key</i></a> is a FIDO U2F hardware device proposed by Google (available since July 2018) as a two-factor authentication token to sign in to applications (e.g. your Google account). Our work describes a side-channel attack that targets the <i>Google Titan Security Key</i>’s secure element (the NXP A700X chip) by the observation of its local electromagnetic radiations during ECDSA signatures (the core cryptographic operation of the FIDO U2F protocol). In other words, an attacker can create a clone of a legitimate <i>Google Titan Security Key</i>.</span></p>

<p><span> To understand the NXP ECDSA implementation, find a vulnerability and design a key-recovery attack, we had to make a quick stop on <i>Rhea</i> (NXP J3D081 JavaCard smartcard). Freely available on the web, this product looks very much like the NXP A700X chip and uses the same cryptographic library. <i>Rhea</i>, as an open JavaCard platform, gives us more control to study the ECDSA engine.</span></p>

<p><span> We could then show that the electromagnetic side-channel signal bears partial information about the ECDSA ephemeral key. The sensitive information is recovered with a non-supervised machine learning method and plugged into a customized lattice-based attack scheme.</span></p>

<p><span> Finally, 4000 ECDSA observations were enough to recover the (known) secret key on <i>Rhea</i> and validate our attack process. It was then applied on the <i>Google Titan Security Key</i> with success (this time by using 6000 observations) as we were able to extract the long term ECDSA private key linked to a FIDO U2F account created for the experiment.</span></p>

<h3>Cautionary Note</h3>
<p><span> Two-factor authentication tokens (like FIDO U2F hardware devices) primary goal is to fight phishing attacks. Our attack requires physical access to the <i>Google Titan Security Key</i>, expensive equipment, custom software, and technical skills.</span></p>

<p><span> <b>Thus, as far as our study goes, it is still safer to use your <i>Google Titan Security Key</i> or other impacted products as FIDO U2F two-factor authentication token to sign in to applications rather than not using one.</b></span></p>

<p><span> Nevertheless, this work shows that the <i>Google Titan Security Key</i> (and other impacted products) would not avoid unnoticed security breach by attackers willing to put enough effort into it. Users that face such a threat should probably switch to other FIDO U2F hardware security keys, where no vulnerability has yet been discovered.</span></p>

<h3>Discovered By</h3>
<p><span> Victor lomné (NinjaLab) and Thomas Roche (NinjaLab).<br>
with the help of Camille Mutschler (NinjaLab) and Dr. Laurent Imbert (LIRMM, CNRS).</span></p>

<h3>List of Impacted Products</h3>
<ul>
<li> Google Titan Security Key (all versions) </li>
<li> Yubico Yubikey Neo </li>
<li> Feitian FIDO NFC USB-A / K9 </li>
<li> Feitian MultiPass FIDO / K13 </li>
<li> Feitian ePass FIDO USB-C / K21 </li>
<li> Feitian FIDO NFC USB-C / K40 </li>
<li> NXP J3D081_M59_DF and variants </li>
<li> NXP J3A081 and variants </li>
<li> NXP J2E081_M64 and variants </li>
<li> NXP J3D145_M59 and variants </li>
<li> NXP J3D081_M59 and variants </li>
<li> NXP J3E145_M64 and variants </li>
<li> NXP J3E081_M64_DF and variants </li>
</ul>


<h3>Further Notes</h3>
<p><span>
1. The impacted Yubico Yubikey Neo is an old product no more available for sale. All FIDO U2F Yubico Yubikeys currently available on their webstore are based on a newer secure element from Infineon, and are not impacted by our work to our knowledge.
</span></p>
<p><span>
2. The NXP P5 / SmartMX secure microcontroller family and its associated cryptographic library (up to v2.9) impacted by our work is quite old. Since, NXP has released two new generations of secure microcontroller families, the “NXP P60 / SmartMX2” family and now the “NXP P70 / SmartMX3” family. Both are Common Criteria certified (with recent certification process), and are not impacted by our work to our knowledge.
</span></p>

<h3>CVE</h3>
<p><span> 
We assigned <a href="https://cve.mitre.org/cgi-bin/cvename.cgi?name=CVE-2021-3011" target="_blank" rel="noopener noreferrer">CVE-2021-3011</a>
</span></p>
	</div><!--/.blog-post-entry.markup-format-->
</article><!--/#post-747.blog-post-->
			</section><!--/#blog-->
		</div><!--/.col-sm-7-->
			</div><!--/.row-->
</div></div>]]>
            </description>
            <link>https://ninjalab.io/a-side-journey-to-titan/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25675556</guid>
            <pubDate>Thu, 07 Jan 2021 19:00:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Dissecting the Apple M1 GPU, part I]]>
            </title>
            <description>
<![CDATA[
Score 484 | Comments 106 (<a href="https://news.ycombinator.com/item?id=25673631">thread link</a>) | @caution
<br/>
January 7, 2021 | https://rosenzweig.io/blog/asahi-gpu-part-1.html | <a href="https://web.archive.org/web/*/https://rosenzweig.io/blog/asahi-gpu-part-1.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
<header><p>7 Jan 2021</p></header><p>Apple’s latest line of Macs includes their in-house “M1” system-on-chip, featuring a custom GPU. This poses a problem for those of us in the <a href="https://asahilinux.org/">Asahi Linux</a> project who wish to run Linux on our devices, as this custom Apple GPU has neither public documentation nor open source drivers. Some speculate it might descend from PowerVR GPUs, as used in older iPhones, while others believe the GPU to be completely custom. But rumours and speculations are no fun when we can peek under the hood ourselves!</p>
<p>A few weeks ago, I purchased a Mac Mini with an M1 GPU as a development target to study the instruction set and command stream, to understand the GPU’s architecture at a level not previously publicly understood, and ultimately to accelerate the development of a Mesa driver for the hardware. Today I’ve reached my first milestone: I now understand enough of the instruction set to disassemble simple shaders with a free and open-source tool chain, <a href="https://github.com/AsahiLinux/gpu">released on GitHub here</a>.</p>
<p>The process for decoding the instruction set and command stream of the GPU parallels the same process I used for reverse-engineering Mali GPUs in the Panfrost project, originally pioneered by the Lima, Freedreno, and Nouveau free software driver projects. Typically, for Linux or Android driver reverse-engineering, a small wrap library will be written to inject into a test application via <code>LD_PRELOAD</code> that hooks key system calls like <code>ioctl</code> and <code>mmap</code> in order to analyze user-kernel interactions. Once the “submit command buffer” call is issued, the library can dump all (mapped) shared memory for offline analysis.</p>
<p>The same overall process will work for the M1, but there are some macOSisms that need to be translated. First, there is no <code>LD_PRELOAD</code> on macOS; the equivalent is <code>DYLD_INSERT_LIBRARIES</code>, which has some extra security features which are easy enough to turn off for our purposes. Second, while the standard Linux/BSD system calls do exist on macOS, they are not used for graphics drivers. Instead, Apple’s own <code>IOKit</code> framework is used for both kernel and userspace drivers, with the critical entry point of <code>IOConnectCallMethod</code>, an analogue of <code>ioctl</code>. These differences are easy enough to paper over, but they do add a layer of distance from the standard Linux tooling.</p>
<p>The bigger issue is orienting ourselves in the IOKit world. Since Linux is under a copyleft license, (legal) kernel drivers are open source, so the <code>ioctl</code> interface is public, albeit vendor-specific. macOS’s kernel (XNU) being under a permissive license brings no such obligations; the kernel interface is proprietary and undocumented. Even after wrapping <code>IOConnectCallMethod</code>, it took some elbow grease to identify the three critical calls: memory allocation, command buffer creation, and command buffer submission. Wrapping the allocation and creation calls is essential for tracking GPU visible memory (what we are interested in studying), and wrapping the submission call is essential for timing the memory dump.</p>
<p>With those obstacles cleared, we can finally get to the shader binaries, black boxes in themselves. However, the process from here on out is standard: start with the simplest fragment or compute shader possible, make a small change in the input source code, and compare the output binaries. Iterating on this process is tedious but will quickly reveal key structures, including opcode numbers.</p>
<p>The findings of the process documented in the free software disassembler confirm a number of traits of the GPU:</p>
<p>One, this is a scalar architecture. Unlike some GPUs that are scalar for 32-bits but vectorized for 16-bits, the M1’s GPU is scalar at all bit sizes. Yet Metal optimization resources imply 16-bit arithmetic should be significantly faster, in addition to a reduction of register usage leading to higher thread count (occupancy). This suggests the hardware is superscalar, with more 16-bit ALUs than 32-bit ALUs, allowing the part to benefit from low-precision graphics shaders much more than competing chips can, while removing a great deal of complexity from the compiler.</p>
<p>Two, this seems to handle scheduling in hardware, common among desktop GPUs but less so in the embedded space. This again makes the compiler simpler at the expense of more hardware. Instructions seem to have minimal encoding overhead, unlike other architectures which need to pad out instructions with <em>nop</em>’s to accommodate highly constrained instruction sets.</p>
<p>Three, various modifiers are supported. Floating point ALUs can do clamps (saturate), negates, and absolute value modifiers “for free”, a common shader architecture trait. Further, most (all?) instructions can type-convert between 16-bit and 32-bit “for free” on both the destination and the sources, which allows the compiler to be much more aggressive about using 16-bit operations without risking conversion overheads. On the integer side, various bitwise complements and shifts are allowed on certain instructions for free. None of this is unique to Apple’s design, but it’s worth noting all the same.</p>
<p>Finally, not all ALU instructions have the same timing. Instructions like <code>imad</code>, used to multiply two integers and add a third, are avoided in favour of repeated <code>iadd</code> integer addition instructions where possible. This also suggests a superscalar architecture; software-scheduled designs like those I work on for my day job cannot exploit differences in pipeline length, inadvertently slowing down simple instructions to match the speed of complex ones.</p>
<p>From my prior experience working with GPUs, I continue to expect to find some eldritch horror waiting in the instruction set, to balloon compiler complexity. Though the above work currently covers only a small surface area of the instruction set, so far everything seems sound. There are no convoluted optimization tricks, but doing away with the trickery is creating a streamlined, efficient design that does one thing and does it well. Maybe Apple’s hardware engineers discovered it’s hard to beat simplicity.</p>
<p>Alas, a shader tool chain isn’t much use without an open-source userspace driver. Next up: dissecting the command stream!</p>
<p><em>Disclaimer: This work is a hobby project, conducted based on public information. Opinions expressed may not reflect those of my employer.</em></p>
<p><a href="https://rosenzweig.io/">Back to home</a></p>
</div>]]>
            </description>
            <link>https://rosenzweig.io/blog/asahi-gpu-part-1.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25673631</guid>
            <pubDate>Thu, 07 Jan 2021 17:01:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[My stack is HTML+CSS]]>
            </title>
            <description>
<![CDATA[
Score 211 | Comments 164 (<a href="https://news.ycombinator.com/item?id=25673495">thread link</a>) | @zdw
<br/>
January 7, 2021 | https://blog.steren.fr/2020/my-stack-will-outlive-yours/ | <a href="https://web.archive.org/web/*/https://blog.steren.fr/2020/my-stack-will-outlive-yours/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="main">
  <article>
	<header>
		
		<time date="2020-12-22">December 2020</time>
	</header>

		<p>
		My stack requires no maintenance, has perfect Lighthouse scores, will never have any security vulnerability, is based on open standards, is portable, has an instant dev loop, has no build step and… will outlive any other stack.
		</p>
		<p>
		It’s not LAMP, Wordpress, Rails, MEAN, Jamstack... I don’t do CSR (Client-side rendering), SSR (Server Side Rendering), SSG (Static Site Generation)...
		</p>
		<p>
		My stack is <b>HTML+CSS</b>.
		</p>
		<p>
		And because my sources are in git, pushed to GitHub, <a href="https://pages.github.com/">GitHub Pages</a> is my host.
		</p>
		<p>
		Of course, I’m being a bit provocative here. I should rather say that, for some specific use cases, I concluded that to get top performances and to guatantee long term support, HTML+CSS was the best choice, instead on relying on technologies currently more popular. Because I’m done rewriting my site every couple of years.
		</p>

		<h3>Why HTML+CSS?</h3>
		<p>
		It all started with <a href="https://labs.steren.fr/">a blog</a>, that I was hosting on Wordpress.com (which is "Wordpress-as-a-Service", because the last thing I want to do is administer a Wordpress installation on my own server). I <strong>paid</strong> Wordpress.com to do one job: host my blog. And one day I looked at its sources and Lighthouse scores:
		</p>
		<figure>
			<img src="https://blog.steren.fr/2020/my-stack-will-outlive-yours/wordpress-sources.png" alt="Sources of my Wordpress.com blog, showing a lot of inlined unreadable scripts">
			<figcaption>Sources of my Wordpress.com blog, what is all this?</figcaption>
		</figure>
		<figure>
			<img src="https://blog.steren.fr/2020/my-stack-will-outlive-yours/wordpress-lighthouse.png" alt="Lighthouse scores of my Wordpress.com blog, showing 19/100 for Performance">
			<figcaption>Lighthouse score of my blog hosted on Wordpress.com</figcaption>
		</figure>
		<p>
		What have we done?
		</p>
		<p>
		Sure, these are the problems of one specific blogging platform. I’m pretty sure others are better, at least in terms of performance. But isn’t there something fundamentally wrong if displaying a short text with images takes seconds, loads countless render-blocking scripts, and has unreadable sources?
		</p>
		<p>
		My requirements were:
		</p>
		<ol>
			<li>performance</li>
			<li>simplicity</li>
			<li>long long term support</li>
		</ol>
		<p>
		It was time to say goodbye to Wordpress. I didn’t need 99% of its features anyway. Other blogging platforms didn’t meet expectations either (I seriously have no idea why so many people publish on Medium… behind a login wall). I looked at static site generators like Jekyll, Hugo, 11ty, but all of these require tooling installed, have a build step and will ultimately need some updates or be abandonned by their maintainer. What if we also get rid of these?
		</p>
		<p>
		The best tool is no tool, the best build step is no build step, the best update is no update. HTML gives us all that, and more.
		</p>

		<figure>
			<img src="https://blog.steren.fr/2020/my-stack-will-outlive-yours/lighthouse-score-pure-html-css.svg" alt="Lighthouse score of 100">
			<figcaption>Lighthouse score of this page</figcaption>
		</figure>

		<h3>What is the HTML+CSS stack good for?</h3>
		<p>
		Let’s first differentiate between what I call a web <em>page</em> and a web <em>app</em>: The goal of a web <em>page</em> is to serve content, on the other hand, the goal of a web <em>app</em> is to enable the user to perform interactive tasks. Of course, there are in-betweens, often in the form of content that might need customization depending on the logged in user and content that might allow some interactions.
		</p>
		<p>
		HTML+CSS fits the web <em>page</em> use case. Wow, what a revelation! It might seem obvious, but it seems we’ve all forgotten this these days. HTML+CSS does not fit the web <em>app </em>use case, or any in between.
		</p>
		<p>
		We said a web <em>page</em> serves content, but let’s dive into more concrete use cases:
		</p>
		<ul>
			<li>Product / Company / Business landing page and marketing sites</li>
			<li>Personal portfolio / bio</li>
			<li>Blog</li>
			<li>Documentation</li>
		</ul>

		<h3>How to develop for HTML+CSS?</h3>
		<p>
		Authoring a pure HTML+CSS site can be done in any text editor, in any environment (any desktop OS, any smartphone, or even directly using GitHub’s single file editor) and previewed by simply opening the file in any browser.
		</p>
		<p>
		Keep the HTML of every page minimal and semantic. First, because there is no need for countless of &lt;div&gt;, but then because it makes sources more readable and easier to edit. See for example the <a href="https://github.com/steren/blog/blob/master/2020/my-stack-will-outlive-yours/index.html">HTML sources of this page</a>: a total of 150 lines, 100 lines are for the content, the rest is metadata and page structure, nothing extra. 
		</p>
		<p>
		For consistency, all pages that need to share the same style can point to the same CSS file. This avoids  duplication when it comes to styling (but note that loading this file creates an extra HTTP request, which could be avoided if style was inlined).
		</p>
		<p>
		When not cluttered with unnecessary scripts, divs or classes, I have no issue writing HTML directly. Yes, the paragraph tags are a bit annoying and distracting, but proper indentation and syntax highlighting mitigate this.
		<br>
		Sometimes, for drafting long blog articles, I’m working in Google Docs, and when I’m happy, export the content to clean HTML using an add-on. Google Docs is awesome for collaboration, with powerful suggestions and commenting system. That’s ideal for the “draft” phase. 
		<br>
		Because all content is in git, final review and approval can be done via GitHub pull requests.
		</p>
		<p>
		When I publish a new page, I need to link to it manually from the index page. I’m OK with that. It’s done in one line. It also allows me to have more control over when I want the page to be “published”.
		</p>
		<p>
		I don't need to pay for custom themes, I have complete freedom in the style and layout of my site.
		I can embed anything I want without being restricted by the choice of the hosting platform: SVG images, 3D models, interactive JS experiences. 
		</p>
		<p>
		Creating a new page requires to clone an existing one.
		So... if I don’t use any templating system, how do I update my header, footer or nav? Well, simply by using the ”Replace in files” feature of any good text editor. They don’t need frequent updates anyway. The benefits of using a templating system is not worth the cost of introducing the tooling it requires.
		</p>
		
		<h3>In conclusion</h3>
		<p>
		You don’t need  Wordpress, or Hugo to put a blog online, or Angular, React or Next.js to put a web page online. Raw HTML and CSS do the job.
		</p>
		<p>
		That being said, you’ll need to pick up some tooling or framework if you want to build a web app or add more interactivity or customization to your web pages. And for that, I’m very glad to see that frameworks now seem to be prioritizing performance, notably by prioritizing serving the content first and leveraging caching whenever possible. The era of “download 5MB of JS first and then download content from a REST API” seems to be over for content web pages. (I personally think it’s still OK to do so for web apps, as the user’s intent and expectations are different).
		</p>
		<p>
		Is the “HTML+CSS only” approach a bit extreme? A bit, it’s basically saying “all software is terrible, how can I minimize my dependencies on software”. Web standards are a model of backward compatibility. I’m pretty confident that my web pages written in raw HTML+CSS will have no issue being accessed and authored 10 years from now, without me having to do anything.
		</p>  
	</article>
</div></div>]]>
            </description>
            <link>https://blog.steren.fr/2020/my-stack-will-outlive-yours/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25673495</guid>
            <pubDate>Thu, 07 Jan 2021 16:54:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[No meetings, no deadlines, no full-time employees]]>
            </title>
            <description>
<![CDATA[
Score 1176 | Comments 401 (<a href="https://news.ycombinator.com/item?id=25673275">thread link</a>) | @sahillavingia
<br/>
January 7, 2021 | https://sahillavingia.com/work | <a href="https://web.archive.org/web/*/https://sahillavingia.com/work">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><label>Jan 7, 2021 • 10 min read</label><h2>No Meetings, No Deadlines, No Full-Time Employees</h2><p>I started Gumroad in 2011. In 2015, we reached a peak of 23 full-time employees. In 2016, after <a href="https://sahillavingia.com/reflecting">failing</a> to raise more money, I ended up back where I began: a one-person company.</p><p>Today, when I’m asked how many people work at Gumroad, I respond with “ten or so.” That’s how I convert the number of people we have into what others expect. But the truth is more complicated:</p><p>If we include everyone who works on Gumroad, it’s 25.</p><p>If we include full-time employees, it’s none. Not even me.</p><p>We have no meetings, and no deadlines either.</p><p>And it’s working: our creators earn over $175 million a year, and we generate $11 million in annualized revenue, growing 85% year-over-year.</p><p><img src="https://sahillavingia.com/2020-earnings.png"></p><p>That said, I don’t expect anyone to copy our way of working wholesale. We got here on accident, not some grand plan.</p><p>However, I do think there are pieces of our story and the way we work that could benefit other companies, their people, and–most importantly–their customers.</p><h2>Freedom at all costs</h2><p>After the layoffs in 2015, even though the team shrunk, Gumroad itself continued to grow.</p><p><img src="https://sahillavingia.com/2018-earnings.png"></p><p>But hiring people full-time and leasing a new office in San Francisco to work out of was untenable. Instead, I found an Indian firm called <a href="https://bigbinary.com/">BigBinary</a> and hired a few engineers as contractors.</p><p>These contractors saved the company. They fixed bugs and maintained the site while I answered support tickets, designed features, and wrote about new initatives.</p><p>Eventually, I hired back the same customer support person we had from before the layoffs, this time via an hourly contracting agreement too.</p><p>Meanwhile, I <a href="https://sahillavingia.com/bubble">moved to Utah</a> and attempted to become a full-time creator.</p><p>While Gumroad was no longer on track to become a billion-dollar company, I acquired a new asset: time. I used that time to take classes on writing and painting.</p><p>Because I was burned out and didn’t want to think about working any more than I needed to, I instituted a no-meeting, no-deadline culture.</p><p>For me, it was no longer about growth at all costs, but “freedom at all costs.”</p><p>This way, Gumroad stayed profitable, I could take a much-needed break to explore my hobbies, and the product continued to improve over time.</p><p><img src="https://sahillavingia.com/operating.png"></p><h2>How we work</h2><p>Today, working at Gumroad resembles working on an open source project like Rails. Except it’s neither open source, nor unpaid.</p><p>Instead of having meetings, people “talk” to each other via GitHub, Notion, and (occasionally) Slack, expecting responses within 24 hours. Because there are no standups or “syncs” and some projects can involve expensive feedback loops to collaborate, working this way requires clear and thoughtful communication.</p><p>Everyone writes well, and writes <em>a lot</em>.</p><p>There are no deadlines either. We ship incrementally, and launch things whenever the stuff in development is better than what’s currently in production. The occasional exception does exist, such as a tax deadline, but as a rule, I try not to tell anyone what to do or how fast to do it. When someone new joins the company, they do what everyone else does: go into our Notion queue, pick a task, and get to work, asking for clarification when needed.</p><p>Instead of setting quarterly goals or using OKRs, we move towards a single north star: maximizing how much money creators earn. It’s simple and measurable, allowing anyone in the company to do the math on how much a feature or bug-fix might be worth.</p><p>But we don’t prioritize ruthlessly.</p><p>People can work on what’s fun or rely on their intuition, because as long as we remain profitable and keep shipping, we tend to get to the important stuff eventually. Our <a href="https://www.notion.so/gumroad/Roadmap-ce2ad07c483046e7941227ad7810730d">public roadmap</a> helps Gumroad's creators hold us accountable.</p><p>We ship big things this way too.</p><p>In November 2020, we shipped <a href="https://gumroad.com/gumroad/p/introducing-gumroad-memberships">Gumroad Memberships</a>, a year in the works and now used by hundreds of creators to earn over $1,500,000 per month.</p><p>This is a screenshot from our roadmap to show what it looks like in practice:</p><p><img src="https://sahillavingia.com/memberships-roadmap.png"></p><p>For more, I recorded <a href="https://www.youtube.com/watch?v=2PcIC1DKBU0">an hour-long video</a> about how we ship something as large as Gumroad Memberships.</p><p>Gumroad engineer Helen Hood, who shipped Memberships, says, “it’s one of the biggest product launches of my career, and we shipped it without a single meeting or video call. I've worked at your typical startup, with an open floor plan, lots of whiteboards, standups and sprint planning, beers after work. I’ve also worked on a remote team with little communication and engineers largely siloed on their own projects. The way we work at Gumroad is ideal for me. It lets me maximize my productive hours, and clock out when I've hit my limit.”</p><p>Those are the broad strokes, but we’ve published more specific documentation about the way we work:</p><ul><li><a href="https://www.notion.so/gumroad/How-do-we-decide-what-to-work-on-f2064b8ab16c4cbcac1077e16c8cf33b">How do we decide what to work on?</a><p>“At the end of the day there's a lot of emotion that goes into Gumroad, that's not dissimilar from an art project. We sometimes pick what's fun and feels good to work on! We love listening to creators! We don't do tons of data analysis to decide what's worth working on.”</p></li><li><a href="https://www.notion.so/gumroad/How-do-we-communicate-06f2032bfdae4552a38149c99c68e3df">How do we communicate?</a><p>“Turn off all notifications from your phone!”</p></li><li><a href="https://www.notion.so/gumroad/What-does-working-at-Gumroad-feel-like-7d9fd1c9548245a58afe5569d76a7960">What does working at Gumroad feel like?</a><p>“We ship incrementally, iteratively, and have one massive tentpole launch a year. Every month we see how much creators got paid, then we move on. The journey is the fun part, we're not waiting to arrive at some destination.”</p></li><li><a href="https://www.notion.so/gumroad/What-s-not-so-good-at-Gumroad-847e3c285b1f45ab955ebacf52867900">What’s not so good at Gumroad?</a><p>“There's not a lot of room for growth. We're staying profitable, and not planning to double the team every year. While there will likely be a few leadership roles, there aren't plenty of them and they aren't built into the career path of working at Gumroad.”</p></li></ul><p>Gumroad’s Chris Maximin says, “this way to work is responsible for the highest level of productivity I've ever experienced. The ability to focus on actual work creates a virtuous circle benefiting both the company and the workers: 1) the company does not have to pay expensive engineers to sit around in endless, useless meetings, and 2) the engineers get to do more and learn more, which benefits them in the long term.”</p><p>This isn’t just for engineers.</p><p>Justin Mikolay, a writer at Gumroad, ships each of our <a href="https://gumroad.com/l/BCMDz">Creator Spotlights</a> this way, even though each one requires at least three people–plus the creator.</p><p><em>Everything</em> is handled this way: support, risk, content, growth, product prioritization, board decks, design feedback, and more.</p><h2>Minimum viable culture</h2><p>This way of working isn’t for everyone.</p><p>There are no retreats planned, and no social channels in Slack. There are limited opportunities for growth. And we can’t compete with the comp packages that big tech companies can provide.</p><p>But we can compete–and win–on flexibility.</p><p><a href="https://twitter.com/sidyadav">Sid Yadav</a>, former VP of Product at Teachable, joined Gumroad in 2018.</p><p>In his words, “most entrepreneurs have two options: work a full-time job and hustle nights/weekends, or leave your job and risk everything to start the company. Gumroad provided a third way: I could contract 20-35 hours a week, and for a couple days a week, incubate ideas and work on my next thing.”</p><p>In 2020, Sid left Gumroad to start his own creator economy company, <a href="https://circle.so/">Circle</a>, together with former Gumroad coworker <a href="https://community.circle.so/u/45ef416b">Rudy Santino</a>:</p><blockquote><p lang="en" dir="ltr">I’m starting a new company: <a href="https://t.co/BW40WmGBlF">https://t.co/BW40WmGBlF</a>! I’ll be sharing more about it in the coming weeks, but today I wanted to show gratitude to the life situation that made this possible: contracting for a flexible remote startup — <a href="https://twitter.com/gumroad?ref_src=twsrc%5Etfw">@gumroad</a>. It wouldn’t have happened without it.</p>— Sid Yadav (@sidyadav) <a href="https://twitter.com/sidyadav/status/1216761573479473152?ref_src=twsrc%5Etfw">January 13, 2020</a></blockquote> <p>Working on Gumroad isn't a majority of anyone's identity.</p><p>People work at Gumroad as little as they need to sustain the other parts of their lives they prefer to spend their time and energy on: a creative side-hustle, their family, or anything else.</p><p>Gumroad engineer Nathan Chan says, “I produce more value for my time than at any other company in my career, and I’m able to fully participate in parenting and watching my kiddo grow up.”</p><p>That includes me.</p><p>From 2011 to 2016, building Gumroad was my singular focus in life. But today, it is just a part of my life, like a hobby might be. For example, I paint for fun, and every once in a while, I sell a painting.</p><h2>A company of creators</h2><p>One day, out of the blue, I received an email from <a href="https://twitter.com/dvassallo">Daniel Vassallo</a>. I knew Daniel; he was a creator who had made over $250,000 on Gumroad in less than a year.</p><p>He was already using the product–so he understood what problems Gumroad ought to solve next–and he had some ideas for how he could help out:</p><blockquote>I love Gumroad (and I’m living off it!), I enjoy product scoping and strategy, and I think I can take over your PM tasks. I would only be able to dedicate around 2hrs/day on average, but I’d be available daily. Don’t know if this is the type of commitment you had in mind, but I figured if there’s a place where this arrangement can work, it’s Gumroad :)</blockquote><p>It was a perfect fit. Daniel became our new Head of Product.</p><p>It can be a great deal for Gumroad too. Before Daniel quit his job at Amazon, he was making over $400,000 a year. We pay him $120,000 a year.</p><p>How? He works ten hours a week for us. In his words:</p><blockquote><p lang="en" dir="ltr">Almost nobody is seeing this trend as an opportunity to work less, rather than to earn more. <a href="https://t.co/U9YBqp1ebn">https://t.co/U9YBqp1ebn</a></p>— Daniel Vassallo (@dvassallo) <a href="https://twitter.com/dvassallo/status/1334288446697865216?ref_src=twsrc%5Etfw">December 3, 2020</a></blockquote> <h2>Getting paid</h2><p>In practice, we pay everyone hourly based on their role. The range varies from $50 (customer support) to $250 (Head of Product) an hour.</p><p>Recently I standardized our rates world-wide:</p><blockquote><p lang="en" dir="ltr">🌍🌎🌏 Excited to announce we've deprecated all location-based pay! Gumroad will now pay you the same salary, no matter if you live in San Francisco, Bangalore, Lagos, or anywhere else.</p>— Sahil (@shl) <a href="https://twitter.com/shl/status/1334201934702493697?ref_src=twsrc%5Etfw">December 2, 2020</a></blockquote> <p>This rate is agreed upon during our interview process:</p><ol><li>Apply via a form.</li><li>An unpaid, few-hour challenge, that resembles the high-level work we do at Gumroad. This may include breaking down a large shipment (like Gumroad Memberships) into its atomic parts, planning the schema associated with a new feature, or writing up a Help Center article.</li><li>A paid, few-week trial period, that resembles the day-to-day work we do at Gumroad. This may …</li></ol></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://sahillavingia.com/work">https://sahillavingia.com/work</a></em></p>]]>
            </description>
            <link>https://sahillavingia.com/work</link>
            <guid isPermaLink="false">hacker-news-small-sites-25673275</guid>
            <pubDate>Thu, 07 Jan 2021 16:41:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: I built an intercom for my 6 yo to keep us connected during quarantine]]>
            </title>
            <description>
<![CDATA[
Score 169 | Comments 119 (<a href="https://news.ycombinator.com/item?id=25671919">thread link</a>) | @daylankifky
<br/>
January 7, 2021 | https://chordata.cc/blog/open-source-intercom-for-kids/ | <a href="https://web.archive.org/web/*/https://chordata.cc/blog/open-source-intercom-for-kids/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
			<!-- .entry-container -->

			<div>
				
<pre><em>Today we’ll take a turn and showcase a personal project developed by our Tech Lead, Bruno, who took the multiple hours of lockdown we experienced last year and turned them into an initiative that allowed him to communicate with his 6 year old daughter. Below you’ll be able to review his experience and gather all of the details of his project (in case you want to replicate his system).</em></pre>



<p>In terms of social interactions, 2020 was an odd year, with cyclic lockdowns and openings. <strong>Keeping in touch with our close ones was one of the main challenges for all of us</strong>. The lockdowns are a bizarre experience in itself, but one of the strangest parts for me was when I topped it all up with a fever. It ended up being just a regular flu in the end, but for precaution my doctor ordered me to lock me down in a room for two weeks. Being there just a few meters away from my family and not being able to hug them or have a direct conversation was <strong>hard for all of us, but especially for my six-year-old daughter who wasn’t able to wrap her head around the reasons we couldn’t just see each other.</strong></p>



<p>So this time I decided to build something for her to keep us in touch in case something similar happens. The basic concept is a <strong>simplified interface for a Telegram voice chat with only a few (big) buttons: it should allow to easily and intuitively send and receive voice messages</strong>. Of course having a raspberry-pi as the core of this device was a no-brainer, since It has everything that’s needed for the project: WiFi connectivity, low level interface to control leds and buttons, and of course a complete OS where to run a Python interpreter to control everything.</p>



<div><figure><img src="https://chordata.cc/wp-content/uploads/2021/01/daddy_box_blueprint-300x217.jpg" alt="" width="538" height="389" srcset="https://chordata.cc/wp-content/uploads/2021/01/daddy_box_blueprint-300x217.jpg 300w, https://chordata.cc/wp-content/uploads/2021/01/daddy_box_blueprint-1024x739.jpg 1024w, https://chordata.cc/wp-content/uploads/2021/01/daddy_box_blueprint-768x555.jpg 768w, https://chordata.cc/wp-content/uploads/2021/01/daddy_box_blueprint-640x462.jpg 640w, https://chordata.cc/wp-content/uploads/2021/01/daddy_box_blueprint-100x72.jpg 100w, https://chordata.cc/wp-content/uploads/2021/01/daddy_box_blueprint.jpg 1108w" sizes="(max-width: 538px) 100vw, 538px"></figure></div>



<h3>TUI</h3>



<p>A good idea when dealing with electronic projects is to <strong>start small and have a proof of concept working before getting all the components</strong> and wire the whole thing together. In this case I started by creating the main program but replacing the physical button interface with a <em>TUI</em> (terminal user interface). The code can be found <a href="https://gitlab.com/daylanKifky/daddy-box-python-module" target="_blank" rel="noreferrer noopener">in this repository</a>, you should be able to test it by running it using the <code>--tui</code> flag like this:</p>



<pre>python -m daddy_box --tui</pre>



<div><figure><img src="https://chordata.cc/wp-content/uploads/2021/01/daddy_box_tui.jpg" alt="" srcset="https://chordata.cc/wp-content/uploads/2021/01/daddy_box_tui.jpg 575w, https://chordata.cc/wp-content/uploads/2021/01/daddy_box_tui-300x242.jpg 300w, https://chordata.cc/wp-content/uploads/2021/01/daddy_box_tui-100x81.jpg 100w" sizes="(max-width: 575px) 100vw, 575px"></figure></div>



<h3>Telegram bot setup</h3>



<p>The first time you run it you will need to give it a telegram bot key. Follow <a href="https://core.telegram.org/bots#3-how-do-i-create-a-bot" target="_blank" rel="noreferrer noopener">this steps</a> to create your instance of a Bot, and then run it with the <code>--setup-bot</code> flag and input the information the <em>BotFather</em> gave you.</p>



<p>You should now be able to search for the bot’s username in telegram and exchange some messages with it. You will first find that you get “not allowed” responses. The <strong>idea behind this bot is to exchange messages privately with just one user</strong>, so you have to tell the bot which is the allowed user id to interact with.</p>



<p>Take a look at the terminal where the bot is running, you will see some printed messages like this one:</p>



<div><figure><img src="https://chordata.cc/wp-content/uploads/2021/01/daddy_box_user_id.png" alt="" srcset="https://chordata.cc/wp-content/uploads/2021/01/daddy_box_user_id.png 571w, https://chordata.cc/wp-content/uploads/2021/01/daddy_box_user_id-300x66.png 300w, https://chordata.cc/wp-content/uploads/2021/01/daddy_box_user_id-100x22.png 100w" sizes="(max-width: 571px) 100vw, 571px"></figure></div>



<p>Copy your user-id from there and give it to the bot using the <code>--setup-user</code> flag.  You should now be able to send and receive voice messages, so we are ready to start with the physical part of the project.</p>







<h3>Raspberry pi HAT</h3>



<p>When doing a one-shot project like this I normally use breadboards or perfboards to assemble all the components. I used that approach a bunch of times in the past to handle a few backlitghted buttons, and the process was always frustrating: I ended up spending lots of time with the soldering and wiring of the components. So this time I decided to actually do what I promised myself each one of those times: design a <strong>breakout HAT for the raspberry with screw terminals where to easily connect everything.</strong></p>



<p>Since I was at it I added a darlington array and a number of selectable power sources in order to potentially handle bigger loads. I designed it in Kicad and then ordered a few PCBs. You can find the project files <a href="https://gitlab.com/daylanKifky/daddy-box-raspberry-pi-hat" target="_blank" rel="noreferrer noopener">here</a>.</p>



<div><figure><img src="https://chordata.cc/wp-content/uploads/2021/01/daddy_box_HAT-1024x681.jpg" alt="" width="583" height="388" srcset="https://chordata.cc/wp-content/uploads/2021/01/daddy_box_HAT-1024x681.jpg 1024w, https://chordata.cc/wp-content/uploads/2021/01/daddy_box_HAT-300x199.jpg 300w, https://chordata.cc/wp-content/uploads/2021/01/daddy_box_HAT-768x511.jpg 768w, https://chordata.cc/wp-content/uploads/2021/01/daddy_box_HAT-640x425.jpg 640w, https://chordata.cc/wp-content/uploads/2021/01/daddy_box_HAT-100x66.jpg 100w, https://chordata.cc/wp-content/uploads/2021/01/daddy_box_HAT.jpg 1053w" sizes="(max-width: 583px) 100vw, 583px"></figure></div>



<h3>Audio</h3>



<p>One little detail I wasn’t taking into consideration when I started the project was the fact that a <strong>raspberry pi doesn’t have an audio input</strong>.<strong> So I had to buy an USB microphone.</strong> A cheap one from a local store did the trick. I removed all the plastic parts and shortened the cable to avoid unnecessary EM interference.</p>



<div><figure><img src="https://chordata.cc/wp-content/uploads/2021/01/daddy_box_mic.jpg" alt="" width="322" height="443" srcset="https://chordata.cc/wp-content/uploads/2021/01/daddy_box_mic.jpg 581w, https://chordata.cc/wp-content/uploads/2021/01/daddy_box_mic-218x300.jpg 218w, https://chordata.cc/wp-content/uploads/2021/01/daddy_box_mic-349x480.jpg 349w, https://chordata.cc/wp-content/uploads/2021/01/daddy_box_mic-73x100.jpg 73w" sizes="(max-width: 322px) 100vw, 322px"></figure></div>



<p>Before using it I also tried a small USB audio card but I had a lot of conflicts being raised by <a rel="noreferrer noopener" href="http://people.csail.mit.edu/hubert/pyaudio/" target="_blank">pyaudio,</a> the library I used to handle the recording and playing of audio files in python.</p>



<p>For the audio output I connected a small speaker directly to the RPi audio output jack. The volume is a little low, but it gets the work done.</p>



<h3>Final assembly</h3>



<p>Once the PCBs and all the components arrived it was time to replace the <em>TUI</em> with a Button UI. I used the handy <a href="https://gpiozero.readthedocs.io/en/stable/" target="_blank" rel="noreferrer noopener">gpiozero</a> library to handle button press and leds. For the external case I used a shoe box to which I made holes for the buttons and speaker.</p>



<div>
<div>
<figure><img src="https://chordata.cc/wp-content/uploads/2021/01/daddy_box_assembly1-1024x576.jpg" alt="" srcset="https://chordata.cc/wp-content/uploads/2021/01/daddy_box_assembly1-1024x576.jpg 1024w, https://chordata.cc/wp-content/uploads/2021/01/daddy_box_assembly1-300x169.jpg 300w, https://chordata.cc/wp-content/uploads/2021/01/daddy_box_assembly1-768x432.jpg 768w, https://chordata.cc/wp-content/uploads/2021/01/daddy_box_assembly1-640x360.jpg 640w, https://chordata.cc/wp-content/uploads/2021/01/daddy_box_assembly1-100x56.jpg 100w, https://chordata.cc/wp-content/uploads/2021/01/daddy_box_assembly1.jpg 1422w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>




</div>



<div>
<figure><img src="https://chordata.cc/wp-content/uploads/2021/01/daddy_box_assembly2-1024x576.jpg" alt="" srcset="https://chordata.cc/wp-content/uploads/2021/01/daddy_box_assembly2-1024x576.jpg 1024w, https://chordata.cc/wp-content/uploads/2021/01/daddy_box_assembly2-300x169.jpg 300w, https://chordata.cc/wp-content/uploads/2021/01/daddy_box_assembly2-768x432.jpg 768w, https://chordata.cc/wp-content/uploads/2021/01/daddy_box_assembly2-640x360.jpg 640w, https://chordata.cc/wp-content/uploads/2021/01/daddy_box_assembly2-100x56.jpg 100w, https://chordata.cc/wp-content/uploads/2021/01/daddy_box_assembly2.jpg 1422w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>
</div>
</div>



<div><figure><img src="https://chordata.cc/wp-content/uploads/2021/01/daddy_box_assembly3-1024x576.jpg" alt="" width="493" height="277" srcset="https://chordata.cc/wp-content/uploads/2021/01/daddy_box_assembly3-1024x576.jpg 1024w, https://chordata.cc/wp-content/uploads/2021/01/daddy_box_assembly3-300x169.jpg 300w, https://chordata.cc/wp-content/uploads/2021/01/daddy_box_assembly3-768x432.jpg 768w, https://chordata.cc/wp-content/uploads/2021/01/daddy_box_assembly3-640x360.jpg 640w, https://chordata.cc/wp-content/uploads/2021/01/daddy_box_assembly3-100x56.jpg 100w, https://chordata.cc/wp-content/uploads/2021/01/daddy_box_assembly3.jpg 1422w" sizes="(max-width: 493px) 100vw, 493px"></figure></div>



<p>Once everything was set and tested I disassembled and packed all the components inside the box, wrapped the whole thing as a gift to prepare it for the best part.</p>



<h3>XMAS</h3>



<p>I gave the box as a present to my daughter to be opened on Christmas eve without telling her what the purpose of all those parts were. <strong>The next morning we spent a couple of hours putting it all together, so she discovered the purpose of the device, its final shape and got a glimpse of the internal functionality during the process.</strong></p>



<div><figure><img src="https://chordata.cc/wp-content/uploads/2021/01/daddy_box_assemblykid-1024x576.jpg" alt="" width="510" height="286" srcset="https://chordata.cc/wp-content/uploads/2021/01/daddy_box_assemblykid-1024x576.jpg 1024w, https://chordata.cc/wp-content/uploads/2021/01/daddy_box_assemblykid-300x169.jpg 300w, https://chordata.cc/wp-content/uploads/2021/01/daddy_box_assemblykid-768x432.jpg 768w, https://chordata.cc/wp-content/uploads/2021/01/daddy_box_assemblykid-640x360.jpg 640w, https://chordata.cc/wp-content/uploads/2021/01/daddy_box_assemblykid-100x56.jpg 100w, https://chordata.cc/wp-content/uploads/2021/01/daddy_box_assemblykid.jpg 1422w" sizes="(max-width: 510px) 100vw, 510px"></figure></div>



<p>When it was done my kid liked it way more than I could ever expect. What I conceived as an utilitary tool to keep us connected when I wasn’t close soon became a part of a game of exchanging messages about every little action in the everyday routine, even when we are just a few meters away 😅.&nbsp;</p>



<p>So I’m quite happy with the result. Not only did this object help strengthen our relationship, it ended up being a <strong>cool way to transmit the hacker-maker values and habits to a young mind.</strong></p>



<p>I hope some of you find this useful and if you try to build this at home I would love to know how it went for you, please share your experience in <a href="https://forum.chordata.cc/">our forum</a> using the <em>offtopic</em> tag.</p>



<p>And above all, have a great starting of the year!</p>



<figure><img src="https://chordata.cc/wp-content/uploads/2021/01/daddy_box_final-1024x576.jpg" alt="" srcset="https://chordata.cc/wp-content/uploads/2021/01/daddy_box_final-1024x576.jpg 1024w, https://chordata.cc/wp-content/uploads/2021/01/daddy_box_final-300x169.jpg 300w, https://chordata.cc/wp-content/uploads/2021/01/daddy_box_final-768x432.jpg 768w, https://chordata.cc/wp-content/uploads/2021/01/daddy_box_final-640x360.jpg 640w, https://chordata.cc/wp-content/uploads/2021/01/daddy_box_final-100x56.jpg 100w, https://chordata.cc/wp-content/uploads/2021/01/daddy_box_final.jpg 1422w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>
			</div><!-- .entry-content -->

			
		</div></div>]]>
            </description>
            <link>https://chordata.cc/blog/open-source-intercom-for-kids/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25671919</guid>
            <pubDate>Thu, 07 Jan 2021 15:11:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[German Foreign Minister: Those Who Incite Bear Responsibility]]>
            </title>
            <description>
<![CDATA[
Score 67 | Comments 5 (<a href="https://news.ycombinator.com/item?id=25671401">thread link</a>) | @dakna
<br/>
January 7, 2021 | https://www.spiegel.de/international/world/german-foreign-minister-heiko-maas-those-who-incite-bear-responsibility-a-9e808002-67ee-4175-93b0-a01bf8e6dde2 | <a href="https://web.archive.org/web/*/https://www.spiegel.de/international/world/german-foreign-minister-heiko-maas-those-who-incite-bear-responsibility-a-9e808002-67ee-4175-93b0-a01bf8e6dde2">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>The images of the storming of the Capitol Building in Washington, D.C., are painful to the soul of every friend of democracy. The democratic world is shocked and appalled. But that’s not enough. We need all democrats around the world to stand shoulder to shoulder. The struggle against narrow-minded delusion, against intolerance, against the division of our societies is our common struggle. Indeed, it would be self-righteous to point the finger solely at America right now. Here in Germany, too, in <a target="_blank" rel="noopener noreferrer" href="https://www.spiegel.de/international/germany/when-far-right-hatred-turns-into-terrorism-a-e58ac378-bc7c-442e-a024-c801296d2b9c" data-link-flag="english">Hanau</a>, <a target="_blank" rel="noopener noreferrer" href="https://www.spiegel.de/international/germany/far-right-terrorism-in-germany-shooting-exposes-lapses-in-security-apparatus-a-1291075.html" data-link-flag="english">Halle </a>and on the steps of Reichstag (in coronavirus protests last summer), we have seen how agitation and inflammatory words can spark hateful deeds.</p><div>
<p>This should be extremely clear: Those who, like Trump, have spent years using words to constantly inflame and incite their own supporters, ultimately bear responsibility for this attack on the heart of American democracy. We see all around the world what happens when radical populists come to power and systematically stir up resentment against democratic institutions. Yes, democracy thrives on contradiction, even disagreement. But it dies when brute force silences the other, when sheer hatred breaks all bounds of decency and respect.</p><p>The radical mob does not represent the majority in the United States. The vast majority of American voters stand firmly behind democracy and voted decisively against a right-wing populist. And it’s not just Donald Trump who needs to finally accept that. Every Republican with a modicum of responsibility needs to finally repudiate Trump once and for all. The American courts have ruled clearly that this was a lawful election. Those who disrespect that election result are disrespecting their own people.</p>
</div><div>
<p>America’s strength is its diversity. It is admired around the world for the freedom of its democracy. U.S. president-elect Joe Biden knows this. His call yesterday for mutual respect and reconciliation were the soothing words of a president. And the confirmation of the election of Joe Biden and Kamala Harris by the U.S. Congress was the best democratic response to those who sowed chaos and discord in Washington yesterday.</p><p>As friends of America and as friends of democracy, we wish Joe Biden and Kamala Harris great strength in the difficult task of overcoming America’s division. We stand together with them in the fight for democracy. In keeping with the quintessential American motto: "E pluribus unum" – out of many, one.</p>
<p><span><svg aria-labelledby="title-96c1fa78-0685-4f94-b192-d76eb79d3cf9" width="10" height="20" viewBox="0 0 10 20" fill="none" xmlns="http://www.w3.org/2000/svg" role="img"><title id="title-96c1fa78-0685-4f94-b192-d76eb79d3cf9">Icon: Der Spiegel</title><g id="l-s-flag-96c1fa78-0685-4f94-b192-d76eb79d3cf9"><path id="vector-96c1fa78-0685-4f94-b192-d76eb79d3cf9" d="M9.85 16.293v-8H3.212V4.667h3.533v2.24h3.212v-3.2C9.85 2.747 8.993 2 8.03 2H1.713C.749 2 0 2.747 0 3.707v7.253h6.638v4.373H3.105v-2.986H0v3.84c0 .96.75 1.706 1.713 1.706H8.03c.963.107 1.82-.64 1.82-1.6z" fill="#000"></path></g></svg>
</span>
</p></div></div>]]>
            </description>
            <link>https://www.spiegel.de/international/world/german-foreign-minister-heiko-maas-those-who-incite-bear-responsibility-a-9e808002-67ee-4175-93b0-a01bf8e6dde2</link>
            <guid isPermaLink="false">hacker-news-small-sites-25671401</guid>
            <pubDate>Thu, 07 Jan 2021 14:30:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[MakAir: Covid-19 ventilator with a Raspberry Pi]]>
            </title>
            <description>
<![CDATA[
Score 92 | Comments 61 (<a href="https://news.ycombinator.com/item?id=25670303">thread link</a>) | @mtmail
<br/>
January 7, 2021 | https://blog.senx.io/makair-covid-19-ventilator-with-a-raspberry-pi/ | <a href="https://web.archive.org/web/*/https://blog.senx.io/makair-covid-19-ventilator-with-a-raspberry-pi/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>During the COVID-19 crisis, The birth of the first open source data enabled ventilator. </p><article>
      
<p>Back to March 20, 2020. <a href="https://twitter.com/waxzce" target="_blank" rel="noreferrer noopener">Quentin Adam</a>, with some friends living in Nantes, is trying to build a ventilator prototype with 3D printing and Arduino, in response to a shortage of equipment. </p>



<p><strong>Project MakAir is started</strong>. </p>



<p>Quentin, a software expert and CEO of <a href="https://www.clever-cloud.com/" target="_blank" rel="noreferrer noopener">Clever Cloud</a>, is struggling with the electronics part and looking for electronics engineers. Among his friends is Mathias, SenX CTO. That is how Mathias asked me to review the electronics part of the project. My first call with Quentin was to help him connect an old pressure sensor to an Arduino, during the late evening of March 20.</p>



<p><strong>The goal was clear: to mass-produce an open-source medical ventilator</strong>. Crazy! Looking at the project that day, it looked like an "amateur" project. So I did the first real schematics, the first BOM, the first Radiospares, and Farnell reference list during the weekend, discussing with more and more people on the MakAir Slack. </p>



<figure></figure>



<h3>Amateur? Not really...</h3>



<p>Next Thursday, I understood that the small "amateur" project is quickly getting big. Two electronics companies detached people, and a whole regulatory team was up. In this team, there were some experts in medical devices. We also knew that we were on a shortlist of projects that the French government is looking at closely.</p>



<p>I soon realized that in Nantes, there is no one able to actually make the prototypes. <a href="https://blog.senx.io/connecting-a-beertender-to-warp-10-using-mqtt-on-lorawan-with-thethingsnetwork/" target="_blank" rel="noreferrer noopener">Engineers with prototyping knowledge</a> are scarce, I just know a few of them like me. So, on the 25th during the evening, in a few minutes, I convinced Cherine, a former Renault Sport colleague living near Paris who has the same knowledge of prototyping as me, to join the project as well.</p>



<p><strong>On the 26th, I joined the MakAir core team, choosing to confine myself with 17 other people to make project MakAir a reality</strong>. Cherine came from Paris the same day I came from Brest. At the same time in France, 100 people were already helping us remotely. </p>



<p>I brought with me all my personal tools, from soldering iron to oscilloscope, and tons of components. </p>



<figure><blockquote><p>If I had been told this would last 25 days, I would have brought more than 3 days of clothing!</p></blockquote></figure>



<div><figure><img loading="lazy" src="https://blog.senx.io/wp-content/uploads/2020/09/DSC_6328-1024x682.jpg" data-src="https://blog.senx.io/wp-content/uploads/2020/09/DSC_6328-1024x682.jpg" alt="working in the Palace, Nantes" width="509" height="339" data-srcset="https://blog.senx.io/wp-content/uploads/2020/09/DSC_6328-1024x682.jpg 1024w, https://blog.senx.io/wp-content/uploads/2020/09/DSC_6328-300x200.jpg 300w, https://blog.senx.io/wp-content/uploads/2020/09/DSC_6328-768x512.jpg 768w, https://blog.senx.io/wp-content/uploads/2020/09/DSC_6328-1536x1024.jpg 1536w, https://blog.senx.io/wp-content/uploads/2020/09/DSC_6328-600x400.jpg 600w, https://blog.senx.io/wp-content/uploads/2020/09/DSC_6328.jpg 2000w" data-sizes="(max-width: 509px) 100vw, 509px" srcset="https://blog.senx.io/wp-content/uploads/2020/09/DSC_6328-1024x682.jpg 1024w, https://blog.senx.io/wp-content/uploads/2020/09/DSC_6328-300x200.jpg 300w, https://blog.senx.io/wp-content/uploads/2020/09/DSC_6328-768x512.jpg 768w, https://blog.senx.io/wp-content/uploads/2020/09/DSC_6328-1536x1024.jpg 1536w, https://blog.senx.io/wp-content/uploads/2020/09/DSC_6328-600x400.jpg 600w, https://blog.senx.io/wp-content/uploads/2020/09/DSC_6328.jpg 2000w"><figcaption>One sleepless night later, the first functional prototype was up.</figcaption></figure></div>







<p>Three days later, <strong>the <a href="http://www.cea.fr/" target="_blank" rel="noreferrer noopener">CEA</a></strong> (french government agency for atomic energy) is now supporting us. On the 31<sup>st</sup> of March, we all moved from Nantes to Grenoble CEA facility, traveling on a nearly empty motorway.</p>



<p>The first prototype had basic electronics: STM32 Nucleo, a small 4 lines screen, a few buttons, a good precision pressure sensor, and several servo outputs. <strong>This first prototype allows us to make a pig breath for 4 hours</strong> on the 3rd of April, only 2 weeks after the project started.</p>



<figure><ul><li><figure><img loading="lazy" width="1024" height="682" src="https://blog.senx.io/wp-content/uploads/2020/09/DSC_6336-1024x682.jpg" data-src="https://blog.senx.io/wp-content/uploads/2020/09/DSC_6336-1024x682.jpg" alt="" data-id="11640" data-link="https://blog.senx.io/?attachment_id=11640" data-srcset="https://blog.senx.io/wp-content/uploads/2020/09/DSC_6336-1024x682.jpg 1024w, https://blog.senx.io/wp-content/uploads/2020/09/DSC_6336-300x200.jpg 300w, https://blog.senx.io/wp-content/uploads/2020/09/DSC_6336-768x512.jpg 768w, https://blog.senx.io/wp-content/uploads/2020/09/DSC_6336-1536x1024.jpg 1536w, https://blog.senx.io/wp-content/uploads/2020/09/DSC_6336-600x400.jpg 600w, https://blog.senx.io/wp-content/uploads/2020/09/DSC_6336.jpg 2000w" data-sizes="(max-width: 1024px) 100vw, 1024px" srcset="https://blog.senx.io/wp-content/uploads/2020/09/DSC_6336-1024x682.jpg 1024w, https://blog.senx.io/wp-content/uploads/2020/09/DSC_6336-300x200.jpg 300w, https://blog.senx.io/wp-content/uploads/2020/09/DSC_6336-768x512.jpg 768w, https://blog.senx.io/wp-content/uploads/2020/09/DSC_6336-1536x1024.jpg 1536w, https://blog.senx.io/wp-content/uploads/2020/09/DSC_6336-600x400.jpg 600w, https://blog.senx.io/wp-content/uploads/2020/09/DSC_6336.jpg 2000w"><figcaption>The first prototype board...</figcaption></figure></li><li><figure><img loading="lazy" width="1024" height="682" src="https://blog.senx.io/wp-content/uploads/2020/09/DSC_6337-1024x682.jpg" data-src="https://blog.senx.io/wp-content/uploads/2020/09/DSC_6337-1024x682.jpg" alt="" data-id="11641" data-link="https://blog.senx.io/?attachment_id=11641" data-srcset="https://blog.senx.io/wp-content/uploads/2020/09/DSC_6337-1024x682.jpg 1024w, https://blog.senx.io/wp-content/uploads/2020/09/DSC_6337-300x200.jpg 300w, https://blog.senx.io/wp-content/uploads/2020/09/DSC_6337-768x512.jpg 768w, https://blog.senx.io/wp-content/uploads/2020/09/DSC_6337-1536x1024.jpg 1536w, https://blog.senx.io/wp-content/uploads/2020/09/DSC_6337-600x400.jpg 600w, https://blog.senx.io/wp-content/uploads/2020/09/DSC_6337.jpg 2000w" data-sizes="(max-width: 1024px) 100vw, 1024px" srcset="https://blog.senx.io/wp-content/uploads/2020/09/DSC_6337-1024x682.jpg 1024w, https://blog.senx.io/wp-content/uploads/2020/09/DSC_6337-300x200.jpg 300w, https://blog.senx.io/wp-content/uploads/2020/09/DSC_6337-768x512.jpg 768w, https://blog.senx.io/wp-content/uploads/2020/09/DSC_6337-1536x1024.jpg 1536w, https://blog.senx.io/wp-content/uploads/2020/09/DSC_6337-600x400.jpg 600w, https://blog.senx.io/wp-content/uploads/2020/09/DSC_6337.jpg 2000w"><figcaption>Stacking a Nucleo F411 with pressure sensor, keyboard, screen.</figcaption></figure></li><li><figure><img loading="lazy" width="1024" height="768" src="https://blog.senx.io/wp-content/uploads/2020/09/4C103809-C6CC-423D-B054-48B8C853F29E_1_105_c.jpeg" data-src="https://blog.senx.io/wp-content/uploads/2020/09/4C103809-C6CC-423D-B054-48B8C853F29E_1_105_c.jpeg" alt="" data-id="11748" data-full-url="https://blog.senx.io/wp-content/uploads/2020/09/4C103809-C6CC-423D-B054-48B8C853F29E_1_105_c.jpeg" data-link="https://blog.senx.io/?attachment_id=11748" data-srcset="https://blog.senx.io/wp-content/uploads/2020/09/4C103809-C6CC-423D-B054-48B8C853F29E_1_105_c.jpeg 1024w, https://blog.senx.io/wp-content/uploads/2020/09/4C103809-C6CC-423D-B054-48B8C853F29E_1_105_c-300x225.jpeg 300w, https://blog.senx.io/wp-content/uploads/2020/09/4C103809-C6CC-423D-B054-48B8C853F29E_1_105_c-768x576.jpeg 768w" data-sizes="(max-width: 1024px) 100vw, 1024px" srcset="https://blog.senx.io/wp-content/uploads/2020/09/4C103809-C6CC-423D-B054-48B8C853F29E_1_105_c.jpeg 1024w, https://blog.senx.io/wp-content/uploads/2020/09/4C103809-C6CC-423D-B054-48B8C853F29E_1_105_c-300x225.jpeg 300w, https://blog.senx.io/wp-content/uploads/2020/09/4C103809-C6CC-423D-B054-48B8C853F29E_1_105_c-768x576.jpeg 768w"><figcaption>First wood prototype</figcaption></figure></li></ul></figure>



<h2>Enters the Raspberry Pi</h2>



<p>What we learned from the first test on a pig:</p>



<ul><li>The ventilator did the job. The pig was alive and woke up correctly.</li><li><strong>There is a huge UX problem.</strong></li><li>The airflow measurement is really helpful.</li></ul>



<p>The experts from the medical world are now used to high-tech screens displaying curves with not only pressure, but real-time air volume blown into the patient lungs. Even in crisis time, we understand that our product does not meet their minimum UI/UX needs.</p>



<figure><img loading="lazy" width="1024" height="418" src="https://blog.senx.io/wp-content/uploads/2020/09/image-4-1024x418.jpg" data-src="https://blog.senx.io/wp-content/uploads/2020/09/image-4-1024x418.jpg" alt="difference of UX between first MakAir screen and a recent ventilator" data-srcset="https://blog.senx.io/wp-content/uploads/2020/09/image-4-1024x418.jpg 1024w, https://blog.senx.io/wp-content/uploads/2020/09/image-4-300x123.jpg 300w, https://blog.senx.io/wp-content/uploads/2020/09/image-4-768x314.jpg 768w, https://blog.senx.io/wp-content/uploads/2020/09/image-4-1536x627.jpg 1536w, https://blog.senx.io/wp-content/uploads/2020/09/image-4.jpg 1660w" data-sizes="(max-width: 1024px) 100vw, 1024px" srcset="https://blog.senx.io/wp-content/uploads/2020/09/image-4-1024x418.jpg 1024w, https://blog.senx.io/wp-content/uploads/2020/09/image-4-300x123.jpg 300w, https://blog.senx.io/wp-content/uploads/2020/09/image-4-768x314.jpg 768w, https://blog.senx.io/wp-content/uploads/2020/09/image-4-1536x627.jpg 1536w, https://blog.senx.io/wp-content/uploads/2020/09/image-4.jpg 1660w"><figcaption>Makair prototype on the left, a recent ventilator on the right. <br>Both can save life, but UX gap is huge!</figcaption></figure>



<p>Always listen to the users. Even if we succeed in mass production of an open-source ventilator, if doctors want curves and measures of the number of air liters entering the lungs, we must do it. </p>



<p>Since the beginning, this project is time driven. We never consider the price, but we always look at worldwide stocks. In a time where lots of plants are closed in Europe, <strong>the supply chain is leading the project.</strong></p>



<div><figure><img loading="lazy" src="https://blog.senx.io/wp-content/uploads/2020/09/DSC_6374-edited.jpg" data-src="https://blog.senx.io/wp-content/uploads/2020/09/DSC_6374-edited.jpg" alt="inside the v1 of the MakAir" width="522" height="347" data-srcset="https://blog.senx.io/wp-content/uploads/2020/09/DSC_6374-edited.jpg 1378w, https://blog.senx.io/wp-content/uploads/2020/09/DSC_6374-edited-300x200.jpg 300w, https://blog.senx.io/wp-content/uploads/2020/09/DSC_6374-edited-1024x683.jpg 1024w, https://blog.senx.io/wp-content/uploads/2020/09/DSC_6374-edited-768x512.jpg 768w, https://blog.senx.io/wp-content/uploads/2020/09/DSC_6374-edited-600x400.jpg 600w" data-sizes="(max-width: 522px) 100vw, 522px" srcset="https://blog.senx.io/wp-content/uploads/2020/09/DSC_6374-edited.jpg 1378w, https://blog.senx.io/wp-content/uploads/2020/09/DSC_6374-edited-300x200.jpg 300w, https://blog.senx.io/wp-content/uploads/2020/09/DSC_6374-edited-1024x683.jpg 1024w, https://blog.senx.io/wp-content/uploads/2020/09/DSC_6374-edited-768x512.jpg 768w, https://blog.senx.io/wp-content/uploads/2020/09/DSC_6374-edited-600x400.jpg 600w"><figcaption>Scooter lead-acid batteries. Because these are the most available batteries in the word.</figcaption></figure></div>



<p>So, what is the world's most available touch screen? </p>



<div><figure><img loading="lazy" src="https://blog.senx.io/wp-content/uploads/2020/09/image-2.png" data-src="https://blog.senx.io/wp-content/uploads/2020/09/image-2.png" alt="farnell stocks" width="616" height="217" data-srcset="https://blog.senx.io/wp-content/uploads/2020/09/image-2.png 832w, https://blog.senx.io/wp-content/uploads/2020/09/image-2-300x106.png 300w, https://blog.senx.io/wp-content/uploads/2020/09/image-2-768x270.png 768w" data-sizes="(max-width: 616px) 100vw, 616px" srcset="https://blog.senx.io/wp-content/uploads/2020/09/image-2.png 832w, https://blog.senx.io/wp-content/uploads/2020/09/image-2-300x106.png 300w, https://blog.senx.io/wp-content/uploads/2020/09/image-2-768x270.png 768w"><figcaption>(and 18000 more at radiospares)</figcaption></figure></div>



<p>As I just said, the supply chain rules the project. MakAir will have a raspberry to display curves. Nice coincidence for an open-source project!</p>



<p>By the way, the mass flow meter sensor was a huge problem. Since the beginning, MakAir did not want to disturb the production of existing ventilators. But this component is on the airway, it should be approved for medical use. In April, it was impossible to source any Sensirion or Honeywell mass flow sensors... Anyway, the next test will be done with a raspberry connected to the STM32. </p>







<h2>Enter Warp&nbsp;10</h2>



<p>On the 17th of April, the first batch of ventilators built in the CEA clean-rooms was ready. This batch was used for the 1st clinical tests. </p>



<p><strong>The pressure switches from the technical team to the regulatory team, remotely working on the project since the beginning. </strong></p>



<p>To prepare the next batch, we came back to Nantes. After 25 days, we switched from commando mode (18h/day, 7 days a week) to a more standard week (14h/day, the weekends with the family).</p>



<div><figure><img loading="lazy" src="https://blog.senx.io/wp-content/uploads/2020/09/IMG_5752-1024x768.jpg" data-src="https://blog.senx.io/wp-content/uploads/2020/09/IMG_5752-1024x768.jpg" alt="MakAir team in the CEA cleanroom with prototypes" width="521" height="390" data-srcset="https://blog.senx.io/wp-content/uploads/2020/09/IMG_5752-1024x768.jpg 1024w, https://blog.senx.io/wp-content/uploads/2020/09/IMG_5752-300x225.jpg 300w, https://blog.senx.io/wp-content/uploads/2020/09/IMG_5752-768x576.jpg 768w, https://blog.senx.io/wp-content/uploads/2020/09/IMG_5752-1536x1152.jpg 1536w, https://blog.senx.io/wp-content/uploads/2020/09/IMG_5752.jpg 2016w" data-sizes="(max-width: 521px) 100vw, 521px" srcset="https://blog.senx.io/wp-content/uploads/2020/09/IMG_5752-1024x768.jpg 1024w, https://blog.senx.io/wp-content/uploads/2020/09/IMG_5752-300x225.jpg 300w, https://blog.senx.io/wp-content/uploads/2020/09/IMG_5752-768x576.jpg 768w, https://blog.senx.io/wp-content/uploads/2020/09/IMG_5752-1536x1152.jpg 1536w, https://blog.senx.io/wp-content/uploads/2020/09/IMG_5752.jpg 2016w"><figcaption>Tyvek sterile clothing in a cleanroom. Could not be better for medical device assembly. Thanks to the CEA.</figcaption></figure></div>



<p>On the 30<sup>th</sup> of April, the prototype with a Raspberry Pi is ready for the next animal test. Two people had to fly to Grenoble CEA with this prototype, but the rest of us, and all the people remotely working on the project wanted to follow the experience. </p>



<p>So, the night before the test, I quickly deployed Warp&nbsp;10 on the raspberry and wrote a small script to copy data every 10s to another Warp&nbsp;10 server.</p>


<span><span><a href="https://twitter.com/intent/tweet?url=https%3A%2F%2Fblog.senx.io%2F%3Fp%3D11630&amp;text=MakAir%3A%20the%20birth%20of%20the%20first%20open-source%20data-enabled%20ventilator.%20From%20the%20first%20prototype%20to%20more%20modern%20UX%2C%20thanks%20to%20Raspberry%20Pi.&amp;via=SenXHQ&amp;related=SenXHQ" target="_blank" rel="noopener noreferrer">MakAir: the birth of the first open-source data-enabled ventilator. From the first prototype to more modern UX, thanks to Raspberry Pi. </a></span><a href="https://twitter.com/intent/tweet?url=https%3A%2F%2Fblog.senx.io%2F%3Fp%3D11630&amp;text=MakAir%3A%20the%20birth%20of%20the%20first%20open-source%20data-enabled%20ventilator.%20From%20the%20first%20prototype%20to%20more%20modern%20UX%2C%20thanks%20to%20Raspberry%20Pi.&amp;via=SenXHQ&amp;related=SenXHQ" target="_blank" rel="noopener noreferrer">Click To Tweet</a></span>


<p>What is <a href="https://www.warp10.io/" target="_blank" rel="noreferrer noopener">Warp&nbsp;10</a>? It is a time series platform. But unlike other TSDB (Time Series Database), there is a full analysis environment behind, and even a task scheduler. Compress time series, replicate to another server while managing network outage is really easy. Same tooling on the server and the connected object, that what I call easy IoT. To stream data, you just need a few WarpScript functions among <a href="https://www.warp10.io/doc/functionList" target="_blank" rel="noreferrer noopener">the thousand available</a>.</p>



<p>Basically, the WarpScript pseudo code is:</p>



<pre><code>- Read the last value of makair.lastupload GTS
- take the last tick as start
- take now as end
- fetch locally all the makair GTS from start to end
- WRAP all the GTS
- build a script that UNWRAP and UPDATE the data
- do a remote execution of the script with REXEC 
- if the REXEC was a success, store end in makair.lastupload</code></pre>



<p>You can follow the <a href="https://www.warp10.io/content/04_Tutorials/01_WarpScript/30_Server_to_Server" target="_blank" rel="noreferrer noopener">server to server tutorial</a> to implement such a WarpScript, then save it as $WARP10HOME/warpscripts/makair/10000/upload_data.mc2 to schedule an execution every 10s.</p>



<p>To display data in real-time, <a href="http://studio.senx.io/" target="_blank" rel="noreferrer noopener">WarpStudio</a> did the job easily too. Autorefresh of the DataViz every 10s is a built-in function:</p>



<div><figure><img loading="lazy" src="https://blog.senx.io/wp-content/uploads/2020/09/image-3.png" data-src="https://blog.senx.io/wp-content/uploads/2020/09/image-3.png" alt="autorefresh settings of the MakAir test" width="522" height="385" data-srcset="https://blog.senx.io/wp-content/uploads/2020/09/image-3.png 575w, https://blog.senx.io/wp-content/uploads/2020/09/image-3-300x221.png 300w" data-sizes="(max-width: 522px) 100vw, 522px" srcset="https://blog.senx.io/wp-content/uploads/2020/09/image-3.png 575w, https://blog.senx.io/wp-content/uploads/2020/09/image-3-300x221.png 300w"><figcaption>In the dataviz tab of WarpStudio.</figcaption></figure></div>







<p>Around 30 lines of code to allow all the MakAir team to follow the pressure inside the pig lungs in real-time!</p>



<div><figure><img loading="lazy" src="https://blog.senx.io/wp-content/uploads/2020/09/DSC_6580-70pc-1024x683.jpg" data-src="https://blog.senx.io/wp-content/uploads/2020/09/DSC_6580-70pc-1024x683.jpg" alt="real time display" width="516" height="343" data-srcset="https://blog.senx.io/wp-content/uploads/2020/09/DSC_6580-70pc-1024x683.jpg 1024w, https://blog.senx.io/wp-content/uploads/2020/09/DSC_6580-70pc-300x200.jpg 300w, https://blog.senx.io/wp-content/uploads/2020/09/DSC_6580-70pc-768x512.jpg 768w, https://blog.senx.io/wp-content/uploads/2020/09/DSC_6580-70pc-1536x1024.jpg 1536w, https://blog.senx.io/wp-content/uploads/2020/09/DSC_6580-70pc-2048x1365.jpg 2048w, https://blog.senx.io/wp-content/uploads/2020/09/DSC_6580-70pc-600x400.jpg 600w" data-sizes="(max-width: 516px) 100vw, 516px" srcset="https://blog.senx.io/wp-content/uploads/2020/09/DSC_6580-70pc-1024x683.jpg 1024w, https://blog.senx.io/wp-content/uploads/2020/09/DSC_6580-70pc-300x200.jpg 300w, https://blog.senx.io/wp-content/uploads/2020/09/DSC_6580-70pc-768x512.jpg 768w, https://blog.senx.io/wp-content/uploads/2020/09/DSC_6580-70pc-1536x1024.jpg 1536w, https://blog.senx.io/wp-content/uploads/2020/09/DSC_6580-70pc-2048x1365.jpg 2048w, https://blog.senx.io/wp-content/uploads/2020/09/DSC_6580-70pc-600x400.jpg 600w"><figcaption>WarpStudio on a 60" 4k display, that's a nice dashboard.</figcaption></figure></div>







<h2>Next steps</h2>



<p>MakAir ventilators are designed to store everything in the <a href="https://warp10.io/" target="_blank" rel="noreferrer noopener">Warp&nbsp;10</a> time series database. They also have built-in WiFi and LoRa. All these features are not yet available, because the priority is still to make an open-source approved ventilator. </p>



<figure><ul><li><figure><img loading="lazy" width="225" height="300" src="https://blog.senx.io/wp-content/uploads/2020/09/IMG_20200519_171307-scaled.jpg" data-src="https://blog.senx.io/wp-content/uploads/2020/09/IMG_20200519_171307-225x300.jpg" alt="" data-id="11728" data-full-url="https://blog.senx.io/wp-content/uploads/2020/09/IMG_20200519_171307-scaled.jpg" data-link="https://blog.senx.io/?attachment_id=11728" data-srcset="https://blog.senx.io/wp-content/uploads/2020/09/IMG_20200519_171307-225x300.jpg 225w, https://blog.senx.io/wp-content/uploads/2020/09/IMG_20200519_171307-768x1024.jpg 768w, https://blog.senx.io/wp-content/uploads/2020/09/IMG_20200519_171307-1152x1536.jpg 1152w, https://blog.senx.io/wp-content/uploads/2020/09/IMG_20200519_171307-1536x2048.jpg 1536w, https://blog.senx.io/wp-content/uploads/2020/09/IMG_20200519_171307-scaled.jpg 1920w" data-sizes="(max-width: 225px) 100vw, 225px" srcset="https://blog.senx.io/wp-content/uploads/2020/09/IMG_20200519_171307-225x300.jpg 225w, https://blog.senx.io/wp-content/uploads/2020/09/IMG_20200519_171307-768x1024.jpg 768w, https://blog.senx.io/wp-content/uploads/2020/09/IMG_20200519_171307-1152x1536.jpg 1152w, https://blog.senx.io/wp-content/uploads/2020/09/IMG_20200519_171307-1536x2048.jpg 1536w, https://blog.senx.io/wp-content/uploads/2020/09/IMG_20200519_171307-scaled.jpg 1920w"><figcaption>Revision 3 has a Raspberry screen on top of the small screen.</figcaption></figure></li><li><figure><img loading="lazy" width="225" height="300" src="https://blog.senx.io/wp-content/uploads/2020/09/IMG_20200519_171259-scaled.jpg" data-src="https://blog.senx.io/wp-content/uploads/2020/09/IMG_20200519_171259-225x300.jpg" alt="" data-id="11727" data-full-url="https://blog.senx.io/wp-content/uploads/2020/09/IMG_20200519_171259-scaled.jpg" data-link="https://blog.senx.io/?attachment_id=11727" data-srcset="https://blog.senx.io/wp-content/uploads/2020/09/IMG_20200519_171259-225x300.jpg 225w, https://blog.senx.io/wp-content/uploads/2020/09/IMG_20200519_171259-768x1024.jpg 768w, https://blog.senx.io/wp-content/uploads/2020/09/IMG_20200519_171259-1152x1536.jpg 1152w, https://blog.senx.io/wp-content/uploads/2020/09/IMG_20200519_171259-1536x2048.jpg 1536w, https://blog.senx.io/wp-content/uploads/2020/09/IMG_20200519_171259-scaled.jpg 1920w" data-sizes="(max-width: 225px) 100vw, 225px" srcset="https://blog.senx.io/wp-content/uploads/2020/09/IMG_20200519_171259-225x300.jpg 225w, https://blog.senx.io/wp-content/uploads/2020/09/IMG_20200519_171259-768x1024.jpg 768w, https://blog.senx.io/wp-content/uploads/2020/09/IMG_20200519_171259-1152x1536.jpg 1152w, https://blog.senx.io/wp-content/uploads/2020/09/IMG_20200519_171259-1536x2048.jpg 1536w, https://blog.senx.io/wp-content/uploads/2020/09/IMG_20200519_171259-scaled.jpg 1920w"><figcaption>The Raspberry Pi connected to the mainboard</figcaption></figure></li></ul></figure>



<p>Connected features + open-source software is an enabler for doctors and researchers to perform extensive data collection and try new algorithms in the machine. Warp&nbsp;10 is the best open source time series database to <a href="https://blog.senx.io/warp-10-for-iot-gdpr-compliant-before-gdpr-even-existed/" target="_blank" rel="noreferrer noopener">securely</a> store medical data and analyze it. It's not a walled garden.</p>



<p>If you need to connect medical devices to a time series database, <a href="mailto:contact@senx.io" target="_blank" rel="noreferrer noopener">just ask us</a>.</p>



<p>MakAir is now entering the second phase of clinical tests. We can consider we are halfway to the goal. Keep in mind that among all the projects of ventilators announced by big companies, MakAir is the only one to reach the clinical tests step. <a href="https://makair.life/" target="_blank" rel="noreferrer noopener">200 people, backed up by CEA and a few french companies</a> are about to make a commercially available open source ventilator... </p>



<p>That's crazy when you think about it!</p>



<p>Learn more about the MakAir project on <a href="http://makair.life/" target="_blank" rel="noreferrer noopener">makair.life</a>.</p>
<!-- relpost-thumb-wrapper --><!-- close relpost-thumb-wrapper -->      
           
    </article></div>]]>
            </description>
            <link>https://blog.senx.io/makair-covid-19-ventilator-with-a-raspberry-pi/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25670303</guid>
            <pubDate>Thu, 07 Jan 2021 12:34:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Reed-Solomon error recovery in RAID-6]]>
            </title>
            <description>
<![CDATA[
Score 99 | Comments 37 (<a href="https://news.ycombinator.com/item?id=25666830">thread link</a>) | @signa11
<br/>
January 6, 2021 | http://anadoxin.org/blog/error-recovery-in-raid6.html/ | <a href="https://web.archive.org/web/*/http://anadoxin.org/blog/error-recovery-in-raid6.html/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        

        

        <p>
            <h3>Reed-Solomon error recovery in RAID-6</h3>
        </p>

        <p>
            https://anadoxin.org/blog/error-recovery-in-raid6.html
        </p>

        
        
        
        

        
        
        
        

        
        <p>There are lots of resources on the Internet about RAID-6 error recovery and how you can create your own implementation of it, but most of those resources require spending a lot of time fighting with mathematical equations and figuring out the real algorithm.</p>
<p>In this post I'll try to give you a simple example how you can create your own error recovery solution based on what is used in RAID-6. More specifically, if you need to provide rendundancy across your mediums so that a failure of 1 or 2 mediums will be tolerated, look no further! ;)</p>
<p>If you'll read this post, as a bonus you'll gain knowledge about how RAID-5 error recovery works, because RAID-6 is an improved version of RAID-5 error recovery system.</p>

<p>Let's assume you have 3 disk drives with some data. Let's name those drives as <code>D1</code>, <code>D2</code> and <code>D3</code>. In order to use the same error recovery technique as RAID-6 uses, you'll need two additional disk drives, the <code>PD</code> drive, and the <code>RS</code> drive. I'll describe what <code>PD</code> and <code>RS</code> means in few moments. So, you'll need a total of 5 disk drives: <code>D1</code>, <code>D2</code>, <code>D3</code>, <code>PD</code> and <code>RS</code>.</p>
<p><img src="https://anadoxin.org/blog/error-recovery-in-raid6.html/image1.svg" alt=""></p>
<p>So, here's the situation:</p>
<ul>
<li><code>D1</code>, <code>D2</code> and <code>D3</code> contain <em>arbitrary user data</em>, and it doesn't matter what their contents are. FWIW you can assume those drives are full of cat pictures.</li>
<li>The special <code>PD</code> drive (named after <code>Parity Drive</code>, sometimes called <code>P</code> in whitepapers) contains the XOR data, generated automatically from <code>D1</code>, <code>D2</code> and <code>D3</code>.</li>
<li>The second special <code>RS</code> drive (named after <code>Reed-Solomon Drive</code>, sometimes also called <code>Q</code>) contains the Reed-Solomon codes, calculated from the same data as <code>PD</code>, namely from drives <code>D1</code>, <code>D2</code> and <code>D3</code>.</li>
</ul>
<p>Let's see how we can perform some basic operations on such disk array.</p>

<p>If we have properly calculated <code>PD</code> and <code>RS</code> drives, we can lose up to 2 drives. How we recover from failures depends on which drives will fail. There are generally 7 cases that RAID-6 can handle. Next points will describe the scenarios, sorted from the easiest case, to the most complicated.</p>
<ol>
<li>
<p>Loss of the <code>PD</code> drive (failure of only one drive).</p>
<p><img src="https://anadoxin.org/blog/error-recovery-in-raid6.html/image-losspd.svg" alt=""></p>
<p>This case is very straightforward. The <code>PD</code> drive contains only autogenerated data, so in case we lose the <code>PD</code> drive, we can regenerate it by using only user data (stored on disks <code>D1</code>, <code>D2</code> and <code>D3</code>).</p>
</li>
<li>
<p>Loss of one of the data drives: either <code>D1</code>, <code>D2</code> or <code>D3</code> (failure of only one drive).</p>
<p><img src="https://anadoxin.org/blog/error-recovery-in-raid6.html/image-datadrive.svg" alt=""></p>
<p>In this case we're losing data, but since we only lose 1 disk, the recovery scenario is the same as in RAID-5 error recovery: we'll use <code>PD</code> drive <em>together with two non-missing data drives</em> to recover data from the missing data drive. It doesn't matter which data drive we lose, because if we have 2 data drives and the <code>PD</code> drive, we can always generate data for the third drive. The <code>RS</code> drive is not needed to regenerate the data drive in this case (and is not used at all in this failure case).</p>
</li>
<li>
<p>Loss of the <code>RS</code> drive (failure of only one drive).</p>
<p><img src="https://anadoxin.org/blog/error-recovery-in-raid6.html/image-lossrs.svg" alt=""></p>
<p>Similar to the situation from point 1: we have all the data drives, and we can simply regenerate the <code>RS</code> drive by calculating Reed-Solomon codes from drives that did not fail.</p>
</li>
<li>
<p>Loss of the <code>PD</code> drive and the <code>RS</code> drive (failure of two drives).</p>
<p><img src="https://anadoxin.org/blog/error-recovery-in-raid6.html/image-losspdrs.svg" alt=""></p>
<p>This case is very similar to points 1 or 3, we have all the data intact, so we can generate contents of <code>PD</code> drive and then <code>RS</code> drive very easily.</p>
</li>
<li>
<p>Loss of the <code>RS</code> drive and one data drive (failure of two drives).</p>
<p><img src="https://anadoxin.org/blog/error-recovery-in-raid6.html/image-lossdatars.svg" alt=""></p>
<p>In this case we're losing two disks, but only one lost disk is filled with data. Since we have <code>PD</code> drive intact, we can use it to regenerate data from missing data drive, so this case is not so different than case #2. After that, we will have all the data drives, so we can regenerate the <code>RS</code> drive easily.</p>
</li>
<li>
<p>Loss of the <code>PD</code> drive and one data drive (failure of two drives).</p>
<p><img src="https://anadoxin.org/blog/error-recovery-in-raid6.html/image-lossdatapd.svg" alt=""></p>
<p>This case is more complicated. We lose one user data drive (in this example <code>D3</code>), and we don't have the <code>PD</code> drive to aid with recovery, because we've lost it as well. We have to use the <code>RS</code> drive in conjunction with all user data drives that are still available (<code>D1</code> and <code>D2</code>) to regenerate the missing data drive <code>D3</code>. After we'll have all data drives regenerated, we can calculate the missing <code>PD</code> drive. This is the first case where recovery using Reed-Solomon codes comes into play.</p>
</li>
<li>
<p>Loss of two data drives (failure of two drives).</p>
<p><img src="https://anadoxin.org/blog/error-recovery-in-raid6.html/image-lossdatadata.svg" alt=""></p>
<p>This is the most complicated scenario. We need to use both <code>PD</code> and <code>RS</code> to regenerate both data drives. Reed-Solomon coding makes this case possible.</p>
</li>
</ol>
<p>In the following sections, I'll try to describe those cases above with more detail, and provide some source code (in Python :P) that will perform actual recovery of data.</p>
<p>Please keep in mind that real RAID-6 arrays don't really dedicate whole disk for <code>PD</code> or <code>RS</code>. Real arrays span this additional checksum data across all disks. There are multiple methods used by various controllers: left asynchronous, right synchronous, there can be an offset to the RAID data, there can be pattern delays, etc. Why it's done this way, and how exactly RAID-6 stripes looks like is beyond the scope of this blog post. So let's stick only to Reed-Solomon codes.</p>
<h2 id="test-data">Test data</h2>
<p>Let's define how our "user data" looks like. To keep things simple, let's pretend that our "disk drives" are 5 bytes big.</p>
<table><thead><tr><th>Disk</th><th>Data in ASCII</th><th>Data in HEX</th></tr></thead><tbody>
<tr><td><code>D1</code></td><td>f i r s t</td><td>0x66, 0x69, 0x72, 0x73, 0x74</td></tr>
<tr><td><code>D2</code></td><td>s e c n d</td><td>0x73, 0x65, 0x63, 0x6e, 0x64</td></tr>
<tr><td><code>D3</code></td><td>t h i r d</td><td>0x74, 0x68, 0x69, 0x72, 0x64</td></tr>
</tbody></table>
<p>Let's go into the scenarios mentioned above in more details.</p>

<p>In order to generate the <code>PD</code> data, we need only the user data drives. In our case it's <code>D1</code>, <code>D2</code> and <code>D3</code>. The <code>PD</code> drive consists of nothing more than <a href="https://en.wikipedia.org/wiki/Bitwise_operation#XOR">XOR</a> of all user data.</p>
<ul>
<li>To generate offset 0 of the <code>PD</code> drive, you need to XOR all bytes from offset 0 from all disk drives.</li>
<li>Then, to generate offset 1 of the <code>PD</code> drive, you need to XOR bytes from offset 1 from all disk drives. E.g.:</li>
</ul>
<pre><code><span>PD[0] = D1[0] xor D2[0] xor D3[0]
PD[1] = D1[1] xor D2[1] xor D3[1]
PD[2] = D1[2] xor D2[2] xor D3[2]
PD[3] = D1[3] xor D2[3] xor D3[3]
PD[4] = D1[4] xor D2[4] xor D3[4]
</span></code></pre>
<p>Example:</p>
<pre><code><span>PD[0] = 0x66 xor 0x73 xor 0x74  =&gt;  0x61
PD[1] = 0x69 xor 0x65 xor 0x63  =&gt;  0x64
PD[2] = 0x72 xor 0x63 xor 0x69  =&gt;  0x78
PD[3] = 0x73 xor 0x6e xor 0x72  =&gt;  0x6f
PD[4] = 0x74 xor 0x64 xor 0x64  =&gt;  0x74
</span></code></pre>
<p>Yes, it's that simple. Do it for the whole drives (in our case, 5 bytes), and you'll have the properly generated <code>PD</code> drive:</p>
<table><thead><tr><th>Disk</th><th>Data in HEX</th></tr></thead><tbody>
<tr><td><code>PD</code></td><td>0x61, 0x64, 0x78, 0x6f, 0x74</td></tr>
</tbody></table>
<p>So, in case when only your <code>PD</code> drive will fail, you can see it's trivial to regenerate it from the data drives <code>D1</code>, <code>D2</code> and <code>D3</code>.</p>

<p>By the way, this is how RAID-5 error recovery works. If only one drive with user data will fail, we can use the <code>PD</code> drive to recalculate missing user data.</p>
<p>Let's say we're losing <code>D2</code>, so the drives that are still working are: <code>D1</code>, <code>D3</code>, <code>PD</code> and <code>RS</code>. In this case, we don't even look at <code>RS</code>. All we need are the <code>D1</code>, <code>D3</code> and <code>PD</code> drives. To calculate missing data, you can use the XOR function again, like in the previous point.</p>
<p>To recover user data from offset 0, XOR the bytes from offsets 0 of disks with user data you haven't lost (<code>D1</code> and <code>D3</code>) together with the byte from offset 0 from the <code>PD</code> drive. Do the same thing for offset 1, like this:</p>
<pre><code><span>D2[0] = D1[0] xor D3[0] xor PD[0]
D2[1] = D1[1] xor D3[1] xor PD[1]
D2[2] = D1[2] xor D3[2] xor PD[2]
D2[3] = D1[3] xor D3[3] xor PD[3]
D2[4] = D1[4] xor D3[4] xor PD[4]
</span></code></pre>
<p>Example:</p>
<pre><code><span>D2[0] = 0x66 xor 0x74 xor 0x61  =&gt;  0x73 (s)
D2[1] = 0x69 xor 0x63 xor 0x64  =&gt;  0x65 (e)
D2[2] = 0x72 xor 0x69 xor 0x78  =&gt;  0x63 (c)
D2[3] = 0x73 xor 0x72 xor 0x6f  =&gt;  0x6e (n)
D2[4] = 0x74 xor 0x64 xor 0x74  =&gt;  0x64 (d)
</span></code></pre>
<p>As you can see, we can easily recover data from the missing drive. It doesn't matter which drive is missing; the <a href="https://en.wikipedia.org/wiki/Bitwise_operation#XOR">XOR function</a> will work anyway.</p>

<p>Now we enter the realm of the Reed-Solomon codes and Galois fields. But don't worry, you don't have to be a mathematician in order to <em>use</em> it.</p>
<p>When we lose only <code>RS</code> drive, or when we initialize a new RAID-6-like redundation system, we simply need to regenerate it. In order to do that, we need to use the <code>gflog</code> and <code>gfilog</code> tables, which are always constant, plus data from our existing data drives <code>D1</code>, <code>D2</code> and <code>D3</code>.</p>
<p>This is the <code>gflog</code> table, it always stays the same:</p>
<pre><code><span>    0x00, 0x00, 0x01, 0x19, 0x02, 0x32, 0x1a, 0xc6, 0x03, 0xdf, 0x33, 0xee, 0x1b, 0x68, 0xc7, 0x4b,
    0x04, 0x64, 0xe0, 0x0e, 0x34, 0x8d, 0xef, 0x81, 0x1c, 0xc1, 0x69, 0xf8, 0xc8, 0x08, 0x4c, 0x71,
    0x05, 0x8a, 0x65, 0x2f, 0xe1, 0x24, 0x0f, 0x21, 0x35, 0x93, 0x8e, 0xda, 0xf0, 0x12, 0x82, 0x45,
    0x1d, 0xb5, 0xc2, 0x7d, 0x6a, 0x27, 0xf9, 0xb9, 0xc9, 0x9a, 0x09, 0x78, 0x4d, 0xe4, 0x72, 0xa6,
    0x06, 0xbf, 0x8b, 0x62, 0x66, 0xdd, 0x30, 0xfd, 0xe2, 0x98, 0x25, 0xb3, 0x10, 0x91, 0x22, 0x88,
    0x36, 0xd0, 0x94, 0xce, 0x8f, 0x96, 0xdb, 0xbd, 0xf1, 0xd2, 0x13, 0x5c, 0x83, 0x38, 0x46, 0x40,
    0x1e, 0x42, 0xb6, 0xa3, 0xc3, 0x48, 0x7e, 0x6e, 0x6b, 0x3a, 0x28, 0x54, 0xfa, 0x85, 0xba, 0x3d,
    0xca, 0x5e, 0x9b, 0x9f, 0x0a, 0x15, 0x79, 0x2b, 0x4e, 0xd4, 0xe5, 0xac, 0x73, 0xf3, 0xa7, 0x57,
    0x07, 0x70, 0xc0, 0xf7, 0x8c, 0x80, 0x63, 0x0d, 0x67, 0x4a, 0xde, 0xed, 0x31, 0xc5, 0xfe, 0x18,
    0xe3, 0xa5, 0x99, 0x77, 0x26, 0xb8, 0xb4, 0x7c, 0x11, 0x44, 0x92, 0xd9, 0x23, 0x20, 0x89, 0x2e,
    0x37, 0x3f, 0xd1, 0x5b, 0x95, 0xbc, 0xcf, 0xcd, 0x90, 0x87, 0x97, 0xb2, 0xdc, 0xfc, 0xbe, 0x61,
    0xf2, 0x56, 0xd3, 0xab, 0x14, 0x2a, 0x5d, 0x9e, 0x84, 0x3c, 0x39, 0x53, 0x47, 0x6d, 0x41, 0xa2,
    0x1f, 0x2d, 0x43, 0xd8, 0xb7, 0x7b, 0xa4, 0x76, 0xc4, 0x17, 0x49, 0xec, 0x7f, 0x0c, 0x6f, 0xf6,
    0x6c, 0xa1, 0x3b, 0x52, 0x29, 0x9d, 0x55, 0xaa, 0xfb, 0x60, 0x86, 0xb1, 0xbb, 0xcc, 0x3e, 0x5a,
    0xcb, 0x59, 0x5f, 0xb0, 0x9c, 0xa9, 0xa0, 0x51, 0x0b, 0xf5, 0x16, 0xeb, 0x7a, 0x75, 0x2c, 0xd7,
    0x4f, 0xae, 0xd5, 0xe9, 0xe6, 0xe7, 0xad, 0xe8, 0x74, 0xd6, 0xf4, 0xea, 0xa8, 0x50, 0x58, 0xaf.
</span></code></pre>
<p>This is the <code>gfilog</code> table, it's also constant:</p>
<pre><code><span>    0x01, 0x02, 0x04, 0x08, 0x10, 0x20, 0x40, 0x80, 0x1d, 0x3a, 0x74, 0xe8, …</span></code></pre></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://anadoxin.org/blog/error-recovery-in-raid6.html/">http://anadoxin.org/blog/error-recovery-in-raid6.html/</a></em></p>]]>
            </description>
            <link>http://anadoxin.org/blog/error-recovery-in-raid6.html/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25666830</guid>
            <pubDate>Thu, 07 Jan 2021 03:13:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Shooting photos with an IMAX projector lens]]>
            </title>
            <description>
<![CDATA[
Score 166 | Comments 63 (<a href="https://news.ycombinator.com/item?id=25666217">thread link</a>) | @dmitrygr
<br/>
January 6, 2021 | https://theslantedlens.com/2021/crazy-huge-imax-lens-amazing-street-portraits/ | <a href="https://web.archive.org/web/*/https://theslantedlens.com/2021/crazy-huge-imax-lens-amazing-street-portraits/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><div><p>What the heck is that huge lens? That Crazy Huge Lens is an IMAX Lens. You will be surprised at the cool street portraits we got with this thing. Take a look at how Jay P rigged this with his <a href="https://bhpho.to/38bRbgL">Canon EOS R</a> camera and the amazing results.</p>
<p><iframe width="750" height="450" src="https://www.youtube.com/embed/D-ihZrP4C0A" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="allowfullscreen"></iframe></p>
<p>This is Jay P Morgan. Today on The Slanted Lens we are in Santa Monica at a skate park. <img loading="lazy" src="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_8.png" alt="" width="1092" height="611" srcset="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_8.png 1092w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_8-300x168.png 300w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_8-768x430.png 768w" sizes="(max-width: 1092px) 100vw, 1092px">This is a great skate park. I’ve been here before with my daughter who comes down to skate. <img loading="lazy" src="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_35.png" alt="" width="1070" height="600" srcset="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_35.png 1070w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_35-300x168.png 300w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_35-768x431.png 768w" sizes="(max-width: 1070px) 100vw, 1070px">This time I came with this huge IMAX lens. <img loading="lazy" src="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_1.png" alt="" width="1072" height="598" srcset="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_1.png 1072w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_1-300x167.png 300w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_1-768x428.png 768w" sizes="(max-width: 1072px) 100vw, 1072px">This thing is a beast. It’s an IMAX lens and it was made by Iwerks. I’ve had it in a huge hard case in my storage for a long, long time. I’ve always wanted to adapt this to a camera and take portraits with it. <img loading="lazy" src="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_2.png" alt="" width="1071" height="601" srcset="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_2.png 1071w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_2-300x168.png 300w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_2-768x431.png 768w" sizes="(max-width: 1071px) 100vw, 1071px">So I want to do street portraits with an IMAX Lens using my Canon EOS R Camera. So here’s the process I went through to get this lens adapted, so I’ll be able to focus it and work with it.</p>
<p><img loading="lazy" src="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_9.png" alt="" width="1090" height="611" srcset="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_9.png 1090w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_9-300x168.png 300w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_9-768x431.png 768w" sizes="(max-width: 1090px) 100vw, 1090px"> <img loading="lazy" src="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_10.png" alt="" width="1093" height="612" srcset="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_10.png 1093w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_10-300x168.png 300w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_10-768x430.png 768w" sizes="(max-width: 1093px) 100vw, 1093px"> <img loading="lazy" src="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_11.png" alt="" width="1092" height="612" srcset="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_11.png 1092w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_11-300x168.png 300w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_11-768x430.png 768w" sizes="(max-width: 1092px) 100vw, 1092px"> <img loading="lazy" src="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_12.png" alt="" width="1091" height="612" srcset="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_12.png 1091w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_12-300x168.png 300w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_12-768x431.png 768w" sizes="(max-width: 1091px) 100vw, 1091px"> <img loading="lazy" src="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_14.png" alt="" width="1091" height="611" srcset="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_14.png 1091w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_14-300x168.png 300w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_14-768x430.png 768w" sizes="(max-width: 1091px) 100vw, 1091px"> <img loading="lazy" src="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_15.png" alt="" width="1086" height="610" srcset="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_15.png 1086w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_15-300x169.png 300w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_15-768x431.png 768w" sizes="(max-width: 1086px) 100vw, 1086px"> <img loading="lazy" src="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_16.png" alt="" width="1094" height="610" srcset="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_16.png 1094w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_16-300x167.png 300w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_16-768x428.png 768w" sizes="(max-width: 1094px) 100vw, 1094px"> <img loading="lazy" src="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_17.png" alt="" width="1091" height="610" srcset="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_17.png 1091w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_17-300x168.png 300w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_17-768x429.png 768w" sizes="(max-width: 1091px) 100vw, 1091px"> <img loading="lazy" src="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_18.png" alt="" width="1088" height="610" srcset="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_18.png 1088w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_18-300x168.png 300w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_18-768x431.png 768w" sizes="(max-width: 1088px) 100vw, 1088px">Let’s take some pictures. The way I focus this thing is so silly. <img loading="lazy" src="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_20.png" alt="" width="1092" height="611" srcset="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_20.png 1092w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_20-300x168.png 300w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_20-768x430.png 768w" sizes="(max-width: 1092px) 100vw, 1092px">I have a track that I can release here and I can move my camera back and forth inside this tape I put around the lens. Then I find the point where it focuses. It’s pretty gorilla. Very, very gorilla, but it works.<img loading="lazy" src="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_25.png" alt="" width="1072" height="599" srcset="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_25.png 1072w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_25-300x168.png 300w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_25-768x429.png 768w" sizes="(max-width: 1072px) 100vw, 1072px"></p>
<p>So in this situation I don’t have a lens on the front of the camera. So if the camera is going to fire without a lens on it, you have to go to the menus and you’ve have to turn on the setting which will allow the camera to fire when there’s no lens attached. There’s no coupling here. <img loading="lazy" src="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_26.png" alt="" width="1071" height="600" srcset="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_26.png 1071w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_26-300x168.png 300w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_26-768x430.png 768w" sizes="(max-width: 1071px) 100vw, 1071px">This is just a space between the lens and the front of the camera. I did have to turn that feature on that will allow me to shoot without a lens in order to make this work.</p>
<p><img loading="lazy" src="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_28.png" alt="" width="1070" height="599" srcset="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_28.png 1070w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_28-300x168.png 300w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_28-768x430.png 768w" sizes="(max-width: 1070px) 100vw, 1070px"> <img loading="lazy" src="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_29.png" alt="" width="1070" height="597" srcset="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_29.png 1070w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_29-300x167.png 300w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_29-768x429.png 768w" sizes="(max-width: 1070px) 100vw, 1070px">This lens is so interesting because it has a 180 degree angle of view. So I can get right here close and to the side and I’m in the shot. And I am in the shot when I move all the way around to the other side.</p>
<p><img loading="lazy" src="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_30.png" alt="" width="1071" height="599" srcset="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_30.png 1071w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_30-300x168.png 300w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_30-768x430.png 768w" sizes="(max-width: 1071px) 100vw, 1071px">This lens has a really strange quality because my face is in focus, but the area around it is out of focus. It almost has a tilt shift kind of quality like it’s you’re focusing on one point. <img loading="lazy" src="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_31.png" alt="" width="1072" height="599" srcset="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_31.png 1072w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_31-300x168.png 300w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_31-768x429.png 768w" sizes="(max-width: 1072px) 100vw, 1072px">When you get somebody up front like this, it gives you a blur all the way around. It’s very cool looking.</p>
<p><img loading="lazy" src="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_37.png" alt="" width="1070" height="600" srcset="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_37.png 1070w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_37-300x168.png 300w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_37-768x431.png 768w" sizes="(max-width: 1070px) 100vw, 1070px"> <img loading="lazy" src="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_38.png" alt="" width="1071" height="600" srcset="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_38.png 1071w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_38-300x168.png 300w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_38-768x430.png 768w" sizes="(max-width: 1071px) 100vw, 1071px"></p>
<p>I’m learning as we go along here, it doesn’t have a flat plane of focus, but I think that’s because of the way I mounted the camera back there. It’s a little bit like a tilt shift. So I didn’t get them quite square, which is kind of cool because I get the face in focus, but the hands or the body go out of focus in the foreground. It’s just kind of cool looking.</p>
<p><img loading="lazy" src="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_39.png" alt="" width="1067" height="596" srcset="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_39.png 1067w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_39-300x168.png 300w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_39-768x429.png 768w" sizes="(max-width: 1067px) 100vw, 1067px"></p>
<p>One of the reasons I love to carry a light in my bag is anytime I’m doing a street portrait or something, a continuous light is so easy to flip up really fast. It gives us a little bit of light on the face and opens up the shadows. The <a href="https://bhpho.to/32nCIvK">LitraStudio</a> is perfect for that because it’s easy. <img loading="lazy" src="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_40.png" alt="" width="1074" height="601" srcset="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_40.png 1074w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_40-300x168.png 300w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_40-768x430.png 768w" sizes="(max-width: 1074px) 100vw, 1074px">Turn it on and it’s so powerful, it’s worth the weight. It’s not like one of the little tiny ones Litra makes. I like the bigger heavier light because it just gives me so much more power. Especially in a situation like this where you have the sun to deal with.</p>
<p><img loading="lazy" src="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_42.png" alt="" width="1072" height="601" srcset="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_42.png 1072w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_42-300x168.png 300w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_42-768x431.png 768w" sizes="(max-width: 1072px) 100vw, 1072px"></p>
<p>So there you have it. I’m going to do more of this. <img loading="lazy" src="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_44.png" alt="" width="1072" height="602" srcset="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_44.png 1072w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_44-300x168.png 300w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_44-768x431.png 768w" sizes="(max-width: 1072px) 100vw, 1072px">I want to adapt some other lenses to my EOS R and just try to get weird views and that kind of gritty look. This actually was way cleaner than I thought it was going to be. <img loading="lazy" src="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_46.png" alt="" width="1071" height="600" srcset="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_46.png 1071w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_46-300x168.png 300w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_46-768x430.png 768w" sizes="(max-width: 1071px) 100vw, 1071px">I don’t even have something blocking the light between the camera and the lens. I used just a little bit of tape in here. But it projects a great image on the sensor. It’s a little hard to focus but a lot of fun to shoot. <img loading="lazy" src="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_48.png" alt="" width="1071" height="600" srcset="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_48.png 1071w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_48-300x168.png 300w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_48-768x430.png 768w" sizes="(max-width: 1071px) 100vw, 1071px">So I hope you enjoyed this. Make sure you subscribe to the channel and ring that bell. Keep those cameras rollin’ and keep on clickin’.</p>
<p>Check out <a href="https://bhpho.to/32nCIvK">LitraStudio lights</a>:</p>
<p><img loading="lazy" src="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_50.png" alt="" width="1073" height="599" srcset="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_50.png 1073w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_50-300x167.png 300w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_50-768x429.png 768w" sizes="(max-width: 1073px) 100vw, 1073px"> <img loading="lazy" src="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_51.png" alt="" width="1070" height="600" srcset="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_51.png 1070w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_51-300x168.png 300w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_51-768x431.png 768w" sizes="(max-width: 1070px) 100vw, 1070px"> <img loading="lazy" src="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_52.png" alt="" width="1072" height="597" srcset="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_52.png 1072w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_52-300x167.png 300w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_52-768x428.png 768w" sizes="(max-width: 1072px) 100vw, 1072px"> <img loading="lazy" src="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_53.png" alt="" width="1071" height="598" srcset="https://theslantedlens.com/wp-content/uploads/2021/01/Imax_53.png 1071w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_53-300x168.png 300w, https://theslantedlens.com/wp-content/uploads/2021/01/Imax_53-768x429.png 768w" sizes="(max-width: 1071px) 100vw, 1071px"></p>
<!-- AddThis Advanced Settings above via filter on the_content --><!-- AddThis Advanced Settings below via filter on the_content --><!-- AddThis Advanced Settings generic via filter on the_content --><!-- AddThis Share Buttons above via filter on the_content --><!-- AddThis Share Buttons below via filter on the_content --><!-- AddThis Share Buttons generic via filter on the_content --><!-- AddThis Related Posts below via filter on the_content --><!-- AddThis Related Posts generic via filter on the_content --><!--<rdf:RDF xmlns:rdf="http://www.w3.org/1999/02/22-rdf-syntax-ns#"
			xmlns:dc="http://purl.org/dc/elements/1.1/"
			xmlns:trackback="http://madskills.com/public/xml/rss/module/trackback/">
		<rdf:Description rdf:about="https://theslantedlens.com/2021/crazy-huge-imax-lens-amazing-street-portraits/"
    dc:identifier="https://theslantedlens.com/2021/crazy-huge-imax-lens-amazing-street-portraits/"
    dc:title="Crazy Huge Imax Lens &#8211; Amazing Street Portraits"
    trackback:ping="https://theslantedlens.com/2021/crazy-huge-imax-lens-amazing-street-portraits/trackback/" />
</rdf:RDF>-->
</div></article></div>]]>
            </description>
            <link>https://theslantedlens.com/2021/crazy-huge-imax-lens-amazing-street-portraits/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25666217</guid>
            <pubDate>Thu, 07 Jan 2021 01:50:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[A developer's perspective: the problem with screen reader testing]]>
            </title>
            <description>
<![CDATA[
Score 69 | Comments 52 (<a href="https://news.ycombinator.com/item?id=25665851">thread link</a>) | @jacobtracey
<br/>
January 6, 2021 | https://jaketracey.com/a-developers-perspective-the-problem-with-screen-reader-testing/ | <a href="https://web.archive.org/web/*/https://jaketracey.com/a-developers-perspective-the-problem-with-screen-reader-testing/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article itemscope="" itemtype="http://schema.org/Article"><header><p>January 06, 2021</p></header><section itemprop="articleBody"><p>Screen readers are an essential part of using the web for people who are vision impaired, illiterate or have a learning disability.</p>
<p>Today’s screen readers traverse web pages and applications and read out user interface elements, content and allow users to navigate and interact with the web.</p>
<p>There are many screen readers available for different devices and platforms, each with differing levels of functionality, interfaces and features. The most common are JAWS, NVDA, VoiceOver and TalkBack.</p>
<p>According to the latest <a href="https://webaim.org/projects/screenreadersurvey8/">WebAIM Screen Reader User Survey</a>, when it comes to desktop screen reader usage, JAWS and NVDA are practically equal in usage, with around 40% of respondents reporting that they use one or the other.</p>
<figure>
<img src="https://jaketracey.com/webaim-graph.png" alt="Line chart of primary screen reader usage since October 2009. JAWS has steady decline from 68% to 40%. NVDA has steady incline from 3% to 41%. VoiceOver has a slow incline from 10% to 13%.">
<figcaption>Source: WebAIM</figcaption>
</figure>
<p>Based on the graph above, there’s a clear pattern over the course of the last 10 years, with NVDA usage increasing as JAWS usage drops, culminating in an inflection point in 2019 when NVDA surpassed JAWS usage for the first time.</p>
<p>As a developer regularly faced with time constraints, I have often wondered: what should be the baseline in terms of testing for screen readers, and what browser and screen reader combinations are the most important to cover in order to achieve the greatest level of WCAG compliance?</p>
<h2>An issue of time</h2>
<p>Given that almost all web applications developed in 2021 are also used on mobile and therefore require testing on both iOS and Android devices, as well as Windows and macOS for desktop users, providing adequate support for such a broad range of scenarios becomes quite difficult to manage.</p>
<p>Let’s say in a best-case scenario, a given page or feature will be tested on the following combinations:</p>
<ul>
<li>iOS / VoiceOver</li>
<li>Android / TalkBack</li>
<li>macOS / Chrome / VoiceOver</li>
<li>macOS / Safari / VoiceOver</li>
<li>macOS / Firefox / VoiceOver</li>
<li>Windows / Microsoft Edge / NVDA</li>
<li>Windows / Chrome / NVDA</li>
<li>Windows / Firefox / NVDA</li>
<li>Windows / Microsoft Edge / JAWS</li>
<li>Windows / Chrome / JAWS</li>
<li>Windows / Firefox / JAWS</li>
</ul>
<p>I should clarify that by “best-case”, I am conveniently leaving out any versions of Internet Explorer, but as frustrating as it may be, including it would add at least another 2 rounds of testing.</p>
<p>It’s also worth noting that WebAIM also recommends using Microsoft Edge with Narrator, but given its low usage, we’ll leave it out (more on this later).</p>
<p>Hypothetically, depending on the size of the functionality or page implemented, let’s say each round of testing takes one hour to complete, assuming the developer has experience with each of these browsers and screen readers.</p>
<p>In this scenario, comprehensively testing screen reader support across all these combinations adds 11 hours of development work – and that’s just to test!</p>
<h2>An issue of fragmentation</h2>
<p>Web developers will be familiar with the issues surrounding browser version fragmentation, and this problem is compounded when testing with screen readers. Contending with not only varying levels of HTML, Javascript and CSS support in the browser can be tough, and to combat this, polyfills and tools like <a href="https://caniuse.com/">caniuse.com</a> have made life a lot easier.</p>
<p>When it comes to screen reader version fragmentation, there is very little in the way of either documentation or support for developers. Fixing issues often comes down to a case of trial and error, retesting and hoping for the best.</p>
<p>A piece of information that would be incredibly useful in this area would be <em>penetration of screen reader updates</em> from the vendors. If, for instance, developers knew that there was a high adoption rate of updates among screen reader users, they could be confident that if a screen reader update resolved an issue, patches for older versions could be sunsetted. This approach has worked exceptionally well for browsers such as Chrome and Firefox.</p>
<p>Sadly, there’s not currently any way for a developer to identify the type or version of a screen reader that is being used, so implementing targeted fixes isn’t an option anyway right now.</p>
<h2>A case for dedicated accessibility testers</h2>
<p>Given the scope and time it takes to properly test across so many devices, browsers and screen readers, having dedicated accessibility testers embedded into teams can significantly increase the quality and speed with which properly accessible applications can be produced.</p>
<p>Let’s face it: developers already have a hard time keeping up with the pace of change in their own domain, let alone the level of knowledge required for comprehensive accessibility auditing.</p>
<p>That is not to say that developers should ignore accessibility completely. However, expecting someone to know about a specific bug on a particular combination of code, browser and screen reader is too much, even for the most experienced accessibility-focused developer.</p>
<h2>Why automation isn’t enough</h2>
<p>The old saying "a good programmer is a lazy programmer" comes to mind when I think about testing here. Being lazy myself (although possibly not that great of a programmer), I rely on automated tools like <a href="https://www.deque.com/axe/">axe</a> to do most of my accessibility for me. While the current range of tooling is excellent, and picks up the most obvious issues, when it comes to screen readers there’s no way around it: you need to manually test.</p>
<p>Why? Well, the current state of both browsers and screen reader support is all over the place. To highlight this, the Powermapper website has a neat <a href="https://www.powermapper.com/tests/screen-readers/aria/">list of screen reader support for WAI-ARIA attributes</a>. Not throwing shade at any one – things are continuously improving with updates to browsers and screen readers – but the point stands. Current automated testing tools are not going to catch these problems because they essentially test the validity of code, in much the same way as a code linter does.</p>
<h2>A compromise, so we can all still get stuff done</h2>
<p>Not every team has the luxury of a dedicated accessibility tester, or even a dedicated tester for that matter. Sometimes, you just need to do the best you can, with the resources that you have available.</p>
<p>"When can we stop supporting this?" has been the desperate cry of developers for years when it comes to Internet Explorer 9/10 and most recently 11, and as their usage has dropped, so has the rate of developers losing their hair trying to get their code working.</p>
<p>Which brings me back to Microsoft Edge with Narrator, as mentioned earlier. With 1% of users in that survey, and possibly 0% of users for your application or site, is it worth testing on this combination at all? More specifically, what number of users justifies support, and the testing and development overhead that comes with it?</p>
<h3>Windows - Chrome (latest version), NVDA</h3>
<p>As of December 2020, Chrome is by far the most popular browser in the world, with 65.3% of users. Later versions of Microsoft Edge utilize the same rendering engine, so there is a high likelihood that if it works in Chrome, it will work similarly in Edge.</p>
<p>Based on the WebAIM stats, it is a safe bet that NVDA will begin to increase its lead over JAWS over the next few years. Given that it is also open-source and free, I can’t help but draw a comparison to the way Firefox overtook Internet Explorer in the 2000s browser wars.</p>
<h3>macOS - Safari (latest version), VoiceOver</h3>
<p>Safari is a fair distance behind Chrome in terms of users, with 16.7% share as of writing, but it has the benefit of being the default browser in macOS. It is also free, and the support for accessibility features with VoiceOver is second to none. In addition to this, because of the similarity with its mobile counterpart, most likely any issues that are identified in the desktop version will have similar fixes.</p>
<h3>iOS - Safari (latest version), VoiceOver</h3>
<p>Safari is by far the most popular browser on iOS and all other browsers on iOS use the WebKit rendering engine. VoiceOver is the gold standard for mobile screen readers (and the only option for iOS devices), and as such it makes sense to use this combination for testing iOS accessibility.</p>
<h3>Android - Chrome (latest version), TalkBack</h3>
<p>In a similar vein to iOS, being the default browser and screen reader combination for Android makes this a simple choice, as it will cover the vast majority of users on this platform. Although manufacturers do include their own browsers and there are quite a few other options on Android, the vast majority of the time they use the inbuilt rendering engine, so the expectation in terms of accessibility should be similar, if not identical, to the Chrome experience.</p>
<p>This is by no means a catch-all solution for everyone. Each circumstance will be different, and the best course of action would be to engage your users and ask rather than trying to make the decision for them.</p>
<p>The reality is that if your site or application’s design or functionality looks bad or works poorly for a large enough number of your users because it does not support the software that they use, it can have potential ramifications to your business, through sales or reputation. Similarly, poor accessibility will have a negative impact if your users are using older versions of screen readers and browser combinations.</p>
<h2>But what about JAWS, ZoomText, System Access, <em>insert screen reader here</em>?</h2>
<p>At the risk of being slightly incendiary, I dislike the idea of paying for something that I can get for free. NVDA is a project that has brought screen readers to everybody – including those without the financial means to pay for it – so I support it. Along with the clear trajectory of its usage uptake, it is not unreasonable to expect that the majority of users will adopt it in the next 5 to 10 years.</p>
<p>At the end of the day, however, your best bet when it comes to identifying where your testing efforts should be placed is to talk to your users to find out what their needs are and what software they use. If you don’t have access to this information, the proposed testing scope above will suffice for the vast majority of your site or application’s users, and most likely will continue to do so in the years to come.</p></section></article></div>]]>
            </description>
            <link>https://jaketracey.com/a-developers-perspective-the-problem-with-screen-reader-testing/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25665851</guid>
            <pubDate>Thu, 07 Jan 2021 01:12:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Love’s contradictions: Catullus on the agony of infatuation]]>
            </title>
            <description>
<![CDATA[
Score 50 | Comments 10 (<a href="https://news.ycombinator.com/item?id=25664867">thread link</a>) | @diodorus
<br/>
January 6, 2021 | https://psyche.co/ideas/loves-contradictions-catullus-on-the-agony-of-infatuation | <a href="https://web.archive.org/web/*/https://psyche.co/ideas/loves-contradictions-catullus-on-the-agony-of-infatuation">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><blockquote>I hate and love. If you ask me to explain<br>The contradiction,<br>I canâ€™t, but I can feel it, and the pain<br>Is crucifixion.</blockquote>
<blockquote> <em>Odi et amo: quare id faciam fortasse requiris.</em><br><em>Nescio, sed fieri sentio et excrucior.</em> </blockquote>
<p><strong>This simple but heartfelt</strong> couplet (translation above by James Michie in 1969) is the best-known Latin love epigram â€“ a short poem in elegiac metre â€“ that survives from Ancient Rome. Composed by the poet Catullus around <span>55 BCE,</span> <span>number 85</span> of his book of <span>116 poems,</span> it pithily encapsulates the searing conflict of emotions that he claims to be experiencing in the course of his affair with a younger married woman, who is addressed in other poems as his â€˜girlâ€™ (<em>puella</em>) and by the pseudonym â€˜Lesbiaâ€™. But for such a short poem â€“ just 14 words in Latin â€“ it has raised a whole host of questions, and hundreds of pages have been written about it. What is the point of the poem? How should it be translated from the Latin? How does it relate to the poetâ€™s life and feelings? Its psychology comes across as complex and strikingly modern, as does much of Catullusâ€™s poetry; to some, the questions it raises might seem more suited to a post-FreudÂ­ian examination of mental conflict than to the concerns of an ancient poet. We might recognise that the opposite emotions of love and hate can be simultaneously entertained; but how, after all, does that work?</p>
<p>In its original Latin, <span>Poem 85</span> is a so-called elegiac couplet, in which a longer line (hexameter) is followed by a shorter one (pentameter). The words of the poem have been placed with care. The couplet is composed in a criss-cross pattern, beginning and ending with two verbs of intense emotional connotation: <em>odi</em>, â€˜I hateâ€™; and <em>excrucior</em>, â€˜Iâ€™m rackedâ€™. The first line concludes with the questÂ­ioning <em>requiris</em>, â€˜you askâ€™; the second opens with the answer <em>nescio</em>, â€˜I donâ€™t knowâ€™. The middle of the first line has <em>faciam</em>, â€˜I doâ€™; the middle of the second has its passive counterÂ­part <em>fieri</em>, â€˜is being doneâ€™ (related to <em>fiat</em> â€“ literally, â€˜let it be doneâ€™).</p>
<p>The couplet thus mimics by its shape the image of the poet being pulled apart in opposite directions, an image made explicit by the verb <em>excrucior</em>. That word (the root of our â€˜excruciatingâ€™) will have evoked for Romans the noun <em>crux</em> (plural <em>cruces</em>). Although in the <span>1st millennium CE</span> <em>crux</em> came to be heard almost exclusively to mean â€˜crossâ€™ with reference to the crucifixion of Christ, in CatullÂ­usâ€™s time it was more commonly used to signify the â€˜rackâ€™. This was the standard instrument of torture in the Roman world, to which unfortÂ­unate victims were bound by their hands and legs so that their bodies might literally be pulled apart.</p>
<p>While Catullus remains utterly infatuated with Lesbia, she has proved to be <br>distressÂ­ingly fickle to him</p>
<p>No less cruel and visible as a method of executÂ­ion in the Roman world was crucifixion. Catullus was in his teens when in <span>71 BCE</span> the slave-revolt led by Spartacus was quelled, and he would probably have witnessed at first hand the gruesome sight of 6,000 captured slaves being nailed or strung up to die on wooden crosses along the Appian Way leading from Rome to Capua. WhatÂ­ever the precise image intended by Catullus as a parallel to his own feeling of torment, what is evident is that the combination of hate and love, pulling him in different directions, is making him feel as if he is being â€˜racked to deathâ€™: the <em>ex</em> of <em>excrucÂ­ior</em> connotes a process leading towards expiry and extinction, as well as extenÂ­sion â€“ both in time and across space. Moreover, Catullus claims, thereâ€™s nothing he can <em>do</em> about it: heâ€™s simply the object of this torturous and self-contradictory feeling. His response to someone who might wish to enquire (<em>requiÂ­ris</em>) about what heâ€™s â€˜doingâ€™ (<em>faciam</em>) is that heâ€™s not â€˜doingâ€™ anything, but that he senses (<em>sentio</em>) it â€˜being doneâ€™ (<em>fieri</em>) to him: the passive form of the verb corresÂ­ponds to his own passivÂ­ity in the process heâ€™s describing.</p>
<p>However, just before Catullus presents himself as the helpless victim of opposing emotÂ­ions, the answer he gives to the imagined question is unequivocal: â€˜I donâ€™t knowâ€™. The implication of <em>nescio</em> (the negative of <em>scio</em>, â€˜knowâ€™, whence comes our word â€˜scienceâ€™) has been overlooked by generations of translators from the Latin, who have rendered the word <em>quare</em> as â€˜whyâ€™ or â€˜the reason whyâ€™ rather than â€˜howâ€™ â€“ even though itâ€™s clear that Catullus does know, as do his readÂ­ers, why or for what reason heâ€™s prey to emotional conflict. For instance, one of the poemâ€™s earliest English transÂ­lators, the poet Richard Lovelace (1617-57), renders it as:</p>
<blockquote>I hate and love; wouldâ€™st thou the reason know?<br>I know not, but I burn, and feel it so.</blockquote>
<p>Similarly, the translator in the popular Loeb series, which prints classical texts with facing versions in straightforward English, in 1976 had it as:</p>
<blockquote>I hate and love. Why I do so, perhaps you ask? <br>I know not, but I feel it, and I am in torment.</blockquote>
<p>Such translations using â€˜whyâ€™ followed by â€˜I donâ€™t knowâ€™ ask us to suppÂ­ose that Catullus is claiming an inability to understand the reason for his painful emotional turmoil. Yet the poet has already made it abundantly clear, in several other poems describing his affair with Lesbia, that he knows the reason only too well: while he remains utterly infatuated with her, she has proved distressÂ­ingly fickle to him, willing to be unfaithful not only to her husband but to her adultÂ­erous liaison with the poet too. In <span>Poem 72</span> (my translation), Catullus analyses the effect on him of Lesbiaâ€™s infidelity:</p>
<blockquote>You used to say you had eyes for Catullus alone, <br>Lesbia, and would rather hold me in your arms than Jove. <br>My feelings for you then were not just vulgar lust,<br>but the kind of love a father feels for his children and their kin. <br>Now that I know your ways, my desire for you burns ever fiercer,<br>even though youâ€™re far shabbier in my eyes, and flightier. <br>How can this be, you say: itâ€™s because such hurtful treatment <br>is bound to make one desire oneâ€™s lover more, but like them less.</blockquote>
<p>How is it possible, in terms of logic or emotion, to feel both hate and love towards the same person at the same time?</p>
<p>In the final couplet here, Catullus explains to the reader, in terms very similar to those he uses in <span>Poem 85,</span> the paradox of his feelings. The enquirer doesnâ€™t need to ask the cause of the poetâ€™s pain, here described as <em>iniuria</em> (â€˜hurtful treatmentâ€™) because itâ€™s easy to understand: Catullus is wounded by Lesbiaâ€™s sexual intimacy with other lovers and hotly resents her behaviour; but his desire for her, perhaps intensified by the prospect of losing her to a love-rival, is even stronger.</p>
<p><strong>The reader might still </strong>ask how such divergent feelings as love and dislike can coexist in a lover and be directed towards the same object â€“ indeed, the final line above describes someÂ­thing that feels like such an emotional contradiction, the combinÂ­ation of desire with disliking. That divergence is, in <span>Poem 85,</span> yet more starkly expressed with â€˜I hate and loveâ€™ (rendered more emphatically in translations that repeat the â€˜Iâ€™: â€˜I hate and I loveâ€™). But, again, Catullus would expect the reader to ask not â€˜whyâ€™, but â€˜howâ€™; that is, how is it possible, whether in terms of logic or emotion, for someone to feel both hate and love towards the same person at the same time? Since Catullus knows, as do his readers, <em>why</em> heâ€™s prey to these contradictory feelings, only in answer to the question â€˜howâ€™ can it be reasonable for him to follow up, as he does, with â€˜I donâ€™t knowâ€™. Having declared his ignorance of how the perplexing phenomenon of simultaneous opposing emotions can arise, he then abandons analysis and simply testifies to his own torment.</p>
<p>The correctness of the translation of <em>quare</em> as â€˜howâ€™ is confirmed by lexical data. In Catullusâ€™s time and before (as found, for example, in passages written by Catullusâ€™s older contempÂ­orary, the orator Cicero) <em>quare</em> is used to mean â€˜howâ€™ or â€˜in what wayâ€™. It comes to mean â€˜whyâ€™ in the course of the languageâ€™s histÂ­Â­ory; but given the compelling contextual and linguistic arguments for the understanding of what Catullus is asking in <span>Poem 85,</span> what explanation can there be for the persistÂ­ent mistranslation of <em>quare</em> as â€˜whyâ€™ rather than as â€˜howâ€™ in English? (TransÂ­lations into other languages such as Italian, German and French also tend to fluctuate between rendering <em>quare</em> as â€˜whyâ€™ and â€˜howâ€™).</p>
<p>One answer must be that translators have been influenced by a later Latin couplet thatâ€™s as famous as Catullusâ€™s, and indeed alludes to it. A satirical squib <span>(number 32)</span> composed by the poet Martial in the late <span>1st century CE,</span> more than <span>100 years</span> after Catullusâ€™s death, uses the same couplet form:</p>
<blockquote>I donâ€™t like you, Sabidius, and Iâ€™m unable to say why:<br>All I can say is this: I donâ€™t like you.</blockquote>
<blockquote> <em>Non amo te, Sabidi, nec possum dicere quare: </em><br><em>Hoc tantum possum dicere: non amo te</em>.</blockquote>
<p>Nothing is known of the context of the epigram or of the implied feud between the poet and the otherwise unknown Sabidius. But the poem has won a firm, if anecdotal, place in the annals of Latin studies in England. The story (undoubÂ­tedly apocryphal) is told how, as a student at Christ Church College, Oxford, the writer Thomas Brown (1662-1704) committed a misdeÂ­meanour and was sent for punishment to the college dean, a <span>Dr Fell.</span> The dean required Brown to transÂ­late some Latin verse on the spot, and opened a book of epigrams at random to present him with Martialâ€™s couplet. After a momentâ€™s thought, Brown recited, allegedly to the deanâ€™s delight, his witty and memorable version of the poem:</p>
<blockquote>I do not like thee, Doctor Fell, <br>The reason why I cannot tell; <br>But this I know, and know full well, <br>I do not like thee, Doctor Fell.</blockquote>
<p>In the case of Martialâ€™s epigram, â€˜the reason whyâ€™ is a …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://psyche.co/ideas/loves-contradictions-catullus-on-the-agony-of-infatuation">https://psyche.co/ideas/loves-contradictions-catullus-on-the-agony-of-infatuation</a></em></p>]]>
            </description>
            <link>https://psyche.co/ideas/loves-contradictions-catullus-on-the-agony-of-infatuation</link>
            <guid isPermaLink="false">hacker-news-small-sites-25664867</guid>
            <pubDate>Thu, 07 Jan 2021 00:15:08 GMT</pubDate>
        </item>
    </channel>
</rss>
