<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 20]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 20. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Sat, 27 Jun 2020 04:16:55 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-20.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Sat, 27 Jun 2020 04:16:55 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[3K, 60fps, 130ms: achieving it with Rust]]>
            </title>
            <description>
<![CDATA[
Score 32 | Comments 22 (<a href="https://news.ycombinator.com/item?id=23649534">thread link</a>) | @lukastyrychtr
<br/>
June 26, 2020 | https://blog.tonari.no/why-we-love-rust?ref=twtr | <a href="https://web.archive.org/web/*/https://blog.tonari.no/why-we-love-rust?ref=twtr">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>How we chose the Rust programming language to advance the state-of-the-art in real-time communication</p><div><p><i>T</i><m><i>his post was written collectively with Ryo Kawaguchi, </i></m><m><m><i>Andrea Law, Brian Schwind</i></m></m><m><i>.</i></m></p><p><m>Our goal for tonari is to build a virtual doorway to another space that allows for truly natural human interactions. Nearly two years in development, tonari is, to the best of our knowledge, the lowest-latency high resolution production-ready "teleconferencing" (we are truly not fond of that word) product available. </m></p><ul><li><b>130ms</b> glass-to-glass latency (the time from light hitting the camera to when it appears on-screen on the other side)</li><li><b>3K, 60fps</b> video transmission</li><li>High-bitrate 48kHz stereo audio</li></ul><p>Compare this to the typical <b>315-500ms</b> latency for Zoom and <m>WebRTC</m>, as measured between two laptops (X1 Carbon and MacBook Pro) on the same network at our office. It's a huge difference. It's the difference between constantly interrupting each other versus having a natural flow of conversation. It's the difference between a blurry face from a camera seemingly pointed up someone's nose versus a wide-view high fidelity image that smoothly transfers all the subtle body language of an in-person conversation.</p><div><picture><source srcset="https://blog.tonari.no/images/ea56c74d-a55d-4183-9a7b-d697954c5159-tonari-frontier-2.png.optimized.webp" type="image/webp"><source srcset="https://blog.tonari.no/images/ea56c74d-a55d-4183-9a7b-d697954c5159-tonari-frontier-2.png.optimized.jpg"><img src="https://blog.tonari.no/images/ea56c74d-a55d-4183-9a7b-d697954c5159-tonari-frontier-2.png.optimized.jpg"></picture></div><p>Since launching <a href="https://blog.tonari.no/changing-communication-and-culture-in-an-organization" rel="noopener" target="_blank">our first pilot</a> in February, we've experienced no software-related downtime (tripping over ethernet cables is a different story). A<m>nd as much as we would love to think we're infallible engineers, we truly don't believe we could have achieved these numbers with this level of stability without Rust.</m></p><a href="#in-the-beginning-(or-why-we're-not-webrtc)" id="in-the-beginning-(or-why-we're-not-webrtc)"><h2>In the beginning (or: why we're not WebRTC)</h2></a><p>The <m>very</m> first tonari proof-of-concept used a basic projector, bluetooth speakers, and a website running on top of vanilla WebRTC (JavaScript). We've come a long way since those days.</p><p>While that prototype (and our opinionated vision of the future) got us grant funding, we knew that tonari would be dead on arrival unless we could<m> achieve </m><i>significantly</i> lower latency and higher fidelity than <m>WebRTC</m>—two things that aren't currently associated with video chat in 2020.</p><p>We figured, “Okay<i>, so we can just </i><m><i>modify</i></m><i> WebRTC directly and wrap it up with a slick UI in C++ and launch it in no time</i>.”</p><p>A week of struggling with WebRTC’s nearly 750,000 LoC <i>behemoth</i> of a codebase revealed just how painful a single small change could be — how hard it was to test, and feel truly <i>safe,</i> with the code you were dealing with.</p><a href="#let-there-be-light...weight-code" id="let-there-be-light...weight-code"><h3>Let there be light...weight code</h3></a><p>So in a furious (read: calm and thoroughly-discussed) rage quit we decided it was easier to re-implement the whole stack from scratch. We wanted to <i>know and understand every line of code</i> being run on our hardware, and it should be designed for the <i>exact</i> hardware we wanted.</p><p>Thus began our journey to the depths beyond high-level interfaces like a browser or existing RTC project, and into the world of low-level systems and hardware interaction from scratch.</p><p>We needed it to <m>be inherently </m><b><m><i>secure</i></m></b><m> to </m>protect the privacy of those who use tonari.  We needed it to be <b><i>performant</i></b> to make it feel as human and real-time as possible.  And we needed it to be <b><i>maintainable</i></b> as the code becomes more mature, as new brains show up and have to learn our work and expand on it.</p><p><m>We discussed and ruled out a handful of alternative approaches:</m></p><ul><li><b><i>Security: </i></b>C and C++ are memory- and concurrency-unsafe, and their disparate and seemingly infinite build systems make it hard to have a consistent and simple development experience.</li><li><i><b>Performance: </b></i>Java, <m>C#, and Go'</m>s memory management is opaque and can be difficult to work with in latency-sensitive applications where you want full control over your memory.</li><li><i><b>Maintainability: </b></i>Haskell, Nim, D, and a handful of other more bespoke languages tend to be more limited in tooling, community, and hire-ability.</li></ul><p>Rust is really the only production-ready language that we found confidently satisfies these needs.</p><a href="#finding-beauty-in-rust" id="finding-beauty-in-rust"><h2>Finding beauty in Rust</h2></a><p>Rust's beauty lies in the countless decisions made by the development community that constantly make you feel like you <m>can have</m> ten cakes and eat all of them too.</p><ul><li>Its build system is opinionated, and cleanly designed. It is itself a complete ecosystem that makes introducing new engineers to your project and setting up dev environments remarkably simple.</li><li>The memory and concurrency safety guarantees cannot be over-appreciated. We're confident that we wouldn't have done our first deployment yet if we had continued this in C++ - we'd still probably be stuck on subtle snags.</li><li>Our ability to interact at the lowest level with hardware via APIs like CUDA, oftentimes through existing <a href="https://crates.io/" rel="noopener" target="_blank"><m>crates</m></a> (Rust's term for a code library), has allowed us to have higher standards about the latency we want from our first production release.</li></ul><p>As tonari is getting more advanced, we're now choosing embedded microcontrollers whose firmware can be written in Rust so we don't have to leave our idyllic utopia into the old world of unsafe system programming.</p><a href="#crates-we-rely-on" id="crates-we-rely-on"><h2>Crates we rely on</h2></a><p>We're not going to <code>cat Cargo.toml</code> here, instead focusing on some select crates that have earned the prestigious award of a lifetime invitation to each of our birthday parties forever.</p><a href="#&quot;better-than-std&quot;-crates" id="&quot;better-than-std&quot;-crates"><h3>"Better-than-std" crates</h3></a><ul><li><a href="https://github.com/crossbeam-rs/crossbeam" rel="noopener" target="_blank"><code>crossbeam</code></a> is better for inter-thread communication than <code>std::sync::mpsc</code> in almost every way, and may be merged into <code>std</code> eventually.</li><li><a href="https://github.com/Amanieu/parking_lot" rel="noopener" target="_blank"><code>parking_lot</code></a> has a mutex implementation better than <code>std::sync::Mutex</code> in almost every way, and may be merged into the standard library (one day). It also provides many other useful synchronization primitives.</li><li><a href="https://github.com/tokio-rs/bytes" rel="noopener" target="_blank"><code>bytes</code></a> is a more robust, and often more performant, way to play with bytes compared to <code>Vec&lt;u8&gt;</code>.</li><li><a href="https://github.com/alexcrichton/socket2-rs" rel="noopener" target="_blank"><code>socket2</code></a> is what you will end up at if you are ever doing lower-level networking optimizations.</li></ul><a href="#beauty-supply" id="beauty-supply"><h3>Beauty supply</h3></a><ul><li><a href="https://github.com/daboross/fern" rel="noopener" target="_blank"><code>fern</code></a> is a dead-simple way to customize and prettify your logging output. We use it to keep our logs readable and internally standardized.</li><li><a href="https://github.com/TeXitoi/structopt" rel="noopener" target="_blank"><code>structopt</code></a> is how you always dreamed CLI arguments would be handled. There's no reason not to use it unless you're going for bare-minimum dependencies.</li></ul><a href="#cargo-cult-classics" id="cargo-cult-classics"><h3>Cargo cult classics</h3></a><ul><li><a href="https://github.com/sunng87/cargo-release" rel="noopener" target="_blank"><code>cargo-release</code></a> allows us to cut internal releases painlessly.</li><li><a href="https://github.com/est31/cargo-udeps" rel="noopener" target="_blank"><code>cargo-udeps</code></a> identifies unused dependencies and allows us to keep our build times minimal.</li><li><code>cargo tree</code> (recently integrated in cargo) shows a dependency tree that's useful in many ways, but <m>mainly</m> in identifying ways to minimize dependencies.</li><li><a href="https://github.com/rust-secure-code/cargo-geiger" rel="noopener" target="_blank"><code>cargo-geiger</code></a> helps us quickly evaluate external dependencies for possible security (or correctness) concerns.</li><li><a href="https://github.com/flamegraph-rs/flamegraph" rel="noopener" target="_blank"><code>cargo-flamegraph</code></a> helps us enormously when tracking down performance hot-spots in our code.</li></ul><a href="#project-structure" id="project-structure"><h2>Project structure</h2></a><p>The tonari codebase is a monorepo. At its root we have a Cargo workspace with a <code>binaries</code> crate, and a number of supporting library crates.</p><p>Having our crates in one repo makes them easy to reference in our <code>binaries</code> crate without needing to publish to <a href="https://crates.io/" rel="noopener" target="_blank">crates.io</a> or get too fancy with specifying git dependencies in our <code>Cargo.toml</code>. When the time comes to publish these libraries as open source, it's trivial to break it out into its own repo.</p><a href="#library,-binary,-why-not-both" id="library,-binary,-why-not-both"><h3>Library, binary, why not both?</h3></a><p>We have one main library crate that contains a unified API for talking to hardware, media codecs, network protocols, etc. Outside of that private API, we also have standalone crates in our workspace that we consider candidates for open-sourcing. For example, we’ve written our own actor framework fit for long-running high-throughput actors, as well as our own network protocol for reliable, high-bandwidth, low-latency media streaming.

We use separate binaries for different parts of the tonari system and each of these lives in <code>binaries</code>, a combination library/binary crate. Its library modules contains a set of reusable actors that combine our private API with our actor system, and then a collection of individual binaries that consume these actors and define the plumbing between them.</p><a href="#flags-as-far-as-the-eye-can-see" id="flags-as-far-as-the-eye-can-see"><h3>Flags as far as the eye can see</h3></a><p>We make extensive use of feature flags to allow development of our project on different OSes (like Brian's 1970s-era MacBook Pro) or different hardware configurations. This allows us to easily swap out camera hardware without extra runtime checks or using awful <code>sed</code> hacks.

For example, Linux uses <code>v4l2</code> (Video For Linux...2) to access most webcams, but other webcams might have their own SDK.  To compile for platforms that don't use <code>v4l2</code> or when an SDK isn't available for a particular OS, we can put those SDKs behind feature flags and export a common interface.

As a (simplified) concrete example, let's say we have a common camera interface defined as a trait:</p><pre><code><span>pub</span> <span>trait</span> Capture <span>{</span>
    
    <span>fn</span> <span>capture</span><span>(</span><span>&amp;</span><span>mut</span> <span>self</span><span>)</span> <span>-&gt;</span> Vec<span>&lt;</span>u8<span>&gt;</span><span>;</span>
<span>}</span></code></pre><p>Let's also say we have three different camera interfaces - <code>v4l2</code>, <code>corevideo</code>, and <code>polaroid.</code> We can make our binaries work exclusively with this trait to be flexible, and we can swap in different implementations of <code>Capture</code> with feature flags.</p><pre><code><span>#[cfg(feature = "v4l2")]</span>
<span>mod</span> v4l2 <span>{</span>
    <span>pub</span> <span>struct</span> V4l2Capture <span>{</span>
        <span>...</span>
    <span>}</span>

    <span>impl</span> Capture <span>for</span> V4l2Capture <span>{</span>
        <span>fn</span> <span>capture</span><span>(</span><span>&amp;</span><span>mut</span> <span>self</span><span>)</span> <span>-&gt;</span> Vec<span>&lt;</span>u8<span>&gt;</span> <span>{</span>
            <span>...</span>
        <span>}</span>
    <span>}</span>
<span>}</span>

<span>#[cfg(feature = "corevideo")]</span>
<span>mod</span> corevideo <span>{</span>
    <span>pub</span> <span>struct</span> CoreVideoCapture <span>{</span>
        <span>...</span>
    <span>}</span>

    <span>impl</span> Capture <span>for</span> CoreVideoCapture <span>{</span>
        <span>fn</span> <span>capture</span><span>(</span><span>&amp;</span><span>mut</span> <span>self</span><span>)</span> <span>-&gt;</span> Vec<span>&lt;</span>u8<span>&gt;</span> <span>{</span>
            <span>...</span>
        <span>}</span>
    <span>}</span>
<span>}</span>

<span>#[cfg(feature = "polaroid")]</span>
<span>mod</span> polaroid <span>{</span>
    <span>pub</span> <span>struct</span> PolaroidCapture <span>{</span>
        <span>...</span>
    <span>}</span>

    <span>impl</span> Capture <span>for</span> PolaroidCapture <span>{</span>
        <span>fn</span> <span>capture</span><span>(</span><span>&amp;</span><span>mut</span> <span>self</span><span>)</span> <span>-&gt;</span> Vec<span>&lt;</span>u8<span>&gt;</span> <span>{</span>
            <span>...</span>
        <span>}</span>
    <span>}</span>
<span>}</span>

<span>#[cfg(feature = "v4l2")]</span>
<span>pub</span> <span>type</span> VideoCapture <span>=</span> v4l2<span>::</span>V4l2Capture<span>;</span>

<span>#[cfg(feature = "corevideo")]</span>
<span>pub</span> <span>type</span> VideoCapture <span>=</span> corevideo<span>::</span>CoreVideoCapture<span>;</span>

<span>#[cfg(feature = "polaroid")]</span>
<span>pub</span> <span>type</span> VideoCapture <span>=</span> polaroid<span>::</span>PolaroidCapture<span>;</span></code></pre><p>If we make our code work with things which implement the <code>Capture</code> trait instead of concrete types, we can now compile on and target various platforms by simply toggling feature flags. For example, we can have a struct which has a field - <code>video_capture: Box&lt;dyn Capture&gt;</code> which will let us store any type which can <code>Capture</code> from a camera.

An example <code>Cargo.toml</code> file to support the capture implementations we wrote above might look something like …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.tonari.no/why-we-love-rust?ref=twtr">https://blog.tonari.no/why-we-love-rust?ref=twtr</a></em></p>]]>
            </description>
            <link>https://blog.tonari.no/why-we-love-rust?ref=twtr</link>
            <guid isPermaLink="false">hacker-news-small-sites-23649534</guid>
            <pubDate>Fri, 26 Jun 2020 07:12:09 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The War on Upstart Fiber Internet Providers]]>
            </title>
            <description>
<![CDATA[
Score 23 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23647609">thread link</a>) | @joecool1029
<br/>
June 25, 2020 | http://chrishacken.com/the-war-on-upstart-fiber-optic-internet-providers/ | <a href="https://web.archive.org/web/*/http://chrishacken.com/the-war-on-upstart-fiber-optic-internet-providers/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>                                
                                    <div> 
                                        <p>As someone who grew up throughout the 90's and 00's, some of my fondest memories stem from progressive advancements in internet and computing technologies.  Upgrading from Dial-Up internet to DSL was a grand event in our house.  I remember my brother and I fighting over the computer day in and day out to play games like Wolfenstein - Enemy Territory, which was released in 2003. (I'm convinced that this will be the all-time best FPS game ever created.)  At around the same time, we upgraded to one of the best Dell computer's available at the time. It had 512MB of RAM and a Pentium 4 processor.  This was a major upgrade from our Compaq Celeron, which had something like 64MB of RAM. <br>
<img src="http://chrishacken.com/content/images/2020/03/MV5BOGFmNjMzZTktNDg2ZS00ZjllLTlkMTAtZTAzMzBkN2UyMzk2XkEyXkFqcGdeQXVyMjU3MzI1NzI@._V1_.jpg" alt="Wolfenstein - Enemy Territory"></p>

<p>Eventually, the grandeur of DSL faded as the rest of the world began to adopt Cable and Fiber internet.  It wasn't until I briefly moved to Philadelphia that I was finally able to experienced what I had been missing out on.  In college I lived in a neighborhood that was one of Verizon's first Fios builds.  I was absolutely blown away by the 25 Mbps connection.  This was in 2009. I'm amazed that over a decade later, in 2020, some households still don't have access to cable or fiber internet yet.</p>

<p>Like many of our customers do now, I could never figure out why it was so difficult to get us fiber service.  The cable is cheap, just throw it up on a pole and give me internet! Right?  Well, not so fast... <br>
<img src="http://chrishacken.com/content/images/2020/03/1849761.jpg" alt="Fiber Spaghetti"></p>

<p>A quick overview of how utility services are run and the challenges involved...</p>

<p>As most people know, there are primarily two ways to deliver utility services to a home or business.  Aerial and underground.  Water, gas, and sewer are always serviced underground for obvious reasons.  Electric, telephone, cable, and fiber have the ability to either be above or below ground.</p>

<h3 id="aerial">Aerial.</h3>

<p>As with anything else, aerial has pro's and con's.</p>

<p>The pro's are primarily upfront costs (this is debatable) and speed of deployment (this is also debatable).</p>

<p>The con's are that contrary to it being cheaper to physically deploy, the pole owners generally charge up-front make ready fee's.  These fees can range from $0 to upwards of $50,000/mile.  It's essentially pay to play.  If we want to attach to 50 poles, the pole owner might determine that 10 of those poles are old and need to be replaced before we can attach to them.  Rather than fork up the cash themselves, they'll force us to pay to replace their poles in order to approve the attachment.</p>

<p>In addition to that, there are the annual pole fee's.  Depending on your agreement, we've seen pole fee's ranging anywhere from $7/pole per year all the way up to $43/pole per year with 10% annual increases (I'm looking at you PPL.  This ridiculous rate was purely intended to keep us from attaching to their poles, IMO.  It's impossible to make money with these rates). <br>
<img src="http://chrishacken.com/content/images/2020/03/Screenshot-2020-03-10-22.04.34.png" alt="Pole Rates"></p>

<p>Another con is that even though installing the cable on poles is faster, it usually takes the pole owner around 6 months just to review applications and to determine make ready requirements and costs.  As an example, if we have fiber on a pole that's 1 pole short from being able to service your house, it would take at least 6 months just to run fiber to that one additional pole. So close, yet so far.</p>

<h3 id="underground">Underground.</h3>

<p>Like aerial, underground has its own list of pro's and con's.</p>

<p>When you install a service underground, you own it for life.  There are no annual fee's.  You pay one time to install it and you're set for life.  This sounds like a pro, but it's also a con.  When we run metro conduit, it generally costs us between $15-25/ft (not including customer drops).  For the sake of argument, let's assume we're at the high-end of our costs.  If we install 1,000ft of conduit, that's $25,000 that we need to pay out of pocket upfront.  Some blocks have upwards of 30 customers, but others have as little as 5.  Let's average it out at 20 customers per block, that's $1,250 upfront per customer, assuming we get every single customer.  Conservatively, we're initially looking at a 50% take rate.  This could grow to 100% overtime, but we never make that assumption. So that's $2,500/customer.  Imagine spending $2,500 per house/building and then have them tell you that your $69/m service is too expensive.  Generally speaking, we won't do a street unless our numbers look better than this, but this is a realistic scenario as we scale and get access to cheaper capital, etc.</p>

<p><img src="http://chrishacken.com/content/images/2020/03/enorthampton01.jpg" alt="Underground Construction">
<img src="http://chrishacken.com/content/images/2020/03/enorthampton02.jpg" alt="Underground Construction Restoration"></p>

<h3 id="politics">Politics</h3>

<p>Cost issues aside, there are a number of other hurdles one needs to get past just to begin the process of building out a network.  You'd think that risking everything you have in an effort to bring your local economy into the 21st Century would be a welcome sight.  That's what I thought too; was I wrong.  While there are plenty of supporters (I truly appreciate you all), there are just as many, if not more, critics.</p>

<p>We've been fortunate enough to have had a handful of people get behind us overtime and give us a shot.  I'm sure others haven't had it so easy.  I know this because even after we've become an established player in our city throughout the past 4 years, neighboring townships and municipalities haven't been as opened armed to welcome us into their communities as I had anticipated or would have liked.</p>

<p>I'll go into more detail on small government policies that really hamper our ability to deploy underground later below.</p>

<h3 id="toomanyopinions">Too Many Opinions</h3>

<p>I'm generally a big fan of individual citizens trying to make an impact in their communities.  However, in too many cases these contributions seem to be made in the form of unproductive complaints rather than productive feedback or action.  Far too many people have a say in things that they probably shouldn't.</p>

<p><strong><em>Case A.</em></strong></p>

<p>A new customer had recently signed an agreement with us to run fiber into their building.  This is a non-profit who's members are selflessly donating their time to restore a landmark in the community.  Upon receiving their signature, I notified the city that we would be pulling a permit to connect the building in question to our underground network.  They said okay; that was that.  Our nearest existing hand hole is approximately 90ft to the right of the new customer's property; in front of another property.  As a courtesy, I notified the manager of that establishment to let her know that we would be performing work over the weekend, from Friday into Saturday.  They're closed Saturday and Sunday so I had assumed they would appreciate the notice and possibly even sign up with us.  The project would involve removing 90ft of sidewalk, running conduit, and then restoring the sidewalk with brand spankin' new concrete.  The total timespan that this would occur, from when our shovel hit the ground to having new sidewalks in place, would be 48 hrs.  The response that I received from a member of their organization made me facepalm.</p>

<p><img src="http://chrishacken.com/content/images/2020/03/Screenshot-2020-03-10-18.53.55-copy.png" alt="Sidewalk Issues"></p>

<p>Not long after receiving this email, I became aware that they didn't even own the building in question, nevermind the sidewalk.  They lease it.  This was eventually "resolved" after a series of negotiations between the non-profit's president and the establishment in question.  Often times we aren't as lucky.</p>

<p>We initially planned to have this new customer installed within a week of them signing the contract.  Now it will end up being around 2 months from start to finish.  Long story short, I learned my lesson in trying to be courteous.</p>

<p><strong><em>Case B.</em></strong></p>

<p>Last year we were installing conduit for our fiber optic network.  There were countless instances where people would literally stop their cars, roll down their windows, and yell profanities at us.  In what world is that acceptable behavior for an adult? I can't imagine being so far off my rocker that I would feel the need to yell at a bunch of construction workers trying to build a fiber optic network (not that they had any idea what we were doing).  If these are the types of people influencing decisions, there's something wrong.</p>

<p>City workers have a tough job fielding complaints from people like this and I commend them for it.  It shouldn't affect policy though.</p>

<p><strong><em>Case C.</em></strong></p>

<p>In another incident that took place not long, maybe a day or two, after <em>Case B</em> above.  A local store owner came back to us as we're swinging pick axes in 95 degree heat telling us we need to hurry up and we should hire more workers.  "My customers keep calling saying there's no where to park."  Mind you, we're standing right next to a massive parking lot that is approximately 1/3rd full.  I made my best attempt to kindly explain that paying 3 guys to stand around a hole to watch one person hand-dig to expose a utility isn't going to make our work go any faster.  I don't think he liked my response.</p>

<h3 id="theconsequences">The Consequences</h3>

<p>In many cases, resident complaints are justified.  Utility providers need to be held accountable for shitty restoration work.  However, the way in which bad restoration work is being combated is counter productive.  There has been a huge increase in curb-to-curb restoration requirements by local governments.  Essentially what these rules state is that anytime a utility cuts asphalt beyond a predetermined length, say 100ft, they are then responsible for replacing the entire road surface from the curb on the left side of the street to the curb on the right side of the street.  I believe some municipalities are also trying to introduce these measures to offload the costs of repaving roads themselves, similar to how pole owners force you to replace their aging utility poles under their make-ready requirements.  (One municipality told me as much when I attended a local council meeting in an effort to get them to waive this ridiculous ordinance for us.)</p>

<p>These policies will ultimately do more harm than good.  For us, these are the one and only thing preventing us from providing superior fiber internet services in these areas.  Forcing curb-to-curb asphalt …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://chrishacken.com/the-war-on-upstart-fiber-optic-internet-providers/">http://chrishacken.com/the-war-on-upstart-fiber-optic-internet-providers/</a></em></p>]]>
            </description>
            <link>http://chrishacken.com/the-war-on-upstart-fiber-optic-internet-providers/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23647609</guid>
            <pubDate>Fri, 26 Jun 2020 00:55:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Re-creating some of Hey's features using Fastmail]]>
            </title>
            <description>
<![CDATA[
Score 29 | Comments 1 (<a href="https://news.ycombinator.com/item?id=23645657">thread link</a>) | @nunodonato
<br/>
June 25, 2020 | https://www.nunodonato.com/2020/06/25/a-guide-on-re-creating-heys-features/ | <a href="https://web.archive.org/web/*/https://www.nunodonato.com/2020/06/25/a-guide-on-re-creating-heys-features/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://www.nunodonato.com/2020/06/25/a-guide-on-re-creating-heys-features/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23645657</guid>
            <pubDate>Thu, 25 Jun 2020 21:01:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Laura Deming, founder of the Longevity Fund, on being homeschooled]]>
            </title>
            <description>
<![CDATA[
Score 106 | Comments 183 (<a href="https://news.ycombinator.com/item?id=23644762">thread link</a>) | @mksm
<br/>
June 25, 2020 | https://blog.withprimer.com/laura-deming/ | <a href="https://web.archive.org/web/*/https://blog.withprimer.com/laura-deming/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="main">
	<article>
		<div>

			<section>
				<p>Laura Deming is a biologist and founder of The Longevity Fund, the first VC firm to focus on companies that work on extending healthy human lifespan and addressing age-related diseases through biotechnology. She grew her roots in biology as a homeschooling student in New Zealand, and moved to the US to work in a <a href="https://hillblomcenter.ucsf.edu/#:~:text=The%20mission%20of%20the%20Hillblom,diseases%20have%20similar%20molecular%20causes.">UCSF biology lab</a> at age 12. By age 14, she was a student at MIT, then became a <a href="https://thielfellowship.org/">Thiel Fellow</a>. We asked Laura to share how her education prepared her to lead and build today.</p><figure><img src="https://blog.withprimer.com/content/images/2020/06/Frame-2.png" alt="" srcset="https://blog.withprimer.com/content/images/size/w600/2020/06/Frame-2.png 600w, https://blog.withprimer.com/content/images/size/w1000/2020/06/Frame-2.png 1000w, https://blog.withprimer.com/content/images/size/w1600/2020/06/Frame-2.png 1600w, https://blog.withprimer.com/content/images/size/w1754/2020/06/Frame-2.png 1754w"><figcaption>Laura Deming. Illustration by <a href="https://www.ne-oh.com/">Annie Oh</a>.</figcaption></figure><h3 id="what-are-you-working-on-and-thinking-about-this-week">What are you working on and thinking about this week?</h3><p>How long do you have? I normally have a few key focuses at work (right now, immune aging from a bunch of different angles), and then a billion other small ideas that float in and out of my cranium. My most persistent focus is something that I can’t talk about yet because it would sound slightly insane, but right now, I’m pursuing these more coherent questions: &nbsp;<br></p><ol><li>Is there a flywheel effect with biological tools? Will biological discoveries become the tools for next-generation discovery? How might we predict progress in biology?</li><li>Why does it normally take about a year for the best proto-entrepreneurs I know to reach full conviction about starting a company? What are ways to accelerate that process?</li><li>Is there an immortal cell that doesn’t replicate anywhere on earth? (We presumably wouldn’t see it if there was.)</li></ol><p>I’m really obsessed with <a href="http://book.bionumbers.org/">Cell Biology by the Numbers</a>. I think quantitative intuitive models of biology are the best thing ever. Also <a href="https://www.cornell.edu/video/nima-arkani-hamed-morality-fundamental-physics">this Nima Arkani-Hamed</a> video is literally the best thing ever.</p><h3 id="what-was-your-education-like">What was your education like?</h3><p>I grew up homeschooled in NZ with a hilariously small amount of context for what the real world was like. In retrospect, it was totally ideal. I had two strong memes deeply implanted in my cranium early in life - <em>I love science </em>and <em>it’s my job to do something really important </em>and<em> I can do it, too. </em>I have no clue who I’d be without those memes, and I’m also not sure that the latter was actually true! My dad just always told me that I was exceptional and could work out a way whatever I wanted to do in the world and I believed him. I still do, in a funny way, despite about a decade of evidence to the contrary and realizing how actually hard it is to make drugs for complex diseases. It’s extraordinarily sad how many otherwise brilliant kids might not do things they could because they don’t have a similarly supportive environment — I’m really excited for things like <a href="https://dcgross.com/">Daniel Gross</a>’s <a href="https://pioneer.app/">Pioneer</a> for that reason. </p><figure><img src="https://blog.withprimer.com/content/images/2020/06/image.png" alt="" srcset="https://blog.withprimer.com/content/images/size/w600/2020/06/image.png 600w, https://blog.withprimer.com/content/images/size/w1000/2020/06/image.png 1000w, https://blog.withprimer.com/content/images/size/w1600/2020/06/image.png 1600w, https://blog.withprimer.com/content/images/size/w2000/2020/06/image.png 2000w"><figcaption>Laura as a child, drawing DNA on the pavement outside of her house in chalk, an anecdote from a talk that she gave for <a href="https://www.youtube.com/watch?v=YwslKJut8eM">TedxYouth@Tallinn</a>. Illustration by <a href="https://www.ne-oh.com/">Annie Oh</a>.</figcaption></figure><p>I feel like it was a lot of puzzle solving and doing obvious stuff. And then starting to think more independently in college, and to try to figure out what problems I wanted to work on. But I had this moment around that time where a friend and I were driving to a camping site, and I was trying to explain a math concept to him, and he abruptly turned to me and said “I’m feeling very frustrated right now because you honestly have absolutely no idea what you are talking about.”<em> </em></p><p>It’s really hard to explain without context how actually useful that comment was. As he explained it, I was just parroting off the definition of something. The real way to understand things is to be able to see, explore, feel the concept from a bunch of different angles, and to be able to rigorously prove things about it. I still struggle with the latter, but having an intuition for what <em>real, deep </em>understanding of a concept looks like has been a great guidepost. For example, I realized I didn’t understand what entropy was, and now kind of do, after a summer of being in near tears with frustration about it. </p><h3 id="where-and-when-did-your-mission-to-improve-longevity-originate">Where and when did your mission to improve longevity originate?</h3><p>It’s funny, because I get asked that question a lot. I think of it like this: if you were to watch a million people jump off a bridge every day and just suffer in a really extreme way throughout all of it, How would we respond as a society? An overwhelming number of people would be inspired to take action and help. When you think of it in acute, immediate terms, viscerally shocking and moving. But with longevity and other deeply existential problems, the horror of what’s happening has been tragically normalized.</p><p>I really just wanted to work on the biggest problem possible. At first I thought that was cancer, but after a variety of experiences, aging just seemed like a bigger deal.</p><p>I have a much less antagonistic relationship with death now than I did when I was a kid. I understand more that we are a species, that there’s something beyond us as individuals — but despite that, I absolutely cannot square the idea of sobbing when a relative gets cancer and then being totally fine with another debilitating degenerative disease also caused by aging that we somehow have collectively decided is natural and normal.</p><h3 id="how-has-the-way-you-learned-as-a-kid-shaped-the-way-you-learn-and-make-decisions-at-the-helm-of-the-longevity-fund">How has the way you learned as a kid shaped the way you learn and make decisions at the helm of The Longevity Fund?</h3><p>I’ve had to un-learn a bunch of stuff I learned when I first came to the professional world. As a kid, I was deeply joyous about science. I loved it directly and with a passion, and I absolutely believed I was going to grow up to be like Michael Faraday (his story about <a href="https://artsandculture.google.com/exhibit/people-of-science-michael-faraday-the-royal-society/HQLyLIo6MWpoKw?hl=en">getting an apprenticeship with Humphrey Davy</a> is amazing, by the way). When I entered the world of finance with my fund, I was totally scared to seem like I didn’t know what I was doing, and I felt like it was really important to hide who I was to seem more ‘adult’. Now, in retrospect, I think that was both understandable and a bit of a mistake.</p><p>One thing I learned as a kid that I keep on forgetting so easily is how not to care about what anyone else thinks (with a few close exceptions). It’s funny - even in Silicon Valley, hypothetically the vanguard of independent thought, I feel like that’s extremely hard to do. In part, because what other people think constrains your access to resources. So it’s an interesting balance. </p><h3 id="i-ve-heard-you-talk-about-your-dad-telling-you-at-12-years-old-to-make-sure-that-everyone-was-a-little-bit-happier-because-you-were-in-the-lab-each-day-what-role-did-your-parents-play-in-your-life-and-education">I’ve heard you talk about your dad telling you at 12 years old to make sure that everyone was a little bit happier because you were in the lab each day. What role did your parents play in your life and education?</h3><p>Oh, man. My Dad had so much good advice as a kid — I really felt like I got a cheat code to life early on. It was like being Ben Franklin’s daughter or something. I’m probably exaggerating, but it felt that way. </p><p>One thing he told me was ‘action comes before motivation’ - that’s always been an incredibly powerful thing in my life. He taught me a lot about putting your head down and working hard and not believing anyone who tells you you are great, having that come mostly from your own self-judgment. Being extremely humble around people who know more, finding any way on earth to help them. </p><p>My dad also taught me a lot about humor and how ridiculous the world was in so many different ways. Almost too much - I think I take things more seriously now. But it’s kind of the Mark Twain effect - the world and everyone in it is a hilarious, self-sabotaging, foolhardy place that is also one of the most deeply joyous and interesting things going on in the galaxy. He used to say you can either look at what’s going on in the world and cry or laugh. Why not pick the latter?</p><p>My mom taught me about kindness and empathy and wanting to help others. She’s probably the most giving person I know. </p><p>When I first met Cynthia Kenyon, who literally changed my and many other lives – she’s amazing – I had this very extreme mental conceit that I would beg her to scrub floors in her lab and somehow work my way up on the academic ladder. I was 12. She very kindly offered for me to just work in her lab as a normal intern, which was so kind in retrospect. It changed my life, to be taken seriously like that at a young age. </p><h3 id="i-love-how-you-describe-the-way-the-longevity-fund-removes-limits-on-who-can-participate-in-biomedical-entrepreneurship-how-can-we-translate-some-of-what-you-ve-learned-about-diverse-participation-in-science-to-the-way-that-kids-learn">I love how you describe the way The Longevity Fund removes limits on who can participate in biomedical entrepreneurship. How can we translate some of what you’ve learned about diverse participation in science to the way that kids learn?</h3><p>I think there’s something about being absolutely delighted when you meet someone who doesn’t know something. That feeling is the best thing in the world because <em>you get to be the first person to tell them about some incredibly cool natural phenomenon</em>. That’s pretty great. I still remember being a preteen in Cynthia’s lab when Marc McCormick described how SVMs (<a href="https://en.wikipedia.org/wiki/Support_vector_machine">Support Vector Machines</a>) worked for handwriting recognition in the postal system. He was just so good at explaining things, and that really stuck. Encourage people to own ideas, be skeptical of them, and learn to delight in poking holes in things.<br></p><p>When thinking about diverse participation, it’s funny – before I came to the Valley, I had absolutely no idea that being a girl was in any way a handicap. To me, it was an obvious advantage – in a sea of people who all looked the same way, I’d stick out like a sore thumb! If I could make it, wouldn’t I obviously be an amazing role model? Being in the valley for a while, it kind of wore off, and the more articles I read about how much it sucked to be a girl in science, the more I believed it. I’m not sure what to think about all of that, really. </p><h3 id="what-s-something-you-believe-that-most-people-don-t">What’s something you believe that most people don’t?</h3><p>I can give you a few!</p><ol><li>That we will see the first drug to measurably affect <a href="https://publichealth.wustl.edu/heatlhspan-is-more-important-than-lifespan-so-why-dont-more-people-know-about-it/">human healthspan</a> tested in the next decade, and that this is one of the biggest deals in how we thinking about disease. It’s not just hype and rhetoric.</li><li>That original thinkers are so darn much more rare to find than I thought they’d be growing up. <br></li></ol><hr><p><em>Primer is a new education company whose goal is to help kids engage in limitless learning, starting with homeschoolers. </em><strong>Homeschooled:</strong><em> is a regular series about homeschooling alumni who have gone on to do amazing things. We're just getting started, so we'd love to hear what you think!</em></p><p>Sign up for …</p></section></div></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.withprimer.com/laura-deming/">https://blog.withprimer.com/laura-deming/</a></em></p>]]>
            </description>
            <link>https://blog.withprimer.com/laura-deming/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23644762</guid>
            <pubDate>Thu, 25 Jun 2020 19:48:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Query-Based Compiler Architectures]]>
            </title>
            <description>
<![CDATA[
Score 104 | Comments 23 (<a href="https://news.ycombinator.com/item?id=23644391">thread link</a>) | @matt_d
<br/>
June 25, 2020 | https://ollef.github.io/blog/posts/query-based-compilers.html | <a href="https://web.archive.org/web/*/https://ollef.github.io/blog/posts/query-based-compilers.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
        <p>Note: This is an old post originally from the documentation of the <a href="https://github.com/ollef/sixten">Sixten</a> programming language, that I've touched up and fleshed out. After the time that it was written I've found out about <a href="https://github.com/salsa-rs/salsa">Salsa</a>, a Rust library with very similar goals to my Rock library, which is definitely worth checking out as well!</p>
<h2 id="background">Background</h2>
<p>Compilers are no longer just black boxes that take a bunch of source files and produce assembly code. We expect them to:</p>
<ul>
<li>Be incremental, meaning that if we recompile a project after having made a few changes we only recompile what is affected by the changes.</li>
<li>Provide editor tooling, e.g. through a <a href="https://langserver.org/">language server</a>, supporting functionality like going to definition, finding the type of the expression at a specific location, and showing error messages on the fly.</li>
</ul>
<p>This is what Anders Hejlsberg talks about in <a href="https://www.youtube.com/watch?v=wSdV1M7n4gQ">his video on modern compiler construction</a> that some of you might have seen.</p>
<p>In this post I will cover how this is achieved in <a href="https://github.com/ollef/sixten">Sixten</a> by building the compiler around a query system.</p>
<p>For those of you that don't know, Sixten is an experimental functional programming language created to give the programmer more control over memory layout and boxing than most other high-level languages do. The most recent development of Sixten is being done in the <a href="https://github.com/ollef/sixty">Sixty</a> repository, and is completely query-based. Here's a little video giving a taste of what its language server can do, showing type-based completions:</p>

<h2 id="traditional-pipeline-based-compiler-architectures">Traditional pipeline-based compiler architectures</h2>
<p>A traditional compiler pipeline might look a bit like this:</p>
<div id="cb1"><pre><code><span id="cb1-1"><a href="#cb1-1"></a>+-----------+            +-----+                +--------+               +--------+</span>
<span id="cb1-2"><a href="#cb1-2"></a>|           |            |     |                |        |               |        |</span>
<span id="cb1-3"><a href="#cb1-3"></a>|source text|---parse---&gt;| AST |---typecheck-+-&gt;|core AST|---generate---&gt;|assembly|</span>
<span id="cb1-4"><a href="#cb1-4"></a>|           |            |     |       ^        |        |               |        |</span>
<span id="cb1-5"><a href="#cb1-5"></a>+-----------+            +-----+       |        +--------+               +---------</span>
<span id="cb1-6"><a href="#cb1-6"></a>                                       |</span>
<span id="cb1-7"><a href="#cb1-7"></a>                                 read and write</span>
<span id="cb1-8"><a href="#cb1-8"></a>                                     types</span>
<span id="cb1-9"><a href="#cb1-9"></a>                                       |</span>
<span id="cb1-10"><a href="#cb1-10"></a>                                       v</span>
<span id="cb1-11"><a href="#cb1-11"></a>                                  +----------+</span>
<span id="cb1-12"><a href="#cb1-12"></a>                                  |          |</span>
<span id="cb1-13"><a href="#cb1-13"></a>                                  |type table|</span>
<span id="cb1-14"><a href="#cb1-14"></a>                                  |          |</span>
<span id="cb1-15"><a href="#cb1-15"></a>                                  +----------+</span></code></pre></div>
<p>There are many variations, and often more steps and intermediate representations than in the illustration, but the idea stays the same:</p>
<p>We push source text down a pipeline and run a fixed set of transformations until we finally output assembly code or some other target language. Along the way we often need to read and update some state. For example, we might update a type table during type checking so we can later look up the type of entities that the code refers to.</p>
<p>Traditional compiler pipelines are probably quite familiar to many of us, but how query-based compilers should be architected might not be as well-known. Here I will describe one way to do it.</p>
<h2 id="going-from-pipeline-to-queries">Going from pipeline to queries</h2>
<p>What does it take to get the type of a qualified name, such as <code>"Data.List.map"</code>? In a pipeline-based architecture we would just look it up in the type table. With queries, we have to think differently. Instead of relying on having updated some piece of state, we do it as if it was done from scratch.</p>
<p>As a first iteration, we do it <em>completely</em> from scratch. It might look a little bit like this:</p>
<div id="cb2"><pre><code><span id="cb2-1"><a href="#cb2-1"></a><span>fetchType ::</span> <span>QualifiedName</span> <span>-&gt;</span> <span>IO</span> <span>Type</span></span>
<span id="cb2-2"><a href="#cb2-2"></a>fetchType (<span>QualifiedName</span> moduleName name) <span>=</span> <span>do</span></span>
<span id="cb2-3"><a href="#cb2-3"></a>  fileName <span>&lt;-</span> moduleFileName moduleName</span>
<span id="cb2-4"><a href="#cb2-4"></a>  sourceCode <span>&lt;-</span> <span>readFile</span> fileName</span>
<span id="cb2-5"><a href="#cb2-5"></a>  parsedModule <span>&lt;-</span> parseModule sourceCode</span>
<span id="cb2-6"><a href="#cb2-6"></a>  resolvedModule <span>&lt;-</span> resolveNames parsedModule</span>
<span id="cb2-7"><a href="#cb2-7"></a>  <span>let</span> definition <span>=</span> <span>lookup</span> name resolvedModule</span>
<span id="cb2-8"><a href="#cb2-8"></a>  inferDefinitionType definition</span></code></pre></div>
<p>We first find out what file the name comes from, which might be <code>Data/List.vix</code> for <code>Data.List</code>, then read the contents of the file, parse it, perhaps we do name resolution to find out what the names in the code refer to given what is imported, and last we look up the name-resolved definition and type check it, returning its type.</p>
<p>All this for just for getting the type of an identifier? It seems ridiculous because looking up the type of a name is something we'll do loads of times during the type checking of a module. Luckily we're not done yet.</p>
<p>Let's first refactor the code into smaller functions:</p>
<div id="cb3"><pre><code><span id="cb3-1"><a href="#cb3-1"></a><span>fetchParsedModule ::</span> <span>ModuleName</span> <span>-&gt;</span> <span>IO</span> <span>ParsedModule</span></span>
<span id="cb3-2"><a href="#cb3-2"></a>fetchParsedModule moduleName <span>=</span> <span>do</span></span>
<span id="cb3-3"><a href="#cb3-3"></a>  fileName <span>&lt;-</span> moduleFileName moduleName</span>
<span id="cb3-4"><a href="#cb3-4"></a>  sourceCode <span>&lt;-</span> <span>readFile</span> fileName</span>
<span id="cb3-5"><a href="#cb3-5"></a>  parseModule moduleName</span>
<span id="cb3-6"><a href="#cb3-6"></a></span>
<span id="cb3-7"><a href="#cb3-7"></a><span>fetchResolvedModule ::</span> <span>ModuleName</span> <span>-&gt;</span> <span>IO</span> <span>ResolvedModule</span></span>
<span id="cb3-8"><a href="#cb3-8"></a>fetchResolvedModule moduleName <span>=</span> <span>do</span></span>
<span id="cb3-9"><a href="#cb3-9"></a>  parsedModule <span>&lt;-</span> fetchParsedModule moduleName</span>
<span id="cb3-10"><a href="#cb3-10"></a>  resolveNames parsedModule</span>
<span id="cb3-11"><a href="#cb3-11"></a></span>
<span id="cb3-12"><a href="#cb3-12"></a><span>fetchType ::</span> <span>QualifiedName</span> <span>-&gt;</span> <span>IO</span> <span>Type</span></span>
<span id="cb3-13"><a href="#cb3-13"></a>fetchType (<span>QualifiedName</span> moduleName name) <span>=</span> <span>do</span></span>
<span id="cb3-14"><a href="#cb3-14"></a>  resolvedModule <span>&lt;-</span> fetchResolvedModule moduleName</span>
<span id="cb3-15"><a href="#cb3-15"></a>  <span>let</span> definition <span>=</span> <span>lookup</span> name resolvedModule</span>
<span id="cb3-16"><a href="#cb3-16"></a>  inferDefinitionType definition</span></code></pre></div>
<p>Note that each of the functions do everything from scratch on their own, i.e. they're each doing a (longer and longer) prefix of the work you'd do in a pipeline. I've found this to be a common pattern in my query-based compilers.</p>
<p>One way to make this efficient would be to add a memoisation layer around each function. That way, we do some expensive work the first time we invoke a function with a specific argument, but subsequent calls are cheap as they can return the cached result.</p>
<p>This is essentially what we'll do, but we won't use a separate cache per function, but instead have a central cache, indexed by the query. This functionality is provided by <a href="https://github.com/ollef/rock">Rock</a>, a library that packages up some functionality for creating query-based compilers.</p>
<h2 id="the-rock-library">The Rock library</h2>
<p><a href="https://github.com/ollef/rock">Rock</a> is an experimental library heavily inspired by <a href="https://github.com/ndmitchell/shake">Shake</a> and the <a href="https://www.microsoft.com/en-us/research/publication/build-systems-la-carte/">Build systems à la carte paper</a>. It essentially implements a build system framework, like <code>make</code>.</p>
<p>Build systems have a lot in common with modern compilers since we want them to be incremental, i.e. to take advantage of previous build results when building anew with few changes. But there's also a difference: Most build systems don't care about the <em>types</em> of their queries since they work at the level of files and file systems.</p>
<p><em>Build systems à la carte</em> is closer to what we want. There the user writes a bunch of computations, <em>tasks</em>, choosing a suitable type for keys and a type for values. The tasks are formulated assuming they're run in an environment where there is a function <code>fetch</code> of type <code>Key -&gt; Task Value</code>, where <code>Task</code> is a type for describing build system rules, that can be used to fetch the value of a dependency with a specific key. In our above example, the key type might look like this:</p>
<div id="cb4"><pre><code><span id="cb4-1"><a href="#cb4-1"></a><span>data</span> <span>Key</span></span>
<span id="cb4-2"><a href="#cb4-2"></a>  <span>=</span> <span>ParsedModuleKey</span> <span>ModuleName</span></span>
<span id="cb4-3"><a href="#cb4-3"></a>  <span>|</span> <span>ResolvedModuleKey</span> <span>ModuleName</span></span>
<span id="cb4-4"><a href="#cb4-4"></a>  <span>|</span> <span>TypeKey</span> <span>QualifiedName</span></span></code></pre></div>
<p>The build system has control over what code runs when we do a <code>fetch</code>, so by varying that it can do fine-grained dependency tracking, memoisation, and incremental updates.</p>
<p><em>Build systems à la carte</em> is also about exploring what kind of build systems we get when we vary what <code>Task</code> is allowed to do, e.g. if it's a <code>Monad</code> or <code>Applicative</code>. In Rock, we're not exploring <em>that</em>, so our <code>Task</code> is a thin layer on top of <code>IO</code>.</p>
<p>A problem that pops up now, however, is that there's no satisfactory type for <code>Value</code>. We want <code>fetch (ParsedModuleKey "Data.List")</code> to return a <code>ParsedModule</code>, while <code>fetch (TypeKey "Data.List.map")</code> should return something of type <code>Type</code>.</p>
<h3 id="indexed-queries">Indexed queries</h3>
<p>Rock allows us to index the key type by the return type of the query. The <code>Key</code> type in our running example becomes the following <a href="https://en.wikipedia.org/wiki/Generalized_algebraic_data_type">GADT</a>:</p>
<div id="cb5"><pre><code><span id="cb5-1"><a href="#cb5-1"></a><span>data</span> <span>Key</span> a <span>where</span></span>
<span id="cb5-2"><a href="#cb5-2"></a>  <span>ParsedModuleKey</span><span> ::</span> <span>ModuleName</span> <span>-&gt;</span> <span>Key</span> <span>ParsedModule</span></span>
<span id="cb5-3"><a href="#cb5-3"></a>  <span>ResolvedModuleKey</span><span> ::</span> <span>ModuleName</span> <span>-&gt;</span> <span>Key</span> <span>ResolvedModule</span></span>
<span id="cb5-4"><a href="#cb5-4"></a>  <span>TypeKey</span><span> ::</span> <span>QualifiedName</span> <span>-&gt;</span> <span>Key</span> <span>Type</span></span></code></pre></div>
<p>The <code>fetch</code> function gets the type <code>forall a. Key a -&gt; Task a</code>, so we get a <code>ParsedModule</code> when we run <code>fetch (ParsedModuleKey "Data.List")</code>, like we wanted, because the return type depends on the key we use.</p>
<p>Now that we know what <code>fetch</code> should look like, it's also worth revealing what the <code>Task</code> type looks like in Rock, more concretely. As mentioned, it's a thin layer around <code>IO</code>, providing a way to <code>fetch</code> <code>key</code>s (like <code>Key</code> above):</p>
<div id="cb6"><pre><code><span id="cb6-1"><a href="#cb6-1"></a><span>newtype</span> <span>Task</span> key a <span>=</span> <span>Task</span> {<span> unTask ::</span> <span>ReaderT</span> (<span>Fetch</span> key) <span>IO</span> a }</span>
<span id="cb6-2"><a href="#cb6-2"></a><span>newtype</span> <span>Fetch</span> key <span>=</span> <span>Fetch</span> (<span>forall</span> a<span>.</span> key a <span>-&gt;</span> <span>IO</span> a)</span></code></pre></div>
<p>The rules of our compiler, i.e. its "Makefile", then becomes the following function, reusing the functions from above:</p>
<div id="cb7"><pre><code><span id="cb7-1"><a href="#cb7-1"></a><span>rules ::</span> <span>Key</span> a <span>-&gt;</span> <span>Task</span> a</span>
<span id="cb7-2"><a href="#cb7-2"></a>rules key <span>=</span> <span>case</span> key <span>of</span></span>
<span id="cb7-3"><a href="#cb7-3"></a>  <span>ParsedModuleKey</span> moduleName <span>-&gt;</span></span>
<span id="cb7-4"><a href="#cb7-4"></a>    fetchParsedModule moduleName</span>
<span id="cb7-5"><a href="#cb7-5"></a></span>
<span id="cb7-6"><a href="#cb7-6"></a>  <span>ResolvedModuleKey</span> moduleName <span>-&gt;</span></span>
<span id="cb7-7"><a href="#cb7-7"></a>    fetchResolvedModule moduleName</span>
<span id="cb7-8"><a href="#cb7-8"></a></span>
<span id="cb7-9"><a href="#cb7-9"></a>  <span>TypeKey</span> qualifiedName <span>-&gt;</span></span>
<span id="cb7-10"><a href="#cb7-10"></a>    fetchType qualifiedName</span></code></pre></div>
<h3 id="caching">Caching</h3>
<p>The most basic way to run a <code>Task</code> in Rock is to directly call the <code>rules</code> function when a <code>Task</code> fetches a key. This results in an inefficient build system that recomputes every query from scratch.</p>
<p>But the <code>Rock</code> library lets us layer more functionality onto our <code>rules</code> function, and one thing that we can add is memoisation. If we do that Rock caches the result of each fetched key by storing the key-value pairs of already performed fetches in a <a href="https://hackage.haskell.org/package/dependent-hashmap">dependent hashmap</a>. This way, we perform each query at most once during a single run of the compiler.</p>
<h3 id="verifying-dependencies-and-reusing-state">Verifying dependencies and reusing state</h3>
<p>Another kind of functionality that can be layered onto the <code>rules</code> function is incremental updates. When it's used, Rock keeps track of what dependencies a task used when it was executed (much like Shake) in a table, i.e. what keys it fetched and what the values were. Using this information it's able to determine when it's safe to reuse the cache <em>from a previous run of the compiler</em> even though there might be changes in other parts of the dependency graph.</p>
<p>This fine-grained dependency tracking also allows reusing the cache when a dependency of a task changes in a way that has no effect. For example, whitespace changes might trigger a re-parse, but since the AST is the same, the cache can be reused in queries that depend on the …</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://ollef.github.io/blog/posts/query-based-compilers.html">https://ollef.github.io/blog/posts/query-based-compilers.html</a></em></p>]]>
            </description>
            <link>https://ollef.github.io/blog/posts/query-based-compilers.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23644391</guid>
            <pubDate>Thu, 25 Jun 2020 19:17:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[ASGI from scratch – Let's build an ASGI web framework]]>
            </title>
            <description>
<![CDATA[
Score 69 | Comments 11 (<a href="https://news.ycombinator.com/item?id=23644252">thread link</a>) | @lukastyrychtr
<br/>
June 25, 2020 | https://shenli.dev/2020/06/20/asgi-from-scratch.html | <a href="https://web.archive.org/web/*/https://shenli.dev/2020/06/20/asgi-from-scratch.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    
<p>The first time I used <a href="https://asgi.readthedocs.io/">ASGI</a>(<em>Asynchronous Server Gateway Interface</em>) was through <a href="https://github.com/django/channels">Channels</a> 1.0 when ASGI spec was still a draft. It was my first interview project which helped me get my current job at <a href="https://fellow.app/">Fellow</a>. It felt magical at that time how easy it is to add WebSocket functionality to my Django app and handles authentication and other Django related things for me seamlessly.</p>

<p>ASGI specification is now at version 3 at the time of writing and both ASGI and Channels became part of Django Software Foundation. Compared to the draft version, it has matured a lot with added lifecycle calls and better application format, etc. Most excitingly, a healthy and fast-growing community is forming and we are seeing more and more ASGI servers running in production environments. At my company, we are serving a few million requests per day through ASGI running on <a href="https://github.com/django/daphne">Daphne</a>, Netflix’s <a href="https://netflixtechblog.com/introducing-dispatch-da4b8a2a8072">Dispatch</a> is based on <a href="https://fastapi.tiangolo.com/">FastAPI</a>, a popular ASGI web application framework, and apparently, Microsoft is <a href="https://github.com/tiangolo/fastapi/pull/26">using it</a> too.</p>

<p>I would humbly advise anyone building web services in Python to learn about ASGI. And the best way to learn something is to built things with it, so in this blog post, I’ll walk through the steps to build a micro web application framework that speaks ASGI. I hope it can help explain how ASGI works.</p>


<p>Before writing the first line of code, we need to have a basic understanding of what ASGI is and what we are building towards.</p>
<h2 id="how-asgi-works">How ASGI works</h2>
<p>Here’s a simple diagram showing how ASGI works at a high level.</p>
<pre><code>graph TD
	A[Client] --&gt;|HTTP, WebSocket, ...| B(ASGI Server)
	B --&gt; |scope, send, receive| C(ASGI application)
</code></pre>
<p>To put it in simple words, A browser(client), establishes a connection to ASGI server with a certain type of request (HTTP or WebSocket), the ASGI server then calls ASGI  application with information about the connection, encapsulated in a python dictionary called <code>scope</code>, and two callbacks, named <code>send</code> and <code>receive</code>, that the application can use to send and receive messages between server and client.</p>

<p>Here’s an example HTTP request scope</p>
<div><div><pre><code><span>{</span>
    <span>"type"</span><span>:</span> <span>"http"</span><span>,</span>
    <span>"http_version"</span><span>:</span> <span>"1.1"</span><span>,</span>
    <span>"server"</span><span>:</span> <span>(</span><span>"127.0.0.1"</span><span>,</span> <span>8000</span><span>),</span>
    <span>"client"</span><span>:</span> <span>(</span><span>"127.0.0.1"</span><span>,</span> <span>60457</span><span>),</span>
    <span>"scheme"</span><span>:</span> <span>"http"</span><span>,</span>
    <span>"method"</span><span>:</span> <span>"GET"</span><span>,</span>
    <span>"root_path"</span><span>:</span> <span>""</span><span>,</span>
    <span>"path"</span><span>:</span> <span>"/hello/a"</span><span>,</span>
    <span>"raw_path"</span><span>:</span> <span>b"/hello/a"</span><span>,</span>
    <span>"query_string"</span><span>:</span> <span>b""</span><span>,</span>
    <span>"headers"</span><span>:</span> <span>[</span>
        <span>(</span><span>b"host"</span><span>,</span> <span>b"localhost:8000"</span><span>),</span>
        <span>(</span><span>b"connection"</span><span>,</span> <span>b"keep-alive"</span><span>),</span>
        <span>(</span>
            <span>b"user-agent"</span><span>,</span>
            <span>b"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_14_6) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/83.0.4103.106 Safari/537.36"</span><span>,</span>
        <span>),</span>
        <span>(</span>
            <span>b"accept"</span><span>,</span>
            <span>b"text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9"</span><span>,</span>
        <span>),</span>
        <span>(</span><span>b"accept-encoding"</span><span>,</span> <span>b"gzip, deflate, br"</span><span>),</span>
        <span>(</span><span>b"accept-language"</span><span>,</span> <span>b"en-US,en;q=0.9"</span><span>),</span>
        <span>(</span>
            <span>b"cookie"</span><span>,</span>
            <span>b'csrftoken=dDA2IAPrvgPc7hkyBSyctxDk78KmhHAzUqR0LUpjXI3Xgki0QrGEWazE3RGZuLGl'</span><span>,</span>
        <span>),</span>
    <span>],</span>
<span>}</span>
</code></pre></div></div>

<p>You might notice that <code>scope</code> is not too different from a WSGI <code>environ</code>. In fact, ASGI interface is very similar to WSGI interface, but instead of getting a <code>environ</code> and <code>start_response</code> to send headers and using the return value of WSGI application as the response body, ASGI interfaces with the connection and allows us to receive and send messages multiple times during the lifecycle of the connection <strong>asynchronously</strong> until the connection is closed.  This allows a nice interface for both WebSocket and HTTP.</p>

<p>It’s also totally possible to wrap a WSGI application inside an ASGI application, just prepare a WSGI <code>environ</code> and <code>start_response</code> based on <code>scope</code>, <code>receive</code>, and <code>send</code> then call the WSGI application and it would work. If you delegate that call into a thread pool or something similar, you just made your WSGI application asynchronous. This is roughly how Channels wraps around Django.</p>

<h2 id="define-asgi-framework">Define ASGI framework</h2>
<p>When I say ASGI framework I refer it as a framework that makes building ASGI application easier and this does not include the ASGI server part. I’m mentioning this because some of the earlier Python asynchronous web frameworks have their own server implementation that also takes over tasks such as parsing  HTTP requests, handles network connections, etc. We are not doing those in ASGI web framework. As a spiritual successor to WSGI, where web servers, such as Gunicorn and uwsgi, and web frameworks, such as Flask and Django, are separated, ASGI has this separation too.</p>

<p>So, what does an ASGI application look like?</p>

<h3 id="asgi-hello-world">ASGI Hello World</h3>
<p>A simple ASGI hello world application can be written as:</p>
<div><div><pre><code><span>async</span> <span>def</span> <span>application</span><span>(</span><span>scope</span><span>,</span> <span>receive</span><span>,</span> <span>send</span><span>):</span>
    <span>name</span> <span>=</span> <span>scope</span><span>[</span><span>"path"</span><span>].</span><span>split</span><span>(</span><span>"/"</span><span>,</span> <span>1</span><span>)[</span><span>-</span><span>1</span><span>]</span> <span>or</span> <span>"world"</span>
    <span>await</span> <span>send</span><span>(</span>
        <span>{</span>
            <span>"type"</span><span>:</span> <span>"http.response.start"</span><span>,</span>
            <span>"status"</span><span>:</span> <span>200</span><span>,</span>
            <span>"headers"</span><span>:</span> <span>[[</span><span>b"content-type"</span><span>,</span> <span>b"text/plain"</span><span>],],</span>
        <span>}</span>
    <span>)</span>
    <span>await</span> <span>send</span><span>(</span>
        <span>{</span>
            <span>"type"</span><span>:</span> <span>"http.response.body"</span><span>,</span>
            <span>"body"</span><span>:</span> <span>f"Hello, </span><span>{</span><span>name</span><span>}</span><span>!"</span><span>.</span><span>encode</span><span>(),</span>
            <span>"more_body"</span><span>:</span> <span>False</span><span>,</span>
        <span>}</span>
    <span>)</span>
</code></pre></div></div>
<p><code>http.response.start</code> starts an HTTP response sending status code and response headers. In this example, it responds with the 200 OK status code and  has <code>content-type</code> set to <code>text/plain</code> in the headers.  <code>http.response.body</code> sends the response body, the <code>more_body</code> key tells the server if the response is finished. ASGI server might use this to know if a connection should be closed or automatically decide between a <code>content-length</code> header or a chunked encoding.</p>

<p>We can run the application with <a href="https://www.uvicorn.org/">uvicorn</a>:</p>
<div><div><pre><code>uvicorn asgi-hello:application
</code></pre></div></div>
<p>And you should be able to visit <code>http://localhost:8000/</code> and get <code>Hello, world</code>.Visiting <code>http://localhost:8000/tom</code> would get you <code>Hello, tom</code>.</p>

<blockquote>
  <p>By the way, uvicorn is pretty fast, a simple benchmark with <code>wrk -d10s http://localhost:8000/hi</code> on a 2018 lowest spec MacBook Air yields <code>Requests/sec:  27857.87</code>.</p>
</blockquote>

<p>Although this approach works with a simple hello world example, it’s not exactly convenient to write a more complex application this way. For one, it doesn’t do routing, if you want to respond differently for different paths, you’ll probably end up with a huge  <code>if ... else if ... else</code> clause. Secondly, having to write the ASGI message every time in the form of a python dict is quite arduous. Third, in a complex application, it gets harder to track the status of the connection, such as is the response started, is the response ended, should I start the response here, etc.</p>

<h3 id="goal">Goal</h3>
<p>With the new framework, I hope to be able to write an ASGI application like this:</p>
<div><div><pre><code><span>import</span> <span>asyncio</span>
<span>from</span> <span>aaf</span> <span>import</span> <span>aaf</span> <span># Another ASGI framework
</span><span>from</span> <span>aaf.routing</span> <span>import</span> <span>Router</span>
<span>from</span> <span>aaf.response</span> <span>import</span> <span>HttpResponse</span>

<span>router</span> <span>=</span> <span>Router</span><span>()</span>

<span>@</span><span>router</span><span>.</span><span>route</span><span>(</span><span>'/'</span><span>)</span>
<span>@</span><span>router</span><span>.</span><span>route</span><span>(</span><span>'/&lt;name&gt;'</span><span>)</span>
<span>async</span> <span>def</span> <span>hello</span><span>(</span><span>connection</span><span>,</span> <span>name</span><span>=</span><span>'world'</span><span>):</span>
	<span>return</span> <span>HttpResponse</span><span>(</span><span>f"Hello, </span><span>{</span><span>name</span><span>}</span><span>"</span><span>)</span>


<span>@</span><span>router</span><span>.</span><span>route</span><span>(</span><span>'/count'</span><span>)</span>
<span>@</span><span>router</span><span>.</span><span>route</span><span>(</span><span>'/count/&lt;int:number&gt;'</span><span>)</span>
<span>async</span> <span>def</span> <span>count</span><span>(</span><span>connection</span><span>,</span> <span>number</span><span>=</span><span>10</span><span>):</span>
	<span>for</span> <span>i</span> <span>in</span> <span>range</span><span>(</span><span>number</span><span>):</span>
		<span>await</span> <span>connection</span><span>.</span><span>send</span><span>(</span><span>f'count </span><span>{</span><span>i</span><span>}</span><span>\n</span><span>'</span><span>,</span> <span>finish</span><span>=</span><span>False</span><span>)</span>
		<span>await</span> <span>asyncio</span><span>.</span><span>sleep</span><span>(</span><span>1</span><span>)</span>
	<span>await</span> <span>connection</span><span>.</span><span>send</span><span>(</span><span>''</span><span>,</span> <span>finish</span><span>=</span><span>True</span><span>)</span>


<span>@</span><span>router</span><span>.</span><span>route</span><span>(</span><span>'/echo'</span><span>)</span>
<span>async</span> <span>def</span> <span>echo</span><span>(</span><span>connection</span><span>):</span>
	<span>body</span> <span>=</span> <span>await</span> <span>connection</span><span>.</span><span>body</span><span>()</span>
	<span>await</span> <span>connection</span><span>.</span><span>send</span><span>(</span><span>body</span><span>,</span> <span>finish</span><span>=</span><span>True</span><span>)</span>


<span>app</span> <span>=</span> <span>aaf</span><span>([</span><span>router</span><span>])</span>
</code></pre></div></div>
<p>I hope this snippet of how I want the framework to look like is self-explanatory. But here are some of the key things I want to achieve:</p>
<ol>
  <li>It should be able to handle HTTP response declaratively and imperatively.</li>
  <li>It should support Flask style routing with parameter parsing.</li>
</ol>


<h2 id="connection-class">Connection class</h2>
<p>The <code>Connection</code> class will represent an ASGI HTTP or WebSocket connection. It’s a class that encapsulates the three basic elements in ASGI, namely <code>scope</code>, <code>send</code> and <code>receive</code>, and expose some convenient methods and properties so that users don’t need to verbosely write out all the ASGI messages and parse everything, such as cookies and headers, from <code>scope</code>. But it should allow users to access the original <code>scope</code>, <code>send</code> and <code>receive</code> when they want to, so that the composability of ASGI applications is maintained. For example, it should allow user to delegate certain <code>connection</code>s to another ASGI application by calling <code>another_asgi_app(connection.scope, connectionn.asgi_send, connection.asgi_receive)</code>.</p>

<p>Here’s a simple implementation of the <code>Connection</code> class.</p>
<div><div><pre><code><span>from</span> <span>enum</span> <span>import</span> <span>Enum</span>
<span>from</span> <span>functools</span> <span>import</span> <span>cached_property</span>
<span>from</span> <span>http.cookies</span> <span>import</span> <span>SimpleCookie</span>
<span>from</span> <span>typing</span> <span>import</span> <span>Any</span><span>,</span> <span>Awaitable</span><span>,</span> <span>Callable</span><span>,</span> <span>Optional</span><span>,</span> <span>Union</span>
<span>from</span> <span>urllib.parse</span> <span>import</span> <span>parse_qsl</span><span>,</span> <span>unquote_plus</span>

<span>from</span> <span>werkzeug.datastructures</span> <span>import</span> <span>Headers</span><span>,</span> <span>MultiDict</span>

<span>CoroutineFunction</span> <span>=</span> <span>Callable</span><span>[[</span><span>Any</span><span>],</span> <span>Awaitable</span><span>]</span>


<span>class</span> <span>ConnectionType</span><span>(</span><span>Enum</span><span>):</span>
    <span>HTTP</span> <span>=</span> <span>"HTTP"</span>
    <span>WebSocket</span> <span>=</span> <span>"WebSocket"</span>


<span>class</span> <span>Connection</span><span>:</span>
    <span>def</span> <span>__init__</span><span>(</span>
        <span>self</span><span>,</span> <span>scope</span><span>:</span> <span>dict</span><span>,</span> <span>*</span><span>,</span> <span>send</span><span>:</span> <span>CoroutineFunction</span><span>,</span> <span>receive</span><span>:</span> <span>CoroutineFunction</span>
    <span>):</span>
        <span>self</span><span>.</span><span>scope</span> <span>=</span> <span>scope</span>
        <span>self</span><span>.</span><span>asgi_send</span> <span>=</span> <span>send</span>
        <span>self</span><span>.</span><span>asgi_receive</span> <span>=</span> <span>receive</span>

        <span>self</span><span>.</span><span>started</span> <span>=</span> <span>False</span>
        <span>self</span><span>.</span><span>finished</span> <span>=</span> <span>False</span>
        <span>self</span><span>.</span><span>resp_headers</span> <span>=</span> <span>Headers</span><span>()</span>
        <span>self</span><span>.</span><span>resp_cookies</span><span>:</span> <span>SimpleCookie</span> <span>=</span> <span>SimpleCookie</span><span>()</span>
        <span>self</span><span>.</span><span>resp_status_code</span><span>:</span> <span>Optional</span><span>[</span><span>int</span><span>]</span> <span>=</span> <span>None</span>

        <span>self</span><span>.</span><span>http_body</span> <span>=</span> <span>b""</span>
        <span>self</span><span>.</span><span>http_has_more_body</span> <span>=</span> <span>True</span>
        <span>self</span><span>.</span><span>http_received_body_length</span> <span>=</span> <span>0</span>

    <span>@</span><span>cached_property</span>
    <span>def</span> <span>req_headers</span><span>(</span><span>self</span><span>)</span> <span>-&gt;</span> <span>Headers</span><span>:</span>
        <span>headers</span> <span>=</span> <span>Headers</span><span>()</span>
        <span>for</span> <span>(</span><span>k</span><span>,</span> <span>v</span><span>)</span> <span>in</span> <span>self</span><span>.</span><span>scope</span><span>[</span><span>"headers"</span><span>]:</span>
            <span>headers</span><span>.</span><span>add</span><span>(</span><span>k</span><span>.</span><span>decode</span><span>(</span><span>"ascii"</span><span>),</span> <span>v</span><span>.</span><span>decode</span><span>(</span><span>"ascii"</span><span>))</span>
        <span>return</span> <span>headers</span>

    <span>@</span><span>cached_property</span>
    <span>def</span> <span>req_cookies</span><span>(</span><span>self</span><span>)</span> <span>-&gt;</span> <span>SimpleCookie</span><span>:</span>
        <span>cookie</span> <span>=</span> <span>SimpleCookie</span><span>()</span>
        <span>cookie</span><span>.</span><span>load</span><span>(</span><span>self</span><span>.</span><span>req_headers</span><span>.</span><span>get</span><span>(</span><span>"cookie"</span><span>,</span> <span>{}))</span>
        <span>return</span> <span>cookie</span>

    <span>@</span><span>cached_property</span>
    <span>def</span> <span>type</span><span>(</span><span>self</span><span>)</span> <span>-&gt;</span> <span>ConnectionType</span><span>:</span>
        <span>return</span> <span>(</span>
            <span>ConnectionType</span><span>.</span><span>WebSocket</span>
            <span>if</span> <span>self</span><span>.</span><span>scope</span><span>.</span><span>get</span><span>(</span><span>"type"</span><span>)</span> <span>==</span> <span>"websocket"</span>
            <span>else</span> <span>ConnectionType</span><span>.</span><span>HTTP</span>
        <span>)</span>

    <span>@</span><span>cached_property</span>
    <span>def</span> <span>method</span><span>(</span><span>self</span><span>)</span> <span>-&gt;</span> <span>str</span><span>:</span>
        <span>return</span> <span>self</span><span>.</span><span>scope</span><span>[</span><span>"method"</span><span>]</span>

    <span>@</span><span>cached_property</span>
    <span>def</span> <span>path</span><span>(</span><span>self</span><span>)</span> <span>-&gt;</span> <span>str</span><span>:</span>
        <span>return</span> <span>self</span><span>.</span><span>sc…</span></code></pre></div></div></div></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://shenli.dev/2020/06/20/asgi-from-scratch.html">https://shenli.dev/2020/06/20/asgi-from-scratch.html</a></em></p>]]>
            </description>
            <link>https://shenli.dev/2020/06/20/asgi-from-scratch.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23644252</guid>
            <pubDate>Thu, 25 Jun 2020 19:04:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Testers vs. TDD]]>
            </title>
            <description>
<![CDATA[
Score 26 | Comments 45 (<a href="https://news.ycombinator.com/item?id=23644228">thread link</a>) | @ohjeez
<br/>
June 25, 2020 | https://www.functionize.com/blog/testers-vs-tdd | <a href="https://web.archive.org/web/*/https://www.functionize.com/blog/testers-vs-tdd">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
          <p><img width="1080" height="634" src="https://3laqvw22wekb3ykm8z4dbnq8-wpengine.netdna-ssl.com/wp-content/uploads/2020/06/TDD-vs-Testers2.jpg" alt="Testers vs TDD" srcset="https://www.functionize.com/wp-content/uploads/2020/06/TDD-vs-Testers2.jpg 1080w, https://www.functionize.com/wp-content/uploads/2020/06/TDD-vs-Testers2-300x176.jpg 300w, https://www.functionize.com/wp-content/uploads/2020/06/TDD-vs-Testers2-1024x601.jpg 1024w, https://www.functionize.com/wp-content/uploads/2020/06/TDD-vs-Testers2-768x451.jpg 768w" sizes="(max-width: 1080px) 100vw, 1080px">      </p>	  
    
        <blockquote><p>Test-driven development was supposed to eliminate the need for independent testing. Alas, it doesn’t go far enough.</p></blockquote>
<p>Test-driven development (TDD) earned a reputation of making software more robust. Does that mean you can fire all the testers? Spoiler: No.</p>
<p><a href="https://martinfowler.com/bliki/TestDrivenDevelopment.html" target="blank" rel="noopener noreferrer">Test-driven development</a> is a method for writing software in small chunks. You start with a test, then write functional code to make the test pass, and finally refactor the functional code to clean it up. The idea of TDD was proposed by <a href="https://amzn.to/3doabIA" target="blank" rel="noopener noreferrer">Kent Beck</a> in the early 1990s, as part of Extreme Programming, an Agile software development methodology.</p>
<p>TDD is sometimes summarized as “Red, Green, Refactor.” The interfaces on many testing harnesses, such as JUnit (for Java) and NUnit (for .NET), show red lights when tests fail and green lights when tests pass. There’s another step to consider, however. You need to think about the desired behavior and carve out a small chunk of code – typically five lines – to implement next.</p>
<p>As proposed by Beck, in TDD you never write functional code until you have a failing test. Yet, it takes practice to learn to write the tests first (rather than after the fact); developers often have trouble shifting their habitual way of working. Writing the tests before the functional code just feels <em>wrong.</em> You do get used to it, though it may take months; by then it starts feeling <em>right</em>.</p>
<p>The <a href="https://www.functionize.com/blog/what-is-test-driven-development-tdd/">biggest benefit of TDD</a> is that it removes the fear of breaking your code. As you add unit tests and functional code, you also build <a href="https://www.functionize.com/blog/dont-fail-your-next-interview-know-what-differentiates-regression-testing-from-retesting/">a library of regression tests</a> that you run frequently. When you add a new feature, fix a bug, or refactor to clean up your code, running the tests again reassures you that you didn’t break anything. Or at least it confirms that you didn’t break any of the tests that <em>you</em> wrote.</p>
<h3>What do testers bring to the table?</h3>
<p>Software managers are sometimes tempted to eliminate or reduce software QA departments when the coders adopt TDD, on the grounds that the programmers are also writing tests. That decision usually is a mistake, because <a href="https://www.functionize.com/blog/five-must-have-skills-to-look-for-in-a-qa-tester/">testers provide value</a> outside of the developers’ unit tests.</p>
<p>Unit tests are only one of the kinds of tests needed to adequately cover modern code. TDD developers rarely write end-to-end integration tests. They may avoid writing unit tests that require significant setup or that rely on other software components, such as a populated database.</p>
<p>Dedicated testers are more likely than coders to take the time to perform exploratory (ad-hoc) testing, which can find bugs that weren’t imagined during the development of the code. Testers also come to the product with fresh eyes compared to the coders who have been immersed in the software for long hours.</p>
<p>Additionally, software developers often are not interested in setting up CI/CD tooling or in organizing the team’s tests into a master regression test. Testers consider all of that to be part of the job. Developers may not be involved in implementing shift left testing beyond TDD. &nbsp;For shift left testing, testers can gather information, help with requirements management, and help to define the acceptance criteria, before a single test or line of functional code is complete.</p>
<h3>What bugs do testers find that TDD doesn’t?</h3>
<p>Security is one large, important testing area that isn’t normally addressed by writing unit tests. Testers look for security flaws with automated vulnerability testing tools, manual security assessments, penetration tests, security audits, and security reviews.</p>
<p>It’s difficult for developers to write <a href="https://www.functionize.com/blog/the-challenges-of-testing-guis/">unit tests to test GUIs</a>. Instead, testers use automation tools specific to the supported application environments, such as browsers, desktop applications, and mobile apps.</p>
<p>Developers can have a hard time with hardware-dependent bugs, as the dominant way of working is for a coder to work on a single machine. QA departments often collect rooms full of varied computers and devices, as well as images of many operating system versions. An alternative way of testing on many different model devices is to use a crowd-sourced testing service.</p>
<p>While TDD can theoretically catch bugs in edge cases, they are called “edge cases” for a good reason. When a coder designs the tests for a function point, obscure edge cases may escape notice in the heat of the moment. Testers are more likely to find these than are the coders who wrote the software.</p>
<p>Similarly, cross-module flaws can sometimes escape scrutiny in unit tests. They can easily arise when one programmer misunderstands the interface or boundary conditions of another programmer’s module. Cross-module bugs are often found during end-to-end testing and ad-hoc testing.</p>
<p>In summary, while there’s a lot to be said for TDD as a development practice, it doesn’t usually provide complete test coverage of your code. For that, you still need testers.</p>
<blockquote><p>Whoever writes the test cases, it makes sense to follow established guidelines. <a href="https://www.functionize.com/project/best-practices-for-effective-test-case-writing/">These</a> might help.</p></blockquote>
<div>
<div>
<p><img src="https://3laqvw22wekb3ykm8z4dbnq8-wpengine.netdna-ssl.com/wp-content/uploads/2020/02/author-Martin-Heller.jpg" alt="Martin Heller"></p>
<div>
<p><span>by</span> Martin Heller</p>
<p>Martin Heller is a freelance writer. Formerly a web and Windows programming consultant, he developed databases, software, and websites from 1986 to 2010. More recently, he has served as VP of technology and education at Alpha Software and chairman and CEO at Tubifi.</p>
</div>

</div>
</div>
<!-- AddThis Advanced Settings above via filter on the_content --><!-- AddThis Advanced Settings below via filter on the_content --><!-- AddThis Advanced Settings generic via filter on the_content --><!-- AddThis Share Buttons above via filter on the_content --><!-- AddThis Share Buttons below via filter on the_content --><!-- AddThis Share Buttons generic via filter on the_content -->  </div></div>]]>
            </description>
            <link>https://www.functionize.com/blog/testers-vs-tdd</link>
            <guid isPermaLink="false">hacker-news-small-sites-23644228</guid>
            <pubDate>Thu, 25 Jun 2020 19:02:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How we launched our MVP in 3 weeks]]>
            </title>
            <description>
<![CDATA[
Score 47 | Comments 62 (<a href="https://news.ycombinator.com/item?id=23642739">thread link</a>) | @adamthewan
<br/>
June 25, 2020 | https://adamthewan.com/blog/meetbutter/how-we-built-meetbutter-three-weeks/ | <a href="https://web.archive.org/web/*/https://adamthewan.com/blog/meetbutter/how-we-built-meetbutter-three-weeks/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAOCAIAAACgpqunAAAACXBIWXMAAAsSAAALEgHS3X78AAADWElEQVQozxWT21MaBxTG95/oUx/71ulDM2msjk2nLRgcjZHEiRgpiQmiIVgUlmyAhb3Ccr8srMsdFpQFuQaQBBMTBLWY6Ux0Js3UNu3YPnQy0z+gY966fT5n5vu+8/0OwFLNsK2hVyQQTRTTciGy7oWr61TTj1Rdxi2WapXS/Q12l7E1AkgtHewkfU8rmX4+8iIV6AAhok7jda8lGiJZy4OkDaRJXQJfzbtNJQrkfZZKxNGMOBsvW697nZO3x2cnr/4Ikw27ng+Rj4EG/9PZu9edWoWyriLmzw0qC41vMfaWx1wWlClD3gmVaWyXYwYJ/0GW2a9m+x64LFiLedpA98mbEldDtTYYvIpaP7FocYeh7oG3PHCpmOim/AcRdymfflDM3SznZ7z4HUjJuYxFO8iTujwA3UuszUdtIFPJ/vh8e4exR2mkJYzNy1wx1X1cdpz9Lvpw/umT9se7ux9tcJ9ZNSmTKmPTbzJkAyBBXnbNu3I/W6gfRJotjXtdrvLoFtMRdysT/eHD+Y3zf794//fUu9+g/R7pd/jvSZ3626xwlKT/KbB4NykWuS9esI4pLTMO83Uc/k6KjYzYKaLFsZk4q0jHR/Z7NyNeBlri0sHa4Yt+LJiGV9ij7ikwLnVMLhBDw8jQEDqxiImniWkJI5Xio5ehWalFPg7Lpx7JJbBiGuYjeVSNbwbT/5z+lVnnc+wOcG3RNqnEL11Ev5lCpXp88j4qvkWMjC6Pjq2JrtogZUqnYMHbybSv0Mm1VPNzQYQ4qh52O2Wt3A+IRc4vL+CiWcTMs9ZCTBawyGn0soicGA/eWYiZVnJZ+plBGSfU4Vq48ufR4dnhyUErx4a/tmpigEjkGL6Ea/F4utlRm6LXH2FXZomvJEgmt/fr6ftB75ds+BlLbRuX44a7bo8p4rPGQKXdrA4L/ACjI6T4BoFns1AgNSdjr4y5hoexGQPZe3s8eHXqs1Yx7UZ/503M1V6S0msKtrk1IHS8eYn7v2cpiMoo9JYXlUGUZNw1MW9XOXxC+NUQAy7FoYWEQFIAqyOarLAdc7f56EujMomscDHPNjDnxGROdM6FyezYtxJC/3Bzp3+sUIeU39OW5Qz1sOgylgT+C4luMbknPAON1e1gIeFrD/Z+/g9UCcPcvxQNXAAAAABJRU5ErkJggg==" alt="Cover"></p></div><div><div><div><p>This should be </p><!-- --><p>an</p><!-- --> <!-- --><p>11 min read</p><p>June 12, 2020</p></div></div><p><img src="https://adamthewan.com/static/adam-head-0b2b466e69071c2bd52efa9911165bc6.png"></p></div><p>Usually, when people think about building and launching a startup, they plan it out a few weeks in advance. In my experience doing software consulting, I’ve seen and worked on some projects where the founders take 2 - 3 months to launch the first version of their product. That’s too much time and effort sunk into a project that may not work.</p><h2>Why you need to get your Minimum Viable Product out ASAP</h2><p>The problem is that most people are not comfortable with launching a minimum viable product. Founders are often creative people who love to explore and dive into “wouldn’t it be cool if”s. This habit can result in a continuous loop of adding features, even before the first version of your product is released.</p><p>Perfectionism can often get in the way of execution, and I’ve fallen for this trap many times. My first product (SideQuest) took me four months to build and launch. To continue developing an untested product is, to put it bluntly, arrogant. Here’s why: it assumes that what you are making is vital for your customer. It assumes that you know what’s best for your user. You don’t.</p><figure>
    <span>
      <a href="https://adamthewan.com/static/bf4b544235b8f033c381798a61ce5e33/c1b63/reiterations.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="Image: What your startup journey will probably look like" title="Image: What your startup journey will probably look like" src="https://adamthewan.com/static/bf4b544235b8f033c381798a61ce5e33/fcda8/reiterations.png" srcset="https://adamthewan.com/static/bf4b544235b8f033c381798a61ce5e33/12f09/reiterations.png 148w,https://adamthewan.com/static/bf4b544235b8f033c381798a61ce5e33/e4a3f/reiterations.png 295w,https://adamthewan.com/static/bf4b544235b8f033c381798a61ce5e33/fcda8/reiterations.png 590w,https://adamthewan.com/static/bf4b544235b8f033c381798a61ce5e33/efc66/reiterations.png 885w,https://adamthewan.com/static/bf4b544235b8f033c381798a61ce5e33/c83ae/reiterations.png 1180w,https://adamthewan.com/static/bf4b544235b8f033c381798a61ce5e33/c1b63/reiterations.png 1200w" sizes="(max-width: 590px) 100vw, 590px" loading="lazy">
  </a>
    </span>
    <figcaption>Image: What your startup journey will probably look like</figcaption>
  </figure><p>No founder knows until they launch their startup and get feedback from people. Your first version is likely going to suck; it might even miss the mark or be utterly irrelevant to the market. You need to get any negative and positive signals from your target market as soon as possible.</p><p>That was what we tried to do with MeetButter. Everyone on our team has had experience getting burnt by wasting time, runway, effort, and emotion building products or features that were inconsequential in the larger picture.</p><p>Here’s the story of how we managed to build and ship MeetButter in three weeks.</p><h3>Step 1 - Identification</h3><figure>
    <span>
      <a href="https://adamthewan.com/static/bb7bc5be7eb59accce1ffcd6b43444df/c1b63/slack-discussion.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="It started with a thread" title="It started with a thread" src="https://adamthewan.com/static/bb7bc5be7eb59accce1ffcd6b43444df/fcda8/slack-discussion.png" srcset="https://adamthewan.com/static/bb7bc5be7eb59accce1ffcd6b43444df/12f09/slack-discussion.png 148w,https://adamthewan.com/static/bb7bc5be7eb59accce1ffcd6b43444df/e4a3f/slack-discussion.png 295w,https://adamthewan.com/static/bb7bc5be7eb59accce1ffcd6b43444df/fcda8/slack-discussion.png 590w,https://adamthewan.com/static/bb7bc5be7eb59accce1ffcd6b43444df/efc66/slack-discussion.png 885w,https://adamthewan.com/static/bb7bc5be7eb59accce1ffcd6b43444df/c83ae/slack-discussion.png 1180w,https://adamthewan.com/static/bb7bc5be7eb59accce1ffcd6b43444df/c1b63/slack-discussion.png 1200w" sizes="(max-width: 590px) 100vw, 590px" loading="lazy">
  </a>
    </span>
    <figcaption>It started with a thread</figcaption>
  </figure><p>The first spark for MeetButter was a Slack thread discussing the pains teachers and educators were dealing with transitioning their classrooms from offline to online. We found that there was a very human problem with online video conferencing - they only allowed the focus to one speaker at a time. It was awkward interrupting the speaker, and this caused some participants to feel reluctant to engage. The discussion thread grew, with more anecdotes and feedback from our friends and family.</p><p>Identifying the problem is the first step. It’s crucial to figure out the groups of people that are facing the same issues and gathering feedback from them. </p><h3>Step 2 - Investigation</h3><p>We decided to take this asynchronous discussion and organize a synchronous brainstorm session. During this particular session, we discussed three significant problems that we had identified and were interested in solving. On the list was the aforementioned “video conferencing” - which eventually became MeetButter.</p><figure>
    <span>
      <a href="https://adamthewan.com/static/a39386985de85513d6f9d5134921e3f4/c1b63/brainstorm.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="Breaking down the current video conferencing experience" title="Breaking down the current video conferencing experience" src="https://adamthewan.com/static/a39386985de85513d6f9d5134921e3f4/fcda8/brainstorm.png" srcset="https://adamthewan.com/static/a39386985de85513d6f9d5134921e3f4/12f09/brainstorm.png 148w,https://adamthewan.com/static/a39386985de85513d6f9d5134921e3f4/e4a3f/brainstorm.png 295w,https://adamthewan.com/static/a39386985de85513d6f9d5134921e3f4/fcda8/brainstorm.png 590w,https://adamthewan.com/static/a39386985de85513d6f9d5134921e3f4/efc66/brainstorm.png 885w,https://adamthewan.com/static/a39386985de85513d6f9d5134921e3f4/c83ae/brainstorm.png 1180w,https://adamthewan.com/static/a39386985de85513d6f9d5134921e3f4/c1b63/brainstorm.png 1200w" sizes="(max-width: 590px) 100vw, 590px" loading="lazy">
  </a>
    </span>
    <figcaption>Breaking down the current video conferencing experience</figcaption>
  </figure><p>Some significant points were brought up by everyone on the team, and we found that these were problems that each one of us had faced while doing online video conferencing:</p><ol><li>It’s difficult to indicate an interest in speaking, reply to the current conversation, or add to the discussion without feeling like you’re interrupting the current speaker.</li><li>It’s impossible to transition smoothly between one speaker to the next. Sometimes mid-sentence pauses are met with several speakers trying to enter into the conversation at once. Combined with lag, this can get quite awkward.</li><li>The avoidance of awkwardness causes some people to remain quiet.</li><li>The loudest voice in the room problem - some people naturally dominated discussions.</li><li>Social cues are almost non-existent when your entire team gets boxed into tiny windows on-screen and are only visible from their shoulder up.</li></ol><p>The purpose of this brainstorm was not to narrow down into solutions, but it was to dive deep into the problems.</p><div><p>Adam is typing something... (Click to reveal)</p><p><img src="https://adamthewan.com/static/adam-head-0b2b466e69071c2bd52efa9911165bc6.png"></p></div><h3>Step 3 - Sketching</h3><p>After the brainstorm session, we discussed some ideas on how to tackle the problem. Solutions can seem pretty vague, and usually, what happens is that several keywords get thrown around. For us, it was “queue,” “overlay,” and “polls.” It’s good to note that people often visualize keywords differently and form very different concepts in their heads. </p><p>A picture is worth a thousand words. Sketching is an essential skill to learn for any founder, as it’s the best medium to transfer your ideas with a low signal-noise ratio. People often misunderstand your words. If you’re not good at drawing, it’s good to learn how to sketch out a prototype digitally using free tools like Figma. I have even used Google Slides to build a low fidelity prototype for a client once! Sometimes I even screenshot parts of other apps and combine them into a Frankenstein of an image - anything to help bridge the gap between your vision and their imagination.</p><figure>
    <span>
      <a href="https://adamthewan.com/static/ac5ea0b862d651aee09be122cf1e3d76/07a9c/prototype-sketch.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="Sketch of the app that turned into MeetButter" title="Sketch of the app that turned into MeetButter" src="https://adamthewan.com/static/ac5ea0b862d651aee09be122cf1e3d76/fcda8/prototype-sketch.png" srcset="https://adamthewan.com/static/ac5ea0b862d651aee09be122cf1e3d76/12f09/prototype-sketch.png 148w,https://adamthewan.com/static/ac5ea0b862d651aee09be122cf1e3d76/e4a3f/prototype-sketch.png 295w,https://adamthewan.com/static/ac5ea0b862d651aee09be122cf1e3d76/fcda8/prototype-sketch.png 590w,https://adamthewan.com/static/ac5ea0b862d651aee09be122cf1e3d76/efc66/prototype-sketch.png 885w,https://adamthewan.com/static/ac5ea0b862d651aee09be122cf1e3d76/c83ae/prototype-sketch.png 1180w,https://adamthewan.com/static/ac5ea0b862d651aee09be122cf1e3d76/07a9c/prototype-sketch.png 1440w" sizes="(max-width: 590px) 100vw, 590px" loading="lazy">
  </a>
    </span>
    <figcaption>Sketch of the app that turned into MeetButter</figcaption>
  </figure><p>Based on the feedback and ideas from the team, this was the very first sketch for MeetButter that I built using Figma. After sharing it on our team Slack, we held a meeting to discuss the steps moving forward. We decided to cut out some features and instead focus on the queuing functionality as we were able to test it internally during our daily standup calls.</p><h3>Step 4 - Prototyping</h3><p>I won’t go into too much detail about how we built the prototype. This step will be different for every team: some teams will opt to do a no-code prototype using tools like AirTable and Google Forms; some will choose to do a “simulated” prototype using Figma or Zeplin; some will opt to build a fully functioning albeit minimal prototype using code. We decided to do the latter as it was the fastest for me to code something quickly.</p><figure>
    <span>
      <a href="https://adamthewan.com/static/2bbc76946aa01d921cf2ae13d7aeaeee/c1b63/hackathon.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="Developers during a hackathon weekend" title="Developers during a hackathon weekend" src="https://adamthewan.com/static/2bbc76946aa01d921cf2ae13d7aeaeee/fcda8/hackathon.png" srcset="https://adamthewan.com/static/2bbc76946aa01d921cf2ae13d7aeaeee/12f09/hackathon.png 148w,https://adamthewan.com/static/2bbc76946aa01d921cf2ae13d7aeaeee/e4a3f/hackathon.png 295w,https://adamthewan.com/static/2bbc76946aa01d921cf2ae13d7aeaeee/fcda8/hackathon.png 590w,https://adamthewan.com/static/2bbc76946aa01d921cf2ae13d7aeaeee/efc66/hackathon.png 885w,https://adamthewan.com/static/2bbc76946aa01d921cf2ae13d7aeaeee/c83ae/hackathon.png 1180w,https://adamthewan.com/static/2bbc76946aa01d921cf2ae13d7aeaeee/c1b63/hackathon.png 1200w" sizes="(max-width: 590px) 100vw, 590px" loading="lazy">
  </a>
    </span>
    <figcaption>Developers during a hackathon weekend</figcaption>
  </figure><p>The purpose of our prototype was to test:</p><ol><li><p>If the core hypothesis works. In this case, we wanted to test if allowing participants to queue would help meetings flow better.</p></li><li><p>If we could build the tech. Founders often underestimate the technical work that goes into creating their vision. Building a prototype allows you to do a mini feasibility test.</p></li></ol><div><p>Adam is typing something... (Click to reveal)</p><p><img src="https://adamthewan.com/static/adam-head-0b2b466e69071c2bd52efa9911165bc6.png"></p></div><h3>Step 5 - Testing and Feedback</h3><figure>
    <span>
      <a href="https://adamthewan.com/static/8282a9af1ca9ee66ef4e2591a938b2d3/c1b63/mvp.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="It's alive!" title="It's alive!" src="https://adamthewan.com/static/8282a9af1ca9ee66ef4e2591a938b2d3/fcda8/mvp.png" srcset="https://adamthewan.com/static/8282a9af1ca9ee66ef4e2591a938b2d3/12f09/mvp.png 148w,https://adamthewan.com/static/8282a9af1ca9ee66ef4e2591a938b2d3/e4a3f/mvp.png 295w,https://adamthewan.com/static/8282a9af1ca9ee66ef4e2591a938b2d3/fcda8/mvp.png 590w,https://adamthewan.com/static/8282a9af1ca9ee66ef4e2591a938b2d3/efc66/mvp.png 885w,https://adamthewan.com/static/8282a9af1ca9ee66ef4e2591a938b2d3/c83ae/mvp.png 1180w,https://adamthewan.com/static/8282a9af1ca9ee66ef4e2591a938b2d3/c1b63/mvp.png 1200w" sizes="(max-width: 590px) 100vw, 590px" loading="lazy">
  </a>
    </span>
    <figcaption>It's alive!</figcaption>
  </figure><p>Once you have your prototype, you need to get it in front of some test users. Finding test users can be tricky.  Ideally, the test users should be from within your team; this was the case for us with MeetButter. It meant that we were building a product for ourselves, that we were part of our target market. Building a product to solve your problems has some apparent benefits: </p><ol><li>It creates a shorter and more efficient feedback loop.</li><li>It’s easier to innovate on issues you face</li><li>It somewhat validates your market.</li></ol><p>If you are building a product that’s not for yourself, I’d suggest finding at least ten people within your networks who can become your loyal test users.</p><p>MeetButter was also super easy to integrate into our daily workflow. All we had to do was open up the web app during our regular standup calls. It’s essential to build some sort of feedback loop. I sent a Google Form to the participants of the meeting to gather initial feedback as soon as the meeting ended - it’s best to strike while the iron is hot. We also had several Slack threads discussing additional ideas that came up as we continued testing.</p><h3>Step 6 - Reiteration</h3><p>After testing our prototype, we collected the feedback and went back to the drawing board. At this point, you have to make a clear decision with your prototype - do you continue to reiterate, or do you kill the project? We found that our prototype worked quite well, and although we were skeptical, there was a sense that we were onto something. We started using the prototype in every meeting, so it was hard to deny that our team internally found it useful.</p><figure>
    <span>
      <a href="https://adamthewan.com/static/e766445b8bfa6e293cbb0db6b23fedef/c1b63/feedback-loop.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="The typical product development feedback loop" title="The typical product development feedback loop" src="https://adamthewan.com/static/e766445b8bfa6e293cbb0db6b23fedef/fcda8/feedback-loop.png" srcset="https://adamthewan.com/static/e766445b8bfa6e293cbb0db6b23fedef/12f09/feedback-loop.png 148w,https://adamthewan.com/static/e766445b8bfa6e293cbb0db6b23fedef/e4a3f/feedback-loop.png 295w,https://adamthewan.com/static/e766445b8bfa6e293cbb0db6b23fedef/fcda8/feedback-loop.png 590w,https://adamthewan.com/static/e766445b8bfa6e293cbb0db6b23fedef/efc66/feedback-loop.png 885w,https://adamthewan.com/static/e766445b8bfa6e293cbb0db6b23fedef/c83ae/feedback-loop.png 1180w,https://adamthewan.com/static/e766445b8bfa6e293cbb0db6b23fedef/c1b63/feedback-loop.png 1200w" sizes="(max-width: 590px) 100vw, 590px" loading="lazy">
  </a>
    </span>
    <figcaption>The typical product development feedback loop</figcaption>
  </figure><p>We repeated the process of designing, reiterating, and receiving feedback several times. Our testing group grew from our internal team of five people out to our friends within our social circles.</p><h3>Final Step - Launch</h3><p>After a few rounds of iterations, our prototype slowly shed its pieces and morphed into something resembling a product. As soon as we exhausted our immediate networks, we knew that the next step was to launch MeetButter beyond internal test users.</p><p>I began to lay the groundwork for a codebase that could grow into a scalable project. Our tech stack ended up being the following:</p><ul><li>Frontend - NextJS with Redux and GraphQL</li><li>Backend - A mix of Firebase and an Express server that’s powered by Apollo GraphQL and Sequelize</li><li>Infrastructure - We used Netlify and AWS to deployment</li></ul><figure>
    <span>
      <a href="https://adamthewan.com/static/ab6b779f27ff6765213b06367efeec87/c1b63/pmf.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="Why it's important to fail fast" title="Why it's important to fail fast" src="https://adamthewan.com/static/ab6b779f27ff6765213b06367efeec87/fcda8/pmf.png" srcset="https://adamthewan.com/static/ab6b779f27ff6765213b06367efeec87/12f09/pmf.png 148w,https://adamthewan.com/static/ab6b779f27ff6765213b06367efeec87/e4a3f/pmf.png 295w,https://adamthewan.com/static/ab6b779f27ff6765213b06367efeec87/fcda8/pmf.png 590w,https://adamthewan.com/static/ab6b779f27ff6765213b06367efeec87/efc66/pmf.png 885w,https://adamthewan.com/static/ab6b779f27ff6765213b06367efeec87/c83ae/pmf.png 1180w,https://adamthewan.com/static/ab6b779f27ff6765213b06367efeec87/c1b63/pmf.png 1200w" sizes="(max-width: 590px) 100vw, 590px" loading="lazy">
  </a>
    </span>
    <figcaption>Why it's important to fail fast</figcaption>
  </figure><p>Several factors allowed us to build and ship MeetButter quickly.</p><p>Firstly, we were fortunate to have had the experience and the skills to execute quickly. We didn’t run into many technical limitations, as each one of us had filled the significant roles that were needed. These roles include design/UI UX, software development, and marketing/networking.</p><p>Secondly, we tried to follow the best practices for idea generation. The brainstorm that led to MeetButter wasn’t the first one that we had together. It was probably our fifth brainstorm session after getting together as a team as Project Phoenix. With a lot of practice, we were able to build a set of best practices to have productive brainstorm sessions, get feedback, and reiterate.</p><p>Thirdly, we were close to our target market, which allowed us to test fast and slowly expand our test userbase.</p><p>Fourth, we threw perfection out the window. Our prototype didn’t work 100% of the time, had a bunch of bugs, and built with the bare minimum UI. Despite this, we still used it every single day for our video calls. It was good …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://adamthewan.com/blog/meetbutter/how-we-built-meetbutter-three-weeks/">https://adamthewan.com/blog/meetbutter/how-we-built-meetbutter-three-weeks/</a></em></p>]]>
            </description>
            <link>https://adamthewan.com/blog/meetbutter/how-we-built-meetbutter-three-weeks/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23642739</guid>
            <pubDate>Thu, 25 Jun 2020 16:55:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[ARM Mac: Why I'm Worried About Virtualization]]>
            </title>
            <description>
<![CDATA[
Score 147 | Comments 283 (<a href="https://news.ycombinator.com/item?id=23642178">thread link</a>) | @bmalehorn
<br/>
June 25, 2020 | https://bmalehorn.com/arm-mac/ | <a href="https://web.archive.org/web/*/https://bmalehorn.com/arm-mac/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>It's late 2020 and you just got a brand-new Mac with Apple's own ARM processors. Exciting! But what will development be like?</p><h2>Docker</h2><p><img src="data:image/png;base64,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" width="150"></p><p>I would <strong>expect about a 5x slowdown running Docker images.</strong></p><p>Docker on a Mac utilizes a <strong>hypervisor</strong>. Hypervisors rely on running the <strong>same architecture on the host as the guest</strong>, and are about about 1x - 2x as slow as running natively.</p><p>Since you're running ARM Mac, these hypervisors can only run ARM Linux. They can't run x86_64 Linux.</p><p>What will happen instead? These tools will fall back on <strong>emulators</strong>. Emulators can run <strong>a different architecture between the host and the guest</strong>, but simulate the guest operating system at about 5x-10x slowdown.</p><div><p><img src="https://bmalehorn.com/static/perf-267ab9cfc29b6f68078fbe19892bce23.png"></p><p>A basic performance test comparing gzip performance on amd64 (hypervisor) and arm64v8 (emulator). Note that the emulator is over 6x slower. On an ARM Mac, the amd64 image will instead be 6x slower.</p></div><p>Why can't you update the Docker image to also support ARM? You theoretically could switch your backend to run ARM Linux. However, this would take months - renting out ARM instances, re-building all repositories, and a tense switch over. What if your hosting provider doesn't offer ARM instances with the same system requirements as x86_64? What if you complete this migration and find it runs at half the speed?</p><p>Worse, it might be impossible if your images include files downloaded off the internet, as those are often only compiled for x86_64.</p><div><p><img src="https://bmalehorn.com/static/phantomjs-615e9c8bc9d2deb5ca62a4533c1299d6.png"></p><p>An example of a Docker command that will only work on x86_64. PhantomJS does not release an arm build.</p></div><p>While moving your backend to ARM is far from impossible, it's a serious migration that you shouldn't take lightly. Getting a new laptop isn't enough justification to switch your backend architecture.</p><p>Another option is to <strong>run Docker remotely</strong>. You set up an x86_64 Linux server, then allow Docker to connect to it remotely. From then on, all Docker commands instead run on the server. This is also supported in Docker, <a href="https://www.digitalocean.com/community/tutorials/how-to-use-a-remote-docker-server-to-speed-up-your-workflow">here</a> is a tutorial on setting it up. This is what heavy Docker users will want to do.</p><h2>VirtualBox</h2><p><img src="https://bmalehorn.com/static/virtualbox-c37e4cc82b13d3c1c080f7ced273ae45.png" width="150"></p><p><strong>VirtualBox won't work.</strong></p><p>VirtualBox is a <strong>hypervisor</strong>. Therefore, <strong>it won't be able to run x86 Windows or x86 Linux</strong>.</p><p>You could use VirtualBox to run ARM Windows. Windows already supports ARM, and has a similar binary translation system to Apple's, so it can run x86 binaries. However, VirtualBox only supports x86 hosts and guests and is <a href="https://forums.virtualbox.org/viewtopic.php?f=8&amp;t=98742">unlikely to be ported by ARM</a>.</p><p>VMWare Fusion similarly is a hypervisor that only support x86, but <a href="https://twitter.com/VMwareFusion/status/1275483803536908288?s=20">they're thinking about supporting ARM</a>.</p><p>Instead of VirtualBox you might use QEMU, an emulator. However, QEMU is pretty low level and not often used to emulate Windows.</p><h2>Boot Camp</h2><p><img src="https://bmalehorn.com/static/boot-camp-f05493e57b0fe815dbc1d989ada98dd0.png" width="150"></p><p><strong>Boot Camp won't work.</strong></p><p><a href="https://support.apple.com/boot-camp">Boot Camp</a> is an Apple-approved way to dual-boot Mac OS and Windows. <a href="https://www.theverge.com/2020/6/24/21302213/apple-silicon-mac-arm-windows-support-boot-camp?utm_campaign=theverge&amp;utm_content=chorus&amp;utm_medium=social&amp;utm_source=twitter">Boot Camp will definitely not be available on ARM Macs</a>. It might be added later with the ability to run ARM Windows, though Microsoft <a href="https://www.theverge.com/2020/6/24/21302213/apple-silicon-mac-arm-windows-support-boot-camp">would have to approve</a>.</p><h2>Should I get an ARM Mac?</h2><p>The point of this post isn't to say that ARM Mac is a bad idea, but to give a realistic idea of what developing on one would look like assuming nothing changes. It's possible Apple could release more virtualization tools before the ARM Mac launches.</p><p>Should you get an ARM Mac if you're a developer? If you work largely on frontend, mobile, or native apps, you'll probably be fine. But if you use virtualization often, I wouldn't recommend it. There will be a lot of problems early on, and not all of them will have solutions. My biggest concern is getting an ARM Mac and realizing I simply can't run an essential application on it.</p><p>However if you like troubleshooting these issues and are excited about ARM Mac, go for it! My plan is for those kinds of people to fix these issues.</p><p>Know something I don't? Have questions? Email me at <a href="mailto:bmalehorn@gmail.com">bmalehorn@gmail.com</a>.</p></div></div>]]>
            </description>
            <link>https://bmalehorn.com/arm-mac/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23642178</guid>
            <pubDate>Thu, 25 Jun 2020 16:01:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[BLEU Score: Bilingual Evaluation Understudy]]>
            </title>
            <description>
<![CDATA[
Score 56 | Comments 12 (<a href="https://news.ycombinator.com/item?id=23641791">thread link</a>) | @keyboardman
<br/>
June 25, 2020 | https://leimao.github.io/blog/BLEU-Score/ | <a href="https://web.archive.org/web/*/https://leimao.github.io/blog/BLEU-Score/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <h3 id="introduction">Introduction</h3>

<p>BLEU is a standard algorithm for evaluating the machine translations against the human translations. At first I thought it should be very straightforward to use. However, it turns out that there are a lot of caveats.</p>



<p>In this blog post, I am going to show the BLEU algorithm in detail and talk about the caveats.</p>

<h3 id="english-translation-example">English Translation Example</h3>

<p>We will use the following examples to illustrate how to compute the BLEU scores.</p>

<h4 id="example-1">Example 1</h4>

<p>Chinese: 猫坐在垫子上</p>

<p>Reference 1: the cat is on the mat</p>

<p>Reference 2: there is a cat on the mat</p>

<p>Candidate: the cat the cat on the mat</p>

<h4 id="example-2">Example 2</h4>

<p>Chinese: 猫坐在垫子上</p>

<p>Reference 1: the cat is on the mat</p>

<p>Reference 2: there is a cat on the mat</p>

<p>Candidate: the the the the the the the the</p>

<h3 id="precision">Precision</h3>

<p>We count each of the ngram in the candidate sentence whether it has shown in any of the reference sentences, gather the total counts for each of the unique ngram, sum up the total counts for each of the unique ngram, and divided by the number of ngrams in the candidate sentence.</p>

<h4 id="example-1-1">Example 1</h4>

<p>We first compute the unigram precision for example 1. All the unigrams in the candidate sentences have shown in the reference sentences.</p>



<table>
  <tbody><tr>
    <th>Unigram</th>
    <th>Shown?</th>
  </tr>
  <tr>
    <td>the</td>
    <td>1</td>
  </tr>
  <tr>
    <td>cat</td>
    <td>1</td>
  </tr>
  <tr>
    <td>the</td>
    <td>1</td>
  </tr>
  <tr>
    <td>cat</td>
    <td>1</td>
  </tr>
  <tr>
    <td>on</td>
    <td>1</td>
  </tr>
  <tr>
    <td>the</td>
    <td>1</td>
  </tr>
  <tr>
    <td>mat</td>
    <td>1</td>
  </tr>
</tbody></table>

<p>We then merge the unigram counts.</p>



<table>
  <tbody><tr>
    <th>Unique Unigram</th>
    <th>Count</th>
  </tr>
  <tr>
    <td>the</td>
    <td>3</td>
  </tr>
  <tr>
    <td>cat</td>
    <td>2</td>
  </tr>
  <tr>
    <td>on</td>
    <td>1</td>
  </tr>
  <tr>
    <td>mat</td>
    <td>1</td>
  </tr>
</tbody></table>

<p>The total number of counts for the unique unigrams in the candidate sentence is 7, and the total number of unigrams in the candidate sentence is 7. The unigram precision is 7/7 = 1.0 for example 1.</p>



<p>We then try to compute the bigram precision for example 1.</p>



<table>
  <tbody><tr>
    <th>Bigram</th>
    <th>Shown?</th>
  </tr>
  <tr>
    <td>the cat</td>
    <td>1</td>
  </tr>
  <tr>
    <td>cat the</td>
    <td>0</td>
  </tr>
  <tr>
    <td>the cat</td>
    <td>1</td>
  </tr>
  <tr>
    <td>cat on</td>
    <td>1</td>
  </tr>
  <tr>
    <td>on the</td>
    <td>1</td>
  </tr>
  <tr>
    <td>the mat</td>
    <td>1</td>
  </tr>
</tbody></table>

<p>We then merge the bigram counts.</p>



<table>
  <tbody><tr>
    <th>Unique Bigram</th>
    <th>Count</th>
  </tr>
  <tr>
    <td>the cat</td>
    <td>2</td>
  </tr>
  <tr>
    <td>cat the</td>
    <td>0</td>
  </tr>
  <tr>
    <td>cat on</td>
    <td>1</td>
  </tr>
  <tr>
    <td>on the</td>
    <td>1</td>
  </tr>
  <tr>
    <td>the mat</td>
    <td>1</td>
  </tr>
</tbody></table>

<p>The total number of counts for the unique bigrams in the candidate sentence is 5, and the total number of bigrams in the candidate sentence is 6. The bigram precision is 5/6 = 0.833 for example 1.</p>

<h4 id="example-2-1">Example 2</h4>

<p>We first compute the unigram precision for example 2. All the unigrams in the candidate sentences have shown in the reference sentences.</p>



<table>
  <tbody><tr>
    <th>Unigram</th>
    <th>Shown?</th>
  </tr>
  <tr>
    <td>the</td>
    <td>1</td>
  </tr>
  <tr>
    <td>the</td>
    <td>1</td>
  </tr>
  <tr>
    <td>the</td>
    <td>1</td>
  </tr>
  <tr>
    <td>the</td>
    <td>1</td>
  </tr>
  <tr>
    <td>the</td>
    <td>1</td>
  </tr>
  <tr>
    <td>the</td>
    <td>1</td>
  </tr>
  <tr>
    <td>the</td>
    <td>1</td>
  </tr>
  <tr>
    <td>the</td>
    <td>1</td>
  </tr>
</tbody></table>

<p>We then merge the unigram counts.</p>



<table>
  <tbody><tr>
    <th>Unique Unigram</th>
    <th>Count</th>
  </tr>
  <tr>
    <td>the</td>
    <td>8</td>
  </tr>
</tbody></table>

<p>The total number of counts for the unique unigrams in the candidate sentence is 8, and the total number of unigrams in the candidate sentence is 8. The unigram precision is 8/8 = 1.0 for example 2.</p>



<p>We then try to compute the bigram precision for example 2.</p>



<table>
  <tbody><tr>
    <th>Bigram</th>
    <th>Shown?</th>
  </tr>
  <tr>
    <td>the the</td>
    <td>0</td>
  </tr>
  <tr>
    <td>the the</td>
    <td>0</td>
  </tr>
  <tr>
    <td>the the</td>
    <td>0</td>
  </tr>
  <tr>
    <td>the the</td>
    <td>0</td>
  </tr>
  <tr>
    <td>the the</td>
    <td>0</td>
  </tr>
  <tr>
    <td>the the</td>
    <td>0</td>
  </tr>
  <tr>
    <td>the the</td>
    <td>0</td>
  </tr>
</tbody></table>

<p>We then merge the bigram counts.</p>



<table>
  <tbody><tr>
    <th>Unique Bigram</th>
    <th>Count</th>
  </tr>
  <tr>
    <td>the the</td>
    <td>0</td>
  </tr>
</tbody></table>

<p>The total number of counts for the unique bigrams in the candidate sentence is 0, and the total number of bigrams in the candidate sentence is 7. The bigram precision is 0/7 = 0 for example 2.</p>

<h4 id="drawbacks">Drawbacks</h4>

<p>We can see from example 1 and 2 that unigram precision is very easy to be over-confident about the quality of the machine translation. To overcome this, clipped count and modified precision were proposed.</p>

<h3 id="modified-precision">Modified Precision</h3>

<p>For each unique ngram, we count its maximum frequency in each of the reference sentences. The minimum of this special count and the original count is called the clipped the count. That is to say, the clipped count is no greater than the original count. We then use this clipped count, in place of the original count, for computing the modified precision.</p>

<h4 id="example-1-2">Example 1</h4>



<table>
  <tbody><tr>
    <th>Unique Unigram</th>
    <th>Count</th>
    <th>Clipped Count</th>
  </tr>
  <tr>
    <td>the</td>
    <td>3</td>
    <td>2</td>
  </tr>
  <tr>
    <td>cat</td>
    <td>2</td>
    <td>1</td>
  </tr>
  <tr>
    <td>on</td>
    <td>1</td>
    <td>1</td>
  </tr>
  <tr>
    <td>mat</td>
    <td>1</td>
    <td>1</td>
  </tr>
</tbody></table>

<p>The total number of clipped counts for the unique unigrams in the candidate sentence is 5, and the total number of unigrams in the candidate sentence is 7. The unigram modified precision is 5/7 = 0.714 for example 1.</p>



<table>
  <tbody><tr>
    <th>Unique Bigram</th>
    <th>Count</th>
    <th>Clipped Count</th>
  </tr>
  <tr>
    <td>the cat</td>
    <td>2</td>
    <td>1</td>
  </tr>
  <tr>
    <td>cat the</td>
    <td>0</td>
    <td>0</td>
  </tr>
  <tr>
    <td>cat on</td>
    <td>1</td>
    <td>1</td>
  </tr>
  <tr>
    <td>on the</td>
    <td>1</td>
    <td>1</td>
  </tr>
  <tr>
    <td>the mat</td>
    <td>1</td>
    <td>1</td>
  </tr>
</tbody></table>

<p>The total number of clipped counts for the unique bigrams in the candidate sentence is 4, and the total number of unigrams in the candidate sentence is 6. The bigram modified precision is 4/6 = 0.667 for example 1.</p>

<h4 id="example-2-2">Example 2</h4>



<table>
  <tbody><tr>
    <th>Unique Unigram</th>
    <th>Count</th>
    <th>Clipped Count</th>
  </tr>
  <tr>
    <td>the</td>
    <td>8</td>
    <td>2</td>
  </tr>
</tbody></table>

<p>The total number of clipped counts for the unique bigrams in the candidate sentence is 0, and the total number of unigrams in the candidate sentence is 8. The unigram modified precision is 2/8 = 0.25 for example 2.</p>



<table>
  <tbody><tr>
    <th>Unique Bigram</th>
    <th>Count</th>
    <th>Clipped Count</th>
  </tr>
  <tr>
    <td>the the</td>
    <td>0</td>
    <td>0</td>
  </tr>
</tbody></table>

<p>The total number of clipped counts for the unique bigrams in the candidate sentence is 0, and the total number of bigrams in the candidate sentence is 7. The bigram precision is 0/7 = 0 for example 2.</p>

<h4 id="advantages">Advantages</h4>

<p>Compared to precision, we found that modified precision is a better metric, at least for unigrams.</p>

<h3 id="bleu">BLEU</h3>

<h4 id="algorithm">Algorithm</h4>

<p>BLEU is computed using a couple of ngram modified precisions. Specifically,</p>



<p>where $p_n$ is the modified precision for $n$gram, the base of $\log$ is the natural base $e$, $w_n$ is weight between 0 and 1 for $\log p_n$ and $\sum_{n=1}^{N} w_n = 1$, and BP is the brevity penalty to penalize short machine translations.</p>



<p>where $c$ is the number of unigrams (length) in all the candidate sentences, and $r$ is the best match lengths for each candidate sentence in the corpus. Here the best match length is the closest reference sentence length to the candidate sentences. For example, if there are three references with lengths 12, 14, and 17 words and the candidate translation is a terse 13 words, ideally the best match length could be either 12 or 14, but we arbitrary choose the shorter one which is 12.</p>



<p>Usually, the BLEU is evaluated on corpus where there are many candidate sentences translated from different source texts and each of them has several reference sentences. Then $c$ is the total number of unigrams (length) in all the candidate sentences, and $r$ is the sum of the best match lengths for each candidate sentence in the corpus.</p>



<p>It is not hard to find that BLEU is always a value between 0 and 1. It is because BP, $w_n$, and $p_n$ are always between 0 and 1, and</p>



<p>Usually, BLEU uses $N = 4$ and $w_n = \frac{1}{N}$.</p>

<h4 id="example-1-3">Example 1</h4>

<p>We have computed the modified precision for some of the ngrams. It is not hard to compute the others. Concretely, we have</p>





<p>Because the corpus only has one translation set and thus $c = 7$ and $r = 7$</p>



<p>We plugin these values to the BLEU equation, the BLEU is</p>



<p>We further compare the BLEU to the BLEU computed using <a href="https://www.nltk.org/">NLTK</a>.</p>

<div><div><pre><code><span>&gt;&gt;&gt;</span> <span>import</span> <span>nltk</span>
<span>&gt;&gt;&gt;</span> <span>reference_1</span> <span>=</span> <span>"the cat is on the mat"</span><span>.</span><span>split</span><span>()</span>
<span>&gt;&gt;&gt;</span> <span>reference_2</span> <span>=</span> <span>"there is a cat on the mat"</span><span>.</span><span>split</span><span>()</span>
<span>&gt;&gt;&gt;</span> <span>candidate</span> <span>=</span> <span>"the cat the cat on the mat"</span><span>.</span><span>split</span><span>()</span>
<span>&gt;&gt;&gt;</span> <span>bleu</span> <span>=</span> <span>nltk</span><span>.</span><span>translate</span><span>.</span><span>bleu_score</span><span>.</span><span>sentence_bleu</span><span>(</span><span>references</span><span>=</span><span>[</span><span>reference_1</span><span>,</span> <span>reference_2</span><span>],</span> <span>hypothesis</span><span>=</span><span>candidate</span><span>,</span> <span>weights</span><span>=</span><span>(</span><span>0.25</span><span>,</span><span>0.25</span><span>,</span><span>0.25</span><span>,</span><span>0.25</span><span>))</span>
<span>&gt;&gt;&gt;</span> <span>print</span><span>(</span><span>bleu</span><span>)</span>
<span>0.4671379777282001</span>
</code></pre></div></div>

<p>The value of <code>bleu</code> is 0.467 which is exactly matching to the BLEU we computed manually.</p>

<h4 id="example-2-3">Example 2</h4>

<p>Similarly,</p>





<p>Because the corpus only has one translation set and thus $c = 8$ and $r = 7$</p>



<p>When we plugin these values to the BLEU equation, actually we would need to compute $\log 0$ which is not mathematically defined. We use a small number $10^{-100}$ instead of $0$ for $p_2$, $p_3$ and $p_4$. The BLEU is</p>



<p>We further also compare the BLEU to the BLEU computed using <a href="https://www.nltk.org/">NLTK</a>.</p>

<div><div><pre><code><span>&gt;&gt;&gt;</span> <span>import</span> <span>nltk</span>
<span>&gt;&gt;&gt;</span> <span>reference_1</span> <span>=</span> <span>"the cat is on the mat"</span><span>.</span><span>split</span><span>()</span>
<span>&gt;&gt;&gt;</span> <span>reference_2</span> <span>=</span> <span>"there is a cat on the mat"</span><span>.</span><span>split</span><span>()</span>
<span>&gt;&gt;&gt;</span> <span>candidate</span> <span>=</span> <span>"the the the the the the the the"</span><span>.</span><span>split</span><span>()</span>
<span>&gt;&gt;&gt;</span> <span>bleu</span> <span>=</span> <span>nltk</span><span>.</span><span>translate</span><span>.</span><span>bleu_score</span><span>.</span><span>sentence_bleu</span><span>(</span><span>references</span><span>=</span><span>[</span><span>reference_1</span><span>,</span> <span>reference_2</span><span>],</span> <span>hypothesis</span><span>=</span><span>candidate</span><span>,</span> <span>weights</span><span>=</span><span>(</span><span>0.25</span><span>,</span><span>0.25</span><span>,</span><span>0.25</span><span>,</span><span>0.25</span><span>))</span>
<span>&gt;&gt;&gt;</span> <span>print</span><span>(</span><span>bleu</span><span>)</span>
<span>1.2882297539194154e-231</span>
</code></pre></div></div>

<p>The value of <code>bleu</code> is 0 which is exactly matching to the BLEU we computed manually.</p>

<p>Note that in the above two examples, due to the candidate sentence is long and we only have one translation in the corpus, thus $\text{BP} = 1$. In practice, there could be scenarios where $\text{BP} &lt; 1$.</p>

<h3 id="caveats">Caveats</h3>

<p>In some scenarios, BLEU does not score the translation very well, especially for those short translations with few reference sentences. For example,</p>



<p>Chinese: 你准备好了吗？</p>

<p>Reference 1: are you ready ?</p>

<p>Candidate: you are ready ?</p>

<div><div><pre><code><span>&gt;&gt;&gt;</span> <span>import</span> <span>nltk</span>
<span>&gt;&gt;&gt;</span> <span>reference_1</span> <span>=</span> <span>"are you ready ?"</span><span>.</span><span>split</span><span>()</span>
<span>&gt;&gt;&gt;</span> <span>candidate</span> <span>=</span> <span>"you are ready ?"</span><span>.</span><span>split</span><span>()</span>
<span>&gt;&gt;&gt;</span> <span>bleu</span> <span>=</span> <span>nltk</span><span>.</span><span>translate</span><span>.</span><span>bleu_score</span><span>.</span><span>sentence_bleu</span><span>(</span><span>references</span><span>=</span><span>[</span><span>reference_1</span><span>],</span> <span>hypothesis</span><span>=</span><span>candidate</span><span>,</span> <span>weights</span><span>=</span><span>[</span><span>0.25</span><span>,</span><span>0.25</span><span>,</span><span>0.25</span><span>,</span><span>0.25</span><span>])</span>
<span>&gt;&gt;&gt;</span> <span>print</span><span>(</span><span>bleu</span><span>)</span>
<span>1.133422688662942e-154</span>
</code></pre></div></div>

<p>This is actually a very good machine translation to me. However, the BLEU score is 0, which means that the machine translation is totally wrong.</p>



<p>In NLTK, you are allowed to provide <a href="https://www.nltk.org/api/nltk.translate.html#nltk.translate.bleu_score.SmoothingFunction">smoothing functions</a>. For example,</p>

<div><div><pre><code><span>&gt;&gt;&gt;</span> <span>import</span> <span>nltk</span>
<span>&gt;&gt;&gt;</span> <span>reference_1</span> <span>=</span> <span>"are you ready ?"</span><span>.</span><span>split</span><span>()</span>
<span>&gt;&gt;&gt;</span> <span>candidate</span> <span>=</span> <span>"you are ready ?"</span><span>.</span><span>split</span><span>()</span>
<span>&gt;&gt;&gt;</span> <span>bleu</span> <span>=</span> <span>nltk</span><span>.</span><span>translate</span><span>.</span><span>bleu_score</span><span>.</span><span>sentence_bleu</span><span>(</span><span>references</span><span>=</span><span>[</span><span>reference_1</span><span>],</span> <span>hypothesis</span><span>=</span><span>candidate</span><span>,</span> <span>weights</span><span>=</span><span>[</span><span>0.25</span><span>,</span><span>0.25</span><span>,</span><span>0.25</span><span>,</span><span>0.25</span><span>],</span> <span>smoothing_function</span><span>=</span><span>nltk</span><span>.</span><span>translate</span><span>.</span><span>bleu_score</span><span>.</span><span>SmoothingFunction</span><span>().</span><span>method7</span><span>)</span>
<span>&gt;&gt;&gt;</span> <span>print</span><span>(</span><span>bleu</span><span>)</span>
<span>0.4002926439114545</span>
</code></pre></div></div>

<p>This time, the value of <code>bleu</code> is 0.4, which is magically higher than the vanilla one we computed without using smoothing functions.</p>



<p>However, one should be always cautious about the smoothing function used in BLEU computation. At least we have to make sure that the BLEU scores we are comparing against are using no smoothing function or the exact same smoothing function.</p>

<h3 id="references">References</h3>

<ul>
  <li><a href="https://www.aclweb.org/anthology/P02-1040/">BLEU: a Method for Automatic Evaluation of Machine Translation</a></li>
  <li><a href="https://www.youtube.com/watch?v=DejHQYAGb7Q">BLEU - Andrew Ng</a></li>
</ul>

      <hr>
      
    </div></div>]]>
            </description>
            <link>https://leimao.github.io/blog/BLEU-Score/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23641791</guid>
            <pubDate>Thu, 25 Jun 2020 15:27:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Permacomputing]]>
            </title>
            <description>
<![CDATA[
Score 44 | Comments 18 (<a href="https://news.ycombinator.com/item?id=23641719">thread link</a>) | @ibobev
<br/>
June 25, 2020 | http://viznut.fi/texts-en/permacomputing.html | <a href="https://web.archive.org/web/*/http://viznut.fi/texts-en/permacomputing.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">



<p>This is a collection of random thoughts regarding the application of
permacultural ideas to the computer world.</p>

<p>Some have tried to connect these worlds before (<a href="http://wiki.c2.com/?PermaCulture">WikiWikiWeb's Permaculture
article</a>; <a href="https://en.wikipedia.org/wiki/Kent_Beck">Kent
Beck</a>'s short-lived idea of <a href="https://www.softwarequotes.com/showquotes.aspx?id=559&amp;name=Kent%20Beck">Permaprogramming</a>),
but these have mostly concentrated on enhancing software engineering
practices with some ideas from gardening. I am more interested in the aspect
of cultural and ecological permanence. That is, how to give computers a
meaningful and sustainable place in a human civilization that has a
meaningful and sustainable place in the planetary biosphere.</p>

<h2>1. Problem</h2>

<p>Over the last few hundred years of human civilization, there has been a
dramatic increase in the consumption of artificially produced energy. In the
overarching story, this is often equated with "progress".</p>

<p>In the computer world, this phenomenon gets multiplied by itself:
"progress" facilitates ever greater densities of data storage and digital
logic, thus dramatically exploding the availability of computing resources.
However, the abundance has also caused an equivalent explosion in
wastefulness, which shows in things like mindblowingly ridiculous hardware
requirements for even quite trivial tasks.</p>

<p>At the same time, computers have been failing their <a href="https://en.wikipedia.org/wiki/Computer_Lib/Dream_Machines">utopian
expectations</a>. Instead of amplifying the users' intelligence, they rather
amplify their stupidity. Instead of making it possible to scale down the
resource requirements of the material world, they have instead become a
major part of the problem. Instead of making the world more comprehensible,
they rather add to its incomprehensibility. And they often even manage to
become slower despite becoming faster.</p>

<p>In both computing and agriculture, a major issue is that problems are too
often "solved" by increasing controllability and resource use. Permaculture
takes another way, advocating methods that "let nature do the work" and thus
minimize the dependence on artificial energy input. Localness and
decentralization are also major themes in the thought.</p>

<p>What makes permacultural philosophy particularly appealing (to me) is
that it does not advocate "going back in time" despite advocating a dramatic
decrease in use of artificial energy. Instead, it trusts in human ingenunity
in finding clever hacks for turning problems into solutions, competition
into co-operation, waste into resources. Very much the same kind of creative
thinking I appreciate in computer hacking.</p>

<p>The presence of intelligent life in an ecosystem can be justified by its
strengthening effect. Ideally, humans could make ecosystems more flexible
and more resilient because of their ability to take leaps that are difficult
or impossible for "unintelligent" natural processes. The existence of
computers in a human civilization can be justified by their ability to
augment this potential.</p>

<h2>2. Physical resources</h2>

<h3>2.1. Energy</h3>

<p>Permaculture emphasizes resource-sensitivity. Computers primarily use
electricity, so to them resource-sensitivity primarily means 1) adapting to
changes in energy conditions and 2) using the available energy wisely.
Today's computers, even mobile ones, are surprisingly bad at this. This is
partially due to their legacy as "calculation factories" that are constantly
guaranteed all the resources they "need".</p>

<p>Intense non-urgent computation (such as long machine learning batches)
would take place only when a lot of surplus energy is being produced or
there is a need for electricity-to-heat conversion. This requires that the
computer is aware of the state of the surrounding energy system.</p>

<p>At times of low energy, both hardware and software would prefer to scale
down: background processes would freeze, user interfaces would become more
rudimentary, clock frequencies would decrease, unneeded processors and
memory banks would power off. At these times, people would prefer to do
something else than interact with computers.</p>

<p>It is often wise to store energy for later use. <a href="https://en.wikipedia.org/wiki/Flywheel_energy_storage">Flywheels</a>
are a potential alternative to chemical batteries. They have similar <a href="https://en.wikipedia.org/wiki/Energy_density">energy densities</a>
(MJ/kg) but require no rare-earth materials and last for decades or
centuries instead of mere years.</p>

<h3>2.2. Silicon</h3>

<p>IC fabrication requires large amounts of energy, highly refined machinery
and poisonous substances. Because of this sacrifice, the resulting
microchips should be treasured like gems or rare exotic spices. Their active
lifespans would be maximized, and they would never be reduced to their raw
materials until they are thoroughly unusable.</p>

<p>Instead of planned obsolescence, there should be planned longevity.</p>

<p>Broken devices would be repaired. If the community needs a kind of device
that does not exist, it should preferrably be built from existing components
that have fallen out of use. Chips should be designed open and flexible, so
that they can be reappropriated even for purposes they were never intended
for.</p>

<p>Complex chips should have enough redundancy and bypass mechanisms to keep
them working even after some of their internals wear out. (In a multicore
CPU, for instance, many partially functioning cores could combine into one
fully functioning one.)</p>

<p>Chips that work but whose practical use cannot be justified can find
artistic and other psychologically meaningful use. They may also be stored
away until they are needed again (especially if the fabrication quality and
the storage conditions allow for decades or centuries of "shelf life").</p>

<p>Use what is available. Even chips that do "evil" things are worth
considering if there's a landfill full of them. Crack their DRM locks,
reverse-engineer their black boxes, deconstruct their philosophies. It might
even be possible to reappropriate something like Bitcoin-mining ASICs for
something artistically interesting or even useful.</p>

<p>Minimized on-chip feature size makes it possible to do more computation
with less energy but it often also means increased fragility and shorter
lifespans. Therefore, the densest chips should be primarily used for
purposes where more computation actually yields more. (In entertainment use,
for example, a large use of resources is nothing more than a decadent
esthetic preference.)</p>

<p><a href="https://en.wikipedia.org/wiki/Unconventional_computing">Alternatives
to semiconductors</a> should be actively researched. <a href="https://www.researchgate.net/publication/328395242_Towards_fungal_computer">Living
cells</a> might be able to replace microchips in some tasks sometime in the
future.</p>

<p>Once perfectly clean ways of producing microchip equivalents have been
taken to use, the need for "junk fetishism" will probably diminish.</p>

<h3>2.3. Miscellaneous</h3>

<p>Whenever bright external light is available, displays should be able to
use it instead of competing against it with their own backlight. (See: <a href="https://en.wikipedia.org/wiki/Transflective_liquid-crystal_display">Transflective
LCD</a>)</p>

<p>Personally-owned computers are primarily for those who dedicate
themselves to the technology and thus spend considerable amounts of time
with it. Most other people would be perfectly happy with shared hardware.
Even if the culture and society embraced computers more than anything else,
requiring everyone to own one would be an overkill.</p>

<h2>3. Observation and interaction</h2>

<p>The first item in many lists of permacultural principles is "Observe and
interact." I interpret this as primarily referring to a bidirectional and
co-operative relationship with natural systems: you should not expect your
garden to be easily top-down controllable like an army unit but accept its
quirkiness and adapt to it.</p><h3>3.1. Observation</h3>

<p>Observation is among the most important human skills computers can augment.
Things that are difficult or impossible for humans to observe can be brought
within human cognitive capacity by various computational processes. Gathered
information can be visualized, slight changes and pattern deviances
emphasized, slow processes sped up, forecasts calculated. In Bill Mollison's
words, "Information is <em>the</em> critical potential resource. It becomes
a resource only when obtained and acted upon."</p>

<p>Computer systems should also make their own inner workings as observable as
possible. If the computer produces visual output, it would use a fraction of
its resources to visualize its own intro- and extrospection. A computer that
communicates with radio waves, for example, would visualize its own view of
the surrounding radio landscape.</p>

<p>Current consumer-oriented computing systems often go to ridiculous
lengths to actually prevent the user from knowing what is going on. Even
error messages have become unfashionable; many websites and apps just
pretend everything is fine even if it isn't. This kind of extreme
unobservability is a major source of technological alienation among computer
users.</p>

<p>The visualizations intended for casual and passive observation would be
pleasant and tranquil while making it easy to see the big picture and notice
the small changes. Tapping into the inborn human tendency to observe the
natural environment may be a good idea when designing visualizers. When the
user wants to observe something more closely, however, there is no limit in
how flashy, technical and "non-natural" the presentation can be, as long as
the observer prefers it that way.</p>

<h3>3.2. Yin and yang hacking</h3>

<p>Traditional computer hacking is often very "yang". A total understanding and
control of the target system is valued. Changing a system's behavior is
often an end in itself. There are predefined goals the system is pushed
towards. Optimization tends to focus on a single measurable parameter.
Finding a system's absolute limits is more important than finding its
individual strengths or essence.</p>

<p>In contrast, "yin" hacking accepts the aspects that are beyond rational
control and comprehension. Rationality gets supported by intuition. The
relationship with the system is more bidirectional, emphasizing
experimentation and observation. The "personality" that stems from
system-specific peculiarities gets more attention than the measurable specs.
It is also increasingly important to understand when to hack and when just
to observe without hacking.</p>

<p>The difference between yin and yang hacking is similar to the difference
between permaculture and …</p></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://viznut.fi/texts-en/permacomputing.html">http://viznut.fi/texts-en/permacomputing.html</a></em></p>]]>
            </description>
            <link>http://viznut.fi/texts-en/permacomputing.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23641719</guid>
            <pubDate>Thu, 25 Jun 2020 15:20:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Angular 10 Now Available]]>
            </title>
            <description>
<![CDATA[
Score 26 | Comments 7 (<a href="https://news.ycombinator.com/item?id=23640966">thread link</a>) | @theodorejb
<br/>
June 25, 2020 | https://blog.angular.io/version-10-of-angular-now-available-78960babd41 | <a href="https://web.archive.org/web/*/https://blog.angular.io/version-10-of-angular-now-available-78960babd41">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><section><div><div><div><div><div><div><p><a href="https://blog.angular.io/@stephenfluin?source=post_page-----78960babd41----------------------" rel="noopener"><img alt="Stephen Fluin" src="https://miro.medium.com/fit/c/96/96/1*y_L34o3bW0QELQm1KOFMTw.jpeg" width="48" height="48"></a></p></div></div></div></div><p id="0c65">Version 10.0.0 is here! This is a <a href="https://semver.org/#spec-item-8" target="_blank" rel="noopener">major</a> release that spans the entire platform, including the framework, Angular Material, and the CLI. This release is smaller than typical; it has only been 4 months since we released version 9.0 of Angular.</p><figure><div><div><div><div><p><img src="https://miro.medium.com/max/60/1*NW08J81iLpExTFTz4wnWHQ.jpeg?q=20" width="2048" height="1365" role="presentation"></p><p><img src="https://miro.medium.com/max/4096/1*NW08J81iLpExTFTz4wnWHQ.jpeg" width="2048" height="1365" srcset="https://miro.medium.com/max/552/1*NW08J81iLpExTFTz4wnWHQ.jpeg 276w, https://miro.medium.com/max/1104/1*NW08J81iLpExTFTz4wnWHQ.jpeg 552w, https://miro.medium.com/max/1280/1*NW08J81iLpExTFTz4wnWHQ.jpeg 640w, https://miro.medium.com/max/1400/1*NW08J81iLpExTFTz4wnWHQ.jpeg 700w" sizes="700px" role="presentation"></p></div></div></div></div><figcaption>Photo of Butterfly Beach by Minko Gechev</figcaption></figure><p id="346b">We try to release two major versions each year to keep Angular synchronized with the rest of the JavaScript ecosystem and to have a predictable schedule. We plan to release version 11 this fall.</p><p id="156d"><strong>New Date Range Picker</strong></p><p id="ba59">Angular Material now includes a new date range picker.</p><figure><div><div><div><p><img src="https://miro.medium.com/max/60/0*ruU5G-8_hqEp3UBY?q=20" width="410" height="94" role="presentation"></p><p><img src="https://miro.medium.com/max/820/0*ruU5G-8_hqEp3UBY" width="410" height="94" srcset="https://miro.medium.com/max/552/0*ruU5G-8_hqEp3UBY 276w, https://miro.medium.com/max/820/0*ruU5G-8_hqEp3UBY 410w" sizes="410px" role="presentation"></p></div></div></div><figcaption>Image of the new date range picker</figcaption></figure><p id="f310">To use the new date range picker, you can use the <code>mat-date-range-input</code> and <code>mat-date-range-picker</code> components.</p><p id="5add">See <a href="https://stackblitz.com/angular/nknyovevygv?file=src%2Fapp%2Fdate-range-picker-overview-example.html" target="_blank" rel="noopener">this example on StackBlitz</a>.</p><p id="41ba">Learn more about <a href="https://next.material.angular.io/components/datepicker/overview#date-range-selection" target="_blank" rel="noopener">date range selection</a>.</p><p id="16c4"><strong>Warnings about CommonJS imports</strong></p><p id="aadf">When you use a dependency that is packaged with CommonJS, it can result in <a href="https://web.dev/commonjs-larger-bundles/" target="_blank" rel="noopener">larger slower applications</a>.</p><p id="9444">Starting with version 10, we now warn you when your build pulls in one of these bundles. If you’ve started seeing these warnings for your dependencies, let your dependency know that you’d prefer an ECMAScript module (ESM) bundle.</p><figure><div><div><div><div><p><img src="https://miro.medium.com/max/60/0*udjNtSSP-495QNzL?q=20" width="1600" height="357" role="presentation"></p><p><img src="https://miro.medium.com/max/3200/0*udjNtSSP-495QNzL" width="1600" height="357" srcset="https://miro.medium.com/max/552/0*udjNtSSP-495QNzL 276w, https://miro.medium.com/max/1104/0*udjNtSSP-495QNzL 552w, https://miro.medium.com/max/1280/0*udjNtSSP-495QNzL 640w, https://miro.medium.com/max/1400/0*udjNtSSP-495QNzL 700w" sizes="700px" role="presentation"></p></div></div></div></div><figcaption>CommonJS or AMD dependencies can cause optimization bailouts</figcaption></figure><p id="dde5"><strong>Optional Stricter Settings</strong></p><p id="7e3d">Version 10 offers a more strict project setup when you create a new workspace with <code>ng new</code>.</p><pre><span id="4b6e">ng new --strict</span></pre><p id="9fa5">Enabling this flag initializes your new project with a few new settings that improve maintainability, help you catch bugs ahead of time, and allow the CLI to perform advanced optimizations on your app. Specifically, the <code>strict</code> flag does the following:</p><ul><li id="0ab9">Enables strict mode in TypeScript</li><li id="0f1b">Turns template type checking to Strict</li><li id="6313">Default bundle budgets have been reduced by ~75%</li><li id="855e">Configures linting rules to <a href="https://palantir.github.io/tslint/rules/no-any/" target="_blank" rel="noopener">prevent declarations of type </a><code><a href="https://palantir.github.io/tslint/rules/no-any/" target="_blank" rel="noopener">any</a></code></li><li id="cb7d">Configures your app as side-effect free to enable more advanced tree-shaking</li></ul><p id="2213"><strong>Keeping Up to Date with the Ecosystem</strong></p><p id="e568">As usual, we have made a few updates to the dependencies of Angular to stay synchronized with the JavaScript ecosystem.</p><ul><li id="0658">TypeScript bumped to <a href="https://www.typescriptlang.org/docs/handbook/release-notes/typescript-3-9.html" target="_blank" rel="noopener">TypeScript 3.9</a></li><li id="498e">TSLib has been updated to v<a href="https://github.com/microsoft/tslib/releases/tag/2.0.0" target="_blank" rel="noopener">2.0</a></li><li id="50e3">TSLint has been updated to v6</li></ul><p id="fcf0">We’ve also updated our project layout. Starting with version 10 you will see a new <code>tsconfig.base.json</code>. This additional <code><a href="https://www.typescriptlang.org/docs/handbook/tsconfig-json.html" target="_blank" rel="noopener">tsconfig.json</a></code><a href="https://www.typescriptlang.org/docs/handbook/tsconfig-json.html" target="_blank" rel="noopener"> file</a> better supports the way that IDEs and build tooling resolve type and package configurations.</p><p id="948c"><strong>New Default Browser Configuration</strong></p><p id="eb51">We’ve updated the browser configuration for new projects to exclude older and less used browsers.</p><p id="686d"><strong>v9 Defaults</strong></p><figure><div><div><div><div><p><img src="https://miro.medium.com/max/46/0*jhzqz-biEH3Bd7zQ?q=20" width="787" height="1036" role="presentation"></p><p><img src="https://miro.medium.com/max/1574/0*jhzqz-biEH3Bd7zQ" width="787" height="1036" srcset="https://miro.medium.com/max/552/0*jhzqz-biEH3Bd7zQ 276w, https://miro.medium.com/max/1104/0*jhzqz-biEH3Bd7zQ 552w, https://miro.medium.com/max/1280/0*jhzqz-biEH3Bd7zQ 640w, https://miro.medium.com/max/1400/0*jhzqz-biEH3Bd7zQ 700w" sizes="700px" role="presentation"></p></div></div></div></div></figure><p id="8574"><strong>v10 Defaults</strong></p><figure><div><div><div><p><img src="https://miro.medium.com/max/60/0*kLsNxh2hOj_aQ8HV?q=20" width="685" height="479" role="presentation"></p><p><img src="https://miro.medium.com/max/1370/0*kLsNxh2hOj_aQ8HV" width="685" height="479" srcset="https://miro.medium.com/max/552/0*kLsNxh2hOj_aQ8HV 276w, https://miro.medium.com/max/1104/0*kLsNxh2hOj_aQ8HV 552w, https://miro.medium.com/max/1280/0*kLsNxh2hOj_aQ8HV 640w, https://miro.medium.com/max/1370/0*kLsNxh2hOj_aQ8HV 685w" sizes="685px" role="presentation"></p></div></div></div></figure><p id="a101">This has the side effect of disabling ES5 builds by default for new projects. To enable ES5 builds and differential loading for browsers that require it (such as IE or UC Browser), simply <a href="https://github.com/browserslist/browserslist#browserslist-" target="_blank" rel="noopener">add the browsers you need to support</a> in the <code>.browserslistrc</code> file.</p><p id="df1c"><strong>Angular Team Fixit</strong></p><p id="4207">We’ve dramatically increased our investment in working with the community. In the last three weeks our open issue count has decreased by over 700 issues across <a href="https://github.com/angular/angular/issues" target="_blank" rel="noopener">framework</a>, <a href="https://github.com/angular/angular-cli/issues" target="_blank" rel="noopener">tooling</a>, and <a href="https://github.com/angular/components/issues" target="_blank" rel="noopener">components</a>. We’ve touched over 2,000 issues, and we plan to make large investments over the next few months, working with the community to do even more.</p><p id="c357"><strong>Deprecations and Removals</strong></p><p id="6e18">We’ve made several new deprecations and removals from Angular.</p><p id="61da">The <a href="https://g.co/ng/apf" target="_blank" rel="noopener">Angular Package Format</a> no longer includes ESM5 or FESM5 bundles, saving you 119MB of download and install time when running <code>yarn</code> or <code>npm install</code> for Angular packages and libraries. These formats are no longer needed as any downleveling to support ES5 is done at the end of the build process.</p><p id="a660">Based on heavy consultation with the community, we are deprecating support for older browsers including IE 9, 10, and <a href="https://en.wikipedia.org/wiki/Internet_Explorer_Mobile" target="_blank" rel="noopener">Internet Explorer Mobile</a>.</p><p id="4190">You can <a href="http://v10.angular.io/guide/deprecations" target="_blank" rel="noopener">read more about our deprecations and removals</a>.</p><p id="792e">Visit <a href="https://update.angular.io/" target="_blank" rel="noopener">update.angular.io</a> for detailed information and guidance. To have the best update experience, we recommend always upgrading one major release at a time.</p><p id="4859">To update:</p><pre><span id="d24d">ng update @angular/cli @angular/core</span></pre><p id="e72b">You can read more about this update in our <a href="https://v10.angular.io/guide/updating-to-version-10" target="_blank" rel="noopener">Updating to version 10 guide</a>.</p></div></div></section></div></div>]]>
            </description>
            <link>https://blog.angular.io/version-10-of-angular-now-available-78960babd41</link>
            <guid isPermaLink="false">hacker-news-small-sites-23640966</guid>
            <pubDate>Thu, 25 Jun 2020 14:13:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Logistic regression from scratch]]>
            </title>
            <description>
<![CDATA[
Score 144 | Comments 52 (<a href="https://news.ycombinator.com/item?id=23640762">thread link</a>) | @pmuens
<br/>
June 25, 2020 | https://philippmuens.com/logistic-regression-from-scratch/ | <a href="https://web.archive.org/web/*/https://philippmuens.com/logistic-regression-from-scratch/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		<p>You can find working code examples (including this one) in my <a href="https://github.com/pmuens/lab">lab repository</a> on <a href="https://github.com/pmuens">GitHub</a>.</p><p>Sometimes it's necessary to split existing data into several classes in order to predict new, unseen data. This problem is called <a href="https://en.wikipedia.org/wiki/Statistical_classification">classification</a> and one of the algorithms which can be used to learn those classes from data is called Logistic Regression.</p><p>In this article we'll take a deep dive into the Logistic Regression model to learn how it differs from other regression models such as <a href="https://en.wikipedia.org/wiki/Linear_regression">Linear-</a> or <a href="https://en.wikipedia.org/wiki/Linear_regression#Simple_and_multiple_linear_regression">Multiple Linear Regression</a>, how to think about it from an intuitive perspective and how we can translate our learnings into code while implementing it from scratch.</p><h2 id="linear-regression-vs-logistic-regression">Linear Regression vs. Logistic Regression</h2><p>If you've read the post about <a href="https://philippmuens.com/linear-and-multiple-regression-from-scratch/">Linear- and Multiple Linear Regression</a> you might remember that the main objective of our algorithm was to find a best fitting line or <a href="https://en.wikipedia.org/wiki/Hyperplane">hyperplane</a> respectively.</p><p>To recap real quick, a line can be represented via the slop-intercept form as follows:</p><p>\[ y = mx + b \]</p><p>Here, \(m\) represents the slope and \(b\) the y-intercept.</p><p>In Linear Regression we've used the existing data to find a line in slope-intercept form (a \(m\) and \(b\) combination) which "best-fitted through" such data.</p><p>Extending the slope-intercept form slightly to support multiple \(x\) values and multiple slopes (we'll use \(\beta_n\) instead of \(m_n\)) yields the following:</p><p>\[ y = &nbsp;\beta_1x_1 + ... + \beta_nx_n + b \]</p><p>This "scaled-up" slope-intercept formula was used in the <a href="https://en.wikipedia.org/wiki/Linear_regression#Simple_and_multiple_linear_regression">Multiple Linear Regression</a> model to find the \(\beta\) and \(b\) values for the <a href="https://en.wikipedia.org/wiki/Hyperplane">hyperplane</a> which "best-fitted" the data. Once found we were able to use it for predictions by plugging in \(x\) values to get respective \(y\) values.</p><p>Linear Regression models always map a set of \(x\) values to a resulting \(y\) value on a <a href="https://en.wikipedia.org/wiki/Continuous_function">continuous</a> scale. This means that the \(y\) value can e.g. be \(0\), \(42\) or \(5.023.212\). How would we use such a Regression model if our \(y\) value is categorical such as a binary value which is either \(0\) or \(1\)? Is there a way to define a threshold so that a value such as \(42\) is assigned to the category \(1\) while a small value such as \(0.002\) gets assigned to the category \(0\)?</p><p>That's where Logistic Regression comes into play. With Logistic Regression we can map any resulting \(y\) value, no matter its magnitude to a value between \(0\) and \(1\).</p><p>Let's take a closer look into the modifications we need to make to turn a Linear Regression model into a Logistic Regression model.</p><h2 id="sigmoid-functions">Sigmoid functions</h2><p>At the very heart of Logistic Regression is the so-called <a href="https://en.wikipedia.org/wiki/Sigmoid_function">Sigmoid function</a>. A Sigmoid function is a class of functions which follows an S-shape when plotted.</p><p>The most prominent Sigmoid function is the so-called <a href="https://en.wikipedia.org/wiki/Logistic_function">Logistic function</a> which was developed by <a href="https://en.wikipedia.org/wiki/Pierre_Fran%C3%A7ois_Verhulst">Pierre Francois Verhulst</a> to model <a href="https://en.wikipedia.org/wiki/Population_growth">population grown</a>. It's mathematically described via this formula:</p><p>\[ f(x) = \frac{1}{1+e^{-x}} \]</p><p>Don't be intimidated by the math! Right now all you need to know is that this function takes any \(x\) value and maps it to a \(y\) value which ranges from \(0\) to \(1\).</p><p>Plotting the function for a range of \(x\) values proofs this claim and results in the aforementioned S-shape curve:</p><figure><img src="https://philippmuens.com/content/images/2020/06/zsigmoid_result.png"></figure><p>Note that the function gets closer and closer to the \(y\) value \(0\) or \(1\) as the \(x\) values get smaller or larger respectively. Also note that the \(x\) value \(0\) results in the \(y\) value \(0.5\).</p><p>This is exactly what we need. with this function we're able to "squish" any number, no matter its magnitude into a value ranging from \(0\) to \(1\). This makes the function outcome predictable which is useful when we later on define threshold values to associate function outputs with classes.</p><p>Let's turn the function into code:</p><pre><code>def sigmoid(x: float) -&gt; float:
    return 1 / (1 + exp(-x))

assert sigmoid(0) == 0.5</code></pre><p><strong><u>Note</u></strong>: Although there are many <a href="https://en.wikipedia.org/wiki/Sigmoid_function#Examples">different Sigmoid functions</a> to choose from, a lot of people use the name "Sigmoid function" when talking about the Logistic function. We'll adhere to this convention and use the term "Sigmoid function" as a synonym for Logistic function.</p><h2 id="from-linear-regression-to-logistic-regression">From Linear Regression to Logistic Regression</h2><p>Now that we've learned about the "mapping" capabilities of the Sigmoid function we should be able to "wrap" a Linear Regression model such as <a href="https://en.wikipedia.org/wiki/Linear_regression#Simple_and_multiple_linear_regression">Multiple Linear Regression</a> inside of it to turn the regressions raw output into a value ranging from \(0\) to \(1\).</p><p>Let's translate this idea into Math. Recall that our Multiple Linear Regression model looks like this:</p><p>\[ y = &nbsp;\beta_1x_1 + ... + \beta_nx_n + b \]</p><p>"Wrapping" this in the Sigmoid function (we use \(\sigma\) to represent the Sigmoid function) results in the following:</p><p>\[ y = \sigma(\beta_1x_1 + ... + \beta_nx_n + b) \]</p><p>Easy enough! Let's turn that into code.</p><p>The first thing we need to do is to implement the underlying Multiple Linear Regression model. Looking at the Math it seems to be possible to use the <a href="https://en.wikipedia.org/wiki/Dot_product">dot-product</a> to calculate the \(\beta\) and \(x\) part to which we then add the single \(b\) value.</p><p>To make everything easier to calculate and implement we'll use a small trick. Multyping a value by the identify \(1\) yields the value so we prepend \(1\) to the \(x\) values and \(b\) to the \(\beta\) values. This way we can solely use the dot-product calculation without the necessity to add \(b\) separately later on. Here's the mathematical formulation of that trick:</p><p>\[ \vec{x} = \begin{pmatrix} 1 \\ x_1 \\ ... \\ x_n \end{pmatrix} \vec{\beta} = \begin{pmatrix} b \\ \beta_1 \\ ... \\ \beta_n \end{pmatrix} \]</p><p>\[ y = \vec{x} \cdot \vec{m} = \sum_{i=1}^n x_i \beta_i = x_1 \times \beta_1 + ... + x_n \times \beta_n \]</p><p>Once we've calculated the dot-product we need to pass it into the Sigmoid function such that its result is translated ("squished") into a value between \(0\) and \(1\).</p><p>Here's the implementation for the <code>dot</code> function which calculates the <a href="https://en.wikipedia.org/wiki/Dot_product">dot-product</a>:</p><pre><code>def dot(a: List[float], b: List[float]) -&gt; float:
    assert len(a) == len(b)
    return sum([a_i * b_i for a_i, b_i in zip(a, b)])

assert dot([1, 2, 3, 4], [5, 6, 7, 8]) == 70</code></pre><p>And here's the <code>squish</code> function which takes as parameters the \(x\) and \(\beta\) values (remember that we've prepended a \(1\) to the \(x\) values and the \(b\) to the \(\beta\) values), uses the <code>dot</code> function to calculate the dot-product of \(x\) and \(\beta\) and then passes this result into the Sigmoid function to map it to a value between \(0\) and \(1\):</p><pre><code>def squish(beta: List[float], x: List[float]) -&gt; float:
    assert len(beta) == len(x)
    # Calculate the dot product
    dot_result: float = dot(beta, x)
    # Use sigmoid to get a result between 0 and 1
    return sigmoid(dot_result)

assert squish([1, 2, 3, 4], [5, 6, 7, 8]) == 1.0</code></pre><h2 id="the-intuition-behind-the-0-1-range">The intuition behind the 0-1 range</h2><p>We've talked quite a lot about how the Sigmoid function is our solution to make the function outcome predictable as all values are mapped to a \(0\) - \(1\) range. But what does a value in that range represent? Let's take a look at an example.</p><p>The following is a data set which describes how long students have studied for an exam and whether they've passed the exam given the hours they've studied.</p><!--kg-card-begin: html--><table>
    <thead>
        <tr>
            <th>Hours studied</th>
            <th>Exam Passed</th>
        </tr>
    </thead>
    <tbody>
        <tr>
            <td>0,5</td>
            <td>0</td>
        </tr>
        <tr>
            <td>1,0</td>
            <td>0</td>
        </tr>
        <tr>
            <td>1,5</td>
            <td>0</td>
        </tr>
        <tr>
            <td>2,0</td>
            <td>0</td>
        </tr>
        <tr>
            <td>2,5</td>
            <td>1</td>
        </tr>
        <tr>
            <td>3,0</td>
            <td>0</td>
        </tr>
        <tr>
            <td>3,5</td>
            <td>1</td>
        </tr>
        <tr>
            <td>4,0</td>
            <td>1</td>
        </tr>
        <tr>
            <td>4,5</td>
            <td>0</td>
        </tr>
        <tr>
            <td>5,0</td>
            <td>1</td>
        </tr>
        <tr>
            <td>5,5</td>
            <td>1</td>
        </tr>
        <tr>
            <td>6,0</td>
            <td>1</td>
        </tr>
    </tbody>
</table><!--kg-card-end: html--><p>Taking a glance at the data it seems to be that the more hours the students studied, the more likely they were to pass the exam. Intuitively that makes sense.</p><p>Let's plot the data to ensure that our intuition is correct:</p><figure><img src="https://philippmuens.com/content/images/2020/06/zmock_student_data.png"></figure><p>Looking at the plotted data we can immediately see that the values seem to "stick" to either the bottom or top of the graph. Given that it seems to be infeasible to use a Linear Regression model to find a line which best describes the data. How would this line be fitted through the data if the values we'd expect this line should produce are either \(o\) or \(1\)?</p><p>Let's try a thought experiment. What would happen if we've somehow found some coefficients \(\beta\) for the Linear Regression model which "best" describe the data and pass the result it computes through the Sigmoid function? Here's the graph from above with the Sigmoid function added to it:</p><figure><img src="https://philippmuens.com/content/images/2020/06/zmock_student_data_w_sigmoid.png"></figure><p>Looking at the plotting above we can see that the Sigmoid function ensures that the result from the "underlying" Linear Regression model is mapped onto a scale between \(0\) and \(1\), which in turn makes it possible to e.g. define a threshold at \(0.5\) to say that a value which is greater than \(0.5\) might be a predictor for a student passing the exam while a value less than \(0.5\) might mean that she'll fail the exam.</p><p>Note that the wording in the last sentence isn't a coincidence. The value the Signoid function produces can be interpreted as a probability where \(0\) means \(0%\) probability and \(1\) means a \(100%\) probability.</p><h2 id="the-probability-density-function">The Probability Density Function</h2><p>As it turns out we can translate our findings from the previous section into a function called <a href="https://en.wikipedia.org/wiki/Probability_density_function">Probability density function</a> or (PDF for short).</p><p>In particular we can define a <a href="https://en.wikipedia.org/wiki/Conditional_probability">conditional probability</a> which states that given some \(\beta\) and \(x_i\), each corresponding \(y_i\) should equal \(1\) with probability \(\sigma(\beta x_i)\) and \(0\) with probability \(1-\sigma(\beta x_i)\):</p><p>\[ P(y_i \mid \beta x_i) = \sigma(\beta x_i)^{y_i} \times (1-\sigma(\beta x_i))^{1-y_i} \]</p><p>Looking at the formula above it might be a mystery how we deduced it from our verbal description from above. Here's something I want you to try: Please apply the formula by setting \(y_i\) to \(0\) and after that to \(1\) and see what happens. What you'll notice is that depending on what value you set \(y_i\) to, only one part of the formula stays the same while the other is canceled out.</p><p>Here's what we'll end up with if we set \(y_i\) to \(0\) and \(1\):</p><p>\[ 1-\sigma(\beta x_i) \quad \textrm{if} &nbsp;y_i = 0 \]</p><p>\[ \sigma(\beta x_i) \quad \textrm{if} &nbsp;y_i = 1 \]</p><p>And that's exactly the desired behavior we described above.</p><h2 id="deriving-a-loss-function">Deriving a Loss function</h2><p>With Logistic Regression our main objective is to find the models \(\beta\) parameters which maximize the likelihood that for a pair of \(x\) values the \(y\) value …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://philippmuens.com/logistic-regression-from-scratch/">https://philippmuens.com/logistic-regression-from-scratch/</a></em></p>]]>
            </description>
            <link>https://philippmuens.com/logistic-regression-from-scratch/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23640762</guid>
            <pubDate>Thu, 25 Jun 2020 13:54:15 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What vertical farming and ag startups don't understand about agriculture, part 2]]>
            </title>
            <description>
<![CDATA[
Score 120 | Comments 118 (<a href="https://news.ycombinator.com/item?id=23640011">thread link</a>) | @kickout
<br/>
June 25, 2020 | http://thinkingagriculture.io/what-sv-doesnt-understand-about-agriculture-part-ii/ | <a href="https://web.archive.org/web/*/http://thinkingagriculture.io/what-sv-doesnt-understand-about-agriculture-part-ii/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-20">
		
	
	<div>
		
<p>Some commenters (/u/coderintherye chain notably) on the <a href="https://news.ycombinator.com/item?id=23630201">HN post</a> of the <a href="https://thinkingagriculture.io/what-silicon-valley-doesnt-understand-about-agriculture/">original article</a> brought up good points that I wanted to expand on and provide some additional context. Also for clarification: although farming is truly global, most ‘farming’ I refer to pertains to the United States (<a href="https://en.wikipedia.org/wiki/Agriculture_in_the_United_States">which is an agriculture juggernaut</a>), but in my experience should reasonably translate across agriculture zones (pending equivalent laws and climatic factors).</p>



<p><strong><em>There is ample VC money for Ag startups</em></strong></p>



<p>The original intention of the article wasn’t to bemoan the lack of capital available for <a href="https://agiowa.com/portfolio/">founders focused on agriculture</a> (there is actually plenty of capital–check out <a href="https://agfundernews.com/">AgFunderNews</a> for examples of successful raises). Instead, it is a recommendation for anyone entering the space to understand the industry and its history to harness existing synergies rather than try and swim upstream. Watching capital go to ‘solved’ problems is painful, because there are many opportunities for a unicorn ag startup if aimed in the correct space. Vertical farming for non-vegetables (or fruits) is likely dead-on-pitch. Yes, vertical farming <em>is</em> and <em>could be</em> successful, but those markets are very specific and probably 10x smaller than people think. Nice businesses no doubt, but not market shaping behemoths VCs are after. Agriculture is rightfully a commodity and the market will brutalize ideas/companies that can’t turn a profit. One bad year (droughts in 2011 and 2012 in the US Midwest) from external forces can absolutely put farmers out of business. Indoor farming has all of the risks of outdoor ag–and more! Indoor farming requires water (whose source can dry up and get shut off unexpectedly, just like a drought), has pests, and requires artificial lighting (power outage for 5 days? Uh oh). Herbicides (and sometimes pesticides) are actually an example of innovation pre-SV. Alternate technologies (i.e mechanical) didn’t work or were uneconomical for the time period; thus, chemical solutions seemed to thrive (glyphosate/glufosinate resistant corn/soy/wheat/cotton/sugar beets &amp; <a href="https://agrilife.org/lubbock/files/2020/02/BtTraitTable_FEB_2020.pdf">BT resistance for insects</a>). I predict in next 5-20 years we see that flip, where chemical and biological solutions fall out in favor of mechanized solutions (who wouldn’t want a semi-autonomous robot pulling weeds in fields in favor of a chemical solution that is <a href="https://www.nbcnews.com/news/us-news/bayer-reaches-10-5-billion-settlement-roundup-cancer-lawsuits-n1232026">open to litigation</a>)? We just have too little understanding of 2nd and 3rd order effects of disrupting nature at this scale (<a href="https://www.nature.com/articles/s41598-019-49660-6">gene drives included</a>, as promising as they appear) using these incredibly effective chemicals.</p>



<p><strong><em>Financing in the Heartland</em></strong></p>



<p>I won’t speak of financing agricultural operations in a municipality not located in the United States, as even understanding the US situation takes time and effort. Let’s be clear though: Most farmers <em>need</em> to borrow capital just to operate for a given year (hence, there is a note called an ‘operating loan’) and financing agriculture operations is more and more important as the size of farms increases. They buy seed, fertilizer, feed, chemicals, etc. to be able to produce an output to then (hopefully) sell at a profit–all to rinse and repeat. Buying big expensive new tractors ($300k+ USD), buildings to store the machines, grain storage, fencing, animal houses–all generally require a loan. Because of the huge cost to purchase these necessities, financing institutions generally need to have a <em>very</em> thorough understanding of the operation (Only farm 160 acres of corn,soy,or wheat? Good luck buying equipment). So bankers have become very good (not perfect) at evaluating and swaying farming practices to ensure maximum likelihood of repayment. Seriously, check of the used auction prices of ag machinery sometime–<a href="https://www.bigiron.com/Lots/2011JohnDeere8335RMFWDTractor-3">this tractor</a> is 10 years old and commands the price of a new Tesla. Is ag financing a place that needs disruption? Likely no because ag lending has evolved hand-in-hand in rural communities where agricultural production is the predominant industry. Because they evolved with ag, they likely have already captured the +EV that startups tend to seek because their very existence depends on it. So where <em>are</em> the value proposition? I know nothing of their founding, but the previous auction link is from <a href="https://www.bigiron.com/">Big Iron Auctions</a> and those founders likely understood ag (“hey, there is a robust secondary market for farm machinery”) and created on-line version of it–with what appears to be great success. I’d imagine these on-line secondary markets exist in Brazil and Eastern Europe given there agriculture exposure. </p>



<p><strong><em>Success Stories</em></strong></p>



<p>There are some truly incredible examples of engineering and innovation in agriculture that focus on the mechanization and scale <em>that already exists</em>. Transplanting vegetables in the Central Valley (CA) used to be labor intensive–<a href="https://www.planttape.com/">this brilliant solution solved that</a>. Auto-steer <a href="https://www.fieldbee.com/blog/fieldbee-tractor-autosteer-versus-other-systems/">systems</a> that leverage machinery that already exists. Sometimes the innovation is statistical/computation (<a href="https://www.annualreviews.org/doi/full/10.1146/annurev-animal-021815-111422">genomic prediction has revolutionized dairy cattle</a>) Starting businesses is hard and agriculture is no different.</p>



<p>Stay away from vertical farming–unless you plan on growing saffron or figure out a way to cultivate morel mushrooms!</p>
	</div><!-- .entry-content -->

	<!-- .entry-footer -->

				
</article></div>]]>
            </description>
            <link>http://thinkingagriculture.io/what-sv-doesnt-understand-about-agriculture-part-ii/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23640011</guid>
            <pubDate>Thu, 25 Jun 2020 12:44:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Faster Integer Parsing]]>
            </title>
            <description>
<![CDATA[
Score 155 | Comments 39 (<a href="https://news.ycombinator.com/item?id=23639486">thread link</a>) | @fanf2
<br/>
June 25, 2020 | https://kholdstare.github.io/technical/2020/05/26/faster-integer-parsing.html | <a href="https://web.archive.org/web/*/https://kholdstare.github.io/technical/2020/05/26/faster-integer-parsing.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
        <p>Back with a post after 6 years of silence. If you had to parse a microsecond-resolution epoch timestamp as quickly as possible, how would you do it?  We’ll take a look at using compiler intrinsics to do it in log(n) time.</p>


        <h3 id="the-problem">The problem</h3>

<p>Let’s say, theoretically, you have some text-based protocol, or file that
contains microsecond timestamps. You need to parse these timestamps as quickly
as possible. Maybe it’s json, maybe it’s a csv file, maybe something else
bespoke. It’s 16 characters long, and this could also apply to credit card
numbers.</p>

<figure><pre><code data-lang="csv">timestamp,event_id
1585201087123567,a
1585201087123585,b
1585201087123621,c</code></pre></figure>

<p>In the end you have to implement a function similar to this:</p>

<figure><pre><code data-lang="cpp"><span>std</span><span>::</span><span>uint64_t</span> <span>parse_timestamp</span><span>(</span><span>std</span><span>::</span><span>string_view</span> <span>s</span><span>)</span>
<span>{</span>
  <span>// ???</span>
<span>}</span></code></pre></figure>

<hr>

<h3 id="the-native-solution">The native solution</h3>

<p>Let’s start with what’s available, and compare. We have
<a href="https://en.cppreference.com/w/cpp/string/byte/atoi"><code>std::atoll</code></a> , a function
inherited from C,
<a href="https://en.cppreference.com/w/cpp/io/basic_stringstream"><code>std::stringstream</code></a>
, the newer C++17
<a href="https://en.cppreference.com/w/cpp/header/charconv"><code>&lt;charconv&gt;</code></a> header, and
by request
<a href="https://www.boost.org/doc/libs/1_73_0/libs/spirit/doc/html/spirit/qi/reference/basics.html"><code>boost::spirit::qi</code></a>.
I’ll be using <a href="https://github.com/google/benchmark">Google Benchmark</a> to
measure the performance, and to have a baseline let’s compare against loading
the final result into a register - i.e. no actual parsing involved.</p>

<p>Let’s run the benchmarks! The code is not important here, it just shows what is being benchmarked.</p>

<figure><pre><code data-lang="cpp"><span>static</span> <span>void</span> <span>BM_mov</span><span>(</span><span>benchmark</span><span>::</span><span>State</span><span>&amp;</span> <span>state</span><span>)</span> <span>{</span>
  <span>for</span> <span>(</span><span>auto</span> <span>_</span> <span>:</span> <span>state</span><span>)</span> <span>{</span>
    <span>benchmark</span><span>::</span><span>DoNotOptimize</span><span>(</span><span>1585201087123789</span><span>);</span>
  <span>}</span>
<span>}</span>

<span>static</span> <span>void</span> <span>BM_atoll</span><span>(</span><span>benchmark</span><span>::</span><span>State</span><span>&amp;</span> <span>state</span><span>)</span> <span>{</span>
  <span>for</span> <span>(</span><span>auto</span> <span>_</span> <span>:</span> <span>state</span><span>)</span> <span>{</span>
    <span>benchmark</span><span>::</span><span>DoNotOptimize</span><span>(</span><span>std</span><span>::</span><span>atoll</span><span>(</span><span>example_timestamp</span><span>));</span>
  <span>}</span>
<span>}</span>

<span>static</span> <span>void</span> <span>BM_sstream</span><span>(</span><span>benchmark</span><span>::</span><span>State</span><span>&amp;</span> <span>state</span><span>)</span> <span>{</span>
  <span>std</span><span>::</span><span>stringstream</span> <span>s</span><span>(</span><span>example_timestamp</span><span>);</span>
  <span>for</span> <span>(</span><span>auto</span> <span>_</span> <span>:</span> <span>state</span><span>)</span> <span>{</span>
    <span>s</span><span>.</span><span>seekg</span><span>(</span><span>0</span><span>);</span>
    <span>std</span><span>::</span><span>uint64_t</span> <span>i</span> <span>=</span> <span>0</span><span>;</span>
    <span>s</span> <span>&gt;&gt;</span> <span>i</span><span>;</span>
    <span>benchmark</span><span>::</span><span>DoNotOptimize</span><span>(</span><span>i</span><span>);</span>
  <span>}</span>
<span>}</span>
<span>static</span> <span>void</span> <span>BM_charconv</span><span>(</span><span>benchmark</span><span>::</span><span>State</span><span>&amp;</span> <span>state</span><span>)</span> <span>{</span>
  <span>auto</span> <span>s</span> <span>=</span> <span>example_timestamp</span><span>;</span>
  <span>for</span> <span>(</span><span>auto</span> <span>_</span> <span>:</span> <span>state</span><span>)</span> <span>{</span>
    <span>std</span><span>::</span><span>uint64_t</span> <span>result</span> <span>=</span> <span>0</span><span>;</span>
    <span>std</span><span>::</span><span>from_chars</span><span>(</span><span>s</span><span>.</span><span>data</span><span>(),</span> <span>s</span><span>.</span><span>data</span><span>()</span> <span>+</span> <span>s</span><span>.</span><span>size</span><span>(),</span> <span>result</span><span>);</span>
    <span>benchmark</span><span>::</span><span>DoNotOptimize</span><span>(</span><span>result</span><span>);</span>
  <span>}</span>
<span>}</span>

<span>static</span> <span>void</span> <span>BM_boost_spirit</span><span>(</span><span>benchmark</span><span>::</span><span>State</span><span>&amp;</span> <span>state</span><span>)</span> <span>{</span>
  <span>using</span> <span>boost</span><span>::</span><span>spirit</span><span>::</span><span>qi</span><span>::</span><span>parse</span><span>;</span>
  <span>for</span> <span>(</span><span>auto</span> <span>_</span> <span>:</span> <span>state</span><span>)</span> <span>{</span>
    <span>std</span><span>::</span><span>uint64_t</span> <span>result</span> <span>=</span> <span>0</span><span>;</span>
    <span>parse</span><span>(</span><span>s</span><span>.</span><span>data</span><span>(),</span> <span>s</span><span>.</span><span>data</span><span>()</span> <span>+</span> <span>s</span><span>.</span><span>size</span><span>(),</span> <span>result</span><span>);</span>
    <span>benchmark</span><span>::</span><span>DoNotOptimize</span><span>(</span><span>result</span><span>);</span>
  <span>}</span>
<span>}</span></code></pre></figure>

<figure>
    <canvas id="benchmark-canvas-native">
    </canvas>

</figure>

<p>Wow, <code>stringstream</code> is pretty bad. Not that it’s a fair comparison but parsing
a single integer using <code>stringstream</code> is 391 times slower than just loading our
integer into a register.  <code>&lt;charconv&gt;</code> and <code>boost::spirit</code> do a lot better by
comparison.</p>

<p>Since we know our string contains the number we’re trying to parse, and we
don’t need to do any whitespace skipping, can we be faster?  Just how much time
is spent in validation?</p>

<hr>

<h3 id="the-naive-solution">The naive solution</h3>

<p>Let’s write a good old for loop. Read the string character by character, and
build up the result.</p>

<figure><pre><code data-lang="cpp"><span>inline</span> <span>std</span><span>::</span><span>uint64_t</span> <span>parse_naive</span><span>(</span><span>std</span><span>::</span><span>string_view</span> <span>s</span><span>)</span> <span>noexcept</span>
<span>{</span>
  <span>std</span><span>::</span><span>uint64_t</span> <span>result</span> <span>=</span> <span>0</span><span>;</span>
  <span>for</span><span>(</span><span>char</span> <span>digit</span> <span>:</span> <span>s</span><span>)</span>
  <span>{</span>
    <span>result</span> <span>*=</span> <span>10</span><span>;</span>
    <span>result</span> <span>+=</span> <span>digit</span> <span>-</span> <span>'0'</span><span>;</span>
  <span>}</span>
  <span>return</span> <span>result</span><span>;</span>
<span>}</span></code></pre></figure>

<figure>
    <canvas id="benchmark-canvas-naive">
    </canvas>

</figure>

<p>That’s actually not bad for a simple for loop. If such a simple solution is
able to beat a standard-library implementation, it means there’s quite a lot of
effort that goes into input validation. As a sidenote - if you know your input,
or can do simpler validation you can get some significant speedups.</p>

<p>For further solutions and benchmarks, let’s ignore the standard library
functions. We should be able to go much faster than this.</p>

<hr>

<h3 id="the-brute-force-solution">The brute force solution</h3>

<p>If we know it’s 16 bytes, why even have a forloop? Let’s unroll it!</p>

<figure><pre><code data-lang="cpp"><span>inline</span> <span>std</span><span>::</span><span>uint64_t</span> <span>parse_unrolled</span><span>(</span><span>std</span><span>::</span><span>string_view</span> <span>s</span><span>)</span> <span>noexcept</span>
<span>{</span>
  <span>std</span><span>::</span><span>uint64_t</span> <span>result</span> <span>=</span> <span>0</span><span>;</span>

  <span>result</span> <span>+=</span> <span>(</span><span>s</span><span>[</span><span>0</span><span>]</span> <span>-</span> <span>'0'</span><span>)</span> <span>*</span> <span>1000000000000000ULL</span><span>;</span>
  <span>result</span> <span>+=</span> <span>(</span><span>s</span><span>[</span><span>1</span><span>]</span> <span>-</span> <span>'0'</span><span>)</span> <span>*</span> <span>100000000000000ULL</span><span>;</span>
  <span>result</span> <span>+=</span> <span>(</span><span>s</span><span>[</span><span>2</span><span>]</span> <span>-</span> <span>'0'</span><span>)</span> <span>*</span> <span>10000000000000ULL</span><span>;</span>
  <span>result</span> <span>+=</span> <span>(</span><span>s</span><span>[</span><span>3</span><span>]</span> <span>-</span> <span>'0'</span><span>)</span> <span>*</span> <span>1000000000000ULL</span><span>;</span>
  <span>result</span> <span>+=</span> <span>(</span><span>s</span><span>[</span><span>4</span><span>]</span> <span>-</span> <span>'0'</span><span>)</span> <span>*</span> <span>100000000000ULL</span><span>;</span>
  <span>result</span> <span>+=</span> <span>(</span><span>s</span><span>[</span><span>5</span><span>]</span> <span>-</span> <span>'0'</span><span>)</span> <span>*</span> <span>10000000000ULL</span><span>;</span>
  <span>result</span> <span>+=</span> <span>(</span><span>s</span><span>[</span><span>6</span><span>]</span> <span>-</span> <span>'0'</span><span>)</span> <span>*</span> <span>1000000000ULL</span><span>;</span>
  <span>result</span> <span>+=</span> <span>(</span><span>s</span><span>[</span><span>7</span><span>]</span> <span>-</span> <span>'0'</span><span>)</span> <span>*</span> <span>100000000ULL</span><span>;</span>
  <span>result</span> <span>+=</span> <span>(</span><span>s</span><span>[</span><span>8</span><span>]</span> <span>-</span> <span>'0'</span><span>)</span> <span>*</span> <span>10000000ULL</span><span>;</span>
  <span>result</span> <span>+=</span> <span>(</span><span>s</span><span>[</span><span>9</span><span>]</span> <span>-</span> <span>'0'</span><span>)</span> <span>*</span> <span>1000000ULL</span><span>;</span>
  <span>result</span> <span>+=</span> <span>(</span><span>s</span><span>[</span><span>10</span><span>]</span> <span>-</span> <span>'0'</span><span>)</span> <span>*</span> <span>100000ULL</span><span>;</span>
  <span>result</span> <span>+=</span> <span>(</span><span>s</span><span>[</span><span>11</span><span>]</span> <span>-</span> <span>'0'</span><span>)</span> <span>*</span> <span>10000ULL</span><span>;</span>
  <span>result</span> <span>+=</span> <span>(</span><span>s</span><span>[</span><span>12</span><span>]</span> <span>-</span> <span>'0'</span><span>)</span> <span>*</span> <span>1000ULL</span><span>;</span>
  <span>result</span> <span>+=</span> <span>(</span><span>s</span><span>[</span><span>13</span><span>]</span> <span>-</span> <span>'0'</span><span>)</span> <span>*</span> <span>100ULL</span><span>;</span>
  <span>result</span> <span>+=</span> <span>(</span><span>s</span><span>[</span><span>14</span><span>]</span> <span>-</span> <span>'0'</span><span>)</span> <span>*</span> <span>10ULL</span><span>;</span>
  <span>result</span> <span>+=</span> <span>(</span><span>s</span><span>[</span><span>15</span><span>]</span> <span>-</span> <span>'0'</span><span>);</span>

  <span>return</span> <span>result</span><span>;</span>
<span>}</span></code></pre></figure>

<figure>
    <canvas id="benchmark-canvas-brute-force">
    </canvas>

</figure>

<p>Ok, that’s slightly better again, but we’re still processing a character at a time.</p>

<hr>

<h3 id="the-byteswap-insight">The byteswap insight</h3>

<p>Let’s draw out the operations in the unrolled solution as a tree, on a
simplified example of parsing ‘1234’ into a 32-bit integer:</p>

<figure>
    <img width="100%" height="100%" src="https://kholdstare.github.io/diagrams/parse-unrolled.png">

<figcaption><p>Unrolled solution graph of operations for ‘1234’</p>
</figcaption>

</figure>

<p>We can see that the amount of multiplications and additions is linear with the
amount of characters. It’s hard to see how to improve this, because every
multiplication is by a different factor (so we can’t multiply “in one go”), and at
the end of the day we need to add up all the intermediate results.</p>

<p>However, it’s still very regular. For one thing, the first character in the
string is multiplied by the largest factor, because it is the most significant
digit.</p>

<blockquote>
  <p>On a little-endian machine (like x86), an integer’s first byte contains the
least significant digits, while the first byte in a string contains the most
significant digit.</p>
</blockquote>

<figure>
    <img width="100%" height="100%" src="https://kholdstare.github.io/diagrams/parse-byteswap-insight.png">

<figcaption><p>Looking at the string as an integer we can get closer to
the final parsed state in fewer operations - see how the hex representation is
<strong>almost</strong> what we want</p>
</figcaption>

</figure>

<p>Now to reinterpret the bytes of a string as an integer we have to use
<code>std::memcpy</code> (<a href="https://blog.regehr.org/archives/1307">to avoid strict-aliasing
violations</a>), and we have compiler
instrinsic <code>__builtin_bswap64</code> to swap the bytes in one instruction. The
<code>std::memcpy</code> will get optimized out, so this is a win so far.</p>

<figure><pre><code data-lang="cpp"><span>template</span> <span>&lt;</span><span>typename</span> <span>T</span><span>&gt;</span>
<span>inline</span> <span>T</span> <span>get_zeros_string</span><span>()</span> <span>noexcept</span><span>;</span>

<span>template</span> <span>&lt;</span><span>&gt;</span>
<span>inline</span> <span>std</span><span>::</span><span>uint64_t</span> <span>get_zeros_string</span><span>&lt;</span><span>std</span><span>::</span><span>uint64_t</span><span>&gt;</span><span>()</span> <span>noexcept</span>
<span>{</span>
  <span>std</span><span>::</span><span>uint64_t</span> <span>result</span> <span>=</span> <span>0</span><span>;</span>
  <span>constexpr</span> <span>char</span> <span>zeros</span><span>[]</span> <span>=</span> <span>"00000000"</span><span>;</span>
  <span>std</span><span>::</span><span>memcpy</span><span>(</span><span>&amp;</span><span>result</span><span>,</span> <span>zeros</span><span>,</span> <span>sizeof</span><span>(</span><span>result</span><span>));</span>
  <span>return</span> <span>result</span><span>;</span>
<span>}</span>

<span>inline</span> <span>std</span><span>::</span><span>uint64_t</span> <span>parse_8_chars</span><span>(</span><span>const</span> <span>char</span><span>*</span> <span>string</span><span>)</span> <span>noexcept</span>
<span>{</span>
  <span>std</span><span>::</span><span>uint64_t</span> <span>chunk</span> <span>=</span> <span>0</span><span>;</span>
  <span>std</span><span>::</span><span>memcpy</span><span>(</span><span>&amp;</span><span>chunk</span><span>,</span> <span>string</span><span>,</span> <span>sizeof</span><span>(</span><span>chunk</span><span>));</span>
  <span>chunk</span> <span>=</span> <span>__builtin_bswap64</span><span>(</span><span>chunk</span> <span>-</span> <span>get_zeros_string</span><span>&lt;</span><span>std</span><span>::</span><span>uint64_t</span><span>&gt;</span><span>());</span>

  <span>// ...</span>
<span>}</span></code></pre></figure>

<p>But now that we have an integer that kind of, sort of looks like what we want,
how do we get it across the finish line without too much work?</p>

<hr>

<h3 id="the-divide-and-conquer-insight">The divide and conquer insight</h3>

<p>From the previous step, we end up with an integer whose bit representation 
has each digit placed in a separate byte. I.e. even though one byte can
represent up to 256 values, we have values 0-9 in each byte of the integer.
They are also in the right little endian order. Now we just need to “smash”
them together somehow.</p>

<p>We know that doing it linearly would be too slow, what’s the next possibility?
<strong>O(log(n))</strong>! We need to combine every adjacent digit into a pair in one step,
and then each pair of digits into a group of four, and so on, until we have the
entire integer.</p>

<p>After I posted the first version of this article, <a href="https://www.reddit.com/r/cpp/comments/gr18ig/faster_integer_parsing/frx9agb">Sopel97 on
reddit</a>
pointed out that the byteswap is not necessary. Combining adjacent digits works
either way - their order doesn’t matter.  I realized that it helped me with the
next insight, but could be omitted for the final code.</p>

<blockquote>
  <p>The key is working on adjacent digits simultaneously. This allows a tree of
operations, running in O(log(n)) time.</p>
</blockquote>

<p>This involves multiplying the even-index digits by a power of 10 and leaving the
odd-index digits alone. This can be done with bitmasks to selectively apply
operations</p>

<figure>
    <img width="100%" height="100%" src="https://kholdstare.github.io/diagrams/parse-mask-insight.png">

<figcaption><p>By using bitmasking, we can apply operations to more than one digit at a time, to combine them into a larger group</p>
</figcaption>

</figure>

<p>Let’s finish the <code>parse_8_chars</code> function we started earlier by employing this
masking trick. As a neat side-effect of the masking, we don’t need to subtract
<code>'0'</code>, since it will be masked away.</p>

<figure><pre><code data-lang="cpp"><span>inline</span> <span>std</span><span>::</span><span>uint64_t</span> <span>parse_8_chars</span><span>(</span><span>const</span> <span>char</span><span>*</span> <span>string</span><span>)</span> <span>noexcept</span>
<span>{</span>
  <span>std</span><span>::</span><span>uint64_t</span> <span>chunk</span> <span>=</span> <span>0</span><span>;</span>
  <span>std</span><span>::</span><span>memcpy</span><span>(</span><span>&amp;</span><span>chunk</span><span>,</span> <span>string</span><span>,</span> <span>sizeof</span><span>(</span><span>chunk</span><span>));</span>

  <span>// 1-byte mask trick (works on 4 pairs of single digits)</span>
  <span>std</span><span>::</span><span>uint64_t</span> <span>lower_digits</span> <span>=</span> <span>(</span><span>chunk</span> <span>&amp;</span> <span>0x0f000f000f000f00</span><span>)</span> <span>&gt;&gt;</span> <span>8</span><span>;</span>
  <span>std</span><span>::</span><span>uint64_t</span> <span>upper_digits</span> <span>=</span> <span>(</span><span>chunk</span> <span>&amp;</span> <span>0x000f000f000f000f</span><span>)</span> <span>*</span> <span>10</span><span>;</span>
  <span>chunk</span> <span>=</span> <span>lower_digits</span> <span>+</span> <span>upper_digits</span><span>;</span>

  <span>// 2-byte mask trick (works on 2 pairs of two digits)</span>
  <span>lower_digits</span> <span>=</span> <span>(</span><span>chunk</span> <span>&amp;</span> <span>0x00ff000000ff0000</span><span>)</span> <span>&gt;&gt;</span> <span>16</span><span>;</span>
  <span>upper_digits</span> <span>=</span> <span>(</span><span>chunk</span> <span>&amp;</span> <span>0x000000ff000000ff</span><span>)</span> <span>*</span> <span>100</span><span>;</span>
  <span>chunk</span> <span>=</span> <span>lower_digits</span> <span>+</span> <span>upper_digits</span><span>;</span>

  <span>// 4-byte mask trick (works on pair of four digits)</span>
  <span>lower_digits</span> <span>=</span> <span>(</span><span>chunk</span> <span>&amp;</span> <span>0x0000ffff00000000</span><span>)</span> <span>&gt;&gt;</span> <span>32</span><span>;</span>
  <span>upper_digits</span> <span>=</span> <span>(</span><span>chunk</span> <span>&amp;</span> <span>0x000000000000ffff</span><span>)</span> <span>*</span> <span>10000</span><span>;</span>
  <span>chunk</span> <span>=</span> <span>lower_digits</span> <span>+</span> <span>upper_digits</span><span>;</span>

  <span>return</span> <span>chunk</span><span>;</span>
<span>}</span></code></pre></figure>

<hr>

<h3 id="the-trick">The trick</h3>

<p>Putting it all together, to parse our 16-digit integer, we break it up into two
chunks of 8 bytes, run <code>parse_8_chars</code> that we have just written, and benchmark it!</p>

<figure><pre><code data-lang="cpp"><span>inline</span> <span>std</span><span>::</span><span>uint64_t</span> <span>parse_trick</span><span>(</span><span>std</span><span>::</span><span>string_view</span> <span>s</span><span>)</span> <span>noexcept</span>
<span>{</span>
  <span>std</span><span>::</span><span>uint64_t</span> <span>upper_digits</span> <span>=</span> <span>parse_8_chars</span><span>(</span><span>s</span><span>.</span><span>data</span><span>());</span>
  <span>std</span><span>::</span><span>uint64_t</span> <span>lower_digits</span> <span>=</span> <span>parse_8_chars</span><span>(</span><span>s</span><span>.</span><span>data</span><span>()</span> <span>+</span> <span>8</span><span>);</span>
  <span>return</span> <span>upper_digits</span> <span>*</span> <span>100000000</span> <span>+</span> <span>lower_digits</span><span>;</span>
<span>}</span>

<span>static</span> <span>void</span> <span>BM_trick</span><span>(</span><span>benchmark</span><span>::</span><span>State</span><span>&amp;</span> <span>state</span><span>)</span> <span>{</span>
  <span>for</span> <span>(</span><span>auto</span> <span>_</span> <span>:</span> <span>state</span><span>)</span> <span>{</span>
    <span>benchmark</span><span>::</span><span>DoNotOptimize</span><span>(</span><span>parse_trick</span><span>(</span><span>example_stringview</span><span>));</span>
  <span>}</span>
<span>}</span></code></pre></figure>

<figure>
    <canvas id="benchmark-canvas-trick">
    </canvas>

</figure>

<p>Not too shabby, we shaved almost 56% off of the unrolled loop benchmark! Still,
it feels like we are manually doing a bunch of masking and elementwise
operations. Maybe we can just let the CPU do all the hard work?</p>

<hr>

<h3 id="the-simd-trick">The SIMD trick</h3>

<p>We have the main insight:</p>

<ul>
  <li>Combine groups of digits simultaneously to achieve O(log(n)) time</li>
</ul>

<p>We also have a 16-character, or 128-bit string to parse - can we use SIMD? Of
course we can! <a href="https://en.wikipedia.org/wiki/SIMD">SIMD stands for Single Instruction Multiple
Data</a>, and is exactly what we are looking
for. SSE and AVX instructions are supported on both Intel and AMD CPUs, and
 they typically work with wider registers.</p>

<p>I used the <a href="https://software.intel.com/sites/landingpage/IntrinsicsGuide/">Intel Intrinsics
Guide</a> to find
the right compiler intrinsics for the right SIMD CPU instructions.</p>

<p>Let’s set up the digits in each of the 16 bytes first:</p>

<figure><pre><code data-lang="cpp"><span>inline</span> <span>std</span><span>::</span><span>uint64_t</span> <span>parse_1…</span></code></pre></figure></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://kholdstare.github.io/technical/2020/05/26/faster-integer-parsing.html">https://kholdstare.github.io/technical/2020/05/26/faster-integer-parsing.html</a></em></p>]]>
            </description>
            <link>https://kholdstare.github.io/technical/2020/05/26/faster-integer-parsing.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23639486</guid>
            <pubDate>Thu, 25 Jun 2020 11:43:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to get your first 100 users as a SaaS startup founder?]]>
            </title>
            <description>
<![CDATA[
Score 35 | Comments 19 (<a href="https://news.ycombinator.com/item?id=23638173">thread link</a>) | @nathanganser
<br/>
June 25, 2020 | https://blog.nat.app/how-to-get-your-first-100-users-as-a-saas-startup-founder-ckbnjyv6v00oajps1v7082imx | <a href="https://web.archive.org/web/*/https://blog.nat.app/how-to-get-your-first-100-users-as-a-saas-startup-founder-ckbnjyv6v00oajps1v7082imx">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="text"><p>You've got to start somewhere right. You've got your landing page and maybe even an MVP, but no one is visiting your website! How do you actually get those first 100 users? I've been there myself with  <a target="_blank" rel="noopener noreferrer" href="https://nat.app/">my startup</a>, and I would have loved to read such an article when I got started, so here it is! In honour of my past self and to help all fellow startup founders! </p>
<h2 id="get-started">Get started</h2>
<p>Here are a few basic tips you should get started with. They will pay off in the coming months. </p>
<h3 id="start-with-seo">Start with SEO</h3>
<p>SEO will not get you users overnight, but it's an amazing long term investment. Do it. 
Obviously, don't try to rank for super general keywords, instead, focus on niche keywords your audience is interested in. Here are a few examples from our own startup: </p>
<ul>
<li><a target="_blank" rel="noopener noreferrer" href="https://medium.com/@nathanganser/which-contacts-am-i-losing-touch-with-find-out-now-25f2db1320c3">Which contacts am I losing touch with? Find out now</a> </li>
<li><a target="_blank" rel="noopener noreferrer" href="https://medium.com/nat-personal-relationship-manager/what-is-a-gmail-metadata-integration-and-why-you-should-use-it-57b37fe54dbe">What is a Gmail Metadata integration and why you should use it</a></li>
<li><a target="_blank" rel="noopener noreferrer" href="https://medium.com/nat-personal-relationship-manager/how-i-created-an-automated-relationship-management-tool-using-coda-zapier-8a31a6d2ebe2">How I created an Automated Relationship Management tool using Coda &amp; Zapier</a>  </li>
<li><a target="_blank" rel="noopener noreferrer" href="https://medium.com/nat-personal-relationship-manager/the-ultimate-personal-relationship-manager-list-2ae87acf5070">Top 6 Best Personal CRM apps</a> </li>
</ul>
<p><em>Like passive income, those articles are generating a steady (albeit small) traffic to our app. But what's powerful about this traffic is that its super high-quality people. Only passionate people will find your articles, and when they do, they'll check out your app as well. </em></p>
<h3 id="quora-twitter-answer-to-questions">Quora &amp; Twitter: Answer to questions</h3>
<p>Create a company account and start replying to questions related to what you're doing. Twitter has a really good advanced search feature and Quora will suggest you more than enough questions you can reply to. If you spend a few hours each week generating good content on those platforms, you'll get a steady stream of clicks to your landing page as well. </p>
<p><img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1592240101831/sk3gE249t.png?auto=format&amp;q=60" alt="quora-answers-stats.png"></p>
<h3 id="pioneer-app">Pioneer.app</h3>
<p> <a target="_blank" rel="noopener noreferrer" href="https://pioneer.app/">Pioneer</a>  is an online accelerator that you can join for free. Every week, you submit a progress update and other users will give you feedback. This is a free way to get a few clicks to your app from startup founders. </p>
<h3 id="get-listed-on-10words-betalist">Get listed on 10words &amp; Betalist</h3>
<p> <a target="_blank" rel="noopener noreferrer" href="https://10words.io/">10words</a> and  <a target="_blank" rel="noopener noreferrer" href="https://blog.nat.app/betalist.com">BetaList</a> are like a small Product Hunts. They are much smaller, you can expect around 50 clicks to your website for each. Still worth something! </p>
<h3 id="list-your-startup-on-indie-hacker-makerlog">List your startup on Indie Hacker &amp; Makerlog</h3>
<p>Those are two cool communities. If you're active, you'll definitely get some attention and users! </p>
<ul>
<li><a target="_blank" rel="noopener noreferrer" href="https://getmakerlog.com/">MakerLog</a> </li>
<li><a target="_blank" rel="noopener noreferrer" href="https://blog.nat.app/indiehackers.com">Indie Hacker</a></li>
</ul>
<h3 id="product-hunt-ship">Product Hunt Ship</h3>
<p>Product Hunt has a place for upcoming apps called <strong> <a target="_blank" rel="noopener noreferrer" href="https://www.producthunt.com/ship">Ship</a> </strong>, I've not found it to be very useful, but it can get you a few additional users. </p>
<h2 id="growth-hacks">Growth hacks</h2>
<p>That's where stuff gets exciting. Use these growth hacks with moderation, there is a fine line between marketing and spamming. </p>
<h3 id="product-hunt-phantombuster-twitter">Product Hunt + PhantomBuster + Twitter</h3>
<p>If there are already a few apps on ProductHunt that are similar to what you're building, consider using  <a target="_blank" rel="noopener noreferrer" href="https://www.indiehackers.com/post/how-i-growth-hacked-my-way-to-500-waiting-list-subscribers-9612933fd3">this growth hack</a>. I've used it extensively myself. </p>
<h3 id="buy-targeted-email-lists">Buy targeted email lists</h3>
<p>I've built a tool myself that lets me scrape email addresses from founders on Indie Hacker. What's powerful is that you can filter by every filter available on Indie Hacker (revenue, location, business model, ...). You can use it to buy an email list here and use a tool like <a target="_blank" rel="noopener noreferrer" href="https://gmass.com/">Gmass</a> or Streak to reach out.  <a target="_blank" rel="noopener noreferrer" href="https://scrapeindiehacker.app/">Buy a list here</a>.</p>
<p>I don't recommend just sending the same email to everyone as this will impact your reputation. Instead, send personalized mass emails. It does take a bit longer, but it's worth every second considering the impact it will have on response rate and trust.</p>

<p>There are many chrome extensions out there that have tons of users but that are not maintained anymore. You can buy one for very cheap that is related to what you do and advertise your business on there. I bought  <a target="_blank" rel="noopener noreferrer" href="https://chrome.google.com/webstore/detail/google-contacts-opener/pjpambjkhcilibnmeihhfgdkhfelbdkj">Google Contacts Opener</a>  and it's been generating significant traffic to our website ever since. </p>
<h2 id="what-you-should-not-be-doing">What you should not be doing</h2>
<h3 id="advertising">Advertising</h3>
<p>It will cost you too much. Just don't think about it. In the early days, ads are not the way to go.</p>
<h3 id="launch-on-product-hunt">Launch on Product Hunt</h3>
<p>You've got only one shot at this, it better be big. You don't want to launch on Product Hunt before having built a mature product. Product Hunt is not for the launching phase, it's for the growth phase.  <a target="_blank" rel="noopener noreferrer" href="https://betalist.com/">BetaList</a> is a better place to start.</p>
<h3 id="my-startup-s-traffic">My startup's traffic</h3>
<p>Here is a breakdown of who visited our website recently. This will give you a better idea of what you should focus on. 
<img src="https://cdn.hashnode.com/res/hashnode/image/upload/v1592241905463/7LrJ4YdmB.png?auto=format&amp;q=60" alt="website visitor origin.png"></p>
</div></div>]]>
            </description>
            <link>https://blog.nat.app/how-to-get-your-first-100-users-as-a-saas-startup-founder-ckbnjyv6v00oajps1v7082imx</link>
            <guid isPermaLink="false">hacker-news-small-sites-23638173</guid>
            <pubDate>Thu, 25 Jun 2020 08:21:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How Zoom works [slides]]]>
            </title>
            <description>
<![CDATA[
Score 186 | Comments 143 (<a href="https://news.ycombinator.com/item?id=23638116">thread link</a>) | @Spidery
<br/>
June 25, 2020 | https://builtformars.co.uk/how-zoom-works/ | <a href="https://web.archive.org/web/*/https://builtformars.co.uk/how-zoom-works/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-elementor-type="single" data-elementor-id="2530" data-elementor-settings="[]">
		<div>
			<div>
						<section data-id="c26fc93" data-element_type="section" data-settings="{&quot;background_background&quot;:&quot;classic&quot;}">
						<div>
				<div>
				<div data-id="28a6896" data-element_type="column">
			<div>
					<div>
				
				<div data-id="b04b2c1" data-element_type="widget" data-widget_type="theme-post-excerpt.default">
				<p>
			Zoom is a significant challenger in the video conferencing space, but is their UX any better than Skype or Cisco?		</p>
				</div>
						</div>
			</div>
		</div>
						</div>
			</div>
		</section>
				<section data-id="052a335" data-element_type="section" data-settings="{&quot;background_background&quot;:&quot;classic&quot;}">
						<div>
				<div>
				<div data-id="4224d77" data-element_type="column">
			<div>
					<div>
				<div data-id="5ad8739" data-element_type="widget" data-widget_type="theme-post-featured-image.default">
				<div>
					<p><img width="720" height="410" src="https://builtformars.co.uk/wp-content/uploads/2020/04/Zoom.png" alt="Zoom UX case study" srcset="https://builtformars.co.uk/wp-content/uploads/2020/04/Zoom.png 1018w, https://builtformars.co.uk/wp-content/uploads/2020/04/Zoom-300x171.png 300w, https://builtformars.co.uk/wp-content/uploads/2020/04/Zoom-768x438.png 768w, https://builtformars.co.uk/wp-content/uploads/2020/04/Zoom-100x57.png 100w, https://builtformars.co.uk/wp-content/uploads/2020/04/Zoom-700x399.png 700w" sizes="(max-width: 720px) 100vw, 720px">											</p>
				</div>
				</div>
						</div>
			</div>
		</div>
				<div data-id="a001539" data-element_type="column">
			<div>
					<div>
				
				<div data-id="724633a" data-element_type="widget" data-widget_type="post-info.default">
				<div>
					<ul>
					<li itemprop="datePublished">
										<span>
															</span>
									<span>
							<span>📅 Added on</span>
										April 15, 2020					</span>
								</li>
				</ul>
				</div>
				</div>
						</div>
			</div>
		</div>
						</div>
			</div>
		</section>
				<section data-id="2643ed8" data-element_type="section" data-settings="{&quot;background_background&quot;:&quot;classic&quot;}">
						<div>
				<div>
				<div data-id="a995590" data-element_type="column">
			<div>
					<div>
				<div data-id="c9f06a8" data-element_type="widget" data-widget_type="theme-post-featured-image.default">
				<div>
					<p><img width="720" height="410" src="https://builtformars.co.uk/wp-content/uploads/2020/04/Zoom.png" alt="Zoom UX case study" srcset="https://builtformars.co.uk/wp-content/uploads/2020/04/Zoom.png 1018w, https://builtformars.co.uk/wp-content/uploads/2020/04/Zoom-300x171.png 300w, https://builtformars.co.uk/wp-content/uploads/2020/04/Zoom-768x438.png 768w, https://builtformars.co.uk/wp-content/uploads/2020/04/Zoom-100x57.png 100w, https://builtformars.co.uk/wp-content/uploads/2020/04/Zoom-700x399.png 700w" sizes="(max-width: 720px) 100vw, 720px">											</p>
				</div>
				</div>
						</div>
			</div>
		</div>
				
						</div>
			</div>
		</section>
				<section data-id="ca3ca43" data-element_type="section" data-settings="{&quot;background_background&quot;:&quot;classic&quot;}">
							
							<div>
				<div>
				<div data-id="ec20c55" data-element_type="column">
			<div>
					<div>
				<div data-id="682e138" data-element_type="widget" data-widget_type="theme-post-content.default">
				<div>
					<div data-elementor-type="wp-post" data-elementor-id="3204" data-elementor-settings="[]">
			<div>
				<div>
							<section data-id="7b73c3c" data-element_type="section">
						<div>
				<div>
				<div data-id="d0a7d7b" data-element_type="column">
			<div>
					<div>
				<div data-id="cd0bf0c" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<div><div><div role="region" aria-label="Slider"><p><img src="data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxMjAwIiBoZWlnaHQ9IjkwMCIgPjwvc3ZnPg==" alt="Slider"></p></div></div></div>
				</div>
				</div>
						</div>
			</div>
		</div>
						</div>
			</div>
		</section>
						</div>
			</div>
		</div>
				</div>
				</div>
						</div>
			</div>
		</div>
						</div>
			</div>
		</section>
				<section data-id="375357f" data-element_type="section" data-settings="{&quot;background_background&quot;:&quot;classic&quot;}">
						<div>
				<div>
				<div data-id="353f855" data-element_type="column">
			<div>
					<div>
				<div data-id="891920c" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<p>💡<strong>Tip:</strong> Try using the ⬅️ <span>➡️arrows on your keyboard to navigate the slides.</span></p>
				</div>
				</div>
						</div>
			</div>
		</div>
						</div>
			</div>
		</section>
				<section data-id="9ffc41b" data-element_type="section" data-settings="{&quot;background_background&quot;:&quot;classic&quot;}">
						<div>
				<div>
				<div data-id="5f2393c" data-element_type="column">
			<div>
					<div>
				<div data-id="b2a958e" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<p><strong>Mobile tip:</strong> Try swiping ⬅️<span>👆➡️ left and right to navigate the slides.</span></p>
				</div>
				</div>
						</div>
			</div>
		</div>
						</div>
			</div>
		</section>
				<section data-id="5094e89" data-element_type="section" data-settings="{&quot;background_background&quot;:&quot;classic&quot;}">
						<div>
				<div>
				<div data-id="4d0fdca" data-element_type="column">
			<div>
					<div>
				
				<div data-id="560b6f9" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<p>New case studies—packed with UX lessons—are published every <strong>14 days</strong>.</p>
				</div>
				</div>
				<div data-id="c135888" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<p><span>📮 No spam, ever.&nbsp; &nbsp;</span><span>📅 1 email a week.&nbsp; &nbsp;</span><span>👋 Unsubscribe anytime.</span></p>
				</div>
				</div>
				
						</div>
			</div>
		</div>
						</div>
			</div>
		</section>
				<section data-id="3daa393" data-element_type="section" data-settings="{&quot;background_background&quot;:&quot;classic&quot;}">
						<div>
				<div>
				<div data-id="4876312" data-element_type="column">
			<div>
					<div>
				<section data-id="05a68ee" data-element_type="section" data-settings="{&quot;background_background&quot;:&quot;classic&quot;}">
						<div>
				<div>
				<div data-id="09ef108" data-element_type="column" data-settings="{&quot;background_background&quot;:&quot;classic&quot;}">
			<div>
							
					<div>
				<div data-id="31901c7" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<p>Subscribe and get a new case study like this every <strong>14 days</strong>!</p>
				</div>
				</div>
						</div>
			</div>
		</div>
				
						</div>
			</div>
		</section>
						</div>
			</div>
		</div>
						</div>
			</div>
		</section>
				<section data-id="94d99dd" data-element_type="section" data-settings="{&quot;background_background&quot;:&quot;classic&quot;}">
						<div>
				<div>
				<div data-id="3a870f9" data-element_type="column">
			<div>
					<div>
				<div data-id="91f57f2" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<p>There’s always more to learn</p>
				</div>
				</div>
				<div data-id="2f5c033" data-element_type="widget" data-widget_type="text-editor.default">
				<div>
					<p>Dive into other case studies. They’re typically a <strong>5 minute read</strong>.</p>
				</div>
				</div>
						</div>
			</div>
		</div>
						</div>
			</div>
		</section>
				<section data-id="c62cabd" data-element_type="section" data-settings="{&quot;background_background&quot;:&quot;classic&quot;}">
						
		</section>
					</div>
		</div>
		</div></div>]]>
            </description>
            <link>https://builtformars.co.uk/how-zoom-works/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23638116</guid>
            <pubDate>Thu, 25 Jun 2020 08:13:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[On Liberty (1859) [pdf]]]>
            </title>
            <description>
<![CDATA[
Score 165 | Comments 101 (<a href="https://news.ycombinator.com/item?id=23636407">thread link</a>) | @mrfusion
<br/>
June 24, 2020 | https://socialsciences.mcmaster.ca/econ/ugcm/3ll3/mill/liberty.pdf | <a href="https://web.archive.org/web/*/https://socialsciences.mcmaster.ca/econ/ugcm/3ll3/mill/liberty.pdf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div p="">&gt; 
endobj
379 0 obj
&lt;&lt; /S 964 /O 1045 /Filter /FlateDecode /Length 380 0 R &gt;&gt; 
stream
ì+ªýc„-ÌéEÎØµ«°L½÷Ëÿé;ÄÛxÃ¼to•F$ˆ¡)•ãz§%u­ÌP¬5,‚|)äìº„H”˜Ïk‚Æ&nbsp;s˜Z‡}8kxgF¼�Ew�‰	ÕìC¸‡2÷¨ÿ&gt;JùwãÏ@ãù«z‰7s¹vëëœEªœ:Øy±cˆ[°ÅÄ§ÁôCEb´.&gt;øõ½ó¶B�š:DØ´×¸æ¢¬aqäÁ"Õ&gt;(¿ìøzF|ñlçJ´W‘~|‹§	|hÓwÎ�&gt;|³¹Žö™&amp;¬frË�/^@¦Šà°GM4mejD›ê²õ`X–Þrm¯ð²ÝUdñØ"LjÝÁ{um]4tÈj»­)6qbÕ<v%aÁ£œps1�l`Ôbä2[›;� qhu'…„+~€úmÿÓ‚Ámïx="£ËÝfÊÙÁš¨Ìâ|â3É5¸æ£gøÕû‘jªãt" Øl4ï="ù2Jd·”õ" ŠÖö*uxi«Áx4ãõ€�´�+otx‰³ö÷ö,¼Þ1¢fçÐ¾›ûødÝ^h¸ÚdÎÌ4bÅs×Çê†~k%’î¦—¦¨éå6xª+§qÔÒ„†hÐ[s¹="ˆžµ—QäyÀ½fî¤u*�su$ØÐwrg" endstream="" endobj="" 380="" 0="" obj="" 488="" 352="" <<="" type="" page="" parent="" 336="" r="" resources="" 366="" contents="" 371="" mediabox="" [="" 432="" 648="" ]="" cropbox="" rotate="">&gt; 
endobj
353 0 obj
&lt;&lt; 
/Count 1 
/First 354 0 R 
/Last 354 0 R 
&gt;&gt; 
endobj
354 0 obj
&lt;&lt; 
/Title (T¬Þô¯ø1n)
/Dest [ 4 0 R /Fit ] 
/Parent 353 0 R 
/First 355 0 R 
/Last 356 0 R 
/Count -11 
&gt;&gt; 
endobj
355 0 obj
&lt;&lt; 
/Title (š[ÌBe°†à0úg)
/Dest [ 20 0 R /Fit ] 
/Parent 354 0 R 
/Next 365 0 R 
&gt;&gt; 
endobj
356 0 obj
&lt;&lt; 
/Title (‘'G`iŸ)
/Dest [ 320 0 R /Fit ] 
/Parent 354 0 R 
/Prev 357 0 R 
&gt;&gt; 
endobj
357 0 obj
&lt;&lt; 
/Title (°DÞ—9³Ùí+ Šk¹)
/Dest [ 260 0 R /Fit ] 
/Parent 354 0 R 
/Prev 358 0 R 
/Next 356 0 R 
&gt;&gt; 
endobj
358 0 obj
&lt;&lt; 
/Title (ø“€·+Š*—ÜI)
/Dest [ 260 0 R /Fit ] 
/Parent 354 0 R 
/Prev 359 0 R 
/Next 357 0 R 
&gt;&gt; 
endobj
359 0 obj
&lt;&lt; 
/Title (*I“KP8iÃ]3¨ŒÎÙÝÊÜ®%zÙ3k&gt;g’Bn~|‹Û°.¦7Z#Ð\(Ü²ÄÃhÿ"SÀv7�K/J\()
/Dest [ 209 0 R /Fit ] 
/Parent 354 0 R 
/Prev 360 0 R 
/Next 358 0 R 
&gt;&gt; 
endobj
360 0 obj
&lt;&lt; 
/Title (D7A­­*!P])
/Dest [ 209 0 R /Fit ] 
/Parent 354 0 R 
/Prev 361 0 R 
/Next 359 0 R 
&gt;&gt; 
endobj
361 0 obj
&lt;&lt; 
/Title (õËÃª5tT±ZOJR¨�»[¿5&lt;¿j+æN*œ§h4èÉÄo	É»W'±WßK¥ÞZ_š¦&amp;-M)
/Dest [ 158 0 R /Fit ] 
/Parent 354 0 R 
/Prev 362 0 R 
/Next 360 0 R 
&gt;&gt; 
endobj
362 0 obj
&lt;&lt; 
/Title (’›­öëQ“uö)
/Dest [ 158 0 R /Fit ] 
/Parent 354 0 R 
/Prev 363 0 R 
/Next 361 0 R 
&gt;&gt; 
endobj
363 0 obj
&lt;&lt; 
/Title (-hs~FD»M„íM±VleÁŸï!Å¤Ÿpnt­ô6qñ‡-Œí*üKª©)
/Dest [ 56 0 R /Fit ] 
/Parent 354 0 R 
/Prev 364 0 R 
/Next 362 0 R 
&gt;&gt; 
endobj
364 0 obj
&lt;&lt; 
/Title (:Gû¹ÀS ˜&nbsp;2)
/Dest [ 56 0 R /Fit ] 
/Parent 354 0 R 
/Prev 365 0 R 
/Next 363 0 R 
&gt;&gt; 
endobj
365 0 obj
&lt;&lt; 
/Title (²ú"0P“ºSf÷–wn&lt;)
/Dest [ 20 0 R /Fit ] 
/Parent 354 0 R 
/Prev 355 0 R 
/Next 364 0 R 
&gt;&gt; 
endobj
366 0 obj
&lt;&lt; 
/ProcSet [ /PDF /Text ] 
/Font &lt;&lt; /F5 368 0 R /F6 372 0 R /F7 375 0 R &gt;&gt; 
/ExtGState &lt;&lt; /GS1 378 0 R /GS2 377 0 R &gt;&gt; 
&gt;&gt; 
endobj
367 0 obj
&lt;&lt; 
/Type /FontDescriptor 
/Ascent 0 
/CapHeight 0 
/Descent 0 
/Flags 4 
/FontBBox [ -146 -274 1207 909 ] 
/FontName /HDDGLC+MSTT31c6b7 
/ItalicAngle 0 
/StemV 0 
/CharSet (ì»µ”±ßhZ\)0UŠ	wå*‹*Àá&nbsp;|B¬=ŠÉš¬b_Øö1ÈÖ2a¼-Sè�bœ”¿r«áÞ„’nòj"<tøþ˜Ì\ ¬ØtrùÇ;f[û<="" {²h[r)="" fontfile="" 369="" 0="" r="">&gt; 
endobj
368 0 obj
&lt;&lt; 
/Type /Font 
/Subtype /Type1 
/Name /F5 
/FirstChar 31 
/LastChar 255 
/Widths [ 750 260 320 380 520 520 900 740 220 440 440 500 520 260 333 260 580 
556 556 556 556 556 556 556 556 556 556 260 260 520 520 520 400 
820 660 640 680 740 620 540 740 820 360 340 660 620 880 760 820 
580 800 660 520 660 780 640 900 740 520 600 440 260 440 520 500 
360 556 556 556 611 500 444 611 667 333 333 556 500 722 611 611 
500 611 556 444 556 611 556 778 611 556 500 280 260 280 520 750 
750 750 300 520 400 1000 500 500 420 1300 520 320 1000 750 750 750 
750 300 300 400 400 460 556 1000 420 980 444 320 833 880 750 520 
750 320 520 520 611 520 260 500 380 740 340 480 520 750 740 400 
400 520 312 312 360 580 600 320 300 312 360 480 780 780 780 400 
660 660 660 660 660 660 880 680 620 620 620 620 360 360 390 370 
740 760 820 820 820 820 820 520 820 780 780 780 780 520 580 888 
556 556 556 556 556 556 722 556 500 500 500 500 347 347 377 357 
611 611 611 611 611 611 611 520 611 611 611 611 611 556 500 556 
] 
/Encoding 370 0 R 
/BaseFont /HDDGLC+MSTT31c6b7 
/FontDescriptor 367 0 R 
&gt;&gt; 
endobj
369 0 obj
&lt;&lt; /Length 10526 /Length1 4144 /Length2 6380 /Length3 0 &gt;&gt; 
stream
zv¥gjQkÜuùxúõüó½�ÕñQÇ9;Õê¡ƒÀÉd¾Ñ®ôQÛçFeœ5íNRAžW!evÔ=Ë½ý™îžÍ8g(XmØpJe*åº0bÝæÆ¡]ó�úqÐÁÊ©OíiÂåt/x�Ò¿ÖUÑS3P¸43G`œŽZŽBª„zïùÖ§¶«X™Åe3?»¹ÏébÃè¦sQŒ–«;îWßê¾ý„ÆaçXOˆn&amp;7¸}ÃŠÈ�Æ³ed½‚$/´ñ?þ2ÿÓ#øKˆÖl%Ù“—0ñ‡ €Eê„†4áN-.‚ÑJHÊr	Ž×+«2¦wDqV/{±gp“™|Mú:4µ$�”yC¿¹
•ÞžœN:sâ-Ú¹(}4,O™�Ù€¡í½MMùcƒÂ–¯­.N¥UwîÈ#G‹©šÕÜ­Š�)~D<a€â-ÑÔší³’È¯=¬Éky÷Ãßm~•‚ 7µl¥”÷á’dï*§yc="" $="">�»‰NHÞVý×ÙpW{5 ÞCžYìg6´Ì�9BUÐñ1Ë^t^8ûªøo#žÞv“–†mEK["ˆ03IBè3F÷Éº ŒB°È:ô•\ˆ÷Gñx?½(Å’=c×ø†Ÿ$h‡ò0KÄqÛÍ°·Ú‘<a}×¨¦’mÑ2uýúsþã¶µf”�[g` dØhhœmí×¹Ä”Žýçfç’Ž’“g›‹%†�ËiÓí="" f{¹õûâð*¾o¶¡e�u©o‚‰Ïß="" %hÌ8ìr1³1<ÁÑ_?dqï½×°˜âÞ%»bb="" œll4beb="A§#Æ‘ìŠá°Fr×i1€" l‰²[r½$ï¨ð*lîn(0vq„Ý="" Ý�="" 5ºð²¢¤m}_‡pü&8r¡äÿu©)›r“boÏ%¶tÀpkÇr$e!óp¾éj”��.\˜þÏÎÌdå$«båý+��'b…wvÎØ.ºõ b£jt3mñ»-}ø¹¤é–Ývoàéƒg¡ìiõ*h0-n¬býá*cÀÍá›®á\="">ÔÅ¨
‚°ôæ‰Ä¦Š¬‡ìäóËp¯;tPÿúÿ$	ÿrëK[Õeœ15X&nbsp;Ñ—åûê	‘3º(uÕ•ÙÛ¯.W6¤Å3r®êÞí´&nbsp;MQtêã}ñ|µ²ÔSùòP^°êéËuÿi•”‚ï¼�Ë‘Ý[Í_Ký@¾Onj³ûö
Ç	âƒ
`IRùÁY…µlt‰¼õ;�(QAr­èz¹LÇœµ.:Ô�#@+‰71.�pU¤ØÄy
D|ÕˆÝ)ÛŸ¸ýáv»ƒo´{œs^áœ,:ïË£óéqžËJ4t¯Dp³ÐzzÑ8þ›+Vpó‘lºÓ±#Q¾Ø¬ªC©ºƒÉ«€{³¶&nbsp;c\tÇ6�OÍ¸A�ÇbXöÃ&amp;4¢­3)³1Ëì\hçÃ|£:’G?£¡¬:zrL{µ¹zÕ÷|b}Oƒ`(uš7êø0s!Ñø ¼Ne�8Ìütr|LYtc”ü†‡}Ñÿ$'Í?XÓœ&nbsp;f/¨•39
PÃál²®sY”0—�2xøZ*úÝÏêt°S?ê2•=¦bAPMóïtØÀªÁìµ¼™à}ZyÙ@	ÕD°—ÚhÄ©Í÷µÇ&gt;9²”0¼çáãB»Ûzû�‹L¾&amp;ãæjÂ¥L–1»#²=çsv)érÁb8A(jóO�o1L‹*Ì*âÃ
¨Ñý—ô”õq7™Ã�Q‰Â`“6Ù-óû/w¯-meèL�´\]
‹c’"øGÇw[®†#úr¯7 ŸFÂ·§°ŸCÀç´§
X¢+F£ŒKôxœŒcye�æÖÖÛ€õ&nbsp;Ã–˜š®[ø
}¿
N5åù?wúmÔ&amp;UZvfc¼“d¼š´ÖÁÕyÝ¥#b¥ôhÑéöÖš]�&amp;QóÞ¸tÄ�*Vù\ÿ~#BÿÛñeóÙuˆ/gÃØ2báwP¿,mÙ¦¥«õ)ã™‰™}°YWó¨ÞP`rÝN½¡ÎVè¸c}'œUà­&gt;?2G�±HÎh¸º¬x’6»î9ÏºÉÐØÓê=ø=ØR'ý‚7¨°}s;mÀ:ÿïp°6…!¬np‰·»Â¼7_ê»-ær?]«tí%I¡8òWÇðf¯?Zö++vÇo#Ò2¼±3Ùú×UP_XkÊGæ¨]8„ÈÞDTœý&amp;˜ðï³{Ô[_²�”‰Å%Z4Y†òvÛØãWááá„¿Œ‡kß(–×\�&nbsp;Ó&lt;¢c.æUp	YíÄª4æ¤g»¥�º%ö?UžÖ´Iõ§7²ø«{xÓóõˆxQ8L†™ÝÑìˆF~•TbÈÚf¥TGKoc	1Q$¯¾iÄFXÏ½¡øiÆÃZMÊ™õõh`3‰Ã}~}&nbsp;)â‡Žáåg¿ƒ«“ÁËÏÊŸ,«“–Ô&nbsp;5$Øe„w‚)î©'Íq‡WÌœìæLÒÅ8Î…6±¾¥6{f¾C&amp;l€@'´%LºJëº&lt;Ç8{;ÏÌ¶à5�\„_öotÝœNxí9NŒTNøÓ‚YVqN¥‰Â³'÷‹‘	€f¸Cù­¸‰Î{)À­ªã^vO/=0”º÷Å£VòŒÜ½þÇv4µÒO9Ôž„Qaœ%0t|'³]±Ý¥
åîSÛÞ9W^ì|�KwAKôpZ—ÚŽÒç.Ÿ@®[;œªc{e]`·h;ïý(¼ËTpÏí¾”éÉ.ïlŒšÖî3%@ö¥n¡Niƒ¦rg\¿°&lt;¥&gt;\î‚RðÆ?ÒO’×ôm“Å‚Þ»ûxæFX·áÛþ0ØË¬ûu5îîlPÁp:�ÖòsŽ#€¹žgv»ÞR—â¯”{È�	ÿ„O˜òþñŒ+i“Ú&nbsp;aJÙ¢aæ@¯ì-zØ ¬”`Úû˜Ã»§vñª¼ ;p9ý”¾!æ¡«Þ”9²&gt;&lt;Nž²Dc^Ìç7òÒý B€³§'×Ýš¬±�5Ã}I©ö¸gWªe´ÀÔââBùˆôç•o¾‘¸åw,TJlY¶�ŠS†×§ÄS/çÇµ-»PÏó¬T¥ÜäåÐÚômüçd›}_öû`$N;_l;Í�€ COH(WÃˆÙ»
¯ºzÒö/¦ç¦P®ð"z#oÈÅŒuà-K—AøXÁ�¿®SàB˜YÅDmŒþƒCÅ/‹Áp¶vø€qã¹ÔPsš3(‹Pïñ+LÒv7W¦&lt;Ô!¶²á+Áw{ml°Pç®r@nsuuTg°ÅHì0ÞG¸¬E/:|Ì�ûÀgGEl=²ìÑQÇF5_ô`Ct˜L&amp;r×ŠàÛãN¨çßIôÙ¯ÎÑÔrDì·³ütr6H›W³©á5Py†¸)´ FFdúøµê¤ö¿¼Ís&amp;XAÖÖ±\Ì6æ¬Ub:iÈ_1œ·´mb;½Šq•ñîË¯Í»8Í9ÊfKÅ³×[u&amp;âÛnª¦&amp;Ë"é¢õB·�˜ïuŸø©EîŸaà8qëÊ	ãíø*¿&lt;Ï *‹´fS15÷î¨©:â©Å¦-3öÈù´�ñEãÓ�A½}šd
Î™Òü= RGW?ÖUì˜U¿»²áŠÊNÇ…�(á­}b¢/WnT	Ï_DgòÝûnÌ¡”/EŒaç¢êÆV`�rø„BšOî|ŠÚ­TàìšÜyá‰»PPáûË £?T’Í¡CÊðs¡µì5x†y×�ñæáÜÏ_'§L´Ãx-(§�U&nbsp;bû[ír&gt;Co™»†j²	Býúç†íO,ô×‰²¬Œ•‰È�—T&nbsp;SæÂÖý²'‘|ã[0}&gt;vE&nbsp;âÐÚa†7LÉtàù0ÒÄH6nx×”ŒÚ¦E…è„žßÍC�³ˆ#”lÇ4ç&nbsp;}ÏG=x=í'´æ#árýÕtƒ,‚ÔÃŸp;¹ïÚrf¶Å[Î¡ÕH?”‚-ê'Ì¦ÜX¶Á-é‡dìõžIV
[�±	ƒ5Úñ¾d&lt;ÆŽž·L/î9þSGæOŒq;«T^�…œå�@¶x•ââñäïŸxœ0ë³­'ƒXòOaÐð‰³´+š“
®ˆ[ˆø;igV`Ôz}á±„n&gt;Éõ&gt;â¬@‚ù‡ç(ÏNwSF~›¨H¶;P’ñˆî´Õç)b½øG–�—ÂU–ÀQ/§Ð^Û¼d„vÚË–N?7½ùj¤‰Îï¼Y
kG–ˆ½À“ÊBÆç€EC`ÙîŸ?.„þù5âêEÉé&lt;¦Hªþ^øÔ!µÎÛe19ü,âlÝœITw sPÇFí�=µœÍ?Rn'Ds‡vK‹7m^„Ù¿p–ŒÑX
ÉÎb§R&nbsp;%ì))åðà gF©_¿Ðþ9ÌCÖúWGÂ@¹!~Ýã}rÂK÷¢Öµs5e[þIBn-É3ú*AUIž­±Š]�#l81nfŸc)ôLß¡g�
ˆ¼£¯FŠ\¸Ç^ïÒ¬�wÌ—0;öÑêä§GEóÓ"Ë³fó
øX*`‰{ˆÌB«3ÝŠmX¨&amp;ñþ·mÕŠ²©š]ºì�Ëó üˆqXi’“çñ(†aÜ
@0ö�.Díz«+êŒœ'µqX]&gt;�8óšª¤r(¤�ßW(¢eã‹‡‚YA,±õ/É–�hizjGž�,m.×Üˆ¯.Y+„nÈT‚7þp¯:|Goª‡­
‹X°¨‡Zø6&amp;L²×ú#Ÿ­Ÿí §sØ&nbsp;žä½×ùÃ
ÕJW$ç
8aY&nbsp;”†êkÿ²X=­ïIrd¯€ÃËÊ¤ž˜.•ÿä¶‹g™$Š^«&lt;Þø¥Ÿ•*ˆÐxEødèriR5YÖÏi‘+âÔ«x‰¶\®ÓÅ{
ŸîVå?B‡�&lt;ë] ëËî:Xå$÷SBáKN[F�¬ê¬è=C…‚³NƒO(ÞåÐPW&amp;ƒÃâ}Ã8wž¸3éJI”×9G#8NmW„ª±iI‰ûœÏ¤$ÍïNgr11§8‘É
îÐ–ÿ¹lžG­ƒÚËÔ3\x—HSâx˜ð"S…�á4@Wâ’•Ì@Õ(jE„ª
dã{8·2œŒþVŒÍð9q¬�ÏOtÅfyš%ÜpL\Öb±Õ„¥Ú™Žzåmí~þí¡Ö78R�âªË‹ÐÉúýÊ¨%&gt;L²È¶Õ™Žl–ý~ö
Ž\Å“#SöläQáù@z9ÒvÃ°�FZÕâU†“ç†c%†=þEdµ;¨£ÚCó•¥sf7OŒC�‹Û€€¾rqÁ([ü±‡X\•[Z›õmUõŸæîwk4³†	]?ÿY_áŠÀéj&amp;¬UáÃ(dW‡f¿%V†G"{ÏÛUdÑ×„W¿À„¡c&lt;•ˆUW.ùÂ<wemj%º‹Ü#‡øÚ\þf�Ïbàn…Ìçzq.hÚaŠš¸Ž+‚¦«Ú%¯ˆ¿’�i*‘¸ïžÇßrß†í£Ê²¦>#OZy?ªD½qÝfK¼cŸlÔ'åGÑºýõ‚Å-x²´ÎZGr—ôé‚÷óÄé+?XÝ#_[¤ì½	Å„6üsl5
ð‰Œ÷±ÌÑ~ù»ñàvÂ3ûÕï�HT¹OöMùˆƒ¹eL¤Âl™Y«(ê‘3mðbBO)Ï˜ø
æÍYb–&lt;î~óÖ¿x¡°S�ƒ
2âQÛTM±áÂæð¸¢Õÿ_:nºðÜ9ÒVŽA¨6¸&gt;ó½�h�H6¹™Ô±A²7NÕ¥žäæ|�Ìû.€rlêMsÐ•�läÛ(f0Û0Œ^€ªö·�¥áûsnÁ\._àñløÈ.�Qò¬à=e‘i¯Ä$Û½ÞN‘wIKÛ³”“ä›|iŽ1?ÆØÂ!n…øú¬ƒÁ(Iè ¶IÞ�'ÓîýêàCãþÜY€VÔ(œ,JV°ý�ÙYšWbÅé§»3?!äà”Òè5…ÕÍ…z?ï,GÀ°]úä±®+¨gùFÙ¿€qÝÐg¯Xç`ñý‘H|žZóëNGòŒ@×nù�ë!(Bå‚{XÊ(!‡ŽXó§ï$c[P$ßb¨Û/!lyîH�âi€1˜´NAbËåt;êN‘§éÐö`ô
Îj•ÓŽŠ¬SüËÜŸŽur!!«�)Sß£¹y¢¾i±iŽG³ŸÐwW×CµˆSc¬;ð–7íB-™“¢^ÂÈ ‚«O
{wã½„J§×üøŒó¤9�ZæÉb8£\‡Ï±™—¼^kO;YU,‚/ª°Xå¼ÌD‰+¼˜Àý¥&amp;q™&lt;1V&nbsp;Bhû3Ê… EùI®¨�±’gÐxeÚƒxK‡Ž^�«Cé¸q9WËñ§X["(ÓbQ·bÐs€4ûZ…º±Þžì»ëûU%*�nºi½&lt;Á®†·Gô»W†öõP‹³^¡9È¤K¯œ˜FCÒÏgó*s²ÁFç+ÒÍ°Pôe#÷a8›1òêOöë=ÕZÂ›Žw?¿Ò"™´f¤¼¿ƒÙ&nbsp;…â&gt;¾–Ly¨›¥˜Úýœ§sh¨?’9Þ×¤ƒ(ÕúfB�¬S×ùÉÏÍÞ„‚$Á�)Ø:&amp;…‰1oÛXÑÖ±òÜÂÇNï
œ±�þµðaØŽ`öâôãLò›Ñ�i„täj?Â�RBUF7+à%žÕ	î@š­ÌãBºšæ‚&amp;"À‹f&amp;ýµlÀ²MÓd-)nÐÅïWèùf[¨Ëä¤„…K!ê›Î =›s(æäæ¢ŽhZ?°àê,ˆOè]Ìé_YÝùäÙÉôÏ«X#«=Ãig‘Â8U³Èg~¸Y’þ•hx1Q6P!§}âj³)ÿÀzÐwÒÛG
&gt;\oÔ$
S�€´¾^ÔMmPÍjqË|QoÄ°áÒp£¡ÑVqAÑ—Ü)

˜eù)­€5¯£€�zè\^…ìýš3ãì*Á¹îí!]Oó„3Š9Ó^àø55È„È“—×¶t™R@„¯Ä®¦uŒéÖwÈV4,ª£Éœlïá)U[J¤Ù;aÑn�H‰Ž
y&lt;£«¹rÜû2ø�k4z®‚¢+¶¿&nbsp;èØñX×žÏ—Kÿe“zvIU­›»ÓaÕ&lt;Ô3®ÜÞæŸ|ÏvE€e&nbsp;]Ö1ú¨HÆÄ^êÄÐ\¥v™E=üPM&lt;Æé’ÉÅi¯„êœ1Ù,t‘rê0iìIø}âsI¦¤N|÷2˜è]€T½3;Ùã`{amPcÞád€ÏT˜N%&amp;Ô×G	¿ýHÍU~=@‚vœ0”9qØ@ˆ}ÆÐ­H°õfÞ—º‰ç½µúIiKØf�mOW¿“�ãì,lÁ¦¡S.C"bx*ú¥j}º–å›Vj¶´Ô§G@–]˜•5â£,³ü&nbsp;ºPÖ�GÉè"Ê�Àxó¯_d`�Á�Vtý¶&lt;ÛYýø,µ80ÖÔ§yœÓE5“v©4Œˆ_©—Œž¬ü¨÷l±2&lt;‡˜ÛÔ•Á„�&amp;�àÏ²‡u'ÖÍ\ü¥Ü.?àðšñ}ølá©¼#�·S‹enê2õo­Û«ïå`é—‡°,ËMµ�
¢T�ŽS“Ä9œæ¥£ôÐÎ–ÂMøèßb�6üú”fr3Á ÓYc�d£b¥•à±LŽ$«Æ†ˆ7ôQ³à�OU–uÕó7Neÿ*ókâØÅÿ`×©¿‘öÇxñtøpfã+Ýv'“^¥œ�èµìF
»~È9Þguq`ø™ü9î-BÉè³qâ¡Ì%h-Ûn…JF_¦[£Èw¥`&lt;\U.lÞZ´!(‡€âÙ²ÛDZ0®´*§ë›&nbsp;ÞÚ–še¡Õ"ÁÐy¥§~§TÒÅlÇ0SüxÄsG�8®�SS*5çó;†2JT»Ø‘UB&amp;f|î<púß¶¿93žg”tÏö|nº•×4|¨zx+vÖ]‰´)c‘¼ât¬› ðuÒ¥ãlà×‡j<¤îh="" ·^káqµt€èb}+lÑ©_="" ÍÃÈx‚¥þ£2üo0¦hc0«Ëô·z£="" e3©nt±”ÀÄlsq ¾l3§›š6k^Ü:ƒûìi…É"ü6ù×'¯c×Í®<p4Žêxspez1@¼¿²ÑÓ‚°âdàØiÐe¾À«»ˆlå†)–~ÛhgËf›@ºÏ°fãp†f="" %Ä2µk5aùÔi9nÀ"~ŸÄ­9}gqçz]%Çô±!15zvŸô-ezr)Æóiè:•còñ¾j3Ô%h="" ã�\à8îv¼›¦©“v§òñ‘“•~="" Ê6Ð="" mtft03="" i:¡‹ÿh¬akêt*& ="" {�ÕªÚôùù="" ·£Æ(ìÖ9üük#ðïŠwobi±l�(Ðœ?ñêˆ—Ôsq¡-r˜xÃ‹px%÷‰v}¼5‹•¡‹ùû„¸Ûho-¤ï„¢ÿŒÙuáe©øþ‰¤a`,a€m7ªi–rÛ÷�fez¬Ð…k.}sñÁ’¥8²�Óo'é?]?,¥-áºaÕ´vòfj�¼žÆÆ6_Ãé(u!ù3guùåólücr)3žzø59à�°6$øâ’ïÕ©§4ñÆhsñ‰�oµ»noÆ2="�ŒiêR‡#ÆµYª+hQJwCçBy/A´H&nbsp;Â" q¥u"„‹øé:c�ÆÑwòqx1p°?Ð+©™æx²�b|Üf="ŽªÄ²,q`”Õba}n•ñ|yŸYó;íÆÔEB­¿á�é¶L§’’8HÑÜÑµò‘jÎ�g­µLŒ&nbsp;¾`™Mºªhw™õò•·šÅæwT—†³Î�»R]3ºî�²Îúè/|‰°ˆ§vr1û£6ÎB¸´<<™»°ãLˆöˆ�×çS1·6ø!¼ñ—›" šv="">Í€½±1¨T5w¤Ò4öªV¶-_;­_÷üÀ¢càCò9V8äÈ‹Éw�àµ¦u1ÐCÒÍªþ3N†Üoˆ@#�ÙÈªÖ%ÎO¥ˆ¹
c?ÿOl2t¨»(–˜°1#*«QqÈ&gt;ä«ÇJø¸ƒJ¦SÝþùcåpÿ–Ãà�•ÓÎ-ÀŽ¢Ê”ÓF¥0Båò0¬ì&nbsp;/‡U�d"žŸéPebFX)ÞXx&amp;¢¤Ñh›ç&gt;PÌƒž³))ŒÚ÷`R&gt;†j=çtQå~Â;b£Ò{îyÊUÆ­+:mLbzi8…‘°AÙ~‰“OñËÿV½ooB•cQ­¾ÆRÞöÊ°/tI�­ü¹¹³ü
ç:Â;)û§{¡€RsÙ÷aß"Õ+¹I¼O#…Eº&nbsp;¯€*¦rudêdI/ÁÿØ†¿ößuÏ�!w†U2×Ì—`§ëgúÑv¿]¢&lt;+ÑrCË}É{‹	&gt;‚ýT¾I)¦E9Å®Tvý�ëÙ‰øÃó§¸@Yþù!¨Ø:n~H~ÜÖ3-£ýOL.-‡@}f„* ¹b2J6HyŠGHOª}É½«±à¬œ¤8RB°"úâ6zµNÖiu%eœM×uGŒåÅôµ‹p=£j²ö»_È°/_Œé oGªßFo_–HÑR1Ò€yNlê÷•[úûk€‡KÓdÏèvuSÉØïâ^®À‰Akü‰"y£9ÃJ+ÚLùòóË.ú»ÐMèŸvŒû¾Ëö7zOKvròF½Š#PF:ñ[k"ˆ°_/¡ÅîÇßþþ-ò+u�®�F•sMa•	òVëØ¨úúB+WÛFšÙ;(Ô&amp;4"Hë4'uÃ4C&amp;hfqÎ½&gt;k†ŒÕ"áÃ^†W_o	—·Äñ.OÓ&amp;ƒáº–g-éHvs8CÖñfµB$�âÛ:H=OþãJ¹¦Éú,Òœ?=™SëélË†;ðFÁ’ªàì†µ 5(hN„;™™;;³Û•SJN”þêd²kõM[Dq=p‹Æ©Á‚�
,Nò�ùœÝ!m|´y}QƒLX¼V 
#Aµ½)7•&gt;˜Ý+xÀó:4&gt;ªìÜçå=Mãt~LIÓJ‡´’„M|›’¤*0±	ñCË»–†éFç4ÕˆPüâ¤(…7Õ›Ð«qäá~ìA‹“´÷8ƒôUê`P&gt;</púß¶¿93žg”tïö|nº•×4|¨zx+vö]‰´)c‘¼ât¬›></wemj%º‹ü#‡øú\þf�ïbàn…ìçzq.húašš¸ž+‚¦«ú%¯ˆ¿’�i*‘¸ïžçßrß†í£ê²¦></a}×¨¦’mñ2uýúsþã¶µf”�[g`></a€â-ñôší³’è¯=¬éky÷ãßm~•‚></tøþ˜ì\></v%aá£œps1�l`ôbä2[›;�></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://socialsciences.mcmaster.ca/econ/ugcm/3ll3/mill/liberty.pdf">https://socialsciences.mcmaster.ca/econ/ugcm/3ll3/mill/liberty.pdf</a></em></p>]]>
            </description>
            <link>https://socialsciences.mcmaster.ca/econ/ugcm/3ll3/mill/liberty.pdf</link>
            <guid isPermaLink="false">hacker-news-small-sites-23636407</guid>
            <pubDate>Thu, 25 Jun 2020 02:54:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to write PureScript react components to replace JavaScript]]>
            </title>
            <description>
<![CDATA[
Score 99 | Comments 72 (<a href="https://news.ycombinator.com/item?id=23636336">thread link</a>) | @JacksonGariety
<br/>
June 24, 2020 | https://thomashoneyman.com/articles/replace-react-components-with-purescript/ | <a href="https://web.archive.org/web/*/https://thomashoneyman.com/articles/replace-react-components-with-purescript/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  

  

<p>I have twice migrated large JavaScript apps to PureScript. At CitizenNet we replaced Angular with Halogen, and at Awake Security we’ve replaced most of a React application with PureScript React. Both companies have seen a dramatic drop in bugs in production.</p>

<p>It’s relatively easy to replace React due to PureScript’s <code>react</code> and <code>react-basic</code> libraries. The React mental model fits well with a strongly-typed, pure functional language like PureScript (or Reason), and using the same underlying library means that components can be shared between languages with little modification.</p>

<p>At Awake Security we share internationalization, a Redux store and middleware, and much more in an code base where PureScript regularly imports JavaScript and JavaScript regularly imports PureScript.</p>

<p>The best way to rewrite a significant app from one language to another is incrementally, while it runs. At first the new language can take over logically isolated parts of the app: the management dashboard, or the chat window, or a form. But eventually you must mix components from both languages together – for example, to support shared global state.</p>

<p>At this point you can’t just let the new language take over a DOM node. You need to support simple, clear features for intermixing the languages. Fortunately, you can transform the interface of idiomatic PureScript code into idiomatic JavaScript (and vice versa). With <code>react</code> and <code>react-basic</code> you can write business logic in PureScript but easily interoperating with the larger React ecosystem and your existing code.</p>

<p>In this article I will demonstrate how to replace part of a React application with simple components written in PureScript. Along the way, I’ll share best practices for making this interop convenient and dependable. The examples will be simple, but the same techniques also apply to complex components.</p>

<h4 id="sections">Sections</h4>

<ol>
<li><a href="#let-s-write-a-react-app-in-javascript">Write a tiny React application in JavaScript</a></li>
<li><a href="#setting-up-a-shared-purescript-javascript-project">Update the application to support PureScript</a></li>
<li><a href="#replacing-a-react-component-with-purescript-react">Replace a React component with PureScript React, with the same interface and behavior as the original</a></li>
<li><a href="#replacing-a-react-component-with-purescript-react-basic">Replace the component again with React Basic</a></li>
</ol>

<p>I encourage you to code along with this article; no code is omitted and dependencies are pinned to help ensure the examples are reproducible. This code uses Node <code>v11.1.0</code>, Yarn <code>v1.12.0</code>, and NPX <code>v6.5.0</code> installed globally, and PureScript tooling installed locally.</p>

<p>Peter Murphy has <a href="https://github.com/ptrfrncsmrph/purescript-react-tutorial">implemented the ideas in this article using React Hooks</a> if you’d like to see this in action.</p>




<h2 id="let-s-write-a-react-app-in-javascript">Let’s write a React app in JavaScript</h2>

<p>We are going to write a tiny React application which shows a few counters, and then we’re going to replace its components with PureScript. The resulting JavaScript code will be indistinguishable, aside from imports, from the original, and yet it will all be PureScript under the hood.</p>

<p>Let’s follow the official React docs in using <code>create-react-app</code> to initialize the project and then trim our source code to the bare minimum.</p>
<div><pre><code data-lang="sh"><span># Create the app</span>
npx create-react-app my-app <span>&amp;&amp;</span> <span>cd</span> my-app</code></pre></div>
<p>At the time of writing, <code>create-react-app</code> produces these React dependencies:</p>
<div><pre><code data-lang="json"><span>"dependencies"</span><span>:</span> <span>{</span>
    <span>"react"</span><span>:</span> <span>"^16.8.6"</span><span>,</span>
    <span>"react-dom"</span><span>:</span> <span>"^16.8.6"</span><span>,</span>
    <span>"react-scripts"</span><span>:</span> <span>"3.0.1"</span>
  <span>}</span></code></pre></div>
<p>We have a handful of source files under <code>src</code>, but our application will need just two of them: <code>index.js</code>, the entrypoint for Webpack, and <code>App.js</code>, the root component of our application. We can delete the rest:</p>
<div><pre><code data-lang="sh"><span># Delete all the source files except for the entrypoint and</span>
<span># root app component</span>
find src -type f -not <span>\(</span> -name <span>'index.js'</span> -or -name <span>'App.js'</span> <span>\)</span> -delete</code></pre></div>
<p>Finally, let’s replace the contents of those two files with the bare minimum we’ll need for this article. From here on out I’ll supply diffs that you can supply to <code>git apply</code> to apply the same changes I did.</p>

<p>First, our entrypoint:</p>
<div><pre><code data-lang="jsx"><span>// src/index.js
</span><span></span><span>import</span> <span>React</span> <span>from</span> <span>"react"</span><span>;</span>
<span>import</span> <span>ReactDOM</span> <span>from</span> <span>"react-dom"</span><span>;</span>
<span>import</span> <span>App</span> <span>from</span> <span>"./App"</span><span>;</span>

<span>ReactDOM</span><span>.</span><span>render</span><span>(&lt;</span><span>App</span> <span>/&gt;,</span> <span>document</span><span>.</span><span>getElementById</span><span>(</span><span>"root"</span><span>));</span></code></pre></div>
<p>Then our main app component:</p>
<div><pre><code data-lang="jsx"><span>// src/App.js
</span><span></span><span>import</span> <span>React</span> <span>from</span> <span>"react"</span><span>;</span>

<span>function</span> <span>App</span><span>()</span> <span>{</span>
  <span>return</span> <span>(</span>
    <span>&lt;</span><span>div</span><span>&gt;</span>
      <span>&lt;</span><span>h1</span><span>&gt;</span><span>My</span> <span>App</span><span>&lt;/</span><span>h1</span><span>&gt;</span>
    <span>&lt;/</span><span>div</span><span>&gt;</span>
  <span>);</span>
<span>}</span>

<span>export</span> <span>default</span> <span>App</span><span>;</span></code></pre></div>
<h3 id="writing-a-react-component">Writing a React component</h3>

<p>Let’s write our first React component: a counter. This is likely the first example of a React component you ever encountered; it’s the first example in the PureScript React libraries as well. It’s also small and simple enough to be replaced twice over the course of this article.</p>

<p>The counter will be a button which maintains the number of times it has been clicked. It will accept, as its only prop, a label to display on the button.</p>
<div><pre><code data-lang="jsx"><span>// src/Counter.js
</span><span></span><span>import</span> <span>React</span> <span>from</span> <span>"react"</span><span>;</span>

<span>class</span> <span>Counter</span> <span>extends</span> <span>React</span><span>.</span><span>Component</span> <span>{</span>
  <span>constructor</span><span>(</span><span>props</span><span>)</span> <span>{</span>
    <span>super</span><span>(</span><span>props</span><span>);</span>
    <span>this</span><span>.</span><span>state</span> <span>=</span> <span>{</span>
      <span>count</span><span>:</span> <span>0</span>
    <span>};</span>
  <span>}</span>

  <span>render</span><span>()</span> <span>{</span>
    <span>return</span> <span>(</span>
      <span>&lt;</span><span>button</span> <span>onClick</span><span>=</span><span>{()</span> <span>=</span><span>&gt;</span> <span>this</span><span>.</span><span>setState</span><span>({</span> <span>count</span><span>:</span> <span>this</span><span>.</span><span>state</span><span>.</span><span>count</span> <span>+</span> <span>1</span> <span>})}</span><span>&gt;</span>
        <span>{</span><span>this</span><span>.</span><span>props</span><span>.</span><span>label</span><span>}</span><span>:</span> <span>{</span><span>this</span><span>.</span><span>state</span><span>.</span><span>count</span><span>}</span>
      <span>&lt;/</span><span>button</span><span>&gt;</span>
    <span>);</span>
  <span>}</span>
<span>}</span>

<span>export</span> <span>default</span> <span>Counter</span><span>;</span></code></pre></div>
<p>Then, we’ll import our new counters into our main application:</p>
<div><pre><code data-lang="diff"><span>--- a/src/App.js
</span><span></span><span>+++ b/src/App.js
</span><span></span><span>@@ -1,9 +1,13 @@
</span><span></span> import React from "react";
<span>+import Counter from "./Counter";
</span><span></span>
 function App() {
   return (
     &lt;div&gt;
       &lt;h1&gt;My App&lt;/h1&gt;
<span>+      &lt;Counter label="Count" /&gt;
</span><span>+      &lt;Counter label="Clicks" /&gt;
</span><span>+      &lt;Counter label="Interactions" /&gt;
</span><span></span>     &lt;/div&gt;
   );
 }
</code></pre></div>
<p>With <code>yarn start</code> we can run the dev server and see our app in action.</p>

<p><img src="https://thomashoneyman.com/images/2019/running-app.gif" alt="running app"></p>



<p>We’ve written entirely too much JavaScript. Let’s support PureScript in this project as well. Our goal is to write code in either language and freely import in either direction without friction. To accomplish that, we will install PureScript tooling, create a separate PureScript source directory, and rely on the compiler to generate JavaScript code.</p>

<h3 id="1-install-the-compiler-and-package-manager">1. Install the compiler and package manager</h3>

<p>First we must install PureScript tooling. I recommend installing versions of the compiler and Spago (a package manager and build tool) which match those used in this article. I’ll use NPX to ensure all commands are run using local copies.</p>
<div><pre><code data-lang="sh"><span># Install the compiler and the Spago package manager however you prefer;</span>
<span># since we're already in a React project I'll use Yarn</span>
yarn add -D purescript@0.13.2 spago@0.8.4</code></pre></div>
<h3 id="2-initialize-the-project-and-package-set">2. Initialize the project and package set</h3>

<p>We can create a new PureScript project with <code>spago init</code>. As of version 0.8.4, Spago always initializes with the same package set, which means you should have identical package versions to those used to write this article. I’m using the <code>psc-0.13.0-20190607</code> package set.</p>
<div><pre><code data-lang="sh"><span># npx ensures we're using our local copy of Spago installed in node_modules.</span>
npx spago init</code></pre></div>
<p>Spago has created a <code>packages.dhall</code> file which points at the set of packages which can be installed and a <code>spago.dhall</code> file which lists the packages we’ve actually installed. We can now install any dependencies we need and we’ll know for sure the versions are all compatible.</p>

<p>Before installing anything, let’s update the existing <code>.gitignore</code> file to cover PureScript. For a Spago-based project this will work:</p>
<div><pre><code data-lang="sh"><span>echo</span> -e <span>"\noutput\n.psc*\n.purs*\.spago"</span> &gt;&gt; .gitignore</code></pre></div>
<h3 id="3-adjust-the-directory-structure">3. Adjust the directory structure</h3>

<p>Finally, let’s organize our source code. It’s typical to separate JavaScript source from PureScript source except when writing an FFI file for PureScript. Since we aren’t doing that in this project, our source files will be entirely separated. Let’s move all JavaScript code into a <code>javascript</code> subdirectory and create a new <code>purescript</code> folder next to it.</p>
<div><pre><code data-lang="sh">mkdir src/javascript src/purescript
mv src/App.js src/Counter.js src/javascript</code></pre></div>
<p>Next, we’ll adjust <code>index.js</code> to the new location of our root component:</p>
<div><pre><code data-lang="diff"><span>--- a/src/index.js
</span><span></span><span>+++ b/src/index.js
</span><span></span><span>@@ -1,5 +1,5 @@
</span><span></span> import React from "react";
 import ReactDOM from "react-dom";
<span>-import App from "./App";
</span><span></span><span>+import App from "./javascript/App";
</span><span></span>
 ReactDOM.render(&lt;App /&gt;, document.getElementById("root"));
</code></pre></div>
<p>We’ve just one task left. The PureScript compiler generates JavaScript into a directory named <code>output</code> in the root of the project. But <code>create-react-app</code> disables importing anything outside the <code>src</code> directory. While there are fancier solutions, for this project we’ll get around the restriction by symlinking the <code>output</code> directory into the <code>src</code> directory.</p>
<div><pre><code data-lang="sh"><span># we can now import compiled PureScript from src/output/...</span>
ln -s <span>$PWD</span>/output <span>$PWD</span>/src</code></pre></div>
<p>Your <code>src</code> directory should now look like this:</p>
<div><pre><code data-lang="sh">src
├── index.js
├── javascript
│ ├── App.js
│ └── Counter.js
├── output -&gt; ../output
└── purescript</code></pre></div>
<h2 id="replacing-a-react-component-with-purescript-react">Replacing a React component with PureScript React</h2>

<p>I like to follow four simple steps when replacing a JavaScript React component with a PureScript one:</p>

<ol>
<li>Write the component in idiomatic PureScript.</li>
<li>Write a separate interop module for the component. This module provides the JavaScript interface and conversion functions between PureScript and JavaScript types and idioms.</li>
<li>Use the PureScript compiler to generate JavaScript</li>
<li>Import the resulting code as if it were a regular JavaScript React component.</li>
</ol>

<p>We’ll start with the <code>react</code> library, which we use at Awake Security. It’s similar to <code>react-basic</code> but maps more directly to the underlying React code and is less opinionated. Later, we’ll switch to <code>react-basic</code>, which will demonstrate some differences between them.</p>

<p>As we take each step in this process I’ll explain more about why it’s necessary and some best practices to keep in mind. Let’s start: install the <code>react</code> library and prepare to write our component:</p>
<div><pre><code data-lang="sh"><span># install the purescript-react library</span>
npx spago install react

<span># build the project so editors can pick up the `output` directory</span>
npx spago build

<span># create the component source file</span>
touch src/purescript/Counter.purs</code></pre></div>
<h3 id="1-write-the-react-component-in-idiomatic-purescript">1. Write the React component in idiomatic PureScript</h3>

<p>Even though we are writing a component to be used from JavaScript, we should still write ordinary PureScript. As we’ll soon see, it’s possible to adjust only the interface of the component for JavaScript but leave the internals untouched. This is especially important if this component is meant to be used by both PureScript and …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://thomashoneyman.com/articles/replace-react-components-with-purescript/">https://thomashoneyman.com/articles/replace-react-components-with-purescript/</a></em></p>]]>
            </description>
            <link>https://thomashoneyman.com/articles/replace-react-components-with-purescript/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23636336</guid>
            <pubDate>Thu, 25 Jun 2020 02:40:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Stop Sabotaging Your Career with Short Stints]]>
            </title>
            <description>
<![CDATA[
Score 27 | Comments 29 (<a href="https://news.ycombinator.com/item?id=23636077">thread link</a>) | @gmays
<br/>
June 24, 2020 | https://staysaasy.com/engineering/2020/06/16/Stop-Sabotaging.html | <a href="https://web.archive.org/web/*/https://staysaasy.com/engineering/2020/06/16/Stop-Sabotaging.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p>Life before a software engineering career is commonly a series of time-bound efforts to gain competency in a new area. This semester you learn geometry. That semester you learn history. Next semester you learn calculus. And so on.</p>

<p>As a result, most people entering the software engineering workforce equate learning with learning a brand new topic. I didn’t know ruby, I learned ruby. I didn’t know SQL, now I know SQL.</p>

<p>This kind of thinking leads people to 2 year cycles. On most modern software teams, it takes roughly one year to really feel like you have your feet under you. By that time the kind of learning novelty people are used to isn’t there. By 16 months they’re restless. By 24 months they’re gone.</p>

<p>This is a problem. It’s a problem because the majority of durable and transferable knowledge comes after achieving basic competency. Mastery of a skillset, understanding and learning from the outcomes of decisions made years ago, architecture and design, leading projects - these all come well after basic competency.</p>

<p>Not only does a life of cyclic learning work against reaching these next levels, but your ego and willpower also work against you. Those next-level skills are harder to learn. And once you’ve gained competency you lose the excuse of “I’m onboarding” or “still ramping up” when something goes wrong.</p>

<p>I always challenge engineers that want to make big changes in what they’re working on to consider whether they’re simply at the end of a novelty cycle. I always encourage them to go after those next level skills.</p>

<p>On the hiring front, I see a lot of people who have a career’s worth of 2-year stints. You can do that successfully for an entire career, and there are even some people that’ll tell you it’s a way to optimize earnings over time. If it does, I believe it only optimizes earnings for people who can’t get to those next level skills. The biggest earnings come from building and growing with a winning company.</p>

<p>24-monthers never deeply learn how things work. They’ll typically add value to a new company by carrying a collection of things they’ve seen before and shallowly applying them to similar problems. But when faced with a new problem that doesn’t map easily to the solutions they’ve seen, things start to break down.</p>

<p>The end-games for both careers are very different.</p>

<p>24-monthers eventually can get into C-level positions where it’s not uncommon to bring in someone who can just apply the common solutions to the similar task at hand. Their stints usually end right around the time where they’ve upleveled the company in some way and don’t know how to grow their team or evolve their strategy or deal with the short-comings of some of their decisions.</p>

<p>People who learn next level skills and how to deeply understand and react to the tasks at hand lead companies to uniquely successful outcomes. The best CEOs, the best CTOs, the best C-level anything - their careers are often a small handful of long-duration roles where they didn’t apply rote practices but innovated and reacted to change and created novel solutions based on deep understanding.</p>

<h2 id="conclusion">Conclusion</h2>

<p>I’m not saying you should stay with any given job. There are bad roles and bad bosses and everything in between. And skill diversification is important. But every job has problems. If you’re leaving because you’re chasing novelty or avoiding tackling your company’s challenges, you’ll start over in the cycle. Leave enough places for these reasons and you’ll find you’ve seriously limited your opportunities and earnings over time.</p>


    




  </div></div>]]>
            </description>
            <link>https://staysaasy.com/engineering/2020/06/16/Stop-Sabotaging.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23636077</guid>
            <pubDate>Thu, 25 Jun 2020 01:59:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I deleted my Facebook, WhatsApp, and Instagram accounts, and felt great since]]>
            </title>
            <description>
<![CDATA[
Score 414 | Comments 228 (<a href="https://news.ycombinator.com/item?id=23634788">thread link</a>) | @shog_hn
<br/>
June 24, 2020 | https://www.shogan.co.uk/life/how-i-deleted-my-facebook-whatsapp-and-instagram-accounts-and-felt-great-since/ | <a href="https://web.archive.org/web/*/https://www.shogan.co.uk/life/how-i-deleted-my-facebook-whatsapp-and-instagram-accounts-and-felt-great-since/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-2503">
	<!-- .entry-header -->

	<div>
		
<blockquote><p>I estimate that over the last 3 years, I’ve collectively <strong>saved around 2920 hours</strong> of time that would have otherwise been spent mindless scrolling through mostly uninteresting content.</p></blockquote>



<h2>The human problem</h2>



<p>It started with an urge to delete Facebook around 3 years ago.</p>



<p>I had noticed how Facebook was mostly just a highly filtered stream of content. Everyone’s happy thoughts and high moments in life, delivered to me in an algorithmically curated form.</p>



<p>I was part of the problem too. I posted things I was proud of, or the happy moments in my life. Very rarely anything else.</p>



<p>Facebook is for the most part, just a small, narrowly defined window into people’s lives.</p>



<p>We see the full picture of our own lives, but end up comparing what we have to this small, ‘happy’ slither of other people’s lives.</p>



<p>For those who don’t notice this unfair comparison, it can lead to moments of envy, anger, or even depression.</p>



<p>Don’t forget about the fake news, agendas, and other drivel that is posted around Facebook either. Scrolling through this kind of stuff on a daily basis will numb the mind and lead to one becoming complacant and perhaps even completely mislead.</p>



<p>One only has to look at how entire countries have been divided and swayed by lies posted to social media platforms to see how poisonous they can be.</p>



<p>The poison runs broad and deep on these platforms. There are many bad actors that wreak havoc, from state sponsored, to criminals and scam artists. They all have agendas to propagate, or nefarious goals to accomplish.</p>



<h2>The data problem</h2>



<p>The number one question to ask yourself whenever signing up for a ‘free’ account of any type is “<strong>Why is this free?</strong>“</p>



<p>A free product, is <a href="https://fee.org/articles/the-hidden-costs-of-free-social-media/" target="_blank" rel="noreferrer noopener" aria-label="not really free (opens in a new tab)">not really free</a>. There is always a catch. In the case of Facebook, you are paying with your own data.</p>



<p>Your own private life, details, habits, information and more is being collected in the background and used to make money for Facebook. They sell your data, and you pay with your privacy.</p>



<h2>Deleting Facebook</h2>



<p>As I mentioned at the start of this post, the urge to delete Facebook began around 3 years ago. It took me year of thinking about it before I took the plunge.</p>



<p>I exported all of my data as a .zip file, and uploaded it to some encrypted cloud storage for safe keeping.</p>



<p>Then I logged in, went to my account settings and requested that my account and data be deleted.</p>



<p>Facebook leaves your account in a ‘to be deleted’ state. They say that if you login again in the next week or so, it’ll automatically be re-enabled. This is a sneaky attempt at catching people out who have a habit of using Facebook on a daily basis.</p>



<p>I was diligent, and after a week or so my account was permanently deleted. Good riddance.</p>



<h2>Instagram purge</h2>



<p>Next up was <strong>Instagram</strong>. Facebook owns a bunch of products of course, Instagram being one of them. My Instagram account had been up and running from when the product had first launched, and was not a part of the Facebook group, but now that it was owned by Facebook, it had to go too.</p>



<p>The same reasons apply as I listed them above for Facebook.</p>



<p>Instagram was the easy one to delete, I didn’t really interact on the platform, and had just kept a bunch of interesting photos on my account. On a rare occasion I would browse through photos that others posted and that was about it.</p>



<p>The account was purged from my life with little fuss or care. More time cumulated over years to come for me to use on more <a href="https://www.shogan.co.uk/kubernetes/building-a-raspberry-pi-kubernetes-cluster-part-1-routing/" target="_blank" rel="noreferrer noopener" aria-label="useful endeavours (opens in a new tab)">useful endeavours</a>!</p>



<h2>Killing WhatsApp with fire</h2>



<p>WhatsApp hung around for a long time. This one was more difficult to get rid of. I had my family contacts and many friends on WhatsApp, and it had become my primary messaging platform.</p>



<p>I started using Telegram alongside WhatsApp and convinced quite a few friends to join.</p>



<p>Telegram is by far a superior product to WhatsApp. I’m not convinced it’s perfect, (hey it’s free too). But at least it’s not in the hands of a massive entity like Facebook. Less power to monopolies is a good thing.</p>



<p>About 9 months or so ago, I sent out a message to most of my WhatsApp contacts telling them I was deleting my account and telling them where to find me on Telegram if they joined there.</p>



<p>Shortly afterwards I deleted my WhatsApp account and have not looked back since.</p>



<p>Telegram offers far superior group chat options, more chat features, bots, and more. I’ve been very happy with it as a replacement for WhatsApp.</p>



<h2>Post Facebook, WhatsApp and Instagram</h2>



<p>I really feel happier without these three apps in my life. Facebook was a time sink, where I wasted time that could have been better used directly interacting with family and friends, or working on hobbies.</p>



<p>Instagram wasn’t too much of an issue, but there was (as with the others) the problem with my data being sold off.</p>



<p>WhatsApp was useful for messaging, but Telegram replaced that and gave me way more useful features.</p>



<p>I feel happier knowing that my data from WhatsApp is no longer up for sale, even though it was of course just a blip in a massive ocean of data.</p>



<p>I estimate that over the last 3 years, I’ve collectively <strong>saved around 2920 hours</strong> of time that would have otherwise been spent mindless scrolling through mostly uninteresting content. Simply as a result of me having deleted my Facebook, WhatsApp and Instagram accounts.</p>



<p>That’s 121 days of my life I have had available to use on better things already.</p>



<p>So that is the story of how I deleted my Facebook, WhatsApp, and Instagram accounts.</p>



<p>I encourage everyone reading this to take the plunge and delete your social media accounts wherever possible. Whether it be to save time in your lives, or to stop allowing your private data to be sold, you’ll be happier for it.</p>



<p>This is post #3 in my effort towards <a rel="noreferrer noopener" href="https://twitter.com/hashtag/100DaysToOffload" target="_blank">100DaysToOffload</a>.</p>
			</div><!-- .entry-content -->

		<!-- .entry-meta -->
	</article></div>]]>
            </description>
            <link>https://www.shogan.co.uk/life/how-i-deleted-my-facebook-whatsapp-and-instagram-accounts-and-felt-great-since/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23634788</guid>
            <pubDate>Wed, 24 Jun 2020 22:55:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Experts warn parts of U.S. on verge of being overwhelmed by Covid-19 resurgence]]>
            </title>
            <description>
<![CDATA[
Score 48 | Comments 66 (<a href="https://news.ycombinator.com/item?id=23634517">thread link</a>) | @awnird
<br/>
June 24, 2020 | https://www.cbc.ca/news/world/coronavirus-covid19-world-june24-1.5624885 | <a href="https://web.archive.org/web/*/https://www.cbc.ca/news/world/coronavirus-covid19-world-june24-1.5624885">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>Here's what's happening around the world with COVID-19 on Wednesday.</p><div><p><span><span><span></span><span>Isolating COVID-19 cases and quarantining contacts is necessary in the Americas in order to prevent further lockdowns, says the World Health Organization.<!-- --> <!-- -->2:52</span></span></span></p><p><span><p><strong><em>The latest:</em></strong></p>  <ul>   <li><em><strong>IMF <a href="https://www.cbc.ca/news/business/img-downgrades-outlook-global-economy-1.5625010">sharply downgrades outlook</a> for global economy in face of COVID-19.</strong></em></li>   <li><strong><em>EU travel recommendations may <a href="https://www.cbc.ca/news/world/european-union-travel-americans-russians-coronavirus-1.5624911">impede Americans and Russians</a>.</em></strong></li>   <li><strong><em>Australia scrambles to <a href="https://www.cbc.ca/news/world/australia-scrambles-to-prevent-2nd-covid-19-wave-after-1st-death-in-a-month-1.5624963">prevent 2nd&nbsp;wave</a> after 1st death in a month.</em></strong></li>   <li><strong><em>Beware 2nd wave of coronavirus, <a href="https://www.cbc.ca/news/world/warning-second-wave-coronavirus-britain-1.5625074">medics warn Britain</a>.</em></strong></li>   <li><strong><em>Russia holds coronavirus-delayed <a href="https://www.cbc.ca/news/world/russia-victory-day-parade-1.5624914">Victory Day parade</a>.</em></strong></li>   <li><em><strong>Some countries <a href="https://www.cbc.ca/news/health/2-metres-coronavirus-covid-distancing-1.5624439">reconsider 2-metre rule</a> for physical distancing, but not Canada.</strong></em></li>   <li><em><strong>How Canada got into a pandemic economy — <a href="https://www.cbc.ca/news/politics/pandemic-covid-coronavirus-economy-debt-canada-1.5622374">and how it might get out</a>.</strong></em></li>   <li><em><strong>INTERACTIVE | <a href="https://newsinteractives.cbc.ca/coronavirustracker/">Tracking the coronavirus</a> in Canada and around the world.</strong></em></li>  </ul>  <p>A coronavirus resurgence is wiping out two months of progress <strong>in the U.S.</strong> and sending infections to dire new levels across the country's South and West, with hospital administrators and health experts warning Wednesday that politicians and a tired-of-being-cooped-up public are letting a disaster unfold.</p>  <p>The U.S. recorded a one-day total of 34,700 new COVID-19 cases, just short of the nation's late-April peak of 36,400, according to the count kept by Johns Hopkins University.</p>  <p>While new cases have been declining steadily in early U.S.&nbsp;hotspots such as New York and New Jersey, several other states set single-day case records this week, including Arizona, California, Mississippi, Nevada,&nbsp;Texas and Oklahoma. Some of them also broke hospitalization records, as did North Carolina and South Carolina.</p>  <p>"People got complacent," said Dr. Marc Boom, CEO of the Houston Methodist hospital system. "And it's coming back and biting us, quite frankly."</p>  <p><em><strong>WATCH |&nbsp;Long lines at COVID-19 test sites in U.S.:</strong></em></p>  <p><span><span><span></span><span>Traffic is seen at a standstill as drivers wait at drive-thru COVID-19 test sites in the U.S.<!-- --> <!-- -->1:11</span></span></span></p>  <p>The stock market slid sharply Wednesday as the virus's resurgence clouded investors' hopes for a relatively quick economic turnaround. The virus&nbsp;has been blamed for more than 120,000 deaths in the U.S. — the highest toll in the world — and more than 2.3 million confirmed infections there.</p>  <p>California, the most populous state, reported over 7,100 new cases, a record.&nbsp;Florida's single-day count of new confirmed cases surged Wednesday to 5,500&nbsp;—&nbsp;a 25 per cent jump from the record set last week.</p>  <p>In Texas, which began lifting its shutdowns on May 1, hospitalizations have doubled and new cases have tripled in two weeks. Gov. Greg Abbott told KFDA-TV that the state is facing a "massive outbreak" and might need new local restrictions to preserve hospital space.</p>  <p>The Houston area's intensive care units are nearly full, and two public hospitals are running at capacity, Mayor Sylvester Turner said. Houston Methodist's Boom said Texans need to "behave perfectly and work together perfectly" to slow the infection rate.</p>  <p>"When I look at a restaurant or a business where people ... are not following the guidelines, where people are just throwing caution to the wind, it makes me angry."</p>  <p><span><figure><div><p><img alt="" srcset="https://i.cbc.ca/1.5625848.1593031612!/cpImage/httpImage/image.jpg_gen/derivatives/original_300/virus-outbreak-texas.jpg 300w,https://i.cbc.ca/1.5625848.1593031612!/cpImage/httpImage/image.jpg_gen/derivatives/original_460/virus-outbreak-texas.jpg 460w,https://i.cbc.ca/1.5625848.1593031612!/cpImage/httpImage/image.jpg_gen/derivatives/original_620/virus-outbreak-texas.jpg 620w,https://i.cbc.ca/1.5625848.1593031612!/cpImage/httpImage/image.jpg_gen/derivatives/original_780/virus-outbreak-texas.jpg 780w,https://i.cbc.ca/1.5625848.1593031612!/cpImage/httpImage/image.jpg_gen/derivatives/original_1180/virus-outbreak-texas.jpg 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.5625848.1593031612!/cpImage/httpImage/image.jpg_gen/derivatives/original_780/virus-outbreak-texas.jpg"></p></div><figcaption>A health-care worker takes down a patient's information at a COVID-19 testing site in Houston on Wednesday.<!-- --> <!-- -->(David J. Phillip/The Associated Press)</figcaption></figure></span></p>  <p>Just 17 percent of intensive-care beds were available Wednesday in Alabama — including just one in Montgomery — though hospitals can add more, said Dr. Don Williamson, head of the Alabama Hospital Association.</p>  <p>"There is nothing that I'm seeing that makes me think we are getting ahead of this," he said.</p>  <p>In Arizona, emergency rooms are seeing about 1,200 suspected COVID-19 patients a day, compared with around 500 a month ago. If the trends continue, hospitals will probably exceed capacity within the next several weeks, said Dr. Joseph Gerald, a University of Arizona public health policy professor.</p>  <p><span><figure><div><p><img alt="" srcset="https://i.cbc.ca/1.5625503.1593036438!/cpImage/httpImage/image.jpg_gen/derivatives/original_300/virus-outbreak-florida.jpg 300w,https://i.cbc.ca/1.5625503.1593036438!/cpImage/httpImage/image.jpg_gen/derivatives/original_460/virus-outbreak-florida.jpg 460w,https://i.cbc.ca/1.5625503.1593036438!/cpImage/httpImage/image.jpg_gen/derivatives/original_620/virus-outbreak-florida.jpg 620w,https://i.cbc.ca/1.5625503.1593036438!/cpImage/httpImage/image.jpg_gen/derivatives/original_780/virus-outbreak-florida.jpg 780w,https://i.cbc.ca/1.5625503.1593036438!/cpImage/httpImage/image.jpg_gen/derivatives/original_1180/virus-outbreak-florida.jpg 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.5625503.1593036438!/cpImage/httpImage/image.jpg_gen/derivatives/original_780/virus-outbreak-florida.jpg"></p></div><figcaption>Volunteers prepare packages of personal protective equipment and sanitizers to be donated in Orlando, Fla., on Wednesday.<!-- --> <!-- -->(John Raoux/The Associated Press)</figcaption></figure></span></p>  <p>"We are in deep trouble," said Gerald, urging the state to impose new restrictions on businesses, which Gov. Doug Ducey has refused to do.</p>  <p>Infectious-disease expert Dr. Peter Hotez said he worries that the states will squander what time they have to head off a much larger crisis.</p>  <ul>   <li><strong><a href="http://cbc.ca/1.5626006">Democrats to hold mostly virtual presidential nomination convention due to pandemic</a></strong></li>  </ul>  <p>"We're still talking about subtlety, still arguing whether or not we should wear masks, and still not understanding that a vaccine is not going to rescue us," said Hotez, of the Baylor College of Medicine in Texas.</p>  <p>Texas Gov. Greg Abbott initially barred local officials from fining or penalizing anyone for not wearing a mask as the state reopened. After cases began spiking, he said last week that cities and counties could allow businesses to require masks. Both Abbott and Ducey are Republicans.</p>  <p><span><figure><div><p><img alt="" srcset="https://i.cbc.ca/1.5625948.1593034776!/cpImage/httpImage/image.jpg_gen/derivatives/original_300/virus-outbreak-texas-daily-life.jpg 300w,https://i.cbc.ca/1.5625948.1593034776!/cpImage/httpImage/image.jpg_gen/derivatives/original_460/virus-outbreak-texas-daily-life.jpg 460w,https://i.cbc.ca/1.5625948.1593034776!/cpImage/httpImage/image.jpg_gen/derivatives/original_620/virus-outbreak-texas-daily-life.jpg 620w,https://i.cbc.ca/1.5625948.1593034776!/cpImage/httpImage/image.jpg_gen/derivatives/original_780/virus-outbreak-texas-daily-life.jpg 780w,https://i.cbc.ca/1.5625948.1593034776!/cpImage/httpImage/image.jpg_gen/derivatives/original_1180/virus-outbreak-texas-daily-life.jpg 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.5625948.1593034776!/cpImage/httpImage/image.jpg_gen/derivatives/original_780/virus-outbreak-texas-daily-life.jpg"></p></div><figcaption>A sign requiring face coverings at a business is seen in San Antonio, Texas, on Wednesday.<!-- --> <!-- -->(Eric Gay/The Associated Press)</figcaption></figure></span></p>  <p>North Carolina Gov. Roy Cooper, a Democrat, ordered people to wear masks in public as the daily count of hospitalizations and new cases hovered near records. In Florida, several counties and cities have recently started requiring masks in public places and cracking down on businesses that don't enforce social distancing rules.</p>  <p>In a sign of the shift in the outbreak, New York, Connecticut and New Jersey announced they will require visitors from states with high coronavirus infection rates to quarantine themselves for 14 days. That is a turnaround from March, when Florida Gov. Ron DeSantis issued such an order for visitors from the New York City area, where cases were surging at the time.</p>  <p>Cases are also surging in some other parts of the world. <strong>India </strong>reported a record daily increase of nearly 16,000 new cases, with an outbreak in the capital city of New Delhi becoming a rising concern. <strong>Mexico</strong>, where testing rates have been low, also set a record with more than 6,200 new cases.</p>  <p><span><figure><div><p><img alt="" srcset="https://i.cbc.ca/1.5625473.1593025804!/cpImage/httpImage/image.jpg_gen/derivatives/original_300/aptopix-virus-outbreak-india.jpg 300w,https://i.cbc.ca/1.5625473.1593025804!/cpImage/httpImage/image.jpg_gen/derivatives/original_460/aptopix-virus-outbreak-india.jpg 460w,https://i.cbc.ca/1.5625473.1593025804!/cpImage/httpImage/image.jpg_gen/derivatives/original_620/aptopix-virus-outbreak-india.jpg 620w,https://i.cbc.ca/1.5625473.1593025804!/cpImage/httpImage/image.jpg_gen/derivatives/original_780/aptopix-virus-outbreak-india.jpg 780w,https://i.cbc.ca/1.5625473.1593025804!/cpImage/httpImage/image.jpg_gen/derivatives/original_1180/aptopix-virus-outbreak-india.jpg 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.5625473.1593025804!/cpImage/httpImage/image.jpg_gen/derivatives/original_780/aptopix-virus-outbreak-india.jpg"></p></div><figcaption>A health worker conducts a COVID-19 test on a patient as others wait in New Delhi on Wednesday.<!-- --> <!-- -->(Manish Swarup/The Associated Press)</figcaption></figure></span></p>  <p>But <strong>China </strong>appears to have tamed a new outbreak in Beijing, once again demonstrating its ability to quickly mobilize its vast resources by testing nearly 2.5 million people in 11 days. China on Wednesday reported 12 cases nationwide, down from 22 the day before.</p>  <p>In Europe, countries are both easing and increasing restrictions as the outbreaks evolve. <strong>Slovenia </strong>reintroduced mandatory use of face masks in public transportation and other enclosed public spaces after cases spiked in recent days, while <strong>Belgium </strong>said theatres and swimming pools could reopen next month. Infections there have nosedived over the past two months.</p>  <p><em><strong>WATCH |&nbsp;Belgian entrepreneur gives coronavirus masks the human touch:</strong></em></p>  <p><span><span><span></span><span>Photo booth operator makes custom masks to show the lower half of the wearer's face.<!-- --> <!-- -->1:59</span></span></span></p>  <p><strong>In Africa</strong>, the head of the Ethiopia-based Africa&nbsp;Centers for Disease Control and Prevention,&nbsp;John Nkengasong, said the outbreak is "picking up speed very quickly," with a steep increase in cases and deaths as more countries loosen lockdowns. Africa has seen nearly 325,000 cases and over 8,600 deaths.</p>  <p>Worldwide, more than 9.3&nbsp;million people have been confirmed infected, and more than 479,000 have died, <a href="https://coronavirus.jhu.edu/map.html">according to the Johns Hopkins&nbsp;count</a>.</p>  <hr>  <h2>What's happening with COVID-19 in Canada</h2>  <p>As of 7&nbsp;p.m. ET on Wednesday, Canada had 102,241 confirmed and presumptive coronavirus cases. Provinces and territories listed 65,091 of the cases as recovered or resolved. A CBC News tally of deaths based on provincial reports, regional health information and CBC's reporting stood at 8,530.</p>  <p>In Ontario, patios and hair salons were back in business in <a href="https://www.cbc.ca/news/canada/toronto/covid-coronavirus-ontario-toronto-peel-1.5624924" target="_blank">Toronto and Peel Region</a> on Wednesday.</p>  <p>Premier Doug&nbsp;Ford also announced&nbsp;a plan to&nbsp;<a href="https://www.cbc.ca/news/canada/windsor/ontario-government-announcement-plan-june24-windsor-essex-1.5625150" target="_blank">reopen&nbsp;parts of Windsor-Essex,</a>&nbsp;which until now has been the&nbsp;only region not cleared to move to the next phase of reopening, due to stubbornly high COVID-19 case numbers among migrant workers on farms in the region.</p>  <p><span><figure><div><p><img alt="" srcset="https://i.cbc.ca/1.5625871.1593083182!/cumulusImage/httpImage/image.jpg_gen/derivatives/original_300/covid-coronavirus-ottawa-mask.jpg 300w,https://i.cbc.ca/1.5625871.1593083182!/cumulusImage/httpImage/image.jpg_gen/derivatives/original_460/covid-coronavirus-ottawa-mask.jpg 460w,https://i.cbc.ca/1.5625871.1593083182!/cumulusImage/httpImage/image.jpg_gen/derivatives/original_620/covid-coronavirus-ottawa-mask.jpg 620w,https://i.cbc.ca/1.5625871.1593083182!/cumulusImage/httpImage/image.jpg_gen/derivatives/original_780/covid-coronavirus-ottawa-mask.jpg 780w,https://i.cbc.ca/1.5625871.1593083182!/cumulusImage/httpImage/image.jpg_gen/derivatives/original_1180/covid-coronavirus-ottawa-mask.jpg 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.5625871.1593083182!/cumulusImage/httpImage/image.jpg_gen/derivatives/original_780/covid-coronavirus-ottawa-mask.jpg"></p></div><figcaption>People are seen wearing protective face coverings in Ottawa on Wednesday.<!-- --> <!-- -->(Andrew Lee/CBC)</figcaption></figure></span></p>  <p>British Columbia is <a href="https://www.cbc.ca/news/canada/british-columbia/covid-19-bc-phase-three-john-horgan-1.5625598">further easing restrictions</a>, meaning residents will be allowed to travel within the province as hotels, motels, resorts, spas&nbsp;and RV parks look to reopen.</p>  <p>Premier John Horgan announced Wednesday that B.C.&nbsp;will gradually be&nbsp;moving into Phase 3 of its restart plan, after the province managed&nbsp;to increase activity without seeing a spike in the number of COVID-19 cases in recent weeks.</p>  <p>Phase 3 of B.C.'s restart plan also means residents can travel within the province&nbsp;"safely and respectfully."</p>  <p><span><figure><div><p><img alt="" srcset="https://i.cbc.ca/1.5626141.1593040455!/cumulusImage/httpImage/image.jpg_gen/derivatives/original_300/senior-covid-survivor-walking-laps.jpg 300w,https://i.cbc.ca/1.5626141.1593040455!/cumulusImage/httpImage/image.jpg_gen/derivatives/original_460/senior-covid-survivor-walking-laps.jpg 460w,https://i.cbc.ca/1.5626141.1593040455!/cumulusImage/httpImage/image.jpg_gen/derivatives/original_620/senior-covid-survivor-walking-laps.jpg 620w,https://i.cbc.ca/1.5626141.1593040455!/cumulusImage/httpImage/image.jpg_gen/derivatives/original_780/senior-covid-survivor-walking-laps.jpg 780w,https://i.cbc.ca/1.5626141.1593040455!/cumulusImage/httpImage/image.jpg_gen/derivatives/original_1180/senior-covid-survivor-walking-laps.jpg 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.5626141.1593040455!/cumulusImage/httpImage/image.jpg_gen/derivatives/original_780/senior-covid-survivor-walking-laps.jpg"></p></div><figcaption>People speak through a glass barrier at the Lynn Valley Care Centre in North Vancouver on Tuesday.<!-- --> <!-- -->(Ben Nelms/CBC)</figcaption></figure></span></p>  <p>Canada's Atlantic provinces announced Wednesday they will move forward with <a href="http://www.cbc.ca/news/canada/prince-edward-island/pei-atlantic-bubble-covid19-1.5625133">a so-called travel bubble</a> as of July 3, allowing travellers in Prince Edward Island, New Brunswick, Nova Scotia and Newfoundland and Labrador to move between provinces without self-isolating.</p>  <p>Visitors from provinces and territories outside the region will still be required to self-isolate for 14 days and adhere to the local entry requirements in each of the four jurisdictions. However, once the self-isolation period has passed, these visitors will also be allowed to travel within the Atlantic region.</p>  <ul>   <li><strong><a href="https://www.cbc.ca/news/politics/cerb-recipients-payments-ei-1.5623923">Why some CERB recipients are getting smaller payments this month</a></strong></li>   <li><strong><a href="http://cbc.ca/1.5625811">Yukon to open borders to B.C., N.W.T., and Nunavut residents July 1</a></strong></li>   <li><strong><a href="https://www.cbc.ca/news/canada/british-columbia/bc-covid-update-june-23-1.5624328">B.C. runs risk of rapid rebound in COVID-19 cases if contacts exceed 65% of normal, health officials say</a></strong></li>   <li><strong><a href="https://www.cbc.ca/news/canada/saskatoon/saskatchewan-interprovincial-travel-covid-19-1.5625045">Sask. working on 'more permissive approach' to interprovincial travel</a></strong></li>   <li><a href="https://www.cbc.ca/news/canada/edmonton/alberta-invests-10m-in-serology-testing-to-help-track-spread-of-covid-19-1.5623785"><strong>Alberta invests $10M in serology testing to help track spread of COVID-19</strong></a></li>   <li><strong><a href="https://www.cbc.ca/news/canada/manitoba/intellectual-disabilities-visits-manitoba-covid19-1.5624387">'Pure joy' as Manitoba adults with intellectual disabilities allowed to have loved ones over for visits</a></strong></li>   <li><strong><a href="https://www.cbc.ca/news/canada/north/nwt-extends-state-of-emergency-1.5624556">N.W.T. extends state of emergency, public health emergency for 7th time</a></strong></li>  </ul></span></p></div></div>]]>
            </description>
            <link>https://www.cbc.ca/news/world/coronavirus-covid19-world-june24-1.5624885</link>
            <guid isPermaLink="false">hacker-news-small-sites-23634517</guid>
            <pubDate>Wed, 24 Jun 2020 22:19:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Understand WebAssembly in 5 Minutes]]>
            </title>
            <description>
<![CDATA[
Score 35 | Comments 11 (<a href="https://news.ycombinator.com/item?id=23634033">thread link</a>) | @jesuisundev
<br/>
June 24, 2020 | https://www.jesuisundev.com/en/understand-webassembly-in-5-minutes/ | <a href="https://web.archive.org/web/*/https://www.jesuisundev.com/en/understand-webassembly-in-5-minutes/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

			
<!-- Horizontal Top Article -->
<p>WebAssembly joined HTML, CSS and Javascript as a web standard on December 5, 2019. This will be useful for many things, and in terms of performance, it’s something never seen before in a browser. If you’ve got five minutes, I need to explain the little revolution that’s going on.</p>



<h3>Once upon a time</h3>



<p>In 1995, Javascript was created <a rel="noreferrer noopener" href="https://thenewstack.io/brendan-eich-on-creating-javascript-in-10-days-and-what-hed-do-differently-today/" target="_blank">within 10 days</a> by <a rel="noreferrer noopener" href="https://twitter.com/BrendanEich" target="_blank">Brendan Eich</a>. And at that time, Javascript was not designed to be fast. <strong>It’s basically for form validation and it’s slow like crazy.</strong> As time went by it got better.</p>



<p>In 2008, Google came out of nowhere and put on the table its new browser: Google Chrome. Inside Chrome was a Javascript engine called V8. <strong>And the revolution of V8 was the Just in Time (JIT) compilation of Javascript.</strong> This change from interpreted code to  JIT compilation monstrously accelerated the performance of Javascript, and thus of browsers in general. This speed was going to allow the birth of technology like NodeJS or Electron and the explosion of popularity of Javascript.</p>



<figure><img src="https://i.imgur.com/YHJMavH.jpg" data-src="https://i.imgur.com/YHJMavH.jpg" alt="webassembly"></figure>



<p>In 2015, WebAssembly is announced for the first time with a <a href="https://www.eteknix.com/gaming-in-your-browser-is-about-to-get-interesting-with-webassembly/" target="_blank" rel="noreferrer noopener">small demo of a game</a> running under Unity. The game runs directly in the browser!</p>



<p>In 2019, the W3C made WebAssembly a new web standard. Just as the V8 engine was in its day, <strong>WebAssembly is shaping up to be the new performance revolution</strong>. So WebAssembly is already here, and it’s off to a flying start.</p>



<h3>What is WebAssembly?</h3>



<p>WebAssembly, abbreviated to wasm, is a way to use non-Javascript code and run it in your browser. This code can be C, C++, Rust and many others. <strong>It will be compile and run in your browser at near native speed on your CPU.</strong> This code is in the form of a binary file that you can use directly from Javascript as a module.</p>



<p><strong>WebAssembly is not there to replace Javascript</strong>. On the contrary, these two technologies are made to work together. By using the <a rel="noreferrer noopener" href="https://developer.mozilla.org/en-US/docs/WebAssembly/Using_the_JavaScript_API" target="_blank">Javascript API</a> you can load WebAssembly modules into your page. This means that you can take advantage of the performance of compiled code via WebAssembly with the flexibility of Javascript.</p>



<div><figure><img src="https://i.imgur.com/gbBMTTf.jpg" data-src="https://i.imgur.com/gbBMTTf.jpg" alt="internet"></figure></div>



<p>The name WebAssembly is a bit misleading. <strong>WebAssembly does indeed work for the Web, but it is not limited to it!</strong> The team that made WebAssembly has gone to a lot of trouble to make it generic so that it can be used everywhere. We’re starting to see <a href="https://github.com/wasmerio/wasmer" target="_blank" rel="noreferrer noopener">examples of this</a>.</p>



<p>Also, there’s a misconception that comes up all the time. <strong>WebAssembly is not a programming language.</strong> WebAssembly is an intermediate format, a <a href="https://en.wikipedia.org/wiki/Bytecode" target="_blank" rel="noreferrer noopener">bytecode</a>, which acts as a compilation target for other languages. Okay, it’s not clear, let’s make some drawings.</p>



<h3>How does it work?</h3>



<div><figure><img src="https://i.imgur.com/EHwFHv0.jpg" data-src="https://i.imgur.com/EHwFHv0.jpg" alt="webassembly"></figure></div>



<p>Did you see that? Another work of art. Do you believe me if I tell you I use Photoshop? Anyway !</p>



<ul><li><strong>Step 1</strong> : It’s you and your developer skills. <strong>You produce source code in C, C++</strong> (you can use others languages). This code is supposed to fix a problem or make a process too intensive for Javascript in the browser.</li></ul>



<ul><li><strong>Step 2 </strong>: you will use <a rel="noreferrer noopener" href="https://emscripten.org/index.html" target="_blank">Emscripten</a> to do the translation. <strong>Emscripten is a tool chain, built with <a rel="noreferrer noopener" href="https://en.wikipedia.org/wiki/LLVM" target="_blank">LLVM</a>, that will compile your source code into WebAssembly</strong>. You can install it and compile whatever you want <a rel="noreferrer noopener" href="https://webassembly.org/getting-started/developers-guide/" target="_blank">in a few quick steps</a>, we’ll look at it later. At the end of this step, you will have a WASM file.</li></ul>



<ul><li><strong>Step 3</strong> : You will use the WASM file on your web page. <strong>If you come from the future, you can load this file like any ES6 module.</strong> Right now, the usage is slightly more complex, but nothing fancy.</li></ul>



<p>OK, let’s get our hands dirty.</p>



<h3>Show me the code</h3>



<p>First of all, we need a small piece of C++ code to compile. Where some people will offer you the whole <a href="https://d07riv.github.io/diabloweb/" target="_blank" rel="noreferrer noopener">Diablo 1  game in the browser</a> as an example, <strong>I’ll keep it simple with a function that adds two digits</strong>. We’re not going to prove the speed of C++ with that, it’s for the example.</p>



<pre data-enlighter-language="cpp" data-enlighter-theme="" data-enlighter-highlight="" data-enlighter-linenumbers="" data-enlighter-lineoffset="" data-enlighter-title="" data-enlighter-group="">int add(int firstNumber, int secondNumber) {
  return firstNumber + secondNumber;
}</pre>



<p>Then go to the Linux distribution of your choice. We will start by downloading and installing emscripten.</p>



<pre data-enlighter-language="generic" data-enlighter-theme="" data-enlighter-highlight="" data-enlighter-linenumbers="" data-enlighter-lineoffset="" data-enlighter-title="" data-enlighter-group=""># installing dependencies (yes, you can use newer version of python)
sudo apt-get install python2.7 git

# gettin emscripten via a git clone.
git clone https://github.com/emscripten-core/emsdk.git

# downloading, installing and activating the sdk
cd emsdk
./emsdk install latest
./emsdk activate latestl
source ./emsdk_env.sh

# make sure the installation worked
emcc --version

# compiling the c++ file to a webassembly template
emcc helloWebassembly.cpp -s WASM=1 -o helloWebassembly.html

# we serve the HTML and look at the result
emrun helloWebassembly.html</pre>



<p>That was the hackerman way of doing the wasm. There’s a simpler way. </p>



<p>You can go to <a rel="noreferrer noopener" href="https://mbebenita.github.io/WasmExplorer/" target="_blank">this site</a> and put your C++ code on the left. Then you get the name of the exported function in the WAT part. <strong>Using the add function code showed before i got : “_Z3addii” as function name, we’ll use that just after</strong>. You just have to click on download and you will get your WASM file back. Easy !</p>



<p><strong>Now we can make WebAssembly work directly in the browser without all the annoying noise around.</strong> </p>



<pre data-enlighter-language="generic" data-enlighter-theme="" data-enlighter-highlight="" data-enlighter-linenumbers="" data-enlighter-lineoffset="" data-enlighter-title="" data-enlighter-group="">&lt;html&gt;
  &lt;head&gt;
    &lt;title&gt;WASM test&lt;/title&gt;
    &lt;link rel="stylesheet" href="/stylesheets/style.css" /&gt;
  &lt;/head&gt;

  &lt;body&gt;
    &lt;script&gt;
      const getRandomNumber = () =&gt; Math.floor(Math.random() * 10000);

      WebAssembly.instantiateStreaming(
        fetch("https://012q1.sse.codesandbox.io/wasm/add.wasm")
      )
        .then(obj =&gt; obj.instance.exports._Z3addii)
        .then(add =&gt; {
          document.getElementById("addTarget").textContent = add(
            getRandomNumber(),
            getRandomNumber()
          );
        });
    &lt;/script&gt;

    &lt;h1&gt;Résultat du C++&lt;/h1&gt;
    &lt;p id="addTarget"&gt;&lt;/p&gt;
  &lt;/body&gt;
&lt;/html&gt;</pre>



<p>This is it. This html web page allows you to use C++ compiled into WebAssembly ! I skip all the HTML and obvious stuff to go directly to line 11 with the <strong>InstantiateStreaming </strong>function. As the <a rel="noreferrer noopener" href="https://developer.mozilla.org/fr/docs/Web/JavaScript/Reference/Objets_globaux/WebAssembly/instantiateStreaming" target="_blank">Mozilla documentation</a> says, this function allows you to compile and instantiate our WebAssembly module via a simple fetch.</p>



<p>Then, I use the add function via the function name we retrieved earlier and use it to replace a piece of DOM. And voila ! <strong>C++ via Javascript inside your browser.</strong> How crazy is that? Look, I even made you a <a rel="noreferrer noopener" href="https://codesandbox.io/s/webassembly-en-5-minutes-012q1?fontsize=14&amp;hidenavigation=1&amp;module=%2Fpublic%2Findex.html&amp;theme=dark" target="_blank">codesandbox</a> with a working demo. I’m embedding it right here, play with it !</p>







<p>You’re gonna tell me it’s complicated just to do this, and you’re right. <strong>They’re working to replace the instantiation javascript bit with a simple import into the future.</strong> So be patient, it’s coming. </p>



<figure><img src="https://i.imgur.com/4FjTgL7.jpg" data-src="https://i.imgur.com/4FjTgL7.jpg" alt="fast"></figure>



<h3>Epilogue</h3>



<p>We’ve already been talking for five minutes, so I’ll stop here. If you want to know more about WebAssembly and you have time in front of you : i<strong> recommend this <a rel="noreferrer noopener" href="https://www.javascriptjanuary.com/blog/webassembly-neither-web-nor-assembly-but-revolutionary" target="_blank">excellent article</a> to go deeper in the subject.</strong> For the rest of the story, I’m looking forward to what this opening of the Web to other languages will bring. There’s a lot of potential and i can’t wait for the web to get even faster !</p>

			<!-- clearfix -->
			

			
		</div></div>]]>
            </description>
            <link>https://www.jesuisundev.com/en/understand-webassembly-in-5-minutes/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23634033</guid>
            <pubDate>Wed, 24 Jun 2020 21:23:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Harm of Studying Abroad]]>
            </title>
            <description>
<![CDATA[
Score 85 | Comments 109 (<a href="https://news.ycombinator.com/item?id=23631503">thread link</a>) | @jeffreyrogers
<br/>
June 24, 2020 | https://www.readingthechinadream.com/zhang-yongle-the-harm-of-studying-abroad.html | <a href="https://web.archive.org/web/*/https://www.readingthechinadream.com/zhang-yongle-the-harm-of-studying-abroad.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.readingthechinadream.com/zhang-yongle-the-harm-of-studying-abroad.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23631503</guid>
            <pubDate>Wed, 24 Jun 2020 17:59:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What vertical farming and ag startups don't understand about agriculture]]>
            </title>
            <description>
<![CDATA[
Score 341 | Comments 311 (<a href="https://news.ycombinator.com/item?id=23630201">thread link</a>) | @kickout
<br/>
June 24, 2020 | http://thinkingagriculture.io/what-silicon-valley-doesnt-understand-about-agriculture/ | <a href="https://web.archive.org/web/*/http://thinkingagriculture.io/what-silicon-valley-doesnt-understand-about-agriculture/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>http://thinkingagriculture.io/what-silicon-valley-doesnt-understand-about-agriculture/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23630201</guid>
            <pubDate>Wed, 24 Jun 2020 16:36:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[New technology for aluminum production promises zero CO2 emission]]>
            </title>
            <description>
<![CDATA[
Score 145 | Comments 67 (<a href="https://news.ycombinator.com/item?id=23629859">thread link</a>) | @dagurp
<br/>
June 24, 2020 | https://icelandmonitor.mbl.is/news/news/2020/06/24/iceland_s_co2_emissions_could_be_reduced_by_a_third/ | <a href="https://web.archive.org/web/*/https://icelandmonitor.mbl.is/news/news/2020/06/24/iceland_s_co2_emissions_could_be_reduced_by_a_third/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        
  
    

        
          <p>
 A new Icelandic technology intended for aluminum production offers hopes of eliminating CO2 emissions from the production,
 <em>
  <a href="https://www.mbl.is/frettir/innlent/2020/06/22/gaeti_minnkad_losun_co2_um_thridjung/" target="_blank">
   mbl.is
  </a>
 </em>
 reports.
</p>

        
          <p>
 The company Arctus Metals, in cooperation with Innovation Center Iceland, reached a milestone recently, when it successfully produced aluminum with this new method in a large pot. Instead of creating CO2 emissions, the process emits oxygen.
</p>

        
          <p>
 The main part of the innovation consists of using multiple,&nbsp;vertical inert metal-alloy anodes and ceramic cathodes, instead of using electrodes made of carbon.
</p>

        
          <p>
 This innovation could potentially eliminate CO2 emissions from aluminum smelters in Iceland and elsewhere.
</p>

        
          
  
  

  



        
          <p>
 “Iceland’s three aluminum smelters produce more than 800,000 tons of aluminum a year and emit more than 1.6 million tons of CO2 a year,” states Arctus Metals CEO Jón Hjaltalín Magnússon. “Their emissions make up 30 percent of Iceland’s total CO2 emissions.”
</p>

        
          <p>
 “If all our aluminum smelters adopted this new technology, Iceland’s CO2 emissions would be reduced by 30 percent,
 <span>
  ”
 </span>
 he adds,
 <span>
  “
 </span>
 enabling us to fulfill our international obligations and more. Using the new Arctus Metals method, an aluminum smelter, the size of [Rio Tinto’s] in Straumsvík [Southwest Iceland] would produce as much oxygen as a forest covering 500 square kilometers.”
</p>

        
          <p>
 Jón reports that a cooperation agreement has been signed between the German company Trimet Aluminum, one of the world’s largest producers of aluminum, which will continue the development process by starting production in larger pots, and planning to eventually convert production in their four smelters to this method.
</p>

        
          <p>
 The project was presented to Icelandic President Guðni Th. Jóhannesson yesterday at the offices of Innovation Center Iceland.
</p>

        
          <p>
 In the video above, you can see the first chunk of aluminum processed in this new way, presented by CEO Jón Hjaltalín Magnússon.
</p>

        
          <p>
 You can read more about the company and the project
 <a href="http://www.sustainordic.com/portfolio/items/arctus-metals/" target="_blank">
  here
 </a>
 .
</p>

    

  

  

      </div></div>]]>
            </description>
            <link>https://icelandmonitor.mbl.is/news/news/2020/06/24/iceland_s_co2_emissions_could_be_reduced_by_a_third/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23629859</guid>
            <pubDate>Wed, 24 Jun 2020 16:19:46 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Relay by Puppet: IFTTT for DevOps]]>
            </title>
            <description>
<![CDATA[
Score 22 | Comments 0 (<a href="https://news.ycombinator.com/item?id=23629644">thread link</a>) | @bradhe
<br/>
June 24, 2020 | https://relay.sh/blog/relay-public-beta/ | <a href="https://web.archive.org/web/*/https://relay.sh/blog/relay-public-beta/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section><p>Today we announce <a href="https://relay.sh/">Relay</a>, an event-driven automation platform. <a href="https://app.relay.sh/signup">Sign up now</a> and try it out! Relay connects infrastructure and operations platforms, APIs, and tools together into a cohesive, easy-to-automate whole. Relay is simple enough for you to start automating common, <em>if-this-then-that</em> (IFTTT) style DevOps tasks in minutes and powerful enough to model multi-step, branching, parallelized DevOps processes when the need arises.</p>
<p>Why bother? Because for all the progress we’ve made as builders and operators, <a href="https://landscape.cncf.io/">things are more complicated than ever</a>. Modern applications comprise a growing variety of runtimes, clouds, infrastructure platforms, 3rd party services, and APIs. Mounting sophistication (<a href="https://www.youtube.com/watch?v=dtI5dMpBmQo">and complexity</a>) of how applications are constructed complicates how we operate and manage them. As a result, accomplishing many basic operational tasks can involve touching many different components, with different APIs, different semantics, from different upstreams, vendors and dev teams. Connecting all of these components together is tough, and automating anything across them all can range from tedious to nightmare fuel.</p>
<p>At layers above the plumbing, <a href="https://relay.sh/blog/rise-of-the-apis/">managing infrastructure stops looking like classic configuration management and starts looking like orchestrating workflows</a>. However, workflows can be tricky. Connectivity, secrets handling, event listening, ordering, parallelism, error handling, and control flow all conspire to make writing workflows from scratch pretty gnarly. The complexity adds up fast. We can do better!</p>
<blockquote>
<p>“Automated workflows are the bedrock of all software organizations.”<br>
— Jason Warner, CTO @ GitHub</p>
</blockquote>
<p>Relay lets you represent any DevOps workflow as code, composed of triggers that listen for incoming events, and steps that define the task you’re automating. Relay does not limit what you can talk to. A single workflow could listen for alerts from PagerDuty, query metrics from DataDog, reconfigure infrastructure with Terraform, and send a notification via Slack. It’s easy to leverage pre-existing triggers, steps, and workflows, and it’s simple to make your own if the need arises.</p>
<p>As a hosted service, Relay supervises things on your behalf. It will automatically trigger your workflow based on incoming events, execute your workflow’s steps in parallel, notify you if you need to intervene, and keep meticulous records of everything done. Relay does this all automatically, so you don’t have to.</p>
<p>Today, we’re proud to announce <a href="https://relay.sh/">beta availability</a> for Relay. Read on to see how it works!</p>
<h2>Workflows</h2>
<p>Relay’s core method of automation is <a href="https://relay.sh/docs/using-workflows/"><em>the workflow</em></a>. Workflows combine useful activities together to accomplish a particular task:</p>
<ul>
<li>When we detect an unused Azure Disk, delete it <em>(so we can save money)</em></li>
<li>When they go unused, nuke any AWS authentication keypairs <em>(so we can reduce our attack surface)</em></li>
<li>When a PagerDuty alert fires with a certain severity, create tickets in Jira and a room in Slack <em>(so we can more quickly troubleshoot issues)</em></li>
</ul>
<p>Relay lets you succinctly express these types of workflows, and beyond, <a href="https://relay.sh/docs/reference/relay-workflows/">as code</a>. And like code, workflows can be versioned, reviewed, refactored, and reused. We’re Puppet; <a href="https://www.google.com/search?hl=en&amp;q=puppet%20infrastructure%20as%20code">we wouldn’t have it any other way</a>.</p>
<p>Running your first workflow is easy, and should only take you about a minute. As tradition demands, here’s “Hello, world” (<a href="https://app.relay.sh/login">log in</a> and follow along!):</p>
<p><img src="https://relay.sh/debec11953b60317076234251dc8c4f0/hello-world.gif" alt="Hello, world!"></p>
<p>Because workflows are code, you can treat them like code. Modifying a workflow is straightforward. Let’s change the workflow, adding a step to emit the current date:</p>
<p><img src="https://relay.sh/2105fe13ad95afadea7d0e9dc45e3976/cli.gif" alt="Change the workflow using the CLI"></p>
<p>That covered <a href="https://relay.sh/docs/getting-started/#install-the-cli">getting the CLI installed</a>, authenticating against the service, downloading your workflow, modifying the logic, and then letting Relay know the code is updated.</p>
<h2>Triggers and steps</h2>
<p>Workflows contain <em>triggers</em> and <em>steps</em>: Triggers determine when Relay should execute your workflow: manually, on a schedule, or when pinged by an external source. Steps represent the set of actions and activities necessary to make your workflow accomplish its goals. Steps are just <a href="https://www.docker.com/resources/what-container">containers</a>, so you’re pretty unconstrained when it comes to what a step can do. Both triggers and steps <a href="https://relay.sh/docs/integrating-with-relay/">are easy to create, remix, and share</a>. With these building blocks, Relay is capable of modeling a huge variety of workflows, and executing them on your behalf. There are a bunch already written, and it’s straightforward to <a href="https://relay.sh/docs/getting-started/">make your own</a>.</p>
<p>Here’s a more interesting example workflow that <a href="https://relay.sh/workflows/ec2-reaper/">cleans up some unneeded EC2 instances</a>. It has more steps, including some that consume AWS credentials, and one which represents a <em>manual approval</em> gate:</p>
<p><img src="https://relay.sh/18f91058f6a39345a357bc6d72855ed8/ec2-reaper.gif" alt="Cleaning up some EC2 instances"></p>
<p>It’s easy to add, remove, or replace triggers and steps to suit your liking. Some modifications for the preceding example could include adding a webhook-based trigger for the workflow, adding a notification step at the end, or better integrating it into your GitOps setup. Perhaps a step that takes the list of terminated instances, computes their money you just saved, then buys an equivalent amount of stuff from your Amazon wish list? Ops is hard work - treat yourself!</p>
<p>Our examples thus far have shown short, linear sequences of steps but you can also express some pretty elaborate processes just as easily. Here’s a picture of the execution graph of one of workflows we use to manage Relay itself:</p>
<p><span>
      <a href="https://relay.sh/static/ed787c9f007e7856c5846c98c4c7f6fa/065ce/relay-graph.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="A more complex workflow graph" title="A more complex workflow graph" src="https://relay.sh/static/ed787c9f007e7856c5846c98c4c7f6fa/64756/relay-graph.png" srcset="https://relay.sh/static/ed787c9f007e7856c5846c98c4c7f6fa/a8a0d/relay-graph.png 300w,
https://relay.sh/static/ed787c9f007e7856c5846c98c4c7f6fa/dface/relay-graph.png 600w,
https://relay.sh/static/ed787c9f007e7856c5846c98c4c7f6fa/64756/relay-graph.png 1200w,
https://relay.sh/static/ed787c9f007e7856c5846c98c4c7f6fa/28bdc/relay-graph.png 1800w,
https://relay.sh/static/ed787c9f007e7856c5846c98c4c7f6fa/98e2c/relay-graph.png 2400w,
https://relay.sh/static/ed787c9f007e7856c5846c98c4c7f6fa/065ce/relay-graph.png 2680w" sizes="(max-width: 1200px) 100vw, 1200px" loading="lazy">
  </a>
    </span></p>
<h2>The Relay service</h2>
<p>Listening for events and running workflows might appear conceptually simple, but there are a lot of practical details that need to be worked out. Relay’s execution environment (and <a href="https://github.com/puppetlabs/relay-core">underlying engine</a>):</p>
<ul>
<li>Manages <a href="https://relay.sh/docs/using-workflows/adding-connections/">connections</a> to upstream/downstream APIs and services, making them securely available to the workflows that need them</li>
<li>Automatically creates <a href="https://relay.sh/docs/reference/relay-workflows/#push"><em>push triggers</em></a> for your workflows, complete with workflow-specific security tokens, so you can easily kick it off from all kinds of other tools</li>
<li>Automatically constructs an environment for running webhooks, so your workflows can respond to events from webhook-only services</li>
<li>Sandboxes workflow and step execution, for fault isolation</li>
<li>Manages your workflows with all the necessary <em>ops accoutrements</em> (e.g. monitoring, logging, error handling)</li>
<li>Supervises the execution of your workflows, invoking steps in the right order (with automatic parallelization)</li>
<li>Standardizes the interfaces between all these pieces so steps, triggers, and connections are reusable and remixable across workflows</li>
</ul>
<p>Relay takes care of this stuff so you don’t have to. Instead, you can focus on the logic of your workflow, the core of what you’re trying to automate.</p>
<p>After all, isn’t that the point?</p>
<h2>Automation for everyone</h2>
<p>How many unique applications are running out there across the planet (<a href="https://twitter.com/lkanies/status/1182350689529298944">or above it</a>)? Thousands? Millions? <a href="https://www.merriam-webster.com/dictionary/bajillion">Bajillions</a>? How many of them are running on identical infrastructure stacks, built with identical technology stacks, managed in identical ways at an identical scale? There’s a truly staggering variety of approaches and constraints.</p>
<p>If there’s no <em>One True Stack</em>, then there’s no <em>One True Way To Manage It</em>. The tools you employ should thrive in this sort of world because that’s the world we’ve got.</p>
<p>Relay’s core value lies in letting you tie a <a href="https://relay.sh/integrations/">wide variety of services, APIs, and platforms</a> together. It’s constructed in a deliberately pluggable way. Users can readily extend the system to talk to new technologies, respond to new kinds of events, and take action in new ways…no CS degree required. Those extensions should be easy to share, so the entire user community can benefit. The ecosystems around the tools we use are every bit as important as the tools themselves.</p>
<p>Even though it’s early days, Relay can already do quite a lot. The future holds many possibilities: new workflows, more integrations with more tools and platforms, higher-level workflow syntax, a more streamlined authoring experience, simplified input/output from steps, and more. Early users have already given us a ton of great suggestions, and we’d love to hear yours!</p>
<h2>Next steps</h2>
<p>The next step (and best step) is to <a href="https://relay.sh/">try it out</a>! And if you’d like to learn more about Relay, you can check out:</p>
<ul>
<li><a href="https://relay.sh/blog/relay-and-open-source/">How to get involved</a>, extend Relay to better meet your needs, and become part of Relay community</li>
<li><a href="https://relay.sh/docs/">The documentation</a> does a great job of introducing Relay, its usage, core concepts, and extension points</li>
<li><a href="https://relay.sh/workflows/">Peruse some workflows</a> to see what they can do. The code and its graphical execution plan are available on every workflow’s page.</li>
<li><a href="https://puppetcommunity.slack.com/archives/CMKBMAW2K">Slack</a> - come linger in the #relay channel! The more the merrier</li>
</ul>
<p>Thanks, and let a thousand workflows bloom!</p></section></div>]]>
            </description>
            <link>https://relay.sh/blog/relay-public-beta/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23629644</guid>
            <pubDate>Wed, 24 Jun 2020 16:07:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Google Blew a Ten-Year Lead]]>
            </title>
            <description>
<![CDATA[
Score 834 | Comments 542 (<a href="https://news.ycombinator.com/item?id=23628761">thread link</a>) | @secondbreakfast
<br/>
June 24, 2020 | https://secondbreakfast.co/google-blew-a-ten-year-lead | <a href="https://web.archive.org/web/*/https://secondbreakfast.co/google-blew-a-ten-year-lead">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
	  <div>
        
          



<p>Back when there were rumors of Google building an operating system, I thought<span></span> <span>“</span>Lol.”</p>
<p>Then I watched then-PM Sundar Pichai <a href="https://www.youtube.com/watch?v=0QRO3gKj3qw">announce Chrome <span>OS</span></a>. My heart raced. It was perfect.</p>
<p>I got my email through Gmail, I wrote documents on Docs, I listened to Pandora, I viewed photos on TheFacebook. Why did I need all of Windows Vista?</p>
<p>In 2010, I predicted that by 2020 Chrome <span>OS</span> would be the most popular desktop <span>OS</span> in the world. It was fast, lightweight, and $0.</p>
<p><span>“</span>Every Windows and <span>OS</span> X app will be re-built for the browser!” I thought. Outlook-&gt;Gmail. Excel-&gt;Sheets. Finder-&gt;Dropbox. Photoshop-&gt;Figma. Terminal-&gt;Repl.it.</p>
<p>All of your files would be accessible by whoever you wanted, wherever you wanted, all the time. It was obvious. Revolutionary.</p>
<p>I haven’t installed <span>MSFT</span> Office on a machine since 2009. Sheets and Docs have been good enough for me. The theoretical unlimited computing power and collaboration features meant Google Docs was better than Office (and free!).</p>
<p>Then something happened at Google. I’m not sure what. But they stopped innovating on cloud software.</p>
<p>Docs and Sheets haven’t changed in a decade. Google Drive remains impossible to navigate. Sharing is complicated. Sheets freezes up. I can’t easily interact with a Sheets <span>API</span> (I’ve tried!). Docs still shows page breaks by default! <span>WTF</span>!</p>
<p>Even though I have an iPhone and a MacBook, I’ve been married to Google services. I browse Chrome. I use Gmail. I get directions and lookup restaurants on Maps. I’m a YouTube addict.</p>
<p>Yet I’ve been ungluing myself from Google so far this year. Not because of Google-is-reading-my-emails-and-tracking-every-keystroke reasons, but because I like other software so much more that it’s worth switching.</p>
<p>At <span>WWDC</span>, Apple shared Safari stats for macOS Big Sur. It reminded me how much Chrome makes my machine go <span>WHURRRRRR</span>. Yesterday, I made Safari my default browser again.</p>
<p>My Gmail inbox has become a mailbox stuffed with clothing flyers, SaaS mailers, and Rollbar alerts. I love when people respond to Second Breakfast, but their responses get lost amid a sea of plastic bottles. I started using <span>HEY</span> last week. My new email is <a href="mailto:billy@hey.com">billy@hey.com</a>. I love it so far.</p>
<p>I’ve given up on Google Docs. I can never find the documents Andy shares with me. The formatting is tired and stuck in the you-might-print-this-out paradigm. Notion is a much better place to write and brainstorm with people.</p>
<p>The mobile Google results page is so cluttered that I switched my iPhone’s default search to DuckDuckGo. The results are a tad worse, but I’m never doing heavy-duty searches on the go. And now I don’t have to scroll past 6 ads to get the first result. DuckDuckGo’s privacy is an added bonus.</p>
<p>I still use Google Sheets heavily. But wow, Airtable makes Sheets feel decrepit. Where’s the easy API? New ways of formatting? Better collaboration? Simple sheet-as-a-database?</p>
<p>My new usage patterns:</p>
<ul>
<li>Email: <del>Gmail</del> <span>HEY</span></li>
<li>Search: <del>Google</del> DuckDuckGo (mobile) and Google (desktop)</li>
<li>Maps: Google</li>
<li>Docs: <del>Google</del> Notion</li>
<li>Sheets: Google</li>
<li>Video: YouTube (but increasingly I’m noticing other people use Twitch, Instagram, and TikTok)</li>
<li>Video Calls: <del>Google Meet</del> Zoom</li>
</ul>
<p>I’m a long shareholder of Google. It’s amazing how they have four monopolies and only monetize one of them. I’m confident they have a bright future ahead.</p>
<p>But the lack of innovation is frustrating. The product goals are all over the place. Microsoft has a new clear mission: The Cloud. What’s Google’s clear mission?</p>
<p>It feels like they blew a 10 year lead.</p>

          
          
          
          <div>
            <div>
              <p>
                I write almost every day. Subscribe to get new posts as you sip your coffee each morning.
                <span>When you join I'll also send you the posts that've made the front page of HN.</span>
              </p>
            </div>
            
          </div>
                
          
      

      </div>
    </div></div>]]>
            </description>
            <link>https://secondbreakfast.co/google-blew-a-ten-year-lead</link>
            <guid isPermaLink="false">hacker-news-small-sites-23628761</guid>
            <pubDate>Wed, 24 Jun 2020 15:12:07 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Text-Only Websites]]>
            </title>
            <description>
<![CDATA[
Score 291 | Comments 113 (<a href="https://news.ycombinator.com/item?id=23626929">thread link</a>) | @lcnmrn
<br/>
June 24, 2020 | https://sjmulder.nl/en/textonly.html | <a href="https://web.archive.org/web/*/https://sjmulder.nl/en/textonly.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">

<p>By <a href="https://sjmulder.nl/en/">Sijmen J. Mulder</a></p>

<p>This is a directory of websites that <strong>primarily stick with
simple, marked up, hyperlinked text</strong>. I appreciate these sites
because they load quickly, scroll smoothly, spare my battery, are more
compact, and lack the usual nonsense that infects many websites.</p>

<p><small><sup>*</sup> not <em>quite</em> text-only, see preceding
parapgraph. See <a href="#notquite">Honorable mentions</a> below
for sites that aren't quite ‘text-only’ but lightweight
and worth visiting nonetheless.</small></p>

<h3>News</h3>

<ul>
  <li><a href="http://thin.npr.org/">NPR</a></li>
  <li><a href="http://lite.cnn.io/en">CNN</a></li>
  <li>
    <a href="https://www.csmonitor.com/layout/set/text/textedition">
      The Christian Science Monitor
    </a>
  </li>
  <li><a href="https://noslite.nl/">NOS</a> (Dutch)</li>
  <li><a href="https://legiblenews.com/">Legible News</a></li>
  <li><a href="https://lite.poandpo.com/">POST Online Media</a></li>
  <li><a href="https://www.ard-text.de/mobil/">ARD Teletext</a></li>
</ul>

<h3>Social</h3>

<ul>
  <li><a href="https://lobste.rs/">Lobsters</a></li>
  <li>
    <a href="https://rawtext.club/">rawtext.club</a>
    – “<em>Resist</em> the dazzling spectacle”
  </li>
</ul>

<h3>Technology</h3>

<ul>
  <li><a href="https://news.ycombinator.com/">Hacker News</a></li>
  <li>
    <a href="https://www.rfc-editor.org/rfc-index-100a.html">
      RFC index
    </a>
  </li>
  <li>
    <a href="https://www.freesoft.org/CIE/Topics/index.htm">Connected</a>,
    an internet encyclopedia.
  </li>
  <li>
    <a href="https://bearblog.dev/">Bear Blog</a>,
    text-first blogging platform
  </li>
  <li>
    <a href="https://mataroa.blog/">Mataroa blog</a>,
    another text-first blogging platform
  </li>
  <li>
    <a href="http://manpages.bsd.lv/index.html">Practical UNIX Manuals</a>,
    on <em>mdoc</em> and history
  </li>
</ul>

<h3>Blogs &amp; Personal</h3>

<ul>
  <li>
    <a href="http://idlewords.com/talks/">Maciej Cegłowski</a>
    (talks on various topics, not quite text only)
  </li>
  <li>
    <a href="http://sommarskog.se/">Erland Sommarskog</a> (mostly SQL)
  </li>
  <li>
    <a href="http://bactra.org/">Cosma's Home Page</a>
  </li>
  <li>
    <a href="http://blog.fefe.de/" hreflang="de">Fefes Blog</a>
    (German)
  </li>
  <li>
    <a href="https://gir.st/">Tobias Girstmair</a>,
    <a href="https://gir.st/blog">blog</a>
    (hardware &amp; software hacker)
  </li>
  <li>
    <a href="http://verisimilitudes.net/">verisimilitudes.net</a>
  </li>
  <li><a href="https://lukesmith.xyz/blogindex">Luke Smith</a></li>
  <li><a href="http://www.tomcooks.com/">Tom Cooks</a></li>
  <li><a href="http://danluu.com/">Dan Luu</a></li>
  <li>
    <a href="https://www.artemix.org/">Artemix</a>
    (back end and UX)
  </li>
  <li>
    <a href="https://idle.nprescott.com/">Nolan Prescott</a>,
    or “Idle Thoughts” (tech &amp; thinking)
  </li>
  <li>
    <a href="https://prog21.dadgum.com/">Programming in the Twenty-First Century</a>
  </li>
  <li>
     <a href="https://nullprogram.com/">null program</a>
     by Chris Wellons
  </li>
  <li>
    <a href="https://greghendershott.com/">Greg Hendershott</a>
    (mostly Racket)
  </li>
  <li><a href="https://terkel.com/">Terkel</a></li>
  <li><a href="https://brokensandals.net/">Jacob Williams</a></li>
  <li>
    <a href="http://www.jaruzel.com/">Jaruzel’s Home</a>
    of Retro and Other Curios
  </li>
  <li><a href="https://allstead.dev/">Willis Allstead</a></li>
  <li><a href="https://www.thomasjost.com/">Thomas Jost</a></li>
  <li><a href="https://wildauer.io/">Manuel Wildauer</a></li>
  <li>
    <a href="https://rgz.ee/">Roman Zolotarev</a>
    (<a href="https://www.openbsd.org/">OpenBSD</a> enthousiast)
  </li>
  <li>
    <a href="https://drewdevault.com/">Drew DeVault</a>,
    creator of <a href="https://sourcehut.org/">SourceHut</a>
  </li>
  <li>
    <a href="http://jrm4.com/">John R. Marks, IV</a>
    (created with <a href="http://zim-wiki.org/">Zim</a>)
  </li>
  <li>
    <a href="https://creativegood.com/">Creative Good</a>
    <span>– Since 1997</span>
  </li>
  <li><a href="https://patrickcollison.com/">Patrick Collison</a></li>
  <li><a href="http://eradman.com/">Eric Radman</a> (BSD &amp; SQL)</li>
</ul>

<h3>Music &amp; Podcasts</h3>

<ul>
  <li>
    <a href="https://vulfpeck.com/">Vulfpeck</a>,
    an American funk band
  </li>
  <li><a href="https://techtonic.fm/">Techtonic</a></li>
  <li><a href="https://19hz.info/">Electronic Music Calendars</a></li>
</ul>

<h3>Misc</h3>

<ul>
  <li>
    <a href="https://gopherpedia.com/">Gopherpedia</a>
    (<a href="https://en.wikipedia.org/wiki/Gopher_(protocol)">Gopher</a> interface to Wikipedia)
  </li>
  <li><a href="http://wttr.in/">wttr</a> (weather)</li>
  <li>
    <a href="http://rate.sx/">rate.sx</a>
    (crypto rates, same author)
  </li>
  <li>
    <a href="https://yarchive.net/">Usenet Archives</a>
    by Norman Yarvin
  </li>
  <li>
    <a href="https://every.sdf.org/">every.sdf.org</a>,
    a collection of plain-text files
  </li>
  <li><a href="https://www.craigslist.org/">Craigslist</a>
</li></ul>

<p>Please send me suggestions on <a href="mailto:ik@sjmulder.nl">ik@sjmulder.nl</a>.</p>

<p><a href="#top">Back to top</a></p>

<hr>

<h2 id="notquite">Honorable mentions</h2>

<p>Note quite as ‘text-only’ but lightweight and worth
visiting nonetheless!</p>

<h3>News</h3>

<ul>
  <li>
    <a href="https://readspike.com/">Readspike</a>
    "Simple news aggregator"
  </li>
  <li><a href="https://spidr.today/">Spidr</a> (aggregator)</li>
  <li>
    <a href="https://www.svt.se/svttext/web/pages/100.html">SVT Text</a>
    (Swedish teletext service)
  </li>
  <li><a href="https://radfi.com/">Radio Fidelity</a> (aggregator)</li>
</ul>

<h3>Social</h3>

<ul>
  <li>
    <a href="https://subreply.com/">Subreply</a>
    (social network)
  </li>
  <li>
    <a href="https://needgap.com/">Needgap</a>
    (“problem validation”)
  </li>
  <li>
    <a href="https://midnight.pub/">midnight</a>
    (“networked writing” platform)
  </li>
</ul>

<h3>Technology</h3>

<ul>
  <li>
    <a href="https://sourcehut.org/">SourceHut</a>
    (git, mailing lists, etc)
  </li>
  <li>
    <a href="https://archive.vn/">archive.today</a>
    (web archiving)
  </li>
</ul>

<h3>Blogs &amp; Personal</h3>

<ul>
  <li>
    <a href="https://engineeringblogs.xyz/">Engineering Blogs</a>,
    a curated collection
  </li>
  <li>
    <a href="http://lucumr.pocoo.org/">Armin Ronacher</a> (mostly Rust)
  </li>
  <li>
    <a href="https://www.gwern.net/">Gwern Branwen</a> (various topics)
  </li>
  <li>
    <a href="https://hugotunius.se/">Hugo Tunius</a> (programming)
  </li>
  <li><a href="https://usmanity.com/">Muhammad Usman</a></li>
  <li>
    <a href="https://sgolem.com/">Stjepan Golemac</a>
    (JS, React, Node, Rust)
  </li>
  <li>
    <a href="http://maddox.xmission.com/">”The Best Page in the Universe”</a>
  </li>
  <li><a href="https://lawzava.com/">Law Zava</a></li>
  <li><a href="https://hitstartup.com/">hitstartup</a></li>
  <li><a href="https://jvns.ca/">Julia Evans</a> (tech)</li>
  <li>
    <a href="https://wingolog.org/">Wingolog</a>
    (mostly functional programming)
  </li>
  <li>
    <a href="http://matt.might.net/">Matt Might</a>
    (medicine and computer science)
  </li>
  <li><a href="https://mnmlist.com/">mnmlist</a></li>
  <li>
    <a href="https://neil.computer/">Neil Panchal</a>
    – “quantum integrated circuits”!
  </li>
  <li>
    <a href="https://www.imperialviolet.org/">ImperialViolet</a>
    by adam Langley (mostly crypto)
  </li>
  <li><a href="https://sirodoht.com/">sirodoht</a></li>
  <li><a href="https://sheep.horse/">Andrew Stephens</a></li>
  <li><a href="https://fnune.com/">Fausto</a></li>
  <li>
    <a href="https://noncombatant.org/">Noncombatant</a>
    (tech, music, more)
  </li>
  <li>
    <a href="https://daringfireball.net/">Daring Fireball</a>
    (predominantly Apple)
  </li>
  <li>
    <a href="https://inessential.com/">Inessential</a>
    by Brent Simmons, author of NetNewsWire
  </li>
</ul>

<h3>Misc</h3>

<ul>
  <li>
    <a href="https://wiby.me/">Wiby</a>,
    a search engine for these kinds of sites
  </li>
  <li><a href="http://www.jimmyr.com/">JimmyR</a> (aggregator)</li>
  <li>
    <a href="http://amasci.com/">Science Hobbyist</a>
    (90s design warning!)
  </li>
  <li>
    <a href="https://tilde.pt/~fimdomeio/index2.html">Web 0.5</a>
    (only for text browsers!)
  </li>
  <li>
    <a href="http://gutenberg.net.au/">Project Gutenberg Australia</a>
  </li>
  <li>
    <a href="http://www.rowlingindex.org/">The J.K. Rowling Index</a>
  </li>
  <li><a href="https://copypastelist.com/">Copy Paste List</a></li>
</ul>

<p><a href="#top">Back to top</a></p>
</div>]]>
            </description>
            <link>https://sjmulder.nl/en/textonly.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23626929</guid>
            <pubDate>Wed, 24 Jun 2020 12:08:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Software Entropy]]>
            </title>
            <description>
<![CDATA[
Score 50 | Comments 17 (<a href="https://news.ycombinator.com/item?id=23626253">thread link</a>) | @1penny42cents
<br/>
June 24, 2020 | https://camhashemi.com/2020/06/23/software-entropy/ | <a href="https://web.archive.org/web/*/https://camhashemi.com/2020/06/23/software-entropy/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-195">
			<!-- .entry-header -->
		<div>
		
<h2>Defining Entropy</h2>



<p>Entropy is a measure of chaos, or disorder, in a system.</p>



<p>My college physics professor described entropy using two shoe closets.</p>



<p>Imagine a clean shoe closet, where all shoes are paired and sorted by color. The closet’s entropy is the total number of arrangements its shoes can have. A clean closet’s entropy is relatively small. There may be a few pairs of grey or blue shoes that can be switched around – but this doesn’t add much complexity. In a closet with low entropy, it’s easy to add or remove shoes from that closet as needed.</p>



<p>Now imagine a messy shoe closet. None of the shoes are paired, and they’re all tangled in a big pile. How many possible combinations can these shoes be in? You can quickly find out by trying to pull out the pair you want. The messy shoe closet has a much greater entropy than the clean one.</p>



<p>In short, we measure entropy by counting the number of possible states a system can be in. More states mean more entropy.</p>



<h2>Entropy in Software</h2>



<p>In software, our building blocks are simple enough for us to measure entropy in a crude way. Take this model for example:</p>


<pre title="">Transaction(
  createdAt: String
  buyerId: String,
  sellerId: String
  amount: Int
)
</pre>


<p>As simple as it seems, this model is like our messy shoe closet. There are many more ways for this model to be wrong than there are for it to be right. We can see that by comparing it to an organized shoe closet:</p>


<pre title="">Transaction(
  createdAt: DateTime,
  buyerId: UserId,
  sellerId: UserId,
  amount: Price
)
</pre>


<p>When `createdAt` was an arbitrary string, it could take on invalid values “foo” and “bar” just as easily as a valid value “06-23-2020”. There are many more possible states that the field can be in, and most of them are invalid. This choice of a broad data type allows chaos into our model. This unwanted chaos leads to misunderstandings, bugs, and wasted energy.</p>



<p>When each model is strongly typed to a strict set of values, this chaos is minimized. DateTime, UserId, and Price are typed such that all possible values are valid. Accordingly, these types are more predictable, easier to manipulate, and lead to less surprises in practice.</p>



<p>As in life, entropy is not all bad – some of it is desirable and some of it is not. In software, we need entropy to a certain extent: our code is valuable <em>because </em>it supports a variety of possible dates, users, and prices. But when this chaos grows beyond the value it adds, our software becomes painful to use and painful to maintain.</p>



<h2>Modeling Software Entropy</h2>



<p>Given our observations, we can describe a simple rule:</p>



<p><code>complexity = number of total possible states</code></p>



<p>A construct with only a few possible states is simple. Booleans and enums are much simpler than strings. A system with one moving piece is much simpler than a system with many moving pieces.</p>



<p>Sometimes, our problems are essentially complex. In these cases, our solutions need some essential complexity to match. But when does essential complexity become unnecessary? In these cases, we can use another rule:</p>



<p><code>cleanliness = number of <strong>valid</strong> possible states / number of <strong>total</strong> possible states</code></p>



<p>If there are thousands of total possible states, but only two of them are valid: it’s a messy solution. A simple example of this is representing a boolean value as a string.</p>


<pre title="">if value == "true": do this
else if value == "false": do that
else: throw error
</pre>


<p>There are many ways for this code to go wrong; not just in execution but also in interpretation. Keeping our solutions clean improves correctness, readability, and maintainability. It’s one of the primary measures of “quality” in my view.</p>



<h2>Minimizing Software Entropy</h2>



<p>Given these definitions, we can ask ourselves some questions to guide our software decisions:</p>



<ol><li>How many possible states does this solution have?</li><li>How many of those states are invalid?</li><li>Is there any way to make the solution simpler, by trimming the number of <em>total</em> possible states?</li><li>Is there any way to make the solution cleaner, by trimming the number of <em>invalid</em> possible states?</li></ol>



<p>The power of this concept is that it smoothly scales up and down the ladder of abstraction. It applies to basic data types just as well as it does to solution architecture and product development.</p>



<p>How many moving pieces does our solution need? When an unimaginable requirement flies in and tries to blow our solution to the ground, how many pieces can be left standing? When an unexpected input arrives, do invalid states propagate across the system, or are they contained and eliminated on sight? In short, how clean is our solution?</p>



<p>To make life possible, we utilize chaos by creating complex systems that support a diversity of people and their use cases. To make life predictable, we combat undesirable chaos by keeping those systems as clean and orderly as possible.</p>



<p>In software, we work in a world where chaos is measurable and cleanliness is achievable. We just need the right set of signals and responses to make it happen.</p>
			</div><!-- .entry-content -->

	<!-- .entry-footer -->
</article></div>]]>
            </description>
            <link>https://camhashemi.com/2020/06/23/software-entropy/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23626253</guid>
            <pubDate>Wed, 24 Jun 2020 10:20:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Don’t Fly During Ramadan (2013)]]>
            </title>
            <description>
<![CDATA[
Score 172 | Comments 101 (<a href="https://news.ycombinator.com/item?id=23625215">thread link</a>) | @luu
<br/>
June 24, 2020 | https://adityamukerjee.net/2013/08/22/dont-fly-during-ramadan/ | <a href="https://web.archive.org/web/*/https://adityamukerjee.net/2013/08/22/dont-fly-during-ramadan/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>A couple of weeks ago, I was scheduled to take a trip from New York (JFK) to Los Angeles on JetBlue. Every year, my family goes on a one-week pilgrimage, where we put our work on hold and spend time visiting temples, praying, and spending time with family and friends. To my Jewish friends, I often explain this trip as vaguely similar to the <a href="https://en.wikipedia.org/wiki/Sabbath" target="_blank" rel="noopener">Sabbath</a>, except we take one week of rest per year, rather than one day per week.</p>
<p>Our family is not Muslim, but by coincidence, this year, our trip happened to be during the last week of <a href="https://en.wikipedia.org/wiki/Ramadan" target="_blank" rel="noopener">Ramadan</a>.</p>
<p>By further coincidence, this was <em>also</em> the same week that I was moving out of my employer-provided temporary housing (at NYU) and moving into my new apartment. The night before my trip, I enlisted the help of two friends and we took most of my belongings, in a couple of suitcases, to my new apartment. The apartment was almost completely unfurnished – I planned on getting new furniture upon my return – so I dropped my few bags (one containing an air mattress) in the corner. Even though I hadn’t decorated the apartment yet, in accordance with Hindu custom, I taped a single photograph to the wall in my bedroom — a long-haired saint with his hands outstretched in <em><a href="https://www.google.com/search?q=pronam&amp;source=lnms&amp;tbm=isch&amp;sa=X&amp;ei=fR8WUre0GIG28wSH94DwCw&amp;ved=0CAcQ_AUoAQ&amp;biw=1046&amp;bih=733" target="_blank" rel="noopener">pronam</a></em> (a sign of reverence and respect).</p>
<p>The next morning, I packed the rest of my clothes into a suitcase and took a cab to the airport. I didn’t bother to eat breakfast, figuring I would grab some yogurt in the terminal while waiting to board.</p>
<p>I got in line for security at the airport and handed the agent my ID. Another agent came over and handed me a paper slip, which he said was being used to track the length of the security lines. He said, “just hand this to someone when your stuff goes through the x-ray machines, and we’ll know how long you were in line.’ I looked at the timestamp on the paper: 10:40.</p>
<p>When going through the security line, I opted out (as I always used to) of the millimeter wave detectors. I fly often enough, and have opted out often enough, that I was prepared for what comes next: a firm pat-down by a TSA employee wearing non-latex gloves, who uses the back of his hand when patting down the inside of the thighs.</p>
<p>After the pat-down, the TSA agent swabbed his hands with some cotton-like material and put the swab in the machine that supposedly checks for explosive residue. The machine beeped. “We’re going to need to pat you down again, this time in private,” the agent said.</p>
<p>Having been selected before for so-called “random” checks, I assumed that this was another such check.</p>
<p>“What do you mean, ‘in private’? Can’t we just do this out here?”</p>
<p>“No, this is a different kind of pat-down, and we can’t do that in public.” When I asked him why this pat-down was different, he wouldn’t tell me. When I asked him specifically why he couldn’t do it in public, he said “Because it would be obscene.”</p>
<p>Naturally, I balked at the thought of going somewhere behind closed doors where a person I just met was going to touch me in “obscene” ways. I didn’t know at the time (and the agent never bothered to tell me) that the TSA has a policy that requires two agents to be present during every private pat-down. I’m not sure if that would make me feel more or less comfortable.</p>
<p>Noticing my hesitation, the agent offered to have his supervisor explain the procedure in more detail. He brought over his supervisor, a rather harried man who, instead of explaining the pat-down to me, rather rudely explained to me that I could either submit immediately to a pat-down behind closed-doors, or he could call the police.</p>
<p>At this point, I didn’t mind having to leave the secure area and go back through security again (this time not opting out of the machines), but I didn’t particularly want to get the cops involved. I told him, “Okay, fine, I’ll leave”.</p>
<p>“You can’t leave here.”</p>
<p>“Are you detaining me, then?” I’ve been through enough “<a href="https://www.flexyourrights.org/" target="_blank" rel="noopener">know your rights</a>” training to know how to handle police searches; however, TSA agents are not law enforcement officials. Technically, they don’t even have the right to detain you against your will.</p>
<p>“We’re not detaining you. You just can’t leave.” My jaw dropped.</p>
<p>“Either you’re detaining me, or I’m free to go. Which one is it?” I asked.</p>
<p>He glanced for a moment at my backpack, then snatched it out of the conveyor belt. “Okay,” he said. “You can leave, but I’m keeping your bag.”</p>
<p>I was speechless. My bag had both my work computer and my personal computer in it. The only way for me to get it back from him would be to snatch it back, at which point he could simply claim that I had assaulted him. I was trapped.</p>
<p>While we waited for the police to arrive, I took my phone and quickly tried to call my parents to let them know what was happening. Unfortunately, my mom’s voicemail was full, and my dad had never even set his up.</p>
<p>“Hey, what’s he doing?” One of the TSA agents had noticed I was touching my phone.<br>
“It’s probably fine; he’s leaving anyway,” another said.</p>
<p>The cops arrived a few minutes later, spoke with the TSA agents for a moment, and then came over and gave me one last chance to submit to the private examination. “Otherwise, we have to escort you out of the building.” I asked him if he could be present while the TSA agent was patting me down.</p>
<p>“No,” he explained, “because when we pat people down, it’s to lock them up.”</p>
<p>I only realized the significance of that explanation later. At this point, I didn’t particularly want to miss my flight. Foolishly, I said, “Fine, I’ll do it.”</p>
<p>The TSA agents and police escorted me to a holding room, where they patted me down again – this time using the front of their hands as they passed down the front of my pants. While they patted me down, they asked me some basic questions.</p>
<p>“What’s the purpose of your travel?”</p>
<p>“Personal,” I responded, (as opposed to business).</p>
<p>“Are you traveling with anybody?”</p>
<p>“My parents are on their way to LA right now; I’m meeting them there.”</p>
<p>“How long is your trip?”</p>
<p>“Ten days.”</p>
<p>“What will you be doing?”</p>
<p>Mentally, I sighed. There wasn’t any other way I could answer this next question.</p>
<p>“We’ll be visiting some temples.” He raised his eyebrow, and I explained that the next week was a religious holiday, and that I was traveling to LA to observe it with my family.</p>
<p>After patting me down, they swabbed not only their hands, but also my backpack, shoes, wallet, and belongings, and then walked out of the room to put it through the machine again. After more than five minutes, I started to wonder why they hadn’t said anything, so I asked the police officer who was guarding the door. He called over the TSA agent, who told me,</p>
<p>“You’re still setting off the alarm. We need to call the explosives specialist”.</p>
<p>I waited for about ten minutes before the specialist showed up. He walked in without a word, grabbed the bins with my possessions, and started to leave. Unlike the other agents I’d seen, he wasn’t wearing a uniform, so I was a bit taken aback.</p>
<p>“What’s happening?” I asked.</p>
<p>“I’m running it through the x-ray again,” he snapped. “Because I can. And I’m going to do it again, and again, until I decide I’m done”. He then asked the TSA agents whether they had patted me down. They said they had, and he just said, “Well, try again”, and left the room. Again I was told to stand with my legs apart and my hands extended horizontally while they patted me down all over before stepping outside.</p>
<p>The explosives specialist walked back into the room and asked me why my clothes were testing positive for explosives. I told him, quite truthfully, “I don’t know.” He asked me what I had done earlier in the day.</p>
<p>“Well, I had to pack my suitcase, and also clean my apartment.”</p>
<p>“And yesterday?”</p>
<p>“I moved my stuff from my old apartment to my new one”.</p>
<p>“What did you eat this morning?”</p>
<p>“Nothing,” I said. Only later did I realize that this made it sound like I was fasting, when in reality, I just hadn’t had breakfast yet.</p>
<p>“Are you taking any medications?”</p>
<p>The other TSA agents stood and listened while the explosives specialist and asked every medication I had taken “recently”, both prescription and over-the-counter, and asked me to explain any medical conditions for which any prescription medicine had been prescribed. Even though I wasn’t carrying any medication on me, he still asked for my complete “recent” medical history.</p>
<p>“What have you touched that would cause you to test positive for certain explosives?”</p>
<p>“I can’t think of anything. What does it say is triggering the alarm?” I asked.</p>
<p>“I’m not going to tell you! It’s right here on my sheet, but I don’t have to tell you what it is!” he exclaimed, pointing at his clipboard.</p>
<p>I was at a loss for words. The first thing that came to my mind was, “Well, I haven’t touched any explosives, but if I don’t even know what chemical we’re talking about, I don’t know how to figure out why the tests are picking it up.”</p>
<p>He didn’t like this answer, so he told them to run my belongings through the x-ray machine and pat me down again, then left the room.</p>
<p>I glanced at my watch. Boarding would start in fifteen minutes, and I hadn’t even had anything to eat. A TSA officer in the room noticed me craning my neck to look at my watch on the table, and he said, “Don’t worry, they’ll hold the flight.”</p>
<p>As they patted me down for the fourth time, a female TSA agent asked me for my baggage claim ticket. I handed it to her, and she told me that a woman from JetBlue corporate security needed to ask me some questions as well. I was a bit surprised, but agreed. After the pat-down, the JetBlue representative walked in and cooly introduced herself by name.</p>
<p>She explained, “We have some questions for you to determine whether or not you’re permitted to fly today. Have you flown on JetBlue before?”</p>
<p>“Yes”</p>
<p>“How often?”</p>
<p>“Maybe about ten times,” I guessed.</p>
<p>“Ten what? Per month?”</p>
<p>“No, ten times total.”</p>
<p>She paused, then asked,</p>
<p>“Will you have any trouble following the instructions of the crew and flight attendants on board the flight?”</p>
<p>“No.” I had no idea why this would even be in doubt.</p>
<p>“We have some female …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://adityamukerjee.net/2013/08/22/dont-fly-during-ramadan/">https://adityamukerjee.net/2013/08/22/dont-fly-during-ramadan/</a></em></p>]]>
            </description>
            <link>https://adityamukerjee.net/2013/08/22/dont-fly-during-ramadan/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23625215</guid>
            <pubDate>Wed, 24 Jun 2020 07:43:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Staring into the COM Abyss]]>
            </title>
            <description>
<![CDATA[
Score 76 | Comments 66 (<a href="https://news.ycombinator.com/item?id=23623994">thread link</a>) | @todsacerdoti
<br/>
June 23, 2020 | https://cmpct.info/~calvin/Articles/COMAbyss/ | <a href="https://web.archive.org/web/*/https://cmpct.info/~calvin/Articles/COMAbyss/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
		
		<p>
			If you're aware of how software is developed on Windows, chances are you're eventually going to run into COM. While Windows exposes some simple C APIs (and these APIs were much better than its contemporaries like Toolbox, X, or Intuition), pretty much anything more complex than USER32 is exposed through COM interfaces, from Internet Explorer to DirectX. COM is also used to <em>extend</em> applications too: Office, Visual Studio, even the Windows shell provide COM interfaces to applications to hook into. Microsoft loves using COM for everything in Windows, even if third-parties don't like it as much (Usually, out of portability/complexity reasons.). Using COM to its full extent can <a href="https://www.joelonsoftware.com/2009/09/23/the-duct-tape-programmer/">make your application 34% sparklier</a>, but it's a lot of work to properly use those interfaces (and there's a lot of them!).
		</p>
		<p>
			Unfortunately not many were able to take advantage of COM, let alone in more obscure scenarios such as extending the shell. The people who could do so were quite rare, as Spolsky pointed out. Naturally, I was <a href="https://xkcd.com/356/">nerd sniped</a> by a friend to write a <a href="https://docs.microsoft.com/en-us/windows/win32/shell/nse-works">shell namespace extension</a>, one of the more obscure (little documentation, few did it, few know they exist) categories of COM extension. A shell namespace extension adds a "namespace" (basically virtual folder) to the shell, which has further objects represented in it. Common use cases for them include MTP for phones, inline ZIP file viewing, etc.
		</p>
		<p>
			My extension was simple enough I thought I could implement it (and I did... with difficulty, as you'll see) myself. It would enumerate all the open Windows Explorer windows, and put links to them in a namespace. The point of this is that this was accessible from the stock system file dialogs, which is useful if you have a bunch of Explorer windows open, but want to save to one of them quickly. This was inspired by an OS/2 Workplace Shell feature (the one good feature of OS/2!). The challenge was going from a bare minimum knowledge of COM to knowing just enough to be <del>dangerous</del> able to make a shell namespace extension that works.
		</p>
		<img src="https://cmpct.info/~calvin/Articles/COMAbyss/os2-version.jpg" alt="The OS/2 feature" title="The OS/2 feature">
		<h2>A Brief Primer on COM</h2>
		<p>
			For something with a near-legendary reputation of complexity, it turns out COM is actually based on some very simple primitives. COM is based on interfaces (in the C++ manner) that implement vtables (a structure full of functions). These interfaces have a fixed shape, so they can be used from C. Every COM class implements the interface <code>IUnknown</code>, which implements three functions:
		</p>
		<ul>
			<li><code>AddRef</code>, which increments the reference count. Every COM object is reference counted, so you'll use this when you make a copy of a held-on reference.</li>
			<li><code>Release</code>, which decrements the reference count. The object frees itself when the count hits zero.</li>
			<li><code>QueryInterface</code>, which gives you the vtable of another interface if the object implements it (casting). The interfaces are identified by a GUID.</li>
		</ul>
		<p>
			This isn't so bad. Of course, objects can implement a <em>lot</em> of interfaces, and because interfaces have a fixed shape, to extend an interface later, you have to create another interface. Microsoft ends up numbering them, so you get into situations where you have an <a href="https://docs.microsoft.com/en-us/windows/win32/api/shobjidl_core/nn-shobjidl_core-ishellfolder2"><code>IShellFolder2</code></a>. And as Microsoft implements more features that require more interfaces, a class can get unwieldy if you're not careful. And then you have to assume the interfaces are well documented! And for extensibility, debugging isn't (as far as I'm aware) very great beyond printf macros.
		</p>
		<p>
			COM classes are registered (that's what REGSVR32 is for), where they become known by other applications. A <a href="https://docs.microsoft.com/en-us/windows/win32/midl/com-dcom-and-type-libraries">type library</a> provides metadata, and is usually generated by an IDL file.
		</p>
		<p>
			While you can use COM from C, it can get a bit unwieldy, because COM benefits from an environment of RAII and scoped destructors. ATL provides a template-based wrapper around COM for C++, and is what Microsoft recommends for COM development. Visual Studio greatly assists in terms of generating the boilerplate for categories of COM classes.
		</p>
		<h2>Do You Eat Your Burgers With or Without the Shell?</h2>
		<p>
			The beautiful part of Windows is how extensible it is. The ugly part of Windows is how no one can extend it properly. Trying to write a shell namespace extension from scratch is a Sisyphean endeavour. I don't think anyone's done it. Instead, you have to do things like your average Windows programmer in 2002 would have done - read someone much smarter than you's <a href="https://www.codeproject.com/Articles/1649/The-Complete-Idiot-s-Guide-to-Writing-Namespace-Ex">article on CodeProject</a>, the site people copied and pasted from <em>before</em> Stack Overflow. His examples are helpful, but they have a critical flaw - they implement the list view on their own, instead of delegating out to the interface which handles using the stock one and its default behaviours for you. (For example, the example will crash on XP and newer because it doesn't handle the new ListView views.) Insightful, but back to the drawing board.
		</p>
		<p>
			Round two. The <a href="https://www.codeproject.com/Articles/7973/An-almost-complete-Namespace-Extension-Sample">example by Pascal Hurni</a> is while slightly rougher, closer to what we want. His example uses the system ShellView, which gives you default behaviours and the ability to use it from a stock file dialog, which is what we want. The example enumerates through the registry (specifically, favourites for the file manager <a href="https://www.gpsoft.com.au/">Directory Opus</a>) and represents real filesystem entities, which is close to what we want - just swap out the enumerator.
		</p>
		<p>
			I took some code I wrote for experimenting with actually listing Explorer windows. First I thought I'd have to enumerate all visible windows and filter on <code>CabinetWClass</code>, then figure out what messages to send to it in order to get useful information out, but it turns out an easier way was possible through COM. You create an instance of <code>IShellWindows</code>, then call <code>get_Count</code> and <code>Item</code>, which returns an <code>IDispatch</code> representing your window. <code>IDispatch</code> is essentially <code>IUnknown</code> with reflection, intended for situations like VBA where you want to enumerate methods and properties. We can cast it to an <code>IWebBrowser</code> (a remnant of when Internet Explorer and Windows Explorer were welded together), and get the location from there. Grafting it onto Pascal's example (and ripping out what code I didn't need for clarity), I had a working MVP (with bugs, of course)
		</p>
		<img src="https://cmpct.info/~calvin/Articles/COMAbyss/explorer-windows.png" alt="Windows XP, opened Explorer windows" title="Windows XP, opened Explorer windows">
		<h2>PIDLy Details</h2>
		<p>
			I <del>cargo-culted (first step of learning)</del> learned some things about the shell, and there's still a lot more I don't know about. Tip of the iceberg as follows:
		</p>
		<ul>
			<li>A PIDL is basically an ID used by Explorer to represent items, since entities may not have real FS representation. A PIDL is basically a free-form struct that has what you want tagged with its size, and what your NSE will use to identify items. They can be absolute or relative (where it only matters to you), like a path.</li>
			<li>It likes to request wrapped PIDLs in the form of <code>IDataObject</code>, one of those can-contain-anything OLE structures usually used for the clipboard.</li>
			<li>Namespaces can be registered at a <em>junction point</em>, which makes it accessible from places other than making a shortcut to its CLSID (GUID). There's also some ceremony in registering the namespace at all; there's a registry resource script that gets called whenever the DLL is registered to make it easier. Some information on creating namespaces (but from a customizer's perspective, so pointing it at existing locations) and making it known in places is available <a href="http://virtualplastic.net/html/ui_shell.html">here</a>.</li>
			<li>Some software (cough, Office) requires an NSE represent a real location before it'll show it. The example works around this by using the temporary directory as a physical manifestation. This can result in weird behaviour, but it's the price to pay to have it work.</li>
			<li>Late in XP's lifecycle and especially Vista, Microsoft extended the column scheme to have property keys. These represent metadata more faithfully, can be extended, and is actively used for search. Namespace extensions can of course, implement these. However, it's not clear on what's the bare minimum you implement to get things like tile view subtitles working. You're almost led to believe you need an <code>IPropertyStore</code> and XML file representing custom metadata columns, but I was seemingly lucky enough I could just use built-in property keys and (I believe) the real filesystem entities have their metadata fill in. I just had to map the (most; I didn't notice anything bad from not mapping everything) column IDs I was using to the system included property keys and handle the property keys that resolve to other property keys for what to display on tiles and such.</li>
		</ul>
		<p>
			The real sad part is for things like this, because the documentation is so lacking/missing, is that you may run into issues where not even Stack Overflow can help you. Experimentation or blind trust in ancient Usenet posts may be required. Or maybe you can be lucky enough to know someone who was there, remembers, and still cares. Remember, not many at the time knew how to use these effectively, and the number of people who do dwindles, to a point of extinction, another point to the <a href="https://www.devever.net/~hl/windowsdefeat">cultural defeat of Windows</a>.
		</p>
		<p>
			I also found <a href="https://www.viksoe.dk/code/regfolder.htm">someone who implemented a wrapper class library and a bunch of samples around them</a>, which probably would be handy if I didn't discover it <em>after</em> actually managing to make it. It might have been useful, but it does a lot for you, so perhaps it was for the best to understand how the shell/COM works at a lower level.
		</p>
		<h2>IActuallyDidIt2</h2>
		<p>
			I managed to actually write the extension. It's available <a href="https://github.com/NattyNarwhal/OpenWindows">on GitHub</a>, and I hope it provides a clearer example of a shell namespace extension (since you're likely not going to find many, let alone many who know it) as well as be useful to Explorer freaks. I had also contacted Pascal about the licensing ambiguities (since people just did open source in Windows circles by the edge of their seats back then) - it's MIT licensed for sure. Now you know how the ISausage is made, and it is delicious - if only people could figure out the best way to eat it.
		</p>
		<img src="https://cmpct.info/~calvin/Articles/COMAbyss/save-dialog.png" alt="Windows Vista, save dialog" title="Windows Vista, save dialog">
	

</div>]]>
            </description>
            <link>https://cmpct.info/~calvin/Articles/COMAbyss/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23623994</guid>
            <pubDate>Wed, 24 Jun 2020 04:08:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Prescriptions Are a Dead End]]>
            </title>
            <description>
<![CDATA[
Score 44 | Comments 29 (<a href="https://news.ycombinator.com/item?id=23623306">thread link</a>) | @gbasin
<br/>
June 23, 2020 | https://garybasin.com/prescriptions-are-a-dead-end/ | <a href="https://web.archive.org/web/*/https://garybasin.com/prescriptions-are-a-dead-end/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-1988">
		<div>
		<!-- .entry-header -->

		<div>
			
<p>I love to read about how great people accomplish great things. It’s similar to getting advice — I’m left with a high. I imagine that if I can follow the instructions, then I too will accomplish what they have. It’s a logical and tantalizing idea: follow the prescription, get the reward. In practice, it tends to fall short.</p>



<p>Kapil Gupta and Naval did a <a href="https://youtu.be/sBtuqpNZwio" data-rel="lightbox-video-0">great interview</a> where they touched on this pitfall. </p>



<p>The catch is, to achieve something truly remarkable, you have to do something new. It’s practically in the definition. Copying others can help you learn a domain. Imitation is good practice. But to do something new — to create art — you inevitably have to write your own script.</p>



<p>I expanded on these thoughts in a <a href="https://twitter.com/garybasin/status/1274859897826488322?s=19">Twitter thread here</a>, also touching on how prescriptions can act like false Gods.</p>
					</div><!-- .entry-content -->

		<!-- .entry-meta -->
	</div>

	
</article></div>]]>
            </description>
            <link>https://garybasin.com/prescriptions-are-a-dead-end/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23623306</guid>
            <pubDate>Wed, 24 Jun 2020 02:30:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Bastions on demand in an AWS VPC]]>
            </title>
            <description>
<![CDATA[
Score 34 | Comments 31 (<a href="https://news.ycombinator.com/item?id=23622728">thread link</a>) | @mooreds
<br/>
June 23, 2020 | https://theconsultingcto.com/posts/bastions-on-demand/ | <a href="https://web.archive.org/web/*/https://theconsultingcto.com/posts/bastions-on-demand/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <p>Any time you have a VPC, you’ll likely need some way to gain access to the resources within the VPC from your local box. Typically, the way to do that is to run a bastion (or jumpbox) which you and your team can SSH into. The downside is that you are exposing an entry point into your network that is accessible by multiple people and running 24x7. And depending on how you manage permissions, you may not be able to restrict access to the box via IAM. Obviously, this is not ideal.</p>
<p>Luckily, we have <a href="https://aws.amazon.com/fargate/">Fargate</a>.</p>
<p>With Fargate, we no longer need to maintain permanent bastion instances—we can create bastions when needed and tear them down when no longer in use. We can lock down bastion instances to an individual user both in terms of SSH keys and IP address. And we can restrict access via IAM to both the API used to manage bastions and to which SSH keys are used to log into an instance.</p>
<p>All in all, we save on infrastructure spend while reducing our attack surface.</p>
<p>Throughout this guide, I’ll be referencing the code from my <a href="https://github.com/jdhollis/bastions-on-demand/"><code>bastions-on-demand</code></a> repo. If you want to skip the explanation, just clone it and follow the directions in the <a href="https://github.com/jdhollis/bastions-on-demand/blob/master/README.md">README.md</a> to get started.</p>
<p>If you run into any trouble, <a href="https://github.com/jdhollis/bastions-on-demand/issues/new/choose">create an issue</a>, and I’ll respond as best I can.</p>
<p>Otherwise, buckle up. This is going to be a bit in-depth.</p>
<h2 id="architecture">Architecture</h2>
<p>There are two key components to bastions on demand—<a href="https://github.com/jdhollis/bastions-on-demand/tree/master/bastion">the infrastructure for managing the bastion image</a> and <a href="https://github.com/jdhollis/bastions-on-demand/tree/master/service">the bastion service itself</a>.</p>
<p>The <a href="#container-infrastructure">container infrastructure</a> consists of an <a href="https://aws.amazon.com/ecr/">ECR</a> repository, a Docker container, an IAM role for fetching a user’s public keys, and scripts for building and pushing images. Typically, I share this infrastructure across multiple services because the requirements don’t vary much. But if a team wants complete service isolation or needs to customize their bastion image, it’s trivial to make that work.</p>
<p>The <a href="#bastion-service">bastion service</a> consists of an <a href="https://aws.amazon.com/ecs/">ECS</a> task, a task role that enables access to any required resources, an API to create and destroy bastion instances, and a set of scripts to make it easy for team members to do just that. The bastion service module should be included in any service that needs bastions—keep it in the service’s repository for ease of access and deploy it alongside the parent service.</p>
<p>Naturally, all of this infrastructure is managed with <a href="https://www.terraform.io/">Terraform</a>.</p>
<p>I owe a debt of gratitude to the following authors as they provided valuable examples that helped me develop this approach:</p>
<ul>
<li><a href="https://ig.nore.me/2018/07/serverless-bastions-on-demand/">Serverless Bastions on Demand</a> &amp; <a href="https://github.com/ArjenSchwarz/workshop-fargate-bastion">ArjenSchwarz/workshop-fargate-bastion</a></li>
<li><a href="https://github.com/alex0ptr/fargate-bastion">alex0ptr/fargate-bastion</a></li>
<li><a href="https://cloudonaut.io/manage-aws-ec2-ssh-access-with-iam/">Manage AWS EC2 SSH access with IAM</a></li>
</ul>
<p>While I recommend using multiple AWS accounts for security and isolation, in this guide, I’m going to use a single account so that we can focus on the essentials. If there’s interest, I will address how to modify this approach for use with multiple accounts in a separate guide. Everything in this guide assumes you’re using the <code>default</code> profile, but you can override via the <code>AWS_PROFILE</code> environment variable.</p>
<p>I’m also deliberately not using <a href="https://www.terraform.io/docs/state/remote.html">Terraform remote state</a> in this guide to make it easier for you to try out my code. If you’re going to use this in a live account, you absolutely should use remote state—insert your own backend configuration where appropriate. And if you don’t have a remote backend, have a look at my <a href="https://github.com/jdhollis/remote-state">remote-state</a> repo for an example of how to set one up on S3 with DynamoDB and KMS.</p>
<p>Now, let’s get started.</p>
<h2 id="initial-setup">Initial Setup</h2>
<p>If you haven’t already, create a role for API Gateway logging:</p>
<section>
<div><pre><code data-lang="hcl"><span>data</span> <span>"aws_iam_policy_document" "assume_role"</span> {
  <span>statement</span> {
    actions <span>=</span> [<span>"sts:AssumeRole"</span>]

    <span>principals</span> {
      identifiers <span>=</span> [<span>"apigateway.amazonaws.com"</span>]
      type        <span>=</span> <span>"Service"</span>
    }
  }
}

<span>data</span> <span>"aws_iam_policy_document" "logger"</span> {
  <span>statement</span> {
    actions <span>=</span> [
      <span>"logs:CreateLogGroup"</span>,
      <span>"logs:CreateLogStream"</span>,
      <span>"logs:DescribeLogGroups"</span>,
      <span>"logs:DescribeLogStreams"</span>,
      <span>"logs:FilterLogEvents"</span>,
      <span>"logs:GetLogEvents"</span>,
      <span>"logs:PutLogEvents"</span>,
    ]

    resources <span>=</span> [<span>"*"</span>]
  }
}

<span>resource</span> <span>"aws_iam_role" "logger"</span> {
  name               <span>=</span> <span>"api-gateway-cloudwatch-logger"</span>
  assume_role_policy <span>=</span> <span>data</span>.<span>aws_iam_policy_document</span>.<span>assume_role</span>.<span>json</span>
}

<span>resource</span> <span>"aws_iam_role_policy" "logger"</span> {
  name   <span>=</span> <span>"api-gateway-cloudwatch-logger"</span>
  policy <span>=</span> <span>data</span>.<span>aws_iam_policy_document</span>.<span>logger</span>.<span>json</span>
  role   <span>=</span> <span>aws_iam_role</span>.<span>logger</span>.<span>name</span>
}

<span>resource</span> <span>"aws_api_gateway_account" "global"</span> {
  cloudwatch_role_arn <span>=</span> <span>aws_iam_role</span>.<span>logger</span>.<span>arn</span>
}
</code></pre></div>  
</section>
<p>Logging API Gateway access is a good idea in general. Unfortunately, this is a global account setting, so use with caution. API Gateway has a lot of stateful corners. I typically manage this logger in a separate repository since it’s shared across all services running in an account.</p>
<h2 id="container-infrastructure">Container Infrastructure</h2>
<p>Creating the ECR repository is straightforward:</p>
<section>
<div><pre><code data-lang="hcl"><span>resource</span> <span>"aws_ecr_repository" "bastion"</span> {
  name <span>=</span> <span>"bastion"</span>
}
</code></pre></div>  
</section>
<p>Next we need to create a role that can fetch a user’s public keys.</p>
<section>
<div><pre><code data-lang="hcl"><span>data</span> <span>"aws_caller_identity" "env"</span> {}<span>
</span><span>
</span><span># …
</span><span></span>
<span>data</span> <span>"aws_iam_policy_document" "assume_role"</span> {
  <span>statement</span> {
    actions <span>=</span> [<span>"sts:AssumeRole"</span>]

    <span>principals</span> {
      identifiers <span>=</span> [<span>"arn:aws:iam::${data.aws_caller_identity.env.account_id}:root"</span>]
      type        <span>=</span> <span>"AWS"</span>
    }
  }
}

<span>data</span> <span>"aws_iam_policy_document" "public_key_fetcher"</span> {
  <span>statement</span> {
    actions <span>=</span> [
      <span>"iam:GetSSHPublicKey"</span>,
      <span>"iam:ListSSHPublicKeys"</span>,
    ]

    resources <span>=</span> [<span>"arn:aws:iam::${data.aws_caller_identity.env.account_id}:user/*"</span>]
  }
}

<span>resource</span> <span>"aws_iam_role" "public_key_fetcher"</span> {
  name               <span>=</span> <span>"public-key-fetcher"</span>
  assume_role_policy <span>=</span> <span>data</span>.<span>aws_iam_policy_document</span>.<span>assume_role</span>.<span>json</span>
}

<span>resource</span> <span>"aws_iam_role_policy" "public_key_fetcher"</span> {
  name   <span>=</span> <span>"public-key-fetcher"</span>
  policy <span>=</span> <span>data</span>.<span>aws_iam_policy_document</span>.<span>public_key_fetcher</span>.<span>json</span>
  role   <span>=</span> <span>aws_iam_role</span>.<span>public_key_fetcher</span>.<span>id</span>
}
</code></pre></div>  
</section>
<p>This role will be used by the bastion instance to fetch a user’s keys when the user attempts to SSH into the instance, as we’ll see below.</p>
<h3 id="dockerfile">Dockerfile</h3>
<p>Creating the container image is fairly straightforward. We start with <a href="https://alpinelinux.org/">Alpine Linux</a> because it’s small and security-oriented and add the scripts we’ll need to start <code>sshd</code> and handle login.</p>
<section>
<div><pre><code data-lang="dockerfile"><span>FROM</span><span> alpine:3.11</span><span>
</span><span>
</span><span></span><span>WORKDIR</span><span> /root</span><span>
</span><span>
</span><span></span><span>ADD</span> fetch_authorized_keys.sh /usr/local/bin/fetch_authorized_keys.sh<span>
</span><span></span><span>ADD</span> entrypoint.sh /usr/local/bin/entrypoint.sh<span>
</span></code></pre></div>  
</section>
<p>Next, we install dependencies including the <a href="https://aws.amazon.com/cli/">AWS CLI</a>. If you typically need any other packages for your bastion, add ‘em to the list. (It still bugs me that AWS doesn’t provide checksums for its CLI bundle. Oh well.)</p>
<section>
<div><pre><code data-lang="dockerfile"><span>RUN</span> <span>echo</span> <span>"Installing dependencies..."</span> <span>&amp;&amp;</span> <span>\
</span><span></span>  apk --no-cache <span>\
</span><span></span>    add <span>\
</span><span></span>      bash <span>\
</span><span></span>      curl <span>\
</span><span></span>      openssh <span>\
</span><span></span>      python <span>\
</span><span></span>      tini <span>\
</span><span></span>  <span>&amp;&amp;</span> <span>\
</span><span></span>  <span>echo</span> <span>"Installing AWS CLI..."</span> <span>&amp;&amp;</span> <span>\
</span><span></span>  wget https://s3.amazonaws.com/aws-cli/awscli-bundle.zip <span>&amp;&amp;</span> <span>\
</span><span></span>  unzip awscli-bundle.zip <span>&amp;&amp;</span> <span>\
</span><span></span>  rm awscli-bundle.zip <span>&amp;&amp;</span> <span>\
</span><span></span>  ./awscli-bundle/install -i /usr/local/aws -b /usr/local/bin/aws <span>&amp;&amp;</span> <span>\
</span><span></span>  rm -R awscli-bundle <span>&amp;&amp;</span> <span>\
</span><span></span>  /usr/local/bin/aws --version<span>
</span></code></pre></div>  
</section>
<p>Now we need a user to log in as.</p>
<p>You could use <code>root</code>. I have in the past with small teams that needed the additional flexibility. But if you’re providing an image to teams that are independent of whoever handles security, you don’t necessarily want people making changes to the bastion that could open up holes in your network.</p>
<p>Instead, we create a user named <code>ops</code> and unlock the account for login.</p>
<section>
<div><pre><code data-lang="dockerfile"><span>RUN</span> <span>echo</span> <span>"Creating user \"ops\"..."</span> <span>&amp;&amp;</span> <span>\
</span><span></span>  adduser ops --disabled-password<span>
</span><span>
</span><span></span><span>RUN</span> <span>echo</span> <span>"Unlocking \"ops\"..."</span> <span>&amp;&amp;</span> <span>\
</span><span></span>  sed -i <span>"s/ops:!:/ops:*:/g"</span> /etc/shadow<span>
</span></code></pre></div>  
</section>
<p>With that out of the way, we now configure <code>sshd</code>.</p>
<section>
<div><pre><code data-lang="dockerfile"><span>RUN</span> <span>echo</span> <span>"Configuring sshd..."</span> <span>&amp;&amp;</span> <span>\
</span><span></span>  sed -i <span>"s:#AuthorizedKeysCommand none:AuthorizedKeysCommand /usr/local/bin/fetch_authorized_keys.sh:g"</span> /etc/ssh/sshd_config <span>&amp;&amp;</span> <span>\
</span><span></span>  sed -i <span>"s:#AuthorizedKeysCommandUser nobody:AuthorizedKeysCommandUser nobody:g"</span> /etc/ssh/sshd_config <span>&amp;&amp;</span> <span>\
</span><span></span>  sed -i <span>"s:#GatewayPorts no:GatewayPorts yes:g"</span> /etc/ssh/sshd_config <span>&amp;&amp;</span> <span>\
</span><span></span>  sed -i <span>"s:#PasswordAuthentication yes:PasswordAuthentication no:g"</span> /etc/ssh/sshd_config <span>&amp;&amp;</span> <span>\
</span><span></span>  sed -i <span>"s:#PermitTunnel no:PermitTunnel yes:g"</span> /etc/ssh/sshd_config <span>&amp;&amp;</span> <span>\
</span><span></span>  sed -i <span>"s:AllowTcpForwarding no:AllowTcpForwarding yes:g"</span> /etc/ssh/sshd_config <span>&amp;&amp;</span> <span>\
</span><span></span>  sed -i <span>"s:AuthorizedKeysFile .ssh/authorized_keys:AuthorizedKeysFile none:g"</span> /etc/ssh/sshd_config<span>
</span></code></pre></div>  
</section>
<p>We’re configuring <code>sshd</code> to do a few different things.</p>
<p>We’re setting the <code>AuthorizedKeysCommand</code> to use <code>fetch_authorized_keys.sh</code>, and we’re disabling both password logins and the ability to use an <code>AuthorizedKeysFile</code> on the instance. The intention here is to make it possible to only use the logic in <code>fetch_authorized_keys.sh</code> to authenticate the user.</p>
<p>We’re also setting <code>sshd</code> up for proxying.</p>
<p>Finally, we configure the <code>ENTRYPOINT</code>:</p>
<section>
<div><pre><code data-lang="dockerfile"><span>ENTRYPOINT</span> [ <span>"/sbin/tini"</span>, <span>"--"</span> ]<span>
</span><span></span><span>CMD</span> [ <span>"/bin/sh"</span>, <span>"/usr/local/bin/entrypoint.sh"</span> ]<span>
</span></code></pre></div>  
</section>
<p>The only interesting thing here is we’re using <a href="https://github.com/krallin/tini"><code>tini</code></a>. If you’re interested in why, check out <a href="https://github.com/krallin/tini/issues/8">this GitHub issue</a>.</p>
<h3 id="entrypointsh">entrypoint.sh</h3>
<p>On container startup, the first thing we need to do is generate host keys.</p>
<section>
  
</section>
<p>Then we export the global environment which includes the AWS credentials injected into the container, the role for fetching SSH keys, and the user name of the person for whom this bastion instance is intended.</p>
<section>
<div><pre><code data-lang="sh"><span>echo</span> <span>"export AWS_CONTAINER_CREDENTIALS_RELATIVE_URI=</span><span>$AWS_CONTAINER_CREDENTIALS_RELATIVE_URI</span><span>"</span> &gt; /etc/profile.d/authorized_keys_configuration.sh
<span>echo</span> <span>"export AWS_DEFAULT_REGION=</span><span>$AWS_DEFAULT_REGION</span><span>"</span> &gt;&gt; /etc/profile.d/authorized_keys_configuration.sh
<span>echo</span> <span>"export AWS_EXECUTION_ENV=</span><span>$AWS_EXECUTION_ENV</span><span>"</span> &gt;&gt; /etc/profile.d/authorized_keys_configuration.sh
<span>echo</span> <span>"export AWS_REGION=</span><span>$AWS_REGION</span><span>"</span> &gt;&gt; /etc/profile.d/authorized_keys_configuration.sh
<span>echo</span> <span>"export ECS_CONTAINER_METADATA_URI=</span><span>$ECS_CONTAINER_METADATA_URI</span><span>"</span> &gt;&gt; /etc/profile.d/authorized_keys_configuration.sh
<span>echo</span> <span>"export ASSUME_ROLE_FOR_AUTHORIZED_KEYS=</span><span>$ASSUME_ROLE_FOR_AUTHORIZED_KEYS</span><span>"</span> &gt;&gt; /etc/profile.d/authorized_keys_configuration.sh
<span>echo</span> <span>"export USER_NAME=</span><span>$USER_NAME</span><span>"</span> &gt;&gt; /etc/profile.d/authorized_keys_configuration.sh
</code></pre></div>  
</section>
<p>Because <code>fet…</code></p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://theconsultingcto.com/posts/bastions-on-demand/">https://theconsultingcto.com/posts/bastions-on-demand/</a></em></p>]]>
            </description>
            <link>https://theconsultingcto.com/posts/bastions-on-demand/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23622728</guid>
            <pubDate>Wed, 24 Jun 2020 01:11:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How effective communication can be achieved in a digital work environment]]>
            </title>
            <description>
<![CDATA[
Score 38 | Comments 2 (<a href="https://news.ycombinator.com/item?id=23622241">thread link</a>) | @markshepard
<br/>
June 23, 2020 | https://www.airsend.io/blog/index.php/2020/05/24/1-tip-on-how-effective-communication-can-be-achieved-in-a-digital-work-environment/ | <a href="https://web.archive.org/web/*/https://www.airsend.io/blog/index.php/2020/05/24/1-tip-on-how-effective-communication-can-be-achieved-in-a-digital-work-environment/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-1668">
	

	




	<div>
		
<div><figure><img src="https://www.airsend.io/blog/wp-content/uploads/2020/05/undraw_Group_chat_unwm-3-1024x692.png" alt="" width="412" height="278" srcset="https://www.airsend.io/blog/wp-content/uploads/2020/05/undraw_Group_chat_unwm-3-1024x692.png 1024w, https://www.airsend.io/blog/wp-content/uploads/2020/05/undraw_Group_chat_unwm-3-300x203.png 300w, https://www.airsend.io/blog/wp-content/uploads/2020/05/undraw_Group_chat_unwm-3-768x519.png 768w, https://www.airsend.io/blog/wp-content/uploads/2020/05/undraw_Group_chat_unwm-3.png 1384w" sizes="(max-width: 412px) 100vw, 412px"><figcaption>Source: unDraw</figcaption></figure></div>



<p>A multi-billion dollar company. A winning presidential
campaign. A happy marriage. What do these three things have in common? The
foundation of success in each is effective communication. </p>



<p>Effective communication has the power to amass riches and
make history. With it, governments have been transformed, along with the lives
of billions of people. With it, enterprises like Amazon, Apple, and Alibaba
rise from obscurity. </p>



<p>It’s no wonder that all successful businesses need strong
communication infrastructures in order to grow and prosper. But that’s not what
this article is about. The topic of communication is so vast that you can get a
Ph.D. in it. This article would have to be a book, maybe three, to properly
cover the topic. </p>



<p>What this article focuses on is a single concept that, if
grasped, can give your organization a big push in the right direction towards
effective communication in a digital work environment. The concept is this:</p>



<blockquote><p><em>Chat is like a river; Wiki is like a dam.</em></p></blockquote>



<h2>River? Dam?</h2>



<div><figure><img src="https://www.airsend.io/blog/wp-content/uploads/2020/05/undraw_chat_1wo5-1024x734.png" alt="" width="357" height="255" srcset="https://www.airsend.io/blog/wp-content/uploads/2020/05/undraw_chat_1wo5-1024x734.png 1024w, https://www.airsend.io/blog/wp-content/uploads/2020/05/undraw_chat_1wo5-300x215.png 300w, https://www.airsend.io/blog/wp-content/uploads/2020/05/undraw_chat_1wo5-768x551.png 768w, https://www.airsend.io/blog/wp-content/uploads/2020/05/undraw_chat_1wo5.png 1109w" sizes="(max-width: 357px) 100vw, 357px"><figcaption>Source: unDraw</figcaption></figure></div>



<p>A while ago, we published an article that dives into
synchronous and asynchronous communication. Synchronous communication is communication
that happens in real time. It’s a company meeting on Zoom or an active chat
room. Asynchronous communication is communication that happens… not in real
time. It’s that email you send to a client which you know you won’t get a
response to until weeks later, or notes on that Zoom company meeting posted to
an online bulletin. Both are important because different types of information
do best in different formats. </p>



<p>Synchronous communication is fast, immediate, brief. Information
flows like a river — as it does in a chat. This format is best for times of uncertainty
and/or urgency. It’s good for exploring ideas together, having discussions to
make decisions, and addressing crisis situations. </p>



<p>Asynchronous communication is slower, usually more
considered and voluminous. Information gathers like a dam — as it does in a
Wiki. This format is best for adding context to real time communication after
it has happened, putting together detailed information, and explaining complex
concepts.</p>



<p>When used properly, synchronous and asynchronous
communication together form effective communication.</p>



<h2>Increasing Effective Communication in Your Organization</h2>



<div><figure><img src="https://www.airsend.io/blog/wp-content/uploads/2020/05/undraw_online_collaboration_7pfp.png" alt="" width="364" height="291" srcset="https://www.airsend.io/blog/wp-content/uploads/2020/05/undraw_online_collaboration_7pfp.png 1000w, https://www.airsend.io/blog/wp-content/uploads/2020/05/undraw_online_collaboration_7pfp-300x240.png 300w, https://www.airsend.io/blog/wp-content/uploads/2020/05/undraw_online_collaboration_7pfp-768x615.png 768w" sizes="(max-width: 364px) 100vw, 364px"><figcaption>Source: unDraw</figcaption></figure></div>



<p>When synchronous and asynchronous communication are used
appropriately in an organization, communication is at its best and collaboration
is smooth and easy. In a digital work environment, some of the most common modes
of communication are chat and Wiki. As mentioned before, chat facilitates
synchronous communication and a Wiki facilitates asynchronous communication. </p>



<p>Increasing effective communication in your organization is
as simple as having both chat and a Wiki available to everyone and then making
it clear which medium to use for each type of interaction. In other words, the
roadmap to achieving effective communication in a digital work environment is:</p>



<ol><li><strong>Provide
the right tools</strong> – Have chat and a Wiki available to all team members and
get everyone accustomed to using them. </li><li><strong>Ensure the tools are used correctly</strong> – Do
this by training management on the concept of synchronous and asynchronous
communication (or “<em>Chat is like a river;
Wiki is like a dam.”) </em>and have them lead by example so the rest of your organization
follows.</li></ol>



<h2>Chat and Wiki in AirSend</h2>



<p>In AirSend, each channel has both a chat section and a Wiki
section. The chat is great for quickly discussing new developments, exchanging links
to articles or tidbits of information, and scheduling calls for further
discussion. The Wiki is great for storing, sharing, and collaborating on more detailed,
complex items.</p>



<p>Having the chat and Wiki together in one place makes communication
much smoother and more efficient than the previous model of emailing back and
forth with document links or attachments. </p>



<figure><video controls="" src="https://www.airsend.io/blog/wp-content/uploads/2020/05/Chat-Wiki-GIF-S10.mp4"></video></figure>



<h2>Finding Balance </h2>



<p>Effective communication is powerful, and one of the key factors of communicating effectively in a digital environment is finding the balance between synchronous and asynchronous communication. When used together correctly, chat and Wiki can streamline the communication process for clutter-free collaboration, resulting in increased productivity. </p>



<p>Just remember: <em>Chat is like a river; Wiki is like a dam.</em></p>
	</div><!-- .entry-content -->

	 <!-- .entry-footer -->
</article></div>]]>
            </description>
            <link>https://www.airsend.io/blog/index.php/2020/05/24/1-tip-on-how-effective-communication-can-be-achieved-in-a-digital-work-environment/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23622241</guid>
            <pubDate>Wed, 24 Jun 2020 00:18:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Wolfram.org Is Not Wolfram.com]]>
            </title>
            <description>
<![CDATA[
Score 30 | Comments 10 (<a href="https://news.ycombinator.com/item?id=23621039">thread link</a>) | @max_
<br/>
June 23, 2020 | http://wolfram.org/business/wolframresearch.html | <a href="https://web.archive.org/web/*/http://wolfram.org/business/wolframresearch.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">







<strong><a href="http://wolfram.org/eric/" title="Eric's Biography/">Eric Wolfram</a>'s

Business: Not Wolfram Research</strong>



<!-- CONTENT STARTS HERE -->



<h2>Wolfram.org is not Wolfram.com</h2>

Once upon a time, Stephen Wolfram's assistant, Scott Koranda, offered me $4000 for my domain name -- wolfram.org. (Otherwise, this site is not affiliated with <a href="http://www.wolfram.com/">Wolfram Research</a>, Math, mathematics, mathematical functions.)

<p>

I understand from <a href="http://www.stephenwolfram.com/about-sw/">Stephen Wolfram's Biography</a> that he is a genius. He was so busy writing his book about the "future of science" that he didn't foresee the popularity of the web in 1997, which is when my friend Bill Morris registered wolfram.org for me. (hmmm) So I must have been totally lucky that he didn't register wolfram.org when he secured wolfram.com.

</p><p>

A while later, Scott Korandaan asked if he could have wolfram.org for a new school that they're building. I was disappointed when he refused my counter offer to trade wolfram.org domain for wolfram.com. I also offered to lease wolfram.org to them because I wasn't using it yet. He said no to both those offers -- of course. By then I <em>knew</em> Dr. Wolfram was smart.

</p><p>

Next, Dr. Wolfram's assistant offered to buy me ewolfram.com, and exchange it for my wolfram.org! I guess I deserved that, but I didn't write back. Only then, a few weeks later, did they offer $4000 for wolfram.org! Wow, $4k for a ".org" address -- I was impressed. But although 4k is a lot of money for something I only paid $70 for (over 2000% profit?) I didn't feel good about selling it. It is my name.

</p><p>

I figured, I got to wolfram.org first. And obviously I registered it for a reason. And $4K is chicken feed compared to a location that is mine for the annals of web history. Put it this way, after taxes, $4K is more like $2K, and $2K isn't even a months rent in San Francisco!

</p><p>

I finally did some research and discovered that Stephen Wolfram was running a $350 million dollar company and he had already registered all these other domains!

<a href="http://wolfram-science.org/">wolfram-science.org</a> ,

<a href="http://stephen-wolfram.org/">stephen-wolfram.org</a> ,

<a href="http://stephenwolfram.org/">stephenwolfram.org</a> ,

<a href="http://complex-systems.org/">complex-systems.org</a> ,

<a href="http://cellularautomata.org/">cellularautomata.org</a> ,

<a href="http://wolframscience.org/">wolframscience.org</a> ,

<a href="http://cellular-automata.org/">cellular-automata.org</a> ,

<a href="http://wolfram-institute.org/">wolfram-institute.org</a> ,

<a href="http://math-world.com/">math-world.com</a> ,

<a href="http://mathsites.com/">mathsites.com</a> ,

<a href="http://wizpower.com/">wizpower.com</a> ,

<a href="http://wri.com/">wri.com</a> ,

<a href="http://mathematica.com/">mathematica.com</a> ,

<a href="http://scienceworld.com/">scienceworld.com</a> ,

<a href="http://wolfram.com/">wolfram.com</a> ,

<a href="http://science-world.com/">science-world.com</a> ,

<a href="http://wolfram-media.com/">wolfram-media.com</a> ,

<a href="http://graphica.com/">graphica.com</a> ,

<a href="http://new-science.com/">new-science.com</a> ,

<a href="http://activesites.com/">activesites.com</a> ,

<a href="http://integrals.com/">integrals.com</a> ,

<a href="http://mathsource.com/">mathsource.com</a> ,

<a href="http://wolfram-research.com/">wolfram-research.com</a> ,

<a href="http://mathlink.com/">mathlink.com</a> ,

<a href="http://mathworld.com/">mathworld.com</a> ,

<a href="http://howabout.com/">howabout.com</a> ,

<a href="http://tgjb.com/">tgjb.com</a> ,

<a href="http://publicon.com/">publicon.com</a> ,

<a href="http://mathscript.com/">mathscript.com</a> ,

<a href="http://bignumbers.com/">bignumbers.com</a> ,

<a href="http://mathjournal.com/">mathjournal.com</a> ,

<a href="http://mathematica-journal.com/">mathematica-journal.com</a> ,

<a href="http://specialfunctions.com/">specialfunctions.com</a> ,

<a href="http://mathchat.com/">mathchat.com</a> ,

<a href="http://mathdirect.com/">mathdirect.com</a> ,

<a href="http://wolfram-science.com/">wolfram-science.com</a> ,

<a href="http://wolframresearch.com/">wolframresearch.com</a> ,

<a href="http://stephenwolfram.com/">stephenwolfram.com</a> ,

<a href="http://stephen-wolfram.com/">stephen-wolfram.com</a> ,

<a href="http://wolframscience.com/">wolframscience.com</a> ,

<a href="http://wolfram-institute.com/">wolfram-institute.com</a> ,

<a href="http://complex-systems.com/">complex-systems.com</a> ,

<a href="http://calculuswiz.com/">calculuswiz.com</a>

</p><p>

Why did he need wolfram.org too? Many of his domains still aren't in use. <b>Why would someone who wants to unify physics into a single fundamental theory need 45 domain names to unify his web pages?</b> The very thought was absurd!

</p><p>

I believe that a single web address can accomplish all that Dr. Stephen Wolfram needs to say -- his views on what science will be like this new milinium, his thoughts on creating machines that think, our hopes of finding extraterrestrial intelligence, and his views on changing the way basic science is organized. One -- maybe two or three -- domains but certainly not 45 domains. Certainly not MINE too!

</p><p>

I started to understand that Mr. Wolfram simply needed a good information designer -- not another domain name. I tried to tell him that. I tried to offer my services, which at the time, I thought were most excellent. But Mr. Wolfram's assistant insisted that they needed my domain (I know, I know -- it's the marketing people...)

</p><p>

So I went to my calculater and figured that those 44 domains they already bought had cost them $3080 to buy plus $1540 per year to maintain! Wow, they have a domain name budget! So I decided to base the price on Dr. Wolfram's net worth (I figured $100,000 was a fair point to start), and, in addition, I decided to ask for perpetual use of the email addresses eric@wolfram.org, eric@wolfram.com, and the web domains eric.wolfram.com and eric.wolfram.org.

</p><p>

I quickly got a reply. For some reason, they decided to "stop wasting both of our times", as they put it, and said "Wolfram Research and its related companies are not prepared to enter into any of the arrangements which you describe...however, in the future, if you decide that you would like to sell the wolfram.org domain, please do get in touch with me."

</p><p>

Ha! Ya right!

</p><p>

What got me was that when they frist contacted me it was "hey, I'm an assistant from a Dr. at a university who wants to open a new school" and now it's all "Wolfram Research and Related company" It's come to this?!? They did, however, sent me a copy of Mathematica and I appreciated that and thanked them! A mighty find gesture.

</p><p>

Still, I must say that I was a tad miffed because I never got to speak with the Good Doctor himself, nor did I get to discuss my views on what science will be like in the 21st century. (which he could have put in his book!) And they never sent me the signed copy of Mr. Wolfram's book, which I requested. I just waited and waited. Oh well, no one realized that the book would actually come out until 2002 -- not 1998 like they were planning. And I guess they forgot about me and my domain by now. And I probably would have read his book too...

</p><p>

In an alternate universe, however, this site might have been about math -- now it's just about me -- Eric Wolfram.

</p><p>
It's not about mathematica sdk, mathworld, partition of unity, statistics, trigonometric identities, substitution integral or a linear bounded either.



<!-- CONTENT ENDS HERE -->



</p><hr size="1">

List of <a href="http://wolfram.org/business/">Mr. Wolfram's Businesses</a>







</div>]]>
            </description>
            <link>http://wolfram.org/business/wolframresearch.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23621039</guid>
            <pubDate>Tue, 23 Jun 2020 22:14:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[What I learned from looking at every AI/ML tool I could find]]>
            </title>
            <description>
<![CDATA[
Score 451 | Comments 106 (<a href="https://news.ycombinator.com/item?id=23620757">thread link</a>) | @amrrs
<br/>
June 23, 2020 | https://huyenchip.com/2020/06/22/mlops.html | <a href="https://web.archive.org/web/*/https://huyenchip.com/2020/06/22/mlops.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
    <p>To better understand the landscape of available tools for machine learning production, I decided to look up every AI/ML tool I could find. The resources I used include:</p>

<ul>
  <li><a href="https://github.com/alirezadir/Production-Level-Deep-Learning">Full stack deep learning</a></li>
  <li><a href="https://landscape.lfai.foundation/">LF AI Foundation landscape</a></li>
  <li><a href="http://dfkoz.com/ai-data-landscape/">AI Data Landscape</a></li>
  <li>Various lists of top AI startups by the media</li>
  <li>Responses to my <a href="https://twitter.com/chipro/status/1202815757593108480">tweet</a> and <a href="https://www.linkedin.com/posts/chiphuyen_machinelearning-machinelearningproduction-activity-6608605129010753536-bdZ7">LinkedIn post</a></li>
  <li>People (friends, strangers, VCs) share with me their lists</li>
</ul>

<p>After filtering out applications companies (e.g. companies that use ML to provide business analytics), tools that aren’t being actively developed, and tools that nobody uses, I got 202 tools. See <a href="https://docs.google.com/spreadsheets/d/1OV0cMh2lmXMU9bK8qv1Kk0oWdc_Odmu2K5sOULS9hHQ/edit?usp=sharing">the full list</a>. Please let me know if there are tools you think I should include but aren’t on the list yet!</p>

<p><strong>Disclaimer</strong></p>

<ol>
  <li>This list was made in November 2019, and the market must have changed in the last 6 months.</li>
  <li>Some tech companies just have a set of tools so large that I can’t enumerate them all. For example, Amazon Web Services offer over 165 fully featured services.</li>
  <li>There are many stealth startups that I’m not aware of, and many that died before I heard of them.</li>
</ol>

<p>This post consists of 6 parts:</p>

<p>I. Overview<br>
II. The landscape over time<br>
III. The landscape is under-developed<br>
IV. Problems facing MLOps<br>
V. Open source and open-core<br>
VI. Conclusion<br></p>

<h2>I. Overview</h2>
<p><a href="https://github.com/chiphuyen/machine-learning-systems-design">In one way to generalize the ML production flow that I agreed with</a>, it consists of 4 steps:</p>

<ol>
  <li>Project setup</li>
  <li>Data pipeline</li>
  <li>Modeling &amp; training</li>
  <li>Serving</li>
</ol>

<p>I categorize the tools based on which step of the workflow that it supports. I don’t include <strong>Project setup</strong> since it requires project management tools, not ML tools. This isn’t always straightforward since one tool might help with more than one step. Their ambiguous descriptions don’t make it any easier: “we push the limits of data science”, “transforming AI projects into real-world business outcomes”, “allows data to move freely, like the air you breathe”, and my personal favorite: “we lived and breathed data science”.</p>

<p>I put the tools that cover more than one step of the pipeline into the category that they are best known for. If they’re known for multiple categories, I put them in the <strong>All-in-one</strong> category. I also include the <strong>Infrastructure</strong> category to include companies that provide infrastructure for training and storage. Most of these are Cloud providers.</p>

<h2>II. The landscape over time</h2>
<p>I tracked the year each tool was launched. If it’s an open-source project, I looked at the first commit to see when the project began its public appearance. If it’s a company, I looked at the year it started on Crunchbase. Then I plotted the number of tools in each category over time.</p>

<center>
<figure>
<img alt="MLOps over time" src="https://huyenchip.com/assets/pics/mlops/mlops_1.png">
</figure>
</center>

<p>As expected, this data shows that the space only started exploding in 2012 with the renewed interest in deep learning.</p>

<h3>Pre-AlexNet (pre-2012)</h3>
<p>Up until 2011, the space is dominated by tools for modeling and training, with some frameworks that either are still very popular (e.g. scikit-learn) or left influence on current frameworks (Theano). A few ML tools that started pre-2012 and survived until today have either had their IPOs (Cloudera, Datadog, Alteryx), been acquired (Figure Eight), or become popular open-source projects actively developed by the community (Spark, Flink, Kafka).</p>

<h3>Development phase (2012-2015)</h3>
<p>As the machine learning community took the “let’s throw data at it” approach, the ML space became the data space. This is even more clear when we look into the number of tools started each year in each category. In 2015, 57% (47 out of 82 tools) are data pipeline tools.</p>

<center>
<figure>
<img alt="Number of tools started each year" src="https://huyenchip.com/assets/pics/mlops/mlops_2.png">
</figure>
</center>

<h3>Production phase (2016-now)</h3>
<p>While it’s important to pursue pure research, most companies can’t afford it unless it leads to short-term business applications. As ML research, data, and off-the-shelf models become more accessible, more people and organizations would want to find applications for them, which increases the demand for tools to help productionize machine learning.</p>

<p>In 2016, Google announced <a href="https://ai.googleblog.com/2016/09/a-neural-network-for-machine.html">its use of neural machine translation to improve Google Translate</a>, marking the one of the first major applications of deep learning in the real world. Since then, many tools have been developed to facilitate serving ML applications.</p>

<h2>III. The landscape is under-developed</h2>
<p>While there are many AI startups, most of them are application startups (providing applications such as business analytics or customer support) instead of tooling startups (creating tools to help other companies build their own applications). Or in VC terms, most startups are vertical AI. Among <a href="https://www.forbes.com/sites/jilliandonfro/2019/09/17/ai-50-americas-most-promising-artificial-intelligence-companies/#2ecf64d9565c">Forbes 50 AI startups in 2019</a>, only 7 companies are tooling companies.</p>

<p>Applications are easier to sell, since you can go to a company and say: “We can automate half of your customer support effort.” Tools take longer to sell but can have a larger impact since you’re not targeting a single application but a part of the ecosystem. Many companies can coexist providing the same application, but for a part of the process, usually a selected few tools can coexist.</p>

<p>After extensive search, I could only find ~200 AI tools, which is puny compared to the number of traditional software engineering tools. If you want testing for traditional Python application development, you can find at least 20 tools within 2 minutes of googling. If you want testing for machine learning models, there’s none.</p>

<h2>IV. Problems facing MLOps</h2>
<p>Many traditional software engineering tools can be used to develop and serve machine learning applications. However, many challenges are unique to ML applications and require their own tools.</p>

<p>In traditional SWE, coding is the hard part, whereas in ML, coding is a small part of the battle. Developing a new model that can provide significant performance improvements in real world tasks is very hard and very costly. Most companies won’t focus on developing ML models but will use an off-the-shelf model, e.g. “if you want it put a BERT on it.”</p>

<p>For ML, applications developed with the most/best data win. Instead of focusing on improving deep learning algorithms, most companies will focus on improving their data. Because data can change quickly, ML applications need faster development and deployment cycles. In many cases, you might have to deploy a new model every night.</p>

<p>The size of ML algorithms is also a problem. The pretrained large BERT model has 340M parameters and is 1.35GB. Even if it can fit on a consumer device (e.g. your phone), the time it takes for BERT to run inference on a new sample makes it useless for many real world applications. For example, an autocompletion model is useless if the time it takes to suggest the next character is longer than the time it takes for you to type.</p>

<p>Git does versioning by comparing differences line by line and therefore works well for most traditional software engineering programs. However, it’s not suitable for versioning datasets or model checkpoints. Pandas works well for most traditional dataframe manipulation, but doesn’t work on GPUs.</p>

<p>Row-based data formats like CSV work well for applications using less data. However, if your samples have many features and you only want to use a subset of them, using row-based data formats still requires you to load all features. Columnar file formats like PARQUET and OCR are optimized for that use case.</p>

<p>Some of the problems facing ML applications development:</p>

<ul>
  <li><strong>Monitoring</strong>: How to know that your data distribution has shifted and you need to retrain your model? Example: <a href="https://www.dessa.com/">Dessa</a>, supported by Alex Krizhevsky from AlexNet and acquired by Square in Feb 2020.</li>
  <li><strong>Data labeling</strong>: How to quickly label the new data or re-label the existing data for the new model? Example: <a href="https://www.snorkel.org/">Snorkel</a>.</li>
  <li><strong>CI/CD test</strong>: How to run tests to make sure your model still works as expected after each change, since you can’t spend days waiting for it to train and converge? Example: <a href="https://argoproj.github.io/">Argo</a>.</li>
  <li><strong>Deployment</strong>: How to package and deploy a new model or replace an existing model? Example: <a href="https://octoml.ai/">OctoML</a>.</li>
  <li><strong>Model compression</strong>: How to compress an ML model to fit in consumer devices? Example: Xnor.ai, a startup spun out of Allen Institute to focus on model compression, raised $14.6M at the valuation of $62M in May 2018. In January 2020, Apple bought it for ~$200M and shut down its website.</li>
  <li><strong>Inference Optimization</strong>: How to speed up inference time for your models? Can we fuse operations together? Can we use lower precision? Making a model smaller might make its inference faster. Example: <a href="https://developer.nvidia.com/tensorrt">TensorRT</a>.</li>
  <li><strong>Edge device</strong>: Hardware designed to run ML algorithms fast and cheap. Example: <a href="https://coral.ai/products/som/">Coral SOM</a>.</li>
  <li><strong>Privacy</strong>: How to use user data to train your models while preserving their privacy? How to make your process GDPR-compliant? Example: <a href="https://github.com/OpenMined/PySyft">PySyft</a>.</li>
</ul>

<p>I plotted the number of tools by the main problems they address.</p>

<center>
<figure>
<img alt="MLOps over time" src="https://huyenchip.com/assets/pics/mlops/mlops_3.png">
</figure>
</center>

<p>A large portion focuses on the data pipeline: data management, labeling, database/query, data processing, data generation. Data pipeline tools are also likely to aim to be all-in-one platforms. Because data handling is the most resource-intensive phase of a project, once you’ve had people put their data on your platform, it’s tempting to provide them with a couple of pre-built/pre-trained models.</p>

<p>Tools for modeling &amp; training are mostly frameworks. The deep learning frameworks competition cooled down to be mostly between PyTorch and TensorFlow, and higher-level frameworks that wrap around these two for specific families of tasks such as NLP, NLU, and multimodal problems. There are frameworks for distributed training. There’s also this new framework coming out of Google that every Googler who hates TensorFlow has been raving about: <a href="https://github.com/google/jax">JAX</a>.</p>

<p>There are standalone tools for experiment tracking, and popular frameworks also have their own experiment tracking features built-in. Hyperparameter tuning is important and it’s not surprising to find several that focus on it, but none seems to catch on because the bottleneck for hyperparameter tuning is not the setup, but the computing power needed to run it.</p>

<p>The most exciting problems yet to be solved are in the deployment and serving space. One reason for the lack of serving solutions is the lack of …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://huyenchip.com/2020/06/22/mlops.html">https://huyenchip.com/2020/06/22/mlops.html</a></em></p>]]>
            </description>
            <link>https://huyenchip.com/2020/06/22/mlops.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23620757</guid>
            <pubDate>Tue, 23 Jun 2020 21:46:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Lossless compression of English messages using GPT-2]]>
            </title>
            <description>
<![CDATA[
Score 126 | Comments 69 (<a href="https://news.ycombinator.com/item?id=23618465">thread link</a>) | @kleiba
<br/>
June 23, 2020 | http://textsynth.org/sms.html | <a href="https://web.archive.org/web/*/http://textsynth.org/sms.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main">
      
      
      

      <div>
        <p>
          This lossless compressor achieves a much higher compression
          rate on English texts than general purpose compressors. Its
          typical compression ratio is 15% (number of output bits
          divided by the number of input bits).
        </p>
        <p>
        The compression is achieved by using the probability of the
        next word computed by
        the <a href="https://openai.com/blog/better-language-models/">GPT-2
        language model</a> released by OpenAI. It is a neural network
        of 1.5 billion parameters based on the Transformer
        architecture. An arithmetic coder generates the bit
        stream. For this demo, each compressed character holds 15 data
        bits by using the CJK and the Hangul Syllables unicode ranges.
        </p>
        <p>
        It is implemented using the
        <a href="https://bellard.org/nncp">LibNC library</a> and runs
        on a standard PC. The Linux standalone command line
        version (<code>gpt2tc</code>) can be downloaded
        <a href="https://bellard.org/nncp/gpt2tc.html">here</a>. Compression
        ratios on several text compression benchmarks is listed in
        the <a href="https://bellard.org/nncp/readme-gpt2tc.txt"><code>gpt2tc</code>
        documentation</a>.
        </p>
        <p>
        The same model can be used to <a href="http://textsynth.org/index.html">complete text messages</a>.
        </p>
        <p>[2020-06-23: Temporary switch to a smaller model (345M) to
        reduce the server load]</p>
        
      </div>
      
      
    </div></div>]]>
            </description>
            <link>http://textsynth.org/sms.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23618465</guid>
            <pubDate>Tue, 23 Jun 2020 18:51:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[You can't tell people anything (2004)]]>
            </title>
            <description>
<![CDATA[
Score 404 | Comments 187 (<a href="https://news.ycombinator.com/item?id=23617188">thread link</a>) | @memexy
<br/>
June 23, 2020 | http://habitatchronicles.com/2004/04/you-cant-tell-people-anything/ | <a href="https://web.archive.org/web/*/http://habitatchronicles.com/2004/04/you-cant-tell-people-anything/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="post-5">
                <h3>You can't tell people anything</h3> 
                <p>This is sort of Morningstar’s version of Murphy’s Law.</p>
<p>When we were assembling our catalog of the things we had learned over the past decade and a half in this business, we almost didn’t include this one because it seems so banal.  But I keep finding that it’s often the first thing I say when people ask me what about my experiences (and another thing I’ve learned is to pay attention to things I find myself saying; that way I’ll know what I really think).  And, upon reflection, I think it’s actually one of the more important lessons that we’ve learned.</p>
<p>We all spend a lot of our time talking to bosses or investors or marketing people or press or friends or other developers. I’m totally convinced that a new idea or a new plan or a new technique is never really understood when you just explain it. People will often think they understand, and they’ll say they understand, but then their actions show that it just ain’t so.</p>
<p>Years ago, before Lucasfilm, I worked for <a href="http://xanadu.com/">Project Xanadu</a> (the original hypertext project, way before this newfangled World Wide Web thing). One of the things I did was travel around the country trying to evangelize the idea of hypertext. People loved it, but nobody <i>got</i> it. Nobody. We provided lots of explanation.  We had pictures.  We had scenarios, little stories that told what it would be like. People would ask astonishing questions, like “who’s going to pay to make all those links?” or “why would anyone want to put documents online?”  Alas, many things really must be experienced to be understood.  We didn’t have much of an experience to deliver to them though — after all, the whole point of all this evangelizing was to get people to give us money to pay for developing the software in the first place!  But someone who’s spent even 10 minutes using the Web would never think to ask some of the questions we got asked.</p>
<p>In 1988 we began consulting to Fujitsu, when they licensed Habitat from Lucasfilm to create Fujitsu Habitat in Japan. We started out with a week long seminar at Skywalker Ranch for their team, explaining everything we knew about Habitat. We gave them copious documentation and complete source code listings. Following that, for the next couple of years they had unlimited access to us via fax, phone and email to answer any questions they might have. We made several visits to Japan to advise them. On our visits they often asked questions that seemed a little, well, odd. We chalked it up to the language barrier, but still, there were clearly things they weren’t getting. For example, their server ran on five (not four, not six, five) Fujitsu A60 minicomputers, and became hopelessly bogged down after about 80 concurrent users. We were never able to get a clear picture of why. We asked lots of questions and they’d try to answer them, but none of the explanations made any sense that we could puzzle out.  They were trying to tell us, you see, but you can’t tell people anything.</p>
<p>The mystery was solved a few years later when we began the WorldsAway project, still consulting to Fujitsu but in a role that was much more hands-on. Our initial plan had been to work from the Fujitsu Habitat code, back porting the client to Macs and Windows, and cleaning up their server (80 users, yeesh). When we took apart their code, we finally figured out what had been puzzling us all that time: <i>they had lost the architecture.</i> In spite of all the information we gave them, we had completely failed to communicate how things worked.  Their guys hadn’t understood the whole client-server concept, which for that day and place was somewhat exotic, so they just implemented what they knew, which was a terminal-mainframe architecture. Their “client” was basically a fancy, highly specialized graphics terminal; all the real work was done on the server.  For example, when you issued a command to an object, instead of sending a command message to the object on the server, the client would send the X-Y coordinates of your mouse click. The server would then render its own copy of the scene into an internal buffer to figure out what object you had clicked on. Not only was this extremely inefficient, but the race conditions inherent a multi-user environment meant that it also sometimes just got the wrong answer. It was amazing…</p>
<p>What’s going on is that without some kind of direct experience to use as a touchstone, people don’t have the context that gives them a place in their minds to put the things you are telling them. The things you say often don’t stick, and the few things that do stick are often distorted.  Also, most people aren’t very good at visualizing hypotheticals, at imagining what something they haven’t experienced might be like, or even what something they <i>have</i> experienced might be like if it were somewhat different. One of the things I really miss from my days at Lucasfilm is having artists on staff, being able to run down the hall and say, “hey Gary, draw me this picture.”</p>
<p>Eventually people can be educated, but what you have to do is find a way give them the experience, to put them in the situation. Sometimes this can only happen by making real the thing you are describing, but sometimes by dint of clever artifice you can simulate it.</p>
<p>With luck, eventually there will be an “Aha!”.  If you’re really good, the “Aha!” will followed by “Oh, so <i>that’s</i> what you meant”.  But don’t be too surprised or upset if the “Aha!” is instead followed by “Why didn’t you <i>tell</i> me that?”.  At Communities.com we developed a system called Passport (I’ll save the astonishing trademark story for a later posting) that let us do some pretty amazing things with web browsers.  For example, with just a few magic HTML tags we could stick avatars on a web page — pretty much any web page.  For months Randy kept getting up at management meetings and saying, “We’ll be able to put avatars on web pages.  Start thinking about what you might do with that.”  Mostly, nobody reacted much.  After a couple of months of this we had things working, and so he got up and presented a demo of avatars walking around on top of our company home page. People were amazed, joyful, and enthusiastic.  But they also pretty much all said the same thing: “why didn’t you <i>tell</i> us that we could put avatars on web pages?”  You can’t tell people anything.</p>
<p>When people ask me about my life’s ambitions, I often joke that my goal is to become independently wealthy so that I can afford to get some work done. Mainly that’s about being able to do things without having to explain them first, so that the finished product can be the explanation.  I think this will be a major labor saving improvement.</p>
<p>One final point: I expect none of you to really get what I’m talking about here, because this principle also applies to itself. But I fully expect I’ll get the occasional email saying “Oh! so <i>that’s</i> what you meant.” or “Why didn’t you <i>tell</i> me that?”  I did, but you can’t tell people anything.</p>

            </div></div>]]>
            </description>
            <link>http://habitatchronicles.com/2004/04/you-cant-tell-people-anything/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23617188</guid>
            <pubDate>Tue, 23 Jun 2020 17:26:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Query 1.6B rows in milliseconds, live]]>
            </title>
            <description>
<![CDATA[
Score 268 | Comments 92 (<a href="https://news.ycombinator.com/item?id=23616878">thread link</a>) | @bluestreak
<br/>
June 23, 2020 | http://try.questdb.io:9000/index.html | <a href="https://web.archive.org/web/*/http://try.questdb.io:9000/index.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>http://try.questdb.io:9000/index.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23616878</guid>
            <pubDate>Tue, 23 Jun 2020 17:08:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Go vs. Crystal Performance]]>
            </title>
            <description>
<![CDATA[
Score 197 | Comments 160 (<a href="https://news.ycombinator.com/item?id=23615303">thread link</a>) | @open-source-ux
<br/>
June 23, 2020 | https://ptimofeev.com/go-vs-crystal-perfomance/ | <a href="https://web.archive.org/web/*/https://ptimofeev.com/go-vs-crystal-perfomance/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p><a href="https://ptimofeev.com/go-vs-crystal-perfomance/"><img src="https://ptimofeev.com/images/go-vs-crystal.png" alt="Go vs Crystal"></a></p>

<p>Itâ€™s a follow up post to the previous <a href="https://ptimofeev.com/ruby-vs-crystal-performance/">Ruby vs Crystal Performance</a>.</p>

<p>I guess this time it will be a fair performance comparison as both languages are compiled and statically typed.</p>

<p>We will perform a couple of tests:</p>
<ul>
  <li>Finding a number in the Fibonacci sequence as in the previous post</li>
  <li>Running an HTTP server locally and performing benchmarks with wrk</li>
</ul>

<p>Language versions installed my machine are:</p>
<ul>
  <li>go version go1.14.3 darwin/amd64</li>
  <li>Crystal 0.34.0 (2020-04-07)</li>
</ul>

<p>Iâ€™m curious to find out how Go and Crystal perform in comparison to each other.</p>

<!-- more -->

<h3 id="compilation">Compilation</h3>

<p>For the tests we will be running previously compiled programs. We will use the release flag to enable optimizations in Crystal:</p>
<div><div><pre><code>crystal build <span>--release</span> program.cr
</code></pre></div></div>

<p>Go binaries donâ€™t have a release version and we wonâ€™t be using any flags. So, itâ€™s just:</p>


<h2 id="fibonacci">Fibonacci</h2>

<p>Alright, first we will write code to generate a Fibonacci sequence for a given number. Letâ€™s find the 47th number which is 2,971,215,073.</p>

<p>Go version:</p>

<div><div><pre><code><span>package</span> <span>main</span>

<span>import</span> <span>"fmt"</span>

<span>func</span> <span>fibonacci</span><span>(</span><span>n</span> <span>uint32</span><span>)</span> <span>uint32</span> <span>{</span>
  <span>if</span> <span>n</span> <span>&lt;</span> <span>2</span> <span>{</span>
    <span>return</span> <span>n</span>
  <span>}</span>
  <span>return</span> <span>fibonacci</span><span>(</span><span>n</span><span>-</span><span>1</span><span>)</span> <span>+</span> <span>fibonacci</span><span>(</span><span>n</span><span>-</span><span>2</span><span>)</span>
<span>}</span>

<span>func</span> <span>main</span><span>()</span> <span>{</span>
  <span>fmt</span><span>.</span><span>Println</span><span>(</span><span>fibonacci</span><span>(</span><span>47</span><span>))</span>
<span>}</span>
</code></pre></div></div>

<p>Crystal version:</p>

<div><div><pre><code><span>def</span> <span>fibonacci</span><span>(</span><span>n</span> <span>:</span> <span>UInt32</span><span>)</span>
  <span>return</span> <span>n</span> <span>if</span> <span>n</span> <span>&lt;</span> <span>2</span>
  <span>fibonacci</span><span>(</span><span>n</span><span>-</span><span>1</span><span>)</span> <span>+</span> <span>fibonacci</span><span>(</span><span>n</span><span>-</span><span>2</span><span>)</span>
  <span>end</span>

<span>puts</span> <span>fibonacci</span><span>(</span><span>47</span><span>)</span>
</code></pre></div></div>

<p>Results on my machine (MacBook Pro 2.2 GHz Intel Core i7):</p>

<table>
  <tbody>
    <tr>
      <td><strong>Language</strong></td>
      <td><strong>Binary size</strong></td>
      <td><strong>Run time</strong></td>
      <td><strong>Memory usage</strong></td>
    </tr>
    <tr>
      <td>go</td>
      <td>2.1M</td>
      <td>21.28s</td>
      <td>2.01M</td>
    </tr>
    <tr>
      <td>Crystal</td>
      <td>418k</td>
      <td>19.69s</td>
      <td>1.72M</td>
    </tr>
  </tbody>
</table>

<p>Crystal is slightly winning here.</p>

<p>A few observations here:</p>

<p>Crystalâ€™s binary size is 5 times smaller than Goâ€™s. Though, they can be slightly reduced in size when we omit the debug information:</p>
<div><div><pre><code>go build <span>-ldflags</span><span>=</span><span>"-w"</span> fibonacci_golang.go
</code></pre></div></div>
<p>This way the binary size goes down from 2.1M to 1.7M.</p>

<p>Also, not in this particular example, but generally Goâ€™s compilation time is much much faster than Crystalâ€™s.</p>

<h2 id="http-server">HTTP Server</h2>

<p>Now, letâ€™s create a simple HTTP server using standard libraries. Both Goâ€™s <em>net/http</em> and Crystalâ€™s <em>http/server</em> employ concurrency: Go uses goroutines and Crystal uses fibers.</p>

<p>Go version:</p>
<div><div><pre><code><span>package</span> <span>main</span>

<span>import</span> <span>(</span>
	<span>"fmt"</span>
	<span>"net/http"</span>
<span>)</span>

<span>func</span> <span>main</span><span>()</span> <span>{</span>
	<span>http</span><span>.</span><span>HandleFunc</span><span>(</span><span>"/"</span><span>,</span> <span>HelloServer</span><span>)</span>
	<span>http</span><span>.</span><span>ListenAndServe</span><span>(</span><span>":8080"</span><span>,</span> <span>nil</span><span>)</span>
<span>}</span>

<span>func</span> <span>HelloServer</span><span>(</span><span>w</span> <span>http</span><span>.</span><span>ResponseWriter</span><span>,</span> <span>r</span> <span>*</span><span>http</span><span>.</span><span>Request</span><span>)</span> <span>{</span>
	<span>fmt</span><span>.</span><span>Fprintf</span><span>(</span><span>w</span><span>,</span> <span>"Hello from %s!"</span><span>,</span> <span>r</span><span>.</span><span>URL</span><span>.</span><span>Path</span><span>[</span><span>1</span><span>:</span><span>])</span>
<span>}</span>
</code></pre></div></div>

<p>Crystal version:</p>
<div><div><pre><code><span>require</span> <span>"http/server"</span>

<span>server</span> <span>=</span> <span>HTTP</span><span>::</span><span>Server</span><span>.</span><span>new</span> <span>do</span> <span>|</span><span>context</span><span>|</span>
  <span>context</span><span>.</span><span>response</span><span>.</span><span>content_type</span> <span>=</span> <span>"text/plain"</span>
  <span>context</span><span>.</span><span>response</span><span>.</span><span>print</span> <span>"Hello from </span><span>#{</span><span>context</span><span>.</span><span>request</span><span>.</span><span>path</span><span>}</span><span>!"</span>
<span>end</span>

<span>puts</span> <span>"Listening on http://127.0.0.1:8080"</span>
<span>server</span><span>.</span><span>listen</span><span>(</span><span>8080</span><span>)</span>
</code></pre></div></div>

<p>For benchmarking we will be using <a href="https://github.com/wg/wrk" target="_blank" rel="noopener noreferrer">wrk</a>. If youâ€™re not familiar with this tool itâ€™s like a pretty well known ApacheBench (ab) but a modern version.</p>

<p>Here is how we can run a benchmark for 60 seconds, using 8 threads, and keeping 400 HTTP connections open:</p>

<div><div><pre><code>wrk <span>-t8</span> <span>-c400</span> <span>-d60s</span> http://localhost:8080/hello
</code></pre></div></div>

<p>Results for the Go server:</p>
<div><div><pre><code>Running 1m test @ http://localhost:8080/hello
  8 threads and 400 connections
  Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency     3.56ms    2.26ms  95.31ms   92.00%
    Req/Sec     8.77k     2.24k   15.75k    64.66%
  4190457 requests in 1.00m, 535.51MB read
  Socket errors: connect 157, read 100, write 0, timeout 0
Requests/sec:  69757.81
Transfer/sec:      8.91MB
</code></pre></div></div>

<p>Results for the Crystal server:</p>
<div><div><pre><code>Running 1m test @ http://localhost:8080/hello
  8 threads and 400 connections
  Thread Stats   Avg      Stdev     Max   +/- Stdev
    Latency     2.89ms    0.97ms  19.01ms   80.34%
    Req/Sec    10.54k     3.41k   18.14k    60.85%
  5035284 requests in 1.00m, 513.82MB read
  Socket errors: connect 157, read 85, write 0, timeout 0
Requests/sec:  83917.26
Transfer/sec:      8.56MB
</code></pre></div></div>

<p>Results:</p>

<table>
  <tbody>
    <tr>
      <td><strong>Language</strong></td>
      <td><strong>Binary size</strong></td>
      <td><strong>Memory usage</strong></td>
      <td><strong>CPU usage</strong></td>
      <td><strong>Throughput</strong></td>
    </tr>
    <tr>
      <td>go</td>
      <td>7.4M</td>
      <td>20.2M</td>
      <td>300%</td>
      <td>69,757</td>
    </tr>
    <tr>
      <td>Crystal</td>
      <td>966kb</td>
      <td>19.1M</td>
      <td>99%</td>
      <td>83,917</td>
    </tr>
  </tbody>
</table>

<p>Crystal again shows better results.</p>

<p>CPU utilization over 100% in the table might seem confusing. But it simply means the system uses multiple cores. One core at max is 100%.</p>

<p>My machine has 8 cores as it can be seen with the following command on macOs:</p>


<h2 id="conclusion">Conclusion</h2>

<p>Frankly speaking, we have only performed a couple of small tests to make any conclusions but Iâ€™m still excited for Crystal as a young language but showing great results.</p>


  </div></div>]]>
            </description>
            <link>https://ptimofeev.com/go-vs-crystal-perfomance/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23615303</guid>
            <pubDate>Tue, 23 Jun 2020 15:34:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Linux Touchpad Like a MacBook update: progress on multitouch]]>
            </title>
            <description>
<![CDATA[
Score 270 | Comments 126 (<a href="https://news.ycombinator.com/item?id=23615218">thread link</a>) | @wbharding
<br/>
June 23, 2020 | https://bill.harding.blog/2020/06/22/linux-touchpad-project-update-progress-on-multitouch/ | <a href="https://web.archive.org/web/*/https://bill.harding.blog/2020/06/22/linux-touchpad-project-update-progress-on-multitouch/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="comments">

		<div id="respond">
		<h3 id="reply-title">Leave a Reply <small></small></h3><form action="https://bill.harding.blog/wp-comments-post.php" method="post" id="commentform" novalidate=""><p><span id="email-notes">Your email address will not be published.</span> Required fields are marked <span>*</span></p><p><label for="comment">Comment</label> </p><p><label for="author">Name <span>*</span></label> </p>
<p><label for="email">Email <span>*</span></label> </p>
<p><label for="url">Website</label> </p>
<p> <label for="wp-comment-cookies-consent">Save my name, email, and website in this browser for the next time I comment.</label></p>
<!-- Anti-spam plugin wordpress.org/plugins/anti-spam/ --><div><p><label>Current ye@r <span>*</span></label>
					
					
				  </p>

</div><!--\End Anti-spam plugin --></form>	</div><!-- #respond -->
	
</div></div>]]>
            </description>
            <link>https://bill.harding.blog/2020/06/22/linux-touchpad-project-update-progress-on-multitouch/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23615218</guid>
            <pubDate>Tue, 23 Jun 2020 15:30:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Chrome killed my extension and won’t tell me why]]>
            </title>
            <description>
<![CDATA[
Score 209 | Comments 69 (<a href="https://news.ycombinator.com/item?id=23614601">thread link</a>) | @mikob
<br/>
June 23, 2020 | https://blog.lipsurf.com/part-ii-after-3-years-of-work-chrome-killed-my-extension-and-wont-tell-me-why/ | <a href="https://web.archive.org/web/*/https://blog.lipsurf.com/part-ii-after-3-years-of-work-chrome-killed-my-extension-and-wont-tell-me-why/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        <hr><!--kg-card-begin: markdown--><p><em>(Part I is <a href="https://blog.lipsurf.com/after-3-years-of-work-chrome-killed-my-extension-and-wont-tell-me-why/">here</a> or <a href="https://medium.com/@miko_89964/after-3-years-of-work-chrome-killed-my-extension-and-wont-tell-me-why-83a3f8d65cbc">here</a>)</em></p>
<!--kg-card-end: markdown--><p>We won the battle but not the war.</p><p>I got lucky. If I didn’t win the <a href="https://www.reddit.com/r/programming/comments/hbix3o/after_3_years_of_work_chrome_killed_my_extension/" rel="noopener">internet attention lottery that day</a>, we may have shutdown and left our users stranded with an unmaintained tool that their daily lives depend on. The fate of web accessibility for thousands of people with disabilities, and our business lie in the hands of a single faceless gatekeeper who made a mistake.</p><p>The story may sound familiar. In short: our Chrome Extension was taken down because it supposedly didn't meet policy. After lots of development work, numerous failed resubmissions, and a week delisted from the store without communication – we complained loudly on <a href="https://www.reddit.com/r/programming" rel="noopener">Reddit</a>. Noticing our post, someone with internal access to the Chrome Webstore reached out to us on <a href="https://twitter.com/DotProto/status/1273845280668966912" rel="noopener">Twitter</a>, they said that it was a mistake and apologized. We resubmitted and were restored later that day.</p><p>Complaining on the internet should not be a support channel. Developers should not have to rely on the internet attention lottery. The Chrome Webstore has been around 10 years and needs to get its act together. We, at <a href="https://www.lipsurf.com/" rel="noopener">LipSurf</a>, want to use our temporary position of attention privilege to improve the system and help other extension developers.</p><p>Firstly, we are very thankful to the unequivocal hero, <a href="https://twitter.com/DotProto">@DotProto</a>. He not only saved <a href="https://www.lipsurf.com/" rel="noopener">us</a>, but has saved <a href="https://blog.pushbullet.com/2020/05/15/our-extension-is-safe/" rel="noopener">PushBullet recently</a>, among others. Furthermore, he does it in <a href="https://www.reddit.com/r/programming/comments/hbix3o/after_3_years_of_work_chrome_killed_my_extension/fvb8mgf?utm_source=share&amp;utm_medium=web2x" rel="noopener">his free time</a>.</p><p>Although <a href="https://twitter.com/DotProto">@DotProto</a> says CWS is working to <a href="https://www.reddit.com/r/programming/comments/hbix3o/after_3_years_of_work_chrome_killed_my_extension/fvb8mgf?utm_source=share&amp;utm_medium=web2x" rel="noopener">improve internally</a>, it would be foolish for us to stand on the sidelines, just waiting ,  hoping. The issues are clearly systemic, as cries for help <a href="https://groups.google.com/a/chromium.org/forum/#!forum/chromium-extensions" rel="noopener">litter the CWS forums</a>, and our Reddit post was <a href="https://www.reddit.com/r/programming/comments/hbix3o/after_3_years_of_work_chrome_killed_my_extension/fv9haxs?utm_source=share&amp;utm_medium=web2x" rel="noopener">full</a> <a href="https://www.reddit.com/r/programming/comments/hbix3o/after_3_years_of_work_chrome_killed_my_extension/fvaosgv?utm_source=share&amp;utm_medium=web2x" rel="noopener">of</a> <a href="https://www.reddit.com/r/programming/comments/hbix3o/after_3_years_of_work_chrome_killed_my_extension/fv9to0o?utm_source=share&amp;utm_medium=web2x" rel="noopener">“me too”</a> <a href="https://www.reddit.com/r/programming/comments/hbix3o/after_3_years_of_work_chrome_killed_my_extension/fv9pkca?utm_source=share&amp;utm_medium=web2x" rel="noopener">stories</a>. </p><p>This can and will happen again.</p><p>Therefore, we are starting a group today for Chrome Extension developers to work together in check with CWS. It's not a technical support channel, nor a platform to get attention when CWS is unresponsive. It's a place for Chrome Extension developers to rally together and discuss improving the foundation we stand on (it also won't be hosted nor managed by Google).</p><p>United, we can have a stronger, common voice to:</p><ol><li><strong>Pressure Google Chrome to allow for 3rd party extension stores.</strong></li></ol><p>This would break down the walled garden of extensions, give extension developers a leveler playing field, and lower the risk of getting wiped out on CWS's whim.</p><p>2. <strong>Pressure CWS to be more fair and communicative with extension publishers.</strong></p><p>Canned emails about rejections with only general policy information are “lose-lose” for publishers and CWS alike. Both parties waste time because of all the guesswork involved currently — especially when CWS makes a mistake.</p><hr><p>We need to start building our defenses and forging relationships today. If we don’t unite and speak together, we will forever be powerless and at the mercy of our gatekeeper. We also open our forum to CWS staff, and extension advocates like <a href="https://twitter.com/DotProto">@DotProto</a>. We don’t want to work against each other, after all – a good platform should &nbsp;work &nbsp;<em>with us</em> &nbsp;not &nbsp;<em>against us</em>.</p><p><strong>If you are a extension developer, or know any extension developers, please share or start by joining us by filling out the form below.</strong> We plan to open the forum once we know that there's enough interest.</p><h3 id="faqs">FAQs</h3><p><em>What power will we have together?</em></p><p>Building awareness to start. We will rally support from other developers and end users alike. One extreme example could be a coordinated a Chrome Extension blackout date. A less extreme example would be proposing ideas as a group, instead of as individuals to Google Chrome that would improve the experience for extensions (eg. improved permissions).</p><p><em>What about adware, or privacy intruding extensions?</em></p><p>If 3rd party extension stores were possible, they would be free to setup their own barriers – monetary or otherwise. It's very possible for a 3rd party extension store to do a <a href="https://www.reddit.com/r/IAmA/comments/dwfbmf/im_brendan_eich_inventor_of_javascript_and/f7mhhay?utm_source=share&amp;utm_medium=web2x">better job</a> <a href="https://forklog.media/google-chrome-extension-with-32m-downloads-has-malicious-add-ons-that-steal-data-report/">than Google</a> at blocking malicious extensions. </p><!--kg-card-begin: html--><!--kg-card-end: html-->
    </div></div>]]>
            </description>
            <link>https://blog.lipsurf.com/part-ii-after-3-years-of-work-chrome-killed-my-extension-and-wont-tell-me-why/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23614601</guid>
            <pubDate>Tue, 23 Jun 2020 14:48:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Is WebP really better than JPEG?]]>
            </title>
            <description>
<![CDATA[
Score 422 | Comments 304 (<a href="https://news.ycombinator.com/item?id=23614305">thread link</a>) | @kasabali
<br/>
June 23, 2020 | https://siipo.la/blog/is-webp-really-better-than-jpeg | <a href="https://web.archive.org/web/*/https://siipo.la/blog/is-webp-really-better-than-jpeg">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
			
			<div>
				<section id="content" role="main">
					<div>
												<div>
									<article id="post-214">
			<section>
				
				
				<div>
					                                                                                    <p>If you have used tools like Google’s PageSpeed Insights, you probably have run into a suggestion to use “next-gen image formats”, namely Google’s <a href="https://developers.google.com/speed/webp">WebP image format</a>. Google <a href="https://developers.google.com/speed/webp/docs/webp_study">claims that</a> their WebP format is 25 – 34% smaller than JPEG at equivalent quality.</p>
<p>When testing out WebP using a <a href="https://github.com/siiptuo/pio">perceptual image optimizer</a>, I ran into a peculiar issue: the WebP files were of very similar size compared to compressed JPEGs, in many cases larger. I’m not only one who noticed this, but Mozilla also noted in <a href="https://research.mozilla.org/2013/10/17/studying-lossy-image-compression-efficiency/">their 2013 study</a> that WebP doesn’t generally have much better compression efficiency when compared to JPEG. (Note that Mozilla somewhat walked back from this and implemented <a href="https://hacks.mozilla.org/2019/01/firefox-65-webp-flexbox-inspector-new-tooling/">WebP support</a> for Firefox in 2019)</p>
<p>I think Google’s result of 25-34% smaller files is mostly caused by the fact that they compared their WebP encoder to the JPEG reference implementation, Independent JPEG Group’s <a href="https://linux.die.net/man/1/cjpeg">cjpeg</a>, not Mozilla’s improved <a href="https://calendar.perfplanet.com/2014/mozjpeg-3-0/">MozJPEG</a> encoder. I decided to run some tests to see how cjpeg, MozJPEG and WebP compare. I also tested the new AVIF format, based on the open AV1 video codec. AVIF support is already in Firefox behind a flag and should be coming soon to Chrome if <a href="https://bugs.chromium.org/p/chromium/issues/detail?id=960620">this ticket</a> is to be believed.</p>
<h2>Images and Tools</h2>
<p>For the testing I used the <a href="http://r0k.us/graphics/kodak/">Kodak image dataset</a> in 3 different sizes: 500 px, 1000px and 1500px.</p>
<ul>
<li>For JPEG conversion I used cjpeg with <code>--optimize</code> flag, <code>--progressive</code>  flag and 4:2:0 chroma subsampling.</li>
<li>For MozJPEG conversion I used MozJPEG with <code>--optimize</code> flag, <code>--progressive</code>  flag and 4:2:0 chroma subsampling</li>
<li>For WebP  I used cwebp with <code>-m 6</code> flag for maximum compression and <code>-af</code> for auto filter which presumably trades encoding time for increased quality. WebP only supports 4:2:0 subsampling so this doesn’t need to be specified separately.</li>
<li>For AVIF I used <a href="https://github.com/joedrago/colorist">colorist</a> with flags <code>--tonemap off</code>, <code>--yuv 420</code> and <code>--speed 0</code> which is the slowest but highest quality encoding</li>
</ul>
<p>In addition to these, ImageMagick was used to scale down the images from the originals and converting between PNG, WebP and TGA (cwebp only supports TGA input). All conversions were done in sRGB color space.</p>
<p>For comparing the quality I used kornelski’s <a href="https://github.com/kornelski/dssim">dssim utility</a> which calculates <a href="https://en.wikipedia.org/wiki/Structural_similarity">structural similarity</a> index between images. My target SSIM is 0.0044 which <a href="https://gist.github.com/joppuyo/12fe6fb5e5fa532b21e2c8098634c7c9">roughly corresponds</a> to JPEG quality of 85.</p>
<h2>Results for 500px images</h2>

<p><a href="https://webp-test-500.b-cdn.net/" target="_blank">Open comparison in a new window</a></p>
<p>Here are the results on a graph:</p>

                                                                                                                                                                                                    <p><a href="https://siipo.la/wp-content/uploads/500px-target-quality-85-median-file-size-error-bars.png" target="_blank">
                                        <img src="https://siipola.b-cdn.net/wp-content/uploads/500px-target-quality-85-median-file-size-error-bars-700x475.png?ver=6b39e3fd553c4abb419975a7ae5e4541" srcset="https://siipola.b-cdn.net/wp-content/uploads/500px-target-quality-85-median-file-size-error-bars-1400x950.png?ver=6b39e3fd553c4abb419975a7ae5e4541 1400w,https://siipola.b-cdn.net/wp-content/uploads/500px-target-quality-85-median-file-size-error-bars-1080x733.png?ver=6b39e3fd553c4abb419975a7ae5e4541 1080w,https://siipola.b-cdn.net/wp-content/uploads/500px-target-quality-85-median-file-size-error-bars-700x475.png?ver=6b39e3fd553c4abb419975a7ae5e4541 700w" sizes="(min-width: 700px) 700px, 100vw">
                                    </a>
                                </p>
                                                                                                                                            <p>If we look at the median file sizes, we can see that compared to cjpeg, MozJPEG is roughly 11% smaller, WebP is 18% smaller compared and AVIF is 31% smaller at the equivalent SSIM index.</p>
<h2>Results for 1000px images</h2>

<p><a href="https://webp-test-1000.b-cdn.net/" target="_blank">Open comparison in a new window</a></p>
<p>Here are the results on a graph:</p>

                                                                                                                                                                                                    <p><a href="https://siipo.la/wp-content/uploads/1000px-target-quality-85-median-file-size-error-bars.png" target="_blank">
                                        <img src="https://siipola.b-cdn.net/wp-content/uploads/1000px-target-quality-85-median-file-size-error-bars-700x475.png?ver=4b73e911c9f7bb42e4224ea9ddb33bc6" srcset="https://siipola.b-cdn.net/wp-content/uploads/1000px-target-quality-85-median-file-size-error-bars-1400x950.png?ver=4b73e911c9f7bb42e4224ea9ddb33bc6 1400w,https://siipola.b-cdn.net/wp-content/uploads/1000px-target-quality-85-median-file-size-error-bars-1080x733.png?ver=4b73e911c9f7bb42e4224ea9ddb33bc6 1080w,https://siipola.b-cdn.net/wp-content/uploads/1000px-target-quality-85-median-file-size-error-bars-700x475.png?ver=4b73e911c9f7bb42e4224ea9ddb33bc6 700w" sizes="(min-width: 700px) 700px, 100vw">
                                    </a>
                                </p>
                                                                                                                                            <p>If we look at the median file sizes, we can see that compared to cjpeg, MozJPEG is roughly 11% smaller, WebP is also 11% smaller compared and avif is 28% smaller at the equivalent SSIM index.</p>
<h2>Results for 1500px images</h2>

<p><a href="https://webp-test-1500.b-cdn.net/" target="_blank">Open comparison in a new window</a></p>
<p>Here are the results on a graph:</p>

                                                                                                                                                                                                    <p><a href="https://siipo.la/wp-content/uploads/1500px-target-quality-85-median-file-size-error-bars.png" target="_blank">
                                        <img src="https://siipola.b-cdn.net/wp-content/uploads/1500px-target-quality-85-median-file-size-error-bars-700x475.png?ver=c1e3e1cf9d96a566fc4bc22b39eefec0" srcset="https://siipola.b-cdn.net/wp-content/uploads/1500px-target-quality-85-median-file-size-error-bars-1400x950.png?ver=c1e3e1cf9d96a566fc4bc22b39eefec0 1400w,https://siipola.b-cdn.net/wp-content/uploads/1500px-target-quality-85-median-file-size-error-bars-1080x733.png?ver=c1e3e1cf9d96a566fc4bc22b39eefec0 1080w,https://siipola.b-cdn.net/wp-content/uploads/1500px-target-quality-85-median-file-size-error-bars-700x475.png?ver=c1e3e1cf9d96a566fc4bc22b39eefec0 700w" sizes="(min-width: 700px) 700px, 100vw">
                                    </a>
                                </p>
                                                                                                                                            <p>If we look at the median file sizes, we can see that compared to cjpeg, MozJPEG is roughly 9% smaller, WebP is the same size as cjpeg and AVIF is 28% smaller at the equivalent SSIM index.</p>
<h2>Average for all image sizes</h2>
<p>Just for fun, I graphed the averages of all image sizes. I know this might not be a fair comparison but still, here you go:</p>

                                                                                                                                                                                                    <p><a href="https://siipo.la/wp-content/uploads/all-sizes-target-quality-85-average-file-size.png" target="_blank">
                                        <img src="https://siipola.b-cdn.net/wp-content/uploads/all-sizes-target-quality-85-average-file-size-700x475.png?ver=4c2aa46286fabb012d9e6339114fb697" srcset="https://siipola.b-cdn.net/wp-content/uploads/all-sizes-target-quality-85-average-file-size-1400x950.png?ver=4c2aa46286fabb012d9e6339114fb697 1400w,https://siipola.b-cdn.net/wp-content/uploads/all-sizes-target-quality-85-average-file-size-1080x733.png?ver=4c2aa46286fabb012d9e6339114fb697 1080w,https://siipola.b-cdn.net/wp-content/uploads/all-sizes-target-quality-85-average-file-size-700x475.png?ver=4c2aa46286fabb012d9e6339114fb697 700w" sizes="(min-width: 700px) 700px, 100vw">
                                    </a>
                                </p>
                                                                                                                                            <p>As you can see, when compared to cjpeg, MozJPEG is about 9% smaller, WebP is 6% smaller and AVIF is 30% smaller.</p>
<p>If you are interested, you can view the raw data for all the images as a spreadsheet <a href="https://docs.google.com/spreadsheets/d/1j-5ZqbSnIt0qtxh1T83sVjfR7YZIhfdgtWG28F3I8U8/edit?usp=sharing">here</a>. Source code for the comparison app and raw images are available on GitHub: <a href="https://github.com/joppuyo/compare-app-webp-500">500px</a>, <a href="https://github.com/joppuyo/compare-app-webp-1000">1000px</a> and <a href="https://github.com/joppuyo/compare-app-webp-1500">1500px</a>. Check the originals directory for the raw images.</p>
<h2>Conclusions</h2>
<h3>Is WebP better than JPEG?</h3>
<p>So, is WebP better than JPEG? It depends if you are using the reference libjpeg library or the improved MozJPEG encoder.</p>
<p>WebP seems to have about 10% better compression compared to libjpeg in most cases, except with 1500px images where the compression is about equal.</p>
<p>However, when compared to MozJPEG, WebP only performs better with small 500px images. With other image sizes the compression is equal or worse.</p>
<p>I think MozJPEG is the clear winner here with consistently about 10% better compression than libjpeg.</p>
<p>Since most of the time WebP is used alongside JPEG fallback, by using WebP you will essentially double your storage costs with little benefit. So, in the end, I would recommend using WebP in only the following cases:</p>
<ul>
<li>You have a lot of small images in the 500 px range.</li>
<li>You can’t use MozJPEG.</li>
<li>You pick an arbitrary fixed quality instead of using a metric like SSIM.</li>
</ul>
<p>In any case, when converting images to WebP, check that they are actually smaller than the JPEG equivalent. There’s no need to serve larger images to your users than needed.</p>
<h3>How do image formats derived from video codecs differ from JPEG?</h3>
<p>One notable difference between JPEG encoders compared to WebP (based on VP8) and AVIF (based on AV1) is that it’s pretty easy to see how the latter were derived from video codecs. JPEG compression uses the same quantization factor for each 16x16 “macroblock” so the compression is consistent throughout the image.</p>
<p>WebP and AVIF on the other hand use different compression factors for different parts of the image so while the detailed parts of the image retain their quality, surfaces like skin or the sky which have low detail are “smoothed out”. This is especially noticeable with the red window shutters in this image.</p>

                                                                                                                                                                                                    <p><a href="https://siipo.la/wp-content/uploads/jpeg-vs-webp-vs-avif.png" target="_blank">
                                        <img src="https://siipola.b-cdn.net/wp-content/uploads/jpeg-vs-webp-vs-avif-700x194.png?ver=63b1240368ae03d4ad9fa923e352b44f" srcset="https://siipola.b-cdn.net/wp-content/uploads/jpeg-vs-webp-vs-avif-1440x399.png?ver=63b1240368ae03d4ad9fa923e352b44f 1440w,https://siipola.b-cdn.net/wp-content/uploads/jpeg-vs-webp-vs-avif-1400x388.png?ver=63b1240368ae03d4ad9fa923e352b44f 1400w,https://siipola.b-cdn.net/wp-content/uploads/jpeg-vs-webp-vs-avif-1080x300.png?ver=63b1240368ae03d4ad9fa923e352b44f 1080w,https://siipola.b-cdn.net/wp-content/uploads/jpeg-vs-webp-vs-avif-700x194.png?ver=63b1240368ae03d4ad9fa923e352b44f 700w" sizes="(min-width: 700px) 700px, 100vw">
                                    </a>
                                </p>
                                                                                                                                            <p>While the bricks in the image look sharp, the doors look almost like they have a “Smart blur” Photoshop filter applied to them.</p>
<p>I think this kind of adaptive compression is a valuable thing to have. Think about a photo with a forest and the sky. A traditional image encoder would have to decide a single compression ratio for the whole image. While it’s good to use a lot of bits for the forest trees with high-frequency detail, they are wasted for the sky with low-frequency detail.</p>
<p>A smarter encoder like WebP or AVIF will be able to process these areas separately to use the available bits efficiently.</p>
<h3>Is AVIF the future of image formats?</h3>
<p>I think AVIF is a really exciting development and compared to WebP it seems like a true next-generation codec with about 30% better compression ratio compared to libjpeg. Only concern I have is the excessive blurring of low detail areas. It remains to be seen if this can be improved when more advanced tooling becomes available.</p>
<p>Right now the tooling is a bit spotty. <a href="https://github.com/joedrago/colorist">Colorist</a> was the only program I found which can reliably encode AVIF files. Encoding AVIF files is also really slow! A big image can take several minutes to encode. I’m using the AOM encoder but <a href="https://github.com/xiph/rav1e">rav1e</a> might be faster. Browser support also still in progress. Firefox has AVIF support but it’s behind a flag and it doesn’t seem to <a href="https://bugzilla.mozilla.org/show_bug.cgi?id=1634741">read ICC profiles correctly</a>. Still, it’s more browser support than Apple’s "next-gen" HEIF which <a href="https://caniuse.com/heif">isn’t even supported in Safari</a>.</p>
<p>I think in the next year or so we might see a radically different landscape. With Chrome on board, we could see supported browsers jump to something like 70% of all browsers which means AVIF would be a pragmatic thing to support in web projects.</p>
<h2>Caveats</h2>
<p>In this test, I only used photographic images. WebP may be better when compressing graphics, for example, since it supports lossy compression for the alpha channel which PNG and JPEG do not.</p>
<p>I also tested the images in “Web quality” target of 85 so WebP may perform differently in very high or very low-quality settings.</p>
<p>Also, Google’s study used <a href="http://mehdi.rabah.free.fr/SSIM/">a different program</a> to compute the SSIM values. In my tests, I used the <a href="https://github.com/kornelski/dssim">dssim</a> utility which computes multi-scale SSIM in …</p></div></section></article></div></div></section></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://siipo.la/blog/is-webp-really-better-than-jpeg">https://siipo.la/blog/is-webp-really-better-than-jpeg</a></em></p>]]>
            </description>
            <link>https://siipo.la/blog/is-webp-really-better-than-jpeg</link>
            <guid isPermaLink="false">hacker-news-small-sites-23614305</guid>
            <pubDate>Tue, 23 Jun 2020 14:28:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I Just Hit $100k/year On GitHub Sponsors]]>
            </title>
            <description>
<![CDATA[
Score 1457 | Comments 488 (<a href="https://news.ycombinator.com/item?id=23613719">thread link</a>) | @calebporzio
<br/>
June 23, 2020 | https://calebporzio.com/i-just-hit-dollar-100000yr-on-github-sponsors-heres-how-i-did-it | <a href="https://web.archive.org/web/*/https://calebporzio.com/i-just-hit-dollar-100000yr-on-github-sponsors-heres-how-i-did-it">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
                
    <span>Jun 2020</span>

    

    <p><a href="https://sponsorsyrup.com/" target="__blank"><img src="https://calebporzio.com/post_images/3735079629.png"></a></p>
<p>I have a story to tell.</p>
<p>My last year as a full-time developer (at <a href="https://tighten.com/">Tighten</a>) was 2018. (Read <a href="https://calebporzio.com/n-leaving-my-day-job">â€œOn Leaving My Day Jobâ€�</a> for that story)</p>
<p>My income for that year was ~$90k:</p>
<p><img src="https://calebporzio.nyc3.cdn.digitaloceanspaces.com/blog_images/hundred_k_gh_sponsors/Screen%20Shot%202020-06-13%20at%209.53.07%20AM.png" alt="90k in income on a W2"></p>
<p>Developer salaries vary like crazy, but $90k was pretty solid for me. Combined with my wifeâ€™s income and some <a href="https://www.mrmoneymustache.com/blog/">Mustachianism</a> it was plenty to save up a chunk of cash for a rainy day. (Or for a few months of working un-paid on open source lol - SPOILER ALERT ðŸ˜¬)</p>
<p>After needing a change of scenery, I left Tighten on January 11th, 2019 to go on a â€œsabbaticalâ€� (fancy word for â€œtake a break and do whatever the hell I wantâ€œ ðŸ˜›) and then start freelancing or something after a couple of months.</p>
<p>4 days into my Sabbatical, I read <a href="https://dockyard.com/blog/2018/12/12/phoenix-liveview-interactive-real-time-apps-no-need-to-write-javascript">this post</a> and hastily made a proof of concept for <a href="https://laravel.com/">Laravel</a>.</p>
<p><img src="https://calebporzio.nyc3.cdn.digitaloceanspaces.com/blog_images/hundred_k_gh_sponsors/Screen%20Shot%202020-06-13%20at%2010.07.30%20AM.png" alt="Original Livewire tweet"></p>
<p>This day marked the abrupt end of my sabbatical. I was completely enamored with the project (now called <a href="https://laravel-livewire.com/">Livewire</a>) and couldnâ€™t stop working on it full-time. (Iâ€™ve never stopped. Iâ€™m STILL enamored with it full-time.)</p>
<p>(I also created a pretty popular JS framework along the way called <a href="https://github.com/alpinejs/alpine">AlpineJS</a> that I work on too, but thatâ€™s a story for another timeâ€¦)</p>
<p>Believe it or not, open-source software doesnâ€™t quite pay the bills, so I took on some small code mentorship clients to stay above the water for the entire year of 2019.</p>
<p>Here was my income for 2019 from that freelance work:</p>
<p><img src="https://calebporzio.nyc3.cdn.digitaloceanspaces.com/blog_images/hundred_k_gh_sponsors/Screen%20Shot%202020-06-13%20at%209.51.34%20AM.png" alt="$21k in self employed income for 2018"></p>
<p>I reduced my salary by ~$70k so I could pursue my passion. It seemed risky, but I knew it would only get harder to make this kind of move in life.</p>
<p>Lots of kind folks reached out to me along the way asking how they could help support the project. Sending me messages like this:</p>
<p><img src="https://calebporzio.nyc3.cdn.digitaloceanspaces.com/blog_images/hundred_k_gh_sponsors/Screen%20Shot%202020-06-13%20at%2010.13.29%20AM.png" alt="Email from a Livewire user asking to support on Patreon"></p>
<p>I avoided creating a Patreon for a long time because I kept picturing a world where a handful of people give me five bucks a month. Which would be nice, but never seemed worth it to me.</p>
<p>Then I saw <a href="https://github.com/sponsors">GitHub Sponsors</a>. ðŸ˜�</p>
<p>It seemed perfect. Hosted directly on GitHub and new enough that thereâ€™s some excitement around it.</p>
<p>I was accepted into GitHub Sponsors on Dec. 12th of 2019.</p>
<p><img src="https://calebporzio.nyc3.cdn.digitaloceanspaces.com/blog_images/hundred_k_gh_sponsors/Screen%20Shot%202020-06-13%20at%2010.17.23%20AM.png" alt="@faustbrian github user sponsoring at $24/mo on Dec 12th">
(Thanks for being my first sponsor, Brian! â�¤ï¸�)</p>
<p>Iâ€™ve since received ~$25k in cash from GitHub sponsorsâ€¦
(They match the first $5k, and they take a ZERO percent cut. You keep EVERYTHING ðŸ™ŒðŸ�»â�¤ï¸�)</p>
<p><img src="https://calebporzio.nyc3.cdn.digitaloceanspaces.com/blog_images/hundred_k_gh_sponsors/Screen%20Shot%202020-06-14%20at%201.36.58%20PM.png" alt="A payout statement from GH sponsors showing $25k in payouts"></p>
<p>â€¦and as of this writing, Iâ€™ve grown my annual GitHub sponsors revenue to $112,680/yr. ðŸŽ‰</p>
<p><img src="https://calebporzio.nyc3.cdn.digitaloceanspaces.com/blog_images/hundred_k_gh_sponsors/Screen%20Shot%202020-06-17%20at%205.23.46%20PM.png" alt="A screenshot of github sponsors dashboard showing $112680 in yearly revenue"></p>
<p>Wow.</p>
<p>I am now making more money than Iâ€™ve ever made while developing open-source software for a community that I adore. Pinch me, Iâ€™m dreaming.</p>
<p>Was it luck? thereâ€™s certainly been a lot of that.</p>
<p>Was it fate? Letâ€™s leave religion out of this mmkay?â€¦</p>
<p>Was it that the software I built was so incredibly compelling that it forced 535 people to give me at least $14/mo. to keep working on it? â€¦I wish.
Itâ€™s more than that though. There were some key things I did along the way to get here. Let me tell you all about them.</p>
<p>Here we go!</p>
<h2>Phase 1: Good-Hearted Folks</h2>
<p>At first, GitHub Sponsors was a place to send loyal/generous followers that wanted to support the project. </p>
<p>However saintly these people are, there arenâ€™t that many of them compared to the number of people actually using the software (and often making money on it).</p>
<p>Because of the nature of open-source, people are already getting the software for free, so without ADDING any value to their lives, this strategy is seriously limiting.</p>
<p>The first section of this income graph is solely from kind folks who just wanted to pitch in.</p>
<p><a href="https://sponsorsyrup.com/" target="__blank"><img src="https://calebporzio.com/post_images/3023657946.png"></a></p>
<p>Huge thank you to all those people.</p>
<p>Now letâ€™s talk about that first spike. </p>
<h2>Phase 2: Sponsorware</h2>
<p>Hereâ€™s where things started to get wild.</p>
<p>I had a cool idea for a small little Laravel package.</p>
<p><img src="https://calebporzio.nyc3.cdn.digitaloceanspaces.com/blog_images/hundred_k_gh_sponsors/7B10BCF2-60A7-421D-ACAC-EF1679BE70A2.png" alt="Sushi Laravel package tweet"></p>
<p>While recording an episode of <a href="https://noplanstomerge.com/">No Plans To Merge</a> with my buddy <a href="https://twitter.com/DCoulbourne">Daniel</a> on how to monetize it, we cooked up a novel idea called: â€œSponsorwareâ€�</p>
<iframe src="https://player.vimeo.com/video/394690352" width="640" height="480" frameborder="0" allow="autoplay; fullscreen" allowfullscreen=""></iframe>
<p>(<a href="https://noplanstomerge.simplecast.com/episodes/funding-opensource-software-aka-sponsorware">Listen To Full Episode</a>)</p>
<p>Hereâ€™s how Sponsorware works:</p>
<ul>
<li>Create a cool piece of software</li>
<li>Make it exclusive to people who sponsor you until you reach a certain number of sponsors</li>
<li>Then open source the project to the world</li>
</ul>
<p>Itâ€™s a win-win.</p>
<p>It worked incredibly well and I increased my yearly revenue by $11k in a matter of days.</p>
<p><a href="https://sponsorsyrup.com/" target="__blank"><img src="https://calebporzio.com/post_images/1455106854.png"></a></p>
<p>I did an entire writeup on â€œSponsorwareâ€� <a href="https://calebporzio.com/sponsorware">here</a> and was interviewed about the process on <a href="https://changelog.com/podcast/381">this episode of The Changelog Podcast</a>.</p>
<p>Also, a friend of mine <a href="https://twitter.com/enunomaduro">Nuno Maduro</a> recently replicated the technique with his project called <a href="https://pestphp.com/">Pest</a> and had similar success:</p>
<p><img src="https://calebporzio.nyc3.cdn.digitaloceanspaces.com/blog_images/hundred_k_gh_sponsors/C9AFA1F2-F052-4D7A-A3FE-A2B3A74E3EA6.png" alt="Nuno's tweet about Pest"></p>
<p>This technique is fantastic, but it requires me to have a constant stream of new ideas. All of which would become projects I would have to maintain ongoing. I needed something more reasonable for the long haul.</p>
<h2>Phase 3: Sponsored Screencasts</h2>
<p>This is where the VAST majority of my sponsorships came from.</p>
<p>The chart speaks for itself:</p>
<p><a href="https://sponsorsyrup.com/" target="__blank"><img src="https://calebporzio.com/post_images/2049117902.png"></a></p>
<p>So whatâ€™s the secret?</p>
<h3>Educational content.</h3>
<p>Building a useful piece of software is one thing. Educating people on how to use it is an entirely different thing. (A much less fun thing I might add)</p>
<p>I try to make <a href="https://laravel-livewire.com/docs">the docs</a> as good as possible, but thereâ€™s always a need for more advanced content.</p>
<p>Rather than taking on the huge task of creating an entire course or book on  Livewire. I decided to go a different route.</p>
<p>Hereâ€™s exactly what I did that took me from ~$40k to &gt;$100k in ~3 months:</p>
<p>I released a free set of screencasts on the basics of using Livewire:</p>
<p><img src="https://calebporzio.nyc3.cdn.digitaloceanspaces.com/blog_images/hundred_k_gh_sponsors/FE07E488-D224-4072-9508-05ECD3D6A250.png" alt="My tweet about new Livewire free screencasts"></p>
<p>I added links to other parts of the documentation pointing people towards them so they know theyâ€™re there:</p>
<p><img src="https://calebporzio.nyc3.cdn.digitaloceanspaces.com/blog_images/hundred_k_gh_sponsors/6D245849-06E2-42A5-82A6-2580BF6BF4EF.png" alt="A call to action telling docs visitors to watch the screencasts"></p>
<p>A few weeks later I added a new â€œprivateâ€� group of screencasts for GitHub sponsors only.</p>
<p><img src="https://calebporzio.nyc3.cdn.digitaloceanspaces.com/blog_images/hundred_k_gh_sponsors/54ECAE52-5CE3-4E9C-A990-CE0E04E2D9F4.png" alt="A screenshot of a video being restricted to sponsors only"></p>
<p>THIS is the secret sauce ðŸŒ¶ï¸�.</p>
<p>(To make all this happen I built a Laravel app with GitHub authentication that calls on the GitHub API to verify a userâ€™s sponsorship)</p>
<p>Now, people watching the screencasts will naturally encounter these â€œprivateâ€� screencasts and if they like the free ones, they will sponsor me (at $14/mo.) to get access.</p>
<p>I release a new batch of videos every time a new feature comes out, or I decide to cover a new Livewire technique.</p>
<p>I also provide sponsors with access to the source code for each lesson (which is hosted on a separate repo and will eventually become an entire web app written with Livewire).</p>
<p>In terms of income, this has been the single most impactful idea I have EVER had.</p>
<p>It raised my annual revenue by ~$80k in 90 days. Itâ€™s like magic.</p>
<p>Now I have a constant stream of income without having to spend all my time on major course launches. I can keep building the software I love for the community I love and release new screencasts over time (which I actually enjoy doing).</p>
<h2>Nuggets Iâ€™ve Picked Up Along The Way:</h2>
<h3>Make good stuff</h3>
<p>All of this works because I spent years and years honing my craft and producing software that is truly useful. Iâ€™ve poured everything I have into that work, and there are no shortcuts there. You saw earlier how I worked full-time on an open-source project for almost an entire year before seeing any returns. The work people are sponsoring for has to be quality and remain the #1 priority.</p>
<h3>Build an audience</h3>
<p>You can build the greatest tool on the internet, but it means nothing if no oneâ€™s paying attention to you. Building an audience is ESSENTIAL for any of this to work. Twitter followers and email subscribers are your most valuable asset. Again, no shortcuts here. Just hard work, and providing value to people publicly and consistently for a long time.</p>
<h3>Charge an impactful amount</h3>
<p>The biggest mistake people make with GitHub sponsors is offering too small of a first tier.</p>
<p>If people have the option of paying $1-5/mo. instead of &gt;$14, they will pay the lesser amount.</p>
<p>I realized early on that if I want to really make a go of this, Iâ€™d need more than five dollar sponsorships. I started at $9 for a long time and then bumped it to $14 for the screencasts.</p>
<p>Iâ€™ve added a $7 tier that gets no perks for kind folks that just want to say thanks but donâ€™t need anything in return. (These people are the aforementioned Saints ðŸ™�ðŸ�»)</p>
<h3>Pick better tier names</h3>
<p>When you are setting up your sponsorship tiers, pick names that describe the type of person the tier is suited for.</p>
<p>For example. For a higher tier, label it something like â€œThe Agencyâ€� or something that implies that a business should be sponsoring at a higher tier, rather than something vague like â€œPlatinumâ€�.</p>
<p>This way, when people are reading the tiers they will think to themselves: â€œWhat level of usage do I fall underâ€�, rather than: â€œHow much money do I want to spend per monthâ€�.</p>
<h3>Donâ€™t be afraid to talk about your sponsorships and how much you make</h3>
<p>I grew up thinking it was rude to talk about money. This is a lie. I got a ten thousand dollar raise once because a coworker told me how much they made. After I learned what they made I felt comfortable asking for that same amount. Nothing would have happened if they didnâ€™t tell me.</p>
<p>Transparency is health.</p>
<p>I donâ€™t hide what I make because Iâ€™ve benefited from others not hiding what they make.</p>
<p>Even if itâ€™s astronomically higher than me, Iâ€™m never bitter or entitled about it, Iâ€™m only ever excited and inspired. My hope is that others feel the same way.</p>
<p>On top of that, if youâ€™re excited about your GitHub sponsors revenue, others will be too!</p>
<p>Itâ€™s not rude to be totally up-front that you rely on this money and it helps you build the software people are using and benefiting from every day.</p>
<h3>Donâ€™t feel guilty about making a lot of money.</h3>
<p>I always remind myself that I am not a code missionary. If my sponsorship revenue climbs beyond a modest living, THATâ€™S OK. Itâ€™s not a non-profit.</p>
<p>Itâ€™s OK for my income to be proportional to the value my software adds to other peopleâ€™s lives.</p>
<p>This isnâ€™t holy work Iâ€™m doing. itâ€™s software that businesses use to make money. They profit from it. Itâ€™s OK to profit as well.</p>
<h2>Well Wishes</h2>
<p>I hope this saga at least amuses you, and at most provides a blueprint for making your own open-source projects financially sustainable.</p>
<p>SO many open source projects are started with enthusiasm …</p></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://calebporzio.com/i-just-hit-dollar-100000yr-on-github-sponsors-heres-how-i-did-it">https://calebporzio.com/i-just-hit-dollar-100000yr-on-github-sponsors-heres-how-i-did-it</a></em></p>]]>
            </description>
            <link>https://calebporzio.com/i-just-hit-dollar-100000yr-on-github-sponsors-heres-how-i-did-it</link>
            <guid isPermaLink="false">hacker-news-small-sites-23613719</guid>
            <pubDate>Tue, 23 Jun 2020 13:37:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Simulating Hydraulic Erosion]]>
            </title>
            <description>
<![CDATA[
Score 54 | Comments 10 (<a href="https://news.ycombinator.com/item?id=23612749">thread link</a>) | @schnautzi
<br/>
June 23, 2020 | https://jobtalle.com/simulating_hydraulic_erosion.html | <a href="https://web.archive.org/web/*/https://jobtalle.com/simulating_hydraulic_erosion.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content"><p><span>14 Jun 2020</span></p><h2>Simulating hydraulic erosion</h2><p><em>Hydraulic erosion</em> is the process by which water transforms terrain over time. This is mostly caused by rainfall, but also by ocean waves hitting the shore and the flow of rivers. Figure 1 shows the considerable effects that a small stream has had on the rocky environment around it. When creating realistically looking environments, the effects of erosion need to be accounted for. I have experimented with procedural terrain generation before to generate scenes for <a href="https://jobtalle.com/layered_voxel_rendering.html" target="_blank">layered voxel rendering</a> and to demonstrate <a href="https://jobtalle.com/cubic_noise.html" target="_blank">cubic noise</a>. These terrains were very basic and did not account for erosion. Therefore, they lack a lot of detail, making them unrealistic at closer inspection.</p><figure title="A small waterfall on La Palma"><img src="https://jobtalle.com/posts/2020_6_14/img/waterfall.jpg"><figcaption>Figure 1: A small waterfall.</figcaption></figure><p>In this article, I will detail a simple and fast method that approximates the effects of hydraulic erosion. The aim of this method is to create believable environments rather than reaching a high degree of realism. Fidelity may be sacrificed for the sake of speed, as long as the results look natural. Summarized, the method should do the following:</p><ul><li>The results must look <em>natural</em>.</li><li>The algorithm must be <em>simple</em>.</li><li>The algorithm must be <em>fast</em>.</li><li>The algorithm should simulate hydraulic erosion caused by <em>rainfall</em> and <em>rivers</em>.</li></ul><h2>Multiple approaches</h2><p>There are several different approaches when it comes to simulating erosion. All methods simulate the same phenomenon: water moving from high places to low places, eroding terrain as it flows, and depositing sediment as they go further down their paths. This process always results in a number of recognizable terrain features like gulleys and valleys where rivers flow, deltas where they meet their destination and <a href="https://en.wikipedia.org/wiki/Alluvial_fan" target="_blank">alluvial fans</a> where smaller streams combine into bigger rivers. While reading about this topic, I have encountered the following distinct strategies in research literature:</p><ul><li>Erosion is simulated by keeping track of where water is for every position on the terrain. A grid (or 2D array) is created for the environment, and water levels and pressures are kept for every cell. When updating, the pressures determine where the water flows to. While flowing, water moves sediment around.</li><li>Erosion is simulated by dropping many particles simulating raindrops on the terrain. The particles then move down the slopes of the terrain. They can bring sediment with them or deposit it.</li></ul><figure title="An island with simulated erosion"><img src="https://jobtalle.com/posts/2020_6_14/img/island.jpg"><figcaption>Figure 2: An island after erosion has been applied to it.</figcaption></figure><p>Mostly for performance reasons, I've chosen to implement a drop based method. Because most drops don't flow very far, many inactive drop simulations can be terminated early and the bulk of the processing power will go to the drops that actually carve out terrain features. The grid based simulation will need to simulate every part on the terrain for every update cycle.</p><h2>Snowballs</h2><p>The drops in the simulation can be seen as <em>snowballs</em> instead of raindrops. Within the context of the simulation, I believe this is a better analogy. The snowballs start small when they are dropped, but gain more material as they roll down the hills. When they become too big, they start shedding material as they go. When they stop rolling in valleys or in the sea, the snowballs fall apart and leave their material on the terrain.</p><p>The complete erosion algorithm (in <em>Javascript</em>) can be read below. This code uses a <code>heightMap</code> object to erode. This height map can be read from and written to, and the <code>sampleNormal</code> function can be used to get the surface normal. This is a 3D vector pointing upwards from the terrain, so it can be used to determine the slope direction and steepness.</p><pre>/**
 * Let a snowball erode the height map
 * @param {Number} x The X coordinate to start at
 * @param {Number} y The Y coordinate to start at
 */
trace = function(x, y) {
  const ox = (random.getFloat() * 2 - 1) * radius; // The X offset
  const oy = (random.getFloat() * 2 - 1) * radius; // The Y offset
  let sediment = 0; // The amount of carried sediment
  let xp = x; // The previous X position
  let yp = y; // The previous Y position
  let vx = 0; // The horizontal velocity
  let vy = 0; // The vertical velocity

  for (let i = 0; i &lt; maxIterations; ++i) {
    // Get the surface normal of the terrain at the current location
    const surfaceNormal = heightMap.sampleNormal(x + ox, y + oy);

    // If the terrain is flat, stop simulating, the snowball cannot roll any further
    if (surfaceNormal.y === 1)
      break;

    // Calculate the deposition and erosion rate
    const deposit = sediment * depositionRate * surfaceNormal.y;
    const erosion = erosionRate * (1 - surfaceNormal.y) * Math.min(1, i * iterationScale);

    // Change the sediment on the place this snowball came from
    heightMap.change(xp, yp, deposit - erosion);
    sediment += erosion - deposit;

    vx = friction * vx + surfaceNormal.x * speed;
    vy = friction * vy + surfaceNormal.z * speed;
    xp = x;
    yp = y;
    x += vx;
    y += vy;
  }
};

// Simulate 50000 snowballs
const snowballs = 50000;

for (let i = 0; i &lt; snowballs; ++i)
  trace(
    random.getFloat() * width,
    random.getFloat() * height);

// Blur the height map to smooth out the effects
heightMap.blur();
</pre><p>The algorithm has a few notable properties:</p><ul><li>The variables <code>ox</code> and <code>oy</code> encode the <em>offset</em> of a snowball. They are used to read the terrain slope with a certain offset to make the snowball motion a bit rougher, which prevents snowball paths from converging too much.</li><li>When the surface normal points perfectly upwards (when the y value of that normal equals one), the snowball terminates. In practice, this means that snowballs that have reached the edge of the simulated are or the sea floor stop simulating there. Because nothing happens in those areas, simulating erosion would be a waste of processing power.</li><li>When changing the amount of sediment, the snowball edits the height map at its previous position instead of its current position. Erosion and deposition take place behind it to prevent snowballs from digging themselves in.</li><li>After simulating erosion, gaussian blur is applied to the height map. Because the height map in these examples has a low resolution, blur is required to keep the surfaces smooth enough to be visually appealing.</li></ul><p>Because the offset is used while eroding, and because the erosion rate is quite high, every traced snowball has a larger influence on the terrain than a smaller node that looks more like a raindrop would. This results in a fast simulation, but it reduces precision.</p><h2>Results</h2><figure title="The results of the erosion algorithm"><img src="https://jobtalle.com/posts/2020_6_14/img/results.jpg"><figcaption>Figure 3: The results of the erosion algorithm.</figcaption></figure><p>Applying the algorithm above with varying snowball counts gives the results rendered in Figure 3. The algorithm <a href="https://jobtalle.com/HydraulicErosion" target="_blank">works in a browser</a>, and the source code can be found <a href="https://github.com/jobtalle/HydraulicErosion" target="_blank">on GitHub</a>. Pressing the space bar generates a new island. The "starting material" for the algorithm is shown in the first image of figure 3. This island shape was generated using a very similar algorithm to the one I used in <a href="https://jobtalle.com/layered_voxel_rendering.html" target="_blank">my layered voxel rendering example terrains</a>. While the shape does contain some details and ridges, it is very smooth and contains no traces of hydraulic erosion.</p><p>The second image shows the same island after dropping 35.000 snowballs on it. They are dropped randomly and evenly spaced. Because of the random initial conditions of the starting shape, valleys and river like structures form where the snowballs find the quickest way to the sea. 35.000 may seem like a high number, but recall that snowballs that reach the sea floor or the edge of the map terminate early. The majority of drops don't fall on the island, so only a small number will actualy roll down one of the valleys that can be seen in the image.</p><p>The third image shows the same island after dropping 50.000 snowballs. Compared to the previous image, no new details form, although the terrain features are more pronounced.</p><p>The last image shows the island after dropping 100.000 snowballs. This is clearly too much; the ridges become very deep and the shore is very rough. At this point, the results start looking less realistic too. The valleys carve out very sharp terrain features that would erode away themselves.</p><p>All islands in the images above can be generated within half a second on my desktop computer, with the algorithm running on a single CPU thread. Therefore, it is not necessary to reduce the number of snowballs for performance reasons in most applications. The algorithm is fast enough as it is.</p><h2>Conclusion</h2><p>The proposed algorithm provides a fast method to approximate hydraulic erosion. While realism was no priority, erosion and deposition patterns that one would expect do show up when testing the method on various terrains.</p><p>Because the code runs very fast (contrary to most alternative solutions that can be found in the literature), it may be suitable for applications like procedural terrain generation in games. In those applications, it is desirable to produce results quickly, while the results do not need to be very realistic; they just need to look credible.</p><p>The method can be extended to track the paths of river beds. Valleys where many snowballs roll through would realistically be rivers. When an area reaches a certain threshold of "snowball traffic", a river or lake can be created there.</p><p>Another interesting addition would be a texture that keeps track of the amount of erosion and deposition of material on the terrain. This data can then be used to color the terrain; if lots of material is deposited, sand and small particles will accumulate there. Areas where little erosion has taken place will look different from heavily eroded slopes.</p><h2>Appendix: rendering shore waves</h2><figure title="Waves"><img src="https://jobtalle.com/posts/2020_6_14/img/waves.jpg"><figcaption>Figure 4: Rendering shore waves.</figcaption></figure><p>The <a href="https://jobtalle.com/HydraulicErosion" target="_blank">animated example</a> contains waves that move towards the shore of the islands. Besides clarifying the shape of the shore, they don't really serve a purpose with regards to the erosion, but it makes the scene prettier.</p><p>Figure 4 shows the steps that create the wave animation:</p><ol>    <li>First, a <a href="https://en.wikipedia.org/wiki/Voronoi_diagram" target="_blank"><em>Voronoi diagram</em></a> is created around the island shore. Instead of creating a diagram from points, the diagram is created from …</li></ol></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://jobtalle.com/simulating_hydraulic_erosion.html">https://jobtalle.com/simulating_hydraulic_erosion.html</a></em></p>]]>
            </description>
            <link>https://jobtalle.com/simulating_hydraulic_erosion.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23612749</guid>
            <pubDate>Tue, 23 Jun 2020 12:02:21 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Sysinternals ProcDump for Linux]]>
            </title>
            <description>
<![CDATA[
Score 82 | Comments 23 (<a href="https://news.ycombinator.com/item?id=23612212">thread link</a>) | @GordonS
<br/>
June 23, 2020 | https://build5nines.com/sysinternals-procdump-for-linux/ | <a href="https://web.archive.org/web/*/https://build5nines.com/sysinternals-procdump-for-linux/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
					
<p>Sysinternals are very widely used tools from Microsoft in the Windows world, and now the ProcDump utility has been ported over to Linux as an Open Source project from Microsoft. ProcDump is a command-line (CLI) utility for monitoring an application for CPU spikes and generates crash dumps during the spike. An admin or developer can use these crash dumps to determine the cause of the spike. This tool was originally built for Windows, and now it’s available for use on Linux as well!</p>



<p>This is not a community port, but rather an official Open Source project from Microsoft. As such, this is the official Linux version of Sysinternals ProcDump created and maintained by Microsoft. Plus, it’s licensed under the MIT License.</p>



<br><h2>Linux ProcDump Usage</h2>



<pre><code>Usage: procdump [OPTIONS...] TARGET
   OPTIONS
      -h          Prints this help screen
      -C          Trigger core dump generation when CPU exceeds or equals specified value (0 to 100 * nCPU)
      -c          Trigger core dump generation when CPU is less than specified value (0 to 100 * nCPU)
      -M          Trigger core dump generation when memory commit exceeds or equals specified value (MB)
      -m          Trigger core dump generation when when memory commit is less than specified value (MB)
      -T          Trigger when thread count exceeds or equals specified value.
      -F          Trigger when filedescriptor count exceeds or equals specified value.
      -I          Polling frequency in milliseconds (default is 1000)
      -n          Number of core dumps to write before exiting (default is 1)
      -s          Consecutive seconds before dump is written (default is 10)
      -d          Writes diagnostic logs to syslog
   TARGET must be exactly one of these:
      -p          pid of the process
      -w          Name of the process executable</code></pre>



<h2>Linux ProcDump Examples</h2>



<p>Create core dump immediately:</p>



<pre><code>sudo procdump -p 1234</code></pre>



<p>Create 3 core dumps 10 seconds apart:</p>



<pre><code>sudo procdump -n 3 -p 1234</code></pre>



<p>Create 3 core dumps 5 seconds apart:</p>



<pre><code>sudo procdump -n 3 -s 5 -p 1234</code></pre>



<p>Create a core dump each time the process has CPU usage &gt;= 65%, up to 3 times, with at least 10 seconds between each dump:</p>



<pre><code>sudo procdump -C 65 -n 3 -p 1234</code></pre>



<p>Create a core dump when CPU usage is outside the range [10,65]:</p>



<pre><code>sudo procdump -c 10 -C 65 -p 1234</code></pre>



<h2>Download Sysinternals ProcDump for Linux</h2>



<p>The Sysinternals ProcDump for Linux utility is licensed under MIT License, and available over in it’s GitHub repo: <a href="https://github.com/Microsoft/ProcDump-for-Linux" target="_blank" rel="noopener">https://github.com/Microsoft/ProcDump-for-Linux</a></p>



<br><h3>System Requirements</h3>



<ul><li>Minimum Operating System<ul><li>Red Hat Enterprise Linux (RHEL) / CentOS 7</li><li>Fedora 29</li><li>Ubuntu 16.04 LTS</li></ul></li><li>gdb &gt;= 7.6.1</li><li>zlib (buil-time only)</li></ul>







<p>Happy monitoring your process dumps and troubleshooting your apps!</p>

<br><h3>Article Author</h3>
					<div id="author-info">
						<p><img alt="" src="https://secure.gravatar.com/avatar/d565ce4d3fdf8007e1d707362cca9465?s=128&amp;d=identicon&amp;r=g" srcset="https://secure.gravatar.com/avatar/d565ce4d3fdf8007e1d707362cca9465?s=256&amp;d=identicon&amp;r=g 2x" height="128" width="128" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7">																						<img id="author-img-mvp" src="https://build5nines.com/wp-content/uploads/2019/08/mvp_logo_horizontal_preferred_cyan300_rgb_300ppi_163x65.png" alt="Microsoft MVP">
													</p>
						
						<p id="author-desc">Chris is a <strong>Microsoft MVP</strong> and has 20 years of experience designing and building Cloud &amp; Enterprise systems. He is also a <strong>Microsoft Certified: Azure Solutions Architect</strong>, developer, <strong>Microsoft Certified Trainer</strong> (MCT), and Cloud Advocate. He has a passion for technology and sharing what he learns with others to help enable them to learn faster and be more productive.</p>
						
					</div>
					
						
										</div></div>]]>
            </description>
            <link>https://build5nines.com/sysinternals-procdump-for-linux/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23612212</guid>
            <pubDate>Tue, 23 Jun 2020 10:47:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[We’ve decided to rename Riot]]>
            </title>
            <description>
<![CDATA[
Score 346 | Comments 222 (<a href="https://news.ycombinator.com/item?id=23611863">thread link</a>) | @anotherevan
<br/>
June 23, 2020 | https://blog.riot.im/the-world-is-changing/ | <a href="https://web.archive.org/web/*/https://blog.riot.im/the-world-is-changing/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
				<p>Hi all,</p><p>It's almost four years since we launched Riot, and it's been a crazy journey - going from a relatively bare bones Matrix app through to today's all-singing, all-dancing encrypted-by-default collaboration tool used by folks ranging from Mozilla to the French Government and beyond.</p><p>However, as some may know, we’ve had a few problems with the name Riot over the years. &nbsp;Firstly, the biggest by far has been from a certain large games company that has consistently blocked us from being able to trademark Riot or even Riot.im - which has been a huge issue when it comes to defending users against abusive forks of the app. We’re in a terrible position if someone forks Riot using the same or similar name and logo, makes some dubious changes, and we can’t take action to persuade the app stores to remove it.</p><p>Secondly, we picked the name “Riot” to evoke something disruptive and vibrant - like a “riot of colour.” &nbsp;There’s a reason the loading animation on the mobile apps has been of the logo running riot through completely different versions of the logo. &nbsp;However, many people hear the word Riot and assume that the app is focused on violence - which it is not.</p><p>Finally, we’ve found that users can get very confused by the different brands that surround Riot. We can’t get away from the fact that Riot builds on Matrix rather than being yet another siloed communication app (and it's very deliberate that Riot is not named after Matrix). However, how come Riot is made by a company called New Vector? Why should I get a server for Riot from Modular, and what do they have to do with Riot or New Vector? What’s RiotX? After all, when I use Slack, it’s made by a company called Slack, who provide hosting called… Slack. Likewise Discord. Likewise Rocket.chat and many others. Back in 2016 it may have made sense to create three different brands (Riot, Modular, New Vector) to spell out the modularity of the ecosystem - but nowadays there are lots of other Matrix clients, vendors and hosting providers that demonstrate perfectly the diversity of the Matrix ecosystem.</p><p><strong>Therefore, we’ve decided to rename Riot (and New Vector, and Modular).</strong></p><p>The new name will be announced in a few weeks once we’re ready, but we wanted to give everyone a heads up so it doesn’t come as a shock. </p><p>This is obviously a bold move: we’ve spent four years building up Riot’s reputation and persuading everyone to move their friends, families and teams onto it. Renaming is inevitably going to cause some confusion. We know that many of you reading this will have put their neck on the line to get folks to adopt Riot, and we really appreciate how frustrating it may be to have to explain the change to your users.</p><p>However, we are extremely confident that now is the right time to fix the name. We’re in the process of landing gigantic improvements to Riot’s user experience and usability which will unrecognisably improve the app. &nbsp;So unrecognisably, in fact, that we can shed our skin and celebrate our long-awaited transition into being a truly mainstream-usable app. &nbsp;And most importantly, we’ve finally found a name which we’re really excited about (much more than we ever were about Riot!), and we hope you’ll like it too!</p><p>So… watch this space. We’re going to have our heads down for the next few weeks while we pull together all the waves of improvements we have in flight, and then all shall be revealed.</p><p>Thanks for using and supporting Riot. &nbsp;We’ll see you on the other side!</p><p>Matthew, Amandine &amp; all of New Vector (and Riot, and Modular)</p><p>P.S. discussion over at <a href="https://news.ycombinator.com/item?id=23611863">HN</a><br></p>
			</section></div>]]>
            </description>
            <link>https://blog.riot.im/the-world-is-changing/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23611863</guid>
            <pubDate>Tue, 23 Jun 2020 10:01:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Archival Identifiers for Digital Files]]>
            </title>
            <description>
<![CDATA[
Score 43 | Comments 19 (<a href="https://news.ycombinator.com/item?id=23611459">thread link</a>) | @todsacerdoti
<br/>
June 23, 2020 | https://blog.adamretter.org.uk/archival-identifiers-for-digital-files/ | <a href="https://web.archive.org/web/*/https://blog.adamretter.org.uk/archival-identifiers-for-digital-files/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-main">
<div>
<article>

<figure>
</figure>
<section>
<div>
<p>As part of Project Omega for TNA (<a href="https://www.nationalarchives.gov.uk/">The National Archives</a>), I have been thinking about how identifiers for Digital Files should be constructed. This blog entry continues on from my previous entry: <a href="https://blog.adamretter.org.uk/archival-catalog-identifiers/">Archival Catalogue Record Identifiers</a>.<strong> </strong></p><p>When considering development of a new archival catalogue that can describe both physical, digitised, and born digital records, we quickly realised that unlike its predecessors this catalogue will also need to describe digital files.</p><p>At this point you might think that I am mixing current concerns between what archives' have often thought of as two separate systems, 1) their Archival catalogue, and 2) their Digital Preservation system. Yes, I am, and intentionally so! However, I would argue that this soup has been cooking for some time; I have seen that until now digital preservation systems have had to include some aspect of cataloguing (for their digital records) as the traditional archival catalogues, that were already in-place, were ill-equipped to describe the new digital world. I believe that a clean and mutually-beneficial separation between cataloguing and (digital) preservation activities can be established, but that as practitioners we are still very much writing the book on digital preservation.</p><p>Anyway, I digress! The archival concept of a Digital File is a complex one, as archivists we have to ask difficult questions like:</p><ul>
<li>What is a digital file?</li>
<li>How do I describe a digital file?</li>
<li>Is a copy of a file the same digital file?</li>
<li>If I change the name of the file, is it still the same digital file?</li>
</ul>
<p>All of these things have to be considered when designing a scheme for local identifiers of Digital File. Without writing an extended article on various principles of digital preservation, it is perhaps enough to say that the file's path and/or name are not suitable for use as an identifier; in no small part due to both their transient nature, and inability to be combined with files from other systems which may cause rise to naming conflicts.</p><h3 id="the-current-approach">The Current Approach</h3><p>To date the predominant approach in digital preservation for generating identifiers for digital files has been to simply assign them a <a href="https://en.wikipedia.org/wiki/Universally_unique_identifier">UUID</a> (Universally Unique Identifier); more specifically a Version 4 UUID. This approach has several nice properties:</p><ul>
<li>
<p>These can be generated independently of each other.</p>
<p>You can just <em>magic</em> a UUID into existence without concern for other UUIDs that have gone before or come after it.</p>
<p>The chance of a collision is <a href="https://en.wikipedia.org/wiki/Universally_unique_identifier#Version_4_(random)#Collisions">incredibly small</a> - "<em>the probability to find a duplicate within 103 trillion version-4 UUIDs is one in a billion</em>".</p>
</li>
<li>
<p>They are relatively compact and presentable.</p>
<p>A UUID is just a 128-bit positive integer. This is typically formatted for presentation as a hexadecimal string of five components, totaling 36 printable characters, albeit they are not very human friendly.</p>
</li>
<li>
<p>They are cheap to compute.</p>
<p>On a modern laptop we can easily generate over 500,000 every second.</p>
</li>
</ul>
<h3 id="a-new-approach-content-identifiers"><br>A New Approach - Content Identifiers</h3><p>As an alternative to UUIDs, I am proposing a new approach for generating an identifier for Digital File which is computed from the content of the file itself.</p><p>I should be clear that this is not some stroke of genius on my part, similar approaches are already widely used in other domains. For example, the <a href="https://git-scm.com/">Git</a> SCM (Source Code Management) uses SHA1 digests to identify files and changes. Likewise, the <a href="https://en.wikipedia.org/wiki/InterPlanetary_File_System">IPFS</a> (InterPlanetary File System) uses <a href="https://docs.ipfs.io/guides/concepts/cid/">its definition of a CID</a> (Content Identifier), which is a hash function's digest of a file's content to address that file.</p><p>To avoid any confusion between IPFS CID's and our "Content Identifiers", I will herein use the abbreviation ACID (Archival Content Identifier) to refer to my proposal for identifiers.</p><p>The main part of an ACID is generated by computing the digest of the byte-stream (i.e. content) of the digital file via a hash function. This raises the question, of which hash function should be used? There is a wealth of <a href="https://en.wikipedia.org/wiki/List_of_hash_functions">different hash algorithms</a> available with various properties and different trade-offs. That being said, I am going to suggest that we use a <a href="https://blake2.net/">BLAKE2b</a>-256 hash for the following reasons:</p><ul>
<li>Recognised and verified by NIST.</li>
<li>Likelihood of collision is incredibly small.</li>
<li>Much faster to generate than equivalents such as SHA-256.</li>
<li>At least as secure as SHA-3.</li>
</ul>
<p>For example, if we wanted to generate a BLAKE2b-256 hash digest for the Apache 2.0 License file, we could run:</p><pre><code>curl https://www.apache.org/licenses/LICENSE-2.0.txt | b2sum --length 256 --binary</code></pre><p>This yields a 256-bit number encoded into a hexadecimal string totaling 64 printable characters:</p><pre><code>3cbae8f16217ad44981e5843100092cd582202e69d452eb094480f2d24abdb49</code></pre><p>This hexadecimal string has some interesting properties:</p><ul>
<li>
<p>It can be used an an identifier for the Digital File.</p>
</li>
<li>
<p>Verifiable Descriptions.</p>
<p>Provoided with both, 1) the description and identifier of a digital file and, 2) the file itself, we can verify that the description is indeed about the file by re-computing the hash digest of the file and comparing the result with the digital file identifier.</p>
</li>
<li>
<p>Verifiable Preservation.</p>
<p>Similarly to above, if the hash digest of the file changes over time, then we can assert that there has been an issue with its preservation, e.g. <a href="https://en.wikipedia.org/wiki/Data_degradation">data-rot</a>.</p>
</li>
</ul>
<p>There are some down-sides to using a hash digest as opposed to a UUID:</p><ul>
<li>
<p>More expensive to compute.</p>
<p>A hash digest is much more expensive to compute than a UUID, and the larger the file being digested the more expensive it becomes.</p>
</li>
<li>
<p>Less compact.</p>
<p>Our 256-bit hash generates a result which is twice as long as a UUID.</p>
</li>
</ul>
<p>I believe that the down-sides of a hash digest are outweighed by its advantage of offering verifiability.</p><p><strong>Which Hash Function was it?</strong></p><p>For the purposes of preservation and interoperability, one thing that we have not yet considered is how one determines which hash function was used to generate an identifier. Sure, I said we would use BLAKE2b-256, but what if you want to use a different hash function? Also, from an digital archaeological perspective, given an identifier like:</p><pre><code>3cbae8f16217ad44981e5843100092cd582202e69d452eb094480f2d24abdb49</code></pre><p>You might be able to infer that it is a hash digest, and the selection of characters used and the number of them would indicate that it could be a 256-bit hash... but which hash function was used?</p><p>Ideally, we need a mechanism to also communicate the hash function that was used. In fact IPFS already thought about this, and they use an encoding called <a href="https://multiformats.io/multihash/">Multihash</a> which prefixes their CIDs with a code indicating the hash function used. Whilst we could adopt Multihash here, it's much more complex than we need (famous last words?!?). Instead, I propose that our ACID's have a single ASCII character at the start that indicates the hash function that was used. A single ASCII character has the advantage of a fixed-length numeric encoding, and it makes the number of characters in the hexadecimal string representation an odd number, thus providing a hint to a digital archeologist that perhaps this ACID is similar to a digest but with an extra character. I will go one step further and say that this character should be outside of the hexadecimal alphabet (and ignorant of case-sensitivity), this should make it glaringly obvious to such a digital archeologist that the prefix character has a meaning which is distinct from the rest of the string.</p><p>An ACID is then formatted from a template like this:</p><pre><code>{Hash Function Type}{Hash Digest}</code></pre><p>For the Hash Function Type, I am going to reserve the <code>!</code> character to indicate BLAKE2b-256. Why? Because, I think it looks cool! This would mean that our earlier digital file identifier now simply becomes:</p><pre><code>!3cbae8f16217ad44981e5843100092cd582202e69d452eb094480f2d24abdb49</code></pre><p><br><strong>What about Collisions?</strong></p><p>Sure, generating a digital file identifier with BLAKE2b-256 has a very small chance of generating a collision (i.e. two different files with the same identifier), but what if...?</p><p>If you detect a collision, I will build you a new digital archive system for free... Nope! Just joking! We actually already have a mechanism for coping with this, the Hash Function Type; for the new file which creates the collision you could switch to a different hash function, perhaps a 512-bit one! This would at least give you a different unique identifier. But... what to do about the original file which is on the other side of the collision, it's probably deeply embedded in your archive by now! You could re-catalogue it, but maybe you don't even need to???<br></p><p><br>I have in mind the idea to write another article about further encoding such ACID's for compact machine use. Okay… that’s enough for today!</p>
</div>
</section>

</article>
</div>
</div></div>]]>
            </description>
            <link>https://blog.adamretter.org.uk/archival-identifiers-for-digital-files/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23611459</guid>
            <pubDate>Tue, 23 Jun 2020 08:58:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Learning operating system development using Linux kernel and Raspberry Pi]]>
            </title>
            <description>
<![CDATA[
Score 440 | Comments 38 (<a href="https://news.ycombinator.com/item?id=23611081">thread link</a>) | @weeber
<br/>
June 23, 2020 | https://s-matyukevich.github.io/raspberry-pi-os/ | <a href="https://web.archive.org/web/*/https://s-matyukevich.github.io/raspberry-pi-os/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <section id="main_content">
        

<p>This repository contains a step-by-step guide that teaches how to create a simple operating system (OS) kernel from scratch. I call this OS Raspberry Pi OS or just RPi OS. The RPi OS source code is largely based on <a href="https://github.com/torvalds/linux">Linux kernel</a>, but the OS has very limited functionality and supports only <a href="https://www.raspberrypi.org/products/raspberry-pi-3-model-b/">Raspberry PI 3</a>.</p>

<p>Each lesson is designed in such a way that it first explains how some kernel feature is implemented in the RPi OS, and then it tries to demonstrate how the same functionality works in the Linux kernel. Each lesson has a corresponding folder in the <a href="https://github.com/s-matyukevich/raspberry-pi-os/tree/master/src">src</a> directory, which contains a snapshot of the OS source code at the time when the lesson had just been completed. This allows the introduction of new concepts gracefully and helps readers to follow the evolution of the RPi OS. Understanding this guide doesn’t require any specific OS development skills.</p>

<p>For more information about project goals and history, please read the <a href="https://s-matyukevich.github.io/raspberry-pi-os/docs/Introduction.html">Introduction</a>. The project is still under active development, if you are willing to participate - please read the <a href="https://s-matyukevich.github.io/raspberry-pi-os/docs/Contributions.html">Contribution guide</a>.</p>

<p>
  <a href="https://twitter.com/RPi_OS" target="_blank">
    <img src="https://raw.githubusercontent.com/s-matyukevich/raspberry-pi-os/master/images/twitter.png" alt="Follow @RPi_OS on twitter" height="34">
  </a>

  <a href="https://www.facebook.com/groups/251043708976964/" target="_blank">
    <img src="https://raw.githubusercontent.com/s-matyukevich/raspberry-pi-os/master/images/facebook.png" alt="Follow Raspberry Pi OS on facebook" height="34">
  </a>

  <a href="https://join.slack.com/t/rpi-os/shared_invite/enQtNDQ1NTg2ODc1MDEwLWVjMTZlZmMyZDE4OGEyYmMzNTY1YjljZjU5YWI1NDllOWEwMjI5YzVkM2RiMzliYjEzN2RlYmUzNzBiYmQyMjY" target="_blank">
    <img src="https://raw.githubusercontent.com/s-matyukevich/raspberry-pi-os/master/images/slack.png" alt="Join Raspberry Pi OS in slack" height="34">
  </a>

  <a href="https://www.producthunt.com/upcoming/raspberry-pi-os" target="_blank">
    <img src="https://raw.githubusercontent.com/s-matyukevich/raspberry-pi-os/master/images/subscribe.png" alt="Subscribe for updates" height="34">
  </a>
</p>

<h2 id="table-of-contents">Table of Contents</h2>

<ul>
  <li><strong><a href="https://s-matyukevich.github.io/raspberry-pi-os/docs/Introduction.html">Introduction</a></strong></li>
  <li><strong><a href="https://s-matyukevich.github.io/raspberry-pi-os/docs/Contributions.html">Contribution guide</a></strong></li>
  <li><strong><a href="https://s-matyukevich.github.io/raspberry-pi-os/docs/Prerequisites.html">Prerequisites</a></strong></li>
  <li><strong>Lesson 1: Kernel Initialization</strong>
    <ul>
      <li>1.1 <a href="https://s-matyukevich.github.io/raspberry-pi-os/docs/lesson01/rpi-os.html">Introducing RPi OS, or bare metal “Hello, world!”</a></li>
      <li>Linux
        <ul>
          <li>1.2 <a href="https://s-matyukevich.github.io/raspberry-pi-os/docs/lesson01/linux/project-structure.html">Project structure</a></li>
          <li>1.3 <a href="https://s-matyukevich.github.io/raspberry-pi-os/docs/lesson01/linux/build-system.html">Kernel build system</a></li>
          <li>1.4 <a href="https://s-matyukevich.github.io/raspberry-pi-os/docs/lesson01/linux/kernel-startup.html">Startup sequence</a></li>
        </ul>
      </li>
      <li>1.5 <a href="https://s-matyukevich.github.io/raspberry-pi-os/docs/lesson01/exercises.html">Exercises</a></li>
    </ul>
  </li>
  <li><strong>Lesson 2: Processor initialization</strong>
    <ul>
      <li>2.1 <a href="https://s-matyukevich.github.io/raspberry-pi-os/docs/lesson02/rpi-os.html">RPi OS</a></li>
      <li>2.2 <a href="https://s-matyukevich.github.io/raspberry-pi-os/docs/lesson02/linux.html">Linux</a></li>
      <li>2.3 <a href="https://s-matyukevich.github.io/raspberry-pi-os/docs/lesson02/exercises.html">Exercises</a></li>
    </ul>
  </li>
  <li><strong>Lesson 3: Interrupt handling</strong>
    <ul>
      <li>3.1 <a href="https://s-matyukevich.github.io/raspberry-pi-os/docs/lesson03/rpi-os.html">RPi OS</a></li>
      <li>Linux
        <ul>
          <li>3.2 <a href="https://s-matyukevich.github.io/raspberry-pi-os/docs/lesson03/linux/low_level-exception_handling.html">Low level exception handling</a></li>
          <li>3.3 <a href="https://s-matyukevich.github.io/raspberry-pi-os/docs/lesson03/linux/interrupt_controllers.html">Interrupt controllers</a></li>
          <li>3.4 <a href="https://s-matyukevich.github.io/raspberry-pi-os/docs/lesson03/linux/timer.html">Timers</a></li>
        </ul>
      </li>
      <li>3.5 <a href="https://s-matyukevich.github.io/raspberry-pi-os/docs/lesson03/exercises.html">Exercises</a></li>
    </ul>
  </li>
  <li><strong>Lesson 4: Process scheduler</strong>
    <ul>
      <li>4.1 <a href="https://s-matyukevich.github.io/raspberry-pi-os/docs/lesson04/rpi-os.html">RPi OS</a></li>
      <li>Linux
        <ul>
          <li>4.2 <a href="https://s-matyukevich.github.io/raspberry-pi-os/docs/lesson04/linux/basic_structures.html">Scheduler basic structures</a></li>
          <li>4.3 <a href="https://s-matyukevich.github.io/raspberry-pi-os/docs/lesson04/linux/fork.html">Forking a task</a></li>
          <li>4.4 <a href="https://s-matyukevich.github.io/raspberry-pi-os/docs/lesson04/linux/scheduler.html">Scheduler</a></li>
        </ul>
      </li>
      <li>4.5 <a href="https://s-matyukevich.github.io/raspberry-pi-os/docs/lesson04/exercises.html">Exercises</a></li>
    </ul>
  </li>
  <li><strong>Lesson 5: User processes and system calls</strong>
    <ul>
      <li>5.1 <a href="https://s-matyukevich.github.io/raspberry-pi-os/docs/lesson05/rpi-os.html">RPi OS</a></li>
      <li>5.2 <a href="https://s-matyukevich.github.io/raspberry-pi-os/docs/lesson05/linux.html">Linux</a></li>
      <li>5.3 <a href="https://s-matyukevich.github.io/raspberry-pi-os/docs/lesson05/exercises.html">Exercises</a></li>
    </ul>
  </li>
  <li><strong>Lesson 6: Virtual memory management</strong>
    <ul>
      <li>6.1 <a href="https://s-matyukevich.github.io/raspberry-pi-os/docs/lesson06/rpi-os.html">RPi OS</a></li>
      <li>6.2 Linux (In progress)</li>
      <li>6.3 <a href="https://s-matyukevich.github.io/raspberry-pi-os/docs/lesson06/exercises.html">Exercises</a></li>
    </ul>
  </li>
  <li><strong>Lesson 7: Signals and interrupt waiting</strong> (To be done)</li>
  <li><strong>Lesson 8: File systems</strong> (To be done)</li>
  <li><strong>Lesson 9: Executable files (ELF)</strong> (To be done)</li>
  <li><strong>Lesson 10: Drivers</strong> (To be done)</li>
  <li><strong>Lesson 11: Networking</strong> (To be done)</li>
</ul>


      </section>
    </div></div>]]>
            </description>
            <link>https://s-matyukevich.github.io/raspberry-pi-os/</link>
            <guid isPermaLink="false">hacker-news-small-sites-23611081</guid>
            <pubDate>Tue, 23 Jun 2020 08:00:43 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Cheap tricks for high-performance Rust]]>
            </title>
            <description>
<![CDATA[
Score 65 | Comments 5 (<a href="https://news.ycombinator.com/item?id=23609434">thread link</a>) | @O_H_E
<br/>
June 22, 2020 | https://deterministic.space/high-performance-rust.html | <a href="https://web.archive.org/web/*/https://deterministic.space/high-performance-rust.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody">
    <p>So you’re writing Rust but it’s not fast enough?
Even though you’re using <code>cargo build --release</code>?
Here’s some small things you can do to increase the runtime speed of a Rust project
– practically without changing any code!</p>

<p>Please remember that the following suggestions <strong>do not</strong> replace actual profiling and optimizations!
I also think it goes without saying that the only way to detect if any of this helps
is having benchmarks that represent how your application behaves under real usage.</p>

<h2 id="tweaking-our-release-profile">Tweaking our <code>release</code> profile</h2>

<p>Let’s first of all enable some more optimizations
for when we do <code>cargo build --release</code>.
The deal is pretty simple:
We enable some features that make building release builds even slower
but get more thorough optimizations as a reward.</p>

<p>We add the flags described below to our main <code>Cargo.toml</code> file,
i.e., the top most manifest file in case you are using a <a href="https://doc.rust-lang.org/1.41.1/book/ch14-03-cargo-workspaces.html">Cargo workspace</a>.
If you don’t already have a section called <code>profile.release</code>, add it:</p>



<h3 id="link-time-optimization">Link-time optimization</h3>

<p>The first thing we’ll do is enable <a href="https://llvm.org/docs/LinkTimeOptimization.html">link-time optimization</a> (LTO).
It’s a kind of whole-program or inter-module optimization as it runs as the very last step
when linking the different parts of your binary together.
You can think of it as allowing
better inlining across dependency boundaries
(but it’s of course more complicated that that).</p>

<p>Rust can use multiple linker flavors,
and the one we want is “optimize across all crates”, which is called “fat”.
To set this, add the <a href="https://doc.rust-lang.org/1.41.1/rustc/codegen-options/index.html#lto"><code>lto</code></a> flag to your profile:</p>



<h3 id="code-generation-units">Code generation units</h3>

<p>Next up is a similar topic.
To speed up compile times, Rust tries to split your crates into small chunks
and compile as many in parallel as possible.
The downside is that there’s less opportunities for the compiler
to optimize code across these chunks.
So, let’s <a href="https://doc.rust-lang.org/1.41.1/rustc/codegen-options/index.html#codegen-units">tell it</a> to do one chunk per crate:</p>



<h3 id="setting-a-specific-target-cpu">Setting a specific target CPU</h3>

<p>By default, Rust wants to build a binary that works on as many machines
of the target architecture as possible.
However, you might actually have a pretty new CPU with cool new features!
To <a href="https://doc.rust-lang.org/1.41.1/rustc/codegen-options/index.html#target-cpu">enable</a> those, we add</p>



<p>as a “Rust flag”,
i.e. the environment variable <code>RUSTFLAGS</code>
or the target’s <code>rustflags</code> field in your <a href="https://doc.rust-lang.org/1.41.1/cargo/reference/config.html"><code>.cargo/config</code></a>.</p>

<h3 id="aborting">Aborting</h3>

<p>Now we get into some of the more unsafe options.
Remember how Rust by default uses <a href="https://doc.rust-lang.org/1.41.1/nomicon/unwinding.html">stack unwinding</a>
(on the most common platforms)?
That costs performance!
Let’s skip stack traces and the ability to catch panics
for reduced code size and better cache usage:</p>



<p>Please note that some libraries might depend on unwinding
and will explode horribly if you enable this!</p>

<h2 id="using-a-different-allocator">Using a different allocator</h2>

<p>One thing many Rust programs do is allocate memory.
And they don’t just do this themselves but actually use an (external) library for that:
an allocator.
Current Rust binaries use the default system allocator by default,
previously they included their own with the standard library.
(This change has lead to smaller binaries and better debug-abiliy
which made some people quite happy).</p>

<p>Sometimes your system’s allocator is not the best pick, though.
Not to worry, we can change it!
I suggest giving both <a href="https://github.com/jemalloc/jemalloc">jemalloc</a> and <a href="https://github.com/microsoft/mimalloc">mimalloc</a> a try.</p>

<h3 id="jemalloc">jemalloc</h3>

<p><a href="https://github.com/jemalloc/jemalloc">jemalloc</a> is the allocator that Rust previously shipped with
and that the Rust compiler still uses itself.
Its focus is to reduce memory fragmentation and support high concurrency.
It’s also the default allocator on FreeBSD.
If this sounds interesting to you, let’s give it a try!</p>

<p>First off, add the <a href="https://docs.rs/jemallocator"><code>jemallocator</code></a> crate as a dependency:</p>

<div><div><pre><code><span>[dependencies]</span>
<span>jemallocator</span> <span>=</span> <span>"0.3.2"</span>
</code></pre></div></div>

<p>Then in your applications entry point (<code>main.rs</code>),
set it as the global allocator like this:</p>

<div><div><pre><code><span>#[global_allocator]</span>
<span>static</span> <span>GLOBAL</span><span>:</span> <span>jemallocator</span><span>::</span><span>Jemalloc</span> <span>=</span> <span>jemallocator</span><span>::</span><span>Jemalloc</span><span>;</span>
</code></pre></div></div>

<p>Please note that jemalloc doesn’t support all platforms.</p>

<h3 id="mimalloc">mimalloc</h3>

<p>Another interesting alternative allocator is <a href="https://github.com/microsoft/mimalloc">mimalloc</a>.
It was developed by Microsoft, has quite a small footprint,
and some innovative ideas for free lists.</p>

<p>It also features configurable security features
(have a look at <a href="https://github.com/purpleprotocol/mimalloc_rust/blob/c6bf4578d3258a0b6a28696196ede6d50e5ee8c2/Cargo.toml#L25-L28">its <code>Cargo.toml</code></a>).
Which means we can turn them off more performance!
Add the <a href="https://docs.rs/mimalloc"><code>mimalloc</code> crate</a> as a dependency like this:</p>

<div><div><pre><code><span>[dependencies]</span>
<span>mimalloc</span> <span>=</span> <span>{</span> <span>version</span> <span>=</span> <span>"0.1.17"</span><span>,</span> <span>default-features</span> <span>=</span> <span>false</span> <span>}</span>
</code></pre></div></div>

<p>and, same as above, add this to your entry point file:</p>

<div><div><pre><code><span>#[global_allocator]</span>
<span>static</span> <span>GLOBAL</span><span>:</span> <span>mimalloc</span><span>::</span><span>MiMalloc</span> <span>=</span> <span>mimalloc</span><span>::</span><span>MiMalloc</span><span>;</span>
</code></pre></div></div>

<h2 id="profile-guided-optimization">Profile Guided Optimization</h2>

<p>This is a neat feature of LLVM
but I’ve never used it.
Please read <a href="https://doc.rust-lang.org/1.41.1/rustc/profile-guided-optimization.html">the docs</a>.</p>

<h2 id="actual-profiling-and-optimizing-your-code">Actual profiling and optimizing your code</h2>

<p>Now this is where you need to actually adjust your code
and fix all those <code>clone()</code> calls.
Sadly, this is a topic for another post!
(While you wait another year for me to write it, you can read about <a href="https://deterministic.space/secret-life-of-cows.html">cows</a>!)</p>

<p><strong>Edit:</strong> People keep asking for those actual tips on how to optimize Rust code.
And luckily <del>I tricked them</del> they had some good material for me to link to:</p>

<ul>
  <li>The very convenient <a href="https://github.com/flamegraph-rs/flamegraph"><code>cargo flamegraph</code></a> (also works as a standalone tool)</li>
  <li>Christopher Sebastian recently published <a href="https://likebike.com/posts/How_To_Write_Fast_Rust_Code.html">How To Write Fast Rust Code</a></li>
  <li>Jack Fransham’s <a href="http://troubles.md/posts/rustfest-2018-workshop/">Fastware Workshop</a> from RustFest 2018</li>
</ul>


  </div></div>]]>
            </description>
            <link>https://deterministic.space/high-performance-rust.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-23609434</guid>
            <pubDate>Tue, 23 Jun 2020 02:44:05 GMT</pubDate>
        </item>
    </channel>
</rss>
