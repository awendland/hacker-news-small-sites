<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 20]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 20. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Fri, 11 Dec 2020 04:35:04 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-20.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Fri, 11 Dec 2020 04:35:04 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[Building a scalable e-commerce data model]]>
            </title>
            <description>
<![CDATA[
Score 96 | Comments 12 (<a href="https://news.ycombinator.com/item?id=25353148">thread link</a>) | @robric
<br/>
December 8, 2020 | https://resources.fabric.inc/blog/ecommerce-data-model | <a href="https://web.archive.org/web/*/https://resources.fabric.inc/blog/ecommerce-data-model">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<div>
<div data-widget-type="cell" data-x="0" data-w="12">

<div>
<div>
<div data-widget-type="custom_widget" data-x="0" data-w="12">
<div id="hs_cos_wrapper_module_151388194052436" data-hs-cos-general-type="widget" data-hs-cos-type="module">
    
<div>
<div>
<div>

 
<div>
<p><img width="100" height="100" alt="James Hickey" src="https://resources.fabric.inc/hs-fs/hubfs/james-hickey.jpeg?width=100&amp;height=100&amp;name=james-hickey.jpeg" srcset="https://resources.fabric.inc/hs-fs/hubfs/james-hickey.jpeg?width=50&amp;height=50&amp;name=james-hickey.jpeg 50w, https://resources.fabric.inc/hs-fs/hubfs/james-hickey.jpeg?width=100&amp;height=100&amp;name=james-hickey.jpeg 100w, https://resources.fabric.inc/hs-fs/hubfs/james-hickey.jpeg?width=150&amp;height=150&amp;name=james-hickey.jpeg 150w, https://resources.fabric.inc/hs-fs/hubfs/james-hickey.jpeg?width=200&amp;height=200&amp;name=james-hickey.jpeg 200w, https://resources.fabric.inc/hs-fs/hubfs/james-hickey.jpeg?width=250&amp;height=250&amp;name=james-hickey.jpeg 250w, https://resources.fabric.inc/hs-fs/hubfs/james-hickey.jpeg?width=300&amp;height=300&amp;name=james-hickey.jpeg 300w" sizes="(max-width: 100px) 100vw, 100px"> 
</p>
<div>
<p id="hubspot-author_data" data-hubspot-form-id="author_data" data-hubspot-name="Blog Author">
James Hickey
</p>
<p> December 08</p><p> &nbsp; • &nbsp;</p>
<p>
7 minute read
</p>
</div>
</div>
</div>
<p><img src="https://resources.fabric.inc/hubfs/ecommerce-data-model.png" alt="ecommerce data model">
</p>
<p><span id="hs_cos_wrapper_post_body" data-hs-cos-general-type="meta_field" data-hs-cos-type="rich_text"><p>If selling products online is a core part of your business, then you need to build an e-commerce data model that’s scalable, flexible, and fast. Most off-the-shelf providers like Shopify and BigCommerce are built for small stores selling a few million dollars in orders per month, so many e-commerce retailers working at scale start to investigate creating a bespoke solution.</p>
<!--more-->
<p>This article will look at what it takes to start building this infrastructure on your own. What are some of the areas to consider? What might the data model look like? How much work is involved?</p>
<p>Along the way, we’ll explore an alternative: API-based commerce platforms that manage data for you across product catalogs, pricing, and orders—without locking you into a monolith, and without requiring you to replatform.</p>
<p><em><strong>Note:</strong> A full summary diagram of the e-commerce data model is at the end of the article.</em></p>

<h2 id="who-are-your-customers-">Who Are Your Customers?</h2>
<p>First, you need to consider <em>who</em> will be purchasing items from your e-commerce application. How might you model customer information in a database as a result? You’ll probably want to have basic information like your customer's name, email address, etc. Do you want your customers to be able to create a profile in your system? Or just fill out a form each time they want to purchase something?</p>
<p>Just starting out, a basic model might look like this:</p>
<p><img src="https://resources.fabric.inc/hs-fs/hubfs/Basic%20e-commerce%20customer%20data%20model.png?width=308&amp;name=Basic%20e-commerce%20customer%20data%20model.png" alt="Basic e-commerce customer data model" width="308" srcset="https://resources.fabric.inc/hs-fs/hubfs/Basic%20e-commerce%20customer%20data%20model.png?width=154&amp;name=Basic%20e-commerce%20customer%20data%20model.png 154w, https://resources.fabric.inc/hs-fs/hubfs/Basic%20e-commerce%20customer%20data%20model.png?width=308&amp;name=Basic%20e-commerce%20customer%20data%20model.png 308w, https://resources.fabric.inc/hs-fs/hubfs/Basic%20e-commerce%20customer%20data%20model.png?width=462&amp;name=Basic%20e-commerce%20customer%20data%20model.png 462w, https://resources.fabric.inc/hs-fs/hubfs/Basic%20e-commerce%20customer%20data%20model.png?width=616&amp;name=Basic%20e-commerce%20customer%20data%20model.png 616w, https://resources.fabric.inc/hs-fs/hubfs/Basic%20e-commerce%20customer%20data%20model.png?width=770&amp;name=Basic%20e-commerce%20customer%20data%20model.png 770w, https://resources.fabric.inc/hs-fs/hubfs/Basic%20e-commerce%20customer%20data%20model.png?width=924&amp;name=Basic%20e-commerce%20customer%20data%20model.png 924w" sizes="(max-width: 308px) 100vw, 308px"></p>
<p>If you want your customers to have a persistent profile, then you need to build some way for them to log in to your application. Moving forward with more real-world requirements, you might also want to keep track of their login attempt history and password history.</p>
<p><img src="https://resources.fabric.inc/hs-fs/hubfs/More%20complex%20e-commerce%20customer%20data%20model.png?width=891&amp;name=More%20complex%20e-commerce%20customer%20data%20model.png" alt="More complex e-commerce customer data model" width="891" srcset="https://resources.fabric.inc/hs-fs/hubfs/More%20complex%20e-commerce%20customer%20data%20model.png?width=446&amp;name=More%20complex%20e-commerce%20customer%20data%20model.png 446w, https://resources.fabric.inc/hs-fs/hubfs/More%20complex%20e-commerce%20customer%20data%20model.png?width=891&amp;name=More%20complex%20e-commerce%20customer%20data%20model.png 891w, https://resources.fabric.inc/hs-fs/hubfs/More%20complex%20e-commerce%20customer%20data%20model.png?width=1337&amp;name=More%20complex%20e-commerce%20customer%20data%20model.png 1337w, https://resources.fabric.inc/hs-fs/hubfs/More%20complex%20e-commerce%20customer%20data%20model.png?width=1782&amp;name=More%20complex%20e-commerce%20customer%20data%20model.png 1782w, https://resources.fabric.inc/hs-fs/hubfs/More%20complex%20e-commerce%20customer%20data%20model.png?width=2228&amp;name=More%20complex%20e-commerce%20customer%20data%20model.png 2228w, https://resources.fabric.inc/hs-fs/hubfs/More%20complex%20e-commerce%20customer%20data%20model.png?width=2673&amp;name=More%20complex%20e-commerce%20customer%20data%20model.png 2673w" sizes="(max-width: 891px) 100vw, 891px"></p>
<p>You might also want to consider whether your customers are part of a large organization; and, if so, how would they like to handle password resets? Do they need single sign-on or OAuth support?</p>
<h4 id="deep-dive-addresses">Deep Dive: Addresses</h4>
<p>Did you notice there’s no address tied to a customer in any of the data models shown so far? It might be your first inclination to include a customer’s address as part of those models. However, most customers will have multiple addresses and multiple <em>kinds</em> of addresses, like billing and shipping. B2B retailers might also have to consider multiple delivery locations based on the number of warehouses and offices they support.</p>
<p>What happens if the billing and shipping address are different? Well, you’ll need to do more than just add extra columns to the <code>Customer</code> table! It’s not that simple.</p>
<p>So how <em>does</em> storing a billing address affect the scalability of your application?</p>
<p>If you were to split the payment and shipping areas into separate (micro)services each having their own database, then putting billing and payment addresses into the <code>Customer</code> area would lead to having “chatty” services. This is a <a href="https://docs.aws.amazon.com/whitepapers/latest/microservices-on-aws/chattiness.html" rel="noopener" target="_blank">well-known <em>design smell</em> when building microservices</a>.</p>
<p>To avoid this issue, you’re better off putting the addresses within the appropriate area/service that requires them, but with that, your data model becomes more complex.</p>
<p>One way to avoid much of this complexity is to consider an <a href="https://resources.fabric.inc/glossary/oms-software" rel="noopener">order management system (OMS)</a> by an API-first software provider. With this software, you can integrate the OMS into your data model without spending months of engineering time.</p>

<h2 id="how-do-you-organize-products-and-catalog-">How Do You Organize Products And Catalog?</h2>
<p>The first thing you see when you enter a store (either in-person or digitally) are products ready for you to purchase, and usually displayed with some thought for how you might be likely to shop.</p>
<p>For an e-commerce web application, you will probably want to highlight things like:</p>
<ul>
<li>Best selling products</li>
<li>Trending products</li>
<li>New products</li>
<li>The ability to browse products by search criteria</li>
</ul>
<p>Providing customers with that information means you first need to keep track of a lot of data about your products: their prices, historical purchase data, and so on.</p>
<p>Let’s see what a “first shot” at creating a data model for a product catalog might look like:</p>
<p><img src="https://resources.fabric.inc/hs-fs/hubfs/Simple%20e-commerce%20product%20data%20model.png?width=562&amp;name=Simple%20e-commerce%20product%20data%20model.png" alt="Simple e-commerce product data model" width="562" srcset="https://resources.fabric.inc/hs-fs/hubfs/Simple%20e-commerce%20product%20data%20model.png?width=281&amp;name=Simple%20e-commerce%20product%20data%20model.png 281w, https://resources.fabric.inc/hs-fs/hubfs/Simple%20e-commerce%20product%20data%20model.png?width=562&amp;name=Simple%20e-commerce%20product%20data%20model.png 562w, https://resources.fabric.inc/hs-fs/hubfs/Simple%20e-commerce%20product%20data%20model.png?width=843&amp;name=Simple%20e-commerce%20product%20data%20model.png 843w, https://resources.fabric.inc/hs-fs/hubfs/Simple%20e-commerce%20product%20data%20model.png?width=1124&amp;name=Simple%20e-commerce%20product%20data%20model.png 1124w, https://resources.fabric.inc/hs-fs/hubfs/Simple%20e-commerce%20product%20data%20model.png?width=1405&amp;name=Simple%20e-commerce%20product%20data%20model.png 1405w, https://resources.fabric.inc/hs-fs/hubfs/Simple%20e-commerce%20product%20data%20model.png?width=1686&amp;name=Simple%20e-commerce%20product%20data%20model.png 1686w" sizes="(max-width: 562px) 100vw, 562px"></p>
<p>Here’s a <code>Product</code> table with some basic information, like a product’s name, SKU, and price. The product is also linked to another table representing various categories that product is associated with. You might also strategically add indexes and full-text search to the <code>Product</code> table to enable site visitors to efficiently search for various products.</p>
<p>This is a decent first attempt. However, to get an even more realistic and useful e-commerce product catalog, you’ll need to support more requirements such as:</p>
<ul>
<li>Tracking pricing history so site administrators can analyze trends in product pricing</li>
<li>Supporting related products to display on a product’s page</li>
<li>Incorporating product vendors so customers can view all products sold by an individual vendor/company</li>
</ul>
<p>To address those extra requirements, you might end up with the following data model:</p>
<p><img src="https://resources.fabric.inc/hs-fs/hubfs/More%20complex%20e-commerce%20product%20data%20model.png?width=816&amp;name=More%20complex%20e-commerce%20product%20data%20model.png" alt="More complex e-commerce product data model" width="816" srcset="https://resources.fabric.inc/hs-fs/hubfs/More%20complex%20e-commerce%20product%20data%20model.png?width=408&amp;name=More%20complex%20e-commerce%20product%20data%20model.png 408w, https://resources.fabric.inc/hs-fs/hubfs/More%20complex%20e-commerce%20product%20data%20model.png?width=816&amp;name=More%20complex%20e-commerce%20product%20data%20model.png 816w, https://resources.fabric.inc/hs-fs/hubfs/More%20complex%20e-commerce%20product%20data%20model.png?width=1224&amp;name=More%20complex%20e-commerce%20product%20data%20model.png 1224w, https://resources.fabric.inc/hs-fs/hubfs/More%20complex%20e-commerce%20product%20data%20model.png?width=1632&amp;name=More%20complex%20e-commerce%20product%20data%20model.png 1632w, https://resources.fabric.inc/hs-fs/hubfs/More%20complex%20e-commerce%20product%20data%20model.png?width=2040&amp;name=More%20complex%20e-commerce%20product%20data%20model.png 2040w, https://resources.fabric.inc/hs-fs/hubfs/More%20complex%20e-commerce%20product%20data%20model.png?width=2448&amp;name=More%20complex%20e-commerce%20product%20data%20model.png 2448w" sizes="(max-width: 816px) 100vw, 816px"></p>
<p>This model still isn’t perfect as it embeds your prices into the product itself, but at least it lets you maintain a previous pricing history.</p>
<p>Another option is to integrate your e-commerce store with a <a href="https://resources.fabric.inc/glossary/promotions-engine" rel="noopener">pricing and promotions engine</a> from an API-first software provider that handles pricing for you. This will let you roll out different prices to different users based on their intent, location, cart, or order history.</p>
<h4 id="deep-dive-pricing">Deep Dive: Pricing</h4>
<p>While the more complex product data model still has a product’s price in the same table, this may not be the best thing to do in a real large-scale application.</p>
<p>Consider that your organization has various departments, such as inventory/warehousing, sales, marketing, customer support, etc. You might have dedicated systems that allow merchandisers to change the price of an item since they are the experts in determining how much a product should sell for. Similar to the considerations with a customer’s billing and shipping addresses, this would lead to cross-boundary/service communication if we left the price in the core <code>Product</code> table.</p>
<p>Therefore, you might want to store product prices under the data stores that the sales department owns. But don’t forget, there are many different kinds of “prices” that haven’t been taken into consideration yet, including:</p>
<ul>
<li>Price (cost) when purchasing stock from vendors</li>
<li>Customer sale price</li>
<li>Discounted sale prices</li>
<li>Manufacturer’s suggested retail price</li>
</ul>
<p>Handling all these in context of your organizational structure would require even more exploration and complexity in your data model. While your engineering team could likely accomplish this task, it’s going to take time. Using ready-made solutions can shave weeks or months off your e-commerce data modeling timeline.</p>

<h2 id="how-do-you-streamline-orders-">How Do You Streamline Orders?</h2>
<p>Now that you have customers in your database and products available to purchase, you’ll need to think about how to design the order-taking process and data model.</p>
<p>The process of placing an order might look something like this:</p>
<ol>
<li>A customer places products into their cart while browsing.</li>
<li>The customer decides they want to purchase the products that are in their cart.</li>
<li>They proceed to purchase the order.</li>
<li>The customer gets an emailed receipt or confirmation number.</li>
</ol>
<p>However, it’s rarely so simple. Placing orders can be deceptively tricky as there are many moving parts:</p>
<ul>
<li>Products</li>
<li>An active cart</li>
<li>Cart converted into an order</li>
<li>A finalized order with confirmation</li>
</ul>
<p>If you were to look at a simple data model for an order placement, it might look something like this:</p>
<p><img src="https://resources.fabric.inc/hs-fs/hubfs/Orders%20data%20model.png?width=837&amp;name=Orders%20data%20model.png" alt="Orders data model" width="837" srcset="https://resources.fabric.inc/hs-fs/hubfs/Orders%20data%20model.png?width=419&amp;name=Orders%20data%20model.png 419w, https://resources.fabric.inc/hs-fs/hubfs/Orders%20data%20model.png?width=837&amp;name=Orders%20data%20model.png 837w, https://resources.fabric.inc/hs-fs/hubfs/Orders%20data%20model.png?width=1256&amp;name=Orders%20data%20model.png 1256w, https://resources.fabric.inc/hs-fs/hubfs/Orders%20data%20model.png?width=1674&amp;name=Orders%20data%20model.png 1674w, https://resources.fabric.inc/hs-fs/hubfs/Orders%20data%20model.png?width=2093&amp;name=Orders%20data%20model.png 2093w, https://resources.fabric.inc/hs-fs/hubfs/Orders%20data%20model.png?width=2511&amp;name=Orders%20data%20model.png 2511w" sizes="(max-width: 837px) 100vw, 837px"></p>
<p>Notice that each row in the <code>ShoppingCartItem</code> table contains the “captured” price of the product. When the customer puts an item into their shopping cart should the price at that moment be “locked-in”? If so, for how long?</p>
<p><em><span>Note:</span> How the price functions is a business requirement that would need to be discussed with your product owners, and so on, as mentioned in the "Deep Dive: Pricing" section earlier.</em></p>
<p>The same question applies to an unpaid order. If a customer has ordered a discounted item, should they be able to keep the promise of that discounted price forever until they pay? Or does it expire?</p>
<p>Other questions to consider for an orders data model might include:</p>
<ul>
<li>Are you tracking analytics on orders?</li>
<li>What happens if a customer returns a defective item?</li>
<li>Should you handle shipping within the same data model or have a dedicated shipping context/schema?</li>
</ul>
<p>With some of these concerns in mind, you might end up with a data model that looks more like this:</p>
<p><img src="https://resources.fabric.inc/hs-fs/hubfs/More%20complex%20orders%20data%20model.png?width=1112&amp;name=More%20complex%20orders%20data%20model.png" alt="More complex orders data model" width="1112" srcset="https://resources.fabric.inc/hs-fs/hubfs/More%20complex%20orders%20data%20model.png?width=556&amp;name=More%20complex%20orders%20data%20model.png 556w, https://resources.fabric.inc/hs-fs/hubfs/More%20complex%20orders%20data%20model.png?width=1112&amp;name=More%20complex%20orders%20data%20model.png 1112w, https://resources.fabric.inc/hs-fs/hubfs/More%20complex%20orders%20data%20model.png?width=1668&amp;name=More%20complex%20orders%20data%20model.png 1668w, https://resources.fabric.inc/hs-fs/hubfs/More%20complex%20orders%20data%20model.png?width=2224&amp;name=More%20complex%20orders%20data%20model.png 2224w, https://resources.fabric.inc/hs-fs/hubfs/More%20complex%20orders%20data%20model.png?width=2780&amp;name=More%20complex%20orders%20data%20model.png 2780w, https://resources.fabric.inc/hs-fs/hubfs/More%20complex%20orders%20data%20model.png?width=3336&amp;name=More%20complex%20orders%20data%20model.png 3336w" sizes="(max-width: 1112px) 100vw, 1112px"></p>
<p>Some things to take note of in this more complex orders model:</p>
<ul>
<li><code>ShoppingCartItem</code> now supports an expiration date for a locked-in price.</li>
<li><code>ShoppingCartHistory</code> tracks when items are added, removed, etc.</li>
<li>An order item may be returned (this still does not handle cases where 1 out of X items of the same product are returned).</li>
<li>An order may have multiple shipments (eg, how Amazon will sometimes split an order up into multiple packages/shipments).</li>
</ul>
<p>This article also hasn’t even touched the surface of using alternative data storage methods like JSON documents or event sourcing!</p>

<h2 id="conclusion">Conclusion</h2>
<p>To help you see how all the pieces fit together, here are all the diagrams shown together. I’ve removed a number of links/lines to the <code>Customer</code> table to increase readability:</p>
<p><img src="https://resources.fabric.inc/hs-fs/hubfs/Summary%20e-commerce%20data%20model.png?width=1396&amp;name=Summary%20e-commerce%20data%20model.png" alt="Summary e-commerce data model" width="1396" srcset="https://resources.fabric.inc/hs-fs/hubfs/Summary%20e-commerce%20data%20model.png?width=698&amp;name=Summary%20e-commerce%20data%20model.png 698w, https://resources.fabric.inc/hs-fs/hubfs/Summary%20e-commerce%20data%20model.png?width=1396&amp;name=Summary%20e-commerce%20data%20model.png 1396w, https://resources.fabric.inc/hs-fs/hubfs/Summary%20e-commerce%20data%20model.png?width=2094&amp;name=Summary%20e-commerce%20data%20model.png 2094w, https://resources.fabric.inc/hs-fs/hubfs/Summary%20e-commerce%20data%20model.png?width=2792&amp;name=Summary%20e-commerce%20data%20model.png 2792w, https://resources.fabric.inc/hs-fs/hubfs/Summary%20e-commerce%20data%20model.png?width=3490&amp;name=Summary%20e-commerce%20data%20model.png 3490w, https://resources.fabric.inc/hs-fs/hubfs/Summary%20e-commerce%20data%20model.png?width=4188&amp;name=Summary%20e-commerce%20data%20model.png 4188w" sizes="(max-width: 1396px) 100vw, 1396px"></p>
<p>As I mentioned above, this article still doesn’t even cover many of the basics like payment processing and invoicing. Beyond the features covered here, you might eventually require more advanced features like:</p>
<ul>
<li>Coupon codes</li>
<li>Taxes</li>
<li>Third-party integrations with OAuth providers, other retailers, or partners</li>
<li>Shipment tracking notifications</li>
</ul>
<p>Building a data model for an e-commerce application, as you can see, is not so simple. What looks up front to be a straightforward set of database tables is not so simple once you dig into real-world requirements.</p>
<h4 id="there-s-another-way">There’s Another Way</h4>
<p>What if you could have more of these abilities out-of-the-box?</p>
<p><a href="https://fabric.inc/solutions">Fabric</a> is an all-in-one commerce platform that helps you do everything this article talked about, like manage customers, orders, and shipments. Most importantly, it is a microservices-based and API-first platform. This means you can choose the services you need and integrate them …</p></span></p></div></div></div></div></div></div></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://resources.fabric.inc/blog/ecommerce-data-model">https://resources.fabric.inc/blog/ecommerce-data-model</a></em></p>]]>
            </description>
            <link>https://resources.fabric.inc/blog/ecommerce-data-model</link>
            <guid isPermaLink="false">hacker-news-small-sites-25353148</guid>
            <pubDate>Tue, 08 Dec 2020 23:38:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Working with Unikernel Volumes in Nanos]]>
            </title>
            <description>
<![CDATA[
Score 34 | Comments 8 (<a href="https://news.ycombinator.com/item?id=25352718">thread link</a>) | @eyberg
<br/>
December 8, 2020 | https://nanovms.com/dev/tutorials/working-with-unikernel-volumes-in-nanos | <a href="https://web.archive.org/web/*/https://nanovms.com/dev/tutorials/working-with-unikernel-volumes-in-nanos">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

    <p>Today's article is about working with external volumes for your
unikernel instance. Many applications won't use this feature but there
are also situations where this makes sense.</p>

<p>The most obvious time when you would want to attach a volume to your
unikernel instance is when you are working with a database. Your
database image probably doesn't change that much but many databases can
grow very large and it makes no sense to keep the same data volume in
your base image.</p>

<p>The second use-case is when you have a base image, say a webserver,
and you want to package additional files or configuation as a build
step. For instance some companies will rotate certificates every few
hours in the day to protect access to various services and this rotation
is usually done out-of-band of deploys. Now unikernel deploys for small
webservers are typically fairly fast but the ability to put your
configuration on a separate partition and re-mount the volume on the fly
every few hours is definitely enticing.</p>

<p>Ok, let's start with the code. For this example we have a simple
little go webserver that implements a root filesystem filewalker. We've
declared that there is a separate partition called 'mnt' in the code but
it is non-existent right now.</p>

<pre><code>import (
  "fmt"
  "io/ioutil"
  "net/http"
  "os"
  "path/filepath"
)

func printDir() {
  err := filepath.Walk("/",
    func(path string, info os.FileInfo, err error) error {
      if err != nil {
        return err
      }
      fmt.Println(path, info.Size())
      return nil
    })
  if err != nil {
    fmt.Println(err)
  }
}

func main() {
  printDir()

  b, err := ioutil.ReadFile("/mnt/bob.txt")
  if err != nil {
    fmt.Println(err)
  }

  fmt.Println(string(b))

  http.HandleFunc("/", func(w http.ResponseWriter, r *http.Request) {
    printDir()

    b, err := ioutil.ReadFile("/mnt/bob.txt")
    if err != nil {
      fmt.Println(err)
    }

    fmt.Println(string(b))
    fmt.Fprintf(w, "Welcome to my website!")
  })

  fs := http.FileServer(http.Dir("static/"))
  http.Handle("/static/", http.StripPrefix("/static/", fs))

  go func() {
    err = http.ListenAndServe(":80", nil)
    if err != nil {
      fmt.Println(err)
    }
  }()

  http.ListenAndServe(":8080", nil)
}
</code></pre><p>

If you run it locally you should see something like this:
</p><pre><code>➜  g2 ops run -p 8080 g2
booting /Users/eyberg/.ops/images/g2.img ...
assigned: 10.0.2.15
/ 0
/dev 0
/dev/null 0
/dev/urandom 0
/etc 0
/etc/passwd 33
/etc/resolv.conf 18
/etc/ssl 0
/etc/ssl/certs 0
/etc/ssl/certs/ca-certificates.crt 207436
/g2 7533614
/lib 0
/lib/x86_64-linux-gnu 0
/lib/x86_64-linux-gnu/libnss_dns.so.2 26936
/proc 0
/proc/self 0
/proc/self/exe 0
/proc/self/maps 0
/proc/sys 0
/proc/sys/kernel 0
/proc/sys/kernel/hostname 7
/sys 0
/sys/devices 0
/sys/devices/system 0
/sys/devices/system/cpu 0
/sys/devices/system/cpu/cpu0 0
/sys/devices/system/cpu/online 0
open /mnt/bob.txt: no such file or directory
</code></pre>

<h3>Creating a Volume</h3>

<p>Let's create a simple volume with one file in it - bob.txt.</p>

<pre><code>mkdir mnt
echo "Hi - I'm a text file" &gt; mnt/bob.txt
➜  g2 ops volume create mnt -d mnt
2020/12/08 11:12:35 volume: mnt created with UUID 04c56e4a-5b8b-512c-eaa3-b82b4cd46d9e and label mnt
</code></pre><p>

You'll see that we can now see it in our local volume store:

</p><pre><code>➜  g2 ops volume list
+--------------------------------------+------+--------+-----------+-------------------------------------------------------------------------+---------+----------+
|                 UUID                 | NAME | STATUS | SIZE (GB) | LOCATION                                 | CREATED | ATTACHED |
+--------------------------------------+------+--------+-----------+-------------------------------------------------------------------------+---------+----------+
| 04c56e4a-5b8b-512c-eaa3-b82b4cd46d9e | mnt  |        | 1.6 MB    | /Users/eyberg/.ops/volumes/mnt:04c56e4a-5b8b-512c-eaa3-b82b4cd46d9e.raw |         |          |
+--------------------------------------+------+--------+-----------+-------------------------------------------------------------------------+---------+----------+
</code></pre>

<h3>Attaching a Volume</h3>

<p>You can attach a volume to an instance that is expecting one. So that
means when we create the image we'll want to pass any mount points with
the volume label and mount path - this is loosely similar to how
something in /etc/fstab would work. Ran locally you can test with 'ops
run' but you can pass the same '--mounts' flag when issuing 'ops image
create' for images ran on Google or AWS. Let's try it out locally:
</p>

<pre><code>➜  g2 ops run -p 8080 g2 --mounts mnt:/mnt
booting /Users/eyberg/.ops/images/g2.img ...
assigned: 10.0.2.15
/ 0
/dev 0
/dev/null 0
/dev/urandom 0
/etc 0
/etc/passwd 33
/etc/resolv.conf 18
/etc/ssl 0
/etc/ssl/certs 0
/etc/ssl/certs/ca-certificates.crt 207436
/g2 7533614
/lib 0
/lib/x86_64-linux-gnu 0
/lib/x86_64-linux-gnu/libnss_dns.so.2 26936
/mnt 0
/mnt/bob.txt 21
/proc 0
/proc/self 0
/proc/self/exe 0
/proc/self/maps 0
/proc/sys 0
/proc/sys/kernel 0
/proc/sys/kernel/hostname 7
/sys 0
/sys/devices 0
/sys/devices/system 0
/sys/devices/system/cpu 0
/sys/devices/system/cpu/cpu0 0
/sys/devices/system/cpu/online 0
Hi - I'm a text file
</code></pre>

<p>Cool! It works! Now let's edit the file.</p>

<pre><code>echo "New text has come to light." &gt; mnt/bob.txt
➜  g2 ops volume create mnt2 -d mnt
2020/12/08 11:19:41 volume: mnt2 created with UUID f82da0e3-3980-ddd8-5720-e1b320e21371 and label mnt2
</code></pre>

<p>Keep in mind we are creating a *new* volume with new contents and then re-attaching the volume to the instance.</p>

<pre><code>➜  g2 ops run -p 8080 g2 --mounts mnt2:/mnt
booting /Users/eyberg/.ops/images/g2.img ...
assigned: 10.0.2.15
/ 0
/dev 0
/dev/null 0
/dev/urandom 0
/etc 0
/etc/passwd 33
/etc/resolv.conf 18
/etc/ssl 0
/etc/ssl/certs 0
/etc/ssl/certs/ca-certificates.crt 207436
/g2 7533614
/lib 0
/lib/x86_64-linux-gnu 0
/lib/x86_64-linux-gnu/libnss_dns.so.2 26936
/mnt 0
/mnt/bob.txt 28
/proc 0
/proc/self 0
/proc/self/exe 0
/proc/self/maps 0
/proc/sys 0
/proc/sys/kernel 0
/proc/sys/kernel/hostname 7
/sys 0
/sys/devices 0
/sys/devices/system 0
/sys/devices/system/cpu 0
/sys/devices/system/cpu/cpu0 0
/sys/devices/system/cpu/online 0
New text has come to light.
</code></pre>

<p>If you are attaching the volume to an instance on Google or AWS you'd
use the attach command:</p>

<pre><code>ops volume attach g2 mnt mnt2 -t gcp -c config.json</code></pre>

<p>Similarly, you can detach as well:</p>

<pre><code>ops volume detach g2 mnt -t gcp -c config.json</code></pre>

<p>What's really great about unikernel volumes when working on AWS or
Google is that this is all managed for you by the cloud provider of choice. There is no duplicate storage layer
you have to manage like you do in container land. Now you know the basics of mounting external volumes into your unikernel images.</p>
                    </div></div>]]>
            </description>
            <link>https://nanovms.com/dev/tutorials/working-with-unikernel-volumes-in-nanos</link>
            <guid isPermaLink="false">hacker-news-small-sites-25352718</guid>
            <pubDate>Tue, 08 Dec 2020 22:59:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Measuring "efficiency" in document prepration: Microsoft Word vs. LaTex]]>
            </title>
            <description>
<![CDATA[
Score 79 | Comments 135 (<a href="https://news.ycombinator.com/item?id=25350851">thread link</a>) | @1vuio0pswjnm7
<br/>
December 8, 2020 | https://blog.cr.yp.to/20201206-msword.html | <a href="https://web.archive.org/web/*/https://blog.cr.yp.to/20201206-msword.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">

<hr>
<hr>

<p>
The boss needed item 3 inserted into a numbered list of hundreds of items.
The intern used a mouse to select the original 3 on the screen,
then typed 4,
then selected the original 4,
then typed 5,
then scrolled down,
then selected the original 5,
then typed 6,
and so on.
Another intern sat watching the screen to make sure there were no mistakes.
</p>
<p>
I happened to be in the room for other reasons.
I remember the horror of watching the beginning of this barbaric editing process.
Those poor interns!
</p>
<p>
When I enter a list of items into the computer,
what I'm typing doesn't look like
</p>
<pre>     1. ...
     2. ...
     3. ...
</pre>
<p>
but more like
</p>
<pre>     * ...
     * ...
     * ...
</pre>
<p>
Each asterisk is a special command to the computer,
telling the computer to automatically display the next number for the reader.
The reader eventually sees
</p>
<pre>     1. ...
     2. ...
     3. ...
</pre>
<p>
but that isn't what I typed.
This small difference produces a tremendous savings of time
whenever I insert an item, or delete an item, or move an item.
</p>
<p>
If I decide later
to skip the numbers
and use bullets instead,
I tell the computer
to introduce each list item with a bullet.
This is one command covering the whole list.
There's also a command that does the same thing
for the whole document.
There isn't separate work for each item.
It's no problem if a coauthor
later wants to change bullets back to numbers.
</p>
<p>
The interns, I suppose,
would be manually changing "1." and "2." and "3."
and so on to "•" and "•" and "•" and so on.
Or maybe they would be trying to figure out
how some search-and-replace feature could do the same thing;
let's hope the document doesn't have a sentence somewhere
that talks about something that happened in the year 2001.
Or maybe the interns would be quitting and finding a better job.
</p>
<p>
[Note added 2020.12.07:
I was expecting that many of my readers
would already be accustomed to relying on the computer
for automatic numbering.
I was surprised, however,
to see some comments along the lines of "Inconceivable!"
from readers unable to imagine
how the interns could have been in a different situation,
going through such a shockingly inefficient revision process.
Here's a hint:
Each item in the list looked like a flush-left paragraph,
like the paragraphs in this blog post,
adjacent to the left margin.
The text being selected by the mouse,
for example to change "3" to "4",
was to the right of the margin,
like the rest of the text in each item.]
</p>
<p>
<b>Abstraction as a time-saver for authors.</b>
This use of asterisks
is just one example of how I'm often typing something more abstract
than what's seen by the ultimate reader.
I don't type "Figure 12" or "see [41]", for example;
I type things like "Figure \ref{network-measurements}" and "see \cite{multiplication-survey}",
and I let the computer automatically convert
"\ref{network-measurements}" and "\cite{multiplication-survey}"
into numbers to display for the reader.
</p>
<p>
With one extra command,
covering the entire document,
I can tell the computer
to include section numbers
as part of all figure numbers in the document,
so that the figures are easier for the reader to find:
e.g., Figures 3.1 and 3.2 and 3.3 are in Section 3.
With another command,
again covering the entire document,
I can tell the computer
to cite all authors by name rather than by number.
</p>
<p>
As another example,
I was recently editing a mathematical paper,
and I decided that a particular concept
would be easier for the reader to remember
if I changed the notation that I was using for the concept.
The notation was all over the paper,
but this change took just a few seconds of editing.
I had given a name to the concept,
had told the computer <i>once</i> to display this name as a particular notation,
and had then typed this name throughout the paper,
so there was only one place where I had to change the notation.
</p>
<p>
Of course one can't,
and shouldn't try to,
prepare in advance for <i>every</i> possible change to a document.
But it's not hard to prepare for the most likely changes.
This small initial effort
saves a tremendous amount of time later.
When I say "small",
I'm including the effort to select a document-creation system
that's designed to
<a href="https://en.wikipedia.org/wiki/LaTeX">make this sort of thing easy</a>.
</p>
<p>
(As a side note,
programmers will recognize this strategy
as an example of the
<a href="https://en.wikipedia.org/wiki/Information%5Fhiding">information hiding</a>
strategy introduced by Parnas,
and will recognize that modern program-creation systems
are designed to make this easy.)
</p>
<p>
Microsoft Word isn't completely missing abstractions,
but these abstractions
are competing for user-interface resources
against features encouraging the user
to work at lower abstraction layers.
The extra effort to use the abstractions
ends up pushing users into doing something simpler,
something that just works now,
and paying heavily for this choice
later when the document is being revised.
</p>
<p>
Have I done a scientific study
<i>proving</i> that Microsoft Word
is less efficient than LaTeX?
No.
I'd love to see a careful study of this topic.
Short-term,
this would help guide new authors to make sensible choices.
Longer-term,
insights from this sort of study could be the basis for further improving
our document-creation systems.
I certainly don't think that the existing systems are perfect.
(<a href="https://cr.yp.to/writing/visual.html">Example.</a>)
</p>
<p>
Imagine, however, that a study looks only at
<i>the time for someone looking at a printout to create a document matching this printout</i>.
This would be blind to the time for subsequent edits.
This would be blind to the suffering of those interns.
This would incorrectly conclude that typing
"1. ... 2. ... 3. ..." and "see [41]"
is more efficient than typing
"* ... * ... * ..." and "see \cite{multiplication-survey}".
It <i>is</i> slightly more efficient in this limited metric,
but it is much less efficient in the metric that matters,
namely the total time spent by the user.
</p>
<p>
<b>An example of a "scientific" study.</b>
At this point you're probably thinking that
nobody could possibly miss such an obvious issue.
This brings me to the main topic of this blog post,
a 2014 peer-reviewed study
<a href="https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0115069">"An Efficiency Comparison of Document Preparation Systems Used in Academic Research and Development"</a>
by two psychologists,
Knauff and Nejasmic ("KN").
</p>
<p>
Participants in the study were given a page of text
and were given a limited time to type the page into the computer.
There were three different types of text:
</p>
<ul>
<li>simple prose with a few footnotes;
</li>
<li>a page with a complicated table of data;
and
</li>
<li>a page with many mathematical formulas.
</li>
</ul>
<p>
Participants were scored
on the basis of how much text they typed and how accurately they typed it.
The time was so rushed that a significant fraction of participants
didn't finish typing the whole page,
even for the case of simple prose.
</p>
<p>
The study considered two document-creation systems:
LaTeX and Microsoft Word,
in each case with "all tools, editors, plug-ins, and add-ons"
that participants were "accustomed to using".
Of course different "add-ons" could have different efficiency,
and of course there are other document-creation systems,
but these are topics for another blog post.
</p>
<p>
The study produced many pages of results,
which I'll summarize by saying that
Word did slightly better on the prose
and much better on the table,
while LaTeX did better on the formulas.
The study authors made no effort to measure any subsequent document-editing step.
</p>
<p>
<b>Slithering from one metric to another.</b>
The fundamental mistake in the KN paper
is the change of cost metric.
</p>
<p>
The original question was how efficiently authors are creating documents:
in particular, how efficiently authors are creating academic research papers.
KN claimed in their title to be comparing "efficiency"
of "document preparation systems used in academic research".
But they then quietly changed this metric in three ways:
</p>
<ul>
<li>
They considered only the efficiency of an initial fragment of the document-creation process,
ignoring the time spent revising documents.
They provided no reason to believe that the efficiency of this fragment
was well correlated with what they had previously claimed to be measuring.
Nothing in their paper acknowledges
the most obvious reason for a negative correlation,
namely that slightly more work at the outset
makes revisions much easier later.
In my experience,
document-creation systems vary in how well they support this work.
</li>
<li>
KN didn't even measure the time taken for this initial fragment of the process.
Instead they imposed a rushed time limit,
and measured how incomplete and inaccurate the resulting document was.
Again they provided no reason to believe that what they measured
was well correlated with what they had previously claimed to be measuring.
Perhaps they were assuming that more mistakes will take more time to fix,
but my experience is that some types of mistakes are much easier to fix than others,
and that document-creation systems vary in the types of mistakes they encourage.
</li>
<li>
KN didn't even measure creating a <i>new</i> document,
which is what academics are actually spending their time doing.
People who were writing papers in the age of typewriters
will remember writing and editing papers <i>by hand</i>
before tediously typing the final pages,
but that was because editing a typed page
ranged from annoying
(<a href="https://en.wikipedia.org/wiki/Correction%5Ffluid">white-out</a>,
or sometimes scissors and tape)
to super-annoying
(retyping the whole page).
Today the initial writing on paper is skipped,
and typing is interleaved in small chunks
with parts of the author's thought process,
making the typing process much less boring.
I'm continually re-reading
and thinking about what I just typed.
Is the error rate of the academic's modern typing process
well correlated with the error rate of the
archaic retyping process that KN measured?
Again KN provide no reason to believe this.
</li>
</ul>
<p>
Did KN use the honest title
"A comparison of the unreliability of
rushed retyping of a page
using document preparation systems
that are also used for academic research and development"?
No.
Would you expect a journal to accept a paper
with such a title?
</p>
<p>
Instead they used a title …</p></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.cr.yp.to/20201206-msword.html">https://blog.cr.yp.to/20201206-msword.html</a></em></p>]]>
            </description>
            <link>https://blog.cr.yp.to/20201206-msword.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25350851</guid>
            <pubDate>Tue, 08 Dec 2020 20:25:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Notion API]]>
            </title>
            <description>
<![CDATA[
Score 44 | Comments 13 (<a href="https://news.ycombinator.com/item?id=25349335">thread link</a>) | @theBashShell
<br/>
December 8, 2020 | https://www.notion.so/api-beta | <a href="https://web.archive.org/web/*/https://www.notion.so/api-beta">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.notion.so/api-beta</link>
            <guid isPermaLink="false">hacker-news-small-sites-25349335</guid>
            <pubDate>Tue, 08 Dec 2020 18:24:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[We Love GPLv3, but Are Switching License to Apache 2.0]]>
            </title>
            <description>
<![CDATA[
Score 144 | Comments 224 (<a href="https://news.ycombinator.com/item?id=25346965">thread link</a>) | @vivek9209
<br/>
December 8, 2020 | https://terminusdb.com/blog/2020/12/08/we-love-gplv3-but-are-switching-license-to-apache-2-0-terminusdb/ | <a href="https://web.archive.org/web/*/https://terminusdb.com/blog/2020/12/08/we-love-gplv3-but-are-switching-license-to-apache-2-0-terminusdb/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <div>
        <div id="markdown" itemprop="articleBody">
          <h2 id="changing-license-from-gplv3-to-apache-20-terminusdb">Changing License from GPLv3 to Apache 2.0: TerminusDB</h2>

<p>We have decided to re-license TerminusDB from GPLv3 to Apache 2.0. We want independent software developers (ISVs) to embed TerminusDB in their applications and those developers feel that Apache is a lower risk option. The substantive points of practical difference are far less important – sufficient people believe it to be true and sufficient lawyers have advised teams to be wary of GPL.</p>

<p>In our experience, ISVs and devs in large companies/institutions size up their options at project conception and there remains a niggling doubt that ‘GPL might limit commercial prospects and cause me headaches’. The world has changed – and code freedom is being overtaken by developer freedom.</p>

<p>Open-source software is everywhere. It’s eating the world. In the top 10 databases on <a href="https://db-engines.com/en/ranking">DB-Engines</a>, the remaining proprietary databases were released in 1980 (Oracle), 1983 (IBM Db2) and 1989 (Microsoft SQL Server). It is hard to imagine another non-OSS database ever entering the top 10.</p>

<p>We had hoped that our association with the principals of the free software movement would result in community adoption and contribution, but that hasn’t really been the case. We see limited community input that relates to our choice of GPL. That might not be too surprising as when you investigate which license to choose on Stackoverflow, you get popular but wrong-headed comments like:</p>

<p><code>the GNU/GPL bunch are generally extremists when you encounter them in the wild.</code></p>

<p><code>don’t use GPL if you want your project to be commercial</code></p>

<p>With the shift to Apache, TerminusDB is, in a sense, becoming more open source as we are removing restrictions on how you can use the software.</p>

<h3 id="debate">Debate</h3>

<p>The core TerminusDB team had a long debate about licenses before the release of 1.0 last year. The main topics of discussion were:</p>

<ol>
<li>The risks of a cloud provider forking the code then hosting the database</li>
<li>What open source means to TerminusDB as a group</li>
<li>What we, as a community of devs and users, are most comfortable with</li>
</ol>

<h4 id="1-the-big-bad-cloud-providers">1. The big bad cloud providers</h4>

<p>In the past there was an unwritten rule, that big platforms wouldn’t come along and fork open source code and deliver the same product as a service. Unfortunately, those days are gone. AWS in particular has actively sought to offer very similar services to open source products. This led to <a href="https://www.mongodb.com/licensing/server-side-public-license/faq">MongoDB</a>, <a href="https://www.cockroachlabs.com/blog/oss-relicensing-cockroachdb/">CockroachDB</a> and <a href="https://www.confluent.io/confluent-community-license-faq/">Confluent</a> (among others) changing their licences to variations of ‘server side’ and moving away from the open-source tradition. They try to say ‘we are still open source, we are just forbidding a specific type of action’, but it can feel like window dressing for ‘we want to sweat our assets’.</p>

<p>Mongo, for example, is hardly suffering – it’s valued at over $15 billion. With such vast resources, they should be (and are) able to compete in the provision of their own database. MongoDB’s technology is more than competitive with AWS’ DocumentDB, and Mongo’s Atlas DBaaS - which runs on AWS infra - has been a huge success.</p>

<p>I’m sure our perspective will shift over time, but from where we’re standing, having a cloud provider launch a competing service would be a sign of enormous success. (And this is not to say that the cloud providers’ parasitic approach to OSS projects is not a genuine problem, it simply acknowledges that you have to be a widely used OSS project before it *becomes* a problem).</p>

<h3 id="2-free-software">2. Free software</h3>

<p>We don’t think it should be our job to provide corporations with free labor.</p>

<p>We do think that the software community should be able to access and use TerminusDB.</p>

<p>In 1974 software became copyrightable in the USA. It subsequently became obvious that researchers were giving out software for free, but businesses were not giving back. GNU/GPL came along to provide a new framework for that interface – the software would be free as in freedom (libre). Everybody would be free to modify and distribute, but proprietary additions would not be allowed.</p>

<p>The problem of businesses not giving back remains today.</p>

<p>GPL and copyleft provisions work well when they dominate open-source, but their waning popularity increases the ability for ISVs and corporates to go for more open licensing and for legal teams to write anti-GPL provisions into internal rules. Only significant developer push back can change that reality (and why push back when there are so many OSS options with permissive licenses).</p>

<p>Maybe if <a href="https://db-engines.com/en/system/MySQL">MySQL</a>, its offshoot <a href="https://db-engines.com/en/system/MariaDB">MariaDB</a>, and our graph brothers <a href="https://db-engines.com/en/system/Neo4j">Neo4j</a> weren’t the only GPL flag flyers in the top 20 databases, it might be easier to gain adoption with GPL; however, the other big OSS players: Postgres, Cassandra, Elastic &amp; Redis all go for less restrictive licenses.</p>

<p>The Affero GPL (AGPL) is treated as an even greater pariah than the GPLv3. The Google internal policy] bans all use of AGPL:</p>

<p><img src="https://terminusdb.com/blog/assets/uploads/agpl-at-google.jpg" alt=""></p>

<p><img src="https://terminusdb.com/blog/assets/uploads/agpl-at-google-2.jpg" alt=""></p>

<p>It reminds of <a href="https://news.ycombinator.com/item?id=13421608">this HN comment</a> on the <a href="http://www.defmacro.org/2017/01/18/why-rethinkdb-failed.html">excellent postmortem</a> of the demise of RethinkDB (recommended reading for all OSS folk):</p>

<p><img src="https://terminusdb.com/blog/assets/uploads/agpl-hn.jpg" alt=""></p>

<p>Our graph database brothers and sisters in <a href="https://neo4j.com/open-core-and-neo4j/">Neo4j moved</a> from the AGPL to ‘AGPL with a commons clause’ to GPLv3 to making some of the code proprietary. Getting the right license for an OSS project that also allows for some commercialization is far from straightforward. (As Neo certainly know – check out this <a href="https://public.igovsol.com/neo4j-court-records/graphfoundation/80-main.pdf">current court case about the formerly GPL enterprise code</a>).</p>

<p>It seems that <a href="https://github.com/graknlabs/grakn">Grakn</a> and <a href="https://github.com/fluree/db">Fluree</a> are seeing some success with the AGPL. We genuinely wish them well as we know it is a hard path to walk.</p>



<p>We did get some negative feedback about the GPL prior to launch. Some people working in corporates weren’t comfortable and thought that it would prevent them from using Terminus. Our response was – <strong>we didn’t develop for them</strong>. And that remains the case; however, the GPL skeptical environment is pervasive. There is a person who tweets TerminusDB after every release asking when the Apache version will land – I always ask him why he thinks he needs an Apache version and he doesn’t really know… though he has a vague feeling that the application he builds on top will be less valuable.</p>

<p>We thought we would focus on the cloud offering – <a href="https://terminusdb.com/hub/">TerminusHub</a>, which, as SaaS built on the database, has the benefit of being an in-house ‘product’ that doesn’t worry about the license of the underlying software. However, the community wants to build applications on the software and we want to offer an easy way to build a version control and collaboration layer into ISV applications. We think TerminusDB is the perfect infrastructure to build the next <a href="https://www.notion.so/">Notion</a> or <a href="https://roamresearch.com/">Roam Research</a>. We worry about the syncing, versioning and data collaboration – you worry about your users.</p>

<h3 id="why-shift-licenses">Why shift Licenses</h3>

<p>We do not think that our job is to provide corporations with free labor.</p>

<p>We still believe that <a href="https://www.gnu.org/gnu/manifesto.en.html">“the fundamental act of friendship among programmers is the sharing of programs.”</a></p>

<p>We would welcome a GPL fork of the TerminusDB code – we are happy to work with any such project should it emerge.</p>

<p>But we wish to build a community first and foremost. In order to facilitate that community, we will be moving to Apache 2.0 immediately.</p>

<p>We are going to continue to focus on creating a great open-source database and allow everybody to use that software in their projects.</p>

        </div>

        



      </div>
    </div></div>]]>
            </description>
            <link>https://terminusdb.com/blog/2020/12/08/we-love-gplv3-but-are-switching-license-to-apache-2-0-terminusdb/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25346965</guid>
            <pubDate>Tue, 08 Dec 2020 16:00:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Kafka Is Not a Database]]>
            </title>
            <description>
<![CDATA[
Score 293 | Comments 148 (<a href="https://news.ycombinator.com/item?id=25346851">thread link</a>) | @andrioni
<br/>
December 8, 2020 | https://materialize.com/kafka-is-not-a-database/ | <a href="https://web.archive.org/web/*/https://materialize.com/kafka-is-not-a-database/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p><em>This post is co-authored by George Fraser, the CEO of <a href="http://fivetran.com/">Fivetran</a>, and Arjun Narayan, the CEO of Materialize. This blog post is cross-posted <a href="https://fivetran.com/blog/kafka-is-not-a-database">on the Fivetran blog</a>.</em></p>
<p>It’s important to understand the uses and abuses of streaming infrastructure.</p>
<p>Apache Kafka is a message broker that has rapidly grown in popularity in the last few years. Message brokers have been around for a long time; they’re a type of datastore specialized for “buffering” messages between producer and consumer systems. Kafka has become popular because it’s open-source and capable of scaling to very large numbers of messages.</p>
<p>Message brokers are classically used to decouple producers and consumers of data. For example, at Fivetran, we use a message broker similar to Kafka to buffer customer-generated webhooks before loading them in batches into your data warehouse:</p>
<p><img src="https://materialize.com/wp-content/uploads/2020/12/kafka_overview.png" data-src="https://materialize.com/wp-content/uploads/2020/12/kafka_overview.png" alt="A Message Broker Used as a buffer before loading into a data warehouse" width="960" height="124" data-srcset="https://materialize.com/wp-content/uploads/2020/12/kafka_overview.png 960w, https://materialize.com/wp-content/uploads/2020/12/kafka_overview-300x39.png 300w, https://materialize.com/wp-content/uploads/2020/12/kafka_overview-768x99.png 768w" data-sizes="(max-width: 960px) 100vw, 960px" srcset="https://materialize.com/wp-content/uploads/2020/12/kafka_overview.png 960w, https://materialize.com/wp-content/uploads/2020/12/kafka_overview-300x39.png 300w, https://materialize.com/wp-content/uploads/2020/12/kafka_overview-768x99.png 768w"></p>
<p>In this scenario, the message broker is providing durable storage of events between when a customer sends them, and when Fivetran loads them into the data warehouse.</p>
<p>However, Kafka has occasionally been described as something much more than just a better message broker. Proponents of this viewpoint position Kafka as a fundamentally new way of managing data, where <a href="https://www.confluent.io/blog/okay-store-data-apache-kafka/" target="_blank" rel="noopener noreferrer">Kafka replaces the relational database as the definitive record of what has happened</a>. Instead of reading and writing a traditional database, you append events to Kafka, and read from downstream views that represent the present state. This architecture has been described as “<a href="https://www.confluent.io/blog/turning-the-database-inside-out-with-apache-samza/" target="_blank" rel="noopener noreferrer">turning the database inside out</a>“.</p>
<p>In principle, it is possible to implement this architecture in a way that supports both reads and writes. However, during that process you will eventually confront every hard problem that database management systems have faced for decades. You will more or less have to write a full-fledged DBMS in your application code. And you will probably not do a great job, because databases take years to get right. You will have to deal with dirty reads, phantom reads, write skew, and all the other symptoms of a hastily implemented database.</p>

<p>The fundamental problem with using Kafka as your primary data store is it provides no isolation. Isolation means that, globally, all transactions (reads and writes) occur along some consistent history. Jepsen provides a <a href="https://jepsen.io/consistency">guide</a> of isolation levels (inhabiting an isolation level means that the system will never encounter certain anomalies).</p>
<p>Let’s consider a simple example of why isolation is important: suppose we’re running an online store. When a user checks out, we want to make sure all their items are actually in stock. The way to do this is to</p>
<ol>
<li>Check the inventory level for each item in the user’s cart.</li>
<li>If an item is no longer available, abort the checkout.</li>
<li>If all items are available, subtract them from the inventory and confirm the checkout.</li>
</ol>
<p>Suppose we are using Kafka to manage this process. Our architecture might look something like this:</p>
<p><img src="https://materialize.com/wp-content/uploads/2020/12/kafka_checkout.png" data-src="https://materialize.com/wp-content/uploads/2020/12/kafka_checkout.png" alt="A microservice workflow for processing checkouts" width="960" height="753" data-srcset="https://materialize.com/wp-content/uploads/2020/12/kafka_checkout.png 960w, https://materialize.com/wp-content/uploads/2020/12/kafka_checkout-300x235.png 300w, https://materialize.com/wp-content/uploads/2020/12/kafka_checkout-768x602.png 768w" data-sizes="(max-width: 960px) 100vw, 960px" srcset="https://materialize.com/wp-content/uploads/2020/12/kafka_checkout.png 960w, https://materialize.com/wp-content/uploads/2020/12/kafka_checkout-300x235.png 300w, https://materialize.com/wp-content/uploads/2020/12/kafka_checkout-768x602.png 768w"></p>
<p>The web server reads the inventory level from a view downstream from Kafka, but it can only commit the transaction <em>upstream</em> in the checkouts topic. The problem is one of <strong>concurrency control</strong>: if there are two users racing to buy the last item, <em>only one must succeed</em>. We need to read the inventory view and confirm the checkout at <em>a single point in time</em>. However, there is no way to do this in this architecture.</p>
<p>The problem we now have is called <a href="http://justinjaffray.com/what-does-write-skew-look-like/">write skew</a>. Our reads from the inventory view can be out of date by the time the checkout event is processed. If two users try to buy the same item at nearly the same time, they will both succeed, and we won’t have enough inventory for them both.</p>
<p>Event-sourced architectures like these suffer many such isolation anomalies, which constantly gaslight users with “time travel” behavior that <a href="https://www.google.com/search?q=facebook+unread+notification+glitch">we’re all familiar with</a>. Even worse, research shows that anomaly-permitting architectures create outright security holes that allow hackers to steal data, as covered in <a href="https://www.cockroachlabs.com/blog/acid-rain/">this excellent blog post</a> on <a href="http://www.bailis.org/papers/acidrain-sigmod2017.pdf">this research paper.</a></p>

<p>These problems can be avoided if you use Kafka as a <em>complement</em> to a traditional database:</p>
<p><img src="https://materialize.com/wp-content/uploads/2020/12/kafka_oltp_flow.png" data-src="https://materialize.com/wp-content/uploads/2020/12/kafka_oltp_flow.png" alt="kafka used for Change Data Capture from an OLTP database" width="960" height="658" data-srcset="https://materialize.com/wp-content/uploads/2020/12/kafka_oltp_flow.png 960w, https://materialize.com/wp-content/uploads/2020/12/kafka_oltp_flow-300x206.png 300w, https://materialize.com/wp-content/uploads/2020/12/kafka_oltp_flow-768x526.png 768w" data-sizes="(max-width: 960px) 100vw, 960px" srcset="https://materialize.com/wp-content/uploads/2020/12/kafka_oltp_flow.png 960w, https://materialize.com/wp-content/uploads/2020/12/kafka_oltp_flow-300x206.png 300w, https://materialize.com/wp-content/uploads/2020/12/kafka_oltp_flow-768x526.png 768w"></p>
<p>OLTP databases perform a crucial task that message brokers are not well suited to provide: admission control of events. Rather than using a message broker as a receptacle for “fire and forget” events, forcing your event schema into an “intent pattern”, an OLTP database can <em>deny</em> events that conflict, ensuring that only a single consistent stream of events are ever emitted. OLTP databases are really good at this core <strong>concurrency control</strong> task – scaling to many millions of transactions per second.</p>
<p>Using a database as the point-of-entry for writes, the best way to extract events from a database is via streaming <strong>change-data-capture</strong>. There are several great open CDC frameworks like <a href="http://debezium.io/">Debezium</a> and <a href="http://maxwells-daemon.io/">Maxwell</a>, as well as native CDC from <a href="https://www.cockroachlabs.com/docs/stable/change-data-capture.html">modern</a> <a href="https://docs.oracle.com/cd/B28359_01/server.111/b28313/cdc.htm">SQL</a> <a href="https://docs.yugabyte.com/latest/architecture/docdb-replication/change-data-capture/">databases</a>. Change-data-capture also sets up an elegant operational story. In recovery scenarios, everything can be purged downstream and rebuilt from the (very durable) OLTP database.</p>

<p>The database community has learned (and re-learned) several important lessons over decades. Each one of these lessons was obtained at the high prices of data corruption, data loss, and numerous user-facing anomalies. The last thing you want to do is to find yourself relearning these lessons because you <a href="https://www.oreilly.com/library/view/strata-hadoop/9781491944608/video244677.html">accidentally misbuilt a database</a>.</p>
<p>Real-time streaming message brokers are a great tool for managing high-velocity data. But you will still need a traditional DBMS for isolating transactions. The best reference architecture for “turning your database inside out” is to use OLTP databases for admission control, use CDC for event generation, and model downstream copies of the data as materialized views.</p>

<p>If you’re interested in getting fully consistent views of your Kafka data updated in realtime, <a href="https://materialize.com/quickstart/">try Materialize out</a>&nbsp;to see if it’s the right solution for you!</p>
<div><h3>Subscribe to our Newsletter</h3>
        
        

        </div></div></div>]]>
            </description>
            <link>https://materialize.com/kafka-is-not-a-database/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25346851</guid>
            <pubDate>Tue, 08 Dec 2020 15:52:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Little Tasks, Little Trust]]>
            </title>
            <description>
<![CDATA[
Score 216 | Comments 75 (<a href="https://news.ycombinator.com/item?id=25346460">thread link</a>) | @aard
<br/>
December 8, 2020 | http://adamard.com/little_tasks.html | <a href="https://web.archive.org/web/*/http://adamard.com/little_tasks.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <h2>{<br>&nbsp;&nbsp;&nbsp;&nbsp;Adam Ard<br>}</h2><br>
  <h2>Little Tasks, Little Trust</h2>
  <h3>How Delegating Responsibilities is Better Than Managing By Tasks</h3>
  <blockquote>
    Trust is the highest form of motivation. It brings out the very
    best in people.
  </blockquote>
  <blockquote>
    --Stephen R. Covey, The 7 Habits of Highly Effective People
  </blockquote>
  <p>
It’s basically a sacred project management mantra by
now: <strong>divide your work into tasks that are as small as
possible</strong>. Estimate them with your team. Then drop them into
the all-knowing product backlog. But no one seems to be looking very
critically at how this practice has affected the software engineering
profession. Back in the 90’s, when I started programming, this was not
how it worked. It was, dare I say, a little more
professional.</p><p>Back then, your boss had a dozen or more things
they were responsible for and when you got hired they breathed a deep
sigh of relief.</p><p>“Finally, now that Vincent is here, I can make
him do A and B; and with Ted doing C, D, and E and Jan doing F, G, and
H, I can finally get to I, J, K, L, and M.”</p><p>Most importantly, A
and B were big things, like whole products or large system
libraries. Building and maintaining them consumed all of your
time. They were your delegated responsibilities, not mere tasks. It
wasn’t that hard to manage people this way either. If you weren’t
doing a good job, the boss would let you know.</p><p>“Hey, Vincent, A
isn’t turning out quite like I was imagining. Can you do a little more
of this — and definitely more cowbell.”</p><p>Then you went back to
your private office (I sure miss private offices, but that is a topic
for another day) and fixed a few things. Later, in a weekly status
meeting you would tell people how it went — yep, that’s right, no
daily stand-ups where you look mournfully at your shoes and admit that
you didn’t make any notable progress yet.</p><p>No backlog grooming
meetings or burn-down charts either. Your manager simply looked at
how <em>your </em>products were coming along. A little trust, some
accountability, and a healthy portion of “give me some space to do my
work.”</p><p>The way we work now is different. Sadly, it’s less
motivating, less efficient, and profoundly less respectful of
individual abilities.</p><h3>whose vision is it again?</h3><p>As I
see it, little tasks are born of a fundamentally different management
attitude. Small tasks are a not-so-subtle way of saying that all the
product vision lies with management. Keep away. Don’t
touch.</p><p>While larger tasks send a completely different
message. Here, management is giving you bigger pieces to chew on,
inviting you to mix some of your own creativity with the end
product. You get to do some design work, think about what the customer
needs, and take pride in what comes out the other end. Sure, the
organization has an overarching strategy, but they still want people
to take on responsibilities, not just errands. They trust you to align
with the overall vision and because you feel like you are part of the
“club”, you actually want to.</p><h3>too much love for the
metrics</h3><p>Small tasks have also taken hold because they fit
nicely with the age-old assembly-line mentality. Sadly, there are
armies of managers that still live by that dogma. For them, it is all
about picking <em>metrics and optimizing them </em>— management by
chart and graph.</p><p>Unfortunately, little tasks in Jira (or any of
the dozens of other issue tracking systems out there) bring the
promise of a whole host of tasty new charts and graphs: burn-down,
burn-up, velocity, lead-time, cycle time, task age, throughput, failed
deployment, flow and control. It’s as irresistible as candy to a
baby.</p><p>But, assigning responsibilities instead of tasks takes
away an assembly-line manager’s favorite tools. Because they are
larger, responsibilities can’t be so easily measured and tracked. So
metrics-managers will fight both tooth and nail to keep your work divided
and cataloged in tiny, traceable instructions.</p><h3>when will I get some design
experience?</h3><p>Sadly, as developers, we do it to ourselves as
well. Once someone gives us a better title, we are right on board with
the program. When a regular developer might have had a chance to do
some research or design, we immediately snatch it away for
ourselves.</p><p>As technical management, we standardize our
frameworks, languages, deployment operating systems, and cloud service
providers. We write wrappers around networking, logging, and
monitoring libraries and demand they always be used. Then, after we
have taken the task of designing and researching the CI/CD tools and
pipeline, we write coding standards for our coding
standards.</p><p>Worse yet, we design every product’s architecture,
and expect any deviation to be approved by us first. All that is left
are tiny morsels. Grunt work for the foot soldiers once the fun has
been stripped away.</p><p>Poor front-line programmers are left
wide-eyed with empty bowls, asking “please sir, can I have some more?
I just wanted to design one little service. I know I am not worthy,
but can I please just write my own sql queries without using that
awful ORM?  PLEASE?”</p><p>Sadly, when those poor programmers finally
seek promotion, hoping for their first real shot at higher level
engagement, they are rebuffed: “You don’t really have any design
experience I am afraid. We are looking for someone who has designed
large systems.”</p><p>To their managers they could rightfully reply,
“that was your doing, not mine!”</p><h3>estimation is never
free</h3><p>There is a grave misconception circulating that if you
just sit down, in a comfy conference room chair, and split a project
into tiny tasks, small enough to be individually estimated,
then when you add them up, Viola! You’ll have a accurate
estimate for the whole project! Easy peasy.</p><p>There are two
problems with this delusion. First, no task, even a small one,
is easy to estimate. I have seen many “tiny”, one-day tasks blow up
into week long campaigns. All because of hidden complexity that comes
popping out like a Pandora’s box once you start coding on
it.</p><p>Second, when you divide work into little tasks, before
actually working on any of them, you are making untested
assumptions. Many of them. The more tasks you define, the more facets
of a hypothetical design you must assume (implicitly of course, since
no one ever writes design assumptions in task descriptions). Soon,
you’ve created a long chain of design choices, all depending on
previous ones, sitting on sticky notes on the wall.</p><p>The problem
is, as soon as you start working on one of them, you will
realize that your implicit design decisions are wrong. Now, you will spend MUCH more time than was
previously estimated for this task and all other tasks that depend on
its faulty design are invalid. The whole house of cards comes
tumbling down. Time for another all-day backlog grooming session? What
a waste!</p><h3>conclusion</h3><p>Back in the day, before everyone
realized that software companies were positioned to make lots of
money, we had some elbow room. We had a lot of responsibility and the
ability to make a lot of decisions. But now, a lot more people have
piled onto the island. Unfortunately, some of them have slowly chipped
away at the domain of the software engineer. One by one, descending
from their vessels they planted their flags:</p><p>“I am Amerigo, the
product guy. Heretofore, no developer will make product decisions, for
they are mine.”</p><p>“And I am Ferdinand, process guy. Heretofore,
no developer will make process decisions, for they are
mine.”</p><p>“I Bartolomeu will enforce compliance.”</p><p>“I Vasco
used to be pretty good at Microsoft Access, I guess I’ll be the
database guy.”</p><p>One by one, until every responsibility that
wasn’t actual open-up-emacs-and-start-typing-stuff programming was
taken away, forbidden even. And then, the remaining, purely technical
tasks were carved up by architecture/standard hoarding engineers,
hungry for something of substance. Only dry, broken carcasses were
left scattered on the ground.</p><p>Of course, there is a solution to
this predicament — delegate <em>responsibilities</em> to everyone,
all the way down to the bottom of the hierarchy. Or better yet,
flatten or abolish the hierarchy all together. But until that
happens, you’ll just have to content yourself with measly for-loops
and if-statements — following the coding standard of
course.</p></div></div>]]>
            </description>
            <link>http://adamard.com/little_tasks.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25346460</guid>
            <pubDate>Tue, 08 Dec 2020 15:29:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[FedEx and UPS hit companies with unexpected holiday shipping limits]]>
            </title>
            <description>
<![CDATA[
Score 207 | Comments 192 (<a href="https://news.ycombinator.com/item?id=25346386">thread link</a>) | @mooreds
<br/>
December 8, 2020 | https://www.modernretail.co/retailers/this-is-going-to-ruin-us-fedex-and-ups-hit-companies-with-unexpected-holiday-shipping-limits/ | <a href="https://web.archive.org/web/*/https://www.modernretail.co/retailers/this-is-going-to-ruin-us-fedex-and-ups-hit-companies-with-unexpected-holiday-shipping-limits/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>Johnny Galbraith, co-founder of Salt Lake City-based e-commerce company Letterfolk, knew that it was going to be difficult to get orders to customers in a timely manner this holiday season, with more people ordering online than ever before.</p><p>He thought he had come up with a solution: to hold his Black Friday sale a week earlier this year. That way, he would be shipping out his products before carriers like FedEx — which he estimates ships 75% of Letterfolk’s packages — would be under the most strain.</p><div id="piano-cta">
<p>But on the Saturday before Thanksgiving, Galbraith got a call from his FedEx representative: through the holidays, FedEx would only pick up 110 Letterfolk packages per day — something that has never happened to Galbraith in the five years he’s been in business. It was a number that was calculated based on the average number of packages FedEx was picking up from Letterfolk per day in September, plus 10%. But thanks to his early Black Friday sale, Galbraith had a queue of 3,000 orders waiting to go out.</p>

<p>“It was like, ‘this is going to ruin us as a business,'” said Galbraith, whose company sells letterboards and other home decor. “We are being told that just to ship out our existing queue — without any other orders coming it — it would take us up until the holidays to get them out to customers.”</p>
<p>Carriers like FedEx and UPS have been warning for months to <a href="https://www.wsj.com/articles/this-holiday-crunch-starts-early-with-more-packages-than-means-to-deliver-them-11603013401">expect holiday shipping delays</a>. But some retail executives, like Galbraith, say they were not given advanced notice by carriers that they could face package pickup limits this holiday. It’s an issue that’s affecting companies both big and small — the Wall Street Journal <a href="https://www.wsj.com/articles/ups-slaps-shipping-limits-on-gap-nike-to-manage-e-commerce-surge-11606926669">reported</a> last week that UPS had temporarily stopped accepting shipments from major retailers like Nike and Macy’s.</p>
<p>Some executives who spoke with Modern Retail said that they feel like their carriers did not give them enough advance notice before applying a limit, and are frustrated by the fact that limits seem to be arbitrarily applied. In the meantime, they’re scrambling to find often expensive alternatives, including renting their own trucks or trying to find space with other carriers.</p>
<p>Representatives from FedEx and UPS would not provide details to Modern Retail about how they calculate package pickup limits.</p>
<p>FedEx has been “proactively working with our customers to understand their expected volume,” a spokeswoman told Modern Retail, and said the company has been preparing for the holidays by hiring more than 70,000 seasonal workers this year, and for the first time, picking up packages seven days a week.</p>

<p>“<span>UPS</span>&nbsp;continues to work closely with our largest customers to steer volume to capacity and ensure the&nbsp;<span>UPS</span> network is reliable for all customers,” a UPS spokesman said. “Agreed upon strategies for our largest customers include shifting package volume away from the heaviest demand shipping days, fully utilizing weekend capacity, and aligning promotional strategies with capacity.”</p>
<p><strong>Making their own deliveries<br>
</strong>For the most part, UPS and FedEx first started imposing shipping limits after Black Friday. Helena Price Hambrecht, founder of aperitif brand Haus, <a href="https://www.nytimes.com/2020/12/05/business/ecommerce-shipping-holiday-season.html?referringSource=articleShare">told the New York Times</a> that FedEx informed her that starting on Wednesday, its drivers would only pick up 500 packages from Haus per week day, through the holidays. FedEx however, did give Haus a larger cap on the weekends. In a follow-up email to Modern Retail, Price Hambrecht did not say exactly when FedEx informed her of the limit, only that “FedEx has been great about communicating changes to us as soon as possible.”</p>
<p>David Malka, chief sales officer of returns processing company goTRG — which works with major retailers like Target, Walmart and Lowe’s to process some of their returns — told Modern Retail that shipping limits of roughly 200 packages per day had been imposed at four of the company’s warehouses. Though he added that the company is getting “conflicting reports” from FedEx about what exactly the limit is at some facilities. Malka, like Gilbraith said that goTRG received no advanced notice from FedEx that package pickup limits would be applied.</p>
<p>The most immediate way that retailers are trying to deal with pickup limits imposed by UPS or FedEx is to redirect some shipments to another carrier. Shortly after Galbraith’s FedEx representative informed him of Letterfolk’s new limit, he immediately set up deliveries through UPS — something he said he hadn’t done previously because he had a good relationship with FedEx.</p>
<p>That’s helped Letterfolk get through some of the 3,000 order backlog, though its <a href="https://www.letterfolk.com/pages/holiday-shipping-info">website is still advising customer</a>s that most orders placed during its Black Friday sale will ship within one to three business weeks. However, he said that it’s more expensive right now for Letterfolk to ship through UPS, because his company didn’t have time to negotiate discounted rates.</p>
<p>Some companies are setting up other contingency plans to ensure their packages get into customers hands more quickly. Price Hambrecht told Modern Retail that Haus will be relying on Ohi, a last-mile delivery provider, to deliver more of its packages in the Bay Area and Southern California.</p>
<p>Jay Sauceda, founder of Austin-based 3PL Sauceda Industries, said that his company rented its own truck for the first time for the holidays. Sauceda — which works with companies including apparel brand Rowing Blazers and bra startup Pepper — has yet to be hit with a package pickup per day limit. But if it does, the plan then is to load packages onto the truck and deliver them directly to a FedEx or UPS sorting facility.</p>
<p>Sauceda is also advising its customers to try and encourage customers to get orders in two to three days ahead of shipping cutoffs given by FedEx, UPS and other carriers to ensure packages arrive in time for Christmas and other key dates.</p>
<p>“[The carriers] are in a very unenviable position,” Sauceda said. “So the biggest thing that we are trying to do this year to try to take the tension off.”</p>
<p><em>This story has been updated to clarify that FedEx has capped the number of Haus packages it will pick up at 500 per week day, not per day as previously stated.&nbsp;</em></p>
</div></div>]]>
            </description>
            <link>https://www.modernretail.co/retailers/this-is-going-to-ruin-us-fedex-and-ups-hit-companies-with-unexpected-holiday-shipping-limits/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25346386</guid>
            <pubDate>Tue, 08 Dec 2020 15:25:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Qt 6.0]]>
            </title>
            <description>
<![CDATA[
Score 438 | Comments 336 (<a href="https://news.ycombinator.com/item?id=25344826">thread link</a>) | @milliams
<br/>
December 8, 2020 | https://www.qt.io/blog/qt-6.0-released | <a href="https://web.archive.org/web/*/https://www.qt.io/blog/qt-6.0-released">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                            

                            <p>
                                Tuesday December 08, 2020 by <a href="https://www.qt.io/blog/author/lars-knoll">Lars Knoll</a> | <a href="#commento">Comments</a>
                            </p>
                            
                            <p><span id="hs_cos_wrapper_post_body" data-hs-cos-general-type="meta_field" data-hs-cos-type="rich_text"><p><span>I am really excited to announce today’s release of Qt 6.0. It is the first release of a new major version, and marks a major milestone for Qt. </span><strong><em>We started working on the initial ideas a few years ago, and since then, have put a massive effort into creating the next generation of Qt. </em></strong></p>
<!--more-->
<p><a href="https://www.qt.io/product/qt6/" rel="noopener" target="_blank"><span><img src="https://www.qt.io/hubfs/Qt%206%20email%20launch%20hero%201-png-1.png" alt="Qt 6"></span></a></p>

<p><span>Qt 5 has been a fantastic success over the years, and we have seen an enormous growth of our user base and Qt usage over eight years since we released Qt 5.0. But the world&nbsp; has undergone significant changes since 2012. Qt usage in embedded systems has skyrocketed, C++ has evolved, and new 3D graphics APIs have emerged. These are examples of factors that have directly affected Qt.</span></p>
<p><span>As a cross-platform framework, Qt needs to adjust to those changing requirements. We have managed to adapt very well to many of those requirements during the lifetime of Qt 5. However, maintaining full source and binary compatibility within the Qt 5 series made certain things impossible to fix within its lifetime. With Qt 6, we now have the opportunity to make changes and build Qt to be better suited for the years to come.</span><span></span></p>
<div>
<p>Thus, the mission of Qt 6 is to enable Qt to be the productivity platform for the future. Qt 6.0, as a major release of Qt, gave us a higher degree of freedom to implement new features, functionality, and better support today and tomorrow's requirements. Qt 6.0 is a continuation of the Qt 5 series, and we have focused on making migration non-disruptive for users. I published a <a href="https://www.qt.io/blog/2019/08/07/technical-vision-qt-6" rel="noopener">Qt 6 vision blog post</a> capturing those ideas around 18 months ago.</p>
<p>When creating Qt 6, we ensured that Qt’s core values have been adhered to and upheld, including:</p>
<ul>
<li>Its cross-platform nature, allowing users to deploy their applications to all desktop, mobile, and embedded platforms using one technology and from a single codebase</li>
<li>Its scalability from low-end, single-purpose devices to high-end complex desktop applications or connected system</li>
<li>Its world-class APIs and tools and <a href="https://doc.qt.io/" rel="noopener">documentation</a>, simplifying the creation of applications and devices</li>
<li>Its maintainability, stability, and compatibility, allowing users to maintain large codebases with minimal effort</li>
<li>Its large developer ecosystem with more than 1.5 million users</li>
</ul>
<p>Qt 6.0 is the first release of the Qt 6 series addressing new market demands while keeping the core values at the heart of what we do.</p>
<p>When developing Qt 6, we had an in-depth look at some of Qt's most central parts to identify how we could improve them. We discovered a couple of core focus areas that we invested considerable time in improving. Those areas include:</p>
<div>
<ul>
<li>Leveraging C++17</li>
<li>Next generation QML</li>
<li>New graphics architecture</li>
<li>Unified 2D and 3D for Qt Quick</li>
<li>CMake build system (with qmake still supported for applications)</li>
</ul>
</div>
<p>We have of course also spent time doing numerous improvements in other areas, too many to mention them all here, and I suggest you look at the more detailed <span><span><a href="https://wiki.qt.io/New_Features_in_Qt_6.0" rel="noopener">wiki page</a>. We are also hosting Meet Qt 6.0 webinar sessions covering the <a href="https://www.qt.io/events/meet-qt-6-1607340244" rel="noopener">Americas/EMEIA</a> and <a href="https://www.qt.io/events/meet-qt-6-1607339968" rel="noopener">EMEIA/APAC</a> time zones. But let's take a look at some of the highlights.</span></span></p>
</div>
<h3><span>C++17</span></h3>
<p><span><img src="https://www.qt.io/hs-fs/hubfs/cpp_logo-png.png?width=168&amp;name=cpp_logo-png.png" width="168" alt="C++ 17 in Qt 6" srcset="https://www.qt.io/hs-fs/hubfs/cpp_logo-png.png?width=84&amp;name=cpp_logo-png.png 84w, https://www.qt.io/hs-fs/hubfs/cpp_logo-png.png?width=168&amp;name=cpp_logo-png.png 168w, https://www.qt.io/hs-fs/hubfs/cpp_logo-png.png?width=252&amp;name=cpp_logo-png.png 252w, https://www.qt.io/hs-fs/hubfs/cpp_logo-png.png?width=336&amp;name=cpp_logo-png.png 336w, https://www.qt.io/hs-fs/hubfs/cpp_logo-png.png?width=420&amp;name=cpp_logo-png.png 420w, https://www.qt.io/hs-fs/hubfs/cpp_logo-png.png?width=504&amp;name=cpp_logo-png.png 504w" sizes="(max-width: 168px) 100vw, 168px"></span></p>
<p><span>With Qt 6 we now require a C++17 compatible compiler enabling the use more modern C++ language constructs when developing Qt and also allows for integration points on the API side.</span></p>
<h3><span>Core libraries and APIs</span></h3>
<p><span>Much work has gone into Qt Core, as it is the module that implements the most central parts of Qt. We've gone through many areas there and made improvements. To name some of the most central ones:</span></p>
<ul>
<li><span>The new <a href="https://www.qt.io/blog/property-bindings-in-qt-6" rel="noopener">property and binding system</a>: This system now brings the concept of bindings that made QML such a huge success in Qt 5 available from C++. </span></li>
<li><span>Strings and Unicode: With Qt 5, we started aligning Qt fully with Unicode, where we completed a lot of the work, but a few items remained that we now cleaned up for Qt 6. More details will come in a separate blog post later on.</span></li>
<li><span>QList has been a class that was often criticized in Qt 5, as it was heap allocating objects stored in there that were larger than a pointer, leading to pressure on heap allocation methods. In Qt 6, we changed this and unified QList and QVector into one class. See our <a href="https://www.qt.io/blog/qlist-changes-in-qt-6" rel="noopener">blog post about QList</a> in Qt 6 for details.</span></li>
<li><span>QMetaType and QVariant are fundamental to how our Qt’s meta-object system works. Signals and slots would not be possible without QMetaType and QVariant is required for dynamic invocations. Those two classes got an almost complete rewrite with Qt 6, and you can read about the details <a href="https://www.qt.io/blog/whats-new-in-qmetatype-qvariant" rel="noopener">here</a>.</span></li>
</ul>
<p><span>Other parts of Qt that are not related to graphics have also seen large changes. For example, Qt Concurrent has undergone an almost complete rewrite and now makes development of multi-threaded applications more effortless than ever. Qt Network has seen lots of clean-up and improvements. See this <a href="https://www.qt.io/blog/qt-network-in-qt-6" rel="noopener">blog post</a> for details.</span></p>
<h3><span>New graphics architecture</span><span>&nbsp;</span><span></span></h3>
<p><span>The graphics architecture of Qt 5 was very much dependent on OpenGL as the underlying 3D graphics API. While this was the right approach in 2012 when we created Qt 5, the market around us has changed significantly over the last couple of years with the introduction of Metal and Vulkan. We now have a large set of different graphics APIs that are commonly being used on different platforms. For Qt as a cross-platform framework, this, of course, meant that we had to adjust to this and ensure our users can run Qt on all of them with </span>maximum performance.</p>
<p><img src="https://www.qt.io/hs-fs/hubfs/image-png-Nov-03-2020-07-47-23-41-AM-png-2.png?width=367&amp;name=image-png-Nov-03-2020-07-47-23-41-AM-png-2.png" width="367" alt="New graphics architecture in Qt 6" srcset="https://www.qt.io/hs-fs/hubfs/image-png-Nov-03-2020-07-47-23-41-AM-png-2.png?width=184&amp;name=image-png-Nov-03-2020-07-47-23-41-AM-png-2.png 184w, https://www.qt.io/hs-fs/hubfs/image-png-Nov-03-2020-07-47-23-41-AM-png-2.png?width=367&amp;name=image-png-Nov-03-2020-07-47-23-41-AM-png-2.png 367w, https://www.qt.io/hs-fs/hubfs/image-png-Nov-03-2020-07-47-23-41-AM-png-2.png?width=551&amp;name=image-png-Nov-03-2020-07-47-23-41-AM-png-2.png 551w, https://www.qt.io/hs-fs/hubfs/image-png-Nov-03-2020-07-47-23-41-AM-png-2.png?width=734&amp;name=image-png-Nov-03-2020-07-47-23-41-AM-png-2.png 734w, https://www.qt.io/hs-fs/hubfs/image-png-Nov-03-2020-07-47-23-41-AM-png-2.png?width=918&amp;name=image-png-Nov-03-2020-07-47-23-41-AM-png-2.png 918w, https://www.qt.io/hs-fs/hubfs/image-png-Nov-03-2020-07-47-23-41-AM-png-2.png?width=1101&amp;name=image-png-Nov-03-2020-07-47-23-41-AM-png-2.png 1101w" sizes="(max-width: 367px) 100vw, 367px"></p>
<p><span>So while Qt 5 relied on OpenGL for hardware-accelerated graphics, the picture completely changes with Qt 6. All of our 3D graphics in Qt Quick is now built on top of a new abstraction layer for 3D graphics called RHI (Rendering Hardware Interface). RHI makes it possible for Qt to use the native 3D graphics API of the underlying OS/platform. So Qt Quick will now use Direct3D on Windows and Metal on macOS by default. For details, have a look at the <a href="https://www.qt.io/blog/graphics-in-qt-6.0-qrhi-qt-quick-qt-quick-3d" rel="noopener">blog post series about the RHI</a>.</span><span>&nbsp;</span></p>
<p><span>The OpenGL specific classes in Qt still exist, but are now moved out of QtGui in the <a href="https://doc.qt.io/qt-6/qtopengl-index.html" rel="noopener">QtOpenGL</a> module. We also added a new module called <a href="https://doc.qt.io/qt-6/qtshadertools-index.html" rel="noopener">QtShaderTools</a> to deal with the different shading languages of those APIs in a cross-platform way.</span></p>
<h3><span>Qt Quick 3D and Qt 3D</span></h3>
<p><span>Qt Quick 3D is a relatively new module. It seamlessly extends Qt Quick with 3D capabilities. With Qt Quick 3D, our focus was to create an API that is as easy to use as the existing parts of Qt Quick (for 2D user interfaces) while providing full support for creating complex 3D scenes. The main goal behind this effort has been to enable seamless integration between 2D and 3D content.</span><span></span></p>
<p><span>This module has seen significant improvements with Qt 6 that we wouldn’t have been able to do in the Qt 5 series. Most importantly it is now always using the RHI abstraction layer to make optimal use of the underlying graphics API and Hardware. Additionally, it now features a much deeper and more performant integration between 2D and 3D content, allowing you to place 2D items into a 3D scene. It also has vastly improved support for glTF2 and physics-based rendering, making it trivial to import assets created in other design tools. There are many other major improvements in the module, a more in-depth description can be found in a <a href="https://www.qt.io/blog/what-is-new-in-qt-quick-3d-6.0" rel="noopener">separate blog post</a>.</span></p>
<p><span>Qt 3D is now also based on top of the RHI abstraction layer, has seen some performance improvements and cleanups. You can find more details in two blog posts by our partner KDAB (<a href="https://www.kdab.com/qt-3d-changes-in-qt-6/" rel="noopener">here</a> and <a href="https://www.kdab.com/qt3d-renderer-qt6/" rel="noopener">here</a>).</span></p>
<h3><span>Desktop styling for Qt Quick</span></h3>
<p><span><img src="https://www.qt.io/hubfs/Qt%206%20Desktop%20Styling-png.png" alt="Desktop Styling in Qt 6"></span></p>
<p><span>When we created the set of controls for Qt Quick, our focus was to make them lightweight and performant. For that reason, they did not support desktop styling in Qt 5. However, in Qt 6, we found a way to make them look &amp; feel native on desktop operating systems. With 6.0, Qt Quick now supports native styling on both macOS and Windows. See this <a href="https://www.qt.io/blog/desktop-styling-with-qt-quick-controls" rel="noopener">blog post for details</a>.</span><span> Native look &amp; feel for Android and Linux already existed with the Material and Fusion styles in Qt 5. We are improving those for future Qt releases and are also planning to implement a native style for iOS.</span></p>
<h3><span>Interfacing with platform specific functionality</span></h3>
<p><span>Even with Qt offering most functionality required to develop your application platform-independently, there is sometimes a need to interface with platform-specific functionality. In Qt 5, we provided a set of add-on modules (QtX11Extras, QtWinExtras, QtMacExtras) to help with this purpose. But this full separation from the rest of Qt has led to a couple of architectural issues, inconsistencies and code duplication within Qt. In Qt 6, we made an effort to clean this up and fold the functionality offered by those add-on modules into platform specific APIs offered directly in Qt. This will make interfacing with OS/platform-specific APIs much easier in Qt 6. Have a look <a href="https://www.qt.io/blog/platform-apis-in-qt-6" rel="noopener">here</a>&nbsp;for more details.</span></p>
<h3><span>Build system and&nbsp;</span><span>Packaging</span></h3>
<p><span><img src="https://www.qt.io/hs-fs/hubfs/600px-Cmake-svg-png.png?width=189&amp;name=600px-Cmake-svg-png.png" width="189" srcset="https://www.qt.io/hs-fs/hubfs/600px-Cmake-svg-png.png?width=95&amp;name=600px-Cmake-svg-png.png 95w, https://www.qt.io/hs-fs/hubfs/600px-Cmake-svg-png.png?width=189&amp;name=600px-Cmake-svg-png.png 189w, https://www.qt.io/hs-fs/hubfs/600px-Cmake-svg-png.png?width=284&amp;name=600px-Cmake-svg-png.png 284w, https://www.qt.io/hs-fs/hubfs/600px-Cmake-svg-png.png?width=378&amp;name=600px-Cmake-svg-png.png 378w, https://www.qt.io/hs-fs/hubfs/600px-Cmake-svg-png.png?width=473&amp;name=600px-Cmake-svg-png.png 473w, https://www.qt.io/hs-fs/hubfs/600px-Cmake-svg-png.png?width=567&amp;name=600px-Cmake-svg-png.png 567w" sizes="(max-width: 189px) 100vw, 189px"></span></p>
<p><span>We also made some considerable changes in how we build and distribute Qt.&nbsp; Worth mentioning is that Qt 6 itself is now <a href="https://www.qt.io/blog/qt-6-build-system" rel="noopener">built using CMake</a>. This has also led to significant improvements for all our users that use CMake to build their projects. We will continue to support qmake for the lifetime of Qt 6, so there is no need to make any changes to your build system if you're using it, but we recommend to use CMake for all new projects.</span></p>
<p><span>Qt 6 also comes with a much smaller default package, and many of the add-ons are now distributed as separate packages through a package manager. This gives us more flexibility in adapting release schedules of add-ons to market requirements, allowing, for example, for more frequent feature releases as the core Qt packages or making them available for multiple Qt versions at the same time. In addition, we can use the package manager as a delivery channel for 3rd party content. And finally, it gives our users more flexibility as they can choose to download only what they really need. </span></p>
<p><span>Currently, we are using the existing Qt …</span></p></span></p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.qt.io/blog/qt-6.0-released">https://www.qt.io/blog/qt-6.0-released</a></em></p>]]>
            </description>
            <link>https://www.qt.io/blog/qt-6.0-released</link>
            <guid isPermaLink="false">hacker-news-small-sites-25344826</guid>
            <pubDate>Tue, 08 Dec 2020 13:39:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Are people with dark personality traits more likely to succeed?]]>
            </title>
            <description>
<![CDATA[
Score 202 | Comments 177 (<a href="https://news.ycombinator.com/item?id=25344640">thread link</a>) | @known
<br/>
December 8, 2020 | https://psyche.co/ideas/are-people-with-dark-personality-traits-more-likely-to-succeed | <a href="https://web.archive.org/web/*/https://psyche.co/ideas/are-people-with-dark-personality-traits-more-likely-to-succeed">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p><strong>â€˜Darkâ€™ personalities come in</strong> various shades, but at the core of all of them is a tendency to callously use others for personal gain. What is it that these types of people are really gaining, though? Might a benevolent approach to life and others be even more advantageous?</p>
<p>For <span>15 years,</span> research into dark personality traits (including narcissism, psychopathy and Machiavellianism) has been rapidly <a href="https://onlinelibrary.wiley.com/doi/abs/10.1111/spc3.12018" rel="nofollow noreferrer noopener">expanding</a>. We now know that these traits are far more <a href="https://europepmc.org/article/med/32484407" rel="nofollow noreferrer noopener">evident</a>, on average, in men than women. We know that <a href="https://pubmed.ncbi.nlm.nih.gov/19243821/" rel="nofollow noreferrer noopener">approximately</a> <a href="https://psycnet.apa.org/record/2008-13625-018" rel="nofollow noreferrer noopener"><span>1-2 per cent</span></a> of individuals in the general population display extremely dark personality features â€“ enough to meet the clinical threshold for a personality disorder â€“ and about <span>10-20 per</span> cent of individuals <a href="https://pubmed.ncbi.nlm.nih.gov/22996170/" rel="nofollow noreferrer noopener">have</a> moderately elevated levels. We know that even people with moderate levels of dark traits can wreak havoc: they are more likely to <a href="https://journals.sagepub.com/doi/10.1177/1745691616666070" rel="nofollow noreferrer noopener">lie and cheat</a>, show <a href="https://www.sciencedirect.com/science/article/pii/S0191886920305468" rel="nofollow noreferrer noopener">racist</a> attitudes, and be <a href="https://psycnet.apa.org/record/2014-04417-005" rel="nofollow noreferrer noopener">violent</a> towards others.</p>
<p>As researchers, we have studied these traits ourselves. But in a bid to balance out the extensive literature on dark traits, we have recently started to <a href="https://www.frontiersin.org/articles/10.3389/fpsyg.2019.00467/full" rel="nofollow noreferrer noopener">focus</a> on the light side of human personality instead â€“ the â€˜everyday saintsâ€™ among us. These people are genuinely interested in others and treat them well without question, not as a means to an end. They applaud the success of others, believe in the fundamental goodness of humans, and respect the dignity of everyone. Our recent <a href="https://www.sciencedirect.com/science/article/pii/S019188692030310X" rel="nofollow noreferrer noopener">study</a> of more than 36,000 adults suggests that these traits are common: around <span>30-50 per cent</span> of people show prominent light personality trait profiles, depending on world region, and these traits are particularly common in women.</p>
<p>We wanted to understand which personality profile â€“ dark or light â€“ leads to more success and happiness in the long run. There is an oft-touted saying that â€˜Nice guys finish lastâ€™ and, on the face of it, this might seem correct. If youâ€™re always expending your energy caring about others, perhaps youâ€™re bound to get left behind. If youâ€™re willing to deceive and exploit others without worrying about their feelings, you can look after â€˜number oneâ€™ and rise faster to the top. But does the research back this up?</p>
<p>Experimental studies support the idea of a â€˜successfulâ€™ dark personality, but only up to a point. One <a href="https://psycnet.apa.org/record/2015-11168-026" rel="nofollow noreferrer noopener">study</a> found that people with psychopathic personality traits win more points on a negotiation task where they are required to compete with a partner, but fewer points on a task that involves cooperation. Those with dark traits are <a href="https://link.springer.com/article/10.1007%2Fs12144-018-9823-9" rel="nofollow noreferrer noopener">more</a> likely to â€˜defectâ€™ in the classic Prisonerâ€™s Dilemma task â€“ an approach that means maximising your own outcome while duping the other participant.</p>
<p>But their success in the real world is questionable. In corporate settings, those with dark personality traits are slightly more likely to <a href="https://psycnet.apa.org/record/2018-51219-001" rel="nofollow noreferrer noopener">emerge</a> as leaders and are seen as <a href="https://onlinelibrary.wiley.com/doi/abs/10.1002/bsl.925" rel="nofollow noreferrer noopener">charismatic</a> but, when it comes to getting the job done, they tend to achieve less and are considered poor team players. Our recent study also found that political figures with dark personality traits are more likely to get elected and hold their positions, but other studies <a href="https://journals.sagepub.com/doi/abs/10.1177/0956797615611922" rel="nofollow noreferrer noopener">show</a> that they are much poorer at getting legislation passed. Hedge fund managers with these traits generally <a href="https://journals.sagepub.com/doi/abs/10.1177/0146167217733080" rel="nofollow noreferrer noopener">obtain</a> significantly lower financial returns on the investment funds they manage. Overall, individuals with dark traits <a href="https://psycnet.apa.org/doiLanding?doi=10.1037%2Fa0025679" rel="nofollow noreferrer noopener">engage</a> in more counterproductive work behaviour, such as theft and abusive supervision. Perhaps unsurprisingly, they donâ€™t end up with higher average incomes than their peers with light personalities.</p>
<p>Through deceitful manipulation and callous use of others, these individuals are cutting off the very (social) branch theyâ€™re sitting on</p>
<p>On top of this, those with dark personality traits donâ€™t have much luck outside of work. Even if they manage to avoid prison (imprisonment being a <a href="https://pubmed.ncbi.nlm.nih.gov/18837606/" rel="nofollow noreferrer noopener">high</a> possibility for those with extreme traits), they are at increased risk of <a href="https://pubmed.ncbi.nlm.nih.gov/19243821/" rel="nofollow noreferrer noopener">suicide</a> and <a href="https://pubmed.ncbi.nlm.nih.gov/28556964/" rel="nofollow noreferrer noopener">violent death</a>. They are also not particularly happy: people with dark traits tend to report poor self-image, an inability to intimately connect with others, and little life satisfaction. In contrast, we found that those with light personality trait profiles have fulfilling, intrinsically rewarding lives: they generally have a more positive view of themselves, more positive connections with others and find life more satisfying.</p>
<p>The key factor here seems to be empathy: the capacity to resonate with â€“ and understand the perspective of â€“ the emotional experiences of others. Individuals with light personality traits show a great deal of empathy for others, while those with dark personality traits tend to show very little. In our new research, we found that this seems to be what leads to a more satisfying life. Similarly, being prosocial â€“ acting kindly, cooperatively and with compassion toward others â€“ is also significantly <a href="https://psycnet.apa.org/record/2020-65092-001" rel="nofollow noreferrer noopener">linked</a> with higher wellbeing.</p>
<p>As a species, weâ€™re fundamentally built for social connectedness, and we depend on cooperation and <a href="https://www.aeaweb.org/articles?id=10.1257/jep.14.3.137" rel="nofollow noreferrer noopener">trust</a>. When those with dark personalities try to take advantage of this for their own personal gain, they do so at their own peril. In essence, through deceitful manipulation and callous use of others, these individuals are cutting off the very (social) branch theyâ€™re sitting on. While those with dark traits might initially capture the attention of others, their social behaviour ultimately leads to limited success in work or politics, and little satisfaction with their lives.</p>
<p><strong>So far, we have</strong> made it seem as though people fall into one of two binary groups: dark or light. But in reality, thereâ€™s a third group: we found that about <span>40 per cent</span> of individuals show a balance of dark and light traits. People in this mixed group are similar to the light group when it comes to critical variables involving empathy and social connectedness, but they still show some dark tendencies â€“ hampering their relationships to some degree with deceitful, self-absorbed or hurtful behaviour toward others.</p>
<p>Some might think that the mixed group is the optimal place to be: youâ€™re able to have some connection with others, but wonâ€™t be taken as a pushover. But compared with those with a light personality, mixed individuals have lower levels of life satisfaction and a less positive self-image. It seems that the mixed group are on the way to the light personality profile, so to speak, but fall short of the full expression â€“ and the added dark traits are whatâ€™s holding them back.</p>
<p>As people age â€“ particularly from 30 to 40 â€“ they become more likely to display light personality trait profiles</p>
<p>Regardless of where you fall on these dimensions of personality, we <a href="https://scottbarrykaufman.com/books/transcend/" rel="nofollow noreferrer noopener">believe</a> in the fundamental ability to grow and change. Large-scale studies have <a href="https://doi.apa.org/doiLanding?doi=10.1037%2Fa0024950" rel="nofollow noreferrer noopener">documented</a> that your general personality (eg, neuroticism, extraversion, conscientiousness) continues to change throughout your lifetime, and weâ€™ve found the same to be true when it comes to light and dark traits.</p>
<p>Specifically, we found that the extent to which you exhibit light or dark personality traits tends to shift as you get older. As people age â€“ particularly as they progress from 30 to 40 â€“ they become more likely to display light personality trait profiles. Other <a href="https://content.apa.org/record/2014-34008-001" rel="nofollow noreferrer noopener">research</a> has shown that moral character traits, such as conscientiousness and self-control, are generally more common in older people. Age doesnâ€™t completely account for the results â€“ younger people can display light personality traits â€“ but the research suggests that what can fundamentally differentiate light and dark profiles is a process of psychological maturation.</p>
<p>We are <a href="https://journals.sagepub.com/doi/10.1177/0963721417734875" rel="nofollow noreferrer noopener">born</a> with an innate sense of fairness, though this is a limited ability. Thus, like language, it is a skill that requires further development. Our research, and studies of our closest relatives, nonhuman primates, both show that moral behaviour can emerge and change across development â€“ in large part through cooperative social interactions. Thus, by embracing and trusting social connections, we can progress toward a light personality trait profile â€“ a pathway that appears to lead to healthy self-actualisation and even transcendence.</p>
<p>If youâ€™re curious about where you fall on the light vs dark personality spectrum, you can answer the <a href="https://scottbarrykaufman.com/lighttriadscale/" rel="nofollow noreferrer noopener">questions</a> we used in our study. We have now tested more than 250,000 individuals from across the globe, and you can see how your responses compare with the average. And remember, there is always scope for change: we believe in the fundamental ability to grow and transcend self-centredness through deliberate and sustained changes in our patterns of behaviour and thinking.</p>
<p>The most important thing is to <em>want</em> to change. Unfortunately, most people with extreme levels of dark personality traits donâ€™t want to change who they are. Despite not being particularly happy with their lives, they remain fixated on what they think they need: more and more power, wealth and domination over others.</p>
<p>Of course, some days weâ€™re all motivated to shut out other people, and simply look out for ourselves. This can be especially true when it seems that those who cheat, deceive and take advantage of others are somehow getting ahead. But rest assured that this doesnâ€™t seem to be the case. We have found that being empathic and connected to others â€“ capitalising on our fundamentally social nature â€“ is ultimately the pathway to a more rewarding life.</p></div></div></div>]]>
            </description>
            <link>https://psyche.co/ideas/are-people-with-dark-personality-traits-more-likely-to-succeed</link>
            <guid isPermaLink="false">hacker-news-small-sites-25344640</guid>
            <pubDate>Tue, 08 Dec 2020 13:17:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Road to Rome: Fundraising and Project Goals]]>
            </title>
            <description>
<![CDATA[
Score 24 | Comments 4 (<a href="https://news.ycombinator.com/item?id=25342500">thread link</a>) | @terabytest
<br/>
December 7, 2020 | https://rome.tools/funding/ | <a href="https://web.archive.org/web/*/https://rome.tools/funding/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main-content"> <section>  <section> <h2 id="introduction">Introduction <a href="#introduction" aria-label="introduction"></a></h2>  <p>I’m Sebastian McKenzie, the creator of <a href="https://babeljs.io/">Babel</a> and <a href="https://yarnpkg.com/">Yarn</a>. These tools have both inspired me to create Rome, a new project that aims to simplify and improve JavaScript and web development.</p> <p>Rome consolidates dozens of separate tools into one. Rome can install your dependencies, check your code for errors, run your tests, bundle your code, and more, all via a single CLI. Rome will be able to replace Babel, ESLint, Prettier, Yarn, and webpack. <a href="https://rome.tools/">Learn more</a>.</p> <p>It’s been three months since we announced our initial <a href="https://rome.tools/blog/2020/08/08/introducing-rome.html">beta release</a>. Since then, we’ve received a tremendous amount of enthusiasm from the community. As that enthusiasm has grown, it’s become clear that Rome will require a full-time developer to be successful and deliver on our ambitious goals and release a stable v1.0.</p> <p><strong>I need your help to make it a reality.</strong></p> </section> <section> <h2 id="funding">Funding <a href="#funding" aria-label="funding"></a></h2> <p>I have left my job so I can work independently and focus on what the community needs. This includes a <a href="#allow-users-to-extend-functionality-with-plugins">plugin system</a>, <a href="#add-more-configuration-and-have-less-opinions">more configuration</a>, and <a href="#integrate-with-existing-tools">dedicated integrations for existing tools</a>.</p> <p>We have an initial goal of <strong>$100,000</strong>. This will allow myself to work independently on our first stable release. Additional funding would allow us to expand upon our release goals, fund future maintenance, and compensate other contributors.</p> <p>If you’re passionate about what we’re building, or have otherwise benefited from my work, I would appreciate your financial support.</p>    <section> <h3 id="recent-contributions">Recent Contributions <a href="#recent-contributions" aria-label="recent-contributions"></a></h3> <ul> <li>Loading...</li> </ul> </section> <section> <h3 id="contribute">Contribute <a href="#contribute" aria-label="contribute"></a></h3> <p>Prices are in USD. Includes sales tax and international shipping. Refer to <a href="#questions-and-answers">Questions and Answers</a> for more information.</p> <p> Loading... </p> <div> <h4>Custom</h4> <p>Want to donate under $10? Something else? Select your own amount!</p>  </div> <section> <h4 id="business">Business <a href="#business" aria-label="business"></a></h4> <p>These tiers include dedicated support, migration assistance, and website advertisement. I’ll make sure Rome works well for you and your organization.</p> <p>Migration support is where I personally help your organization adopt and use Rome. This could include porting configuration, integrating with CI, or even adding new features and configuration to Rome.</p> <p>Interested in something else or have questions? Get in touch at <a href="https://rome.tools/cdn-cgi/l/email-protection#9be8fef9fae8eff2faf5dbe9f4f6feb5eff4f4f7e8"><span data-cfemail="5f2c3a3d3e2c2b363e311f2d30323a712b3030332c">[email&nbsp;protected]</span></a>!</p> <p> Loading... </p> </section> </section> </section> <section> <h2 id="goals">Goals <a href="#goals" aria-label="goals"></a></h2> <p>Funding will allow us to focus on usage and labor-intensive goals. We can make Rome easier to use and work for more people.</p> <section> <h3 id="add-more-configuration-and-have-less-opinions">Add more configuration and have less opinions <a href="#add-more-configuration-and-have-less-opinions" aria-label="add-more-configuration-and-have-less-opinions"></a></h3> <p>We have deliberately tried to keep configuration to a minimum. While this does produce a minimal API surface, it makes it almost impossible to easily migrate without losing functionality or changing conventions.</p> <p>We should aim to reduce the functional differences between Rome and other tools by introducing additional configuration and supported languages. This could include:</p> <ul> <li>Code formatting options</li> <li>Ability to customize expected filenames and directories</li> <li>Support for other configuration languages such as YAML and TOML</li> <li>More CLI flags</li> <li>Public JavaScript API</li> <li>Dynamic configuration (as opposed to static JSON-only configuration files)</li> <li><a href="#allow-users-to-extend-functionality-with-plugins">Allow extending functionality with plugins</a></li> </ul> <p>We have so far kept configuration light, as by reducing the amount of configuration options supported, we reduce maintenance cost and the potential for internal bugs.</p> <p>While this makes it easier for us as maintainers, it makes it drastically more difficult for users. No matter how persuasive our arguments may be for why you should use hard tabs instead of spaces, they seem like artificial and arbitrary constraints and introduces excessive prerequisites for adoption.</p> <p>Strong defaults and guided documentation for new users can provide the experience we ultimately want to offer, while removing our existing adoption restrictions.</p> </section> <section> <h3 id="integrate-with-existing-tools">Integrate with existing tools <a href="#integrate-with-existing-tools" aria-label="integrate-with-existing-tools"></a></h3> <p>Rome attempts to replace many tools. However we should still strive to support scenarios where another tool is better situated or preferred. This can also help during a migration where Rome is used in conjunction with another tool. We can do this in a couple of ways:</p> <p><strong>Integrating Rome as a first-class plugin in tools such as Babel, eslint, and webpack</strong></p> <p>Rome could be exposed as a plugin for those tools to allow you to adopt the Rome compiler without having to adopt the bundler first. This would reduce adoption prerequisites and allow easier experimentation inside of existing setups.</p> <p><strong>Seamlessly integrate other tools into Rome</strong></p> <p>We can introduce compatibility layers to have ESLint, Babel, and other tools run inside of Rome itself. ESLint errors could be displayed alongside Rome linter errors with the same UI and output format Instantly you could benefit from Rome’s file caching and parallelisation without needing a major migration.</p> </section> <section> <h3 id="assist-in-migrating-from-existing-tools">Assist in migrating from existing tools <a href="#assist-in-migrating-from-existing-tools" aria-label="assist-in-migrating-from-existing-tools"></a></h3> <p>It should be easy to migrate from other tools to Rome. First we need to ensure popular configuration options from other tools are supported. Then, offer automated tools to migrate basic setups without users needing to it manually.</p> <p>This needs to be accompanied with dedicated documentation and guides that can explain the differences between the tools, why you might want to use one over the other, similar concepts, new terminology, and equivalent config options.</p> </section> <section> <h3 id="allow-users-to-extend-functionality-with-plugins">Allow users to extend functionality with plugins <a href="#allow-users-to-extend-functionality-with-plugins" aria-label="allow-users-to-extend-functionality-with-plugins"></a></h3> <p>One of the fears with Rome is creating a monoculture where it’s impossible to innovate and experiment with new ideas. While it’s extremely optimistic to think we’ll ever get into any sort of monopolistic position, not allowing extensions does stiffle innovation regardless of our market position by restricting the viability and adoption of new ideas.</p> <p>Plugins allow us to avoid supporting functionality that we might not want, while still giving users a choice. It reduces our role as an arbiter and allows new languages, non-standard JavaScript features, code conventions, and ideas that interact with Rome to be viable, receive support, and proliferate.</p> <p>We need to be extremely careful not to get into the position where Babel and Webpack are today, where they’re heavily restricted by the usage of internal APIs. We need to be able to maintain our autonomy when it comes to making architectural changes. Balancing this with a powerful plugin API will be a challenge and will likely require several iterations.</p> </section> <section> <h3 id="release-undocumented-features">Release undocumented features <a href="#release-undocumented-features" aria-label="release-undocumented-features"></a></h3> <p>Rome currently does a lot more than linting. It’s a major challenge today to market and explain Rome when so much of the project isn’t officially supported. While we strive to make each individual component of Rome competitive on it’s own, to some the biggest advantage and compelling reason for using Rome might be the reduction in dependencies.</p> <p>We should focus on releasing and maturing basic versions of all core functionality. This would increase user confidence in our architecture and show that Rome is viable as the comprehensive replacement that we want to be.</p> </section> <section> <h3 id="provide-accessible-and-comprehensive-documentation">Provide accessible and comprehensive documentation <a href="#provide-accessible-and-comprehensive-documentation" aria-label="provide-accessible-and-comprehensive-documentation"></a></h3> <p>Documentation for developer tools is generally quite obtuse and relies a lot on prerequisite knowledge. This can make it intimidating and inaccessible for developers new to the ecosystem. Further complicating that is the broad scope of what Rome is trying to do.</p> <p>We have tried to address some of this by making our documentation a single page. This makes it easy to search, and it can be read from top to bottom without needing to jump around to learn about different concepts. However as our supported features grow, it will be more difficult to use this structure without oversimplifcation and doesn’t allow different paths for different demographics.</p> <p>We need to invest in a more scalable approach for our documentation. We can offer dedicated sections that explain features like linting end-to-end without needing to introduce other components like the compiler and bundler that contain significantly more concepts and overwhelm the reader. Separate guides can be offered for new users and those already experienced with other tools to properly cater for multiple audiences.</p> </section> <section> <h3 id="regularly-release-new-versions">Regularly release new versions <a href="#regularly-release-new-versions" aria-label="regularly-release-new-versions"></a></h3> <p>One of the reasons Babel was successful is how quickly I was able to quickly fix bugs and release new versions. I would regularly have releases out within minutes of a bug report. This was critical during the early days when adoption was low. Being able to unblock users quickly would often make them more excited to use Babel even though they ran into a bug.</p> <p>Similarly, we should try and replicate this by building out our release infrastructure to allow the rapid testing and release of versions. We need to maintain momentum as the scope of supported features grow.</p> <p>We can achieve this with automated releases that can be manually triggered or deployed on a schedule. Automatic changelog generation would also take a lot of the manual work out of producing releases. Nightly releases would allow users to test experimental features and provide early feedback.</p> </section> </section> <section> <h2 id="questions-and-answers">Questions and Answers <a href="#questions-and-answers" aria-label="questions-and-answers"></a></h2> <section> <h3 id="when-will-physical-rewards-be-shipped">When will physical rewards be shipped? <a href="#when-will-physical-rewards-be-shipped" aria-label="when-will-physical-rewards-be-shipped"></a></h3> <p>We are tentatively aiming for the end of April 2021, however due to COVID delays or order volume this could be extended. We’ll make sure to keep you updated via email.</p> </section> <section> <h3 id="what-is-my-email-used-for">What is my email used for? <a href="#what-is-my-email-used-for" aria-label="what-is-my-email-used-for"></a></h3> <p>We use your email address to send information about your order such as order questions, shipping status and delays. We may also send a survey to decide on customization options for rewards.</p> <p>Your email address will not be used for any other purpose or be displayed publicly.</p> </section> <section> <h3 id="how-is-payment-information-stored">How is payment information stored? <a href="#how-is-payment-information-stored" aria-label="how-is-payment-information-stored"></a></h3> <p>Payment information is entered and stored via Stripe. We do not have access to full payment details. Your billing address is used if we need to calculate and pay sales tax in your jurisdiction.</p> </section> <section> <h3 id="what-do-tier-prices-include">What do tier prices include? <a href="#what-do-tier-prices-include" aria-label="what-do-tier-prices-include"></a></h3> <p>Prices include processing fees, international shipping, and sales tax. This does mean the effective donation is reduced if you live in a country with import duty or high shipping cost.</p> <p>You have the option to add an additional donation in the order review screen if you would like to cover those costs.</p> </section> <section> <h3 id="why-do-you-need-my-usernames">Why do you need my usernames? <a href="#why-do-you-need-my-usernames" aria-label="why-do-you-need-my-usernames"></a></h3> <p>Usernames are used to allocate tier rewards. They are not required and you can …</p></section></section></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://rome.tools/funding/">https://rome.tools/funding/</a></em></p>]]>
            </description>
            <link>https://rome.tools/funding/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25342500</guid>
            <pubDate>Tue, 08 Dec 2020 06:28:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Evolution of my role as a founder CTO]]>
            </title>
            <description>
<![CDATA[
Score 95 | Comments 13 (<a href="https://news.ycombinator.com/item?id=25342265">thread link</a>) | @kwindla
<br/>
December 7, 2020 | https://miguelcarranza.es/cto | <a href="https://web.archive.org/web/*/https://miguelcarranza.es/cto">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
  
  <p>There is a lot written about the importance of scaling as a founder in a fast-growing startup. Most of it focused on the CEO role. The generic advice on leadership also applies to other non-CEO roles, but I could not find a lot of content targeted to technical founders. In fact, after reading a <a href="https://twitter.com/elwatto/status/1230977002192031744?s=20" target="_blank">bunch of S-1 forms</a>, <strong>it was hard to find first-time CTOs going all the way from MVP to IPO</strong> (as opposed to founding CEOs). I found this fact really intriguing, and I wanted to dig deeper to try to understand the reasons. It was also stressing me out to some degree: <em>what if I don’t manage to scale fast enough? What does scaling even mean? I’d rather prepare before it becomes a real problem! I want to be the CTO who makes <a href="https://revenuecat.com/" target="_blank">RevenueCat</a> a public company!</em><sup>1</sup></p>

<p>Is it really much harder for non-CEO founders to scale quickly? Or perhaps it is that CEOs have a stronger support network. These could be the reasons. Or maybe I was asking the wrong question. After talking to a lot of founder CTOs, there was something clear: <strong>there is no standard definition for the CTO role</strong>, responsibilities will totally change <strong>depending on the company and the stage</strong>. At inception, the CTO is probably a glorified individual contributor, but this can escalate very quickly. Everyone’s experiences are different. Unfortunately, I don’t have the answers for other non-CEO founder roles, and maybe I don’t even have it for first-time CTOs either. However, I thought it would be a good self-awareness exercise to reflect on the things I’ve learned and how my responsibilities have changed during the first 3 years at <a href="https://revenuecat.com/" target="_blank">RevenueCat</a>.</p>

<h3 id="the-cto-vs-vp-of-engineering-dilemma">The CTO vs VP of Engineering dilemma</h3>
<p>Simplifying, we could say that the CTO role is closer to architecture and code; whereas the VPE would be in charge of processes and management. A simple analogy could be the Senior/Staff Engineer path versus the Engineering Management career path.</p>

<p>During the early days, you need a CTO to architect and coordinate a small group of ICs hacking the minimum viable product. At this stage, being a founder is extremely helpful to set the vision of the product and the engineering culture. Ideally, the CTO is a domain expert in the problem that the startup is trying to solve.</p>

<p>But what if the product becomes successful? What if you reach product-market fit? You will need to hire a lot more engineers to satisfy customer demands. That’s a great problem to have. You might get lucky and get funding, or you might even be profitable already. But a higher headcount means more polished processes. At some point, somebody will inevitably need to start wearing the VP of Engineering hat. It will happen, and it will become quite obvious as the previous (or lack of) processes start to break. You have a couple of options at this stage. The CTO can start acting as VPE, or you can hire externally. It is probably a matter of personal preference or previous management experience. But <strong>it is a totally different set of skills</strong>, which might be difficult to acquire in a hyper-growth environment. Therefore, most commonly, the VP of Engineering is <a href="https://www.saastr.com/makes-bad-cto/" target="_blank">hired externally</a>.</p>

<p>If you are a founder you have some flexibility. You might have control to decide which way you want to go. Perhaps you hate people management and want to keep using your technical skills and problem knowledge to influence the technology directly. Or maybe you want to improve your management skills. Early employees tend to be more forgiving about founder managerial flaws. They joined because they trusted the founders, believed in the vision, and know they have good intentions. In the beginning, they might even prefer you as a direct manager than an external person. But eventually, there will be several layers of management, so you better learn fast if you want to follow this path and don’t have the experience.</p>

<p>Bryan Helmig, Zapier’s co-founder and CTO, says you need to <a href="https://zapier.com/engineering/startup-cto/" target="_blank"><em>figure out where you get your dopamine hits</em></a>. Personally, I have always been more of a <em>computer person</em> than a <em>people person</em>. 
I was not sure which path I should take, but I would have bet on the one involving computers. I’ve always loved them, and I would say I am a better, more experienced engineer than I am a manager. I feel  more energized after shipping a new feature than during a one-on-one meeting.</p>

<p>However, as a founder, <strong>I get the dopamine hits when the company is doing well</strong>. When a customer recommends our product. When we hit the revenue goal. When we hire engineers that are better than me. When these engineers are happy and successfully shipping ambitious features. When code review is exhaustive but collaborative, not adversarial.</p>

<p>So, ultimately, I’ve taken the approach to not simply follow my personal preference, but to <strong>do whatever is more impactful for the company at each stage</strong>. I am a problem solver after all. That is how I have been thinking about my role. My <strong>founder identity should be more important than my CTO title</strong>. In the long run, as a major shareholder, I need to do whatever is best for the company.</p>

<p>Typically breaking points start happening <strong>somewhere between 8 and 12 engineers</strong>. But it can be different depending on the product and the environment. In our case, as a fully distributed company, we encountered several breaking points as we were adding new time zones. During this <em>no man’s land stage</em> most technical founders are temporarily forced to wear both CTO and VPE hats simultaneously. Being flexible turned out to be very advantageous. I tried to step up and (poorly and temporarily) do work that nobody had the bandwidth to do. This helped me to identify the pain points and tweak the process or hire somebody to take over these tasks.</p>

<figure>
  <img src="https://miguelcarranza.es/assets/posts/notebooks.jpeg" alt="RevenueCat journals">
</figure>

<p>One thing that helped me a lot to navigate my role was to learn how other founders were spending their time at each stage. I have been journaling since we started the company. Based on these notes, I will briefly describe the tasks I’ve been focused on and how my role has evolved.</p>

<table>
  <thead>
    <tr>
      <th>Metrics (EOY)</th>
      <th>2018</th>
      <th>2019</th>
      <th>2020</th>
      <th>2021</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Product Engineers</td>
      <td>2</td>
      <td>4</td>
      <td>8</td>
      <td>~18</td>
    </tr>
    <tr>
      <td>Total team size</td>
      <td>5</td>
      <td>9</td>
      <td>19</td>
      <td>~45</td>
    </tr>
    <tr>
      <td>Number of cities</td>
      <td>1</td>
      <td>5</td>
      <td>14</td>
      <td>??</td>
    </tr>
    <tr>
      <td>Number of time zones</td>
      <td>1</td>
      <td>3</td>
      <td>6</td>
      <td>??</td>
    </tr>
  </tbody>
</table>

<h2 id="2018-yc-mvp-and-first-hires">2018: YC, MVP, and first hires</h2>
<p>When we did Y-Combinator it was only <a href="https://twitter.com/jeiting" target="_blank">Jacob</a> and me. Jacob would write SDK and frontend code and I would focus on the backend and infrastructure. After YC we hired our first two engineers to take over Jacob’s coding responsibilities full time. We were all based in San Francisco and these hires were people we already knew. Easy (almost inexistent) management. <strong>There was no process overhead</strong>, we had one-week sprints and <strong>we were moving really fast</strong>.</p>

<p>These days were stressful but fun. We were setting the foundations of the engineering culture and seeing customers signing up one by one. Most of my time was spent architecting the initial version of features, listening to customers, and building their requests as fast as we humanly could. <strong>We would ship most requests on the same day</strong>.</p>

<p>My biggest concern here was making sure we were building something people wanted and the ability to keep growing to justify our <a href="https://techcrunch.com/2018/10/24/revenuecat-seed-funding/" target="_blank">$1.5M seed round</a>.</p>

<p><strong>Main learnings</strong>: Too many, impossible to summarize. We learned a lot while doing Y-Combinator. The main thing would be that talking to customers, building what they want, and making them happy was paramount. We even made this and shipping fast two of our <a href="https://www.revenuecat.com/blog/values" target="_blank">core values</a>.</p>

<h2 id="2019-keeping-up-with-customers-and-scaling-the-tech">2019: Keeping up with customers and scaling the tech</h2>
<p>It looks like we had achieved some kind of product-market fit. <strong>Customers were coming to us, support tickets started piling up and our API throughput would increase every day</strong>. We added our first remote engineer, located in Taiwan. The time zone difference was hard initially and we needed to adapt processes. But it all worked out fine. We got better coverage for customer requests and monitoring.</p>

<p><strong>Onboarding was a complete, one-off manual process</strong>. I started doing one-on-ones (not very regularly, maybe once a month), but <strong>management was still pretty light</strong>. Most conversations were still very technical. I was still an individual contributor. I was also on booth duty at a couple of conferences.</p>

<figure>
  <img src="https://miguelcarranza.es/assets/posts/boothduty.JPG" alt="Booth Duty, AltConf 2019">
</figure>

<p>My main concern at this stage was purely technical: <strong>the scalability of our systems</strong>. All of our engineers had a more product-oriented background, and we had some clear single points of failure. Not going down was constantly in my mind. The scale was outgrowing my comfort zone every single day. We did a decent job optimizing the most common scenarios, <a href="https://www.revenuecat.com/blog/aurora-migration-zero-downtime" target="_blank">migrating infrastructure before reaching breaking points</a>, and <strong>paying down the technical debt we took the year before</strong>.</p>

<p>Up until Q4, I was the de-facto on-call engineer. I did not want to disturb other team members outside working hours, and I felt reliability was my ultimate responsibility as a technical founder. I would carry my laptop literally everywhere. Eventually, <strong>we implemented an on-call rotation, and in retrospect, we should have done it earlier</strong>.</p>

<p><strong>Main learnings</strong>: Do not stress over scalability, but monitor as much as possible and always look out for the next bottleneck and single point of failure. Again, these are stressful but great problems to have. Establish an on-call policy as soon as possible, train engineers, and document resolution for known incidents. Rely on your team. <a href="https://miguelcarranza.es/technical-debt" target="_blank">Technical debt is actually good</a> if taken responsibly while trying to find product-market fit.</p>

<h2 id="2020-delegation-and-planning-the-future-organization">2020: Delegation and planning the future organization</h2>
<p>In 2020 we doubled the team again. We added engineers in Europe and Latin America. By the end of the year, we had multiple members in every team (SDK, frontend, backend…). We were able to work on several projects at the same time, and finally tackle more ambitious features. But we needed more coordination. <strong>A little bit of management structure was unavoidable at this stage.</strong></p>

<p>During Q1 and Q2 I spent most of my time reviewing code, providing architectural guidance, and coding a little bit on the side. I was still the person who had more context about our systems. By mid-year, it became very obvious that I was the bottleneck for …</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://miguelcarranza.es/cto">https://miguelcarranza.es/cto</a></em></p>]]>
            </description>
            <link>https://miguelcarranza.es/cto</link>
            <guid isPermaLink="false">hacker-news-small-sites-25342265</guid>
            <pubDate>Tue, 08 Dec 2020 05:35:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Cemetery of Soviet Computers]]>
            </title>
            <description>
<![CDATA[
Score 134 | Comments 15 (<a href="https://news.ycombinator.com/item?id=25340452">thread link</a>) | @detaro
<br/>
December 7, 2020 | https://rusue.com/cemetery-of-soviet-computers/ | <a href="https://web.archive.org/web/*/https://rusue.com/cemetery-of-soviet-computers/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody"><p>The building did not stand out. Unremarkable industrial building, which was built in hundreds of Soviet cities.<span id="more-10215"></span></p>
<p>Non-broken glass, burning lights, live plants inside, modern plastic entrance doors. Except for one floor.</p>
<!-- WP QUADS Content Ad Plugin v. 2.0.17.1 -->


<p>Despite the twilight, the floor remained lifelessly dark. Somewhere in the depths, there was a dim glow of electric light, hardly penetrating through old glass blocks.</p>
<p>Inside the floor was empty and black, but not completely.&nbsp;Inside burned several fluorescent lamps, spotlighting dozens of silhouettes of tall cabinets.</p>
<p>Some of them were covered with darkened translucent film.</p>
<p>The surface of the floor, tables and enclosures covered with black spots of soot, sometimes diluted with white stains of dried extinguishing mixture.</p>
<p>The air felt a persistent, but not strong smell of burning.&nbsp;The fire walked here a few years ago but did not touch the equipment.</p>
<p>Part of the cabinets were antique electronic computers. Others served to measure signals, and computers controlled this process. Dozens of terminals froze on the tables with extinct screens.</p>

<p><a href="https://i0.wp.com/rusue.com/wp-content/uploads/2019/01/2.jpg?ssl=1"><img loading="lazy" src="https://i0.wp.com/rusue.com/wp-content/uploads/2019/01/2.jpg?resize=1050%2C788&amp;ssl=1" alt="" width="1050" height="788" srcset="https://i0.wp.com/rusue.com/wp-content/uploads/2019/01/2.jpg?w=1050&amp;ssl=1 1050w, https://i0.wp.com/rusue.com/wp-content/uploads/2019/01/2.jpg?resize=300%2C225&amp;ssl=1 300w, https://i0.wp.com/rusue.com/wp-content/uploads/2019/01/2.jpg?resize=768%2C576&amp;ssl=1 768w, https://i0.wp.com/rusue.com/wp-content/uploads/2019/01/2.jpg?resize=1024%2C768&amp;ssl=1 1024w, https://i0.wp.com/rusue.com/wp-content/uploads/2019/01/2.jpg?resize=200%2C150&amp;ssl=1 200w, https://i0.wp.com/rusue.com/wp-content/uploads/2019/01/2.jpg?resize=360%2C270&amp;ssl=1 360w, https://i0.wp.com/rusue.com/wp-content/uploads/2019/01/2.jpg?resize=545%2C409&amp;ssl=1 545w" sizes="(max-width: 1050px) 100vw, 1050px" data-recalc-dims="1"></a></p>
<p><a href="https://i0.wp.com/rusue.com/wp-content/uploads/2019/01/3.jpg?ssl=1"><img loading="lazy" src="https://i0.wp.com/rusue.com/wp-content/uploads/2019/01/3.jpg?resize=1050%2C1438&amp;ssl=1" alt="" width="1050" height="1438" srcset="https://i0.wp.com/rusue.com/wp-content/uploads/2019/01/3.jpg?w=1050&amp;ssl=1 1050w, https://i0.wp.com/rusue.com/wp-content/uploads/2019/01/3.jpg?resize=219%2C300&amp;ssl=1 219w, https://i0.wp.com/rusue.com/wp-content/uploads/2019/01/3.jpg?resize=768%2C1052&amp;ssl=1 768w, https://i0.wp.com/rusue.com/wp-content/uploads/2019/01/3.jpg?resize=748%2C1024&amp;ssl=1 748w, https://i0.wp.com/rusue.com/wp-content/uploads/2019/01/3.jpg?resize=360%2C493&amp;ssl=1 360w, https://i0.wp.com/rusue.com/wp-content/uploads/2019/01/3.jpg?resize=545%2C746&amp;ssl=1 545w" sizes="(max-width: 1050px) 100vw, 1050px" data-recalc-dims="1"></a></p>
<p><a href="https://i0.wp.com/rusue.com/wp-content/uploads/2019/01/121.jpg?ssl=1"><img loading="lazy" src="https://i0.wp.com/rusue.com/wp-content/uploads/2019/01/121.jpg?resize=1050%2C788&amp;ssl=1" alt="" width="1050" height="788" srcset="https://i0.wp.com/rusue.com/wp-content/uploads/2019/01/121.jpg?w=1050&amp;ssl=1 1050w, https://i0.wp.com/rusue.com/wp-content/uploads/2019/01/121.jpg?resize=300%2C225&amp;ssl=1 300w, https://i0.wp.com/rusue.com/wp-content/uploads/2019/01/121.jpg?resize=768%2C576&amp;ssl=1 768w, https://i0.wp.com/rusue.com/wp-content/uploads/2019/01/121.jpg?resize=1024%2C768&amp;ssl=1 1024w, https://i0.wp.com/rusue.com/wp-content/uploads/2019/01/121.jpg?resize=200%2C150&amp;ssl=1 200w, https://i0.wp.com/rusue.com/wp-content/uploads/2019/01/121.jpg?resize=360%2C270&amp;ssl=1 360w, https://i0.wp.com/rusue.com/wp-content/uploads/2019/01/121.jpg?resize=545%2C409&amp;ssl=1 545w" sizes="(max-width: 1050px) 100vw, 1050px" data-recalc-dims="1"></a></p>
<p>Suddenly it became clear that before them the legendary machine “Saratov-2”.&nbsp;The machine, which was massively placed on many enterprises of the Soviet Union in the 70s, but at the same time, not a single high-quality (I’m not talking about color) photos remained. Not on the Internet, not even in the museum of the enterprise developer.</p>
<p><a href="https://i0.wp.com/rusue.com/wp-content/uploads/2019/01/4-1.jpg?ssl=1"><img loading="lazy" src="https://i0.wp.com/rusue.com/wp-content/uploads/2019/01/4-1.jpg?resize=1050%2C1400&amp;ssl=1" alt="" width="1050" height="1400" srcset="https://i0.wp.com/rusue.com/wp-content/uploads/2019/01/4-1.jpg?w=1050&amp;ssl=1 1050w, https://i0.wp.com/rusue.com/wp-content/uploads/2019/01/4-1.jpg?resize=225%2C300&amp;ssl=1 225w, https://i0.wp.com/rusue.com/wp-content/uploads/2019/01/4-1.jpg?resize=768%2C1024&amp;ssl=1 768w, https://i0.wp.com/rusue.com/wp-content/uploads/2019/01/4-1.jpg?resize=360%2C480&amp;ssl=1 360w, https://i0.wp.com/rusue.com/wp-content/uploads/2019/01/4-1.jpg?resize=545%2C727&amp;ssl=1 545w" sizes="(max-width: 1050px) 100vw, 1050px" data-recalc-dims="1"></a></p>
<p><a href="https://i0.wp.com/rusue.com/wp-content/uploads/2019/01/5.jpg?ssl=1"><img loading="lazy" src="https://i0.wp.com/rusue.com/wp-content/uploads/2019/01/5.jpg?resize=1050%2C1400&amp;ssl=1" alt="" width="1050" height="1400" srcset="https://i0.wp.com/rusue.com/wp-content/uploads/2019/01/5.jpg?w=1050&amp;ssl=1 1050w, https://i0.wp.com/rusue.com/wp-content/uploads/2019/01/5.jpg?resize=225%2C300&amp;ssl=1 225w, https://i0.wp.com/rusue.com/wp-content/uploads/2019/01/5.jpg?resize=768%2C1024&amp;ssl=1 768w, https://i0.wp.com/rusue.com/wp-content/uploads/2019/01/5.jpg?resize=360%2C480&amp;ssl=1 360w, https://i0.wp.com/rusue.com/wp-content/uploads/2019/01/5.jpg?resize=545%2C727&amp;ssl=1 545w" sizes="(max-width: 1050px) 100vw, 1050px" data-recalc-dims="1"></a></p>
<p>This computer did not even have a traditional microprocessor. Domestic clone of the popular American PDP-8, Saratov-2 was produced in two versions.</p>
<p>Steel frame, like a chest of drawers, filled with drawers.&nbsp;Different boxes responded to various computer nodes — a twelve-bit computing unit, input-output device interfaces, and RAM.</p>
<p>The memory was ferromagnetic – two boxes of four cubes in each. Reading or writing programs occurred through punched tapes, and to display the results of calculations used electric typewriter CONSUL-260.</p>
<p>The monitor and keyboard in that era were not yet a much-needed</p>
<p>part of the computer. The necessary input of programs into the operative memory was carried out in binary codes, manually using a group of switches on the front panel. Bulbs controlled the correctness of the input.</p>
<p><a href="https://i0.wp.com/rusue.com/wp-content/uploads/2019/01/6.jpg?ssl=1"><img loading="lazy" src="https://i0.wp.com/rusue.com/wp-content/uploads/2019/01/6.jpg?resize=1050%2C788&amp;ssl=1" alt="" width="1050" height="788" srcset="https://i0.wp.com/rusue.com/wp-content/uploads/2019/01/6.jpg?w=1050&amp;ssl=1 1050w, https://i0.wp.com/rusue.com/wp-content/uploads/2019/01/6.jpg?resize=300%2C225&amp;ssl=1 300w, https://i0.wp.com/rusue.com/wp-content/uploads/2019/01/6.jpg?resize=768%2C576&amp;ssl=1 768w, https://i0.wp.com/rusue.com/wp-content/uploads/2019/01/6.jpg?resize=1024%2C768&amp;ssl=1 1024w, https://i0.wp.com/rusue.com/wp-content/uploads/2019/01/6.jpg?resize=200%2C150&amp;ssl=1 200w, https://i0.wp.com/rusue.com/wp-content/uploads/2019/01/6.jpg?resize=360%2C270&amp;ssl=1 360w, https://i0.wp.com/rusue.com/wp-content/uploads/2019/01/6.jpg?resize=545%2C409&amp;ssl=1 545w" sizes="(max-width: 1050px) 100vw, 1050px" data-recalc-dims="1"></a></p>
<p><a href="https://i0.wp.com/rusue.com/wp-content/uploads/2019/01/7.jpg?ssl=1"><img loading="lazy" src="https://i0.wp.com/rusue.com/wp-content/uploads/2019/01/7.jpg?resize=1050%2C773&amp;ssl=1" alt="" width="1050" height="773" srcset="https://i0.wp.com/rusue.com/wp-content/uploads/2019/01/7.jpg?w=1050&amp;ssl=1 1050w, https://i0.wp.com/rusue.com/wp-content/uploads/2019/01/7.jpg?resize=300%2C221&amp;ssl=1 300w, https://i0.wp.com/rusue.com/wp-content/uploads/2019/01/7.jpg?resize=768%2C565&amp;ssl=1 768w, https://i0.wp.com/rusue.com/wp-content/uploads/2019/01/7.jpg?resize=1024%2C754&amp;ssl=1 1024w, https://i0.wp.com/rusue.com/wp-content/uploads/2019/01/7.jpg?resize=360%2C265&amp;ssl=1 360w, https://i0.wp.com/rusue.com/wp-content/uploads/2019/01/7.jpg?resize=545%2C401&amp;ssl=1 545w" sizes="(max-width: 1050px) 100vw, 1050px" data-recalc-dims="1"></a></p>
<p><a href="https://i0.wp.com/rusue.com/wp-content/uploads/2019/01/8.jpg?ssl=1"><img loading="lazy" src="https://i0.wp.com/rusue.com/wp-content/uploads/2019/01/8.jpg?resize=1050%2C774&amp;ssl=1" alt="" width="1050" height="774" srcset="https://i0.wp.com/rusue.com/wp-content/uploads/2019/01/8.jpg?w=1050&amp;ssl=1 1050w, https://i0.wp.com/rusue.com/wp-content/uploads/2019/01/8.jpg?resize=300%2C221&amp;ssl=1 300w, https://i0.wp.com/rusue.com/wp-content/uploads/2019/01/8.jpg?resize=768%2C566&amp;ssl=1 768w, https://i0.wp.com/rusue.com/wp-content/uploads/2019/01/8.jpg?resize=1024%2C755&amp;ssl=1 1024w, https://i0.wp.com/rusue.com/wp-content/uploads/2019/01/8.jpg?resize=360%2C265&amp;ssl=1 360w, https://i0.wp.com/rusue.com/wp-content/uploads/2019/01/8.jpg?resize=545%2C402&amp;ssl=1 545w" sizes="(max-width: 1050px) 100vw, 1050px" data-recalc-dims="1"></a></p>
<p><a href="https://i2.wp.com/rusue.com/wp-content/uploads/2019/01/9.jpg?ssl=1"><img loading="lazy" src="https://i2.wp.com/rusue.com/wp-content/uploads/2019/01/9.jpg?resize=1050%2C1088&amp;ssl=1" alt="" width="1050" height="1088" srcset="https://i2.wp.com/rusue.com/wp-content/uploads/2019/01/9.jpg?w=1050&amp;ssl=1 1050w, https://i2.wp.com/rusue.com/wp-content/uploads/2019/01/9.jpg?resize=290%2C300&amp;ssl=1 290w, https://i2.wp.com/rusue.com/wp-content/uploads/2019/01/9.jpg?resize=768%2C796&amp;ssl=1 768w, https://i2.wp.com/rusue.com/wp-content/uploads/2019/01/9.jpg?resize=988%2C1024&amp;ssl=1 988w, https://i2.wp.com/rusue.com/wp-content/uploads/2019/01/9.jpg?resize=360%2C373&amp;ssl=1 360w, https://i2.wp.com/rusue.com/wp-content/uploads/2019/01/9.jpg?resize=545%2C565&amp;ssl=1 545w" sizes="(max-width: 1050px) 100vw, 1050px" data-recalc-dims="1"></a></p>
<p><a href="https://i0.wp.com/rusue.com/wp-content/uploads/2019/01/10.jpg?ssl=1"><img loading="lazy" src="https://i0.wp.com/rusue.com/wp-content/uploads/2019/01/10.jpg?resize=1050%2C828&amp;ssl=1" alt="" width="1050" height="828" srcset="https://i0.wp.com/rusue.com/wp-content/uploads/2019/01/10.jpg?w=1050&amp;ssl=1 1050w, https://i0.wp.com/rusue.com/wp-content/uploads/2019/01/10.jpg?resize=300%2C237&amp;ssl=1 300w, https://i0.wp.com/rusue.com/wp-content/uploads/2019/01/10.jpg?resize=768%2C606&amp;ssl=1 768w, https://i0.wp.com/rusue.com/wp-content/uploads/2019/01/10.jpg?resize=1024%2C807&amp;ssl=1 1024w, https://i0.wp.com/rusue.com/wp-content/uploads/2019/01/10.jpg?resize=360%2C284&amp;ssl=1 360w, https://i0.wp.com/rusue.com/wp-content/uploads/2019/01/10.jpg?resize=545%2C430&amp;ssl=1 545w" sizes="(max-width: 1050px) 100vw, 1050px" data-recalc-dims="1"></a></p>
<p><a href="https://i0.wp.com/rusue.com/wp-content/uploads/2019/01/121-1.jpg?ssl=1"><img loading="lazy" src="https://i0.wp.com/rusue.com/wp-content/uploads/2019/01/121-1.jpg?resize=1050%2C788&amp;ssl=1" alt="" width="1050" height="788" srcset="https://i0.wp.com/rusue.com/wp-content/uploads/2019/01/121-1.jpg?w=1050&amp;ssl=1 1050w, https://i0.wp.com/rusue.com/wp-content/uploads/2019/01/121-1.jpg?resize=300%2C225&amp;ssl=1 300w, https://i0.wp.com/rusue.com/wp-content/uploads/2019/01/121-1.jpg?resize=768%2C576&amp;ssl=1 768w, https://i0.wp.com/rusue.com/wp-content/uploads/2019/01/121-1.jpg?resize=1024%2C768&amp;ssl=1 1024w, https://i0.wp.com/rusue.com/wp-content/uploads/2019/01/121-1.jpg?resize=200%2C150&amp;ssl=1 200w, https://i0.wp.com/rusue.com/wp-content/uploads/2019/01/121-1.jpg?resize=360%2C270&amp;ssl=1 360w, https://i0.wp.com/rusue.com/wp-content/uploads/2019/01/121-1.jpg?resize=545%2C409&amp;ssl=1 545w" sizes="(max-width: 1050px) 100vw, 1050px" data-recalc-dims="1"></a></p>
<p>The next generation of computers was Electronics 100/25. These machines were clones of American PDP-11.</p>
<p>They thought faster, had more memory, allowed them to work with magnetic tape drives and punched tapes, but the general principle remained the same.</p>
<p>It was possible to connect a monitor and a keyboard to this computer, while still having the ability to enter programs through the front switches.</p>
<p><a href="https://i0.wp.com/rusue.com/wp-content/uploads/2019/01/11.jpg?ssl=1"><img loading="lazy" src="https://i0.wp.com/rusue.com/wp-content/uploads/2019/01/11.jpg?resize=1050%2C778&amp;ssl=1" alt="" width="1050" height="778" srcset="https://i0.wp.com/rusue.com/wp-content/uploads/2019/01/11.jpg?w=1050&amp;ssl=1 1050w, https://i0.wp.com/rusue.com/wp-content/uploads/2019/01/11.jpg?resize=300%2C222&amp;ssl=1 300w, https://i0.wp.com/rusue.com/wp-content/uploads/2019/01/11.jpg?resize=768%2C569&amp;ssl=1 768w, https://i0.wp.com/rusue.com/wp-content/uploads/2019/01/11.jpg?resize=1024%2C759&amp;ssl=1 1024w, https://i0.wp.com/rusue.com/wp-content/uploads/2019/01/11.jpg?resize=360%2C267&amp;ssl=1 360w, https://i0.wp.com/rusue.com/wp-content/uploads/2019/01/11.jpg?resize=545%2C404&amp;ssl=1 545w" sizes="(max-width: 1050px) 100vw, 1050px" data-recalc-dims="1"></a></p>
<p><a href="https://i1.wp.com/rusue.com/wp-content/uploads/2019/01/12.jpg?ssl=1"><img loading="lazy" src="https://i1.wp.com/rusue.com/wp-content/uploads/2019/01/12.jpg?resize=1050%2C788&amp;ssl=1" alt="" width="1050" height="788" srcset="https://i1.wp.com/rusue.com/wp-content/uploads/2019/01/12.jpg?w=1050&amp;ssl=1 1050w, https://i1.wp.com/rusue.com/wp-content/uploads/2019/01/12.jpg?resize=300%2C225&amp;ssl=1 300w, https://i1.wp.com/rusue.com/wp-content/uploads/2019/01/12.jpg?resize=768%2C576&amp;ssl=1 768w, https://i1.wp.com/rusue.com/wp-content/uploads/2019/01/12.jpg?resize=1024%2C768&amp;ssl=1 1024w, https://i1.wp.com/rusue.com/wp-content/uploads/2019/01/12.jpg?resize=200%2C150&amp;ssl=1 200w, https://i1.wp.com/rusue.com/wp-content/uploads/2019/01/12.jpg?resize=360%2C270&amp;ssl=1 360w, https://i1.wp.com/rusue.com/wp-content/uploads/2019/01/12.jpg?resize=545%2C409&amp;ssl=1 545w" sizes="(max-width: 1050px) 100vw, 1050px" data-recalc-dims="1"></a></p>
<!-- WP QUADS Content Ad Plugin v. 2.0.17.1 -->


<p><a href="https://i0.wp.com/rusue.com/wp-content/uploads/2019/01/13.jpg?ssl=1"><img loading="lazy" src="https://i0.wp.com/rusue.com/wp-content/uploads/2019/01/13.jpg?resize=1050%2C801&amp;ssl=1" alt="" width="1050" height="801" srcset="https://i0.wp.com/rusue.com/wp-content/uploads/2019/01/13.jpg?w=1050&amp;ssl=1 1050w, https://i0.wp.com/rusue.com/wp-content/uploads/2019/01/13.jpg?resize=300%2C229&amp;ssl=1 300w, https://i0.wp.com/rusue.com/wp-content/uploads/2019/01/13.jpg?resize=768%2C586&amp;ssl=1 768w, https://i0.wp.com/rusue.com/wp-content/uploads/2019/01/13.jpg?resize=1024%2C781&amp;ssl=1 1024w, https://i0.wp.com/rusue.com/wp-content/uploads/2019/01/13.jpg?resize=360%2C275&amp;ssl=1 360w, https://i0.wp.com/rusue.com/wp-content/uploads/2019/01/13.jpg?resize=545%2C416&amp;ssl=1 545w" sizes="(max-width: 1050px) 100vw, 1050px" data-recalc-dims="1"></a></p>
<p>Electronics-60 – the further development of Electronics 100/25. The same architecture, but bulky tape drives are a thing of the past.</p>
<p>They were replaced by flexible eight-inch floppy disks. The new chipset, allowed to fit the processor module, power supply and control devices, in a very compact size.</p>
<p>I note that all these computers were managers, that is, they worked with a bunch of external equipment. It could be machine tools, laboratory complexes, measuring devices.</p>
<p><a href="https://i2.wp.com/rusue.com/wp-content/uploads/2019/01/16.jpg?ssl=1"><img loading="lazy" src="https://i2.wp.com/rusue.com/wp-content/uploads/2019/01/16.jpg?resize=1050%2C779&amp;ssl=1" alt="" width="1050" height="779" srcset="https://i2.wp.com/rusue.com/wp-content/uploads/2019/01/16.jpg?w=1050&amp;ssl=1 1050w, https://i2.wp.com/rusue.com/wp-content/uploads/2019/01/16.jpg?resize=300%2C223&amp;ssl=1 300w, https://i2.wp.com/rusue.com/wp-content/uploads/2019/01/16.jpg?resize=768%2C570&amp;ssl=1 768w, https://i2.wp.com/rusue.com/wp-content/uploads/2019/01/16.jpg?resize=1024%2C760&amp;ssl=1 1024w, https://i2.wp.com/rusue.com/wp-content/uploads/2019/01/16.jpg?resize=360%2C267&amp;ssl=1 360w, https://i2.wp.com/rusue.com/wp-content/uploads/2019/01/16.jpg?resize=545%2C404&amp;ssl=1 545w" sizes="(max-width: 1050px) 100vw, 1050px" data-recalc-dims="1"></a> <a href="https://i0.wp.com/rusue.com/wp-content/uploads/2019/01/17.jpg?ssl=1"><img loading="lazy" src="https://i0.wp.com/rusue.com/wp-content/uploads/2019/01/17.jpg?resize=1050%2C1385&amp;ssl=1" alt="" width="1050" height="1385" srcset="https://i0.wp.com/rusue.com/wp-content/uploads/2019/01/17.jpg?w=1050&amp;ssl=1 1050w, https://i0.wp.com/rusue.com/wp-content/uploads/2019/01/17.jpg?resize=227%2C300&amp;ssl=1 227w, https://i0.wp.com/rusue.com/wp-content/uploads/2019/01/17.jpg?resize=768%2C1013&amp;ssl=1 768w, https://i0.wp.com/rusue.com/wp-content/uploads/2019/01/17.jpg?resize=776%2C1024&amp;ssl=1 776w, https://i0.wp.com/rusue.com/wp-content/uploads/2019/01/17.jpg?resize=360%2C475&amp;ssl=1 360w, https://i0.wp.com/rusue.com/wp-content/uploads/2019/01/17.jpg?resize=545%2C719&amp;ssl=1 545w" sizes="(max-width: 1050px) 100vw, 1050px" data-recalc-dims="1"></a></p>
<p><a href="https://i1.wp.com/rusue.com/wp-content/uploads/2019/01/18.jpg?ssl=1"><img loading="lazy" src="https://i1.wp.com/rusue.com/wp-content/uploads/2019/01/18.jpg?resize=1050%2C1418&amp;ssl=1" alt="" width="1050" height="1418" srcset="https://i1.wp.com/rusue.com/wp-content/uploads/2019/01/18.jpg?w=1050&amp;ssl=1 1050w, https://i1.wp.com/rusue.com/wp-content/uploads/2019/01/18.jpg?resize=222%2C300&amp;ssl=1 222w, https://i1.wp.com/rusue.com/wp-content/uploads/2019/01/18.jpg?resize=768%2C1037&amp;ssl=1 768w, https://i1.wp.com/rusue.com/wp-content/uploads/2019/01/18.jpg?resize=758%2C1024&amp;ssl=1 758w, https://i1.wp.com/rusue.com/wp-content/uploads/2019/01/18.jpg?resize=360%2C486&amp;ssl=1 360w, https://i1.wp.com/rusue.com/wp-content/uploads/2019/01/18.jpg?resize=545%2C736&amp;ssl=1 545w" sizes="(max-width: 1050px) 100vw, 1050px" data-recalc-dims="1"></a></p>
<p>15VM16-1 some early version of Electronics-60, having a control panel of light bulbs and switches. Assembled on the element base of the previous Electronics 100/25. I occupied a small nightstand built into the table on which the controlled equipment was placed.</p>
<p><a href="https://i1.wp.com/rusue.com/wp-content/uploads/2019/01/19.jpg?ssl=1"><img loading="lazy" src="https://i1.wp.com/rusue.com/wp-content/uploads/2019/01/19.jpg?resize=1050%2C858&amp;ssl=1" alt="" width="1050" height="858" srcset="https://i1.wp.com/rusue.com/wp-content/uploads/2019/01/19.jpg?w=1050&amp;ssl=1 1050w, https://i1.wp.com/rusue.com/wp-content/uploads/2019/01/19.jpg?resize=300%2C245&amp;ssl=1 300w, https://i1.wp.com/rusue.com/wp-content/uploads/2019/01/19.jpg?resize=768%2C628&amp;ssl=1 768w, https://i1.wp.com/rusue.com/wp-content/uploads/2019/01/19.jpg?resize=1024%2C837&amp;ssl=1 1024w, https://i1.wp.com/rusue.com/wp-content/uploads/2019/01/19.jpg?resize=360%2C294&amp;ssl=1 360w, https://i1.wp.com/rusue.com/wp-content/uploads/2019/01/19.jpg?resize=545%2C445&amp;ssl=1 545w" sizes="(max-width: 1050px) 100vw, 1050px" data-recalc-dims="1"></a> <a href="https://i2.wp.com/rusue.com/wp-content/uploads/2019/01/20.jpg?ssl=1"><img loading="lazy" src="https://i2.wp.com/rusue.com/wp-content/uploads/2019/01/20.jpg?resize=1050%2C814&amp;ssl=1" alt="" width="1050" height="814" srcset="https://i2.wp.com/rusue.com/wp-content/uploads/2019/01/20.jpg?w=1050&amp;ssl=1 1050w, https://i2.wp.com/rusue.com/wp-content/uploads/2019/01/20.jpg?resize=300%2C233&amp;ssl=1 300w, https://i2.wp.com/rusue.com/wp-content/uploads/2019/01/20.jpg?resize=768%2C595&amp;ssl=1 768w, https://i2.wp.com/rusue.com/wp-content/uploads/2019/01/20.jpg?resize=1024%2C794&amp;ssl=1 1024w, https://i2.wp.com/rusue.com/wp-content/uploads/2019/01/20.jpg?resize=360%2C279&amp;ssl=1 360w, https://i2.wp.com/rusue.com/wp-content/uploads/2019/01/20.jpg?resize=545%2C423&amp;ssl=1 545w" sizes="(max-width: 1050px) 100vw, 1050px" data-recalc-dims="1"></a></p>
<p>DVK-2M or Interactive Computing Complex. Massive, stylish in appearance, the computer of the 80s, which could be considered a personal computer.</p>
<p>It consisted of two desktop blocks – processor and pairing. A set of interchangeable interface cards allowed connecting drives of various types, a monochrome monitor on an openwork leg, and a keyboard.</p>
<p>Back in 1993, when we were studying, one teaching DVK could distribute programs for a couple of dozen Spectrums through the network.</p>
<p><a href="https://i1.wp.com/rusue.com/wp-content/uploads/2019/01/21.jpg?ssl=1"><img loading="lazy" src="https://i1.wp.com/rusue.com/wp-content/uploads/2019/01/21.jpg?resize=1050%2C788&amp;ssl=1" alt="" width="1050" height="788" srcset="https://i1.wp.com/rusue.com/wp-content/uploads/2019/01/21.jpg?w=1050&amp;ssl=1 1050w, https://i1.wp.com/rusue.com/wp-content/uploads/2019/01/21.jpg?resize=300%2C225&amp;ssl=1 300w, https://i1.wp.com/rusue.com/wp-content/uploads/2019/01/21.jpg?resize=768%2C576&amp;ssl=1 768w, https://i1.wp.com/rusue.com/wp-content/uploads/2019/01/21.jpg?resize=1024%2C768&amp;ssl=1 1024w, https://i1.wp.com/rusue.com/wp-content/uploads/2019/01/21.jpg?resize=200%2C150&amp;ssl=1 200w, https://i1.wp.com/rusue.com/wp-content/uploads/2019/01/21.jpg?resize=360%2C270&amp;ssl=1 360w, https://i1.wp.com/rusue.com/wp-content/uploads/2019/01/21.jpg?resize=545%2C409&amp;ssl=1 545w" sizes="(max-width: 1050px) 100vw, 1050px" data-recalc-dims="1"></a></p>
<p><a href="https://i2.wp.com/rusue.com/wp-content/uploads/2019/01/22.jpg?ssl=1"><img loading="lazy" src="https://i2.wp.com/rusue.com/wp-content/uploads/2019/01/22.jpg?resize=1050%2C788&amp;ssl=1" alt="" width="1050" height="788" srcset="https://i2.wp.com/rusue.com/wp-content/uploads/2019/01/22.jpg?w=1050&amp;ssl=1 1050w, https://i2.wp.com/rusue.com/wp-content/uploads/2019/01/22.jpg?resize=300%2C225&amp;ssl=1 300w, https://i2.wp.com/rusue.com/wp-content/uploads/2019/01/22.jpg?resize=768%2C576&amp;ssl=1 768w, https://i2.wp.com/rusue.com/wp-content/uploads/2019/01/22.jpg?resize=1024%2C768&amp;ssl=1 1024w, https://i2.wp.com/rusue.com/wp-content/uploads/2019/01/22.jpg?resize=200%2C150&amp;ssl=1 200w, https://i2.wp.com/rusue.com/wp-content/uploads/2019/01/22.jpg?resize=360%2C270&amp;ssl=1 360w, https://i2.wp.com/rusue.com/wp-content/uploads/2019/01/22.jpg?resize=545%2C409&amp;ssl=1 545w" sizes="(max-width: 1050px) 100vw, 1050px" data-recalc-dims="1"></a></p>
<p><a href="https://i2.wp.com/rusue.com/wp-content/uploads/2019/01/23.jpg?ssl=1"><img loading="lazy" src="https://i2.wp.com/rusue.com/wp-content/uploads/2019/01/23.jpg?resize=1050%2C788&amp;ssl=1" alt="" width="1050" height="788" srcset="https://i2.wp.com/rusue.com/wp-content/uploads/2019/01/23.jpg?w=1050&amp;ssl=1 1050w, https://i2.wp.com/rusue.com/wp-content/uploads/2019/01/23.jpg?resize=300%2C225&amp;ssl=1 300w, https://i2.wp.com/rusue.com/wp-content/uploads/2019/01/23.jpg?resize=768%2C576&amp;ssl=1 768w, https://i2.wp.com/rusue.com/wp-content/uploads/2019/01/23.jpg?resize=1024%2C768&amp;ssl=1 1024w, https://i2.wp.com/rusue.com/wp-content/uploads/2019/01/23.jpg?resize=200%2C150&amp;ssl=1 200w, https://i2.wp.com/rusue.com/wp-content/uploads/2019/01/23.jpg?resize=360%2C270&amp;ssl=1 360w, https://i2.wp.com/rusue.com/wp-content/uploads/2019/01/23.jpg?resize=545%2C409&amp;ssl=1 545w" sizes="(max-width: 1050px) 100vw, 1050px" data-recalc-dims="1"></a></p>
<p>The DVK-3 in the monoblock plastic case is the next stage of the DVK-2M.</p>
<p><a href="https://i0.wp.com/rusue.com/wp-content/uploads/2019/01/24.jpg?ssl=1"><img loading="lazy" src="https://i0.wp.com/rusue.com/wp-content/uploads/2019/01/24.jpg?resize=1050%2C790&amp;ssl=1" alt="" width="1050" height="790" srcset="https://i0.wp.com/rusue.com/wp-content/uploads/2019/01/24.jpg?w=1050&amp;ssl=1 1050w, https://i0.wp.com/rusue.com/wp-content/uploads/2019/01/24.jpg?resize=300%2C226&amp;ssl=1 300w, https://i0.wp.com/rusue.com/wp-content/uploads/2019/01/24.jpg?resize=768%2C578&amp;ssl=1 768w, https://i0.wp.com/rusue.com/wp-content/uploads/2019/01/24.jpg?resize=1024%2C770&amp;ssl=1 1024w, https://i0.wp.com/rusue.com/wp-content/uploads/2019/01/24.jpg?resize=200%2C150&amp;ssl=1 200w, https://i0.wp.com/rusue.com/wp-content/uploads/2019/01/24.jpg?resize=360%2C270&amp;ssl=1 360w, https://i0.wp.com/rusue.com/wp-content/uploads/2019/01/24.jpg?resize=545%2C410&amp;ssl=1 545w" sizes="(max-width: 1050px) 100vw, 1050px" data-recalc-dims="1"></a></p>
<p><a href="https://i1.wp.com/rusue.com/wp-content/uploads/2019/01/25.jpg?ssl=1"><img loading="lazy" src="https://i1.wp.com/rusue.com/wp-content/uploads/2019/01/25.jpg?resize=1050%2C811&amp;ssl=1" alt="" width="1050" height="811" srcset="https://i1.wp.com/rusue.com/wp-content/uploads/2019/01/25.jpg?w=1050&amp;ssl=1 1050w, https://i1.wp.com/rusue.com/wp-content/uploads/2019/01/25.jpg?resize=300%2C232&amp;ssl=1 300w, https://i1.wp.com/rusue.com/wp-content/uploads/2019/01/25.jpg?resize=768%2C593&amp;ssl=1 768w, https://i1.wp.com/rusue.com/wp-content/uploads/2019/01/25.jpg?resize=1024%2C791&amp;ssl=1 1024w, https://i1.wp.com/rusue.com/wp-content/uploads/2019/01/25.jpg?resize=360%2C278&amp;ssl=1 360w, https://i1.wp.com/rusue.com/wp-content/uploads/2019/01/25.jpg?resize=545%2C421&amp;ssl=1 545w" sizes="(max-width: 1050px) 100vw, 1050px" data-recalc-dims="1"></a> <a href="https://i1.wp.com/rusue.com/wp-content/uploads/2019/01/26.jpg?ssl=1"><img loading="lazy" src="https://i1.wp.com/rusue.com/wp-content/uploads/2019/01/26.jpg?resize=1050%2C740&amp;ssl=1" alt="" width="1050" height="740" srcset="https://i1.wp.com/rusue.com/wp-content/uploads/2019/01/26.jpg?w=1050&amp;ssl=1 1050w, https://i1.wp.com/rusue.com/wp-content/uploads/2019/01/26.jpg?resize=300%2C211&amp;ssl=1 300w, https://i1.wp.com/rusue.com/wp-content/uploads/2019/01/26.jpg?resize=768%2C541&amp;ssl=1 768w, https://i1.wp.com/rusue.com/wp-content/uploads/2019/01/26.jpg?resize=1024%2C722&amp;ssl=1 1024w, https://i1.wp.com/rusue.com/wp-content/uploads/2019/01/26.jpg?resize=360%2C254&amp;ssl=1 360w, https://i1.wp.com/rusue.com/wp-content/uploads/2019/01/26.jpg?resize=545%2C384&amp;ssl=1 545w" sizes="(max-width: 1050px) 100vw, 1050px" data-recalc-dims="1"></a></p>
<p><a href="https://ralphmirebs.livejournal.com/226286.html" target="_blank" rel="noopener noreferrer">Source</a></p>
<div><!--Yasr Visitor Votes Shortcode--><div id="yasr_visitor_votes_10215"><p>Our Reader Score</p><p><span data-postid="10215" id="yasr-total-average-dashicon-10215"></span><span id="yasr-total-average-text-2cf1f4df52237">Total: <span id="yasr-vv-votes-number-container-2cf1f4df52237">83</span>  Average: <span id="yasr-vv-average-container-2cf1f4df52237">4.8</span></span></p></div><!--End Yasr Visitor Votes Shortcode--></div>
<!-- WP QUADS Content Ad Plugin v. 2.0.17.1 -->


</div></div>]]>
            </description>
            <link>https://rusue.com/cemetery-of-soviet-computers/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25340452</guid>
            <pubDate>Tue, 08 Dec 2020 01:29:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Librem 5 Evergreen vs. Pinephone]]>
            </title>
            <description>
<![CDATA[
Score 176 | Comments 117 (<a href="https://news.ycombinator.com/item?id=25338633">thread link</a>) | @ThatGeoGuy
<br/>
December 7, 2020 | https://thatgeoguy.ca/blog/2020/12/06/Librem-5-Evergreen-vs-Pinephone/ | <a href="https://web.archive.org/web/*/https://thatgeoguy.ca/blog/2020/12/06/Librem-5-Evergreen-vs-Pinephone/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="layout">
	 <!-- sidebar -->
	<div>
	
<p>On <em>2020-12-06</em> by <em>ThatGeoGuy</em></p>

<p>Huzzah! I recently received my Librem 5 (Evergreen) from
<a href="https://puri.sm/">Purism</a>. The Librem 5 is a smartphone that runs an otherwise
standard linux kernel. However, unlike Android which also relies on the linux
kernel under the hood, the Librem 5 uses a GNU userspace, adapted for mobile.
This makes it more akin to your typical laptop in some ways, although the form
factor still resembles a modern smartphone (at least, mostly). Here are some
preliminary thoughts about the phone and how it compares to
<a href="https://pine64.org/">Pine64</a>’s Pinephone, which is another phone that uses
neither Android nor iOS, and relies on a GNU / Linux based OS.</p>

<p>This is a bit of a long post, and I’m sorry for that. Brevity is certainly a
hard-earned skill, but going forward without comparing the Librem 5 to the
Pinephone seemed like the wrong choice ;)</p>



<h2 id="purism-librem-5">Purism Librem 5</h2>

<p>Purism touts the Librem 5 as a “Security and Privacy Focused Phone.” This is
not wholly untrue, and there are some features that are unique to the Librem 5
in this respect. For example, there are “kill-switches” on one side of the
phone that allow you to disable:</p>

<ul>
  <li>Mobile network and mobile data</li>
  <li>Wifi &amp; Bluetooth</li>
  <li>Camera &amp; Microphone</li>
</ul>

<p>There’s an additional feature where if you disable all three switches, then
other sensors on the phone such as GPS are all disabled as well. You’d be
better served reading through the <a href="https://puri.sm/products/librem-5">Librem 5 product
page</a> to learn more.</p>

<h2 id="pine64-pinephone">Pine64 Pinephone</h2>

<p>In contrast to the Librem 5, which touts itself as being privacy and security
focused, the <a href="https://www.pine64.org/pinephone/">Pinephone is touted as</a> “An
Open Source Smart Phone Supported by All Major Linux Phone Projects.” It is
considerably different from the Librem 5 in many ways, from the hardware all
the way to the final software. It too has kill-switches, but these are not easy
to access on the side of the phone and instead are inside the case of the
phone. You can access these kill-switches by removing the back plate.</p>

<p>One of the neat things about the Pinephone is the ability to boot and use a
variety of Linux distributions on the hardware itself. It’s as easy as loading
the distro onto an SD card, and then booting the phone. You don’t even have to
flash anything to the internal eMMC in order to run it!</p>

<h2 id="price-">Price $$$</h2>

<h3 id="librem-5">Librem 5</h3>

<p>The Librem 5 starts at $799.00 USD, or can be purchased at $1999.00 USD if you
want your Librem 5 assembled in the good ol’ US of A before they ship it to
you. There’s a lot of talk about anti-interdiction or controlling the supply
chain, but trust me in saying that you’re definitely not in the market for a
$2k phone like the Librem 5. I don’t know anyone who is.</p>

<p>I could probably write an entire post on the economics of this, but quite
frankly, it’s kind of appalling that literally anyone would pay this much. It’s
kind of appalling that Purism would charge this much. I can imagine a scheme
where the parts are shipped from China, and verified and assembled by a
part-time college student in the States and they’d likely still be able to
price it cheaper than $1999.00.</p>

<p>Anyways this post isn’t about Purism’s business practices, of which I will
comment on at some point, but regardless I will drop this matter here. Please
just don’t spend $1999.00 on a Librem 5.</p>

<p>And for that one person who will eventually claim they did purchase the
$1999.00 USA version and it was very necessary for their use case: <em>look buddy,
I get it, you’ve drank the Kool-Aid on this one but I’m sincerely doubtful that
your very specific concerns and use-case apply to even the general nerd who
gets excited about the intersection of FOSS and mobile hardware. Moreover, I’m
doubtful that even if they did apply to such a niche group that $2k is a price
point upon which you still don’t balk at and go look for literally anything
else.</em></p>

<hr>

<p>
<strong>Update (2020-12-08)</strong>:
</p>
<p>
Many wonderful people on Hacker News as well as the
Purism / Librem Matrix channels corrected me on the fact that part of the
reason that the phone is so expensive is due to the fact that the PCB is
fabricated in the States, in addition to the assembly.  I am still inclined to
believe that the price is rather exorbitant. Perhaps had the USA edition been
something that had been launched after Evergreen was completed I would be less
averse to the idea of it. Nonetheless, I still think that for the general
person reading this: you should not purchase it. You might argue that I don't
know your threat vector, but Bayes' theorem would suggest you will be better
served spending your money on a regular Librem 5 and putting the remaining
funds to something more important to you (like maybe an iPhone, so you can use
Signal while it is unavailable on the Librem 5 :-P).
</p>
<hr>

<p>I bought my Librem 5 back during the original crowdfunding campaign, so I ended
up spending a lot less than even the $799 USD. Surprisingly, I’ve been waiting
on this phone since around the end of 2017, and here we are in 2020 and I
finally have it. Purism has been sending out what are effectively <a href="https://en.wikipedia.org/wiki/Engineering_validation_test">DVT and
EVT</a> runs of the
phone that have been going through several phases named Aspen, Birch, Chestnut,
Dogwood, and finally Evergreen. Evergreen is supposed to be the final version
of the hardware, which I opted for. I wanted to get the final, true Librem 5,
not one that could be radically different. While my unit does not have FCC
certification (it is technically what you might consider a PVT unit), it is
representative of the final hardware that Purism will land on for this phone,
as there is ostensibly no more hardware revisions.</p>

<h3 id="pinephone">Pinephone</h3>

<p>The Pinephone starts at $149.99 USD, sold in small batches surrounding a
particular distro / community that is building software for the device (called
<code>&lt;distro-name&gt;</code> Community Edition). Recent batches have made a “convergence
edition” available, for $199.99 USD. The convergence editions have an extra
gigabyte of RAM and a larger eMMC flash storage, and are touted as being useful
for connecting the Pinephone to a full-size monitor and running it as if you
had a full desktop available.</p>

<p>I originally purchased a Pinephone from the UBPorts CE batch. Eventually, I
upgraded my mainboard so that my specs match that of the convergence editions
from later batches. All in all, I’ve managed to spend more than the original
$200, but I’m not disappointed, since I have had a lot of fun with the
Pinephone.</p>



<p>For the vast majority of people, the Librem 5 and Pinephone are probably not
worth even considering. The GNU userspace and associated “mobile” paradigms
within it are very much not ready for daily use.</p>

<p>For the Librem 5, there are some security aspects that this “security and
privacy focused phone” don’t even hit (e.g.  hardware backed security / secure
enclave, device encryption, etc.). That’s not to say that these can’t be made
possible in future updates, but as far as the software story today goes, they
do not yet exist.</p>

<p>
Small note: Hardware-backed features like the secure enclave do not exist on
the base phone today. However, there is a smart card reader and the M.2 slots
used for the SIM And wifi/bluetooth chipsets on board could be replaced as
well. That said, this isn't exactly in "buy an iPhone and guarantee your
physical security" territory, and there's no clear path to "do X steps to
enable this" yet.

Basically, don't be tricked by the marketing to believe this is somehow the
full package at present. It is not.
</p>

<p>Anyways, so why do I, the author, care? I will admit, after my first bout of
usage, neither phone will be a daily driver for me. I will probably continue to
stick to my Pixel 3, and it is very likely that I will eventually get another
Android device at some point in the next two years. Linux phones are definitely
not yet ready to be daily drivers; however, they are interesting for a few key
reasons.</p>

<h2 id="device-longevity">Device longevity</h2>

<p>Digital waste is a blight on our society. I can admit that the year-over-year
hardware cycle provides a vast set of improvements that can change the
smartphone landscape. However, I also acknowledge that the number of phones,
tablets, and other electronics that find their way into landfills or are
otherwise rendered into trash is a growing concern. Linux phones and mobile
hardware present an opportunity to move away from that, and it’s important to
support this in some way.</p>

<h2 id="free-software">Free software</h2>

<p>I’m a fan of free software! While my day job isn’t working on FOSS, I think
that there’s a lot of benefits to having better FOSS software available. The
least of which is because leaps in the mobile space have also attracted others
to work on Linux in the desktop space as well.</p>

<h2 id="a-third-option">A third option</h2>

<p>I care about Linux phones because they present a third option from the Android
/ iOS duopoly. Even if they suck now in (a lot of) ways, they will improve over
time. I want to move towards a future where I don’t have to choose between an
OS that’s built towards data collection and advertising, and another that’s
built on locking you into an ecosystem.</p>



<p>First, before I get into my impressions comparing the two, I should at the very
least mention what I am / am not testing. I did not / will not test:</p>

<ul>
  <li>Phone calls &amp; SMS / MMS functionality
    <ul>
      <li>I do not have a secondary mobile number, and my primary mobile number is
registered to an e-SIM on my Pixel 3. So the best I can do is test how
mobile data works on a data-only SIM.</li>
    </ul>
  </li>
  <li>Convergence features
    <ul>
      <li>I don’t really plan to use these as anything other than a mobile device, so
I haven’t bothered plugging them into a display. Additionally, my display
may be a bit too large and high-resolution for either phone to drive it
effectively.</li>
    </ul>
  </li>
  <li>Email
    <ul>
      <li>This one is still on my TODO list, however I’ve been too lazy to try
setting this up on several of the Pinephone’s possible distros.</li>
    </ul>
  </li>
  <li>Cameras
    <ul>
      <li>The Librem 5 does not yet have a functioning camera. For a phone to ship
with the hardware but no software… Well it’s not typical. So I can’t
compare anything, given that the Librem 5 hasn’t yet made it possible to do
so.</li>
    </ul>
  </li>
  <li>GPS / location
    <ul>
      <li>Look, I want to do this more than …</li></ul></li></ul></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://thatgeoguy.ca/blog/2020/12/06/Librem-5-Evergreen-vs-Pinephone/">https://thatgeoguy.ca/blog/2020/12/06/Librem-5-Evergreen-vs-Pinephone/</a></em></p>]]>
            </description>
            <link>https://thatgeoguy.ca/blog/2020/12/06/Librem-5-Evergreen-vs-Pinephone/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25338633</guid>
            <pubDate>Mon, 07 Dec 2020 22:33:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[German court forces mail provider Tutanota to insert a backdoor]]>
            </title>
            <description>
<![CDATA[
Score 258 | Comments 89 (<a href="https://news.ycombinator.com/item?id=25337507">thread link</a>) | @carlesfe
<br/>
December 7, 2020 | https://www.heise.de/news/Gericht-zwingt-Mailprovider-Tutanota-zu-Ueberwachungsfunktion-4972460.html | <a href="https://web.archive.org/web/*/https://www.heise.de/news/Gericht-zwingt-Mailprovider-Tutanota-zu-Ueberwachungsfunktion-4972460.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

      <p>Tutanota gehÃ¶rt zu den wenigen E-Mail-Anbietern, die standardmÃ¤ÃŸig alle eingehenden Mails verschlÃ¼sseln. Ein Urteil des Landgerichts KÃ¶ln zwingt das hannoversche Unternehmen nun jedoch zum Einbau einer Funktion, mit der Ermittler einzelne PostfÃ¤cher Ã¼berwachen und Mails im Klartext lesen kÃ¶nnen.</p>

<a-paternoster height="360" media="(min-width: 320px) and (max-width: 767px)">
  


  


  <a-ad height="600" instant="" layout="fixed" media="(min-width: 320px) and (max-width: 767px)" preload-distance="200" safeframe="" sizes="300x600,300x50,300x75,300x100,300x150,300x250,320x50,320x75,320x100,320x250" targeting="{&quot;kw&quot;:[&quot;E-Mail&quot;,&quot;E-Mail-Provider&quot;,&quot;Gerichtsurteil&quot;,&quot;LKA&quot;,&quot;Tutanota&quot;,&quot;VerschlÃ¼sselung&quot;,&quot;Ãœberwachung&quot;],&quot;mpos&quot;:[&quot;understitial&quot;,&quot;top&quot;],&quot;themenhub&quot;:&quot;yes&quot;}" type="gpt" unit="/6514/www.heise.de/ct/ct-inhalt" width="300"></a-ad>

</a-paternoster>




<figure>
  <a href="https://www.heise.de/ct/" name="meldung.newsticker.inline.branding_ct" title="Mehr von c't Magazin">
    
  <a-img alt="Mehr von c't Magazin" height="693" high-dpi-quality="100" quality="100" src="/Magazin-Banner/ct_mobil.jpg" width="1200">
  </a-img>

  

    
  <a-img alt="Mehr von c't Magazin" height="500" high-dpi-quality="100" quality="100" src="/Magazin-Banner/ct_desktop.jpg" width="1830">
  </a-img>

  

  </a>
</figure>

<p>Tutanota will Beschwerde gegen den Beschluss einlegen, diese hat jedoch keine aufschiebende Wirkung. â€žWir mussten daher bereits mit der Entwicklung der Ãœberwachungsfunktion beginnenâ€œ, erklÃ¤rte eine Sprecherin Mitte November gegenÃ¼ber câ€™t. Sollte die Beschwerde Erfolg haben, werde man die Funktion nicht aktivieren beziehungsweise wieder entfernen.</p>
<h3 id="nav_abweichende__0">Abweichende Rechtssprechung</h3>
<p>Das KÃ¶lner Urteil ist bemerkenswert, weil es von der Rechtsprechung anderer Gerichte abweicht. So hatte im Sommer <a href="https://www.heise.de/news/Mailanbieter-Tutanota-Staatsanwaltschaft-wollte-Chef-in-Beugehaft-nehmen-4908806.html">das Landgericht Hannover entschieden</a>, dass Tutanota im rechtlichen Sinn keine â€žTelekommunikationsdiensteâ€œ erbringt oder daran mitwirkt â€“ und deshalb auch nicht zur TelekommunikationsÃ¼berwachung verpflichtet werden kann. Die hannoverschen Richter verwiesen wiederum auf ein Grundsatzurteil des EuropÃ¤ischen Gerichtshof (EuGH) von 2019. Diesem zufolge sind E-Mail-Dienste keine Kommunikationsdienste.</p>

  <a-script name="132" needs-consent="" src="https://a.teads.tv/page/87298/tag"></a-script>
  


<p>Das KÃ¶lner Gericht sieht Tutanota dennoch als â€žMitwirkendenâ€œ bei der Erbringung von Telekommunikationsdiensten. Folglich mÃ¼sse das Unternehmen die Ãœberwachung ermÃ¶glichen. Das Urteil, das câ€™t vorliegt, nennt allerdings weder den Namen noch den Betreiber des Telekommunikationsdienstes, an dem Tutanota angeblich mitwirkt. Aus Sicht des Unternehmens ist das Urteil deshalb â€žabsurdâ€œ.</p>
<h3 id="nav_lka_will__1">LKA will Postfach Ã¼berwachen</h3>






  


  <a-ad height="250" instant="" layout="responsive" media="(min-width: 320px) and (max-width: 767px)" preload-distance="200" safeframe="" sizes="300x50,300x75,300x100,300x150,300x250,320x50,320x75,320x100,320x250,fluid" targeting="{&quot;kw&quot;:[&quot;E-Mail&quot;,&quot;E-Mail-Provider&quot;,&quot;Gerichtsurteil&quot;,&quot;LKA&quot;,&quot;Tutanota&quot;,&quot;VerschlÃ¼sselung&quot;,&quot;Ãœberwachung&quot;],&quot;mpos&quot;:[&quot;2&quot;],&quot;themenhub&quot;:&quot;yes&quot;}" type="gpt" unit="/6514/www.heise.de/ct/ct-inhalt" width="300"></a-ad>



<p>In dem Fall geht es um eine Erpressungsmail, die von einem Tutanota-Postfach aus an einen Autozulieferer gesendet worden war. Tutanota sieht sich nun gezwungen, bis Jahresende eine Funktion zu programmieren, die es dem Landeskriminalamt Nordrhein-Westfalen ermÃ¶glicht, dieses Postfach zu Ã¼berwachen.</p>





  

<a-lightbox tabindex="1">
  
    

<figure>

  <div>
      <a href="https://www.heise.de/imgs/18/3/0/0/9/6/0/7/Tutonia-9fa96e1a083080c4.jpg">
      

<a-img alt="" height="1137" high-dpi-quality="70" layout="responsive" quality="85" src="/imgs/18/3/0/0/9/6/0/7/Tutonia-9fa96e1a083080c4.jpg" width="1800"></a-img>



      </a>
    

  </div>
    

<figcaption>    <p>Tutanota-Team: Der hannoversche Mailprovider versendet Mails Ende-zu-Ende-verschlÃ¼sselt und speichert auch das Postfach in verschlÃ¼sselter Form.</p>
      
        <p>
      (Bild:Â&nbsp;Tutao GmbH)
    </p>
</figcaption>

</figure>

  
</a-lightbox>




<p>FÃ¼r die anderen Nutzer soll sich dadurch nichts Ã¤ndern, ihre Mails sollen weiter standardmÃ¤ÃŸig verschlÃ¼sselt werden. Gleichwohl sieht Tutanota eine einmalige Umgehung der VerschlÃ¼sselung als Datenschutz- und Sicherheitsrisiko fÃ¼r letztlich alle Kunden an.</p>
<p><strong>[Update, 30.11., 12 Uhr]</strong> Wie Tutanota betonte, betrifft die ÃœberwachungsmaÃŸnahme nur die neu eingehenden unverschlÃ¼sselten E-Mails. Bereits verschlÃ¼sselte Daten sowie Ende-zu-Ende verschlÃ¼sselte E-Mails in Tutanota kann das Unternehmen nicht entschlÃ¼sseln.<strong> [Update]</strong></p>
<p>AuÃŸer Tutanota speichern auch einige andere Anbieter alle eingehenden Mails in verschlÃ¼sselter Form. Bei Protonmail ist das ebenfalls Standard, Posteo und Mailbox.org bieten die VerschlÃ¼sselung als Option an. Einen Ãœberblick Ã¼ber die Zahl der Anfragen von BehÃ¶rden gibt Tutanota in seinem <a href="https://tutanota.com/blog/posts/transparency-report/" rel="external noopener" target="_blank">Transparenzbericht</a>.</p>








<a-collapse media="(min-width: 993px)" sneak-peek="" toggle-class-on-media="a-box--full-bordered">
  
  <div data-collapse-target="">
    <div>
      
  <div data-collapse-content="">
    
      <figure>
        
  <a-img alt="" height="1000" high-dpi-quality="70" quality="85" src="/imgs/18/3/0/0/9/6/0/7/ct-2020-25-e065397de69d9c0b.jpg" width="707">
  </a-img>

  


        
      </figure>
    

    <div>

      
        <h4>c't 25/2020</h4><p>Dieser Artikel stammt aus <a href="https://www.heise.de/select/ct/2020/25">câ€™t 25/2020</a>. Darin liefert die Redaktion Auswahlhilfen fÃ¼r den TV-Kauf sowie einen Test von Smart-TVs. Jede Menge Handreichungen und ein Test aktueller E-Mail-Clients soll Ihnen helfen, in den tÃ¤glichen E-Mail-Fluten Oberwasser zu behalten. Beim Navi-Spezialist TomTom hat c't ein Datenleck aufgedeckt und sie analysiert die ÃœberwachungstÃ¼cken von Office 365. Dazu gibts viele weitere Tests und nicht zu vergessen eine TÃ¼te voller nerdiger Geschenketipps fÃ¼rs bevorstehende Weihnachtsfest. c't 25/2020 ist ab sofort <a href="https://shop.heise.de/c-t-25-2020" rel="external noopener" target="_blank">im Heise-Shop</a> und am gut sortierten Zeitschriftenkiosk erhÃ¤ltlich.</p>
      

      

      

    </div>
  </div>


    </div>
  </div>
  
</a-collapse>



<p>

<!-- RSPEAK_STOP -->
<span>(<a href="mailto:uk@ct.de" title="Ulrike Kuhlmann">uk</a>)</span>
<!-- RSPEAK_START -->
</p>

      <!-- RSPEAK_STOP -->

      

      

     

      

      <!-- RSPEAK_STOP -->

    </div></div>]]>
            </description>
            <link>https://www.heise.de/news/Gericht-zwingt-Mailprovider-Tutanota-zu-Ueberwachungsfunktion-4972460.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25337507</guid>
            <pubDate>Mon, 07 Dec 2020 21:05:22 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[FuzzOS – an operating system which is designed specifically for fuzzing]]>
            </title>
            <description>
<![CDATA[
Score 118 | Comments 21 (<a href="https://news.ycombinator.com/item?id=25336540">thread link</a>) | @URfejk
<br/>
December 7, 2020 | https://gamozolabs.github.io/fuzzing/2020/12/06/fuzzos.html | <a href="https://web.archive.org/web/*/https://gamozolabs.github.io/fuzzing/2020/12/06/fuzzos.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <h2 id="summary">Summary</h2>

<p>We’re going to work on an <em>operating system</em> which is designed specifically for fuzzing! This is going to be a streaming series for most of December which will cover making a new operating system with a strong focus on fuzzing. This means that things like the memory manager, determinism, and scalability will be the most important parts of the OS, and a lot of effort will go into making them super fast!</p>

<h2 id="when">When</h2>

<p>Streaming will start sometime on Thursday, December 10th, probably around 18:00 UTC, but the streams will be at relatively random times on relatively random days. I can’t really commit to specific times!</p>

<p>Streams will likely be 4-5 days a week (probably M-F), and probably 8-12 hours in length. We’ll see, who knows, depends how much fun we have!</p>

<h2 id="where">Where</h2>

<p>You’ll be able to find the streams live on my <a href="https://twitch.tv/gamozo">Twitch Channel</a>, and if you’re unlucky and miss the streams, you’ll be able to find the recordings on my <a href="https://www.youtube.com/user/gamozolabs">YouTube Channel</a>! Don’t forget to like, comment, and subscribe, of course.</p>

<h2 id="what">What</h2>

<p>So… ultimately, I don’t really know what all will happen. But, I can predict a handful of things that we’ll do. First of all, it’s important to note that these streams are not training material. There is no prepared script, materials, flow, etc. If we end up building something totally different, that’s fine and we’re just going with the flow. There is no requirement of completing this project, or committing to certain ways the project will be done. So… with that aside.</p>

<p>We’ll be working on making an operating system, specifically for x86-64 (Intel flavor processors at the start, but AMD should work in non-hypervisor mode). This operating system will be designed for fuzzing, which means we’ll want to focus on making virtual memory management extremely fast. This is the backbone of most performant fuzzing, and we’ll need to be able to map in, unmap, and restore pages as they are modified by a fuzz case.</p>

<p>To keep you on the edge of your toes, I’ll first start with the boring things that we have to do.</p>

<h3 id="os">OS</h3>

<p>We have to make an operating system which boots. We’re gonna make a UEFI kernel, and we might dabble in running it on ARM64 as most of our code will be platform agnostic. But, who knows. It’ll be a pretty generic kernel, I’m mainly going to develop it on bare metal, but of course, we’ll make sure it runs on KVM/Xen/Hyper-V such that it can be used in a cloud environment.</p>

<h3 id="acpi">ACPI</h3>

<p>We’re gonna need to write ACPI table parsers such that we can find the NUMA locality of memory and CPUs on the system. This will be critical to getting a high performance memory manager that scales with cores.</p>

<h3 id="multi-processing">Multi-processing</h3>

<p>Of course, the kernel will support multiple cores, as otherwise it’s kinda useless for compute.</p>

<h3 id="10gbit-networking--tcp-stack">10gbit networking + TCP stack</h3>

<p>Since I never work with disks, I’m going to follow my standard model of just using the network as general purpose whatever. To do this, we’ll need 10gbit network drivers and a TCP stack such that we can communicate with the rest of a network. Nothing too crazy here, we’ll probably borrow some code from <a href="https://github.com/gamozolabs/chocolate_milk">Chocolate Milk</a></p>

<hr>

<h2 id="interesting-stuff">Interesting stuff</h2>

<p>Okay, that stuff was boring, lets talk about the fun parts!</p>

<h3 id="exotic-memory-model">Exotic memory model</h3>

<p>Since we’ll be “snapshotting” memory itself, we need to make sure things like pointers aren’t a problem. The fastest, easiest, and best solution to this, is simply to make sure the memory always gets loaded at the same address. This is no problem for a single core, but it’s difficult for multiple cores, as they need to have copies of the same data mapped at the same location.</p>

<p>What’s the solution? Well of course, we’ll have every single core on the system running it’s own address space. This means there is no shared memory between cores (with some very, very minor execeptions). Not only does this lead to execeptionally high memory access performance (due to caches only being in the exclusive or shared states), but it also means that shared (mutable) memory will not be a thing! This means that we’ll do all of our core synchronization through message passing, which is higher latency in the best case than shared memory models, but with an advantage of scaling much better. As long as our messages can be serialized to TCP streams, that means we can scale across the network without any effort.</p>

<p>This has some awesome properties since we no longer need any locks to our page tables to add and remove entries, nor do we need to perform any TLB shootdowns, which can cost tens thousands of cycles.</p>

<p>I used this model in <a href="https://gamozolabs.github.io/metrology/2019/08/19/sushi_roll.html">Sushi Roll</a>, and I really miss it. It had incredibly good performance properties and forced a bit more thought about sharing information between cores.</p>

<h3 id="scaling">Scaling</h3>

<p>As with most things I write, linear scaling will be required, and scaling across the network is just implied, as it’s required for really any realistic application of fuzzing.</p>

<h3 id="fast-and-differential-memory-snapshotting">Fast and differential memory snapshotting</h3>

<p>So far, none of these things are super interesting. I’ve had many OSes that do these things well, for fuzzing, for quite a long time. However, I’ve never made these memory management techniques into a true data structure, rather I use them as needed manually. I plan to make the core of this operating system, a combination of Rust procedural macros and virtual memory management tricks to allow for arbitrary data structure to be stored in a tree-shaped checkpointed structure.</p>

<p>This will allow for fast transitions between different state of the structure as they were snapshotted. This will be done by leveraging the dirty bits in the page tables, and creating an allocator that will allocate in a pool of memory which will be saved and restored on snapshots. This memory will be treated as an opaque blob internally, and thus it can hold any information you want, device state, guest memory state, register state, something completely unrelated to fuzzing, won’t matter. To handle nested structures (or more specifically, pointers in structures which are to be tracked), we’ll use a Rust procedural macro to disallow untracked pointers within tracked structures.</p>

<p>Effectively, we’re going to heavily leverage the hardware’s MMU to differentally snapshot, teleport between, and restore blobs of memory. For fuzzing, this is necessary as a way to hold guest memory state and register state. By treating this opaquely, we can focus on doing the MMU aspects really well, and stop worrying about special casing all these variables that need to be restored upon resets.</p>

<h3 id="linux-emulator">Linux emulator</h3>

<p>Okay, so all of that is kinda to make room for developing high performance fuzzers. In my case, I want this mainly for a new rewrite of vectorized emulation, but to make it interesting for others, we’re going to implement a Linux emulator capable of running QEMU.</p>

<p>This means that we’ll be able to (probably staticially only) compile QEMU. Then we can take this binary, and load it into our OS and run QEMU in our OS. This means we can control the syscall responses to the requests QEMU makes. If we do this deterministically (we will), this means QEMU will be deterministic. Which thus means, the guest inside of QEMU will also be deterministic. You see? This is a technique I’ve used in the past, and works exceptionally well. We’ll definitely outperform Linux’s handling of syscalls, and we’ll scale better, and we’ll blow Linux away when it comes to memory management.</p>

<h3 id="kvm-emulator--hypervisor">KVM emulator + hypervisor</h3>

<p>So, I have no idea how hard this would be, but from about 5 minutes of skimming the interwebs, it seems that I could pretty easily write a hypervisor in my OS that emulates KVM ioctls. Meaning QEMU would just think KVM is there, and use it!</p>

<p>This will give us full control of QEMU’s determinism, syscalls, performance, and reset speeds… without actually having to modify QEMU code.</p>

<h2 id="thats-it">That’s it</h2>

<p>So that’s the plan. An OS + fast MMU code + hypervisor + Linux emulator, to allow us to deterministically run anything QEMU can run, which is effectively everything. We’ll do this with performance likely into the millions of VM resets per second per core, scaling linearly with cores, including over the network, to allow some of the fastest general purpose fuzzing the world has ever seen :D</p>

<h2 id="faq">FAQ</h2>

<p>Some people have asked questions on the internet, and I’ll post them here:</p>

<h3 id="hackernews-q1">Hackernews Q1</h3>

<p>Q:</p>

<div><div><pre><code>Huh. So my initial response was, "why on earth would you need a whole OS for that", but memory snapshotting and improved virtual memory performance might actually be a good justification. Linux does have CRIU which might be made to work for such a purpose, but I could see a reasonable person preferring to do it from a clean slate. On the other hand, if you need qemu to run applications (which I'm really unclear about; I can't tell if the plan is to run stuff natively on this OS or just to provide enough system to run qemu and then run apps on linux on qemu) then I'm surprised that it's not easier to just make qemu do what you want (again, I'm pretty sure qemu already has its own memory snapshotting features to build on).

Of course, writing an OS can be its own reward, too:) 
</code></pre></div></div>

<p>A:</p>

<div><div><pre><code>Oooh, wasn't really expecting this to make it to HN cause it was meant to be more of an announcement than a description.

But yes, I've done about 7 or 8 operating systems for fuzzing in the past and it's a massive performance (and cleanliness) cleanup. This one is going to be like an operating system I wrote 2-3 years ago for my vectorized emulation work.

To answer your QEMU questions, the goal is to effectively build QEMU with MUSL (just to make it static so I don't need a dynamic loader), and modify MUSL to turn all syscalls to `call` instructions. This means a "syscall" is just a call to another area, which will by my Rust Linux emulator. I'll implement the bare minimum syscalls (and enum variants to those syscalls) to get QEMU to work, nothing more. The goal is not to run Linux applications, but run a QEMU+MUSL combination which may be modified lightly if it means a lower emulation burden …</code></pre></div></div></div></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://gamozolabs.github.io/fuzzing/2020/12/06/fuzzos.html">https://gamozolabs.github.io/fuzzing/2020/12/06/fuzzos.html</a></em></p>]]>
            </description>
            <link>https://gamozolabs.github.io/fuzzing/2020/12/06/fuzzos.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25336540</guid>
            <pubDate>Mon, 07 Dec 2020 20:00:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why I Love Tailwind]]>
            </title>
            <description>
<![CDATA[
Score 263 | Comments 280 (<a href="https://news.ycombinator.com/item?id=25332101">thread link</a>) | @theBashShell
<br/>
December 7, 2020 | https://mxstbr.com/thoughts/tailwind/ | <a href="https://web.archive.org/web/*/https://mxstbr.com/thoughts/tailwind/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p font-family="system" color="#333" font-size="18px"><a target="_blank" rel="noopener" to="https://tailwindcss.com" href="https://tailwindcss.com/" color="blue">Tailwind</a> is an atomic CSS framework that has taken the frontend world by storm. It gives developers without a deep understanding of design the ability to build visually gorgeous, modern user interfaces. </p><p font-family="system" color="#333" font-size="18px">If you have not seen it before, here is the canonical Tailwind example from their original homepage:</p><pre font-size="15px"><code font-size="15px"><span><span><span>&lt;</span>div</span> <span>class</span><span><span>=</span><span>"</span>shadow-lg flex bg-white rounded-lg p-6 leading-normal<span>"</span></span><span>&gt;</span></span>
  <span><span><span>&lt;</span>img</span> <span>class</span><span><span>=</span><span>"</span>h-24 w-24 rounded-full mx-auto mx-0 mr-6<span>"</span></span> <span>src</span><span><span>=</span><span>"</span>avatar.jpg<span>"</span></span> <span>/&gt;</span></span>
  <span><span><span>&lt;</span>div</span> <span>class</span><span><span>=</span><span>"</span>text-center text-left<span>"</span></span><span>&gt;</span></span>
    <span><span><span>&lt;</span>h1</span> <span>class</span><span><span>=</span><span>"</span>text-lg<span>"</span></span><span>&gt;</span></span>Erin Lindford<span><span><span>&lt;/</span>h1</span><span>&gt;</span></span>
    <span><span><span>&lt;</span>h2</span> <span>class</span><span><span>=</span><span>"</span>text-purple-500<span>"</span></span><span>&gt;</span></span>Customer Support<span><span><span>&lt;/</span>h2</span><span>&gt;</span></span>
    <span><span><span>&lt;</span>p</span> <span>class</span><span><span>=</span><span>"</span>text-gray-600<span>"</span></span><span>&gt;</span></span>erinlindford@example.com<span><span><span>&lt;/</span>p</span><span>&gt;</span></span>
    <span><span><span>&lt;</span>p</span> <span>class</span><span><span>=</span><span>"</span>text-gray-600<span>"</span></span><span>&gt;</span></span>(555) 765-4321<span><span><span>&lt;/</span>p</span><span>&gt;</span></span>
  <span><span><span>&lt;/</span>div</span><span>&gt;</span></span>
<span><span><span>&lt;/</span>div</span><span>&gt;</span></span>
</code></pre><div><p><img alt="Avatar of Erin Lindford" src="https://randomuser.me/api/portraits/women/17.jpg"></p><div><p>Erin Lindford</p><p>Customer Support</p><p>erinlindford@example.com</p><p>(555) 765-4321</p></div></div><p font-family="system" color="#333" font-size="18px">Many people think Tailwind is cool because it uses atomic CSS. Here is the thing though: <strong>Tailwind is awesome <em>despite</em> using atomic CSS, not because of it</strong>.</p><p font-family="system" color="#333" font-size="18px">Hear me out.</p><h3 font-family="system" font-size="4" font-weight="bold">The key to Tailwind</h3><p font-family="system" color="#333" font-size="18px">We have had <a target="_blank" rel="noopener" to="https://github.com/basscss/basscss/commit/ed65eec980c4899d930f2c293f70bc619573456f" href="https://github.com/basscss/basscss/commit/ed65eec980c4899d930f2c293f70bc619573456f" color="blue">atomic</a> <a target="_blank" rel="noopener" to="https://github.com/tachyons-css/tachyons/commit/7f27af8d52d8ed03615e23a9db5ff33fc8153729" href="https://github.com/tachyons-css/tachyons/commit/7f27af8d52d8ed03615e23a9db5ff33fc8153729" color="blue">CSS</a> <a target="_blank" rel="noopener" to="https://medium.com/buzzfeed-design/introducing-solid-1c16b1bf4868" href="https://medium.com/buzzfeed-design/introducing-solid-1c16b1bf4868" color="blue">frameworks</a> for almost a decade but none of them have been as critically acclaimed as Tailwind. What makes it different?</p><p font-family="system" color="#333" font-size="18px"><strong>The key to Tailwind's popularity is the painstakingly constructed system of design tokens at the core of the framework.</strong> The system's carefully selected constraints give developers <em>just</em> the right guardrails. They make it obvious whether a choice is good or bad by offering only discrete steps.</p><p font-family="system" color="#333" font-size="18px">This does require some design <em>taste</em>, but most frontend engineers I know have developed that over the years of building user interfaces. Tailwind's system lets them turn that taste into implementation without requiring a lot of design <em>skill</em> — it helps them cross <a target="_blank" rel="noopener" to="https://vimeo.com/85040589" href="https://vimeo.com/85040589" color="blue">"the gap"</a>.</p><p font-family="system" color="#333" font-size="18px">Tailwind's system is a masterpiece of design. I, and many other developers all around the world, feel empowered by and love it.</p><h3 font-family="system" font-size="4" font-weight="bold">The problem with Tailwind</h3><p font-family="system" color="#333" font-size="18px">The atomic CSS framework is basically a delivery mechanism that allows developers to apply the system to their UIs. It's undeniable that it has a fantastic developer experience: once you get used to the custom vocabulary you feel like you are flying!</p><ul><li><p font-family="system" color="#333" font-size="18px">Users still have to add a separate setup for the <a target="_blank" rel="noopener" to="https://twitter.com/kentcdodds/status/1240868842361913347" href="https://twitter.com/kentcdodds/status/1240868842361913347" color="blue">custom CSS they inevitably need</a> (coined <a target="_blank" rel="noopener" to="https://twitter.com/samselikoff/status/1251637275412357121" href="https://twitter.com/samselikoff/status/1251637275412357121" color="blue">"bailwind"</a>). You cannot get by on <em>just</em> Tailwind in the real world. Not having a dedicated place for custom styles in the same system can cause maintenance issues down the line.</p></li><li><p font-family="system" color="#333" font-size="18px">Due to file-size considerations, <a target="_blank" rel="noopener" to="https://tailwindcss.com/docs/hover-focus-and-other-states#default-variants-reference" href="https://tailwindcss.com/docs/hover-focus-and-other-states#default-variants-reference" color="blue">Tailwind does not include all variants</a> (e.g. <code font-size="2">hover:</code>, <code font-size="2">sm:</code>) for all utilities by default. It leaves it to you to manually configure which ones you need for every single CSS property.</p></li><li><p font-family="system" color="#333" font-size="18px">Atomic CSS is not ideal for performance. No tooling can extract the <em>per-page</em> critical CSS, so you end up shipping more CSS to the browser than necessary. The bigger and more dynamic the app, the more unnecessary code you will ship.<sup id="fnref-1"><a href="https://mxstbr.com/thoughts/tailwind/#fn-1" color="blue">1</a></sup></p></li></ul><h3 font-family="system" font-size="4" font-weight="bold">Tailwind without the downsides</h3><p font-family="system" color="#333" font-size="18px">Brent Jackson, the creator of one of the original atomic CSS libraries, said it best in <a target="_blank" rel="noopener" to="https://jxnblk.com/blog/two-steps-forward/" href="https://jxnblk.com/blog/two-steps-forward/" color="blue">his post on atomic CSS</a>:</p><p font-family="system" color="#333" font-size="18px">“This methodology was created before React was released and was intended for use in template-based user interfaces, including Rails and PHP. It was never designed for functional component-based UI and doesn't take advantage of this new paradigm.”</p><p font-family="system" color="#333" font-size="18px">Now, here is the thing: you can have your cake and eat it too. You can use Tailwind's marvelous system and fantastic developer experience without the downsides of atomic CSS.</p><p font-family="system" color="#333" font-size="18px">Let me illustrate. Here is the canonical Tailwind example built with <a target="_blank" rel="noopener" to="https://github.com/ben-rogerson/twin.macro" href="https://github.com/ben-rogerson/twin.macro" color="blue">twin.macro</a> and React:</p><pre font-size="15px"><code font-size="15px"><span>import</span> <span>"twin.macro"</span>

<span>const</span> <span>Card</span> <span>=</span> <span>(</span><span>)</span> <span>=&gt;</span> <span>(</span>
  <span><span><span>&lt;</span>div</span> <span>tw</span><span><span>=</span><span>"</span>shadow-lg md:flex bg-white rounded-lg p-6 leading-normal<span>"</span></span><span>&gt;</span></span><span>
    </span><span><span><span>&lt;</span>img</span> <span>tw</span><span><span>=</span><span>"</span>h-16 w-16 md:h-24 md:w-24 rounded-full mx-auto md:mx-0 md:mr-6<span>"</span></span> <span>src</span><span><span>=</span><span>"</span>avatar.jpg<span>"</span></span> <span>/&gt;</span></span><span>
    </span><span><span><span>&lt;</span>div</span> <span>tw</span><span><span>=</span><span>"</span>text-center md:text-left<span>"</span></span><span>&gt;</span></span><span>
      </span><span><span><span>&lt;</span>h1</span> <span>tw</span><span><span>=</span><span>"</span>text-lg<span>"</span></span><span>&gt;</span></span><span>Erin Lindford</span><span><span><span>&lt;/</span>h1</span><span>&gt;</span></span><span>
      </span><span><span><span>&lt;</span>h2</span> <span>tw</span><span><span>=</span><span>"</span>text-purple-500<span>"</span></span><span>&gt;</span></span><span>Customer Support</span><span><span><span>&lt;/</span>h2</span><span>&gt;</span></span><span>
      </span><span><span><span>&lt;</span>p</span> <span>tw</span><span><span>=</span><span>"</span>text-gray-600<span>"</span></span><span>&gt;</span></span><span>erinlindford@example.com</span><span><span><span>&lt;/</span>p</span><span>&gt;</span></span><span>
      </span><span><span><span>&lt;</span>p</span> <span>tw</span><span><span>=</span><span>"</span>text-gray-600<span>"</span></span><span>&gt;</span></span><span>(555) 765-4321</span><span><span><span>&lt;/</span>p</span><span>&gt;</span></span><span>
    </span><span><span><span>&lt;/</span>div</span><span>&gt;</span></span><span>
  </span><span><span><span>&lt;/</span>div</span><span>&gt;</span></span>
<span>)</span>
</code></pre><div><p><img alt="Avatar of Erin Lindford" src="https://randomuser.me/api/portraits/women/17.jpg"></p><div><h2>Erin Lindford</h2><p>Customer Support</p><p>erinlindford@example.com</p><p>(555) 765-4321</p></div></div><p font-family="system" color="#333" font-size="18px">Unsurprisingly, the result looks identical — we are still using the same system after all. Even the code looks the same, except that we use the <code font-size="2">tw</code> prop instead of the <code font-size="2">class</code> attribute!</p><p font-family="system" color="#333" font-size="18px">However, under the hood this automatically compiles the class names to the actual CSS they refer to (with <a target="_blank" rel="noopener" to="https://medium.com/styled-components/announcing-native-support-for-the-css-prop-in-styled-components-245ca5252feb" href="https://medium.com/styled-components/announcing-native-support-for-the-css-prop-in-styled-components-245ca5252feb" color="blue">the css prop</a>):</p><pre font-size="15px"><code font-size="15px"><span>import</span> <span>"twin.macro"</span>

<span><span><span>&lt;</span>div</span> <span>tw</span><span><span>=</span><span>"</span>text-center md:text-left<span>"</span></span> <span>/&gt;</span></span>



<span>import</span> <span>"styled-components/macro"</span>

<span><span><span>&lt;</span>div</span> 
  <span>css</span><span><span>=</span><span>{</span><span>{</span>
    textAlign<span>:</span> <span>"center"</span><span>,</span>
    <span>"@media (min-width: 768px)"</span><span>:</span> <span>{</span>
      <span>"textAlign"</span><span>:</span><span>"left"</span>
    <span>}</span>
  <span>}</span><span>}</span></span>
<span>/&gt;</span></span>
</code></pre><ul><li><p font-family="system" color="#333" font-size="18px">Extending your elements with custom styles is as simple as using the css prop, no extra separate setup required to "bailwind":</p><pre font-size="15px"><code font-size="15px"><span>import</span> <span>"twin.macro"</span>

<span><span><span>&lt;</span>div</span>
  <span>tw</span><span><span>=</span><span>"</span>text-center md:text-left<span>"</span></span>
  <span>css</span><span><span>=</span><span>{</span><span>{</span><span><span>`
    &amp;:hover { 
      background-image: url("/bg.png");
    }
  `</span></span><span>}</span><span>}</span></span>
<span>/&gt;</span></span>
</code></pre></li><li><p font-family="system" color="#333" font-size="18px">You can use all variants in all combinations with all utilities allowing for even more expression within the system. Since twin.macro runs at build-time, you don't have to worry about configuration or file size:</p><pre font-size="15px"><code font-size="15px"><span>import</span> <span>"twin.macro"</span>

<span><span><span>&lt;</span>div</span> <span>tw</span><span><span>=</span><span>"</span>sm:hover:first:bg-black<span>"</span></span><span>&gt;</span></span><span>...</span><span><span><span>&lt;/</span>div</span><span>&gt;</span></span>
</code></pre></li><li><p font-family="system" color="#333" font-size="18px">You get fully automatic critical CSS extraction and code splitting. Users will only load exactly the styles they need for the page they requested — nothing more and nothing less! CSS performance does not get better.<sup id="fnref-1"><a href="https://mxstbr.com/thoughts/tailwind/#fn-1" color="blue">1</a></sup></p></li></ul><p font-family="system" color="#333" font-size="18px">The ideal setup for both developer <em>and</em> user experience!</p><div display="block"><div><p font-family="system" color="#333" font-size="18px"><strong>Lesson</strong>: <!-- -->use <a target="_blank" rel="noopener" to="https://github.com/ben-rogerson/twin.macro" href="https://github.com/ben-rogerson/twin.macro" color="blue">twin.macro</a> to leverage Tailwind's marvelous system and developer experience without the downsides of atomic CSS.</p></div></div><p font-family="system" color="#333" font-size="18px">Rather than taking two steps forward with Tailwind's system and one step backward with atomic CSS, let's take five steps forward. Together.</p></div></div>]]>
            </description>
            <link>https://mxstbr.com/thoughts/tailwind/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25332101</guid>
            <pubDate>Mon, 07 Dec 2020 13:56:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Is Stencil a Better React?]]>
            </title>
            <description>
<![CDATA[
Score 81 | Comments 61 (<a href="https://news.ycombinator.com/item?id=25331909">thread link</a>) | @yoava
<br/>
December 7, 2020 | https://www.wix.engineering/post/is-stencil-a-better-react | <a href="https://web.archive.org/web/*/https://www.wix.engineering/post/is-stencil-a-better-react">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-hook="post-description"><article><div><div data-rce-version="8.7.1"><div dir="ltr"><div><div id="viewer-9ud64"><div><div data-hook="imageViewer" role="button" tabindex="0"><div role="img"><p><img data-pin-url="https://www.wix.engineering/post/is-stencil-a-better-react" data-pin-media="https://static.wixstatic.com/media/66bc35_7ba678e807d947b0a64706b33bc23f72~mv2.jpg/v1/fit/w_1000%2Ch_1000%2Cal_c%2Cq_80/file.png" src="https://static.wixstatic.com/media/66bc35_7ba678e807d947b0a64706b33bc23f72~mv2.jpg/v1/fit/w_300,h_300,al_c,q_5/file.jpg"></p></div></div></div></div><p id="viewer-coc16"><span>Photo by <a href="https://unsplash.com/@joshcala?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" target="_blank" rel="noopener">Josh Calabrese</a> on <a href="https://unsplash.com/?utm_source=unsplash&amp;utm_medium=referral&amp;utm_content=creditCopyText" target="_blank" rel="noopener">Unsplash</a></span></p><p id="viewer-8u5rt"><span><span>Recently I went looking for ways to code web components and found this great post - “</span><a href="https://webcomponents.dev/blog/all-the-ways-to-make-a-web-component/" target="_blank" rel="noopener"><span><u>All the Ways to Make a Web Component - October 2020 Update</u></span></a><span>”. It lists ~30 libraries for creating web components, comparing code style, performance and bundle size. One of the libraries got me intrigued - Stencil - which looks very promising and has lots of stars on GitHub - about 8.6k.</span></span></p><p id="viewer-m0td"><span><a href="https://stenciljs.com/" target="_blank" rel="noopener"><span><u>Stencil</u></span></a><span> is a React-inspired web component library. It is using the same JSX as React and some of the same concepts (Render function, props, state). However, Stencil differs as it compiles to an optimal bundle, creating Virtual DOM that is consolidated directly into the DOM itself (no VDOM to VDOM comparison). The result is standard web components with optimal performance.</span></span></p><p id="viewer-876ce"><span><span>On top, Stencil provides good development experience through their template applications - for building a component, a website / app or a PWA. Stencil also supports server-side rendering and hydrations for websites that need to be optimized for indexing.</span></span></p><p id="viewer-4f7v9"><span><span>To learn Stencil, we decided to build yet another version of </span><a href="http://todomvc.com/" target="_blank" rel="noopener"><span><u>TodoMVC</u></span></a><span>. TodoMVC is a great platform to compare different javascript libraries - it </span>exposes<span> 54 Javascript UI libraries on one simple use case - a Todo list application. Each application has to look exactly the same, with the same functionality - adding a todo item, marking an item as complete, removing completed items, etc. Every instance of the application needs to be persistent with local storage and feature routing for display all, active or completed todos, and so on. </span></span></p><p id="viewer-5ab1d"><span><span>Here is an example of a TodoMVC application:</span></span></p><div id="viewer-9kpfo"><div><div data-hook="imageViewer" role="button" tabindex="0"><div role="img"><p><img data-pin-url="https://www.wix.engineering/post/is-stencil-a-better-react" data-pin-media="https://static.wixstatic.com/media/66bc35_451dfe597f8c4a3e99ebd9013facd90f~mv2.png/v1/fit/w_1000%2Ch_1000%2Cal_c%2Cq_80/file.png" src="https://static.wixstatic.com/media/66bc35_451dfe597f8c4a3e99ebd9013facd90f~mv2.png/v1/fit/w_300,h_300,al_c,q_5/file.png"></p></div></div></div></div><p id="viewer-5isi0"><span><span>In this article we share what we’ve learned from building a TodoMVC application using Stencil.</span></span></p><p id="viewer-7pffh"><span><span>Our finished copy of the complete Stencil TodoMVC application is on GithuB: </span></span></p><ul><li id="viewer-2ajfe"><p><span>Github pages - </span><a href="https://yoavaa.github.io/stencil-todo-mvc/" target="_blank" rel="noopener"><span><u>demo</u></span></a> </p></li><li id="viewer-504l8"><p><span>Github </span><a href="https://github.com/yoavaa/stencil-todo-mvc" target="_blank" rel="noopener"><span><u>repo</u></span></a> </p></li><li id="viewer-6isa4"><p><span>Pull request for TodoMVC is </span><a href="https://github.com/tastejs/todomvc/pull/2130" target="_blank" rel="noopener"><span><u>here</u></span></a><span>.</span></p></li></ul><p id="viewer-df9em"><span><span>Here’s an equivalent React TodoMVC application for reference:</span></span></p><ul><li id="viewer-e9k4l"><p><a href="http://todomvc.com/examples/react/#/" target="_blank" rel="noopener"><span><u>TodoMVC React Example</u></span></a></p></li></ul><p id="viewer-ce1qk"><span><span>Just for the fun of it, we also added a </span><a href="https://svelte.dev/" target="_blank" rel="noopener"><span><u>Svelte</u></span></a><span> TodoMVC application for the performance comparison</span></span></p><ul><li id="viewer-acl7k"><p><a href="http://svelte-todomvc.surge.sh/" target="_blank" rel="noopener"><span><u>Svelte TodoMVC Example</u></span></a></p></li></ul><p id="viewer-8a90"><span><span>A side note on Svelte - that’s another framework we’ve considered in the past and one we’re following closely today. Our Wix Engineering podcast did a whole episode on Svelte, speaking to its creator and Wix devs. You can listen to it </span><a href="https://www.wix.engineering/podcast/episode/8fd2ff59/wix-engineering-podcast-outmatched-how-svelte-beats-the-odds" target="_blank" rel="noopener"><span><u>here</u></span></a><span> and read the full podcast transcript </span><a href="https://www.wix.engineering/post/how-svelte-beats-the-odds-e04-full-transcript" target="_blank" rel="noopener"><span><u>here</u></span></a><span>. Now back to Stencil.</span></span></p><p id="viewer-b0csu"><span><span>To get started building TodoMVC with Stencil, we first need to create a dev project.</span></span></p><div id="viewer-blmkj"><div><div data-hook="imageViewer" role="button" tabindex="0"><div role="img"><p><img data-pin-url="https://www.wix.engineering/post/is-stencil-a-better-react" data-pin-media="https://static.wixstatic.com/media/66bc35_ebdf4b650aee451cbe398b706ce36c6b~mv2.png/v1/fit/w_1000%2Ch_304%2Cal_c%2Cq_80/file.png" src="https://static.wixstatic.com/media/66bc35_ebdf4b650aee451cbe398b706ce36c6b~mv2.png/v1/fit/w_300,h_300,al_c,q_5/file.png"></p></div></div></div></div><p id="viewer-okcd"><span><span>Running this command asks us which type of project we want to create - we’re creating a component, so we choose “component”.</span></span></p><p id="viewer-avn2i"><span><span>With the project created, we start working on our TodoMVC application.</span></span></p><p id="viewer-1ho6a"><span><span>First, we define the Todo component as </span></span></p><div id="viewer-5eveb"><div><div data-hook="imageViewer" role="button" tabindex="0"><div role="img"><p><img data-pin-url="https://www.wix.engineering/post/is-stencil-a-better-react" data-pin-media="https://static.wixstatic.com/media/66bc35_d479219dd8dc4364a0138d36868b1f6c~mv2.png/v1/fit/w_1000%2Ch_532%2Cal_c%2Cq_80/file.png" src="https://static.wixstatic.com/media/66bc35_d479219dd8dc4364a0138d36868b1f6c~mv2.png/v1/fit/w_300,h_300,al_c,q_5/file.png"></p></div></div></div></div><p id="viewer-cfkou"><span><span>There are a few things similar to React, a few that are different.</span></span></p><p id="viewer-9jmdh"><span><span>The first thing we see is the </span><span>@Component</span><span> decorator which tells Stencil to generate a web component named</span><span> `todo-app`</span><span>, include a CSS file and use the shadow DOM.</span></span></p><p id="viewer-fs96p"><span><span>Second, we see the decorators for</span><span> @State</span><span>, </span><span>@Prop</span><span> which are used to declare state and props of the component. Those decorators accept additional parameters to fine-tune the props and state declarations.</span></span></p><p id="viewer-6dh3h"><span><span>In fact, the actual Render functions are very similar - here they are side by side:</span></span></p><div id="viewer-336dk"><div><div data-hook="imageViewer" role="button" tabindex="0"><div role="img"><p><img data-pin-url="https://www.wix.engineering/post/is-stencil-a-better-react" data-pin-media="https://static.wixstatic.com/media/66bc35_840ce5691517407e8ea9ed8104d9ce76~mv2.png/v1/fit/w_1000%2Ch_892%2Cal_c%2Cq_80/file.png" src="https://static.wixstatic.com/media/66bc35_840ce5691517407e8ea9ed8104d9ce76~mv2.png/v1/fit/w_300,h_300,al_c,q_5/file.png"></p></div></div></div></div><div id="viewer-1n343"><div><div data-hook="imageViewer" role="button" tabindex="0"><div role="img"><p><img data-pin-url="https://www.wix.engineering/post/is-stencil-a-better-react" data-pin-media="https://static.wixstatic.com/media/66bc35_ceed6aca271c4f1bbd2bf64c3ab53e80~mv2.png/v1/fit/w_1000%2Ch_1000%2Cal_c%2Cq_80/file.png" src="https://static.wixstatic.com/media/66bc35_ceed6aca271c4f1bbd2bf64c3ab53e80~mv2.png/v1/fit/w_300,h_300,al_c,q_5/file.png"></p></div></div></div></div><div id="viewer-c2ish"><div><div data-hook="imageViewer" role="button" tabindex="0"><div role="img"><p><img data-pin-url="https://www.wix.engineering/post/is-stencil-a-better-react" data-pin-media="https://static.wixstatic.com/media/66bc35_4b6a81c88c76467790404aeeece07fd7~mv2.png/v1/fit/w_1000%2Ch_996%2Cal_c%2Cq_80/file.png" src="https://static.wixstatic.com/media/66bc35_4b6a81c88c76467790404aeeece07fd7~mv2.png/v1/fit/w_300,h_300,al_c,q_5/file.png"></p></div></div></div></div><p id="viewer-1quff"><span><span>While very similar, there are still some important differences between the render functions.</span></span></p><p id="viewer-ch90r"><span><span>First, in React access to props and states is done via </span><span>this.state.newTodo</span><span> and</span><span> this.prop.model</span><span>. With Stencil both the props and state are just members of </span><span>this</span><span> - </span><span>this.newTodo</span><span> and</span><span> this.mode</span><span>l.</span></span></p><p id="viewer-6ojpl"><span><span>The second difference is the use of the </span><span>class</span><span> attribute instead of the </span><span>className</span><span> attribute. The semantics are the same, with Stencil using the more standard naming scheme.</span></span></p><p id="viewer-acdmj"><span><span>The third difference is event binding, where in Stencil they promote using arrow functions while React promotes explicit binding using the</span><span> .bind() </span><span>function. This is obviously a preference and both options can be used in both libraries.</span></span></p><p id="viewer-8hram"><span><span>The last, not so obvious, difference is with using child components. In the React version, we see the use of </span><span>TodoFooter</span><span> and </span><span>TodoItem</span><span> - both are React components which are imported into the module. However, with Stencil, the child components are</span><span> todo-footer</span><span> and</span><span> todo-item</span><span>, and there is no import statement to import those into the module. </span></span></p><p id="viewer-d0h3a"><span><span>While this may seem strange at first glance, it actually makes sense once you remember that both </span><span>todo-footer</span><span> and</span><span> todo-item</span><span> are web components and are supported natively by browsers.</span></span></p><p id="viewer-f06tp"><span><span>When comparing Stencil to React and Svelte in terms of performance, Stencil scores a higher lighthouse score for desktop. For mobile, Svelte takes the lead but is less stable. Stencil on mobile is close behind Svelte and is more stable.</span></span></p><p id="viewer-9o36j"><span><span><strong>Desktop comparison:</strong></span></span></p><div id="viewer-83opl"><div><div data-hook="imageViewer" role="button" tabindex="0"><div role="img"><p><img data-pin-url="https://www.wix.engineering/post/is-stencil-a-better-react" data-pin-media="https://static.wixstatic.com/media/66bc35_d9cba83a658e4417a9cc3b645d5b8618~mv2.png/v1/fit/w_1000%2Ch_320%2Cal_c%2Cq_80/file.png" src="https://static.wixstatic.com/media/66bc35_d9cba83a658e4417a9cc3b645d5b8618~mv2.png/v1/fit/w_300,h_300,al_c,q_5/file.png"></p></div></div></div></div><p id="viewer-6ong4"><span><span><strong>Mobile Comparison (3 runs):</strong></span></span></p><div id="viewer-b92bd"><div><div data-hook="imageViewer" role="button" tabindex="0"><div role="img"><p><img data-pin-url="https://www.wix.engineering/post/is-stencil-a-better-react" data-pin-media="https://static.wixstatic.com/media/66bc35_b34e4ab9ba6b4111b98a2e7b44ffcd1d~mv2.png/v1/fit/w_1000%2Ch_488%2Cal_c%2Cq_80/file.png" src="https://static.wixstatic.com/media/66bc35_b34e4ab9ba6b4111b98a2e7b44ffcd1d~mv2.png/v1/fit/w_300,h_300,al_c,q_5/file.png"></p></div></div></div></div><p id="viewer-9gf8n"><span><span>All the libraries score very high grades for the TodoMVC case. For me it was no surprise that Stencil was faster compared to React. What was a surprise is that it is also faster compared to Svelte, at least within this use case. </span></span></p><p id="viewer-pb8o"><span><span><strong>Stencil desktop</strong></span></span></p><div id="viewer-5f41m"><div><div data-hook="imageViewer" role="button" tabindex="0"><div role="img"><p><img data-pin-url="https://www.wix.engineering/post/is-stencil-a-better-react" data-pin-media="https://static.wixstatic.com/media/66bc35_1c49f2b173cc4326ad16357d32f15069~mv2.png/v1/fit/w_992%2Ch_954%2Cal_c%2Cq_80/file.png" src="https://static.wixstatic.com/media/66bc35_1c49f2b173cc4326ad16357d32f15069~mv2.png/v1/fit/w_300,h_300,al_c,q_5/file.png"></p></div></div></div></div><p id="viewer-520fu"><span><span><strong>React desktop</strong></span></span></p><div id="viewer-7b9su"><div><div data-hook="imageViewer" role="button" tabindex="0"><div role="img"><p><img data-pin-url="https://www.wix.engineering/post/is-stencil-a-better-react" data-pin-media="https://static.wixstatic.com/media/66bc35_b673f1bb8e634d27a1166d7bf04b862e~mv2.png/v1/fit/w_990%2Ch_954%2Cal_c%2Cq_80/file.png" src="https://static.wixstatic.com/media/66bc35_b673f1bb8e634d27a1166d7bf04b862e~mv2.png/v1/fit/w_300,h_300,al_c,q_5/file.png"></p></div></div></div></div><p id="viewer-2iv4b"><span><span><strong>Svelte desktop</strong></span></span></p><div id="viewer-6tjb8"><div><div data-hook="imageViewer" role="button" tabindex="0"><div role="img"><p><img data-pin-url="https://www.wix.engineering/post/is-stencil-a-better-react" data-pin-media="https://static.wixstatic.com/media/66bc35_fd26b273556c4a288164730f2561f829~mv2.png/v1/fit/w_990%2Ch_1000%2Cal_c%2Cq_80/file.png" src="https://static.wixstatic.com/media/66bc35_fd26b273556c4a288164730f2561f829~mv2.png/v1/fit/w_300,h_300,al_c,q_5/file.png"></p></div></div></div></div><p id="viewer-2nj6b"><span><span><strong>Stencil Mobile</strong></span></span></p><div id="viewer-99c53"><div><div data-hook="imageViewer" role="button" tabindex="0"><div role="img"><p><img data-pin-url="https://www.wix.engineering/post/is-stencil-a-better-react" data-pin-media="https://static.wixstatic.com/media/66bc35_13e477762abe42fdb9c0136e211caf25~mv2.png/v1/fit/w_990%2Ch_1000%2Cal_c%2Cq_80/file.png" src="https://static.wixstatic.com/media/66bc35_13e477762abe42fdb9c0136e211caf25~mv2.png/v1/fit/w_300,h_300,al_c,q_5/file.png"></p></div></div></div></div><p id="viewer-cenfc"><span><span><strong>React Mobile</strong></span></span></p><div id="viewer-ehele"><div><div data-hook="imageViewer" role="button" tabindex="0"><div role="img"><p><img data-pin-url="https://www.wix.engineering/post/is-stencil-a-better-react" data-pin-media="https://static.wixstatic.com/media/66bc35_9a6f4718afff41429a3a30a8b57b1c0a~mv2.png/v1/fit/w_988%2Ch_1000%2Cal_c%2Cq_80/file.png" src="https://static.wixstatic.com/media/66bc35_9a6f4718afff41429a3a30a8b57b1c0a~mv2.png/v1/fit/w_300,h_300,al_c,q_5/file.png"></p></div></div></div></div><p id="viewer-ckcb3"><span><span><strong>Svelte Mobile</strong></span></span></p><div id="viewer-7glqb"><div><div data-hook="imageViewer" role="button" tabindex="0"><div role="img"><p><img data-pin-url="https://www.wix.engineering/post/is-stencil-a-better-react" data-pin-media="https://static.wixstatic.com/media/66bc35_0850646adbd3437c9856402387ed9c28~mv2.png/v1/fit/w_990%2Ch_1000%2Cal_c%2Cq_80/file.png" src="https://static.wixstatic.com/media/66bc35_0850646adbd3437c9856402387ed9c28~mv2.png/v1/fit/w_300,h_300,al_c,q_5/file.png"></p></div></div></div></div><p id="viewer-c018s"><span><span>I have to admit that coding in Stencil was a quite delightful experience. The coding style is a bit cleaner for me with the use of decorators, the split of CSS to multiple files makes a lot of sense. </span></span></p><p id="viewer-9b5h2"><span><span>Stencil gives a great way to build web components while allowing us to keep using the standard toolset we all like - from SCSS, LESS, PostCSS, Rolloup or Stylus, to integrations with different frameworks like React, Angular, Vue, etc. </span></span></p><p id="viewer-15s6e"><span><span>It enables creating web components, static site generation, server-side rendering with client side dehydration. It even has documentation generation for Stencil components.</span></span></p><p id="viewer-74lkv"><span><span>Overall, Stencil is a great alternative to React and stacks well against Svelte too, which makes it a framework that’s definitely worth looking into.</span></span></p><div id="viewer-cgl09"><div><div data-hook="imageViewer" role="button" tabindex="0"><div role="img"><p><img data-pin-url="https://www.wix.engineering/post/is-stencil-a-better-react" data-pin-media="https://static.wixstatic.com/media/66bc35_133a1a4778a948db80c6f78b36ae82af~mv2.png/v1/fit/w_722%2Ch_862%2Cal_c%2Cq_80/file.png" src="https://static.wixstatic.com/media/66bc35_133a1a4778a948db80c6f78b36ae82af~mv2.png/v1/fit/w_300,h_300,al_c,q_5/file.png"></p></div></div></div></div><p id="viewer-3utm6"><span>This post was written by <strong>Yoav Abrahami</strong></span></p><p id="viewer-3jb16"><span>You can <a href="https://twitter.com/yoavabrahami" target="_blank" rel="noopener"><u>follow him on Twitter</u></a></span></p><p id="viewer-41gj6"><span><strong>For more engineering updates and insights:</strong></span></p><ul><li id="viewer-8pnpr"><p>Follow us on: <a href="https://twitter.com/WixEng" target="_blank" rel="noopener"><u>Twitter</u></a> | <a href="https://www.facebook.com/WixEngineering/" target="_blank" rel="noopener"><u>Facebook</u></a> | <a href="https://www.linkedin.com/showcase/wix-engineering/" target="_blank" rel="noopener"><u>LinkedIn</u></a></p></li><li id="viewer-6v46r"><p>Visit us on <a href="https://github.com/wix" target="_blank" rel="noopener"><u>GitHub</u></a> </p></li><li id="viewer-d33l"><p><a href="https://www.wix.engineering/subscribe" target="_blank" rel="noopener"><u>Subscribe to our monthly newsletter</u></a> </p></li><li id="viewer-c4bod"><p>Subscribe to our <a href="https://www.youtube.com/WixTechTalks" target="_blank" rel="noopener"><u>YouTube channel</u></a> </p></li><li id="viewer-13nvn"><p><a href="https://medium.com/wix-engineering" target="_blank" rel="noopener"><u>Follow our Medium publication</u></a></p></li><li id="viewer-3dk0n"><p>Listen to our podcast on <a href="https://podcasts.apple.com/il/podcast/wix-engineering-podcast/id1503976848" target="_blank" rel="noopener"><u>Apple</u></a>, <a href="https://open.spotify.com/show/5CmjtjpdcKkHDnr0601uYS?si=PcOf7Rx_RUmGojFj5n7CEA" target="_blank" rel="noopener"><u>Spotify</u></a> or <a href="https://podcasts.google.com/?feed=aHR0cHM6Ly9yYW5sZXZpLmNvbS9mZWVkL3dpeF9wb2Qv&amp;ved=0CAAQ4aUDahcKEwjY3bLcy7_oAhUAAAAAHQAAAAAQAQ" target="_blank" rel="noopener"><u>Google</u></a></p></li></ul></div></div></div></div></article></div></div>]]>
            </description>
            <link>https://www.wix.engineering/post/is-stencil-a-better-react</link>
            <guid isPermaLink="false">hacker-news-small-sites-25331909</guid>
            <pubDate>Mon, 07 Dec 2020 13:25:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Architecture of IMGZ]]>
            </title>
            <description>
<![CDATA[
Score 195 | Comments 90 (<a href="https://news.ycombinator.com/item?id=25331877">thread link</a>) | @sirodoht
<br/>
December 7, 2020 | https://imgz.org/blog/2020/11/19/look-ma-no-seo/ | <a href="https://web.archive.org/web/*/https://imgz.org/blog/2020/11/19/look-ma-no-seo/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>
Posted on
<time itemprop="datePublished" datetime="2020-11-19">November 19, 2020</time>.
</p><div itemprop="articleBody"><p>Every day at work, hundreds of customers ask us "can I get a large cappuccino?". Later, we go home and use the money to narrowly avoid starvation while working on IMGZ, the best image host, in true Silicon Valley spirit. We thought that some of the architectural challenges we faced while building the service would interest others, and decided to write about them to help our readers and change the world.</p>
<p>If you aren't familiar with IMGZ, it's an image host with a twist: You pay to host images, thus ensuring that we always have your best interests in mind and won't turn into a social network. In essence, we flip the traditional "startup giving away VC money to users" on its head, and take money <strong>from</strong> users. If that sounds good to you, you can sign up <a href="https://imgz.org/">on our home page</a> and we'll only be mildly surprised.</p>
<p>At IMGZ, we're passionate about two things: Serving images, and speaking about ourself in the plural so it doesn't look like it's the one-man sideproject it is, and we don't even really care about serving images that much. Today, though, we're going to talk about the former, and take a deep dive into the technical details of serving more than one million bytes of images per day while maintaining the elusive "nine fives" reliability guarantee we're loved for and usually uphold.</p>
<h2>Architecture deep-dive</h2>
<p>Our architecture is pretty simple, a fairly run-of-the-mill, scrappy-startup SaaS architecture which you've no doubt seen countless times before:</p>
<p><a href="https://imgz.org/i9hxfgRu/"><img src="https://imgz.org/i9hxfgRu.png" alt="Architecture diagram"></a></p>
<p>While designing the IMGZ storage and serving model, we wanted scalability and reliability to be our foremost concerns.
After months of designs and grueling research, we ended up designing a Kafka-based georeplicated image processing pipeline over a multitenant, distributed, resilient microservices architecture, where metadata about each image is kept in a georeplicated MongoDB instance, and with images themselves stored in DynamoDB on AWS, ensuring scalability and low latency.</p>
<p>When we realized we didn't have investors to impress, we trashed that plan, as it sounded like too much work.
We realize that architecture design nowadays is mostly aspirational, but at some point a startup needs to come to terms with the fact that it doesn't have ten million users right now, it probably won't have ten million users soon, and it'll likely never have ten users.
Instead, we stored the images in a small Postgres database (yes, the actual image data itself), with a small Django app handling the business logic. Sexy.</p>
<p>When the user uploads an image, we process it, create thumbnails for displaying in various views of the website, and store it along with its metadata in the database, at least in theory.
When a user requests the image, the request first goes through our CDN, which fetches the image from our server and then caches it forever, so each image is only served by us at most once.
For our CDN (for serving, caching, georeplication, etc), we use CloudFlare's free tier, which is excellent.
We ensure that we'll always remain in the free tier by providing a paid service nobody would actually ever pay for.</p>
<h2>The hardware</h2>
<p>This is the heart of IMGZ:</p>
<p><a href="https://imgz.org/iABb4tze/"><img src="https://imgz.org/iABb4tze.jpg" alt="Servers"></a></p>
<p>Images, just like the one above, are the heart of our service, but let's not digress.
The hardware is a $5/mo Hetzner VM that serves ~10 other projects, so it's pretty beefy.
As our favorite proverb goes, "you don't need lots of resources when all your content is static and you can get someone else to serve it for free".</p>
<p>We're pretty confident in our ability to scale our infrastructure in the event that more users join the service, as our VPS provider has a button we can press to make the server larger, solving all scalability problems once and for all.</p>
<h2>Moral of the story</h2>
<p>This article was a bit boring, wasn't it? That's by design: Your architecture doesn't have to be exciting to work, especially in the early stages of a company. Doing the easiest thing that works (taking care not to paint yoursellf into a corner) is often the best way to start, since you usually don't even know where you'll end up.</p>
<p>To summarize, our architecture follows the tried-and-true Silicon Valley approach: Build the simplest thing you can, by piggybacking off of everyone's free tier, while they hope you one day become successful and pay them exorbitant amounts of money in return. The strategy to outsmarting them is simple:</p>
<p>Just make sure you never succeed.</p>
</div></div>]]>
            </description>
            <link>https://imgz.org/blog/2020/11/19/look-ma-no-seo/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25331877</guid>
            <pubDate>Mon, 07 Dec 2020 13:21:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Steve McConnell]]>
            </title>
            <description>
<![CDATA[
Score 52 | Comments 37 (<a href="https://news.ycombinator.com/item?id=25330992">thread link</a>) | @ivanche
<br/>
December 7, 2020 | https://deprogrammaticaipsum.com/steve-mcconnell/ | <a href="https://web.archive.org/web/*/https://deprogrammaticaipsum.com/steve-mcconnell/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

		<p>I almost wrote this article not about McConnell, but Microsoft Press. Why? Because developers always have something to learn, books have been a great way to share information for centuries, so reading about computing is central to the software engineering experience. If you do not believe me, reflect on the activity you are undertaking <em>right now</em>, reading an online magazine about computing.</p>
<p>You can tell the seriousness with which a platform company treats its developers—or its “developers, developers, developers”—by the tools, knowledge and support it gives them. Where some companies release their API documentation in bound form through a recognised publisher, Microsoft just went and started their own book imprint. Not to bind their header comments between two boards, but to support professional programmers whatever their stripe (though maybe bear in mind which company has your back when choosing your technology, please).</p>
<p>Am I over-selling the importance of Microsoft Press, though? Steve McConnell, in <em>Code Complete, 2nd Edition</em> (2004, Microsoft Press), cites DeMarco and Lister’s <em>Peopleware</em> when he tells readers “one book is more than most programmers read each year.” He recommends trying to get through one every two months, as well as journals like <em>IEEE Software</em>, <em>Communications of the ACM</em>, and the now defunct and much-missed <em>Dr. Dobb’s Journal</em>. The “software developer’s reading plan” at the back of the book contains 5 introductory-level books, 8 intermediate-level, and 7 leadership-level. It would take the median programmer (at least in 1999 when <em>Peopleware</em> was written) over 20 years to follow the plan, but a little over three years at McConnell’s suggested rate. As long as you read <em>CC2E</em> first to know how quickly you are supposed to be reading!</p>
<p>Coincidentally, I left university to look for a job (which I found in the very room where I conducted my job search) in 2004, the year <em>CC2E</em> was published. Within a couple of years, when it was clear that my ability to solve problems using a computer was being hampered by my home-grown and BASIC-honed techniques at expressing computer programs, a manager gave me a copy of <em>Code Complete</em>. And the rest, as they say, is history.</p>
<p>There is lots to critique about the book, of course, particularly in 2020. Writing at the start of the Agile revolution, McConnell does not have much to say about agile practices or methodology (two entries in the index, in fact, both pointing to single-paragraph descriptions of books; there is no discussion of agile in the main text). Sure, all of the parts are there—there is a distinct shift in the discussion of change management and risk between the first edition and the second, for example—McConnell acknowledges that the different activities in software construction occur in parallel, and that the earlier a change is handled, the cheaper it will be. But he never quite gets to the conclusion that software need not be “measure twice, cut once”; that unlike carpentry, software has a limitless supply of infinitely malleable wood.</p>
<p>In some of the places where McConnell uses multiple citations to make a claim about software engineering, other writers have found the citations based on questionable data or not generalisable to the way most software is written, particularly “classic” studies from the 1970s looking at programming batch systems. But we will save that story, because a future instalment of the Programmer’s Library will cover one of those books in detail. It is more interesting than it sounds!</p>
<p>There is also lots to recommend the book: in fact, in the 16 years since it was written, nothing else comes close. I still use and recommend practices described in <em>Code Complete</em>. I have internalised most of the ideas about code organisation and conception. When I see someone who reminds me of mid-aughts me, this is one of the books that springs to mind.</p>
<p>Other books have come and gone that try to do bits of what McConnell does here, with varying degrees of success. Robert Martin’s <em>Clean Code</em> on low-level design teaches similar ideas but with less intellectual rigour. The same goes for his <em>Clean Coder</em> on the practice of being a developer, though this is a more contested field with good showings from Pete McBreen (<em>Software Craftsmanship: The New Imperative</em>) and Hunt &amp; Thomas (<em>The Pragmatic Programmer</em>). But none of these come close to supplanting <em>CC2E</em> as a manual for turning a programmer into a software engineer, and the realities of the software publishing business in 2020 mean that no replacement is likely to show up soon.</p>
<p>If all Steve McConnell had done was write this one book, his would be a significant contribution to the field. Even among the MS press books on software requirements, object thinking (not OOP), secure software development, solutions architecture, and more, this is a stand-out work. But he was and remains a prolific author, so now we turn to the rest of his library.</p>
<p>We will start by going back from 2004 to 1996. After the first edition of <em>Code Complete</em>, McConnell wrote a book about improving the capability of software teams to successfully deliver working software, ways of so doing he had uncovered by doing it and by helping others to do it. This book was <em>Rapid Development</em>, as distinct from the then-popular fad of Rapid Application Development. <em>Rapid Development</em> was explicitly <em>not</em> “programming, motherfucker”: an exhortation to just get down to coding as quickly as possible. <em>Rapid Development</em> was the (then, and from what I have seen, now too) groundbreaking advice that you should maybe align your development practices with your customers’ expectations and needs, and that doing so will help you give them what they need faster. This book had many recommendations for developers and managers to adopt on their team, including early and continuous delivery of working software through iterative, evolutionary development; continuous collaboration between the software team and the customers throughout the project; frequent feedback on the status and risks and reprioritisation so that the biggest risks are always next to be addressed; and more.</p>
<p>If this all sounds like it actually <em>is</em> agile software development, expressed four years before the Snowbird ski trip, that is for multiple reasons. Firstly by the time the manifesto was written, there was already broad understanding (at least among the more experienced and expert practitioners of software delivery) that the ideas of iterative, incremental development were transformative to the capabilities of software teams, there just was not yet a common banner under which all of the people calling for this could march. Secondly it is because I have been selective in my presentation of what is in <em>Rapid Development</em>: one of the “case studies” features a team who fail because they integrate their work too early, before all of the modules are fully tested and debugged, and this causes schedule slippage. Nowadays we recognise integration as one of the risks that we <em>should</em> mitigate by early and continuous monitoring; thus continuous integration.</p>
<p>But mostly it is because agile software development has been hollowed out since its introduction at the beginning of the millennium. Ask many development teams what they understand by Agile in 2020 and you will get a list similar to the highlights of <em>Rapid Development</em> I gave above: incremental and iterative delivery, customer involvement on the team, frequent retrospectives and feedback. That is not the entirety of the story, that is the <a href="https://www.adventureswithagile.com/2014/08/19/declaration-of-interdependence/">Project Managers’ Declaration of Interdependence</a> (originally published on Alistair Cockburn’s site in 2005). Agile software development also included a number of <em>technical</em> practices, not explicitly called out in the manifesto, on the basis that what we do changes more frequently than why we do it.</p>
<p>We have already mentioned Continuous Integration, and developers might readily mention Test-Driven Development (and maybe its more agile siblings, Behaviour-Driven Development and Acceptance Test-Driven Development, which remind us that software is done not when the tests pass, but when the software does what the customer wants from it). Some may begrudgingly allow daily stand-up meetings as an agile practice, though they may grumble. But how about user stories? Those are a technical practice, and an example of specification-by-customer-conversation. Domain-Driven Design encourages a shared vocabulary between the software team and the customers, enabling those conversations. A <a href="https://dl.acm.org/doi/10.1145/1985782.1985784">review of agile practices in scientific software development</a> lists 35 practices explicitly mentioned in the Scrum and XP methodologies. Of those, I informally count 22 technical (or at least not purely project-management) practices, and I would also suggest that those technical practices are the ones most patchily adopted across the industry, based on my own experience in many teams that describe their work as “Agile”.</p>
<p><em>Rapid Development</em> gets a bye on some of those practices on the basis that they had not been invented in 1996, but also because McConnell makes a much more general and much more useful argument: technical practices <em>are not guaranteed</em> to improve your ability to deliver working software to your customers. Indeed adopting new practices on a new project is likely to <em>reduce</em> your control over and understanding of the project, thus <em>harming</em> your ability to communicate effectively with customers what you are capable of, how much it will cost, and how long it will take. This incredibly simple and important notion has been rediscovered many times in the industry, and is currently usually cited in the form of “innovation tokens” from Dan McKinley’s <a href="https://mcfunley.com/choose-boring-technology">choose boring technology</a>.</p>
<p><em>CC2E</em> gets a bye on its short shrift on Agile for the innovation tokens reason: before the agile-industrial complex took over and made agile all about hiring scrum masters and producing burn-down charts, it was a shorthand for a lot of project management <em>and</em> technical practices and there was not …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://deprogrammaticaipsum.com/steve-mcconnell/">https://deprogrammaticaipsum.com/steve-mcconnell/</a></em></p>]]>
            </description>
            <link>https://deprogrammaticaipsum.com/steve-mcconnell/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25330992</guid>
            <pubDate>Mon, 07 Dec 2020 10:53:39 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The CIA's Deadly Deceits and the Vietnam War, with Ralph McGehee (1986)]]>
            </title>
            <description>
<![CDATA[
Score 104 | Comments 65 (<a href="https://news.ycombinator.com/item?id=25329913">thread link</a>) | @AndrewBissell
<br/>
December 6, 2020 | https://ourhiddenhistory.org/entry/the-cia-s-deadly-deceits-and-the-vietnam-war-w-ex-cia-officer-ralph-mcgehee | <a href="https://web.archive.org/web/*/https://ourhiddenhistory.org/entry/the-cia-s-deadly-deceits-and-the-vietnam-war-w-ex-cia-officer-ralph-mcgehee">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-bolt-field="body"><p><iframe allowfullscreen="" frameborder="0" src="https://www.youtube.com/embed/BDZv57p1Ixk"></iframe></p>



<p><b>Ralph W. McGehee:</b> It's a real honor for me to be here today. I don't often say that, but I really mean it. I like to start off my talk by mentioning two things. One, please don't believe anything I'm going to tell you. The American people are so inundated by misinformation, there's absolutely no reason you should believe anything anybody tells you, particularly the evening news. Of course, with everything there is an exception, and I think in my case, I have a fairly valid exception. Because of the process that I had to go through to clear my book, I had to prove that everything I am saying is in the public domain. I still go down to the Agency about twice a month and turn in new material to let them clear it. And in doing that process, I have to produce or pull out from government documents that particular information, because they inevitably will say, "You can't say it, it's classified." And I will inevitably locate that information in the public domain.</p> 
 
<p>So if you doubt me, and I hope you will, there is a way to check up on me. Go to the library and look in the back of my book, and almost every major conclusion that I will be talking about here today will be documented to an official government document. I've drawn upon the Pentagon Papers. Are you all familiar with the Pentagon Papers? And the Senate and House investigations of the Agency and a variety of other material. So don't believe what I say, but if you want to check up on me, the information is available.</p> 
 
<p>Secondly, I'd like to say my message is basically a real downer. It is real negative, but I don't want to leave you with that impression, because I just returned from a two week speaking trip in Iowa, where I was going to testify at the court case there in Iowa City for the protesters, and in Nebraska. And I've been in Arizona and various other places speaking, and wherever you go, you find concerned groups. So I am encouraged. I know during the Vietnam War for the first ten years, we didn't even know what was going on. And then eleven or twelve years later, people began to protest. But this time in Latin America, the protest was almost instantaneous. The substructure is there. The only reason we got out of Vietnam, of course, is because of the student protests. So I am very encouraged. My message is negative, but I don't want to leave you with that impression. I am very, very encouraged.</p> 
 
<p>I think I should talk in three basic phases. One, walk you very quickly through my career with the Agency up to right now where I am today, and back up and walk you through Vietnam a little bit or walk you through my career in a little more detail, including Vietnam. Now I do that not to talk about Vietnam but because the processes that are followed today in Central America, in the Middle East and in Africa have all been used in Vietnam. I'll take out three or four incidences, and they are documented by the way, and show you that these are sort of typical of what the Agency does around the world since the very beginning in '47, what it's doing today in '86.</p> 
 
<p>Then I'll go back and review the Agency's domestic operations, and I'll do that for one purpose, because everything they were doing up to the mid-seventies they are now doing again. The only difference now is under President Reagan's Executive Order 12333 of December '81, they can do the things legally that they were doing illegally before. It's the only difference. Then I would like to talk, sort of bring it all together in Central America and talk about El Salvador, Grenada, and particularly Nicaragua, and then come to my conclusion. So that's basically the approach I'll take.</p> 
 
<p>I went to the University of Notre Dame. I played on four undefeated football teams, three national championships, and then I tried out with the Green Bay Packers. And to this day, I can't understand what's the matter with the coaches up there. When I was cut, I received a cable, "Would you be interested in an important government position similar to the State Department in function?" My football background was not irrelevant. When I went down to Washington, I found that the class before me, my class, and the class after me were basically rejects from the National Football League, not the standard concept of an intelligent (He does say "intelligent" here, I think as a joke about football players) officer.</p> 
 
<p>Well, I served in the Agency for 25 years. The first 15 or 16 years, I believed that the CIA was sort of like a missionary organization, out saving the world for democracy and religion and gathering good intelligence to help our policymakers make good decisions. When I'd go into work in the morning, I'd feel a real pride that I'm part of the great crusade to stop the international communist conspiracy. All that began to change for me in Vietnam. That's when I began protesting.</p> 
 
<p>I should mention that I served my entire 25 years in the Directorate of Operations. Now, the Agency is broken down to basically four directorates, Administration, Science and Technology, Intelligence, and Operations. Administrators administrate. Science and Technology, they devise the sophisticated collection devices and monitor the results. The Directorate of Intelligence, that's the scholars who sit and read the reports that come in from around the world and then put out the final reports. And the Operators operate. The Directorate of Operations has two basic functions, covert operations and gathering intelligence covertly.</p> 
 
<p>Since it's my contention that the Agency is little more than a covert action agency, I will dwell a little bit on it. Now, covert action operations in broadest context can be described as those operations designed to overthrow or support foreign governments. Overthrow operations have four basic components, economic warfare, political warfare, psychological warfare, and economic warfare. In my 25 years in the Agency, I served overseas in Japan, in the Philippines, in Taiwan, six years or three tours in Thailand, and two years as the chief police adviser to the head of the Vietnamese Special Police. That's the equivalent of our FBI.</p> 
 
<p>As I said, my period of protests began around the Vietnam War. I for the next period within the Agency began protesting, and having no luck with those protests, I finally left the Agency in 1977. Now, in a stroke of real irony at this particular point, because they had assigned me to the CIA’s Siberia. When you escalate your protest, you become persona non grata. In '77 in a stroke of irony, they awarded me the Career Intelligence Medal and the Honorable Service Medal. Of course, I think I know why. They knew they had a loose cannon and they wanted to kind of damp me down, appease me a little bit. And I think that was the purpose of giving them to me.</p> 
 
<p>But I also earlier had won awards, two Vietnam service awards, a commendation from the director for devising a program of counterinsurgency and intelligence, and a variety of other CIA and foreign awards. Well, when I left the Agency, I testified before the Senate and House intelligence committees and before a variety of other Senate and House committees, all related to CIA activities.</p> 
 
<p>I immediately set about writing a book about my experiences. It took me three years to research and write the book, and then like all CIA officers, when you join the Agency, you have to sign a secrecy agreement. And as I said, I must now submit everything to the CIA for pre-publication review. I did, and they came back and they said they have identified approximately 400 security violations in my manuscript. And they returned it in little bits and pieces of paper, because some of these deletions ran up to several pages in length.</p> 
 
<p>Well, to defeat this process, I went through going through the public record and pulling out the identical information. And ultimately with this effort, I got virtually everything reinstated. There are a few little specifics that I didn't get reinstated, but for the most part they were all reinstated. I did in a few cases, they had deleted some very boring information, so I said rather than fight them over this one, let's just leave this comment, "Seven words deleted." It looks a lot sexier than mine. So I didn't fight them on all of them.</p> 
 
<p>Then I went looking for a publisher, a long hard process, and finally one publisher said, "You know, you've written a nice legal brief here. You make your points and then you have your citations to your information. But boy, it's dull as mud. Who would want to read a legal brief? So we will publish it if you'll rewrite it as a autobiography," which I did. I then resubmitted it to the CIA for pre-publication review. I didn't put any more secret details in there. I just added my personal life.</p> 
 
<p>At this time, William Casey had become Director of the CIA, and they in essence told me, "We're not going to let you publish a book." And I said, "Well, you can't stop me. Everything that's in the book, you have not only cleared for other people, it's not only in the public record, but you also cleared for me before. And the laws that you operate under say you may not reclassify information once it's been declassified and released." And their response in essence, "Well, that's tough. We're doing it anyhow. There's nothing you can do about it." Well, this was a very critical period. I just didn't know what to do. I really worried about this, because if they would've stopped me with that, then I would not be able to speak to you here this evening, because everything would have been classified.</p> 
 
<p>So I called <i>The Washington Post</i>, and <i>The Washington Post</i> ran a long exposé of how the CIA was violating the law by reclassifying information that was in the public domain, a violation of the law of the land. This public exposure forced the Agency to relent, and the book was finally released. Subsequent to the release of the book, I then traveled to Cuba, where we stayed about a week, and to Grenada, …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://ourhiddenhistory.org/entry/the-cia-s-deadly-deceits-and-the-vietnam-war-w-ex-cia-officer-ralph-mcgehee">https://ourhiddenhistory.org/entry/the-cia-s-deadly-deceits-and-the-vietnam-war-w-ex-cia-officer-ralph-mcgehee</a></em></p>]]>
            </description>
            <link>https://ourhiddenhistory.org/entry/the-cia-s-deadly-deceits-and-the-vietnam-war-w-ex-cia-officer-ralph-mcgehee</link>
            <guid isPermaLink="false">hacker-news-small-sites-25329913</guid>
            <pubDate>Mon, 07 Dec 2020 06:45:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[TeX: A Tale of Two Worlds]]>
            </title>
            <description>
<![CDATA[
Score 28 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25329049">thread link</a>) | @Bella-Xiang
<br/>
December 6, 2020 | https://bitbashing.io/tex.html | <a href="https://web.archive.org/web/*/https://bitbashing.io/tex.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
    <!-- for XeTeX -->


<p>Best viewed in <del>Internet Explorer 6</del>
<a href="https://assets.bitbashing.io/papers/tex-tale-of-two-worlds.pdf">PDF</a>
because… well… read the damn thing.</p>

<!--
It all started when a college friend told me about a cool program for typesetting
papers. Now typography books litter my apartment and I can't read a menu
without noticing bad kerning. Thanks, Max. This is all your fault.
-->

<hr>

<p>Most serious programmers have heard of Donald Knuth,
the man who coined the term <em>analysis of algorithms</em> in 1968
and pioneered many of the computer science fundamentals we use today.
Knuth is perhaps most famous for his ongoing magnum opus,
<em>The Art of Computer Programming</em>.</p>

<p>When the first volume of TAOCP was released that same year,
it was printed the way most books had been since the turn of the century:
with <em>hot metal</em> type.
Each individual letter was cast from molten lead,
then arranged into its line.</p>

<figure>
<img src="https://upload.wikimedia.org/wikipedia/commons/7/72/Matrixcase-bembo-16pts.jpg" alt="Monotype matrix case" height="400">
<figcaption>
A case of letter molds—or <em>matrices</em>—used by the Monotype caster,
the most commonly-used machine for printing books in the days of hot metal type.
Its main contemporary, the Linotype, molded entire lines at a time,
and was often used for printing newspapers.
</figcaption>
</figure>

<p>These lines were clamped together to form pages of the book,
which were finally inked and pressed against paper.
By March of 1977, Knuth was ready for a second run of TAOCP, Volume&nbsp;2,
but he was horrified when he received the proofs.
Hot metal typesetting was an expensive, complicated, and time-consuming process,
so publishers had replaced it with phototypesetting,
which works by projecting characters onto film.
The new technology, while much cheaper and faster,
didn’t provide the same level of quality he had come to expect.</p>

<p>The average author would have resigned themselves to the change and moved on,
but Knuth took great pride in print quality,
especially for the mathematics in his books.
Around this time, he discovered an exciting new technology:
digital typesetting.
Instead of working with metal or film,
letters and shapes were built from tiny dots,
often packed together at over 1,000 per inch.
Inspired by this burgeoning tech and frustrated with the current state of affairs,
Knuth set off on one of the greatest yak shaves of all time.
For years, he paused all work on his books to create his own
digital typesetting system.
When the dust settled in 1978, Knuth had the first version of
<span>T<sub>e</sub>X</span>
.<sup id="fnref:1"><a href="#fn:1">1</a></sup></p>

<p>It’s hard to understand how much of a revolution <span>T<sub>e</sub>X</span>
 was,
especially looking back from a time where anybody with a copy
of Word can be their own desktop publisher.
Adobe’s PDF wouldn’t exist for another decade, so Knuth
invented a device-independent format, DVI.
Scalable fonts were uncommon at the time, so Knuth created a system,
<span>METAFONT</span>
, to rasterize his characters into dots on the
page.<sup id="fnref:2"><a href="#fn:2">2</a></sup>
Perhaps most importantly, Knuth and his graduate students designed algorithms
to automatically hyphenate and justify lines of text into
beautifully-typeset paragraphs.</p>

<p>Here is where the timelines diverge.
In one, <span>T<sub>e</sub>X</span>
 was just the beginning.
Computer typography evolves rapidly as the decades go by,
building on Knuth’s prior work and
taking advantage of the million-fold increases we’ve seen in computing power.
Browsers, e-readers, and word processors deliver beautiful type
to every person who looks at a screen, with almost no effort from authors.</p>

<p>In the darker timeline… none of this happens.
<span>T<sub>e</sub>X</span>
 is still some of the best we’ve got for computer typesetting.
It’s seen some impressive improvements,<sup id="fnref:3"><a href="#fn:3">3</a></sup>
but its core hasn’t changed much in decades.
To this day,
it doesn’t lay out more than one page at a time because 1980s computers didn’t
have enough RAM to do any better.<sup id="fnref:4"><a href="#fn:4">4</a></sup>
Almost no other software—except for a handful of professional layout
programs like Adobe InDesign—leverages any of the advances
<span>T<sub>e</sub>X</span>
 made in line breaking and hyphenation.
Layout in Word, browsers, and even e-readers is a sad joke.</p>

<figure>
<img src="https://assets.bitbashing.io/images/exa.png" alt="Mobile browser layout example" height="400">
<figcaption>
State of the art text layout in today's browsers. Mind the gaps.
</figcaption>
</figure>

<p>I’m not sure what to make of this.
Maybe most people, outside a small cadre of designers and
enthusiasts, just don’t care about typography very much.
After all, the human brain is incredibly good glossing over minor details and
im<span>p</span>erfections when reading.
But even the design world seems largely unaware or indifferent to Knuth’s work.
Despite collaborations with famous type designers like Hermann Zapf,
you’ll find no mention of him in renowned books and documentaries on
the subject.<sup id="fnref:5"><a href="#fn:5">5</a></sup>
And parametric font families—just like the ones <span>METAFONT</span>
 offered in 1983—are
heralded in 2017 as “a new era of type design”.<sup id="fnref:6"><a href="#fn:6">6</a></sup>
It’s bizarre.</p>

<p>Good typography can make almost anything more enjoyable to read,
and it feels like such a shame that better layout isn’t
available to the masses
when so much of the groundwork was laid almost forty years ago.
In an age when the average American reads from a screen they keep in their pocket
dozens of times a day,
and where each one of those devices holds more processing power than you could
fit in several rooms back when Donald Knuth
wrote <span>T<sub>e</sub>X</span>
, surely we can—and <em>should</em>—do better.</p>

<hr>



  </article></div>]]>
            </description>
            <link>https://bitbashing.io/tex.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25329049</guid>
            <pubDate>Mon, 07 Dec 2020 03:23:48 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Three Cheers for Solutionism?]]>
            </title>
            <description>
<![CDATA[
Score 44 | Comments 33 (<a href="https://news.ycombinator.com/item?id=25328149">thread link</a>) | @panic
<br/>
December 6, 2020 | https://aelkus.github.io/theory/2020/12/03/solu.html | <a href="https://web.archive.org/web/*/https://aelkus.github.io/theory/2020/12/03/solu.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody"><p>Economist Noah Smith <a href="https://noahpinion.substack.com/p/climate-change-isnt-that-hard">is fed up with</a> generic critiques of technological “solutionism,” specifically what he calls the “2010s consensus that technology is a sideshow compared to social movements.”</p>

<blockquote>
  <p>In the last decade, we’ve basically been taught to deride “solutionism” — while Silicon Valley techbros were bending their genius toward figuring out ways to sell more ads or lower taxi drivers’ wages, inequality was running rampant and parents were struggling to feed their kids. Instead of trusting wizardry to solve the world’s problems, we were supposed to place our faith in politics, in mass action, and in cultural change.</p>

  <p>Except then consider what happened with COVID. Our leaders failed to fight the virus effectively, and the President actively sabotaged containment efforts. Culturally, we screeched our heads off about masks and herd immunity and “just the flu” and beach parties and school closings and bar closings and restaurant closings and dorm closings and so on and so forth. We didn’t implement strict lockdowns and we protested against lockdowns and we didn’t even obey the half-assed lockdowns we did implement. We became one of the planet’s worst-hit countries, despite having the planet’s most expensive health care system. We died in the red states, we died in the blue states. We died in droves, in hundreds of thousands. Collectively, as a society, we wrung our hands and ran in circles and screeched and died and screeched and died and screeched and died until scientists made vaccines against the virus.</p>
</blockquote>

<p>Is this correct? In some ways, Smith stacks the deck in his favor. Scientific breakthroughs on vaccines can be produced by small groups of experts insulated from public pressure and the clown show of 21st century American politics. This was never the case with non-pharmaceutical interventions, even if I share Smith’s sense out of outrage and horror over America’s failed response to COVID.</p>

<p>Comparing them is a little akin to comparing World War II’s military-technical research achievements to the great campaigns of Europe and the Pacific War. The latter required extensive political and organizational coordination on a hitherto unprecedented scale, and buy-in from millions of ordinary people. The former were not exactly a bunch of eggheads in a seminar room, but they represent at least crudely processes that are largely autonomous from the need to attain large-scale consensus and cooperation.</p>

<p>Come next year, when we enter into the challenge of rolling out vaccines while preserving basic social distancing measures, we will get a reminder of how different these two kinds of activities are. I’m more optimistic that next year will be significantly better than 2020 was, but only guardedly. However, Smith is also on to something larger when he notes the dubious framing of how the answer to engineering our way to nirvana is supposed to be large-scale political and cultural change driven by mass popular mobilization.</p>

<p>‘Political solution’ in this framing seems to be a euphemism for either a deliberative process that harmonizes competing views or (more often) the imposition of one’s will on the body politic via political struggle. Neither look particularly promising in a polarized society in which merely putting on a piece of cloth held together with string has become a <a href="https://www.pewresearch.org/politics/2020/06/25/republicans-democrats-move-even-further-apart-in-coronavirus-concerns/">partisan issue</a>. Moreover, Smith <a href="https://www.bloomberg.com/opinion/articles/2019-10-17/california-is-back-on-the-brink-of-being-a-failed-state">observes elsewhere</a> that even in my home state of California – where GOP opposition has been virtually eradicated – single-party dominance has failed to resolve basic governance issues.</p>

<p>Certainly most thoughtful critics of techno-determinism likely will say that they aren’t categorically against the use of technology, but rather criticize a particular mindset that uncritically postulates that objective solutions can be discovered to objectively framed problems and then objectively implemented and accepted by a mostly cooperative public. However, it is hard to tell if they are talking about the technologists or themselves when they make this criticism. Statements like “if only we had the political will” to do something of interest are just as naive as “if only we had the right app.”</p>

<p>Technologists are often criticized for wanting to ‘route around’ the US political system, but <a href="https://www.pewresearch.org/fact-tank/2019/07/22/key-findings-about-americans-declining-trust-in-government-and-each-other/">given</a> low institutional trust and increasingly low interpersonal trust, it is difficult to be entirely critical of that desire. The biggest problem with it is that it often devolves into fantasies of taking one’s toys and exiting into an autonomous space free of the need to gain mass consensus (seasteading!) or instituting impersonal mechanisms that suppress political resistance (make the AI president!) There are idiots. Look around. But we’re all idiots in some shape or form and we’re stuck with each other. What do we do next?</p>

<p>First, somewhat of a meta-point: indirection often is a very underrated way of creating change. Part of what this post is looking to encourage is something I sometimes refer to as the “Andrew Marshall style” of change. For decades, Marshall headed up the Office of Net Assessment (ONA) within the United States Department of Defense. Most people interested in defense and strategy, including yours truly, have in some way directly or indirectly benefited from ONA and its projects. But Marshall did so largely below the radar.</p>

<p>Demanding only autonomy, a tiny (by Pentagon standards) budget, a small office, and the freedom to report directly to the Secretary of Defense, Marshall at first glance took a rather counter-intuitive approach. But this was actually critical to his success. He was not a threat to other people’s bureaucratic rice bowls. But he preserved his own autonomy. And by slowly building up a network of relationships and becoming a hub for innovative work, ONA ended up exercising a profound influence on American national security and defense.</p>

<p>What is remarkable about Marshall’s success is that he propagated his particular institutional relationships forward through decades of changing political, economic, and bureaucratic turmoil while slowly altering the surrounding environment around him. It would be ridiculous to assert that Marshall is singularly responsible for any particular major shift in American national security and defense, but it is also very evident that ONA’s presence and persistence changed the boundary conditions of the US defense and security system.</p>

<p>While many technologists often valorize another Cold War American defense icon – John Boyd – Marshall is also a model worth emulating. Technology is complicated, frustrating, and more often than not disappointing relative to our ambitions. But it can change the boundary conditions of problems. Tweaking the boundary conditions of problems is a big part of how meaningful change can happen overall.</p>

<p>Getting 2-3 promising vaccines in under a year is a great example. Vaccines do not change the massive amount of political and institutional failures America has experienced since the COVID-19 outbreak began. However, consider the alternative world without vaccines that we were in only a short time ago. We had all of those problems but without any kind of roadmap as to how we might escape them. Now we have a <a href="https://www.forbes.com/sites/carlieporterfield/2020/11/15/heres-when-experts-say-things-could-get-back-to-back-to-normal-after-coronavirus/?sh=3f66c9d936ed">hazy but nonetheless meaningful</a> idea of how long it could take to get back to normal, even if there is no really coherent shared idea of ‘normality.’ This is worth celebrating!</p>

<p>Even without a vaccine, we would be much worse off than we are now if everything from the physical network backbone to distributed work solutions did not perform well under significant stress. The Internet, also created originally in part for the purpose of scientific collaboration, enabled scientific researchers around the world to work together at breakneck speed to learn as much as possible about a novel virus and figure out how to attack it. Outside of the US and most <a href="https://www.atlanticcouncil.org/blogs/new-atlanticist/lessons-from-taiwans-experience-with-covid-19/">successfully in Taiwan</a>, governments have also found success in working together with the private sector to manage information flows during the pandemic.</p>

<p>Beyond COVID, what might this mean? Even in the best of times, the <a href="https://texaspolitics.utexas.edu/archive/html/bur/features/0303_02/muddling.html">most</a> we can often accomplish on the most intractable social problems is to <a href="https://texaspolitics.utexas.edu/archive/html/bur/features/0303_02/muddling.html">muddle through</a>. They have <a href="https://link.springer.com/article/10.1007/BF01405730">no inherent point</a> at which they officially stop being problems, and often no inherently correct shared framing. It doesn’t mean that action is pointless, but true students of politics often understand that politics is a secular activity instead of a means of bringing about religious salvation.</p>

<p>It seems unwise to stake our hopes on some kind of decisive reckoning at which political solutions will somehow materialize and then be imposed on our friends, neighbors, and co-workers. Much for the same reason that many of us find that we cannot get even members of our own family to take sensible COVID precautions no matter how much we plead, cajole, and threaten them. Still, we have also seen what happens when we simply stand still and do nothing.</p>

<p>“Techno-scientific” changes in the surrounding environment can do a number of salient things. They can provide tools we did not have before to mitigate problems. They can subtly influence or even shift the dynamics of particular interpersonal and institutional relationships and interactions. New frontiers to explore can distract people that otherwise would make trouble, and a bigger pie can make people feel more generous than they otherwise would be. While much has been made of the costs of technological disruption, breaking up established social hierarchies can be necessary for the system as a whole to survive and grow.</p>

<p>Preventing stasis and injecting more slack into the system are both means to the same end: propagating the system forward into the future. So technological “solutionism” (a term I have always disliked due to its imprecision), is both more and less important than ever. It certainly falls short of the hopes of its biggest boosters and the fears of its opponents. But if you are a technologist looking to make a difference now is as good of a …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://aelkus.github.io/theory/2020/12/03/solu.html">https://aelkus.github.io/theory/2020/12/03/solu.html</a></em></p>]]>
            </description>
            <link>https://aelkus.github.io/theory/2020/12/03/solu.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25328149</guid>
            <pubDate>Mon, 07 Dec 2020 00:40:41 GMT</pubDate>
        </item>
    </channel>
</rss>
