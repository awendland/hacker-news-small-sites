<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 20]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 20. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Sat, 21 Nov 2020 08:24:53 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-20.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Sat, 21 Nov 2020 08:24:53 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[The Mac is losing me]]>
            </title>
            <description>
<![CDATA[
Score 29 | Comments 35 (<a href="https://news.ycombinator.com/item?id=25146808">thread link</a>) | @lawik
<br/>
November 18, 2020 | https://underjord.io/the-mac-is-losing-me.html | <a href="https://web.archive.org/web/*/https://underjord.io/the-mac-is-losing-me.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
        
        <small>2020-11-18</small>
        <p>I’ve been mostly happy using a Mac since I got myself my first computer earned with programmer money. I believe it was a mid 2009 15" MacBook Pro. That was a computer I used at least until 2016 which I consider very decent usable life. At that point I had replaced the hard-drive with an SSD, upgraded the RAM and switched a battery that was worn out. I stopped using it when it just straight died some time in 2016.</p>
<h2 id="my-history-with-the-mac">My history with the Mac</h2>
<p>So what was that computer to me? It was an extremely well-built and solid-feeling piece of aluminium. A cool keyboard backlight. The magsafe charger and a bunch of USB ports. The keyboard and touchpad were best in class. The build quality was better than any laptop I had owned before. Partly because I had only bought the cheap ones before but also because they really were a step above at the time.</p>
<p>I got it primarily on recommendation from a friendly hacker who’s recommendations had never lead me wrong before. He spoke well of the underlying UNIX and the experience of using it. Fast, clean and visually pleasing. I think he mostly really liked the backlit keyboard, very hackerly. His recommendation held true, this computer was very good to me.</p>
<p>I’ve also been the admin on an Xserve server. That was wild. Neat UIs but buggy and finicky as all hell.</p>
<p>Since then I’ve used the second generation Macbook Air (I believe 2nd, first wedge version) at 11". That was a cool little machine and did what it did very nicely.</p>
<p>Hardware aside, MacOS in it’s earlier incarnations on these computers was always a snappy and competent experience. A polished surface which did a bunch of stuff under the hood that generally made it work better than the different Ubuntu desktop environments and various Windows versions I’ve had before. Things like Wifi and even Bluetooth felt good in a way they never had before.</p>
<p>A lot of it was the visual polish and the extremely snappy UI. But in total the experience was just great. Spotlight was glorious. I think my first upgrade was Snow Leopard which was generally a very good update as it focused on performance and stability.</p>
<p>As a developer’s machine it was fast enough, competent enough, got out of the way and the UNIX underpinnings meant I didn’t miss Linux at all. I’ve never been able to really connect with the equivalent powershell stuff in Windows. I guess I just like UNIX.</p>
<p>The only bad thing I can say about my early years of MacBook Pro usage was that the trackpad and the Magic Trackpad I got eventually are probably some of the biggest culprits in some of the RSI-style hand pain I’ve been dealing with. Trackpads are just murder on my hands and I worked loads off of that setup for a number of years. Took a while before I realized that it was trackpad-related.</p>
<p>Beyond that I’ve had some refurb Macs for my wife and assorted family, some 13" MBP for work at one point and then a 15" butterfly touchbar MBP for work. I think that was when I started to feel that Apple was diverging from my preferences in the MBP line.</p>
<h2 id="my-current-experience">My current experience</h2>
<p>That’s the same computer I have and work on now and it is.. fine? Maybe just OK. Not great. I’ve had some keys getting stuck but fixable with canned air. I don’t like the touchbar, it has been between useless and an actual hindrance. The TouchID power button is good though. I don’t like living in dongle-town though I mostly like USB C in the long run.</p>
<p>The reason it has been mostly fine for me is that I keep it on tray mounted on a VESA arm, dangling dongles like a technical octopus and I use external peripherals for input.</p>
<p>It gets really hot and loud and then it performs incredibly poorly. So I guess this is one of the throttliest generations. I think I had the “don’t charge it on the wrong side” problem as well. Some of the CPU shenanigans have calmed down as I installed the Turbo Boost Switcher tool to just disable the Turbo Boost, removing performance for peace and quiet.</p>
<p>As I’ve been using these devices it has become increasingly annoying to figure out how to install “unknown” apps. I need some non-discoverable terminal incantation to get the option to accept installing things that are unsigned. There’s always a new piece getting locked down. And while I think that’s often to the benefit of the average consumer, I’m not that. And I just get more annoyed.</p>
<p>I’ve been frustrated about the uninspiring performance delivered for the incredible brand markup that Apple charges. I don’t mind the computer being expensive if the experience is good and the hardware reasonable. The experience feels like it is slipping, especially for my needs and the hardware has just been getting less impressive to me.</p>
<h2 id="the-hardware">The hardware</h2>
<p>My gaming computer has a Ryzen. For a while I did my dev on that as we had just moved to our house and the office wasn’t finalized. Woof, aside from running Windows as a dev environment which I didn’t enjoy there was some serious upside on that machine.</p>
<p>On the Mac my options are very limited. I can’t get a Ryzen, I can’t get anything modern with Intel or meaningfully upgradable at all. The Mac Pro doesn’t count. It comes underspeced at hilarious prices. I like some of the design decisions but the price-point doesn’t make any kind of sense for me and what I do. I can’t buy an interesting Mac from a performance standpoint.</p>
<p>Or can I? Well, they just announced the M1 chip and ARM Macs are now a fact. I think I might get one at some point. For a travel laptop I don’t think the rest of the industry is ready to fight Apple. Battery life and good bang for buck power might actually keep a Mac in my life for that. But I feel like the general trend is away from what I want. Or I might just use my iPad Pro for that use-case.</p>
<p>I think the M1 will be quite impressive when the benchmarks roll in. I’m sure it will suit many people for real-world use-cases as well. However, from the first presentation on it and the first batch of Macs I don’t feel like the direction is for me. IO was heavily sacrificed. Upgradability is pretty much out the window. These things can be fine for a travel device for me where battery and weight are primary concerns. In that regard the new Air looks pretty good.</p>
<h2 id="the-software">The software</h2>
<p>Beyond that the coming OS, Big Sur, is taking MacOS in a direction I dislike. Catalina was quite messy and felt like it took steps toward walling off the Mac. Big Sur seems even more heavy-handed in that area and finally the M1 can push that even further if Apple feels like it. My trust is eroding on letting Apple set the tone for my computing life.</p>
<p>Don’t get me wrong, I think their approach to this transition is incredibly neat with Rosetta2 and how they are using the bytecode stuff with the App Store and whatnot. And the possibility to run iOS and iPad apps natively could be very useful. But none of this really moves the needle for me.</p>
<h2 id="so-whats-next">So what’s next?</h2>
<p>With my office in the garage as my primary work location I’m looking to transition to a desktop computer with lots of power. It will run Linux. Marking my first major return to desktop linux as a daily driver in a bundle of years. And it will run as light a desktop environment as I can stomach. I just wanted a stupid amount of performance to offset som of the UX niceties I know I will miss or have to customize  on my own.</p>
<p>I’m excited about exercising my development tools on a strong modern CPU rather than the throttled mess my current laptop offers. But I’m not thrilled about this move beyond the hardware aspect. I liked MacOS but I just don’t feel like Apple gives much of a care for the things I care about. And I feel like the software side on the Mac is slipping, consistently.</p>
<p>If they released an expandable Mac that wasn’t ridiculously expensive they would really make me think twice. But that feels unlikely.</p>
<p>So I’ll build myself a monstrous machine that can compensate in raw power for the potential lack of elegance and which offers unbounded flexibility rather than a poorly tended garden that someone keeps trying to wall in.</p>
<p>I’m not happy about it. I’ve generally enjoyed using my Macs. But when someone says “we’ll give you the full experience”, settling into that requires trust. And my trust that Apple and me are in alignment keeps fading.</p>
<p>Also, I’m developing a lot with heavily concurrent workloads. So I really look forward to exercising more cores. 2021, year of the Linux desktop (for me).</p>
<p>If you have thoughts, comments or a hell yeah you want to share about this topic or maybe you want me to cover some specific part of my transition here, let me know either via <a href="mailto:lars@underjord.io">lars@underjord.io</a> or on Twitter <a href="https://twitter.com/lawik">@lawik</a>. My first thoughts and my build might just show up first on my newsletter, so consider signing up for that below. It don’t track. Thanks for reading.</p>

    </article></div>]]>
            </description>
            <link>https://underjord.io/the-mac-is-losing-me.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25146808</guid>
            <pubDate>Thu, 19 Nov 2020 06:29:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[RPC DRAM support in open source DRAM controller]]>
            </title>
            <description>
<![CDATA[
Score 25 | Comments 5 (<a href="https://news.ycombinator.com/item?id=25145897">thread link</a>) | @pabs3
<br/>
November 18, 2020 | https://antmicro.com/blog/2020/10/rpc-dram-support-in-litedram/ | <a href="https://web.archive.org/web/*/https://antmicro.com/blog/2020/10/rpc-dram-support-in-litedram/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
        
        <p>
          <span>Published:</span>
          <time>Oct 28 2020</time>
        </p>
          <p>
            <span>Topics:</span>
            open hardware, open ASICs, open FPGA</p>
      </div><div>
        <p>The Internet of Things is one of the areas that is hugely benefiting from miniaturization of semiconductor technologies, as more computing power can be encapsulated into increasingly smaller devices. Shrinking in size and requiring less power, various devices - including AI-capable ones - are applied in ways that were not possible a few years ago. One of the new and exciting developments in this space is the emergence of <a href="https://etronamerica.com/products/rpc-dram/">RPC (reduced pin-count) DRAM</a> - a small form factor memory, for which Antmicro has developed support in the open source memory controller, LiteDRAM. Our contribution, already made available on <a href="https://github.com/antmicro/litedram/tree/rpc-dram-support">GitHub</a> is being polished and undergoing final tests, and will be mainlined shortly.</p>

<h3 id="what-is-rpc-dram">What is RPC DRAM</h3>

<p>Standard modern DRAM chips, with their small but not miniscule footprints and rather high I/O requirements, are impossible to use in space-constrained applications. By using a large number of pins in the device they connect to, they can also push the envelope of the device itself even more, requiring larger and more expensive packages of the FPGA or SoC used. <br>
And while many edge devices could easily do with a smaller amount (e.g. sub-1Gb) of RAM than what modern memory parts offer, it is impossible to cut a RAM chip in half and get less memory capacity. Well, at least until now - kind of.</p>

<p>The so-called RPC (Reduced Pin Count) DRAM - a new technology from Etron - has the potential to profoundly impact the AI, IoT and VR/AR markets. It is a tiny memory chip family which can get as small as 1.96mm x 4.63mm, offering 256Mbits and high bandwidth (the same as DDR3) using only 10% of the DDR3 PCB area and only half of the SoC or FPGA pins that the DDR3 memory takes up. Its clock speed can go up to 1200MHz, with bandwidth of up to 4800 Mb/s.</p>

<p><img src="https://antmicro.com/blog/images/LiteDRAM_with_RPC_RAM_blog-note.png" alt="DDR RAM and RPC DRAM comparison"></p>

<p>RPC DRAM is ideal for space-constrained edge AI applications that locally process data such as video, audio or image, where, apart from space saving, low power consumption is critical. The small number of pins used by RPC DRAM leaves more available resources for other system functionalities, while the possibility of stacking multiple RPC DRAM chips on top of one another for further layout optimization makes the technology even more appealing. It also enables interesting scenarios like <a href="https://antmicro.com/blog/2020/10/open-chiplet-initiative/#future-developments">embedding in a chiplet-based SiP</a>, or even bare-die integration with small FPGAs for a powerful, Linux-capable device. But to use the memory with FPGAs, you need to interface with it using a DRAM controller - and that is where our latest work with LiteDRAM comes in.</p>

<h3 id="litedram-and-open-source-ip-ecosystem">LiteDRAM and open source IP ecosystem</h3>

<p>LiteDRAM is a configurable memory controller that is part of LiteX, an open source SoC builder that we are developing and using to design FPGA-based systems. By creating support for RPC DRAM in LiteDRAM we have enabled the miniscule memory to be added to products that we build and to the whole LiteX ecosystem. This enables our customer’s devices to run more compute-hungry applications or full-fledged operating systems such as Linux in dedicated SoCs created by Antmicro on demand.</p>

<p>We use and contribute to LiteDRAM, LiteX and other open source IP to develop unique designs interfaced with DDR memories for high-bandwidth video and other data processing systems; and RPC DRAM support is just one example of the enablement work we are performing in the ecosystem. Combined with the exciting work related to open source we are performing as part of <a href="https://antmicro.com/blog/2020/07/swerv-cores-tools-ecosystem/">CHIPS Alliance</a>, <a href="https://antmicro.com/blog/2020/06/skywater-open-source-pdk/">SkyWater PDK</a> and the fantastic enregy catalyzed by the open <a href="https://antmicro.com/technologies/risc-v/">RISC-V</a> CPU architecture (which is an obvious candidate for combining with RPC RAM both in soft- and hard CPU contexts), future is looking bright for tiny, open, ML-capable systems.</p>

<h3 id="antmicros-open-source-fpga-ip">Antmicro’s open source FPGA IP</h3>

<p>We often use FPGAs to build a wide array of configurable systems for our customers, leveraging the flexibility and customizability that this technology offers. We create open source FPGA IPs that are reusable across various designs and platforms without any licensing restrictions imposed on our customers. Antmicro’s open source IP cores portfolio includes MIPI CSI, MIDI, PCIe, USB, Ethernet etc.</p>

<p>The FPGA systems that we build consist of modern, vendor-neutral components that ensure future-proofness and give our clients full control over the product. Reach out to us at <a href="mailto:contact@antmicro.com">contact@antmicro.com</a> if you’d like to get a specialized FPGA-based system performing complex tasks.</p>

      </div></div>]]>
            </description>
            <link>https://antmicro.com/blog/2020/10/rpc-dram-support-in-litedram/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25145897</guid>
            <pubDate>Thu, 19 Nov 2020 03:29:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Changes to the pip dependency resolver in 20.3]]>
            </title>
            <description>
<![CDATA[
Score 47 | Comments 15 (<a href="https://news.ycombinator.com/item?id=25145396">thread link</a>) | @di
<br/>
November 18, 2020 | https://pip.pypa.io/en/latest/user_guide/#changes-to-the-pip-dependency-resolver-in-20-2-2020 | <a href="https://web.archive.org/web/*/https://pip.pypa.io/en/latest/user_guide/#changes-to-the-pip-dependency-resolver-in-20-2-2020">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="user-guide">

<div id="running-pip">
<h2>Running pip<a href="#running-pip" title="Permalink to this headline">¶</a></h2>
<p>pip is a command line program. When you install pip, a <code><span>pip</span></code> command is added
to your system, which can be run from the command prompt as follows:</p>
<div>
<p><label for="tab-set--0-input--1">Unix/macOS</label></p><div>
<div><div><pre><span></span>python -m pip &lt;pip arguments&gt;
</pre></div>
</div>
<p><code><span>python</span> <span>-m</span> <span>pip</span></code> executes pip using the Python interpreter you
specified as python. So <code><span>/usr/bin/python3.7</span> <span>-m</span> <span>pip</span></code> means
you are executing pip for your interpreter located at /usr/bin/python3.7.</p>
</div>
<p><label for="tab-set--0-input--2">Windows</label></p><div>
<div><div><pre><span></span>py -m pip &lt;pip arguments&gt;
</pre></div>
</div>
<p><code><span>py</span> <span>-m</span> <span>pip</span></code> executes pip using the latest Python interpreter you
have installed. For more details, read the <a href="https://docs.python.org/3/using/windows.html#launcher">Python Windows launcher</a> docs.</p>
</div>
</div>
</div>
<div id="installing-packages">
<h2>Installing Packages<a href="#installing-packages" title="Permalink to this headline">¶</a></h2>
<p>pip supports installing from <a href="https://pypi.org/">PyPI</a>, version control, local projects, and
directly from distribution files.</p>
<p>The most common scenario is to install from <a href="https://pypi.org/">PyPI</a> using <a href="https://pip.pypa.io/en/latest/reference/pip_install/#requirement-specifiers"><span>Requirement Specifiers</span></a></p>
<div>
<p><label for="tab-set--1-input--1">Unix/macOS</label></p><div>
<div><div><pre><span></span>python -m pip install SomePackage            <span># latest version</span>
python -m pip install <span>SomePackage</span><span>==</span><span>1</span>.0.4     <span># specific version</span>
python -m pip install <span>'SomePackage&gt;=1.0.4'</span>     <span># minimum version</span>
</pre></div>
</div>
</div>
<p><label for="tab-set--1-input--2">Windows</label></p><div>
<div><div><pre><span></span>py -m pip install SomePackage            <span># latest version</span>
py -m pip install <span>SomePackage</span><span>==</span><span>1</span>.0.4     <span># specific version</span>
py -m pip install <span>'SomePackage&gt;=1.0.4'</span>     <span># minimum version</span>
</pre></div>
</div>
</div>
</div>
<p>For more information and examples, see the <a href="https://pip.pypa.io/en/latest/reference/pip_install/#pip-install"><span>pip install</span></a> reference.</p>
</div>
<div id="basic-authentication-credentials">
<h2>Basic Authentication Credentials<a href="#basic-authentication-credentials" title="Permalink to this headline">¶</a></h2>
<p>pip supports basic authentication credentials. Basically, in the URL there is
a username and password separated by <code><span>:</span></code>.</p>
<p><code><span>https://[username[:password]@]pypi.company.com/simple</span></code></p>
<p>Certain special characters are not valid in the authentication part of URLs.
If the user or password part of your login credentials contain any of the
special characters
<a href="https://en.wikipedia.org/wiki/Percent-encoding#Percent-encoding_reserved_characters">here</a>
then they must be percent-encoded. For example, for a
user with username “user” and password “he//o” accessing a repository at
pypi.company.com, the index URL with credentials would look like:</p>
<p><code><span>https://user:he%2F%2Fo@pypi.company.com</span></code></p>
<p>Support for percent-encoded authentication in index URLs was added in pip 10.0.0
(in <a href="https://github.com/pypa/pip/issues/3236">#3236</a>). Users that must use authentication
for their Python repository on systems with older pip versions should make the latest
get-pip.py available in their environment to bootstrap pip to a recent-enough version.</p>
<p>For indexes that only require single-part authentication tokens, provide the token
as the “username” and do not provide a password, for example -</p>
<p><code><span>https://0123456789abcdef@pypi.company.com</span></code></p>
<div id="netrc-support">
<h3>netrc Support<a href="#netrc-support" title="Permalink to this headline">¶</a></h3>
<p>If no credentials are part of the URL, pip will attempt to get authentication credentials
for the URL’s hostname from the user’s .netrc file. This behaviour comes from the underlying
use of <a href="https://requests.readthedocs.io/en/master/user/authentication/#netrc-authentication">requests</a> which in turn delegates it to the <a href="https://docs.python.org/3/library/netrc.html">Python standard library</a>.</p>
<p>The .netrc file contains login and initialization information used by the auto-login process.
It resides in the user’s home directory. The .netrc file format is simple. You specify lines
with a machine name and follow that with lines for the login and password that are
associated with that machine. Machine name is the hostname in your URL.</p>
<p>An example .netrc for the host example.com with a user named ‘daniel’, using the password
‘qwerty’ would look like:</p>
<div><div><pre><span></span>machine example.com
login daniel
password qwerty
</pre></div>
</div>
<p>As mentioned in the <a href="https://docs.python.org/3/library/netrc.html">standard library docs</a>,
only ASCII characters are allowed. Whitespace and non-printable characters are not allowed in passwords.</p>
</div>
<div id="keyring-support">
<h3>Keyring Support<a href="#keyring-support" title="Permalink to this headline">¶</a></h3>
<p>pip also supports credentials stored in your keyring using the <a href="https://pypi.org/project/keyring/">keyring</a>
library. Note that <code><span>keyring</span></code> will need to be installed separately, as pip
does not come with it included.</p>
<div><div><pre><span></span>pip install keyring
<span>echo</span> your-password <span>|</span> keyring <span>set</span> pypi.company.com your-username
pip install your-package --extra-index-url https://pypi.company.com/
</pre></div>
</div>
</div>
</div>
<div id="using-a-proxy-server">
<h2>Using a Proxy Server<a href="#using-a-proxy-server" title="Permalink to this headline">¶</a></h2>
<p>When installing packages from <a href="https://pypi.org/">PyPI</a>, pip requires internet access, which
in many corporate environments requires an outbound HTTP proxy server.</p>
<p>pip can be configured to connect through a proxy server in various ways:</p>
<ul>
<li><p>using the <code><span>--proxy</span></code> command-line option to specify a proxy in the form
<code><span>[user:passwd@]proxy.server:port</span></code></p></li>
<li><p>using <code><span>proxy</span></code> in a <a href="#config-file"><span>Config file</span></a></p></li>
<li><p>by setting the standard environment-variables <code><span>http_proxy</span></code>, <code><span>https_proxy</span></code>
and <code><span>no_proxy</span></code>.</p></li>
<li><p>using the environment variable <code><span>PIP_USER_AGENT_USER_DATA</span></code> to include
a JSON-encoded string in the user-agent variable used in pip’s requests.</p></li>
</ul>
</div>
<div id="requirements-files">
<h2>Requirements Files<a href="#requirements-files" title="Permalink to this headline">¶</a></h2>
<p>“Requirements files” are files containing a list of items to be
installed using <a href="https://pip.pypa.io/en/latest/reference/pip_install/#pip-install"><span>pip install</span></a> like so:</p>
<div>
<p><label for="tab-set--2-input--1">Unix/macOS</label></p><div>
<div><div><pre><span></span>python -m pip install -r requirements.txt
</pre></div>
</div>
</div>
<p><label for="tab-set--2-input--2">Windows</label></p><div>
<div><div><pre><span></span>py -m pip install -r requirements.txt
</pre></div>
</div>
</div>
</div>
<p>Details on the format of the files are here: <a href="https://pip.pypa.io/en/latest/reference/pip_install/#requirements-file-format"><span>Requirements File Format</span></a>.</p>
<p>Logically, a Requirements file is just a list of <a href="https://pip.pypa.io/en/latest/reference/pip_install/#pip-install"><span>pip install</span></a> arguments
placed in a file. Note that you should not rely on the items in the file being
installed by pip in any particular order.</p>
<p>In practice, there are 4 common uses of Requirements files:</p>
<ol>
<li><p>Requirements files are used to hold the result from <a href="https://pip.pypa.io/en/latest/reference/pip_freeze/#pip-freeze"><span>pip freeze</span></a> for the
purpose of achieving <a href="#repeatability"><span>repeatable installations</span></a>.  In
this case, your requirement file contains a pinned version of everything that
was installed when <code><span>pip</span> <span>freeze</span></code> was run.</p>
<div>
<p><label for="tab-set--3-input--1">Unix/macOS</label></p><div>
<div><div><pre><span></span>python -m pip freeze &gt; requirements.txt
python -m pip install -r requirements.txt
</pre></div>
</div>
</div>
<p><label for="tab-set--3-input--2">Windows</label></p><div>
<div><div><pre><span></span>py -m pip freeze &gt; requirements.txt
py -m pip install -r requirements.txt
</pre></div>
</div>
</div>
</div>
</li>
<li><p>Requirements files are used to force pip to properly resolve dependencies.
pip 20.2 and earlier <a href="https://github.com/pypa/pip/issues/988">doesn’t have true dependency resolution</a>, but instead simply uses the first
specification it finds for a project. E.g. if <code><span>pkg1</span></code> requires
<code><span>pkg3&gt;=1.0</span></code> and <code><span>pkg2</span></code> requires <code><span>pkg3&gt;=1.0,&lt;=2.0</span></code>, and if <code><span>pkg1</span></code> is
resolved first, pip will only use <code><span>pkg3&gt;=1.0</span></code>, and could easily end up
installing a version of <code><span>pkg3</span></code> that conflicts with the needs of <code><span>pkg2</span></code>.
To solve this problem, you can place <code><span>pkg3&gt;=1.0,&lt;=2.0</span></code> (i.e. the correct
specification) into your requirements file directly along with the other top
level requirements. Like so:</p>
<div><div><pre><span></span><span>pkg1</span>
<span>pkg2</span>
<span>pkg3</span><span>&gt;=</span><span>1.0</span><span>,</span><span>&lt;=</span><span>2.0</span>
</pre></div>
</div>
</li>
<li><p>Requirements files are used to force pip to install an alternate version of a
sub-dependency.  For example, suppose <code><span>ProjectA</span></code> in your requirements file
requires <code><span>ProjectB</span></code>, but the latest version (v1.3) has a bug, you can force
pip to accept earlier versions like so:</p>

</li>
<li><p>Requirements files are used to override a dependency with a local patch that
lives in version control.  For example, suppose a dependency
<code><span>SomeDependency</span></code> from PyPI has a bug, and you can’t wait for an upstream
fix.
You could clone/copy the src, make the fix, and place it in VCS with the tag
<code><span>sometag</span></code>.  You’d reference it in your requirements file with a line like
so:</p>
<div><div><pre><span></span><span>git</span><span>+</span><span>https</span><span>:</span><span>//</span><span>myvcs</span><span>.</span><span>com</span><span>/</span><span>some_dependency</span><span>@sometag</span><span>#egg=SomeDependency</span>
</pre></div>
</div>
<p>If <code><span>SomeDependency</span></code> was previously a top-level requirement in your
requirements file, then <strong>replace</strong> that line with the new line. If
<code><span>SomeDependency</span></code> is a sub-dependency, then <strong>add</strong> the new line.</p>
</li>
</ol>
<p>It’s important to be clear that pip determines package dependencies using
<a href="https://setuptools.readthedocs.io/en/latest/setuptools.html#declaring-dependencies">install_requires metadata</a>,
not by discovering <code><span>requirements.txt</span></code> files embedded in projects.</p>
<p>See also:</p>
<ul>
<li><p><a href="https://pip.pypa.io/en/latest/reference/pip_install/#requirements-file-format"><span>Requirements File Format</span></a></p></li>
<li><p><a href="https://pip.pypa.io/en/latest/reference/pip_freeze/#pip-freeze"><span>pip freeze</span></a></p></li>
<li><p><a href="https://caremad.io/2013/07/setup-vs-requirement/">“setup.py vs requirements.txt” (an article by Donald Stufft)</a></p></li>
</ul>
</div>
<div id="constraints-files">
<h2>Constraints Files<a href="#constraints-files" title="Permalink to this headline">¶</a></h2>
<p>Constraints files are requirements files that only control which version of a
requirement is installed, not whether it is installed or not. Their syntax and
contents is nearly identical to <a href="#requirements-files"><span>Requirements Files</span></a>. There is one key
difference: Including a package in a constraints file does not trigger
installation of the package.</p>
<p>Use a constraints file like so:</p>
<div>
<p><label for="tab-set--4-input--1">Unix/macOS</label></p><div>
<div><div><pre><span></span>python -m pip install -c constraints.txt
</pre></div>
</div>
</div>
<p><label for="tab-set--4-input--2">Windows</label></p><div>
<div><div><pre><span></span>py -m pip install -c constraints.txt
</pre></div>
</div>
</div>
</div>
<p>Constraints files are used for exactly the same reason as requirements files
when you don’t know exactly what things you want to install. For instance, say
that the “helloworld” package doesn’t work in your environment, so you have a
local patched version. Some things you install depend on “helloworld”, and some
don’t.</p>
<p>One way to ensure that the patched version is used consistently is to
manually audit the dependencies of everything you install, and if “helloworld”
is present, write a requirements file to use when installing that thing.</p>
<p>Constraints files offer a better way: write a single constraints file for your
organisation and use that everywhere. If the thing being installed requires
“helloworld” to be installed, your fixed version specified in your constraints
file will be used.</p>
<p>Constraints file support was added in pip 7.1. In <a href="#resolver-changes-2020"><span>Changes to the pip dependency resolver in 20.3 (2020)</span></a> we did a fairly comprehensive overhaul, removing several
undocumented and unsupported quirks from the previous implementation,
and stripped constraints files down to being purely a way to specify
global (version) limits for packages.</p>
</div>
<div id="installing-from-wheels">
<h2>Installing from Wheels<a href="#installing-from-wheels" title="Permalink to this headline">¶</a></h2>
<p>“Wheel” is a built, archive format that can greatly speed installation compared
to building and installing from source archives. For more information, see the
<a href="https://wheel.readthedocs.io/">Wheel docs</a> , <span id="index-0"></span><a href="https://www.python.org/dev/peps/pep-0427"><strong>PEP 427</strong></a>, and <span id="index-1"></span><a href="https://www.python.org/dev/peps/pep-0425"><strong>PEP 425</strong></a>.</p>
<p>pip prefers Wheels where they are available. To disable this, use the
<a href="https://pip.pypa.io/en/latest/reference/pip_install/#install-no-binary"><span>--no-binary</span></a> flag for <a href="https://pip.pypa.io/en/latest/reference/pip_install/#pip-install"><span>pip install</span></a>.</p>
<p>If no satisfactory wheels are found, pip will default to finding source
archives.</p>
<p>To install directly from a wheel archive:</p>
<div>
<p><label for="tab-set--5-input--1">Unix/macOS</label></p><div>
<div><div><pre><span></span>python -m pip install SomePackage-1.0-py2.py3-none-any.whl
</pre></div>
</div>
</div>
<p><label for="tab-set--5-input--2">Windows</label></p><div>
<div><div><pre><span></span>py -m pip install SomePackage-1.0-py2.py3-none-any.whl
</pre></div>
</div>
</div>
</div>
<p>For the cases where wheels are not available, pip offers <a href="https://pip.pypa.io/en/latest/reference/pip_wheel/#pip-wheel"><span>pip wheel</span></a> as a
convenience, to build wheels for all your requirements and dependencies.</p>
<p><a href="https://pip.pypa.io/en/latest/reference/pip_wheel/#pip-wheel"><span>pip wheel</span></a> requires the <a href="https://pypi.org/project/wheel/">wheel package</a> to be installed, which provides the
“bdist_wheel” setuptools extension that it uses.</p>
<p>To build wheels for your requirements and all their dependencies to a local
directory:</p>
<div>
<p><label for="tab-set--6-input--1">Unix/macOS</label></p><div>
<div><div><pre><span></span>python -m pip install wheel
python -m pip wheel --wheel-dir<span>=</span>/local/wheels -r requirements.txt
</pre></div>
</div>
</div>
<p><label for="tab-set--6-input--2">Windows</label></p><div>
<div><div><pre><span></span>py -m pip install wheel
py -m pip wheel --wheel-dir<span>=</span>/local/wheels -r requirements.txt
</pre></div>
</div>
</div>
</div>
<p>And <em>then</em> to install those requirements just using your local directory of
wheels (and not from PyPI):</p>
<div>
<p><label for="tab-set--7-input--1">Unix/macOS</label></p><div>
<div><div><pre><span></span>python -m pip install --no-index --find-links<span>=</span>/local/wheels -r requirements.txt
</pre></div>
</div>
</div>
<p><label for="tab-set--7-input--2">Windows</label></p><div>
<div><div><pre><span></span>py -m pip install --no-index --find-links<span>=</span>…</pre></div></div></div></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://pip.pypa.io/en/latest/user_guide/#changes-to-the-pip-dependency-resolver-in-20-2-2020">https://pip.pypa.io/en/latest/user_guide/#changes-to-the-pip-dependency-resolver-in-20-2-2020</a></em></p>]]>
            </description>
            <link>https://pip.pypa.io/en/latest/user_guide/#changes-to-the-pip-dependency-resolver-in-20-2-2020</link>
            <guid isPermaLink="false">hacker-news-small-sites-25145396</guid>
            <pubDate>Thu, 19 Nov 2020 02:03:35 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Chrome ‘Bug’ Exempts Google Cookies from Data Privacy Settings]]>
            </title>
            <description>
<![CDATA[
Score 171 | Comments 27 (<a href="https://news.ycombinator.com/item?id=25143814">thread link</a>) | @betaman0
<br/>
November 18, 2020 | https://hfet.org/chrome-bug-exempts-google-cookies-from-data-privacy-settings/ | <a href="https://web.archive.org/web/*/https://hfet.org/chrome-bug-exempts-google-cookies-from-data-privacy-settings/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">

			
	<main id="main" role="main">

		
<article id="post-342">

	<!-- .entry-header -->

	
		<figure>
			<img width="1080" height="540" src="https://hfet.org/wp-content/uploads/2020/11/pexels-deepanker-verma-1482061-1080x540.jpg" alt="" loading="lazy">		</figure>

		
	
<div>

	<h4>A programmer named <a href="https://lapcatsoftware.com/articles/chrome-google.html" target="_blank" rel="noopener noreferrer">Jeff Johnson</a> recently discovered that enabling the “Clear cookies and site data when you quit Chrome” meant Google Search and YouTube cookies were not deleted, and exempt from this rule.</h4>
<p>He found that the only way to include Google and YouTube cookies for clearing is to specifically add <code>google.com</code> and <code>youtube.com</code> to <em>sites that can never use cookies</em> – it is not made obvious to the user that Google’s own services are exempt from the cookie clearing rule by default. <em>(<a href="https://lapcatsoftware.com/articles/chrome-google.html" target="_blank" rel="noopener noreferrer">source</a>)</em></p>
<p>Furthermore, <a href="https://www.independent.co.uk/life-style/gadgets-and-tech/google-privacy-chrome-youtube-search-bug-b1180705.html" target="_blank" rel="noopener noreferrer"><em>The Independent</em></a> investigated this issue and found similar results.</p>
<p>Google was made aware of this issue, and a Google spokesperson issued the following statement:</p>
<blockquote><p>“We are aware of a bug in Chrome that is impacting how cookies are cleared on some first-party Google websites. We are investigating the issue, and plan to roll out a fix in the coming days.” (<a href="https://www.theregister.com/2020/10/19/google_cookie_wipe/" target="_blank" rel="noopener noreferrer">source</a>)<em><br>
</em></p></blockquote>
<hr>
<p><em><strong>Author’s Note:</strong> Google has a <a href="https://en.wikipedia.org/wiki/Privacy_concerns_regarding_Google" target="_blank" rel="noopener noreferrer">long history of privacy violations</a>, which is one of the primary reasons I recommend finding ways to become less reliant on their services. A good first step would be to replace Chrome with <a href="https://www.mozilla.org/en-US/firefox/new/?redirect_source=firefox-com" target="_blank" rel="noopener noreferrer">Firefox</a>, and from there, looking to replace Google Search with <a href="https://duckduckgo.com/" target="_blank" rel="noopener noreferrer">DuckDuckGo</a> or <a href="https://startpage.com/" target="_blank" rel="noopener noreferrer">Startpage</a>.</em></p>
<p><a href="https://hfet.org/feed/"><img src="https://hfet.org/wp-content/uploads/2020/11/rss_button_hfet-1.png" alt="" width="219" height="30"></a><a href="https://hfet.org/support/"><img src="https://hfet.org/wp-content/uploads/2020/11/support_button_hfet.png" alt="" width="165" height="30"></a></p>
    <div itemtype="http://schema.org/Person" itemscope="" itemprop="author"><p><img width="100" height="100" src="https://hfet.org/wp-content/uploads/2020/11/karl-swanepoel-150x150.jpg" alt="" loading="lazy" srcset="https://hfet.org/wp-content/uploads/2020/11/karl-swanepoel-150x150.jpg 150w, https://hfet.org/wp-content/uploads/2020/11/karl-swanepoel-300x300.jpg 300w, https://hfet.org/wp-content/uploads/2020/11/karl-swanepoel-20x20.jpg 20w, https://hfet.org/wp-content/uploads/2020/11/karl-swanepoel-36x36.jpg 36w, https://hfet.org/wp-content/uploads/2020/11/karl-swanepoel-48x48.jpg 48w, https://hfet.org/wp-content/uploads/2020/11/karl-swanepoel-24x24.jpg 24w, https://hfet.org/wp-content/uploads/2020/11/karl-swanepoel-96x96.jpg 96w, https://hfet.org/wp-content/uploads/2020/11/karl-swanepoel.jpg 640w" sizes="(max-width: 100px) 100vw, 100px"></p><div><p>I’m an AI &amp; Robotics Student interested in FOSS, Tech Sustainability and Data Rights. I’m also the founder of Humans For Ethical Technology.</p></div></div>	
</div><!-- .entry-content -->


</article>

	</main><!-- #main -->

	


	</div></div>]]>
            </description>
            <link>https://hfet.org/chrome-bug-exempts-google-cookies-from-data-privacy-settings/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25143814</guid>
            <pubDate>Wed, 18 Nov 2020 23:02:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Apple's 15% Deflection Tactic]]>
            </title>
            <description>
<![CDATA[
Score 466 | Comments 382 (<a href="https://news.ycombinator.com/item?id=25143303">thread link</a>) | @lux
<br/>
November 18, 2020 | https://www.johnluxford.com/blog/apples-15-percent-deflection-tactic/ | <a href="https://web.archive.org/web/*/https://www.johnluxford.com/blog/apples-15-percent-deflection-tactic/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-server-rendered="true" id="app" data-v-8769139c=""><div data-v-8769139c=""><div data-v-8769139c=""><div data-v-8769139c=""><blockquote>
<p>This post is in response to <a href="https://www.apple.com/newsroom/2020/11/apple-announces-app-store-small-business-program/" target="_blank" rel="nofollow noopener noreferrer">Apple’s App Store Small Business Program announcement</a>.</p>
</blockquote>
<p>For decades, developers were able to create and distribute their software, whether free or for a fee, to anyone with a PC or laptop. There was no gatekeeper deciding who was in or out, and there was no requirement that they hand over a significant percentage of their revenue to the device maker.</p>
<p>Video game consoles were the obvious exception to this, with the claim that they were specialized devices and, therefore, closed ecosystems. But personal computing was open, and that was an important catalyst for innovation for a long time.</p>
<p>That changed with the introduction of Apple's app store on iOS. Developers had to be approved by Apple, and had to agree to use Apple as their sole payment processor, to the tune of $99/year and 30% of their revenue. For contrast, payment processors at the time were charging around 2.9% and $0.30/transaction. That's a massive difference in and of itself.</p>
<blockquote>
<p>The 30% number was based on what video game consoles were charging developers.</p>
</blockquote>
<h2 id="apples-original-rationale">Apple's original rationale</h2>
<p>Apple's argument for the iPhone being a closed ecosystem was that a phone is a specialized device because its primary function is to make phone calls, and that primary function must be protected against rogue software that may disrupt its ability to make those calls.</p>
<p>Apple's argument that the 30% fee was fair was that it takes manpower to review and approve apps to be listed on their store.</p>
<h2 id="ripples-into-other-app-stores">Ripples into other app stores</h2>
<p>The issue grew bigger as Google implemented similar requirements and fee structures on the Android app store, and pretty much every app store from Steam to Samsung Galaxy followed suit.</p>
<p>Now that Microsoft and Apple have introduced app stores on Windows and macOS, they plan to slowly erode our freedom on PCs too so that they can reap the same financial benefits on our labour on all computing platforms (save for open source operating systems like Linux). Apple has since added warning messages discouraging users not to install third party software that hasn't paid for Apple's signature of approval. These warnings are getting more and more alarming with each OS upgrade, causing users to fear installing third party software through other, traditional means.</p>
<p>This needs to be stopped now because device makers are making the case that future devices like VR and AR headsets are also specialized devices and so they too should be subject to the same closed ecosystem and payment processing restrictions, which is simply untrue.</p>
<p>If an AR device replaces your PC, it's a generalized computing device, plain and simple.</p>
<h2 id="phones-are-not-specialized-computing-devices">Phones are not specialized computing devices</h2>
<p>Making phone calls was the sole function of a telephone, but a mobile phone is a powerful computer that can perform a wide range of functions. The new iPhone 12 Pro has built-in Lidar, a total of 4 cameras, GPS, and many other features that extend far being making phone calls.</p>
<p>What was once a primary feature is now just one of thousands, and potentially one of its least important features as we have dozens or more options for voice, video, and text-based messaging available to us. Many young people would probably be just fine on an iPod Touch that doesn't make calls at all, and many probably wouldn't know the difference.</p>
<p>Phones are general computing devices, and as such, should not be maintained as closed ecosystems. This doesn't benefit users, many of whom are also developers themselves, because it limits our freedom on both sides of the equation. General computing platforms should be protected from such predatory practices by manufacturers through strong government regulations.</p>
<h2 id="the-fee-isnt-the-issue-the-requirement-to-pay-is">The fee isn't the issue, the requirement to pay is</h2>
<p>Tying your right distribute an app that you developed independently of the hardware maker to the requirement to use their payment processor is anti-competitive because it means that every developer benefits the hardware maker while the hardware maker provides little more than a gatekeeper function and a small amount of file storage for their release builds.</p>
<p>How can any indie developer hope to compete with the likes of Apple or Google or Microsoft when every sale they make gives 15% of their profits over to their competition? And if they make more than $1m, it goes back up to 30%. That's a huge disparity that serves to protect the interests of the hardware maker at the expense of businesses everywhere.</p>
<p>If there was a hard cost for Apple and others to review and approve apps, then that should be charged up-front and not as a percentage of profit. Developers should be free to choose the payment processing service that best serves their needs, whether that's Stripe or Paypal or Apple's built-in offering. Apple's payment processor should be chosen because it's better, not because you have no other choice.</p>
<h2 id="disproportionate-profits">Disproportionate profits</h2>
<p>Since the cost of the review process and hosting are the justification for the payment processing fees, a good way to tell if they're in line with each other is to look at Apple's profits on the app store. In 2019, Apple generated about <a href="https://www.cnbc.com/2020/01/07/apple-app-store-had-estimated-gross-sales-of-50-billion-in-2019.html" target="_blank" rel="nofollow noopener noreferrer">$50bn in sales on the iOS app store</a>, with their take being about <strong>$15bn in profit</strong>.</p>
<p>Does it really cost Apple anywhere close to $15bn/year to maintain the app store's review process and hosting infrastructure?</p>
<h2 id="this-makes-some-business-models-unfeasible">This makes some business models unfeasible</h2>
<p>Some business models, like establishing a marketplace for content creators to share their work with each other, become unfeasible when 15-30% off the top goes straight to the device maker. Many businesses operate with profit margins well under 30% or even 15%. Amazon is widely known for maintaining a 1% profit margin across their entire business as a strategic advantage to be able to undercut everyone else.</p>
<p>Other payment processors are essentially locked out of these ecosystems entirely, which is unfair and anti-competitive against them. I bet Stripe would love to be able to provide a better mobile payment option – their core business – without Apple being such a significant portion of the sale, thereby negating any benefit that Stripe on its own can differentiate itself with.</p>
<h2 id="this-is-not-just-a-problem-for-developers">This is not just a "problem for developers"</h2>
<p>I've seen many comments on sites like Hacker News and MacRumours that this isn't a problem users should care about and that developers should essentially stop whining or take their software elsewhere. But this also limits the choices users have, and it limits the types of apps they get to benefit from. This limitation won't be felt directly, because you don't feel the absence of something you never knew you could have. <em>You don't know what you don't know.</em></p>
<p>Stifling innovation isn't good for anyone, and as more and more people become software developers, this really just hurts the small guys. The indies who are more similar in size and need to average consumers than the likes of tech giants like Apple or Google. Indie developers need protection from monopolistic and anti-competitive practices from larger players in the market through strong government regulation, not a discount on their first $1m in sales.</p>
<h2 id="this-model-is-being-replicated-in-vr-and-ar">This model is being replicated in VR and AR</h2>
<p>It's no secret that I work in Virtual Reality. In fact, writing this gives me some anxiety because my company could be targeted and harmed for me saying things that don't benefit the VR headset makers. <em>But this needs to be said.</em> In fact, I'd say this is one of the most important fights in the software industry today because it will determine whether future platforms are open or closed.</p>
<p>VR headsets have already been set up to be <a href="https://searchsecurity.techtarget.com/definition/walled-garden" target="_blank" rel="nofollow noopener noreferrer">walled gardens</a>, and although Oculus has turned a blind eye for the time being to third party app stores like <a href="https://sidequestvr.com/" target="_blank" rel="nofollow noopener noreferrer">SideQuest</a>, they could still decide to cut it off at any point in the future with little or no recourse.</p>
<p>Whether third party app stores are the solution also remains to be seen, but gauging by how difficult device makers make it for average users to install them, and what little percentage market share they have on each respective platform, I'd say they don't go far enough to solve this problem.</p>
<p>The ability to easily <a href="https://en.wikipedia.org/wiki/Sideloading" target="_blank" rel="nofollow noopener noreferrer">sideload</a>, aka install software directly onto a device that you own and not through any given app store, is paramount to maintaining free access to today's as well as tomorrow's computing platforms. And we should have the ability to do so without navigating a maze of warnings discouraging the average user from doing so.</p>
<h2 id="pcs-will-become-headsets-which-are-general-computing-devices">PCs will become headsets, which are general computing devices</h2>
<p>Augmented Reality is still in its infancy and isn't a general computing platform yet, not because it's specialized but because the technology isn't of sufficient quality yet. But it's improving rapidly, and one day it will be good enough to overtake both PCs and phones as the dominant computing platform of the future.</p>
<p>When it does, it will be critical to indie developers everywhere that we maintain the same level of freedom on these future platforms that we enjoy today on PCs, and stop the current erosion of those freedoms by big tech companies. Failure to do so will close off all software that isn't blessed by device makers, which will further increase the financial divide between indie developers and the companies who will control the platforms of the future, whether that's Apple, Google, Microsoft, or Facebook. <em>We can't let that happen.</em></p>
<h2 id="whats-the-solution">What's the solution?</h2>
<p>The solution is simple and threefold:</p>
<ol>
<li>Mobile phones and headset-based computing devices should be classified as general computing platforms in the eyes of the law.</li>
<li>General computing platforms should have the legal requirement that developers can distribute their software however they see fit, so long as it doesn't harm users (malware, spyware, etc.).</li>
<li>Choice of payment processors should not be forced on developers in exchange for the ability to distribute software on any general computing platform.</li>
</ol>
<p>Only when the above rights have been won in the eyes of the law will our fight be over on this front, but there will always be other …</p></div></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.johnluxford.com/blog/apples-15-percent-deflection-tactic/">https://www.johnluxford.com/blog/apples-15-percent-deflection-tactic/</a></em></p>]]>
            </description>
            <link>https://www.johnluxford.com/blog/apples-15-percent-deflection-tactic/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25143303</guid>
            <pubDate>Wed, 18 Nov 2020 22:23:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Open Letter from Facebook Content Moderators]]>
            </title>
            <description>
<![CDATA[
Score 336 | Comments 160 (<a href="https://news.ycombinator.com/item?id=25142657">thread link</a>) | @ynac
<br/>
November 18, 2020 | https://www.foxglove.org.uk/news/open-letter-from-content-moderators-re-pandemic | <a href="https://web.archive.org/web/*/https://www.foxglove.org.uk/news/open-letter-from-content-moderators-re-pandemic">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-layout-label="Post Body" data-type="item" data-updated-on="1605716470576" id="item-5fb548adc77fc917bd132369"><div><div><div data-block-type="2" id="block-5e3e902ee21503131a93"><div><p><em>Foxglove is supporting social media content moderators in their fights for fair treatment from the platforms they work for, and for safe working conditions during the pandemic. Here is the full text of an open letter which over 200 Facebook content moderators from across the world have just addressed to Facebook’s leaders:</em></p><p><strong>November 2020</strong></p><p><strong>Mark Zuckerberg <br>Sheryl Sandberg <br>Anne Heraty (CEO, CPL/Covalen) <br>Julie Sweet (CEO, Accenture) <p>Via email and posting on Facebook’s Workplace channels </p></strong></p><div><p><strong>Open letter from content moderators re: pandemic <br></strong><br>Dear Mr. Zuckerberg, Ms. Sandberg, Ms. Heraty, Ms. Sweet </p><p>We, the undersigned Facebook content moderators and Facebook employees, write to express our dismay at your decision to risk our lives—and the lives of our colleagues and loved ones—to maintain Facebook’s profits during the pandemic. </p></div><p>After months of allowing content moderators to work from home, faced with intense pressure to keep Facebook free of hate and disinformation, you have forced us back to the office. Moderators who secure a doctors’ note about a personal COVID risk have been excused from attending in person.[1] Moderators with vulnerable relatives, who might die were they to contract COVID from us, have not. </p><p>The pandemic has been good for Facebook. More than 3 billion people have now joined Facebook services, creating more demand for our work than ever.[2] Mr. Zuckerberg nearly doubled his fortune during the crisis.[3] He is now worth well over $100 billion. It has been good for Facebook’s contractors, too: CPL, one of the main European contractors, is due to be sold for €318m.[4] </p><p>Despite vast sums flowing to each of you as corporate executives, you have refused moderators hazard pay. A content moderator at Accenture’s office in Austin, Texas generally earns $18/hour[5]. </p><p>Before the pandemic, content moderation was easily Facebook’s most brutal job. We waded through violence and child abuse for hours on end. Moderators working on child abuse content had targets increased during the pandemic, with no additional support. </p><p>Now, on top of work that is psychologically toxic, holding onto the job means walking into a hot zone. In several offices, multiple COVID cases have occurred on the floor.[6] Workers have asked Facebook leadership, and the leadership of your outsourcing firms like Accenture and CPL, to take urgent steps to protect us and value our work. You refused. We are publishing this letter because we are left with no choice. </p><p>Stop Needlessly Risking Moderators’ Lives </p><p>It is important to explain that the reason you have chosen to risk our lives is that this year Facebook tried using ‘AI’ to moderate content—and failed.[7] </p><p>At the start of the pandemic, both full-time Facebook staff and content moderators worked from home. To cover the pressing need to moderate the masses of violence, hate, terrorism, child abuse, and other horrors that we fight for you every day, you sought to substitute our work with the work of a machine. </p><p>Without informing the public, Facebook undertook a massive live experiment in heavily automated content moderation. Management told moderators that we should no longer see certain varieties of toxic content coming up in the review tool from which we work— such as graphic violence or child abuse, for example. </p><p>The AI wasn’t up to the job. Important speech got swept into the maw of the Facebook filter—and risky content, like self-harm, stayed up. </p><p>The lesson is clear. Facebook’s algorithms are years away from achieving the necessary level of sophistication to moderate content automatically. They may never get there. </p><p>This raises a stark question. If our work is so core to Facebook’s business that you will ask us to risk our lives in the name of Facebook’s community—and profit—are we not, in fact, the heart of your company? </p><p>Without our work, Facebook is unusable. Its empire collapses. Your algorithms cannot spot satire. They cannot sift journalism from disinformation. They cannot respond quickly enough to self-harm or child abuse. We can. </p><p>Facebook needs us. It is time that you acknowledged this and valued our work. To sacrifice our health and safety for profit is immoral. </p><p>These are our demands. </p><p>1. Keep moderators and their families safe. At the moment, only individual content moderators with a doctors’ note indicating that they are high risk are excused from working in the office. Even this is not offered in some workplaces. Those who live with an at-risk person – who have, for example, a child with epilepsy – have been forced to come in. All content moderators who are high risk or who live with someone who is high risk for Covid should be permitted to work from home indefinitely. </p><p>2. Maximize at-home working. Work that can be done from home should continue to be done from home. You have previously said content moderation cannot be performed remotely for security reasons. If that is so, it is time to fundamentally change the way that the work is organized. There is a pervasive and needlessly secretive culture at Facebook. Some content, such as content that is criminal, may need to be moderated in Facebook offices. The rest should be done at home. </p><p>3. Offer hazard pay. If you want moderators to risk their lives to maintain ‘community’ and profit, you should pay. Moderators who are working in the office on high-risk material (eg, child abuse) should be paid hazard pay of 1.5x their usual wage. </p><p>4. End outsourcing. There is, if anything, more clamor than ever for aggressive content moderation at Facebook. This requires our work. Facebook should bring the content moderation workforce in house, giving us the same rights and benefits as full Facebook staff. </p><p>5. Offer real healthcare and psychiatric care. Facebook employees enjoy various benefits, including private health insurance and visits to psychiatrists. Content moderators, who bear the brunt of the mental health trauma associated with Facebook’s toxic content, are offered 45 minutes a week with a ‘wellness coach’. These ‘coaches’ are generally not psychologists or psychiatrists and are contractually forbidden from diagnosis or treatment. And they generally cannot build a relationship of trust with moderators, since workers know that Facebook management (and Accenture/CPL management) ask ‘coaches’ to reveal confidential details of counselling sessions. Moderators deserve at least as much mental and physical health support as full Facebook staff. </p><p>The current crisis highlights that at the core of Facebook’s business lies a deep hypocrisy. By outsourcing our jobs, Facebook implies that the 35,000 of us who work in moderation are somehow peripheral to social media. Yet we are so integral to Facebook’s viability that we must risk our lives to come into work. </p><p>It is time to reorganize Facebook’s moderation work on the basis of equality and justice. We are the core of Facebook’s business. We deserve the rights and benefits of full Facebook staff. We look forward to your public response. </p><p>Very sincerely yours, </p><ul data-rte-list="default"><li><p>Andrea</p></li><li><p>Angela De Hoyos Hart</p></li><li><p>Ani Niow</p></li><li><p>Audrey Martin</p></li><li><p>Aune Mitchell</p></li><li><p>Azer Gueco</p></li><li><p>Baris Aytan</p></li><li><p>Brady Bennett</p></li><li><p>Cam Herringshaw</p></li><li><p>Carlin Scrudato</p></li><li><p>Carlos Ancira</p></li><li><p>Charles Maxwell</p></li><li><p>Chris Chan</p></li><li><p>Christopher Glenn</p></li><li><p>Claire Sexton</p></li><li><p>Crystal Chan</p></li><li><p>Danica Michaels</p></li><li><p>Daniel Baxley</p></li><li><p>Daniel Finlayson</p></li><li><p>Daniel Rezende Fuser</p></li><li><p>Danille Sindac</p></li><li><p>Diego Ramirez</p></li><li><p>Dominick Martinez</p></li><li><p>Douglas Hart</p></li><li><p>Erin Donohue</p></li><li><p>Fletcher West</p></li><li><p>Hua Hoai Nam</p></li><li><p>James J. Morrow</p></li><li><p>Jeremy Calvert</p></li><li><p>Jess L</p></li><li><p>Jessica den Boer</p></li><li><p>John Reese</p></li><li><p>John Royales McTurk</p></li><li><p>Jonathan Daniel</p></li><li><p>Jonathan de la Rosa</p></li><li><p>Joseph Pouttu</p></li><li><p>Joseph Sarhan</p></li><li><p>Joshua Sklar</p></li><li><p>Katie Adamsky</p></li><li><p>Kelly Lambert</p></li><li><p>Kevin Fei</p></li><li><p>Kevin Liao</p></li><li><p>Kiara Gaytan</p></li><li><p>Lucy Yang</p></li><li><p>Marcus Rodriguez</p></li><li><p>Maria Sam</p></li><li><p>Mark Reitblatt</p></li><li><p>Mayra Ota Coffey</p></li><li><p>Michael Thot</p></li><li><p>Mike Vitousek</p></li><li><p>Naomi Shiffman</p></li><li><p>Nathan Tokala</p></li><li><p>Niccolo Coluccio</p></li><li><p>Nicholas O'Brien</p></li><li><p>Nick Azcarate</p></li><li><p>Nick Martens</p></li><li><p>Noah Korotzer</p></li><li><p>Nuno Picareta</p></li><li><p>Palina Andrayuk </p></li><li><p>Phil Wills</p></li><li><p>Phillip Shih</p></li><li><p>Phong Vu</p></li><li><p>Purnam Jantrania</p></li><li><p>Raimonds Gabalis</p></li><li><p>Ramazan Sahin</p></li><li><p>Rena</p></li><li><p>Robert Boyce</p></li><li><p>Ryan Hoyt</p></li><li><p>Sam Ringel</p></li><li><p>Sara Valderrama</p></li><li><p>Sarah Dunn</p></li><li><p>Shom Mazumder</p></li><li><p>Steffan Voges</p></li><li><p>Stephanie Marina</p></li><li><p>Stuart Millican</p></li><li><p>Tariq Yusuf</p></li><li><p>Thi Cat Tuong Trinh</p></li><li><p>Tina Wall</p></li><li><p>Tom G</p></li><li><p>Tristam MacDonald</p></li><li><p>Vahid Liaghat</p></li><li><p>Vitor Cordeiro Pileggi</p></li><li><p>Zoya Waliany</p></li><li><p><em>(and a further  248 content moderators who’ve signed anonymously)</em></p></li></ul><p><br>[1] <a href="https://www.vice.com/en/article/z3vvv9/leaked-audio-facebook-moderators-terrifiedto-return-to-office-during-covid-outbreak">https://www.vice.com/en/article/z3vvv9/leaked-audio-facebook-moderators-terrifiedto-return-to-office-during-covid-outbreak </a><br>[2] <a href="https://www.vox.com/2020/4/29/21241601/facebook-coronavirus-pandemic-usersadvertising-growth-making-losing-money-users-q1-2020-earnings">https://www.vox.com/2020/4/29/21241601/facebook-coronavirus-pandemic-usersadvertising-growth-making-losing-money-users-q1-2020-earnings </a><br>[3] <a href="https://www.theguardian.com/business/2020/sep/17/wealth-of-us-billionaires-rises-bynearly-a-third-during-pandemic">https://www.theguardian.com/business/2020/sep/17/wealth-of-us-billionaires-rises-bynearly-a-third-during-pandemic </a><br>[4] <a href="https://www.irishtimes.com/business/retail-and-services/cpl-agrees-318m-takeover-byjapan-s-outsourcing-inc-1.4399832">https://www.irishtimes.com/business/retail-and-services/cpl-agrees-318m-takeover-byjapan-s-outsourcing-inc-1.4399832</a> <br>[5] <a href="https://www.glassdoor.co.uk/Salaries/austin-content-moderator-salarySRCH_IL.0,6_IM60_KO7,24.htm">https://www.glassdoor.co.uk/Salaries/austin-content-moderator-salarySRCH_IL.0,6_IM60_KO7,24.htm </a><br>[6]<a href="https://theintercept.com/2020/10/20/facebook-coronavuris-content-moderatoraccenture/"> https://theintercept.com/2020/10/20/facebook-coronavuris-content-moderatoraccenture/ </a><br>[7] <a href="https://www.politico.eu/article/facebook-content-moderation-automation">https://www.politico.eu/article/facebook-content-moderation-automation</a></p></div></div></div></div></div></div>]]>
            </description>
            <link>https://www.foxglove.org.uk/news/open-letter-from-content-moderators-re-pandemic</link>
            <guid isPermaLink="false">hacker-news-small-sites-25142657</guid>
            <pubDate>Wed, 18 Nov 2020 21:27:00 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Vue vs React: Best Choice for Startups]]>
            </title>
            <description>
<![CDATA[
Score 56 | Comments 59 (<a href="https://news.ycombinator.com/item?id=25141661">thread link</a>) | @morchen
<br/>
November 18, 2020 | https://swimm.io/blog/vue-vs-react-best-choice-for-startups/ | <a href="https://web.archive.org/web/*/https://swimm.io/blog/vue-vs-react-best-choice-for-startups/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section data-v-f94c7cca=""> <!----> <div data-v-0cf44990="" data-v-f94c7cca=""><div><p>A former front-end student of mine (Zoe*) recently emailed me, and honestly wanted to understand why is it that I chose to code <a href="http://swimm.io/">Swimm</a>, with Vue.Js and not React:</p>
<blockquote>
<p>“I just have one question for you: Why Vue?[...] I hope you're not rolling your eyes thinking - “ah no, another question about Vue”. Although knowing you and your passion, I'm sure you have a pretty strong opinion that could swallow me into becoming a Vue fan without even knowing it.”</p>
</blockquote>
<p>Vue.js gained a reputation in recent years as an edgy must-know framework, but developers often question what the hype is about, how it relates to them and what web framework they should choose for their product.</p>
<p>While there might be some over-hype around the expected <a href="https://madewithvuejs.com/blog/vue-3-roundup#:~:text=Vue%203%20release%20date,2020%2C%20according%20to%20the%20roadmap.">Vue 3 release due in Q3 2020</a>, Vue has been gaining traction for a few years now, and it was just a matter of time for <a href="https://www.netguru.com/blog/13-top-companies-that-have-trusted-vue.js-examples-of-applications">bigger companies</a> like Netflix, Behance, Grammarly, Alibibaba, GitLab and others, to pick it up. Yet according to <a href="https://insights.stackoverflow.com/survey/2020#technology-most-loved-dreaded-and-wanted-web-frameworks-wanted2">Stackoverflow’s 2020 developer</a> React.js is still the most wanted web framework (Vue.js coming in second).</p>
<h3>Vue.js vs React In a Nutshell</h3>
<p>I first used Vue at <a href="https://www.imcreator.com/">IM Creator</a>, a product I co-built originally with JQuery, and Vue was a breath of crisp air in my face. It was user friendly and progressive as it enabled me to use the framework for specific parts each time, without huge migrations. I could then for example create a menu in Vue, while the rest remained in legacy JQuery. What’s there not to like?</p>
<p>With Swimm (a new dev tool product) it wasn't even a question. I started our PoC with Vue.js and continued since then to our Beta self-served version. Several benefits should speak volumes to Startups these days especially compared to React:</p>
<ul>
<li><strong>Vue is Lightweight and Flexible</strong>. It means it's a framework that feels more like a library than a framework at all. You can try it out first in small use cases in your app before going all-in.</li>
<li><strong>Vue is less intrusive than React</strong> and much easier to onboard. Project components and structure in Vue are similar whie projects in React each vary in architecture and implementation. I find that you can recognize Vue structures easily which is what speeds up onboarding time for any developer learning a new codebase. Vue becomes easier to maintain. This is especially true for smaller products.</li>
<li><strong>Readability is key</strong> - Vue is based on the most basic principles of the Web and is more readable than React. The html/css and JS are separate while in React everything is in JS.</li>
<li><strong>Indie at its core</strong>. While it’s my personal opinion, many developers appreciate tools that are not backed by tech giants (for example React backed by Facebook, and Angular by Google), but rather grows from a community and that is why it is highly oriented to developer needs.</li>
</ul>
<h3>When does React Trump Vue.js:</h3>
<ul>
<li><strong>React is still most wanted by the industry</strong>. That can be a problem for new coders. From my recent experience recruiting for Swimm’s growing dev team, Vue is still harder to recruit for because of React’s persistent popularity. <strong>By the same token</strong>, even if many of the larger companies are picking it up, it’s still part of side projects and not the main product. This is why for the <a href="https://www.itc.tech/">ITC.tech</a> web-dev Bootcamp, I created a React-based curriculum.</li>
<li><strong>Flexibility in some aspects</strong>. React still has the ability to split between the visibility of a component and maintenance of the component - and still provides more flexibility.</li>
<li><strong>Docs are light years ahead</strong>. The features Release in React is fast paced and as React docs are extensive and elaborate. [Try skimming through all of the 500 pages of questions on React on Stackoverflow].</li>
</ul>
<h3><strong>To Sum it Up: A Note to Zoe</strong></h3>
<blockquote>
<p>“ Hi Zoë,</p>
<p>I chose Vue for many reasons.</p>
<p>It is easy to integrate into existing projects (That was my need the first time I used Vue)</p>
<p>It is has a more readable syntax</p>
<p>It's really reactive (no need to explicitly call the set function)</p>
<p>It is not maintained by a big company (Facebook / Google)[...]</p>
<p>Give it a try :)”</p>
</blockquote>
<p>Of course there is always a trade-off. These lessons learned reflect my personal views, insight gained from working in various startups and alongside numerous tech clients. As always, <a href="https://www.mindk.com/blog/react-vs-vue/">in depth research</a> is required to make sure which framework best suits your business case. But if you’re looking for a flexible  non-enterprise solution, Vue has proved easy to learn, scalable, user-friendly backed by a solid community that caters to other developers.</p>
<p>...</p>
<p>* Thanks for the inquisitive question, <a href="https://www.linkedin.com/in/zo%C3%ABcohen/">Zoe Cohen</a>.</p>
<p><strong>About Author:</strong></p>
<p><a href="https://www.linkedin.com/in/gilad-navot/">Gilad Navot</a> is Co-Founder and CPO at Swimm. Previously VP R&amp;D at <a href="https://www.imcreator.com/">IM Creator</a>, and was part of the founding <a href="https://www.itc.tech/">ITC.tech</a> team teaching front-end development to hundreds of students around the world.</p>
</div></div> </section></div>]]>
            </description>
            <link>https://swimm.io/blog/vue-vs-react-best-choice-for-startups/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25141661</guid>
            <pubDate>Wed, 18 Nov 2020 19:57:31 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Scratch.js – Interactive JavaScript Scratchpad]]>
            </title>
            <description>
<![CDATA[
Score 156 | Comments 65 (<a href="https://news.ycombinator.com/item?id=25138872">thread link</a>) | @kahole
<br/>
November 18, 2020 | https://hole.dev/scratch/ | <a href="https://web.archive.org/web/*/https://hole.dev/scratch/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://hole.dev/scratch/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25138872</guid>
            <pubDate>Wed, 18 Nov 2020 16:39:52 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Writing a technical book: from idea to print]]>
            </title>
            <description>
<![CDATA[
Score 165 | Comments 31 (<a href="https://news.ycombinator.com/item?id=25138216">thread link</a>) | @sararob
<br/>
November 18, 2020 | https://sararobinson.dev/2020/11/17/writing-a-technical-book.html | <a href="https://web.archive.org/web/*/https://sararobinson.dev/2020/11/17/writing-a-technical-book.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
	  <p><strong>tl;dr</strong> - I co-authored an O’Reilly book with my colleagues <a href="https://twitter.com/lak_gcp" target="_blank">Lak</a> and <a href="https://www.linkedin.com/in/munnm/" target="_blank">Mike</a>! You can <a href="https://www.oreilly.com/library/view/machine-learning-design/9781098115777/" target="_blank">order it here</a> and 100% of the royalties go to <a href="https://girlswhocode.com/" target="_blank">Girls Who Code</a>. This post is about the writing process.</p>

<h3 id="deciding-to-write">Deciding to write</h3>

<p>Back in January of this year, Lak graciously reached out to me asking if I was interested in co-writing an O’Reilly book on machine learning. As I read the email, my reaction was almost an immediate no because:</p>

<ul>
  <li>It sounded like something that would take a lot of time.</li>
  <li>With a quickly evolving field like ML, wouldn’t a book be obsolete before it hit the shelves?</li>
</ul>

<p>I let Lak’s request sit in my inbox for a few days even though I was sure I had made up my mind, because saying no to projects is much harder than saying yes. A few days later on a long car ride with my fiancé, I mentioned the book offer in passing.</p>

<blockquote>
  <p>“You have an opportunity to write a book and you’re saying <em>no</em>?” he said, nearly pulling off the road.</p>
</blockquote>

<p>I suppose I had considered this offer as more of a <strong>burden</strong>, but from his perspective it was an <strong>opportunity</strong>. Ok, he wouldn’t be the one writing it, but he has <a href="https://www.amazon.com/Building-Embedded-Linux-Systems-Techniques-dp-0596529686/dp/0596529686" target="_blank">written</a> an O’Reilly book before!</p>

<p>It would no doubt be hard, but it also provided a chance to learn a lot along the way and have a book at the end of it. With his advice in mind, I decided to learn more about the book before saying no. The plan for the book was to catalog a series of patterns, each of which would outline a common challenge in ML and provide some approaches for solving it. I was intrigued, but some doubts started to creep in as I read through the pattern ideas:</p>

<ul>
  <li>
    <p>I was very familiar with some, but much less so with others. Didn’t I need to have all this knowledge in my head before writing for this to work?</p>
  </li>
  <li>
    <p>Why me? Why was I qualified to do this? Objectively, I have created a lot of ML content over the years to educate app developers, data scientists, and customers. I’d like to think I’m a decent writer, but a book? That seemed like a different beast, and I wasn’t sure I was the best person for the job.</p>
  </li>
</ul>

<p>There can always be a million reasons not to do something, but I ultimately decided to ignore them all and give it a try.</p>

<h3 id="starting-with-an-idea">Starting with an idea</h3>

<p>This happened before I joined the project, so I asked Lak what he did before reaching out to O’Reilly with the idea for the book. Publishers get cold proposals all the time, so it helps if you can clearly communicate what the book will be about and show that you know what you will be writing about.</p>

<p>In our case, Lak wrote a couple of blog posts on machine learning design patterns (<a href="https://medium.com/swlh/ml-design-pattern-1-transform-9e82ccbc3209">Transform</a> and <a href="https://towardsdatascience.com/ml-design-pattern-2-checkpoints-e6ca25a4c5fe">Checkpoints</a>) to gauge whether readers were interested in this idea. They were, but he realized that readers’ interest was very much in how to implement, adapt, and extend these patterns. He also did a talk on the topic at a couple of conferences and discovered that conference attendees were a bit different – they needed a clear explanation of the reason to use the pattern and a prescriptive approach to addressing the problem. In other words, readers who knew the pattern beforehand wanted a technical manual, while conference attendees (who were being introduced to the pattern for the first time) wanted to know why the pattern matters. This helped him write the next set of blog posts, where he started with a crisp problem statement, a canonical solution, and a couple of variations.</p>

<p>Once he had a good idea of how to communicate ML design patterns, Lak reached out to an O’Reilly editor with a short message:</p>

<blockquote>
  <p>I have a <a href="https://link.medium.com/7BSgxXdts1">list</a> of about 20 machine learning design patterns that I want to write about. Do you think they would do well as a book? If so, I can see about finding a co-author who would be interested in expanding on these…</p>
</blockquote>

<p>The editor replied that since O’Reilly has a solid franchise in design patterns, he was very interested. He was assigned an acquisitions editor who would work with us to craft the actual proposal. And that’s when Lak reached out to me to see if I was interested in co-authoring.</p>

<h3 id="building-an-outline">Building an outline</h3>

<p>I knew nothing about writing a book going into this, and my first question was: how will we split up the work? Will we alternate paragraphs, sections, chapters, words? I’m sure this varies for every book with multiple authors. We decided to split work by sections. In our case, each section was a design pattern and each chapter had 3-6 patterns. We started by making an outline, with an initial list of 20 patterns.</p>

<p>Chapters in our book are organized by different phases in a typical machine learning workflow. We first determined the topic for each chapter, and then came up with the patterns we wanted to be included in it. In the outline, each pattern had a 1-2 sentence description. It took a few iterations of adding and removing patterns and moving some between chapters before we had something we were happy with. We finished this process with a total of 30 patterns split across 6 chapters, with 2 additional chapters for an intro and conclusion. This brought us to the end of February.</p>

<h3 id="submitting-a-book-proposal">Submitting a book proposal</h3>

<p>The first step in the publishing process for many books is writing a proposal and submitting it to an acquisitions editor. Acquisitions editors are in charge of reviewing proposals, providing feedback, and deciding whether a proposal will move to the next stage in the approval process. They also work on overall content strategy, deciding which topics they want to cover. Sometimes people reach out to them cold, and other times these editors may proactively reach out to prospective authors.</p>

<p>The proposal (which includes the outline, but also comparisons with existing titles, and who the intended audience is) went through a few rounds of feedback (which is where I joined the process), including detailed technical feedback, before getting approved. The acquisitions editor focuses on acquiring new content, so once ours got approved we moved to the next step in the process which was working with a development editor. This person was our main point of contact throughout the writing process – more on that in the next section.</p>

<p>I recently had a great conversation with our acquisitions editor, where I learned a lot more about the publishing industry and how this all works. One thing from this conversation especially stood out: she mentioned she <em>rarely</em> receives a cold book proposal from a woman, and she gets many cold proposals each day. I’m sharing this data (with her permission) in hopes that it encourages more women with book ideas to just go for it. Reach out! You’ve got nothing to lose. If your proposal gets rejected, you’ll likely still get some feedback in the process.</p>

<h3 id="writing-time">Writing time</h3>

<p>I assumed we’d begin at the beginning, but we started by writing Chapter 2. Chapter 1 didn’t have any patterns – it was meant to be an overview of the entire book, explain our goals, and set the stage for the intended audience. Without anything written yet this would be hard to write, so we got right into patterns by starting with Chapter 2. Before sitting down to write this chapter, we took our short Chapter 2 outline and worked together to expand it. This is something we did before every chapter, with the goals of:</p>

<ul>
  <li>Ensuring the three of us had the same understanding of each pattern</li>
  <li>Agreeing on what should and shouldn’t be covered</li>
  <li>Splitting up the writing by pattern</li>
</ul>

<p>Early on in the outline process, we had decided each pattern should follow the same structure. If you’re reading the book, you’ll notice that every pattern is split into the following:</p>

<ul>
  <li><strong>Problem</strong>: describes the ML challenge a pattern addresses</li>
  <li><strong>Solution</strong>: describes one approach to solving the problem, including code snippets and recommended tooling for solving the problem</li>
  <li><strong>Tradeoffs and Alternatives</strong>: extended discussion on the pattern, including tools not covered in the Solution section, potential gotchas, and related solutions</li>
</ul>

<p>Having a structure for each section was extremely useful in ensuring consistency throughout the book.</p>

<p>After outlining Chapter 2 in detail, I had two patterns assigned to me and it was finally time to write. I wish I could tell you this is the part where I sat down at my desk, closed the door, and let the insights flow onto the page. This is how I’d always imagined book writing went. For better or worse (and maybe because the outside world went into chaos while this was happening), my process went more like this:</p>

<blockquote><div lang="en" dir="ltr"><p>My writing process:</p><p>* Write 2 sentences<br>* My glasses are splotchy, where are the lens wipes?<br>* Edit the last sentence I wrote<br>* Research the latest keyboards<br>* Write another 2 sentences<br>* Refill water, clean the counter<br>* Stare at my now perfect paragraph<br>* Open Twitter</p></div>— Sara Robinson (@SRobTweets) <a href="https://twitter.com/SRobTweets/status/1244312122613473281?ref_src=twsrc%5Etfw">March 29, 2020</a></blockquote>


<p>It wasn’t a very efficient way to start, but it got the job done and over time my process improved. I also quickly debunked my initial question:</p>

<p><em>Didn’t I need to have all this knowledge in my head before writing for this to work?</em></p>

<p>Even if I did have experience implementing a particular pattern, I couldn’t write only what I already knew. I had to do a considerable amount of research before I started writing the bulk of each pattern to find out:</p>

<ul>
  <li>What writing on this topic already existed?</li>
  <li>Are there any important research papers that cover this?</li>
  <li>What tools are available for solving this pattern?</li>
</ul>

<p>With all this research I started to have some doubts. If I was just collating information from various sources, was I providing anything useful? Then I thought about some of my favorite non-fiction books and realized most of them work by:</p>

<p><em>Presenting existing, relevant information + adding a unique angle</em></p>

<p>I’ve met with a lot of customers and seen production use of ML, and I’ve also built demos to help developers understand how to use different ML tools. Turns out I did have a unique angle! Before writing I did a lot of reading to make sure I fully understood the ins and outs of the pattern. Then I had enough information to write. I still wouldn’t say the words flowed at this point, but I did slowly get …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://sararobinson.dev/2020/11/17/writing-a-technical-book.html">https://sararobinson.dev/2020/11/17/writing-a-technical-book.html</a></em></p>]]>
            </description>
            <link>https://sararobinson.dev/2020/11/17/writing-a-technical-book.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25138216</guid>
            <pubDate>Wed, 18 Nov 2020 15:56:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Programming Language Fragility]]>
            </title>
            <description>
<![CDATA[
Score 28 | Comments 28 (<a href="https://news.ycombinator.com/item?id=25138125">thread link</a>) | @da_big_ghey
<br/>
November 18, 2020 | https://cancel.fm/blog/2019-11/language-fragility/ | <a href="https://web.archive.org/web/*/https://cancel.fm/blog/2019-11/language-fragility/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><main><dl><dt>Published</dt><dd><time datetime="2019-11-02T00:00:00Z">2019-11-02</time></dd><dt>Last updated</dt><dd>2019-11-02 16:28 UTC</dd></dl><section><p>Suggestions and corrections: <a href="mailto:cancel@cancel.fm">cancel@cancel.fm</a></p><hr><p>How fragile are the products of programming languages? If you write some software in a particular language, can you copy the compiled program to another computer and expect it to work? If the internet stopped functioning, would you be left helpless?</p><table><thead><tr><th>Language</th><th>Portable by Default</th><th>Portable with Effort</th><th>Notes</th></tr></thead><tbody><tr><td>C</td><td>No (libc)</td><td>OK</td><td></td></tr><tr><td>C++</td><td>No (libc)</td><td>OK</td><td></td></tr><tr><td>Rust</td><td>No (libc)</td><td>OK</td><td>Requires no_std. Most of the Rust ecosystem will be unusable.</td></tr><tr><td>Go</td><td>OK</td><td>OK</td><td></td></tr><tr><td>Pascal (fpc &amp; Delphi)</td><td>OK</td><td>OK</td><td></td></tr><tr><td>Zig</td><td>OK</td><td>OK</td><td></td></tr><tr><td>Nim</td><td>OK</td><td>OK</td><td></td></tr><tr><td>Odin</td><td>No (libc)</td><td>OK</td><td></td></tr><tr><td>D</td><td>No (libc)</td><td>No (libc)</td><td>Must use glibc on on Linux, and glibc cannot be statically linked.</td></tr><tr><td>Haskell</td><td>No (libc)</td><td>Partial (static libc)</td><td>Complex build process to statically link runtime libc. Must avoid using libgmp features.</td></tr><tr><td>OCaml</td><td>No (libc)</td><td>Partial (static libc)</td><td>Complex build process to statically link runtime libc. Win32 requires cygwin.</td></tr><tr><td>Swift</td><td>No (no Win32)</td><td>No (no Win32)</td><td></td></tr><tr><td>Java</td><td>No (complex runtime)</td><td>No (fragile bundling)</td><td>Complex and fragile bundling of a separate runtime (with licensing issues)</td></tr><tr><td>C#/F#/.NET</td><td>No (complex runtime)</td><td>No (fragile bundling)</td><td>Complex and fragile bundling of a separate runtime (with licensing issues)</td></tr><tr><td>Python</td><td>No (complex runtime)</td><td>No (fragile bundling)</td><td>Complex and fragile bundling of a separate runtime</td></tr><tr><td>Ruby</td><td>No (complex runtime)</td><td>No (fragile bundling)</td><td>Complex and fragile bundling of a separate runtime</td></tr><tr><td>Perl</td><td>No (complex runtime)</td><td>No (fragile bundling)</td><td>Complex and fragile bundling of a separate runtime</td></tr><tr><td>JavaScript (Node.js)</td><td>No (complex runtime)</td><td>No (fragile bundling)</td><td>Complex and fragile bundling of a separate runtime</td></tr><tr><td>Scheme (Racket)</td><td>No (complex runtime)</td><td>No (fragile bundling)</td><td>Complex and fragile bundling of a separate runtime (with licensing issues)</td></tr><tr><td>Lua</td><td>No (custom binary)</td><td>Partial (custom binary)</td><td>Must build custom binary of the runtime plus your program code bundled together.</td></tr><tr><td>Tcl</td><td>No (complex runtime)</td><td>Partial (custom binary)</td><td>Must build custom binary of the runtime plus your program code bundled together.</td></tr></tbody></table><hr><p>What about the compilers themselves? How likely is something to go wrong when acquiring or setting up a compiler?</p><table><thead><tr><th>Compiler/Interpreter</th><th>Portable</th><th>Notes</th></tr></thead><tbody><tr><td>gcc</td><td>No</td><td>Requires installer or package manager. Heavy environment entanglement. Multiple executables.</td></tr><tr><td>clang</td><td>No</td><td>Requires installer or package manager. Heavy environment entanglement. Multiple executables.</td></tr><tr><td>msvc</td><td>No</td><td>Requires installer. Heavy environment entanglement. Multiple executables.</td></tr><tr><td>tcc</td><td>OK</td><td></td></tr><tr><td>Rust</td><td>No</td><td>Requires installer or package manager. Recommended installation method is to pipe curl into bash.</td></tr><tr><td>Go</td><td>OK</td><td></td></tr><tr><td>Free Pascal</td><td>No</td><td>Requires installer or package manager.</td></tr><tr><td>Delphi</td><td>No</td><td>Requires installer.</td></tr><tr><td>Zig</td><td>OK</td><td></td></tr><tr><td>Nim</td><td>No</td><td>Requires a C compiler.</td></tr><tr><td>Odin</td><td>OK</td><td></td></tr><tr><td>D</td><td>Partial</td><td>Multiple executables. Some environment entanglement. No installer required.</td></tr><tr><td>Haskell</td><td>No</td><td>Requires installer or package manager.</td></tr><tr><td>OCaml</td><td>No</td><td>Requires installer or package manager. Requires cygwin on Win32.</td></tr><tr><td>Swift</td><td>No</td><td>Requires installer. Heavy environment entanglement. Mac only.</td></tr><tr><td>Java</td><td>No</td><td>Requires installer or package manager. Multiple executables. Licensing issues.</td></tr><tr><td>C#/F#/.NET</td><td>No</td><td>Requires installer or package manager. Multiple executables. (Mono, .NET, and .NET Core)</td></tr><tr><td>Python</td><td>No</td><td>Requires installer or package manager. Heavy environment entanglement. Multiple executables.</td></tr><tr><td>Ruby</td><td>No</td><td>Requires installer or package manager.</td></tr><tr><td>Perl</td><td>No</td><td>Requires installer or package manager. Heavy environment entanglement.</td></tr><tr><td>JavaScript (Node.js)</td><td>No</td><td>Requires installer or package manager.</td></tr><tr><td>Scheme (Racket)</td><td>No</td><td>Requires installer or package manager.</td></tr><tr><td>Lua</td><td>OK</td><td>Rolling your own host executable is required.</td></tr><tr><td>Tcl</td><td>OK</td><td>Fully portable via tclkits/all-in-one binaries.</td></tr></tbody></table><hr><p>Bonus round: portable compilers that can build themselves, portably.</p><table><thead><tr><th>Compiler/Interpreter</th><th>Builds Itself Portably</th><th>Notes</th></tr></thead><tbody><tr><td>tcc</td><td>OK</td><td>When using musl-libc. No Win32.</td></tr><tr><td>Go</td><td>OK</td><td></td></tr><tr><td>Everything else</td><td>No</td><td></td></tr></tbody></table><hr><p><span>P.S.</span> I’ve been working on some indie shareware: if you use Slack but don’t like the default browser-based client, give Ripcord a try.</p><a href="https://cancel.fm/ripcord/"><div><dl><dt>Ripcord</dt><dd>Cross-platform, not-a-web-browser desktop chat client for Slack (and Discord.)</dd></dl><p><img src="https://cancel.fm/ripcord/static/ripcord_screenshot_win_7_small.jpg" height="75px" alt="Screenshot of the main Ripcord window with light theme"></p></div></a></section></main></div></div>]]>
            </description>
            <link>https://cancel.fm/blog/2019-11/language-fragility/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25138125</guid>
            <pubDate>Wed, 18 Nov 2020 15:50:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to Have a Difficult Conversation]]>
            </title>
            <description>
<![CDATA[
Score 93 | Comments 18 (<a href="https://news.ycombinator.com/item?id=25136200">thread link</a>) | @MurizS
<br/>
November 18, 2020 | https://psyche.co/guides/use-mediation-techniques-to-overcome-the-muck-of-blame-and-anger | <a href="https://web.archive.org/web/*/https://psyche.co/guides/use-mediation-techniques-to-overcome-the-muck-of-blame-and-anger">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><section><div><h2 data-guide-section-number="1"><span>Need to know</span></h2><div><p>Iâ€™m in a Zoom meeting, speaking to a screen full of black squares, trying to coax voices out of the void. The other callers are all members of an executive board, and theyâ€™re in turmoil over the strategic direction of their company. Several of them are no longer on speaking terms, and employees and shareholders have not been shielded from the drama. On a good day, these calls are tense, but more often than not theyâ€™re explosive. Only my camera is turned on, and I watch myself try to look optimistic.</p>
<p>Iâ€™m a mediator. I have helped people have difficult conversations for more than 20 years: in conflict zones and in living rooms, with leaders of corporations and foundations, and people in my own community. If youâ€™ve ever avoided or postponed a difficult conversation, youâ€™re not alone. Conflict avoidance is everywhere. At home and at work, we steer around conflict as prodigiously as we create it.</p>
<p>And yet conflict isnâ€™t inherently bad. It offers us information about how we could work with others more effectively, improve our relationships, and grow as individuals. Itâ€™s far worse to try to avoid it, because you just end up creating new conflict â€“ which ends up being more insidious and costly than the original issue.</p>
<p>When I help people have difficult conversations, weâ€™re always aiming for one of three outcomes: a solution, a plan or an understanding. A solution is a grand bargain, a resounding win, a comprehensive resolution expected to withstand the pressures of all unknown future challenges. With a mediator this can happen, but itâ€™s ambitious. We all have a tendency to hope for a dramatic and permanent solution, but this usually causes new problems by overburdening an already stressed relationship. A plan is more realistic, and is like a map for finding a solution. It leaves the precise terms of the resolution open-ended but provides a path forward. A plan reorganises the relationship with new boundaries, revised norms, and sets up shared expectations for how the trickiest parts will be navigated.</p>
<p>But the <em>most</em> realistic outcome, especially at the beginning, is to focus on reaching an understanding. An understanding is a new awareness of what the other person has experienced in the conflict; itâ€™s a mutual appreciation for one anotherâ€™s needs, fears and hopes. Reaching an understanding is feasible, provides great relief, and can lay a foundation for a plan, a solution and a new relationship.</p>
<p>For example, I recently helped a family to reach an understanding when the COVID-19 pandemic forced a college student to move back in with his parents. They were having difficulties renegotiating their relationships once they were suddenly living together again. Their renewed understanding led to a plan for new expectations and boundaries, which theyâ€™re currently using to navigate the uncertainties and discomfort of this period. I expect theyâ€™ll find their solution soon.</p>
<p>In my work as a mediator, Iâ€™ve learnt that successful conversations always involve what I call a â€˜gem statementâ€™. When two parties have listened long and hard to each other â€“ have made the heroic effort to listen curiously and empathically even when they disagree strenuously â€“ someone eventually unearths a glowing, priceless gem. It usually takes the form of a short, powerful statement, such as these two Iâ€™ve heard recently:</p>
<blockquote>Weâ€™ve kept on fighting in part because neither of us is willing to walk away from this friendship. Thatâ€™s something.</blockquote>
<blockquote>Even when we canâ€™t agree on Dadâ€™s medical care, Iâ€™ve never doubted your good intentions. I know you want the best for him.</blockquote>
<p>It happens almost every time. From the muck of blame and anger, someone lifts out a beacon. I then seize the opportunity and hold up the gleaming gem for all parties to see. It lights the way toward a new conversation revolving around compromise, solutions and goodwill.</p>
<p>In addition to gratitude for the person who dug out the gem, I have also felt impatience. Iâ€™ve wondered, <em>Why canâ€™t they say something like this earlier in the process? Or better yet, at the beginning?</em> Does the conversation need to naturally find its way to such a moment, or could we engineer it to happen much sooner? It seemed worthwhile to find out, so I developed a process to reduce the amount of time people spend digging in the muck. And Iâ€™ve found it works: when people find a gem earlier on, they experience less pain and more benefit from having their difficult conversation.</p>
<p>This Guide is to help you do this â€“ without a mediator. Mediators can be helpful during challenging times, but we donâ€™t actually resolve peoplesâ€™ conflicts. We create the conditions in which people feel heard and acknowledged, increasing the quality of their communication and problem-solving. When youâ€™re facing a tough conversation, itâ€™s not really the mediator you need â€“ itâ€™s the conditions weâ€™re good at creating and maintaining.</p>
<p>If you donâ€™t feel safe or if your situation involves illegal activity or any type of abuse, this Guide isnâ€™t right for you. In those instances, get help from a professional right away. There are also some situations that donâ€™t call for further conversation â€“ some relationships or difficulties are better left in the past, and you should trust your instinct about whether a conversation is the right step for you. But if you think talking could do some good, then this resource can help get you started.</p>
<p>Maybe you feel misunderstood or unappreciated at work. Or maybe youâ€™re caught in a recurring family pattern that causes pain and drives you <a href="https://psyche.co/guides/a-family-rift-is-locked-on-the-past-heres-how-to-move-forward" rel="noopener">away</a> from the people you love. If you feel hurt or angry when thinking of a difficult conversation you need to have, there is a good chance that the relationship is important to you. Whether itâ€™s a relationship within your family, at work or in your community, itâ€™s become this challenging because you have a vested interest, you care deeply or your future is somehow intertwined with the person you need to talk with.</p>
<p>If you feel the situation could improve if someone <em>really heard</em> what you have to say, thereâ€™s hope. If you feel ready to make an earnest effort to <em>really hear</em> someone in return, thereâ€™s even more than hope. Remember that your goal here is not to find a quick solution or plan straight away â€“ thatâ€™s tempting but unrealistic, and might backfire. Your goal is to understand each other.</p></div></div></section><section><div><h2 data-guide-section-number="2"><span>What to do</span></h2><div><p><strong>1. Prepare for the conversation</strong></p>
<p>The first step is a thought experiment: think about the person with whom you need to talk, and allow yourself to imagine that you just finished having the best possible conversation with them. You were heard fully. Each of your concerns was addressed to your satisfaction. If an apology was appropriate, you received an excellent one. <em>Stay with this â€“ just imagine it!</em> Youâ€™ve reached an understanding that gives you confidence in the future of the relationship. <em>This is a challenging thought experiment, but youâ€™re almost thereâ€¦</em> You are relieved, you feel lighter, and even grateful to the person youâ€™ve been in conflict with.</p>
<p><strong>2. Dig out a gem</strong></p>
<p>What would you say to them in this moment? (Remember, in this exercise youâ€™ve been heard, youâ€™ve received an apology, and it went exceedingly well.) What would you say to your counterpart if all of that happened? Whatâ€™s â€˜underneathâ€™ the conflict? Whatâ€™s true when youâ€™re not consumed with negative feelings? Write down the first gem statement you think of. You can write others too, but usually the first one is the real deal.</p>
<p>Your statement should be an authentic expression of how youâ€™re feeling, but should also have significant meaning and positive impact for the other person. For example, two more gem statements I heard recently were: â€˜I can tell you care a lot about reaching our teamâ€™s goals, and I have a lot of respect for you<em>.</em>â€™ You can tell itâ€™s a gem when youâ€™re terribly tempted to tack on a grievance to the end of it. Like this: <em>I can tell you care a lot about reaching our teamâ€™s goals, </em><em><strong>but the way you go about it is causing great difficulty to everyone around you.</strong></em> If you find yourself doing this, leave out the second part. Youâ€™ll get to say it, just not here.</p>
<p><strong>3. Ask yourself if youâ€™re ready</strong></p>
<p>Are you willing to say the statement to them? We recoil from being generous and kind when we feel our counterpart doesnâ€™t deserve it. Moreover, making such statements can put us in an even more vulnerable position. If thatâ€™s the case, it might help to think of this another way. Uttering your gem statement is a temporary discomfort; the benefits youâ€™ll experience will be lasting and profound.</p>
<p>At this point, you should share this Guide with the other person. Even if you donâ€™t follow these steps closely or have the conversation right away, it will be helpful simply to both read the Guide and give thought to it. If you do proceed with a conversation, having this Guide in advance means that they will have undertaken this same process and unearthed a gem statement for you, which will likely mitigate your vulnerability and discomfort.</p>
<p><strong>4. Phone a friend</strong></p>
<p>Tell a friend who isnâ€™t involved in the conversation what youâ€™re going to do. The purpose is not to craft the gem statement together, and it isnâ€™t even to get their advice. Instead, say the four sentences below to your friend:</p><ul>
<li>The biggest emotion that Iâ€™m feeling toward the person I need to have a difficult conversation with isâ€¦</li>
<li>The biggest emotion that I expect the person is feeling toward me isâ€¦</li>
<li>The gem statement I will make to them isâ€¦</li>
<li>My hope for the conversation isâ€¦</li>
</ul><p>The fourth sentence â€“ identifying your hope for the conversation â€“ is a critical piece of your planning. Remember that the best initial outcome is achieving a new, shared understanding, rather than a comprehensive solution or a detailed plan. New understanding can bring you relief and allow space for forward movement, without expecting a miraculous resolution of all tension and …</p></div></div></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://psyche.co/guides/use-mediation-techniques-to-overcome-the-muck-of-blame-and-anger">https://psyche.co/guides/use-mediation-techniques-to-overcome-the-muck-of-blame-and-anger</a></em></p>]]>
            </description>
            <link>https://psyche.co/guides/use-mediation-techniques-to-overcome-the-muck-of-blame-and-anger</link>
            <guid isPermaLink="false">hacker-news-small-sites-25136200</guid>
            <pubDate>Wed, 18 Nov 2020 12:55:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Pfizer and BioNTech Conclude Phase 3 Study of Covid-19 Vaccine Candidate]]>
            </title>
            <description>
<![CDATA[
Score 261 | Comments 171 (<a href="https://news.ycombinator.com/item?id=25135984">thread link</a>) | @doener
<br/>
November 18, 2020 | https://investors.biontech.de/news-releases/news-release-details/pfizer-and-biontech-conclude-phase-3-study-covid-19-vaccine | <a href="https://web.archive.org/web/*/https://investors.biontech.de/news-releases/news-release-details/pfizer-and-biontech-conclude-phase-3-study-covid-19-vaccine">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="block-nir-pid3469-content">
  
    
      <h2>

</h2>





<article role="article">

  <div>
                <ul><li><em>Primary efficacy analysis demonstrates BNT162b2 to be 95% effective against COVID-19 beginning 28 days after the first dose; 170 confirmed cases of COVID-19 were evaluated, with 162 observed in the placebo group versus 8 in the vaccine group</em></li><li><em>Efficacy was consistent across age, gender, race and ethnicity demographics; observed efficacy in adults over 65 years of age was over 94%</em></li><li><em>Safety data milestone required by U.S. Food and Drug Administration (FDA) for Emergency Use Authorization (EUA) has been achieved</em></li><li><em>Data demonstrates vaccine was well tolerated across all populations with over 43,000 participants enrolled; no serious safety concerns observed; the only Grade 3 adverse event greater than 2% in frequency was fatigue at 3.8% and headache at 2.0%</em></li><li><em>Companies plan to submit within days to the FDA for EUA and share data with other regulatory agencies around the globe</em></li><li><em>The companies expect to produce globally up to 50 million vaccine doses in 2020 and up to 1.3 billion doses by the end of 2021</em></li></ul><p><strong>NEW YORK and MAINZ, GERMANY, November 18, 2020</strong> — <a href="https://www.globenewswire.com/Tracker?data=Yli2d5nvthuV5tgeZIpzfNa66X9aMWyRcb2c3eYCC7LVUbfEPTAS5qEjoWW9lex6gtFcZvarKhgdJF9WTS1yog==" rel="nofollow" target="_blank"><u>Pfizer Inc.</u></a> (NYSE: PFE) and <a href="https://www.globenewswire.com/Tracker?data=hDf010SOKY9ImJTMfLoYkeqr7USo3RbkSJXZNMRX8mlCKyHr1c2F9DT9mjo9LMT6ewFhRCEzViCxu4yA2e7l7g==" rel="nofollow" target="_blank"><u>BioNTech SE</u></a> (Nasdaq: BNTX) today announced that, after conducting the final efficacy analysis in their ongoing Phase 3 study, their mRNA-based COVID-19 vaccine candidate, BNT162b2, met all of the study’s primary efficacy endpoints. Analysis of the data indicates a vaccine efficacy rate of 95% (p&lt;0.0001) in participants without prior SARS-CoV-2 infection (first primary objective) and also in participants with and without prior SARS-CoV-2 infection (second primary objective), in each case measured from 28 days after the first dose, 7 days after the second dose. The first primary objective analysis is based on 170 cases of COVID-19, as specified in the study protocol, of which 162 cases of COVID-19 were observed in the placebo group versus 8 cases in the BNT162b2 group. Efficacy was consistent across age, gender, race and ethnicity demographics. The observed efficacy in adults over 65 years of age was over 94%.</p>  <p>There were 10 severe cases of COVID-19 observed in the trial, with nine of the cases occurring in the placebo group and one in the BNT162b2 vaccinated group. To date, the Data Monitoring Committee for the study has not reported any serious safety concerns related to the vaccine. A review of unblinded reactogenicity data from the final analysis which consisted of a randomized subset of at least 8,000 participants 18 years and older in the Phase 2/3 study demonstrates that the vaccine was well tolerated, with most solicited adverse events resolving shortly after vaccination. The only Grade 3 (severe) solicited adverse events greater than or equal to 2% in frequency after the first or second dose were fatigue at 3.8% and headache at 2.0% following dose 2. Consistent with earlier shared results, older adults tended to report fewer and milder solicited adverse events following vaccination. </p>  <p>In addition, the companies announced that the safety milestone required by the U.S. Food and Drug Administration (FDA) for Emergency Use Authorization (EUA) has been achieved. Pfizer and BioNTech plan to submit a request within days to the FDA for an EUA based on the totality of safety and efficacy data collected to date, as well as manufacturing data relating to the quality and consistency of the vaccine. These data also will be submitted to other regulatory agencies around the world.</p>  <p>“The study results mark an important step in this historic eight-month journey to bring forward a vaccine capable of helping to end this devastating pandemic. We continue to move at the speed of science to compile all the data collected thus far and share with regulators around the world,” said <strong>Dr. Albert Bourla, Pfizer Chairman and CEO</strong>. “With hundreds of thousands of people around the globe infected every day, we urgently need to get a safe and effective vaccine to the world.” </p>  <p>“We are grateful that the first global trial to reach the final efficacy analysis mark indicates that a high rate of protection against COVID-19 can be achieved very fast after the first 30 µg dose, underscoring the potential of BNT162 to provide early protection,” said <strong>Ugur Sahin, M.D., CEO and Co-founder of BioNTech</strong>. “These achievements highlight the potential of mRNA as a new drug class. Our goal from the very beginning was to design and develop a vaccine that would generate rapid and potent protection against COVID-19 with a benign tolerability profile across all ages. We believe we have&nbsp;successfully accomplished this with our vaccine candidate BNT162b2 in all age groups studied so far and look forward to sharing further details with the regulatory authorities. I want to thank all the devoted women and men who contributed to this historically unprecedented achievement. We will continue to work with our partners and governments around the world to prepare for global distribution in 2020 and beyond.”</p>  <p>The Phase 3 clinical trial of BNT162b2 began on July 27 and has enrolled 43,661 participants to date, 41,135 of whom have received a second dose of the vaccine candidate as of November 13, 2020. Approximately 42% of global participants and 30% of U.S. participants have racially and ethnically diverse backgrounds, and 41% of global and 45% of U.S. participants are 56-85 years of age. A breakdown of the diversity of clinical trial participants can be found <a href="https://www.globenewswire.com/Tracker?data=ad78-V3TIZpaI0hRxmiSbgkEJUyAXaiiyEL-ARI3BmSe5nBb577HWGg9iwQLkpFDr5Zut3MDUXtDp4gcUuk1TJMOdJQMV0I0rP8L9ghyxUs=" rel="nofollow" target="_blank"><u>here</u></a><u>&nbsp;</u>from approximately 150 clinical trials sites in United States, Germany, Turkey, South Africa, Brazil and Argentina. The trial will continue to collect efficacy and safety data in participants for an additional two years. </p>  <p>Based on current projections, the companies expect to produce globally up to 50 million vaccine doses in 2020 and up to 1.3 billion doses&nbsp;by the end of 2021. Four of Pfizer’s facilities are part of the manufacturing and supply chain; St. Louis, MO; Andover, MA; and Kalamazoo, MI in the U.S.; and Puurs in Belgium. BioNTech’s German sites will also be leveraged for global supply.</p>  <p>Pfizer is confident in its vast experience, expertise and existing cold-chain infrastructure to distribute the vaccine around the world. The companies have developed specially designed, temperature-controlled thermal shippers utilizing dry ice to maintain temperature conditions of -70°C±10°C. They can be used be as temporary storage units for 15 days by refilling with dry ice. Each shipper contains a GPS-enabled thermal sensor to track the location and temperature of each vaccine shipment across their pre-set routes leveraging Pfizer’s broad distribution network.</p>  <p>Pfizer and BioNTech plan to submit the efficacy and safety data from the study for peer-review in a scientific journal once analysis of the data is completed.</p>  <p><strong>About Pfizer: Breakthroughs That Change Patients’ Lives</strong><br>At Pfizer, we apply science and our global resources to bring therapies to people that extend and significantly improve their lives. We strive to set the standard for quality, safety and value in the discovery, development and manufacture of health care products, including innovative medicines and vaccines. Every day, Pfizer colleagues work across developed and emerging markets to advance wellness, prevention, treatments and cures that challenge the most feared diseases of our time. Consistent with our responsibility as one of the world's premier innovative biopharmaceutical companies, we collaborate with health care providers, governments and local communities to support and expand access to reliable, affordable health care around the world. For more than 150 years, we have worked to make a difference for all who rely on us. We routinely post information that may be important to investors on our website at <a href="https://www.globenewswire.com/Tracker?data=efkBESitL-YYL3Z0laTvow2llGFscFffkJd5BwOiTNGOtjFDXsnDOMTTrrWjwIHkGrKr7l170Vr-Cf0IOcmK5A==" rel="nofollow" target="_blank"><u>www.Pfizer.com</u></a>. In addition, to learn more, please visit us on <a href="https://www.globenewswire.com/Tracker?data=efkBESitL-YYL3Z0laTvo2zbdJuTNF9-WfK2D7Q6C5GUvy5ow-iKwQsyx4ZETtqc0zENUzOZqpNT5axWduuvIg==" rel="nofollow" target="_blank"><u>www.Pfizer.com</u></a> and follow us on Twitter at <a href="https://www.globenewswire.com/Tracker?data=_G7bMvP0UnHgRNdBi7C58Y5yD_vt1MwKM6uavr4WH8J9GONODA3QgMnza1EVMOxj60PNXXgeMmkscyRk7kz9qg==" rel="nofollow" target="_blank"><u>@Pfizer</u></a> and <a href="https://www.globenewswire.com/Tracker?data=_G7bMvP0UnHgRNdBi7C58aDSWJrj99jYJyKkvw72mTcupprjbYWTE_o_8oUmeQOe0zPfz4E2RmC-oF4TaVBRlXH8iP_6Bix5Xu9JnlN_J7M=" rel="nofollow" target="_blank"><u>@Pfizer News</u></a>, <a href="https://www.globenewswire.com/Tracker?data=33yxYtC2I0K4tZPfGski5s3o4ZHP3agvfitL54fVKSjNuaz9dJMbcS2fs_yowRkoI0H6GkHJ-V8eJS481Br7O_HudP6nCQCn8GgLiQR8_ao=" rel="nofollow" target="_blank"><u>LinkedIn</u></a>, <a href="https://www.globenewswire.com/Tracker?data=wDqRtJtHVFLrdnoY4rjV_QUVojDDDSL9NIZNQLhPL9rquT_S_TQq6AO4do7dxb91mS86msyzNiDLUOTenvwXSw==" rel="nofollow" target="_blank"><u>YouTube</u></a> and like us on Facebook at <a href="https://www.globenewswire.com/Tracker?data=dksh0JnhdKBurO_iVOmXvoO4yOIddjXTCsCPmWuYLjSsFuZnBZqF1BL6C2m7YnFEj37K3VlD2qyWE_dSx5HscHETzEHDKFBMIAuvMoaa-uE=" rel="nofollow" target="_blank"><u>Facebook.com/Pfizer</u></a>.</p>  <p><strong>Pfizer Disclosure Notice</strong><br>The information contained in this release is as of November 18, 2020. Pfizer assumes no obligation to update forward-looking statements contained in this release as the result of new information or future events or developments.</p>  <p>This release contains forward-looking information about Pfizer’s efforts to combat COVID-19, the collaboration between BioNTech and Pfizer to develop a potential COVID-19 vaccine, the BNT162 mRNA vaccine program, and modRNA candidate BNT162b2 (including qualitative assessments of available data, potential benefits, expectations for clinical trials, anticipated timing of regulatory submissions and anticipated manufacturing, distribution and supply), that involves substantial risks and uncertainties that could cause actual results to differ materially from those expressed or implied by such statements. Risks and uncertainties include, among other things, the uncertainties inherent in research and development, including the ability to meet anticipated clinical endpoints, commencement and/or completion dates for clinical trials, regulatory submission dates, regulatory approval dates and/or launch dates, as well as risks associated with clinical data (including the Phase 3 data that is the subject of this release), including the possibility of unfavorable new preclinical or clinical trial data and further analyses of existing preclinical or clinical trial data; the ability to produce comparable clinical or other results, including the rate of vaccine effectiveness and safety and tolerability profile observed to date, in additional analyses of the Phase 3 trial or in larger, more diverse populations upon commercialization; the risk that clinical trial data are subject to differing interpretations and assessments, including during the peer review/publication process, in the scientific community generally, and by regulatory authorities; whether and when data from the BNT162 mRNA vaccine program will be published in scientific journal publications and, if so, when and with what modifications; whether …</p></div></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://investors.biontech.de/news-releases/news-release-details/pfizer-and-biontech-conclude-phase-3-study-covid-19-vaccine">https://investors.biontech.de/news-releases/news-release-details/pfizer-and-biontech-conclude-phase-3-study-covid-19-vaccine</a></em></p>]]>
            </description>
            <link>https://investors.biontech.de/news-releases/news-release-details/pfizer-and-biontech-conclude-phase-3-study-covid-19-vaccine</link>
            <guid isPermaLink="false">hacker-news-small-sites-25135984</guid>
            <pubDate>Wed, 18 Nov 2020 12:24:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Six Months of Tiny Projects]]>
            </title>
            <description>
<![CDATA[
Score 806 | Comments 135 (<a href="https://news.ycombinator.com/item?id=25135752">thread link</a>) | @tinyprojects
<br/>
November 18, 2020 | https://tinyprojects.dev/posts/six_months_of_tiny_projects | <a href="https://web.archive.org/web/*/https://tinyprojects.dev/posts/six_months_of_tiny_projects">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
	
	<nav>
		<a href="https://tinyprojects.dev/">Home</a>
		<a href="https://tinyprojects.dev/projects">Projects</a>
		<a href="https://tinyprojects.dev/guides">Guides</a>
		<a href="https://tinyprojects.dev/blog">Blog</a>
	</nav>
	
	<p><i>November 18th 2020</i></p>

	<p>Six months ago, I set myself the goal of creating one tiny project each week.</p> 

	<p>My main aim was to get better at testing out all the ideas I had written down in my phone, but not actually done anything with.</p>

	<p>26 weeks later, and a quick glance of this website, you'll notice I've launched 6 things.</p>

	<p>Although I'm 20 projects short, it's not all bad. My projects are generating some passive income, I've gone from no online following, to a few hundred twitter followers, and I've had a great time building weird and wonderful internet things.</p>

	<p>In this post I'll give an update on how these projects are performing, and the pros and cons of launching micro-businesses.</p>

	<p>Let's rewind.</p>

	<h3>💡 <a href="https://tinyprojects.dev/projects/tiny_website" target="_blank">Tiny Website</a></h3>
	<ul>
		<li><i>Page views: <b>129,000</b></i></li>
		<li><i>Unique users: <b>58,000</b></i></li>
		<li><i>HN Upvotes: <b>348</b></i></li>
		<li><i>Cost: <b>£10.00</b></i></li>
	</ul>

	<p>Tiny Projects was born the day after my 25th birthday. Project #1 is this bare-bones tiny website that you're reading right now.</p>

	<p>When it launched, the only content on this website was a blog post, a guide on making tiny websites, and an update about my goals.</p>

	<p>Randomly, I decided to submit my blog post "Tiny websites are great" onto Hacker News. Over the next 24 hours it hit the top of the front page, bringing 25k users to this site in its first day. It was absolutely thrilling.</p>

	<p>As a double whammy, the guide I'd produced also hit the top of the learn programming sub-reddit with 1.3k upvotes.</p>

	<p>Somehow, I'd managed to hit a homerun with no idea what I was doing. Pageviews, followers and emails were flying in fast. Anyone who has produced a bit of viral content on the internet will know, the dopamine rush is insane.</p> 

	<h3>🌐 <a href="https://tinyprojects.dev/projects/silicon_valley_domain_names" target="_blank">Silicon Valley Domain names</a></h3>
	<ul>
		<li><i>Page views: <b>28,500</b></i></li>
		<li><i>Unique users: <b>25,500</b></i></li>
		<li><i>HN Upvotes: <b>410</b></i></li>
		<li><i>Cost: <b>£76.25</b></i></li>
	</ul>

	<p>Funnily enough, my second Tiny Project was the only one I actually completed in a week. Spurred on by the previous project, I was keen to replicate my success.</p>

	<p>I wanted to investigate domain names. Specifically, was it possible to buy a google.x domain name? It was an investigative piece with a bit of coding sprinkled in.</p>

	<p>Completing this project in a week was gruelling. My day-job was neglected, and I pulled some very long hours. However, 7 days later, I hit publish on my second blog post: "I bought netflix.soy".</p>

	<p>Again, I posted it on Hacker News. It became the most viral thing I've written.</p>

	<p>The Tiny Projects website received 28k page views, and the post got 410 upvotes. Hundreds of followers and emails again poured in.</p>

	<p>Writing two viral pieces back-to-back made me question what I was really doing. Somehow I'd  stumbled into writing click-baity blog posts for Hacker News instead of building tiny projects.</p>

	<p>6 months on, I still own all the domains I purchased for this project except the Facebook one. Damn you Zuck.</p>

	<h3>⚔️ <a href="https://tinyprojects.dev/projects/battle_royale" target="_blank">8-bit Battle Royale</a></h3>
	<ul>
		<li><i>Downloads: <b>25</b></i></li>
		<li><i>HN Upvotes: <b>3</b></i></li>
		<li><i>Revenue: <b>£0.00</b></i></li>
		<li><i>Cost: <b>£36.71</b></i></li>
	</ul>

	<p>For my third tiny project, I decided I wanted to make an online game.</p>

	<p>With minimal knowledge of Unity, I cobbled together a tiny battle royale game called "Wee Royale" in 2 weeks and launched it on Android.</p>

	<p>Posting this project write up on Hacker News got zero attention. I expected this, as it didn't really fit the usual HN content, but I was still disappointed. My brain had been jaded by the massive numbers of the first two posts.</p>

	<p>Wee Royale currently has 25 downloads on the Google Play Store. I'm actually not sure if the game still works though.</p>

	<p>Overall, Wee Royale was a flop, but it was hilarious to play it with my friends.</p>

	<h3>🛍️ <a href="https://tinyprojects.dev/projects/one_item_store" target="_blank">One Item Store</a></h3>
	<ul>
		<li><i>Page views: <b>1,500</b></i></li>
		<li><i>Stores: <b>1,400</b></i></li>
		<li><i>PH Upvotes: <b>83</b></i></li>
		<li><i>Revenue: <b>£1.63</b></i></li>
		<li><i>Cost: <b>£41.00</b></i></li>
	</ul>

	<p>With a minimalist design, and the tag line "just sell your stuff", One Item Store lets anyone create an online shop in minutes to sell their goods.</p>

	<p>After two weeks of building my micro e-commerce platform, I launched it on Product Hunt. At the end of the day I finished on the homepage with 83 upvotes.</p>

	<p>Today, people have created over 1400 stores, selling everything from t-shirts, to human beings. I've seen some very strange things.</p>

	<p>In total, £163.09 has flowed through One Item Store checkouts, mainly from a car dealership in Australia offering deals throughout the pandemic. I take a small 1% fee on every transaction, netting me a small fortune of £1.63.</p>

	<p>Although its not a significant amount, this was my first Tiny Projects internet money! The best thing is, One Item Store makes money without me having to do anything.</p>

	<p>One Item Store is a Tiny Project I'd like to continue building. My next step would be to add some better checkout designs, and make the website look a bit more legit.</p>

	<h3>📗 <a href="https://tinyprojects.dev/projects/snormal" target="_blank">Snormal</a></h3>
	<ul>
		<li><i>Page views: <b>2,000</b></i></li>
		<li><i>Users: <b>200</b></i></li>
		<li><i>PH Upvotes: <b>59</b></i></li>
		<li><i>Revenue: <b>£0.00</b></i></li>
		<li><i>Cost: <b>£10.00</b></i></li>
	</ul>

	<p>Snormal is a social network for everything that doesn't make it onto your Instagram highlight reel. A typical post on Snormal is something like: "Dude, I just ate a whole baguette in bed".</p>

	<p>I launched Snormal with zero intentions of making any money. It was a bit of a social experiment to see if people were becoming as jaded with social media as me.</p>

	<p>After 1 month of building, and an accidental Product Hunt launch, Snormal has gone on to gain 200 registered users, who have scrolled 4432 times on the discover feed.</p>

	<p>Its incredibly fun running a micro-social network.</p>

	<p>Two weeks after Snormal launched, I hadn't implemented comments on posts. When I finally added them, it felt godlike letting people finally talk to each other.</p>

	<p>Growth on Snormal slowly increasing. For some strange reason it has become popular in Portugal. Have a scroll now, and you'll see loads of statuses in Portugese.</p>

	<h3>💸 <a href="https://tinyprojects.dev/projects/earlyname" target="_blank">Earlyname</a></h3>
	<ul>
		<li><i>Page views: <b>10,000</b></i></li>
		<li><i>Subscribers: <b>1,500</b></i></li>
		<li><i>PH Upvotes: <b>274</b></i></li>
		<li><i>MRR: <b>$200.00</b></i></li>
		<li><i>Cost: <b>$108.20</b></i></li>
	</ul>

	<p>Earlyname helps you claim rare usernames (like @ben or @alice) on new, emerging social platforms. Currently it is generating $200/month.</p>

	<p>Running Earlyname is so much fun. I get to talk with founders, try out new products, do a bit of web scraping/automation, and find rare usernames for people.</p>

	<p>The only downside is that it requires my input every month to produce a new email. I'm anxious for the month I can't find any new social platforms.</p>

	<p>At present, Earlyname has 1500 subscribers on its email list, a number which thankfully seems to be growing naturally.</p>

	<p>Although its currently only at $200/mo, its cool to think Earlyname is generating $2k/year. My plan is to keep plugging away launching monthly newsletters and see how high that monthly revenue number can get.</p>

	<h3>👍 Positives of Tiny Projects</h3>

	<p>I believe there's a big advantage to this "micro-bet" approach of launching many tiny businesses, and then sticking with the ones that become successful.</p>

	<p>Firstly, it drastically reduces the risk of putting too much time into an idea that doesn't quite work. Even if you stumbled across a decent idea that did work, what if there's an amazing one just around the corner? It keeps you on your toes.</p>

	<p>Creating lots of tiny businesses also keeps things fun and interesting. This is probably the most important factor for me.</p>

	<p>Feeling obligued to keep building something that you've sunk hundreds of hours into but no longer enjoy sounds like my personal hell.</p>

	<p>With tiny projects, the stakes are so low, I can kill a project with no guilt and build something else, or just bounce between the projects I want to work on.</p>

	<h3>👎 Negatives of Tiny Projects</h3>

	<p>My original plan was to launch one tiny project each week, however I've realised this is an insane schedule. You can't build or document anything meaningful in this time.</p>

	<p>This schedule might be possible if I treated Tiny Projects full-time like a YouTuber. But, I don't think going all in on Micro-SaaS businesses would be very fun with the revenue they're currently generating.</p>

	<p>1-2 months is a more reasonable tiny project timeframe. It gives you enough time to build something with substance, and test the idea thoroughly.</p>

	<p>One major downside of launching lots of things is that you become way too happy to give up on a project when it doesn't show instant success.</p>

	<p>Perhaps if I spent more time on marketing, or slightly pivoted a project, I could see more success. Currently, I'm more inclined to just start something new.</p>

	<p>Maintaining lots of software can also become a bit of a burden. Once the domain name renewal date comes around, I'll have to make some decisions as to whether a project lives on for another year or not.</p>

	<h3>🔮 Conclusions &amp; The Future</h3>

	<p>I feel like I'm trying to learn the skill of generating better ideas, and rapidly building and launching them into a business.</p>

	<p>I try to think about this process like going for a run. The more runs I do, the faster and fitter I'll be. The more projects I launch, the better and more profitable they'll be.</p>

	<p>How often does someone build &amp; launch a business in their lifetime? I'm hoping that by doing this process over and over again, I'll discover some really interesting things.</p>
	
	<p>My main goal for the next six months of Tiny Projects is to learn how to get better at making money on the internet from my projects.</p>

	<p>A Product Hunt launch can easily get you a spike in traffic, but afterwards I really don't know what I'm doing. There's this whole other level afterwards called "sales &amp; marketing" that I want to master.</p>

	<p>Another goal is to also be more consistent with my writing. Hopefully, this ultimately means you'll be hearing a lot more things from me!</p>

	<p>It was nice to catch up.</p>

	
	
	
	
	
	

</div>]]>
            </description>
            <link>https://tinyprojects.dev/posts/six_months_of_tiny_projects</link>
            <guid isPermaLink="false">hacker-news-small-sites-25135752</guid>
            <pubDate>Wed, 18 Nov 2020 11:48:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[UI design for software developers. Part 1, Colors]]>
            </title>
            <description>
<![CDATA[
Score 220 | Comments 89 (<a href="https://news.ycombinator.com/item?id=25135215">thread link</a>) | @Igor_Wiwi
<br/>
November 18, 2020 | http://amortizedcost.net/ui-desing-for-software-developer-part-1/ | <a href="https://web.archive.org/web/*/http://amortizedcost.net/ui-desing-for-software-developer-part-1/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
				<!--kg-card-begin: markdown--><p>In this series of articles, I will show full process of creating a UI design for <a href="https://play.google.com/store/apps/details?id=net.amortizedcost.batchimageshrinker">Batch Image Shrinker</a> (<a href="market://details?id=net.amortizedcost.batchimageshrinker">Google play link</a>) mobile application which I did by myself. As a software developer always I've been thinking that UI design is not for me, that it's complex and requires some art skill or something.</p>
<p>It's a myth and I will try to debunk it.</p>
<p>I will show you that UI design is for everyone, you just need to know some basic technics and a couple of tricks.</p>
<p>It's not going to be easy, but I promise you it will be very interesting.</p>
<h2 id="dominatingcolor">Dominating color</h2>
<p>With the dominating presence of dark-mode, I noticed that for me it was easier to work with darker colors as baseline colors than with brighter ones, and since  I almost always use dark-mode of the applications, so I wanted to have something similar in my application. I was certain that I didn't want to use <a href="https://colornames.org/color/3b5998">Facebook blue</a> color and it's successors, so I had to find something more futuristic and brave than that. My choice fell on <code>#464d77</code> which is a very intense dark blue, almost purple color.</p>
<p><img src="http://amortizedcost.net/content/images/2020/11/Screenshot-2020-11-17-at-20.10.09.png" alt="Screenshot-2020-11-17-at-20.10.09"></p>
<p>Common advice here will be not to use pure black or white colors, which, as perfectly described in <a href="https://ianstormtaylor.com/design-tip-never-use-black/">the article</a>, hardly present in the real-world color pallet. <em>What a coincidence, I found <a href="https://lawsofux.com/aesthetic-usability-effect.html">a website</a> with a perfect example of dark background color and great content to read.</em></p>
<h2 id="colorpalette">Color palette</h2>
<p>Of cause, just one baseline color will not be enough to build a feature-rich application. You will need a couple of colors for different types of components like buttons, checkboxes, radio buttons, etc. Another one or two colors will be needed for the text itself. Also,  some gradients for several states of a component, such as "active", "disabled", "pressed". So before creating an actual UI, we will need to have a rich pallet of colors to work with. In my case, I ended up with 6 colors in total which was more than enough to create a simple yet interesting UI.</p>
<p>This step is much easier than the previous one, because here we will be either reusing or generating new color pallets using the baseline color from the previous part.</p>
<p>The generator which I was using is <a href="https://coolors.co/palettes/popular/f9db6d">this</a>. Here you could either put the color hex into a search bar or simply choose the pallet from the <a href="https://coolors.co/a1e8af-94c595-747c92-372772-3a2449">hundreds</a> of pre-generated ones. If the color range is not enough for you, try to extend it with <a href="https://learnui.design/tools/data-color-picker.html#palette">another</a> good palette generator. Put on the left side the baseline color and select how many colors you will need.</p>
<p>Pro-tip, you can combine those tools to get even more combinations. As you can see here, I was using a baseline color on the right side and colors from <a href="https://coolors.co/464d77-36827f-f9db6d-f4eded-877666">the palette</a> as values for the right side of the generator:</p>
<p><img src="http://amortizedcost.net/content/images/2020/11/Screenshot-2020-11-16-at-23.50.31.png" alt="Screenshot-2020-11-16-at-23.50.31"><br>
<img src="http://amortizedcost.net/content/images/2020/11/Screenshot-2020-11-16-at-23.51.04.png" alt="Screenshot-2020-11-16-at-23.51.04"></p>
<p>If you are not satisfied with the results try to get back to choosing the baseline color and repeat the whole process again. Since we are learning it's ok to do multiple roundtrips until your gut feelings tell you that that is it.</p>
<p>Once we are done with the color schema we are good to go to we move to the next step - choosing fonts, which will be covered next time.</p>
<!--kg-card-end: markdown-->
			</section><section>
				<p>Get the latest posts delivered right to your inbox.</p>
        


      </section></div>]]>
            </description>
            <link>http://amortizedcost.net/ui-desing-for-software-developer-part-1/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25135215</guid>
            <pubDate>Wed, 18 Nov 2020 10:33:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Cobalt – Lightweight Electron Alternative]]>
            </title>
            <description>
<![CDATA[
Score 31 | Comments 0 (<a href="https://news.ycombinator.com/item?id=25134848">thread link</a>) | @ash
<br/>
November 18, 2020 | https://cobalt.foo/overview.html | <a href="https://web.archive.org/web/*/https://cobalt.foo/overview.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="centerCol">
      <div id="content">
        <p>Cobalt is a lightweight HTML5/CSS/JS application container that is designed
to provide a rich application development environment with minimal resource
consumption (deployment size, RAM, CPU, GPU). At the same time, Cobalt enables
a rich, low-latency user experience across a wide variety of platforms and
devices.</p>

<h4 id="target-audiences">Target audiences</h4>

<p>Cobalt's documentation is written with two audiences in mind:</p>

<ul>
<li><p><strong>Porters</strong> enable Cobalt to work on other platforms by using Starboard,
Cobalt's porting layer and OS abstraction, to implement the
platform-specific functionality that Cobalt uses. Each Starboard module
(memory, socket, thread, etc.) defines functions that must be implemented
for the porter's platform.</p></li>
<li><p><strong>Developers</strong> want to build applications in familiar environments with
advanced debugging tools without having to worry about compatibility with
a highly fragmented set of browsers. At the same time, they want to have
full control over their codebase so that they can ship features for
constrained platforms, like TVs, on time and without technical risk.</p></li>
</ul>

<h2 id="benefits-of-cobalt">Benefits of Cobalt</h2>

<p>Cobalt significantly reduces the cost of supporting a browser on non-standard
and resource-constrained platforms. In addition, since Cobalt operates at a
consolidated, versioned platform abstraction layer, its porting effort is
man-weeks, and subsequent rebases are near-free.</p>

<p>These are some other benefits that Cobalt provides:</p>

<ul>
<li><p><strong>More platforms</strong></p>

<ul>
<li>  Cobalt does not require platforms to support JIT compilation and can
run on platforms that disallow execution of dynamically generated code.</li>
<li>  Cobalt is a single-process application and does not rely on the ability
to spawn multiple processes.</li>
<li>  Cobalt precompiles a set of shaders that are sufficient to express all
graphical effects, thereby accommodating platforms that cannot compile
shaders at runtime.</li>
<li>  Cobalt requires a compliant C++11 compiler, allowing it to reach
platforms with toolchains that don't support the newest C++17 features.</li>
</ul></li>
<li><p><strong>Small footprint</strong></p>

<ul>
<li>  Cobalt is optimized for memory. Its surface cache never exceeds a
predefined budget, and it never creates duplicate layers, reducing
the likelihood of out-of-memory crashes.</li>
<li>  Cobalt's small binary is designed to take up as little space as
possible. By supporting a subset of HTML5/CSS/JS, Cobalt's reduced
package size even allows bundling of CJK fonts on low-end devices.</li>
</ul></li>
<li><p><strong>Reduced input latency</strong></p>

<ul>
<li>  Cobalt produces consistent 60FPS animations by only supporting
animation of properties that don't affect layout, like <code>transform</code>,
and always running animations on a separate thread.</li>
<li>  Cobalt is optimized to run on single-core CPUs, resulting in better
input latency since the renderer and resource loader do not compete
with layout operations.</li>
<li>  On platforms that support GLES2, Cobalt avoids CPU painting by
performing almost all rendering operations on the GPU.</li>
</ul></li>
</ul>

<h2 id="getting-started">Getting started</h2>

<h3 id="porters">Porters</h3>

<p>Porters should begin with the <a href="https://cobalt.foo/starboard/porting.html">porting guide</a>,
which explains how to use Starboard, Cobalt's porting layer, to customize the
platform-specific functionality that Cobalt uses. There are several reference
documents to help porters customize configuration files and to implement
module-specific functionality. The <a href="https://cobalt.foo/starboard/testing.html">Testing with
NPLB</a> document provides an overview of
Starboard's compliance test suite.</p>

<h3 id="developers">Developers</h3>

<p>Developers can follow the setup instructions for
<a href="https://cobalt.foo/development/setup-linux.html">Linux</a> or
<a href="https://cobalt.foo/development/setup-raspi.html">RasPi</a> to set up their Cobalt development
environment, fetch a copy of the Cobalt code repository, and build a Cobalt
binary. The <a href="https://cobalt.foo/development/reference/supported-features.html">Cobalt support</a>
guide lists the HTML elements, CSS properties, CSS selectors, and JavaScript Web
APIs that developers can use in their Cobalt applications.</p>

        
          
            
          
        
      </div>
    </div></div>]]>
            </description>
            <link>https://cobalt.foo/overview.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25134848</guid>
            <pubDate>Wed, 18 Nov 2020 09:34:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I/Q Data for Dummies]]>
            </title>
            <description>
<![CDATA[
Score 94 | Comments 41 (<a href="https://news.ycombinator.com/item?id=25134698">thread link</a>) | @pabo
<br/>
November 18, 2020 | http://whiteboard.ping.se/SDR/IQ | <a href="https://web.archive.org/web/*/http://whiteboard.ping.se/SDR/IQ">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="wikitext">
<p>This is a description of using I/Q Data (aka "analytic signal") representing a signal. Since the topic may be quite confusing, I've described the same thing here from different point of views. If you find the information somewhat redundant, it is because it is. Different views may appeal to different readers, and if something seems unclear, keep on reading and it may be more comprehensible later - hopefully.
</p>
<h2>Why I/Q Data?</h2>
<p>I/Q Data is a signal representation much more precise than just using a series of samples of the momentary amplitude of the signal. Have a look at the following signal below.
</p>
<p><img src="http://whiteboard.ping.se/uploads/SDR/cosample.png" alt="Plain signal" title="Plain signal"></p>
<p>This is what you may be used to work with. So why I/Q Data - isn't this good enough?
</p>
<p>Not really. We have a few problems here.
</p>
<ul><li>First, it is impossible to determine the frequency of this signal. Sure, it looks simple enough, just look at the period length? True, but you have no clue if it's a positive or negative frequency since they both generate the same curve. I.e. cos(x) = cos(-x). This becomes a problem working with the signal. Mixing (multiplying) two signals and it'll cause multiple solutions due to the uncertainty of the sign: f1 âŠ— f2 equals f1 + f2 as well as f1 - f2.
</li><li>Second, it's hard to determine the power (peak amplitude, envelope) of the signal. Basically you can only see the peak amplitude here at 0Â°, 180Â°, 360Â° etc, and how do you know the power is the same everywhere else as well? And did you sample the signal exactly at its peak? You really don't know.
</li></ul><p>I/Q Data solves this. Instead of looking at the signal as a flat curve as above, look at it as a corkscrew (helix, spiral, coil spring) in three dimensions.
</p>
<p><img src="http://whiteboard.ping.se/uploads/SDR/corkscrew.png" alt="Complex signal" title="Complex signal"></p>
<hr>
<p>Now if you look at this curve from the side, you'll actually get the same graph as the first one above. Your "real" signal actually is this 2D projection of this corkscrew signal. This is your "I" in I/Q data.
</p>
<p><img src="http://whiteboard.ping.se/uploads/SDR/corkI.png" alt="Side view" title="Side view"></p>
<hr>
<p>Now have a look at the corkscrew from above. This looks quite similar, but as you see, it is out of phase 90Â°  starting at zero, not at one as the other. This this the Q part of your I/Q data.
</p>
<p><img src="http://whiteboard.ping.se/uploads/SDR/corkQ.png" alt="Top view" title="Top view"></p>
<hr>
<p>Now looking at the corkscrew down the time axis you'll see it winds counter-clockwise. This means we know the frequency is positive. It could have wound clockwise as well, still generating the same I-signal (projection) but different Q-signal, representing a negative frequency.
</p>
<p>You also see that the radius of the corkscrew is constant at every sample, if small in I large in Q and vice versa. The radius is the peak amplitude of your signal. 
</p>
<p>The axes are of course 90Â°, so the radius must be equal to (IÂ²+QÂ²)<sup>1/2</sup>. This is the peak amplitude of your signal, and as you can see you know this for each and every sample.
</p>
<p><img src="http://whiteboard.ping.se/uploads/SDR/corkT.png" alt="Viewed down time axis" title="Viewed down time axis"></p>
<h2>What is I/Q Data?</h2>
<p>AS you now understand, the I/Q Data Sample is the coordinates of your signal as seen down the time axis of the corkscrew.
</p>
<p><img src="http://whiteboard.ping.se/uploads/SDR/onesample.png" alt="" title=""></p>
<p>You might object that your signal isn't a pure cosine function as the one we have shown here, and it might be very true. Still, every single sample of your signal can be described as such, i.e. with a peak amplitude times cosine of some phase angle.
</p>
<p>Every single point of your signal can be described as the function Aâ‹…cos(Ï•)
</p>
<p>Since you may freely chose any amplitude A and angle Ï• this must of course be true (as long as the signal is continuous). The value of Aâ‹…cos(Ï•) is the <strong>I</strong> component of the I/Q signal, i.e. your real signal. Note that this only describes your signal in one single point, i.e. one sample. Next sample gives you a new I and Q very likely resulting in another amplitude and/or phase angle, reflecting the modulation of the signal.
</p>
<h2>One sample I/Q Data</h2>
<p>Ok, lets take one sample of I/Q Data and see what it represents. This is also called a phase vector, or phasor.
</p>
<pre>I = 0.69
Q = 0.40
</pre>
<p>Lets draw this in the complex plane.
</p>
<p><img src="http://whiteboard.ping.se/uploads/SDR/iqdraw1.png" alt="" title=""></p>
<p>Lets see what this tells us about our data point.
</p>
<ul><li>The momentary amplitude of our real signal is by definition <strong>I</strong>, i.e. 0.69
</li><li>Pythagoras tells us the amplitude A of the cosine wave is <code>(0.69Â²+0.40Â²)<sup>1/2</sup> = 0.8</code>
</li><li>Trigonometry tells us our angle is +30Â° into our cosine wave.
</li></ul><p>- <em>Hold it</em>, you say, <em>what cosine wave?</em>
</p>
<p>Well, I/Q actually assumes your real signal (<strong>I</strong>, that is) can be described as the
function <strong>I</strong> = Aâ‹…cos(Ï•)
</p>
<p>Since you are free to chose A and Ï• this must of course be true, as long the function is continuous. Remember we are looking at one single sample now, i.e. one point in time.
</p>
<p>So by using IQ Data we not only get the momentary values of our signal, but the function generating it as well. If we put above together we get:
</p>
<p>The real signal I = 0.8â‹…cos(30Â°)
</p>
<hr>
<ul><li>I/Q Data is the representation (data type) of this cosine function.
</li></ul><p>I/Q Data is the rectangular representation of the polar notation we used above. There is a unique transformation between the two, and the different notations have different properties calculating with them. The rectangular form of I/Q Data is chosen due to the ease of hardware implementations of the most common operations.
</p>
<p>I/Q Data consists of I and Q represented as two separate variables, a vector of length two, or more often, the complex number  I + Q<em>i</em>  (yes, I is the real part).
</p>
<p><img src="http://whiteboard.ping.se/uploads/SDR/polrep.png" alt="" title=""></p>
<p>Note that the Amplitude above is the waves peak amplitude, not the momentary amplitude.
</p>
<ul><li>I is the current momentary amplitude of the signal (i.e. the Real signal)
</li><li>Q is the momentary amplitude of the signal phase shifted -90Â°.
</li></ul><p>For a simple function such as sine, the phase shift is what the signal was earlier in time, but for a signal with more than one sine component, Q reflects a -90Â° shift of the individual components, and not the composite signal as such. To convert a Real Signal to a I/Q Data Signal, discrete Fourier transformation is required (Hilberts transform).
</p>
<h2>Different ways of representing the same I/Q Data Sample</h2>
<p>There are at least three common ways to represent the I/Q Data Sample. Different representations gives you different pros and cons. Some are more easy to add, other are more easy to multiply etc. This may be important in the implementation, resulting in less complex hardware/software using the best representation.
</p>
<h3>The rectangular form</h3>
<p>The I/Q Data on the form Q and I is called "rectangular" (or "Cartesian") form as it can be viewed as positions in a coordinate system. I and Q are the x and y axis respectively. This is the most common representation you are used to. This form is most common due the ease of modulating/demodulating it in hardware. More about that later.
</p>
<ul><li>As a complex number: I + Q<em>i</em>
</li><li>As a vector [I,Q]
</li><li>Or just the two plain variables I and Q
</li></ul><h3>The polar form</h3>
<ul><li>Amplitude and angle
</li></ul><p>I = Amplitudeâ‹…cos(angle) <br>Q = Amplitudeâ‹…sin(angle)
</p>
<p>The Amplitude is the peak amplitude of the cos (and sin) function, and the angle is how far into the period from zero to 360Â° you are (or 0 to 2Ï€ if you prefers radians).
</p>
<h3>Eulers form</h3>
<p>Since cos(Ï•) + iâ‹…sin(Ï•) = e<sup>iÏ•</sup> we can write our IQ sample as
</p>
<p><span> Ae<sup>iÏ•</sup> </span>
</p>
<p>This might (not?) be the most intuitive representation of the sample. Ï• rotates the angle as seen in the polar representation, and A is of course the amplitude. Realizing this, Eulers identity becomes obvious. Because Ï• is the rotation of the vector in the complex plane, rotating it half a turn, 180Â° or Ï€ radians, results in a real part of -1 and no imaginary part, hence:
</p>
<p><span> e<sup>Ï€i</sup>+1 = 0 </span>
</p>
<p><em>"The student should find this to be immediately obvious,</em> <br><em>otherwise he'll never be a first rate mathematician"</em>
</p>
<p><em>-- Carl Friedrich Gauss </em>
</p>
<h2>Positive versus negative frequency</h2>
<p>It is now easy to see that using I/Q we can represent the signal frequency either as positive or negative. Have a look at the two I/Q signals red and blue below to the left and compare them with their corresponding real projections. It is as obvious they differ in signs in I/Q, as it's impossible to determine the signs using only the real signal component (neither the I nor the Q projection separately).
</p>
<p><img src="http://whiteboard.ping.se/uploads/SDR/freqsign.gif" alt="Positive versus negative frequencies" title="Positive versus negative frequencies"></p>
<p><span>(sidenote: I've put them slightly out of phase compared to each other since else they wouldn't be possible to distinguish at all in the real representation to the right. Also, please note I'm here, quiet unconventional, using the x axis in the phasor for the imaginary <strong>Q</strong>)</span>
</p>
<p>The same signal (well, more or less) in a 3D representation.
</p>
<p>The <strong>I</strong> components (side view):
</p><p><img src="http://whiteboard.ping.se/uploads/SDR/sign-i.png" alt="" title=""></p>
<p>The <strong>Q</strong> components (top view):
</p><p><img src="http://whiteboard.ping.se/uploads/SDR/sign-q.png" alt="" title=""></p>
<p>The I/Q signals in 3D:
</p><p><img src="http://whiteboard.ping.se/uploads/SDR/sign-3d.png" alt="" title=""></p>
<p><a name="twopriceone" id="twopriceone"></a>
As the Nyquistâ€“Shannon sampling theorem states you can only represent
frequencies up to <code>f/2</code> using a samplings rate of <code>f</code>. This is still true
using IQ Data, but since you now can represent negative frequencies
the signal spans <code>[-f/2..+f/2]</code> compared to <code>[0..+f/2]</code> using a â„�eal signal,
hence the range is in effect doubled. Using a
sampling rate of <code>f</code> and you now can represent a signal range of <code>f</code> as well.
Two to the price of one!
</p>
<h2>Mixing and multiplying signals</h2>
<p>Using real signals or IQ Signals gives different results when you multiply them. This is because using only the real component it's not possible to uniquely determine the phase angle of the signal, hence impossible to distinguish a positive frequency from a negative.
</p>
<p><span><img src="http://whiteboard.ping.se/uploads/SDR/mix-real.png" alt="Mixing 10 kHz with 3 kHz using real" title="Mixing 10 kHz with 3 kHz using real"></span></p>
<p>Multiplying two signals f1 and f2 in the real domain:
</p>
<p><span> Â±f1 âŠ— Â±f2 = (Â±)f1 Â± f2 </span>
</p>
<p><span><img src="http://whiteboard.ping.se/uploads/SDR/mix-iq.png" alt="Mixing 10 kHz with 3 kHz using I/Q" title="Mixing 10 kHz with 3 kHz using I/Q"></span></p>
<p>Using IQ Data the signs are now given, and the result is unambiguous:
</p>
<p><span> f1 âŠ— f2 = f1 + f2 </span>
</p>
<p><br>
A frequency spectrum in the real domain usually never show the negative side, since it always must be symmetric around zero due to the uncertainty of the sign of the frequency of the real signal -- hence the parentheses around the sign of <code>f1</code> in the first formula mixing the real signals. I've included the negative side here for illustrative purposes, despite of its redundancy.
</p>
<p>Multiplying two complex number is easiest understood in the polar representation. The amplitude is multiplied and the angle added.
</p>
<p><span> A<sub>1</sub>â‹…e<sup>iÏ•<sub>1</sub></sup>â‹…A<sub>2</sub> e<sup>iÏ•<sub>2</sub></sup> = A<sub>1</sub>A<sub>2</sub> e<sup>i(Ï•<sub>1</sub>+Ï•<sub>2</sub>)</sup> </span>
</p>
<p>Realizing the angle is added under multiplication makes it obvious that the frequencies are added as well.
</p>
<h3>And in time domain ...</h3>
<p>Now let us have a look at this in time domain. To make it easier (doable!) to calculate the DFT in our …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://whiteboard.ping.se/SDR/IQ">http://whiteboard.ping.se/SDR/IQ</a></em></p>]]>
            </description>
            <link>http://whiteboard.ping.se/SDR/IQ</link>
            <guid isPermaLink="false">hacker-news-small-sites-25134698</guid>
            <pubDate>Wed, 18 Nov 2020 09:15:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Games released before PS4 are no longer appearing in search on PlayStation.com]]>
            </title>
            <description>
<![CDATA[
Score 193 | Comments 141 (<a href="https://news.ycombinator.com/item?id=25134263">thread link</a>) | @petepete
<br/>
November 18, 2020 | https://delistedgames.com/sony-basically-removed-25-years-of-history-from-playstation-com/ | <a href="https://web.archive.org/web/*/https://delistedgames.com/sony-basically-removed-25-years-of-history-from-playstation-com/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <!-- .entry-header -->


            <div>
                
<p>The heartbreak continues for those of us that relied on Sony’s websites to find and buy games or to research what was available. After <a href="https://delistedgames.com/sony-makes-it-official-playstation-3-psp-vita-removed-from-psn-website-between-october-21-and-26/">cutting out</a> older PlayStation content from the PlayStation Store over the past month, Sony’s eye has seemingly fallen on PlayStation.com and I find myself feeling gutted this morning. For those who didn’t use it regularly, PlayStation.com housed a gargantuan history of pages for North American PlayStation releases going all the way back to the original console from 1995. Up until this week you could easily find titles using the search box on the site but now anything before the PlayStation 4 returns a disappointing “<em>0 results found</em>“.</p>



<p>The older pages weren’t overflowing with info but they did offer some product details that I couldn’t easily find elsewhere. For newer games these pages also frequently retained links to the PlayStation Store which helped in my research. Even when they <em>were</em> on sale some games were just hard to find on the PlayStation Store while their PlayStation.com pages linked directly to them. Sometimes these pages were among the scant bits of evidence that I could find to confirm these games even existed digitally. Now, like with the changes to the PlayStation Store, all that’s gone too. Well, mostly gone.</p>



<p>Thankfully, like our “<a href="https://delistedgames.com/get-the-old-playstation-store-back-for-now/">old PS Store</a>” workaround, there’s still a way to search PlayStation.com but it might also eventually go away. Google’s “search within a site” function has been around for nearly a decade at this point but I’m sure lots of people don’t even know it exists. For our purposes just head to <em>the Google</em>, type ‘site:playstation.com’ and then whatever game you’re looking for. You can use Google’s other search operators to refine the results as well. Put it all together and it looks something like this: <strong>site:playstation.com “age of booty”</strong></p>



<p>You’ll get search results across the playstation.com domain including PlayStation Blog posts and PlayStation Store pages but look for the ones that specifically state ‘www.playstation.com’. In the case of Age of Booty the page gives us a description and even some screenshots as well as a ‘Buy Download’ link. Of course, the download page has been hidden by Sony’s recent changes to their sites but the URL remains accessible so you can check other territories or check it out using the “<a href="https://delistedgames.com/get-the-old-playstation-store-back-for-now/">old</a>” method. Yes, <a href="https://delistedgames.com/age-of-booty/">Age of Booty</a> is still delisted on PlayStation 3.</p>



<p>Maybe it was just a feature that only <strong><em>I</em></strong> benefited from but it’s really sad to see Sony ostensibly kill 25 years of PlayStation content on the web. It makes the nostalgia trip of Astro’s Playroom feel a little more hollow.</p>

                            </div>
            <!-- .entry-content -->



                    </div></div>]]>
            </description>
            <link>https://delistedgames.com/sony-basically-removed-25-years-of-history-from-playstation-com/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25134263</guid>
            <pubDate>Wed, 18 Nov 2020 08:10:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA["Equal pay for equal work" in remote jobs]]>
            </title>
            <description>
<![CDATA[
Score 222 | Comments 555 (<a href="https://news.ycombinator.com/item?id=25134220">thread link</a>) | @nityeshaga
<br/>
November 18, 2020 | https://www.nityesh.com/equal-pay-for-equal-work-at-a-remote-company/ | <a href="https://web.archive.org/web/*/https://www.nityesh.com/equal-pay-for-equal-work-at-a-remote-company/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="wrapper">
        <main id="main">
            <div>

                

                
<section>

    <header>
        <span>June 24, 2020</span>
        
            <p>Tough questions to ask your remote employer who gives you Cost Of Living based compensation and some thoughts on how remote compensation will work in the future</p>
    </header>

    <!--<div class="image main"><img src="/content/images/2020/06/micheile-henderson-03NMNUqHPdE-unsplash.jpg" alt="You should expect &quot;equal pay for equal work&quot; at your new remote job" /></div>-->

    <div>
        <figure><img src="https://www.nityesh.com/content/images/2020/06/micheile-henderson-03NMNUqHPdE-unsplash--1-.jpg" alt=""></figure><blockquote>Your star designer out in the sticks is just as valuable (maybe more so) to the team as those working from the big-city home office. Make sure she feels that way. <p>By the same token, as a remote worker, you shouldn’t let employers get away with paying you less just because you live in a cheaper city. “Equal pay for equal work” might be a dusty slogan, but it works for a reason. If with regard to compensation you accept being treated as a second-class worker based on location, you’re opening the door to being treated poorly on other matters as well.</p><p>- <a href="https://www.nityesh.com/books-read/#remote-office-not-required-by-david-heinemeier-hanson">Remote</a> by David Heinemeir Hanson and Jason Fried</p></blockquote><p>Almost all the knowledge jobs have become work-from-home in this sudden pandemic. Societies, companies, employees and job-seekers - all have been caught in this sudden shift in the way of working.</p><p>I am writing this for the new job-seekers. It's a tough market out there but you should still expect "equal pay for equal work" at whatever remote company you work for in the future. Most of us will probably not get it anytime soon but I believe that there's value in setting expectations.</p><h2 id="tough-questions-against-cost-of-living-col-based-adjustments">Tough questions against Cost Of Living (COL) based adjustments</h2><p>Big companies like Twitter, Shopify and Facebook have announced that they are adopting remote work for good. It's inevitable that this will pave the path for other companies to follow suit. </p><p>But along with this they might also make location based compensation the norm.</p><figure><blockquote><p lang="en" dir="ltr">Wait what? Facebook is seriously going to dunk someone's salary if they move? That's barbaric. <a href="https://t.co/xoV5XpstH3">https://t.co/xoV5XpstH3</a></p>— DHH (@dhh) <a href="https://twitter.com/dhh/status/1263544194359947264?ref_src=twsrc%5Etfw">May 21, 2020</a></blockquote>

</figure><p>Below I present some tough questions that you can ask your employer who has adopted this practice.</p><h3 id="-1-opening-the-doors-to-discrimination-at-work">#1. Opening the doors to discrimination at work</h3><p>If you don't live in the highest wage city of the world, you might have a peer at the company who lives in a more expensive city than you. Are you ready to be treated as a second-class employee just because of the geography that you live in?</p><p><em>How will you know that all the lousy work doesn't get passed on to you because it is justified in terms of 'returns on investment'?</em></p><p>When your manager has the final say, isn't it possible that they distribute work so that a low-risk, low-impact project is assigned to you while your "more expensive" peers get assigned the high-risk, high impact one?</p><p><strong>HR at your COL company</strong><em>: "We have a policy that says we won't discriminate based on the employee's location."</em></p><p>That's all well and good but what about the silent bias.</p><p><em>How can you be sure that your extremely well-meaning manager wasn't thinking about it when they assign you a project that you don't like? Wouldn't they be making a wise decision that is justified in terms of returns of investment? Can you be sure that they won't?</em></p><h3 id="-2-differences-in-government-spending-across-countries">#2. Differences in Government spending across countries</h3><p>Public spending enables governments to produce and purchase goods and services, in order to fulfil their objectives – such as the provision of public goods or the redistribution of resources - like social protection, education and healthcare.</p><p>Recent data on public spending reveals substantial cross-country heterogeneity. Relative to low-income countries, government expenditure in high-income countries tends to be much larger (both in per capita terms, and as share of GDP), and it also tends to be more focused on social protection.</p><figure><blockquote data-width="550"><p lang="en" dir="ltr">Yes! In Spain families with more than 2 children also get benefits from the government, but they have nothing to do with your employer.</p>— Rosa (@rosapolis) <a href="https://twitter.com/rosapolis/status/1264238728123465728?ref_src=twsrc%5Etfw">May 23, 2020</a></blockquote>

</figure><p>In India, the government spent about 1,700 US dollars per head (adjusted based on Purchasing Power Parity) in the year 2015; while in countries such as Norway, that figure was over 30,000 US dollars (adjusted based on PPP) and in USA it was over 21,000 USD.</p><!--kg-card-begin: html--><!--kg-card-end: html--><p>Source: <a href="https://ourworldindata.org/government-spending">https://ourworldindata.org/government-spending</a></p><p>This lack of government spending is ultimately passed on to the citizens who need to pay for these benefits with their own money, thus reflecting it in their costs of living.</p><p>An impotent public schooling system means that employees need to send their children to expensive private schools. A broken public hospital infracture means that people need to avail the expensive private hospitals for their healthcare. And a lot of these private enterprises are not above profiteering in times of crises.</p><p><em>How does cost of living based compensation take into account the differences in government spending accross countries? Shouldn't the employees be compensated for this difference?</em></p><h3 id="-3-relocations-get-complicated-at-best-and-outright-unfair-at-worst">#3. Relocations get complicated, at best and outright unfair, at worst</h3><p><em>What happens if I relocate to a lower paid region? Will I be compensated differently?</em></p><p>Companies like GitLab are pretty transparent about this. <a href="https://about.gitlab.com/handbook/total-rewards/compensation/#relocating">"Yes, you take a pay cut."</a></p><p><em>But what happens if I was living in a cheap city and decide to move to a more expensive one?</em></p><p>I asked the CEO of Gitlab. Here's what he replied -</p><figure><blockquote><p lang="en" dir="ltr">I don’t remember ever declining such a request.</p>— Sid Sijbrandij (@sytses) <a href="https://twitter.com/sytses/status/1264219857609912320?ref_src=twsrc%5Etfw">May 23, 2020</a></blockquote>

</figure><p>Coming from India, I know for a fact that a lot of people in lower-income countries will jump at this opportunity.</p><p><em>What happens if I choose to be a digital nomad changing cities every couple of months?</em></p><p><em>What if I choose to get an official address in some expensive city while I actually live in the suburbs?</em></p><h3 id="-4-loose-definition-of-cost-of-living">#4: Loose definition of "Cost of Living"</h3><p>The most common arguement against "equal pay for equal work" for remote employees is the difference in housing prices across cities/countries.</p><figure><blockquote><p lang="en" dir="ltr">But those COL adjustments are meant to reflect the local reality no (the house I live in here in SF will a lot cheaper in the middle of nowhere )? Assuming you have the same pool of money to pay people, how do you make sure people have the same experience regardless of place?</p>— Sriram Krishnan (@sriramk) <a href="https://twitter.com/sriramk/status/1263541004289753088?ref_src=twsrc%5Etfw">May 21, 2020</a></blockquote>

</figure><p>So, how do you define the "Cost of Living"?</p><p>Is it just the housing prices? And groceries? Restaurant bills, maybe?</p><p>That seems incomplete. It is only a small percentage of a lot of people's actual costs of living.</p><p>What about living with an elderly parent?</p><p>What about living a single life vs. being married? For that matter, how about having a stay-at-home spouse vs. having a spouse in a high-paying job?</p><p>What about the number of kids one has?</p><p>Number of dogs? Cats?</p><p><em>What's included in "Cost of Living"? </em></p><p><em>More importantly, who defines it? Should it be the employee who is actually incurring these costs? Or should it be the employer who is paying the employee?</em></p><figure><blockquote><div lang="en" dir="ltr"><p>If you’re going to pay people differentially based on where they choose to live, why not pay them differentially based on whether they have kids, too?</p><p>These little monsters are expensive, after all. I’ve got costs!</p></div>— Blair Reeves (@BlairReeves) <a href="https://twitter.com/BlairReeves/status/1263527961371738112?ref_src=twsrc%5Etfw">May 21, 2020</a></blockquote>

</figure><h3 id="other-tough-questions">Other tough questions</h3><ul><li><em>Who dictates the proportion in which I should be spending my money?</em></li></ul><p>Electronic devices from big brands are priced the same regardless of whether they are sold in the USA or Brazil. A Macbook would cost you the same every city of the world (except for the import duties that people outside the USA probably need to bear).</p><p>So, what if I choose to spend just 10% of my income on housing expenses and 30% surrounding myself with the latest tech gadgets from the world? And maybe another 40% investing in NASDAQ stocks?</p><p>It sure doesn't make sense to have a 100% of my salary reduced based on just 10% of my expenses.</p><ul><li><em>Where does the leadership in the company live? </em></li></ul><p>Leadership in companies that offer COL based compensation, often live and work in high-wage markets but they might feel differently if they were subject to lower pay for the same work.</p><ul><li><em>How do you account for the costs of reduced opportunities that employees, who don't live in primary talent markets, incur?</em></li></ul><p>People who don't live in the tech hubs of the world might have to bear costs in terms of reduced networking advantages and lesser alternate job opportunities.</p><hr><p>Unless a company is ready to give satisfactory answers to all such questions, it should default to equal pay for equal work.</p><figure><blockquote><div lang="en" dir="ltr"><p>Where you live is a consumption choice. We all make different choices based on what we like, and those are okay!</p><p>Just don’t penalize my compensation for your choices. Give me that bread! I’ve got a mortgage and a dog</p></div>— Blair Reeves (@BlairReeves) <a href="https://twitter.com/BlairReeves/status/1263285240098951168?ref_src=twsrc%5Etfw">May 21, 2020</a></blockquote>

</figure><p><em>People doing the same jobs and providing the same value should be paid the same.</em></p><p>It is simple. It is fair.</p><p><strong>A COL employer</strong>: <em>"But it's unreal!"</em></p><p>Actually, no. A lot of remote companies are doing this already:</p><figure><blockquote><p lang="en" dir="ltr">Adding <a href="https://twitter.com/podia?ref_src=twsrc%5Etfw">@podia</a>, <a href="https://twitter.com/ConvertKit?ref_src=twsrc%5Etfw">@ConvertKit</a>, <a href="https://twitter.com/MeetEdgar?ref_src=twsrc%5Etfw">@MeetEdgar</a>, <a href="https://twitter.com/WhimsicalPowers?ref_src=twsrc%5Etfw">@WhimsicalPowers</a>, <a href="https://twitter.com/boundless_HQ?ref_src=twsrc%5Etfw">@boundless_HQ</a>, <a href="https://twitter.com/honeycombio?ref_src=twsrc%5Etfw">@honeycombio</a>, <a href="https://twitter.com/upstream_tech?ref_src=twsrc%5Etfw">@upstream_tech</a>, <a href="https://twitter.com/timeular?ref_src=twsrc%5Etfw">@timeular</a> to this list. Pumped to see that <a href="https://twitter.com/automattic?ref_src=twsrc%5Etfw">@automattic</a> and <a href="https://twitter.com/photomatt?ref_src=twsrc%5Etfw">@photomatt</a> are doing equal pay for equal work as well, which I wasn't aware of! 🙌 <a href="https://t.co/YKW3SekIZU">https://t.co/YKW3SekIZU</a></p>— Nick Francis (@nickfrancis) <a href="https://twitter.com/nickfrancis/status/1262837601762869248?ref_src=twsrc%5Etfw">May 19, 2020</a></blockquote>

</figure><h2 id="tough-questions-against-equal-pay-for-equal-work-and-my-answers-to-them">Tough questions against "equal pay for equal work" and my answers to them</h2><p>There are some really tough questions on the other side as well. I have been thinking about them for a while now. I'll take a stab at composing a reply to them.</p><h3 id="isn-t-it-against-market-economics-to-pay-people-living-in-different-cities-of-the-world-the-same-money">"Isn't it against market economics to pay people, living in different cities of the world, the same money?"</h3><p>No, it is not. </p><p>On the contrary, I believe that equal pay for equal work is the default market state. </p><p>I say this because we already see it in a lot of places -</p><ul><li>Freelancers have been living this way for a long time now. Create a name for yourself and work for clients in the US from a beach in Bali.</li><li>When you start a company, your customers pay you money regardless of where you live (unless your product's value is market-specific).</li><li>Writing a book, teaching an online course, paid newsletters and other forms of passive income don't earn the creator a subsidised income based on the city that she lives in. </li></ul><p>This is because we, as consumers, pay for the value that we get …</p></div></section></div></main></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.nityesh.com/equal-pay-for-equal-work-at-a-remote-company/">https://www.nityesh.com/equal-pay-for-equal-work-at-a-remote-company/</a></em></p>]]>
            </description>
            <link>https://www.nityesh.com/equal-pay-for-equal-work-at-a-remote-company/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25134220</guid>
            <pubDate>Wed, 18 Nov 2020 08:03:16 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Rust from a Gopher – Lessons 7, 8 and 9]]>
            </title>
            <description>
<![CDATA[
Score 50 | Comments 57 (<a href="https://news.ycombinator.com/item?id=25133921">thread link</a>) | @BookPage
<br/>
November 17, 2020 | https://levpaul.com/posts/rust-lesson-7-8-9/ | <a href="https://web.archive.org/web/*/https://levpaul.com/posts/rust-lesson-7-8-9/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody"><p>Hello and welcome to the fifth post in my series about learning Rust. In case you want to hit it from the start, <a href="https://levpaul.com/posts/rust-lesson-1/">here’s</a> a link to the first one! This entire series covers my journey from being a completely land-locked Gopher to becoming (hopefully) a hardened Rustacean, able to skitter the hazardous seabed of any application safely.</p><hr><p>I can’t believe we’re at post number five! It’s been a wonderful ride, and I’ve been blown away by the helpful feedback from the Rust community at large. Thank you to everyone for all of the warm help.</p><p>Whilst I’m still in my infancy with Rust, it’s getting harder and harder to hold the itch to learn more. Often I want nothing more than to open the Rust Book and truck on with learning, blog posts be darned! However, I’ve made my commitment to myself, you and the Book, so every night; write, I do.</p><p>I’ve decided to make this post a <em>triple</em>, so let’s begin where we left off!</p><h3 id="7-packages-and-crates-and-stuffhttpsdocrust-langorgbookch07-00-managing-growing-projects-with-packages-crates-and-moduleshtmlmanaging-growing-projects-with-packages-crates-and-modules">7. <a href="https://doc.rust-lang.org/book/ch07-00-managing-growing-projects-with-packages-crates-and-modules.html#managing-growing-projects-with-packages-crates-and-modules">Packages and Crates and Stuff</a></h3><p>Right off the bat, I think this chapter is very well-placed. Even though it took me the entire chapter <em>grok</em> crates, modules and packages; I don’t think it came a line too early or late. Bravo! The chapter introduced many new keywords, such as <code>use</code>, <code>pub</code>, <code>mod</code>, <code>super</code>, but you walk away feeling like you can actually use them properly.</p><h4 id="modules">Modules</h4><p>Modules are introduced leaning heavily on the analogy of a file system… Now given that modules, at the most granular level, can be defined as single files <em>with the module name</em>, I’m actually wondering how much of this <em>is an analogy</em> and how much of it is really what’s happening at the compiler level. I would grin so hard if the bit about <strong><code>use</code></strong> being <em>like</em> a symlink <em>was</em> actually just a thing that was happening somewhere in the build chain. I’m sure it’s not though… Right.</p><h4 id="privacy">Privacy</h4><p>I enjoyed how the authors talked about privacy through scope. It helped me link project structure ideas with programming rules. For some reason I always thought of privacy as logical rules applied to code after the fact, rather than just having or not having something within a certain scope. It’s a lot easier to think about the later way. All this being said, there was also an overarching “Restaurant” example which they tried to tie in with privacy - check this gem:</p><blockquote><p>The way privacy works in Rust is that all items (functions, methods, structs, enums, modules, and constants) are private by default. […] To continue with the restaurant metaphor, think of the privacy rules as being like the back office of a restaurant: what goes on in there is private to restaurant customers, but office managers can see and do everything in the restaurant in which they operate.</p></blockquote><p>… I think that metaphor died somewhere in the rafters above the restaurant, and the smell could be starting to affect the food. Sorry.</p><p>For those who don’t know, privacy in Go is defined by whether you capitalize the first letter of your func/struct/interface name. Whilst lean and consistent - I much prefer the Rust approach. Rust is private by default unless you plop a <code>pub</code> in front of it. The main irk I have with the Go way is that Go’s naming convention also tells you acronyms should be entirely uppercase. So what happens when you want a private struct called <code>jsonData</code>? Well you have to think of something else because calling it <code>JSONData</code> will make it publicly exported and <code>jsonData</code> is not idiomatic. It’s definitely but only a nit, however I’ve become (unreasonably?) irked by it on more than one occasion.</p><h5 id="clean-your-room">Clean your room!</h5><p>The lesson proved once again that the Rust compiler is helpful. Gentle warnings about my variables being unused really makes me feel cared for. Go isn’t like this. Go grabs you by your collar and pierces your eardrums with a shrewd screech. It won’t let you go either. Like a harpy, the tiny chipmunk won’t let up. Thank Crabby for small mercies is all I can say.</p><p>On a more serious note though, I like this choice by Rust - my preference for most things I’d code would be to enforce compiler errors for unused variables; but it should be a compiler option; which as far as I know - it is <strong>not</strong>, in Go. I’m going to guess you should be able to upgrade the Rust warnings to errors through compiler flags somehow.</p><h5 id="re-exporting-imports">Re-exporting Imports</h5><p>This <a href="https://doc.rust-lang.org/book/ch07-04-bringing-paths-into-scope-with-the-use-keyword.html#re-exporting-names-with-pub-use">feature</a> of Rust gives me mixed feelings. As I understand it, when you <code>use</code> a package, that package can then bring more packages into your scope? I mean it does make sense from a library user-experience perspective, but I can’t help but feel like there’s a bit of trust going on here, if not only taste-trust. It’s definitely nice to just <code>use</code> a crate once and have everything you need to interact with it.</p><p>There’s only one Rust project I’m really interested in right now - a Game engine and editor called <a href="https://github.com/mrDIMAS/rg3d">rg3d</a>. I checked that project’s source for re-exports and found some in the top level <a href="https://github.com/mrDIMAS/rg3d/blob/master/src/lib.rs"><code>lib.rs</code></a>. Basically it just imports its own submodules publicly. I have no idea if this is idiomatic but to my lay-eyes this use-case looks correct and just.</p><p>Rust has been giving me a strong Java vibe from its imports. The nested paths feature seems good - ugly but succinct. Maybe my editor or <code>rustfmt</code> will automatically manage this for me? I enjoy not needing to worry about imports 99% of the time in Go, thanks to <code>goimports</code>, so hopefully that trend will continue in Rust.</p><h5 id="prelude-to-nothing">Prelude to Nothing</h5><p>In previous posts I mentioned being wooed by wistful mentions of a <code>prelude</code> by the Book. Well this chapter mentioned it again, and more than wistfully. It drowned my unquenchable satiety with <a href="https://doc.rust-lang.org/std/prelude/index.html">this link</a>, which to my utmost sorrow, was not a chapter in the Book. Alas, I read it in spite the fact. Oh, but my heart was flattened like my toddler’s playdough on a Sunday morning, for I was to find <strong>the prelude</strong> means nothing more than the default set of imports for a program. Through the sobriety of hindsight, I do question what else I was expecting. Given Rust doesn’t have a runtime, it doesn’t need anything fancy. Oh well, at least the great prelude mystery is solved.</p><h3 id="8-common-collectionshttpsdocrust-langorgbookch08-00-common-collectionshtml"><a href="https://doc.rust-lang.org/book/ch08-00-common-collections.html">8. Common Collections</a></h3><p>I just want to take a moment to swoon over Rust’s type inference again.</p><p>*<em><strong>swoons</strong></em>*</p><p>It’s fantastic. This is all…</p><hr><p>Now for actual chapter 8; it’s fairly dense. Covered is a brief introduction of standard library’s collections, Vectors, HashMaps and finally a deep dive into Rust Strings. Let’s begin the blow-by-blow starting with this gem:</p><div><pre><code data-lang="rust"><span>fn</span> <span>main</span><span>()</span><span> </span><span>{</span><span>
</span><span>    </span><span>let</span><span> </span><span>mut</span><span> </span><span>v</span><span> </span><span>=</span><span> </span><span>vec</span><span>!</span><span>[</span><span>1</span><span>,</span><span> </span><span>2</span><span>,</span><span> </span><span>3</span><span>,</span><span> </span><span>4</span><span>,</span><span> </span><span>5</span><span>];</span><span>
</span><span>    </span><span>let</span><span> </span><span>first</span><span> </span><span>=</span><span> </span><span>&amp;</span><span>v</span><span>[</span><span>0</span><span>];</span><span>
</span><span>    </span><span>v</span><span>.</span><span>push</span><span>(</span><span>6</span><span>);</span><span>
</span><span>    </span><span>println</span><span>!</span><span>(</span><span>"The first element is: {}"</span><span>,</span><span> </span><span>first</span><span>);</span><span>
</span><span></span><span>}</span><span>
</span></code></pre></div><p>Guess what won’t compile? Correct - the code above! What’s happening here is that <code>v</code> is mutable and <code>first</code> is immutable. If <code>v</code> needs to grow from something like a push; then this may end up moving the entire heap-allocated vector into another part of the heap. Had this to happen, then <code>first</code> would be a “dangling” ref to what <em>used</em> to be the first element of <code>v</code>.</p><p>Now what really tickles me is wondering about how that enforcement is encoded - what is <code>first</code> a reference to exactly? The Vec? No, my IDE tells me it’s an <code>&amp;i32</code> ref… But, somehow the compiler knows that <em>THAT</em> i32 ref is a child, or related to the Vec in the same scope. I
’d love to know more about how this works.</p><p>Perhaps not by major coincidence the Book offers up possibly the most perfect lead for such questions only paragraphs later… The Book introduces the <a href="https://doc.rust-lang.org/nomicon/vec.html">Rustinomicon</a>, telling us that we can peer into it to see details about how <code>vec</code> is made… At first, I was a little tense. Why does this reference-style-looking book have the Lovecraftian name? Only when I glimpsed the first line of its opening, did the ink droplets align:</p><h3 id="the-dark-arts-of-unsafe-rust"><code>The Dark Arts of Unsafe Rust</code></h3><p>…<em>followed by</em></p><p>THE KNOWLEDGE IS PROVIDED “AS IS”, WITHOUT WARRANTY OF ANY KIND, EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF UNLEASHING INDESCRIBABLE HORRORS THAT SHATTER YOUR PSYCHE AND SET YOUR MIND ADRIFT IN THE UNKNOWABLY INFINITE COSMOS.</p><h4 id="okay-this-looks-awesome"><strong>OKAY THIS LOOKS AWESOME</strong>.</h4><p>Flipping back to the <code>vec</code> chapter of the Rustinomicon, I realised it’s not at all a boring appendix style libdoc for vectors - the god damn tomb is teaching you to write your <em>OWN</em> std::Vec from scratch!</p><p>Good God, this is made me bite my lip in awkward nuclear attraction. I had some plans in mind for what I wanted to write about after this series. Right now the thought of doing a mini-series through the nomcon is sounding mighty fine though.. <em>More to come on this later</em>, as I managed to pry myself away and back to the lesson at hand.</p><hr><p>Looking through the method list (by god the <a href="https://doc.rust-lang.org/std/vec/struct.Vec.html">doc pages</a> are ugly; hint - only use the sidebar to navigate, do not bother free-scrolling), <code>vec</code> REALLY has some cool funcs. <code>dedup</code>, <code>drain</code>, <code>retain</code> all look to do what you’d expect. I jaunted quickly through <a href="https://doc.rust-lang.org/std/iter/trait.Iterator.html"><code>std::iter:Iterator</code></a> too and found SO many nice to haves, such as <code>gt</code>, <code>is_sorted</code>, <code>map</code>, <code>fold</code>, <code>filter</code>…</p><p>Seriously, I know there’s a lot you wouldn’t need here - but I really do wish we had simple collections/traits outside of slices and maps in Go. And yes, before I get screamed at - <em>I know</em> you can write your own in <a href="https://gobyexample.com/collection-functions">a few lines</a>, but it’s not the same - especially when you start involving complex data types. Being able to just conform to standard interfaces for elegance is something I adore and miss.</p><h4 id="string-theory">String Theory</h4><p>The chapter devotes a large swath to Strings and UTF-8. At first, I thought “how boring”, but then I realised I am the boring one! This is a much more interesting problem than I gave credit for and it made me go back to Go to better understand the “rune” system it uses for strings.</p><p>First, strings; there’s actually shit-loads of them in Rust… <code>OsString</code>, <code>CString</code>, <code>CStr</code>, <code>OsStr</code>… How wrong I was to assume a single String type in Rust indeed.</p><p>The stdlib provides many helpful functions over regular <code>String</code>. In Go, string is a part of <code>builtin</code>, but you use the stdlib’s <code>strings</code> package for more helpers.</p><hr><p><strong>Random question</strong>: Is there a difference between <code>String::from("")</code> and <code>String::new()</code>? According to this test; no:</p><div><pre><code data-lang="rust"><span>    </span><span>assert_eq</span><span>!</span><span>(</span><span>true</span><span>,</span><span> </span><span>String</span>::<span>from</span><span>(</span><span>""</span><span>)</span><span> </span><span>==</span><span> </span><span>String</span>::<span>new</span><span>());</span><span>
</span></code></pre></div><p>I’ve seen both methods being used so far and am not sure which one is “better”/idiomatic.</p><h4 id="indexing-into-strings">Indexing into Strings</h4><blockquote><p>A final reason …</p></blockquote></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://levpaul.com/posts/rust-lesson-7-8-9/">https://levpaul.com/posts/rust-lesson-7-8-9/</a></em></p>]]>
            </description>
            <link>https://levpaul.com/posts/rust-lesson-7-8-9/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25133921</guid>
            <pubDate>Wed, 18 Nov 2020 06:58:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[India’s WhiteHat Jr is startup hell]]>
            </title>
            <description>
<![CDATA[
Score 22 | Comments 4 (<a href="https://news.ycombinator.com/item?id=25133421">thread link</a>) | @_pythonlover_
<br/>
November 17, 2020 | https://themorningcontext.com/indias-whitehatjr-is-startup-hell/ | <a href="https://web.archive.org/web/*/https://themorningcontext.com/indias-whitehatjr-is-startup-hell/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="content">
	<div id="primary">
		<main id="main">

		
<article id="post-83914">
	<!-- .entry-header -->

			
			<p><img width="640" height="480" src="https://mk0themorningcocbq4h.kinstacdn.com/wp-content/uploads/2020/11/pexels-shamia-casiano-944743-1440x1080.jpg" alt="WhiteHat Jr" srcset="https://mk0themorningcocbq4h.kinstacdn.com/wp-content/uploads/2020/11/pexels-shamia-casiano-944743-1440x1080.jpg 1440w, https://mk0themorningcocbq4h.kinstacdn.com/wp-content/uploads/2020/11/pexels-shamia-casiano-944743-1024x768.jpg 1024w, https://mk0themorningcocbq4h.kinstacdn.com/wp-content/uploads/2020/11/pexels-shamia-casiano-944743-400x300.jpg 400w, https://mk0themorningcocbq4h.kinstacdn.com/wp-content/uploads/2020/11/pexels-shamia-casiano-944743-768x576.jpg 768w, https://mk0themorningcocbq4h.kinstacdn.com/wp-content/uploads/2020/11/pexels-shamia-casiano-944743-1536x1152.jpg 1536w, https://mk0themorningcocbq4h.kinstacdn.com/wp-content/uploads/2020/11/pexels-shamia-casiano-944743-2048x1536.jpg 2048w, https://mk0themorningcocbq4h.kinstacdn.com/wp-content/uploads/2020/11/pexels-shamia-casiano-944743-600x450.jpg 600w" sizes="(max-width: 640px) 100vw, 640px">			</p><!-- .post-thumbnail -->

							<!-- <div class="blog-feaured-img" style="background-image: url('');"></div> -->
		
		<div>
								<div>
						
<p>Shaarif Ansari got the call on 11 November at around 9 in the morning. On the phone was a police officer from Powai police station, in the suburbs of Mumbai. “Ansari please come to the police station,” said the officer. “We have received a complaint from your employer WhiteHat Jr. The company officials are here at the station already. We are waiting for you.”&nbsp;</p>


<p>Ansari was taken aback. It is not everyday that you have a police officer call you. Almost immediately he clarified that he did not work at WhiteHat Jr anymore. That he was fired by the company in the first week of September and had had no contact with them since, so what was all this about? The person was in no mood to explain or chat. He cut Ansari off, and asked him to turn up at the station immediately. Caught completely by surprise and with no idea about what was in store for him, Ansari said he was on his way.</p>

						<div>
							<div>
								<p>
									You can read this story by signing up for a <span><a href="https://themorningcontext.com/indias-whitehatjr-is-startup-hell/">free account</a></span>.  or <a href="https://themorningcontext.com/indias-whitehatjr-is-startup-hell/">log in</a> if you are already a member.
								</p>
							</div>
						</div>
					</div>
				
		
					</div><!-- .entry-content -->

					
				
				<div>
				<p><img src="https://mk0themorningcocbq4h.kinstacdn.com/wp-content/themes/tmc/images/auth-abt-close.svg" alt=""></p><div>
				<p>
				<h3>sign up to read the whole article</h3>
				<h5>PLUS OTHER FREE STORIES ON THE MORNING CONTEXT</h5>
		<!-- / 		<div class="tmc-form-container">
		// 			<img src="https://mk0themorningcocbq4h.kinstacdn.com/images/auth-abt-close.svg" alt="" class="close-sign-up">
		// 			<div class="width-setter">
		// 				<div class="left-side-content">
		// 					<h3 class="form-title main-title"></h3>
		// 					<h5 class="form-subtitle"></h3>
		// 					
		// 							// 				</div>
		// 				<div class="right-side-img">
		// 					<img src="https://mk0themorningcocbq4h.kinstacdn.com/images/half-ellipse.svg" alt="">
		// 				</div>
		// 			</div>
		// 		</div>
	-->
	</p></div></div></article><!-- #post-83914 -->

		</main><!-- #main -->
	</div><!-- #primary -->


	</div></div>]]>
            </description>
            <link>https://themorningcontext.com/indias-whitehatjr-is-startup-hell/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25133421</guid>
            <pubDate>Wed, 18 Nov 2020 05:10:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[40 millisecond bug]]>
            </title>
            <description>
<![CDATA[
Score 116 | Comments 25 (<a href="https://news.ycombinator.com/item?id=25133127">thread link</a>) | @sshroot
<br/>
November 17, 2020 | https://vorner.github.io/2020/11/06/40-ms-bug.html | <a href="https://web.archive.org/web/*/https://vorner.github.io/2020/11/06/40-ms-bug.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main_content_wrap">
      <section id="main_content">
        

<p>This is a small story about tracking down a production bug in a Rust
application. I don’t know if there’s any take away from this one for the reader,
but it felt interesting so I’m sharing it.</p>

<h2 id="a-bit-of-backstory">A bit of backstory</h2>

<p>In Avast, we have a Rust application called <a href="https://vorner.github.io/2019/05/19/rust-in-avast.html">urlite</a>. It serves as a backend to
some other applications, provides them a HTTP API. It’s in Rust because it is
latency critical. Latencies of most requests are under a millisecond.</p>

<p>It was written with <a href="https://docs.rs/tokio/0.1.*"><code>tokio-0.1</code></a> and <a href="https://docs.rs/hyper/0.12.*"><code>hyper-0.12</code></a> to deal with the HTTP. We
were quite late to update to newer versions, in part because it worked fine and
the amount of <code>async</code> code was single quite short function, so we didn’t have
much motivation. And in part because we use the <a href="https://crates.io/crates/spirit"><code>spirit</code></a> libraries for
configuration. It’s a library to take configuration and set up the internal
state of the program for it ‒ configuration contains the ports to listen to,
etc, and it manages spawning the HTTP server objects inside the program and can
even migrate from one set of ports to other at runtime.</p>

<p>But migrating <a href="https://crates.io/crates/spirit"><code>spirit</code></a> to newer <code>tokio</code> and <code>hyper</code> was a big task (because
the API surface is quite large, the library does a bit unusual things compared
to all the usual applications and the change between old and new <code>tokio</code> was
quite large).</p>

<p>Anyway, eventually I got permission to work on the migration of <a href="https://crates.io/crates/spirit"><code>spirit</code></a> as
part of my job. It took about a week to migrate both <a href="https://crates.io/crates/spirit"><code>spirit</code></a> and <a href="https://vorner.github.io/2019/05/19/rust-in-avast.html">urlite</a>. It
went through review, went through the automatic tests and we put it to the
staging environment for a while, watching the logs and graphs. Everything seemed
fine, so after few days of everything looking fine, we pushed the button and put
it to production.</p>

<h2 id="the-increased-latencies">The increased latencies</h2>

<p>As it goes in these kinds of stories, by now you’re expecting to see what went
wrong.</p>

<p>The thing is, our own metrics and graphs were fine. But the latency on the
downstream service querying us increased by 40ms. The deployment got reverted,
and we started to dig into where these latencies come from.</p>

<h2 id="it-was-acting-really-weird">It was acting really weird</h2>

<p>There were several very suspicious things about that.</p>

<ul>
  <li>Our own „internal“ latencies stayed the same. Our CPU usage also stayed the
same.</li>
  <li>The latency graph on the downstream side was flat 40ms <em>constant</em>.</li>
</ul>

<p>Now, if we introduced some performance regression in the query handling, we
would expect our CPU consumption to rise. We would also expect the latency graph
to be a bit spiky, not completely flat 40ms constant. It almost looked like
there was a 40ms <code>sleep</code> somewhere. But why would anyone put a 40ms sleep
anywhere?</p>

<p>I’ve looked through documentation and didn’t see anything obvious. I’ve tried
searching both our code and code of the dependencies for <code>40</code>, asked on Slack if
that <code>40ms</code> value was familiar to anyone. Nothing.</p>

<p>The working theory we started with was that there could be some kind of back-off
sleep on some kind of failure. Maybe <code>hyper</code> would be closing inactive
connections in the new version, forcing the application to reconnect (the graph
was for 99th percentile, so if we happened to close each 100th connection and
reconnection took this long…) and maybe try IPv6 first and we would be listening
on IPv4 only or… (in other words, we didn’t have a clear clue).</p>

<h2 id="the-benchmarks">The benchmarks</h2>

<p>My colleague started to investigate in a more thorough way than just throwing
ideas around on Slack. He run a <code>wrk</code> benchmark against the service. On his
machine, the latencies were fine. So he commandeered one of the stage nodes to
play with it and run the benchmark there. And every request had 40ms latency on
that machine. The previous version of <code>urlite</code> was fine, with under one
millisecond.</p>

<p><em>Something</em> was probably sleeping somewhere on the production servers, but not
on the development machine. There probably was some difference in the OS
settings, but definitely difference in the kernel version. The servers are
running some well-tried Linux distribution, so they have a lot older version,
while a developer is likely to run something much more on the edge.</p>

<h2 id="configuration-options">Configuration options</h2>

<p>The selling point of <a href="https://crates.io/crates/spirit"><code>spirit</code></a> is that most of the thing one can set in the
builders of various libraries and types now can be just put into a config file
without any recompilation. If we did configuration by hand, we would expose only
the things we thought would be useful, but with spirit, there’s everything. So,
naturally, tweaking some of the config knobs was the next step (because it was
easy to do).</p>

<p>It was discovered that turning the <code>http1-writev</code> option <em>off</em>, which
corresponds to
<a href="https://docs.rs/hyper/0.13.8/hyper/server/struct.Builder.html#method.http1_writev">this method</a>
in <code>hyper</code>, made the latencies go away.</p>

<p>We now had a solution, but I wasn’t happy about not understanding <em>why</em> that
helped, so I went to dig the rabbit hole and find the root cause. Turns out
there were several little things in just the constellation to make the problem
manifest.</p>

<h2 id="overriding-the-defaults-of-http1_writev">Overriding the defaults of <code>http1_writev</code></h2>

<p>The method controls the strategy in which way data are pushed into the socket.
With vectored writes enabled, it sends two separate buffers (one with headers,
the other with the body if it’s small enough) through a single <a href="https://linux.die.net/man/2/writev"><code>writev</code></a>
syscall.  If they are disabled, <code>hyper</code> copies all the bytes into a single
buffer and sends that as a whole.</p>

<p>It turns out that the method takes a <code>bool</code>, but there are actually 3 states.
The third (auto) is signalled by <em>not</em> calling the method and <code>spirit-hyper</code> was
calling it always, with the default to turn the <a href="https://linux.die.net/man/2/writev"><code>writev</code></a> on. I don’t know if
leaving it on auto would make the bug go away, but I’ve fixed the problem in the
library anyway.</p>

<h2 id="splitting-vectored-writes">Splitting vectored writes</h2>

<p>Spirit wants to support a bit of configuration on top of what the underlying
libraries provide on their own. One of such things is limiting the number of
concurrently accepted connections on a single listening socket. Users don’t have
to take advantage of that (the types for the configuration can be composed
together to either contain that bit or not and the administrator may leave the
values for the limits unset in the configuration and then they won’t be
enforced).</p>

<p>Anyway, in case the support for the limits is opted in through using the type
with the configuration fields, the connections themselves are wrapped in a
<a href="https://docs.rs/spirit-tokio/0.7.*/spirit_tokio/net/limits/struct.Tracked.html"><code>Tracked</code></a>
type. The type tries to be mostly transparent for use and can be used inside
<code>hyper</code> (which is what the default configuration type alias in <code>spirit-hyper</code>
does), but tracks how many connections there are, to not accept more if it runs
out of the limit.</p>

<p>When implementing the bunch of traits for the wrapper, I’ve overlooked the
<a href="https://docs.rs/tokio/0.2.*/tokio/io/trait.AsyncWrite.html#method.poll_write_buf"><code>AsyncWrite::poll_write_buff</code></a>.
It is a provided method, which means it has a default implementation. It is the
one that abstracts the OS-level <code>writev</code>, it can write multiple buffers (the
<a href="https://docs.rs/bytes/0.5.*/bytes/buf/trait.Buf.html"><code>Buf</code></a> represents a
segmented buffer).</p>

<p>The default implementation simply delegates to multiple calls to the ordinary
write. Therefore, this omission combined with the default of enabling vectored
writes results in calling into the kernel twice, each time with a small buffer,
instead of once with two small buffers or once with a big buffer.</p>

<p>That was definitely something to get fixed, because if nothing else, syscalls
are expensive and calling more of them is not great. But I’ve finally felt like
I’m on the right path, because:</p>

<h2 id="nagles-algorithm">Nagle’s algorithm</h2>

<p>You probably know that TCP stream is built from packets going there and back.
Optimizing how to split the stream into the packets and when to send them is a
hard problem and the research in that area is still ongoing, because there are
many conflicting requirements. One wants to deliver the data with low latency,
utilize the whole bandwidth, but not overflow the capacity of the link (in which
case the latencies would go up or packets would get lost and would have to be
retransmitted), leave some bandwidth to other connections, etc.</p>

<p>The <a href="https://en.wikipedia.org/wiki/Nagle%27s_algorithm">Nagle’s algorithm</a> is
one of the older tricks up in TCP’s sleeve. The network doesn’t like small
packets.  It is better to send as large packets as the link allows, because each
packet has certain overhead ‒ the headers that take some space, but also routers
spend computation power mostly based on number of packets and less on their
size. If you start sending a lot of tiny packets, the performance will suffer.
While the links are limited by the number of bytes that can pass through them,
routers are more limited by the number of packets. If a router declares to be
able to handle a gigabit connection, it actually means a gigabit <em>if you use
full-sized packets</em>, but will get to few megabits if you split the data into
tiny packets.</p>

<p>So it would be better to wait until the send buffer contains a packetfull of
data before sending anything. But we can’t do that, because we don’t <em>know</em>
there’ll ever be a full packet of data, or generating more data might wait for
the other side to answer. We would never send anything and wait forever and the
Internet would not work.</p>

<p>Instead, the algorithm is willing to send <em>one</em> undersized packet and then it
waits for an <code>ACK</code> from the other side until sending another undersized one. If
it gets a packetfull of data to send in the meantime, that’s great and it sends
it (it won’t get better by waiting longer), but it won’t ever have two
undersized ones somewhere in flight, therefore won’t kill the network’s
performance by them.</p>

<p>This works, it’ll make progress eventually because once the <code>ACK</code> comes and
all the data that accumulated until then is sent.</p>

<p>But it also slows things down. Like in our case. What happens if we do it using
single syscall, the whole HTTP response forms a single undersized packet (we
have really small answers) and gets sent, no matter if it’s submitted to the
kernel by one big or two small buffers.</p>

<p>On the other hand, if we split the submission into two syscalls, this is what
happens:</p>

<ul>
  <li>We write the first part (headers). The kernel sends them out as an undersized
packet.</li>
  <li>We write the second part (the body). But the kernel shelves them into the send
buffer and waits for sending them until it sees the <code>ACK</code>, because there’s one
undersized packet …</li></ul></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://vorner.github.io/2020/11/06/40-ms-bug.html">https://vorner.github.io/2020/11/06/40-ms-bug.html</a></em></p>]]>
            </description>
            <link>https://vorner.github.io/2020/11/06/40-ms-bug.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25133127</guid>
            <pubDate>Wed, 18 Nov 2020 04:09:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Math of Password Hashing Algorithms and Entropy (2019)]]>
            </title>
            <description>
<![CDATA[
Score 77 | Comments 9 (<a href="https://news.ycombinator.com/item?id=25133061">thread link</a>) | @mooreds
<br/>
November 17, 2020 | https://fusionauth.io/learn/expert-advice/security/math-of-password-hashing-algorithms-entropy/ | <a href="https://web.archive.org/web/*/https://fusionauth.io/learn/expert-advice/security/math-of-password-hashing-algorithms-entropy/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            
              <p>Here’s the reality, billions of credentials have been leaked or stolen and are now easily downloaded online by anyone. Many of these databases of identities include passwords in plain text, while others are one-way hashed. One-way hashing is better (we’ll get to why in a second), but it is only as secure as is mathematically feasible. Let’s take a look at one-way hashing algorithms and how computers handle them.</p>

<h2 id="hashing">Hashing</h2>

<p>A hash by definition is a function that can map data of an arbitrary size to data of a fixed size. SHA2 is a hashing algorithm that uses various bit-wise operations on any number of bytes to produce a fixed sized hash. For example, the SHA-256 algorithm produces a 256 bit result. The algorithm was designed specifically so that going from a hash back to the original bytes is infeasible. Developers use an SHA2 hash so that instead of storing a plain text password, they instead only store the hash. When a user is authenticated, the plain text password they type into the login form is hashed, and because the algorithm will always produce the same hash result given the same input, comparing this hash to the hash in the database tells us the password is correct.</p>

<h2 id="cracking-passwords">Cracking Passwords</h2>

<p>While one-way hashing means we aren’t storing plain text passwords, it is still possible to determine the original plain text password from a hash. Next, we’ll outline the two most common approaches of reversing a hash.</p>

<h3 id="lookup-tables">Lookup Tables</h3>

<p>The first is called a lookup table, or sometimes referred to as a rainbow table. This method builds a massive lookup table that maps hashes to plain text passwords. The table is built by simply hashing every possible password combination and storing it in some type of database or data-structure that allows for quick lookups.</p>

<p>Here’s an example of a lookup table for SHA2 hashed passwords:</p>

<div><div><pre><code><span>sha2_hash                                                          password</span>
<span>-----------------------------------------------------------------------------------------</span>
<span>e150a1ec81e8e93e1eae2c3a77e66ec6dbd6a3b460f89c1d08aecf422ee401a0   </span><span>123456</span>
<span>e5d316bfd85b606e728017e9b6532e400f5f03e49a61bc9ef59ec2233e41015a   broncosfan123</span>
<span>561acac680e997e22634a224df2c0931cf80b9f7c60102a4e12e059f87558232   Letmein</span>
<span>bdc511ea9b88c90b75c3ebeeb990e4e7c813ee0d5716ab0431aa94e9d2b018d6   newenglandclamchowder</span>
<span>9515e65f46cb737cd8c191db2fd80bbd05686e5992b241e8ad7727510b7142e6   opensesame</span>
<span>6b3a55e0261b0304143f805a24924d0c1c44524821305f31d9277843b8a10f4e   password</span>
<span>c194ead20ad91d30c927a34e8c800cb9a13a7e445a3ffc77fed14176edc3c08f   xboxjunkie42</span>
</code></pre></div></div>

<p>Using a lookup table, all the attacker needs to know is the SHA2 hash of the password and they can see if it exists in the table. For example, let’s assume for a moment that Netflix stores your password using an SHA2 hash. If Netflix is breached, their user database is likely now available to anyone with a good internet connection and a torrent client. Even a mediocre hacker now only needs to lookup the SHA2 hash associated with your Netflix account to see if it exists in their lookup table. This will reveal nearly instantly what your plain text password is for Netflix. Now, this hacker can log in to your Netflix account and binge watch all four seasons of Fuller House (“how rude!”). And he can also try this password on Hulu and HBO Go to see if you used the same email address and password for those accounts as well.</p>

<p><img src="https://fusionauth.io/assets/img/blogs/salt.png" alt="Salt"></p>

<p>The best way to protect against this type of attack is to use what is called a <strong>salt</strong>. A salt is simply a bunch of random characters that you prepend to the password before it is hashed. Each password should have a different salt, which means that a lookup table is unlikely to have an entry for the combination of the salt and the password. This makes salts an ideal defense against lookup tables.</p>

<p>Here’s an example of a salt and the resulting combination of the password and the salt which is then hashed:</p>

<div><div><pre><code><span>// Bad, no salt. Very bland.</span>
<span>sha2</span><span>(</span><span>"password"</span><span>)</span> <span>// 6b3a55e0261b0304143f805a24924d0c1c44524821305f31d9277843b8a10f4e</span>

<span>// Better, add a salt.</span>
<span>salt</span> <span>=</span> <span>";L'-2!;+=#/5B)40/o-okOw8//3a"</span>
<span>toHash</span> <span>=</span> <span>";L'-2!;+=#/5B)40/o-okOw8//3apassword"</span>
<span>sha2</span><span>(</span><span>toHash</span><span>)</span> <span>// f534e6bf84a638112e07e69861927ab624c0217c0655e4d3be07659bcf6c1c07</span>
</code></pre></div></div>

<p>Now that we have added the salt, the “password” that we actually generated the hash from was the String <code>;L'-2!;+=#/5B)40/o-okOw8//3apassword</code>. This String is long, complex and contains a lot of random characters. Therefore, it is nearly impossible that the hacker that created the lookup table would have generated the hash for the String <code>;L'-2!;+=#/5B)40/o-okOw8//3apassword</code>.</p>

<h3 id="brute-force">Brute Force</h3>

<p><img src="https://fusionauth.io/assets/img/blogs/hulk.png" alt="Brute Force"></p>

<p>The second method that attackers use to crack passwords is called brute force cracking. This means that the attacker writes a computer program that can generate all possible combinations of characters that can be used for a password and then computes the hash for each combination. This program can also take a salt if the password was hashed with a salt. The attacker then runs the program until it generates a hash that is the same as the hash from the database. Here’s a simple Java program for cracking passwords. We left out some detail to keep the code short (such as all the possible password characters), but you get the idea.</p>



<div><div><pre><code><span>import</span> <span>org.apache.commons.codec.digest.DigestUtils</span><span>;</span>

<span>public</span> <span>class</span> <span>PasswordCrack</span> <span>{</span>
  <span>public</span> <span>static</span> <span>final</span> <span>char</span><span>[]</span> <span>PASSWORD_CHARACTERS</span> <span>=</span> <span>new</span> <span>char</span><span>[]</span> <span>{</span><span>'a'</span><span>,</span> <span>'b'</span><span>,</span> <span>'c'</span><span>,</span> <span>'d'</span><span>};</span>

  <span>public</span> <span>static</span> <span>void</span> <span>main</span><span>(</span><span>String</span><span>...</span> <span>args</span><span>)</span> <span>{</span>
    <span>String</span> <span>salt</span> <span>=</span> <span>args</span><span>[</span><span>0</span><span>];</span>
    <span>String</span> <span>hashFromDatabase</span> <span>=</span> <span>args</span><span>[</span><span>1</span><span>].</span><span>toUpperCase</span><span>();</span>

    <span>for</span> <span>(</span><span>int</span> <span>i</span> <span>=</span> <span>6</span><span>;</span> <span>i</span> <span>&lt;=</span> <span>8</span><span>;</span> <span>i</span><span>++)</span> <span>{</span>
      <span>char</span><span>[]</span> <span>ca</span> <span>=</span> <span>new</span> <span>char</span><span>[</span><span>i</span><span>];</span>

      <span>fillArrayHashAndCheck</span><span>(</span><span>ca</span><span>,</span> <span>0</span><span>,</span> <span>salt</span><span>,</span> <span>hashFromDatabase</span><span>);</span>
    <span>}</span>
  <span>}</span>

  <span>private</span> <span>static</span> <span>void</span> <span>fillArrayHashAndCheck</span><span>(</span><span>char</span><span>[]</span> <span>ca</span><span>,</span> <span>int</span> <span>index</span><span>,</span> <span>String</span> <span>salt</span><span>,</span> <span>String</span> <span>hashFromDatabase</span><span>)</span> <span>{</span>
    <span>for</span> <span>(</span><span>int</span> <span>i</span> <span>=</span> <span>0</span><span>;</span> <span>i</span> <span>&lt;</span> <span>PASSWORD_CHARACTERS</span><span>.</span><span>length</span><span>;</span> <span>i</span><span>++)</span> <span>{</span>
      <span>ca</span><span>[</span><span>index</span><span>]</span> <span>=</span> <span>PASSWORD_CHARACTERS</span><span>[</span><span>i</span><span>];</span>

      <span>if</span> <span>(</span><span>index</span> <span>&lt;</span> <span>ca</span><span>.</span><span>length</span> <span>-</span> <span>1</span><span>)</span> <span>{</span>
        <span>fillArrayHashAndCheck</span><span>(</span><span>ca</span><span>,</span> <span>index</span> <span>+</span> <span>1</span><span>,</span> <span>salt</span><span>,</span> <span>hashFromDatabase</span><span>);</span>
      <span>}</span> <span>else</span> <span>{</span>
        <span>String</span> <span>password</span> <span>=</span> <span>salt</span> <span>+</span> <span>new</span> <span>String</span><span>(</span><span>ca</span><span>);</span>
        <span>String</span> <span>sha2Hex</span> <span>=</span> <span>DigestUtils</span><span>.</span><span>sha2Hex</span><span>(</span><span>password</span><span>).</span><span>toUpperCase</span><span>();</span>
        <span>if</span> <span>(</span><span>sha2Hex</span><span>.</span><span>equals</span><span>(</span><span>hashFromDatabase</span><span>))</span> <span>{</span>
          <span>System</span><span>.</span><span>out</span><span>.</span><span>println</span><span>(</span><span>"plain text password is ["</span> <span>+</span> <span>password</span> <span>+</span> <span>"]"</span><span>);</span>
          <span>System</span><span>.</span><span>exit</span><span>(</span><span>0</span><span>);</span>
        <span>}</span>
      <span>}</span>
    <span>}</span>
  <span>}</span>
<span>}</span>
</code></pre></div></div>

<p>This program will generate all the possible passwords with lengths between 6 and 8 characters and then hash each one until it finds a match. This type of brute-force hacking takes time because of the number of possible combinations.</p>

<h2 id="password-complexity-vs-computational-power">Password complexity vs. computational power</h2>

<p>Let’s bust out our TI-85 calculators and see if we can figure out how long this program will take to run. For this example we will assume the passwords can only contain ASCII characters (uppercase, lowercase, digits, punctuation). This set is roughly 100 characters (this is rounded up to make the math easier to read). If we know that there are at least 6 characters and at most 8 characters in a password, then all the possible combinations can be represented by this expression:</p>

<div><div><pre><code>possiblePasswords = 100^8 + 100^7 + 100^6
</code></pre></div></div>

<p>The result of this expression is equal to <code>10,101,000,000,000,000</code>. This is quite a large number, North of 10 quadrillion to be a little more precise, but what does it actually mean when it comes to our cracking program? This depends on the speed of the computer the cracking program is running on and how long it takes the computer to execute the SHA2 algorithm. The algorithm is the key component here because the rest of the program is extremely fast at creating the passwords.</p>

<p>Here’s where things get dicey. If you run a quick Google search for <a href="http://lmgtfy.com/?q=fastest+bitcoin+rig">“fastest bitcoin rig”</a> you’ll see that these machines are rated in terms of the number of hashes they can perform per second. The bigger ones can be rated as high as <code>44 TH/s</code>. That means it can generate 44 tera-hashes per second or <code>44,000,000,000,000</code>.</p>

<p>Now, if we divide the total number of passwords by the number of hashes we can generate per second, we are left with the total time it takes a Bitcoin rig to generate the hashes for all possible passwords. In our example above, this equates to:</p>

<div><div><pre><code>bitcoinRig = 4.4e13
possiblePasswords = 100^8 + 100^7 + 100^6 = 1.0101e16

numberOfSeconds = possiblePasswords / bitcoinRig = ~230
numberOfMinutes = numberOfSeconds / 60 = ~4
</code></pre></div></div>

<p>This means that using this example Bitcoin rig, we could generate all the hashes for a password between 6 and 8 characters in length in roughly 4 minutes. Feeling nervous yet? Let’s add one additional character and see long it takes to hash all possible passwords between 6 and 9 characters.</p>

<div><div><pre><code>bitcoinRig = 4.4e13
possiblePasswords = 100^9 + 100^8 + 100^7 + 100^6 = 1.010101E18

numberOfSeconds = possiblePasswords / bitcoinRig = 22,956
numberOfMinutes = numberOfSeconds / 60 = ~383
numberOfHours = numberOfMinutes / 60 = ~6
</code></pre></div></div>

<p>By adding one additional character to the potential length of the password we increased the total compute time from 4 minutes to 6 hours. This is nearing a 100x increase in computational time to use the brute force strategy. You probably can see where this is going. To defeat the brute force strategy, you simply need to make it improbable to calculate all possible password combinations.</p>

<p>Let’s get crazy and make a jump to 16 characters:</p>

<div><div><pre><code>bitcoinRig = 4.4e13
possiblePasswords = 100^16 + 100^15 ... 100^7 + 100^6 = 1e32

numberOfSeconds = possiblePasswords / bitcoinRig = 2.27e18
numberOfMinutes = numberOfSeconds / 60 = 3.78e16
numberOfHours = numberOfMinutes / 60 = 630,000,000,000,000 or 630 trillion
numberOfDays = numberOfHours / 24 = 26,250,000,000,000 or 26.25 trillion days
numberOfYears = numberOfDays / 365 = 71,917,808,219 or 71.9 billion years
</code></pre></div></div>

<p>To boil down our results, if we take these expressions and simplify them, we can build an equation that solves for any length password.</p>

<div><div><pre><code>numberOfSeconds = 100^lengthOfPassword / computeSpeed
</code></pre></div></div>

<p>This equation shows that as the password length increases, …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://fusionauth.io/learn/expert-advice/security/math-of-password-hashing-algorithms-entropy/">https://fusionauth.io/learn/expert-advice/security/math-of-password-hashing-algorithms-entropy/</a></em></p>]]>
            </description>
            <link>https://fusionauth.io/learn/expert-advice/security/math-of-password-hashing-algorithms-entropy/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25133061</guid>
            <pubDate>Wed, 18 Nov 2020 04:00:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Write Code Like You Write a Recipe]]>
            </title>
            <description>
<![CDATA[
Score 104 | Comments 82 (<a href="https://news.ycombinator.com/item?id=25133041">thread link</a>) | @ahungry
<br/>
November 17, 2020 | https://ahungry.com/blog/2020-11-17-Write-Code-Like-You-Write-a-Recipe.html | <a href="https://web.archive.org/web/*/https://ahungry.com/blog/2020-11-17-Write-Code-Like-You-Write-a-Recipe.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="text-orgdb8398b">
<p>
As it tends to do, time continues to move on.  The project and code in
it eventually becomes legacy code (aka, someone else's problem to
maintain).
</p>

<p>
One day, the business drudges up that old automated cookie creation
idea and requests that it handles a new task - "instead of just cooking
peanut butter cookies, it'd be great if the cookie system could handle
oatmeal raisin as well!".
</p>

<p>
Hah!  You remember that old system, but you're onto newer and better
things.  This is a perfect task for the intern to sink their teeth
into - afterall, it's legacy and not high profile, it's been stable,
and it was so simple to implement the first time around.
</p>

<p>
The new set of requirements/recipe the intern works off of looks very
similar to the initial ones:
</p>

<ul>
<li>Step 1: Preheat oven to 325F, grease cookie sheet</li>
<li>Step 2: In bowl, stir oats, pumpkin puree and sugar until smooth.</li>
<li>Step 3: Beat in one egg white, then stir in baking soda, salt, and cinnamon.</li>
<li>Step 4: Roll dough into 1 inch balls and place 2 inches apart on the sheet.</li>
<li>Step 5: Bake for 8 minutes, cool for 5, enjoy!</li>
</ul>

<p>
He eagerly begins to expand the original code to handle the new case:
</p>

<div>
<pre><span>function</span> <span>makeCookies</span> <span>(</span><span>type</span> = <span>'peanut-butter'</span><span>)</span> <span>{</span>
  <span>if</span> <span>(</span>type === <span>'peanut-butter'</span><span>)</span> <span>{</span>
    oven.setTemperature<span>(</span>350<span>)</span>
  <span>}</span>

  <span>if</span> <span>(</span>type === <span>'oatmeal-raisin'</span><span>)</span> <span>{</span>
    oven.setTemperature<span>(</span>325<span>)</span>
  <span>}</span>

  sheet.grease<span>()</span>

  <span>if</span> <span>(</span>type === <span>'peanut-butter'</span><span>)</span> <span>{</span>
    bowl.add<span>(</span>peanutButter<span>)</span>
    bowl.add<span>(</span>sugar<span>)</span>
  <span>}</span>

  <span>if</span> <span>(</span>type === <span>'oatmeal-raisin'</span><span>)</span> <span>{</span>
    bowl.add<span>(</span>oats<span>)</span>
    bowl.add<span>(</span>pumpkinPuree<span>)</span>
    bowl.add<span>(</span>sugar<span>)</span>
  <span>}</span>

  bowl.stir<span>()</span>

  <span>if</span> <span>(</span>type === <span>'peanut-butter'</span><span>)</span> <span>{</span>
    bowl.beat<span>(</span>egg<span>)</span>
    bowl.beat<span>(</span>egg<span>)</span>
    bowl.stirIn<span>(</span><span>[</span>bakingSoda, salt, vanilla<span>]</span><span>)</span>
  <span>}</span>

  <span>if</span> <span>(</span>type === <span>'oatmeal-raisin'</span><span>)</span> <span>{</span>
    bowl.beat<span>(</span>eggWhite<span>)</span>
    bowl.stirIn<span>(</span><span>[</span>bakingSoda, salt, cinnamon<span>]</span><span>)</span>
  <span>}</span>

  <span>const</span> <span>dough</span> = bowl.makeDough<span>()</span>
  sheet.add<span>(</span>dough.balls<span>()</span><span>)</span>
  oven.add<span>(</span>sheet<span>)</span>

  <span>if</span> <span>(</span>type === <span>'peanut-butter'</span><span>)</span> <span>{</span>
    oven.setTimer<span>(</span>10<span>)</span>
  <span>}</span>

  <span>if</span> <span>(</span>type === <span>'oatmeal-raisin'</span><span>)</span> <span>{</span>
    oven.setTimer<span>(</span>8<span>)</span>
  <span>}</span>

  <span>const</span> <span>cookies</span> = oven.remove<span>(</span>sheet<span>)</span>
  sheet.cool<span>(</span>5<span>)</span>

  <span>return</span> cookies
<span>}</span>
</pre>
</div>

<p>
The code comes in, the peer reviews pass it as it meets the
requirements and nothing is obviously wrong.  Still, it has become a
bit harder to understand and you're left with a nagging feeling.
</p>
</div></div>]]>
            </description>
            <link>https://ahungry.com/blog/2020-11-17-Write-Code-Like-You-Write-a-Recipe.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25133041</guid>
            <pubDate>Wed, 18 Nov 2020 03:56:33 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Run x86 Apps (including homebrew) in the Terminal on Apple Silicon]]>
            </title>
            <description>
<![CDATA[
Score 216 | Comments 129 (<a href="https://news.ycombinator.com/item?id=25132217">thread link</a>) | @JoshuaMulliken
<br/>
November 17, 2020 | https://www.notion.so/Run-x86-Apps-including-homebrew-in-the-Terminal-on-Apple-Silicon-8350b43d97de4ce690f283277e958602 | <a href="https://web.archive.org/web/*/https://www.notion.so/Run-x86-Apps-including-homebrew-in-the-Terminal-on-Apple-Silicon-8350b43d97de4ce690f283277e958602">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://www.notion.so/Run-x86-Apps-including-homebrew-in-the-Terminal-on-Apple-Silicon-8350b43d97de4ce690f283277e958602</link>
            <guid isPermaLink="false">hacker-news-small-sites-25132217</guid>
            <pubDate>Wed, 18 Nov 2020 01:41:41 GMT</pubDate>
        </item>
    </channel>
</rss>
