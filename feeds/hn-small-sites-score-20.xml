<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 20]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 20. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Tue, 15 Dec 2020 12:41:04 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-20.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Tue, 15 Dec 2020 12:41:04 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[Who Owns the Stars: The Trouble with Urbit]]>
            </title>
            <description>
<![CDATA[
Score 63 | Comments 33 (<a href="https://news.ycombinator.com/item?id=25404575">thread link</a>) | @deegles
<br/>
December 12, 2020 | http://distributedweb.care/posts/who-owns-the-stars/ | <a href="https://web.archive.org/web/*/http://distributedweb.care/posts/who-owns-the-stars/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  <h2>
  <a href="http://distributedweb.care/">
    Distributed Web of Care
  </a>
  </h2>
  <section>
    
    

    <p>by Francis Tseng</p>

<p>The application that introduced peer-to-peer (P2P) computing to the mainstream was file sharing, services like Napster, Kazaa, Gnutella, and BitTorrent. For me, these programs were the first time the contradiction of artificial scarcity‚Äîthe imposed scarcity of infinitely replicable digital information‚Äîand the excessive measures that were used to enforce it became startlingly clear. Over time, I encountered the term P2P in other settings and alongside other ideas‚Äîdemocratic governance, communalism, autonomy, cooperatives‚Äîand I started to see the purchase this idea had beyond file sharing and networking protocols.</p>

<p><a href="https://p2pfoundation.net/the-p2p-foundation/about-the-p2p-foundation">The P2P Foundation‚Äôs mission and strategic priorities</a>, for example, extend the early P2P ideas of open culture and exchange into values of cooperative living and regenerative production. <a href="https://www.scuttlebutt.nz/principles/">Scuttlebutt, a more recent P2P social networking protocol, has its own ‚Äúprinciples stack‚Äù</a> that similarly advocates pluralistic exchange and mutual interdependence. It‚Äôs beautiful how, at least in the ideal scenario, by using a P2P service we are helping others access it as well. P2P is both an acknowledgment of our shared needs and an example of how cooperation helps us fulfill those needs.</p>

<p>Over the years, I‚Äôve followed along with P2P projects because of these shared values, and I always find it exciting when new projects emerge. It seems that P2P is experiencing something of a renaissance, likely due to the frenzy around blockchain (which purports to offer something similar to P2P) and the increasing popular anxiety around centralized internet services like Facebook.</p>

<p>Urbit, ‚Äú<a href="https://urbit.org/">a personal server built from scratch</a>,‚Äù first came across my radar a couple of years ago. Urbit positions itself as a P2P project, but it stands out in contrast to other P2P projects, mainly because the person behind it, Curtis Yarvin, seems antithetical to what I understand P2P to represent.</p>

<p>My central question is this: <em>Is Urbit a project that should be supported?</em></p>

<p>We can further break this down into two parts. First, Urbit‚Äôs marketing materials correctly identify that concentrated data aggregation and decision-making power are fundamental issues of the internet-as-we-know-it. Twitter‚Äôs persistent neglect of harassment on its platform is one everyday example. It is clear that new protocols and platforms that reduce our dependency on distant power are needed to challenge these issues. What‚Äôs less clear, though, is whether or not Urbit actually offers a meaningful alternative. Does Urbit genuinely enable new kinds of relations? Or, does it merely replace the old aristocracy with a new one?</p>

<p>The second, and more urgent, question is: who and what are we supporting by supporting Urbit? Many people in tech still believe that technology can be divorced from its creators; however, those of us in tech need to recognize that we have a considerable amount of influence over which products enter the mainstream consciousness, which products get created at all, and who receives both financial and social capital (shout out to <a href="https://techworkerscoalition.org/">Tech Workers Coalition</a> et al.). For example, consider Peter Thiel , who co-founded PayPal and was an early investor in Facebook. Early support of PayPal and Facebook contributed to their financial success, which developed Thiel‚Äôs influence and made him quite rich. Thiel then turned that money and influence into Palantir Technologies, a software company that <a href="https://theintercept.com/2017/03/02/palantir-provides-the-engine-for-donald-trumps-deportation-machine/">develops technologies to help expand surveillance and deportation for the government</a>. We have to consider what similar groundwork we help to lay by supporting Urbit.</p>

<h2 id="context">Context</h2>

<p>In order to discuss Urbit‚Äôs design, we need to have an understanding of the politics of its creator, Curtis Yarvin. <a href="https://en.wikipedia.org/wiki/Curtis_Yarvin">Curtis Yarvin</a> is innocuously described on Wikipedia as an ‚ÄúAmerican political theorist and computer scientist,‚Äù but to many, he is better known as <a href="https://www.theatlantic.com/politics/archive/2017/02/behind-the-internets-dark-anti-democracy-movement/516243/">one of the intellectual forebears of the alt-right</a>. From 2007 to 2014<sup id="fnref:1"><a href="#fn:1">1</a></sup>, working under the pen name Mencius Moldbug, Yarvin writings, which among other things espoused anti-democratic ideas and scientific racism and helped introduce many of what are now understood as the alt-right‚Äôs foundational ideologies to a wider public. The term ‚Äúred pill,‚Äù which describes the process of reactionary radicalization and the community around it, was first used in this way by Yarvin.<sup id="fnref:2"><a href="#fn:2">2</a></sup> Defenders of Urbit are quick to dismiss any inclusion of Yarvin‚Äôs politics in discussions about Urbit as unfair or irrelevant, and might point out that Yarvin left the project in January of this year.<sup id="fnref:3"><a href="#fn:3">3</a></sup> However, given that Yarvin basically laid out the general design for Urbit independently, as he worked on it alone for 11 years<sup id="fnref:3:1"><a href="#fn:3">3</a></sup> and in parallel with his political writings<sup id="fnref:4"><a href="#fn:4">4</a></sup>, and that Urbit, as a P2P project, is a fundamentally social and thus incorporates ideas about how people should be organized, Yarvin‚Äôs politics should be considered as something that influences his design decisions and his long-term vision for the project. <a href="https://lobste.rs/s/z5j1hq/urbit_2017#c_4z4gik">Dog-whistles</a> have been identified in some of his writing about Urbit and its design, including his <a href="https://urbit.org/posts/essays/the-dao-as-a-lesson-in-decentralized-governance/">leaning on Nazi philosopher Carl Schmitt</a> for questions around Urbit‚Äôs governance.</p>

<p>To save space I‚Äôll provide only a very brief overview of Yarvin‚Äôs political philosophy‚Äîif you like, you can read more about it <a href="https://thebaffler.com/latest/mouthbreathing-machiavellis">here</a>, <a href="https://www.viewpointmag.com/2017/03/28/the-darkness-at-the-end-of-the-tunnel-artificial-intelligence-and-neoreaction/">here</a>, <a href="https://thebaffler.com/latest/the-moldbug-variations-pein">here</a>, and <a href="https://slatestarcodex.com/2013/10/20/the-anti-reactionary-faq/">here</a>.</p>

<p>Yavin refers to his brand of political philosophy as ‚Äúneocameralism.‚Äù Neocameralism, as described in his essay ‚Äú<a href="https://www.unqualified-reservations.org/2007/08/against-political-freedom/">Against Political Freedom</a>,‚Äù is a political philosophy arguing that state should be run like a business, (i.e., with a CEO at its head and no democratic mechanisms). His ideas are credited as being foundational to the ‚Äú<a href="https://techcrunch.com/2013/11/22/geeks-for-monarchy/">neoreactionary‚Äù movement</a>, which could be described as a neo-monarchist movement (though Yarvin himself doesn‚Äôt identify as a ‚Äúmonarchist‚Äù because of its association with a constitutional monarchy and not absolute monarchy). In the neoreactionary movement, ‚Äúdivine right‚Äù is supplanted with ‚Äúgenetic right‚Äù based on scientific racism reframed as ‚Äúhuman biodiversity.‚Äù Yarvin‚Äôs writings are also popular within the right-libertarian sects of Silicon Valley, such as <a href="https://thebaffler.com/latest/the-moldbug-variations-pein">with Peter Thiel</a> (<a href="https://www.theverge.com/2017/2/21/14671978/alt-right-mencius-moldbug-urbit-curtis-yarvin-tlon">Peter Thiel also has a stake in Tl√∂n</a>, Yarvin‚Äôs company which develops Urbit, via Thiel‚Äôs VC firm, Founders Fund). The point here is that Yarvin is not a fringe philosopher. His writings have influence over people with considerable power and contributes to the intellectual miasma that emboldens and normalizes anti-democratic, anti-immigrant, misogynistic, and racist policies and attacks.</p>

<h2 id="urbit">Urbit</h2>
<h4 id="a-self-sovereign-internet">A self-sovereign internet</h4>

<p>Urbit positions itself as infrastructure for self-sovereignty in the digital age, liberating people from ceding control of their data to corporations.<sup id="fnref:5"><a href="#fn:5">5</a></sup> The core idea is that Urbit helps you run a personal server that acts as an intermediary between you and other services, including existing services like Facebook (yes, there is a lot more to Urbit‚Äîsuch as its reinvention of parts of the lower-level computational stack‚Äîbut its P2P layer is what‚Äôs of interest here).</p>

<p>Self-sovereignty is an important principle, and I wager that many who regularly use the internet would agree that more of it is valuable for a healthy internet: for being able to control who can access your data, who can and cannot contact you, and so on. <em>But</em>, self-sovereignty is far too vague of a concept on its own. Left- and right-libertarianism both start with self-sovereignty as a core value, but they end up with vastly different conceptions of what meaningful self-sovereignty looks like and how it can be achieved. Left-libertarianism finds that self-sovereignty arises from social organizing, care, and democratic governance, which build towards positive freedoms (freedom to learn, to flourish, and so on); whereas, right-libertarianism believes it comes from the market and that negative freedoms (freedom from restrictions and regulation) are the goal. Though Yarvin does not identify as a libertarian (he is, in his own words, sympathetic to it), his neocameralism is right-libertarianism taken to its logical conclusion<sup id="fnref:6"><a href="#fn:6">6</a></sup> of corporate tyranny and serfdom.</p>

<p>To draw an example that you might be familiar with, consider the Twitter-alternative, Gab, which markets itself as a bastion for free speech. Gab, in practice, operates as a niche platform for members of the far-right who have been banned from Twitter: ‚Äú<a href="https://www.nytimes.com/2018/10/28/us/gab-robert-bowers-pittsburgh-synagogue-shootings.html">a haven for white nationalists, neo-Nazis and other extremists</a>‚Äù. We might ask then, is Gab a platform for free speech, or is it a platform for hate speech? Who‚Äôs speech does Gab prioritize? It quickly becomes clear that the concept of ‚Äúfree speech‚Äù that Gab deploys is not quite the same as what others see it to mean.</p>

<p>In a similar way, this slipperiness of self-sovereignty as a concept, especially in light of Yarvin‚Äôs political writings, makes me suspicious of what it really means in the context of Urbit. Is Urbit actually designed to give users more autonomy and control? Does it restore any power to internet users?</p>

<p>One central design feature of Urbit is its network hierarchy. As a participant in Urbit, you may be a galaxy (the top of the hierarchy), a star (which fall under galaxies), or a planet (which fall under stars). The description of this hierarchy <a href="https://github.com/cgyarvin/urbit/blob/6ac688960687aa9c89d4da6fff49a3125c10aca1/Spec/urbit/3-intro.txt">used to use explicitly feudal metaphors</a> as part of what Yarvin called ‚Äúdigital feudalism,‚Äù with himself as the ‚Äúprince,‚Äù and further contributes to my suspicion of Yarvin‚Äôs conception of self-sovereignty actually entails.</p>

<p>In trying to backpedal on these naming conventions, Yarvin claims that his ideas about governance are flipped for the internet:</p>

<blockquote>
  <p>If the real world today is governed as an insanely dysfunctional republic, and the Internet today is governed as a cluster of insanely despotic corporate monarchies, it doesn‚Äôt strike me as at all inconsistent with historical thought to treat the former case of misgovernment with efficient monarchism, and the latter case with liberating republicanism.<sup id="fnref:7"><a href="#fn:7">7</a></sup></p>
</blockquote>

<p>The rationale for why the ‚Ä¶</p></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="http://distributedweb.care/posts/who-owns-the-stars/">http://distributedweb.care/posts/who-owns-the-stars/</a></em></p>]]>
            </description>
            <link>http://distributedweb.care/posts/who-owns-the-stars/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25404575</guid>
            <pubDate>Sun, 13 Dec 2020 05:41:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[To listen well, get curious]]>
            </title>
            <description>
<![CDATA[
Score 109 | Comments 17 (<a href="https://news.ycombinator.com/item?id=25403240">thread link</a>) | @axiomdata316
<br/>
December 12, 2020 | https://www.benkuhn.net/listen/ | <a href="https://web.archive.org/web/*/https://www.benkuhn.net/listen/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><figure><a href="https://www.benkuhn.net/listen/shawarma.jpg" title="fullsize"><img width="414" height="139" src="https://www.benkuhn.net/listen/shawarma_hu8d3539d292afb8dcad4d284a93a9ab60_28658_828x278_resize_q75_box.jpg" srcset="https://www.benkuhn.net/listen/shawarma_hu8d3539d292afb8dcad4d284a93a9ab60_28658_828x278_resize_q75_box.jpg 2x, https://www.benkuhn.net/listen/shawarma_hu8d3539d292afb8dcad4d284a93a9ab60_28658_414x139_resize_q75_box.jpg"></a><figcaption><a href="https://twitter.com/thecassiecao/status/1276506378388017155/photo/1">source</a></figcaption></figure><p>A common piece of interacting-with-people advice goes: ‚Äúoften when people complain, they don‚Äôt want help, they just want you to listen!‚Äù</p><p>For instance, <em>Nonviolent Communication</em>:<sup><label for="sn0">‚úª</label><span><span><sup>‚úª</sup>
<em>Nonviolent Communication</em>, ch. 7.</span></span></sup></p><blockquote><p>It is often frustrating for someone needing empathy to have us assume that they want reassurance or ‚Äúfix-it‚Äù advice.</p></blockquote><p><em>Active Listening</em>:<sup><label for="sn1">‚Ä†</label><span><span><sup>‚Ä†</sup>
<a href="https://www.benkuhn.net/listen/active-listening.pdf">Active Listening</a>, p. 2</span></span></sup></p><blockquote><p>Similarly, advice and information are almost always seen as efforts to change a person and thus serve as barriers to his self-expression and the development of a creative relationship.</p></blockquote><p>You can find similar advice in most books on relationships, people management, etc.</p><p>This always used to seem silly to me. If I complain at my partner and she ‚Äújust listens,‚Äù I‚Äôve accomplished nothing except maybe made her empathetically sad. When I complain at people, I want <em>results</em>, not to grouse into the void!<sup><label for="sn2">‚Ä°</label><span><span><sup>‚Ä°</sup>
Empirically, I did notice that I usually got better results from listening than from giving advice. So I inferred that this advice was true for other people, but not me, because other people didn‚Äôt actually want to fix their problems.</span></span></sup></p><p>Frequently the ‚Äújust listen‚Äù advice comes with tactical tips, like ‚Äúreflect what people said back to you to prove that you‚Äôre listening.‚Äù For instance, consider these example dialogues from <em>Nonviolent Communication</em>:<sup><label for="sn3">¬ß</label><span><span><sup>¬ß</sup>
<em>Nonviolent Communication</em>, Chapter 7, Exercise 5.5, 5.6 and solutions.</span></span></sup></p><blockquote><p>Person A: How could you say a thing like that to me?</p><p>Person B: Are you feeling hurt because you would have liked me to agree to do what you requested?</p></blockquote><p>Or:</p><blockquote><p>Person A: I‚Äôm furious with my husband. He‚Äôs never around when I need him.</p><p>Person B: So you‚Äôre feeling furious because you would like him to be around more than he is?</p></blockquote><p>I say this with great respect for <em>Nonviolent Communication</em>, but these sound like a <a href="https://en.wikipedia.org/wiki/ELIZA" target="_blank">1970s-era chatbot</a>. If I were Person A in either of these dialogues my next line would be ‚Äúyes, you dingbat‚Äîcan you turn the nonviolence down a couple notches?‚Äù I‚Äôd feel alienated knowing that someone is going through their NVC checklist on me.</p><hr><p>Recently, I realized why people keep giving this weird-seeming advice. Good listeners <em>do</em> often reflect words back‚Äîbut not because they read it in a book somewhere. Rather, it‚Äôs <a href="https://en.wikipedia.org/wiki/Cargo_cult_science" target="_blank">cargo cult advice</a>: it teaches you to imitate the surface appearance of good listening, but misses what‚Äôs actually important, the thing that‚Äôs <em>generating</em> that surface appearance.</p><p>The generator is curiosity.</p><p>When I‚Äôve listened the most effectively to people, it‚Äôs because I was intensely curious‚ÄîI was trying to build a <em>detailed, precise</em> understanding of what was going on in their head. When a friend says, ‚ÄúI‚Äôm furious with my husband. He‚Äôs never around when I need him,‚Äù that one sentence has a huge amount underneath. How often does she need him? What does she need him for? Why isn‚Äôt he around? Have they talked about it? If so, what did he say? If not, why not?</p><p>It turns out that <a href="http://johnsalvatier.org/blog/2017/reality-has-a-surprising-amount-of-detail" target="_blank">reality has a surprising amount of detail</a>, and those details can matter a lot to figuring out what the root problem or best solution is. So if I want to help, I can‚Äôt treat those details as a black box: I need to <a href="https://www.lesswrong.com/posts/B7P97C27rvHPz3s9B/gears-in-understanding" target="_blank">open it up and see the gears inside</a>. Otherwise, anything I suggest will be wrong‚Äîor even if it‚Äôs right, I won‚Äôt have enough ‚Äúshared language‚Äù with my friend for it to land correctly.</p><p>Some stories from recent memory:</p><ul><li><p>When we started doing a pair programming rotation at Wave, I suggested that, to make scheduling easier, we designate a default time when pairing sessions would happen. A coworker objected that this seemed authoritarian. I was extremely puzzled, but they‚Äôd previously mentioned being an anarchist, so I was tempted to just chalk it up to a political disagreement and move on. But instead I tried to get curious and explore more deeply whatever ‚Äúpolitical‚Äù models were generating that disagreement. After a lot of digging into what was or wasn‚Äôt authoritarian for them and why, it turned out the disagreement was because they‚Äôd missed the word ‚Äúdefault‚Äù and thought I was suggesting a single <em>mandatory</em> time for pair programming.</p></li><li><p>My partner, Eve, wrote a post about Polish attitudes about sex, with some details that upset her (Polish) parents. When her parents told her that, she initially got very stressed about having to have a conversation to calm them down. I thought she shouldn‚Äôt be worried and the conversation would be fine, but of course just telling her that wasn‚Äôt very helpful. Instead, I summoned up my curiosity and asked lots of questions about her relationship with her parents, her parents‚Äô relationship with each other, each of their relationships with Catholicism, etc. By the end of the conversation, after thinking through all the baggage involved, Eve agreed with me, and her attitude about the upcoming conversation shifted from impending doom to compassionate curiosity about where her parents were coming from.</p></li><li><p>I was stressed by work and complained to Eve about some things that I felt frustrated and stuck about. Instead of suggesting solutions, she kept asking for more details until she had more or less a complete snapshot of my mental state. At that point, she observed that every time I mentioned feeling sad, I sounded contemptuous and exasperated with myself. She hypothesized that I wasn‚Äôt giving myself permission to be sad. The ‚Äúsolution‚Äù to my problem ended up being to give me a big hug and let me cry on her shoulder for a bit, after which I immediately felt much less stressed.</p></li></ul><p>In each case, the ‚Äúhelper‚Äù tried to learn about the ‚Äúcomplainer‚Äôs‚Äù reality in as much detail as possible‚Äînot just the problem, but the whole person and whatever else was behind the immediate issue. And that‚Äôs what made it possible for them to actually help.</p><p>It often feels like I understand enough to be helpful without knowing all those details. But when I think that, I‚Äôm usually wrong: I end up giving bad advice, based on bad assumptions, and the person I‚Äôm talking to ends up having to do a bunch of work to argue with me and correct my bad assumptions. That makes the conversation feel disfluent and adversarial instead of collaborative.</p><p>It turns out this is a really common failure mode of helping-conversations, which is what I think generates the old saw at the beginning of this post, that ‚Äúsometimes people don‚Äôt want help, just to be listened to.‚Äù</p><p>But I think that‚Äôs actually too nice to the helper, and uncharitable to the complainer (in that it assumes they weirdly don‚Äôt care about solving their problem). What‚Äôs really going on is probably that your advice is bad, because you didn‚Äôt really listen, because you weren‚Äôt curious enough.</p><hr><p>When I‚Äôm curious about what someone‚Äôs saying, I often do repeat things back to them in my own words. But it‚Äôs because I‚Äôm genuinely curious, not because I‚Äôm checking off the ‚Äúreflect words‚Äù box in my ‚Äúbe a good listener‚Äù checklist. That means I do it in a way that sounds like my natural speech, instead of mimicking them like a chatbot.</p><p>When done this way, reflective listening feels validating rather than alienating. It‚Äôs a way of demonstrating that I care a lot about what someone has to say. Putting their idea into my own words shows them that I‚Äôve fully digested it, and helps us establish a shared language in which to talk about it. That, in turn, makes the conversation fluent and collaborative, rather than a zigzag of bad assumptions and corrections.</p><p>So the right advice isn‚Äôt ‚Äúlisten harder and repeat everything back‚Äù‚Äîyou won‚Äôt be genuine if you‚Äôre just imitating the surface appearance of a good listener. Instead, be humble and get curious! Remind yourself that there‚Äôs a ton of detail behind whatever you‚Äôre hearing, and try to internalize all of it that you can. Once you‚Äôve done that, your advice will be more likely hit the mark, and you‚Äôll be able to communicate it clearly.</p></article></div>]]>
            </description>
            <link>https://www.benkuhn.net/listen/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25403240</guid>
            <pubDate>Sun, 13 Dec 2020 00:45:06 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Why radio receivers won‚Äôt tune 800-900 MHz]]>
            </title>
            <description>
<![CDATA[
Score 339 | Comments 120 (<a href="https://news.ycombinator.com/item?id=25403163">thread link</a>) | @jtakkala
<br/>
December 12, 2020 | https://computer.rip/2020-11-28%20the%20verboten%20band.html | <a href="https://web.archive.org/web/*/https://computer.rip/2020-11-28%20the%20verboten%20band.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://computer.rip/2020-11-28%20the%20verboten%20band.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25403163</guid>
            <pubDate>Sun, 13 Dec 2020 00:32:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Rizin ‚Äì a free and open-source Reverse Engineering framework]]>
            </title>
            <description>
<![CDATA[
Score 37 | Comments 7 (<a href="https://news.ycombinator.com/item?id=25402690">thread link</a>) | @homarp
<br/>
December 12, 2020 | https://rizin.re/posts/announcing-rizin/ | <a href="https://web.archive.org/web/*/https://rizin.re/posts/announcing-rizin/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><article><div><p>We are excited to announce Rizin ‚Äî a <strong>free</strong> and <strong>open-source</strong> Reverse Engineering framework, providing a complete binary analysis experience with features like Disassembler, Hexadecimal editor, Emulation, Binary inspection, Debugger, and more.</p><p>Rizin is a fork of radare2 with a focus on usability, stability, and working features, which strives to provide a welcoming environment for developers and users alike. Rizin was founded by a group of the core developers of radare2 and Cutter who contributed to the project in one way or the other in the past years and together constructed the Core group of radare2. With the establishment of Rizin, we are committed to creating an environment and a project which will be aligned with our values and vision.</p><p>During recent years, the environment that was created in radare2 was one where many of us felt stressed, disrespected, and unwelcome. Moreover, the number of users of radare2 grew every year, and we held the ultimate responsibility to provide them a stable, usable framework. As the core developer team, we have come to the conclusion that it is impossible for us to continue to pursue the goal of making radare2 better under the current circumstances and environment, and we decided to move forward on our own and fork the project. Cutter, the Graphical User Interface for radare2, and its entire team will also join Rizin and will use it as its backend.</p><p>Rizin is a newborn project that was created from radare2, hence more and more changes and differences will appear over time. A lot of efforts were put into improving our workflows, putting more tests in place, improving the API, removing redundant features, and more. We hope to provide better consistency between releases, making the framework more trustworthy to users.</p><p>We are also working to create a more inclusive and diverse community that will be inviting for new contributors and users. As an initial step, we adopted a <a href="https://rizin.re/code-of-conduct">Code of Conduct</a> that we believe is aligned with our values and with the community we want to create around Rizin.</p><p>Finally, we know and understand that now it is our turn to prove that Rizin can become a tool you can trust and enjoy using, and a community in which you feel welcome. We invite you to read our answers to your <a href="https://rizin.re/posts/faq/">Frequently Asked Questions</a> and join our communities on <a href="https://im.rizin.re/">Mattermost</a> and other chat platforms.</p></div></article></div></div>]]>
            </description>
            <link>https://rizin.re/posts/announcing-rizin/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25402690</guid>
            <pubDate>Sat, 12 Dec 2020 23:11:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Bulk loading into PostgreSQL: Options and comparison]]>
            </title>
            <description>
<![CDATA[
Score 83 | Comments 18 (<a href="https://news.ycombinator.com/item?id=25402430">thread link</a>) | @eatonphil
<br/>
December 12, 2020 | https://www.highgo.ca/2020/12/08/bulk-loading-into-postgresql-options-and-comparison/ | <a href="https://web.archive.org/web/*/https://www.highgo.ca/2020/12/08/bulk-loading-into-postgresql-options-and-comparison/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
                        
<p>You have a file, possibly a huge CSV, and you want to import its content into your database. There are lots of options to do this but how would you decide which one to use. More often than not the&nbsp;question is how much time would the&nbsp;bulk load would take. I found my self&nbsp;doing the same few days back when I wanted to design a data ingestion process for PostgreSQL where we needed to bulk load around 250GB of data from CSV files every 24 hours.</p>



<p>Goto solution for bulk loading into PostgreSQL is the native copy command. But one limitation with the copy command is that it requires the CSV file to be placed on the server. So I decided to do a simple comparison of bulk loading options and techniques.</p>



<p>In short I wanted to see the performance difference of loading the data into standard vs unlogged tables and want to compare the loading time difference between loading into table that has an index vs drop-index-&gt;load-&gt;recreate-index option.</p>



<p>Moreover, I wanted to see the performance difference of COPY command, client-side copy command, loading through file_fdw, and pg_bulkload for each of the above options.</p>



<h2>Database and system settings</h2>



<p>Since the intention was to do a relative performance comparison among different data loading techniques and options, so using the personal MacBook Pro running macOS Catalena with 16GB of RAM, 2.7 GHz Quad-Core Intel Core i7 processor, and 500 GB SSD disk was good enough to serve the purpose. </p>



<p>For database I compiled PostgreSQL v12 from source code with default configure options. I left most of the configuration parameter to their default values and only changed the below mentioned settings.</p>



<pre><code>shared_buffers = 2GB
work_mem = 400MB
maintenance_work_mem = 640MB
</code></pre>



<h2>Sample data and schema</h2>



<p>For the purpose of this exercise, I downloaded a sample CSV file from <a href="http://eforexcel.com/wp/downloads-18-sample-csv-files-data-sets-for-testing-sales/">http://eforexcel.com/wp/downloads-18-sample-csv-files-data-sets-for-testing-sales/</a> with 5million rows.</p>



<p>The sample CSV file contains 5 million rows, 14 columns and 624MB in size.</p>



<p><img loading="lazy" width="986" height="71" src="https://www.highgo.ca/wp-content/uploads/2020/12/1-3.png" alt="" srcset="https://www.highgo.ca/wp-content/uploads/2020/12/1-3.png 986w, https://www.highgo.ca/wp-content/uploads/2020/12/1-3-300x22.png 300w, https://www.highgo.ca/wp-content/uploads/2020/12/1-3-768x55.png 768w" sizes="(max-width: 986px) 100vw, 986px"></p>



<p><img loading="lazy" width="2618" height="390" src="https://www.highgo.ca/wp-content/uploads/2020/12/sample-csv.png" alt="" srcset="https://www.highgo.ca/wp-content/uploads/2020/12/sample-csv.png 2618w, https://www.highgo.ca/wp-content/uploads/2020/12/sample-csv-300x45.png 300w, https://www.highgo.ca/wp-content/uploads/2020/12/sample-csv-1024x153.png 1024w, https://www.highgo.ca/wp-content/uploads/2020/12/sample-csv-768x114.png 768w, https://www.highgo.ca/wp-content/uploads/2020/12/sample-csv-1536x229.png 1536w, https://www.highgo.ca/wp-content/uploads/2020/12/sample-csv-2048x305.png 2048w, https://www.highgo.ca/wp-content/uploads/2020/12/sample-csv-1920x286.png 1920w" sizes="(max-width: 2618px) 100vw, 2618px"></p>



<p>To keep things simple I created a sales_record table in PostgreSQL with one to one mapping with the CSV file</p>



<pre>CREATE TABLE sales_record 
(
	region VARCHAR,
	country VARCHAR,
	item_type VARCHAR,
	sales_channel VARCHAR,
	order_priority CHAR,
	order_date DATE,
	order_id INT,
	ship_date DATE,
	unit_sold INT,
	unit_price FLOAT,
	unit_cost FLOAT,
	total_revenue FLOAT,
	total_cost FLOAT,
	total_profit FLOAT
);</pre>



<p>Along with that I also wanted to see the impact of having an index on the bulk load performance, So for tests that&nbsp;require&nbsp;an INDEX, I created a <code>btree</code> index on the <code>country</code> column.</p>



<pre><code>CREATE INDEX country_idx ON sales_record USING btree (country);</code></pre>



<h2>Load using the <a href="https://www.postgresql.org/docs/current/sql-copy.html">COPY</a> command</h2>



<p><code>COPY</code>&nbsp;moves data between&nbsp;PostgreSQL&nbsp;tables and standard file-system files. The copy command comes in two variants, COPY TO and COPY FROM. The former copies the table content to the file, while we will use the latter to load data into the table from the file.</p>



<pre><code>COPY sales_record FROM '/Users/muhammadusama/work/data/5m_Sales_Records.csv' CSV HEADER;</code></pre>



<h2>Load using <a href="https://www.postgresql.org/docs/current/app-psql.html">psql</a> ‚Äò\copy‚Äô</h2>



<p>‚Äò<code>\copy</code>‚Äò is a <code>psql</code> operation that runs an&nbsp;SQL&nbsp;<a href="https://www.postgresql.org/docs/current/sql-copy.html">COPY</a>&nbsp;command, but instead of the server reading or writing the specified file,&nbsp;<code>psql</code>&nbsp;(client) reads or writes the file and routes the data between the server and the local file system. This means that file accessibility and privileges are those of the local user, not the server, and no SQL superuser privileges are required.</p>



<pre>\copy sales_record FROM '/Users/muhammadusama/work/data/5m_Sales_Records.csv' csv header;</pre>



<h2>Through <a href="https://www.postgresql.org/docs/current/file-fdw.html">file_fdw</a></h2>



<p>The foreign-data wrapper&nbsp;<code>file_fdw</code>, can be used to access data files in the server‚Äôs file system, or to execute programs on the server and read their output.&nbsp;We can also use the file_fdw to load data from CSV to PostgreSQL tables.</p>



<pre><code>-- Create file_fdw extension and foreign server
CREATE  EXTENSION file_fdw ;
CREATE SERVER file_fdw_server FOREIGN DATA WRAPPER file_fdw; 

-- Define the foreign table that points to our CSV file
CREATE FOREIGN TABLE foreign_sales_record (
	region VARCHAR,
	country VARCHAR,
	item_type VARCHAR,
	sales_channel VARCHAR,
	order_priority CHAR,
	order_date DATE,
	order_id INT,
	ship_date DATE,
	unit_sold INT,
	unit_price FLOAT,
	unit_cost FLOAT,
	total_revenue FLOAT,
	total_cost FLOAT,
	total_profit FLOAT) SERVER file_fdw_server
		OPTIONS (
			format 'csv',
			header 'false' ,
			filename '/Users/muhammadusama/work/data/5m_Sales_Records.csv',
			delimiter ',',
			null '');

-- Copy the data from foreign table to local table
INSERT INTO sales_record SELECT * from foreign_sales_record;
</code></pre>



<p>Although <code>file_fdw</code> is not expected to be as fast as COPY command when it comes to loading the data but it provides a lot of flexibility and options when it comes to pre-processing the data before loading.</p>



<h2><a href="https://github.com/ossc-db/pg_bulkload">pg_bulkload</a> tool</h2>



<p>pg_bulkload is also a very interesting option when it comes to high speed data loading. Its an open-source tool that achieves its performance by skipping the shared buffers and WAL logging.</p>



<pre><code>-- CREATE pg_bulkload extension
$ bin/psql -c "CREATE EXTENSION pg_bulkload" postgres

-- Create control file with appropriate contents
$ more sample_csv.ctl 
WRITER = PARALLEL
OUTPUT = public.sales_record  # [&lt;schema_name&gt;.]table_name
INPUT = /Users/muhammadusama/work/data/5m_Sales_Records.csv  # Input data location (absolute path)

TYPE = CSV           # Input file type
QUOTE = "\""         # Quoting character
ESCAPE = \           # Escape character for Quoting
DELIMITER = ","      # Delimiter

-- Execute pg_bulkload utility
$ bin/pg_bulkload -d postgres -h localhost sample_csv.ctl
</code></pre>



<h2>Results</h2>



<p>Below chart shows the time taken by each tool/command to load 5 million rows from CSV file </p>



<p><img loading="lazy" width="2162" height="756" src="https://www.highgo.ca/wp-content/uploads/2020/12/Screenshot-2020-12-07-at-12.39.13-AM.png" alt="" srcset="https://www.highgo.ca/wp-content/uploads/2020/12/Screenshot-2020-12-07-at-12.39.13-AM.png 2162w, https://www.highgo.ca/wp-content/uploads/2020/12/Screenshot-2020-12-07-at-12.39.13-AM-300x105.png 300w, https://www.highgo.ca/wp-content/uploads/2020/12/Screenshot-2020-12-07-at-12.39.13-AM-1024x358.png 1024w, https://www.highgo.ca/wp-content/uploads/2020/12/Screenshot-2020-12-07-at-12.39.13-AM-768x269.png 768w, https://www.highgo.ca/wp-content/uploads/2020/12/Screenshot-2020-12-07-at-12.39.13-AM-1536x537.png 1536w, https://www.highgo.ca/wp-content/uploads/2020/12/Screenshot-2020-12-07-at-12.39.13-AM-2048x716.png 2048w, https://www.highgo.ca/wp-content/uploads/2020/12/Screenshot-2020-12-07-at-12.39.13-AM-1920x671.png 1920w" sizes="(max-width: 2162px) 100vw, 2162px"></p>



<p><img loading="lazy" width="1784" height="1092" src="https://www.highgo.ca/wp-content/uploads/2020/12/Screenshot-2020-12-07-at-12.38.31-AM.png" alt="" srcset="https://www.highgo.ca/wp-content/uploads/2020/12/Screenshot-2020-12-07-at-12.38.31-AM.png 1784w, https://www.highgo.ca/wp-content/uploads/2020/12/Screenshot-2020-12-07-at-12.38.31-AM-300x184.png 300w, https://www.highgo.ca/wp-content/uploads/2020/12/Screenshot-2020-12-07-at-12.38.31-AM-1024x627.png 1024w, https://www.highgo.ca/wp-content/uploads/2020/12/Screenshot-2020-12-07-at-12.38.31-AM-768x470.png 768w, https://www.highgo.ca/wp-content/uploads/2020/12/Screenshot-2020-12-07-at-12.38.31-AM-1536x940.png 1536w, https://www.highgo.ca/wp-content/uploads/2020/12/Screenshot-2020-12-07-at-12.38.31-AM-1764x1080.png 1764w" sizes="(max-width: 1784px) 100vw, 1784px"></p>



<p><img loading="lazy" width="1904" height="1204" src="https://www.highgo.ca/wp-content/uploads/2020/12/Screenshot-2020-12-07-at-12.38.47-AM.png" alt="" srcset="https://www.highgo.ca/wp-content/uploads/2020/12/Screenshot-2020-12-07-at-12.38.47-AM.png 1904w, https://www.highgo.ca/wp-content/uploads/2020/12/Screenshot-2020-12-07-at-12.38.47-AM-300x190.png 300w, https://www.highgo.ca/wp-content/uploads/2020/12/Screenshot-2020-12-07-at-12.38.47-AM-1024x648.png 1024w, https://www.highgo.ca/wp-content/uploads/2020/12/Screenshot-2020-12-07-at-12.38.47-AM-768x486.png 768w, https://www.highgo.ca/wp-content/uploads/2020/12/Screenshot-2020-12-07-at-12.38.47-AM-1536x971.png 1536w, https://www.highgo.ca/wp-content/uploads/2020/12/Screenshot-2020-12-07-at-12.38.47-AM-1708x1080.png 1708w" sizes="(max-width: 1904px) 100vw, 1904px"></p>



<p><img loading="lazy" width="1794" height="928" src="https://www.highgo.ca/wp-content/uploads/2020/12/Screenshot-2020-12-07-at-12.36.01-AM.png" alt="" srcset="https://www.highgo.ca/wp-content/uploads/2020/12/Screenshot-2020-12-07-at-12.36.01-AM.png 1794w, https://www.highgo.ca/wp-content/uploads/2020/12/Screenshot-2020-12-07-at-12.36.01-AM-300x155.png 300w, https://www.highgo.ca/wp-content/uploads/2020/12/Screenshot-2020-12-07-at-12.36.01-AM-1024x530.png 1024w, https://www.highgo.ca/wp-content/uploads/2020/12/Screenshot-2020-12-07-at-12.36.01-AM-768x397.png 768w, https://www.highgo.ca/wp-content/uploads/2020/12/Screenshot-2020-12-07-at-12.36.01-AM-1536x795.png 1536w" sizes="(max-width: 1794px) 100vw, 1794px"></p>



<h2>Conclusion</h2>



<p>Each method for data loading has its own pros and cons which may make one preferred choice over others for a particular use case. But when it comes to raw performance pg_bulkload is a clear winner with COPY and /copy line up behind while file_fdw stands at the last place.</p>



<p>While no matter which data loading method we use, loading into an indexed table is always slow, So do consider <code>drop-index-&gt;load-&gt;create-index </code>when you have a huge data to be loaded.</p>



<blockquote><p>Comparison of all the tools was an apple to apple comparison with both client and server were running on the same machine. So, /copy had no network overhead. In the case of PostgreSQL server and client are on different<em> machines the /copy command may not perform as well as these above results.</em></p></blockquote>
<div itemtype="http://schema.org/Person" itemscope="" itemprop="author"><p><a href="https://www.highgo.ca/author/muhammad-u/"><img src="https://www.highgo.ca/wp-content/uploads/2019/08/usama.jpg" alt="" itemprop="image"></a></p><div><p>Muhammad Usama is a database architect / PostgreSQL consultant at HighGo Software and also Pgpool-II core committer. Usama has been involved with database development (PostgreSQL) since 2006, he is the core committer for open source middleware project Pgpool-II and has played a pivotal role in driving and enhancing the product. Prior to coming to open source development, Usama was doing software design and development with the main focus on system-level embedded development. After joining the EnterpriseDB, an Enterprise PostgreSQL‚Äôs company in 2006 he started his career in open source development specifically in PostgreSQL and Pgpool-II. He is a major contributor to the Pgpool-II project and has contributed to many performance and high availability related features.</p></div></div>                                                                    </div></div>]]>
            </description>
            <link>https://www.highgo.ca/2020/12/08/bulk-loading-into-postgresql-options-and-comparison/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25402430</guid>
            <pubDate>Sat, 12 Dec 2020 22:34:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I Hacked into Facebook's Legal Department Admin Panel]]>
            </title>
            <description>
<![CDATA[
Score 560 | Comments 236 (<a href="https://news.ycombinator.com/item?id=25401294">thread link</a>) | @hackerpain
<br/>
December 12, 2020 | https://alaa.blog/2020/12/how-i-hacked-facebook-part-one/ | <a href="https://web.archive.org/web/*/https://alaa.blog/2020/12/how-i-hacked-facebook-part-one/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
						<p>We‚Äôve been in this pandemic since&nbsp; March and once the pandemic started I was having plenty of free time, And I need to use that time wisely, So I‚Äôve decided to take the OSWE certification and I finished the exam on 8 of August, after that, I took a couple of weeks to recover from the OSWE exam, then in the med of September, I said you know what? I did not register my name in the Facebook hall of fame for 2020 as I do every year. okay, let‚Äôs do it.</p>

<p>I never found a vulnerability on one of Facebook subdomains, and I took a look at some writeups and I saw one writeup in one of Facebook subdomains which It got all my attention It was a great write up you can check it out <a href="https://ysamm.com/?p=280">[HTML to PDF converter bug leads to RCE in Facebook server.]</a></p>
<p>So after reading this writeup now I took a good idea about how many vulnerabilities I could find in such a huge web app.</p>

<p>So my main target was https://legal.tapprd.thefacebook.com and my goal was RCE or something similar.</p>

<p>I ran some fuzzing tools just to get the full endpoints of this web app and I took a 2 hours nap and watched a movie, Then I got back to see the results okay I got some good results.</p>

<p>Dirs found with a 403 response:</p>
<pre><code>
Dirs found with a 403 response:

/tapprd/
/tapprd/content/
/tapprd/services/
/tapprd/Content/
/tapprd/api/
/tapprd/Services/
/tapprd/temp/
/tapprd/logs/
/tapprd/logs/portal/
/tapprd/logs/api/
/tapprd/certificates/
/tapprd/logs/auth/
/tapprd/logs/Portal/
/tapprd/API/
/tapprd/webroot/
/tapprd/logs/API/
/tapprd/certificates/sso/
/tapprd/callback/
/tapprd/logs/callback/
/tapprd/Webroot/
/tapprd/certificates/dkim/
/tapprd/SERVICES/
</code></pre>
<p>Okay, I think this result is very enough to support my previous theory about how huge this application, Then I started to read the javascript files to see how the website works and what methods it uses ..etc</p>

<p>I noticed a way to bypass the redirection into the Login SSO, https://legal.tapprd.thefacebook.com/tapprd/portal/authentication/login and after analyzing the login page, I noticed this endpoint</p>
<p><strong> /tapprd/auth/identity/user/forgotpassword</strong></p>
<p>and after doing some fuzzing on the user endpoint I‚Äôve noticed another endpoint which its <strong>/savepassword&nbsp;&nbsp;</strong>and it was expecting a POST request, Then after reading the javascript files I knew how the page work, there should be a generated token and xsrf token.. etc The idea that first came to me okay, Lets test it and see if it will work I tried to change manually using burp suite but I got an error, the error <em>was execution this operation failed</em>.</p>

<p>I said okay, this might be because the email is wrong or something? let‚Äôs get an admin email, Then I started to put random emails in a list to make a wordlist and after that, I used the intruder and I said let‚Äôs see what will happen.</p>
<p>I got back after a couple of hours I found the same error results plus one other result, This one was 302 redirect to the login page, I said wow, I‚Äôll be damned if this worked Haha.</p>

<p>So let‚Äôs get back to see what I‚Äôve done here, I sent random requests using intruder with a CSRF token and random emails with a new password to this endpoint <em><strong>/savepassword</strong></em></p>
<p>and one of the results was 302 redirect.</p>
<div id="attachment_128"><p><img aria-describedby="caption-attachment-128" loading="lazy" src="https://alaa.blog/wp-content/uploads/2020/11/redirect-login.png" alt="fbredtrect" width="989" height="446" srcset="https://alaa.blog/wp-content/uploads/2020/11/redirect-login.png 1671w, https://alaa.blog/wp-content/uploads/2020/11/redirect-login-300x135.png 300w, https://alaa.blog/wp-content/uploads/2020/11/redirect-login-1024x461.png 1024w, https://alaa.blog/wp-content/uploads/2020/11/redirect-login-768x346.png 768w, https://alaa.blog/wp-content/uploads/2020/11/redirect-login-1536x692.png 1536w" sizes="(max-width: 989px) 100vw, 989px"></p><p id="caption-attachment-128">Redirect</p></div>
<p><strong>Now I went to the login page and I put the login email and the new password and BOOM I logged in Successfully into the application and I can enter the admin panel üôÇ</strong></p>

<p><img loading="lazy" src="https://alaa.blog/wp-content/uploads/2020/11/fblegal-admin.png" alt="" width="882" height="468" srcset="https://alaa.blog/wp-content/uploads/2020/11/fblegal-admin.png 1785w, https://alaa.blog/wp-content/uploads/2020/11/fblegal-admin-300x159.png 300w, https://alaa.blog/wp-content/uploads/2020/11/fblegal-admin-1024x543.png 1024w, https://alaa.blog/wp-content/uploads/2020/11/fblegal-admin-768x407.png 768w, https://alaa.blog/wp-content/uploads/2020/11/fblegal-admin-1536x815.png 1536w" sizes="(max-width: 882px) 100vw, 882px"></p>

<p>I read the hacker report who found RCE before using the PDF and they gave him a reward of 1000$ only so I said okay, let‚Äôs make a good Impact here and a perfect exploit.</p>
<p>I wrote a quick and simple script to exploit this vulnerability with python you put the email and the new password and the script will change the password.</p>
<p><img loading="lazy" src="https://alaa.blog/wp-content/uploads/2020/11/Exploit1.png" alt="" width="983" height="123" srcset="https://alaa.blog/wp-content/uploads/2020/11/Exploit1.png 983w, https://alaa.blog/wp-content/uploads/2020/11/Exploit1-300x38.png 300w, https://alaa.blog/wp-content/uploads/2020/11/Exploit1-768x96.png 768w" sizes="(max-width: 983px) 100vw, 983px"></p>
<p><strong>The Impact here was so high because the Facebook workers used to login with their workplace accounts, Which mean they‚Äôre using their Facebook accounts access token, and maybe if another attacker wanted to exploit this it might give him the ability to gain access to some Facebook workers accounts .. etc&nbsp;</strong></p>
<p>Then I reported the vulnerability and the report triaged.</p>

<p><strong>And on 2 of October, I received a bounty of 7500$&nbsp;</strong></p>
<p><img loading="lazy" src="https://alaa.blog/wp-content/uploads/2020/11/reward.png" alt="" width="654" height="171" srcset="https://alaa.blog/wp-content/uploads/2020/11/reward.png 696w, https://alaa.blog/wp-content/uploads/2020/11/reward-300x78.png 300w" sizes="(max-width: 654px) 100vw, 654px"></p>
<p>I enjoyed exploiting this vulnerability so much, so I said that‚Äôs not enough, this is a weak script! let‚Äôs dig more and more.</p>
<p>And I found two more vulnerabilities on the same application, But we will talk about the other vulnerabilities in the Part two writeup üôÇ</p>

<p>Cheers.</p>
<div id="sexy-author-bio"><p><a id="sab-Email" href="https://alaa.blog/cdn-cgi/l/email-protection#76171a1717051714041f051e36111b171f1a5815191b" target="_top"><img id="sig-Email" alt="Alaa Abdulridha on Email" src="https://alaa.blog/wp-content/plugins/sexy-author-bio/public/assets/images/flat-circle/sabemail.png"></a><a id="sab-Facebook" href="https://www.facebook.com/alaa.abdulridha.716" target="_top"><img id="sig-Facebook" alt="Alaa Abdulridha on Facebook" src="https://alaa.blog/wp-content/plugins/sexy-author-bio/public/assets/images/flat-circle/sabfacebook.png"></a><a id="sab-Github" href="https://github.com/Alaa-abdulridha" target="_top"><img id="sig-Github" alt="Alaa Abdulridha on Github" src="https://alaa.blog/wp-content/plugins/sexy-author-bio/public/assets/images/flat-circle/sabgithub.png"></a><a id="sab-Instagram" href="https://www.instagram.com/al_shwele" target="_top"><img id="sig-Instagram" alt="Alaa Abdulridha on Instagram" src="https://alaa.blog/wp-content/plugins/sexy-author-bio/public/assets/images/flat-circle/sabinstagram.png"></a><a id="sab-Twitter" href="https://twitter.com/alaa0x2" target="_top"><img id="sig-Twitter" alt="Alaa Abdulridha on Twitter" src="https://alaa.blog/wp-content/plugins/sexy-author-bio/public/assets/images/flat-circle/sabtwitter.png"></a></p><p><a href="https://alaa.blog/author/alaaabdulridha/" target="_top"><img src="https://alaa.blog/wp-content/uploads/2019/08/aaaaaaaaaa-150x150.jpg" width="100" height="100" alt="Alaa Abdulridha"></a></p><p>My name is Alaa Abdulridha I'm a computer engineering student and cybersecurity researcher I'm interested in web application pen-testing and game development, also I'm interested in some bug bounty programs, I like a lot of things such as reverse engineering, reading the others code to learn and then to find my own exploits and teaching it to you, Do you want to know more about me? <a href="https://alaa.blog/whoami/">Click Here</a>.</p></div>						
											</div></div>]]>
            </description>
            <link>https://alaa.blog/2020/12/how-i-hacked-facebook-part-one/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25401294</guid>
            <pubDate>Sat, 12 Dec 2020 20:17:12 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Yo WASM ‚Äì The Easy Way to WebAssembly]]>
            </title>
            <description>
<![CDATA[
Score 75 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25400837">thread link</a>) | @praveenperera
<br/>
December 12, 2020 | https://deislabs.io/posts/introducing-yo-wasm/ | <a href="https://web.archive.org/web/*/https://deislabs.io/posts/introducing-yo-wasm/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <p>WebAssembly (Wasm) is a portable standard for bytecode, allowing code to be compiled to an efficient representation that‚Äôs amenable to just-in-time optimisation, and to be run on the operating system and runtime environment of your choice.  An ever-increasing number of languages offer compilation to Wasm, and Wasm runtimes are available in major browsers and as separate programs.  The existence of runtimes outside the browser, such as <a href="https://wasmtime.dev/"><code>wasmtime</code></a> and <a href="https://wascc.dev/"><code>waSCC</code></a>, opens up the possibility of using WASM as a general-purpose bytecode format, similar to <a href="https://en.wikipedia.org/wiki/Java_bytecode">Java bytecode</a> or <a href="https://en.wikipedia.org/wiki/Common_Intermediate_Language">.NET CIL</a>.  For example, the <a href="https://deislabs.io/posts/introducing-krustlet/">Krustlet</a> project provides a way to run WebAssembly modules as Kubernetes pods, performing compute work or serving HTTP requests.</p>

<p>Although languages such as <a href="https://rustwasm.github.io/docs/book/">Rust</a> and <a href="https://developer.mozilla.org/en-US/docs/WebAssembly/C_to_wasm">C/C++</a> can compile to WASM, it‚Äôs not always obvious how to set up projects in this way - there is extra ceremony compared to most languages‚Äô ‚Äúnative‚Äù target.  Setting up debugging and deployment also involves extra steps too, and those aren‚Äôt always obvious.  So there‚Äôs a barrier to entry in the first place, and unwelcome configuration every time you create a new project.</p>

<p>To make this a bit easier, we‚Äôre building a Wasm project generator, using the popular <a href="https://yeoman.io/">Yeoman</a> code generator, to take care of this setup for you.  We‚Äôve just released the first preview and we‚Äôd love folks to try it out and let us know how it goes.</p>

<p>To install Yeoman and the Wasm generator, you‚Äôll need to have Node.js and NPM already installed; then run:</p>

<pre><code>npm install -g yo
npm install -g generator-wasm
</code></pre>

<p>Then generate your new project:</p>

<pre><code>mkdir myproject
cd myproject
yo wasm
</code></pre>

<p>The generator will ask you a few questions, of which two are interesting:</p>

<ol>
<li><p>Which language do you want the project generated in?  At the moment, we can do Rust, C and AssemblyScript.  We‚Äôd be delighted to have more.</p></li>

<li><p>Do you want to publish the compiled Wasm module to an OCI registry, and if so which one?  This is relevant for workloads that you envisage running in a cloud environment such as Kubernetes with Krustlet.  You don‚Äôt have to publish to an OCI registry; if you do, we currently only offer Azure Container Registry, but again would love to extend that to other OCI registries.</p></li>
</ol>

<p><img src="https://i.imgur.com/QYAQcHH.png" alt="Project setup in yo wasm"></p>

<p>The result of all this is a ‚Äúhello, world‚Äù application.  The code itself is uninteresting, being just a minimal Rust, C or AssemblyScript program, but the generator also provides a bunch of things to make the development experience easier:</p>

<ol>
<li><p>Visual Studio Code tasks to build and debug the Wasm build.  This means that - if you‚Äôre a VS Code user - you can get up and running editing and debugging the project very quickly.  The Debug Wasm debug configuration uses <code>wasmtime</code> to run the program, and the LLDB debugger to support breakpoints, etc. in the running Wasm.</p>

<p><img src="https://i.imgur.com/ypz6o0P.png" alt="The Debug WASM configuration in VS Code"></p></li>

<li><p>GitHub actions to build pull requests, and to publish the compiled Wasm module to your chosen OCI registry when you merge to <code>main</code> or tag a release with a string of the form <code>v*</code> (e.g. <code>v1.0.0</code>).  (If you chose not to publish to an OCI registry, this action just creates a build artifact.)</p>

<p><img src="https://i.imgur.com/ARpY3jl.png" alt="Build and publish workflows running out of the box"></p></li>
</ol>

<p>The preview release has some limitations.  We‚Äôve mentioned the limited language and registry options.  One important restriction is that all our current templates target WASI (WebAssembly System Interface) and the <code>wasmtime</code> runtime.  We‚Äôd love to have templates for other environments and runtimes, but we could really do with feedback on that before we invest in it.</p>

<p>We hope you‚Äôll give <code>yo wasm</code> a try.  Please let us know if you run into any problems by raising an issue at <a href="https://github.com/deislabs/generator-wasm/issues">https://github.com/deislabs/generator-wasm/issues</a>, or feel free to send a pull request if there‚Äôs something you‚Äôd like to add or improve.  Thanks!</p>

      
      
    </div></div>]]>
            </description>
            <link>https://deislabs.io/posts/introducing-yo-wasm/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25400837</guid>
            <pubDate>Sat, 12 Dec 2020 19:32:50 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I built a picture frame with a greyscale e-paper that runs on battery for years]]>
            </title>
            <description>
<![CDATA[
Score 153 | Comments 73 (<a href="https://news.ycombinator.com/item?id=25400702">thread link</a>) | @clash
<br/>
December 12, 2020 | https://framelabs.eu/en/ | <a href="https://web.archive.org/web/*/https://framelabs.eu/en/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://framelabs.eu/en/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25400702</guid>
            <pubDate>Sat, 12 Dec 2020 19:19:45 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Thread-Per-Core Buffer Management for a modern storage system]]>
            </title>
            <description>
<![CDATA[
Score 107 | Comments 32 (<a href="https://news.ycombinator.com/item?id=25400350">thread link</a>) | @arjunnarayan
<br/>
December 12, 2020 | https://vectorized.io/blog/tpc-buffers/ | <a href="https://web.archive.org/web/*/https://vectorized.io/blog/tpc-buffers/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><section><p><a href="https://vectorized.io/blog/redpanda-raison-detre">As I have previously observed</a>, software does not run on category theory, it runs on superscalar CPUs with wide, multi-channel GB/s memory units and NVMe SSD access times in the order of 10-100‚Äôs of microseconds. The reason some software written a decade ago - on a different hardware platform - feels slow is because it fails to exploit the advances in modern hardware.</p>
<p>The new bottleneck in storage systems is the CPU. SSD devices are 100-1000x faster than spinning disks and are 10x cheaper today[1] than they were a decade ago, from $2,500 down to $200 per Terabyte. Networks have 100x higher throughput in public clouds from 1Gbps to 100Gbps.</p>
<p>Although computers did, in fact, get faster, single-core speeds remain roughly the same. The reason being that CPU frequency has a cubic dependency on power consumption, and we‚Äôve hit a wall. Instruction level parallelism, prefetching, speculative execution, branch prediction, deep hierarchy of data caches and instruction caches, etc, have contributed to programs <em>feeling</em> faster when you interact with them, but in the datacenter, the material improvements have come from the rise in core count. While the instructions per clock are 3x higher than a decade ago, core count is up 20x.</p>
<p>This is all to say that the rise of readily available, many-core systems necessitates a different approach for building infrastructure. Case in point[9]: in order to take full advantage of 96 vCPUs on a i3en.metal on AWS, you‚Äôll need to find a way to exploit sustained CPU clock speed of 3.1 GHz, 60 TB of total NVMe instance storage, 768 GiB of memory and NVMe devices capable of delivering up to 2 million random IOPS at 4 KB block sizes. This kind of beast necessitates a new kind of storage engine and threading model that leverages these hardware advances.</p>
<p><a href="https://vectorized.io/redpanda" target="_self" rel="nofollow">Redpanda</a> - a Kafka-API compatible system for mission critical workloads[3] - addresses all of these issues. It uses a thread-per-core architecture with Structured Message Passing (SMP) to communicate between these pinned threads. Threading is a foundational decision for any application, whether you are using a thread-pool, pinned threads with a network of Single Producer Single Consumer SPSC[7] queues, or any other of the advanced Safe Memory Reclamation (SMR) techniques, threading is your ring-0, the true kernel of your application. It tells you what your sensitivity is for blocking - which for Redpanda is less than 500 microseconds - otherwise, Seastar‚Äôs[4] reactor will print a stack trace warning you of the blocking since it effectively injects latency on the network poller.</p>
<p>Once you have decided on your threading model, the next step is your memory model and ultimately, for storage engines, your buffer management. In this post, we‚Äôll cover the perils of buffer management in a thread-per-core environment and describe <code>iobuf</code>, our solution for a 0-copy memory management in the world of Seastar.</p>
<h2 id="Request-Flow-Architecture">Request Flow Architecture<a href="#Request-Flow-Architecture" aria-label="Request Flow Architecture permalink"></a></h2>
<p>As mentioned earlier, Redpanda uses a <em>single</em> pinned thread per core architecture to do everything. Network polling, submitting async IO to the kernel, reaping events, triggering timers, scheduling compute tasks, etc. Structurally, it means nothing can block for longer than 500 microseconds, or you‚Äôll be introducing latency in other parts of your stack. This is an incredibly strict programming paradigm, but this opinionated idea forces a truly asynchronous system, whether you like it or not as the programmer.</p>
<p><img src="https://vectorized.io/31d1a730c507b605e6c1ebea60eb1e56/flow.svg" alt="Kafka request flow">
<small>
Figure 1: request flow architecture. Core-0 accepts the connection from the Kafka Java client and becomes the source core. After the request goes through the metadata cache(valid request) it filters through the partition router which decides to send the request to core-1, the destination core. Core-1 then accepts the write through the Raft-log interface and saves it to disk.
</small></p>
<p>The challenge in a TpC (thread-per-core) architecture[8] is that all communication between cores is explicit. This muscles the programmer into implementing algorithms that favor core-locality (d-cache, i-cache) over the straightforward multi-threaded implementations via mutexes. This imperative has to be co-designed with the asynchronicity of a <strong>future&lt;&gt;</strong>-based implementation.</p>
<p>For our Kafka-API implementation as shown in Figure 1, we explicitly trade memory usage to reduce latency and increase throughput by materializing key components. The metadata Cache is materialized on every core since every request has to know if the partition exists, and that that particular machine is, in fact, the leader of the partition. The Partition Router maintains a map of which logical core actually owns the underlying Kafka partition on the machine. Other things like Access Control Lists (ACLs) are deferred until the request reaches the destination core since they can get unwieldy in memory footprint.  We have no hard and fast rule of what we materialize on every core vs. what is deferred for the destination core, and it‚Äôs often a function of memory (smaller data structures are good candidates for broadcast), computation (how much time is spent deciding) and frequency of access (very likely operations tend to get materialized on every core).</p>
<p>One question remaining is how, exactly, does memory management work in a TpC architecture? How does data actually travel from L-core-0 to L-core-66 safely using a network of SPSC queues within a fully asynchronous execution model where things can suspend at any point in time?</p>
<h2 id="struct-iobuf--">struct iobuf { };<a href="#struct-iobuf--" aria-label="struct iobuf   permalink"></a></h2>
<h3 id="Redpandas-0-copy-buffer-management-for-TpC">Redpanda‚Äôs 0-copy buffer management for TpC<a href="#Redpandas-0-copy-buffer-management-for-TpC" aria-label="Redpandas 0 copy buffer management for TpC permalink"></a></h3>
<p>To understand <strong>iobuf</strong>, we need to understand the actual memory constraints of Seastar, our TpC framework. During program bootstrap, Seastar allocates the full memory of the computer and splits it evenly across all the cores. It consults the hardware to understand what memory belongs to each particular core, reducing inter-core traffic to main memory.</p>
<p><img src="https://vectorized.io/efa273909c5b695bf7f978f77b32c12b/seastar_model.svg" alt="Seastar mental model">
<small>
Figure 2: Copy from alexgallego.org (<a href="https://www.alexgallego.org/concurrency/smf/2017/12/16/future.html" target="_self" rel="nofollow">https://www.alexgallego.org/concurrency/smf/2017/12/16/future.html</a>) Seastar threading model. Seastar uses a network of SPS queues to send messages to neighboring cores. Similar to other message passing or actor models like Erlang, Orleans and Pony, once a function is futurized, transitive functions too will become futurized. Both approaches, however, are intrinsically safe. The programmer worries about correctness and construction while the frameworks worry about efficient execution. Counter to general wisdom, it is actually faster and more scalable than the synchronous approach. While the machine does more work, it is executing your code simultaneously. This simultaneity is the key to finishing work sooner.
</small></p>
<p>As Figure 2 suggests, memory allocated on core-0, <em>must</em> be deallocated on core-0. However, there is no way to guarantee that a Java or Go client connecting to Redpanda will actually communicate with the exact core that owns the data.</p>
<p>At its core, an iobuf is a ref-counted, fragmented-buffer-chain with deferred deletes that allows Redpanda to simply share a view of a remote core‚Äôs parsed messages as the fragments come in, without incurring a copy overhead.</p>
<p><img src="https://vectorized.io/6df6fc00e05201d068dc5d03e080606a/iobuf.svg" alt="iobuf architecture"></p>
<p>The fragmented buffers abstraction is not new. The linux kernel has <strong>sk_buff</strong>[5] and the freebsd kernel has an <strong>mbuf</strong>[6] which are roughly similar. The additional extension of an iobuf is that it works in the TCP model leveraging Seastar‚Äôs network of SPSC queues to have proper deletes in addition to being able to share sub-views arbitrarily, tailored for a storage-like workload.</p>
<p>Removing the C++ templates, allocators, pooling, pointer caching, etc, one could think of an iobuf as being equivalent to:</p>
<div data-language="cpp"><pre><code><span>struct</span> <span>fragment</span> <span>{</span>
    <span>void</span> <span>*</span> data<span>;</span>
    size_t ref_count<span>;</span>
    size_t capacity<span>;</span>
    size_t size<span>;</span>

    fragment<span>*</span> next<span>;</span>  
    fragment<span>*</span> prev<span>;</span>
<span>}</span>
<span>struct</span> <span>iobuf</span> <span>{</span>
    fragment<span>*</span> head<span>;</span>
<span>}</span><span>;</span></code></pre></div>
<p>The origins of iobuf are rooted in one of our central product tenets for building a Kafka¬Æ replacement for mission critical systems - giving users 10x lower tail latencies for most workloads. Aside from a thread-per-core architecture, the memory management would have been our second bottleneck if not designed from the ground up for latency. On long running storage systems, memory fragmentation is a real problem, and one that is eventually either met with a proper solution (iobuf), stalls or an OOM.</p>
<p>Like its predecessors skbuff and mbuff, iobuf allows us to optimize and train our memory allocator with predictable memory sizes. Here is our iobuf allocation table logic:</p>
<div data-language="cpp"><pre><code><span>struct</span> <span>io_allocation_size</span> <span>{</span>
   <span>static</span> <span>constexpr</span> size_t max_chunk_size <span>=</span> <span>128</span> <span>*</span> <span>1024</span><span>;</span>
   <span>static</span> <span>constexpr</span> size_t default_chunk_size <span>=</span> <span>512</span><span>;</span>

   
   
   
   
   
   
   <span>static</span> <span>constexpr</span> std<span>::</span>array<span>&lt;</span><span>uint32_t</span><span>,</span> <span>15</span><span>&gt;</span> alloc_table <span>=</span>
     
     <span>{</span><span>{</span><span>512</span><span>,</span>
       <span>768</span><span>,</span>
       <span>1152</span><span>,</span>
       <span>1728</span><span>,</span>
       <span>2592</span><span>,</span>
       <span>3888</span><span>,</span>
       <span>5832</span><span>,</span>
       <span>8748</span><span>,</span>
       <span>13122</span><span>,</span>
       <span>19683</span><span>,</span>
       <span>29525</span><span>,</span>
       <span>44288</span><span>,</span>
       <span>66432</span><span>,</span>
       <span>99648</span><span>,</span>
       <span>131072</span><span>}</span><span>}</span><span>;</span>

   <span>static</span> size_t <span>next_allocation_size</span><span>(</span>size_t data_size<span>)</span><span>;</span>
<span>}</span><span>;</span>   </code></pre></div>
<p>Predictability, memory pooling, fixed sizes, size capping, fragmented traversal, etc, are all known techniques to reduce latency. Asking for contiguous and variably sized memory could cause the allocator to compact all of the arenas and reshuffle a lot of bytes for what could be a short-lived request, not only injecting latency on the request path, but for the entire system since we have exactly one thread performing all operations.</p>
<p>Hardware is the platform. When we ask the network layer to give us exactly 11225 bytes in contiguous memory, we are simply asking the allocator to linearize an empty buffer of that exact size and for the network layer to copy bytes as the fragments come from the hardware into the destination buffer. There is ultimately no free lunch when it comes to trying to squeeze every single ounce of performance of your hardware and often it requires re-architecting from zero.</p>
<p>If you made it this far, I encourage you to sign up for our <a href="https://vectorized.io/slack" target="_self" rel="nofollow">Community Slack (here!)</a> and ask us questions directly or engage with us on twitter via <a href="https://twitter.com/vectorizedio" target="_self" rel="nofollow">@vectorize‚Ä¶</a></p></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://vectorized.io/blog/tpc-buffers/">https://vectorized.io/blog/tpc-buffers/</a></em></p>]]>
            </description>
            <link>https://vectorized.io/blog/tpc-buffers/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25400350</guid>
            <pubDate>Sat, 12 Dec 2020 18:34:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Red Hat Goes Full IBM and Says Farewell to CentOS]]>
            </title>
            <description>
<![CDATA[
Score 212 | Comments 292 (<a href="https://news.ycombinator.com/item?id=25400249">thread link</a>) | @vanburen
<br/>
December 12, 2020 | https://www.servethehome.com/red-hat-goes-full-ibm-and-says-farewell-to-centos/ | <a href="https://web.archive.org/web/*/https://www.servethehome.com/red-hat-goes-full-ibm-and-says-farewell-to-centos/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <!-- image --><div><figure><a href="https://www.servethehome.com/wp-content/uploads/2020/12/Red-Hat-Summary-scaled.jpg" data-caption="Red Hat Distro Family Progression 2020-2025"><img width="696" height="391" src="https://www.servethehome.com/wp-content/uploads/2020/12/Red-Hat-Summary-696x391.jpg" srcset="https://www.servethehome.com/wp-content/uploads/2020/12/Red-Hat-Summary-696x391.jpg 696w, https://www.servethehome.com/wp-content/uploads/2020/12/Red-Hat-Summary-400x224.jpg 400w, https://www.servethehome.com/wp-content/uploads/2020/12/Red-Hat-Summary-800x449.jpg 800w, https://www.servethehome.com/wp-content/uploads/2020/12/Red-Hat-Summary-1536x862.jpg 1536w, https://www.servethehome.com/wp-content/uploads/2020/12/Red-Hat-Summary-2048x1149.jpg 2048w, https://www.servethehome.com/wp-content/uploads/2020/12/Red-Hat-Summary-1068x599.jpg 1068w, https://www.servethehome.com/wp-content/uploads/2020/12/Red-Hat-Summary-749x420.jpg 749w" sizes="(max-width: 696px) 100vw, 696px" alt="Red Hat Distro Family Progression 2020-2025" title="Red Hat Distro Family Progression 2020-2025"></a><figcaption>Red Hat Distro Family Progression 2020-2025</figcaption></figure></div>
            <!-- content --><p>This week, Red Hat caught a lot of the Linux community off-guard by what was a shocking announcement for many: CentOS 8 as we know it, will see a reduced lifecycle, ending in December 2021. Further, while the project will still support CentOS 7, CentOS, as the community has known it, is effectively a dead project at this point. This is fairly consistent with how <a href="https://www.servethehome.com/ibm-gobbles-up-red-hat/">IBM</a> is known to do some acquisitions, but it is still shocking.<span id="more-49249"></span></p>
<h2>The Video Version</h2>
<p>Since we have been doing more content with video lately, we are also including a version of this as a video for you to listen to.</p>
<p><iframe title="Red Hat Says Sayonara to CentOS" width="696" height="392" src="https://www.youtube.com/embed/qqc3k5Ym1tA?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe></p>
<p>Of course, we know most of the folks on here prefer to read, but this video is a fairly close representation of what is in the article. Feel free to open it on YouTube and check it out there.</p>
<h2>CentOS Project Key History</h2>
<p>While some will like to go back to the founding of CentOS, we instead wanted to focus on what CentOS had effectively become over the last 5-10 years: a Red Hat Enterprise Linux (RHEL) alternative without the support contract.</p>
<figure id="attachment_49262" aria-describedby="caption-attachment-49262"><a href="https://www.servethehome.com/red-hat-goes-full-ibm-and-says-farewell-to-centos/red-hat-2020/" rel="attachment wp-att-49262"><img loading="lazy" src="https://www.servethehome.com/wp-content/uploads/2020/12/Red-Hat-2020-scaled.jpg" alt="Red Hat 2020" width="2560" height="1439" srcset="https://www.servethehome.com/wp-content/uploads/2020/12/Red-Hat-2020-scaled.jpg 2560w, https://www.servethehome.com/wp-content/uploads/2020/12/Red-Hat-2020-400x225.jpg 400w, https://www.servethehome.com/wp-content/uploads/2020/12/Red-Hat-2020-800x450.jpg 800w, https://www.servethehome.com/wp-content/uploads/2020/12/Red-Hat-2020-1536x864.jpg 1536w, https://www.servethehome.com/wp-content/uploads/2020/12/Red-Hat-2020-2048x1151.jpg 2048w, https://www.servethehome.com/wp-content/uploads/2020/12/Red-Hat-2020-696x391.jpg 696w, https://www.servethehome.com/wp-content/uploads/2020/12/Red-Hat-2020-1068x600.jpg 1068w, https://www.servethehome.com/wp-content/uploads/2020/12/Red-Hat-2020-747x420.jpg 747w" sizes="(max-width: 2560px) 100vw, 2560px"></a><figcaption id="caption-attachment-49262">Red Hat Distro Family Progression 2020</figcaption></figure>
<p>Even if you run on Debian derivatives, you are aware of how mature the RHEL ecosystem is. It is a testament to Red Hat being the top open-source company in the world. CentOS releases generally lagged the RHEL releases by a few months, but effectively were clones of RHEL for those that did not have the budget for RHEL. Some can say CentOS was something different, but if we are being fair, a huge portion of the usage was effectively to access key parts of the RHEL ecosystem while not paying a subscription fee.</p>
<p>In 2014, Red Hat saw the potential and the benefits to its ecosystem and brought the CentOS team in-house. There is a team inside Red Hat developing CentOS with salaries and badges. The rationale from what I have been told is that it was better to have applications built on CentOS then brought up to RHEL as they matured rather than putting more development effort into the Ubuntu/ Debian ecosystem. That is both simplistic, but also makes a lot of sense. As part of this arrangement, Red Hat effectively got control of the CentOS governing body. That makes a lot of sense since Red Hat would be paying for developers, but it also made a few folks think about what could happen with CentOS not being independent.</p>
<figure id="attachment_49263" aria-describedby="caption-attachment-49263"><a href="https://www.servethehome.com/red-hat-goes-full-ibm-and-says-farewell-to-centos/red-hat-acquisition-passage/" rel="attachment wp-att-49263"><img loading="lazy" src="https://www.servethehome.com/wp-content/uploads/2020/12/Red-Hat-Acquisition-Passage.jpg" alt="Red Hat Acquisition Passage" width="1714" height="1602" srcset="https://www.servethehome.com/wp-content/uploads/2020/12/Red-Hat-Acquisition-Passage.jpg 1714w, https://www.servethehome.com/wp-content/uploads/2020/12/Red-Hat-Acquisition-Passage-321x300.jpg 321w, https://www.servethehome.com/wp-content/uploads/2020/12/Red-Hat-Acquisition-Passage-800x748.jpg 800w, https://www.servethehome.com/wp-content/uploads/2020/12/Red-Hat-Acquisition-Passage-1536x1436.jpg 1536w, https://www.servethehome.com/wp-content/uploads/2020/12/Red-Hat-Acquisition-Passage-696x651.jpg 696w, https://www.servethehome.com/wp-content/uploads/2020/12/Red-Hat-Acquisition-Passage-1068x998.jpg 1068w, https://www.servethehome.com/wp-content/uploads/2020/12/Red-Hat-Acquisition-Passage-449x420.jpg 449w" sizes="(max-width: 1714px) 100vw, 1714px"></a><figcaption id="caption-attachment-49263">Red Hat Absorbs CentOS Press Release</figcaption></figure>
<p>Taking a step back to 2014, anyone building applications saw Red Hat‚Äôs signal that it was committing resources to CentOS and frankly felt fairly good about platforming on CentOS. We almost switched back our hosting infrastructure to CentOS because of that, but there was a not-insignificant risk that we would get forced into a subscription at some point.</p>
<p>Between that acquisition, and 2020, we had a period where loosely CentOS would follow RHEL releases, supported by official Red Hat resources, by a few months. It took some time to extract bits of IP in RHEL and other changes, but for years, this was the operating model.</p>
<figure id="attachment_49269" aria-describedby="caption-attachment-49269"><a href="https://www.servethehome.com/red-hat-goes-full-ibm-and-says-farewell-to-centos/red-hat-centos-eol-summary/" rel="attachment wp-att-49269"><img loading="lazy" src="https://www.servethehome.com/wp-content/uploads/2020/12/Red-Hat-CentOS-EOL-Summary.jpg" alt="Red Hat CentOS EOL Summary" width="1118" height="188" srcset="https://www.servethehome.com/wp-content/uploads/2020/12/Red-Hat-CentOS-EOL-Summary.jpg 1118w, https://www.servethehome.com/wp-content/uploads/2020/12/Red-Hat-CentOS-EOL-Summary-400x67.jpg 400w, https://www.servethehome.com/wp-content/uploads/2020/12/Red-Hat-CentOS-EOL-Summary-800x135.jpg 800w, https://www.servethehome.com/wp-content/uploads/2020/12/Red-Hat-CentOS-EOL-Summary-696x117.jpg 696w, https://www.servethehome.com/wp-content/uploads/2020/12/Red-Hat-CentOS-EOL-Summary-1068x180.jpg 1068w" sizes="(max-width: 1118px) 100vw, 1118px"></a><figcaption id="caption-attachment-49269">Red Hat CentOS EOL Summary</figcaption></figure>
<p>Another key factoid is that the end of support for CentOS 6 was in November 2020. Since RHEL and CentOS are known for long support cycles, a lot of organizations decided to jump from CentOS 6 to 8 instead of re-platforming on 7 since that maximizes the time until another re-platforming effort would need to be scheduled. Or that is what many in the industry thought.</p>
<figure id="attachment_49267" aria-describedby="caption-attachment-49267"><a href="https://www.servethehome.com/red-hat-goes-full-ibm-and-says-farewell-to-centos/red-hat-2022/" rel="attachment wp-att-49267"><img loading="lazy" src="https://www.servethehome.com/wp-content/uploads/2020/12/Red-Hat-2022-scaled.jpg" alt="Red Hat 2022" width="2560" height="1444" srcset="https://www.servethehome.com/wp-content/uploads/2020/12/Red-Hat-2022-scaled.jpg 2560w, https://www.servethehome.com/wp-content/uploads/2020/12/Red-Hat-2022-400x226.jpg 400w, https://www.servethehome.com/wp-content/uploads/2020/12/Red-Hat-2022-800x451.jpg 800w, https://www.servethehome.com/wp-content/uploads/2020/12/Red-Hat-2022-1536x866.jpg 1536w, https://www.servethehome.com/wp-content/uploads/2020/12/Red-Hat-2022-2048x1155.jpg 2048w, https://www.servethehome.com/wp-content/uploads/2020/12/Red-Hat-2022-696x392.jpg 696w, https://www.servethehome.com/wp-content/uploads/2020/12/Red-Hat-2022-1068x602.jpg 1068w, https://www.servethehome.com/wp-content/uploads/2020/12/Red-Hat-2022-745x420.jpg 745w" sizes="(max-width: 2560px) 100vw, 2560px"></a><figcaption id="caption-attachment-49267">Red Hat Distro Family Progression 2022</figcaption></figure>
<p>Then, on December 8, 2020, Red Hat announced that it was going to cut the current CentOS 8 support timeframe down considerably in the process of effectively killing the project. While 2021 may not be impacted, with CentOS 6 EOL on November 30, 2020, and CentOS 8 EOL on December 31, 2021, by January 1, 2022 CentOS 7 will be the only one receiving Maintenance Updates. The CentOS name will live on but in a different part of the ecosystem than it has to date.</p>
<h2>CentOS Stream and the New Red Hat Operating Model</h2>
<p>CentOS Stream is a project that sits between the upstream Fedora Linux and RHEL. While CentOS 8 is being shut down, and we do not expect a CentOS 9 unless there is a major change in direction at Red Hat, the CentOS name will live on for now in the CentOS Stream after CentOS 7 eventually goes EOL on June 30, 2024. By the second half of 2024, and by 2025 we expect this is what the diagram will look like.</p>
<figure id="attachment_49268" aria-describedby="caption-attachment-49268"><a href="https://www.servethehome.com/red-hat-goes-full-ibm-and-says-farewell-to-centos/red-hat-2025/" rel="attachment wp-att-49268"><img loading="lazy" src="https://www.servethehome.com/wp-content/uploads/2020/12/Red-Hat-2025-scaled.jpg" alt="Red Hat 2025" width="2560" height="1449" srcset="https://www.servethehome.com/wp-content/uploads/2020/12/Red-Hat-2025-scaled.jpg 2560w, https://www.servethehome.com/wp-content/uploads/2020/12/Red-Hat-2025-400x226.jpg 400w, https://www.servethehome.com/wp-content/uploads/2020/12/Red-Hat-2025-800x453.jpg 800w, https://www.servethehome.com/wp-content/uploads/2020/12/Red-Hat-2025-1536x870.jpg 1536w, https://www.servethehome.com/wp-content/uploads/2020/12/Red-Hat-2025-2048x1159.jpg 2048w, https://www.servethehome.com/wp-content/uploads/2020/12/Red-Hat-2025-696x394.jpg 696w, https://www.servethehome.com/wp-content/uploads/2020/12/Red-Hat-2025-1068x605.jpg 1068w, https://www.servethehome.com/wp-content/uploads/2020/12/Red-Hat-2025-742x420.jpg 742w" sizes="(max-width: 2560px) 100vw, 2560px"></a><figcaption id="caption-attachment-49268">Red Hat Distro Family Progression 2025</figcaption></figure>
<p>For those who are current CentOS users, this means that what will be known as CentOS is being moved upstream of RHEL instead of downstream. Many of the current CentOS users like the fact that it is broadly tied to the RHEL ecosystem, and by moving it upstream it becomes a different value proposition.</p>
<figure id="attachment_49272" aria-describedby="caption-attachment-49272"><a href="https://www.servethehome.com/red-hat-goes-full-ibm-and-says-farewell-to-centos/red-hat-summary/" rel="attachment wp-att-49272"><img loading="lazy" src="https://www.servethehome.com/wp-content/uploads/2020/12/Red-Hat-Summary-scaled.jpg" alt="Red Hat Summary" width="2560" height="1436" srcset="https://www.servethehome.com/wp-content/uploads/2020/12/Red-Hat-Summary-scaled.jpg 2560w, https://www.servethehome.com/wp-content/uploads/2020/12/Red-Hat-Summary-400x224.jpg 400w, https://www.servethehome.com/wp-content/uploads/2020/12/Red-Hat-Summary-800x449.jpg 800w, https://www.servethehome.com/wp-content/uploads/2020/12/Red-Hat-Summary-1536x862.jpg 1536w, https://www.servethehome.com/wp-content/uploads/2020/12/Red-Hat-Summary-2048x1149.jpg 2048w, https://www.servethehome.com/wp-content/uploads/2020/12/Red-Hat-Summary-696x391.jpg 696w, https://www.servethehome.com/wp-content/uploads/2020/12/Red-Hat-Summary-1068x599.jpg 1068w, https://www.servethehome.com/wp-content/uploads/2020/12/Red-Hat-Summary-749x420.jpg 749w" sizes="(max-width: 2560px) 100vw, 2560px"></a><figcaption id="caption-attachment-49272">Red Hat Distro Family Progression 2020-2025</figcaption></figure>
<p>As much as I have an affinity for the CentOS brand, I do not like ‚ÄúCentOS Stream‚Äù being used, especially without CentOS being discontinued as a downstream distribution from RHEL. It made some sense for both to be active, but CentOS Stream may as well be called ‚ÄúBigBlue Hat Enterprise Linux Stream‚Äù or something like that. Fedora is not RHEL Stream for a reason. In the future Fedora, CentOS Stream, then RHEL will make sense from a branding perspective, except that CentOS is so widely used that it has a history, a history that will be chronicled for decades in Q&amp;A sites, how-tos, and other user support artifacts from the CentOS (non-stream) era.</p>
<h2>What Red Hat Needs to Do, ASAP</h2>
<p>As part of the announcement, RHEL has hinted that it would be doing something with its RHEL licensing to help the CentOS community, and there is a step it could take to turn this into an amazing gambit for Red Hat: opening a non-subscription level to RHEL beyond the current developer license.</p>
<p>‚ÄúThere are different kinds of CentOS users, and we are working with the CentOS Project Governing Board to tailor programs that meet the needs of these different user groups. In the first half of 2021, we plan to introduce low- or no-cost programs for a variety of use cases, including options for open source projects and communities and expansion of the Red Hat Enterprise Linux Developer subscription use cases to better serve the needs of systems administrators. We‚Äôll share more details as these initiatives coalesce.‚Äú (<strong>Source</strong>: <a href="https://www.redhat.com/en/blog/centos-stream-building-innovative-future-enterprise-linux">Red Hat</a>)</p>
<p>This is the sort of move that could yield huge dividends for Red Hat. If the migration path was from CentOS 8 to a carefully crafted ‚ÄúRHEL-freemium‚Äù distribution, which is how many viewed CentOS at a high-level anyway, then it has the ability to greatly increase Red Hat‚Äôs installed base in its main RHEL distribution. There are huge ramifications for this from an IP, licensing, and even just a business perspective, but it would be an amazing move. At the same time, it is a move that if Red Hat wanted to do, it should have been announced along with the CentOS retirement to quell the confusion. Effectively, Red Hat would be doing what iXsystems did to migrate FreeNAS to TrueNAS Core just on a much grander scale.</p>
<p>Red Hat desperately needs to have a good path forward. Perhaps none are perfect, but asking CentOS users to upgrade to CentOS Stream, pay for a RHEL license, or leave the ecosystem seems like a highly imperfect set of options.</p>
<h2>Final Words</h2>
<p>The intellectually easy answer to what is happening is that IBM is putting pressure on Red Hat to hit bigger numbers in the future. Red Hat sees a captive audience in its CentOS userbase and is looking to covert a percentage to paying customers. Everyone else can go to Ubuntu or elsewhere if they do not want to pay. That seems a bit shortsighted of an explanation we have heard offered.</p>
<figure id="attachment_30704" aria-describedby="caption-attachment-30704"><a href="https://www.servethehome.com/ibm-gobbles-up-red-hat/ibm-and-red-hat-merger/" rel="attachment wp-att-30704"><img loading="lazy" src="https://www.servethehome.com/wp-content/uploads/2018/10/IBM-and-Red-Hat-Merger.jpg" alt="IBM And Red Hat Merger" width="1039" height="572" srcset="https://www.servethehome.com/wp-content/uploads/2018/10/IBM-and-Red-Hat-Merger.jpg 1039w, https://www.servethehome.com/wp-content/uploads/2018/10/IBM-and-Red-Hat-Merger-400x220.jpg 400w, https://www.servethehome.com/wp-content/uploads/2018/10/IBM-and-Red-Hat-Merger-800x440.jpg 800w, https://www.servethehome.com/wp-content/uploads/2018/10/IBM-and-Red-Hat-Merger-696x383.jpg 696w, https://www.servethehome.com/wp-content/uploads/2018/10/IBM-and-Red-Hat-Merger-763x420.jpg 763w" sizes="(max-width: 1039px) 100vw, 1039px"></a><figcaption id="caption-attachment-30704">IBM And Red Hat Merger</figcaption></figure>
<p>The strange part of the Red Hat announcement was that it sets a precedent that is not great. Both Red Hat, and IBM its parent, are very large, sophisticated companies. There is little chance they did not foresee community outcry over an abrupt change of direction like this. Sometimes, those changes have to be made, and in the technology industry change should be the status quo. At the same time, seeing a large, established company making this kind of abrupt change, that has a major operating impact on a large user base, without a clear path forward, is a scary precedent. RHEL customers are taking notice asking if this is what they can expect from the company moving forward.</p>
<p>There are basically two paths forward here. One is that Red Hat becomes the Apple (or IBM?) of the Linux ecosystem, becoming a high-priced exclusive vendor with great technology. The second is that Red Hat unveils a roadmap that does not leave the CentOS community peering over the edge of an end-of-support cliff.</p>
<p>As always, we would love to hear STH community‚Äôs thoughts on the announcement. There is a thread in our <a href="https://forums.servethehome.com/index.php?threads/centos-8-to-be-discontinued-at-end-of-2021.31052/">forums here</a>.</p>
        </div></div>]]>
            </description>
            <link>https://www.servethehome.com/red-hat-goes-full-ibm-and-says-farewell-to-centos/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25400249</guid>
            <pubDate>Sat, 12 Dec 2020 18:19:03 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[GitHub Dark Mode is too Dark]]>
            </title>
            <description>
<![CDATA[
Score 354 | Comments 184 (<a href="https://news.ycombinator.com/item?id=25400139">thread link</a>) | @karenying7
<br/>
December 12, 2020 | https://blog.karenying.com/posts/github-darkmode-sucks | <a href="https://web.archive.org/web/*/https://blog.karenying.com/posts/github-darkmode-sucks">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>If you hate it too this is why. Using color theory to show why GitHub dark mode is disappointing</p><div><p><span>
      <a href="https://blog.karenying.com/static/1240ac771aa160847206d70e5dd76dce/6389a/github-darkmode-sucks.jpg" target="_blank" rel="noopener">
    <span></span>
  <picture>
        <source srcset="https://blog.karenying.com/static/1240ac771aa160847206d70e5dd76dce/8ac56/github-darkmode-sucks.webp 240w,
https://blog.karenying.com/static/1240ac771aa160847206d70e5dd76dce/d3be9/github-darkmode-sucks.webp 480w,
https://blog.karenying.com/static/1240ac771aa160847206d70e5dd76dce/e46b2/github-darkmode-sucks.webp 960w,
https://blog.karenying.com/static/1240ac771aa160847206d70e5dd76dce/30504/github-darkmode-sucks.webp 1325w" sizes="(max-width: 960px) 100vw, 960px" type="image/webp">
        <source srcset="https://blog.karenying.com/static/1240ac771aa160847206d70e5dd76dce/09b79/github-darkmode-sucks.jpg 240w,
https://blog.karenying.com/static/1240ac771aa160847206d70e5dd76dce/7cc5e/github-darkmode-sucks.jpg 480w,
https://blog.karenying.com/static/1240ac771aa160847206d70e5dd76dce/6a068/github-darkmode-sucks.jpg 960w,
https://blog.karenying.com/static/1240ac771aa160847206d70e5dd76dce/6389a/github-darkmode-sucks.jpg 1325w" sizes="(max-width: 960px) 100vw, 960px" type="image/jpeg">
        <img src="https://blog.karenying.com/static/1240ac771aa160847206d70e5dd76dce/6a068/github-darkmode-sucks.jpg" alt="toggle" title="toggle" loading="lazy">
      </picture>
  </a>
    </span></p>
<p>This past week, GitHub <a href="https://twitter.com/github/status/1336362679506784256" target="_blank">released</a> a long-awaited feature ‚Äî dark mode. Like many devs around the world, I was hype. In 2020, a dark mode toggle for anything remotely related to tech seems like a requirement.</p>
<p>So I flipped the switch. My immediate reaction was that it seemed a bit off. But I wanted to give it a chance and credited that feeling towards just not being used to the theme yet.</p>
<p>Flash forward a couple of days, I found myself switching to light mode for code review specifically. I didn‚Äôt feel confident code reviewing in dark mode. I was scared I would miss something. It was after a couple of instances of this did I realize, GitHub dark mode is <em>too</em> dark. And here‚Äôs why.</p>
<h2 id="the-proof-is-in-the-palette-pudding"><a href="#the-proof-is-in-the-palette-pudding" aria-label="the proof is in the palette pudding permalink"></a>The Proof is in the Palette (Pudding)</h2>
<h3 id="accessibility-and-contrast-ratio"><a href="#accessibility-and-contrast-ratio" aria-label="accessibility and contrast ratio permalink"></a>Accessibility and Contrast Ratio</h3>
<p>I explain contrast ratio in depth <a href="https://blog.karenying.com/posts/boost-visual-accessibility-by-auto-flipping-text-color#wcag-and-contrast-ratio" target="_blank">here</a> but this is what you need to know:</p>
<ul>
<li>The contrast ratio between two colors mathematically calculates how different our eyes perceive them to be</li>
<li>It ranges between <strong>1</strong> (two of the same colors) to <strong>21</strong> (black and white)</li>
<li>The smaller the text is, the larger the contrast ratio between the text color and the background color needs to be</li>
<li>The <a href="https://www.w3.org/WAI/standards-guidelines/wcag/" target="_blank">Web Content Accessibility Guidelines</a> (WCAG) defines a level <strong>AA</strong> contrast ratio as above <strong>4.5</strong> and level <strong>AAA</strong> as above <strong>7</strong> for small text</li>
<li><strong>AAA</strong> is considered the gold standard level for web accessibility</li>
</ul>
<h3 id="other-dark-mode-site-palettes"><a href="#other-dark-mode-site-palettes" aria-label="other dark mode site palettes permalink"></a>Other Dark Mode Site Palettes</h3>
<p><em>I did a deep dive into the dark mode palettes of Spotify, Twitter, Facebook and more in this <a href="https://blog.karenying.com/posts/50-shades-of-dark-mode-gray" target="_blank">post</a>.</em></p>
<p>I grabbed the dark mode colors of a couple of popular sites/apps. Every palette image shows the background color, primary text color, and secondary text color from left to right. <strong>I put the contrast ratios of the primary and secondary colors with the background color on top of the respective color.</strong></p>
<p><strong>Spotify</strong>:
<span>
      <a href="https://blog.karenying.com/static/f41785977c16229244c691d3ea4a2e08/cd7c1/spotify.png" target="_blank" rel="noopener">
    <span></span>
  <picture>
        <source srcset="https://blog.karenying.com/static/f41785977c16229244c691d3ea4a2e08/8ac56/spotify.webp 240w,
https://blog.karenying.com/static/f41785977c16229244c691d3ea4a2e08/d3be9/spotify.webp 480w,
https://blog.karenying.com/static/f41785977c16229244c691d3ea4a2e08/e46b2/spotify.webp 960w,
https://blog.karenying.com/static/f41785977c16229244c691d3ea4a2e08/f992d/spotify.webp 1440w,
https://blog.karenying.com/static/f41785977c16229244c691d3ea4a2e08/0dd1a/spotify.webp 1547w" sizes="(max-width: 960px) 100vw, 960px" type="image/webp">
        <source srcset="https://blog.karenying.com/static/f41785977c16229244c691d3ea4a2e08/8ff5a/spotify.png 240w,
https://blog.karenying.com/static/f41785977c16229244c691d3ea4a2e08/e85cb/spotify.png 480w,
https://blog.karenying.com/static/f41785977c16229244c691d3ea4a2e08/d9199/spotify.png 960w,
https://blog.karenying.com/static/f41785977c16229244c691d3ea4a2e08/07a9c/spotify.png 1440w,
https://blog.karenying.com/static/f41785977c16229244c691d3ea4a2e08/cd7c1/spotify.png 1547w" sizes="(max-width: 960px) 100vw, 960px" type="image/png">
        <img src="https://blog.karenying.com/static/f41785977c16229244c691d3ea4a2e08/d9199/spotify.png" alt="spotify" title="spotify" loading="lazy">
      </picture>
  </a>
    </span></p>
<p><strong>Facebook</strong>:
<span>
      <a href="https://blog.karenying.com/static/ad8798f88b992514cc4c3731757290b2/dca52/facebook.png" target="_blank" rel="noopener">
    <span></span>
  <picture>
        <source srcset="https://blog.karenying.com/static/ad8798f88b992514cc4c3731757290b2/8ac56/facebook.webp 240w,
https://blog.karenying.com/static/ad8798f88b992514cc4c3731757290b2/d3be9/facebook.webp 480w,
https://blog.karenying.com/static/ad8798f88b992514cc4c3731757290b2/e46b2/facebook.webp 960w,
https://blog.karenying.com/static/ad8798f88b992514cc4c3731757290b2/f992d/facebook.webp 1440w,
https://blog.karenying.com/static/ad8798f88b992514cc4c3731757290b2/eb054/facebook.webp 1550w" sizes="(max-width: 960px) 100vw, 960px" type="image/webp">
        <source srcset="https://blog.karenying.com/static/ad8798f88b992514cc4c3731757290b2/8ff5a/facebook.png 240w,
https://blog.karenying.com/static/ad8798f88b992514cc4c3731757290b2/e85cb/facebook.png 480w,
https://blog.karenying.com/static/ad8798f88b992514cc4c3731757290b2/d9199/facebook.png 960w,
https://blog.karenying.com/static/ad8798f88b992514cc4c3731757290b2/07a9c/facebook.png 1440w,
https://blog.karenying.com/static/ad8798f88b992514cc4c3731757290b2/dca52/facebook.png 1550w" sizes="(max-width: 960px) 100vw, 960px" type="image/png">
        <img src="https://blog.karenying.com/static/ad8798f88b992514cc4c3731757290b2/d9199/facebook.png" alt="facebook" title="facebook" loading="lazy">
      </picture>
  </a>
    </span></p>
<p><strong>YouTube</strong>:
<span>
      <a href="https://blog.karenying.com/static/fd8122a79767abe8f5819c42f7c9b391/acd79/youtube.png" target="_blank" rel="noopener">
    <span></span>
  <picture>
        <source srcset="https://blog.karenying.com/static/fd8122a79767abe8f5819c42f7c9b391/8ac56/youtube.webp 240w,
https://blog.karenying.com/static/fd8122a79767abe8f5819c42f7c9b391/d3be9/youtube.webp 480w,
https://blog.karenying.com/static/fd8122a79767abe8f5819c42f7c9b391/e46b2/youtube.webp 960w,
https://blog.karenying.com/static/fd8122a79767abe8f5819c42f7c9b391/f992d/youtube.webp 1440w,
https://blog.karenying.com/static/fd8122a79767abe8f5819c42f7c9b391/bb338/youtube.webp 1543w" sizes="(max-width: 960px) 100vw, 960px" type="image/webp">
        <source srcset="https://blog.karenying.com/static/fd8122a79767abe8f5819c42f7c9b391/8ff5a/youtube.png 240w,
https://blog.karenying.com/static/fd8122a79767abe8f5819c42f7c9b391/e85cb/youtube.png 480w,
https://blog.karenying.com/static/fd8122a79767abe8f5819c42f7c9b391/d9199/youtube.png 960w,
https://blog.karenying.com/static/fd8122a79767abe8f5819c42f7c9b391/07a9c/youtube.png 1440w,
https://blog.karenying.com/static/fd8122a79767abe8f5819c42f7c9b391/acd79/youtube.png 1543w" sizes="(max-width: 960px) 100vw, 960px" type="image/png">
        <img src="https://blog.karenying.com/static/fd8122a79767abe8f5819c42f7c9b391/d9199/youtube.png" alt="youtube" title="youtube" loading="lazy">
      </picture>
  </a>
    </span></p>
<p>All of these satisfy the AAA standard of a contrast ratio of at least 7 üëçüèº</p>
<p>And then we have GitHub‚Äôs new look‚Ä¶</p>
<p><strong>GitHub</strong>:
<span>
      <a href="https://blog.karenying.com/static/bf248615c0d8b1075b682c980b07202d/d3deb/github.png" target="_blank" rel="noopener">
    <span></span>
  <picture>
        <source srcset="https://blog.karenying.com/static/bf248615c0d8b1075b682c980b07202d/8ac56/github.webp 240w,
https://blog.karenying.com/static/bf248615c0d8b1075b682c980b07202d/d3be9/github.webp 480w,
https://blog.karenying.com/static/bf248615c0d8b1075b682c980b07202d/e46b2/github.webp 960w,
https://blog.karenying.com/static/bf248615c0d8b1075b682c980b07202d/f992d/github.webp 1440w,
https://blog.karenying.com/static/bf248615c0d8b1075b682c980b07202d/383eb/github.webp 1758w" sizes="(max-width: 960px) 100vw, 960px" type="image/webp">
        <source srcset="https://blog.karenying.com/static/bf248615c0d8b1075b682c980b07202d/8ff5a/github.png 240w,
https://blog.karenying.com/static/bf248615c0d8b1075b682c980b07202d/e85cb/github.png 480w,
https://blog.karenying.com/static/bf248615c0d8b1075b682c980b07202d/d9199/github.png 960w,
https://blog.karenying.com/static/bf248615c0d8b1075b682c980b07202d/07a9c/github.png 1440w,
https://blog.karenying.com/static/bf248615c0d8b1075b682c980b07202d/d3deb/github.png 1758w" sizes="(max-width: 960px) 100vw, 960px" type="image/png">
        <img src="https://blog.karenying.com/static/bf248615c0d8b1075b682c980b07202d/d9199/github.png" alt="github" title="github" loading="lazy">
      </picture>
  </a>
    </span></p>
<p>Not only do the colors look noticeably darker than their counterparts in other apps, <strong>the secondary text color fails AAA standards</strong>! It‚Äôs important for the secondary text color to have high contrast because of how small the font is. I knew my eyes didn‚Äôt deceive me.</p>
<p><strong>While contrast ratios aren‚Äôt <a href="https://www.bounteous.com/insights/2019/03/22/orange-you-accessible-mini-case-study-color-ratio/" target="_blank">everything</a>, they are a simple way to quantify the difference between two colors.</strong> In this case, it‚Äôs clear that GitHub‚Äôs dark mode colors <em>are</em> darker. This can make it harder to read text.</p>
<h3 id="code-review-palette"><a href="#code-review-palette" aria-label="code review palette permalink"></a>Code Review Palette</h3>
<p>Finally, my main gripe with GitHub dark mode is that the red / green for code diffs looks super off to me.</p>
<p>On the right is the light mode colors and left is the new shades. I overlaid the respective background colors on top:</p>
<p><span>
      <a href="https://blog.karenying.com/static/8746d6d25da3c72d11a920e17b5ad110/c95f0/diff.png" target="_blank" rel="noopener">
    <span></span>
  <picture>
        <source srcset="https://blog.karenying.com/static/8746d6d25da3c72d11a920e17b5ad110/8ac56/diff.webp 240w,
https://blog.karenying.com/static/8746d6d25da3c72d11a920e17b5ad110/d3be9/diff.webp 480w,
https://blog.karenying.com/static/8746d6d25da3c72d11a920e17b5ad110/e46b2/diff.webp 960w,
https://blog.karenying.com/static/8746d6d25da3c72d11a920e17b5ad110/f992d/diff.webp 1440w,
https://blog.karenying.com/static/8746d6d25da3c72d11a920e17b5ad110/2ac07/diff.webp 1842w" sizes="(max-width: 960px) 100vw, 960px" type="image/webp">
        <source srcset="https://blog.karenying.com/static/8746d6d25da3c72d11a920e17b5ad110/8ff5a/diff.png 240w,
https://blog.karenying.com/static/8746d6d25da3c72d11a920e17b5ad110/e85cb/diff.png 480w,
https://blog.karenying.com/static/8746d6d25da3c72d11a920e17b5ad110/d9199/diff.png 960w,
https://blog.karenying.com/static/8746d6d25da3c72d11a920e17b5ad110/07a9c/diff.png 1440w,
https://blog.karenying.com/static/8746d6d25da3c72d11a920e17b5ad110/c95f0/diff.png 1842w" sizes="(max-width: 960px) 100vw, 960px" type="image/png">
        <img src="https://blog.karenying.com/static/8746d6d25da3c72d11a920e17b5ad110/d9199/diff.png" alt="diff colors" title="diff colors" loading="lazy">
      </picture>
  </a>
    </span></p>
<p>I did calculate the contrast ratios of both palettes and they were pretty similar (close to 1 lol). However, for some reason the lighter one is easier for me to parse at a cursory glance. Maybe I‚Äôm not used to it yet, but I really dislike how dark the new diff colors are. For something as important as code review, I‚Äôm using GitHub light mode.</p>
<p>I also investigated <strong>VSCode‚Äôs Git integration</strong> diff colors (which I enjoy!):</p>
<p><span><span>
      <a href="https://blog.karenying.com/static/8dc099fd4d8ccf05421bcfe28ae70892/dc61a/vscode-diff.png" target="_blank" rel="noopener">
    <span></span>
  <picture>
        <source srcset="https://blog.karenying.com/static/8dc099fd4d8ccf05421bcfe28ae70892/8ac56/vscode-diff.webp 240w,
https://blog.karenying.com/static/8dc099fd4d8ccf05421bcfe28ae70892/d3be9/vscode-diff.webp 480w,
https://blog.karenying.com/static/8dc099fd4d8ccf05421bcfe28ae70892/e46b2/vscode-diff.webp 960w,
https://blog.karenying.com/static/8dc099fd4d8ccf05421bcfe28ae70892/f8f9f/vscode-diff.webp 1147w" sizes="(max-width: 960px) 100vw, 960px" type="image/webp">
        <source srcset="https://blog.karenying.com/static/8dc099fd4d8ccf05421bcfe28ae70892/8ff5a/vscode-diff.png 240w,
https://blog.karenying.com/static/8dc099fd4d8ccf05421bcfe28ae70892/e85cb/vscode-diff.png 480w,
https://blog.karenying.com/static/8dc099fd4d8ccf05421bcfe28ae70892/d9199/vscode-diff.png 960w,
https://blog.karenying.com/static/8dc099fd4d8ccf05421bcfe28ae70892/dc61a/vscode-diff.png 1147w" sizes="(max-width: 960px) 100vw, 960px" type="image/png">
        <img src="https://blog.karenying.com/static/8dc099fd4d8ccf05421bcfe28ae70892/d9199/vscode-diff.png" alt="vscode diff colors" title="vscode diff colors" loading="lazy">
      </picture>
  </a>
    </span></span></p>
<p>IMO these shades work well even on a darker background and don‚Äôt hinder code review.</p>
<h2 id="conclusion"><a href="#conclusion" aria-label="conclusion permalink"></a>Conclusion</h2>
<p>While there is no color theory justification that GitHub‚Äôs new code diff palette is worse, its text colors are not as WCAG accessible as other dark mode apps we use daily.</p>
<p>Maybe if GitHub put as much effort into researching their dark mode palette as they did into the <a href="https://twitter.com/github/status/1336362679506784256" target="_blank">promo video</a> they released, we wouldn‚Äôt be here. This is still a beta feature so I have hope. <strong>GitHub, please give us the dark mode experience we deserve ü•∫</strong></p>
<p><em>Thanks for reading. Happy hacking!</em></p></div></div>]]>
            </description>
            <link>https://blog.karenying.com/posts/github-darkmode-sucks</link>
            <guid isPermaLink="false">hacker-news-small-sites-25400139</guid>
            <pubDate>Sat, 12 Dec 2020 18:03:08 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[I've designed Python fantasy cards to learn it easier]]>
            </title>
            <description>
<![CDATA[
Score 67 | Comments 37 (<a href="https://news.ycombinator.com/item?id=25400117">thread link</a>) | @tomaszs
<br/>
December 12, 2020 | https://summonthejson.com/products/summon-the-json-python-deck | <a href="https://web.archive.org/web/*/https://summonthejson.com/products/summon-the-json-python-deck">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

<p data-mce-style="text-align: left;">If you are learning to code, it is often hard to discover and memorize all programming functions. STJ&nbsp;Python flashcards make it super easy. It combines state of art memory techniques to help you remember functions fast.</p>
<p data-mce-style="text-align: left;"><strong>The science behind STJ:&nbsp;Python</strong></p>
<div data-mce-style="text-align: left;"><p>According to research, images help stick the information in the long term memory, transmit messages faster, improve comprehension, trigger emotions, motivate learners. In fact, 90% of information transmitted to the brain is visual (<a href="https://www.shiftelearning.com/blog/bid/350326/studies-confirm-the-power-of-visuals-in-elearning">source</a>). That is why STJ: Python intriguing and beautiful illustrations can help you memorize faster. Side-by-side with the fantasy setting and funny descriptions STJ:&nbsp;Python cards are a great combo to help boost your memory! They are eye-catching but also cause emotions - the cornerstone of fast memorization (<a href="https://www.memory-key.com/memory/emotion">source</a>).</p><p>Dive into a fantasy world of Summon The JSON, where excellent visual design, creatures, and fun descriptions will help you remember&nbsp;Python function automagically.</p></div>
<p data-mce-style="text-align: left;"><img alt="" src="https://cdn.shopify.com/s/files/1/0448/5260/9188/files/IMG20201117083121_1024x1024.jpg?v=1606044111"></p>
<p data-mce-style="text-align: left;">STJ:&nbsp;Python is an excellent choice if you:</p>
<p data-mce-style="text-align: left;"><strong>Want to become a programmer</strong></p>
<div data-mce-style="text-align: left;"><p>Flashcards contain the most useful set of&nbsp;Python functions programmers use most of the time. STJ:&nbsp;Python will give you a great overview of what tools every programmer has at hand. With that knowledge, it will be easier for you to start thinking about how to create your application from these building blocks.</p><p><strong>Go to a coding job interview</strong></p></div>
<p data-mce-style="text-align: left;">A lot of companies use knowledge tests and whiteboard tasks to assess coding job candidate knowledge. STJ:&nbsp;Python helps you remember functions easier. Regular flashcards are boring and make it hard to stick programming functions to anything meaningful.&nbsp; Contrary STJ:&nbsp;Python helps your brain store information about&nbsp;Python functions in an efficient way.&nbsp; It increases the chance, that during a job interview your brain will be able to give you all information you need.<br></p>
<p data-mce-style="text-align: left;"><img alt="" src="https://cdn.shopify.com/s/files/1/0448/5260/9188/files/IMG20201117083241_8b6c81c4-e7f9-4e0a-b7aa-b22ca2d539a8_1024x1024.jpg?v=1606044472"></p>
<p data-mce-style="text-align: left;"><strong>Switch from another language to&nbsp;Python</strong></p>
<p data-mce-style="text-align: left;">If you are already a software developer, you know how confusing it is to switch to learn another language. Some functions are similar. Some are not. It gets even worse when you code in 2 or 3 languages at the same time. There is a lot of things to remember in every language. You need to find equivalents. STJ:&nbsp;Python will help you progress faster in learning Python. It shows you the toolset of the language and helps you remember it faster. Also, if you come back to Python, you can also take a look at cards, to recalibrate your brain easier.</p>
<p data-mce-style="text-align: left;"><img alt="" src="https://cdn.shopify.com/s/files/1/0448/5260/9188/files/IMG20201117082424_1024x1024.jpg?v=1606044528"></p>
<p data-mce-style="text-align: left;"><strong>Write faster without searching online</strong><br></p>
<p data-mce-style="text-align: left;">It is great, we have a lot of easily accessible sources on the Internet, we can find all information within seconds or minutes. But the Internet will never beat the human brain speed. If you remember function names, you will code faster. Moreover, your coding experience will become more fulfilling. You won't worry about connection lags, that the search engine does not give the answer you are looking for. You won't be distracted by websites and online ads. Focus is one of the most important assets of a programmer. STJ:&nbsp;Python will help you be more focused in the zone!</p>
<p data-mce-style="text-align: left;"><img src="https://cdn.shopify.com/s/files/1/0448/5260/9188/files/IMG20201117082538_1024x1024.jpg?v=1606044208" alt=""></p>

<div data-mce-style="text-align: left;"><p>Summon The JSON:&nbsp;Python is not only a flashcard deck. It is also a game for everyone. Up to four people can play a game with STJ: Python. The deck is divided into heroes, animals, and food.&nbsp; Some cards have points, some have super-powers. You can combine them to win battles against other players.</p><p>STJ:&nbsp;Python game can be played by everyone. You don't need to have any prior programming knowledge to do so. In fact, it is a great way to spend time in a mixed group of geeks and non-geeks. You can play it with your family, friends, colleagues, or even meet new people</p></div>
<p data-mce-style="text-align: left;">STJ:&nbsp;Python game is a great ice-breaker, conversation starter, and a way to spend time with other people, chat, and bond. Have a great time together.</p>
<p data-mce-style="text-align: left;"><img src="https://cdn.shopify.com/s/files/1/0448/5260/9188/files/IMG20201117082016_1024x1024.jpg?v=1606044238" alt=""></p>
<h2 data-mce-style="text-align: left;">What is inside?</h2>
<p data-mce-style="text-align: left;">One deck contains:</p>
<ul>
<li data-mce-style="text-align: left;">A complete deck of 65-cards with several custom cards (make your own cards)</li>
<li data-mce-style="text-align: left;">8-page long booklet instruction with 2 memorization modes and game instruction</li>
</ul>
<p data-mce-style="text-align: left;">Cards are premium quality with linen texture and durable UV coating. The learning game takes approx 3 minutes. Each game takes about 15 minutes and can be repeated indefinitely.&nbsp;</p>
<p data-mce-style="text-align: left;"><img src="https://cdn.shopify.com/s/files/1/0448/5260/9188/files/IMG20201117082811_1024x1024.jpg?v=1606044272" alt=""></p>
</div></div>]]>
            </description>
            <link>https://summonthejson.com/products/summon-the-json-python-deck</link>
            <guid isPermaLink="false">hacker-news-small-sites-25400117</guid>
            <pubDate>Sat, 12 Dec 2020 18:00:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Buy Don't Build]]>
            </title>
            <description>
<![CDATA[
Score 203 | Comments 185 (<a href="https://news.ycombinator.com/item?id=25399250">thread link</a>) | @jrott
<br/>
December 12, 2020 | https://jrott.com/posts/why-buy/ | <a href="https://web.archive.org/web/*/https://jrott.com/posts/why-buy/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
				

<p>Standing up and managing a service or building a custom service is a common desire for engineers. It‚Äôs usually a major mistake, that ends up costing a ton of time and money.
The desire to build custom versions of everything seems to come from a few places:</p>

<ol>
<li>The hope that it will be cheaper to build than buy.</li>
<li>The idea that their companies process is special so industry-standard stuff will not work.</li>
<li>That they need to have total control over what the service does.</li>
<li>To avoid vendor lock-in</li>
</ol>

<p>All four of those things are less true and less important than you would think. It‚Äôs worth building when something is core to your business or provides a significant competitive advantage. Otherwise, it‚Äôs probably worth using the services that your cloud provider has or another saas. Running your own stuff has a significant operational burden and a large opportunity cost.
If you only get one thing out of this let it be: Building stuff is fun, but being paged at two in the morning about a Rube Goldberg contraption of a system to handle customer analytics isn‚Äôt.</p>

<h2 id="p-align-center-running-services-isn-t-easy-p"><p> Running services isn‚Äôt easy </p></h2>

<p>Keeping systems up in production takes time and energy. Building them isn‚Äôt where most of the expense lies. Instead, that comes with running and maintaining complicated systems.
Most enterprise systems require an engineering team to keep them running. Engineers aren‚Äôt cheap to hire and there is also additional complexity that gets introduced to keep a large number of teams coordinated. This all results in slower decision making.</p>

<p>Slower decisions happen because more teams are needed to maintain more services. These teams then need to work together and coordinate. All of a sudden, to make a change there are a million teams that need to be informed and handoffs that have to be managed. That can lead to fiefdoms for managers and way more politics, since there are now more teams and a more complicated organizational structure.</p>

<p>If you are following a DevOps model, the team that builds the service will also end up maintaining it. The more moving pieces that there are for the team to maintain, the less time that they will have for new feature development. This is painful, especially in young companies with a rapidly evolving product. Slowing down the time it takes to find product-market fit in exchange for getting to run your own stuff is a bad trade.</p>

<p>You also have to consider the level of operational excellence that exists in your organization. To put it bluntly, who do you trust more for uptime - Amazon or you? The answer, for services which you absolutely depend on for survival, might be you. Other systems though may suffer from getting less time and attention, because it becomes harder to justify the expense of keeping them up and running.</p>

<h2 id="p-align-center-vendor-lock-in-p"><p> Vendor lock-in </p></h2>

<p>At this point, you might be thinking ‚ÄúBut I don‚Äôt want to be stuck on a vendor‚Äôs special snowflake of a system‚Äù. My counter-argument to that is there is also lock-in with internal systems. The most common version of this is The Keeper of The Spreadsheet. Now, if you‚Äôre going ‚Äúwhat spreadsheet?‚Äù, well that‚Äôs a fair question. But it‚Äôs the one that for some important internal process that has turned into The Keeper of The Spreadsheet‚Äôs job. Most large companies have at least one spreadsheet like this. If you work at a large company, you probably realize that is a gross understatement - there can be many.</p>

<p>The Keeper(s) of The Spreadsheet will defend their process, and not want to change it at all costs, because they are worried that they‚Äôll get fired if that process gets automated or is no longer necessary. You also see this with engineering teams, where they become the Keepers of A Database or ticketing system. All of a sudden you‚Äôve got a system that sucks, and nobody wants to advocate for getting rid of it because their co-worker is convinced that they‚Äôll lose their job if it happens. This also creates a political trap for the unwary when they try and fix that process.</p>

<p>Being The Keeper of The Ticketing System isn‚Äôt all that fun usually either. It‚Äôs a good way to get pigeonholed into boring work. It also means that you end up with a system that isn‚Äôt the most important thing to the business, instead of allowing an outside company to take it. That outside company is likely to specialize in solving that problem, and has built deeper expertise because of that. Unless of course you‚Äôre slightly evil and looking for awful projects to exile people to.</p>

<p>All of this makes being locked into a vendor less of a concern than most people think. There is lock-in no matter what you do. The thing that you want to avoid is giving wholesale pricing power to any vendor. This can be avoided by making sure that the key differentiators for your business are in-house.</p>

<h2 id="p-align-center-engineering-time-is-expensive-p"><p> Engineering time is expensive </p></h2>

<p>Software and systems engineers aren‚Äôt cheap to hire. As a group, we also tend to undervalue our time. Think about how often you hear ‚ÄúOh I could build that in a week‚Äù, or ‚ÄúThat‚Äôll be easy‚Äù. With luck that‚Äôs just a comment on Reddit or hacker news, but if it‚Äôs at work then it usually turns into a total slog.</p>

<p>It‚Äôs common to express the cost of owning or maintaining a service in terms of the total cost of ownership (TCO). This is often really hard to calculate since many of the things that go into TCO aren‚Äôt tracked. The major issue that you‚Äôll run into is that it‚Äôs not just the cost of the engineer. The metric we care about is the opportunity cost of the other things that engineers could be producing.</p>

<p>Another reason that will come up for building something custom is for unique company processes. Usually with the idea that you couldn‚Äôt customize the software to make it work, or that it‚Äôd cost more than just building it. While these can be  valid reasons to build, it‚Äôs true less often than you would think. Many processes are shared across a large number of businesses. Also, processes tend to get bloated over time. Large amounts of the custom work that is needed to match up with a business‚Äôs processes are stuff that could just not be done. For an absurd example, that happened at a company I worked with:
1. Our process for recommending articles is complicated and requires tons of joins on fuzzy data
2. We can build our own database system that is designed specially to handle this.
3. A few months of intense development go by.
4. It turns out operating this thing is hard, we don‚Äôt know why some queries take the system down, and why our customers complaining about the recommendations.</p>

<p>You really don‚Äôt want that to be you. It‚Äôs demoralizing to have built and maintained a product for something that doesn‚Äôt even work correctly. When things are getting so complicated that no existing tooling will work for it, you should be asking if all of the complexity is fundamental to the domain or if the model you are using is flawed.</p>

<h2 id="p-align-center-loss-of-focus-p"><p> Loss of focus </p></h2>

<p>A significant problem that comes from running your own version of a service is that it‚Äôs another thing that engineers have to pay attention to. There is a limit on how many things can be important. What then happens to all of the non-core services that you are running is usually some form of neglect, where they are kept in a barely good enough state.</p>

<p>The problem then with that is everyone who is working on those services is usually trying to get off of them. After all, no one wants to work on something that their boss doesn‚Äôt care about. So you end up with a ton of maneuvering since people are trying to change teams, and that increases drag.</p>

<p>Compounding this problem even further is that not revenue-generating things are frequently ignored. Yes, your CI/CD system is absolutely critical, but it‚Äôs easy for executives to not think about. This leads to a failure mode where you have a lost garden of internal tools. Whereas if you are paying someone money to do the same thing, it is their business so they keep working on it.</p>

<h2 id="p-align-center-opportunity-cost-p"><p> Opportunity cost </p></h2>

<p>In many ways, the biggest problem with building a service is opportunity cost. The reason isn‚Äôt salary but instead what else could be done. It‚Äôs basically the same problem that you see when a company is building a one-off feature to close a sale. The big difference is that engineering is doing it to themselves so there may be willful blindness to the damage being done.</p>

<p>Engineers like building things, and many like to be in control of all the buttons and knobs. Many times this is a good thing. After all, it‚Äôs how anything super cool actually gets built. The problem with it arises when that impulse exists, without a keen sense of the business effects of decisions that are made.</p>

<p>The question you should be asking is what else could be done instead of tuning your own stuff or building a new internal system. The answer is usually spending more time coming up with the correct architecture,or developing actual customer-facing features, instead of fighting fires .</p>

<p>Having large operational footprints usually results in reduced velocity and fewer changes happening per engineer. Think about the difference in speed between big companies and startups. This isn‚Äôt because startups hire smarter people, instead it‚Äôs the amount of stuff that is tied up with any change at a big company.</p>

<p>This is an area where engineering can‚Äôt just think about the software that is being built. Instead, you have to think of the health of the entire product. It‚Äôs about building stuff that is useful for the customer and letting go of things that aren‚Äôt critical. By keeping a tight focus on core projects things are built faster. There is also less craft and maintenance work that goes along with the product.</p>

<h2 id="p-align-center-summing-up-p"><p> Summing up </p></h2>

<p>None of these reasons might apply in your case. There are many good reasons to build. However, if you haven‚Äôt considered whether you can just buy something to solve a problem instead of building it yourself, you should.</p>

<p>Think about if it‚Äôs worth as being paged at 2 in the morning over. If you are willing to be paged over it, also consider if someone else can ‚Ä¶</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://jrott.com/posts/why-buy/">https://jrott.com/posts/why-buy/</a></em></p>]]>
            </description>
            <link>https://jrott.com/posts/why-buy/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25399250</guid>
            <pubDate>Sat, 12 Dec 2020 16:22:26 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Semgrep for Cloud Security]]>
            </title>
            <description>
<![CDATA[
Score 57 | Comments 5 (<a href="https://news.ycombinator.com/item?id=25398963">thread link</a>) | @okram87
<br/>
December 12, 2020 | https://www.marcolancini.it/2020/blog-semgrep-for-cloud-security/ | <a href="https://web.archive.org/web/*/https://www.marcolancini.it/2020/blog-semgrep-for-cloud-security/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

<ul id="markdown-toc">
<li><a href="#what-is-semgrep" id="markdown-toc-what-is-semgrep">What is Semgrep?</a></li>
<li><a href="#semgrep-for-infrastructure-as-code" id="markdown-toc-semgrep-for-infrastructure-as-code">Semgrep for Infrastructure as Code</a> <ul>
<li><a href="#terraform" id="markdown-toc-terraform">Terraform</a> <ul>
<li><a href="#unencrypted-ebs-volumes" id="markdown-toc-unencrypted-ebs-volumes">Unencrypted EBS Volumes</a></li>
<li><a href="#open-security-groups" id="markdown-toc-open-security-groups">Open Security Groups</a></li>
</ul>
</li>
<li><a href="#kubernetes" id="markdown-toc-kubernetes">Kubernetes</a></li>
</ul>
</li>
<li><a href="#conclusions" id="markdown-toc-conclusions">Conclusions</a></li>
</ul>
<p><a href="https://semgrep.dev/" target="_blank">Semgrep</a> is an emerging
static analysis tool which is getting traction within the AppSec
community. Its broad support to multiple programming languages, together with
the easiness with which is possible to create rules, makes it a
powerful tool that can help AppSec teams scaling their efforts into preventing
complete classes of vulnerabilities from their codebases.</p>
<p>But what about cloud security? In the era of Infrastructure as Code,
where tools like Terraform, CloudFormation, Pulumi (and many others) are used
to provision infrastructure from (de-facto) source code, can we apply the
same approach to eradicate classes of cloud-related vulnerabilities from a
codebase?</p>

<p>I decided to spend part of my weekend experimenting with this,
and to get an idea of what Semgrep can provide to cloud/platform security teams.</p>

<p>Before jumping into the details, it is worth explaining what Semgrep
actually is.
As per their <a href="https://github.com/returntocorp/semgrep" target="_blank">website</a>, Semgrep is:</p>
<blockquote>
<p>A fast, open-source, static analysis tool that excels at expressing code standards ‚Äî without complicated queries ‚Äî and surfacing bugs early at editor, commit, and CI time.</p>
<p>Precise rules look like the code you‚Äôre searching; no more traversing abstract syntax trees or wrestling with regexes.</p>
<p>The Semgrep Registry has 1,000+ rules written by the Semgrep community covering security, correctness, and performance bugs. No need to DIY unless you want to.</p>
</blockquote>
<p>At a high level, Semgrep leverages Abstract Syntax Trees (ASTs)
to build a model of the code you are analyzing. Unlike other tools based on ASTs,
though, Semgrep lowers the entry bar by abstracting away the AST syntax itself.</p>
<figure>
<a href="https://www.marcolancini.it/images/posts/blog_semgrep_cloud_ast.jpg">
<img src="https://www.marcolancini.it/images/posts/blog_semgrep_cloud_ast.jpg" alt="Code as ASTs">
</a>
<figcaption>Code as ASTs. Image courtesy of <a href="https://docs.google.com/presentation/d/1j9uqQsMlePEuSzOD6E4Th2IYY4Hi7dl5XYbHdSDMkrc/edit#slide=id.g787344da8e_0_1645" target="_blank">Clint Gibler</a>.</figcaption>
</figure>
<p>Out of the box, Semgrep supports mainstream programming languages
(e.g., Go, Java, Python, Ruby, Javascript, etc.) and has a library of
<a href="https://github.com/returntocorp/semgrep-rules" target="_blank">open source rules</a>
ready to be re-used.</p>
<p>Explaining how to use Semgrep is out of scope for this blog post,
but the <a href="https://semgrep.dev/docs/" target="_blank">official documentation</a>
is really well made, and the
<a href="https://semgrep.dev/editor" target="_blank">online playground</a>
is an excellent space where to start playing with it
(without having to spend time installing anything).</p>
<hr>

<p>As briefly mentioned earlier, the benefit that Semgrep can bring to AppSec teams
is obvious (and if you are still not convinced, I recommend you to watch this
<a href="https://docs.google.com/presentation/d/1j9uqQsMlePEuSzOD6E4Th2IYY4Hi7dl5XYbHdSDMkrc/" target="_blank">this presentation</a> from <a href="https://twitter.com/clintgibler/" target="_blank">Clint Gibler</a>).</p>
<p>What I was curious to try was how well the same approach could fit a codebase
made of Terraform (HCL) and YAML files, as those languages are not currently
supported by Semgrep. Hence, I relied on its <code>Generic Pattern Matching</code> engine.</p>
<h2 id="terraform">Terraform</h2>
<p>The official <a href="https://github.com/returntocorp/semgrep-rules/tree/develop/terraform/lang/security" target="_blank">semgrep-rules</a> repository already contains a folder dedicated to Terraform.</p>
<figure>
<a href="https://www.marcolancini.it/images/posts/blog_semgrep_cloud_terraform_rules.jpg">
<img src="https://www.marcolancini.it/images/posts/blog_semgrep_cloud_terraform_rules.jpg" alt="Open source Terraform rules">
</a>
<figcaption>Open source Terraform rules.</figcaption>
</figure>
<p>Within this folder, we can see 7 rules already made open source, mainly focusing
on <a href="https://github.com/bridgecrewio/terragoat" target="_blank">Terragoat</a>
scenarios and S3 buckets.</p>
<h3 id="unencrypted-ebs-volumes">Unencrypted EBS Volumes</h3>
<p>Let‚Äôs start wrapping our head around it by picking the <code>unencrypted-ebs-volume</code> rule.
In the repo we can see a sample <a href="https://github.com/returntocorp/semgrep-rules/blob/develop/terraform/lang/security/ebs-unencrypted-volume.tf" target="_blank">Terraform file</a> (shown here below):</p>
<figure><pre><code data-lang="terraform"><span>resource</span> <span>"aws_ebs_volume"</span> <span>"web_host_storage"</span> <span>{</span>
  <span>availability_zone</span> <span>=</span> <span>"ap-southeast-2"</span>
  <span>encrypted</span>         <span>=</span> <span>false</span>
  <span>size</span> <span>=</span> <span>1</span>
  <span># ruleid: unencrypted-ebs-volume</span>
  <span>tags</span> <span>=</span> <span>{</span>
    <span>Name</span> <span>=</span> <span>"abcd-ebs"</span>
  <span>}</span>
<span>}</span></code></pre></figure>
<p>Quite straightforward, with an <code>aws_ebs_volume</code> resource declaring an EBS volume
with encryption disabled (as it can bee seen from <code>encrypted = false</code>).</p>
<p>So what we want to <code>grep</code> here is for an occurrence of <code>encrypted = false</code>
(or the lack of <code>encrypted = true</code>), as shown in the
<a href="https://github.com/returntocorp/semgrep-rules/blob/develop/terraform/lang/security/ebs-unencrypted-volume.yaml" target="_blank">corresponding rule</a>:</p>
<figure><pre><code data-lang="yaml"><span>rules</span><span>:</span>
<span>-</span> <span>id</span><span>:</span> <span>unencrypted-ebs-volume</span>
  <span>patterns</span><span>:</span>
    <span>-</span> <span>pattern-either</span><span>:</span>
      <span>-</span> <span>pattern</span><span>:</span> <span>|</span>
          <span>{...}</span>
    <span>-</span> <span>pattern-not-inside</span><span>:</span> <span>|</span>
        <span>resource "aws_ebs_volume" "..." {... encrypted=true ...}</span>
    <span>-</span> <span>pattern-inside</span><span>:</span> <span>|</span>
        <span>resource "aws_ebs_volume" "..." {...}</span>
  <span>languages</span><span>:</span>
    <span>-</span> <span>generic</span>
  <span>paths</span><span>:</span>
    <span>include</span><span>:</span>
    <span>-</span> <span>'</span><span>*.tf'</span>
  <span>message</span><span>:</span> <span>|</span>
    <span>An EBS volume is configured without encryption enabled.</span>
  <span>severity</span><span>:</span> <span>WARNING</span></code></pre></figure>
<p>You can try this rule in the Semgrep playground:
<a href="https://semgrep.dev/s/ZWrA/" target="_blank">https://semgrep.dev/s/ZWrA/</a>.</p>
<h3 id="open-security-groups">Open Security Groups</h3>
<p>As a second test, I wanted to create my first Semgrep rule to detect
a Security Group open to the world (<code>0.0.0.0/0</code>), like the one below:</p>
<figure><pre><code data-lang="terraform"><span>resource</span> <span>"aws_security_group"</span> <span>"allow_tls"</span> <span>{</span>
  <span>name</span>        <span>=</span> <span>"allow_tls"</span>
  <span>description</span> <span>=</span> <span>"Allow TLS inbound traffic"</span>
  <span>vpc_id</span>      <span>=</span> <span>aws_vpc</span><span>.</span><span>main</span><span>.</span><span>id</span>

  <span>ingress</span> <span>{</span>
    <span>description</span> <span>=</span> <span>"TLS from VPC"</span>
    <span>from_port</span>   <span>=</span> <span>443</span>
    <span>to_port</span>     <span>=</span> <span>443</span>
    <span>protocol</span>    <span>=</span> <span>"tcp"</span>
    <span>cidr_blocks</span> <span>=</span> <span>[</span><span>"10.0.1.0/24"</span><span>,</span> <span>"0.0.0.0/0"</span><span>]</span>
  <span>}</span>

  <span>tags</span> <span>=</span> <span>{</span>
    <span>Name</span> <span>=</span> <span>"allow_tls"</span>
  <span>}</span>
<span>}</span></code></pre></figure>
<p>What we want to <code>grep</code> here is any occurrence of <code>0.0.0.0/0</code> within an <code>ingress</code> block:</p>
<figure><pre><code data-lang="yaml"><span>rules</span><span>:</span>
<span>-</span> <span>id</span><span>:</span> <span>open-security-group</span>
  <span>patterns</span><span>:</span>
    <span>-</span> <span>pattern-inside</span><span>:</span> <span>ingress { ... }</span>
    <span>-</span> <span>pattern</span><span>:</span> <span>"</span><span>0.0.0.0/0"</span>
  <span>languages</span><span>:</span>
    <span>-</span> <span>generic</span>
  <span>paths</span><span>:</span>
    <span>include</span><span>:</span>
    <span>-</span> <span>'</span><span>*.tf'</span>
  <span>message</span><span>:</span> <span>|</span>
    <span>A security group is allowing inbound traffic from the public internet (0.0.0.0/0).</span>
  <span>severity</span><span>:</span> <span>WARNING</span></code></pre></figure>
<figure>
<a href="https://www.marcolancini.it/images/posts/blog_semgrep_cloud_rule_sg.jpg">
<img src="https://www.marcolancini.it/images/posts/blog_semgrep_cloud_rule_sg.jpg" alt="open-security-group rule">
</a>
<figcaption>open-security-group rule.</figcaption>
</figure>
<p>You can try this rule in the Semgrep playground:
<a href="https://semgrep.dev/s/ne51/" target="_blank">https://semgrep.dev/s/ne51/</a>.</p>
<p>Of course this is a vary basic case, where the offending string (<code>0.0.0.0/0</code>)
is directly hardcoded within the security group definition. The rule
will have to be extended if we want to take into account cases where
the CIDR can be specified, for example, via variables.</p>
<h2 id="kubernetes">Kubernetes</h2>
<p>Next, I wanted to create a rule more focused on Kubernetes (or, more precisely, YAML files).</p>
<p>Let‚Äôs take as a sample the case where you might want to enforce all your
Kubernetes Ingresses to be private, removing all the <code>public</code> ones:</p>
<figure><pre><code data-lang="yaml"><span>apiVersion</span><span>:</span> <span>extensions/v1beta1</span>
<span>kind</span><span>:</span> <span>Ingress</span>
<span>metadata</span><span>:</span>
  <span>name</span><span>:</span> <span>test-ingress</span>
  <span>annotations</span><span>:</span>
    <span>kubernetes.io/ingress.class</span><span>:</span> <span>public</span>
<span>spec</span><span>:</span>
  <span>rules</span><span>:</span>
  <span>-</span> <span>http</span><span>:</span>
      <span>paths</span><span>:</span>
      <span>-</span> <span>path</span><span>:</span> <span>/testpath</span>
        <span>pathType</span><span>:</span> <span>Prefix</span>
        <span>backend</span><span>:</span>
          <span>service</span><span>:</span>
            <span>name</span><span>:</span> <span>test</span>
            <span>port</span><span>:</span>
              <span>number</span><span>:</span> <span>80</span></code></pre></figure>
<p>In this example, we want to <code>grep</code> for the <code>kubernetes.io/ingress.class</code>
annotation, and ensure it has the approved value of <code>nginx-internal</code>:</p>
<figure><pre><code data-lang="yaml"><span>rules</span><span>:</span>
<span>-</span> <span>id</span><span>:</span> <span>public-ingress</span>
  <span>patterns</span><span>:</span>
    <span>-</span> <span>pattern</span><span>:</span> <span>kubernetes.io/ingress.class</span>
    <span>-</span> <span>pattern-not-inside</span><span>:</span> <span>|</span>
        <span>kubernetes.io/ingress.class: nginx-internal</span>
  <span>languages</span><span>:</span>
    <span>-</span> <span>generic</span>
  <span>paths</span><span>:</span>
    <span>include</span><span>:</span>
    <span>-</span> <span>'</span><span>*.yaml'</span>
  <span>message</span><span>:</span> <span>|</span>
    <span>An Ingress has been made public.</span>
  <span>severity</span><span>:</span> <span>WARNING</span></code></pre></figure>
<p>You can try this rule in the Semgrep playground:
<a href="https://semgrep.dev/s/ErGE/" target="_blank">https://semgrep.dev/s/ErGE/</a>.</p>
<hr>

<p>I have to say the extensibility, and simple syntax, of Semgrep are making it
very promising for cloud security teams as well.
In a few hours, thanks to the official documentation and Playground, I was able
to go from absolute 0 to writing my first rules.</p>
<p>The main challenge I can think of at the moment is: how much does Semgrep
overlap with <a href="https://github.com/open-policy-agent/conftest" target="_blank">OPA Conftest</a>?
Although Conftest has been created with cloud resources in mind,
and benefits from the sinergies
with the rest of the OPA offering (like <a href="https://github.com/open-policy-agent/gatekeeper" target="_blank">Gatekeeper</a>), basically everyone in the
industry at some point complained about how cumbersome the <a href="https://www.openpolicyagent.org/docs/latest/policy-language/" target="_blank">Rego</a> language is.
In my opinion, this could be a defining factor that might help expand the adotpion
of Semgrep from platform teams.</p>
<p>I‚Äôm quite curious to hear other people‚Äôs opinions on this, so please
feel free to reach out to me on <a href="https://twitter.com/lancinimarco" target="_blank">Twitter</a>.</p>
</div></div>]]>
            </description>
            <link>https://www.marcolancini.it/2020/blog-semgrep-for-cloud-security/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25398963</guid>
            <pubDate>Sat, 12 Dec 2020 15:51:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Badges of kindness for your website footers, repos, and more]]>
            </title>
            <description>
<![CDATA[
Score 27 | Comments 27 (<a href="https://news.ycombinator.com/item?id=25398272">thread link</a>) | @Nathanael
<br/>
December 12, 2020 | https://kindspeech.org/badges/ | <a href="https://web.archive.org/web/*/https://kindspeech.org/badges/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="site-content" role="main">

	
<article class="page" id="post-190">

	
<!-- .entry-header -->

	<div>

		<div>

			
<p>Badges are a discrete and simple way to offer kindness:</p>



<figure><img src="https://api.kindspeech.org/v1/badge" alt=""></figure>



<p>They display a changing, short, kind message, which aspires to make the recipient feel good about who they are and what they already have.</p>



<h2>How to Use Them</h2>



<p>They can easily be embedded online, any place where an image can be displayed from a URL:</p>



<pre><code>https://api.kindspeech.org/v1/badge</code></pre>



<p>The background color can also be customized:</p>



<figure><img src="https://api.kindspeech.org/v1/badge?color=plum" alt=""></figure>



<pre><code>https://api.kindspeech.org/v1/badge?color=plum</code></pre>



<p>For detailed technical information see <a href="https://api.kindspeech.org/">the API documentation.</a></p>



<h4>Markdown</h4>



<pre><code>![](https://api.kindspeech.org/v1/badge)</code></pre>



<h4>HTML</h4>



<pre><code>&lt;img src="https://api.kindspeech.org/v1/badge" /&gt;</code></pre>



<h2>Where to Use Them</h2>



<p>Just a few suggestions! The rest is entirely up to you. üòÑ</p>



<h4>Website Footers</h4>



<p>A little surprise for those who reach the bottom of your pages.</p>



<figure><img src="https://api.kindspeech.org/v1/badge?color=1e8296" alt=""></figure>



<h4>GitHub Repository Documentation</h4>



<p>Many GitHub repositories use badges to display dynamic information about the state of their project. The Kind Speech badges were designed to have a consistent look and feel so that you can share some love along with the state of your build:</p>



<p>
<img src="https://img.shields.io/badge/contributors-9000-green">
<img src="https://img.shields.io/badge/build-passing-green">
<img src="https://api.kindspeech.org/v1/badge">
</p>



<h4>Email Signatures</h4>



<p>Share some love with every email you send out! Note that some email providers block outside images by default, so recipients may need to explicitly allow the image to load before they can see it. ü§∑</p>



<blockquote><p>Dear Doug,</p><p>I was so glad to meet you from your wonderful email. It was interesting to know about your fish and how you take care of them.</p><p>You‚Äôre special ‚Äî just because you‚Äôre you.</p><p>Your television friend,</p><cite>‚Äî<br>Mister Rogers<p><img src="https://api.kindspeech.org/v1/badge?color=dc5830"></p></cite></blockquote>





		</div><!-- .entry-content -->

	</div><!-- .post-inner -->

	<!-- .section-inner -->

	
</article><!-- .post -->

</div></div>]]>
            </description>
            <link>https://kindspeech.org/badges/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25398272</guid>
            <pubDate>Sat, 12 Dec 2020 14:04:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Regex literals optimization (or how to cheat on benchmarks)]]>
            </title>
            <description>
<![CDATA[
Score 41 | Comments 10 (<a href="https://news.ycombinator.com/item?id=25395709">thread link</a>) | @nitely
<br/>
December 11, 2020 | https://nitely.github.io/2020/11/30/regex-literals-optimization.html | <a href="https://web.archive.org/web/*/https://nitely.github.io/2020/11/30/regex-literals-optimization.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p>The regex literals optimization avoids running the regex engine on parts of the input text that cannot possibly ever match the regex.</p>

<p>An example of a regex this can be applied to is <code>\w+@\w+\.\w+</code>, where the algorithm <em>quickly</em> finds the first <code>@</code>, then matches <code>\w+</code> backwards to find the start of the match, and then matches <code>\w+\.\w+</code> forward to find the end of the match. It then finds the second <code>@</code>, starting from the end of the previous match, and so on. This is a fairly naive (and incorrect) implementation, but it gives the idea of how it works.</p>

<p>I‚Äôve recently implemented it in my pet project <a href="https://github.com/nitely/nim-regex/pull/68">nim-regex</a>, an NFA based regex engine that runs in (super)linear time. The results show it‚Äôs around ~100x faster than before in some benchmarks. It‚Äôs up to ~60x faster than PCRE when the optimization kicks in. The tests are based on <a href="https://github.com/mariomka/regex-benchmark">mariomka/regex-benchmark</a>.</p>

<p>This is not to be confused with <em>Chivers‚Äô String Prefix Optimization</em>.</p>

<h2 id="literals-optimization">Literals Optimization</h2>

<p>Since nim-regex has to guarantee linear time, I‚Äôll describe optimizations that are guaranteed to take linear time. We must also ensure the matches are not overlapped.</p>

<p>Here‚Äôs a high-level description of the algorithm:</p>

<ul>
  <li>We pick a literal that is <code>memchr</code>‚Äòed to skip parts of the text.</li>
  <li>The prefix is the regex part before the literal; none of the
characters or symbols within the prefix must match the literal.</li>
  <li>The prefix is ran backwards to find the start of the match.</li>
  <li>A full scan is ran from the start of the match
until a character that cannot be matched is found (safe break point)
or the end is reached. The scan tries to start the match at every character (NFAs can do this in linear time).</li>
  <li>Go to step one and repeat from the last scanned char. Make the prefix
match until the previous last scanned char.</li>
</ul>

<p>There are two important constraints to picking a literal:</p>

<ul>
  <li><em>‚Äúnone of the characters or symbols within the prefix must match the literal‚Äù</em>, why? consider the regex: <code>\d\w+x</code>, and the input text: <code>xxxxxxxxxxx</code>; this would take quadratic time, as the prefix will match until the start of the string every time. What about the limit? while the limit does avoid the excessive matching, sometimes we‚Äôd need to match past the limit, ex: regex: <code>\d\w+x</code>, and text: <code>1xxx</code>. If we add this constraint, the literal becomes a delimeter, and these cases are solved.</li>
  <li>The literal cannot be part of a repetition, nor it can be part of an alternation. For example: <code>(abc)*def</code> the first literal candidate is <code>d</code>, since <code>(abc)*</code> may or may not be part of the match. Same thing for alternations.</li>
</ul>

<p>Here‚Äôs the main algorithm in <a href="https://nim-lang.org/">Nim</a>:</p>

<figure><pre><code data-lang="nim"><span>func</span> <span>findAll</span><span>(</span>
  <span>matches</span><span>:</span> <span>var</span> <span>Matches</span><span>,</span>
  <span>text</span><span>:</span> <span>string</span><span>,</span>
  <span>regex</span><span>:</span> <span>Regex</span><span>,</span>
  <span>start</span><span>:</span> <span>int</span>
<span>):</span> <span>int</span> <span>=</span>
  <span>var</span> <span>i</span> <span>=</span> <span>start</span>
  <span>var</span> <span>limit</span> <span>=</span> <span>start</span>
  <span>while</span> <span>i</span> <span>&lt;</span> <span>text</span><span>.</span><span>len</span><span>:</span>
    <span>limit</span> <span>=</span> <span>i</span>  <span># rather pointless since the literal is a delimiter</span>
    <span>i</span> <span>=</span> <span>memchr</span><span>(</span><span>text</span><span>,</span> <span>regex</span><span>.</span><span>lit</span><span>,</span> <span>i</span><span>)</span>
    <span>if</span> <span>i</span> <span>==</span> <span>-</span><span>1</span><span>:</span>
      <span>return</span> <span>-</span><span>1</span>
    <span>var</span> <span>litIdx</span> <span>=</span> <span>i</span>
    <span>i</span> <span>=</span> <span>matchPrefix</span><span>(</span><span>text</span><span>,</span> <span>regex</span><span>,</span> <span>i</span><span>,</span> <span>limit</span><span>)</span>
    <span>if</span> <span>i</span> <span>==</span> <span>-</span><span>1</span><span>:</span>
      <span>i</span> <span>=</span> <span>litIdx</span><span>+</span><span>1</span>
    <span>else</span><span>:</span>
      <span>i</span> <span>=</span> <span>findSome</span><span>(</span><span>matches</span><span>,</span> <span>text</span><span>,</span> <span>regex</span><span>,</span> <span>i</span><span>)</span>
      <span>if</span> <span>i</span> <span>==</span> <span>-</span><span>1</span><span>:</span>
        <span>return</span> <span>-</span><span>1</span>
      <span>if</span> <span>matches</span><span>.</span><span>len</span> <span>&gt;</span> <span>0</span><span>:</span>
        <span>return</span> <span>i</span>  <span># this is used as "start" to resume the matching</span>
  <span>return</span> <span>-</span><span>1</span></code></pre></figure>

<p>A given character may be consumed only twice, once by the backward prefix match, and a second time by the forward scan. Hence the algorithm runs in linear time.</p>

<p>I may describe how <code>matchPrefix</code> and <code>findSome</code> work, how to construct the reversed NFA in the right order, and how to pick the literal in a future article. The nim-regex code contains descriptions of the algorithms, though.</p>

<h2 id="benchmarks">Benchmarks</h2>

<p>The <a href="https://github.com/nitely/nim-regex/tree/master/bench">benchmarks</a> regexes are based on <a href="https://github.com/mariomka/regex-benchmark">mariomka/regex-benchmark</a>. The only difference is the regexes are pre-compiled, so just the matching is tested. The results show nim-regex is ~63x faster than PCRE in the email test, and ~2x faster in the URI and IP tests.</p>

<p>Why is nim-regex so fast in the email case? The regex engine doesn‚Äôt run as often. There are orders of magnitud more IP/URI candidates than email candidates (<code>@</code> chars within the text) to match. In the former case the time is dominated by the regex engine, while in the latter case it‚Äôs dominated by searching the char literal.</p>

<div><div><pre><code>==================================================
GlobalBenchmark       relative  time/iter  iters/s
==================================================
GlobalBenchmark                  294.86ps    3.39G
==================================================
bench.nim             relative  time/iter  iters/s
==================================================
pcre_email                        21.76ms    45.96
nim_regex_email       3247.14%   670.02us    1.49K
nim_regex_email_macro 6335.93%   343.38us    2.91K
pcre_uri                          22.15ms    45.14
nim_regex_uri           92.82%    23.87ms    41.90
nim_regex_uri_macro    256.29%     8.64ms   115.68
pcre_ip                            5.73ms   174.58
nim_regex_ip            88.70%     6.46ms   154.84
nim_regex_ip_macro     214.75%     2.67ms   374.91
</code></pre></div></div>

<blockquote>
  <p>Note Nim‚Äôs PCRE is at the top of the mariomka/regex-benchmark. I ran those benchmarks, and IIRC nim-regex was just a bit faster, mainly because the non-macro regex engine is slower (see the above results), and the regex compilation is also tested.</p>
</blockquote>

<h2 id="other-optimizations">Other optimizations</h2>

<p>Here are other possible optimizations:</p>

<ul>
  <li>Picking a literal ‚Äîeven if the prefix matches it‚Äî should take linear time as long as the prefix is bounded (i.e: does not contain repetitions), ex: <code>\d\wx</code>.</li>
  <li>Picking a literal within a ‚Äúone or more‚Äù repetition/repetition group should be possible, since <code>(abc)+</code> matches the same as <code>abc(abc)*</code>.</li>
  <li>It‚Äôs better to pick the last literal within the first literal sequence, since that way we always try to match as many literals as possible early on, and potentially fail early. We want to keep the prefix regex as short as possible, so the picking a literal in the first sequence is best.</li>
  <li>Alternations can be optimized this very same way in some cases, ex: <code>bar|baz</code>, since both alternations have <code>ba</code> in common, <code>a</code> can be picked as the literal.</li>
  <li>Alternations can be optimized in other cases. PCRE seems to use <code>memchr</code> or similar for up to two alternation terms. A DFA could be used to quickly match candidates instead of <code>memchr</code>, as that‚Äôs a more general solution.</li>
</ul>

<h2 id="conclusion">Conclusion</h2>

<p>Literals optimization is not a general optimization as it does not work on every regex, but when it does, it can greatly improve the matching speed.</p>

<p>Can a backtracker like PCRE implement this? PCRE in particular already has some sort of similar optimization, but it‚Äôs not as good/fast as this one. Backtrackers cannot implement this as described here exactly, but they can do something similar that requires backtracking. If they provide a resumable <code>find</code> function, then probably yes.</p>

<p>Hopefully, more regex engines will implement these sort of optimizations, so they are more compelling alternatives to backtrackers such as PCRE.</p>

  </div>
</article>

      </div>
    </div></div>]]>
            </description>
            <link>https://nitely.github.io/2020/11/30/regex-literals-optimization.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25395709</guid>
            <pubDate>Sat, 12 Dec 2020 04:59:59 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Amazon owns more than $2B worth of IPv4 addresses]]>
            </title>
            <description>
<![CDATA[
Score 338 | Comments 338 (<a href="https://news.ycombinator.com/item?id=25395432">thread link</a>) | @dangoldin
<br/>
December 11, 2020 | https://dangoldin.com/2020/12/11/amazon-owns-more-than-2b-worth-of-ipv4-addresses/ | <a href="https://web.archive.org/web/*/https://dangoldin.com/2020/12/11/amazon-owns-more-than-2b-worth-of-ipv4-addresses/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div role="main">
  <article>
    

    <section>
      
<p>While listening to a <a href="https://softwareengineeringdaily.com/2020/12/02/bgp-with-andree-toonk/">podcast discussing BGP</a> I heard the fact that AWS owns more than $2B worth of IP addresses. I knew AWS was massive but this came as a big shock so I decided to do some digging around. I came across a <a href="https://ipv4marketgroup.com/ipv4-pricing/">site</a> that listed the market prices of IP addresses and the range looks to be anywhere from $20 to $30 per IP depending on the block size. Now it was time to figure out the IP addresses owned by Amazon. I figured this would be difficult but lucky for us AWS actually <a href="https://ip-ranges.amazonaws.com/ip-ranges.json">publishes</a> their entire set of IP addresses as JSON.</p>

<p>The work is simply to download the JSON and then convert the CIDR blocks to the number of IPs and add them all up. As of today, December 11, 2020 AWS self reports owning 109,847,486 IPV4 addresses - at a price of $20 this is almost $2.2B and at $30 it‚Äôs almost $3.3B. That‚Äôs wild.</p>

<figure><pre><code data-lang="python"><span>import</span> <span>urllib.request</span>
<span>import</span> <span>json</span>

<span>with</span> <span>urllib</span><span>.</span><span>request</span><span>.</span><span>urlopen</span><span>(</span><span>' https://ip-ranges.amazonaws.com/ip-ranges.json'</span><span>)</span> <span>as</span> <span>f</span><span>:</span>
    <span>j</span> <span>=</span> <span>json</span><span>.</span><span>loads</span><span>(</span><span>f</span><span>.</span><span>read</span><span>().</span><span>decode</span><span>(</span><span>'utf-8'</span><span>))</span>

<span>print</span><span>(</span><span>'All keys'</span><span>,</span> <span>j</span><span>.</span><span>keys</span><span>())</span>

<span>print</span><span>(</span><span>'IPV4 prefixes'</span><span>,</span> <span>len</span><span>(</span><span>j</span><span>[</span><span>'prefixes'</span><span>]))</span>

<span>ips</span> <span>=</span> <span>0</span>
<span>for</span> <span>prefix</span> <span>in</span> <span>j</span><span>[</span><span>'prefixes'</span><span>]:</span>
    <span>cidr</span> <span>=</span> <span>int</span><span>(</span><span>prefix</span><span>[</span><span>'ip_prefix'</span><span>].</span><span>split</span><span>(</span><span>'/'</span><span>)[</span><span>1</span><span>])</span>
    <span>ips</span> <span>+=</span> <span>2</span><span>**</span><span>(</span><span>32</span><span>-</span><span>cidr</span><span>)</span>

<span>print</span><span>(</span><span>'# IPS'</span><span>,</span> <span>ips</span><span>)</span></code></pre></figure>

    </section>

    
    <br>
    

    

    

    

  </article>
</div></div>]]>
            </description>
            <link>https://dangoldin.com/2020/12/11/amazon-owns-more-than-2b-worth-of-ipv4-addresses/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25395432</guid>
            <pubDate>Sat, 12 Dec 2020 04:08:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Reverse Engineering the TP-Link HS110]]>
            </title>
            <description>
<![CDATA[
Score 63 | Comments 10 (<a href="https://news.ycombinator.com/item?id=25393505">thread link</a>) | @zdw
<br/>
December 11, 2020 | https://www.softscheck.com/en/reverse-engineering-tp-link-hs110/ | <a href="https://web.archive.org/web/*/https://www.softscheck.com/en/reverse-engineering-tp-link-hs110/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
	<div>
		<div>
			
<article id="post-3286">

<div>
<div>
	<!-- .entry-header -->

		<div>
      
		<p><em>by Lubomir Stroetmann, Consultant and Tobias Esser, Consultant</em></p>
<p><teaser><br>The <strong>TP-Link HS110 Wi-Fi</strong> is a cloud-enabled power plug that can be turned on and off remotely via app and offers energy monitoring and scheduling capabilities. As part of ongoing research into Internet of Things security, we performed a security analysis by reverse engineering the device firmware and Android app, sniffing app-to-device and device-to-app communications and <a href="https://www.softscheck.com/de/fuzzing-de/" target="_blank" rel="noopener noreferrer">fuzzing</a> the proprietary protocols being used.</teaser></p>
<p>While cloud communication was found to be reasonably secure for an IoT device, we discovered two insecure proprietary local configuration protocols: A human-readable JSON protocol ‚Äúencrypted‚Äù with an easily reversible autokey XOR cipher and a binary DES-encrypted configuration and debugging protocol (<strong>TDDP ‚Äì TP-Link Device Debug Protocol</strong>). TDDP is in use across most of the TP-Link product line including routers and access points and thus merits further research. We also release a <a href="https://github.com/softScheck/tplink-smartplug" target="_blank" rel="noopener noreferrer">Wireshark dissector and two python clients</a> for the proprietary protocols on GitHub.</p>

<p><strong id="nav">Contents</strong> </p>
<ol>
<li><a href="#Security Analysis Summary">Security Analysis Summary</a></li>
<li><a href="#Device Setup">Device Setup</a></li>
<li><a href="#Reverse Engineering the firmware">Reverse Engineering the firmware</a></li>
<li><a href="#Busybox">Busybox</a></li>
<li><a href="#Portscan">Portscan</a></li>
<li><a href="#TP-Link Smart Home Protocol">TP-Link Smart Home Protocol</a></li>
<li><a href="#Test Mode">Test Mode</a></li>
<li><a href="#TP-Link Device Debug Protocol">TP-Link Device Debug Protocol</a></li>
</ol>
<p><strong id="Security Analysis Summary">1. Security Analysis Summary</strong> <a href="#nav"></a></p>
<p><strong>The Good:</strong></p>
<ul>
<li>Cloud functionality can be turned off</li>
<li>Cloud communication uses HTTPS and CA pinning</li>
<li>Stores energy monitoring data locally</li>
<li>Firmware update checks signature against RSA keys</li>
</ul>
<p><strong>The Bad:</strong></p>
<ul>
<li>Useless encryption for local communication</li>
<li>No authentication: Anybody on the local network can turn the Smart Plug on and off, reset it or render it inoperable</li>
<li>TLS cloud connection could be intercepted with any valid Symantec EV certificate (only Root CA is checked)</li>
<li>Phones home even if set up as local-only</li>
<li>Undocumented configuration and debug service (TDDP)</li>
</ul>
<p><strong id="Device Setup">2. Device Setup</strong> <a href="#nav"></a></p>
<p>The Smart Plug has two physical buttons: An on/off relay switch and a device reset button that resets the device if pushed for five seconds or longer. When plugged in, an unconfigured or freshly reset Smart Plug will start an unsecured open Access Point with the SSID ‚Äú<code>TP-LINK_Smart Plug_XXXX</code>‚Äù where XXXX are four hexadecimal numbers. A quick search on <a href="https://www.wigle.net/" target="_blank" rel="noopener noreferrer">WiGLE</a> reveals several unconfigured TP-Link Smart Plugs in the wild:</p>
<p><img src="https://www.softscheck.com/assets/img/blog/wigle-suche-1.png" alt="wigle-suche"></p>
<p>&nbsp;<br>
TP-Link‚Äôs Smart Home app ‚Äú<a href="https://play.google.com/store/apps/details?id=com.tplink.kasa_android" target="_blank" rel="noopener noreferrer">Kasa</a>‚Äù makes the smartphone connect to this access point, sends UDP broadcast packets to <code>255.255.255.255</code> to find the Smart Plug IP and proceeds to configure it with the SSID and password that the user entered into the app. The Smart Plug then turns off the Access Point and connects to the configured WiFi as a client.</p>
<p>We perform a KARMA attack using the Sensepost <a href="https://github.com/sensepost/mana" target="_blank" rel="noopener noreferrer">MANA Toolkit</a>, forcibly deauthenticating the Smart Plug and trying to get it to connect to a rogue Access Point with the same SSID and no security. The attack is not successful; however repeated deauthentication can be used to perform a temporary Denial of Service attack against the device.</p>
<p><strong id="Reverse Engineering the firmware">3. Reverse Engineering the TP-Link HS110 firmware</strong> <a href="#nav"></a></p>
<p>We download the current official firmware for the device (<code>HS110(US)_V1_151016.zip</code>) and use binwalk to extract the contents of the .bin file:</p>
<p><img src="https://www.softscheck.com/assets/img/blog/binwalk-1.png" alt="binwalk"></p>
<p>&nbsp;<br>
As we can see, the firmware is a typical embedded Linux system and contains three parts:</p>
<ul>
<li>U-Boot Bootloader 1.1.4 (Oct 16 2015 ‚Äì 11:22:22)</li>
<li>Linux Kernel 2.6.31‚ÄîLSDK-9.2.0_U11.14 (yt@yangtao.localdomain)</li>
<li>Squashfs filesystem</li>
</ul>
<p>Examining the contents of the filesystem, we find the following interesting files:</p>
<ul>
<li>/bin/busybox v1.01 (2015.10.16-03:17+0000)</li>
<li>/etc/newroot2048.crt</li>
</ul>
<p>This is the certificate used to verify the identity of the cloud server. The file contains the ‚Äú<a href="https://www.symantec.com/theme/roots">VeriSign Class 3 Public Primary Certification Authority ‚Äì G5</a>‚Äù root certificate. This means the only check performed when establishing a TLS connection to the cloud is if the provided server certificate has been signed by the Symantec/VeriSign CA for Extended Validation (EV) certificates (<a href="https://www.owasp.org/index.php/Certificate_and_Public_Key_Pinning" target="_blank" rel="noopener noreferrer">CA pinning</a>). A determined attacker could buy his own EV certificate and use it to impersonate a cloud server.</p>
<ul>
<li>/etc/shadow</li>
</ul>
<pre>root:7KBNXuMnKTx6g:15502:0:99999:7:::</pre>
<p>The oldschool descrypt password is trivially broken, the password is ‚Äúmedia‚Äù.</p>
<ul>
<li>/usr/bin/shd ‚Äì the main server application</li>
<li>/usr/bin/shdTester ‚Äì client for energy monitor calibration</li>
<li>/usr/bin/calDump ‚Äì dumps wifi calibration data from /dev/caldata</li>
</ul>
<p>All proprietary server logic is contained in the shd (‚ÄúSmart Home Daemon‚Äù) binary, which is <code>MIPS32 R2 Big Endian</code>:</p>
<pre>shd: ELF 32-bit MSB executable, MIPS, MIPS32 rel2 version 1 (SYSV), 
dynamically linked, interpreter /lib/ld-uClibc.so.0, corrupted section header size
</pre>
<p>The shd binary also contains a copy of <code>OpenSSL 1.0.1j 15 Oct 2014</code> for establishing TLS connections to the cloud server.<br>
We load the shd binary into IDA and start analyzing!</p>
<p><strong id="Busybox">4. Busybox</strong> <a href="#nav"></a></p>
<p>The Busybox version provided in the firmware is vulnerable to <a href="https://web.nvd.nist.gov/view/vuln/detail?vulnId=CVE-2011-2716" target="_blank" rel="noopener noreferrer">CVE-2011-2716</a>, a command injection vulnerability in the udhcpc DHCP client component of Busybox, which allows to inject shell commands into one of the following DHCP options: (12) Hostname, (15) Domainname, (40) NIS Domain or (66) TFTP Server Name. For this to work, those values have to be actually used by the shell script invoking udhcpc. Analyzing the firmware we find that the shd binary creates a shell script <code>/tmp/udhcpc.script</code> containing:</p>
<pre>#!/bin/sh
if[ $1 = renew ‚Äìo $1 = bound]
then
    ifconfig $interface $ip netmask $subnet
    route del default
    route add default gw $router
   echo "nameserver $dns" &gt; /tmp/resolv.conf
fi
</pre>
<p>It then executes udhcpc:</p>
<pre>/sbin/udhcpc ‚Äìb ‚ÄìH "HS100(US)" ‚Äìi br0 ‚Äìs /tmp/udhcpc.script
</pre>
<p>As we can see, the hostname is hardcoded and none of the other options are used. Unfortunately, the udhcpc vulnerability is not exploitable in this case.</p>
<p><strong id="Portscan">5. Portscan</strong> <a href="#nav"></a></p>
<p>An nmap port scan on all TCP and UDP ports reveals the following:</p>
<table>
<thead>
<tr>
<th><strong>Port</strong></th>
<th><strong>Protocol</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td>80/tcp</td>
<td>HTTP</td>
</tr>
<tr>
<td>9999/tcp</td>
<td>TP-Link Smart Home Protocol</td>
</tr>
<tr>
<td>1040/udp</td>
<td>TP-Link Device Debug Protocol (TDDP)</td>
</tr>
</tbody>
</table>
<p>The Webserver on Port <code>80</code> replies with a meaningless ellipsis, no matter what the request is:</p>
<pre>HTTP/1.1 200 OK
Server: TP-LINK Smart Plug
Connection: close
Content-Length: 5
Content-Type: text/html

‚Ä¶
</pre>
<p>Looking through the shd binary we see that the HTTP Server routine is called ‚Äú<code>fake_httpd</code>‚Äù and will always return this hardcoded reply.</p>
<p>Port <code>9999 TCP</code> is used for controlling the Smart Plug on the local network via the Kasa app and is described in the <a href="#TP-Link Smart Home Protocol">TP-Link Smart Home Protocol section</a>. Port <code>1040 UDP</code> is described in the <a href="#TP-Link Device Debug Protocol">TP-Link Device Debug Protocol section</a>.</p>
<p><strong id="TP-Link Smart Home Protocol">6. TP-Link Smart Home Protocol</strong> <a href="#nav"></a></p>
<p>Sniffing the local wireless network traffic reveals that the TP-Link Kasa SmartHome app talks to the HS110 Smart Plug on TCP port 9999 using what looks like encrypted data.</p>
<p>After decompiling the Kasa app for Android, we find the encryption function:</p>
<p><img src="https://www.softscheck.com/assets/img/blog/tphome-encryption-1.png" alt="hs110 tphome-encryption"></p>
<p>We see the initial key (initialization vector) i has a hardcoded value of <code>-85 (= 171)</code>. The first byte of the plaintext is <code>XORed</code> with the key. The key is then set to the plaintext byte. During the next iteration, the next plaintext byte is <code>XORed</code> with the previous plaintext byte. Decryption works the same, with the keystream made out of cyphertext bytes. This is known as an <a href="https://en.wikipedia.org/wiki/Autokey_cipher" target="_blank" rel="noopener noreferrer">autokey cipher</a> and while it has better statistical properties than simple XOR encryption with a repeating key, it can be easily broken by known plaintext attacks.</p>
<p>Now that we know the algorithm and the key, we implement a Wireshark dissector in LUA which automatically decrypts TP-Link Smart Home packets on port <code>9999</code>. It turns out that the protocol uses JSON, so we also pass the decrypted contents to the JSON dissector. We can now monitor communications between the Kasa app and the Smart Plug on the local WiFi:</p>
<p><a href="https://www.softscheck.com/assets/img/blog/wireshark-dissector-1.png" target="_blank" rel="noopener noreferrer"><img src="https://www.softscheck.com/assets/img/blog/wireshark-dissector-1.png" alt="wireshark-dissector"></a></p>
<p>&nbsp;<br>
The Smart Plug commands are grouped into the following categories:</p>
<ul>
<li>system</li>
<li>netif (WLAN interface commands)</li>
<li>cnCloud (cloud connection)</li>
<li>time</li>
<li>emeter (energy meter)</li>
<li>schedule (scheduled on/off)</li>
<li>count_down (countdown on/off)</li>
<li>anti_theft (random scheduled on/off)</li>
</ul>
<p>We provide a comprehensive list of JSON commands (<a href="https://github.com/softScheck/tplink-smartplug/blob/master/tplink-smarthome-commands.txt" target="_blank" rel="noopener noreferrer">tplink-smarthome-commands.txt</a>) and a python client to send them with (<a href="https://github.com/softScheck/tplink-smartplug/blob/master/tplink_smartplug.py" target="_blank" rel="noopener noreferrer">tplink_smartplug.py</a>).</p>
<p><strong>System Commands</strong></p>
<p>We can read out information about the system using the <code>get_sysinfo</code> command:</p>
<pre>{"system":{"get_sysinfo":{}}}</pre>
<p>To send the command using our python client, invoke it with the <code>‚Äìc</code> info option:</p>
<pre>./tplink_smartplug.py ‚Äìt 192.168.0.1 ‚Äìc info</pre>
<p>We provide several predefined commands to read out information from the HS110 Smart Plug using <code>‚Äìc</code> options.<br>
Alternatively, you can use the <code>‚Äìj</code> option and provide the full JSON string:</p>
<pre>./tplink_smartplug.py ‚Äìt 192.168.0.1 ‚Äìj '{"system":{"get_sysinfo":{}}}'</pre>
<p>This allows to send any of the commands listed in <code>tplink-smarthome-commands.txt</code>.<br>
The <code>get_sysinfo</code> reply will contain the following information:</p>
<p><a href="https://www.softscheck.com/assets/img/blog/sysinfo.png" target="_blank" rel="noopener noreferrer"><img src="https://www.softscheck.com/assets/img/blog/sysinfo.png" alt="hs110 sysinfo"></a></p>
<p>&nbsp;<br>
We can turn the HS110 Smart Plug on and off using the <code>set_relay_state</code> command, using <code>1</code> for on and <code>0</code> for off:</p>
<pre>{‚Äúsystem":{"set_relay_state":{"state":1}}}</pre>
<p>We can reboot the HS110 Smart Plug using the <code>reboot</code> command which requires a <code>delay</code> parameter in seconds:</p>
<pre>{"system":{"reboot":{"delay":1}}}</pre>
<p>The HS110 Smart Plug can be reset to factory settings, making it act as an open Access Point again:</p>
<pre>{"system":{"reset":{"delay":1}}}</pre>
<p>Note that since the protocol does not provide authentication, anybody on your network can send this command and force a reset. Here, a prankster would set a high delay value, giving them time to leave the premises.</p>
<p>There are further commands to change the MAC address, change the Device and Hardware IDs, turn off the device LED (night mode) etc.</p>
<p>Of special interest are the firmware flashing commands. You can download a&nbsp; firmware file from an arbitrary URL using:</p>
<pre>{"system":{"download_firmware":{"url":"http://..."}}}</pre>
<p>While downloading, you can get the download state using:</p>
<pre>{"system":{"get_download_state":{}}}</pre>
<p>Once the download is finished, you can flash the firmware using:</p>
<pre>{"system":{"flash_firmware":{}}}</pre>
<p>Flashing a modified image will not work since the image‚Äôs signature has to match one of four hardcoded RSA keys (we won‚Äôt go into wild speculations why there are four keys here):</p>
<p><a href="https://www.softscheck.com/assets/img/blog/checkfirmware2-1.png" target="_blank" rel="noopener noreferrer"><img src="https://www.softscheck.com/assets/img/blog/checkfirmware2-1.png" alt="hs110 checkfirmware2"></a></p>
<p>&nbsp;<br>
<strong>WiFi Commands</strong></p>
<p>You can instruct the ‚Ä¶</p></div></div></div></article></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.softscheck.com/en/reverse-engineering-tp-link-hs110/">https://www.softscheck.com/en/reverse-engineering-tp-link-hs110/</a></em></p>]]>
            </description>
            <link>https://www.softscheck.com/en/reverse-engineering-tp-link-hs110/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25393505</guid>
            <pubDate>Sat, 12 Dec 2020 00:05:04 GMT</pubDate>
        </item>
    </channel>
</rss>
