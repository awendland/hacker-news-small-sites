<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" version="2.0">
    <channel>
        <title>
<![CDATA[Hacker News - Small Sites - Score >= 20]]>
        </title>
        <description>
<![CDATA[Hacker News stories from domains that aren't in the top 1M and that have a score of at least 20. Updated nightly via https://github.com/awendland/hacker-news-small-sites]]>
        </description>
        <link>https://news.ycombinator.com</link>
        <generator>RSS for Node</generator>
        <lastBuildDate>Fri, 28 Aug 2020 12:31:10 GMT</lastBuildDate>
        <atom:link href="https://raw.githubusercontent.com/awendland/hacker-news-small-sites/generated/feeds/hn-small-sites-score-20.xml" rel="self" type="application/rss+xml"></atom:link>
        <pubDate>Fri, 28 Aug 2020 12:31:10 GMT</pubDate>
        <language>
<![CDATA[en-US]]>
        </language>
        <managingEditor>
<![CDATA[me@alexwendland.com (Alex Wendland)]]>
        </managingEditor>
        <ttl>240</ttl>
        <item>
            <title>
<![CDATA[YC Software Startups: Value and Initial Programming Language Used]]>
            </title>
            <description>
<![CDATA[
Score 62 | Comments 63 (<a href="https://news.ycombinator.com/item?id=24279611">thread link</a>) | @charliereese
<br/>
August 25, 2020 | https://charliereese.ca/article/top-50-y-combinator-tech-startups | <a href="https://web.archive.org/web/*/https://charliereese.ca/article/top-50-y-combinator-tech-startups">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>

			<div>

				<p>This article contains a list of the top 50 YC software startups (sourced from the October 2019 <a href="https://www.ycombinator.com/topcompanies/">YC Top Companies</a> page). It also contains aggregated statistics for valuations and back-end programming languages used.</p>
<p>Values in this article are sourced, but I cannot guarantee their accuracy.</p>
<p>Follow me on Twitter <a href="https://twitter.com/charlieinthe6">@charlieinthe6</a> for similar content. <a href="https://news.ycombinator.com/item?id=24279611">View article comments on HackerNews</a>.</p>
<p>☕</p>
<p><strong>Table of Contents:</strong></p>
<ol>
<li><a href="#top-50">Top 50 Software Startups</a></li>
<li><a href="#stats">Aggregated Stats</a></li>
</ol>
<h3 id="top-50">1. Top 50 Software Startups:</h3>
<table>
<thead>
<tr>
<th>Company</th>
<th>Latest val ($MM)</th>
<th>Initial back-end language(s)</th>
<th>DataSci / LowLv</th>
</tr>
</thead>
<tbody>
<tr>
<td><a href="https://stripe.com/">Stripe</a>: <br>Payment / economic infrastructure for internet</td>
<td>36,000 <small> <a href="https://detroit.cbslocal.com/2020/08/11/general-motors-cfo-exits-suddenly-for-silicon-valley/">source</a> </small></td>
<td>Ruby <small> <a href="https://qr.ae/pN2pJk">source</a> </small></td>
<td>N / N</td>
</tr>
<tr>
<td><a href="https://getcruise.com/">Cruise</a>: <br>Building self-driving car tech</td>
<td>19,000 <small> <a href="https://www.thedrive.com/tech/27872/gm-cruise-divisions-new-1b-investment-sets-valuation-at-staggering-19b">source</a> </small></td>
<td>C++, Python <small> <a href="https://angel.co/company/cruise-automation/jobs/757823-staff-deep-learning-optimization-engineer">source</a>, <a href="https://angel.co/company/cruise-automation/jobs/841627-staff-software-engineer-c-frameworks">source</a> </small></td>
<td>Y / N</td>
</tr>
<tr>
<td><a href="https://airbnb.com/">Airbnb</a>: <br>Marketplace to rent someone’s room</td>
<td>18,000 <small> <a href="https://sanfrancisco.cbslocal.com/2020/08/11/airbnb-ipo-reportedly-close-to-filing-wsj/">source</a> </small></td>
<td>Ruby <small> <a href="https://www.forbes.com/sites/quora/2018/02/20/what-technology-stack-does-airbnb-use/#448ff4184025">source</a> </small></td>
<td>N / N</td>
</tr>
<tr>
<td><a href="https://doordash.com/">DoorDash</a>: <br>Food delivery</td>
<td>16,000 <small> <a href="https://www.cnn.com/2020/06/18/tech/doordash-funding-valuation/index.html">source</a> </small></td>
<td>Python <small> <a href="https://medium.com/@DoorDash/implementing-rest-apis-with-embedded-privacy-a2394dc4dceb">source</a> </small></td>
<td>N / N</td>
</tr>
<tr>
<td><a href="https://twitch.tv/">Twitch</a>: <br>Gaming video platform / community</td>
<td>15,000 <small> <a href="https://www.cnbc.com/2020/06/16/amazon-media-assets-worth-500-billion-almost-as-much-as-aws-needham.html#:~:text=To%20get%20to%20%24500%20billion,business%20is%20at%20%243.8%20billion.">source</a> </small></td>
<td>C++, Ruby <small> <a href="https://blog.twitch.tv/en/2015/12/18/twitch-engineering-an-introduction-and-overview-a23917b71a25/">source</a> (founded before Go)</small></td>
<td>N / Y</td>
</tr>
<tr>
<td><a href="https://instacart.com/">Instacart</a>: <br>Grocery pick-up / delivery</td>
<td>13,700 <small> <a href="https://techcrunch.com/2020/06/11/instacart-raises-225-million-at-13-7-billion-valuation/">source</a> </small></td>
<td>Ruby <small> <a href="https://stackshare.io/posts/the-tech-behind-instacarts-grocery-delivery-service">source</a> </small></td>
<td>N / N</td>
</tr>
<tr>
<td><a href="https://dropbox.com/">Dropbox</a>: <br>File hosting / syncing</td>
<td>8000 (market cap @ Aug 2020) <small> <a href="https://finance.yahoo.com/quote/DBX?p=DBX">source</a> </small></td>
<td>Python <small> <a href="https://eranki.tumblr.com/post/27076431887/scaling-lessons-learned-at-dropbox-part-1">source</a> </small></td>
<td>N / Y</td>
</tr>
<tr>
<td><a href="https://coinbase.com/">Coinbase</a>: <br>Cryptocurrency exchange</td>
<td>8,000 <small> <a href="https://www.coindesk.com/coinbase-existing-valuation-doesnt-need-ipo-lawyer-says">source</a> </small></td>
<td>Ruby <small> <a href="https://blog.coinbase.com/scaling-connections-with-ruby-and-mongodb-99204dbf8857">source</a> </small></td>
<td>N / N</td>
</tr>
<tr>
<td><a href="https://gusto.com/">Gusto</a>: <br>Employee payroll and benefits</td>
<td>3,800 <small> <a href="https://www.forbes.com/sites/donnafuscaldo/2019/07/24/gusto-amasses-3-8-billion-valuation-with-latest-fundraising-round/#50e7fa8d2820">source</a> </small></td>
<td>Ruby <small> <a href="https://boards.greenhouse.io/gusto/jobs/1337386?t=bae6d7cd1">source</a> </small></td>
<td>N / N</td>
</tr>
<tr>
<td><a href="https://rappi.com/">Rappi</a>: <br>On-demand delivery</td>
<td>3,500 <small> <a href="https://techcrunch.com/2020/04/08/ifood-merges-with-delivery-heros-domicilios-com-to-challenge-rappi-in-colombia/">source</a> </small></td>
<td>Go, Node, Python, Java <small> <a href="https://www.rappi.com/jobs/position-detail?id=b88ad33f-7ad5-4e3b-8ecb-f13a3cce3a6a&amp;lang=lang">source</a> (may have used PHP - no source)</small></td>
<td>N / N</td>
</tr>
<tr>
<td><a href="https://flexport.com/">Flexport</a>: <br>Freight forwarding platform</td>
<td>3,200 <small> <a href="https://www.joc.com/technology/wework-spanner-flexports-works_20191021.html">source</a> </small></td>
<td>Ruby <small> <a href="https://stackshare.io/posts/how-flexport-builds-software-to-move-over-1-billion-dollars-in-merchandise">source</a> </small></td>
<td>N / N</td>
</tr>
<tr>
<td><a href="https://reddit.com/">Reddit</a>: <br>Online network of communities</td>
<td>3,000 <small> <a href="https://techcrunch.com/2019/02/11/reddit-300-million/">source</a> </small></td>
<td>Lisp <small> <a href="http://www.aaronsw.com/weblog/rewritingreddit">source</a> </small></td>
<td>N / N</td>
</tr>
<tr>
<td><a href="https://about.gitlab.com/">GitLab</a>: <br>DevOps platform</td>
<td>2,750 <small> <a href="https://www.forbes.com/sites/alexkonrad/2019/09/17/gitlab-doubles-valuation-to-nearly-3-billion/#483591ce1794">source</a> </small></td>
<td>Ruby <small> <a href="https://about.gitlab.com/blog/2018/10/29/why-we-use-rails-to-build-gitlab/">source</a> </small></td>
<td>N / N</td>
</tr>
<tr>
<td><a href="https://brex.com/">Brex</a>: <br>Corporate credit cards</td>
<td>2,750 <small> <a href="https://techcrunch.com/2020/05/19/brex-brings-on-150m-in-new-cash-in-case-of-an-extended-recession/">source</a> </small></td>
<td>Elixir <small> <a href="https://medium.com/brexeng/why-brex-chose-elixir-fe1a4f313195">source</a> </small></td>
<td>N / N</td>
</tr>
<tr>
<td><a href="https://pagerduty.com/">PargerDuty</a>: <br>SaaS incident response platform</td>
<td>2,270 <small> <a href="https://www.google.com/search?tbm=fin&amp;q=NYSE:+PD&amp;stick=H4sIAAAAAAAAAONgecRowS3w8sc9YSn9SWtOXmPU5OIKzsgvd80rySypFJLmYoOyBKX4uXj10_UNDdOyCwszkotLeBaxcvhFBrtaKQS4AAASRGHASAAAAA&amp;sa=X&amp;ved=2ahUKEwjCtra68ZbrAhUYXc0KHdn_DoAQ3ecFMAB6BAhqEBc&amp;biw=1278&amp;bih=968#scso=_Z4c0X5TmCsjOtQbEu5zQAQ1:0">source</a> </small></td>
<td>Ruby <small> <a href="https://www.pagerduty.com/blog/elixir-at-pagerduty/">source</a> </small></td>
<td>N / N</td>
</tr>
<tr>
<td><a href="https://checkr.com/">Checkr</a>: <br>Background checks</td>
<td>2,200 <small> <a href="https://www.forbes.com/sites/bizcarson/2019/09/19/checkr-background-funding-round/#552c8c845460">source</a> </small></td>
<td>Ruby <small> <a href="https://engineering.checkr.com/yet-another-attempt-at-faster-builds-caching-db-schema-efe63d367f5">source</a> </small></td>
<td>N / N</td>
</tr>
<tr>
<td><a href="https://podium.com/">Podium</a>: <br>Interaction management platform</td>
<td>1,500 <small> <a href="https://techcrunch.com/2020/04/07/utahs-podium-raises-125m-series-c-led-by-yc-after-reaching-100m-arr/">source</a> </small></td>
<td>Ruby <small> <a href="https://devchat.tv/elixir-mix/emx-072-people-centered-solutions-with-travis-elnicky/">source</a> </small></td>
<td>N / N</td>
</tr>
<tr>
<td><a href="https://segment.com/">Segment</a>: <br>Customer data platform</td>
<td>1,500 <small> <a href="https://www.bloomberg.com/news/articles/2019-04-02/startup-segment-is-worth-1-5-billion-thanks-to-companies-troves-of-customer-data">source</a> </small></td>
<td>Go, JS <small> <a href="https://www.workatastartup.com/companies/88">source</a>, <a href="https://angel.co/company/segment/jobs/348613-senior-software-engineer">source</a> </small></td>
<td>N / N</td>
</tr>
<tr>
<td><a href="https://docker.com/">Docker</a>: <br>Build / deliver software in containers</td>
<td>1000 est. <small> <a href="https://techcrunch.com/2019/11/13/mirantis-acquires-docker-enterprise/">source</a>, <a href="https://techcrunch.com/2018/10/15/docker-has-raised-92-million-in-new-funding/">source</a> </small></td>
<td>Go <small> <a href="https://thenewstack.io/go-programming-language-helps-docker-container-ecosystem/">source</a>, <a href="https://techcrunch.com/2019/11/13/after-selling-enterprise-biz-docker-lands-35m-investment-and-new-ceo/">source</a> </small></td>
<td>N / Y</td>
</tr>
<tr>
<td><a href="https://scale.com/">Scale</a>: <br>Training / validation data for ML</td>
<td>1,000 <small> <a href="https://www.forbes.com/sites/stevenli1/2019/12/22/scale-ai-growth-story/#3360214b6f4a">source</a> </small></td>
<td>Python, JS <small> <a href="https://scale.com/careers/41e05b90-7e65-4dac-8676-50be9c1afc27">source</a>, <a href="https://scale.com/careers/37b0c485-cd77-4170-ac07-a8521b9a10fc">source</a> </small></td>
<td>Y / N</td>
</tr>
<tr>
<td><a href="https://amplitude.com/">Amplitude</a>: <br>Product / customer analytics</td>
<td>1,000 <small> <a href="https://www.forbes.com/sites/davidjeans/2020/05/20/amplitude-now-valued-1-billion-backed-sequoia-benchmark/#68a1ad2041c7">source</a> </small></td>
<td>Python, Java <small> <a href="https://news.ycombinator.com/item?id=13301832&amp;p=2">source</a> </small></td>
<td>Y / N</td>
</tr>
<tr>
<td><a href="https://zapier.com/">Zapier</a>: <br>Connect apps and automate workflows</td>
<td>1000 est. (20x 2018 ARR) <small> <a href="https://www.drift.com/blog/how-zapier-grew/">source</a> </small></td>
<td>Python <small> <a href="https://zapier.com/blog/zapier-tech-stack/">source</a> </small></td>
<td>N / N</td>
</tr>
<tr>
<td><a href="https://faire.com/">Faire</a>: <br>B2B wholesale marketplace</td>
<td>1,000 <small> <a href="https://www.forbes.com/sites/laurendebter/2019/10/30/faire-wholesale-marketplace-series-d-1-billion-valuation/#21c2bdfb7aa9">source</a> </small></td>
<td>Java <small> <a href="https://boards.greenhouse.io/faire/jobs/4187498002">source</a> </small></td>
<td>N / N</td>
</tr>
<tr>
<td><a href="https://plangrid.com/">PlanGrid</a>: <br>Construction software</td>
<td>875 <small> <a href="https://techcrunch.com/2018/11/20/autodesk-agrees-to-buy-plangrid-for-875-million/#:~:text=Autodesk%20announced%20plans%20to%20acquire%20PlanGrid%20for%20%24875%20million%20today.">source</a> </small></td>
<td>Python <small> <a href="https://stackoverflow.com/jobs/companies/plangrid">source</a> </small></td>
<td>N / N</td>
</tr>
<tr>
<td><a href="https://mixpanel.com/">Mixpanel</a>: <br>User analytics</td>
<td>865 <small> <a href="https://www.forbes.com/pictures/feki45efhmk/mixpanel/#71dc3892190f">source</a> </small></td>
<td>Python<small> <a href="https://boards.greenhouse.io/mixpanel/jobs/1545756?gh_jid=1545756">source</a> (founded before Go)</small></td>
<td>Y / N</td>
</tr>
<tr>
<td><a href="https://benchling.com/">Benchling</a>: <br>Biotech research</td>
<td>850 <small> <a href="https://www.forbes.com/sites/amyfeldman/2020/05/28/biotech-rd-software-startup-benchling-started-by-mit-undergrads-scores-850-million-valuation-amid-coronavirus-pandemic/#5de0e0c61dcd">source</a> </small></td>
<td>Python <small> <a href="https://www.workatastartup.com/companies/445">source</a> </small></td>
<td>Y / N</td>
</tr>
<tr>
<td><a href="https://meesho.com/">Meesho</a>: <br>Social commerce platform</td>
<td>700 <small> <a href="https://economictimes.indiatimes.com/small-biz/startups/newsbuzz/meesho-raised-125-mn-from-naspers-and-others/articleshow/70641492.cms">source</a> </small></td>
<td>Java <small> <a href="https://angel.co/company/meesho/jobs/596045-software-development-engineer-iii">source</a> </small></td>
<td>N / N</td>
</tr>
<tr>
<td><a href="https://optimizely.com/">Optimizely</a>: <br>Digital experience optimization / testing</td>
<td>600 <small> <a href="https://pitchbook.com/newsletter/optimizely-brings-in-50m#:~:text=Optimizely%2C%20which%20operates%20an%20optimization,with%20participation%20from%20Accenture%20Ventures">source</a> </small></td>
<td>Python <small> <a href="https://news.ycombinator.com/item?id=2647003">source</a> </small></td>
<td>Y / N</td>
</tr>
<tr>
<td><a href="https://algolia.com/">Algolia</a>: <br>Search service</td>
<td>578 <small> <a href="https://www.bizjournals.com/sanfrancisco/news/2019/10/15/fast-growing-san-francisco-search-company-scores.html">source</a> </small></td>
<td>C++, Ruby <small> <a href="https://www.algolia.com/doc/faq/why/what-architecture-does-algolia-use-to-provide-an-high-performance-search-engine/">source</a>, <a href="https://stackshare.io/posts/how-algolia-built-their-realtime-search-as-a-service-product">source</a> </small></td>
<td>N / Y</td>
</tr>
<tr>
<td><a href="https://goat.com/">Goat</a>: <br>Sneaker marketplace</td>
<td>550 <small> <a href="https://www.forbes.com/sites/kurtbadenhausen/2019/02/07/foot-locker-invests-100-million-in-secondary-sneaker-firm-goat/#3b07b65e568d">source</a> </small></td>
<td>Ruby <small> <a href="https://www.workatastartup.com/jobs/20990">source</a> </small></td>
<td>N / N</td>
</tr>
<tr>
<td><a href="https://standard.ai/">StandardCognition</a>: <br>Autonomous checkout</td>
<td>535 <small> <a href="https://techcrunch.com/2019/07/25/standard-cognition-lands-35m-at-535m-valuation-to-battle-amazon-go/">source</a> </small></td>
<td>Python <small> <a href="https://jobs.lever.co/standard/9b874041-7cfe-4e0a-a459-fcd66451ee75">source</a> </small></td>
<td>Y / N</td>
</tr>
<tr>
<td><a href="https://people.ai/">People.ai</a>: <br>Intelligent CRM</td>
<td>500 <small> <a href="https://techcrunch.com/2019/05/21/people-ai-the-predictive-sales-startup-raises-60m-at-around-500m-valuation/#:~:text=People.ai%2C%20the%20predictive%20sales,around%20%24500M%20valuation%20%7C%20TechCrunch">source</a> </small></td>
<td>Python <small> <a href="https://www.workatastartup.com/companies/1299">source</a>, <a href="https://news.ycombinator.com/item?id=16974829">source</a> </small></td>
<td>Y / N</td>
</tr>
<tr>
<td><a href="https://razorpay.com/">Razorpay</a>: <br>Digital payments</td>
<td>450 <small> <a href="https://www.pymnts.com/news/investment-tracker/2019/razorpay-sequoia-india-ribbit-capital/#:~:text=With%20the%20funding%2C%20Razorpay%20is,Razorpay%20X%20neo%2Dbanking%20platform.">source</a> </small></td>
<td>PHP <small> <a href="https://news.ycombinator.com/item?id=12407955">source</a> </small></td>
<td>N / N</td>
</tr>
<tr>
<td><a href="https://equipmentshare.com/">EquipmentShare</a>: <br>Equipment rentals</td>
<td>400 est. <small> <a href="https://www.forbes.com/sites/alexkonrad/2019/11/18/softbank-looks-to-invest-equipmentshare-unicorn/#48a6b2d779b8">source</a> </small></td>
<td>Python <small> <a href="https://news.ycombinator.com/item?id=16492994&amp;p=2">source</a> </small></td>
<td>N / N</td>
</tr>
<tr>
<td><a href="https://weebly.com/">Weebly</a>: <br>Website builder</td>
<td>365 <small> <a href="https://techcrunch.com/2018/04/26/square-acquires-weebly/">source</a> </small></td>
<td>PHP <small> <a href="https://news.ycombinator.com/item?id=2839742">source</a>, <a href="https://news.ycombinator.com/item?id=5729035">source</a> </small></td>
<td>N / N</td>
</tr>
<tr>
<td><a href="https://webflow.com/">Webflow</a>: <br>Website builder</td>
<td>350 <small> <a href="https://growthhackers.com/articles/how-webflow-quietly-grew-without-vc-money?r=latest">source</a> </small></td>
<td>JS <small> <a href="https://boards.greenhouse.io/webflow/jobs/1838218">source</a>, <a href="https://www.workatastartup.com/companies/566">source</a> </small></td>
<td>N / N</td>
</tr>
<tr>
<td><a href="https://matterport.com/">Matterport</a>: <br>3D technology platform</td>
<td>325 <small> <a href="https://techcrunch.com/2019/03/05/matterport-2/#:~:text=Matterport%20had%20raised%20just%20under,DCM%2C%20Qualcomm%20Ventures%20and%20more.">source</a> </small></td>
<td>C++ <small> <a href="https://news.ycombinator.com/item?id=3300290">source</a>, <a href="https://news.ycombinator.com/item?id=5186626">source</a> </small></td>
<td>N / Y</td>
</tr>
<tr>
<td><a href="https://influxdata.com/">InfluxData</a>: <br>InfluxDB creator</td>
<td>300 est. <small> <a href="https://www.crunchbase.com/organization/influxdb/company_financials">source</a> </small></td>
<td>Go <small> <a href="https://github.com/influxdata/influxdb">source</a> </small></td>
<td>N / Y</td>
</tr>
<tr>
<td><a href="https://embarktrucks.com/">Embark</a>: <br>Self-driving trucks</td>
<td>300 est. <small> <a href="https://www.crunchbase.com/organization/embark-trucks/company_financials">source</a> </small></td>
<td>Python, C++ <small> <a href="https://jobs.lever.co/embark/25999d12-5d82-45fc-b3e4-0ebc335f6f59">source</a> </small></td>
<td>Y / Y</td>
</tr>
<tr>
<td><a href="https://sendbird.com/">SendBird</a>: <br>Chat / calls as a service</td>
<td>300 est. <small> <a href="https://www.crunchbase.com/organization/sendbird/company_financials">source</a> </small></td>
<td>Python <small> <a href="https://sendbird.com/careers/4317963002">source</a> </small></td>
<td>N / N</td>
</tr>
<tr>
<td><a href="https://rescale.com/">Rescale</a>: <br>Cloud simulation platform</td>
<td>300 est. <small> <a href="https://www.crunchbase.com/organization/rescale/company_financials">source</a> </small></td>
<td>Java, Python <small> <a href="https://news.ycombinator.com/item?id=5828217">source</a> </small></td>
<td>Y / N</td>
</tr>
<tr>
<td><a href="https://gocardless.com/">GoCardless</a>: <br>Direct debit payments</td>
<td>300 est. <small> <a href="https://www.crunchbase.com/organization/gocardless/company_financials">source</a> </small></td>
<td>Ruby <small> <a href="https://news.ycombinator.com/item?id=14978103">source</a>, <a href="https://news.ycombinator.com/item?id=16283469">source</a>, <a href="https://news.ycombinator.com/item?id=4596703">source</a>, <a href="https://boards.greenhouse.io/gocardless/jobs/2282283">source</a> </small></td>
<td>N / N</td>
</tr>
<tr>
<td><a href="https://rigetti.com/">Rigetti Computing</a>: <br>Quantum computing</td>
<td>300 est. <small> <a href="https://www.crunchbase.com/organization/rigetti-computing/company_financials">source</a> </small></td>
<td>Python, Lisp, C <small> <a href="https://news.ycombinator.com/item?id=16968407">source</a> </small></td>
<td>Y / Y</td>
</tr>
<tr>
<td><a href="https://messagebird.com/">MessageBird</a>: <br>Omnichannel customer communication</td>
<td>300 <small> <a href="https://www.fool.com/investing/2020/03/13/twilio-investors-keep-tabs-on-startup-messagebird.aspx">source</a> </small></td>
<td>Go, PHP, Python, Java <small> <a href="https://careers.sh/uk/kompaniya/messagebird/robochi-mistsya/71009">source</a> </small></td>
<td>N / N</td>
</tr>
<tr>
<td><a href="https://ironcladapp.com/">Ironclad</a>: <br>Digital contracting platform</td>
<td>300 est. <small> <a href="https://www.crunchbase.com/organization/ironclad/company_financials">source</a> </small></td>
<td>JS, Java <small> <a href="https://jobs.lever.co/ironcladapp/2d6616e3-27b8-4138-a6fc-238e46757822">source</a> </small></td>
<td>N / N</td>
</tr>
<tr>
<td><a href="https://sift.com/">Sift</a>: <br>Digital safety and fraud detection</td>
<td>300 est. <small> <a href="https://www.crunchbase.com/organization/sift-science/company_financials">source</a> </small></td>
<td>Java, Ruby <small> <a href="https://news.ycombinator.com/item?id=6657091">source</a> </small></td>
<td>Y / N</td>
</tr>
<tr>
<td><a href="https://mattermost.com/">Mattermost</a>: <br>Open source Slack alternative</td>
<td>250 est. <small> <a href="https://app.dealroom.co/companies/mattermost">source</a> </small></td>
<td>Go <small> <a href="https://github.com/mattermost/mattermost-server">source</a> </small></td>
<td>N / N</td>
</tr>
<tr>
<td><a href="https://xendit.co/">Xendit</a>: <br>Digital payments</td>
<td>150 est. <small> <a href="https://www.ycombinator.com/topcompanies/">source</a> </small></td>
<td>JS <small> <a href="https://www.workatastartup.com/companies/938">source</a>, <a href="https://www.xendit.co/en/careers/job-application/?gh_jid=4114942003">source</a> </small></td>
<td>N / N</td>
</tr>
<tr>
<td><a href="https://easypost.com/">EasyPost</a>: <br>Logistics software</td>
<td>150 est. <small> <a href="https://www.ycombinator.com/topcompanies/">source</a> </small></td>
<td>Ruby <small> <a href="https://news.ycombinator.com/item?id=6231587">source</a>, <a href="https://news.ycombinator.com/item?id=13542390">source</a>, <a href="https://www.linkedin.com/jobs/view/senior-software-engineer-at-easypost-1669977835/">source</a> </small></td>
<td>N / N</td>
</tr>
<tr>
<td><a href="https://newfrontinsurance.com/">Newfront</a>: <br>Insurance platform</td>
<td>150 est. <small> <a href="https://www.ycombinator.com/topcompanies/">source</a> </small></td>
<td>JS, Go <small> <a href="https://www.keyvalues.com/newfront">source</a>, <a href="https://news.ycombinator.com/item?id=21683554">source</a> </small></td>
<td>N / N</td>
</tr>
</tbody>
</table>
<p><small>
<p>Note: Ginkgo Bioworks, Boom Supersonic, Grin, Memebox, Helion Energy, North, RelativitySpace, and The Athletic were excluded from the below list; I didn't feel they were primarily software businesses. Feel free to disagree with my judgement.</p>
<p>Note: values current as of August 15, 2020.</p>
<p>Note: if one language was the primary language used to build the initial product, one language is listed above. If it was not clear which language was primary, multiple languages are listed above.</p>
<p>Note: if I couldn't find which language was used to build the startup initially, I referenced the oldest job posting I could find.</p>
<p>Note: valuations are approximate and predominantly sourced from recent articles online. Where I couldn't find an indication of value, ~$150M is assumed; startups listed above were all worth +$150M as of October 2019, as per the <a href="https://www.ycombinator.com/topcompanies/">YC Top Companies</a> page.</p>
<p>Note: "Y" and "N" values in the "DataSci / LowLv" column describe a startup's primary product (i.e. ML startups would have a "Y" for DataSci). It was included to provide additional colour on why initial back-end language(s) may have been used / selected. The values in this column are based entirely on my own judgement. Feel free to disagree with them or ignore them.</p>
<p>Note: Ruby and ruby on rails was a popular choice for YC startups around 2010 - 2012. Anecdotally, ~40% of YC startups used ruby during its peak popularity.</p>
</small></p>

<h3 id="stats">2. Aggregated Stats:</h3>

<p><strong>Startups with one (initial) primary back-end language:</strong> </p>
<table>
<thead>
<tr>
<th>Language</th>
<th>Count</th>
<th>Total Valuation ($BN)</th>
</tr>
</thead>
<tbody>
<tr>
<td>All</td>
<td>35 (70%)</td>
<td>132.1 (75%)</td>
</tr>
<tr>
<td>Ruby</td>
<td>13 (26%)</td>
<td>92.4 (52%)</td>
</tr>
<tr>
<td>Python</td>
<td>11 (22%)</td>
<td>29.9 (17%)</td>
</tr>
<tr>
<td>Lisp</td>
<td>1 (2%)</td>
<td>3.0 (2%)</td>
</tr>
<tr>
<td>Elixir</td>
<td>1 (2%)</td>
<td>2.8 (2%)</td>
</tr>
<tr>
<td>Java</td>
<td>2 (4%)</td>
<td>1.7 (1%)</td>
</tr>
<tr>
<td>Go</td>
<td>3 (6%)</td>
<td>1.6 (1%)</td>
</tr>
<tr>
<td>PHP</td>
<td>2 (4%)</td>
<td>0.8 (0%)</td>
</tr>
<tr>
<td>JS</td>
<td>2 (4%)</td>
<td>0.5 (0%)</td>
</tr>
<tr>
<td>C++</td>
<td>1 (2%)</td>
<td>0.3 (0%)</td>
</tr>
</tbody>
</table>

<p><strong>Startups with multiple (initial) primary back-end languages:</strong> </p>
<table>
<thead>
<tr>
<th>Language</th>
<th>Count</th>
<th>Total Valuation ($BN)</th>
</tr>
</thead>
<tbody>
<tr>
<td>All</td>
<td>15 (30%)</td>
<td>44.4 (25%)</td>
</tr>
<tr>
<td>C++ is one</td>
<td>4 (8%)</td>
<td>34.9 (20%)</td>
</tr>
<tr>
<td>Python is one</td>
<td>8 (16%)</td>
<td>25.7 (15%)</td>
</tr>
<tr>
<td>Ruby is one</td>
<td>3 (6%)</td>
<td>15.9 (9%)</td>
</tr>
<tr>
<td>JS is one</td>
<td>5 (10%)</td>
<td>6.5 (4%)</td>
</tr>
<tr>
<td>Java is one</td>
<td>6 (12%)</td>
<td>5.7 (3%)</td>
</tr>
<tr>
<td>Go is one</td>
<td>4 (8%)</td>
<td>5.5 (3%)</td>
</tr>
<tr>
<td>Lisp is one</td>
<td>1 (2%)</td>
<td>0.3 (0%)</td>
</tr>
<tr>
<td>C is one</td>
<td>1 (2%)</td>
<td>0.3 (0%)</td>
</tr>
<tr>
<td>PHP is one</td>
<td>1 (2%)</td>
<td>0.3 (0%)</td>
</tr>
</tbody>
</table>
<p><small>Note: "Startups with multiple (initial) primary back-end languages" table doesn't add to 100% because multiple languages were used for startups.</small></p>

<p><strong>All startups:</strong> </p>
<table>
<thead>
<tr>
<th>Language</th>
<th>Count</th>
<th>Total Valuation ($BN)</th>
</tr>
</thead>
<tbody>
<tr>
<td>All</td>
<td>50 (100%)</td>
<td>176.5 (100%)</td>
</tr>
<tr>
<td>Ruby is one</td>
<td>16 (32%)</td>
<td>108.3 (61%)</td>
</tr>
<tr>
<td>Python is one</td>
<td>19 (38%)</td>
<td>55.6 (32%)</td>
</tr>
<tr>
<td>C++ is one</td>
<td>5 (10%)</td>
<td>35.2 (20%)</td>
</tr>
<tr>
<td>Java is one</td>
<td>8 (16%)</td>
<td>7.4 (4%)</td>
</tr>
<tr>
<td>Go is one</td>
<td>7 (14%)</td>
<td>7.0 (4%)</td>
</tr>
<tr>
<td>JS is one</td>
<td>7 (14%)</td>
<td>7.0 (4%)</td>
</tr>
<tr>
<td>Lisp is one</td>
<td>2 (4%)</td>
<td>3.3 (2%)</td>
</tr>
<tr>
<td>Elixir is one</td>
<td>1 (2%)</td>
<td>2.8 (2%)</td>
</tr>
<tr>
<td>PHP is one</td>
<td>3 (6%)</td>
<td>1.1 (1%)</td>
</tr>
<tr>
<td>C is one</td>
<td>1 (2%)</td>
<td>0.3 (0%)</td>
</tr>
</tbody>
</table>
<p><small>Note: "All startups" table doesn't add to 100% because multiple languages were used for some startups.</small></p>
				
			</div>

		</article></div>]]>
            </description>
            <link>https://charliereese.ca/article/top-50-y-combinator-tech-startups</link>
            <guid isPermaLink="false">hacker-news-small-sites-24279611</guid>
            <pubDate>Wed, 26 Aug 2020 06:03:02 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[PCI Express Retimers vs. Redrivers: An Eye-Popping Difference (2019)]]>
            </title>
            <description>
<![CDATA[
Score 84 | Comments 19 (<a href="https://news.ycombinator.com/item?id=24278760">thread link</a>) | @tragiclos
<br/>
August 25, 2020 | https://www.asteralabs.com/2019/06/26/pci-express-retimers-vs-redrivers-an-eye-popping-difference/ | <a href="https://web.archive.org/web/*/https://www.asteralabs.com/2019/06/26/pci-express-retimers-vs-redrivers-an-eye-popping-difference/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><p>Retimers and redrivers have enabled longer physical channels in servers and storage systems since Peripheral Component Interface Express (PCIe) 3.0 was first introduced almost 10 years ago. Now that PCIe 4.0 is ramping up and PCIe 5.0 is just around the corner, how do these reach extension tools stack up in the face of new challenges in high-speed connectivity?</p>
<p>A redriver is a mostly analog reach extension device designed to boost the high-frequency portions of a signal to counteract the frequency-dependent attenuation caused by the interconnect: the central processing unit (CPU) package, system board, connectors and so on. A redriver’s data path typically includes a continuous time linear equalizer (CTLE), a wideband gain stage and a linear driver. In addition, redrivers often have input loss-of-signal threshold and output receiver (Rx) detection capability. Figure 1 illustrates a typical redriver block diagram.</p>
<p><a href="https://www.intel.com/content/dam/www/public/us/en/documents/white-papers/serial-bus-white-paper.pdf" target="_blank" rel="noopener noreferrer"><img src="https://www.asteralabs.com/wp-content/uploads/2020/02/red-river-block.jpg" alt="" width="731" height="419" srcset="https://www.asteralabs.com/wp-content/uploads/2020/02/red-river-block.jpg 731w, https://www.asteralabs.com/wp-content/uploads/2020/02/red-river-block-300x172.jpg 300w, https://www.asteralabs.com/wp-content/uploads/2020/02/red-river-block-260x150.jpg 260w, https://www.asteralabs.com/wp-content/uploads/2020/02/red-river-block-523x300.jpg 523w, https://www.asteralabs.com/wp-content/uploads/2020/02/red-river-block-200x115.jpg 200w, https://www.asteralabs.com/wp-content/uploads/2020/02/red-river-block-564x323.jpg 564w, https://www.asteralabs.com/wp-content/uploads/2020/02/red-river-block-600x344.jpg 600w" sizes="(max-width: 731px) 100vw, 731px"></a></p>
<p><a href="https://www.intel.com/content/dam/www/public/us/en/documents/white-papers/serial-bus-white-paper.pdf" target="_blank" rel="noopener noreferrer">Figure 1: Redriver block diagram [1]</a></p>
<p>A retimer is a mixed signal analog/digital device that is protocol-aware and has the ability to fully recover the data, extract the embedded clock and retransmit a fresh copy of the data using a clean clock. In addition to the CTLE and wideband gain stages also found in a redriver, retimers contain a clock and data recovery (CDR) circuit, a decision feedback equalizer (DFE) and a transmit (Tx) finite impulse response (FIR) driver. Finite state machines (FSMs) and/or a microcontroller typically manage the automatic adaptation of the CTLE, wideband gain, DFE and FIR driver, and implement the PCIe link training and status state machine (LTSSM). Figure 2 illustrates a typical retimer block diagram.</p>
<p><a href="https://www.intel.com/content/dam/www/public/us/en/documents/white-papers/serial-bus-white-paper.pdf" target="_blank" rel="noopener noreferrer"><img src="https://www.asteralabs.com/wp-content/uploads/2020/02/retimer-block.jpg" alt="retimer-block" width="787" height="440" srcset="https://www.asteralabs.com/wp-content/uploads/2020/02/retimer-block.jpg 787w, https://www.asteralabs.com/wp-content/uploads/2020/02/retimer-block-300x168.jpg 300w, https://www.asteralabs.com/wp-content/uploads/2020/02/retimer-block-768x429.jpg 768w, https://www.asteralabs.com/wp-content/uploads/2020/02/retimer-block-260x145.jpg 260w, https://www.asteralabs.com/wp-content/uploads/2020/02/retimer-block-537x300.jpg 537w, https://www.asteralabs.com/wp-content/uploads/2020/02/retimer-block-200x112.jpg 200w, https://www.asteralabs.com/wp-content/uploads/2020/02/retimer-block-564x315.jpg 564w, https://www.asteralabs.com/wp-content/uploads/2020/02/retimer-block-600x335.jpg 600w" sizes="(max-width: 787px) 100vw, 787px"></a></p>
<p><a href="https://www.intel.com/content/dam/www/public/us/en/documents/white-papers/serial-bus-white-paper.pdf" target="_blank" rel="noopener noreferrer">Figure 2: Retimer block diagram [1]</a></p>
<p>In simple terms, a redriver amplifies a signal, whereas a retimer retransmits a fresh copy of the signal. Figure 3 illustrates this and shows how an attenuated eye opening is boosted by a redriver and completely regenerated by a retimer.</p>
<p><img src="https://www.asteralabs.com/wp-content/uploads/2020/02/eye-attenuated-1024x238.png" alt="eye-attenuated" width="1024" height="238" srcset="https://www.asteralabs.com/wp-content/uploads/2020/02/eye-attenuated-1024x238.png 1024w, https://www.asteralabs.com/wp-content/uploads/2020/02/eye-attenuated-300x70.png 300w, https://www.asteralabs.com/wp-content/uploads/2020/02/eye-attenuated-768x178.png 768w, https://www.asteralabs.com/wp-content/uploads/2020/02/eye-attenuated-1536x357.png 1536w, https://www.asteralabs.com/wp-content/uploads/2020/02/eye-attenuated-260x60.png 260w, https://www.asteralabs.com/wp-content/uploads/2020/02/eye-attenuated-800x186.png 800w, https://www.asteralabs.com/wp-content/uploads/2020/02/eye-attenuated-200x46.png 200w, https://www.asteralabs.com/wp-content/uploads/2020/02/eye-attenuated-564x131.png 564w, https://www.asteralabs.com/wp-content/uploads/2020/02/eye-attenuated-600x139.png 600w, https://www.asteralabs.com/wp-content/uploads/2020/02/eye-attenuated.png 1658w" sizes="(max-width: 1024px) 100vw, 1024px"></p>
<p>Figure 3: Example of an eye attenuated by a channel (left), the eye after a redriver (middle) and the eye after a retimer (right)</p>
<p>The PCIe 4.0 specification took the unprecedented step of formally defining the terms “retimer,” “redriver” and the superset term “repeater,” all of which are types of extension devices or components whose purpose is to extend the physical length of a link. The definitions are:</p>
<ul>
<li><strong>Repeater</strong>: An imprecise term for an extension device [2]. (This term causes confusion … please don’t use it!)</li>
<li><strong>Redriver</strong>: A non-protocol-aware software-transparent extension device [2].</li>
<li><strong>Retimer</strong>: A physical layer protocol-aware, software-transparent extension device that forms two separate electrical link segments [2].</li>
</ul>
<h3>Use Cases for Retimers and Redrivers</h3>
<p>Reach extension devices are necessary whenever the channel – the electrical path between the root complex (RC) and endpoint (EP) – is longer than the PCIe specification allows. The specification defines the maximum channel length in terms of insertion loss at the Nyquist frequency (an informative specification, but easy to validate) and in terms of a reference receiver’s ability to sufficiently equalize and recover the data assuming a worst-case link partner transmitter (a normative specification, but time-consuming to validate).</p>
<p>Suffice it to say, at PCIe 4.0 speeds, reach extension devices are necessary for:</p>
<ul>
<li>Multiconnector topologies.</li>
<li>Cabled topologies.</li>
<li>Single-connector add-in card (AIC) topologies with baseboard channels longer than 9.5 inches.</li>
</ul>
<p>Figure 4 shows an example of a two-connector “riser card” topology, which ordinarily would exceed the PCIe 4.0 loss budget of 28 dB. A redriver or retimer will enable reliable, error-free communication between the RC and EP. But how do you choose which one is the right tool for the job? Well, it helps to know more about the fundamental differences in their capabilities.</p>
<p><img src="https://www.asteralabs.com/wp-content/uploads/2020/02/redriver-1024x391.png" alt="redriver" width="1024" height="391" srcset="https://www.asteralabs.com/wp-content/uploads/2020/02/redriver-1024x391.png 1024w, https://www.asteralabs.com/wp-content/uploads/2020/02/redriver-300x115.png 300w, https://www.asteralabs.com/wp-content/uploads/2020/02/redriver-768x293.png 768w, https://www.asteralabs.com/wp-content/uploads/2020/02/redriver-260x99.png 260w, https://www.asteralabs.com/wp-content/uploads/2020/02/redriver-785x300.png 785w, https://www.asteralabs.com/wp-content/uploads/2020/02/redriver-200x76.png 200w, https://www.asteralabs.com/wp-content/uploads/2020/02/redriver-564x216.png 564w, https://www.asteralabs.com/wp-content/uploads/2020/02/redriver-600x229.png 600w, https://www.asteralabs.com/wp-content/uploads/2020/02/redriver.png 1120w" sizes="(max-width: 1024px) 100vw, 1024px"><br>
Figure 4: Example of redriver (top) and retimer (bottom) used in a two-connector topology</p>
<h3>Comparing Retimer and Redriver Capabilities</h3>
<p>Not all redrivers and retimers are the same. There are many distinctions between the two, which are universally true for all PCIe reach extension devices. For example:</p>
<p><strong>Retimers actively participate in the PCIe protocol; redrivers do not.</strong> The PCIe base specification spells out how and to what extent retimers participate in the protocol during Detect, Recovery, L0 and other LTSSM states. Equalization to the L0 and L1 link states requires value-added functionality from the retimer (handshakes, timeouts, bit manipulation, etc.). Redrivers are unaware of and unparticipating in the protocol. If the link works reliably the first time, that’s great! But if the link experiences marginality of any sort, it becomes exceedingly difficult to pinpoint whether the problem is physically before the redriver or after it, since the redriver’s role in link formation is undefined and unknown to its link partners.</p>
<p><strong>Retimers reset the jitter and insertion loss budgets; redrivers do not.</strong> A retimer’s CDR fully recovers the data stream and retransmits it on a clean clock. Starting with a fresh copy of the data enables the extension of the channel to twice the original specification. Without a CDR, the best a redriver can do is attenuate (not reset) the data-dependent jitter (DDJ) caused by intersymbol interference (ISI). A redriver cannot attenuate uncorrelated or random jitter (RJ). In fact, a redriver will always add to RJ due to its own device thermal noise in a root-mean-square (RMS) manner <a href="https://www.intel.com/content/dam/www/public/us/en/documents/white-papers/serial-bus-white-paper.pdf" target="_blank" rel="noopener noreferrer">[1]</a>.</p>
<p><strong>Retimers have a DFE; redrivers do not.</strong> A DFE compensates for reflections in the channel response caused by impedance discontinuities in board vias, connectors and package socket-board interfaces. The nice thing about a DFE is that it is unaffected by crosstalk. The DFE equalizes just as well in the presence of crosstalk, and once the data is sampled by the retimer’s CDR, crosstalk is eliminated for good. Redrivers use a CTLE that boosts both the signal and the noise <a href="https://www.intel.com/content/dam/www/public/us/en/documents/white-papers/serial-bus-white-paper.pdf" target="_blank" rel="noopener noreferrer">[1]</a>. Crosstalk is not eliminated or even attenuated through a redriver; in fact, it gets amplified.</p>
<p><strong>Retimers automatically adapt their receive and transmit equalizers to match the characteristics of the channel and the link partner’s needs; redrivers do not.</strong> A retimer will examine the signal it receives and adjust the CTLE and DFE to minimize its own bit error rate (BER). Likewise, the retimer’s transmitter will adjust its de-emphasis and pre-shoot equalization to minimize the link partner’s BER according to PCIe equalization protocol. A redriver, conversely, operates with a static equalizer setting. The optimal setting (which can be different for every channel in the system) is often painstakingly selected following an exhaustive search in Input/Output Buffer Information Specification (IBIS) algorithmic modeling interface (AMI) simulations and again in lab testing – a process fondly referred to as “tuning.”</p>
<p><strong>Retimers have built-in features to help diagnose link issues (both electrical and protocol); redrivers do not.</strong> Retimers have tools for assessing the electrical performance (internal eye monitors, pattern generators, pattern checkers) and protocol performance (link state history monitors, timeout adjustments). Redrivers cannot offer such diagnostic features because they are neither protocol-aware nor aware of the actual data passing through. Redrivers do not know what state the link is in.</p>
<p><strong>Retimers correct for lane-to-lane skew; redrivers do not.</strong> PCIe has a tight requirement on the physical skew between lanes on a board (1.6 ns for PCIe 4.0), typically caused by mismatches in channel routing length [3]. Retimers are required to compensate and reset any lane-to-lane skew, effectively doubling the specification budget. Redrivers cannot compensate for lane-to-lane skew, and what’s worse is that they may degrade the skew depending on how symmetric the redriver package is across all lanes.</p>
<p><strong>Retimers can be placed anywhere between two PCIe-compliant channels; redrivers cannot.</strong> By definition, retimers extend the total PCIe channel reach by two times the specification. A redriver’s reach extension, however, depends on where it is placed in the channel – how much loss is before the redriver versus how much is after <a href="https://www.intel.com/content/dam/www/public/us/en/documents/white-papers/serial-bus-white-paper.pdf" target="_blank" rel="noopener noreferrer">[1]</a>. The specific placement of a redriver must be carefully determined by IBIS-AMI simulation and experimentation. Too close to the root complex transmitter, and the redriver’s CTLE will enter nonlinear operation and will have limited benefit. Placed too far from the transmitter, the redriver’s device noise may significantly degrade the signal-to-noise ratio (SNR) of the data signal.</p>
<p>It’s not all bad news for redrivers. They do have lower power consumption and lower input-to-output latency compared to retimers. But if the link does not form in the first place or if the BER is too high, none of that matters!</p>
<p><img src="https://www.asteralabs.com/wp-content/uploads/2020/02/comparision.png" alt="comparision" width="809" height="527" srcset="https://www.asteralabs.com/wp-content/uploads/2020/02/comparision.png 809w, https://www.asteralabs.com/wp-content/uploads/2020/02/comparision-300x195.png 300w, https://www.asteralabs.com/wp-content/uploads/2020/02/comparision-768x500.png 768w, https://www.asteralabs.com/wp-content/uploads/2020/02/comparision-230x150.png 230w, https://www.asteralabs.com/wp-content/uploads/2020/02/comparision-461x300.png 461w, https://www.asteralabs.com/wp-content/uploads/2020/02/comparision-200x130.png 200w, https://www.asteralabs.com/wp-content/uploads/2020/02/comparision-564x367.png 564w, https://www.asteralabs.com/wp-content/uploads/2020/02/comparision-600x391.png 600w" sizes="(max-width: 809px) 100vw, 809px"></p>
<p>Table 1: Comparison of retimer and redriver capabilities and usage</p>
<h3>Outlook for PCIe 4.0 Systems</h3>
<p>Looking ahead to the upcoming PCIe 4.0 systems, all signs are pointing to an increased need for reach extension devices – and retimers in particular – due to several trends and challenges:</p>
<ul>
<li>CPUs have more PCIe lanes per socket (&gt;100 in some cases [4]) compared to PCIe 3.0. This leads to a greater number of PCIe slots and riser cards, denser routing, and an increased use of multiconnector topologies.</li>
<li>PCIe is shifting from an I/O bus to a multipurpose system interconnect. This means that more servers will be designed to be modular, allowing an array of compute, storage and networking resources to plug in to an increasing number of PCIe slots. This type of open, “plug anything in and it will work” server architecture requires a reach extension solution that is PCIe compliant with plug-and-play interoperability.</li>
<li>The disaggregation of resources such as modular servers, storage trays and accelerator trays is pushing endpoints physically away from CPUs, requiring cables or carrier cards to connect everything together. These longer physical topologies will increasingly need reach …</li></ul></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.asteralabs.com/2019/06/26/pci-express-retimers-vs-redrivers-an-eye-popping-difference/">https://www.asteralabs.com/2019/06/26/pci-express-retimers-vs-redrivers-an-eye-popping-difference/</a></em></p>]]>
            </description>
            <link>https://www.asteralabs.com/2019/06/26/pci-express-retimers-vs-redrivers-an-eye-popping-difference/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24278760</guid>
            <pubDate>Wed, 26 Aug 2020 03:20:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[You want people to do the right thing? Save them the guilt trip]]>
            </title>
            <description>
<![CDATA[
Score 212 | Comments 121 (<a href="https://news.ycombinator.com/item?id=24277190">thread link</a>) | @canada_random1
<br/>
August 25, 2020 | https://psyche.co/ideas/you-want-people-to-do-the-right-thing-save-them-the-guilt-trip | <a href="https://web.archive.org/web/*/https://psyche.co/ideas/you-want-people-to-do-the-right-thing-save-them-the-guilt-trip">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p><strong>Major global problems </strong>such as racial injustice or climate change often seem insurmountable. Itâ€™s hard to believe that our individual actions can make any real difference. Yet we know that many social dilemmas are overcome only through collective action. They call for people to make behavioural changes without any direct personal benefits â€“ in fact, these changes often come at a personal cost. So what might motivate people to adopt such a â€˜prosocialâ€™ mindset?</p>
<p>Researchers have explored a range of answers to this puzzle. A central line of enquiry relates to emotions and self-perception. Thereâ€™s a close link between emotions and behaviour: feelings motivate us to pursue goals, seek positive reinforcement and avoid punishment. But which emotional route is the most promising â€“ to make people feel bad about their shortcomings, or to encourage them to have a positive self-image because theyâ€™ve done â€˜the right thingâ€™?</p>
<p>There are good arguments both ways. Guilt can be a powerful motivator for action; the feeling of wanting to â€˜make upâ€™ for something can lead to reparative action. On the other hand, feeling good about our actions and what they reflect about who we are can elicit positive emotions. These feelings can then provide us with the energy and mental resources to engage in difficult problems, or to â€˜give to othersâ€™.</p>
<p>Itâ€™s important to distinguish here between guilt that arises internally, and guilt thatâ€™s externally induced. If we feel guilty about failing to recycle our plastics or adopt a vegetarian diet, we might be motivated to engage in reparative action. But if someone buttonholes us over dinner and tries to make us feel bad about our lifestyle choices, the picture might look very different; we might become defensive and try to justify our actions, which drives us further away from changing the way we behave. These scenarios then raise doubts about whether negative self-directed emotional appeals will be effective at promoting prosociality.</p>
<p>In a <a href="https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0188781">study</a> that my colleagues and I conducted at Columbia University in New York, we set out to test the consequences of positive versus negative self-directed emotions. Participants were prompted to think about either how guilty they felt about non-environmentally friendly behaviour, or how proud they might be for acting to preserve the environment. They were then asked a range of questions, such as whether they would pay increased rent to have more energy-efficient appliances, how likely they were to take public transport, and whether theyâ€™d be willing to use reusable shopping bags and mugs. Those participants who had been thinking of how proud they would feel about themselves chose to have a higher number of energy-efficient appliances compared with those participants who had been asked to think about personal guilt. Furthermore, participants in the pride group expressed higher intentions to engage in green behaviours compared with those in the guilt group. These findings suggest that inducing people to consider positive rather than negative self-directed emotions might recruit more people to a climate-change mitigation agenda, and to prosocial behaviour more broadly.</p>
<p>This potential advantage â€“ of appealing to positive emotions over negative ones â€“ links up with what we know about human self-perception. Having a positive self-image about who we are and what we do is a fundamental human need. When weâ€™re balanced and on good terms with ourselves, we are more energetic and have greater cognitive and emotional resources. By contrast, when we feel bad about ourselves, itâ€™s much more difficult to be prosocial â€“ especially if those feelings and actions arenâ€™t geared towards friends and family, but a removed, impersonal â€˜greater goodâ€™. Satisfying our important internal needs as emotional creatures can help us free up prosocial resources for others.</p>
<p>Research on self-affirmation supports this picture. In one <a href="https://academiccommons.columbia.edu/doi/10.7916/D84J1XJH">study</a>, we prompted one set of participants to engage in a self-affirming exercise. This involved reflecting on the values and behaviours that were important to them, and that they appreciated in themselves. Another group completed an unrelated exercise, describing the layout of the store at which they shop most frequently. This second â€˜controlâ€™ group allowed us to quantify the effect of the self-affirmation exercise.</p>
<p>Feeling good about ourselves can translate into acts of kindness towards others, for the benefit of society at large</p>
<p>Both groups were entered into a raffle to win a $10 bonus, and were given the option to either keep the money for themselves or to donate all or a portion to a selection of charities with varying missions and beneficiaries. The â€˜affirmationâ€™ group reported feeling more positively about themselves and more at peace with themselves â€“ and whatâ€™s more, these positive self-directed emotions translated into increased levels of charitable giving compared with those participants who had engaged in the unrelated exercise.</p>
<p><strong>My colleagues and</strong> I were curious about whether the effects of a positive self-image would extend to more challenging contexts, such as when the beneficiaries of prosociality were members of a marginalised group. In a field <a href="https://spssi.onlinelibrary.wiley.com/doi/full/10.1111/josi.12374">study</a> in Nigeria, we investigated how the public felt about enhanced social support for ex-prisoners. Like many other nations, Nigeria has high rates of recidivism. Social stigma means that those released from prison often struggle to secure jobs or have a supportive social network, which feeds into a cycle of reoffending. Interventions that reduce stigma and enhance social support can help ex-offenders to successfully reintegrate into society.</p>
<p>For the study, members of the general public in Nigeria were asked to engage in the self-affirming exercise prior to answering a range of survey questions. The results were striking. The self-affirmed participants showed more prosocial intentions and decreased discriminatory tendencies, compared with participants in the control group. They were more comfortable with having an ex-prisoner as their neighbour, for instance, and indicated stronger intentions to help an ex-prisoner whose employer was discriminating against them. They also expressed more willingness to invest personal time and effort to provide social support, such as participating in a tutoring programme for ex-prisoners.</p>
<p>Follow-up research in the United States replicated these results. Obtaining these findings in two studies and two different countries suggests that these effects can be generalised. The fact that a positive self-image can enhance prosociality doesnâ€™t seem to depend on a particular culture but could be an intrinsic part of human behaviour more generally. Feeling good about ourselves doesnâ€™t just enhance individual wellbeing by fulfilling a fundamental human psychological need; it can also translate into acts of kindness towards others, for the benefit of society at large.</p>
<p>A positive self-image can create a flywheel effect, in which the resulting prosocial behaviour sends a social signal to others. If others discriminate less, we are less likely to do so; if people in our social groups recycle more and watch their carbon footprint, we are more likely to do so. Getting a critical mass to â€˜join inâ€™ and acknowledging problems can, over time, help to shift norms â€“ which are drivers, not just inhibitors, of human behaviour.</p>
<p>The potential of positive self-directed emotions has largely not been embraced by activists. The worry could be that it might make those engaging in the cause appear self-satisfied or selfish. But these studies suggest that, instead of focusing on â€˜doom and gloomâ€™ messaging that zooms in on peopleâ€™s shortcomings and risks alienating them, policymakers and strategists might find that positive messaging, speaking to peopleâ€™s positive sense of self, might be a more powerful lever of behavioural change.</p></div></div></div>]]>
            </description>
            <link>https://psyche.co/ideas/you-want-people-to-do-the-right-thing-save-them-the-guilt-trip</link>
            <guid isPermaLink="false">hacker-news-small-sites-24277190</guid>
            <pubDate>Tue, 25 Aug 2020 22:50:20 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Squeak Smalltalk on a PostmarketOS Cellphone]]>
            </title>
            <description>
<![CDATA[
Score 25 | Comments 2 (<a href="https://news.ycombinator.com/item?id=24276883">thread link</a>) | @tonyg
<br/>
August 25, 2020 | https://eighty-twenty.org/2020/08/25/postmarketos-smalltalk | <a href="https://web.archive.org/web/*/https://eighty-twenty.org/2020/08/25/postmarketos-smalltalk">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <p>Back in 2007, when <a href="https://en.wikipedia.org/wiki/Openmoko">Openmoko</a>
was first a thing, I
<a href="https://leastfixedpoint.com/tonyg/kcbbs/openmoko-info.html">wrote an Erlang-based userland</a>
that got to the point of being able to take and make calls and receive
and send SMS. The project stalled: the Openmoko GTA01 was too slow,
its power-management too primitive, and Erlang’s GUI facilities too
rudimentary to make further work worthwhile.</p>

<p>Modern cellphone hardware is <em>much</em> more capable. Is it time to have
another run at the idea of a mobile personal computer?</p>

<figure>
<p><a href="https://leastfixedpoint.com/pictures/openmoko-erlang-ui.png"><img src="https://leastfixedpoint.com/pictures/openmoko-erlang-ui.png" alt="Erlang OpenMoko userland (2008)"></a>
Erlang OpenMoko userland (2008)</p>

<p><a href="https://eighty-twenty.org/images/postmarketos-samsung-galaxy-s7-herolte-20200825/IMG_20200825_213231.jpg"><img src="https://eighty-twenty.org/images/postmarketos-samsung-galaxy-s7-herolte-20200825/IMG_20200825_213231.jpg" alt="PostmarketOS on my cellphone"></a>
PostmarketOS on my cellphone</p>

<p><a href="https://eighty-twenty.org/images/postmarketos-samsung-galaxy-s7-herolte-20200825/IMG_20200825_213240.jpg"><img src="https://eighty-twenty.org/images/postmarketos-samsung-galaxy-s7-herolte-20200825/IMG_20200825_213240.jpg" alt="PostmarketOS Weston demo"></a>
PostmarketOS <a href="https://wiki.postmarketos.org/wiki/Weston">Weston</a> demo</p>

</figure>

<h3 id="postmarketos-is-awesome">PostmarketOS is awesome</h3>

<p>Last week, I installed <a href="http://postmarketos.org/">PostmarketOS</a> on my
previous cellphone, a Samsung Galaxy S7 (using PostmarketOS’s
<a href="https://wiki.postmarketos.org/wiki/Samsung_Galaxy_S7_(samsung-herolte)">samsung-herolte</a>
configuration).</p>

<p>PostmarketOS turns out to be a beautifully engineered system that’s
easy to understand and modify. The basics of kernel and Alpine Linux
userland installed cleanly and easily on the phone, and it’s running
well as a development platform. I’m looking forward to getting into
PostmarketOS more deeply.</p>

<figure>
<p><a href="https://eighty-twenty.org/images/pm-htop-20200825.png"><img src="https://eighty-twenty.org/images/pm-htop-20200825.png" alt="htop running on my cellphone"></a>
<code>htop</code> running on my cellphone. Six cores!</p>
</figure>

<p>Running <code>htop</code> on the phone shows what an <em>amazing</em> little machine it
is! So much power. Loads of cores, lots of RAM. Plenty of space to
explore alternative visions of mobile personal computing.</p>

<p>However, the built-in demos, such as the
<a href="https://wiki.postmarketos.org/wiki/Weston">Weston</a> demo (shown above
at right), currently leave quite a bit to be desired. Perhaps some of
the other
<a href="https://wiki.postmarketos.org/wiki/User-Interfaces">user interface options</a>
included with PostmarketOS could get me closer to a day-to-day usable
cellphone - but I’m interested in running my own software! Let’s get
hacking.</p>

<h3 id="running-my-own-programs">Running my own programs</h3>

<p>PostmarketOS is a plain, clean Alpine Linux distribution. You can SSH
into it initially
<a href="https://wiki.postmarketos.org/wiki/USB_Network">via USB networking</a>.
From there, you can
<a href="https://wiki.postmarketos.org/wiki/WiFi#Using_NetworkManager">configure wifi using nmcli</a>,
set up SSH keys, and then access it directly using SSH over wifi.</p>

<figure>
<p><a href="https://eighty-twenty.org/images/postmarketos-samsung-galaxy-s7-herolte-20200825/IMG_20200825_213419.jpg"><img src="https://eighty-twenty.org/images/postmarketos-samsung-galaxy-s7-herolte-20200825/IMG_20200825_213419.jpg" alt="lflow: Framebuffer demo"></a>
<code>lflow</code>: Framebuffer demo</p>
</figure>

<p>Building software is just as simple:</p>

<figure><pre><code data-lang="shell"><span></span>apk add alpine-sdk</code></pre></figure>

<p>To experiment with drawing to the framebuffer and reading touchscreen
input via <code>/dev/input</code>, I compiled and ran an old
<a href="https://github.com/tonyg/mac-display-hacks/blob/a1fde2054f00588076218b76d7ecf34764e5f99e/lflow.c">quick and dirty framebuffer hack</a>
I wrote years ago. The results (shown at left) were encouraging: the
program effortlessly animates tens of thousands of points at 30 frames
per second, responding to touch inputs. Display is via brute-force
pixel output to the <code>mmap</code>‘d frame buffer. It doesn’t even use a full
core.</p>

<p>PostmarketOS turns a phone into a fully capable Linux machine, with
total control over the attached hardware, and with everything
accessible to the developer in the usual places using the usual tools.</p>

<p>But Unix tools are inappropriate for a mobile personal computing
platform. We’ll need something else.</p>

<h3 id="a-smalltalk-phone">A Smalltalk phone</h3>

<figure>
<p><a href="https://eighty-twenty.org/images/postmarketos-samsung-galaxy-s7-herolte-20200825/IMG_20200825_213500.jpg"><img src="https://eighty-twenty.org/images/postmarketos-samsung-galaxy-s7-herolte-20200825/IMG_20200825_213500.jpg" alt="Squeak Smalltalk on PostmarketOS"></a>
Squeak Smalltalk
<a href="http://files.squeak.org/6.0alpha/Squeak6.0alpha-19812-64bit/">6.0-alpha</a>
on PostmarketOS</p>
</figure>

<p>Smalltalk could make an ideal basis for a mobile personal computing
platform.</p>

<p>I’ve <a href="https://eighty-twenty.org/tag/smalltalk">enjoyed</a> using,
developing with, and contributing to the
<a href="https://squeak.org/">Squeak Smalltalk</a> implementation since the mid
’00s.</p>

<p>So I compiled the
<a href="https://github.com/OpenSmalltalk/opensmalltalk-vm">Cog Smalltalk VM</a>
on the phone itself, making use of the 64-bit ARM support code that
landed extremely recently.</p>

<p>And lo and behold, it runs! Shown to the right is a bleeding-edge,
fully up-to-date Squeak 6.0-alpha image running on the phone itself.
(<a href="https://eighty-twenty.org/images/postmarketos-samsung-galaxy-s7-herolte-20200825/IMG_20200825_213500.jpg">Click here or on the image to embiggen.</a>)</p>

<p>From here, I can experiment with new ideas using the full power of a
modern Smalltalk environment.</p>

<h3 id="what-next">What next?</h3>

<p>My previous Openmoko experiments foundered, in part, on the GUI aspect
of the system; GTK+ via Erlang was fine for quick prototyping but
wasn’t really up to the task for a day-to-day usable machine.</p>

<p>I recall getting Squeak running on my GTA01, in order to see if it
could provide a viable UI. However, I remember being stymied by the
mismatch between the expectations of the Smalltalk environment and the
realities of the phone.</p>

<p>Squeak wants a mouse and keyboard. It assumes a monitor-sized display,
in everything from widget and font sizes to window management. To work
well on a phone, it needs a touchscreen-based, high-DPI UI in addition
to its existing toolset.</p>

<p>Smalltalk, in both its language aspect and its system design aspect,
also <a href="https://eighty-twenty.org/2011/05/08/weaknesses-of-smalltalk-strengths-of-erlang">suffers from some weaknesses in areas where Erlang shines</a>.</p>

<p>However, in the years since the GTA01:</p>

<ul>
  <li>
    <p>the hardware is much better,</p>
  </li>
  <li>
    <p>the Squeak VM and image are better,</p>
  </li>
  <li>
    <p>I’ve learned a heck of a lot about
<a href="https://syndicate-lang.org/tonyg-dissertation/html/">some good ways to design interactive systems</a>,
and</p>
  </li>
  <li>
    <p>I’ve recently
<a href="https://tonyg.github.io/squeak-actors/">built some tools that help bring Erlang- and Syndicate-style architectural patterns for concurrency to Smalltalk</a>.</p>
  </li>
</ul>

<p>So I think using Erlang/Syndicate-style
<a href="https://tonyg.github.io/squeak-actors/">Actors</a> to structure a
Smalltalk-based phone userland, perhaps with <code>cgroups</code>-based
sub-virtual-machines and images, could work well.</p>

<p>My initial experiments have concentrated on</p>

<ul>
  <li>
    <p>fixing the tiny fonts (the DPI-change support code in the image
needs work, and the support in the VM seems to be absent (?)),</p>
  </li>
  <li>
    <p>reading from the touchscreen (probably
<a href="http://lists.squeakfoundation.org/pipermail/squeak-dev/2016-June/190051.html">like this</a>),</p>
  </li>
  <li>
    <p>thinking about how to structure Actor supervision hierarchies and
<a href="https://syndicate-lang.org/tonyg-dissertation/html/#sec:Syndicate's-approach-to-concurrency">Dataspaces</a>
for a mobile phone (probably borrowing some design elements from my
earlier
<a href="https://github.com/tonyg/erlang-openmoko">Openmoko Erlang-based userland</a>),
and</p>
  </li>
  <li>
    <p>thinking about how to layer a touchscreen (panel-based?) GUI atop
Squeak’s <a href="http://wiki.squeak.org/squeak/morphic">Morphic</a> UI.</p>
  </li>
</ul>

<p>I’ll write more on this blog as things develop.</p>

<hr>

<p><strong>Update:</strong> <a href="https://eighty-twenty.org/2020/08/27/squeak-postmarketos-update">Some progress on the font front!</a></p>

  </div></div>]]>
            </description>
            <link>https://eighty-twenty.org/2020/08/25/postmarketos-smalltalk</link>
            <guid isPermaLink="false">hacker-news-small-sites-24276883</guid>
            <pubDate>Tue, 25 Aug 2020 22:17:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Tipe raises $2.1M seed round to build a customizable CMS for developers]]>
            </title>
            <description>
<![CDATA[
Score 39 | Comments 41 (<a href="https://news.ycombinator.com/item?id=24275948">thread link</a>) | @tmvnty
<br/>
August 25, 2020 | https://tipe.io/blog/tipe-raises-seed | <a href="https://web.archive.org/web/*/https://tipe.io/blog/tipe-raises-seed">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div><div><p>Today we're excited to announce that tipe has raised $2.1m in seed funding led by CRV and joined by investors YC, M Ventures, and Precursor Ventures. This investment will help tipe deliver an excellent experience for developers and teams who need a better workflow for managing content. Since graduating from YC's Winter 18 batch, we've been building prototypes, talking with users, and learning from the community. We're finally ready to show everyone what we've learned.  </p><p>Teams are shifting away from legacy site builders to more sophisticated builds with frameworks like Next.js and Gatsby. Cloud computing, crawlers, and JavaScript have all approved and come together to enable this shift. Jamstack offers so many benefits for low effort but also introduces more decision making. Teams must now decide on a content workflow, and developers are on the hook to figure it out.</p><p>We want to make this decision easy for developers. </p><h2>Make it your own, together</h2><p>They always say, "...never build a CMS". We know every team has different needs and use cases when it comes to content workflows. Customization and extendability are at the core of tipe's design.  That's why tipe is open-source and has a simple plugin features that make it easy for you to create your own CMS.</p><p>We invest in the open-source community and all the efforts to create and maintain the fantastic projects leading the Jamstack wave. We encourage developers to use plugins and extensions for tipe created by the community. One of our goals is to make sure we're not another app devs have to maintain, so we'll be working with developers to make sure working with tipe stays lean and fast. </p><p>We can't do this alone, so today we're launching the <a href="https://join.slack.com/t/tipe-hq/shared_invite/zt-gfesfzxf-9KHj1Q3GPhUbUOa6PjNpTA">tipe community slack</a>ðŸŽ‰. You can interact with the tipe team more closely, see what the community is cooking up, or even get help for anything that comes up. </p><h2>Roadmap to the best experience</h2><p>Developer and user experience are our main focuses here at tipe. As we grow, we want to move towards a minimal and straightforward product to use but powerful when combined with plugins and extensions. To achieve this goal, we plan on maintaining transparency about the direction of tipe and what's coming next. We'll also be leaning on our users and the community to help us build something that they would love. </p><p>To start, we have support for Jamstack frameworks like Next.js and Gatsby, a CLI to get started without ever visiting our web app, and SDKs to query content. As the community grows and improves tooling, we'll support all that comes from it. Open-source is are core, well before tipe, and will remain that way as we grow. </p><h2>Perfect timing</h2><p>The web is transitioning into another era with all the moving pieces seeing significant enhancements. Now is the time to build a fast experience for your users. You can't do that if your team is slow, because of content changes or any reason.</p><p>We look forward to helping teams stay fast as they deliver amazing journeys for their users. Also, <a href="https://tipe.io/jobs">we're hiring</a>! If anything you read here resonates with you, we'd love to hear from you. </p></div></div></div>]]>
            </description>
            <link>https://tipe.io/blog/tipe-raises-seed</link>
            <guid isPermaLink="false">hacker-news-small-sites-24275948</guid>
            <pubDate>Tue, 25 Aug 2020 20:51:56 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Optimal Peanut Butter and Banana Sandwiches]]>
            </title>
            <description>
<![CDATA[
Score 285 | Comments 99 (<a href="https://news.ycombinator.com/item?id=24272814">thread link</a>) | @ethanahte
<br/>
August 25, 2020 | https://www.ethanrosenthal.com/2020/08/25/optimal-peanut-butter-and-banana-sandwiches/ | <a href="https://web.archive.org/web/*/https://www.ethanrosenthal.com/2020/08/25/optimal-peanut-butter-and-banana-sandwiches/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>

      <section>
          <section>
              

              
              
              
              
              


              <article>
                  <div>
<video autoplay="" muted="" loop="loop">
    <source src="https://www.ethanrosenthal.com/videos/optimal-peanut-butter-and-banana/banana_small.mp4" type="video/mp4">
</video>

<p>I was personally useless for most of the Spring of 2020. There was a period of time, though, after the peak in coronavirus cases here in NYC and before the onslaught of police violence here in NYC that I managed to scrounge up the motivation to do something other than drink and maniacally refresh my Twitter feed. I set out to work on something completely meaningless. It was almost therapeutic to work on a project with no value of any kind (<em>insert PhD joke here</em>).</p>
<p>A side effect of having spent 10 years with limited income in college and grad school, 6 of those here in expensive ass NYC, is that I eat of lot of cheap sandwiches, even though I now have a nice Tech™ job. While my sandwich consumption was quite formidable pre-covid, sheltering in place cemented this staple in my diet. I am particularly fond of peanut butter and banana sandwiches, having been introduced to them as a child by my maternal grandfather who ate them regularly.</p>
<p>I start a peanut butter and banana sandwich by spreading peanut butter on two slices of bread. I then slice circular slices of the banana, starting at the end of the banana, and place each slice on one of the pieces of bread until I have a single layer of banana slices. Every time I do this, the former condensed matter physicist in me starts to twitch his eye. You see, I have this urge, this desire, this <em>need</em> to maximize the <a href="https://en.wikipedia.org/wiki/Atomic_packing_factor">packing fraction</a> of the banana slices. That is, I want to maximize the coverage of the banana slices on the bread. Just as bowl-form food is perfect because you get every ingredient in every bite, each bite of my sandwich should yield the same golden ratio of bread, peanut butter, and banana.</p>
<p>If you were a machine learning model (or my wife), then you would tell me to just cut long rectangular strips along the long axis of the banana, but I’m not a sociopath. If life were simple, then the banana slices would be perfect circles of equal diameter, and we could coast along looking up optimal configurations on <a href="http://packomania.com/">packomania</a>. But alas, life is not simple. We’re in the middle of a global pandemic, and banana slices are elliptical with varying size.</p>
<p>So, how do we make optimal peanut butter and banana sandwiches? It’s really quite simple. You take a picture of your banana and bread, pass the image through a deep learning model to locate said items, do some nonlinear curve fitting to the banana, transform to polar coordinates and “slice” the banana along the fitted curve, turn those slices into elliptical polygons, and feed the polygons and bread “box” into a 2D nesting algorithm.</p>
<p>You may have noticed that I supposedly started this project in the Spring, and it’s now August. Like most idiot engineers, I had no idea how complicated this stupid project was going to be, but time’s meaningless in quarantine, so here we are. And here you are! Because I made a pip installable python package <a href="https://github.com/EthanRosenthal/nannernest">nannernest</a> if you want to optimize your own sandwiches, and I’m going to spend the rest of this post describing how this whole godforsaken thing works.</p>
</div>
<div>
<h2 id="sandwich-segmentation">Sandwich Segmentation</h2>
<p>I know that deep learning has been properly commoditized when the easiest part of this project was identifying every pixel that belongs to a banana or slice of bread in an image. Seriously, this step was super easy. I used a pretrained Mask-RCNN torchvision <a href="https://pytorch.org/docs/stable/torchvision/models.html#torchvision.models.detection.maskrcnn_resnet50_fpn">model</a> with a Resnet backbone. The model was pretrained on the COCO <a href="https://cocodataset.org/">dataset</a>, and thankfully the dataset has “banana” as segmentation category, along with “sandwich” and “cake” which were close enough categories for suitable detection of most slices of bread.</p>
<p>Passing an image through the model outputs a bunch of detected objects, where each detected object has an associated <code>label</code>, <code>score</code>, <code>bounding box</code>, and <code>mask</code>, where the mask identifies the pixels that correspond to the object with a weight at each pixel corresponding to the model’s confidence in that pixel’s label.</p>
<p>Because there could be multiple bananas and slices of bread in the image, I pick out the banana and slice of bread with the highest score. Below, you can see the model is clearly able to identify the banana and bread, with the mask overlaid in a semi-transparent, radioactive green.</p>
</div>
<div>
<div>
<div><pre><code data-lang="python"><span>%</span><span>config</span> <span>InlineBackend</span><span>.</span><span>figure_format</span> <span>=</span> <span></span><span>'</span><span>retina</span><span>'</span>

<span>from</span> <span>pathlib</span> <span>import</span> <span>Path</span>
<span>import</span> <span>matplotlib.pyplot</span> <span>as</span> <span>plt</span>
<span>import</span> <span>numpy</span> <span>as</span> <span>np</span>
<span>import</span> <span>nannernest</span>

<span>_RC_PARAMS</span> <span>=</span> <span>{</span>
    <span></span><span>"</span><span>figure.figsize</span><span>"</span><span>:</span> <span>(</span><span>8</span><span>,</span> <span>4</span><span>)</span><span>,</span>
    <span></span><span>"</span><span>axes.labelsize</span><span>"</span><span>:</span> <span>16</span><span>,</span>
    <span></span><span>"</span><span>axes.titlesize</span><span>"</span><span>:</span> <span>18</span><span>,</span>
    <span></span><span>"</span><span>axes.spines.right</span><span>"</span><span>:</span> <span>False</span><span>,</span>
    <span></span><span>"</span><span>axes.spines.top</span><span>"</span><span>:</span> <span>False</span><span>,</span>
    <span></span><span>"</span><span>font.size</span><span>"</span><span>:</span> <span>14</span><span>,</span>
    <span></span><span>"</span><span>lines.linewidth</span><span>"</span><span>:</span> <span>2</span><span>,</span>
    <span></span><span>"</span><span>lines.markersize</span><span>"</span><span>:</span> <span>6</span><span>,</span>
    <span></span><span>"</span><span>legend.fontsize</span><span>"</span><span>:</span> <span>14</span><span>,</span>
<span>}</span>
<span>for</span> <span>k</span><span>,</span> <span>v</span> <span>in</span> <span>_RC_PARAMS</span><span>.</span><span>items</span><span>(</span><span>)</span><span>:</span>
    <span>plt</span><span>.</span><span>rcParams</span><span>[</span><span>k</span><span>]</span> <span>=</span> <span>v</span>

<span>DPI</span> <span>=</span> <span>160</span>
</code></pre></div></div>
</div>
<div>
<div>
<div><pre><code data-lang="python"><span>image</span><span>,</span> <span>banana</span><span>,</span> <span>bread</span> <span>=</span> <span>nannernest</span><span>.</span><span>segmentation</span><span>.</span><span>run</span><span>(</span><span>Path</span><span>(</span><span></span><span>"</span><span>pre_sandwich.jpg</span><span>"</span><span>)</span><span>)</span>
</code></pre></div></div>
</div>
<div>
<div>
<div><pre><code data-lang="python"><span>nannernest</span><span>.</span><span>viz</span><span>.</span><span>plot</span><span>(</span><span>image</span><span>,</span> <span>banana</span><span>=</span><span>banana</span><span>,</span> <span>bread</span><span>=</span><span>bread</span><span>,</span> <span>show</span><span>=</span><span>True</span><span>,</span> <span>dpi</span><span>=</span><span>DPI</span><span>)</span>
</code></pre></div></div>



<figure>
    
        <img src="https://www.ethanrosenthal.com/2020/08/25/optimal-peanut-butter-and-banana-sandwiches/index_4_0.png"> </figure>

</div>
<div>
<h2 id="what-shape-does-a-banana-makehttpswwwyoutubecomwatchv3o1ad4lzygk"><a href="https://www.youtube.com/watch?v=3O1ad4lZYGk">What shape does a banana make?</a></h2>
<p>Now that we have identified the banana in the image, we need to virtually “slice” it. This is where we are first introduced to the universal pain of computer vision:</p>
<p><em>By eye, I can see exactly what I want to do; by code, it’s so damn difficult.</em></p>
<p>I could ask you to draw lines on the banana identifying where you would slice it, and you could easily draw well-spaced, somewhat parallel slices. It’s not so easy to do this with code. However, I would also argue that this is the fun part of the problem. There are many ways to solve this, and it feels creative, as opposed to using a pre-trained deep learning model. On the other hand, “creatively” solving these problems likely leads to more brittle solutions compared to deep learning models trained on millions of examples. There’s a tradeoff here.</p>
<p>I tried a bunch of analytical solutions based on ellipses, but nothing seemed to work quite right. I ended up landing on a somewhat simpler solution that may not be robust to straight bananas, but who cares – this is a silly project anyway. Using the wonderful <a href="https://scikit-image.org/">scikit-image</a> library, I first calculate the <a href="https://scikit-image.org/docs/dev/auto_examples/edges/plot_skeleton.html">skeleton</a> of the banana segmentation mask. This reduces the mask to a one pixel wide representation which effectively creates a curve that runs along the long axis of the banana.</p>
</div>
<div>
<div>
<div><pre><code data-lang="python"><span>slices</span><span>,</span> <span>banana_circle</span><span>,</span> <span>banana_centroid</span><span>,</span> <span>banana_skeleton</span> <span>=</span> <span>nannernest</span><span>.</span><span>slicing</span><span>.</span><span>run</span><span>(</span>
    <span>banana</span><span>.</span><span>mask</span>
<span>)</span>
</code></pre></div></div>
</div>
<div>
<div>
<div><pre><code data-lang="python"><span>nannernest</span><span>.</span><span>viz</span><span>.</span><span>plot</span><span>(</span><span>image</span><span>,</span> <span>banana_skeleton</span><span>=</span><span>banana_skeleton</span><span>,</span> <span>show</span><span>=</span><span>True</span><span>,</span> <span>dpi</span><span>=</span><span>DPI</span><span>)</span>
</code></pre></div></div>



<figure>
    
        <img src="https://www.ethanrosenthal.com/2020/08/25/optimal-peanut-butter-and-banana-sandwiches/index_7_0.png"> </figure>

</div>
<p>I then fit a circle to the banana skeleton using a nice scipy-based least squares optimization I found <a href="https://scipy-cookbook.readthedocs.io/items/Least_Squares_Circle.html#Using-scipy.optimize.leastsq">here</a>. I actually originally tried to fit this with PyTorch and totally failed, likely due to the fact that this is actually a nonlinear optimization problem.</p>
<div>
<div>
<div><pre><code data-lang="python"><span>nannernest</span><span>.</span><span>viz</span><span>.</span><span>plot</span><span>(</span>
    <span>image</span><span>,</span>
    <span>banana_skeleton</span><span>=</span><span>banana_skeleton</span><span>,</span>
    <span>banana_circle</span><span>=</span><span>banana_circle</span><span>,</span>
    <span>show</span><span>=</span><span>True</span><span>,</span>
    <span>dpi</span><span>=</span><span>DPI</span><span>,</span>
<span>)</span>
</code></pre></div></div>



<figure>
    
        <img src="https://www.ethanrosenthal.com/2020/08/25/optimal-peanut-butter-and-banana-sandwiches/index_9_0.png"> </figure>

</div>
<div>
<h2 id="rad-coordinate-transformations">Rad Coordinate Transformations</h2>
<p>With the circle fit to the banana, the goal is to now draw radial lines out from the center of the circle to the banana and have each radial line correspond to the slice of a knife. Again, while it’s easy to visualize this, it’s much harder in practice. For example, we need to start slicing at one end of the banana, but how do we find an end of the banana? Also, there are two ends, and we have to differentiate between them. Contrary to the behavior of <a href="https://www.thekitchn.com/why-you-should-peel-your-banana-like-a-monkey-206322">monkeys</a>, I start slicing my bananas at the stem end, and that’s what we’re going to do here.</p>
<p>Crucially, because we now have this circle and want to cut radial slices, we must transform from cartesian to polar coordinates and orient ourselves both radially and angularly with respect to the banana. As a start for orienting ourselves angularly, we calculate the <em>centroid</em> of the banana mask, which corresponds to the center of mass of the banana mask if the banana mask were a 2D object. The centroid is shown below as a red dot.</p>
<p>We now draw a radial line originating from the banana circle and passing through the centroid, shown as the dashed white line below. We will consider that line to mark our <em>reference</em> angle which orients us to the center of the banana.</p>
</div>
<div>
<div>
<div><pre><code data-lang="python"><span>ax</span> <span>=</span> <span>nannernest</span><span>.</span><span>viz</span><span>.</span><span>plot</span><span>(</span>
    <span>image</span><span>,</span>
    <span>banana_skeleton</span><span>=</span><span>banana_skeleton</span><span>,</span>
    <span>banana_circle</span><span>=</span><span>banana_circle</span><span>,</span>
    <span>banana_centroid</span><span>=</span><span>banana_centroid</span><span>,</span>
    <span>show</span><span>=</span><span>False</span><span>,</span>
    <span>dpi</span><span>=</span><span>DPI</span><span>,</span>
<span>)</span>

<span>dy</span> <span>=</span> <span>banana_centroid</span><span>[</span><span>0</span><span>]</span> <span>-</span> <span>banana_circle</span><span>.</span><span>yc</span>
<span>dx</span> <span>=</span> <span>banana_centroid</span><span>[</span><span>1</span><span>]</span> <span>-</span> <span>banana_circle</span><span>.</span><span>xc</span>
<span>reference_angle</span> <span>=</span> <span>np</span><span>.</span><span>arctan2</span><span>(</span><span>dy</span><span>,</span> <span>dx</span><span>)</span>
<span>radius</span> <span>=</span> <span>np</span><span>.</span><span>sqrt</span><span>(</span><span>dx</span> <span>*</span><span>*</span> <span>2</span> <span>+</span> <span>dy</span> <span>*</span><span>*</span> <span>2</span><span>)</span>

<span>radial_end_point</span> <span>=</span> <span>(</span>
    <span>banana_circle</span><span>.</span><span>xc</span> <span>+</span> <span>2</span> <span>*</span> <span>radius</span> <span>*</span> <span>np</span><span>.</span><span>cos</span><span>(</span><span>reference_angle</span><span>)</span><span>,</span>
    <span>banana_circle</span><span>.</span><span>yc</span> <span>+</span> <span>2</span> <span>*</span> <span>radius</span> <span>*</span> <span>np</span><span>.</span><span>sin</span><span>(</span><span>reference_angle</span><span>)</span><span>,</span>
<span>)</span>

<span>ax</span><span>.</span><span>plot</span><span>(</span>
    <span>(</span><span>banana_circle</span><span>.</span><span>xc</span><span>,</span> <span>radial_end_point</span><span>[</span><span>0</span><span>]</span><span>)</span><span>,</span>
    <span>(</span><span>banana_circle</span><span>.</span><span>yc</span><span>,</span> <span>radial_end_point</span><span>[</span><span>1</span><span>]</span><span>)</span><span>,</span>
    <span>color</span><span>=</span><span></span><span>"</span><span>white</span><span>"</span><span>,</span>
    <span>linestyle</span><span>=</span><span></span><span>"</span><span>--</span><span>"</span><span>,</span>
    <span>linewidth</span><span>=</span><span>1</span><span>,</span>
<span>)</span>
<span>None</span>
</code></pre></div></div>



<figure>
    
        <img src="https://www.ethanrosenthal.com/2020/08/25/optimal-peanut-butter-and-banana-sandwiches/index_11_0.png"> </figure>

</div>
<p>Using <code>scikit-image</code>, we calculate the segmentation <code>mask</code> intensity along this radial line using the <code>profile_line</code> function. Because our line is passing at an angle along discrete <code>mask</code> pixels (aka matrix entries), we take an average of neighboring points along the radial line cut using the <code>linewidth</code> arguments. As you can see, the banana mask pops out a little over 100 points from the banana circle center.</p>
<div>
<div>
<div><pre><code data-lang="python"><span>from</span> <span>skimage</span> <span>import</span> <span>measure</span>

<span>profile_line</span> <span>=</span> <span>measure</span><span>.</span><span>profile_line</span><span>(</span>
    <span>banana</span><span>.</span><span>mask</span><span>.</span><span>T</span><span>,</span> <span>banana_circle</span><span>.</span><span>center</span><span>,</span> <span>radial_end_point</span><span>,</span> <span>linewidth</span><span>=</span><span>2</span><span>,</span> <span>mode</span><span>=</span><span></span><span>"</span><span>constant</span><span>"</span>
<span>)</span>
</code></pre></div></div>
</div>
<div>
<div>
<div><pre><code data-lang="python"><span>fig</span><span>,</span> <span>ax</span> <span>=</span> <span>plt</span><span>.</span><span>subplots</span><span>(</span><span>)</span>
<span>ax</span><span>.</span><span>plot</span><span>(</span><span>profile_line</span><span>)</span>
<span>ax</span><span>.</span><span>set_xlabel</span><span>(</span><span></span><span>"</span><span>Distance from banana circle center</span><span>"</span><span>)</span>
<span>ax</span><span>.</span><span>set_title</span><span>(</span><span></span><span>"</span><span>Mask Intensity</span><span>"</span><span>)</span>
<span>None</span>
</code></pre></div></div>



<figure>
    
        <img src="https://www.ethanrosenthal.com/2020/08/25/optimal-peanut-butter-and-banana-sandwiches/index_14_0.png"> </figure>

</div>
<p>This profile line is what allows us to orient ourselves radially. You can clearly see where the banana starts and ends, in the radial direction. As always, just seeing it is not good enough. We need code to define the start and end of the banana in this direction. The <code>mask</code> tends to be monotonically increasing and then monotonically decreasing along the start and end, respectively. Using this information, there are a couple ways …</p></article></section></section></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.ethanrosenthal.com/2020/08/25/optimal-peanut-butter-and-banana-sandwiches/">https://www.ethanrosenthal.com/2020/08/25/optimal-peanut-butter-and-banana-sandwiches/</a></em></p>]]>
            </description>
            <link>https://www.ethanrosenthal.com/2020/08/25/optimal-peanut-butter-and-banana-sandwiches/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24272814</guid>
            <pubDate>Tue, 25 Aug 2020 16:10:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Unpopular Opinion – Data Scientists Should Be More End-to-End]]>
            </title>
            <description>
<![CDATA[
Score 23 | Comments 14 (<a href="https://news.ycombinator.com/item?id=24272617">thread link</a>) | @importantbrian
<br/>
August 25, 2020 | https://eugeneyan.com/writing/end-to-end-data-science/?mkt_tok=eyJpIjoiWmpBNVlURTRNRE00WXpjMiIsInQiOiJockxCUXB1YmRPOGxvNm40UDhwdEk2dlI0UHhRY0NzTmdDV3ZnbFl4d3p6WGNZRU56Qmh1S2VNXC9zbmR2RUJrTjk4bW1DeVNUVHdBQW50aHdEOXhLd3VPVDRnbmRWOWdiSFFQVTVmaFZwZ3o3N0tLMk9Xdk9sYXBPc0I3Y1FhREoifQ%3D%3D | <a href="https://web.archive.org/web/*/https://eugeneyan.com/writing/end-to-end-data-science/?mkt_tok=eyJpIjoiWmpBNVlURTRNRE00WXpjMiIsInQiOiJockxCUXB1YmRPOGxvNm40UDhwdEk2dlI0UHhRY0NzTmdDV3ZnbFl4d3p6WGNZRU56Qmh1S2VNXC9zbmR2RUJrTjk4bW1DeVNUVHdBQW50aHdEOXhLd3VPVDRnbmRWOWdiSFFQVTVmaFZwZ3o3N0tLMk9Xdk9sYXBPc0I3Y1FhREoifQ%3D%3D">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <p>Recently, I came across a <a href="https://www.reddit.com/r/datascience/comments/i48b5q/for_those_that_work_for_a_team_that_has_both_data/" target="_blank">Reddit thread</a> on the different roles in data science and machine learning: data scientist, decision scientist, product data scientist, data engineer, machine learning engineer, machine learning tooling engineer, AI architect, etc.</p>

<p>I found this <em>worrying</em>. It’s difficult to be effective when the data science process (problem framing, data engineering, ML, deployment/maintenance) is split across different people. It leads to coordination overhead, diffusion of responsibility, and lack of a big picture view.</p>

<p>IMHO, <strong>I believe data scientists can be more effective by being end-to-end</strong>. Here, I’ll discuss the <a href="#from-start-identify-the-problem-to-finish-solve-it">benefits</a> and <a href="#but-we-need-specialist-experts-too">counter-arguments</a>, <a href="#the-best-way-to-pick-it-up-is-via-learning-by-doing">how to</a> become end-to-end, and the experiences of <a href="#end-to-end-in-stitch-fix-and-netflix">Stitch Fix and Netflix</a>.</p>

<h2 id="from-start-identify-the-problem-to-finish-solve-it">From start (identify the problem) to finish (solve it)</h2>

<p>You may have come across similar <em>labels</em> and definitions, such as:</p>
<ul>
  <li><a href="https://towardsdatascience.com/why-you-shouldnt-be-a-data-science-generalist-f69ea37cdd2c" target="_blank">Generalist</a>: Focused on roles (<a href="https://en.wikipedia.org/wiki/Product_manager" target="_blank">PM</a>, <a href="https://en.wikipedia.org/wiki/Business_analyst" target="_blank">BA</a>, <a href="https://www.oreilly.com/content/data-engineering-a-quick-and-simple-definition/" target="_blank">DE</a>, <a href="https://en.wikipedia.org/wiki/Category:Data_scientists" target="_blank">DS</a>, <a href="https://www.quora.com/What-exactly-does-a-machine-learning-engineer-do" target="_blank">MLE</a>); some negative connotation</li>
  <li><a href="https://skillcrush.com/blog/front-end-back-end-full-stack/" target="_blank">Full-stack</a>: Focused on tech (Spark, Torch, Docker); popularized by full-stack devs</li>
  <li><a href="https://www.infoworld.com/article/3429185/stop-searching-for-that-data-science-unicorn.html" target="_blank">Unicorn</a>: Focused on mythology; believed not to exist</li>
</ul>

<p>I find these definitions to be more prescriptive than I prefer. Instead, I have a simple (and pragmatic) definition: An end-to-end data scientist can <strong>identify and solve problems with data, to deliver value</strong>. To achieve the goal, they’ll wear as many (or as little) hats as required. They’ll also learn and apply whatever tech, methodology, and process that works. Throughout the process, they ask questions such as:</p>
<ul>
  <li>What is the problem? Why is it important?</li>
  <li>Can we solve it? How should we solve it?</li>
  <li>What is the estimated value? What was the actual value?</li>
</ul>

<details><summary>Data Science Processes</summary>
<div>
<p>Another way of defining end-to-end data science is via processes. These processes are usually complex and I’ve left them out of the main discussion. Nonetheless, here are a few in case you’re curious:</p>

<ul>
  <li><a href="https://en.wikipedia.org/wiki/Cross-industry_standard_process_for_data_mining" target="_blank">CRISP-DM</a>: Cross-Industry Standard Process for Data Mining (1997).</li>
  <li><a href="https://en.wikipedia.org/wiki/Data_mining#Process" target="_blank">KDD</a>: Knowledge Discovery in Databases.</li>
  <li><a href="https://docs.microsoft.com/en-us/azure/machine-learning/team-data-science-process/overview" target="_blank">TDSP</a>: Team Data Science Process, proposed by Microsoft in 2018.</li>
  <li><a href="https://github.com/dslp/dslp" target="_blank">DSLP</a>: Data Science Lifecycle Process.</li>
</ul>

<p>Don’t worry if these processes seem heavy and overwhelming. You don’t have to adopt them wholesale—start bit by bit, keep what works and adapt the rest.</p>
</div>

</details>

<h2 id="more-context-faster-iteration-greater-satisfaction">More context, faster iteration, greater satisfaction</h2>

<p>For most data science roles, being more end-to-end improves your ability to make meaningful impact. (Nonetheless, there are <a href="https://nvidia.wd5.myworkdayjobs.com/en-US/NVIDIAExternalCareerSite/job/US-CA-Santa-Clara/Senior-Deep-Learning-Data-Scientist--RAPIDS---AI_JR1929838" target="_blank">roles</a> that focus on machine learning.)</p>

<p><strong>Working end-to-end provides increased context.</strong> While specialized roles can increase efficiency, it reduces context (for the data scientist) and leads to suboptimal solutions.</p>

<blockquote>
  <p>The trick to forgetting the big picture is to look at everything close-up. – Chuck Palahniuk</p>
</blockquote>

<p>It’s hard to design a holistic solution without full context of the upstream problem. Let’s say conversion has decreased and a PM raises a request to improve our search algorithm. However, what’s causing the decrease in the first place? There could be various causes:</p>
<ul>
  <li>Product: Is fraudulent/poor quality product reducing customer trust?</li>
  <li>Data pipelines: Has data quality been compromised or are there delays/outages?</li>
  <li>Model refresh: Is the model not refreshing regularly/correctly?</li>
</ul>

<p>More often than not, the problem—and solution—lies <em>outside</em> of machine learning. A solution to <em>improve the algorithm</em> would miss the root cause.</p>

<p>Similarly, it’s risky to develop a solution without awareness of downstream engineering and product constraints. There’s no point:</p>
<ul>
  <li>Building a near-real time recommender if infra and engineer cannot support it</li>
  <li>Building an infinite scroll recommender if it doesn’t fit in our product and app</li>
</ul>

<p>By working end-to-end, data scientists will have the full context to identify the right problems and develop usable solutions. It can also lead to innovative ideas that specialists, with their narrow context, might miss. Overall, it increases the ability to deliver value.</p>

<p><strong>Communication and coordination overhead is reduced.</strong> With multiple roles comes additional overhead. Let’s look at an example of a data engineer (DE) cleaning the data and creating features, a data scientist (DS) analysing the data and training the model, and a machine learning engineer (MLE) deploying and maintaining it.</p>

<blockquote>
  <p>What one programmer can do in one month, two programmers can do in two months. – Frederick P. Brooks</p>
</blockquote>

<p>The DE and DS need to <em>communicate</em> on what data is (and is not) available, how it should be cleaned (e.g., outliers, normalisation), and which features should be created. Similarly, the DS and MLE have to discuss how to deploy, monitor, and maintain the model, as well as how often it should be refreshed. When issues occur, we’ll need three people in the room (likely with a PM) to triage the root cause and next steps to fix it.</p>

<p>It also leads to additional coordination, where schedules need to be aligned as work is executed and passed along in a sequential approach. If the DS wants to experiment with additional data and features, we’ll need to wait for the DE to ingest the data and create the features. If a new model is ready for A/B testing, we’ll need to wait for the MLE to (convert it to production code) and deploy it.</p>

<p>While the actual development work may take days, the communication back-and-forth and coordination can take weeks, if not longer. With end-to-end data scientists, we can minimize this overhead as well as prevent technical details from being lost in translation.</p>

<p>(But, can an end-to-end DS really do all that? I think so. While the DS might not be as proficient in some tasks as a DE or MLE, they will be able to perform most tasks effectively. If they need help with scaling or hardening, they can always get help from specialist DEs and MLEs.)</p>

<details><summary>The Cost of Communication and Coordination</summary>
<div>
<p>Richard Hackman, a Harvard psychologist, showed that the number of relationships in a team is <code><span>N</span><span>(</span><span>N</span><span>-</span><span>1</span><span>)</span> <span>/</span> <span>2</span></code>, where <code><span>N</span></code> is the number of people. This leads to exponential growth in links, where:</p>

<ul>
  <li>A start-up team of 7 has 21 links to maintain</li>
  <li>A group of 21 (i.e., three start-up teams) has 210 links</li>
  <li>A group of 63 has almost 2,000 links.</li>
</ul>

<p>In our simple example, we only had three roles (i.e., six links). But as a PM, BA, and additional members are included, this leads to greater than linear growth in communication and coordination costs. Thus, while each additional member increases total team productivity, the increased overhead means productivity grows at a decreasing rate. (Amazon’s <a href="https://buffer.com/resources/small-teams-why-startups-often-win-against-google-and-facebook-the-science-behind-why-smaller-teams-get-more-done/" target="_blank">two-pizza teams</a> are a possible solution to this.)</p>
</div>
</details>

<p><strong>Iteration and learning rate is increased.</strong> With greater context and lesser overhead, we can now iterate, fail (read: learn), and deliver value faster.</p>

<p>This is especially important for developing data and algorithmic products. Unlike software engineering (a far more mature craft), we can’t do all the learning and design before we start building—our blueprints, architectures, and design patterns are not as developed. Thus, rapid iteration is essential for the design-build-learn cycle.</p>

<p><strong>There’s greater ownership and accountability.</strong> Having the data science process split across multiple people can lead to diffusion of responsibility, and worse, social loafing.</p>

<p>A common anti-pattern observed is “<a href="https://wiki.c2.com/?ThrownOverTheWall" target="_blank">throw over the wall</a>”. For example, the DE creates features and throws a database table to the DS, the DS trains a model and throws <code>R</code> code over to the MLE, and the MLE translates it to <code>Java</code> to production.</p>

<p>If things get lost-in-translation or if results are unexpected, who is responsible? With a strong culture of ownership, everyone steps up to contribute in their respective roles. But without it, work can degenerate into ass-covering and finger-pointing while the issue persists and customers and the business suffers.</p>

<p>Having the end-to-end data scientist take ownership and responsibility for the entire process can mitigate this. They should be empowered to take action from start to finish, from the customer problem and input (i.e., raw data) to the output (i.e., deployed model) and measurable outcomes.</p>

<details><summary>Diffusion of Responsibilty &amp; Social Loafing</summary>
<div>

<p><a href="https://en.wikipedia.org/wiki/Diffusion_of_responsibility" target="_blank">Diffusion of responsibility</a>: We are less likely to take responsibility and act when there are others present. Individuals feel less responsibility and urgency to help if we know that there are others also watching the situation. </p>

<p>One form of this is the <a href="https://en.wikipedia.org/wiki/Diffusion_of_responsibility#Bystander_effect" target="_blank">Bystander effect</a>, where <a href="https://en.wikipedia.org/wiki/Murder_of_Kitty_Genovese" target="_blank">Kitty Genovese</a> was stabbed outside the apartment building across the street from where she lived. While there were 38 witnesses who saw or heard the attack, none called the police or helped her.</p>

<p><a href="https://en.wikipedia.org/wiki/Social_loafing" target="_blank">Social loafing</a>: We exert less effort when we work in a group vs. working alone. In the 1890s, Ringelmann made people pull on ropes both separately and in groups. He measured how hard they pulled and found that members of a group tended to exert less effort in pulling a rope than did individuals alone.</p>

</div>
</details>

<p><strong>For (some) data scientists, it can lead to increased motivation and job satisfaction</strong>, which is <a href="https://www.clearpointstrategy.com/how-employees-are-motivated-autonomy-mastery-purpose/" target="_blank">closely tied</a> to autonomy, mastery, and purpose.</p>
<ul>
  <li><strong>Autonomy:</strong> By being able to solve problems independently. Instead of waiting and depending on others, end-to-end data scientists are able to identify and define the problem, build their own data pipelines, and deploy and validate a solution.</li>
  <li><strong>Mastery:</strong> In the problem, solution, outcome from end-to-end. They can also pick up the domain and tech as required.</li>
  <li><strong>Purpose</strong>: By being deeply involved in the entire process, they have a more direct connection with the work and outcomes, leading to an increased sense of <em>purpose</em>.</li>
</ul>

<h2 id="but-we-need-specialist-experts-too">But, we need specialist experts too</h2>

<p>Being end-to-end is not for everyone (and every team) though, for reasons such as:</p>

<p><strong>Wanting to specialize</strong> in machine learning, or perhaps a specific niche in machine learning such as neural text generation (read: <a href="https://mc.ai/the-subtle-art-of-priming-gpt-3/" target="_blank">GPT-3 primer</a>). While being end-to-end is valuable, we also need such world-class experts in research and industry who push the envelope. Much of what we have in ML came from academia and pure research efforts.</p>

<blockquote>
  <p>No one achieves greatness by …</p></blockquote></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://eugeneyan.com/writing/end-to-end-data-science/?mkt_tok=eyJpIjoiWmpBNVlURTRNRE00WXpjMiIsInQiOiJockxCUXB1YmRPOGxvNm40UDhwdEk2dlI0UHhRY0NzTmdDV3ZnbFl4d3p6WGNZRU56Qmh1S2VNXC9zbmR2RUJrTjk4bW1DeVNUVHdBQW50aHdEOXhLd3VPVDRnbmRWOWdiSFFQVTVmaFZwZ3o3N0tLMk9Xdk9sYXBPc0I3Y1FhREoifQ%3D%3D">https://eugeneyan.com/writing/end-to-end-data-science/?mkt_tok=eyJpIjoiWmpBNVlURTRNRE00WXpjMiIsInQiOiJockxCUXB1YmRPOGxvNm40UDhwdEk2dlI0UHhRY0NzTmdDV3ZnbFl4d3p6WGNZRU56Qmh1S2VNXC9zbmR2RUJrTjk4bW1DeVNUVHdBQW50aHdEOXhLd3VPVDRnbmRWOWdiSFFQVTVmaFZwZ3o3N0tLMk9Xdk9sYXBPc0I3Y1FhREoifQ%3D%3D</a></em></p>]]>
            </description>
            <link>https://eugeneyan.com/writing/end-to-end-data-science/?mkt_tok=eyJpIjoiWmpBNVlURTRNRE00WXpjMiIsInQiOiJockxCUXB1YmRPOGxvNm40UDhwdEk2dlI0UHhRY0NzTmdDV3ZnbFl4d3p6WGNZRU56Qmh1S2VNXC9zbmR2RUJrTjk4bW1DeVNUVHdBQW50aHdEOXhLd3VPVDRnbmRWOWdiSFFQVTVmaFZwZ3o3N0tLMk9Xdk9sYXBPc0I3Y1FhREoifQ%3D%3D</link>
            <guid isPermaLink="false">hacker-news-small-sites-24272617</guid>
            <pubDate>Tue, 25 Aug 2020 15:54:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Global Mass Surveillance – The Fourteen Eyes]]>
            </title>
            <description>
<![CDATA[
Score 316 | Comments 133 (<a href="https://news.ycombinator.com/item?id=24272244">thread link</a>) | @latexr
<br/>
August 25, 2020 | https://www.privacytools.io/providers/#ukusa | <a href="https://web.archive.org/web/*/https://www.privacytools.io/providers/#ukusa">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
  <nav id="breadcrumb" aria-label="breadcrumb">
  
  <ol itemscope="" itemtype="https://schema.org/BreadcrumbList">
    <li>
      <a href="https://www.privacytools.io/"> <span>Home</span></a>
    </li>
    
    
    <li aria-current="page" itemprop="itemListElement" itemscope="" itemtype="https://schema.org/ListItem">
      
      <span itemprop="name">Providers 
      </span>
      <meta itemprop="position" content="1">
    </li>
    
    
  </ol>
</nav>


<div>
  
  <p>There's a ton of people providing services online. Discover which ones you should avoid and our recommendations for a variety of services.</p>
</div>



<p>Click on whatever service you need to view our recommendations.</p>





<img src="https://www.privacytools.io/assets/img/svg/layout/ukusa.svg" width="260" height="115" alt="UKUSA Agreement">

<p>The UKUSA Agreement is an agreement between the United Kingdom, United States, Australia, Canada, and New Zealand to cooperatively collect, analyze, and share intelligence. Members of this group, known as the <a href="https://www.giswatch.org/en/communications-surveillance/unmasking-five-eyes-global-surveillance-practices">Five Eyes</a>, focus on gathering and analyzing intelligence from different parts of the world. While Five Eyes countries have agreed to <a href="https://www.pbs.org/newshour/world/an-exclusive-club-the-five-countries-that-dont-spy-on-each-other">not spy on each other</a> as adversaries, leaks by Snowden have revealed that some Five Eyes members monitor each other's citizens and <a href="https://www.theguardian.com/uk/2013/jun/21/gchq-cables-secret-world-communications-nsa">share intelligence</a> to <a href="https://www.theguardian.com/politics/2013/jun/10/nsa-offers-intelligence-british-counterparts-blunkett">avoid breaking domestic laws</a> that prohibit them from spying on their own citizens. The Five Eyes alliance also cooperates with groups of third-party countries to share intelligence (forming the Nine Eyes and Fourteen Eyes); however, Five Eyes and third-party countries can and do spy on each other.</p>

<div>
  <div>
    <div>
        
        
        <div>
            
  <ol>
    <li>Australia </li>
    <li>Canada </li>
    <li>New Zealand </li>
    <li>United Kingdom </li>
    <li>United States of America </li>
  </ol>
  
        </div>
    </div>
</div>


  <div>
    <div>
        
        
        <div>
            
  <ol>
    <li>Denmark </li>
    <li>France </li>
    <li>Netherlands </li>
    <li>Norway </li>
  </ol>
  
        </div>
    </div>
</div>


  <div>
    <div>
        
        
        <div>
            
  <ol>
    <li>Belgium </li>
    <li>Germany </li>
    <li>Italy </li>
    <li>Spain </li>
    <li>Sweden </li>
  </ol>
  
        </div>
    </div>
</div>

</div>




<h3>Who is required to hand over the encryption keys to authorities?</h3>

<p>Mandatory <a href="https://en.wikipedia.org/wiki/Key_disclosure_law">key disclosure laws</a> require individuals to turn over encryption keys to law enforcement conducting a criminal investigation. How these laws are implemented (who may be legally compelled to assist) vary from nation to nation, but a warrant is generally required. Defenses against key disclosure laws include steganography and encrypting data in a way that provides plausible deniability.</p>  <p><a href="https://en.wikipedia.org/wiki/Steganography">Steganography</a> involves hiding sensitive information (which may be encrypted) inside of ordinary data (for example, encrypting an image file and then hiding it in an audio file). With plausible deniability, data is encrypted in a way that prevents an adversary from being able to prove that the information they are after exists (for example, one password may decrypt benign data and another password, used on the same file, could decrypt sensitive data).</p>



<p> * (people who know how to access a system may be ordered to share their knowledge, <strong>however, this doesn't apply to the suspect itself or family members.</strong>)</p>

<h3>Related Information</h3>

<ul>
  <li><a href="https://en.wikipedia.org/wiki/Key_disclosure_law">Wikipedia page on key disclosure law</a></li>
  <li><a href="https://law.stackexchange.com/questions/1523/can-a-us-citizen-be-required-to-provide-the-authentication-key-for-encrypted-dat">law.stackexchange.com question about key disclosure law in US</a></li>
  <li><a href="https://peertube.mastodon.host/videos/watch/e09915eb-5962-4830-a02f-8da5c2b59e71">DEFCON 20: Crypto and the Cops: the Law of Key Disclosure and Forced Decryption</a></li>
</ul>

<h3 id="usa">Why is it not recommended to choose a US-based service?</h3>

<img src="https://www.privacytools.io/assets/img/svg/layout/great_seal_of_the_united_states_obverse.svg" width="200" height="200" alt="USA">

<p>Services based in the United States are not recommended because of the country's surveillance programs and use of <a href="https://www.eff.org/issues/national-security-letters/faq">National Security Letters</a> (NSLs) with accompanying gag orders, which forbid the recipient from talking about the request. This combination allows the government to <a href="https://www.schneier.com/blog/archives/2013/08/more_on_the_nsa.html">secretly force</a> companies to grant complete access to customer data and transform the service into a tool of mass surveillance.</p>

<p>An example of this is <a href="https://en.wikipedia.org/wiki/Lavabit#Suspension_and_gag_order">Lavabit</a> – a secure email service created by Ladar Levison. The FBI <a href="https://www.vice.com/en_us/article/nzz888/lavabit-founder-ladar-levison-discusses-his-federal-battle-for-privacy">requested</a> Snowden's records after finding out that he used the service. Since Lavabit did not keep logs and email content was stored encrypted, the FBI served a subpoena (with a gag order) for the service's SSL keys. Having the SSL keys would allow them to access
communications (both metadata and unencrypted content) in real time for all of Lavabit's customers, not just Snowden's.</p>

<p>Ultimately, Levison turned over the SSL keys and <a href="https://www.theguardian.com/commentisfree/2014/may/20/why-did-lavabit-shut-down-snowden-email">shut down</a> the service at the same time. The US government then <a href="https://www.cnbc.com/id/100962389">threatened Levison with arrest</a>, saying that shutting down the service was a violation of the court order.</p>

<h3>Related Information</h3>

<ul>
  <li><a href="https://www.bestvpn.com/the-ultimate-privacy-guide/#avoidus">Avoid all US and UK based services</a></li>
  <li><a href="https://en.wikipedia.org/wiki/Surespot#History">Proof that warrant canaries work based on the surespot example.</a></li>
  <li><a href="https://en.wikipedia.org/wiki/UKUSA_Agreement">The United Kingdom – United States of America Agreement (UKUSA)</a></li>
  <li><a href="https://en.wikipedia.org/wiki/Lavabit#Suspension_and_gag_order">Lavabit: Suspension and gag order</a></li>
  <li><a href="https://en.wikipedia.org/wiki/Key_disclosure_law">Key disclosure law</a></li>
  <li><a href="https://en.wikipedia.org/wiki/Portal:Mass_surveillance">Wikipedia Portal: Mass_surveillance</a></li>
</ul>




<img src="https://www.privacytools.io/assets/img/svg/layout/warrant_canary_example.svg" width="450px" alt="Warrant Canary Example">

<p>A warrant canary is a posted document stating that an organization has not received any secret subpoenas during a specific period of time. If this document fails to be updated during the specified time then the user is to assume that the service has received such a subpoena and should stop using the service.</p>

<h4>Warrant Canary Examples:</h4>

<ol>
  <li><a href="https://proxy.sh/canary">https://proxy.sh/canary</a></li>
  <li><a href="https://www.ivpn.net/resources/canary.txt">https://www.ivpn.net/resources/canary.txt</a></li>
  <li><a href="https://www.bolehvpn.net/canary.txt">https://www.bolehvpn.net/canary.txt</a></li>
  <li><a href="https://www.ipredator.se/static/downloads/canary.txt">https://www.ipredator.se/static/downloads/canary.txt</a></li>
</ol>

<h4>Related Warrant Canary Information</h4>

<ul>
  <li><a href="https://www.eff.org/deeplinks/2014/04/warrant-canary-faq">Warrant Canary Frequently Asked Questions</a></li>
  <li><a href="https://en.wikipedia.org/wiki/Warrant_canary#Companies_and_organizations_with_warrant_canaries">Companies and organizations with warrant canaries</a></li>
  <li><a href="https://www.schneier.com/blog/archives/2015/03/australia_outla.html">Warrant canary criticism by Bruce Schneier and an example of a law against warrant canaries.</a></li>
</ul>



  </div></div>]]>
            </description>
            <link>https://www.privacytools.io/providers/#ukusa</link>
            <guid isPermaLink="false">hacker-news-small-sites-24272244</guid>
            <pubDate>Tue, 25 Aug 2020 15:20:51 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Mathematical Structure of Particle Collisions Comes into View]]>
            </title>
            <description>
<![CDATA[
Score 50 | Comments 5 (<a href="https://news.ycombinator.com/item?id=24270579">thread link</a>) | @rbanffy
<br/>
August 25, 2020 | http://abstractions.nautil.us/article/606/the-mathematical-structure-of-particle-collisions-comes-into-view | <a href="https://web.archive.org/web/*/http://abstractions.nautil.us/article/606/the-mathematical-structure-of-particle-collisions-comes-into-view">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
        <p><span><br></span><span>W</span>hen particle physicists try to model experiments, they confront an impossible calculation—an infinitely long equation that lies beyond the reach of modern mathematics.&nbsp;<br></p>

<p>Fortunately, they can generate largely accurate predictions without seeing this arcane math all the way through. By cutting the calculation short, scientists at CERNâ€™s Large Hadron Collider in Europe make forecasts that match events they actually observe when they send subatomic particles barreling toward each other around a nearly 17-mile track.</p>
<p>Unfortunately, the era of agreement between forecast and observation may be ending. As measurements grow more precise, the approximation schemes theorists use to make predictions may not be able to keep up.</p>
<p>â€œWeâ€™re getting close to exhausting what can be done,â€� said&nbsp;<a href="https://theory.cern/roster/duhr-claude" target="_blank">Claude Duhr</a>, a particle physicist at CERN.&nbsp;</p>
<p>But&nbsp;<a href="https://link.springer.com/article/10.1007/JHEP02(2019)139" target="_blank">three</a>&nbsp;<a href="https://journals.aps.org/prl/abstract/10.1103/PhysRevLett.123.201602" target="_blank">papers</a>&nbsp;from a group of physicists led by&nbsp;<a href="https://amplitudesatpadova.wixsite.com/amplitudes-at-padova" target="_blank">Pierpaolo Mastrolia</a>&nbsp;of the University of Padua in Italy and&nbsp;<a href="https://www.ias.edu/scholars/sebastian-mizera" target="_blank">Sebastian Mizera</a>&nbsp;of the Institute for Advanced Study in Princeton, New Jersey, have revealed an underlying mathematical structure in the equations. The structure provides a new way of collapsing interminable terms into just dozens of essential components. Their method may help bring about new levels of predictive accuracy, which theorists desperately need if they are to move beyond the leading but incomplete model of particle physics.</p>
<p>â€œThey have delivered lots of proof-of-concept results which show that this is a very promising technique,â€� Duhr said.</p>
<p>There could be a bigger payoff than improved predictions.&nbsp;</p>
<p>The new method skirts the traditional mathematical slog by directly computing â€œintersection numbers,â€� which some hope could eventually lead to a more elegant description of the subatomic world.&nbsp;</p>
<p>â€œThis is something thatâ€™s not just mathematics,â€� said&nbsp;<a href="https://www.physics.mcgill.ca/~schuot/" target="_blank">Simon Caron-Huot</a>&nbsp;of McGill University, a quantum theorist who is studying the implications of Mastrolia and Mizeraâ€™s work.&nbsp;â€œItâ€™s something thatâ€™s deeply baked into quantum field theory.â€�&nbsp;</p>
<p><strong>An Infinite Loop</strong></p>
<p>When physicists model particle collisions they use a tool called a Feynman diagram, a simple schematic invented by Richard Feynman in the 1940s.</p>
<p>To get a feel for these diagrams, consider a simple particle event: Two quarks streak in, exchange a single gluon as they â€œcollide,â€� then bounce away on their separate trajectories.</p>
<p>In a Feynman diagram the quarksâ€™ paths are represented by â€œlegs,â€� which join to form â€œverticesâ€� when particles interact. Feynman developed rules for turning this cartoon into an equation which calculates the probability that the event actually takes place: You write a specific function for each leg and vertex—generally a fraction involving the particleâ€™s mass and momentum—and multiply everything together. For straightforward scenarios like this one, the calculation might fit on a cocktail napkin.&nbsp;</p>
<figure><img src="https://s3.amazonaws.com/nautilus-vertical/abstractions_5242dbae24adf53fee012a27d96504f9.jpg" alt="nautilus gluon"><figcaption><br><span>Samuel Velasco/Quanta Magazine</span></figcaption></figure>
<p>But the golden rule of quantum theory is to consider all possibilities, and exchanging a simple gluon represents just one among a vast landscape of scenarios that could unfold when two quarks collide. The exchanged gluon might momentarily split into a â€œvirtualâ€� quark pair, for instance, before reconstituting itself in a flash. Two quarks enter and two quarks leave, but a lot can happen in the middle. A full accounting, implying a perfect prediction, would demand an infinite number of diagrams. No one expects perfection, but the key to improving a calculationâ€™s precision is getting further along in the infinite line of events.<strong>&nbsp;</strong><br></p>
<p>And thatâ€™s where physicists are getting stuck.&nbsp;</p>
<p>Zooming in to that hidden center involves virtual particles—quantum fluctuations that subtly influence each interactionâ€™s outcome. The fleeting existence of the quark pair above, like many virtual events, is represented by a Feynman diagram with a closed â€œloop.â€� Loops confound physicists—theyâ€™re black boxes that introduce additional layers of infinite scenarios. To tally the possibilities implied by a loop, theorists must turn to a summing operation known as an integral. These integrals take on monstrous proportions in multi-loop Feynman diagrams, which come into play as researchers march down the line and fold in more complicated virtual interactions.&nbsp;</p>
<p>Physicists have algorithms to compute the probabilities of no-loop and one-loop scenarios, but many two-loop collisions bring computers to their knees. This imposes a ceiling on predictive precision—and on how well physicists can understand what quantum theory says.&nbsp;</p>
<center>
<iframe width="560" height="315" src="https://www.youtube.com/embed/qe7atm1x6Mg" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""><span id="selection-marker-1" class="redactor-selection-marker"></span></iframe>
</center>
<p>But there is one small mercy: Physicists donâ€™t need to calculate every last integral in a complicated Feynman diagram because the vast majority can be lumped together.<br></p>
<p>Thousands of integrals can be reduced to just dozens of â€œmaster integrals,â€� which are weighted and added together. But exactly which integrals can be subsumed under which master integrals is itself a hard computational question. Researchers use computers to essentially guess at millions of relationships and laboriously extract the combinations of integrals that matter.</p>
<p>But with intersection numbers, physicists may have found a way of elegantly plucking out the essential information from a sprawling calculation of Feynman integrals.</p>
<p><strong>A Geometric Fingerprint&nbsp;</strong></p>
<p>Mastrolia and Mizeraâ€™s work is rooted in a branch of pure math called algebraic topology, which classifies shapes and spaces. Mathematicians pursue this classification with â€œcohomologyâ€� theories, which allow them to extract algebraic fingerprints from complicated geometric spaces.</p>
<p>â€œItâ€™s kind of a summary, an algebraic gadget that incorporates the essence of the space you want to study,â€� said&nbsp;<a href="https://imag.umontpellier.fr/~dupont/" target="_blank">ClÃ©ment Dupont</a>, a mathematician at the University of Montpellier in France.</p>
<p>Feynman diagrams can be translated into geometric spaces that are amenable to analysis by cohomology. Each point within these spaces might represent one of a multitude of scenarios that could play out when two particles collide.</p>
<p>You might hope, naively, that by taking the cohomology of this space—finding its algebraic structure—you could calculate the weights for the master integrals that support it. But the type of geometric space that characterizes most Feynman diagrams is warped in a way that resists many cohomology calculations.</p>
<p>In 2017, Mizera was struggling to analyze how objects in string theory collide when he stumbled upon tools pioneered by Israel Gelfand and Kazuhiko Aomoto in the 1970s and 1980s as they worked with a type of cohomology called â€œtwisted cohomology.â€� Later that year Mizera met Mastrolia, who realized that these techniques could work for Feynman diagrams too. In 2019,&nbsp;they published three papers that used this cohomology theory to streamline calculations involving simple particle collisions.</p>
<p>Their method takes a family of related physical scenarios, represents it as a geometric space, and calculates the twisted cohomology of that space. â€œThis twisted cohomology has everything to say about the integrals we are interested in,â€� Mizera said.</p>
<p>In particular, the twisted cohomology tells them how many master integrals to expect and what their weights should be. The weights emerge as values they call â€œintersection numbers.â€� In the end, thousands of integrals shrink to a weighted sum of dozens of master integrals.</p>
<p>The cohomology theories that produce these intersection numbers may do more than just ease a computational burden—they could also point to the physical significance of the most important quantities in the calculation.</p>
<p>For example, when a virtual gluon splits into two virtual quarks, the quarksâ€™ possible lifetimes can vary. In the associated geometric space, each point can stand for a different quark lifetime. When researchers compute the weights, they see that scenarios with the longest-lasting virtual particles—that is, cases in which the particles become essentially real—shape the outcome the most.</p>
<p>â€œThatâ€™s the amazing thing about this method,â€� said Caron-Huot. â€œIt reconstructs everything starting from just these rare, special events.â€�</p>
<p>In August 2020,&nbsp;Mizera, Mastrolia and colleagues published&nbsp;<a href="https://arxiv.org/abs/2008.04823" target="_blank">another preprint</a>&nbsp;showing that the technique has matured enough to handle real-world two-loop diagrams. A forthcoming paper by Caron-Huot will push the method further, perhaps bringing three-loop diagrams to heel.</p>
<p>If successful, the technique could help usher in the next generation of theoretical predictions. And, a few researchers suspect, it may even foreshadow a new perspective on reality.</p>

<ul><li> is a journalist covering developments in the physical sciences both on and off the planet. His work has appeared in <span>Scientific American, The Christian Science Monitor</span> and <span>LiveScience</span>, among other publications. Previously, he taught physics and English in Mozambique and Japan, and he has a bachelorâ€™s in physics from Brown University.</li></ul>
<p>Lead image:&nbsp;<a href="https://www.istockphoto.com/video/animation-of-particles-collision-in-hadron-collider-astrophysics-concept-gm1151477191-312085198" target="_blank" rel="noreferrer nofollow" data-is-link="https://www.istockphoto.com/video/animation-of-particles-collision-in-hadron-collider-astrophysics-concept-gm1151477191-312085198">vchal</a></p>
<p>Video: The brilliant physicist Richard Feynman devised a system of line drawings that simplified calculations of particle interactions and helped rescue the field of quantum electrodynamics.&nbsp;Directed by&nbsp;<a href="http://www.bonscifilms.com/" target="_blank">Emily Driscoll</a>&nbsp;and animated by&nbsp;<a href="http://metteilene.com/" target="_blank">Mette Ilene Holmriis&nbsp;</a>for Quanta Magazine.<br></p>





                    <p>Reprinted with permission from <a href="https://www.quantamagazine.org/">Quanta Magazine</a>'s <a href="https://www.quantamagazine.org/category/abstractions/">Abstractions blog</a>.</p>
            </article></div>]]>
            </description>
            <link>http://abstractions.nautil.us/article/606/the-mathematical-structure-of-particle-collisions-comes-into-view</link>
            <guid isPermaLink="false">hacker-news-small-sites-24270579</guid>
            <pubDate>Tue, 25 Aug 2020 12:23:19 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Practical tips for better microcopy]]>
            </title>
            <description>
<![CDATA[
Score 25 | Comments 8 (<a href="https://news.ycombinator.com/item?id=24270552">thread link</a>) | @jrdnbwmn
<br/>
August 25, 2020 | https://learnuxd.io/posts/7-practical-tips-for-better-microcopy/ | <a href="https://web.archive.org/web/*/https://learnuxd.io/posts/7-practical-tips-for-better-microcopy/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article itemscope="" itemtype="http://schema.org/BlogPosting">
        
        <p>Good microcopy is one of the fastest ways to improve an interface. Try doing an audit on your UI with these tips to see how it stands up.</p>

<h2 id="1-use-personal-pronouns">1) Use personal pronouns</h2>

<p>Address the reader instead of just talking out loud. Use the word <em>you</em>. People pay more attention when you talk directly to them.</p>

<figure>
    <img src="https://learnuxd.io/img/7-tips-for-better-microcopy/post1.png">
</figure>

<h2 id="2-start-with-a-verb">2) Start with a verb</h2>

<p>Names for interactive elements should begin with an action verb. The same goes for important copy. Starting with a verb is more direct and engaging.</p>

<figure>
    <img src="https://learnuxd.io/img/7-tips-for-better-microcopy/post2.png">
</figure>

<h2 id="3-prevent-concerns">3) Prevent concerns</h2>

<p>Point out concerning actions before your user can worry about your motives. Be transparent<span>—</span>make sure they understand what they’re doing and why.</p>

<figure>
    <img src="https://learnuxd.io/img/7-tips-for-better-microcopy/post3.png">
</figure>

<h2 id="4-use-natural-language">4) Use natural language</h2>

<p>Write conversationally, like you’re one-on-one. Be professional but get rid of jargon. Use familiar, simple words with a friendly, relaxed tone.</p>

<figure>
    <img src="https://learnuxd.io/img/7-tips-for-better-microcopy/post4.png">
</figure>

<h2 id="5-default-to-active-voice">5) Default to active voice</h2>

<p>Most of the time, active voice is the way to go. It’s easier to understand than passive voice, feels more personal, and is often shorter and stronger.</p>

<figure>
    <img src="https://learnuxd.io/img/7-tips-for-better-microcopy/post5.png">
</figure>

<h2 id="6-show-useful-error-messages">6) Show useful error messages</h2>

<p>Avoid negative, threatening, or overly technical words. Be friendly, show empathy, take the time to explain what’s going on, and be helpful.</p>

<figure>
    <img src="https://learnuxd.io/img/7-tips-for-better-microcopy/post6.png">
</figure>

<h2 id="7-write-iteratively">7) Write iteratively</h2>

<p>We write code iteratively, so why everything else? Things probably won’t be perfect the first time around. Test, refine, ship again. It adds up.</p>

<figure>
    <img src="https://learnuxd.io/img/7-tips-for-better-microcopy/post7.png">
</figure>

<p>Thanks for reading. If you enjoyed the article, sharing on Twitter is really appreciated:</p>

<div>
    <div>
        <blockquote><div lang="en" dir="ltr"><p>Good microcopy is one of the fastest ways to improve an interface. </p><p>Try doing an audit on your UI with these tips to see how it stands up. 👇 <a href="https://t.co/DqRSmVTIvt">pic.twitter.com/DqRSmVTIvt</a></p></div>— Learn UXD (@learn_uxd) <a href="https://twitter.com/learn_uxd/status/1298228761771552773?ref_src=twsrc%5Etfw">August 25, 2020</a></blockquote> 
    </div>
</div>


    </article></div>]]>
            </description>
            <link>https://learnuxd.io/posts/7-practical-tips-for-better-microcopy/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24270552</guid>
            <pubDate>Tue, 25 Aug 2020 12:19:01 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Stealing local files using Safari Web Share API]]>
            </title>
            <description>
<![CDATA[
Score 24 | Comments 4 (<a href="https://news.ycombinator.com/item?id=24270538">thread link</a>) | @doener
<br/>
August 25, 2020 | https://blog.redteam.pl/2020/08/stealing-local-files-using-safari-web.html | <a href="https://web.archive.org/web/*/https://blog.redteam.pl/2020/08/stealing-local-files-using-safari-web.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/>Unable to extract article]]>
            </description>
            <link>https://blog.redteam.pl/2020/08/stealing-local-files-using-safari-web.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24270538</guid>
            <pubDate>Tue, 25 Aug 2020 12:16:37 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Secure Modular Runtimes]]>
            </title>
            <description>
<![CDATA[
Score 21 | Comments 6 (<a href="https://news.ycombinator.com/item?id=24270195">thread link</a>) | @ispivey
<br/>
August 25, 2020 | https://guybedford.com/secure-modular-runtimes.html | <a href="https://web.archive.org/web/*/https://guybedford.com/secure-modular-runtimes.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
<p>I recently posted the following Tweet with regards to the current state of the third-party security problem in the JavaScript ecosystem:

</p><blockquote><div lang="en" dir="ltr"><p>Having worked on and followed modules standards from TC39 and WhatWG to Node.js, it's so so clear that security was, is, and always will be an afterthought.</p><p>Where are the secure-by-default open platform developments? Crypto is the only community I see doing it.</p></div>— Guy Bedford (@guybedford) <a href="https://twitter.com/guybedford/status/1296935308445900801?ref_src=twsrc%5Etfw">August 21, 2020</a></blockquote> 

<p>I wanted to fill in some of the background to this from my own work on Node.js modules and security concepts, following the Agoric SES and compartment models, and from a growing feeling of the inadequacy of the Node.js, Deno and browser runtimes for supporting the third-party security needs of the ecosystem.

</p><p><em>TLDR; I think we need to think about new more secure runtimes for JS, and it should be a collaborative effort, with the components being modules, adding isolated scopes to import maps, and a careful security model plus compatibility with the existing ecosystem. <a href="#secure-modular-runtime-proposal">Skip ahead to the proposal here.</a></em>

</p><p><em>Update: Since posting this, I see that <a rel="noopener" target="_blank" href="https://github.com/Agoric/SES-shim/tree/master/packages/endo">Endo</a> and <a rel="noopener" target="_blank" href="https://github.com/LavaMoat/LavaMoat">LavaMoat</a> provide techniques very close to these directions, although neither has quite yet taken the leap that I argue is necessary that such a security system should be integrated into the primary runtime itself.</em></p>

<h2><a href="#third-party-security-problem">#</a>The Third-Party Security Problem</h2>

<p>The underlying issue is the <code>npm install</code> one. As the registry and our dependence on it continues to expand, the security gap here continues to grow in terms of the amount of untrusted code we are running on a daily basis.

</p><p>Maintainers giving up their time freely now find themselves obliged to respond to regular security issues or risk having unpatchable advisories released for their packages, which may or may not even be genuine escalations of privilege.
  We engage in security theatre to create the illusion of safety, and yet all the while everything remains highly unsecure.

</p><p>Rather than simply accepting the status quo, many companies are actively working on mitigating these security properties. The problem is that they end up creating side ecosystems or patches to the existing ecosystem, security measures that are never fundamentally designed into the ecosystem itself. Third-party security remains a huge if not impossible effort, that only dedicated teams can afford to tackle, as we see for example with these intiatives by <a rel="noopener" target="_blank" href="https://www.figma.com/blog/how-we-built-the-figma-plugin-system/">Figma</a> or <a rel="noopener" target="_blank" href="https://developer.salesforce.com/blogs/developer-relations/2017/02/lockerservice-lightning-container-third-party-libraries-lightning-components.html">Salesforce</a>.

</p><p>The <a rel="noopener" target="_blank" href="https://github.com/tc39/proposal-realms">Realms proposal</a> may give us the tools for constructing a secure runtime, but the JavaScript ecosystem conventions themselves work against supporting security restrictions.

</p><p>The general view from Chrome/v8, is that this type of third-party per-package security within the same process isn't possible:

</p><blockquote><p lang="en" dir="ltr">how is this possible post spectre</p>— Sathya Gunasekaran (@_gsathya) <a href="https://twitter.com/_gsathya/status/1297121933004353536?ref_src=twsrc%5Etfw">August 22, 2020</a></blockquote> 

<p>Now I admit I have fully bought in to the elegance of the the OCAP, SES and compartment models, the ideas shared by those at Agoric (who are long-time members of TC39). I gave a session on these concepts at the Node.js Collaboration summit.

</p><p>For all the tremendous benefits of the concept of modular security, there are certainly important questions, but I believe we should actively tackle this work and these questions, and not abandon the same-process modular security models unless they can be fully disproved.

<a name="compartment-model"></a>
</p><h2><a href="#compartment-model">#</a>The Compartment Model</h2>

<p>The gist of the compartment model builds on top of SES (<a rel="noopener" target="_blank" href="https://github.com/Agoric/ses-shim">Secure ECMAScript</a>), as proposed by Agoric, something like the following:

</p><ol>
  <li>All capabilities are imported through the module system (<code>import fetch from 'fetch'</code> kind of thing) - <em>the module resolver acts as the capability system, enforcing permissions</em>.</li>
  <li>The consequence of (1) is that <em>all global capabilities should be disabled / carefully controlled.</em></li>
  <li>JavaScript needs a whole bunch of patching to prevent prototype mutations and unintentional side channels such as <code>return { toString() {} }</code> object hooks. You have to manage package interfaces very carefully and freeze the entire global object from prototype mutation.</li>
</ol>

<p>See the talk by Mark Miller on <a rel="noopener" target="_blank" href="https://www.youtube.com/watch?v=9WdbTucMaRo">Extremely Modular Distributed JavaScript</a>, or my presentation from the Node.js Collaboration Summit,
<a rel="noopener" target="_blank" href="https://docs.google.com/presentation/d/1VUpxoxitZCINJI7jXec4i87YiYZsXr8pCSHdHY5pW30/edit?usp=sharing">Security, Modules and Node.js</a>, for a more in-depth coverage of the full model.

</p><p>The result of this model is, in theory, the ability to restrict destructive code. The date time library you npm install cannot install a trojan horse on your computer, which seems a pretty useful property to have.

</p><p>Towards (3) we already <a rel="noopener" href="https://nodejs.org/dist/latest-v14.x/docs/api/cli.html#cli_frozen_intrinsics">shipped the `--frozen-intrinsics` flag in Node.js</a>. (1) and (2) clearly require breaking changes to what we have in any existing runtimes today.</p>

<h2><a href="#criticisms">#</a>Criticisms</h2>

<p>The criticisms of this model include the Spectre class of vulnerabilities, the difficulty in providing secure cross-package interfaces, and that these ideas might sound good in theory but are impractical in real JS environments.

<a name="spectre"></a>
</p><h3><a href="#spectre">#</a>Spectre</h3>

<p>The Spectre class of attacks means that code running on the same process can use CPU reverse engineering and timing information to read secret information
used by other separate code in the same process. Think - passwords, secure tokens, etc.

</p><p>The first thing to note is that Spectre is the ability to steal secrets and not the ability to install a trojan horse on your computer. Even if we can't fully mitigate Spectre (and we can certainly try), we are still limiting destructive capabilities such as giving full disk and network access
  to random people on the internet, which is a huge win. What we are comparing this model against, is having no separate security for third-party libraries at all, which is the case in Node.js, Deno and browsers today. <em>In the case of an attack, it is better to just lose a credit card, than to lose a credit card AND have your house burnt down.</em>

</p><p>The second thing to note here is that if you have a true capability system and can carefully control network access, then the capability to exfiltrate (basically to use <code>fetch</code>), can itself be treated as a critical permission. Secrets might be discovered but not as easily shared.

</p><p>The counterargument to controlling the capability to exfiltrate is that there are always side channels to be found - the blinking of a light through whatever complex window to share the information of the secret token. It's a complex boundary to mitigate.

</p><p>Finally, in terms of genuine Spectre mitigations, Cloudflare have this same problem for their same-process deployment of Cloudflare Workers, which they recently discussed here - <a rel="noopener" target="_blank" href="https://blog.cloudflare.com/mitigating-spectre-and-other-security-threats-the-cloudflare-workers-security-model/">Mitigating Spectre and Other Security Threats: The Cloudflare Workers Security Model</a>.

</p><p>Their mitigations are summarized at the end, and roughly involve:

</p><ul>
<li>Restricting Date.now() and multi-threading via new Worker (which allows custom timer creation) to attempt to disable the time measurements necessary to initiate the attack.
</li><li>Proactively detecting the attack behaviour based on monitoring and initiating full isolation.
</li><li>Exploring memory shuffling techniques so that secret information does not remain static.
</li></ul>

<p>As Cloudflare mention, this is an active mitigation space that can continue to be developed. In theory, these similar mitigations could apply to new runtime development as well.

</p><p>The important thing to note is that these mitigation techniques do not apply to the Web platform at all as they are simply not possible (at least not without <a rel="noopener" target="_blank" href="https://github.com/tc39/proposal-realms">Realms</a>). The Google / v8 position completely makes sense, given this angle,
  but the focus I want to make is on <strong>new JavaScript runtimes</strong>, like successors to Node.js such as Deno and others, <em>which should really be exploring these security properties today</em>.

<a name="insecure-module-interfaces"></a>
</p><h3><a href="#insecure-module-interfaces">#</a>Insecure Module Interfaces</h3>

<p>The next major problem comes down to the complex interface boundary between third-party packages. For example, consider the following code:

</p><pre><code>
import { renderer } from 'renderer';
import { renderGraph } from 'graph';
import { renderTitle } from 'title';

renderer.render([renderGraph, renderTitle]);
</code></pre>

<p>In theory, <code>renderGraph</code> doesn't need any other capabilities other than the ability to call into the renderer so it can be treated as low-trust code.

</p><p>But now consider a malicious implementation of <code>renderGraph</code>:

</p><pre><code>
export function renderGraph () {
  this[1].setTitle('Changed the title');
}
</code></pre>

<p><code>renderGraph</code> knows the renderer will call it via <code>renderArray[i]()</code>, which in JavaScript will set the <code>this</code> binding to the array itself, thus giving access to the title component from the graph component.

</p><p>Yes, it's a contrived example, but it demonstrates how easily you can get capability spillage in JavaScript, and that's before we even get to information spillage eg via <code>toString()</code>.

</p><p>Locking down these sorts of inadvertant side channels means making all package interfaces out of <code>SafeFunction</code> and <code>SafeObject</code> objects that don't have these sorts of awful flaws, and it's not an easy problem to solve - this is where the bulk of the effort needs to be made.

</p><p>The other side of this to consider is that Web Assembly module interfaces don't have these same sorts of capability and information spillage that we have in JavaScript, which certainly gives hope for future ecosystems dealing with these problems.

<a name="impractical-constraints"></a>
</p><h3><a href="#impractical-constraints">#</a>Impractical Constraints</h3>

<p>The third argument is that the security requirements are simply too much of a constraint on JavaScript and its ecosystems. That there exists no path from the ecosystems today to this kind of secure ecosystem. As a result, secure runtimes will always be a fringe effort
  adopted by the few who can invest in the time and effort to support them.

</p><p>This, I believe, is the most crucial problem to solve. The ability to run third-party libraries with less risk should be fully democratized.

<a name="secure-modular-runtime-proposal"></a>
</p><h2><a href="#secure-modular-runtime-proposal">#</a>Secure Modular Runtime Proposal</h2>

<p>I'd like to propose a hypothetical runtime for JavaScript, as a strawman, and to invite scrutiny as to whether this solves the following problems:

</p><ol>
<li>That this runtime can fully restrict high-level capability access from packages for third-party code running in the same process than we have in Node.js, Deno and browsers today.
</li><li>That this runtime can support …</li></ol></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://guybedford.com/secure-modular-runtimes.html">https://guybedford.com/secure-modular-runtimes.html</a></em></p>]]>
            </description>
            <link>https://guybedford.com/secure-modular-runtimes.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24270195</guid>
            <pubDate>Tue, 25 Aug 2020 11:25:40 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Show HN: Seamless head tracking for games using the TrueDepth camera (iOS)]]>
            </title>
            <description>
<![CDATA[
Score 25 | Comments 16 (<a href="https://news.ycombinator.com/item?id=24269925">thread link</a>) | @epaga
<br/>
August 25, 2020 | http://www.inflightassistant.com/smoothtrack/index.html | <a href="https://web.archive.org/web/*/http://www.inflightassistant.com/smoothtrack/index.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
      <div>
        <h2>
          <p><a href="https://apps.apple.com/de/app/smoothtrack/id1528839485?l=en"><img src="http://www.inflightassistant.com/img/appstore.svg" height="45/"></a></p>
            
            <p><b><a href="https://testflight.apple.com/join/ytc1tAdA">Click here to join a free public beta</a> which runs on ANY iOS 13 device, not only ones with TrueDepth!</b></p>
            
          <p>SmoothTrack is the best input source for the free OpenTrack software which enables you to use head tracking in your Mac or PC games.</p>
<br>
<div>
  <div>
    <div>
      <p>
        <h6>
          "Just flew a few patterns with this - it genuinely works better for me than TrackIR ever did, at a fraction of the cost." - /u/yawnyprawny
        </h6>
      </p>
    </div>
  </div>
</div>

          <p>SmoothTrack provides you with 6 degrees-of-freedom head tracking for beautiful head tracking for your games.</p>
          

            <p>No headset or extra equipment of any kind is required! Simply set up your device so that it can see your face. Using the on-screen controls, you can shift your perspective in-game.</p>
            

              <p>It's an amazing experience to seamlessly move your head and have your game perspective play along.</p>
              <br>
              <div>
                <div>
                  <div>
                    <p>
                      <h6>
                        "This worked perfectly and way better than expected! Totally enhanced my experience with MFS 2020!" - /u/lexpert1
                      </h6>
                    </p>
                  </div>
                </div>
              </div>
              
              
                <p>Any game that supports the FreeTrack or TrackIR protocol will work with this, including Flight Simulator, Elite: Dangerous, FSX, IL2: Sturmovik, and many, many others!</p>
                

                  <p>INSTRUCTIONS (included in the app):</p>
                  <br>

                    <ol><li>On your computer, install and run the free program "OpenTrack".</li>
                      <li>In OpenTrack, as Input source, choose "UDP over network". As Output, choose "freetrack 2.0 Enhanced".</li>
                        <li>Make sure the UDP port OpenTrack is using is open both on your firewall and router.</li>
                          <li>Find the IP address of your PC</li>
                            <li>Now, in SmoothTrack, set up your IP address and port in the settings</li>
                              <li>Tap Play and you should see the OpenTrack octopus move around, which means any game that supports TrackIR will now be supporting your head tracking!</li>
</ol>
<p>Email support is provided if there are any issues.</p>

    
  
</h2></div></div></div>]]>
            </description>
            <link>http://www.inflightassistant.com/smoothtrack/index.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24269925</guid>
            <pubDate>Tue, 25 Aug 2020 10:43:47 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[My AI Timelines Have Sped Up]]>
            </title>
            <description>
<![CDATA[
Score 77 | Comments 72 (<a href="https://news.ycombinator.com/item?id=24269316">thread link</a>) | @T-A
<br/>
August 25, 2020 | https://www.alexirpan.com/2020/08/18/ai-timelines.html | <a href="https://web.archive.org/web/*/https://www.alexirpan.com/2020/08/18/ai-timelines.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article>
    <p>For this post, I’m going to take artificial general intelligence (AGI) to mean
an AI system that matches or exceeds humans at almost all (95%+)
economically valuable work. I prefer this definition because it focuses on what
causes the most societal change, rather than how we get there.</p>

<p>In 2015, I made the following forecasts about when AGI could happen.</p>

<ul>
  <li>10% chance by 2045</li>
  <li>50% chance by 2050</li>
  <li>90% chance by 2070</li>
</ul>

<p>Now that it’s 2020, I’m updating my forecast to:</p>

<ul>
  <li>10% chance by 2035</li>
  <li>50% chance by 2045</li>
  <li>90% chance by 2070</li>
</ul>

<p>I’m keeping the 90% line the same, but shifting everything else to
be faster. Now, if you’re looking for an argument of why I picked these particular
years, and why I shifted by 10 years instead of 5 or 15, you’re going to be
disappointed. Both are driven by a gut feeling.
What’s important is why parts of my thinking have changed - you can choose
your own timeline adjustment based on that.</p>

<p>Let’s start with the easy part first.</p>

<h2 id="i-should-have-been-more-uncertain">I Should Have Been More Uncertain</h2>

<p>It would be incredibly weird if I was never surprised by machine learning (ML)
research.
Historically, it’s very hard to predict the trajectory a research field will
take, and if I were never surprised, I’d take that as a personal failing to
not consider large enough ideas.</p>

<p>At the same time, when I think back on the past 5 years, I believe I was
surprised more often than average. It wasn’t all in a positive direction.
Unsupervised learning got better way faster than I expected. Deep reinforcement
learning got better
a little faster than I expected. Transfer learning has been slower than
expected. Combined, I’ve decided I should widen the distribution of outcomes,
so now I’m allocating 35 years to the 10%-90% interval instead of 25 years.</p>

<p>I also noticed that my 2015 prediction placed 10% to 50% in a 5 year range,
and 50% to 90% in a 20 year range. AGI is a long-tailed event, and there’s
a real possibility it’s never viable, but a 5-20 split is absurdly skewed.
I’m adjusting accordingly.</p>

<p>Now we’re at the hard part. Why did I choose to shift the 10% and 50% lines
closer to present day?</p>



<p>Three years ago, I was talking to someone who mentioned
that <a href="https://intelligence.org/2017/10/13/fire-alarm/">there was no fire alarm for AGI</a>.
I told them I knew Eliezer Yudkowsky had written another post about AGI, and
I’d seen it shared among Facebook friends, but I hadn’t gotten around to reading it.
They summarized it as, “It will never be obvious when AGI is going to occur.
Even a few years before it happens, it will be possible to argue AGI is far
away. By the time it’s common knowledge that AI safety is the most
important problem in the world, it’ll be too late.”</p>

<p>And my reaction was, “Okay, that matches what I’ve gotten from my Facebook
timeline. I already know the story of
Fermi predicting <a href="https://books.google.com/books?id=aSgFMMNQ6G4C&amp;pg=PA813&amp;lpg=PA813&amp;dq=weart+fermi&amp;source=bl&amp;ots=Jy1pBOUL10&amp;sig=c9wK_yLHbXZS_GFIv0K3bgpmE58&amp;hl=en&amp;sa=X&amp;ved=0ahUKEwjNofKsisnWAhXGlFQKHbOSB1QQ6AEIKTAA#v=onepage&amp;q=%22ten%20per%20cent%22&amp;f=false">a nuclear chain reaction was very likely
to be impossible</a>, only a few years before he worked on the
Manhattan Project. More recently, we had
<a href="https://www.wired.com/2014/05/the-world-of-computer-go/">Rémi Coulom state that superhuman Go was about 10 years away</a>,
one year before <a href="https://arxiv.org/abs/1412.6564">the first signs it could happen</a>,
and two years before <a href="https://en.wikipedia.org/wiki/AlphaGo_versus_Lee_Sedol">AlphaGo</a> made it official.
I <em>also</em> already know the <a href="https://en.wikipedia.org/wiki/Common_knowledge_(logic)">common knowledge</a>
arguments for AI safety.”
I decided it wasn’t worth my time to read it.</p>

<p>(If you haven’t heard the common knowledge arguments, here’s the quick
version: it’s possible for the majority to believe AI safety is
worthwhile, even if no one says so publicly, because each individual could be
afraid everyone else will call them crazy if they argue for drastic action. This can happen
even if literally everyone agrees, because they don’t know that everyone agrees.)</p>

<p>I read the post several years later out of boredom, and
I now need to retroactively complain to all my Facebook friends who only
shared the historical events and common knowledge arguments. Although
that post summary is <em>correct</em>, the ideas I found useful were all
<em>outside that summary</em>. I trusted you, filter bubble! How could you let me
down like this?</p>

<p>Part of the fire alarm post proposes hypotheses for why people claim AGI is
impossible. One of the hypotheses is that researchers pay too much attention
to the difficulty of getting something working with their current tools,
extrapolate that difficulty to the future, and conclude we could never create
AGI because the available tools aren’t good enough.
This is a bad argument, because your extrapolation needs to account for
research tools also improving over time.</p>

<p>What “tool” means is a bit fuzzy. One clear example is our coding libraries.
People used to write neural nets in Caffe, MATLAB, and Theano. Now it’s mostly
TensorFlow and PyTorch. A less obvious example is
feature engineering for computer vision. When was the
last time anyone talked about <a href="https://en.wikipedia.org/wiki/Scale-invariant_feature_transform">SIFT features</a> for computer vision? Ages ago,
they’re obsolete. But feature engineering didn’t disappear, it just turned into
<a href="https://en.wikipedia.org/wiki/Convolutional_neural_network">convolutional neural net</a> architecture tuning instead.
For a computer vision researcher, SIFT features were the old tool,
convolutional neural nets are the new tool, and computer vision is the application
that’s been supercharged by the better tool.</p>

<p>Whereas for me, I’m not a computer vision person. I think ML for control is a much
more interesting problem. However, you have to do computer vision to do control
in image-based environments, and if you want to handle the real world, image-based
inputs are the way to go. So for me, computer vision is the tool, robotics
is the application, and the improvements in computer vision have driven many
promising robot learning results.</p>

<p><img src="https://www.alexirpan.com/public/ai-timelines/filters.png" alt="AlexNet conv filters"></p>

<p>(Filters automatically learned by <a href="https://en.wikipedia.org/wiki/AlexNet">AlexNet</a>, which has
itself been obsoleted by the better tool, <a href="https://en.wikipedia.org/wiki/Residual_neural_network">ResNets</a>.)</p>

<p>I’m a big advocate for research tools. I think on average, people underestimate
their impact. So after reading the hypothesis that people don’t forecast
tool improvement properly, I thought for a bit, and decided I hadn’t properly
accounted for it either. That deserved shaving off a few years.</p>

<p>In the more empirical sides of ML, the obvious components of progress are your
ideas and computational budget, but there are less obvious ones too, like
your coding and debugging skills, and your ability to utilize your compute.
It doesn’t matter how many processors you have per machine, if your code doesn’t
use all the processors available.
There are a surprising number of ML applications where the main value-add
comes from better data management and data summarizing,
because those tools free up decision making time for everything else.</p>

<p>In general, everyone’s research tools are deficient in some way.
Research is
about doing something new, which naturally leads to discovering new problems,
and it’s highly unlikely someone’s already made the perfect tool for a problem
that didn’t exist three months ago. So, your current
research tools will <em>always</em> feel janky, and you shouldn’t be using that to
argue anything about timelines.</p>

<p>The research stack has lots of parts, improvements continually happen across that
entire stack, and most of
these improvements have multiplicative benefits. Multiplicative factors
can be very powerful.
One simple example is that to get 10x better results, you can either make one
thing 10x better with a paradigm shift, or you can make ten different
things
<a href="https://www.google.com/search?&amp;q=1.26^10">1.26x better</a>, and they’ll combine
to a 10x total improvement.
The latter is just as transformative, but can be much easier,
especially if you get 10 experts with different skill sets
to work together on a common goal. This is how corporations become a thing.</p>

<p><img src="https://www.alexirpan.com/public/ai-timelines/tiny-gains-graph.jpg" alt="Tiny gains graph"></p>

<p>(From <a href="https://jamesclear.com/marginal-gains">JamesClear.com</a>)</p>

<h2 id="semi-supervised-and-unsupervised-learning-are-getting-better">Semi-Supervised and Unsupervised Learning are Getting Better</h2>

<p>Historically, unsupervised learning has been in this weird position where it is
obviously the right way to do learning, and also a complete waste of time if
you want something to work ASAP.</p>

<p>On the one hand, humans don’t have labels for most things they learn,
so ML systems shouldn’t need labels either. On the other hand, the
deep learning boom of 2015 was mostly powered by supervised learning on
large, labeled datasets.
Richard Socher made a notable tweet at the time:</p>

<div>
<blockquote><p lang="en" dir="ltr">Rather than spending a month figuring out an unsupervised machine learning problem, just label some data for a week and train a classifier.</p>— Richard Socher (@RichardSocher) <a href="https://twitter.com/RichardSocher/status/840333380130553856?ref_src=twsrc%5Etfw">March 10, 2017</a></blockquote> 
</div>

<p>I wouldn’t say unsupervised learning has always been useless. In 2010, it was
common wisdom that deep networks should go through an unsupervised pre-training
step before starting supervised learning. See <a href="https://jmlr.csail.mit.edu/papers/volume11/erhan10a/erhan10a.pdf">(Erhan et al, JMLR 2010)</a>.
In 2015, self-supervised word vectors like <a href="https://nlp.stanford.edu/projects/glove/">GloVe</a>
and <a href="https://en.wikipedia.org/wiki/Word2vec">word2vec</a> were automatically
learning interesting relationships between words.
As someone who started ML around 2015,
these unsupervised successes felt like exceptions to the rule. Most other
applications relied on labels. Pretrained ImageNet features
were the closest thing to general behavior, and those features were learned
from scratch through only supervised learning.</p>

<p>I’ve long agreed that unsupervised learning is the future, and the right way
to do things, as soon as we figure out how to do so.
But man, we have spent a long time trying to do so.
That’s made me
pretty impressed with the semi-supervised and unsupervised learning papers from
the past few months.
Momentum Contrast from <a href="https://arxiv.org/abs/1911.05722">(He et al, CVPR 2020)</a>
was quite nice, SimCLR from <a href="https://arxiv.org/abs/2002.05709">(Chen et al, ICML 2020)</a> improved
on that, and Bootstrap Your Own Latent <a href="https://arxiv.org/abs/2006.07733">(Grill, Strub, Altché, Tallec, Richemond et al, 2020)</a>
has improved on that. And then there’s <a href="https://arxiv.org/abs/2005.14165">GPT-3</a>,
but I’ll get to that later.</p>

<p>When I was thinking through what made ML hard, the trend lines were pointing to larger
models and larger labeled datasets. They’re still pointing that way now.
I concluded that future ML progress would be bottlenecked by labeling requirements.
Defining a 10x bigger model is easy. <em>Training</em> a 10x bigger model is harder, but
it doesn’t need 10x as many people to work on it. Getting 10x as many labels
does. Yes, data labeling tools are getting better, <a href="https://en.wikipedia.org/wiki/Amazon_Mechanical_Turk">Amazon Mechanical Turk</a> is very popular, and there are even
startups whose missions are to provide fast data labeling …</p></article></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://www.alexirpan.com/2020/08/18/ai-timelines.html">https://www.alexirpan.com/2020/08/18/ai-timelines.html</a></em></p>]]>
            </description>
            <link>https://www.alexirpan.com/2020/08/18/ai-timelines.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24269316</guid>
            <pubDate>Tue, 25 Aug 2020 08:41:32 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[DIY Single-Chip 2D Retro Game Console]]>
            </title>
            <description>
<![CDATA[
Score 124 | Comments 25 (<a href="https://news.ycombinator.com/item?id=24268585">thread link</a>) | @0xmarcin
<br/>
August 24, 2020 | http://www.voja.rs/PROJECTS/GAME_HTM/1_intro.htm | <a href="https://web.archive.org/web/*/http://www.voja.rs/PROJECTS/GAME_HTM/1_intro.htm">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
    <td rowspan="4">
      <div>
			<iframe width="420" height="315" src="//www.youtube.com/embed/VbTwWFwbsE4" frameborder="0" allowfullscreen=""></iframe>
			<p>
			<img height="420" src="http://www.voja.rs/PROJECTS/GAME_HTM/console.jpg" width="600"></p>
			<p>This 
			DIY project offers the
            simple stand-alone VGA game console which is based on <b> PIC24EP512GP202</b>  microcontroller.
            As the video signal and the corresponding sync signals are generated by software, 
			the console contains a
            minimum of hardware. There is also an audio signal output with five binary tone channels, mixed by 
			a 
			passive resistor network. Two of those channels are used for sound effects,  
			similar to ones used in video games of that time (early eighties) and 
			three for background music. This output is capable of driving line 
			output for PC speakers or headphones.</p>
			<p>
			It should be noted that there is no video processing unit, PGA or 
			any special purpose chips, and that PIC microcontrollers are not 
			designed for video signal generation. Everything is achieved by a 
			series of different design tricks and some compromises.</p>
			<p>
			This is an open hardware and open software project. Video 
			and audio generators, which are the vital parts of the firmware, are 
			the parts of the operating system, which will soon be documented, and can be used 
			for any other game or application. As the timings are critical, those parts 
			are written in assembly language, but all the other parts of the 
			program (scenario for some other games or any other application) may 
			also be written in some other programming language, preferably 
			Microchip's C. In this case all parts are written in Assembler, but 
			only as a result of author's preference.</p>
			<p>
			At the moment, only the game Jumping Jack is written for the 
			platform, well known to those who played with the Spectrum personal 
			computer back in the day. However, once a new game is created, it is 
			easy to download it from the computer, via 
			the serial port. The console has a USB connector, but it is used 
			only for 5V power supply. Unfortunately, microcontrollers which are 
			packed in DIP packages (with thru-hole soldering, convenient for DIY 
			projects and workshops) do not have USB interface but only serial ports, so 
			you have to use RS 232 to download the new game instead of Jumping 
			Jack, which is deafult in this project.</p>
			<p>
			If you want to build this console, you need the PCB and components 
			which are listed <span><strong>
			<a href="http://www.voja.rs/PROJECTS/GAME_HTM/2.%20Hardware.htm#BOM">here</a></strong></span>. 
			To program the microcontroller, you should need a PIC programmer (e.g. 
			<strong>PICKIT3</strong>, avaliable <span><strong>
			<a href="http://www.microchipdirect.com/ProductSearch.aspx?Keywords=PG164130">here</a></strong></span>) and
			<strong>MPLAB X IDE</strong> software, available <span><strong>
			<a href="http://www.microchip.com/pagehandler/en-us/family/mplabx/">here</a></strong></span>. 
			But if you want to know how PIC generates video and audio signals by 
			software in real time, or even if you feel ambitious enough to 
			create your own game for this platform, please visit the
			<span>
			<strong><a href="http://www.voja.rs/PROJECTS/GAME_HTM/2.%20Hardware.htm">next page</a></strong></span></p>
          </div>
    </td>
  </div></div>]]>
            </description>
            <link>http://www.voja.rs/PROJECTS/GAME_HTM/1_intro.htm</link>
            <guid isPermaLink="false">hacker-news-small-sites-24268585</guid>
            <pubDate>Tue, 25 Aug 2020 06:23:11 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[The Renaissance of the Shell?]]>
            </title>
            <description>
<![CDATA[
Score 41 | Comments 59 (<a href="https://news.ycombinator.com/item?id=24268533">thread link</a>) | @dwmkerr
<br/>
August 24, 2020 | https://effective-shell.com/docs/part-1-transitioning-to-the-shell/6-the-renaissance-of-the-shell/ | <a href="https://web.archive.org/web/*/https://effective-shell.com/docs/part-1-transitioning-to-the-shell/6-the-renaissance-of-the-shell/">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><article><p>This is the first of the “interludes” which end each section of the book. They don't teach any specific skills but instead give a little flavour and background about the world of the shell, Linux and modern computing.</p><p>In this first interlude we'll look at just why the shell is experiencing something of a renaissance in the modern age of IT.</p><p>To be honest, it is hard to know whether there is an increase in popularity of the use of the shell and command-line tooling in general. There are data sources which indicate there is more widespread usage amongst the technical community - Stack Overflow tag popularity is one. LinkedIn data on desired skillsets is another. However, disassociating whether there is a general increase in the need for diverse technical skillsets and whether there is a <em>specific</em> increase in the popularity of keyboard and script operated systems is a challenge.</p><p>For the purposes of this chapter, we'll instead examine changes in the technology landscape over the last few decades and consider what those changes might mean for the shell, the command-line and similar tools.</p><p>We'll look at three specific developments in technology:</p><ul><li>Diversity of programming languages</li><li>Convergence of operating platforms</li><li>DevOps</li></ul><p>Each of these developments has a potentially profound impact on how we work with computers, and might hint at the long term need for shell skills.</p><p>So let's look at some of the key changes in the technology landscape over recent years and consider how they might affect the popularity and importance of the shell.</p><h2 id="the-diversity-of-programming-languages">The Diversity of Programming Languages</h2><p>There have been many programming languages and platforms over the years. But in recent years it is possible that the diversity has increased at a greater rate than ever before.</p><p>With the advent of the internet and the increase in the size of the online technical community, programming has in a sense become more democratised (which we will discuss a little more in the ‘citizen coder’ section). When in the past it was necessary to find physical books or teachers and tutors to learn a programming language, students can now find a wealth of resources online.</p><p>It is perhaps this democratisation which has led to a startlingly diverse world of programming languages. For many years, there were a small number of ‘general purpose’ languages, and a larger number of highly specialised languages (and associated platforms).</p><p>“C”, and later, “C++” were the go-to languages for systems programming (sometimes backed up by assembly language). This was the language which kernels and compilers were written in.</p><p>“Java” become the ‘general purpose’ language of choice for applications which had to run on many systems. “Basic” and later “C#” were the standards for Windows platform development. PHP was a staple for web development.</p><p>Alongside these giants were the workhorses for specific use cases. Erlang was (and is) a language which is highly popular in the telecommunications industry, where high availability and reliability were paramount. COBOL was the language for the financial industry, where mission critical systems ran on mainframes (and many still do).</p><p>Of course there were many other languages, but many of these other languages were highly specific, in a sense C, Java, PHP and later C# dominated the landscape.</p><p>Transition to the time of writing. In the Stack Overflow 2020 Technology Survey[^1], the top ten languages most wanted by employers are:</p><ul><li>Python</li><li>JavaScript</li><li>Go</li><li>TypeScript</li><li>Rust</li><li>Kotlin</li><li>Java</li><li>C++</li><li>SQL</li><li>C#</li></ul><p>Some of our old friends are there, but there are many new languages, languages which are evolving quickly. Later on in the list we will see Swift, Dart, Ruby, Haskell, Scala. There are many programming languages which are extremely popular today.</p><p>Why does this matter for the shell? The answer is that for <em>many</em> new languages, developer tooling is not as mature (some might say bloated) as it is for the ‘Workhorse’ languages. Java developers are likely very familiar with the Eclipse IDE, Microsoft shops will be familiar with Visual Studio. These are products which have been evolving for years (or decades) to support developers with rich integrated development environments.</p><p>For server-side JavaScript, Golang, Rust, Python and other languages, the development environment really is the shell. Modern editors like Visual Studio Code, Atom and so on provide a vast amount of support and tooling, encompassing the features of a full fledged IDE if the user wants. But for modern programming languages, users often have <em>had</em> to rely on the shell to compile, transpile, manage packages, bundle and so on. The average developer today is perhaps much more likely to have to use the shell - to manage Python virtual environments one day, to run Node.js another, to install packages for Golang another.</p><p>In time tooling will likely catch up and provide a ‘friendly’ interface on top of these operations, but many engineers have realised (or always known) that direct access to simple command line tools can be <em>extremely efficient</em> when working, and that overly featured IDEs can get in the way and hide complexity.</p><p>The modern programming is often polyglot - having to be at least familiar in a number of languages. The shell provides a common environment and interface for tooling, which is accessible by all, without installing many complex components, for both development and runtime environments.</p><h2 id="convergence-of-operating-platforms">Convergence of Operating Platforms</h2><p>Whilst the variety in programming languages and developer tooling may have increased, in many ways the <em>operating platforms</em> engineers use have become more homogeneous.</p><p>In the early days of computing, each operating environment was highly diverse. There were many systems which were used for production and many of them were highly proprietary. Even popular application servers were often closed source and highly specialised.</p><p>The modern execution environment however is often fairly uniform. A Linux-like system, with few customisations, which the developer or operator can tweak to suit their needs.</p><p>More and more enterprise users have moved away from proprietary Unix platforms to Linux platforms (whether commercial or non-commercial). The earliest cloud environments were using open-source Linux distributions as the available operating systems.</p><p>Even Windows has increasing support for Linux-like operation, in the form of the Windows Subsystem for Linux.</p><p>Perhaps the greatest movement in this area has been the rapid adoption of Docker as a common container technology. Containers, or container-like systems have been around for a long time, but Docker brought containers to the masses. With Docker, engineers expect operating environments to be even more uniform and Linux-like.</p><p>This has made knowledge of the shell extremely valuable. For any containerised workloads, Linux and shell skills are crucial. Kubernetes (as an execution environment) has standardised things even more.</p><p>Whilst there are still many workloads which run on proprietary systems, modern solutions are often built to run in containers on Linux. The shell has historically been the most common way to manage Linux systems, and the standardisation of operating environments around Linux, or Linux-like systems has made shell skills even more critical.</p><h2 id="devops">DevOps</h2><p>Love it or hate it, DevOps has exploded in popularity. DevOps engineers, site-reliability engineers, these kinds of roles may have been unheard of in companies not that long ago and are now becoming ubiquitous.</p><p>In attempting to unify the goals of development and operation of software, DevOps represents an organisational and cultural change. Rather than having one group focus on feature development and another group focus on reliable software operations, a single group is responsible for both. The theory is that this encourages software engineers to also consider security, reliability, maintainability etc, and operators to also consider speed of delivery.</p><p>Regardless of whether teams are genuinely combined, or specialised roles are added to teams, or even if teams are still separated, the lines between development and operations blur somewhat. Software developers are expected to build and plan with knowledge of the execution environment, operators are expected to work with developers to build features which support reliability.</p><p>The intersection of these two roles often is in the realm of automation. Automated deployments after testing, automated failover in case of errors, automated alerting when potential issues are discovered, automated provisioning of environments, automated scaling of systems when load increases.</p><p>The world of automation is intimately linked to the world of the shell and in particular shell scripting. Many tasks which require automation can be easily achieved using shell scripts. Many aspects of modern environments (such as cloud environments) support provisioning and management of services via scripting. In fact, services which <em>cannot</em> be managed via shell scripts or simple interfaces are increasingly becoming obsolete. If it cannot be scripted, it cannot be automated, and the increasingly complex systems we build <em>require</em> automation.</p><p>In practice, this means software engineers are far more likely to have to build shell scripts (or at least understand how to interface with systems via the shell) than they perhaps might have been. Similarly, operators are far more likely to have to <em>program</em> automated routines to manage high availability and so on. Again, the shell and shell scripts are a common way to manage this (even if they are simply entrypoints to more complex systems, such as scripts which execute programs).</p><p>The rise in popularity of DevOps as a set of practices and beliefs has perhaps made the shell more popular, and more important, than any other recent developments in software engineering.</p><p>And for these reasons and many more, learning how to use the shell effectively has never been more relevant or practical.</p></article></div>]]>
            </description>
            <link>https://effective-shell.com/docs/part-1-transitioning-to-the-shell/6-the-renaissance-of-the-shell/</link>
            <guid isPermaLink="false">hacker-news-small-sites-24268533</guid>
            <pubDate>Tue, 25 Aug 2020 06:13:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[Animal behavior during a solar eclipse]]>
            </title>
            <description>
<![CDATA[
Score 55 | Comments 36 (<a href="https://news.ycombinator.com/item?id=24268252">thread link</a>) | @everbody
<br/>
August 24, 2020 | https://readwildness.com/23/poli-eclipse | <a href="https://web.archive.org/web/*/https://readwildness.com/23/poli-eclipse">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><section>
				
				<p><span>The farm dimmed mid-afternoon</span>, dipping into dusk-light. Beside the parked tractors, we passed around a block of green glass from a welder’s helmet and took turns looking through it up at the sky. I chewed a single pebble of a snap pea in my mouth. That was the size of the sun through the glass, I thought, no bigger than a pea, a sliver missing as if chewed by a caterpillar or potato beetle.</p>
				
				<p>In a total solar eclipse, photosynthesis slows down. Plants, which turn to face the sun throughout the day, may change direction, feeling for the light. Without the sun, they become unmoored. Lost in the dark. In the 2017 eclipse, changes in light intensity were attributed to bees going temporarily still. Observers in the path of totality—the stretch of land where the sun goes fully dark—reported fireflies emerging, crickets chirping. Night behavior bleeding into day.</p>
				
				<p>I stared through the glass. Sun the size of a blueberry. Size of a chrysanthemum bud.</p>
				
				<p>We wouldn’t get to see the total eclipse—that dramatic upheaval of the afternoon’s forward march, an ebb when there should be flow. The path of totality was south of us, stretching from Oregon to South Carolina. Still, the light waned at our small farm. Contrast became muted, the sky and hayfields feeling duller, softer. The zinnia patch still sparked with its shocks of red, orange, pink, yellow, but the flowers seemed unsure of themselves. The shadows from the trees did strange things, cast crescent-shaped spells on the ground, reminding me of the light funneled through a dime-store kaleidoscope. Someone arrived with a pair of glasses—the kind made from plastic and cardboard that they’d been selling at gas stations for months, running out in the final few days. We passed them around, but <span>I preferred the welding glass, the way it turned the sliver of sun goblin-green.</span></p>
				
				<p>Sun the size of a kernel of the summer’s first sweet corn; the size of a worm, coiled inside an ear from the later crop, chewing on its silky tassel.</p>
				
				<p>During a total solar eclipse, dairy cows have been known to return to their barn as the sun and sky darken. Orb-weaving spiders have been observed taking down their webs during totality, then rebuilding them <span>when the sun reappears. Some species of birds will sing out their night calls,</span> then go to their roosts, falling silent; when the sun reappears, they start their morning rituals. In this sense, the eclipse is a microcosm of night, the dark sped up, the hour hand spinning around a clock at a horse’s trot.</p>
				
				<p>Sun the size of a pepper seed. Size of a flea beetle. A ladybug resting on a windowsill. A thistle bur stuck to a coat.</p>
				
				<p>There is no evidence that an eclipse affects the behavior of horses, but nevertheless, there will be some owners who usher them into the safety of the barn before the sky goes dark. This is a form of love which happens to involve a kind of captivity.</p>
				
				<p>Sun the size of a nostril, size of a belly button, a baby’s tooth, a fingertip. Size of the chunk of flesh I’d sliced off the top of my thumb one day when I was careless with a head of cauliflower. It bled so much and so steadily that I ran to the back of the farm stand where someone sat me down on a bench to bandage the cut. I remember they held my hand so carefully, tilting it one direction then the other, saying twice, maybe three times, <i>You need to be more careful</i>.</p>
				
				<p>Once we’d passed around the glass, we scattered to our different jobs. I drove back to the snap pea patch, where I continued filling a bucket with round, ripe pods. I heard a tractor starting, the exhaust clearing its throat, then watched from where I was crouched as someone connected a hay rake to the back and pulled back onto the road, headed for one of the higher fields, leaving a cloud of dust and acres of silence behind. I realized then that the birds, which were usually a constant chorus, had gone quiet—the small snapping of my hands plucking peas from their vines, the only noise that reached me. I stood, stretching, and looked at the sky, the familiar fields—their flat, muted light. I stood there looking at the farm that for years I had grown to know and care for, and I thought of scale—of how the land surrounding me had come to feel like it was my own body, a breathing, pulsing creature that could weep or swell; and, at the same time, how the land felt unthinkably large—a roaring sun—the weight of it and of the people who worked it reaching deep into the smallest cracks and crevasses of my life like the tendrilled arms of solar flares bursting.</p>
				
				<p>I thought of all of this as I rolled another snap pea over my tongue, biting down, tasting the small eruption of green. Then I bent down, knees to dirt, to finish my work.</p>
				
				<hr>
				
				<p>Read more from <a href="https://readwildness.com/23">Issue No. 23</a> or share  on <a href="http://www.facebook.com/share.php?u=http://readwildness.com/23/poli-eclipse">Facebook</a> and <a href="https://twitter.com/share?url=http://readwildness.com/23/poli-eclipse&amp;via=platypuspress&amp;related=twitterapi%2Ctwitter&amp;hashtags=wildnessjournal&amp;text=Check%20this%20out">Twitter</a>.</p>
				
			</section></div>]]>
            </description>
            <link>https://readwildness.com/23/poli-eclipse</link>
            <guid isPermaLink="false">hacker-news-small-sites-24268252</guid>
            <pubDate>Tue, 25 Aug 2020 05:02:55 GMT</pubDate>
        </item>
        <item>
            <title>
<![CDATA[rc.d belongs in libexec, not etc]]>
            </title>
            <description>
<![CDATA[
Score 70 | Comments 65 (<a href="https://news.ycombinator.com/item?id=24267933">thread link</a>) | @Khaine
<br/>
August 24, 2020 | https://jmmv.dev/2020/08/rcd-libexec-etc.html | <a href="https://web.archive.org/web/*/https://jmmv.dev/2020/08/rcd-libexec-etc.html">archive.org</a>
<br/><!-- hnss:readable-content --><hr/><div id="readability-page-1" class="page"><div>
            <div>
              
              <article>

<p>Let’s open with the controversy: the scripts that live under <code>/etc/rc.d/</code> in FreeBSD, NetBSD, and OpenBSD are in the wrong place. They all should live in <code>/libexec/rc.d/</code> because they are code, <em>not</em> configuration.</p>

<p>This misplacement is something that has bugged me for ages but I never had the energy to open this can of worms back when I was very involved in NetBSD. I suspect it would have been a draining discussion and a very difficult thing to change.</p>

<p>But… what am I talking about anyway?</p>

<p>If you have administered a BSD system, you have certainly encountered the <code>/etc/rc.d/</code> directory; and if you have administered pre-systemd Linux systems, you have dealt with <code>/etc/init.d/</code>. These directories contain startup scripts to configure the system at boot time and are immutable. Their code is parameterized to allow changing their behavior via configuration files, not via code edits. And that’s the base of my critique.</p>

<p>But before getting into why the current state is problematic and how things should look like, let’s first dig into how we got here. And, for that, we need to go back in history.</p>



<p>4.4BSD’s (1993) boot process was rather simple: the kernel started <code>init</code> which in turn ran the <code>/etc/rc</code> script before starting <code>getty</code> on each console. The <code>/etc/rc</code> monolith was in charge of configuring the machine’s file systems and processes, and delegated to two other scripts: <code>/etc/netstart</code> for network configuration and <code>/etc/rc.local</code> for locally-added services. Current BSD systems are more advanced in this area as we shall see later, but the core boot process remains the same: <code>/etc/rc</code> is the primary entry point and bootstraps a collection of shell scripts.</p>

<p>In the early days, package management and file provenance tracking, like we are used to having in popular Linux distributions, was not a thing. You were expected to tune the systems’ behavior by <em>editing</em> files which might or might not have been designed to support edits. If you had to edit <code>/etc/rc</code>, which was a script shipped by the system, that was alright.</p>

<p><code>/etc/rc.local</code>, on the other hard, was <em>not</em> shipped by the system, and it was up to you to create it if you wanted to add custom startup commands without modifying <code>/etc/rc</code>. And this is where things get interesting. <code>/etc/rc.local</code> didn’t need to be supported: if you were expected and able to edit <code>/etc/rc</code> anyway, why would you deal with a separate file? The reason is, most likely, to simplify system upgrades: during an upgrade, you want to benefit from any upstream changes made to <code>/etc/rc</code> (some of which might actually be <em>necessary</em> for proper system operation). Applying updates to a manually-modified file is tricky, so putting as many of your manual overrides into <code>/etc/rc.local</code> helped minimize this problem.</p>



<p>System V 4 (SVR4, 1988) also came with its own, and very different, boot process. The key difference was that System V had the concept of runlevels. As a result, configuring the boot process was a more convoluted endeavour because it was possible to select different services per runlevel.</p>

<p>To accomplish per-runlevel tuning, the system used <a href="https://jmmv.dev/2020/08/config-files-vs-directories.html">configuration directories rather than files</a>: there was a separate <code>/etc/rcX.d/</code> directory for each runlevel (where <code>X</code> was the number of the runlevel), and these directories contained one file per action to take at startup time. To avoid duplicates, these files were just symlinks to common files under <code>/etc/init.d/</code>—and the symlinks, not their targets, were named so that their lexicographical order determined startup execution order.</p>

<p>Once again, we can already observe issues here: the symlinks under <code>/etc/rcX.d/</code> <em>are</em> configuration because their presence indicates what to start and their names determine their startup order. But the files under <code>/etc/init.d/</code> are <em>not</em>: they are shell scripts shipped with the system and should not be manually modified.</p>



<p>NetBSD <a href="http://www.mewburn.net/luke/papers/rc.d.pdf">modernized the boot process</a> in its 1.5 release (2000), and it did so in two ways: first, it introduced <code>/etc/rc.d/</code> as a directory to contain separate scripts per action and service; and, second, it introduced <a href="https://netbsd.gw.com/cgi-bin/man-cgi?rcorder+8+NetBSD-9.0-STABLE">the <code>rcorder(8)</code> tool</a> to determine the order in which these services run. <code>rcorder(8)</code> uses dependency information encoded in the scripts as comments—not lexicographical ordering as System V did. FreeBSD <a href="https://www.freebsd.org/cgi/man.cgi?query=rc&amp;apropos=0&amp;sektion=8&amp;manpath=FreeBSD+12.1-RELEASE&amp;arch=default&amp;format=html">inherited this design</a> in its 5.0 release (2003) and OpenBSD reimplemented something similar in its 4.9 release (2011).</p>

<p>With these two pieces in place, the <code>/etc/rc</code> script in NetBSD and FreeBSD changed to execute all files from <code>/etc/rc.d/</code> based on the output of <code>rcorder(8)</code>. Among these scripts is <a href="https://github.com/NetBSD/src/blob/8f8c6d6b2a8778b653d9630f3f18e057b477a012/etc/rc.d/local"><code>/etc/rc.d/local</code></a>, whose purpose is to run <code>/etc/rc.local</code> if it exists. And that’s all, really. The <code>/etc/rc</code> script thus became <a href="https://github.com/NetBSD/src/blob/8f8c6d6b2a8778b653d9630f3f18e057b477a012/etc/rc">trivial</a>.</p>

<p>The key thing to notice here is that the scripts shipped in <code>/etc/rc.d/</code> are <em>highly configurable</em> via the user-controlled <a href="https://github.com/NetBSD/src/blob/8f8c6d6b2a8778b653d9630f3f18e057b477a012/etc/rc.conf"><code>/etc/rc.conf</code></a> file. This essentially makes the scripts read-only, as it shifts local customizations to the configuration file. <em>System administrators are not supposed to edit the scripts.</em> Instead, they are supposed to: modify <code>/etc/rc.conf</code> to customize what gets run and how; add new scripts under <code>/etc/rc.d/</code> if they so choose; and edit <code>/etc/rc.local</code> to easily run arbitrary commands.</p>



<p>My main gripe is that the files under <code>/etc/rc.d/</code> are immutable scripts. They do not belong in <code>/etc/</code> and their presence there makes system upgrades harder for no good reason.</p>

<p>You see: in NetBSD and FreeBSD, system upgrades happen by unpacking new distribution sets in the root directory and then running a script to incorporate configuration updates. This script is interactive and helps highlight how new system-provided updates to configuration files conflict with previous manual edits. (This process might seem rudimentary to you, but it’s actually pretty robust and easy to understand—and you can use tooling like <a href="https://github.com/jmmv/sysupgrade/">sysupgrade</a> to make it trivial.)</p>

<p>So why is that a problem? Because you will <em>always</em> face merges like this:</p>
<div><pre><code data-lang="diff"><span>--- /etc/rc.d/npf               2019-08-09 19:09:42.800758233 -0400
</span><span></span><span>+++ /tmp/temproot/etc/rc.d/npf  2019-11-16 10:39:27.000000000 -0500
</span><span></span><span>@@ -1,6 +1,6 @@
</span><span></span> #!/bin/sh
 #
<span>-# $NetBSD: npf,v 1.3 2012/11/01 06:06:14 mrg Exp $
</span><span></span><span>+# $NetBSD: npf,v 1.4 2019/04/19 18:36:25 leot Exp $
</span><span></span> #
 # Public Domain.
 #
<span>@@ -36,7 +36,11 @@
</span><span></span>        echo "Enabling NPF."
        npf_cfg_check
        /sbin/npfctl reload
<span>-       /sbin/npfctl start
</span><span></span><span>+
</span><span>+       # The npf_boot script has enabled npf already.
</span><span>+       if [ "$autoboot" != "yes" ]; then
</span><span>+               /sbin/npfctl start
</span><span>+       fi
</span><span></span> }
 
 npf_stop()

File: /etc/rc.d/npf (modified)

Please select one of the following operations:

  d  Don't install the new file (keep your old file)
  i  Install the new file (overwrites your local modifications!)
  m  Merge the currently installed and new files
  s  Show the differences between the currently installed and new files
  su  Show differences in unified format ("diff -u")
  sc  Show differences in context format ("diff -c")
  ss  Show differences side by side ("sdiff -w187")
  scommand Show differences using the specified diff-like command
  v  Show the new file

What do you want to do? [Leave it for later]
</code></pre></div>
<p>And, really, who cares? Why are you being distracted to review a <em>code</em> change when what you are trying to do is assess <em>configuration</em> conflicts? How many times have you actually objected to these merges?</p>

<p>You might say: well, I want to know <em>exactly</em> how the boot process of my machine changes during an upgrade. Sure, that’s a fine goal, but then this procedure is flawed and completely insufficient to achieve such goal. In the example above, whatever <code>/etc/rc.d/npf</code> does can also be done from within the <code>/sbin/npfctl</code> binary it invokes… and you were never asked to review changes to the latter during an upgrade, were you? And <em>of course</em> you could review the binary’s code as part of your own system build, but if you did that, then you could have reviewed the startup script as well, right?</p>



<p>Startup scripts provided by the system need to live in a location that can contain executables—but we don’t want those executables to show up in the <code>PATH</code>. These requirements discard <code>bin</code> and <code>sbin</code>, and points us towards <code>libexec</code> on BSD systems and somewhere under <code>lib</code> on Linux.</p>

<p>Therefore, the read-only startup scripts should move from <code>/etc/rc.d/</code> to <code>/libexec/rc.d/</code> (which, by the way, also applies to <code>/etc/rc</code>, <code>/etc/rc.subr</code>, and <code>/etc/rc.shutdown</code>). And that’s it. <del><code>/etc/rc</code></del> <code>/libexec/rc</code> should continue to use <code>rcorder(8)</code> to check what’s needed to run, but it should read files from <code>/libexec/rc.d/</code>. You might even want to support a separate location for user-created services, which might still be <code>/etc/rc.d/</code> or, better yet, a more fitting location like <code>/usr/pkg/libexec/rc.d/</code> (though that quickly runs into problems if you have multiple file systems).</p>

<p>With this design, system upgrades would be much saner because the configuration merge process would focus, purely, on actual configuration changes and not on irrelevant code changes. All updates to <code>/libexec/rc.d/</code> would be applied by unpacking the new distribution sets (<code>base.txz</code> in this case) without disturbing you about how exactly they changed.</p>

<p>Does this relate to Linux distributions at all? I briefly mentioned <code>/etc/init.d/</code> at the beginning, and the problem there is similar. But it’s also an obsolete problem given that Linux distributions have moved onto systemd by now. That said, systemd still has to manage individual services and, like it or not, has gotten this right. If we look at the <a href="https://www.freedesktop.org/software/systemd/man/systemd.unit.html"><code>systemd.unit(5)</code></a> manual page, which describes where units are loaded from, the system first looks into various <code>/etc/</code> and <code>/run/</code> directories, but then also looks at <code>/usr/lib/systemd/system/</code> (a read-only location correctly controlled by the package manager)—and the vast majority of the scripts live inside the latter.</p>



<p>I currently don’t run BSD systems any more so my incentives to make this happen are low… but if this all makes sense and is something you’d like to pursue, by all means please do! I’m happy to help …</p></article></div></div></div>
<br/><p><em>Article truncated for RSS feed. Read the full article at <a href="https://jmmv.dev/2020/08/rcd-libexec-etc.html">https://jmmv.dev/2020/08/rcd-libexec-etc.html</a></em></p>]]>
            </description>
            <link>https://jmmv.dev/2020/08/rcd-libexec-etc.html</link>
            <guid isPermaLink="false">hacker-news-small-sites-24267933</guid>
            <pubDate>Tue, 25 Aug 2020 03:35:21 GMT</pubDate>
        </item>
    </channel>
</rss>
